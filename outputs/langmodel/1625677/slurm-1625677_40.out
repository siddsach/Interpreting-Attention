TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5188708305358887 and batch: 50, loss is 7.383351888656616 and perplexity is 1608.9738405504058
At time: 2.358762264251709 and batch: 100, loss is 6.631669225692749 and perplexity is 758.7476352220078
At time: 3.1857094764709473 and batch: 150, loss is 6.29790189743042 and perplexity is 543.4305401762807
At time: 4.012826919555664 and batch: 200, loss is 6.061224060058594 and perplexity is 428.9001151750025
At time: 4.839493036270142 and batch: 250, loss is 5.9252208232879635 and perplexity is 374.3610938811093
At time: 5.675968647003174 and batch: 300, loss is 5.781761932373047 and perplexity is 324.3301350511235
At time: 6.504471302032471 and batch: 350, loss is 5.687692594528198 and perplexity is 295.2116611622322
At time: 7.334334373474121 and batch: 400, loss is 5.583799924850464 and perplexity is 266.0807741358337
At time: 8.165742635726929 and batch: 450, loss is 5.485111494064331 and perplexity is 241.07582102278283
At time: 8.995026350021362 and batch: 500, loss is 5.427492866516113 and perplexity is 227.57796125355844
At time: 9.825737714767456 and batch: 550, loss is 5.361917104721069 and perplexity is 213.13315361158982
At time: 10.65701413154602 and batch: 600, loss is 5.364329805374146 and perplexity is 213.64800094700277
At time: 11.488957166671753 and batch: 650, loss is 5.416578245162964 and perplexity is 225.10754035732737
At time: 12.320805549621582 and batch: 700, loss is 5.3594178867340085 and perplexity is 212.6011524707655
At time: 13.151378154754639 and batch: 750, loss is 5.292709732055664 and perplexity is 198.88161178837544
At time: 13.983708620071411 and batch: 800, loss is 5.266990118026733 and perplexity is 193.83167310679545
At time: 14.815938472747803 and batch: 850, loss is 5.261004943847656 and perplexity is 192.67502161497612
At time: 15.647279262542725 and batch: 900, loss is 5.270399103164673 and perplexity is 194.49356995693924
At time: 16.481019258499146 and batch: 950, loss is 5.301376867294311 and perplexity is 200.61283715908698
At time: 17.31255078315735 and batch: 1000, loss is 5.258219776153564 and perplexity is 192.1391359814053
At time: 18.14453673362732 and batch: 1050, loss is 5.147750368118286 and perplexity is 172.04401893622264
At time: 18.97501826286316 and batch: 1100, loss is 5.234002666473389 and perplexity is 187.54197114613615
At time: 19.806408643722534 and batch: 1150, loss is 5.1245302486419675 and perplexity is 168.09516017269948
At time: 20.638314723968506 and batch: 1200, loss is 5.204043493270874 and perplexity is 182.00669885060123
At time: 21.470155715942383 and batch: 1250, loss is 5.154129133224488 and perplexity is 173.14495489391578
At time: 22.308418035507202 and batch: 1300, loss is 5.1717360401153565 and perplexity is 176.2204979414644
At time: 23.14538311958313 and batch: 1350, loss is 5.103183298110962 and perplexity is 164.5448698588138
At time: 23.983073949813843 and batch: 1400, loss is 5.1039926719665525 and perplexity is 164.67810208461594
At time: 24.821496963500977 and batch: 1450, loss is 5.047647514343262 and perplexity is 155.65585526710052
At time: 25.678319692611694 and batch: 1500, loss is 5.022947959899902 and perplexity is 151.85831681052386
At time: 26.566341876983643 and batch: 1550, loss is 5.007120494842529 and perplexity is 149.47370556339936
At time: 27.484246492385864 and batch: 1600, loss is 5.060283250808716 and perplexity is 157.63516028698243
At time: 28.41166615486145 and batch: 1650, loss is 5.026912631988526 and perplexity is 152.46158032140391
At time: 29.33995485305786 and batch: 1700, loss is 5.047161569595337 and perplexity is 155.58023349723882
At time: 30.267346620559692 and batch: 1750, loss is 5.043204851150513 and perplexity is 154.96586256563842
At time: 31.19619584083557 and batch: 1800, loss is 5.0037939071655275 and perplexity is 148.97729431199372
At time: 32.12324500083923 and batch: 1850, loss is 4.999960222244263 and perplexity is 148.4072556775989
At time: 33.04896664619446 and batch: 1900, loss is 5.073719673156738 and perplexity is 159.76750634803466
At time: 33.97699284553528 and batch: 1950, loss is 4.990079622268677 and perplexity is 146.94812337286405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.777649777434593 and perplexity of 118.82475699534285
finished 1 epochs...
Completing Train Step...
At time: 37.04932689666748 and batch: 50, loss is 4.962420330047608 and perplexity is 142.93933794001373
At time: 38.01260805130005 and batch: 100, loss is 4.925536479949951 and perplexity is 137.7632290317512
At time: 38.937068700790405 and batch: 150, loss is 4.873807535171509 and perplexity is 130.81806422348328
At time: 39.85885500907898 and batch: 200, loss is 4.846093320846558 and perplexity is 127.24232265578358
At time: 40.780638217926025 and batch: 250, loss is 4.846569700241089 and perplexity is 127.3029527167183
At time: 41.73049473762512 and batch: 300, loss is 4.8577179431915285 and perplexity is 128.73009725812446
At time: 42.65380644798279 and batch: 350, loss is 4.85967342376709 and perplexity is 128.98207274909774
At time: 43.57630801200867 and batch: 400, loss is 4.809378185272217 and perplexity is 122.65532491231923
At time: 44.49886631965637 and batch: 450, loss is 4.80075779914856 and perplexity is 121.60253290774521
At time: 45.42147159576416 and batch: 500, loss is 4.789366121292114 and perplexity is 120.22513635066277
At time: 46.343968629837036 and batch: 550, loss is 4.743213052749634 and perplexity is 114.80247613231005
At time: 47.26644825935364 and batch: 600, loss is 4.729974851608277 and perplexity is 113.29271318330352
At time: 48.18935465812683 and batch: 650, loss is 4.808292169570922 and perplexity is 122.52219160913101
At time: 49.12164378166199 and batch: 700, loss is 4.805298175811767 and perplexity is 122.15590952883916
At time: 50.04571032524109 and batch: 750, loss is 4.759950761795044 and perplexity is 116.74017768067984
At time: 50.97297549247742 and batch: 800, loss is 4.740109243392944 and perplexity is 114.44670354347964
At time: 51.895190715789795 and batch: 850, loss is 4.734157876968384 and perplexity is 113.76761204017586
At time: 52.81764268875122 and batch: 900, loss is 4.72554877281189 and perplexity is 112.79237878423805
At time: 53.74090790748596 and batch: 950, loss is 4.79652419090271 and perplexity is 121.08880365323084
At time: 54.664873123168945 and batch: 1000, loss is 4.77085578918457 and perplexity is 118.02019916547377
At time: 55.587379693984985 and batch: 1050, loss is 4.686173019409179 and perplexity is 108.43739690504786
At time: 56.50942397117615 and batch: 1100, loss is 4.756223821640015 and perplexity is 116.3059037838636
At time: 57.43244123458862 and batch: 1150, loss is 4.692723064422608 and perplexity is 109.14999797271939
At time: 58.354406118392944 and batch: 1200, loss is 4.760748500823975 and perplexity is 116.83334303253793
At time: 59.27626967430115 and batch: 1250, loss is 4.740331087112427 and perplexity is 114.47209564231093
At time: 60.199095726013184 and batch: 1300, loss is 4.741314277648926 and perplexity is 114.58469886958262
At time: 61.12110471725464 and batch: 1350, loss is 4.64644871711731 and perplexity is 104.21423342058978
At time: 62.0432813167572 and batch: 1400, loss is 4.650618782043457 and perplexity is 104.64972091467122
At time: 62.964415073394775 and batch: 1450, loss is 4.599013690948486 and perplexity is 99.38624173447441
At time: 63.88762903213501 and batch: 1500, loss is 4.5994436645507815 and perplexity is 99.4289843832984
At time: 64.8101487159729 and batch: 1550, loss is 4.5983568382263185 and perplexity is 99.32098104672173
At time: 65.73377275466919 and batch: 1600, loss is 4.665401048660279 and perplexity is 106.20817132667544
At time: 66.65386533737183 and batch: 1650, loss is 4.627722415924072 and perplexity is 102.28084539894495
At time: 67.58416175842285 and batch: 1700, loss is 4.652131805419922 and perplexity is 104.80817823334036
At time: 68.5084457397461 and batch: 1750, loss is 4.647069997787476 and perplexity is 104.27899982634487
At time: 69.44048357009888 and batch: 1800, loss is 4.609640903472901 and perplexity is 100.44807260518239
At time: 70.36591672897339 and batch: 1850, loss is 4.634251337051392 and perplexity is 102.95081367652874
At time: 71.29017043113708 and batch: 1900, loss is 4.71521990776062 and perplexity is 111.63335751630538
At time: 72.21560525894165 and batch: 1950, loss is 4.646792697906494 and perplexity is 104.25008728101209
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.603355514171511 and perplexity of 99.81869737048099
finished 2 epochs...
Completing Train Step...
At time: 75.28190779685974 and batch: 50, loss is 4.630324144363403 and perplexity is 102.54729885268058
At time: 76.22228646278381 and batch: 100, loss is 4.6034571647644045 and perplexity is 99.82884451597347
At time: 77.13562226295471 and batch: 150, loss is 4.569117784500122 and perplexity is 96.45897462207768
At time: 78.05391216278076 and batch: 200, loss is 4.5532963085174565 and perplexity is 94.94486061515286
At time: 78.97375512123108 and batch: 250, loss is 4.54648380279541 and perplexity is 94.3002464209326
At time: 79.90142178535461 and batch: 300, loss is 4.565769672393799 and perplexity is 96.13655920404993
At time: 80.8198676109314 and batch: 350, loss is 4.57486590385437 and perplexity is 97.0150289231963
At time: 81.73610305786133 and batch: 400, loss is 4.529017086029053 and perplexity is 92.66743218976669
At time: 82.65658688545227 and batch: 450, loss is 4.546940698623657 and perplexity is 94.34334165439148
At time: 83.57971501350403 and batch: 500, loss is 4.5408175086975096 and perplexity is 93.76742447972127
At time: 84.51034665107727 and batch: 550, loss is 4.501312656402588 and perplexity is 90.13537045097715
At time: 85.43298363685608 and batch: 600, loss is 4.490264368057251 and perplexity is 89.14500985680932
At time: 86.3559217453003 and batch: 650, loss is 4.568646411895752 and perplexity is 96.41351721852428
At time: 87.27868938446045 and batch: 700, loss is 4.573441247940064 and perplexity is 96.87691429473573
At time: 88.25948286056519 and batch: 750, loss is 4.530690441131592 and perplexity is 92.8226275224978
At time: 89.1825532913208 and batch: 800, loss is 4.516799411773682 and perplexity is 91.54213991423272
At time: 90.10370922088623 and batch: 850, loss is 4.51057861328125 and perplexity is 90.97444230522026
At time: 91.02495265007019 and batch: 900, loss is 4.494586715698242 and perplexity is 89.5311595152099
At time: 91.94634008407593 and batch: 950, loss is 4.580788421630859 and perplexity is 97.59130698063002
At time: 92.86767601966858 and batch: 1000, loss is 4.551627902984619 and perplexity is 94.78658615409546
At time: 93.79148936271667 and batch: 1050, loss is 4.48408429145813 and perplexity is 88.59578573908146
At time: 94.7219762802124 and batch: 1100, loss is 4.543666048049927 and perplexity is 94.03490546251368
At time: 95.65186929702759 and batch: 1150, loss is 4.491412000656128 and perplexity is 89.24737430330107
At time: 96.57895183563232 and batch: 1200, loss is 4.557705898284912 and perplexity is 95.36445293610032
At time: 97.50449109077454 and batch: 1250, loss is 4.545697221755981 and perplexity is 94.22610079967724
At time: 98.43158221244812 and batch: 1300, loss is 4.541055717468262 and perplexity is 93.78976336319654
At time: 99.36159420013428 and batch: 1350, loss is 4.4411890506744385 and perplexity is 84.87580332832637
At time: 100.28354263305664 and batch: 1400, loss is 4.45074875831604 and perplexity is 85.69108189749404
At time: 101.21179246902466 and batch: 1450, loss is 4.39128228187561 and perplexity is 80.74388905289904
At time: 102.13862943649292 and batch: 1500, loss is 4.401155529022216 and perplexity is 81.5450419070737
At time: 103.06215953826904 and batch: 1550, loss is 4.402345676422119 and perplexity is 81.64215030186367
At time: 103.9868803024292 and batch: 1600, loss is 4.478789930343628 and perplexity is 88.12796714918707
At time: 104.9117157459259 and batch: 1650, loss is 4.435741109848022 and perplexity is 84.4146622494117
At time: 105.83624339103699 and batch: 1700, loss is 4.467261781692505 and perplexity is 87.11784842983545
At time: 106.76134514808655 and batch: 1750, loss is 4.463230895996094 and perplexity is 86.76739313782686
At time: 107.68649220466614 and batch: 1800, loss is 4.423643836975097 and perplexity is 83.39962700354116
At time: 108.61099076271057 and batch: 1850, loss is 4.4583973217010495 and perplexity is 86.34900845799994
At time: 109.53574681282043 and batch: 1900, loss is 4.536265316009522 and perplexity is 93.34154716885864
At time: 110.46143078804016 and batch: 1950, loss is 4.467647485733032 and perplexity is 87.15145661696697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.534755972928779 and perplexity of 93.20076901848283
finished 3 epochs...
Completing Train Step...
At time: 113.5038115978241 and batch: 50, loss is 4.454933471679688 and perplexity is 86.0504258644089
At time: 114.39462447166443 and batch: 100, loss is 4.431195278167724 and perplexity is 84.03179828036674
At time: 115.29676508903503 and batch: 150, loss is 4.400031442642212 and perplexity is 81.45342973575261
At time: 116.1954607963562 and batch: 200, loss is 4.39124831199646 and perplexity is 80.74114623933255
At time: 117.08968234062195 and batch: 250, loss is 4.379173202514648 and perplexity is 79.77205080071424
At time: 117.99263596534729 and batch: 300, loss is 4.3992351722717284 and perplexity is 81.38859659885834
At time: 118.89592170715332 and batch: 350, loss is 4.411893472671509 and perplexity is 82.425386056007
At time: 119.7982497215271 and batch: 400, loss is 4.36417555809021 and perplexity is 78.5845848021151
At time: 120.70323014259338 and batch: 450, loss is 4.396050596237183 and perplexity is 81.12982068912304
At time: 121.60841059684753 and batch: 500, loss is 4.3959289646148685 and perplexity is 81.11995333751769
At time: 122.51119995117188 and batch: 550, loss is 4.358264675140381 and perplexity is 78.12145063405272
At time: 123.43124341964722 and batch: 600, loss is 4.3508028793334965 and perplexity is 77.54069376051748
At time: 124.34434223175049 and batch: 650, loss is 4.419910984039307 and perplexity is 83.08888879188368
At time: 125.26166296005249 and batch: 700, loss is 4.430673637390137 and perplexity is 83.98797529869054
At time: 126.17562103271484 and batch: 750, loss is 4.395596284866333 and perplexity is 81.09297086035085
At time: 127.08780694007874 and batch: 800, loss is 4.378156633377075 and perplexity is 79.69099820059526
At time: 128.00005435943604 and batch: 850, loss is 4.374122171401978 and perplexity is 79.37013558782282
At time: 128.91270542144775 and batch: 900, loss is 4.357717752456665 and perplexity is 78.07873592250324
At time: 129.82555484771729 and batch: 950, loss is 4.448273229598999 and perplexity is 85.47921351479366
At time: 130.74111032485962 and batch: 1000, loss is 4.415891246795654 and perplexity is 82.75556367958745
At time: 131.65812253952026 and batch: 1050, loss is 4.357079038619995 and perplexity is 78.02888187644919
At time: 132.57060647010803 and batch: 1100, loss is 4.4100181770324705 and perplexity is 82.2709589325023
At time: 133.48936986923218 and batch: 1150, loss is 4.361414060592652 and perplexity is 78.36787303006345
At time: 134.46502804756165 and batch: 1200, loss is 4.426060609817505 and perplexity is 83.60142871337267
At time: 135.36961150169373 and batch: 1250, loss is 4.420471076965332 and perplexity is 83.13543932582276
At time: 136.28753328323364 and batch: 1300, loss is 4.41277307510376 and perplexity is 82.4979195216909
At time: 137.19953966140747 and batch: 1350, loss is 4.31156156539917 and perplexity is 74.5568234404971
At time: 138.11184215545654 and batch: 1400, loss is 4.327459125518799 and perplexity is 75.75156661174563
At time: 139.0245988368988 and batch: 1450, loss is 4.259806079864502 and perplexity is 70.79625330400982
At time: 139.9342930316925 and batch: 1500, loss is 4.274555253982544 and perplexity is 71.84817801182366
At time: 140.8475911617279 and batch: 1550, loss is 4.2750699329376225 and perplexity is 71.88516627473085
At time: 141.77375721931458 and batch: 1600, loss is 4.363520650863648 and perplexity is 78.5331360385542
At time: 142.68667674064636 and batch: 1650, loss is 4.314937000274658 and perplexity is 74.80891035467737
At time: 143.59594202041626 and batch: 1700, loss is 4.350789661407471 and perplexity is 77.53966884013705
At time: 144.5089886188507 and batch: 1750, loss is 4.344944543838501 and perplexity is 77.0877623693631
At time: 145.41872334480286 and batch: 1800, loss is 4.305860147476197 and perplexity is 74.13295330963281
At time: 146.3239815235138 and batch: 1850, loss is 4.33860631942749 and perplexity is 76.60070799263222
At time: 147.23018670082092 and batch: 1900, loss is 4.418508539199829 and perplexity is 82.97244288214813
At time: 148.1378915309906 and batch: 1950, loss is 4.349028902053833 and perplexity is 77.40326026952411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5077605491460755 and perplexity of 90.71843138915833
finished 4 epochs...
Completing Train Step...
At time: 151.16414618492126 and batch: 50, loss is 4.336623983383179 and perplexity is 76.44901005597922
At time: 152.0635883808136 and batch: 100, loss is 4.313030967712402 and perplexity is 74.66645793819366
At time: 152.9456648826599 and batch: 150, loss is 4.2891386604309085 and perplexity is 72.90364665245258
At time: 153.82860231399536 and batch: 200, loss is 4.279565925598145 and perplexity is 72.20908908634782
At time: 154.71512579917908 and batch: 250, loss is 4.2696130752563475 and perplexity is 71.49396748178033
At time: 155.60913705825806 and batch: 300, loss is 4.2885606002807615 and perplexity is 72.86151613768142
At time: 156.50616264343262 and batch: 350, loss is 4.293471364974976 and perplexity is 73.22020188853122
At time: 157.4289906024933 and batch: 400, loss is 4.251866588592529 and perplexity is 70.23639251466285
At time: 158.3259289264679 and batch: 450, loss is 4.2898791313171385 and perplexity is 72.95764967166299
At time: 159.2224519252777 and batch: 500, loss is 4.29671875 and perplexity is 73.45836256608845
At time: 160.11917448043823 and batch: 550, loss is 4.257760310173035 and perplexity is 70.65156852106387
At time: 161.01620650291443 and batch: 600, loss is 4.256029772758484 and perplexity is 70.5294090695786
At time: 161.91320872306824 and batch: 650, loss is 4.315044651031494 and perplexity is 74.81696402397914
At time: 162.81207084655762 and batch: 700, loss is 4.33183226108551 and perplexity is 76.08356388737505
At time: 163.71573185920715 and batch: 750, loss is 4.298580827713013 and perplexity is 73.59527517725799
At time: 164.6194908618927 and batch: 800, loss is 4.277607436180115 and perplexity is 72.06780674463172
At time: 165.53087162971497 and batch: 850, loss is 4.279714155197143 and perplexity is 72.21979340399591
At time: 166.43896961212158 and batch: 900, loss is 4.255907616615295 and perplexity is 70.52079399518816
At time: 167.34686279296875 and batch: 950, loss is 4.351363496780396 and perplexity is 77.58417661376852
At time: 168.25365161895752 and batch: 1000, loss is 4.318400106430054 and perplexity is 75.0684306664285
At time: 169.16029834747314 and batch: 1050, loss is 4.264370040893555 and perplexity is 71.12010310187858
At time: 170.06571245193481 and batch: 1100, loss is 4.312471046447754 and perplexity is 74.62466230286252
At time: 170.97552919387817 and batch: 1150, loss is 4.265764007568359 and perplexity is 71.2193112858978
At time: 171.87847542762756 and batch: 1200, loss is 4.330936131477356 and perplexity is 76.01541369334565
At time: 172.7852337360382 and batch: 1250, loss is 4.3262135028839115 and perplexity is 75.65726748849971
At time: 173.68875694274902 and batch: 1300, loss is 4.320800876617431 and perplexity is 75.24886922587667
At time: 174.59255480766296 and batch: 1350, loss is 4.218132767677307 and perplexity is 67.90656849603981
At time: 175.49694991111755 and batch: 1400, loss is 4.23968936920166 and perplexity is 69.38629497061434
At time: 176.40244054794312 and batch: 1450, loss is 4.164745483398438 and perplexity is 64.37629552222161
At time: 177.31053948402405 and batch: 1500, loss is 4.180896129608154 and perplexity is 65.42445574424676
At time: 178.2354702949524 and batch: 1550, loss is 4.18557761669159 and perplexity is 65.73145754053057
At time: 179.14425587654114 and batch: 1600, loss is 4.2742718315124515 and perplexity is 71.8278175091882
At time: 180.05341577529907 and batch: 1650, loss is 4.2243045759201046 and perplexity is 68.32697080196347
At time: 180.9590528011322 and batch: 1700, loss is 4.263917441368103 and perplexity is 71.08792146021183
At time: 181.86516070365906 and batch: 1750, loss is 4.257822241783142 and perplexity is 70.65594422195466
At time: 182.7720124721527 and batch: 1800, loss is 4.217404551506043 and perplexity is 67.85713583574173
At time: 183.67476177215576 and batch: 1850, loss is 4.250714626312256 and perplexity is 70.15552942434067
At time: 184.58948397636414 and batch: 1900, loss is 4.329369115829468 and perplexity is 75.89638963124708
At time: 185.49771881103516 and batch: 1950, loss is 4.26399709701538 and perplexity is 71.09358424014255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496165004996366 and perplexity of 89.67257715573982
finished 5 epochs...
Completing Train Step...
At time: 188.4608600139618 and batch: 50, loss is 4.250070543289184 and perplexity is 70.11035798750325
At time: 189.3660318851471 and batch: 100, loss is 4.223616743087769 and perplexity is 68.27998942763003
At time: 190.24491477012634 and batch: 150, loss is 4.202643990516663 and perplexity is 66.86288236495037
At time: 191.12549996376038 and batch: 200, loss is 4.196763906478882 and perplexity is 66.47087664041652
At time: 192.0127558708191 and batch: 250, loss is 4.184297676086426 and perplexity is 65.64737899823645
At time: 192.8994436264038 and batch: 300, loss is 4.207351593971253 and perplexity is 67.17838835682969
At time: 193.79269313812256 and batch: 350, loss is 4.208627080917358 and perplexity is 67.26412818262956
At time: 194.68485975265503 and batch: 400, loss is 4.165743374824524 and perplexity is 64.44056813877947
At time: 195.57787132263184 and batch: 450, loss is 4.208450508117676 and perplexity is 67.2522522157154
At time: 196.47197794914246 and batch: 500, loss is 4.219871068000794 and perplexity is 68.02471316172894
At time: 197.372474193573 and batch: 550, loss is 4.178605117797852 and perplexity is 65.27473911022769
At time: 198.2743923664093 and batch: 600, loss is 4.179860925674438 and perplexity is 65.35676313417241
At time: 199.17907118797302 and batch: 650, loss is 4.235016365051269 and perplexity is 69.0628089406793
At time: 200.08884692192078 and batch: 700, loss is 4.256055364608764 and perplexity is 70.53121407075247
At time: 200.99333691596985 and batch: 750, loss is 4.221600198745728 and perplexity is 68.1424385366226
At time: 201.89424800872803 and batch: 800, loss is 4.201259932518005 and perplexity is 66.77040427008603
At time: 202.84196829795837 and batch: 850, loss is 4.20404598236084 and perplexity is 66.95668932363425
At time: 203.76204133033752 and batch: 900, loss is 4.183108196258545 and perplexity is 65.56933918775628
At time: 204.6744954586029 and batch: 950, loss is 4.274383525848389 and perplexity is 71.83584071763185
At time: 205.57926559448242 and batch: 1000, loss is 4.244384241104126 and perplexity is 69.71282063560497
At time: 206.47914147377014 and batch: 1050, loss is 4.192804565429688 and perplexity is 66.20821609442953
At time: 207.380047082901 and batch: 1100, loss is 4.2393459749221805 and perplexity is 69.3624722043821
At time: 208.2822070121765 and batch: 1150, loss is 4.1919088506698605 and perplexity is 66.14893896971289
At time: 209.1826364994049 and batch: 1200, loss is 4.258172917366028 and perplexity is 70.68072588128649
At time: 210.0834321975708 and batch: 1250, loss is 4.252285733222961 and perplexity is 70.2658378919511
At time: 210.98349833488464 and batch: 1300, loss is 4.247951693534851 and perplexity is 69.96196194268575
At time: 211.88460540771484 and batch: 1350, loss is 4.147986493110657 and perplexity is 63.30640400262298
At time: 212.78571939468384 and batch: 1400, loss is 4.174052772521972 and perplexity is 64.97826130668238
At time: 213.68794226646423 and batch: 1450, loss is 4.094295167922974 and perplexity is 59.9970364152451
At time: 214.59300470352173 and batch: 1500, loss is 4.111799840927124 and perplexity is 61.05651074176133
At time: 215.4997673034668 and batch: 1550, loss is 4.117387156486512 and perplexity is 61.398607545661235
At time: 216.40329360961914 and batch: 1600, loss is 4.204094710350037 and perplexity is 66.95995206796115
At time: 217.3131968975067 and batch: 1650, loss is 4.154629211425782 and perplexity is 63.72833042967588
At time: 218.2196867465973 and batch: 1700, loss is 4.1971176242828365 and perplexity is 66.49439273171359
At time: 219.12013864517212 and batch: 1750, loss is 4.191664643287659 and perplexity is 66.13278688280138
At time: 220.02014660835266 and batch: 1800, loss is 4.148948764801025 and perplexity is 63.36735128223168
At time: 220.92371249198914 and batch: 1850, loss is 4.180695128440857 and perplexity is 65.41130667380591
At time: 221.832097530365 and batch: 1900, loss is 4.260149898529053 and perplexity is 70.82059856221329
At time: 222.75021624565125 and batch: 1950, loss is 4.194346160888672 and perplexity is 66.31036109261171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495404194676599 and perplexity of 89.6043792797531
finished 6 epochs...
Completing Train Step...
At time: 225.7392122745514 and batch: 50, loss is 4.180195627212524 and perplexity is 65.3786418045258
At time: 226.61556339263916 and batch: 100, loss is 4.157675485610962 and perplexity is 63.92276039065826
At time: 227.49231386184692 and batch: 150, loss is 4.134301981925964 and perplexity is 62.44598742629552
At time: 228.36792063713074 and batch: 200, loss is 4.131125612258911 and perplexity is 62.247950571639294
At time: 229.25255680084229 and batch: 250, loss is 4.118930263519287 and perplexity is 61.49342530692984
At time: 230.15071630477905 and batch: 300, loss is 4.139025826454162 and perplexity is 62.741670392648786
At time: 231.0599648952484 and batch: 350, loss is 4.140241928100586 and perplexity is 62.81801705455419
At time: 231.95939421653748 and batch: 400, loss is 4.095846643447876 and perplexity is 60.090192594890205
At time: 232.85826206207275 and batch: 450, loss is 4.143993411064148 and perplexity is 63.054120367214246
At time: 233.77022290229797 and batch: 500, loss is 4.159715423583984 and perplexity is 64.05329194979603
At time: 234.68660593032837 and batch: 550, loss is 4.117616777420044 and perplexity is 61.412707570011875
At time: 235.60443782806396 and batch: 600, loss is 4.120238890647888 and perplexity is 61.57394994839071
At time: 236.52072525024414 and batch: 650, loss is 4.171806859970093 and perplexity is 64.83248957057452
At time: 237.42944431304932 and batch: 700, loss is 4.194182486534118 and perplexity is 66.29950867521512
At time: 238.34524011611938 and batch: 750, loss is 4.162374982833862 and perplexity is 64.22387220849221
At time: 239.24387907981873 and batch: 800, loss is 4.14038191318512 and perplexity is 62.82681125549594
At time: 240.14804220199585 and batch: 850, loss is 4.143467230796814 and perplexity is 63.0209512605329
At time: 241.0481915473938 and batch: 900, loss is 4.123307847976685 and perplexity is 61.76320803730337
At time: 241.94815802574158 and batch: 950, loss is 4.212072696685791 and perplexity is 67.4962942712186
At time: 242.84716081619263 and batch: 1000, loss is 4.184195456504821 and perplexity is 65.64066889357971
At time: 243.75501203536987 and batch: 1050, loss is 4.133220186233521 and perplexity is 62.3784701526198
At time: 244.67217016220093 and batch: 1100, loss is 4.179733185768128 and perplexity is 65.34841500057915
At time: 245.57879090309143 and batch: 1150, loss is 4.131992106437683 and perplexity is 62.30191143346022
At time: 246.48488092422485 and batch: 1200, loss is 4.199854168891907 and perplexity is 66.67660680843981
At time: 247.3897089958191 and batch: 1250, loss is 4.194211754798889 and perplexity is 66.3014491751866
At time: 248.29562497138977 and batch: 1300, loss is 4.1877545690536495 and perplexity is 65.87470766005478
At time: 249.20074248313904 and batch: 1350, loss is 4.091344857215882 and perplexity is 59.82028737681253
At time: 250.11366295814514 and batch: 1400, loss is 4.118367457389832 and perplexity is 61.45882616746307
At time: 251.02020716667175 and batch: 1450, loss is 4.034406986236572 and perplexity is 56.50939944852445
At time: 251.93149137496948 and batch: 1500, loss is 4.058466944694519 and perplexity is 57.88550134628784
At time: 252.83970260620117 and batch: 1550, loss is 4.062268686294556 and perplexity is 58.10598591190803
At time: 253.74700045585632 and batch: 1600, loss is 4.150241184234619 and perplexity is 63.449301424055044
At time: 254.6521270275116 and batch: 1650, loss is 4.097389039993286 and perplexity is 60.18294701402091
At time: 255.55636525154114 and batch: 1700, loss is 4.141856770515442 and perplexity is 62.91954020279201
At time: 256.4603979587555 and batch: 1750, loss is 4.136156296730041 and perplexity is 62.561889371371
At time: 257.36433267593384 and batch: 1800, loss is 4.092603902816773 and perplexity is 59.89565127981808
At time: 258.2804319858551 and batch: 1850, loss is 4.125742840766907 and perplexity is 61.913784255178044
At time: 259.1875739097595 and batch: 1900, loss is 4.203763842582703 and perplexity is 66.93780084288488
At time: 260.09589743614197 and batch: 1950, loss is 4.140403027534485 and perplexity is 62.82813781674296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496756904069767 and perplexity of 89.72566998231511
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 263.0818598270416 and batch: 50, loss is 4.1460082054138185 and perplexity is 63.18128951947911
At time: 264.0064241886139 and batch: 100, loss is 4.139018354415893 and perplexity is 62.74120158623802
At time: 264.89175510406494 and batch: 150, loss is 4.111803350448608 and perplexity is 61.05672502127353
At time: 265.7778387069702 and batch: 200, loss is 4.103579878807068 and perplexity is 60.556685622391385
At time: 266.67827105522156 and batch: 250, loss is 4.084461488723755 and perplexity is 59.40993621485043
At time: 267.5896637439728 and batch: 300, loss is 4.103619723320008 and perplexity is 60.55909852210534
At time: 268.5141749382019 and batch: 350, loss is 4.096731219291687 and perplexity is 60.143370444162514
At time: 269.43024015426636 and batch: 400, loss is 4.052732529640198 and perplexity is 57.554511778728184
At time: 270.3450949192047 and batch: 450, loss is 4.088542532920838 and perplexity is 59.65288619790571
At time: 271.2972538471222 and batch: 500, loss is 4.102713861465454 and perplexity is 60.50426518427219
At time: 272.2100327014923 and batch: 550, loss is 4.0602616119384765 and perplexity is 57.98947983493981
At time: 273.1268939971924 and batch: 600, loss is 4.052662706375122 and perplexity is 57.55049327509007
At time: 274.02682852745056 and batch: 650, loss is 4.089396195411682 and perplexity is 59.70383137122145
At time: 274.92657709121704 and batch: 700, loss is 4.1091743516922 and perplexity is 60.896417783219086
At time: 275.8375542163849 and batch: 750, loss is 4.069767880439758 and perplexity is 58.54337195287403
At time: 276.7490692138672 and batch: 800, loss is 4.042217903137207 and perplexity is 56.952517999910754
At time: 277.6529257297516 and batch: 850, loss is 4.049295554161072 and perplexity is 57.357037883892026
At time: 278.5515351295471 and batch: 900, loss is 4.017142477035523 and perplexity is 55.54216583324075
At time: 279.44997453689575 and batch: 950, loss is 4.104331259727478 and perplexity is 60.602203859197125
At time: 280.3493118286133 and batch: 1000, loss is 4.064057965278625 and perplexity is 58.21004680056665
At time: 281.24948358535767 and batch: 1050, loss is 4.009548163414001 and perplexity is 55.12195881818269
At time: 282.1523103713989 and batch: 1100, loss is 4.043126645088196 and perplexity is 57.00429666539121
At time: 283.0510468482971 and batch: 1150, loss is 3.9979038619995118 and perplexity is 54.48382463886528
At time: 283.9501328468323 and batch: 1200, loss is 4.0575664567947385 and perplexity is 57.83339961476285
At time: 284.85809421539307 and batch: 1250, loss is 4.048283376693726 and perplexity is 57.2990117538769
At time: 285.76821088790894 and batch: 1300, loss is 4.038287982940674 and perplexity is 56.72913836873613
At time: 286.6885974407196 and batch: 1350, loss is 3.9390706825256347 and perplexity is 51.37083929230274
At time: 287.5991532802582 and batch: 1400, loss is 3.95287380695343 and perplexity is 52.08483371978931
At time: 288.5041310787201 and batch: 1450, loss is 3.863498816490173 and perplexity is 47.631714790762246
At time: 289.4138197898865 and batch: 1500, loss is 3.889143915176392 and perplexity is 48.869032573891495
At time: 290.3238956928253 and batch: 1550, loss is 3.885431513786316 and perplexity is 48.6879474477446
At time: 291.24090242385864 and batch: 1600, loss is 3.9616682815551756 and perplexity is 52.54491257767825
At time: 292.1524884700775 and batch: 1650, loss is 3.904718446731567 and perplexity is 49.63610273765184
At time: 293.06873631477356 and batch: 1700, loss is 3.940673522949219 and perplexity is 51.45324457372972
At time: 293.976229429245 and batch: 1750, loss is 3.9211707973480223 and perplexity is 50.45948804225481
At time: 294.87522983551025 and batch: 1800, loss is 3.8842329597473144 and perplexity is 48.62962726860511
At time: 295.7893240451813 and batch: 1850, loss is 3.8984981632232665 and perplexity is 49.32831037667265
At time: 296.6951410770416 and batch: 1900, loss is 3.9728468799591066 and perplexity is 53.135586355104145
At time: 297.6095700263977 and batch: 1950, loss is 3.910717725753784 and perplexity is 49.93477859163135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385383641442587 and perplexity of 80.26901182612146
finished 8 epochs...
Completing Train Step...
At time: 300.6380395889282 and batch: 50, loss is 4.051575045585633 and perplexity is 57.48793188908979
At time: 301.5509042739868 and batch: 100, loss is 4.041514630317688 and perplexity is 56.91247892284583
At time: 302.44672989845276 and batch: 150, loss is 4.013242835998535 and perplexity is 55.32599309606121
At time: 303.35371136665344 and batch: 200, loss is 4.0068263244628906 and perplexity is 54.97212972144517
At time: 304.2542095184326 and batch: 250, loss is 3.99165566444397 and perplexity is 54.14446025087387
At time: 305.15648460388184 and batch: 300, loss is 4.012297844886779 and perplexity is 55.27373521983953
At time: 306.05473160743713 and batch: 350, loss is 4.011212606430053 and perplexity is 55.213782574074514
At time: 306.9644238948822 and batch: 400, loss is 3.9706486654281616 and perplexity is 53.018911222536595
At time: 307.8728311061859 and batch: 450, loss is 4.010561137199402 and perplexity is 55.17782420777602
At time: 308.7800726890564 and batch: 500, loss is 4.028848919868469 and perplexity is 56.19618768815733
At time: 309.680073261261 and batch: 550, loss is 3.9888536500930787 and perplexity is 53.992959049622954
At time: 310.57942175865173 and batch: 600, loss is 3.9843669891357423 and perplexity is 53.7512535789964
At time: 311.4779210090637 and batch: 650, loss is 4.022079768180848 and perplexity is 55.81707176366472
At time: 312.3773195743561 and batch: 700, loss is 4.044210405349731 and perplexity is 57.06610914575877
At time: 313.27713775634766 and batch: 750, loss is 4.009412851333618 and perplexity is 55.11450065586132
At time: 314.17721366882324 and batch: 800, loss is 3.98331955909729 and perplexity is 53.694982376611776
At time: 315.08133721351624 and batch: 850, loss is 3.9923235416412353 and perplexity is 54.180634179760155
At time: 315.99309730529785 and batch: 900, loss is 3.9592891550064087 and perplexity is 52.42005017179041
At time: 316.92825508117676 and batch: 950, loss is 4.051916499137878 and perplexity is 57.5075646993002
At time: 317.8310434818268 and batch: 1000, loss is 4.0150379991531375 and perplexity is 55.425401480797596
At time: 318.74333357810974 and batch: 1050, loss is 3.964934959411621 and perplexity is 52.716840543815
At time: 319.6477301120758 and batch: 1100, loss is 3.997472743988037 and perplexity is 54.46034074325836
At time: 320.54968786239624 and batch: 1150, loss is 3.9542203330993653 and perplexity is 52.155014549757006
At time: 321.4622447490692 and batch: 1200, loss is 4.016083216667175 and perplexity is 55.48336336726047
At time: 322.37238359451294 and batch: 1250, loss is 4.011661128997803 and perplexity is 55.23855275618739
At time: 323.2897222042084 and batch: 1300, loss is 4.005254168510437 and perplexity is 54.8857728614974
At time: 324.2134602069855 and batch: 1350, loss is 3.9066695404052734 and perplexity is 49.733041961692
At time: 325.12763929367065 and batch: 1400, loss is 3.9251083946228027 and perplexity is 50.65856887771086
At time: 326.049556016922 and batch: 1450, loss is 3.837499375343323 and perplexity is 46.40927703483912
At time: 326.9656686782837 and batch: 1500, loss is 3.864697518348694 and perplexity is 47.68884525015955
At time: 327.8795437812805 and batch: 1550, loss is 3.863667392730713 and perplexity is 47.63974504300798
At time: 328.78749322891235 and batch: 1600, loss is 3.944180655479431 and perplexity is 51.63401472871568
At time: 329.6982147693634 and batch: 1650, loss is 3.8894884395599365 and perplexity is 48.885872047851564
At time: 330.6226930618286 and batch: 1700, loss is 3.9301910257339476 and perplexity is 50.91670314085185
At time: 331.5519094467163 and batch: 1750, loss is 3.9134361267089846 and perplexity is 50.07070601035975
At time: 332.47046399116516 and batch: 1800, loss is 3.8800689125061036 and perplexity is 48.42755222034617
At time: 333.3784010410309 and batch: 1850, loss is 3.8973640823364257 and perplexity is 49.272399792249296
At time: 334.2884304523468 and batch: 1900, loss is 3.9742170333862306 and perplexity is 53.2084401598985
At time: 335.20823669433594 and batch: 1950, loss is 3.9142355585098265 and perplexity is 50.11075012917339
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3808860601380815 and perplexity of 79.9088060537687
finished 9 epochs...
Completing Train Step...
At time: 338.2282383441925 and batch: 50, loss is 4.014178037643433 and perplexity is 55.377758257469445
At time: 339.1111731529236 and batch: 100, loss is 4.00324287891388 and perplexity is 54.775492617472096
At time: 340.0278911590576 and batch: 150, loss is 3.973920211791992 and perplexity is 53.192649089544574
At time: 340.91677260398865 and batch: 200, loss is 3.967481598854065 and perplexity is 52.85126241860104
At time: 341.8152389526367 and batch: 250, loss is 3.954033446311951 and perplexity is 52.14526837738404
At time: 342.7101662158966 and batch: 300, loss is 3.974739122390747 and perplexity is 53.236226954412224
At time: 343.6033658981323 and batch: 350, loss is 3.973427166938782 and perplexity is 53.166429192006284
At time: 344.4955630302429 and batch: 400, loss is 3.9340902614593505 and perplexity is 51.115626942117615
At time: 345.3917717933655 and batch: 450, loss is 3.9750095129013063 and perplexity is 53.25062347125174
At time: 346.2924585342407 and batch: 500, loss is 3.995586609840393 and perplexity is 54.357718045400915
At time: 347.19512271881104 and batch: 550, loss is 3.9561928033828737 and perplexity is 52.25799029100033
At time: 348.1029317378998 and batch: 600, loss is 3.952958221435547 and perplexity is 52.0892306196323
At time: 349.01646542549133 and batch: 650, loss is 3.990354118347168 and perplexity is 54.07403458104064
At time: 349.9297845363617 and batch: 700, loss is 4.012813444137573 and perplexity is 55.302241664626735
At time: 350.85165143013 and batch: 750, loss is 3.980156798362732 and perplexity is 53.52542626874827
At time: 351.77258491516113 and batch: 800, loss is 3.953944916725159 and perplexity is 52.14065218265935
At time: 352.6939625740051 and batch: 850, loss is 3.963022508621216 and perplexity is 52.61611852410138
At time: 353.6052963733673 and batch: 900, loss is 3.931019997596741 and perplexity is 50.9589291547724
At time: 354.52677512168884 and batch: 950, loss is 4.026089758872986 and perplexity is 56.04134707232021
At time: 355.4493417739868 and batch: 1000, loss is 3.989933423995972 and perplexity is 54.05129072458742
At time: 356.3614718914032 and batch: 1050, loss is 3.9414140462875364 and perplexity is 51.49136101348349
At time: 357.2707796096802 and batch: 1100, loss is 3.973301286697388 and perplexity is 53.15973701028109
At time: 358.1934485435486 and batch: 1150, loss is 3.930243058204651 and perplexity is 50.91935253164291
At time: 359.1060371398926 and batch: 1200, loss is 3.9931877708435057 and perplexity is 54.2274789053901
At time: 360.0231649875641 and batch: 1250, loss is 3.990478639602661 and perplexity is 54.08076836695728
At time: 360.94300961494446 and batch: 1300, loss is 3.984950451850891 and perplexity is 53.78262458236768
At time: 361.8623559474945 and batch: 1350, loss is 3.8877863979339597 and perplexity is 48.80273702840559
At time: 362.76910853385925 and batch: 1400, loss is 3.908356671333313 and perplexity is 49.817018935086175
At time: 363.6768810749054 and batch: 1450, loss is 3.8206537055969236 and perplexity is 45.63402979324108
At time: 364.5954852104187 and batch: 1500, loss is 3.848124957084656 and perplexity is 46.905031778464476
At time: 365.5135455131531 and batch: 1550, loss is 3.848144698143005 and perplexity is 46.90595774257342
At time: 366.4203612804413 and batch: 1600, loss is 3.9304859018325806 and perplexity is 50.931719473499264
At time: 367.3274974822998 and batch: 1650, loss is 3.876760330200195 and perplexity is 48.2675904472189
At time: 368.23356795310974 and batch: 1700, loss is 3.9191385746002196 and perplexity is 50.35704724932381
At time: 369.139924287796 and batch: 1750, loss is 3.902959523200989 and perplexity is 49.548873365966855
At time: 370.0570216178894 and batch: 1800, loss is 3.871139826774597 and perplexity is 47.99706325144402
At time: 370.96469497680664 and batch: 1850, loss is 3.8897736406326295 and perplexity is 48.89981633936808
At time: 371.87631487846375 and batch: 1900, loss is 3.967406325340271 and perplexity is 52.84728426809692
At time: 372.7988193035126 and batch: 1950, loss is 3.9077823543548584 and perplexity is 49.78841638954572
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380182878361192 and perplexity of 79.85263538894719
finished 10 epochs...
Completing Train Step...
At time: 375.7950441837311 and batch: 50, loss is 3.9864997243881226 and perplexity is 53.86601310470777
At time: 376.7056574821472 and batch: 100, loss is 3.9757687616348267 and perplexity is 53.29106929195759
At time: 377.58693075180054 and batch: 150, loss is 3.9459129428863524 and perplexity is 51.723537199136366
At time: 378.4725935459137 and batch: 200, loss is 3.939542279243469 and perplexity is 51.39507132492981
At time: 379.3581585884094 and batch: 250, loss is 3.9269590520858766 and perplexity is 50.752407340916626
At time: 380.25733518600464 and batch: 300, loss is 3.9473516607284544 and perplexity is 51.79800633215121
At time: 381.1624984741211 and batch: 350, loss is 3.945857605934143 and perplexity is 51.72067505542216
At time: 382.0662372112274 and batch: 400, loss is 3.907443413734436 and perplexity is 49.77154393234687
At time: 382.96629333496094 and batch: 450, loss is 3.949160685539246 and perplexity is 51.891795018208114
At time: 383.86635994911194 and batch: 500, loss is 3.9713016986846923 and perplexity is 53.053545642273086
At time: 384.76616764068604 and batch: 550, loss is 3.9333486223220824 and perplexity is 51.0777316467054
At time: 385.69336128234863 and batch: 600, loss is 3.9302662324905397 and perplexity is 50.920532564948914
At time: 386.5986442565918 and batch: 650, loss is 3.9670299339294433 and perplexity is 52.82739674719364
At time: 387.4998691082001 and batch: 700, loss is 3.9893120241165163 and perplexity is 54.017713692509034
At time: 388.39687633514404 and batch: 750, loss is 3.9588908338546753 and perplexity is 52.399174314955744
At time: 389.2960526943207 and batch: 800, loss is 3.9319520950317384 and perplexity is 51.00644998550947
At time: 390.19594383239746 and batch: 850, loss is 3.9409762907028196 and perplexity is 51.46882531555885
At time: 391.1009678840637 and batch: 900, loss is 3.909707202911377 and perplexity is 49.88434384425792
At time: 392.01337933540344 and batch: 950, loss is 4.006640305519104 and perplexity is 54.96190481497934
At time: 392.91956210136414 and batch: 1000, loss is 3.9704095363616942 and perplexity is 53.00623437555254
At time: 393.82544112205505 and batch: 1050, loss is 3.9226509714126587 and perplexity is 50.534232171283925
At time: 394.7393898963928 and batch: 1100, loss is 3.9547429943084715 and perplexity is 52.18228107768005
At time: 395.6564223766327 and batch: 1150, loss is 3.9119393634796142 and perplexity is 49.99581807746792
At time: 396.57191157341003 and batch: 1200, loss is 3.974982957839966 and perplexity is 53.24920941645428
At time: 397.48696398735046 and batch: 1250, loss is 3.9732926654815675 and perplexity is 53.15927871069093
At time: 398.39849877357483 and batch: 1300, loss is 3.9684846782684327 and perplexity is 52.904303029481625
At time: 399.30698347091675 and batch: 1350, loss is 3.871945958137512 and perplexity is 48.03577078904268
At time: 400.2222604751587 and batch: 1400, loss is 3.8932770347595214 and perplexity is 49.071432112051546
At time: 401.12982177734375 and batch: 1450, loss is 3.805722222328186 and perplexity is 44.957707851185155
At time: 402.04045152664185 and batch: 1500, loss is 3.833566403388977 and perplexity is 46.22710911531733
At time: 402.9504873752594 and batch: 1550, loss is 3.8344054889678953 and perplexity is 46.265913893919375
At time: 403.86836338043213 and batch: 1600, loss is 3.918054838180542 and perplexity is 50.30250304434145
At time: 404.7811629772186 and batch: 1650, loss is 3.86438006401062 and perplexity is 47.67370862207841
At time: 405.68817162513733 and batch: 1700, loss is 3.9076411151885986 and perplexity is 49.78138481170425
At time: 406.5939257144928 and batch: 1750, loss is 3.891465258598328 and perplexity is 48.98260615183176
At time: 407.5056540966034 and batch: 1800, loss is 3.860761590003967 and perplexity is 47.50151427489678
At time: 408.4112718105316 and batch: 1850, loss is 3.880469517707825 and perplexity is 48.44695643612765
At time: 409.3203673362732 and batch: 1900, loss is 3.9581206703186034 and perplexity is 52.3588339179235
At time: 410.2329659461975 and batch: 1950, loss is 3.899080390930176 and perplexity is 49.35703904821169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3807018191315406 and perplexity of 79.89408493106875
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 413.21766448020935 and batch: 50, loss is 3.9842913722991944 and perplexity is 53.74718923290871
At time: 414.1319558620453 and batch: 100, loss is 3.994711799621582 and perplexity is 54.310186151907935
At time: 415.01168036460876 and batch: 150, loss is 3.970827007293701 and perplexity is 53.02836755727802
At time: 415.89998269081116 and batch: 200, loss is 3.9633721351623534 and perplexity is 52.634517731867305
At time: 416.7909574508667 and batch: 250, loss is 3.952465467453003 and perplexity is 52.06356976655983
At time: 417.6931457519531 and batch: 300, loss is 3.968251962661743 and perplexity is 52.891992804951876
At time: 418.5971579551697 and batch: 350, loss is 3.967500720024109 and perplexity is 52.85227300623857
At time: 419.5043697357178 and batch: 400, loss is 3.9285946464538575 and perplexity is 50.83548561518295
At time: 420.4033327102661 and batch: 450, loss is 3.965051155090332 and perplexity is 52.722966368771786
At time: 421.306369304657 and batch: 500, loss is 3.9811256456375124 and perplexity is 53.5773093614583
At time: 422.2221598625183 and batch: 550, loss is 3.9418121862411497 and perplexity is 51.511865863197976
At time: 423.13068675994873 and batch: 600, loss is 3.940952754020691 and perplexity is 51.46761392443399
At time: 424.0350980758667 and batch: 650, loss is 3.9668964290618898 and perplexity is 52.82034450335263
At time: 424.9395751953125 and batch: 700, loss is 3.990620150566101 and perplexity is 54.088421930111245
At time: 425.8504195213318 and batch: 750, loss is 3.9522997665405275 and perplexity is 52.054943500252605
At time: 426.76603078842163 and batch: 800, loss is 3.922627930641174 and perplexity is 50.53306783700195
At time: 427.676144361496 and batch: 850, loss is 3.9378923082351687 and perplexity is 51.3103408678955
At time: 428.58017468452454 and batch: 900, loss is 3.900244131088257 and perplexity is 49.41451125150537
At time: 429.4844026565552 and batch: 950, loss is 3.9949417114257812 and perplexity is 54.32267414030548
At time: 430.3891439437866 and batch: 1000, loss is 3.9561209630966188 and perplexity is 52.25423619686793
At time: 431.3199460506439 and batch: 1050, loss is 3.902341923713684 and perplexity is 49.51828145492618
At time: 432.2247145175934 and batch: 1100, loss is 3.9331978702545167 and perplexity is 51.07003215342494
At time: 433.12948751449585 and batch: 1150, loss is 3.8946795797348024 and perplexity is 49.140305290164875
At time: 434.03437304496765 and batch: 1200, loss is 3.9551227140426635 and perplexity is 52.20209948206189
At time: 434.9498131275177 and batch: 1250, loss is 3.943069486618042 and perplexity is 51.57667248371918
At time: 435.8587441444397 and batch: 1300, loss is 3.9380842304229735 and perplexity is 51.32018940581812
At time: 436.76341676712036 and batch: 1350, loss is 3.8418306589126585 and perplexity is 46.610724722524665
At time: 437.67554807662964 and batch: 1400, loss is 3.8583523559570314 and perplexity is 47.387209757880925
At time: 438.5894331932068 and batch: 1450, loss is 3.772244024276733 and perplexity is 43.47752005951761
At time: 439.4936909675598 and batch: 1500, loss is 3.797889442443848 and perplexity is 44.606939560261445
At time: 440.39891362190247 and batch: 1550, loss is 3.799049220085144 and perplexity is 44.658703703055544
At time: 441.30398893356323 and batch: 1600, loss is 3.874601335525513 and perplexity is 48.1634933894156
At time: 442.2108497619629 and batch: 1650, loss is 3.817392044067383 and perplexity is 45.48542950748375
At time: 443.12580585479736 and batch: 1700, loss is 3.8547199964523315 and perplexity is 47.215394612215604
At time: 444.0396430492401 and batch: 1750, loss is 3.8374569272994994 and perplexity is 46.407307093624105
At time: 444.95220279693604 and batch: 1800, loss is 3.804063415527344 and perplexity is 44.88319351917807
At time: 445.86968541145325 and batch: 1850, loss is 3.8194954347610475 and perplexity is 45.58120382670218
At time: 446.7863986492157 and batch: 1900, loss is 3.8945202684402465 and perplexity is 49.13247730807376
At time: 447.7025535106659 and batch: 1950, loss is 3.842193212509155 and perplexity is 46.62762667215431
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348714287336483 and perplexity of 77.37891189505174
finished 12 epochs...
Completing Train Step...
At time: 450.688738822937 and batch: 50, loss is 3.9667166757583616 and perplexity is 52.81085072522921
At time: 451.57620453834534 and batch: 100, loss is 3.966583924293518 and perplexity is 52.80384047275674
At time: 452.4623954296112 and batch: 150, loss is 3.9385446071624757 and perplexity is 51.34382146669557
At time: 453.34749817848206 and batch: 200, loss is 3.9316451740264893 and perplexity is 50.9907974367766
At time: 454.2609918117523 and batch: 250, loss is 3.9202438402175903 and perplexity is 50.41273593196474
At time: 455.1479456424713 and batch: 300, loss is 3.9352033233642576 and perplexity is 51.172553474712515
At time: 456.0469551086426 and batch: 350, loss is 3.937588024139404 and perplexity is 51.29473032236195
At time: 456.94646286964417 and batch: 400, loss is 3.899952130317688 and perplexity is 49.400084282588175
At time: 457.8464391231537 and batch: 450, loss is 3.938467164039612 and perplexity is 51.33984539478313
At time: 458.74634528160095 and batch: 500, loss is 3.955900568962097 and perplexity is 52.24272093870052
At time: 459.6461892127991 and batch: 550, loss is 3.9174262046813966 and perplexity is 50.27089114302802
At time: 460.5503087043762 and batch: 600, loss is 3.917696828842163 and perplexity is 50.28449750177625
At time: 461.45709681510925 and batch: 650, loss is 3.944859085083008 and perplexity is 51.669056658256295
At time: 462.3718910217285 and batch: 700, loss is 3.9705786371231078 and perplexity is 53.01519852804625
At time: 463.27997279167175 and batch: 750, loss is 3.9336939907073973 and perplexity is 51.095375327019084
At time: 464.18642830848694 and batch: 800, loss is 3.90431999206543 and perplexity is 49.61632894064961
At time: 465.0931968688965 and batch: 850, loss is 3.919097080230713 and perplexity is 50.354957758749336
At time: 466.005571603775 and batch: 900, loss is 3.8822462129592896 and perplexity is 48.533108423826754
At time: 466.91453289985657 and batch: 950, loss is 3.9791519689559935 and perplexity is 53.471669359210104
At time: 467.8204891681671 and batch: 1000, loss is 3.9410407638549803 and perplexity is 51.472143779939735
At time: 468.7260081768036 and batch: 1050, loss is 3.889232063293457 and perplexity is 48.87334047695966
At time: 469.63184118270874 and batch: 1100, loss is 3.9208202886581422 and perplexity is 50.44180465248104
At time: 470.53828525543213 and batch: 1150, loss is 3.882544574737549 and perplexity is 48.547591008778
At time: 471.44847798347473 and batch: 1200, loss is 3.9443434572219847 and perplexity is 51.64242152059017
At time: 472.35402727127075 and batch: 1250, loss is 3.9336995267868042 and perplexity is 51.09565819585721
At time: 473.2593755722046 and batch: 1300, loss is 3.9304755783081053 and perplexity is 50.93119368136073
At time: 474.17152881622314 and batch: 1350, loss is 3.8344118785858154 and perplexity is 46.266209516376335
At time: 475.08095932006836 and batch: 1400, loss is 3.8531746244430543 and perplexity is 47.14248561324797
At time: 475.99226093292236 and batch: 1450, loss is 3.7685891294479372 and perplexity is 43.3189043347484
At time: 476.8983402252197 and batch: 1500, loss is 3.795061550140381 and perplexity is 44.48097413147623
At time: 477.8038523197174 and batch: 1550, loss is 3.796812777519226 and perplexity is 44.55893867811218
At time: 478.7094249725342 and batch: 1600, loss is 3.8737836980819704 and perplexity is 48.12412920881562
At time: 479.6145386695862 and batch: 1650, loss is 3.8176926660537718 and perplexity is 45.49910548320054
At time: 480.53055119514465 and batch: 1700, loss is 3.8563323736190798 and perplexity is 47.29158504375702
At time: 481.4362189769745 and batch: 1750, loss is 3.8403364324569704 and perplexity is 46.54112975279675
At time: 482.3411674499512 and batch: 1800, loss is 3.808780016899109 and perplexity is 45.09538968027008
At time: 483.2474136352539 and batch: 1850, loss is 3.825570430755615 and perplexity is 45.85895226349248
At time: 484.1533546447754 and batch: 1900, loss is 3.9009436702728273 and perplexity is 49.44909073185279
At time: 485.0650284290314 and batch: 1950, loss is 3.8486289834976195 and perplexity is 46.92867911232153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346926099200582 and perplexity of 77.24066748317838
finished 13 epochs...
Completing Train Step...
At time: 488.006587266922 and batch: 50, loss is 3.956059288978577 and perplexity is 52.25101356231413
At time: 488.9085223674774 and batch: 100, loss is 3.9541954612731933 and perplexity is 52.15371737543274
At time: 489.7905225753784 and batch: 150, loss is 3.9253914308547975 and perplexity is 50.67290911747224
At time: 490.679758310318 and batch: 200, loss is 3.9185138034820555 and perplexity is 50.325595446718424
At time: 491.5681662559509 and batch: 250, loss is 3.9070287227630613 and perplexity is 49.75090840142666
At time: 492.45691752433777 and batch: 300, loss is 3.921601138114929 and perplexity is 50.48120749008337
At time: 493.35243582725525 and batch: 350, loss is 3.924915313720703 and perplexity is 50.64878861975377
At time: 494.2655577659607 and batch: 400, loss is 3.886797046661377 and perplexity is 48.75447785499473
At time: 495.17295479774475 and batch: 450, loss is 3.9260609483718873 and perplexity is 50.706846877462965
At time: 496.06961941719055 and batch: 500, loss is 3.9441053533554076 and perplexity is 51.63012672412409
At time: 496.96471786499023 and batch: 550, loss is 3.9060155296325685 and perplexity is 49.7005266503306
At time: 497.8627772331238 and batch: 600, loss is 3.9067625045776366 and perplexity is 49.7376655676886
At time: 498.7700572013855 and batch: 650, loss is 3.933990488052368 and perplexity is 51.11052721628029
At time: 499.6945638656616 and batch: 700, loss is 3.9603248548507692 and perplexity is 52.47436973412023
At time: 500.6007282733917 and batch: 750, loss is 3.9243475675582884 and perplexity is 50.62004112579584
At time: 501.4985761642456 and batch: 800, loss is 3.894758162498474 and perplexity is 49.14416702289308
At time: 502.39642119407654 and batch: 850, loss is 3.9094734048843383 and perplexity is 49.87268234635773
At time: 503.29516339302063 and batch: 900, loss is 3.8732631731033327 and perplexity is 48.09908591588245
At time: 504.1993761062622 and batch: 950, loss is 3.9708759641647338 and perplexity is 53.03096372377917
At time: 505.1021075248718 and batch: 1000, loss is 3.933109607696533 and perplexity is 51.065524780669826
At time: 505.99894070625305 and batch: 1050, loss is 3.8822935962677003 and perplexity is 48.535408137554924
At time: 506.8968813419342 and batch: 1100, loss is 3.913940706253052 and perplexity is 50.09597703945558
At time: 507.79862928390503 and batch: 1150, loss is 3.8759950542449952 and perplexity is 48.23066655112117
At time: 508.7000639438629 and batch: 1200, loss is 3.9381428813934325 and perplexity is 51.32319947300173
At time: 509.6060037612915 and batch: 1250, loss is 3.9281194162368775 and perplexity is 50.81133279585311
At time: 510.509192943573 and batch: 1300, loss is 3.925717287063599 and perplexity is 50.689423890100656
At time: 511.4200789928436 and batch: 1350, loss is 3.829732003211975 and perplexity is 46.05019527592989
At time: 512.334764957428 and batch: 1400, loss is 3.849329643249512 and perplexity is 46.96157167088533
At time: 513.2398369312286 and batch: 1450, loss is 3.765695962905884 and perplexity is 43.193756653924986
At time: 514.155042886734 and batch: 1500, loss is 3.7923436117172242 and perplexity is 44.36024172872579
At time: 515.0630133152008 and batch: 1550, loss is 3.794152455329895 and perplexity is 44.44055508388487
At time: 515.9666881561279 and batch: 1600, loss is 3.8720903396606445 and perplexity is 48.04270676749556
At time: 516.869975566864 and batch: 1650, loss is 3.81632333278656 and perplexity is 45.43684468205578
At time: 517.7725567817688 and batch: 1700, loss is 3.855511999130249 and perplexity is 47.25280414345639
At time: 518.6758816242218 and batch: 1750, loss is 3.840144462585449 and perplexity is 46.53219611561967
At time: 519.5793147087097 and batch: 1800, loss is 3.8091921472549437 and perplexity is 45.11397868954992
At time: 520.482342004776 and batch: 1850, loss is 3.8267013835906982 and perplexity is 45.91084591467355
At time: 521.3942012786865 and batch: 1900, loss is 3.902392530441284 and perplexity is 49.520787476517235
At time: 522.3129622936249 and batch: 1950, loss is 3.8498845005035403 and perplexity is 46.987635869873735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346333916242733 and perplexity of 77.19494041697291
finished 14 epochs...
Completing Train Step...
At time: 525.2776298522949 and batch: 50, loss is 3.947244362831116 and perplexity is 51.79244881314582
At time: 526.1829469203949 and batch: 100, loss is 3.944338278770447 and perplexity is 51.64215409350546
At time: 527.0619177818298 and batch: 150, loss is 3.9152746629714965 and perplexity is 50.16284749582569
At time: 527.9499206542969 and batch: 200, loss is 3.9085491609573366 and perplexity is 49.826609117306646
At time: 528.8419368267059 and batch: 250, loss is 3.897236428260803 and perplexity is 49.26611037104378
At time: 529.739180803299 and batch: 300, loss is 3.9116019678115843 and perplexity is 49.978952550366856
At time: 530.6289250850677 and batch: 350, loss is 3.9153425741195678 and perplexity is 50.16625422806589
At time: 531.5207364559174 and batch: 400, loss is 3.8771008443832398 and perplexity is 48.28402904497657
At time: 532.4187157154083 and batch: 450, loss is 3.916773586273193 and perplexity is 50.2380941372002
At time: 533.3279137611389 and batch: 500, loss is 3.9353265714645387 and perplexity is 51.17886078338872
At time: 534.2360882759094 and batch: 550, loss is 3.897701454162598 and perplexity is 49.28902571614855
At time: 535.145539522171 and batch: 600, loss is 3.8987443590164186 and perplexity is 49.340456294246245
At time: 536.0452716350555 and batch: 650, loss is 3.925983052253723 and perplexity is 50.702897164762504
At time: 536.9440653324127 and batch: 700, loss is 3.9526569700241088 and perplexity is 52.07354102876177
At time: 537.8530249595642 and batch: 750, loss is 3.9172737836837768 and perplexity is 50.263229387569794
At time: 538.7542929649353 and batch: 800, loss is 3.887365684509277 and perplexity is 48.78220938020785
At time: 539.6523268222809 and batch: 850, loss is 3.9021750354766844 and perplexity is 49.51001812578031
At time: 540.560873746872 and batch: 900, loss is 3.8663543033599854 and perplexity is 47.76792090176486
At time: 541.4582033157349 and batch: 950, loss is 3.9644904232025144 and perplexity is 52.69341120734361
At time: 542.3563508987427 and batch: 1000, loss is 3.9269046497344973 and perplexity is 50.749646365721574
At time: 543.2621626853943 and batch: 1050, loss is 3.876744227409363 and perplexity is 48.266813210563804
At time: 544.1657831668854 and batch: 1100, loss is 3.908389644622803 and perplexity is 49.818661593154815
At time: 545.0930275917053 and batch: 1150, loss is 3.8706553173065186 and perplexity is 47.97381385259048
At time: 545.9911971092224 and batch: 1200, loss is 3.933032751083374 and perplexity is 51.0616002082026
At time: 546.8947548866272 and batch: 1250, loss is 3.923417258262634 and perplexity is 50.57297072939862
At time: 547.7991971969604 and batch: 1300, loss is 3.9214651679992674 and perplexity is 50.47434402108611
At time: 548.7031562328339 and batch: 1350, loss is 3.8254116344451905 and perplexity is 45.85167060923832
At time: 549.6072235107422 and batch: 1400, loss is 3.845590343475342 and perplexity is 46.78629618456534
At time: 550.5117104053497 and batch: 1450, loss is 3.762603244781494 and perplexity is 43.0603768991671
At time: 551.4155683517456 and batch: 1500, loss is 3.789289565086365 and perplexity is 44.22497014992689
At time: 552.3204689025879 and batch: 1550, loss is 3.791120185852051 and perplexity is 44.30600344663331
At time: 553.2253847122192 and batch: 1600, loss is 3.869520139694214 and perplexity is 47.91938595164026
At time: 554.1288673877716 and batch: 1650, loss is 3.814109697341919 and perplexity is 45.33637531447802
At time: 555.0349500179291 and batch: 1700, loss is 3.8536554050445555 and perplexity is 47.165156255203115
At time: 555.9517028331757 and batch: 1750, loss is 3.838674740791321 and perplexity is 46.46385696493099
At time: 556.8613967895508 and batch: 1800, loss is 3.808126916885376 and perplexity is 45.065947496042604
At time: 557.7744846343994 and batch: 1850, loss is 3.826142358779907 and perplexity is 45.88518778515654
At time: 558.6797749996185 and batch: 1900, loss is 3.902135009765625 and perplexity is 49.50803649175869
At time: 559.5842006206512 and batch: 1950, loss is 3.8495228576660154 and perplexity is 46.970646200190515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345785451489825 and perplexity of 77.15261332157242
finished 15 epochs...
Completing Train Step...
At time: 562.5752274990082 and batch: 50, loss is 3.9398332691192626 and perplexity is 51.41002894650372
At time: 563.4434542655945 and batch: 100, loss is 3.9359827423095703 and perplexity is 51.212453879916666
At time: 564.3230452537537 and batch: 150, loss is 3.9067204332351686 and perplexity is 49.7355730813441
At time: 565.2176854610443 and batch: 200, loss is 3.900209755897522 and perplexity is 49.41281264745112
At time: 566.1212871074677 and batch: 250, loss is 3.8890980195999147 and perplexity is 48.86678975293781
At time: 567.0228838920593 and batch: 300, loss is 3.903216953277588 and perplexity is 49.561630378181725
At time: 567.9481680393219 and batch: 350, loss is 3.907328238487244 and perplexity is 49.76581181257683
At time: 568.8529353141785 and batch: 400, loss is 3.868972101211548 and perplexity is 47.89313147896083
At time: 569.7558262348175 and batch: 450, loss is 3.9088577795028687 and perplexity is 49.84198890606317
At time: 570.6553151607513 and batch: 500, loss is 3.9280121421813963 and perplexity is 50.80588235047061
At time: 571.5684854984283 and batch: 550, loss is 3.8907542419433594 and perplexity is 48.94779108156816
At time: 572.471031665802 and batch: 600, loss is 3.891984934806824 and perplexity is 49.00806786222853
At time: 573.3779420852661 and batch: 650, loss is 3.9191493129730226 and perplexity is 50.35758800497385
At time: 574.2780458927155 and batch: 700, loss is 3.946153268814087 and perplexity is 51.73596920000569
At time: 575.1784241199493 and batch: 750, loss is 3.9110974264144898 and perplexity is 49.95374246012364
At time: 576.0769805908203 and batch: 800, loss is 3.8810260248184205 and perplexity is 48.47392501527809
At time: 576.9871070384979 and batch: 850, loss is 3.895980062484741 and perplexity is 49.20425298194383
At time: 577.8870832920074 and batch: 900, loss is 3.86050491809845 and perplexity is 47.48932353529
At time: 578.7859327793121 and batch: 950, loss is 3.9590803241729735 and perplexity is 52.409104391972264
At time: 579.6849737167358 and batch: 1000, loss is 3.921427845954895 and perplexity is 50.472460250532194
At time: 580.5923557281494 and batch: 1050, loss is 3.8717950439453124 and perplexity is 48.028522056479424
At time: 581.4909746646881 and batch: 1100, loss is 3.903350133895874 and perplexity is 49.5682314663175
At time: 582.3904256820679 and batch: 1150, loss is 3.8657511615753175 and perplexity is 47.73911875946318
At time: 583.2899534702301 and batch: 1200, loss is 3.9283973932266236 and perplexity is 50.82545914049711
At time: 584.1885232925415 and batch: 1250, loss is 3.919112067222595 and perplexity is 50.355712433747634
At time: 585.0941700935364 and batch: 1300, loss is 3.9174007606506347 and perplexity is 50.26961206519986
At time: 585.9942879676819 and batch: 1350, loss is 3.8213749074935914 and perplexity is 45.66695301279772
At time: 586.8930594921112 and batch: 1400, loss is 3.841912693977356 and perplexity is 46.61454859318646
At time: 587.792671918869 and batch: 1450, loss is 3.7594624853134153 and perplexity is 42.92534677229563
At time: 588.6911470890045 and batch: 1500, loss is 3.7861197900772097 and perplexity is 44.08500888481329
At time: 589.5899348258972 and batch: 1550, loss is 3.7879270458221437 and perplexity is 44.164753808416435
At time: 590.5004847049713 and batch: 1600, loss is 3.866557264328003 and perplexity is 47.7776169091535
At time: 591.4022507667542 and batch: 1650, loss is 3.811553807258606 and perplexity is 45.220648477934844
At time: 592.3020520210266 and batch: 1700, loss is 3.8513399934768677 and perplexity is 47.05607583858011
At time: 593.2046580314636 and batch: 1750, loss is 3.8366448354721068 and perplexity is 46.36963539731077
At time: 594.1081295013428 and batch: 1800, loss is 3.8063976669311526 and perplexity is 44.988084550048754
At time: 595.0072824954987 and batch: 1850, loss is 3.8247805070877074 and perplexity is 45.82274149546835
At time: 595.9169430732727 and batch: 1900, loss is 3.9011189985275267 and perplexity is 49.45776131470415
At time: 596.82120013237 and batch: 1950, loss is 3.84871600151062 and perplexity is 46.932762930410924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346094601653343 and perplexity of 77.1764687518617
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 599.7722587585449 and batch: 50, loss is 3.941919345855713 and perplexity is 51.517386150659966
At time: 600.6702444553375 and batch: 100, loss is 3.951731562614441 and perplexity is 52.02537407850987
At time: 601.5607571601868 and batch: 150, loss is 3.9253398513793947 and perplexity is 50.67029550280784
At time: 602.4538979530334 and batch: 200, loss is 3.922167320251465 and perplexity is 50.50979714070601
At time: 603.3450303077698 and batch: 250, loss is 3.916927342414856 and perplexity is 50.24581914658783
At time: 604.2308371067047 and batch: 300, loss is 3.927031798362732 and perplexity is 50.756099523886775
At time: 605.1243085861206 and batch: 350, loss is 3.935504035949707 and perplexity is 51.187944019521225
At time: 606.0240404605865 and batch: 400, loss is 3.897521963119507 and perplexity is 49.28017957143545
At time: 606.9331519603729 and batch: 450, loss is 3.9362722730636595 and perplexity is 51.227283607034714
At time: 607.8341987133026 and batch: 500, loss is 3.9479823446273805 and perplexity is 51.830684804551375
At time: 608.7341265678406 and batch: 550, loss is 3.9078094244003294 and perplexity is 49.78976418248364
At time: 609.6343879699707 and batch: 600, loss is 3.9048328971862794 and perplexity is 49.64178393728204
At time: 610.5341465473175 and batch: 650, loss is 3.928123574256897 and perplexity is 50.81154407083134
At time: 611.4391052722931 and batch: 700, loss is 3.9535463285446166 and perplexity is 52.119873676282204
At time: 612.3450529575348 and batch: 750, loss is 3.9189025592803954 and perplexity is 50.34516361712665
At time: 613.2784631252289 and batch: 800, loss is 3.8876528120040894 and perplexity is 48.79621810482736
At time: 614.1948325634003 and batch: 850, loss is 3.9026807737350464 and perplexity is 49.535063568804254
At time: 615.101441860199 and batch: 900, loss is 3.862613568305969 and perplexity is 47.58956755986544
At time: 616.013747215271 and batch: 950, loss is 3.9658560705184938 and perplexity is 52.76542098171478
At time: 616.9247846603394 and batch: 1000, loss is 3.9261147451400755 and perplexity is 50.70957481532645
At time: 617.8406684398651 and batch: 1050, loss is 3.873354015350342 and perplexity is 48.103455543396514
At time: 618.7474136352539 and batch: 1100, loss is 3.9034630107879638 and perplexity is 49.57382689002288
At time: 619.662195444107 and batch: 1150, loss is 3.8712076807022093 and perplexity is 48.000320151194956
At time: 620.5754637718201 and batch: 1200, loss is 3.9323012447357177 and perplexity is 51.02426198176861
At time: 621.4961955547333 and batch: 1250, loss is 3.9176653957366945 and perplexity is 50.28291692870413
At time: 622.4147477149963 and batch: 1300, loss is 3.9137583589553833 and perplexity is 50.08684300622682
At time: 623.3260641098022 and batch: 1350, loss is 3.8143392038345336 and perplexity is 45.34678150106232
At time: 624.232622385025 and batch: 1400, loss is 3.8346461725234984 and perplexity is 46.27705067874531
At time: 625.1533606052399 and batch: 1450, loss is 3.75243661403656 and perplexity is 42.62481579359951
At time: 626.0673546791077 and batch: 1500, loss is 3.780800824165344 and perplexity is 43.8511447344144
At time: 626.9787132740021 and batch: 1550, loss is 3.783436393737793 and perplexity is 43.9668699110829
At time: 627.8847510814667 and batch: 1600, loss is 3.86213125705719 and perplexity is 47.566620110458125
At time: 628.7895436286926 and batch: 1650, loss is 3.8024556112289427 and perplexity is 44.81108810893914
At time: 629.6943471431732 and batch: 1700, loss is 3.836289005279541 and perplexity is 46.35313861621861
At time: 630.6113245487213 and batch: 1750, loss is 3.8259508085250853 and perplexity is 45.876399307488185
At time: 631.528048992157 and batch: 1800, loss is 3.794487113952637 and perplexity is 44.4554299877117
At time: 632.4424357414246 and batch: 1850, loss is 3.808446307182312 and perplexity is 45.080343421232094
At time: 633.3538048267365 and batch: 1900, loss is 3.8817913722991944 and perplexity is 48.5110386122591
At time: 634.2709360122681 and batch: 1950, loss is 3.8335354423522947 and perplexity is 46.225677898252385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336879996366279 and perplexity of 76.46858450064778
finished 17 epochs...
Completing Train Step...
At time: 637.2582845687866 and batch: 50, loss is 3.9429607820510864 and perplexity is 51.57106616859338
At time: 638.1640310287476 and batch: 100, loss is 3.9440450143814085 and perplexity is 51.627011509235494
At time: 639.0402457714081 and batch: 150, loss is 3.912756896018982 and perplexity is 50.0367079977213
At time: 639.9253704547882 and batch: 200, loss is 3.9087078380584717 and perplexity is 49.834516086511655
At time: 640.8062763214111 and batch: 250, loss is 3.901769742965698 and perplexity is 49.48995615197362
At time: 641.6883687973022 and batch: 300, loss is 3.9114562702178954 and perplexity is 49.97167126769074
At time: 642.5846846103668 and batch: 350, loss is 3.9204097843170165 and perplexity is 50.421102322185924
At time: 643.4812319278717 and batch: 400, loss is 3.884662556648254 and perplexity is 48.650522893800115
At time: 644.3803400993347 and batch: 450, loss is 3.924044122695923 and perplexity is 50.60468306466371
At time: 645.2871341705322 and batch: 500, loss is 3.9370398569107055 and perplexity is 51.266619937494085
At time: 646.1860501766205 and batch: 550, loss is 3.897944784164429 and perplexity is 49.3010206741737
At time: 647.090359210968 and batch: 600, loss is 3.896599626541138 and perplexity is 49.234747614226855
At time: 647.9952256679535 and batch: 650, loss is 3.9204382514953613 and perplexity is 50.4225376891284
At time: 648.9045596122742 and batch: 700, loss is 3.9474773025512695 and perplexity is 51.80451473694033
At time: 649.8040316104889 and batch: 750, loss is 3.912786602973938 and perplexity is 50.03819445803093
At time: 650.7110085487366 and batch: 800, loss is 3.881797261238098 and perplexity is 48.511324291642815
At time: 651.6174285411835 and batch: 850, loss is 3.8969918394088747 and perplexity is 49.25406190318967
At time: 652.5179426670074 and batch: 900, loss is 3.856857852935791 and perplexity is 47.316442323973334
At time: 653.4171600341797 and batch: 950, loss is 3.960921106338501 and perplexity is 52.50566698473089
At time: 654.3170337677002 and batch: 1000, loss is 3.921625757217407 and perplexity is 50.48245030740224
At time: 655.2171423435211 and batch: 1050, loss is 3.8695876741409303 and perplexity is 47.922622270137744
At time: 656.1161065101624 and batch: 1100, loss is 3.899913229942322 and perplexity is 49.39816263814304
At time: 657.0151054859161 and batch: 1150, loss is 3.867818570137024 and perplexity is 47.83791711540816
At time: 657.9129550457001 and batch: 1200, loss is 3.929174394607544 and perplexity is 50.864965938866014
At time: 658.8370666503906 and batch: 1250, loss is 3.9149740314483643 and perplexity is 50.14776922919307
At time: 659.7364773750305 and batch: 1300, loss is 3.911235899925232 and perplexity is 49.96066020916826
At time: 660.6348972320557 and batch: 1350, loss is 3.8125227308273315 and perplexity is 45.264485063759224
At time: 661.5341551303864 and batch: 1400, loss is 3.8338718032836914 and perplexity is 46.2412290255739
At time: 662.4340147972107 and batch: 1450, loss is 3.75240086555481 and perplexity is 42.62329204838595
At time: 663.3330664634705 and batch: 1500, loss is 3.781369285583496 and perplexity is 43.87607950489374
At time: 664.2321870326996 and batch: 1550, loss is 3.784359393119812 and perplexity is 44.00747003890422
At time: 665.1338164806366 and batch: 1600, loss is 3.863554525375366 and perplexity is 47.63436837440647
At time: 666.0405662059784 and batch: 1650, loss is 3.804318737983704 and perplexity is 44.894654669478925
At time: 666.9457762241364 and batch: 1700, loss is 3.838440170288086 and perplexity is 46.45295919281841
At time: 667.8472378253937 and batch: 1750, loss is 3.828468017578125 and perplexity is 45.99202526144111
At time: 668.7463252544403 and batch: 1800, loss is 3.7974153900146486 and perplexity is 44.58579854357483
At time: 669.6451699733734 and batch: 1850, loss is 3.8114333295822145 and perplexity is 45.21520072745405
At time: 670.5439460277557 and batch: 1900, loss is 3.8848748302459715 and perplexity is 48.6608512115014
At time: 671.4437348842621 and batch: 1950, loss is 3.8365280342102053 and perplexity is 46.36421968166982
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336162336482558 and perplexity of 76.41372575250267
finished 18 epochs...
Completing Train Step...
At time: 674.3813478946686 and batch: 50, loss is 3.9399913215637206 and perplexity is 51.41815506940825
At time: 675.2504403591156 and batch: 100, loss is 3.940255618095398 and perplexity is 51.43174650546394
At time: 676.1369323730469 and batch: 150, loss is 3.908334722518921 and perplexity is 49.81592552258361
At time: 677.0270538330078 and batch: 200, loss is 3.904215931892395 and perplexity is 49.61116612550107
At time: 677.9193315505981 and batch: 250, loss is 3.897109022140503 and perplexity is 49.25983396689377
At time: 678.826550245285 and batch: 300, loss is 3.906359429359436 and perplexity is 49.717621587174406
At time: 679.7323489189148 and batch: 350, loss is 3.915662617683411 and perplexity is 50.18231218433941
At time: 680.6349058151245 and batch: 400, loss is 3.879933280944824 and perplexity is 48.420984361244145
At time: 681.5612137317657 and batch: 450, loss is 3.919309906959534 and perplexity is 50.36567578018931
At time: 682.4652514457703 and batch: 500, loss is 3.932410717010498 and perplexity is 51.029848029549846
At time: 683.3741521835327 and batch: 550, loss is 3.893660297393799 and perplexity is 49.090242962908455
At time: 684.2736709117889 and batch: 600, loss is 3.892634472846985 and perplexity is 49.039910807062284
At time: 685.1717870235443 and batch: 650, loss is 3.91659930229187 and perplexity is 50.22933920508425
At time: 686.0840451717377 and batch: 700, loss is 3.944130711555481 and perplexity is 51.63143598780759
At time: 686.9866936206818 and batch: 750, loss is 3.9096413803100587 and perplexity is 49.88106043504348
At time: 687.8850467205048 and batch: 800, loss is 3.878735966682434 and perplexity is 48.363043919449886
At time: 688.7843778133392 and batch: 850, loss is 3.8938450145721437 and perplexity is 49.09931161161463
At time: 689.6918759346008 and batch: 900, loss is 3.853949909210205 and perplexity is 47.179048635775345
At time: 690.5999383926392 and batch: 950, loss is 3.958379921913147 and perplexity is 52.37240978881221
At time: 691.4979801177979 and batch: 1000, loss is 3.919117832183838 and perplexity is 50.35600273331494
At time: 692.3990209102631 and batch: 1050, loss is 3.8674759006500246 and perplexity is 47.82152732919129
At time: 693.3020133972168 and batch: 1100, loss is 3.8979173469543458 and perplexity is 49.2996680102689
At time: 694.2001264095306 and batch: 1150, loss is 3.866033878326416 and perplexity is 47.75261731606328
At time: 695.0983273983002 and batch: 1200, loss is 3.9275776815414427 and perplexity is 50.783813988575666
At time: 695.9955344200134 and batch: 1250, loss is 3.9135713148117066 and perplexity is 50.07747543166955
At time: 696.8929805755615 and batch: 1300, loss is 3.9099862003326415 and perplexity is 49.89826338922022
At time: 697.7920591831207 and batch: 1350, loss is 3.811558198928833 and perplexity is 45.2208470725465
At time: 698.6901092529297 and batch: 1400, loss is 3.8332660675048826 and perplexity is 46.21322754030395
At time: 699.5880076885223 and batch: 1450, loss is 3.7519364500045778 and perplexity is 42.60350172457936
At time: 700.4857976436615 and batch: 1500, loss is 3.7812196969985963 and perplexity is 43.869516635127084
At time: 701.3831257820129 and batch: 1550, loss is 3.7843335342407225 and perplexity is 44.006332069770814
At time: 702.290816783905 and batch: 1600, loss is 3.8638144874572755 and perplexity is 47.646753113691084
At time: 703.1878626346588 and batch: 1650, loss is 3.804809799194336 and perplexity is 44.916706106811475
At time: 704.0855481624603 and batch: 1700, loss is 3.8391641664505003 and perplexity is 46.48660313457956
At time: 704.9830102920532 and batch: 1750, loss is 3.8292744731903077 and perplexity is 46.029130748281865
At time: 705.8812234401703 and batch: 1800, loss is 3.798475155830383 and perplexity is 44.633074094820486
At time: 706.7799978256226 and batch: 1850, loss is 3.812514429092407 and perplexity is 45.26410929156252
At time: 707.6781649589539 and batch: 1900, loss is 3.8859569931030276 and perplexity is 48.71353868034437
At time: 708.5766217708588 and batch: 1950, loss is 3.8375498914718627 and perplexity is 46.411621511059685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335850063590116 and perplexity of 76.38986754266963
finished 19 epochs...
Completing Train Step...
At time: 711.5183248519897 and batch: 50, loss is 3.9372538137435913 and perplexity is 51.27758995464189
At time: 712.4299232959747 and batch: 100, loss is 3.937174367904663 and perplexity is 51.27351632530831
At time: 713.3147759437561 and batch: 150, loss is 3.90496844291687 and perplexity is 49.64851312519969
At time: 714.2000982761383 and batch: 200, loss is 3.900887818336487 and perplexity is 49.446328981510426
At time: 715.0866694450378 and batch: 250, loss is 3.8937175941467284 and perplexity is 49.093055755011896
At time: 715.9745943546295 and batch: 300, loss is 3.9027238035202028 and perplexity is 49.53719509780662
At time: 716.8645462989807 and batch: 350, loss is 3.912227840423584 and perplexity is 50.01024279877792
At time: 717.7630355358124 and batch: 400, loss is 3.8764754486083985 and perplexity is 48.25384185767313
At time: 718.6630940437317 and batch: 450, loss is 3.915910687446594 and perplexity is 50.19476244284146
At time: 719.5623285770416 and batch: 500, loss is 3.929086103439331 and perplexity is 50.86047520985093
At time: 720.4682943820953 and batch: 550, loss is 3.890567202568054 and perplexity is 48.93863677343642
At time: 721.3698999881744 and batch: 600, loss is 3.8897091817855833 and perplexity is 48.89666441517186
At time: 722.2688522338867 and batch: 650, loss is 3.913730583190918 and perplexity is 50.08545182519332
At time: 723.1681652069092 and batch: 700, loss is 3.9415514278411865 and perplexity is 51.49843546259736
At time: 724.0673770904541 and batch: 750, loss is 3.907248239517212 and perplexity is 49.76183075813127
At time: 724.9671895503998 and batch: 800, loss is 3.876387176513672 and perplexity is 48.24958257796428
At time: 725.8736302852631 and batch: 850, loss is 3.8914288234710694 and perplexity is 48.980821496855434
At time: 726.7986450195312 and batch: 900, loss is 3.85172420501709 and perplexity is 47.07415879957356
At time: 727.7011287212372 and batch: 950, loss is 3.9564096832275393 and perplexity is 52.2693252249321
At time: 728.6066617965698 and batch: 1000, loss is 3.917163257598877 and perplexity is 50.257674296608045
At time: 729.5121269226074 and batch: 1050, loss is 3.865803370475769 and perplexity is 47.74161123142618
At time: 730.4188904762268 and batch: 1100, loss is 3.896292796134949 and perplexity is 49.21964321398091
At time: 731.326910495758 and batch: 1150, loss is 3.8645681047439577 and perplexity is 47.68267406411636
At time: 732.2348532676697 and batch: 1200, loss is 3.926227331161499 and perplexity is 50.7152843260025
At time: 733.1426410675049 and batch: 1250, loss is 3.9123615646362304 and perplexity is 50.016930826286064
At time: 734.0509481430054 and batch: 1300, loss is 3.9088781213760377 and perplexity is 49.84300279579217
At time: 734.9576389789581 and batch: 1350, loss is 3.8106014204025267 and perplexity is 45.17760142867681
At time: 735.8647627830505 and batch: 1400, loss is 3.8325083541870115 and perplexity is 46.17822442517279
At time: 736.7697291374207 and batch: 1450, loss is 3.7512848949432374 and perplexity is 42.575752238540616
At time: 737.6753997802734 and batch: 1500, loss is 3.7807384061813356 and perplexity is 43.848407719783964
At time: 738.5803599357605 and batch: 1550, loss is 3.7838898944854735 and perplexity is 43.98681344132188
At time: 739.4852645397186 and batch: 1600, loss is 3.863607258796692 and perplexity is 47.63688036385587
At time: 740.3914761543274 and batch: 1650, loss is 3.80475359916687 and perplexity is 44.91418185762669
At time: 741.2974183559418 and batch: 1700, loss is 3.839308729171753 and perplexity is 46.493323850201264
At time: 742.2032382488251 and batch: 1750, loss is 3.829465765953064 and perplexity is 46.03793663009385
At time: 743.1088678836823 and batch: 1800, loss is 3.7988671970367434 and perplexity is 44.6505755294498
At time: 744.0158123970032 and batch: 1850, loss is 3.8129361295700073 and perplexity is 45.28320121332225
At time: 744.9226226806641 and batch: 1900, loss is 3.886405529975891 and perplexity is 48.73539339960748
At time: 745.8379621505737 and batch: 1950, loss is 3.8379378604888914 and perplexity is 46.42963127562547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335680300690407 and perplexity of 76.37690047794158
Finished Training.
Improved accuracyfrom -10000000 to -76.37690047794158
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
778.4823987483978


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.319066047668457 and batch: 50, loss is 8.178346204757691 and perplexity is 3562.9573837529233
At time: 2.1419830322265625 and batch: 100, loss is 7.306783828735352 and perplexity is 1490.376167871804
At time: 3.008223295211792 and batch: 150, loss is 7.06303708076477 and perplexity is 1167.987055567596
At time: 3.8439090251922607 and batch: 200, loss is 6.98328125 and perplexity is 1078.4512358306604
At time: 4.671638250350952 and batch: 250, loss is 6.922292127609253 and perplexity is 1014.6430224649454
At time: 5.497637033462524 and batch: 300, loss is 6.833883228302002 and perplexity is 928.7905243548719
At time: 6.32266092300415 and batch: 350, loss is 6.800862550735474 and perplexity is 898.6220645846204
At time: 7.162279367446899 and batch: 400, loss is 6.774612636566162 and perplexity is 875.3402225589897
At time: 7.9973344802856445 and batch: 450, loss is 6.697450141906739 and perplexity is 810.3369443963661
At time: 8.825179815292358 and batch: 500, loss is 6.687399787902832 and perplexity is 802.233560391538
At time: 9.660825967788696 and batch: 550, loss is 6.656942834854126 and perplexity is 778.1683079084639
At time: 10.496076822280884 and batch: 600, loss is 6.708785533905029 and perplexity is 819.5746891268503
At time: 11.322185754776001 and batch: 650, loss is 6.790957899093628 and perplexity is 889.7654592765838
At time: 12.153610467910767 and batch: 700, loss is 6.675232849121094 and perplexity is 792.5319727653942
At time: 12.991063594818115 and batch: 750, loss is 6.620281162261963 and perplexity is 750.1559830169244
At time: 13.816671371459961 and batch: 800, loss is 6.627173318862915 and perplexity is 755.3440334181225
At time: 14.642366170883179 and batch: 850, loss is 6.6804565334320065 and perplexity is 796.6827413112359
At time: 15.479111671447754 and batch: 900, loss is 6.657795104980469 and perplexity is 778.8318002077324
At time: 16.30417799949646 and batch: 950, loss is 6.676790885925293 and perplexity is 793.7677291744693
At time: 17.13659930229187 and batch: 1000, loss is 6.6728345489501955 and perplexity is 790.6335206386652
At time: 17.971261978149414 and batch: 1050, loss is 6.577418222427368 and perplexity is 718.6814563080338
At time: 18.81278419494629 and batch: 1100, loss is 6.651088466644287 and perplexity is 773.6259334446994
At time: 19.643142700195312 and batch: 1150, loss is 6.561712951660156 and perplexity is 707.4825406314359
At time: 20.472524642944336 and batch: 1200, loss is 6.65500506401062 and perplexity is 776.6618561006418
At time: 21.332611083984375 and batch: 1250, loss is 6.578396615982055 and perplexity is 719.3849537052998
At time: 22.21824073791504 and batch: 1300, loss is 6.595449619293213 and perplexity is 731.7578251723409
At time: 23.126731872558594 and batch: 1350, loss is 6.614121284484863 and perplexity is 745.5493166649298
At time: 24.05790114402771 and batch: 1400, loss is 6.639527387619019 and perplexity is 764.7334850870014
At time: 24.980182886123657 and batch: 1450, loss is 6.639823808670044 and perplexity is 764.9602017905464
At time: 25.90241003036499 and batch: 1500, loss is 6.622251834869385 and perplexity is 751.6357524556016
At time: 26.824190139770508 and batch: 1550, loss is 6.590119037628174 and perplexity is 727.867508363928
At time: 27.746641397476196 and batch: 1600, loss is 6.5760963344573975 and perplexity is 717.7320675677227
At time: 28.668549060821533 and batch: 1650, loss is 6.568950033187866 and perplexity is 712.621221555482
At time: 29.591049194335938 and batch: 1700, loss is 6.603107433319092 and perplexity is 737.3830012964779
At time: 30.511812686920166 and batch: 1750, loss is 6.617001037597657 and perplexity is 747.6994090120126
At time: 31.433977365493774 and batch: 1800, loss is 6.6278158473968505 and perplexity is 755.8295194651483
At time: 32.367300510406494 and batch: 1850, loss is 6.566462917327881 and perplexity is 710.8510522337714
At time: 33.29275417327881 and batch: 1900, loss is 6.513385028839111 and perplexity is 674.1044227709367
At time: 34.21487331390381 and batch: 1950, loss is 6.469638404846191 and perplexity is 645.250365371282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.987273460210756 and perplexity of 398.32707338030224
finished 1 epochs...
Completing Train Step...
At time: 37.261536836624146 and batch: 50, loss is 6.095334453582764 and perplexity is 443.7824449880124
At time: 38.182841300964355 and batch: 100, loss is 5.8445103931427 and perplexity is 345.33342277170203
At time: 39.106987953186035 and batch: 150, loss is 5.673622407913208 and perplexity is 291.08706297723177
At time: 40.02995181083679 and batch: 200, loss is 5.578315687179566 and perplexity is 264.62551806336256
At time: 40.94782614707947 and batch: 250, loss is 5.544928894042969 and perplexity is 255.93637899507388
At time: 41.87560319900513 and batch: 300, loss is 5.5096000289916995 and perplexity is 247.0522935487166
At time: 42.79988241195679 and batch: 350, loss is 5.460675525665283 and perplexity is 235.2562923629027
At time: 43.72298526763916 and batch: 400, loss is 5.402444820404053 and perplexity is 221.94837735700526
At time: 44.64539384841919 and batch: 450, loss is 5.330861339569092 and perplexity is 206.61586395277436
At time: 45.57235407829285 and batch: 500, loss is 5.3045987701416015 and perplexity is 201.26023459612148
At time: 46.494375705718994 and batch: 550, loss is 5.253120021820068 and perplexity is 191.16176787690355
At time: 47.42107939720154 and batch: 600, loss is 5.24209529876709 and perplexity is 189.06583708503413
At time: 48.33744406700134 and batch: 650, loss is 5.3138963413238525 and perplexity is 203.14019192930138
At time: 49.29895782470703 and batch: 700, loss is 5.280408973693848 and perplexity is 196.45020188968223
At time: 50.222965717315674 and batch: 750, loss is 5.203832197189331 and perplexity is 181.9682456109719
At time: 51.144461154937744 and batch: 800, loss is 5.1858617782592775 and perplexity is 178.72740683542796
At time: 52.06863713264465 and batch: 850, loss is 5.1851723003387455 and perplexity is 178.604220706559
At time: 52.99039268493652 and batch: 900, loss is 5.206227788925171 and perplexity is 182.4046897986631
At time: 53.91905426979065 and batch: 950, loss is 5.2364498805999755 and perplexity is 188.00148854665792
At time: 54.837305545806885 and batch: 1000, loss is 5.200315895080567 and perplexity is 181.3295139301068
At time: 55.75543165206909 and batch: 1050, loss is 5.0861138916015625 and perplexity is 161.76002205264544
At time: 56.67499876022339 and batch: 1100, loss is 5.178053712844848 and perplexity is 177.33732553664936
At time: 57.59448552131653 and batch: 1150, loss is 5.073076114654541 and perplexity is 159.6647196891113
At time: 58.52571773529053 and batch: 1200, loss is 5.152199916839599 and perplexity is 172.81124281488195
At time: 59.451446533203125 and batch: 1250, loss is 5.092107582092285 and perplexity is 162.73247293217767
At time: 60.37159013748169 and batch: 1300, loss is 5.1190463829040525 and perplexity is 167.17587181388166
At time: 61.289355754852295 and batch: 1350, loss is 5.0408628559112545 and perplexity is 154.6033579110428
At time: 62.20749020576477 and batch: 1400, loss is 5.045566263198853 and perplexity is 155.33223322638017
At time: 63.12544918060303 and batch: 1450, loss is 4.992022123336792 and perplexity is 147.23384767951484
At time: 64.04307794570923 and batch: 1500, loss is 4.973633890151977 and perplexity is 144.55121736036102
At time: 64.96163606643677 and batch: 1550, loss is 4.972541236877442 and perplexity is 144.39335925716622
At time: 65.88034152984619 and batch: 1600, loss is 5.017272176742554 and perplexity is 150.99884333350218
At time: 66.79852867126465 and batch: 1650, loss is 4.9975949478149415 and perplexity is 148.05664659742249
At time: 67.71675610542297 and batch: 1700, loss is 5.007220258712769 and perplexity is 149.48861838263332
At time: 68.64242005348206 and batch: 1750, loss is 5.014951448440552 and perplexity is 150.64882235310097
At time: 69.56344628334045 and batch: 1800, loss is 4.9664518260955814 and perplexity is 143.5167604722787
At time: 70.48190522193909 and batch: 1850, loss is 4.974060878753662 and perplexity is 144.6129522616452
At time: 71.40970540046692 and batch: 1900, loss is 5.036584310531616 and perplexity is 153.943293493084
At time: 72.33363366127014 and batch: 1950, loss is 4.957733936309815 and perplexity is 142.27103511002713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7457102221111915 and perplexity of 115.08951560226221
finished 2 epochs...
Completing Train Step...
At time: 75.34129881858826 and batch: 50, loss is 4.927529897689819 and perplexity is 138.0381225942276
At time: 76.28733897209167 and batch: 100, loss is 4.877628335952759 and perplexity is 131.318850077734
At time: 77.20542073249817 and batch: 150, loss is 4.822099475860596 and perplexity is 124.22562589336474
At time: 78.12383651733398 and batch: 200, loss is 4.795385007858276 and perplexity is 120.95093988218274
At time: 79.0423355102539 and batch: 250, loss is 4.802113704681396 and perplexity is 121.76752628736183
At time: 79.96583271026611 and batch: 300, loss is 4.830518093109131 and perplexity is 125.275848398163
At time: 80.89602470397949 and batch: 350, loss is 4.830763549804687 and perplexity is 125.30660196812428
At time: 81.83007335662842 and batch: 400, loss is 4.785651988983155 and perplexity is 119.77943250129265
At time: 82.7527437210083 and batch: 450, loss is 4.775634613037109 and perplexity is 118.58554668051161
At time: 83.67894673347473 and batch: 500, loss is 4.773975553512574 and perplexity is 118.38896931168667
At time: 84.6202540397644 and batch: 550, loss is 4.728771705627441 and perplexity is 113.15648747691753
At time: 85.55723595619202 and batch: 600, loss is 4.717233800888062 and perplexity is 111.85840169920688
At time: 86.49185609817505 and batch: 650, loss is 4.799920024871827 and perplexity is 121.50070009610066
At time: 87.42039608955383 and batch: 700, loss is 4.805104198455811 and perplexity is 122.13221634653901
At time: 88.34557461738586 and batch: 750, loss is 4.746478509902954 and perplexity is 115.17797144748128
At time: 89.27337551116943 and batch: 800, loss is 4.732330026626587 and perplexity is 113.55985180677422
At time: 90.19158959388733 and batch: 850, loss is 4.738333482742309 and perplexity is 114.2436539278478
At time: 91.11001086235046 and batch: 900, loss is 4.740569467544556 and perplexity is 114.49938680264691
At time: 92.03582191467285 and batch: 950, loss is 4.799333152770996 and perplexity is 121.42941564445675
At time: 92.96097922325134 and batch: 1000, loss is 4.770854396820068 and perplexity is 118.02003483845235
At time: 93.88340878486633 and batch: 1050, loss is 4.68659140586853 and perplexity is 108.48277513575685
At time: 94.80864810943604 and batch: 1100, loss is 4.759182796478272 and perplexity is 116.65055968930635
At time: 95.77714800834656 and batch: 1150, loss is 4.686143999099731 and perplexity is 108.43425006389532
At time: 96.70067071914673 and batch: 1200, loss is 4.773498678207398 and perplexity is 118.33252599509827
At time: 97.62396693229675 and batch: 1250, loss is 4.733201360702514 and perplexity is 113.65884349646385
At time: 98.54360723495483 and batch: 1300, loss is 4.756054887771606 and perplexity is 116.28625743713201
At time: 99.46274137496948 and batch: 1350, loss is 4.65665711402893 and perplexity is 105.28354235805203
At time: 100.39163875579834 and batch: 1400, loss is 4.664986839294434 and perplexity is 106.16418801716091
At time: 101.31283116340637 and batch: 1450, loss is 4.6074557209014895 and perplexity is 100.22881487392691
At time: 102.2311327457428 and batch: 1500, loss is 4.613415994644165 and perplexity is 100.82798989725904
At time: 103.15492343902588 and batch: 1550, loss is 4.618126707077026 and perplexity is 101.30408204905218
At time: 104.07506394386292 and batch: 1600, loss is 4.687498292922974 and perplexity is 108.58120138415701
At time: 104.9936420917511 and batch: 1650, loss is 4.653636503219604 and perplexity is 104.96600157695823
At time: 105.92524695396423 and batch: 1700, loss is 4.669224119186401 and perplexity is 106.61498980848113
At time: 106.84686231613159 and batch: 1750, loss is 4.665233068466186 and perplexity is 106.19033195581423
At time: 107.77971696853638 and batch: 1800, loss is 4.629039278030396 and perplexity is 102.4156238913213
At time: 108.70882248878479 and batch: 1850, loss is 4.662490568161011 and perplexity is 105.89950391829346
At time: 109.63155126571655 and batch: 1900, loss is 4.736778326034546 and perplexity is 114.06612522138151
At time: 110.55101156234741 and batch: 1950, loss is 4.6682832813262936 and perplexity is 106.5147295613282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.598211244095204 and perplexity of 99.30652154741941
finished 3 epochs...
Completing Train Step...
At time: 113.61256122589111 and batch: 50, loss is 4.642727460861206 and perplexity is 103.82714622451375
At time: 114.50229454040527 and batch: 100, loss is 4.599083642959595 and perplexity is 99.39319424512851
At time: 115.41076755523682 and batch: 150, loss is 4.565674962997437 and perplexity is 96.12745459971201
At time: 116.31781268119812 and batch: 200, loss is 4.5492432498931885 and perplexity is 94.560822319595
At time: 117.22855353355408 and batch: 250, loss is 4.548043174743652 and perplexity is 94.44741029169886
At time: 118.1450731754303 and batch: 300, loss is 4.5841765880584715 and perplexity is 97.92252336182557
At time: 119.07061839103699 and batch: 350, loss is 4.584138746261597 and perplexity is 97.91881786769878
At time: 120.0120964050293 and batch: 400, loss is 4.5399323844909665 and perplexity is 93.68446538249778
At time: 120.93107771873474 and batch: 450, loss is 4.548539695739746 and perplexity is 94.49431705806884
At time: 121.85317635536194 and batch: 500, loss is 4.555164709091186 and perplexity is 95.12242147294896
At time: 122.77760124206543 and batch: 550, loss is 4.5131032848358155 and perplexity is 91.20441307007273
At time: 123.69941544532776 and batch: 600, loss is 4.506802492141723 and perplexity is 90.6315595812589
At time: 124.62048435211182 and batch: 650, loss is 4.584285764694214 and perplexity is 97.9332147971065
At time: 125.54744815826416 and batch: 700, loss is 4.598745565414429 and perplexity is 99.35959731751531
At time: 126.47178244590759 and batch: 750, loss is 4.5435435009002685 and perplexity is 94.02338245895092
At time: 127.39775776863098 and batch: 800, loss is 4.528562803268432 and perplexity is 92.62534453342406
At time: 128.32534098625183 and batch: 850, loss is 4.532951049804687 and perplexity is 93.03270051628832
At time: 129.2517433166504 and batch: 900, loss is 4.53151351928711 and perplexity is 92.89905924987701
At time: 130.17113757133484 and batch: 950, loss is 4.595003309249878 and perplexity is 98.98846312468544
At time: 131.09107756614685 and batch: 1000, loss is 4.569018955230713 and perplexity is 96.44944212314054
At time: 132.01928901672363 and batch: 1050, loss is 4.4967640686035155 and perplexity is 89.72631282720864
At time: 132.94909119606018 and batch: 1100, loss is 4.563307485580444 and perplexity is 95.90014420408028
At time: 133.86914014816284 and batch: 1150, loss is 4.4968523502349855 and perplexity is 89.73423436214868
At time: 134.7930188179016 and batch: 1200, loss is 4.586242876052856 and perplexity is 98.12506868264565
At time: 135.71515655517578 and batch: 1250, loss is 4.554425373077392 and perplexity is 95.05212003243045
At time: 136.63669228553772 and batch: 1300, loss is 4.570119819641113 and perplexity is 96.55567834648656
At time: 137.5661153793335 and batch: 1350, loss is 4.469291305541992 and perplexity is 87.29483572015275
At time: 138.48780131340027 and batch: 1400, loss is 4.477709379196167 and perplexity is 88.03279180333568
At time: 139.41038584709167 and batch: 1450, loss is 4.41414737701416 and perplexity is 82.61137451294228
At time: 140.3328731060028 and batch: 1500, loss is 4.432572650909424 and perplexity is 84.1476211360651
At time: 141.2555603981018 and batch: 1550, loss is 4.4388182163238525 and perplexity is 84.6748152071766
At time: 142.17876887321472 and batch: 1600, loss is 4.51527156829834 and perplexity is 91.40238464232209
At time: 143.1106560230255 and batch: 1650, loss is 4.475193243026734 and perplexity is 87.81156774342553
At time: 144.0418825149536 and batch: 1700, loss is 4.49368574142456 and perplexity is 89.45053057155
At time: 144.97104406356812 and batch: 1750, loss is 4.488662624359131 and perplexity is 89.00233669247659
At time: 145.9019160270691 and batch: 1800, loss is 4.448752145767212 and perplexity is 85.52016069654312
At time: 146.83060717582703 and batch: 1850, loss is 4.49353256225586 and perplexity is 89.43682966301093
At time: 147.7528793811798 and batch: 1900, loss is 4.5698816680908205 and perplexity is 96.53268619991513
At time: 148.68546223640442 and batch: 1950, loss is 4.503997192382813 and perplexity is 90.37766717767008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5374142668968025 and perplexity of 93.44885365543543
finished 4 epochs...
Completing Train Step...
At time: 151.66413474082947 and batch: 50, loss is 4.481438751220703 and perplexity is 88.36171178559488
At time: 152.578861951828 and batch: 100, loss is 4.442578859329224 and perplexity is 84.99384646405909
At time: 153.45662426948547 and batch: 150, loss is 4.410921459197998 and perplexity is 82.34530639576056
At time: 154.3467960357666 and batch: 200, loss is 4.400240631103515 and perplexity is 81.4704706357046
At time: 155.2314841747284 and batch: 250, loss is 4.393278541564942 and perplexity is 80.90523581521272
At time: 156.12041878700256 and batch: 300, loss is 4.432133092880249 and perplexity is 84.11064150150182
At time: 157.009423494339 and batch: 350, loss is 4.433949003219604 and perplexity is 84.26351764773203
At time: 157.90389108657837 and batch: 400, loss is 4.390133838653565 and perplexity is 80.65121250785573
At time: 158.80874228477478 and batch: 450, loss is 4.405124158859253 and perplexity is 81.86930701193516
At time: 159.71297335624695 and batch: 500, loss is 4.417432804107666 and perplexity is 82.88323450455114
At time: 160.6156165599823 and batch: 550, loss is 4.376165609359742 and perplexity is 79.53248935903095
At time: 161.5270917415619 and batch: 600, loss is 4.373904342651367 and perplexity is 79.35284837324646
At time: 162.43434476852417 and batch: 650, loss is 4.448206415176392 and perplexity is 85.47350246129025
At time: 163.34791588783264 and batch: 700, loss is 4.463665943145752 and perplexity is 86.80514925714535
At time: 164.25186681747437 and batch: 750, loss is 4.412589340209961 and perplexity is 82.48276316762714
At time: 165.1559808254242 and batch: 800, loss is 4.39806116104126 and perplexity is 81.29310153952366
At time: 166.08532094955444 and batch: 850, loss is 4.403292541503906 and perplexity is 81.7194910130176
At time: 166.9898533821106 and batch: 900, loss is 4.399491128921508 and perplexity is 81.40943121763993
At time: 167.89086842536926 and batch: 950, loss is 4.466013746261597 and perplexity is 87.00919008716505
At time: 168.7946240901947 and batch: 1000, loss is 4.440813817977905 and perplexity is 84.84396112626435
At time: 169.6991469860077 and batch: 1050, loss is 4.375712871551514 and perplexity is 79.49649014383341
At time: 170.60873460769653 and batch: 1100, loss is 4.432070789337158 and perplexity is 84.10540127376869
At time: 171.51569986343384 and batch: 1150, loss is 4.374146347045898 and perplexity is 79.3720544351533
At time: 172.42075085639954 and batch: 1200, loss is 4.463545198440552 and perplexity is 86.79466862774139
At time: 173.33748984336853 and batch: 1250, loss is 4.436401720046997 and perplexity is 84.47044585981898
At time: 174.24523830413818 and batch: 1300, loss is 4.443974723815918 and perplexity is 85.11256919707222
At time: 175.14910554885864 and batch: 1350, loss is 4.343738679885864 and perplexity is 76.99486103997194
At time: 176.06499862670898 and batch: 1400, loss is 4.353045063018799 and perplexity is 77.71474929833758
At time: 176.97375440597534 and batch: 1450, loss is 4.288917398452758 and perplexity is 72.88751763181521
At time: 177.88663148880005 and batch: 1500, loss is 4.314285674095154 and perplexity is 74.7602012173933
At time: 178.80145525932312 and batch: 1550, loss is 4.319445667266845 and perplexity is 75.14696032422604
At time: 179.71855401992798 and batch: 1600, loss is 4.400751714706421 and perplexity is 81.51211949948659
At time: 180.63089609146118 and batch: 1650, loss is 4.354782247543335 and perplexity is 77.84987149025615
At time: 181.5363531112671 and batch: 1700, loss is 4.379671802520752 and perplexity is 79.81183506312291
At time: 182.44040966033936 and batch: 1750, loss is 4.370242433547974 and perplexity is 79.06279685068603
At time: 183.3461673259735 and batch: 1800, loss is 4.329608821868897 and perplexity is 75.91458463485156
At time: 184.25006461143494 and batch: 1850, loss is 4.375855798721314 and perplexity is 79.50785316420153
At time: 185.15418195724487 and batch: 1900, loss is 4.455716648101807 and perplexity is 86.11784492612291
At time: 186.05670285224915 and batch: 1950, loss is 4.390316896438598 and perplexity is 80.66597769157737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.510612452307413 and perplexity of 90.97752084384064
finished 5 epochs...
Completing Train Step...
At time: 189.04568457603455 and batch: 50, loss is 4.37102294921875 and perplexity is 79.12453069158445
At time: 189.93129420280457 and batch: 100, loss is 4.332157917022705 and perplexity is 76.10834498651498
At time: 190.81599283218384 and batch: 150, loss is 4.303850317001343 and perplexity is 73.98410826763488
At time: 191.70647978782654 and batch: 200, loss is 4.293971719741822 and perplexity is 73.25684713262231
At time: 192.60777616500854 and batch: 250, loss is 4.2853605175018314 and perplexity is 72.6287259272721
At time: 193.50746202468872 and batch: 300, loss is 4.3274760055542 and perplexity is 75.7528453116639
At time: 194.41090488433838 and batch: 350, loss is 4.327260370254517 and perplexity is 75.73651208523667
At time: 195.3160207271576 and batch: 400, loss is 4.280695610046386 and perplexity is 72.29070866481445
At time: 196.21981835365295 and batch: 450, loss is 4.302396659851074 and perplexity is 73.87663887039886
At time: 197.12429189682007 and batch: 500, loss is 4.320829372406006 and perplexity is 75.25101353229635
At time: 198.0368573665619 and batch: 550, loss is 4.276562557220459 and perplexity is 71.9925439368054
At time: 198.9517514705658 and batch: 600, loss is 4.278609819412232 and perplexity is 72.14008252365075
At time: 199.86670327186584 and batch: 650, loss is 4.351423978805542 and perplexity is 77.58886920379668
At time: 200.78156161308289 and batch: 700, loss is 4.364341468811035 and perplexity is 78.59762390885923
At time: 201.6965777873993 and batch: 750, loss is 4.31699234008789 and perplexity is 74.96282620701967
At time: 202.61284923553467 and batch: 800, loss is 4.3046331882476805 and perplexity is 74.04205097656454
At time: 203.52464985847473 and batch: 850, loss is 4.309758853912354 and perplexity is 74.42254007191168
At time: 204.43703150749207 and batch: 900, loss is 4.302069292068482 and perplexity is 73.85245799718186
At time: 205.34965872764587 and batch: 950, loss is 4.37200626373291 and perplexity is 79.2023732566294
At time: 206.2640345096588 and batch: 1000, loss is 4.346201028823852 and perplexity is 77.18468286215537
At time: 207.17962646484375 and batch: 1050, loss is 4.285092678070068 and perplexity is 72.60927569547584
At time: 208.10482621192932 and batch: 1100, loss is 4.339460592269898 and perplexity is 76.66617385605282
At time: 209.02044129371643 and batch: 1150, loss is 4.282590446472168 and perplexity is 72.42781759130914
At time: 209.94660210609436 and batch: 1200, loss is 4.372960643768311 and perplexity is 79.27799850229397
At time: 210.8745403289795 and batch: 1250, loss is 4.349047174453736 and perplexity is 77.4046746257713
At time: 211.78897380828857 and batch: 1300, loss is 4.3511660861968995 and perplexity is 77.56886218785775
At time: 212.7042498588562 and batch: 1350, loss is 4.252707133293152 and perplexity is 70.29545416068136
At time: 213.62472009658813 and batch: 1400, loss is 4.263235816955566 and perplexity is 71.03948270790151
At time: 214.54279947280884 and batch: 1450, loss is 4.196850695610046 and perplexity is 66.47664584039617
At time: 215.46745800971985 and batch: 1500, loss is 4.225699610710144 and perplexity is 68.4223558205707
At time: 216.38699793815613 and batch: 1550, loss is 4.230480489730835 and perplexity is 68.7502580318948
At time: 217.30909156799316 and batch: 1600, loss is 4.313230247497558 and perplexity is 74.68133893658178
At time: 218.22572588920593 and batch: 1650, loss is 4.267743544578552 and perplexity is 71.36043217936184
At time: 219.1510889530182 and batch: 1700, loss is 4.291712307929993 and perplexity is 73.09151659213512
At time: 220.07100772857666 and batch: 1750, loss is 4.281939921379089 and perplexity is 72.38071680031331
At time: 220.98817467689514 and batch: 1800, loss is 4.24097843170166 and perplexity is 69.47579591523716
At time: 221.9052894115448 and batch: 1850, loss is 4.288718004226684 and perplexity is 72.8729857304833
At time: 222.82358026504517 and batch: 1900, loss is 4.367330951690674 and perplexity is 78.83294172395175
At time: 223.73689937591553 and batch: 1950, loss is 4.301364479064941 and perplexity is 73.80042416365728
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495531091024709 and perplexity of 89.61575046972438
finished 6 epochs...
Completing Train Step...
At time: 226.74555921554565 and batch: 50, loss is 4.286056118011475 and perplexity is 72.67926408118687
At time: 227.65970277786255 and batch: 100, loss is 4.247960948944092 and perplexity is 69.9626094722714
At time: 228.54666471481323 and batch: 150, loss is 4.220980758666992 and perplexity is 68.10024144976292
At time: 229.43399667739868 and batch: 200, loss is 4.21096697807312 and perplexity is 67.42170360809853
At time: 230.32049536705017 and batch: 250, loss is 4.203340172767639 and perplexity is 66.90944732387021
At time: 231.20810866355896 and batch: 300, loss is 4.2462592124938965 and perplexity is 69.84365279474598
At time: 232.10176467895508 and batch: 350, loss is 4.24454083442688 and perplexity is 69.72373805260185
At time: 233.00962448120117 and batch: 400, loss is 4.193356471061707 and perplexity is 66.24476686713885
At time: 233.90980124473572 and batch: 450, loss is 4.224231071472168 and perplexity is 68.32194865027301
At time: 234.8098108768463 and batch: 500, loss is 4.244215726852417 and perplexity is 69.70107402156476
At time: 235.74508953094482 and batch: 550, loss is 4.198986883163452 and perplexity is 66.61880420824137
At time: 236.65052723884583 and batch: 600, loss is 4.2076725578308105 and perplexity is 67.19995365229067
At time: 237.56126713752747 and batch: 650, loss is 4.272616415023804 and perplexity is 71.70901092006471
At time: 238.48010635375977 and batch: 700, loss is 4.286907153129578 and perplexity is 72.74114301411564
At time: 239.38859701156616 and batch: 750, loss is 4.244017124176025 and perplexity is 69.68723257623624
At time: 240.28875303268433 and batch: 800, loss is 4.229942479133606 and perplexity is 68.71327961279408
At time: 241.18860006332397 and batch: 850, loss is 4.237049131393433 and perplexity is 69.20334027948573
At time: 242.0887734889984 and batch: 900, loss is 4.225258135795594 and perplexity is 68.39215573366235
At time: 242.98963618278503 and batch: 950, loss is 4.299252223968506 and perplexity is 73.64470336052582
At time: 243.90338492393494 and batch: 1000, loss is 4.27199354171753 and perplexity is 71.66435919896948
At time: 244.80938267707825 and batch: 1050, loss is 4.214791994094849 and perplexity is 67.68008654902826
At time: 245.7181625366211 and batch: 1100, loss is 4.266353583335876 and perplexity is 71.26131284634569
At time: 246.6249520778656 and batch: 1150, loss is 4.211715207099915 and perplexity is 67.47216936139036
At time: 247.5434329509735 and batch: 1200, loss is 4.300340104103088 and perplexity is 73.72486356477013
At time: 248.46011447906494 and batch: 1250, loss is 4.280141353607178 and perplexity is 72.25065217585093
At time: 249.3754858970642 and batch: 1300, loss is 4.276759366989136 and perplexity is 72.0067141670982
At time: 250.2977056503296 and batch: 1350, loss is 4.181336574554443 and perplexity is 65.45327796197715
At time: 251.21390771865845 and batch: 1400, loss is 4.190455541610718 and perplexity is 66.05287394045249
At time: 252.13033723831177 and batch: 1450, loss is 4.1241340065002445 and perplexity is 61.81425532173687
At time: 253.04831290245056 and batch: 1500, loss is 4.154677262306214 and perplexity is 63.73139270563342
At time: 253.96239161491394 and batch: 1550, loss is 4.159068880081176 and perplexity is 64.0118920948982
At time: 254.8809072971344 and batch: 1600, loss is 4.243846206665039 and perplexity is 69.67532282571825
At time: 255.79562401771545 and batch: 1650, loss is 4.199217534065246 and perplexity is 66.63417166769949
At time: 256.7099995613098 and batch: 1700, loss is 4.222098202705383 and perplexity is 68.17638219217032
At time: 257.6239628791809 and batch: 1750, loss is 4.211832280158997 and perplexity is 67.48006899706861
At time: 258.5482568740845 and batch: 1800, loss is 4.172186489105225 and perplexity is 64.85710654488335
At time: 259.46955943107605 and batch: 1850, loss is 4.219654231071472 and perplexity is 68.00996449089502
At time: 260.3838543891907 and batch: 1900, loss is 4.296748647689819 and perplexity is 73.46055883425856
At time: 261.29819560050964 and batch: 1950, loss is 4.229527416229248 and perplexity is 68.68476519743746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493650356558867 and perplexity of 89.44736543253885
finished 7 epochs...
Completing Train Step...
At time: 264.29685139656067 and batch: 50, loss is 4.216601929664612 and perplexity is 67.80269406742181
At time: 265.18411207199097 and batch: 100, loss is 4.180216498374939 and perplexity is 65.38000634701713
At time: 266.07636976242065 and batch: 150, loss is 4.153988342285157 and perplexity is 63.68750199355973
At time: 266.96796560287476 and batch: 200, loss is 4.147040166854858 and perplexity is 63.246523827914615
At time: 267.85998344421387 and batch: 250, loss is 4.137702383995056 and perplexity is 62.658690323880684
At time: 268.7523901462555 and batch: 300, loss is 4.179391708374023 and perplexity is 65.32610380371739
At time: 269.65145325660706 and batch: 350, loss is 4.177136316299438 and perplexity is 65.17893385229125
At time: 270.55160427093506 and batch: 400, loss is 4.12378532409668 and perplexity is 61.79270553585064
At time: 271.45105743408203 and batch: 450, loss is 4.158111057281494 and perplexity is 63.950609398865836
At time: 272.3576557636261 and batch: 500, loss is 4.1802295255661015 and perplexity is 65.38085807040578
At time: 273.2585687637329 and batch: 550, loss is 4.136903219223022 and perplexity is 62.608635709518296
At time: 274.17100501060486 and batch: 600, loss is 4.148542532920837 and perplexity is 63.34161467184752
At time: 275.0770516395569 and batch: 650, loss is 4.210947580337525 and perplexity is 67.4203957924029
At time: 275.9830746650696 and batch: 700, loss is 4.224484457969665 and perplexity is 68.33926270302463
At time: 276.89022040367126 and batch: 750, loss is 4.185297508239746 and perplexity is 65.71304818215025
At time: 277.79654002189636 and batch: 800, loss is 4.169639649391175 and perplexity is 64.69213605606468
At time: 278.7026877403259 and batch: 850, loss is 4.175815091133118 and perplexity is 65.09287466887015
At time: 279.6090624332428 and batch: 900, loss is 4.162814774513245 and perplexity is 64.25212354500324
At time: 280.51960158348083 and batch: 950, loss is 4.240200042724609 and perplexity is 69.42173776338909
At time: 281.4688904285431 and batch: 1000, loss is 4.21205159664154 and perplexity is 67.49487011144771
At time: 282.37275886535645 and batch: 1050, loss is 4.155731530189514 and perplexity is 63.79861809667969
At time: 283.27601146698 and batch: 1100, loss is 4.20505286693573 and perplexity is 67.02414093359411
At time: 284.18046855926514 and batch: 1150, loss is 4.152213087081909 and perplexity is 63.5745407214736
At time: 285.0850019454956 and batch: 1200, loss is 4.238099246025086 and perplexity is 69.27604988970359
At time: 285.9886565208435 and batch: 1250, loss is 4.2232640266418455 and perplexity is 68.25591019925099
At time: 286.8926794528961 and batch: 1300, loss is 4.214988369941711 and perplexity is 67.69337858841504
At time: 287.7961733341217 and batch: 1350, loss is 4.12401243686676 and perplexity is 61.80674104213666
At time: 288.6996681690216 and batch: 1400, loss is 4.131341452598572 and perplexity is 62.26138764051245
At time: 289.6036229133606 and batch: 1450, loss is 4.065392689704895 and perplexity is 58.2877930452496
At time: 290.5112566947937 and batch: 1500, loss is 4.097160172462464 and perplexity is 60.16917466762178
At time: 291.41990518569946 and batch: 1550, loss is 4.098284029960633 and perplexity is 60.23683425847841
At time: 292.3221433162689 and batch: 1600, loss is 4.18687970161438 and perplexity is 65.81710122592267
At time: 293.2288694381714 and batch: 1650, loss is 4.14145628452301 and perplexity is 62.894346853419016
At time: 294.1383879184723 and batch: 1700, loss is 4.163827257156372 and perplexity is 64.31721064909806
At time: 295.0474910736084 and batch: 1750, loss is 4.152307872772217 and perplexity is 63.58056696379811
At time: 295.9572036266327 and batch: 1800, loss is 4.114296207427978 and perplexity is 61.20912057562119
At time: 296.86648869514465 and batch: 1850, loss is 4.161733446121215 and perplexity is 64.18268345010513
At time: 297.77681064605713 and batch: 1900, loss is 4.237246189117432 and perplexity is 69.21697867594587
At time: 298.6871066093445 and batch: 1950, loss is 4.168063635826111 and perplexity is 64.59026067166792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493468386627907 and perplexity of 89.43109018247452
finished 8 epochs...
Completing Train Step...
At time: 301.63848209381104 and batch: 50, loss is 4.162198524475098 and perplexity is 64.21254036923712
At time: 302.5473601818085 and batch: 100, loss is 4.126308856010437 and perplexity is 61.94883832048289
At time: 303.43415546417236 and batch: 150, loss is 4.098268599510193 and perplexity is 60.235904784163836
At time: 304.34668946266174 and batch: 200, loss is 4.091351470947266 and perplexity is 59.82068301343286
At time: 305.23440623283386 and batch: 250, loss is 4.083181571960449 and perplexity is 59.33394508311779
At time: 306.1227581501007 and batch: 300, loss is 4.124442124366761 and perplexity is 61.83330433272649
At time: 307.01661944389343 and batch: 350, loss is 4.1233833265304565 and perplexity is 61.76787001085962
At time: 307.91342759132385 and batch: 400, loss is 4.065646114349366 and perplexity is 58.302566480376264
At time: 308.81196641921997 and batch: 450, loss is 4.103172340393066 and perplexity is 60.53201147494862
At time: 309.71383929252625 and batch: 500, loss is 4.128491759300232 and perplexity is 62.08421434608118
At time: 310.6193222999573 and batch: 550, loss is 4.086044344902039 and perplexity is 59.5040480625501
At time: 311.52123379707336 and batch: 600, loss is 4.099327731132507 and perplexity is 60.29973633275831
At time: 312.4252154827118 and batch: 650, loss is 4.156897192001343 and perplexity is 63.87302907003184
At time: 313.33675360679626 and batch: 700, loss is 4.170993137359619 and perplexity is 64.77975536633463
At time: 314.24888920783997 and batch: 750, loss is 4.136105537414551 and perplexity is 62.55871385328497
At time: 315.15276193618774 and batch: 800, loss is 4.121487612724304 and perplexity is 61.650886725352
At time: 316.0600504875183 and batch: 850, loss is 4.125903887748718 and perplexity is 61.92375608620997
At time: 316.9673664569855 and batch: 900, loss is 4.110970044136048 and perplexity is 61.00586725987882
At time: 317.87428641319275 and batch: 950, loss is 4.192711405754089 and perplexity is 66.20204844578875
At time: 318.7835955619812 and batch: 1000, loss is 4.160609011650085 and perplexity is 64.11055478796091
At time: 319.6989505290985 and batch: 1050, loss is 4.107027926445007 and perplexity is 60.76584835351511
At time: 320.61094546318054 and batch: 1100, loss is 4.155476112365722 and perplexity is 63.78232487336292
At time: 321.51600432395935 and batch: 1150, loss is 4.103689203262329 and perplexity is 60.56330631095446
At time: 322.4221992492676 and batch: 1200, loss is 4.187796726226806 and perplexity is 65.87748481005025
At time: 323.33475136756897 and batch: 1250, loss is 4.175643758773804 and perplexity is 65.08172310841745
At time: 324.23808455467224 and batch: 1300, loss is 4.164634971618653 and perplexity is 64.36918157632213
At time: 325.14125967025757 and batch: 1350, loss is 4.073834705352783 and perplexity is 58.78194237969122
At time: 326.04391384124756 and batch: 1400, loss is 4.081467971801758 and perplexity is 59.232357490523675
At time: 326.9468004703522 and batch: 1450, loss is 4.0171511316299435 and perplexity is 55.5426465302394
At time: 327.8501663208008 and batch: 1500, loss is 4.049143815040589 and perplexity is 57.34833523769266
At time: 328.75428223609924 and batch: 1550, loss is 4.048295288085938 and perplexity is 57.29969426894411
At time: 329.6576476097107 and batch: 1600, loss is 4.138165678977966 and perplexity is 62.68772650638292
At time: 330.56088066101074 and batch: 1650, loss is 4.091170530319214 and perplexity is 59.80986000066885
At time: 331.46392130851746 and batch: 1700, loss is 4.115298581123352 and perplexity is 61.270505748304615
At time: 332.36698150634766 and batch: 1750, loss is 4.1063123178482055 and perplexity is 60.72237934529439
At time: 333.27010798454285 and batch: 1800, loss is 4.066451482772827 and perplexity is 58.34954043955902
At time: 334.1729528903961 and batch: 1850, loss is 4.113701324462891 and perplexity is 61.172719140853005
At time: 335.07594537734985 and batch: 1900, loss is 4.186316609382629 and perplexity is 65.78005055995607
At time: 335.97884798049927 and batch: 1950, loss is 4.119105734825134 and perplexity is 61.50421658532164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4945406181867735 and perplexity of 89.52703244668189
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 338.9773139953613 and batch: 50, loss is 4.134931836128235 and perplexity is 62.48533168316296
At time: 339.85235595703125 and batch: 100, loss is 4.117769684791565 and perplexity is 61.42209874367593
At time: 340.72747254371643 and batch: 150, loss is 4.085556688308716 and perplexity is 59.47503759533073
At time: 341.6086447238922 and batch: 200, loss is 4.072025294303894 and perplexity is 58.67567785077285
At time: 342.49181604385376 and batch: 250, loss is 4.063923416137695 and perplexity is 58.20221521565446
At time: 343.37489128112793 and batch: 300, loss is 4.092513837814331 and perplexity is 59.89025702075993
At time: 344.27113795280457 and batch: 350, loss is 4.087243809700012 and perplexity is 59.57546389536451
At time: 345.16914558410645 and batch: 400, loss is 4.032845959663391 and perplexity is 56.42125558970287
At time: 346.0746190547943 and batch: 450, loss is 4.060320920944214 and perplexity is 57.99291923532476
At time: 346.9736177921295 and batch: 500, loss is 4.079867844581604 and perplexity is 59.1376539720347
At time: 347.8725838661194 and batch: 550, loss is 4.039062294960022 and perplexity is 56.77308143304818
At time: 348.77168464660645 and batch: 600, loss is 4.041474032402038 and perplexity is 56.91016844172778
At time: 349.6714754104614 and batch: 650, loss is 4.083178243637085 and perplexity is 59.3337476008907
At time: 350.6088066101074 and batch: 700, loss is 4.0953918552398685 and perplexity is 60.06287049723598
At time: 351.5088744163513 and batch: 750, loss is 4.044643077850342 and perplexity is 57.090805424218
At time: 352.41575598716736 and batch: 800, loss is 4.038087601661682 and perplexity is 56.71777205027044
At time: 353.3389210700989 and batch: 850, loss is 4.042146320343018 and perplexity is 56.94844132544783
At time: 354.25664043426514 and batch: 900, loss is 4.01450788974762 and perplexity is 55.3960277405039
At time: 355.1621661186218 and batch: 950, loss is 4.100491032600403 and perplexity is 60.369923921295104
At time: 356.06708097457886 and batch: 1000, loss is 4.060998892784118 and perplexity is 58.03225013259402
At time: 356.97649002075195 and batch: 1050, loss is 4.007062029838562 and perplexity is 54.98508847509659
At time: 357.8780851364136 and batch: 1100, loss is 4.039082446098328 and perplexity is 56.77422548679113
At time: 358.7878737449646 and batch: 1150, loss is 3.9884834909439086 and perplexity is 53.97297676038172
At time: 359.6865336894989 and batch: 1200, loss is 4.060420198440552 and perplexity is 57.998676912950934
At time: 360.5938642024994 and batch: 1250, loss is 4.042009119987488 and perplexity is 56.94062851502354
At time: 361.5003490447998 and batch: 1300, loss is 4.028300919532776 and perplexity is 56.16540059487871
At time: 362.41350293159485 and batch: 1350, loss is 3.9392887020111083 and perplexity is 51.38204035723443
At time: 363.3190407752991 and batch: 1400, loss is 3.941594371795654 and perplexity is 51.50064705655197
At time: 364.2221245765686 and batch: 1450, loss is 3.8639118528366088 and perplexity is 47.65139248373534
At time: 365.1279537677765 and batch: 1500, loss is 3.8975695848464964 and perplexity is 49.282526434573384
At time: 366.0377848148346 and batch: 1550, loss is 3.8881066131591795 and perplexity is 48.818366910163974
At time: 366.95081901550293 and batch: 1600, loss is 3.9746016216278077 and perplexity is 53.22890743582121
At time: 367.86316990852356 and batch: 1650, loss is 3.921986451148987 and perplexity is 50.500662305160496
At time: 368.7726526260376 and batch: 1700, loss is 3.9346073865890503 and perplexity is 51.14206695313759
At time: 369.6833345890045 and batch: 1750, loss is 3.920711011886597 and perplexity is 50.43629283607993
At time: 370.59902024269104 and batch: 1800, loss is 3.8818833017349244 and perplexity is 48.51549840965559
At time: 371.5043306350708 and batch: 1850, loss is 3.9111670684814452 and perplexity is 49.9572214631418
At time: 372.40979075431824 and batch: 1900, loss is 3.9824338722229005 and perplexity is 53.647446489563265
At time: 373.3213481903076 and batch: 1950, loss is 3.920787115097046 and perplexity is 50.44013134594751
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38595339752907 and perplexity of 80.31475861518356
finished 10 epochs...
Completing Train Step...
At time: 376.32343792915344 and batch: 50, loss is 4.049838795661926 and perplexity is 57.3882050721252
At time: 377.227499961853 and batch: 100, loss is 4.033226227760315 and perplexity is 56.44271487307381
At time: 378.11900520324707 and batch: 150, loss is 3.997469415664673 and perplexity is 54.4601594819355
At time: 379.0051078796387 and batch: 200, loss is 3.9891716480255126 and perplexity is 54.01013142921261
At time: 379.89557337760925 and batch: 250, loss is 3.980413098335266 and perplexity is 53.53914659221499
At time: 380.7960488796234 and batch: 300, loss is 4.0127490663528445 and perplexity is 55.29868154341541
At time: 381.69583678245544 and batch: 350, loss is 4.012147331237793 and perplexity is 55.2654163943226
At time: 382.59565925598145 and batch: 400, loss is 3.958204188346863 and perplexity is 52.36320700710764
At time: 383.49561882019043 and batch: 450, loss is 3.99329270362854 and perplexity is 54.23316944433387
At time: 384.3966598510742 and batch: 500, loss is 4.016363348960876 and perplexity is 55.498908226309666
At time: 385.3001570701599 and batch: 550, loss is 3.9784994983673094 and perplexity is 53.43679204707289
At time: 386.19968938827515 and batch: 600, loss is 3.983373212814331 and perplexity is 53.69786338929055
At time: 387.1008126735687 and batch: 650, loss is 4.026901726722717 and perplexity is 56.08686932319962
At time: 388.0008456707001 and batch: 700, loss is 4.042155723571778 and perplexity is 56.94897682718686
At time: 388.91158723831177 and batch: 750, loss is 3.9964342451095582 and perplexity is 54.403813097503594
At time: 389.81166648864746 and batch: 800, loss is 3.9893141746520997 and perplexity is 54.017829859649375
At time: 390.7118067741394 and batch: 850, loss is 3.997216725349426 and perplexity is 54.446399665626984
At time: 391.6116807460785 and batch: 900, loss is 3.966881985664368 and perplexity is 52.81958160362916
At time: 392.5117623806 and batch: 950, loss is 4.056492133140564 and perplexity is 57.77130118843221
At time: 393.41164898872375 and batch: 1000, loss is 4.019235591888428 and perplexity is 55.65854371916074
At time: 394.32042932510376 and batch: 1050, loss is 3.9681515312194824 and perplexity is 52.88668105256836
At time: 395.22667145729065 and batch: 1100, loss is 4.001129307746887 and perplexity is 54.65984297554467
At time: 396.1548388004303 and batch: 1150, loss is 3.953282856941223 and perplexity is 52.10614337844726
At time: 397.0544579029083 and batch: 1200, loss is 4.027495617866516 and perplexity is 56.12018871123949
At time: 397.954607963562 and batch: 1250, loss is 4.013087034225464 and perplexity is 55.31737387970194
At time: 398.867693901062 and batch: 1300, loss is 4.001614556312561 and perplexity is 54.686373022261506
At time: 399.7697651386261 and batch: 1350, loss is 3.913656516075134 and perplexity is 50.08174227761334
At time: 400.66960859298706 and batch: 1400, loss is 3.918525261878967 and perplexity is 50.32617210066963
At time: 401.57011365890503 and batch: 1450, loss is 3.8438025665283204 and perplexity is 46.70272744620017
At time: 402.47079586982727 and batch: 1500, loss is 3.8803833055496217 and perplexity is 48.442779899491626
At time: 403.3706865310669 and batch: 1550, loss is 3.872868847846985 and perplexity is 48.080122970528436
At time: 404.27721905708313 and batch: 1600, loss is 3.9620946931838987 and perplexity is 52.56732311714936
At time: 405.18334913253784 and batch: 1650, loss is 3.9111570835113527 and perplexity is 49.95672264426994
At time: 406.0898141860962 and batch: 1700, loss is 3.927580728530884 and perplexity is 50.78396872655642
At time: 406.99601221084595 and batch: 1750, loss is 3.916913809776306 and perplexity is 50.245139192679474
At time: 407.90257477760315 and batch: 1800, loss is 3.880119080543518 and perplexity is 48.429981796540886
At time: 408.8071849346161 and batch: 1850, loss is 3.911755142211914 and perplexity is 49.986608632795814
At time: 409.71396136283875 and batch: 1900, loss is 3.9884339952468872 and perplexity is 53.9703053963877
At time: 410.62053966522217 and batch: 1950, loss is 3.925229105949402 and perplexity is 50.66468430985725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382396041515261 and perplexity of 80.02955800643916
finished 11 epochs...
Completing Train Step...
At time: 413.6092743873596 and batch: 50, loss is 4.019274945259094 and perplexity is 55.66073411356188
At time: 414.4850754737854 and batch: 100, loss is 4.001141166687011 and perplexity is 54.66049118719325
At time: 415.36102199554443 and batch: 150, loss is 3.963866186141968 and perplexity is 52.660528291656476
At time: 416.24048352241516 and batch: 200, loss is 3.956061725616455 and perplexity is 52.25114087926806
At time: 417.1330852508545 and batch: 250, loss is 3.947806191444397 and perplexity is 51.821555468551246
At time: 418.03633165359497 and batch: 300, loss is 3.980973358154297 and perplexity is 53.569150829095136
At time: 418.943190574646 and batch: 350, loss is 3.980179991722107 and perplexity is 53.52666771759204
At time: 419.8774983882904 and batch: 400, loss is 3.9261679220199586 and perplexity is 50.71227146399436
At time: 420.7816219329834 and batch: 450, loss is 3.96377977848053 and perplexity is 52.65597821514027
At time: 421.68654894828796 and batch: 500, loss is 3.987473840713501 and perplexity is 53.91851043255692
At time: 422.5874333381653 and batch: 550, loss is 3.9506399917602537 and perplexity is 51.9686156800301
At time: 423.4850227832794 and batch: 600, loss is 3.9559076118469236 and perplexity is 52.243088879462796
At time: 424.38968563079834 and batch: 650, loss is 3.9997668981552126 and perplexity is 54.58542458686966
At time: 425.2922565937042 and batch: 700, loss is 4.015696496963501 and perplexity is 55.46191100571304
At time: 426.19488739967346 and batch: 750, loss is 3.9718457221984864 and perplexity is 53.08241587092221
At time: 427.092999458313 and batch: 800, loss is 3.9649086380004883 and perplexity is 52.71545298044281
At time: 427.9905960559845 and batch: 850, loss is 3.974325489997864 and perplexity is 53.21421127998095
At time: 428.88830280303955 and batch: 900, loss is 3.943527112007141 and perplexity is 51.600280679975974
At time: 429.7903890609741 and batch: 950, loss is 4.034315524101257 and perplexity is 56.50423121453797
At time: 430.68834352493286 and batch: 1000, loss is 3.997477316856384 and perplexity is 54.46058978379613
At time: 431.5857925415039 and batch: 1050, loss is 3.9480123138427734 and perplexity is 51.83223815278444
At time: 432.4866273403168 and batch: 1100, loss is 3.981345462799072 and perplexity is 53.58908786803765
At time: 433.3844072818756 and batch: 1150, loss is 3.9332808303833007 and perplexity is 51.07426910561601
At time: 434.28313183784485 and batch: 1200, loss is 4.008410582542419 and perplexity is 55.05928878510082
At time: 435.1823480129242 and batch: 1250, loss is 3.9964552211761473 and perplexity is 54.404954287478624
At time: 436.08071303367615 and batch: 1300, loss is 3.985842156410217 and perplexity is 53.830604182555234
At time: 436.9794499874115 and batch: 1350, loss is 3.897928533554077 and perplexity is 49.30021950900652
At time: 437.88131833076477 and batch: 1400, loss is 3.903884768486023 and perplexity is 49.594739442841075
At time: 438.7851150035858 and batch: 1450, loss is 3.8298488903045653 and perplexity is 46.05557826396369
At time: 439.69530725479126 and batch: 1500, loss is 3.8684600162506104 and perplexity is 47.868612405058556
At time: 440.6020333766937 and batch: 1550, loss is 3.861373338699341 and perplexity is 47.530582154494915
At time: 441.5195617675781 and batch: 1600, loss is 3.951828408241272 and perplexity is 52.03041275245644
At time: 442.4365758895874 and batch: 1650, loss is 3.901485686302185 and perplexity is 49.47590019659009
At time: 443.34853863716125 and batch: 1700, loss is 3.9192358303070067 and perplexity is 50.36194499770889
At time: 444.265554189682 and batch: 1750, loss is 3.909267559051514 and perplexity is 49.86241731906774
At time: 445.17700815200806 and batch: 1800, loss is 3.8734781408309935 and perplexity is 48.109426778520394
At time: 446.09684205055237 and batch: 1850, loss is 3.905872325897217 and perplexity is 49.69340985885305
At time: 447.00838589668274 and batch: 1900, loss is 3.9845116567611694 and perplexity is 53.75903020771504
At time: 447.92034125328064 and batch: 1950, loss is 3.920131034851074 and perplexity is 50.407049425551094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38158697083939 and perplexity of 79.96483462427908
finished 12 epochs...
Completing Train Step...
At time: 450.8813228607178 and batch: 50, loss is 3.9962225580215454 and perplexity is 54.392297731602326
At time: 451.80137729644775 and batch: 100, loss is 3.977468957901001 and perplexity is 53.381751636035254
At time: 452.68919563293457 and batch: 150, loss is 3.9395342683792114 and perplexity is 51.394659607639014
At time: 453.57215213775635 and batch: 200, loss is 3.932091064453125 and perplexity is 51.013538814904784
At time: 454.4590497016907 and batch: 250, loss is 3.9240969944000246 and perplexity is 50.607358691224704
At time: 455.35479497909546 and batch: 300, loss is 3.9574884796142578 and perplexity is 52.325743610624635
At time: 456.2557632923126 and batch: 350, loss is 3.95682692527771 and perplexity is 52.291138735790526
At time: 457.1553816795349 and batch: 400, loss is 3.9028149175643922 and perplexity is 49.541708837619204
At time: 458.06102895736694 and batch: 450, loss is 3.9422322702407837 and perplexity is 51.533509719639
At time: 458.9634828567505 and batch: 500, loss is 3.966197786331177 and perplexity is 52.78345484147915
At time: 459.86250352859497 and batch: 550, loss is 3.930136079788208 and perplexity is 50.91390555130265
At time: 460.760427236557 and batch: 600, loss is 3.935688452720642 and perplexity is 51.197384805360976
At time: 461.6593954563141 and batch: 650, loss is 3.9795746850967406 and perplexity is 53.494277474992
At time: 462.5578224658966 and batch: 700, loss is 3.995780267715454 and perplexity is 54.36824586493543
At time: 463.4609806537628 and batch: 750, loss is 3.9534286785125734 and perplexity is 52.11374213216935
At time: 464.3640296459198 and batch: 800, loss is 3.946446657180786 and perplexity is 51.75115015835828
At time: 465.3010654449463 and batch: 850, loss is 3.956818313598633 and perplexity is 52.29068842322414
At time: 466.19936323165894 and batch: 900, loss is 3.925698986053467 and perplexity is 50.68849623092905
At time: 467.09745359420776 and batch: 950, loss is 4.017111768722534 and perplexity is 55.54046025321617
At time: 467.99527764320374 and batch: 1000, loss is 3.9809398746490476 and perplexity is 53.567357176181204
At time: 468.90305399894714 and batch: 1050, loss is 3.932609577178955 and perplexity is 51.03999684278925
At time: 469.80504417419434 and batch: 1100, loss is 3.9655135011672975 and perplexity is 52.74734826144025
At time: 470.7036018371582 and batch: 1150, loss is 3.917374300956726 and perplexity is 50.268281964248814
At time: 471.6020607948303 and batch: 1200, loss is 3.992656636238098 and perplexity is 54.19868446231893
At time: 472.51061367988586 and batch: 1250, loss is 3.9826162385940553 and perplexity is 53.65723087184532
At time: 473.4123923778534 and batch: 1300, loss is 3.9717771577835084 and perplexity is 53.07877643090186
At time: 474.31729006767273 and batch: 1350, loss is 3.8844005393981935 and perplexity is 48.63777728743475
At time: 475.21831727027893 and batch: 1400, loss is 3.8910823678970337 and perplexity is 48.96385475750741
At time: 476.1243939399719 and batch: 1450, loss is 3.817187647819519 and perplexity is 45.47613340643639
At time: 477.0236248970032 and batch: 1500, loss is 3.856871876716614 and perplexity is 47.3171058840426
At time: 477.9303753376007 and batch: 1550, loss is 3.8505750608444216 and perplexity is 47.020094873877774
At time: 478.8346457481384 and batch: 1600, loss is 3.9415969324111937 and perplexity is 51.500778930077956
At time: 479.73860478401184 and batch: 1650, loss is 3.8912778425216676 and perplexity is 48.973426884160226
At time: 480.64087986946106 and batch: 1700, loss is 3.909780945777893 and perplexity is 49.88802259440638
At time: 481.5465919971466 and batch: 1750, loss is 3.900102710723877 and perplexity is 49.40752352743341
At time: 482.45341992378235 and batch: 1800, loss is 3.8653918504714966 and perplexity is 47.721968645304024
At time: 483.35646510124207 and batch: 1850, loss is 3.8975403833389284 and perplexity is 49.28108733151682
At time: 484.2608301639557 and batch: 1900, loss is 3.9773979330062867 and perplexity is 53.37796033738552
At time: 485.15843534469604 and batch: 1950, loss is 3.912099852561951 and perplexity is 50.00384250433107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381663619640261 and perplexity of 79.97096406786919
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 488.1268780231476 and batch: 50, loss is 3.9951776266098022 and perplexity is 54.33549119578136
At time: 488.9975872039795 and batch: 100, loss is 3.9954655361175537 and perplexity is 54.351137152506745
At time: 489.8816041946411 and batch: 150, loss is 3.9630872297286985 and perplexity is 52.61952400776585
At time: 490.77988481521606 and batch: 200, loss is 3.946240291595459 and perplexity is 51.740471603845464
At time: 491.6888835430145 and batch: 250, loss is 3.9435988521575926 and perplexity is 51.603982624662756
At time: 492.5913529396057 and batch: 300, loss is 3.969163188934326 and perplexity is 52.94021134406839
At time: 493.49191546440125 and batch: 350, loss is 3.963551254272461 and perplexity is 52.643946424248675
At time: 494.39180636405945 and batch: 400, loss is 3.914861307144165 and perplexity is 50.142116675395634
At time: 495.2918059825897 and batch: 450, loss is 3.9537004041671753 and perplexity is 52.12790469694292
At time: 496.19263219833374 and batch: 500, loss is 3.974671149253845 and perplexity is 53.23260844405146
At time: 497.0928752422333 and batch: 550, loss is 3.9374912357330323 and perplexity is 51.28976582741543
At time: 497.99302673339844 and batch: 600, loss is 3.942793245315552 and perplexity is 51.56242684424177
At time: 498.89262771606445 and batch: 650, loss is 3.979951791763306 and perplexity is 53.51445432782466
At time: 499.7927026748657 and batch: 700, loss is 3.9935920238494873 and perplexity is 54.249404958282206
At time: 500.6927788257599 and batch: 750, loss is 3.9443591451644897 and perplexity is 51.643231690284736
At time: 501.5938768386841 and batch: 800, loss is 3.932778730392456 and perplexity is 51.04863115251232
At time: 502.4933228492737 and batch: 850, loss is 3.9451209783554075 and perplexity is 51.68259020868188
At time: 503.39385080337524 and batch: 900, loss is 3.9084355354309084 and perplexity is 49.82094786425308
At time: 504.3011119365692 and batch: 950, loss is 4.004089703559876 and perplexity is 54.82189750024324
At time: 505.2017865180969 and batch: 1000, loss is 3.9661303424835204 and perplexity is 52.77989504223667
At time: 506.10974526405334 and batch: 1050, loss is 3.9190533638000487 and perplexity is 50.35275646784651
At time: 507.02137446403503 and batch: 1100, loss is 3.9441395378112794 and perplexity is 51.631891702079976
At time: 507.9226875305176 and batch: 1150, loss is 3.896889662742615 and perplexity is 49.24902954444384
At time: 508.8307635784149 and batch: 1200, loss is 3.9683973836898803 and perplexity is 52.89968497221367
At time: 509.7446753978729 and batch: 1250, loss is 3.956236343383789 and perplexity is 52.26026565347971
At time: 510.6587951183319 and batch: 1300, loss is 3.9438872718811036 and perplexity is 51.61886837763261
At time: 511.57916808128357 and batch: 1350, loss is 3.853644599914551 and perplexity is 47.164646632311374
At time: 512.4948916435242 and batch: 1400, loss is 3.8588787746429443 and perplexity is 47.41216183761504
At time: 513.4056782722473 and batch: 1450, loss is 3.77540545463562 and perplexity is 43.61518871162861
At time: 514.3216261863708 and batch: 1500, loss is 3.8185865688323974 and perplexity is 45.53979544374186
At time: 515.2271506786346 and batch: 1550, loss is 3.81091269493103 and perplexity is 45.19166625415784
At time: 516.1416110992432 and batch: 1600, loss is 3.8981351613998414 and perplexity is 49.31040735966994
At time: 517.0522613525391 and batch: 1650, loss is 3.8467204570770264 and perplexity is 46.839199902230874
At time: 517.964866399765 and batch: 1700, loss is 3.862204923629761 and perplexity is 47.57012430940002
At time: 518.8809535503387 and batch: 1750, loss is 3.847488923072815 and perplexity is 46.87520806837929
At time: 519.7900812625885 and batch: 1800, loss is 3.823607783317566 and perplexity is 45.769035574563645
At time: 520.701714515686 and batch: 1850, loss is 3.8425251626968384 and perplexity is 46.64310729083434
At time: 521.6112365722656 and batch: 1900, loss is 3.919262671470642 and perplexity is 50.36329678905731
At time: 522.5261535644531 and batch: 1950, loss is 3.8556458282470705 and perplexity is 47.25912836767547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350767055777617 and perplexity of 77.53791602689603
finished 14 epochs...
Completing Train Step...
At time: 525.480033159256 and batch: 50, loss is 3.9791932916641235 and perplexity is 53.47387899905009
At time: 526.3886377811432 and batch: 100, loss is 3.9710599994659423 and perplexity is 53.0407241912692
At time: 527.2712483406067 and batch: 150, loss is 3.9333947134017944 and perplexity is 51.08008592876152
At time: 528.1547515392303 and batch: 200, loss is 3.917424955368042 and perplexity is 50.2708283389716
At time: 529.0371925830841 and batch: 250, loss is 3.915185012817383 and perplexity is 50.15835059039405
At time: 529.9241094589233 and batch: 300, loss is 3.941589493751526 and perplexity is 51.500395834735734
At time: 530.8209924697876 and batch: 350, loss is 3.9394168615341187 and perplexity is 51.38862587700744
At time: 531.7169616222382 and batch: 400, loss is 3.8902448844909667 and perplexity is 48.922865507954846
At time: 532.6140415668488 and batch: 450, loss is 3.9316813468933107 and perplexity is 50.99264195346193
At time: 533.5114562511444 and batch: 500, loss is 3.9526947498321534 and perplexity is 52.075508394309146
At time: 534.4595987796783 and batch: 550, loss is 3.9165939617156984 and perplexity is 50.22907095218849
At time: 535.360030412674 and batch: 600, loss is 3.9229295301437377 and perplexity is 50.5483108836567
At time: 536.257426738739 and batch: 650, loss is 3.961400547027588 and perplexity is 52.530846373420424
At time: 537.1627640724182 and batch: 700, loss is 3.976157741546631 and perplexity is 53.311802479526044
At time: 538.0619060993195 and batch: 750, loss is 3.928939781188965 and perplexity is 50.853033735103466
At time: 538.9605264663696 and batch: 800, loss is 3.9177527809143067 and perplexity is 50.28731110232083
At time: 539.8593246936798 and batch: 850, loss is 3.930791206359863 and perplexity is 50.94727153197294
At time: 540.7592971324921 and batch: 900, loss is 3.894714984893799 and perplexity is 49.14204514128648
At time: 541.6572239398956 and batch: 950, loss is 3.9904176902771 and perplexity is 54.077472281047605
At time: 542.5547406673431 and batch: 1000, loss is 3.952929348945618 and perplexity is 52.087726695556945
At time: 543.4546213150024 and batch: 1050, loss is 3.9075741386413574 and perplexity is 49.77805073808629
At time: 544.3584146499634 and batch: 1100, loss is 3.9341357278823854 and perplexity is 51.11795103966966
At time: 545.257749080658 and batch: 1150, loss is 3.887266392707825 and perplexity is 48.77736594722024
At time: 546.1567771434784 and batch: 1200, loss is 3.959894857406616 and perplexity is 52.45181073975357
At time: 547.0564160346985 and batch: 1250, loss is 3.94914824962616 and perplexity is 51.89114970036796
At time: 547.9566609859467 and batch: 1300, loss is 3.938048453330994 and perplexity is 51.31835335152587
At time: 548.8600034713745 and batch: 1350, loss is 3.8482972955703736 and perplexity is 46.91311601720644
At time: 549.7621958255768 and batch: 1400, loss is 3.8547554302215574 and perplexity is 47.217067661253246
At time: 550.6645090579987 and batch: 1450, loss is 3.7731782150268556 and perplexity is 43.51815533418909
At time: 551.5678746700287 and batch: 1500, loss is 3.8168411016464234 and perplexity is 45.46037655683286
At time: 552.4813327789307 and batch: 1550, loss is 3.810757055282593 and perplexity is 45.18463318643604
At time: 553.3869462013245 and batch: 1600, loss is 3.8986554765701293 and perplexity is 49.336070988681016
At time: 554.2906219959259 and batch: 1650, loss is 3.84802095413208 and perplexity is 46.90015377033687
At time: 555.1938121318817 and batch: 1700, loss is 3.864943256378174 and perplexity is 47.70056565303489
At time: 556.0969181060791 and batch: 1750, loss is 3.851256947517395 and perplexity is 47.05216818387278
At time: 557.0181097984314 and batch: 1800, loss is 3.828185448646545 and perplexity is 45.979031179950105
At time: 557.9264025688171 and batch: 1850, loss is 3.8476184511184695 and perplexity is 46.88128011571175
At time: 558.8310689926147 and batch: 1900, loss is 3.9244954872131346 and perplexity is 50.6275293786237
At time: 559.734158039093 and batch: 1950, loss is 3.8609934520721434 and perplexity is 47.512529351177896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349124784247819 and perplexity of 77.4106822197512
finished 15 epochs...
Completing Train Step...
At time: 562.683919429779 and batch: 50, loss is 3.970319709777832 and perplexity is 53.001473220437525
At time: 563.5576786994934 and batch: 100, loss is 3.9605706310272217 and perplexity is 52.48726826908661
At time: 564.4330990314484 and batch: 150, loss is 3.9222656726837157 and perplexity is 50.514765146411015
At time: 565.3185946941376 and batch: 200, loss is 3.905852599143982 and perplexity is 49.692429578888266
At time: 566.2057907581329 and batch: 250, loss is 3.9033471584320067 and perplexity is 49.56808397805523
At time: 567.1040551662445 and batch: 300, loss is 3.9298666381835936 and perplexity is 50.900189074871406
At time: 568.016654253006 and batch: 350, loss is 3.9284845495224 and perplexity is 50.82988909229322
At time: 568.9199588298798 and batch: 400, loss is 3.879258246421814 and perplexity is 48.38830955471415
At time: 569.8231117725372 and batch: 450, loss is 3.921196475028992 and perplexity is 50.46078374152585
At time: 570.7256672382355 and batch: 500, loss is 3.942263798713684 and perplexity is 51.53513451811723
At time: 571.6289420127869 and batch: 550, loss is 3.9064333200454713 and perplexity is 49.72129539206983
At time: 572.540876865387 and batch: 600, loss is 3.913296971321106 and perplexity is 50.063738886611176
At time: 573.4455451965332 and batch: 650, loss is 3.9522815227508543 and perplexity is 52.05399382947476
At time: 574.3493061065674 and batch: 700, loss is 3.967338275909424 and perplexity is 52.843688162838504
At time: 575.2628755569458 and batch: 750, loss is 3.920945572853088 and perplexity is 50.44812460925563
At time: 576.170286655426 and batch: 800, loss is 3.909658098220825 and perplexity is 49.8818943491314
At time: 577.0774183273315 and batch: 850, loss is 3.923193893432617 and perplexity is 50.56167576788374
At time: 577.9848465919495 and batch: 900, loss is 3.8872949981689455 and perplexity is 48.77876126622219
At time: 578.8971047401428 and batch: 950, loss is 3.9834010887145994 and perplexity is 53.699360286438605
At time: 579.8267865180969 and batch: 1000, loss is 3.9459882497787477 and perplexity is 51.72743248465561
At time: 580.7289686203003 and batch: 1050, loss is 3.9015071249008177 and perplexity is 49.476960901926375
At time: 581.632390499115 and batch: 1100, loss is 3.92866144657135 and perplexity is 50.83888154501783
At time: 582.5353760719299 and batch: 1150, loss is 3.8818236637115477 and perplexity is 48.51260512750298
At time: 583.4383239746094 and batch: 1200, loss is 3.9548430490493773 and perplexity is 52.187502423499
At time: 584.3411290645599 and batch: 1250, loss is 3.944981026649475 and perplexity is 51.67535764813155
At time: 585.2470638751984 and batch: 1300, loss is 3.9342489862442016 and perplexity is 51.12374090293284
At time: 586.1518607139587 and batch: 1350, loss is 3.844908390045166 and perplexity is 46.75440098615313
At time: 587.0543029308319 and batch: 1400, loss is 3.851962242126465 and perplexity is 47.08536553001642
At time: 587.9583477973938 and batch: 1450, loss is 3.771092481613159 and perplexity is 43.427482655894536
At time: 588.8605661392212 and batch: 1500, loss is 3.8149044513702393 and perplexity is 45.37242090317975
At time: 589.7631566524506 and batch: 1550, loss is 3.809447002410889 and perplexity is 45.12547768485103
At time: 590.665096282959 and batch: 1600, loss is 3.8977394819259645 and perplexity is 49.290900103194204
At time: 591.5680196285248 and batch: 1650, loss is 3.8473658990859985 and perplexity is 46.86944164811114
At time: 592.4709415435791 and batch: 1700, loss is 3.8648980331420897 and perplexity is 47.69840852786947
At time: 593.3733105659485 and batch: 1750, loss is 3.8515964555740356 and perplexity is 47.06814548611156
At time: 594.2761807441711 and batch: 1800, loss is 3.8290599393844604 and perplexity is 46.01925700284656
At time: 595.1891779899597 and batch: 1850, loss is 3.8486563301086427 and perplexity is 46.92996247020272
At time: 596.092747926712 and batch: 1900, loss is 3.9255533599853516 and perplexity is 50.68111520197241
At time: 596.9961066246033 and batch: 1950, loss is 3.8618871355056763 and perplexity is 47.555009490615426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348508187227471 and perplexity of 77.36296573618391
finished 16 epochs...
Completing Train Step...
At time: 599.9392263889313 and batch: 50, loss is 3.9627476167678832 and perplexity is 52.60165676956544
At time: 600.8390533924103 and batch: 100, loss is 3.95245680809021 and perplexity is 52.063118931172895
At time: 601.7132923603058 and batch: 150, loss is 3.9137946271896364 and perplexity is 50.0886596005241
At time: 602.6213178634644 and batch: 200, loss is 3.89724338054657 and perplexity is 49.266452884312315
At time: 603.5123045444489 and batch: 250, loss is 3.8945881748199462 and perplexity is 49.13581383001771
At time: 604.4100954532623 and batch: 300, loss is 3.9213049030303955 and perplexity is 50.46625540009135
At time: 605.2984511852264 and batch: 350, loss is 3.9204293870925904 and perplexity is 50.42209072542663
At time: 606.1937880516052 and batch: 400, loss is 3.8711936378479006 and perplexity is 47.99964609442515
At time: 607.0960431098938 and batch: 450, loss is 3.9134952878952025 and perplexity is 50.0736683403487
At time: 608.0005872249603 and batch: 500, loss is 3.934728217124939 and perplexity is 51.1482468498466
At time: 608.9004364013672 and batch: 550, loss is 3.8990161275863646 and perplexity is 49.35386730175644
At time: 609.7997224330902 and batch: 600, loss is 3.906281065940857 and perplexity is 49.71372569703285
At time: 610.6977863311768 and batch: 650, loss is 3.9455239391326904 and perplexity is 51.70342046201003
At time: 611.5975093841553 and batch: 700, loss is 3.9607336854934694 and perplexity is 52.49582725037013
At time: 612.4964511394501 and batch: 750, loss is 3.914814076423645 and perplexity is 50.139748483022814
At time: 613.3956758975983 and batch: 800, loss is 3.903415379524231 and perplexity is 49.57146568223414
At time: 614.2955138683319 and batch: 850, loss is 3.917362241744995 and perplexity is 50.26767577204836
At time: 615.1934096813202 and batch: 900, loss is 3.881607050895691 and perplexity is 48.50209781355228
At time: 616.0934643745422 and batch: 950, loss is 3.9778560113906862 and perplexity is 53.402417228378305
At time: 616.9957733154297 and batch: 1000, loss is 3.940533981323242 and perplexity is 51.44606520524214
At time: 617.90718126297 and batch: 1050, loss is 3.8967887210845946 and perplexity is 49.24405851664186
At time: 618.8097422122955 and batch: 1100, loss is 3.924224376678467 and perplexity is 50.61380558248187
At time: 619.7105808258057 and batch: 1150, loss is 3.87736741065979 and perplexity is 48.296901654441506
At time: 620.6153433322906 and batch: 1200, loss is 3.95063129901886 and perplexity is 51.968163932256864
At time: 621.5134830474854 and batch: 1250, loss is 3.9413287162780763 and perplexity is 51.48696744261548
At time: 622.4134457111359 and batch: 1300, loss is 3.9307732820510863 and perplexity is 50.946358345530804
At time: 623.3106479644775 and batch: 1350, loss is 3.8417053508758543 and perplexity is 46.60488439004361
At time: 624.2168712615967 and batch: 1400, loss is 3.8491698503494263 and perplexity is 46.954068144676526
At time: 625.1144952774048 and batch: 1450, loss is 3.7686751747131346 and perplexity is 43.32263188172653
At time: 626.0133605003357 and batch: 1500, loss is 3.8125776481628417 and perplexity is 45.266970936930306
At time: 626.912623167038 and batch: 1550, loss is 3.807461476325989 and perplexity is 45.03596876237041
At time: 627.8113913536072 and batch: 1600, loss is 3.896048626899719 and perplexity is 49.20762675842315
At time: 628.716676235199 and batch: 1650, loss is 3.8458058881759642 and perplexity is 46.79638180968214
At time: 629.6286056041718 and batch: 1700, loss is 3.8636896800994873 and perplexity is 47.64080681940614
At time: 630.5309946537018 and batch: 1750, loss is 3.8506858253479006 and perplexity is 47.025303319790154
At time: 631.4357073307037 and batch: 1800, loss is 3.828627519607544 and perplexity is 45.9993616678777
At time: 632.3402762413025 and batch: 1850, loss is 3.8482058334350584 and perplexity is 46.9088254396569
At time: 633.24374127388 and batch: 1900, loss is 3.925090847015381 and perplexity is 50.65767994883095
At time: 634.1563587188721 and batch: 1950, loss is 3.861247057914734 and perplexity is 47.52458033425288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348215786246366 and perplexity of 77.34034803598153
finished 17 epochs...
Completing Train Step...
At time: 637.1250813007355 and batch: 50, loss is 3.9560299348831176 and perplexity is 52.24947980358534
At time: 638.009104013443 and batch: 100, loss is 3.94558735370636 and perplexity is 51.706699316338366
At time: 638.8945941925049 and batch: 150, loss is 3.9065443086624145 and perplexity is 49.72681419613457
At time: 639.7788434028625 and batch: 200, loss is 3.8900036334991457 and perplexity is 48.91106424171915
At time: 640.6648921966553 and batch: 250, loss is 3.8872971296310426 and perplexity is 48.77886523641377
At time: 641.5586371421814 and batch: 300, loss is 3.914205904006958 and perplexity is 50.10926414182317
At time: 642.4581446647644 and batch: 350, loss is 3.9137551975250244 and perplexity is 50.08668466041106
At time: 643.3563704490662 and batch: 400, loss is 3.8644126224517823 and perplexity is 47.67526082898415
At time: 644.2552361488342 and batch: 450, loss is 3.9070607376098634 and perplexity is 49.75250119463377
At time: 645.1537125110626 and batch: 500, loss is 3.9284650754928587 and perplexity is 50.8288992391697
At time: 646.0531706809998 and batch: 550, loss is 3.892797727584839 and perplexity is 49.04791745838958
At time: 646.951655626297 and batch: 600, loss is 3.900429730415344 and perplexity is 49.423683402688205
At time: 647.850494146347 and batch: 650, loss is 3.939811224937439 and perplexity is 51.40889566696923
At time: 648.7902038097382 and batch: 700, loss is 3.955123600959778 and perplexity is 52.20214578101786
At time: 649.691132068634 and batch: 750, loss is 3.909563202857971 and perplexity is 49.87716101325666
At time: 650.5958847999573 and batch: 800, loss is 3.8979800271987917 and perplexity is 49.302758222357504
At time: 651.5087978839874 and batch: 850, loss is 3.912274913787842 and perplexity is 50.01259700456355
At time: 652.416684627533 and batch: 900, loss is 3.876698808670044 and perplexity is 48.26462104253997
At time: 653.3234062194824 and batch: 950, loss is 3.9730530071258543 and perplexity is 53.14654017187383
At time: 654.2307267189026 and batch: 1000, loss is 3.9358057308197023 and perplexity is 51.20338948942988
At time: 655.1372785568237 and batch: 1050, loss is 3.892599096298218 and perplexity is 49.038175974952466
At time: 656.0440535545349 and batch: 1100, loss is 3.9201642799377443 and perplexity is 50.40872524013419
At time: 656.9509975910187 and batch: 1150, loss is 3.8732770252227784 and perplexity is 48.09975219478046
At time: 657.8652498722076 and batch: 1200, loss is 3.946773204803467 and perplexity is 51.7680521329131
At time: 658.7762954235077 and batch: 1250, loss is 3.9378669834136963 and perplexity is 51.30904145912705
At time: 659.6886172294617 and batch: 1300, loss is 3.927414436340332 and perplexity is 50.775524451279935
At time: 660.5995986461639 and batch: 1350, loss is 3.8385387325286864 and perplexity is 46.457537926200374
At time: 661.5110557079315 and batch: 1400, loss is 3.8462999868392944 and perplexity is 46.8195095526059
At time: 662.4232852458954 and batch: 1450, loss is 3.7660557651519775 and perplexity is 43.20930066080289
At time: 663.3354063034058 and batch: 1500, loss is 3.8100232601165773 and perplexity is 45.1514890830043
At time: 664.2476117610931 and batch: 1550, loss is 3.805119261741638 and perplexity is 44.9306082960922
At time: 665.1598527431488 and batch: 1600, loss is 3.89397093296051 and perplexity is 49.10549450706461
At time: 666.0721826553345 and batch: 1650, loss is 3.843820767402649 and perplexity is 46.70357748440892
At time: 666.9840359687805 and batch: 1700, loss is 3.861922569274902 and perplexity is 47.5566945737015
At time: 667.8964519500732 and batch: 1750, loss is 3.8491743183135987 and perplexity is 46.954277934239414
At time: 668.808079957962 and batch: 1800, loss is 3.8275834131240845 and perplexity is 45.95135850069522
At time: 669.7209434509277 and batch: 1850, loss is 3.84701997756958 and perplexity is 46.85323130369764
At time: 670.633266210556 and batch: 1900, loss is 3.9238979911804197 and perplexity is 50.59728866592641
At time: 671.545330286026 and batch: 1950, loss is 3.8598790073394778 and perplexity is 47.45960875712273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348118697765262 and perplexity of 77.33283954356259
finished 18 epochs...
Completing Train Step...
At time: 674.4779591560364 and batch: 50, loss is 3.949921145439148 and perplexity is 51.931271655750884
At time: 675.3785376548767 and batch: 100, loss is 3.9395082283020018 and perplexity is 51.39332130415951
At time: 676.2533626556396 and batch: 150, loss is 3.9002041530609133 and perplexity is 49.41253579631105
At time: 677.1276407241821 and batch: 200, loss is 3.883595781326294 and perplexity is 48.59865138911629
At time: 678.0091071128845 and batch: 250, loss is 3.8808460521697996 and perplexity is 48.465201819595904
At time: 678.8911962509155 and batch: 300, loss is 3.907946000099182 and perplexity is 49.79656471870599
At time: 679.7773292064667 and batch: 350, loss is 3.9078315782546995 and perplexity is 49.79086722988679
At time: 680.6652581691742 and batch: 400, loss is 3.858412652015686 and perplexity is 47.390067106002505
At time: 681.5602841377258 and batch: 450, loss is 3.9013754987716673 and perplexity is 49.47044886966693
At time: 682.4579524993896 and batch: 500, loss is 3.9229265880584716 and perplexity is 50.54816216643479
At time: 683.3550806045532 and batch: 550, loss is 3.8872655391693116 and perplexity is 48.7773243138776
At time: 684.2525889873505 and batch: 600, loss is 3.8952135753631594 and perplexity is 49.166553005824944
At time: 685.1495594978333 and batch: 650, loss is 3.9346959590911865 and perplexity is 51.14659693458499
At time: 686.0465502738953 and batch: 700, loss is 3.95008740901947 and perplexity is 51.93990665272992
At time: 686.9418432712555 and batch: 750, loss is 3.9048086071014403 and perplexity is 49.64057814878306
At time: 687.8383545875549 and batch: 800, loss is 3.8930618715286256 and perplexity is 49.06087487997844
At time: 688.7346258163452 and batch: 850, loss is 3.9076296710968017 and perplexity is 49.78081511222654
At time: 689.6297364234924 and batch: 900, loss is 3.8722037076950073 and perplexity is 48.04815358346883
At time: 690.5257737636566 and batch: 950, loss is 3.9685913038253786 and perplexity is 52.909944281002424
At time: 691.4226195812225 and batch: 1000, loss is 3.931415843963623 and perplexity is 50.97910505475341
At time: 692.3195922374725 and batch: 1050, loss is 3.888714609146118 and perplexity is 48.848057306240484
At time: 693.2172563076019 and batch: 1100, loss is 3.91637978553772 and perplexity is 50.21831423370609
At time: 694.1403760910034 and batch: 1150, loss is 3.8694231939315795 and perplexity is 47.91474059540164
At time: 695.0372993946075 and batch: 1200, loss is 3.943064317703247 and perplexity is 51.57640588898271
At time: 695.9334604740143 and batch: 1250, loss is 3.934445939064026 and perplexity is 51.13381085948426
At time: 696.829482793808 and batch: 1300, loss is 3.92412784576416 and perplexity is 50.60892002136008
At time: 697.7297811508179 and batch: 1350, loss is 3.8353873443603517 and perplexity is 46.311362639359736
At time: 698.6312608718872 and batch: 1400, loss is 3.8433689737319945 and perplexity is 46.68248186949602
At time: 699.5330047607422 and batch: 1450, loss is 3.7633409786224363 and perplexity is 43.09215571712275
At time: 700.4348323345184 and batch: 1500, loss is 3.8073528957366944 and perplexity is 45.03107899581442
At time: 701.3423731327057 and batch: 1550, loss is 3.802601237297058 and perplexity is 44.817614246684776
At time: 702.2595806121826 and batch: 1600, loss is 3.891740655899048 and perplexity is 48.99609768702913
At time: 703.1700150966644 and batch: 1650, loss is 3.8416007375717163 and perplexity is 46.60000915411031
At time: 704.0803587436676 and batch: 1700, loss is 3.8598452758789064 and perplexity is 47.45800790220094
At time: 704.9910690784454 and batch: 1750, loss is 3.8473432636260987 and perplexity is 46.86838074875121
At time: 705.9022459983826 and batch: 1800, loss is 3.826187171936035 and perplexity is 45.88724409131516
At time: 706.8134558200836 and batch: 1850, loss is 3.8454463481903076 and perplexity is 46.77955966353581
At time: 707.7243402004242 and batch: 1900, loss is 3.922301812171936 and perplexity is 50.51659075715909
At time: 708.6411411762238 and batch: 1950, loss is 3.8581193828582765 and perplexity is 47.37617109868753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348120401071948 and perplexity of 77.33297126521741
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 711.6222977638245 and batch: 50, loss is 3.9524452543258666 and perplexity is 52.062517409640705
At time: 712.5065569877625 and batch: 100, loss is 3.9561797761917115 and perplexity is 52.257309520605325
At time: 713.3912014961243 and batch: 150, loss is 3.9233384323120117 and perplexity is 50.5689844240193
At time: 714.2834300994873 and batch: 200, loss is 3.9008129358291628 and perplexity is 49.442626455047275
At time: 715.1681935787201 and batch: 250, loss is 3.89746470451355 and perplexity is 49.27735793783405
At time: 716.0548918247223 and batch: 300, loss is 3.922198076248169 and perplexity is 50.51135064375004
At time: 716.9428930282593 and batch: 350, loss is 3.9207159233093263 and perplexity is 50.436540550643265
At time: 717.8767175674438 and batch: 400, loss is 3.8731038570404053 and perplexity is 48.091423569267576
At time: 718.7753138542175 and batch: 450, loss is 3.915010747909546 and perplexity is 50.149610511617794
At time: 719.6791071891785 and batch: 500, loss is 3.934618377685547 and perplexity is 51.14262906361961
At time: 720.5830597877502 and batch: 550, loss is 3.8989910316467284 and perplexity is 49.35262873562338
At time: 721.4867024421692 and batch: 600, loss is 3.905420756340027 and perplexity is 49.670974893622734
At time: 722.3959467411041 and batch: 650, loss is 3.9436988639831543 and perplexity is 51.60914389126084
At time: 723.3020105361938 and batch: 700, loss is 3.959857692718506 and perplexity is 52.44986142078976
At time: 724.2045295238495 and batch: 750, loss is 3.911768569946289 and perplexity is 49.98727984420526
At time: 725.1074938774109 and batch: 800, loss is 3.896129722595215 and perplexity is 49.21161744695046
At time: 726.0182294845581 and batch: 850, loss is 3.91186824798584 and perplexity is 49.99226272660046
At time: 726.9220240116119 and batch: 900, loss is 3.8720084476470946 and perplexity is 48.03877261459203
At time: 727.8255980014801 and batch: 950, loss is 3.9692726230621336 and perplexity is 52.94600512693578
At time: 728.7288966178894 and batch: 1000, loss is 3.9282602643966675 and perplexity is 50.81848998260035
At time: 729.631952047348 and batch: 1050, loss is 3.8870489597320557 and perplexity is 48.76676129233477
At time: 730.5357973575592 and batch: 1100, loss is 3.9148811292648316 and perplexity is 50.14311060833375
At time: 731.4385485649109 and batch: 1150, loss is 3.8715526485443115 and perplexity is 48.01688157447271
At time: 732.3460826873779 and batch: 1200, loss is 3.938073515892029 and perplexity is 51.31963953700644
At time: 733.2536716461182 and batch: 1250, loss is 3.9296686935424803 and perplexity is 50.89011465233425
At time: 734.1590757369995 and batch: 1300, loss is 3.918341007232666 and perplexity is 50.316900123858154
At time: 735.0623300075531 and batch: 1350, loss is 3.8298793029785156 and perplexity is 46.05697895854835
At time: 735.969868183136 and batch: 1400, loss is 3.837798824310303 and perplexity is 46.4231763258658
At time: 736.8745756149292 and batch: 1450, loss is 3.7527818298339843 and perplexity is 42.639533093549815
At time: 737.7771239280701 and batch: 1500, loss is 3.7944699239730837 and perplexity is 44.45466580634734
At time: 738.6805474758148 and batch: 1550, loss is 3.791828136444092 and perplexity is 44.33738101357735
At time: 739.5842685699463 and batch: 1600, loss is 3.881246976852417 and perplexity is 48.48463661093687
At time: 740.4876494407654 and batch: 1650, loss is 3.8288613510131837 and perplexity is 46.0101190209295
At time: 741.3905837535858 and batch: 1700, loss is 3.8442030143737793 and perplexity is 46.72143319787207
At time: 742.2939512729645 and batch: 1750, loss is 3.8311333990097047 and perplexity is 46.11477506642865
At time: 743.1966509819031 and batch: 1800, loss is 3.8155041694641114 and perplexity is 45.399639725952625
At time: 744.1018364429474 and batch: 1850, loss is 3.8336310529708864 and perplexity is 46.23009777520127
At time: 745.0081670284271 and batch: 1900, loss is 3.906900644302368 and perplexity is 49.74453678970234
At time: 745.9184308052063 and batch: 1950, loss is 3.8441045093536377 and perplexity is 46.71683112882104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337854287790698 and perplexity of 76.54312349221806
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
1550.9062628746033


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.273787021636963 and batch: 50, loss is 7.387720565795899 and perplexity is 1616.0183040748732
At time: 2.1029226779937744 and batch: 100, loss is 6.639540700912476 and perplexity is 764.7436662760772
At time: 2.92588472366333 and batch: 150, loss is 6.289970321655273 and perplexity is 539.1373281437237
At time: 3.750643253326416 and batch: 200, loss is 6.094788951873779 and perplexity is 443.5404269224898
At time: 4.576412916183472 and batch: 250, loss is 5.979424695968628 and perplexity is 395.21293514519374
At time: 5.403001546859741 and batch: 300, loss is 5.892456178665161 and perplexity is 362.2940513596803
At time: 6.230506658554077 and batch: 350, loss is 5.80037823677063 and perplexity is 330.42451497834054
At time: 7.056862831115723 and batch: 400, loss is 5.722420797348023 and perplexity is 305.6439301181921
At time: 7.883836984634399 and batch: 450, loss is 5.62559139251709 and perplexity is 277.4363097742699
At time: 8.736257791519165 and batch: 500, loss is 5.585604877471924 and perplexity is 266.5614710136718
At time: 9.563507795333862 and batch: 550, loss is 5.526988182067871 and perplexity is 251.38564192823546
At time: 10.390900611877441 and batch: 600, loss is 5.538888235092163 and perplexity is 254.3950147313509
At time: 11.217800617218018 and batch: 650, loss is 5.59566782951355 and perplexity is 269.25740810560717
At time: 12.04526424407959 and batch: 700, loss is 5.540611581802368 and perplexity is 254.83380352709725
At time: 12.873432159423828 and batch: 750, loss is 5.482699928283691 and perplexity is 240.49515126533746
At time: 13.70519232749939 and batch: 800, loss is 5.460552377700806 and perplexity is 235.22732281317485
At time: 14.534084558486938 and batch: 850, loss is 5.465606660842895 and perplexity is 236.41923790624378
At time: 15.373286008834839 and batch: 900, loss is 5.4710030841827395 and perplexity is 237.6985048281062
At time: 16.208003520965576 and batch: 950, loss is 5.493527173995972 and perplexity is 243.11319890732238
At time: 17.036996603012085 and batch: 1000, loss is 5.467387561798096 and perplexity is 236.84065229011802
At time: 17.866806030273438 and batch: 1050, loss is 5.35459044456482 and perplexity is 211.57730597032148
At time: 18.69675040245056 and batch: 1100, loss is 5.441809597015381 and perplexity is 230.85956848349738
At time: 19.534955739974976 and batch: 1150, loss is 5.341355228424073 and perplexity is 208.79548420920798
At time: 20.402970790863037 and batch: 1200, loss is 5.416115198135376 and perplexity is 225.00332910909367
At time: 21.31074285507202 and batch: 1250, loss is 5.36460163116455 and perplexity is 213.70608387759017
At time: 22.233104705810547 and batch: 1300, loss is 5.384923868179321 and perplexity is 218.09349962020846
At time: 23.158490419387817 and batch: 1350, loss is 5.327513542175293 and perplexity is 205.92531246011993
At time: 24.083627700805664 and batch: 1400, loss is 5.333096628189087 and perplexity is 207.07822660665093
At time: 25.0084707736969 and batch: 1450, loss is 5.285129022598267 and perplexity is 197.37964824041603
At time: 25.934349060058594 and batch: 1500, loss is 5.261610898971558 and perplexity is 192.79180941208014
At time: 26.859517335891724 and batch: 1550, loss is 5.246637468338013 and perplexity is 189.92655947083938
At time: 27.784770488739014 and batch: 1600, loss is 5.2847181224823 and perplexity is 197.29856158046437
At time: 28.70992612838745 and batch: 1650, loss is 5.263855037689209 and perplexity is 193.22494680444484
At time: 29.63489031791687 and batch: 1700, loss is 5.283397645950317 and perplexity is 197.03820539505088
At time: 30.56041693687439 and batch: 1750, loss is 5.291143341064453 and perplexity is 198.57032928205572
At time: 31.484684467315674 and batch: 1800, loss is 5.259874639511108 and perplexity is 192.45736323577836
At time: 32.410492181777954 and batch: 1850, loss is 5.239971885681152 and perplexity is 188.664798148813
At time: 33.3479642868042 and batch: 1900, loss is 5.292954778671264 and perplexity is 198.93035302594296
At time: 34.273587226867676 and batch: 1950, loss is 5.223257455825806 and perplexity is 185.53758124223623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.831408407521803 and perplexity of 125.38743295685128
finished 1 epochs...
Completing Train Step...
At time: 37.253602743148804 and batch: 50, loss is 5.045967283248902 and perplexity is 155.3945370580307
At time: 38.20901393890381 and batch: 100, loss is 4.993642301559448 and perplexity is 147.47258610033464
At time: 39.124876260757446 and batch: 150, loss is 4.936317348480225 and perplexity is 139.25647105229447
At time: 40.04267501831055 and batch: 200, loss is 4.900280628204346 and perplexity is 134.3274704729722
At time: 40.96826648712158 and batch: 250, loss is 4.906080465316773 and perplexity is 135.108811556712
At time: 41.88810420036316 and batch: 300, loss is 4.9174915599823 and perplexity is 136.65938101765215
At time: 42.8122341632843 and batch: 350, loss is 4.9233690452575685 and perplexity is 137.4649595863518
At time: 43.73472332954407 and batch: 400, loss is 4.870360984802246 and perplexity is 130.36796925895612
At time: 44.65115261077881 and batch: 450, loss is 4.848448476791382 and perplexity is 127.54235133690328
At time: 45.567891359329224 and batch: 500, loss is 4.833217554092407 and perplexity is 125.61448252222534
At time: 46.48423433303833 and batch: 550, loss is 4.797426996231079 and perplexity is 121.19817263239482
At time: 47.40491199493408 and batch: 600, loss is 4.784740829467774 and perplexity is 119.67034403766522
At time: 48.32614302635193 and batch: 650, loss is 4.86666576385498 and perplexity is 129.88711977778843
At time: 49.242918968200684 and batch: 700, loss is 4.867780914306641 and perplexity is 130.03204424934992
At time: 50.16283869743347 and batch: 750, loss is 4.8209210300445555 and perplexity is 124.07931894862094
At time: 51.07896614074707 and batch: 800, loss is 4.795698862075806 and perplexity is 120.98890680250634
At time: 51.99657201766968 and batch: 850, loss is 4.7894775009155275 and perplexity is 120.23852772682368
At time: 52.91355609893799 and batch: 900, loss is 4.797983779907226 and perplexity is 121.26567258618785
At time: 53.830183267593384 and batch: 950, loss is 4.850815935134888 and perplexity is 127.84466025140728
At time: 54.7464816570282 and batch: 1000, loss is 4.824724397659302 and perplexity is 124.55213679204033
At time: 55.662829875946045 and batch: 1050, loss is 4.7366143989562985 and perplexity is 114.04742822726062
At time: 56.57910346984863 and batch: 1100, loss is 4.814376621246338 and perplexity is 123.26994448942482
At time: 57.496055364608765 and batch: 1150, loss is 4.743364515304566 and perplexity is 114.81986572556043
At time: 58.41217517852783 and batch: 1200, loss is 4.8182188987731935 and perplexity is 123.74449291643462
At time: 59.32842564582825 and batch: 1250, loss is 4.785161714553833 and perplexity is 119.72072210165852
At time: 60.24481225013733 and batch: 1300, loss is 4.801564035415649 and perplexity is 121.70061281242067
At time: 61.16760778427124 and batch: 1350, loss is 4.699096603393555 and perplexity is 109.84789140147626
At time: 62.08585286140442 and batch: 1400, loss is 4.707529973983765 and perplexity is 110.77819666902215
At time: 63.00248837471008 and batch: 1450, loss is 4.643629159927368 and perplexity is 103.92080928690847
At time: 63.91914987564087 and batch: 1500, loss is 4.648835744857788 and perplexity is 104.46329282431059
At time: 64.83623313903809 and batch: 1550, loss is 4.640687627792358 and perplexity is 103.61557203957231
At time: 65.75457715988159 and batch: 1600, loss is 4.707609052658081 and perplexity is 110.78695720833925
At time: 66.68016719818115 and batch: 1650, loss is 4.678094263076782 and perplexity is 107.5648867420889
At time: 67.59705352783203 and batch: 1700, loss is 4.700847120285034 and perplexity is 110.04035039307962
At time: 68.51387286186218 and batch: 1750, loss is 4.6956648254394535 and perplexity is 109.47156393494886
At time: 69.42996096611023 and batch: 1800, loss is 4.658791399002075 and perplexity is 105.50848740345273
At time: 70.34696912765503 and batch: 1850, loss is 4.679552707672119 and perplexity is 107.72187862395914
At time: 71.26310634613037 and batch: 1900, loss is 4.7606479358673095 and perplexity is 116.82159428322495
At time: 72.17960953712463 and batch: 1950, loss is 4.689098472595215 and perplexity is 108.75508990473286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.604958893531977 and perplexity of 99.97887298645647
finished 2 epochs...
Completing Train Step...
At time: 75.17162299156189 and batch: 50, loss is 4.646465129852295 and perplexity is 104.21594387522119
At time: 76.07754755020142 and batch: 100, loss is 4.60812668800354 and perplexity is 100.2960876777801
At time: 76.9899091720581 and batch: 150, loss is 4.582132711410522 and perplexity is 97.72258619607211
At time: 77.90410089492798 and batch: 200, loss is 4.563842029571533 and perplexity is 95.95142075347383
At time: 78.82156467437744 and batch: 250, loss is 4.555598516464233 and perplexity is 95.16369523250931
At time: 79.7374415397644 and batch: 300, loss is 4.580788612365723 and perplexity is 97.59132559469641
At time: 80.65951299667358 and batch: 350, loss is 4.59142240524292 and perplexity is 98.63462884183781
At time: 81.5778386592865 and batch: 400, loss is 4.547942619323731 and perplexity is 94.43791357017791
At time: 82.49428939819336 and batch: 450, loss is 4.552012147903443 and perplexity is 94.82301441643693
At time: 83.41046857833862 and batch: 500, loss is 4.551526021957398 and perplexity is 94.77692969124476
At time: 84.3585696220398 and batch: 550, loss is 4.517204990386963 and perplexity is 91.57927497848084
At time: 85.28083658218384 and batch: 600, loss is 4.50623776435852 and perplexity is 90.58039187080203
At time: 86.19850492477417 and batch: 650, loss is 4.586206035614014 and perplexity is 98.12145377864164
At time: 87.12525200843811 and batch: 700, loss is 4.5985699653625485 and perplexity is 99.34215129887724
At time: 88.0421667098999 and batch: 750, loss is 4.560444974899292 and perplexity is 95.62602154367309
At time: 88.95862078666687 and batch: 800, loss is 4.534402885437012 and perplexity is 93.16786680174174
At time: 89.87506484985352 and batch: 850, loss is 4.531961879730225 and perplexity is 92.94072085225658
At time: 90.79214978218079 and batch: 900, loss is 4.530064735412598 and perplexity is 92.7645660402
At time: 91.70965313911438 and batch: 950, loss is 4.596769113540649 and perplexity is 99.16341179470545
At time: 92.63423585891724 and batch: 1000, loss is 4.570382404327392 and perplexity is 96.58103571807668
At time: 93.55115127563477 and batch: 1050, loss is 4.495627746582032 and perplexity is 89.62441274865283
At time: 94.46766376495361 and batch: 1100, loss is 4.560559978485108 and perplexity is 95.63701951143861
At time: 95.3835825920105 and batch: 1150, loss is 4.505258846282959 and perplexity is 90.4917644744659
At time: 96.3005805015564 and batch: 1200, loss is 4.579448232650757 and perplexity is 97.46060378951205
At time: 97.21824359893799 and batch: 1250, loss is 4.563339500427246 and perplexity is 95.90321448165224
At time: 98.14748454093933 and batch: 1300, loss is 4.567202014923096 and perplexity is 96.27435835064813
At time: 99.06523418426514 and batch: 1350, loss is 4.461902484893799 and perplexity is 86.65220689374702
At time: 99.98190450668335 and batch: 1400, loss is 4.467355833053589 and perplexity is 87.12604236737444
At time: 100.89897465705872 and batch: 1450, loss is 4.404638652801514 and perplexity is 81.8295686148348
At time: 101.81598567962646 and batch: 1500, loss is 4.416343746185302 and perplexity is 82.79301899525707
At time: 102.73258304595947 and batch: 1550, loss is 4.415289936065673 and perplexity is 82.70581682933765
At time: 103.64915180206299 and batch: 1600, loss is 4.493981351852417 and perplexity is 89.47697698989023
At time: 104.5651113986969 and batch: 1650, loss is 4.4607012081146244 and perplexity is 86.54817610713573
At time: 105.4816210269928 and batch: 1700, loss is 4.483224487304687 and perplexity is 88.51964345294319
At time: 106.39898085594177 and batch: 1750, loss is 4.478977565765381 and perplexity is 88.14450462893132
At time: 107.31609654426575 and batch: 1800, loss is 4.44359335899353 and perplexity is 85.08011644579955
At time: 108.23334646224976 and batch: 1850, loss is 4.476761350631714 and perplexity is 87.9493737496941
At time: 109.15696907043457 and batch: 1900, loss is 4.554857187271118 and perplexity is 95.09317375015526
At time: 110.07620477676392 and batch: 1950, loss is 4.492477006912232 and perplexity is 89.34247394714393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.533527604923692 and perplexity of 93.08635446174799
finished 3 epochs...
Completing Train Step...
At time: 113.06097054481506 and batch: 50, loss is 4.455553197860718 and perplexity is 86.1037700939064
At time: 113.97506046295166 and batch: 100, loss is 4.426065292358398 and perplexity is 83.60182018139793
At time: 114.86387991905212 and batch: 150, loss is 4.4034788608551025 and perplexity is 81.73471835409335
At time: 115.76042294502258 and batch: 200, loss is 4.38986741065979 and perplexity is 80.62972762932542
At time: 116.65795183181763 and batch: 250, loss is 4.374890832901001 and perplexity is 79.43116780877564
At time: 117.55506467819214 and batch: 300, loss is 4.401019525527954 and perplexity is 81.5339522505677
At time: 118.45151448249817 and batch: 350, loss is 4.414539480209351 and perplexity is 82.64377304821741
At time: 119.36325597763062 and batch: 400, loss is 4.370051412582398 and perplexity is 79.04769564126019
At time: 120.27433395385742 and batch: 450, loss is 4.394052772521973 and perplexity is 80.96789940828336
At time: 121.18505692481995 and batch: 500, loss is 4.396060905456543 and perplexity is 81.1306570785524
At time: 122.09610176086426 and batch: 550, loss is 4.360347003936767 and perplexity is 78.28429466889277
At time: 123.0071542263031 and batch: 600, loss is 4.3520541000366215 and perplexity is 77.63777500425086
At time: 123.91897749900818 and batch: 650, loss is 4.429895811080932 and perplexity is 83.92267264220096
At time: 124.83978390693665 and batch: 700, loss is 4.441449232101441 and perplexity is 84.8978893090107
At time: 125.75495100021362 and batch: 750, loss is 4.407744579315185 and perplexity is 82.08412034645043
At time: 126.66703176498413 and batch: 800, loss is 4.382505073547363 and perplexity is 80.03828426748913
At time: 127.57841610908508 and batch: 850, loss is 4.381745233535766 and perplexity is 79.9774910761177
At time: 128.48996686935425 and batch: 900, loss is 4.375579681396484 and perplexity is 79.48590269907422
At time: 129.401184797287 and batch: 950, loss is 4.449319944381714 and perplexity is 85.56873271355562
At time: 130.3404734134674 and batch: 1000, loss is 4.420334444046021 and perplexity is 83.12408106402336
At time: 131.25106549263 and batch: 1050, loss is 4.354335880279541 and perplexity is 77.81512961052802
At time: 132.16236901283264 and batch: 1100, loss is 4.408667469024659 and perplexity is 82.15990990375127
At time: 133.0732262134552 and batch: 1150, loss is 4.36276614189148 and perplexity is 78.47390443100025
At time: 133.9840111732483 and batch: 1200, loss is 4.436756916046143 and perplexity is 84.5004547534384
At time: 134.89569234848022 and batch: 1250, loss is 4.4255866527557375 and perplexity is 83.56181461429271
At time: 135.8070604801178 and batch: 1300, loss is 4.426241664886475 and perplexity is 83.61656654616371
At time: 136.7214391231537 and batch: 1350, loss is 4.322717833518982 and perplexity is 75.39325641286513
At time: 137.636652469635 and batch: 1400, loss is 4.3325146484375 and perplexity is 76.13550006734691
At time: 138.5505895614624 and batch: 1450, loss is 4.259784011840821 and perplexity is 70.79469098785404
At time: 139.46427488327026 and batch: 1500, loss is 4.278912596702575 and perplexity is 72.16192820938431
At time: 140.3786916732788 and batch: 1550, loss is 4.282290964126587 and perplexity is 72.40612998630112
At time: 141.2994909286499 and batch: 1600, loss is 4.367328662872314 and perplexity is 78.83276128987386
At time: 142.21249222755432 and batch: 1650, loss is 4.331088709831238 and perplexity is 76.02701288490692
At time: 143.12481498718262 and batch: 1700, loss is 4.348961477279663 and perplexity is 77.39804154811794
At time: 144.03753781318665 and batch: 1750, loss is 4.348440341949463 and perplexity is 77.35771720231214
At time: 144.94986820220947 and batch: 1800, loss is 4.313459978103638 and perplexity is 74.69849749668627
At time: 145.86216473579407 and batch: 1850, loss is 4.34636981010437 and perplexity is 77.19771129121176
At time: 146.7737262248993 and batch: 1900, loss is 4.4217509937286374 and perplexity is 83.2419138929969
At time: 147.68534088134766 and batch: 1950, loss is 4.364383134841919 and perplexity is 78.60089882811042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504412132085756 and perplexity of 90.4151762415032
finished 4 epochs...
Completing Train Step...
At time: 150.65577244758606 and batch: 50, loss is 4.332837419509888 and perplexity is 76.16007837071973
At time: 151.56960701942444 and batch: 100, loss is 4.305813007354736 and perplexity is 74.12945875557706
At time: 152.46546959877014 and batch: 150, loss is 4.286866226196289 and perplexity is 72.73816600312854
At time: 153.3798632621765 and batch: 200, loss is 4.2753002738952635 and perplexity is 71.90172627992126
At time: 154.27065205574036 and batch: 250, loss is 4.258565645217896 and perplexity is 70.70848962237069
At time: 155.1621778011322 and batch: 300, loss is 4.286260528564453 and perplexity is 72.69412200825458
At time: 156.0603849887848 and batch: 350, loss is 4.299237012863159 and perplexity is 73.64358315170459
At time: 156.9603714942932 and batch: 400, loss is 4.256898341178894 and perplexity is 70.59069529879535
At time: 157.86025261878967 and batch: 450, loss is 4.286368198394776 and perplexity is 72.70194939341572
At time: 158.76057410240173 and batch: 500, loss is 4.2904072189331055 and perplexity is 72.99618787782374
At time: 159.6604506969452 and batch: 550, loss is 4.251218996047974 and perplexity is 70.19092267506753
At time: 160.56038355827332 and batch: 600, loss is 4.248703360557556 and perplexity is 70.01456981164495
At time: 161.46392464637756 and batch: 650, loss is 4.32060845375061 and perplexity is 75.23439101574922
At time: 162.3705382347107 and batch: 700, loss is 4.332321491241455 and perplexity is 76.1207953678394
At time: 163.27732229232788 and batch: 750, loss is 4.302749547958374 and perplexity is 73.90271365813418
At time: 164.18454432487488 and batch: 800, loss is 4.2794062566757205 and perplexity is 72.1975604593104
At time: 165.09511184692383 and batch: 850, loss is 4.281320095062256 and perplexity is 72.33586722811768
At time: 166.0076084136963 and batch: 900, loss is 4.269148373603821 and perplexity is 71.46075183522653
At time: 166.91415667533875 and batch: 950, loss is 4.346172180175781 and perplexity is 77.18245622052093
At time: 167.82084679603577 and batch: 1000, loss is 4.315904407501221 and perplexity is 74.8813160524165
At time: 168.72697043418884 and batch: 1050, loss is 4.254969854354858 and perplexity is 70.45469325423758
At time: 169.6333818435669 and batch: 1100, loss is 4.306265149116516 and perplexity is 74.16298335802391
At time: 170.5407087802887 and batch: 1150, loss is 4.259559597969055 and perplexity is 70.77880545968212
At time: 171.4467430114746 and batch: 1200, loss is 4.331866745948791 and perplexity is 76.08618766391369
At time: 172.3529601097107 and batch: 1250, loss is 4.326034708023071 and perplexity is 75.6437415671062
At time: 173.25894737243652 and batch: 1300, loss is 4.326548099517822 and perplexity is 75.68258639110583
At time: 174.16534972190857 and batch: 1350, loss is 4.225606112480164 and perplexity is 68.41595875047241
At time: 175.07592010498047 and batch: 1400, loss is 4.237636246681213 and perplexity is 69.24398254821047
At time: 175.98997473716736 and batch: 1450, loss is 4.162157316207885 and perplexity is 64.20989433623475
At time: 176.90989637374878 and batch: 1500, loss is 4.182136845588684 and perplexity is 65.5056792892618
At time: 177.8255650997162 and batch: 1550, loss is 4.185885272026062 and perplexity is 65.75168328520513
At time: 178.74016642570496 and batch: 1600, loss is 4.275918917655945 and perplexity is 71.94622159622236
At time: 179.65787196159363 and batch: 1650, loss is 4.235485854148865 and perplexity is 69.09524078913022
At time: 180.58107471466064 and batch: 1700, loss is 4.254049019813538 and perplexity is 70.38984600046875
At time: 181.49847435951233 and batch: 1750, loss is 4.256367349624634 and perplexity is 70.55322218561616
At time: 182.4131565093994 and batch: 1800, loss is 4.22158218383789 and perplexity is 68.14121096792985
At time: 183.32741856575012 and batch: 1850, loss is 4.250489196777344 and perplexity is 70.13971607843561
At time: 184.24121618270874 and batch: 1900, loss is 4.325212545394898 and perplexity is 75.58157566847557
At time: 185.16450548171997 and batch: 1950, loss is 4.270655546188355 and perplexity is 71.56853672607559
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496094601653343 and perplexity of 89.66626412876228
finished 5 epochs...
Completing Train Step...
At time: 188.18487787246704 and batch: 50, loss is 4.243113918304443 and perplexity is 69.624319074798
At time: 189.06949734687805 and batch: 100, loss is 4.217032585144043 and perplexity is 67.83189995752906
At time: 189.95364904403687 and batch: 150, loss is 4.200765399932862 and perplexity is 66.73739229287325
At time: 190.84403491020203 and batch: 200, loss is 4.187981224060058 and perplexity is 65.88964018454344
At time: 191.74264907836914 and batch: 250, loss is 4.169773511886596 and perplexity is 64.70079648647179
At time: 192.6450960636139 and batch: 300, loss is 4.19566056728363 and perplexity is 66.39757716140645
At time: 193.54304933547974 and batch: 350, loss is 4.214239587783814 and perplexity is 67.64270996656764
At time: 194.43977308273315 and batch: 400, loss is 4.168459095954895 and perplexity is 64.61580859573105
At time: 195.3371090888977 and batch: 450, loss is 4.203493947982788 and perplexity is 66.91973712966622
At time: 196.24250984191895 and batch: 500, loss is 4.211674981117248 and perplexity is 67.46945528166377
At time: 197.14008140563965 and batch: 550, loss is 4.174015626907349 and perplexity is 64.97584769405684
At time: 198.03714990615845 and batch: 600, loss is 4.170623564720154 and perplexity is 64.75581896455203
At time: 198.96116089820862 and batch: 650, loss is 4.235514907836914 and perplexity is 69.0972482898643
At time: 199.86750888824463 and batch: 700, loss is 4.255145936012268 and perplexity is 70.46710012567732
At time: 200.76885652542114 and batch: 750, loss is 4.225758490562439 and perplexity is 68.42638463738194
At time: 201.67365837097168 and batch: 800, loss is 4.198961591720581 and perplexity is 66.61711934386697
At time: 202.57348346710205 and batch: 850, loss is 4.207863783836364 and perplexity is 67.21280525974262
At time: 203.47358798980713 and batch: 900, loss is 4.191645474433899 and perplexity is 66.13151920523087
At time: 204.3725655078888 and batch: 950, loss is 4.268571615219116 and perplexity is 71.41954813086144
At time: 205.28079199790955 and batch: 1000, loss is 4.239963397979737 and perplexity is 69.4053114176483
At time: 206.1843719482422 and batch: 1050, loss is 4.1837036991119385 and perplexity is 65.608397544865
At time: 207.0906708240509 and batch: 1100, loss is 4.2265680170059206 and perplexity is 68.48180003226526
At time: 208.00748682022095 and batch: 1150, loss is 4.18234531879425 and perplexity is 65.51933689177865
At time: 208.9268856048584 and batch: 1200, loss is 4.252744040489197 and perplexity is 70.2980486166659
At time: 209.83540439605713 and batch: 1250, loss is 4.2503602504730225 and perplexity is 70.13067240434786
At time: 210.74969744682312 and batch: 1300, loss is 4.24987687587738 and perplexity is 70.09678121066318
At time: 211.66078972816467 and batch: 1350, loss is 4.148865513801574 and perplexity is 63.36207610648977
At time: 212.57397961616516 and batch: 1400, loss is 4.165954012870788 and perplexity is 64.45414320381475
At time: 213.49500679969788 and batch: 1450, loss is 4.0809788274765015 and perplexity is 59.20339140386161
At time: 214.41382908821106 and batch: 1500, loss is 4.106956534385681 and perplexity is 60.76151030931723
At time: 215.32509922981262 and batch: 1550, loss is 4.110299816131592 and perplexity is 60.964993118232414
At time: 216.23720288276672 and batch: 1600, loss is 4.2036576843261715 and perplexity is 66.93069521981832
At time: 217.14925384521484 and batch: 1650, loss is 4.161086773872375 and perplexity is 64.14119170708716
At time: 218.06095433235168 and batch: 1700, loss is 4.183037514686585 and perplexity is 65.56470480757464
At time: 218.97286009788513 and batch: 1750, loss is 4.180977435111999 and perplexity is 65.42977532883766
At time: 219.885098695755 and batch: 1800, loss is 4.148936915397644 and perplexity is 63.366600421373775
At time: 220.79676842689514 and batch: 1850, loss is 4.178774886131286 and perplexity is 65.28582163460604
At time: 221.70875144004822 and batch: 1900, loss is 4.251150426864624 and perplexity is 70.18610990582683
At time: 222.62007594108582 and batch: 1950, loss is 4.195901203155517 and perplexity is 66.41355672282863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491385242550872 and perplexity of 89.24498624461575
finished 6 epochs...
Completing Train Step...
At time: 225.58116674423218 and batch: 50, loss is 4.174437446594238 and perplexity is 65.00326156723573
At time: 226.49308896064758 and batch: 100, loss is 4.1488551425933835 and perplexity is 63.36141896861473
At time: 227.37726211547852 and batch: 150, loss is 4.134154181480408 and perplexity is 62.43675856356253
At time: 228.2670738697052 and batch: 200, loss is 4.12062394618988 and perplexity is 61.59766390436276
At time: 229.15635752677917 and batch: 250, loss is 4.098207035064697 and perplexity is 60.23219650823704
At time: 230.04841375350952 and batch: 300, loss is 4.128045139312744 and perplexity is 62.05649248607591
At time: 230.9482707977295 and batch: 350, loss is 4.145619902610779 and perplexity is 63.15676081025052
At time: 231.84836220741272 and batch: 400, loss is 4.102160086631775 and perplexity is 60.47076872048825
At time: 232.7485179901123 and batch: 450, loss is 4.136257882118225 and perplexity is 62.56824506800581
At time: 233.6485149860382 and batch: 500, loss is 4.15101996421814 and perplexity is 63.498733715913815
At time: 234.5483157634735 and batch: 550, loss is 4.107606158256531 and perplexity is 60.80099526063794
At time: 235.44832801818848 and batch: 600, loss is 4.108301448822021 and perplexity is 60.84328431890305
At time: 236.34837436676025 and batch: 650, loss is 4.169057731628418 and perplexity is 64.65450150415212
At time: 237.2501254081726 and batch: 700, loss is 4.192267861366272 and perplexity is 66.17269140979418
At time: 238.15036058425903 and batch: 750, loss is 4.166885495185852 and perplexity is 64.51420906914429
At time: 239.05039262771606 and batch: 800, loss is 4.137223410606384 and perplexity is 62.62868566493671
At time: 239.95032787322998 and batch: 850, loss is 4.146599726676941 and perplexity is 63.21867365132577
At time: 240.85473203659058 and batch: 900, loss is 4.128577175140381 and perplexity is 62.089517547895056
At time: 241.76320505142212 and batch: 950, loss is 4.208639230728149 and perplexity is 67.26494543402474
At time: 242.67173957824707 and batch: 1000, loss is 4.178298892974854 and perplexity is 65.25475342501007
At time: 243.57640099525452 and batch: 1050, loss is 4.121617374420166 and perplexity is 61.65888716802912
At time: 244.52567791938782 and batch: 1100, loss is 4.160197577476501 and perplexity is 64.0841829403454
At time: 245.4305136203766 and batch: 1150, loss is 4.121595911979675 and perplexity is 61.65756383203362
At time: 246.33951878547668 and batch: 1200, loss is 4.19011513710022 and perplexity is 66.03039307074359
At time: 247.24408388137817 and batch: 1250, loss is 4.1915682554244995 and perplexity is 66.12641279198641
At time: 248.14713191986084 and batch: 1300, loss is 4.190532760620117 and perplexity is 66.05797467488044
At time: 249.05240082740784 and batch: 1350, loss is 4.087789106369018 and perplexity is 59.60795905632749
At time: 249.96341466903687 and batch: 1400, loss is 4.109887657165527 and perplexity is 60.939871027205804
At time: 250.86791610717773 and batch: 1450, loss is 4.022643957138062 and perplexity is 55.84857202439187
At time: 251.77378726005554 and batch: 1500, loss is 4.050113763809204 and perplexity is 57.4039871702372
At time: 252.68542885780334 and batch: 1550, loss is 4.050603294372559 and perplexity is 57.432095055688656
At time: 253.59791660308838 and batch: 1600, loss is 4.144029383659363 and perplexity is 63.0563886283602
At time: 254.51024198532104 and batch: 1650, loss is 4.104653396606445 and perplexity is 60.6217292087556
At time: 255.4231617450714 and batch: 1700, loss is 4.127077045440674 and perplexity is 61.996445046446915
At time: 256.3351345062256 and batch: 1750, loss is 4.123953237533569 and perplexity is 61.80308223258086
At time: 257.2477991580963 and batch: 1800, loss is 4.09206184387207 and perplexity is 59.863193104210026
At time: 258.16020131111145 and batch: 1850, loss is 4.120485367774964 and perplexity is 61.58912838916907
At time: 259.0721309185028 and batch: 1900, loss is 4.191446423530579 and perplexity is 66.11835697661535
At time: 259.9857668876648 and batch: 1950, loss is 4.135933089256286 and perplexity is 62.54792664844113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4934942201126455 and perplexity of 89.43340052901995
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 262.94218707084656 and batch: 50, loss is 4.146396980285645 and perplexity is 63.205857592629165
At time: 263.8569793701172 and batch: 100, loss is 4.135059180259705 and perplexity is 62.49328933012483
At time: 264.7454032897949 and batch: 150, loss is 4.1112445449829105 and perplexity is 61.022615720733434
At time: 265.63363003730774 and batch: 200, loss is 4.097169299125671 and perplexity is 60.16972381392038
At time: 266.5228681564331 and batch: 250, loss is 4.079034147262573 and perplexity is 59.08837161460354
At time: 267.44772934913635 and batch: 300, loss is 4.093474602699279 and perplexity is 59.947825126935186
At time: 268.34771275520325 and batch: 350, loss is 4.104140954017639 and perplexity is 60.590672011096984
At time: 269.24725103378296 and batch: 400, loss is 4.053867678642273 and perplexity is 57.61988182068823
At time: 270.14724111557007 and batch: 450, loss is 4.081590347290039 and perplexity is 59.23960652273647
At time: 271.0475871562958 and batch: 500, loss is 4.099713888168335 and perplexity is 60.32302599664614
At time: 271.9471414089203 and batch: 550, loss is 4.052590608596802 and perplexity is 57.54634416195643
At time: 272.8476059436798 and batch: 600, loss is 4.0362097263336185 and perplexity is 56.61136308812703
At time: 273.74844789505005 and batch: 650, loss is 4.094217472076416 and perplexity is 59.99237507579553
At time: 274.654825925827 and batch: 700, loss is 4.1062663507461545 and perplexity is 60.71958817763769
At time: 275.5619978904724 and batch: 750, loss is 4.06612979888916 and perplexity is 58.33077335147699
At time: 276.470094203949 and batch: 800, loss is 4.044611887931824 and perplexity is 57.089024794417675
At time: 277.38483238220215 and batch: 850, loss is 4.049127473831176 and perplexity is 57.34739810419406
At time: 278.2943775653839 and batch: 900, loss is 4.02746473312378 and perplexity is 56.11845548041415
At time: 279.2043671607971 and batch: 950, loss is 4.105883221626282 and perplexity is 60.6963291911422
At time: 280.11243414878845 and batch: 1000, loss is 4.063426218032837 and perplexity is 58.17328437732568
At time: 281.029470205307 and batch: 1050, loss is 4.003804841041565 and perplexity is 54.80628302055833
At time: 281.93660044670105 and batch: 1100, loss is 4.027567963600159 and perplexity is 56.124248914331396
At time: 282.84554409980774 and batch: 1150, loss is 3.9890079641342164 and perplexity is 54.00129156422235
At time: 283.7591392993927 and batch: 1200, loss is 4.044231581687927 and perplexity is 57.06731760978094
At time: 284.6668107509613 and batch: 1250, loss is 4.0406817436218265 and perplexity is 56.865097010943586
At time: 285.57332611083984 and batch: 1300, loss is 4.038121700286865 and perplexity is 56.71970608129451
At time: 286.47972226142883 and batch: 1350, loss is 3.9288673496246336 and perplexity is 50.84935050371176
At time: 287.3858952522278 and batch: 1400, loss is 3.9470338821411133 and perplexity is 51.78154864995989
At time: 288.30005073547363 and batch: 1450, loss is 3.857196555137634 and perplexity is 47.33247122153006
At time: 289.2056493759155 and batch: 1500, loss is 3.8774086618423462 and perplexity is 48.29889399984157
At time: 290.12284564971924 and batch: 1550, loss is 3.872893838882446 and perplexity is 48.08132455760096
At time: 291.0279779434204 and batch: 1600, loss is 3.95874436378479 and perplexity is 52.39149996627682
At time: 291.9339783191681 and batch: 1650, loss is 3.914794616699219 and perplexity is 50.138772786827964
At time: 292.8415286540985 and batch: 1700, loss is 3.920581941604614 and perplexity is 50.42978342963591
At time: 293.7538764476776 and batch: 1750, loss is 3.913374457359314 and perplexity is 50.06761827769276
At time: 294.67002296447754 and batch: 1800, loss is 3.876118836402893 and perplexity is 48.236637016614644
At time: 295.5870749950409 and batch: 1850, loss is 3.894036431312561 and perplexity is 49.10871094136589
At time: 296.4987561702728 and batch: 1900, loss is 3.9604634189605714 and perplexity is 52.481641302227416
At time: 297.40989422798157 and batch: 1950, loss is 3.904190630912781 and perplexity is 49.609910930277195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378043525163517 and perplexity of 79.68198500389504
finished 8 epochs...
Completing Train Step...
At time: 300.4009311199188 and batch: 50, loss is 4.050006303787232 and perplexity is 57.39781886794347
At time: 301.28449726104736 and batch: 100, loss is 4.034726061820984 and perplexity is 56.5274330950734
At time: 302.16892647743225 and batch: 150, loss is 4.009434943199158 and perplexity is 55.11571825144852
At time: 303.0653803348541 and batch: 200, loss is 3.9980261373519896 and perplexity is 54.4904870750449
At time: 303.9543161392212 and batch: 250, loss is 3.9802448081970216 and perplexity is 53.53013723994733
At time: 304.85024976730347 and batch: 300, loss is 4.0009393310546875 and perplexity is 54.64945986568568
At time: 305.7517349720001 and batch: 350, loss is 4.015884442329407 and perplexity is 55.47233579448554
At time: 306.65696382522583 and batch: 400, loss is 3.9703952264785767 and perplexity is 53.00547586796121
At time: 307.5562038421631 and batch: 450, loss is 4.003578071594238 and perplexity is 54.79385603913084
At time: 308.455589056015 and batch: 500, loss is 4.02291356086731 and perplexity is 55.86363103757468
At time: 309.3553569316864 and batch: 550, loss is 3.97987509727478 and perplexity is 53.51035022150443
At time: 310.26144313812256 and batch: 600, loss is 3.9669133043289184 and perplexity is 52.82123586829165
At time: 311.159907579422 and batch: 650, loss is 4.0244433784484865 and perplexity is 55.94915760582809
At time: 312.0591380596161 and batch: 700, loss is 4.042750172615051 and perplexity is 56.98284015599169
At time: 312.9833104610443 and batch: 750, loss is 4.007256164550781 and perplexity is 54.99576402563796
At time: 313.88010025024414 and batch: 800, loss is 3.985513963699341 and perplexity is 53.81294026938278
At time: 314.7821021080017 and batch: 850, loss is 3.99239248752594 and perplexity is 54.18436984029526
At time: 315.6847825050354 and batch: 900, loss is 3.9682319164276123 and perplexity is 52.89093253030775
At time: 316.58943223953247 and batch: 950, loss is 4.052358040809631 and perplexity is 57.532962292191165
At time: 317.49287581443787 and batch: 1000, loss is 4.012637076377868 and perplexity is 55.292488992211446
At time: 318.39667105674744 and batch: 1050, loss is 3.9593082571029665 and perplexity is 52.4210515142142
At time: 319.2996277809143 and batch: 1100, loss is 3.9824015855789185 and perplexity is 53.6457144215194
At time: 320.2044687271118 and batch: 1150, loss is 3.9473878955841064 and perplexity is 51.7998832594386
At time: 321.1168863773346 and batch: 1200, loss is 4.003884682655334 and perplexity is 54.81065901733039
At time: 322.02022528648376 and batch: 1250, loss is 4.005709915161133 and perplexity is 54.910792569540924
At time: 322.92352318763733 and batch: 1300, loss is 4.0040112972259525 and perplexity is 54.81759928474739
At time: 323.8288064002991 and batch: 1350, loss is 3.8964840269088743 and perplexity is 49.229056424464126
At time: 324.732373714447 and batch: 1400, loss is 3.918010015487671 and perplexity is 50.30024840122681
At time: 325.6349227428436 and batch: 1450, loss is 3.8315651082992552 and perplexity is 46.13468754110124
At time: 326.53958916664124 and batch: 1500, loss is 3.853043627738953 and perplexity is 47.13631050747757
At time: 327.4455361366272 and batch: 1550, loss is 3.851736316680908 and perplexity is 47.07472894941218
At time: 328.35530138015747 and batch: 1600, loss is 3.9407432079315186 and perplexity is 51.45683021709839
At time: 329.2606043815613 and batch: 1650, loss is 3.900039668083191 and perplexity is 49.40440884486043
At time: 330.165159702301 and batch: 1700, loss is 3.9087579822540284 and perplexity is 49.837015060885776
At time: 331.0697720050812 and batch: 1750, loss is 3.905473093986511 and perplexity is 49.673574623578524
At time: 331.97372674942017 and batch: 1800, loss is 3.8707352352142332 and perplexity is 47.97764797262406
At time: 332.8778393268585 and batch: 1850, loss is 3.891773853302002 and perplexity is 48.997724257226025
At time: 333.79194140434265 and batch: 1900, loss is 3.9602363967895506 and perplexity is 52.4697281584053
At time: 334.69344115257263 and batch: 1950, loss is 3.905778980255127 and perplexity is 49.688771412094916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374665300236192 and perplexity of 79.41325550581142
finished 9 epochs...
Completing Train Step...
At time: 337.63700795173645 and batch: 50, loss is 4.012041039466858 and perplexity is 55.25954244752421
At time: 338.5480194091797 and batch: 100, loss is 3.9951921272277833 and perplexity is 54.336279099694536
At time: 339.43104362487793 and batch: 150, loss is 3.969546413421631 and perplexity is 52.96050321734156
At time: 340.32160449028015 and batch: 200, loss is 3.958319163322449 and perplexity is 52.36922781166918
At time: 341.2122120857239 and batch: 250, loss is 3.9410310792922973 and perplexity is 51.47164529715067
At time: 342.1092758178711 and batch: 300, loss is 3.96273745059967 and perplexity is 52.60112201499265
At time: 343.0083079338074 and batch: 350, loss is 3.9770940256118776 and perplexity is 53.36174084527714
At time: 343.9083981513977 and batch: 400, loss is 3.932158637046814 and perplexity is 51.01698604850371
At time: 344.80774569511414 and batch: 450, loss is 3.96756950378418 and perplexity is 52.85590850933458
At time: 345.71525406837463 and batch: 500, loss is 3.9877414226531984 and perplexity is 53.93293998262146
At time: 346.6134569644928 and batch: 550, loss is 3.9459056186676027 and perplexity is 51.723158366022744
At time: 347.5109694004059 and batch: 600, loss is 3.93463791847229 and perplexity is 51.14362844059191
At time: 348.42136549949646 and batch: 650, loss is 3.992154574394226 and perplexity is 54.1714802005447
At time: 349.324481010437 and batch: 700, loss is 4.011027674674988 and perplexity is 55.20357273645
At time: 350.2277321815491 and batch: 750, loss is 3.9774737310409547 and perplexity is 53.38200643521487
At time: 351.13075852394104 and batch: 800, loss is 3.9550688219070436 and perplexity is 52.1992862752425
At time: 352.03420972824097 and batch: 850, loss is 3.9644821739196776 and perplexity is 52.69297652628382
At time: 352.93804144859314 and batch: 900, loss is 3.9389648723602293 and perplexity is 51.365404022858655
At time: 353.8425829410553 and batch: 950, loss is 4.0253446006774904 and perplexity is 55.999602958178635
At time: 354.74658036231995 and batch: 1000, loss is 3.9873601770401 and perplexity is 53.91238220488189
At time: 355.6500828266144 and batch: 1050, loss is 3.935211281776428 and perplexity is 51.17296072860543
At time: 356.55398869514465 and batch: 1100, loss is 3.957997212409973 and perplexity is 52.352370204796124
At time: 357.45734214782715 and batch: 1150, loss is 3.923483862876892 and perplexity is 50.576339234783696
At time: 358.3607292175293 and batch: 1200, loss is 3.9802672719955443 and perplexity is 53.53133974367152
At time: 359.30885195732117 and batch: 1250, loss is 3.9850504970550538 and perplexity is 53.78800554518971
At time: 360.2122082710266 and batch: 1300, loss is 3.983807826042175 and perplexity is 53.721206263219976
At time: 361.11701941490173 and batch: 1350, loss is 3.87717866897583 and perplexity is 48.287786876089555
At time: 362.020822763443 and batch: 1400, loss is 3.8998807954788206 and perplexity is 49.39656046122295
At time: 362.9239706993103 and batch: 1450, loss is 3.815326328277588 and perplexity is 45.39156651805175
At time: 363.83652091026306 and batch: 1500, loss is 3.8371752595901487 and perplexity is 46.394237494466346
At time: 364.7504732608795 and batch: 1550, loss is 3.836305947303772 and perplexity is 46.35392393886869
At time: 365.652795791626 and batch: 1600, loss is 3.9262493515014647 and perplexity is 50.716401106100705
At time: 366.5665156841278 and batch: 1650, loss is 3.8872858810424806 and perplexity is 48.77831654611421
At time: 367.4701843261719 and batch: 1700, loss is 3.8968294525146483 and perplexity is 49.2460643384166
At time: 368.37273049354553 and batch: 1750, loss is 3.89450514793396 and perplexity is 49.13173440575829
At time: 369.27708768844604 and batch: 1800, loss is 3.8615350341796875 and perplexity is 47.53826825619475
At time: 370.1820864677429 and batch: 1850, loss is 3.883922553062439 and perplexity is 48.61453464976402
At time: 371.08673620224 and batch: 1900, loss is 3.9530666732788085 and perplexity is 52.09488009904977
At time: 371.990207195282 and batch: 1950, loss is 3.8984642887115477 and perplexity is 49.326639432546095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3744592001271805 and perplexity of 79.39689011170742
finished 10 epochs...
Completing Train Step...
At time: 374.9291741847992 and batch: 50, loss is 3.98392183303833 and perplexity is 53.72733120571237
At time: 375.85711693763733 and batch: 100, loss is 3.966980776786804 and perplexity is 52.824799967142155
At time: 376.7430901527405 and batch: 150, loss is 3.940816378593445 and perplexity is 51.46059548517791
At time: 377.6283519268036 and batch: 200, loss is 3.9300492811203003 and perplexity is 50.909486483910165
At time: 378.51731610298157 and batch: 250, loss is 3.9133740615844728 and perplexity is 50.067598462193004
At time: 379.41268157958984 and batch: 300, loss is 3.9360635805130006 and perplexity is 51.216593970018046
At time: 380.31342911720276 and batch: 350, loss is 3.949102072715759 and perplexity is 51.88875358272074
At time: 381.2156181335449 and batch: 400, loss is 3.9046388626098634 and perplexity is 49.63215264919491
At time: 382.1619551181793 and batch: 450, loss is 3.941560583114624 and perplexity is 51.49890694701391
At time: 383.0613124370575 and batch: 500, loss is 3.9632033920288086 and perplexity is 52.62563676773454
At time: 383.96155428886414 and batch: 550, loss is 3.9214372777938844 and perplexity is 50.47293630089568
At time: 384.8612060546875 and batch: 600, loss is 3.9111387014389036 and perplexity is 49.95580434461512
At time: 385.76126170158386 and batch: 650, loss is 3.969116096496582 and perplexity is 52.93771831916328
At time: 386.6623556613922 and batch: 700, loss is 3.987549319267273 and perplexity is 53.922580277336984
At time: 387.5623691082001 and batch: 750, loss is 3.954919204711914 and perplexity is 52.19147694866157
At time: 388.4623956680298 and batch: 800, loss is 3.9325563955307006 and perplexity is 51.03728252380686
At time: 389.36239767074585 and batch: 850, loss is 3.9434694910049437 and perplexity is 51.597307505749
At time: 390.26236391067505 and batch: 900, loss is 3.9170197820663453 and perplexity is 50.25046406728266
At time: 391.1618185043335 and batch: 950, loss is 4.004593825340271 and perplexity is 54.849541380171225
At time: 392.0612099170685 and batch: 1000, loss is 3.9676654005050658 and perplexity is 52.8609774606841
At time: 392.96092081069946 and batch: 1050, loss is 3.9165926504135133 and perplexity is 50.22900508674119
At time: 393.8616840839386 and batch: 1100, loss is 3.939214143753052 and perplexity is 51.37820954462114
At time: 394.76358127593994 and batch: 1150, loss is 3.9047254705429078 and perplexity is 49.63645137349752
At time: 395.66991448402405 and batch: 1200, loss is 3.960981192588806 and perplexity is 52.50882194816378
At time: 396.5797538757324 and batch: 1250, loss is 3.9681992721557617 and perplexity is 52.88920597250907
At time: 397.48674988746643 and batch: 1300, loss is 3.9672340250015257 and perplexity is 52.838179447520105
At time: 398.39454317092896 and batch: 1350, loss is 3.8614966440200806 and perplexity is 47.53644328951956
At time: 399.3016972541809 and batch: 1400, loss is 3.8847305965423584 and perplexity is 48.6538331828405
At time: 400.2094130516052 and batch: 1450, loss is 3.8005532217025757 and perplexity is 44.725921000448764
At time: 401.12080216407776 and batch: 1500, loss is 3.8231925773620605 and perplexity is 45.750035943068376
At time: 402.0314826965332 and batch: 1550, loss is 3.8222061347961427 and perplexity is 45.704928411874
At time: 402.9354977607727 and batch: 1600, loss is 3.9129912137985228 and perplexity is 50.04843386177042
At time: 403.8480324745178 and batch: 1650, loss is 3.8750437021255495 and perplexity is 48.184804023441
At time: 404.75281405448914 and batch: 1700, loss is 3.8848546504974366 and perplexity is 48.659869257668284
At time: 405.66353487968445 and batch: 1750, loss is 3.8831989431381224 and perplexity is 48.57936941451643
At time: 406.567764043808 and batch: 1800, loss is 3.8507626247406006 and perplexity is 47.02891497321127
At time: 407.471745967865 and batch: 1850, loss is 3.8735420083999634 and perplexity is 48.11249950877614
At time: 408.375519990921 and batch: 1900, loss is 3.9435257005691526 and perplexity is 51.600207849431015
At time: 409.2805335521698 and batch: 1950, loss is 3.8885249090194702 and perplexity is 48.83879170245387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375360817132994 and perplexity of 79.46850797913284
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 412.27882528305054 and batch: 50, loss is 3.9825173950195314 and perplexity is 53.65192746145523
At time: 413.16578817367554 and batch: 100, loss is 3.9898657464981078 and perplexity is 54.0476327922561
At time: 414.0569853782654 and batch: 150, loss is 3.9624263143539427 and perplexity is 52.584758445149696
At time: 414.9487283229828 and batch: 200, loss is 3.9538579988479614 and perplexity is 52.13612042480418
At time: 415.83907866477966 and batch: 250, loss is 3.938111352920532 and perplexity is 51.32158135640648
At time: 416.7303020954132 and batch: 300, loss is 3.9547187519073486 and perplexity is 52.181016069224135
At time: 417.6216540336609 and batch: 350, loss is 3.9670023584365843 and perplexity is 52.82594002577688
At time: 418.52361249923706 and batch: 400, loss is 3.91887496471405 and perplexity is 50.3437743833368
At time: 419.4335730075836 and batch: 450, loss is 3.9528250551223754 and perplexity is 52.08229455067036
At time: 420.3525221347809 and batch: 500, loss is 3.9691023445129394 and perplexity is 52.93699032553257
At time: 421.25876116752625 and batch: 550, loss is 3.9300027179718016 and perplexity is 50.90711603311927
At time: 422.16273021698 and batch: 600, loss is 3.9148745489120484 and perplexity is 50.14278065006193
At time: 423.06862711906433 and batch: 650, loss is 3.9761285972595215 and perplexity is 53.31024876768928
At time: 423.97267985343933 and batch: 700, loss is 3.9857125806808473 and perplexity is 53.823629494640755
At time: 424.87643671035767 and batch: 750, loss is 3.9483449554443357 and perplexity is 51.84948257944398
At time: 425.7799594402313 and batch: 800, loss is 3.9249100065231324 and perplexity is 50.64851981733915
At time: 426.7231111526489 and batch: 850, loss is 3.9360651922225953 and perplexity is 51.21667651636047
At time: 427.6275734901428 and batch: 900, loss is 3.9076289892196656 and perplexity is 49.78078116783847
At time: 428.53054666519165 and batch: 950, loss is 3.9988895559310915 and perplexity is 54.537555490918095
At time: 429.43358421325684 and batch: 1000, loss is 3.957875428199768 and perplexity is 52.345994900951936
At time: 430.3372263908386 and batch: 1050, loss is 3.9021502923965454 and perplexity is 49.50879311058953
At time: 431.2488145828247 and batch: 1100, loss is 3.9166184711456298 and perplexity is 50.23030205317025
At time: 432.1525435447693 and batch: 1150, loss is 3.88394127368927 and perplexity is 48.615444752844574
At time: 433.05666303634644 and batch: 1200, loss is 3.9342088985443113 and perplexity is 51.121691510828235
At time: 433.9637243747711 and batch: 1250, loss is 3.936069564819336 and perplexity is 51.2169004667229
At time: 434.870409488678 and batch: 1300, loss is 3.935773663520813 and perplexity is 51.20174756136123
At time: 435.7736551761627 and batch: 1350, loss is 3.8299397325515745 and perplexity is 46.059762246218796
At time: 436.6761066913605 and batch: 1400, loss is 3.8477338695526124 and perplexity is 46.88669139192783
At time: 437.578232049942 and batch: 1450, loss is 3.758737587928772 and perplexity is 42.894241576085264
At time: 438.481609582901 and batch: 1500, loss is 3.782224488258362 and perplexity is 43.91361849488336
At time: 439.3902952671051 and batch: 1550, loss is 3.782244610786438 and perplexity is 43.91450215679516
At time: 440.30163955688477 and batch: 1600, loss is 3.8684057903289797 and perplexity is 47.86601675581008
At time: 441.2155101299286 and batch: 1650, loss is 3.825870680809021 and perplexity is 45.87272348366007
At time: 442.1193606853485 and batch: 1700, loss is 3.829856400489807 and perplexity is 46.0559241511867
At time: 443.0227081775665 and batch: 1750, loss is 3.8238417100906372 and perplexity is 45.779743429740364
At time: 443.93397760391235 and batch: 1800, loss is 3.790524206161499 and perplexity is 44.279605835411026
At time: 444.8437383174896 and batch: 1850, loss is 3.8156415605545044 and perplexity is 45.40587766046653
At time: 445.7507076263428 and batch: 1900, loss is 3.8840236902236938 and perplexity is 48.61945163443495
At time: 446.65566420555115 and batch: 1950, loss is 3.830370364189148 and perplexity is 46.07960130841846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3452497615370635 and perplexity of 77.11129450981099
finished 12 epochs...
Completing Train Step...
At time: 449.5946309566498 and batch: 50, loss is 3.9617542457580566 and perplexity is 52.54942975335836
At time: 450.4960386753082 and batch: 100, loss is 3.958397150039673 and perplexity is 52.37331207508685
At time: 451.37653708457947 and batch: 150, loss is 3.9308615732192993 and perplexity is 50.95085665760302
At time: 452.2572355270386 and batch: 200, loss is 3.919024877548218 and perplexity is 50.35132212697499
At time: 453.13839769363403 and batch: 250, loss is 3.9042398262023927 and perplexity is 49.61235156424638
At time: 454.0258448123932 and batch: 300, loss is 3.922968783378601 and perplexity is 50.55029510731911
At time: 454.9125940799713 and batch: 350, loss is 3.9378688383102416 and perplexity is 51.30913663217906
At time: 455.7986981868744 and batch: 400, loss is 3.8899315786361695 and perplexity is 48.907540088654905
At time: 456.6903784275055 and batch: 450, loss is 3.925957269668579 and perplexity is 50.701589929851316
At time: 457.5865354537964 and batch: 500, loss is 3.943007478713989 and perplexity is 51.57347442151404
At time: 458.48231768608093 and batch: 550, loss is 3.9060911321640015 and perplexity is 49.704284278000216
At time: 459.37669587135315 and batch: 600, loss is 3.891627321243286 and perplexity is 48.99054504582337
At time: 460.2730369567871 and batch: 650, loss is 3.9531412363052367 and perplexity is 52.09876459578949
At time: 461.16791248321533 and batch: 700, loss is 3.9662082147598268 and perplexity is 52.78400529284203
At time: 462.0616226196289 and batch: 750, loss is 3.929553303718567 and perplexity is 50.884242789748704
At time: 462.9567401409149 and batch: 800, loss is 3.906477270126343 and perplexity is 49.72348069504512
At time: 463.8610098361969 and batch: 850, loss is 3.9182318115234374 and perplexity is 50.31140603423392
At time: 464.7561137676239 and batch: 900, loss is 3.889583010673523 and perplexity is 48.890495457826844
At time: 465.6518986225128 and batch: 950, loss is 3.9824484729766847 and perplexity is 53.648229788438975
At time: 466.5503206253052 and batch: 1000, loss is 3.9420492696762084 and perplexity is 51.5240799211213
At time: 467.44500756263733 and batch: 1050, loss is 3.8885191679000854 and perplexity is 48.83851131392497
At time: 468.341361284256 and batch: 1100, loss is 3.9039710569381714 and perplexity is 49.59901908078131
At time: 469.237509727478 and batch: 1150, loss is 3.872245149612427 and perplexity is 48.0501448323421
At time: 470.13314938545227 and batch: 1200, loss is 3.923178586959839 and perplexity is 50.56090185289295
At time: 471.0294816493988 and batch: 1250, loss is 3.9274766349792483 and perplexity is 50.77868271800999
At time: 471.9245102405548 and batch: 1300, loss is 3.9274298095703126 and perplexity is 50.77630504109479
At time: 472.8203866481781 and batch: 1350, loss is 3.823227143287659 and perplexity is 45.75161736273836
At time: 473.71487379074097 and batch: 1400, loss is 3.8421653366088866 and perplexity is 46.62632690319963
At time: 474.6087076663971 and batch: 1450, loss is 3.7553030681610107 and perplexity is 42.747173154736565
At time: 475.50344133377075 and batch: 1500, loss is 3.7794110107421877 and perplexity is 43.79024215625524
At time: 476.39975094795227 and batch: 1550, loss is 3.78031494140625 and perplexity is 43.829843394617356
At time: 477.29512453079224 and batch: 1600, loss is 3.8677998304367067 and perplexity is 47.837020655577334
At time: 478.19097900390625 and batch: 1650, loss is 3.8261747264862063 and perplexity is 45.88667300747474
At time: 479.08743476867676 and batch: 1700, loss is 3.831649160385132 and perplexity is 46.138565420789995
At time: 479.9901044368744 and batch: 1750, loss is 3.8272128295898438 and perplexity is 45.93433283876871
At time: 480.8886067867279 and batch: 1800, loss is 3.7947798919677735 and perplexity is 44.468447465788266
At time: 481.7940151691437 and batch: 1850, loss is 3.8210395908355714 and perplexity is 45.65164268977814
At time: 482.6895241737366 and batch: 1900, loss is 3.8895179271697997 and perplexity is 48.88731359662815
At time: 483.5898244380951 and batch: 1950, loss is 3.835773220062256 and perplexity is 46.32923651725015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343431481649709 and perplexity of 76.97121198712712
finished 13 epochs...
Completing Train Step...
At time: 486.54758524894714 and batch: 50, loss is 3.9506434488296507 and perplexity is 51.96879533945152
At time: 487.44705748558044 and batch: 100, loss is 3.945992040634155 and perplexity is 51.727628576244435
At time: 488.32334446907043 and batch: 150, loss is 3.918087043762207 and perplexity is 50.304123091798346
At time: 489.2103383541107 and batch: 200, loss is 3.9055114078521727 and perplexity is 49.67547784670326
At time: 490.1071469783783 and batch: 250, loss is 3.890373315811157 and perplexity is 48.92914913965845
At time: 491.00411677360535 and batch: 300, loss is 3.9095734786987304 and perplexity is 49.877673545654105
At time: 491.90044713020325 and batch: 350, loss is 3.924765524864197 and perplexity is 50.6412025637905
At time: 492.7964413166046 and batch: 400, loss is 3.8769940900802613 and perplexity is 48.27887479223511
At time: 493.69147658348083 and batch: 450, loss is 3.9137600469589233 and perplexity is 50.08692755306648
At time: 494.5857455730438 and batch: 500, loss is 3.9308605289459226 and perplexity is 50.95080345100767
At time: 495.5092885494232 and batch: 550, loss is 3.894676365852356 and perplexity is 49.14014735925408
At time: 496.4163134098053 and batch: 600, loss is 3.880612807273865 and perplexity is 48.453898876869125
At time: 497.3162043094635 and batch: 650, loss is 3.942367391586304 and perplexity is 51.54047346727657
At time: 498.2130551338196 and batch: 700, loss is 3.956296057701111 and perplexity is 52.263386432742955
At time: 499.1100084781647 and batch: 750, loss is 3.9196385526657105 and perplexity is 50.3822309635191
At time: 500.0068485736847 and batch: 800, loss is 3.896985993385315 and perplexity is 49.253773963625015
At time: 500.90770840644836 and batch: 850, loss is 3.9093230628967284 and perplexity is 49.86518495176706
At time: 501.80719685554504 and batch: 900, loss is 3.880432810783386 and perplexity is 48.44517812999674
At time: 502.7074120044708 and batch: 950, loss is 3.9739589881896973 and perplexity is 53.19471174885165
At time: 503.6044194698334 and batch: 1000, loss is 3.9337388706207275 and perplexity is 51.097668534494424
At time: 504.5057566165924 and batch: 1050, loss is 3.8812256383895876 and perplexity is 48.48360203435891
At time: 505.41032457351685 and batch: 1100, loss is 3.8970727634429934 and perplexity is 49.25804790185498
At time: 506.3125123977661 and batch: 1150, loss is 3.865713562965393 and perplexity is 47.737323868701715
At time: 507.2134177684784 and batch: 1200, loss is 3.916768488883972 and perplexity is 50.237838054733345
At time: 508.1214089393616 and batch: 1250, loss is 3.9221539211273195 and perplexity is 50.50912035819773
At time: 509.02286529541016 and batch: 1300, loss is 3.922252264022827 and perplexity is 50.514087815596355
At time: 509.92542719841003 and batch: 1350, loss is 3.8188827896118163 and perplexity is 45.553287275624605
At time: 510.8275899887085 and batch: 1400, loss is 3.8380856943130492 and perplexity is 46.43649565295225
At time: 511.7300760746002 and batch: 1450, loss is 3.7523408937454223 and perplexity is 42.62073592908808
At time: 512.6329843997955 and batch: 1500, loss is 3.7766959142684935 and perplexity is 43.671508683550535
At time: 513.5367650985718 and batch: 1550, loss is 3.7779603004455566 and perplexity is 43.72676125839656
At time: 514.4476819038391 and batch: 1600, loss is 3.865920104980469 and perplexity is 47.747184650065655
At time: 515.3526675701141 and batch: 1650, loss is 3.8248217153549193 and perplexity is 45.824629810151094
At time: 516.2639434337616 and batch: 1700, loss is 3.8309013748168947 and perplexity is 46.10407656417092
At time: 517.1788203716278 and batch: 1750, loss is 3.827267436981201 and perplexity is 45.936841261347354
At time: 518.0867602825165 and batch: 1800, loss is 3.7951410245895385 and perplexity is 44.484509372872154
At time: 518.9900324344635 and batch: 1850, loss is 3.8219184350967406 and perplexity is 45.69178100905131
At time: 519.8940041065216 and batch: 1900, loss is 3.890406398773193 and perplexity is 48.93076788761823
At time: 520.8077850341797 and batch: 1950, loss is 3.8364254331588743 and perplexity is 46.35946290801551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3428248205850295 and perplexity of 76.92453071100135
finished 14 epochs...
Completing Train Step...
At time: 523.7683482170105 and batch: 50, loss is 3.941329951286316 and perplexity is 51.487031029483774
At time: 524.6469337940216 and batch: 100, loss is 3.9363149547576906 and perplexity is 51.2294701209414
At time: 525.534200668335 and batch: 150, loss is 3.908199782371521 and perplexity is 49.80920380777552
At time: 526.4128265380859 and batch: 200, loss is 3.8954406499862673 and perplexity is 49.17771874999885
At time: 527.2987635135651 and batch: 250, loss is 3.880125584602356 and perplexity is 48.43029678901636
At time: 528.1889662742615 and batch: 300, loss is 3.8994724798202514 and perplexity is 49.376395189285475
At time: 529.0896303653717 and batch: 350, loss is 3.91493136882782 and perplexity is 50.145629839579605
At time: 529.9814484119415 and batch: 400, loss is 3.867529067993164 and perplexity is 47.824069940335605
At time: 530.8722951412201 and batch: 450, loss is 3.904654016494751 and perplexity is 49.63290477482169
At time: 531.7635233402252 and batch: 500, loss is 3.9220467615127563 and perplexity is 50.503708110320595
At time: 532.6623673439026 and batch: 550, loss is 3.8862609100341796 and perplexity is 48.728345799478795
At time: 533.5626196861267 and batch: 600, loss is 3.87244601726532 and perplexity is 48.0597975215798
At time: 534.4625506401062 and batch: 650, loss is 3.934307546615601 and perplexity is 51.1267348158489
At time: 535.3624908924103 and batch: 700, loss is 3.948815679550171 and perplexity is 51.87389512610553
At time: 536.262416601181 and batch: 750, loss is 3.912078366279602 and perplexity is 50.002768119194805
At time: 537.1623721122742 and batch: 800, loss is 3.8897377347946165 and perplexity is 48.89806058200489
At time: 538.0616428852081 and batch: 850, loss is 3.902527918815613 and perplexity is 49.52749246930796
At time: 538.9576368331909 and batch: 900, loss is 3.873410367965698 and perplexity is 48.10616637530458
At time: 539.8571684360504 and batch: 950, loss is 3.9673767137527465 and perplexity is 52.84571939928261
At time: 540.8009362220764 and batch: 1000, loss is 3.9273919582366945 and perplexity is 50.77438312660652
At time: 541.7065994739532 and batch: 1050, loss is 3.8754704141616823 and perplexity is 48.20536944672127
At time: 542.6075508594513 and batch: 1100, loss is 3.8916231775283814 and perplexity is 48.990342043392275
At time: 543.5086035728455 and batch: 1150, loss is 3.8603542327880858 and perplexity is 47.482168130954804
At time: 544.4093315601349 and batch: 1200, loss is 3.911489839553833 and perplexity is 49.973348811667755
At time: 545.3212707042694 and batch: 1250, loss is 3.917677836418152 and perplexity is 50.283542486347564
At time: 546.2383768558502 and batch: 1300, loss is 3.917745680809021 and perplexity is 50.28695405838501
At time: 547.144877910614 and batch: 1350, loss is 3.81494704246521 and perplexity is 45.3743534054209
At time: 548.0513234138489 and batch: 1400, loss is 3.834289927482605 and perplexity is 46.260567645107656
At time: 548.95632147789 and batch: 1450, loss is 3.7492216348648073 and perplexity is 42.487997949729255
At time: 549.8622283935547 and batch: 1500, loss is 3.7737853956222533 and perplexity is 43.54458673716098
At time: 550.7689502239227 and batch: 1550, loss is 3.7751939344406127 and perplexity is 43.60596419402732
At time: 551.6762166023254 and batch: 1600, loss is 3.8634274339675905 and perplexity is 47.62831484015551
At time: 552.5922601222992 and batch: 1650, loss is 3.822603254318237 and perplexity is 45.723082335602456
At time: 553.5037608146667 and batch: 1700, loss is 3.8290901708602907 and perplexity is 46.020648253932045
At time: 554.4134330749512 and batch: 1750, loss is 3.825850257873535 and perplexity is 45.8717866375544
At time: 555.3204746246338 and batch: 1800, loss is 3.794084753990173 and perplexity is 44.43754650061141
At time: 556.2274208068848 and batch: 1850, loss is 3.8212470483779906 and perplexity is 45.661114449838024
At time: 557.1342628002167 and batch: 1900, loss is 3.88963321685791 and perplexity is 48.89295012467579
At time: 558.0397260189056 and batch: 1950, loss is 3.835544629096985 and perplexity is 46.31864728270217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3426698196765985 and perplexity of 76.91260826287953
finished 15 epochs...
Completing Train Step...
At time: 560.9846050739288 and batch: 50, loss is 3.9332065200805664 and perplexity is 51.07047390222994
At time: 561.8911488056183 and batch: 100, loss is 3.9280687761306763 and perplexity is 50.80875976971382
At time: 562.7722208499908 and batch: 150, loss is 3.8997852087020872 and perplexity is 49.39183902888359
At time: 563.678414106369 and batch: 200, loss is 3.886903085708618 and perplexity is 48.759648007489396
At time: 564.5597970485687 and batch: 250, loss is 3.8715975379943846 and perplexity is 48.01903707426005
At time: 565.440948009491 and batch: 300, loss is 3.89109375 and perplexity is 48.964412072315596
At time: 566.3246245384216 and batch: 350, loss is 3.9066903352737428 and perplexity is 49.734076164511194
At time: 567.2193467617035 and batch: 400, loss is 3.859676995277405 and perplexity is 47.4500223120139
At time: 568.1215991973877 and batch: 450, loss is 3.8971108531951906 and perplexity is 49.25992416442624
At time: 569.0204918384552 and batch: 500, loss is 3.914708080291748 and perplexity is 50.134434145283926
At time: 569.919417142868 and batch: 550, loss is 3.879234781265259 and perplexity is 48.387174128776536
At time: 570.8182985782623 and batch: 600, loss is 3.8655443525314332 and perplexity is 47.72924689878688
At time: 571.7243103981018 and batch: 650, loss is 3.9274886512756346 and perplexity is 50.77929289337765
At time: 572.6231660842896 and batch: 700, loss is 3.942344937324524 and perplexity is 51.53931617698618
At time: 573.5219464302063 and batch: 750, loss is 3.9055333232879637 and perplexity is 49.67656651837771
At time: 574.4208514690399 and batch: 800, loss is 3.8834009647369383 and perplexity is 48.589184487790035
At time: 575.319376707077 and batch: 850, loss is 3.8966829490661623 and perplexity is 49.23885014863141
At time: 576.2157535552979 and batch: 900, loss is 3.8672796058654786 and perplexity is 47.81214113404827
At time: 577.114440202713 and batch: 950, loss is 3.961681604385376 and perplexity is 52.545612629289735
At time: 578.0173449516296 and batch: 1000, loss is 3.9218975830078127 and perplexity is 50.49617460458312
At time: 578.9148898124695 and batch: 1050, loss is 3.8703929233551024 and perplexity is 47.96122746537735
At time: 579.8152875900269 and batch: 1100, loss is 3.8867484617233274 and perplexity is 48.752109179249956
At time: 580.7186985015869 and batch: 1150, loss is 3.855595154762268 and perplexity is 47.25673364362738
At time: 581.6212940216064 and batch: 1200, loss is 3.9065970468521116 and perplexity is 49.7294367674489
At time: 582.5259039402008 and batch: 1250, loss is 3.913437314033508 and perplexity is 50.070765460572204
At time: 583.4333999156952 and batch: 1300, loss is 3.913548402786255 and perplexity is 50.076328068422164
At time: 584.3364596366882 and batch: 1350, loss is 3.8110980224609374 and perplexity is 45.20004229016817
At time: 585.2385103702545 and batch: 1400, loss is 3.830621418952942 and perplexity is 46.091171264126146
At time: 586.140700340271 and batch: 1450, loss is 3.7460374355316164 and perplexity is 42.35292286211965
At time: 587.0427610874176 and batch: 1500, loss is 3.7707746124267576 and perplexity is 43.41368059105702
At time: 587.9466888904572 and batch: 1550, loss is 3.772325897216797 and perplexity is 43.48107983763431
At time: 588.8503391742706 and batch: 1600, loss is 3.8606889867782592 and perplexity is 47.498065636927045
At time: 589.7527079582214 and batch: 1650, loss is 3.8200749921798707 and perplexity is 45.60762840808029
At time: 590.6638841629028 and batch: 1700, loss is 3.826779990196228 and perplexity is 45.91445495227313
At time: 591.564573764801 and batch: 1750, loss is 3.823895354270935 and perplexity is 45.782199312422215
At time: 592.4648103713989 and batch: 1800, loss is 3.7923979711532594 and perplexity is 44.362653191990844
At time: 593.365526676178 and batch: 1850, loss is 3.8197134590148925 and perplexity is 45.59114271807617
At time: 594.265590429306 and batch: 1900, loss is 3.888067264556885 and perplexity is 48.8164460134523
At time: 595.1656749248505 and batch: 1950, loss is 3.833896961212158 and perplexity is 46.24239237373959
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342804380904797 and perplexity of 76.92295841426024
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 598.0679430961609 and batch: 50, loss is 3.934316802024841 and perplexity is 51.127208016892574
At time: 598.9731109142303 and batch: 100, loss is 3.944728593826294 and perplexity is 51.662314738010124
At time: 599.8531720638275 and batch: 150, loss is 3.920847678184509 and perplexity is 50.44318624854011
At time: 600.7415804862976 and batch: 200, loss is 3.909563455581665 and perplexity is 49.87717361839863
At time: 601.6223356723785 and batch: 250, loss is 3.897219958305359 and perplexity is 49.26529896708296
At time: 602.5051846504211 and batch: 300, loss is 3.9136042261123656 and perplexity is 50.079123573640814
At time: 603.3926734924316 and batch: 350, loss is 3.929744529724121 and perplexity is 50.89397411065418
At time: 604.2806925773621 and batch: 400, loss is 3.880819754600525 and perplexity is 48.463927319351846
At time: 605.1681399345398 and batch: 450, loss is 3.9190778303146363 and perplexity is 50.35398843936812
At time: 606.0558474063873 and batch: 500, loss is 3.934442548751831 and perplexity is 51.13363750019559
At time: 606.9525983333588 and batch: 550, loss is 3.8958291816711426 and perplexity is 49.19682956426114
At time: 607.8546845912933 and batch: 600, loss is 3.878499302864075 and perplexity is 48.35159949110291
At time: 608.782398223877 and batch: 650, loss is 3.9339443683624267 and perplexity is 51.108170068968214
At time: 609.6840193271637 and batch: 700, loss is 3.951384983062744 and perplexity is 52.0073462718999
At time: 610.5876755714417 and batch: 750, loss is 3.913382387161255 and perplexity is 50.06801530556353
At time: 611.4899246692657 and batch: 800, loss is 3.888192238807678 and perplexity is 48.82254719345649
At time: 612.3949029445648 and batch: 850, loss is 3.901291308403015 and perplexity is 49.466284109658005
At time: 613.299637556076 and batch: 900, loss is 3.870614891052246 and perplexity is 47.9718744901941
At time: 614.2045180797577 and batch: 950, loss is 3.968615007400513 and perplexity is 52.91119845070613
At time: 615.112958908081 and batch: 1000, loss is 3.9248539352416993 and perplexity is 50.645679969548
At time: 616.0167438983917 and batch: 1050, loss is 3.875514965057373 and perplexity is 48.20751708694652
At time: 616.9199209213257 and batch: 1100, loss is 3.887990856170654 and perplexity is 48.81271617008837
At time: 617.8222603797913 and batch: 1150, loss is 3.8613336849212647 and perplexity is 47.528697424706905
At time: 618.7263894081116 and batch: 1200, loss is 3.9111589002609253 and perplexity is 49.95681340320689
At time: 619.6309251785278 and batch: 1250, loss is 3.9115396404266356 and perplexity is 49.975837590026586
At time: 620.5353968143463 and batch: 1300, loss is 3.909369320869446 and perplexity is 49.867491667483705
At time: 621.4409499168396 and batch: 1350, loss is 3.8060769557952883 and perplexity is 44.973658683743984
At time: 622.3482632637024 and batch: 1400, loss is 3.8248203372955323 and perplexity is 45.82456666113334
At time: 623.2561364173889 and batch: 1450, loss is 3.7365713834762575 and perplexity is 41.953899457345194
At time: 624.1594836711884 and batch: 1500, loss is 3.760654993057251 and perplexity is 42.97656611438965
At time: 625.0643579959869 and batch: 1550, loss is 3.762860918045044 and perplexity is 43.07147383664304
At time: 625.9692227840424 and batch: 1600, loss is 3.8520281219482424 and perplexity is 47.0884676076869
At time: 626.8735890388489 and batch: 1650, loss is 3.809867014884949 and perplexity is 45.144434929237455
At time: 627.7786295413971 and batch: 1700, loss is 3.8143063020706176 and perplexity is 45.34528953650729
At time: 628.6836524009705 and batch: 1750, loss is 3.809500370025635 and perplexity is 45.12788598822148
At time: 629.5880720615387 and batch: 1800, loss is 3.7754883575439453 and perplexity is 43.61880468750535
At time: 630.4919853210449 and batch: 1850, loss is 3.802395248413086 and perplexity is 44.80838326711603
At time: 631.3986086845398 and batch: 1900, loss is 3.8735269498825073 and perplexity is 48.11177501131737
At time: 632.3025646209717 and batch: 1950, loss is 3.822839913368225 and perplexity is 45.73390439734944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331425440588663 and perplexity of 76.05261782928464
finished 17 epochs...
Completing Train Step...
At time: 635.2510261535645 and batch: 50, loss is 3.9356197929382324 and perplexity is 51.19386972473401
At time: 636.1214256286621 and batch: 100, loss is 3.936767382621765 and perplexity is 51.25265300458171
At time: 637.0068514347076 and batch: 150, loss is 3.908230586051941 and perplexity is 49.81073813820297
At time: 637.8922595977783 and batch: 200, loss is 3.8947080087661745 and perplexity is 49.14170232130363
At time: 638.7815089225769 and batch: 250, loss is 3.8811838722229 and perplexity is 48.481577102441854
At time: 639.6673722267151 and batch: 300, loss is 3.8985653924942016 and perplexity is 49.33162679449466
At time: 640.5714132785797 and batch: 350, loss is 3.9153641414642335 and perplexity is 50.16733619262892
At time: 641.4714045524597 and batch: 400, loss is 3.867403087615967 and perplexity is 47.818045425458706
At time: 642.3713274002075 and batch: 450, loss is 3.9073681020736695 and perplexity is 49.76779569585915
At time: 643.2703659534454 and batch: 500, loss is 3.9234684467315675 and perplexity is 50.57555954859795
At time: 644.1699304580688 and batch: 550, loss is 3.886512875556946 and perplexity is 48.74062520953071
At time: 645.0695102214813 and batch: 600, loss is 3.8698073196411134 and perplexity is 47.93314941455398
At time: 645.969396352768 and batch: 650, loss is 3.925740737915039 and perplexity is 50.69061261418814
At time: 646.8771269321442 and batch: 700, loss is 3.94403208732605 and perplexity is 51.626344128313356
At time: 647.7774887084961 and batch: 750, loss is 3.906821436882019 and perplexity is 49.74059680930666
At time: 648.6773746013641 and batch: 800, loss is 3.881602349281311 and perplexity is 48.501869775927815
At time: 649.5766360759735 and batch: 850, loss is 3.895096707344055 and perplexity is 49.16080734391756
At time: 650.476087808609 and batch: 900, loss is 3.864384455680847 and perplexity is 47.673917989744915
At time: 651.3813395500183 and batch: 950, loss is 3.9632233572006226 and perplexity is 52.626687458103
At time: 652.2840480804443 and batch: 1000, loss is 3.919826331138611 and perplexity is 50.39169255022409
At time: 653.1895709037781 and batch: 1050, loss is 3.8709413242340087 and perplexity is 47.98753665800561
At time: 654.11736369133 and batch: 1100, loss is 3.883598747253418 and perplexity is 48.59879552938838
At time: 655.007337808609 and batch: 1150, loss is 3.857193250656128 and perplexity is 47.332314812512685
At time: 655.9042654037476 and batch: 1200, loss is 3.9073594570159913 and perplexity is 49.76736545225459
At time: 656.808839559555 and batch: 1250, loss is 3.9088495111465456 and perplexity is 49.84157679644278
At time: 657.711400270462 and batch: 1300, loss is 3.9068949747085573 and perplexity is 49.74425475918393
At time: 658.6113014221191 and batch: 1350, loss is 3.8039730548858643 and perplexity is 44.87913802825117
At time: 659.5109386444092 and batch: 1400, loss is 3.8235334062576296 and perplexity is 45.765631534854286
At time: 660.4085166454315 and batch: 1450, loss is 3.736367359161377 and perplexity is 41.94534071487732
At time: 661.3062827587128 and batch: 1500, loss is 3.7610127258300783 and perplexity is 42.99194299079468
At time: 662.2053887844086 and batch: 1550, loss is 3.7638896179199217 and perplexity is 43.11580425382761
At time: 663.1046319007874 and batch: 1600, loss is 3.8533420753479004 and perplexity is 47.15038032609056
At time: 664.0030879974365 and batch: 1650, loss is 3.8116148948669433 and perplexity is 45.22341098357439
At time: 664.9136559963226 and batch: 1700, loss is 3.815967059135437 and perplexity is 45.420659614833085
At time: 665.8255620002747 and batch: 1750, loss is 3.8116493225097656 and perplexity is 45.224967945816054
At time: 666.7391374111176 and batch: 1800, loss is 3.7782304763793944 and perplexity is 43.73857677301522
At time: 667.6530923843384 and batch: 1850, loss is 3.805727653503418 and perplexity is 44.957952025037606
At time: 668.5663132667542 and batch: 1900, loss is 3.876966805458069 and perplexity is 48.27755753934699
At time: 669.4701888561249 and batch: 1950, loss is 3.8261219215393067 and perplexity is 45.8842500281164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33060416288154 and perplexity of 75.99018315130708
finished 18 epochs...
Completing Train Step...
At time: 672.4083864688873 and batch: 50, loss is 3.932933645248413 and perplexity is 51.05653995643391
At time: 673.318295955658 and batch: 100, loss is 3.9330913829803467 and perplexity is 51.0645941344542
At time: 674.2055804729462 and batch: 150, loss is 3.9040327787399294 and perplexity is 49.60208051608209
At time: 675.0959582328796 and batch: 200, loss is 3.89015296459198 and perplexity is 48.91836872977408
At time: 675.9870073795319 and batch: 250, loss is 3.87630774974823 and perplexity is 48.24575042187608
At time: 676.903532743454 and batch: 300, loss is 3.8936598014831545 and perplexity is 49.09021861854046
At time: 677.8004288673401 and batch: 350, loss is 3.9105398511886595 and perplexity is 49.925897254510176
At time: 678.7005054950714 and batch: 400, loss is 3.8625966453552247 and perplexity is 47.588762210772146
At time: 679.6006646156311 and batch: 450, loss is 3.9029232168197634 and perplexity is 49.54707445833725
At time: 680.5004425048828 and batch: 500, loss is 3.919024271965027 and perplexity is 50.35129163506989
At time: 681.4016280174255 and batch: 550, loss is 3.882458930015564 and perplexity is 48.54343334188667
At time: 682.3013801574707 and batch: 600, loss is 3.8660471296310424 and perplexity is 47.753250104734676
At time: 683.2014803886414 and batch: 650, loss is 3.9219580125808715 and perplexity is 50.49922615905672
At time: 684.1013789176941 and batch: 700, loss is 3.940727939605713 and perplexity is 51.45604456344755
At time: 685.0014986991882 and batch: 750, loss is 3.9036473989486695 and perplexity is 49.58296855956419
At time: 685.9017808437347 and batch: 800, loss is 3.8785417556762694 and perplexity is 48.35365219604665
At time: 686.8016204833984 and batch: 850, loss is 3.892030940055847 and perplexity is 49.01032254245784
At time: 687.7020740509033 and batch: 900, loss is 3.861367344856262 and perplexity is 47.53029726449784
At time: 688.6034867763519 and batch: 950, loss is 3.9605108642578126 and perplexity is 52.484131368369205
At time: 689.5035564899445 and batch: 1000, loss is 3.9171354150772095 and perplexity is 50.256275015702336
At time: 690.4044373035431 and batch: 1050, loss is 3.868603162765503 and perplexity is 47.87546512055656
At time: 691.3055891990662 and batch: 1100, loss is 3.8812844228744505 and perplexity is 48.48645220170079
At time: 692.2055678367615 and batch: 1150, loss is 3.855236625671387 and perplexity is 47.23979376677689
At time: 693.1064884662628 and batch: 1200, loss is 3.9054505157470705 and perplexity is 49.67245309437792
At time: 694.0075902938843 and batch: 1250, loss is 3.9073455333709717 and perplexity is 49.76667251394859
At time: 694.907698392868 and batch: 1300, loss is 3.9055636739730835 and perplexity is 49.67807425908631
At time: 695.8084943294525 and batch: 1350, loss is 3.802922601699829 and perplexity is 44.832019347040045
At time: 696.7085523605347 and batch: 1400, loss is 3.822671666145325 and perplexity is 45.726210442203644
At time: 697.6084592342377 and batch: 1450, loss is 3.7360025596618653 and perplexity is 41.93004186625351
At time: 698.5070939064026 and batch: 1500, loss is 3.760923309326172 and perplexity is 42.98809897341816
At time: 699.4053893089294 and batch: 1550, loss is 3.7640878486633302 and perplexity is 43.12435197894047
At time: 700.309287071228 and batch: 1600, loss is 3.853737449645996 and perplexity is 47.16902606039611
At time: 701.214882850647 and batch: 1650, loss is 3.8121666383743285 and perplexity is 45.248369591708226
At time: 702.120031118393 and batch: 1700, loss is 3.8165582466125487 and perplexity is 45.44751967888397
At time: 703.0261616706848 and batch: 1750, loss is 3.8123228120803834 and perplexity is 45.25543674911802
At time: 703.9319796562195 and batch: 1800, loss is 3.7792113065719604 and perplexity is 43.78149793543911
At time: 704.8382172584534 and batch: 1850, loss is 3.8068470430374144 and perplexity is 45.00830566341434
At time: 705.742386341095 and batch: 1900, loss is 3.878095827102661 and perplexity is 48.33209472779688
At time: 706.648930311203 and batch: 1950, loss is 3.827122936248779 and perplexity is 45.93020383370806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330267759811046 and perplexity of 75.96462411967696
finished 19 epochs...
Completing Train Step...
At time: 709.573516368866 and batch: 50, loss is 3.9302276849746702 and perplexity is 50.91856974274299
At time: 710.4733891487122 and batch: 100, loss is 3.930023226737976 and perplexity is 50.9081600859647
At time: 711.3475611209869 and batch: 150, loss is 3.9007426071166993 and perplexity is 49.43914934105978
At time: 712.2300317287445 and batch: 200, loss is 3.8866751050949095 and perplexity is 48.7485330200614
At time: 713.1189835071564 and batch: 250, loss is 3.8726796388626097 and perplexity is 48.07102663987342
At time: 714.0164775848389 and batch: 300, loss is 3.890058407783508 and perplexity is 48.913743383633765
At time: 714.914294719696 and batch: 350, loss is 3.9070481061935425 and perplexity is 49.751872754047234
At time: 715.8121728897095 and batch: 400, loss is 3.8592086124420164 and perplexity is 47.42780274006343
At time: 716.7101423740387 and batch: 450, loss is 3.8997215032577515 and perplexity is 49.38869260005508
At time: 717.6091752052307 and batch: 500, loss is 3.915864443778992 and perplexity is 50.19244130660101
At time: 718.5087885856628 and batch: 550, loss is 3.8794873428344725 and perplexity is 48.39939641277895
At time: 719.4162969589233 and batch: 600, loss is 3.8632801485061647 and perplexity is 47.621300398402674
At time: 720.3161427974701 and batch: 650, loss is 3.9192198514938354 and perplexity is 50.36114028002806
At time: 721.2160410881042 and batch: 700, loss is 3.9382387590408325 and perplexity is 51.328120456526634
At time: 722.1413149833679 and batch: 750, loss is 3.9013017892837523 and perplexity is 49.466802562599185
At time: 723.0401413440704 and batch: 800, loss is 3.8761976861953737 and perplexity is 48.24044061538788
At time: 723.9391751289368 and batch: 850, loss is 3.889706735610962 and perplexity is 48.89654480553858
At time: 724.8414709568024 and batch: 900, loss is 3.8591503715515136 and perplexity is 47.42504058303328
At time: 725.7445662021637 and batch: 950, loss is 3.9585328006744387 and perplexity is 52.38041702999955
At time: 726.6443190574646 and batch: 1000, loss is 3.915092363357544 and perplexity is 50.15370366157649
At time: 727.5442132949829 and batch: 1050, loss is 3.8668063068389893 and perplexity is 47.7895170485963
At time: 728.4443678855896 and batch: 1100, loss is 3.8795714712142946 and perplexity is 48.403468346863725
At time: 729.3442661762238 and batch: 1150, loss is 3.8537168455123902 and perplexity is 47.16805419349337
At time: 730.243166923523 and batch: 1200, loss is 3.903938546180725 and perplexity is 49.59740660531395
At time: 731.142361164093 and batch: 1250, loss is 3.9060686254501342 and perplexity is 49.7031656104848
At time: 732.0413029193878 and batch: 1300, loss is 3.9043965482711793 and perplexity is 49.62012752393723
At time: 732.9403750896454 and batch: 1350, loss is 3.801989393234253 and perplexity is 44.79020124259593
At time: 733.8540239334106 and batch: 1400, loss is 3.8217858028411866 and perplexity is 45.6857212069473
At time: 734.7574043273926 and batch: 1450, loss is 3.735460786819458 and perplexity is 41.907331460785315
At time: 735.6597392559052 and batch: 1500, loss is 3.760561270713806 and perplexity is 42.972538438644754
At time: 736.5625696182251 and batch: 1550, loss is 3.7638886976242065 and perplexity is 43.11576457455596
At time: 737.4655978679657 and batch: 1600, loss is 3.8536705446243285 and perplexity is 47.16587032125406
At time: 738.3690812587738 and batch: 1650, loss is 3.8121678400039674 and perplexity is 45.2484239635229
At time: 739.273788690567 and batch: 1700, loss is 3.8166352891921997 and perplexity is 45.451021207920455
At time: 740.1778569221497 and batch: 1750, loss is 3.8125581550598144 and perplexity is 45.26608855180234
At time: 741.0817863941193 and batch: 1800, loss is 3.779529323577881 and perplexity is 43.79542341047884
At time: 741.9873254299164 and batch: 1850, loss is 3.8072506952285767 and perplexity is 45.02647703182549
At time: 742.890665769577 and batch: 1900, loss is 3.8785038137435914 and perplexity is 48.35181759983458
At time: 743.7931344509125 and batch: 1950, loss is 3.827397413253784 and perplexity is 45.94281234879018
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330079260537791 and perplexity of 75.95030619273909
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
2320.7359561920166


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}, {'best_accuracy': -75.95030619273909, 'params': {'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.022236433569113312, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5875562008890167}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3010163307189941 and batch: 50, loss is 7.376492223739624 and perplexity is 1597.9745878686795
At time: 2.121288299560547 and batch: 100, loss is 6.6022208881378175 and perplexity is 736.7295676419513
At time: 2.9686107635498047 and batch: 150, loss is 6.305336990356445 and perplexity is 547.4860546221241
At time: 3.7934253215789795 and batch: 200, loss is 6.078408327102661 and perplexity is 436.33414049003983
At time: 4.620788812637329 and batch: 250, loss is 5.932411699295044 and perplexity is 377.0627801930095
At time: 5.451344966888428 and batch: 300, loss is 5.787098274230957 and perplexity is 326.0654976525306
At time: 6.28544807434082 and batch: 350, loss is 5.695839052200317 and perplexity is 297.62641294628196
At time: 7.114706039428711 and batch: 400, loss is 5.595237064361572 and perplexity is 269.14144637521275
At time: 7.94940185546875 and batch: 450, loss is 5.486971740722656 and perplexity is 241.52469889557918
At time: 8.776893377304077 and batch: 500, loss is 5.43203405380249 and perplexity is 228.613785553838
At time: 9.604754209518433 and batch: 550, loss is 5.3659630966186525 and perplexity is 213.99723547957203
At time: 10.438504934310913 and batch: 600, loss is 5.352920475006104 and perplexity is 211.22427316909636
At time: 11.270453453063965 and batch: 650, loss is 5.4101268005371095 and perplexity is 223.65994608387095
At time: 12.09757399559021 and batch: 700, loss is 5.3501918983459475 and perplexity is 210.64871712874861
At time: 12.924422264099121 and batch: 750, loss is 5.288794975280762 and perplexity is 198.1045606267527
At time: 13.752411603927612 and batch: 800, loss is 5.260229024887085 and perplexity is 192.52557939749937
At time: 14.580085515975952 and batch: 850, loss is 5.252538557052612 and perplexity is 191.0506463537547
At time: 15.408403635025024 and batch: 900, loss is 5.251625690460205 and perplexity is 190.8763221807032
At time: 16.239623069763184 and batch: 950, loss is 5.290911970138549 and perplexity is 198.52439119568646
At time: 17.06701350212097 and batch: 1000, loss is 5.2479813861846925 and perplexity is 190.18197675515137
At time: 17.895592212677002 and batch: 1050, loss is 5.143840885162353 and perplexity is 171.37272883013816
At time: 18.73479413986206 and batch: 1100, loss is 5.2242929649353025 and perplexity is 185.72980660614763
At time: 19.57808780670166 and batch: 1150, loss is 5.119225749969482 and perplexity is 167.2058603488169
At time: 20.449037790298462 and batch: 1200, loss is 5.1938635444641115 and perplexity is 180.1632788540602
At time: 21.352036714553833 and batch: 1250, loss is 5.1407810306549075 and perplexity is 170.84915465228406
At time: 22.286155700683594 and batch: 1300, loss is 5.164167261123657 and perplexity is 174.8917587486018
At time: 23.21082067489624 and batch: 1350, loss is 5.0881162452697755 and perplexity is 162.08424732467455
At time: 24.134741067886353 and batch: 1400, loss is 5.090575141906738 and perplexity is 162.48328613186155
At time: 25.059048414230347 and batch: 1450, loss is 5.03163106918335 and perplexity is 153.18266056086256
At time: 25.983218669891357 and batch: 1500, loss is 5.007261066436768 and perplexity is 149.49471879738445
At time: 26.915464401245117 and batch: 1550, loss is 5.004321117401123 and perplexity is 149.0558573742318
At time: 27.848793029785156 and batch: 1600, loss is 5.050083208084106 and perplexity is 156.03544735687484
At time: 28.777048587799072 and batch: 1650, loss is 5.015029468536377 and perplexity is 150.66057644717867
At time: 29.70178461074829 and batch: 1700, loss is 5.038956260681152 and perplexity is 154.308872707541
At time: 30.62890362739563 and batch: 1750, loss is 5.038709192276001 and perplexity is 154.27075256979526
At time: 31.553723573684692 and batch: 1800, loss is 4.994374809265136 and perplexity is 147.5806504801944
At time: 32.478580713272095 and batch: 1850, loss is 4.992608118057251 and perplexity is 147.32015122116812
At time: 33.40493845939636 and batch: 1900, loss is 5.069645147323609 and perplexity is 159.1178539276905
At time: 34.331315755844116 and batch: 1950, loss is 4.977399625778198 and perplexity is 145.09658524053876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.770020666787791 and perplexity of 117.92167899780351
finished 1 epochs...
Completing Train Step...
At time: 37.40352964401245 and batch: 50, loss is 4.9607017230987545 and perplexity is 142.6938923732064
At time: 38.326762437820435 and batch: 100, loss is 4.926607351303101 and perplexity is 137.91083474649872
At time: 39.249611139297485 and batch: 150, loss is 4.875313549041748 and perplexity is 131.01522646995568
At time: 40.172807455062866 and batch: 200, loss is 4.850872364044189 and perplexity is 127.85187458969202
At time: 41.094937801361084 and batch: 250, loss is 4.848774995803833 and perplexity is 127.58400313919012
At time: 42.0161817073822 and batch: 300, loss is 4.8611555099487305 and perplexity is 129.17337702649363
At time: 42.94509673118591 and batch: 350, loss is 4.8561367893219 and perplexity is 128.5267159976125
At time: 43.86663293838501 and batch: 400, loss is 4.802735900878906 and perplexity is 121.84331315390314
At time: 44.78864812850952 and batch: 450, loss is 4.798597450256348 and perplexity is 121.34011257229028
At time: 45.712482929229736 and batch: 500, loss is 4.782498540878296 and perplexity is 119.40230920875335
At time: 46.63683605194092 and batch: 550, loss is 4.747939643859863 and perplexity is 115.34638489999584
At time: 47.56546092033386 and batch: 600, loss is 4.730770702362061 and perplexity is 113.38291316258855
At time: 48.48823642730713 and batch: 650, loss is 4.808737697601319 and perplexity is 122.5767908416796
At time: 49.45830535888672 and batch: 700, loss is 4.8034491443634035 and perplexity is 121.93024810234711
At time: 50.381993532180786 and batch: 750, loss is 4.756548166275024 and perplexity is 116.34363309809538
At time: 51.308369874954224 and batch: 800, loss is 4.739828176498413 and perplexity is 114.41454088406651
At time: 52.23154544830322 and batch: 850, loss is 4.738569631576538 and perplexity is 114.27063561926298
At time: 53.153566122055054 and batch: 900, loss is 4.722725467681885 and perplexity is 112.47438059677967
At time: 54.074928522109985 and batch: 950, loss is 4.794930067062378 and perplexity is 120.89592688010639
At time: 54.99413180351257 and batch: 1000, loss is 4.764697875976562 and perplexity is 117.29567409296918
At time: 55.92249536514282 and batch: 1050, loss is 4.685489311218261 and perplexity is 108.36328270771105
At time: 56.844319581985474 and batch: 1100, loss is 4.748571968078613 and perplexity is 115.41934427727303
At time: 57.76461672782898 and batch: 1150, loss is 4.688764791488648 and perplexity is 108.71880643987866
At time: 58.68567085266113 and batch: 1200, loss is 4.762393789291382 and perplexity is 117.02572580361736
At time: 59.606361865997314 and batch: 1250, loss is 4.738383464813232 and perplexity is 114.24936420496547
At time: 60.533636808395386 and batch: 1300, loss is 4.747156429290771 and perplexity is 115.2560792997973
At time: 61.45536994934082 and batch: 1350, loss is 4.644264545440674 and perplexity is 103.98686004528574
At time: 62.38573718070984 and batch: 1400, loss is 4.651076412200927 and perplexity is 104.69762274275719
At time: 63.30602264404297 and batch: 1450, loss is 4.595113763809204 and perplexity is 98.99939745562043
At time: 64.22641444206238 and batch: 1500, loss is 4.593598937988281 and perplexity is 98.84954414158922
At time: 65.14641666412354 and batch: 1550, loss is 4.591572284698486 and perplexity is 98.6494132542208
At time: 66.06658625602722 and batch: 1600, loss is 4.665058946609497 and perplexity is 106.17184350771977
At time: 66.98657298088074 and batch: 1650, loss is 4.618716449737549 and perplexity is 101.36384300798295
At time: 67.90659880638123 and batch: 1700, loss is 4.649832420349121 and perplexity is 104.56746073018886
At time: 68.83013892173767 and batch: 1750, loss is 4.64466555595398 and perplexity is 104.02856823156124
At time: 69.75136065483093 and batch: 1800, loss is 4.607927989959717 and perplexity is 100.27616102111485
At time: 70.67354011535645 and batch: 1850, loss is 4.633411245346069 and perplexity is 102.86436187070983
At time: 71.59755373001099 and batch: 1900, loss is 4.719990329742432 and perplexity is 112.16716797715955
At time: 72.51874041557312 and batch: 1950, loss is 4.64176383972168 and perplexity is 103.72714438123842
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.593112679414971 and perplexity of 98.8014893877475
finished 2 epochs...
Completing Train Step...
At time: 75.50302696228027 and batch: 50, loss is 4.631672706604004 and perplexity is 102.68568355700997
At time: 76.45730447769165 and batch: 100, loss is 4.599967098236084 and perplexity is 99.48104248631377
At time: 77.38107895851135 and batch: 150, loss is 4.568548784255982 and perplexity is 96.40410505384745
At time: 78.30019903182983 and batch: 200, loss is 4.555137367248535 and perplexity is 95.11982068622375
At time: 79.21725296974182 and batch: 250, loss is 4.550334463119507 and perplexity is 94.66406465906022
At time: 80.1392776966095 and batch: 300, loss is 4.569736423492432 and perplexity is 96.51866636685382
At time: 81.06183314323425 and batch: 350, loss is 4.571526803970337 and perplexity is 96.69162628870285
At time: 81.98291110992432 and batch: 400, loss is 4.520745334625244 and perplexity is 91.90407174392423
At time: 82.9084084033966 and batch: 450, loss is 4.543115892410278 and perplexity is 93.98318585717047
At time: 83.8319480419159 and batch: 500, loss is 4.536678380966187 and perplexity is 93.38011125518298
At time: 84.75009107589722 and batch: 550, loss is 4.498819646835327 and perplexity is 89.91094197749706
At time: 85.66815137863159 and batch: 600, loss is 4.491471157073975 and perplexity is 89.25265401442995
At time: 86.5855462551117 and batch: 650, loss is 4.568969058990478 and perplexity is 96.44462977866581
At time: 87.50300812721252 and batch: 700, loss is 4.568194627761841 and perplexity is 96.36996895909739
At time: 88.42118525505066 and batch: 750, loss is 4.534523344039917 and perplexity is 93.17909034878514
At time: 89.33883738517761 and batch: 800, loss is 4.512746810913086 and perplexity is 91.17190686932607
At time: 90.25661969184875 and batch: 850, loss is 4.513404092788696 and perplexity is 91.23185220961082
At time: 91.17712903022766 and batch: 900, loss is 4.493693161010742 and perplexity is 89.45119425993273
At time: 92.09488606452942 and batch: 950, loss is 4.576435546875 and perplexity is 97.16742746060245
At time: 93.0125105381012 and batch: 1000, loss is 4.547268438339233 and perplexity is 94.37426678177121
At time: 93.92951560020447 and batch: 1050, loss is 4.479524364471436 and perplexity is 88.19271510952127
At time: 94.85631394386292 and batch: 1100, loss is 4.534332771301269 and perplexity is 93.16133464628284
At time: 95.80085301399231 and batch: 1150, loss is 4.48823748588562 and perplexity is 88.96450641703883
At time: 96.71898078918457 and batch: 1200, loss is 4.562354488372803 and perplexity is 95.80879516904265
At time: 97.64055037498474 and batch: 1250, loss is 4.544817867279053 and perplexity is 94.14327907625912
At time: 98.56272053718567 and batch: 1300, loss is 4.542181329727173 and perplexity is 93.8953937088517
At time: 99.48025584220886 and batch: 1350, loss is 4.431270923614502 and perplexity is 84.03815514372204
At time: 100.39752984046936 and batch: 1400, loss is 4.453354225158692 and perplexity is 85.91463827799043
At time: 101.314537525177 and batch: 1450, loss is 4.387172517776489 and perplexity is 80.41273167191208
At time: 102.23171257972717 and batch: 1500, loss is 4.393124513626098 and perplexity is 80.8927751081716
At time: 103.14950919151306 and batch: 1550, loss is 4.399397735595703 and perplexity is 81.40182847513483
At time: 104.07466793060303 and batch: 1600, loss is 4.477667207717896 and perplexity is 88.02907940864813
At time: 104.99782490730286 and batch: 1650, loss is 4.431485319137574 and perplexity is 84.0561744795155
At time: 105.91573190689087 and batch: 1700, loss is 4.466213903427124 and perplexity is 87.02660734306386
At time: 106.83551478385925 and batch: 1750, loss is 4.458925762176514 and perplexity is 86.39465082766098
At time: 107.76008152961731 and batch: 1800, loss is 4.422868766784668 and perplexity is 83.33501148277449
At time: 108.67778897285461 and batch: 1850, loss is 4.453994340896607 and perplexity is 85.96965119550813
At time: 109.59548950195312 and batch: 1900, loss is 4.537892417907715 and perplexity is 93.49354700351265
At time: 110.51351237297058 and batch: 1950, loss is 4.463334836959839 and perplexity is 86.776412293013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.533588356195494 and perplexity of 93.09200974795017
finished 3 epochs...
Completing Train Step...
At time: 113.5390362739563 and batch: 50, loss is 4.455602025985717 and perplexity is 86.10797448220083
At time: 114.43782925605774 and batch: 100, loss is 4.424235887527466 and perplexity is 83.44901841844043
At time: 115.3355541229248 and batch: 150, loss is 4.3989247131347655 and perplexity is 81.36333268730864
At time: 116.23277997970581 and batch: 200, loss is 4.390003452301025 and perplexity is 80.64069737595868
At time: 117.13074016571045 and batch: 250, loss is 4.3841370105743405 and perplexity is 80.16900834487987
At time: 118.03042721748352 and batch: 300, loss is 4.400391035079956 and perplexity is 81.48272503998314
At time: 118.9307496547699 and batch: 350, loss is 4.403149642944336 and perplexity is 81.70781424977923
At time: 119.85947871208191 and batch: 400, loss is 4.355687494277954 and perplexity is 77.92037673972187
At time: 120.76191067695618 and batch: 450, loss is 4.384280338287353 and perplexity is 80.18049960898907
At time: 121.66669940948486 and batch: 500, loss is 4.389742650985718 and perplexity is 80.61966891825962
At time: 122.57717609405518 and batch: 550, loss is 4.353799486160279 and perplexity is 77.77340122504611
At time: 123.4884386062622 and batch: 600, loss is 4.3498111343383785 and perplexity is 77.4638312858497
At time: 124.40293622016907 and batch: 650, loss is 4.422774705886841 and perplexity is 83.32717328541372
At time: 125.31853675842285 and batch: 700, loss is 4.423525314331055 and perplexity is 83.38974284499642
At time: 126.22884726524353 and batch: 750, loss is 4.393675270080567 and perplexity is 80.93733959714578
At time: 127.14462685585022 and batch: 800, loss is 4.37373140335083 and perplexity is 79.33912633372734
At time: 128.06860399246216 and batch: 850, loss is 4.375238513946533 and perplexity is 79.45878932170719
At time: 128.98456621170044 and batch: 900, loss is 4.3516746997833256 and perplexity is 77.60832479980968
At time: 129.90221428871155 and batch: 950, loss is 4.4383847045898435 and perplexity is 84.63811563663121
At time: 130.8190324306488 and batch: 1000, loss is 4.410665502548218 and perplexity is 82.32423226415752
At time: 131.73554921150208 and batch: 1050, loss is 4.347639093399048 and perplexity is 77.29575926870737
At time: 132.65224695205688 and batch: 1100, loss is 4.396774444580078 and perplexity is 81.1885676347628
At time: 133.57143831253052 and batch: 1150, loss is 4.356425065994262 and perplexity is 77.97786980575245
At time: 134.4948012828827 and batch: 1200, loss is 4.432889537811279 and perplexity is 84.17429064041056
At time: 135.4115653038025 and batch: 1250, loss is 4.4133526229858395 and perplexity is 82.5457448734277
At time: 136.32900595664978 and batch: 1300, loss is 4.410641746520996 and perplexity is 82.32227659068444
At time: 137.2596127986908 and batch: 1350, loss is 4.3014735412597656 and perplexity is 73.80847343882338
At time: 138.1810553073883 and batch: 1400, loss is 4.3255800533294675 and perplexity is 75.60935760196882
At time: 139.1065149307251 and batch: 1450, loss is 4.2557805728912355 and perplexity is 70.51183533997786
At time: 140.02729749679565 and batch: 1500, loss is 4.266225457191467 and perplexity is 71.25218299398406
At time: 140.95484280586243 and batch: 1550, loss is 4.2694557762146 and perplexity is 71.48272243364555
At time: 141.87635493278503 and batch: 1600, loss is 4.354585838317871 and perplexity is 77.83458255878702
At time: 142.79508662223816 and batch: 1650, loss is 4.31024468421936 and perplexity is 74.45870558184208
At time: 143.71308135986328 and batch: 1700, loss is 4.3432783079147335 and perplexity is 76.95942292201205
At time: 144.63194799423218 and batch: 1750, loss is 4.3387972927093506 and perplexity is 76.61533807816366
At time: 145.55232119560242 and batch: 1800, loss is 4.298653144836425 and perplexity is 73.60059756830323
At time: 146.47903752326965 and batch: 1850, loss is 4.333623657226562 and perplexity is 76.21998184293841
At time: 147.40725350379944 and batch: 1900, loss is 4.416511468887329 and perplexity is 82.80690642869827
At time: 148.32564163208008 and batch: 1950, loss is 4.344952793121338 and perplexity is 77.08839829074105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.514040640897529 and perplexity of 91.28994415979916
finished 4 epochs...
Completing Train Step...
At time: 151.2872576713562 and batch: 50, loss is 4.336842150688171 and perplexity is 76.46569054997552
At time: 152.1899299621582 and batch: 100, loss is 4.309673595428467 and perplexity is 74.4161951894595
At time: 153.06541395187378 and batch: 150, loss is 4.286909742355347 and perplexity is 72.74133135760142
At time: 153.94083905220032 and batch: 200, loss is 4.276910524368287 and perplexity is 72.01759933595899
At time: 154.8245551586151 and batch: 250, loss is 4.274191222190857 and perplexity is 71.82202775090454
At time: 155.70869708061218 and batch: 300, loss is 4.287715749740601 and perplexity is 72.79998504236505
At time: 156.60105967521667 and batch: 350, loss is 4.288504610061645 and perplexity is 72.85743671963255
At time: 157.50114226341248 and batch: 400, loss is 4.242705883979798 and perplexity is 69.59591575794359
At time: 158.39942741394043 and batch: 450, loss is 4.275822925567627 and perplexity is 71.93931565962768
At time: 159.2976315021515 and batch: 500, loss is 4.285999975204468 and perplexity is 72.67518377783107
At time: 160.19595551490784 and batch: 550, loss is 4.251232161521911 and perplexity is 70.19184677791378
At time: 161.09480476379395 and batch: 600, loss is 4.249630298614502 and perplexity is 70.07949906899485
At time: 161.99173164367676 and batch: 650, loss is 4.319956512451172 and perplexity is 75.185358593975
At time: 162.89004564285278 and batch: 700, loss is 4.322082843780517 and perplexity is 75.34539766520848
At time: 163.7969264984131 and batch: 750, loss is 4.296167020797729 and perplexity is 73.41784462080439
At time: 164.69581198692322 and batch: 800, loss is 4.27575882434845 and perplexity is 71.93470440958208
At time: 165.63996481895447 and batch: 850, loss is 4.27635272026062 and perplexity is 71.9774388251154
At time: 166.5400049686432 and batch: 900, loss is 4.252532863616944 and perplexity is 70.28320486201754
At time: 167.43979287147522 and batch: 950, loss is 4.341090602874756 and perplexity is 76.79124243633659
At time: 168.3380582332611 and batch: 1000, loss is 4.313149709701538 and perplexity is 74.67532450833761
At time: 169.23706364631653 and batch: 1050, loss is 4.253070793151855 and perplexity is 70.32102244440638
At time: 170.14409184455872 and batch: 1100, loss is 4.298082551956177 and perplexity is 73.55861357037296
At time: 171.0656077861786 and batch: 1150, loss is 4.2609908437728885 and perplexity is 70.88017985653154
At time: 171.97776651382446 and batch: 1200, loss is 4.332815327644348 and perplexity is 76.15839587109372
At time: 172.89712262153625 and batch: 1250, loss is 4.318633623123169 and perplexity is 75.0859624450169
At time: 173.81083822250366 and batch: 1300, loss is 4.315180759429932 and perplexity is 74.82714793417057
At time: 174.72315764427185 and batch: 1350, loss is 4.2076058053970335 and perplexity is 67.19546804154906
At time: 175.64336585998535 and batch: 1400, loss is 4.233553214073181 and perplexity is 68.96183351338995
At time: 176.55534386634827 and batch: 1450, loss is 4.161256942749024 and perplexity is 64.1521074703621
At time: 177.4681556224823 and batch: 1500, loss is 4.177038469314575 and perplexity is 65.17255660213966
At time: 178.3800721168518 and batch: 1550, loss is 4.175463137626648 and perplexity is 65.06996903447981
At time: 179.29083776474 and batch: 1600, loss is 4.263004398345947 and perplexity is 71.02304475168303
At time: 180.20263504981995 and batch: 1650, loss is 4.220707631111145 and perplexity is 68.08164393712532
At time: 181.11477255821228 and batch: 1700, loss is 4.255408220291137 and perplexity is 70.48558496225283
At time: 182.03778290748596 and batch: 1750, loss is 4.247583112716675 and perplexity is 69.93618005715778
At time: 182.94981980323792 and batch: 1800, loss is 4.206995444297791 and perplexity is 67.15446705578732
At time: 183.86093497276306 and batch: 1850, loss is 4.247478342056274 and perplexity is 69.9288531812148
At time: 184.7728660106659 and batch: 1900, loss is 4.325595865249634 and perplexity is 75.6105531405469
At time: 185.6853482723236 and batch: 1950, loss is 4.253689842224121 and perplexity is 70.36456808516499
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499934990461482 and perplexity of 90.01127951857016
finished 5 epochs...
Completing Train Step...
At time: 188.6725356578827 and batch: 50, loss is 4.251651496887207 and perplexity is 70.22128687382845
At time: 189.55513381958008 and batch: 100, loss is 4.223506331443787 and perplexity is 68.2724509379224
At time: 190.45788192749023 and batch: 150, loss is 4.202794198989868 and perplexity is 66.87292649076203
At time: 191.35960006713867 and batch: 200, loss is 4.1933311128616335 and perplexity is 66.24308704038562
At time: 192.25084519386292 and batch: 250, loss is 4.187854824066162 and perplexity is 65.88131226076212
At time: 193.1414840221405 and batch: 300, loss is 4.201086297035217 and perplexity is 66.7588115651862
At time: 194.0554599761963 and batch: 350, loss is 4.202427101135254 and perplexity is 66.8483820882899
At time: 194.95954489707947 and batch: 400, loss is 4.158156013488769 and perplexity is 63.953484440342336
At time: 195.86594939231873 and batch: 450, loss is 4.191352314949036 and perplexity is 66.1121349646033
At time: 196.77205634117126 and batch: 500, loss is 4.210143537521362 and perplexity is 67.36620869479572
At time: 197.67770218849182 and batch: 550, loss is 4.171921133995056 and perplexity is 64.83989866343153
At time: 198.59155464172363 and batch: 600, loss is 4.173143229484558 and perplexity is 64.91918765061638
At time: 199.50251364707947 and batch: 650, loss is 4.240535593032837 and perplexity is 69.44503615756634
At time: 200.40914797782898 and batch: 700, loss is 4.243685293197632 and perplexity is 69.66411202993783
At time: 201.3136978149414 and batch: 750, loss is 4.218628435134888 and perplexity is 67.94023591543205
At time: 202.22502326965332 and batch: 800, loss is 4.201914701461792 and perplexity is 66.81413777327356
At time: 203.13334465026855 and batch: 850, loss is 4.198627066612244 and perplexity is 66.59483797184836
At time: 204.04055643081665 and batch: 900, loss is 4.179973950386048 and perplexity is 65.3641504809459
At time: 204.95399022102356 and batch: 950, loss is 4.267720251083374 and perplexity is 71.35876996483843
At time: 205.8610019683838 and batch: 1000, loss is 4.238353910446167 and perplexity is 69.29369428144761
At time: 206.7680525779724 and batch: 1050, loss is 4.177762999534607 and perplexity is 65.21979319901921
At time: 207.67471289634705 and batch: 1100, loss is 4.224817748069763 and perplexity is 68.36204329879419
At time: 208.58044695854187 and batch: 1150, loss is 4.1871586465835575 and perplexity is 65.83546313605764
At time: 209.4865915775299 and batch: 1200, loss is 4.259018259048462 and perplexity is 70.74050050645016
At time: 210.3919334411621 and batch: 1250, loss is 4.246871023178101 and perplexity is 69.8863969620855
At time: 211.30595469474792 and batch: 1300, loss is 4.239632139205932 and perplexity is 69.382324106877
At time: 212.21686029434204 and batch: 1350, loss is 4.133852024078369 and perplexity is 62.41789568472594
At time: 213.12642574310303 and batch: 1400, loss is 4.164410429000855 and perplexity is 64.35472957439137
At time: 214.0328814983368 and batch: 1450, loss is 4.08906699180603 and perplexity is 59.684179889509586
At time: 214.948495388031 and batch: 1500, loss is 4.105845789909363 and perplexity is 60.69405726585119
At time: 215.85799860954285 and batch: 1550, loss is 4.102645435333252 and perplexity is 60.50012525306526
At time: 216.76912450790405 and batch: 1600, loss is 4.190520696640014 and perplexity is 66.05717775759533
At time: 217.6801164150238 and batch: 1650, loss is 4.1505138254165646 and perplexity is 63.466602674998505
At time: 218.5945417881012 and batch: 1700, loss is 4.185200819969177 and perplexity is 65.70669480832103
At time: 219.5157985687256 and batch: 1750, loss is 4.179559364318847 and perplexity is 65.3370570315335
At time: 220.4297788143158 and batch: 1800, loss is 4.140164294242859 and perplexity is 62.81314043885316
At time: 221.34744572639465 and batch: 1850, loss is 4.1766947078704835 and perplexity is 65.15015664030916
At time: 222.26604175567627 and batch: 1900, loss is 4.254538044929505 and perplexity is 70.4242768211539
At time: 223.1803069114685 and batch: 1950, loss is 4.181196165084839 and perplexity is 65.44408834710423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49713872865189 and perplexity of 89.75993599014753
finished 6 epochs...
Completing Train Step...
At time: 226.15676856040955 and batch: 50, loss is 4.184089474678039 and perplexity is 65.63371254420899
At time: 227.07203078269958 and batch: 100, loss is 4.159560980796814 and perplexity is 64.04340014473854
At time: 227.94639682769775 and batch: 150, loss is 4.137378993034363 and perplexity is 62.63843034594451
At time: 228.83089303970337 and batch: 200, loss is 4.1253273391723635 and perplexity is 61.88806432280231
At time: 229.7286217212677 and batch: 250, loss is 4.1212575340271 and perplexity is 61.636703801309636
At time: 230.63591265678406 and batch: 300, loss is 4.132619004249573 and perplexity is 62.34098061032566
At time: 231.53325653076172 and batch: 350, loss is 4.137805080413818 and perplexity is 62.665125477409205
At time: 232.43108677864075 and batch: 400, loss is 4.091803331375122 and perplexity is 59.84771972080301
At time: 233.32988858222961 and batch: 450, loss is 4.129548835754394 and perplexity is 62.14987680624755
At time: 234.22708582878113 and batch: 500, loss is 4.14629798412323 and perplexity is 63.19960076499141
At time: 235.1509964466095 and batch: 550, loss is 4.114759192466736 and perplexity is 61.23746604394077
At time: 236.0491852760315 and batch: 600, loss is 4.114217143058777 and perplexity is 61.204281306422935
At time: 236.94821310043335 and batch: 650, loss is 4.176028161048889 and perplexity is 65.10674547986696
At time: 237.84928345680237 and batch: 700, loss is 4.181165800094605 and perplexity is 65.44210116817118
At time: 238.76353859901428 and batch: 750, loss is 4.1611167383193965 and perplexity is 64.14311369122342
At time: 239.67732429504395 and batch: 800, loss is 4.139001927375793 and perplexity is 62.74017094246889
At time: 240.5886995792389 and batch: 850, loss is 4.136191511154175 and perplexity is 62.56409249106852
At time: 241.50956463813782 and batch: 900, loss is 4.118988924026489 and perplexity is 61.497032648251135
At time: 242.43087720870972 and batch: 950, loss is 4.204772739410401 and perplexity is 67.00536825635164
At time: 243.34221744537354 and batch: 1000, loss is 4.177108030319214 and perplexity is 65.17709022833176
At time: 244.2541081905365 and batch: 1050, loss is 4.123063597679138 and perplexity is 61.74812419755399
At time: 245.16576838493347 and batch: 1100, loss is 4.161937594413757 and perplexity is 64.19578757288886
At time: 246.07762360572815 and batch: 1150, loss is 4.127593498229981 and perplexity is 62.028471552795665
At time: 246.98956608772278 and batch: 1200, loss is 4.198342709541321 and perplexity is 66.57590395092306
At time: 247.90050506591797 and batch: 1250, loss is 4.186147432327271 and perplexity is 65.76892302598927
At time: 248.8119342327118 and batch: 1300, loss is 4.176970829963684 and perplexity is 65.16814852179671
At time: 249.7247974872589 and batch: 1350, loss is 4.0768211603164675 and perplexity is 58.95775439995536
At time: 250.63730001449585 and batch: 1400, loss is 4.105868349075317 and perplexity is 60.695426488605676
At time: 251.5495960712433 and batch: 1450, loss is 4.02696741104126 and perplexity is 56.09055347198438
At time: 252.4618022441864 and batch: 1500, loss is 4.050234537124634 and perplexity is 57.41092045875636
At time: 253.3723201751709 and batch: 1550, loss is 4.0439900779724125 and perplexity is 57.053537304608156
At time: 254.28345274925232 and batch: 1600, loss is 4.1336825084686275 and perplexity is 62.40731577383554
At time: 255.19506883621216 and batch: 1650, loss is 4.096599879264832 and perplexity is 60.13547173099317
At time: 256.1081097126007 and batch: 1700, loss is 4.134180784225464 and perplexity is 62.43841957482633
At time: 257.0233657360077 and batch: 1750, loss is 4.122470335960388 and perplexity is 61.711502263532836
At time: 257.94252610206604 and batch: 1800, loss is 4.085467391014099 and perplexity is 59.469726872496324
At time: 258.8538348674774 and batch: 1850, loss is 4.122006740570068 and perplexity is 61.68289972606827
At time: 259.7662401199341 and batch: 1900, loss is 4.195182814598083 and perplexity is 66.36586311694195
At time: 260.6787645816803 and batch: 1950, loss is 4.124623441696167 and perplexity is 61.84451679881298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.502008766351744 and perplexity of 90.19813642259305
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 263.65393257141113 and batch: 50, loss is 4.15002140045166 and perplexity is 63.43535782890614
At time: 264.53079414367676 and batch: 100, loss is 4.136791553497314 and perplexity is 62.60164486110256
At time: 265.4070429801941 and batch: 150, loss is 4.111816997528076 and perplexity is 61.05755827293768
At time: 266.29114985466003 and batch: 200, loss is 4.101029677391052 and perplexity is 60.4024506257107
At time: 267.18192315101624 and batch: 250, loss is 4.097062392234802 and perplexity is 60.163291599653135
At time: 268.0821886062622 and batch: 300, loss is 4.099252319335937 and perplexity is 60.29518919276491
At time: 268.98197984695435 and batch: 350, loss is 4.095094113349915 and perplexity is 60.04498992668761
At time: 269.8835184574127 and batch: 400, loss is 4.047614846229553 and perplexity is 57.260718420508645
At time: 270.78847336769104 and batch: 450, loss is 4.071049189567566 and perplexity is 58.61843218714233
At time: 271.70159935951233 and batch: 500, loss is 4.082721548080444 and perplexity is 59.30665632870523
At time: 272.60883140563965 and batch: 550, loss is 4.0486734580993655 and perplexity is 57.321367392899695
At time: 273.5134735107422 and batch: 600, loss is 4.03802894115448 and perplexity is 56.71444505457719
At time: 274.417409658432 and batch: 650, loss is 4.088965759277344 and perplexity is 59.67813821486898
At time: 275.3203263282776 and batch: 700, loss is 4.102143607139587 and perplexity is 60.469772201138625
At time: 276.2250201702118 and batch: 750, loss is 4.0622585487365725 and perplexity is 58.10539686209244
At time: 277.1298711299896 and batch: 800, loss is 4.042058572769165 and perplexity is 56.94344445712159
At time: 278.0338776111603 and batch: 850, loss is 4.042582149505615 and perplexity is 56.97326652632224
At time: 278.93808150291443 and batch: 900, loss is 4.011718273162842 and perplexity is 55.24170940735384
At time: 279.8434340953827 and batch: 950, loss is 4.099601879119873 and perplexity is 60.316269650296924
At time: 280.79402256011963 and batch: 1000, loss is 4.062240228652954 and perplexity is 58.10433237611402
At time: 281.69876646995544 and batch: 1050, loss is 3.997458734512329 and perplexity is 54.45957778778198
At time: 282.60220885276794 and batch: 1100, loss is 4.027038226127624 and perplexity is 56.09452567001685
At time: 283.5058693885803 and batch: 1150, loss is 3.996581254005432 and perplexity is 54.41181152990434
At time: 284.41173219680786 and batch: 1200, loss is 4.052851333618164 and perplexity is 57.561349889866726
At time: 285.3165361881256 and batch: 1250, loss is 4.039094738960266 and perplexity is 56.774923408796404
At time: 286.219927072525 and batch: 1300, loss is 4.026954731941223 and perplexity is 56.08984229875433
At time: 287.1255986690521 and batch: 1350, loss is 3.9221773672103883 and perplexity is 50.510304613112396
At time: 288.0296747684479 and batch: 1400, loss is 3.94086642742157 and perplexity is 51.46317109212907
At time: 288.9333577156067 and batch: 1450, loss is 3.8572848415374756 and perplexity is 47.336650219481434
At time: 289.8367476463318 and batch: 1500, loss is 3.880013108253479 and perplexity is 48.424849832391146
At time: 290.7399642467499 and batch: 1550, loss is 3.865566163063049 and perplexity is 47.73028791038784
At time: 291.64139676094055 and batch: 1600, loss is 3.9468692684173585 and perplexity is 51.7730253979562
At time: 292.5537040233612 and batch: 1650, loss is 3.899387159347534 and perplexity is 49.372182551621535
At time: 293.45850348472595 and batch: 1700, loss is 3.925945258140564 and perplexity is 50.70098092994099
At time: 294.36228227615356 and batch: 1750, loss is 3.9049304819107054 and perplexity is 49.64662845345912
At time: 295.2748212814331 and batch: 1800, loss is 3.87017107963562 and perplexity is 47.95058874839539
At time: 296.1794958114624 and batch: 1850, loss is 3.8982344579696657 and perplexity is 49.315303957081035
At time: 297.0834331512451 and batch: 1900, loss is 3.960228371620178 and perplexity is 52.469307081639506
At time: 297.9864709377289 and batch: 1950, loss is 3.8956599950790407 and perplexity is 49.18850682439279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385215297965116 and perplexity of 80.25550019886657
finished 8 epochs...
Completing Train Step...
At time: 300.9255676269531 and batch: 50, loss is 4.056855406761169 and perplexity is 57.792291790617206
At time: 301.831346988678 and batch: 100, loss is 4.039118986129761 and perplexity is 56.77630005667722
At time: 302.7182192802429 and batch: 150, loss is 4.01288537979126 and perplexity is 55.306220010621935
At time: 303.6394488811493 and batch: 200, loss is 4.004038228988647 and perplexity is 54.81907563920314
At time: 304.5401940345764 and batch: 250, loss is 4.003071579933167 and perplexity is 54.76611043502076
At time: 305.4403340816498 and batch: 300, loss is 4.005280828475952 and perplexity is 54.88723613381447
At time: 306.34115743637085 and batch: 350, loss is 4.00782799243927 and perplexity is 55.02722113042432
At time: 307.2411081790924 and batch: 400, loss is 3.961314597129822 and perplexity is 52.526331546572294
At time: 308.142865896225 and batch: 450, loss is 3.9943660831451417 and perplexity is 54.291413470916225
At time: 309.0580916404724 and batch: 500, loss is 4.009710793495178 and perplexity is 55.130924035807205
At time: 309.96562814712524 and batch: 550, loss is 3.9774773359298705 and perplexity is 53.38219887176503
At time: 310.8722767829895 and batch: 600, loss is 3.9730905199050905 and perplexity is 53.14853388369707
At time: 311.79415678977966 and batch: 650, loss is 4.02320318698883 and perplexity is 55.87981294760494
At time: 312.70607590675354 and batch: 700, loss is 4.036980628967285 and perplexity is 56.65502176315874
At time: 313.61317896842957 and batch: 750, loss is 4.002374191284179 and perplexity is 54.72793048593315
At time: 314.52049589157104 and batch: 800, loss is 3.982093343734741 and perplexity is 53.62918111583311
At time: 315.4266107082367 and batch: 850, loss is 3.986164951324463 and perplexity is 53.84798323259972
At time: 316.3392593860626 and batch: 900, loss is 3.956365065574646 and perplexity is 52.26699314234867
At time: 317.24613761901855 and batch: 950, loss is 4.047541017532349 and perplexity is 57.256491092317646
At time: 318.15208172798157 and batch: 1000, loss is 4.012805061340332 and perplexity is 55.301778079090944
At time: 319.059424161911 and batch: 1050, loss is 3.9519662761688235 and perplexity is 52.03758657214075
At time: 319.9658615589142 and batch: 1100, loss is 3.9840968894958495 and perplexity is 53.73673734526393
At time: 320.8725845813751 and batch: 1150, loss is 3.9545932006835938 and perplexity is 52.17446509005021
At time: 321.7794268131256 and batch: 1200, loss is 4.014440188407898 and perplexity is 55.39227748216078
At time: 322.6865289211273 and batch: 1250, loss is 4.0030406665802 and perplexity is 54.76441745708623
At time: 323.59858870506287 and batch: 1300, loss is 3.991110019683838 and perplexity is 54.11492466854848
At time: 324.50480461120605 and batch: 1350, loss is 3.8894447326660155 and perplexity is 48.88373544492021
At time: 325.41911220550537 and batch: 1400, loss is 3.912172336578369 and perplexity is 50.00746711503372
At time: 326.3386731147766 and batch: 1450, loss is 3.8306665802001953 and perplexity is 46.09325284591087
At time: 327.2564797401428 and batch: 1500, loss is 3.8557243156433105 and perplexity is 47.26283775917796
At time: 328.1689293384552 and batch: 1550, loss is 3.843933148384094 and perplexity is 46.70882637321573
At time: 329.08265447616577 and batch: 1600, loss is 3.9299247026443482 and perplexity is 50.903144652708534
At time: 329.99517607688904 and batch: 1650, loss is 3.8835361003875732 and perplexity is 48.59575106252879
At time: 330.91279125213623 and batch: 1700, loss is 3.9150487184524536 and perplexity is 50.151514755707886
At time: 331.8351092338562 and batch: 1750, loss is 3.8964425134658813 and perplexity is 49.2270127992559
At time: 332.75226950645447 and batch: 1800, loss is 3.864214038848877 and perplexity is 47.66579424390468
At time: 333.6665358543396 and batch: 1850, loss is 3.896569595336914 and perplexity is 49.23326905766787
At time: 334.579781293869 and batch: 1900, loss is 3.961502847671509 and perplexity is 52.53622058771824
At time: 335.49389004707336 and batch: 1950, loss is 3.8980684900283813 and perplexity is 49.30711987677572
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381175054505814 and perplexity of 79.93190258587356
finished 9 epochs...
Completing Train Step...
At time: 338.4802451133728 and batch: 50, loss is 4.019097948074341 and perplexity is 55.65088319214088
At time: 339.3639497756958 and batch: 100, loss is 4.00017397403717 and perplexity is 54.607649520035615
At time: 340.2470111846924 and batch: 150, loss is 3.9730807733535767 and perplexity is 53.14801587129811
At time: 341.12992095947266 and batch: 200, loss is 3.9662573289871217 and perplexity is 52.78659780213954
At time: 342.01377606391907 and batch: 250, loss is 3.962405343055725 and perplexity is 52.58365568606183
At time: 342.9030683040619 and batch: 300, loss is 3.967063341140747 and perplexity is 52.82916159267853
At time: 343.80075573921204 and batch: 350, loss is 3.9689984798431395 and perplexity is 52.931492328040996
At time: 344.6988286972046 and batch: 400, loss is 3.922733030319214 and perplexity is 50.53837912526443
At time: 345.5959098339081 and batch: 450, loss is 3.958371109962463 and perplexity is 52.37194828775333
At time: 346.4921405315399 and batch: 500, loss is 3.9762932586669923 and perplexity is 53.31902763103415
At time: 347.3889904022217 and batch: 550, loss is 3.9445913791656495 and perplexity is 51.65522639734849
At time: 348.2858064174652 and batch: 600, loss is 3.942412118911743 and perplexity is 51.54277878636163
At time: 349.1830973625183 and batch: 650, loss is 3.9910075998306276 and perplexity is 54.109382509725826
At time: 350.11247873306274 and batch: 700, loss is 4.005937876701355 and perplexity is 54.92331154525819
At time: 351.015349149704 and batch: 750, loss is 3.972675395011902 and perplexity is 53.126475183120114
At time: 351.9187750816345 and batch: 800, loss is 3.952267508506775 and perplexity is 52.05326433721158
At time: 352.82114458084106 and batch: 850, loss is 3.9585362815856935 and perplexity is 52.38059936190006
At time: 353.723571062088 and batch: 900, loss is 3.9282271385192873 and perplexity is 50.81680660341439
At time: 354.62562823295593 and batch: 950, loss is 4.020527548789978 and perplexity is 55.73049863016223
At time: 355.5292863845825 and batch: 1000, loss is 3.9864384031295774 and perplexity is 53.8627100742654
At time: 356.4320685863495 and batch: 1050, loss is 3.9280375909805296 and perplexity is 50.80717531561748
At time: 357.3345878124237 and batch: 1100, loss is 3.9611888551712036 and perplexity is 52.51972719799516
At time: 358.23739552497864 and batch: 1150, loss is 3.9310915327072142 and perplexity is 50.962574637787554
At time: 359.13964676856995 and batch: 1200, loss is 3.99233314037323 and perplexity is 54.18115424764293
At time: 360.0417330265045 and batch: 1250, loss is 3.9815262746810913 and perplexity is 53.59877828791589
At time: 360.9440026283264 and batch: 1300, loss is 3.969376130104065 and perplexity is 52.95148569494234
At time: 361.84562945365906 and batch: 1350, loss is 3.8700402927398683 and perplexity is 47.94431784982814
At time: 362.748060464859 and batch: 1400, loss is 3.8943656301498413 and perplexity is 49.12488013320167
At time: 363.6508479118347 and batch: 1450, loss is 3.8137682676315308 and perplexity is 45.32089877121054
At time: 364.552463054657 and batch: 1500, loss is 3.8400034427642824 and perplexity is 46.525634616306554
At time: 365.4544885158539 and batch: 1550, loss is 3.828645257949829 and perplexity is 46.00017762753671
At time: 366.3559226989746 and batch: 1600, loss is 3.9165063524246215 and perplexity is 50.224670611649096
At time: 367.25785207748413 and batch: 1650, loss is 3.87016535282135 and perplexity is 47.950314145065796
At time: 368.1604428291321 and batch: 1700, loss is 3.903090410232544 and perplexity is 49.55535909535831
At time: 369.0632700920105 and batch: 1750, loss is 3.8857626628875734 and perplexity is 48.70407308763222
At time: 369.9649884700775 and batch: 1800, loss is 3.8541678857803343 and perplexity is 47.18933368388797
At time: 370.86873507499695 and batch: 1850, loss is 3.8884021520614622 and perplexity is 48.832796768919124
At time: 371.7715857028961 and batch: 1900, loss is 3.954785408973694 and perplexity is 52.18449441860122
At time: 372.6744067668915 and batch: 1950, loss is 3.8911251163482667 and perplexity is 48.96594793120435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38059933684593 and perplexity of 79.88589762217246
finished 10 epochs...
Completing Train Step...
At time: 375.6013672351837 and batch: 50, loss is 3.9912131595611573 and perplexity is 54.12050636308264
At time: 376.51191329956055 and batch: 100, loss is 3.9725630617141725 and perplexity is 53.12050764614887
At time: 377.3938412666321 and batch: 150, loss is 3.944652643203735 and perplexity is 51.65839110204613
At time: 378.2788224220276 and batch: 200, loss is 3.937156343460083 and perplexity is 51.27259215698372
At time: 379.1720869541168 and batch: 250, loss is 3.9347959852218626 and perplexity is 51.151713186648784
At time: 380.0720491409302 and batch: 300, loss is 3.940573101043701 and perplexity is 51.448077800297504
At time: 380.9719269275665 and batch: 350, loss is 3.941246089935303 and perplexity is 51.48271343854402
At time: 381.8708333969116 and batch: 400, loss is 3.8953944730758665 and perplexity is 49.17544792731661
At time: 382.7708044052124 and batch: 450, loss is 3.933446159362793 and perplexity is 51.082713860467685
At time: 383.6723635196686 and batch: 500, loss is 3.9530690574645995 and perplexity is 52.095004303070745
At time: 384.5770742893219 and batch: 550, loss is 3.921059799194336 and perplexity is 50.453887443080006
At time: 385.48179030418396 and batch: 600, loss is 3.919660358428955 and perplexity is 50.38332959849746
At time: 386.3858468532562 and batch: 650, loss is 3.967336821556091 and perplexity is 52.84361130950039
At time: 387.2892692089081 and batch: 700, loss is 3.9828201055526735 and perplexity is 53.66817092343067
At time: 388.1944577693939 and batch: 750, loss is 3.9506480169296263 and perplexity is 51.96903273864647
At time: 389.098402261734 and batch: 800, loss is 3.9300899076461793 and perplexity is 50.91155480149428
At time: 390.0018804073334 and batch: 850, loss is 3.9376210260391233 and perplexity is 51.29642317384168
At time: 390.90862131118774 and batch: 900, loss is 3.90713698387146 and perplexity is 49.756294781476505
At time: 391.8131260871887 and batch: 950, loss is 4.0006066513061525 and perplexity is 54.63128212097141
At time: 392.72394323349 and batch: 1000, loss is 3.9664439153671265 and perplexity is 52.79644798126227
At time: 393.629310131073 and batch: 1050, loss is 3.908962063789368 and perplexity is 49.847186913344466
At time: 394.5320158004761 and batch: 1100, loss is 3.9428329277038574 and perplexity is 51.564473005083784
At time: 395.47909212112427 and batch: 1150, loss is 3.912710428237915 and perplexity is 50.03438295694891
At time: 396.38215136528015 and batch: 1200, loss is 3.974746136665344 and perplexity is 53.236600369236214
At time: 397.2864019870758 and batch: 1250, loss is 3.964145836830139 and perplexity is 52.675256903969995
At time: 398.20151567459106 and batch: 1300, loss is 3.9513882970809937 and perplexity is 52.00751862548015
At time: 399.11009216308594 and batch: 1350, loss is 3.854380168914795 and perplexity is 47.19935224690385
At time: 400.0130431652069 and batch: 1400, loss is 3.8793118143081666 and perplexity is 48.39090168360798
At time: 400.91817831993103 and batch: 1450, loss is 3.798835105895996 and perplexity is 44.649142664537294
At time: 401.8202838897705 and batch: 1500, loss is 3.8260886096954345 and perplexity is 45.882721564601376
At time: 402.7226331233978 and batch: 1550, loss is 3.814686236381531 and perplexity is 45.36252104105312
At time: 403.63691878318787 and batch: 1600, loss is 3.903521933555603 and perplexity is 49.5767480031649
At time: 404.5439372062683 and batch: 1650, loss is 3.8573948335647583 and perplexity is 47.34185715995957
At time: 405.44930720329285 and batch: 1700, loss is 3.891081805229187 and perplexity is 48.96382720712845
At time: 406.35411524772644 and batch: 1750, loss is 3.874535002708435 and perplexity is 48.160298675177145
At time: 407.25764751434326 and batch: 1800, loss is 3.843515005111694 and perplexity is 46.68929947451125
At time: 408.17025208473206 and batch: 1850, loss is 3.8785791969299317 and perplexity is 48.35546265129667
At time: 409.0748064517975 and batch: 1900, loss is 3.9455277967453 and perplexity is 51.70361991416148
At time: 409.98332929611206 and batch: 1950, loss is 3.8813259267807005 and perplexity is 48.4884646206287
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381307628542878 and perplexity of 79.94250018335718
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 412.9547791481018 and batch: 50, loss is 3.988648314476013 and perplexity is 53.98187351022629
At time: 413.83319783210754 and batch: 100, loss is 3.990193600654602 and perplexity is 54.065355438378575
At time: 414.7128484249115 and batch: 150, loss is 3.9676935148239134 and perplexity is 52.86246363195027
At time: 415.6024055480957 and batch: 200, loss is 3.956697354316711 and perplexity is 52.284363761622245
At time: 416.49600648880005 and batch: 250, loss is 3.961332230567932 and perplexity is 52.52725777455504
At time: 417.3949213027954 and batch: 300, loss is 3.9646543312072753 and perplexity is 52.702048787103536
At time: 418.29482221603394 and batch: 350, loss is 3.9632852935791014 and perplexity is 52.62994706547859
At time: 419.21989345550537 and batch: 400, loss is 3.912737350463867 and perplexity is 50.035730012045036
At time: 420.1169936656952 and batch: 450, loss is 3.9495541715621947 and perplexity is 51.91221773201622
At time: 421.01393270492554 and batch: 500, loss is 3.963002710342407 and perplexity is 52.61507682582895
At time: 421.92021107673645 and batch: 550, loss is 3.9334652853012084 and perplexity is 51.08369087465019
At time: 422.8206160068512 and batch: 600, loss is 3.9252341747283936 and perplexity is 50.66494111859555
At time: 423.720166683197 and batch: 650, loss is 3.9662784337997437 and perplexity is 52.78771186515111
At time: 424.62104511260986 and batch: 700, loss is 3.978246488571167 and perplexity is 53.42327372541657
At time: 425.5254077911377 and batch: 750, loss is 3.944371876716614 and perplexity is 51.64388919296636
At time: 426.43013882637024 and batch: 800, loss is 3.9193484210968017 and perplexity is 50.36761560809505
At time: 427.33245372772217 and batch: 850, loss is 3.931924500465393 and perplexity is 51.00504250406082
At time: 428.2375183105469 and batch: 900, loss is 3.8943229007720945 and perplexity is 49.12278110248716
At time: 429.14689445495605 and batch: 950, loss is 3.9924526691436766 and perplexity is 54.187630841453476
At time: 430.0572762489319 and batch: 1000, loss is 3.9559003782272337 and perplexity is 52.24271097419323
At time: 430.9708626270294 and batch: 1050, loss is 3.89418963432312 and perplexity is 49.11623512007549
At time: 431.8801517486572 and batch: 1100, loss is 3.9213444089889524 and perplexity is 50.4682491572681
At time: 432.7840645313263 and batch: 1150, loss is 3.8927133798599245 and perplexity is 49.04378055261192
At time: 433.69032859802246 and batch: 1200, loss is 3.949997429847717 and perplexity is 51.93523335320134
At time: 434.5943377017975 and batch: 1250, loss is 3.9334033346176147 and perplexity is 51.08052630310471
At time: 435.4987585544586 and batch: 1300, loss is 3.9297197008132936 and perplexity is 50.89271048439663
At time: 436.40845465660095 and batch: 1350, loss is 3.825234727859497 and perplexity is 45.843559864185764
At time: 437.31249928474426 and batch: 1400, loss is 3.84231960773468 and perplexity is 46.633520554014645
At time: 438.2175099849701 and batch: 1450, loss is 3.7555398416519163 and perplexity is 42.75729575048464
At time: 439.1214175224304 and batch: 1500, loss is 3.789142713546753 and perplexity is 44.21847612181176
At time: 440.0240638256073 and batch: 1550, loss is 3.776862983703613 and perplexity is 43.67880546735492
At time: 440.9341948032379 and batch: 1600, loss is 3.860305209159851 and perplexity is 47.47984043985297
At time: 441.8396384716034 and batch: 1650, loss is 3.810111780166626 and perplexity is 45.15548607198192
At time: 442.74529218673706 and batch: 1700, loss is 3.83818274974823 and perplexity is 46.441002785963455
At time: 443.65059781074524 and batch: 1750, loss is 3.818328313827515 and perplexity is 45.528036082169535
At time: 444.5542664527893 and batch: 1800, loss is 3.7862674379348755 and perplexity is 44.09151842247814
At time: 445.45779180526733 and batch: 1850, loss is 3.8167095088958742 and perplexity is 45.45439469443424
At time: 446.3640949726105 and batch: 1900, loss is 3.882354335784912 and perplexity is 48.538356244345266
At time: 447.27444314956665 and batch: 1950, loss is 3.819908790588379 and perplexity is 45.600048977528864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3502552121184594 and perplexity of 77.49823889134476
finished 12 epochs...
Completing Train Step...
At time: 450.237811088562 and batch: 50, loss is 3.9720348596572874 and perplexity is 53.09245669368497
At time: 451.14287781715393 and batch: 100, loss is 3.9613613080978394 and perplexity is 52.52878515967012
At time: 452.02124214172363 and batch: 150, loss is 3.935269637107849 and perplexity is 51.175947030821014
At time: 452.9094204902649 and batch: 200, loss is 3.923709545135498 and perplexity is 50.587754705340366
At time: 453.8002014160156 and batch: 250, loss is 3.928289647102356 and perplexity is 50.81998318927216
At time: 454.700156211853 and batch: 300, loss is 3.9325392484664916 and perplexity is 51.03640739174937
At time: 455.60021924972534 and batch: 350, loss is 3.933229126930237 and perplexity is 51.07162845780643
At time: 456.49999237060547 and batch: 400, loss is 3.882694959640503 and perplexity is 48.554892382534945
At time: 457.40407538414 and batch: 450, loss is 3.9222560214996336 and perplexity is 50.51427762146633
At time: 458.30998706817627 and batch: 500, loss is 3.93678382396698 and perplexity is 51.25349567407024
At time: 459.2146759033203 and batch: 550, loss is 3.907823700904846 and perplexity is 49.79047501135094
At time: 460.1214280128479 and batch: 600, loss is 3.901274771690369 and perplexity is 49.465466106695565
At time: 461.0282051563263 and batch: 650, loss is 3.9441341400146483 and perplexity is 51.63161300438107
At time: 461.93455481529236 and batch: 700, loss is 3.9577125263214112 and perplexity is 52.337468334573806
At time: 462.84413743019104 and batch: 750, loss is 3.9257423639297486 and perplexity is 50.6906950379369
At time: 463.75943541526794 and batch: 800, loss is 3.9012145376205445 and perplexity is 49.46248669008829
At time: 464.6961302757263 and batch: 850, loss is 3.914310584068298 and perplexity is 50.11450985722335
At time: 465.60279417037964 and batch: 900, loss is 3.8773236227035524 and perplexity is 48.294786878126644
At time: 466.5081744194031 and batch: 950, loss is 3.9762144088745117 and perplexity is 53.31482360251574
At time: 467.41413021087646 and batch: 1000, loss is 3.9405059909820555 and perplexity is 51.444625232477094
At time: 468.3205075263977 and batch: 1050, loss is 3.880626540184021 and perplexity is 48.45456429447817
At time: 469.2270140647888 and batch: 1100, loss is 3.9090174531936643 and perplexity is 49.8499479958001
At time: 470.1329593658447 and batch: 1150, loss is 3.8809140396118162 and perplexity is 48.46849695670714
At time: 471.0396330356598 and batch: 1200, loss is 3.939736533164978 and perplexity is 51.40505598882956
At time: 471.9457178115845 and batch: 1250, loss is 3.9247044420242307 and perplexity is 50.63810934979072
At time: 472.8517782688141 and batch: 1300, loss is 3.920888414382935 and perplexity is 50.445241154038584
At time: 473.75795340538025 and batch: 1350, loss is 3.817528095245361 and perplexity is 45.49161827473408
At time: 474.66343545913696 and batch: 1400, loss is 3.8367121839523315 and perplexity is 46.372758426947826
At time: 475.5777039527893 and batch: 1450, loss is 3.751627607345581 and perplexity is 42.5903459774567
At time: 476.4827826023102 and batch: 1500, loss is 3.7860657739639283 and perplexity is 44.08262764829251
At time: 477.3880066871643 and batch: 1550, loss is 3.7753300619125367 and perplexity is 43.61190056773647
At time: 478.2946095466614 and batch: 1600, loss is 3.8598122930526735 and perplexity is 47.45644262878666
At time: 479.200471162796 and batch: 1650, loss is 3.8101263666152954 and perplexity is 45.156144734965416
At time: 480.1105332374573 and batch: 1700, loss is 3.8399006128311157 and perplexity is 46.52085063438091
At time: 481.0208787918091 and batch: 1750, loss is 3.820824103355408 and perplexity is 45.64180639216715
At time: 481.92648673057556 and batch: 1800, loss is 3.790371050834656 and perplexity is 44.2728246972038
At time: 482.83320212364197 and batch: 1850, loss is 3.821932430267334 and perplexity is 45.692420477795984
At time: 483.7392141819 and batch: 1900, loss is 3.8885622453689574 and perplexity is 48.84061519869054
At time: 484.6452841758728 and batch: 1950, loss is 3.825738801956177 and perplexity is 45.86667424040261
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348398040061773 and perplexity of 77.35444489406002
finished 13 epochs...
Completing Train Step...
At time: 487.61136198043823 and batch: 50, loss is 3.9612966108322145 and perplexity is 52.52538680083714
At time: 488.48725271224976 and batch: 100, loss is 3.949014902114868 and perplexity is 51.88423060602961
At time: 489.37152338027954 and batch: 150, loss is 3.9224713945388796 and perplexity is 50.52515820661326
At time: 490.25907039642334 and batch: 200, loss is 3.910227656364441 and perplexity is 49.91031308056865
At time: 491.1538190841675 and batch: 250, loss is 3.9146068572998045 and perplexity is 50.12935964469275
At time: 492.04270815849304 and batch: 300, loss is 3.91874849319458 and perplexity is 50.337407732303184
At time: 492.93223905563354 and batch: 350, loss is 3.9202271699905396 and perplexity is 50.411895547215224
At time: 493.8366906642914 and batch: 400, loss is 3.8695746278762817 and perplexity is 47.92199706300327
At time: 494.74570202827454 and batch: 450, loss is 3.9100069046020507 and perplexity is 49.89929650700341
At time: 495.64971017837524 and batch: 500, loss is 3.924896922111511 and perplexity is 50.64785711559339
At time: 496.5536184310913 and batch: 550, loss is 3.896301350593567 and perplexity is 49.22006426318289
At time: 497.45745944976807 and batch: 600, loss is 3.8901891613006594 and perplexity is 48.92013944576291
At time: 498.3711488246918 and batch: 650, loss is 3.9335143852233885 and perplexity is 51.086199141474154
At time: 499.2777268886566 and batch: 700, loss is 3.9475813484191895 and perplexity is 51.809905063054025
At time: 500.1818027496338 and batch: 750, loss is 3.9160189867019652 and perplexity is 50.20019879260855
At time: 501.08732986450195 and batch: 800, loss is 3.891675786972046 and perplexity is 48.9929194658299
At time: 501.99883127212524 and batch: 850, loss is 3.905319609642029 and perplexity is 49.66595109260062
At time: 502.90319776535034 and batch: 900, loss is 3.868469042778015 and perplexity is 47.86904449435038
At time: 503.8064091205597 and batch: 950, loss is 3.9677259016036985 and perplexity is 52.86417570464293
At time: 504.71088218688965 and batch: 1000, loss is 3.9325949859619143 and perplexity is 51.03925211255083
At time: 505.6157991886139 and batch: 1050, loss is 3.8732687282562255 and perplexity is 48.09935311440088
At time: 506.51936745643616 and batch: 1100, loss is 3.902050666809082 and perplexity is 49.5038610136769
At time: 507.42196822166443 and batch: 1150, loss is 3.874297318458557 and perplexity is 48.14885309098407
At time: 508.3261127471924 and batch: 1200, loss is 3.9338845682144163 and perplexity is 51.10511388421461
At time: 509.231369972229 and batch: 1250, loss is 3.919368624687195 and perplexity is 50.3686332250496
At time: 510.144234418869 and batch: 1300, loss is 3.9153318119049074 and perplexity is 50.16571433097443
At time: 511.05377554893494 and batch: 1350, loss is 3.8126994800567626 and perplexity is 45.272486233694316
At time: 511.9575569629669 and batch: 1400, loss is 3.832623620033264 and perplexity is 46.18354750406831
At time: 512.8639364242554 and batch: 1450, loss is 3.748221745491028 and perplexity is 42.4455358842879
At time: 513.7714333534241 and batch: 1500, loss is 3.78291175365448 and perplexity is 43.94380917861099
At time: 514.673122882843 and batch: 1550, loss is 3.7730208587646485 and perplexity is 43.51130801867567
At time: 515.5814964771271 and batch: 1600, loss is 3.858164358139038 and perplexity is 47.3783019032005
At time: 516.4934046268463 and batch: 1650, loss is 3.808415484428406 and perplexity is 45.07895394231471
At time: 517.3980836868286 and batch: 1700, loss is 3.839145884513855 and perplexity is 46.485753277214734
At time: 518.2997105121613 and batch: 1750, loss is 3.820205626487732 and perplexity is 45.61358671822196
At time: 519.2025809288025 and batch: 1800, loss is 3.7907005167007446 and perplexity is 44.28741348485867
At time: 520.1131720542908 and batch: 1850, loss is 3.8227106046676638 and perplexity is 45.72799098793611
At time: 521.0199031829834 and batch: 1900, loss is 3.8897630405426025 and perplexity is 48.8992979996598
At time: 521.93181681633 and batch: 1950, loss is 3.826662664413452 and perplexity is 45.909068318906805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3477076330850295 and perplexity of 77.30105727733523
finished 14 epochs...
Completing Train Step...
At time: 524.9085862636566 and batch: 50, loss is 3.952200102806091 and perplexity is 52.04975576870614
At time: 525.8184821605682 and batch: 100, loss is 3.9392719078063965 and perplexity is 51.38117744397615
At time: 526.702778339386 and batch: 150, loss is 3.9122503423690795 and perplexity is 50.011368139196705
At time: 527.6021811962128 and batch: 200, loss is 3.900048351287842 and perplexity is 49.40483783531558
At time: 528.4918863773346 and batch: 250, loss is 3.904435453414917 and perplexity is 49.622058039684084
At time: 529.3803670406342 and batch: 300, loss is 3.9087294864654543 and perplexity is 49.83559493607532
At time: 530.2695753574371 and batch: 350, loss is 3.9106206560134886 and perplexity is 49.92993167089022
At time: 531.1718842983246 and batch: 400, loss is 3.859906530380249 and perplexity is 47.46091500784546
At time: 532.0780675411224 and batch: 450, loss is 3.9010607290267942 and perplexity is 49.454879519606195
At time: 532.9761760234833 and batch: 500, loss is 3.916293210983276 and perplexity is 50.21396679371795
At time: 533.909051656723 and batch: 550, loss is 3.8878567171096803 and perplexity is 48.80616891730872
At time: 534.8090054988861 and batch: 600, loss is 3.882025818824768 and perplexity is 48.52241319002674
At time: 535.709046125412 and batch: 650, loss is 3.9254266214370728 and perplexity is 50.674692358026114
At time: 536.6088225841522 and batch: 700, loss is 3.9399355363845827 and perplexity is 51.415286778421574
At time: 537.5128214359283 and batch: 750, loss is 3.9087195873260496 and perplexity is 49.835101609015496
At time: 538.4109768867493 and batch: 800, loss is 3.884439172744751 and perplexity is 48.639656363837744
At time: 539.3094620704651 and batch: 850, loss is 3.8985567331314086 and perplexity is 49.331199615890625
At time: 540.2087669372559 and batch: 900, loss is 3.86170569896698 and perplexity is 47.546382056985294
At time: 541.1081027984619 and batch: 950, loss is 3.961154594421387 and perplexity is 52.51792786358464
At time: 542.0079522132874 and batch: 1000, loss is 3.926527152061462 and perplexity is 50.730492107882505
At time: 542.909321308136 and batch: 1050, loss is 3.867450213432312 and perplexity is 47.82029894298443
At time: 543.814906835556 and batch: 1100, loss is 3.896491775512695 and perplexity is 49.22943788239671
At time: 544.7253246307373 and batch: 1150, loss is 3.8688855743408204 and perplexity is 47.88898761544497
At time: 545.6323132514954 and batch: 1200, loss is 3.9289553213119506 and perplexity is 50.85382400364233
At time: 546.5363368988037 and batch: 1250, loss is 3.914739556312561 and perplexity is 50.13601220261187
At time: 547.4425532817841 and batch: 1300, loss is 3.9105737733840944 and perplexity is 49.92759087927968
At time: 548.3631579875946 and batch: 1350, loss is 3.808331995010376 and perplexity is 45.075190483791324
At time: 549.2759068012238 and batch: 1400, loss is 3.828836555480957 and perplexity is 46.008978189684385
At time: 550.1866540908813 and batch: 1450, loss is 3.7447582387924196 and perplexity is 42.29877977851003
At time: 551.0989799499512 and batch: 1500, loss is 3.7795662450790406 and perplexity is 43.79704043310634
At time: 552.0074803829193 and batch: 1550, loss is 3.7701766109466552 and perplexity is 43.387726906751126
At time: 552.9177632331848 and batch: 1600, loss is 3.8556112670898437 and perplexity is 47.257495065734126
At time: 553.8277034759521 and batch: 1650, loss is 3.8059857273101807 and perplexity is 44.969555992136534
At time: 554.7380561828613 and batch: 1700, loss is 3.837381725311279 and perplexity is 46.403817303083954
At time: 555.6485457420349 and batch: 1750, loss is 3.8184215354919435 and perplexity is 45.53228047930309
At time: 556.5588803291321 and batch: 1800, loss is 3.7897087430953977 and perplexity is 44.243512170796066
At time: 557.4779903888702 and batch: 1850, loss is 3.8219150495529175 and perplexity is 45.69162631778621
At time: 558.3876903057098 and batch: 1900, loss is 3.8892813873291017 and perplexity is 48.87575116679941
At time: 559.298168182373 and batch: 1950, loss is 3.8258953666687012 and perplexity is 45.87385590525248
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34747314453125 and perplexity of 77.28293318923728
finished 15 epochs...
Completing Train Step...
At time: 562.2687931060791 and batch: 50, loss is 3.944232931137085 and perplexity is 51.63671400134546
At time: 563.1527624130249 and batch: 100, loss is 3.930822515487671 and perplexity is 50.948866671579864
At time: 564.0392348766327 and batch: 150, loss is 3.903849968910217 and perplexity is 49.59301359697579
At time: 564.9245221614838 and batch: 200, loss is 3.8916213083267213 and perplexity is 48.99025047064918
At time: 565.8093614578247 and batch: 250, loss is 3.8959783935546874 and perplexity is 49.20417086355578
At time: 566.6980390548706 and batch: 300, loss is 3.900428252220154 and perplexity is 49.42361034489111
At time: 567.5870990753174 and batch: 350, loss is 3.9025452661514284 and perplexity is 49.52835164680412
At time: 568.4792022705078 and batch: 400, loss is 3.8518249797821045 and perplexity is 47.078902925904934
At time: 569.3820233345032 and batch: 450, loss is 3.8935420322418213 and perplexity is 49.08443764115422
At time: 570.2882127761841 and batch: 500, loss is 3.9090647745132445 and perplexity is 49.852307016935825
At time: 571.1883256435394 and batch: 550, loss is 3.8807531452178954 and perplexity is 48.460699274583526
At time: 572.1018190383911 and batch: 600, loss is 3.8750827503204346 and perplexity is 48.186685589794656
At time: 573.0044293403625 and batch: 650, loss is 3.9185983657836916 and perplexity is 50.32985127483938
At time: 573.911562204361 and batch: 700, loss is 3.933421049118042 and perplexity is 51.081431177124415
At time: 574.8198373317719 and batch: 750, loss is 3.902424488067627 and perplexity is 49.52237006862743
At time: 575.726824760437 and batch: 800, loss is 3.8782685470581053 and perplexity is 48.340443366012245
At time: 576.6354677677155 and batch: 850, loss is 3.8927544450759886 and perplexity is 49.04579458741002
At time: 577.543523311615 and batch: 900, loss is 3.8558017301559446 and perplexity is 47.266496730355705
At time: 578.4523577690125 and batch: 950, loss is 3.95542290687561 and perplexity is 52.217772530541886
At time: 579.3883578777313 and batch: 1000, loss is 3.9210433626174925 and perplexity is 50.45305816069729
At time: 580.298098564148 and batch: 1050, loss is 3.862320990562439 and perplexity is 47.57564594824938
At time: 581.2048695087433 and batch: 1100, loss is 3.8914357233047485 and perplexity is 48.98115945754316
At time: 582.1114864349365 and batch: 1150, loss is 3.8640145111083983 and perplexity is 47.65628454443704
At time: 583.017187833786 and batch: 1200, loss is 3.9244474077224734 and perplexity is 50.625095291313045
At time: 583.929931640625 and batch: 1250, loss is 3.910417637825012 and perplexity is 49.91979601550766
At time: 584.8373250961304 and batch: 1300, loss is 3.906223793029785 and perplexity is 49.71087852877553
At time: 585.7444124221802 and batch: 1350, loss is 3.8042774057388304 and perplexity is 44.89279911096609
At time: 586.6503219604492 and batch: 1400, loss is 3.825127625465393 and perplexity is 45.83865017209463
At time: 587.5561182498932 and batch: 1450, loss is 3.741265835762024 and perplexity is 42.151313048343305
At time: 588.4609508514404 and batch: 1500, loss is 3.7761233854293823 and perplexity is 43.64651264154195
At time: 589.3661289215088 and batch: 1550, loss is 3.7670808124542234 and perplexity is 43.253614946116315
At time: 590.2722828388214 and batch: 1600, loss is 3.8527933883666994 and perplexity is 47.12451662243457
At time: 591.1786377429962 and batch: 1650, loss is 3.8031978893280027 and perplexity is 44.84436274622691
At time: 592.0843040943146 and batch: 1700, loss is 3.835132346153259 and perplexity is 46.29955483046772
At time: 592.9913334846497 and batch: 1750, loss is 3.81614164352417 and perplexity is 45.42859004517231
At time: 593.8967266082764 and batch: 1800, loss is 3.788021969795227 and perplexity is 44.168946301299066
At time: 594.8031225204468 and batch: 1850, loss is 3.8204034852981565 and perplexity is 45.622612661130944
At time: 595.7104043960571 and batch: 1900, loss is 3.8880758142471312 and perplexity is 48.816863380728826
At time: 596.6246395111084 and batch: 1950, loss is 3.824391760826111 and perplexity is 45.80493153801736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347392237463663 and perplexity of 77.27668070667686
finished 16 epochs...
Completing Train Step...
At time: 599.5508201122284 and batch: 50, loss is 3.937044596672058 and perplexity is 51.266862929613815
At time: 600.4525418281555 and batch: 100, loss is 3.923320713043213 and perplexity is 50.56808838652999
At time: 601.3280789852142 and batch: 150, loss is 3.896403670310974 and perplexity is 49.22510070390827
At time: 602.2425518035889 and batch: 200, loss is 3.884196376800537 and perplexity is 48.62784828607936
At time: 603.1292209625244 and batch: 250, loss is 3.888557415008545 and perplexity is 48.84037928148614
At time: 604.0144650936127 and batch: 300, loss is 3.8930540227890016 and perplexity is 49.060489815456926
At time: 604.9098896980286 and batch: 350, loss is 3.895438747406006 and perplexity is 49.177625185530864
At time: 605.801698923111 and batch: 400, loss is 3.8447216653823855 and perplexity is 46.74567160141655
At time: 606.6904263496399 and batch: 450, loss is 3.886864867210388 and perplexity is 48.75778452257834
At time: 607.5885725021362 and batch: 500, loss is 3.9027219867706298 and perplexity is 49.53710510121033
At time: 608.4848415851593 and batch: 550, loss is 3.874447913169861 and perplexity is 48.15610459962063
At time: 609.3963758945465 and batch: 600, loss is 3.868906469345093 and perplexity is 47.889988266500076
At time: 610.303017616272 and batch: 650, loss is 3.9124886131286623 and perplexity is 50.02328580563034
At time: 611.2058312892914 and batch: 700, loss is 3.927556118965149 and perplexity is 50.78271897051779
At time: 612.1124324798584 and batch: 750, loss is 3.8967928075790406 and perplexity is 49.24425975262466
At time: 613.0230178833008 and batch: 800, loss is 3.8727558851242065 and perplexity is 48.07469201567966
At time: 613.9323356151581 and batch: 850, loss is 3.887496566772461 and perplexity is 48.78859452401657
At time: 614.8391439914703 and batch: 900, loss is 3.850427827835083 and perplexity is 47.01317247342554
At time: 615.7425947189331 and batch: 950, loss is 3.9502138805389406 and perplexity is 51.94647598705353
At time: 616.6468658447266 and batch: 1000, loss is 3.915987410545349 and perplexity is 50.198613688295204
At time: 617.5520970821381 and batch: 1050, loss is 3.8575762271881104 and perplexity is 47.35044544987299
At time: 618.454644203186 and batch: 1100, loss is 3.8867381525039675 and perplexity is 48.751606585652844
At time: 619.357711315155 and batch: 1150, loss is 3.8594159126281737 and perplexity is 47.437635551537085
At time: 620.2675819396973 and batch: 1200, loss is 3.9201425552368163 and perplexity is 50.40763013754962
At time: 621.1782796382904 and batch: 1250, loss is 3.9062571239471438 and perplexity is 49.712535465573055
At time: 622.0839078426361 and batch: 1300, loss is 3.902025957107544 and perplexity is 49.502637803158905
At time: 622.9925320148468 and batch: 1350, loss is 3.8002882862091063 and perplexity is 44.714073086033466
At time: 623.895988702774 and batch: 1400, loss is 3.8214607715606688 and perplexity is 45.67087433146221
At time: 624.7992789745331 and batch: 1450, loss is 3.737776002883911 and perplexity is 42.004468390902574
At time: 625.7025575637817 and batch: 1500, loss is 3.7726297903060915 and perplexity is 43.49429544527625
At time: 626.6047313213348 and batch: 1550, loss is 3.763957495689392 and perplexity is 43.11873095777724
At time: 627.5121402740479 and batch: 1600, loss is 3.8499055814743044 and perplexity is 46.988626425292686
At time: 628.420440196991 and batch: 1650, loss is 3.800272989273071 and perplexity is 44.71338910294903
At time: 629.3241727352142 and batch: 1700, loss is 3.8326531934738157 and perplexity is 46.184913330660876
At time: 630.2274265289307 and batch: 1750, loss is 3.8135929012298586 and perplexity is 45.31295170511704
At time: 631.1351189613342 and batch: 1800, loss is 3.7859515523910523 and perplexity is 44.077592748778564
At time: 632.0386116504669 and batch: 1850, loss is 3.8184886503219606 and perplexity is 45.53533647311786
At time: 632.9428203105927 and batch: 1900, loss is 3.8863879203796388 and perplexity is 48.734535196562845
At time: 633.8466548919678 and batch: 1950, loss is 3.822479877471924 and perplexity is 45.71744151388073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347534747456395 and perplexity of 77.28769419062984
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 636.8318336009979 and batch: 50, loss is 3.940322608947754 and perplexity is 51.435192077410115
At time: 637.7066111564636 and batch: 100, loss is 3.9382181644439695 and perplexity is 51.32706338546311
At time: 638.5832850933075 and batch: 150, loss is 3.921421332359314 and perplexity is 50.47213149440883
At time: 639.4656176567078 and batch: 200, loss is 3.9066416215896607 and perplexity is 49.7316534934459
At time: 640.3610827922821 and batch: 250, loss is 3.913272943496704 and perplexity is 50.06253597833599
At time: 641.2499921321869 and batch: 300, loss is 3.9111636018753053 and perplexity is 49.95704828143132
At time: 642.1465699672699 and batch: 350, loss is 3.915355839729309 and perplexity is 50.16691971843073
At time: 643.0501792430878 and batch: 400, loss is 3.867799472808838 and perplexity is 47.83700354772865
At time: 643.9564383029938 and batch: 450, loss is 3.9107132291793825 and perplexity is 49.934554056689
At time: 644.8604650497437 and batch: 500, loss is 3.9246686363220213 and perplexity is 50.636296249186756
At time: 645.7739326953888 and batch: 550, loss is 3.8951230525970457 and perplexity is 49.162102514885
At time: 646.6782848834991 and batch: 600, loss is 3.887429699897766 and perplexity is 48.78533229224882
At time: 647.5819864273071 and batch: 650, loss is 3.9253685426712037 and perplexity is 50.671749319898005
At time: 648.5131866931915 and batch: 700, loss is 3.9386532354354857 and perplexity is 51.349399160293366
At time: 649.4176087379456 and batch: 750, loss is 3.905705327987671 and perplexity is 49.68511185618226
At time: 650.32177901268 and batch: 800, loss is 3.8779887199401855 and perplexity is 48.32691829149574
At time: 651.2248892784119 and batch: 850, loss is 3.8920214939117432 and perplexity is 49.009859586075116
At time: 652.1349701881409 and batch: 900, loss is 3.8494658851623536 and perplexity is 46.96797024110664
At time: 653.0527889728546 and batch: 950, loss is 3.9531311559677125 and perplexity is 52.09823942530472
At time: 653.9570350646973 and batch: 1000, loss is 3.917884340286255 and perplexity is 50.293927304588586
At time: 654.8622739315033 and batch: 1050, loss is 3.8603135681152345 and perplexity is 47.48023732337958
At time: 655.7662060260773 and batch: 1100, loss is 3.8871644163131713 and perplexity is 48.77239206091405
At time: 656.6712305545807 and batch: 1150, loss is 3.862067141532898 and perplexity is 47.5635704494373
At time: 657.5846664905548 and batch: 1200, loss is 3.9195223236083985 and perplexity is 50.37637542460741
At time: 658.4891412258148 and batch: 1250, loss is 3.9048019886016845 and perplexity is 49.64024960371594
At time: 659.3938891887665 and batch: 1300, loss is 3.9042230653762817 and perplexity is 49.6115200272175
At time: 660.2987856864929 and batch: 1350, loss is 3.8025234746932983 and perplexity is 44.8141292478097
At time: 661.2024638652802 and batch: 1400, loss is 3.821476101875305 and perplexity is 45.67157448570221
At time: 662.1037843227386 and batch: 1450, loss is 3.7281063270568846 and perplexity is 41.600256248039365
At time: 663.0069055557251 and batch: 1500, loss is 3.765482950210571 and perplexity is 43.18455681527544
At time: 663.9095458984375 and batch: 1550, loss is 3.7539082670211794 and perplexity is 42.68759091124596
At time: 664.8230016231537 and batch: 1600, loss is 3.839650731086731 and perplexity is 46.509227375354726
At time: 665.7273392677307 and batch: 1650, loss is 3.7913458585739135 and perplexity is 44.31600323132284
At time: 666.6306245326996 and batch: 1700, loss is 3.821834154129028 and perplexity is 45.6879302238076
At time: 667.5337090492249 and batch: 1750, loss is 3.8013808155059814 and perplexity is 44.76295121639544
At time: 668.4360852241516 and batch: 1800, loss is 3.774256110191345 and perplexity is 43.56508863343532
At time: 669.3394804000854 and batch: 1850, loss is 3.8009249353408814 and perplexity is 44.742549325566564
At time: 670.2433643341064 and batch: 1900, loss is 3.871710767745972 and perplexity is 48.024474565736526
At time: 671.1467368602753 and batch: 1950, loss is 3.8097357082366945 and perplexity is 45.13850755395996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335519622093023 and perplexity of 76.36462933058203
finished 18 epochs...
Completing Train Step...
At time: 674.1115667819977 and batch: 50, loss is 3.943213357925415 and perplexity is 51.58409342083654
At time: 675.0140357017517 and batch: 100, loss is 3.9306964588165285 and perplexity is 50.942444631827755
At time: 675.8912539482117 and batch: 150, loss is 3.9075232315063477 and perplexity is 49.77551674463657
At time: 676.770262002945 and batch: 200, loss is 3.8931467437744143 and perplexity is 49.06503896331492
At time: 677.658793926239 and batch: 250, loss is 3.8990782737731933 and perplexity is 49.356934551722446
At time: 678.5528039932251 and batch: 300, loss is 3.8976931095123293 and perplexity is 49.288614418182945
At time: 679.4518792629242 and batch: 350, loss is 3.903001656532288 and perplexity is 49.55096106904451
At time: 680.3510179519653 and batch: 400, loss is 3.854836564064026 and perplexity is 47.2208987187948
At time: 681.256424665451 and batch: 450, loss is 3.897941818237305 and perplexity is 49.30087445115609
At time: 682.1578032970428 and batch: 500, loss is 3.9124300336837767 and perplexity is 50.02035555514355
At time: 683.0558059215546 and batch: 550, loss is 3.883099761009216 and perplexity is 48.574551448169004
At time: 683.9579420089722 and batch: 600, loss is 3.8763043165206907 and perplexity is 48.24558478352142
At time: 684.8558008670807 and batch: 650, loss is 3.9162445211410524 and perplexity is 50.21152194311751
At time: 685.7536256313324 and batch: 700, loss is 3.930889439582825 and perplexity is 50.95227649247931
At time: 686.6524791717529 and batch: 750, loss is 3.8994706678390503 and perplexity is 49.37630572026667
At time: 687.5519173145294 and batch: 800, loss is 3.8717157506942748 and perplexity is 48.02471386980678
At time: 688.4518795013428 and batch: 850, loss is 3.886025514602661 and perplexity is 48.71687671942962
At time: 689.3520798683167 and batch: 900, loss is 3.8436609268188477 and perplexity is 46.696112953901554
At time: 690.2519571781158 and batch: 950, loss is 3.9477447271347046 and perplexity is 51.8183703903025
At time: 691.153525352478 and batch: 1000, loss is 3.9130569314956665 and perplexity is 50.05172303766681
At time: 692.057338476181 and batch: 1050, loss is 3.8561630392074586 and perplexity is 47.283577629013564
At time: 692.961807012558 and batch: 1100, loss is 3.8839629220962526 and perplexity is 48.616497211170206
At time: 693.9019768238068 and batch: 1150, loss is 3.8586545181274414 and perplexity is 47.401530543521915
At time: 694.8098390102386 and batch: 1200, loss is 3.916951994895935 and perplexity is 50.24705784596209
At time: 695.7147290706635 and batch: 1250, loss is 3.902175488471985 and perplexity is 49.510040553590926
At time: 696.6191055774689 and batch: 1300, loss is 3.9013760566711424 and perplexity is 49.47047646921209
At time: 697.5242168903351 and batch: 1350, loss is 3.800023984909058 and perplexity is 44.70225666000353
At time: 698.4288847446442 and batch: 1400, loss is 3.819713816642761 and perplexity is 45.59115902274229
At time: 699.3328790664673 and batch: 1450, loss is 3.72708890914917 and perplexity is 41.55795292609489
At time: 700.2364213466644 and batch: 1500, loss is 3.765229163169861 and perplexity is 43.17359852499176
At time: 701.1453931331635 and batch: 1550, loss is 3.7544497299194335 and perplexity is 42.710710916687965
At time: 702.0519382953644 and batch: 1600, loss is 3.841006665229797 and perplexity is 46.57233359899354
At time: 702.9643776416779 and batch: 1650, loss is 3.7927900075912477 and perplexity is 44.38004837807855
At time: 703.8687672615051 and batch: 1700, loss is 3.8239358282089233 and perplexity is 45.78405233581747
At time: 704.7715842723846 and batch: 1750, loss is 3.803908123970032 and perplexity is 44.876224079320934
At time: 705.6742169857025 and batch: 1800, loss is 3.777146224975586 and perplexity is 43.69117886001876
At time: 706.5784592628479 and batch: 1850, loss is 3.8041070318222046 and perplexity is 44.885151200473985
At time: 707.4911780357361 and batch: 1900, loss is 3.875004405975342 and perplexity is 48.182910583347066
At time: 708.3958828449249 and batch: 1950, loss is 3.812830047607422 and perplexity is 45.278397737250984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3347681799600295 and perplexity of 76.30726728546057
finished 19 epochs...
Completing Train Step...
At time: 711.3569266796112 and batch: 50, loss is 3.940622673034668 and perplexity is 51.450628247160324
At time: 712.2350816726685 and batch: 100, loss is 3.927037501335144 and perplexity is 50.7563889853475
At time: 713.1198122501373 and batch: 150, loss is 3.9032739067077635 and perplexity is 49.56445316341974
At time: 714.0088546276093 and batch: 200, loss is 3.8886113119125367 and perplexity is 48.843011697658106
At time: 714.9015209674835 and batch: 250, loss is 3.894423370361328 and perplexity is 49.12771669606091
At time: 715.8114984035492 and batch: 300, loss is 3.8926655673980712 and perplexity is 49.04143570478203
At time: 716.7120554447174 and batch: 350, loss is 3.898310618400574 and perplexity is 49.31905997490892
At time: 717.6378395557404 and batch: 400, loss is 3.8499052000045775 and perplexity is 46.98860850055761
At time: 718.547367811203 and batch: 450, loss is 3.8932820177078247 and perplexity is 49.07167663307015
At time: 719.4472575187683 and batch: 500, loss is 3.9079527139663695 and perplexity is 49.79689904735022
At time: 720.3472881317139 and batch: 550, loss is 3.8787138080596923 and perplexity is 48.36197227287819
At time: 721.247314453125 and batch: 600, loss is 3.8721329879760744 and perplexity is 48.044755751700436
At time: 722.1471276283264 and batch: 650, loss is 3.912468600273132 and perplexity is 50.02228470685583
At time: 723.0465145111084 and batch: 700, loss is 3.9273689556121827 and perplexity is 50.77321519596943
At time: 723.9551584720612 and batch: 750, loss is 3.896348180770874 and perplexity is 49.22236930149166
At time: 724.8585529327393 and batch: 800, loss is 3.86863356590271 and perplexity is 47.87692070701855
At time: 725.7642998695374 and batch: 850, loss is 3.8830009508132934 and perplexity is 48.56975202434346
At time: 726.6699013710022 and batch: 900, loss is 3.840896611213684 and perplexity is 46.56720840867027
At time: 727.576758146286 and batch: 950, loss is 3.945128288269043 and perplexity is 51.68296800533358
At time: 728.4830369949341 and batch: 1000, loss is 3.910732979774475 and perplexity is 49.93554030358676
At time: 729.3890419006348 and batch: 1050, loss is 3.8541406106948854 and perplexity is 47.188046608332094
At time: 730.2957286834717 and batch: 1100, loss is 3.882264323234558 and perplexity is 48.53398737973898
At time: 731.2025241851807 and batch: 1150, loss is 3.857028851509094 and perplexity is 47.324534059922435
At time: 732.1081416606903 and batch: 1200, loss is 3.9156336975097656 and perplexity is 50.18086092414257
At time: 733.013697385788 and batch: 1250, loss is 3.9008597469329835 and perplexity is 49.44494097313958
At time: 733.9199361801147 and batch: 1300, loss is 3.900091428756714 and perplexity is 49.40696611651972
At time: 734.8248794078827 and batch: 1350, loss is 3.7987728929519653 and perplexity is 44.64636499632804
At time: 735.7315428256989 and batch: 1400, loss is 3.8188520002365114 and perplexity is 45.55188473995801
At time: 736.6395499706268 and batch: 1450, loss is 3.726530156135559 and perplexity is 41.53473878074874
At time: 737.5441446304321 and batch: 1500, loss is 3.764949517250061 and perplexity is 43.161526892291256
At time: 738.4584560394287 and batch: 1550, loss is 3.754369339942932 and perplexity is 42.70727754164733
At time: 739.3765387535095 and batch: 1600, loss is 3.841339783668518 and perplexity is 46.58785028635347
At time: 740.2983155250549 and batch: 1650, loss is 3.793068470954895 and perplexity is 44.39240831644387
At time: 741.2096238136292 and batch: 1700, loss is 3.82457661151886 and perplexity is 45.81339939396389
At time: 742.1212735176086 and batch: 1750, loss is 3.804572286605835 and perplexity is 44.90603909050257
At time: 743.0272846221924 and batch: 1800, loss is 3.7781007623672487 and perplexity is 43.73290363468717
At time: 743.9409251213074 and batch: 1850, loss is 3.8051867055892945 and perplexity is 44.933638691382846
At time: 744.8462820053101 and batch: 1900, loss is 3.8761021184921263 and perplexity is 48.235830607562065
At time: 745.7514243125916 and batch: 1950, loss is 3.813819937705994 and perplexity is 45.32324056592461
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334438590116279 and perplexity of 76.28212132931245
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
3092.852302312851


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}, {'best_accuracy': -75.95030619273909, 'params': {'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}}, {'best_accuracy': -76.28212132931245, 'params': {'wordvec_dim': 300, 'dropout': 0.022236433569113312, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5875562008890167}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.968078670033271, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.28515311562638934}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.28560209274292 and batch: 50, loss is 9.488563385009765 and perplexity is 13207.807156812474
At time: 2.103624105453491 and batch: 100, loss is 8.308540878295899 and perplexity is 4058.386980849893
At time: 2.9214940071105957 and batch: 150, loss is 7.8733939361572265 and perplexity is 2626.4645313615606
At time: 3.7411727905273438 and batch: 200, loss is 7.708084316253662 and perplexity is 2226.2733348951397
At time: 4.564754247665405 and batch: 250, loss is 7.582130708694458 and perplexity is 1962.8066823221864
At time: 5.389953851699829 and batch: 300, loss is 7.433305425643921 and perplexity is 1691.389104536607
At time: 6.2143073081970215 and batch: 350, loss is 7.365741071701049 and perplexity is 1580.8865428023894
At time: 7.038448333740234 and batch: 400, loss is 7.3059178066253665 and perplexity is 1489.0860278837424
At time: 7.862871885299683 and batch: 450, loss is 7.207076625823975 and perplexity is 1348.943032415169
At time: 8.687209129333496 and batch: 500, loss is 7.177905683517456 and perplexity is 1310.1614901451833
At time: 9.537926435470581 and batch: 550, loss is 7.126289052963257 and perplexity is 1244.251039228634
At time: 10.362415552139282 and batch: 600, loss is 7.164648542404175 and perplexity is 1292.907118912746
At time: 11.18683648109436 and batch: 650, loss is 7.234047956466675 and perplexity is 1385.8209081011923
At time: 12.011922121047974 and batch: 700, loss is 7.095289554595947 and perplexity is 1206.2715944117342
At time: 12.83771800994873 and batch: 750, loss is 7.0481281566619876 and perplexity is 1150.7027902582265
At time: 13.662665843963623 and batch: 800, loss is 7.039915323257446 and perplexity is 1141.2909617362925
At time: 14.490474939346313 and batch: 850, loss is 7.079760475158691 and perplexity is 1187.6840046136506
At time: 15.316303253173828 and batch: 900, loss is 7.050068826675415 and perplexity is 1152.9380929485492
At time: 16.142436981201172 and batch: 950, loss is 7.053635196685791 and perplexity is 1157.0572376181228
At time: 16.970686435699463 and batch: 1000, loss is 7.047886648178101 and perplexity is 1150.424919327391
At time: 17.796406984329224 and batch: 1050, loss is 6.966045999526978 and perplexity is 1060.0231214182832
At time: 18.632079124450684 and batch: 1100, loss is 7.007175579071045 and perplexity is 1104.5304362542608
At time: 19.47331738471985 and batch: 1150, loss is 6.929643840789795 and perplexity is 1022.1298738180801
At time: 20.31048274040222 and batch: 1200, loss is 7.00615779876709 and perplexity is 1103.4068388157864
At time: 21.169605255126953 and batch: 1250, loss is 6.9258672142028805 and perplexity is 1018.2769510660801
At time: 22.056164264678955 and batch: 1300, loss is 6.952795629501343 and perplexity is 1046.070068527532
At time: 22.972426176071167 and batch: 1350, loss is 6.958396997451782 and perplexity is 1051.945932959564
At time: 23.905779600143433 and batch: 1400, loss is 6.985769853591919 and perplexity is 1081.1384157257862
At time: 24.83222198486328 and batch: 1450, loss is 6.98994924545288 and perplexity is 1085.6663722824974
At time: 25.754581212997437 and batch: 1500, loss is 6.951897563934327 and perplexity is 1045.1310507311875
At time: 26.676469802856445 and batch: 1550, loss is 6.927283420562744 and perplexity is 1019.7200629912282
At time: 27.59868884086609 and batch: 1600, loss is 6.89980146408081 and perplexity is 992.0777329869842
At time: 28.52134609222412 and batch: 1650, loss is 6.898060007095337 and perplexity is 990.3515757392789
At time: 29.4437575340271 and batch: 1700, loss is 6.912534513473511 and perplexity is 1004.7906732481092
At time: 30.366899013519287 and batch: 1750, loss is 6.932695627212524 and perplexity is 1025.2539604872493
At time: 31.299045085906982 and batch: 1800, loss is 6.936665725708008 and perplexity is 1029.3324102599875
At time: 32.2209734916687 and batch: 1850, loss is 6.871857709884644 and perplexity is 964.739107519698
At time: 33.15069508552551 and batch: 1900, loss is 6.817717323303222 and perplexity is 913.8964970509217
At time: 34.08145570755005 and batch: 1950, loss is 6.780766153335572 and perplexity is 880.7432500584688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.266614621184593 and perplexity of 526.6913067277306
finished 1 epochs...
Completing Train Step...
At time: 37.14736723899841 and batch: 50, loss is 6.414384107589722 and perplexity is 610.5646028886728
At time: 38.09227728843689 and batch: 100, loss is 6.065098304748535 and perplexity is 430.565002176082
At time: 39.01152682304382 and batch: 150, loss is 5.8394727039337155 and perplexity is 343.59811495496507
At time: 39.953805685043335 and batch: 200, loss is 5.733050012588501 and perplexity is 308.91001243416287
At time: 40.87212777137756 and batch: 250, loss is 5.684496688842773 and perplexity is 294.26969854950715
At time: 41.79553294181824 and batch: 300, loss is 5.6426045608520505 and perplexity is 282.19676076707856
At time: 42.72320580482483 and batch: 350, loss is 5.59670506477356 and perplexity is 269.5368362746359
At time: 43.641268491744995 and batch: 400, loss is 5.533829545974731 and perplexity is 253.11135898391123
At time: 44.55888652801514 and batch: 450, loss is 5.4533625507354735 and perplexity is 233.54214439465426
At time: 45.476778984069824 and batch: 500, loss is 5.422377834320068 and perplexity is 226.4168647092729
At time: 46.39414310455322 and batch: 550, loss is 5.374493417739868 and perplexity is 215.83050870521635
At time: 47.31193995475769 and batch: 600, loss is 5.37539589881897 and perplexity is 216.02537957602618
At time: 48.23045110702515 and batch: 650, loss is 5.450093574523926 and perplexity is 232.7799471612961
At time: 49.14955711364746 and batch: 700, loss is 5.399311428070068 and perplexity is 221.2540144366932
At time: 50.06766319274902 and batch: 750, loss is 5.329424743652344 and perplexity is 206.31925355194204
At time: 50.98534917831421 and batch: 800, loss is 5.319845037460327 and perplexity is 204.35221260139426
At time: 51.910210371017456 and batch: 850, loss is 5.3233154773712155 and perplexity is 205.06263670493968
At time: 52.8297963142395 and batch: 900, loss is 5.340924949645996 and perplexity is 208.7056632688025
At time: 53.75348234176636 and batch: 950, loss is 5.36331335067749 and perplexity is 213.4309477640607
At time: 54.67158555984497 and batch: 1000, loss is 5.339629888534546 and perplexity is 208.4355516238595
At time: 55.59007978439331 and batch: 1050, loss is 5.221971216201783 and perplexity is 185.2990888655499
At time: 56.507317781448364 and batch: 1100, loss is 5.307116613388062 and perplexity is 201.76761480244713
At time: 57.42587852478027 and batch: 1150, loss is 5.200997304916382 and perplexity is 181.45311575138817
At time: 58.34286570549011 and batch: 1200, loss is 5.291372919082642 and perplexity is 198.61592189805438
At time: 59.26026153564453 and batch: 1250, loss is 5.231234722137451 and perplexity is 187.02358317484584
At time: 60.17831778526306 and batch: 1300, loss is 5.256779527664184 and perplexity is 191.86260706403579
At time: 61.09695243835449 and batch: 1350, loss is 5.2018639087677006 and perplexity is 181.61043187586637
At time: 62.01445531845093 and batch: 1400, loss is 5.1979718589782715 and perplexity is 180.90496877202057
At time: 62.93241262435913 and batch: 1450, loss is 5.143543090820312 and perplexity is 171.32170259915097
At time: 63.859089612960815 and batch: 1500, loss is 5.115264539718628 and perplexity is 166.54483287955247
At time: 64.77764105796814 and batch: 1550, loss is 5.107047929763794 and perplexity is 165.18200552552526
At time: 65.69866585731506 and batch: 1600, loss is 5.157707271575927 and perplexity is 173.7656012143994
At time: 66.62250208854675 and batch: 1650, loss is 5.132837715148926 and perplexity is 169.497421641278
At time: 67.54027938842773 and batch: 1700, loss is 5.151127414703369 and perplexity is 172.62600174127826
At time: 68.45764875411987 and batch: 1750, loss is 5.15818148612976 and perplexity is 173.84802293269541
At time: 69.38440656661987 and batch: 1800, loss is 5.1213118267059325 and perplexity is 167.55502867362503
At time: 70.3010241985321 and batch: 1850, loss is 5.105037641525269 and perplexity is 164.85027563067152
At time: 71.2283718585968 and batch: 1900, loss is 5.172050800323486 and perplexity is 176.27597387242295
At time: 72.14726209640503 and batch: 1950, loss is 5.099815130233765 and perplexity is 163.99158741094348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.872222474563953 and perplexity of 130.61087391110615
finished 2 epochs...
Completing Train Step...
At time: 75.17826652526855 and batch: 50, loss is 5.09267786026001 and perplexity is 162.82530217540037
At time: 76.09808015823364 and batch: 100, loss is 5.045983219146729 and perplexity is 155.39701342922768
At time: 77.01597905158997 and batch: 150, loss is 4.9911469459533695 and perplexity is 147.10504831531773
At time: 77.93495202064514 and batch: 200, loss is 4.954930868148804 and perplexity is 141.8727981047631
At time: 78.85536623001099 and batch: 250, loss is 4.97773063659668 and perplexity is 145.1446217298383
At time: 79.77586126327515 and batch: 300, loss is 5.0070646953582765 and perplexity is 149.4653652404146
At time: 80.69609141349792 and batch: 350, loss is 5.018300466537475 and perplexity is 151.1541937620884
At time: 81.6250970363617 and batch: 400, loss is 4.973456411361695 and perplexity is 144.52556486162456
At time: 82.54506659507751 and batch: 450, loss is 4.939467868804932 and perplexity is 139.69589323548408
At time: 83.46666836738586 and batch: 500, loss is 4.941627750396728 and perplexity is 139.99794590530846
At time: 84.39408564567566 and batch: 550, loss is 4.900970239639282 and perplexity is 134.4201361806298
At time: 85.31977391242981 and batch: 600, loss is 4.891140785217285 and perplexity is 133.1053320683389
At time: 86.26753973960876 and batch: 650, loss is 4.976928634643555 and perplexity is 145.02826212627699
At time: 87.18763065338135 and batch: 700, loss is 4.970949640274048 and perplexity is 144.1637260671977
At time: 88.10805487632751 and batch: 750, loss is 4.9274507331848145 and perplexity is 138.02719530711298
At time: 89.02875208854675 and batch: 800, loss is 4.910634689331054 and perplexity is 135.72553062329126
At time: 89.96216177940369 and batch: 850, loss is 4.906259078979492 and perplexity is 135.1329459917155
At time: 90.8850724697113 and batch: 900, loss is 4.908991003036499 and perplexity is 135.50262367351942
At time: 91.81069540977478 and batch: 950, loss is 4.962764492034912 and perplexity is 142.9885406929961
At time: 92.73062825202942 and batch: 1000, loss is 4.93998854637146 and perplexity is 139.7686486926514
At time: 93.65087103843689 and batch: 1050, loss is 4.8506114959716795 and perplexity is 127.81852646752033
At time: 94.57148671150208 and batch: 1100, loss is 4.92640869140625 and perplexity is 137.8834401154907
At time: 95.49104428291321 and batch: 1150, loss is 4.856398954391479 and perplexity is 128.56041563029513
At time: 96.41636896133423 and batch: 1200, loss is 4.941788206100464 and perplexity is 140.02041117653243
At time: 97.34009504318237 and batch: 1250, loss is 4.909020671844482 and perplexity is 135.50664393448025
At time: 98.26152420043945 and batch: 1300, loss is 4.92245701789856 and perplexity is 137.33964493618504
At time: 99.18835163116455 and batch: 1350, loss is 4.835337429046631 and perplexity is 125.88105196472705
At time: 100.10879445075989 and batch: 1400, loss is 4.834973583221435 and perplexity is 125.83525900079299
At time: 101.02872061729431 and batch: 1450, loss is 4.778475542068481 and perplexity is 118.9229188009957
At time: 101.95367813110352 and batch: 1500, loss is 4.781206789016724 and perplexity is 119.2481706293886
At time: 102.87832021713257 and batch: 1550, loss is 4.778991432189941 and perplexity is 118.9842857879705
At time: 103.79848551750183 and batch: 1600, loss is 4.84551736831665 and perplexity is 127.16905821858289
At time: 104.71832489967346 and batch: 1650, loss is 4.817614316940308 and perplexity is 123.66970185503429
At time: 105.63790845870972 and batch: 1700, loss is 4.831923999786377 and perplexity is 125.45209841643151
At time: 106.55751252174377 and batch: 1750, loss is 4.833178014755249 and perplexity is 125.60951590703793
At time: 107.47811913490295 and batch: 1800, loss is 4.807699928283691 and perplexity is 122.44965039173033
At time: 108.39856004714966 and batch: 1850, loss is 4.830320205688476 and perplexity is 125.2510603363569
At time: 109.31858563423157 and batch: 1900, loss is 4.8998079681396485 and perplexity is 134.26399424460865
At time: 110.23890113830566 and batch: 1950, loss is 4.834135656356811 and perplexity is 125.72986242023923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.712161325853924 and perplexity of 111.29243937761954
finished 3 epochs...
Completing Train Step...
At time: 113.22217202186584 and batch: 50, loss is 4.828387088775635 and perplexity is 125.00916927045238
At time: 114.16426849365234 and batch: 100, loss is 4.786055545806885 and perplexity is 119.82778006345929
At time: 115.07084965705872 and batch: 150, loss is 4.736512756347656 and perplexity is 114.03583673825119
At time: 115.98536992073059 and batch: 200, loss is 4.717930822372437 and perplexity is 111.93639658729765
At time: 116.89857506752014 and batch: 250, loss is 4.7383969783782955 and perplexity is 114.25090813161407
At time: 117.81427812576294 and batch: 300, loss is 4.780310840606689 and perplexity is 119.14137826788061
At time: 118.7302188873291 and batch: 350, loss is 4.791263408660889 and perplexity is 120.45345450735775
At time: 119.6457507610321 and batch: 400, loss is 4.740523357391357 and perplexity is 114.49410734009962
At time: 120.56525588035583 and batch: 450, loss is 4.728349561691284 and perplexity is 113.10872923302811
At time: 121.48116159439087 and batch: 500, loss is 4.739547815322876 and perplexity is 114.38246798509358
At time: 122.3972315788269 and batch: 550, loss is 4.699425840377808 and perplexity is 109.8840633442118
At time: 123.3129050731659 and batch: 600, loss is 4.687428941726685 and perplexity is 108.57367140905595
At time: 124.22950983047485 and batch: 650, loss is 4.770854330062866 and perplexity is 118.02002695976525
At time: 125.14527559280396 and batch: 700, loss is 4.770919389724732 and perplexity is 118.02770555259328
At time: 126.06085419654846 and batch: 750, loss is 4.739366931915283 and perplexity is 114.36177996563171
At time: 126.97695827484131 and batch: 800, loss is 4.716981363296509 and perplexity is 111.83016799746075
At time: 127.89285683631897 and batch: 850, loss is 4.714547872543335 and perplexity is 111.55836117154566
At time: 128.80829858779907 and batch: 900, loss is 4.707537136077881 and perplexity is 110.77899007573392
At time: 129.7233588695526 and batch: 950, loss is 4.7717076110839844 and perplexity is 118.12077418561705
At time: 130.6388156414032 and batch: 1000, loss is 4.746152448654175 and perplexity is 115.14042249624084
At time: 131.55426454544067 and batch: 1050, loss is 4.6716950988769534 and perplexity is 106.87875903299587
At time: 132.51366424560547 and batch: 1100, loss is 4.7391823959350585 and perplexity is 114.34067804955679
At time: 133.42980575561523 and batch: 1150, loss is 4.677596025466919 and perplexity is 107.51130721878846
At time: 134.34940838813782 and batch: 1200, loss is 4.762749853134156 and perplexity is 117.06740185247712
At time: 135.27206826210022 and batch: 1250, loss is 4.740298070907593 and perplexity is 114.46831627054402
At time: 136.18785619735718 and batch: 1300, loss is 4.747320623397827 and perplexity is 115.27500522254064
At time: 137.10397267341614 and batch: 1350, loss is 4.651055383682251 and perplexity is 104.69542112999036
At time: 138.02448105812073 and batch: 1400, loss is 4.6490045928955075 and perplexity is 104.48093273550798
At time: 138.95339632034302 and batch: 1450, loss is 4.593701257705688 and perplexity is 98.85965891647325
At time: 139.88156700134277 and batch: 1500, loss is 4.604060535430908 and perplexity is 99.88909648773361
At time: 140.80117321014404 and batch: 1550, loss is 4.6044044685363765 and perplexity is 99.92345756350811
At time: 141.72014093399048 and batch: 1600, loss is 4.672143201828003 and perplexity is 106.92666245235333
At time: 142.63749384880066 and batch: 1650, loss is 4.647619676589966 and perplexity is 104.3363355387635
At time: 143.5553901195526 and batch: 1700, loss is 4.663648357391358 and perplexity is 106.02218422869606
At time: 144.4744153022766 and batch: 1750, loss is 4.659049463272095 and perplexity is 105.53571888782086
At time: 145.3988742828369 and batch: 1800, loss is 4.63651364326477 and perplexity is 103.18398359340982
At time: 146.3182249069214 and batch: 1850, loss is 4.664774227142334 and perplexity is 106.1416186200197
At time: 147.23523092269897 and batch: 1900, loss is 4.73931547164917 and perplexity is 114.35589502942298
At time: 148.1528022289276 and batch: 1950, loss is 4.675733003616333 and perplexity is 107.31119776627528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6436412722565406 and perplexity of 103.9220680175815
finished 4 epochs...
Completing Train Step...
At time: 151.12014079093933 and batch: 50, loss is 4.669315528869629 and perplexity is 106.6247358963635
At time: 152.03651666641235 and batch: 100, loss is 4.624737806320191 and perplexity is 101.9760321060851
At time: 152.92081212997437 and batch: 150, loss is 4.5809610557556155 and perplexity is 97.6081560248126
At time: 153.805428981781 and batch: 200, loss is 4.577476139068604 and perplexity is 97.26859175334845
At time: 154.69693446159363 and batch: 250, loss is 4.594121437072754 and perplexity is 98.90120643347858
At time: 155.6120891571045 and batch: 300, loss is 4.63044490814209 and perplexity is 102.5596835997836
At time: 156.5009617805481 and batch: 350, loss is 4.63809949874878 and perplexity is 103.34774829891
At time: 157.38963723182678 and batch: 400, loss is 4.58852388381958 and perplexity is 98.34914819281548
At time: 158.2927224636078 and batch: 450, loss is 4.587084999084473 and perplexity is 98.20773686646754
At time: 159.1930239200592 and batch: 500, loss is 4.602259893417358 and perplexity is 99.70939382254102
At time: 160.0889916419983 and batch: 550, loss is 4.5563954257965085 and perplexity is 95.2395622949039
At time: 160.98506259918213 and batch: 600, loss is 4.549649019241333 and perplexity is 94.59919998854188
At time: 161.88199615478516 and batch: 650, loss is 4.634331512451172 and perplexity is 102.95906813007052
At time: 162.78031086921692 and batch: 700, loss is 4.6401718235015865 and perplexity is 103.56214046422608
At time: 163.67891097068787 and batch: 750, loss is 4.608083572387695 and perplexity is 100.29176344341474
At time: 164.57741904258728 and batch: 800, loss is 4.582336483001709 and perplexity is 97.74250131195465
At time: 165.48066186904907 and batch: 850, loss is 4.5842303276062015 and perplexity is 97.9277858153433
At time: 166.3839235305786 and batch: 900, loss is 4.570884094238282 and perplexity is 96.62950160568654
At time: 167.28718447685242 and batch: 950, loss is 4.644002122879028 and perplexity is 103.9595751273408
At time: 168.19019508361816 and batch: 1000, loss is 4.613384208679199 and perplexity is 100.8247850332397
At time: 169.09303522109985 and batch: 1050, loss is 4.552609758377075 and perplexity is 94.87969857883117
At time: 169.99526929855347 and batch: 1100, loss is 4.605933694839478 and perplexity is 100.07638003984644
At time: 170.89852714538574 and batch: 1150, loss is 4.54895245552063 and perplexity is 94.53332856230865
At time: 171.80995154380798 and batch: 1200, loss is 4.637896347045898 and perplexity is 103.32675516032226
At time: 172.71443343162537 and batch: 1250, loss is 4.616854057312012 and perplexity is 101.17523943598795
At time: 173.61732411384583 and batch: 1300, loss is 4.618184461593628 and perplexity is 101.30993298629805
At time: 174.5274817943573 and batch: 1350, loss is 4.522951602935791 and perplexity is 92.1070606266534
At time: 175.43212747573853 and batch: 1400, loss is 4.523457517623902 and perplexity is 92.15367073087714
At time: 176.33942937850952 and batch: 1450, loss is 4.463404397964478 and perplexity is 86.7824487573799
At time: 177.24743556976318 and batch: 1500, loss is 4.477093524932862 and perplexity is 87.97859312414978
At time: 178.15781164169312 and batch: 1550, loss is 4.483426399230957 and perplexity is 88.53751842919023
At time: 179.06787157058716 and batch: 1600, loss is 4.55103798866272 and perplexity is 94.73068667897074
At time: 179.9791305065155 and batch: 1650, loss is 4.530057392120361 and perplexity is 92.76388484538347
At time: 180.8937680721283 and batch: 1700, loss is 4.5433782291412355 and perplexity is 94.00784433318374
At time: 181.81574773788452 and batch: 1750, loss is 4.54060266494751 and perplexity is 93.74728129851404
At time: 182.72727847099304 and batch: 1800, loss is 4.515760374069214 and perplexity is 91.44707357662158
At time: 183.637757062912 and batch: 1850, loss is 4.544971885681153 and perplexity is 94.157779990346
At time: 184.54845690727234 and batch: 1900, loss is 4.624010047912598 and perplexity is 101.9018451896973
At time: 185.45908379554749 and batch: 1950, loss is 4.556490440368652 and perplexity is 95.24861187108048
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607610658157704 and perplexity of 100.24434525458328
finished 5 epochs...
Completing Train Step...
At time: 188.43193674087524 and batch: 50, loss is 4.547438659667969 and perplexity is 94.39033266220022
At time: 189.3123893737793 and batch: 100, loss is 4.506703472137451 and perplexity is 90.62258568814674
At time: 190.19597339630127 and batch: 150, loss is 4.4705453205108645 and perplexity is 87.40437341745265
At time: 191.08864188194275 and batch: 200, loss is 4.464752731323242 and perplexity is 86.89953934883066
At time: 191.98548769950867 and batch: 250, loss is 4.482924146652222 and perplexity is 88.49306139750827
At time: 192.8824770450592 and batch: 300, loss is 4.5180002784729005 and perplexity is 91.65213585364272
At time: 193.77974104881287 and batch: 350, loss is 4.5227624130249025 and perplexity is 92.08963654834314
At time: 194.68201613426208 and batch: 400, loss is 4.468251285552978 and perplexity is 87.20409454056553
At time: 195.59016585350037 and batch: 450, loss is 4.4763180446624755 and perplexity is 87.91039390795673
At time: 196.50097393989563 and batch: 500, loss is 4.495347166061402 and perplexity is 89.5992694117929
At time: 197.41242861747742 and batch: 550, loss is 4.448290157318115 and perplexity is 85.48066049515731
At time: 198.3234634399414 and batch: 600, loss is 4.445870151519776 and perplexity is 85.27404690499105
At time: 199.2351996898651 and batch: 650, loss is 4.527069263458252 and perplexity is 92.48710815039888
At time: 200.14628911018372 and batch: 700, loss is 4.5401421165466305 and perplexity is 93.70411607862465
At time: 201.0832235813141 and batch: 750, loss is 4.50771092414856 and perplexity is 90.7139295989276
At time: 201.9899172782898 and batch: 800, loss is 4.479697771072388 and perplexity is 88.20800963452464
At time: 202.90634942054749 and batch: 850, loss is 4.478556900024414 and perplexity is 88.10743305349702
At time: 203.81268739700317 and batch: 900, loss is 4.467091751098633 and perplexity is 87.10303698956473
At time: 204.71651220321655 and batch: 950, loss is 4.542290172576904 and perplexity is 93.90561410727817
At time: 205.62022304534912 and batch: 1000, loss is 4.507880487442017 and perplexity is 90.72931265575684
At time: 206.5240240097046 and batch: 1050, loss is 4.455840740203858 and perplexity is 86.1285321336092
At time: 207.4280662536621 and batch: 1100, loss is 4.499647188186645 and perplexity is 89.98537779502999
At time: 208.3312361240387 and batch: 1150, loss is 4.443989458084107 and perplexity is 85.11382327773195
At time: 209.23521447181702 and batch: 1200, loss is 4.53979609489441 and perplexity is 93.67169803455526
At time: 210.14781022071838 and batch: 1250, loss is 4.521177272796631 and perplexity is 91.94377719514905
At time: 211.05114555358887 and batch: 1300, loss is 4.512899694442749 and perplexity is 91.18584661780615
At time: 211.95477032661438 and batch: 1350, loss is 4.418230457305908 and perplexity is 82.94937295590128
At time: 212.85861229896545 and batch: 1400, loss is 4.424058847427368 and perplexity is 83.43424590356888
At time: 213.76211380958557 and batch: 1450, loss is 4.3590750408172605 and perplexity is 78.1847832340914
At time: 214.66556239128113 and batch: 1500, loss is 4.376731204986572 and perplexity is 79.57748531076061
At time: 215.57800936698914 and batch: 1550, loss is 4.384012746810913 and perplexity is 80.15904686113123
At time: 216.48107838630676 and batch: 1600, loss is 4.455604419708252 and perplexity is 86.10818060104647
At time: 217.38415813446045 and batch: 1650, loss is 4.428736400604248 and perplexity is 83.8254282003139
At time: 218.28733777999878 and batch: 1700, loss is 4.444800243377686 and perplexity is 85.18286029724396
At time: 219.1933469772339 and batch: 1750, loss is 4.442544574737549 and perplexity is 84.9909325346899
At time: 220.09749388694763 and batch: 1800, loss is 4.41582314491272 and perplexity is 82.74992806177781
At time: 221.00057411193848 and batch: 1850, loss is 4.44846658706665 and perplexity is 85.49574315706909
At time: 221.90490794181824 and batch: 1900, loss is 4.529597940444947 and perplexity is 92.72127411260915
At time: 222.80829453468323 and batch: 1950, loss is 4.465919942855835 and perplexity is 87.00102871159068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.577522313317587 and perplexity of 97.27308316121524
finished 6 epochs...
Completing Train Step...
At time: 225.756178855896 and batch: 50, loss is 4.451706342697143 and perplexity is 85.77317763964587
At time: 226.67293214797974 and batch: 100, loss is 4.413291110992431 and perplexity is 82.54066747627517
At time: 227.56270599365234 and batch: 150, loss is 4.383612480163574 and perplexity is 80.12696828860987
At time: 228.46111369132996 and batch: 200, loss is 4.37765326499939 and perplexity is 79.65089436646268
At time: 229.35943603515625 and batch: 250, loss is 4.397518692016601 and perplexity is 81.2490145090254
At time: 230.25863671302795 and batch: 300, loss is 4.424260883331299 and perplexity is 83.45110431980416
At time: 231.15733742713928 and batch: 350, loss is 4.429086713790894 and perplexity is 83.85479849728948
At time: 232.05791234970093 and batch: 400, loss is 4.3718514919281 and perplexity is 79.1901159109455
At time: 232.95641994476318 and batch: 450, loss is 4.386741228103638 and perplexity is 80.37805796891874
At time: 233.85388612747192 and batch: 500, loss is 4.408534278869629 and perplexity is 82.14896774132431
At time: 234.75775790214539 and batch: 550, loss is 4.3654390144348145 and perplexity is 78.683935743944
At time: 235.66213846206665 and batch: 600, loss is 4.3638968086242675 and perplexity is 78.56268244384736
At time: 236.56595301628113 and batch: 650, loss is 4.44156774520874 and perplexity is 84.90795141790997
At time: 237.47602558135986 and batch: 700, loss is 4.458212881088257 and perplexity is 86.33308366260059
At time: 238.38785338401794 and batch: 750, loss is 4.422625331878662 and perplexity is 83.3147273011263
At time: 239.29977011680603 and batch: 800, loss is 4.397451515197754 and perplexity is 81.24355664201934
At time: 240.21152925491333 and batch: 850, loss is 4.396940765380859 and perplexity is 81.20207210535212
At time: 241.12398505210876 and batch: 900, loss is 4.384746732711792 and perplexity is 80.21790406889319
At time: 242.03608870506287 and batch: 950, loss is 4.457924127578735 and perplexity is 86.30815828052414
At time: 242.948801279068 and batch: 1000, loss is 4.423177852630615 and perplexity is 83.36077313637179
At time: 243.8600299358368 and batch: 1050, loss is 4.373411054611206 and perplexity is 79.31371421519084
At time: 244.77168130874634 and batch: 1100, loss is 4.412701349258423 and perplexity is 82.49200250087888
At time: 245.68221187591553 and batch: 1150, loss is 4.361415405273437 and perplexity is 78.36797840990735
At time: 246.59448504447937 and batch: 1200, loss is 4.456976642608643 and perplexity is 86.22642132613966
At time: 247.54170203208923 and batch: 1250, loss is 4.442094421386718 and perplexity is 84.95268219152518
At time: 248.4466404914856 and batch: 1300, loss is 4.428006944656372 and perplexity is 83.7643035397139
At time: 249.35560703277588 and batch: 1350, loss is 4.3375923490524295 and perplexity is 76.52307650868278
At time: 250.26812887191772 and batch: 1400, loss is 4.346697235107422 and perplexity is 77.22299189059119
At time: 251.18840098381042 and batch: 1450, loss is 4.278535795211792 and perplexity is 72.13474260936617
At time: 252.10018944740295 and batch: 1500, loss is 4.2970161485672 and perplexity is 73.48021222673226
At time: 253.01266145706177 and batch: 1550, loss is 4.303490629196167 and perplexity is 73.95750187139919
At time: 253.92488598823547 and batch: 1600, loss is 4.376328115463257 and perplexity is 79.54541492419271
At time: 254.83737134933472 and batch: 1650, loss is 4.3486534786224365 and perplexity is 77.37420672598418
At time: 255.74986219406128 and batch: 1700, loss is 4.370142250061035 and perplexity is 79.0548764607632
At time: 256.66239047050476 and batch: 1750, loss is 4.361122922897339 and perplexity is 78.34506050907645
At time: 257.5759537220001 and batch: 1800, loss is 4.338358793258667 and perplexity is 76.58174965929229
At time: 258.4895579814911 and batch: 1850, loss is 4.371120080947876 and perplexity is 79.13221656733201
At time: 259.40195059776306 and batch: 1900, loss is 4.453933820724488 and perplexity is 85.96444845485773
At time: 260.3146741390228 and batch: 1950, loss is 4.387161417007446 and perplexity is 80.4118390337042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.553566156431686 and perplexity of 94.9704847449102
finished 7 epochs...
Completing Train Step...
At time: 263.2690267562866 and batch: 50, loss is 4.377217330932617 and perplexity is 79.61617939542843
At time: 264.17851734161377 and batch: 100, loss is 4.336457672119141 and perplexity is 76.43629678169204
At time: 265.06139516830444 and batch: 150, loss is 4.313284244537353 and perplexity is 74.6853716166877
At time: 265.94458508491516 and batch: 200, loss is 4.305106296539306 and perplexity is 74.07708917258752
At time: 266.840931892395 and batch: 250, loss is 4.3216963958740235 and perplexity is 75.31628621940776
At time: 267.7284359931946 and batch: 300, loss is 4.351221160888672 and perplexity is 77.57313438667781
At time: 268.6189811229706 and batch: 350, loss is 4.353444919586182 and perplexity is 77.74583026477721
At time: 269.5242075920105 and batch: 400, loss is 4.297466745376587 and perplexity is 73.51332963665403
At time: 270.4581575393677 and batch: 450, loss is 4.311928358078003 and perplexity is 74.58417535342612
At time: 271.35685658454895 and batch: 500, loss is 4.336273746490479 and perplexity is 76.42223948054244
At time: 272.2536029815674 and batch: 550, loss is 4.292417507171631 and perplexity is 73.14307885290283
At time: 273.15031695365906 and batch: 600, loss is 4.296524424552917 and perplexity is 73.44408912383224
At time: 274.0587944984436 and batch: 650, loss is 4.371243152618408 and perplexity is 79.14195610073588
At time: 274.9548738002777 and batch: 700, loss is 4.389167175292969 and perplexity is 80.57328760537881
At time: 275.85196137428284 and batch: 750, loss is 4.355689239501953 and perplexity is 77.92051272835205
At time: 276.7488543987274 and batch: 800, loss is 4.331190881729126 and perplexity is 76.03478110594432
At time: 277.6460711956024 and batch: 850, loss is 4.327774715423584 and perplexity is 75.77547681415075
At time: 278.54277753829956 and batch: 900, loss is 4.3165269947052005 and perplexity is 74.9279507171743
At time: 279.45140624046326 and batch: 950, loss is 4.391375713348388 and perplexity is 80.75143342580652
At time: 280.35414481163025 and batch: 1000, loss is 4.354320106506347 and perplexity is 77.81390218200315
At time: 281.25595712661743 and batch: 1050, loss is 4.305633764266968 and perplexity is 74.11617275324276
At time: 282.15863585472107 and batch: 1100, loss is 4.343650312423706 and perplexity is 76.9880575001128
At time: 283.0616056919098 and batch: 1150, loss is 4.292616138458252 and perplexity is 73.15760879976601
At time: 283.96422362327576 and batch: 1200, loss is 4.387848372459412 and perplexity is 80.46709736276311
At time: 284.86641478538513 and batch: 1250, loss is 4.376243963241577 and perplexity is 79.53872128244875
At time: 285.76917147636414 and batch: 1300, loss is 4.363424806594849 and perplexity is 78.52560944825015
At time: 286.67235350608826 and batch: 1350, loss is 4.2712029409408565 and perplexity is 71.60772369191493
At time: 287.5749852657318 and batch: 1400, loss is 4.278918161392212 and perplexity is 72.16232976923561
At time: 288.47811245918274 and batch: 1450, loss is 4.212691898345947 and perplexity is 67.53810103075745
At time: 289.3808104991913 and batch: 1500, loss is 4.232883205413819 and perplexity is 68.91564396319768
At time: 290.28168535232544 and batch: 1550, loss is 4.2335583782196045 and perplexity is 68.96218964331538
At time: 291.1841700077057 and batch: 1600, loss is 4.3136285781860355 and perplexity is 74.71109273126814
At time: 292.0890419483185 and batch: 1650, loss is 4.282065172195434 and perplexity is 72.38978311194981
At time: 292.991317987442 and batch: 1700, loss is 4.305664329528809 and perplexity is 74.11843816809092
At time: 293.89402627944946 and batch: 1750, loss is 4.294886207580566 and perplexity is 73.32387026968085
At time: 294.7965097427368 and batch: 1800, loss is 4.273604202270508 and perplexity is 71.77987916213583
At time: 295.7003273963928 and batch: 1850, loss is 4.312095613479614 and perplexity is 74.5966510029095
At time: 296.6100685596466 and batch: 1900, loss is 4.3926495170593265 and perplexity is 80.85436044185815
At time: 297.5124776363373 and batch: 1950, loss is 4.324602813720703 and perplexity is 75.53550523453366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.540093852198401 and perplexity of 93.69959361967338
finished 8 epochs...
Completing Train Step...
At time: 300.4855935573578 and batch: 50, loss is 4.3097843122482296 and perplexity is 74.4244347700514
At time: 301.360867023468 and batch: 100, loss is 4.271722211837768 and perplexity is 71.64491715472788
At time: 302.241694688797 and batch: 150, loss is 4.250710229873658 and perplexity is 70.15522099054125
At time: 303.1340854167938 and batch: 200, loss is 4.241879453659058 and perplexity is 69.53842334297126
At time: 304.0419147014618 and batch: 250, loss is 4.259823808670044 and perplexity is 70.79750844814382
At time: 304.94919443130493 and batch: 300, loss is 4.287196025848389 and perplexity is 72.76215898119119
At time: 305.85448479652405 and batch: 350, loss is 4.291291131973266 and perplexity is 73.06073868461812
At time: 306.7579870223999 and batch: 400, loss is 4.2293536710739135 and perplexity is 68.67283258888556
At time: 307.6613030433655 and batch: 450, loss is 4.251395797729492 and perplexity is 70.20333364533167
At time: 308.5662977695465 and batch: 500, loss is 4.277608575820923 and perplexity is 72.06788887609207
At time: 309.47094798088074 and batch: 550, loss is 4.2341312789917 and perplexity is 69.00170945439163
At time: 310.37539863586426 and batch: 600, loss is 4.2379319906234745 and perplexity is 69.26446406508012
At time: 311.282080411911 and batch: 650, loss is 4.310915699005127 and perplexity is 74.50868524088634
At time: 312.18705224990845 and batch: 700, loss is 4.329980278015137 and perplexity is 75.9427888118866
At time: 313.0911695957184 and batch: 750, loss is 4.295764498710632 and perplexity is 73.38829826368703
At time: 313.9944894313812 and batch: 800, loss is 4.2717667579650875 and perplexity is 71.64810872941486
At time: 314.9259583950043 and batch: 850, loss is 4.266972942352295 and perplexity is 71.3054628539202
At time: 315.83056688308716 and batch: 900, loss is 4.2551829051971435 and perplexity is 70.4697052850845
At time: 316.7351472377777 and batch: 950, loss is 4.335319204330444 and perplexity is 76.3493260360087
At time: 317.6382100582123 and batch: 1000, loss is 4.297147970199585 and perplexity is 73.48989914671482
At time: 318.54242491722107 and batch: 1050, loss is 4.248610210418701 and perplexity is 70.0080482484921
At time: 319.44720816612244 and batch: 1100, loss is 4.284993906021118 and perplexity is 72.60210428271598
At time: 320.3515110015869 and batch: 1150, loss is 4.232205123901367 and perplexity is 68.8689293790454
At time: 321.25640511512756 and batch: 1200, loss is 4.329822549819946 and perplexity is 75.93081143747919
At time: 322.16144037246704 and batch: 1250, loss is 4.318199834823608 and perplexity is 75.05339809657431
At time: 323.06493282318115 and batch: 1300, loss is 4.306067972183228 and perplexity is 74.14836156998888
At time: 323.97411847114563 and batch: 1350, loss is 4.215462698936462 and perplexity is 67.72549513693512
At time: 324.87892413139343 and batch: 1400, loss is 4.2242420959472655 and perplexity is 68.32270186804641
At time: 325.78274297714233 and batch: 1450, loss is 4.15552324295044 and perplexity is 63.785331042469544
At time: 326.6863868236542 and batch: 1500, loss is 4.180640201568604 and perplexity is 65.40771393399021
At time: 327.5887336730957 and batch: 1550, loss is 4.174786682128906 and perplexity is 65.02596698058214
At time: 328.4938564300537 and batch: 1600, loss is 4.261245222091675 and perplexity is 70.89821253098216
At time: 329.39886569976807 and batch: 1650, loss is 4.228063178062439 and perplexity is 68.58426793667492
At time: 330.3029980659485 and batch: 1700, loss is 4.251787767410279 and perplexity is 70.23085661734369
At time: 331.20764541625977 and batch: 1750, loss is 4.238335061073303 and perplexity is 69.29238815107686
At time: 332.1130769252777 and batch: 1800, loss is 4.221414251327515 and perplexity is 68.1297688040945
At time: 333.01660203933716 and batch: 1850, loss is 4.260007495880127 and perplexity is 70.81051423941369
At time: 333.92022800445557 and batch: 1900, loss is 4.3376361274719235 and perplexity is 76.52642664135837
At time: 334.8256046772003 and batch: 1950, loss is 4.268218603134155 and perplexity is 71.3943406168091
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5448946220930235 and perplexity of 94.1505053034515
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 337.81644582748413 and batch: 50, loss is 4.273462018966675 and perplexity is 71.76967398728776
At time: 338.7369270324707 and batch: 100, loss is 4.249120011329651 and perplexity is 70.04374751424888
At time: 339.62424898147583 and batch: 150, loss is 4.222991819381714 and perplexity is 68.23733297349044
At time: 340.517879486084 and batch: 200, loss is 4.216181735992432 and perplexity is 67.77420978929376
At time: 341.4109766483307 and batch: 250, loss is 4.230999364852905 and perplexity is 68.78594008688823
At time: 342.309219121933 and batch: 300, loss is 4.247315130233765 and perplexity is 69.9174408969763
At time: 343.21088552474976 and batch: 350, loss is 4.252244081497192 and perplexity is 70.26291125949037
At time: 344.1135139465332 and batch: 400, loss is 4.184041113853454 and perplexity is 65.6305385204996
At time: 345.01523208618164 and batch: 450, loss is 4.203493537902832 and perplexity is 66.919709687229
At time: 345.9172716140747 and batch: 500, loss is 4.2220447683334354 and perplexity is 68.17273932733418
At time: 346.8221547603607 and batch: 550, loss is 4.18683171749115 and perplexity is 65.81394312579671
At time: 347.7261736392975 and batch: 600, loss is 4.171354985237121 and perplexity is 64.80320002476319
At time: 348.6260783672333 and batch: 650, loss is 4.223598294258117 and perplexity is 68.27872975335626
At time: 349.5272080898285 and batch: 700, loss is 4.238165454864502 and perplexity is 69.28063672840909
At time: 350.4285922050476 and batch: 750, loss is 4.198748812675476 and perplexity is 66.60294612476088
At time: 351.3377089500427 and batch: 800, loss is 4.177188663482666 and perplexity is 65.18234587518835
At time: 352.2536389827728 and batch: 850, loss is 4.175295548439026 and perplexity is 65.05906492496172
At time: 353.1683385372162 and batch: 900, loss is 4.159158210754395 and perplexity is 64.0176105757271
At time: 354.07404041290283 and batch: 950, loss is 4.23745165348053 and perplexity is 69.23120175950349
At time: 354.9799704551697 and batch: 1000, loss is 4.188199372291565 and perplexity is 65.90401546093784
At time: 355.8950741291046 and batch: 1050, loss is 4.134748344421387 and perplexity is 62.47386719485086
At time: 356.80104899406433 and batch: 1100, loss is 4.163867201805115 and perplexity is 64.31977982879768
At time: 357.71597504615784 and batch: 1150, loss is 4.110898666381836 and perplexity is 61.001512953482205
At time: 358.625608921051 and batch: 1200, loss is 4.194423303604126 and perplexity is 66.31547665124067
At time: 359.5381808280945 and batch: 1250, loss is 4.183288526535034 and perplexity is 65.58116439101026
At time: 360.4449825286865 and batch: 1300, loss is 4.167146129608154 and perplexity is 64.53102588418055
At time: 361.35687923431396 and batch: 1350, loss is 4.071463479995727 and perplexity is 58.642722273739075
At time: 362.2631709575653 and batch: 1400, loss is 4.0774273109436034 and perplexity is 58.993502513035466
At time: 363.1788649559021 and batch: 1450, loss is 3.9969937229156494 and perplexity is 54.43425933970259
At time: 364.08449602127075 and batch: 1500, loss is 4.023361477851868 and perplexity is 55.88865891152195
At time: 364.98913502693176 and batch: 1550, loss is 4.012503647804261 and perplexity is 55.28511188644329
At time: 365.8946855068207 and batch: 1600, loss is 4.092106990814209 and perplexity is 59.86589580533422
At time: 366.80014204978943 and batch: 1650, loss is 4.050136375427246 and perplexity is 57.405285181944194
At time: 367.707181930542 and batch: 1700, loss is 4.065772919654846 and perplexity is 58.30996002388949
At time: 368.6138253211975 and batch: 1750, loss is 4.047696676254272 and perplexity is 57.265404258230916
At time: 369.5200560092926 and batch: 1800, loss is 4.029808783531189 and perplexity is 56.25015426283614
At time: 370.42608737945557 and batch: 1850, loss is 4.050644845962524 and perplexity is 57.43448150013319
At time: 371.33180379867554 and batch: 1900, loss is 4.131463751792908 and perplexity is 62.269002623702804
At time: 372.2386248111725 and batch: 1950, loss is 4.060729947090149 and perplexity is 58.01664470740952
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.426915084484012 and perplexity of 83.67289454481505
finished 10 epochs...
Completing Train Step...
At time: 375.1947672367096 and batch: 50, loss is 4.1853623199462895 and perplexity is 65.71730729496382
At time: 376.10049772262573 and batch: 100, loss is 4.160467562675476 and perplexity is 64.10148705705024
At time: 376.9858965873718 and batch: 150, loss is 4.132798357009888 and perplexity is 62.3521626400128
At time: 377.8727443218231 and batch: 200, loss is 4.128610186576843 and perplexity is 62.09156724589008
At time: 378.7720785140991 and batch: 250, loss is 4.143986973762512 and perplexity is 63.05371447012851
At time: 379.6777169704437 and batch: 300, loss is 4.1623819017410275 and perplexity is 64.22431656903906
At time: 380.57635521888733 and batch: 350, loss is 4.169874200820923 and perplexity is 64.70731146870787
At time: 381.474098443985 and batch: 400, loss is 4.105388517379761 and perplexity is 60.66630988529435
At time: 382.3724522590637 and batch: 450, loss is 4.131336088180542 and perplexity is 62.261053645297885
At time: 383.27083444595337 and batch: 500, loss is 4.1530637502670285 and perplexity is 63.62864425145421
At time: 384.1957371234894 and batch: 550, loss is 4.119124054908752 and perplexity is 61.505343358033606
At time: 385.09488701820374 and batch: 600, loss is 4.1112673425674435 and perplexity is 61.02400690483151
At time: 385.99471974372864 and batch: 650, loss is 4.165355949401856 and perplexity is 64.41560706002177
At time: 386.89343547821045 and batch: 700, loss is 4.182988109588623 and perplexity is 65.56146565692676
At time: 387.79208159446716 and batch: 750, loss is 4.146685800552368 and perplexity is 63.2241153617575
At time: 388.6923773288727 and batch: 800, loss is 4.127384791374206 and perplexity is 62.015527136370594
At time: 389.5955150127411 and batch: 850, loss is 4.12538932800293 and perplexity is 61.891900810444156
At time: 390.50947189331055 and batch: 900, loss is 4.109788908958435 and perplexity is 60.93385362131035
At time: 391.4160141944885 and batch: 950, loss is 4.190442481040955 and perplexity is 66.0520112579179
At time: 392.3184504508972 and batch: 1000, loss is 4.141384544372559 and perplexity is 62.88983496535692
At time: 393.22099328041077 and batch: 1050, loss is 4.092748956680298 and perplexity is 59.904340005595955
At time: 394.12518644332886 and batch: 1100, loss is 4.121817479133606 and perplexity is 61.67122663652864
At time: 395.0294978618622 and batch: 1150, loss is 4.073424072265625 and perplexity is 58.757809524436226
At time: 395.9328942298889 and batch: 1200, loss is 4.158072028160095 and perplexity is 63.948113511474546
At time: 396.8362648487091 and batch: 1250, loss is 4.1507837772369385 and perplexity is 63.48373791266381
At time: 397.73979139328003 and batch: 1300, loss is 4.1382521057128905 and perplexity is 62.69314463603695
At time: 398.6521303653717 and batch: 1350, loss is 4.043518509864807 and perplexity is 57.02663901867458
At time: 399.5561683177948 and batch: 1400, loss is 4.051519856452942 and perplexity is 57.48475926753658
At time: 400.46199655532837 and batch: 1450, loss is 3.972988362312317 and perplexity is 53.14310463474029
At time: 401.36816143989563 and batch: 1500, loss is 4.0021899223327635 and perplexity is 54.71784675665699
At time: 402.2770342826843 and batch: 1550, loss is 3.993906283378601 and perplexity is 54.26645602982962
At time: 403.1885974407196 and batch: 1600, loss is 4.076859011650085 and perplexity is 58.95998607182212
At time: 404.0957119464874 and batch: 1650, loss is 4.0375130033493045 and perplexity is 56.685191475436596
At time: 405.0003414154053 and batch: 1700, loss is 4.056130690574646 and perplexity is 57.75042395428207
At time: 405.90481543540955 and batch: 1750, loss is 4.04094961643219 and perplexity is 56.880331664675154
At time: 406.8082149028778 and batch: 1800, loss is 4.0243259000778195 and perplexity is 55.9425851760191
At time: 407.7127604484558 and batch: 1850, loss is 4.049401731491089 and perplexity is 57.36312822435455
At time: 408.616872549057 and batch: 1900, loss is 4.132342066764831 and perplexity is 62.32371844633956
At time: 409.52020955085754 and batch: 1950, loss is 4.062717137336731 and perplexity is 58.13204944551942
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.420557492278343 and perplexity of 83.14262381125472
finished 11 epochs...
Completing Train Step...
At time: 412.5184690952301 and batch: 50, loss is 4.150838499069214 and perplexity is 63.487211954174164
At time: 413.38691210746765 and batch: 100, loss is 4.124173593521118 and perplexity is 61.816702412388786
At time: 414.26855278015137 and batch: 150, loss is 4.0965397167205815 and perplexity is 60.13185393684307
At time: 415.1551914215088 and batch: 200, loss is 4.092759919166565 and perplexity is 59.90499670970016
At time: 416.0454909801483 and batch: 250, loss is 4.108269877433777 and perplexity is 60.8413634422743
At time: 416.94170355796814 and batch: 300, loss is 4.127212209701538 and perplexity is 62.00482531646154
At time: 417.8417007923126 and batch: 350, loss is 4.1335611915588375 and perplexity is 62.399745170367964
At time: 418.7407577037811 and batch: 400, loss is 4.070300621986389 and perplexity is 58.57456874856996
At time: 419.6407597064972 and batch: 450, loss is 4.098172898292542 and perplexity is 60.23014041056287
At time: 420.5408606529236 and batch: 500, loss is 4.121799583435059 and perplexity is 61.67012299672296
At time: 421.44132447242737 and batch: 550, loss is 4.087007932662964 and perplexity is 59.56141306865892
At time: 422.3432695865631 and batch: 600, loss is 4.081933245658875 and perplexity is 59.25992317025719
At time: 423.24685549736023 and batch: 650, loss is 4.13617995262146 and perplexity is 62.56336934613793
At time: 424.1506435871124 and batch: 700, loss is 4.154971504211426 and perplexity is 63.750147911193366
At time: 425.05577063560486 and batch: 750, loss is 4.119648613929749 and perplexity is 61.53761500418309
At time: 425.9601466655731 and batch: 800, loss is 4.100878353118897 and perplexity is 60.39331096037739
At time: 426.86559104919434 and batch: 850, loss is 4.098605694770813 and perplexity is 60.25621344497012
At time: 427.77032470703125 and batch: 900, loss is 4.083603444099427 and perplexity is 59.358981702198655
At time: 428.6738312244415 and batch: 950, loss is 4.166750726699829 and perplexity is 64.50551517270584
At time: 429.6052100658417 and batch: 1000, loss is 4.116866087913513 and perplexity is 61.366622994639165
At time: 430.5097002983093 and batch: 1050, loss is 4.069974308013916 and perplexity is 58.55545816655025
At time: 431.4177360534668 and batch: 1100, loss is 4.09825098991394 and perplexity is 60.23484406354016
At time: 432.32250118255615 and batch: 1150, loss is 4.051096577644348 and perplexity is 57.46043233602198
At time: 433.2269124984741 and batch: 1200, loss is 4.136365132331848 and perplexity is 62.57495588551725
At time: 434.1307291984558 and batch: 1250, loss is 4.130985069274902 and perplexity is 62.23920267365976
At time: 435.0343608856201 and batch: 1300, loss is 4.120059094429016 and perplexity is 61.562880180190014
At time: 435.94656133651733 and batch: 1350, loss is 4.025566368103028 and perplexity is 56.01202322311196
At time: 436.84942054748535 and batch: 1400, loss is 4.034416613578796 and perplexity is 56.50994348647062
At time: 437.7534341812134 and batch: 1450, loss is 3.9569454622268676 and perplexity is 52.297337535230376
At time: 438.65710377693176 and batch: 1500, loss is 3.986356997489929 and perplexity is 53.85832552436458
At time: 439.559294462204 and batch: 1550, loss is 3.978860926628113 and perplexity is 53.456109104540346
At time: 440.46257758140564 and batch: 1600, loss is 4.063164525032043 and perplexity is 58.15806282774432
At time: 441.3675391674042 and batch: 1650, loss is 4.025618929862976 and perplexity is 56.01496739100546
At time: 442.2801094055176 and batch: 1700, loss is 4.045251450538635 and perplexity is 57.12554847828178
At time: 443.184579372406 and batch: 1750, loss is 4.031136693954468 and perplexity is 56.324899045197185
At time: 444.09248518943787 and batch: 1800, loss is 4.014175553321838 and perplexity is 55.377620681479634
At time: 444.99575114250183 and batch: 1850, loss is 4.040668668746949 and perplexity is 56.86435351177583
At time: 445.89822697639465 and batch: 1900, loss is 4.12445034980774 and perplexity is 61.833812941013576
At time: 446.80234599113464 and batch: 1950, loss is 4.05496503829956 and perplexity is 57.68314626002904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418460153978924 and perplexity of 82.96842833929334
finished 12 epochs...
Completing Train Step...
At time: 449.73558735847473 and batch: 50, loss is 4.124154114723206 and perplexity is 61.815498309062164
At time: 450.6379017829895 and batch: 100, loss is 4.097250242233276 and perplexity is 60.174594335464526
At time: 451.5236587524414 and batch: 150, loss is 4.0699261999130245 and perplexity is 58.55264124242001
At time: 452.440304517746 and batch: 200, loss is 4.066256380081176 and perplexity is 58.338157397629864
At time: 453.3310158252716 and batch: 250, loss is 4.081641306877136 and perplexity is 59.242625425545064
At time: 454.23240208625793 and batch: 300, loss is 4.101050362586975 and perplexity is 60.40370007515864
At time: 455.1367163658142 and batch: 350, loss is 4.106825642585754 and perplexity is 60.75355764634712
At time: 456.04110312461853 and batch: 400, loss is 4.044340071678161 and perplexity is 57.07350917836665
At time: 456.945916891098 and batch: 450, loss is 4.0730690574646 and perplexity is 58.7369533347263
At time: 457.8504593372345 and batch: 500, loss is 4.098400268554688 and perplexity is 60.24383651036101
At time: 458.7598247528076 and batch: 550, loss is 4.063204550743103 and perplexity is 58.16039069214978
At time: 459.6729350090027 and batch: 600, loss is 4.060023956298828 and perplexity is 57.97569994551582
At time: 460.57584714889526 and batch: 650, loss is 4.113805651664734 and perplexity is 61.17910145238865
At time: 461.47859811782837 and batch: 700, loss is 4.133180379867554 and perplexity is 62.37598714182858
At time: 462.39125967025757 and batch: 750, loss is 4.098575658798218 and perplexity is 60.254403618174486
At time: 463.29506254196167 and batch: 800, loss is 4.080335445404053 and perplexity is 59.16531325391723
At time: 464.19811964035034 and batch: 850, loss is 4.077486400604248 and perplexity is 58.996988522071725
At time: 465.10247254371643 and batch: 900, loss is 4.062689142227173 and perplexity is 58.13042205520597
At time: 466.00663018226624 and batch: 950, loss is 4.147728056907654 and perplexity is 63.29004544985894
At time: 466.9106857776642 and batch: 1000, loss is 4.0976855134963985 and perplexity is 60.20079230834756
At time: 467.8151831626892 and batch: 1050, loss is 4.051624622344971 and perplexity is 57.490782025103556
At time: 468.72832441329956 and batch: 1100, loss is 4.078994069099426 and perplexity is 59.086003508660895
At time: 469.6353907585144 and batch: 1150, loss is 4.032882523536682 and perplexity is 56.42331860705888
At time: 470.54032731056213 and batch: 1200, loss is 4.118085236549377 and perplexity is 61.44148365321331
At time: 471.4451222419739 and batch: 1250, loss is 4.114090237617493 and perplexity is 61.1965146429216
At time: 472.3592908382416 and batch: 1300, loss is 4.104188575744629 and perplexity is 60.59355751224332
At time: 473.2641541957855 and batch: 1350, loss is 4.009704809188843 and perplexity is 55.130594116456415
At time: 474.1680166721344 and batch: 1400, loss is 4.019154396057129 and perplexity is 55.65402466090138
At time: 475.07336592674255 and batch: 1450, loss is 3.942253952026367 and perplexity is 51.53462707026013
At time: 475.98509192466736 and batch: 1500, loss is 3.9718061208724977 and perplexity is 53.08031377849014
At time: 476.88821482658386 and batch: 1550, loss is 3.964106755256653 and perplexity is 52.67319831227316
At time: 477.7932891845703 and batch: 1600, loss is 4.049560794830322 and perplexity is 57.3722533207937
At time: 478.6993055343628 and batch: 1650, loss is 4.012903122901917 and perplexity is 55.307201323709364
At time: 479.6042101383209 and batch: 1700, loss is 4.033416833877563 and perplexity is 56.45347422516934
At time: 480.51094579696655 and batch: 1750, loss is 4.019911556243897 and perplexity is 55.69617962962609
At time: 481.4218649864197 and batch: 1800, loss is 4.002149119377136 and perplexity is 54.71561415233248
At time: 482.3260359764099 and batch: 1850, loss is 4.029807500839233 and perplexity is 56.25008211126201
At time: 483.23544001579285 and batch: 1900, loss is 4.113909268379212 and perplexity is 61.18544095830957
At time: 484.1426274776459 and batch: 1950, loss is 4.044261951446533 and perplexity is 57.06905075675852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417094385901163 and perplexity of 82.85519005462486
finished 13 epochs...
Completing Train Step...
At time: 487.114639043808 and batch: 50, loss is 4.101190996170044 and perplexity is 60.412195461285116
At time: 488.02728509902954 and batch: 100, loss is 4.075010190010071 and perplexity is 58.851080278392665
At time: 488.91301345825195 and batch: 150, loss is 4.047817978858948 and perplexity is 57.27235112225307
At time: 489.79790139198303 and batch: 200, loss is 4.04391457080841 and perplexity is 57.049229516446474
At time: 490.6873664855957 and batch: 250, loss is 4.059254698753357 and perplexity is 57.93111885024915
At time: 491.58490443229675 and batch: 300, loss is 4.079125266075135 and perplexity is 59.0937559221634
At time: 492.48213267326355 and batch: 350, loss is 4.084052028656006 and perplexity is 59.385615197925375
At time: 493.3821952342987 and batch: 400, loss is 4.0224926471710205 and perplexity is 55.84012221808564
At time: 494.28306698799133 and batch: 450, loss is 4.051912641525268 and perplexity is 57.50734285782134
At time: 495.1952040195465 and batch: 500, loss is 4.078512058258057 and perplexity is 59.057530277150946
At time: 496.1061999797821 and batch: 550, loss is 4.043199367523194 and perplexity is 57.0084423073888
At time: 497.006041765213 and batch: 600, loss is 4.0417778062820435 and perplexity is 56.927458890467456
At time: 497.9418957233429 and batch: 650, loss is 4.094677538871765 and perplexity is 60.01998192555254
At time: 498.84385871887207 and batch: 700, loss is 4.114534125328064 and perplexity is 61.223685053560956
At time: 499.7439250946045 and batch: 750, loss is 4.080280776023865 and perplexity is 59.162078811326296
At time: 500.6440896987915 and batch: 800, loss is 4.062304954528809 and perplexity is 58.10809335163292
At time: 501.54407954216003 and batch: 850, loss is 4.059151611328125 and perplexity is 57.92514718817301
At time: 502.4440770149231 and batch: 900, loss is 4.043954362869263 and perplexity is 57.05149966802569
At time: 503.3441710472107 and batch: 950, loss is 4.130992903709411 and perplexity is 62.23969028452708
At time: 504.2451844215393 and batch: 1000, loss is 4.080800557136536 and perplexity is 59.19283813584422
At time: 505.14606738090515 and batch: 1050, loss is 4.035171604156494 and perplexity is 56.55262407104137
At time: 506.0458629131317 and batch: 1100, loss is 4.061847758293152 and perplexity is 58.081532622286744
At time: 506.9470601081848 and batch: 1150, loss is 4.01631929397583 and perplexity is 55.496463276594156
At time: 507.84694170951843 and batch: 1200, loss is 4.101617865562439 and perplexity is 60.437989083317106
At time: 508.7481994628906 and batch: 1250, loss is 4.0986861944198605 and perplexity is 60.261064244246555
At time: 509.6481490135193 and batch: 1300, loss is 4.089571018218994 and perplexity is 59.7142698750467
At time: 510.54812693595886 and batch: 1350, loss is 3.99495023727417 and perplexity is 54.32313728916363
At time: 511.4481725692749 and batch: 1400, loss is 4.004958605766296 and perplexity is 54.86955306895745
At time: 512.3513824939728 and batch: 1450, loss is 3.928088459968567 and perplexity is 50.80975989094763
At time: 513.2564504146576 and batch: 1500, loss is 3.9578468942642213 and perplexity is 52.34450128501677
At time: 514.1615090370178 and batch: 1550, loss is 3.949731636047363 and perplexity is 51.92143112451078
At time: 515.0682888031006 and batch: 1600, loss is 4.036131896972656 and perplexity is 56.60695723336933
At time: 515.9751570224762 and batch: 1650, loss is 3.9999769067764284 and perplexity is 54.59688920041733
At time: 516.8887465000153 and batch: 1700, loss is 4.021285457611084 and perplexity is 55.772753277240845
At time: 517.803909778595 and batch: 1750, loss is 4.008004531860352 and perplexity is 55.036936461730676
At time: 518.7129616737366 and batch: 1800, loss is 3.989579162597656 and perplexity is 54.03214583010333
At time: 519.6182074546814 and batch: 1850, loss is 4.018085021972656 and perplexity is 55.59454149977643
At time: 520.5259947776794 and batch: 1900, loss is 4.102581362724305 and perplexity is 60.49624897638156
At time: 521.4325983524323 and batch: 1950, loss is 4.032466149330139 and perplexity is 56.39983028284884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416379564861918 and perplexity of 82.79598458474194
finished 14 epochs...
Completing Train Step...
At time: 524.3990306854248 and batch: 50, loss is 4.08080370426178 and perplexity is 59.19302442341252
At time: 525.282356262207 and batch: 100, loss is 4.055490083694458 and perplexity is 57.71344048256118
At time: 526.1699404716492 and batch: 150, loss is 4.028136286735535 and perplexity is 56.15615468898117
At time: 527.0581862926483 and batch: 200, loss is 4.024383888244629 and perplexity is 55.94582927803891
At time: 527.9464514255524 and batch: 250, loss is 4.039182782173157 and perplexity is 56.779922275519866
At time: 528.8412985801697 and batch: 300, loss is 4.059372229576111 and perplexity is 57.93792794244195
At time: 529.7407133579254 and batch: 350, loss is 4.064126925468445 and perplexity is 58.21406111485579
At time: 530.6397650241852 and batch: 400, loss is 4.003068814277649 and perplexity is 54.765958971034685
At time: 531.5387451648712 and batch: 450, loss is 4.033120646476745 and perplexity is 56.436755893373274
At time: 532.4378626346588 and batch: 500, loss is 4.060686225891113 and perplexity is 58.01410820558875
At time: 533.3366799354553 and batch: 550, loss is 4.025108966827393 and perplexity is 55.98640911064925
At time: 534.2347159385681 and batch: 600, loss is 4.025171480178833 and perplexity is 55.98990911811532
At time: 535.1328048706055 and batch: 650, loss is 4.077608489990235 and perplexity is 59.00419186789254
At time: 536.030864238739 and batch: 700, loss is 4.097692775726318 and perplexity is 60.20122950193015
At time: 536.9298577308655 and batch: 750, loss is 4.063599562644958 and perplexity is 58.18336927679813
At time: 537.8303439617157 and batch: 800, loss is 4.045667552947998 and perplexity is 57.14932350271922
At time: 538.7300634384155 and batch: 850, loss is 4.042525525093079 and perplexity is 56.97004053991055
At time: 539.6296627521515 and batch: 900, loss is 4.026753034591675 and perplexity is 56.07853026706783
At time: 540.5287671089172 and batch: 950, loss is 4.115589308738708 and perplexity is 61.28832136595301
At time: 541.4280893802643 and batch: 1000, loss is 4.06509747505188 and perplexity is 58.270588174340695
At time: 542.3367676734924 and batch: 1050, loss is 4.019789814949036 and perplexity is 55.68939951731736
At time: 543.2919619083405 and batch: 1100, loss is 4.0460890197753905 and perplexity is 57.17341512333635
At time: 544.2037920951843 and batch: 1150, loss is 4.00100947856903 and perplexity is 54.65329352391467
At time: 545.1155033111572 and batch: 1200, loss is 4.086325221061706 and perplexity is 59.52076367845368
At time: 546.0273637771606 and batch: 1250, loss is 4.083991017341614 and perplexity is 59.381992114011815
At time: 546.9479224681854 and batch: 1300, loss is 4.075596551895142 and perplexity is 58.885598427837785
At time: 547.8688545227051 and batch: 1350, loss is 3.9810445213317873 and perplexity is 53.572963115729195
At time: 548.7784738540649 and batch: 1400, loss is 3.9913083028793337 and perplexity is 54.12565581260338
At time: 549.6904246807098 and batch: 1450, loss is 3.9143975019454955 and perplexity is 50.11886589334289
At time: 550.600861787796 and batch: 1500, loss is 3.944181318283081 and perplexity is 51.63404895194045
At time: 551.5117816925049 and batch: 1550, loss is 3.9356808948516844 and perplexity is 51.19699786369787
At time: 552.4391560554504 and batch: 1600, loss is 4.023125219345093 and perplexity is 55.87545630009789
At time: 553.3560769557953 and batch: 1650, loss is 3.9870467233657836 and perplexity is 53.895485818844094
At time: 554.2686576843262 and batch: 1700, loss is 4.009294519424438 and perplexity is 55.10797923762877
At time: 555.1800858974457 and batch: 1750, loss is 3.995709500312805 and perplexity is 54.364398501524555
At time: 556.0928297042847 and batch: 1800, loss is 3.9769399642944334 and perplexity is 53.35352049841639
At time: 557.0044186115265 and batch: 1850, loss is 4.006337251663208 and perplexity is 54.945250921438536
At time: 557.9260306358337 and batch: 1900, loss is 4.0907135009765625 and perplexity is 59.782531385133936
At time: 558.8386354446411 and batch: 1950, loss is 4.020299181938172 and perplexity is 55.71777308474213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416028967569041 and perplexity of 82.76696162466831
finished 15 epochs...
Completing Train Step...
At time: 561.7994754314423 and batch: 50, loss is 4.061700148582458 and perplexity is 58.072959856787016
At time: 562.7018599510193 and batch: 100, loss is 4.0375928926467894 and perplexity is 56.68972019645713
At time: 563.5805850028992 and batch: 150, loss is 4.01012930393219 and perplexity is 55.15400173170974
At time: 564.460578918457 and batch: 200, loss is 4.00648654460907 and perplexity is 54.9534544721606
At time: 565.3470544815063 and batch: 250, loss is 4.020891103744507 and perplexity is 55.75076341251539
At time: 566.2657425403595 and batch: 300, loss is 4.0413471126556395 and perplexity is 56.90294587593444
At time: 567.1513969898224 and batch: 350, loss is 4.04597017288208 and perplexity is 57.16662064432833
At time: 568.0488419532776 and batch: 400, loss is 3.9853525590896606 and perplexity is 53.80425531367764
At time: 568.9489891529083 and batch: 450, loss is 4.015634956359864 and perplexity is 55.458497951252674
At time: 569.8487384319305 and batch: 500, loss is 4.044277830123901 and perplexity is 57.069956944997735
At time: 570.7488069534302 and batch: 550, loss is 4.008213844299316 and perplexity is 55.04845758284952
At time: 571.6488854885101 and batch: 600, loss is 4.009812479019165 and perplexity is 55.1365303377407
At time: 572.5478479862213 and batch: 650, loss is 4.061826329231263 and perplexity is 58.08028800286512
At time: 573.4468619823456 and batch: 700, loss is 4.082293090820312 and perplexity is 59.28125140407787
At time: 574.3469080924988 and batch: 750, loss is 4.04821298122406 and perplexity is 57.29497830500302
At time: 575.2458472251892 and batch: 800, loss is 4.029868760108948 and perplexity is 56.253528055760476
At time: 576.1457192897797 and batch: 850, loss is 4.027110056877136 and perplexity is 56.09855512655695
At time: 577.0529706478119 and batch: 900, loss is 4.010149655342102 and perplexity is 55.155124204829185
At time: 577.9499809741974 and batch: 950, loss is 4.100907516479492 and perplexity is 60.395072257965055
At time: 578.851381778717 and batch: 1000, loss is 4.050269703865052 and perplexity is 57.41293944919371
At time: 579.7496211528778 and batch: 1050, loss is 4.005314292907715 and perplexity is 54.88907293471633
At time: 580.6478598117828 and batch: 1100, loss is 4.031185665130615 and perplexity is 56.327657409289415
At time: 581.546689748764 and batch: 1150, loss is 3.9866335582733154 and perplexity is 53.873222684953724
At time: 582.4449524879456 and batch: 1200, loss is 4.071736564636231 and perplexity is 58.65873888731539
At time: 583.3448028564453 and batch: 1250, loss is 4.070229902267456 and perplexity is 58.57042651800183
At time: 584.2448949813843 and batch: 1300, loss is 4.062433528900146 and perplexity is 58.11556504352897
At time: 585.1448705196381 and batch: 1350, loss is 3.967934184074402 and perplexity is 52.875187532515945
At time: 586.0440626144409 and batch: 1400, loss is 3.9785169887542726 and perplexity is 53.43772668541744
At time: 586.942666053772 and batch: 1450, loss is 3.9008611392974855 and perplexity is 49.445009818568124
At time: 587.8396444320679 and batch: 1500, loss is 3.9307138204574583 and perplexity is 50.943329083937286
At time: 588.7377049922943 and batch: 1550, loss is 3.9219129037857057 and perplexity is 50.4969482511851
At time: 589.639169216156 and batch: 1600, loss is 4.0104181098937985 and perplexity is 55.169932836604744
At time: 590.5435252189636 and batch: 1650, loss is 3.9740953779220582 and perplexity is 53.201967456140835
At time: 591.447103023529 and batch: 1700, loss is 3.99723352432251 and perplexity is 54.447314316912056
At time: 592.3485126495361 and batch: 1750, loss is 3.9832739543914797 and perplexity is 53.69253368857327
At time: 593.2636430263519 and batch: 1800, loss is 3.9643834972381593 and perplexity is 52.68777721475051
At time: 594.167295217514 and batch: 1850, loss is 3.9945353984832765 and perplexity is 54.30060661819433
At time: 595.075451374054 and batch: 1900, loss is 4.078882703781128 and perplexity is 59.07942374345878
At time: 595.982013463974 and batch: 1950, loss is 4.007729787826538 and perplexity is 55.02181746882005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416034361373547 and perplexity of 82.76740805468286
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 598.9546744823456 and batch: 50, loss is 4.059668865203857 and perplexity is 57.95511694537679
At time: 599.8691053390503 and batch: 100, loss is 4.054440493583679 and perplexity is 57.652896804752515
At time: 600.7559220790863 and batch: 150, loss is 4.027300601005554 and perplexity is 56.10924539530067
At time: 601.6568946838379 and batch: 200, loss is 4.023415923118591 and perplexity is 55.89170186729972
At time: 602.5627546310425 and batch: 250, loss is 4.037960176467895 and perplexity is 56.71054523762456
At time: 603.4632830619812 and batch: 300, loss is 4.051258397102356 and perplexity is 57.46973130439625
At time: 604.3631567955017 and batch: 350, loss is 4.052828521728515 and perplexity is 57.56003682168187
At time: 605.2631521224976 and batch: 400, loss is 3.994194917678833 and perplexity is 54.282121451072065
At time: 606.1700158119202 and batch: 450, loss is 4.022432589530945 and perplexity is 55.83676869282712
At time: 607.0696823596954 and batch: 500, loss is 4.04993845462799 and perplexity is 57.393924606303685
At time: 607.9779460430145 and batch: 550, loss is 4.011592779159546 and perplexity is 55.23477733906701
At time: 608.885143995285 and batch: 600, loss is 4.008640613555908 and perplexity is 55.07195558592469
At time: 609.7912156581879 and batch: 650, loss is 4.0554197931289675 and perplexity is 57.70938391476414
At time: 610.698136806488 and batch: 700, loss is 4.07272804737091 and perplexity is 58.716926855576446
At time: 611.631409406662 and batch: 750, loss is 4.039162645339966 and perplexity is 56.77877891920822
At time: 612.5384244918823 and batch: 800, loss is 4.011732888221741 and perplexity is 55.242516774090355
At time: 613.4442076683044 and batch: 850, loss is 4.016833367347718 and perplexity is 55.524999864920254
At time: 614.3513441085815 and batch: 900, loss is 3.9907574224472047 and perplexity is 54.095847259168295
At time: 615.2584235668182 and batch: 950, loss is 4.086030445098877 and perplexity is 59.50322097374289
At time: 616.1705281734467 and batch: 1000, loss is 4.0335375642776485 and perplexity is 56.4602902871434
At time: 617.077627658844 and batch: 1050, loss is 3.9876589965820313 and perplexity is 53.9284946854789
At time: 617.9831233024597 and batch: 1100, loss is 4.010954222679138 and perplexity is 55.199518072767845
At time: 618.8906002044678 and batch: 1150, loss is 3.9671340799331665 and perplexity is 52.83289879595518
At time: 619.7974238395691 and batch: 1200, loss is 4.045543508529663 and perplexity is 57.14223488778772
At time: 620.704507112503 and batch: 1250, loss is 4.041974086761474 and perplexity is 56.9386337360574
At time: 621.6122996807098 and batch: 1300, loss is 4.030535340309143 and perplexity is 56.29103804407244
At time: 622.5180687904358 and batch: 1350, loss is 3.93450665473938 and perplexity is 51.13691557759559
At time: 623.4275419712067 and batch: 1400, loss is 3.9430549716949463 and perplexity is 51.5759238577177
At time: 624.333464384079 and batch: 1450, loss is 3.859181451797485 and perplexity is 47.42651458786591
At time: 625.2389764785767 and batch: 1500, loss is 3.887123703956604 and perplexity is 48.770406462317304
At time: 626.1448483467102 and batch: 1550, loss is 3.8804992961883547 and perplexity is 48.44839913435719
At time: 627.0605840682983 and batch: 1600, loss is 3.967992968559265 and perplexity is 52.87829586453703
At time: 627.9667599201202 and batch: 1650, loss is 3.9251538848876955 and perplexity is 50.660873401844505
At time: 628.8733747005463 and batch: 1700, loss is 3.9429451274871825 and perplexity is 51.57025885236157
At time: 629.7798929214478 and batch: 1750, loss is 3.9273741626739502 and perplexity is 50.773479575925414
At time: 630.6918737888336 and batch: 1800, loss is 3.9103587007522584 and perplexity is 49.9168539755565
At time: 631.6065719127655 and batch: 1850, loss is 3.9379408073425295 and perplexity is 51.3128294339721
At time: 632.518150806427 and batch: 1900, loss is 4.017517051696777 and perplexity is 55.5629744181341
At time: 633.4257011413574 and batch: 1950, loss is 3.951070799827576 and perplexity is 51.991009002178195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388530216660611 and perplexity of 80.52198209577931
finished 17 epochs...
Completing Train Step...
At time: 636.3784523010254 and batch: 50, loss is 4.0410529184341435 and perplexity is 56.88620782031199
At time: 637.2512438297272 and batch: 100, loss is 4.03059531211853 and perplexity is 56.29441402070692
At time: 638.12726521492 and batch: 150, loss is 4.001350402832031 and perplexity is 54.67192933424933
At time: 639.0211765766144 and batch: 200, loss is 3.9969341373443603 and perplexity is 54.431015939893015
At time: 639.9215960502625 and batch: 250, loss is 4.012319197654724 and perplexity is 55.274915479681994
At time: 640.8207142353058 and batch: 300, loss is 4.026366386413574 and perplexity is 56.056851796750124
At time: 641.7207131385803 and batch: 350, loss is 4.030127220153808 and perplexity is 56.268069224219914
At time: 642.6190612316132 and batch: 400, loss is 3.971205892562866 and perplexity is 53.048463031292485
At time: 643.5186882019043 and batch: 450, loss is 4.001360964775086 and perplexity is 54.67250677910309
At time: 644.4177656173706 and batch: 500, loss is 4.028907976150513 and perplexity is 56.199506524065285
At time: 645.3166673183441 and batch: 550, loss is 3.9910841178894043 and perplexity is 54.1135230130467
At time: 646.216915845871 and batch: 600, loss is 3.9897682428359986 and perplexity is 54.04236320703663
At time: 647.1158030033112 and batch: 650, loss is 4.03882963180542 and perplexity is 56.759873965330634
At time: 648.0147116184235 and batch: 700, loss is 4.058147196769714 and perplexity is 57.86699553611094
At time: 648.9159100055695 and batch: 750, loss is 4.024547200202942 and perplexity is 55.95496664707826
At time: 649.8153831958771 and batch: 800, loss is 3.998723039627075 and perplexity is 54.528474854805616
At time: 650.7149534225464 and batch: 850, loss is 4.0036893081665035 and perplexity is 54.79995145886834
At time: 651.614089012146 and batch: 900, loss is 3.9788142538070677 and perplexity is 53.45361421534854
At time: 652.5137639045715 and batch: 950, loss is 4.074759273529053 and perplexity is 58.83631542487514
At time: 653.4138910770416 and batch: 1000, loss is 4.02164210319519 and perplexity is 55.79264793086992
At time: 654.3137378692627 and batch: 1050, loss is 3.977113518714905 and perplexity is 53.362781041327445
At time: 655.2140021324158 and batch: 1100, loss is 4.000343589782715 and perplexity is 54.61691262278324
At time: 656.1136515140533 and batch: 1150, loss is 3.9577826166152956 and perplexity is 52.341136811671355
At time: 657.0563426017761 and batch: 1200, loss is 4.037168788909912 and perplexity is 56.66568297177796
At time: 657.9541635513306 and batch: 1250, loss is 4.034629502296448 and perplexity is 56.5219750965256
At time: 658.8646078109741 and batch: 1300, loss is 4.024578399658203 and perplexity is 55.95671243879053
At time: 659.768792629242 and batch: 1350, loss is 3.929083776473999 and perplexity is 50.86035685942605
At time: 660.6721632480621 and batch: 1400, loss is 3.9387679433822633 and perplexity is 51.355289682277686
At time: 661.5819993019104 and batch: 1450, loss is 3.8564811086654665 and perplexity is 47.29861948297305
At time: 662.4865169525146 and batch: 1500, loss is 3.884894189834595 and perplexity is 48.66179327468186
At time: 663.3904097080231 and batch: 1550, loss is 3.879616069793701 and perplexity is 48.40562712092911
At time: 664.294695854187 and batch: 1600, loss is 3.9680051517486574 and perplexity is 52.878940094754675
At time: 665.2079873085022 and batch: 1650, loss is 3.925918402671814 and perplexity is 50.69961934961504
At time: 666.1218373775482 and batch: 1700, loss is 3.9444301319122315 and perplexity is 51.64689780546656
At time: 667.0324742794037 and batch: 1750, loss is 3.9307395124435427 and perplexity is 50.94463793605264
At time: 667.9359164237976 and batch: 1800, loss is 3.913839316368103 and perplexity is 50.09089807158949
At time: 668.8482093811035 and batch: 1850, loss is 3.9419996166229248 and perplexity is 51.52152165674893
At time: 669.7544493675232 and batch: 1900, loss is 4.022012057304383 and perplexity is 55.813292468765034
At time: 670.6589555740356 and batch: 1950, loss is 3.9558360052108763 and perplexity is 52.23934806154671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386548987100291 and perplexity of 80.36260749556253
finished 18 epochs...
Completing Train Step...
At time: 673.6220314502716 and batch: 50, loss is 4.0322256278991695 and perplexity is 56.386266546212845
At time: 674.5270674228668 and batch: 100, loss is 4.02025776386261 and perplexity is 55.71546540959641
At time: 675.4020817279816 and batch: 150, loss is 3.9909801959991453 and perplexity is 54.107899725643
At time: 676.2954943180084 and batch: 200, loss is 3.9863565587997436 and perplexity is 53.858301897250946
At time: 677.1918370723724 and batch: 250, loss is 4.00172034740448 and perplexity is 54.69215865940564
At time: 678.0897691249847 and batch: 300, loss is 4.015944294929504 and perplexity is 55.47565605737851
At time: 678.9878799915314 and batch: 350, loss is 4.020067853927612 and perplexity is 55.70488549382949
At time: 679.9118506908417 and batch: 400, loss is 3.9610461091995237 and perplexity is 52.512230753560274
At time: 680.8181974887848 and batch: 450, loss is 3.9911741638183593 and perplexity is 54.118395934885534
At time: 681.714061498642 and batch: 500, loss is 4.019088592529297 and perplexity is 55.65036255023186
At time: 682.6088228225708 and batch: 550, loss is 3.981083183288574 and perplexity is 53.57503439135364
At time: 683.5037400722504 and batch: 600, loss is 3.9804410791397093 and perplexity is 53.540644681564615
At time: 684.406613111496 and batch: 650, loss is 4.030353379249573 and perplexity is 56.28079619898239
At time: 685.304856300354 and batch: 700, loss is 4.050260848999024 and perplexity is 57.41243106755744
At time: 686.2016303539276 and batch: 750, loss is 4.016913919448853 and perplexity is 55.529472700470635
At time: 687.0986797809601 and batch: 800, loss is 3.9915436506271362 and perplexity is 54.13839566288594
At time: 687.9956541061401 and batch: 850, loss is 3.996895318031311 and perplexity is 54.42890300625723
At time: 688.8922100067139 and batch: 900, loss is 3.9721057271957396 and perplexity is 53.096219358725065
At time: 689.788449048996 and batch: 950, loss is 4.0686293935775755 and perplexity is 58.47675901920777
At time: 690.6947498321533 and batch: 1000, loss is 4.015310564041138 and perplexity is 55.44051055815302
At time: 691.5951890945435 and batch: 1050, loss is 3.9714081382751463 and perplexity is 53.059192940486106
At time: 692.498786687851 and batch: 1100, loss is 3.994525589942932 and perplexity is 54.30007401111564
At time: 693.4154644012451 and batch: 1150, loss is 3.952515597343445 and perplexity is 52.06617977302736
At time: 694.3258697986603 and batch: 1200, loss is 4.032155599594116 and perplexity is 56.38231804979319
At time: 695.2350549697876 and batch: 1250, loss is 4.029936370849609 and perplexity is 56.25733152703344
At time: 696.1444079875946 and batch: 1300, loss is 4.020684795379639 and perplexity is 55.739262750057826
At time: 697.0541207790375 and batch: 1350, loss is 3.9256351518630983 and perplexity is 50.68526067508178
At time: 697.9656281471252 and batch: 1400, loss is 3.9356706380844115 and perplexity is 51.196472750698696
At time: 698.8845963478088 and batch: 1450, loss is 3.8541223287582396 and perplexity is 47.18718392733932
At time: 699.7929413318634 and batch: 1500, loss is 3.882639627456665 and perplexity is 48.552205808631086
At time: 700.7017686367035 and batch: 1550, loss is 3.8781053256988525 and perplexity is 48.332553817028135
At time: 701.6150469779968 and batch: 1600, loss is 3.9669004487991333 and perplexity is 52.82055682768539
At time: 702.5398237705231 and batch: 1650, loss is 3.9249449396133422 and perplexity is 50.650289157555
At time: 703.451611995697 and batch: 1700, loss is 3.94361358165741 and perplexity is 51.60474273111337
At time: 704.3639442920685 and batch: 1750, loss is 3.930996608734131 and perplexity is 50.957737297317806
At time: 705.274112701416 and batch: 1800, loss is 3.913944306373596 and perplexity is 50.096157391336355
At time: 706.1848509311676 and batch: 1850, loss is 3.9423228025436403 and perplexity is 51.53817537814142
At time: 707.0954196453094 and batch: 1900, loss is 4.022506484985351 and perplexity is 55.840894928675404
At time: 708.0063321590424 and batch: 1950, loss is 3.9564331197738647 and perplexity is 52.27055025174928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385618981649709 and perplexity of 80.28790457501461
finished 19 epochs...
Completing Train Step...
At time: 710.9688858985901 and batch: 50, loss is 4.024460139274598 and perplexity is 55.95009536778859
At time: 711.8780128955841 and batch: 100, loss is 4.012080926895141 and perplexity is 55.26174665252028
At time: 712.7603826522827 and batch: 150, loss is 3.9828891944885254 and perplexity is 53.67187892833847
At time: 713.6447405815125 and batch: 200, loss is 3.978284659385681 and perplexity is 53.425312974208325
At time: 714.5290830135345 and batch: 250, loss is 3.9938129997253418 and perplexity is 54.261394092663394
At time: 715.4178221225739 and batch: 300, loss is 4.0084943151473995 and perplexity is 55.063899235798985
At time: 716.3061456680298 and batch: 350, loss is 4.013024678230286 and perplexity is 55.31392461734524
At time: 717.1991488933563 and batch: 400, loss is 3.953961801528931 and perplexity is 52.141532574772604
At time: 718.0937385559082 and batch: 450, loss is 3.983960299491882 and perplexity is 53.72939794535249
At time: 718.990415096283 and batch: 500, loss is 4.012022800445557 and perplexity is 55.258534576743735
At time: 719.8876612186432 and batch: 550, loss is 3.9736698770523073 and perplexity is 53.17933478816722
At time: 720.7849204540253 and batch: 600, loss is 3.9734285736083983 and perplexity is 53.16650397965944
At time: 721.68163895607 and batch: 650, loss is 4.023892030715943 and perplexity is 55.91831866691511
At time: 722.5779685974121 and batch: 700, loss is 4.044112119674683 and perplexity is 57.06050064032138
At time: 723.4755709171295 and batch: 750, loss is 4.010981721878052 and perplexity is 55.201036036166556
At time: 724.3719408512115 and batch: 800, loss is 3.98577693939209 and perplexity is 53.827093625541735
At time: 725.2945182323456 and batch: 850, loss is 3.99160973072052 and perplexity is 54.14197325132938
At time: 726.1926975250244 and batch: 900, loss is 3.966730456352234 and perplexity is 52.81157849512964
At time: 727.0899150371552 and batch: 950, loss is 4.063698844909668 and perplexity is 58.18914614023368
At time: 727.9867515563965 and batch: 1000, loss is 4.010272440910339 and perplexity is 55.16189687388037
At time: 728.8839638233185 and batch: 1050, loss is 3.966739478111267 and perplexity is 52.81205495061421
At time: 729.780725479126 and batch: 1100, loss is 3.9896709012985228 and perplexity is 54.03710289634075
At time: 730.6774182319641 and batch: 1150, loss is 3.9480549335479735 and perplexity is 51.834447274570095
At time: 731.5747013092041 and batch: 1200, loss is 4.027803030014038 and perplexity is 56.137443390983734
At time: 732.4717040061951 and batch: 1250, loss is 4.025735983848572 and perplexity is 56.02152454995491
At time: 733.3684704303741 and batch: 1300, loss is 4.016994929313659 and perplexity is 55.5339713177606
At time: 734.2674045562744 and batch: 1350, loss is 3.922410936355591 and perplexity is 50.522103639675436
At time: 735.1709041595459 and batch: 1400, loss is 3.932616534233093 and perplexity is 51.04035193204568
At time: 736.0743668079376 and batch: 1450, loss is 3.8514753341674806 and perplexity is 47.06244487136656
At time: 736.9761803150177 and batch: 1500, loss is 3.879964532852173 and perplexity is 48.422497633007325
At time: 737.8796877861023 and batch: 1550, loss is 3.8760350275039674 and perplexity is 48.23259452657909
At time: 738.7837102413177 and batch: 1600, loss is 3.9652013874053953 and perplexity is 52.73088765706821
At time: 739.6886601448059 and batch: 1650, loss is 3.9232372856140136 and perplexity is 50.56386979689188
At time: 740.5913097858429 and batch: 1700, loss is 3.941880898475647 and perplexity is 51.51540548021067
At time: 741.4937553405762 and batch: 1750, loss is 3.9299970960617063 and perplexity is 50.90682983869421
At time: 742.3971922397614 and batch: 1800, loss is 3.91274600982666 and perplexity is 50.036163291459786
At time: 743.3008613586426 and batch: 1850, loss is 3.9412783575057984 and perplexity is 51.484374687431284
At time: 744.2064349651337 and batch: 1900, loss is 4.021529173851013 and perplexity is 55.78634765947863
At time: 745.1093649864197 and batch: 1950, loss is 3.9555034255981445 and perplexity is 52.221977208154996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385014307776163 and perplexity of 80.2393712516514
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
3864.3780574798584


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}, {'best_accuracy': -75.95030619273909, 'params': {'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}}, {'best_accuracy': -76.28212132931245, 'params': {'wordvec_dim': 300, 'dropout': 0.022236433569113312, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5875562008890167}}, {'best_accuracy': -80.2393712516514, 'params': {'wordvec_dim': 300, 'dropout': 0.968078670033271, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.28515311562638934}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.25274251415391286, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5835372336256769}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3067779541015625 and batch: 50, loss is 7.41911322593689 and perplexity is 1667.554108163158
At time: 2.153961181640625 and batch: 100, loss is 6.661452417373657 and perplexity is 781.6854465600783
At time: 2.979400873184204 and batch: 150, loss is 6.3458724784851075 and perplexity is 570.1346029546534
At time: 3.80729079246521 and batch: 200, loss is 6.109115018844604 and perplexity is 449.9403501899011
At time: 4.634991884231567 and batch: 250, loss is 5.994280261993408 and perplexity is 401.127873093528
At time: 5.462884426116943 and batch: 300, loss is 5.910179891586304 and perplexity is 368.772488510738
At time: 6.2908244132995605 and batch: 350, loss is 5.80963828086853 and perplexity is 333.4984710770406
At time: 7.119518756866455 and batch: 400, loss is 5.7325953769683835 and perplexity is 308.7696028591148
At time: 7.947703123092651 and batch: 450, loss is 5.632517490386963 and perplexity is 279.36453062339046
At time: 8.775678634643555 and batch: 500, loss is 5.588465747833252 and perplexity is 267.32516071330707
At time: 9.614525556564331 and batch: 550, loss is 5.524277944564819 and perplexity is 250.70524956268434
At time: 10.442892789840698 and batch: 600, loss is 5.537581691741943 and perplexity is 254.06285365519875
At time: 11.277865409851074 and batch: 650, loss is 5.596039714813233 and perplexity is 269.35755959879214
At time: 12.114804744720459 and batch: 700, loss is 5.526605968475342 and perplexity is 251.28957727870062
At time: 12.948960304260254 and batch: 750, loss is 5.4736770915985105 and perplexity is 238.3349629603773
At time: 13.777878522872925 and batch: 800, loss is 5.450359621047974 and perplexity is 232.84188569600693
At time: 14.607483148574829 and batch: 850, loss is 5.45786208152771 and perplexity is 234.59534213557583
At time: 15.445488452911377 and batch: 900, loss is 5.457365989685059 and perplexity is 234.47899016303677
At time: 16.276284217834473 and batch: 950, loss is 5.484386672973633 and perplexity is 240.90114749442424
At time: 17.111854314804077 and batch: 1000, loss is 5.452278919219971 and perplexity is 233.2892078365541
At time: 17.945024967193604 and batch: 1050, loss is 5.34639458656311 and perplexity is 209.85033508528716
At time: 18.77408218383789 and batch: 1100, loss is 5.425517416000366 and perplexity is 227.1288360110291
At time: 19.618505716323853 and batch: 1150, loss is 5.3269823455810545 and perplexity is 205.81595468328442
At time: 20.480135679244995 and batch: 1200, loss is 5.404268274307251 and perplexity is 222.3534592038017
At time: 21.37068009376526 and batch: 1250, loss is 5.354808406829834 and perplexity is 211.6234268652812
At time: 22.291267156600952 and batch: 1300, loss is 5.369267139434815 and perplexity is 214.70546086734907
At time: 23.2295982837677 and batch: 1350, loss is 5.301868963241577 and perplexity is 200.71158221725125
At time: 24.163703680038452 and batch: 1400, loss is 5.303410902023315 and perplexity is 201.0213059159414
At time: 25.094818353652954 and batch: 1450, loss is 5.265437088012695 and perplexity is 193.53088033135046
At time: 26.020957946777344 and batch: 1500, loss is 5.238406076431274 and perplexity is 188.3696162223502
At time: 26.946237325668335 and batch: 1550, loss is 5.230937843322754 and perplexity is 186.96806807618856
At time: 27.87169361114502 and batch: 1600, loss is 5.271514749526977 and perplexity is 194.71067708562367
At time: 28.79603385925293 and batch: 1650, loss is 5.249410772323609 and perplexity is 190.4540146138514
At time: 29.721224069595337 and batch: 1700, loss is 5.262813215255737 and perplexity is 193.02374554634838
At time: 30.646783590316772 and batch: 1750, loss is 5.270034341812134 and perplexity is 194.4226391564955
At time: 31.578738689422607 and batch: 1800, loss is 5.239460477828979 and perplexity is 188.56833815691206
At time: 32.50392818450928 and batch: 1850, loss is 5.220943078994751 and perplexity is 185.10867388099683
At time: 33.43529748916626 and batch: 1900, loss is 5.28195478439331 and perplexity is 196.7541115465577
At time: 34.365527629852295 and batch: 1950, loss is 5.200057144165039 and perplexity is 181.28260082203178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.826011196402616 and perplexity of 124.71251348927771
finished 1 epochs...
Completing Train Step...
At time: 37.405410289764404 and batch: 50, loss is 5.043085947036743 and perplexity is 154.94743758251028
At time: 38.32122445106506 and batch: 100, loss is 4.99422703742981 and perplexity is 147.55884382785848
At time: 39.237385272979736 and batch: 150, loss is 4.936594915390015 and perplexity is 139.29512940552434
At time: 40.16272568702698 and batch: 200, loss is 4.904467687606812 and perplexity is 134.89108669510867
At time: 41.08107352256775 and batch: 250, loss is 4.90762619972229 and perplexity is 135.31781538581419
At time: 41.99848484992981 and batch: 300, loss is 4.919662532806396 and perplexity is 136.95638709941318
At time: 42.92527723312378 and batch: 350, loss is 4.9177982616424565 and perplexity is 136.70130110483782
At time: 43.84250211715698 and batch: 400, loss is 4.867096109390259 and perplexity is 129.94302814897108
At time: 44.764214515686035 and batch: 450, loss is 4.854607009887696 and perplexity is 128.3302487847992
At time: 45.687195777893066 and batch: 500, loss is 4.845762233734131 and perplexity is 127.20020133589487
At time: 46.635114431381226 and batch: 550, loss is 4.801462306976318 and perplexity is 121.68823302871236
At time: 47.552793741226196 and batch: 600, loss is 4.790035791397095 and perplexity is 120.30567449432776
At time: 48.46943473815918 and batch: 650, loss is 4.865277299880981 and perplexity is 129.7069013336516
At time: 49.38704466819763 and batch: 700, loss is 4.8580748653411865 and perplexity is 128.77605208182288
At time: 50.30447053909302 and batch: 750, loss is 4.811926574707031 and perplexity is 122.96829706453492
At time: 51.222630739212036 and batch: 800, loss is 4.794689197540283 and perplexity is 120.86681024277158
At time: 52.14006209373474 and batch: 850, loss is 4.789107332229614 and perplexity is 120.19402742583597
At time: 53.05720591545105 and batch: 900, loss is 4.782128963470459 and perplexity is 119.35818896625084
At time: 53.975072383880615 and batch: 950, loss is 4.844958944320679 and perplexity is 127.09806378926989
At time: 54.89236044883728 and batch: 1000, loss is 4.821479978561402 and perplexity is 124.14869228617447
At time: 55.80987739562988 and batch: 1050, loss is 4.734658813476562 and perplexity is 113.8246166671524
At time: 56.72705054283142 and batch: 1100, loss is 4.806741943359375 and perplexity is 122.33240164290112
At time: 57.64398407936096 and batch: 1150, loss is 4.73890380859375 and perplexity is 114.30882862068536
At time: 58.56129026412964 and batch: 1200, loss is 4.816499481201172 and perplexity is 123.53190727499086
At time: 59.478200912475586 and batch: 1250, loss is 4.785929126739502 and perplexity is 119.81263250474734
At time: 60.39521026611328 and batch: 1300, loss is 4.804930391311646 and perplexity is 122.11099073943979
At time: 61.31309938430786 and batch: 1350, loss is 4.69770917892456 and perplexity is 109.69559142586557
At time: 62.23067235946655 and batch: 1400, loss is 4.705575532913208 and perplexity is 110.56189865144651
At time: 63.14847493171692 and batch: 1450, loss is 4.6466291141510006 and perplexity is 104.23303505499575
At time: 64.06620216369629 and batch: 1500, loss is 4.644138612747192 and perplexity is 103.97376552444503
At time: 64.9834496974945 and batch: 1550, loss is 4.643701143264771 and perplexity is 103.92829012283107
At time: 65.90106129646301 and batch: 1600, loss is 4.7120161056518555 and perplexity is 111.27627864054554
At time: 66.81819295883179 and batch: 1650, loss is 4.681760892868042 and perplexity is 107.96001130538161
At time: 67.73482751846313 and batch: 1700, loss is 4.706696453094483 and perplexity is 110.68589919929974
At time: 68.65192914009094 and batch: 1750, loss is 4.7013419723510745 and perplexity is 110.09481756330385
At time: 69.56868028640747 and batch: 1800, loss is 4.65506217956543 and perplexity is 105.11575584771788
At time: 70.48581433296204 and batch: 1850, loss is 4.68267442703247 and perplexity is 108.05868152654807
At time: 71.40397310256958 and batch: 1900, loss is 4.762374429702759 and perplexity is 117.02346025563762
At time: 72.32135486602783 and batch: 1950, loss is 4.685352354049683 and perplexity is 108.3484425955866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.592345055868459 and perplexity of 98.72567613980286
finished 2 epochs...
Completing Train Step...
At time: 75.31838941574097 and batch: 50, loss is 4.651303806304932 and perplexity is 104.72143307193379
At time: 76.25384092330933 and batch: 100, loss is 4.61260495185852 and perplexity is 100.7462472363403
At time: 77.16510820388794 and batch: 150, loss is 4.5769384765625 and perplexity is 97.21630813527123
At time: 78.07769131660461 and batch: 200, loss is 4.565252275466919 and perplexity is 96.08683130939622
At time: 78.99607586860657 and batch: 250, loss is 4.56643684387207 and perplexity is 96.20072017517509
At time: 79.91405892372131 and batch: 300, loss is 4.586091594696045 and perplexity is 98.11022531190906
At time: 80.83205509185791 and batch: 350, loss is 4.589965000152588 and perplexity is 98.4909829322463
At time: 81.75031518936157 and batch: 400, loss is 4.547378616333008 and perplexity is 94.38466532198382
At time: 82.66890335083008 and batch: 450, loss is 4.565022077560425 and perplexity is 96.0647148676641
At time: 83.58706378936768 and batch: 500, loss is 4.562476062774659 and perplexity is 95.8204437740796
At time: 84.50497937202454 and batch: 550, loss is 4.521883888244629 and perplexity is 92.00876904788173
At time: 85.42265939712524 and batch: 600, loss is 4.515043277740478 and perplexity is 91.38152072255072
At time: 86.34752154350281 and batch: 650, loss is 4.58013916015625 and perplexity is 97.52796526964218
At time: 87.26764726638794 and batch: 700, loss is 4.596377811431885 and perplexity is 99.12461653338673
At time: 88.18552875518799 and batch: 750, loss is 4.554261150360108 and perplexity is 95.03651159666002
At time: 89.10388898849487 and batch: 800, loss is 4.53357928276062 and perplexity is 93.09116508749437
At time: 90.02159571647644 and batch: 850, loss is 4.528884925842285 and perplexity is 92.65518605386484
At time: 90.93968057632446 and batch: 900, loss is 4.51954047203064 and perplexity is 91.79340664709366
At time: 91.85898566246033 and batch: 950, loss is 4.594413347244263 and perplexity is 98.93008091578349
At time: 92.77681589126587 and batch: 1000, loss is 4.568850154876709 and perplexity is 96.43316279718333
At time: 93.72127747535706 and batch: 1050, loss is 4.49261365890503 and perplexity is 89.35468360846858
At time: 94.63949251174927 and batch: 1100, loss is 4.557120971679687 and perplexity is 95.30868804116061
At time: 95.5616626739502 and batch: 1150, loss is 4.5014136695861815 and perplexity is 90.14447577157176
At time: 96.4854805469513 and batch: 1200, loss is 4.577935647964478 and perplexity is 97.31329780717634
At time: 97.40376210212708 and batch: 1250, loss is 4.5605684089660645 and perplexity is 95.63782578090898
At time: 98.32076168060303 and batch: 1300, loss is 4.57355996131897 and perplexity is 96.88841556323334
At time: 99.23842811584473 and batch: 1350, loss is 4.461271266937256 and perplexity is 86.59752772383409
At time: 100.156569480896 and batch: 1400, loss is 4.479472789764404 and perplexity is 88.18816671336931
At time: 101.07525038719177 and batch: 1450, loss is 4.414117012023926 and perplexity is 82.60886605744676
At time: 101.99264812469482 and batch: 1500, loss is 4.416389389038086 and perplexity is 82.796797991076
At time: 102.91061997413635 and batch: 1550, loss is 4.41775860786438 and perplexity is 82.91024257314758
At time: 103.82887268066406 and batch: 1600, loss is 4.499748077392578 and perplexity is 89.99445680632071
At time: 104.74704217910767 and batch: 1650, loss is 4.46247410774231 and perplexity is 86.70175343469965
At time: 105.66506910324097 and batch: 1700, loss is 4.491602849960327 and perplexity is 89.26440872804082
At time: 106.58334565162659 and batch: 1750, loss is 4.487016611099243 and perplexity is 88.85595816966382
At time: 107.50798559188843 and batch: 1800, loss is 4.441542863845825 and perplexity is 84.90583881863867
At time: 108.42552828788757 and batch: 1850, loss is 4.4751253414154055 and perplexity is 87.80560539891117
At time: 109.34422183036804 and batch: 1900, loss is 4.55903172492981 and perplexity is 95.49097352242804
At time: 110.26115298271179 and batch: 1950, loss is 4.487551708221435 and perplexity is 88.90351746045506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.526076773710029 and perplexity of 92.39536118021171
finished 3 epochs...
Completing Train Step...
At time: 113.27776002883911 and batch: 50, loss is 4.457464742660522 and perplexity is 86.26851871989659
At time: 114.1714437007904 and batch: 100, loss is 4.421946115493775 and perplexity is 83.2581577868862
At time: 115.06784701347351 and batch: 150, loss is 4.395255174636841 and perplexity is 81.0653139357486
At time: 115.96978211402893 and batch: 200, loss is 4.393944244384766 and perplexity is 80.95911258980416
At time: 116.9015588760376 and batch: 250, loss is 4.388167695999146 and perplexity is 80.4927965040771
At time: 117.80815720558167 and batch: 300, loss is 4.4101806735992435 and perplexity is 82.28432876712066
At time: 118.71525597572327 and batch: 350, loss is 4.409574756622314 and perplexity is 82.23448639707942
At time: 119.6223452091217 and batch: 400, loss is 4.373351831436157 and perplexity is 79.30901714429915
At time: 120.5295820236206 and batch: 450, loss is 4.400815324783325 and perplexity is 81.51730465658898
At time: 121.4417405128479 and batch: 500, loss is 4.405242528915405 and perplexity is 81.87899845998064
At time: 122.35092258453369 and batch: 550, loss is 4.364270534515381 and perplexity is 78.59204883950132
At time: 123.25835156440735 and batch: 600, loss is 4.364739332199097 and perplexity is 78.6289012474426
At time: 124.17440247535706 and batch: 650, loss is 4.423469095230103 and perplexity is 83.38505488040285
At time: 125.09321212768555 and batch: 700, loss is 4.445910196304322 and perplexity is 85.27746175419972
At time: 126.01081800460815 and batch: 750, loss is 4.409119777679443 and perplexity is 82.19707994760962
At time: 126.92915534973145 and batch: 800, loss is 4.383873224258423 and perplexity is 80.14786364648147
At time: 127.84701991081238 and batch: 850, loss is 4.374347820281982 and perplexity is 79.38804739083713
At time: 128.77193570137024 and batch: 900, loss is 4.365195150375366 and perplexity is 78.66474989942418
At time: 129.69046831130981 and batch: 950, loss is 4.447773027420044 and perplexity is 85.43646731769992
At time: 130.60840463638306 and batch: 1000, loss is 4.422034111022949 and perplexity is 83.26548445489102
At time: 131.52687311172485 and batch: 1050, loss is 4.353557443618774 and perplexity is 77.75457903132984
At time: 132.44498872756958 and batch: 1100, loss is 4.410255784988403 and perplexity is 82.29050948947886
At time: 133.36297607421875 and batch: 1150, loss is 4.357422285079956 and perplexity is 78.05566961106251
At time: 134.28128576278687 and batch: 1200, loss is 4.433760747909546 and perplexity is 84.24765608614912
At time: 135.19987082481384 and batch: 1250, loss is 4.419450569152832 and perplexity is 83.05064223590072
At time: 136.1178481578827 and batch: 1300, loss is 4.4308836460113525 and perplexity is 84.00561534979829
At time: 137.0366473197937 and batch: 1350, loss is 4.321929488182068 and perplexity is 75.3338439125981
At time: 137.9555742740631 and batch: 1400, loss is 4.344460201263428 and perplexity is 77.05043452449246
At time: 138.87838006019592 and batch: 1450, loss is 4.270650038719177 and perplexity is 71.5681425656509
At time: 139.80839252471924 and batch: 1500, loss is 4.284159755706787 and perplexity is 72.5415684661028
At time: 140.7316174507141 and batch: 1550, loss is 4.279130640029908 and perplexity is 72.17766435183587
At time: 141.65426445007324 and batch: 1600, loss is 4.367529811859131 and perplexity is 78.84862001486509
At time: 142.58208966255188 and batch: 1650, loss is 4.32992579460144 and perplexity is 75.93865130222031
At time: 143.5140779018402 and batch: 1700, loss is 4.362727165222168 and perplexity is 78.4708458391849
At time: 144.43629336357117 and batch: 1750, loss is 4.353093166351318 and perplexity is 77.71848772667943
At time: 145.35927271842957 and batch: 1800, loss is 4.312103805541992 and perplexity is 74.59726210583078
At time: 146.28155970573425 and batch: 1850, loss is 4.347070035934448 and perplexity is 77.25178605274364
At time: 147.2094268798828 and batch: 1900, loss is 4.428591365814209 and perplexity is 83.81327147853003
At time: 148.13315343856812 and batch: 1950, loss is 4.357799100875854 and perplexity is 78.0850877625954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49153314634811 and perplexity of 89.25818689315474
finished 4 epochs...
Completing Train Step...
At time: 151.13431668281555 and batch: 50, loss is 4.330899930000305 and perplexity is 76.01266187290162
At time: 152.04972791671753 and batch: 100, loss is 4.296841058731079 and perplexity is 73.46734771467092
At time: 152.9363148212433 and batch: 150, loss is 4.271350965499878 and perplexity is 71.61832417818377
At time: 153.82321691513062 and batch: 200, loss is 4.2757209777832035 and perplexity is 71.93198197961581
At time: 154.71357417106628 and batch: 250, loss is 4.268946704864502 and perplexity is 71.44634188855983
At time: 155.6047863960266 and batch: 300, loss is 4.290769128799439 and perplexity is 73.02261069947296
At time: 156.49552822113037 and batch: 350, loss is 4.289069881439209 and perplexity is 72.89863258557783
At time: 157.39033818244934 and batch: 400, loss is 4.255003108978271 and perplexity is 70.45703623748675
At time: 158.28568696975708 and batch: 450, loss is 4.291620063781738 and perplexity is 73.08477463840009
At time: 159.17479968070984 and batch: 500, loss is 4.297049055099487 and perplexity is 73.48263024549249
At time: 160.07670831680298 and batch: 550, loss is 4.256172227859497 and perplexity is 70.53945705934872
At time: 160.97416019439697 and batch: 600, loss is 4.260755748748779 and perplexity is 70.86351823754788
At time: 161.87178373336792 and batch: 650, loss is 4.31468638420105 and perplexity is 74.7901643884117
At time: 162.76907753944397 and batch: 700, loss is 4.341243915557861 and perplexity is 76.8030164102802
At time: 163.7167205810547 and batch: 750, loss is 4.305100202560425 and perplexity is 74.07663774974597
At time: 164.62042927742004 and batch: 800, loss is 4.278440246582031 and perplexity is 72.12785056281973
At time: 165.5217089653015 and batch: 850, loss is 4.271089181900025 and perplexity is 71.59957812927607
At time: 166.42595291137695 and batch: 900, loss is 4.260042138099671 and perplexity is 70.81296731528371
At time: 167.3366539478302 and batch: 950, loss is 4.347203865051269 and perplexity is 77.26212528287354
At time: 168.24210000038147 and batch: 1000, loss is 4.317279777526855 and perplexity is 74.98437642682383
At time: 169.14899945259094 and batch: 1050, loss is 4.256130867004394 and perplexity is 70.53653954742208
At time: 170.05553197860718 and batch: 1100, loss is 4.3078474426269535 and perplexity is 74.28042385347035
At time: 170.97191452980042 and batch: 1150, loss is 4.257793583869934 and perplexity is 70.65391939905126
At time: 171.87491631507874 and batch: 1200, loss is 4.32796051979065 and perplexity is 75.78955753674866
At time: 172.7780864238739 and batch: 1250, loss is 4.319385499954223 and perplexity is 75.14243906958887
At time: 173.6813895702362 and batch: 1300, loss is 4.328969421386719 and perplexity is 75.8660603277176
At time: 174.58410668373108 and batch: 1350, loss is 4.222435431480408 and perplexity is 68.19937710707818
At time: 175.4872362613678 and batch: 1400, loss is 4.249130210876465 and perplexity is 70.04446193237406
At time: 176.39501523971558 and batch: 1450, loss is 4.1737892436981205 and perplexity is 64.96113991799311
At time: 177.3036813735962 and batch: 1500, loss is 4.190832362174988 and perplexity is 66.0777687118187
At time: 178.2167363166809 and batch: 1550, loss is 4.1819095087051394 and perplexity is 65.49078912488362
At time: 179.13045072555542 and batch: 1600, loss is 4.273797311782837 and perplexity is 71.79374187806395
At time: 180.04421496391296 and batch: 1650, loss is 4.238278322219848 and perplexity is 69.28845669195434
At time: 180.95792531967163 and batch: 1700, loss is 4.271025857925415 and perplexity is 71.59504430296
At time: 181.86947298049927 and batch: 1750, loss is 4.259807143211365 and perplexity is 70.79632858502372
At time: 182.78166890144348 and batch: 1800, loss is 4.218468265533447 and perplexity is 67.92935482635681
At time: 183.69400143623352 and batch: 1850, loss is 4.255288467407227 and perplexity is 70.4771446155675
At time: 184.60737800598145 and batch: 1900, loss is 4.333855037689209 and perplexity is 76.23761969804899
At time: 185.5232756137848 and batch: 1950, loss is 4.2642506408691405 and perplexity is 71.1116118667688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476425099927326 and perplexity of 87.91980568224065
finished 5 epochs...
Completing Train Step...
At time: 188.54068422317505 and batch: 50, loss is 4.239842114448547 and perplexity is 69.3968942068411
At time: 189.42545008659363 and batch: 100, loss is 4.210088248252869 and perplexity is 67.36248416935992
At time: 190.31169891357422 and batch: 150, loss is 4.184538621902465 and perplexity is 65.66319836526866
At time: 191.20297503471375 and batch: 200, loss is 4.18862434387207 and perplexity is 65.93202874655347
At time: 192.09581446647644 and batch: 250, loss is 4.178231282234192 and perplexity is 65.25034165194258
At time: 192.9956362247467 and batch: 300, loss is 4.202313723564148 and perplexity is 66.84080341073052
At time: 193.89541935920715 and batch: 350, loss is 4.201145277023316 and perplexity is 66.76274911521499
At time: 194.7947371006012 and batch: 400, loss is 4.168045825958252 and perplexity is 64.58911033790407
At time: 195.69247341156006 and batch: 450, loss is 4.2071183395385745 and perplexity is 67.16272052733166
At time: 196.59168934822083 and batch: 500, loss is 4.213433246612549 and perplexity is 67.58818884885073
At time: 197.4918291568756 and batch: 550, loss is 4.176184496879578 and perplexity is 65.11692479267988
At time: 198.39154958724976 and batch: 600, loss is 4.180295352935791 and perplexity is 65.38516206197926
At time: 199.30422282218933 and batch: 650, loss is 4.234748134613037 and perplexity is 69.04428667740005
At time: 200.20866799354553 and batch: 700, loss is 4.260817122459412 and perplexity is 70.8678675280753
At time: 201.11326026916504 and batch: 750, loss is 4.228549327850342 and perplexity is 68.61761826995767
At time: 202.01737880706787 and batch: 800, loss is 4.198513431549072 and perplexity is 66.5872708931794
At time: 202.9295802116394 and batch: 850, loss is 4.194298877716064 and perplexity is 66.30722580248631
At time: 203.8359203338623 and batch: 900, loss is 4.184457612037659 and perplexity is 65.6578792139011
At time: 204.74703001976013 and batch: 950, loss is 4.268477983474732 and perplexity is 71.41286130704117
At time: 205.65203261375427 and batch: 1000, loss is 4.240148682594299 and perplexity is 69.41817234545213
At time: 206.55706334114075 and batch: 1050, loss is 4.181861190795899 and perplexity is 65.4876248233254
At time: 207.461487531662 and batch: 1100, loss is 4.228707823753357 and perplexity is 68.62849474324359
At time: 208.36637210845947 and batch: 1150, loss is 4.182586755752563 and perplexity is 65.53515759096238
At time: 209.3101589679718 and batch: 1200, loss is 4.249999318122864 and perplexity is 70.10536454342636
At time: 210.22241854667664 and batch: 1250, loss is 4.243990898132324 and perplexity is 69.6854049797947
At time: 211.13344025611877 and batch: 1300, loss is 4.247270674705505 and perplexity is 69.91433274929436
At time: 212.04434084892273 and batch: 1350, loss is 4.147541551589966 and perplexity is 63.27824262050529
At time: 212.95542240142822 and batch: 1400, loss is 4.175650215148925 and perplexity is 65.08214330179186
At time: 213.86711978912354 and batch: 1450, loss is 4.095567264556885 and perplexity is 60.073407008402036
At time: 214.78032541275024 and batch: 1500, loss is 4.117050709724427 and perplexity is 61.37795365761768
At time: 215.69476628303528 and batch: 1550, loss is 4.110159983634949 and perplexity is 60.95646882703721
At time: 216.6084406375885 and batch: 1600, loss is 4.2057483959198 and perplexity is 67.07077438182331
At time: 217.53099608421326 and batch: 1650, loss is 4.169720501899719 and perplexity is 64.697366789004
At time: 218.44448733329773 and batch: 1700, loss is 4.200431318283081 and perplexity is 66.71510027863778
At time: 219.35753393173218 and batch: 1750, loss is 4.189007863998413 and perplexity is 65.95731985606317
At time: 220.27048516273499 and batch: 1800, loss is 4.145051651000976 and perplexity is 63.120882074290364
At time: 221.18312120437622 and batch: 1850, loss is 4.182309331893921 and perplexity is 65.51697909635743
At time: 222.09565925598145 and batch: 1900, loss is 4.259396104812622 and perplexity is 70.7672345552766
At time: 223.00802993774414 and batch: 1950, loss is 4.189949731826783 and perplexity is 66.01947219873237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.478738758175872 and perplexity of 88.12345756545173
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 225.96713995933533 and batch: 50, loss is 4.189566178321838 and perplexity is 65.99415505432609
At time: 226.8865988254547 and batch: 100, loss is 4.176961464881897 and perplexity is 65.16753821961365
At time: 227.77812218666077 and batch: 150, loss is 4.148426432609558 and perplexity is 63.334261117550405
At time: 228.6717131137848 and batch: 200, loss is 4.149866342544556 and perplexity is 63.425522437632075
At time: 229.57171416282654 and batch: 250, loss is 4.138270349502563 and perplexity is 62.69428840701494
At time: 230.4706747531891 and batch: 300, loss is 4.161558494567871 and perplexity is 64.17145557213374
At time: 231.36965441703796 and batch: 350, loss is 4.156986246109009 and perplexity is 63.87871747892392
At time: 232.2690167427063 and batch: 400, loss is 4.110228252410889 and perplexity is 60.96063039260053
At time: 233.19488096237183 and batch: 450, loss is 4.13870979309082 and perplexity is 62.72184506443048
At time: 234.09392142295837 and batch: 500, loss is 4.1440029096603395 and perplexity is 63.054719295686304
At time: 234.99355626106262 and batch: 550, loss is 4.111140651702881 and perplexity is 61.01627621035218
At time: 235.89367413520813 and batch: 600, loss is 4.09953731060028 and perplexity is 60.312375243787656
At time: 236.79363799095154 and batch: 650, loss is 4.143085508346558 and perplexity is 62.99689933947144
At time: 237.70120549201965 and batch: 700, loss is 4.165578002929688 and perplexity is 64.42991236102937
At time: 238.61474609375 and batch: 750, loss is 4.119992618560791 and perplexity is 61.558787870301025
At time: 239.53253030776978 and batch: 800, loss is 4.088812141418457 and perplexity is 59.66897129117368
At time: 240.44572687149048 and batch: 850, loss is 4.08521580696106 and perplexity is 59.45476711947315
At time: 241.35877799987793 and batch: 900, loss is 4.066175470352173 and perplexity is 58.33343746407109
At time: 242.27205061912537 and batch: 950, loss is 4.148597626686096 and perplexity is 63.34510449603029
At time: 243.1827027797699 and batch: 1000, loss is 4.110608558654786 and perplexity is 60.98381850998415
At time: 244.09575271606445 and batch: 1050, loss is 4.052521433830261 and perplexity is 57.54236354471448
At time: 245.00909399986267 and batch: 1100, loss is 4.083502449989319 and perplexity is 59.352987097379724
At time: 245.9216911792755 and batch: 1150, loss is 4.0434113788604735 and perplexity is 57.02053002479992
At time: 246.83481359481812 and batch: 1200, loss is 4.096395149230957 and perplexity is 60.123161454013285
At time: 247.74961400032043 and batch: 1250, loss is 4.0854604005813595 and perplexity is 59.46931115482362
At time: 248.66916179656982 and batch: 1300, loss is 4.084795503616333 and perplexity is 59.429783332745274
At time: 249.58395171165466 and batch: 1350, loss is 3.9850117492675783 and perplexity is 53.78592141936001
At time: 250.49535298347473 and batch: 1400, loss is 4.007706036567688 and perplexity is 55.02051064691038
At time: 251.40671229362488 and batch: 1450, loss is 3.9131359672546386 and perplexity is 50.055679069916906
At time: 252.31816291809082 and batch: 1500, loss is 3.938484377861023 and perplexity is 51.340729157319466
At time: 253.22976636886597 and batch: 1550, loss is 3.9256486082077027 and perplexity is 50.685942718004675
At time: 254.14126753807068 and batch: 1600, loss is 4.01646023273468 and perplexity is 55.50428543045832
At time: 255.05262970924377 and batch: 1650, loss is 3.9743086242675782 and perplexity is 53.213313791014556
At time: 255.9736201763153 and batch: 1700, loss is 3.986676044464111 and perplexity is 53.87551160159483
At time: 256.89162516593933 and batch: 1750, loss is 3.969468789100647 and perplexity is 52.95639235379391
At time: 257.80239844322205 and batch: 1800, loss is 3.927049994468689 and perplexity is 50.75702309565436
At time: 258.7128927707672 and batch: 1850, loss is 3.9514553499221803 and perplexity is 52.01100599428474
At time: 259.63239312171936 and batch: 1900, loss is 4.023409228324891 and perplexity is 55.89132768513868
At time: 260.55178332328796 and batch: 1950, loss is 3.9510568714141847 and perplexity is 51.99028485495531
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368144474473111 and perplexity of 78.897100211708
finished 7 epochs...
Completing Train Step...
At time: 263.5203011035919 and batch: 50, loss is 4.095849504470825 and perplexity is 60.09036451455617
At time: 264.4064164161682 and batch: 100, loss is 4.0787144947052 and perplexity is 59.069486883942965
At time: 265.2923676967621 and batch: 150, loss is 4.049060506820679 and perplexity is 57.34355784896984
At time: 266.18255138397217 and batch: 200, loss is 4.050707483291626 and perplexity is 57.438079155325305
At time: 267.09033703804016 and batch: 250, loss is 4.038612990379334 and perplexity is 56.7475787571641
At time: 267.9940083026886 and batch: 300, loss is 4.06408196926117 and perplexity is 58.211444090284175
At time: 268.89400839805603 and batch: 350, loss is 4.065894780158996 and perplexity is 58.31706613798348
At time: 269.79499888420105 and batch: 400, loss is 4.021719770431519 and perplexity is 55.79698135992271
At time: 270.69488406181335 and batch: 450, loss is 4.058583946228027 and perplexity is 57.89227443493638
At time: 271.6016159057617 and batch: 500, loss is 4.066439208984375 and perplexity is 58.34882427403842
At time: 272.51094794273376 and batch: 550, loss is 4.035264368057251 and perplexity is 56.55787035637745
At time: 273.41151785850525 and batch: 600, loss is 4.02683207988739 and perplexity is 56.082963186274455
At time: 274.3117368221283 and batch: 650, loss is 4.074086532592774 and perplexity is 58.79674713804447
At time: 275.21683526039124 and batch: 700, loss is 4.099702291488647 and perplexity is 60.32232645389206
At time: 276.1329369544983 and batch: 750, loss is 4.057779445648193 and perplexity is 57.84571879611576
At time: 277.0478014945984 and batch: 800, loss is 4.0294819879531865 and perplexity is 56.23177496446136
At time: 277.95459842681885 and batch: 850, loss is 4.027469482421875 and perplexity is 56.118722004320766
At time: 278.90748357772827 and batch: 900, loss is 4.008085794448853 and perplexity is 55.04140908737683
At time: 279.8136839866638 and batch: 950, loss is 4.094731154441834 and perplexity is 60.023200017368154
At time: 280.72496128082275 and batch: 1000, loss is 4.059532122612 and perplexity is 57.9471925542875
At time: 281.6364107131958 and batch: 1050, loss is 4.00491473197937 and perplexity is 54.86714578668605
At time: 282.5432665348053 and batch: 1100, loss is 4.036201024055481 and perplexity is 56.61087044244328
At time: 283.4510886669159 and batch: 1150, loss is 4.000365195274353 and perplexity is 54.61809266077978
At time: 284.3583872318268 and batch: 1200, loss is 4.053809247016907 and perplexity is 57.616515095702574
At time: 285.26607155799866 and batch: 1250, loss is 4.047154459953308 and perplexity is 57.23436243901152
At time: 286.1734778881073 and batch: 1300, loss is 4.046952075958252 and perplexity is 57.22278029214674
At time: 287.07973051071167 and batch: 1350, loss is 3.9486097288131714 and perplexity is 51.86321275923169
At time: 287.98796820640564 and batch: 1400, loss is 3.97682523727417 and perplexity is 53.34739975910284
At time: 288.8944048881531 and batch: 1450, loss is 3.884018425941467 and perplexity is 48.619195688593535
At time: 289.7989320755005 and batch: 1500, loss is 3.913701491355896 and perplexity is 50.083994768686146
At time: 290.7031888961792 and batch: 1550, loss is 3.9021333837509156 and perplexity is 49.50795599102856
At time: 291.60767126083374 and batch: 1600, loss is 3.996004786491394 and perplexity is 54.38045392736535
At time: 292.51254630088806 and batch: 1650, loss is 3.9569427824020384 and perplexity is 52.29719738771453
At time: 293.4173016548157 and batch: 1700, loss is 3.9727316236495973 and perplexity is 53.129462496430705
At time: 294.3226134777069 and batch: 1750, loss is 3.958778667449951 and perplexity is 52.39329721757491
At time: 295.22908878326416 and batch: 1800, loss is 3.9212629222869873 and perplexity is 50.464136833642435
At time: 296.1336374282837 and batch: 1850, loss is 3.9484585189819335 and perplexity is 51.855371124463986
At time: 297.03844451904297 and batch: 1900, loss is 4.022556915283203 and perplexity is 55.84371107264784
At time: 297.9437243938446 and batch: 1950, loss is 3.951732497215271 and perplexity is 52.025422701490385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363404455850291 and perplexity of 78.5240114098917
finished 8 epochs...
Completing Train Step...
At time: 300.88768005371094 and batch: 50, loss is 4.056390619277954 and perplexity is 57.765436898158974
At time: 301.8146779537201 and batch: 100, loss is 4.0374523591995235 and perplexity is 56.68175395442822
At time: 302.7006723880768 and batch: 150, loss is 4.007284398078919 and perplexity is 54.99731677200868
At time: 303.594398021698 and batch: 200, loss is 4.009161539077759 and perplexity is 55.100651446681844
At time: 304.49054765701294 and batch: 250, loss is 3.997118763923645 and perplexity is 54.4410662799244
At time: 305.3865694999695 and batch: 300, loss is 4.023084077835083 and perplexity is 55.87315754674065
At time: 306.28459334373474 and batch: 350, loss is 4.024994440078736 and perplexity is 55.979997536400205
At time: 307.18332862854004 and batch: 400, loss is 3.9813433122634887 and perplexity is 53.58897262292123
At time: 308.0865173339844 and batch: 450, loss is 4.020942912101746 and perplexity is 55.75365184280438
At time: 308.99805903434753 and batch: 500, loss is 4.0309796714782715 and perplexity is 56.31605546441623
At time: 309.9007239341736 and batch: 550, loss is 3.999618721008301 and perplexity is 54.57733687361335
At time: 310.809369802475 and batch: 600, loss is 3.9924544143676757 and perplexity is 54.187725411089794
At time: 311.71237206459045 and batch: 650, loss is 4.040295715332031 and perplexity is 56.843149711207246
At time: 312.6180922985077 and batch: 700, loss is 4.066729063987732 and perplexity is 58.365739424046275
At time: 313.5290400981903 and batch: 750, loss is 4.025952777862549 and perplexity is 56.03367099772223
At time: 314.4398856163025 and batch: 800, loss is 3.997807250022888 and perplexity is 54.47856110313729
At time: 315.35211992263794 and batch: 850, loss is 3.99722535610199 and perplexity is 54.446869581058344
At time: 316.26441740989685 and batch: 900, loss is 3.977578377723694 and perplexity is 53.387592977407735
At time: 317.1745705604553 and batch: 950, loss is 4.066089072227478 and perplexity is 58.32839778217988
At time: 318.08542704582214 and batch: 1000, loss is 4.032020092010498 and perplexity is 56.374678335746765
At time: 318.99621295928955 and batch: 1050, loss is 3.9776361846923827 and perplexity is 53.39067924152627
At time: 319.91809582710266 and batch: 1100, loss is 4.009880332946778 and perplexity is 55.14027169481051
At time: 320.8357255458832 and batch: 1150, loss is 3.975095496177673 and perplexity is 53.25520233117625
At time: 321.746212720871 and batch: 1200, loss is 4.028599181175232 and perplexity is 56.18215507799496
At time: 322.65713000297546 and batch: 1250, loss is 4.023849444389343 and perplexity is 55.915937361839354
At time: 323.5675823688507 and batch: 1300, loss is 4.023324022293091 and perplexity is 55.88656560977625
At time: 324.4786822795868 and batch: 1350, loss is 3.92570924282074 and perplexity is 50.689016133704556
At time: 325.38946175575256 and batch: 1400, loss is 3.956373038291931 and perplexity is 52.26740985396949
At time: 326.30023765563965 and batch: 1450, loss is 3.864599847793579 and perplexity is 47.68418768162854
At time: 327.21091413497925 and batch: 1500, loss is 3.8956627321243285 and perplexity is 49.188641455747856
At time: 328.12957763671875 and batch: 1550, loss is 3.884221758842468 and perplexity is 48.6290825758279
At time: 329.0404815673828 and batch: 1600, loss is 3.98016809463501 and perplexity is 53.52603090995229
At time: 329.95000863075256 and batch: 1650, loss is 3.9420778703689576 and perplexity is 51.52555356657385
At time: 330.8606734275818 and batch: 1700, loss is 3.9586545848846435 and perplexity is 52.38679652617081
At time: 331.7734377384186 and batch: 1750, loss is 3.9456396389007566 and perplexity is 51.709402881841335
At time: 332.6941866874695 and batch: 1800, loss is 3.910865931510925 and perplexity is 49.94217976173465
At time: 333.6051712036133 and batch: 1850, loss is 3.938521909713745 and perplexity is 51.3426561061656
At time: 334.5162842273712 and batch: 1900, loss is 4.013216409683228 and perplexity is 55.32453105324123
At time: 335.43141508102417 and batch: 1950, loss is 3.942616105079651 and perplexity is 51.5532938727192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362306958575582 and perplexity of 78.43787879517065
finished 9 epochs...
Completing Train Step...
At time: 338.4288077354431 and batch: 50, loss is 4.026692805290222 and perplexity is 56.07515279807566
At time: 339.31259083747864 and batch: 100, loss is 4.007354159355163 and perplexity is 55.00115358884579
At time: 340.1964135169983 and batch: 150, loss is 3.97691695690155 and perplexity is 53.352292987129545
At time: 341.0840835571289 and batch: 200, loss is 3.9791979122161867 and perplexity is 53.474126078462845
At time: 341.98079895973206 and batch: 250, loss is 3.9674224519729613 and perplexity is 52.84813652371097
At time: 342.8783733844757 and batch: 300, loss is 3.9933618688583374 and perplexity is 54.236920623685215
At time: 343.77541875839233 and batch: 350, loss is 3.9949025821685793 and perplexity is 54.3205485760033
At time: 344.67275166511536 and batch: 400, loss is 3.951591062545776 and perplexity is 52.018065023352925
At time: 345.57046699523926 and batch: 450, loss is 3.993414435386658 and perplexity is 54.23977174524532
At time: 346.4792456626892 and batch: 500, loss is 4.004753365516662 and perplexity is 54.85829278375969
At time: 347.3817868232727 and batch: 550, loss is 3.973509612083435 and perplexity is 53.17081268664815
At time: 348.3115966320038 and batch: 600, loss is 3.9667753314971925 and perplexity is 52.81394847554631
At time: 349.2149775028229 and batch: 650, loss is 4.014814972877502 and perplexity is 55.41304153827696
At time: 350.11774134635925 and batch: 700, loss is 4.041927728652954 and perplexity is 56.93599422987741
At time: 351.02055978775024 and batch: 750, loss is 4.002075991630554 and perplexity is 54.71161306906357
At time: 351.9239902496338 and batch: 800, loss is 3.9739551067352297 and perplexity is 53.19450527640079
At time: 352.82694578170776 and batch: 850, loss is 3.974320859909058 and perplexity is 53.21396489402737
At time: 353.72931122779846 and batch: 900, loss is 3.9540520334243774 and perplexity is 52.14623761635753
At time: 354.63205456733704 and batch: 950, loss is 4.044199151992798 and perplexity is 57.06546696407711
At time: 355.53605341911316 and batch: 1000, loss is 4.0104014110565185 and perplexity is 55.16901157056561
At time: 356.43931579589844 and batch: 1050, loss is 3.9562155532836916 and perplexity is 52.25917916861977
At time: 357.3422565460205 and batch: 1100, loss is 3.9889457273483275 and perplexity is 53.99793080198415
At time: 358.2554295063019 and batch: 1150, loss is 3.9547146654129026 and perplexity is 52.180802832227485
At time: 359.1591811180115 and batch: 1200, loss is 4.008032131195068 and perplexity is 55.03845546552349
At time: 360.0621249675751 and batch: 1250, loss is 4.004415206909179 and perplexity is 54.83974511606653
At time: 360.96491861343384 and batch: 1300, loss is 4.003765459060669 and perplexity is 54.80412468306753
At time: 361.87204933166504 and batch: 1350, loss is 3.906650676727295 and perplexity is 49.73210382245196
At time: 362.7811653614044 and batch: 1400, loss is 3.938878927230835 and perplexity is 51.36098960626504
At time: 363.6848945617676 and batch: 1450, loss is 3.847546782493591 and perplexity is 46.87792031923076
At time: 364.5868413448334 and batch: 1500, loss is 3.8797030544281004 and perplexity is 48.4098378498388
At time: 365.48883056640625 and batch: 1550, loss is 3.8680849647521973 and perplexity is 47.85066257651454
At time: 366.39161491394043 and batch: 1600, loss is 3.965430917739868 and perplexity is 52.74299238449711
At time: 367.294016122818 and batch: 1650, loss is 3.927536325454712 and perplexity is 50.781713812187675
At time: 368.20497822761536 and batch: 1700, loss is 3.9450387573242187 and perplexity is 51.678340987510474
At time: 369.10913372039795 and batch: 1750, loss is 3.9321984577178957 and perplexity is 51.01901761957373
At time: 370.0130364894867 and batch: 1800, loss is 3.8989783048629763 and perplexity is 49.35200063938669
At time: 370.91634130477905 and batch: 1850, loss is 3.92673903465271 and perplexity is 50.741242154839284
At time: 371.81999254226685 and batch: 1900, loss is 4.001751766204834 and perplexity is 54.69387704841422
At time: 372.72251296043396 and batch: 1950, loss is 3.9309845685958864 and perplexity is 50.95712376280964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362965854378634 and perplexity of 78.48957821470393
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 375.67276191711426 and batch: 50, loss is 4.020517582893372 and perplexity is 55.72994322854259
At time: 376.59418964385986 and batch: 100, loss is 4.02522644996643 and perplexity is 55.99298695612041
At time: 377.48036670684814 and batch: 150, loss is 4.00153356552124 and perplexity is 54.681944108988944
At time: 378.36456990242004 and batch: 200, loss is 3.9966484928131103 and perplexity is 54.41547023823743
At time: 379.2533378601074 and batch: 250, loss is 3.9861629676818846 and perplexity is 53.847876417553366
At time: 380.1525981426239 and batch: 300, loss is 4.003397493362427 and perplexity is 54.78396235481207
At time: 381.05794620513916 and batch: 350, loss is 4.006045198440551 and perplexity is 54.92920632688908
At time: 381.9727506637573 and batch: 400, loss is 3.9601408004760743 and perplexity is 52.46471248556799
At time: 382.8779833316803 and batch: 450, loss is 4.004267439842224 and perplexity is 54.83164220646451
At time: 383.7904226779938 and batch: 500, loss is 4.013369541168213 and perplexity is 55.33300362953009
At time: 384.6995394229889 and batch: 550, loss is 3.98315664768219 and perplexity is 53.68623556354621
At time: 385.60419154167175 and batch: 600, loss is 3.9700486135482786 and perplexity is 52.98710666833374
At time: 386.5166082382202 and batch: 650, loss is 4.011570949554443 and perplexity is 55.233571598850205
At time: 387.4250645637512 and batch: 700, loss is 4.038180360794067 and perplexity is 56.72303338561131
At time: 388.3304600715637 and batch: 750, loss is 3.991528339385986 and perplexity is 54.13756674320038
At time: 389.2351357936859 and batch: 800, loss is 3.9620173454284666 and perplexity is 52.56325730993973
At time: 390.1401572227478 and batch: 850, loss is 3.964489917755127 and perplexity is 52.6933845736033
At time: 391.05132007598877 and batch: 900, loss is 3.93630117893219 and perplexity is 51.22876439756149
At time: 391.95686197280884 and batch: 950, loss is 4.029738631248474 and perplexity is 56.246208324521426
At time: 392.86161613464355 and batch: 1000, loss is 3.9847759771347047 and perplexity is 53.77324169277022
At time: 393.793062210083 and batch: 1050, loss is 3.9334509658813475 and perplexity is 51.08295939106973
At time: 394.6984484195709 and batch: 1100, loss is 3.9593232536315917 and perplexity is 52.421837653908455
At time: 395.6031496524811 and batch: 1150, loss is 3.9296397399902343 and perplexity is 50.888641224071456
At time: 396.50779604911804 and batch: 1200, loss is 3.9788388776779176 and perplexity is 53.454930466446974
At time: 397.4121472835541 and batch: 1250, loss is 3.9717304563522338 and perplexity is 53.07629763395437
At time: 398.3279285430908 and batch: 1300, loss is 3.9697355937957766 and perplexity is 52.97052325292231
At time: 399.23431038856506 and batch: 1350, loss is 3.869605622291565 and perplexity is 47.9234824002999
At time: 400.1499719619751 and batch: 1400, loss is 3.900662832260132 and perplexity is 49.43520549732417
At time: 401.05631256103516 and batch: 1450, loss is 3.8017693519592286 and perplexity is 44.780346633856006
At time: 401.97908425331116 and batch: 1500, loss is 3.833584146499634 and perplexity is 46.227929335306314
At time: 402.89171075820923 and batch: 1550, loss is 3.824058632850647 and perplexity is 45.78967517520955
At time: 403.8046371936798 and batch: 1600, loss is 3.918305549621582 and perplexity is 50.31511603841252
At time: 404.71756887435913 and batch: 1650, loss is 3.8781423377990722 and perplexity is 48.33434273945957
At time: 405.6303734779358 and batch: 1700, loss is 3.8870973443984984 and perplexity is 48.769120912897655
At time: 406.5448157787323 and batch: 1750, loss is 3.86931688785553 and perplexity is 47.90964723807622
At time: 407.4640851020813 and batch: 1800, loss is 3.8357225036621094 and perplexity is 46.326886924734396
At time: 408.3832814693451 and batch: 1850, loss is 3.8629506158828737 and perplexity is 47.60561021171403
At time: 409.29640102386475 and batch: 1900, loss is 3.937599639892578 and perplexity is 51.295326152749006
At time: 410.20914220809937 and batch: 1950, loss is 3.8666520071029664 and perplexity is 47.78214370759795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334555834393169 and perplexity of 76.29106549578323
finished 11 epochs...
Completing Train Step...
At time: 413.1831600666046 and batch: 50, loss is 4.001213593482971 and perplexity is 54.664450214803644
At time: 414.06043910980225 and batch: 100, loss is 3.9988644695281983 and perplexity is 54.53618735698909
At time: 414.93508982658386 and batch: 150, loss is 3.971476812362671 and perplexity is 53.062836857265985
At time: 415.82631731033325 and batch: 200, loss is 3.9641878747940065 and perplexity is 52.677471311060685
At time: 416.7308347225189 and batch: 250, loss is 3.953674302101135 and perplexity is 52.12654406868967
At time: 417.6719765663147 and batch: 300, loss is 3.9716875982284545 and perplexity is 53.0740229321657
At time: 418.5681788921356 and batch: 350, loss is 3.977284383773804 and perplexity is 53.37189965505713
At time: 419.4657337665558 and batch: 400, loss is 3.9323189544677732 and perplexity is 51.02516561577817
At time: 420.3723430633545 and batch: 450, loss is 3.9770535707473753 and perplexity is 53.35958214694685
At time: 421.2691447734833 and batch: 500, loss is 3.987350568771362 and perplexity is 53.911864202713915
At time: 422.17453145980835 and batch: 550, loss is 3.9582120847702025 and perplexity is 52.363620490790105
At time: 423.0752184391022 and batch: 600, loss is 3.945787386894226 and perplexity is 51.71704340678285
At time: 423.97798323631287 and batch: 650, loss is 3.9890142393112185 and perplexity is 54.00163043294848
At time: 424.8805193901062 and batch: 700, loss is 4.018126039505005 and perplexity is 55.59682189744866
At time: 425.78980898857117 and batch: 750, loss is 3.973494873046875 and perplexity is 53.17002900587139
At time: 426.6966714859009 and batch: 800, loss is 3.9441679906845093 and perplexity is 51.63336079864911
At time: 427.5998284816742 and batch: 850, loss is 3.9467728424072264 and perplexity is 51.768033372369025
At time: 428.50241780281067 and batch: 900, loss is 3.9192228174209593 and perplexity is 50.36128964772151
At time: 429.40553307533264 and batch: 950, loss is 4.014113478660583 and perplexity is 55.37418324112482
At time: 430.30906081199646 and batch: 1000, loss is 3.970462746620178 and perplexity is 53.00905492602536
At time: 431.2120409011841 and batch: 1050, loss is 3.9207071018218995 and perplexity is 50.4360956272974
At time: 432.11483931541443 and batch: 1100, loss is 3.9471273231506347 and perplexity is 51.78638739620547
At time: 433.0182602405548 and batch: 1150, loss is 3.9187776136398313 and perplexity is 50.33887360137241
At time: 433.92549180984497 and batch: 1200, loss is 3.9688032484054565 and perplexity is 52.92115944537968
At time: 434.83289074897766 and batch: 1250, loss is 3.9630948162078856 and perplexity is 52.61992320620382
At time: 435.734742641449 and batch: 1300, loss is 3.961529335975647 and perplexity is 52.537612201538096
At time: 436.6381001472473 and batch: 1350, loss is 3.8617496061325074 and perplexity is 47.54846972968406
At time: 437.54114174842834 and batch: 1400, loss is 3.8946752405166625 and perplexity is 49.140092060123386
At time: 438.44397711753845 and batch: 1450, loss is 3.797303295135498 and perplexity is 44.580800983980915
At time: 439.34674048423767 and batch: 1500, loss is 3.830893330574036 and perplexity is 46.10370569327394
At time: 440.2530016899109 and batch: 1550, loss is 3.8225845432281496 and perplexity is 45.72222681489369
At time: 441.1592335700989 and batch: 1600, loss is 3.9177766942977907 and perplexity is 50.288513656454114
At time: 442.0658595561981 and batch: 1650, loss is 3.878313994407654 and perplexity is 48.342640360962655
At time: 442.97196888923645 and batch: 1700, loss is 3.888314971923828 and perplexity is 48.82853970454416
At time: 443.87760639190674 and batch: 1750, loss is 3.871846904754639 and perplexity is 48.03101291909255
At time: 444.78271985054016 and batch: 1800, loss is 3.8401263666152956 and perplexity is 46.53135407800635
At time: 445.6919527053833 and batch: 1850, loss is 3.86819034576416 and perplexity is 47.85570539346386
At time: 446.6004478931427 and batch: 1900, loss is 3.942809958457947 and perplexity is 51.56328862162533
At time: 447.5132963657379 and batch: 1950, loss is 3.871756901741028 and perplexity is 48.02669017771584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332689010265262 and perplexity of 76.14877634970102
finished 12 epochs...
Completing Train Step...
At time: 450.46422600746155 and batch: 50, loss is 3.9899487781524656 and perplexity is 54.05212064293522
At time: 451.367374420166 and batch: 100, loss is 3.9863690757751464 and perplexity is 53.858976044510165
At time: 452.2593741416931 and batch: 150, loss is 3.958667821884155 and perplexity is 52.38748997476043
At time: 453.14813232421875 and batch: 200, loss is 3.9507420825958253 and perplexity is 51.97392147026004
At time: 454.04668641090393 and batch: 250, loss is 3.9399709129333496 and perplexity is 51.41710570599515
At time: 454.94663739204407 and batch: 300, loss is 3.9574837064743043 and perplexity is 52.32549385312328
At time: 455.845978975296 and batch: 350, loss is 3.963718581199646 and perplexity is 52.65275591105034
At time: 456.7447307109833 and batch: 400, loss is 3.918855209350586 and perplexity is 50.34277983359957
At time: 457.64468216896057 and batch: 450, loss is 3.963903646469116 and perplexity is 52.66250100922317
At time: 458.5530962944031 and batch: 500, loss is 3.9748128175735475 and perplexity is 53.24015035245524
At time: 459.4638729095459 and batch: 550, loss is 3.946158504486084 and perplexity is 51.73624007327998
At time: 460.37504529953003 and batch: 600, loss is 3.9339286041259767 and perplexity is 51.107364394041156
At time: 461.2889003753662 and batch: 650, loss is 3.9778720903396607 and perplexity is 53.4032758900232
At time: 462.19878220558167 and batch: 700, loss is 4.007435827255249 and perplexity is 55.00564560098581
At time: 463.13600063323975 and batch: 750, loss is 3.9636726808547973 and perplexity is 52.65033918686146
At time: 464.0406129360199 and batch: 800, loss is 3.9344564723968505 and perplexity is 51.13434947176931
At time: 464.9465169906616 and batch: 850, loss is 3.937315487861633 and perplexity is 51.28075255230186
At time: 465.8509256839752 and batch: 900, loss is 3.910150508880615 and perplexity is 49.90646277402017
At time: 466.7664325237274 and batch: 950, loss is 4.0054873180389405 and perplexity is 54.89857094543728
At time: 467.67938113212585 and batch: 1000, loss is 3.9626582956314085 and perplexity is 52.59695853963107
At time: 468.59068393707275 and batch: 1050, loss is 3.913561420440674 and perplexity is 50.07697994899849
At time: 469.50192618370056 and batch: 1100, loss is 3.9399933862686156 and perplexity is 51.41826123283431
At time: 470.41325759887695 and batch: 1150, loss is 3.9121163368225096 and perplexity is 50.00466678749368
At time: 471.32469940185547 and batch: 1200, loss is 3.9625448179244995 and perplexity is 52.590990296023314
At time: 472.23613119125366 and batch: 1250, loss is 3.9576457643508913 and perplexity is 52.33397429869142
At time: 473.14769864082336 and batch: 1300, loss is 3.9562251949310303 and perplexity is 52.25968303562457
At time: 474.05866289138794 and batch: 1350, loss is 3.856638207435608 and perplexity is 47.306050621619306
At time: 474.9698700904846 and batch: 1400, loss is 3.8903279447555543 and perplexity is 48.9269292228726
At time: 475.8808693885803 and batch: 1450, loss is 3.79367280960083 and perplexity is 44.41924447262199
At time: 476.7923400402069 and batch: 1500, loss is 3.828060746192932 and perplexity is 45.97329783943546
At time: 477.7027277946472 and batch: 1550, loss is 3.8201282024383545 and perplexity is 45.610055266343025
At time: 478.6141302585602 and batch: 1600, loss is 3.9157201194763185 and perplexity is 50.18519784022666
At time: 479.5259094238281 and batch: 1650, loss is 3.876632571220398 and perplexity is 48.26142422300974
At time: 480.4387185573578 and batch: 1700, loss is 3.8870981216430662 and perplexity is 48.7691588184467
At time: 481.34978556632996 and batch: 1750, loss is 3.8712201738357543 and perplexity is 48.00091982935073
At time: 482.2610080242157 and batch: 1800, loss is 3.84045690536499 and perplexity is 46.54673703579665
At time: 483.17193055152893 and batch: 1850, loss is 3.8689971780776977 and perplexity is 47.89433250366733
At time: 484.08295249938965 and batch: 1900, loss is 3.9434789180755616 and perplexity is 51.597793919503275
At time: 484.9936320781708 and batch: 1950, loss is 3.872266411781311 and perplexity is 48.05116649349776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3320315338844475 and perplexity of 76.09872678283016
finished 13 epochs...
Completing Train Step...
At time: 487.9712061882019 and batch: 50, loss is 3.9804835367202758 and perplexity is 53.54291793605787
At time: 488.85544443130493 and batch: 100, loss is 3.9764622163772585 and perplexity is 53.32803705294052
At time: 489.7390921115875 and batch: 150, loss is 3.9486727046966554 and perplexity is 51.86647899372145
At time: 490.6224217414856 and batch: 200, loss is 3.940513563156128 and perplexity is 51.44501478160932
At time: 491.5061559677124 and batch: 250, loss is 3.9296825742721557 and perplexity is 50.89082104916153
At time: 492.39040422439575 and batch: 300, loss is 3.9468282365798952 and perplexity is 51.770901099175326
At time: 493.2784299850464 and batch: 350, loss is 3.9534556388854982 and perplexity is 52.11514715703165
At time: 494.1671724319458 and batch: 400, loss is 3.908703575134277 and perplexity is 49.83430364620011
At time: 495.0600471496582 and batch: 450, loss is 3.9541173934936524 and perplexity is 52.14964600944576
At time: 495.9665551185608 and batch: 500, loss is 3.9655142498016356 and perplexity is 52.74738774993118
At time: 496.8645625114441 and batch: 550, loss is 3.9372090673446656 and perplexity is 51.275295518480085
At time: 497.7621965408325 and batch: 600, loss is 3.92504771232605 and perplexity is 50.655494892670326
At time: 498.6647803783417 and batch: 650, loss is 3.9695089530944823 and perplexity is 52.95851933672372
At time: 499.5650534629822 and batch: 700, loss is 3.9992200040817263 and perplexity is 54.55558030323914
At time: 500.4648118019104 and batch: 750, loss is 3.956054701805115 and perplexity is 52.25077387840109
At time: 501.36814188957214 and batch: 800, loss is 3.9268692111968995 and perplexity is 50.74784790433838
At time: 502.2733099460602 and batch: 850, loss is 3.9300872468948365 and perplexity is 50.9114193386867
At time: 503.1839098930359 and batch: 900, loss is 3.903035626411438 and perplexity is 49.55264433779385
At time: 504.08699226379395 and batch: 950, loss is 3.998586959838867 and perplexity is 54.52105513634438
At time: 504.9900369644165 and batch: 1000, loss is 3.9564050674438476 and perplexity is 52.26908396158996
At time: 505.8926908969879 and batch: 1050, loss is 3.9077233028411866 and perplexity is 49.78547639500101
At time: 506.7960922718048 and batch: 1100, loss is 3.9340740728378294 and perplexity is 51.11479945727717
At time: 507.6992025375366 and batch: 1150, loss is 3.906478509902954 and perplexity is 49.72354234109172
At time: 508.6282720565796 and batch: 1200, loss is 3.9572117567062377 and perplexity is 52.31126588194037
At time: 509.53179001808167 and batch: 1250, loss is 3.952816209793091 and perplexity is 52.08183386766261
At time: 510.43488574028015 and batch: 1300, loss is 3.9515022373199464 and perplexity is 52.01344471218313
At time: 511.3377900123596 and batch: 1350, loss is 3.851971673965454 and perplexity is 47.08580963369718
At time: 512.2415592670441 and batch: 1400, loss is 3.886249513626099 and perplexity is 48.72779047452932
At time: 513.1448359489441 and batch: 1450, loss is 3.789982867240906 and perplexity is 44.25564204823436
At time: 514.0474920272827 and batch: 1500, loss is 3.8248963737487793 and perplexity is 45.82805113112553
At time: 514.9510157108307 and batch: 1550, loss is 3.817071404457092 and perplexity is 45.47084741501572
At time: 515.8532571792603 and batch: 1600, loss is 3.9129553604125977 and perplexity is 50.04663948812361
At time: 516.7576823234558 and batch: 1650, loss is 3.8740462017059327 and perplexity is 48.13676362535047
At time: 517.668447971344 and batch: 1700, loss is 3.8848595237731933 and perplexity is 48.66010639120727
At time: 518.5796473026276 and batch: 1750, loss is 3.869363307952881 and perplexity is 47.91187126018432
At time: 519.4906873703003 and batch: 1800, loss is 3.839288363456726 and perplexity is 46.49237699005883
At time: 520.4016280174255 and batch: 1850, loss is 3.8681841230392457 and perplexity is 47.85540760150015
At time: 521.3115751743317 and batch: 1900, loss is 3.9425384616851806 and perplexity is 51.54929125537721
At time: 522.2223970890045 and batch: 1950, loss is 3.8712106466293337 and perplexity is 48.00046251685759
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331829124273256 and perplexity of 76.08332522789381
finished 14 epochs...
Completing Train Step...
At time: 525.187756061554 and batch: 50, loss is 3.9721613693237305 and perplexity is 53.09917382755416
At time: 526.1049239635468 and batch: 100, loss is 3.9680321121215822 and perplexity is 52.880365749917516
At time: 526.9942693710327 and batch: 150, loss is 3.940202136039734 and perplexity is 51.42899590348901
At time: 527.8801610469818 and batch: 200, loss is 3.931916537284851 and perplexity is 51.00463634331597
At time: 528.7761068344116 and batch: 250, loss is 3.9211040925979614 and perplexity is 50.4561222669746
At time: 529.6758065223694 and batch: 300, loss is 3.9379218292236327 and perplexity is 51.31185562223475
At time: 530.5746221542358 and batch: 350, loss is 3.9447234439849854 and perplexity is 51.66204868597266
At time: 531.4734306335449 and batch: 400, loss is 3.9000819063186647 and perplexity is 49.4064956439857
At time: 532.3994674682617 and batch: 450, loss is 3.9458532619476316 and perplexity is 51.720450381995356
At time: 533.2983691692352 and batch: 500, loss is 3.9576257467269897 and perplexity is 52.332926707361814
At time: 534.2064685821533 and batch: 550, loss is 3.9297009992599485 and perplexity is 50.891758720556396
At time: 535.1051547527313 and batch: 600, loss is 3.917539758682251 and perplexity is 50.27659992796537
At time: 536.003714799881 and batch: 650, loss is 3.962389817237854 and perplexity is 52.5828392881383
At time: 536.901718378067 and batch: 700, loss is 3.992113947868347 and perplexity is 54.169279446207234
At time: 537.8014175891876 and batch: 750, loss is 3.9494459867477416 and perplexity is 51.90660192215118
At time: 538.706286907196 and batch: 800, loss is 3.9202351140975953 and perplexity is 50.41229602630106
At time: 539.6118111610413 and batch: 850, loss is 3.92385715007782 and perplexity is 50.59522225906619
At time: 540.5171506404877 and batch: 900, loss is 3.8968406677246095 and perplexity is 49.24661664646504
At time: 541.4241831302643 and batch: 950, loss is 3.992476849555969 and perplexity is 54.18894113655005
At time: 542.3296194076538 and batch: 1000, loss is 3.9508426570892334 and perplexity is 51.97914898395521
At time: 543.2351093292236 and batch: 1050, loss is 3.902422060966492 and perplexity is 49.52224987297268
At time: 544.1411259174347 and batch: 1100, loss is 3.9287113523483277 and perplexity is 50.84141876221238
At time: 545.0452411174774 and batch: 1150, loss is 3.9012974643707277 and perplexity is 49.46658862344313
At time: 545.9596252441406 and batch: 1200, loss is 3.9522820043563844 and perplexity is 52.054018898972096
At time: 546.8689420223236 and batch: 1250, loss is 3.9482556343078614 and perplexity is 51.84485153156269
At time: 547.7805931568146 and batch: 1300, loss is 3.9470004510879515 and perplexity is 51.77981756719029
At time: 548.6926803588867 and batch: 1350, loss is 3.8474863624572753 and perplexity is 46.87508803914675
At time: 549.5978949069977 and batch: 1400, loss is 3.8822516107559206 and perplexity is 48.533370396382935
At time: 550.5027589797974 and batch: 1450, loss is 3.7862425374984743 and perplexity is 44.09042053809678
At time: 551.4080400466919 and batch: 1500, loss is 3.8215600299835204 and perplexity is 45.67540777540613
At time: 552.3123741149902 and batch: 1550, loss is 3.8137563037872315 and perplexity is 45.32035656227759
At time: 553.2179205417633 and batch: 1600, loss is 3.9098661661148073 and perplexity is 49.89227424966104
At time: 554.1221616268158 and batch: 1650, loss is 3.871076993942261 and perplexity is 47.99404755475948
At time: 555.0281958580017 and batch: 1700, loss is 3.882165117263794 and perplexity is 48.529172757229524
At time: 555.933119058609 and batch: 1750, loss is 3.866910719871521 and perplexity is 47.79450715750623
At time: 556.838764667511 and batch: 1800, loss is 3.8373622369766234 and perplexity is 46.402912978774964
At time: 557.744127035141 and batch: 1850, loss is 3.8665497207641604 and perplexity is 47.7772564970095
At time: 558.6497609615326 and batch: 1900, loss is 3.9408294486999513 and perplexity is 51.461268085037254
At time: 559.5541892051697 and batch: 1950, loss is 3.8694092416763306 and perplexity is 47.914072081374314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331852118913518 and perplexity of 76.08507475670218
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 562.4976618289948 and batch: 50, loss is 3.973958854675293 and perplexity is 53.194704646591866
At time: 563.3726658821106 and batch: 100, loss is 3.983186945915222 and perplexity is 53.687862186263715
At time: 564.2605624198914 and batch: 150, loss is 3.9640305614471436 and perplexity is 52.669185093527865
At time: 565.1564407348633 and batch: 200, loss is 3.95787926197052 and perplexity is 52.346195583880856
At time: 566.0519542694092 and batch: 250, loss is 3.9467222690582275 and perplexity is 51.76541535575179
At time: 566.9492506980896 and batch: 300, loss is 3.9560798931121828 and perplexity is 52.25209016026976
At time: 567.8450348377228 and batch: 350, loss is 3.9597565174102782 and perplexity is 52.444555058334956
At time: 568.741622209549 and batch: 400, loss is 3.9151334381103515 and perplexity is 50.15576375486539
At time: 569.6384508609772 and batch: 450, loss is 3.961151580810547 and perplexity is 52.51776959522641
At time: 570.5352346897125 and batch: 500, loss is 3.9713225412368773 and perplexity is 53.05465142509036
At time: 571.4363586902618 and batch: 550, loss is 3.9456978368759157 and perplexity is 51.712412351957425
At time: 572.3467030525208 and batch: 600, loss is 3.9288183450698853 and perplexity is 50.846858714986084
At time: 573.2559270858765 and batch: 650, loss is 3.9695393800735475 and perplexity is 52.960130728997676
At time: 574.159206867218 and batch: 700, loss is 4.001405329704284 and perplexity is 54.67493237480076
At time: 575.0618507862091 and batch: 750, loss is 3.955860276222229 and perplexity is 52.24061597874332
At time: 575.9636151790619 and batch: 800, loss is 3.9259816884994505 and perplexity is 50.70282801851701
At time: 576.8671247959137 and batch: 850, loss is 3.930383143424988 and perplexity is 50.926486080002405
At time: 577.813225030899 and batch: 900, loss is 3.8978419399261472 and perplexity is 49.295950608973925
At time: 578.7147896289825 and batch: 950, loss is 3.995097723007202 and perplexity is 54.331149767735944
At time: 579.6161546707153 and batch: 1000, loss is 3.951388988494873 and perplexity is 52.0075545842128
At time: 580.5178942680359 and batch: 1050, loss is 3.9020481395721434 and perplexity is 49.503735905848814
At time: 581.4198520183563 and batch: 1100, loss is 3.923535680770874 and perplexity is 50.57896006207044
At time: 582.321061372757 and batch: 1150, loss is 3.900221166610718 and perplexity is 49.41337648610132
At time: 583.2273404598236 and batch: 1200, loss is 3.9477095556259156 and perplexity is 51.81654789208308
At time: 584.138701915741 and batch: 1250, loss is 3.942764105796814 and perplexity is 51.560924361829485
At time: 585.0521106719971 and batch: 1300, loss is 3.94057683467865 and perplexity is 51.44826988899742
At time: 585.968428850174 and batch: 1350, loss is 3.842391848564148 and perplexity is 46.63688951990745
At time: 586.8790690898895 and batch: 1400, loss is 3.876557641029358 and perplexity is 48.25780812075216
At time: 587.791684627533 and batch: 1450, loss is 3.7759176874160767 and perplexity is 43.63753556391904
At time: 588.7005915641785 and batch: 1500, loss is 3.8069407606124877 and perplexity is 45.012523930339064
At time: 589.6105716228485 and batch: 1550, loss is 3.8011353731155397 and perplexity is 44.751965838839475
At time: 590.5211687088013 and batch: 1600, loss is 3.8977822256088257 and perplexity is 49.29300702282459
At time: 591.4320147037506 and batch: 1650, loss is 3.858005962371826 and perplexity is 47.37079797503227
At time: 592.3554940223694 and batch: 1700, loss is 3.867174520492554 and perplexity is 47.807117041350814
At time: 593.2663950920105 and batch: 1750, loss is 3.850505838394165 and perplexity is 47.016840140350915
At time: 594.176206111908 and batch: 1800, loss is 3.8183325481414796 and perplexity is 45.528228862576654
At time: 595.0865023136139 and batch: 1850, loss is 3.848406457901001 and perplexity is 46.91823744181611
At time: 596.0063090324402 and batch: 1900, loss is 3.922054958343506 and perplexity is 50.50412208236483
At time: 596.9166867733002 and batch: 1950, loss is 3.8541776514053345 and perplexity is 47.18979451947491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322776617005814 and perplexity of 75.39768842162388
finished 16 epochs...
Completing Train Step...
At time: 599.8615276813507 and batch: 50, loss is 3.971703777313232 and perplexity is 53.07488162822865
At time: 600.787918806076 and batch: 100, loss is 3.973457918167114 and perplexity is 53.16806415014833
At time: 601.6760957241058 and batch: 150, loss is 3.9499212455749513 and perplexity is 51.93127685593075
At time: 602.5637986660004 and batch: 200, loss is 3.9441910934448243 and perplexity is 51.634553685587335
At time: 603.4523587226868 and batch: 250, loss is 3.9329804372787476 and perplexity is 51.058929051495184
At time: 604.340993642807 and batch: 300, loss is 3.942331438064575 and perplexity is 51.5386204390555
At time: 605.2292833328247 and batch: 350, loss is 3.9474472570419312 and perplexity is 51.80295826729161
At time: 606.1168963909149 and batch: 400, loss is 3.9034819078445433 and perplexity is 49.57476369828591
At time: 607.0057573318481 and batch: 450, loss is 3.9504386520385744 and perplexity is 51.95815338668598
At time: 607.90083360672 and batch: 500, loss is 3.9617412900924682 and perplexity is 52.54874894492979
At time: 608.7983210086823 and batch: 550, loss is 3.936454153060913 and perplexity is 51.23660167259566
At time: 609.7005071640015 and batch: 600, loss is 3.9205136489868164 and perplexity is 50.426339565307124
At time: 610.6010468006134 and batch: 650, loss is 3.962193670272827 and perplexity is 52.57252633525969
At time: 611.4972233772278 and batch: 700, loss is 3.9946452522277833 and perplexity is 54.30657207081798
At time: 612.394858121872 and batch: 750, loss is 3.9498637247085573 and perplexity is 51.92828980980261
At time: 613.2914974689484 and batch: 800, loss is 3.9197650480270387 and perplexity is 50.38860448513132
At time: 614.1891520023346 and batch: 850, loss is 3.9239175844192506 and perplexity is 50.59828004039953
At time: 615.0862941741943 and batch: 900, loss is 3.8924135875701906 and perplexity is 49.02907980903774
At time: 615.9837839603424 and batch: 950, loss is 3.9898000526428223 and perplexity is 54.04408231151259
At time: 616.8805408477783 and batch: 1000, loss is 3.947079825401306 and perplexity is 51.78392771777334
At time: 617.778192281723 and batch: 1050, loss is 3.8984044551849366 and perplexity is 49.32368813404715
At time: 618.6754179000854 and batch: 1100, loss is 3.920784044265747 and perplexity is 50.43997645305127
At time: 619.5767223834991 and batch: 1150, loss is 3.897335844039917 and perplexity is 49.27100844325903
At time: 620.4780704975128 and batch: 1200, loss is 3.9451445722579956 and perplexity is 51.683809617066004
At time: 621.3808839321136 and batch: 1250, loss is 3.9404867124557494 and perplexity is 51.44363346547618
At time: 622.2839796543121 and batch: 1300, loss is 3.938484492301941 and perplexity is 51.340735032799984
At time: 623.1914076805115 and batch: 1350, loss is 3.840566806793213 and perplexity is 46.551852869789585
At time: 624.0978412628174 and batch: 1400, loss is 3.875431332588196 and perplexity is 48.20348554184603
At time: 625.0008382797241 and batch: 1450, loss is 3.7755493831634523 and perplexity is 43.621466633306184
At time: 625.9094109535217 and batch: 1500, loss is 3.8074636316299437 and perplexity is 45.0360658286766
At time: 626.8223693370819 and batch: 1550, loss is 3.802202696800232 and perplexity is 44.799756171255844
At time: 627.7280559539795 and batch: 1600, loss is 3.8990100240707397 and perplexity is 49.353566070575496
At time: 628.6311383247375 and batch: 1650, loss is 3.8596209907531738 and perplexity is 47.44736497050183
At time: 629.5349633693695 and batch: 1700, loss is 3.8687445974349974 and perplexity is 47.882236850010145
At time: 630.4355173110962 and batch: 1750, loss is 3.8527112340927125 and perplexity is 47.12064530100945
At time: 631.3382368087769 and batch: 1800, loss is 3.8209799194335936 and perplexity is 45.64891867353
At time: 632.2417356967926 and batch: 1850, loss is 3.851282958984375 and perplexity is 47.05339209570963
At time: 633.1489489078522 and batch: 1900, loss is 3.9247961902618407 and perplexity is 50.642755520215175
At time: 634.0580410957336 and batch: 1950, loss is 3.857046070098877 and perplexity is 47.325348928676505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322002180232558 and perplexity of 75.33932028322529
finished 17 epochs...
Completing Train Step...
At time: 637.0244297981262 and batch: 50, loss is 3.968748164176941 and perplexity is 52.918244404426616
At time: 637.9113428592682 and batch: 100, loss is 3.969635648727417 and perplexity is 52.96522937490766
At time: 638.7979063987732 and batch: 150, loss is 3.9456331872940065 and perplexity is 51.70906927418481
At time: 639.6904237270355 and batch: 200, loss is 3.939653673171997 and perplexity is 51.400796742714135
At time: 640.5945048332214 and batch: 250, loss is 3.9282035636901855 and perplexity is 50.815608620004404
At time: 641.4995257854462 and batch: 300, loss is 3.93750807762146 and perplexity is 51.29062965120318
At time: 642.4049496650696 and batch: 350, loss is 3.94274712562561 and perplexity is 51.560048855939534
At time: 643.3126709461212 and batch: 400, loss is 3.8988654804229737 and perplexity is 49.346432841649275
At time: 644.2272996902466 and batch: 450, loss is 3.9459144496917724 and perplexity is 51.72361513650128
At time: 645.1333847045898 and batch: 500, loss is 3.95738018989563 and perplexity is 52.32007757736417
At time: 646.0386981964111 and batch: 550, loss is 3.9322698450088502 and perplexity is 51.02265985903201
At time: 646.9829137325287 and batch: 600, loss is 3.9165194988250733 and perplexity is 50.225330889621645
At time: 647.8884196281433 and batch: 650, loss is 3.958402462005615 and perplexity is 52.373590281075785
At time: 648.7938749790192 and batch: 700, loss is 3.991169810295105 and perplexity is 54.118160329703194
At time: 649.6998074054718 and batch: 750, loss is 3.946840453147888 and perplexity is 51.77153356577193
At time: 650.6052486896515 and batch: 800, loss is 3.916638607978821 and perplexity is 50.2313135425679
At time: 651.5171942710876 and batch: 850, loss is 3.9207785511016846 and perplexity is 50.439699378746326
At time: 652.4257950782776 and batch: 900, loss is 3.8895045423507693 and perplexity is 48.88665925316191
At time: 653.3315122127533 and batch: 950, loss is 3.987082815170288 and perplexity is 53.897431039284996
At time: 654.2368867397308 and batch: 1000, loss is 3.944755001068115 and perplexity is 51.66367901526177
At time: 655.142254114151 and batch: 1050, loss is 3.8963953638076783 and perplexity is 49.22469181714525
At time: 656.0479888916016 and batch: 1100, loss is 3.919012703895569 and perplexity is 50.35070917119996
At time: 656.9533755779266 and batch: 1150, loss is 3.895678758621216 and perplexity is 49.189429783674086
At time: 657.8586647510529 and batch: 1200, loss is 3.9436627864837646 and perplexity is 51.607281995990064
At time: 658.7640933990479 and batch: 1250, loss is 3.9391372537612916 and perplexity is 51.37425922638452
At time: 659.671865940094 and batch: 1300, loss is 3.937159857749939 and perplexity is 51.27277234405084
At time: 660.5868785381317 and batch: 1350, loss is 3.8393658876419066 and perplexity is 46.49598141341529
At time: 661.4916470050812 and batch: 1400, loss is 3.8746215105056763 and perplexity is 48.16446509674139
At time: 662.4001219272614 and batch: 1450, loss is 3.7750379848480224 and perplexity is 43.59916439190373
At time: 663.3044829368591 and batch: 1500, loss is 3.8074510955810545 and perplexity is 45.03550125789235
At time: 664.2091844081879 and batch: 1550, loss is 3.802389497756958 and perplexity is 44.80812559025313
At time: 665.1145586967468 and batch: 1600, loss is 3.899364309310913 and perplexity is 49.371054408331275
At time: 666.024162530899 and batch: 1650, loss is 3.8601658821105955 and perplexity is 47.473225674603924
At time: 666.9290904998779 and batch: 1700, loss is 3.86921263217926 and perplexity is 47.90465264576539
At time: 667.8345935344696 and batch: 1750, loss is 3.853464937210083 and perplexity is 47.156173665503
At time: 668.7401480674744 and batch: 1800, loss is 3.8219951438903808 and perplexity is 45.6952861048859
At time: 669.6451404094696 and batch: 1850, loss is 3.8523042583465577 and perplexity is 47.10147224297821
At time: 670.559342622757 and batch: 1900, loss is 3.9257154083251953 and perplexity is 50.6893286580228
At time: 671.4650802612305 and batch: 1950, loss is 3.857936797142029 and perplexity is 47.36752167620893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321644769712936 and perplexity of 75.31239802904992
finished 18 epochs...
Completing Train Step...
At time: 674.3740439414978 and batch: 50, loss is 3.9660176420211792 and perplexity is 52.773947058839624
At time: 675.2743856906891 and batch: 100, loss is 3.9665145206451418 and perplexity is 52.80017582075123
At time: 676.151823759079 and batch: 150, loss is 3.942316761016846 and perplexity is 51.537864009814506
At time: 677.0342388153076 and batch: 200, loss is 3.9361685800552366 and perplexity is 51.22197197127868
At time: 677.9207990169525 and batch: 250, loss is 3.9246613693237307 and perplexity is 50.635928276645494
At time: 678.8184406757355 and batch: 300, loss is 3.9338500785827635 and perplexity is 51.10335131805647
At time: 679.7150812149048 and batch: 350, loss is 3.939191288948059 and perplexity is 51.37703531907951
At time: 680.6115407943726 and batch: 400, loss is 3.895392279624939 and perplexity is 49.175340063503036
At time: 681.5084719657898 and batch: 450, loss is 3.942511310577393 and perplexity is 51.5478916540144
At time: 682.4048743247986 and batch: 500, loss is 3.9541022396087646 and perplexity is 52.14885574570099
At time: 683.301406621933 and batch: 550, loss is 3.92917085647583 and perplexity is 50.864785972235254
At time: 684.1977117061615 and batch: 600, loss is 3.913553376197815 and perplexity is 50.07657711923037
At time: 685.0950226783752 and batch: 650, loss is 3.9555355072021485 and perplexity is 52.22365259982258
At time: 685.9914577007294 and batch: 700, loss is 3.9884455394744873 and perplexity is 53.97092844547315
At time: 686.8886411190033 and batch: 750, loss is 3.944476356506348 and perplexity is 51.64928521753314
At time: 687.7854804992676 and batch: 800, loss is 3.914240312576294 and perplexity is 50.11098835957653
At time: 688.6829538345337 and batch: 850, loss is 3.9183759355545043 and perplexity is 50.31865763943295
At time: 689.579097032547 and batch: 900, loss is 3.8872340297698975 and perplexity is 48.77578739389728
At time: 690.4806826114655 and batch: 950, loss is 3.984945282936096 and perplexity is 53.78234658528224
At time: 691.3827278614044 and batch: 1000, loss is 3.9428893327713013 and perplexity is 51.56738158468989
At time: 692.3289432525635 and batch: 1050, loss is 3.8947703409194947 and perplexity is 49.14476552489418
At time: 693.2346241474152 and batch: 1100, loss is 3.917466154098511 and perplexity is 50.272899475942594
At time: 694.142838716507 and batch: 1150, loss is 3.8942439699172975 and perplexity is 49.118903952400125
At time: 695.0456943511963 and batch: 1200, loss is 3.9423486614227294 and perplexity is 51.53950811481846
At time: 695.9495415687561 and batch: 1250, loss is 3.9379215812683106 and perplexity is 51.31184289918865
At time: 696.8528580665588 and batch: 1300, loss is 3.9359611320495604 and perplexity is 51.21134717743068
At time: 697.7556958198547 and batch: 1350, loss is 3.8382324171066284 and perplexity is 46.44330944517557
At time: 698.6582531929016 and batch: 1400, loss is 3.87376296043396 and perplexity is 48.123131237911096
At time: 699.5608758926392 and batch: 1450, loss is 3.7743498849868775 and perplexity is 43.56917413226969
At time: 700.4625749588013 and batch: 1500, loss is 3.8070921802520754 and perplexity is 45.01934022653706
At time: 701.3647453784943 and batch: 1550, loss is 3.8021374416351317 and perplexity is 44.79683285115234
At time: 702.2695803642273 and batch: 1600, loss is 3.8992522287368776 and perplexity is 49.36552118230181
At time: 703.1737096309662 and batch: 1650, loss is 3.8601935291290284 and perplexity is 47.47453818589264
At time: 704.0767176151276 and batch: 1700, loss is 3.86920973777771 and perplexity is 47.90451399066518
At time: 704.9879989624023 and batch: 1750, loss is 3.8536234283447266 and perplexity is 47.16364809327231
At time: 705.8907182216644 and batch: 1800, loss is 3.8223551082611085 and perplexity is 45.71173774061758
At time: 706.7958602905273 and batch: 1850, loss is 3.852673740386963 and perplexity is 47.118878606519985
At time: 707.6981840133667 and batch: 1900, loss is 3.926014852523804 and perplexity is 50.70450955622332
At time: 708.6062624454498 and batch: 1950, loss is 3.8581966400146483 and perplexity is 47.37983138833636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321433559683866 and perplexity of 75.29649297498547
finished 19 epochs...
Completing Train Step...
At time: 711.5614788532257 and batch: 50, loss is 3.9634964275360107 and perplexity is 52.641060207594
At time: 712.4356315135956 and batch: 100, loss is 3.963734440803528 and perplexity is 52.653590969524224
At time: 713.3176484107971 and batch: 150, loss is 3.9394353818893433 and perplexity is 51.389577621426476
At time: 714.2052631378174 and batch: 200, loss is 3.933225779533386 and perplexity is 51.071457501084296
At time: 715.0988721847534 and batch: 250, loss is 3.921693720817566 and perplexity is 50.48588139306312
At time: 716.0196216106415 and batch: 300, loss is 3.930762977600098 and perplexity is 50.945833373982964
At time: 716.9173982143402 and batch: 350, loss is 3.9362003326416017 and perplexity is 51.22359842718944
At time: 717.8146216869354 and batch: 400, loss is 3.892463493347168 and perplexity is 49.031526704416684
At time: 718.7134094238281 and batch: 450, loss is 3.9396483278274537 and perplexity is 51.400521988480065
At time: 719.6162345409393 and batch: 500, loss is 3.9513263654708863 and perplexity is 52.004297815849974
At time: 720.5259795188904 and batch: 550, loss is 3.92655198097229 and perplexity is 50.731751706384465
At time: 721.4376585483551 and batch: 600, loss is 3.9110528230667114 and perplexity is 49.95151440566558
At time: 722.3566648960114 and batch: 650, loss is 3.9531168699264527 and perplexity is 52.09749515302309
At time: 723.2667422294617 and batch: 700, loss is 3.9860797786712645 and perplexity is 53.84339705230976
At time: 724.1832320690155 and batch: 750, loss is 3.942414541244507 and perplexity is 51.54290364027464
At time: 725.0978493690491 and batch: 800, loss is 3.912163300514221 and perplexity is 50.007015246394545
At time: 726.0079832077026 and batch: 850, loss is 3.916299304962158 and perplexity is 50.21427279750356
At time: 726.9188055992126 and batch: 900, loss is 3.8852525472640993 and perplexity is 48.67923471478303
At time: 727.8293120861053 and batch: 950, loss is 3.9830525732040405 and perplexity is 53.6806484873372
At time: 728.7477598190308 and batch: 1000, loss is 3.9412107276916504 and perplexity is 51.4808929264764
At time: 729.6609592437744 and batch: 1050, loss is 3.8932916259765626 and perplexity is 49.07214812919179
At time: 730.5720674991608 and batch: 1100, loss is 3.9160146284103394 and perplexity is 50.199980005979306
At time: 731.482634305954 and batch: 1150, loss is 3.892880620956421 and perplexity is 49.05198337415318
At time: 732.3939955234528 and batch: 1200, loss is 3.9410926294326782 and perplexity is 51.474813481644446
At time: 733.3051359653473 and batch: 1250, loss is 3.936750020980835 and perplexity is 51.25176318214793
At time: 734.2158784866333 and batch: 1300, loss is 3.934795069694519 and perplexity is 51.15166635587812
At time: 735.1267068386078 and batch: 1350, loss is 3.837107529640198 and perplexity is 46.39109532149365
At time: 736.0371162891388 and batch: 1400, loss is 3.872851696014404 and perplexity is 48.079298315380974
At time: 736.9476640224457 and batch: 1450, loss is 3.773555693626404 and perplexity is 43.53458560736272
At time: 737.857342004776 and batch: 1500, loss is 3.806533975601196 and perplexity is 44.99421723398108
At time: 738.7685408592224 and batch: 1550, loss is 3.8016584968566893 and perplexity is 44.77538277907756
At time: 739.6791241168976 and batch: 1600, loss is 3.898881196975708 and perplexity is 49.34720840355785
At time: 740.5900466442108 and batch: 1650, loss is 3.8599307537078857 and perplexity is 47.46206468306405
At time: 741.5013606548309 and batch: 1700, loss is 3.868958306312561 and perplexity is 47.892470802606915
At time: 742.4125649929047 and batch: 1750, loss is 3.8534801054000853 and perplexity is 47.156888944729666
At time: 743.3327059745789 and batch: 1800, loss is 3.8223847579956054 and perplexity is 45.713093101597934
At time: 744.2522628307343 and batch: 1850, loss is 3.852713932991028 and perplexity is 47.12077247501129
At time: 745.1627082824707 and batch: 1900, loss is 3.9260075092315674 and perplexity is 50.70413721955904
At time: 746.0734250545502 and batch: 1950, loss is 3.858156418800354 and perplexity is 47.37792575230862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321291333575582 and perplexity of 75.28578460934482
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdaf8802b38>
ELAPSED
4637.158886194229


RESULTS SO FAR:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}, {'best_accuracy': -75.95030619273909, 'params': {'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}}, {'best_accuracy': -76.28212132931245, 'params': {'wordvec_dim': 300, 'dropout': 0.022236433569113312, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5875562008890167}}, {'best_accuracy': -80.2393712516514, 'params': {'wordvec_dim': 300, 'dropout': 0.968078670033271, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.28515311562638934}}, {'best_accuracy': -75.28578460934482, 'params': {'wordvec_dim': 300, 'dropout': 0.25274251415391286, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5835372336256769}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -76.37690047794158, 'params': {'wordvec_dim': 300, 'dropout': 0.03089071058373749, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.1325622008817794}}, {'best_accuracy': -76.54312349221806, 'params': {'wordvec_dim': 300, 'dropout': 0.9178534839434576, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5233480276214579}}, {'best_accuracy': -75.95030619273909, 'params': {'wordvec_dim': 300, 'dropout': 0.27222257079557977, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5730079993540301}}, {'best_accuracy': -76.28212132931245, 'params': {'wordvec_dim': 300, 'dropout': 0.022236433569113312, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5875562008890167}}, {'best_accuracy': -80.2393712516514, 'params': {'wordvec_dim': 300, 'dropout': 0.968078670033271, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.28515311562638934}}, {'best_accuracy': -75.28578460934482, 'params': {'wordvec_dim': 300, 'dropout': 0.25274251415391286, 'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'FALSE', 'batch_size': 32, 'seq_len': 35, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'rnn_dropout': 0.5835372336256769}}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7fdaf62e3b38>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7fdaeff72dd8>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
