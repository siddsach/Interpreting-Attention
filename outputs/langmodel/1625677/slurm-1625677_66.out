FALSE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7856743335723877 and batch: 50, loss is 7.687996768951416 and perplexity is 2181.9991327826015
At time: 2.910567045211792 and batch: 100, loss is 6.897462072372437 and perplexity is 989.7595871471707
At time: 4.042259216308594 and batch: 150, loss is 6.468151502609253 and perplexity is 644.2916540912324
At time: 5.171233654022217 and batch: 200, loss is 6.307360973358154 and perplexity is 548.5952792375732
At time: 6.301574468612671 and batch: 250, loss is 6.17203125 and perplexity is 479.15840877786457
At time: 7.434001684188843 and batch: 300, loss is 6.049980506896973 and perplexity is 424.10476284635143
At time: 8.5625901222229 and batch: 350, loss is 5.938313798904419 and perplexity is 379.29482266982313
At time: 9.69778823852539 and batch: 400, loss is 5.859301872253418 and perplexity is 350.47937921207006
At time: 10.828148126602173 and batch: 450, loss is 5.754374608993531 and perplexity is 315.56813232790915
At time: 11.964522361755371 and batch: 500, loss is 5.69576922416687 and perplexity is 297.60563100475355
At time: 13.101033210754395 and batch: 550, loss is 5.620670547485352 and perplexity is 276.0744422054253
At time: 14.229432582855225 and batch: 600, loss is 5.624943494796753 and perplexity is 277.25661763897665
At time: 15.359834432601929 and batch: 650, loss is 5.672030963897705 and perplexity is 290.62418263463644
At time: 16.486005306243896 and batch: 700, loss is 5.593964605331421 and perplexity is 268.79919270944856
At time: 17.61704969406128 and batch: 750, loss is 5.516752891540527 and perplexity is 248.825759765505
At time: 18.74677848815918 and batch: 800, loss is 5.502488670349121 and perplexity is 245.30164819700846
At time: 19.87369966506958 and batch: 850, loss is 5.500748653411865 and perplexity is 244.87519030398474
At time: 21.001972675323486 and batch: 900, loss is 5.492694864273071 and perplexity is 242.91093761180394
At time: 22.127452850341797 and batch: 950, loss is 5.5119275379180905 and perplexity is 247.62797966463484
At time: 23.25268864631653 and batch: 1000, loss is 5.469409074783325 and perplexity is 237.31991299681485
At time: 24.37700366973877 and batch: 1050, loss is 5.358823699951172 and perplexity is 212.474865198781
At time: 25.504273176193237 and batch: 1100, loss is 5.443886041641235 and perplexity is 231.3394336280858
At time: 26.630924224853516 and batch: 1150, loss is 5.3339982509613035 and perplexity is 207.26501724608292
At time: 27.75583004951477 and batch: 1200, loss is 5.408832483291626 and perplexity is 223.37064642168917
At time: 28.878894805908203 and batch: 1250, loss is 5.3493901634216305 and perplexity is 210.47990037764916
At time: 30.007251024246216 and batch: 1300, loss is 5.366317224502564 and perplexity is 214.07303128764772
At time: 31.13508129119873 and batch: 1350, loss is 5.298490142822265 and perplexity is 200.03455824018175
At time: 32.26128387451172 and batch: 1400, loss is 5.324759521484375 and perplexity is 205.3589701060597
At time: 33.38893795013428 and batch: 1450, loss is 5.2757714653015135 and perplexity is 195.54127164455358
At time: 34.51514458656311 and batch: 1500, loss is 5.2353762435913085 and perplexity is 187.7997515064244
At time: 35.63992667198181 and batch: 1550, loss is 5.215803108215332 and perplexity is 184.15966174291307
At time: 36.76389408111572 and batch: 1600, loss is 5.249586095809937 and perplexity is 190.48740860296843
At time: 37.886969804763794 and batch: 1650, loss is 5.225593109130859 and perplexity is 185.9714391807056
At time: 39.012112855911255 and batch: 1700, loss is 5.245753698348999 and perplexity is 189.75878222662925
At time: 40.14121174812317 and batch: 1750, loss is 5.251204595565796 and perplexity is 190.79596205677575
At time: 41.2682728767395 and batch: 1800, loss is 5.2314041709899906 and perplexity is 187.05527679156032
At time: 42.39391255378723 and batch: 1850, loss is 5.195172681808471 and perplexity is 180.3992917834528
At time: 43.52097678184509 and batch: 1900, loss is 5.244179010391235 and perplexity is 189.46020650087377
At time: 44.64787769317627 and batch: 1950, loss is 5.164736385345459 and perplexity is 174.99132221400168
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.799126203670058 and perplexity of 121.40428853616766
finished 1 epochs...
Completing Train Step...
At time: 47.90596795082092 and batch: 50, loss is 5.025105199813843 and perplexity is 152.18626523734872
At time: 48.90594935417175 and batch: 100, loss is 4.972171449661255 and perplexity is 144.33997430995456
At time: 49.86579132080078 and batch: 150, loss is 4.906410112380981 and perplexity is 135.1533571215443
At time: 50.82483124732971 and batch: 200, loss is 4.8775615406036374 and perplexity is 131.31007888223766
At time: 51.78426170349121 and batch: 250, loss is 4.8826515579223635 and perplexity is 131.98015335650535
At time: 52.743221044540405 and batch: 300, loss is 4.888700504302978 and perplexity is 132.78091366391214
At time: 53.73125743865967 and batch: 350, loss is 4.886853179931641 and perplexity is 132.53585067116381
At time: 54.692262172698975 and batch: 400, loss is 4.845416650772095 and perplexity is 127.15625070827706
At time: 55.65312194824219 and batch: 450, loss is 4.814463510513305 and perplexity is 123.28065578988237
At time: 56.612640380859375 and batch: 500, loss is 4.804387731552124 and perplexity is 122.04474399491704
At time: 57.572004079818726 and batch: 550, loss is 4.757926521301269 and perplexity is 116.50410649880048
At time: 58.53044033050537 and batch: 600, loss is 4.741495819091797 and perplexity is 114.60550262946144
At time: 59.48987579345703 and batch: 650, loss is 4.81479513168335 and perplexity is 123.3215450446958
At time: 60.468029737472534 and batch: 700, loss is 4.805312938690186 and perplexity is 122.15771291499117
At time: 61.42756175994873 and batch: 750, loss is 4.772363662719727 and perplexity is 118.19829293810848
At time: 62.386950731277466 and batch: 800, loss is 4.755162115097046 and perplexity is 116.18248657285378
At time: 63.347148418426514 and batch: 850, loss is 4.737287015914917 and perplexity is 114.12416426566041
At time: 64.30559659004211 and batch: 900, loss is 4.731449546813965 and perplexity is 113.45990865515441
At time: 65.2661600112915 and batch: 950, loss is 4.795817823410034 and perplexity is 121.00330066042562
At time: 66.22568368911743 and batch: 1000, loss is 4.765531139373779 and perplexity is 117.3934530169844
At time: 67.18854284286499 and batch: 1050, loss is 4.677636547088623 and perplexity is 107.51566383957659
At time: 68.15747046470642 and batch: 1100, loss is 4.752915210723877 and perplexity is 115.92172869440105
At time: 69.14340710639954 and batch: 1150, loss is 4.68014009475708 and perplexity is 107.78517165116415
At time: 70.10979890823364 and batch: 1200, loss is 4.757996568679809 and perplexity is 116.51226759187814
At time: 71.06850218772888 and batch: 1250, loss is 4.71682505607605 and perplexity is 111.81268950078076
At time: 72.02787590026855 and batch: 1300, loss is 4.736619081497192 and perplexity is 114.04796226025744
At time: 72.9885606765747 and batch: 1350, loss is 4.630639753341675 and perplexity is 102.5796688087517
At time: 73.94859886169434 and batch: 1400, loss is 4.644019317626953 and perplexity is 103.96136270139792
At time: 74.90694737434387 and batch: 1450, loss is 4.5894792366027835 and perplexity is 98.44315122114487
At time: 75.86433839797974 and batch: 1500, loss is 4.573503932952881 and perplexity is 96.88298721568853
At time: 76.825035572052 and batch: 1550, loss is 4.5758445262908936 and perplexity is 97.1100164780759
At time: 77.78647422790527 and batch: 1600, loss is 4.639866456985474 and perplexity is 103.53052088221786
At time: 78.74723625183105 and batch: 1650, loss is 4.595785856246948 and perplexity is 99.06595656642367
At time: 79.70638155937195 and batch: 1700, loss is 4.635079469680786 and perplexity is 103.03610591632585
At time: 80.66456389427185 and batch: 1750, loss is 4.622804613113403 and perplexity is 101.77908316507694
At time: 81.62492895126343 and batch: 1800, loss is 4.583241510391235 and perplexity is 97.8310009940403
At time: 82.58565282821655 and batch: 1850, loss is 4.601065216064453 and perplexity is 99.59034439485636
At time: 83.54798984527588 and batch: 1900, loss is 4.677706413269043 and perplexity is 107.52317581075766
At time: 84.50767207145691 and batch: 1950, loss is 4.606098232269287 and perplexity is 100.09284770493927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515123660065407 and perplexity of 91.38886647687237
finished 2 epochs...
Completing Train Step...
At time: 87.69343566894531 and batch: 50, loss is 4.574973907470703 and perplexity is 97.02550746300857
At time: 88.67365956306458 and batch: 100, loss is 4.532017240524292 and perplexity is 92.94586626678993
At time: 89.63122081756592 and batch: 150, loss is 4.486175317764282 and perplexity is 88.7812356804574
At time: 90.58817672729492 and batch: 200, loss is 4.4848638439178465 and perplexity is 88.66487772869118
At time: 91.5612645149231 and batch: 250, loss is 4.481155204772949 and perplexity is 88.33666068784332
At time: 92.5381965637207 and batch: 300, loss is 4.504978475570678 and perplexity is 90.46639679034868
At time: 93.49561738967896 and batch: 350, loss is 4.507425394058227 and perplexity is 90.68803173989977
At time: 94.45339322090149 and batch: 400, loss is 4.4683019638061525 and perplexity is 87.2085140037309
At time: 95.44761300086975 and batch: 450, loss is 4.47394811630249 and perplexity is 87.70229925440532
At time: 96.40452170372009 and batch: 500, loss is 4.476006889343262 and perplexity is 87.88304437647488
At time: 97.36178302764893 and batch: 550, loss is 4.436207084655762 and perplexity is 84.45400652143167
At time: 98.31949257850647 and batch: 600, loss is 4.418567934036255 and perplexity is 82.97737116317676
At time: 99.29187750816345 and batch: 650, loss is 4.483930644989013 and perplexity is 88.58217435512137
At time: 100.2626838684082 and batch: 700, loss is 4.503490676879883 and perplexity is 90.33190107972348
At time: 101.25256967544556 and batch: 750, loss is 4.468070602416992 and perplexity is 87.18833965465706
At time: 102.27950096130371 and batch: 800, loss is 4.453589324951172 and perplexity is 85.93483916613984
At time: 103.23640894889832 and batch: 850, loss is 4.439976568222046 and perplexity is 84.77295526949122
At time: 104.19460010528564 and batch: 900, loss is 4.425458583831787 and perplexity is 83.55111362785827
At time: 105.15884375572205 and batch: 950, loss is 4.496686563491822 and perplexity is 89.719358848799
At time: 106.11557173728943 and batch: 1000, loss is 4.478602275848389 and perplexity is 88.11143109157656
At time: 107.07263207435608 and batch: 1050, loss is 4.403110933303833 and perplexity is 81.70465143087954
At time: 108.06881332397461 and batch: 1100, loss is 4.463935432434082 and perplexity is 86.8285454674144
At time: 109.02666521072388 and batch: 1150, loss is 4.413327169418335 and perplexity is 82.54364381647818
At time: 109.98455691337585 and batch: 1200, loss is 4.484898099899292 and perplexity is 88.66791508312097
At time: 110.9417335987091 and batch: 1250, loss is 4.463820695877075 and perplexity is 86.81858363056195
At time: 111.89806580543518 and batch: 1300, loss is 4.4707129955291744 and perplexity is 87.41903017611759
At time: 112.8668885231018 and batch: 1350, loss is 4.354230127334595 and perplexity is 77.80690086652498
At time: 113.84116911888123 and batch: 1400, loss is 4.373308677673339 and perplexity is 79.30559473562947
At time: 114.82670569419861 and batch: 1450, loss is 4.315508060455322 and perplexity is 74.8516429448188
At time: 115.78385901451111 and batch: 1500, loss is 4.3147768211364745 and perplexity is 74.7969284875365
At time: 116.77034878730774 and batch: 1550, loss is 4.322225437164307 and perplexity is 75.35614218644515
At time: 117.72866559028625 and batch: 1600, loss is 4.3948415088653565 and perplexity is 81.03178692508523
At time: 118.71225881576538 and batch: 1650, loss is 4.352255792617798 and perplexity is 77.65343554674276
At time: 119.68417429924011 and batch: 1700, loss is 4.390630531311035 and perplexity is 80.69128132304384
At time: 120.64935898780823 and batch: 1750, loss is 4.375411624908447 and perplexity is 79.4725456998148
At time: 121.63075757026672 and batch: 1800, loss is 4.335007400512695 and perplexity is 76.325523735685
At time: 122.60001969337463 and batch: 1850, loss is 4.365880041122437 and perplexity is 78.71864511281063
At time: 123.55807137489319 and batch: 1900, loss is 4.448837165832519 and perplexity is 85.52743193528683
At time: 124.5141236782074 and batch: 1950, loss is 4.3818112659454345 and perplexity is 79.98277235693861
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416432367369186 and perplexity of 82.8003565357437
finished 3 epochs...
Completing Train Step...
At time: 127.6406762599945 and batch: 50, loss is 4.35838219165802 and perplexity is 78.13063173433902
At time: 128.62406253814697 and batch: 100, loss is 4.3139955520629885 and perplexity is 74.7385147818995
At time: 129.58181476593018 and batch: 150, loss is 4.278961544036865 and perplexity is 72.16546042985304
At time: 130.53817987442017 and batch: 200, loss is 4.279218502044678 and perplexity is 72.18400630545158
At time: 131.49578428268433 and batch: 250, loss is 4.27503538608551 and perplexity is 71.88268291141893
At time: 132.45889592170715 and batch: 300, loss is 4.293737478256226 and perplexity is 73.23968934953066
At time: 133.44334626197815 and batch: 350, loss is 4.299122362136841 and perplexity is 73.63514034540377
At time: 134.40139722824097 and batch: 400, loss is 4.26506085395813 and perplexity is 71.16925077222716
At time: 135.38784384727478 and batch: 450, loss is 4.293937664031983 and perplexity is 73.25435236117352
At time: 136.3447721004486 and batch: 500, loss is 4.289467849731445 and perplexity is 72.92764970345772
At time: 137.30100560188293 and batch: 550, loss is 4.250722045898438 and perplexity is 70.15604995126841
At time: 138.2580201625824 and batch: 600, loss is 4.238446168899536 and perplexity is 69.30008750542015
At time: 139.2443778514862 and batch: 650, loss is 4.30174111366272 and perplexity is 73.82822519181396
At time: 140.2018027305603 and batch: 700, loss is 4.326065530776978 and perplexity is 75.64607315146984
At time: 141.15819001197815 and batch: 750, loss is 4.29239501953125 and perplexity is 73.1414340561431
At time: 142.11578154563904 and batch: 800, loss is 4.277061195373535 and perplexity is 72.0284511175504
At time: 143.10492253303528 and batch: 850, loss is 4.260261459350586 and perplexity is 70.82849980709683
At time: 144.09124851226807 and batch: 900, loss is 4.241795177459717 and perplexity is 69.53256315588436
At time: 145.0486354827881 and batch: 950, loss is 4.324966802597046 and perplexity is 75.56300432258543
At time: 146.00539994239807 and batch: 1000, loss is 4.305506572723389 and perplexity is 74.10674640231487
At time: 146.96259450912476 and batch: 1050, loss is 4.238241977691651 and perplexity is 69.28593848144818
At time: 147.9204387664795 and batch: 1100, loss is 4.291035828590393 and perplexity is 73.04208841171688
At time: 148.87657356262207 and batch: 1150, loss is 4.246644234657287 and perplexity is 69.8705493265923
At time: 149.85038375854492 and batch: 1200, loss is 4.321862149238586 and perplexity is 75.32877118193868
At time: 150.80774021148682 and batch: 1250, loss is 4.305528049468994 and perplexity is 74.10833799114597
At time: 151.76544070243835 and batch: 1300, loss is 4.302184009552002 and perplexity is 73.8609306512866
At time: 152.7223641872406 and batch: 1350, loss is 4.19228765964508 and perplexity is 66.17400152815722
At time: 153.67911863327026 and batch: 1400, loss is 4.212699666023254 and perplexity is 67.53862564696968
At time: 154.63676404953003 and batch: 1450, loss is 4.151419262886048 and perplexity is 63.52409373847509
At time: 155.59439635276794 and batch: 1500, loss is 4.1593822526931765 and perplexity is 64.03195481211192
At time: 156.55244660377502 and batch: 1550, loss is 4.162405285835266 and perplexity is 64.2258184140697
At time: 157.50992250442505 and batch: 1600, loss is 4.24718334197998 and perplexity is 69.90822720667282
At time: 158.46706223487854 and batch: 1650, loss is 4.195772795677185 and perplexity is 66.40502927298867
At time: 159.42264080047607 and batch: 1700, loss is 4.23345326423645 and perplexity is 68.95494113384147
At time: 160.381249666214 and batch: 1750, loss is 4.22629364490509 and perplexity is 68.46301311434269
At time: 161.33774876594543 and batch: 1800, loss is 4.18016547203064 and perplexity is 65.3766703294161
At time: 162.29394960403442 and batch: 1850, loss is 4.213977994918824 and perplexity is 67.62501743049329
At time: 163.25098633766174 and batch: 1900, loss is 4.30315167427063 and perplexity is 73.9324378598845
At time: 164.20732045173645 and batch: 1950, loss is 4.23442057132721 and perplexity is 69.02167400773078
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371818223110465 and perplexity of 79.18748139324464
finished 4 epochs...
Completing Train Step...
At time: 167.33008909225464 and batch: 50, loss is 4.214924321174622 and perplexity is 67.6890430498208
At time: 168.34456276893616 and batch: 100, loss is 4.173396167755127 and perplexity is 64.93561027453492
At time: 169.3013916015625 and batch: 150, loss is 4.14355619430542 and perplexity is 63.02655807486997
At time: 170.25794911384583 and batch: 200, loss is 4.143820843696594 and perplexity is 63.043240222455026
At time: 171.21682691574097 and batch: 250, loss is 4.138309192657471 and perplexity is 62.69672369826825
At time: 172.1982660293579 and batch: 300, loss is 4.152108063697815 and perplexity is 63.56786425866329
At time: 173.16458940505981 and batch: 350, loss is 4.163275184631348 and perplexity is 64.28171268383976
At time: 174.13796257972717 and batch: 400, loss is 4.124474391937256 and perplexity is 61.83529957542367
At time: 175.09537982940674 and batch: 450, loss is 4.162965893745422 and perplexity is 64.2618340102797
At time: 176.05310130119324 and batch: 500, loss is 4.162696866989136 and perplexity is 64.2445481828022
At time: 177.01057863235474 and batch: 550, loss is 4.122839241027832 and perplexity is 61.7342721491423
At time: 177.99429988861084 and batch: 600, loss is 4.115854263305664 and perplexity is 61.30456213803833
At time: 178.9519238471985 and batch: 650, loss is 4.176141605377198 and perplexity is 65.11413188984149
At time: 179.90867495536804 and batch: 700, loss is 4.202977595329284 and perplexity is 66.8851918653645
At time: 180.8658049106598 and batch: 750, loss is 4.168936190605163 and perplexity is 64.6466438074072
At time: 181.8532292842865 and batch: 800, loss is 4.1521890306472775 and perplexity is 63.57301136308601
At time: 182.8107316493988 and batch: 850, loss is 4.140348348617554 and perplexity is 62.824702536133906
At time: 183.76781249046326 and batch: 900, loss is 4.118976130485534 and perplexity is 61.49624588847809
At time: 184.724267244339 and batch: 950, loss is 4.206779270172119 and perplexity is 67.13995156657975
At time: 185.70206379890442 and batch: 1000, loss is 4.185052886009216 and perplexity is 65.69697527570429
At time: 186.67539429664612 and batch: 1050, loss is 4.12173526763916 and perplexity is 61.66615676122641
At time: 187.64113807678223 and batch: 1100, loss is 4.167239651679993 and perplexity is 64.53706124163429
At time: 188.59798741340637 and batch: 1150, loss is 4.130510048866272 and perplexity is 62.209644803024595
At time: 189.5554177761078 and batch: 1200, loss is 4.208144187927246 and perplexity is 67.23165464789636
At time: 190.51277565956116 and batch: 1250, loss is 4.189331893920898 and perplexity is 65.97869546428475
At time: 191.4700210094452 and batch: 1300, loss is 4.186044640541077 and perplexity is 65.76216286836566
At time: 192.42733192443848 and batch: 1350, loss is 4.076869268417358 and perplexity is 58.960590813779014
At time: 193.38429737091064 and batch: 1400, loss is 4.097134990692139 and perplexity is 60.16765952036179
At time: 194.34130096435547 and batch: 1450, loss is 4.040092191696167 and perplexity is 56.83158196389896
At time: 195.29772114753723 and batch: 1500, loss is 4.049730987548828 and perplexity is 57.38201849151008
At time: 196.2789375782013 and batch: 1550, loss is 4.047229337692261 and perplexity is 57.238648179112595
At time: 197.2360122203827 and batch: 1600, loss is 4.138091793060303 and perplexity is 62.683094937289745
At time: 198.19321942329407 and batch: 1650, loss is 4.083967847824097 and perplexity is 59.380616277844126
At time: 199.15048122406006 and batch: 1700, loss is 4.1248195314407345 and perplexity is 61.85664506339023
At time: 200.13689494132996 and batch: 1750, loss is 4.11709358215332 and perplexity is 61.380585135980006
At time: 201.10397934913635 and batch: 1800, loss is 4.068729152679444 and perplexity is 58.48259289915416
At time: 202.06435823440552 and batch: 1850, loss is 4.107050895690918 and perplexity is 60.76724411525865
At time: 203.02709674835205 and batch: 1900, loss is 4.196652817726135 and perplexity is 66.46349288377029
At time: 203.9876663684845 and batch: 1950, loss is 4.1241435527801515 and perplexity is 61.814845420737036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350595305686773 and perplexity of 77.52460002631948
finished 5 epochs...
Completing Train Step...
At time: 207.14687657356262 and batch: 50, loss is 4.108737535476685 and perplexity is 60.86982304939295
At time: 208.12456798553467 and batch: 100, loss is 4.072421498298645 and perplexity is 58.69892999472405
At time: 209.07977032661438 and batch: 150, loss is 4.046045083999633 and perplexity is 57.17090322017183
At time: 210.03913593292236 and batch: 200, loss is 4.043701696395874 and perplexity is 57.03708648774341
At time: 210.99999141693115 and batch: 250, loss is 4.03651186466217 and perplexity is 56.62847013496464
At time: 211.96145153045654 and batch: 300, loss is 4.049859638214111 and perplexity is 57.3894012012494
At time: 212.92355060577393 and batch: 350, loss is 4.061076860427857 and perplexity is 58.03677494678997
At time: 213.88379621505737 and batch: 400, loss is 4.024160509109497 and perplexity is 55.93333354277575
At time: 214.8442325592041 and batch: 450, loss is 4.062602047920227 and perplexity is 58.12535944684998
At time: 215.80444884300232 and batch: 500, loss is 4.069038605690002 and perplexity is 58.50069331406157
At time: 216.76326394081116 and batch: 550, loss is 4.030611109733582 and perplexity is 56.29530334521376
At time: 217.72522115707397 and batch: 600, loss is 4.023957753181458 and perplexity is 55.921993877455996
At time: 218.68350076675415 and batch: 650, loss is 4.078399810791016 and perplexity is 59.0509015910012
At time: 219.64196109771729 and batch: 700, loss is 4.10790283203125 and perplexity is 60.81903599738301
At time: 220.60023832321167 and batch: 750, loss is 4.07692054271698 and perplexity is 58.9636140542849
At time: 221.56399726867676 and batch: 800, loss is 4.05834502696991 and perplexity is 57.87844450786142
At time: 222.54601740837097 and batch: 850, loss is 4.046600527763367 and perplexity is 57.20266726258548
At time: 223.5059838294983 and batch: 900, loss is 4.026082830429077 and perplexity is 56.04095879433555
At time: 224.46639752388 and batch: 950, loss is 4.1150480031967165 and perplexity is 61.25515463541562
At time: 225.4540765285492 and batch: 1000, loss is 4.09409451007843 and perplexity is 59.984998747005676
At time: 226.4172022342682 and batch: 1050, loss is 4.031635456085205 and perplexity is 56.352998778817486
At time: 227.40733408927917 and batch: 1100, loss is 4.078618955612183 and perplexity is 59.06384370831731
At time: 228.38169145584106 and batch: 1150, loss is 4.042324514389038 and perplexity is 56.95859010282115
At time: 229.34186434745789 and batch: 1200, loss is 4.121753563880921 and perplexity is 61.66728503046048
At time: 230.30289125442505 and batch: 1250, loss is 4.103905944824219 and perplexity is 60.57643431919864
At time: 231.29597282409668 and batch: 1300, loss is 4.099241871833801 and perplexity is 60.29455926193762
At time: 232.2572739124298 and batch: 1350, loss is 3.9865066957473756 and perplexity is 53.86638862534559
At time: 233.21858978271484 and batch: 1400, loss is 4.012012825012207 and perplexity is 55.25798335166442
At time: 234.17846417427063 and batch: 1450, loss is 3.948770751953125 and perplexity is 51.87156460900077
At time: 235.16564655303955 and batch: 1500, loss is 3.9612906789779663 and perplexity is 52.52507522882241
At time: 236.12589144706726 and batch: 1550, loss is 3.9653388023376466 and perplexity is 52.73813416630104
At time: 237.08670854568481 and batch: 1600, loss is 4.057010684013367 and perplexity is 57.80126631563641
At time: 238.05961656570435 and batch: 1650, loss is 3.9951550579071045 and perplexity is 54.334264928072315
At time: 239.03862714767456 and batch: 1700, loss is 4.038474459648132 and perplexity is 56.73971801807448
At time: 239.9968228340149 and batch: 1750, loss is 4.029471464157105 and perplexity is 56.23118319584215
At time: 240.96816158294678 and batch: 1800, loss is 3.9826207733154297 and perplexity is 53.657474192988744
At time: 241.9575960636139 and batch: 1850, loss is 4.022398166656494 and perplexity is 55.83484666382971
At time: 242.94800758361816 and batch: 1900, loss is 4.10937771320343 and perplexity is 60.90880303006654
At time: 243.93853282928467 and batch: 1950, loss is 4.0411943912506105 and perplexity is 56.89425624165345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349525912972384 and perplexity of 77.44174009666449
finished 6 epochs...
Completing Train Step...
At time: 247.14553546905518 and batch: 50, loss is 4.022547664642334 and perplexity is 55.84319448492134
At time: 248.1340193748474 and batch: 100, loss is 3.9917256927490232 and perplexity is 54.1482520284176
At time: 249.10316348075867 and batch: 150, loss is 3.963792953491211 and perplexity is 52.65667196278574
At time: 250.1001009941101 and batch: 200, loss is 3.9672546863555906 and perplexity is 52.83927116713198
At time: 251.069482088089 and batch: 250, loss is 3.959864068031311 and perplexity is 52.45019580612878
At time: 252.02643537521362 and batch: 300, loss is 3.9685050010681153 and perplexity is 52.90537820395968
At time: 252.98740077018738 and batch: 350, loss is 3.980189733505249 and perplexity is 53.5271891653212
At time: 253.98936986923218 and batch: 400, loss is 3.9470931005477907 and perplexity is 51.78461516156229
At time: 254.98204898834229 and batch: 450, loss is 3.9832163763046267 and perplexity is 53.6894422642052
At time: 255.95778131484985 and batch: 500, loss is 3.993677468299866 and perplexity is 54.254040466908656
At time: 256.95771884918213 and batch: 550, loss is 3.954666657447815 and perplexity is 52.17829779819814
At time: 257.9519817829132 and batch: 600, loss is 3.9511085844039915 and perplexity is 51.99297349754434
At time: 258.9263696670532 and batch: 650, loss is 3.998651537895203 and perplexity is 54.52457611380217
At time: 259.9028871059418 and batch: 700, loss is 4.032589616775513 and perplexity is 56.40679425571653
At time: 260.8633646965027 and batch: 750, loss is 4.001380596160889 and perplexity is 54.67358008671172
At time: 261.82468271255493 and batch: 800, loss is 3.985843105316162 and perplexity is 53.8306552627598
At time: 262.78645873069763 and batch: 850, loss is 3.9743820810317994 and perplexity is 53.217222812429405
At time: 263.7466847896576 and batch: 900, loss is 3.9514373350143432 and perplexity is 52.01006902924493
At time: 264.71742010116577 and batch: 950, loss is 4.046026558876037 and perplexity is 57.16984413193348
At time: 265.7140426635742 and batch: 1000, loss is 4.02016236782074 and perplexity is 55.710150628234004
At time: 266.67894411087036 and batch: 1050, loss is 3.9621312046051025 and perplexity is 52.56924245986399
At time: 267.6379201412201 and batch: 1100, loss is 4.007066535949707 and perplexity is 54.985336244574796
At time: 268.5973951816559 and batch: 1150, loss is 3.9716309452056886 and perplexity is 53.0710162135069
At time: 269.58595991134644 and batch: 1200, loss is 4.051226534843445 and perplexity is 57.46790021810929
At time: 270.54481410980225 and batch: 1250, loss is 4.03379310131073 and perplexity is 56.47471982577251
At time: 271.50492572784424 and batch: 1300, loss is 4.026357932090759 and perplexity is 56.05637787603238
At time: 272.46570920944214 and batch: 1350, loss is 3.9157044315338134 and perplexity is 50.18441054390388
At time: 273.45481729507446 and batch: 1400, loss is 3.946481122970581 and perplexity is 51.752933833358995
At time: 274.4489130973816 and batch: 1450, loss is 3.878588914871216 and perplexity is 48.35593256912679
At time: 275.43902039527893 and batch: 1500, loss is 3.8958285236358643 and perplexity is 49.196797191022355
At time: 276.4099473953247 and batch: 1550, loss is 3.898457431793213 and perplexity is 49.32630120496737
At time: 277.4163556098938 and batch: 1600, loss is 3.989625473022461 and perplexity is 54.0346481396709
At time: 278.405077457428 and batch: 1650, loss is 3.9291194534301757 and perplexity is 50.86217143451791
At time: 279.3898205757141 and batch: 1700, loss is 3.9709744215011598 and perplexity is 53.03618526826098
At time: 280.35922503471375 and batch: 1750, loss is 3.965172529220581 and perplexity is 52.72936596132357
At time: 281.31693387031555 and batch: 1800, loss is 3.9134135818481446 and perplexity is 50.069577185985224
At time: 282.2738378047943 and batch: 1850, loss is 3.958139338493347 and perplexity is 52.35981137090806
At time: 283.232501745224 and batch: 1900, loss is 4.043987865447998 and perplexity is 57.05341107240359
At time: 284.223299741745 and batch: 1950, loss is 3.9696676969528197 and perplexity is 52.96692684371747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348527491369913 and perplexity of 77.36445917630896
finished 7 epochs...
Completing Train Step...
At time: 287.4073877334595 and batch: 50, loss is 3.95462052822113 and perplexity is 52.17589090918538
At time: 288.3767087459564 and batch: 100, loss is 3.9260809087753294 and perplexity is 50.707859016685234
At time: 289.33705496788025 and batch: 150, loss is 3.9000929307937624 and perplexity is 49.40704032766901
At time: 290.29759526252747 and batch: 200, loss is 3.9045104789733887 and perplexity is 49.625781101961685
At time: 291.2571723461151 and batch: 250, loss is 3.8949084186553957 and perplexity is 49.15155179135462
At time: 292.2203457355499 and batch: 300, loss is 3.9080488729476928 and perplexity is 49.801687696667805
At time: 293.19782876968384 and batch: 350, loss is 3.9159479761123657 and perplexity is 50.19663417345863
At time: 294.16353845596313 and batch: 400, loss is 3.8829488611221312 and perplexity is 48.56722210685257
At time: 295.17330503463745 and batch: 450, loss is 3.9235457372665405 and perplexity is 50.579468711720736
At time: 296.13319754600525 and batch: 500, loss is 3.9348814058303834 and perplexity is 51.15608278374023
At time: 297.1205515861511 and batch: 550, loss is 3.8942866134643555 and perplexity is 49.12099860135357
At time: 298.08270931243896 and batch: 600, loss is 3.8914542770385743 and perplexity is 48.98206824936893
At time: 299.05412340164185 and batch: 650, loss is 3.9409240818023683 and perplexity is 51.466138254926456
At time: 300.0219614505768 and batch: 700, loss is 3.9699714374542237 and perplexity is 52.983017488201305
At time: 300.9819300174713 and batch: 750, loss is 3.9419775867462157 and perplexity is 51.52038665648097
At time: 301.9424030780792 and batch: 800, loss is 3.925244855880737 and perplexity is 50.66548228144023
At time: 302.91285157203674 and batch: 850, loss is 3.9123191356658937 and perplexity is 50.01480870443175
At time: 303.89612555503845 and batch: 900, loss is 3.892363510131836 and perplexity is 49.02662461979132
At time: 304.86654472351074 and batch: 950, loss is 3.9891493844985964 and perplexity is 54.00892898658314
At time: 305.84773993492126 and batch: 1000, loss is 3.964168891906738 and perplexity is 52.67647135005231
At time: 306.80922746658325 and batch: 1050, loss is 3.902958059310913 and perplexity is 49.54880083191596
At time: 307.80515909194946 and batch: 1100, loss is 3.9445044803619385 and perplexity is 51.65073781499818
At time: 308.79807567596436 and batch: 1150, loss is 3.913714337348938 and perplexity is 50.08463815146688
At time: 309.75884532928467 and batch: 1200, loss is 3.9913293600082396 and perplexity is 54.126795555514754
At time: 310.720046043396 and batch: 1250, loss is 3.9742755460739136 and perplexity is 53.21155361982725
At time: 311.6811647415161 and batch: 1300, loss is 3.968036403656006 and perplexity is 52.88059268831443
At time: 312.64240169525146 and batch: 1350, loss is 3.8577428150177 and perplexity is 47.35833411487013
At time: 313.60400676727295 and batch: 1400, loss is 3.8901243162155152 and perplexity is 48.91696731800484
At time: 314.56315898895264 and batch: 1450, loss is 3.8212125492095947 and perplexity is 45.65953920653392
At time: 315.5212752819061 and batch: 1500, loss is 3.84163152217865 and perplexity is 46.601443739156686
At time: 316.5030748844147 and batch: 1550, loss is 3.8417192554473876 and perplexity is 46.605532415497656
At time: 317.46747493743896 and batch: 1600, loss is 3.932914237976074 and perplexity is 51.05554909787325
At time: 318.4288954734802 and batch: 1650, loss is 3.874036741256714 and perplexity is 48.13630823209676
At time: 319.38983154296875 and batch: 1700, loss is 3.9167238759994505 and perplexity is 50.23559684985926
At time: 320.35000133514404 and batch: 1750, loss is 3.911695899963379 and perplexity is 49.983647401419624
At time: 321.31080198287964 and batch: 1800, loss is 3.8588522481918335 and perplexity is 47.410904177902694
At time: 322.2896018028259 and batch: 1850, loss is 3.9009097957611085 and perplexity is 49.44741569641998
At time: 323.25651693344116 and batch: 1900, loss is 3.9837987279891967 and perplexity is 53.72071750706269
At time: 324.2143557071686 and batch: 1950, loss is 3.917455668449402 and perplexity is 50.27237233472271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344022529069767 and perplexity of 77.01671907048818
finished 8 epochs...
Completing Train Step...
At time: 327.38765048980713 and batch: 50, loss is 3.9025301361083984 and perplexity is 49.52760228638144
At time: 328.34893774986267 and batch: 100, loss is 3.874156074523926 and perplexity is 48.14205283778408
At time: 329.3570787906647 and batch: 150, loss is 3.852618021965027 and perplexity is 47.11625329010054
At time: 330.33858370780945 and batch: 200, loss is 3.8492358779907225 and perplexity is 46.957168513399274
At time: 331.31757974624634 and batch: 250, loss is 3.8439356327056884 and perplexity is 46.70894241310587
At time: 332.27975583076477 and batch: 300, loss is 3.8597919368743896 and perplexity is 47.45547660681208
At time: 333.2784113883972 and batch: 350, loss is 3.8611251735687255 and perplexity is 47.51878818485286
At time: 334.2631525993347 and batch: 400, loss is 3.828380460739136 and perplexity is 45.987998521377385
At time: 335.22504210472107 and batch: 450, loss is 3.871807336807251 and perplexity is 48.02911246809909
At time: 336.186562538147 and batch: 500, loss is 3.8867542219161986 and perplexity is 48.75239000161049
At time: 337.1495978832245 and batch: 550, loss is 3.8414242887496948 and perplexity is 46.591787362772905
At time: 338.1092858314514 and batch: 600, loss is 3.843059320449829 and perplexity is 46.66802872361303
At time: 339.06918144226074 and batch: 650, loss is 3.8902498722076415 and perplexity is 48.92310952195545
At time: 340.06155490875244 and batch: 700, loss is 3.917795615196228 and perplexity is 50.289465169315285
At time: 341.0226845741272 and batch: 750, loss is 3.8934254121780394 and perplexity is 49.07871374467288
At time: 341.98231077194214 and batch: 800, loss is 3.8725556993484496 and perplexity is 48.06506910938084
At time: 342.94709300994873 and batch: 850, loss is 3.861821675300598 and perplexity is 47.55189663182697
At time: 343.974098443985 and batch: 900, loss is 3.8405758237838743 and perplexity is 46.55227262930465
At time: 344.9557659626007 and batch: 950, loss is 3.936164207458496 and perplexity is 51.22174799874065
At time: 345.9412145614624 and batch: 1000, loss is 3.9133037185668944 and perplexity is 50.06407668010211
At time: 346.9314444065094 and batch: 1050, loss is 3.852560305595398 and perplexity is 47.11353398948496
At time: 347.8996560573578 and batch: 1100, loss is 3.9000098800659178 and perplexity is 49.40293720739507
At time: 348.88869547843933 and batch: 1150, loss is 3.866186738014221 and perplexity is 47.759917324162366
At time: 349.84927010536194 and batch: 1200, loss is 3.943883066177368 and perplexity is 51.61865128442157
At time: 350.80939054489136 and batch: 1250, loss is 3.924724097251892 and perplexity is 50.639104663139854
At time: 351.78070402145386 and batch: 1300, loss is 3.9173517274856566 and perplexity is 50.26714724744748
At time: 352.757860660553 and batch: 1350, loss is 3.807180156707764 and perplexity is 45.023301042754355
At time: 353.72430205345154 and batch: 1400, loss is 3.843167610168457 and perplexity is 46.67308266495242
At time: 354.6843955516815 and batch: 1450, loss is 3.7713218832015993 and perplexity is 43.43744613217271
At time: 355.67634654045105 and batch: 1500, loss is 3.7943465232849123 and perplexity is 44.44918040845231
At time: 356.63801646232605 and batch: 1550, loss is 3.798820443153381 and perplexity is 44.6484879904501
At time: 357.5992171764374 and batch: 1600, loss is 3.882150731086731 and perplexity is 48.528474612979345
At time: 358.56267833709717 and batch: 1650, loss is 3.8275468301773072 and perplexity is 45.949677495341106
At time: 359.5352780818939 and batch: 1700, loss is 3.864187173843384 and perplexity is 47.66451371928121
At time: 360.4957311153412 and batch: 1750, loss is 3.8612853717803954 and perplexity is 47.52640121952178
At time: 361.45622181892395 and batch: 1800, loss is 3.8106501960754393 and perplexity is 45.1798050503282
At time: 362.41839623451233 and batch: 1850, loss is 3.855983467102051 and perplexity is 47.27508757973835
At time: 363.40349769592285 and batch: 1900, loss is 3.935776267051697 and perplexity is 51.20188086686584
At time: 364.3596873283386 and batch: 1950, loss is 3.8715488290786744 and perplexity is 48.01669817599378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347529921420785 and perplexity of 77.28732119836548
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 367.5237789154053 and batch: 50, loss is 3.8906690645217896 and perplexity is 48.943622012490096
At time: 368.5075180530548 and batch: 100, loss is 3.8869505167007445 and perplexity is 48.76196078081826
At time: 369.4677758216858 and batch: 150, loss is 3.860305905342102 and perplexity is 47.47987349448667
At time: 370.4294583797455 and batch: 200, loss is 3.854518828392029 and perplexity is 47.20589733817117
At time: 371.3901927471161 and batch: 250, loss is 3.852988076210022 and perplexity is 47.13369208609006
At time: 372.35085225105286 and batch: 300, loss is 3.8670338439941405 and perplexity is 47.800392176552506
At time: 373.3124186992645 and batch: 350, loss is 3.866008062362671 and perplexity is 47.75138455213849
At time: 374.27250146865845 and batch: 400, loss is 3.822407488822937 and perplexity is 45.71413220983386
At time: 375.23378467559814 and batch: 450, loss is 3.8549784326553347 and perplexity is 47.22759835639921
At time: 376.1937041282654 and batch: 500, loss is 3.868011865615845 and perplexity is 47.84716486224781
At time: 377.1547312736511 and batch: 550, loss is 3.814175248146057 and perplexity is 45.339347247741834
At time: 378.11674404144287 and batch: 600, loss is 3.8064791917800904 and perplexity is 44.991752346351944
At time: 379.0774953365326 and batch: 650, loss is 3.847046346664429 and perplexity is 46.85446679728722
At time: 380.03661370277405 and batch: 700, loss is 3.87105073928833 and perplexity is 47.99278750419136
At time: 380.9928901195526 and batch: 750, loss is 3.8325901794433594 and perplexity is 46.1820031248185
At time: 381.9543743133545 and batch: 800, loss is 3.811115946769714 and perplexity is 45.2008524769439
At time: 382.91543316841125 and batch: 850, loss is 3.7909817695617676 and perplexity is 44.299871198410266
At time: 383.876704454422 and batch: 900, loss is 3.7607629442214967 and perplexity is 42.98120573515872
At time: 384.8372268676758 and batch: 950, loss is 3.8616251277923586 and perplexity is 47.54255134345858
At time: 385.7983944416046 and batch: 1000, loss is 3.8294797992706298 and perplexity is 46.038582699611894
At time: 386.7593650817871 and batch: 1050, loss is 3.762706756591797 and perplexity is 43.06483438742961
At time: 387.7207782268524 and batch: 1100, loss is 3.788926696777344 and perplexity is 44.20892522106624
At time: 388.683034658432 and batch: 1150, loss is 3.7577615213394164 and perplexity is 42.85239436616118
At time: 389.6427845954895 and batch: 1200, loss is 3.8228802728652953 and perplexity is 45.7357502319782
At time: 390.6029908657074 and batch: 1250, loss is 3.7918840408325196 and perplexity is 44.33985973703252
At time: 391.5638015270233 and batch: 1300, loss is 3.7923889780044555 and perplexity is 44.3622542338433
At time: 392.5327625274658 and batch: 1350, loss is 3.672433466911316 and perplexity is 39.34754038895844
At time: 393.5334575176239 and batch: 1400, loss is 3.7012738227844237 and perplexity is 40.4988598872611
At time: 394.5241436958313 and batch: 1450, loss is 3.6206694507598876 and perplexity is 37.362571853754666
At time: 395.51446413993835 and batch: 1500, loss is 3.634563989639282 and perplexity is 37.88533089873157
At time: 396.51408290863037 and batch: 1550, loss is 3.6364685010910036 and perplexity is 37.957552697071435
At time: 397.47650814056396 and batch: 1600, loss is 3.7120144081115725 and perplexity is 40.93618571103834
At time: 398.43696665763855 and batch: 1650, loss is 3.646121497154236 and perplexity is 38.325730956560946
At time: 399.3969473838806 and batch: 1700, loss is 3.6715326642990114 and perplexity is 39.312111981185126
At time: 400.3565499782562 and batch: 1750, loss is 3.662743034362793 and perplexity is 38.968087204969606
At time: 401.31899523735046 and batch: 1800, loss is 3.604664831161499 and perplexity is 36.76935784874999
At time: 402.28072476387024 and batch: 1850, loss is 3.6342717742919923 and perplexity is 37.87426184095885
At time: 403.241313457489 and batch: 1900, loss is 3.7112077569961546 and perplexity is 40.90317780589514
At time: 404.21265864372253 and batch: 1950, loss is 3.642136268615723 and perplexity is 38.17329810142116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283829090207122 and perplexity of 72.51758543751805
finished 10 epochs...
Completing Train Step...
At time: 407.38937401771545 and batch: 50, loss is 3.8101249742507934 and perplexity is 45.15608186119621
At time: 408.36731576919556 and batch: 100, loss is 3.7849064683914184 and perplexity is 44.031552024257174
At time: 409.3273825645447 and batch: 150, loss is 3.7582130146026613 and perplexity is 42.87174630183697
At time: 410.287207365036 and batch: 200, loss is 3.7492937517166136 and perplexity is 42.49106216087025
At time: 411.24472403526306 and batch: 250, loss is 3.7437760829925537 and perplexity is 42.25725618128215
At time: 412.2040665149689 and batch: 300, loss is 3.757138271331787 and perplexity is 42.82569493212103
At time: 413.1650893688202 and batch: 350, loss is 3.760746421813965 and perplexity is 42.980495588028035
At time: 414.1259343624115 and batch: 400, loss is 3.7235876941680908 and perplexity is 41.4127040209263
At time: 415.0870141983032 and batch: 450, loss is 3.762749934196472 and perplexity is 43.06669386396778
At time: 416.0703430175781 and batch: 500, loss is 3.7791027641296386 and perplexity is 43.77674604262039
At time: 417.0310821533203 and batch: 550, loss is 3.726619310379028 and perplexity is 41.53844194403633
At time: 418.0001802444458 and batch: 600, loss is 3.721269989013672 and perplexity is 41.31683272697109
At time: 418.95976209640503 and batch: 650, loss is 3.765423183441162 and perplexity is 43.18197589095376
At time: 419.92044043540955 and batch: 700, loss is 3.791850252151489 and perplexity is 44.3383615769655
At time: 420.8812954425812 and batch: 750, loss is 3.7544175243377684 and perplexity is 42.70933541554909
At time: 421.8417785167694 and batch: 800, loss is 3.73438371181488 and perplexity is 41.86221842098539
At time: 422.801393032074 and batch: 850, loss is 3.7169891500473025 and perplexity is 41.14034005734272
At time: 423.7582333087921 and batch: 900, loss is 3.6895675611495973 and perplexity is 40.02753375342475
At time: 424.7196321487427 and batch: 950, loss is 3.7948094987869263 and perplexity is 44.4697640545603
At time: 425.6816349029541 and batch: 1000, loss is 3.7630824422836304 and perplexity is 43.08101626899051
At time: 426.6699585914612 and batch: 1050, loss is 3.7014694690704344 and perplexity is 40.506784113933186
At time: 427.64128160476685 and batch: 1100, loss is 3.7269947481155397 and perplexity is 41.55403997051867
At time: 428.60780000686646 and batch: 1150, loss is 3.700054235458374 and perplexity is 40.44949809764799
At time: 429.568879365921 and batch: 1200, loss is 3.7665423822402953 and perplexity is 43.23033216160752
At time: 430.5289421081543 and batch: 1250, loss is 3.740039072036743 and perplexity is 42.09963505134976
At time: 431.4894599914551 and batch: 1300, loss is 3.7421954870224 and perplexity is 42.19051728995799
At time: 432.4491832256317 and batch: 1350, loss is 3.624503674507141 and perplexity is 37.506103304021146
At time: 433.40896797180176 and batch: 1400, loss is 3.6555258798599244 and perplexity is 38.6878609334307
At time: 434.36954617500305 and batch: 1450, loss is 3.579508509635925 and perplexity is 35.85591367955751
At time: 435.33042907714844 and batch: 1500, loss is 3.595603280067444 and perplexity is 36.43767548184601
At time: 436.289687871933 and batch: 1550, loss is 3.5999475431442263 and perplexity is 36.5963146657254
At time: 437.24980306625366 and batch: 1600, loss is 3.677975182533264 and perplexity is 39.5661985793784
At time: 438.2364020347595 and batch: 1650, loss is 3.6149955558776856 and perplexity is 37.15118082088796
At time: 439.1964957714081 and batch: 1700, loss is 3.64458146572113 and perplexity is 38.26675355137638
At time: 440.15609216690063 and batch: 1750, loss is 3.6384097385406493 and perplexity is 38.03130888583986
At time: 441.11650133132935 and batch: 1800, loss is 3.5853631019592287 and perplexity is 36.066451140663425
At time: 442.0763900279999 and batch: 1850, loss is 3.6173501873016356 and perplexity is 37.23876122801078
At time: 443.0360195636749 and batch: 1900, loss is 3.697662310600281 and perplexity is 40.352861557396174
At time: 443.9972276687622 and batch: 1950, loss is 3.6302502727508545 and perplexity is 37.72225628873601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.287647336028343 and perplexity of 72.79500469549993
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 447.1556820869446 and batch: 50, loss is 3.788933506011963 and perplexity is 44.209226251035226
At time: 448.13276648521423 and batch: 100, loss is 3.7898670625686646 and perplexity is 44.250517334850734
At time: 449.0918610095978 and batch: 150, loss is 3.7826707887649538 and perplexity is 43.933221539162815
At time: 450.0502920150757 and batch: 200, loss is 3.7790893793106077 and perplexity is 43.7761601027182
At time: 451.0399389266968 and batch: 250, loss is 3.7727172565460205 and perplexity is 43.49809989413521
At time: 452.0003342628479 and batch: 300, loss is 3.785196499824524 and perplexity is 44.04432441049984
At time: 452.9599370956421 and batch: 350, loss is 3.7985138511657714 and perplexity is 44.63480122000763
At time: 453.95019364356995 and batch: 400, loss is 3.7676452827453613 and perplexity is 43.27803721891297
At time: 454.92529296875 and batch: 450, loss is 3.8091557741165163 and perplexity is 45.11233778240068
At time: 455.90212178230286 and batch: 500, loss is 3.8164790630340577 and perplexity is 45.44392112411735
At time: 456.862722158432 and batch: 550, loss is 3.7636438751220704 and perplexity is 43.10521015722345
At time: 457.82485818862915 and batch: 600, loss is 3.74536395072937 and perplexity is 42.324408415342376
At time: 458.7821846008301 and batch: 650, loss is 3.782613549232483 and perplexity is 43.93070689407123
At time: 459.7394919395447 and batch: 700, loss is 3.8042933416366576 and perplexity is 44.893514523726246
At time: 460.69953441619873 and batch: 750, loss is 3.761666483879089 and perplexity is 43.0200585089393
At time: 461.6888334751129 and batch: 800, loss is 3.7399689817428587 and perplexity is 42.09668437896454
At time: 462.66252398490906 and batch: 850, loss is 3.7244457244873046 and perplexity is 41.4482526252861
At time: 463.6385087966919 and batch: 900, loss is 3.685891194343567 and perplexity is 39.88064802535213
At time: 464.61540508270264 and batch: 950, loss is 3.791077766418457 and perplexity is 44.30412405092404
At time: 465.5952353477478 and batch: 1000, loss is 3.7604898500442503 and perplexity is 42.96946942077392
At time: 466.57896733283997 and batch: 1050, loss is 3.70058536529541 and perplexity is 40.470987739370564
At time: 467.5392961502075 and batch: 1100, loss is 3.7217366600036623 and perplexity is 41.336118593930365
At time: 468.50998544692993 and batch: 1150, loss is 3.692951226234436 and perplexity is 40.163202921890814
At time: 469.47013568878174 and batch: 1200, loss is 3.753924388885498 and perplexity is 42.688279120342315
At time: 470.4296872615814 and batch: 1250, loss is 3.730412731170654 and perplexity is 41.696313981578015
At time: 471.39014196395874 and batch: 1300, loss is 3.73403564453125 and perplexity is 41.847650087860025
At time: 472.35088062286377 and batch: 1350, loss is 3.6079345607757567 and perplexity is 36.88978047443017
At time: 473.3161532878876 and batch: 1400, loss is 3.6343938970565794 and perplexity is 37.87888743296086
At time: 474.29838395118713 and batch: 1450, loss is 3.541729907989502 and perplexity is 34.526595392025605
At time: 475.292729139328 and batch: 1500, loss is 3.559083480834961 and perplexity is 35.130984165180735
At time: 476.2529218196869 and batch: 1550, loss is 3.562585072517395 and perplexity is 35.25421415176559
At time: 477.212819814682 and batch: 1600, loss is 3.643076992034912 and perplexity is 38.209225513162146
At time: 478.1956374645233 and batch: 1650, loss is 3.574741644859314 and perplexity is 35.68540011803191
At time: 479.1935510635376 and batch: 1700, loss is 3.5951205682754517 and perplexity is 36.42009083071881
At time: 480.15535950660706 and batch: 1750, loss is 3.586494779586792 and perplexity is 36.107289840287784
At time: 481.11516523361206 and batch: 1800, loss is 3.542517828941345 and perplexity is 34.553810340136735
At time: 482.0949320793152 and batch: 1850, loss is 3.5623371410369873 and perplexity is 35.24547460570939
At time: 483.0872645378113 and batch: 1900, loss is 3.6440635347366332 and perplexity is 38.246939145726266
At time: 484.0691981315613 and batch: 1950, loss is 3.580548448562622 and perplexity is 35.89322103526865
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25963617369186 and perplexity of 70.78422560539263
finished 12 epochs...
Completing Train Step...
At time: 487.2308864593506 and batch: 50, loss is 3.7814132976531982 and perplexity is 43.87801062445914
At time: 488.21037578582764 and batch: 100, loss is 3.7623756313323975 and perplexity is 43.050576893610526
At time: 489.20561265945435 and batch: 150, loss is 3.7438743829727175 and perplexity is 42.26141027289676
At time: 490.1871829032898 and batch: 200, loss is 3.7346064758300783 and perplexity is 41.8715448556044
At time: 491.1626853942871 and batch: 250, loss is 3.7262142372131346 and perplexity is 41.521619243294126
At time: 492.1437168121338 and batch: 300, loss is 3.735717120170593 and perplexity is 41.9180750844115
At time: 493.10388922691345 and batch: 350, loss is 3.7502138662338256 and perplexity is 42.53017679622856
At time: 494.0966606140137 and batch: 400, loss is 3.7189684677124024 and perplexity is 41.22185050008493
At time: 495.0617849826813 and batch: 450, loss is 3.762310891151428 and perplexity is 43.047789881688395
At time: 496.04026079177856 and batch: 500, loss is 3.7713812828063964 and perplexity is 43.44002637593833
At time: 497.02199363708496 and batch: 550, loss is 3.7197734689712525 and perplexity is 41.25504750165094
At time: 498.0062577724457 and batch: 600, loss is 3.7036589097976687 and perplexity is 40.5955684753832
At time: 498.98267364501953 and batch: 650, loss is 3.742680616378784 and perplexity is 42.210990114038836
At time: 499.9706027507782 and batch: 700, loss is 3.76881178855896 and perplexity is 43.32855075737014
At time: 500.93100666999817 and batch: 750, loss is 3.7267039012908936 and perplexity is 41.541955867338736
At time: 501.89089822769165 and batch: 800, loss is 3.7055968379974367 and perplexity is 40.67431605124609
At time: 502.87630915641785 and batch: 850, loss is 3.691519455909729 and perplexity is 40.10573958676756
At time: 503.840824842453 and batch: 900, loss is 3.6539272975921633 and perplexity is 38.62606461137709
At time: 504.84241461753845 and batch: 950, loss is 3.7609596490859984 and perplexity is 42.98966117899518
At time: 505.8021743297577 and batch: 1000, loss is 3.732049503326416 and perplexity is 41.76461723048011
At time: 506.77984619140625 and batch: 1050, loss is 3.6743464136123656 and perplexity is 39.42288217597612
At time: 507.77566027641296 and batch: 1100, loss is 3.6960654926300047 and perplexity is 40.288476801957344
At time: 508.7629795074463 and batch: 1150, loss is 3.669995040893555 and perplexity is 39.25171120640782
At time: 509.72020196914673 and batch: 1200, loss is 3.7325653886795043 and perplexity is 41.786168543312
At time: 510.6804039478302 and batch: 1250, loss is 3.7100540018081665 and perplexity is 40.85601276598312
At time: 511.6412181854248 and batch: 1300, loss is 3.7150153589248656 and perplexity is 41.05921770498967
At time: 512.6010386943817 and batch: 1350, loss is 3.5905621671676635 and perplexity is 36.25445126094839
At time: 513.5610001087189 and batch: 1400, loss is 3.6188668966293336 and perplexity is 37.29528445833702
At time: 514.5231990814209 and batch: 1450, loss is 3.5293693780899047 and perplexity is 34.10245507696889
At time: 515.4832279682159 and batch: 1500, loss is 3.5495346879959104 and perplexity is 34.797122201295636
At time: 516.4439518451691 and batch: 1550, loss is 3.5554380989074708 and perplexity is 35.003151451504145
At time: 517.4128186702728 and batch: 1600, loss is 3.6385209465026858 and perplexity is 38.035538505373964
At time: 518.3762536048889 and batch: 1650, loss is 3.572086501121521 and perplexity is 35.590775927381536
At time: 519.3373303413391 and batch: 1700, loss is 3.5945972871780394 and perplexity is 36.401037871082636
At time: 520.2972877025604 and batch: 1750, loss is 3.587299494743347 and perplexity is 36.136357617756325
At time: 521.2575678825378 and batch: 1800, loss is 3.5455805683135986 and perplexity is 34.65980188491217
At time: 522.2192599773407 and batch: 1850, loss is 3.5663676261901855 and perplexity is 35.38781763085532
At time: 523.1798379421234 and batch: 1900, loss is 3.649045367240906 and perplexity is 38.43795439828675
At time: 524.1404957771301 and batch: 1950, loss is 3.5855284404754637 and perplexity is 36.072414807179186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259434047965116 and perplexity of 70.76991973819072
finished 13 epochs...
Completing Train Step...
At time: 527.3504807949066 and batch: 50, loss is 3.7645567798614503 and perplexity is 43.14457907516969
At time: 528.3386948108673 and batch: 100, loss is 3.7438746595382693 and perplexity is 42.26142196094863
At time: 529.3441545963287 and batch: 150, loss is 3.7242954778671264 and perplexity is 41.44202563322084
At time: 530.3042395114899 and batch: 200, loss is 3.7140439796447753 and perplexity is 41.019352996664786
At time: 531.2655444145203 and batch: 250, loss is 3.7048956394195556 and perplexity is 40.64580527570048
At time: 532.2262032032013 and batch: 300, loss is 3.7145168113708498 and perplexity is 41.03875283421256
At time: 533.2152323722839 and batch: 350, loss is 3.7286311197280884 and perplexity is 41.622093487148874
At time: 534.173220872879 and batch: 400, loss is 3.6976198673248293 and perplexity is 40.35114888612378
At time: 535.1321215629578 and batch: 450, loss is 3.741563014984131 and perplexity is 42.163841404257134
At time: 536.0922014713287 and batch: 500, loss is 3.7512052154541013 and perplexity is 42.572359959501995
At time: 537.0705049037933 and batch: 550, loss is 3.6998129653930665 and perplexity is 40.43974002181345
At time: 538.0310335159302 and batch: 600, loss is 3.684355072975159 and perplexity is 39.819433538212465
At time: 538.9913880825043 and batch: 650, loss is 3.723550629615784 and perplexity is 41.41116910603759
At time: 539.9526968002319 and batch: 700, loss is 3.7508532857894896 and perplexity is 42.55738011921941
At time: 540.913428068161 and batch: 750, loss is 3.7091719627380373 and perplexity is 40.81999205464651
At time: 541.8739800453186 and batch: 800, loss is 3.688179602622986 and perplexity is 39.97201573391936
At time: 542.8336362838745 and batch: 850, loss is 3.67448052406311 and perplexity is 39.42816955101259
At time: 543.7940101623535 and batch: 900, loss is 3.6374603843688966 and perplexity is 37.99522083697218
At time: 544.7540767192841 and batch: 950, loss is 3.745404672622681 and perplexity is 42.32613198047949
At time: 545.7135272026062 and batch: 1000, loss is 3.7171572637557984 and perplexity is 41.14725689386977
At time: 546.6756784915924 and batch: 1050, loss is 3.660671992301941 and perplexity is 38.88746617093015
At time: 547.6503188610077 and batch: 1100, loss is 3.6823606443405152 and perplexity is 39.74009566291254
At time: 548.6249763965607 and batch: 1150, loss is 3.6571406888961793 and perplexity is 38.75038490941357
At time: 549.5846872329712 and batch: 1200, loss is 3.7203191089630128 and perplexity is 41.27756404783521
At time: 550.5442645549774 and batch: 1250, loss is 3.6987345838546752 and perplexity is 40.39615405812974
At time: 551.5034449100494 and batch: 1300, loss is 3.703762993812561 and perplexity is 40.59979404504027
At time: 552.4612400531769 and batch: 1350, loss is 3.5799449777603147 and perplexity is 35.87156705880154
At time: 553.4206042289734 and batch: 1400, loss is 3.6088349437713623 and perplexity is 36.92301036304937
At time: 554.3804445266724 and batch: 1450, loss is 3.520374779701233 and perplexity is 33.79709255482944
At time: 555.3374938964844 and batch: 1500, loss is 3.5415518426895143 and perplexity is 34.5204479507988
At time: 556.2959213256836 and batch: 1550, loss is 3.548208613395691 and perplexity is 34.75100920277917
At time: 557.2562956809998 and batch: 1600, loss is 3.632737169265747 and perplexity is 37.81618438274978
At time: 558.2177181243896 and batch: 1650, loss is 3.567024908065796 and perplexity is 35.411085047789534
At time: 559.1888432502747 and batch: 1700, loss is 3.5905799579620363 and perplexity is 36.255096262173396
At time: 560.1630418300629 and batch: 1750, loss is 3.5835049533843994 and perplexity is 35.999496540938885
At time: 561.1421744823456 and batch: 1800, loss is 3.5433025217056273 and perplexity is 34.58093510600095
At time: 562.1106204986572 and batch: 1850, loss is 3.5643122720718385 and perplexity is 35.315157830537494
At time: 563.0777235031128 and batch: 1900, loss is 3.6475183820724486 and perplexity is 38.37930500179001
At time: 564.0465998649597 and batch: 1950, loss is 3.5836882066726683 and perplexity is 36.00609417155632
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260788176780523 and perplexity of 70.86581623922643
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 567.1999244689941 and batch: 50, loss is 3.7611203622817992 and perplexity is 42.996570740043595
At time: 568.1599171161652 and batch: 100, loss is 3.75522798538208 and perplexity is 42.743963698673625
At time: 569.1212515830994 and batch: 150, loss is 3.745928463935852 and perplexity is 42.34830784798737
At time: 570.0811967849731 and batch: 200, loss is 3.7444370222091674 and perplexity is 42.285194890956234
At time: 571.0416367053986 and batch: 250, loss is 3.7379457998275756 and perplexity is 42.01160122680533
At time: 572.0057179927826 and batch: 300, loss is 3.7430800580978394 and perplexity is 42.227854312400986
At time: 572.9658570289612 and batch: 350, loss is 3.7613166332244874 and perplexity is 43.00501054573231
At time: 573.9236030578613 and batch: 400, loss is 3.7342571878433226 and perplexity is 41.85692218191023
At time: 574.8807544708252 and batch: 450, loss is 3.781579403877258 and perplexity is 43.885299640481925
At time: 575.8395643234253 and batch: 500, loss is 3.7904539775848387 and perplexity is 44.276496250910256
At time: 576.8252093791962 and batch: 550, loss is 3.7450516176223756 and perplexity is 42.3111911655601
At time: 577.7830770015717 and batch: 600, loss is 3.720094017982483 and perplexity is 41.26827388607484
At time: 578.7403585910797 and batch: 650, loss is 3.75102587223053 and perplexity is 42.564725579839404
At time: 579.7257282733917 and batch: 700, loss is 3.7719350624084473 and perplexity is 43.46408923860418
At time: 580.6861851215363 and batch: 750, loss is 3.730398564338684 and perplexity is 41.69572328108825
At time: 581.6438767910004 and batch: 800, loss is 3.7103611421585083 and perplexity is 40.8685632233349
At time: 582.6005306243896 and batch: 850, loss is 3.6981391859054566 and perplexity is 40.37210942961878
At time: 583.5877869129181 and batch: 900, loss is 3.6552374172210693 and perplexity is 38.6767025404413
At time: 584.5555284023285 and batch: 950, loss is 3.763412070274353 and perplexity is 43.0952193185543
At time: 585.5764336585999 and batch: 1000, loss is 3.7341827821731566 and perplexity is 41.85380790542555
At time: 586.541383266449 and batch: 1050, loss is 3.67761004447937 and perplexity is 39.55175409190565
At time: 587.5059826374054 and batch: 1100, loss is 3.6926089191436766 and perplexity is 40.14945712551905
At time: 588.4722216129303 and batch: 1150, loss is 3.663722734451294 and perplexity is 39.00628295058565
At time: 589.4505858421326 and batch: 1200, loss is 3.7228479480743406 and perplexity is 41.38208046312032
At time: 590.4492084980011 and batch: 1250, loss is 3.702389807701111 and perplexity is 40.544081232514614
At time: 591.4313652515411 and batch: 1300, loss is 3.70946093082428 and perplexity is 40.83178943408197
At time: 592.3965017795563 and batch: 1350, loss is 3.5846902036666872 and perplexity is 36.04219025074397
At time: 593.3530857563019 and batch: 1400, loss is 3.614137773513794 and perplexity is 37.119326857019416
At time: 594.3105301856995 and batch: 1450, loss is 3.519650921821594 and perplexity is 33.77263711527389
At time: 595.2627289295197 and batch: 1500, loss is 3.532300519943237 and perplexity is 34.20256085078575
At time: 596.2389752864838 and batch: 1550, loss is 3.5386961030960085 and perplexity is 34.42200716832096
At time: 597.1960341930389 and batch: 1600, loss is 3.626342396736145 and perplexity is 37.57513005094885
At time: 598.1819016933441 and batch: 1650, loss is 3.5589193391799925 and perplexity is 35.12521818053127
At time: 599.1386795043945 and batch: 1700, loss is 3.583908619880676 and perplexity is 36.01403126496849
At time: 600.0961365699768 and batch: 1750, loss is 3.5731017875671385 and perplexity is 35.62692910958197
At time: 601.0537073612213 and batch: 1800, loss is 3.533987183570862 and perplexity is 34.26029774381546
At time: 602.0099401473999 and batch: 1850, loss is 3.5484690713882445 and perplexity is 34.76006155970352
At time: 602.9630861282349 and batch: 1900, loss is 3.6311713314056395 and perplexity is 37.75701670510253
At time: 603.9163188934326 and batch: 1950, loss is 3.573689408302307 and perplexity is 35.6478703840181
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247765545512355 and perplexity of 69.94893987387391
finished 15 epochs...
Completing Train Step...
At time: 607.0495719909668 and batch: 50, loss is 3.7669244956970216 and perplexity is 43.246854209712644
At time: 608.0269737243652 and batch: 100, loss is 3.7495796728134154 and perplexity is 42.50321298897383
At time: 608.988009929657 and batch: 150, loss is 3.732161741256714 and perplexity is 41.7693050677494
At time: 609.9638860225677 and batch: 200, loss is 3.7268453550338747 and perplexity is 41.547832548116375
At time: 610.9237542152405 and batch: 250, loss is 3.719150767326355 and perplexity is 41.22936591252508
At time: 611.8836076259613 and batch: 300, loss is 3.721351580619812 and perplexity is 41.320203971244666
At time: 612.8433222770691 and batch: 350, loss is 3.7368504428863525 and perplexity is 41.96560872149313
At time: 613.8031706809998 and batch: 400, loss is 3.708140640258789 and perplexity is 40.77791518038046
At time: 614.7634928226471 and batch: 450, loss is 3.756821885108948 and perplexity is 42.81214761546617
At time: 615.7248337268829 and batch: 500, loss is 3.7659419298172 and perplexity is 43.20438219554954
At time: 616.6833930015564 and batch: 550, loss is 3.7208600568771364 and perplexity is 41.29989910051242
At time: 617.6419866085052 and batch: 600, loss is 3.6982716035842897 and perplexity is 40.37745576460587
At time: 618.6000442504883 and batch: 650, loss is 3.730788073539734 and perplexity is 41.71196731234511
At time: 619.5576756000519 and batch: 700, loss is 3.7545595932006837 and perplexity is 42.71540351330111
At time: 620.5170435905457 and batch: 750, loss is 3.714134206771851 and perplexity is 41.02305422201312
At time: 621.4778842926025 and batch: 800, loss is 3.693674464225769 and perplexity is 40.19226098277772
At time: 622.4730136394501 and batch: 850, loss is 3.6825406312942506 and perplexity is 39.74724900540691
At time: 623.4477307796478 and batch: 900, loss is 3.6407883882522585 and perplexity is 38.12187972319742
At time: 624.4085865020752 and batch: 950, loss is 3.749219617843628 and perplexity is 42.48791225062395
At time: 625.3692715167999 and batch: 1000, loss is 3.720139226913452 and perplexity is 41.27013962279383
At time: 626.3486335277557 and batch: 1050, loss is 3.664492607116699 and perplexity is 39.036324384163834
At time: 627.3427400588989 and batch: 1100, loss is 3.6809196710586547 and perplexity is 39.68287248528027
At time: 628.3017134666443 and batch: 1150, loss is 3.654145941734314 and perplexity is 38.63451089747054
At time: 629.2620313167572 and batch: 1200, loss is 3.714467453956604 and perplexity is 41.03672731747633
At time: 630.2230045795441 and batch: 1250, loss is 3.695398964881897 and perplexity is 40.261632361515886
At time: 631.1825988292694 and batch: 1300, loss is 3.703115301132202 and perplexity is 40.57350636969966
At time: 632.1613981723785 and batch: 1350, loss is 3.5792999362945555 and perplexity is 35.848435871696296
At time: 633.1600985527039 and batch: 1400, loss is 3.610435242652893 and perplexity is 36.98214551957833
At time: 634.1207230091095 and batch: 1450, loss is 3.5169811248779297 and perplexity is 33.682591287447835
At time: 635.1112124919891 and batch: 1500, loss is 3.5322056198120118 and perplexity is 34.19931517728262
At time: 636.0721709728241 and batch: 1550, loss is 3.5398647785186768 and perplexity is 34.46225883808475
At time: 637.0314190387726 and batch: 1600, loss is 3.628745427131653 and perplexity is 37.66553280735922
At time: 638.016300201416 and batch: 1650, loss is 3.5624260091781617 and perplexity is 35.24860694470292
At time: 638.9784586429596 and batch: 1700, loss is 3.5879494667053224 and perplexity is 36.15985287181682
At time: 639.9401950836182 and batch: 1750, loss is 3.5780095291137695 and perplexity is 35.8022066263175
At time: 640.9011409282684 and batch: 1800, loss is 3.539858994483948 and perplexity is 34.462059507759264
At time: 641.8613765239716 and batch: 1850, loss is 3.5541168308258055 and perplexity is 34.95693344464596
At time: 642.8216004371643 and batch: 1900, loss is 3.637316470146179 and perplexity is 37.98975317774485
At time: 643.7934274673462 and batch: 1950, loss is 3.578835048675537 and perplexity is 35.83177425088906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2465723791787795 and perplexity of 69.86552892521067
finished 16 epochs...
Completing Train Step...
At time: 646.9741339683533 and batch: 50, loss is 3.7630498933792116 and perplexity is 43.07961405193014
At time: 647.9582073688507 and batch: 100, loss is 3.743725800514221 and perplexity is 42.255131435133016
At time: 648.9178771972656 and batch: 150, loss is 3.725258479118347 and perplexity is 41.48195357800346
At time: 649.8771281242371 and batch: 200, loss is 3.718822088241577 and perplexity is 41.21581690902999
At time: 650.8349361419678 and batch: 250, loss is 3.7105791187286377 and perplexity is 40.87747258355306
At time: 651.7920289039612 and batch: 300, loss is 3.7122823286056517 and perplexity is 40.94715482349916
At time: 652.7529249191284 and batch: 350, loss is 3.727458395957947 and perplexity is 41.57331087860656
At time: 653.7122488021851 and batch: 400, loss is 3.698321990966797 and perplexity is 40.37949033017193
At time: 654.6725015640259 and batch: 450, loss is 3.747041816711426 and perplexity is 42.39548271032976
At time: 655.637989282608 and batch: 500, loss is 3.756401195526123 and perplexity is 42.79414077885585
At time: 656.5981678962708 and batch: 550, loss is 3.7113422918319703 and perplexity is 40.90868107838823
At time: 657.5873472690582 and batch: 600, loss is 3.6894443702697752 and perplexity is 40.02260303004087
At time: 658.5596613883972 and batch: 650, loss is 3.722257905006409 and perplexity is 41.35767045559252
At time: 659.5201098918915 and batch: 700, loss is 3.7467561960220337 and perplexity is 42.383375412460616
At time: 660.4924609661102 and batch: 750, loss is 3.7069675445556642 and perplexity is 40.730106830667424
At time: 661.450439453125 and batch: 800, loss is 3.686439833641052 and perplexity is 39.90253411930464
At time: 662.4071691036224 and batch: 850, loss is 3.6755844593048095 and perplexity is 39.47171973076197
At time: 663.3665177822113 and batch: 900, loss is 3.6343616247177124 and perplexity is 37.877665012395006
At time: 664.3265931606293 and batch: 950, loss is 3.7430953073501585 and perplexity is 42.22849826051614
At time: 665.2875275611877 and batch: 1000, loss is 3.7141349267959596 and perplexity is 41.023083759611815
At time: 666.2469220161438 and batch: 1050, loss is 3.6590085315704344 and perplexity is 38.822832170971516
At time: 667.2152001857758 and batch: 1100, loss is 3.6758049297332764 and perplexity is 39.480423037098916
At time: 668.204503774643 and batch: 1150, loss is 3.6497426652908325 and perplexity is 38.464766455843176
At time: 669.196789264679 and batch: 1200, loss is 3.7103912115097044 and perplexity is 40.86979213299151
At time: 670.1572868824005 and batch: 1250, loss is 3.691803321838379 and perplexity is 40.11712585578999
At time: 671.1169011592865 and batch: 1300, loss is 3.699702515602112 and perplexity is 40.43527370763806
At time: 672.0939395427704 and batch: 1350, loss is 3.57647958278656 and perplexity is 35.74747305217534
At time: 673.0632400512695 and batch: 1400, loss is 3.608100748062134 and perplexity is 36.89591159638542
At time: 674.0475900173187 and batch: 1450, loss is 3.515153851509094 and perplexity is 33.62110018303319
At time: 675.0446906089783 and batch: 1500, loss is 3.531373677253723 and perplexity is 34.17087514339994
At time: 676.0267677307129 and batch: 1550, loss is 3.539430088996887 and perplexity is 34.44728171070663
At time: 677.0162103176117 and batch: 1600, loss is 3.6288985776901246 and perplexity is 37.67130174649065
At time: 678.0015609264374 and batch: 1650, loss is 3.5628307390213014 and perplexity is 35.262875995223055
At time: 678.9896998405457 and batch: 1700, loss is 3.5885980415344236 and perplexity is 36.18331284916651
At time: 679.9559669494629 and batch: 1750, loss is 3.5789800834655763 and perplexity is 35.83697148162479
At time: 680.9136474132538 and batch: 1800, loss is 3.5411873149871824 and perplexity is 34.50786658449142
At time: 681.8717324733734 and batch: 1850, loss is 3.5552700424194335 and perplexity is 34.99726943906999
At time: 682.8523540496826 and batch: 1900, loss is 3.6387275505065917 and perplexity is 38.043397611753356
At time: 683.8164865970612 and batch: 1950, loss is 3.5796982049942017 and perplexity is 35.862716025115574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246475006813227 and perplexity of 69.8587262845886
finished 17 epochs...
Completing Train Step...
At time: 686.9887597560883 and batch: 50, loss is 3.7584647369384765 and perplexity is 42.88253943633607
At time: 687.9758625030518 and batch: 100, loss is 3.7383557605743407 and perplexity is 42.02882786509855
At time: 688.9371993541718 and batch: 150, loss is 3.719529643058777 and perplexity is 41.24498967827844
At time: 689.897707939148 and batch: 200, loss is 3.712664246559143 and perplexity is 40.96279626375395
At time: 690.8581824302673 and batch: 250, loss is 3.704124903678894 and perplexity is 40.61449017025221
At time: 691.8179552555084 and batch: 300, loss is 3.705726480484009 and perplexity is 40.67958951254352
At time: 692.7877202033997 and batch: 350, loss is 3.7208293962478636 and perplexity is 41.29863283902938
At time: 693.7659859657288 and batch: 400, loss is 3.6916046142578125 and perplexity is 40.109155070725855
At time: 694.7371120452881 and batch: 450, loss is 3.7403830909729003 and perplexity is 42.114120614523884
At time: 695.6997230052948 and batch: 500, loss is 3.7499335908889773 and perplexity is 42.51825830656796
At time: 696.6598529815674 and batch: 550, loss is 3.704846296310425 and perplexity is 40.64379973477528
At time: 697.619909286499 and batch: 600, loss is 3.683334527015686 and perplexity is 39.7788167054041
At time: 698.5780098438263 and batch: 650, loss is 3.7162421321868897 and perplexity is 41.10961896456755
At time: 699.5356073379517 and batch: 700, loss is 3.741165509223938 and perplexity is 42.14708436515752
At time: 700.5194790363312 and batch: 750, loss is 3.7017831420898437 and perplexity is 40.519491992167836
At time: 701.5036108493805 and batch: 800, loss is 3.6812573194503786 and perplexity is 39.69627360565997
At time: 702.4707744121552 and batch: 850, loss is 3.670555663108826 and perplexity is 39.2737227572032
At time: 703.460161447525 and batch: 900, loss is 3.6296434450149535 and perplexity is 37.699372321374526
At time: 704.4181885719299 and batch: 950, loss is 3.7386436557769773 and perplexity is 42.04092950493179
At time: 705.3772447109222 and batch: 1000, loss is 3.70977725982666 and perplexity is 40.84470775641134
At time: 706.3794112205505 and batch: 1050, loss is 3.6549962615966796 and perplexity is 38.66737656064226
At time: 707.3653297424316 and batch: 1100, loss is 3.6719176959991455 and perplexity is 39.32725130486984
At time: 708.3337821960449 and batch: 1150, loss is 3.6462746477127075 and perplexity is 38.331601013150525
At time: 709.3010106086731 and batch: 1200, loss is 3.707107591629028 and perplexity is 40.73581136236902
At time: 710.280677318573 and batch: 1250, loss is 3.688825836181641 and perplexity is 39.99785534020481
At time: 711.2720115184784 and batch: 1300, loss is 3.696750588417053 and perplexity is 40.31608772466442
At time: 712.2565062046051 and batch: 1350, loss is 3.5739290857315065 and perplexity is 35.65641539793076
At time: 713.2169392108917 and batch: 1400, loss is 3.605818543434143 and perplexity is 36.81180358853468
At time: 714.1767141819 and batch: 1450, loss is 3.513148937225342 and perplexity is 33.5537602869576
At time: 715.1359326839447 and batch: 1500, loss is 3.5299638509750366 and perplexity is 34.12273408889272
At time: 716.09738945961 and batch: 1550, loss is 3.5382062578201294 and perplexity is 34.40514983980172
At time: 717.0794215202332 and batch: 1600, loss is 3.628049178123474 and perplexity is 37.63931734480349
At time: 718.0442588329315 and batch: 1650, loss is 3.5620859050750733 and perplexity is 35.23662078723908
At time: 719.0295321941376 and batch: 1700, loss is 3.5880590963363646 and perplexity is 36.16381728045005
At time: 719.9909493923187 and batch: 1750, loss is 3.578649435043335 and perplexity is 35.825124002329595
At time: 720.9522833824158 and batch: 1800, loss is 3.5411133050918577 and perplexity is 34.5053127554031
At time: 721.9129667282104 and batch: 1850, loss is 3.5550758695602416 and perplexity is 34.99047457890916
At time: 722.8741700649261 and batch: 1900, loss is 3.6387924432754515 and perplexity is 38.045866433264685
At time: 723.8325614929199 and batch: 1950, loss is 3.5793986320495605 and perplexity is 35.8519741347433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246712334211483 and perplexity of 69.87530764187059
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 726.9759862422943 and batch: 50, loss is 3.758200235366821 and perplexity is 42.87119843718075
At time: 727.940948009491 and batch: 100, loss is 3.7440808629989624 and perplexity is 42.270137310947575
At time: 728.9019734859467 and batch: 150, loss is 3.7296557521820066 and perplexity is 41.66476269132842
At time: 729.8631110191345 and batch: 200, loss is 3.726162147521973 and perplexity is 41.51945645130128
At time: 730.8481602668762 and batch: 250, loss is 3.7193492460250854 and perplexity is 41.237549875565186
At time: 731.8076906204224 and batch: 300, loss is 3.7186520719528198 and perplexity is 41.208810144449956
At time: 732.7684962749481 and batch: 350, loss is 3.7337778282165526 and perplexity is 41.836862471607105
At time: 733.728360414505 and batch: 400, loss is 3.7051074647903444 and perplexity is 40.65441600042679
At time: 734.6881899833679 and batch: 450, loss is 3.754551076889038 and perplexity is 42.71503973716174
At time: 735.6493258476257 and batch: 500, loss is 3.763081669807434 and perplexity is 43.080982989943784
At time: 736.6094753742218 and batch: 550, loss is 3.720387964248657 and perplexity is 41.28040632415017
At time: 737.5697245597839 and batch: 600, loss is 3.6972805738449095 and perplexity is 40.33746032675024
At time: 738.5298538208008 and batch: 650, loss is 3.7278401279449462 and perplexity is 41.589183770576945
At time: 739.4908726215363 and batch: 700, loss is 3.753681516647339 and perplexity is 42.67791258137242
At time: 740.4522953033447 and batch: 750, loss is 3.713838806152344 and perplexity is 41.01093777607281
At time: 741.4122803211212 and batch: 800, loss is 3.6924378061294556 and perplexity is 40.14258761863874
At time: 742.3732216358185 and batch: 850, loss is 3.681149220466614 and perplexity is 39.69198271074882
At time: 743.3641188144684 and batch: 900, loss is 3.6392148876190187 and perplexity is 38.06194208963151
At time: 744.3478388786316 and batch: 950, loss is 3.7505249881744387 and perplexity is 42.54341092597534
At time: 745.3124439716339 and batch: 1000, loss is 3.721604061126709 and perplexity is 41.33063783440652
At time: 746.2688052654266 and batch: 1050, loss is 3.6674623537063598 and perplexity is 39.1524246842839
At time: 747.2235381603241 and batch: 1100, loss is 3.680544624328613 and perplexity is 39.66799234426454
At time: 748.183844089508 and batch: 1150, loss is 3.651603240966797 and perplexity is 38.53639968354845
At time: 749.148161649704 and batch: 1200, loss is 3.7094190979003905 and perplexity is 40.83008135666949
At time: 750.1092600822449 and batch: 1250, loss is 3.6864083909988405 and perplexity is 39.901279497925394
At time: 751.0692176818848 and batch: 1300, loss is 3.6918217611312865 and perplexity is 40.11786559404437
At time: 752.0296211242676 and batch: 1350, loss is 3.5702285146713257 and perplexity is 35.524710141629456
At time: 752.989887714386 and batch: 1400, loss is 3.602383503913879 and perplexity is 36.68557052030879
At time: 753.9683933258057 and batch: 1450, loss is 3.5102000427246094 and perplexity is 33.454959535861704
At time: 754.9467825889587 and batch: 1500, loss is 3.5239222383499147 and perplexity is 33.91719925393112
At time: 755.9292595386505 and batch: 1550, loss is 3.5306921672821043 and perplexity is 34.147595284879664
At time: 756.9155421257019 and batch: 1600, loss is 3.6203511428833006 and perplexity is 37.35068094542936
At time: 757.8925306797028 and batch: 1650, loss is 3.5528650760650633 and perplexity is 34.913203312196444
At time: 758.8569672107697 and batch: 1700, loss is 3.5772305631637575 and perplexity is 35.77432878577424
At time: 759.8177919387817 and batch: 1750, loss is 3.568984618186951 and perplexity is 35.4805485514934
At time: 760.7786419391632 and batch: 1800, loss is 3.530680384635925 and perplexity is 34.14719293821691
At time: 761.7661719322205 and batch: 1850, loss is 3.54293221950531 and perplexity is 34.568132080282766
At time: 762.7271647453308 and batch: 1900, loss is 3.628824381828308 and perplexity is 37.66850679547999
At time: 763.6881587505341 and batch: 1950, loss is 3.5710973596572875 and perplexity is 35.55558902045076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244361203215843 and perplexity of 69.71121461793095
finished 19 epochs...
Completing Train Step...
At time: 766.858184337616 and batch: 50, loss is 3.758193254470825 and perplexity is 42.870899158847855
At time: 767.8201205730438 and batch: 100, loss is 3.7408223390579223 and perplexity is 42.13262322467675
At time: 768.7784507274628 and batch: 150, loss is 3.723081045150757 and perplexity is 41.39172762941175
At time: 769.7345247268677 and batch: 200, loss is 3.7190848112106325 and perplexity is 41.22664667337201
At time: 770.6902179718018 and batch: 250, loss is 3.7116920375823974 and perplexity is 40.922991218060375
At time: 771.6458570957184 and batch: 300, loss is 3.710528655052185 and perplexity is 40.875409808050456
At time: 772.6021571159363 and batch: 350, loss is 3.7253805875778196 and perplexity is 41.48701918472121
At time: 773.5577104091644 and batch: 400, loss is 3.6973584699630737 and perplexity is 40.340602580709394
At time: 774.5132582187653 and batch: 450, loss is 3.7470257806777956 and perplexity is 42.39480286039431
At time: 775.469274520874 and batch: 500, loss is 3.7552386283874513 and perplexity is 42.74441862532974
At time: 776.4252188205719 and batch: 550, loss is 3.7125474548339845 and perplexity is 40.95801242747267
At time: 777.3810946941376 and batch: 600, loss is 3.6898711109161377 and perplexity is 40.039685946255126
At time: 778.3575668334961 and batch: 650, loss is 3.720451989173889 and perplexity is 41.28304938368857
At time: 779.3130104541779 and batch: 700, loss is 3.746935496330261 and perplexity is 42.390975446059606
At time: 780.2698211669922 and batch: 750, loss is 3.7070578718185425 and perplexity is 40.73378603589794
At time: 781.2246794700623 and batch: 800, loss is 3.6857264757156374 and perplexity is 39.874079480724134
At time: 782.1843321323395 and batch: 850, loss is 3.674560613632202 and perplexity is 39.43132746257821
At time: 783.1399047374725 and batch: 900, loss is 3.6330880165100097 and perplexity is 37.82945441456993
At time: 784.0954523086548 and batch: 950, loss is 3.7440416765213014 and perplexity is 42.26848092561028
At time: 785.0531668663025 and batch: 1000, loss is 3.7151848030090333 and perplexity is 41.06617553599534
At time: 786.0093932151794 and batch: 1050, loss is 3.6610679531097414 and perplexity is 38.90286713233585
At time: 786.969003200531 and batch: 1100, loss is 3.6751278495788573 and perplexity is 39.45370067378425
At time: 787.9565048217773 and batch: 1150, loss is 3.64740216255188 and perplexity is 38.3748448365471
At time: 788.9107789993286 and batch: 1200, loss is 3.7060837364196777 and perplexity is 40.694125133671314
At time: 789.8651704788208 and batch: 1250, loss is 3.6843008852005004 and perplexity is 39.81727587018101
At time: 790.823121547699 and batch: 1300, loss is 3.690379614830017 and perplexity is 40.06005146080239
At time: 791.7808427810669 and batch: 1350, loss is 3.5691143703460693 and perplexity is 35.48515252795614
At time: 792.7419571876526 and batch: 1400, loss is 3.6020230531692503 and perplexity is 36.67234956199289
At time: 793.7042465209961 and batch: 1450, loss is 3.5103302431106567 and perplexity is 33.45931566808736
At time: 794.6623933315277 and batch: 1500, loss is 3.525157823562622 and perplexity is 33.95913274465137
At time: 795.6199948787689 and batch: 1550, loss is 3.5326534509658813 and perplexity is 34.21463412595522
At time: 796.5830178260803 and batch: 1600, loss is 3.623290848731995 and perplexity is 37.46064250879337
At time: 797.5438723564148 and batch: 1650, loss is 3.556222710609436 and perplexity is 35.03062611079878
At time: 798.502932548523 and batch: 1700, loss is 3.5815751361846924 and perplexity is 35.930091084794846
At time: 799.4617605209351 and batch: 1750, loss is 3.5734255743026733 and perplexity is 35.6384665043824
At time: 800.4224128723145 and batch: 1800, loss is 3.535119204521179 and perplexity is 34.29910307870761
At time: 801.3813025951385 and batch: 1850, loss is 3.54690110206604 and perplexity is 34.70560155650474
At time: 802.3417074680328 and batch: 1900, loss is 3.633011860847473 and perplexity is 37.82657359710226
At time: 803.3043706417084 and batch: 1950, loss is 3.5741951990127565 and perplexity is 35.66590530626923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243636162336482 and perplexity of 69.66068945620029
Finished Training.
Improved accuracyfrom -10000000 to -69.66068945620029
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
836.0587079524994


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5827438831329346 and batch: 50, loss is 7.6597620964050295 and perplexity is 2121.252714897536
At time: 2.706023931503296 and batch: 100, loss is 6.853867254257202 and perplexity is 947.5382014124218
At time: 3.8281092643737793 and batch: 150, loss is 6.513574209213257 and perplexity is 674.2319621614441
At time: 4.949749708175659 and batch: 200, loss is 6.3804230213165285 and perplexity is 590.1773124443695
At time: 6.072897434234619 and batch: 250, loss is 6.301138830184937 and perplexity is 545.1924383261062
At time: 7.197100877761841 and batch: 300, loss is 6.208945779800415 and perplexity is 497.17684104484516
At time: 8.321278095245361 and batch: 350, loss is 6.127023839950562 and perplexity is 458.07083785066294
At time: 9.446738004684448 and batch: 400, loss is 6.05949893951416 and perplexity is 428.16084862010564
At time: 10.569582223892212 and batch: 450, loss is 5.961047096252441 and perplexity is 388.01620191038336
At time: 11.691926717758179 and batch: 500, loss is 5.925334005355835 and perplexity is 374.4034672417525
At time: 12.814215183258057 and batch: 550, loss is 5.86847806930542 and perplexity is 353.71024793179885
At time: 13.936740159988403 and batch: 600, loss is 5.889456920623779 and perplexity is 361.2090659018111
At time: 15.06979513168335 and batch: 650, loss is 5.942240991592407 and perplexity is 380.78731525878896
At time: 16.19333028793335 and batch: 700, loss is 5.84504096031189 and perplexity is 345.5166939627877
At time: 17.317229509353638 and batch: 750, loss is 5.773220453262329 and perplexity is 321.57167341951595
At time: 18.44023561477661 and batch: 800, loss is 5.767854843139649 and perplexity is 319.8508659130062
At time: 19.565007209777832 and batch: 850, loss is 5.783786468505859 and perplexity is 324.9874182507849
At time: 20.705072164535522 and batch: 900, loss is 5.757849025726318 and perplexity is 316.66645443668756
At time: 21.829057931900024 and batch: 950, loss is 5.786139297485351 and perplexity is 325.75295830567217
At time: 22.95584774017334 and batch: 1000, loss is 5.754479818344116 and perplexity is 315.60133479275106
At time: 24.079553604125977 and batch: 1050, loss is 5.642867736816406 and perplexity is 282.2710379452867
At time: 25.208293676376343 and batch: 1100, loss is 5.71761908531189 and perplexity is 304.1798338775124
At time: 26.338491439819336 and batch: 1150, loss is 5.619945640563965 and perplexity is 275.8743864511137
At time: 27.463905572891235 and batch: 1200, loss is 5.697512903213501 and perplexity is 298.12501239332346
At time: 28.586593866348267 and batch: 1250, loss is 5.625527381896973 and perplexity is 277.4185514724042
At time: 29.71235203742981 and batch: 1300, loss is 5.640645589828491 and perplexity is 281.6444866109438
At time: 30.84215545654297 and batch: 1350, loss is 5.597576780319214 and perplexity is 269.7718981636092
At time: 31.980034589767456 and batch: 1400, loss is 5.615622549057007 and perplexity is 274.684330447984
At time: 33.112475872039795 and batch: 1450, loss is 5.58657751083374 and perplexity is 266.82086371990533
At time: 34.23693895339966 and batch: 1500, loss is 5.55190224647522 and perplexity is 257.72735084744613
At time: 35.36336159706116 and batch: 1550, loss is 5.520806741714478 and perplexity is 249.8365094446991
At time: 36.48995232582092 and batch: 1600, loss is 5.5436085510253905 and perplexity is 255.59867817364386
At time: 37.61415338516235 and batch: 1650, loss is 5.527647094726563 and perplexity is 251.55133769343885
At time: 38.73634386062622 and batch: 1700, loss is 5.5470333003997805 and perplexity is 256.47554024617835
At time: 39.8578782081604 and batch: 1750, loss is 5.550563879013062 and perplexity is 257.3826476681768
At time: 40.9797306060791 and batch: 1800, loss is 5.537594909667969 and perplexity is 254.06621186139844
At time: 42.10383105278015 and batch: 1850, loss is 5.506826438903809 and perplexity is 246.36802114038804
At time: 43.228416204452515 and batch: 1900, loss is 5.51950008392334 and perplexity is 249.51027181001305
At time: 44.349971294403076 and batch: 1950, loss is 5.448767395019531 and perplexity is 232.47144377698436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.94931754178779 and perplexity of 141.07865077657672
finished 1 epochs...
Completing Train Step...
At time: 47.534738302230835 and batch: 50, loss is 5.20397102355957 and perplexity is 181.99350935560537
At time: 48.49528384208679 and batch: 100, loss is 5.121159963607788 and perplexity is 167.52958517987372
At time: 49.45393466949463 and batch: 150, loss is 5.033672990798951 and perplexity is 153.49576710731964
At time: 50.410983085632324 and batch: 200, loss is 4.999018239974975 and perplexity is 148.26752449659682
At time: 51.39072608947754 and batch: 250, loss is 5.011378555297852 and perplexity is 150.11153062329748
At time: 52.34870004653931 and batch: 300, loss is 5.010241327285766 and perplexity is 149.94091661763662
At time: 53.32408809661865 and batch: 350, loss is 5.003817825317383 and perplexity is 148.98085761615576
At time: 54.28640651702881 and batch: 400, loss is 4.958526115417481 and perplexity is 142.3837839043907
At time: 55.244274616241455 and batch: 450, loss is 4.917009916305542 and perplexity is 136.59357573953554
At time: 56.20581603050232 and batch: 500, loss is 4.901662349700928 and perplexity is 134.51320191151763
At time: 57.16797590255737 and batch: 550, loss is 4.85004490852356 and perplexity is 127.74612660714959
At time: 58.12605285644531 and batch: 600, loss is 4.837973556518555 and perplexity is 126.213328232885
At time: 59.08481812477112 and batch: 650, loss is 4.913496265411377 and perplexity is 136.11447578789148
At time: 60.04189372062683 and batch: 700, loss is 4.899308500289917 and perplexity is 134.196950440613
At time: 61.01063823699951 and batch: 750, loss is 4.8620931434631345 and perplexity is 129.29455111352738
At time: 62.000746726989746 and batch: 800, loss is 4.8372611141204835 and perplexity is 126.12344053035746
At time: 62.96119666099548 and batch: 850, loss is 4.819671649932861 and perplexity is 123.92439351578379
At time: 63.918888330459595 and batch: 900, loss is 4.812928504943848 and perplexity is 123.0915644618881
At time: 64.87671256065369 and batch: 950, loss is 4.871628971099853 and perplexity is 130.53337890404313
At time: 65.83441233634949 and batch: 1000, loss is 4.8416994762420655 and perplexity is 126.6844661278589
At time: 66.79040884971619 and batch: 1050, loss is 4.754814538955689 and perplexity is 116.14211132961957
At time: 67.77576398849487 and batch: 1100, loss is 4.824420213699341 and perplexity is 124.51425579153779
At time: 68.7413284778595 and batch: 1150, loss is 4.7488368701934816 and perplexity is 115.44992315569479
At time: 69.69926953315735 and batch: 1200, loss is 4.830847091674805 and perplexity is 125.31707075327564
At time: 70.65648484230042 and batch: 1250, loss is 4.78429328918457 and perplexity is 119.61679872074043
At time: 71.61379504203796 and batch: 1300, loss is 4.807709646224976 and perplexity is 122.45084035602514
At time: 72.5714385509491 and batch: 1350, loss is 4.704320936203003 and perplexity is 110.42327503367473
At time: 73.52944946289062 and batch: 1400, loss is 4.714227981567383 and perplexity is 111.52268036580305
At time: 74.49290585517883 and batch: 1450, loss is 4.662585649490357 and perplexity is 105.90957346260832
At time: 75.46596598625183 and batch: 1500, loss is 4.649499378204346 and perplexity is 104.53264115730803
At time: 76.44333696365356 and batch: 1550, loss is 4.649654569625855 and perplexity is 104.54886498535026
At time: 77.40939784049988 and batch: 1600, loss is 4.708831186294556 and perplexity is 110.92243644522968
At time: 78.39803266525269 and batch: 1650, loss is 4.669887838363647 and perplexity is 106.68577571018056
At time: 79.3552885055542 and batch: 1700, loss is 4.699037504196167 and perplexity is 109.84139967108965
At time: 80.31348586082458 and batch: 1750, loss is 4.694852600097656 and perplexity is 109.3826844564833
At time: 81.27044224739075 and batch: 1800, loss is 4.653089075088501 and perplexity is 104.90855595999356
At time: 82.25993609428406 and batch: 1850, loss is 4.667715320587158 and perplexity is 106.45425055327455
At time: 83.2164363861084 and batch: 1900, loss is 4.745094327926636 and perplexity is 115.01865446262133
At time: 84.17733073234558 and batch: 1950, loss is 4.669892864227295 and perplexity is 106.68631189968985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.539485771711482 and perplexity of 93.6426340449191
finished 2 epochs...
Completing Train Step...
At time: 87.29256892204285 and batch: 50, loss is 4.627689094543457 and perplexity is 102.27743731674704
At time: 88.27017736434937 and batch: 100, loss is 4.572818508148194 and perplexity is 96.8166039660606
At time: 89.22619819641113 and batch: 150, loss is 4.526144104003906 and perplexity is 92.40158239646867
At time: 90.17961072921753 and batch: 200, loss is 4.516941776275635 and perplexity is 91.55517319310546
At time: 91.1361289024353 and batch: 250, loss is 4.521733407974243 and perplexity is 91.99492458512292
At time: 92.09767627716064 and batch: 300, loss is 4.542091150283813 and perplexity is 93.88692665629576
At time: 93.05381083488464 and batch: 350, loss is 4.547338447570801 and perplexity is 94.3808740829517
At time: 94.01069188117981 and batch: 400, loss is 4.510625267028809 and perplexity is 90.97868670289361
At time: 94.9698920249939 and batch: 450, loss is 4.5097420787811275 and perplexity is 90.89837086822943
At time: 95.93436694145203 and batch: 500, loss is 4.5056179237365725 and perplexity is 90.52426386137576
At time: 96.89118266105652 and batch: 550, loss is 4.471326951980591 and perplexity is 87.47271813301808
At time: 97.87411785125732 and batch: 600, loss is 4.450978212356567 and perplexity is 85.7107463184267
At time: 98.83862233161926 and batch: 650, loss is 4.523702955245971 and perplexity is 92.17629148456477
At time: 99.79600048065186 and batch: 700, loss is 4.53738691329956 and perplexity is 93.44629752808957
At time: 100.75285339355469 and batch: 750, loss is 4.511589546203613 and perplexity is 91.06645786698401
At time: 101.72921633720398 and batch: 800, loss is 4.481079139709473 and perplexity is 88.32994160968761
At time: 102.6861960887909 and batch: 850, loss is 4.466829109191894 and perplexity is 87.0801630858014
At time: 103.6442563533783 and batch: 900, loss is 4.452855739593506 and perplexity is 85.8718217435695
At time: 104.63271999359131 and batch: 950, loss is 4.528107719421387 and perplexity is 92.58320182526008
At time: 105.62860751152039 and batch: 1000, loss is 4.507720317840576 and perplexity is 90.71478174164622
At time: 106.59340643882751 and batch: 1050, loss is 4.4295260524749756 and perplexity is 83.89164724806335
At time: 107.55806756019592 and batch: 1100, loss is 4.486671857833862 and perplexity is 88.82533006780871
At time: 108.51698136329651 and batch: 1150, loss is 4.4350172996521 and perplexity is 84.35358416332753
At time: 109.4733681678772 and batch: 1200, loss is 4.518040513992309 and perplexity is 91.65582359912239
At time: 110.42877960205078 and batch: 1250, loss is 4.491507949829102 and perplexity is 89.25593792588525
At time: 111.38542795181274 and batch: 1300, loss is 4.502695751190186 and perplexity is 90.26012246406857
At time: 112.34165000915527 and batch: 1350, loss is 4.3854453563690186 and perplexity is 80.27396577514575
At time: 113.32802939414978 and batch: 1400, loss is 4.403252372741699 and perplexity is 81.71620850814293
At time: 114.28416466712952 and batch: 1450, loss is 4.351348581314087 and perplexity is 77.58301941822626
At time: 115.23979210853577 and batch: 1500, loss is 4.349477314949036 and perplexity is 77.43797667261941
At time: 116.1950261592865 and batch: 1550, loss is 4.363029432296753 and perplexity is 78.49456857731765
At time: 117.15762591362 and batch: 1600, loss is 4.429128723144531 and perplexity is 83.85832125716766
At time: 118.16433072090149 and batch: 1650, loss is 4.3875352478027345 and perplexity is 80.44190507489667
At time: 119.1293671131134 and batch: 1700, loss is 4.4130974292755125 and perplexity is 82.52468240614064
At time: 120.08523106575012 and batch: 1750, loss is 4.407626342773438 and perplexity is 82.07441557766873
At time: 121.04043316841125 and batch: 1800, loss is 4.367850379943848 and perplexity is 78.87390041779447
At time: 121.99664998054504 and batch: 1850, loss is 4.396014671325684 and perplexity is 81.12690615984727
At time: 122.953537940979 and batch: 1900, loss is 4.479906415939331 and perplexity is 88.2264157030572
At time: 123.91332936286926 and batch: 1950, loss is 4.409107456207275 and perplexity is 82.19606716481627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425087720294331 and perplexity of 83.52013331138981
finished 3 epochs...
Completing Train Step...
At time: 127.13711476325989 and batch: 50, loss is 4.382499041557312 and perplexity is 80.03780147881085
At time: 128.1217474937439 and batch: 100, loss is 4.334525289535523 and perplexity is 76.28873523163699
At time: 129.1082582473755 and batch: 150, loss is 4.297939777374268 and perplexity is 73.5481120197697
At time: 130.06636714935303 and batch: 200, loss is 4.300031538009644 and perplexity is 73.70211808105321
At time: 131.02220916748047 and batch: 250, loss is 4.291571969985962 and perplexity is 73.08125979869595
At time: 132.00475931167603 and batch: 300, loss is 4.311716299057007 and perplexity is 74.56836078308933
At time: 132.95985579490662 and batch: 350, loss is 4.316650543212891 and perplexity is 74.93720852555212
At time: 133.9164481163025 and batch: 400, loss is 4.278620247840881 and perplexity is 72.14083483527682
At time: 134.87185525894165 and batch: 450, loss is 4.300747108459473 and perplexity is 73.75487601259906
At time: 135.84866857528687 and batch: 500, loss is 4.300581970214844 and perplexity is 73.74269726745749
At time: 136.83733367919922 and batch: 550, loss is 4.264367837905883 and perplexity is 71.11994642534084
At time: 137.7945647239685 and batch: 600, loss is 4.25417420387268 and perplexity is 70.39865823867788
At time: 138.75093126296997 and batch: 650, loss is 4.316394300460815 and perplexity is 74.91800886899814
At time: 139.70761895179749 and batch: 700, loss is 4.34377345085144 and perplexity is 76.99753827217941
At time: 140.66294527053833 and batch: 750, loss is 4.317885522842407 and perplexity is 75.02981162127276
At time: 141.63591480255127 and batch: 800, loss is 4.290395455360413 and perplexity is 72.99532918691199
At time: 142.59968733787537 and batch: 850, loss is 4.278294267654419 and perplexity is 72.11732218502297
At time: 143.5560266971588 and batch: 900, loss is 4.255938668251037 and perplexity is 70.5229838151941
At time: 144.54450726509094 and batch: 950, loss is 4.340289545059204 and perplexity is 76.7297528430648
At time: 145.50139498710632 and batch: 1000, loss is 4.317375555038452 and perplexity is 74.99155858774586
At time: 146.49132990837097 and batch: 1050, loss is 4.249986934661865 and perplexity is 70.10449640175403
At time: 147.47706007957458 and batch: 1100, loss is 4.297058291435242 and perplexity is 73.48330895887199
At time: 148.43337750434875 and batch: 1150, loss is 4.259140119552613 and perplexity is 70.74912150477468
At time: 149.38966965675354 and batch: 1200, loss is 4.341847758293152 and perplexity is 76.84940735879701
At time: 150.3612551689148 and batch: 1250, loss is 4.318363027572632 and perplexity is 75.06564726639391
At time: 151.3271679878235 and batch: 1300, loss is 4.3263560390472415 and perplexity is 75.6680521537197
At time: 152.29348254203796 and batch: 1350, loss is 4.205182905197144 and perplexity is 67.03285720306586
At time: 153.25126314163208 and batch: 1400, loss is 4.226754474639892 and perplexity is 68.4945701771779
At time: 154.20731616020203 and batch: 1450, loss is 4.171658444404602 and perplexity is 64.82286813397587
At time: 155.16352081298828 and batch: 1500, loss is 4.174756445884705 and perplexity is 65.02400086928913
At time: 156.120361328125 and batch: 1550, loss is 4.187062811851502 and perplexity is 65.82915411440476
At time: 157.0755741596222 and batch: 1600, loss is 4.267422595024109 and perplexity is 71.33753275542551
At time: 158.06263160705566 and batch: 1650, loss is 4.21882981300354 and perplexity is 67.95391895302069
At time: 159.01874661445618 and batch: 1700, loss is 4.2391434049606325 and perplexity is 69.34842287408898
At time: 159.97469997406006 and batch: 1750, loss is 4.238496594429016 and perplexity is 69.30358208713295
At time: 160.9313097000122 and batch: 1800, loss is 4.200298080444336 and perplexity is 66.70621189501264
At time: 161.88994455337524 and batch: 1850, loss is 4.2316230249404905 and perplexity is 68.82885251230006
At time: 162.84668731689453 and batch: 1900, loss is 4.311733751296997 and perplexity is 74.5696621793735
At time: 163.81418824195862 and batch: 1950, loss is 4.246689739227295 and perplexity is 69.87372882823601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370151253633721 and perplexity of 79.05558824029384
finished 4 epochs...
Completing Train Step...
At time: 166.94348764419556 and batch: 50, loss is 4.224165663719178 and perplexity is 68.31748001127526
At time: 167.91682982444763 and batch: 100, loss is 4.183767056465149 and perplexity is 65.61255445096569
At time: 168.87348580360413 and batch: 150, loss is 4.15387836933136 and perplexity is 63.680498475951374
At time: 169.8317096233368 and batch: 200, loss is 4.156090497970581 and perplexity is 63.82152385602184
At time: 170.78546810150146 and batch: 250, loss is 4.143745803833008 and perplexity is 63.038509643801916
At time: 171.74367475509644 and batch: 300, loss is 4.1667291975021366 and perplexity is 64.5041264356667
At time: 172.71426677703857 and batch: 350, loss is 4.167149295806885 and perplexity is 64.53123020255626
At time: 173.68626594543457 and batch: 400, loss is 4.134879078865051 and perplexity is 62.4820352150313
At time: 174.64342999458313 and batch: 450, loss is 4.163939561843872 and perplexity is 64.32443417895139
At time: 175.59684252738953 and batch: 500, loss is 4.1665719842910764 and perplexity is 64.49398633192314
At time: 176.55478954315186 and batch: 550, loss is 4.1309202194213865 and perplexity is 62.23516660135421
At time: 177.5302538871765 and batch: 600, loss is 4.121788291931153 and perplexity is 61.66942665221965
At time: 178.50607347488403 and batch: 650, loss is 4.180588278770447 and perplexity is 65.40431787062903
At time: 179.47397136688232 and batch: 700, loss is 4.211211833953858 and perplexity is 67.43821422999524
At time: 180.4306468963623 and batch: 750, loss is 4.181579327583313 and perplexity is 65.46916887215711
At time: 181.41513538360596 and batch: 800, loss is 4.161289343833923 and perplexity is 64.1541861019175
At time: 182.38897681236267 and batch: 850, loss is 4.154536962509155 and perplexity is 63.722451831386664
At time: 183.3447196483612 and batch: 900, loss is 4.125279378890991 and perplexity is 61.88509622499978
At time: 184.31203889846802 and batch: 950, loss is 4.214762516021729 and perplexity is 67.67809149989343
At time: 185.32396173477173 and batch: 1000, loss is 4.1895031023025515 and perplexity is 65.98999253700795
At time: 186.30536270141602 and batch: 1050, loss is 4.126977005004883 and perplexity is 61.99024320528957
At time: 187.2754590511322 and batch: 1100, loss is 4.166468958854676 and perplexity is 64.48734215310166
At time: 188.2808482646942 and batch: 1150, loss is 4.1348891448974605 and perplexity is 62.48266416438829
At time: 189.24305605888367 and batch: 1200, loss is 4.215983529090881 and perplexity is 67.76077780436637
At time: 190.20030188560486 and batch: 1250, loss is 4.202303895950317 and perplexity is 66.84014652835424
At time: 191.155499458313 and batch: 1300, loss is 4.200738406181335 and perplexity is 66.73559082460248
At time: 192.1123492717743 and batch: 1350, loss is 4.08567298412323 and perplexity is 59.48195469547821
At time: 193.06901597976685 and batch: 1400, loss is 4.105535736083985 and perplexity is 60.67524175827895
At time: 194.03322052955627 and batch: 1450, loss is 4.048487749099731 and perplexity is 57.31072328748717
At time: 194.98964262008667 and batch: 1500, loss is 4.056581444740296 and perplexity is 57.776461066174974
At time: 195.96725630760193 and batch: 1550, loss is 4.067152070999145 and perplexity is 58.39043376362014
At time: 196.9382722377777 and batch: 1600, loss is 4.150252304077148 and perplexity is 63.45000697421828
At time: 197.8964240550995 and batch: 1650, loss is 4.103049306869507 and perplexity is 60.52456446641396
At time: 198.8521409034729 and batch: 1700, loss is 4.1216268491745 and perplexity is 61.659471373605136
At time: 199.80837488174438 and batch: 1750, loss is 4.129452233314514 and perplexity is 62.14387326649277
At time: 200.76425433158875 and batch: 1800, loss is 4.082824950218201 and perplexity is 59.31278908081717
At time: 201.73065328598022 and batch: 1850, loss is 4.1149705791473385 and perplexity is 61.250412196890245
At time: 202.68700313568115 and batch: 1900, loss is 4.191568655967712 and perplexity is 66.12643927847755
At time: 203.64366722106934 and batch: 1950, loss is 4.133751578330994 and perplexity is 62.41162638741173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348229696584302 and perplexity of 77.34142387384139
finished 5 epochs...
Completing Train Step...
At time: 206.8312509059906 and batch: 50, loss is 4.111388773918152 and perplexity is 61.03141758235077
At time: 207.81470608711243 and batch: 100, loss is 4.076648645401001 and perplexity is 58.94758418522104
At time: 208.77112007141113 and batch: 150, loss is 4.049684238433838 and perplexity is 57.37933599563191
At time: 209.728515625 and batch: 200, loss is 4.051603369712829 and perplexity is 57.48956020764513
At time: 210.68465900421143 and batch: 250, loss is 4.0420282936096195 and perplexity is 56.94172028358518
At time: 211.63973355293274 and batch: 300, loss is 4.057903809547424 and perplexity is 57.85291316260954
At time: 212.59641814231873 and batch: 350, loss is 4.0622551107406615 and perplexity is 58.10519709631901
At time: 213.55405044555664 and batch: 400, loss is 4.027413506507873 and perplexity is 56.1155807954808
At time: 214.51306056976318 and batch: 450, loss is 4.0633828783035275 and perplexity is 58.170763217561316
At time: 215.48005533218384 and batch: 500, loss is 4.070661716461181 and perplexity is 58.59572352091425
At time: 216.44264221191406 and batch: 550, loss is 4.030887198448181 and perplexity is 56.31084798890394
At time: 217.422767162323 and batch: 600, loss is 4.025272922515869 and perplexity is 55.995589153439866
At time: 218.3833999633789 and batch: 650, loss is 4.076529335975647 and perplexity is 58.94055160236097
At time: 219.36449027061462 and batch: 700, loss is 4.112441554069519 and perplexity is 61.09570408122863
At time: 220.3400707244873 and batch: 750, loss is 4.080747027397155 and perplexity is 59.18966964345065
At time: 221.31318855285645 and batch: 800, loss is 4.064431657791138 and perplexity is 58.231803524118206
At time: 222.30865383148193 and batch: 850, loss is 4.057951579093933 and perplexity is 57.85567683604471
At time: 223.31508111953735 and batch: 900, loss is 4.030615787506104 and perplexity is 56.295566682452794
At time: 224.3114411830902 and batch: 950, loss is 4.119804363250733 and perplexity is 61.54720019235888
At time: 225.31657123565674 and batch: 1000, loss is 4.090865550041198 and perplexity is 59.791621954201354
At time: 226.32667207717896 and batch: 1050, loss is 4.039548177719116 and perplexity is 56.80067319713553
At time: 227.29570865631104 and batch: 1100, loss is 4.072868709564209 and perplexity is 58.72518668820116
At time: 228.27379536628723 and batch: 1150, loss is 4.04279393196106 and perplexity is 56.9853337423691
At time: 229.2706048488617 and batch: 1200, loss is 4.121187596321106 and perplexity is 61.632393222378525
At time: 230.27289509773254 and batch: 1250, loss is 4.111121063232422 and perplexity is 61.01508100653426
At time: 231.25215911865234 and batch: 1300, loss is 4.108691835403443 and perplexity is 60.8670413575836
At time: 232.2172749042511 and batch: 1350, loss is 3.989215955734253 and perplexity is 54.0125245474014
At time: 233.1872045993805 and batch: 1400, loss is 4.014054441452027 and perplexity is 55.37091420041863
At time: 234.1555392742157 and batch: 1450, loss is 3.9549531984329223 and perplexity is 52.19325116132385
At time: 235.11902809143066 and batch: 1500, loss is 3.9649921321868895 and perplexity is 52.71985459805237
At time: 236.08353281021118 and batch: 1550, loss is 3.977549948692322 and perplexity is 53.386075241426084
At time: 237.08730173110962 and batch: 1600, loss is 4.0599554252624515 and perplexity is 57.97172694685232
At time: 238.05308485031128 and batch: 1650, loss is 4.017391681671143 and perplexity is 55.556008923248214
At time: 239.01974391937256 and batch: 1700, loss is 4.030844936370849 and perplexity is 56.308468225778824
At time: 240.0062117576599 and batch: 1750, loss is 4.040495972633362 and perplexity is 56.85453410683369
At time: 240.97533535957336 and batch: 1800, loss is 3.997489447593689 and perplexity is 54.46125043491135
At time: 241.94764256477356 and batch: 1850, loss is 4.027877645492554 and perplexity is 56.14163226946065
At time: 242.92507791519165 and batch: 1900, loss is 4.101764059066772 and perplexity is 60.446825370624225
At time: 243.90552425384521 and batch: 1950, loss is 4.04680212020874 and perplexity is 57.21420005058323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34173101380814 and perplexity of 76.84043613799184
finished 6 epochs...
Completing Train Step...
At time: 247.18091320991516 and batch: 50, loss is 4.025908722877502 and perplexity is 56.03120248955976
At time: 248.1494438648224 and batch: 100, loss is 3.994968571662903 and perplexity is 54.324133279810304
At time: 249.14335823059082 and batch: 150, loss is 3.969747071266174 and perplexity is 52.97113122402387
At time: 250.1288685798645 and batch: 200, loss is 3.9701838731765746 and perplexity is 52.99427416941201
At time: 251.10391998291016 and batch: 250, loss is 3.959962844848633 and perplexity is 52.455376925421454
At time: 252.086421251297 and batch: 300, loss is 3.9719747066497804 and perplexity is 53.089263118791436
At time: 253.075590133667 and batch: 350, loss is 3.9809045600891113 and perplexity is 53.565465501937595
At time: 254.08645367622375 and batch: 400, loss is 3.9461341094970703 and perplexity is 51.73497798366618
At time: 255.08196711540222 and batch: 450, loss is 3.984283504486084 and perplexity is 53.746766361732156
At time: 256.0714523792267 and batch: 500, loss is 3.994037594795227 and perplexity is 54.27358230291644
At time: 257.0699243545532 and batch: 550, loss is 3.9531861782073974 and perplexity is 52.10110606598531
At time: 258.0674216747284 and batch: 600, loss is 3.947877583503723 and perplexity is 51.825255248179495
At time: 259.0606379508972 and batch: 650, loss is 4.004599752426148 and perplexity is 54.84986647907675
At time: 260.02192783355713 and batch: 700, loss is 4.038181958198547 and perplexity is 56.72312399531131
At time: 260.97396183013916 and batch: 750, loss is 4.0063717603683475 and perplexity is 54.94714704361758
At time: 261.93439292907715 and batch: 800, loss is 3.9908233165740965 and perplexity is 54.09941197523755
At time: 262.8908724784851 and batch: 850, loss is 3.984484243392944 and perplexity is 53.757556511824106
At time: 263.84852480888367 and batch: 900, loss is 3.9501089096069335 and perplexity is 51.94102340324109
At time: 264.8062791824341 and batch: 950, loss is 4.044665780067444 and perplexity is 57.0921015267894
At time: 265.7829940319061 and batch: 1000, loss is 4.015239744186402 and perplexity is 55.436584408275124
At time: 266.7545154094696 and batch: 1050, loss is 3.9678319692611694 and perplexity is 52.869783181304754
At time: 267.7113621234894 and batch: 1100, loss is 3.9988557434082033 and perplexity is 54.53571146975047
At time: 268.669495344162 and batch: 1150, loss is 3.974028010368347 and perplexity is 53.198383490463556
At time: 269.6254971027374 and batch: 1200, loss is 4.051271448135376 and perplexity is 57.470481348651546
At time: 270.5837354660034 and batch: 1250, loss is 4.040862827301026 and perplexity is 56.87539528432482
At time: 271.54395937919617 and batch: 1300, loss is 4.035140357017517 and perplexity is 56.55085699094577
At time: 272.50125670433044 and batch: 1350, loss is 3.9167607831954956 and perplexity is 50.237450939095055
At time: 273.46906208992004 and batch: 1400, loss is 3.945923714637756 and perplexity is 51.72409435522157
At time: 274.4623062610626 and batch: 1450, loss is 3.890301728248596 and perplexity is 48.9256465465059
At time: 275.41818046569824 and batch: 1500, loss is 3.896474199295044 and perplexity is 49.22857262268567
At time: 276.37397384643555 and batch: 1550, loss is 3.9046994924545286 and perplexity is 49.635161930125626
At time: 277.35352182388306 and batch: 1600, loss is 3.9900811433792116 and perplexity is 54.05927573767265
At time: 278.3406994342804 and batch: 1650, loss is 3.9463240671157838 and perplexity is 51.74480637034706
At time: 279.29944467544556 and batch: 1700, loss is 3.964055733680725 and perplexity is 52.67051091124441
At time: 280.25234842300415 and batch: 1750, loss is 3.9662402439117432 and perplexity is 52.78569594684127
At time: 281.2080042362213 and batch: 1800, loss is 3.9245814990997316 and perplexity is 50.631884135217035
At time: 282.16467452049255 and batch: 1850, loss is 3.961243357658386 and perplexity is 52.5225897317605
At time: 283.13657426834106 and batch: 1900, loss is 4.031800155639648 and perplexity is 56.362280856964
At time: 284.0970833301544 and batch: 1950, loss is 3.977597503662109 and perplexity is 53.38861407498785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34385986328125 and perplexity of 77.00419210403363
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 287.2462749481201 and batch: 50, loss is 3.9939197397232054 and perplexity is 54.26718626287554
At time: 288.2190456390381 and batch: 100, loss is 3.9823938751220704 and perplexity is 53.645300790147914
At time: 289.1936557292938 and batch: 150, loss is 3.966118221282959 and perplexity is 52.77925529042054
At time: 290.1527419090271 and batch: 200, loss is 3.9600061559677124 and perplexity is 52.457648875697835
At time: 291.11718678474426 and batch: 250, loss is 3.9506484508514403 and perplexity is 51.96905528914832
At time: 292.11203932762146 and batch: 300, loss is 3.9620292377471924 and perplexity is 52.563882412665876
At time: 293.0836179256439 and batch: 350, loss is 3.9686497592926027 and perplexity is 52.91303724691567
At time: 294.03991413116455 and batch: 400, loss is 3.9238522911071776 and perplexity is 50.59497641896386
At time: 295.0372519493103 and batch: 450, loss is 3.9554410123825074 and perplexity is 52.21871796834139
At time: 295.99431467056274 and batch: 500, loss is 3.9562841129302977 and perplexity is 52.26276216229848
At time: 296.96694016456604 and batch: 550, loss is 3.9169801092147827 and perplexity is 50.24847052762573
At time: 297.968633890152 and batch: 600, loss is 3.894847092628479 and perplexity is 49.14853761439116
At time: 298.9353566169739 and batch: 650, loss is 3.9401271867752077 and perplexity is 51.425141482515535
At time: 299.8916516304016 and batch: 700, loss is 3.96687970161438 and perplexity is 52.81946096120222
At time: 300.8481185436249 and batch: 750, loss is 3.9227168655395506 and perplexity is 50.53756219010413
At time: 301.80443143844604 and batch: 800, loss is 3.9060260009765626 and perplexity is 49.701047084366664
At time: 302.78383469581604 and batch: 850, loss is 3.8972227287292482 and perplexity is 49.265435453033206
At time: 303.7433741092682 and batch: 900, loss is 3.8573661470413207 and perplexity is 47.34049910614358
At time: 304.69922971725464 and batch: 950, loss is 3.9542061281204224 and perplexity is 52.15427369413549
At time: 305.6566822528839 and batch: 1000, loss is 3.918434405326843 and perplexity is 50.321599845903755
At time: 306.61353182792664 and batch: 1050, loss is 3.8649318170547486 and perplexity is 47.7000199939578
At time: 307.569944858551 and batch: 1100, loss is 3.889501118659973 and perplexity is 48.886491880643085
At time: 308.5256760120392 and batch: 1150, loss is 3.855789270401001 and perplexity is 47.26590780505833
At time: 309.51070404052734 and batch: 1200, loss is 3.9120677852630616 and perplexity is 50.00223904187737
At time: 310.4720573425293 and batch: 1250, loss is 3.8954350328445435 and perplexity is 49.17744251255881
At time: 311.42881536483765 and batch: 1300, loss is 3.8911431884765624 and perplexity is 48.96683285809371
At time: 312.40222215652466 and batch: 1350, loss is 3.7741845226287842 and perplexity is 43.561970026555365
At time: 313.38717103004456 and batch: 1400, loss is 3.790061001777649 and perplexity is 44.25910007741805
At time: 314.3428301811218 and batch: 1450, loss is 3.7200513887405395 and perplexity is 41.266514688339655
At time: 315.2988896369934 and batch: 1500, loss is 3.726817178726196 and perplexity is 41.54666190009547
At time: 316.29782581329346 and batch: 1550, loss is 3.729786367416382 and perplexity is 41.67020509949552
At time: 317.26255989074707 and batch: 1600, loss is 3.8068499183654785 and perplexity is 45.00843507724479
At time: 318.24931740760803 and batch: 1650, loss is 3.7555426931381226 and perplexity is 42.75741767249752
At time: 319.20534896850586 and batch: 1700, loss is 3.7689833736419676 and perplexity is 43.33598592821241
At time: 320.1613187789917 and batch: 1750, loss is 3.749556999206543 and perplexity is 42.50224929875691
At time: 321.11613512039185 and batch: 1800, loss is 3.710271329879761 and perplexity is 40.864892889365684
At time: 322.0793409347534 and batch: 1850, loss is 3.736945834159851 and perplexity is 41.96961206529121
At time: 323.08056807518005 and batch: 1900, loss is 3.8057994508743285 and perplexity is 44.96118000367332
At time: 324.07252049446106 and batch: 1950, loss is 3.7398986434936523 and perplexity is 42.093723476021516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2712927529978195 and perplexity of 71.61415521768409
finished 8 epochs...
Completing Train Step...
At time: 327.2584824562073 and batch: 50, loss is 3.9052647018432616 and perplexity is 49.663224119419176
At time: 328.2365388870239 and batch: 100, loss is 3.880605173110962 and perplexity is 48.45352897332378
At time: 329.1983449459076 and batch: 150, loss is 3.856083517074585 and perplexity is 47.279817687571864
At time: 330.1616380214691 and batch: 200, loss is 3.8502975034713747 and perplexity is 47.007045910865884
At time: 331.12942838668823 and batch: 250, loss is 3.8399220180511473 and perplexity is 46.52184643408241
At time: 332.1271376609802 and batch: 300, loss is 3.853284020423889 and perplexity is 47.1476430937993
At time: 333.1151113510132 and batch: 350, loss is 3.859967060089111 and perplexity is 47.46378789015969
At time: 334.07263469696045 and batch: 400, loss is 3.8205540370941162 and perplexity is 45.629481744466894
At time: 335.0286138057709 and batch: 450, loss is 3.8583100128173826 and perplexity is 47.38520327712123
At time: 335.98477840423584 and batch: 500, loss is 3.863796758651733 and perplexity is 47.6459084011583
At time: 336.9412133693695 and batch: 550, loss is 3.824275770187378 and perplexity is 45.79961890286508
At time: 337.9403419494629 and batch: 600, loss is 3.807622718811035 and perplexity is 45.04323105936979
At time: 338.90923023223877 and batch: 650, loss is 3.8535543298721313 and perplexity is 47.160389269818204
At time: 339.8663377761841 and batch: 700, loss is 3.8847755193710327 and perplexity is 48.65601889974685
At time: 340.82342314720154 and batch: 750, loss is 3.844083323478699 and perplexity is 46.71584140236335
At time: 341.7811665534973 and batch: 800, loss is 3.8277946853637697 and perplexity is 45.96106777273595
At time: 342.76501297950745 and batch: 850, loss is 3.82023802280426 and perplexity is 45.61506445435174
At time: 343.75838017463684 and batch: 900, loss is 3.7844496059417723 and perplexity is 44.011440256043315
At time: 344.7142844200134 and batch: 950, loss is 3.8839998197555543 and perplexity is 48.61829107921531
At time: 345.67120599746704 and batch: 1000, loss is 3.846726245880127 and perplexity is 46.839471045921286
At time: 346.62397146224976 and batch: 1050, loss is 3.8000178146362305 and perplexity is 44.701980835734894
At time: 347.57939171791077 and batch: 1100, loss is 3.822846574783325 and perplexity is 45.73420905088549
At time: 348.534592628479 and batch: 1150, loss is 3.7942717695236206 and perplexity is 44.44585778922113
At time: 349.49299812316895 and batch: 1200, loss is 3.8538350534439085 and perplexity is 47.17363016116863
At time: 350.44941329956055 and batch: 1250, loss is 3.8409699153900148 and perplexity is 46.570622104644244
At time: 351.40627336502075 and batch: 1300, loss is 3.839308109283447 and perplexity is 46.49329502954243
At time: 352.3769700527191 and batch: 1350, loss is 3.7235896730422975 and perplexity is 41.41278597153921
At time: 353.3437502384186 and batch: 1400, loss is 3.7414407300949097 and perplexity is 42.158685718819505
At time: 354.3007378578186 and batch: 1450, loss is 3.674755082130432 and perplexity is 39.438996359268316
At time: 355.2580895423889 and batch: 1500, loss is 3.6829710531234743 and perplexity is 39.76436077140506
At time: 356.21513772010803 and batch: 1550, loss is 3.689042081832886 and perplexity is 40.00650563774216
At time: 357.1758053302765 and batch: 1600, loss is 3.77169291973114 and perplexity is 43.45356600178301
At time: 358.14266300201416 and batch: 1650, loss is 3.722898020744324 and perplexity is 41.3841526262575
At time: 359.0979743003845 and batch: 1700, loss is 3.7417193412780763 and perplexity is 42.17043323654729
At time: 360.07149171829224 and batch: 1750, loss is 3.72557147026062 and perplexity is 41.494939094107316
At time: 361.0461778640747 and batch: 1800, loss is 3.6904231214523318 and perplexity is 40.06179437624511
At time: 362.0034272670746 and batch: 1850, loss is 3.7193260526657106 and perplexity is 41.2365934493426
At time: 362.9613013267517 and batch: 1900, loss is 3.793315062522888 and perplexity is 44.40335645982205
At time: 363.915230512619 and batch: 1950, loss is 3.728706407546997 and perplexity is 41.625227241751226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273135163063227 and perplexity of 71.74621947898754
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 367.0356373786926 and batch: 50, loss is 3.8831938886642456 and perplexity is 48.57912387198332
At time: 368.012451171875 and batch: 100, loss is 3.892814073562622 and perplexity is 49.04871920111129
At time: 368.9727144241333 and batch: 150, loss is 3.873274869918823 and perplexity is 48.09964852530602
At time: 369.9297630786896 and batch: 200, loss is 3.872995963096619 and perplexity is 48.08623507582492
At time: 370.88587641716003 and batch: 250, loss is 3.866885919570923 and perplexity is 47.7933218540598
At time: 371.8411431312561 and batch: 300, loss is 3.8769122838973997 and perplexity is 48.27492544331829
At time: 372.7991781234741 and batch: 350, loss is 3.890188684463501 and perplexity is 48.9201161188282
At time: 373.7785792350769 and batch: 400, loss is 3.851619462966919 and perplexity is 47.06922841388467
At time: 374.7449777126312 and batch: 450, loss is 3.8837064409255984 and perplexity is 48.604029593975255
At time: 375.7012369632721 and batch: 500, loss is 3.884382882118225 and perplexity is 48.63691848416623
At time: 376.68064546585083 and batch: 550, loss is 3.8491293716430666 and perplexity is 46.95216754320691
At time: 377.63894963264465 and batch: 600, loss is 3.8297496700286864 and perplexity is 46.051008843475906
At time: 378.5956988334656 and batch: 650, loss is 3.8645753955841062 and perplexity is 47.683021712138135
At time: 379.55219769477844 and batch: 700, loss is 3.896405086517334 and perplexity is 49.22517041685831
At time: 380.5100259780884 and batch: 750, loss is 3.846821961402893 and perplexity is 46.843954524944394
At time: 381.4708435535431 and batch: 800, loss is 3.8289681673049927 and perplexity is 46.01503391371964
At time: 382.42763566970825 and batch: 850, loss is 3.8193610763549803 and perplexity is 45.57508002021106
At time: 383.3850271701813 and batch: 900, loss is 3.775928511619568 and perplexity is 43.63800790804021
At time: 384.34170508384705 and batch: 950, loss is 3.8807270622253416 and perplexity is 48.459435291009505
At time: 385.3159885406494 and batch: 1000, loss is 3.840044312477112 and perplexity is 46.52753614448973
At time: 386.317818403244 and batch: 1050, loss is 3.796346697807312 and perplexity is 44.53817549983384
At time: 387.28184509277344 and batch: 1100, loss is 3.8208945035934447 and perplexity is 45.64501969930906
At time: 388.23976945877075 and batch: 1150, loss is 3.7963366413116457 and perplexity is 44.53772760411707
At time: 389.19235491752625 and batch: 1200, loss is 3.8435365676879885 and perplexity is 46.69030622694734
At time: 390.1480793952942 and batch: 1250, loss is 3.821129446029663 and perplexity is 45.65574491129283
At time: 391.1042332649231 and batch: 1300, loss is 3.8211242246627806 and perplexity is 45.6555065265207
At time: 392.0826714038849 and batch: 1350, loss is 3.6974811506271363 and perplexity is 40.34555189620913
At time: 393.0489070415497 and batch: 1400, loss is 3.712756414413452 and perplexity is 40.966571890785126
At time: 394.00597524642944 and batch: 1450, loss is 3.636222786903381 and perplexity is 37.94822713360489
At time: 394.96164536476135 and batch: 1500, loss is 3.6427280616760256 and perplexity is 38.195895480152906
At time: 395.91752195358276 and batch: 1550, loss is 3.646041359901428 and perplexity is 38.322659760830476
At time: 396.87428545951843 and batch: 1600, loss is 3.729917917251587 and perplexity is 41.67568716868406
At time: 397.8315861225128 and batch: 1650, loss is 3.6775927686691285 and perplexity is 39.55107080920939
At time: 398.8006691932678 and batch: 1700, loss is 3.69513979434967 and perplexity is 40.25119908488576
At time: 399.7715036869049 and batch: 1750, loss is 3.6770558881759645 and perplexity is 39.529842309901674
At time: 400.7624442577362 and batch: 1800, loss is 3.634183406829834 and perplexity is 37.87091513643092
At time: 401.73444294929504 and batch: 1850, loss is 3.6557829427719115 and perplexity is 38.697807426003195
At time: 402.6910984516144 and batch: 1900, loss is 3.742190022468567 and perplexity is 42.190286738234946
At time: 403.6470835208893 and batch: 1950, loss is 3.679249601364136 and perplexity is 39.61665463215688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244165890715843 and perplexity of 69.69760047587523
finished 10 epochs...
Completing Train Step...
At time: 406.74876379966736 and batch: 50, loss is 3.8738689851760864 and perplexity is 48.128233750982446
At time: 407.74712920188904 and batch: 100, loss is 3.8644434070587157 and perplexity is 47.67672851574018
At time: 408.7046754360199 and batch: 150, loss is 3.8368806219100953 and perplexity is 46.38057001753885
At time: 409.66619873046875 and batch: 200, loss is 3.829673547744751 and perplexity is 46.04750346892546
At time: 410.6241657733917 and batch: 250, loss is 3.820540552139282 and perplexity is 45.62886643711517
At time: 411.581095457077 and batch: 300, loss is 3.827806854248047 and perplexity is 45.96162707105395
At time: 412.53987312316895 and batch: 350, loss is 3.840637011528015 and perplexity is 46.555121144997706
At time: 413.5196967124939 and batch: 400, loss is 3.80188081741333 and perplexity is 44.785338373726475
At time: 414.4757122993469 and batch: 450, loss is 3.8390427827835083 and perplexity is 46.48096076267791
At time: 415.4326374530792 and batch: 500, loss is 3.842191400527954 and perplexity is 46.62754218384787
At time: 416.4239978790283 and batch: 550, loss is 3.806926717758179 and perplexity is 45.01189183046169
At time: 417.4004018306732 and batch: 600, loss is 3.789907808303833 and perplexity is 44.252320391444314
At time: 418.389666557312 and batch: 650, loss is 3.825998568534851 and perplexity is 45.878590417090415
At time: 419.35946798324585 and batch: 700, loss is 3.8592916917800903 and perplexity is 47.43174317420343
At time: 420.3357241153717 and batch: 750, loss is 3.813325114250183 and perplexity is 45.30081911118758
At time: 421.29170870780945 and batch: 800, loss is 3.794867877960205 and perplexity is 44.472360238402494
At time: 422.2485122680664 and batch: 850, loss is 3.7870445394515992 and perplexity is 44.125795324910385
At time: 423.2302303314209 and batch: 900, loss is 3.745266842842102 and perplexity is 42.320298581013176
At time: 424.18841767311096 and batch: 950, loss is 3.8504976081848143 and perplexity is 47.01645318350593
At time: 425.17364406585693 and batch: 1000, loss is 3.810936870574951 and perplexity is 45.1927588049959
At time: 426.13679909706116 and batch: 1050, loss is 3.769208536148071 and perplexity is 43.34574466601818
At time: 427.0965042114258 and batch: 1100, loss is 3.7938616466522217 and perplexity is 44.427633263805625
At time: 428.07472944259644 and batch: 1150, loss is 3.7710197877883913 and perplexity is 43.42432586082139
At time: 429.0295009613037 and batch: 1200, loss is 3.820894365310669 and perplexity is 45.64501338738946
At time: 429.98655819892883 and batch: 1250, loss is 3.800306701660156 and perplexity is 44.714896523439585
At time: 430.9709198474884 and batch: 1300, loss is 3.803373084068298 and perplexity is 44.85221993096058
At time: 431.92722606658936 and batch: 1350, loss is 3.6807503509521484 and perplexity is 39.676153945892544
At time: 432.8834898471832 and batch: 1400, loss is 3.697701964378357 and perplexity is 40.3544617325394
At time: 433.8406584262848 and batch: 1450, loss is 3.6240508651733396 and perplexity is 37.48912403484646
At time: 434.80323123931885 and batch: 1500, loss is 3.6323725414276122 and perplexity is 37.802398062782565
At time: 435.77693367004395 and batch: 1550, loss is 3.637368998527527 and perplexity is 37.99174877039924
At time: 436.7507870197296 and batch: 1600, loss is 3.7243758773803712 and perplexity is 41.445357685855534
At time: 437.7082796096802 and batch: 1650, loss is 3.673811101913452 and perplexity is 39.40178429341792
At time: 438.6639816761017 and batch: 1700, loss is 3.6943115282058714 and perplexity is 40.21787418228587
At time: 439.62057638168335 and batch: 1750, loss is 3.6775927543640137 and perplexity is 39.551070243426786
At time: 440.5759048461914 and batch: 1800, loss is 3.6369114398956297 and perplexity is 37.97436929417638
At time: 441.532351732254 and batch: 1850, loss is 3.65987886428833 and perplexity is 38.85663566001875
At time: 442.4891023635864 and batch: 1900, loss is 3.747145733833313 and perplexity is 42.399888555791456
At time: 443.447557926178 and batch: 1950, loss is 3.6844570350646975 and perplexity is 39.82349381785404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243475199854651 and perplexity of 69.64947760110755
finished 11 epochs...
Completing Train Step...
At time: 446.6092767715454 and batch: 50, loss is 3.856881561279297 and perplexity is 47.317564131739466
At time: 447.5671126842499 and batch: 100, loss is 3.8453935956954957 and perplexity is 46.777091990145884
At time: 448.5231294631958 and batch: 150, loss is 3.816948447227478 and perplexity is 45.465256789300334
At time: 449.47697925567627 and batch: 200, loss is 3.809486312866211 and perplexity is 45.12725162279237
At time: 450.4317343235016 and batch: 250, loss is 3.798808569908142 and perplexity is 44.647957871149764
At time: 451.38913226127625 and batch: 300, loss is 3.806158084869385 and perplexity is 44.97730750304239
At time: 452.345908164978 and batch: 350, loss is 3.8189527654647826 and perplexity is 45.55647501728831
At time: 453.30224800109863 and batch: 400, loss is 3.779859585762024 and perplexity is 43.80988977138433
At time: 454.2597887516022 and batch: 450, loss is 3.8184305572509767 and perplexity is 45.532691262418794
At time: 455.21642446517944 and batch: 500, loss is 3.8219513845443727 and perplexity is 45.69328655280017
At time: 456.1738166809082 and batch: 550, loss is 3.7866884231567384 and perplexity is 44.11008420782993
At time: 457.1301341056824 and batch: 600, loss is 3.7705326080322266 and perplexity is 43.403175560754235
At time: 458.0863151550293 and batch: 650, loss is 3.8072130489349365 and perplexity is 45.02478198375591
At time: 459.06220984458923 and batch: 700, loss is 3.840467872619629 and perplexity is 46.54724752851367
At time: 460.0266981124878 and batch: 750, loss is 3.796118612289429 and perplexity is 44.52801814542614
At time: 460.98399901390076 and batch: 800, loss is 3.777564272880554 and perplexity is 43.709447684162555
At time: 461.9721302986145 and batch: 850, loss is 3.770448579788208 and perplexity is 43.39952862135215
At time: 462.93084025382996 and batch: 900, loss is 3.7292295551300048 and perplexity is 41.64700907583505
At time: 463.93136835098267 and batch: 950, loss is 3.8347925615310667 and perplexity is 46.28382562614418
At time: 464.88527846336365 and batch: 1000, loss is 3.7952349042892455 and perplexity is 44.488685761289666
At time: 465.8393557071686 and batch: 1050, loss is 3.7546703147888185 and perplexity is 42.72013329245542
At time: 466.7934024333954 and batch: 1100, loss is 3.7790427589416504 and perplexity is 43.77411928955478
At time: 467.74819898605347 and batch: 1150, loss is 3.757180304527283 and perplexity is 42.82749507076088
At time: 468.701943397522 and batch: 1200, loss is 3.808075304031372 and perplexity is 45.063621573898196
At time: 469.65569400787354 and batch: 1250, loss is 3.7880658864974976 and perplexity is 44.170886098357826
At time: 470.6089825630188 and batch: 1300, loss is 3.7925140142440794 and perplexity is 44.36780147008949
At time: 471.56309843063354 and batch: 1350, loss is 3.670307741165161 and perplexity is 39.26398714640793
At time: 472.51721143722534 and batch: 1400, loss is 3.687832374572754 and perplexity is 39.95813873821274
At time: 473.47209668159485 and batch: 1450, loss is 3.6153806972503664 and perplexity is 37.165492033409144
At time: 474.4219768047333 and batch: 1500, loss is 3.6240387916564942 and perplexity is 37.48867141200829
At time: 475.37210297584534 and batch: 1550, loss is 3.629270257949829 and perplexity is 37.68530602810348
At time: 476.33000683784485 and batch: 1600, loss is 3.7180475759506226 and perplexity is 41.18390711111271
At time: 477.28920698165894 and batch: 1650, loss is 3.6679859018325804 and perplexity is 39.17292822969241
At time: 478.2431089878082 and batch: 1700, loss is 3.6899337863922117 and perplexity is 40.04219553127756
At time: 479.1970944404602 and batch: 1750, loss is 3.673803758621216 and perplexity is 39.40149495566358
At time: 480.17698073387146 and batch: 1800, loss is 3.634071865081787 and perplexity is 37.866691183934364
At time: 481.130295753479 and batch: 1850, loss is 3.6576344347000123 and perplexity is 38.7695224735167
At time: 482.0858073234558 and batch: 1900, loss is 3.7451043367385863 and perplexity is 42.313421832963066
At time: 483.0642991065979 and batch: 1950, loss is 3.6825591135025024 and perplexity is 39.74798362912918
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244490370639535 and perplexity of 69.72021961748936
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 486.25191378593445 and batch: 50, loss is 3.852721028327942 and perplexity is 47.12110681395378
At time: 487.2081518173218 and batch: 100, loss is 3.857933373451233 and perplexity is 47.367359504738566
At time: 488.1815195083618 and batch: 150, loss is 3.8376023387908935 and perplexity is 46.41405574001365
At time: 489.1378104686737 and batch: 200, loss is 3.8350603914260866 and perplexity is 46.29622347848638
At time: 490.09531450271606 and batch: 250, loss is 3.832090711593628 and perplexity is 46.15894245853157
At time: 491.0512909889221 and batch: 300, loss is 3.8323709297180177 and perplexity is 46.17187884323119
At time: 492.0055968761444 and batch: 350, loss is 3.8515828227996827 and perplexity is 47.06750382107879
At time: 492.9594056606293 and batch: 400, loss is 3.815941128730774 and perplexity is 45.41948185401918
At time: 493.920428276062 and batch: 450, loss is 3.855015721321106 and perplexity is 47.229359443363585
At time: 494.9056603908539 and batch: 500, loss is 3.8569544506073 and perplexity is 47.321013202890484
At time: 495.8616452217102 and batch: 550, loss is 3.8264673805236815 and perplexity is 45.900103892802235
At time: 496.83443307876587 and batch: 600, loss is 3.8038324451446535 and perplexity is 44.872828027901406
At time: 497.81813883781433 and batch: 650, loss is 3.834621787071228 and perplexity is 46.275922205693995
At time: 498.7738769054413 and batch: 700, loss is 3.866784443855286 and perplexity is 47.78847223858525
At time: 499.7281119823456 and batch: 750, loss is 3.819058880805969 and perplexity is 45.56130951468065
At time: 500.6881580352783 and batch: 800, loss is 3.796787071228027 and perplexity is 44.55779324778146
At time: 501.64596462249756 and batch: 850, loss is 3.7908088302612306 and perplexity is 44.292210672093454
At time: 502.60326957702637 and batch: 900, loss is 3.742554335594177 and perplexity is 42.205660013639914
At time: 503.56103515625 and batch: 950, loss is 3.848971619606018 and perplexity is 46.94476132732132
At time: 504.51831889152527 and batch: 1000, loss is 3.8057910680770872 and perplexity is 44.960803104797364
At time: 505.4739372730255 and batch: 1050, loss is 3.763543477058411 and perplexity is 43.10088269482809
At time: 506.4292628765106 and batch: 1100, loss is 3.78149188041687 and perplexity is 43.88145881528083
At time: 507.3851590156555 and batch: 1150, loss is 3.7658102560043334 and perplexity is 43.19869368433551
At time: 508.34157943725586 and batch: 1200, loss is 3.817438282966614 and perplexity is 45.48753275230071
At time: 509.29988074302673 and batch: 1250, loss is 3.7926807737350465 and perplexity is 44.375200839018326
At time: 510.2562355995178 and batch: 1300, loss is 3.7973069763183593 and perplexity is 44.58096509436349
At time: 511.2120306491852 and batch: 1350, loss is 3.669417390823364 and perplexity is 39.22904400016127
At time: 512.2048122882843 and batch: 1400, loss is 3.688733959197998 and perplexity is 39.994180626717345
At time: 513.162264585495 and batch: 1450, loss is 3.613736696243286 and perplexity is 37.10444212388411
At time: 514.1205258369446 and batch: 1500, loss is 3.618498902320862 and perplexity is 37.28156253087398
At time: 515.0787136554718 and batch: 1550, loss is 3.6249604511260984 and perplexity is 37.52323912840264
At time: 516.0356831550598 and batch: 1600, loss is 3.712831430435181 and perplexity is 40.969645155302835
At time: 516.9991023540497 and batch: 1650, loss is 3.6569152784347536 and perplexity is 38.74165115164788
At time: 517.9727964401245 and batch: 1700, loss is 3.6734963178634645 and perplexity is 39.38938319211815
At time: 518.9329731464386 and batch: 1750, loss is 3.6620673084259034 and perplexity is 38.94176435225299
At time: 519.9185345172882 and batch: 1800, loss is 3.617355456352234 and perplexity is 37.238957441444846
At time: 520.875697851181 and batch: 1850, loss is 3.636107006072998 and perplexity is 37.943833710697774
At time: 521.833530664444 and batch: 1900, loss is 3.725128321647644 and perplexity is 41.47655474320289
At time: 522.7896900177002 and batch: 1950, loss is 3.672235074043274 and perplexity is 39.33973489187335
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.232224859193314 and perplexity of 68.87028854088447
finished 13 epochs...
Completing Train Step...
At time: 525.9611339569092 and batch: 50, loss is 3.855526924133301 and perplexity is 47.25350939696538
At time: 526.9172487258911 and batch: 100, loss is 3.846419792175293 and perplexity is 46.82511911570022
At time: 527.9146738052368 and batch: 150, loss is 3.8203818655014037 and perplexity is 45.62162632018016
At time: 528.8752658367157 and batch: 200, loss is 3.815259566307068 and perplexity is 45.38853618878252
At time: 529.8304345607758 and batch: 250, loss is 3.8100043296813966 and perplexity is 45.15063435375713
At time: 530.7899553775787 and batch: 300, loss is 3.8101881313323975 and perplexity is 45.15893387760481
At time: 531.7955083847046 and batch: 350, loss is 3.826870002746582 and perplexity is 45.9185880154725
At time: 532.7577028274536 and batch: 400, loss is 3.7913850021362303 and perplexity is 44.3177379515083
At time: 533.7207226753235 and batch: 450, loss is 3.8319248151779175 and perplexity is 46.15128549057404
At time: 534.6811830997467 and batch: 500, loss is 3.8348363733291624 and perplexity is 46.28585344818855
At time: 535.6593060493469 and batch: 550, loss is 3.8041110372543336 and perplexity is 44.88533098526078
At time: 536.6231062412262 and batch: 600, loss is 3.7849084997177123 and perplexity is 44.0316414667974
At time: 537.6110618114471 and batch: 650, loss is 3.816560969352722 and perplexity is 45.44764342084004
At time: 538.5773034095764 and batch: 700, loss is 3.8501539707183836 and perplexity is 47.00029934434454
At time: 539.5350804328918 and batch: 750, loss is 3.804572696685791 and perplexity is 44.90605750557289
At time: 540.491055727005 and batch: 800, loss is 3.7826281118392946 and perplexity is 43.931346644340884
At time: 541.4472434520721 and batch: 850, loss is 3.7765830039978026 and perplexity is 43.66657800005124
At time: 542.4044272899628 and batch: 900, loss is 3.730014977455139 and perplexity is 41.6797324156769
At time: 543.3651003837585 and batch: 950, loss is 3.8365046882629397 and perplexity is 46.36313727767705
At time: 544.3234343528748 and batch: 1000, loss is 3.7939581537246703 and perplexity is 44.43192105152532
At time: 545.3029136657715 and batch: 1050, loss is 3.7522579288482665 and perplexity is 42.617200050793926
At time: 546.2718675136566 and batch: 1100, loss is 3.7713331604003906 and perplexity is 43.43793598764982
At time: 547.2282907962799 and batch: 1150, loss is 3.756411118507385 and perplexity is 42.79456542641981
At time: 548.1865203380585 and batch: 1200, loss is 3.80876051902771 and perplexity is 45.09451042473325
At time: 549.1580390930176 and batch: 1250, loss is 3.7857625389099123 and perplexity is 44.069262276843396
At time: 550.1339082717896 and batch: 1300, loss is 3.791514811515808 and perplexity is 44.32349118297971
At time: 551.0908572673798 and batch: 1350, loss is 3.664512391090393 and perplexity is 39.03709668541813
At time: 552.0628044605255 and batch: 1400, loss is 3.6846958208084106 and perplexity is 39.833004235873524
At time: 553.0359952449799 and batch: 1450, loss is 3.611254482269287 and perplexity is 37.01245517202602
At time: 553.992938041687 and batch: 1500, loss is 3.61794246673584 and perplexity is 37.260823513315366
At time: 554.9502267837524 and batch: 1550, loss is 3.6247518396377565 and perplexity is 37.51541216606617
At time: 555.912070274353 and batch: 1600, loss is 3.7140304613113404 and perplexity is 41.01879848712173
At time: 556.8843290805817 and batch: 1650, loss is 3.6594609022140503 and perplexity is 38.840398453483395
At time: 557.8574485778809 and batch: 1700, loss is 3.67749596118927 and perplexity is 39.54724215504281
At time: 558.8183200359344 and batch: 1750, loss is 3.666621751785278 and perplexity is 39.11952690978268
At time: 559.7817528247833 and batch: 1800, loss is 3.622604475021362 and perplexity is 37.434939330593906
At time: 560.7675702571869 and batch: 1850, loss is 3.641615905761719 and perplexity is 38.15343930241313
At time: 561.7259624004364 and batch: 1900, loss is 3.730908098220825 and perplexity is 41.7169740783812
At time: 562.6826965808868 and batch: 1950, loss is 3.6776451587677004 and perplexity is 39.553142947987006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2311756222747094 and perplexity of 68.79806518788247
finished 14 epochs...
Completing Train Step...
At time: 565.8002300262451 and batch: 50, loss is 3.8513600778579713 and perplexity is 47.05702094023135
At time: 566.776638507843 and batch: 100, loss is 3.84013277053833 and perplexity is 46.53165206217069
At time: 567.7345535755157 and batch: 150, loss is 3.8131237745285036 and perplexity is 45.2916991750094
At time: 568.6914751529694 and batch: 200, loss is 3.807289705276489 and perplexity is 45.02823355111256
At time: 569.6479403972626 and batch: 250, loss is 3.8011453437805174 and perplexity is 44.75241204792245
At time: 570.6046772003174 and batch: 300, loss is 3.801019048690796 and perplexity is 44.74676039492313
At time: 571.5608673095703 and batch: 350, loss is 3.81747154712677 and perplexity is 45.489045882041644
At time: 572.5239479541779 and batch: 400, loss is 3.7815182399749756 and perplexity is 43.88261552638936
At time: 573.482132434845 and batch: 450, loss is 3.82271279335022 and perplexity is 45.72809107210183
At time: 574.4377217292786 and batch: 500, loss is 3.825801100730896 and perplexity is 45.8695317670175
At time: 575.3943212032318 and batch: 550, loss is 3.7948737001419066 and perplexity is 44.472619165318264
At time: 576.3502893447876 and batch: 600, loss is 3.7767723751068116 and perplexity is 43.67484797137585
At time: 577.3061237335205 and batch: 650, loss is 3.808610715866089 and perplexity is 45.08775563045727
At time: 578.2601318359375 and batch: 700, loss is 3.8424704265594483 and perplexity is 46.64055429717651
At time: 579.2160544395447 and batch: 750, loss is 3.797751793861389 and perplexity is 44.60079990083055
At time: 580.1977105140686 and batch: 800, loss is 3.7759891891479493 and perplexity is 43.64065583483757
At time: 581.1624186038971 and batch: 850, loss is 3.769963321685791 and perplexity is 43.37847375738238
At time: 582.118750333786 and batch: 900, loss is 3.7240105438232423 and perplexity is 41.43021907139599
At time: 583.0759234428406 and batch: 950, loss is 3.8306349611282347 and perplexity is 46.09179544307321
At time: 584.0682687759399 and batch: 1000, loss is 3.7883584928512573 and perplexity is 44.18381267138787
At time: 585.0282702445984 and batch: 1050, loss is 3.746988310813904 and perplexity is 42.393214362662
At time: 585.9850852489471 and batch: 1100, loss is 3.7663598823547364 and perplexity is 43.222443350810785
At time: 586.9408438205719 and batch: 1150, loss is 3.7518471813201906 and perplexity is 42.59969873577655
At time: 587.9050056934357 and batch: 1200, loss is 3.804579982757568 and perplexity is 44.90638469552306
At time: 588.8641965389252 and batch: 1250, loss is 3.7821732902526857 and perplexity is 43.91137026274738
At time: 589.8210051059723 and batch: 1300, loss is 3.788551616668701 and perplexity is 44.192346441970834
At time: 590.7771728038788 and batch: 1350, loss is 3.6617910623550416 and perplexity is 38.93100832858129
At time: 591.7369439601898 and batch: 1400, loss is 3.682181544303894 and perplexity is 39.73297884765394
At time: 592.6946089267731 and batch: 1450, loss is 3.609305863380432 and perplexity is 36.940402227418794
At time: 593.6621417999268 and batch: 1500, loss is 3.6167255640029907 and perplexity is 37.21550829305358
At time: 594.6384160518646 and batch: 1550, loss is 3.6237559366226195 and perplexity is 37.478069052122244
At time: 595.5942783355713 and batch: 1600, loss is 3.713744463920593 and perplexity is 41.00706889517912
At time: 596.5803983211517 and batch: 1650, loss is 3.659486837387085 and perplexity is 38.841405799000796
At time: 597.5833599567413 and batch: 1700, loss is 3.6781659173965453 and perplexity is 39.57374595260572
At time: 598.5604078769684 and batch: 1750, loss is 3.6674089193344117 and perplexity is 39.15033265495429
At time: 599.5418446063995 and batch: 1800, loss is 3.623794689178467 and perplexity is 37.47952145122815
At time: 600.528404712677 and batch: 1850, loss is 3.642857542037964 and perplexity is 38.20084141871829
At time: 601.5008761882782 and batch: 1900, loss is 3.7321323919296265 and perplexity is 41.76807918474226
At time: 602.484237909317 and batch: 1950, loss is 3.6786523151397703 and perplexity is 39.59299921532021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.23100216887718 and perplexity of 68.78613296460443
finished 15 epochs...
Completing Train Step...
At time: 605.7252418994904 and batch: 50, loss is 3.8466101121902465 and perplexity is 46.83403172116722
At time: 606.7310314178467 and batch: 100, loss is 3.8346044969558717 and perplexity is 46.275122096577846
At time: 607.7149908542633 and batch: 150, loss is 3.8071904611587524 and perplexity is 45.02376498554363
At time: 608.7143142223358 and batch: 200, loss is 3.8011424684524537 and perplexity is 44.752283370241166
At time: 609.6774230003357 and batch: 250, loss is 3.794562873840332 and perplexity is 44.45879805367556
At time: 610.6407420635223 and batch: 300, loss is 3.794297161102295 and perplexity is 44.446986354043894
At time: 611.6254284381866 and batch: 350, loss is 3.810738372802734 and perplexity is 45.18378903332207
At time: 612.5916976928711 and batch: 400, loss is 3.7745630407333373 and perplexity is 43.57846214196564
At time: 613.5483138561249 and batch: 450, loss is 3.816209526062012 and perplexity is 45.43167395782588
At time: 614.5073425769806 and batch: 500, loss is 3.8194144058227537 and perplexity is 45.577510579781915
At time: 615.4705889225006 and batch: 550, loss is 3.7884019899368284 and perplexity is 44.18573458026691
At time: 616.4421226978302 and batch: 600, loss is 3.770984902381897 and perplexity is 43.42281101198521
At time: 617.404543876648 and batch: 650, loss is 3.802929391860962 and perplexity is 44.832323764708846
At time: 618.3659391403198 and batch: 700, loss is 3.8369364833831785 and perplexity is 46.3831609768692
At time: 619.327999830246 and batch: 750, loss is 3.792710332870483 and perplexity is 44.37651255097639
At time: 620.2906799316406 and batch: 800, loss is 3.771082820892334 and perplexity is 43.42706311713499
At time: 621.2463338375092 and batch: 850, loss is 3.7650605487823485 and perplexity is 43.1663194488155
At time: 622.2056350708008 and batch: 900, loss is 3.7194755268096924 and perplexity is 41.24275771453682
At time: 623.1657614707947 and batch: 950, loss is 3.8262177896499634 and perplexity is 45.88864907533629
At time: 624.1257679462433 and batch: 1000, loss is 3.7841159391403196 and perplexity is 43.99675754924788
At time: 625.0857243537903 and batch: 1050, loss is 3.7429894399642945 and perplexity is 42.22402787643445
At time: 626.0543382167816 and batch: 1100, loss is 3.762437496185303 and perplexity is 43.053240293602116
At time: 627.0144197940826 and batch: 1150, loss is 3.748221001625061 and perplexity is 42.445504310510046
At time: 627.9686439037323 and batch: 1200, loss is 3.8011952781677247 and perplexity is 44.75464678798883
At time: 628.924950838089 and batch: 1250, loss is 3.7791419792175294 and perplexity is 43.7784627852249
At time: 629.9205574989319 and batch: 1300, loss is 3.7859387016296386 and perplexity is 44.07702632178997
At time: 630.8985052108765 and batch: 1350, loss is 3.659301686286926 and perplexity is 38.83421493570407
At time: 631.8607172966003 and batch: 1400, loss is 3.67976676940918 and perplexity is 39.63714839888804
At time: 632.8210597038269 and batch: 1450, loss is 3.607222905158997 and perplexity is 36.863536994222144
At time: 633.7818930149078 and batch: 1500, loss is 3.615011806488037 and perplexity is 37.15178455515709
At time: 634.762202501297 and batch: 1550, loss is 3.6221241188049316 and perplexity is 37.41696154299146
At time: 635.7341210842133 and batch: 1600, loss is 3.7126512241363527 and perplexity is 40.96226283237562
At time: 636.6979353427887 and batch: 1650, loss is 3.65856418132782 and perplexity is 38.805585068238294
At time: 637.6658639907837 and batch: 1700, loss is 3.6776686334609985 and perplexity is 39.554071456784875
At time: 638.6211311817169 and batch: 1750, loss is 3.666936421394348 and perplexity is 39.13183857297391
At time: 639.5802600383759 and batch: 1800, loss is 3.6236461448669433 and perplexity is 37.47395449499802
At time: 640.5464296340942 and batch: 1850, loss is 3.6427704334259032 and perplexity is 38.19751394137082
At time: 641.5032248497009 and batch: 1900, loss is 3.732055215835571 and perplexity is 41.76485581191985
At time: 642.4599208831787 and batch: 1950, loss is 3.6784520673751833 and perplexity is 39.58507159950421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.231113735465116 and perplexity of 68.7938076268666
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 645.5827343463898 and batch: 50, loss is 3.8457532787322997 and perplexity is 46.7939199428289
At time: 646.5584707260132 and batch: 100, loss is 3.8386966705322267 and perplexity is 46.46487591644835
At time: 647.5260574817657 and batch: 150, loss is 3.8134731674194335 and perplexity is 45.30752653754225
At time: 648.4826953411102 and batch: 200, loss is 3.809195818901062 and perplexity is 45.11414433241874
At time: 649.438286781311 and batch: 250, loss is 3.8055986022949218 and perplexity is 44.95215052135084
At time: 650.3938393592834 and batch: 300, loss is 3.80244966506958 and perplexity is 44.81082165586022
At time: 651.3501615524292 and batch: 350, loss is 3.8204755115509035 and perplexity is 45.62589880530435
At time: 652.3058183193207 and batch: 400, loss is 3.7879347133636476 and perplexity is 44.16509244479752
At time: 653.2603876590729 and batch: 450, loss is 3.8315729904174805 and perplexity is 46.13505118159585
At time: 654.215434551239 and batch: 500, loss is 3.8340470123291017 and perplexity is 46.249331616972995
At time: 655.1723029613495 and batch: 550, loss is 3.8067063903808593 and perplexity is 45.00197557083835
At time: 656.1278703212738 and batch: 600, loss is 3.7866268587112426 and perplexity is 44.10736867854578
At time: 657.1104757785797 and batch: 650, loss is 3.8154940938949586 and perplexity is 45.39918230104747
At time: 658.0740311145782 and batch: 700, loss is 3.850812249183655 and perplexity is 47.03124881483158
At time: 659.0306072235107 and batch: 750, loss is 3.807587571144104 and perplexity is 45.041647922708954
At time: 659.9884414672852 and batch: 800, loss is 3.783355302810669 and perplexity is 43.96330474139247
At time: 660.9829289913177 and batch: 850, loss is 3.7778935289382933 and perplexity is 43.72384165411386
At time: 661.9390964508057 and batch: 900, loss is 3.726487545967102 and perplexity is 41.532969016237715
At time: 662.8927850723267 and batch: 950, loss is 3.8360447549819945 and perplexity is 46.3418182308794
At time: 663.8461039066315 and batch: 1000, loss is 3.7935968399047852 and perplexity is 44.41587008429813
At time: 664.8020925521851 and batch: 1050, loss is 3.747910904884338 and perplexity is 42.4323441385337
At time: 665.7825093269348 and batch: 1100, loss is 3.761074252128601 and perplexity is 42.99458820728756
At time: 666.7496461868286 and batch: 1150, loss is 3.74663601398468 and perplexity is 42.37828199812821
At time: 667.7077000141144 and batch: 1200, loss is 3.800835771560669 and perplexity is 44.73856008858272
At time: 668.6637902259827 and batch: 1250, loss is 3.7776630210876463 and perplexity is 43.71376412687133
At time: 669.6203753948212 and batch: 1300, loss is 3.7837282276153563 and perplexity is 43.97970280565899
At time: 670.5777902603149 and batch: 1350, loss is 3.652698917388916 and perplexity is 38.578646248131
At time: 671.5332844257355 and batch: 1400, loss is 3.674261269569397 and perplexity is 39.41952569529638
At time: 672.489631652832 and batch: 1450, loss is 3.5993770217895507 and perplexity is 36.575441641525366
At time: 673.4504108428955 and batch: 1500, loss is 3.605297493934631 and perplexity is 36.792627812896725
At time: 674.4244465827942 and batch: 1550, loss is 3.6154800605773927 and perplexity is 37.169185103823
At time: 675.3923482894897 and batch: 1600, loss is 3.705784411430359 and perplexity is 40.681946187922684
At time: 676.3538992404938 and batch: 1650, loss is 3.649336619377136 and perplexity is 38.44915116507955
At time: 677.3271865844727 and batch: 1700, loss is 3.6643664407730103 and perplexity is 39.03139962452122
At time: 678.2846028804779 and batch: 1750, loss is 3.6557326889038086 and perplexity is 38.69586276035683
At time: 679.269736289978 and batch: 1800, loss is 3.6124155044555666 and perplexity is 37.055452409192654
At time: 680.2447810173035 and batch: 1850, loss is 3.6318143081665037 and perplexity is 37.78130139581271
At time: 681.2157275676727 and batch: 1900, loss is 3.7193645095825194 and perplexity is 41.23817931207986
At time: 682.1718647480011 and batch: 1950, loss is 3.670207939147949 and perplexity is 39.260068716823774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.228254735192587 and perplexity of 68.59740700061471
finished 17 epochs...
Completing Train Step...
At time: 685.369179725647 and batch: 50, loss is 3.846335711479187 and perplexity is 46.82118219260166
At time: 686.3249309062958 and batch: 100, loss is 3.8355614805221556 and perplexity is 46.319427824497474
At time: 687.2807340621948 and batch: 150, loss is 3.808746166229248 and perplexity is 45.093863196958154
At time: 688.2376480102539 and batch: 200, loss is 3.80312162399292 and perplexity is 44.84094280628859
At time: 689.1917300224304 and batch: 250, loss is 3.798951196670532 and perplexity is 44.654326318973
At time: 690.175360918045 and batch: 300, loss is 3.7956192016601564 and perplexity is 44.50578593182785
At time: 691.1359326839447 and batch: 350, loss is 3.812641673088074 and perplexity is 45.26986924414099
At time: 692.0912432670593 and batch: 400, loss is 3.779948310852051 and perplexity is 43.813776980242295
At time: 693.0474326610565 and batch: 450, loss is 3.8232648277282717 and perplexity is 45.753341519332544
At time: 694.0031249523163 and batch: 500, loss is 3.8263573169708254 and perplexity is 45.89505224229773
At time: 694.9816806316376 and batch: 550, loss is 3.7976671123504637 and perplexity is 44.5970231976172
At time: 695.9463458061218 and batch: 600, loss is 3.778613977432251 and perplexity is 43.75535378005244
At time: 696.9053628444672 and batch: 650, loss is 3.8078553533554076 and perplexity is 45.053710889842385
At time: 697.8910202980042 and batch: 700, loss is 3.8435116624832153 and perplexity is 46.68914340979
At time: 698.8477289676666 and batch: 750, loss is 3.800493426322937 and perplexity is 44.723246676979734
At time: 699.821980714798 and batch: 800, loss is 3.7769720458984377 and perplexity is 43.68356943352609
At time: 700.8090424537659 and batch: 850, loss is 3.7713104057312012 and perplexity is 43.43694758303161
At time: 701.7779531478882 and batch: 900, loss is 3.7215837383270265 and perplexity is 41.329797888668104
At time: 702.7343792915344 and batch: 950, loss is 3.830778946876526 and perplexity is 46.09843248253826
At time: 703.6905357837677 and batch: 1000, loss is 3.7884239625930785 and perplexity is 44.18670546889046
At time: 704.6877598762512 and batch: 1050, loss is 3.743705792427063 and perplexity is 42.25428599923819
At time: 705.641265630722 and batch: 1100, loss is 3.7580942249298097 and perplexity is 42.86665388358853
At time: 706.5959317684174 and batch: 1150, loss is 3.744049725532532 and perplexity is 42.26882114645716
At time: 707.5857853889465 and batch: 1200, loss is 3.798115568161011 and perplexity is 44.617027476985676
At time: 708.5633721351624 and batch: 1250, loss is 3.7756204271316527 and perplexity is 43.624565785481266
At time: 709.5215826034546 and batch: 1300, loss is 3.781863627433777 and perplexity is 43.89777464918633
At time: 710.4940176010132 and batch: 1350, loss is 3.652028784751892 and perplexity is 38.552802098659114
At time: 711.4743185043335 and batch: 1400, loss is 3.6741211938858034 and perplexity is 39.41400436499876
At time: 712.4377098083496 and batch: 1450, loss is 3.600168390274048 and perplexity is 36.604397749311424
At time: 713.4252581596375 and batch: 1500, loss is 3.607278199195862 and perplexity is 36.86557538435057
At time: 714.3940057754517 and batch: 1550, loss is 3.617786502838135 and perplexity is 37.25501262320484
At time: 715.3565678596497 and batch: 1600, loss is 3.7083730697631836 and perplexity is 40.787394272563766
At time: 716.3430511951447 and batch: 1650, loss is 3.6522808647155762 and perplexity is 38.562521712620565
At time: 717.3171920776367 and batch: 1700, loss is 3.667631649971008 and perplexity is 39.159053604644775
At time: 718.281539440155 and batch: 1750, loss is 3.659624080657959 and perplexity is 38.84673688639757
At time: 719.2372560501099 and batch: 1800, loss is 3.615817036628723 and perplexity is 37.18171233962113
At time: 720.1982679367065 and batch: 1850, loss is 3.6353372859954836 and perplexity is 37.91463881746194
At time: 721.1559588909149 and batch: 1900, loss is 3.722670707702637 and perplexity is 41.37474653775019
At time: 722.1121122837067 and batch: 1950, loss is 3.6732965230941774 and perplexity is 39.38151418551028
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.227418979378633 and perplexity of 68.54010026944432
finished 18 epochs...
Completing Train Step...
At time: 725.2401044368744 and batch: 50, loss is 3.8457728147506716 and perplexity is 46.79483411863825
At time: 726.226970911026 and batch: 100, loss is 3.8336406326293946 and perplexity is 46.23054064587203
At time: 727.1863403320312 and batch: 150, loss is 3.8061654949188233 and perplexity is 44.97764078834943
At time: 728.1423773765564 and batch: 200, loss is 3.800106267929077 and perplexity is 44.705935048015554
At time: 729.1133806705475 and batch: 250, loss is 3.7955075883865357 and perplexity is 44.50081877257055
At time: 730.0743632316589 and batch: 300, loss is 3.7920811939239503 and perplexity is 44.34860233924048
At time: 731.0260202884674 and batch: 350, loss is 3.8086912965774538 and perplexity is 45.09138898026681
At time: 731.9812343120575 and batch: 400, loss is 3.7757257413864136 and perplexity is 43.629160316046764
At time: 732.9374551773071 and batch: 450, loss is 3.8189804267883303 and perplexity is 45.55773518711236
At time: 733.8954427242279 and batch: 500, loss is 3.8222656202316285 and perplexity is 45.70764727030986
At time: 734.8516592979431 and batch: 550, loss is 3.792965121269226 and perplexity is 44.38782061207126
At time: 735.8081498146057 and batch: 600, loss is 3.7744838428497314 and perplexity is 43.57501095665828
At time: 736.7704102993011 and batch: 650, loss is 3.8038962268829346 and perplexity is 44.87569018615036
At time: 737.7701897621155 and batch: 700, loss is 3.8398336029052733 and perplexity is 46.51773338007443
At time: 738.7317454814911 and batch: 750, loss is 3.797013854980469 and perplexity is 44.56789937724438
At time: 739.6870782375336 and batch: 800, loss is 3.7737508964538575 and perplexity is 43.54308451104333
At time: 740.6432828903198 and batch: 850, loss is 3.768030605316162 and perplexity is 43.294716436706544
At time: 741.6110637187958 and batch: 900, loss is 3.719080662727356 and perplexity is 41.226475645672494
At time: 742.5832698345184 and batch: 950, loss is 3.828316583633423 and perplexity is 45.98506103495438
At time: 743.5427043437958 and batch: 1000, loss is 3.786050543785095 and perplexity is 44.08195626710263
At time: 744.5003468990326 and batch: 1050, loss is 3.7417695236206057 and perplexity is 42.17254950077168
At time: 745.4571108818054 and batch: 1100, loss is 3.7566440725326538 and perplexity is 42.80453575396439
At time: 746.4145085811615 and batch: 1150, loss is 3.742841806411743 and perplexity is 42.21779465332378
At time: 747.3742964267731 and batch: 1200, loss is 3.7968667459487917 and perplexity is 44.561343518947915
At time: 748.3277668952942 and batch: 1250, loss is 3.774780683517456 and perplexity is 43.58794771198933
At time: 749.2819809913635 and batch: 1300, loss is 3.781178660392761 and perplexity is 43.867716416002445
At time: 750.2385935783386 and batch: 1350, loss is 3.6517755794525146 and perplexity is 38.54304156062401
At time: 751.2233793735504 and batch: 1400, loss is 3.674106469154358 and perplexity is 39.41342400864211
At time: 752.1994411945343 and batch: 1450, loss is 3.6005467128753663 and perplexity is 36.61824864017497
At time: 753.1857237815857 and batch: 1500, loss is 3.608223671913147 and perplexity is 36.90044726269056
At time: 754.1751005649567 and batch: 1550, loss is 3.6189132499694825 and perplexity is 37.29701325941101
At time: 755.158474445343 and batch: 1600, loss is 3.7096853113174437 and perplexity is 40.84095231907983
At time: 756.1150403022766 and batch: 1650, loss is 3.653752131462097 and perplexity is 38.61929922566995
At time: 757.0709674358368 and batch: 1700, loss is 3.6691975927352907 and perplexity is 39.220422478824744
At time: 758.0293889045715 and batch: 1750, loss is 3.661411852836609 and perplexity is 38.91624811844388
At time: 758.9848396778107 and batch: 1800, loss is 3.6174541664123536 and perplexity is 37.242633482600816
At time: 759.9415910243988 and batch: 1850, loss is 3.636887135505676 and perplexity is 37.973446361512515
At time: 760.9055688381195 and batch: 1900, loss is 3.7241203689575197 and perplexity is 41.43476940063434
At time: 761.8821988105774 and batch: 1950, loss is 3.6745749568939208 and perplexity is 39.43189304048403
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.227101880450581 and perplexity of 68.51836972266891
finished 19 epochs...
Completing Train Step...
At time: 765.0265753269196 and batch: 50, loss is 3.8447580528259278 and perplexity is 46.74737258784988
At time: 765.9913606643677 and batch: 100, loss is 3.8319089460372924 and perplexity is 46.15055311514566
At time: 766.9483456611633 and batch: 150, loss is 3.804068098068237 and perplexity is 44.8834036870592
At time: 767.9057419300079 and batch: 200, loss is 3.797837748527527 and perplexity is 44.604633712460156
At time: 768.8616890907288 and batch: 250, loss is 3.792965178489685 and perplexity is 44.387823151962806
At time: 769.8447661399841 and batch: 300, loss is 3.78947874546051 and perplexity is 44.23333743776478
At time: 770.8017826080322 and batch: 350, loss is 3.805927939414978 and perplexity is 44.96695737123269
At time: 771.7626574039459 and batch: 400, loss is 3.772761526107788 and perplexity is 43.50002557857953
At time: 772.7188651561737 and batch: 450, loss is 3.816064591407776 and perplexity is 45.42508981101649
At time: 773.6729803085327 and batch: 500, loss is 3.8194086074829103 and perplexity is 45.577246306652526
At time: 774.6274774074554 and batch: 550, loss is 3.789807720184326 and perplexity is 44.24789148155684
At time: 775.5836124420166 and batch: 600, loss is 3.7717198944091797 and perplexity is 43.45473816354485
At time: 776.5384092330933 and batch: 650, loss is 3.801244173049927 and perplexity is 44.75683511467008
At time: 777.548238992691 and batch: 700, loss is 3.8373712968826292 and perplexity is 46.40333338670937
At time: 778.5303666591644 and batch: 750, loss is 3.7947274160385134 and perplexity is 44.46611400391057
At time: 779.4863758087158 and batch: 800, loss is 3.77159716129303 and perplexity is 43.44940515539362
At time: 780.451682806015 and batch: 850, loss is 3.7658656549453737 and perplexity is 43.20108691251049
At time: 781.4089863300323 and batch: 900, loss is 3.71735191822052 and perplexity is 41.15526717072799
At time: 782.364563703537 and batch: 950, loss is 3.826660895347595 and perplexity is 45.908987102813356
At time: 783.320229768753 and batch: 1000, loss is 3.7844771766662597 and perplexity is 44.0126537000646
At time: 784.2767186164856 and batch: 1050, loss is 3.74043740272522 and perplexity is 42.11640796832639
At time: 785.2377450466156 and batch: 1100, loss is 3.7555705738067626 and perplexity is 42.75860979451004
At time: 786.208242893219 and batch: 1150, loss is 3.741939706802368 and perplexity is 42.17972717017074
At time: 787.1756162643433 and batch: 1200, loss is 3.795960669517517 and perplexity is 44.52098582217944
At time: 788.1395845413208 and batch: 1250, loss is 3.774159049987793 and perplexity is 43.5608604022646
At time: 789.1064591407776 and batch: 1300, loss is 3.7806828784942628 and perplexity is 43.84597298671963
At time: 790.0668697357178 and batch: 1350, loss is 3.651458773612976 and perplexity is 38.53083283398409
At time: 791.0203242301941 and batch: 1400, loss is 3.6739067888259886 and perplexity is 39.405554708892225
At time: 791.9872965812683 and batch: 1450, loss is 3.600561146736145 and perplexity is 36.61877718669227
At time: 792.9605488777161 and batch: 1500, loss is 3.6085768699645997 and perplexity is 36.913482730676904
At time: 793.9296569824219 and batch: 1550, loss is 3.619372034072876 and perplexity is 37.31412846198971
At time: 794.8983380794525 and batch: 1600, loss is 3.7102818441390992 and perplexity is 40.86532255570616
At time: 795.8794033527374 and batch: 1650, loss is 3.6544158601760866 and perplexity is 38.64494047195456
At time: 796.8605453968048 and batch: 1700, loss is 3.6699361562728883 and perplexity is 39.24939995233224
At time: 797.8454253673553 and batch: 1750, loss is 3.6622498655319213 and perplexity is 38.94887409700384
At time: 798.8136587142944 and batch: 1800, loss is 3.6182674026489257 and perplexity is 37.2729328603003
At time: 799.7858469486237 and batch: 1850, loss is 3.637607383728027 and perplexity is 38.00080652062114
At time: 800.7770578861237 and batch: 1900, loss is 3.7247820234298707 and perplexity is 41.462193972914044
At time: 801.7714650630951 and batch: 1950, loss is 3.6751104688644407 and perplexity is 39.45301494623939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.226978390715843 and perplexity of 68.50990892978844
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
1665.0857589244843


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5699141025543213 and batch: 50, loss is 7.646170902252197 and perplexity is 2092.6173923096426
At time: 2.689575672149658 and batch: 100, loss is 6.8151095008850096 and perplexity is 911.5163221636132
At time: 3.8072988986968994 and batch: 150, loss is 6.436238851547241 and perplexity is 624.0552159457607
At time: 4.922485828399658 and batch: 200, loss is 6.3245007514953615 and perplexity is 558.079123934964
At time: 6.038233041763306 and batch: 250, loss is 6.239242248535156 and perplexity is 512.4700388561387
At time: 7.15515661239624 and batch: 300, loss is 6.165667915344239 and perplexity is 476.1190439732155
At time: 8.274776458740234 and batch: 350, loss is 6.07506667137146 and perplexity is 434.8784954955299
At time: 9.39817762374878 and batch: 400, loss is 6.009088115692139 and perplexity is 407.11191199485575
At time: 10.515829086303711 and batch: 450, loss is 5.911833944320679 and perplexity is 369.3829623925359
At time: 11.63711142539978 and batch: 500, loss is 5.878166646957397 and perplexity is 357.1538520108165
At time: 12.75615119934082 and batch: 550, loss is 5.819520320892334 and perplexity is 336.8104539371744
At time: 13.882530927658081 and batch: 600, loss is 5.846965608596801 and perplexity is 346.18233242972303
At time: 15.00441861152649 and batch: 650, loss is 5.9077219390869145 and perplexity is 367.8671763138748
At time: 16.127605438232422 and batch: 700, loss is 5.822021970748901 and perplexity is 337.65409056270414
At time: 17.24987006187439 and batch: 750, loss is 5.753620319366455 and perplexity is 315.33019230818434
At time: 18.37229013442993 and batch: 800, loss is 5.750373458862304 and perplexity is 314.3080194852837
At time: 19.494675159454346 and batch: 850, loss is 5.769089698791504 and perplexity is 320.2460795281922
At time: 20.61611580848694 and batch: 900, loss is 5.754692163467407 and perplexity is 315.66835831290547
At time: 21.7374906539917 and batch: 950, loss is 5.77552749633789 and perplexity is 322.31440955467264
At time: 22.858915328979492 and batch: 1000, loss is 5.750501928329467 and perplexity is 314.34840106291637
At time: 23.979960203170776 and batch: 1050, loss is 5.647009668350219 and perplexity is 283.4426098688643
At time: 25.098265647888184 and batch: 1100, loss is 5.732420949935913 and perplexity is 308.7157497904231
At time: 26.217721223831177 and batch: 1150, loss is 5.624284038543701 and perplexity is 277.0738393025569
At time: 27.338982820510864 and batch: 1200, loss is 5.688471183776856 and perplexity is 295.4415992897527
At time: 28.464646100997925 and batch: 1250, loss is 5.6412912940979005 and perplexity is 281.82640438462505
At time: 29.591066122055054 and batch: 1300, loss is 5.658895111083984 and perplexity is 286.8315504117012
At time: 30.710464477539062 and batch: 1350, loss is 5.6133583068847654 and perplexity is 274.0630821965924
At time: 31.83244562149048 and batch: 1400, loss is 5.6290148258209225 and perplexity is 278.38772209595317
At time: 32.956852436065674 and batch: 1450, loss is 5.591798534393311 and perplexity is 268.21758471941746
At time: 34.077597856521606 and batch: 1500, loss is 5.560771284103393 and perplexity is 260.02331084777416
At time: 35.1973512172699 and batch: 1550, loss is 5.529169387817383 and perplexity is 251.93456417430158
At time: 36.316405296325684 and batch: 1600, loss is 5.554986667633057 and perplexity is 258.52351776719485
At time: 37.43605709075928 and batch: 1650, loss is 5.545300989151001 and perplexity is 256.0316293896694
At time: 38.557778120040894 and batch: 1700, loss is 5.562271203994751 and perplexity is 260.4136176252063
At time: 39.679219007492065 and batch: 1750, loss is 5.570751094818116 and perplexity is 262.6312861760878
At time: 40.798792362213135 and batch: 1800, loss is 5.561101808547973 and perplexity is 260.10926911304136
At time: 41.9196195602417 and batch: 1850, loss is 5.536306571960449 and perplexity is 253.73909954126455
At time: 43.040616035461426 and batch: 1900, loss is 5.549237337112427 and perplexity is 257.0414451612944
At time: 44.16101408004761 and batch: 1950, loss is 5.482686338424682 and perplexity is 240.49188299234717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.085810319767442 and perplexity of 161.71092371887627
finished 1 epochs...
Completing Train Step...
At time: 47.37693119049072 and batch: 50, loss is 5.316390352249146 and perplexity is 203.64745808807345
At time: 48.350544452667236 and batch: 100, loss is 5.242187252044678 and perplexity is 189.08322310777262
At time: 49.31229043006897 and batch: 150, loss is 5.1666206359863285 and perplexity is 175.32136056486974
At time: 50.2651846408844 and batch: 200, loss is 5.124336738586425 and perplexity is 168.06263521597268
At time: 51.2227680683136 and batch: 250, loss is 5.12692626953125 and perplexity is 168.49840258356542
At time: 52.175540924072266 and batch: 300, loss is 5.1311118602752686 and perplexity is 169.2051459753044
At time: 53.147263050079346 and batch: 350, loss is 5.121443290710449 and perplexity is 167.57705757664348
At time: 54.09956192970276 and batch: 400, loss is 5.072121505737305 and perplexity is 159.51237505027237
At time: 55.05543041229248 and batch: 450, loss is 5.0257309055328365 and perplexity is 152.28151885111777
At time: 56.016151905059814 and batch: 500, loss is 5.0140892696380615 and perplexity is 150.51899210833287
At time: 56.99406051635742 and batch: 550, loss is 4.963024845123291 and perplexity is 143.0257730477373
At time: 57.96639704704285 and batch: 600, loss is 4.949554605484009 and perplexity is 141.11209936755398
At time: 58.928075551986694 and batch: 650, loss is 5.010323534011841 and perplexity is 149.9532432761565
At time: 59.891074657440186 and batch: 700, loss is 5.000853538513184 and perplexity is 148.53988952668888
At time: 60.852477073669434 and batch: 750, loss is 4.946943531036377 and perplexity is 140.74412578291717
At time: 61.83548140525818 and batch: 800, loss is 4.932806310653686 and perplexity is 138.76839364535172
At time: 62.79666328430176 and batch: 850, loss is 4.926394729614258 and perplexity is 137.88151502901954
At time: 63.770370960235596 and batch: 900, loss is 4.9182960891723635 and perplexity is 136.76937171820873
At time: 64.7475836277008 and batch: 950, loss is 4.973994092941284 and perplexity is 144.60329449065264
At time: 65.71201539039612 and batch: 1000, loss is 4.945670747756958 and perplexity is 140.56510296573623
At time: 66.67171025276184 and batch: 1050, loss is 4.853707933425904 and perplexity is 128.2149219303796
At time: 67.63262248039246 and batch: 1100, loss is 4.92091570854187 and perplexity is 137.1281251070209
At time: 68.59274673461914 and batch: 1150, loss is 4.834284181594849 and perplexity is 125.74853786483669
At time: 69.5894045829773 and batch: 1200, loss is 4.923962106704712 and perplexity is 137.54650893371237
At time: 70.5894706249237 and batch: 1250, loss is 4.871939353942871 and perplexity is 130.57390051357694
At time: 71.57412910461426 and batch: 1300, loss is 4.895070190429688 and perplexity is 133.6293857893862
At time: 72.5622615814209 and batch: 1350, loss is 4.797921028137207 and perplexity is 121.25806318934454
At time: 73.54223084449768 and batch: 1400, loss is 4.816942663192749 and perplexity is 123.58666652494075
At time: 74.54623246192932 and batch: 1450, loss is 4.7603652286529545 and perplexity is 116.78857264367643
At time: 75.53375244140625 and batch: 1500, loss is 4.737869853973389 and perplexity is 114.19069955975307
At time: 76.5239508152008 and batch: 1550, loss is 4.732089529037475 and perplexity is 113.53254422003079
At time: 77.4902720451355 and batch: 1600, loss is 4.7894864273071285 and perplexity is 120.23960102779803
At time: 78.50217318534851 and batch: 1650, loss is 4.751527891159058 and perplexity is 115.76101971532687
At time: 79.49989128112793 and batch: 1700, loss is 4.780340509414673 and perplexity is 119.14491310299228
At time: 80.47351384162903 and batch: 1750, loss is 4.777903699874878 and perplexity is 118.85493309863813
At time: 81.47177910804749 and batch: 1800, loss is 4.731762027740478 and perplexity is 113.49536825246841
At time: 82.45589780807495 and batch: 1850, loss is 4.73967472076416 and perplexity is 114.3969846637717
At time: 83.43544793128967 and batch: 1900, loss is 4.81950309753418 and perplexity is 123.90350752224322
At time: 84.43546676635742 and batch: 1950, loss is 4.742632703781128 and perplexity is 114.73586996298502
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.609292957394622 and perplexity of 100.41312817199058
finished 2 epochs...
Completing Train Step...
At time: 87.71789288520813 and batch: 50, loss is 4.715830106735229 and perplexity is 111.70149686375973
At time: 88.70842218399048 and batch: 100, loss is 4.664459142684937 and perplexity is 106.10818031393146
At time: 89.68972492218018 and batch: 150, loss is 4.618343029022217 and perplexity is 101.32599871557927
At time: 90.67747855186462 and batch: 200, loss is 4.607952184677124 and perplexity is 100.27858720384373
At time: 91.68375563621521 and batch: 250, loss is 4.611413249969482 and perplexity is 100.62625925234897
At time: 92.68718409538269 and batch: 300, loss is 4.630127410888672 and perplexity is 102.52712635062134
At time: 93.66048049926758 and batch: 350, loss is 4.646342210769653 and perplexity is 104.2031345342757
At time: 94.64527678489685 and batch: 400, loss is 4.597263689041138 and perplexity is 99.21246771865313
At time: 95.62908101081848 and batch: 450, loss is 4.594296503067016 and perplexity is 98.91852218717217
At time: 96.6393096446991 and batch: 500, loss is 4.600040168762207 and perplexity is 99.48831188401364
At time: 97.59726691246033 and batch: 550, loss is 4.557343187332154 and perplexity is 95.32986947679551
At time: 98.5526328086853 and batch: 600, loss is 4.53639663696289 and perplexity is 93.35380567470347
At time: 99.52882051467896 and batch: 650, loss is 4.6078519439697265 and perplexity is 100.26853571111835
At time: 100.52527093887329 and batch: 700, loss is 4.6215165424346925 and perplexity is 101.64806890827138
At time: 101.51092576980591 and batch: 750, loss is 4.579616928100586 and perplexity is 97.47704633676145
At time: 102.5161406993866 and batch: 800, loss is 4.565908765792846 and perplexity is 96.14993209486121
At time: 103.48707675933838 and batch: 850, loss is 4.55214370727539 and perplexity is 94.83549009328785
At time: 104.45230913162231 and batch: 900, loss is 4.539894914627075 and perplexity is 93.68095510409637
At time: 105.4088978767395 and batch: 950, loss is 4.614181003570557 and perplexity is 100.90515372130439
At time: 106.36531114578247 and batch: 1000, loss is 4.5934115982055665 and perplexity is 98.83102742398141
At time: 107.32079219818115 and batch: 1050, loss is 4.513493490219116 and perplexity is 91.24000846733965
At time: 108.27711248397827 and batch: 1100, loss is 4.573106641769409 and perplexity is 96.84450410404602
At time: 109.23377323150635 and batch: 1150, loss is 4.514160232543945 and perplexity is 91.30086232737027
At time: 110.19087743759155 and batch: 1200, loss is 4.594641056060791 and perplexity is 98.95261073244943
At time: 111.14822459220886 and batch: 1250, loss is 4.561154222488403 and perplexity is 95.6938681260776
At time: 112.1078085899353 and batch: 1300, loss is 4.573141164779663 and perplexity is 96.84784752556641
At time: 113.06284284591675 and batch: 1350, loss is 4.462371759414673 and perplexity is 86.69288010932517
At time: 114.0197229385376 and batch: 1400, loss is 4.490279340744019 and perplexity is 89.1463446071112
At time: 115.00502514839172 and batch: 1450, loss is 4.429254951477051 and perplexity is 83.86890722133812
At time: 115.965003490448 and batch: 1500, loss is 4.41930853843689 and perplexity is 83.03884733136371
At time: 116.92171931266785 and batch: 1550, loss is 4.423977699279785 and perplexity is 83.42747564376957
At time: 117.87852954864502 and batch: 1600, loss is 4.491835899353028 and perplexity is 89.2852141685381
At time: 118.8653073310852 and batch: 1650, loss is 4.458661069869995 and perplexity is 86.3717858544873
At time: 119.82224488258362 and batch: 1700, loss is 4.478335771560669 and perplexity is 88.0879521461523
At time: 120.77693724632263 and batch: 1750, loss is 4.483387060165406 and perplexity is 88.53403551445672
At time: 121.73362851142883 and batch: 1800, loss is 4.436187467575073 and perplexity is 84.45234979662135
At time: 122.69024729728699 and batch: 1850, loss is 4.463213157653809 and perplexity is 86.76585404175877
At time: 123.6644537448883 and batch: 1900, loss is 4.549526681900025 and perplexity is 94.58762768180247
At time: 124.62832713127136 and batch: 1950, loss is 4.478092861175537 and perplexity is 88.06655726639545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462725688135901 and perplexity of 86.72356863997773
finished 3 epochs...
Completing Train Step...
At time: 127.76101779937744 and batch: 50, loss is 4.459608240127563 and perplexity is 86.45363339680158
At time: 128.73540019989014 and batch: 100, loss is 4.408264389038086 and perplexity is 82.12679956187685
At time: 129.6948323249817 and batch: 150, loss is 4.371599702835083 and perplexity is 79.17017921351116
At time: 130.64960622787476 and batch: 200, loss is 4.368747415542603 and perplexity is 78.94468485761656
At time: 131.60233068466187 and batch: 250, loss is 4.367445116043091 and perplexity is 78.84194214944688
At time: 132.55532789230347 and batch: 300, loss is 4.387675256729126 and perplexity is 80.45316844813105
At time: 133.51012349128723 and batch: 350, loss is 4.399619255065918 and perplexity is 81.41986256243017
At time: 134.49637007713318 and batch: 400, loss is 4.35998682975769 and perplexity is 78.25610376444847
At time: 135.45178842544556 and batch: 450, loss is 4.371762371063232 and perplexity is 79.18305873380201
At time: 136.4110095500946 and batch: 500, loss is 4.3820413303375245 and perplexity is 80.00117566172997
At time: 137.38856101036072 and batch: 550, loss is 4.339719915390015 and perplexity is 76.68605774552933
At time: 138.35504817962646 and batch: 600, loss is 4.321746273040771 and perplexity is 75.32004287605926
At time: 139.3112931251526 and batch: 650, loss is 4.388872528076172 and perplexity is 80.54955040765907
At time: 140.26328778266907 and batch: 700, loss is 4.416146411895752 and perplexity is 82.77668270558196
At time: 141.21889233589172 and batch: 750, loss is 4.378201208114624 and perplexity is 79.69455048509556
At time: 142.17461919784546 and batch: 800, loss is 4.360949983596802 and perplexity is 78.33151274061605
At time: 143.13095474243164 and batch: 850, loss is 4.34454047203064 and perplexity is 77.05661967022561
At time: 144.0871753692627 and batch: 900, loss is 4.333766012191773 and perplexity is 76.23083290813518
At time: 145.0474898815155 and batch: 950, loss is 4.412898426055908 and perplexity is 82.50826136261944
At time: 146.00360536575317 and batch: 1000, loss is 4.396957063674927 and perplexity is 81.20339557138732
At time: 146.95978474617004 and batch: 1050, loss is 4.327629022598266 and perplexity is 75.7644376750251
At time: 147.920156955719 and batch: 1100, loss is 4.37565245628357 and perplexity is 79.49168748715913
At time: 148.87613487243652 and batch: 1150, loss is 4.328404984474182 and perplexity is 75.82325080563366
At time: 149.83153653144836 and batch: 1200, loss is 4.406510801315307 and perplexity is 81.98290921350093
At time: 150.82729983329773 and batch: 1250, loss is 4.379632797241211 and perplexity is 79.80872204089812
At time: 151.78166961669922 and batch: 1300, loss is 4.384292554855347 and perplexity is 80.18147914549759
At time: 152.73766326904297 and batch: 1350, loss is 4.27307758808136 and perplexity is 71.74208881061476
At time: 153.69211840629578 and batch: 1400, loss is 4.306837844848633 and perplexity is 74.20546834639863
At time: 154.67131900787354 and batch: 1450, loss is 4.238342804908752 and perplexity is 69.29292474200624
At time: 155.63233041763306 and batch: 1500, loss is 4.236545543670655 and perplexity is 69.16849910047705
At time: 156.58716464042664 and batch: 1550, loss is 4.246349296569824 and perplexity is 69.84994487907146
At time: 157.54268884658813 and batch: 1600, loss is 4.320307922363281 and perplexity is 75.21178411705388
At time: 158.4987871646881 and batch: 1650, loss is 4.284300212860107 and perplexity is 72.55175816389817
At time: 159.46345114707947 and batch: 1700, loss is 4.303438863754272 and perplexity is 73.95367352772219
At time: 160.41920137405396 and batch: 1750, loss is 4.310646009445191 and perplexity is 74.48859373570865
At time: 161.3743453025818 and batch: 1800, loss is 4.262790999412537 and perplexity is 71.00789012673339
At time: 162.32907271385193 and batch: 1850, loss is 4.295749158859253 and perplexity is 73.38717250673318
At time: 163.28385400772095 and batch: 1900, loss is 4.383911342620849 and perplexity is 80.1509188100242
At time: 164.2382333278656 and batch: 1950, loss is 4.3110207748413085 and perplexity is 74.51651471462785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.405103390715843 and perplexity of 81.86760675608194
finished 4 epochs...
Completing Train Step...
At time: 167.35097908973694 and batch: 50, loss is 4.294899802207947 and perplexity is 73.32486708715098
At time: 168.33615159988403 and batch: 100, loss is 4.254495334625244 and perplexity is 70.42126904309556
At time: 169.29860663414001 and batch: 150, loss is 4.214704732894898 and perplexity is 67.67418096113128
At time: 170.25374507904053 and batch: 200, loss is 4.216656875610352 and perplexity is 67.80641965292303
At time: 171.209645986557 and batch: 250, loss is 4.209331340789795 and perplexity is 67.31151629377698
At time: 172.16539859771729 and batch: 300, loss is 4.2295154142379765 and perplexity is 68.68394084843196
At time: 173.125314950943 and batch: 350, loss is 4.241895542144776 and perplexity is 69.53954211990174
At time: 174.1189546585083 and batch: 400, loss is 4.20097216129303 and perplexity is 66.75119243349657
At time: 175.0807240009308 and batch: 450, loss is 4.221302156448364 and perplexity is 68.12213223391205
At time: 176.03455233573914 and batch: 500, loss is 4.238936080932617 and perplexity is 69.33404677002959
At time: 176.99093890190125 and batch: 550, loss is 4.198788590431214 and perplexity is 66.60559549317583
At time: 177.94651651382446 and batch: 600, loss is 4.179545512199402 and perplexity is 65.33615198108374
At time: 178.90703463554382 and batch: 650, loss is 4.245302572250366 and perplexity is 69.77686949461672
At time: 179.86452960968018 and batch: 700, loss is 4.277323594093323 and perplexity is 72.04735377081953
At time: 180.82020235061646 and batch: 750, loss is 4.239908361434937 and perplexity is 69.40149169423027
At time: 181.7770552635193 and batch: 800, loss is 4.222988548278809 and perplexity is 68.23710976251739
At time: 182.72928643226624 and batch: 850, loss is 4.20426203250885 and perplexity is 66.97115688907645
At time: 183.68239903450012 and batch: 900, loss is 4.191975712776184 and perplexity is 66.15336197496755
At time: 184.6396951675415 and batch: 950, loss is 4.278402070999146 and perplexity is 72.12509709264023
At time: 185.59799981117249 and batch: 1000, loss is 4.259630298614502 and perplexity is 70.78380974381304
At time: 186.5695095062256 and batch: 1050, loss is 4.200559406280518 and perplexity is 66.72364622953646
At time: 187.5378725528717 and batch: 1100, loss is 4.241812419891358 and perplexity is 69.53376207668751
At time: 188.50071573257446 and batch: 1150, loss is 4.197660555839539 and perplexity is 66.5305044380768
At time: 189.47146558761597 and batch: 1200, loss is 4.276339392662049 and perplexity is 71.976479545097
At time: 190.42835187911987 and batch: 1250, loss is 4.254089584350586 and perplexity is 70.39270138989805
At time: 191.38503527641296 and batch: 1300, loss is 4.256134495735169 and perplexity is 70.53679550599827
At time: 192.3419587612152 and batch: 1350, loss is 4.139487295150757 and perplexity is 62.7706303910595
At time: 193.2977385520935 and batch: 1400, loss is 4.173536410331726 and perplexity is 64.9447176504389
At time: 194.27498769760132 and batch: 1450, loss is 4.1066665363311765 and perplexity is 60.743892144279044
At time: 195.24027299880981 and batch: 1500, loss is 4.107557964324951 and perplexity is 60.79806509224111
At time: 196.201397895813 and batch: 1550, loss is 4.118645763397216 and perplexity is 61.47593290833624
At time: 197.15810632705688 and batch: 1600, loss is 4.200073318481445 and perplexity is 66.69122056069412
At time: 198.11442255973816 and batch: 1650, loss is 4.157900066375732 and perplexity is 63.937117825214465
At time: 199.09242248535156 and batch: 1700, loss is 4.180449695587158 and perplexity is 65.39525456008339
At time: 200.05560564994812 and batch: 1750, loss is 4.189170889854431 and perplexity is 65.96807348112897
At time: 201.0147967338562 and batch: 1800, loss is 4.139460015296936 and perplexity is 62.7689180407946
At time: 201.97786903381348 and batch: 1850, loss is 4.176270833015442 and perplexity is 65.12254697904129
At time: 202.93416237831116 and batch: 1900, loss is 4.263803420066833 and perplexity is 71.07981638498674
At time: 203.88975477218628 and batch: 1950, loss is 4.1900148725509645 and perplexity is 66.02377289503522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377865529614826 and perplexity of 79.66780322743743
finished 5 epochs...
Completing Train Step...
At time: 207.09386825561523 and batch: 50, loss is 4.1785422134399415 and perplexity is 65.2706331738182
At time: 208.0794677734375 and batch: 100, loss is 4.138916873931885 and perplexity is 62.73483490178637
At time: 209.03939366340637 and batch: 150, loss is 4.102294335365295 and perplexity is 60.47888738955229
At time: 210.01915454864502 and batch: 200, loss is 4.105832934379578 and perplexity is 60.69327701660548
At time: 210.98197150230408 and batch: 250, loss is 4.100305972099304 and perplexity is 60.35875286661527
At time: 211.943932056427 and batch: 300, loss is 4.109224200248718 and perplexity is 60.899453457404064
At time: 212.907475233078 and batch: 350, loss is 4.125764784812927 and perplexity is 61.915142909016154
At time: 213.86946988105774 and batch: 400, loss is 4.085663275718689 and perplexity is 59.48137722340232
At time: 214.84613275527954 and batch: 450, loss is 4.112418255805969 and perplexity is 61.09428067399473
At time: 215.83256554603577 and batch: 500, loss is 4.129968733787536 and perplexity is 62.17597889700328
At time: 216.82010912895203 and batch: 550, loss is 4.087200856208801 and perplexity is 59.57290497615734
At time: 217.77410554885864 and batch: 600, loss is 4.073018755912781 and perplexity is 58.733998849132675
At time: 218.75900268554688 and batch: 650, loss is 4.141224865913391 and perplexity is 62.87979361512732
At time: 219.76755166053772 and batch: 700, loss is 4.1705827808380125 and perplexity is 64.75317802471766
At time: 220.72479391098022 and batch: 750, loss is 4.139058237075806 and perplexity is 62.74370392214295
At time: 221.68116974830627 and batch: 800, loss is 4.118987083435059 and perplexity is 61.496919457444015
At time: 222.65819764137268 and batch: 850, loss is 4.102724671363831 and perplexity is 60.50491923276527
At time: 223.61576390266418 and batch: 900, loss is 4.0882577085494995 and perplexity is 59.63589802153407
At time: 224.5738182067871 and batch: 950, loss is 4.178541855812073 and perplexity is 65.27060983122495
At time: 225.56755471229553 and batch: 1000, loss is 4.158541860580445 and perplexity is 63.97816546756124
At time: 226.5722770690918 and batch: 1050, loss is 4.104505972862244 and perplexity is 60.61279278519237
At time: 227.53259205818176 and batch: 1100, loss is 4.141489019393921 and perplexity is 62.896405725442555
At time: 228.48809504508972 and batch: 1150, loss is 4.099483771324158 and perplexity is 60.309146249315646
At time: 229.44467091560364 and batch: 1200, loss is 4.180906748771667 and perplexity is 65.42515050092891
At time: 230.4011037349701 and batch: 1250, loss is 4.155911803245544 and perplexity is 63.8101203052725
At time: 231.35630655288696 and batch: 1300, loss is 4.158940615653992 and perplexity is 64.00368217275741
At time: 232.3125991821289 and batch: 1350, loss is 4.044943766593933 and perplexity is 57.107974567926384
At time: 233.26946425437927 and batch: 1400, loss is 4.079899754524231 and perplexity is 59.13954108128865
At time: 234.22629165649414 and batch: 1450, loss is 4.006762442588806 and perplexity is 54.968618110941456
At time: 235.2151117324829 and batch: 1500, loss is 4.013807544708252 and perplexity is 55.35724498951397
At time: 236.1781404018402 and batch: 1550, loss is 4.022464942932129 and perplexity is 55.838575231429125
At time: 237.13308715820312 and batch: 1600, loss is 4.104615206718445 and perplexity is 60.619414115913585
At time: 238.08851170539856 and batch: 1650, loss is 4.064662046432495 and perplexity is 58.245221015775414
At time: 239.0735845565796 and batch: 1700, loss is 4.0918977832794186 and perplexity is 59.85337271886248
At time: 240.03388452529907 and batch: 1750, loss is 4.0955514812469485 and perplexity is 60.07245885868278
At time: 240.98941588401794 and batch: 1800, loss is 4.048286924362182 and perplexity is 57.299215032134086
At time: 241.94647336006165 and batch: 1850, loss is 4.086031303405762 and perplexity is 59.50327204578906
At time: 242.90341591835022 and batch: 1900, loss is 4.173644070625305 and perplexity is 64.95170999419969
At time: 243.8589608669281 and batch: 1950, loss is 4.097209634780884 and perplexity is 60.172150848102085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363924248273983 and perplexity of 78.56483820591085
finished 6 epochs...
Completing Train Step...
At time: 247.002299785614 and batch: 50, loss is 4.084901604652405 and perplexity is 59.43608922885553
At time: 247.98729848861694 and batch: 100, loss is 4.050953278541565 and perplexity is 57.452198897558965
At time: 248.97466039657593 and batch: 150, loss is 4.015537257194519 and perplexity is 55.45307996696216
At time: 249.97487139701843 and batch: 200, loss is 4.017471046447754 and perplexity is 55.56041828845764
At time: 250.94299411773682 and batch: 250, loss is 4.012276139259338 and perplexity is 55.27253548175615
At time: 251.91586995124817 and batch: 300, loss is 4.019090137481689 and perplexity is 55.650448527459055
At time: 252.91472721099854 and batch: 350, loss is 4.035418744087219 and perplexity is 56.566602209843616
At time: 253.88752794265747 and batch: 400, loss is 3.994364848136902 and perplexity is 54.29134642061465
At time: 254.87278938293457 and batch: 450, loss is 4.02306252002716 and perplexity is 55.87195305692534
At time: 255.87328147888184 and batch: 500, loss is 4.048891572952271 and perplexity is 57.333871398121985
At time: 256.866996049881 and batch: 550, loss is 4.004698939323426 and perplexity is 54.855307136965436
At time: 257.84981632232666 and batch: 600, loss is 3.994110779762268 and perplexity is 54.27755445859775
At time: 258.8626661300659 and batch: 650, loss is 4.055377869606018 and perplexity is 57.70696458479698
At time: 259.8327615261078 and batch: 700, loss is 4.0874134016036985 and perplexity is 59.585568268485254
At time: 260.80342388153076 and batch: 750, loss is 4.059295558929444 and perplexity is 57.933485974326516
At time: 261.773473739624 and batch: 800, loss is 4.037075567245483 and perplexity is 56.66040074870798
At time: 262.73958802223206 and batch: 850, loss is 4.023150825500489 and perplexity is 55.876887074032965
At time: 263.70608830451965 and batch: 900, loss is 4.009129948616028 and perplexity is 55.09891081915473
At time: 264.6811399459839 and batch: 950, loss is 4.105911011695862 and perplexity is 60.6980159697914
At time: 265.64690017700195 and batch: 1000, loss is 4.08215072631836 and perplexity is 59.272812458963976
At time: 266.6111783981323 and batch: 1050, loss is 4.029971327781677 and perplexity is 56.25929814512323
At time: 267.57932329177856 and batch: 1100, loss is 4.060709843635559 and perplexity is 58.01547838415078
At time: 268.5666651725769 and batch: 1150, loss is 4.018899021148681 and perplexity is 55.639813834070395
At time: 269.535432100296 and batch: 1200, loss is 4.102524461746216 and perplexity is 60.49280677857726
At time: 270.5031039714813 and batch: 1250, loss is 4.07809769153595 and perplexity is 59.033063871296534
At time: 271.4729588031769 and batch: 1300, loss is 4.081209816932678 and perplexity is 59.21706834259931
At time: 272.44284558296204 and batch: 1350, loss is 3.9629312467575075 and perplexity is 52.61131689816977
At time: 273.4120981693268 and batch: 1400, loss is 4.001935758590698 and perplexity is 54.70394123118262
At time: 274.3779044151306 and batch: 1450, loss is 3.93316632270813 and perplexity is 51.06842104463001
At time: 275.3383824825287 and batch: 1500, loss is 3.937633113861084 and perplexity is 51.29704323961984
At time: 276.2908716201782 and batch: 1550, loss is 3.94660448551178 and perplexity is 51.75931860060363
At time: 277.24444365501404 and batch: 1600, loss is 4.0290489721298215 and perplexity is 56.207430987169914
At time: 278.2020916938782 and batch: 1650, loss is 3.9908805322647094 and perplexity is 54.102507399008026
At time: 279.15591979026794 and batch: 1700, loss is 4.020012125968933 and perplexity is 55.701781260769565
At time: 280.1104121208191 and batch: 1750, loss is 4.019466714859009 and perplexity is 55.67140917381709
At time: 281.0636763572693 and batch: 1800, loss is 3.9749762058258056 and perplexity is 53.24884987825208
At time: 282.0164315700531 and batch: 1850, loss is 4.014508829116822 and perplexity is 55.39607977785071
At time: 282.9691126346588 and batch: 1900, loss is 4.098058204650879 and perplexity is 60.22323279255885
At time: 283.92330622673035 and batch: 1950, loss is 4.024720826148987 and perplexity is 55.96468272455541
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360343329851017 and perplexity of 78.28400704620962
finished 7 epochs...
Completing Train Step...
At time: 287.0784523487091 and batch: 50, loss is 4.012484354972839 and perplexity is 55.28404529038842
At time: 288.0348002910614 and batch: 100, loss is 3.9791974020004273 and perplexity is 53.47409879512796
At time: 289.00946712493896 and batch: 150, loss is 3.9436655473709106 and perplexity is 51.60742447806825
At time: 289.9813175201416 and batch: 200, loss is 3.948419051170349 and perplexity is 51.85332454683405
At time: 290.93707394599915 and batch: 250, loss is 3.9432247638702393 and perplexity is 51.58468178951535
At time: 291.896812915802 and batch: 300, loss is 3.945194411277771 and perplexity is 51.68638555166606
At time: 292.8530671596527 and batch: 350, loss is 3.9629521274566653 and perplexity is 52.612415470719654
At time: 293.83695125579834 and batch: 400, loss is 3.9256493520736693 and perplexity is 50.68598042156648
At time: 294.80831265449524 and batch: 450, loss is 3.95272919178009 and perplexity is 52.077302007145626
At time: 295.77967739105225 and batch: 500, loss is 3.978014073371887 and perplexity is 53.410858787373535
At time: 296.7499041557312 and batch: 550, loss is 3.941782760620117 and perplexity is 51.5103501168554
At time: 297.7088317871094 and batch: 600, loss is 3.930160789489746 and perplexity is 50.9151636342563
At time: 298.6645987033844 and batch: 650, loss is 3.991790943145752 and perplexity is 54.151785338618325
At time: 299.62044310569763 and batch: 700, loss is 4.020489468574524 and perplexity is 55.728376441173964
At time: 300.5768916606903 and batch: 750, loss is 3.994667625427246 and perplexity is 54.30778709617902
At time: 301.5332896709442 and batch: 800, loss is 3.97363073348999 and perplexity is 53.177253200302594
At time: 302.48973512649536 and batch: 850, loss is 3.959461727142334 and perplexity is 52.42909719242326
At time: 303.44982981681824 and batch: 900, loss is 3.938664689064026 and perplexity is 51.34998730060528
At time: 304.4058964252472 and batch: 950, loss is 4.038991303443908 and perplexity is 56.76905116898178
At time: 305.36286997795105 and batch: 1000, loss is 4.0134492683410645 and perplexity is 55.33741534933947
At time: 306.3178915977478 and batch: 1050, loss is 3.966040930747986 and perplexity is 52.77517611118666
At time: 307.2746741771698 and batch: 1100, loss is 3.995449113845825 and perplexity is 54.35024459069263
At time: 308.230144739151 and batch: 1150, loss is 3.949161024093628 and perplexity is 51.8918125864057
At time: 309.2277297973633 and batch: 1200, loss is 4.033743062019348 and perplexity is 56.471893941514665
At time: 310.20876002311707 and batch: 1250, loss is 4.014226183891297 and perplexity is 55.380424552930215
At time: 311.1781208515167 and batch: 1300, loss is 4.016536688804626 and perplexity is 55.50852923221763
At time: 312.1502335071564 and batch: 1350, loss is 3.899763584136963 and perplexity is 49.390770963392164
At time: 313.12106561660767 and batch: 1400, loss is 3.940004868507385 and perplexity is 51.418851632976455
At time: 314.08920192718506 and batch: 1450, loss is 3.868116397857666 and perplexity is 47.852166695077486
At time: 315.0696589946747 and batch: 1500, loss is 3.8743459367752076 and perplexity is 48.15119406407662
At time: 316.04134345054626 and batch: 1550, loss is 3.8842028427124022 and perplexity is 48.628162710477085
At time: 317.00073170661926 and batch: 1600, loss is 3.9712807083129884 and perplexity is 53.05243204031735
At time: 317.9845871925354 and batch: 1650, loss is 3.93338397026062 and perplexity is 51.07953717113488
At time: 318.9608793258667 and batch: 1700, loss is 3.9584324312210084 and perplexity is 52.375159900003844
At time: 319.9400804042816 and batch: 1750, loss is 3.958450355529785 and perplexity is 52.376098696955744
At time: 320.9284691810608 and batch: 1800, loss is 3.9118411779403686 and perplexity is 49.99090945209191
At time: 321.8888187408447 and batch: 1850, loss is 3.955496768951416 and perplexity is 52.22162958605826
At time: 322.8447244167328 and batch: 1900, loss is 4.036227135658264 and perplexity is 56.61234866230474
At time: 323.8326072692871 and batch: 1950, loss is 3.965378875732422 and perplexity is 52.74024760471725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3646595089934594 and perplexity of 78.62262508698424
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 326.97762060165405 and batch: 50, loss is 3.9788120651245116 and perplexity is 53.45349722248358
At time: 327.9564871788025 and batch: 100, loss is 3.968425784111023 and perplexity is 52.90118736687942
At time: 328.9369149208069 and batch: 150, loss is 3.9372079181671142 and perplexity is 51.2752365940954
At time: 329.89371943473816 and batch: 200, loss is 3.944239168167114 and perplexity is 51.63703606208563
At time: 330.85013723373413 and batch: 250, loss is 3.936210985183716 and perplexity is 51.224144091635274
At time: 331.80650639533997 and batch: 300, loss is 3.939885182380676 and perplexity is 51.412697878051574
At time: 332.7629039287567 and batch: 350, loss is 3.9511256551742555 and perplexity is 51.99386106522597
At time: 333.73169779777527 and batch: 400, loss is 3.909131669998169 and perplexity is 49.85564202273549
At time: 334.71508860588074 and batch: 450, loss is 3.9247616815567015 and perplexity is 50.641007934451125
At time: 335.67078733444214 and batch: 500, loss is 3.9267844676971437 and perplexity is 50.74354753631858
At time: 336.6557400226593 and batch: 550, loss is 3.893815960884094 and perplexity is 49.09788511625419
At time: 337.6202745437622 and batch: 600, loss is 3.8760756778717043 and perplexity is 48.23455523913507
At time: 338.5767436027527 and batch: 650, loss is 3.9314689874649047 and perplexity is 50.98181433487792
At time: 339.534060716629 and batch: 700, loss is 3.96320237159729 and perplexity is 52.6255830669035
At time: 340.49507236480713 and batch: 750, loss is 3.922756381034851 and perplexity is 50.53955924636242
At time: 341.49477076530457 and batch: 800, loss is 3.8965778875350954 and perplexity is 49.233677311384675
At time: 342.49871039390564 and batch: 850, loss is 3.8780743741989134 and perplexity is 48.331057875142555
At time: 343.51638627052307 and batch: 900, loss is 3.8495737314224243 and perplexity is 46.97303583418799
At time: 344.5182144641876 and batch: 950, loss is 3.9586084127426147 and perplexity is 52.38437777140115
At time: 345.498637676239 and batch: 1000, loss is 3.9215221548080446 and perplexity is 50.47722047483617
At time: 346.48097681999207 and batch: 1050, loss is 3.8614042615890503 and perplexity is 47.5320519601699
At time: 347.47511076927185 and batch: 1100, loss is 3.878245334625244 and perplexity is 48.33932127973936
At time: 348.481041431427 and batch: 1150, loss is 3.831360788345337 and perplexity is 46.12526226678741
At time: 349.48445534706116 and batch: 1200, loss is 3.906821537017822 and perplexity is 49.740601790121524
At time: 350.4843101501465 and batch: 1250, loss is 3.8794302272796632 and perplexity is 48.39663213334283
At time: 351.4753408432007 and batch: 1300, loss is 3.880172028541565 and perplexity is 48.432546135010156
At time: 352.4851427078247 and batch: 1350, loss is 3.76237190246582 and perplexity is 43.05041636405251
At time: 353.4474754333496 and batch: 1400, loss is 3.7941064500808714 and perplexity is 44.438510632109605
At time: 354.40917444229126 and batch: 1450, loss is 3.7157581663131714 and perplexity is 41.08972812553902
At time: 355.372505903244 and batch: 1500, loss is 3.7114130783081056 and perplexity is 40.911576962258614
At time: 356.35646295547485 and batch: 1550, loss is 3.716859903335571 and perplexity is 41.13502314727477
At time: 357.349889755249 and batch: 1600, loss is 3.795951132774353 and perplexity is 44.52056123899682
At time: 358.3203363418579 and batch: 1650, loss is 3.746437873840332 and perplexity is 42.36988599103637
At time: 359.3020889759064 and batch: 1700, loss is 3.7627437353134154 and perplexity is 43.06642689939632
At time: 360.3048870563507 and batch: 1750, loss is 3.7615520668029787 and perplexity is 43.01513656121341
At time: 361.26749324798584 and batch: 1800, loss is 3.7034265327453615 and perplexity is 40.586136092821235
At time: 362.2299418449402 and batch: 1850, loss is 3.7384614181518554 and perplexity is 42.03326876383973
At time: 363.1925940513611 and batch: 1900, loss is 3.816283555030823 and perplexity is 45.435037342292745
At time: 364.18640875816345 and batch: 1950, loss is 3.7417317914962767 and perplexity is 42.17095827091108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.291080350654069 and perplexity of 73.04534046862182
finished 9 epochs...
Completing Train Step...
At time: 367.2972221374512 and batch: 50, loss is 3.8930553293228147 and perplexity is 49.06055391468763
At time: 368.2661066055298 and batch: 100, loss is 3.8674350023269652 and perplexity is 47.81957154891173
At time: 369.2300543785095 and batch: 150, loss is 3.834036626815796 and perplexity is 46.248851296418295
At time: 370.19898653030396 and batch: 200, loss is 3.8424102878570556 and perplexity is 46.637749479102105
At time: 371.16850090026855 and batch: 250, loss is 3.8316193056106567 and perplexity is 46.13718798488637
At time: 372.1637125015259 and batch: 300, loss is 3.8344702768325805 and perplexity is 46.2689114607902
At time: 373.13391375541687 and batch: 350, loss is 3.851609058380127 and perplexity is 47.068738680560145
At time: 374.106778383255 and batch: 400, loss is 3.812830104827881 and perplexity is 45.27840032810176
At time: 375.0855050086975 and batch: 450, loss is 3.835559759140015 and perplexity is 46.31934809113027
At time: 376.06029176712036 and batch: 500, loss is 3.843741660118103 and perplexity is 46.699883037346304
At time: 377.0340061187744 and batch: 550, loss is 3.8102245903015137 and perplexity is 45.16058035579464
At time: 378.0066406726837 and batch: 600, loss is 3.7981645154953 and perplexity is 44.61921141499312
At time: 378.98425912857056 and batch: 650, loss is 3.8519943618774413 and perplexity is 47.08687792452061
At time: 379.9643840789795 and batch: 700, loss is 3.8872535467147826 and perplexity is 48.77673935754125
At time: 380.9351897239685 and batch: 750, loss is 3.8485952377319337 and perplexity is 46.92709549483261
At time: 381.90648341178894 and batch: 800, loss is 3.8236188793182375 and perplexity is 45.7695434306307
At time: 382.8752586841583 and batch: 850, loss is 3.809129042625427 and perplexity is 45.11113187846312
At time: 383.8574273586273 and batch: 900, loss is 3.779200177192688 and perplexity is 43.78101067725492
At time: 384.8310372829437 and batch: 950, loss is 3.8920060539245607 and perplexity is 49.009102880313065
At time: 385.84663248062134 and batch: 1000, loss is 3.8551541233062743 and perplexity is 47.235896532831426
At time: 386.8267729282379 and batch: 1050, loss is 3.8005964040756224 and perplexity is 44.72785241355546
At time: 387.8006474971771 and batch: 1100, loss is 3.817892050743103 and perplexity is 45.50817821266377
At time: 388.78814935684204 and batch: 1150, loss is 3.7749013471603394 and perplexity is 43.59320750987287
At time: 389.747195482254 and batch: 1200, loss is 3.8529984855651858 and perplexity is 47.134182719984736
At time: 390.7125475406647 and batch: 1250, loss is 3.8292436456680297 and perplexity is 46.02771180609963
At time: 391.7062385082245 and batch: 1300, loss is 3.832142934799194 and perplexity is 46.16135308941719
At time: 392.6784899234772 and batch: 1350, loss is 3.7160781621932983 and perplexity is 41.102878773219054
At time: 393.6485195159912 and batch: 1400, loss is 3.7504182052612305 and perplexity is 42.53886825916276
At time: 394.61850333213806 and batch: 1450, loss is 3.6742622327804564 and perplexity is 39.41956366463777
At time: 395.5869348049164 and batch: 1500, loss is 3.6737028408050536 and perplexity is 39.397518843472774
At time: 396.5818712711334 and batch: 1550, loss is 3.6817990016937254 and perplexity is 39.7177821970843
At time: 397.550555229187 and batch: 1600, loss is 3.7653870248794554 and perplexity is 43.18041452104251
At time: 398.55385303497314 and batch: 1650, loss is 3.7153240776062013 and perplexity is 41.07189540935763
At time: 399.5356512069702 and batch: 1700, loss is 3.7371411180496215 and perplexity is 41.97780885471189
At time: 400.536479473114 and batch: 1750, loss is 3.738745470046997 and perplexity is 42.04521008938888
At time: 401.5266637802124 and batch: 1800, loss is 3.6839215469360354 and perplexity is 39.80217451829808
At time: 402.5245723724365 and batch: 1850, loss is 3.72123863697052 and perplexity is 41.31553738015453
At time: 403.50701570510864 and batch: 1900, loss is 3.8035617733001708 and perplexity is 44.860683860388185
At time: 404.48244071006775 and batch: 1950, loss is 3.729409112930298 and perplexity is 41.65448779258437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.292100631359012 and perplexity of 73.11990525212451
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 407.7492072582245 and batch: 50, loss is 3.8685836935043336 and perplexity is 47.87453302969611
At time: 408.7381191253662 and batch: 100, loss is 3.871303014755249 and perplexity is 48.00489643439652
At time: 409.7425117492676 and batch: 150, loss is 3.8503259658813476 and perplexity is 47.008383863718805
At time: 410.71951246261597 and batch: 200, loss is 3.868644757270813 and perplexity is 47.87745651826004
At time: 411.69106364250183 and batch: 250, loss is 3.8576655054092406 and perplexity is 47.35467300212384
At time: 412.69584035873413 and batch: 300, loss is 3.866954026222229 and perplexity is 47.796577008013635
At time: 413.6799819469452 and batch: 350, loss is 3.8833385372161864 and perplexity is 48.586151280145906
At time: 414.66966366767883 and batch: 400, loss is 3.86075252532959 and perplexity is 47.501083691089
At time: 415.64434027671814 and batch: 450, loss is 3.8835186672210695 and perplexity is 48.5949038920936
At time: 416.6237530708313 and batch: 500, loss is 3.87693546295166 and perplexity is 48.27604442340295
At time: 417.6087577342987 and batch: 550, loss is 3.8391791725158693 and perplexity is 46.48730072081898
At time: 418.5829608440399 and batch: 600, loss is 3.8075567865371704 and perplexity is 45.04026135462461
At time: 419.56063294410706 and batch: 650, loss is 3.8522462892532348 and perplexity is 47.098741892476845
At time: 420.5345981121063 and batch: 700, loss is 3.8933699893951417 and perplexity is 49.07599374115189
At time: 421.5048747062683 and batch: 750, loss is 3.8516559553146363 and perplexity is 47.07094611187597
At time: 422.475040435791 and batch: 800, loss is 3.8300650835037233 and perplexity is 46.06553624315255
At time: 423.4451479911804 and batch: 850, loss is 3.8156668090820314 and perplexity is 45.4070241064915
At time: 424.4384422302246 and batch: 900, loss is 3.778076982498169 and perplexity is 43.731863684329255
At time: 425.441529750824 and batch: 950, loss is 3.889851031303406 and perplexity is 48.90360087539742
At time: 426.43608236312866 and batch: 1000, loss is 3.850289397239685 and perplexity is 47.00666486240513
At time: 427.42967772483826 and batch: 1050, loss is 3.797279691696167 and perplexity is 44.57974873616794
At time: 428.4361732006073 and batch: 1100, loss is 3.8131790733337403 and perplexity is 45.29420382111225
At time: 429.4366488456726 and batch: 1150, loss is 3.7756949853897095 and perplexity is 43.62781847837076
At time: 430.4381539821625 and batch: 1200, loss is 3.832338185310364 and perplexity is 46.17036699716059
At time: 431.4166736602783 and batch: 1250, loss is 3.804401922225952 and perplexity is 44.89838935263984
At time: 432.38790249824524 and batch: 1300, loss is 3.805585250854492 and perplexity is 44.95155034939756
At time: 433.3497123718262 and batch: 1350, loss is 3.6903512620925905 and perplexity is 40.05891566478356
At time: 434.3058862686157 and batch: 1400, loss is 3.724427132606506 and perplexity is 41.447482031477406
At time: 435.2812190055847 and batch: 1450, loss is 3.6438219213485716 and perplexity is 38.23769928945772
At time: 436.27281951904297 and batch: 1500, loss is 3.6472909545898435 and perplexity is 38.37057748554546
At time: 437.22989439964294 and batch: 1550, loss is 3.6476953125 and perplexity is 38.38609606938862
At time: 438.18534088134766 and batch: 1600, loss is 3.7303098964691164 and perplexity is 41.69202637403569
At time: 439.14162397384644 and batch: 1650, loss is 3.675945749282837 and perplexity is 39.48598304395711
At time: 440.1017816066742 and batch: 1700, loss is 3.68841016292572 and perplexity is 39.981232756466795
At time: 441.0732798576355 and batch: 1750, loss is 3.6838613843917845 and perplexity is 39.799779990243515
At time: 442.0650112628937 and batch: 1800, loss is 3.631071834564209 and perplexity is 37.753260188082415
At time: 443.0296080112457 and batch: 1850, loss is 3.6657663106918337 and perplexity is 39.086076768260604
At time: 444.0179657936096 and batch: 1900, loss is 3.7488287353515624 and perplexity is 42.47130771502331
At time: 444.9746766090393 and batch: 1950, loss is 3.684172315597534 and perplexity is 39.8121569079097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26431884765625 and perplexity of 71.1164623267557
finished 11 epochs...
Completing Train Step...
At time: 448.1265711784363 and batch: 50, loss is 3.8632193851470946 and perplexity is 47.61840685613875
At time: 449.0839030742645 and batch: 100, loss is 3.846591386795044 and perplexity is 46.83315474362522
At time: 450.0431227684021 and batch: 150, loss is 3.813564419746399 and perplexity is 45.311661143411186
At time: 450.99989891052246 and batch: 200, loss is 3.8220826148986817 and perplexity is 45.69928329245256
At time: 451.97872138023376 and batch: 250, loss is 3.810354208946228 and perplexity is 45.166434388402564
At time: 452.9405550956726 and batch: 300, loss is 3.815413317680359 and perplexity is 45.3955152750615
At time: 453.8933267593384 and batch: 350, loss is 3.8344885778427122 and perplexity is 46.269758236356026
At time: 454.849169254303 and batch: 400, loss is 3.810715870857239 and perplexity is 45.182772321603004
At time: 455.80471897125244 and batch: 450, loss is 3.8375335693359376 and perplexity is 46.410863980447154
At time: 456.7728452682495 and batch: 500, loss is 3.835218143463135 and perplexity is 46.303527378135136
At time: 457.7288293838501 and batch: 550, loss is 3.7978527641296385 and perplexity is 44.6053034829208
At time: 458.6844811439514 and batch: 600, loss is 3.7712384843826294 and perplexity is 43.433823651523625
At time: 459.6451835632324 and batch: 650, loss is 3.8169751930236817 and perplexity is 45.46647281005441
At time: 460.61206316947937 and batch: 700, loss is 3.860574131011963 and perplexity is 47.492610523482334
At time: 461.60691928863525 and batch: 750, loss is 3.819750871658325 and perplexity is 45.59284843514986
At time: 462.59161162376404 and batch: 800, loss is 3.7988688707351685 and perplexity is 44.65065026111029
At time: 463.5977580547333 and batch: 850, loss is 3.786977143287659 and perplexity is 44.12282151578746
At time: 464.57351994514465 and batch: 900, loss is 3.750231394767761 and perplexity is 42.53092229440954
At time: 465.5526487827301 and batch: 950, loss is 3.863074321746826 and perplexity is 47.61149966912696
At time: 466.5195891857147 and batch: 1000, loss is 3.8239998626708984 and perplexity is 45.786984186844585
At time: 467.514178276062 and batch: 1050, loss is 3.7719570446014403 and perplexity is 43.46504468510346
At time: 468.47653460502625 and batch: 1100, loss is 3.7892495584487915 and perplexity is 44.22320089296566
At time: 469.45233273506165 and batch: 1150, loss is 3.752516269683838 and perplexity is 42.62821123612294
At time: 470.42358350753784 and batch: 1200, loss is 3.8120623302459715 and perplexity is 45.24365006511168
At time: 471.3855106830597 and batch: 1250, loss is 3.7865537548065187 and perplexity is 44.10414437552429
At time: 472.3486998081207 and batch: 1300, loss is 3.7885726499557495 and perplexity is 44.193275962054294
At time: 473.3107042312622 and batch: 1350, loss is 3.6754072761535643 and perplexity is 39.46472662662341
At time: 474.27416920661926 and batch: 1400, loss is 3.710576238632202 and perplexity is 40.877354852659515
At time: 475.25314259529114 and batch: 1450, loss is 3.63264132976532 and perplexity is 37.81256027219973
At time: 476.2289090156555 and batch: 1500, loss is 3.637165012359619 and perplexity is 37.983999769526825
At time: 477.24016427993774 and batch: 1550, loss is 3.640526728630066 and perplexity is 38.11190607145965
At time: 478.22898149490356 and batch: 1600, loss is 3.724816255569458 and perplexity is 41.46361333681951
At time: 479.2073509693146 and batch: 1650, loss is 3.6717277908325197 and perplexity is 39.31978356576141
At time: 480.1982741355896 and batch: 1700, loss is 3.686922507286072 and perplexity is 39.921798669764904
At time: 481.17970728874207 and batch: 1750, loss is 3.684161162376404 and perplexity is 39.81171287659623
At time: 482.1809206008911 and batch: 1800, loss is 3.6333878231048584 and perplexity is 37.840797634784096
At time: 483.15751600265503 and batch: 1850, loss is 3.6695852136611937 and perplexity is 39.23562808211492
At time: 484.1351056098938 and batch: 1900, loss is 3.7533754014968874 and perplexity is 42.664850225136185
At time: 485.10659408569336 and batch: 1950, loss is 3.68790620803833 and perplexity is 39.961089094989944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26338373228561 and perplexity of 71.04999131360519
finished 12 epochs...
Completing Train Step...
At time: 488.26483631134033 and batch: 50, loss is 3.8457646799087524 and perplexity is 46.79445345160839
At time: 489.24817419052124 and batch: 100, loss is 3.8277430009841917 and perplexity is 45.958692364849654
At time: 490.2370676994324 and batch: 150, loss is 3.7941558742523194 and perplexity is 44.440707022954925
At time: 491.20822167396545 and batch: 200, loss is 3.801659417152405 and perplexity is 44.775423985689464
At time: 492.17515563964844 and batch: 250, loss is 3.789639811515808 and perplexity is 44.24046250072604
At time: 493.14321637153625 and batch: 300, loss is 3.794144620895386 and perplexity is 44.44020691863035
At time: 494.1123080253601 and batch: 350, loss is 3.813487091064453 and perplexity is 45.308157387850336
At time: 495.07805705070496 and batch: 400, loss is 3.789437246322632 and perplexity is 44.231501830483964
At time: 496.0576388835907 and batch: 450, loss is 3.817440376281738 and perplexity is 45.48762797214065
At time: 497.04211044311523 and batch: 500, loss is 3.8161711359024046 and perplexity is 45.429929862089686
At time: 498.00998759269714 and batch: 550, loss is 3.778713846206665 and perplexity is 43.75972379181872
At time: 498.9767508506775 and batch: 600, loss is 3.7534219646453857 and perplexity is 42.666836881144995
At time: 499.9680368900299 and batch: 650, loss is 3.799300079345703 and perplexity is 44.66990815775587
At time: 500.9679846763611 and batch: 700, loss is 3.843379054069519 and perplexity is 46.682952447041544
At time: 501.9688415527344 and batch: 750, loss is 3.8028650426864625 and perplexity is 44.82943893450291
At time: 502.9476544857025 and batch: 800, loss is 3.7825797176361085 and perplexity is 43.929220673267885
At time: 503.9263572692871 and batch: 850, loss is 3.771760149002075 and perplexity is 43.45648745154721
At time: 504.8892982006073 and batch: 900, loss is 3.734948043823242 and perplexity is 41.88584927797874
At time: 505.87653636932373 and batch: 950, loss is 3.84868004322052 and perplexity is 46.931075338847904
At time: 506.8749077320099 and batch: 1000, loss is 3.8097798824310303 and perplexity is 45.14050155520605
At time: 507.88292813301086 and batch: 1050, loss is 3.7581217384338377 and perplexity is 42.86783331166785
At time: 508.8411784172058 and batch: 1100, loss is 3.7760649585723876 and perplexity is 43.64396258748607
At time: 509.79660201072693 and batch: 1150, loss is 3.739269142150879 and perplexity is 42.06723375910197
At time: 510.78447127342224 and batch: 1200, loss is 3.8002917861938474 and perplexity is 44.714229584880854
At time: 511.74287939071655 and batch: 1250, loss is 3.775688161849976 and perplexity is 43.62752078323355
At time: 512.6976163387299 and batch: 1300, loss is 3.777952780723572 and perplexity is 43.72643244654489
At time: 513.6554980278015 and batch: 1350, loss is 3.665582709312439 and perplexity is 39.07890116939591
At time: 514.6122994422913 and batch: 1400, loss is 3.700961766242981 and perplexity is 40.486223924782216
At time: 515.569314956665 and batch: 1450, loss is 3.6242627334594726 and perplexity is 37.497067632772875
At time: 516.5426399707794 and batch: 1500, loss is 3.629146032333374 and perplexity is 37.6806248384987
At time: 517.5380914211273 and batch: 1550, loss is 3.6336359453201292 and perplexity is 37.850187942244624
At time: 518.4936711788177 and batch: 1600, loss is 3.7186544132232666 and perplexity is 41.20890662553224
At time: 519.4581696987152 and batch: 1650, loss is 3.6659703922271727 and perplexity is 39.094054328826566
At time: 520.4527537822723 and batch: 1700, loss is 3.6821173000335694 and perplexity is 39.73042631341378
At time: 521.4611241817474 and batch: 1750, loss is 3.680412449836731 and perplexity is 39.66274959401902
At time: 522.4362983703613 and batch: 1800, loss is 3.630515022277832 and perplexity is 37.73224456038174
At time: 523.4181849956512 and batch: 1850, loss is 3.667451114654541 and perplexity is 39.151984650626844
At time: 524.4064688682556 and batch: 1900, loss is 3.7516155529022215 and perplexity is 42.589832577637836
At time: 525.3597490787506 and batch: 1950, loss is 3.685708131790161 and perplexity is 39.873348040290466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2641698083212205 and perplexity of 71.10586396630676
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 528.4808654785156 and batch: 50, loss is 3.841708016395569 and perplexity is 46.605008616447314
At time: 529.4370102882385 and batch: 100, loss is 3.841451711654663 and perplexity is 46.593065062449085
At time: 530.3999223709106 and batch: 150, loss is 3.8154443168640135 and perplexity is 45.39692252078823
At time: 531.3858735561371 and batch: 200, loss is 3.824765639305115 and perplexity is 45.82206021797455
At time: 532.3416032791138 and batch: 250, loss is 3.8128249883651733 and perplexity is 45.278168663447666
At time: 533.3039219379425 and batch: 300, loss is 3.818120770454407 and perplexity is 45.51858802046527
At time: 534.2809612751007 and batch: 350, loss is 3.839361991882324 and perplexity is 46.495800276602985
At time: 535.2460038661957 and batch: 400, loss is 3.8244868993759153 and perplexity is 45.80928956008244
At time: 536.2232575416565 and batch: 450, loss is 3.8643144226074218 and perplexity is 47.67057935565463
At time: 537.1772446632385 and batch: 500, loss is 3.8679281187057497 and perplexity is 47.843157977818215
At time: 538.1444199085236 and batch: 550, loss is 3.83267626285553 and perplexity is 46.18597880034576
At time: 539.1050400733948 and batch: 600, loss is 3.792890396118164 and perplexity is 44.38450384939505
At time: 540.0616762638092 and batch: 650, loss is 3.8237879848480225 and perplexity is 45.77728396798594
At time: 541.0179626941681 and batch: 700, loss is 3.8619572019577024 and perplexity is 47.55834161814032
At time: 542.0076937675476 and batch: 750, loss is 3.8206870317459107 and perplexity is 45.63555062505845
At time: 542.9939186573029 and batch: 800, loss is 3.798257999420166 and perplexity is 44.62338278897579
At time: 543.951708316803 and batch: 850, loss is 3.7842835187911987 and perplexity is 44.004131128331444
At time: 544.9082727432251 and batch: 900, loss is 3.7472690629959104 and perplexity is 42.405118021007425
At time: 545.8643844127655 and batch: 950, loss is 3.8615812158584593 and perplexity is 47.54046370392306
At time: 546.8491499423981 and batch: 1000, loss is 3.820611529350281 and perplexity is 45.632105161732376
At time: 547.8090236186981 and batch: 1050, loss is 3.771031155586243 and perplexity is 43.42481950258542
At time: 548.7696464061737 and batch: 1100, loss is 3.7902095174789427 and perplexity is 44.26567373683842
At time: 549.75519323349 and batch: 1150, loss is 3.758248152732849 and perplexity is 42.87325276130683
At time: 550.7497341632843 and batch: 1200, loss is 3.808772587776184 and perplexity is 45.09505466232125
At time: 551.7196159362793 and batch: 1250, loss is 3.7796244335174563 and perplexity is 43.79958898864388
At time: 552.6880247592926 and batch: 1300, loss is 3.779531617164612 and perplexity is 43.79552385919604
At time: 553.6784052848816 and batch: 1350, loss is 3.6598233461380003 and perplexity is 38.854478471360984
At time: 554.6744201183319 and batch: 1400, loss is 3.6949377822875977 and perplexity is 40.24306867840547
At time: 555.6328587532043 and batch: 1450, loss is 3.6152537298202514 and perplexity is 37.16077352595143
At time: 556.610889673233 and batch: 1500, loss is 3.6182580614089965 and perplexity is 37.27258468651778
At time: 557.588707447052 and batch: 1550, loss is 3.6239053773880006 and perplexity is 37.48367022195753
At time: 558.56289935112 and batch: 1600, loss is 3.7127365922927855 and perplexity is 40.965759854501975
At time: 559.5389683246613 and batch: 1650, loss is 3.6578007411956786 and perplexity is 38.77597063310848
At time: 560.5244674682617 and batch: 1700, loss is 3.6671874570846557 and perplexity is 39.14166329420932
At time: 561.506195306778 and batch: 1750, loss is 3.664455032348633 and perplexity is 39.03485763088557
At time: 562.4818639755249 and batch: 1800, loss is 3.6161136484146117 and perplexity is 37.19274250947891
At time: 563.4582438468933 and batch: 1850, loss is 3.651012716293335 and perplexity is 38.513649706581404
At time: 564.450177192688 and batch: 1900, loss is 3.736079730987549 and perplexity is 41.933277788028875
At time: 565.4494528770447 and batch: 1950, loss is 3.6798922634124756 and perplexity is 39.642122935450566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.250885719476744 and perplexity of 70.16753358276169
finished 14 epochs...
Completing Train Step...
At time: 568.711391210556 and batch: 50, loss is 3.8526132488250733 and perplexity is 47.11602839816622
At time: 569.7116105556488 and batch: 100, loss is 3.8398415184020998 and perplexity is 46.51810159250267
At time: 570.7227740287781 and batch: 150, loss is 3.802432270050049 and perplexity is 44.81004217752185
At time: 571.7115616798401 and batch: 200, loss is 3.8037577724456786 and perplexity is 44.86947737782452
At time: 572.7057020664215 and batch: 250, loss is 3.793452401161194 and perplexity is 44.4094551751195
At time: 573.6661064624786 and batch: 300, loss is 3.7932467746734617 and perplexity is 44.40032435363129
At time: 574.6253542900085 and batch: 350, loss is 3.8144900465011595 and perplexity is 45.35362224643201
At time: 575.5812840461731 and batch: 400, loss is 3.795767822265625 and perplexity is 44.51240090022802
At time: 576.5377721786499 and batch: 450, loss is 3.8356901884078978 and perplexity is 46.325389883795346
At time: 577.4975326061249 and batch: 500, loss is 3.841259217262268 and perplexity is 46.58409702187654
At time: 578.4576194286346 and batch: 550, loss is 3.8067650318145754 and perplexity is 45.004614628584186
At time: 579.4196462631226 and batch: 600, loss is 3.7723879194259644 and perplexity is 43.48377671389509
At time: 580.3816714286804 and batch: 650, loss is 3.804447331428528 and perplexity is 44.90042819898813
At time: 581.3449165821075 and batch: 700, loss is 3.844692792892456 and perplexity is 46.74432195696788
At time: 582.3005969524384 and batch: 750, loss is 3.8051939582824708 and perplexity is 44.93396458245936
At time: 583.2560534477234 and batch: 800, loss is 3.7843361949920653 and perplexity is 44.006449159833736
At time: 584.2112667560577 and batch: 850, loss is 3.771502275466919 and perplexity is 43.445282618279684
At time: 585.1714837551117 and batch: 900, loss is 3.734623417854309 and perplexity is 41.87225425034119
At time: 586.1323156356812 and batch: 950, loss is 3.84901207447052 and perplexity is 46.94666050969521
At time: 587.1100182533264 and batch: 1000, loss is 3.808372488021851 and perplexity is 45.07701575095186
At time: 588.0698709487915 and batch: 1050, loss is 3.7594517135620116 and perplexity is 42.9248843936216
At time: 589.0295488834381 and batch: 1100, loss is 3.7787733459472657 and perplexity is 43.76232756149413
At time: 589.9981982707977 and batch: 1150, loss is 3.7477972316741943 and perplexity is 42.427520991898014
At time: 590.96346616745 and batch: 1200, loss is 3.7998454761505127 and perplexity is 44.69427762784774
At time: 591.9234466552734 and batch: 1250, loss is 3.771917767524719 and perplexity is 43.46333753873475
At time: 592.8852095603943 and batch: 1300, loss is 3.7730272150039674 and perplexity is 43.51158458784148
At time: 593.841245174408 and batch: 1350, loss is 3.65525634765625 and perplexity is 38.677434714181906
At time: 594.8018991947174 and batch: 1400, loss is 3.6914656019210814 and perplexity is 40.10357979088048
At time: 595.7647352218628 and batch: 1450, loss is 3.6133478546142577 and perplexity is 37.09001717685618
At time: 596.7323718070984 and batch: 1500, loss is 3.618230576515198 and perplexity is 37.27156026756416
At time: 597.701847076416 and batch: 1550, loss is 3.624793515205383 and perplexity is 37.516975674742774
At time: 598.6683616638184 and batch: 1600, loss is 3.715005555152893 and perplexity is 41.0588151717551
At time: 599.6388893127441 and batch: 1650, loss is 3.660513300895691 and perplexity is 38.88129555386289
At time: 600.5957722663879 and batch: 1700, loss is 3.6709364557266237 and perplexity is 39.288680748668206
At time: 601.553297996521 and batch: 1750, loss is 3.669460473060608 and perplexity is 39.230734111548365
At time: 602.5107572078705 and batch: 1800, loss is 3.621340551376343 and perplexity is 37.387654314244045
At time: 603.4767718315125 and batch: 1850, loss is 3.6568732357025144 and perplexity is 38.740022381021234
At time: 604.45543384552 and batch: 1900, loss is 3.7419724225997926 and perplexity is 42.18110713615348
At time: 605.4153695106506 and batch: 1950, loss is 3.6850382614135744 and perplexity is 39.846647009736095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249769769712936 and perplexity of 70.08927381533915
finished 15 epochs...
Completing Train Step...
At time: 608.5442807674408 and batch: 50, loss is 3.8489834785461428 and perplexity is 46.945318045736094
At time: 609.5517175197601 and batch: 100, loss is 3.8342518424987793 and perplexity is 46.25880584568639
At time: 610.5500569343567 and batch: 150, loss is 3.79584632396698 and perplexity is 44.51589533658789
At time: 611.5371391773224 and batch: 200, loss is 3.7956574726104737 and perplexity is 44.50748924314354
At time: 612.5100364685059 and batch: 250, loss is 3.7853453588485717 and perplexity is 44.050881293659934
At time: 613.4711289405823 and batch: 300, loss is 3.784213833808899 and perplexity is 44.00106480807214
At time: 614.4338791370392 and batch: 350, loss is 3.805414972305298 and perplexity is 44.943896716263296
At time: 615.3948917388916 and batch: 400, loss is 3.786041512489319 and perplexity is 44.081558151714944
At time: 616.3570017814636 and batch: 450, loss is 3.826287417411804 and perplexity is 45.89184431050254
At time: 617.3168852329254 and batch: 500, loss is 3.8322019577026367 and perplexity is 46.16407774691117
At time: 618.2799096107483 and batch: 550, loss is 3.7979122018814087 and perplexity is 44.60795480067026
At time: 619.2345724105835 and batch: 600, loss is 3.764744143486023 and perplexity is 43.15266355723115
At time: 620.2171139717102 and batch: 650, loss is 3.796979990005493 and perplexity is 44.566390112003
At time: 621.1725151538849 and batch: 700, loss is 3.8376383638381957 and perplexity is 46.415727838685704
At time: 622.1318435668945 and batch: 750, loss is 3.7985152912139895 and perplexity is 44.63486549631987
At time: 623.0927629470825 and batch: 800, loss is 3.7778056955337522 and perplexity is 43.72000140889514
At time: 624.0538146495819 and batch: 850, loss is 3.7653022623062133 and perplexity is 43.17675459310869
At time: 625.0155982971191 and batch: 900, loss is 3.7288156080245973 and perplexity is 41.62977298464038
At time: 625.971292257309 and batch: 950, loss is 3.8434279489517214 and perplexity is 46.68523506030589
At time: 626.9274532794952 and batch: 1000, loss is 3.802763748168945 and perplexity is 44.8248981880957
At time: 627.8837885856628 and batch: 1050, loss is 3.7542515707015993 and perplexity is 42.70224823412654
At time: 628.8558421134949 and batch: 1100, loss is 3.773726782798767 and perplexity is 43.542034540781216
At time: 629.8171236515045 and batch: 1150, loss is 3.743172836303711 and perplexity is 42.23177231871189
At time: 630.7765097618103 and batch: 1200, loss is 3.795669603347778 and perplexity is 44.50802915507839
At time: 631.737916469574 and batch: 1250, loss is 3.7682694482803343 and perplexity is 43.30505831010597
At time: 632.7262692451477 and batch: 1300, loss is 3.7698965311050414 and perplexity is 43.375576580681226
At time: 633.6817829608917 and batch: 1350, loss is 3.6528582525253297 and perplexity is 38.584793671730885
At time: 634.6362285614014 and batch: 1400, loss is 3.6892704153060913 and perplexity is 40.015641505097705
At time: 635.5968084335327 and batch: 1450, loss is 3.6117489194869994 and perplexity is 37.03076003231117
At time: 636.5631077289581 and batch: 1500, loss is 3.617313599586487 and perplexity is 37.237398771747216
At time: 637.5295586585999 and batch: 1550, loss is 3.624295163154602 and perplexity is 37.498283670962216
At time: 638.4928867816925 and batch: 1600, loss is 3.71502968788147 and perplexity is 41.05980604495351
At time: 639.4517731666565 and batch: 1650, loss is 3.660639958381653 and perplexity is 38.88622047289103
At time: 640.4151124954224 and batch: 1700, loss is 3.6714359855651857 and perplexity is 39.30831151968963
At time: 641.3718512058258 and batch: 1750, loss is 3.670391755104065 and perplexity is 39.26728600719837
At time: 642.3272411823273 and batch: 1800, loss is 3.622332606315613 and perplexity is 37.424763325419654
At time: 643.2833850383759 and batch: 1850, loss is 3.6581577110290526 and perplexity is 38.789814955740056
At time: 644.242509841919 and batch: 1900, loss is 3.7431894397735594 and perplexity is 42.23247351849138
At time: 645.2030785083771 and batch: 1950, loss is 3.6857941818237303 and perplexity is 39.87677929085535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2495988712754365 and perplexity of 70.0772966914237
finished 16 epochs...
Completing Train Step...
At time: 648.3494465351105 and batch: 50, loss is 3.8444498443603514 and perplexity is 46.73296687197068
At time: 649.3265268802643 and batch: 100, loss is 3.8290109252929687 and perplexity is 46.01700146605043
At time: 650.3152821063995 and batch: 150, loss is 3.7903867769241333 and perplexity is 44.27352094108099
At time: 651.2713603973389 and batch: 200, loss is 3.789555215835571 and perplexity is 44.236720107004196
At time: 652.2260947227478 and batch: 250, loss is 3.7792246389389037 and perplexity is 43.782081650326056
At time: 653.2053551673889 and batch: 300, loss is 3.7777855348587037 and perplexity is 43.71911999303862
At time: 654.1689345836639 and batch: 350, loss is 3.7989738368988037 and perplexity is 44.65533731455872
At time: 655.1324741840363 and batch: 400, loss is 3.779360280036926 and perplexity is 43.78802070273551
At time: 656.1141412258148 and batch: 450, loss is 3.819891080856323 and perplexity is 45.59924142003057
At time: 657.1144106388092 and batch: 500, loss is 3.8260385942459108 and perplexity is 45.88042677704484
At time: 658.0847601890564 and batch: 550, loss is 3.791830244064331 and perplexity is 44.3374744600374
At time: 659.0610723495483 and batch: 600, loss is 3.7593367528915405 and perplexity is 42.91995000376763
At time: 660.0944902896881 and batch: 650, loss is 3.7916187238693237 and perplexity is 44.32809718057044
At time: 661.0734539031982 and batch: 700, loss is 3.8325734090805055 and perplexity is 46.18122864236297
At time: 662.0336766242981 and batch: 750, loss is 3.793684415817261 and perplexity is 44.41976001497879
At time: 663.0131366252899 and batch: 800, loss is 3.7730646181106566 and perplexity is 43.51321208671861
At time: 663.979653596878 and batch: 850, loss is 3.76072838306427 and perplexity is 42.97972028061917
At time: 664.9695127010345 and batch: 900, loss is 3.724499044418335 and perplexity is 41.45046270217747
At time: 665.9393768310547 and batch: 950, loss is 3.8393078660964965 and perplexity is 46.49328372298117
At time: 666.8950278759003 and batch: 1000, loss is 3.7986583805084226 and perplexity is 44.64125272469196
At time: 667.8499464988708 and batch: 1050, loss is 3.7504207992553713 and perplexity is 42.5389786048809
At time: 668.8119430541992 and batch: 1100, loss is 3.7699689769744875 and perplexity is 43.37871907586836
At time: 669.7869029045105 and batch: 1150, loss is 3.739638047218323 and perplexity is 42.08275543764596
At time: 670.7937989234924 and batch: 1200, loss is 3.7923972463607787 and perplexity is 44.362621038285035
At time: 671.7989184856415 and batch: 1250, loss is 3.765327491760254 and perplexity is 43.17784393279598
At time: 672.8080515861511 and batch: 1300, loss is 3.767248578071594 and perplexity is 43.26087202425834
At time: 673.8230247497559 and batch: 1350, loss is 3.6506010246276857 and perplexity is 38.497797221375386
At time: 674.8150987625122 and batch: 1400, loss is 3.6870731782913206 and perplexity is 39.92781418047196
At time: 675.7901694774628 and batch: 1450, loss is 3.6099340867996217 and perplexity is 36.9636163442748
At time: 676.7863111495972 and batch: 1500, loss is 3.61582706451416 and perplexity is 37.182085195442305
At time: 677.763845205307 and batch: 1550, loss is 3.6230620670318605 and perplexity is 37.452073179602316
At time: 678.7597916126251 and batch: 1600, loss is 3.7141259050369264 and perplexity is 41.02271366090481
At time: 679.7478148937225 and batch: 1650, loss is 3.6597705268859864 and perplexity is 38.85242626106932
At time: 680.735258102417 and batch: 1700, loss is 3.670796947479248 and perplexity is 39.283200035986454
At time: 681.7409346103668 and batch: 1750, loss is 3.670023636817932 and perplexity is 39.2528336614219
At time: 682.7238178253174 and batch: 1800, loss is 3.622022671699524 and perplexity is 37.413165893081874
At time: 683.729816198349 and batch: 1850, loss is 3.658061022758484 and perplexity is 38.78606461692612
At time: 684.74955534935 and batch: 1900, loss is 3.7431102180480957 and perplexity is 42.22912792159238
At time: 685.7625153064728 and batch: 1950, loss is 3.685420789718628 and perplexity is 39.86189239578874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2497291742369185 and perplexity of 70.08642856565746
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 689.0226233005524 and batch: 50, loss is 3.8443530893325804 and perplexity is 46.72844544120227
At time: 689.9875583648682 and batch: 100, loss is 3.8358976316452025 and perplexity is 46.33500076946439
At time: 690.9476273059845 and batch: 150, loss is 3.8004542636871337 and perplexity is 44.721495231054035
At time: 691.908408164978 and batch: 200, loss is 3.7995663833618165 and perplexity is 44.68180551778477
At time: 692.8714826107025 and batch: 250, loss is 3.789767746925354 and perplexity is 44.2461227844822
At time: 693.8271176815033 and batch: 300, loss is 3.7855340433120728 and perplexity is 44.059193794758826
At time: 694.7826683521271 and batch: 350, loss is 3.8076716232299805 and perplexity is 45.0454339262767
At time: 695.7422454357147 and batch: 400, loss is 3.788400583267212 and perplexity is 44.185672425580314
At time: 696.7009840011597 and batch: 450, loss is 3.8322289752960206 and perplexity is 46.16532500604157
At time: 697.6583988666534 and batch: 500, loss is 3.843489618301392 and perplexity is 46.68811419716761
At time: 698.6202390193939 and batch: 550, loss is 3.811175961494446 and perplexity is 45.20356527506604
At time: 699.6058614253998 and batch: 600, loss is 3.7793993663787844 and perplexity is 43.789732249730825
At time: 700.5629653930664 and batch: 650, loss is 3.8066079950332643 and perplexity is 44.997547803649006
At time: 701.5214171409607 and batch: 700, loss is 3.8460774660110473 and perplexity is 46.809092395622315
At time: 702.4832429885864 and batch: 750, loss is 3.8061376571655274 and perplexity is 44.976388729308674
At time: 703.4443244934082 and batch: 800, loss is 3.7817158031463625 and perplexity is 43.89128597153363
At time: 704.429322719574 and batch: 850, loss is 3.7669243955612184 and perplexity is 43.24684987915438
At time: 705.3892548084259 and batch: 900, loss is 3.729059166908264 and perplexity is 41.63991352053449
At time: 706.3451635837555 and batch: 950, loss is 3.843558325767517 and perplexity is 46.69132212939545
At time: 707.3210487365723 and batch: 1000, loss is 3.8010205698013304 and perplexity is 44.74682845974351
At time: 708.3118555545807 and batch: 1050, loss is 3.753343787193298 and perplexity is 42.66350142692935
At time: 709.273289680481 and batch: 1100, loss is 3.7701378059387207 and perplexity is 43.386043278331066
At time: 710.2340066432953 and batch: 1150, loss is 3.7432606077194213 and perplexity is 42.23547922383403
At time: 711.1974642276764 and batch: 1200, loss is 3.795706171989441 and perplexity is 44.50965678300757
At time: 712.1865565776825 and batch: 1250, loss is 3.767041540145874 and perplexity is 43.25191631016783
At time: 713.1491107940674 and batch: 1300, loss is 3.7683827829360963 and perplexity is 43.309966552114005
At time: 714.1081740856171 and batch: 1350, loss is 3.6471407890319822 and perplexity is 38.364815978972636
At time: 715.0671215057373 and batch: 1400, loss is 3.68167706489563 and perplexity is 39.71293943315729
At time: 716.0261754989624 and batch: 1450, loss is 3.6017672634124756 and perplexity is 36.66297035022235
At time: 716.987487077713 and batch: 1500, loss is 3.6060088777542116 and perplexity is 36.81881080497693
At time: 717.97580742836 and batch: 1550, loss is 3.6147262763977053 and perplexity is 37.14117811705774
At time: 718.9354441165924 and batch: 1600, loss is 3.70742018699646 and perplexity is 40.74854717876437
At time: 719.8970489501953 and batch: 1650, loss is 3.6529429960250854 and perplexity is 38.58806362073549
At time: 720.8578267097473 and batch: 1700, loss is 3.66091197013855 and perplexity is 38.89679942077482
At time: 721.8173079490662 and batch: 1750, loss is 3.661500267982483 and perplexity is 38.91968905631141
At time: 722.7972002029419 and batch: 1800, loss is 3.6122218799591064 and perplexity is 37.0482782604467
At time: 723.7566101551056 and batch: 1850, loss is 3.6465484046936036 and perplexity is 38.342095992988256
At time: 724.7114524841309 and batch: 1900, loss is 3.7312570714950564 and perplexity is 41.73153472790735
At time: 725.6969857215881 and batch: 1950, loss is 3.6782708263397215 and perplexity is 39.57789781025082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246710347020349 and perplexity of 69.8751687864167
finished 18 epochs...
Completing Train Step...
At time: 728.8715071678162 and batch: 50, loss is 3.8452252674102785 and perplexity is 46.76921874512725
At time: 729.8844857215881 and batch: 100, loss is 3.8326785659790037 and perplexity is 46.18608517248018
At time: 730.8467955589294 and batch: 150, loss is 3.7947384023666384 and perplexity is 44.46660252591299
At time: 731.806578874588 and batch: 200, loss is 3.792870979309082 and perplexity is 44.38364205232431
At time: 732.7852027416229 and batch: 250, loss is 3.7837594318389893 and perplexity is 43.98107517955247
At time: 733.7418909072876 and batch: 300, loss is 3.7785546588897705 and perplexity is 43.752758353219704
At time: 734.6978793144226 and batch: 350, loss is 3.800052103996277 and perplexity is 44.703513664330266
At time: 735.6818974018097 and batch: 400, loss is 3.7795460271835326 and perplexity is 43.79615495807056
At time: 736.6445882320404 and batch: 450, loss is 3.8226535749435424 and perplexity is 45.725383207586646
At time: 737.6051180362701 and batch: 500, loss is 3.833923511505127 and perplexity is 46.2436201391034
At time: 738.5641553401947 and batch: 550, loss is 3.8011509132385255 and perplexity is 44.75266129529619
At time: 739.5238344669342 and batch: 600, loss is 3.7701486921310425 and perplexity is 43.386515589713106
At time: 740.4759685993195 and batch: 650, loss is 3.798259768486023 and perplexity is 44.62346173074853
At time: 741.4488139152527 and batch: 700, loss is 3.8385159492492678 and perplexity is 46.456479483190144
At time: 742.4072289466858 and batch: 750, loss is 3.799514307975769 and perplexity is 44.67947875609717
At time: 743.3844285011292 and batch: 800, loss is 3.776485576629639 and perplexity is 43.662323887516834
At time: 744.35294008255 and batch: 850, loss is 3.7618841791152953 and perplexity is 43.02942479019842
At time: 745.3126788139343 and batch: 900, loss is 3.724507293701172 and perplexity is 41.45080464017838
At time: 746.278157711029 and batch: 950, loss is 3.8392373371124267 and perplexity is 46.490004714548036
At time: 747.2455167770386 and batch: 1000, loss is 3.7971082639694216 and perplexity is 44.5721071861887
At time: 748.2274370193481 and batch: 1050, loss is 3.7496108293533323 and perplexity is 42.5045372626557
At time: 749.1871428489685 and batch: 1100, loss is 3.767274146080017 and perplexity is 43.261978132739074
At time: 750.1760511398315 and batch: 1150, loss is 3.7401016044616697 and perplexity is 42.10226772593095
At time: 751.1360657215118 and batch: 1200, loss is 3.793040313720703 and perplexity is 44.391158366604216
At time: 752.1260585784912 and batch: 1250, loss is 3.764990334510803 and perplexity is 43.16328866354354
At time: 753.0965442657471 and batch: 1300, loss is 3.7665960359573365 and perplexity is 43.23265169184207
At time: 754.066150188446 and batch: 1350, loss is 3.646080856323242 and perplexity is 38.32417339865687
At time: 755.0355966091156 and batch: 1400, loss is 3.6814680433273317 and perplexity is 39.70463943974428
At time: 756.011477470398 and batch: 1450, loss is 3.602119665145874 and perplexity is 36.67589272132456
At time: 757.0080780982971 and batch: 1500, loss is 3.606850280761719 and perplexity is 36.849803299881835
At time: 757.9794681072235 and batch: 1550, loss is 3.6158998441696166 and perplexity is 37.18479139326886
At time: 758.9713070392609 and batch: 1600, loss is 3.709312539100647 and perplexity is 40.82573078400671
At time: 759.9633276462555 and batch: 1650, loss is 3.6555244064331056 and perplexity is 38.68780392974083
At time: 760.9374194145203 and batch: 1700, loss is 3.6638264417648316 and perplexity is 39.01032839716912
At time: 761.9064853191376 and batch: 1750, loss is 3.664887270927429 and perplexity is 39.051733649241804
At time: 762.8760182857513 and batch: 1800, loss is 3.616226997375488 and perplexity is 37.196958507129466
At time: 763.8591697216034 and batch: 1850, loss is 3.6504750728607176 and perplexity is 38.492948661139756
At time: 764.8484997749329 and batch: 1900, loss is 3.7351672649383545 and perplexity is 41.89503254711136
At time: 765.8092408180237 and batch: 1950, loss is 3.6818131732940675 and perplexity is 39.71834506560843
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246060251635174 and perplexity of 69.82975802391323
finished 19 epochs...
Completing Train Step...
At time: 768.9926328659058 and batch: 50, loss is 3.845119857788086 and perplexity is 46.76428907927075
At time: 769.98992395401 and batch: 100, loss is 3.830906419754028 and perplexity is 46.10430915692548
At time: 770.9682836532593 and batch: 150, loss is 3.7920378494262694 and perplexity is 44.3466801130085
At time: 771.9387884140015 and batch: 200, loss is 3.7896281099319458 and perplexity is 44.239944820272825
At time: 772.9177553653717 and batch: 250, loss is 3.7807330894470215 and perplexity is 43.84817459006977
At time: 773.9142379760742 and batch: 300, loss is 3.7750545835494993 and perplexity is 43.5998880874243
At time: 774.89990067482 and batch: 350, loss is 3.7964508724212647 and perplexity is 44.54281548875302
At time: 775.8920478820801 and batch: 400, loss is 3.775343828201294 and perplexity is 43.61250094588542
At time: 776.8717799186707 and batch: 450, loss is 3.818115119934082 and perplexity is 45.518330817485165
At time: 777.8416051864624 and batch: 500, loss is 3.829310894012451 and perplexity is 46.03080719759491
At time: 778.8251724243164 and batch: 550, loss is 3.796417293548584 and perplexity is 44.54131981633452
At time: 779.806916475296 and batch: 600, loss is 3.765885524749756 and perplexity is 43.20194531818469
At time: 780.7763714790344 and batch: 650, loss is 3.7944621419906617 and perplexity is 44.45431986226553
At time: 781.7844576835632 and batch: 700, loss is 3.835002188682556 and perplexity is 46.29352898967891
At time: 782.7484781742096 and batch: 750, loss is 3.796338858604431 and perplexity is 44.53782635740865
At time: 783.7148830890656 and batch: 800, loss is 3.773834481239319 and perplexity is 43.54672420252981
At time: 784.7065215110779 and batch: 850, loss is 3.7592755556106567 and perplexity is 42.91732349990001
At time: 785.7063434123993 and batch: 900, loss is 3.722152714729309 and perplexity is 41.353320259580265
At time: 786.6770310401917 and batch: 950, loss is 3.837074398994446 and perplexity is 46.38955838000857
At time: 787.6577455997467 and batch: 1000, loss is 3.795068211555481 and perplexity is 44.48127043869589
At time: 788.6552090644836 and batch: 1050, loss is 3.7477120304107667 and perplexity is 42.42390626749714
At time: 789.6307854652405 and batch: 1100, loss is 3.7656479024887086 and perplexity is 43.191680793844576
At time: 790.6420340538025 and batch: 1150, loss is 3.7384770107269287 and perplexity is 42.03392417584827
At time: 791.6201169490814 and batch: 1200, loss is 3.791566491127014 and perplexity is 44.32578186296155
At time: 792.6115229129791 and batch: 1250, loss is 3.763812928199768 and perplexity is 43.112497841650715
At time: 793.601291179657 and batch: 1300, loss is 3.7656806087493897 and perplexity is 43.19309345531719
At time: 794.5706205368042 and batch: 1350, loss is 3.6455498790740966 and perplexity is 38.30382953603195
At time: 795.5399079322815 and batch: 1400, loss is 3.6813123989105225 and perplexity is 39.69846011519522
At time: 796.5118491649628 and batch: 1450, loss is 3.602339515686035 and perplexity is 36.68395682256625
At time: 797.5084092617035 and batch: 1500, loss is 3.607397880554199 and perplexity is 36.869987770523366
At time: 798.4966566562653 and batch: 1550, loss is 3.616623888015747 and perplexity is 37.21172456186766
At time: 799.491302728653 and batch: 1600, loss is 3.710431399345398 and perplexity is 40.87143463448665
At time: 800.5093986988068 and batch: 1650, loss is 3.656832957267761 and perplexity is 38.73846202498198
At time: 801.5059123039246 and batch: 1700, loss is 3.6652796030044557 and perplexity is 39.06705790291747
At time: 802.4771053791046 and batch: 1750, loss is 3.666571617126465 and perplexity is 39.117565714810446
At time: 803.449517250061 and batch: 1800, loss is 3.6180691432952883 and perplexity is 37.265543885214164
At time: 804.4204196929932 and batch: 1850, loss is 3.652287874221802 and perplexity is 38.56279201780394
At time: 805.3906795978546 and batch: 1900, loss is 3.736961102485657 and perplexity is 41.97025287589421
At time: 806.3614130020142 and batch: 1950, loss is 3.6832956647872925 and perplexity is 39.77727084198211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245808446130087 and perplexity of 69.81217672005135
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
2498.1324310302734


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -69.81217672005135, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.725269039096756, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9500194842048229, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5633420944213867 and batch: 50, loss is 7.670479497909546 and perplexity is 2144.109294726886
At time: 2.6842691898345947 and batch: 100, loss is 7.012163200378418 and perplexity is 1110.0531770137031
At time: 3.804395914077759 and batch: 150, loss is 6.773913621902466 and perplexity is 874.7285607129037
At time: 4.923443794250488 and batch: 200, loss is 6.680139255523682 and perplexity is 796.4300115723759
At time: 6.0434486865997314 and batch: 250, loss is 6.640743045806885 and perplexity is 765.6637049097964
At time: 7.165508508682251 and batch: 300, loss is 6.583045778274536 and perplexity is 722.7372778169797
At time: 8.286211490631104 and batch: 350, loss is 6.553422079086304 and perplexity is 701.6411416468976
At time: 9.411622047424316 and batch: 400, loss is 6.543666887283325 and perplexity is 694.8297748442624
At time: 10.533918142318726 and batch: 450, loss is 6.4645951557159425 and perplexity is 642.004399015751
At time: 11.652245283126831 and batch: 500, loss is 6.459864330291748 and perplexity is 638.974361223552
At time: 12.775458574295044 and batch: 550, loss is 6.434605875015259 and perplexity is 623.0369800274095
At time: 13.893931150436401 and batch: 600, loss is 6.495198602676392 and perplexity is 661.9556784252254
At time: 15.013720512390137 and batch: 650, loss is 6.589094409942627 and perplexity is 727.1220971131653
At time: 16.13859486579895 and batch: 700, loss is 6.488959188461304 and perplexity is 657.8383210620154
At time: 17.262336254119873 and batch: 750, loss is 6.428152494430542 and perplexity is 619.0292309509032
At time: 18.385814905166626 and batch: 800, loss is 6.434894704818726 and perplexity is 623.2169576661055
At time: 19.51007914543152 and batch: 850, loss is 6.496027975082398 and perplexity is 662.5049139278124
At time: 20.635474681854248 and batch: 900, loss is 6.483260049819946 and perplexity is 654.0998723542151
At time: 21.76012945175171 and batch: 950, loss is 6.501642456054688 and perplexity is 666.2349966017841
At time: 22.88629937171936 and batch: 1000, loss is 6.497113790512085 and perplexity is 663.2246626720297
At time: 24.00918459892273 and batch: 1050, loss is 6.408399124145507 and perplexity is 606.9212972858868
At time: 25.132583618164062 and batch: 1100, loss is 6.483705186843872 and perplexity is 654.3911012383161
At time: 26.25359797477722 and batch: 1150, loss is 6.397987365722656 and perplexity is 600.6349620477234
At time: 27.37394094467163 and batch: 1200, loss is 6.492766199111938 and perplexity is 660.3474917459337
At time: 28.493927001953125 and batch: 1250, loss is 6.421702709197998 and perplexity is 615.0494734455899
At time: 29.614647388458252 and batch: 1300, loss is 6.430570707321167 and perplexity is 620.5279868419076
At time: 30.737537145614624 and batch: 1350, loss is 6.446063747406006 and perplexity is 630.2167119173837
At time: 31.86059856414795 and batch: 1400, loss is 6.46859824180603 and perplexity is 644.5795487293934
At time: 32.98220634460449 and batch: 1450, loss is 6.474836835861206 and perplexity is 648.6133885315917
At time: 34.10656213760376 and batch: 1500, loss is 6.452254056930542 and perplexity is 634.1300483169235
At time: 35.22710394859314 and batch: 1550, loss is 6.424999265670777 and perplexity is 617.0803644025322
At time: 36.34436917304993 and batch: 1600, loss is 6.407692136764527 and perplexity is 606.4923632308056
At time: 37.46030616760254 and batch: 1650, loss is 6.395137224197388 and perplexity is 598.9255046558161
At time: 38.57697105407715 and batch: 1700, loss is 6.438068790435791 and perplexity is 625.1982443711361
At time: 39.696250915527344 and batch: 1750, loss is 6.454972038269043 and perplexity is 635.8559463712887
At time: 40.811997413635254 and batch: 1800, loss is 6.4696910858154295 and perplexity is 645.2843586813236
At time: 41.92778658866882 and batch: 1850, loss is 6.403961277008056 and perplexity is 604.2338410147997
At time: 43.04439043998718 and batch: 1900, loss is 6.354908313751221 and perplexity is 575.309590263033
At time: 44.161176681518555 and batch: 1950, loss is 6.303226537704468 and perplexity is 546.3318296232421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.827029206031977 and perplexity of 339.3490440124244
finished 1 epochs...
Completing Train Step...
At time: 47.34273648262024 and batch: 50, loss is 6.1429564571380615 and perplexity is 465.42755541371616
At time: 48.29300785064697 and batch: 100, loss is 6.053308191299439 and perplexity is 425.51840041604163
At time: 49.24450135231018 and batch: 150, loss is 5.920046157836914 and perplexity is 372.42890399206254
At time: 50.198007106781006 and batch: 200, loss is 5.845240707397461 and perplexity is 345.58571680874974
At time: 51.155147314071655 and batch: 250, loss is 5.796379461288452 and perplexity is 329.10585978928435
At time: 52.11954188346863 and batch: 300, loss is 5.757287893295288 and perplexity is 316.48881246428095
At time: 53.09762144088745 and batch: 350, loss is 5.694659252166748 and perplexity is 297.2754803501472
At time: 54.05824685096741 and batch: 400, loss is 5.618200340270996 and perplexity is 275.39332272606106
At time: 55.023786783218384 and batch: 450, loss is 5.531084423065185 and perplexity is 252.4174900072426
At time: 55.98467683792114 and batch: 500, loss is 5.4916853332519535 and perplexity is 242.66583522496393
At time: 56.94867420196533 and batch: 550, loss is 5.424692621231079 and perplexity is 226.94157857022762
At time: 57.90626621246338 and batch: 600, loss is 5.417768650054931 and perplexity is 225.37566903376856
At time: 58.86337113380432 and batch: 650, loss is 5.481191720962524 and perplexity is 240.13270810591104
At time: 59.82150149345398 and batch: 700, loss is 5.410499353408813 and perplexity is 223.7432867625102
At time: 60.78763127326965 and batch: 750, loss is 5.333590183258057 and perplexity is 207.1804563409925
At time: 61.7862594127655 and batch: 800, loss is 5.314866952896118 and perplexity is 203.33745786919542
At time: 62.7832612991333 and batch: 850, loss is 5.308743858337403 and perplexity is 202.09620741240002
At time: 63.75305366516113 and batch: 900, loss is 5.306660051345825 and perplexity is 201.67551639409425
At time: 64.73899483680725 and batch: 950, loss is 5.334970178604126 and perplexity is 207.4665617732175
At time: 65.7042624950409 and batch: 1000, loss is 5.297413911819458 and perplexity is 199.81939065275353
At time: 66.67295527458191 and batch: 1050, loss is 5.191934089660645 and perplexity is 179.81599709023888
At time: 67.63446092605591 and batch: 1100, loss is 5.270143070220947 and perplexity is 194.44377956994919
At time: 68.59492564201355 and batch: 1150, loss is 5.157491807937622 and perplexity is 173.72816507895723
At time: 69.55590558052063 and batch: 1200, loss is 5.234320821762085 and perplexity is 187.60164810887616
At time: 70.51211309432983 and batch: 1250, loss is 5.173027811050415 and perplexity is 176.44828154931403
At time: 71.4695975780487 and batch: 1300, loss is 5.200756568908691 and perplexity is 181.40943871024828
At time: 72.43109822273254 and batch: 1350, loss is 5.125591640472412 and perplexity is 168.27366971997324
At time: 73.40911197662354 and batch: 1400, loss is 5.123971080780029 and perplexity is 168.00119303553345
At time: 74.37158560752869 and batch: 1450, loss is 5.084147882461548 and perplexity is 161.44231278279912
At time: 75.34139490127563 and batch: 1500, loss is 5.041349840164185 and perplexity is 154.67866564714814
At time: 76.31021618843079 and batch: 1550, loss is 5.032117176055908 and perplexity is 153.25714180637397
At time: 77.28769969940186 and batch: 1600, loss is 5.074369192123413 and perplexity is 159.87131208191315
At time: 78.2563374042511 and batch: 1650, loss is 5.03416485786438 and perplexity is 153.57128519074908
At time: 79.21773076057434 and batch: 1700, loss is 5.064910755157471 and perplexity is 158.36630806677206
At time: 80.19121646881104 and batch: 1750, loss is 5.0672690963745115 and perplexity is 158.74023060363578
At time: 81.18566942214966 and batch: 1800, loss is 5.03436089515686 and perplexity is 153.60139384081324
At time: 82.15230655670166 and batch: 1850, loss is 5.0069391059875485 and perplexity is 149.44659515793452
At time: 83.11814188957214 and batch: 1900, loss is 5.071012735366821 and perplexity is 159.33561046886553
At time: 84.08084201812744 and batch: 1950, loss is 4.999965620040894 and perplexity is 148.40805675194562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.786216274527616 and perplexity of 119.84704137713861
finished 2 epochs...
Completing Train Step...
At time: 87.22478795051575 and batch: 50, loss is 4.97288332939148 and perplexity is 144.44276359439007
At time: 88.19863796234131 and batch: 100, loss is 4.932977962493896 and perplexity is 138.7922155399615
At time: 89.16148042678833 and batch: 150, loss is 4.87822021484375 and perplexity is 131.3965979394736
At time: 90.12368512153625 and batch: 200, loss is 4.8627962970733645 and perplexity is 129.3854970146481
At time: 91.08452606201172 and batch: 250, loss is 4.883438758850097 and perplexity is 132.08408915948303
At time: 92.08203530311584 and batch: 300, loss is 4.901425457000732 and perplexity is 134.48134048992293
At time: 93.04659700393677 and batch: 350, loss is 4.905989532470703 and perplexity is 135.09652628652378
At time: 94.00250315666199 and batch: 400, loss is 4.857488069534302 and perplexity is 128.70050900078337
At time: 94.97668218612671 and batch: 450, loss is 4.839571981430054 and perplexity is 126.41523208197869
At time: 95.9385392665863 and batch: 500, loss is 4.841906242370605 and perplexity is 126.71066289267475
At time: 96.91424417495728 and batch: 550, loss is 4.793538637161255 and perplexity is 120.72782565018176
At time: 97.88719296455383 and batch: 600, loss is 4.772858438491821 and perplexity is 118.25678905979571
At time: 98.85119795799255 and batch: 650, loss is 4.844757871627808 and perplexity is 127.07251040845473
At time: 99.81009006500244 and batch: 700, loss is 4.846715497970581 and perplexity is 127.32151455128582
At time: 100.78679084777832 and batch: 750, loss is 4.806084575653077 and perplexity is 122.25201069872737
At time: 101.77128481864929 and batch: 800, loss is 4.790666618347168 and perplexity is 120.38159049845865
At time: 102.73983001708984 and batch: 850, loss is 4.790688629150391 and perplexity is 120.38424022311993
At time: 103.70285105705261 and batch: 900, loss is 4.784804086685181 and perplexity is 119.67791429006924
At time: 104.66439986228943 and batch: 950, loss is 4.8401103019714355 and perplexity is 126.48330231831133
At time: 105.64680242538452 and batch: 1000, loss is 4.8133740234375 and perplexity is 123.14641624810379
At time: 106.61511611938477 and batch: 1050, loss is 4.7329074573516845 and perplexity is 113.62544368990675
At time: 107.57231116294861 and batch: 1100, loss is 4.7996132183074955 and perplexity is 121.4634286016023
At time: 108.552161693573 and batch: 1150, loss is 4.716900596618652 and perplexity is 111.82113621104601
At time: 109.52752327919006 and batch: 1200, loss is 4.8047135543823245 and perplexity is 122.08451543768675
At time: 110.50105667114258 and batch: 1250, loss is 4.762680759429932 and perplexity is 117.05931351146921
At time: 111.46517825126648 and batch: 1300, loss is 4.785200185775757 and perplexity is 119.72532799272392
At time: 112.45130681991577 and batch: 1350, loss is 4.677754173278808 and perplexity is 107.52831124131755
At time: 113.40891695022583 and batch: 1400, loss is 4.681543455123902 and perplexity is 107.936539276011
At time: 114.36824917793274 and batch: 1450, loss is 4.63836259841919 and perplexity is 103.37494263467859
At time: 115.33192801475525 and batch: 1500, loss is 4.616327514648438 and perplexity is 101.12198037874097
At time: 116.31263852119446 and batch: 1550, loss is 4.625997266769409 and perplexity is 102.10454779851874
At time: 117.31263589859009 and batch: 1600, loss is 4.692148342132568 and perplexity is 109.08728505890761
At time: 118.28325963020325 and batch: 1650, loss is 4.6476218891143795 and perplexity is 104.33656638570848
At time: 119.23965430259705 and batch: 1700, loss is 4.688138370513916 and perplexity is 108.65072402552939
At time: 120.1955897808075 and batch: 1750, loss is 4.676481904983521 and perplexity is 107.39159336942804
At time: 121.18135714530945 and batch: 1800, loss is 4.644913301467896 and perplexity is 104.0543440354478
At time: 122.16159582138062 and batch: 1850, loss is 4.650831413269043 and perplexity is 104.6719750789678
At time: 123.15586352348328 and batch: 1900, loss is 4.731701908111572 and perplexity is 113.48854515814949
At time: 124.12102723121643 and batch: 1950, loss is 4.659628839492798 and perplexity is 105.59688149014701
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.58453369140625 and perplexity of 97.95749806716151
finished 3 epochs...
Completing Train Step...
At time: 127.248952627182 and batch: 50, loss is 4.6502463912963865 and perplexity is 104.61075758216158
At time: 128.25397324562073 and batch: 100, loss is 4.599763593673706 and perplexity is 99.46079970011726
At time: 129.21515464782715 and batch: 150, loss is 4.557435379028321 and perplexity is 95.3386585042894
At time: 130.17559599876404 and batch: 200, loss is 4.5558562850952145 and perplexity is 95.18822860978024
At time: 131.1684606075287 and batch: 250, loss is 4.575935592651367 and perplexity is 97.118860336525
At time: 132.14759755134583 and batch: 300, loss is 4.59796522140503 and perplexity is 99.28209289496111
At time: 133.10315585136414 and batch: 350, loss is 4.6004432201385494 and perplexity is 99.52841886709292
At time: 134.05918383598328 and batch: 400, loss is 4.557457761764526 and perplexity is 95.3407924682148
At time: 135.0487244129181 and batch: 450, loss is 4.556849737167358 and perplexity is 95.28284054116452
At time: 136.0259656906128 and batch: 500, loss is 4.564633102416992 and perplexity is 96.02735534785296
At time: 137.0208375453949 and batch: 550, loss is 4.525904893875122 and perplexity is 92.37948164551086
At time: 137.9913568496704 and batch: 600, loss is 4.514692811965943 and perplexity is 91.3495002384821
At time: 138.9621615409851 and batch: 650, loss is 4.584018545150757 and perplexity is 97.90704862437119
At time: 139.9344458580017 and batch: 700, loss is 4.595390644073486 and perplexity is 99.02681223008159
At time: 140.93075942993164 and batch: 750, loss is 4.565817155838013 and perplexity is 96.141124207376
At time: 141.90985679626465 and batch: 800, loss is 4.551363124847412 and perplexity is 94.76149206071156
At time: 142.91162514686584 and batch: 850, loss is 4.540751991271972 and perplexity is 93.7612812807156
At time: 143.91900658607483 and batch: 900, loss is 4.519813871383667 and perplexity is 91.81850633604616
At time: 144.90747237205505 and batch: 950, loss is 4.591789741516113 and perplexity is 98.67086757429733
At time: 145.87449717521667 and batch: 1000, loss is 4.568062076568603 and perplexity is 96.35719585128365
At time: 146.873188495636 and batch: 1050, loss is 4.501484661102295 and perplexity is 90.15087549173629
At time: 147.86194014549255 and batch: 1100, loss is 4.560382938385009 and perplexity is 95.62008942262773
At time: 148.84299087524414 and batch: 1150, loss is 4.495703411102295 and perplexity is 89.63119439340907
At time: 149.81419968605042 and batch: 1200, loss is 4.578091144561768 and perplexity is 97.32843087039583
At time: 150.8028106689453 and batch: 1250, loss is 4.548625087738037 and perplexity is 94.50238646115591
At time: 151.78808641433716 and batch: 1300, loss is 4.567989225387573 and perplexity is 96.35017637145695
At time: 152.75710558891296 and batch: 1350, loss is 4.4468874263763425 and perplexity is 85.36083818663484
At time: 153.7232050895691 and batch: 1400, loss is 4.467035083770752 and perplexity is 87.09810123305762
At time: 154.71229910850525 and batch: 1450, loss is 4.417783107757568 and perplexity is 82.91227389011823
At time: 155.697256565094 and batch: 1500, loss is 4.403963823318481 and perplexity is 81.77436623754045
At time: 156.6680862903595 and batch: 1550, loss is 4.414993867874146 and perplexity is 82.68133389220847
At time: 157.6399850845337 and batch: 1600, loss is 4.483835372924805 and perplexity is 88.57373535052555
At time: 158.61192846298218 and batch: 1650, loss is 4.439226312637329 and perplexity is 84.7093777390482
At time: 159.58368587493896 and batch: 1700, loss is 4.47882116317749 and perplexity is 88.13071967832809
At time: 160.5786838531494 and batch: 1750, loss is 4.479180335998535 and perplexity is 88.16237952287317
At time: 161.5489604473114 and batch: 1800, loss is 4.434585809707642 and perplexity is 84.31719429147853
At time: 162.51866364479065 and batch: 1850, loss is 4.449278383255005 and perplexity is 85.56517645451456
At time: 163.4884798526764 and batch: 1900, loss is 4.5323419094085695 and perplexity is 92.97604779672571
At time: 164.4599289894104 and batch: 1950, loss is 4.467387428283692 and perplexity is 87.12879517821857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497908623273982 and perplexity of 89.8290682910243
finished 4 epochs...
Completing Train Step...
At time: 167.66545486450195 and batch: 50, loss is 4.458098964691162 and perplexity is 86.32324946890824
At time: 168.6515760421753 and batch: 100, loss is 4.411549711227417 and perplexity is 82.39705625589204
At time: 169.63671350479126 and batch: 150, loss is 4.371224632263184 and perplexity is 79.14049037716863
At time: 170.61697053909302 and batch: 200, loss is 4.377556028366089 and perplexity is 79.64314975819102
At time: 171.58824968338013 and batch: 250, loss is 4.387709121704102 and perplexity is 80.45589303880115
At time: 172.56232333183289 and batch: 300, loss is 4.415532035827637 and perplexity is 82.72584231188947
At time: 173.5427417755127 and batch: 350, loss is 4.416082143783569 and perplexity is 82.77136297539809
At time: 174.5544490814209 and batch: 400, loss is 4.372034854888916 and perplexity is 79.20463777641172
At time: 175.5290973186493 and batch: 450, loss is 4.387678442001342 and perplexity is 80.4534247137814
At time: 176.50010704994202 and batch: 500, loss is 4.399100065231323 and perplexity is 81.37760116924584
At time: 177.46939325332642 and batch: 550, loss is 4.364251508712768 and perplexity is 78.59055357691751
At time: 178.44972825050354 and batch: 600, loss is 4.3557171058654784 and perplexity is 77.92268411994006
At time: 179.4302852153778 and batch: 650, loss is 4.417357692718506 and perplexity is 82.87700926346561
At time: 180.4009313583374 and batch: 700, loss is 4.43323561668396 and perplexity is 84.20342662540767
At time: 181.37851405143738 and batch: 750, loss is 4.404868268966675 and perplexity is 81.84836016391613
At time: 182.36136960983276 and batch: 800, loss is 4.394397420883179 and perplexity is 80.99580967146166
At time: 183.3311414718628 and batch: 850, loss is 4.381903247833252 and perplexity is 79.99012966169708
At time: 184.31773233413696 and batch: 900, loss is 4.359031019210815 and perplexity is 78.18134149008995
At time: 185.30162739753723 and batch: 950, loss is 4.432523460388183 and perplexity is 84.14348197252492
At time: 186.2868914604187 and batch: 1000, loss is 4.414287471771241 and perplexity is 82.62294874411238
At time: 187.25675439834595 and batch: 1050, loss is 4.349088220596314 and perplexity is 77.40785185428825
At time: 188.2246642112732 and batch: 1100, loss is 4.40247428894043 and perplexity is 81.652651179672
At time: 189.1925563812256 and batch: 1150, loss is 4.354358711242676 and perplexity is 77.81690622516435
At time: 190.15117001533508 and batch: 1200, loss is 4.438759336471557 and perplexity is 84.66982971333809
At time: 191.11088109016418 and batch: 1250, loss is 4.408826675415039 and perplexity is 82.17299132773654
At time: 192.0704686641693 and batch: 1300, loss is 4.420474729537964 and perplexity is 83.13574298460775
At time: 193.03194189071655 and batch: 1350, loss is 4.302081246376037 and perplexity is 73.85334085745546
At time: 193.99381852149963 and batch: 1400, loss is 4.319072189331055 and perplexity is 75.1188998329166
At time: 194.95539927482605 and batch: 1450, loss is 4.2762367534637455 and perplexity is 71.96909231605592
At time: 195.9256236553192 and batch: 1500, loss is 4.262691240310669 and perplexity is 71.00080679670805
At time: 196.89065980911255 and batch: 1550, loss is 4.274968070983887 and perplexity is 71.87784428417194
At time: 197.85530972480774 and batch: 1600, loss is 4.3475642585754395 and perplexity is 77.28997507062927
At time: 198.8127942085266 and batch: 1650, loss is 4.299984941482544 and perplexity is 73.69868389832185
At time: 199.76989245414734 and batch: 1700, loss is 4.342359485626221 and perplexity is 76.88874336486899
At time: 200.72686982154846 and batch: 1750, loss is 4.338545074462891 and perplexity is 76.59601672864254
At time: 201.6875298023224 and batch: 1800, loss is 4.294621639251709 and perplexity is 73.30447366183544
At time: 202.67390656471252 and batch: 1850, loss is 4.3166243362426755 and perplexity is 74.93524467409368
At time: 203.64310097694397 and batch: 1900, loss is 4.394390048980713 and perplexity is 80.9952125804535
At time: 204.60418939590454 and batch: 1950, loss is 4.337000064849853 and perplexity is 76.47776651885431
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462692189771076 and perplexity of 86.72066359089395
finished 5 epochs...
Completing Train Step...
At time: 207.79183650016785 and batch: 50, loss is 4.326018471717834 and perplexity is 75.64251340219928
At time: 208.75421690940857 and batch: 100, loss is 4.279929456710815 and perplexity is 72.23534410881791
At time: 209.71530508995056 and batch: 150, loss is 4.241401748657227 and perplexity is 69.5052124234636
At time: 210.67708778381348 and batch: 200, loss is 4.252847356796265 and perplexity is 70.30531192664576
At time: 211.64018869400024 and batch: 250, loss is 4.250649600028992 and perplexity is 70.15096761933202
At time: 212.59894013404846 and batch: 300, loss is 4.278650064468383 and perplexity is 72.14298586374485
At time: 213.58707404136658 and batch: 350, loss is 4.288042993545532 and perplexity is 72.82381228491538
At time: 214.5522003173828 and batch: 400, loss is 4.247637319564819 and perplexity is 69.93997117980142
At time: 215.52175903320312 and batch: 450, loss is 4.270422306060791 and perplexity is 71.55184601798716
At time: 216.50282454490662 and batch: 500, loss is 4.286340570449829 and perplexity is 72.69994081570691
At time: 217.51220798492432 and batch: 550, loss is 4.24608959197998 and perplexity is 69.83180688314835
At time: 218.50904655456543 and batch: 600, loss is 4.236433143615723 and perplexity is 69.16072499429175
At time: 219.48537611961365 and batch: 650, loss is 4.2991626262664795 and perplexity is 73.63810525993003
At time: 220.4422538280487 and batch: 700, loss is 4.316067533493042 and perplexity is 74.89353213771984
At time: 221.41756319999695 and batch: 750, loss is 4.289115962982177 and perplexity is 72.90199194444926
At time: 222.38901567459106 and batch: 800, loss is 4.279272341728211 and perplexity is 72.18789277412938
At time: 223.38440012931824 and batch: 850, loss is 4.2700425720214845 and perplexity is 71.52468050464041
At time: 224.35518503189087 and batch: 900, loss is 4.242868618965149 and perplexity is 69.60724236986799
At time: 225.34944438934326 and batch: 950, loss is 4.318889026641846 and perplexity is 75.10514211320168
At time: 226.31116557121277 and batch: 1000, loss is 4.306754989624023 and perplexity is 74.19932029035435
At time: 227.31275153160095 and batch: 1050, loss is 4.241767644882202 and perplexity is 69.53064877155356
At time: 228.27921557426453 and batch: 1100, loss is 4.29200662612915 and perplexity is 73.11303192169339
At time: 229.234219789505 and batch: 1150, loss is 4.246596283912659 and perplexity is 69.86719906204898
At time: 230.1945996284485 and batch: 1200, loss is 4.327912912368775 and perplexity is 75.78594947719517
At time: 231.17163348197937 and batch: 1250, loss is 4.301224670410156 and perplexity is 73.79010694686731
At time: 232.13103556632996 and batch: 1300, loss is 4.30504207611084 and perplexity is 74.07233206293473
At time: 233.0918629169464 and batch: 1350, loss is 4.192841305732727 and perplexity is 66.21064864903865
At time: 234.07941055297852 and batch: 1400, loss is 4.214449253082275 and perplexity is 67.65689378241656
At time: 235.0552933216095 and batch: 1450, loss is 4.165980396270752 and perplexity is 64.45584374568713
At time: 236.00919270515442 and batch: 1500, loss is 4.159993500709533 and perplexity is 64.07110618185384
At time: 236.96336817741394 and batch: 1550, loss is 4.168866701126099 and perplexity is 64.64215170188461
At time: 237.91859889030457 and batch: 1600, loss is 4.247025847434998 and perplexity is 69.89721790921327
At time: 238.87624788284302 and batch: 1650, loss is 4.203366904258728 and perplexity is 66.91123593707117
At time: 239.8329577445984 and batch: 1700, loss is 4.242002367973328 and perplexity is 69.54697113590414
At time: 240.79345035552979 and batch: 1750, loss is 4.228994703292846 and perplexity is 68.64818567853955
At time: 241.75311946868896 and batch: 1800, loss is 4.186542348861694 and perplexity is 65.79490139044866
At time: 242.71414637565613 and batch: 1850, loss is 4.222665147781372 and perplexity is 68.21504541527928
At time: 243.6746129989624 and batch: 1900, loss is 4.295060787200928 and perplexity is 73.33667224056508
At time: 244.62926745414734 and batch: 1950, loss is 4.237821578979492 and perplexity is 69.25681688390983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.430936591569767 and perplexity of 84.01006319175868
finished 6 epochs...
Completing Train Step...
At time: 247.78380846977234 and batch: 50, loss is 4.224195470809937 and perplexity is 68.31951638695146
At time: 248.74500226974487 and batch: 100, loss is 4.184358816146851 and perplexity is 65.65139280565612
At time: 249.70744609832764 and batch: 150, loss is 4.1480126953125 and perplexity is 63.308062791530475
At time: 250.6688413619995 and batch: 200, loss is 4.158075723648071 and perplexity is 63.94834983139578
At time: 251.62835836410522 and batch: 250, loss is 4.148939590454102 and perplexity is 63.36676993083419
At time: 252.58639860153198 and batch: 300, loss is 4.179228086471557 and perplexity is 65.31541589674401
At time: 253.5434811115265 and batch: 350, loss is 4.188219003677368 and perplexity is 65.90530926079084
At time: 254.50333189964294 and batch: 400, loss is 4.150277018547058 and perplexity is 63.451575126884364
At time: 255.48493838310242 and batch: 450, loss is 4.17607804775238 and perplexity is 65.10999352179034
At time: 256.47451066970825 and batch: 500, loss is 4.196932873725891 and perplexity is 66.48210899037163
At time: 257.4761435985565 and batch: 550, loss is 4.153373074531555 and perplexity is 63.64832917939611
At time: 258.45622420310974 and batch: 600, loss is 4.146426033973694 and perplexity is 63.207693982575364
At time: 259.44358825683594 and batch: 650, loss is 4.20099142074585 and perplexity is 66.7524780373179
At time: 260.41525077819824 and batch: 700, loss is 4.2264823150634765 and perplexity is 68.47593126046658
At time: 261.38598585128784 and batch: 750, loss is 4.202324023246765 and perplexity is 66.84149185333688
At time: 262.3716220855713 and batch: 800, loss is 4.190456056594849 and perplexity is 66.05290795664312
At time: 263.3425738811493 and batch: 850, loss is 4.1805838680267335 and perplexity is 65.40402938958135
At time: 264.3140389919281 and batch: 900, loss is 4.152569398880005 and perplexity is 63.59719711652191
At time: 265.30337405204773 and batch: 950, loss is 4.229978723526001 and perplexity is 68.71577012899645
At time: 266.28815150260925 and batch: 1000, loss is 4.220544619560242 and perplexity is 68.07054674726874
At time: 267.2871181964874 and batch: 1050, loss is 4.155286912918091 and perplexity is 63.770258434246024
At time: 268.2701187133789 and batch: 1100, loss is 4.205990657806397 and perplexity is 67.08702504253895
At time: 269.25883746147156 and batch: 1150, loss is 4.16107186794281 and perplexity is 64.14023563012697
At time: 270.2584619522095 and batch: 1200, loss is 4.243539867401123 and perplexity is 69.65398180757346
At time: 271.24803137779236 and batch: 1250, loss is 4.216795921325684 and perplexity is 67.815848500553
At time: 272.2229483127594 and batch: 1300, loss is 4.2205427503585815 and perplexity is 68.07041950980867
At time: 273.216450214386 and batch: 1350, loss is 4.106277813911438 and perplexity is 60.72028422030234
At time: 274.1842987537384 and batch: 1400, loss is 4.132118968963623 and perplexity is 62.30981571268339
At time: 275.15428256988525 and batch: 1450, loss is 4.0771707248687745 and perplexity is 58.97836754357947
At time: 276.11137557029724 and batch: 1500, loss is 4.080336580276489 and perplexity is 59.16538039903852
At time: 277.06761145591736 and batch: 1550, loss is 4.085012154579163 and perplexity is 59.442660247372665
At time: 278.0225203037262 and batch: 1600, loss is 4.168300371170044 and perplexity is 64.60555327932173
At time: 278.9826729297638 and batch: 1650, loss is 4.126185073852539 and perplexity is 61.94117063416749
At time: 279.9430510997772 and batch: 1700, loss is 4.1622222852706905 and perplexity is 64.21406612840985
At time: 280.9041554927826 and batch: 1750, loss is 4.1526229238510135 and perplexity is 63.60060124575593
At time: 281.8652329444885 and batch: 1800, loss is 4.106317782402039 and perplexity is 60.72271116691185
At time: 282.8455491065979 and batch: 1850, loss is 4.142947363853454 and perplexity is 62.98819726583071
At time: 283.81389689445496 and batch: 1900, loss is 4.210861802101135 and perplexity is 67.41461283778452
At time: 284.80844950675964 and batch: 1950, loss is 4.157927985191345 and perplexity is 63.938902898736316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.415651969022529 and perplexity of 82.73576448144497
finished 7 epochs...
Completing Train Step...
At time: 288.0399663448334 and batch: 50, loss is 4.145623393058777 and perplexity is 63.15698125602459
At time: 288.9975371360779 and batch: 100, loss is 4.107403898239136 and perplexity is 60.78869889385249
At time: 289.9535958766937 and batch: 150, loss is 4.072307577133179 and perplexity is 58.69224332509125
At time: 290.9168710708618 and batch: 200, loss is 4.084264454841613 and perplexity is 59.39823159762119
At time: 291.8725595474243 and batch: 250, loss is 4.068385314941406 and perplexity is 58.46248783333542
At time: 292.82954382896423 and batch: 300, loss is 4.095780992507935 and perplexity is 60.086247746758005
At time: 293.78793597221375 and batch: 350, loss is 4.111130437850952 and perplexity is 61.015653002324406
At time: 294.74972343444824 and batch: 400, loss is 4.0714005279541015 and perplexity is 58.63903071084238
At time: 295.76010394096375 and batch: 450, loss is 4.106872901916504 and perplexity is 60.75642888666808
At time: 296.724484205246 and batch: 500, loss is 4.125226593017578 and perplexity is 61.881829652359464
At time: 297.68724489212036 and batch: 550, loss is 4.081549234390259 and perplexity is 59.237171060795305
At time: 298.6429252624512 and batch: 600, loss is 4.0765665340423585 and perplexity is 58.94274411770989
At time: 299.5985143184662 and batch: 650, loss is 4.126968822479248 and perplexity is 61.98973597061067
At time: 300.556946516037 and batch: 700, loss is 4.155198292732239 and perplexity is 63.76460735249542
At time: 301.5185077190399 and batch: 750, loss is 4.131313199996948 and perplexity is 62.2596286191795
At time: 302.4798104763031 and batch: 800, loss is 4.116622633934021 and perplexity is 61.35168486451056
At time: 303.4426712989807 and batch: 850, loss is 4.109043407440185 and perplexity is 60.88844426939638
At time: 304.4322328567505 and batch: 900, loss is 4.083881893157959 and perplexity is 59.375512456148705
At time: 305.3867537975311 and batch: 950, loss is 4.157844862937927 and perplexity is 63.933588373926995
At time: 306.34147787094116 and batch: 1000, loss is 4.149451627731323 and perplexity is 63.399224387412566
At time: 307.2979590892792 and batch: 1050, loss is 4.087610530853271 and perplexity is 59.59731548466531
At time: 308.2536790370941 and batch: 1100, loss is 4.132548947334289 and perplexity is 62.33661334650862
At time: 309.24533128738403 and batch: 1150, loss is 4.092227268218994 and perplexity is 59.8730967529638
At time: 310.2286596298218 and batch: 1200, loss is 4.173153948783875 and perplexity is 64.91988354254993
At time: 311.19093775749207 and batch: 1250, loss is 4.146666746139527 and perplexity is 63.222910674839206
At time: 312.1732497215271 and batch: 1300, loss is 4.150281405448913 and perplexity is 63.45185348332756
At time: 313.1446714401245 and batch: 1350, loss is 4.03623251914978 and perplexity is 56.61265343522381
At time: 314.1054382324219 and batch: 1400, loss is 4.061109566688538 and perplexity is 58.03867314372176
At time: 315.09521222114563 and batch: 1450, loss is 4.011448292732239 and perplexity is 55.22679723994808
At time: 316.0892262458801 and batch: 1500, loss is 4.014615335464478 and perplexity is 55.401980126189
At time: 317.05593943595886 and batch: 1550, loss is 4.014600257873536 and perplexity is 55.401144804092624
At time: 318.03002524375916 and batch: 1600, loss is 4.099252033233642 and perplexity is 60.29517194217539
At time: 319.0023522377014 and batch: 1650, loss is 4.058737788200379 and perplexity is 57.90118138173293
At time: 319.9750907421112 and batch: 1700, loss is 4.096907200813294 and perplexity is 60.1539554973674
At time: 320.94623851776123 and batch: 1750, loss is 4.085721888542175 and perplexity is 59.48486369704127
At time: 321.9506139755249 and batch: 1800, loss is 4.0405707263946535 and perplexity is 56.858784355963714
At time: 322.9294557571411 and batch: 1850, loss is 4.078124489784241 and perplexity is 59.03464587519689
At time: 323.9103031158447 and batch: 1900, loss is 4.142643156051636 and perplexity is 62.969038679043514
At time: 324.89435291290283 and batch: 1950, loss is 4.087507247924805 and perplexity is 59.591160417255466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413102402797965 and perplexity of 82.52509284552214
finished 8 epochs...
Completing Train Step...
At time: 328.06914353370667 and batch: 50, loss is 4.0754108905792235 and perplexity is 58.87466666497916
At time: 329.0489046573639 and batch: 100, loss is 4.042051858901978 and perplexity is 56.943062147681694
At time: 330.00482845306396 and batch: 150, loss is 4.005484175682068 and perplexity is 54.89839843480662
At time: 330.9631435871124 and batch: 200, loss is 4.019756445884704 and perplexity is 55.68754124516688
At time: 331.91995215415955 and batch: 250, loss is 4.005995087623596 and perplexity is 54.92645384845037
At time: 332.8806354999542 and batch: 300, loss is 4.030876426696778 and perplexity is 56.31024142571495
At time: 333.84154057502747 and batch: 350, loss is 4.04309386253357 and perplexity is 57.00242794955264
At time: 334.82322669029236 and batch: 400, loss is 4.0123793363571165 and perplexity is 55.27823974133117
At time: 335.8031716346741 and batch: 450, loss is 4.049058566093445 and perplexity is 57.34344656087342
At time: 336.7895197868347 and batch: 500, loss is 4.064107689857483 and perplexity is 58.21294134259346
At time: 337.74569153785706 and batch: 550, loss is 4.018896565437317 and perplexity is 55.63967719891504
At time: 338.7051610946655 and batch: 600, loss is 4.014030437469483 and perplexity is 55.36958509391272
At time: 339.6861321926117 and batch: 650, loss is 4.062761926651001 and perplexity is 58.13465319846096
At time: 340.6481740474701 and batch: 700, loss is 4.096072773933411 and perplexity is 60.10378235578928
At time: 341.60972595214844 and batch: 750, loss is 4.072247924804688 and perplexity is 58.688742300535715
At time: 342.57059240341187 and batch: 800, loss is 4.057334213256836 and perplexity is 57.81996974098846
At time: 343.52666568756104 and batch: 850, loss is 4.049416294097901 and perplexity is 57.363963587118896
At time: 344.49857115745544 and batch: 900, loss is 4.022377142906189 and perplexity is 55.83367281829449
At time: 345.45379304885864 and batch: 950, loss is 4.097514381408692 and perplexity is 60.190490902553904
At time: 346.40985131263733 and batch: 1000, loss is 4.086563744544983 and perplexity is 59.53496247163904
At time: 347.3667690753937 and batch: 1050, loss is 4.031807599067688 and perplexity is 56.362700387107054
At time: 348.3247756958008 and batch: 1100, loss is 4.073331046104431 and perplexity is 58.752343765209254
At time: 349.28616404533386 and batch: 1150, loss is 4.030453972816467 and perplexity is 56.28645796978377
At time: 350.2469515800476 and batch: 1200, loss is 4.114989805221557 and perplexity is 61.25158981318151
At time: 351.20753502845764 and batch: 1250, loss is 4.091062369346619 and perplexity is 59.803391257879454
At time: 352.1694552898407 and batch: 1300, loss is 4.091710114479065 and perplexity is 59.84214116214659
At time: 353.13148307800293 and batch: 1350, loss is 3.9759935665130617 and perplexity is 53.30305073099329
At time: 354.0922157764435 and batch: 1400, loss is 4.007384719848633 and perplexity is 55.00283447692514
At time: 355.05343437194824 and batch: 1450, loss is 3.950849661827087 and perplexity is 51.97951308554292
At time: 356.0158784389496 and batch: 1500, loss is 3.959120874404907 and perplexity is 52.41122963640007
At time: 356.9777982234955 and batch: 1550, loss is 3.957931332588196 and perplexity is 52.34892135358353
At time: 357.9378082752228 and batch: 1600, loss is 4.045072340965271 and perplexity is 57.11531766191158
At time: 358.8950493335724 and batch: 1650, loss is 4.002881665229797 and perplexity is 54.75571053298119
At time: 359.84532403945923 and batch: 1700, loss is 4.04013542175293 and perplexity is 56.83403884951845
At time: 360.80167388916016 and batch: 1750, loss is 4.029096503257751 and perplexity is 56.2101026532559
At time: 361.76219749450684 and batch: 1800, loss is 3.9840650272369387 and perplexity is 53.73502519870219
At time: 362.73023414611816 and batch: 1850, loss is 4.022074694633484 and perplexity is 55.816788573825825
At time: 363.72563195228577 and batch: 1900, loss is 4.087497982978821 and perplexity is 59.59060831093071
At time: 364.70117354393005 and batch: 1950, loss is 4.033521728515625 and perplexity is 56.459396202501914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407284758811773 and perplexity of 82.04638506130436
finished 9 epochs...
Completing Train Step...
At time: 367.8887252807617 and batch: 50, loss is 4.019698729515076 and perplexity is 55.68432725520348
At time: 368.88474321365356 and batch: 100, loss is 3.985102128982544 and perplexity is 53.79078279528864
At time: 369.8892078399658 and batch: 150, loss is 3.951175694465637 and perplexity is 51.99646286628547
At time: 370.8864324092865 and batch: 200, loss is 3.9607113885879515 and perplexity is 52.494656768918944
At time: 371.8769073486328 and batch: 250, loss is 3.952580199241638 and perplexity is 52.06954345572134
At time: 372.84030842781067 and batch: 300, loss is 3.9726814460754394 and perplexity is 53.12679665576958
At time: 373.80268025398254 and batch: 350, loss is 3.9844708251953125 and perplexity is 53.75683518714609
At time: 374.77602982521057 and batch: 400, loss is 3.9560837507247926 and perplexity is 52.25229172898043
At time: 375.7761662006378 and batch: 450, loss is 3.993459734916687 and perplexity is 54.242228837066406
At time: 376.79182028770447 and batch: 500, loss is 4.01015634059906 and perplexity is 55.155492932239596
At time: 377.77014565467834 and batch: 550, loss is 3.968658528327942 and perplexity is 52.9135012452436
At time: 378.7764382362366 and batch: 600, loss is 3.9624006843566892 and perplexity is 52.583410715206405
At time: 379.7552766799927 and batch: 650, loss is 4.006845874786377 and perplexity is 54.97320445486962
At time: 380.7609188556671 and batch: 700, loss is 4.043124918937683 and perplexity is 57.00419826748019
At time: 381.76657724380493 and batch: 750, loss is 4.020377683639526 and perplexity is 55.72214719641032
At time: 382.7713921070099 and batch: 800, loss is 4.007916302680969 and perplexity is 55.03208081219905
At time: 383.7353620529175 and batch: 850, loss is 4.0055625629425045 and perplexity is 54.90270193853
At time: 384.6990900039673 and batch: 900, loss is 3.973571538925171 and perplexity is 53.174105489105735
At time: 385.6659302711487 and batch: 950, loss is 4.04457112789154 and perplexity is 57.08669789088998
At time: 386.65699529647827 and batch: 1000, loss is 4.034623341560364 and perplexity is 56.52162688062673
At time: 387.62410020828247 and batch: 1050, loss is 3.982937798500061 and perplexity is 53.67448766035794
At time: 388.599244594574 and batch: 1100, loss is 4.022181482315063 and perplexity is 55.82274943753857
At time: 389.5865762233734 and batch: 1150, loss is 3.981590929031372 and perplexity is 53.60224379413076
At time: 390.55230832099915 and batch: 1200, loss is 4.065539383888245 and perplexity is 58.29634415263316
At time: 391.5219328403473 and batch: 1250, loss is 4.04605767250061 and perplexity is 57.171622920672824
At time: 392.5094521045685 and batch: 1300, loss is 4.0449685907363895 and perplexity is 57.10939224201865
At time: 393.4799175262451 and batch: 1350, loss is 3.924477581977844 and perplexity is 50.62662288891348
At time: 394.44663667678833 and batch: 1400, loss is 3.956008176803589 and perplexity is 52.24834296761616
At time: 395.43625020980835 and batch: 1450, loss is 3.9004181814193726 and perplexity is 49.423112612063726
At time: 396.4091086387634 and batch: 1500, loss is 3.908899827003479 and perplexity is 49.844084681182856
At time: 397.37738037109375 and batch: 1550, loss is 3.9115492153167724 and perplexity is 49.97631610547187
At time: 398.3656327724457 and batch: 1600, loss is 3.99416277885437 and perplexity is 54.280376915533076
At time: 399.3479869365692 and batch: 1650, loss is 3.955993618965149 and perplexity is 52.247582350216966
At time: 400.3141396045685 and batch: 1700, loss is 3.9899722480773927 and perplexity is 54.053389257035946
At time: 401.29598808288574 and batch: 1750, loss is 3.982343077659607 and perplexity is 53.642575814206204
At time: 402.26102352142334 and batch: 1800, loss is 3.937089595794678 and perplexity is 51.26916994537156
At time: 403.24811363220215 and batch: 1850, loss is 3.978227014541626 and perplexity is 53.42223336913587
At time: 404.2373354434967 and batch: 1900, loss is 4.039118795394898 and perplexity is 56.77628922745842
At time: 405.25162267684937 and batch: 1950, loss is 3.981572160720825 and perplexity is 53.60123778001383
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407310024527616 and perplexity of 82.04845804814292
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 408.53360629081726 and batch: 50, loss is 3.9916583490371704 and perplexity is 54.14460560691882
At time: 409.55986523628235 and batch: 100, loss is 3.9722920560836794 and perplexity is 53.10611363999857
At time: 410.55618023872375 and batch: 150, loss is 3.948854718208313 and perplexity is 51.87592025289272
At time: 411.5619716644287 and batch: 200, loss is 3.9423390865325927 and perplexity is 51.53901463205308
At time: 412.52991342544556 and batch: 250, loss is 3.922391095161438 and perplexity is 50.521101230752635
At time: 413.50135254859924 and batch: 300, loss is 3.9449631071090696 and perplexity is 51.674431657768906
At time: 414.48185896873474 and batch: 350, loss is 3.9674703454971314 and perplexity is 52.85066766782713
At time: 415.47470808029175 and batch: 400, loss is 3.9475196027755737 and perplexity is 51.80670612588146
At time: 416.4364547729492 and batch: 450, loss is 3.977509651184082 and perplexity is 53.38392395896511
At time: 417.44579577445984 and batch: 500, loss is 3.9858901119232177 and perplexity is 53.83318571869289
At time: 418.448894739151 and batch: 550, loss is 3.939684147834778 and perplexity is 51.40236318852987
At time: 419.41578817367554 and batch: 600, loss is 3.910132174491882 and perplexity is 49.90554777791935
At time: 420.3947741985321 and batch: 650, loss is 3.9459898710250854 and perplexity is 51.727516347634065
At time: 421.38403034210205 and batch: 700, loss is 3.98500937461853 and perplexity is 53.78579369682456
At time: 422.37356996536255 and batch: 750, loss is 3.9489123249053955 and perplexity is 51.878908739394184
At time: 423.35169410705566 and batch: 800, loss is 3.934934039115906 and perplexity is 51.15877536731074
At time: 424.34564757347107 and batch: 850, loss is 3.9267151308059693 and perplexity is 50.74002925845989
At time: 425.3338928222656 and batch: 900, loss is 3.8938796710968018 and perplexity is 49.1010132526045
At time: 426.31705594062805 and batch: 950, loss is 3.970736446380615 and perplexity is 53.023565477336234
At time: 427.3208169937134 and batch: 1000, loss is 3.9406509733200075 and perplexity is 51.45208433522438
At time: 428.28410506248474 and batch: 1050, loss is 3.8790608930587767 and perplexity is 48.378760901352244
At time: 429.2773039340973 and batch: 1100, loss is 3.903148989677429 and perplexity is 49.55826210581274
At time: 430.2659385204315 and batch: 1150, loss is 3.864739890098572 and perplexity is 47.69086595279252
At time: 431.26400089263916 and batch: 1200, loss is 3.9388471126556395 and perplexity is 51.35935560419178
At time: 432.257954120636 and batch: 1250, loss is 3.9157576417922972 and perplexity is 50.187080940406396
At time: 433.2327401638031 and batch: 1300, loss is 3.9229473733901976 and perplexity is 50.5492128376728
At time: 434.195458650589 and batch: 1350, loss is 3.799409146308899 and perplexity is 44.674780434682276
At time: 435.16544699668884 and batch: 1400, loss is 3.8176067447662354 and perplexity is 45.495196309418695
At time: 436.16901302337646 and batch: 1450, loss is 3.753716297149658 and perplexity is 42.6793969664236
At time: 437.1739549636841 and batch: 1500, loss is 3.753185534477234 and perplexity is 42.65675034615425
At time: 438.16945791244507 and batch: 1550, loss is 3.7614659214019777 and perplexity is 43.01143116462896
At time: 439.17790246009827 and batch: 1600, loss is 3.84040310382843 and perplexity is 46.54423281718828
At time: 440.18785333633423 and batch: 1650, loss is 3.793335027694702 and perplexity is 44.40424298931272
At time: 441.1770362854004 and batch: 1700, loss is 3.809015254974365 and perplexity is 45.10599908075996
At time: 442.1497268676758 and batch: 1750, loss is 3.7909660005569457 and perplexity is 44.29917263903553
At time: 443.12118101119995 and batch: 1800, loss is 3.748503875732422 and perplexity is 42.45751274301061
At time: 444.09255361557007 and batch: 1850, loss is 3.773197445869446 and perplexity is 43.518992233031256
At time: 445.075722694397 and batch: 1900, loss is 3.826052680015564 and perplexity is 45.881073042719585
At time: 446.0392038822174 and batch: 1950, loss is 3.772901406288147 and perplexity is 43.50611079559379
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332728470203488 and perplexity of 76.15178123499769
finished 11 epochs...
Completing Train Step...
At time: 449.2660584449768 and batch: 50, loss is 3.9107280111312868 and perplexity is 49.93529219232096
At time: 450.236270904541 and batch: 100, loss is 3.8863086795806883 and perplexity is 48.73067358605796
At time: 451.24589467048645 and batch: 150, loss is 3.8624820613861086 and perplexity is 47.583309613908774
At time: 452.23966789245605 and batch: 200, loss is 3.8513494825363157 and perplexity is 47.05652235859965
At time: 453.20066380500793 and batch: 250, loss is 3.8338456678390505 and perplexity is 46.24002050628524
At time: 454.15557980537415 and batch: 300, loss is 3.8560437631607054 and perplexity is 47.27793816713067
At time: 455.1313045024872 and batch: 350, loss is 3.8767089080810546 and perplexity is 48.265108489246614
At time: 456.0898349285126 and batch: 400, loss is 3.8642011213302614 and perplexity is 47.665178524096994
At time: 457.050931930542 and batch: 450, loss is 3.8964603614807127 and perplexity is 49.22789141155117
At time: 458.01219487190247 and batch: 500, loss is 3.909628219604492 and perplexity is 49.88040396941353
At time: 458.97307801246643 and batch: 550, loss is 3.865036211013794 and perplexity is 47.70499984782032
At time: 459.93004727363586 and batch: 600, loss is 3.836386675834656 and perplexity is 46.35766617409951
At time: 460.8858232498169 and batch: 650, loss is 3.8766716861724855 and perplexity is 48.26331200322587
At time: 461.8692228794098 and batch: 700, loss is 3.918429207801819 and perplexity is 50.321338298809
At time: 462.8313903808594 and batch: 750, loss is 3.884744544029236 and perplexity is 48.65451178627275
At time: 463.7912609577179 and batch: 800, loss is 3.8714717626571655 and perplexity is 48.01299784348021
At time: 464.7529604434967 and batch: 850, loss is 3.864743232727051 and perplexity is 47.691025365905666
At time: 465.71238899230957 and batch: 900, loss is 3.830744786262512 and perplexity is 46.0968577586765
At time: 466.7003130912781 and batch: 950, loss is 3.91058735370636 and perplexity is 49.92826891665773
At time: 467.65747833251953 and batch: 1000, loss is 3.882859992980957 and perplexity is 48.5629062198772
At time: 468.614506483078 and batch: 1050, loss is 3.8286331510543823 and perplexity is 45.99962071156692
At time: 469.5756220817566 and batch: 1100, loss is 3.85146776676178 and perplexity is 47.06208873210047
At time: 470.5371239185333 and batch: 1150, loss is 3.819950189590454 and perplexity is 45.601936813128084
At time: 471.4987795352936 and batch: 1200, loss is 3.8933670711517334 and perplexity is 49.07585052566562
At time: 472.45447731018066 and batch: 1250, loss is 3.8743133401870726 and perplexity is 48.149624525016456
At time: 473.4085257053375 and batch: 1300, loss is 3.8821795845031737 and perplexity is 48.52987484546733
At time: 474.36492466926575 and batch: 1350, loss is 3.758923864364624 and perplexity is 42.90223250676258
At time: 475.32366728782654 and batch: 1400, loss is 3.7799964904785157 and perplexity is 43.81588796250398
At time: 476.2847545146942 and batch: 1450, loss is 3.7176091289520263 and perplexity is 41.165854108580966
At time: 477.24570083618164 and batch: 1500, loss is 3.722327919006348 and perplexity is 41.36056617289847
At time: 478.21489906311035 and batch: 1550, loss is 3.733126926422119 and perplexity is 41.80963964340586
At time: 479.1917464733124 and batch: 1600, loss is 3.813679256439209 and perplexity is 45.31686488350706
At time: 480.14483284950256 and batch: 1650, loss is 3.769127526283264 and perplexity is 43.342233375329336
At time: 481.1074764728546 and batch: 1700, loss is 3.7879680585861206 and perplexity is 44.166565164184576
At time: 482.0607578754425 and batch: 1750, loss is 3.770599365234375 and perplexity is 43.40607313203483
At time: 483.015109539032 and batch: 1800, loss is 3.733370471000671 and perplexity is 41.81982339452058
At time: 483.97030448913574 and batch: 1850, loss is 3.761653733253479 and perplexity is 43.019509979776586
At time: 484.94142627716064 and batch: 1900, loss is 3.81636905670166 and perplexity is 45.43892227998202
At time: 485.90806341171265 and batch: 1950, loss is 3.765575475692749 and perplexity is 43.18855267207385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333580691315407 and perplexity of 76.21670705232297
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 489.0665955543518 and batch: 50, loss is 3.8917665529251098 and perplexity is 48.99736655667776
At time: 490.0275239944458 and batch: 100, loss is 3.895590682029724 and perplexity is 49.18509753714888
At time: 490.99995708465576 and batch: 150, loss is 3.895886096954346 and perplexity is 49.19962969543286
At time: 491.9571466445923 and batch: 200, loss is 3.888495512008667 and perplexity is 48.83735600906922
At time: 492.9153823852539 and batch: 250, loss is 3.851392889022827 and perplexity is 47.058564961233465
At time: 493.8766031265259 and batch: 300, loss is 3.8569366931915283 and perplexity is 47.320172911445034
At time: 494.8386616706848 and batch: 350, loss is 3.875716514587402 and perplexity is 48.217234268573065
At time: 495.8219578266144 and batch: 400, loss is 3.8775670385360717 and perplexity is 48.30654402476069
At time: 496.8033308982849 and batch: 450, loss is 3.9271105480194093 and perplexity is 50.76009670668489
At time: 497.770653963089 and batch: 500, loss is 3.9524295473098756 and perplexity is 52.061699669269366
At time: 498.73108983039856 and batch: 550, loss is 3.9183954000473022 and perplexity is 50.31963707611426
At time: 499.7160129547119 and batch: 600, loss is 3.876675457954407 and perplexity is 48.26349404225686
At time: 500.70523405075073 and batch: 650, loss is 3.8940129184722903 and perplexity is 49.107556269664485
At time: 501.6758608818054 and batch: 700, loss is 3.928296880722046 and perplexity is 50.82035080303279
At time: 502.66258120536804 and batch: 750, loss is 3.886095504760742 and perplexity is 48.720286540658
At time: 503.64997482299805 and batch: 800, loss is 3.87608416557312 and perplexity is 48.234964641375306
At time: 504.6415185928345 and batch: 850, loss is 3.870597367286682 and perplexity is 47.97103384967748
At time: 505.617192029953 and batch: 900, loss is 3.8432352113723756 and perplexity is 46.67623792817976
At time: 506.6095070838928 and batch: 950, loss is 3.932601766586304 and perplexity is 51.039598191721836
At time: 507.59945249557495 and batch: 1000, loss is 3.894810552597046 and perplexity is 49.14674175809236
At time: 508.5891201496124 and batch: 1050, loss is 3.831975827217102 and perplexity is 46.153639821807005
At time: 509.5789649486542 and batch: 1100, loss is 3.847628288269043 and perplexity is 46.881741296191684
At time: 510.53510332107544 and batch: 1150, loss is 3.810056252479553 and perplexity is 45.15297876189491
At time: 511.4912838935852 and batch: 1200, loss is 3.8719234800338747 and perplexity is 48.034691048143884
At time: 512.4781303405762 and batch: 1250, loss is 3.8549312686920167 and perplexity is 47.225370968209376
At time: 513.4618592262268 and batch: 1300, loss is 3.8681636667251587 and perplexity is 47.85442866626422
At time: 514.4298410415649 and batch: 1350, loss is 3.7460583543777464 and perplexity is 42.353808845662996
At time: 515.4147663116455 and batch: 1400, loss is 3.7625469875335695 and perplexity is 43.0579545090073
At time: 516.3786072731018 and batch: 1450, loss is 3.6866910076141357 and perplexity is 39.91255785613369
At time: 517.3340976238251 and batch: 1500, loss is 3.6912384271621703 and perplexity is 40.09447030457187
At time: 518.2900991439819 and batch: 1550, loss is 3.7023854732513426 and perplexity is 40.54390549661196
At time: 519.248123884201 and batch: 1600, loss is 3.784873843193054 and perplexity is 44.030115509571516
At time: 520.2357375621796 and batch: 1650, loss is 3.7451265382766725 and perplexity is 42.31436126643784
At time: 521.1973676681519 and batch: 1700, loss is 3.753406801223755 and perplexity is 42.66618991081287
At time: 522.1590468883514 and batch: 1750, loss is 3.731348762512207 and perplexity is 41.735361310202734
At time: 523.1444337368011 and batch: 1800, loss is 3.693085026741028 and perplexity is 40.16857713831655
At time: 524.101194858551 and batch: 1850, loss is 3.716181230545044 and perplexity is 41.107115397513404
At time: 525.0861620903015 and batch: 1900, loss is 3.772177996635437 and perplexity is 43.47464943618996
At time: 526.0461812019348 and batch: 1950, loss is 3.722373447418213 and perplexity is 41.36244929665765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307428688226744 and perplexity of 74.24932511095436
finished 13 epochs...
Completing Train Step...
At time: 529.2196521759033 and batch: 50, loss is 3.891812129020691 and perplexity is 48.999599716228126
At time: 530.1765632629395 and batch: 100, loss is 3.8692533826828 and perplexity is 47.90660482425847
At time: 531.1318168640137 and batch: 150, loss is 3.866048254966736 and perplexity is 47.75330384320174
At time: 532.0903770923615 and batch: 200, loss is 3.8601120805740354 and perplexity is 47.47067161082406
At time: 533.0523540973663 and batch: 250, loss is 3.823536515235901 and perplexity is 45.765773819429484
At time: 534.014191865921 and batch: 300, loss is 3.8250721168518065 and perplexity is 45.83610580279276
At time: 534.9754753112793 and batch: 350, loss is 3.8392424154281617 and perplexity is 46.49024080606998
At time: 535.9400947093964 and batch: 400, loss is 3.8369019174575807 and perplexity is 46.38155772768693
At time: 536.8963816165924 and batch: 450, loss is 3.8875565576553344 and perplexity is 48.791521482670746
At time: 537.8533985614777 and batch: 500, loss is 3.9120700645446775 and perplexity is 50.00235301119145
At time: 538.8264002799988 and batch: 550, loss is 3.878349485397339 and perplexity is 48.344356119559855
At time: 539.782393693924 and batch: 600, loss is 3.839999976158142 and perplexity is 46.52547333053547
At time: 540.741849899292 and batch: 650, loss is 3.8605773878097533 and perplexity is 47.49276519756322
At time: 541.7242681980133 and batch: 700, loss is 3.8966291666030886 and perplexity is 49.23620203320322
At time: 542.6881546974182 and batch: 750, loss is 3.8584986686706544 and perplexity is 47.394143616375075
At time: 543.6505298614502 and batch: 800, loss is 3.8474871921539306 and perplexity is 46.87512693126666
At time: 544.6262140274048 and batch: 850, loss is 3.843224968910217 and perplexity is 46.675759851027436
At time: 545.5937473773956 and batch: 900, loss is 3.8152312421798706 and perplexity is 45.38725061631664
At time: 546.5748407840729 and batch: 950, loss is 3.905028376579285 and perplexity is 49.65148883159633
At time: 547.5318310260773 and batch: 1000, loss is 3.86874605178833 and perplexity is 47.88230648775151
At time: 548.4930431842804 and batch: 1050, loss is 3.8093934774398805 and perplexity is 45.12306240960556
At time: 549.4542517662048 and batch: 1100, loss is 3.825936541557312 and perplexity is 45.87574479504667
At time: 550.4183642864227 and batch: 1150, loss is 3.7916896390914916 and perplexity is 44.33124082889522
At time: 551.3760170936584 and batch: 1200, loss is 3.8551887464523316 and perplexity is 47.237532016488856
At time: 552.3338668346405 and batch: 1250, loss is 3.8396544599533082 and perplexity is 46.50940080238157
At time: 553.2973093986511 and batch: 1300, loss is 3.8540156364440916 and perplexity is 47.18214968605019
At time: 554.2766761779785 and batch: 1350, loss is 3.732259154319763 and perplexity is 41.77337414188476
At time: 555.2543156147003 and batch: 1400, loss is 3.7505854606628417 and perplexity is 42.545983709689715
At time: 556.2254192829132 and batch: 1450, loss is 3.6770904445648194 and perplexity is 39.53120834210634
At time: 557.1924600601196 and batch: 1500, loss is 3.6835596704483033 and perplexity is 39.78777365300373
At time: 558.2122890949249 and batch: 1550, loss is 3.697388434410095 and perplexity is 40.34181138266869
At time: 559.1863129138947 and batch: 1600, loss is 3.780688080787659 and perplexity is 43.846201086928666
At time: 560.1546227931976 and batch: 1650, loss is 3.7412826776504517 and perplexity is 42.15202296203288
At time: 561.1301898956299 and batch: 1700, loss is 3.752368679046631 and perplexity is 42.62192017552585
At time: 562.1003694534302 and batch: 1750, loss is 3.73149227142334 and perplexity is 41.74135113624654
At time: 563.0735366344452 and batch: 1800, loss is 3.6956858158111574 and perplexity is 40.27318310476384
At time: 564.0435841083527 and batch: 1850, loss is 3.7199306297302246 and perplexity is 41.26153168574403
At time: 565.028971195221 and batch: 1900, loss is 3.7767878723144532 and perplexity is 43.67552481480815
At time: 565.9998614788055 and batch: 1950, loss is 3.725889859199524 and perplexity is 41.50815272716105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.305932901071948 and perplexity of 74.13834694475055
finished 14 epochs...
Completing Train Step...
At time: 569.2192404270172 and batch: 50, loss is 3.8780464506149293 and perplexity is 48.32970831763126
At time: 570.2386388778687 and batch: 100, loss is 3.854112772941589 and perplexity is 47.186733017415875
At time: 571.2402601242065 and batch: 150, loss is 3.8501544189453125 and perplexity is 47.00032041114909
At time: 572.2451062202454 and batch: 200, loss is 3.846116533279419 and perplexity is 46.81092113471886
At time: 573.2160084247589 and batch: 250, loss is 3.8089409923553466 and perplexity is 45.10264951551005
At time: 574.2082409858704 and batch: 300, loss is 3.808524785041809 and perplexity is 45.08388136891265
At time: 575.1945269107819 and batch: 350, loss is 3.821633276939392 and perplexity is 45.67875348251381
At time: 576.1633985042572 and batch: 400, loss is 3.8186124563217163 and perplexity is 45.540974369969646
At time: 577.1276354789734 and batch: 450, loss is 3.870020127296448 and perplexity is 47.9433510411473
At time: 578.1197073459625 and batch: 500, loss is 3.8945838165283204 and perplexity is 49.13559968227843
At time: 579.0930509567261 and batch: 550, loss is 3.8603378629684446 and perplexity is 47.48139086278821
At time: 580.1057319641113 and batch: 600, loss is 3.8235361433029174 and perplexity is 45.765756797631845
At time: 581.1020519733429 and batch: 650, loss is 3.844211139678955 and perplexity is 46.72181282531734
At time: 582.0771207809448 and batch: 700, loss is 3.88138710975647 and perplexity is 48.49143137994133
At time: 583.0333766937256 and batch: 750, loss is 3.844128794670105 and perplexity is 46.7179656756257
At time: 583.9893045425415 and batch: 800, loss is 3.8335585594177246 and perplexity is 46.226746512624466
At time: 584.9490554332733 and batch: 850, loss is 3.82940712928772 and perplexity is 46.03523719815416
At time: 585.9211962223053 and batch: 900, loss is 3.8009465408325194 and perplexity is 44.74351602078481
At time: 586.905478477478 and batch: 950, loss is 3.891213240623474 and perplexity is 48.97026321001324
At time: 587.9167113304138 and batch: 1000, loss is 3.855449514389038 and perplexity is 47.24985165646165
At time: 588.9241104125977 and batch: 1050, loss is 3.7980616235733033 and perplexity is 44.61462069475072
At time: 589.8883726596832 and batch: 1100, loss is 3.81484290599823 and perplexity is 45.369628526586105
At time: 590.8434731960297 and batch: 1150, loss is 3.7818209886550904 and perplexity is 43.895902941592176
At time: 591.7992889881134 and batch: 1200, loss is 3.845513343811035 and perplexity is 46.78269379415817
At time: 592.7594838142395 and batch: 1250, loss is 3.8309458541870116 and perplexity is 46.10612729006347
At time: 593.7204849720001 and batch: 1300, loss is 3.8450597095489503 and perplexity is 46.76147637421868
At time: 594.7075123786926 and batch: 1350, loss is 3.7235045194625855 and perplexity is 41.409259674708416
At time: 595.6674249172211 and batch: 1400, loss is 3.7424420881271363 and perplexity is 42.20092280108363
At time: 596.6552836894989 and batch: 1450, loss is 3.66948890209198 and perplexity is 39.231849419172654
At time: 597.6399450302124 and batch: 1500, loss is 3.676928334236145 and perplexity is 39.52480044433636
At time: 598.6025238037109 and batch: 1550, loss is 3.6918641042709353 and perplexity is 40.11956434639463
At time: 599.5587100982666 and batch: 1600, loss is 3.775493016242981 and perplexity is 43.61900789486204
At time: 600.5369958877563 and batch: 1650, loss is 3.736245284080505 and perplexity is 41.94022054654619
At time: 601.4927704334259 and batch: 1700, loss is 3.748884129524231 and perplexity is 42.47366044313944
At time: 602.4495203495026 and batch: 1750, loss is 3.7285013151168824 and perplexity is 41.61669109812129
At time: 603.409777879715 and batch: 1800, loss is 3.6940167713165284 and perplexity is 40.206021433721375
At time: 604.3713364601135 and batch: 1850, loss is 3.719351029396057 and perplexity is 41.23762341748016
At time: 605.3432230949402 and batch: 1900, loss is 3.776431555747986 and perplexity is 43.65996527399318
At time: 606.3211131095886 and batch: 1950, loss is 3.724540934562683 and perplexity is 41.452199104412166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.305766828670058 and perplexity of 74.12603563371408
finished 15 epochs...
Completing Train Step...
At time: 609.5003190040588 and batch: 50, loss is 3.8660103368759153 and perplexity is 47.75149316341861
At time: 610.5018632411957 and batch: 100, loss is 3.8420690393447874 and perplexity is 46.62183713166369
At time: 611.4596824645996 and batch: 150, loss is 3.8373107290267945 and perplexity is 46.400522921415345
At time: 612.4529819488525 and batch: 200, loss is 3.8340257596969605 and perplexity is 46.24834870738611
At time: 613.4300820827484 and batch: 250, loss is 3.7970529890060423 and perplexity is 44.56964353268605
At time: 614.3907430171967 and batch: 300, loss is 3.795746088027954 and perplexity is 44.5114334676408
At time: 615.3897740840912 and batch: 350, loss is 3.8079425621032716 and perplexity is 45.057640138885674
At time: 616.391206741333 and batch: 400, loss is 3.8046718502044676 and perplexity is 44.91051031993691
At time: 617.3647046089172 and batch: 450, loss is 3.8565931367874144 and perplexity is 47.30391855530148
At time: 618.338784456253 and batch: 500, loss is 3.881374545097351 and perplexity is 48.49082210546352
At time: 619.3087770938873 and batch: 550, loss is 3.847028021812439 and perplexity is 46.85360820398491
At time: 620.2964894771576 and batch: 600, loss is 3.8113586950302123 and perplexity is 45.21182623713242
At time: 621.304482460022 and batch: 650, loss is 3.831700520515442 and perplexity is 46.14093516437698
At time: 622.31037068367 and batch: 700, loss is 3.869971013069153 and perplexity is 47.9409963983307
At time: 623.2959179878235 and batch: 750, loss is 3.8329807806015013 and perplexity is 46.200045392160234
At time: 624.2775616645813 and batch: 800, loss is 3.822946991920471 and perplexity is 45.738801779818495
At time: 625.2482397556305 and batch: 850, loss is 3.8187702989578245 and perplexity is 45.54816324475569
At time: 626.2352669239044 and batch: 900, loss is 3.7896774005889893 and perplexity is 44.24212548996346
At time: 627.2362773418427 and batch: 950, loss is 3.8805608415603636 and perplexity is 48.45138100086425
At time: 628.2108573913574 and batch: 1000, loss is 3.8451162910461427 and perplexity is 46.76412228341691
At time: 629.1982626914978 and batch: 1050, loss is 3.7890012407302858 and perplexity is 44.212220851940685
At time: 630.1937770843506 and batch: 1100, loss is 3.8060003519058228 and perplexity is 44.97021365851816
At time: 631.1717581748962 and batch: 1150, loss is 3.773871521949768 and perplexity is 43.548337234005736
At time: 632.1434292793274 and batch: 1200, loss is 3.8376715278625486 and perplexity is 46.41726719653962
At time: 633.1238527297974 and batch: 1250, loss is 3.8237505626678465 and perplexity is 45.775570914270624
At time: 634.1054773330688 and batch: 1300, loss is 3.837345118522644 and perplexity is 46.402118639443586
At time: 635.0932855606079 and batch: 1350, loss is 3.7158546590805055 and perplexity is 41.09369317841124
At time: 636.0618331432343 and batch: 1400, loss is 3.7352105808258056 and perplexity is 41.896847306929615
At time: 637.0579507350922 and batch: 1450, loss is 3.6623796319961546 and perplexity is 38.95392868263203
At time: 638.0566122531891 and batch: 1500, loss is 3.6705637836456297 and perplexity is 39.274041682209194
At time: 639.028751373291 and batch: 1550, loss is 3.6861238956451414 and perplexity is 39.88992938390549
At time: 639.999400138855 and batch: 1600, loss is 3.769838032722473 and perplexity is 43.37303925382378
At time: 640.9696764945984 and batch: 1650, loss is 3.7308148670196535 and perplexity is 41.71308493607615
At time: 641.9687974452972 and batch: 1700, loss is 3.7445270109176634 and perplexity is 42.289000252250176
At time: 642.9781684875488 and batch: 1750, loss is 3.724455852508545 and perplexity is 41.44867241619489
At time: 643.9741899967194 and batch: 1800, loss is 3.690777859687805 and perplexity is 40.07600834746251
At time: 644.9418060779572 and batch: 1850, loss is 3.7172222566604614 and perplexity is 41.1499312605207
At time: 645.9090926647186 and batch: 1900, loss is 3.774597754478455 and perplexity is 43.57997493985034
At time: 646.8916857242584 and batch: 1950, loss is 3.721734356880188 and perplexity is 41.33602339185493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306162279705669 and perplexity of 74.15535464800635
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 650.0459094047546 and batch: 50, loss is 3.872166676521301 and perplexity is 48.04637433689122
At time: 651.0160269737244 and batch: 100, loss is 3.8762110567092893 and perplexity is 48.241085619182435
At time: 651.9703040122986 and batch: 150, loss is 3.8761364459991454 and perplexity is 48.23748645179616
At time: 652.9365413188934 and batch: 200, loss is 3.8862616348266603 and perplexity is 48.728381117430224
At time: 653.9086425304413 and batch: 250, loss is 3.8696197366714475 and perplexity is 47.924158815309376
At time: 654.8977618217468 and batch: 300, loss is 3.868302526473999 and perplexity is 47.86107418159633
At time: 655.8519010543823 and batch: 350, loss is 3.8551891660690307 and perplexity is 47.23755183815028
At time: 656.8093645572662 and batch: 400, loss is 3.8275343990325927 and perplexity is 45.94910629180094
At time: 657.7645833492279 and batch: 450, loss is 3.8690272426605223 and perplexity is 47.895772448439274
At time: 658.7179863452911 and batch: 500, loss is 3.8923984241485594 and perplexity is 49.02833636606499
At time: 659.6700484752655 and batch: 550, loss is 3.869940633773804 and perplexity is 47.93954000676396
At time: 660.6517467498779 and batch: 600, loss is 3.8445118856430054 and perplexity is 46.73586633511992
At time: 661.6615273952484 and batch: 650, loss is 3.865715012550354 and perplexity is 47.73739306805862
At time: 662.6232187747955 and batch: 700, loss is 3.9008448410034178 and perplexity is 49.44420395582503
At time: 663.5853140354156 and batch: 750, loss is 3.8599715089797972 and perplexity is 47.463999051833284
At time: 664.5471653938293 and batch: 800, loss is 3.847393374443054 and perplexity is 46.870729420446345
At time: 665.5026445388794 and batch: 850, loss is 3.8422804260253907 and perplexity is 46.631693408764725
At time: 666.4583656787872 and batch: 900, loss is 3.811153841018677 and perplexity is 45.20256536175503
At time: 667.4277021884918 and batch: 950, loss is 3.9156743717193603 and perplexity is 50.18290203250739
At time: 668.4224758148193 and batch: 1000, loss is 3.883547616004944 and perplexity is 48.59631067582602
At time: 669.4131195545197 and batch: 1050, loss is 3.8270128774642944 and perplexity is 45.9251490894676
At time: 670.3750388622284 and batch: 1100, loss is 3.837745089530945 and perplexity is 46.420681853749386
At time: 671.3447499275208 and batch: 1150, loss is 3.8044206714630127 and perplexity is 44.89923117107716
At time: 672.3333194255829 and batch: 1200, loss is 3.857215890884399 and perplexity is 47.33338643905554
At time: 673.3252553939819 and batch: 1250, loss is 3.8377698850631714 and perplexity is 46.42183289353253
At time: 674.2863276004791 and batch: 1300, loss is 3.8508507347106935 and perplexity is 47.03305887205978
At time: 675.2714350223541 and batch: 1350, loss is 3.7270575952529907 and perplexity is 41.55665160504637
At time: 676.2397730350494 and batch: 1400, loss is 3.748035740852356 and perplexity is 42.43764155193649
At time: 677.2349331378937 and batch: 1450, loss is 3.6682574796676635 and perplexity is 39.18356817345594
At time: 678.2250783443451 and batch: 1500, loss is 3.668167276382446 and perplexity is 39.18003384628652
At time: 679.2124149799347 and batch: 1550, loss is 3.676804051399231 and perplexity is 39.51988849525046
At time: 680.2035655975342 and batch: 1600, loss is 3.7641706562042234 and perplexity is 43.1279231483383
At time: 681.2029113769531 and batch: 1650, loss is 3.721790118217468 and perplexity is 41.3383284080619
At time: 682.2038996219635 and batch: 1700, loss is 3.7388578176498415 and perplexity is 42.049934033310436
At time: 683.1726706027985 and batch: 1750, loss is 3.720213394165039 and perplexity is 41.273200629134074
At time: 684.1345632076263 and batch: 1800, loss is 3.683086323738098 and perplexity is 39.76894469790223
At time: 685.1139175891876 and batch: 1850, loss is 3.7091148710250854 and perplexity is 40.81766163790181
At time: 686.0815660953522 and batch: 1900, loss is 3.779007549285889 and perplexity is 43.77257804501683
At time: 687.065701007843 and batch: 1950, loss is 3.7366245126724245 and perplexity is 41.95612849351236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.285848644167878 and perplexity of 72.66418659906383
finished 17 epochs...
Completing Train Step...
At time: 690.2530248165131 and batch: 50, loss is 3.8975985765457155 and perplexity is 49.28395523946817
At time: 691.2139670848846 and batch: 100, loss is 3.88672381401062 and perplexity is 48.7509075660776
At time: 692.1741163730621 and batch: 150, loss is 3.8669455432891846 and perplexity is 47.79617155457084
At time: 693.145473241806 and batch: 200, loss is 3.867788481712341 and perplexity is 47.83647776949598
At time: 694.140830039978 and batch: 250, loss is 3.850319490432739 and perplexity is 47.00807946433049
At time: 695.1125931739807 and batch: 300, loss is 3.847337050437927 and perplexity is 46.86808954758697
At time: 696.0743415355682 and batch: 350, loss is 3.836208963394165 and perplexity is 46.34942857209211
At time: 697.0369284152985 and batch: 400, loss is 3.8096847629547117 and perplexity is 45.13620801854008
At time: 697.9974944591522 and batch: 450, loss is 3.854411563873291 and perplexity is 47.200834091869794
At time: 698.9626557826996 and batch: 500, loss is 3.8790817308425902 and perplexity is 48.379769018016496
At time: 699.9285478591919 and batch: 550, loss is 3.8555208444595337 and perplexity is 47.25322211191719
At time: 700.9081382751465 and batch: 600, loss is 3.829681363105774 and perplexity is 46.04786334819556
At time: 701.8694579601288 and batch: 650, loss is 3.8491000843048098 and perplexity is 46.95079245933056
At time: 702.8258302211761 and batch: 700, loss is 3.8837928771972656 and perplexity is 48.60823092665251
At time: 703.7850103378296 and batch: 750, loss is 3.8448697328567505 and perplexity is 46.75259362739887
At time: 704.7796976566315 and batch: 800, loss is 3.8324878787994385 and perplexity is 46.177278917810106
At time: 705.74458527565 and batch: 850, loss is 3.8272819662094117 and perplexity is 45.93750869304594
At time: 706.7057838439941 and batch: 900, loss is 3.7967825508117676 and perplexity is 44.55759182846362
At time: 707.6658308506012 and batch: 950, loss is 3.9016654443740846 and perplexity is 49.48479468841933
At time: 708.6277902126312 and batch: 1000, loss is 3.8695978832244875 and perplexity is 47.92311151869016
At time: 709.6423194408417 and batch: 1050, loss is 3.8136630487442016 and perplexity is 45.31613040753443
At time: 710.6301777362823 and batch: 1100, loss is 3.825590114593506 and perplexity is 45.85985495255884
At time: 711.5925097465515 and batch: 1150, loss is 3.7941804218292234 and perplexity is 44.44179794801797
At time: 712.5735223293304 and batch: 1200, loss is 3.847656364440918 and perplexity is 46.88305757449606
At time: 713.5365133285522 and batch: 1250, loss is 3.829521312713623 and perplexity is 46.040493959361505
At time: 714.4968626499176 and batch: 1300, loss is 3.8431621265411375 and perplexity is 46.672826727862976
At time: 715.4571330547333 and batch: 1350, loss is 3.7210683584213258 and perplexity is 41.308502829323814
At time: 716.417759180069 and batch: 1400, loss is 3.7439290475845337 and perplexity is 42.26372053962848
At time: 717.3805854320526 and batch: 1450, loss is 3.665396947860718 and perplexity is 39.07164249019528
At time: 718.3661527633667 and batch: 1500, loss is 3.6678625965118408 and perplexity is 39.16809829699705
At time: 719.3503119945526 and batch: 1550, loss is 3.6775653171539306 and perplexity is 39.5499850872904
At time: 720.3682804107666 and batch: 1600, loss is 3.7655510902404785 and perplexity is 43.18749951252498
At time: 721.348605632782 and batch: 1650, loss is 3.7237050199508666 and perplexity is 41.41756308388353
At time: 722.3168787956238 and batch: 1700, loss is 3.741206045150757 and perplexity is 42.148792870912665
At time: 723.2998743057251 and batch: 1750, loss is 3.7233582067489626 and perplexity is 41.403201416767175
At time: 724.2609927654266 and batch: 1800, loss is 3.687284355163574 and perplexity is 39.93624690175302
At time: 725.2243649959564 and batch: 1850, loss is 3.7140719223022463 and perplexity is 41.0204992024092
At time: 726.1860177516937 and batch: 1900, loss is 3.7837953472137453 and perplexity is 43.982654804715956
At time: 727.1693887710571 and batch: 1950, loss is 3.7397672367095947 and perplexity is 42.0881924386064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284788335755814 and perplexity of 72.5871809828229
finished 18 epochs...
Completing Train Step...
At time: 730.3589870929718 and batch: 50, loss is 3.893471655845642 and perplexity is 49.08098337687532
At time: 731.3197321891785 and batch: 100, loss is 3.882003917694092 and perplexity is 48.52135050595177
At time: 732.2835810184479 and batch: 150, loss is 3.861624488830566 and perplexity is 47.54252096559446
At time: 733.2449295520782 and batch: 200, loss is 3.8622481203079224 and perplexity is 47.572179225132366
At time: 734.2233822345734 and batch: 250, loss is 3.84358847618103 and perplexity is 46.69272991328765
At time: 735.1868557929993 and batch: 300, loss is 3.839860854148865 and perplexity is 46.51900106343099
At time: 736.1498398780823 and batch: 350, loss is 3.828565320968628 and perplexity is 45.99650065916729
At time: 737.117506980896 and batch: 400, loss is 3.8019471263885496 and perplexity is 44.788308142078954
At time: 738.1039502620697 and batch: 450, loss is 3.848011727333069 and perplexity is 46.89972103404084
At time: 739.0675828456879 and batch: 500, loss is 3.872949271202087 and perplexity is 48.08398989082472
At time: 740.0293388366699 and batch: 550, loss is 3.849131531715393 and perplexity is 46.95226896339422
At time: 740.9921827316284 and batch: 600, loss is 3.8232943487167357 and perplexity is 45.754692223136686
At time: 741.9549050331116 and batch: 650, loss is 3.8423280906677246 and perplexity is 46.63391614472501
At time: 742.9197371006012 and batch: 700, loss is 3.877468366622925 and perplexity is 48.30177776079631
At time: 743.8813073635101 and batch: 750, loss is 3.838865628242493 and perplexity is 46.47272717873797
At time: 744.844512462616 and batch: 800, loss is 3.826626524925232 and perplexity is 45.90740921865279
At time: 745.821225643158 and batch: 850, loss is 3.8216266775131227 and perplexity is 45.67845202994283
At time: 746.7981021404266 and batch: 900, loss is 3.7911315679550173 and perplexity is 44.30650774499655
At time: 747.7606160640717 and batch: 950, loss is 3.8961456394195557 and perplexity is 49.212400745854694
At time: 748.7226660251617 and batch: 1000, loss is 3.864141583442688 and perplexity is 47.662340724535994
At time: 749.6950807571411 and batch: 1050, loss is 3.8086457777023317 and perplexity is 45.08933651767598
At time: 750.6728348731995 and batch: 1100, loss is 3.8211100721359252 and perplexity is 45.65486039031073
At time: 751.6328432559967 and batch: 1150, loss is 3.7905467844009397 and perplexity is 44.28060560224037
At time: 752.6027371883392 and batch: 1200, loss is 3.843797416687012 and perplexity is 46.702486935184446
At time: 753.5670213699341 and batch: 1250, loss is 3.8260399961471556 and perplexity is 45.88049109691734
At time: 754.5282788276672 and batch: 1300, loss is 3.839989004135132 and perplexity is 46.524962854772006
At time: 755.4948379993439 and batch: 1350, loss is 3.7183627319335937 and perplexity is 41.19688851131642
At time: 756.5000398159027 and batch: 1400, loss is 3.7419478607177736 and perplexity is 42.180071101500104
At time: 757.4784951210022 and batch: 1450, loss is 3.6636848068237304 and perplexity is 39.004803562868275
At time: 758.4438788890839 and batch: 1500, loss is 3.6670717763900758 and perplexity is 39.13713562129966
At time: 759.405767917633 and batch: 1550, loss is 3.6770957279205323 and perplexity is 39.53141720009351
At time: 760.3848698139191 and batch: 1600, loss is 3.7653842687606813 and perplexity is 43.18029551085537
At time: 761.3579368591309 and batch: 1650, loss is 3.7235458517074584 and perplexity is 41.410971247740626
At time: 762.3523836135864 and batch: 1700, loss is 3.74132155418396 and perplexity is 42.15366171842039
At time: 763.341315984726 and batch: 1750, loss is 3.7237632942199705 and perplexity is 41.41997673242643
At time: 764.3150119781494 and batch: 1800, loss is 3.6880794620513915 and perplexity is 39.96801311383166
At time: 765.3002645969391 and batch: 1850, loss is 3.715151462554932 and perplexity is 41.0648063938788
At time: 766.2612028121948 and batch: 1900, loss is 3.7846815633773803 and perplexity is 44.02165022095538
At time: 767.2219095230103 and batch: 1950, loss is 3.7399363279342652 and perplexity is 42.0953097843334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284592171602471 and perplexity of 72.57294337642149
finished 19 epochs...
Completing Train Step...
At time: 770.3874225616455 and batch: 50, loss is 3.8896381568908693 and perplexity is 48.893191658057475
At time: 771.3487408161163 and batch: 100, loss is 3.878132176399231 and perplexity is 48.33385159737229
At time: 772.3099548816681 and batch: 150, loss is 3.8571756219863893 and perplexity is 47.33148041412158
At time: 773.2707784175873 and batch: 200, loss is 3.857701201438904 and perplexity is 47.35636340610619
At time: 774.2566986083984 and batch: 250, loss is 3.838532900810242 and perplexity is 46.457266999709546
At time: 775.2181737422943 and batch: 300, loss is 3.83443377494812 and perplexity is 46.26722258915363
At time: 776.1706991195679 and batch: 350, loss is 3.8231044578552247 and perplexity is 45.746004650083734
At time: 777.136066198349 and batch: 400, loss is 3.7963586044311524 and perplexity is 44.538705802293094
At time: 778.1019320487976 and batch: 450, loss is 3.8429543924331666 and perplexity is 46.66313219681342
At time: 779.0667495727539 and batch: 500, loss is 3.8680641794204713 and perplexity is 47.849667994955965
At time: 780.0327172279358 and batch: 550, loss is 3.844179277420044 and perplexity is 46.720324186536125
At time: 780.9991567134857 and batch: 600, loss is 3.8187376260757446 and perplexity is 45.5466750793005
At time: 781.9553298950195 and batch: 650, loss is 3.837717652320862 and perplexity is 46.419408217221765
At time: 783.0017757415771 and batch: 700, loss is 3.8733099555969237 and perplexity is 48.10133616369673
At time: 783.9835929870605 and batch: 750, loss is 3.834756751060486 and perplexity is 46.28216821024482
At time: 784.9532225131989 and batch: 800, loss is 3.8225873279571534 and perplexity is 45.7223541390821
At time: 785.9145400524139 and batch: 850, loss is 3.817695860862732 and perplexity is 45.49925084438261
At time: 786.8795163631439 and batch: 900, loss is 3.7871334743499756 and perplexity is 44.129719822543194
At time: 787.8416659832001 and batch: 950, loss is 3.8922311735153197 and perplexity is 49.020137031452144
At time: 788.7988977432251 and batch: 1000, loss is 3.860320463180542 and perplexity is 47.4805647038454
At time: 789.7704679965973 and batch: 1050, loss is 3.8051431798934936 and perplexity is 44.9316829660564
At time: 790.7465007305145 and batch: 1100, loss is 3.8180242395401 and perplexity is 45.51419428161493
At time: 791.7074892520905 and batch: 1150, loss is 3.788034143447876 and perplexity is 44.16948400198209
At time: 792.6748583316803 and batch: 1200, loss is 3.8409830379486083 and perplexity is 46.571233234371334
At time: 793.6519496440887 and batch: 1250, loss is 3.823403949737549 and perplexity is 45.75970725893284
At time: 794.6130359172821 and batch: 1300, loss is 3.837572388648987 and perplexity is 46.41266565327453
At time: 795.6031260490417 and batch: 1350, loss is 3.716232557296753 and perplexity is 41.10922534636683
At time: 796.5681009292603 and batch: 1400, loss is 3.7402860355377197 and perplexity is 42.11003340856637
At time: 797.5251922607422 and batch: 1450, loss is 3.662033033370972 and perplexity is 38.940429644014415
At time: 798.481912612915 and batch: 1500, loss is 3.665956425666809 and perplexity is 39.093508323169836
At time: 799.4357762336731 and batch: 1550, loss is 3.6760007619857786 and perplexity is 39.488155334363896
At time: 800.3902072906494 and batch: 1600, loss is 3.764477868080139 and perplexity is 43.141174593909554
At time: 801.3437478542328 and batch: 1650, loss is 3.7225701904296873 and perplexity is 41.3705878700717
At time: 802.3023462295532 and batch: 1700, loss is 3.7405985307693483 and perplexity is 42.123194649515696
At time: 803.2996969223022 and batch: 1750, loss is 3.723174695968628 and perplexity is 41.395604180075566
At time: 804.2578494548798 and batch: 1800, loss is 3.687750096321106 and perplexity is 39.95485118766706
At time: 805.2123520374298 and batch: 1850, loss is 3.7150917148590086 and perplexity is 41.062352939608076
At time: 806.1702687740326 and batch: 1900, loss is 3.7845099353790284 and perplexity is 44.01409552156132
At time: 807.1470732688904 and batch: 1950, loss is 3.739408240318298 and perplexity is 42.073085641209865
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284593591024709 and perplexity of 72.57304638814433
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
3332.4511263370514


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -69.81217672005135, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -72.57294337642149, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.725269039096756, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9500194842048229, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.22182319704545472, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9619850400189879, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.572005271911621 and batch: 50, loss is 7.652363624572754 and perplexity is 2105.616599440391
At time: 2.705528974533081 and batch: 100, loss is 6.952712144851684 and perplexity is 1045.9827413796318
At time: 3.8248696327209473 and batch: 150, loss is 6.72581377029419 and perplexity is 833.6501002778654
At time: 4.945810556411743 and batch: 200, loss is 6.6028041076660156 and perplexity is 737.1593680346093
At time: 6.064960479736328 and batch: 250, loss is 6.569153003692627 and perplexity is 712.7658773244549
At time: 7.187071323394775 and batch: 300, loss is 6.480895843505859 and perplexity is 652.5552719024806
At time: 8.312027215957642 and batch: 350, loss is 6.44431303024292 and perplexity is 629.1143459504392
At time: 9.435595273971558 and batch: 400, loss is 6.441716022491455 and perplexity is 627.4826507970025
At time: 10.558910846710205 and batch: 450, loss is 6.35761134147644 and perplexity is 576.8667716402063
At time: 11.681029558181763 and batch: 500, loss is 6.355070142745972 and perplexity is 575.4026995693856
At time: 12.80214238166809 and batch: 550, loss is 6.3240006637573245 and perplexity is 557.8001051809733
At time: 13.922106266021729 and batch: 600, loss is 6.384305381774903 and perplexity is 592.4730470566938
At time: 15.041390180587769 and batch: 650, loss is 6.463101654052735 and perplexity is 641.0462800322761
At time: 16.161293983459473 and batch: 700, loss is 6.3464854717254635 and perplexity is 570.4841987513407
At time: 17.281904458999634 and batch: 750, loss is 6.296611919403076 and perplexity is 542.7299786716864
At time: 18.402170658111572 and batch: 800, loss is 6.300798320770264 and perplexity is 545.0068267710823
At time: 19.522801399230957 and batch: 850, loss is 6.341949729919434 and perplexity is 567.9024891316261
At time: 20.641804218292236 and batch: 900, loss is 6.324134082794189 and perplexity is 557.8745312985897
At time: 21.761786699295044 and batch: 950, loss is 6.338392763137818 and perplexity is 565.8860671415885
At time: 22.884405374526978 and batch: 1000, loss is 6.3244468879699705 and perplexity is 558.0490646354589
At time: 24.009644985198975 and batch: 1050, loss is 6.223957424163818 and perplexity is 504.6965836052066
At time: 25.135745763778687 and batch: 1100, loss is 6.304825248718262 and perplexity is 547.2059548871107
At time: 26.274629592895508 and batch: 1150, loss is 6.217163925170898 and perplexity is 501.2795478291101
At time: 27.406392097473145 and batch: 1200, loss is 6.306907529830933 and perplexity is 548.346578649236
At time: 28.534104108810425 and batch: 1250, loss is 6.239220933914185 and perplexity is 512.4591158679114
At time: 29.66591715812683 and batch: 1300, loss is 6.245574169158935 and perplexity is 515.7252534685149
At time: 30.790224313735962 and batch: 1350, loss is 6.249111213684082 and perplexity is 517.5526264975193
At time: 31.91447377204895 and batch: 1400, loss is 6.265114936828613 and perplexity is 525.9020279970106
At time: 33.0384087562561 and batch: 1450, loss is 6.2607607173919675 and perplexity is 523.6171132849764
At time: 34.164573431015015 and batch: 1500, loss is 6.237134037017822 and perplexity is 511.39078166888453
At time: 35.28691649436951 and batch: 1550, loss is 6.2123847007751465 and perplexity is 498.88953613531385
At time: 36.40788984298706 and batch: 1600, loss is 6.200824728012085 and perplexity is 493.15559265456056
At time: 37.52910852432251 and batch: 1650, loss is 6.196360816955567 and perplexity is 490.9590960819671
At time: 38.651236057281494 and batch: 1700, loss is 6.230340375900268 and perplexity is 507.92834064213923
At time: 39.77755117416382 and batch: 1750, loss is 6.24779052734375 and perplexity is 516.8695529755216
At time: 40.9011766910553 and batch: 1800, loss is 6.261223011016845 and perplexity is 523.8592340994675
At time: 42.02149724960327 and batch: 1850, loss is 6.205324735641479 and perplexity is 495.3797972995636
At time: 43.141748905181885 and batch: 1900, loss is 6.173543624877929 and perplexity is 479.88362417839454
At time: 44.26702094078064 and batch: 1950, loss is 6.119537000656128 and perplexity is 454.6541411912042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.683370049055233 and perplexity of 293.9383492895326
finished 1 epochs...
Completing Train Step...
At time: 47.539599657058716 and batch: 50, loss is 5.990141639709472 and perplexity is 399.47118690309765
At time: 48.502572536468506 and batch: 100, loss is 5.959343357086182 and perplexity is 387.35568634294106
At time: 49.45574474334717 and batch: 150, loss is 5.866720561981201 and perplexity is 353.0891455362855
At time: 50.40988373756409 and batch: 200, loss is 5.799362983703613 and perplexity is 330.08922070915884
At time: 51.38017702102661 and batch: 250, loss is 5.7665129566192626 and perplexity is 319.42195018997825
At time: 52.36916446685791 and batch: 300, loss is 5.7246341896057125 and perplexity is 306.3211892703104
At time: 53.356667280197144 and batch: 350, loss is 5.668604183197021 and perplexity is 289.6299817215766
At time: 54.3481125831604 and batch: 400, loss is 5.6003789043426515 and perplexity is 270.52889258110304
At time: 55.34777355194092 and batch: 450, loss is 5.515145044326783 and perplexity is 248.4260074174268
At time: 56.33350491523743 and batch: 500, loss is 5.490075540542603 and perplexity is 242.275507790032
At time: 57.30462598800659 and batch: 550, loss is 5.4138432884216305 and perplexity is 224.49272210619847
At time: 58.27641797065735 and batch: 600, loss is 5.402505559921265 and perplexity is 221.96185880371593
At time: 59.275331258773804 and batch: 650, loss is 5.459067296981812 and perplexity is 234.87825051590912
At time: 60.24483251571655 and batch: 700, loss is 5.398956127166748 and perplexity is 221.17541664925997
At time: 61.21397614479065 and batch: 750, loss is 5.3224928665161135 and perplexity is 204.89401931676576
At time: 62.209481954574585 and batch: 800, loss is 5.31166916847229 and perplexity is 202.68826705298977
At time: 63.222320795059204 and batch: 850, loss is 5.298852310180664 and perplexity is 200.10701734809797
At time: 64.21065092086792 and batch: 900, loss is 5.2922243404388425 and perplexity is 198.78509974623628
At time: 65.18171954154968 and batch: 950, loss is 5.327133779525757 and perplexity is 205.84712456521427
At time: 66.15357804298401 and batch: 1000, loss is 5.287973680496216 and perplexity is 197.9419251792793
At time: 67.11488676071167 and batch: 1050, loss is 5.185631265640259 and perplexity is 178.6862126608589
At time: 68.084397315979 and batch: 1100, loss is 5.267767276763916 and perplexity is 193.9823696350702
At time: 69.0590341091156 and batch: 1150, loss is 5.155543050765991 and perplexity is 173.38994073693968
At time: 70.07230257987976 and batch: 1200, loss is 5.230925636291504 and perplexity is 186.965785765069
At time: 71.05737376213074 and batch: 1250, loss is 5.159801511764527 and perplexity is 174.12988944023755
At time: 72.05653023719788 and batch: 1300, loss is 5.182872285842896 and perplexity is 178.19390046205422
At time: 73.03674840927124 and batch: 1350, loss is 5.100882987976075 and perplexity is 164.16680063198135
At time: 74.007315158844 and batch: 1400, loss is 5.111954679489136 and perplexity is 165.99450401899375
At time: 74.97854495048523 and batch: 1450, loss is 5.063477296829223 and perplexity is 158.1394591916087
At time: 75.9510109424591 and batch: 1500, loss is 5.020890512466431 and perplexity is 151.54619750098936
At time: 76.91350793838501 and batch: 1550, loss is 5.0113576221466065 and perplexity is 150.10838834881224
At time: 77.91468262672424 and batch: 1600, loss is 5.059196863174439 and perplexity is 157.46400038795232
At time: 78.92389845848083 and batch: 1650, loss is 5.022716264724732 and perplexity is 151.82313604697336
At time: 79.89332962036133 and batch: 1700, loss is 5.049171323776245 and perplexity is 155.89322593555636
At time: 80.8651487827301 and batch: 1750, loss is 5.064261331558227 and perplexity is 158.26349463733555
At time: 81.85402393341064 and batch: 1800, loss is 5.019556522369385 and perplexity is 151.34417115480997
At time: 82.8430609703064 and batch: 1850, loss is 5.0010905265808105 and perplexity is 148.57509587965134
At time: 83.80737018585205 and batch: 1900, loss is 5.057935256958007 and perplexity is 157.2654680873239
At time: 84.77622652053833 and batch: 1950, loss is 4.9832269477844235 and perplexity is 145.9445781288941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.784952988735465 and perplexity of 119.69573590368518
finished 2 epochs...
Completing Train Step...
At time: 87.9721188545227 and batch: 50, loss is 4.973683748245239 and perplexity is 144.55842458810514
At time: 88.97473692893982 and batch: 100, loss is 4.923949060440063 and perplexity is 137.54471447726075
At time: 89.96077394485474 and batch: 150, loss is 4.869484338760376 and perplexity is 130.2537327745156
At time: 90.92970418930054 and batch: 200, loss is 4.859653396606445 and perplexity is 128.97948963027287
At time: 91.90041017532349 and batch: 250, loss is 4.873795194625854 and perplexity is 130.8164498671503
At time: 92.88293218612671 and batch: 300, loss is 4.888609180450439 and perplexity is 132.76878815301535
At time: 93.8652491569519 and batch: 350, loss is 4.891790056228638 and perplexity is 133.19178156344603
At time: 94.83432793617249 and batch: 400, loss is 4.847723226547242 and perplexity is 127.44988475021829
At time: 95.80184674263 and batch: 450, loss is 4.835861787796021 and perplexity is 125.94707610436198
At time: 96.76966571807861 and batch: 500, loss is 4.83072566986084 and perplexity is 125.30185545097748
At time: 97.73804640769958 and batch: 550, loss is 4.785963859558105 and perplexity is 119.81679400744848
At time: 98.70898389816284 and batch: 600, loss is 4.764346885681152 and perplexity is 117.25451167389635
At time: 99.67971277236938 and batch: 650, loss is 4.824854555130005 and perplexity is 124.56834923819851
At time: 100.66545414924622 and batch: 700, loss is 4.840745468139648 and perplexity is 126.5636657521531
At time: 101.65327334403992 and batch: 750, loss is 4.801973705291748 and perplexity is 121.75048010125829
At time: 102.62529397010803 and batch: 800, loss is 4.78733645439148 and perplexity is 119.98136683992622
At time: 103.59334635734558 and batch: 850, loss is 4.7730204868316655 and perplexity is 118.27595392891388
At time: 104.57834911346436 and batch: 900, loss is 4.780385265350342 and perplexity is 119.15024566438936
At time: 105.55511045455933 and batch: 950, loss is 4.830179767608643 and perplexity is 125.2334715530425
At time: 106.52596402168274 and batch: 1000, loss is 4.798539438247681 and perplexity is 121.33307359280272
At time: 107.4954206943512 and batch: 1050, loss is 4.721832695007325 and perplexity is 112.3740113533203
At time: 108.46353101730347 and batch: 1100, loss is 4.7907333660125735 and perplexity is 120.38962595675328
At time: 109.43510866165161 and batch: 1150, loss is 4.713516645431518 and perplexity is 111.44337846178924
At time: 110.40653347969055 and batch: 1200, loss is 4.801516132354736 and perplexity is 121.69478312018317
At time: 111.39376091957092 and batch: 1250, loss is 4.747354249954224 and perplexity is 115.27888158917901
At time: 112.3726875782013 and batch: 1300, loss is 4.784153661727905 and perplexity is 119.60009809732054
At time: 113.34388995170593 and batch: 1350, loss is 4.673281698226929 and perplexity is 107.04846739659295
At time: 114.34128093719482 and batch: 1400, loss is 4.689328279495239 and perplexity is 108.78008544676973
At time: 115.33680391311646 and batch: 1450, loss is 4.63716383934021 and perplexity is 103.25109523008757
At time: 116.33353686332703 and batch: 1500, loss is 4.618337678909302 and perplexity is 101.32545661149506
At time: 117.31812500953674 and batch: 1550, loss is 4.622039823532105 and perplexity is 101.70127334054236
At time: 118.28518772125244 and batch: 1600, loss is 4.693935098648072 and perplexity is 109.28237171051698
At time: 119.2485179901123 and batch: 1650, loss is 4.653176860809326 and perplexity is 104.91776583744117
At time: 120.20860004425049 and batch: 1700, loss is 4.6811019229888915 and perplexity is 107.88889234497852
At time: 121.17260265350342 and batch: 1750, loss is 4.68066180229187 and perplexity is 107.84141865832113
At time: 122.16793417930603 and batch: 1800, loss is 4.639331092834473 and perplexity is 103.47510918684416
At time: 123.16364789009094 and batch: 1850, loss is 4.655200834274292 and perplexity is 105.1303316527204
At time: 124.18285465240479 and batch: 1900, loss is 4.733836870193482 and perplexity is 113.73109772693107
At time: 125.16493535041809 and batch: 1950, loss is 4.663335056304931 and perplexity is 105.98897256608858
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.596467625817588 and perplexity of 99.13351974974118
finished 3 epochs...
Completing Train Step...
At time: 128.4356667995453 and batch: 50, loss is 4.663170833587646 and perplexity is 105.97156819814691
At time: 129.45108771324158 and batch: 100, loss is 4.604147233963013 and perplexity is 99.89775710119817
At time: 130.43803310394287 and batch: 150, loss is 4.565310173034668 and perplexity is 96.09239466427253
At time: 131.438711643219 and batch: 200, loss is 4.562414960861206 and perplexity is 95.81458914048363
At time: 132.41363048553467 and batch: 250, loss is 4.574362640380859 and perplexity is 96.96621708639516
At time: 133.385009765625 and batch: 300, loss is 4.596772871017456 and perplexity is 99.1637843996254
At time: 134.38984656333923 and batch: 350, loss is 4.603879117965699 and perplexity is 99.87097650473713
At time: 135.37710547447205 and batch: 400, loss is 4.556649036407471 and perplexity is 95.26371912156962
At time: 136.34871745109558 and batch: 450, loss is 4.564182996749878 and perplexity is 95.98414261689003
At time: 137.3196885585785 and batch: 500, loss is 4.56837755203247 and perplexity is 96.38759897780982
At time: 138.29023361206055 and batch: 550, loss is 4.539587860107422 and perplexity is 93.65219435921057
At time: 139.29794430732727 and batch: 600, loss is 4.512634162902832 and perplexity is 91.1616371138708
At time: 140.27752590179443 and batch: 650, loss is 4.5697479152679445 and perplexity is 96.51977554407367
At time: 141.25565576553345 and batch: 700, loss is 4.596951704025269 and perplexity is 99.18151974324086
At time: 142.23203015327454 and batch: 750, loss is 4.568510131835938 and perplexity is 96.40037887389832
At time: 143.243008852005 and batch: 800, loss is 4.5489216232299805 and perplexity is 94.53041392817902
At time: 144.2438817024231 and batch: 850, loss is 4.531742057800293 and perplexity is 92.92029268899098
At time: 145.2269742488861 and batch: 900, loss is 4.5250841331481935 and perplexity is 92.30369130212554
At time: 146.23565483093262 and batch: 950, loss is 4.594603195190429 and perplexity is 98.94886437140325
At time: 147.2463653087616 and batch: 1000, loss is 4.564972581863404 and perplexity is 96.05996019531149
At time: 148.22956728935242 and batch: 1050, loss is 4.496041841506958 and perplexity is 89.66153344833783
At time: 149.23424243927002 and batch: 1100, loss is 4.55889121055603 and perplexity is 95.47755661073852
At time: 150.2185230255127 and batch: 1150, loss is 4.499904451370239 and perplexity is 90.00853069786547
At time: 151.2003960609436 and batch: 1200, loss is 4.584690942764282 and perplexity is 97.97290322797146
At time: 152.17680406570435 and batch: 1250, loss is 4.540585565567016 and perplexity is 93.7456782917861
At time: 153.14083099365234 and batch: 1300, loss is 4.5722385597229005 and perplexity is 96.76047160755802
At time: 154.11851167678833 and batch: 1350, loss is 4.453901519775391 and perplexity is 85.96167176642913
At time: 155.08095359802246 and batch: 1400, loss is 4.473653573989868 and perplexity is 87.67647102030124
At time: 156.0577244758606 and batch: 1450, loss is 4.419312896728516 and perplexity is 83.03920923966534
At time: 157.0374038219452 and batch: 1500, loss is 4.413960027694702 and perplexity is 82.59589877787725
At time: 158.01255774497986 and batch: 1550, loss is 4.4184024143219 and perplexity is 82.9636379089974
At time: 158.9906165599823 and batch: 1600, loss is 4.4935071086883545 and perplexity is 89.43455320560174
At time: 159.9694046974182 and batch: 1650, loss is 4.45087797164917 and perplexity is 85.70215504318917
At time: 160.94783091545105 and batch: 1700, loss is 4.47444827079773 and perplexity is 87.74617492501254
At time: 161.94764733314514 and batch: 1750, loss is 4.4788663196563725 and perplexity is 88.1346994411655
At time: 162.92003989219666 and batch: 1800, loss is 4.437301483154297 and perplexity is 84.54648345344171
At time: 163.92667865753174 and batch: 1850, loss is 4.46230860710144 and perplexity is 86.68740542627677
At time: 164.90265417099 and batch: 1900, loss is 4.547505645751953 and perplexity is 94.3966557127271
At time: 165.8824532032013 and batch: 1950, loss is 4.480338621139526 and perplexity is 88.2645558603121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.510836437136628 and perplexity of 90.9979007106145
finished 4 epochs...
Completing Train Step...
At time: 169.07403588294983 and batch: 50, loss is 4.476770248413086 and perplexity is 87.95015630747505
At time: 170.06799578666687 and batch: 100, loss is 4.420587244033814 and perplexity is 83.14509748706547
At time: 171.07867741584778 and batch: 150, loss is 4.386372108459472 and perplexity is 80.34839432381638
At time: 172.05604791641235 and batch: 200, loss is 4.385171031951904 and perplexity is 80.25194768646276
At time: 173.0300326347351 and batch: 250, loss is 4.391932744979858 and perplexity is 80.7964270587862
At time: 174.0231626033783 and batch: 300, loss is 4.419370775222778 and perplexity is 83.0440155631509
At time: 175.02584648132324 and batch: 350, loss is 4.42010006904602 and perplexity is 83.10460114041665
At time: 176.0172939300537 and batch: 400, loss is 4.378931713104248 and perplexity is 79.75278902105147
At time: 177.00949931144714 and batch: 450, loss is 4.396774711608887 and perplexity is 81.1885893144522
At time: 177.99150133132935 and batch: 500, loss is 4.402734699249268 and perplexity is 81.67391714060072
At time: 179.0292296409607 and batch: 550, loss is 4.37420657157898 and perplexity is 79.37683472401525
At time: 180.01724672317505 and batch: 600, loss is 4.359651498794555 and perplexity is 78.22986646913655
At time: 181.0064241886139 and batch: 650, loss is 4.412705516815185 and perplexity is 82.49234629169808
At time: 181.97902965545654 and batch: 700, loss is 4.441098680496216 and perplexity is 84.86813343342293
At time: 182.96819376945496 and batch: 750, loss is 4.412803297042847 and perplexity is 82.5004128064652
At time: 183.96127557754517 and batch: 800, loss is 4.395723218917847 and perplexity is 81.10326497301436
At time: 184.9376780986786 and batch: 850, loss is 4.37533730506897 and perplexity is 79.46663953245097
At time: 185.91083550453186 and batch: 900, loss is 4.361278209686279 and perplexity is 78.35722740660702
At time: 186.88316297531128 and batch: 950, loss is 4.443925485610962 and perplexity is 85.10837851011756
At time: 187.85436344146729 and batch: 1000, loss is 4.412915182113648 and perplexity is 82.50964388739362
At time: 188.85292387008667 and batch: 1050, loss is 4.349283685684204 and perplexity is 77.42298386569617
At time: 189.84925055503845 and batch: 1100, loss is 4.405922613143921 and perplexity is 81.93470201488753
At time: 190.82384300231934 and batch: 1150, loss is 4.354029302597046 and perplexity is 77.79127688497248
At time: 191.79621267318726 and batch: 1200, loss is 4.438362474441528 and perplexity is 84.63623413968057
At time: 192.76834392547607 and batch: 1250, loss is 4.39994550704956 and perplexity is 81.44643028774992
At time: 193.74473667144775 and batch: 1300, loss is 4.424050617218017 and perplexity is 83.43355922508385
At time: 194.74467945098877 and batch: 1350, loss is 4.3020731687545775 and perplexity is 73.85274430053387
At time: 195.72426414489746 and batch: 1400, loss is 4.326018753051758 and perplexity is 75.64253468300741
At time: 196.6969223022461 and batch: 1450, loss is 4.268637228012085 and perplexity is 71.42423432062218
At time: 197.66976714134216 and batch: 1500, loss is 4.273016486167908 and perplexity is 71.73770536563316
At time: 198.6411726474762 and batch: 1550, loss is 4.2834264087677 and perplexity is 72.48838983048974
At time: 199.62601923942566 and batch: 1600, loss is 4.356830644607544 and perplexity is 78.00950237636836
At time: 200.60843324661255 and batch: 1650, loss is 4.3175767993927 and perplexity is 75.00665173418226
At time: 201.58046984672546 and batch: 1700, loss is 4.338361558914184 and perplexity is 76.58196145832362
At time: 202.5871102809906 and batch: 1750, loss is 4.340609531402588 and perplexity is 76.75430924475287
At time: 203.5893349647522 and batch: 1800, loss is 4.302270088195801 and perplexity is 73.8672887736721
At time: 204.58084440231323 and batch: 1850, loss is 4.331230955123901 and perplexity is 76.03782813879633
At time: 205.57703757286072 and batch: 1900, loss is 4.414943714141845 and perplexity is 82.67718721870862
At time: 206.5626997947693 and batch: 1950, loss is 4.349584503173828 and perplexity is 77.44627755674101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.468098769077035 and perplexity of 87.1907954935661
finished 5 epochs...
Completing Train Step...
At time: 209.8740234375 and batch: 50, loss is 4.347923393249512 and perplexity is 77.3177375655742
At time: 210.88229990005493 and batch: 100, loss is 4.290351982116699 and perplexity is 72.9921559121531
At time: 211.87041401863098 and batch: 150, loss is 4.263748016357422 and perplexity is 71.075878408585
At time: 212.84957075119019 and batch: 200, loss is 4.266592311859131 and perplexity is 71.27832698512599
At time: 213.82900834083557 and batch: 250, loss is 4.264295530319214 and perplexity is 71.11480409956759
At time: 214.80264902114868 and batch: 300, loss is 4.29154932975769 and perplexity is 73.07960524102158
At time: 215.78758096694946 and batch: 350, loss is 4.295285196304321 and perplexity is 73.35313150416364
At time: 216.77849507331848 and batch: 400, loss is 4.250954122543335 and perplexity is 70.17233342139382
At time: 217.76622343063354 and batch: 450, loss is 4.27753568649292 and perplexity is 72.06263608753969
At time: 218.7804079055786 and batch: 500, loss is 4.284841356277465 and perplexity is 72.59102969505327
At time: 219.7924861907959 and batch: 550, loss is 4.253345184326172 and perplexity is 70.34032055982922
At time: 220.7854597568512 and batch: 600, loss is 4.239268574714661 and perplexity is 69.35710374240212
At time: 221.78301429748535 and batch: 650, loss is 4.2990555000305175 and perplexity is 73.63021710941165
At time: 222.75366687774658 and batch: 700, loss is 4.327470455169678 and perplexity is 75.75242485541065
At time: 223.7237651348114 and batch: 750, loss is 4.297117166519165 and perplexity is 73.48763542221306
At time: 224.69514751434326 and batch: 800, loss is 4.279252591133118 and perplexity is 72.18646703436825
At time: 225.6890184879303 and batch: 850, loss is 4.2640018653869625 and perplexity is 71.09392324157754
At time: 226.6643087863922 and batch: 900, loss is 4.246598539352417 and perplexity is 69.86735664348521
At time: 227.69133615493774 and batch: 950, loss is 4.329533405303955 and perplexity is 75.90885963353212
At time: 228.66279935836792 and batch: 1000, loss is 4.301546821594238 and perplexity is 73.81388234662475
At time: 229.63423132896423 and batch: 1050, loss is 4.24051944732666 and perplexity is 69.44391492746867
At time: 230.62840938568115 and batch: 1100, loss is 4.291466650962829 and perplexity is 73.07356335710261
At time: 231.62862944602966 and batch: 1150, loss is 4.244131627082825 and perplexity is 69.69521242378221
At time: 232.5999674797058 and batch: 1200, loss is 4.335239515304566 and perplexity is 76.34324207500609
At time: 233.5965061187744 and batch: 1250, loss is 4.291344623565674 and perplexity is 73.0646469244009
At time: 234.567857503891 and batch: 1300, loss is 4.31265739440918 and perplexity is 74.63856975232696
At time: 235.54050636291504 and batch: 1350, loss is 4.189090566635132 and perplexity is 65.96277492589736
At time: 236.53927946090698 and batch: 1400, loss is 4.218928728103638 and perplexity is 67.96064095416416
At time: 237.51201176643372 and batch: 1450, loss is 4.160864057540894 and perplexity is 64.12690800683903
At time: 238.48175764083862 and batch: 1500, loss is 4.168081789016724 and perplexity is 64.59143320162418
At time: 239.45273876190186 and batch: 1550, loss is 4.176188702583313 and perplexity is 65.11719865574962
At time: 240.42286372184753 and batch: 1600, loss is 4.25698031425476 and perplexity is 70.59648207239314
At time: 241.3933560848236 and batch: 1650, loss is 4.214766488075257 and perplexity is 67.67836032142942
At time: 242.36562991142273 and batch: 1700, loss is 4.2348508596420285 and perplexity is 69.05137961805572
At time: 243.36603689193726 and batch: 1750, loss is 4.240425209999085 and perplexity is 69.43737102685424
At time: 244.36923599243164 and batch: 1800, loss is 4.198523626327515 and perplexity is 66.5879497391136
At time: 245.33825731277466 and batch: 1850, loss is 4.2324257087707515 and perplexity is 68.88412249846166
At time: 246.31277632713318 and batch: 1900, loss is 4.312395524978638 and perplexity is 74.61902675153839
At time: 247.33158707618713 and batch: 1950, loss is 4.245828676223755 and perplexity is 69.8135890412112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.44041378997093 and perplexity of 84.81002795315342
finished 6 epochs...
Completing Train Step...
At time: 250.6222071647644 and batch: 50, loss is 4.2442951488494876 and perplexity is 69.70661003989942
At time: 251.5951690673828 and batch: 100, loss is 4.191945571899414 and perplexity is 66.15136808468526
At time: 252.60068607330322 and batch: 150, loss is 4.167868723869324 and perplexity is 64.57767248440499
At time: 253.6204309463501 and batch: 200, loss is 4.170361495018005 and perplexity is 64.73885064990128
At time: 254.62656688690186 and batch: 250, loss is 4.159251050949097 and perplexity is 64.02355425905938
At time: 255.6507351398468 and batch: 300, loss is 4.191239643096924 and perplexity is 66.10468640753898
At time: 256.6657431125641 and batch: 350, loss is 4.196018371582031 and perplexity is 66.42133875066412
At time: 257.68404746055603 and batch: 400, loss is 4.154994330406189 and perplexity is 63.751603101093906
At time: 258.66741466522217 and batch: 450, loss is 4.1834076356887815 and perplexity is 65.58897617322077
At time: 259.6401479244232 and batch: 500, loss is 4.193541083335877 and perplexity is 66.2569975931384
At time: 260.6115550994873 and batch: 550, loss is 4.161000866889953 and perplexity is 64.13568176753319
At time: 261.6094853878021 and batch: 600, loss is 4.153252391815186 and perplexity is 63.64064838961696
At time: 262.61439967155457 and batch: 650, loss is 4.204731912612915 and perplexity is 67.00263269759381
At time: 263.58552265167236 and batch: 700, loss is 4.236766247749329 and perplexity is 69.18376655507707
At time: 264.566752910614 and batch: 750, loss is 4.209627628326416 and perplexity is 67.33146281193233
At time: 265.5565803050995 and batch: 800, loss is 4.190341868400574 and perplexity is 66.04536592497061
At time: 266.5583827495575 and batch: 850, loss is 4.172342658042908 and perplexity is 64.86723600124628
At time: 267.5349597930908 and batch: 900, loss is 4.152131352424622 and perplexity is 63.56934469052631
At time: 268.51820516586304 and batch: 950, loss is 4.2428285074234005 and perplexity is 69.60445037205571
At time: 269.49113297462463 and batch: 1000, loss is 4.215043983459473 and perplexity is 67.69714336001265
At time: 270.46390438079834 and batch: 1050, loss is 4.157167563438415 and perplexity is 63.89030084748412
At time: 271.47295808792114 and batch: 1100, loss is 4.197417283058167 and perplexity is 66.51432134574883
At time: 272.48587822914124 and batch: 1150, loss is 4.1562429666519165 and perplexity is 63.83125538146256
At time: 273.4694809913635 and batch: 1200, loss is 4.2444016551971435 and perplexity is 69.7140346317183
At time: 274.4388327598572 and batch: 1250, loss is 4.208723459243775 and perplexity is 67.27061129914262
At time: 275.42744183540344 and batch: 1300, loss is 4.2264108562469485 and perplexity is 68.47103822628534
At time: 276.39266300201416 and batch: 1350, loss is 4.099826407432556 and perplexity is 60.32981388102361
At time: 277.38771414756775 and batch: 1400, loss is 4.133634524345398 and perplexity is 62.40432128534955
At time: 278.3468339443207 and batch: 1450, loss is 4.072786684036255 and perplexity is 58.7203699213105
At time: 279.3079605102539 and batch: 1500, loss is 4.0866095113754275 and perplexity is 59.537687260524
At time: 280.2780463695526 and batch: 1550, loss is 4.090643634796143 and perplexity is 59.77835475391456
At time: 281.27131271362305 and batch: 1600, loss is 4.17437294960022 and perplexity is 64.99906918746264
At time: 282.2499027252197 and batch: 1650, loss is 4.1309601593017575 and perplexity is 62.23765231610238
At time: 283.2186391353607 and batch: 1700, loss is 4.1544008588790895 and perplexity is 63.7137795645526
At time: 284.1963384151459 and batch: 1750, loss is 4.158635368347168 and perplexity is 63.98414820264492
At time: 285.1846468448639 and batch: 1800, loss is 4.11340190410614 and perplexity is 61.154405525335875
At time: 286.15723395347595 and batch: 1850, loss is 4.149109354019165 and perplexity is 63.3775282127605
At time: 287.15700936317444 and batch: 1900, loss is 4.231715388298035 and perplexity is 68.83521006981219
At time: 288.1301431655884 and batch: 1950, loss is 4.168771371841431 and perplexity is 64.6359897055175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425612054869186 and perplexity of 83.56393728794757
finished 7 epochs...
Completing Train Step...
At time: 291.38819217681885 and batch: 50, loss is 4.166206259727478 and perplexity is 64.47040360957043
At time: 292.39049553871155 and batch: 100, loss is 4.113413186073303 and perplexity is 61.15509547122286
At time: 293.4033770561218 and batch: 150, loss is 4.089008264541626 and perplexity is 59.68067490381657
At time: 294.3858814239502 and batch: 200, loss is 4.0895671367645265 and perplexity is 59.714038097276955
At time: 295.3838653564453 and batch: 250, loss is 4.079132227897644 and perplexity is 59.09416732383561
At time: 296.3688449859619 and batch: 300, loss is 4.1074407052993775 and perplexity is 60.79093638833223
At time: 297.37034916877747 and batch: 350, loss is 4.111610012054443 and perplexity is 61.04492155317352
At time: 298.35334038734436 and batch: 400, loss is 4.074532561302185 and perplexity is 58.822978024717415
At time: 299.34431982040405 and batch: 450, loss is 4.106429491043091 and perplexity is 60.72949479734531
At time: 300.35900115966797 and batch: 500, loss is 4.116571707725525 and perplexity is 61.348560535371334
At time: 301.3606147766113 and batch: 550, loss is 4.084522910118103 and perplexity is 59.413585368037786
At time: 302.33177399635315 and batch: 600, loss is 4.0828641986846925 and perplexity is 59.31511706251651
At time: 303.30295991897583 and batch: 650, loss is 4.132233033180237 and perplexity is 62.31692343836085
At time: 304.2992699146271 and batch: 700, loss is 4.165063509941101 and perplexity is 64.3967721487988
At time: 305.29331827163696 and batch: 750, loss is 4.13511697769165 and perplexity is 62.49690138614471
At time: 306.2849590778351 and batch: 800, loss is 4.112426271438599 and perplexity is 61.094770385267054
At time: 307.30342078208923 and batch: 850, loss is 4.098169374465942 and perplexity is 60.22992817036595
At time: 308.3185303211212 and batch: 900, loss is 4.083767170906067 and perplexity is 59.368701154363904
At time: 309.2925796508789 and batch: 950, loss is 4.171495423316956 and perplexity is 64.81230150082375
At time: 310.28045082092285 and batch: 1000, loss is 4.145555830001831 and perplexity is 63.15271432144861
At time: 311.2696268558502 and batch: 1050, loss is 4.089915013313293 and perplexity is 59.73481482442169
At time: 312.2546720504761 and batch: 1100, loss is 4.12115394115448 and perplexity is 61.630319008819264
At time: 313.23620796203613 and batch: 1150, loss is 4.082033619880677 and perplexity is 59.26587163746082
At time: 314.208372592926 and batch: 1200, loss is 4.176847696304321 and perplexity is 65.16012462321144
At time: 315.207368850708 and batch: 1250, loss is 4.135927186012268 and perplexity is 62.547557413857135
At time: 316.205429315567 and batch: 1300, loss is 4.1504423666000365 and perplexity is 63.462067588720174
At time: 317.20628213882446 and batch: 1350, loss is 4.027898969650269 and perplexity is 56.142829455245995
At time: 318.21959495544434 and batch: 1400, loss is 4.064913926124572 and perplexity is 58.25989365190178
At time: 319.2049877643585 and batch: 1450, loss is 4.002241125106812 and perplexity is 54.720648533929655
At time: 320.19748711586 and batch: 1500, loss is 4.016983752250671 and perplexity is 55.53335061453404
At time: 321.1683576107025 and batch: 1550, loss is 4.022092123031616 and perplexity is 55.817761379516725
At time: 322.17133808135986 and batch: 1600, loss is 4.107282848358154 and perplexity is 60.78134087443901
At time: 323.15017890930176 and batch: 1650, loss is 4.062226920127869 and perplexity is 58.103559098294625
At time: 324.15046739578247 and batch: 1700, loss is 4.08541130065918 and perplexity is 59.466391287957045
At time: 325.127161026001 and batch: 1750, loss is 4.091561908721924 and perplexity is 59.83327286948894
At time: 326.09882712364197 and batch: 1800, loss is 4.041852612495422 and perplexity is 56.931717577390444
At time: 327.0784101486206 and batch: 1850, loss is 4.080288405418396 and perplexity is 59.162530183888684
At time: 328.08068108558655 and batch: 1900, loss is 4.163521237373352 and perplexity is 64.29753132153613
At time: 329.0558190345764 and batch: 1950, loss is 4.102667679786682 and perplexity is 60.50147106025229
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416414482648983 and perplexity of 82.79887568777663
finished 8 epochs...
Completing Train Step...
At time: 332.28394293785095 and batch: 50, loss is 4.098276100158691 and perplexity is 60.23635659420706
At time: 333.319783449173 and batch: 100, loss is 4.050563397407532 and perplexity is 57.42980373510947
At time: 334.316912651062 and batch: 150, loss is 4.021575160026551 and perplexity is 55.788913119242096
At time: 335.2931387424469 and batch: 200, loss is 4.02502790927887 and perplexity is 55.98187117349564
At time: 336.264034986496 and batch: 250, loss is 4.014422526359558 and perplexity is 55.391299149717966
At time: 337.2761118412018 and batch: 300, loss is 4.037847628593445 and perplexity is 56.704162945462585
At time: 338.2797327041626 and batch: 350, loss is 4.042558264732361 and perplexity is 56.97190574902069
At time: 339.26896834373474 and batch: 400, loss is 4.011136174201965 and perplexity is 55.2095626229234
At time: 340.27198576927185 and batch: 450, loss is 4.04447536945343 and perplexity is 57.08123161958804
At time: 341.2617509365082 and batch: 500, loss is 4.055811595916748 and perplexity is 57.73199904230876
At time: 342.23299837112427 and batch: 550, loss is 4.022302980422974 and perplexity is 55.82953220801213
At time: 343.2290503978729 and batch: 600, loss is 4.018301720619202 and perplexity is 55.60659006708174
At time: 344.24214577674866 and batch: 650, loss is 4.0669080352783205 and perplexity is 58.376186150561324
At time: 345.2153630256653 and batch: 700, loss is 4.1015236377716064 and perplexity is 60.43229441342574
At time: 346.18785572052 and batch: 750, loss is 4.077058129310608 and perplexity is 58.97172721520889
At time: 347.20718026161194 and batch: 800, loss is 4.046113300323486 and perplexity is 57.17480334204533
At time: 348.2178716659546 and batch: 850, loss is 4.04055995464325 and perplexity is 56.85817189057218
At time: 349.1885316371918 and batch: 900, loss is 4.021613917350769 and perplexity is 55.7910753901373
At time: 350.19633388519287 and batch: 950, loss is 4.107776293754577 and perplexity is 60.811340548273705
At time: 351.24962282180786 and batch: 1000, loss is 4.083642172813415 and perplexity is 59.3612806437409
At time: 352.2420914173126 and batch: 1050, loss is 4.031728086471557 and perplexity is 56.35821902063926
At time: 353.23558282852173 and batch: 1100, loss is 4.05795467376709 and perplexity is 57.85585588073183
At time: 354.2085802555084 and batch: 1150, loss is 4.021221294403076 and perplexity is 55.76917483327458
At time: 355.1794466972351 and batch: 1200, loss is 4.111976799964904 and perplexity is 61.0673161991859
At time: 356.15065598487854 and batch: 1250, loss is 4.084684891700745 and perplexity is 59.42321005411599
At time: 357.1506578922272 and batch: 1300, loss is 4.091953091621399 and perplexity is 59.85668320121728
At time: 358.1413052082062 and batch: 1350, loss is 3.9723680591583252 and perplexity is 53.11015002130445
At time: 359.1084051132202 and batch: 1400, loss is 4.001528358459472 and perplexity is 54.68165937746971
At time: 360.06947231292725 and batch: 1450, loss is 3.9427783155441283 and perplexity is 51.56165703474149
At time: 361.0511112213135 and batch: 1500, loss is 3.954728856086731 and perplexity is 52.18154331823457
At time: 362.04287672042847 and batch: 1550, loss is 3.9650008344650267 and perplexity is 52.72031338288667
At time: 363.0144855976105 and batch: 1600, loss is 4.046172952651977 and perplexity is 57.17821405392314
At time: 364.02043890953064 and batch: 1650, loss is 4.003613128662109 and perplexity is 54.79577698473207
At time: 365.0009915828705 and batch: 1700, loss is 4.025611176490783 and perplexity is 56.0145330877986
At time: 365.9751172065735 and batch: 1750, loss is 4.027614479064941 and perplexity is 56.12685962057384
At time: 366.9393768310547 and batch: 1800, loss is 3.9837682819366456 and perplexity is 53.719081948172665
At time: 367.90710973739624 and batch: 1850, loss is 4.026567287445069 and perplexity is 56.06811480743576
At time: 368.86836791038513 and batch: 1900, loss is 4.1018862056732175 and perplexity is 60.45420919615908
At time: 369.87864780426025 and batch: 1950, loss is 4.04748462677002 and perplexity is 57.25326244617043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.414701240007267 and perplexity of 82.65714256954112
finished 9 epochs...
Completing Train Step...
At time: 373.20608854293823 and batch: 50, loss is 4.03892970085144 and perplexity is 56.76555415597146
At time: 374.1973807811737 and batch: 100, loss is 3.991522340774536 and perplexity is 54.13724199394665
At time: 375.1957116127014 and batch: 150, loss is 3.9608642625808717 and perplexity is 52.50268245014952
At time: 376.2244951725006 and batch: 200, loss is 3.9693862104415896 and perplexity is 52.95201946648088
At time: 377.1953675746918 and batch: 250, loss is 3.9578878355026244 and perplexity is 52.3466443775931
At time: 378.1962969303131 and batch: 300, loss is 3.981367325782776 and perplexity is 53.590259498200034
At time: 379.1676769256592 and batch: 350, loss is 3.9810733890533445 and perplexity is 53.57450966743402
At time: 380.1448817253113 and batch: 400, loss is 3.9569123792648315 and perplexity is 52.29560741301705
At time: 381.1229021549225 and batch: 450, loss is 3.986461386680603 and perplexity is 53.86394804483719
At time: 382.12301683425903 and batch: 500, loss is 4.001410436630249 and perplexity is 54.675211596345505
At time: 383.09561944007874 and batch: 550, loss is 3.9676852464675902 and perplexity is 52.862026548071825
At time: 384.0653238296509 and batch: 600, loss is 3.9653475952148436 and perplexity is 52.738597888277084
At time: 385.0588130950928 and batch: 650, loss is 4.014037508964538 and perplexity is 55.36997664104433
At time: 386.0450773239136 and batch: 700, loss is 4.044519233703613 and perplexity is 57.083735499927585
At time: 387.0171160697937 and batch: 750, loss is 4.020454339981079 and perplexity is 55.72641881607913
At time: 387.98881316185 and batch: 800, loss is 3.988526439666748 and perplexity is 53.975294880581224
At time: 388.97522473335266 and batch: 850, loss is 3.985762720108032 and perplexity is 53.82632824824904
At time: 389.9492185115814 and batch: 900, loss is 3.9673990917205813 and perplexity is 52.8469019923235
At time: 390.93169808387756 and batch: 950, loss is 4.055956749916077 and perplexity is 57.74037968108589
At time: 391.93183875083923 and batch: 1000, loss is 4.0339055919647215 and perplexity is 56.481073061272824
At time: 392.90962409973145 and batch: 1050, loss is 3.9824249505996705 and perplexity is 53.64696786939348
At time: 393.8828239440918 and batch: 1100, loss is 4.00682755947113 and perplexity is 54.972197612520254
At time: 394.8631684780121 and batch: 1150, loss is 3.9671452808380128 and perplexity is 52.83349057554158
At time: 395.84785175323486 and batch: 1200, loss is 4.060133237838745 and perplexity is 57.982035965482325
At time: 396.8218398094177 and batch: 1250, loss is 4.030157852172851 and perplexity is 56.26979285518692
At time: 397.8327600955963 and batch: 1300, loss is 4.0371060562133785 and perplexity is 56.662128292182715
At time: 398.8302574157715 and batch: 1350, loss is 3.923102626800537 and perplexity is 50.557061384596885
At time: 399.8354012966156 and batch: 1400, loss is 3.956646227836609 and perplexity is 52.28169071447105
At time: 400.83826780319214 and batch: 1450, loss is 3.8884388494491575 and perplexity is 48.83458883787632
At time: 401.822167634964 and batch: 1500, loss is 3.9057925748825073 and perplexity is 49.689446917018856
At time: 402.79387855529785 and batch: 1550, loss is 3.9162906789779663 and perplexity is 50.21383965184836
At time: 403.78587794303894 and batch: 1600, loss is 3.998425369262695 and perplexity is 54.51224575940672
At time: 404.75701451301575 and batch: 1650, loss is 3.954139246940613 and perplexity is 52.15078567142156
At time: 405.75078225135803 and batch: 1700, loss is 3.9773597383499144 and perplexity is 53.37592162346681
At time: 406.7317588329315 and batch: 1750, loss is 3.9757742071151734 and perplexity is 53.2913594882182
At time: 407.73815989494324 and batch: 1800, loss is 3.9373885202407837 and perplexity is 51.28449784442752
At time: 408.7497253417969 and batch: 1850, loss is 3.9774417781829836 and perplexity is 53.38030075479586
At time: 409.7244522571564 and batch: 1900, loss is 4.0522052526474 and perplexity is 57.52417260811175
At time: 410.72335386276245 and batch: 1950, loss is 3.9952444410324097 and perplexity is 54.339121711536755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413073162699854 and perplexity of 82.52267983898918
finished 10 epochs...
Completing Train Step...
At time: 413.98276710510254 and batch: 50, loss is 3.988295564651489 and perplexity is 53.96283477197128
At time: 415.0085687637329 and batch: 100, loss is 3.94388662815094 and perplexity is 51.618835149020725
At time: 416.01845359802246 and batch: 150, loss is 3.9162734079360964 and perplexity is 50.21297241401035
At time: 417.01088070869446 and batch: 200, loss is 3.921616277694702 and perplexity is 50.48197176013655
At time: 417.9979543685913 and batch: 250, loss is 3.9073047733306883 and perplexity is 49.76464406371229
At time: 418.98590755462646 and batch: 300, loss is 3.930626254081726 and perplexity is 50.938868356549385
At time: 419.9699206352234 and batch: 350, loss is 3.9371438789367676 and perplexity is 51.27195307254629
At time: 420.96534514427185 and batch: 400, loss is 3.899809203147888 and perplexity is 49.39302417290655
At time: 421.95873975753784 and batch: 450, loss is 3.9404230880737305 and perplexity is 51.44036050020944
At time: 422.9494218826294 and batch: 500, loss is 3.955412259101868 and perplexity is 52.217216530474744
At time: 423.94608521461487 and batch: 550, loss is 3.9187178230285644 and perplexity is 50.33586389932616
At time: 424.9285616874695 and batch: 600, loss is 3.9159713792800903 and perplexity is 50.197808947454064
At time: 425.9128363132477 and batch: 650, loss is 3.968155889511108 and perplexity is 52.8869115486498
At time: 426.88212513923645 and batch: 700, loss is 3.9983013916015624 and perplexity is 54.50548787759622
At time: 427.8485405445099 and batch: 750, loss is 3.9779823780059815 and perplexity is 53.40916593748882
At time: 428.8071837425232 and batch: 800, loss is 3.9465650129318237 and perplexity is 51.75727556708386
At time: 429.7891163825989 and batch: 850, loss is 3.941491107940674 and perplexity is 51.49532917578009
At time: 430.78378462791443 and batch: 900, loss is 3.9160927820205687 and perplexity is 50.20390346896461
At time: 431.75965785980225 and batch: 950, loss is 4.011452345848084 and perplexity is 55.22702108100865
At time: 432.76861810684204 and batch: 1000, loss is 3.9909340286254884 and perplexity is 54.105401763681186
At time: 433.75302743911743 and batch: 1050, loss is 3.9412575864791872 and perplexity is 51.48330531522061
At time: 434.73880338668823 and batch: 1100, loss is 3.9580545091629027 and perplexity is 52.35536991155294
At time: 435.75165724754333 and batch: 1150, loss is 3.9237669467926026 and perplexity is 50.5906586096333
At time: 436.7481322288513 and batch: 1200, loss is 4.016324343681336 and perplexity is 55.4967435180979
At time: 437.72939109802246 and batch: 1250, loss is 3.9902571392059327 and perplexity is 54.068790781877524
At time: 438.737051486969 and batch: 1300, loss is 3.9935731172561644 and perplexity is 54.24837929654056
At time: 439.72643518447876 and batch: 1350, loss is 3.878217239379883 and perplexity is 48.33796319372538
At time: 440.74086833000183 and batch: 1400, loss is 3.9098930597305297 and perplexity is 49.893616051355096
At time: 441.74293780326843 and batch: 1450, loss is 3.844919300079346 and perplexity is 46.754911081048505
At time: 442.76287055015564 and batch: 1500, loss is 3.861340627670288 and perplexity is 47.529027405670014
At time: 443.79103231430054 and batch: 1550, loss is 3.869097270965576 and perplexity is 47.89912662564539
At time: 444.8135132789612 and batch: 1600, loss is 3.949397487640381 and perplexity is 51.90408455933724
At time: 445.8347215652466 and batch: 1650, loss is 3.9072259521484374 and perplexity is 49.76072171021719
At time: 446.82945704460144 and batch: 1700, loss is 3.9346418476104734 and perplexity is 51.143829391370026
At time: 447.8547031879425 and batch: 1750, loss is 3.929595422744751 and perplexity is 50.886386029638395
At time: 448.86683559417725 and batch: 1800, loss is 3.893226218223572 and perplexity is 49.06893853521554
At time: 449.8837585449219 and batch: 1850, loss is 3.934844608306885 and perplexity is 51.154200401215626
At time: 450.8945860862732 and batch: 1900, loss is 4.010525541305542 and perplexity is 55.17586013875869
At time: 451.8910608291626 and batch: 1950, loss is 3.950510778427124 and perplexity is 51.961901075797485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417655625454215 and perplexity of 82.90170471617213
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 455.1392648220062 and batch: 50, loss is 3.975734233856201 and perplexity is 53.289229301479935
At time: 456.1340379714966 and batch: 100, loss is 3.944422092437744 and perplexity is 51.646482593218344
At time: 457.1329333782196 and batch: 150, loss is 3.9049808311462404 and perplexity is 49.64912818617793
At time: 458.141704082489 and batch: 200, loss is 3.9125745820999147 and perplexity is 50.02758644090766
At time: 459.1523892879486 and batch: 250, loss is 3.90197256565094 and perplexity is 49.49999485577689
At time: 460.1240966320038 and batch: 300, loss is 3.9321527338027953 and perplexity is 51.0166848836749
At time: 461.101446390152 and batch: 350, loss is 3.9207769441604614 and perplexity is 50.43961832517923
At time: 462.0975852012634 and batch: 400, loss is 3.8836142301559446 and perplexity is 48.599547985627574
At time: 463.06278800964355 and batch: 450, loss is 3.920961036682129 and perplexity is 50.44890473646188
At time: 464.027649641037 and batch: 500, loss is 3.925815110206604 and perplexity is 50.69438273140347
At time: 464.9922170639038 and batch: 550, loss is 3.8847444343566893 and perplexity is 48.654506450208835
At time: 465.9570984840393 and batch: 600, loss is 3.873823084831238 and perplexity is 48.12602469915483
At time: 466.92125725746155 and batch: 650, loss is 3.925920124053955 and perplexity is 50.69970662310948
At time: 467.88719177246094 and batch: 700, loss is 3.945479321479797 and perplexity is 51.701113628205604
At time: 468.85321712493896 and batch: 750, loss is 3.9149095106124876 and perplexity is 50.14453375758383
At time: 469.81986808776855 and batch: 800, loss is 3.879747052192688 and perplexity is 48.411967821344895
At time: 470.7864944934845 and batch: 850, loss is 3.8738555669784547 and perplexity is 48.12758796116299
At time: 471.76082396507263 and batch: 900, loss is 3.8390702199935913 and perplexity is 46.48223608805882
At time: 472.7523376941681 and batch: 950, loss is 3.9327877616882323 and perplexity is 51.04909218988111
At time: 473.71880173683167 and batch: 1000, loss is 3.900709557533264 and perplexity is 49.43751542476894
At time: 474.70340061187744 and batch: 1050, loss is 3.853619627952576 and perplexity is 47.163468853254884
At time: 475.66991901397705 and batch: 1100, loss is 3.8619246435165406 and perplexity is 47.55679321787987
At time: 476.6363127231598 and batch: 1150, loss is 3.8178372097015383 and perplexity is 45.50568256520345
At time: 477.60061025619507 and batch: 1200, loss is 3.885674629211426 and perplexity is 48.69978567775595
At time: 478.5655391216278 and batch: 1250, loss is 3.865861110687256 and perplexity is 47.74436792174059
At time: 479.5347843170166 and batch: 1300, loss is 3.8745137739181517 and perplexity is 48.1592763011485
At time: 480.5516619682312 and batch: 1350, loss is 3.75062931060791 and perplexity is 42.54784938964295
At time: 481.5346395969391 and batch: 1400, loss is 3.777950506210327 and perplexity is 43.72633299030825
At time: 482.51737785339355 and batch: 1450, loss is 3.702179217338562 and perplexity is 40.53554393871609
At time: 483.5087971687317 and batch: 1500, loss is 3.7162028884887697 and perplexity is 41.10800570274646
At time: 484.496209859848 and batch: 1550, loss is 3.7185306787490844 and perplexity is 41.20380797858501
At time: 485.4852271080017 and batch: 1600, loss is 3.7935735988616943 and perplexity is 44.41483782514301
At time: 486.4843897819519 and batch: 1650, loss is 3.75031973361969 and perplexity is 42.5346795932118
At time: 487.4510614871979 and batch: 1700, loss is 3.7635181951522827 and perplexity is 43.09979303613214
At time: 488.40939259529114 and batch: 1750, loss is 3.74885413646698 and perplexity is 42.47238654731423
At time: 489.36960911750793 and batch: 1800, loss is 3.7126783418655394 and perplexity is 40.96337365098735
At time: 490.3457827568054 and batch: 1850, loss is 3.7386481857299803 and perplexity is 42.041119948798
At time: 491.3248212337494 and batch: 1900, loss is 3.804766826629639 and perplexity is 44.91477596222423
At time: 492.2996771335602 and batch: 1950, loss is 3.7448655796051025 and perplexity is 42.3033204076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345146143713663 and perplexity of 77.1033048192586
finished 12 epochs...
Completing Train Step...
At time: 495.56339406967163 and batch: 50, loss is 3.8988945579528806 and perplexity is 49.34786773488751
At time: 496.5621027946472 and batch: 100, loss is 3.860860619544983 and perplexity is 47.506218560980784
At time: 497.54518580436707 and batch: 150, loss is 3.8174500322341918 and perplexity is 45.488067200634156
At time: 498.50929284095764 and batch: 200, loss is 3.819533095359802 and perplexity is 45.582920474455044
At time: 499.53139877319336 and batch: 250, loss is 3.8066879081726075 and perplexity is 45.00114384264021
At time: 500.5216360092163 and batch: 300, loss is 3.836601061820984 and perplexity is 46.367605673492726
At time: 501.4826166629791 and batch: 350, loss is 3.828946285247803 and perplexity is 46.014027021132435
At time: 502.47477197647095 and batch: 400, loss is 3.799346661567688 and perplexity is 44.67198902979917
At time: 503.45425844192505 and batch: 450, loss is 3.8407694578170775 and perplexity is 46.56128760638366
At time: 504.4435923099518 and batch: 500, loss is 3.8472890186309816 and perplexity is 46.865838442620664
At time: 505.41513895988464 and batch: 550, loss is 3.8113491582870482 and perplexity is 45.21139506561361
At time: 506.41933369636536 and batch: 600, loss is 3.8052663660049437 and perplexity is 44.937218266290955
At time: 507.433655500412 and batch: 650, loss is 3.8570442819595336 and perplexity is 47.325264304433816
At time: 508.44356656074524 and batch: 700, loss is 3.8786634635925292 and perplexity is 48.35953757644042
At time: 509.44087195396423 and batch: 750, loss is 3.8488933992385865 and perplexity is 46.94108943445158
At time: 510.42837619781494 and batch: 800, loss is 3.8139514780044554 and perplexity is 45.32920279064371
At time: 511.4028913974762 and batch: 850, loss is 3.8115800428390503 and perplexity is 45.221834883458676
At time: 512.3956091403961 and batch: 900, loss is 3.781388158798218 and perplexity is 43.87690759537772
At time: 513.3617858886719 and batch: 950, loss is 3.8752470874786376 and perplexity is 48.19460510348507
At time: 514.3267931938171 and batch: 1000, loss is 3.8423516273498537 and perplexity is 46.63501376530287
At time: 515.2905602455139 and batch: 1050, loss is 3.8017776012420654 and perplexity is 44.78071604112459
At time: 516.2618863582611 and batch: 1100, loss is 3.8107926845550537 and perplexity is 45.18624311072292
At time: 517.2455804347992 and batch: 1150, loss is 3.7707204532623293 and perplexity is 43.411329406061135
At time: 518.2094285488129 and batch: 1200, loss is 3.838996753692627 and perplexity is 46.47882133554903
At time: 519.1844027042389 and batch: 1250, loss is 3.824031729698181 and perplexity is 45.788443305167625
At time: 520.1705000400543 and batch: 1300, loss is 3.8319516372680664 and perplexity is 46.15252338111529
At time: 521.1363871097565 and batch: 1350, loss is 3.7083021545410157 and perplexity is 40.78450192799412
At time: 522.1278131008148 and batch: 1400, loss is 3.7415587186813353 and perplexity is 42.16366025601656
At time: 523.0929324626923 and batch: 1450, loss is 3.6695410346984865 and perplexity is 39.2338947310542
At time: 524.0586431026459 and batch: 1500, loss is 3.683663864135742 and perplexity is 39.79191950383762
At time: 525.021969795227 and batch: 1550, loss is 3.6887991714477537 and perplexity is 39.996788822255375
At time: 525.9895310401917 and batch: 1600, loss is 3.7688039636611936 and perplexity is 43.32821171721658
At time: 526.9627020359039 and batch: 1650, loss is 3.725799922943115 and perplexity is 41.50441980715926
At time: 527.9728655815125 and batch: 1700, loss is 3.7432322883605957 and perplexity is 42.23428315907869
At time: 528.9902491569519 and batch: 1750, loss is 3.730175929069519 and perplexity is 41.68644137579062
At time: 529.9856941699982 and batch: 1800, loss is 3.6958283805847167 and perplexity is 40.278925051283615
At time: 530.9858853816986 and batch: 1850, loss is 3.72710250377655 and perplexity is 41.55851789481987
At time: 531.9699420928955 and batch: 1900, loss is 3.795639500617981 and perplexity is 44.50668936206874
At time: 532.9775531291962 and batch: 1950, loss is 3.7367326545715334 and perplexity is 41.96066595426729
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3454345703125 and perplexity of 77.12554667064332
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 536.3374772071838 and batch: 50, loss is 3.8877627849578857 and perplexity is 48.80158466414922
At time: 537.3068006038666 and batch: 100, loss is 3.889180588722229 and perplexity is 48.87082480746118
At time: 538.2735590934753 and batch: 150, loss is 3.867509765625 and perplexity is 47.82314683143963
At time: 539.2418859004974 and batch: 200, loss is 3.8649454069137574 and perplexity is 47.70066823490898
At time: 540.2329580783844 and batch: 250, loss is 3.8467918825149536 and perplexity is 46.842545532076166
At time: 541.2091484069824 and batch: 300, loss is 3.8720078611373903 and perplexity is 48.038744439393966
At time: 542.1815958023071 and batch: 350, loss is 3.870487356185913 and perplexity is 47.965756793711336
At time: 543.1625714302063 and batch: 400, loss is 3.830333671569824 and perplexity is 46.07791055816828
At time: 544.1810495853424 and batch: 450, loss is 3.8738223934173583 and perplexity is 48.125991424164894
At time: 545.1686398983002 and batch: 500, loss is 3.8767041635513304 and perplexity is 48.264879494547976
At time: 546.1626577377319 and batch: 550, loss is 3.8436102867126465 and perplexity is 46.693748317655604
At time: 547.1395609378815 and batch: 600, loss is 3.8267890310287473 and perplexity is 45.91487005904703
At time: 548.1116285324097 and batch: 650, loss is 3.8837961196899413 and perplexity is 48.6083885387408
At time: 549.1056237220764 and batch: 700, loss is 3.9136042976379395 and perplexity is 50.079127155579
At time: 550.0765850543976 and batch: 750, loss is 3.8739455699920655 and perplexity is 48.13191978405295
At time: 551.0476584434509 and batch: 800, loss is 3.8366137456893923 and perplexity is 46.368193797831346
At time: 552.0392079353333 and batch: 850, loss is 3.824338092803955 and perplexity is 45.80247334390054
At time: 553.0496518611908 and batch: 900, loss is 3.787290029525757 and perplexity is 44.13662909941461
At time: 554.0625913143158 and batch: 950, loss is 3.8743076610565184 and perplexity is 48.14935107778911
At time: 555.0719962120056 and batch: 1000, loss is 3.840767092704773 and perplexity is 46.56117748383965
At time: 556.0574488639832 and batch: 1050, loss is 3.804186658859253 and perplexity is 44.88872541437169
At time: 557.0293400287628 and batch: 1100, loss is 3.8175504302978513 and perplexity is 45.492634343763044
At time: 558.0031495094299 and batch: 1150, loss is 3.7793789863586427 and perplexity is 43.788839823199446
At time: 558.9936966896057 and batch: 1200, loss is 3.8336027526855467 and perplexity is 46.228789468755764
At time: 559.9960165023804 and batch: 1250, loss is 3.811200861930847 and perplexity is 45.20469087758222
At time: 560.9935395717621 and batch: 1300, loss is 3.817159414291382 and perplexity is 45.474849472869366
At time: 561.9817144870758 and batch: 1350, loss is 3.6949413919448855 and perplexity is 40.24321394235378
At time: 562.952229976654 and batch: 1400, loss is 3.7301050186157227 and perplexity is 41.68348547611885
At time: 563.9254431724548 and batch: 1450, loss is 3.6488877582550048 and perplexity is 38.43189670865962
At time: 564.9083070755005 and batch: 1500, loss is 3.662595443725586 and perplexity is 38.96233630454826
At time: 565.9006702899933 and batch: 1550, loss is 3.6613961601257325 and perplexity is 38.91563742180552
At time: 566.9068989753723 and batch: 1600, loss is 3.744719915390015 and perplexity is 42.2971587764127
At time: 567.9037582874298 and batch: 1650, loss is 3.6962387943267823 and perplexity is 40.295459468384195
At time: 568.8749206066132 and batch: 1700, loss is 3.7137097835540773 and perplexity is 41.005646779659976
At time: 569.8578450679779 and batch: 1750, loss is 3.6981387329101563 and perplexity is 40.37209114124708
At time: 570.8441751003265 and batch: 1800, loss is 3.6584964895248415 and perplexity is 38.80295833712447
At time: 571.853175163269 and batch: 1850, loss is 3.687090067863464 and perplexity is 39.92848854986499
At time: 572.8281455039978 and batch: 1900, loss is 3.753529133796692 and perplexity is 42.67140969487037
At time: 573.8028540611267 and batch: 1950, loss is 3.697634334564209 and perplexity is 40.351732660076756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316208950308866 and perplexity of 74.9041240914831
finished 14 epochs...
Completing Train Step...
At time: 577.2031471729279 and batch: 50, loss is 3.8823578929901124 and perplexity is 48.538528905545604
At time: 578.1968593597412 and batch: 100, loss is 3.865693283081055 and perplexity is 47.73635577111153
At time: 579.1628861427307 and batch: 150, loss is 3.8350071477890015 and perplexity is 46.29375856478615
At time: 580.1190083026886 and batch: 200, loss is 3.8265288829803468 and perplexity is 45.90292694876438
At time: 581.0727910995483 and batch: 250, loss is 3.8047451829910277 and perplexity is 44.913803853565035
At time: 582.063551902771 and batch: 300, loss is 3.8268343687057493 and perplexity is 45.916951779785194
At time: 583.048722743988 and batch: 350, loss is 3.82709237575531 and perplexity is 45.92880020546166
At time: 584.0331161022186 and batch: 400, loss is 3.7882084131240843 and perplexity is 44.17718207440822
At time: 585.0085446834564 and batch: 450, loss is 3.8341513156890867 and perplexity is 46.254155829244105
At time: 585.9801545143127 and batch: 500, loss is 3.839250373840332 and perplexity is 46.490610796040464
At time: 586.9519689083099 and batch: 550, loss is 3.8071974420547487 and perplexity is 45.02407929286143
At time: 587.9249262809753 and batch: 600, loss is 3.795126872062683 and perplexity is 44.483879809113574
At time: 588.9272577762604 and batch: 650, loss is 3.8521804428100586 and perplexity is 47.09564070994719
At time: 589.9184124469757 and batch: 700, loss is 3.8826629734039306 and perplexity is 48.55333931909891
At time: 590.9247381687164 and batch: 750, loss is 3.8435166597366335 and perplexity is 46.68937672785447
At time: 591.9174420833588 and batch: 800, loss is 3.807052206993103 and perplexity is 45.01754069275828
At time: 592.8997898101807 and batch: 850, loss is 3.7952506065368654 and perplexity is 44.48938433913438
At time: 593.8986849784851 and batch: 900, loss is 3.7599458742141723 and perplexity is 42.946101424366596
At time: 594.8714165687561 and batch: 950, loss is 3.848270835876465 and perplexity is 46.91187472693847
At time: 595.843092918396 and batch: 1000, loss is 3.81581467628479 and perplexity is 45.41373881256189
At time: 596.834725856781 and batch: 1050, loss is 3.7821035528182985 and perplexity is 43.90830810321965
At time: 597.8531968593597 and batch: 1100, loss is 3.795486855506897 and perplexity is 44.499896152015424
At time: 598.8255879878998 and batch: 1150, loss is 3.759375948905945 and perplexity is 42.921632327716196
At time: 599.82133436203 and batch: 1200, loss is 3.8154308652877806 and perplexity is 45.39631186473136
At time: 600.7942507266998 and batch: 1250, loss is 3.7949555206298826 and perplexity is 44.47625808558703
At time: 601.7651903629303 and batch: 1300, loss is 3.801763882637024 and perplexity is 44.7801017163816
At time: 602.7597646713257 and batch: 1350, loss is 3.6796730852127073 and perplexity is 39.633435198426646
At time: 603.7630794048309 and batch: 1400, loss is 3.717241201400757 and perplexity is 41.150710842666086
At time: 604.776157617569 and batch: 1450, loss is 3.638480906486511 and perplexity is 38.03401559228593
At time: 605.7637987136841 and batch: 1500, loss is 3.6543176984786987 and perplexity is 38.64114720518218
At time: 606.737114906311 and batch: 1550, loss is 3.655524263381958 and perplexity is 38.68779839540647
At time: 607.7297110557556 and batch: 1600, loss is 3.740706162452698 and perplexity is 42.12772868386238
At time: 608.7024276256561 and batch: 1650, loss is 3.6944249773025515 and perplexity is 40.22243712260808
At time: 609.6977314949036 and batch: 1700, loss is 3.713418917655945 and perplexity is 40.99372136981251
At time: 610.7061107158661 and batch: 1750, loss is 3.69929039478302 and perplexity is 40.4186129228814
At time: 611.6867763996124 and batch: 1800, loss is 3.66036669254303 and perplexity is 38.87559564900945
At time: 612.6657819747925 and batch: 1850, loss is 3.6898604583740235 and perplexity is 40.039259424086126
At time: 613.6523761749268 and batch: 1900, loss is 3.757915287017822 and perplexity is 42.85898410027668
At time: 614.6420257091522 and batch: 1950, loss is 3.701787524223328 and perplexity is 40.519669554379504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315433661882268 and perplexity of 74.84607429654525
finished 15 epochs...
Completing Train Step...
At time: 617.8930897712708 and batch: 50, loss is 3.8684953927993773 and perplexity is 47.87030586131385
At time: 618.9366025924683 and batch: 100, loss is 3.849661169052124 and perplexity is 46.97714322466876
At time: 619.9188928604126 and batch: 150, loss is 3.8182061529159546 and perplexity is 45.52247467548036
At time: 620.9293384552002 and batch: 200, loss is 3.8086990404129026 and perplexity is 45.09173816191523
At time: 621.9274170398712 and batch: 250, loss is 3.7864589166641234 and perplexity is 44.09996181873588
At time: 622.9503302574158 and batch: 300, loss is 3.8080755424499513 and perplexity is 45.0636323179041
At time: 623.9151520729065 and batch: 350, loss is 3.8080869817733767 and perplexity is 45.06414781831739
At time: 624.9130280017853 and batch: 400, loss is 3.7691176557540893 and perplexity is 43.341805566661655
At time: 625.898458480835 and batch: 450, loss is 3.816321930885315 and perplexity is 45.43678098413128
At time: 626.9128167629242 and batch: 500, loss is 3.821914873123169 and perplexity is 45.691618256424775
At time: 627.916228055954 and batch: 550, loss is 3.789548635482788 and perplexity is 44.236429014737666
At time: 628.9032213687897 and batch: 600, loss is 3.779738211631775 and perplexity is 43.80457270680059
At time: 629.9142136573792 and batch: 650, loss is 3.8370203161239624 and perplexity is 46.38704956737343
At time: 630.9107031822205 and batch: 700, loss is 3.867024073600769 and perplexity is 47.799925150199144
At time: 631.9018943309784 and batch: 750, loss is 3.8284630393981933 and perplexity is 45.991796305433816
At time: 632.8755986690521 and batch: 800, loss is 3.791932473182678 and perplexity is 44.34200727264995
At time: 633.8476402759552 and batch: 850, loss is 3.780414915084839 and perplexity is 43.834225444334656
At time: 634.8280515670776 and batch: 900, loss is 3.745778789520264 and perplexity is 42.34196986408793
At time: 635.818088054657 and batch: 950, loss is 3.8343963384628297 and perplexity is 46.26549053937688
At time: 636.8039529323578 and batch: 1000, loss is 3.802247610092163 and perplexity is 44.80176832096899
At time: 637.7766406536102 and batch: 1050, loss is 3.7701473569869997 and perplexity is 43.38645766250395
At time: 638.7468729019165 and batch: 1100, loss is 3.7836419916152955 and perplexity is 43.97591033553124
At time: 639.721693277359 and batch: 1150, loss is 3.7483568143844606 and perplexity is 42.45126934304819
At time: 640.6958572864532 and batch: 1200, loss is 3.805514760017395 and perplexity is 44.94838178866317
At time: 641.7161900997162 and batch: 1250, loss is 3.7854339694976806 and perplexity is 44.05478484379069
At time: 642.7422511577606 and batch: 1300, loss is 3.792256026268005 and perplexity is 44.35635658716993
At time: 643.7591075897217 and batch: 1350, loss is 3.6705704736709595 and perplexity is 39.27430442742174
At time: 644.7554676532745 and batch: 1400, loss is 3.708975396156311 and perplexity is 40.81196899690059
At time: 645.759622335434 and batch: 1450, loss is 3.6317982864379883 and perplexity is 37.78069607890791
At time: 646.7581644058228 and batch: 1500, loss is 3.6482235622406005 and perplexity is 38.40637887140075
At time: 647.7955186367035 and batch: 1550, loss is 3.6503980922698975 and perplexity is 38.489985565261314
At time: 648.8142499923706 and batch: 1600, loss is 3.7362425088882447 and perplexity is 41.940104154532236
At time: 649.8356325626373 and batch: 1650, loss is 3.6907784605026244 and perplexity is 40.07603242572946
At time: 650.8550448417664 and batch: 1700, loss is 3.7101002740859985 and perplexity is 40.857903310496496
At time: 651.8588092327118 and batch: 1750, loss is 3.6967284059524537 and perplexity is 40.315193424394614
At time: 652.8255805969238 and batch: 1800, loss is 3.65802387714386 and perplexity is 38.78462391147518
At time: 653.7920079231262 and batch: 1850, loss is 3.688001470565796 and perplexity is 39.9648960706656
At time: 654.7511458396912 and batch: 1900, loss is 3.756877956390381 and perplexity is 42.81454821474558
At time: 655.7095458507538 and batch: 1950, loss is 3.700900650024414 and perplexity is 40.483749635482255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316045716751454 and perplexity of 74.89189822270596
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 658.998918056488 and batch: 50, loss is 3.868779044151306 and perplexity is 47.88388626424743
At time: 660.0112318992615 and batch: 100, loss is 3.8719431877136232 and perplexity is 48.035637709780104
At time: 660.9777760505676 and batch: 150, loss is 3.8616083335876463 and perplexity is 47.54175291082331
At time: 661.9423475265503 and batch: 200, loss is 3.8655429553985594 and perplexity is 47.72918021473358
At time: 662.9073870182037 and batch: 250, loss is 3.8473685073852537 and perplexity is 46.86956389780032
At time: 663.8895251750946 and batch: 300, loss is 3.8607274389266966 and perplexity is 47.499892074712406
At time: 664.8695802688599 and batch: 350, loss is 3.8613458347320555 and perplexity is 47.529274892895806
At time: 665.831324338913 and batch: 400, loss is 3.826990761756897 and perplexity is 45.92413343353917
At time: 666.7911982536316 and batch: 450, loss is 3.868354525566101 and perplexity is 47.86356297870783
At time: 667.7565014362335 and batch: 500, loss is 3.8698346710205076 and perplexity is 47.93446047023868
At time: 668.7220013141632 and batch: 550, loss is 3.8353554582595826 and perplexity is 46.30988597412654
At time: 669.686713218689 and batch: 600, loss is 3.814613618850708 and perplexity is 45.359227046385556
At time: 670.6504020690918 and batch: 650, loss is 3.861917872428894 and perplexity is 47.55647120775499
At time: 671.6166546344757 and batch: 700, loss is 3.8983031511306763 and perplexity is 49.318691697552005
At time: 672.6002707481384 and batch: 750, loss is 3.856559453010559 and perplexity is 47.30232520749962
At time: 673.568146944046 and batch: 800, loss is 3.8268633317947387 and perplexity is 45.91828169580486
At time: 674.5356087684631 and batch: 850, loss is 3.810017676353455 and perplexity is 45.151236968488504
At time: 675.5154061317444 and batch: 900, loss is 3.76819194316864 and perplexity is 43.30170207678901
At time: 676.4795722961426 and batch: 950, loss is 3.8585396814346313 and perplexity is 47.39608742106123
At time: 677.4444444179535 and batch: 1000, loss is 3.818962426185608 and perplexity is 45.55691512780113
At time: 678.4114089012146 and batch: 1050, loss is 3.7799050760269166 and perplexity is 43.81188274020494
At time: 679.3776023387909 and batch: 1100, loss is 3.797628779411316 and perplexity is 44.595313695406126
At time: 680.3574419021606 and batch: 1150, loss is 3.771020793914795 and perplexity is 43.42436955120417
At time: 681.3414664268494 and batch: 1200, loss is 3.832138891220093 and perplexity is 46.16116643271193
At time: 682.3302915096283 and batch: 1250, loss is 3.818989291191101 and perplexity is 45.558139031016296
At time: 683.2967138290405 and batch: 1300, loss is 3.82169246673584 and perplexity is 45.68145727865221
At time: 684.2622170448303 and batch: 1350, loss is 3.6833942985534667 and perplexity is 39.78119441750872
At time: 685.2310183048248 and batch: 1400, loss is 3.7168241357803344 and perplexity is 41.13355187437426
At time: 686.1962580680847 and batch: 1450, loss is 3.64038200378418 and perplexity is 38.10639073084007
At time: 687.1886644363403 and batch: 1500, loss is 3.6583432006835936 and perplexity is 38.79701073246635
At time: 688.155211687088 and batch: 1550, loss is 3.6600990200042727 and perplexity is 38.865191112192896
At time: 689.1220774650574 and batch: 1600, loss is 3.7427630043029785 and perplexity is 42.21446793315571
At time: 690.0897707939148 and batch: 1650, loss is 3.693967652320862 and perplexity is 40.20404660283006
At time: 691.0697722434998 and batch: 1700, loss is 3.7026980447769167 and perplexity is 40.55658034780136
At time: 692.0518484115601 and batch: 1750, loss is 3.693995923995972 and perplexity is 40.20518325464117
At time: 693.0573828220367 and batch: 1800, loss is 3.6541988706588744 and perplexity is 38.63655583470095
At time: 694.0543580055237 and batch: 1850, loss is 3.6808704996109007 and perplexity is 39.68092126896159
At time: 695.0548324584961 and batch: 1900, loss is 3.7561353492736815 and perplexity is 42.78276562899081
At time: 696.0549066066742 and batch: 1950, loss is 3.7034872341156007 and perplexity is 40.588599801669275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2961939612100295 and perplexity of 73.41982255445171
finished 17 epochs...
Completing Train Step...
At time: 699.3073604106903 and batch: 50, loss is 3.875377950668335 and perplexity is 48.200912415923625
At time: 700.278418302536 and batch: 100, loss is 3.8601451253890993 and perplexity is 47.472240296306715
At time: 701.2690799236298 and batch: 150, loss is 3.8372956466674806 and perplexity is 46.3998230973338
At time: 702.2684073448181 and batch: 200, loss is 3.8357668685913087 and perplexity is 46.32894225938488
At time: 703.2354378700256 and batch: 250, loss is 3.817829437255859 and perplexity is 45.50532887613214
At time: 704.198388338089 and batch: 300, loss is 3.8321447944641114 and perplexity is 46.16143893414588
At time: 705.157811164856 and batch: 350, loss is 3.8336565399169924 and perplexity is 46.23127605422705
At time: 706.136420249939 and batch: 400, loss is 3.7985971546173096 and perplexity is 44.6385196078831
At time: 707.1156768798828 and batch: 450, loss is 3.84245313167572 and perplexity is 46.639747661188274
At time: 708.0951414108276 and batch: 500, loss is 3.846433458328247 and perplexity is 46.82575903931279
At time: 709.0642521381378 and batch: 550, loss is 3.8142726230621338 and perplexity is 45.34376237783302
At time: 710.0331628322601 and batch: 600, loss is 3.7947210311889648 and perplexity is 44.465830095369
At time: 710.9981112480164 and batch: 650, loss is 3.8423111629486084 and perplexity is 46.63312674557261
At time: 711.9656138420105 and batch: 700, loss is 3.8816995859146117 and perplexity is 48.506586163752736
At time: 712.965806722641 and batch: 750, loss is 3.8427012252807615 and perplexity is 46.651320119790896
At time: 713.9317669868469 and batch: 800, loss is 3.814229965209961 and perplexity is 45.34182815157581
At time: 714.9232332706451 and batch: 850, loss is 3.7994215869903565 and perplexity is 44.67533622285203
At time: 715.8874213695526 and batch: 900, loss is 3.7590941858291624 and perplexity is 42.90954030015446
At time: 716.8649046421051 and batch: 950, loss is 3.849778051376343 and perplexity is 46.982634343255114
At time: 717.8429751396179 and batch: 1000, loss is 3.8093639421463013 and perplexity is 45.12172970639108
At time: 718.822936296463 and batch: 1050, loss is 3.7695466041564942 and perplexity is 43.36040095286229
At time: 719.8349866867065 and batch: 1100, loss is 3.7862487602233887 and perplexity is 44.0906949015088
At time: 720.9226498603821 and batch: 1150, loss is 3.7587654304504396 and perplexity is 42.895435876561855
At time: 721.9415459632874 and batch: 1200, loss is 3.8197213792800904 and perplexity is 45.59150381344716
At time: 722.9450671672821 and batch: 1250, loss is 3.8086595726013184 and perplexity is 45.08995852480887
At time: 723.9420461654663 and batch: 1300, loss is 3.812727813720703 and perplexity is 45.27376898727748
At time: 724.9154748916626 and batch: 1350, loss is 3.6774231719970705 and perplexity is 39.544363647996
At time: 725.8933339118958 and batch: 1400, loss is 3.713143911361694 and perplexity is 40.98244938841501
At time: 726.8675692081451 and batch: 1450, loss is 3.6385372257232667 and perplexity is 38.03615769933519
At time: 727.840606212616 and batch: 1500, loss is 3.6581438112258913 and perplexity is 38.789275788694674
At time: 728.8151521682739 and batch: 1550, loss is 3.6613309288024904 and perplexity is 38.91309898607535
At time: 729.8105888366699 and batch: 1600, loss is 3.745267505645752 and perplexity is 42.32032663107085
At time: 730.7877044677734 and batch: 1650, loss is 3.6972578668594362 and perplexity is 40.33654439502363
At time: 731.7589061260223 and batch: 1700, loss is 3.7072346019744873 and perplexity is 40.7409855604241
At time: 732.7330203056335 and batch: 1750, loss is 3.6992952680587767 and perplexity is 40.41880989440783
At time: 733.7064335346222 and batch: 1800, loss is 3.659546346664429 and perplexity is 38.843717291767874
At time: 734.6826088428497 and batch: 1850, loss is 3.68621675491333 and perplexity is 39.89363370554381
At time: 735.6539306640625 and batch: 1900, loss is 3.761850504875183 and perplexity is 43.02797583141257
At time: 736.643522977829 and batch: 1950, loss is 3.7082651042938233 and perplexity is 40.782990880108585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.295091921784157 and perplexity of 73.33895558283595
finished 18 epochs...
Completing Train Step...
At time: 740.0321352481842 and batch: 50, loss is 3.871673936843872 and perplexity is 48.022705813587976
At time: 741.0101935863495 and batch: 100, loss is 3.8541060495376587 and perplexity is 47.18641576301615
At time: 741.989387512207 and batch: 150, loss is 3.82993860244751 and perplexity is 46.05971019392368
At time: 742.9678680896759 and batch: 200, loss is 3.8275004959106447 and perplexity is 45.947548500054076
At time: 743.9751155376434 and batch: 250, loss is 3.8098597288131715 and perplexity is 45.14410600484249
At time: 744.9644675254822 and batch: 300, loss is 3.8240613412857054 and perplexity is 45.78979919373906
At time: 746.0140368938446 and batch: 350, loss is 3.825660648345947 and perplexity is 45.86308973429437
At time: 746.9880435466766 and batch: 400, loss is 3.78986843585968 and perplexity is 44.25057810373035
At time: 747.9625339508057 and batch: 450, loss is 3.83401547908783 and perplexity is 46.247873248634114
At time: 748.9365885257721 and batch: 500, loss is 3.8383285665512084 and perplexity is 46.44777515826766
At time: 749.9115006923676 and batch: 550, loss is 3.8063635492324828 and perplexity is 44.986549686319506
At time: 750.8872590065002 and batch: 600, loss is 3.787431654930115 and perplexity is 44.14288041001955
At time: 751.8598341941833 and batch: 650, loss is 3.8353466272354124 and perplexity is 46.30947701220996
At time: 752.8343551158905 and batch: 700, loss is 3.874968490600586 and perplexity is 48.18118010713217
At time: 753.8084063529968 and batch: 750, loss is 3.8366767358779907 and perplexity is 46.37111463109459
At time: 754.7824518680573 and batch: 800, loss is 3.808784217834473 and perplexity is 45.095579123485265
At time: 755.75745677948 and batch: 850, loss is 3.794193859100342 and perplexity is 44.44239512851822
At time: 756.7325541973114 and batch: 900, loss is 3.7540287876129153 and perplexity is 42.69273595499799
At time: 757.7064349651337 and batch: 950, loss is 3.8453147745132448 and perplexity is 46.77340510975701
At time: 758.6800248622894 and batch: 1000, loss is 3.8043432235717773 and perplexity is 44.89575395495814
At time: 759.6698727607727 and batch: 1050, loss is 3.7646191024780276 and perplexity is 43.147268042019626
At time: 760.6502335071564 and batch: 1100, loss is 3.7813607835769654 and perplexity is 43.87570647176501
At time: 761.6332263946533 and batch: 1150, loss is 3.754170718193054 and perplexity is 42.69879578980757
At time: 762.6060950756073 and batch: 1200, loss is 3.8152006340026854 and perplexity is 45.385861416568375
At time: 763.5784168243408 and batch: 1250, loss is 3.8050629186630247 and perplexity is 44.928076838612554
At time: 764.5519568920135 and batch: 1300, loss is 3.8095737409591677 and perplexity is 45.1311971848161
At time: 765.5268721580505 and batch: 1350, loss is 3.6748448753356935 and perplexity is 39.44253787216323
At time: 766.5001635551453 and batch: 1400, loss is 3.711143202781677 and perplexity is 40.90053741860723
At time: 767.4741051197052 and batch: 1450, loss is 3.637229113578796 and perplexity is 37.98643466826043
At time: 768.4485275745392 and batch: 1500, loss is 3.657476406097412 and perplexity is 38.76339626412764
At time: 769.4219236373901 and batch: 1550, loss is 3.661114811897278 and perplexity is 38.90469011623244
At time: 770.3958790302277 and batch: 1600, loss is 3.7456576585769654 and perplexity is 42.33684125196026
At time: 771.3691198825836 and batch: 1650, loss is 3.6977853536605836 and perplexity is 40.35782700244968
At time: 772.3411557674408 and batch: 1700, loss is 3.70795793056488 and perplexity is 40.77046534057932
At time: 773.3106279373169 and batch: 1750, loss is 3.700344467163086 and perplexity is 40.4612395282209
At time: 774.2882738113403 and batch: 1800, loss is 3.660607490539551 and perplexity is 38.88495794172072
At time: 775.2687947750092 and batch: 1850, loss is 3.686822171211243 and perplexity is 39.917793274132464
At time: 776.2437703609467 and batch: 1900, loss is 3.7626809883117676 and perplexity is 43.063724695015196
At time: 777.219048500061 and batch: 1950, loss is 3.708773999214172 and perplexity is 40.803750418767976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.295002782067587 and perplexity of 73.33241846048472
finished 19 epochs...
Completing Train Step...
At time: 780.4859890937805 and batch: 50, loss is 3.867592844963074 and perplexity is 47.82712011186946
At time: 781.4828410148621 and batch: 100, loss is 3.8492111492156984 and perplexity is 46.95600733450066
At time: 782.4692687988281 and batch: 150, loss is 3.824665699005127 and perplexity is 45.81748097635951
At time: 783.459484577179 and batch: 200, loss is 3.821775407791138 and perplexity is 45.685246304057166
At time: 784.4539630413055 and batch: 250, loss is 3.804427089691162 and perplexity is 44.89951934551133
At time: 785.426783323288 and batch: 300, loss is 3.8183196210861206 and perplexity is 45.52764032044581
At time: 786.4248762130737 and batch: 350, loss is 3.820076413154602 and perplexity is 45.60769321541385
At time: 787.384085893631 and batch: 400, loss is 3.783852734565735 and perplexity is 43.98517892523427
At time: 788.3428609371185 and batch: 450, loss is 3.8280284929275514 and perplexity is 45.97181507437195
At time: 789.3157632350922 and batch: 500, loss is 3.832274808883667 and perplexity is 46.167440977002364
At time: 790.289927482605 and batch: 550, loss is 3.800490617752075 and perplexity is 44.72312106874867
At time: 791.2628774642944 and batch: 600, loss is 3.7821687126159667 and perplexity is 43.91116925290656
At time: 792.2363784313202 and batch: 650, loss is 3.830497908592224 and perplexity is 46.08547887847894
At time: 793.2106237411499 and batch: 700, loss is 3.870232138633728 and perplexity is 47.95351665268961
At time: 794.1852312088013 and batch: 750, loss is 3.8323335742950437 and perplexity is 46.170154105381854
At time: 795.1764359474182 and batch: 800, loss is 3.8048239183425903 and perplexity is 44.91734029692118
At time: 796.1514332294464 and batch: 850, loss is 3.7902547407150267 and perplexity is 44.26767561911769
At time: 797.1263294219971 and batch: 900, loss is 3.7502611684799194 and perplexity is 42.53218861669923
At time: 798.1000080108643 and batch: 950, loss is 3.8417665338516236 and perplexity is 46.6077359027871
At time: 799.0779399871826 and batch: 1000, loss is 3.800530290603638 and perplexity is 44.72489539768836
At time: 800.052169084549 and batch: 1050, loss is 3.760873637199402 and perplexity is 42.98596371614818
At time: 801.0265357494354 and batch: 1100, loss is 3.7777263498306275 and perplexity is 43.71653255226399
At time: 802.025187253952 and batch: 1150, loss is 3.750818076133728 and perplexity is 42.5558817148946
At time: 803.0407857894897 and batch: 1200, loss is 3.8119148778915406 and perplexity is 45.23697927421053
At time: 804.0151064395905 and batch: 1250, loss is 3.8023270416259765 and perplexity is 44.80532713548346
At time: 804.9940855503082 and batch: 1300, loss is 3.8070392847061156 and perplexity is 45.0169589669366
At time: 805.9603776931763 and batch: 1350, loss is 3.6726191663742065 and perplexity is 39.35484788455273
At time: 806.9288830757141 and batch: 1400, loss is 3.709183735847473 and perplexity is 40.8204726357091
At time: 807.900324344635 and batch: 1450, loss is 3.635773844718933 and perplexity is 37.931194397262594
At time: 808.8879864215851 and batch: 1500, loss is 3.6564379024505613 and perplexity is 38.723161231473185
At time: 809.876983165741 and batch: 1550, loss is 3.6603516483306886 and perplexity is 38.87501080069291
At time: 810.8508150577545 and batch: 1600, loss is 3.7452454376220703 and perplexity is 42.319392715405414
At time: 811.8254570960999 and batch: 1650, loss is 3.697416591644287 and perplexity is 40.34294731249176
At time: 812.7994384765625 and batch: 1700, loss is 3.707630715370178 and perplexity is 40.75712680722922
At time: 813.7722945213318 and batch: 1750, loss is 3.700159201622009 and perplexity is 40.45374414912624
At time: 814.7427730560303 and batch: 1800, loss is 3.660350408554077 and perplexity is 38.87496260439362
At time: 815.7135207653046 and batch: 1850, loss is 3.6864179229736327 and perplexity is 39.90165983772844
At time: 816.6898653507233 and batch: 1900, loss is 3.7625298595428465 and perplexity is 43.0572170190778
At time: 817.662091255188 and batch: 1950, loss is 3.708431372642517 and perplexity is 40.78977236441448
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.295111509811046 and perplexity of 73.34039216233978
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
4176.447175979614


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -69.81217672005135, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -72.57294337642149, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.725269039096756, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9500194842048229, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -73.33241846048472, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.22182319704545472, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9619850400189879, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.60562622183787, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07897425315755363, 'wordvec_source': 'glove', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.652496099472046 and batch: 50, loss is 7.631826171875 and perplexity is 2062.8136345304983
At time: 2.780212640762329 and batch: 100, loss is 6.8587994956970215 and perplexity is 952.223232950862
At time: 3.9070611000061035 and batch: 150, loss is 6.5394131565094 and perplexity is 691.8804333478803
At time: 5.03718113899231 and batch: 200, loss is 6.378258752822876 and perplexity is 588.9013914971713
At time: 6.166864633560181 and batch: 250, loss is 6.295405120849609 and perplexity is 542.0754079654341
At time: 7.296671390533447 and batch: 300, loss is 6.204009008407593 and perplexity is 494.7284412065803
At time: 8.421508312225342 and batch: 350, loss is 6.11656888961792 and perplexity is 453.3066779157053
At time: 9.551229238510132 and batch: 400, loss is 6.047895040512085 and perplexity is 423.2212282308548
At time: 10.680596828460693 and batch: 450, loss is 5.947008094787598 and perplexity is 382.60690131742297
At time: 11.805552959442139 and batch: 500, loss is 5.914383211135864 and perplexity is 370.3258194070905
At time: 12.92787218093872 and batch: 550, loss is 5.852962741851806 and perplexity is 348.2646718001295
At time: 14.049583196640015 and batch: 600, loss is 5.87834939956665 and perplexity is 357.2191287737439
At time: 15.171913385391235 and batch: 650, loss is 5.92633246421814 and perplexity is 374.7774803889966
At time: 16.294434547424316 and batch: 700, loss is 5.840747518539429 and perplexity is 344.03641816871533
At time: 17.436742305755615 and batch: 750, loss is 5.7683538150787355 and perplexity is 320.010502343527
At time: 18.55865740776062 and batch: 800, loss is 5.75356707572937 and perplexity is 315.3134034288176
At time: 19.68401861190796 and batch: 850, loss is 5.774355440139771 and perplexity is 321.93686025093206
At time: 20.816905975341797 and batch: 900, loss is 5.752116622924805 and perplexity is 314.8563877384653
At time: 21.949215412139893 and batch: 950, loss is 5.772011070251465 and perplexity is 321.1830051726669
At time: 23.084636211395264 and batch: 1000, loss is 5.745964803695679 and perplexity is 312.9253938105998
At time: 24.216152667999268 and batch: 1050, loss is 5.635327825546264 and perplexity is 280.1507428285069
At time: 25.34635639190674 and batch: 1100, loss is 5.7086733627319335 and perplexity is 301.47086039749905
At time: 26.480217456817627 and batch: 1150, loss is 5.608942966461182 and perplexity is 272.8556679252458
At time: 27.60874652862549 and batch: 1200, loss is 5.685071229934692 and perplexity is 294.4388171615744
At time: 28.740114212036133 and batch: 1250, loss is 5.622016019821167 and perplexity is 276.44614273035114
At time: 29.86577010154724 and batch: 1300, loss is 5.635339908599853 and perplexity is 280.15412792539655
At time: 30.990788221359253 and batch: 1350, loss is 5.582564744949341 and perplexity is 265.75231940364716
At time: 32.117039918899536 and batch: 1400, loss is 5.6072203636169435 and perplexity is 272.3860505738308
At time: 33.23966407775879 and batch: 1450, loss is 5.571607599258423 and perplexity is 262.8563273995073
At time: 34.36542868614197 and batch: 1500, loss is 5.541004676818847 and perplexity is 254.93399711680436
At time: 35.497544288635254 and batch: 1550, loss is 5.5114657497406006 and perplexity is 247.51365439027165
At time: 36.62579417228699 and batch: 1600, loss is 5.531329593658447 and perplexity is 252.47938293987082
At time: 37.75147104263306 and batch: 1650, loss is 5.522062997817994 and perplexity is 250.1505653105662
At time: 38.876049518585205 and batch: 1700, loss is 5.528744812011719 and perplexity is 251.82762155797286
At time: 40.003384828567505 and batch: 1750, loss is 5.536855545043945 and perplexity is 253.87843371900047
At time: 41.13039493560791 and batch: 1800, loss is 5.5233492660522465 and perplexity is 250.47253306055933
At time: 42.26023054122925 and batch: 1850, loss is 5.490904397964478 and perplexity is 242.47640288799752
At time: 43.38937020301819 and batch: 1900, loss is 5.503789186477661 and perplexity is 245.62087448131854
At time: 44.51763081550598 and batch: 1950, loss is 5.434882507324219 and perplexity is 229.26590962804497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.943727857013082 and perplexity of 140.2922654608296
finished 1 epochs...
Completing Train Step...
At time: 47.96420979499817 and batch: 50, loss is 5.189947538375854 and perplexity is 179.45913796702683
At time: 48.94573378562927 and batch: 100, loss is 5.109414911270141 and perplexity is 165.57345136756044
At time: 49.92600679397583 and batch: 150, loss is 5.0270786952972415 and perplexity is 152.4869006982187
At time: 50.93762493133545 and batch: 200, loss is 4.991315832138062 and perplexity is 147.12989442369985
At time: 51.922017335891724 and batch: 250, loss is 4.996473035812378 and perplexity is 147.89063321216352
At time: 52.91707515716553 and batch: 300, loss is 4.997355232238769 and perplexity is 148.02115936666817
At time: 53.93784976005554 and batch: 350, loss is 4.9881717967987065 and perplexity is 146.66803926108412
At time: 54.90952730178833 and batch: 400, loss is 4.947600498199463 and perplexity is 140.83662043160047
At time: 55.87972378730774 and batch: 450, loss is 4.9149337577819825 and perplexity is 136.31028000818475
At time: 56.851985454559326 and batch: 500, loss is 4.8972893333435055 and perplexity is 133.9262577727865
At time: 57.82501816749573 and batch: 550, loss is 4.8389232730865475 and perplexity is 126.33325205961796
At time: 58.79717969894409 and batch: 600, loss is 4.834534702301025 and perplexity is 125.78004442370113
At time: 59.76816010475159 and batch: 650, loss is 4.902587909698486 and perplexity is 134.63775958425805
At time: 60.76173186302185 and batch: 700, loss is 4.8920893955230715 and perplexity is 133.2316570652181
At time: 61.73107051849365 and batch: 750, loss is 4.848386964797974 and perplexity is 127.53450619391624
At time: 62.704201459884644 and batch: 800, loss is 4.826375236511231 and perplexity is 124.75792211101223
At time: 63.67525362968445 and batch: 850, loss is 4.813271579742431 and perplexity is 123.13380132035975
At time: 64.68051624298096 and batch: 900, loss is 4.809800930023194 and perplexity is 122.70718776870804
At time: 65.65251326560974 and batch: 950, loss is 4.873869724273682 and perplexity is 130.82619993441898
At time: 66.62659668922424 and batch: 1000, loss is 4.842875757217407 and perplexity is 126.83357033226373
At time: 67.59889912605286 and batch: 1050, loss is 4.752126960754395 and perplexity is 115.83038939912306
At time: 68.56988954544067 and batch: 1100, loss is 4.817333812713623 and perplexity is 123.63501684582441
At time: 69.54291677474976 and batch: 1150, loss is 4.742125368118286 and perplexity is 114.67767512775146
At time: 70.51945948600769 and batch: 1200, loss is 4.827226047515869 and perplexity is 124.86411269171165
At time: 71.49053621292114 and batch: 1250, loss is 4.781073169708252 and perplexity is 119.2322378357807
At time: 72.4601845741272 and batch: 1300, loss is 4.80049614906311 and perplexity is 121.57071975675736
At time: 73.42922139167786 and batch: 1350, loss is 4.6966972923278805 and perplexity is 109.58464806770182
At time: 74.42512106895447 and batch: 1400, loss is 4.714048051834107 and perplexity is 111.50261592481947
At time: 75.39730834960938 and batch: 1450, loss is 4.65354323387146 and perplexity is 104.95621192295825
At time: 76.39623093605042 and batch: 1500, loss is 4.643443536758423 and perplexity is 103.9015209672042
At time: 77.36650109291077 and batch: 1550, loss is 4.636503705978393 and perplexity is 103.18295822971002
At time: 78.33937907218933 and batch: 1600, loss is 4.7012033367156985 and perplexity is 110.07955555627281
At time: 79.30948519706726 and batch: 1650, loss is 4.663395776748657 and perplexity is 105.99540845892597
At time: 80.2982885837555 and batch: 1700, loss is 4.6879878330230715 and perplexity is 108.63436924919054
At time: 81.29362440109253 and batch: 1750, loss is 4.686357192993164 and perplexity is 108.45737004828004
At time: 82.27101922035217 and batch: 1800, loss is 4.64286883354187 and perplexity is 103.84182558410699
At time: 83.27068614959717 and batch: 1850, loss is 4.657235975265503 and perplexity is 105.34450456219834
At time: 84.25672841072083 and batch: 1900, loss is 4.740244331359864 and perplexity is 114.46216496028413
At time: 85.22947216033936 and batch: 1950, loss is 4.659958696365356 and perplexity is 105.6317190926227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525723337572674 and perplexity of 92.36271109084724
finished 2 epochs...
Completing Train Step...
At time: 88.55927038192749 and batch: 50, loss is 4.6166435241699215 and perplexity is 101.15394093702635
At time: 89.60485005378723 and batch: 100, loss is 4.562777442932129 and perplexity is 95.84932650663573
At time: 90.61861777305603 and batch: 150, loss is 4.521095161437988 and perplexity is 91.93622787663142
At time: 91.63590693473816 and batch: 200, loss is 4.517142429351806 and perplexity is 91.57354586345083
At time: 92.65174794197083 and batch: 250, loss is 4.506903467178344 and perplexity is 90.64071156835998
At time: 93.6648576259613 and batch: 300, loss is 4.531841516494751 and perplexity is 92.92953487959097
At time: 94.66455698013306 and batch: 350, loss is 4.539814157485962 and perplexity is 93.6733900034575
At time: 95.6262195110321 and batch: 400, loss is 4.499995403289795 and perplexity is 90.01671751880673
At time: 96.59033441543579 and batch: 450, loss is 4.501611528396606 and perplexity is 90.16231341492352
At time: 97.54884386062622 and batch: 500, loss is 4.500274772644043 and perplexity is 90.04186894415666
At time: 98.5193989276886 and batch: 550, loss is 4.450755186080933 and perplexity is 85.69163270139211
At time: 99.49246978759766 and batch: 600, loss is 4.445323057174683 and perplexity is 85.22740671560142
At time: 100.48075604438782 and batch: 650, loss is 4.515531282424927 and perplexity is 91.42612621569498
At time: 101.47940969467163 and batch: 700, loss is 4.5316918849945065 and perplexity is 92.91563073414494
At time: 102.4800124168396 and batch: 750, loss is 4.497375364303589 and perplexity is 89.78117890441335
At time: 103.50731158256531 and batch: 800, loss is 4.466813726425171 and perplexity is 87.07882356226922
At time: 104.49982810020447 and batch: 850, loss is 4.459321212768555 and perplexity is 86.42882239961884
At time: 105.49376964569092 and batch: 900, loss is 4.445204162597657 and perplexity is 85.21727424148897
At time: 106.4660165309906 and batch: 950, loss is 4.525081958770752 and perplexity is 92.3034905992796
At time: 107.43788313865662 and batch: 1000, loss is 4.506101341247558 and perplexity is 90.5680354548204
At time: 108.44171118736267 and batch: 1050, loss is 4.425435647964478 and perplexity is 83.54919733257857
At time: 109.43958020210266 and batch: 1100, loss is 4.474290113449097 and perplexity is 87.7322983200062
At time: 110.45107340812683 and batch: 1150, loss is 4.42912428855896 and perplexity is 83.85794938109072
At time: 111.43245100975037 and batch: 1200, loss is 4.509040002822876 and perplexity is 90.83457570454439
At time: 112.40441536903381 and batch: 1250, loss is 4.482682847976685 and perplexity is 88.47171071504816
At time: 113.37814497947693 and batch: 1300, loss is 4.483451681137085 and perplexity is 88.53975685471565
At time: 114.39314794540405 and batch: 1350, loss is 4.379319267272949 and perplexity is 79.78370353703995
At time: 115.393137216568 and batch: 1400, loss is 4.404374265670777 and perplexity is 81.80793678969339
At time: 116.37794733047485 and batch: 1450, loss is 4.33877779006958 and perplexity is 76.61384389139455
At time: 117.34893608093262 and batch: 1500, loss is 4.343925905227661 and perplexity is 77.00927777869408
At time: 118.3319582939148 and batch: 1550, loss is 4.343803796768189 and perplexity is 76.99987486851855
At time: 119.34534049034119 and batch: 1600, loss is 4.416598463058472 and perplexity is 82.8141104602378
At time: 120.3186674118042 and batch: 1650, loss is 4.377988662719726 and perplexity is 79.67761357538636
At time: 121.28317403793335 and batch: 1700, loss is 4.402880516052246 and perplexity is 81.68582743842452
At time: 122.28326845169067 and batch: 1750, loss is 4.395799169540405 and perplexity is 81.10942505040846
At time: 123.2572660446167 and batch: 1800, loss is 4.358218011856079 and perplexity is 78.1178053156436
At time: 124.22551655769348 and batch: 1850, loss is 4.385636825561523 and perplexity is 80.2893372380857
At time: 125.20387768745422 and batch: 1900, loss is 4.473466329574585 and perplexity is 87.66005562764421
At time: 126.16924142837524 and batch: 1950, loss is 4.4005779266357425 and perplexity is 81.49795489635706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.414933173601018 and perplexity of 82.67631576103406
finished 3 epochs...
Completing Train Step...
At time: 129.36165285110474 and batch: 50, loss is 4.370882320404053 and perplexity is 79.11340428498484
At time: 130.34396076202393 and batch: 100, loss is 4.3240260410308835 and perplexity is 75.49195097966246
At time: 131.30915665626526 and batch: 150, loss is 4.290000162124634 and perplexity is 72.96648032929575
At time: 132.28438711166382 and batch: 200, loss is 4.291953678131104 and perplexity is 73.10916083550606
At time: 133.26723527908325 and batch: 250, loss is 4.276497163772583 and perplexity is 71.9878362500636
At time: 134.23564338684082 and batch: 300, loss is 4.298549156188965 and perplexity is 73.59294433964119
At time: 135.2020411491394 and batch: 350, loss is 4.311348094940185 and perplexity is 74.54090945981959
At time: 136.2126908302307 and batch: 400, loss is 4.270534605979919 and perplexity is 71.55988173570525
At time: 137.17566108703613 and batch: 450, loss is 4.289080390930176 and perplexity is 72.89939871712427
At time: 138.14229822158813 and batch: 500, loss is 4.2925410556793215 and perplexity is 73.15211612940249
At time: 139.10822796821594 and batch: 550, loss is 4.248443603515625 and perplexity is 69.99638539596585
At time: 140.07394742965698 and batch: 600, loss is 4.24525025844574 and perplexity is 69.77321929657727
At time: 141.0393373966217 and batch: 650, loss is 4.315615196228027 and perplexity is 74.85966266301561
At time: 142.00486302375793 and batch: 700, loss is 4.3368495750427245 and perplexity is 76.46625826048077
At time: 142.9685571193695 and batch: 750, loss is 4.301188907623291 and perplexity is 73.78746805418717
At time: 143.93347144126892 and batch: 800, loss is 4.2716736364364625 and perplexity is 71.64143705864979
At time: 144.89812850952148 and batch: 850, loss is 4.265296869277954 and perplexity is 71.18604978804434
At time: 145.86645984649658 and batch: 900, loss is 4.24339409828186 and perplexity is 69.64382914798236
At time: 146.839040517807 and batch: 950, loss is 4.333445501327515 and perplexity is 76.20640401306895
At time: 147.80693364143372 and batch: 1000, loss is 4.316147174835205 and perplexity is 74.89949699666015
At time: 148.7741823196411 and batch: 1050, loss is 4.245375232696533 and perplexity is 69.78193969728572
At time: 149.7402515411377 and batch: 1100, loss is 4.290161066055298 and perplexity is 72.97822186739191
At time: 150.70735335350037 and batch: 1150, loss is 4.249865446090698 and perplexity is 70.09598002398559
At time: 151.66943311691284 and batch: 1200, loss is 4.3290059280395505 and perplexity is 75.86882999419899
At time: 152.65882682800293 and batch: 1250, loss is 4.308353099822998 and perplexity is 74.31799378226901
At time: 153.6242687702179 and batch: 1300, loss is 4.30814416885376 and perplexity is 74.30246807375337
At time: 154.60431480407715 and batch: 1350, loss is 4.201291809082031 and perplexity is 66.77253271507635
At time: 155.57331371307373 and batch: 1400, loss is 4.223542199134827 and perplexity is 68.27489975701569
At time: 156.53593516349792 and batch: 1450, loss is 4.162233233451843 and perplexity is 64.21476915948682
At time: 157.50252389907837 and batch: 1500, loss is 4.170299310684204 and perplexity is 64.734825032769
At time: 158.4808371067047 and batch: 1550, loss is 4.170312104225158 and perplexity is 64.735653225702
At time: 159.46218180656433 and batch: 1600, loss is 4.247769956588745 and perplexity is 69.94924842467164
At time: 160.42659664154053 and batch: 1650, loss is 4.207371611595153 and perplexity is 67.17973312200152
At time: 161.39231491088867 and batch: 1700, loss is 4.231429405212403 and perplexity is 68.8155271786574
At time: 162.373046875 and batch: 1750, loss is 4.229975423812866 and perplexity is 68.7155433870413
At time: 163.35470843315125 and batch: 1800, loss is 4.190243983268738 and perplexity is 66.0389013820164
At time: 164.34912419319153 and batch: 1850, loss is 4.219644927978516 and perplexity is 68.00933179081643
At time: 165.3219187259674 and batch: 1900, loss is 4.308956890106201 and perplexity is 74.36287981429325
At time: 166.30048179626465 and batch: 1950, loss is 4.235026130676269 and perplexity is 69.06348338546606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369346441224564 and perplexity of 78.99198891805959
finished 4 epochs...
Completing Train Step...
At time: 169.4915578365326 and batch: 50, loss is 4.214361772537232 and perplexity is 67.65097537934886
At time: 170.47935795783997 and batch: 100, loss is 4.1721628332138065 and perplexity is 64.85557231036015
At time: 171.44633769989014 and batch: 150, loss is 4.141943573951721 and perplexity is 62.92500207214178
At time: 172.41375255584717 and batch: 200, loss is 4.1477393579483035 and perplexity is 63.290760697276816
At time: 173.4108989238739 and batch: 250, loss is 4.127931356430054 and perplexity is 62.04943192116455
At time: 174.37766242027283 and batch: 300, loss is 4.1464414882659915 and perplexity is 63.20867082030176
At time: 175.3432605266571 and batch: 350, loss is 4.160829133987427 and perplexity is 64.12466850644446
At time: 176.34769916534424 and batch: 400, loss is 4.124596977233887 and perplexity is 61.84288013858768
At time: 177.31559562683105 and batch: 450, loss is 4.151766519546509 and perplexity is 63.54615673366486
At time: 178.28503012657166 and batch: 500, loss is 4.157151560783387 and perplexity is 63.88927844122061
At time: 179.25225567817688 and batch: 550, loss is 4.115550346374512 and perplexity is 61.28593347457422
At time: 180.2294626235962 and batch: 600, loss is 4.113831834793091 and perplexity is 61.18070333362578
At time: 181.21166491508484 and batch: 650, loss is 4.17986912727356 and perplexity is 65.35729916634169
At time: 182.17749166488647 and batch: 700, loss is 4.202799677848816 and perplexity is 66.87329287909739
At time: 183.14220428466797 and batch: 750, loss is 4.169051423072815 and perplexity is 64.65409362892093
At time: 184.09935688972473 and batch: 800, loss is 4.143447117805481 and perplexity is 63.01968373343333
At time: 185.0657341480255 and batch: 850, loss is 4.136992883682251 and perplexity is 62.61424973066758
At time: 186.03075575828552 and batch: 900, loss is 4.111072683334351 and perplexity is 61.012129174539616
At time: 186.98579025268555 and batch: 950, loss is 4.207517118453979 and perplexity is 67.18950894515228
At time: 187.9409453868866 and batch: 1000, loss is 4.187666749954223 and perplexity is 65.86892285656495
At time: 188.9048354625702 and batch: 1050, loss is 4.123238906860352 and perplexity is 61.75895015956608
At time: 189.87108445167542 and batch: 1100, loss is 4.162365093231201 and perplexity is 64.22323706305538
At time: 190.83863019943237 and batch: 1150, loss is 4.127096657752991 and perplexity is 61.99766095201299
At time: 191.8055465221405 and batch: 1200, loss is 4.202839703559875 and perplexity is 66.8759695837639
At time: 192.77156472206116 and batch: 1250, loss is 4.188101167678833 and perplexity is 65.89754370040562
At time: 193.7373342514038 and batch: 1300, loss is 4.182852258682251 and perplexity is 65.55255967735057
At time: 194.70315670967102 and batch: 1350, loss is 4.077042207717896 and perplexity is 58.9707882988612
At time: 195.6965720653534 and batch: 1400, loss is 4.10575297832489 and perplexity is 60.68842441562918
At time: 196.6631121635437 and batch: 1450, loss is 4.036779737472534 and perplexity is 56.6436413942995
At time: 197.64970207214355 and batch: 1500, loss is 4.0493372631073 and perplexity is 57.35943023539183
At time: 198.6199791431427 and batch: 1550, loss is 4.05011510848999 and perplexity is 57.4040643603277
At time: 199.58795428276062 and batch: 1600, loss is 4.133220477104187 and perplexity is 62.3784882966896
At time: 200.57867431640625 and batch: 1650, loss is 4.089806680679321 and perplexity is 59.72834394510196
At time: 201.5543155670166 and batch: 1700, loss is 4.114930644035339 and perplexity is 61.24796620365998
At time: 202.5214183330536 and batch: 1750, loss is 4.114217462539673 and perplexity is 61.20430086002469
At time: 203.51345109939575 and batch: 1800, loss is 4.07100163936615 and perplexity is 58.6156449351529
At time: 204.50582671165466 and batch: 1850, loss is 4.104568099975586 and perplexity is 60.616558600018095
At time: 205.47281670570374 and batch: 1900, loss is 4.189127883911133 and perplexity is 65.96523652290483
At time: 206.46662640571594 and batch: 1950, loss is 4.115859441757202 and perplexity is 61.30487960156439
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359579964571221 and perplexity of 78.22427055654917
finished 5 epochs...
Completing Train Step...
At time: 209.6819076538086 and batch: 50, loss is 4.104481945037842 and perplexity is 60.61133640914765
At time: 210.676616191864 and batch: 100, loss is 4.0629015111923215 and perplexity is 58.14276846373208
At time: 211.6417944431305 and batch: 150, loss is 4.0396849727630615 and perplexity is 56.808443779198114
At time: 212.6064202785492 and batch: 200, loss is 4.04454463481903 and perplexity is 57.08518550889731
At time: 213.57153749465942 and batch: 250, loss is 4.0192331075668335 and perplexity is 55.65840544561041
At time: 214.5371687412262 and batch: 300, loss is 4.032339587211609 and perplexity is 56.39269265252983
At time: 215.53023862838745 and batch: 350, loss is 4.046403155326844 and perplexity is 57.19137814688901
At time: 216.52687668800354 and batch: 400, loss is 4.0198796224594116 and perplexity is 55.6944010682274
At time: 217.52548003196716 and batch: 450, loss is 4.048099889755249 and perplexity is 57.28849909812943
At time: 218.49083757400513 and batch: 500, loss is 4.060879445075988 and perplexity is 58.02531872729654
At time: 219.46158504486084 and batch: 550, loss is 4.020045962333679 and perplexity is 55.70366603844412
At time: 220.43182253837585 and batch: 600, loss is 4.017230911254883 and perplexity is 55.54707787851102
At time: 221.3986144065857 and batch: 650, loss is 4.085040860176086 and perplexity is 59.44436660890873
At time: 222.36530542373657 and batch: 700, loss is 4.105063166618347 and perplexity is 60.64657526569184
At time: 223.35871267318726 and batch: 750, loss is 4.070613813400269 and perplexity is 58.59291667363003
At time: 224.35674715042114 and batch: 800, loss is 4.045043296813965 and perplexity is 57.11365882007345
At time: 225.37156629562378 and batch: 850, loss is 4.043020520210266 and perplexity is 56.99824741235991
At time: 226.36307907104492 and batch: 900, loss is 4.017708940505981 and perplexity is 55.57363735414736
At time: 227.35207867622375 and batch: 950, loss is 4.115303931236267 and perplexity is 61.270833553305586
At time: 228.31786680221558 and batch: 1000, loss is 4.090879282951355 and perplexity is 59.79244307281193
At time: 229.28301763534546 and batch: 1050, loss is 4.0348236989974975 and perplexity is 56.53295254348366
At time: 230.24817371368408 and batch: 1100, loss is 4.066722898483277 and perplexity is 58.36537957092916
At time: 231.21382665634155 and batch: 1150, loss is 4.03091332912445 and perplexity is 56.312319448668205
At time: 232.1783800125122 and batch: 1200, loss is 4.111198558807373 and perplexity is 61.019809588537264
At time: 233.14351773262024 and batch: 1250, loss is 4.100024123191833 and perplexity is 60.341743215251945
At time: 234.10733795166016 and batch: 1300, loss is 4.090984916687011 and perplexity is 59.79875950554605
At time: 235.08703184127808 and batch: 1350, loss is 3.9840506410598753 and perplexity is 53.7342521626757
At time: 236.05959606170654 and batch: 1400, loss is 4.015700993537902 and perplexity is 55.462160394883036
At time: 237.02633333206177 and batch: 1450, loss is 3.944507875442505 and perplexity is 51.650913173712055
At time: 237.9950451850891 and batch: 1500, loss is 3.9613605737686157 and perplexity is 52.52874658626226
At time: 238.96370220184326 and batch: 1550, loss is 3.9587362670898436 and perplexity is 52.391075770001095
At time: 239.92828488349915 and batch: 1600, loss is 4.045665082931518 and perplexity is 57.14918234312267
At time: 240.89405012130737 and batch: 1650, loss is 4.001381621360779 and perplexity is 54.67363613808876
At time: 241.85915660858154 and batch: 1700, loss is 4.028826107978821 and perplexity is 56.19490576154677
At time: 242.82412719726562 and batch: 1750, loss is 4.030580768585205 and perplexity is 56.29359530697409
At time: 243.80408811569214 and batch: 1800, loss is 3.9830909299850465 and perplexity is 53.68270754370462
At time: 244.78875494003296 and batch: 1850, loss is 4.018220472335815 and perplexity is 55.602072310626276
At time: 245.76301288604736 and batch: 1900, loss is 4.100462484359741 and perplexity is 60.36820049077882
At time: 246.72995829582214 and batch: 1950, loss is 4.0265680694580075 and perplexity is 56.068158653444144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346448321675146 and perplexity of 77.20377244271764
finished 6 epochs...
Completing Train Step...
At time: 249.9365222454071 and batch: 50, loss is 4.018091425895691 and perplexity is 55.59489752408136
At time: 250.92627239227295 and batch: 100, loss is 3.981200361251831 and perplexity is 53.5813125725901
At time: 251.8934235572815 and batch: 150, loss is 3.9556366348266603 and perplexity is 52.22893412080266
At time: 252.8634054660797 and batch: 200, loss is 3.963561987876892 and perplexity is 52.64451148657785
At time: 253.85458135604858 and batch: 250, loss is 3.9420113372802734 and perplexity is 51.52212552638922
At time: 254.8511712551117 and batch: 300, loss is 3.9507343435287474 and perplexity is 51.97351924215192
At time: 255.83063745498657 and batch: 350, loss is 3.9620592308044436 and perplexity is 52.565458987843456
At time: 256.8140461444855 and batch: 400, loss is 3.935808653831482 and perplexity is 51.203539157759266
At time: 257.77949237823486 and batch: 450, loss is 3.9685476636886596 and perplexity is 52.907635334181954
At time: 258.7467601299286 and batch: 500, loss is 3.981941876411438 and perplexity is 53.62105866247723
At time: 259.7135307788849 and batch: 550, loss is 3.941371440887451 and perplexity is 51.48916725017999
At time: 260.6793780326843 and batch: 600, loss is 3.944074511528015 and perplexity is 51.62853438122292
At time: 261.6451108455658 and batch: 650, loss is 4.0118991565704345 and perplexity is 55.2517026197686
At time: 262.6115448474884 and batch: 700, loss is 4.029404835700989 and perplexity is 56.22743672373245
At time: 263.57655334472656 and batch: 750, loss is 3.9954320907592775 and perplexity is 54.34931938965
At time: 264.5338442325592 and batch: 800, loss is 3.973376541137695 and perplexity is 53.16373766706839
At time: 265.4961576461792 and batch: 850, loss is 3.9697678518295287 and perplexity is 52.97223200540962
At time: 266.45898818969727 and batch: 900, loss is 3.9430018138885496 and perplexity is 51.57318226761164
At time: 267.4145407676697 and batch: 950, loss is 4.040928997993469 and perplexity is 56.87915889313271
At time: 268.3695797920227 and batch: 1000, loss is 4.018203792572021 and perplexity is 55.601144888928275
At time: 269.3350179195404 and batch: 1050, loss is 3.9636928749084475 and perplexity is 52.651402421371166
At time: 270.3158085346222 and batch: 1100, loss is 3.995715832710266 and perplexity is 54.36474275959358
At time: 271.301292181015 and batch: 1150, loss is 3.959849338531494 and perplexity is 52.44942324666899
At time: 272.2677719593048 and batch: 1200, loss is 4.038416409492493 and perplexity is 56.736424364212105
At time: 273.23266673088074 and batch: 1250, loss is 4.027324771881103 and perplexity is 56.11060162127879
At time: 274.19744658470154 and batch: 1300, loss is 4.020722880363464 and perplexity is 55.74138561940256
At time: 275.18362188339233 and batch: 1350, loss is 3.915223264694214 and perplexity is 50.160269278139346
At time: 276.1523072719574 and batch: 1400, loss is 3.943455548286438 and perplexity is 51.59658810403002
At time: 277.1198527812958 and batch: 1450, loss is 3.871827826499939 and perplexity is 48.03009657993568
At time: 278.0855362415314 and batch: 1500, loss is 3.8941027116775513 and perplexity is 49.11196599252308
At time: 279.0499804019928 and batch: 1550, loss is 3.88777717590332 and perplexity is 48.80228697014464
At time: 280.0242075920105 and batch: 1600, loss is 3.9791377639770507 and perplexity is 53.470909800667584
At time: 280.98875403404236 and batch: 1650, loss is 3.9313675928115845 and perplexity is 50.97664531354779
At time: 281.97132873535156 and batch: 1700, loss is 3.9581893396377565 and perplexity is 52.36242948685152
At time: 282.940025806427 and batch: 1750, loss is 3.9639226150512696 and perplexity is 52.663499951674204
At time: 283.9082360267639 and batch: 1800, loss is 3.9122507619857787 and perplexity is 50.01138912480633
At time: 284.88176798820496 and batch: 1850, loss is 3.9534172010421753 and perplexity is 52.11314400166921
At time: 285.8794138431549 and batch: 1900, loss is 4.029970350265503 and perplexity is 56.25924315077625
At time: 286.86104369163513 and batch: 1950, loss is 3.951367793083191 and perplexity is 52.0064522743648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342027389171512 and perplexity of 76.86321312527613
finished 7 epochs...
Completing Train Step...
At time: 290.0378932952881 and batch: 50, loss is 3.9487467765808106 and perplexity is 51.87032098383498
At time: 291.0052344799042 and batch: 100, loss is 3.916790509223938 and perplexity is 50.23894432118659
At time: 291.9715406894684 and batch: 150, loss is 3.8949559688568116 and perplexity is 49.15388901310944
At time: 292.9372355937958 and batch: 200, loss is 3.901674828529358 and perplexity is 49.48525906359523
At time: 293.9042718410492 and batch: 250, loss is 3.8762404918670654 and perplexity is 48.24250562404786
At time: 294.8703122138977 and batch: 300, loss is 3.884739007949829 and perplexity is 48.65424243177758
At time: 295.838036775589 and batch: 350, loss is 3.8928470516204836 and perplexity is 49.05033675928295
At time: 296.8048167228699 and batch: 400, loss is 3.87260169506073 and perplexity is 48.06727994731447
At time: 297.7910532951355 and batch: 450, loss is 3.9063452816009523 and perplexity is 49.716918199247495
At time: 298.75649070739746 and batch: 500, loss is 3.921169834136963 and perplexity is 50.45943943914129
At time: 299.75906229019165 and batch: 550, loss is 3.882676920890808 and perplexity is 48.55401652088454
At time: 300.7343964576721 and batch: 600, loss is 3.8821116304397583 and perplexity is 48.52657715532153
At time: 301.70053029060364 and batch: 650, loss is 3.950465817451477 and perplexity is 51.95956487054807
At time: 302.6677768230438 and batch: 700, loss is 3.9686768531799315 and perplexity is 52.91447088620641
At time: 303.6355516910553 and batch: 750, loss is 3.937295298576355 and perplexity is 51.27971724101043
At time: 304.611670255661 and batch: 800, loss is 3.9123048210144042 and perplexity is 50.01409276500005
At time: 305.58314299583435 and batch: 850, loss is 3.909946947097778 and perplexity is 49.89630475940965
At time: 306.5762577056885 and batch: 900, loss is 3.8824614000320437 and perplexity is 48.54355324511509
At time: 307.5567624568939 and batch: 950, loss is 3.982558650970459 and perplexity is 53.6541409684016
At time: 308.5412118434906 and batch: 1000, loss is 3.9584100580215456 and perplexity is 52.37398811321286
At time: 309.5069456100464 and batch: 1050, loss is 3.906366467475891 and perplexity is 49.71797150681639
At time: 310.473349571228 and batch: 1100, loss is 3.93287157535553 and perplexity is 51.053370980817824
At time: 311.437650680542 and batch: 1150, loss is 3.9026207637786867 and perplexity is 49.532091060992144
At time: 312.4049458503723 and batch: 1200, loss is 3.979658327102661 and perplexity is 53.498752030793085
At time: 313.37292218208313 and batch: 1250, loss is 3.971323595046997 and perplexity is 53.054707334648384
At time: 314.33894205093384 and batch: 1300, loss is 3.962508034706116 and perplexity is 52.58905586571974
At time: 315.3052592277527 and batch: 1350, loss is 3.856258487701416 and perplexity is 47.28809099068054
At time: 316.297860622406 and batch: 1400, loss is 3.8878133153915404 and perplexity is 48.804050691689525
At time: 317.26557779312134 and batch: 1450, loss is 3.8127025413513183 and perplexity is 45.27262482632208
At time: 318.23251485824585 and batch: 1500, loss is 3.8324388790130617 and perplexity is 46.1750162964421
At time: 319.19941449165344 and batch: 1550, loss is 3.828261594772339 and perplexity is 45.982532438344144
At time: 320.16912317276 and batch: 1600, loss is 3.9246852684020994 and perplexity is 50.63713844312453
At time: 321.1525013446808 and batch: 1650, loss is 3.876067681312561 and perplexity is 48.23416953020352
At time: 322.11992049217224 and batch: 1700, loss is 3.9032917499542235 and perplexity is 49.56533756206343
At time: 323.1063287258148 and batch: 1750, loss is 3.905438256263733 and perplexity is 49.671844139499626
At time: 324.1046302318573 and batch: 1800, loss is 3.855793790817261 and perplexity is 47.26612146711943
At time: 325.07205843925476 and batch: 1850, loss is 3.895333518981934 and perplexity is 49.17245057379588
At time: 326.037992477417 and batch: 1900, loss is 3.9744660902023314 and perplexity is 53.22169373497251
At time: 327.0030143260956 and batch: 1950, loss is 3.8939265632629394 and perplexity is 49.10331575945982
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343539925508721 and perplexity of 76.97955949499762
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 330.1810653209686 and batch: 50, loss is 3.9233282899856565 and perplexity is 50.56847153947675
At time: 331.1609151363373 and batch: 100, loss is 3.920802969932556 and perplexity is 50.44093107227287
At time: 332.1222493648529 and batch: 150, loss is 3.9027424240112305 and perplexity is 49.53811751329136
At time: 333.0766878128052 and batch: 200, loss is 3.916078658103943 and perplexity is 50.20319439822518
At time: 334.03100395202637 and batch: 250, loss is 3.8912077856063845 and perplexity is 48.969996077119156
At time: 334.9968726634979 and batch: 300, loss is 3.889186086654663 and perplexity is 48.871093496692595
At time: 335.9979844093323 and batch: 350, loss is 3.8891749000549316 and perplexity is 48.870546798389064
At time: 336.96556210517883 and batch: 400, loss is 3.856149392127991 and perplexity is 47.28293235067523
At time: 337.9315972328186 and batch: 450, loss is 3.8824489545822143 and perplexity is 48.54294910251806
At time: 338.89904952049255 and batch: 500, loss is 3.8899652051925657 and perplexity is 48.90918470846119
At time: 339.8663671016693 and batch: 550, loss is 3.854231915473938 and perplexity is 47.19235529920063
At time: 340.82926654815674 and batch: 600, loss is 3.8374630641937255 and perplexity is 46.40759189123294
At time: 341.79161286354065 and batch: 650, loss is 3.900360903739929 and perplexity is 49.42028185193289
At time: 342.75193524360657 and batch: 700, loss is 3.9177142667770384 and perplexity is 50.28537436721426
At time: 343.71165323257446 and batch: 750, loss is 3.871879663467407 and perplexity is 48.03258637902085
At time: 344.6731605529785 and batch: 800, loss is 3.847258939743042 and perplexity is 46.864428791518435
At time: 345.6328008174896 and batch: 850, loss is 3.8421581745147706 and perplexity is 46.625992962253925
At time: 346.61208510398865 and batch: 900, loss is 3.79932891368866 and perplexity is 44.671196203777434
At time: 347.6125671863556 and batch: 950, loss is 3.9023515224456786 and perplexity is 49.518756769919904
At time: 348.5852861404419 and batch: 1000, loss is 3.8649031352996825 and perplexity is 47.69865189328755
At time: 349.55211663246155 and batch: 1050, loss is 3.8123223114013673 and perplexity is 45.255414090676155
At time: 350.5188820362091 and batch: 1100, loss is 3.8259246063232424 and perplexity is 45.87519726056191
At time: 351.4817678928375 and batch: 1150, loss is 3.797803897857666 and perplexity is 44.6031238412853
At time: 352.44202518463135 and batch: 1200, loss is 3.8589921140670778 and perplexity is 47.41753580927031
At time: 353.40144419670105 and batch: 1250, loss is 3.836054344177246 and perplexity is 46.34226261375336
At time: 354.361985206604 and batch: 1300, loss is 3.830288906097412 and perplexity is 46.07584790490255
At time: 355.3222305774689 and batch: 1350, loss is 3.7211906051635744 and perplexity is 41.31355296789707
At time: 356.28209590911865 and batch: 1400, loss is 3.7399359130859375 and perplexity is 42.09529232116816
At time: 357.2557237148285 and batch: 1450, loss is 3.6606198215484618 and perplexity is 38.88543743543991
At time: 358.216171503067 and batch: 1500, loss is 3.6653333282470704 and perplexity is 39.06915684646417
At time: 359.1756236553192 and batch: 1550, loss is 3.6592374086380004 and perplexity is 38.831718843892446
At time: 360.1354420185089 and batch: 1600, loss is 3.751985182762146 and perplexity is 42.60557796129043
At time: 361.09761095046997 and batch: 1650, loss is 3.692469987869263 and perplexity is 40.14387949773602
At time: 362.05775260925293 and batch: 1700, loss is 3.7144065380096434 and perplexity is 41.03422760250865
At time: 363.0274131298065 and batch: 1750, loss is 3.701282596588135 and perplexity is 40.49921521786707
At time: 363.9881227016449 and batch: 1800, loss is 3.647911105155945 and perplexity is 38.3943804008276
At time: 364.9497039318085 and batch: 1850, loss is 3.675149564743042 and perplexity is 39.4545574266743
At time: 365.9132082462311 and batch: 1900, loss is 3.7482618474960328 and perplexity is 42.447238069510654
At time: 366.88194012641907 and batch: 1950, loss is 3.664335470199585 and perplexity is 39.03019081841206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.277049361827761 and perplexity of 72.02759877062027
finished 9 epochs...
Completing Train Step...
At time: 370.07958221435547 and batch: 50, loss is 3.8334077167510987 and perplexity is 46.21977407279499
At time: 371.0616281032562 and batch: 100, loss is 3.8167638540267945 and perplexity is 45.456864986588386
At time: 372.02675914764404 and batch: 150, loss is 3.7910832023620604 and perplexity is 44.30436488629835
At time: 372.99298644065857 and batch: 200, loss is 3.8039020490646362 and perplexity is 44.8759514613332
At time: 373.95897364616394 and batch: 250, loss is 3.781257667541504 and perplexity is 43.87118241611592
At time: 374.9233589172363 and batch: 300, loss is 3.78151388168335 and perplexity is 43.882424273570365
At time: 375.91747403144836 and batch: 350, loss is 3.7855558443069457 and perplexity is 44.06015433948723
At time: 376.8831388950348 and batch: 400, loss is 3.7530357789993287 and perplexity is 42.65036274242154
At time: 377.84713101387024 and batch: 450, loss is 3.787692642211914 and perplexity is 44.154402643901406
At time: 378.8112061023712 and batch: 500, loss is 3.7975306844711305 and perplexity is 44.59093933533143
At time: 379.7770788669586 and batch: 550, loss is 3.7645355749130247 and perplexity is 43.14366420629546
At time: 380.7430465221405 and batch: 600, loss is 3.7533034229278566 and perplexity is 42.661779380787884
At time: 381.71415662765503 and batch: 650, loss is 3.8166475009918215 and perplexity is 45.451576250073074
At time: 382.69448924064636 and batch: 700, loss is 3.835620527267456 and perplexity is 46.322162916703036
At time: 383.7002956867218 and batch: 750, loss is 3.7932904624938963 and perplexity is 44.402264149401304
At time: 384.673193693161 and batch: 800, loss is 3.7676971626281737 and perplexity is 43.28028253665514
At time: 385.6404128074646 and batch: 850, loss is 3.7658314371109007 and perplexity is 43.19960869016039
At time: 386.62953639030457 and batch: 900, loss is 3.7262404680252077 and perplexity is 41.52270840337018
At time: 387.5948259830475 and batch: 950, loss is 3.8322644329071043 and perplexity is 46.166961947202026
At time: 388.563129901886 and batch: 1000, loss is 3.7956356048583983 and perplexity is 44.506515975044906
At time: 389.5299515724182 and batch: 1050, loss is 3.7493127298355104 and perplexity is 42.49186856895202
At time: 390.4949550628662 and batch: 1100, loss is 3.7629945850372315 and perplexity is 43.07723145579312
At time: 391.45993185043335 and batch: 1150, loss is 3.7378428840637206 and perplexity is 42.007277793252854
At time: 392.4245810508728 and batch: 1200, loss is 3.800415959358215 and perplexity is 44.71978223699873
At time: 393.4018301963806 and batch: 1250, loss is 3.7822251510620117 and perplexity is 43.91364760099962
At time: 394.3837716579437 and batch: 1300, loss is 3.77869029045105 and perplexity is 43.758693010599764
At time: 395.352308511734 and batch: 1350, loss is 3.6711459589004516 and perplexity is 39.29691271426191
At time: 396.3058981895447 and batch: 1400, loss is 3.6940952157974243 and perplexity is 40.20917549790948
At time: 397.2634379863739 and batch: 1450, loss is 3.6172274494171144 and perplexity is 37.2341909017173
At time: 398.2398579120636 and batch: 1500, loss is 3.623935170173645 and perplexity is 37.48478698154522
At time: 399.2305974960327 and batch: 1550, loss is 3.6205881595611573 and perplexity is 37.35953472894846
At time: 400.2050361633301 and batch: 1600, loss is 3.717120199203491 and perplexity is 41.14573181747764
At time: 401.18047189712524 and batch: 1650, loss is 3.6601747608184816 and perplexity is 38.86813490489334
At time: 402.1610701084137 and batch: 1700, loss is 3.687301630973816 and perplexity is 39.93693683873587
At time: 403.1266760826111 and batch: 1750, loss is 3.6775735425949097 and perplexity is 39.5503104046964
At time: 404.0921518802643 and batch: 1800, loss is 3.627205476760864 and perplexity is 37.60757439414031
At time: 405.0602560043335 and batch: 1850, loss is 3.657208213806152 and perplexity is 38.75300161401137
At time: 406.0517919063568 and batch: 1900, loss is 3.7360713386535647 and perplexity is 41.932925871433326
At time: 407.02395725250244 and batch: 1950, loss is 3.6538835859298704 and perplexity is 38.62437623878615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2798811091933135 and perplexity of 72.23185179367745
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 410.23260402679443 and batch: 50, loss is 3.8082928705215453 and perplexity is 45.073426974503136
At time: 411.22277307510376 and batch: 100, loss is 3.8223171758651735 and perplexity is 45.710003817768865
At time: 412.18920063972473 and batch: 150, loss is 3.805704965591431 and perplexity is 44.9569320345497
At time: 413.15787529945374 and batch: 200, loss is 3.833654479980469 and perplexity is 46.231180820831064
At time: 414.12447595596313 and batch: 250, loss is 3.823538827896118 and perplexity is 45.76587966023629
At time: 415.09258556365967 and batch: 300, loss is 3.8334859466552733 and perplexity is 46.223389982725976
At time: 416.060818195343 and batch: 350, loss is 3.836301398277283 and perplexity is 46.35371307412042
At time: 417.02964210510254 and batch: 400, loss is 3.7990432453155516 and perplexity is 44.65843687838773
At time: 417.9982271194458 and batch: 450, loss is 3.8257109785079955 and perplexity is 45.86539808912217
At time: 418.9687919616699 and batch: 500, loss is 3.8293357515335082 and perplexity is 46.03195142357535
At time: 419.98736691474915 and batch: 550, loss is 3.8006134700775145 and perplexity is 44.72861574568288
At time: 420.9542751312256 and batch: 600, loss is 3.780875883102417 and perplexity is 43.85443627825594
At time: 421.92183899879456 and batch: 650, loss is 3.8341051721572876 and perplexity is 46.252021548375765
At time: 422.8873829841614 and batch: 700, loss is 3.8525585460662843 and perplexity is 47.11345109192319
At time: 423.8554871082306 and batch: 750, loss is 3.808161725997925 and perplexity is 45.067516228984054
At time: 424.8240592479706 and batch: 800, loss is 3.7769727516174316 and perplexity is 43.683600261861635
At time: 425.79140424728394 and batch: 850, loss is 3.773822226524353 and perplexity is 43.54619055310688
At time: 426.78794384002686 and batch: 900, loss is 3.724443306922913 and perplexity is 41.44815242158758
At time: 427.77069640159607 and batch: 950, loss is 3.840044937133789 and perplexity is 46.527565208234925
At time: 428.75221276283264 and batch: 1000, loss is 3.7992664623260497 and perplexity is 44.66840651381595
At time: 429.72650814056396 and batch: 1050, loss is 3.743596386909485 and perplexity is 42.2496634000821
At time: 430.6924726963043 and batch: 1100, loss is 3.7634546613693236 and perplexity is 43.09705483022101
At time: 431.6576964855194 and batch: 1150, loss is 3.738024640083313 and perplexity is 42.014913562760974
At time: 432.6217620372772 and batch: 1200, loss is 3.792498016357422 and perplexity is 44.36709168470787
At time: 433.5876896381378 and batch: 1250, loss is 3.768534002304077 and perplexity is 43.31651635309919
At time: 434.55346274375916 and batch: 1300, loss is 3.7606522941589358 and perplexity is 42.9764501251643
At time: 435.53137135505676 and batch: 1350, loss is 3.6482203912734987 and perplexity is 38.406257086229935
At time: 436.4974982738495 and batch: 1400, loss is 3.6688869762420655 and perplexity is 39.20824186057996
At time: 437.4639904499054 and batch: 1450, loss is 3.584290804862976 and perplexity is 36.027797917406374
At time: 438.4294807910919 and batch: 1500, loss is 3.59231201171875 and perplexity is 36.3179464520955
At time: 439.39384365081787 and batch: 1550, loss is 3.5803043985366823 and perplexity is 35.884462362564555
At time: 440.3596966266632 and batch: 1600, loss is 3.6753237724304197 and perplexity is 39.46143131260462
At time: 441.3257346153259 and batch: 1650, loss is 3.61669376373291 and perplexity is 37.21432484865569
At time: 442.3175208568573 and batch: 1700, loss is 3.644962568283081 and perplexity is 38.28133988846103
At time: 443.2894778251648 and batch: 1750, loss is 3.6328285837173464 and perplexity is 37.81964148651893
At time: 444.2565324306488 and batch: 1800, loss is 3.5803047800064087 and perplexity is 35.884476051403205
At time: 445.2243764400482 and batch: 1850, loss is 3.602819309234619 and perplexity is 36.70156177141897
At time: 446.19031381607056 and batch: 1900, loss is 3.689946699142456 and perplexity is 40.042712589485994
At time: 447.1558516025543 and batch: 1950, loss is 3.6156950902938845 and perplexity is 37.17717844252998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.248731036518896 and perplexity of 70.01650755898665
finished 11 epochs...
Completing Train Step...
At time: 450.3753788471222 and batch: 50, loss is 3.805374765396118 and perplexity is 44.9420896974174
At time: 451.3435335159302 and batch: 100, loss is 3.7934898567199706 and perplexity is 44.41111858722987
At time: 452.3099572658539 and batch: 150, loss is 3.766996111869812 and perplexity is 43.24995149480289
At time: 453.27547335624695 and batch: 200, loss is 3.787241287231445 and perplexity is 44.13447783127841
At time: 454.2424850463867 and batch: 250, loss is 3.7720269775390625 and perplexity is 43.468084429650055
At time: 455.21414709091187 and batch: 300, loss is 3.779102487564087 and perplexity is 43.776733935482135
At time: 456.18118929862976 and batch: 350, loss is 3.782162599563599 and perplexity is 43.910900822449854
At time: 457.1467537879944 and batch: 400, loss is 3.7478861904144285 and perplexity is 42.431295458600125
At time: 458.11460852622986 and batch: 450, loss is 3.7774124765396118 and perplexity is 43.702813253493375
At time: 459.07984590530396 and batch: 500, loss is 3.7824586725234983 and perplexity is 43.92390357761533
At time: 460.0490560531616 and batch: 550, loss is 3.754326734542847 and perplexity is 42.70545801976212
At time: 461.0151255130768 and batch: 600, loss is 3.7384252643585203 and perplexity is 42.03174912919808
At time: 461.9791955947876 and batch: 650, loss is 3.793796501159668 and perplexity is 44.424739098025604
At time: 462.94424080848694 and batch: 700, loss is 3.814446120262146 and perplexity is 45.35163007613567
At time: 463.9088513851166 and batch: 750, loss is 3.7728194904327395 and perplexity is 43.502547101276036
At time: 464.8735599517822 and batch: 800, loss is 3.7420795249938963 and perplexity is 42.18562507565046
At time: 465.8378326892853 and batch: 850, loss is 3.7392627382278443 and perplexity is 42.06696436463729
At time: 466.80177116394043 and batch: 900, loss is 3.6918340158462524 and perplexity is 40.11835723006469
At time: 467.79164123535156 and batch: 950, loss is 3.8081150674819946 and perplexity is 45.065413494615754
At time: 468.75818490982056 and batch: 1000, loss is 3.7688231229782105 and perplexity is 43.329041864113144
At time: 469.74766087532043 and batch: 1050, loss is 3.7160777950286867 and perplexity is 41.102863681699304
At time: 470.7248103618622 and batch: 1100, loss is 3.736503438949585 and perplexity is 41.95104901634153
At time: 471.69216108322144 and batch: 1150, loss is 3.712249503135681 and perplexity is 40.94581073595839
At time: 472.65779209136963 and batch: 1200, loss is 3.769598293304443 and perplexity is 43.36264227296773
At time: 473.62496519088745 and batch: 1250, loss is 3.7485493087768553 and perplexity is 42.45944176089384
At time: 474.59089970588684 and batch: 1300, loss is 3.7415204763412477 and perplexity is 42.16204784981301
At time: 475.5490472316742 and batch: 1350, loss is 3.630873589515686 and perplexity is 37.74577653300781
At time: 476.5157172679901 and batch: 1400, loss is 3.6541486120224 and perplexity is 38.63461406288245
At time: 477.47815918922424 and batch: 1450, loss is 3.572053155899048 and perplexity is 35.58958916482679
At time: 478.4319112300873 and batch: 1500, loss is 3.58242280960083 and perplexity is 35.96056098028252
At time: 479.3861322402954 and batch: 1550, loss is 3.572367811203003 and perplexity is 35.600789379834204
At time: 480.348078250885 and batch: 1600, loss is 3.670270771980286 and perplexity is 39.262535615639294
At time: 481.31183409690857 and batch: 1650, loss is 3.61371964931488 and perplexity is 37.1038096125069
At time: 482.27825379371643 and batch: 1700, loss is 3.64423948764801 and perplexity is 38.2536693981066
At time: 483.2436554431915 and batch: 1750, loss is 3.633913116455078 and perplexity is 37.86068037582729
At time: 484.2104277610779 and batch: 1800, loss is 3.582662420272827 and perplexity is 35.96917854685363
At time: 485.1760082244873 and batch: 1850, loss is 3.6064671373367307 and perplexity is 36.835687244444976
At time: 486.1439003944397 and batch: 1900, loss is 3.6948702764511108 and perplexity is 40.24035212808406
At time: 487.1107773780823 and batch: 1950, loss is 3.620564274787903 and perplexity is 37.35864241558897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2482995321584305 and perplexity of 69.98630164813021
finished 12 epochs...
Completing Train Step...
At time: 490.32348012924194 and batch: 50, loss is 3.7885191679000854 and perplexity is 44.19091247801187
At time: 491.3160092830658 and batch: 100, loss is 3.7744931983947754 and perplexity is 43.57541862654307
At time: 492.3019790649414 and batch: 150, loss is 3.7472450160980224 and perplexity is 42.404098321724796
At time: 493.2714011669159 and batch: 200, loss is 3.7659531259536743 and perplexity is 43.204865920416815
At time: 494.2392852306366 and batch: 250, loss is 3.7502350425720214 and perplexity is 42.53107743917205
At time: 495.20715522766113 and batch: 300, loss is 3.7571361875534057 and perplexity is 42.82560569295674
At time: 496.1782307624817 and batch: 350, loss is 3.759289813041687 and perplexity is 42.91793539504183
At time: 497.143896818161 and batch: 400, loss is 3.726063780784607 and perplexity is 41.51537251869782
At time: 498.1099417209625 and batch: 450, loss is 3.756063389778137 and perplexity is 42.779687113523686
At time: 499.0983612537384 and batch: 500, loss is 3.761682357788086 and perplexity is 43.02074141085325
At time: 500.0695946216583 and batch: 550, loss is 3.7335424184799195 and perplexity is 41.82701482599242
At time: 501.03815603256226 and batch: 600, loss is 3.718895378112793 and perplexity is 41.218837721639446
At time: 502.0063819885254 and batch: 650, loss is 3.774721550941467 and perplexity is 43.58537032056369
At time: 502.9736421108246 and batch: 700, loss is 3.7958252668380736 and perplexity is 44.51495796951057
At time: 503.94150400161743 and batch: 750, loss is 3.7552829504013063 and perplexity is 42.74631318602935
At time: 504.90757942199707 and batch: 800, loss is 3.724653038978577 and perplexity is 41.4568463394632
At time: 505.8739368915558 and batch: 850, loss is 3.72186318397522 and perplexity is 41.34134893469841
At time: 506.84011816978455 and batch: 900, loss is 3.675236072540283 and perplexity is 39.4579707011637
At time: 507.8053903579712 and batch: 950, loss is 3.7918794345855713 and perplexity is 44.339655497159306
At time: 508.7727122306824 and batch: 1000, loss is 3.753659052848816 and perplexity is 42.67695388411083
At time: 509.76878213882446 and batch: 1050, loss is 3.701859030723572 and perplexity is 40.52256707773503
At time: 510.737722158432 and batch: 1100, loss is 3.72248544216156 and perplexity is 41.367081932961455
At time: 511.70468163490295 and batch: 1150, loss is 3.6984748029708863 and perplexity is 40.38566127249842
At time: 512.6715376377106 and batch: 1200, loss is 3.7566532993316653 and perplexity is 42.804930704634636
At time: 513.6378865242004 and batch: 1250, loss is 3.7368415117263796 and perplexity is 41.96523392160198
At time: 514.6058239936829 and batch: 1300, loss is 3.7302503538131715 and perplexity is 41.68954399395815
At time: 515.5993325710297 and batch: 1350, loss is 3.619998908042908 and perplexity is 37.337527051053925
At time: 516.5913388729095 and batch: 1400, loss is 3.6446035432815553 and perplexity is 38.26759839726622
At time: 517.5595619678497 and batch: 1450, loss is 3.563196702003479 and perplexity is 35.27578326412968
At time: 518.5255560874939 and batch: 1500, loss is 3.5742718887329104 and perplexity is 35.668640619450066
At time: 519.4911675453186 and batch: 1550, loss is 3.5648935556411745 and perplexity is 35.33569191901882
At time: 520.457062959671 and batch: 1600, loss is 3.664014945030212 and perplexity is 39.017682664585486
At time: 521.4218378067017 and batch: 1650, loss is 3.607973184585571 and perplexity is 36.89120532581173
At time: 522.3873896598816 and batch: 1700, loss is 3.6396414756774904 and perplexity is 38.078182323307786
At time: 523.3564605712891 and batch: 1750, loss is 3.630114870071411 and perplexity is 37.71714893994203
At time: 524.3250501155853 and batch: 1800, loss is 3.5793415975570677 and perplexity is 35.849929393904596
At time: 525.2912201881409 and batch: 1850, loss is 3.6037362480163573 and perplexity is 36.73523029038396
At time: 526.256454706192 and batch: 1900, loss is 3.6927993488311768 and perplexity is 40.15710350211821
At time: 527.2212011814117 and batch: 1950, loss is 3.618356170654297 and perplexity is 37.27624165105985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249578715479651 and perplexity of 70.07588424197696
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 530.4031555652618 and batch: 50, loss is 3.784853596687317 and perplexity is 44.02922406260961
At time: 531.3702795505524 and batch: 100, loss is 3.7854500341415407 and perplexity is 44.05549257390424
At time: 532.3365502357483 and batch: 150, loss is 3.7650099897384646 and perplexity is 43.16413705614649
At time: 533.3019258975983 and batch: 200, loss is 3.788817300796509 and perplexity is 44.2040892068551
At time: 534.267106294632 and batch: 250, loss is 3.7807778215408323 and perplexity is 43.85013605459884
At time: 535.2360434532166 and batch: 300, loss is 3.790488247871399 and perplexity is 44.27801364512527
At time: 536.2287442684174 and batch: 350, loss is 3.800178894996643 and perplexity is 44.709182026888726
At time: 537.1955013275146 and batch: 400, loss is 3.7754346704483033 and perplexity is 43.61646298342651
At time: 538.1856620311737 and batch: 450, loss is 3.8124221563339233 and perplexity is 45.25993284002719
At time: 539.1781575679779 and batch: 500, loss is 3.8144871854782103 and perplexity is 45.35349248886355
At time: 540.1607513427734 and batch: 550, loss is 3.7882380533218383 and perplexity is 44.178491514227055
At time: 541.1276061534882 and batch: 600, loss is 3.762338557243347 and perplexity is 43.04898086227499
At time: 542.0932011604309 and batch: 650, loss is 3.8070070552825928 and perplexity is 45.015508119680455
At time: 543.0579500198364 and batch: 700, loss is 3.8234267616271973 and perplexity is 45.760751136231534
At time: 544.0208895206451 and batch: 750, loss is 3.777627944946289 and perplexity is 43.71223084359255
At time: 544.9896302223206 and batch: 800, loss is 3.7437043809890747 and perplexity is 42.25422635997585
At time: 545.9561381340027 and batch: 850, loss is 3.740881609916687 and perplexity is 42.135120535445424
At time: 546.9239377975464 and batch: 900, loss is 3.687549934387207 and perplexity is 39.94685454772284
At time: 547.8902018070221 and batch: 950, loss is 3.8072571897506715 and perplexity is 45.02676945822501
At time: 548.8567991256714 and batch: 1000, loss is 3.768655848503113 and perplexity is 43.321794627534594
At time: 549.8285613059998 and batch: 1050, loss is 3.712682480812073 and perplexity is 40.96354319655159
At time: 550.7971687316895 and batch: 1100, loss is 3.7288337564468383 and perplexity is 41.63052850619405
At time: 551.7642323970795 and batch: 1150, loss is 3.7067104053497313 and perplexity is 40.719634869772975
At time: 552.7326927185059 and batch: 1200, loss is 3.764394006729126 and perplexity is 43.1375568684196
At time: 553.7008244991302 and batch: 1250, loss is 3.7444103956222534 and perplexity is 42.284068995528735
At time: 554.6689124107361 and batch: 1300, loss is 3.732522487640381 and perplexity is 41.78437591171366
At time: 555.6501896381378 and batch: 1350, loss is 3.6187759685516356 and perplexity is 37.29189342398648
At time: 556.6259789466858 and batch: 1400, loss is 3.647442536354065 and perplexity is 38.37639420621817
At time: 557.592119216919 and batch: 1450, loss is 3.560688133239746 and perplexity is 35.18740243715577
At time: 558.5582349300385 and batch: 1500, loss is 3.57180636882782 and perplexity is 35.580807198033106
At time: 559.55331158638 and batch: 1550, loss is 3.562898030281067 and perplexity is 35.26524895841068
At time: 560.5160012245178 and batch: 1600, loss is 3.6595282220840453 and perplexity is 38.843013272071474
At time: 561.479740858078 and batch: 1650, loss is 3.594935803413391 and perplexity is 36.413362299277466
At time: 562.4555611610413 and batch: 1700, loss is 3.61938455581665 and perplexity is 37.314595702870804
At time: 563.4103772640228 and batch: 1750, loss is 3.6156445789337157 and perplexity is 37.175300620105695
At time: 564.374626159668 and batch: 1800, loss is 3.5668493843078615 and perplexity is 35.40487010652029
At time: 565.3437116146088 and batch: 1850, loss is 3.588596806526184 and perplexity is 36.183268162504596
At time: 566.3364541530609 and batch: 1900, loss is 3.677536869049072 and perplexity is 39.548859981171134
At time: 567.3066439628601 and batch: 1950, loss is 3.609168381690979 and perplexity is 36.93532394760474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.236279012990552 and perplexity of 69.15006602996867
finished 14 epochs...
Completing Train Step...
At time: 570.5071325302124 and batch: 50, loss is 3.7957033777236937 and perplexity is 44.509532411371964
At time: 571.4928250312805 and batch: 100, loss is 3.784028477668762 and perplexity is 43.992909696360755
At time: 572.4715542793274 and batch: 150, loss is 3.7553904390335084 and perplexity is 42.75090817571555
At time: 573.44216132164 and batch: 200, loss is 3.7691918992996216 and perplexity is 43.34502353543192
At time: 574.4093244075775 and batch: 250, loss is 3.7567714071273803 and perplexity is 42.8099865992103
At time: 575.4003839492798 and batch: 300, loss is 3.7610196828842164 and perplexity is 42.99224208910999
At time: 576.3658421039581 and batch: 350, loss is 3.7700837898254393 and perplexity is 43.383699796195984
At time: 577.3479654788971 and batch: 400, loss is 3.745210299491882 and perplexity is 42.31790571720001
At time: 578.3168587684631 and batch: 450, loss is 3.782861294746399 and perplexity is 43.941591877924665
At time: 579.2851550579071 and batch: 500, loss is 3.7856121587753297 and perplexity is 44.062635633521495
At time: 580.2586052417755 and batch: 550, loss is 3.760772771835327 and perplexity is 42.98162813992625
At time: 581.2386631965637 and batch: 600, loss is 3.7384331226348877 and perplexity is 42.032079427596734
At time: 582.2213664054871 and batch: 650, loss is 3.7844914484024046 and perplexity is 44.013281841527565
At time: 583.1976454257965 and batch: 700, loss is 3.8030661725997925 and perplexity is 44.8384563824793
At time: 584.1658976078033 and batch: 750, loss is 3.760083627700806 and perplexity is 42.95201780706694
At time: 585.1279017925262 and batch: 800, loss is 3.727661509513855 and perplexity is 41.58175583922395
At time: 586.0953235626221 and batch: 850, loss is 3.725644974708557 and perplexity is 41.49798926879693
At time: 587.0602974891663 and batch: 900, loss is 3.6736760568618774 and perplexity is 39.39646363669815
At time: 588.0308427810669 and batch: 950, loss is 3.7935940408706665 and perplexity is 44.41574576293634
At time: 589.0431520938873 and batch: 1000, loss is 3.755625729560852 and perplexity is 42.76096824291748
At time: 590.008092880249 and batch: 1050, loss is 3.7000403785705567 and perplexity is 40.44893759737399
At time: 590.9742698669434 and batch: 1100, loss is 3.7181207084655763 and perplexity is 41.186919103951325
At time: 591.9394931793213 and batch: 1150, loss is 3.6965130949020386 and perplexity is 40.30651405216663
At time: 592.9241013526917 and batch: 1200, loss is 3.7546270847320558 and perplexity is 42.7182865385862
At time: 593.9014945030212 and batch: 1250, loss is 3.7362729120254516 and perplexity is 41.9413792846572
At time: 594.8774175643921 and batch: 1300, loss is 3.7260064840316773 and perplexity is 41.51299389080031
At time: 595.8447642326355 and batch: 1350, loss is 3.613035340309143 and perplexity is 37.07842782692461
At time: 596.8346118927002 and batch: 1400, loss is 3.6426238489151 and perplexity is 38.19191518783112
At time: 597.8156177997589 and batch: 1450, loss is 3.5575177478790283 and perplexity is 35.07602146518284
At time: 598.7839252948761 and batch: 1500, loss is 3.5708081197738646 and perplexity is 35.5453064131692
At time: 599.7538061141968 and batch: 1550, loss is 3.563498616218567 and perplexity is 35.2864351324398
At time: 600.7396891117096 and batch: 1600, loss is 3.6614654541015623 and perplexity is 38.91833413447632
At time: 601.707507610321 and batch: 1650, loss is 3.597681770324707 and perplexity is 36.51348959748884
At time: 602.6901025772095 and batch: 1700, loss is 3.624151372909546 and perplexity is 37.49289217119581
At time: 603.665833234787 and batch: 1750, loss is 3.6211685514450074 and perplexity is 37.38122419327524
At time: 604.6358201503754 and batch: 1800, loss is 3.57341091632843 and perplexity is 35.637944120486864
At time: 605.6034860610962 and batch: 1850, loss is 3.5954138708114622 and perplexity is 36.43077450241861
At time: 606.5705664157867 and batch: 1900, loss is 3.684535002708435 and perplexity is 39.82659888287815
At time: 607.5376980304718 and batch: 1950, loss is 3.6154918098449706 and perplexity is 37.16962181708996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2351593727289245 and perplexity of 69.07268615884045
finished 15 epochs...
Completing Train Step...
At time: 610.7394502162933 and batch: 50, loss is 3.792532229423523 and perplexity is 44.36860964491528
At time: 611.7271013259888 and batch: 100, loss is 3.778776960372925 and perplexity is 43.762485737459635
At time: 612.6929285526276 and batch: 150, loss is 3.7489963817596434 and perplexity is 42.4784284740764
At time: 613.6851556301117 and batch: 200, loss is 3.7612028026580813 and perplexity is 43.00011553962953
At time: 614.6525993347168 and batch: 250, loss is 3.7476214361190796 and perplexity is 42.42006307784638
At time: 615.641087770462 and batch: 300, loss is 3.7509382867813112 and perplexity is 42.56099769248536
At time: 616.622236251831 and batch: 350, loss is 3.7597831535339354 and perplexity is 42.93911377406233
At time: 617.5888576507568 and batch: 400, loss is 3.734807906150818 and perplexity is 41.87997990382324
At time: 618.5540668964386 and batch: 450, loss is 3.772627925872803 and perplexity is 43.494214353139554
At time: 619.5207631587982 and batch: 500, loss is 3.775240240097046 and perplexity is 43.60798344357471
At time: 620.485221862793 and batch: 550, loss is 3.7504810667037964 and perplexity is 42.54154239783588
At time: 621.4543151855469 and batch: 600, loss is 3.729339361190796 and perplexity is 41.65158242093131
At time: 622.4250495433807 and batch: 650, loss is 3.7756050968170167 and perplexity is 43.62389701228818
At time: 623.40638256073 and batch: 700, loss is 3.794708104133606 and perplexity is 44.46525528683709
At time: 624.390193939209 and batch: 750, loss is 3.752597002983093 and perplexity is 42.631652891183585
At time: 625.3900556564331 and batch: 800, loss is 3.7207139110565186 and perplexity is 41.29386373389949
At time: 626.3643906116486 and batch: 850, loss is 3.718449273109436 and perplexity is 41.20045389276317
At time: 627.3325526714325 and batch: 900, loss is 3.6672042846679687 and perplexity is 39.14232195935127
At time: 628.318176984787 and batch: 950, loss is 3.7873981285095213 and perplexity is 44.1414004820532
At time: 629.28595495224 and batch: 1000, loss is 3.749562373161316 and perplexity is 42.50247770453612
At time: 630.2535388469696 and batch: 1050, loss is 3.6944525384902955 and perplexity is 40.223545716026145
At time: 631.2204673290253 and batch: 1100, loss is 3.712968120574951 and perplexity is 40.97524568458529
At time: 632.2067248821259 and batch: 1150, loss is 3.6916123533248903 and perplexity is 40.10946547936852
At time: 633.1708381175995 and batch: 1200, loss is 3.750156626701355 and perplexity is 42.52774245846369
At time: 634.132887840271 and batch: 1250, loss is 3.7324617290496827 and perplexity is 41.781837229044235
At time: 635.091269493103 and batch: 1300, loss is 3.722779088020325 and perplexity is 41.379230988932946
At time: 636.0753078460693 and batch: 1350, loss is 3.6101695680618286 and perplexity is 36.972321608230324
At time: 637.0539140701294 and batch: 1400, loss is 3.64022057056427 and perplexity is 38.100239589997834
At time: 638.0394127368927 and batch: 1450, loss is 3.5557217264175414 and perplexity is 35.01308071623471
At time: 639.0198409557343 and batch: 1500, loss is 3.569713554382324 and perplexity is 35.50642103611392
At time: 639.9874355792999 and batch: 1550, loss is 3.5630034017562866 and perplexity is 35.26896510550192
At time: 640.953850030899 and batch: 1600, loss is 3.6614077949523924 and perplexity is 38.916090201135276
At time: 641.9189150333405 and batch: 1650, loss is 3.597738308906555 and perplexity is 36.51555407676984
At time: 642.8974044322968 and batch: 1700, loss is 3.625007495880127 and perplexity is 37.52500444148182
At time: 643.874659538269 and batch: 1750, loss is 3.622201976776123 and perplexity is 37.41987486511655
At time: 644.8414695262909 and batch: 1800, loss is 3.574843530654907 and perplexity is 35.68903613864028
At time: 645.8113524913788 and batch: 1850, loss is 3.596826682090759 and perplexity is 36.482280687241236
At time: 646.7796523571014 and batch: 1900, loss is 3.6860502338409424 and perplexity is 39.88699112795765
At time: 647.7459185123444 and batch: 1950, loss is 3.616639008522034 and perplexity is 37.21228722623673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.235017714389535 and perplexity of 69.06290212983303
finished 16 epochs...
Completing Train Step...
At time: 650.9145722389221 and batch: 50, loss is 3.7880550241470337 and perplexity is 44.170406301318586
At time: 651.8998727798462 and batch: 100, loss is 3.7734547805786134 and perplexity is 43.53019262130332
At time: 652.866837978363 and batch: 150, loss is 3.7432959985733034 and perplexity is 42.23697399995842
At time: 653.8320305347443 and batch: 200, loss is 3.7549341106414795 and perplexity is 42.7314041729835
At time: 654.799024105072 and batch: 250, loss is 3.740939917564392 and perplexity is 42.13757740683612
At time: 655.7808198928833 and batch: 300, loss is 3.7438777542114257 and perplexity is 42.261552746439094
At time: 656.7598116397858 and batch: 350, loss is 3.7526644134521483 and perplexity is 42.63452680776653
At time: 657.7282454967499 and batch: 400, loss is 3.7277320194244385 and perplexity is 41.584687868477424
At time: 658.6947650909424 and batch: 450, loss is 3.7657572555541994 and perplexity is 43.196404194797566
At time: 659.6622540950775 and batch: 500, loss is 3.768222074508667 and perplexity is 43.30300683475499
At time: 660.6291129589081 and batch: 550, loss is 3.7434701251983644 and perplexity is 42.244329222045245
At time: 661.5951406955719 and batch: 600, loss is 3.7230734252929687 and perplexity is 41.39141223153524
At time: 662.5798516273499 and batch: 650, loss is 3.7694201612472535 and perplexity is 43.35491868422427
At time: 663.5481793880463 and batch: 700, loss is 3.7888417863845825 and perplexity is 44.20517158322585
At time: 664.5153243541718 and batch: 750, loss is 3.747206883430481 and perplexity is 42.402481371170616
At time: 665.4826829433441 and batch: 800, loss is 3.7156092977523802 and perplexity is 41.083611612139244
At time: 666.4488997459412 and batch: 850, loss is 3.7131811380386353 and perplexity is 40.98397505721626
At time: 667.4216542243958 and batch: 900, loss is 3.6624067401885987 and perplexity is 38.95498466754007
At time: 668.4120457172394 and batch: 950, loss is 3.782834587097168 and perplexity is 43.94041831697374
At time: 669.3792152404785 and batch: 1000, loss is 3.745115485191345 and perplexity is 42.31389356477696
At time: 670.3525247573853 and batch: 1050, loss is 3.69035147190094 and perplexity is 40.05892406947942
At time: 671.3265056610107 and batch: 1100, loss is 3.7090673303604125 and perplexity is 40.81572118526272
At time: 672.2933776378632 and batch: 1150, loss is 3.687843189239502 and perplexity is 39.958570874503756
At time: 673.260621547699 and batch: 1200, loss is 3.746681880950928 and perplexity is 42.3802258059362
At time: 674.2263326644897 and batch: 1250, loss is 3.7293773460388184 and perplexity is 41.653164580008315
At time: 675.1939713954926 and batch: 1300, loss is 3.719977855682373 and perplexity is 41.263480346878325
At time: 676.1653952598572 and batch: 1350, loss is 3.6075456714630127 and perplexity is 36.875437222203715
At time: 677.1568970680237 and batch: 1400, loss is 3.637965931892395 and perplexity is 38.01443408296635
At time: 678.1230676174164 and batch: 1450, loss is 3.55376380443573 and perplexity is 34.944594902667504
At time: 679.0893456935883 and batch: 1500, loss is 3.568121337890625 and perplexity is 35.44993211021272
At time: 680.0574636459351 and batch: 1550, loss is 3.561733112335205 and perplexity is 35.22419175581279
At time: 681.0263104438782 and batch: 1600, loss is 3.6603972625732424 and perplexity is 38.876784095308295
At time: 681.9984259605408 and batch: 1650, loss is 3.5967797565460207 and perplexity is 36.480568776513174
At time: 682.9681038856506 and batch: 1700, loss is 3.624560203552246 and perplexity is 37.50822354815365
At time: 683.9606988430023 and batch: 1750, loss is 3.621826658248901 and perplexity is 37.40583312802022
At time: 684.926726102829 and batch: 1800, loss is 3.5747433614730837 and perplexity is 35.68546137613371
At time: 685.8953514099121 and batch: 1850, loss is 3.596725125312805 and perplexity is 36.478575852490955
At time: 686.8629174232483 and batch: 1900, loss is 3.686060862541199 and perplexity is 39.88741507708348
At time: 687.8298764228821 and batch: 1950, loss is 3.616418161392212 and perplexity is 37.204069906827804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.235197697129361 and perplexity of 69.07533337885025
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 691.0523331165314 and batch: 50, loss is 3.7880219411849976 and perplexity is 44.1689450376154
At time: 692.0221197605133 and batch: 100, loss is 3.7793610286712647 and perplexity is 43.788053483963694
At time: 692.9905309677124 and batch: 150, loss is 3.751869144439697 and perplexity is 42.600634368325494
At time: 693.9786536693573 and batch: 200, loss is 3.76372887134552 and perplexity is 43.10887409300597
At time: 694.9780251979828 and batch: 250, loss is 3.7504268074035645 and perplexity is 42.53923418613613
At time: 695.9450364112854 and batch: 300, loss is 3.7508021116256716 and perplexity is 42.5552023366011
At time: 696.9312403202057 and batch: 350, loss is 3.7623379707336424 and perplexity is 43.04895561363734
At time: 697.8983318805695 and batch: 400, loss is 3.740902919769287 and perplexity is 42.13601843822038
At time: 698.8629374504089 and batch: 450, loss is 3.7847099685668946 and perplexity is 44.02290068203234
At time: 699.8179271221161 and batch: 500, loss is 3.788590841293335 and perplexity is 44.1940799041687
At time: 700.7726151943207 and batch: 550, loss is 3.765906500816345 and perplexity is 43.202851534570854
At time: 701.7222208976746 and batch: 600, loss is 3.7436735010147095 and perplexity is 42.25292157069507
At time: 702.693249464035 and batch: 650, loss is 3.786521897315979 and perplexity is 44.102739350542485
At time: 703.6805129051208 and batch: 700, loss is 3.8044315719604493 and perplexity is 44.89972059769894
At time: 704.6753990650177 and batch: 750, loss is 3.758237771987915 and perplexity is 42.87280770731543
At time: 705.6432816982269 and batch: 800, loss is 3.725726866722107 and perplexity is 41.501387761849244
At time: 706.6085422039032 and batch: 850, loss is 3.721277289390564 and perplexity is 41.317134356523
At time: 707.5727844238281 and batch: 900, loss is 3.670257635116577 and perplexity is 39.26201983244794
At time: 708.5444481372833 and batch: 950, loss is 3.7912645959854125 and perplexity is 44.31240214450705
At time: 709.5082757472992 and batch: 1000, loss is 3.750637378692627 and perplexity is 42.548192670681146
At time: 710.4905099868774 and batch: 1050, loss is 3.6959996461868285 and perplexity is 40.28582403639749
At time: 711.4557576179504 and batch: 1100, loss is 3.7071630811691283 and perplexity is 40.73807183652288
At time: 712.4218363761902 and batch: 1150, loss is 3.687545208930969 and perplexity is 39.94666578105584
At time: 713.3865213394165 and batch: 1200, loss is 3.747760367393494 and perplexity is 42.425956960683365
At time: 714.3548004627228 and batch: 1250, loss is 3.7296258306503294 and perplexity is 41.66351603646273
At time: 715.322674036026 and batch: 1300, loss is 3.717429141998291 and perplexity is 41.15844545865222
At time: 716.2903568744659 and batch: 1350, loss is 3.60222442150116 and perplexity is 36.67973495541861
At time: 717.2569658756256 and batch: 1400, loss is 3.634182734489441 and perplexity is 37.8708896742935
At time: 718.2351920604706 and batch: 1450, loss is 3.5474080657958984 and perplexity is 34.723200498352476
At time: 719.2198655605316 and batch: 1500, loss is 3.56087513923645 and perplexity is 35.193983307731905
At time: 720.1873276233673 and batch: 1550, loss is 3.5558746576309206 and perplexity is 35.01843571861586
At time: 721.1532447338104 and batch: 1600, loss is 3.6558505392074583 and perplexity is 38.70042334826118
At time: 722.1196653842926 and batch: 1650, loss is 3.5871314668655394 and perplexity is 36.13028621237108
At time: 723.0868694782257 and batch: 1700, loss is 3.6102522897720335 and perplexity is 36.975380148406096
At time: 724.0541369915009 and batch: 1750, loss is 3.607355947494507 and perplexity is 36.868441731540635
At time: 725.0239379405975 and batch: 1800, loss is 3.561000094413757 and perplexity is 35.198381252923554
At time: 725.992134809494 and batch: 1850, loss is 3.5854785442352295 and perplexity is 36.07061497420696
At time: 726.958890914917 and batch: 1900, loss is 3.6748073434829713 and perplexity is 39.441057548420645
At time: 727.9266138076782 and batch: 1950, loss is 3.606690707206726 and perplexity is 36.84392351491006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.232312579487646 and perplexity of 68.876330127847
finished 18 epochs...
Completing Train Step...
At time: 731.1275396347046 and batch: 50, loss is 3.78919554233551 and perplexity is 44.220812192051305
At time: 732.0958762168884 and batch: 100, loss is 3.776152515411377 and perplexity is 43.647784082187755
At time: 733.0627646446228 and batch: 150, loss is 3.7482843351364137 and perplexity is 42.44819261846826
At time: 734.0284948348999 and batch: 200, loss is 3.7579887294769287 and perplexity is 42.86213188505293
At time: 735.0140199661255 and batch: 250, loss is 3.743229823112488 and perplexity is 42.234179041220386
At time: 735.9810655117035 and batch: 300, loss is 3.742862133979797 and perplexity is 42.218652847140156
At time: 736.9481375217438 and batch: 350, loss is 3.7535240125656126 and perplexity is 42.67119116528042
At time: 737.9373497962952 and batch: 400, loss is 3.7316934156417845 and perplexity is 41.749748012160865
At time: 738.914707660675 and batch: 450, loss is 3.7747141313552857 and perplexity is 43.585046936352036
At time: 739.8807988166809 and batch: 500, loss is 3.77856107711792 and perplexity is 43.753039169306156
At time: 740.8479125499725 and batch: 550, loss is 3.7555062866210935 and perplexity is 42.75586105217864
At time: 741.8144006729126 and batch: 600, loss is 3.7338355875015257 and perplexity is 41.83927900865704
At time: 742.7936625480652 and batch: 650, loss is 3.7771543073654175 and perplexity is 43.691531990585574
At time: 743.7846629619598 and batch: 700, loss is 3.7961281061172487 and perplexity is 44.5284408887703
At time: 744.7811934947968 and batch: 750, loss is 3.7507547760009765 and perplexity is 42.55318800718962
At time: 745.7454564571381 and batch: 800, loss is 3.7190231895446777 and perplexity is 41.22410629699418
At time: 746.7132620811462 and batch: 850, loss is 3.715461001396179 and perplexity is 41.07751951396672
At time: 747.6814470291138 and batch: 900, loss is 3.6643240451812744 and perplexity is 39.02974490031461
At time: 748.6732881069183 and batch: 950, loss is 3.785388774871826 and perplexity is 44.052793849264035
At time: 749.6683225631714 and batch: 1000, loss is 3.746004033088684 and perplexity is 42.35150819465753
At time: 750.6349363327026 and batch: 1050, loss is 3.6914075803756714 and perplexity is 40.10125298670758
At time: 751.6021082401276 and batch: 1100, loss is 3.7043906545639036 and perplexity is 40.62528494125561
At time: 752.5701236724854 and batch: 1150, loss is 3.6847914981842043 and perplexity is 39.83681553551346
At time: 753.5364983081818 and batch: 1200, loss is 3.7447501039505005 and perplexity is 42.29843568602273
At time: 754.5164570808411 and batch: 1250, loss is 3.727255539894104 and perplexity is 41.564878335725965
At time: 755.4906375408173 and batch: 1300, loss is 3.7154681491851806 and perplexity is 41.07781312845826
At time: 756.459180355072 and batch: 1350, loss is 3.601048803329468 and perplexity is 36.63663892967118
At time: 757.4262080192566 and batch: 1400, loss is 3.6332508373260497 and perplexity is 37.835614338676386
At time: 758.3943910598755 and batch: 1450, loss is 3.5475554180145266 and perplexity is 34.7283174159691
At time: 759.3611307144165 and batch: 1500, loss is 3.562190976142883 and perplexity is 35.24032333112292
At time: 760.3295240402222 and batch: 1550, loss is 3.558060736656189 and perplexity is 35.0950725229731
At time: 761.2972383499146 and batch: 1600, loss is 3.6584779453277587 and perplexity is 38.80223877408955
At time: 762.266987323761 and batch: 1650, loss is 3.5899711990356447 and perplexity is 36.23303236517512
At time: 763.2556641101837 and batch: 1700, loss is 3.6136615324020385 and perplexity is 37.1016533162968
At time: 764.2220091819763 and batch: 1750, loss is 3.611339473724365 and perplexity is 37.015601048131515
At time: 765.2150046825409 and batch: 1800, loss is 3.5654340982437134 and perplexity is 35.35479752912415
At time: 766.2145030498505 and batch: 1850, loss is 3.5900075960159303 and perplexity is 36.234351162139774
At time: 767.1826992034912 and batch: 1900, loss is 3.6790864276885986 and perplexity is 39.61019076438894
At time: 768.1507341861725 and batch: 1950, loss is 3.6102072763442994 and perplexity is 36.973715797263196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.231615643168604 and perplexity of 68.82834443528688
finished 19 epochs...
Completing Train Step...
At time: 771.3322281837463 and batch: 50, loss is 3.7891720962524413 and perplexity is 44.219775399369695
At time: 772.2979233264923 and batch: 100, loss is 3.774622473716736 and perplexity is 43.58105221694984
At time: 773.3047268390656 and batch: 150, loss is 3.7463801860809327 and perplexity is 42.36744183774709
At time: 774.2731325626373 and batch: 200, loss is 3.755115060806274 and perplexity is 42.739137127229085
At time: 775.227662563324 and batch: 250, loss is 3.739711894989014 and perplexity is 42.0858632700714
At time: 776.1923699378967 and batch: 300, loss is 3.7388527154922486 and perplexity is 42.049719488467545
At time: 777.159734249115 and batch: 350, loss is 3.749077248573303 and perplexity is 42.48186370813271
At time: 778.1303672790527 and batch: 400, loss is 3.726991310119629 and perplexity is 41.55389710814477
At time: 779.0998585224152 and batch: 450, loss is 3.769688301086426 and perplexity is 43.36654542387398
At time: 780.0674824714661 and batch: 500, loss is 3.773536639213562 and perplexity is 43.53375608929868
At time: 781.0344290733337 and batch: 550, loss is 3.750265164375305 and perplexity is 42.53235857121503
At time: 781.9998581409454 and batch: 600, loss is 3.7290178298950196 and perplexity is 41.63819228645338
At time: 782.9706304073334 and batch: 650, loss is 3.7726058769226074 and perplexity is 43.493255361945906
At time: 783.9735631942749 and batch: 700, loss is 3.7920765399932863 and perplexity is 44.34839594440042
At time: 784.9411480426788 and batch: 750, loss is 3.7471660470962522 and perplexity is 42.40074984462405
At time: 785.9062280654907 and batch: 800, loss is 3.715794310569763 and perplexity is 41.091213310055956
At time: 786.8738770484924 and batch: 850, loss is 3.712431426048279 and perplexity is 40.953260394717425
At time: 787.8590533733368 and batch: 900, loss is 3.661448907852173 and perplexity is 38.917690187341385
At time: 788.8355445861816 and batch: 950, loss is 3.7825957202911376 and perplexity is 43.929923663056854
At time: 789.8024413585663 and batch: 1000, loss is 3.743700375556946 and perplexity is 42.25405711387897
At time: 790.768652677536 and batch: 1050, loss is 3.689148049354553 and perplexity is 40.01074525262193
At time: 791.7344481945038 and batch: 1100, loss is 3.703005828857422 and perplexity is 40.56906493877276
At time: 792.7003066539764 and batch: 1150, loss is 3.68344096660614 and perplexity is 39.783050971705755
At time: 793.6967377662659 and batch: 1200, loss is 3.7433322858810425 and perplexity is 42.23850669384043
At time: 794.6661305427551 and batch: 1250, loss is 3.726203293800354 and perplexity is 41.52116485756171
At time: 795.6567115783691 and batch: 1300, loss is 3.714713931083679 and perplexity is 41.04684317874312
At time: 796.6328465938568 and batch: 1350, loss is 3.600573401451111 and perplexity is 36.619225942118774
At time: 797.6029105186462 and batch: 1400, loss is 3.63288113117218 and perplexity is 37.82162886463714
At time: 798.5718958377838 and batch: 1450, loss is 3.5476495170593263 and perplexity is 34.73158547122347
At time: 799.5709795951843 and batch: 1500, loss is 3.5628532648086546 and perplexity is 35.26367032821564
At time: 800.5393579006195 and batch: 1550, loss is 3.5591234827041625 and perplexity is 35.13238949832202
At time: 801.5059654712677 and batch: 1600, loss is 3.6597095584869384 and perplexity is 38.850057563049646
At time: 802.4721927642822 and batch: 1650, loss is 3.591392674446106 and perplexity is 36.28457335317359
At time: 803.4402527809143 and batch: 1700, loss is 3.6153976488113404 and perplexity is 37.16612205185336
At time: 804.4334137439728 and batch: 1750, loss is 3.6132792949676515 and perplexity is 37.08747438555335
At time: 805.3977391719818 and batch: 1800, loss is 3.5675408315658568 and perplexity is 35.42935917234815
At time: 806.3651874065399 and batch: 1850, loss is 3.592118806838989 and perplexity is 36.31093032541484
At time: 807.3320798873901 and batch: 1900, loss is 3.681013970375061 and perplexity is 39.68661472947143
At time: 808.2991981506348 and batch: 1950, loss is 3.6117630863189696 and perplexity is 37.031284644582314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.231347088481105 and perplexity of 68.80986274253964
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f080feb7b38>
ELAPSED
5013.363657712936


RESULTS SO FAR:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -69.81217672005135, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -72.57294337642149, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.725269039096756, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9500194842048229, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -73.33241846048472, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.22182319704545472, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9619850400189879, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.80986274253964, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.60562622183787, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07897425315755363, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -69.66068945620029, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.2848608319542799, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.2155760985892745, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.50990892978844, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.6158813161034504, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07280350159811178, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -69.81217672005135, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.1663981392059215, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.7845663968622133, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -72.57294337642149, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.725269039096756, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9500194842048229, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -73.33241846048472, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.22182319704545472, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.9619850400189879, 'wordvec_source': 'glove', 'data': 'wikitext'}}, {'best_accuracy': -68.80986274253964, 'params': {'wordvec_dim': 300, 'num_layers': 3, 'seq_len': 35, 'dropout': 0.60562622183787, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'tie_weights': 'FALSE', 'rnn_dropout': 0.07897425315755363, 'wordvec_source': 'glove', 'data': 'wikitext'}}]
