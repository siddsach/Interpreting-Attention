TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8222522735595703 and batch: 50, loss is 7.6627116203308105 and perplexity is 2127.5186367333085
At time: 2.973332166671753 and batch: 100, loss is 6.874430122375489 and perplexity is 967.2240091760384
At time: 4.125900745391846 and batch: 150, loss is 6.596070165634155 and perplexity is 732.2120557341882
At time: 5.281767845153809 and batch: 200, loss is 6.512919330596924 and perplexity is 673.7905666130047
At time: 6.43194580078125 and batch: 250, loss is 6.466594944000244 and perplexity is 643.2895564845024
At time: 7.586452007293701 and batch: 300, loss is 6.40200590133667 and perplexity is 603.0534912519445
At time: 8.740983486175537 and batch: 350, loss is 6.3391823387146 and perplexity is 566.3330534009393
At time: 9.901408433914185 and batch: 400, loss is 6.291559190750122 and perplexity is 539.9946276702972
At time: 11.063354253768921 and batch: 450, loss is 6.200738620758057 and perplexity is 493.1131302088569
At time: 12.223016738891602 and batch: 500, loss is 6.176130609512329 and perplexity is 481.12668293413145
At time: 13.382707118988037 and batch: 550, loss is 6.124245347976685 and perplexity is 456.79985822523724
At time: 14.545727014541626 and batch: 600, loss is 6.164501523971557 and perplexity is 475.56402657463224
At time: 15.70630931854248 and batch: 650, loss is 6.237028036117554 and perplexity is 511.33657665857953
At time: 16.868096351623535 and batch: 700, loss is 6.129837865829468 and perplexity is 459.3616764174952
At time: 18.031159162521362 and batch: 750, loss is 6.057210521697998 and perplexity is 427.1821579596174
At time: 19.197874307632446 and batch: 800, loss is 6.063309440612793 and perplexity is 429.79546838649344
At time: 20.35944628715515 and batch: 850, loss is 6.09514705657959 and perplexity is 443.69928927956914
At time: 21.520970344543457 and batch: 900, loss is 6.0741222476959225 and perplexity is 434.4679798292716
At time: 22.68965244293213 and batch: 950, loss is 6.094111957550049 and perplexity is 443.240254190201
At time: 23.855974674224854 and batch: 1000, loss is 6.073235607147216 and perplexity is 434.08293362525416
At time: 25.013888359069824 and batch: 1050, loss is 5.96644811630249 and perplexity is 390.1175548130104
At time: 26.17989420890808 and batch: 1100, loss is 6.0400774288177494 and perplexity is 419.9255479666557
At time: 27.3398334980011 and batch: 1150, loss is 5.948674249649048 and perplexity is 383.2449150333068
At time: 28.50258469581604 and batch: 1200, loss is 6.034278602600097 and perplexity is 417.4975193514553
At time: 29.66665029525757 and batch: 1250, loss is 5.958553466796875 and perplexity is 387.04983865675206
At time: 30.83116865158081 and batch: 1300, loss is 5.966334609985352 and perplexity is 390.07327651909316
At time: 31.99319863319397 and batch: 1350, loss is 5.947037906646728 and perplexity is 382.6183077104895
At time: 33.15737175941467 and batch: 1400, loss is 5.967427091598511 and perplexity is 390.49965726563016
At time: 34.3233802318573 and batch: 1450, loss is 5.943885011672974 and perplexity is 381.41385212998097
At time: 35.486786127090454 and batch: 1500, loss is 5.917705116271972 and perplexity is 371.5580521956809
At time: 36.65203666687012 and batch: 1550, loss is 5.882043733596801 and perplexity is 358.54125624393566
At time: 37.814802408218384 and batch: 1600, loss is 5.888622150421143 and perplexity is 360.9076651543581
At time: 38.99664568901062 and batch: 1650, loss is 5.880583000183106 and perplexity is 358.0179053818553
At time: 40.23280310630798 and batch: 1700, loss is 5.890066051483155 and perplexity is 361.4291565157253
At time: 41.51342701911926 and batch: 1750, loss is 5.903183469772339 and perplexity is 366.2014053068886
At time: 42.798773765563965 and batch: 1800, loss is 5.9118273735046385 and perplexity is 369.38053525301564
At time: 44.075220823287964 and batch: 1850, loss is 5.861697368621826 and perplexity is 351.319957691557
At time: 45.35819888114929 and batch: 1900, loss is 5.840047721862793 and perplexity is 343.79574684695643
At time: 46.64428973197937 and batch: 1950, loss is 5.776804227828979 and perplexity is 322.7261813164367
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.219514784702035 and perplexity of 184.84447294182183
finished 1 epochs...
Completing Train Step...
At time: 50.20263457298279 and batch: 50, loss is 5.480286531448364 and perplexity is 239.9154408453848
At time: 51.30213809013367 and batch: 100, loss is 5.375486736297607 and perplexity is 216.04500366811666
At time: 52.426729679107666 and batch: 150, loss is 5.255223741531372 and perplexity is 191.56434195907931
At time: 53.542983293533325 and batch: 200, loss is 5.198063621520996 and perplexity is 180.92156983361272
At time: 54.68757700920105 and batch: 250, loss is 5.19252064704895 and perplexity is 179.92150043072473
At time: 55.82029747962952 and batch: 300, loss is 5.177316513061523 and perplexity is 177.20664067503267
At time: 56.93435573577881 and batch: 350, loss is 5.153258399963379 and perplexity is 172.9942574408601
At time: 58.03248739242554 and batch: 400, loss is 5.109317560195922 and perplexity is 165.5573333987712
At time: 59.15511918067932 and batch: 450, loss is 5.054180078506469 and perplexity is 156.6760156326429
At time: 60.25059771537781 and batch: 500, loss is 5.032045164108276 and perplexity is 153.24610585846887
At time: 61.33536410331726 and batch: 550, loss is 4.977208690643311 and perplexity is 145.06888384913273
At time: 62.42066955566406 and batch: 600, loss is 4.9689257526397705 and perplexity is 143.87224994165547
At time: 63.53440880775452 and batch: 650, loss is 5.037823944091797 and perplexity is 154.13424509661812
At time: 64.64758658409119 and batch: 700, loss is 5.0122060966491695 and perplexity is 150.2358055364204
At time: 65.73472881317139 and batch: 750, loss is 4.9648308849334715 and perplexity is 143.28431668752035
At time: 66.81952548027039 and batch: 800, loss is 4.939009704589844 and perplexity is 139.63190423606304
At time: 67.90360379219055 and batch: 850, loss is 4.932190971374512 and perplexity is 138.68303026844674
At time: 68.99336266517639 and batch: 900, loss is 4.933682222366333 and perplexity is 138.88999575527237
At time: 70.10585355758667 and batch: 950, loss is 4.991564846038818 and perplexity is 147.16653637461638
At time: 71.20474600791931 and batch: 1000, loss is 4.947502155303955 and perplexity is 140.82277083156973
At time: 72.32283997535706 and batch: 1050, loss is 4.8570435428619385 and perplexity is 128.64331090576707
At time: 73.44689750671387 and batch: 1100, loss is 4.925105295181274 and perplexity is 137.7038404303593
At time: 74.53110027313232 and batch: 1150, loss is 4.836964101791382 and perplexity is 126.08598587605358
At time: 75.63661003112793 and batch: 1200, loss is 4.923905830383301 and perplexity is 137.53876853996914
At time: 76.71929550170898 and batch: 1250, loss is 4.870063714981079 and perplexity is 130.329220555744
At time: 77.82094597816467 and batch: 1300, loss is 4.893322076797485 and perplexity is 133.39599049860578
At time: 78.91573882102966 and batch: 1350, loss is 4.799595460891724 and perplexity is 121.46127174414974
At time: 79.99971675872803 and batch: 1400, loss is 4.813521280288696 and perplexity is 123.16455173685121
At time: 81.08026051521301 and batch: 1450, loss is 4.755113725662231 and perplexity is 116.17686470401377
At time: 82.16462302207947 and batch: 1500, loss is 4.740316896438599 and perplexity is 114.47047121766514
At time: 83.25175309181213 and batch: 1550, loss is 4.73203932762146 and perplexity is 113.52684486860608
At time: 84.3352267742157 and batch: 1600, loss is 4.7885173892974855 and perplexity is 120.12314072048335
At time: 85.41931319236755 and batch: 1650, loss is 4.750989370346069 and perplexity is 115.69869677948255
At time: 86.51369762420654 and batch: 1700, loss is 4.778818378448486 and perplexity is 118.96369689368451
At time: 87.64582085609436 and batch: 1750, loss is 4.780196418762207 and perplexity is 119.12774667151615
At time: 88.77679514884949 and batch: 1800, loss is 4.737586278915405 and perplexity is 114.15832251638213
At time: 89.89058351516724 and batch: 1850, loss is 4.746866436004638 and perplexity is 115.22266065643967
At time: 91.02109551429749 and batch: 1900, loss is 4.8207193374633786 and perplexity is 124.05429559410882
At time: 92.14611506462097 and batch: 1950, loss is 4.735932140350342 and perplexity is 113.96964492504623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.573039494004361 and perplexity of 96.83800143036063
finished 2 epochs...
Completing Train Step...
At time: 95.69991421699524 and batch: 50, loss is 4.7006415748596195 and perplexity is 110.01773442682916
At time: 96.78220200538635 and batch: 100, loss is 4.635746746063233 and perplexity is 103.10488242025953
At time: 97.87885761260986 and batch: 150, loss is 4.583129682540894 and perplexity is 97.82006137519079
At time: 98.95040845870972 and batch: 200, loss is 4.57164927482605 and perplexity is 96.70346892008848
At time: 100.03307747840881 and batch: 250, loss is 4.575385627746582 and perplexity is 97.06546305640805
At time: 101.11598825454712 and batch: 300, loss is 4.597478923797607 and perplexity is 99.23382398820455
At time: 102.23137426376343 and batch: 350, loss is 4.601235942840576 and perplexity is 99.60734858478189
At time: 103.31582283973694 and batch: 400, loss is 4.564807767868042 and perplexity is 96.04412947407546
At time: 104.44488191604614 and batch: 450, loss is 4.558844966888428 and perplexity is 95.47314148043378
At time: 105.55474519729614 and batch: 500, loss is 4.558404912948609 and perplexity is 95.43113739108874
At time: 106.70241451263428 and batch: 550, loss is 4.5146267700195315 and perplexity is 91.34346753889045
At time: 107.79709267616272 and batch: 600, loss is 4.4996671390533445 and perplexity is 89.98717309921614
At time: 108.89614033699036 and batch: 650, loss is 4.5685184288024905 and perplexity is 96.40117870793561
At time: 110.01522469520569 and batch: 700, loss is 4.580521154403686 and perplexity is 97.56522750786657
At time: 111.10701012611389 and batch: 750, loss is 4.549921827316284 and perplexity is 94.62501093473992
At time: 112.19478678703308 and batch: 800, loss is 4.524354267120361 and perplexity is 92.23634655291247
At time: 113.3169527053833 and batch: 850, loss is 4.524452381134033 and perplexity is 92.24539667504384
At time: 114.41443014144897 and batch: 900, loss is 4.505756607055664 and perplexity is 90.53681893731607
At time: 115.53209018707275 and batch: 950, loss is 4.579465131759644 and perplexity is 97.46225080078419
At time: 116.62131142616272 and batch: 1000, loss is 4.557063522338868 and perplexity is 95.30321277713492
At time: 117.74484515190125 and batch: 1050, loss is 4.485887269973755 and perplexity is 88.75566612448328
At time: 118.82723116874695 and batch: 1100, loss is 4.536289796829224 and perplexity is 93.3438322744161
At time: 119.91662549972534 and batch: 1150, loss is 4.47537691116333 and perplexity is 87.8276974116523
At time: 121.01132845878601 and batch: 1200, loss is 4.56304931640625 and perplexity is 95.8753889387067
At time: 122.12556505203247 and batch: 1250, loss is 4.529317636489868 and perplexity is 92.69528761498461
At time: 123.23588466644287 and batch: 1300, loss is 4.531996831893921 and perplexity is 92.94396938831723
At time: 124.34381985664368 and batch: 1350, loss is 4.428589630126953 and perplexity is 83.81312600502906
At time: 125.47773790359497 and batch: 1400, loss is 4.450523309707641 and perplexity is 85.67176513987795
At time: 126.64024186134338 and batch: 1450, loss is 4.390257368087768 and perplexity is 80.66117592187943
At time: 127.75609922409058 and batch: 1500, loss is 4.390674629211426 and perplexity is 80.69483971758832
At time: 128.86543989181519 and batch: 1550, loss is 4.393891191482544 and perplexity is 80.95481758785209
At time: 129.95184183120728 and batch: 1600, loss is 4.46531662940979 and perplexity is 86.94855565159217
At time: 131.03586506843567 and batch: 1650, loss is 4.422428979873657 and perplexity is 83.29836989333171
At time: 132.11977910995483 and batch: 1700, loss is 4.449925422668457 and perplexity is 85.62055841132184
At time: 133.204514503479 and batch: 1750, loss is 4.448777170181274 and perplexity is 85.52230081523251
At time: 134.28832864761353 and batch: 1800, loss is 4.4078867149353025 and perplexity is 82.09578825299057
At time: 135.4076669216156 and batch: 1850, loss is 4.436867961883545 and perplexity is 84.50983869821171
At time: 136.48990201950073 and batch: 1900, loss is 4.519886674880982 and perplexity is 91.82519128776666
At time: 137.58667755126953 and batch: 1950, loss is 4.446504678726196 and perplexity is 85.32817277810734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.424046999909157 and perplexity of 83.43325742067667
finished 3 epochs...
Completing Train Step...
At time: 141.11555862426758 and batch: 50, loss is 4.4167224788665775 and perplexity is 82.82438135593262
At time: 142.18813753128052 and batch: 100, loss is 4.360239391326904 and perplexity is 78.2758707449005
At time: 143.24770045280457 and batch: 150, loss is 4.323638744354248 and perplexity is 75.46271885905232
At time: 144.30248498916626 and batch: 200, loss is 4.327300968170166 and perplexity is 75.73958689218085
At time: 145.39318919181824 and batch: 250, loss is 4.323739595413208 and perplexity is 75.47032973793739
At time: 146.45753049850464 and batch: 300, loss is 4.340431509017944 and perplexity is 76.74064647576483
At time: 147.5426104068756 and batch: 350, loss is 4.352487115859986 and perplexity is 77.67140066901553
At time: 148.62009382247925 and batch: 400, loss is 4.315050935745239 and perplexity is 74.81743422865884
At time: 149.73012733459473 and batch: 450, loss is 4.32748836517334 and perplexity is 75.7537815937668
At time: 150.8908121585846 and batch: 500, loss is 4.332723569869995 and perplexity is 76.1514080667879
At time: 152.01200342178345 and batch: 550, loss is 4.293895483016968 and perplexity is 73.25126248340419
At time: 153.10214400291443 and batch: 600, loss is 4.277812404632568 and perplexity is 72.08257988541408
At time: 154.19139289855957 and batch: 650, loss is 4.340493030548096 and perplexity is 76.74536782299165
At time: 155.26510071754456 and batch: 700, loss is 4.366254558563233 and perplexity is 78.74813213967947
At time: 156.33013200759888 and batch: 750, loss is 4.3364740657806395 and perplexity is 76.43754986273893
At time: 157.42002201080322 and batch: 800, loss is 4.3099801731109615 and perplexity is 74.43901303166264
At time: 158.49674654006958 and batch: 850, loss is 4.308610067367554 and perplexity is 74.33709354855249
At time: 159.5625238418579 and batch: 900, loss is 4.2907940292358395 and perplexity is 73.02442901698487
At time: 160.62588953971863 and batch: 950, loss is 4.371926727294922 and perplexity is 79.19607403249263
At time: 161.69041419029236 and batch: 1000, loss is 4.35412181854248 and perplexity is 77.79847415142585
At time: 162.76587200164795 and batch: 1050, loss is 4.289145984649658 and perplexity is 72.90418061666375
At time: 163.88195061683655 and batch: 1100, loss is 4.3298204898834225 and perplexity is 75.93065502498854
At time: 164.96171855926514 and batch: 1150, loss is 4.280847516059875 and perplexity is 72.30169089229209
At time: 166.04006934165955 and batch: 1200, loss is 4.366268854141236 and perplexity is 78.74925789779174
At time: 167.11863899230957 and batch: 1250, loss is 4.3368699264526365 and perplexity is 76.46781447248256
At time: 168.20066142082214 and batch: 1300, loss is 4.3344424533843995 and perplexity is 76.2824160281692
At time: 169.28731656074524 and batch: 1350, loss is 4.2329733228683475 and perplexity is 68.92185474545461
At time: 170.37339186668396 and batch: 1400, loss is 4.255960960388183 and perplexity is 70.5245559407442
At time: 171.47566771507263 and batch: 1450, loss is 4.194535450935364 and perplexity is 66.32291417200811
At time: 172.5644884109497 and batch: 1500, loss is 4.20004448890686 and perplexity is 66.68929790889152
At time: 173.64880752563477 and batch: 1550, loss is 4.207500324249268 and perplexity is 67.18838056025979
At time: 174.73913526535034 and batch: 1600, loss is 4.284263443946839 and perplexity is 72.54909056363744
At time: 175.82634830474854 and batch: 1650, loss is 4.239949750900268 and perplexity is 69.40436424431095
At time: 176.91028475761414 and batch: 1700, loss is 4.265988163948059 and perplexity is 71.23527733825975
At time: 178.00220441818237 and batch: 1750, loss is 4.266196217536926 and perplexity is 71.2500996352265
At time: 179.08631825447083 and batch: 1800, loss is 4.225081915855408 and perplexity is 68.3801047339142
At time: 180.16906547546387 and batch: 1850, loss is 4.252887763977051 and perplexity is 70.30815282349094
At time: 181.29156708717346 and batch: 1900, loss is 4.33444450378418 and perplexity is 76.28257243777863
At time: 182.38360285758972 and batch: 1950, loss is 4.269163007736206 and perplexity is 71.4617976089812
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36570675872093 and perplexity of 78.70500573870801
finished 4 epochs...
Completing Train Step...
At time: 185.83148431777954 and batch: 50, loss is 4.247293815612793 and perplexity is 69.91595064910639
At time: 186.87889742851257 and batch: 100, loss is 4.1934597253799435 and perplexity is 66.25160727852341
At time: 187.94129610061646 and batch: 150, loss is 4.164551277160644 and perplexity is 64.36379445799678
At time: 188.98135447502136 and batch: 200, loss is 4.174306759834289 and perplexity is 64.99476705666751
At time: 190.0258584022522 and batch: 250, loss is 4.166065235137939 and perplexity is 64.46131233842546
At time: 191.10886096954346 and batch: 300, loss is 4.178126459121704 and perplexity is 65.24350226650883
At time: 192.20031642913818 and batch: 350, loss is 4.197670001983642 and perplexity is 66.53113289777725
At time: 193.30086255073547 and batch: 400, loss is 4.159141883850098 and perplexity is 64.01656537485839
At time: 194.36113691329956 and batch: 450, loss is 4.176372652053833 and perplexity is 65.12917803173023
At time: 195.42184948921204 and batch: 500, loss is 4.187827639579773 and perplexity is 65.87952133546847
At time: 196.4864685535431 and batch: 550, loss is 4.150988512039184 and perplexity is 63.496736573784936
At time: 197.59424710273743 and batch: 600, loss is 4.137899932861328 and perplexity is 62.67106969984181
At time: 198.67507243156433 and batch: 650, loss is 4.197665734291077 and perplexity is 66.53084896396187
At time: 199.73958539962769 and batch: 700, loss is 4.225983247756958 and perplexity is 68.44176568806033
At time: 200.8036675453186 and batch: 750, loss is 4.194322276115417 and perplexity is 66.3087773035869
At time: 201.8684377670288 and batch: 800, loss is 4.171556029319763 and perplexity is 64.8162296343835
At time: 202.93464994430542 and batch: 850, loss is 4.166049156188965 and perplexity is 64.4602758766062
At time: 204.01176857948303 and batch: 900, loss is 4.146929569244385 and perplexity is 63.239529300304646
At time: 205.0896270275116 and batch: 950, loss is 4.2363219785690305 and perplexity is 69.15303716638529
At time: 206.16730332374573 and batch: 1000, loss is 4.2120100688934325 and perplexity is 67.4920672596816
At time: 207.24229836463928 and batch: 1050, loss is 4.155496544837952 and perplexity is 63.783628117258836
At time: 208.3263750076294 and batch: 1100, loss is 4.1933259010314945 and perplexity is 66.24274179356777
At time: 209.40398621559143 and batch: 1150, loss is 4.149887347221375 and perplexity is 63.42685468422462
At time: 210.48139357566833 and batch: 1200, loss is 4.233428139686584 and perplexity is 68.95320869374791
At time: 211.5580620765686 and batch: 1250, loss is 4.209873113632202 and perplexity is 67.34799372563494
At time: 212.6349527835846 and batch: 1300, loss is 4.20572256565094 and perplexity is 67.0690419480631
At time: 213.71359848976135 and batch: 1350, loss is 4.101483206748963 and perplexity is 60.429851123354595
At time: 214.79074120521545 and batch: 1400, loss is 4.130533218383789 and perplexity is 62.21108618717761
At time: 215.88717579841614 and batch: 1450, loss is 4.060846223831176 and perplexity is 58.02339108599731
At time: 216.96719551086426 and batch: 1500, loss is 4.073578462600708 and perplexity is 58.76688186266013
At time: 218.04488325119019 and batch: 1550, loss is 4.0790586137771605 and perplexity is 59.089817318795205
At time: 219.12223291397095 and batch: 1600, loss is 4.156634330749512 and perplexity is 63.85624153214553
At time: 220.199538230896 and batch: 1650, loss is 4.113241114616394 and perplexity is 61.144573330153754
At time: 221.28570079803467 and batch: 1700, loss is 4.141095652580261 and perplexity is 62.87166923230837
At time: 222.3787682056427 and batch: 1750, loss is 4.142691793441773 and perplexity is 62.97210140322513
At time: 223.49132752418518 and batch: 1800, loss is 4.097697148323059 and perplexity is 60.201492738205566
At time: 224.5782196521759 and batch: 1850, loss is 4.1319804811477665 and perplexity is 62.301187159887405
At time: 225.66337370872498 and batch: 1900, loss is 4.207604022026062 and perplexity is 67.19534820720878
At time: 226.77411150932312 and batch: 1950, loss is 4.1434397315979 and perplexity is 63.01921825868666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339179176507995 and perplexity of 76.6446018218225
finished 5 epochs...
Completing Train Step...
At time: 230.20761513710022 and batch: 50, loss is 4.127118968963623 and perplexity is 61.99904421031626
At time: 231.26230025291443 and batch: 100, loss is 4.074097800254822 and perplexity is 58.797409643653175
At time: 232.30553817749023 and batch: 150, loss is 4.050643725395203 and perplexity is 57.43441714096615
At time: 233.3905885219574 and batch: 200, loss is 4.0613952732086185 and perplexity is 58.05525754007802
At time: 234.47909235954285 and batch: 250, loss is 4.054949598312378 and perplexity is 57.682255639865765
At time: 235.5812509059906 and batch: 300, loss is 4.0634228706359865 and perplexity is 58.173089648582696
At time: 236.64058327674866 and batch: 350, loss is 4.085308923721313 and perplexity is 59.4603036125351
At time: 237.6842863559723 and batch: 400, loss is 4.044739007949829 and perplexity is 57.096282413562015
At time: 238.74644422531128 and batch: 450, loss is 4.067890882492065 and perplexity is 58.43358922707448
At time: 239.81170058250427 and batch: 500, loss is 4.085418543815613 and perplexity is 59.46682201389155
At time: 240.876118183136 and batch: 550, loss is 4.047569417953492 and perplexity is 57.25811722386913
At time: 241.94058394432068 and batch: 600, loss is 4.03704797744751 and perplexity is 56.6588375212629
At time: 243.00673127174377 and batch: 650, loss is 4.091969223022461 and perplexity is 59.8576487811683
At time: 244.09559512138367 and batch: 700, loss is 4.120906367301941 and perplexity is 61.61506284190094
At time: 245.2047483921051 and batch: 750, loss is 4.094374160766602 and perplexity is 60.001775938952555
At time: 246.27847838401794 and batch: 800, loss is 4.074336929321289 and perplexity is 58.81147149456359
At time: 247.35506892204285 and batch: 850, loss is 4.066540579795838 and perplexity is 58.3547394415106
At time: 248.4453420639038 and batch: 900, loss is 4.04398404121399 and perplexity is 57.05319288722586
At time: 249.5219542980194 and batch: 950, loss is 4.133427834510803 and perplexity is 62.39142427939099
At time: 250.60336565971375 and batch: 1000, loss is 4.1104357624053955 and perplexity is 60.97328164526371
At time: 251.68301701545715 and batch: 1050, loss is 4.064318656921387 and perplexity is 58.22522365144547
At time: 252.7545087337494 and batch: 1100, loss is 4.092369117736816 and perplexity is 59.88159032525907
At time: 253.84028029441833 and batch: 1150, loss is 4.054329252243042 and perplexity is 57.64648377592388
At time: 254.9307999610901 and batch: 1200, loss is 4.139325265884399 and perplexity is 62.76046053579776
At time: 256.0246841907501 and batch: 1250, loss is 4.114046831130981 and perplexity is 61.19385837488423
At time: 257.11796021461487 and batch: 1300, loss is 4.106516547203064 and perplexity is 60.73478190409375
At time: 258.2204170227051 and batch: 1350, loss is 4.001500859260559 and perplexity is 54.680155696316675
At time: 259.29286193847656 and batch: 1400, loss is 4.036316075325012 and perplexity is 56.617383969644536
At time: 260.38193559646606 and batch: 1450, loss is 3.9606428432464598 and perplexity is 52.491058628063534
At time: 261.4667909145355 and batch: 1500, loss is 3.9793160152435303 and perplexity is 53.480441907589196
At time: 262.5484735965729 and batch: 1550, loss is 3.982511086463928 and perplexity is 53.65158899635523
At time: 263.62032294273376 and batch: 1600, loss is 4.062333545684814 and perplexity is 58.10975475294569
At time: 264.715806722641 and batch: 1650, loss is 4.020689811706543 and perplexity is 55.739542357122474
At time: 265.8243510723114 and batch: 1700, loss is 4.048503632545471 and perplexity is 57.31163358648015
At time: 266.9274628162384 and batch: 1750, loss is 4.050152955055236 and perplexity is 57.40623694810714
At time: 268.01295161247253 and batch: 1800, loss is 4.008576016426087 and perplexity is 55.06839821055956
At time: 269.0765609741211 and batch: 1850, loss is 4.037598166465759 and perplexity is 56.69001916856727
At time: 270.1410782337189 and batch: 1900, loss is 4.11361141204834 and perplexity is 61.16721920123053
At time: 271.2054982185364 and batch: 1950, loss is 4.054592580795288 and perplexity is 57.66166573987325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328511082848837 and perplexity of 75.83129595608634
finished 6 epochs...
Completing Train Step...
At time: 274.59635972976685 and batch: 50, loss is 4.03618501663208 and perplexity is 56.609964255523884
At time: 275.6275680065155 and batch: 100, loss is 3.986089835166931 and perplexity is 53.84393853092157
At time: 276.65988850593567 and batch: 150, loss is 3.963350872993469 and perplexity is 52.63339861975957
At time: 277.699743270874 and batch: 200, loss is 3.976234483718872 and perplexity is 53.31589390004464
At time: 278.74175810813904 and batch: 250, loss is 3.9671691036224366 and perplexity is 52.8347492313902
At time: 279.78243041038513 and batch: 300, loss is 3.97264208316803 and perplexity is 53.124705471749664
At time: 280.822881937027 and batch: 350, loss is 4.002455878257751 and perplexity is 54.732401227542596
At time: 281.8706114292145 and batch: 400, loss is 3.9593004322052003 and perplexity is 52.420641326450145
At time: 282.92087268829346 and batch: 450, loss is 3.982596573829651 and perplexity is 53.65617572541627
At time: 283.97080183029175 and batch: 500, loss is 4.005368905067444 and perplexity is 54.892070627389295
At time: 285.0204563140869 and batch: 550, loss is 3.9644533252716063 and perplexity is 52.6914564270747
At time: 286.0743188858032 and batch: 600, loss is 3.9549221754074098 and perplexity is 52.19163199387736
At time: 287.1333270072937 and batch: 650, loss is 4.012706475257874 and perplexity is 55.29632636217326
At time: 288.1920063495636 and batch: 700, loss is 4.040367007255554 and perplexity is 56.84720231314643
At time: 289.25120997428894 and batch: 750, loss is 4.018488554954529 and perplexity is 55.61698025796872
At time: 290.3109037876129 and batch: 800, loss is 3.9909588289260864 and perplexity is 54.10674361054794
At time: 291.37448167800903 and batch: 850, loss is 3.9865632104873656 and perplexity is 53.86943295631693
At time: 292.4387836456299 and batch: 900, loss is 3.9629247283935545 and perplexity is 52.61097395957588
At time: 293.50367641448975 and batch: 950, loss is 4.056076531410217 and perplexity is 57.74729632427098
At time: 294.56803727149963 and batch: 1000, loss is 4.03335747718811 and perplexity is 56.45012343327813
At time: 295.6557538509369 and batch: 1050, loss is 3.984231557846069 and perplexity is 53.743974470323316
At time: 296.72039341926575 and batch: 1100, loss is 4.012104597091675 and perplexity is 55.26305472440543
At time: 297.84778475761414 and batch: 1150, loss is 3.981946349143982 and perplexity is 53.62129849566771
At time: 298.9250841140747 and batch: 1200, loss is 4.060515360832214 and perplexity is 58.004196468382126
At time: 299.9880986213684 and batch: 1250, loss is 4.0350538349151615 and perplexity is 56.54596430357475
At time: 301.05160427093506 and batch: 1300, loss is 4.0322445154190065 and perplexity is 56.387331552998404
At time: 302.1409969329834 and batch: 1350, loss is 3.9307650661468507 and perplexity is 50.945939776848945
At time: 303.2049968242645 and batch: 1400, loss is 3.962026309967041 and perplexity is 52.56372851739956
At time: 304.278249502182 and batch: 1450, loss is 3.883193769454956 and perplexity is 48.57911808090082
At time: 305.34372544288635 and batch: 1500, loss is 3.906535472869873 and perplexity is 49.72637482226169
At time: 306.40671968460083 and batch: 1550, loss is 3.9092799186706544 and perplexity is 49.863033603363746
At time: 307.4937686920166 and batch: 1600, loss is 3.9932155799865723 and perplexity is 54.22898694607768
At time: 308.5583927631378 and batch: 1650, loss is 3.9486162662506104 and perplexity is 51.86355181284876
At time: 309.62201261520386 and batch: 1700, loss is 3.9785080337524414 and perplexity is 53.437248152619745
At time: 310.685063123703 and batch: 1750, loss is 3.978771457672119 and perplexity is 53.451326656210775
At time: 311.7487211227417 and batch: 1800, loss is 3.9325690412521364 and perplexity is 51.03792793114531
At time: 312.8121991157532 and batch: 1850, loss is 3.963925628662109 and perplexity is 52.66365865920765
At time: 313.90019726753235 and batch: 1900, loss is 4.042150950431823 and perplexity is 56.94870500239894
At time: 314.96257853507996 and batch: 1950, loss is 3.980398864746094 and perplexity is 53.538384543421124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3309757676235465 and perplexity of 76.01842671110738
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 318.358295917511 and batch: 50, loss is 3.9989375686645507 and perplexity is 54.540174050895004
At time: 319.4087743759155 and batch: 100, loss is 3.9817983865737916 and perplexity is 53.61336513745985
At time: 320.45004057884216 and batch: 150, loss is 3.95165976524353 and perplexity is 52.02163892751899
At time: 321.48242378234863 and batch: 200, loss is 3.96724479675293 and perplexity is 52.8387486103192
At time: 322.5195801258087 and batch: 250, loss is 3.9524982833862303 and perplexity is 52.065278309222414
At time: 323.5609004497528 and batch: 300, loss is 3.9575807571411135 and perplexity is 52.33057232362333
At time: 324.62465596199036 and batch: 350, loss is 3.985491404533386 and perplexity is 53.81172630802575
At time: 325.67075634002686 and batch: 400, loss is 3.939569926261902 and perplexity is 51.396492265056374
At time: 326.7205092906952 and batch: 450, loss is 3.953670835494995 and perplexity is 52.12636336680516
At time: 327.78969979286194 and batch: 500, loss is 3.9626808309555055 and perplexity is 52.59814384249382
At time: 328.8617968559265 and batch: 550, loss is 3.920265140533447 and perplexity is 50.4138097505996
At time: 329.9309513568878 and batch: 600, loss is 3.8954129791259766 and perplexity is 49.176357979040844
At time: 331.02022790908813 and batch: 650, loss is 3.9436610651016237 and perplexity is 51.60719316021296
At time: 332.09481167793274 and batch: 700, loss is 3.9746227073669433 and perplexity is 53.23002981851097
At time: 333.16202545166016 and batch: 750, loss is 3.931470847129822 and perplexity is 50.9819091440576
At time: 334.25297117233276 and batch: 800, loss is 3.9078563928604124 and perplexity is 49.79210278595506
At time: 335.31320095062256 and batch: 850, loss is 3.899198684692383 and perplexity is 49.362878023402466
At time: 336.3963623046875 and batch: 900, loss is 3.8677946758270263 and perplexity is 47.836774075043095
At time: 337.49734234809875 and batch: 950, loss is 3.966780786514282 and perplexity is 52.81423657732361
At time: 338.57041907310486 and batch: 1000, loss is 3.932175316810608 and perplexity is 51.01783700687736
At time: 339.67539501190186 and batch: 1050, loss is 3.8691482543945312 and perplexity is 47.901568749618114
At time: 340.7618248462677 and batch: 1100, loss is 3.889054546356201 and perplexity is 48.86466540125394
At time: 341.8516480922699 and batch: 1150, loss is 3.8608837890625 and perplexity is 47.5073192698953
At time: 342.9147369861603 and batch: 1200, loss is 3.9319186067581176 and perplexity is 51.004741896156574
At time: 344.0006248950958 and batch: 1250, loss is 3.8989734554290774 and perplexity is 49.351761310702116
At time: 345.0881233215332 and batch: 1300, loss is 3.885531907081604 and perplexity is 48.69283563659628
At time: 346.1896724700928 and batch: 1350, loss is 3.7834324550628664 and perplexity is 43.96669674021581
At time: 347.2974317073822 and batch: 1400, loss is 3.802996792793274 and perplexity is 44.835345606964644
At time: 348.39377522468567 and batch: 1450, loss is 3.7188193893432615 and perplexity is 41.215705671881274
At time: 349.48111844062805 and batch: 1500, loss is 3.7348798656463624 and perplexity is 41.88299367448394
At time: 350.54428696632385 and batch: 1550, loss is 3.7318639278411867 and perplexity is 41.756867460478055
At time: 351.63332891464233 and batch: 1600, loss is 3.8114371347427367 and perplexity is 45.215372778878205
At time: 352.72567105293274 and batch: 1650, loss is 3.7615572881698607 and perplexity is 43.01536115960923
At time: 353.8301463127136 and batch: 1700, loss is 3.780223879814148 and perplexity is 43.82585236101396
At time: 354.9215261936188 and batch: 1750, loss is 3.7662304401397706 and perplexity is 43.21684890409382
At time: 355.9865503311157 and batch: 1800, loss is 3.7148006343841553 and perplexity is 41.05040222980934
At time: 357.06763648986816 and batch: 1850, loss is 3.7324843883514403 and perplexity is 41.78278398702839
At time: 358.14992690086365 and batch: 1900, loss is 3.8016884899139405 and perplexity is 44.776725749836494
At time: 359.23140573501587 and batch: 1950, loss is 3.7415061092376707 and perplexity is 42.161442107655915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.271669183775436 and perplexity of 71.6411180643253
finished 8 epochs...
Completing Train Step...
At time: 362.6941261291504 and batch: 50, loss is 3.9108570432662964 and perplexity is 49.94173586539637
At time: 363.7575469017029 and batch: 100, loss is 3.8794252634048463 and perplexity is 48.3963918991156
At time: 364.7878007888794 and batch: 150, loss is 3.844110550880432 and perplexity is 46.717113370660634
At time: 365.80121874809265 and batch: 200, loss is 3.859673080444336 and perplexity is 47.44983655346104
At time: 366.81599378585815 and batch: 250, loss is 3.843662157058716 and perplexity is 46.69617040135674
At time: 367.8403377532959 and batch: 300, loss is 3.8493733835220336 and perplexity is 46.96362582775262
At time: 368.86848044395447 and batch: 350, loss is 3.8812270641326903 and perplexity is 48.48367115956938
At time: 369.9039821624756 and batch: 400, loss is 3.8347505140304565 and perplexity is 46.28187954787207
At time: 370.9443371295929 and batch: 450, loss is 3.8572281551361085 and perplexity is 47.33396695118085
At time: 371.98642468452454 and batch: 500, loss is 3.87116042137146 and perplexity is 47.99805174179104
At time: 373.0481631755829 and batch: 550, loss is 3.828898100852966 and perplexity is 46.01180991650177
At time: 374.1363844871521 and batch: 600, loss is 3.8119285440444948 and perplexity is 45.23759749391281
At time: 375.2180826663971 and batch: 650, loss is 3.85957914352417 and perplexity is 47.445379471298395
At time: 376.29498529434204 and batch: 700, loss is 3.8935642433166504 and perplexity is 49.085527871379156
At time: 377.34315848350525 and batch: 750, loss is 3.8539870023727416 and perplexity is 47.180798688352006
At time: 378.40492963790894 and batch: 800, loss is 3.831940522193909 and perplexity is 46.15201039524629
At time: 379.4536111354828 and batch: 850, loss is 3.8263184595108033 and perplexity is 45.893268911788084
At time: 380.49975514411926 and batch: 900, loss is 3.794017906188965 and perplexity is 44.43457604762199
At time: 381.5496497154236 and batch: 950, loss is 3.896290464401245 and perplexity is 49.21952844701374
At time: 382.5977792739868 and batch: 1000, loss is 3.8627619838714597 and perplexity is 47.59663111660422
At time: 383.65340209007263 and batch: 1050, loss is 3.8049405670166014 and perplexity is 44.92258015071199
At time: 384.7167136669159 and batch: 1100, loss is 3.8242421913146973 and perplexity is 45.79808102911329
At time: 385.79972100257874 and batch: 1150, loss is 3.8010071754455566 and perplexity is 44.74622910881734
At time: 386.870778799057 and batch: 1200, loss is 3.874513683319092 and perplexity is 48.159271937963545
At time: 387.9353594779968 and batch: 1250, loss is 3.844448094367981 and perplexity is 46.73288508970676
At time: 389.02444314956665 and batch: 1300, loss is 3.8339644479751587 and perplexity is 46.2455132284213
At time: 390.11154413223267 and batch: 1350, loss is 3.731931610107422 and perplexity is 41.75969375554261
At time: 391.1847002506256 and batch: 1400, loss is 3.7566534900665283 and perplexity is 42.80493886902801
At time: 392.26445269584656 and batch: 1450, loss is 3.674587721824646 and perplexity is 39.432396389079656
At time: 393.33723497390747 and batch: 1500, loss is 3.692003207206726 and perplexity is 40.12514548374516
At time: 394.4024612903595 and batch: 1550, loss is 3.6933891105651857 and perplexity is 40.18079361018535
At time: 395.4671597480774 and batch: 1600, loss is 3.7783969259262085 and perplexity is 43.745857645229506
At time: 396.53313851356506 and batch: 1650, loss is 3.728813118934631 and perplexity is 41.62966936451911
At time: 397.59818410873413 and batch: 1700, loss is 3.752499532699585 and perplexity is 42.62749777439337
At time: 398.6614830493927 and batch: 1750, loss is 3.7412541341781616 and perplexity is 42.15081981410458
At time: 399.7435927391052 and batch: 1800, loss is 3.693758511543274 and perplexity is 40.19563917645984
At time: 400.8117210865021 and batch: 1850, loss is 3.7163929748535156 and perplexity is 41.11582051683372
At time: 401.8717646598816 and batch: 1900, loss is 3.788103380203247 and perplexity is 44.172542259611504
At time: 402.93337202072144 and batch: 1950, loss is 3.7299619197845457 and perplexity is 41.677521044829575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273306061500727 and perplexity of 71.75848184357268
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 406.3250222206116 and batch: 50, loss is 3.88649600982666 and perplexity is 48.739803170224135
At time: 407.36355209350586 and batch: 100, loss is 3.887529582977295 and perplexity is 48.79020536483871
At time: 408.38534355163574 and batch: 150, loss is 3.861728720664978 and perplexity is 47.54747666803377
At time: 409.42842411994934 and batch: 200, loss is 3.8794561290740965 and perplexity is 48.39788570919447
At time: 410.49733567237854 and batch: 250, loss is 3.870433893203735 and perplexity is 47.96319246985954
At time: 411.52806067466736 and batch: 300, loss is 3.871357789039612 and perplexity is 48.007525940258624
At time: 412.57164001464844 and batch: 350, loss is 3.905429654121399 and perplexity is 49.67141685706412
At time: 413.6334753036499 and batch: 400, loss is 3.867993640899658 and perplexity is 47.84629286919378
At time: 414.67400336265564 and batch: 450, loss is 3.8964935827255247 and perplexity is 49.22952685054884
At time: 415.75263381004333 and batch: 500, loss is 3.906159300804138 and perplexity is 49.70767266695804
At time: 416.81502389907837 and batch: 550, loss is 3.8637410497665403 and perplexity is 47.643254174649954
At time: 417.8582971096039 and batch: 600, loss is 3.8335644435882568 and perplexity is 46.22701851948436
At time: 418.9165246486664 and batch: 650, loss is 3.866405463218689 and perplexity is 47.77036476436206
At time: 419.96579909324646 and batch: 700, loss is 3.89853404045105 and perplexity is 49.330080171447676
At time: 421.0480787754059 and batch: 750, loss is 3.8526228570938112 and perplexity is 47.11648110380379
At time: 422.13704085350037 and batch: 800, loss is 3.825844717025757 and perplexity is 45.87153246967149
At time: 423.1986401081085 and batch: 850, loss is 3.8205649185180666 and perplexity is 45.62997826090378
At time: 424.27330327033997 and batch: 900, loss is 3.7847140264511108 and perplexity is 44.023079322228625
At time: 425.3273181915283 and batch: 950, loss is 3.9007118463516237 and perplexity is 49.4376285783914
At time: 426.37606859207153 and batch: 1000, loss is 3.865823359489441 and perplexity is 47.742565548683714
At time: 427.459655046463 and batch: 1050, loss is 3.7995020723342896 and perplexity is 44.678932077358105
At time: 428.5185670852661 and batch: 1100, loss is 3.8162089824676513 and perplexity is 45.431649261430834
At time: 429.57763481140137 and batch: 1150, loss is 3.7879197549819947 and perplexity is 44.16443181143001
At time: 430.6771230697632 and batch: 1200, loss is 3.852537784576416 and perplexity is 47.1124729566395
At time: 431.76123666763306 and batch: 1250, loss is 3.8184907388687135 and perplexity is 45.535431575896304
At time: 432.8218789100647 and batch: 1300, loss is 3.8093671131134035 and perplexity is 45.121872786138425
At time: 433.89421486854553 and batch: 1350, loss is 3.7038258361816405 and perplexity is 40.60234551245149
At time: 434.9533805847168 and batch: 1400, loss is 3.727612590789795 and perplexity is 41.57972176253674
At time: 436.0124545097351 and batch: 1450, loss is 3.6367511320114136 and perplexity is 37.96828219129871
At time: 437.09755635261536 and batch: 1500, loss is 3.6551938915252684 and perplexity is 38.67501914668765
At time: 438.15845823287964 and batch: 1550, loss is 3.6531691551208496 and perplexity is 38.596791649235556
At time: 439.26050901412964 and batch: 1600, loss is 3.7342787408828735 and perplexity is 41.85782433553153
At time: 440.3638496398926 and batch: 1650, loss is 3.6815113830566406 and perplexity is 39.7063602653597
At time: 441.46397852897644 and batch: 1700, loss is 3.704196653366089 and perplexity is 40.617404351762055
At time: 442.5589859485626 and batch: 1750, loss is 3.694821443557739 and perplexity is 40.238387123238184
At time: 443.6292796134949 and batch: 1800, loss is 3.6449238538742064 and perplexity is 38.27985787770408
At time: 444.73145031929016 and batch: 1850, loss is 3.6581718730926513 and perplexity is 38.790364303456386
At time: 445.8354170322418 and batch: 1900, loss is 3.7281422233581543 and perplexity is 41.60174957017275
At time: 446.89723563194275 and batch: 1950, loss is 3.6746203899383545 and perplexity is 39.433684592130156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249570198946221 and perplexity of 70.07528744090749
finished 10 epochs...
Completing Train Step...
At time: 450.3323743343353 and batch: 50, loss is 3.875417866706848 and perplexity is 48.20283644379952
At time: 451.4211587905884 and batch: 100, loss is 3.8583628225326536 and perplexity is 47.387705742291004
At time: 452.45307898521423 and batch: 150, loss is 3.823633966445923 and perplexity is 45.770233966785625
At time: 453.5002017021179 and batch: 200, loss is 3.8363523864746094 and perplexity is 46.356076626645596
At time: 454.56076550483704 and batch: 250, loss is 3.82433744430542 and perplexity is 45.80244364107329
At time: 455.5881667137146 and batch: 300, loss is 3.821578288078308 and perplexity is 45.676241728943936
At time: 456.635379076004 and batch: 350, loss is 3.8577607917785643 and perplexity is 47.359185471969745
At time: 457.6941239833832 and batch: 400, loss is 3.8191301155090334 and perplexity is 45.564555176635665
At time: 458.7311382293701 and batch: 450, loss is 3.850385766029358 and perplexity is 47.011195056085604
At time: 459.8045506477356 and batch: 500, loss is 3.859859519004822 and perplexity is 47.45868385739704
At time: 460.8410475254059 and batch: 550, loss is 3.81852463722229 and perplexity is 45.53697517821877
At time: 461.90346574783325 and batch: 600, loss is 3.7937264251708984 and perplexity is 44.42162609958198
At time: 462.97173261642456 and batch: 650, loss is 3.8279300260543825 and perplexity is 45.967288596345405
At time: 464.0544219017029 and batch: 700, loss is 3.862479166984558 and perplexity is 47.58317188890297
At time: 465.1065833568573 and batch: 750, loss is 3.8193451166152954 and perplexity is 45.57435265960207
At time: 466.1557788848877 and batch: 800, loss is 3.794009108543396 and perplexity is 44.4341851296905
At time: 467.2295615673065 and batch: 850, loss is 3.7891440629959106 and perplexity is 44.21853579243738
At time: 468.3133964538574 and batch: 900, loss is 3.7541067457199095 and perplexity is 42.69606432961066
At time: 469.3766577243805 and batch: 950, loss is 3.8720485019683837 and perplexity is 48.04069681356065
At time: 470.4496111869812 and batch: 1000, loss is 3.8358704042434693 and perplexity is 46.333739204958775
At time: 471.5252139568329 and batch: 1050, loss is 3.7729297780990603 and perplexity is 43.507345160253344
At time: 472.57370352745056 and batch: 1100, loss is 3.7904770946502686 and perplexity is 44.27751980540184
At time: 473.6227366924286 and batch: 1150, loss is 3.7653140783309937 and perplexity is 43.17726477372504
At time: 474.6728003025055 and batch: 1200, loss is 3.8316045236587524 and perplexity is 46.136505992233175
At time: 475.722740650177 and batch: 1250, loss is 3.7997285079956056 and perplexity is 44.68905012639026
At time: 476.7717533111572 and batch: 1300, loss is 3.7932313823699952 and perplexity is 44.39964093562453
At time: 477.82050108909607 and batch: 1350, loss is 3.6883683252334594 and perplexity is 39.97956006894546
At time: 478.8697464466095 and batch: 1400, loss is 3.714031009674072 and perplexity is 41.01882098030828
At time: 479.91985750198364 and batch: 1450, loss is 3.6257444477081298 and perplexity is 37.55266875448177
At time: 480.9698374271393 and batch: 1500, loss is 3.6451612424850466 and perplexity is 38.288946158673355
At time: 482.0428509712219 and batch: 1550, loss is 3.646028561592102 and perplexity is 38.32216929871521
At time: 483.0992212295532 and batch: 1600, loss is 3.730198082923889 and perplexity is 41.68736490137186
At time: 484.1583125591278 and batch: 1650, loss is 3.6786646366119387 and perplexity is 39.59348706236359
At time: 485.22356629371643 and batch: 1700, loss is 3.7032014513015747 and perplexity is 40.57700193471504
At time: 486.2837700843811 and batch: 1750, loss is 3.6953490114212038 and perplexity is 40.25962120387883
At time: 487.3444483280182 and batch: 1800, loss is 3.6470207500457765 and perplexity is 38.36021098175168
At time: 488.40456199645996 and batch: 1850, loss is 3.661461238861084 and perplexity is 38.918170084684675
At time: 489.4647264480591 and batch: 1900, loss is 3.7333581829071045 and perplexity is 41.819309511775096
At time: 490.5397651195526 and batch: 1950, loss is 3.679377236366272 and perplexity is 39.62171142666061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24869498319404 and perplexity of 70.01398327659905
finished 11 epochs...
Completing Train Step...
At time: 493.87971544265747 and batch: 50, loss is 3.858534088134766 and perplexity is 47.39582232127323
At time: 494.9228174686432 and batch: 100, loss is 3.8393388652801512 and perplexity is 46.49472499916108
At time: 495.94895219802856 and batch: 150, loss is 3.804064111709595 and perplexity is 44.88322476607164
At time: 496.979190826416 and batch: 200, loss is 3.8158317756652833 and perplexity is 45.414515366000735
At time: 498.029137134552 and batch: 250, loss is 3.803240723609924 and perplexity is 44.846283663443636
At time: 499.06966257095337 and batch: 300, loss is 3.7995661020278932 and perplexity is 44.68179294727889
At time: 500.1008424758911 and batch: 350, loss is 3.8361109352111815 and perplexity is 46.34488524451758
At time: 501.14120149612427 and batch: 400, loss is 3.797279744148254 and perplexity is 44.57975107446887
At time: 502.1876678466797 and batch: 450, loss is 3.829720458984375 and perplexity is 46.04966366506312
At time: 503.235933303833 and batch: 500, loss is 3.8393983364105226 and perplexity is 46.49749017523635
At time: 504.3059093952179 and batch: 550, loss is 3.7983077144622803 and perplexity is 44.625601297476585
At time: 505.3580012321472 and batch: 600, loss is 3.7751342344284056 and perplexity is 43.603360995138914
At time: 506.42205476760864 and batch: 650, loss is 3.809366822242737 and perplexity is 45.12185966151112
At time: 507.4714734554291 and batch: 700, loss is 3.8444415140151977 and perplexity is 46.73257757184809
At time: 508.5308210849762 and batch: 750, loss is 3.802448754310608 and perplexity is 44.810780844020925
At time: 509.5883574485779 and batch: 800, loss is 3.7773496818542482 and perplexity is 43.70006903524769
At time: 510.68779969215393 and batch: 850, loss is 3.772734546661377 and perplexity is 43.498851987802034
At time: 511.7383668422699 and batch: 900, loss is 3.7379059314727785 and perplexity is 42.00992632677001
At time: 512.8103420734406 and batch: 950, loss is 3.8568543815612792 and perplexity is 47.31627807116655
At time: 513.8594863414764 and batch: 1000, loss is 3.8199812936782838 and perplexity is 45.60335524183528
At time: 514.9348208904266 and batch: 1050, loss is 3.7585906076431272 and perplexity is 42.887937431509734
At time: 515.9838104248047 and batch: 1100, loss is 3.77627836227417 and perplexity is 43.65327736453129
At time: 517.0330641269684 and batch: 1150, loss is 3.752136216163635 and perplexity is 42.61201331261659
At time: 518.0828967094421 and batch: 1200, loss is 3.8190586948394776 and perplexity is 45.56130104180456
At time: 519.1324257850647 and batch: 1250, loss is 3.788449010848999 and perplexity is 44.187812282659145
At time: 520.1790633201599 and batch: 1300, loss is 3.7825028705596924 and perplexity is 43.925844970798
At time: 521.2268793582916 and batch: 1350, loss is 3.6779729413986204 and perplexity is 39.56610990629941
At time: 522.2757914066315 and batch: 1400, loss is 3.704491219520569 and perplexity is 40.629370626710184
At time: 523.346512556076 and batch: 1450, loss is 3.617012825012207 and perplexity is 37.22620039316254
At time: 524.3962516784668 and batch: 1500, loss is 3.6366974449157716 and perplexity is 37.966243839218436
At time: 525.4444994926453 and batch: 1550, loss is 3.638716444969177 and perplexity is 38.0429751217238
At time: 526.4928824901581 and batch: 1600, loss is 3.724625644683838 and perplexity is 41.45571067395108
At time: 527.5419986248016 and batch: 1650, loss is 3.6731475448608397 and perplexity is 39.37564763410584
At time: 528.5910532474518 and batch: 1700, loss is 3.6984682273864746 and perplexity is 40.3853957140468
At time: 529.6377184391022 and batch: 1750, loss is 3.691495585441589 and perplexity is 40.10478225541455
At time: 530.686772108078 and batch: 1800, loss is 3.643753423690796 and perplexity is 38.235080186319905
At time: 531.7355945110321 and batch: 1850, loss is 3.6588689517974853 and perplexity is 38.81741366703742
At time: 532.7825372219086 and batch: 1900, loss is 3.731812176704407 and perplexity is 41.75470655103385
At time: 533.8310170173645 and batch: 1950, loss is 3.6773192834854127 and perplexity is 39.54025565630242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249456929051599 and perplexity of 70.06735047000187
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 537.135003566742 and batch: 50, loss is 3.854342403411865 and perplexity is 47.1975697732865
At time: 538.1495852470398 and batch: 100, loss is 3.8506912899017336 and perplexity is 47.02556029279378
At time: 539.1928222179413 and batch: 150, loss is 3.823558988571167 and perplexity is 45.76680234056534
At time: 540.2336478233337 and batch: 200, loss is 3.8411158323287964 and perplexity is 46.57741804306812
At time: 541.2747452259064 and batch: 250, loss is 3.834572820663452 and perplexity is 46.27365629549425
At time: 542.3207023143768 and batch: 300, loss is 3.8266489028930666 and perplexity is 45.90843654467435
At time: 543.3714046478271 and batch: 350, loss is 3.863297452926636 and perplexity is 47.622124464538125
At time: 544.4208817481995 and batch: 400, loss is 3.8288948249816896 and perplexity is 46.01165918798217
At time: 545.4747967720032 and batch: 450, loss is 3.867807297706604 and perplexity is 47.83737786885534
At time: 546.5237574577332 and batch: 500, loss is 3.8813383388519287 and perplexity is 48.48906646664039
At time: 547.5728154182434 and batch: 550, loss is 3.844954562187195 and perplexity is 46.756559786833776
At time: 548.6207811832428 and batch: 600, loss is 3.8162244033813475 and perplexity is 45.43234986437513
At time: 549.6712183952332 and batch: 650, loss is 3.842905406951904 and perplexity is 46.66084643681053
At time: 550.7314782142639 and batch: 700, loss is 3.873377594947815 and perplexity is 48.10458981688811
At time: 551.7900128364563 and batch: 750, loss is 3.830355644226074 and perplexity is 46.07892302338093
At time: 552.849363565445 and batch: 800, loss is 3.802053918838501 and perplexity is 44.79309145064071
At time: 553.9096629619598 and batch: 850, loss is 3.787333836555481 and perplexity is 44.138562636388436
At time: 554.9737441539764 and batch: 900, loss is 3.7440407705307006 and perplexity is 42.268442630781195
At time: 556.0329797267914 and batch: 950, loss is 3.86906192779541 and perplexity is 47.89743374857825
At time: 557.0923619270325 and batch: 1000, loss is 3.8333657455444334 and perplexity is 46.217834213814754
At time: 558.1513600349426 and batch: 1050, loss is 3.772507495880127 and perplexity is 43.488976660617524
At time: 559.2111616134644 and batch: 1100, loss is 3.7866270637512205 and perplexity is 44.107377722320614
At time: 560.2733242511749 and batch: 1150, loss is 3.7621886777877807 and perplexity is 43.04252918795945
At time: 561.332545042038 and batch: 1200, loss is 3.8223747539520265 and perplexity is 45.712635788109914
At time: 562.3915820121765 and batch: 1250, loss is 3.786499648094177 and perplexity is 44.101758109828566
At time: 563.4507479667664 and batch: 1300, loss is 3.7812589597702027 and perplexity is 43.87123910775352
At time: 564.5106139183044 and batch: 1350, loss is 3.6724563694000243 and perplexity is 39.348441555877336
At time: 565.5685505867004 and batch: 1400, loss is 3.7014582109451295 and perplexity is 40.506328086048946
At time: 566.6267857551575 and batch: 1450, loss is 3.609662470817566 and perplexity is 36.95357779869754
At time: 567.6854863166809 and batch: 1500, loss is 3.627570538520813 and perplexity is 37.62130598772339
At time: 568.7427163124084 and batch: 1550, loss is 3.6314952754974366 and perplexity is 37.76924984890838
At time: 569.8019001483917 and batch: 1600, loss is 3.712621603012085 and perplexity is 40.96104950206817
At time: 570.8597779273987 and batch: 1650, loss is 3.6581463956832887 and perplexity is 38.789376038054975
At time: 571.9175822734833 and batch: 1700, loss is 3.6790133810043333 and perplexity is 39.60729747696429
At time: 572.9753375053406 and batch: 1750, loss is 3.6725213098526 and perplexity is 39.35099694445328
At time: 574.0319364070892 and batch: 1800, loss is 3.6260320234298704 and perplexity is 37.56346954325001
At time: 575.0889370441437 and batch: 1850, loss is 3.641207160949707 and perplexity is 38.1378474687955
At time: 576.146062374115 and batch: 1900, loss is 3.7172932910919187 and perplexity is 41.15285442631379
At time: 577.2032315731049 and batch: 1950, loss is 3.6685648584365844 and perplexity is 39.19561422165792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.233758402979651 and perplexity of 68.97598516842841
finished 13 epochs...
Completing Train Step...
At time: 580.53084897995 and batch: 50, loss is 3.859728145599365 and perplexity is 47.4524494580063
At time: 581.5541224479675 and batch: 100, loss is 3.841191258430481 and perplexity is 46.58093132863269
At time: 582.5783877372742 and batch: 150, loss is 3.8093999910354612 and perplexity is 45.12335632394267
At time: 583.6029276847839 and batch: 200, loss is 3.8233150577545167 and perplexity is 45.75563976859794
At time: 584.6468050479889 and batch: 250, loss is 3.813733468055725 and perplexity is 45.31932165059988
At time: 585.6771097183228 and batch: 300, loss is 3.8035012674331665 and perplexity is 44.85796960793174
At time: 586.7058045864105 and batch: 350, loss is 3.840592260360718 and perplexity is 46.55303779559931
At time: 587.7356178760529 and batch: 400, loss is 3.803634428977966 and perplexity is 44.86394336218966
At time: 588.7811224460602 and batch: 450, loss is 3.8419439363479615 and perplexity is 46.61600496493936
At time: 589.8178570270538 and batch: 500, loss is 3.8551480197906494 and perplexity is 47.235608228678714
At time: 590.8607800006866 and batch: 550, loss is 3.8186176729202272 and perplexity is 45.541211939568385
At time: 591.9010725021362 and batch: 600, loss is 3.793150796890259 and perplexity is 44.3960631134218
At time: 592.9415564537048 and batch: 650, loss is 3.821290774345398 and perplexity is 45.66311106989199
At time: 593.9836823940277 and batch: 700, loss is 3.853873348236084 and perplexity is 47.17543670012211
At time: 595.0256443023682 and batch: 750, loss is 3.812621216773987 and perplexity is 45.26894319894882
At time: 596.0900053977966 and batch: 800, loss is 3.784752140045166 and perplexity is 44.02475723197835
At time: 597.1516795158386 and batch: 850, loss is 3.7720813846588133 and perplexity is 43.470449467261815
At time: 598.2023403644562 and batch: 900, loss is 3.7299738073349 and perplexity is 41.678016491404456
At time: 599.2894494533539 and batch: 950, loss is 3.85483510017395 and perplexity is 47.22082959264039
At time: 600.3595271110535 and batch: 1000, loss is 3.819496097564697 and perplexity is 45.58123403810045
At time: 601.4168360233307 and batch: 1050, loss is 3.760176296234131 and perplexity is 42.955998291990475
At time: 602.4837152957916 and batch: 1100, loss is 3.776100745201111 and perplexity is 43.64552448571858
At time: 603.5244352817535 and batch: 1150, loss is 3.7535947132110596 and perplexity is 42.674208152688024
At time: 604.5890078544617 and batch: 1200, loss is 3.814531435966492 and perplexity is 45.35549944745558
At time: 605.6685841083527 and batch: 1250, loss is 3.780091562271118 and perplexity is 43.82005381554146
At time: 606.7096014022827 and batch: 1300, loss is 3.775556793212891 and perplexity is 43.62178987172812
At time: 607.751029253006 and batch: 1350, loss is 3.668228015899658 and perplexity is 39.182413694901385
At time: 608.8150660991669 and batch: 1400, loss is 3.698509120941162 and perplexity is 40.387047250203366
At time: 609.8566963672638 and batch: 1450, loss is 3.6079464387893676 and perplexity is 36.8902186543471
At time: 610.9088625907898 and batch: 1500, loss is 3.627858486175537 and perplexity is 37.63214051436362
At time: 611.9538021087646 and batch: 1550, loss is 3.6322574853897094 and perplexity is 37.79804891884067
At time: 613.0235176086426 and batch: 1600, loss is 3.7150030517578125 and perplexity is 41.05871238544784
At time: 614.1114890575409 and batch: 1650, loss is 3.6613130950927735 and perplexity is 38.91240502735179
At time: 615.168479681015 and batch: 1700, loss is 3.6836086225509646 and perplexity is 39.78972139585692
At time: 616.2088124752045 and batch: 1750, loss is 3.6786064672470093 and perplexity is 39.591184001350285
At time: 617.2497751712799 and batch: 1800, loss is 3.6323078584671022 and perplexity is 37.79995297084023
At time: 618.2894537448883 and batch: 1850, loss is 3.647256622314453 and perplexity is 38.36926015892587
At time: 619.3308258056641 and batch: 1900, loss is 3.723995771408081 and perplexity is 41.42960705152016
At time: 620.371472120285 and batch: 1950, loss is 3.6741802215576174 and perplexity is 39.41633095057908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.232359704305959 and perplexity of 68.87957598887007
finished 14 epochs...
Completing Train Step...
At time: 623.7068018913269 and batch: 50, loss is 3.8559013271331786 and perplexity is 47.27120456499364
At time: 624.7198648452759 and batch: 100, loss is 3.8348339939117433 and perplexity is 46.28574331495362
At time: 625.7340607643127 and batch: 150, loss is 3.8024866819381713 and perplexity is 44.81248044285828
At time: 626.7644400596619 and batch: 200, loss is 3.815495376586914 and perplexity is 45.39924053425073
At time: 627.7933070659637 and batch: 250, loss is 3.8051648330688477 and perplexity is 44.93265589020003
At time: 628.8251709938049 and batch: 300, loss is 3.7943269205093384 and perplexity is 44.44830908968448
At time: 629.8566265106201 and batch: 350, loss is 3.8313200187683107 and perplexity is 46.12338179768779
At time: 630.911520242691 and batch: 400, loss is 3.7938806343078615 and perplexity is 44.42847684841575
At time: 631.9768898487091 and batch: 450, loss is 3.8320030117034913 and perplexity is 46.1548945018544
At time: 633.0413353443146 and batch: 500, loss is 3.8451144456863404 and perplexity is 46.76403598686508
At time: 634.105783700943 and batch: 550, loss is 3.808660764694214 and perplexity is 45.09001227626013
At time: 635.1483500003815 and batch: 600, loss is 3.7842066383361814 and perplexity is 44.00074820074983
At time: 636.2177801132202 and batch: 650, loss is 3.8126963901519777 and perplexity is 45.2723463462386
At time: 637.2594294548035 and batch: 700, loss is 3.845801229476929 and perplexity is 46.79616379993116
At time: 638.3010473251343 and batch: 750, loss is 3.8052815866470335 and perplexity is 44.93790224481198
At time: 639.3688638210297 and batch: 800, loss is 3.777455406188965 and perplexity is 43.704689440213826
At time: 640.4404273033142 and batch: 850, loss is 3.765436191558838 and perplexity is 43.182537610831076
At time: 641.4955990314484 and batch: 900, loss is 3.7236494207382203 and perplexity is 41.41526036400163
At time: 642.5364031791687 and batch: 950, loss is 3.848887300491333 and perplexity is 46.940803153484296
At time: 643.5817215442657 and batch: 1000, loss is 3.8134098482131957 and perplexity is 45.304657791749605
At time: 644.6475796699524 and batch: 1050, loss is 3.7547241973876955 and perplexity is 42.72243522627812
At time: 645.7145111560822 and batch: 1100, loss is 3.7711906003952027 and perplexity is 43.4317439166514
At time: 646.7550375461578 and batch: 1150, loss is 3.7492973899841306 and perplexity is 42.4912167550027
At time: 647.7962963581085 and batch: 1200, loss is 3.810570788383484 and perplexity is 45.176217568724866
At time: 648.8364849090576 and batch: 1250, loss is 3.776796426773071 and perplexity is 43.67589843687586
At time: 649.8904149532318 and batch: 1300, loss is 3.7727830743789674 and perplexity is 43.500962939026216
At time: 650.9683501720428 and batch: 1350, loss is 3.665912890434265 and perplexity is 39.09180641524078
At time: 652.0186710357666 and batch: 1400, loss is 3.6964617013931274 and perplexity is 40.30444261220725
At time: 653.0590224266052 and batch: 1450, loss is 3.606583399772644 and perplexity is 36.839970100135346
At time: 654.1246128082275 and batch: 1500, loss is 3.627068085670471 and perplexity is 37.60240780341715
At time: 655.1664428710938 and batch: 1550, loss is 3.631731381416321 and perplexity is 37.778168445174785
At time: 656.20703291893 and batch: 1600, loss is 3.715150375366211 and perplexity is 41.064761748708726
At time: 657.2477622032166 and batch: 1650, loss is 3.6616915893554687 and perplexity is 38.92713593700885
At time: 658.2965466976166 and batch: 1700, loss is 3.684422459602356 and perplexity is 39.8221169259467
At time: 659.3457551002502 and batch: 1750, loss is 3.679839668273926 and perplexity is 39.6400380073314
At time: 660.3937251567841 and batch: 1800, loss is 3.6336092948913574 and perplexity is 37.849179231948206
At time: 661.4427959918976 and batch: 1850, loss is 3.648450183868408 and perplexity is 38.415083573798434
At time: 662.5037348270416 and batch: 1900, loss is 3.7255472850799563 and perplexity is 41.49393554364426
At time: 663.5662896633148 and batch: 1950, loss is 3.675258994102478 and perplexity is 39.45887514985887
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.232146790970203 and perplexity of 68.86491216969756
finished 15 epochs...
Completing Train Step...
At time: 666.9614224433899 and batch: 50, loss is 3.8513921213150026 and perplexity is 47.0585288340188
At time: 667.9964084625244 and batch: 100, loss is 3.8293699502944945 and perplexity is 46.03352568619858
At time: 669.0304894447327 and batch: 150, loss is 3.7968428182601928 and perplexity is 44.56027728175299
At time: 670.0591752529144 and batch: 200, loss is 3.8094292879104614 and perplexity is 45.124678316637514
At time: 671.0837290287018 and batch: 250, loss is 3.798889832496643 and perplexity is 44.65158622720046
At time: 672.1316995620728 and batch: 300, loss is 3.7877224922180175 and perplexity is 44.1557206727613
At time: 673.1924984455109 and batch: 350, loss is 3.824702892303467 and perplexity is 45.81918511128965
At time: 674.24560379982 and batch: 400, loss is 3.7871101188659666 and perplexity is 44.12868916361337
At time: 675.3057427406311 and batch: 450, loss is 3.8252393293380735 and perplexity is 45.84377081282968
At time: 676.3956308364868 and batch: 500, loss is 3.8384326839447023 and perplexity is 46.452611431316434
At time: 677.495343208313 and batch: 550, loss is 3.801958818435669 and perplexity is 44.78883181214953
At time: 678.5809392929077 and batch: 600, loss is 3.77815390586853 and perplexity is 43.73522781606454
At time: 679.6439101696014 and batch: 650, loss is 3.8067662620544436 and perplexity is 45.00466999508941
At time: 680.7044334411621 and batch: 700, loss is 3.840186815261841 and perplexity is 46.53416692039769
At time: 681.7747597694397 and batch: 750, loss is 3.800156831741333 and perplexity is 44.70819560767282
At time: 682.8440821170807 and batch: 800, loss is 3.772309250831604 and perplexity is 43.48035604085505
At time: 683.9127039909363 and batch: 850, loss is 3.760604429244995 and perplexity is 42.97439311030739
At time: 684.9803700447083 and batch: 900, loss is 3.7189668464660643 and perplexity is 41.22178366936493
At time: 686.0389449596405 and batch: 950, loss is 3.8445686674118043 and perplexity is 46.73852015562037
At time: 687.091447353363 and batch: 1000, loss is 3.808894238471985 and perplexity is 45.100540840790046
At time: 688.1372883319855 and batch: 1050, loss is 3.7506449174880983 and perplexity is 42.54851343401245
At time: 689.2030189037323 and batch: 1100, loss is 3.767355408668518 and perplexity is 43.26549385591226
At time: 690.2444472312927 and batch: 1150, loss is 3.7458177614212036 and perplexity is 42.34362004329816
At time: 691.2853636741638 and batch: 1200, loss is 3.807315583229065 and perplexity is 45.029398804682096
At time: 692.3465571403503 and batch: 1250, loss is 3.774017300605774 and perplexity is 43.55468611483341
At time: 693.4117343425751 and batch: 1300, loss is 3.7702880048751832 and perplexity is 43.39256030530179
At time: 694.4511098861694 and batch: 1350, loss is 3.6636417627334597 and perplexity is 39.003124672716126
At time: 695.517420053482 and batch: 1400, loss is 3.694320969581604 and perplexity is 40.21825389613971
At time: 696.5568535327911 and batch: 1450, loss is 3.604891133308411 and perplexity is 36.777679774971105
At time: 697.620744228363 and batch: 1500, loss is 3.6256193017959593 and perplexity is 37.54796948554934
At time: 698.6630234718323 and batch: 1550, loss is 3.6304692125320432 and perplexity is 37.730516095440954
At time: 699.7480118274689 and batch: 1600, loss is 3.7143342208862307 and perplexity is 41.0312602325041
At time: 700.8208119869232 and batch: 1650, loss is 3.66097110748291 and perplexity is 38.89909974221346
At time: 701.8740198612213 and batch: 1700, loss is 3.6839106035232545 and perplexity is 39.801738949056066
At time: 702.9569146633148 and batch: 1750, loss is 3.6795497941970825 and perplexity is 39.628549053163425
At time: 704.0156686306 and batch: 1800, loss is 3.6333893585205077 and perplexity is 37.840855736181574
At time: 705.0889151096344 and batch: 1850, loss is 3.648221244812012 and perplexity is 38.4062898674635
At time: 706.1377580165863 and batch: 1900, loss is 3.7256543493270873 and perplexity is 41.4983782984396
At time: 707.203622341156 and batch: 1950, loss is 3.6750980186462403 and perplexity is 39.4525237506524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2322813521984015 and perplexity of 68.87417934034582
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 710.5505108833313 and batch: 50, loss is 3.8510461807250977 and perplexity is 47.0422521943314
At time: 711.6172063350677 and batch: 100, loss is 3.834639139175415 and perplexity is 46.27672519728422
At time: 712.641354560852 and batch: 150, loss is 3.8057046604156493 and perplexity is 44.95691831478493
At time: 713.6662697792053 and batch: 200, loss is 3.81970064163208 and perplexity is 45.59055836269206
At time: 714.7325966358185 and batch: 250, loss is 3.811852068901062 and perplexity is 45.2341380744374
At time: 715.7823069095612 and batch: 300, loss is 3.7985446786880495 and perplexity is 44.636177221545864
At time: 716.8176465034485 and batch: 350, loss is 3.8359377431869506 and perplexity is 46.33685937505768
At time: 717.8846349716187 and batch: 400, loss is 3.798906183242798 and perplexity is 44.652316319921034
At time: 718.9353003501892 and batch: 450, loss is 3.83832426071167 and perplexity is 46.4475751620315
At time: 720.0229346752167 and batch: 500, loss is 3.853801727294922 and perplexity is 47.17205807193762
At time: 721.0693035125732 and batch: 550, loss is 3.818218870162964 and perplexity is 45.523053599716434
At time: 722.0997548103333 and batch: 600, loss is 3.793563265800476 and perplexity is 44.41437888627589
At time: 723.1336290836334 and batch: 650, loss is 3.8192865371704103 and perplexity is 45.571683017516115
At time: 724.2011289596558 and batch: 700, loss is 3.8510128450393677 and perplexity is 47.0406840347342
At time: 725.2475183010101 and batch: 750, loss is 3.8130601930618284 and perplexity is 45.28881955389388
At time: 726.314352273941 and batch: 800, loss is 3.784408001899719 and perplexity is 44.00960924032117
At time: 727.3750813007355 and batch: 850, loss is 3.771333336830139 and perplexity is 43.437943651394626
At time: 728.4146182537079 and batch: 900, loss is 3.723338556289673 and perplexity is 41.40238783283695
At time: 729.4547355175018 and batch: 950, loss is 3.849040503501892 and perplexity is 46.94799517675121
At time: 730.4993166923523 and batch: 1000, loss is 3.8109383392333984 and perplexity is 45.19282517777161
At time: 731.5590908527374 and batch: 1050, loss is 3.7537440729141234 and perplexity is 42.68058243576485
At time: 732.6029434204102 and batch: 1100, loss is 3.768475170135498 and perplexity is 43.31396802346946
At time: 733.6467928886414 and batch: 1150, loss is 3.7505905485153197 and perplexity is 42.54620017792904
At time: 734.6910779476166 and batch: 1200, loss is 3.8101638031005858 and perplexity is 45.157835253956904
At time: 735.7367324829102 and batch: 1250, loss is 3.7729146909713744 and perplexity is 43.50668876433322
At time: 736.8110873699188 and batch: 1300, loss is 3.7669821119308473 and perplexity is 43.249346002360184
At time: 737.8598864078522 and batch: 1350, loss is 3.6599289560317994 and perplexity is 38.858582105394326
At time: 738.9012577533722 and batch: 1400, loss is 3.6887583780288695 and perplexity is 39.99515724977386
At time: 739.9787452220917 and batch: 1450, loss is 3.598205122947693 and perplexity is 36.532604029401824
At time: 741.0483283996582 and batch: 1500, loss is 3.6157706069946287 and perplexity is 37.1799860463981
At time: 742.086746931076 and batch: 1550, loss is 3.6225085496902465 and perplexity is 37.43134854386978
At time: 743.1383469104767 and batch: 1600, loss is 3.705485668182373 and perplexity is 40.66979454638491
At time: 744.2165729999542 and batch: 1650, loss is 3.6505679178237913 and perplexity is 38.49652270345014
At time: 745.2624650001526 and batch: 1700, loss is 3.6705678939819335 and perplexity is 39.274203112060285
At time: 746.3235058784485 and batch: 1750, loss is 3.6663840627670288 and perplexity is 39.11022973279932
At time: 747.3973567485809 and batch: 1800, loss is 3.620097584724426 and perplexity is 37.34121157610478
At time: 748.4794402122498 and batch: 1850, loss is 3.636302390098572 and perplexity is 37.9512480539724
At time: 749.5419609546661 and batch: 1900, loss is 3.714814510345459 and perplexity is 41.050971847554166
At time: 750.600168466568 and batch: 1950, loss is 3.6674853944778443 and perplexity is 39.15332679674676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.228935773982558 and perplexity of 68.64414040749865
finished 17 epochs...
Completing Train Step...
At time: 753.9464519023895 and batch: 50, loss is 3.851187047958374 and perplexity is 47.04887937301031
At time: 754.9950063228607 and batch: 100, loss is 3.830351357460022 and perplexity is 46.07872549424136
At time: 756.0083854198456 and batch: 150, loss is 3.8005134534835814 and perplexity is 44.7241423655945
At time: 757.0343396663666 and batch: 200, loss is 3.8141522216796875 and perplexity is 45.338303254806995
At time: 758.0978014469147 and batch: 250, loss is 3.8054069566726683 and perplexity is 44.9435364639421
At time: 759.1542432308197 and batch: 300, loss is 3.7924787616729736 and perplexity is 44.36623741858194
At time: 760.2095062732697 and batch: 350, loss is 3.829618182182312 and perplexity is 46.04495409357144
At time: 761.2602820396423 and batch: 400, loss is 3.791775231361389 and perplexity is 44.33503540281591
At time: 762.3093166351318 and batch: 450, loss is 3.830995144844055 and perplexity is 46.10839994738126
At time: 763.3500730991364 and batch: 500, loss is 3.8459898233413696 and perplexity is 46.8049901015702
At time: 764.416476726532 and batch: 550, loss is 3.8100052785873415 and perplexity is 45.15067719748281
At time: 765.4816555976868 and batch: 600, loss is 3.786170506477356 and perplexity is 44.087244774462
At time: 766.5232925415039 and batch: 650, loss is 3.8122508335113525 and perplexity is 45.25217944476941
At time: 767.600400686264 and batch: 700, loss is 3.844974718093872 and perplexity is 46.75750221718712
At time: 768.6418285369873 and batch: 750, loss is 3.806855173110962 and perplexity is 45.00867158573713
At time: 769.6900618076324 and batch: 800, loss is 3.7780972480773927 and perplexity is 43.73274994485761
At time: 770.7631652355194 and batch: 850, loss is 3.765529079437256 and perplexity is 43.18654893143309
At time: 771.8075504302979 and batch: 900, loss is 3.7188486289978027 and perplexity is 41.2169108224958
At time: 772.8618874549866 and batch: 950, loss is 3.8441749000549317 and perplexity is 46.72011967506661
At time: 773.903685092926 and batch: 1000, loss is 3.806604881286621 and perplexity is 44.99740769290372
At time: 774.9461705684662 and batch: 1050, loss is 3.749848370552063 and perplexity is 42.514635040660224
At time: 775.9881682395935 and batch: 1100, loss is 3.765325541496277 and perplexity is 43.17775972468447
At time: 777.0336079597473 and batch: 1150, loss is 3.7476194715499878 and perplexity is 42.41997974078345
At time: 778.1186680793762 and batch: 1200, loss is 3.8076478958129885 and perplexity is 45.044365127162315
At time: 779.1569273471832 and batch: 1250, loss is 3.771074414253235 and perplexity is 43.42669804302275
At time: 780.1973881721497 and batch: 1300, loss is 3.7654148149490356 and perplexity is 43.18161452444056
At time: 781.237631559372 and batch: 1350, loss is 3.658903579711914 and perplexity is 38.81875785638933
At time: 782.2788753509521 and batch: 1400, loss is 3.68862841129303 and perplexity is 39.989959547508235
At time: 783.3638446331024 and batch: 1450, loss is 3.598489303588867 and perplexity is 36.542987363540064
At time: 784.4132463932037 and batch: 1500, loss is 3.6173483991622923 and perplexity is 37.23869463997627
At time: 785.4707670211792 and batch: 1550, loss is 3.6244167613983156 and perplexity is 37.50284367363742
At time: 786.511513710022 and batch: 1600, loss is 3.7074903583526613 and perplexity is 40.751406659908795
At time: 787.5524797439575 and batch: 1650, loss is 3.652959957122803 and perplexity is 38.5887181222038
At time: 788.5924372673035 and batch: 1700, loss is 3.6735015058517457 and perplexity is 39.38958754430664
At time: 789.6322977542877 and batch: 1750, loss is 3.669591636657715 and perplexity is 39.23588009322694
At time: 790.6929562091827 and batch: 1800, loss is 3.62325834274292 and perplexity is 37.45942483334823
At time: 791.738602399826 and batch: 1850, loss is 3.6397569036483763 and perplexity is 38.0825778643077
At time: 792.7854692935944 and batch: 1900, loss is 3.7185603046417235 and perplexity is 41.20502869625884
At time: 793.8321943283081 and batch: 1950, loss is 3.6707546949386596 and perplexity is 39.28154025604769
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.22806765534157 and perplexity of 68.58457500827386
finished 18 epochs...
Completing Train Step...
At time: 797.1946458816528 and batch: 50, loss is 3.850844383239746 and perplexity is 47.03276014390147
At time: 798.2385425567627 and batch: 100, loss is 3.82834125995636 and perplexity is 45.986195791171504
At time: 799.2905378341675 and batch: 150, loss is 3.7981276750564574 and perplexity is 44.6175676539424
At time: 800.3581454753876 and batch: 200, loss is 3.8113210868835448 and perplexity is 45.21012593611297
At time: 801.3943359851837 and batch: 250, loss is 3.802088556289673 and perplexity is 44.794642996029296
At time: 802.4391474723816 and batch: 300, loss is 3.7890910863876344 and perplexity is 44.216193306437184
At time: 803.484646320343 and batch: 350, loss is 3.826013569831848 and perplexity is 45.87927866061333
At time: 804.5370182991028 and batch: 400, loss is 3.7878636741638183 and perplexity is 44.16195510340829
At time: 805.6379725933075 and batch: 450, loss is 3.8269042444229124 and perplexity is 45.92016037182078
At time: 806.6815428733826 and batch: 500, loss is 3.8416949987411497 and perplexity is 46.60440193249975
At time: 807.7250406742096 and batch: 550, loss is 3.805608229637146 and perplexity is 44.952583293170846
At time: 808.7881817817688 and batch: 600, loss is 3.782163367271423 and perplexity is 43.91093453320493
At time: 809.8383204936981 and batch: 650, loss is 3.8084232711791994 and perplexity is 45.079304962261745
At time: 810.8876850605011 and batch: 700, loss is 3.8415391397476197 and perplexity is 46.59713878334874
At time: 811.9722490310669 and batch: 750, loss is 3.80349524974823 and perplexity is 44.857699667615954
At time: 813.0350699424744 and batch: 800, loss is 3.7748634958267213 and perplexity is 43.59155748006004
At time: 814.1172785758972 and batch: 850, loss is 3.7625411701202394 and perplexity is 43.05770402381736
At time: 815.1836371421814 and batch: 900, loss is 3.716326689720154 and perplexity is 41.11309523951117
At time: 816.2445557117462 and batch: 950, loss is 3.841675901412964 and perplexity is 46.603511921439576
At time: 817.2831676006317 and batch: 1000, loss is 3.8042761707305908 and perplexity is 44.89274366802352
At time: 818.3248660564423 and batch: 1050, loss is 3.74783718585968 and perplexity is 42.429216182806194
At time: 819.3662853240967 and batch: 1100, loss is 3.763736991882324 and perplexity is 43.10922416162599
At time: 820.4066426753998 and batch: 1150, loss is 3.7462098360061646 and perplexity is 42.36022515556092
At time: 821.4479501247406 and batch: 1200, loss is 3.8063862705230713 and perplexity is 44.9875718503999
At time: 822.5144958496094 and batch: 1250, loss is 3.7702197360992433 and perplexity is 43.38959804944079
At time: 823.5653743743896 and batch: 1300, loss is 3.764706840515137 and perplexity is 43.15105386470216
At time: 824.6416585445404 and batch: 1350, loss is 3.6584560585021975 and perplexity is 38.80138952555183
At time: 825.6935606002808 and batch: 1400, loss is 3.688608374595642 and perplexity is 39.98915828881754
At time: 826.7365906238556 and batch: 1450, loss is 3.598693037033081 and perplexity is 36.55043315066967
At time: 827.7780106067657 and batch: 1500, loss is 3.618208956718445 and perplexity is 37.27075447271711
At time: 828.8637781143188 and batch: 1550, loss is 3.6254161405563354 and perplexity is 37.54034196835745
At time: 829.9573500156403 and batch: 1600, loss is 3.708550672531128 and perplexity is 40.79463886999504
At time: 831.0417764186859 and batch: 1650, loss is 3.654188938140869 and perplexity is 38.63617207832029
At time: 832.0837135314941 and batch: 1700, loss is 3.6749906826019285 and perplexity is 39.44828930007354
At time: 833.1416008472443 and batch: 1750, loss is 3.671296043395996 and perplexity is 39.30281101419369
At time: 834.1905677318573 and batch: 1800, loss is 3.6248666048049927 and perplexity is 37.51971787568536
At time: 835.2317802906036 and batch: 1850, loss is 3.6414165019989015 and perplexity is 38.14583212152727
At time: 836.297021150589 and batch: 1900, loss is 3.7203481721878053 and perplexity is 41.27876372439117
At time: 837.3713591098785 and batch: 1950, loss is 3.6722223472595217 and perplexity is 39.339234226760446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.227699457212936 and perplexity of 68.55932694453284
finished 19 epochs...
Completing Train Step...
At time: 840.7296056747437 and batch: 50, loss is 3.849975919723511 and perplexity is 46.99193163924817
At time: 841.7545838356018 and batch: 100, loss is 3.8265996503829958 and perplexity is 45.90617549462275
At time: 842.7621877193451 and batch: 150, loss is 3.796218295097351 and perplexity is 44.53245704454338
At time: 843.821165561676 and batch: 200, loss is 3.8091688919067384 and perplexity is 45.11292956046554
At time: 844.8594851493835 and batch: 250, loss is 3.7996191596984863 and perplexity is 44.68416372202393
At time: 845.9130661487579 and batch: 300, loss is 3.7865296936035158 and perplexity is 44.10308318951996
At time: 846.9407727718353 and batch: 350, loss is 3.823364772796631 and perplexity is 45.757914568701416
At time: 847.972029209137 and batch: 400, loss is 3.7850521564483643 and perplexity is 44.03796736282366
At time: 849.0067248344421 and batch: 450, loss is 3.8240004444122313 and perplexity is 45.78701082303355
At time: 850.0541567802429 and batch: 500, loss is 3.838712396621704 and perplexity is 46.46560663299021
At time: 851.1181313991547 and batch: 550, loss is 3.8026084184646605 and perplexity is 44.817936090639826
At time: 852.1777441501617 and batch: 600, loss is 3.779422569274902 and perplexity is 43.79074831012697
At time: 853.2237017154694 and batch: 650, loss is 3.805826811790466 and perplexity is 44.96241019957842
At time: 854.2886710166931 and batch: 700, loss is 3.8391425704956053 and perplexity is 46.4855992228353
At time: 855.3302140235901 and batch: 750, loss is 3.8012021446228026 and perplexity is 44.75495409481558
At time: 856.3728289604187 and batch: 800, loss is 3.772658038139343 and perplexity is 43.495524082234475
At time: 857.4140160083771 and batch: 850, loss is 3.760510969161987 and perplexity is 42.97037690764033
At time: 858.4636235237122 and batch: 900, loss is 3.7145128440856934 and perplexity is 41.038590022100564
At time: 859.5084006786346 and batch: 950, loss is 3.8399478340148927 and perplexity is 46.52304745588603
At time: 860.5528502464294 and batch: 1000, loss is 3.802651410102844 and perplexity is 44.81986292855103
At time: 861.5954251289368 and batch: 1050, loss is 3.7464158964157104 and perplexity is 42.36895482029318
At time: 862.6385455131531 and batch: 1100, loss is 3.762585344314575 and perplexity is 43.0596061052137
At time: 863.6803874969482 and batch: 1150, loss is 3.7452044820785524 and perplexity is 42.31765953716727
At time: 864.7270283699036 and batch: 1200, loss is 3.805448455810547 and perplexity is 44.945401620659496
At time: 865.775098323822 and batch: 1250, loss is 3.7695437622070314 and perplexity is 43.3602777249692
At time: 866.8243010044098 and batch: 1300, loss is 3.76413592338562 and perplexity is 43.12642522002063
At time: 867.8978269100189 and batch: 1350, loss is 3.6580592584609986 and perplexity is 38.78599618683021
At time: 868.9476475715637 and batch: 1400, loss is 3.6884342861175536 and perplexity is 39.98219724304752
At time: 869.9965653419495 and batch: 1450, loss is 3.598670744895935 and perplexity is 36.54961837248273
At time: 871.0456788539886 and batch: 1500, loss is 3.6185709476470946 and perplexity is 37.28424858996682
At time: 872.0955457687378 and batch: 1550, loss is 3.6258713817596435 and perplexity is 37.55743576941379
At time: 873.1535212993622 and batch: 1600, loss is 3.7090724515914917 and perplexity is 40.81593021253781
At time: 874.2034430503845 and batch: 1650, loss is 3.6547883701324464 and perplexity is 38.6593387786331
At time: 875.2517309188843 and batch: 1700, loss is 3.6757481145858764 and perplexity is 39.47818001476408
At time: 876.3017997741699 and batch: 1750, loss is 3.672212347984314 and perplexity is 39.33884086489762
At time: 877.3517348766327 and batch: 1800, loss is 3.625709171295166 and perplexity is 37.551344054396374
At time: 878.4017157554626 and batch: 1850, loss is 3.642249627113342 and perplexity is 38.177625614418666
At time: 879.4506912231445 and batch: 1900, loss is 3.7212537717819214 and perplexity is 41.31616268775267
At time: 880.4986386299133 and batch: 1950, loss is 3.6729036664962766 and perplexity is 39.36604593642797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.227528274890989 and perplexity of 68.54759180420825
Finished Training.
Improved accuracyfrom -10000000 to -68.54759180420825
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
912.420966386795


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6165540218353271 and batch: 50, loss is 7.679118919372558 and perplexity is 2162.7134072545095
At time: 2.7723255157470703 and batch: 100, loss is 6.754753913879394 and perplexity is 858.1285503769566
At time: 3.9260001182556152 and batch: 150, loss is 6.455832614898681 and perplexity is 636.4033846610661
At time: 5.076390027999878 and batch: 200, loss is 6.29542685508728 and perplexity is 542.0871896892194
At time: 6.2267327308654785 and batch: 250, loss is 6.148832311630249 and perplexity is 468.1703903640014
At time: 7.376095533370972 and batch: 300, loss is 6.027048749923706 and perplexity is 414.489959003514
At time: 8.526374578475952 and batch: 350, loss is 5.904373455047607 and perplexity is 366.63743897235287
At time: 9.677472114562988 and batch: 400, loss is 5.818132677078247 and perplexity is 336.3434051178952
At time: 10.831014394760132 and batch: 450, loss is 5.7083757209777835 and perplexity is 301.3811434342048
At time: 12.022574663162231 and batch: 500, loss is 5.6503074359893795 and perplexity is 284.3788806885377
At time: 13.177269220352173 and batch: 550, loss is 5.57011399269104 and perplexity is 262.4640165146148
At time: 14.334178924560547 and batch: 600, loss is 5.564818878173828 and perplexity is 261.07791251887556
At time: 15.490344047546387 and batch: 650, loss is 5.606431398391724 and perplexity is 272.1712322053474
At time: 16.64775562286377 and batch: 700, loss is 5.531650533676148 and perplexity is 252.5604266818949
At time: 17.805665493011475 and batch: 750, loss is 5.470619010925293 and perplexity is 237.60722871854506
At time: 18.96731996536255 and batch: 800, loss is 5.439693870544434 and perplexity is 230.37164911735076
At time: 20.122906923294067 and batch: 850, loss is 5.435055065155029 and perplexity is 229.30547466961977
At time: 21.27852511405945 and batch: 900, loss is 5.424254627227783 and perplexity is 226.84220128463153
At time: 22.42997097969055 and batch: 950, loss is 5.4485140132904055 and perplexity is 232.41254722255835
At time: 23.587132692337036 and batch: 1000, loss is 5.403196258544922 and perplexity is 222.1152205113593
At time: 24.744022130966187 and batch: 1050, loss is 5.293408184051514 and perplexity is 199.02056956908737
At time: 25.900125741958618 and batch: 1100, loss is 5.373421287536621 and perplexity is 215.59923429834316
At time: 27.067211866378784 and batch: 1150, loss is 5.261118412017822 and perplexity is 192.6968853375104
At time: 28.236987352371216 and batch: 1200, loss is 5.345782203674316 and perplexity is 209.72186567112357
At time: 29.40579128265381 and batch: 1250, loss is 5.285662994384766 and perplexity is 197.48507154783653
At time: 30.576240301132202 and batch: 1300, loss is 5.307069702148437 and perplexity is 201.75814985552861
At time: 31.747724294662476 and batch: 1350, loss is 5.226874628067017 and perplexity is 186.2099178764448
At time: 32.920769453048706 and batch: 1400, loss is 5.241671514511109 and perplexity is 188.98573093499502
At time: 34.131224632263184 and batch: 1450, loss is 5.195959568023682 and perplexity is 180.5413013647543
At time: 35.39935827255249 and batch: 1500, loss is 5.161831092834473 and perplexity is 174.4836590481697
At time: 36.684378147125244 and batch: 1550, loss is 5.1440972805023195 and perplexity is 171.41667363258804
At time: 37.96681189537048 and batch: 1600, loss is 5.178886289596558 and perplexity is 177.48503395186535
At time: 39.252117395401 and batch: 1650, loss is 5.151663408279419 and perplexity is 172.71855297048722
At time: 40.5398850440979 and batch: 1700, loss is 5.176188545227051 and perplexity is 177.0068699729403
At time: 41.82174587249756 and batch: 1750, loss is 5.175542707443237 and perplexity is 176.89258915572438
At time: 43.10980558395386 and batch: 1800, loss is 5.143276720046997 and perplexity is 171.27607358213206
At time: 44.39569020271301 and batch: 1850, loss is 5.118166332244873 and perplexity is 167.0288132966567
At time: 45.68217396736145 and batch: 1900, loss is 5.176768102645874 and perplexity is 177.10948535049522
At time: 46.96478843688965 and batch: 1950, loss is 5.10389479637146 and perplexity is 164.66198490612777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.771239098837209 and perplexity of 118.06544611826314
finished 1 epochs...
Completing Train Step...
At time: 50.50657820701599 and batch: 50, loss is 4.992952814102173 and perplexity is 147.3709406475857
At time: 51.62048578262329 and batch: 100, loss is 4.940813255310059 and perplexity is 139.8839646910955
At time: 52.72281002998352 and batch: 150, loss is 4.888718948364258 and perplexity is 132.78336270580564
At time: 53.81996726989746 and batch: 200, loss is 4.859951419830322 and perplexity is 129.0179342419955
At time: 54.96000623703003 and batch: 250, loss is 4.864814567565918 and perplexity is 129.6468956432745
At time: 56.06802535057068 and batch: 300, loss is 4.871836452484131 and perplexity is 130.56046496002165
At time: 57.152385234832764 and batch: 350, loss is 4.870503120422363 and perplexity is 130.38650050805427
At time: 58.255889654159546 and batch: 400, loss is 4.824098796844482 and perplexity is 124.47424124207602
At time: 59.33756613731384 and batch: 450, loss is 4.796947774887085 and perplexity is 121.1401057957613
At time: 60.4210684299469 and batch: 500, loss is 4.7911961555480955 and perplexity is 120.44535390999364
At time: 61.504581928253174 and batch: 550, loss is 4.74465274810791 and perplexity is 114.9678757582843
At time: 62.62338399887085 and batch: 600, loss is 4.7302607154846195 and perplexity is 113.32510410693241
At time: 63.74747061729431 and batch: 650, loss is 4.803807554244995 and perplexity is 121.97395694050371
At time: 64.83726978302002 and batch: 700, loss is 4.7920598220825195 and perplexity is 120.54942346561981
At time: 65.92052388191223 and batch: 750, loss is 4.7544288825988765 and perplexity is 116.09732902193758
At time: 67.0036780834198 and batch: 800, loss is 4.733490324020385 and perplexity is 113.69169147868837
At time: 68.08753609657288 and batch: 850, loss is 4.719500141143799 and perplexity is 112.1121983841108
At time: 69.17019462585449 and batch: 900, loss is 4.713087406158447 and perplexity is 111.39555285207898
At time: 70.2762553691864 and batch: 950, loss is 4.77833270072937 and perplexity is 118.90593290519615
At time: 71.35983943939209 and batch: 1000, loss is 4.747789192199707 and perplexity is 115.32903215030238
At time: 72.44341468811035 and batch: 1050, loss is 4.6621690940856935 and perplexity is 105.86546544473133
At time: 73.5265600681305 and batch: 1100, loss is 4.727996501922608 and perplexity is 113.06880213998966
At time: 74.60883688926697 and batch: 1150, loss is 4.6563420009613035 and perplexity is 105.2503713646302
At time: 75.69309306144714 and batch: 1200, loss is 4.748155736923218 and perplexity is 115.37131314696946
At time: 76.776522397995 and batch: 1250, loss is 4.699815034866333 and perplexity is 109.92683793932049
At time: 77.88313364982605 and batch: 1300, loss is 4.727397499084472 and perplexity is 113.00109388734549
At time: 78.99302005767822 and batch: 1350, loss is 4.61042628288269 and perplexity is 100.5269934405024
At time: 80.10096955299377 and batch: 1400, loss is 4.630847234725952 and perplexity is 102.60095438853924
At time: 81.18599486351013 and batch: 1450, loss is 4.576733026504517 and perplexity is 97.19633709072433
At time: 82.2681736946106 and batch: 1500, loss is 4.560359296798706 and perplexity is 95.61782883875328
At time: 83.38268876075745 and batch: 1550, loss is 4.569122257232666 and perplexity is 96.45940605823752
At time: 84.47664284706116 and batch: 1600, loss is 4.624844913482666 and perplexity is 101.98695505447702
At time: 85.55883073806763 and batch: 1650, loss is 4.5867866516113285 and perplexity is 98.17844120669055
At time: 86.64139747619629 and batch: 1700, loss is 4.620837316513062 and perplexity is 101.57905034723652
At time: 87.72433090209961 and batch: 1750, loss is 4.6098308277130124 and perplexity is 100.46715194079943
At time: 88.80794644355774 and batch: 1800, loss is 4.570161333084107 and perplexity is 96.55968678833682
At time: 89.92391419410706 and batch: 1850, loss is 4.586350545883179 and perplexity is 98.1356343609333
At time: 91.01633954048157 and batch: 1900, loss is 4.6671000099182125 and perplexity is 106.38876826519578
At time: 92.09758424758911 and batch: 1950, loss is 4.595620403289795 and perplexity is 99.04956716683121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5091368209484015 and perplexity of 90.84337056364105
finished 2 epochs...
Completing Train Step...
At time: 95.5423469543457 and batch: 50, loss is 4.570264005661011 and perplexity is 96.56960132917149
At time: 96.60973978042603 and batch: 100, loss is 4.52592251777649 and perplexity is 92.38110974673047
At time: 97.66998481750488 and batch: 150, loss is 4.485607118606567 and perplexity is 88.73080458593242
At time: 98.75915193557739 and batch: 200, loss is 4.477773933410645 and perplexity is 88.03847487448998
At time: 99.82303619384766 and batch: 250, loss is 4.484102935791015 and perplexity is 88.59743756380158
At time: 100.88711094856262 and batch: 300, loss is 4.501398086547852 and perplexity is 90.14307105769547
At time: 101.96318030357361 and batch: 350, loss is 4.510337285995483 and perplexity is 90.95249033889532
At time: 103.0746214389801 and batch: 400, loss is 4.469305114746094 and perplexity is 87.2960412006796
At time: 104.18177819252014 and batch: 450, loss is 4.471645669937134 and perplexity is 87.50060170225576
At time: 105.29164576530457 and batch: 500, loss is 4.477186794281006 and perplexity is 87.98679921286346
At time: 106.39090728759766 and batch: 550, loss is 4.443247585296631 and perplexity is 85.0507030648833
At time: 107.47414088249207 and batch: 600, loss is 4.430731229782104 and perplexity is 83.99281250637634
At time: 108.56635284423828 and batch: 650, loss is 4.488845806121827 and perplexity is 89.01864179074866
At time: 109.68788266181946 and batch: 700, loss is 4.504685697555542 and perplexity is 90.43991409522447
At time: 110.78088307380676 and batch: 750, loss is 4.468227262496948 and perplexity is 87.20199965687921
At time: 111.85881090164185 and batch: 800, loss is 4.449427995681763 and perplexity is 85.57797902589787
At time: 112.93566107749939 and batch: 850, loss is 4.4318703842163085 and perplexity is 84.08854780947902
At time: 114.02975940704346 and batch: 900, loss is 4.420838422775269 and perplexity is 83.16598439107375
At time: 115.11493515968323 and batch: 950, loss is 4.497601299285889 and perplexity is 89.80146590516527
At time: 116.19202423095703 and batch: 1000, loss is 4.476470317840576 and perplexity is 87.92378132227137
At time: 117.27710175514221 and batch: 1050, loss is 4.396699352264404 and perplexity is 81.18247122611244
At time: 118.35336589813232 and batch: 1100, loss is 4.453900909423828 and perplexity is 85.96161929960442
At time: 119.43088126182556 and batch: 1150, loss is 4.403086967468262 and perplexity is 81.70269333410175
At time: 120.50745368003845 and batch: 1200, loss is 4.491812295913697 and perplexity is 89.28310675527352
At time: 121.58350849151611 and batch: 1250, loss is 4.459702348709106 and perplexity is 86.46176980845684
At time: 122.66591048240662 and batch: 1300, loss is 4.473716630935669 and perplexity is 87.68199980509468
At time: 123.74912571907043 and batch: 1350, loss is 4.355085740089416 and perplexity is 77.87350193161683
At time: 124.83280682563782 and batch: 1400, loss is 4.374628190994263 and perplexity is 79.41030859477964
At time: 125.91575336456299 and batch: 1450, loss is 4.31849057674408 and perplexity is 75.07522243814657
At time: 126.99906492233276 and batch: 1500, loss is 4.3133335876464844 and perplexity is 74.6890569160512
At time: 128.08386993408203 and batch: 1550, loss is 4.329018964767456 and perplexity is 75.86981908193933
At time: 129.1678261756897 and batch: 1600, loss is 4.396718196868896 and perplexity is 81.18400109208919
At time: 130.25149989128113 and batch: 1650, loss is 4.351873865127564 and perplexity is 77.62378322787465
At time: 131.33463716506958 and batch: 1700, loss is 4.382577295303345 and perplexity is 80.04406498166885
At time: 132.41852927207947 and batch: 1750, loss is 4.379326105117798 and perplexity is 79.78424908749138
At time: 133.50217080116272 and batch: 1800, loss is 4.335532283782959 and perplexity is 76.36559624196202
At time: 134.58465218544006 and batch: 1850, loss is 4.361046953201294 and perplexity is 78.33910888471735
At time: 135.69300651550293 and batch: 1900, loss is 4.4456261539459225 and perplexity is 85.2532427826145
At time: 136.77698683738708 and batch: 1950, loss is 4.378007116317749 and perplexity is 79.67908392760532
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.409514103379361 and perplexity of 82.22949876005654
finished 3 epochs...
Completing Train Step...
At time: 140.2309012413025 and batch: 50, loss is 4.361490797996521 and perplexity is 78.37388700793213
At time: 141.30023574829102 and batch: 100, loss is 4.318790168762207 and perplexity is 75.0977177450871
At time: 142.36342358589172 and batch: 150, loss is 4.283749217987061 and perplexity is 72.5117935282851
At time: 143.43689370155334 and batch: 200, loss is 4.279906978607178 and perplexity is 72.23372041351564
At time: 144.48716139793396 and batch: 250, loss is 4.279740934371948 and perplexity is 72.22172741636335
At time: 145.53490900993347 and batch: 300, loss is 4.296314144134522 and perplexity is 73.42864689369884
At time: 146.58282947540283 and batch: 350, loss is 4.307184896469116 and perplexity is 74.23122594378641
At time: 147.63119912147522 and batch: 400, loss is 4.270372505187988 and perplexity is 71.54828276233219
At time: 148.7088177204132 and batch: 450, loss is 4.2855379772186275 and perplexity is 72.6416157440842
At time: 149.78233218193054 and batch: 500, loss is 4.300738191604614 and perplexity is 73.75421835400664
At time: 150.8430094718933 and batch: 550, loss is 4.263408403396607 and perplexity is 71.05174421745016
At time: 151.927743434906 and batch: 600, loss is 4.251796875 and perplexity is 70.23149625408432
At time: 153.008526802063 and batch: 650, loss is 4.306963844299316 and perplexity is 74.21481878371061
At time: 154.10554456710815 and batch: 700, loss is 4.331516246795655 and perplexity is 76.05952419260711
At time: 155.16890907287598 and batch: 750, loss is 4.300304660797119 and perplexity is 73.72225055818033
At time: 156.2390456199646 and batch: 800, loss is 4.275432395935058 and perplexity is 71.91122671025644
At time: 157.34235548973083 and batch: 850, loss is 4.259592361450196 and perplexity is 70.78112445772896
At time: 158.420401096344 and batch: 900, loss is 4.243017578125 and perplexity is 69.617611778501
At time: 159.54322171211243 and batch: 950, loss is 4.3335300636291505 and perplexity is 76.21284847446708
At time: 160.65640497207642 and batch: 1000, loss is 4.312023553848267 and perplexity is 74.59127578940877
At time: 161.7358422279358 and batch: 1050, loss is 4.240818338394165 and perplexity is 69.46467419555842
At time: 162.8229410648346 and batch: 1100, loss is 4.285031628608704 and perplexity is 72.60484307361054
At time: 163.93545079231262 and batch: 1150, loss is 4.24371220588684 and perplexity is 69.66598690376273
At time: 165.05306887626648 and batch: 1200, loss is 4.330699872970581 and perplexity is 75.99745652656486
At time: 166.15775871276855 and batch: 1250, loss is 4.305215129852295 and perplexity is 74.0851516663447
At time: 167.2590296268463 and batch: 1300, loss is 4.318081407546997 and perplexity is 75.04451025332925
At time: 168.34860515594482 and batch: 1350, loss is 4.19378466129303 and perplexity is 66.27313830294001
At time: 169.42457747459412 and batch: 1400, loss is 4.221404318809509 and perplexity is 68.12909210729981
At time: 170.50041723251343 and batch: 1450, loss is 4.161355962753296 and perplexity is 64.15846012683275
At time: 171.5747423171997 and batch: 1500, loss is 4.162056636810303 and perplexity is 64.20343004816993
At time: 172.67251300811768 and batch: 1550, loss is 4.169997496604919 and perplexity is 64.71529009926138
At time: 173.7496054172516 and batch: 1600, loss is 4.24929283618927 and perplexity is 70.055853861189
At time: 174.85009002685547 and batch: 1650, loss is 4.2017937707901005 and perplexity is 66.80605838324702
At time: 175.94207406044006 and batch: 1700, loss is 4.229434747695922 and perplexity is 68.6784005758894
At time: 177.03478455543518 and batch: 1750, loss is 4.23147819519043 and perplexity is 68.8188847686241
At time: 178.11114835739136 and batch: 1800, loss is 4.18921820640564 and perplexity is 65.97119493670365
At time: 179.18826007843018 and batch: 1850, loss is 4.2182168292999265 and perplexity is 67.91227707230682
At time: 180.26485395431519 and batch: 1900, loss is 4.299061002731324 and perplexity is 73.63062227558143
At time: 181.34249663352966 and batch: 1950, loss is 4.2334965801239015 and perplexity is 68.95792804300068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372141851380814 and perplexity of 79.2131128481892
finished 4 epochs...
Completing Train Step...
At time: 184.7360668182373 and batch: 50, loss is 4.217071642875672 and perplexity is 67.83454936941312
At time: 185.79116201400757 and batch: 100, loss is 4.1851713085174564 and perplexity is 65.70475573698202
At time: 186.8439438343048 and batch: 150, loss is 4.147575888633728 and perplexity is 63.280415445595324
At time: 187.9016466140747 and batch: 200, loss is 4.150365934371949 and perplexity is 63.45721722685964
At time: 188.96593260765076 and batch: 250, loss is 4.146153779029846 and perplexity is 63.19048771775098
At time: 190.03493547439575 and batch: 300, loss is 4.160810875892639 and perplexity is 64.1234977228568
At time: 191.08634042739868 and batch: 350, loss is 4.171314263343811 and perplexity is 64.8005611694956
At time: 192.14550948143005 and batch: 400, loss is 4.135908942222596 and perplexity is 62.54641631978411
At time: 193.1878628730774 and batch: 450, loss is 4.161004567146302 and perplexity is 64.13591908643588
At time: 194.2572603225708 and batch: 500, loss is 4.178587193489075 and perplexity is 65.27356911613424
At time: 195.32203102111816 and batch: 550, loss is 4.142191519737244 and perplexity is 62.94060599559316
At time: 196.41055965423584 and batch: 600, loss is 4.130572552680969 and perplexity is 62.21353326465633
At time: 197.5105369091034 and batch: 650, loss is 4.184878759384155 and perplexity is 65.68553667903383
At time: 198.5898516178131 and batch: 700, loss is 4.210253787040711 and perplexity is 67.37363619635637
At time: 199.6807940006256 and batch: 750, loss is 4.179884462356568 and perplexity is 65.35830143363448
At time: 200.76651644706726 and batch: 800, loss is 4.151001224517822 and perplexity is 63.49754377982298
At time: 201.83005261421204 and batch: 850, loss is 4.1406174325943 and perplexity is 62.841609931582795
At time: 202.91960644721985 and batch: 900, loss is 4.124066038131714 and perplexity is 61.81005405042911
At time: 204.0105938911438 and batch: 950, loss is 4.214626135826111 and perplexity is 67.66886217789832
At time: 205.08053946495056 and batch: 1000, loss is 4.195848293304444 and perplexity is 66.4100428843923
At time: 206.16490936279297 and batch: 1050, loss is 4.130327725410462 and perplexity is 62.19830355951815
At time: 207.25281834602356 and batch: 1100, loss is 4.164886136054992 and perplexity is 64.38535085601941
At time: 208.3169810771942 and batch: 1150, loss is 4.128640737533569 and perplexity is 62.09346423165129
At time: 209.37996697425842 and batch: 1200, loss is 4.217840852737427 and perplexity is 67.88674844720475
At time: 210.44251537322998 and batch: 1250, loss is 4.196971077919006 and perplexity is 66.48464893422012
At time: 211.5224609375 and batch: 1300, loss is 4.206624274253845 and perplexity is 67.12954595456831
At time: 212.59995079040527 and batch: 1350, loss is 4.081406021118164 and perplexity is 59.22868811914747
At time: 213.66446805000305 and batch: 1400, loss is 4.114157085418701 and perplexity is 61.20060563210238
At time: 214.7275834083557 and batch: 1450, loss is 4.048741760253907 and perplexity is 57.32528269950429
At time: 215.79667496681213 and batch: 1500, loss is 4.052727704048157 and perplexity is 57.55423404480431
At time: 216.8876028060913 and batch: 1550, loss is 4.063865065574646 and perplexity is 58.19881918270711
At time: 217.97586607933044 and batch: 1600, loss is 4.139024620056152 and perplexity is 62.741594701268134
At time: 219.0532054901123 and batch: 1650, loss is 4.092020783424378 and perplexity is 59.86073514516366
At time: 220.1299319267273 and batch: 1700, loss is 4.124126243591308 and perplexity is 61.8137754651644
At time: 221.20647168159485 and batch: 1750, loss is 4.125677881240844 and perplexity is 61.909762495723314
At time: 222.28641772270203 and batch: 1800, loss is 4.085955481529236 and perplexity is 59.49876056707968
At time: 223.38562607765198 and batch: 1850, loss is 4.113208570480347 and perplexity is 61.142583465220135
At time: 224.4849214553833 and batch: 1900, loss is 4.191749844551087 and perplexity is 66.138421719842
At time: 225.56129431724548 and batch: 1950, loss is 4.12715630531311 and perplexity is 62.0013590715127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352568586482558 and perplexity of 77.67772886416162
finished 5 epochs...
Completing Train Step...
At time: 228.99681401252747 and batch: 50, loss is 4.110058360099792 and perplexity is 60.95027452993285
At time: 230.0398290157318 and batch: 100, loss is 4.078983993530273 and perplexity is 59.08540818654567
At time: 231.0823850631714 and batch: 150, loss is 4.051461591720581 and perplexity is 57.48141003099513
At time: 232.12413930892944 and batch: 200, loss is 4.056011910438538 and perplexity is 57.74356475844064
At time: 233.1657509803772 and batch: 250, loss is 4.0449507474899296 and perplexity is 57.10837323414893
At time: 234.2052297592163 and batch: 300, loss is 4.058172874450683 and perplexity is 57.86848144543823
At time: 235.24676752090454 and batch: 350, loss is 4.069660277366638 and perplexity is 58.53707284504885
At time: 236.2918267250061 and batch: 400, loss is 4.034234638214111 and perplexity is 56.49966100450394
At time: 237.36299443244934 and batch: 450, loss is 4.065234127044678 and perplexity is 58.2785515104267
At time: 238.41581010818481 and batch: 500, loss is 4.084747543334961 and perplexity is 59.426933131963516
At time: 239.47509932518005 and batch: 550, loss is 4.051222400665283 and perplexity is 57.46766263606232
At time: 240.53385066986084 and batch: 600, loss is 4.038178353309632 and perplexity is 56.722919515118946
At time: 241.59142994880676 and batch: 650, loss is 4.085463123321533 and perplexity is 59.46947307452664
At time: 242.6730318069458 and batch: 700, loss is 4.113407130241394 and perplexity is 61.15472512736569
At time: 243.77050876617432 and batch: 750, loss is 4.087194981575013 and perplexity is 59.57255500818487
At time: 244.83050227165222 and batch: 800, loss is 4.058353610038758 and perplexity is 57.878941284667356
At time: 245.88815188407898 and batch: 850, loss is 4.04920461177826 and perplexity is 57.351821935374815
At time: 246.9493227005005 and batch: 900, loss is 4.032785143852234 and perplexity is 56.41782438961431
At time: 248.04106879234314 and batch: 950, loss is 4.124622526168824 and perplexity is 61.84446017849271
At time: 249.09984040260315 and batch: 1000, loss is 4.104752926826477 and perplexity is 60.62776320307988
At time: 250.1633939743042 and batch: 1050, loss is 4.0444923639297485 and perplexity is 57.08220169346996
At time: 251.22778844833374 and batch: 1100, loss is 4.074744091033936 and perplexity is 58.83542214958458
At time: 252.31647443771362 and batch: 1150, loss is 4.045898532867431 and perplexity is 57.16252537348235
At time: 253.37964963912964 and batch: 1200, loss is 4.133476476669312 and perplexity is 62.39445920675251
At time: 254.44291615486145 and batch: 1250, loss is 4.117101583480835 and perplexity is 61.381076264109595
At time: 255.50576734542847 and batch: 1300, loss is 4.121047782897949 and perplexity is 61.62377678886531
At time: 256.56973099708557 and batch: 1350, loss is 3.9945955944061278 and perplexity is 54.30387539170352
At time: 257.6334638595581 and batch: 1400, loss is 4.027180624008179 and perplexity is 56.1025139803287
At time: 258.6978614330292 and batch: 1450, loss is 3.962437868118286 and perplexity is 52.585366000566594
At time: 259.7621259689331 and batch: 1500, loss is 3.967168622016907 and perplexity is 52.83472378588894
At time: 260.82637906074524 and batch: 1550, loss is 3.9752386903762815 and perplexity is 53.262828713209586
At time: 261.88982367515564 and batch: 1600, loss is 4.06195173740387 and perplexity is 58.0875722023876
At time: 262.977707862854 and batch: 1650, loss is 4.0139136362075805 and perplexity is 55.36311823417878
At time: 264.0417010784149 and batch: 1700, loss is 4.045991668701172 and perplexity is 57.16784950087139
At time: 265.10635900497437 and batch: 1750, loss is 4.042280430793762 and perplexity is 56.9560792187324
At time: 266.17036628723145 and batch: 1800, loss is 4.002351765632629 and perplexity is 54.72670319019552
At time: 267.25280475616455 and batch: 1850, loss is 4.034369411468506 and perplexity is 56.5072761608379
At time: 268.3178095817566 and batch: 1900, loss is 4.107182278633117 and perplexity is 60.77522841906904
At time: 269.3818871974945 and batch: 1950, loss is 4.0429153680801395 and perplexity is 56.992254240333935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349193200399709 and perplexity of 77.41597854191873
finished 6 epochs...
Completing Train Step...
At time: 272.7488925457001 and batch: 50, loss is 4.029908142089844 and perplexity is 56.255743474751206
At time: 273.8008985519409 and batch: 100, loss is 4.002858195304871 and perplexity is 54.75442543564633
At time: 274.8430564403534 and batch: 150, loss is 3.974393925666809 and perplexity is 53.217853154742926
At time: 275.8844883441925 and batch: 200, loss is 3.9800252151489257 and perplexity is 53.518383684492576
At time: 276.9264543056488 and batch: 250, loss is 3.9639844846725465 and perplexity is 52.666758323267395
At time: 277.9682092666626 and batch: 300, loss is 3.9794012832641603 and perplexity is 53.485002273437
At time: 279.0201711654663 and batch: 350, loss is 3.989145817756653 and perplexity is 54.00873635101434
At time: 280.08534812927246 and batch: 400, loss is 3.954186134338379 and perplexity is 52.15323094337892
At time: 281.13415122032166 and batch: 450, loss is 3.989702568054199 and perplexity is 54.03881410316966
At time: 282.18220043182373 and batch: 500, loss is 4.00910135269165 and perplexity is 55.09733523739536
At time: 283.22800040245056 and batch: 550, loss is 3.980004687309265 and perplexity is 53.51728507896945
At time: 284.2779676914215 and batch: 600, loss is 3.963854584693909 and perplexity is 52.65991735681661
At time: 285.3270606994629 and batch: 650, loss is 4.011175975799561 and perplexity is 55.21176009544951
At time: 286.3805854320526 and batch: 700, loss is 4.041682667732239 and perplexity is 56.922043152211394
At time: 287.44025564193726 and batch: 750, loss is 4.0142988586425785 and perplexity is 55.38444945776319
At time: 288.5462465286255 and batch: 800, loss is 3.9848265075683593 and perplexity is 53.77595894664341
At time: 289.6135108470917 and batch: 850, loss is 3.9764333009719848 and perplexity is 53.32649507343027
At time: 290.69057536125183 and batch: 900, loss is 3.960419945716858 and perplexity is 52.47935980463702
At time: 291.75447034835815 and batch: 950, loss is 4.053251438140869 and perplexity is 57.58438505422009
At time: 292.8195605278015 and batch: 1000, loss is 4.036879534721375 and perplexity is 56.64929455595527
At time: 293.887357711792 and batch: 1050, loss is 3.976271448135376 and perplexity is 53.31786472737807
At time: 294.9740569591522 and batch: 1100, loss is 4.004206504821777 and perplexity is 54.82830114102048
At time: 296.0513536930084 and batch: 1150, loss is 3.9797632360458373 and perplexity is 53.50436482274076
At time: 297.11579990386963 and batch: 1200, loss is 4.06273732662201 and perplexity is 58.13322310189714
At time: 298.2092185020447 and batch: 1250, loss is 4.053326535224914 and perplexity is 57.58870963600393
At time: 299.27303075790405 and batch: 1300, loss is 4.050981540679931 and perplexity is 57.453822642498814
At time: 300.33736848831177 and batch: 1350, loss is 3.9263542461395264 and perplexity is 50.72172126366164
At time: 301.40195870399475 and batch: 1400, loss is 3.9614778184890747 and perplexity is 52.53490566552453
At time: 302.51744842529297 and batch: 1450, loss is 3.8942776584625243 and perplexity is 49.120558724690696
At time: 303.6003863811493 and batch: 1500, loss is 3.901007556915283 and perplexity is 49.4522499691476
At time: 304.68117451667786 and batch: 1550, loss is 3.9081267786026 and perplexity is 49.80556768089769
At time: 305.75208139419556 and batch: 1600, loss is 3.994539136886597 and perplexity is 54.30080961614184
At time: 306.8168888092041 and batch: 1650, loss is 3.9497872591018677 and perplexity is 51.92431923342615
At time: 307.8784546852112 and batch: 1700, loss is 3.974594974517822 and perplexity is 53.22855361859501
At time: 308.9406268596649 and batch: 1750, loss is 3.977236032485962 and perplexity is 53.3693191173609
At time: 310.0206136703491 and batch: 1800, loss is 3.9356019258499146 and perplexity is 51.19295504751364
At time: 311.0843315124512 and batch: 1850, loss is 3.968590273857117 and perplexity is 52.90988978546715
At time: 312.17946195602417 and batch: 1900, loss is 4.043878479003906 and perplexity is 57.047170543963894
At time: 313.26670694351196 and batch: 1950, loss is 3.9804407072067263 and perplexity is 53.54062476803663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344473621457122 and perplexity of 77.05146856318648
finished 7 epochs...
Completing Train Step...
At time: 316.62657499313354 and batch: 50, loss is 3.9628730154037477 and perplexity is 52.60825335916158
At time: 317.6724810600281 and batch: 100, loss is 3.939797396659851 and perplexity is 51.40818477540467
At time: 318.7274115085602 and batch: 150, loss is 3.91237539768219 and perplexity is 50.017622717574405
At time: 319.7512528896332 and batch: 200, loss is 3.9211687707901 and perplexity is 50.45938578328318
At time: 320.77972531318665 and batch: 250, loss is 3.905103340148926 and perplexity is 49.65521102394981
At time: 321.811053276062 and batch: 300, loss is 3.9164414548873903 and perplexity is 50.22141125998124
At time: 322.8652994632721 and batch: 350, loss is 3.9249700355529784 and perplexity is 50.65156029010432
At time: 323.9064886569977 and batch: 400, loss is 3.8875842094421387 and perplexity is 48.79287067407434
At time: 324.94643449783325 and batch: 450, loss is 3.926159620285034 and perplexity is 50.711850465906764
At time: 325.9865052700043 and batch: 500, loss is 3.947402172088623 and perplexity is 51.80062278598484
At time: 327.02610874176025 and batch: 550, loss is 3.9171641206741334 and perplexity is 50.2577176727819
At time: 328.0947744846344 and batch: 600, loss is 3.906236562728882 and perplexity is 49.711513325789255
At time: 329.1348989009857 and batch: 650, loss is 3.9531825494766237 and perplexity is 52.10091700544141
At time: 330.17467045783997 and batch: 700, loss is 3.9789840269088743 and perplexity is 53.462689971624506
At time: 331.22290897369385 and batch: 750, loss is 3.955026721954346 and perplexity is 52.197088734017974
At time: 332.27190494537354 and batch: 800, loss is 3.9233737182617188 and perplexity is 50.57076883014247
At time: 333.32398676872253 and batch: 850, loss is 3.9196048641204833 and perplexity is 50.38053368804217
At time: 334.3888099193573 and batch: 900, loss is 3.8987876653671263 and perplexity is 49.3425930956188
At time: 335.4528970718384 and batch: 950, loss is 3.998149209022522 and perplexity is 54.49719372300808
At time: 336.52069902420044 and batch: 1000, loss is 3.9780988693237305 and perplexity is 53.41538800401008
At time: 337.5975136756897 and batch: 1050, loss is 3.9275752782821653 and perplexity is 50.78369194205021
At time: 338.6736946105957 and batch: 1100, loss is 3.945200982093811 and perplexity is 51.6867251745131
At time: 339.75011372566223 and batch: 1150, loss is 3.921873288154602 and perplexity is 50.49494782233571
At time: 340.8488574028015 and batch: 1200, loss is 4.001251230239868 and perplexity is 54.66650764614455
At time: 341.92512917518616 and batch: 1250, loss is 3.9973649072647093 and perplexity is 54.454468235202995
At time: 343.0007121562958 and batch: 1300, loss is 3.9979339122772215 and perplexity is 54.485461917526585
At time: 344.07718873023987 and batch: 1350, loss is 3.8742774438858034 and perplexity is 48.147896162609605
At time: 345.1526515483856 and batch: 1400, loss is 3.9113983297348023 and perplexity is 49.96877596879484
At time: 346.2277019023895 and batch: 1450, loss is 3.839974036216736 and perplexity is 46.5242664781363
At time: 347.30515241622925 and batch: 1500, loss is 3.847897562980652 and perplexity is 46.89436706338256
At time: 348.3821487426758 and batch: 1550, loss is 3.848313374519348 and perplexity is 46.91387033686944
At time: 349.45836877822876 and batch: 1600, loss is 3.9387300300598143 and perplexity is 51.353342669529596
At time: 350.53441762924194 and batch: 1650, loss is 3.889677715301514 and perplexity is 48.895125833267
At time: 351.61109137535095 and batch: 1700, loss is 3.919041185379028 and perplexity is 50.35214325451269
At time: 352.69083762168884 and batch: 1750, loss is 3.919954471588135 and perplexity is 50.39815017809259
At time: 353.7884018421173 and batch: 1800, loss is 3.880491304397583 and perplexity is 48.448011946435244
At time: 354.85973167419434 and batch: 1850, loss is 3.9134611654281617 and perplexity is 50.07195973240228
At time: 355.92544054985046 and batch: 1900, loss is 3.9849604892730714 and perplexity is 53.783164423985895
At time: 357.0069725513458 and batch: 1950, loss is 3.9277534961700438 and perplexity is 50.792743310900754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344403218114099 and perplexity of 77.04604407316815
finished 8 epochs...
Completing Train Step...
At time: 360.3158493041992 and batch: 50, loss is 3.9110032749176025 and perplexity is 49.94903946189653
At time: 361.3363153934479 and batch: 100, loss is 3.8867777967453003 and perplexity is 48.753539344420815
At time: 362.3471853733063 and batch: 150, loss is 3.862439999580383 and perplexity is 47.58130821607551
At time: 363.3601088523865 and batch: 200, loss is 3.865622420310974 and perplexity is 47.73297316056003
At time: 364.3837640285492 and batch: 250, loss is 3.852611427307129 and perplexity is 47.115942575553184
At time: 365.40707325935364 and batch: 300, loss is 3.86188955783844 and perplexity is 47.55512468481251
At time: 366.4647595882416 and batch: 350, loss is 3.866466064453125 and perplexity is 47.77325979515657
At time: 367.53013277053833 and batch: 400, loss is 3.837008843421936 and perplexity is 46.38651738562864
At time: 368.56984877586365 and batch: 450, loss is 3.877730631828308 and perplexity is 48.31444729777786
At time: 369.6087017059326 and batch: 500, loss is 3.899624218940735 and perplexity is 49.38388808853275
At time: 370.6877326965332 and batch: 550, loss is 3.866234221458435 and perplexity is 47.76218518337475
At time: 371.74327516555786 and batch: 600, loss is 3.8609733104705812 and perplexity is 47.511572382379974
At time: 372.78370690345764 and batch: 650, loss is 3.9024487781524657 and perplexity is 49.52357298580723
At time: 373.8331995010376 and batch: 700, loss is 3.92982795715332 and perplexity is 50.898220241195375
At time: 374.89911246299744 and batch: 750, loss is 3.9033626985549925 and perplexity is 49.56885427816168
At time: 376.0141820907593 and batch: 800, loss is 3.8773616790771483 and perplexity is 48.296624837551626
At time: 377.0491464138031 and batch: 850, loss is 3.870672221183777 and perplexity is 47.974624802905545
At time: 378.0979950428009 and batch: 900, loss is 3.8474405193328858 and perplexity is 46.87293918791041
At time: 379.153847694397 and batch: 950, loss is 3.9469468784332276 and perplexity is 51.77704365920557
At time: 380.2130517959595 and batch: 1000, loss is 3.9279592847824096 and perplexity is 50.80319695464849
At time: 381.27180767059326 and batch: 1050, loss is 3.8756534242630005 and perplexity is 48.21419232358097
At time: 382.33582973480225 and batch: 1100, loss is 3.8976376628875733 and perplexity is 49.285881606637844
At time: 383.39966678619385 and batch: 1150, loss is 3.8775965547561646 and perplexity is 48.30796987238877
At time: 384.4635388851166 and batch: 1200, loss is 3.9564874172210693 and perplexity is 52.27338848624568
At time: 385.5276472568512 and batch: 1250, loss is 3.951014280319214 and perplexity is 51.98807057895005
At time: 386.59135818481445 and batch: 1300, loss is 3.9545618152618407 and perplexity is 52.172827598155436
At time: 387.654732465744 and batch: 1350, loss is 3.8279691410064696 and perplexity is 45.96908663980139
At time: 388.7184009552002 and batch: 1400, loss is 3.8649337482452393 and perplexity is 47.70011211187177
At time: 389.7823431491852 and batch: 1450, loss is 3.792759370803833 and perplexity is 44.378688736798566
At time: 390.8461046218872 and batch: 1500, loss is 3.799650959968567 and perplexity is 44.68558471309245
At time: 391.909227848053 and batch: 1550, loss is 3.8036785697937012 and perplexity is 44.86592373695411
At time: 392.97336769104004 and batch: 1600, loss is 3.8977822828292847 and perplexity is 49.29300984339316
At time: 394.0363485813141 and batch: 1650, loss is 3.8492215347290037 and perplexity is 46.956494999271925
At time: 395.09922671318054 and batch: 1700, loss is 3.873384461402893 and perplexity is 48.104920126027146
At time: 396.1647455692291 and batch: 1750, loss is 3.8720641136169434 and perplexity is 48.04144681389022
At time: 397.22863006591797 and batch: 1800, loss is 3.8351635360717773 and perplexity is 46.3009989323309
At time: 398.30559253692627 and batch: 1850, loss is 3.8679155826568605 and perplexity is 47.842558217410115
At time: 399.3691062927246 and batch: 1900, loss is 3.937635898590088 and perplexity is 51.29718608818286
At time: 400.4340898990631 and batch: 1950, loss is 3.8802582168579103 and perplexity is 48.4367206345118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348157873819041 and perplexity of 77.33586919838798
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 403.7940435409546 and batch: 50, loss is 3.8947340631484986 and perplexity is 49.14298269468356
At time: 404.84966492652893 and batch: 100, loss is 3.896456699371338 and perplexity is 49.22771113395862
At time: 405.8914084434509 and batch: 150, loss is 3.875180516242981 and perplexity is 48.1913968358617
At time: 406.93329334259033 and batch: 200, loss is 3.8772551155090333 and perplexity is 48.29147845109455
At time: 407.97582626342773 and batch: 250, loss is 3.8644226884841917 and perplexity is 47.67574073212013
At time: 409.01760506629944 and batch: 300, loss is 3.86248815536499 and perplexity is 47.58359958647622
At time: 410.059698343277 and batch: 350, loss is 3.8612179374694824 and perplexity is 47.52319641746339
At time: 411.1278266906738 and batch: 400, loss is 3.817196569442749 and perplexity is 45.47653912917445
At time: 412.1700026988983 and batch: 450, loss is 3.8598245906829836 and perplexity is 47.45702623416241
At time: 413.2120096683502 and batch: 500, loss is 3.875120677947998 and perplexity is 48.18851323111805
At time: 414.25413703918457 and batch: 550, loss is 3.840966987609863 and perplexity is 46.5704857563008
At time: 415.29679131507874 and batch: 600, loss is 3.819603796005249 and perplexity is 45.586143330281594
At time: 416.33724331855774 and batch: 650, loss is 3.8512158584594727 and perplexity is 47.0502348943277
At time: 417.38593196868896 and batch: 700, loss is 3.882908511161804 and perplexity is 48.56526246090344
At time: 418.4627938270569 and batch: 750, loss is 3.847324781417847 and perplexity is 46.86751452558266
At time: 419.5183961391449 and batch: 800, loss is 3.810952515602112 and perplexity is 45.19346585246575
At time: 420.5604615211487 and batch: 850, loss is 3.8118706560134887 and perplexity is 45.23497885426112
At time: 421.6019694805145 and batch: 900, loss is 3.770890598297119 and perplexity is 43.41871625661335
At time: 422.6717178821564 and batch: 950, loss is 3.869596228599548 and perplexity is 47.92303222398028
At time: 423.71369981765747 and batch: 1000, loss is 3.8369718313217165 and perplexity is 46.38480055497029
At time: 424.760648727417 and batch: 1050, loss is 3.781698160171509 and perplexity is 43.89051160551002
At time: 425.8090717792511 and batch: 1100, loss is 3.7979007959365845 and perplexity is 44.607446007700716
At time: 426.8590598106384 and batch: 1150, loss is 3.772837743759155 and perplexity is 43.50334117471541
At time: 427.9090437889099 and batch: 1200, loss is 3.833319888114929 and perplexity is 46.21571483133554
At time: 428.9961607456207 and batch: 1250, loss is 3.8278855371475218 and perplexity is 45.9652436074144
At time: 430.0440480709076 and batch: 1300, loss is 3.8308232259750366 and perplexity is 46.100473724763184
At time: 431.09407234191895 and batch: 1350, loss is 3.701240463256836 and perplexity is 40.4975088869619
At time: 432.1413037776947 and batch: 1400, loss is 3.7262742280960084 and perplexity is 41.52411023660858
At time: 433.18899416923523 and batch: 1450, loss is 3.6481145238876342 and perplexity is 38.40219133141059
At time: 434.2379415035248 and batch: 1500, loss is 3.642089080810547 and perplexity is 38.1714968297668
At time: 435.2841341495514 and batch: 1550, loss is 3.64351601600647 and perplexity is 38.226003961898186
At time: 436.3303985595703 and batch: 1600, loss is 3.723839898109436 and perplexity is 41.42314978527825
At time: 437.40390372276306 and batch: 1650, loss is 3.6691812658309937 and perplexity is 39.21978213596787
At time: 438.4670581817627 and batch: 1700, loss is 3.682051191329956 and perplexity is 39.727799873252415
At time: 439.5228409767151 and batch: 1750, loss is 3.671222620010376 and perplexity is 39.299925374682665
At time: 440.569048166275 and batch: 1800, loss is 3.6321308326721193 and perplexity is 37.79326199637026
At time: 441.61931467056274 and batch: 1850, loss is 3.6541242027282714 and perplexity is 38.63367103073366
At time: 442.6759202480316 and batch: 1900, loss is 3.720567851066589 and perplexity is 41.28783279302867
At time: 443.7333278656006 and batch: 1950, loss is 3.6535530519485473 and perplexity is 38.61161167960832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.281388819494913 and perplexity of 72.34083864038045
finished 10 epochs...
Completing Train Step...
At time: 447.0295057296753 and batch: 50, loss is 3.8073469543457032 and perplexity is 45.03081144936215
At time: 448.06450963020325 and batch: 100, loss is 3.798891935348511 and perplexity is 44.65168012297068
At time: 449.09407806396484 and batch: 150, loss is 3.7699575853347778 and perplexity is 43.37822492394419
At time: 450.13164925575256 and batch: 200, loss is 3.7689560508728026 and perplexity is 43.3348018852481
At time: 451.1757686138153 and batch: 250, loss is 3.7589001178741457 and perplexity is 42.90121374140295
At time: 452.2239422798157 and batch: 300, loss is 3.7542997074127196 and perplexity is 42.70430382938837
At time: 453.2699887752533 and batch: 350, loss is 3.7597935247421264 and perplexity is 42.93955910686012
At time: 454.3277516365051 and batch: 400, loss is 3.721361584663391 and perplexity is 41.320617342433565
At time: 455.3771061897278 and batch: 450, loss is 3.7671285915374755 and perplexity is 43.25568161355712
At time: 456.4223246574402 and batch: 500, loss is 3.7849783182144163 and perplexity is 44.03471579713334
At time: 457.470086812973 and batch: 550, loss is 3.7554341459274294 and perplexity is 42.75277672595818
At time: 458.5185720920563 and batch: 600, loss is 3.7361277961730956 and perplexity is 41.93529336724555
At time: 459.56685185432434 and batch: 650, loss is 3.7674152421951295 and perplexity is 43.26808266043813
At time: 460.6149706840515 and batch: 700, loss is 3.802690100669861 and perplexity is 44.82159706800856
At time: 461.6632158756256 and batch: 750, loss is 3.7716431283950804 and perplexity is 43.45140244453888
At time: 462.71135544776917 and batch: 800, loss is 3.7344092321395874 and perplexity is 41.863286772024736
At time: 463.7607972621918 and batch: 850, loss is 3.73891318321228 and perplexity is 42.05226221600867
At time: 464.8096663951874 and batch: 900, loss is 3.6995111465454102 and perplexity is 40.427536387816566
At time: 465.85775804519653 and batch: 950, loss is 3.801207718849182 and perplexity is 44.75520356975663
At time: 466.905268907547 and batch: 1000, loss is 3.771194882392883 and perplexity is 43.431929891676276
At time: 467.9540500640869 and batch: 1050, loss is 3.718459544181824 and perplexity is 41.20087706778074
At time: 469.00315737724304 and batch: 1100, loss is 3.73600088596344 and perplexity is 41.9299716880672
At time: 470.05031275749207 and batch: 1150, loss is 3.713795294761658 and perplexity is 41.009153371958064
At time: 471.0977518558502 and batch: 1200, loss is 3.777883310317993 and perplexity is 43.723394859060754
At time: 472.15505266189575 and batch: 1250, loss is 3.77393581867218 and perplexity is 43.55113733937421
At time: 473.2045600414276 and batch: 1300, loss is 3.7795181846618653 and perplexity is 43.79493557965255
At time: 474.2540719509125 and batch: 1350, loss is 3.6526919841766357 and perplexity is 38.5783787751143
At time: 475.3030912876129 and batch: 1400, loss is 3.6821805238723755 and perplexity is 39.73293830289069
At time: 476.3521249294281 and batch: 1450, loss is 3.603224596977234 and perplexity is 36.71643947921241
At time: 477.4080476760864 and batch: 1500, loss is 3.6025009107589723 and perplexity is 36.6898779102576
At time: 478.4565534591675 and batch: 1550, loss is 3.605605707168579 and perplexity is 36.803969535445084
At time: 479.50486421585083 and batch: 1600, loss is 3.6911616420745847 and perplexity is 40.0913917653523
At time: 480.5536379814148 and batch: 1650, loss is 3.637529745101929 and perplexity is 37.99785630473909
At time: 481.6020185947418 and batch: 1700, loss is 3.654153366088867 and perplexity is 38.63479773484223
At time: 482.6510889530182 and batch: 1750, loss is 3.6467404174804687 and perplexity is 38.34945887255501
At time: 483.6998972892761 and batch: 1800, loss is 3.6115191411972045 and perplexity is 37.02225214510246
At time: 484.74749875068665 and batch: 1850, loss is 3.6371785306930544 and perplexity is 37.98451325337163
At time: 485.79574942588806 and batch: 1900, loss is 3.709114661216736 and perplexity is 40.81765307401649
At time: 486.84400701522827 and batch: 1950, loss is 3.642494239807129 and perplexity is 38.18696548854191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.285460574127907 and perplexity of 72.63599327611166
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 490.2094316482544 and batch: 50, loss is 3.7854495906829833 and perplexity is 44.055473037123384
At time: 491.2513861656189 and batch: 100, loss is 3.8065147686004637 and perplexity is 44.99335303831704
At time: 492.2723503112793 and batch: 150, loss is 3.792562794685364 and perplexity is 44.36996580381218
At time: 493.29466581344604 and batch: 200, loss is 3.7950968456268313 and perplexity is 44.48254413680288
At time: 494.31709718704224 and batch: 250, loss is 3.7928125858306885 and perplexity is 44.38105041274927
At time: 495.3773467540741 and batch: 300, loss is 3.785279841423035 and perplexity is 44.04799528786781
At time: 496.41216111183167 and batch: 350, loss is 3.794241886138916 and perplexity is 44.44452961639954
At time: 497.45210552215576 and batch: 400, loss is 3.753055047988892 and perplexity is 42.65118457973405
At time: 498.49150228500366 and batch: 450, loss is 3.7962457752227783 and perplexity is 44.5336808188632
At time: 499.5324010848999 and batch: 500, loss is 3.810795617103577 and perplexity is 45.186375621767716
At time: 500.59889245033264 and batch: 550, loss is 3.787369422912598 and perplexity is 44.140133394989654
At time: 501.63882327079773 and batch: 600, loss is 3.7596513080596923 and perplexity is 42.93345281943703
At time: 502.7095730304718 and batch: 650, loss is 3.7807831287384035 and perplexity is 43.85036877655196
At time: 503.7769453525543 and batch: 700, loss is 3.815093603134155 and perplexity is 45.38100398835398
At time: 504.81614112854004 and batch: 750, loss is 3.7765423917770384 and perplexity is 43.664804639355786
At time: 505.8565249443054 and batch: 800, loss is 3.7367072916030883 and perplexity is 41.95960172071688
At time: 506.94392490386963 and batch: 850, loss is 3.7405418062210085 and perplexity is 42.12080529809265
At time: 508.00023126602173 and batch: 900, loss is 3.6979199981689455 and perplexity is 40.36326132806782
At time: 509.03968238830566 and batch: 950, loss is 3.8061454486846924 and perplexity is 44.976739165068636
At time: 510.0792303085327 and batch: 1000, loss is 3.769641146659851 and perplexity is 43.364500547504846
At time: 511.1197967529297 and batch: 1050, loss is 3.711292405128479 and perplexity is 40.90664033004858
At time: 512.1590807437897 and batch: 1100, loss is 3.725163516998291 and perplexity is 41.47801455077978
At time: 513.1994962692261 and batch: 1150, loss is 3.707612566947937 and perplexity is 40.75638713639454
At time: 514.2388257980347 and batch: 1200, loss is 3.764485673904419 and perplexity is 43.14151134765198
At time: 515.2851631641388 and batch: 1250, loss is 3.7557017326354982 and perplexity is 42.76421833148559
At time: 516.3434572219849 and batch: 1300, loss is 3.762176904678345 and perplexity is 43.042022446535896
At time: 517.3837070465088 and batch: 1350, loss is 3.6308393907546996 and perplexity is 37.74448569629056
At time: 518.4234039783478 and batch: 1400, loss is 3.659874048233032 and perplexity is 38.856448524763344
At time: 519.4712359905243 and batch: 1450, loss is 3.5722822904586793 and perplexity is 35.597744904012714
At time: 520.5183017253876 and batch: 1500, loss is 3.572999243736267 and perplexity is 35.6232759750953
At time: 521.5659058094025 and batch: 1550, loss is 3.5754632711410523 and perplexity is 35.71116093435458
At time: 522.6283600330353 and batch: 1600, loss is 3.6556364917755126 and perplexity is 38.69214050852019
At time: 523.6876118183136 and batch: 1650, loss is 3.5990177249908446 and perplexity is 36.56230256298809
At time: 524.7355091571808 and batch: 1700, loss is 3.6064710283279418 and perplexity is 36.835830572059145
At time: 525.7823586463928 and batch: 1750, loss is 3.5977909421920775 and perplexity is 36.51747606093329
At time: 526.8392159938812 and batch: 1800, loss is 3.5610332441329957 and perplexity is 35.19954808871977
At time: 527.9008955955505 and batch: 1850, loss is 3.5762659406661985 and perplexity is 35.739836701986974
At time: 528.9640717506409 and batch: 1900, loss is 3.656332426071167 and perplexity is 38.71907706802297
At time: 530.0261902809143 and batch: 1950, loss is 3.598074026107788 and perplexity is 36.52781503437798
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2632449127906975 and perplexity of 71.04012887426275
finished 12 epochs...
Completing Train Step...
At time: 533.3948128223419 and batch: 50, loss is 3.7843577098846435 and perplexity is 44.007395964045315
At time: 534.4368014335632 and batch: 100, loss is 3.782190623283386 and perplexity is 43.912131386472524
At time: 535.4885165691376 and batch: 150, loss is 3.7563544702529907 and perplexity is 42.792141257653945
At time: 536.5490732192993 and batch: 200, loss is 3.754299831390381 and perplexity is 42.704309123768425
At time: 537.6037096977234 and batch: 250, loss is 3.7487847089767454 and perplexity is 42.4694378984718
At time: 538.6457424163818 and batch: 300, loss is 3.7395284032821654 and perplexity is 42.07814157164126
At time: 539.6877117156982 and batch: 350, loss is 3.749218215942383 and perplexity is 42.48785268680862
At time: 540.7308735847473 and batch: 400, loss is 3.7083278560638426 and perplexity is 40.78555016527199
At time: 541.7723186016083 and batch: 450, loss is 3.7523677825927733 and perplexity is 42.621881966958206
At time: 542.8311553001404 and batch: 500, loss is 3.767216992378235 and perplexity is 43.259505621199644
At time: 543.8828310966492 and batch: 550, loss is 3.744222469329834 and perplexity is 42.27612345382547
At time: 544.9240138530731 and batch: 600, loss is 3.721426181793213 and perplexity is 41.323286621929334
At time: 545.9766108989716 and batch: 650, loss is 3.744046449661255 and perplexity is 42.268682679466856
At time: 547.0373156070709 and batch: 700, loss is 3.7797986602783205 and perplexity is 43.80722071396664
At time: 548.0790050029755 and batch: 750, loss is 3.7433207607269288 and perplexity is 42.23801989134649
At time: 549.1206789016724 and batch: 800, loss is 3.7045076656341553 and perplexity is 40.6300388274491
At time: 550.1634855270386 and batch: 850, loss is 3.7079746532440185 and perplexity is 40.77114713769026
At time: 551.2370262145996 and batch: 900, loss is 3.6662830400466917 and perplexity is 39.10627891056347
At time: 552.2784423828125 and batch: 950, loss is 3.777018804550171 and perplexity is 43.68561206609069
At time: 553.3205196857452 and batch: 1000, loss is 3.74068913936615 and perplexity is 42.12701154599489
At time: 554.3890597820282 and batch: 1050, loss is 3.6851082754135134 and perplexity is 39.84943693054303
At time: 555.43204164505 and batch: 1100, loss is 3.700808634757996 and perplexity is 40.48002468385277
At time: 556.4752326011658 and batch: 1150, loss is 3.684307312965393 and perplexity is 39.81753180709152
At time: 557.5167758464813 and batch: 1200, loss is 3.7426809597015382 and perplexity is 42.21100460603471
At time: 558.5587024688721 and batch: 1250, loss is 3.7361596202850342 and perplexity is 41.936627941951556
At time: 559.6006224155426 and batch: 1300, loss is 3.743902244567871 and perplexity is 42.26258775960366
At time: 560.6452419757843 and batch: 1350, loss is 3.6152262687683105 and perplexity is 37.15975306603098
At time: 561.7129230499268 and batch: 1400, loss is 3.6461357736587523 and perplexity is 38.32627811793781
At time: 562.7582428455353 and batch: 1450, loss is 3.560642147064209 and perplexity is 35.185784340295925
At time: 563.8067910671234 and batch: 1500, loss is 3.56444625377655 and perplexity is 35.31988973257286
At time: 564.8580515384674 and batch: 1550, loss is 3.5679569673538207 and perplexity is 35.4441056647032
At time: 565.9072997570038 and batch: 1600, loss is 3.6500546312332154 and perplexity is 38.47676802490218
At time: 566.95738530159 and batch: 1650, loss is 3.5950695943832396 and perplexity is 36.418234404249496
At time: 568.0014810562134 and batch: 1700, loss is 3.6049126291275027 and perplexity is 36.778470349819166
At time: 569.0510787963867 and batch: 1750, loss is 3.5980739831924438 and perplexity is 36.52781346677426
At time: 570.0980253219604 and batch: 1800, loss is 3.562848000526428 and perplexity is 35.26348469079131
At time: 571.1450805664062 and batch: 1850, loss is 3.579819750785828 and perplexity is 35.8670752522422
At time: 572.1916997432709 and batch: 1900, loss is 3.6605181741714476 and perplexity is 38.881485033599596
At time: 573.2378289699554 and batch: 1950, loss is 3.6024582290649416 and perplexity is 36.68831195753361
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.263392532703488 and perplexity of 71.0506165859703
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 576.5877728462219 and batch: 50, loss is 3.7795361995697023 and perplexity is 43.79572454848733
At time: 577.6390390396118 and batch: 100, loss is 3.792708992958069 and perplexity is 44.37645309037616
At time: 578.6609439849854 and batch: 150, loss is 3.774124040603638 and perplexity is 43.55933539006367
At time: 579.6851184368134 and batch: 200, loss is 3.780274395942688 and perplexity is 43.828066329325274
At time: 580.7135472297668 and batch: 250, loss is 3.7787491989135744 and perplexity is 43.76127084385445
At time: 581.7423377037048 and batch: 300, loss is 3.7696627044677733 and perplexity is 43.36543540115496
At time: 582.8018622398376 and batch: 350, loss is 3.782752857208252 and perplexity is 43.936827218217815
At time: 583.8400647640228 and batch: 400, loss is 3.74642050743103 and perplexity is 42.36915018464335
At time: 584.8925094604492 and batch: 450, loss is 3.79390784740448 and perplexity is 44.42968590129979
At time: 585.9300444126129 and batch: 500, loss is 3.805872206687927 and perplexity is 44.96445130990668
At time: 586.9688239097595 and batch: 550, loss is 3.782090630531311 and perplexity is 43.90774071112721
At time: 588.0068411827087 and batch: 600, loss is 3.752943606376648 and perplexity is 42.646431727798046
At time: 589.0487968921661 and batch: 650, loss is 3.767053451538086 and perplexity is 43.252431503775234
At time: 590.0951719284058 and batch: 700, loss is 3.797378921508789 and perplexity is 44.58417259576751
At time: 591.1416680812836 and batch: 750, loss is 3.7567902755737306 and perplexity is 42.810794364766316
At time: 592.1889417171478 and batch: 800, loss is 3.7180127096176148 and perplexity is 41.18247120432536
At time: 593.2387003898621 and batch: 850, loss is 3.718687744140625 and perplexity is 41.21028017908419
At time: 594.2901468276978 and batch: 900, loss is 3.6706525564193724 and perplexity is 39.2775283025816
At time: 595.3400583267212 and batch: 950, loss is 3.7877551794052122 and perplexity is 44.157164022658044
At time: 596.3890700340271 and batch: 1000, loss is 3.7522861671447756 and perplexity is 42.61840350491702
At time: 597.4493880271912 and batch: 1050, loss is 3.6949182462692263 and perplexity is 40.2422824967559
At time: 598.4986164569855 and batch: 1100, loss is 3.708565311431885 and perplexity is 40.795236063035986
At time: 599.5748918056488 and batch: 1150, loss is 3.6946421480178833 and perplexity is 40.231173206626856
At time: 600.6403849124908 and batch: 1200, loss is 3.753199453353882 and perplexity is 42.6573440843326
At time: 601.6979410648346 and batch: 1250, loss is 3.7432358264923096 and perplexity is 42.2344325897997
At time: 602.7672357559204 and batch: 1300, loss is 3.7442289447784423 and perplexity is 42.27639721157661
At time: 603.8443105220795 and batch: 1350, loss is 3.609763889312744 and perplexity is 36.957325765002665
At time: 604.9194359779358 and batch: 1400, loss is 3.6375712871551515 and perplexity is 37.99943484649575
At time: 605.9772551059723 and batch: 1450, loss is 3.549853277206421 and perplexity is 34.80820995511137
At time: 607.0513753890991 and batch: 1500, loss is 3.550927929878235 and perplexity is 34.845636797766964
At time: 608.1151480674744 and batch: 1550, loss is 3.559560899734497 and perplexity is 35.14776036529935
At time: 609.1624522209167 and batch: 1600, loss is 3.642835884094238 and perplexity is 38.20001407600386
At time: 610.2110559940338 and batch: 1650, loss is 3.5837697696685793 and perplexity is 36.009031056236935
At time: 611.2868609428406 and batch: 1700, loss is 3.594594483375549 and perplexity is 36.400935809905086
At time: 612.3368780612946 and batch: 1750, loss is 3.5891871452331543 and perplexity is 36.204634852417136
At time: 613.3861050605774 and batch: 1800, loss is 3.5522088289260862 and perplexity is 34.89029913863147
At time: 614.4349925518036 and batch: 1850, loss is 3.5655960416793824 and perplexity is 35.36052347013016
At time: 615.4829738140106 and batch: 1900, loss is 3.6481318283081055 and perplexity is 38.40285586482607
At time: 616.532331943512 and batch: 1950, loss is 3.593215751647949 and perplexity is 36.35078326618584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247193234465843 and perplexity of 69.90891877624286
finished 14 epochs...
Completing Train Step...
At time: 619.8660929203033 and batch: 50, loss is 3.7805233430862426 and perplexity is 43.8389785594734
At time: 620.9112243652344 and batch: 100, loss is 3.7794273328781127 and perplexity is 43.79095691237306
At time: 621.9373569488525 and batch: 150, loss is 3.751903748512268 and perplexity is 42.60210854927493
At time: 622.9667854309082 and batch: 200, loss is 3.754016389846802 and perplexity is 42.69220666372391
At time: 624.0067234039307 and batch: 250, loss is 3.7520028352737427 and perplexity is 42.606330063387695
At time: 625.0551178455353 and batch: 300, loss is 3.7431034326553343 and perplexity is 42.2288413813456
At time: 626.0869271755219 and batch: 350, loss is 3.755627808570862 and perplexity is 42.7610571434909
At time: 627.1247997283936 and batch: 400, loss is 3.7197121477127073 and perplexity is 41.25251776778082
At time: 628.165376663208 and batch: 450, loss is 3.7670383501052855 and perplexity is 43.25177833501934
At time: 629.2084600925446 and batch: 500, loss is 3.780063009262085 and perplexity is 43.818802639011544
At time: 630.2491278648376 and batch: 550, loss is 3.7559212398529054 and perplexity is 42.77360641639463
At time: 631.290144443512 and batch: 600, loss is 3.7300800848007203 and perplexity is 41.68244616076043
At time: 632.3284070491791 and batch: 650, loss is 3.746023597717285 and perplexity is 42.35233679429165
At time: 633.3756682872772 and batch: 700, loss is 3.7786039400100706 and perplexity is 43.75491459129805
At time: 634.4307632446289 and batch: 750, loss is 3.740947947502136 and perplexity is 42.1379157703179
At time: 635.4720251560211 and batch: 800, loss is 3.703200225830078 and perplexity is 40.57695220878622
At time: 636.520510673523 and batch: 850, loss is 3.7039215898513795 and perplexity is 40.60623352217695
At time: 637.6292104721069 and batch: 900, loss is 3.6573361492156984 and perplexity is 38.757959812301806
At time: 638.6790323257446 and batch: 950, loss is 3.775405535697937 and perplexity is 43.615192247177
At time: 639.7279658317566 and batch: 1000, loss is 3.739334535598755 and perplexity is 42.06998477050817
At time: 640.7883243560791 and batch: 1050, loss is 3.6831164932250977 and perplexity is 39.770144524661276
At time: 641.8508067131042 and batch: 1100, loss is 3.697290925979614 and perplexity is 40.3378779077346
At time: 642.9211173057556 and batch: 1150, loss is 3.683979034423828 and perplexity is 39.80446271109042
At time: 643.9699094295502 and batch: 1200, loss is 3.743181781768799 and perplexity is 42.23215010324649
At time: 645.0193576812744 and batch: 1250, loss is 3.734889464378357 and perplexity is 41.883395700044815
At time: 646.0674350261688 and batch: 1300, loss is 3.737608275413513 and perplexity is 41.99742367848637
At time: 647.1169662475586 and batch: 1350, loss is 3.6049480485916137 and perplexity is 36.77977304660005
At time: 648.1653625965118 and batch: 1400, loss is 3.6343095445632936 and perplexity is 37.87569238911985
At time: 649.2140617370605 and batch: 1450, loss is 3.548402018547058 and perplexity is 34.757730876956444
At time: 650.2620482444763 and batch: 1500, loss is 3.5507344245910644 and perplexity is 34.838894635154865
At time: 651.3118557929993 and batch: 1550, loss is 3.5608501720428465 and perplexity is 35.19310462370616
At time: 652.3638710975647 and batch: 1600, loss is 3.6451099348068237 and perplexity is 38.286981692140884
At time: 653.4260942935944 and batch: 1650, loss is 3.587082448005676 and perplexity is 36.12851519034152
At time: 654.5023419857025 and batch: 1700, loss is 3.5989096927642823 and perplexity is 36.5583528693849
At time: 655.5520687103271 and batch: 1750, loss is 3.5943657684326173 and perplexity is 36.39261132395211
At time: 656.6009967327118 and batch: 1800, loss is 3.5576664304733274 and perplexity is 35.08123704677547
At time: 657.676854133606 and batch: 1850, loss is 3.5716342878341676 and perplexity is 35.57468494415239
At time: 658.7390534877777 and batch: 1900, loss is 3.653878984451294 and perplexity is 38.62419850995527
At time: 659.7880883216858 and batch: 1950, loss is 3.59808424949646 and perplexity is 36.52818847433733
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2460576966751455 and perplexity of 69.8295796119006
finished 15 epochs...
Completing Train Step...
At time: 663.1371586322784 and batch: 50, loss is 3.775699281692505 and perplexity is 43.62800591709189
At time: 664.1756143569946 and batch: 100, loss is 3.772570838928223 and perplexity is 43.49173147220594
At time: 665.2107610702515 and batch: 150, loss is 3.743818850517273 and perplexity is 42.25906345817656
At time: 666.2667317390442 and batch: 200, loss is 3.7451260089874268 and perplexity is 42.31433886990741
At time: 667.30894780159 and batch: 250, loss is 3.742568917274475 and perplexity is 42.20627544756802
At time: 668.3669948577881 and batch: 300, loss is 3.733336262702942 and perplexity is 41.81839283401958
At time: 669.4009811878204 and batch: 350, loss is 3.745695629119873 and perplexity is 42.3384488353278
At time: 670.4413750171661 and batch: 400, loss is 3.7095081758499147 and perplexity is 40.83371857859138
At time: 671.5083856582642 and batch: 450, loss is 3.757052683830261 and perplexity is 42.82202974474003
At time: 672.5494384765625 and batch: 500, loss is 3.7700391149520875 and perplexity is 43.38176167819496
At time: 673.5900492668152 and batch: 550, loss is 3.745551905632019 and perplexity is 42.33236424305075
At time: 674.6310319900513 and batch: 600, loss is 3.7207151556015017 and perplexity is 41.29391512600241
At time: 675.6923208236694 and batch: 650, loss is 3.7370320177078247 and perplexity is 41.97322931123738
At time: 676.7407088279724 and batch: 700, loss is 3.770400767326355 and perplexity is 43.39745363265104
At time: 677.7818806171417 and batch: 750, loss is 3.7334722566604612 and perplexity is 41.82408026947784
At time: 678.847357749939 and batch: 800, loss is 3.6957999515533446 and perplexity is 40.277779976736454
At time: 679.8877260684967 and batch: 850, loss is 3.696679368019104 and perplexity is 40.313216499099056
At time: 680.9510176181793 and batch: 900, loss is 3.6506462860107423 and perplexity is 38.49953972435601
At time: 681.991513967514 and batch: 950, loss is 3.7689551496505738 and perplexity is 43.33476283097895
At time: 683.0323388576508 and batch: 1000, loss is 3.732919840812683 and perplexity is 41.80098236512982
At time: 684.0738062858582 and batch: 1050, loss is 3.6773890256881714 and perplexity is 39.54301337699317
At time: 685.1180205345154 and batch: 1100, loss is 3.6917129278182985 and perplexity is 40.11349967140499
At time: 686.1681027412415 and batch: 1150, loss is 3.6788229370117187 and perplexity is 39.599755223307355
At time: 687.216668844223 and batch: 1200, loss is 3.73822874546051 and perplexity is 42.02348990775091
At time: 688.2646446228027 and batch: 1250, loss is 3.730664682388306 and perplexity is 41.70682074219725
At time: 689.3126010894775 and batch: 1300, loss is 3.7341024112701415 and perplexity is 41.85044421226291
At time: 690.3608198165894 and batch: 1350, loss is 3.6021186828613283 and perplexity is 36.67585669517963
At time: 691.4082989692688 and batch: 1400, loss is 3.6320898580551146 and perplexity is 37.79171346366009
At time: 692.4891679286957 and batch: 1450, loss is 3.5468815660476682 and perplexity is 34.70492355385788
At time: 693.5382554531097 and batch: 1500, loss is 3.549944314956665 and perplexity is 34.81137896048308
At time: 694.6123013496399 and batch: 1550, loss is 3.560610227584839 and perplexity is 35.184661246302944
At time: 695.6600468158722 and batch: 1600, loss is 3.6451808071136473 and perplexity is 38.28969527501253
At time: 696.7081096172333 and batch: 1650, loss is 3.5874722671508787 and perplexity is 36.14260152263308
At time: 697.7906970977783 and batch: 1700, loss is 3.599597840309143 and perplexity is 36.58351906819196
At time: 698.8650789260864 and batch: 1750, loss is 3.595336146354675 and perplexity is 36.42794305029804
At time: 699.9138391017914 and batch: 1800, loss is 3.558827977180481 and perplexity is 35.12200921695592
At time: 700.9641697406769 and batch: 1850, loss is 3.5730893182754517 and perplexity is 35.62648486978069
At time: 702.0140137672424 and batch: 1900, loss is 3.6551645851135253 and perplexity is 38.67388573726053
At time: 703.0686287879944 and batch: 1950, loss is 3.5989279317855836 and perplexity is 36.559019664042445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245967989189681 and perplexity of 69.82331565686857
finished 16 epochs...
Completing Train Step...
At time: 706.5080943107605 and batch: 50, loss is 3.7706397914886476 and perplexity is 43.4078279124536
At time: 707.5463271141052 and batch: 100, loss is 3.7667092084884644 and perplexity is 43.237544717334224
At time: 708.5616185665131 and batch: 150, loss is 3.7374765157699583 and perplexity is 41.991890477446574
At time: 709.6138575077057 and batch: 200, loss is 3.738401231765747 and perplexity is 42.030739009425666
At time: 710.6543266773224 and batch: 250, loss is 3.735658597946167 and perplexity is 41.915622017194075
At time: 711.6921558380127 and batch: 300, loss is 3.7262273168563844 and perplexity is 41.5221623348127
At time: 712.7168517112732 and batch: 350, loss is 3.738510546684265 and perplexity is 42.03533384737333
At time: 713.7488238811493 and batch: 400, loss is 3.7023112916946412 and perplexity is 40.54089799813931
At time: 714.7895381450653 and batch: 450, loss is 3.7500949478149415 and perplexity is 42.52511947555934
At time: 715.8544445037842 and batch: 500, loss is 3.7629930210113525 and perplexity is 43.077164081941014
At time: 716.915091753006 and batch: 550, loss is 3.7383061599731446 and perplexity is 42.026743261668095
At time: 717.9574358463287 and batch: 600, loss is 3.7141188383102417 and perplexity is 41.02242376562381
At time: 718.9967694282532 and batch: 650, loss is 3.7305842065811157 and perplexity is 41.70346448718316
At time: 720.0378181934357 and batch: 700, loss is 3.7644052600860594 and perplexity is 43.138042313475715
At time: 721.079540014267 and batch: 750, loss is 3.727899737358093 and perplexity is 41.59166295130529
At time: 722.1200633049011 and batch: 800, loss is 3.6902713918685914 and perplexity is 40.05571627798583
At time: 723.162425994873 and batch: 850, loss is 3.6912308979034423 and perplexity is 40.09416842406785
At time: 724.2052536010742 and batch: 900, loss is 3.6455226039886472 and perplexity is 38.30278481005588
At time: 725.2523238658905 and batch: 950, loss is 3.7639804887771606 and perplexity is 43.11972240194075
At time: 726.3051428794861 and batch: 1000, loss is 3.728106198310852 and perplexity is 41.600250892171765
At time: 727.3770067691803 and batch: 1050, loss is 3.673043041229248 and perplexity is 39.371532950935205
At time: 728.449657201767 and batch: 1100, loss is 3.687495565414429 and perplexity is 39.94468273731545
At time: 729.5003154277802 and batch: 1150, loss is 3.674929280281067 and perplexity is 39.44586715791983
At time: 730.5659506320953 and batch: 1200, loss is 3.734451565742493 and perplexity is 41.8650590332961
At time: 731.6272423267365 and batch: 1250, loss is 3.7273231840133665 and perplexity is 41.56769005041014
At time: 732.6758208274841 and batch: 1300, loss is 3.7311159420013427 and perplexity is 41.725645593114386
At time: 733.7317206859589 and batch: 1350, loss is 3.5994729089736937 and perplexity is 36.57894892578228
At time: 734.7967092990875 and batch: 1400, loss is 3.6297633695602416 and perplexity is 37.703893672562884
At time: 735.8661224842072 and batch: 1450, loss is 3.544927740097046 and perplexity is 34.63718237239292
At time: 736.9221103191376 and batch: 1500, loss is 3.5484897232055665 and perplexity is 34.760779425557544
At time: 737.9781763553619 and batch: 1550, loss is 3.559461531639099 and perplexity is 35.14426797281342
At time: 739.048172712326 and batch: 1600, loss is 3.64421808719635 and perplexity is 38.252850761063456
At time: 740.0952897071838 and batch: 1650, loss is 3.5867335605621338 and perplexity is 36.11591260360774
At time: 741.1427159309387 and batch: 1700, loss is 3.5990718364715577 and perplexity is 36.56428105684718
At time: 742.190860748291 and batch: 1750, loss is 3.595004024505615 and perplexity is 36.41584654336304
At time: 743.2400796413422 and batch: 1800, loss is 3.5586591005325316 and perplexity is 35.116078430569864
At time: 744.287103176117 and batch: 1850, loss is 3.5732133865356444 and perplexity is 35.63090525998465
At time: 745.3491015434265 and batch: 1900, loss is 3.6551876306533813 and perplexity is 38.674777008105536
At time: 746.397940158844 and batch: 1950, loss is 3.5986616516113283 and perplexity is 36.54928601791171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246201626090116 and perplexity of 69.83963086575996
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 749.7450563907623 and batch: 50, loss is 3.769625840187073 and perplexity is 43.36383679503754
At time: 750.7651863098145 and batch: 100, loss is 3.7705813598632814 and perplexity is 43.40529159661631
At time: 751.7807445526123 and batch: 150, loss is 3.7431190538406374 and perplexity is 42.22950105105435
At time: 752.8048090934753 and batch: 200, loss is 3.7452451038360595 and perplexity is 42.319378589786496
At time: 753.8541495800018 and batch: 250, loss is 3.743890686035156 and perplexity is 42.26209926892355
At time: 754.8790392875671 and batch: 300, loss is 3.7351264905929566 and perplexity is 41.893324339409595
At time: 755.9019289016724 and batch: 350, loss is 3.74809193611145 and perplexity is 42.440026413207164
At time: 756.92751121521 and batch: 400, loss is 3.7153979444503786 and perplexity is 41.07492937270917
At time: 757.98126745224 and batch: 450, loss is 3.7656439542770386 and perplexity is 43.19151026428306
At time: 759.0192065238953 and batch: 500, loss is 3.7802775382995604 and perplexity is 43.8282040529671
At time: 760.0861639976501 and batch: 550, loss is 3.7548619651794435 and perplexity is 42.72832140729111
At time: 761.145884513855 and batch: 600, loss is 3.7294932651519774 and perplexity is 41.657993257769306
At time: 762.1866145133972 and batch: 650, loss is 3.74317578792572 and perplexity is 42.231896971124506
At time: 763.2457811832428 and batch: 700, loss is 3.774593653678894 and perplexity is 43.579796227474674
At time: 764.2873365879059 and batch: 750, loss is 3.735476222038269 and perplexity is 41.90797831460835
At time: 765.3281164169312 and batch: 800, loss is 3.697363429069519 and perplexity is 40.340802634547714
At time: 766.389327287674 and batch: 850, loss is 3.6974110841751098 and perplexity is 40.34272512556476
At time: 767.4470059871674 and batch: 900, loss is 3.6494377660751343 and perplexity is 38.45304036644735
At time: 768.5360367298126 and batch: 950, loss is 3.7664602279663084 and perplexity is 43.22678075093835
At time: 769.586267709732 and batch: 1000, loss is 3.7318010711669922 and perplexity is 41.754242845152866
At time: 770.6356008052826 and batch: 1050, loss is 3.6761069965362547 and perplexity is 39.492350563630175
At time: 771.6842210292816 and batch: 1100, loss is 3.686723818778992 and perplexity is 39.91386745513395
At time: 772.7320022583008 and batch: 1150, loss is 3.6749848031997683 and perplexity is 39.448057368398025
At time: 773.7789862155914 and batch: 1200, loss is 3.7347046089172364 and perplexity is 41.87565404118539
At time: 774.8382589817047 and batch: 1250, loss is 3.728310966491699 and perplexity is 41.60877017207869
At time: 775.9206190109253 and batch: 1300, loss is 3.729194402694702 and perplexity is 41.64554510777414
At time: 776.9908609390259 and batch: 1350, loss is 3.5956920051574706 and perplexity is 36.44090856130901
At time: 778.0670397281647 and batch: 1400, loss is 3.625661587715149 and perplexity is 37.54955726952296
At time: 779.1171872615814 and batch: 1450, loss is 3.5401279020309446 and perplexity is 34.47132786175527
At time: 780.1668591499329 and batch: 1500, loss is 3.5419575071334837 and perplexity is 34.534454509911754
At time: 781.2138056755066 and batch: 1550, loss is 3.551919865608215 and perplexity is 34.88021857855705
At time: 782.2610983848572 and batch: 1600, loss is 3.6371465730667114 and perplexity is 37.98329937788665
At time: 783.3323571681976 and batch: 1650, loss is 3.5761474800109863 and perplexity is 35.73560318827143
At time: 784.4037294387817 and batch: 1700, loss is 3.5875415325164797 and perplexity is 36.14510503984383
At time: 785.4561939239502 and batch: 1750, loss is 3.5837594747543333 and perplexity is 36.00866034825834
At time: 786.5241084098816 and batch: 1800, loss is 3.5465340566635133 and perplexity is 34.69286536253521
At time: 787.5728230476379 and batch: 1850, loss is 3.561181859970093 and perplexity is 35.204779687764024
At time: 788.6220381259918 and batch: 1900, loss is 3.643140549659729 and perplexity is 38.211654077957945
At time: 789.670253276825 and batch: 1950, loss is 3.59070508480072 and perplexity is 36.25963303158475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243397983284884 and perplexity of 69.64409971499472
finished 18 epochs...
Completing Train Step...
At time: 793.003924369812 and batch: 50, loss is 3.7700377559661864 and perplexity is 43.38170272303253
At time: 794.0307681560516 and batch: 100, loss is 3.7673755168914793 and perplexity is 43.26636385685631
At time: 795.0726556777954 and batch: 150, loss is 3.737699341773987 and perplexity is 42.00124840515937
At time: 796.1147665977478 and batch: 200, loss is 3.737976908683777 and perplexity is 42.012908179995485
At time: 797.1427178382874 and batch: 250, loss is 3.7365798473358156 and perplexity is 41.954254550760844
At time: 798.1935231685638 and batch: 300, loss is 3.726962909698486 and perplexity is 41.552716976724966
At time: 799.2445025444031 and batch: 350, loss is 3.7401012229919433 and perplexity is 42.102251665193464
At time: 800.2767753601074 and batch: 400, loss is 3.706823525428772 and perplexity is 40.724241338625106
At time: 801.3165581226349 and batch: 450, loss is 3.757070288658142 and perplexity is 42.82278362583914
At time: 802.3483331203461 and batch: 500, loss is 3.7719451856613158 and perplexity is 43.464529238797354
At time: 803.3780522346497 and batch: 550, loss is 3.7462596702575683 and perplexity is 42.36233619827152
At time: 804.4161968231201 and batch: 600, loss is 3.721151204109192 and perplexity is 41.3119252024179
At time: 805.45645403862 and batch: 650, loss is 3.7353113412857057 and perplexity is 41.90106906522221
At time: 806.4969327449799 and batch: 700, loss is 3.767835602760315 and perplexity is 43.28627467945557
At time: 807.5374779701233 and batch: 750, loss is 3.7298871374130247 and perplexity is 41.67440441750257
At time: 808.5778410434723 and batch: 800, loss is 3.692078528404236 and perplexity is 40.12816787157676
At time: 809.6174786090851 and batch: 850, loss is 3.6919630432128905 and perplexity is 40.123533930012734
At time: 810.6568846702576 and batch: 900, loss is 3.644456453323364 and perplexity is 38.261970031766054
At time: 811.6978132724762 and batch: 950, loss is 3.762563719749451 and perplexity is 43.05867497002499
At time: 812.7382371425629 and batch: 1000, loss is 3.728018035888672 and perplexity is 41.59658347495638
At time: 813.7822318077087 and batch: 1050, loss is 3.6724297618865966 and perplexity is 39.34739460561872
At time: 814.8467466831207 and batch: 1100, loss is 3.683834490776062 and perplexity is 39.79870964464742
At time: 815.8866271972656 and batch: 1150, loss is 3.6722818756103517 and perplexity is 39.3415760962
At time: 816.9365811347961 and batch: 1200, loss is 3.7326191806793214 and perplexity is 41.78841636533952
At time: 817.9982891082764 and batch: 1250, loss is 3.7263928604125978 and perplexity is 41.52903663020923
At time: 819.0549674034119 and batch: 1300, loss is 3.727523307800293 and perplexity is 41.57600956639558
At time: 820.1134090423584 and batch: 1350, loss is 3.5943550491333007 and perplexity is 36.39222122274923
At time: 821.1722273826599 and batch: 1400, loss is 3.6246291732788087 and perplexity is 37.51081056928767
At time: 822.2476243972778 and batch: 1450, loss is 3.5396011066436768 and perplexity is 34.45317330753226
At time: 823.314683675766 and batch: 1500, loss is 3.5415589570999146 and perplexity is 34.52069354430635
At time: 824.3739025592804 and batch: 1550, loss is 3.5527005910873415 and perplexity is 34.90746108699528
At time: 825.4340977668762 and batch: 1600, loss is 3.638534245491028 and perplexity is 38.03604434292069
At time: 826.4933233261108 and batch: 1650, loss is 3.5779910278320313 and perplexity is 35.80154424573332
At time: 827.5528357028961 and batch: 1700, loss is 3.5905277919769287 and perplexity is 36.25320502869117
At time: 828.6119654178619 and batch: 1750, loss is 3.587643747329712 and perplexity is 36.14879979383081
At time: 829.6704022884369 and batch: 1800, loss is 3.5505039405822756 and perplexity is 34.830865752357674
At time: 830.7660026550293 and batch: 1850, loss is 3.565542163848877 and perplexity is 35.35861837316176
At time: 831.8431384563446 and batch: 1900, loss is 3.64720639705658 and perplexity is 38.36733310133388
At time: 832.9018247127533 and batch: 1950, loss is 3.5938495540618898 and perplexity is 36.37382978306611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242554278706395 and perplexity of 69.58536544986877
finished 19 epochs...
Completing Train Step...
At time: 836.261091709137 and batch: 50, loss is 3.769074330329895 and perplexity is 43.33992780522782
At time: 837.2855141162872 and batch: 100, loss is 3.7650881385803223 and perplexity is 43.16751041527755
At time: 838.3342423439026 and batch: 150, loss is 3.7347078371047973 and perplexity is 41.87578922386907
At time: 839.3666896820068 and batch: 200, loss is 3.7342579698562623 and perplexity is 41.85695491457779
At time: 840.3926033973694 and batch: 250, loss is 3.7327245807647706 and perplexity is 41.79282110012085
At time: 841.4173502922058 and batch: 300, loss is 3.722781467437744 and perplexity is 41.379329447513086
At time: 842.4436979293823 and batch: 350, loss is 3.735851221084595 and perplexity is 41.923696713517884
At time: 843.4688119888306 and batch: 400, loss is 3.7021953153610228 and perplexity is 40.53619648606522
At time: 844.4959371089935 and batch: 450, loss is 3.7524615144729614 and perplexity is 42.625877183328775
At time: 845.5336825847626 and batch: 500, loss is 3.7673045778274536 and perplexity is 43.26329469036369
At time: 846.6078977584839 and batch: 550, loss is 3.7416031980514526 and perplexity is 42.165535710775806
At time: 847.6460855007172 and batch: 600, loss is 3.716744956970215 and perplexity is 41.13029509761642
At time: 848.676901102066 and batch: 650, loss is 3.7312591457366944 and perplexity is 41.73162128928408
At time: 849.7300901412964 and batch: 700, loss is 3.7642976331710813 and perplexity is 43.13339974890026
At time: 850.7882509231567 and batch: 750, loss is 3.7269580936431885 and perplexity is 41.55251685702413
At time: 851.8336141109467 and batch: 800, loss is 3.689284782409668 and perplexity is 40.016216418093805
At time: 852.8783411979675 and batch: 850, loss is 3.6891800212860106 and perplexity is 40.01202449387651
At time: 853.9230234622955 and batch: 900, loss is 3.6419827270507814 and perplexity is 38.16743736343665
At time: 854.9694485664368 and batch: 950, loss is 3.760524535179138 and perplexity is 42.970959848464524
At time: 856.0125365257263 and batch: 1000, loss is 3.726007733345032 and perplexity is 41.51304575357036
At time: 857.0551338195801 and batch: 1050, loss is 3.6705441236495973 and perplexity is 39.27326956229551
At time: 858.1018590927124 and batch: 1100, loss is 3.682254195213318 and perplexity is 39.73586558956229
At time: 859.1487925052643 and batch: 1150, loss is 3.6708478832244875 and perplexity is 39.2852010060157
At time: 860.2062766551971 and batch: 1200, loss is 3.731373906135559 and perplexity is 41.73641070160068
At time: 861.2533993721008 and batch: 1250, loss is 3.7253577852249147 and perplexity is 41.48607319385424
At time: 862.2938642501831 and batch: 1300, loss is 3.7267685890197755 and perplexity is 41.544643209035186
At time: 863.3342311382294 and batch: 1350, loss is 3.5938258218765258 and perplexity is 36.37296656283839
At time: 864.3806664943695 and batch: 1400, loss is 3.6242630767822264 and perplexity is 37.4970805063716
At time: 865.4309766292572 and batch: 1450, loss is 3.539579496383667 and perplexity is 34.45242877354373
At time: 866.4789531230927 and batch: 1500, loss is 3.5417178869247437 and perplexity is 34.52618034808115
At time: 867.524316072464 and batch: 1550, loss is 3.5534181594848633 and perplexity is 34.932518567061756
At time: 868.5841722488403 and batch: 1600, loss is 3.6395531463623048 and perplexity is 38.07481905207956
At time: 869.6441085338593 and batch: 1650, loss is 3.579208836555481 and perplexity is 35.84517023729363
At time: 870.6928291320801 and batch: 1700, loss is 3.5921784400939942 and perplexity is 36.31309572894679
At time: 871.740053653717 and batch: 1750, loss is 3.58971390247345 and perplexity is 36.22371092974774
At time: 872.789669752121 and batch: 1800, loss is 3.552482705116272 and perplexity is 34.89985606948217
At time: 873.838089466095 and batch: 1850, loss is 3.56759584903717 and perplexity is 35.43130845972201
At time: 874.8860449790955 and batch: 1900, loss is 3.648943462371826 and perplexity is 38.43403758315076
At time: 875.9344112873077 and batch: 1950, loss is 3.5950896453857424 and perplexity is 36.41896463367957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242263581031977 and perplexity of 69.56514008583451
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
1815.1133942604065


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.599862813949585 and batch: 50, loss is 7.692682428359985 and perplexity is 2192.2472283412176
At time: 2.7549641132354736 and batch: 100, loss is 6.836073112487793 and perplexity is 930.8266967131715
At time: 3.9068217277526855 and batch: 150, loss is 6.505236330032349 and perplexity is 668.6336689002994
At time: 5.05743408203125 and batch: 200, loss is 6.370899772644043 and perplexity is 584.583584643121
At time: 6.207977533340454 and batch: 250, loss is 6.294824323654175 and perplexity is 541.7606634989731
At time: 7.368061542510986 and batch: 300, loss is 6.207564926147461 and perplexity is 496.49078636728933
At time: 8.529226064682007 and batch: 350, loss is 6.12120795249939 and perplexity is 455.41448143552975
At time: 9.68555736541748 and batch: 400, loss is 6.061195039749146 and perplexity is 428.8876685415413
At time: 10.839941501617432 and batch: 450, loss is 5.961980714797973 and perplexity is 388.3786301910102
At time: 11.998570680618286 and batch: 500, loss is 5.928648443222046 and perplexity is 375.6464630490943
At time: 13.156269073486328 and batch: 550, loss is 5.864789724349976 and perplexity is 352.408045485314
At time: 14.313786506652832 and batch: 600, loss is 5.893743028640747 and perplexity is 362.76056955591343
At time: 15.471065759658813 and batch: 650, loss is 5.954190855026245 and perplexity is 385.364968364549
At time: 16.62995457649231 and batch: 700, loss is 5.865252170562744 and perplexity is 352.5710529394828
At time: 17.78815793991089 and batch: 750, loss is 5.7877771759033205 and perplexity is 326.2869392242082
At time: 18.945135831832886 and batch: 800, loss is 5.778769388198852 and perplexity is 323.3610135875881
At time: 20.103981494903564 and batch: 850, loss is 5.802841329574585 and perplexity is 331.23938436091777
At time: 21.26165509223938 and batch: 900, loss is 5.781693000793457 and perplexity is 324.30777923312553
At time: 22.41882061958313 and batch: 950, loss is 5.79826865196228 and perplexity is 329.728191176533
At time: 23.57778811454773 and batch: 1000, loss is 5.769276914596557 and perplexity is 320.30604026841024
At time: 24.735580444335938 and batch: 1050, loss is 5.6612287044525145 and perplexity is 287.5016802167537
At time: 25.896109580993652 and batch: 1100, loss is 5.739936637878418 and perplexity is 311.0447019047754
At time: 27.056896448135376 and batch: 1150, loss is 5.646834506988525 and perplexity is 283.39296602332615
At time: 28.21487522125244 and batch: 1200, loss is 5.713994817733765 and perplexity is 303.0794001054367
At time: 29.375776767730713 and batch: 1250, loss is 5.653323726654053 and perplexity is 285.23794499409695
At time: 30.537500858306885 and batch: 1300, loss is 5.665341014862061 and perplexity is 288.6864106892078
At time: 31.69888997077942 and batch: 1350, loss is 5.61890212059021 and perplexity is 275.5866561708618
At time: 32.86903429031372 and batch: 1400, loss is 5.635810222625732 and perplexity is 280.2859193304116
At time: 34.09129190444946 and batch: 1450, loss is 5.605298986434937 and perplexity is 271.86319669217136
At time: 35.36412310600281 and batch: 1500, loss is 5.573967370986939 and perplexity is 263.4773407662819
At time: 36.6461660861969 and batch: 1550, loss is 5.550313510894775 and perplexity is 257.31821532523935
At time: 37.92654895782471 and batch: 1600, loss is 5.571092481613159 and perplexity is 262.72096033506966
At time: 39.2047438621521 and batch: 1650, loss is 5.566948461532593 and perplexity is 261.6344921277067
At time: 40.48491930961609 and batch: 1700, loss is 5.583306589126587 and perplexity is 265.9495393585793
At time: 41.7657470703125 and batch: 1750, loss is 5.5845912837982175 and perplexity is 266.29142287566066
At time: 43.045836210250854 and batch: 1800, loss is 5.581616468429566 and perplexity is 265.5004321673321
At time: 44.32690215110779 and batch: 1850, loss is 5.542639493942261 and perplexity is 255.35110843809778
At time: 45.60823655128479 and batch: 1900, loss is 5.5595841884613035 and perplexity is 259.7148214480629
At time: 46.89043879508972 and batch: 1950, loss is 5.47565803527832 and perplexity is 238.807559037493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.994057730741279 and perplexity of 147.53386324339618
finished 1 epochs...
Completing Train Step...
At time: 50.53354477882385 and batch: 50, loss is 5.236877727508545 and perplexity is 188.0819416119094
At time: 51.62732720375061 and batch: 100, loss is 5.164453144073486 and perplexity is 174.94176446804445
At time: 52.697843074798584 and batch: 150, loss is 5.07492992401123 and perplexity is 159.96098216263198
At time: 53.778400182724 and batch: 200, loss is 5.035566816329956 and perplexity is 153.78673674586847
At time: 54.889832496643066 and batch: 250, loss is 5.043726587295533 and perplexity is 155.04673495257222
At time: 56.00711011886597 and batch: 300, loss is 5.043790044784546 and perplexity is 155.0565741412339
At time: 57.12264156341553 and batch: 350, loss is 5.038556108474731 and perplexity is 154.24713802411543
At time: 58.21354794502258 and batch: 400, loss is 4.988418865203857 and perplexity is 146.7042807765133
At time: 59.30041718482971 and batch: 450, loss is 4.941508207321167 and perplexity is 139.98121112056643
At time: 60.38838219642639 and batch: 500, loss is 4.9308430862426755 and perplexity is 138.49622739659853
At time: 61.47536659240723 and batch: 550, loss is 4.8836743259429936 and perplexity is 132.11520748946754
At time: 62.56231713294983 and batch: 600, loss is 4.869558219909668 and perplexity is 130.26335642549134
At time: 63.64947509765625 and batch: 650, loss is 4.937707376480103 and perplexity is 139.45017604271214
At time: 64.7348165512085 and batch: 700, loss is 4.920125656127929 and perplexity is 137.01982948600232
At time: 65.81593418121338 and batch: 750, loss is 4.8786278820037845 and perplexity is 131.4501749374431
At time: 66.92793226242065 and batch: 800, loss is 4.855820865631103 and perplexity is 128.48611777643623
At time: 68.0330023765564 and batch: 850, loss is 4.845605764389038 and perplexity is 127.18029996071431
At time: 69.11628913879395 and batch: 900, loss is 4.849662294387818 and perplexity is 127.69725848273711
At time: 70.19877767562866 and batch: 950, loss is 4.902307291030883 and perplexity is 134.59998301620752
At time: 71.32509279251099 and batch: 1000, loss is 4.872664289474487 and perplexity is 130.66859249220397
At time: 72.4112901687622 and batch: 1050, loss is 4.78201623916626 and perplexity is 119.34473515574908
At time: 73.4952142238617 and batch: 1100, loss is 4.857686204910278 and perplexity is 128.72601165092775
At time: 74.57849192619324 and batch: 1150, loss is 4.765903377532959 and perplexity is 117.43715947393609
At time: 75.66074419021606 and batch: 1200, loss is 4.8547780418396 and perplexity is 128.35219923479787
At time: 76.74376702308655 and batch: 1250, loss is 4.806949043273926 and perplexity is 122.35773929645055
At time: 77.82775568962097 and batch: 1300, loss is 4.825757188796997 and perplexity is 124.6808395852121
At time: 78.90979290008545 and batch: 1350, loss is 4.729621162414551 and perplexity is 113.25264986032258
At time: 79.99294853210449 and batch: 1400, loss is 4.748616867065429 and perplexity is 115.42452660522987
At time: 81.07587242126465 and batch: 1450, loss is 4.68911735534668 and perplexity is 108.75714351945494
At time: 82.15888786315918 and batch: 1500, loss is 4.6642739200592045 and perplexity is 106.0885284981987
At time: 83.24280285835266 and batch: 1550, loss is 4.672644023895264 and perplexity is 106.98022709654626
At time: 84.32724499702454 and batch: 1600, loss is 4.726656341552735 and perplexity is 112.91737330441902
At time: 85.41007161140442 and batch: 1650, loss is 4.6929323101043705 and perplexity is 109.17283952812468
At time: 86.49437260627747 and batch: 1700, loss is 4.723601560592652 and perplexity is 112.57296178109637
At time: 87.57947278022766 and batch: 1750, loss is 4.718676567077637 and perplexity is 112.01990369599376
At time: 88.6633129119873 and batch: 1800, loss is 4.679869871139527 and perplexity is 107.75604948708744
At time: 89.7468638420105 and batch: 1850, loss is 4.683197050094605 and perplexity is 108.11517024544555
At time: 90.83317112922668 and batch: 1900, loss is 4.764253959655762 and perplexity is 117.24361618441255
At time: 91.9366843700409 and batch: 1950, loss is 4.685886449813843 and perplexity is 108.40632649622734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.554779762445494 and perplexity of 95.08581146277524
finished 2 epochs...
Completing Train Step...
At time: 95.41678142547607 and batch: 50, loss is 4.64017107963562 and perplexity is 103.56206342790306
At time: 96.49646878242493 and batch: 100, loss is 4.59038821220398 and perplexity is 98.53267432470426
At time: 97.54731154441833 and batch: 150, loss is 4.546789836883545 and perplexity is 94.32910992724008
At time: 98.6075370311737 and batch: 200, loss is 4.540151824951172 and perplexity is 93.70502580050672
At time: 99.69549322128296 and batch: 250, loss is 4.5433433055877686 and perplexity is 94.00456130253374
At time: 100.77910351753235 and batch: 300, loss is 4.568650617599487 and perplexity is 96.4139227060664
At time: 101.85276532173157 and batch: 350, loss is 4.574396953582764 and perplexity is 96.96954436486445
At time: 102.91932201385498 and batch: 400, loss is 4.533662099838256 and perplexity is 93.09887494499023
At time: 103.98281931877136 and batch: 450, loss is 4.524304409027099 and perplexity is 92.2317479391839
At time: 105.06170558929443 and batch: 500, loss is 4.526765823364258 and perplexity is 92.45904811109429
At time: 106.14437413215637 and batch: 550, loss is 4.491654739379883 and perplexity is 89.26904072657153
At time: 107.2251398563385 and batch: 600, loss is 4.4774738121032716 and perplexity is 88.01205661685081
At time: 108.30640506744385 and batch: 650, loss is 4.5426068687438965 and perplexity is 93.93535836502261
At time: 109.38755798339844 and batch: 700, loss is 4.555996627807617 and perplexity is 95.20158852143331
At time: 110.47109627723694 and batch: 750, loss is 4.520852451324463 and perplexity is 91.91391673200613
At time: 111.64516377449036 and batch: 800, loss is 4.499629173278809 and perplexity is 89.98375673134407
At time: 112.73229813575745 and batch: 850, loss is 4.489521427154541 and perplexity is 89.07880497891529
At time: 113.80964803695679 and batch: 900, loss is 4.470916633605957 and perplexity is 87.43683383198643
At time: 114.90544009208679 and batch: 950, loss is 4.552331514358521 and perplexity is 94.85330254265924
At time: 115.98663401603699 and batch: 1000, loss is 4.532360172271728 and perplexity is 92.97774582106899
At time: 117.06725072860718 and batch: 1050, loss is 4.457588214874267 and perplexity is 86.27917114250499
At time: 118.1484146118164 and batch: 1100, loss is 4.5158092212677 and perplexity is 91.45154061907591
At time: 119.22958087921143 and batch: 1150, loss is 4.457094898223877 and perplexity is 86.23661868757878
At time: 120.31085753440857 and batch: 1200, loss is 4.543316793441773 and perplexity is 94.00206907291754
At time: 121.41506552696228 and batch: 1250, loss is 4.508531017303467 and perplexity is 90.78835398493996
At time: 122.49298119544983 and batch: 1300, loss is 4.516795892715454 and perplexity is 91.54181777267887
At time: 123.57208037376404 and batch: 1350, loss is 4.4093357372283934 and perplexity is 82.21483310883349
At time: 124.64998435974121 and batch: 1400, loss is 4.433204679489136 and perplexity is 84.2008216478889
At time: 125.72765517234802 and batch: 1450, loss is 4.371706504821777 and perplexity is 79.17863519748796
At time: 126.80699563026428 and batch: 1500, loss is 4.365077533721924 and perplexity is 78.65549815888716
At time: 127.8838894367218 and batch: 1550, loss is 4.3742466640472415 and perplexity is 79.3800172010384
At time: 128.9606432914734 and batch: 1600, loss is 4.445639991760254 and perplexity is 85.25442250932171
At time: 130.08113884925842 and batch: 1650, loss is 4.410292301177979 and perplexity is 82.29351448018869
At time: 131.1775255203247 and batch: 1700, loss is 4.430982532501221 and perplexity is 84.01392278096907
At time: 132.25531268119812 and batch: 1750, loss is 4.432892656326294 and perplexity is 84.17455313960903
At time: 133.33359503746033 and batch: 1800, loss is 4.389974069595337 and perplexity is 80.63832796889116
At time: 134.43060970306396 and batch: 1850, loss is 4.413075475692749 and perplexity is 82.52287071358207
At time: 135.51348996162415 and batch: 1900, loss is 4.4989222812652585 and perplexity is 89.92017040934087
At time: 136.5910530090332 and batch: 1950, loss is 4.433030872344971 and perplexity is 84.18618821527633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.435581508902616 and perplexity of 84.40119066457798
finished 3 epochs...
Completing Train Step...
At time: 140.12037253379822 and batch: 50, loss is 4.393287973403931 and perplexity is 80.90599890396895
At time: 141.18359851837158 and batch: 100, loss is 4.350555715560913 and perplexity is 77.52153087840155
At time: 142.25754523277283 and batch: 150, loss is 4.31676287651062 and perplexity is 74.94562694213383
At time: 143.31517148017883 and batch: 200, loss is 4.31202805519104 and perplexity is 74.59161155106467
At time: 144.38006472587585 and batch: 250, loss is 4.310050039291382 and perplexity is 74.44421398286063
At time: 145.4435477256775 and batch: 300, loss is 4.339156427383423 and perplexity is 76.64285824406042
At time: 146.51563453674316 and batch: 350, loss is 4.348415470123291 and perplexity is 77.35579319854368
At time: 147.5945405960083 and batch: 400, loss is 4.303275003433227 and perplexity is 73.94155644781688
At time: 148.66077542304993 and batch: 450, loss is 4.317133874893188 and perplexity is 74.97343680689835
At time: 149.7261996269226 and batch: 500, loss is 4.319725999832153 and perplexity is 75.16802941742732
At time: 150.79286098480225 and batch: 550, loss is 4.289483623504639 and perplexity is 72.92880005673635
At time: 151.85921025276184 and batch: 600, loss is 4.278053236007691 and perplexity is 72.0999417228039
At time: 152.92553448677063 and batch: 650, loss is 4.338935918807984 and perplexity is 76.62595969977687
At time: 153.99124765396118 and batch: 700, loss is 4.358249645233155 and perplexity is 78.120276484721
At time: 155.0573148727417 and batch: 750, loss is 4.327556285858154 and perplexity is 75.75892701722827
At time: 156.1477677822113 and batch: 800, loss is 4.304071655273438 and perplexity is 74.00048559471908
At time: 157.21721267700195 and batch: 850, loss is 4.298894948959351 and perplexity is 73.61839664810374
At time: 158.28482508659363 and batch: 900, loss is 4.272840113639831 and perplexity is 71.72505392089586
At time: 159.35224175453186 and batch: 950, loss is 4.364311609268189 and perplexity is 78.59527705477869
At time: 160.41945624351501 and batch: 1000, loss is 4.339354639053345 and perplexity is 76.6580512586472
At time: 161.4909610748291 and batch: 1050, loss is 4.274879741668701 and perplexity is 71.87149564379895
At time: 162.56131315231323 and batch: 1100, loss is 4.331253585815429 and perplexity is 76.03954894690085
At time: 163.63286805152893 and batch: 1150, loss is 4.278969898223877 and perplexity is 72.16606331612356
At time: 164.6991250514984 and batch: 1200, loss is 4.360572605133057 and perplexity is 78.30195769174539
At time: 165.82538628578186 and batch: 1250, loss is 4.336376523971557 and perplexity is 76.43009436946058
At time: 166.895001411438 and batch: 1300, loss is 4.336995525360107 and perplexity is 76.4774193496054
At time: 167.98407816886902 and batch: 1350, loss is 4.225849986076355 and perplexity is 68.43264563103183
At time: 169.04891729354858 and batch: 1400, loss is 4.251096353530884 and perplexity is 70.18231481148963
At time: 170.11381554603577 and batch: 1450, loss is 4.190499963760376 and perplexity is 66.05580821627697
At time: 171.18095064163208 and batch: 1500, loss is 4.1931493282318115 and perplexity is 66.23104615978639
At time: 172.24511647224426 and batch: 1550, loss is 4.204122505187988 and perplexity is 66.9618132348434
At time: 173.32842302322388 and batch: 1600, loss is 4.282198143005371 and perplexity is 72.39940948004018
At time: 174.40445351600647 and batch: 1650, loss is 4.239533176422119 and perplexity is 69.37545817867723
At time: 175.4693567752838 and batch: 1700, loss is 4.259092698097229 and perplexity is 70.74576655801465
At time: 176.53211164474487 and batch: 1750, loss is 4.268212223052979 and perplexity is 71.39388511657351
At time: 177.59478378295898 and batch: 1800, loss is 4.222419114112854 and perplexity is 68.19826428185418
At time: 178.65635776519775 and batch: 1850, loss is 4.249727458953857 and perplexity is 70.0863083476968
At time: 179.72955632209778 and batch: 1900, loss is 4.336462869644165 and perplexity is 76.43669406228972
At time: 180.79269862174988 and batch: 1950, loss is 4.272464046478271 and perplexity is 71.69808555473138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392083598292151 and perplexity of 80.80861638680662
finished 4 epochs...
Completing Train Step...
At time: 184.19845700263977 and batch: 50, loss is 4.239848256111145 and perplexity is 69.3973204204595
At time: 185.33121800422668 and batch: 100, loss is 4.199160900115967 and perplexity is 66.63039801826032
At time: 186.38268160820007 and batch: 150, loss is 4.169796562194824 and perplexity is 64.7022878769618
At time: 187.41968750953674 and batch: 200, loss is 4.1693806552886965 and perplexity is 64.67538334386992
At time: 188.4685070514679 and batch: 250, loss is 4.162054915428161 and perplexity is 64.20331952962712
At time: 189.51739692687988 and batch: 300, loss is 4.194847540855408 and perplexity is 66.34361611525502
At time: 190.5651466846466 and batch: 350, loss is 4.203670392036438 and perplexity is 66.9315457611053
At time: 191.6657440662384 and batch: 400, loss is 4.155407385826111 and perplexity is 63.77794148551527
At time: 192.71547842025757 and batch: 450, loss is 4.184693942070007 and perplexity is 65.67339797632222
At time: 193.76393961906433 and batch: 500, loss is 4.184847216606141 and perplexity is 65.68346480740807
At time: 194.82117414474487 and batch: 550, loss is 4.158398780822754 and perplexity is 63.96901214199207
At time: 195.88106083869934 and batch: 600, loss is 4.144775023460388 and perplexity is 63.10342351479294
At time: 196.943696975708 and batch: 650, loss is 4.199873886108398 and perplexity is 66.67792149849214
At time: 198.00804114341736 and batch: 700, loss is 4.228481225967407 and perplexity is 68.61294544006705
At time: 199.07199144363403 and batch: 750, loss is 4.1945280170440675 and perplexity is 66.32242113650629
At time: 200.13547229766846 and batch: 800, loss is 4.172985005378723 and perplexity is 64.9089166827776
At time: 201.19829416275024 and batch: 850, loss is 4.170184445381165 and perplexity is 64.72738967451495
At time: 202.26113629341125 and batch: 900, loss is 4.141262898445129 and perplexity is 62.88218513835123
At time: 203.32498025894165 and batch: 950, loss is 4.23745373249054 and perplexity is 69.23134569201453
At time: 204.38820695877075 and batch: 1000, loss is 4.210069427490234 and perplexity is 67.36121636796541
At time: 205.47296595573425 and batch: 1050, loss is 4.153611350059509 and perplexity is 63.663496825602394
At time: 206.53725504875183 and batch: 1100, loss is 4.2059135389328 and perplexity is 67.08185156622363
At time: 207.60137009620667 and batch: 1150, loss is 4.155230078697205 and perplexity is 63.766634204283335
At time: 208.66515231132507 and batch: 1200, loss is 4.236329202651977 and perplexity is 69.15353673546628
At time: 209.72908639907837 and batch: 1250, loss is 4.210885777473449 and perplexity is 67.41622914760246
At time: 210.79261684417725 and batch: 1300, loss is 4.213348007202148 and perplexity is 67.58242791701588
At time: 211.8564817905426 and batch: 1350, loss is 4.09923948764801 and perplexity is 60.29441550867752
At time: 212.92367029190063 and batch: 1400, loss is 4.132145900726318 and perplexity is 62.311493848451185
At time: 213.9858808517456 and batch: 1450, loss is 4.069241919517517 and perplexity is 58.512588523120804
At time: 215.0482268333435 and batch: 1500, loss is 4.0715528059005734 and perplexity is 58.64796082193437
At time: 216.11124348640442 and batch: 1550, loss is 4.087589111328125 and perplexity is 59.59603895213903
At time: 217.17255330085754 and batch: 1600, loss is 4.166426591873169 and perplexity is 64.48461007694453
At time: 218.23458695411682 and batch: 1650, loss is 4.122411255836487 and perplexity is 61.707856448031634
At time: 219.29565143585205 and batch: 1700, loss is 4.140825695991516 and perplexity is 62.854698901683086
At time: 220.3572633266449 and batch: 1750, loss is 4.149820504188537 and perplexity is 63.42261518258633
At time: 221.4532973766327 and batch: 1800, loss is 4.106183481216431 and perplexity is 60.71455658240623
At time: 222.52720737457275 and batch: 1850, loss is 4.134869661331177 and perplexity is 62.48144679111888
At time: 223.58892679214478 and batch: 1900, loss is 4.219319081306457 and perplexity is 67.98717478647256
At time: 224.649400472641 and batch: 1950, loss is 4.158220682144165 and perplexity is 63.957620359919716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374630098564681 and perplexity of 79.41046007567968
finished 5 epochs...
Completing Train Step...
At time: 228.05881786346436 and batch: 50, loss is 4.128469972610474 and perplexity is 62.08286175129869
At time: 229.10193848609924 and batch: 100, loss is 4.0902199459075925 and perplexity is 59.75303269394604
At time: 230.1313600540161 and batch: 150, loss is 4.062135248184204 and perplexity is 58.09823287623455
At time: 231.15927243232727 and batch: 200, loss is 4.065520873069763 and perplexity is 58.29526504957598
At time: 232.18812680244446 and batch: 250, loss is 4.051399669647217 and perplexity is 57.47785077310557
At time: 233.22537398338318 and batch: 300, loss is 4.086276445388794 and perplexity is 59.51786058395379
At time: 234.2852783203125 and batch: 350, loss is 4.095568723678589 and perplexity is 60.073494662878005
At time: 235.33912706375122 and batch: 400, loss is 4.05085825920105 and perplexity is 57.446740086858995
At time: 236.3859703540802 and batch: 450, loss is 4.084152040481567 and perplexity is 59.391554758721576
At time: 237.44428205490112 and batch: 500, loss is 4.087581324577331 and perplexity is 59.59557489444219
At time: 238.50237441062927 and batch: 550, loss is 4.05614360332489 and perplexity is 57.751169675897735
At time: 239.56116724014282 and batch: 600, loss is 4.048041520118713 and perplexity is 57.28515528684887
At time: 240.61894130706787 and batch: 650, loss is 4.100521750450135 and perplexity is 60.37177838402882
At time: 241.67705273628235 and batch: 700, loss is 4.127315292358398 and perplexity is 62.011217268037335
At time: 242.7357201576233 and batch: 750, loss is 4.099925837516785 and perplexity is 60.335812777729736
At time: 243.7985486984253 and batch: 800, loss is 4.077968587875366 and perplexity is 59.025442978608446
At time: 244.9005286693573 and batch: 850, loss is 4.070944895744324 and perplexity is 58.612318965528274
At time: 245.96382093429565 and batch: 900, loss is 4.044365682601929 and perplexity is 57.07497090237734
At time: 247.0427758693695 and batch: 950, loss is 4.140410461425781 and perplexity is 62.82860487602587
At time: 248.1141381263733 and batch: 1000, loss is 4.11792670249939 and perplexity is 61.431743858037535
At time: 249.17655062675476 and batch: 1050, loss is 4.062163348197937 and perplexity is 58.099865460313936
At time: 250.23935747146606 and batch: 1100, loss is 4.105060243606568 and perplexity is 60.64639799529705
At time: 251.3263645172119 and batch: 1150, loss is 4.0664117860794065 and perplexity is 58.347224201714766
At time: 252.3885486125946 and batch: 1200, loss is 4.1485424852371215 and perplexity is 63.34161165148405
At time: 253.4517686367035 and batch: 1250, loss is 4.118018116950989 and perplexity is 61.4373598639012
At time: 254.5158715248108 and batch: 1300, loss is 4.122396163940429 and perplexity is 61.70692516650362
At time: 255.57927322387695 and batch: 1350, loss is 4.0059144115448 and perplexity is 54.922022776274865
At time: 256.64162135124207 and batch: 1400, loss is 4.04213966846466 and perplexity is 56.94806251260339
At time: 257.705007314682 and batch: 1450, loss is 3.9775794410705565 and perplexity is 53.38764974696741
At time: 258.76771783828735 and batch: 1500, loss is 3.9811916875839235 and perplexity is 53.58084782809432
At time: 259.82981634140015 and batch: 1550, loss is 3.994953360557556 and perplexity is 54.32330695598077
At time: 260.8926088809967 and batch: 1600, loss is 4.079280157089233 and perplexity is 59.1029097228475
At time: 261.95412492752075 and batch: 1650, loss is 4.031937432289124 and perplexity is 56.37001861313131
At time: 263.0172381401062 and batch: 1700, loss is 4.054863677024842 and perplexity is 57.67729971910578
At time: 264.09233117103577 and batch: 1750, loss is 4.061389923095703 and perplexity is 58.05494693872572
At time: 265.17928671836853 and batch: 1800, loss is 4.019138441085816 and perplexity is 55.653136709618096
At time: 266.2613916397095 and batch: 1850, loss is 4.047924280166626 and perplexity is 57.278439571670496
At time: 267.3227071762085 and batch: 1900, loss is 4.129680280685425 and perplexity is 62.15804662944705
At time: 268.3836839199066 and batch: 1950, loss is 4.067474179267883 and perplexity is 58.40924483458869
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361068938499273 and perplexity of 78.34083121230249
finished 6 epochs...
Completing Train Step...
At time: 271.72737765312195 and batch: 50, loss is 4.041016182899475 and perplexity is 56.88411811343593
At time: 272.73684549331665 and batch: 100, loss is 4.004261798858643 and perplexity is 54.83133290294346
At time: 273.7466690540314 and batch: 150, loss is 3.980690712928772 and perplexity is 53.55401190395111
At time: 274.76731038093567 and batch: 200, loss is 3.9820449495315553 and perplexity is 53.62658583714424
At time: 275.79356694221497 and batch: 250, loss is 3.970145239830017 and perplexity is 52.992226862799875
At time: 276.8182809352875 and batch: 300, loss is 4.0039871978759765 and perplexity is 54.816278232155696
At time: 277.8449409008026 and batch: 350, loss is 4.010625352859497 and perplexity is 55.18136760194962
At time: 278.8740427494049 and batch: 400, loss is 3.9678097581863403 and perplexity is 52.86860889963539
At time: 279.9054560661316 and batch: 450, loss is 4.006597976684571 and perplexity is 54.95957839084254
At time: 280.9374165534973 and batch: 500, loss is 4.0087282800674435 and perplexity is 55.07678376378601
At time: 281.97265553474426 and batch: 550, loss is 3.9812519931793213 and perplexity is 53.584079150456944
At time: 283.01203179359436 and batch: 600, loss is 3.975694990158081 and perplexity is 53.28713807608615
At time: 284.05638360977173 and batch: 650, loss is 4.021580982208252 and perplexity is 55.789237933376754
At time: 285.105268239975 and batch: 700, loss is 4.049269380569458 and perplexity is 57.355536663852554
At time: 286.1524577140808 and batch: 750, loss is 4.024753627777099 and perplexity is 55.96651848737341
At time: 287.2013897895813 and batch: 800, loss is 3.9994362878799437 and perplexity is 54.56738106747213
At time: 288.2492892742157 and batch: 850, loss is 3.9969811248779297 and perplexity is 54.43357357916982
At time: 289.3000545501709 and batch: 900, loss is 3.9703258275985718 and perplexity is 53.0017974749415
At time: 290.34856724739075 and batch: 950, loss is 4.066010518074036 and perplexity is 58.32381602423085
At time: 291.39727449417114 and batch: 1000, loss is 4.043866667747498 and perplexity is 57.04649674918441
At time: 292.44550037384033 and batch: 1050, loss is 3.9931400775909425 and perplexity is 54.22489268221599
At time: 293.4932918548584 and batch: 1100, loss is 4.0312864780426025 and perplexity is 56.333336250703724
At time: 294.54215955734253 and batch: 1150, loss is 3.9938165187835692 and perplexity is 54.26158504200469
At time: 295.6070969104767 and batch: 1200, loss is 4.073056025505066 and perplexity is 58.73618788211499
At time: 296.6554617881775 and batch: 1250, loss is 4.047467846870422 and perplexity is 57.25230175023515
At time: 297.7049300670624 and batch: 1300, loss is 4.052039842605591 and perplexity is 57.5146583192168
At time: 298.7502157688141 and batch: 1350, loss is 3.9335736274719237 and perplexity is 51.08922569242937
At time: 299.8139314651489 and batch: 1400, loss is 3.970783734321594 and perplexity is 53.02607291185626
At time: 300.86634707450867 and batch: 1450, loss is 3.904014663696289 and perplexity is 49.60118198036742
At time: 301.9097352027893 and batch: 1500, loss is 3.9119416427612306 and perplexity is 49.995932032146825
At time: 302.95430994033813 and batch: 1550, loss is 3.92104362487793 and perplexity is 50.453071392540124
At time: 304.00019931793213 and batch: 1600, loss is 4.009530487060547 and perplexity is 55.12098447156703
At time: 305.04596972465515 and batch: 1650, loss is 3.9631932830810546 and perplexity is 52.625104780610855
At time: 306.091495513916 and batch: 1700, loss is 3.9826766729354857 and perplexity is 53.66047370924442
At time: 307.13641381263733 and batch: 1750, loss is 3.989922590255737 and perplexity is 54.05070515011634
At time: 308.182076215744 and batch: 1800, loss is 3.9514008569717407 and perplexity is 52.00817183833424
At time: 309.2272388935089 and batch: 1850, loss is 3.9795987701416013 and perplexity is 53.49556590258064
At time: 310.28306102752686 and batch: 1900, loss is 4.059465541839599 and perplexity is 57.94333451388589
At time: 311.3388600349426 and batch: 1950, loss is 3.9979377603530883 and perplexity is 54.485671582121086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347041640170785 and perplexity of 77.24959246042884
finished 7 epochs...
Completing Train Step...
At time: 314.68874883651733 and batch: 50, loss is 3.9720164012908934 and perplexity is 53.091476702711105
At time: 315.71056604385376 and batch: 100, loss is 3.938816857337952 and perplexity is 51.35780173407827
At time: 316.7383596897125 and batch: 150, loss is 3.917890501022339 and perplexity is 50.294237153155784
At time: 317.76624941825867 and batch: 200, loss is 3.9138959646224976 and perplexity is 50.093735713899285
At time: 318.80524158477783 and batch: 250, loss is 3.906438555717468 and perplexity is 49.72155571714525
At time: 319.8421800136566 and batch: 300, loss is 3.933126459121704 and perplexity is 51.06638531479007
At time: 320.8797199726105 and batch: 350, loss is 3.942715630531311 and perplexity is 51.55842499291074
At time: 321.9166302680969 and batch: 400, loss is 3.903946566581726 and perplexity is 49.59780439799874
At time: 322.97852206230164 and batch: 450, loss is 3.945344958305359 and perplexity is 51.69416736912769
At time: 324.0185205936432 and batch: 500, loss is 3.948631000518799 and perplexity is 51.86431598996017
At time: 325.060099363327 and batch: 550, loss is 3.9239686346054077 and perplexity is 50.600863157948574
At time: 326.09914088249207 and batch: 600, loss is 3.91113338470459 and perplexity is 49.95553874358206
At time: 327.1387777328491 and batch: 650, loss is 3.95728485584259 and perplexity is 52.31508993006345
At time: 328.1802508831024 and batch: 700, loss is 3.9859168100357056 and perplexity is 53.83462298232682
At time: 329.21991086006165 and batch: 750, loss is 3.963409423828125 and perplexity is 52.6364804394002
At time: 330.2595705986023 and batch: 800, loss is 3.935985527038574 and perplexity is 51.21259649292091
At time: 331.30564737319946 and batch: 850, loss is 3.935857934951782 and perplexity is 51.206062587710505
At time: 332.3673446178436 and batch: 900, loss is 3.908135323524475 and perplexity is 49.80599326740076
At time: 333.40800380706787 and batch: 950, loss is 4.0037585687637325 and perplexity is 54.80374706767605
At time: 334.44751167297363 and batch: 1000, loss is 3.980933837890625 and perplexity is 53.567033803962666
At time: 335.4877827167511 and batch: 1050, loss is 3.934703769683838 and perplexity is 51.14699642137926
At time: 336.5512602329254 and batch: 1100, loss is 3.9737529373168945 and perplexity is 53.18375206123268
At time: 337.59473276138306 and batch: 1150, loss is 3.9362143087387085 and perplexity is 51.224314338178026
At time: 338.63606429100037 and batch: 1200, loss is 4.012035040855408 and perplexity is 55.25921096799436
At time: 339.68810296058655 and batch: 1250, loss is 3.988818340301514 and perplexity is 53.99105260315125
At time: 340.75428891181946 and batch: 1300, loss is 3.9920011806488036 and perplexity is 54.16317127158682
At time: 341.7974786758423 and batch: 1350, loss is 3.8729092645645142 and perplexity is 48.08206625054754
At time: 342.8376462459564 and batch: 1400, loss is 3.910773377418518 and perplexity is 49.93755762251622
At time: 343.8783805370331 and batch: 1450, loss is 3.843924951553345 and perplexity is 46.70844351044059
At time: 344.91918992996216 and batch: 1500, loss is 3.8493281698226927 and perplexity is 46.96150247649713
At time: 345.9585974216461 and batch: 1550, loss is 3.8638003969192507 and perplexity is 47.646081750034526
At time: 346.9981412887573 and batch: 1600, loss is 3.9502857065200807 and perplexity is 51.95020722765648
At time: 348.0369620323181 and batch: 1650, loss is 3.9078138160705564 and perplexity is 49.78998284318875
At time: 349.0771641731262 and batch: 1700, loss is 3.9255271482467653 and perplexity is 50.679786779239684
At time: 350.11651945114136 and batch: 1750, loss is 3.9294963932037352 and perplexity is 50.88134702369526
At time: 351.15605211257935 and batch: 1800, loss is 3.8919977378845214 and perplexity is 49.00869532034587
At time: 352.19558596611023 and batch: 1850, loss is 3.924471168518066 and perplexity is 50.626298198145086
At time: 353.23551416397095 and batch: 1900, loss is 4.005258359909058 and perplexity is 54.8860029101322
At time: 354.2895858287811 and batch: 1950, loss is 3.9365951442718505 and perplexity is 51.24382609238767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358835619549419 and perplexity of 78.16606637486007
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 357.63425493240356 and batch: 50, loss is 3.944874758720398 and perplexity is 51.669866506661265
At time: 358.69129157066345 and batch: 100, loss is 3.9346325492858885 and perplexity is 51.143353841654736
At time: 359.7109260559082 and batch: 150, loss is 3.913228645324707 and perplexity is 50.06031834862545
At time: 360.75424003601074 and batch: 200, loss is 3.9198718881607055 and perplexity is 50.39398829796831
At time: 361.7984240055084 and batch: 250, loss is 3.9040245628356933 and perplexity is 49.60167299181275
At time: 362.8436276912689 and batch: 300, loss is 3.9237681102752684 and perplexity is 50.59071747102189
At time: 363.8868787288666 and batch: 350, loss is 3.9251482677459717 and perplexity is 50.66058883333799
At time: 364.9272940158844 and batch: 400, loss is 3.890893692970276 and perplexity is 48.954617377255694
At time: 365.9731328487396 and batch: 450, loss is 3.9298468542099 and perplexity is 50.899182076830996
At time: 367.01347494125366 and batch: 500, loss is 3.92211275100708 and perplexity is 50.50704093444474
At time: 368.06308603286743 and batch: 550, loss is 3.892343807220459 and perplexity is 49.02565866206744
At time: 369.11383056640625 and batch: 600, loss is 3.8641284847259523 and perplexity is 47.66171641312473
At time: 370.1772413253784 and batch: 650, loss is 3.90193696975708 and perplexity is 49.49823289057348
At time: 371.26390504837036 and batch: 700, loss is 3.9243991565704346 and perplexity is 50.622652631074224
At time: 372.33082365989685 and batch: 750, loss is 3.892931900024414 and perplexity is 49.054498778637075
At time: 373.3829379081726 and batch: 800, loss is 3.8662952518463136 and perplexity is 47.76510021701433
At time: 374.4510600566864 and batch: 850, loss is 3.8574578189849853 and perplexity is 47.34483910063552
At time: 375.55161571502686 and batch: 900, loss is 3.832448959350586 and perplexity is 46.175481758537565
At time: 376.60081219673157 and batch: 950, loss is 3.922351155281067 and perplexity is 50.51908346430821
At time: 377.64831924438477 and batch: 1000, loss is 3.884380326271057 and perplexity is 48.63679417579471
At time: 378.69621205329895 and batch: 1050, loss is 3.8346472454071043 and perplexity is 46.27710032866095
At time: 379.74390745162964 and batch: 1100, loss is 3.8576528644561767 and perplexity is 47.35407439770854
At time: 380.79177713394165 and batch: 1150, loss is 3.8238867473602296 and perplexity is 45.78180527081658
At time: 381.84048557281494 and batch: 1200, loss is 3.8891725015640257 and perplexity is 48.870429582967574
At time: 382.8893835544586 and batch: 1250, loss is 3.85171169757843 and perplexity is 47.07357002610194
At time: 383.9611117839813 and batch: 1300, loss is 3.859127149581909 and perplexity is 47.42393929296948
At time: 385.0222878456116 and batch: 1350, loss is 3.73602126121521 and perplexity is 41.93082603050073
At time: 386.07043528556824 and batch: 1400, loss is 3.766756086349487 and perplexity is 43.239571648455176
At time: 387.1187686920166 and batch: 1450, loss is 3.6922781705856322 and perplexity is 40.1361799462935
At time: 388.16724371910095 and batch: 1500, loss is 3.6871581411361696 and perplexity is 39.931206705270576
At time: 389.21555852890015 and batch: 1550, loss is 3.693627648353577 and perplexity is 40.19037939106895
At time: 390.26399540901184 and batch: 1600, loss is 3.772780990600586 and perplexity is 43.50087229275452
At time: 391.31225967407227 and batch: 1650, loss is 3.7215846395492553 and perplexity is 41.32983513601746
At time: 392.36078929901123 and batch: 1700, loss is 3.727173299789429 and perplexity is 41.56146017633764
At time: 393.40904116630554 and batch: 1750, loss is 3.72101261138916 and perplexity is 41.30620006707455
At time: 394.4729435443878 and batch: 1800, loss is 3.683528423309326 and perplexity is 39.78653041833467
At time: 395.5246524810791 and batch: 1850, loss is 3.705252528190613 and perplexity is 40.6603138960218
At time: 396.5725688934326 and batch: 1900, loss is 3.7808857059478758 and perplexity is 43.854867055721904
At time: 397.6174032688141 and batch: 1950, loss is 3.7150317525863645 and perplexity is 41.059890821423544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.279611418968023 and perplexity of 72.21237419587098
finished 9 epochs...
Completing Train Step...
At time: 400.963093996048 and batch: 50, loss is 3.8623586893081665 and perplexity is 47.57743952423637
At time: 402.0071921348572 and batch: 100, loss is 3.8364602518081665 and perplexity is 46.36107710999788
At time: 403.0241014957428 and batch: 150, loss is 3.811047978401184 and perplexity is 45.19778035314967
At time: 404.04405069351196 and batch: 200, loss is 3.8150549221038816 and perplexity is 45.37924863831446
At time: 405.1093678474426 and batch: 250, loss is 3.798812952041626 and perplexity is 44.64815352488962
At time: 406.1360650062561 and batch: 300, loss is 3.8197523069381716 and perplexity is 45.59291387369333
At time: 407.18779826164246 and batch: 350, loss is 3.823541398048401 and perplexity is 45.76599728566754
At time: 408.2148275375366 and batch: 400, loss is 3.7896927976608277 and perplexity is 44.24280669439218
At time: 409.24355387687683 and batch: 450, loss is 3.8380416011810303 and perplexity is 46.43444816755929
At time: 410.2838535308838 and batch: 500, loss is 3.8348268270492554 and perplexity is 46.285411592584836
At time: 411.32516956329346 and batch: 550, loss is 3.8046048736572264 and perplexity is 44.90750246974968
At time: 412.3655161857605 and batch: 600, loss is 3.781121783256531 and perplexity is 43.86522141687462
At time: 413.4058344364166 and batch: 650, loss is 3.8181809616088866 and perplexity is 45.52132791928652
At time: 414.4625663757324 and batch: 700, loss is 3.8437594604492187 and perplexity is 46.700714318125954
At time: 415.50337195396423 and batch: 750, loss is 3.8121393299102784 and perplexity is 45.24713394510579
At time: 416.5442862510681 and batch: 800, loss is 3.7889594793319703 and perplexity is 44.21037452632811
At time: 417.6247959136963 and batch: 850, loss is 3.782492322921753 and perplexity is 43.92538165933249
At time: 418.6649453639984 and batch: 900, loss is 3.7583201789855956 and perplexity is 42.87634087225747
At time: 419.71304965019226 and batch: 950, loss is 3.8518394899368285 and perplexity is 47.07958605302675
At time: 420.7611632347107 and batch: 1000, loss is 3.8174386692047118 and perplexity is 45.48755032132223
At time: 421.83579444885254 and batch: 1050, loss is 3.7731330680847166 and perplexity is 43.51619066689791
At time: 422.88570380210876 and batch: 1100, loss is 3.7963338613510134 and perplexity is 44.537603791159775
At time: 423.93375301361084 and batch: 1150, loss is 3.763461093902588 and perplexity is 43.097332054351426
At time: 425.0099244117737 and batch: 1200, loss is 3.8320200061798095 and perplexity is 46.15567888678107
At time: 426.05935168266296 and batch: 1250, loss is 3.799487338066101 and perplexity is 44.67827377084034
At time: 427.10955119132996 and batch: 1300, loss is 3.8082061910629275 and perplexity is 45.06952020357578
At time: 428.1922469139099 and batch: 1350, loss is 3.6857642269134523 and perplexity is 39.87558480339999
At time: 429.24456906318665 and batch: 1400, loss is 3.7210029315948487 and perplexity is 41.30580023348927
At time: 430.29228925704956 and batch: 1450, loss is 3.649102120399475 and perplexity is 38.44013593551176
At time: 431.34150290489197 and batch: 1500, loss is 3.646585297584534 and perplexity is 38.34351056984752
At time: 432.3912889957428 and batch: 1550, loss is 3.6551802825927733 and perplexity is 38.67449282454418
At time: 433.4390478134155 and batch: 1600, loss is 3.737995591163635 and perplexity is 42.01369309263838
At time: 434.48839592933655 and batch: 1650, loss is 3.6891994142532347 and perplexity is 40.01280045328014
At time: 435.53525280952454 and batch: 1700, loss is 3.7009957075119018 and perplexity is 40.48759810191656
At time: 436.5835602283478 and batch: 1750, loss is 3.6971701049804686 and perplexity is 40.333004539430924
At time: 437.6335461139679 and batch: 1800, loss is 3.663872284889221 and perplexity is 39.012116793498826
At time: 438.68106746673584 and batch: 1850, loss is 3.689216432571411 and perplexity is 40.01348140964374
At time: 439.7265467643738 and batch: 1900, loss is 3.769142107963562 and perplexity is 43.34286538252766
At time: 440.77360248565674 and batch: 1950, loss is 3.7051771831512452 and perplexity is 40.65725045847946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2831165402434594 and perplexity of 72.46593143986227
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 444.0741629600525 and batch: 50, loss is 3.8395170307159425 and perplexity is 46.50300949008561
At time: 445.12644815444946 and batch: 100, loss is 3.838883023262024 and perplexity is 46.47353557976596
At time: 446.14864778518677 and batch: 150, loss is 3.821804904937744 and perplexity is 45.68659390834028
At time: 447.17048811912537 and batch: 200, loss is 3.8365989446640016 and perplexity is 46.36750750609655
At time: 448.21432614326477 and batch: 250, loss is 3.8270269680023192 and perplexity is 45.925796204086225
At time: 449.28284668922424 and batch: 300, loss is 3.8423931121826174 and perplexity is 46.636948451179634
At time: 450.32579374313354 and batch: 350, loss is 3.8454681062698364 and perplexity is 46.78057750798842
At time: 451.3850932121277 and batch: 400, loss is 3.8130964994430543 and perplexity is 45.29046385689104
At time: 452.42337679862976 and batch: 450, loss is 3.859856491088867 and perplexity is 47.45854015670855
At time: 453.4603228569031 and batch: 500, loss is 3.8560933589935305 and perplexity is 47.28028301399516
At time: 454.523903131485 and batch: 550, loss is 3.828284249305725 and perplexity is 45.983574162960295
At time: 455.5747501850128 and batch: 600, loss is 3.794594616889954 and perplexity is 44.46020933390735
At time: 456.61303329467773 and batch: 650, loss is 3.826412796974182 and perplexity is 45.897598570584684
At time: 457.65078043937683 and batch: 700, loss is 3.8519103574752807 and perplexity is 47.082922585626214
At time: 458.6881549358368 and batch: 750, loss is 3.820339732170105 and perplexity is 45.61970416957762
At time: 459.73716950416565 and batch: 800, loss is 3.7959836769104003 and perplexity is 44.52201014577527
At time: 460.7880291938782 and batch: 850, loss is 3.7865977907180786 and perplexity is 44.106086584488594
At time: 461.84934997558594 and batch: 900, loss is 3.7510755920410155 and perplexity is 42.56684194254075
At time: 462.9221103191376 and batch: 950, loss is 3.856797151565552 and perplexity is 47.31357023826008
At time: 463.98035979270935 and batch: 1000, loss is 3.816389436721802 and perplexity is 45.43984833556979
At time: 465.0506582260132 and batch: 1050, loss is 3.765830044746399 and perplexity is 43.19954854060063
At time: 466.09105157852173 and batch: 1100, loss is 3.7800536870956423 and perplexity is 43.818394154744006
At time: 467.13005113601685 and batch: 1150, loss is 3.747849426269531 and perplexity is 42.42973553698047
At time: 468.1732897758484 and batch: 1200, loss is 3.8106141567230223 and perplexity is 45.17817682875206
At time: 469.22142219543457 and batch: 1250, loss is 3.7746241903305053 and perplexity is 43.58112702884837
At time: 470.2702691555023 and batch: 1300, loss is 3.7792126369476318 and perplexity is 43.78155618131757
At time: 471.31754899024963 and batch: 1350, loss is 3.6568993663787843 and perplexity is 38.74103469723096
At time: 472.36581659317017 and batch: 1400, loss is 3.690411062240601 and perplexity is 40.06131126549737
At time: 473.41070318222046 and batch: 1450, loss is 3.6096665239334107 and perplexity is 36.95372757613276
At time: 474.4723677635193 and batch: 1500, loss is 3.607031021118164 and perplexity is 36.85646414838913
At time: 475.52914667129517 and batch: 1550, loss is 3.619583625793457 and perplexity is 37.32202465798836
At time: 476.5774872303009 and batch: 1600, loss is 3.695018796920776 and perplexity is 40.24632908792108
At time: 477.62691140174866 and batch: 1650, loss is 3.6385633897781373 and perplexity is 38.03715289247139
At time: 478.6753771305084 and batch: 1700, loss is 3.6462258768081663 and perplexity is 38.32973159188366
At time: 479.7245593070984 and batch: 1750, loss is 3.6423544120788574 and perplexity is 38.181626265202496
At time: 480.7744951248169 and batch: 1800, loss is 3.605672183036804 and perplexity is 36.806416192595016
At time: 481.82427859306335 and batch: 1850, loss is 3.6271623086929323 and perplexity is 37.605950982854125
At time: 482.8728566169739 and batch: 1900, loss is 3.71255784034729 and perplexity is 40.958437799664544
At time: 483.92160654067993 and batch: 1950, loss is 3.660201029777527 and perplexity is 38.869155943748076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25804925962936 and perplexity of 70.67198620307356
finished 11 epochs...
Completing Train Step...
At time: 487.26990246772766 and batch: 50, loss is 3.8379415464401245 and perplexity is 46.42980241329752
At time: 488.28700613975525 and batch: 100, loss is 3.8142632102966307 and perplexity is 45.343335569639464
At time: 489.30775570869446 and batch: 150, loss is 3.788745632171631 and perplexity is 44.20092127408972
At time: 490.33672523498535 and batch: 200, loss is 3.7935431003570557 and perplexity is 44.413483259661795
At time: 491.36866879463196 and batch: 250, loss is 3.782017788887024 and perplexity is 43.90454251557921
At time: 492.40864658355713 and batch: 300, loss is 3.795410990715027 and perplexity is 44.49652030471121
At time: 493.4484760761261 and batch: 350, loss is 3.7989354848861696 and perplexity is 44.65362472533869
At time: 494.48832058906555 and batch: 400, loss is 3.7669605827331543 and perplexity is 43.248414888663106
At time: 495.5567977428436 and batch: 450, loss is 3.8155600023269653 and perplexity is 45.402174588574724
At time: 496.62278604507446 and batch: 500, loss is 3.8124173212051393 and perplexity is 45.2597140029522
At time: 497.66375064849854 and batch: 550, loss is 3.7857663106918333 and perplexity is 44.069428496803596
At time: 498.72426199913025 and batch: 600, loss is 3.7548237943649294 and perplexity is 42.7266904635876
At time: 499.7706377506256 and batch: 650, loss is 3.7888275814056396 and perplexity is 44.204543654154214
At time: 500.8112678527832 and batch: 700, loss is 3.8156622552871706 and perplexity is 45.406817332689286
At time: 501.8632142543793 and batch: 750, loss is 3.78617467880249 and perplexity is 44.08742872116522
At time: 502.92583322525024 and batch: 800, loss is 3.761932396888733 and perplexity is 43.031499623275614
At time: 503.9732618331909 and batch: 850, loss is 3.7533695840835573 and perplexity is 42.664602026789694
At time: 505.0233862400055 and batch: 900, loss is 3.720002875328064 and perplexity is 41.26451275745179
At time: 506.0913829803467 and batch: 950, loss is 3.8253278493881226 and perplexity is 45.84782908533306
At time: 507.1474447250366 and batch: 1000, loss is 3.7870803451538086 and perplexity is 44.127375308283575
At time: 508.21435546875 and batch: 1050, loss is 3.7389496517181398 and perplexity is 42.053795827143794
At time: 509.26247668266296 and batch: 1100, loss is 3.755082063674927 and perplexity is 42.73772688157479
At time: 510.31006956100464 and batch: 1150, loss is 3.725011191368103 and perplexity is 41.47169686725916
At time: 511.35605096817017 and batch: 1200, loss is 3.788691282272339 and perplexity is 44.19851902375147
At time: 512.442617893219 and batch: 1250, loss is 3.7557514619827272 and perplexity is 42.76634502102697
At time: 513.5017573833466 and batch: 1300, loss is 3.7627520418167113 and perplexity is 43.066784632299054
At time: 514.5524933338165 and batch: 1350, loss is 3.641598048210144 and perplexity is 38.15275798148642
At time: 515.6007878780365 and batch: 1400, loss is 3.677303423881531 and perplexity is 39.539628568483025
At time: 516.648321390152 and batch: 1450, loss is 3.599224534034729 and perplexity is 36.569864759761735
At time: 517.6953682899475 and batch: 1500, loss is 3.598608922958374 and perplexity is 36.547358874101846
At time: 518.7642583847046 and batch: 1550, loss is 3.6120359230041506 and perplexity is 37.04138951595986
At time: 519.8140354156494 and batch: 1600, loss is 3.690079755783081 and perplexity is 40.04804089277987
At time: 520.8621628284454 and batch: 1650, loss is 3.6350287294387815 and perplexity is 37.90294181174653
At time: 521.9103631973267 and batch: 1700, loss is 3.645102548599243 and perplexity is 38.28669889759086
At time: 522.9845385551453 and batch: 1750, loss is 3.6427976274490357 and perplexity is 38.19855269957249
At time: 524.0343942642212 and batch: 1800, loss is 3.607729926109314 and perplexity is 36.88223231884113
At time: 525.1085379123688 and batch: 1850, loss is 3.6313922071456908 and perplexity is 37.76535723518587
At time: 526.1564223766327 and batch: 1900, loss is 3.7181772089004514 and perplexity is 41.18924624853359
At time: 527.205991268158 and batch: 1950, loss is 3.6656125259399412 and perplexity is 39.08006638780663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2578826194585755 and perplexity of 70.66021039241177
finished 12 epochs...
Completing Train Step...
At time: 530.5621399879456 and batch: 50, loss is 3.822148380279541 and perplexity is 45.70228882205211
At time: 531.5785722732544 and batch: 100, loss is 3.7966259241104128 and perplexity is 44.5506134663484
At time: 532.6335337162018 and batch: 150, loss is 3.770357403755188 and perplexity is 43.395571804883666
At time: 533.6829259395599 and batch: 200, loss is 3.7734451484680176 and perplexity is 43.529773335693044
At time: 534.7191960811615 and batch: 250, loss is 3.761565775871277 and perplexity is 43.01572626270051
At time: 535.7468175888062 and batch: 300, loss is 3.7745421266555788 and perplexity is 43.577550748150315
At time: 536.7763197422028 and batch: 350, loss is 3.778259391784668 and perplexity is 43.73984150997381
At time: 537.8085305690765 and batch: 400, loss is 3.7460374450683593 and perplexity is 42.35292326602858
At time: 538.8461472988129 and batch: 450, loss is 3.7949279022216795 and perplexity is 44.47502973909844
At time: 539.9111666679382 and batch: 500, loss is 3.792287940979004 and perplexity is 44.357772230061165
At time: 540.9492712020874 and batch: 550, loss is 3.76571533203125 and perplexity is 43.19459328731506
At time: 541.9906203746796 and batch: 600, loss is 3.7359339809417724 and perplexity is 41.92716645624597
At time: 543.034529209137 and batch: 650, loss is 3.770282907485962 and perplexity is 43.39233911709635
At time: 544.0842335224152 and batch: 700, loss is 3.7980049514770506 and perplexity is 44.61209236231605
At time: 545.1449203491211 and batch: 750, loss is 3.7690432405471803 and perplexity is 43.338580397234914
At time: 546.2065632343292 and batch: 800, loss is 3.744594774246216 and perplexity is 42.291865992763384
At time: 547.257570028305 and batch: 850, loss is 3.736849389076233 and perplexity is 41.96556449773329
At time: 548.3124630451202 and batch: 900, loss is 3.7041405296325682 and perplexity is 40.615124815352566
At time: 549.3604905605316 and batch: 950, loss is 3.8095706796646116 and perplexity is 45.13105902513932
At time: 550.4078335762024 and batch: 1000, loss is 3.7722428131103514 and perplexity is 43.47746740103884
At time: 551.4575827121735 and batch: 1050, loss is 3.7250987672805786 and perplexity is 41.4753289479933
At time: 552.5067088603973 and batch: 1100, loss is 3.7415653896331786 and perplexity is 42.16394152870185
At time: 553.5548222064972 and batch: 1150, loss is 3.7122642517089846 and perplexity is 40.9464146327028
At time: 554.6039576530457 and batch: 1200, loss is 3.7761573028564452 and perplexity is 43.647993044056605
At time: 555.6525723934174 and batch: 1250, loss is 3.7444793367385865 and perplexity is 42.2869842069362
At time: 556.7023737430573 and batch: 1300, loss is 3.7523733711242677 and perplexity is 42.62212016135351
At time: 557.7514982223511 and batch: 1350, loss is 3.6317089366912843 and perplexity is 37.77732053408724
At time: 558.8008081912994 and batch: 1400, loss is 3.667893099784851 and perplexity is 39.16929307041485
At time: 559.8495123386383 and batch: 1450, loss is 3.590681791305542 and perplexity is 36.25878842783449
At time: 560.8983726501465 and batch: 1500, loss is 3.590870780944824 and perplexity is 36.26564161075016
At time: 561.9484524726868 and batch: 1550, loss is 3.6046585845947265 and perplexity is 36.769128167218376
At time: 562.9964184761047 and batch: 1600, loss is 3.6842120122909545 and perplexity is 39.813737350265846
At time: 564.0580384731293 and batch: 1650, loss is 3.6293578481674196 and perplexity is 37.68860703682437
At time: 565.1192722320557 and batch: 1700, loss is 3.640565748214722 and perplexity is 38.1133932112186
At time: 566.1734886169434 and batch: 1750, loss is 3.638810873031616 and perplexity is 38.046567615767415
At time: 567.2223036289215 and batch: 1800, loss is 3.60435097694397 and perplexity is 36.757819441496935
At time: 568.270504951477 and batch: 1850, loss is 3.6293076181411745 and perplexity is 37.6867139846482
At time: 569.3191874027252 and batch: 1900, loss is 3.7166353559494016 and perplexity is 41.12578742231479
At time: 570.3665735721588 and batch: 1950, loss is 3.6640686321258547 and perplexity is 39.01977746687787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259227663971657 and perplexity of 70.75531546663417
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 573.7218341827393 and batch: 50, loss is 3.8185267066955566 and perplexity is 45.53706941586905
At time: 574.7394516468048 and batch: 100, loss is 3.8082440805435183 and perplexity is 45.07122789663836
At time: 575.771773815155 and batch: 150, loss is 3.788231153488159 and perplexity is 44.17818669103503
At time: 576.7935359477997 and batch: 200, loss is 3.795800361633301 and perplexity is 44.51384932917241
At time: 577.8529269695282 and batch: 250, loss is 3.7883583402633665 and perplexity is 44.1838059294736
At time: 578.884090423584 and batch: 300, loss is 3.8008246517181394 and perplexity is 44.73806260560551
At time: 579.917014837265 and batch: 350, loss is 3.805971541404724 and perplexity is 44.96891806279162
At time: 580.9481084346771 and batch: 400, loss is 3.7782042455673217 and perplexity is 43.73742948967471
At time: 581.979371547699 and batch: 450, loss is 3.8244947624206542 and perplexity is 45.80964976199185
At time: 583.0104563236237 and batch: 500, loss is 3.823791437149048 and perplexity is 45.77744200522312
At time: 584.07217669487 and batch: 550, loss is 3.800087404251099 and perplexity is 44.705091737607084
At time: 585.1242823600769 and batch: 600, loss is 3.7612876749038695 and perplexity is 43.003765210880246
At time: 586.1709427833557 and batch: 650, loss is 3.789441161155701 and perplexity is 44.23167498976896
At time: 587.2204110622406 and batch: 700, loss is 3.812995071411133 and perplexity is 45.285870367235475
At time: 588.2693493366241 and batch: 750, loss is 3.781088089942932 and perplexity is 43.863743477111825
At time: 589.3171665668488 and batch: 800, loss is 3.757240128517151 and perplexity is 42.83005725903147
At time: 590.3665268421173 and batch: 850, loss is 3.7507283449172975 and perplexity is 42.55206329518034
At time: 591.4151656627655 and batch: 900, loss is 3.7101230812072754 and perplexity is 40.85883517227892
At time: 592.4634280204773 and batch: 950, loss is 3.824294772148132 and perplexity is 45.80048919369462
At time: 593.5114648342133 and batch: 1000, loss is 3.787737717628479 and perplexity is 44.15639296685074
At time: 594.563140630722 and batch: 1050, loss is 3.7357655572891235 and perplexity is 41.920105524356856
At time: 595.6295223236084 and batch: 1100, loss is 3.7488794136047363 and perplexity is 42.47346014124846
At time: 596.6782467365265 and batch: 1150, loss is 3.717938666343689 and perplexity is 41.17942203221576
At time: 597.7267735004425 and batch: 1200, loss is 3.7773129510879517 and perplexity is 43.69846392770341
At time: 598.7755427360535 and batch: 1250, loss is 3.744410490989685 and perplexity is 42.28407302805199
At time: 599.8422455787659 and batch: 1300, loss is 3.7446657752990724 and perplexity is 42.29486886637847
At time: 600.894535779953 and batch: 1350, loss is 3.621148934364319 and perplexity is 37.38049088997667
At time: 601.9445037841797 and batch: 1400, loss is 3.6589149332046507 and perplexity is 38.81919858737662
At time: 602.9931390285492 and batch: 1450, loss is 3.577412028312683 and perplexity is 35.78082116872787
At time: 604.0406074523926 and batch: 1500, loss is 3.576402630805969 and perplexity is 35.74472231916139
At time: 605.0891933441162 and batch: 1550, loss is 3.596242618560791 and perplexity is 36.46097893899446
At time: 606.1580846309662 and batch: 1600, loss is 3.6772683000564577 and perplexity is 39.53823980987512
At time: 607.2117793560028 and batch: 1650, loss is 3.618688530921936 and perplexity is 37.2886328517689
At time: 608.2595331668854 and batch: 1700, loss is 3.626063780784607 and perplexity is 37.56466247861957
At time: 609.3079872131348 and batch: 1750, loss is 3.628274736404419 and perplexity is 37.647808162070795
At time: 610.3564960956573 and batch: 1800, loss is 3.587114315032959 and perplexity is 36.12966651706535
At time: 611.4043972492218 and batch: 1850, loss is 3.6041564655303957 and perplexity is 36.75067032139273
At time: 612.4782152175903 and batch: 1900, loss is 3.694378180503845 and perplexity is 40.22055488535626
At time: 613.5266664028168 and batch: 1950, loss is 3.644972519874573 and perplexity is 38.28172085061294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246579760174418 and perplexity of 69.86604460427807
finished 14 epochs...
Completing Train Step...
At time: 616.863401889801 and batch: 50, loss is 3.818767285346985 and perplexity is 45.548025980524045
At time: 617.9055359363556 and batch: 100, loss is 3.799211368560791 and perplexity is 44.66594563090327
At time: 618.9413294792175 and batch: 150, loss is 3.773519153594971 and perplexity is 43.53299488129897
At time: 619.9663906097412 and batch: 200, loss is 3.7777895593643187 and perplexity is 43.71929594123656
At time: 620.9929316043854 and batch: 250, loss is 3.7700404739379882 and perplexity is 43.38182063343749
At time: 622.0192649364471 and batch: 300, loss is 3.780374493598938 and perplexity is 43.832453635618684
At time: 623.0471255779266 and batch: 350, loss is 3.784702572822571 and perplexity is 44.02257510111848
At time: 624.0780577659607 and batch: 400, loss is 3.7574124431610105 and perplexity is 42.8374381409933
At time: 625.1097519397736 and batch: 450, loss is 3.8044802522659302 and perplexity is 44.90190638301556
At time: 626.1423149108887 and batch: 500, loss is 3.8030457162857054 and perplexity is 44.83753916231387
At time: 627.1824264526367 and batch: 550, loss is 3.77998740196228 and perplexity is 43.81548974290447
At time: 628.2235522270203 and batch: 600, loss is 3.743616237640381 and perplexity is 42.25050209510502
At time: 629.2633562088013 and batch: 650, loss is 3.772468400001526 and perplexity is 43.48727645410128
At time: 630.3032908439636 and batch: 700, loss is 3.7980989360809327 and perplexity is 44.616285409182915
At time: 631.3454740047455 and batch: 750, loss is 3.768191418647766 and perplexity is 43.301679364148356
At time: 632.4273724555969 and batch: 800, loss is 3.7435901927948 and perplexity is 42.24940170163208
At time: 633.4881293773651 and batch: 850, loss is 3.737196559906006 and perplexity is 41.98013624687862
At time: 634.5373733043671 and batch: 900, loss is 3.6977850198745728 and perplexity is 40.357813531573846
At time: 635.5992617607117 and batch: 950, loss is 3.811724557876587 and perplexity is 45.228370590866966
At time: 636.6793541908264 and batch: 1000, loss is 3.775488271713257 and perplexity is 43.618800943673484
At time: 637.7268424034119 and batch: 1050, loss is 3.7246005487442018 and perplexity is 41.45467031699285
At time: 638.7759928703308 and batch: 1100, loss is 3.7389277362823488 and perplexity is 42.05287420998043
At time: 639.846108675003 and batch: 1150, loss is 3.7097743368148803 and perplexity is 40.84458836702391
At time: 640.910612821579 and batch: 1200, loss is 3.7696968650817873 and perplexity is 43.36691681635813
At time: 641.9732458591461 and batch: 1250, loss is 3.7381811237335203 and perplexity is 42.02148872423764
At time: 643.0210318565369 and batch: 1300, loss is 3.7399118423461912 and perplexity is 42.09427906853707
At time: 644.0682678222656 and batch: 1350, loss is 3.6176233530044555 and perplexity is 37.248934969889184
At time: 645.1162931919098 and batch: 1400, loss is 3.6559845066070555 and perplexity is 38.70560829063933
At time: 646.164915561676 and batch: 1450, loss is 3.5758408546447753 and perplexity is 35.72464742560027
At time: 647.2135355472565 and batch: 1500, loss is 3.576538233757019 and perplexity is 35.74956973764702
At time: 648.263072013855 and batch: 1550, loss is 3.5967805099487307 and perplexity is 36.4805962610829
At time: 649.3113524913788 and batch: 1600, loss is 3.678765449523926 and perplexity is 39.59747879829596
At time: 650.4056899547577 and batch: 1650, loss is 3.620798387527466 and perplexity is 37.36738957358184
At time: 651.4541099071503 and batch: 1700, loss is 3.6291391181945802 and perplexity is 37.68036431032939
At time: 652.5007481575012 and batch: 1750, loss is 3.632650890350342 and perplexity is 37.81292178412524
At time: 653.576075553894 and batch: 1800, loss is 3.5919868898391725 and perplexity is 36.30614061235499
At time: 654.6245048046112 and batch: 1850, loss is 3.6093258666992187 and perplexity is 36.94114116545124
At time: 655.6815664768219 and batch: 1900, loss is 3.699880151748657 and perplexity is 40.442457111841215
At time: 656.7312290668488 and batch: 1950, loss is 3.6496670627593994 and perplexity is 38.461858532052716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245504689771075 and perplexity of 69.79097404782249
finished 15 epochs...
Completing Train Step...
At time: 660.0594456195831 and batch: 50, loss is 3.814860992431641 and perplexity is 45.370449108772014
At time: 661.0857653617859 and batch: 100, loss is 3.793823299407959 and perplexity is 44.42592961916609
At time: 662.1015193462372 and batch: 150, loss is 3.76714346408844 and perplexity is 43.256324940670375
At time: 663.1320810317993 and batch: 200, loss is 3.7703412532806397 and perplexity is 43.39487095146529
At time: 664.1480073928833 and batch: 250, loss is 3.762299885749817 and perplexity is 43.047316126079224
At time: 665.1743659973145 and batch: 300, loss is 3.7719135904312133 and perplexity is 43.46315598868895
At time: 666.2040276527405 and batch: 350, loss is 3.776385531425476 and perplexity is 43.65795589991103
At time: 667.2347249984741 and batch: 400, loss is 3.748810667991638 and perplexity is 42.470540377552275
At time: 668.2656605243683 and batch: 450, loss is 3.796155323982239 and perplexity is 44.52965287435639
At time: 669.3029100894928 and batch: 500, loss is 3.794513864517212 and perplexity is 44.456619211468436
At time: 670.3535766601562 and batch: 550, loss is 3.77160719871521 and perplexity is 43.44984127760541
At time: 671.4122486114502 and batch: 600, loss is 3.735982117652893 and perplexity is 41.929184740722185
At time: 672.452071428299 and batch: 650, loss is 3.7649334144592284 and perplexity is 43.160831876847546
At time: 673.491311788559 and batch: 700, loss is 3.791284704208374 and perplexity is 44.31329319712803
At time: 674.5644953250885 and batch: 750, loss is 3.7617939424514772 and perplexity is 43.02554213364097
At time: 675.6222901344299 and batch: 800, loss is 3.736900873184204 and perplexity is 41.96772511300515
At time: 676.6650750637054 and batch: 850, loss is 3.730688853263855 and perplexity is 41.70782884475427
At time: 677.7132592201233 and batch: 900, loss is 3.6917211198806763 and perplexity is 40.113828285042494
At time: 678.7604525089264 and batch: 950, loss is 3.805578546524048 and perplexity is 44.951248980360276
At time: 679.8080687522888 and batch: 1000, loss is 3.7697992515563965 and perplexity is 43.371357229400864
At time: 680.8555037975311 and batch: 1050, loss is 3.719284052848816 and perplexity is 41.23486155633822
At time: 681.9036440849304 and batch: 1100, loss is 3.7340521812438965 and perplexity is 41.84834211614638
At time: 682.971960067749 and batch: 1150, loss is 3.705426993370056 and perplexity is 40.6674083238292
At time: 684.0265786647797 and batch: 1200, loss is 3.7656958723068237 and perplexity is 43.1937527406114
At time: 685.0755338668823 and batch: 1250, loss is 3.7347752237319947 and perplexity is 41.87861118714632
At time: 686.1245727539062 and batch: 1300, loss is 3.7371851444244384 and perplexity is 41.97965702614237
At time: 687.1724960803986 and batch: 1350, loss is 3.615389976501465 and perplexity is 37.16583690294199
At time: 688.2195370197296 and batch: 1400, loss is 3.654025058746338 and perplexity is 38.62984092462008
At time: 689.2657482624054 and batch: 1450, loss is 3.574474964141846 and perplexity is 35.67588477876045
At time: 690.3134391307831 and batch: 1500, loss is 3.57584584236145 and perplexity is 35.7248256104643
At time: 691.3630301952362 and batch: 1550, loss is 3.596167244911194 and perplexity is 36.458230845512155
At time: 692.4110479354858 and batch: 1600, loss is 3.6787184429168702 and perplexity is 39.595617498916724
At time: 693.4585936069489 and batch: 1650, loss is 3.6209675693511962 and perplexity is 37.373711991501956
At time: 694.5065588951111 and batch: 1700, loss is 3.629616017341614 and perplexity is 37.698338329485445
At time: 695.5536279678345 and batch: 1750, loss is 3.6335329961776734 and perplexity is 37.846291498425394
At time: 696.6179623603821 and batch: 1800, loss is 3.593062572479248 and perplexity is 36.345215509866534
At time: 697.6639506816864 and batch: 1850, loss is 3.610656566619873 and perplexity is 36.99033146057119
At time: 698.7389187812805 and batch: 1900, loss is 3.7012364530563353 and perplexity is 40.49734648415713
At time: 699.7893676757812 and batch: 1950, loss is 3.6506494760513304 and perplexity is 38.49966253964625
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245454442223838 and perplexity of 69.78746731066046
finished 16 epochs...
Completing Train Step...
At time: 703.1109731197357 and batch: 50, loss is 3.8104206037521364 and perplexity is 45.169433304602485
At time: 704.1498301029205 and batch: 100, loss is 3.788813991546631 and perplexity is 44.20394292472033
At time: 705.175984621048 and batch: 150, loss is 3.7617896795272827 and perplexity is 43.025358719407365
At time: 706.2007114887238 and batch: 200, loss is 3.76452898979187 and perplexity is 43.143380100975044
At time: 707.225522518158 and batch: 250, loss is 3.7563835859298704 and perplexity is 42.7933871979499
At time: 708.2506670951843 and batch: 300, loss is 3.7656321859359743 and perplexity is 43.19100197485006
At time: 709.2763276100159 and batch: 350, loss is 3.770290493965149 and perplexity is 43.39266831342266
At time: 710.3022100925446 and batch: 400, loss is 3.7426176929473876 and perplexity is 42.208334137260685
At time: 711.3279030323029 and batch: 450, loss is 3.7901337575912475 and perplexity is 44.26232030139691
At time: 712.3588321208954 and batch: 500, loss is 3.788439688682556 and perplexity is 44.187400358438325
At time: 713.4247741699219 and batch: 550, loss is 3.7655362844467164 and perplexity is 43.18686009204767
At time: 714.4697577953339 and batch: 600, loss is 3.730421361923218 and perplexity is 41.69667385369979
At time: 715.525496006012 and batch: 650, loss is 3.7594130277633666 and perplexity is 42.92322384230717
At time: 716.5652334690094 and batch: 700, loss is 3.786220660209656 and perplexity is 44.08945596978366
At time: 717.6042568683624 and batch: 750, loss is 3.756956696510315 and perplexity is 42.81791957013565
At time: 718.6435616016388 and batch: 800, loss is 3.73191424369812 and perplexity is 41.758968545905695
At time: 719.6844747066498 and batch: 850, loss is 3.7259105396270753 and perplexity is 41.50901114238248
At time: 720.7234573364258 and batch: 900, loss is 3.6871780443191526 and perplexity is 39.932001471293525
At time: 721.7865886688232 and batch: 950, loss is 3.8010489988327025 and perplexity is 44.74810058681618
At time: 722.8592026233673 and batch: 1000, loss is 3.765590777397156 and perplexity is 43.189213535596764
At time: 723.9074444770813 and batch: 1050, loss is 3.715362901687622 and perplexity is 41.073490018923536
At time: 724.9572033882141 and batch: 1100, loss is 3.730324378013611 and perplexity is 41.69263014334245
At time: 726.0315048694611 and batch: 1150, loss is 3.7019731044769286 and perplexity is 40.52718990272372
At time: 727.0788357257843 and batch: 1200, loss is 3.7624480724334717 and perplexity is 43.053695637763845
At time: 728.1513404846191 and batch: 1250, loss is 3.7319152259826662 and perplexity is 41.759009565115306
At time: 729.2003388404846 and batch: 1300, loss is 3.734713978767395 and perplexity is 41.87604641162727
At time: 730.2493798732758 and batch: 1350, loss is 3.6132285451889037 and perplexity is 37.0855922521933
At time: 731.3061883449554 and batch: 1400, loss is 3.6520521211624146 and perplexity is 38.55370179317347
At time: 732.3672382831573 and batch: 1450, loss is 3.572824869155884 and perplexity is 35.61706472285326
At time: 733.4253442287445 and batch: 1500, loss is 3.5745853853225706 and perplexity is 35.67982436958425
At time: 734.4832973480225 and batch: 1550, loss is 3.594918479919434 and perplexity is 36.41273149807957
At time: 735.5294907093048 and batch: 1600, loss is 3.6779096364974975 and perplexity is 39.5636052569031
At time: 736.5789318084717 and batch: 1650, loss is 3.620263977050781 and perplexity is 37.3474253841185
At time: 737.6273422241211 and batch: 1700, loss is 3.6290984582901 and perplexity is 37.678832261462446
At time: 738.6759586334229 and batch: 1750, loss is 3.633221426010132 and perplexity is 37.83450155983435
At time: 739.7305347919464 and batch: 1800, loss is 3.592901096343994 and perplexity is 36.33934709874794
At time: 740.779054403305 and batch: 1850, loss is 3.6107261991500854 and perplexity is 36.992907280623584
At time: 741.8275060653687 and batch: 1900, loss is 3.7013054132461547 and perplexity is 40.50013928515279
At time: 742.877649307251 and batch: 1950, loss is 3.65052095413208 and perplexity is 38.49471480707902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245720441951308 and perplexity of 69.80603322710083
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 746.2308385372162 and batch: 50, loss is 3.8092570209503176 and perplexity is 45.11690549499584
At time: 747.2453639507294 and batch: 100, loss is 3.792768340110779 and perplexity is 44.37908678466479
At time: 748.2656517028809 and batch: 150, loss is 3.767942500114441 and perplexity is 43.290902115014696
At time: 749.2902007102966 and batch: 200, loss is 3.77255832195282 and perplexity is 43.491187090679894
At time: 750.3161256313324 and batch: 250, loss is 3.765800004005432 and perplexity is 43.19825081364548
At time: 751.346969127655 and batch: 300, loss is 3.7751505899429323 and perplexity is 43.60407415637513
At time: 752.3781604766846 and batch: 350, loss is 3.7817715406417847 and perplexity is 43.893732430063636
At time: 753.409093618393 and batch: 400, loss is 3.75811842918396 and perplexity is 42.86769145153043
At time: 754.4689137935638 and batch: 450, loss is 3.805919089317322 and perplexity is 44.96655941102965
At time: 755.51526927948 and batch: 500, loss is 3.8061352252960203 and perplexity is 44.97627935273338
At time: 756.5670824050903 and batch: 550, loss is 3.7872139596939087 and perplexity is 44.13327176115836
At time: 757.6077072620392 and batch: 600, loss is 3.748650732040405 and perplexity is 42.463748354436426
At time: 758.6720499992371 and batch: 650, loss is 3.7747726392745973 and perplexity is 43.58759708136249
At time: 759.726765871048 and batch: 700, loss is 3.7973658084869384 and perplexity is 44.58358796637121
At time: 760.7825219631195 and batch: 750, loss is 3.762461290359497 and perplexity is 43.054264722088945
At time: 761.8227028846741 and batch: 800, loss is 3.7365533304214478 and perplexity is 41.95314206813543
At time: 762.8617091178894 and batch: 850, loss is 3.731200385093689 and perplexity is 41.72916918442779
At time: 763.899555683136 and batch: 900, loss is 3.689025192260742 and perplexity is 40.00582995068501
At time: 764.9649109840393 and batch: 950, loss is 3.803949947357178 and perplexity is 44.87810099426345
At time: 766.0053789615631 and batch: 1000, loss is 3.7703153562545775 and perplexity is 43.393747167912686
At time: 767.0656588077545 and batch: 1050, loss is 3.718845400810242 and perplexity is 41.21677776679175
At time: 768.1302332878113 and batch: 1100, loss is 3.732413854598999 and perplexity is 41.77983699441878
At time: 769.1710135936737 and batch: 1150, loss is 3.703119058609009 and perplexity is 40.57365882399523
At time: 770.2539594173431 and batch: 1200, loss is 3.763076996803284 and perplexity is 43.08078167280185
At time: 771.2982044219971 and batch: 1250, loss is 3.7329998588562012 and perplexity is 41.80432733178288
At time: 772.3715550899506 and batch: 1300, loss is 3.733183407783508 and perplexity is 41.81200117546276
At time: 773.4114611148834 and batch: 1350, loss is 3.608921961784363 and perplexity is 36.92622346984222
At time: 774.4680745601654 and batch: 1400, loss is 3.6473277902603147 and perplexity is 38.37199091752571
At time: 775.5090072154999 and batch: 1450, loss is 3.564181785583496 and perplexity is 35.310549980244566
At time: 776.5733442306519 and batch: 1500, loss is 3.56411123752594 and perplexity is 35.308058977400954
At time: 777.6142840385437 and batch: 1550, loss is 3.584328112602234 and perplexity is 36.029142058170386
At time: 778.6549782752991 and batch: 1600, loss is 3.6682949304580688 and perplexity is 39.18503565653396
At time: 779.7109959125519 and batch: 1650, loss is 3.6113464927673338 and perplexity is 37.015860863137604
At time: 780.7629518508911 and batch: 1700, loss is 3.618938102722168 and perplexity is 37.29794020437598
At time: 781.8035562038422 and batch: 1750, loss is 3.6247402954101564 and perplexity is 37.514979082109434
At time: 782.8443970680237 and batch: 1800, loss is 3.5845574378967284 and perplexity is 36.03740539924361
At time: 783.8847472667694 and batch: 1850, loss is 3.6017545890808105 and perplexity is 36.662505674521036
At time: 784.9261238574982 and batch: 1900, loss is 3.690819501876831 and perplexity is 40.077677234925346
At time: 786.00048661232 and batch: 1950, loss is 3.6413013458251955 and perplexity is 38.14143964637249
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243335528706395 and perplexity of 69.63975025792598
finished 18 epochs...
Completing Train Step...
At time: 789.3589510917664 and batch: 50, loss is 3.8076434564590453 and perplexity is 45.044165159726234
At time: 790.3774378299713 and batch: 100, loss is 3.7875485897064207 and perplexity is 44.14804254967674
At time: 791.4192905426025 and batch: 150, loss is 3.7614288997650145 and perplexity is 43.00983884051452
At time: 792.4457168579102 and batch: 200, loss is 3.7653178453445433 and perplexity is 43.17742742337283
At time: 793.493501663208 and batch: 250, loss is 3.7584229469299317 and perplexity is 42.88074741209122
At time: 794.5338587760925 and batch: 300, loss is 3.7677465009689333 and perplexity is 43.28241796666196
At time: 795.5935711860657 and batch: 350, loss is 3.773558006286621 and perplexity is 43.534686288183345
At time: 796.640273809433 and batch: 400, loss is 3.7493369483947756 and perplexity is 42.4928976732509
At time: 797.7157793045044 and batch: 450, loss is 3.7966531991958616 and perplexity is 44.551828604708916
At time: 798.7555165290833 and batch: 500, loss is 3.7966908168792726 and perplexity is 44.55350457281557
At time: 799.8127145767212 and batch: 550, loss is 3.7763721132278443 and perplexity is 43.65737009276082
At time: 800.851254940033 and batch: 600, loss is 3.739482741355896 and perplexity is 42.0762202465093
At time: 801.8919122219086 and batch: 650, loss is 3.7663433265686037 and perplexity is 43.22172777520601
At time: 802.9318714141846 and batch: 700, loss is 3.790780668258667 and perplexity is 44.29096333230683
At time: 803.9724540710449 and batch: 750, loss is 3.7573476314544676 and perplexity is 42.834661863492066
At time: 805.0138037204742 and batch: 800, loss is 3.731832585334778 and perplexity is 41.75555871610183
At time: 806.0533735752106 and batch: 850, loss is 3.7263555479049684 and perplexity is 41.5274871066216
At time: 807.0938856601715 and batch: 900, loss is 3.6846444702148435 and perplexity is 39.83095883997905
At time: 808.1365146636963 and batch: 950, loss is 3.799824848175049 and perplexity is 44.6933556848944
At time: 809.1849763393402 and batch: 1000, loss is 3.765723261833191 and perplexity is 43.19493581324282
At time: 810.2312784194946 and batch: 1050, loss is 3.714718236923218 and perplexity is 41.047019920243926
At time: 811.2814469337463 and batch: 1100, loss is 3.7290461587905885 and perplexity is 41.639371867162374
At time: 812.330552816391 and batch: 1150, loss is 3.700110149383545 and perplexity is 40.451759851089
At time: 813.3795449733734 and batch: 1200, loss is 3.760457181930542 and perplexity is 42.96806571218927
At time: 814.4273114204407 and batch: 1250, loss is 3.7305100536346436 and perplexity is 41.70037216706709
At time: 815.4763753414154 and batch: 1300, loss is 3.7309656047821047 and perplexity is 41.71937314708787
At time: 816.5252611637115 and batch: 1350, loss is 3.6077889680862425 and perplexity is 36.88440998303694
At time: 817.5752556324005 and batch: 1400, loss is 3.6465526962280275 and perplexity is 38.34226053976617
At time: 818.624505519867 and batch: 1450, loss is 3.564587106704712 and perplexity is 35.32486499284581
At time: 819.6752066612244 and batch: 1500, loss is 3.565220413208008 and perplexity is 35.347243545067194
At time: 820.7232902050018 and batch: 1550, loss is 3.5862751054763793 and perplexity is 36.099358874658506
At time: 821.7715466022491 and batch: 1600, loss is 3.6708531522750856 and perplexity is 39.28540800227289
At time: 822.8467221260071 and batch: 1650, loss is 3.614235701560974 and perplexity is 37.12296205820234
At time: 823.8953928947449 and batch: 1700, loss is 3.622121615409851 and perplexity is 37.416867873671244
At time: 824.9673264026642 and batch: 1750, loss is 3.6290401315689085 and perplexity is 37.67663464280887
At time: 826.0394349098206 and batch: 1800, loss is 3.5888415431976317 and perplexity is 36.192124618822405
At time: 827.0879933834076 and batch: 1850, loss is 3.6054577302932738 and perplexity is 36.79852380196565
At time: 828.137318611145 and batch: 1900, loss is 3.694156150817871 and perplexity is 40.211625719491984
At time: 829.1851937770844 and batch: 1950, loss is 3.6435917663574218 and perplexity is 38.22889970478917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242591183684593 and perplexity of 69.58793354365102
finished 19 epochs...
Completing Train Step...
At time: 832.5275938510895 and batch: 50, loss is 3.806541404724121 and perplexity is 44.994551502793485
At time: 833.582040309906 and batch: 100, loss is 3.7850459384918214 and perplexity is 44.03769353750767
At time: 834.6071102619171 and batch: 150, loss is 3.7583613777160645 and perplexity is 42.878107359456834
At time: 835.6245718002319 and batch: 200, loss is 3.7618672180175783 and perplexity is 43.02869497010914
At time: 836.6518268585205 and batch: 250, loss is 3.754767379760742 and perplexity is 42.72428012224673
At time: 837.6934590339661 and batch: 300, loss is 3.764026165008545 and perplexity is 43.12169199333982
At time: 838.7289135456085 and batch: 350, loss is 3.7696733331680297 and perplexity is 43.365896321818816
At time: 839.7660717964172 and batch: 400, loss is 3.7451081895828247 and perplexity is 42.31358486030064
At time: 840.810868024826 and batch: 450, loss is 3.792386975288391 and perplexity is 44.36216538893305
At time: 841.8693692684174 and batch: 500, loss is 3.7922304821014405 and perplexity is 44.3552235554803
At time: 842.9010400772095 and batch: 550, loss is 3.7715892696380617 and perplexity is 43.44906226903253
At time: 843.9348728656769 and batch: 600, loss is 3.7354097461700437 and perplexity is 41.90519253795881
At time: 844.9850528240204 and batch: 650, loss is 3.7625337505340575 and perplexity is 43.05738455465673
At time: 846.0564382076263 and batch: 700, loss is 3.7876737785339354 and perplexity is 44.15356973732445
At time: 847.0935373306274 and batch: 750, loss is 3.7547558116912843 and perplexity is 42.723785887665414
At time: 848.1375260353088 and batch: 800, loss is 3.7292994260787964 and perplexity is 41.649919093535175
At time: 849.1815505027771 and batch: 850, loss is 3.7238624620437624 and perplexity is 41.42408446505458
At time: 850.2493238449097 and batch: 900, loss is 3.6823918771743775 and perplexity is 39.741336878101286
At time: 851.3066165447235 and batch: 950, loss is 3.7976444864273073 and perplexity is 44.59601416021257
At time: 852.3465790748596 and batch: 1000, loss is 3.763571720123291 and perplexity is 43.10210001304475
At time: 853.3866853713989 and batch: 1050, loss is 3.712752676010132 and perplexity is 40.96641874150302
At time: 854.4398829936981 and batch: 1100, loss is 3.7273767471313475 and perplexity is 41.569916605126586
At time: 855.5060482025146 and batch: 1150, loss is 3.6987660837173464 and perplexity is 40.39742655147659
At time: 856.5719003677368 and batch: 1200, loss is 3.7592130088806153 and perplexity is 42.914639245599496
At time: 857.6155841350555 and batch: 1250, loss is 3.7294340038299563 and perplexity is 41.655524623164105
At time: 858.6603331565857 and batch: 1300, loss is 3.7302171421051025 and perplexity is 41.68815943598538
At time: 859.7101616859436 and batch: 1350, loss is 3.607480139732361 and perplexity is 36.873020790161355
At time: 860.7594683170319 and batch: 1400, loss is 3.646345543861389 and perplexity is 38.334318672369804
At time: 861.8079433441162 and batch: 1450, loss is 3.564816451072693 and perplexity is 35.33296748077608
At time: 862.8563268184662 and batch: 1500, loss is 3.565911293029785 and perplexity is 35.371672680214495
At time: 863.9046289920807 and batch: 1550, loss is 3.587270402908325 and perplexity is 36.1353063600938
At time: 864.9545464515686 and batch: 1600, loss is 3.672091736793518 and perplexity is 39.33409644657711
At time: 866.00226521492 and batch: 1650, loss is 3.6155904054641725 and perplexity is 37.17328675963919
At time: 867.0487508773804 and batch: 1700, loss is 3.6236136054992674 and perplexity is 37.472735136053124
At time: 868.0985560417175 and batch: 1750, loss is 3.630979299545288 and perplexity is 37.749766851067086
At time: 869.1467604637146 and batch: 1800, loss is 3.590755362510681 and perplexity is 36.261456128727794
At time: 870.218505859375 and batch: 1850, loss is 3.6071228790283203 and perplexity is 36.85984986166144
At time: 871.2678277492523 and batch: 1900, loss is 3.6956414937973023 and perplexity is 40.27139815574084
At time: 872.3324801921844 and batch: 1950, loss is 3.6445238828659057 and perplexity is 38.26455010588767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242294808321221 and perplexity of 69.56731245050365
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
2714.4685702323914


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56731245050365}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.6765022317192798, 'rnn_dropout': 0.40821417681898475, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6325352191925049 and batch: 50, loss is 7.6468743896484375 and perplexity is 2094.090040204169
At time: 2.784719944000244 and batch: 100, loss is 6.831514139175415 and perplexity is 926.5927412227421
At time: 3.941805124282837 and batch: 150, loss is 6.518230781555176 and perplexity is 677.3788933384085
At time: 5.096486330032349 and batch: 200, loss is 6.415649509429931 and perplexity is 611.3377014977762
At time: 6.25046706199646 and batch: 250, loss is 6.360890846252442 and perplexity is 578.7617145116493
At time: 7.40573787689209 and batch: 300, loss is 6.290675439834595 and perplexity is 539.5176177337439
At time: 8.562774419784546 and batch: 350, loss is 6.222218418121338 and perplexity is 503.8196758915956
At time: 9.716866254806519 and batch: 400, loss is 6.167382850646972 and perplexity is 476.9362578642191
At time: 10.870451211929321 and batch: 450, loss is 6.072171792984009 and perplexity is 433.6213955913326
At time: 12.026755094528198 and batch: 500, loss is 6.047428932189941 and perplexity is 423.0240072610069
At time: 13.182791233062744 and batch: 550, loss is 5.997529344558716 and perplexity is 402.43329022809115
At time: 14.342501878738403 and batch: 600, loss is 6.026504755020142 and perplexity is 414.26453989721904
At time: 15.500968933105469 and batch: 650, loss is 6.095037517547607 and perplexity is 443.65068955076225
At time: 16.659760236740112 and batch: 700, loss is 5.997074117660523 and perplexity is 402.25013346175723
At time: 17.817914247512817 and batch: 750, loss is 5.92449384689331 and perplexity is 374.08904110273664
At time: 18.976722240447998 and batch: 800, loss is 5.9306157779693605 and perplexity is 376.38621281767433
At time: 20.135454416275024 and batch: 850, loss is 5.957212810516357 and perplexity is 386.53128553809995
At time: 21.293681859970093 and batch: 900, loss is 5.9353855609893795 and perplexity is 378.1857817494024
At time: 22.450057983398438 and batch: 950, loss is 5.954799728393555 and perplexity is 385.5996782775367
At time: 23.610225915908813 and batch: 1000, loss is 5.941344699859619 and perplexity is 380.44617164111185
At time: 24.771812915802002 and batch: 1050, loss is 5.826854982376099 and perplexity is 339.2899265313391
At time: 25.931498289108276 and batch: 1100, loss is 5.907433795928955 and perplexity is 367.76119317387366
At time: 27.093154907226562 and batch: 1150, loss is 5.810397176742554 and perplexity is 333.75165774974363
At time: 28.263980865478516 and batch: 1200, loss is 5.881944808959961 and perplexity is 358.505789434669
At time: 29.433093547821045 and batch: 1250, loss is 5.8163589668273925 and perplexity is 335.74735813601717
At time: 30.603142499923706 and batch: 1300, loss is 5.831865234375 and perplexity is 340.99412021888816
At time: 31.774070739746094 and batch: 1350, loss is 5.794428358078003 and perplexity is 328.4643663031753
At time: 32.94338798522949 and batch: 1400, loss is 5.811594715118408 and perplexity is 334.15157757978216
At time: 34.11424231529236 and batch: 1450, loss is 5.783298645019531 and perplexity is 324.828920418027
At time: 35.33176827430725 and batch: 1500, loss is 5.753755760192871 and perplexity is 315.372903782398
At time: 36.60293793678284 and batch: 1550, loss is 5.728216028213501 and perplexity is 307.4203496648452
At time: 37.884859561920166 and batch: 1600, loss is 5.737366180419922 and perplexity is 310.24620142625184
At time: 39.17000389099121 and batch: 1650, loss is 5.729690771102906 and perplexity is 307.87405010309135
At time: 40.45256471633911 and batch: 1700, loss is 5.750657901763916 and perplexity is 314.39743488653124
At time: 41.73257851600647 and batch: 1750, loss is 5.748210678100586 and perplexity is 313.62897472465215
At time: 43.016164779663086 and batch: 1800, loss is 5.748808107376099 and perplexity is 313.8164018374491
At time: 44.29773187637329 and batch: 1850, loss is 5.710547304153442 and perplexity is 302.0363287920217
At time: 45.57858371734619 and batch: 1900, loss is 5.706381607055664 and perplexity is 300.7807539217146
At time: 46.86033654212952 and batch: 1950, loss is 5.640767383575439 and perplexity is 281.6787912372775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.102297192950582 and perplexity of 164.39913038030576
finished 1 epochs...
Completing Train Step...
At time: 50.44321966171265 and batch: 50, loss is 5.366172609329223 and perplexity is 214.04207531752598
At time: 51.521140575408936 and batch: 100, loss is 5.269370784759522 and perplexity is 194.2936714365479
At time: 52.60342788696289 and batch: 150, loss is 5.165909090042114 and perplexity is 175.19665573369556
At time: 53.708210706710815 and batch: 200, loss is 5.120390138626099 and perplexity is 167.40066634886537
At time: 54.79143261909485 and batch: 250, loss is 5.124418897628784 and perplexity is 168.07644364837432
At time: 55.887845516204834 and batch: 300, loss is 5.112799301147461 and perplexity is 166.13476579798083
At time: 57.01033663749695 and batch: 350, loss is 5.097110757827759 and perplexity is 163.548692233811
At time: 58.093586921691895 and batch: 400, loss is 5.057753686904907 and perplexity is 157.2369159801147
At time: 59.17600226402283 and batch: 450, loss is 4.998326158523559 and perplexity is 148.1649467932026
At time: 60.25667142868042 and batch: 500, loss is 4.990373382568359 and perplexity is 146.99129723869717
At time: 61.3395516872406 and batch: 550, loss is 4.9321847343444825 and perplexity is 138.68216530091982
At time: 62.423590898513794 and batch: 600, loss is 4.921364269256592 and perplexity is 137.18964919444005
At time: 63.50614356994629 and batch: 650, loss is 4.987393817901611 and perplexity is 146.55397899565332
At time: 64.58825087547302 and batch: 700, loss is 4.968538980484009 and perplexity is 143.81661492112326
At time: 65.67111682891846 and batch: 750, loss is 4.921165113449097 and perplexity is 137.16232979957311
At time: 66.75347566604614 and batch: 800, loss is 4.901745309829712 and perplexity is 134.52436160696988
At time: 67.83626985549927 and batch: 850, loss is 4.89020977973938 and perplexity is 132.9814679430813
At time: 68.928537607193 and batch: 900, loss is 4.8938295269012455 and perplexity is 133.46369948583884
At time: 70.02407050132751 and batch: 950, loss is 4.948623132705689 and perplexity is 140.98071848665788
At time: 71.11491394042969 and batch: 1000, loss is 4.9134262180328365 and perplexity is 136.1049416596054
At time: 72.19760704040527 and batch: 1050, loss is 4.82093804359436 and perplexity is 124.08142999625174
At time: 73.28029608726501 and batch: 1100, loss is 4.894799413681031 and perplexity is 133.59320695719146
At time: 74.36340951919556 and batch: 1150, loss is 4.808635082244873 and perplexity is 122.5642132259347
At time: 75.44693398475647 and batch: 1200, loss is 4.8869515323638915 and perplexity is 132.54888653548176
At time: 76.53884720802307 and batch: 1250, loss is 4.83725263595581 and perplexity is 126.12237123959228
At time: 77.64724135398865 and batch: 1300, loss is 4.867671394348145 and perplexity is 130.0178039250747
At time: 78.7536051273346 and batch: 1350, loss is 4.771658802032471 and perplexity is 118.11500896336369
At time: 79.83725881576538 and batch: 1400, loss is 4.783486490249634 and perplexity is 119.52033093521808
At time: 80.92122912406921 and batch: 1450, loss is 4.728753938674926 and perplexity is 113.15447704883746
At time: 82.0042679309845 and batch: 1500, loss is 4.704058952331543 and perplexity is 110.39434970573227
At time: 83.10976934432983 and batch: 1550, loss is 4.701870880126953 and perplexity is 110.15306297026352
At time: 84.19181060791016 and batch: 1600, loss is 4.763014335632324 and perplexity is 117.09836822622455
At time: 85.27604031562805 and batch: 1650, loss is 4.725084190368652 and perplexity is 112.73998959581475
At time: 86.37551665306091 and batch: 1700, loss is 4.750453815460205 and perplexity is 115.63675036646694
At time: 87.46385622024536 and batch: 1750, loss is 4.753980093002319 and perplexity is 116.04523743843912
At time: 88.54534888267517 and batch: 1800, loss is 4.704463109970093 and perplexity is 110.43897544272738
At time: 89.65389370918274 and batch: 1850, loss is 4.715669612884522 and perplexity is 111.68357089894035
At time: 90.7375419139862 and batch: 1900, loss is 4.788820466995239 and perplexity is 120.15955288299833
At time: 91.8206934928894 and batch: 1950, loss is 4.707136402130127 and perplexity is 110.73460606739606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.570566576580669 and perplexity of 96.59882490313552
finished 2 epochs...
Completing Train Step...
At time: 95.28314089775085 and batch: 50, loss is 4.668041048049926 and perplexity is 106.48893127413315
At time: 96.3635630607605 and batch: 100, loss is 4.617664480209351 and perplexity is 101.25726740085152
At time: 97.43128705024719 and batch: 150, loss is 4.566858520507813 and perplexity is 96.24129432519887
At time: 98.53571844100952 and batch: 200, loss is 4.553512048721314 and perplexity is 94.96534624844506
At time: 99.61491465568542 and batch: 250, loss is 4.55638087272644 and perplexity is 95.238176276966
At time: 100.69421124458313 and batch: 300, loss is 4.58075608253479 and perplexity is 97.58815101700881
At time: 101.77744483947754 and batch: 350, loss is 4.580180692672729 and perplexity is 97.53201593558353
At time: 102.86059665679932 and batch: 400, loss is 4.550886020660401 and perplexity is 94.71629173957062
At time: 103.94276547431946 and batch: 450, loss is 4.538050594329834 and perplexity is 93.50833664792461
At time: 105.02513074874878 and batch: 500, loss is 4.548304300308228 and perplexity is 94.47207614533632
At time: 106.10818314552307 and batch: 550, loss is 4.50242127418518 and perplexity is 90.23535153566385
At time: 107.19085454940796 and batch: 600, loss is 4.4822621917724605 and perplexity is 88.43450236754731
At time: 108.27277970314026 and batch: 650, loss is 4.545654821395874 and perplexity is 94.22210566377001
At time: 109.35738730430603 and batch: 700, loss is 4.564201955795288 and perplexity is 95.98596240185918
At time: 110.44125628471375 and batch: 750, loss is 4.527278709411621 and perplexity is 92.50648122967552
At time: 111.53962445259094 and batch: 800, loss is 4.509823942184449 and perplexity is 90.9058124228164
At time: 112.6227593421936 and batch: 850, loss is 4.500889797210693 and perplexity is 90.09726393847946
At time: 113.70672988891602 and batch: 900, loss is 4.487219219207764 and perplexity is 88.87396293117312
At time: 114.7897138595581 and batch: 950, loss is 4.565610866546631 and perplexity is 96.12129336850582
At time: 115.87869048118591 and batch: 1000, loss is 4.544307775497437 and perplexity is 94.09526960896623
At time: 116.96081447601318 and batch: 1050, loss is 4.467246761322022 and perplexity is 87.11653989730365
At time: 118.0441722869873 and batch: 1100, loss is 4.526036882400513 and perplexity is 92.39167548177517
At time: 119.12698173522949 and batch: 1150, loss is 4.4722327136993405 and perplexity is 87.55198346487042
At time: 120.21051287651062 and batch: 1200, loss is 4.547085466384888 and perplexity is 94.35700051740751
At time: 121.2941243648529 and batch: 1250, loss is 4.5170645332336425 and perplexity is 91.56641291751959
At time: 122.39559483528137 and batch: 1300, loss is 4.532094659805298 and perplexity is 92.95306234748293
At time: 123.48618364334106 and batch: 1350, loss is 4.416642723083496 and perplexity is 82.81777589595463
At time: 124.56826257705688 and batch: 1400, loss is 4.442194662094116 and perplexity is 84.96119833530841
At time: 125.650141954422 and batch: 1450, loss is 4.392835607528687 and perplexity is 80.86940806780906
At time: 126.73292970657349 and batch: 1500, loss is 4.381050262451172 and perplexity is 79.92192834188458
At time: 127.81508946418762 and batch: 1550, loss is 4.390155963897705 and perplexity is 80.65299695536325
At time: 128.8980987071991 and batch: 1600, loss is 4.454362659454346 and perplexity is 86.00132124542134
At time: 130.00566864013672 and batch: 1650, loss is 4.410536375045776 and perplexity is 82.31360262795876
At time: 131.08799767494202 and batch: 1700, loss is 4.437414827346802 and perplexity is 84.55606684943879
At time: 132.17030715942383 and batch: 1750, loss is 4.442613363265991 and perplexity is 84.99677913695719
At time: 133.25220489501953 and batch: 1800, loss is 4.397127227783203 and perplexity is 81.21721465050601
At time: 134.33322381973267 and batch: 1850, loss is 4.422875118255615 and perplexity is 83.33554078435975
At time: 135.41562914848328 and batch: 1900, loss is 4.506405696868897 and perplexity is 90.59560454071497
At time: 136.49876832962036 and batch: 1950, loss is 4.432529134750366 and perplexity is 84.1439594344716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425239882358285 and perplexity of 83.53284287418826
finished 3 epochs...
Completing Train Step...
At time: 139.95662331581116 and batch: 50, loss is 4.409634561538696 and perplexity is 82.23940457072612
At time: 141.03632855415344 and batch: 100, loss is 4.361235904693603 and perplexity is 78.35391257479293
At time: 142.07906460762024 and batch: 150, loss is 4.320826511383057 and perplexity is 75.25079823772766
At time: 143.12028574943542 and batch: 200, loss is 4.319715118408203 and perplexity is 75.16721148668185
At time: 144.16313648223877 and batch: 250, loss is 4.314740924835205 and perplexity is 74.7942436026465
At time: 145.20613861083984 and batch: 300, loss is 4.338547086715698 and perplexity is 76.5961708593473
At time: 146.2529740333557 and batch: 350, loss is 4.341124048233032 and perplexity is 76.7938107899019
At time: 147.30730056762695 and batch: 400, loss is 4.3068242931365965 and perplexity is 74.20446274207394
At time: 148.39381194114685 and batch: 450, loss is 4.313511810302734 and perplexity is 74.70236938442407
At time: 149.4560580253601 and batch: 500, loss is 4.328503475189209 and perplexity is 75.830719059592
At time: 150.52200055122375 and batch: 550, loss is 4.286918220520019 and perplexity is 72.74194807320147
At time: 151.58491134643555 and batch: 600, loss is 4.270640330314636 and perplexity is 71.5674477565434
At time: 152.64866852760315 and batch: 650, loss is 4.332030344009399 and perplexity is 76.09863623490783
At time: 153.71280241012573 and batch: 700, loss is 4.354714488983154 and perplexity is 77.84459667376267
At time: 154.77569317817688 and batch: 750, loss is 4.324865274429321 and perplexity is 75.55533293864616
At time: 155.84032344818115 and batch: 800, loss is 4.303310842514038 and perplexity is 73.94420649272098
At time: 156.9040994644165 and batch: 850, loss is 4.29692889213562 and perplexity is 73.47380088534109
At time: 157.9670774936676 and batch: 900, loss is 4.284154739379883 and perplexity is 72.54120457479394
At time: 159.03799653053284 and batch: 950, loss is 4.370697898864746 and perplexity is 79.09881541447915
At time: 160.11398696899414 and batch: 1000, loss is 4.3476001739501955 and perplexity is 77.29275101889812
At time: 161.20980596542358 and batch: 1050, loss is 4.277328901290893 and perplexity is 72.04773614137505
At time: 162.29428458213806 and batch: 1100, loss is 4.324616374969483 and perplexity is 75.53652959725767
At time: 163.3711814880371 and batch: 1150, loss is 4.280597658157348 and perplexity is 72.28362800012873
At time: 164.4845473766327 and batch: 1200, loss is 4.359055614471435 and perplexity is 78.18326440420672
At time: 165.60882449150085 and batch: 1250, loss is 4.337630100250244 and perplexity is 76.5259654010107
At time: 166.7060534954071 and batch: 1300, loss is 4.345715589523316 and perplexity is 77.1472234765592
At time: 167.7821717262268 and batch: 1350, loss is 4.223808259963989 and perplexity is 68.29306745020459
At time: 168.85790014266968 and batch: 1400, loss is 4.256431932449341 and perplexity is 70.55777885913692
At time: 169.95395374298096 and batch: 1450, loss is 4.20356514453888 and perplexity is 66.9245017540948
At time: 171.03103375434875 and batch: 1500, loss is 4.198224935531616 and perplexity is 66.56806350147468
At time: 172.10546350479126 and batch: 1550, loss is 4.209042987823486 and perplexity is 67.29210961650787
At time: 173.20207715034485 and batch: 1600, loss is 4.279204745292663 and perplexity is 72.18301329480771
At time: 174.27531170845032 and batch: 1650, loss is 4.238083400726318 and perplexity is 69.2749521986923
At time: 175.3624722957611 and batch: 1700, loss is 4.265652027130127 and perplexity is 71.21133656272424
At time: 176.46342158317566 and batch: 1750, loss is 4.26383909702301 and perplexity is 71.08235234171832
At time: 177.5381395816803 and batch: 1800, loss is 4.220188865661621 and perplexity is 68.04633469190405
At time: 178.61182045936584 and batch: 1850, loss is 4.251123657226563 and perplexity is 70.18423107421567
At time: 179.68588137626648 and batch: 1900, loss is 4.339486446380615 and perplexity is 76.66815601742337
At time: 180.78282570838928 and batch: 1950, loss is 4.263382635116577 and perplexity is 71.04991335979769
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375407941951308 and perplexity of 79.47225300637423
finished 4 epochs...
Completing Train Step...
At time: 184.1602382659912 and batch: 50, loss is 4.244413223266601 and perplexity is 69.71484109317771
At time: 185.2114655971527 and batch: 100, loss is 4.205499863624572 and perplexity is 67.05410719957584
At time: 186.2504243850708 and batch: 150, loss is 4.1663930702209475 and perplexity is 64.48244848250224
At time: 187.28853487968445 and batch: 200, loss is 4.172958402633667 and perplexity is 64.90718995038326
At time: 188.33448934555054 and batch: 250, loss is 4.1622529792785645 and perplexity is 64.21603714571027
At time: 189.38143920898438 and batch: 300, loss is 4.183332271575928 and perplexity is 65.58403330447831
At time: 190.42749166488647 and batch: 350, loss is 4.188028235435485 and perplexity is 65.8927378199664
At time: 191.50178480148315 and batch: 400, loss is 4.150870418548584 and perplexity is 63.489238465268805
At time: 192.5645875930786 and batch: 450, loss is 4.170621156692505 and perplexity is 64.75566303093727
At time: 193.64082717895508 and batch: 500, loss is 4.18534378528595 and perplexity is 65.71608925828264
At time: 194.7122917175293 and batch: 550, loss is 4.144126839637757 and perplexity is 63.06253414986201
At time: 195.778156042099 and batch: 600, loss is 4.134823188781739 and perplexity is 62.47854318646339
At time: 196.84146666526794 and batch: 650, loss is 4.193768877983093 and perplexity is 66.27209230171236
At time: 197.9060356616974 and batch: 700, loss is 4.216630997657776 and perplexity is 67.80466498431466
At time: 198.96888780593872 and batch: 750, loss is 4.188236684799194 and perplexity is 65.90647455089466
At time: 200.03097486495972 and batch: 800, loss is 4.164990930557251 and perplexity is 64.39209844036384
At time: 201.09581589698792 and batch: 850, loss is 4.161637887954712 and perplexity is 64.17655056358174
At time: 202.1597888469696 and batch: 900, loss is 4.140200891494751 and perplexity is 62.81543926924111
At time: 203.22378587722778 and batch: 950, loss is 4.238315081596374 and perplexity is 69.29100373923642
At time: 204.28762650489807 and batch: 1000, loss is 4.217379951477051 and perplexity is 67.85546656876497
At time: 205.3520815372467 and batch: 1050, loss is 4.149328489303588 and perplexity is 63.3914179872457
At time: 206.41694402694702 and batch: 1100, loss is 4.193198900222779 and perplexity is 66.23432944598721
At time: 207.48125171661377 and batch: 1150, loss is 4.149143595695495 and perplexity is 63.37969840272341
At time: 208.5455560684204 and batch: 1200, loss is 4.228200821876526 and perplexity is 68.59370878662249
At time: 209.60968732833862 and batch: 1250, loss is 4.217323288917542 and perplexity is 67.85162181328036
At time: 210.67350006103516 and batch: 1300, loss is 4.217093806266785 and perplexity is 67.83605282972263
At time: 211.73621439933777 and batch: 1350, loss is 4.092518424987793 and perplexity is 59.89053174838765
At time: 212.7986240386963 and batch: 1400, loss is 4.134619789123535 and perplexity is 62.465836364459655
At time: 213.86217856407166 and batch: 1450, loss is 4.078473577499389 and perplexity is 59.055257742305564
At time: 214.9254927635193 and batch: 1500, loss is 4.075612411499024 and perplexity is 58.88653233750889
At time: 216.0027940273285 and batch: 1550, loss is 4.083102288246155 and perplexity is 59.32924105404678
At time: 217.07649564743042 and batch: 1600, loss is 4.160374245643616 and perplexity is 64.09550557563165
At time: 218.1401011943817 and batch: 1650, loss is 4.112539830207825 and perplexity is 61.101708626139754
At time: 219.20371651649475 and batch: 1700, loss is 4.145811438560486 and perplexity is 63.16885875897178
At time: 220.27661967277527 and batch: 1750, loss is 4.141734347343445 and perplexity is 62.911837864581734
At time: 221.35008907318115 and batch: 1800, loss is 4.101670603752137 and perplexity is 60.44117655750041
At time: 222.41122889518738 and batch: 1850, loss is 4.132673397064209 and perplexity is 62.3443716039502
At time: 223.47302293777466 and batch: 1900, loss is 4.22031256198883 and perplexity is 68.05475229418802
At time: 224.5339114665985 and batch: 1950, loss is 4.147957897186279 and perplexity is 63.304593723364924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3514154478561045 and perplexity of 77.58820729989992
finished 5 epochs...
Completing Train Step...
At time: 227.93057775497437 and batch: 50, loss is 4.1290302753448485 and perplexity is 62.117656695436615
At time: 228.95209980010986 and batch: 100, loss is 4.093644843101502 and perplexity is 59.95803153754422
At time: 229.9800660610199 and batch: 150, loss is 4.052938804626465 and perplexity is 57.56638505939325
At time: 231.01144790649414 and batch: 200, loss is 4.066169672012329 and perplexity is 58.33309922795702
At time: 232.04245924949646 and batch: 250, loss is 4.053013725280762 and perplexity is 57.57069813219449
At time: 233.08460426330566 and batch: 300, loss is 4.070640082359314 and perplexity is 58.594455868774915
At time: 234.13422513008118 and batch: 350, loss is 4.076129698753357 and perplexity is 58.91700147010653
At time: 235.19851064682007 and batch: 400, loss is 4.041007733345031 and perplexity is 56.88363747001357
At time: 236.24587774276733 and batch: 450, loss is 4.065187964439392 and perplexity is 58.27586128275113
At time: 237.29231882095337 and batch: 500, loss is 4.0825710439682 and perplexity is 59.29773110470263
At time: 238.3437352180481 and batch: 550, loss is 4.04100124835968 and perplexity is 56.88326858165396
At time: 239.4333188533783 and batch: 600, loss is 4.037186217308045 and perplexity is 56.66667057246738
At time: 240.48292088508606 and batch: 650, loss is 4.090993328094482 and perplexity is 59.799262499393954
At time: 241.54245018959045 and batch: 700, loss is 4.1150561666488645 and perplexity is 61.25565469098039
At time: 242.62345170974731 and batch: 750, loss is 4.088706526756287 and perplexity is 59.662669705704474
At time: 243.68190479278564 and batch: 800, loss is 4.062976870536804 and perplexity is 58.14715022975136
At time: 244.75818943977356 and batch: 850, loss is 4.06009539604187 and perplexity is 57.9798418625696
At time: 245.82045483589172 and batch: 900, loss is 4.03926167011261 and perplexity is 56.78440170327457
At time: 246.88355016708374 and batch: 950, loss is 4.140749182701111 and perplexity is 62.84988986583259
At time: 247.9478898048401 and batch: 1000, loss is 4.117704696655274 and perplexity is 61.418107165655506
At time: 249.03943586349487 and batch: 1050, loss is 4.054879727363587 and perplexity is 57.67822546673344
At time: 250.1251540184021 and batch: 1100, loss is 4.0900383472442625 and perplexity is 59.74218260828925
At time: 251.18942546844482 and batch: 1150, loss is 4.052633452415466 and perplexity is 57.54880971990709
At time: 252.2523500919342 and batch: 1200, loss is 4.129027304649353 and perplexity is 62.11747216306776
At time: 253.31546354293823 and batch: 1250, loss is 4.123854565620422 and perplexity is 61.79698430507064
At time: 254.39013695716858 and batch: 1300, loss is 4.118820958137512 and perplexity is 61.486704111938096
At time: 255.46663331985474 and batch: 1350, loss is 4.000044283866882 and perplexity is 54.60056790388825
At time: 256.5297541618347 and batch: 1400, loss is 4.038889203071594 and perplexity is 56.763255323605534
At time: 257.59322118759155 and batch: 1450, loss is 3.9790910148620604 and perplexity is 53.46841014138556
At time: 258.65632367134094 and batch: 1500, loss is 3.9834624099731446 and perplexity is 53.70265329975927
At time: 259.71981287002563 and batch: 1550, loss is 3.992576322555542 and perplexity is 54.19433174117394
At time: 260.80705666542053 and batch: 1600, loss is 4.071120090484619 and perplexity is 58.62258843507981
At time: 261.8698284626007 and batch: 1650, loss is 4.0212976312637325 and perplexity is 55.773432239499215
At time: 262.93367552757263 and batch: 1700, loss is 4.054500999450684 and perplexity is 57.65638524879362
At time: 263.997474193573 and batch: 1750, loss is 4.049889049530029 and perplexity is 57.391089123880356
At time: 265.082914352417 and batch: 1800, loss is 4.007403373718262 and perplexity is 55.003860502198314
At time: 266.1684408187866 and batch: 1850, loss is 4.040552134513855 and perplexity is 56.85772725404941
At time: 267.25980734825134 and batch: 1900, loss is 4.134565758705139 and perplexity is 62.4624614003616
At time: 268.32280349731445 and batch: 1950, loss is 4.058338971138 and perplexity is 57.87809400679157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34766845703125 and perplexity of 77.29802898627673
finished 6 epochs...
Completing Train Step...
At time: 271.7586073875427 and batch: 50, loss is 4.042046203613281 and perplexity is 56.942740119136545
At time: 272.7970700263977 and batch: 100, loss is 4.00797559261322 and perplexity is 55.035343757270965
At time: 273.8629729747772 and batch: 150, loss is 3.972470660209656 and perplexity is 53.11559945808715
At time: 274.91104006767273 and batch: 200, loss is 3.9810993814468385 and perplexity is 53.57590221526829
At time: 275.9422824382782 and batch: 250, loss is 3.9711553192138673 and perplexity is 53.045780260696674
At time: 276.9734916687012 and batch: 300, loss is 3.985840368270874 and perplexity is 53.83050792602008
At time: 278.0110924243927 and batch: 350, loss is 3.991768116950989 and perplexity is 54.15054927352679
At time: 279.0557737350464 and batch: 400, loss is 3.956132006645203 and perplexity is 52.254813272250566
At time: 280.1288034915924 and batch: 450, loss is 3.9866765308380128 and perplexity is 53.87553780524398
At time: 281.1992509365082 and batch: 500, loss is 4.004375095367432 and perplexity is 54.8375454534571
At time: 282.2737147808075 and batch: 550, loss is 3.9616948127746583 and perplexity is 52.546306676780034
At time: 283.3226463794708 and batch: 600, loss is 3.9601082897186277 and perplexity is 52.46300684575184
At time: 284.37139320373535 and batch: 650, loss is 4.016181120872497 and perplexity is 55.488795687778726
At time: 285.44426941871643 and batch: 700, loss is 4.038265357017517 and perplexity is 56.72785483413125
At time: 286.4920744895935 and batch: 750, loss is 4.012219171524048 and perplexity is 55.26938682027293
At time: 287.5430748462677 and batch: 800, loss is 3.984004564285278 and perplexity is 53.73177631869055
At time: 288.6114287376404 and batch: 850, loss is 3.9836305379867554 and perplexity is 53.711682979233956
At time: 289.6692578792572 and batch: 900, loss is 3.9585534286499025 and perplexity is 52.38149754310119
At time: 290.7281823158264 and batch: 950, loss is 4.065252957344055 and perplexity is 58.27964892333116
At time: 291.78717374801636 and batch: 1000, loss is 4.03796302318573 and perplexity is 56.71070667677489
At time: 292.846143245697 and batch: 1050, loss is 3.979836621284485 and perplexity is 53.50829139739652
At time: 293.90840697288513 and batch: 1100, loss is 4.012867922782898 and perplexity is 55.30525453790392
At time: 294.97184658050537 and batch: 1150, loss is 3.9787983083724976 and perplexity is 53.452761881035975
At time: 296.058305978775 and batch: 1200, loss is 4.056221632957459 and perplexity is 57.75567615426509
At time: 297.1214642524719 and batch: 1250, loss is 4.049209084510803 and perplexity is 57.352078455308884
At time: 298.1843237876892 and batch: 1300, loss is 4.041365838050842 and perplexity is 56.90401141606045
At time: 299.2475287914276 and batch: 1350, loss is 3.920884442329407 and perplexity is 50.44504078323843
At time: 300.3100481033325 and batch: 1400, loss is 3.9654412984848024 and perplexity is 52.74353989888992
At time: 301.37290048599243 and batch: 1450, loss is 3.8996239137649535 and perplexity is 49.38387301776841
At time: 302.43628573417664 and batch: 1500, loss is 3.909233446121216 and perplexity is 49.86071639491317
At time: 303.5000960826874 and batch: 1550, loss is 3.9140602588653564 and perplexity is 50.10196650239743
At time: 304.5638563632965 and batch: 1600, loss is 3.996778302192688 and perplexity is 54.422534335151596
At time: 305.6270401477814 and batch: 1650, loss is 3.9500322914123536 and perplexity is 51.93704392825534
At time: 306.6907796859741 and batch: 1700, loss is 3.9833933687210084 and perplexity is 53.698945729321544
At time: 307.7550313472748 and batch: 1750, loss is 3.980301551818848 and perplexity is 53.533174819992006
At time: 308.8181083202362 and batch: 1800, loss is 3.9318129348754884 and perplexity is 50.99935241382078
At time: 309.8845272064209 and batch: 1850, loss is 3.9679143476486205 and perplexity is 52.87413868818547
At time: 310.9471528530121 and batch: 1900, loss is 4.06094886302948 and perplexity is 58.02934686598422
At time: 312.0080020427704 and batch: 1950, loss is 3.986163845062256 and perplexity is 53.84792366264391
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341029251453488 and perplexity of 76.78653132899025
finished 7 epochs...
Completing Train Step...
At time: 315.5168948173523 and batch: 50, loss is 3.9714747142791746 and perplexity is 53.0627255271205
At time: 316.54518866539 and batch: 100, loss is 3.93849262714386 and perplexity is 51.341152683262244
At time: 317.5738546848297 and batch: 150, loss is 3.9058273887634276 and perplexity is 49.69117682961913
At time: 318.60192251205444 and batch: 200, loss is 3.9140110445022582 and perplexity is 50.09950082669988
At time: 319.62832713127136 and batch: 250, loss is 3.9022809219360353 and perplexity is 49.51526084386358
At time: 320.6607201099396 and batch: 300, loss is 3.91290358543396 and perplexity is 50.044048391510785
At time: 321.6986813545227 and batch: 350, loss is 3.9232390451431276 and perplexity is 50.56395876557117
At time: 322.7379813194275 and batch: 400, loss is 3.88852596282959 and perplexity is 48.838843169293916
At time: 323.80513429641724 and batch: 450, loss is 3.9181650829315187 and perplexity is 50.30804893696023
At time: 324.85077452659607 and batch: 500, loss is 3.9372760486602782 and perplexity is 51.27873012025813
At time: 325.8967432975769 and batch: 550, loss is 3.901739139556885 and perplexity is 49.48844161378849
At time: 326.95286774635315 and batch: 600, loss is 3.895352849960327 and perplexity is 49.173401134563065
At time: 328.0096035003662 and batch: 650, loss is 3.953271369934082 and perplexity is 52.1055448382439
At time: 329.0665166378021 and batch: 700, loss is 3.9763370609283446 and perplexity is 53.3213631761682
At time: 330.124596118927 and batch: 750, loss is 3.947767276763916 and perplexity is 51.819538888515694
At time: 331.1812210083008 and batch: 800, loss is 3.9203300046920777 and perplexity is 50.41707990600922
At time: 332.2380487918854 and batch: 850, loss is 3.922344489097595 and perplexity is 50.518746695951485
At time: 333.2948889732361 and batch: 900, loss is 3.8999690914154055 and perplexity is 49.40092216935066
At time: 334.351886510849 and batch: 950, loss is 4.004433345794678 and perplexity is 54.840739856945675
At time: 335.41771817207336 and batch: 1000, loss is 3.974144253730774 and perplexity is 53.204567808872184
At time: 336.49377155303955 and batch: 1050, loss is 3.921628303527832 and perplexity is 50.48257885155538
At time: 337.55646777153015 and batch: 1100, loss is 3.9500698900222777 and perplexity is 51.93899672562162
At time: 338.61728048324585 and batch: 1150, loss is 3.91515109539032 and perplexity is 50.156649377046854
At time: 339.6777877807617 and batch: 1200, loss is 3.9945906305313112 and perplexity is 54.30360583473305
At time: 340.73930644989014 and batch: 1250, loss is 3.9875554895401 and perplexity is 53.9229129953953
At time: 341.7997610569 and batch: 1300, loss is 3.981310362815857 and perplexity is 53.5872069249637
At time: 342.8627870082855 and batch: 1350, loss is 3.8628436088562013 and perplexity is 47.60051634945674
At time: 343.9265248775482 and batch: 1400, loss is 3.9033178329467773 and perplexity is 49.56663039125435
At time: 344.99164366722107 and batch: 1450, loss is 3.8413273763656615 and perplexity is 46.58727226037141
At time: 346.0546123981476 and batch: 1500, loss is 3.853610677719116 and perplexity is 47.16304673108693
At time: 347.1172695159912 and batch: 1550, loss is 3.8537559604644773 and perplexity is 47.169899205756735
At time: 348.1817684173584 and batch: 1600, loss is 3.9390806341171265 and perplexity is 51.37135051645371
At time: 349.24673223495483 and batch: 1650, loss is 3.8885346937179563 and perplexity is 48.83926957764304
At time: 350.30954933166504 and batch: 1700, loss is 3.9197285079956057 and perplexity is 50.38676331757792
At time: 351.4118666648865 and batch: 1750, loss is 3.920312523841858 and perplexity is 50.41619858029005
At time: 352.4830629825592 and batch: 1800, loss is 3.870802574157715 and perplexity is 47.98087884552984
At time: 353.54745841026306 and batch: 1850, loss is 3.910818486213684 and perplexity is 49.939810296381424
At time: 354.61150765419006 and batch: 1900, loss is 3.9998027753829954 and perplexity is 54.58738299571211
At time: 355.6782202720642 and batch: 1950, loss is 3.926234450340271 and perplexity is 50.71564537846327
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342767759811046 and perplexity of 76.92014146296883
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 359.0531675815582 and batch: 50, loss is 3.9457443952560425 and perplexity is 51.714820054157904
At time: 360.095920085907 and batch: 100, loss is 3.9347295331954957 and perplexity is 51.1483141645926
At time: 361.1222059726715 and batch: 150, loss is 3.9093554830551147 and perplexity is 49.86680161516726
At time: 362.1474087238312 and batch: 200, loss is 3.9112263774871825 and perplexity is 49.960184464141626
At time: 363.17347025871277 and batch: 250, loss is 3.9069244050979615 and perplexity is 49.745718773515264
At time: 364.20040941238403 and batch: 300, loss is 3.908950033187866 and perplexity is 49.846587225310046
At time: 365.2368314266205 and batch: 350, loss is 3.9132074308395386 and perplexity is 50.059256356009165
At time: 366.30042910575867 and batch: 400, loss is 3.8752422094345094 and perplexity is 48.19437000864803
At time: 367.3454065322876 and batch: 450, loss is 3.89395028591156 and perplexity is 49.10448063398258
At time: 368.3924915790558 and batch: 500, loss is 3.9099657773971557 and perplexity is 49.89724433061228
At time: 369.4397978782654 and batch: 550, loss is 3.8599792385101317 and perplexity is 47.464365927671636
At time: 370.5132327079773 and batch: 600, loss is 3.8422983837127687 and perplexity is 46.63253081365577
At time: 371.56103587150574 and batch: 650, loss is 3.9078187704086305 and perplexity is 49.79022952020752
At time: 372.63456654548645 and batch: 700, loss is 3.931502561569214 and perplexity is 50.98352603236446
At time: 373.685578584671 and batch: 750, loss is 3.891262640953064 and perplexity is 48.972682416910246
At time: 374.73192739486694 and batch: 800, loss is 3.8552887725830076 and perplexity is 47.24225724035814
At time: 375.7780900001526 and batch: 850, loss is 3.846937265396118 and perplexity is 46.849356131366974
At time: 376.8909320831299 and batch: 900, loss is 3.810772557258606 and perplexity is 45.18533364296507
At time: 377.95713353157043 and batch: 950, loss is 3.91368528842926 and perplexity is 50.083183267967634
At time: 379.00929141044617 and batch: 1000, loss is 3.874661755561829 and perplexity is 48.16640351734942
At time: 380.09188580513 and batch: 1050, loss is 3.8203863668441773 and perplexity is 45.621831679220314
At time: 381.15087246894836 and batch: 1100, loss is 3.8429001474380495 and perplexity is 46.660601024087605
At time: 382.2110905647278 and batch: 1150, loss is 3.805881462097168 and perplexity is 44.96486747623073
At time: 383.2686321735382 and batch: 1200, loss is 3.8685611581802366 and perplexity is 47.87345417373452
At time: 384.3263819217682 and batch: 1250, loss is 3.8576617097854613 and perplexity is 47.354493261942046
At time: 385.38474798202515 and batch: 1300, loss is 3.8455643320083617 and perplexity is 46.78507922019458
At time: 386.4435405731201 and batch: 1350, loss is 3.7326981163024904 and perplexity is 41.791715090218304
At time: 387.5028073787689 and batch: 1400, loss is 3.762205791473389 and perplexity is 43.0432658105749
At time: 388.5613307952881 and batch: 1450, loss is 3.6880145263671875 and perplexity is 39.96541784781744
At time: 389.61990690231323 and batch: 1500, loss is 3.6938658142089844 and perplexity is 40.199952507105216
At time: 390.6886763572693 and batch: 1550, loss is 3.688964352607727 and perplexity is 40.003396083910786
At time: 391.7533962726593 and batch: 1600, loss is 3.768730206489563 and perplexity is 43.32501606872095
At time: 392.8119568824768 and batch: 1650, loss is 3.708608641624451 and perplexity is 40.79700376676757
At time: 393.87085795402527 and batch: 1700, loss is 3.7307761240005495 and perplexity is 41.7114688765353
At time: 394.9293088912964 and batch: 1750, loss is 3.714675898551941 and perplexity is 41.04528209306338
At time: 395.9877128601074 and batch: 1800, loss is 3.664778323173523 and perplexity is 39.04747928233065
At time: 397.04573822021484 and batch: 1850, loss is 3.6848815488815307 and perplexity is 39.840403030057466
At time: 398.1043939590454 and batch: 1900, loss is 3.771076788902283 and perplexity is 43.426801166312366
At time: 399.16287326812744 and batch: 1950, loss is 3.6967333221435545 and perplexity is 40.315391622076945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.27638422056686 and perplexity of 71.97970617219163
finished 9 epochs...
Completing Train Step...
At time: 402.5144636631012 and batch: 50, loss is 3.8657968044281006 and perplexity is 47.74129775876021
At time: 403.55797839164734 and batch: 100, loss is 3.8414001989364626 and perplexity is 46.590664988836124
At time: 404.58405232429504 and batch: 150, loss is 3.807629442214966 and perplexity is 45.04353390422463
At time: 405.614129781723 and batch: 200, loss is 3.804894862174988 and perplexity is 44.920527018220724
At time: 406.6531801223755 and batch: 250, loss is 3.801004195213318 and perplexity is 44.7460957548615
At time: 407.70005917549133 and batch: 300, loss is 3.805657639503479 and perplexity is 44.95480444917575
At time: 408.74706840515137 and batch: 350, loss is 3.812418456077576 and perplexity is 45.25976536698325
At time: 409.7955005168915 and batch: 400, loss is 3.777775511741638 and perplexity is 43.71868179337699
At time: 410.84322214126587 and batch: 450, loss is 3.800754270553589 and perplexity is 44.73491399946218
At time: 411.8898980617523 and batch: 500, loss is 3.8213397598266603 and perplexity is 45.66534795415067
At time: 412.93739676475525 and batch: 550, loss is 3.7747806310653687 and perplexity is 43.58794542571054
At time: 413.98618054389954 and batch: 600, loss is 3.762029752731323 and perplexity is 43.0356891951157
At time: 415.0340168476105 and batch: 650, loss is 3.823346161842346 and perplexity is 45.75706297816969
At time: 416.11839270591736 and batch: 700, loss is 3.850591630935669 and perplexity is 47.020874007595445
At time: 417.17709136009216 and batch: 750, loss is 3.8147182750701902 and perplexity is 45.36397442002362
At time: 418.22420620918274 and batch: 800, loss is 3.778842582702637 and perplexity is 43.76535762795676
At time: 419.2718207836151 and batch: 850, loss is 3.775735378265381 and perplexity is 43.62958076701009
At time: 420.3192093372345 and batch: 900, loss is 3.7397395849227903 and perplexity is 42.08702864097272
At time: 421.3941786289215 and batch: 950, loss is 3.8459109926223753 and perplexity is 46.80130057597386
At time: 422.44117188453674 and batch: 1000, loss is 3.8078919219970704 and perplexity is 45.05535847297625
At time: 423.5135250091553 and batch: 1050, loss is 3.756848316192627 and perplexity is 42.81327920187674
At time: 424.56509923934937 and batch: 1100, loss is 3.7786826133728026 and perplexity is 43.75835707297903
At time: 425.62299251556396 and batch: 1150, loss is 3.7455122423172 and perplexity is 42.33068523445847
At time: 426.6813883781433 and batch: 1200, loss is 3.8114003896713258 and perplexity is 45.2137113673011
At time: 427.73814511299133 and batch: 1250, loss is 3.804118847846985 and perplexity is 44.88568156766625
At time: 428.81729459762573 and batch: 1300, loss is 3.7953564071655275 and perplexity is 44.494091592977064
At time: 429.8745148181915 and batch: 1350, loss is 3.682812285423279 and perplexity is 39.758047976442874
At time: 430.9347388744354 and batch: 1400, loss is 3.718425040245056 and perplexity is 41.1994554998486
At time: 431.99598026275635 and batch: 1450, loss is 3.643992862701416 and perplexity is 38.244236252206626
At time: 433.07385993003845 and batch: 1500, loss is 3.6514494132995607 and perplexity is 38.53047217500055
At time: 434.1423931121826 and batch: 1550, loss is 3.650264735221863 and perplexity is 38.48485299664714
At time: 435.2045352458954 and batch: 1600, loss is 3.7327947092056273 and perplexity is 41.79575206827452
At time: 436.28800916671753 and batch: 1650, loss is 3.676905269622803 and perplexity is 39.52388883060972
At time: 437.3556342124939 and batch: 1700, loss is 3.7027536916732786 and perplexity is 40.558837258419224
At time: 438.41748428344727 and batch: 1750, loss is 3.692476525306702 and perplexity is 40.14414193669463
At time: 439.47947359085083 and batch: 1800, loss is 3.644214334487915 and perplexity is 38.25270720953709
At time: 440.5404760837555 and batch: 1850, loss is 3.668291702270508 and perplexity is 39.18490916009347
At time: 441.6019265651703 and batch: 1900, loss is 3.757479815483093 and perplexity is 42.840324295895314
At time: 442.6632511615753 and batch: 1950, loss is 3.684288582801819 and perplexity is 39.81678602519198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.279403899436773 and perplexity of 72.19739027260957
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 446.0000834465027 and batch: 50, loss is 3.845505504608154 and perplexity is 46.78232705656766
At time: 447.0393018722534 and batch: 100, loss is 3.8507201147079466 and perplexity is 47.02691581499252
At time: 448.0522925853729 and batch: 150, loss is 3.8272036695480347 and perplexity is 45.93391208028652
At time: 449.0883700847626 and batch: 200, loss is 3.8347539710998535 and perplexity is 46.28203954781805
At time: 450.09792399406433 and batch: 250, loss is 3.8395843935012817 and perplexity is 46.50614216784328
At time: 451.1243999004364 and batch: 300, loss is 3.8396237659454346 and perplexity is 46.507973264375686
At time: 452.1522295475006 and batch: 350, loss is 3.8576937770843505 and perplexity is 47.35601181697907
At time: 453.1819112300873 and batch: 400, loss is 3.8215131425857543 and perplexity is 45.67326622459989
At time: 454.21175146102905 and batch: 450, loss is 3.844303984642029 and perplexity is 46.726150911685465
At time: 455.2621099948883 and batch: 500, loss is 3.8640635585784913 and perplexity is 47.65862202195118
At time: 456.35949182510376 and batch: 550, loss is 3.8099724149703977 and perplexity is 45.149193407304125
At time: 457.3894157409668 and batch: 600, loss is 3.7803155422210692 and perplexity is 43.8298697282447
At time: 458.4210772514343 and batch: 650, loss is 3.836496558189392 and perplexity is 46.36276034349333
At time: 459.45984959602356 and batch: 700, loss is 3.8639146947860716 and perplexity is 47.65152790677705
At time: 460.5207402706146 and batch: 750, loss is 3.830547823905945 and perplexity is 46.08777930702797
At time: 461.59194588661194 and batch: 800, loss is 3.794669737815857 and perplexity is 44.4635493514494
At time: 462.63249135017395 and batch: 850, loss is 3.7887361526489256 and perplexity is 44.20050227243887
At time: 463.67127799987793 and batch: 900, loss is 3.74891535282135 and perplexity is 42.474986631563084
At time: 464.70983123779297 and batch: 950, loss is 3.8543187475204466 and perplexity is 47.19645328590653
At time: 465.74953866004944 and batch: 1000, loss is 3.8038756132125853 and perplexity is 44.87476514300046
At time: 466.78980588912964 and batch: 1050, loss is 3.7490965843200685 and perplexity is 42.482685134632916
At time: 467.8553059101105 and batch: 1100, loss is 3.7711776638031007 and perplexity is 43.43118206153032
At time: 468.9099078178406 and batch: 1150, loss is 3.7385258960723875 and perplexity is 42.035979068979266
At time: 469.9616241455078 and batch: 1200, loss is 3.798092761039734 and perplexity is 44.616009902633
At time: 471.00957584381104 and batch: 1250, loss is 3.7831824970245362 and perplexity is 43.95570828433042
At time: 472.05719900131226 and batch: 1300, loss is 3.773114619255066 and perplexity is 43.51538785151478
At time: 473.1070795059204 and batch: 1350, loss is 3.66079692363739 and perplexity is 38.892324737498406
At time: 474.1724708080292 and batch: 1400, loss is 3.692842597961426 and perplexity is 40.158840299475216
At time: 475.219824552536 and batch: 1450, loss is 3.6142173910140993 and perplexity is 37.122282322688626
At time: 476.284969329834 and batch: 1500, loss is 3.620111870765686 and perplexity is 37.34174503800457
At time: 477.3334755897522 and batch: 1550, loss is 3.6159270095825193 and perplexity is 37.18580154720132
At time: 478.3809850215912 and batch: 1600, loss is 3.692998375892639 and perplexity is 40.16509664782484
At time: 479.4284236431122 and batch: 1650, loss is 3.636160664558411 and perplexity is 37.94586977397099
At time: 480.47624468803406 and batch: 1700, loss is 3.6556920909881594 and perplexity is 38.69429182087316
At time: 481.52267694473267 and batch: 1750, loss is 3.6468877744674684 and perplexity is 38.35511034964963
At time: 482.57018852233887 and batch: 1800, loss is 3.5964979362487792 and perplexity is 36.470289260333224
At time: 483.6184813976288 and batch: 1850, loss is 3.609990005493164 and perplexity is 36.965683359201215
At time: 484.66649317741394 and batch: 1900, loss is 3.698219041824341 and perplexity is 40.37533351024382
At time: 485.7134006023407 and batch: 1950, loss is 3.634300537109375 and perplexity is 37.87535122710251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253320028615552 and perplexity of 70.33855112133617
finished 11 epochs...
Completing Train Step...
At time: 489.058780670166 and batch: 50, loss is 3.8396708583831787 and perplexity is 46.510163489782364
At time: 490.0964367389679 and batch: 100, loss is 3.8218243408203123 and perplexity is 45.687481876243616
At time: 491.10530257225037 and batch: 150, loss is 3.7898721742630004 and perplexity is 44.25074353054767
At time: 492.12059235572815 and batch: 200, loss is 3.790057578086853 and perplexity is 44.25894854820388
At time: 493.14301323890686 and batch: 250, loss is 3.7913759565353393 and perplexity is 44.3173370727515
At time: 494.17520356178284 and batch: 300, loss is 3.790570406913757 and perplexity is 44.28165163376867
At time: 495.20584893226624 and batch: 350, loss is 3.8084122848510744 and perplexity is 45.07880970894629
At time: 496.2443709373474 and batch: 400, loss is 3.7726828956604006 and perplexity is 43.49660528657823
At time: 497.2862503528595 and batch: 450, loss is 3.797278366088867 and perplexity is 44.579689640966755
At time: 498.32613587379456 and batch: 500, loss is 3.8195875215530397 and perplexity is 45.585401446807445
At time: 499.36747694015503 and batch: 550, loss is 3.766932282447815 and perplexity is 43.24719096350009
At time: 500.40724897384644 and batch: 600, loss is 3.741533193588257 and perplexity is 42.162584038399345
At time: 501.44781279563904 and batch: 650, loss is 3.7981715631484985 and perplexity is 44.619525876829265
At time: 502.4875180721283 and batch: 700, loss is 3.8280033445358277 and perplexity is 45.970658971695336
At time: 503.5288224220276 and batch: 750, loss is 3.796640033721924 and perplexity is 44.55124206263161
At time: 504.5681324005127 and batch: 800, loss is 3.761360836029053 and perplexity is 43.00691152982291
At time: 505.6223359107971 and batch: 850, loss is 3.756285939216614 and perplexity is 42.789208768349184
At time: 506.66246819496155 and batch: 900, loss is 3.7172700214385985 and perplexity is 41.15189682479972
At time: 507.7240171432495 and batch: 950, loss is 3.823897647857666 and perplexity is 45.78230431798748
At time: 508.7641978263855 and batch: 1000, loss is 3.7746749210357664 and perplexity is 43.58333798623986
At time: 509.80513429641724 and batch: 1050, loss is 3.7230661344528198 and perplexity is 41.39111045446523
At time: 510.8458721637726 and batch: 1100, loss is 3.744720849990845 and perplexity is 42.29719830739088
At time: 511.88639974594116 and batch: 1150, loss is 3.7148319721221923 and perplexity is 41.0516886767178
At time: 512.9248559474945 and batch: 1200, loss is 3.776599988937378 and perplexity is 43.66731968053871
At time: 513.9765601158142 and batch: 1250, loss is 3.7641483211517333 and perplexity is 43.12695989466818
At time: 515.0530507564545 and batch: 1300, loss is 3.75654746055603 and perplexity is 42.80040052291638
At time: 516.0983860492706 and batch: 1350, loss is 3.644591794013977 and perplexity is 38.267148783654385
At time: 517.1388444900513 and batch: 1400, loss is 3.6788536071777345 and perplexity is 39.60096977299936
At time: 518.1786909103394 and batch: 1450, loss is 3.602358465194702 and perplexity is 36.68465197211036
At time: 519.2192895412445 and batch: 1500, loss is 3.6105600214004516 and perplexity is 36.98676039329138
At time: 520.2598083019257 and batch: 1550, loss is 3.608249554634094 and perplexity is 36.90140235903007
At time: 521.3012263774872 and batch: 1600, loss is 3.6873305511474608 and perplexity is 39.9380918385854
At time: 522.3422982692719 and batch: 1650, loss is 3.6328873825073242 and perplexity is 37.8218653010539
At time: 523.3809072971344 and batch: 1700, loss is 3.6547023391723634 and perplexity is 38.65601302166288
At time: 524.4182696342468 and batch: 1750, loss is 3.648065223693848 and perplexity is 38.4002981426038
At time: 525.457957983017 and batch: 1800, loss is 3.598526997566223 and perplexity is 36.54436484003938
At time: 526.498509645462 and batch: 1850, loss is 3.6135320711135863 and perplexity is 37.09685039935738
At time: 527.5395381450653 and batch: 1900, loss is 3.702982840538025 and perplexity is 40.56813233486986
At time: 528.5802114009857 and batch: 1950, loss is 3.638888750076294 and perplexity is 38.04953068538953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2529024345930235 and perplexity of 70.30918429496691
finished 12 epochs...
Completing Train Step...
At time: 531.9200513362885 and batch: 50, loss is 3.822617449760437 and perplexity is 45.72373139958182
At time: 532.9275405406952 and batch: 100, loss is 3.8027891302108765 and perplexity is 44.82603594998038
At time: 533.9871716499329 and batch: 150, loss is 3.7704786396026613 and perplexity is 43.400833222737795
At time: 535.0319111347198 and batch: 200, loss is 3.7693439388275145 and perplexity is 43.351614193354315
At time: 536.0784685611725 and batch: 250, loss is 3.7698935317993163 and perplexity is 43.375446484261154
At time: 537.1332759857178 and batch: 300, loss is 3.7687928819656373 and perplexity is 43.327731569825765
At time: 538.1710460186005 and batch: 350, loss is 3.786367807388306 and perplexity is 44.09594408618012
At time: 539.2085244655609 and batch: 400, loss is 3.7508983278274535 and perplexity is 42.55929703352092
At time: 540.2460730075836 and batch: 450, loss is 3.7764139699935915 and perplexity is 43.659197487318075
At time: 541.2837617397308 and batch: 500, loss is 3.7988682651519774 and perplexity is 44.650623221435204
At time: 542.3248317241669 and batch: 550, loss is 3.746572003364563 and perplexity is 42.37556942483568
At time: 543.3709349632263 and batch: 600, loss is 3.7231913089752195 and perplexity is 41.39629189123313
At time: 544.4380040168762 and batch: 650, loss is 3.779645366668701 and perplexity is 43.80050586166114
At time: 545.5054540634155 and batch: 700, loss is 3.8102625465393065 and perplexity is 45.16229451405278
At time: 546.583265542984 and batch: 750, loss is 3.779511981010437 and perplexity is 43.79466389198063
At time: 547.6430599689484 and batch: 800, loss is 3.744218726158142 and perplexity is 42.275965207333094
At time: 548.6941893100739 and batch: 850, loss is 3.739666295051575 and perplexity is 42.08394420109426
At time: 549.7337143421173 and batch: 900, loss is 3.7009293699264525 and perplexity is 40.48491234150225
At time: 550.7745368480682 and batch: 950, loss is 3.8077081441879272 and perplexity is 45.04707905871554
At time: 551.8150820732117 and batch: 1000, loss is 3.7593669366836546 and perplexity is 42.921245510167644
At time: 552.8551545143127 and batch: 1050, loss is 3.70907350063324 and perplexity is 40.815973030175044
At time: 553.8948514461517 and batch: 1100, loss is 3.730340337753296 and perplexity is 41.69329555217618
At time: 554.9351029396057 and batch: 1150, loss is 3.7014054822921754 and perplexity is 40.50419229824195
At time: 555.975424528122 and batch: 1200, loss is 3.763966121673584 and perplexity is 43.11910290087303
At time: 557.0158772468567 and batch: 1250, loss is 3.752561831474304 and perplexity is 42.630153497997355
At time: 558.0585427284241 and batch: 1300, loss is 3.7460748624801634 and perplexity is 42.35450803244828
At time: 559.1067702770233 and batch: 1350, loss is 3.634034376144409 and perplexity is 37.86527162852884
At time: 560.1573204994202 and batch: 1400, loss is 3.669217391014099 and perplexity is 39.22119898337067
At time: 561.2033960819244 and batch: 1450, loss is 3.593437075614929 and perplexity is 36.35882945611564
At time: 562.2753386497498 and batch: 1500, loss is 3.6025168228149416 and perplexity is 36.69046172629326
At time: 563.3225557804108 and batch: 1550, loss is 3.6006662464141845 and perplexity is 36.62262601063633
At time: 564.3704969882965 and batch: 1600, loss is 3.6807080554962157 and perplexity is 39.67447586035969
At time: 565.4184296131134 and batch: 1650, loss is 3.6274107837677003 and perplexity is 37.61529628532559
At time: 566.4661061763763 and batch: 1700, loss is 3.6502781438827516 and perplexity is 38.485369030449974
At time: 567.5144011974335 and batch: 1750, loss is 3.6448075485229494 and perplexity is 38.27540598428209
At time: 568.5916905403137 and batch: 1800, loss is 3.595350856781006 and perplexity is 36.428478924812126
At time: 569.6396126747131 and batch: 1850, loss is 3.6111690378189087 and perplexity is 37.00929279824227
At time: 570.6838798522949 and batch: 1900, loss is 3.701405324935913 and perplexity is 40.50418592465415
At time: 571.7328636646271 and batch: 1950, loss is 3.6368414831161497 and perplexity is 37.97171282251796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2540632380995635 and perplexity of 70.39084683054753
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 575.1070911884308 and batch: 50, loss is 3.8195593214035033 and perplexity is 45.58411594979566
At time: 576.1155047416687 and batch: 100, loss is 3.814827394485474 and perplexity is 45.368924780472575
At time: 577.1263072490692 and batch: 150, loss is 3.7911852979660035 and perplexity is 44.30888839810014
At time: 578.1409764289856 and batch: 200, loss is 3.794494481086731 and perplexity is 44.45575749803205
At time: 579.1619358062744 and batch: 250, loss is 3.800007266998291 and perplexity is 44.70150933791246
At time: 580.1893157958984 and batch: 300, loss is 3.7992126893997193 and perplexity is 44.666004627462
At time: 581.2281527519226 and batch: 350, loss is 3.8252257537841796 and perplexity is 45.84314846247269
At time: 582.2686893939972 and batch: 400, loss is 3.794753966331482 and perplexity is 44.46729460793717
At time: 583.3087167739868 and batch: 450, loss is 3.8247001361846924 and perplexity is 45.81905882834735
At time: 584.348881483078 and batch: 500, loss is 3.851953163146973 and perplexity is 47.08493804488895
At time: 585.404233455658 and batch: 550, loss is 3.801158618927002 and perplexity is 44.75300614669129
At time: 586.4450650215149 and batch: 600, loss is 3.7737964630126952 and perplexity is 43.54506866477087
At time: 587.4950103759766 and batch: 650, loss is 3.8103692722320557 and perplexity is 45.16711474843779
At time: 588.5701894760132 and batch: 700, loss is 3.8355336427688598 and perplexity is 46.31813841364013
At time: 589.6368534564972 and batch: 750, loss is 3.801438422203064 and perplexity is 44.76552993644175
At time: 590.676566362381 and batch: 800, loss is 3.769909462928772 and perplexity is 43.37613750961869
At time: 591.7161719799042 and batch: 850, loss is 3.7649641323089598 and perplexity is 43.16215770515862
At time: 592.781581401825 and batch: 900, loss is 3.7231193923950197 and perplexity is 41.393314918535495
At time: 593.8212413787842 and batch: 950, loss is 3.833885111808777 and perplexity is 46.24184443222544
At time: 594.8611326217651 and batch: 1000, loss is 3.7829095840454103 and perplexity is 43.94371383782747
At time: 595.9058508872986 and batch: 1050, loss is 3.7273915100097654 and perplexity is 41.570530301281224
At time: 596.9719054698944 and batch: 1100, loss is 3.7449334764480593 and perplexity is 42.30619276701323
At time: 598.0152544975281 and batch: 1150, loss is 3.7155385780334473 and perplexity is 41.08070629340616
At time: 599.0579829216003 and batch: 1200, loss is 3.7732821226119997 and perplexity is 43.52267743555604
At time: 600.1037509441376 and batch: 1250, loss is 3.7557684803009033 and perplexity is 42.76707283848686
At time: 601.1872100830078 and batch: 1300, loss is 3.7461908721923827 and perplexity is 42.35942185175619
At time: 602.2282843589783 and batch: 1350, loss is 3.633883934020996 and perplexity is 37.85957552513912
At time: 603.2687404155731 and batch: 1400, loss is 3.6634552001953127 and perplexity is 38.99584882950251
At time: 604.3229699134827 and batch: 1450, loss is 3.5841925621032713 and perplexity is 36.024258620970855
At time: 605.3758840560913 and batch: 1500, loss is 3.592484002113342 and perplexity is 36.324193327222424
At time: 606.4158654212952 and batch: 1550, loss is 3.5892505264282226 and perplexity is 36.206929618162825
At time: 607.4553532600403 and batch: 1600, loss is 3.668908534049988 and perplexity is 39.20908711343783
At time: 608.5100629329681 and batch: 1650, loss is 3.6143848180770872 and perplexity is 37.12849811772096
At time: 609.5528366565704 and batch: 1700, loss is 3.635352373123169 and perplexity is 37.91521084477404
At time: 610.5931088924408 and batch: 1750, loss is 3.6306346797943116 and perplexity is 37.73675977719146
At time: 611.6341078281403 and batch: 1800, loss is 3.582334489822388 and perplexity is 35.95738509175303
At time: 612.674525976181 and batch: 1850, loss is 3.5972170400619508 and perplexity is 36.49652461624949
At time: 613.7140145301819 and batch: 1900, loss is 3.6884321546554566 and perplexity is 39.98211202260036
At time: 614.7540748119354 and batch: 1950, loss is 3.6272972631454468 and perplexity is 37.61102641584874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.239588253997093 and perplexity of 69.37927931590492
finished 14 epochs...
Completing Train Step...
At time: 618.0623648166656 and batch: 50, loss is 3.8238958644866945 and perplexity is 45.782222671227764
At time: 619.0969874858856 and batch: 100, loss is 3.808695559501648 and perplexity is 45.09158120184955
At time: 620.1205019950867 and batch: 150, loss is 3.77851637840271 and perplexity is 43.751083508376844
At time: 621.1493406295776 and batch: 200, loss is 3.774803876876831 and perplexity is 43.58895867464879
At time: 622.1804540157318 and batch: 250, loss is 3.77634635925293 and perplexity is 43.656245756424745
At time: 623.2186250686646 and batch: 300, loss is 3.7728412103652955 and perplexity is 43.50349198392645
At time: 624.2591862678528 and batch: 350, loss is 3.797639002799988 and perplexity is 44.59576961296149
At time: 625.3001394271851 and batch: 400, loss is 3.766835961341858 and perplexity is 43.24302554684893
At time: 626.3415448665619 and batch: 450, loss is 3.7952110815048217 and perplexity is 44.4876259295436
At time: 627.38152384758 and batch: 500, loss is 3.8229417753219606 and perplexity is 45.738563179475605
At time: 628.4242730140686 and batch: 550, loss is 3.773589000701904 and perplexity is 43.53603564124048
At time: 629.47345662117 and batch: 600, loss is 3.748846492767334 and perplexity is 42.47206190238896
At time: 630.5214445590973 and batch: 650, loss is 3.7874210119247436 and perplexity is 44.14241059960635
At time: 631.5700986385345 and batch: 700, loss is 3.814661102294922 and perplexity is 45.36138090984862
At time: 632.6184754371643 and batch: 750, loss is 3.783151454925537 and perplexity is 43.954343828060175
At time: 633.6664710044861 and batch: 800, loss is 3.7520111083984373 and perplexity is 42.60668255232718
At time: 634.714191198349 and batch: 850, loss is 3.7480401849746703 and perplexity is 42.43783015042535
At time: 635.7607820034027 and batch: 900, loss is 3.70760648727417 and perplexity is 40.75613935161005
At time: 636.8077478408813 and batch: 950, loss is 3.8192838287353514 and perplexity is 45.57155958973929
At time: 637.8713989257812 and batch: 1000, loss is 3.768574094772339 and perplexity is 43.318253053970366
At time: 638.918726682663 and batch: 1050, loss is 3.7148881435394285 and perplexity is 41.053994673015644
At time: 639.9682087898254 and batch: 1100, loss is 3.734096188545227 and perplexity is 41.8501837892713
At time: 641.0576784610748 and batch: 1150, loss is 3.7051111221313477 and perplexity is 40.6545646877613
At time: 642.1408281326294 and batch: 1200, loss is 3.7636434841156006 and perplexity is 43.1051933028107
At time: 643.2016332149506 and batch: 1250, loss is 3.7483143186569214 and perplexity is 42.44946538380305
At time: 644.2550489902496 and batch: 1300, loss is 3.740518102645874 and perplexity is 42.11980689625243
At time: 645.3056426048279 and batch: 1350, loss is 3.6289800786972046 and perplexity is 37.674372120638594
At time: 646.3535380363464 and batch: 1400, loss is 3.6604228019714355 and perplexity is 38.87777699765679
At time: 647.4036450386047 and batch: 1450, loss is 3.582752642631531 and perplexity is 35.97242391738305
At time: 648.4624638557434 and batch: 1500, loss is 3.5936015272140502 and perplexity is 36.36480921543888
At time: 649.5292930603027 and batch: 1550, loss is 3.5917550563812255 and perplexity is 36.297724609825295
At time: 650.6054422855377 and batch: 1600, loss is 3.6718992376327515 and perplexity is 39.32652539475556
At time: 651.6676380634308 and batch: 1650, loss is 3.6185586261749267 and perplexity is 37.28378919596573
At time: 652.7266049385071 and batch: 1700, loss is 3.640182638168335 and perplexity is 38.098794384034726
At time: 653.7745423316956 and batch: 1750, loss is 3.6364765214920043 and perplexity is 37.957857133085916
At time: 654.8229870796204 and batch: 1800, loss is 3.5886397790908813 and perplexity is 36.18482308374591
At time: 655.8791353702545 and batch: 1850, loss is 3.603899083137512 and perplexity is 36.74121256310778
At time: 656.9274134635925 and batch: 1900, loss is 3.6956108951568605 and perplexity is 40.27016592456098
At time: 657.9753484725952 and batch: 1950, loss is 3.6330669927597046 and perplexity is 37.828659105926356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.238061807321948 and perplexity of 69.27345633278722
finished 15 epochs...
Completing Train Step...
At time: 661.3344759941101 and batch: 50, loss is 3.8200949811935425 and perplexity is 45.60854006869965
At time: 662.3685338497162 and batch: 100, loss is 3.802641668319702 and perplexity is 44.81942630529268
At time: 663.3837022781372 and batch: 150, loss is 3.7717468309402467 and perplexity is 43.45590869921442
At time: 664.4126455783844 and batch: 200, loss is 3.7665003442764284 and perplexity is 43.22851488466374
At time: 665.4352290630341 and batch: 250, loss is 3.767217631340027 and perplexity is 43.259533262379705
At time: 666.4642465114594 and batch: 300, loss is 3.7630932331085205 and perplexity is 43.08148115120138
At time: 667.4909360408783 and batch: 350, loss is 3.7875791215896606 and perplexity is 44.14939049313465
At time: 668.5221936702728 and batch: 400, loss is 3.756424412727356 and perplexity is 42.79513435056783
At time: 669.5595817565918 and batch: 450, loss is 3.784731960296631 and perplexity is 44.02386883241197
At time: 670.5999286174774 and batch: 500, loss is 3.812589349746704 and perplexity is 45.26750063528607
At time: 671.6403591632843 and batch: 550, loss is 3.763458294868469 and perplexity is 43.0972114236174
At time: 672.6782052516937 and batch: 600, loss is 3.7398032093048097 and perplexity is 42.08970648734829
At time: 673.7170698642731 and batch: 650, loss is 3.7784441566467284 and perplexity is 43.74792384239946
At time: 674.7555606365204 and batch: 700, loss is 3.80629047870636 and perplexity is 44.98326261556094
At time: 675.7941465377808 and batch: 750, loss is 3.77562283039093 and perplexity is 43.62467062674969
At time: 676.8342628479004 and batch: 800, loss is 3.7447391080856325 and perplexity is 42.297970580696926
At time: 677.8735098838806 and batch: 850, loss is 3.7409076356887816 and perplexity is 42.136217148759705
At time: 678.913920879364 and batch: 900, loss is 3.7007966947555544 and perplexity is 40.4795413551447
At time: 679.9611682891846 and batch: 950, loss is 3.8127581739425658 and perplexity is 45.275143529814095
At time: 681.0214805603027 and batch: 1000, loss is 3.7623814582824706 and perplexity is 43.05082774790356
At time: 682.0606324672699 and batch: 1050, loss is 3.709291090965271 and perplexity is 40.82485515759635
At time: 683.1004824638367 and batch: 1100, loss is 3.728881502151489 and perplexity is 41.63251623256488
At time: 684.1412246227264 and batch: 1150, loss is 3.70033269405365 and perplexity is 40.4607631764241
At time: 685.1833577156067 and batch: 1200, loss is 3.759310636520386 and perplexity is 42.91882910506037
At time: 686.2232489585876 and batch: 1250, loss is 3.7447104692459106 and perplexity is 42.296759233242774
At time: 687.2635846138 and batch: 1300, loss is 3.7375914239883423 and perplexity is 41.99671596800687
At time: 688.3318800926208 and batch: 1350, loss is 3.626357831954956 and perplexity is 37.575710035779124
At time: 689.3979551792145 and batch: 1400, loss is 3.658201060295105 and perplexity is 38.791496502195336
At time: 690.455050945282 and batch: 1450, loss is 3.5813660287857054 and perplexity is 35.92257862238585
At time: 691.5145206451416 and batch: 1500, loss is 3.592924075126648 and perplexity is 36.34018214230082
At time: 692.5903997421265 and batch: 1550, loss is 3.591698126792908 and perplexity is 36.295658254125335
At time: 693.6405172348022 and batch: 1600, loss is 3.6720741176605225 and perplexity is 39.33340342000583
At time: 694.6896824836731 and batch: 1650, loss is 3.619164853096008 and perplexity is 37.30639848518371
At time: 695.7392685413361 and batch: 1700, loss is 3.641090888977051 and perplexity is 38.1334133638235
At time: 696.7874779701233 and batch: 1750, loss is 3.637753620147705 and perplexity is 38.006364028856744
At time: 697.8368828296661 and batch: 1800, loss is 3.5899370527267456 and perplexity is 36.23179516198271
At time: 698.9103591442108 and batch: 1850, loss is 3.605368928909302 and perplexity is 36.79525618721041
At time: 699.9604821205139 and batch: 1900, loss is 3.6972527837753297 and perplexity is 40.33633936149701
At time: 701.0105752944946 and batch: 1950, loss is 3.6340373516082765 and perplexity is 37.86538429544402
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.237836403070494 and perplexity of 69.25784356087559
finished 16 epochs...
Completing Train Step...
At time: 704.3657684326172 and batch: 50, loss is 3.81546368598938 and perplexity is 45.39780182798746
At time: 705.4287173748016 and batch: 100, loss is 3.797132520675659 and perplexity is 44.573188371812044
At time: 706.4462220668793 and batch: 150, loss is 3.766084756851196 and perplexity is 43.21055339001038
At time: 707.4671080112457 and batch: 200, loss is 3.7601600170135496 and perplexity is 42.9552990075109
At time: 708.4933176040649 and batch: 250, loss is 3.760621566772461 and perplexity is 42.975129591460366
At time: 709.5504069328308 and batch: 300, loss is 3.7562148761749268 and perplexity is 42.78616814506197
At time: 710.5727250576019 and batch: 350, loss is 3.780590271949768 and perplexity is 43.84191275067644
At time: 711.6082818508148 and batch: 400, loss is 3.7493357181549074 and perplexity is 42.492845396826226
At time: 712.6506536006927 and batch: 450, loss is 3.7777918863296507 and perplexity is 43.71939767464092
At time: 713.7195041179657 and batch: 500, loss is 3.8057018089294434 and perplexity is 44.95679012093527
At time: 714.7717366218567 and batch: 550, loss is 3.756697063446045 and perplexity is 42.80680406551069
At time: 715.8390276432037 and batch: 600, loss is 3.7336953020095827 and perplexity is 41.83340997649842
At time: 716.933929681778 and batch: 650, loss is 3.7722491073608397 and perplexity is 43.4777410599705
At time: 717.9825143814087 and batch: 700, loss is 3.8004750919342043 and perplexity is 44.722426711106586
At time: 719.0306313037872 and batch: 750, loss is 3.7702788400650022 and perplexity is 43.392162622545676
At time: 720.0762846469879 and batch: 800, loss is 3.739568853378296 and perplexity is 42.07984367093763
At time: 721.1255204677582 and batch: 850, loss is 3.735829167366028 and perplexity is 41.92277215030435
At time: 722.1751294136047 and batch: 900, loss is 3.6958785533905028 and perplexity is 40.28094600866561
At time: 723.223507642746 and batch: 950, loss is 3.807995057106018 and perplexity is 45.06000550191284
At time: 724.2722039222717 and batch: 1000, loss is 3.757866530418396 and perplexity is 42.856894492898576
At time: 725.3209133148193 and batch: 1050, loss is 3.7051426219940184 and perplexity is 40.655845321135686
At time: 726.3667709827423 and batch: 1100, loss is 3.7248745441436766 and perplexity is 41.466030262161745
At time: 727.4143762588501 and batch: 1150, loss is 3.696706619262695 and perplexity is 40.31431509935085
At time: 728.4622628688812 and batch: 1200, loss is 3.7559612560272218 and perplexity is 42.77531808673214
At time: 729.5102963447571 and batch: 1250, loss is 3.7417410612106323 and perplexity is 42.17134918546019
At time: 730.557806968689 and batch: 1300, loss is 3.73501603603363 and perplexity is 41.88869728627523
At time: 731.6062121391296 and batch: 1350, loss is 3.6239232301712034 and perplexity is 37.48433941576912
At time: 732.6551201343536 and batch: 1400, loss is 3.655941982269287 and perplexity is 38.7039623952744
At time: 733.7031767368317 and batch: 1450, loss is 3.5796040678024292 and perplexity is 35.85934016863896
At time: 734.751077413559 and batch: 1500, loss is 3.591516013145447 and perplexity is 36.28904892125681
At time: 735.8001947402954 and batch: 1550, loss is 3.590608711242676 and perplexity is 36.256138730117954
At time: 736.850358247757 and batch: 1600, loss is 3.6711702871322633 and perplexity is 39.29786875029319
At time: 737.8972020149231 and batch: 1650, loss is 3.6185101890563964 and perplexity is 37.281983320385244
At time: 738.9445900917053 and batch: 1700, loss is 3.64068657875061 and perplexity is 38.11799875118417
At time: 739.9939923286438 and batch: 1750, loss is 3.637579526901245 and perplexity is 37.999747953480544
At time: 741.0421993732452 and batch: 1800, loss is 3.589749813079834 and perplexity is 36.22501176852952
At time: 742.0905873775482 and batch: 1850, loss is 3.605352463722229 and perplexity is 36.79465035142151
At time: 743.1404545307159 and batch: 1900, loss is 3.6973864793777467 and perplexity is 40.34173251319954
At time: 744.189492225647 and batch: 1950, loss is 3.6337651014328003 and perplexity is 37.8550768410919
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2380121275436045 and perplexity of 69.27001492831633
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 747.5587713718414 and batch: 50, loss is 3.8148226881027223 and perplexity is 45.368711257449995
At time: 748.5902774333954 and batch: 100, loss is 3.8020176792144778 and perplexity is 44.791468195260954
At time: 749.606481552124 and batch: 150, loss is 3.7741347885131837 and perplexity is 43.55980356437627
At time: 750.629519701004 and batch: 200, loss is 3.768830642700195 and perplexity is 43.329367687686876
At time: 751.6595199108124 and batch: 250, loss is 3.7707856798172 and perplexity is 43.41416106986948
At time: 752.6905989646912 and batch: 300, loss is 3.7657533836364747 and perplexity is 43.19623694219831
At time: 753.7281091213226 and batch: 350, loss is 3.7929606103897093 and perplexity is 44.38762038441208
At time: 754.767904996872 and batch: 400, loss is 3.764436469078064 and perplexity is 43.139388629301834
At time: 755.8187630176544 and batch: 450, loss is 3.792469711303711 and perplexity is 44.365835889567514
At time: 756.8950862884521 and batch: 500, loss is 3.823600425720215 and perplexity is 45.76869882566758
At time: 757.933251619339 and batch: 550, loss is 3.777155389785767 and perplexity is 43.691579283214494
At time: 758.9735107421875 and batch: 600, loss is 3.7550507164001465 and perplexity is 42.73638719130467
At time: 760.013909816742 and batch: 650, loss is 3.784501800537109 and perplexity is 44.01373747530836
At time: 761.0576162338257 and batch: 700, loss is 3.810682592391968 and perplexity is 45.18126873330215
At time: 762.0969586372375 and batch: 750, loss is 3.7786580753326415 and perplexity is 43.75728334182947
At time: 763.1649577617645 and batch: 800, loss is 3.7471674394607546 and perplexity is 42.40080888196411
At time: 764.2263481616974 and batch: 850, loss is 3.743623824119568 and perplexity is 42.250822628875675
At time: 765.2660984992981 and batch: 900, loss is 3.703699440956116 and perplexity is 40.59721389414647
At time: 766.3078372478485 and batch: 950, loss is 3.8194003915786743 and perplexity is 45.57687184989978
At time: 767.3478796482086 and batch: 1000, loss is 3.7687387371063235 and perplexity is 43.32538565940559
At time: 768.4522647857666 and batch: 1050, loss is 3.7143213081359865 and perplexity is 41.03073040950926
At time: 769.508208990097 and batch: 1100, loss is 3.731960587501526 and perplexity is 41.760903860178985
At time: 770.5487675666809 and batch: 1150, loss is 3.704179859161377 and perplexity is 40.61672222048645
At time: 771.5928874015808 and batch: 1200, loss is 3.763420000076294 and perplexity is 43.09556105646305
At time: 772.6413969993591 and batch: 1250, loss is 3.74608238697052 and perplexity is 42.35482672973455
At time: 773.6894841194153 and batch: 1300, loss is 3.7355261993408204 and perplexity is 41.9100728146582
At time: 774.7373819351196 and batch: 1350, loss is 3.6213872957229616 and perplexity is 37.38940201656386
At time: 775.7884440422058 and batch: 1400, loss is 3.6501221370697023 and perplexity is 38.479365518985034
At time: 776.8374705314636 and batch: 1450, loss is 3.571910271644592 and perplexity is 35.58450433619222
At time: 777.8968377113342 and batch: 1500, loss is 3.579742374420166 and perplexity is 35.86430009567941
At time: 778.954683303833 and batch: 1550, loss is 3.580031452178955 and perplexity is 35.87466916583318
At time: 780.0009186267853 and batch: 1600, loss is 3.661733775138855 and perplexity is 38.928778143371964
At time: 781.0484993457794 and batch: 1650, loss is 3.606121382713318 and perplexity is 36.8229533368042
At time: 782.0965139865875 and batch: 1700, loss is 3.630426254272461 and perplexity is 37.72889529295003
At time: 783.1431210041046 and batch: 1750, loss is 3.624970192909241 and perplexity is 37.52360467344156
At time: 784.1882598400116 and batch: 1800, loss is 3.5777650022506715 and perplexity is 35.793453095319535
At time: 785.2324688434601 and batch: 1850, loss is 3.594430031776428 and perplexity is 36.3949501099941
At time: 786.2804338932037 and batch: 1900, loss is 3.685625786781311 and perplexity is 39.87006480427412
At time: 787.3291480541229 and batch: 1950, loss is 3.6254753398895265 and perplexity is 37.54256439735226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.236401934956396 and perplexity of 69.15856661446685
finished 18 epochs...
Completing Train Step...
At time: 790.6764807701111 and batch: 50, loss is 3.815353455543518 and perplexity is 45.392797883849376
At time: 791.6984357833862 and batch: 100, loss is 3.7999170351028444 and perplexity is 44.697476017965364
At time: 792.7332329750061 and batch: 150, loss is 3.7711414337158202 and perplexity is 43.429608574517495
At time: 793.7560777664185 and batch: 200, loss is 3.7637162399291992 and perplexity is 43.10832957030923
At time: 794.8189287185669 and batch: 250, loss is 3.7652712202072145 and perplexity is 43.17541431682076
At time: 795.8524992465973 and batch: 300, loss is 3.759907865524292 and perplexity is 42.94446913033686
At time: 796.9006371498108 and batch: 350, loss is 3.7858532238006593 and perplexity is 44.07325887429103
At time: 797.9375386238098 and batch: 400, loss is 3.756203269958496 and perplexity is 42.78567156241597
At time: 798.9711537361145 and batch: 450, loss is 3.784421167373657 and perplexity is 44.01018865149875
At time: 800.010701417923 and batch: 500, loss is 3.815204086303711 and perplexity is 45.386018102494745
At time: 801.0514090061188 and batch: 550, loss is 3.768546953201294 and perplexity is 43.31707734448293
At time: 802.1176743507385 and batch: 600, loss is 3.7464566469192504 and perplexity is 42.37068141171607
At time: 803.157767534256 and batch: 650, loss is 3.776810312271118 and perplexity is 43.67650490268883
At time: 804.2010362148285 and batch: 700, loss is 3.8038655805587767 and perplexity is 44.874314932275446
At time: 805.2807402610779 and batch: 750, loss is 3.772373929023743 and perplexity is 43.48316836262429
At time: 806.3212692737579 and batch: 800, loss is 3.7409845209121704 and perplexity is 42.13945692577184
At time: 807.3605284690857 and batch: 850, loss is 3.7375733041763306 and perplexity is 41.995955002302715
At time: 808.4009330272675 and batch: 900, loss is 3.698081097602844 and perplexity is 40.369764350420624
At time: 809.4564754962921 and batch: 950, loss is 3.8136493253707884 and perplexity is 45.3155085216224
At time: 810.5056116580963 and batch: 1000, loss is 3.763471870422363 and perplexity is 43.0977964961051
At time: 811.5455281734467 and batch: 1050, loss is 3.7098476839065553 and perplexity is 40.84758430866175
At time: 812.5850493907928 and batch: 1100, loss is 3.7279757118225096 and perplexity is 41.594822975661266
At time: 813.6246907711029 and batch: 1150, loss is 3.7004687213897705 and perplexity is 40.46626732060494
At time: 814.6728291511536 and batch: 1200, loss is 3.759990305900574 and perplexity is 42.948009634469436
At time: 815.7312273979187 and batch: 1250, loss is 3.74350350856781 and perplexity is 42.24573950363449
At time: 816.7722532749176 and batch: 1300, loss is 3.7335766315460206 and perplexity is 41.82844588089572
At time: 817.8116104602814 and batch: 1350, loss is 3.620093903541565 and perplexity is 37.341074116529725
At time: 818.8518118858337 and batch: 1400, loss is 3.649707765579224 and perplexity is 38.46342407001135
At time: 819.8914997577667 and batch: 1450, loss is 3.572359127998352 and perplexity is 35.6004802522364
At time: 820.9317359924316 and batch: 1500, loss is 3.581433825492859 and perplexity is 35.925014137487935
At time: 821.9918987751007 and batch: 1550, loss is 3.582161660194397 and perplexity is 35.951171127258156
At time: 823.0307042598724 and batch: 1600, loss is 3.6641505098342897 and perplexity is 39.02297244763757
At time: 824.070791721344 and batch: 1650, loss is 3.6089106512069704 and perplexity is 36.92580581529582
At time: 825.1194534301758 and batch: 1700, loss is 3.6339522790908814 and perplexity is 37.86216312889818
At time: 826.1671373844147 and batch: 1750, loss is 3.6285295057296754 and perplexity is 37.65740089066824
At time: 827.2152655124664 and batch: 1800, loss is 3.581743836402893 and perplexity is 35.93615301031052
At time: 828.3029282093048 and batch: 1850, loss is 3.5985638904571533 and perplexity is 36.545713092175845
At time: 829.3785161972046 and batch: 1900, loss is 3.6898433685302736 and perplexity is 40.03857516524566
At time: 830.42733502388 and batch: 1950, loss is 3.6289378118515017 and perplexity is 37.67277977741711
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.235657306050145 and perplexity of 69.10708831514431
finished 19 epochs...
Completing Train Step...
At time: 833.7752296924591 and batch: 50, loss is 3.815129051208496 and perplexity is 45.382612686069464
At time: 834.793758392334 and batch: 100, loss is 3.7986327981948853 and perplexity is 44.64011071277577
At time: 835.8232884407043 and batch: 150, loss is 3.769243588447571 and perplexity is 43.347264060671236
At time: 836.8534405231476 and batch: 200, loss is 3.7607776880264283 and perplexity is 42.98183944634344
At time: 837.892459154129 and batch: 250, loss is 3.7620748233795167 and perplexity is 43.0376288852344
At time: 838.932226896286 and batch: 300, loss is 3.7563423109054566 and perplexity is 42.79162093630005
At time: 839.9736683368683 and batch: 350, loss is 3.7817308044433595 and perplexity is 43.891944402688715
At time: 841.0454859733582 and batch: 400, loss is 3.751564788818359 and perplexity is 42.587670598681086
At time: 842.0919713973999 and batch: 450, loss is 3.7798034954071045 and perplexity is 43.80743252803254
At time: 843.1395058631897 and batch: 500, loss is 3.8103952646255492 and perplexity is 45.16828876511498
At time: 844.18727684021 and batch: 550, loss is 3.7637368059158325 and perplexity is 43.109216144755564
At time: 845.2600290775299 and batch: 600, loss is 3.7419181632995606 and perplexity is 42.17881848088824
At time: 846.3074893951416 and batch: 650, loss is 3.7726746559143067 and perplexity is 43.49624688707129
At time: 847.3884565830231 and batch: 700, loss is 3.800187792778015 and perplexity is 44.70957984118556
At time: 848.4309921264648 and batch: 750, loss is 3.7689937353134155 and perplexity is 43.33643496378684
At time: 849.4722218513489 and batch: 800, loss is 3.737745747566223 and perplexity is 42.00319755159201
At time: 850.5135228633881 and batch: 850, loss is 3.7344197845458984 and perplexity is 41.863728532767084
At time: 851.5535352230072 and batch: 900, loss is 3.6952321577072142 and perplexity is 40.25491699247498
At time: 852.5946061611176 and batch: 950, loss is 3.810884532928467 and perplexity is 45.1903935842575
At time: 853.6364653110504 and batch: 1000, loss is 3.7609137010574343 and perplexity is 42.98768593419501
At time: 854.6771302223206 and batch: 1050, loss is 3.7077406358718874 and perplexity is 40.76160709728945
At time: 855.7432820796967 and batch: 1100, loss is 3.7261796760559083 and perplexity is 41.52018423288112
At time: 856.7842211723328 and batch: 1150, loss is 3.6987696743011473 and perplexity is 40.39757160208237
At time: 857.8261365890503 and batch: 1200, loss is 3.758377866744995 and perplexity is 42.87881438363863
At time: 858.8645169734955 and batch: 1250, loss is 3.74234543800354 and perplexity is 42.19684427377728
At time: 859.9099986553192 and batch: 1300, loss is 3.7327717876434328 and perplexity is 41.794794055323635
At time: 860.9721577167511 and batch: 1350, loss is 3.619478101730347 and perplexity is 37.31808649409213
At time: 862.0371880531311 and batch: 1400, loss is 3.6494829559326174 and perplexity is 38.454778093124816
At time: 863.1162259578705 and batch: 1450, loss is 3.5725022840499876 and perplexity is 35.60557704123503
At time: 864.1834909915924 and batch: 1500, loss is 3.582157669067383 and perplexity is 35.95102764185421
At time: 865.224639415741 and batch: 1550, loss is 3.583188395500183 and perplexity is 35.988102420025584
At time: 866.2662470340729 and batch: 1600, loss is 3.6652825450897217 and perplexity is 39.067172841701996
At time: 867.306468963623 and batch: 1650, loss is 3.610292019844055 and perplexity is 36.97684921210523
At time: 868.3798320293427 and batch: 1700, loss is 3.635589632987976 and perplexity is 37.92420766982375
At time: 869.4268569946289 and batch: 1750, loss is 3.6302954244613646 and perplexity is 37.72395955158407
At time: 870.4674348831177 and batch: 1800, loss is 3.583684620857239 and perplexity is 36.00596506057977
At time: 871.5097272396088 and batch: 1850, loss is 3.6006201124191284 and perplexity is 36.62093650156122
At time: 872.550787448883 and batch: 1900, loss is 3.6919445323944093 and perplexity is 40.12279121743346
At time: 873.6006736755371 and batch: 1950, loss is 3.6305434989929197 and perplexity is 37.733319066058826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.235276900890262 and perplexity of 69.08080462170798
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
3614.817453145981


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56731245050365}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.6765022317192798, 'rnn_dropout': 0.40821417681898475, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.08080462170798}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.9990387741788632, 'rnn_dropout': 0.09278654931862784, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5911750793457031 and batch: 50, loss is 10.002416858673095 and perplexity is 22079.765032118205
At time: 2.7498087882995605 and batch: 100, loss is 9.126588668823242 and perplexity is 9196.59576321524
At time: 3.903474807739258 and batch: 150, loss is 8.26493034362793 and perplexity is 3885.2023392786678
At time: 5.058563470840454 and batch: 200, loss is 7.7483374118804935 and perplexity is 2317.7158027628407
At time: 6.211407661437988 and batch: 250, loss is 7.398169794082642 and perplexity is 1632.9929799312736
At time: 7.365279674530029 and batch: 300, loss is 6.96501781463623 and perplexity is 1058.9337817782443
At time: 8.518566608428955 and batch: 350, loss is 6.815213060379028 and perplexity is 911.6107232207045
At time: 9.67025637626648 and batch: 400, loss is 6.7880822277069095 and perplexity is 887.2104616319713
At time: 10.820189952850342 and batch: 450, loss is 6.718914823532105 and perplexity is 827.9185860564044
At time: 11.970900297164917 and batch: 500, loss is 6.722036085128784 and perplexity is 830.5067736482715
At time: 13.121730089187622 and batch: 550, loss is 6.720078096389771 and perplexity is 828.8822416644592
At time: 14.271676301956177 and batch: 600, loss is 6.7632513427734375 and perplexity is 865.4515057986562
At time: 15.423878908157349 and batch: 650, loss is 6.84222038269043 and perplexity is 936.566363496345
At time: 16.576870918273926 and batch: 700, loss is 6.7756196308135985 and perplexity is 876.2221290905346
At time: 17.728351354599 and batch: 750, loss is 6.736173524856567 and perplexity is 842.3314011378466
At time: 18.879332304000854 and batch: 800, loss is 6.753342018127442 and perplexity is 856.9178172376661
At time: 20.03274631500244 and batch: 850, loss is 6.788760261535645 and perplexity is 887.8122243228421
At time: 21.189913034439087 and batch: 900, loss is 6.8252785015106205 and perplexity is 920.8328216749403
At time: 22.344865322113037 and batch: 950, loss is 6.78863486289978 and perplexity is 887.7009008610592
At time: 23.500147581100464 and batch: 1000, loss is 6.816542224884033 and perplexity is 912.823209454718
At time: 24.651245594024658 and batch: 1050, loss is 6.736730709075927 and perplexity is 842.8008656790036
At time: 25.80665349960327 and batch: 1100, loss is 6.805690317153931 and perplexity is 902.970891123645
At time: 26.962100982666016 and batch: 1150, loss is 6.7273453330993656 and perplexity is 834.927866003442
At time: 28.11380124092102 and batch: 1200, loss is 6.8151798439025875 and perplexity is 911.5804432274938
At time: 29.271852016448975 and batch: 1250, loss is 6.771908454895019 and perplexity is 872.9763411959685
At time: 30.42553162574768 and batch: 1300, loss is 6.808940467834472 and perplexity is 905.9104570082999
At time: 31.579432010650635 and batch: 1350, loss is 6.7946649932861325 and perplexity is 893.0700250271824
At time: 32.74190282821655 and batch: 1400, loss is 6.786706562042236 and perplexity is 885.9907957811291
At time: 33.90442156791687 and batch: 1450, loss is 6.81024582862854 and perplexity is 907.0937691584315
At time: 35.06954002380371 and batch: 1500, loss is 6.78461633682251 and perplexity is 884.140809592791
At time: 36.232640504837036 and batch: 1550, loss is 6.779910230636597 and perplexity is 879.9897244446166
At time: 37.40912890434265 and batch: 1600, loss is 6.782085199356079 and perplexity is 881.9057574693817
At time: 38.63889527320862 and batch: 1650, loss is 6.767551670074463 and perplexity is 869.1812443372083
At time: 39.910733699798584 and batch: 1700, loss is 6.796353178024292 and perplexity is 894.5789655403443
At time: 41.18788290023804 and batch: 1750, loss is 6.830051498413086 and perplexity is 925.238459564567
At time: 42.4653799533844 and batch: 1800, loss is 6.832955198287964 and perplexity is 927.9289787034608
At time: 43.73706912994385 and batch: 1850, loss is 6.786778955459595 and perplexity is 886.0549380042933
At time: 45.00673294067383 and batch: 1900, loss is 6.773724126815796 and perplexity is 874.5628196525329
At time: 46.274824142456055 and batch: 1950, loss is 6.730136604309082 and perplexity is 837.2616316892565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.628318041424419 and perplexity of 756.2091878613047
finished 1 epochs...
Completing Train Step...
At time: 49.77061748504639 and batch: 50, loss is 6.774475526809693 and perplexity is 875.2202131016686
At time: 50.84417414665222 and batch: 100, loss is 6.7803567600250245 and perplexity is 880.3827534610681
At time: 51.91944360733032 and batch: 150, loss is 6.744834699630737 and perplexity is 849.6586661773476
At time: 52.99429273605347 and batch: 200, loss is 6.773533620834351 and perplexity is 874.3962260732801
At time: 54.06939482688904 and batch: 250, loss is 6.7870089721679685 and perplexity is 886.2587688859267
At time: 55.15129899978638 and batch: 300, loss is 6.787240934371948 and perplexity is 886.464371268323
At time: 56.241469621658325 and batch: 350, loss is 6.775867862701416 and perplexity is 876.4396623620165
At time: 57.31624984741211 and batch: 400, loss is 6.782771224975586 and perplexity is 882.5109749866217
At time: 58.39045810699463 and batch: 450, loss is 6.727708444595337 and perplexity is 835.2310929591599
At time: 59.466163873672485 and batch: 500, loss is 6.727815027236939 and perplexity is 835.3201188396175
At time: 60.54053783416748 and batch: 550, loss is 6.728548107147216 and perplexity is 835.9326997453337
At time: 61.615673303604126 and batch: 600, loss is 6.768468904495239 and perplexity is 869.9788530335627
At time: 62.69178104400635 and batch: 650, loss is 6.849688777923584 and perplexity is 943.5871958029384
At time: 63.77038860321045 and batch: 700, loss is 6.785059852600098 and perplexity is 884.533026962321
At time: 64.84768986701965 and batch: 750, loss is 6.7423108863830565 and perplexity is 847.5169901116633
At time: 65.92264699935913 and batch: 800, loss is 6.761809597015381 and perplexity is 864.2046438063417
At time: 66.99928641319275 and batch: 850, loss is 6.796567583084107 and perplexity is 894.7707883601167
At time: 68.07998919487 and batch: 900, loss is 6.834726829528808 and perplexity is 929.574383766557
At time: 69.15991020202637 and batch: 950, loss is 6.79620283126831 and perplexity is 894.4444786049963
At time: 70.23934578895569 and batch: 1000, loss is 6.822344264984131 and perplexity is 918.1348405678907
At time: 71.31627416610718 and batch: 1050, loss is 6.741107339859009 and perplexity is 846.4975775624118
At time: 72.39551258087158 and batch: 1100, loss is 6.810981245040893 and perplexity is 907.7611061590287
At time: 73.4740092754364 and batch: 1150, loss is 6.73246015548706 and perplexity is 839.2093138331375
At time: 74.55186796188354 and batch: 1200, loss is 6.818837623596192 and perplexity is 914.9209092818301
At time: 75.63219738006592 and batch: 1250, loss is 6.776100540161133 and perplexity is 876.6436138427864
At time: 76.71068835258484 and batch: 1300, loss is 6.81444972038269 and perplexity is 910.9151198193052
At time: 77.78889584541321 and batch: 1350, loss is 6.798370857238769 and perplexity is 896.385761078765
At time: 78.86669158935547 and batch: 1400, loss is 6.789568138122559 and perplexity is 888.5297568322804
At time: 79.96661972999573 and batch: 1450, loss is 6.8159702777862545 and perplexity is 912.3012721437786
At time: 81.05861067771912 and batch: 1500, loss is 6.793403491973877 and perplexity is 891.9441263293287
At time: 82.13603782653809 and batch: 1550, loss is 6.78298770904541 and perplexity is 882.7020452352376
At time: 83.21598935127258 and batch: 1600, loss is 6.787829666137696 and perplexity is 886.9864146595769
At time: 84.29205894470215 and batch: 1650, loss is 6.779494285583496 and perplexity is 879.6237731850383
At time: 85.36921525001526 and batch: 1700, loss is 6.794371881484985 and perplexity is 892.808294023693
At time: 86.44741463661194 and batch: 1750, loss is 6.832616319656372 and perplexity is 927.6145766760167
At time: 87.527188539505 and batch: 1800, loss is 6.8324833106994625 and perplexity is 927.491203833787
At time: 88.60699534416199 and batch: 1850, loss is 6.786560983657837 and perplexity is 885.8618240604615
At time: 89.68682956695557 and batch: 1900, loss is 6.773723011016846 and perplexity is 874.5618438168013
At time: 90.76429724693298 and batch: 1950, loss is 6.730721197128296 and perplexity is 837.7512319213922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.62724609375 and perplexity of 755.3990054951342
finished 2 epochs...
Completing Train Step...
At time: 94.219646692276 and batch: 50, loss is 6.779285469055176 and perplexity is 879.4401123788672
At time: 95.30213212966919 and batch: 100, loss is 6.786675596237183 and perplexity is 885.9633607876433
At time: 96.38559317588806 and batch: 150, loss is 6.745034408569336 and perplexity is 849.8283675526179
At time: 97.48333787918091 and batch: 200, loss is 6.774781274795532 and perplexity is 875.4878508317539
At time: 98.56026268005371 and batch: 250, loss is 6.785248394012451 and perplexity is 884.699813791116
At time: 99.63642382621765 and batch: 300, loss is 6.7875521373748775 and perplexity is 886.740284572949
At time: 100.7131679058075 and batch: 350, loss is 6.776391639709472 and perplexity is 876.8988415493632
At time: 101.78893899917603 and batch: 400, loss is 6.782448816299438 and perplexity is 882.226491653902
At time: 102.864173412323 and batch: 450, loss is 6.726148414611816 and perplexity is 833.929123230931
At time: 103.94078278541565 and batch: 500, loss is 6.728713760375976 and perplexity is 836.0711861661173
At time: 105.01739621162415 and batch: 550, loss is 6.727428750991821 and perplexity is 834.9975168313988
At time: 106.09507703781128 and batch: 600, loss is 6.768393898010254 and perplexity is 869.9136014249631
At time: 107.17270278930664 and batch: 650, loss is 6.848994760513306 and perplexity is 942.9325570525571
At time: 108.24950981140137 and batch: 700, loss is 6.783446111679077 and perplexity is 883.1067709340927
At time: 109.32671308517456 and batch: 750, loss is 6.7420494270324705 and perplexity is 847.2954278358446
At time: 110.42176580429077 and batch: 800, loss is 6.760277986526489 and perplexity is 862.8820320309251
At time: 111.49873399734497 and batch: 850, loss is 6.796364250183106 and perplexity is 894.5888705155569
At time: 112.57590913772583 and batch: 900, loss is 6.834900512695312 and perplexity is 929.7358492105395
At time: 113.65447783470154 and batch: 950, loss is 6.796686925888062 and perplexity is 894.877579187128
At time: 114.73382091522217 and batch: 1000, loss is 6.821437463760376 and perplexity is 917.3026521426582
At time: 115.82811379432678 and batch: 1050, loss is 6.740262670516968 and perplexity is 845.7828688992743
At time: 116.90787887573242 and batch: 1100, loss is 6.81039888381958 and perplexity is 907.2326151938437
At time: 117.98696899414062 and batch: 1150, loss is 6.731952323913574 and perplexity is 838.7832450415583
At time: 119.06474757194519 and batch: 1200, loss is 6.818554105758667 and perplexity is 914.6615496524025
At time: 120.14521336555481 and batch: 1250, loss is 6.775628614425659 and perplexity is 876.2300007655792
At time: 121.24066019058228 and batch: 1300, loss is 6.813135375976563 and perplexity is 909.7186500860063
At time: 122.31795406341553 and batch: 1350, loss is 6.797427864074707 and perplexity is 895.5408738577505
At time: 123.3944103717804 and batch: 1400, loss is 6.789167156219483 and perplexity is 888.1735439016883
At time: 124.47166085243225 and batch: 1450, loss is 6.8164083290100095 and perplexity is 912.7009943754889
At time: 125.55017423629761 and batch: 1500, loss is 6.794545001983643 and perplexity is 892.9628708205798
At time: 126.62568378448486 and batch: 1550, loss is 6.784080591201782 and perplexity is 883.6672618878259
At time: 127.70458626747131 and batch: 1600, loss is 6.785311737060547 and perplexity is 884.7558551488676
At time: 128.78140425682068 and batch: 1650, loss is 6.770627918243409 and perplexity is 871.8591784316687
At time: 129.8578691482544 and batch: 1700, loss is 6.795990333557129 and perplexity is 894.2544313935281
At time: 130.93604445457458 and batch: 1750, loss is 6.830392732620239 and perplexity is 925.5542364506175
At time: 132.01516389846802 and batch: 1800, loss is 6.831644163131714 and perplexity is 926.7132283097685
At time: 133.09480047225952 and batch: 1850, loss is 6.786130075454712 and perplexity is 885.4801811660709
At time: 134.17385935783386 and batch: 1900, loss is 6.772985763549805 and perplexity is 873.9173129312521
At time: 135.25963735580444 and batch: 1950, loss is 6.729774494171142 and perplexity is 836.9585056501322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.628589434956395 and perplexity of 756.4144459953166
Annealing...
finished 3 epochs...
Completing Train Step...
At time: 138.66803574562073 and batch: 50, loss is 6.770062608718872 and perplexity is 871.3664474199356
At time: 139.72985172271729 and batch: 100, loss is 6.773410978317261 and perplexity is 874.2889944948906
At time: 140.77643418312073 and batch: 150, loss is 6.728721942901611 and perplexity is 836.0780273680198
At time: 141.82303142547607 and batch: 200, loss is 6.756240005493164 and perplexity is 859.4047560636208
At time: 142.8670732975006 and batch: 250, loss is 6.763516502380371 and perplexity is 865.6810190072252
At time: 143.91276812553406 and batch: 300, loss is 6.740609455108642 and perplexity is 846.0762242287251
At time: 144.9579803943634 and batch: 350, loss is 6.738103647232055 and perplexity is 843.9587738317698
At time: 146.00421047210693 and batch: 400, loss is 6.735712842941284 and perplexity is 841.9434436640248
At time: 147.05990648269653 and batch: 450, loss is 6.685095539093018 and perplexity is 800.3871427845719
At time: 148.122793674469 and batch: 500, loss is 6.679707202911377 and perplexity is 796.0859862292339
At time: 149.20230317115784 and batch: 550, loss is 6.675496530532837 and perplexity is 792.7409762687832
At time: 150.26211023330688 and batch: 600, loss is 6.7116407299041745 and perplexity is 821.9180793274375
At time: 151.32182097434998 and batch: 650, loss is 6.794026985168457 and perplexity is 892.5004208269355
At time: 152.3822820186615 and batch: 700, loss is 6.7294588375091555 and perplexity is 836.6943558145383
At time: 153.44680333137512 and batch: 750, loss is 6.677567701339722 and perplexity is 794.3845797404632
At time: 154.52001476287842 and batch: 800, loss is 6.689126348495483 and perplexity is 803.6198616652049
At time: 155.60179352760315 and batch: 850, loss is 6.733751230239868 and perplexity is 840.2934955197504
At time: 156.68213486671448 and batch: 900, loss is 6.752762060165406 and perplexity is 856.420985011577
At time: 157.7631597518921 and batch: 950, loss is 6.75408332824707 and perplexity is 857.5532946010726
At time: 158.84281206130981 and batch: 1000, loss is 6.746466007232666 and perplexity is 851.0458519742676
At time: 159.92124819755554 and batch: 1050, loss is 6.679819993972778 and perplexity is 796.1757826766102
At time: 161.00164318084717 and batch: 1100, loss is 6.735367546081543 and perplexity is 841.6527734234963
At time: 162.08233523368835 and batch: 1150, loss is 6.670751714706421 and perplexity is 788.9884758401336
At time: 163.16165137290955 and batch: 1200, loss is 6.734889192581177 and perplexity is 841.2502621522495
At time: 164.28026127815247 and batch: 1250, loss is 6.691505184173584 and perplexity is 805.5338168536423
At time: 165.36058974266052 and batch: 1300, loss is 6.727241945266724 and perplexity is 834.8415490831002
At time: 166.4422791004181 and batch: 1350, loss is 6.727682886123657 and perplexity is 835.2097460017229
At time: 167.52125763893127 and batch: 1400, loss is 6.736065626144409 and perplexity is 842.240519567544
At time: 168.6011507511139 and batch: 1450, loss is 6.747075614929199 and perplexity is 851.5648142413582
At time: 169.6816394329071 and batch: 1500, loss is 6.727026147842407 and perplexity is 834.6614118643685
At time: 170.76288294792175 and batch: 1550, loss is 6.713514356613159 and perplexity is 823.4594905571637
At time: 171.84152626991272 and batch: 1600, loss is 6.707679138183594 and perplexity is 818.6684166378541
At time: 172.92082238197327 and batch: 1650, loss is 6.709135322570801 and perplexity is 819.8614172080532
At time: 174.00148797035217 and batch: 1700, loss is 6.714015789031983 and perplexity is 823.8725033816728
At time: 175.0816388130188 and batch: 1750, loss is 6.731669511795044 and perplexity is 838.5460605159504
At time: 176.16287922859192 and batch: 1800, loss is 6.724551239013672 and perplexity is 832.598255082707
At time: 177.23638606071472 and batch: 1850, loss is 6.677674703598022 and perplexity is 794.4695852322628
At time: 178.31026792526245 and batch: 1900, loss is 6.664576225280761 and perplexity is 784.1310996253436
At time: 179.38423037528992 and batch: 1950, loss is 6.629624519348145 and perplexity is 757.1978041330101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.442697924236919 and perplexity of 628.0990796938465
finished 4 epochs...
Completing Train Step...
At time: 182.7428503036499 and batch: 50, loss is 6.689509534835816 and perplexity is 803.9278568250155
At time: 183.79455542564392 and batch: 100, loss is 6.709454994201661 and perplexity is 820.1235455396344
At time: 184.83622550964355 and batch: 150, loss is 6.670842914581299 and perplexity is 789.060434771683
At time: 185.8866548538208 and batch: 200, loss is 6.707064895629883 and perplexity is 818.1657100666656
At time: 186.92314887046814 and batch: 250, loss is 6.717862606048584 and perplexity is 827.0478938043625
At time: 187.96123504638672 and batch: 300, loss is 6.698379487991333 and perplexity is 811.0903779088578
At time: 189.00000882148743 and batch: 350, loss is 6.701999101638794 and perplexity is 814.0315314186014
At time: 190.05317163467407 and batch: 400, loss is 6.702923555374145 and perplexity is 814.7844138573876
At time: 191.0954372882843 and batch: 450, loss is 6.654505138397217 and perplexity is 776.2736799835001
At time: 192.16210794448853 and batch: 500, loss is 6.653293724060059 and perplexity is 775.3338602884702
At time: 193.2358856201172 and batch: 550, loss is 6.645605440139771 and perplexity is 769.395729704571
At time: 194.28927493095398 and batch: 600, loss is 6.684295282363892 and perplexity is 799.7468838075991
At time: 195.34613490104675 and batch: 650, loss is 6.768984060287476 and perplexity is 870.4271431385346
At time: 196.4060423374176 and batch: 700, loss is 6.709123725891113 and perplexity is 819.8519095929381
At time: 197.4645700454712 and batch: 750, loss is 6.660787448883057 and perplexity is 781.1658231542984
At time: 198.52326273918152 and batch: 800, loss is 6.670221796035767 and perplexity is 788.5704868757143
At time: 199.58394694328308 and batch: 850, loss is 6.712874984741211 and perplexity is 822.93316199898
At time: 200.6443977355957 and batch: 900, loss is 6.728722314834595 and perplexity is 836.0783383330731
At time: 201.70477175712585 and batch: 950, loss is 6.728676872253418 and perplexity is 836.0403456385626
At time: 202.763671875 and batch: 1000, loss is 6.723912124633789 and perplexity is 832.0662995735332
At time: 203.82159209251404 and batch: 1050, loss is 6.664004020690918 and perplexity is 783.6825445559723
At time: 204.88092041015625 and batch: 1100, loss is 6.720436506271362 and perplexity is 829.1793744950378
At time: 205.9413561820984 and batch: 1150, loss is 6.655668001174927 and perplexity is 777.1769048127541
At time: 207.0006697177887 and batch: 1200, loss is 6.720889739990234 and perplexity is 829.5552717247671
At time: 208.0625822544098 and batch: 1250, loss is 6.6768459129333495 and perplexity is 793.8114090394729
At time: 209.13040137290955 and batch: 1300, loss is 6.712656002044678 and perplexity is 822.7529736058897
At time: 210.2071497440338 and batch: 1350, loss is 6.716663064956665 and perplexity is 826.056410652038
At time: 211.28087210655212 and batch: 1400, loss is 6.722907772064209 and perplexity is 831.2310311696925
At time: 212.3545846939087 and batch: 1450, loss is 6.729752864837646 and perplexity is 836.9404029912663
At time: 213.42964792251587 and batch: 1500, loss is 6.704705047607422 and perplexity is 816.2372396771887
At time: 214.50484204292297 and batch: 1550, loss is 6.695076866149902 and perplexity is 808.4160716533174
At time: 215.57911229133606 and batch: 1600, loss is 6.694747142791748 and perplexity is 808.1495619310406
At time: 216.65444231033325 and batch: 1650, loss is 6.6909010696411135 and perplexity is 805.0473291304316
At time: 217.72909665107727 and batch: 1700, loss is 6.707547521591186 and perplexity is 818.5606733811
At time: 218.80188250541687 and batch: 1750, loss is 6.730818386077881 and perplexity is 837.8326560403344
At time: 219.87729406356812 and batch: 1800, loss is 6.731927938461304 and perplexity is 838.7627911821609
At time: 220.95266842842102 and batch: 1850, loss is 6.687285623550415 and perplexity is 802.1419791443851
At time: 222.026780128479 and batch: 1900, loss is 6.673974313735962 and perplexity is 791.5351706207766
At time: 223.10175776481628 and batch: 1950, loss is 6.63477710723877 and perplexity is 761.1094011389451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.442030795784884 and perplexity of 627.6801966670142
finished 5 epochs...
Completing Train Step...
At time: 226.53787636756897 and batch: 50, loss is 6.682953720092773 and perplexity is 798.6746929280637
At time: 227.57688236236572 and batch: 100, loss is 6.701087102890015 and perplexity is 813.2894741095829
At time: 228.61624813079834 and batch: 150, loss is 6.663724822998047 and perplexity is 783.4637727393034
At time: 229.65367770195007 and batch: 200, loss is 6.701412239074707 and perplexity is 813.5539469387586
At time: 230.6916422843933 and batch: 250, loss is 6.712658386230469 and perplexity is 822.7549352041773
At time: 231.7305772304535 and batch: 300, loss is 6.694860363006592 and perplexity is 808.2410659780251
At time: 232.7698996067047 and batch: 350, loss is 6.697673578262329 and perplexity is 810.5180233590803
At time: 233.8094184398651 and batch: 400, loss is 6.698421573638916 and perplexity is 811.1245138909728
At time: 234.85380959510803 and batch: 450, loss is 6.650032377243042 and perplexity is 772.8093465661301
At time: 235.90036821365356 and batch: 500, loss is 6.649775762557983 and perplexity is 772.6110577820458
At time: 236.94796299934387 and batch: 550, loss is 6.641416110992432 and perplexity is 766.1792199615635
At time: 237.99417853355408 and batch: 600, loss is 6.681083364486694 and perplexity is 797.1822833420961
At time: 239.04836201667786 and batch: 650, loss is 6.766417493820191 and perplexity is 868.19599843609
At time: 240.12970495224 and batch: 700, loss is 6.706797676086426 and perplexity is 817.9471094076342
At time: 241.18538761138916 and batch: 750, loss is 6.658571510314942 and perplexity is 779.4367241747806
At time: 242.2405025959015 and batch: 800, loss is 6.6673780536651615 and perplexity is 786.3311810834392
At time: 243.33506560325623 and batch: 850, loss is 6.71020016670227 and perplexity is 820.7349068093862
At time: 244.4127812385559 and batch: 900, loss is 6.7261762619018555 and perplexity is 833.952346220445
At time: 245.47528409957886 and batch: 950, loss is 6.72571816444397 and perplexity is 833.5704022611017
At time: 246.53798484802246 and batch: 1000, loss is 6.721498947143555 and perplexity is 830.0607966994576
At time: 247.59741687774658 and batch: 1050, loss is 6.662558889389038 and perplexity is 782.5508383091135
At time: 248.65899538993835 and batch: 1100, loss is 6.71931827545166 and perplexity is 828.25267878983
At time: 249.73756647109985 and batch: 1150, loss is 6.654337978363037 and perplexity is 776.1439288935215
At time: 250.8072395324707 and batch: 1200, loss is 6.719741706848144 and perplexity is 828.603461239162
At time: 251.86758494377136 and batch: 1250, loss is 6.6761893463134765 and perplexity is 793.2903900263861
At time: 252.92829251289368 and batch: 1300, loss is 6.7112776470184325 and perplexity is 821.6197091091896
At time: 254.017156124115 and batch: 1350, loss is 6.716495037078857 and perplexity is 825.9176218069306
At time: 255.0792155265808 and batch: 1400, loss is 6.72237120628357 and perplexity is 830.7851406780488
At time: 256.15821409225464 and batch: 1450, loss is 6.728645944595337 and perplexity is 836.0144892684515
At time: 257.2223587036133 and batch: 1500, loss is 6.702246150970459 and perplexity is 814.2326622079831
At time: 258.2851572036743 and batch: 1550, loss is 6.693717994689941 and perplexity is 807.3182841707386
At time: 259.34528851509094 and batch: 1600, loss is 6.694341917037963 and perplexity is 807.8221452589509
At time: 260.40616059303284 and batch: 1650, loss is 6.6869877910614015 and perplexity is 801.9031107753406
At time: 261.46752309799194 and batch: 1700, loss is 6.7096994018554685 and perplexity is 820.3240145083096
At time: 262.52841782569885 and batch: 1750, loss is 6.733641319274902 and perplexity is 840.2011431261667
At time: 263.6075370311737 and batch: 1800, loss is 6.735330362319946 and perplexity is 841.6214781892629
At time: 264.67443561553955 and batch: 1850, loss is 6.690584764480591 and perplexity is 804.792728773589
At time: 265.7358543872833 and batch: 1900, loss is 6.676667470932006 and perplexity is 793.6697723802952
At time: 266.7973065376282 and batch: 1950, loss is 6.636017332077026 and perplexity is 762.0539335180569
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441842296511628 and perplexity of 627.5618905567634
finished 6 epochs...
Completing Train Step...
At time: 270.2504680156708 and batch: 50, loss is 6.680944156646729 and perplexity is 797.0713170422418
At time: 271.2902615070343 and batch: 100, loss is 6.698928890228271 and perplexity is 811.5361152101634
At time: 272.3211576938629 and batch: 150, loss is 6.661754770278931 and perplexity is 781.9218271592355
At time: 273.3509168624878 and batch: 200, loss is 6.69967363357544 and perplexity is 812.1407264451055
At time: 274.380423784256 and batch: 250, loss is 6.710778379440308 and perplexity is 821.2096034116413
At time: 275.41110610961914 and batch: 300, loss is 6.693235263824463 and perplexity is 806.9286607658923
At time: 276.44897389411926 and batch: 350, loss is 6.695755462646485 and perplexity is 808.9648461444871
At time: 277.4975817203522 and batch: 400, loss is 6.696755962371826 and perplexity is 809.7746202727133
At time: 278.5416610240936 and batch: 450, loss is 6.648452167510986 and perplexity is 771.5891100843621
At time: 279.5849530696869 and batch: 500, loss is 6.648415641784668 and perplexity is 771.5609277463905
At time: 280.6299214363098 and batch: 550, loss is 6.640153942108154 and perplexity is 765.2127824223433
At time: 281.67454528808594 and batch: 600, loss is 6.680149660110474 and perplexity is 796.4382981406642
At time: 282.71985912323 and batch: 650, loss is 6.765613441467285 and perplexity is 867.4982039699992
At time: 283.7679760456085 and batch: 700, loss is 6.705957822799682 and perplexity is 817.2604422296209
At time: 284.8118097782135 and batch: 750, loss is 6.657698154449463 and perplexity is 778.7562957112975
At time: 285.85797572135925 and batch: 800, loss is 6.666498460769653 and perplexity is 785.6398338596686
At time: 286.9051127433777 and batch: 850, loss is 6.709406986236572 and perplexity is 820.0841740221725
At time: 287.95213627815247 and batch: 900, loss is 6.725780258178711 and perplexity is 833.6221633675508
At time: 288.9988479614258 and batch: 950, loss is 6.72527437210083 and perplexity is 833.2005521734985
At time: 290.0547833442688 and batch: 1000, loss is 6.72101282119751 and perplexity is 829.6573806728304
At time: 291.10966897010803 and batch: 1050, loss is 6.66226655960083 and perplexity is 782.3221088221392
At time: 292.16580605506897 and batch: 1100, loss is 6.719078054428101 and perplexity is 828.0537389792846
At time: 293.2208800315857 and batch: 1150, loss is 6.654055080413818 and perplexity is 775.924390422695
At time: 294.28739953041077 and batch: 1200, loss is 6.719549102783203 and perplexity is 828.4438842123882
At time: 295.3696436882019 and batch: 1250, loss is 6.676149291992187 and perplexity is 793.2586159545772
At time: 296.43086218833923 and batch: 1300, loss is 6.711195583343506 and perplexity is 821.5522867429694
At time: 297.49338126182556 and batch: 1350, loss is 6.71696105003357 and perplexity is 826.3025998136198
At time: 298.5539331436157 and batch: 1400, loss is 6.722839651107788 and perplexity is 831.1744088454474
At time: 299.6150052547455 and batch: 1450, loss is 6.729053773880005 and perplexity is 836.3555099939742
At time: 300.67670464515686 and batch: 1500, loss is 6.702725353240967 and perplexity is 814.6229378514539
At time: 301.76478099823 and batch: 1550, loss is 6.694488286972046 and perplexity is 807.9403947869795
At time: 302.8256893157959 and batch: 1600, loss is 6.695015106201172 and perplexity is 808.3661454599148
At time: 303.88744354248047 and batch: 1650, loss is 6.687195520401001 and perplexity is 802.0697068818155
At time: 304.9490737915039 and batch: 1700, loss is 6.710942802429199 and perplexity is 821.3446402504162
At time: 306.0097453594208 and batch: 1750, loss is 6.735072250366211 and perplexity is 841.4042736579712
At time: 307.0959014892578 and batch: 1800, loss is 6.736714391708374 and perplexity is 842.7871134997042
At time: 308.1572587490082 and batch: 1850, loss is 6.691832027435303 and perplexity is 805.7971431846415
At time: 309.21790289878845 and batch: 1900, loss is 6.677637901306152 and perplexity is 794.4403474687169
At time: 310.2795696258545 and batch: 1950, loss is 6.6363755798339845 and perplexity is 762.3269865378165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.44173214934593 and perplexity of 627.4927701999943
finished 7 epochs...
Completing Train Step...
At time: 313.6663794517517 and batch: 50, loss is 6.679837226867676 and perplexity is 796.1895032084151
At time: 314.68154549598694 and batch: 100, loss is 6.697872743606568 and perplexity is 810.679466536624
At time: 315.69752311706543 and batch: 150, loss is 6.660771894454956 and perplexity is 781.1536726611644
At time: 316.7175145149231 and batch: 200, loss is 6.6987762451171875 and perplexity is 811.4122476438386
At time: 317.7493426799774 and batch: 250, loss is 6.70986611366272 and perplexity is 820.4607836074952
At time: 318.7865834236145 and batch: 300, loss is 6.6924081325531 and perplexity is 806.26150078929
At time: 319.82333874702454 and batch: 350, loss is 6.6947861003875735 and perplexity is 808.1810461083111
At time: 320.8608400821686 and batch: 400, loss is 6.695933132171631 and perplexity is 809.108587313396
At time: 321.9109468460083 and batch: 450, loss is 6.647663049697876 and perplexity is 770.9804755469535
At time: 322.9439465999603 and batch: 500, loss is 6.647743873596191 and perplexity is 771.0427917127961
At time: 323.9806764125824 and batch: 550, loss is 6.639589719772339 and perplexity is 764.7811540574819
At time: 325.0176088809967 and batch: 600, loss is 6.6797214698791505 and perplexity is 796.0973440433648
At time: 326.0753962993622 and batch: 650, loss is 6.765261650085449 and perplexity is 867.1930792513544
At time: 327.1529803276062 and batch: 700, loss is 6.705576295852661 and perplexity is 816.9486948219759
At time: 328.20730423927307 and batch: 750, loss is 6.657304677963257 and perplexity is 778.4499336975274
At time: 329.28504633903503 and batch: 800, loss is 6.666125555038452 and perplexity is 785.3469188811935
At time: 330.38055205345154 and batch: 850, loss is 6.709062347412109 and perplexity is 819.8015898740083
At time: 331.4474844932556 and batch: 900, loss is 6.725662832260132 and perplexity is 833.5242802663886
At time: 332.5331599712372 and batch: 950, loss is 6.725119552612305 and perplexity is 833.0715664751797
At time: 333.58856558799744 and batch: 1000, loss is 6.720841751098633 and perplexity is 829.5154632419454
At time: 334.6615023612976 and batch: 1050, loss is 6.662195949554444 and perplexity is 782.2668709719425
At time: 335.7253432273865 and batch: 1100, loss is 6.719024791717529 and perplexity is 828.0096357671862
At time: 336.787202835083 and batch: 1150, loss is 6.653984861373901 and perplexity is 775.8699076698371
At time: 337.8743977546692 and batch: 1200, loss is 6.71952184677124 and perplexity is 828.4213044436881
At time: 338.935693025589 and batch: 1250, loss is 6.67620099067688 and perplexity is 793.2996274417537
At time: 340.00304198265076 and batch: 1300, loss is 6.7113011360168455 and perplexity is 821.639008359892
At time: 341.1010510921478 and batch: 1350, loss is 6.71735315322876 and perplexity is 826.6266592314153
At time: 342.1943278312683 and batch: 1400, loss is 6.723231573104858 and perplexity is 831.5002282233959
At time: 343.27185702323914 and batch: 1450, loss is 6.729343385696411 and perplexity is 836.597763510432
At time: 344.3553943634033 and batch: 1500, loss is 6.703059930801391 and perplexity is 814.8955380070703
At time: 345.4161412715912 and batch: 1550, loss is 6.694974613189697 and perplexity is 808.3334129430347
At time: 346.4763402938843 and batch: 1600, loss is 6.695569267272949 and perplexity is 808.8142346547986
At time: 347.53856348991394 and batch: 1650, loss is 6.687781190872192 and perplexity is 802.5395930107567
At time: 348.59928488731384 and batch: 1700, loss is 6.711564426422119 and perplexity is 821.8553665086541
At time: 349.6601436138153 and batch: 1750, loss is 6.735774993896484 and perplexity is 841.9957728794116
At time: 350.7302348613739 and batch: 1800, loss is 6.73738203048706 and perplexity is 843.3499787332742
At time: 351.8036382198334 and batch: 1850, loss is 6.692452344894409 and perplexity is 806.2971482859709
At time: 352.86237812042236 and batch: 1900, loss is 6.678104124069214 and perplexity is 794.8108199972538
At time: 353.92055892944336 and batch: 1950, loss is 6.63652398109436 and perplexity is 762.4401252181907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441680482376453 and perplexity of 627.4603503877132
finished 8 epochs...
Completing Train Step...
At time: 357.2858817577362 and batch: 50, loss is 6.679200830459595 and perplexity is 795.6829722627543
At time: 358.3379156589508 and batch: 100, loss is 6.697285614013672 and perplexity is 810.2036323333075
At time: 359.34983563423157 and batch: 150, loss is 6.660233764648438 and perplexity is 780.7334236708297
At time: 360.36540508270264 and batch: 200, loss is 6.698278465270996 and perplexity is 811.0084434911312
At time: 361.424120426178 and batch: 250, loss is 6.709374227523804 and perplexity is 820.0573095602949
At time: 362.4531877040863 and batch: 300, loss is 6.6919495677948 and perplexity is 805.8918624370916
At time: 363.4821970462799 and batch: 350, loss is 6.694262981414795 and perplexity is 807.7583818311416
At time: 364.5202853679657 and batch: 400, loss is 6.695488796234131 and perplexity is 808.7491511518286
At time: 365.55610609054565 and batch: 450, loss is 6.64722770690918 and perplexity is 770.644907805497
At time: 366.5934805870056 and batch: 500, loss is 6.647380094528199 and perplexity is 770.7623534965136
At time: 367.63129138946533 and batch: 550, loss is 6.6392905807495115 and perplexity is 764.5524123848666
At time: 368.6655457019806 and batch: 600, loss is 6.679497594833374 and perplexity is 795.9191376627498
At time: 369.701651096344 and batch: 650, loss is 6.765086002349854 and perplexity is 867.0407721272522
At time: 370.7398569583893 and batch: 700, loss is 6.705379877090454 and perplexity is 816.7882465285958
At time: 371.7760980129242 and batch: 750, loss is 6.657102899551392 and perplexity is 778.292875152234
At time: 372.8112316131592 and batch: 800, loss is 6.665942049026489 and perplexity is 785.2028162223588
At time: 373.8472065925598 and batch: 850, loss is 6.708889751434326 and perplexity is 819.6601076270008
At time: 374.9184844493866 and batch: 900, loss is 6.725620613098145 and perplexity is 833.4890903126304
At time: 375.95756101608276 and batch: 950, loss is 6.725051956176758 and perplexity is 833.0152557099556
At time: 376.99432277679443 and batch: 1000, loss is 6.72076922416687 and perplexity is 829.4553032121837
At time: 378.04320073127747 and batch: 1050, loss is 6.662185773849488 and perplexity is 782.2589108955664
At time: 379.0987584590912 and batch: 1100, loss is 6.719020118713379 and perplexity is 828.0057664837627
At time: 380.15537762641907 and batch: 1150, loss is 6.653969011306763 and perplexity is 775.8576101771679
At time: 381.21202325820923 and batch: 1200, loss is 6.719529323577881 and perplexity is 828.4274984127538
At time: 382.2670660018921 and batch: 1250, loss is 6.6762541484832765 and perplexity is 793.3417986306179
At time: 383.3223397731781 and batch: 1300, loss is 6.711404018402099 and perplexity is 821.723544889475
At time: 384.3824601173401 and batch: 1350, loss is 6.717625484466553 and perplexity is 826.8518061485946
At time: 385.4376931190491 and batch: 1400, loss is 6.72349404335022 and perplexity is 831.7185009361094
At time: 386.4937250614166 and batch: 1450, loss is 6.7295314311981205 and perplexity is 836.7550967490406
At time: 387.5503432750702 and batch: 1500, loss is 6.70327317237854 and perplexity is 815.0693261455764
At time: 388.60705757141113 and batch: 1550, loss is 6.695279226303101 and perplexity is 808.5796794067121
At time: 389.66234493255615 and batch: 1600, loss is 6.695902595520019 and perplexity is 809.083880223587
At time: 390.7177526950836 and batch: 1650, loss is 6.688116359710693 and perplexity is 802.8086243569406
At time: 391.7778627872467 and batch: 1700, loss is 6.71192886352539 and perplexity is 822.1549356814776
At time: 392.8383650779724 and batch: 1750, loss is 6.73618145942688 and perplexity is 842.3380847020911
At time: 393.8991961479187 and batch: 1800, loss is 6.737749910354614 and perplexity is 843.6602872863871
At time: 394.9598741531372 and batch: 1850, loss is 6.692793931961059 and perplexity is 806.5726160091295
At time: 396.0219192504883 and batch: 1900, loss is 6.678351802825928 and perplexity is 795.0077021337283
At time: 397.0826940536499 and batch: 1950, loss is 6.636591424942017 and perplexity is 762.4915488479277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441647551780523 and perplexity of 627.4396880846654
finished 9 epochs...
Completing Train Step...
At time: 400.42220640182495 and batch: 50, loss is 6.678816041946411 and perplexity is 795.3768614926225
At time: 401.4664237499237 and batch: 100, loss is 6.696932582855225 and perplexity is 809.91765568871
At time: 402.4886431694031 and batch: 150, loss is 6.659915924072266 and perplexity is 780.4853143413081
At time: 403.53347659111023 and batch: 200, loss is 6.697980461120605 and perplexity is 810.7667956167917
At time: 404.5626211166382 and batch: 250, loss is 6.709086656570435 and perplexity is 819.8215188028787
At time: 405.58751463890076 and batch: 300, loss is 6.691677436828614 and perplexity is 805.6725841434852
At time: 406.6220808029175 and batch: 350, loss is 6.693962593078613 and perplexity is 807.51577707443
At time: 407.6640317440033 and batch: 400, loss is 6.695231904983521 and perplexity is 808.5414172546118
At time: 408.70770359039307 and batch: 450, loss is 6.646971111297607 and perplexity is 770.4471890720378
At time: 409.7508637905121 and batch: 500, loss is 6.64716875076294 and perplexity is 770.5994748909009
At time: 410.7962872982025 and batch: 550, loss is 6.639117870330811 and perplexity is 764.4203776198228
At time: 411.84083437919617 and batch: 600, loss is 6.679370126724243 and perplexity is 795.8176898210704
At time: 412.8859074115753 and batch: 650, loss is 6.764988641738892 and perplexity is 866.9563606171939
At time: 413.931636095047 and batch: 700, loss is 6.70526873588562 and perplexity is 816.6974727432297
At time: 414.9756329059601 and batch: 750, loss is 6.656988697052002 and perplexity is 778.2039972357712
At time: 416.04675364494324 and batch: 800, loss is 6.665841646194458 and perplexity is 785.1239835934674
At time: 417.09250497817993 and batch: 850, loss is 6.708793745040894 and perplexity is 819.5814187936029
At time: 418.1378312110901 and batch: 900, loss is 6.725604000091553 and perplexity is 833.4752436678965
At time: 419.18234634399414 and batch: 950, loss is 6.725018672943115 and perplexity is 832.9875307299627
At time: 420.2275855541229 and batch: 1000, loss is 6.720734071731568 and perplexity is 829.4261463507719
At time: 421.2718138694763 and batch: 1050, loss is 6.66219204902649 and perplexity is 782.2638197240955
At time: 422.31641817092896 and batch: 1100, loss is 6.719027423858643 and perplexity is 828.0118152082596
At time: 423.3892819881439 and batch: 1150, loss is 6.653968744277954 and perplexity is 775.8574030008621
At time: 424.43180894851685 and batch: 1200, loss is 6.719541912078857 and perplexity is 828.4379271387676
At time: 425.4996600151062 and batch: 1250, loss is 6.676295022964478 and perplexity is 793.3742267277887
At time: 426.54453778266907 and batch: 1300, loss is 6.711482172012329 and perplexity is 821.7877680607226
At time: 427.59063243865967 and batch: 1350, loss is 6.717811870574951 and perplexity is 827.0059342021823
At time: 428.6351013183594 and batch: 1400, loss is 6.723668212890625 and perplexity is 831.8633735809987
At time: 429.7004351615906 and batch: 1450, loss is 6.729652938842773 and perplexity is 836.856775067219
At time: 430.75029277801514 and batch: 1500, loss is 6.703409156799316 and perplexity is 815.1801704121607
At time: 431.79633045196533 and batch: 1550, loss is 6.695473461151123 and perplexity is 808.7367490115573
At time: 432.8407492637634 and batch: 1600, loss is 6.696111936569213 and perplexity is 809.2532724217107
At time: 433.90352630615234 and batch: 1650, loss is 6.688323163986206 and perplexity is 802.974665781323
At time: 434.9514513015747 and batch: 1700, loss is 6.712152347564698 and perplexity is 822.3386947202815
At time: 435.99552178382874 and batch: 1750, loss is 6.7364294147491455 and perplexity is 842.5469728097288
At time: 437.0394766330719 and batch: 1800, loss is 6.737966136932373 and perplexity is 843.8427287867382
At time: 438.0881142616272 and batch: 1850, loss is 6.6929943656921385 and perplexity is 806.7342965705203
At time: 439.15477180480957 and batch: 1900, loss is 6.678493051528931 and perplexity is 795.1200038715831
At time: 440.20006346702576 and batch: 1950, loss is 6.636623954772949 and perplexity is 762.5163529725336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441631086482558 and perplexity of 627.4293571882968
finished 10 epochs...
Completing Train Step...
At time: 443.49566984176636 and batch: 50, loss is 6.678574953079224 and perplexity is 795.1851280994202
At time: 444.5407803058624 and batch: 100, loss is 6.696709909439087 and perplexity is 809.7373286352931
At time: 445.56550574302673 and batch: 150, loss is 6.659719171524048 and perplexity is 780.3317669727786
At time: 446.5914514064789 and batch: 200, loss is 6.697793312072754 and perplexity is 810.6150755805359
At time: 447.6180884838104 and batch: 250, loss is 6.708909997940063 and perplexity is 819.6767030480712
At time: 448.6517276763916 and batch: 300, loss is 6.69150857925415 and perplexity is 805.5365517104916
At time: 449.7030336856842 and batch: 350, loss is 6.693781290054321 and perplexity is 807.3693852929208
At time: 450.75938534736633 and batch: 400, loss is 6.695075635910034 and perplexity is 808.4150771082477
At time: 451.82454562187195 and batch: 450, loss is 6.646812839508057 and perplexity is 770.3252586659953
At time: 452.8600435256958 and batch: 500, loss is 6.647040328979492 and perplexity is 770.5005194861625
At time: 453.9390594959259 and batch: 550, loss is 6.639012136459351 and perplexity is 764.3395567667003
At time: 454.9751513004303 and batch: 600, loss is 6.679294424057007 and perplexity is 795.757446579633
At time: 456.01695728302 and batch: 650, loss is 6.76493091583252 and perplexity is 866.906316219935
At time: 457.06258726119995 and batch: 700, loss is 6.705202493667603 and perplexity is 816.6433746829933
At time: 458.1061062812805 and batch: 750, loss is 6.656919889450073 and perplexity is 778.1504527270655
At time: 459.1756625175476 and batch: 800, loss is 6.66578236579895 and perplexity is 785.0774425126978
At time: 460.2201335430145 and batch: 850, loss is 6.708736686706543 and perplexity is 819.534656177093
At time: 461.28291416168213 and batch: 900, loss is 6.7255973052978515 and perplexity is 833.4696637417629
At time: 462.3368647098541 and batch: 950, loss is 6.7250010108947755 and perplexity is 832.9728185938524
At time: 463.3809654712677 and batch: 1000, loss is 6.720715560913086 and perplexity is 829.4107931360336
At time: 464.4232060909271 and batch: 1050, loss is 6.662201642990112 and perplexity is 782.2713247707268
At time: 465.4672830104828 and batch: 1100, loss is 6.719035949707031 and perplexity is 828.0188747415539
At time: 466.51283407211304 and batch: 1150, loss is 6.653972215652466 and perplexity is 775.8600962971507
At time: 467.5574960708618 and batch: 1200, loss is 6.719553718566894 and perplexity is 828.4477081389833
At time: 468.62487506866455 and batch: 1250, loss is 6.676324615478515 and perplexity is 793.3977050131191
At time: 469.6871314048767 and batch: 1300, loss is 6.711538333892822 and perplexity is 821.8339225031908
At time: 470.7326567173004 and batch: 1350, loss is 6.717940921783447 and perplexity is 827.1126672042881
At time: 471.77494597435 and batch: 1400, loss is 6.72378472328186 and perplexity is 831.9602999544641
At time: 472.81884717941284 and batch: 1450, loss is 6.729732408523559 and perplexity is 836.9232824506227
At time: 473.86465859413147 and batch: 1500, loss is 6.703496990203857 and perplexity is 815.2517736063721
At time: 474.93555998802185 and batch: 1550, loss is 6.695600051879882 and perplexity is 808.8391340663516
At time: 476.0005819797516 and batch: 1600, loss is 6.696246719360351 and perplexity is 809.3623531874449
At time: 477.04544591903687 and batch: 1650, loss is 6.688453941345215 and perplexity is 803.0796835542886
At time: 478.0897889137268 and batch: 1700, loss is 6.71229471206665 and perplexity is 822.4557748928241
At time: 479.1343734264374 and batch: 1750, loss is 6.73658670425415 and perplexity is 842.6795070288728
At time: 480.1774117946625 and batch: 1800, loss is 6.7380990791320805 and perplexity is 843.954918552522
At time: 481.24953413009644 and batch: 1850, loss is 6.693117237091064 and perplexity is 806.833427232138
At time: 482.2930588722229 and batch: 1900, loss is 6.678577289581299 and perplexity is 795.1869860532929
At time: 483.33878445625305 and batch: 1950, loss is 6.636640453338623 and perplexity is 762.5289335024411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.4416237054869185 and perplexity of 627.424726152038
finished 11 epochs...
Completing Train Step...
At time: 486.70209765434265 and batch: 50, loss is 6.678419885635376 and perplexity is 795.0618303342014
At time: 487.7138102054596 and batch: 100, loss is 6.6965646553039555 and perplexity is 809.6197194817532
At time: 488.74656891822815 and batch: 150, loss is 6.659592475891113 and perplexity is 780.2329086082564
At time: 489.7705099582672 and batch: 200, loss is 6.697671403884888 and perplexity is 810.5162609888911
At time: 490.82565927505493 and batch: 250, loss is 6.708797397613526 and perplexity is 819.58441237973
At time: 491.8540186882019 and batch: 300, loss is 6.69140025138855 and perplexity is 805.4492943814672
At time: 492.8918368816376 and batch: 350, loss is 6.693668556213379 and perplexity is 807.2783725712608
At time: 493.93016505241394 and batch: 400, loss is 6.694977540969848 and perplexity is 808.3357795690207
At time: 494.96652936935425 and batch: 450, loss is 6.646712665557861 and perplexity is 770.2480960068082
At time: 496.00150871276855 and batch: 500, loss is 6.646959505081177 and perplexity is 770.4382471471041
At time: 497.0685532093048 and batch: 550, loss is 6.63894495010376 and perplexity is 764.2882053025253
At time: 498.1048128604889 and batch: 600, loss is 6.6792472457885745 and perplexity is 795.7199050067914
At time: 499.1414306163788 and batch: 650, loss is 6.764894933700561 and perplexity is 866.8751236436602
At time: 500.1795301437378 and batch: 700, loss is 6.705161600112915 and perplexity is 816.6099799153108
At time: 501.2147400379181 and batch: 750, loss is 6.656876897811889 and perplexity is 778.1169994834595
At time: 502.25134086608887 and batch: 800, loss is 6.665745544433594 and perplexity is 785.0485354215562
At time: 503.28912258148193 and batch: 850, loss is 6.708700962066651 and perplexity is 819.5053791195809
At time: 504.3347678184509 and batch: 900, loss is 6.725595092773437 and perplexity is 833.4678196718233
At time: 505.40843534469604 and batch: 950, loss is 6.724991111755371 and perplexity is 832.9645729206138
At time: 506.44417214393616 and batch: 1000, loss is 6.720705127716064 and perplexity is 829.402139774958
At time: 507.47824454307556 and batch: 1050, loss is 6.6622107887268065 and perplexity is 782.278479251003
At time: 508.5142993927002 and batch: 1100, loss is 6.719043426513672 and perplexity is 828.0250657017192
At time: 509.5796902179718 and batch: 1150, loss is 6.65397614479065 and perplexity is 775.8631447646692
At time: 510.6450822353363 and batch: 1200, loss is 6.719562978744507 and perplexity is 828.4553797474233
At time: 511.68309783935547 and batch: 1250, loss is 6.6763459491729735 and perplexity is 793.414631297891
At time: 512.7216672897339 and batch: 1300, loss is 6.711578588485718 and perplexity is 821.8670057590416
At time: 513.7639737129211 and batch: 1350, loss is 6.718030996322632 and perplexity is 827.1871723520984
At time: 514.8089609146118 and batch: 1400, loss is 6.723864326477051 and perplexity is 832.0265292886102
At time: 515.8717997074127 and batch: 1450, loss is 6.729785203933716 and perplexity is 836.967469325011
At time: 516.9241528511047 and batch: 1500, loss is 6.70355484008789 and perplexity is 815.2989371911241
At time: 517.9684503078461 and batch: 1550, loss is 6.695684156417847 and perplexity is 808.9071639687812
At time: 519.013457775116 and batch: 1600, loss is 6.696335544586182 and perplexity is 809.4342481742426
At time: 520.083247423172 and batch: 1650, loss is 6.688538970947266 and perplexity is 803.1479720034251
At time: 521.1478924751282 and batch: 1700, loss is 6.712387351989746 and perplexity is 822.5319706618908
At time: 522.2098393440247 and batch: 1750, loss is 6.736689462661743 and perplexity is 842.7661038823273
At time: 523.2625482082367 and batch: 1800, loss is 6.73818302154541 and perplexity is 844.0257651386019
At time: 524.3080558776855 and batch: 1850, loss is 6.693194255828858 and perplexity is 806.8955709173965
At time: 525.3535916805267 and batch: 1900, loss is 6.67862907409668 and perplexity is 795.2281654922222
At time: 526.3990774154663 and batch: 1950, loss is 6.636649131774902 and perplexity is 762.5355510899165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441615188953488 and perplexity of 627.4193826911367
finished 12 epochs...
Completing Train Step...
At time: 529.7763516902924 and batch: 50, loss is 6.678317546844482 and perplexity is 794.9804688310896
At time: 530.8093543052673 and batch: 100, loss is 6.696467504501343 and perplexity is 809.5410680967792
At time: 531.8839683532715 and batch: 150, loss is 6.659509181976318 and perplexity is 780.1679226613512
At time: 532.9026787281036 and batch: 200, loss is 6.697589645385742 and perplexity is 810.4499971047139
At time: 533.9278900623322 and batch: 250, loss is 6.708723430633545 and perplexity is 819.5237924378714
At time: 534.9581966400146 and batch: 300, loss is 6.691329355239868 and perplexity is 805.3921931526899
At time: 535.9995753765106 and batch: 350, loss is 6.6935960483551025 and perplexity is 807.2198406674697
At time: 537.027330160141 and batch: 400, loss is 6.694914236068725 and perplexity is 808.2846095720938
At time: 538.0626533031464 and batch: 450, loss is 6.646647357940674 and perplexity is 770.1977945815661
At time: 539.0973565578461 and batch: 500, loss is 6.646907224655151 and perplexity is 770.3979693601958
At time: 540.134806394577 and batch: 550, loss is 6.638901290893554 and perplexity is 764.254837811517
At time: 541.17067527771 and batch: 600, loss is 6.679217338562012 and perplexity is 795.6961075871709
At time: 542.2067003250122 and batch: 650, loss is 6.764872121810913 and perplexity is 866.8553488095523
At time: 543.2434825897217 and batch: 700, loss is 6.705135374069214 and perplexity is 816.5885637471225
At time: 544.3025054931641 and batch: 750, loss is 6.656848764419555 and perplexity is 778.0951087205634
At time: 545.33735704422 and batch: 800, loss is 6.665721626281738 and perplexity is 785.0297587360246
At time: 546.3991115093231 and batch: 850, loss is 6.708677825927734 and perplexity is 819.4864191486178
At time: 547.4353530406952 and batch: 900, loss is 6.725594339370727 and perplexity is 833.4671917351459
At time: 548.4768731594086 and batch: 950, loss is 6.7249854564666744 and perplexity is 832.9598622787997
At time: 549.520956993103 and batch: 1000, loss is 6.720699033737183 and perplexity is 829.3970854312345
At time: 550.5889730453491 and batch: 1050, loss is 6.6622185802459715 and perplexity is 782.2845744125117
At time: 551.6328737735748 and batch: 1100, loss is 6.719049291610718 and perplexity is 828.029922163328
At time: 552.678564786911 and batch: 1150, loss is 6.653979806900025 and perplexity is 775.8659860655679
At time: 553.7225034236908 and batch: 1200, loss is 6.719570207595825 and perplexity is 828.4613685498335
At time: 554.7662558555603 and batch: 1250, loss is 6.676360731124878 and perplexity is 793.4263596014945
At time: 555.8108015060425 and batch: 1300, loss is 6.711606864929199 and perplexity is 821.8902455635467
At time: 556.8854341506958 and batch: 1350, loss is 6.718094797134399 and perplexity is 827.2399492487643
At time: 557.9293415546417 and batch: 1400, loss is 6.723919553756714 and perplexity is 832.0724811193161
At time: 558.9737973213196 and batch: 1450, loss is 6.729820508956909 and perplexity is 836.9970190025502
At time: 560.0196435451508 and batch: 1500, loss is 6.7035933685302735 and perplexity is 815.33034999439
At time: 561.0653953552246 and batch: 1550, loss is 6.695740928649903 and perplexity is 808.9530887376193
At time: 562.1091618537903 and batch: 1600, loss is 6.696395502090454 and perplexity is 809.4827812865834
At time: 563.1538064479828 and batch: 1650, loss is 6.6885953044891355 and perplexity is 803.1932174477395
At time: 564.2152788639069 and batch: 1700, loss is 6.712448816299439 and perplexity is 822.5825285754054
At time: 565.2698743343353 and batch: 1750, loss is 6.736757764816284 and perplexity is 842.8236685888711
At time: 566.3144242763519 and batch: 1800, loss is 6.738237648010254 and perplexity is 844.0718725417195
At time: 567.3818805217743 and batch: 1850, loss is 6.693243961334229 and perplexity is 806.9356790663204
At time: 568.426381111145 and batch: 1900, loss is 6.678662071228027 and perplexity is 795.2544061733812
At time: 569.4712255001068 and batch: 1950, loss is 6.636653642654419 and perplexity is 762.538990803673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441611782340116 and perplexity of 627.4172453195184
finished 13 epochs...
Completing Train Step...
At time: 572.8189663887024 and batch: 50, loss is 6.678249053955078 and perplexity is 794.926020186453
At time: 573.8357999324799 and batch: 100, loss is 6.696401453018188 and perplexity is 809.4875984744499
At time: 574.8476469516754 and batch: 150, loss is 6.659452962875366 and perplexity is 780.1240635550187
At time: 575.8813383579254 and batch: 200, loss is 6.697534074783325 and perplexity is 810.4049611614952
At time: 576.9005134105682 and batch: 250, loss is 6.708673934936524 and perplexity is 819.4832305403675
At time: 577.927782535553 and batch: 300, loss is 6.691281785964966 and perplexity is 805.3538821412703
At time: 578.9559097290039 and batch: 350, loss is 6.693548755645752 and perplexity is 807.181665956863
At time: 579.9915409088135 and batch: 400, loss is 6.694872074127197 and perplexity is 808.250531442052
At time: 581.0533082485199 and batch: 450, loss is 6.646604051589966 and perplexity is 770.1644408479788
At time: 582.0880932807922 and batch: 500, loss is 6.646872577667236 and perplexity is 770.3712778534544
At time: 583.1561748981476 and batch: 550, loss is 6.638872327804566 and perplexity is 764.2327029511881
At time: 584.1975786685944 and batch: 600, loss is 6.679197483062744 and perplexity is 795.6803088005362
At time: 585.2323987483978 and batch: 650, loss is 6.764857158660889 and perplexity is 866.8423780199612
At time: 586.2684178352356 and batch: 700, loss is 6.705118169784546 and perplexity is 816.5745150458645
At time: 587.3149151802063 and batch: 750, loss is 6.656830453872681 and perplexity is 778.0808615040401
At time: 588.3657696247101 and batch: 800, loss is 6.665705699920654 and perplexity is 785.0172561681857
At time: 589.4030137062073 and batch: 850, loss is 6.708662109375 and perplexity is 819.4735397483066
At time: 590.4682304859161 and batch: 900, loss is 6.725594244003296 and perplexity is 833.4671122495245
At time: 591.5059463977814 and batch: 950, loss is 6.724982166290284 and perplexity is 832.9571216984348
At time: 592.5401039123535 and batch: 1000, loss is 6.720695180892944 and perplexity is 829.3938898996086
At time: 593.5766251087189 and batch: 1050, loss is 6.662224197387696 and perplexity is 782.2889686281762
At time: 594.6159956455231 and batch: 1100, loss is 6.719053430557251 and perplexity is 828.0333493419961
At time: 595.6665670871735 and batch: 1150, loss is 6.6539821434021 and perplexity is 775.8677988801724
At time: 596.7166357040405 and batch: 1200, loss is 6.719575414657593 and perplexity is 828.4656824105829
At time: 597.7604956626892 and batch: 1250, loss is 6.6763714408874515 and perplexity is 793.4348570549282
At time: 598.8051006793976 and batch: 1300, loss is 6.7116274166107175 and perplexity is 821.9071369636894
At time: 599.8515825271606 and batch: 1350, loss is 6.718140439987183 and perplexity is 827.2777077016798
At time: 600.8964958190918 and batch: 1400, loss is 6.723957948684692 and perplexity is 832.1044290956175
At time: 601.9406640529633 and batch: 1450, loss is 6.729844551086426 and perplexity is 837.017142435191
At time: 602.9852817058563 and batch: 1500, loss is 6.703619585037232 and perplexity is 815.3517253883767
At time: 604.0306174755096 and batch: 1550, loss is 6.695779657363891 and perplexity is 808.9844190571108
At time: 605.0748159885406 and batch: 1600, loss is 6.696436262130737 and perplexity is 809.5157765097955
At time: 606.1188354492188 and batch: 1650, loss is 6.688633127212524 and perplexity is 803.2235969771455
At time: 607.1644294261932 and batch: 1700, loss is 6.712490711212158 and perplexity is 822.6169913205464
At time: 608.2087020874023 and batch: 1750, loss is 6.736803750991822 and perplexity is 842.8624277172274
At time: 609.2525339126587 and batch: 1800, loss is 6.738273639678955 and perplexity is 844.1022526436274
At time: 610.2962312698364 and batch: 1850, loss is 6.6932767868042 and perplexity is 806.9621675439678
At time: 611.3403027057648 and batch: 1900, loss is 6.6786831092834475 and perplexity is 795.2711369556425
At time: 612.3855698108673 and batch: 1950, loss is 6.636655740737915 and perplexity is 762.5405906758225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.4416072401889535 and perplexity of 627.4143955020202
finished 14 epochs...
Completing Train Step...
At time: 615.6848828792572 and batch: 50, loss is 6.678202085494995 and perplexity is 794.888684612209
At time: 616.7362575531006 and batch: 100, loss is 6.696355962753296 and perplexity is 809.4507755067183
At time: 617.767587184906 and batch: 150, loss is 6.659414520263672 and perplexity is 780.09407412501
At time: 618.7894175052643 and batch: 200, loss is 6.6974958896636965 and perplexity is 810.374016341925
At time: 619.809342622757 and batch: 250, loss is 6.708640298843384 and perplexity is 819.4556667896693
At time: 620.8297579288483 and batch: 300, loss is 6.69124921798706 and perplexity is 805.3276538209345
At time: 621.8512599468231 and batch: 350, loss is 6.693517293930054 and perplexity is 807.1562710362576
At time: 622.8764202594757 and batch: 400, loss is 6.694844160079956 and perplexity is 808.227970213424
At time: 623.9034402370453 and batch: 450, loss is 6.646574954986573 and perplexity is 770.142032004708
At time: 624.9292461872101 and batch: 500, loss is 6.646849088668823 and perplexity is 770.3531828162495
At time: 625.9568512439728 and batch: 550, loss is 6.6388525295257566 and perplexity is 764.2175726088377
At time: 626.9898586273193 and batch: 600, loss is 6.679184551239014 and perplexity is 795.6700192695687
At time: 628.0265414714813 and batch: 650, loss is 6.764847087860107 and perplexity is 866.8336482670209
At time: 629.0646324157715 and batch: 700, loss is 6.705106840133667 and perplexity is 816.5652635941004
At time: 630.0988402366638 and batch: 750, loss is 6.656817798614502 and perplexity is 778.0710147521602
At time: 631.1352505683899 and batch: 800, loss is 6.665694904327393 and perplexity is 785.0087814869298
At time: 632.1836273670197 and batch: 850, loss is 6.708651733398438 and perplexity is 819.4650369541772
At time: 633.2252924442291 and batch: 900, loss is 6.725594396591187 and perplexity is 833.4672394265228
At time: 634.2625374794006 and batch: 950, loss is 6.724979972839355 and perplexity is 832.9552946498666
At time: 635.3372478485107 and batch: 1000, loss is 6.720692834854126 and perplexity is 829.3919441116295
At time: 636.3729591369629 and batch: 1050, loss is 6.662228574752808 and perplexity is 782.29239300011
At time: 637.4090175628662 and batch: 1100, loss is 6.719056549072266 and perplexity is 828.0359315804554
At time: 638.4462702274323 and batch: 1150, loss is 6.653984565734863 and perplexity is 775.8696782924375
At time: 639.4810481071472 and batch: 1200, loss is 6.719579496383667 and perplexity is 828.4690639874618
At time: 640.518434047699 and batch: 1250, loss is 6.676378774642944 and perplexity is 793.4406759335063
At time: 641.5671253204346 and batch: 1300, loss is 6.711642255783081 and perplexity is 821.9193334758547
At time: 642.6055846214294 and batch: 1350, loss is 6.718173522949218 and perplexity is 827.305076951402
At time: 643.6647157669067 and batch: 1400, loss is 6.7239852714538575 and perplexity is 832.127164803455
At time: 644.7102506160736 and batch: 1450, loss is 6.729861125946045 and perplexity is 837.0310159918014
At time: 645.7451460361481 and batch: 1500, loss is 6.703637742996216 and perplexity is 815.3665306459803
At time: 646.7832825183868 and batch: 1550, loss is 6.695806474685669 and perplexity is 809.0061141434903
At time: 647.8183274269104 and batch: 1600, loss is 6.696464881896973 and perplexity is 809.5389449936202
At time: 648.8566379547119 and batch: 1650, loss is 6.68865888595581 and perplexity is 803.244287274058
At time: 649.9003872871399 and batch: 1700, loss is 6.71251950263977 and perplexity is 822.6406759790601
At time: 650.9431669712067 and batch: 1750, loss is 6.736835327148437 and perplexity is 842.8890424934444
At time: 651.9868001937866 and batch: 1800, loss is 6.738297653198242 and perplexity is 844.1225227527294
At time: 653.030522108078 and batch: 1850, loss is 6.693298301696777 and perplexity is 806.9795294350857
At time: 654.0725014209747 and batch: 1900, loss is 6.6786970615386965 and perplexity is 795.2822328589436
At time: 655.1157186031342 and batch: 1950, loss is 6.636656789779663 and perplexity is 762.5413906131566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441603833575582 and perplexity of 627.4122581473914
finished 15 epochs...
Completing Train Step...
At time: 658.4002311229706 and batch: 50, loss is 6.67816990852356 and perplexity is 794.863107913203
At time: 659.4242198467255 and batch: 100, loss is 6.69632396697998 and perplexity is 809.4248769175194
At time: 660.434473991394 and batch: 150, loss is 6.659387683868408 and perplexity is 780.0731394929999
At time: 661.4641134738922 and batch: 200, loss is 6.697468948364258 and perplexity is 810.3521841069893
At time: 662.4740986824036 and batch: 250, loss is 6.70861699104309 and perplexity is 819.4365673032229
At time: 663.488983631134 and batch: 300, loss is 6.691227283477783 and perplexity is 805.3099895477698
At time: 664.5096919536591 and batch: 350, loss is 6.693496208190918 and perplexity is 807.1392517291182
At time: 665.5402307510376 and batch: 400, loss is 6.694825134277344 and perplexity is 808.2125931738775
At time: 666.5761606693268 and batch: 450, loss is 6.64655517578125 and perplexity is 770.1267993579747
At time: 667.6112587451935 and batch: 500, loss is 6.6468332004547115 and perplexity is 770.3409433771711
At time: 668.6480896472931 and batch: 550, loss is 6.6388389778137205 and perplexity is 764.2072162225344
At time: 669.6842987537384 and batch: 600, loss is 6.679175863265991 and perplexity is 795.663106539935
At time: 670.7204082012177 and batch: 650, loss is 6.764840335845947 and perplexity is 866.8277954137125
At time: 671.7580122947693 and batch: 700, loss is 6.705099201202392 and perplexity is 816.5590259319948
At time: 672.7939338684082 and batch: 750, loss is 6.656809453964233 and perplexity is 778.0645220487477
At time: 673.8295757770538 and batch: 800, loss is 6.665687437057495 and perplexity is 785.0029196363726
At time: 674.8665380477905 and batch: 850, loss is 6.708644142150879 and perplexity is 819.4588162158277
At time: 675.9049026966095 and batch: 900, loss is 6.725595073699951 and perplexity is 833.4678037746868
At time: 676.9430181980133 and batch: 950, loss is 6.724978876113892 and perplexity is 832.9543811270861
At time: 677.9786486625671 and batch: 1000, loss is 6.720691318511963 and perplexity is 829.3906864706086
At time: 679.0136585235596 and batch: 1050, loss is 6.662231903076172 and perplexity is 782.2949967264925
At time: 680.0500965118408 and batch: 1100, loss is 6.719058952331543 and perplexity is 828.0379215678809
At time: 681.0878195762634 and batch: 1150, loss is 6.653986129760742 and perplexity is 775.8708917736424
At time: 682.1475255489349 and batch: 1200, loss is 6.719582347869873 and perplexity is 828.4714263589383
At time: 683.1831033229828 and batch: 1250, loss is 6.676384201049805 and perplexity is 793.4449814771157
At time: 684.2201969623566 and batch: 1300, loss is 6.711652984619141 and perplexity is 821.9281517609426
At time: 685.2582869529724 and batch: 1350, loss is 6.7181973361969 and perplexity is 827.3247780066796
At time: 686.2950525283813 and batch: 1400, loss is 6.724004640579223 and perplexity is 832.1432825349231
At time: 687.3325214385986 and batch: 1450, loss is 6.729872388839722 and perplexity is 837.0404434362283
At time: 688.3692171573639 and batch: 1500, loss is 6.7036502647399905 and perplexity is 815.3767405206819
At time: 689.4067854881287 and batch: 1550, loss is 6.695825157165527 and perplexity is 809.0212285251097
At time: 690.4424731731415 and batch: 1600, loss is 6.696484727859497 and perplexity is 809.5550112326088
At time: 691.4798748493195 and batch: 1650, loss is 6.688676719665527 and perplexity is 803.2586122272422
At time: 692.5399181842804 and batch: 1700, loss is 6.712539253234863 and perplexity is 822.6569237824095
At time: 693.5843834877014 and batch: 1750, loss is 6.7368572807312015 and perplexity is 842.9075471309205
At time: 694.646861076355 and batch: 1800, loss is 6.738313827514649 and perplexity is 844.1361759679135
At time: 695.7085783481598 and batch: 1850, loss is 6.693312635421753 and perplexity is 806.9910965406215
At time: 696.7443447113037 and batch: 1900, loss is 6.678706121444702 and perplexity is 795.2894380738608
At time: 697.780784368515 and batch: 1950, loss is 6.636657457351685 and perplexity is 762.5418996646243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441603833575582 and perplexity of 627.4122581473914
finished 16 epochs...
Completing Train Step...
At time: 701.0913515090942 and batch: 50, loss is 6.678147258758545 and perplexity is 794.8451046544754
At time: 702.1089420318604 and batch: 100, loss is 6.696301736831665 and perplexity is 809.4068834824549
At time: 703.1128997802734 and batch: 150, loss is 6.659369068145752 and perplexity is 780.0586180029482
At time: 704.1125276088715 and batch: 200, loss is 6.697449760437012 and perplexity is 810.3366352774121
At time: 705.1382853984833 and batch: 250, loss is 6.708600921630859 and perplexity is 819.423399545025
At time: 706.1484916210175 and batch: 300, loss is 6.691211757659912 and perplexity is 805.297486548602
At time: 707.1598796844482 and batch: 350, loss is 6.69348147392273 and perplexity is 807.1273592105316
At time: 708.204912185669 and batch: 400, loss is 6.694811992645263 and perplexity is 808.2019720111252
At time: 709.2383501529694 and batch: 450, loss is 6.646541538238526 and perplexity is 770.11629679246
At time: 710.2568638324738 and batch: 500, loss is 6.646822195053101 and perplexity is 770.3324655123636
At time: 711.2766265869141 and batch: 550, loss is 6.63882960319519 and perplexity is 764.2000521049846
At time: 712.3052906990051 and batch: 600, loss is 6.6791696357727055 and perplexity is 795.6581515687101
At time: 713.3544569015503 and batch: 650, loss is 6.764835948944092 and perplexity is 866.8239927335898
At time: 714.3757004737854 and batch: 700, loss is 6.705093879699707 and perplexity is 816.5546806225071
At time: 715.4238090515137 and batch: 750, loss is 6.65680344581604 and perplexity is 778.0598473358385
At time: 716.4503085613251 and batch: 800, loss is 6.665682258605957 and perplexity is 784.9988545473217
At time: 717.4780094623566 and batch: 850, loss is 6.708639087677002 and perplexity is 819.4546742931157
At time: 718.5068075656891 and batch: 900, loss is 6.7255955410003665 and perplexity is 833.4681932546285
At time: 719.5374138355255 and batch: 950, loss is 6.724977951049805 and perplexity is 832.9536105912587
At time: 720.5736815929413 and batch: 1000, loss is 6.720690450668335 and perplexity is 829.3899666894985
At time: 721.6102519035339 and batch: 1050, loss is 6.662234449386597 and perplexity is 782.2969886949339
At time: 722.6468484401703 and batch: 1100, loss is 6.71906063079834 and perplexity is 828.039311403205
At time: 723.6831314563751 and batch: 1150, loss is 6.653987102508545 and perplexity is 775.8716465007143
At time: 724.7190492153168 and batch: 1200, loss is 6.71958438873291 and perplexity is 828.4731171573748
At time: 725.7550518512726 and batch: 1250, loss is 6.676388206481934 and perplexity is 793.4481595735019
At time: 726.8157737255096 and batch: 1300, loss is 6.7116608142852785 and perplexity is 821.9345872091537
At time: 727.8525018692017 and batch: 1350, loss is 6.7182149410247805 and perplexity is 827.339343045205
At time: 728.8889920711517 and batch: 1400, loss is 6.724018526077271 and perplexity is 832.1548373390698
At time: 729.924572467804 and batch: 1450, loss is 6.729880390167236 and perplexity is 837.0471408977533
At time: 730.9611983299255 and batch: 1500, loss is 6.703658952713012 and perplexity is 815.383824522579
At time: 732.0062344074249 and batch: 1550, loss is 6.695838317871094 and perplexity is 809.0318758853591
At time: 733.063239812851 and batch: 1600, loss is 6.696498765945434 and perplexity is 809.5663759151964
At time: 734.0997502803802 and batch: 1650, loss is 6.688689308166504 and perplexity is 803.2687241127135
At time: 735.1372966766357 and batch: 1700, loss is 6.712553243637085 and perplexity is 822.6684331641746
At time: 736.1744086742401 and batch: 1750, loss is 6.736872472763062 and perplexity is 842.9203527065027
At time: 737.2110431194305 and batch: 1800, loss is 6.738325204849243 and perplexity is 844.145780042265
At time: 738.2487082481384 and batch: 1850, loss is 6.693322496414185 and perplexity is 806.9990543129525
At time: 739.2841854095459 and batch: 1900, loss is 6.678712425231933 and perplexity is 795.2944514250669
At time: 740.3219554424286 and batch: 1950, loss is 6.636657648086548 and perplexity is 762.5420451079626
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.441604401344477 and perplexity of 627.412614372657
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 743.5868294239044 and batch: 50, loss is 6.681803331375122 and perplexity is 797.7564348503803
At time: 744.5957555770874 and batch: 100, loss is 6.708893957138062 and perplexity is 819.6635548818263
At time: 745.6244580745697 and batch: 150, loss is 6.667143592834472 and perplexity is 786.1468388328888
At time: 746.6291711330414 and batch: 200, loss is 6.704612846374512 and perplexity is 816.1619850666807
At time: 747.6379265785217 and batch: 250, loss is 6.720234928131103 and perplexity is 829.0122469039865
At time: 748.6603453159332 and batch: 300, loss is 6.691189556121826 and perplexity is 805.2796079042519
At time: 749.6817853450775 and batch: 350, loss is 6.693618860244751 and perplexity is 807.23825508743
At time: 750.7058799266815 and batch: 400, loss is 6.695430345535279 and perplexity is 808.7018805802597
At time: 751.7336268424988 and batch: 450, loss is 6.650345058441162 and perplexity is 773.0510273010748
At time: 752.7603561878204 and batch: 500, loss is 6.652785558700561 and perplexity is 774.9399625696905
At time: 753.7877712249756 and batch: 550, loss is 6.643805208206177 and perplexity is 768.0118849368916
At time: 754.8162202835083 and batch: 600, loss is 6.678365898132324 and perplexity is 795.0189080898532
At time: 755.8440761566162 and batch: 650, loss is 6.756528024673462 and perplexity is 859.6523167664101
At time: 756.8788189888 and batch: 700, loss is 6.690066871643066 and perplexity is 804.3760402929681
At time: 757.9167666435242 and batch: 750, loss is 6.650079498291015 and perplexity is 772.8457630104081
At time: 758.9534208774567 and batch: 800, loss is 6.655797748565674 and perplexity is 777.2777480302329
At time: 759.9904282093048 and batch: 850, loss is 6.698634033203125 and perplexity is 811.2968633597117
At time: 761.0568506717682 and batch: 900, loss is 6.70045841217041 and perplexity is 812.7783272583347
At time: 762.1213381290436 and batch: 950, loss is 6.714564228057862 and perplexity is 824.3244711419262
At time: 763.1574409008026 and batch: 1000, loss is 6.713462266921997 and perplexity is 823.4165979237578
At time: 764.2430965900421 and batch: 1050, loss is 6.650965480804444 and perplexity is 773.530794260056
At time: 765.2981514930725 and batch: 1100, loss is 6.700559520721436 and perplexity is 812.8605102519407
At time: 766.3347625732422 and batch: 1150, loss is 6.646447238922119 and perplexity is 770.0436787760871
At time: 767.3797373771667 and batch: 1200, loss is 6.710074815750122 and perplexity is 820.632033355134
At time: 768.4352719783783 and batch: 1250, loss is 6.662330312728882 and perplexity is 782.3719858936131
At time: 769.4719758033752 and batch: 1300, loss is 6.689879131317139 and perplexity is 804.2250406478003
At time: 770.50994348526 and batch: 1350, loss is 6.6940566921234135 and perplexity is 807.5917671129532
At time: 771.549836397171 and batch: 1400, loss is 6.71070366859436 and perplexity is 821.1482524392898
At time: 772.5877904891968 and batch: 1450, loss is 6.7066580677032475 and perplexity is 817.8329251048928
At time: 773.6262986660004 and batch: 1500, loss is 6.6838091945648195 and perplexity is 799.358231072363
At time: 774.6654224395752 and batch: 1550, loss is 6.682386026382447 and perplexity is 798.2214190008434
At time: 775.7268948554993 and batch: 1600, loss is 6.674663772583008 and perplexity is 792.0810897196602
At time: 776.7648990154266 and batch: 1650, loss is 6.666498718261718 and perplexity is 785.6400361557178
At time: 777.8293504714966 and batch: 1700, loss is 6.678656387329101 and perplexity is 795.2498860405622
At time: 778.8645823001862 and batch: 1750, loss is 6.702319383621216 and perplexity is 814.2922928075961
At time: 779.9015619754791 and batch: 1800, loss is 6.702128438949585 and perplexity is 814.1368228766845
At time: 780.9641199111938 and batch: 1850, loss is 6.656380319595337 and perplexity is 777.7306994536152
At time: 781.999804019928 and batch: 1900, loss is 6.642657384872437 and perplexity is 767.130848708472
At time: 783.0379297733307 and batch: 1950, loss is 6.618899536132813 and perplexity is 749.1202635631358
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.402063272165698 and perplexity of 603.0880899231536
finished 18 epochs...
Completing Train Step...
At time: 786.308128118515 and batch: 50, loss is 6.667604656219482 and perplexity is 786.5093859276886
At time: 787.311253786087 and batch: 100, loss is 6.687969551086426 and perplexity is 802.6907737782014
At time: 788.3241329193115 and batch: 150, loss is 6.645868396759033 and perplexity is 769.5980740072498
At time: 789.3472962379456 and batch: 200, loss is 6.683226013183594 and perplexity is 798.8921961397284
At time: 790.3666732311249 and batch: 250, loss is 6.698493194580078 and perplexity is 811.182609472463
At time: 791.3874046802521 and batch: 300, loss is 6.671461791992187 and perplexity is 789.5489175904888
At time: 792.4098780155182 and batch: 350, loss is 6.677025537490845 and perplexity is 793.9540098694787
At time: 793.4314594268799 and batch: 400, loss is 6.6805548667907715 and perplexity is 796.7610856529271
At time: 794.4823708534241 and batch: 450, loss is 6.6370267486572265 and perplexity is 762.8235517609158
At time: 795.5102410316467 and batch: 500, loss is 6.639051284790039 and perplexity is 764.3694799701447
At time: 796.5478692054749 and batch: 550, loss is 6.62978232383728 and perplexity is 757.3173027741288
At time: 797.5909295082092 and batch: 600, loss is 6.664840669631958 and perplexity is 784.3384860851172
At time: 798.6194133758545 and batch: 650, loss is 6.743670730590821 and perplexity is 848.6702651411152
At time: 799.6466705799103 and batch: 700, loss is 6.682301988601685 and perplexity is 798.154341062814
At time: 800.6748375892639 and batch: 750, loss is 6.643423347473145 and perplexity is 767.7186673432377
At time: 801.7021725177765 and batch: 800, loss is 6.648999233245849 and perplexity is 772.0113355298892
At time: 802.7295022010803 and batch: 850, loss is 6.690332803726196 and perplexity is 804.5899781341905
At time: 803.7699446678162 and batch: 900, loss is 6.695454940795899 and perplexity is 808.7217710583814
At time: 804.8139700889587 and batch: 950, loss is 6.708599748611451 and perplexity is 819.4224383460371
At time: 805.8569233417511 and batch: 1000, loss is 6.706000699996948 and perplexity is 817.2954848180784
At time: 806.9006454944611 and batch: 1050, loss is 6.644487447738648 and perplexity is 768.536031782722
At time: 807.944895029068 and batch: 1100, loss is 6.695373697280884 and perplexity is 808.6560703279467
At time: 808.9905061721802 and batch: 1150, loss is 6.640922374725342 and perplexity is 765.801022866072
At time: 810.0347905158997 and batch: 1200, loss is 6.704326915740967 and perplexity is 815.9286527132385
At time: 811.0801539421082 and batch: 1250, loss is 6.657740507125855 and perplexity is 778.7892788231345
At time: 812.1279985904694 and batch: 1300, loss is 6.687003927230835 and perplexity is 801.916050524204
At time: 813.199006319046 and batch: 1350, loss is 6.691906070709228 and perplexity is 805.8568092521509
At time: 814.2448143959045 and batch: 1400, loss is 6.709789276123047 and perplexity is 820.3977438414257
At time: 815.290965795517 and batch: 1450, loss is 6.706920347213745 and perplexity is 818.0474540562025
At time: 816.3353023529053 and batch: 1500, loss is 6.684365482330322 and perplexity is 799.8030279826315
At time: 817.386426448822 and batch: 1550, loss is 6.682117147445679 and perplexity is 798.0068229258721
At time: 818.4354765415192 and batch: 1600, loss is 6.675432024002075 and perplexity is 792.6898409479098
At time: 819.5378930568695 and batch: 1650, loss is 6.668187274932861 and perplexity is 786.9677545282744
At time: 820.5875723361969 and batch: 1700, loss is 6.6833963966369625 and perplexity is 799.0283257477628
At time: 821.632256269455 and batch: 1750, loss is 6.7089753913879395 and perplexity is 819.7303062864585
At time: 822.675482749939 and batch: 1800, loss is 6.710358486175537 and perplexity is 820.8648554139502
At time: 823.7177655696869 and batch: 1850, loss is 6.665754299163819 and perplexity is 785.0554083397827
At time: 824.7602360248566 and batch: 1900, loss is 6.650468311309814 and perplexity is 773.1463139298589
At time: 825.8029325008392 and batch: 1950, loss is 6.623717832565307 and perplexity is 752.7384568204141
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.401333689135174 and perplexity of 602.648247557108
finished 19 epochs...
Completing Train Step...
At time: 829.0719919204712 and batch: 50, loss is 6.665158348083496 and perplexity is 784.5876931026127
At time: 830.0717718601227 and batch: 100, loss is 6.6836466979980464 and perplexity is 799.2283486572011
At time: 831.0733919143677 and batch: 150, loss is 6.640993928909301 and perplexity is 765.8558210938363
At time: 832.0741114616394 and batch: 200, loss is 6.678420352935791 and perplexity is 795.0622018670117
At time: 833.0756328105927 and batch: 250, loss is 6.693306493759155 and perplexity is 806.9861402888067
At time: 834.0838959217072 and batch: 300, loss is 6.6664732837677 and perplexity is 785.6200540530359
At time: 835.1032156944275 and batch: 350, loss is 6.6726673889160155 and perplexity is 790.5013693578454
At time: 836.1372354030609 and batch: 400, loss is 6.676677932739258 and perplexity is 793.6780756439088
At time: 837.1547577381134 and batch: 450, loss is 6.63322606086731 and perplexity is 759.9298002083812
At time: 838.1726059913635 and batch: 500, loss is 6.635140037536621 and perplexity is 761.3856809327191
At time: 839.1908826828003 and batch: 550, loss is 6.625439548492432 and perplexity is 754.0355749245093
At time: 840.2099432945251 and batch: 600, loss is 6.6612382507324215 and perplexity is 781.5180535391261
At time: 841.2278075218201 and batch: 650, loss is 6.740387487411499 and perplexity is 845.8884434790265
At time: 842.2639300823212 and batch: 700, loss is 6.679737520217896 and perplexity is 796.1101217779541
At time: 843.2878727912903 and batch: 750, loss is 6.641611156463623 and perplexity is 766.328674323262
At time: 844.3105216026306 and batch: 800, loss is 6.647082061767578 and perplexity is 770.5326752920332
At time: 845.3352534770966 and batch: 850, loss is 6.688367204666138 and perplexity is 803.0100301103005
At time: 846.3638939857483 and batch: 900, loss is 6.694193105697632 and perplexity is 807.701941106858
At time: 847.4343411922455 and batch: 950, loss is 6.707035436630249 and perplexity is 818.1416080783239
At time: 848.4746778011322 and batch: 1000, loss is 6.704144706726074 and perplexity is 815.7799967008494
At time: 849.5028986930847 and batch: 1050, loss is 6.643172683715821 and perplexity is 767.5262522142707
At time: 850.5442650318146 and batch: 1100, loss is 6.694590911865235 and perplexity is 808.0233138384041
At time: 851.5957372188568 and batch: 1150, loss is 6.640162982940674 and perplexity is 765.2197006142244
At time: 852.6449060440063 and batch: 1200, loss is 6.7033036518096925 and perplexity is 815.0941693735888
At time: 853.6943485736847 and batch: 1250, loss is 6.657043752670288 and perplexity is 778.2468429174284
At time: 854.7437405586243 and batch: 1300, loss is 6.68693904876709 and perplexity is 801.8640251304753
At time: 855.7920713424683 and batch: 1350, loss is 6.692255859375 and perplexity is 806.1387381351517
At time: 856.8410959243774 and batch: 1400, loss is 6.71087532043457 and perplexity is 821.2892161459001
At time: 857.9104692935944 and batch: 1450, loss is 6.708441877365113 and perplexity is 819.293085315249
At time: 858.9750528335571 and batch: 1500, loss is 6.685793542861939 and perplexity is 800.9460110502189
At time: 860.0130536556244 and batch: 1550, loss is 6.683543014526367 and perplexity is 799.1454861831563
At time: 861.0514614582062 and batch: 1600, loss is 6.676890888214111 and perplexity is 793.8471117333297
At time: 862.0894904136658 and batch: 1650, loss is 6.669912919998169 and perplexity is 788.3269539610387
At time: 863.1262850761414 and batch: 1700, loss is 6.68616870880127 and perplexity is 801.2465550862254
At time: 864.1643970012665 and batch: 1750, loss is 6.712558469772339 and perplexity is 822.6727325519097
At time: 865.20157122612 and batch: 1800, loss is 6.714240484237671 and perplexity is 824.0576443826494
At time: 866.2383794784546 and batch: 1850, loss is 6.669802312850952 and perplexity is 788.2397641875816
At time: 867.2756772041321 and batch: 1900, loss is 6.6538084030151365 and perplexity is 775.733011017949
At time: 868.312965631485 and batch: 1950, loss is 6.625609302520752 and perplexity is 754.1635863657712
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.40117925599564 and perplexity of 602.5551858822912
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
4509.4447276592255


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56731245050365}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.6765022317192798, 'rnn_dropout': 0.40821417681898475, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.08080462170798}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.9990387741788632, 'rnn_dropout': 0.09278654931862784, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -602.5551858822912}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.604511707161204, 'rnn_dropout': 0.4360814554105134, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.580474853515625 and batch: 50, loss is 7.634359254837036 and perplexity is 2068.0455362249586
At time: 2.730975866317749 and batch: 100, loss is 6.84794620513916 and perplexity is 941.944358233535
At time: 3.882441520690918 and batch: 150, loss is 6.544251623153687 and perplexity is 695.2361855472875
At time: 5.034456253051758 and batch: 200, loss is 6.397302989959717 and perplexity is 600.2240426649954
At time: 6.186371564865112 and batch: 250, loss is 6.3349603652954105 and perplexity is 563.947050667351
At time: 7.335511207580566 and batch: 300, loss is 6.248493814468384 and perplexity is 517.2331885323589
At time: 8.486553430557251 and batch: 350, loss is 6.178196544647217 and perplexity is 482.1216869056721
At time: 9.642378807067871 and batch: 400, loss is 6.120180969238281 and perplexity is 454.9470184656376
At time: 10.794819355010986 and batch: 450, loss is 6.025322179794312 and perplexity is 413.7749304724441
At time: 11.965611696243286 and batch: 500, loss is 5.993251943588257 and perplexity is 400.7155979302058
At time: 13.122805118560791 and batch: 550, loss is 5.936292181015014 and perplexity is 378.5288080262966
At time: 14.281558513641357 and batch: 600, loss is 5.959819440841675 and perplexity is 387.5401439979694
At time: 15.439615249633789 and batch: 650, loss is 6.025231418609619 and perplexity is 413.7373774737612
At time: 16.596466779708862 and batch: 700, loss is 5.927902545928955 and perplexity is 375.36637384102386
At time: 17.754700899124146 and batch: 750, loss is 5.861625118255615 and perplexity is 351.29457561289996
At time: 18.911587238311768 and batch: 800, loss is 5.8582058525085445 and perplexity is 350.0954573237001
At time: 20.070185899734497 and batch: 850, loss is 5.881669273376465 and perplexity is 358.4070219403948
At time: 21.22719407081604 and batch: 900, loss is 5.861346921920776 and perplexity is 351.19686034216096
At time: 22.384339570999146 and batch: 950, loss is 5.875649909973145 and perplexity is 356.25611985410336
At time: 23.538820028305054 and batch: 1000, loss is 5.852534294128418 and perplexity is 348.11549055482465
At time: 24.6944580078125 and batch: 1050, loss is 5.75026382446289 and perplexity is 314.27356240321166
At time: 25.85262131690979 and batch: 1100, loss is 5.818811912536621 and perplexity is 336.57193909024375
At time: 27.01528811454773 and batch: 1150, loss is 5.716552000045777 and perplexity is 303.8554211773225
At time: 28.185800313949585 and batch: 1200, loss is 5.79684947013855 and perplexity is 329.2605788128115
At time: 29.3581645488739 and batch: 1250, loss is 5.728642492294312 and perplexity is 307.55148136117947
At time: 30.533031940460205 and batch: 1300, loss is 5.735419225692749 and perplexity is 309.64275375107013
At time: 31.703675746917725 and batch: 1350, loss is 5.702050943374633 and perplexity is 299.480990086155
At time: 32.87672972679138 and batch: 1400, loss is 5.7137690448760985 and perplexity is 303.0109807270851
At time: 34.048983097076416 and batch: 1450, loss is 5.690919151306153 and perplexity is 296.1657166779355
At time: 35.26964068412781 and batch: 1500, loss is 5.656605930328369 and perplexity is 286.1756921218937
At time: 36.54317760467529 and batch: 1550, loss is 5.631840009689331 and perplexity is 279.17533064319383
At time: 37.82298302650452 and batch: 1600, loss is 5.640643301010132 and perplexity is 281.6438419786099
At time: 39.1027467250824 and batch: 1650, loss is 5.636514368057251 and perplexity is 280.4833508821323
At time: 40.38387489318848 and batch: 1700, loss is 5.65363694190979 and perplexity is 285.3272998629077
At time: 41.665377616882324 and batch: 1750, loss is 5.659839248657226 and perplexity is 287.10248673609215
At time: 42.9501051902771 and batch: 1800, loss is 5.653720092773438 and perplexity is 285.3510260607269
At time: 44.23075246810913 and batch: 1850, loss is 5.616768264770508 and perplexity is 274.9992209546861
At time: 45.512097120285034 and batch: 1900, loss is 5.61841893196106 and perplexity is 275.4535279978542
At time: 46.79402184486389 and batch: 1950, loss is 5.559277563095093 and perplexity is 259.63519850365714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.028654728379361 and perplexity of 152.72741457744013
finished 1 epochs...
Completing Train Step...
At time: 50.30208659172058 and batch: 50, loss is 5.284213275909424 and perplexity is 197.1989812163349
At time: 51.38152861595154 and batch: 100, loss is 5.207955312728882 and perplexity is 182.72007057766677
At time: 52.46423697471619 and batch: 150, loss is 5.113623456954956 and perplexity is 166.2717431676342
At time: 53.5463330745697 and batch: 200, loss is 5.070591888427734 and perplexity is 159.26856867306893
At time: 54.642284631729126 and batch: 250, loss is 5.074654750823974 and perplexity is 159.91697124492364
At time: 55.72421741485596 and batch: 300, loss is 5.072344322204589 and perplexity is 159.54792099413305
At time: 56.806896686553955 and batch: 350, loss is 5.058644504547119 and perplexity is 157.37704780556106
At time: 57.88892960548401 and batch: 400, loss is 5.019469413757324 and perplexity is 151.33098834829357
At time: 58.96971082687378 and batch: 450, loss is 4.96992259979248 and perplexity is 144.01574009135507
At time: 60.05312490463257 and batch: 500, loss is 4.951698637008667 and perplexity is 141.41497272610056
At time: 61.134177684783936 and batch: 550, loss is 4.89891713142395 and perplexity is 134.14444020840813
At time: 62.22210931777954 and batch: 600, loss is 4.890353374481201 and perplexity is 133.0005647537055
At time: 63.32837176322937 and batch: 650, loss is 4.955362148284912 and perplexity is 141.93399822068838
At time: 64.41668963432312 and batch: 700, loss is 4.942561168670654 and perplexity is 140.12868355329107
At time: 65.51271605491638 and batch: 750, loss is 4.898234844207764 and perplexity is 134.05294638781285
At time: 66.59502625465393 and batch: 800, loss is 4.873668661117554 and perplexity is 130.79989824999436
At time: 67.67486381530762 and batch: 850, loss is 4.862381715774536 and perplexity is 129.33186732494752
At time: 68.75481271743774 and batch: 900, loss is 4.866359672546387 and perplexity is 129.84736854339022
At time: 69.83555507659912 and batch: 950, loss is 4.92089584350586 and perplexity is 137.12540107893412
At time: 70.92308616638184 and batch: 1000, loss is 4.889545602798462 and perplexity is 132.89317404313599
At time: 72.00284385681152 and batch: 1050, loss is 4.802670726776123 and perplexity is 121.83537238405731
At time: 73.08345174789429 and batch: 1100, loss is 4.8727148818969725 and perplexity is 130.6752035000729
At time: 74.16886878013611 and batch: 1150, loss is 4.783739347457885 and perplexity is 119.55055633362156
At time: 75.26779818534851 and batch: 1200, loss is 4.869910764694214 and perplexity is 130.3092881884426
At time: 76.34839653968811 and batch: 1250, loss is 4.817572050094604 and perplexity is 123.66447483729335
At time: 77.42901706695557 and batch: 1300, loss is 4.845184211730957 and perplexity is 127.12669806601467
At time: 78.510897397995 and batch: 1350, loss is 4.743391332626342 and perplexity is 114.82294492813374
At time: 79.59136176109314 and batch: 1400, loss is 4.757597398757935 and perplexity is 116.46576868022694
At time: 80.67051029205322 and batch: 1450, loss is 4.7018558788299565 and perplexity is 110.15141054384512
At time: 81.75059986114502 and batch: 1500, loss is 4.674318180084229 and perplexity is 107.15947871157002
At time: 82.84306263923645 and batch: 1550, loss is 4.673291454315185 and perplexity is 107.0495117759831
At time: 83.92337369918823 and batch: 1600, loss is 4.736160984039307 and perplexity is 113.99572914351144
At time: 85.00283885002136 and batch: 1650, loss is 4.7026264858245845 and perplexity is 110.23632670557026
At time: 86.10029602050781 and batch: 1700, loss is 4.72877908706665 and perplexity is 113.15732273773368
At time: 87.18042373657227 and batch: 1750, loss is 4.728115110397339 and perplexity is 113.08221385350691
At time: 88.26076602935791 and batch: 1800, loss is 4.695034456253052 and perplexity is 109.40257817978863
At time: 89.34034490585327 and batch: 1850, loss is 4.695048007965088 and perplexity is 109.40406078207
At time: 90.42027950286865 and batch: 1900, loss is 4.7715616703033445 and perplexity is 118.10353680547156
At time: 91.4998230934143 and batch: 1950, loss is 4.692102479934692 and perplexity is 109.08228219097664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.542841569767442 and perplexity of 93.95740767717486
finished 2 epochs...
Completing Train Step...
At time: 94.95647072792053 and batch: 50, loss is 4.649506750106812 and perplexity is 104.5334117645836
At time: 96.03230214118958 and batch: 100, loss is 4.59942816734314 and perplexity is 99.42744352362136
At time: 97.10891366004944 and batch: 150, loss is 4.550310306549072 and perplexity is 94.66177792753456
At time: 98.18907523155212 and batch: 200, loss is 4.544155540466309 and perplexity is 94.0809461029657
At time: 99.26985192298889 and batch: 250, loss is 4.540040731430054 and perplexity is 93.6946163574656
At time: 100.3507490158081 and batch: 300, loss is 4.564119310379028 and perplexity is 95.97802992983712
At time: 101.43177509307861 and batch: 350, loss is 4.575226221084595 and perplexity is 97.0499914081227
At time: 102.51250076293945 and batch: 400, loss is 4.536859054565429 and perplexity is 93.39698410017404
At time: 103.59284257888794 and batch: 450, loss is 4.533417224884033 and perplexity is 93.07608015330054
At time: 104.68343567848206 and batch: 500, loss is 4.537757043838501 and perplexity is 93.48089125825872
At time: 105.77173089981079 and batch: 550, loss is 4.493385257720948 and perplexity is 89.42365618269392
At time: 106.87563180923462 and batch: 600, loss is 4.476530990600586 and perplexity is 87.92911606258976
At time: 107.95700860023499 and batch: 650, loss is 4.538765716552734 and perplexity is 93.57523045326053
At time: 109.05572080612183 and batch: 700, loss is 4.5599431133270265 and perplexity is 95.57804255856313
At time: 110.14810371398926 and batch: 750, loss is 4.521226825714112 and perplexity is 91.94833339043869
At time: 111.22674131393433 and batch: 800, loss is 4.499621524810791 and perplexity is 89.98306849609055
At time: 112.30824899673462 and batch: 850, loss is 4.492720317840576 and perplexity is 89.36421459218163
At time: 113.3902702331543 and batch: 900, loss is 4.476752777099609 and perplexity is 87.94861971614705
At time: 114.4715039730072 and batch: 950, loss is 4.553065671920776 and perplexity is 94.92296538064653
At time: 115.55378365516663 and batch: 1000, loss is 4.528749189376831 and perplexity is 92.64261021992282
At time: 116.63566708564758 and batch: 1050, loss is 4.458460645675659 and perplexity is 86.35447659354932
At time: 117.71801710128784 and batch: 1100, loss is 4.516118173599243 and perplexity is 91.47979915081822
At time: 118.79928040504456 and batch: 1150, loss is 4.460734415054321 and perplexity is 86.55105015491948
At time: 119.88082385063171 and batch: 1200, loss is 4.541960430145264 and perplexity is 93.87465454635871
At time: 120.98009586334229 and batch: 1250, loss is 4.511063938140869 and perplexity is 91.01860517946446
At time: 122.06166791915894 and batch: 1300, loss is 4.520284366607666 and perplexity is 91.86171666908258
At time: 123.14496994018555 and batch: 1350, loss is 4.404105129241944 and perplexity is 81.78592225632495
At time: 124.22557616233826 and batch: 1400, loss is 4.426726703643799 and perplexity is 83.65713365920868
At time: 125.30659532546997 and batch: 1450, loss is 4.368029298782349 and perplexity is 78.88801370697429
At time: 126.38785862922668 and batch: 1500, loss is 4.3629658412933345 and perplexity is 78.48957718764433
At time: 127.46926307678223 and batch: 1550, loss is 4.366490602493286 and perplexity is 78.76672235224119
At time: 128.55068016052246 and batch: 1600, loss is 4.441553907394409 and perplexity is 84.90677648557231
At time: 129.63192486763 and batch: 1650, loss is 4.404258680343628 and perplexity is 81.79848153901085
At time: 130.71336221694946 and batch: 1700, loss is 4.428398952484131 and perplexity is 83.79714623926536
At time: 131.79431056976318 and batch: 1750, loss is 4.423691320419311 and perplexity is 83.40358719909855
At time: 132.87475848197937 and batch: 1800, loss is 4.399662227630615 and perplexity is 81.42336145791946
At time: 133.95639729499817 and batch: 1850, loss is 4.416972436904907 and perplexity is 82.84508656343094
At time: 135.03621292114258 and batch: 1900, loss is 4.495799169540406 and perplexity is 89.6397777475479
At time: 136.11691808700562 and batch: 1950, loss is 4.425061206817627 and perplexity is 83.51791893163654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418354265079942 and perplexity of 82.95964336888981
finished 3 epochs...
Completing Train Step...
At time: 139.52032256126404 and batch: 50, loss is 4.393454928398132 and perplexity is 80.91950769219525
At time: 140.5953381061554 and batch: 100, loss is 4.352914276123047 and perplexity is 77.7045858921574
At time: 141.65342378616333 and batch: 150, loss is 4.311673135757446 and perplexity is 74.56514223605711
At time: 142.71056628227234 and batch: 200, loss is 4.3149714756011965 and perplexity is 74.81148946074734
At time: 143.76844024658203 and batch: 250, loss is 4.307225914001465 and perplexity is 74.2342707879434
At time: 144.82967805862427 and batch: 300, loss is 4.327538242340088 and perplexity is 75.75756007199224
At time: 145.8873496055603 and batch: 350, loss is 4.344826450347901 and perplexity is 77.07865934393692
At time: 146.94458627700806 and batch: 400, loss is 4.300829191207885 and perplexity is 73.7609302640024
At time: 148.0020613670349 and batch: 450, loss is 4.319617290496826 and perplexity is 75.15985839505274
At time: 149.05974888801575 and batch: 500, loss is 4.323874225616455 and perplexity is 75.48049100776069
At time: 150.11650609970093 and batch: 550, loss is 4.2841385555267335 and perplexity is 72.54003058809168
At time: 151.17494106292725 and batch: 600, loss is 4.264142026901245 and perplexity is 71.10388857187698
At time: 152.2362401485443 and batch: 650, loss is 4.328238019943237 and perplexity is 75.8105920689376
At time: 153.29681134223938 and batch: 700, loss is 4.358686800003052 and perplexity is 78.15443460185992
At time: 154.36544227600098 and batch: 750, loss is 4.317266263961792 and perplexity is 74.9833631274209
At time: 155.43787336349487 and batch: 800, loss is 4.298312292098999 and perplexity is 73.57551487814054
At time: 156.51127886772156 and batch: 850, loss is 4.294192485809326 and perplexity is 73.27302154399645
At time: 157.58327436447144 and batch: 900, loss is 4.270904154777527 and perplexity is 71.58633149089421
At time: 158.6573932170868 and batch: 950, loss is 4.3535401821136475 and perplexity is 77.75323688184906
At time: 159.73189878463745 and batch: 1000, loss is 4.332125244140625 and perplexity is 76.10585834815691
At time: 160.80660605430603 and batch: 1050, loss is 4.272977352142334 and perplexity is 71.7348980353682
At time: 161.87946033477783 and batch: 1100, loss is 4.319718647003174 and perplexity is 75.16747672179423
At time: 162.96611261367798 and batch: 1150, loss is 4.27189914226532 and perplexity is 71.65759444201782
At time: 164.04043054580688 and batch: 1200, loss is 4.355077986717224 and perplexity is 77.87289815171312
At time: 165.13379406929016 and batch: 1250, loss is 4.3345176887512205 and perplexity is 76.28815537961945
At time: 166.20907354354858 and batch: 1300, loss is 4.336863470077515 and perplexity is 76.46732076918136
At time: 167.28482699394226 and batch: 1350, loss is 4.213317728042602 and perplexity is 67.58038160887888
At time: 168.38318157196045 and batch: 1400, loss is 4.244327912330627 and perplexity is 69.70889390851632
At time: 169.4569058418274 and batch: 1450, loss is 4.185115675926209 and perplexity is 65.70110051283882
At time: 170.53148412704468 and batch: 1500, loss is 4.184593601226807 and perplexity is 65.6668085827916
At time: 171.60618114471436 and batch: 1550, loss is 4.187376680374146 and perplexity is 65.84981905662136
At time: 172.6812343597412 and batch: 1600, loss is 4.271112251281738 and perplexity is 71.6012299063271
At time: 173.7563111782074 and batch: 1650, loss is 4.23045578956604 and perplexity is 68.74855991016379
At time: 174.8301477432251 and batch: 1700, loss is 4.253745303153992 and perplexity is 70.36847067776067
At time: 175.9164638519287 and batch: 1750, loss is 4.249259691238404 and perplexity is 70.05353190183568
At time: 177.00378966331482 and batch: 1800, loss is 4.223483061790466 and perplexity is 68.27086228014156
At time: 178.07885670661926 and batch: 1850, loss is 4.24558427810669 and perplexity is 69.79652881633231
At time: 179.1536259651184 and batch: 1900, loss is 4.328167657852173 and perplexity is 75.80525806481289
At time: 180.22818112373352 and batch: 1950, loss is 4.257218580245972 and perplexity is 70.61330481723458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3724115416061045 and perplexity of 79.23447873139462
finished 4 epochs...
Completing Train Step...
At time: 183.61519384384155 and batch: 50, loss is 4.235745830535889 and perplexity is 69.1132062553884
At time: 184.67292428016663 and batch: 100, loss is 4.1977117204666134 and perplexity is 66.53390853360936
At time: 185.71260714530945 and batch: 150, loss is 4.158372359275818 and perplexity is 63.967322004063426
At time: 186.7573835849762 and batch: 200, loss is 4.162984738349914 and perplexity is 64.26304501053592
At time: 187.80257439613342 and batch: 250, loss is 4.154039406776429 and perplexity is 63.69075424648602
At time: 188.8784420490265 and batch: 300, loss is 4.1732508134841915 and perplexity is 64.92617229218789
At time: 189.93657302856445 and batch: 350, loss is 4.1924490547180175 and perplexity is 66.1846825478692
At time: 190.98638319969177 and batch: 400, loss is 4.149928584098816 and perplexity is 63.429470263586474
At time: 192.06036925315857 and batch: 450, loss is 4.174728574752808 and perplexity is 65.02218860203953
At time: 193.1338665485382 and batch: 500, loss is 4.183993005752564 and perplexity is 65.62738123587705
At time: 194.2086145877838 and batch: 550, loss is 4.145253410339356 and perplexity is 63.13361858650753
At time: 195.28298330307007 and batch: 600, loss is 4.131283445358276 and perplexity is 62.25777613398623
At time: 196.38083291053772 and batch: 650, loss is 4.192789826393128 and perplexity is 66.20724025630342
At time: 197.45613479614258 and batch: 700, loss is 4.223734188079834 and perplexity is 68.28800904136907
At time: 198.53075766563416 and batch: 750, loss is 4.185617532730102 and perplexity is 65.73408133228659
At time: 199.60535383224487 and batch: 800, loss is 4.164443988800048 and perplexity is 64.35688934243355
At time: 200.68031978607178 and batch: 850, loss is 4.162239065170288 and perplexity is 64.21514364303252
At time: 201.75491452217102 and batch: 900, loss is 4.1358288335800175 and perplexity is 62.54140601196176
At time: 202.82984399795532 and batch: 950, loss is 4.222023138999939 and perplexity is 68.17126481236633
At time: 203.9037082195282 and batch: 1000, loss is 4.197961983680725 and perplexity is 66.5505616071453
At time: 204.97708582878113 and batch: 1050, loss is 4.141986393928528 and perplexity is 62.927696576959995
At time: 206.0517222881317 and batch: 1100, loss is 4.184764499664307 and perplexity is 65.67803189677012
At time: 207.12535166740417 and batch: 1150, loss is 4.142298483848572 and perplexity is 62.947338741654626
At time: 208.19962763786316 and batch: 1200, loss is 4.228135824203491 and perplexity is 68.5892505000572
At time: 209.2735722064972 and batch: 1250, loss is 4.210608186721802 and perplexity is 67.39751762307338
At time: 210.3472616672516 and batch: 1300, loss is 4.209449944496154 and perplexity is 67.31950016253893
At time: 211.42042565345764 and batch: 1350, loss is 4.086967144012451 and perplexity is 59.55898368854316
At time: 212.49114108085632 and batch: 1400, loss is 4.119663691520691 and perplexity is 61.53854285016449
At time: 213.56753540039062 and batch: 1450, loss is 4.05959921836853 and perplexity is 57.95108069544816
At time: 214.64214491844177 and batch: 1500, loss is 4.061262550354004 and perplexity is 58.04755279188133
At time: 215.7172269821167 and batch: 1550, loss is 4.066406397819519 and perplexity is 58.34690981255408
At time: 216.79276156425476 and batch: 1600, loss is 4.157148804664612 and perplexity is 63.88910235502343
At time: 217.8678240776062 and batch: 1650, loss is 4.111012907028198 and perplexity is 61.008482203829345
At time: 218.9430694580078 and batch: 1700, loss is 4.1358297109603885 and perplexity is 62.54146088458784
At time: 220.0377697944641 and batch: 1750, loss is 4.128724255561829 and perplexity is 62.098650371916804
At time: 221.11191940307617 and batch: 1800, loss is 4.102354779243469 and perplexity is 60.48254307853465
At time: 222.18638372421265 and batch: 1850, loss is 4.128259711265564 and perplexity is 62.06980949753129
At time: 223.260568857193 and batch: 1900, loss is 4.208666853904724 and perplexity is 67.26680353115289
At time: 224.33557868003845 and batch: 1950, loss is 4.140350623130798 and perplexity is 62.82484543191441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3496530932049415 and perplexity of 77.45158978150899
finished 5 epochs...
Completing Train Step...
At time: 227.69909167289734 and batch: 50, loss is 4.1185211563110355 and perplexity is 61.46827304871258
At time: 228.72328233718872 and batch: 100, loss is 4.086169319152832 and perplexity is 59.511485001079116
At time: 229.74800992012024 and batch: 150, loss is 4.049434957504272 and perplexity is 57.36503420407305
At time: 230.78131341934204 and batch: 200, loss is 4.055662698745728 and perplexity is 57.72340355091206
At time: 231.83161783218384 and batch: 250, loss is 4.047183742523194 and perplexity is 57.23603843276806
At time: 232.88752698898315 and batch: 300, loss is 4.064271283149719 and perplexity is 58.22246536833058
At time: 233.93524050712585 and batch: 350, loss is 4.082830381393433 and perplexity is 59.31311121984297
At time: 234.99321842193604 and batch: 400, loss is 4.040913391113281 and perplexity is 56.87827119384178
At time: 236.05034112930298 and batch: 450, loss is 4.067820091247558 and perplexity is 58.429452786985664
At time: 237.1111717224121 and batch: 500, loss is 4.077110300064087 and perplexity is 58.97480389490732
At time: 238.17309975624084 and batch: 550, loss is 4.041604251861572 and perplexity is 56.9175797356411
At time: 239.23509430885315 and batch: 600, loss is 4.034938559532166 and perplexity is 56.539446321571454
At time: 240.2973301410675 and batch: 650, loss is 4.089022936820984 and perplexity is 59.681550561775005
At time: 241.36330842971802 and batch: 700, loss is 4.1216900396347045 and perplexity is 61.663367787084006
At time: 242.46084308624268 and batch: 750, loss is 4.082924718856812 and perplexity is 59.31870693223907
At time: 243.52265810966492 and batch: 800, loss is 4.063252301216125 and perplexity is 58.1631679446235
At time: 244.58392548561096 and batch: 850, loss is 4.0634741735458375 and perplexity is 58.176074173913456
At time: 245.6446373462677 and batch: 900, loss is 4.03210720539093 and perplexity is 56.37958953845998
At time: 246.70562148094177 and batch: 950, loss is 4.128535432815552 and perplexity is 62.08692584117737
At time: 247.76633429527283 and batch: 1000, loss is 4.099571275711059 and perplexity is 60.3144237950836
At time: 248.82821202278137 and batch: 1050, loss is 4.045824904441833 and perplexity is 57.15831674167525
At time: 249.88860368728638 and batch: 1100, loss is 4.0850357246398925 and perplexity is 59.444061330996384
At time: 250.94995379447937 and batch: 1150, loss is 4.050325789451599 and perplexity is 57.41615957787869
At time: 252.0125117301941 and batch: 1200, loss is 4.131943168640137 and perplexity is 62.29886258973423
At time: 253.0752830505371 and batch: 1250, loss is 4.114090294837951 and perplexity is 61.19651814461433
At time: 254.13771224021912 and batch: 1300, loss is 4.120253548622132 and perplexity is 61.574852504377915
At time: 255.20013403892517 and batch: 1350, loss is 3.9926356840133668 and perplexity is 54.19754889119835
At time: 256.2621040344238 and batch: 1400, loss is 4.031967697143554 and perplexity is 56.37172466935552
At time: 257.3240900039673 and batch: 1450, loss is 3.9667263984680177 and perplexity is 52.81136419229364
At time: 258.386257648468 and batch: 1500, loss is 3.9666032695770266 and perplexity is 52.80486198790174
At time: 259.44679713249207 and batch: 1550, loss is 3.974972424507141 and perplexity is 53.24864852776287
At time: 260.5071077346802 and batch: 1600, loss is 4.0693653964996335 and perplexity is 58.519813927043806
At time: 261.5686676502228 and batch: 1650, loss is 4.015217394828796 and perplexity is 55.43534545007077
At time: 262.6315588951111 and batch: 1700, loss is 4.047456383705139 and perplexity is 57.25164546139895
At time: 263.6909444332123 and batch: 1750, loss is 4.043799352645874 and perplexity is 57.04265678770362
At time: 264.75232458114624 and batch: 1800, loss is 4.011853680610657 and perplexity is 55.249190052693756
At time: 265.8140664100647 and batch: 1850, loss is 4.038454113006591 and perplexity is 56.73856356711549
At time: 266.87499952316284 and batch: 1900, loss is 4.118910155296326 and perplexity is 61.49218879585518
At time: 267.93699622154236 and batch: 1950, loss is 4.052857303619385 and perplexity is 57.561693532221646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341836618822675 and perplexity of 76.84855130186052
finished 6 epochs...
Completing Train Step...
At time: 271.28206419944763 and batch: 50, loss is 4.034433484077454 and perplexity is 56.51089684543815
At time: 272.3112576007843 and batch: 100, loss is 3.996057057380676 and perplexity is 54.38329651634339
At time: 273.3646833896637 and batch: 150, loss is 3.9667517232894896 and perplexity is 52.812701647598836
At time: 274.39270758628845 and batch: 200, loss is 3.9714725017547607 and perplexity is 53.06260812467468
At time: 275.42386531829834 and batch: 250, loss is 3.9640060091018676 and perplexity is 52.66789195738487
At time: 276.4668426513672 and batch: 300, loss is 3.97600182056427 and perplexity is 53.30349069891934
At time: 277.5194444656372 and batch: 350, loss is 3.9972774600982666 and perplexity is 54.449706554456455
At time: 278.5754177570343 and batch: 400, loss is 3.955985779762268 and perplexity is 52.247172772424285
At time: 279.6323039531708 and batch: 450, loss is 3.985873203277588 and perplexity is 53.83227548012792
At time: 280.6891415119171 and batch: 500, loss is 4.002548894882202 and perplexity is 54.73749248753511
At time: 281.76928091049194 and batch: 550, loss is 3.966478590965271 and perplexity is 52.798278761417436
At time: 282.8249750137329 and batch: 600, loss is 3.9555145692825318 and perplexity is 52.22255915662961
At time: 283.8847060203552 and batch: 650, loss is 4.007917256355285 and perplexity is 55.03213329490612
At time: 284.9465124607086 and batch: 700, loss is 4.037974863052368 and perplexity is 56.71137812795384
At time: 286.0082149505615 and batch: 750, loss is 4.009229478836059 and perplexity is 55.10439509879328
At time: 287.0929627418518 and batch: 800, loss is 3.9860239171981813 and perplexity is 53.84038936484232
At time: 288.15400886535645 and batch: 850, loss is 3.9852082920074463 and perplexity is 53.79649369063964
At time: 289.2155282497406 and batch: 900, loss is 3.9560535621643065 and perplexity is 52.250714331320836
At time: 290.2956392765045 and batch: 950, loss is 4.051961579322815 and perplexity is 57.510157209387096
At time: 291.3636214733124 and batch: 1000, loss is 4.029770569801331 and perplexity is 56.24800477570685
At time: 292.42517375946045 and batch: 1050, loss is 3.975129475593567 and perplexity is 53.257011942589365
At time: 293.48776865005493 and batch: 1100, loss is 4.009005293846131 and perplexity is 55.09204290517298
At time: 294.58397221565247 and batch: 1150, loss is 3.9744164991378783 and perplexity is 53.219054479970474
At time: 295.6477689743042 and batch: 1200, loss is 4.055507316589355 and perplexity is 57.714435060784865
At time: 296.7090308666229 and batch: 1250, loss is 4.040165410041809 and perplexity is 56.83574323064928
At time: 297.7711455821991 and batch: 1300, loss is 4.044525861740112 and perplexity is 57.084113854263855
At time: 298.8338644504547 and batch: 1350, loss is 3.919435305595398 and perplexity is 50.37199196323861
At time: 299.8954653739929 and batch: 1400, loss is 3.955861372947693 and perplexity is 52.24067327238853
At time: 300.9593417644501 and batch: 1450, loss is 3.8909249687194825 and perplexity is 48.95614849353456
At time: 302.02118468284607 and batch: 1500, loss is 3.8927755546569824 and perplexity is 49.0468299345111
At time: 303.08202600479126 and batch: 1550, loss is 3.8994041109085082 and perplexity is 49.373019494278196
At time: 304.1431484222412 and batch: 1600, loss is 3.9958561420440675 and perplexity is 54.37237117558893
At time: 305.2045922279358 and batch: 1650, loss is 3.941954321861267 and perplexity is 51.51918805455561
At time: 306.2662019729614 and batch: 1700, loss is 3.974943299293518 and perplexity is 53.24709767208397
At time: 307.32881140708923 and batch: 1750, loss is 3.973213109970093 and perplexity is 53.155049765303666
At time: 308.3906099796295 and batch: 1800, loss is 3.9389258146286013 and perplexity is 51.36339784587198
At time: 309.4522936344147 and batch: 1850, loss is 3.964557409286499 and perplexity is 52.69694105083605
At time: 310.51470828056335 and batch: 1900, loss is 4.045958781242371 and perplexity is 57.165969426491806
At time: 311.5756528377533 and batch: 1950, loss is 3.9801160764694212 and perplexity is 53.52324665642962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34066048555596 and perplexity of 76.75822029523933
finished 7 epochs...
Completing Train Step...
At time: 314.92572927474976 and batch: 50, loss is 3.965865874290466 and perplexity is 52.76593828440587
At time: 315.96529245376587 and batch: 100, loss is 3.928647365570068 and perplexity is 50.83816568770163
At time: 317.0050699710846 and batch: 150, loss is 3.8997607612609864 and perplexity is 49.39063153956813
At time: 318.0453805923462 and batch: 200, loss is 3.901290225982666 and perplexity is 49.466230566374456
At time: 319.0842032432556 and batch: 250, loss is 3.8951464700698852 and perplexity is 49.163253780565185
At time: 320.12220287323 and batch: 300, loss is 3.906262264251709 and perplexity is 49.71279100380282
At time: 321.17548632621765 and batch: 350, loss is 3.9299313974380494 and perplexity is 50.90348543990147
At time: 322.2147216796875 and batch: 400, loss is 3.883786468505859 and perplexity is 48.60791941249889
At time: 323.2551460266113 and batch: 450, loss is 3.9208548736572264 and perplexity is 50.44354921241638
At time: 324.2967712879181 and batch: 500, loss is 3.9402447319030762 and perplexity is 51.43118661262759
At time: 325.3367040157318 and batch: 550, loss is 3.9000007915496826 and perplexity is 49.40248821003856
At time: 326.37703680992126 and batch: 600, loss is 3.8945816802978515 and perplexity is 49.135494717425395
At time: 327.4213447570801 and batch: 650, loss is 3.939798970222473 and perplexity is 51.408265669466346
At time: 328.4676377773285 and batch: 700, loss is 3.9746829223632814 and perplexity is 53.233235161065444
At time: 329.51402592658997 and batch: 750, loss is 3.9469850873947143 and perplexity is 51.77902204406841
At time: 330.56064534187317 and batch: 800, loss is 3.923017563819885 and perplexity is 50.55276103316547
At time: 331.60713624954224 and batch: 850, loss is 3.924944806098938 and perplexity is 50.65028239501226
At time: 332.6533191204071 and batch: 900, loss is 3.896166033744812 and perplexity is 49.21340440979663
At time: 333.6996672153473 and batch: 950, loss is 3.9871609210968018 and perplexity is 53.9016409124789
At time: 334.746212720871 and batch: 1000, loss is 3.9644281911849975 and perplexity is 52.690132092088355
At time: 335.7920525074005 and batch: 1050, loss is 3.91686806678772 and perplexity is 50.242840882417056
At time: 336.83989810943604 and batch: 1100, loss is 3.949030833244324 and perplexity is 51.88505718700827
At time: 337.89714550971985 and batch: 1150, loss is 3.9126528024673464 and perplexity is 50.03149977014982
At time: 338.959570646286 and batch: 1200, loss is 3.9927306461334227 and perplexity is 54.20269584972207
At time: 340.0203547477722 and batch: 1250, loss is 3.980974850654602 and perplexity is 53.56923078112876
At time: 341.1022906303406 and batch: 1300, loss is 3.98524423122406 and perplexity is 53.79842712922238
At time: 342.1735816001892 and batch: 1350, loss is 3.8577813863754273 and perplexity is 47.36016082534577
At time: 343.23488879203796 and batch: 1400, loss is 3.895041193962097 and perplexity is 49.158078336991025
At time: 344.29771876335144 and batch: 1450, loss is 3.827939734458923 and perplexity is 45.967734867545026
At time: 345.35963797569275 and batch: 1500, loss is 3.834843535423279 and perplexity is 46.286184953014335
At time: 346.4338254928589 and batch: 1550, loss is 3.8402365970611574 and perplexity is 46.53648353261877
At time: 347.50958609580994 and batch: 1600, loss is 3.9368067836761473 and perplexity is 51.25467245293391
At time: 348.57135701179504 and batch: 1650, loss is 3.8839507627487184 and perplexity is 48.615906069878676
At time: 349.632794380188 and batch: 1700, loss is 3.9205504274368286 and perplexity is 50.428194202021245
At time: 350.7207987308502 and batch: 1750, loss is 3.9162468671798707 and perplexity is 50.21163974143529
At time: 351.7822263240814 and batch: 1800, loss is 3.87845543384552 and perplexity is 48.34947840041311
At time: 352.8436713218689 and batch: 1850, loss is 3.9103037834167482 and perplexity is 49.914112750210194
At time: 353.90551805496216 and batch: 1900, loss is 3.98557427406311 and perplexity is 53.816185845255866
At time: 354.9668118953705 and batch: 1950, loss is 3.9234097099304197 and perplexity is 50.572588989255244
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344641681050145 and perplexity of 77.06441888981789
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 358.33842039108276 and batch: 50, loss is 3.936500520706177 and perplexity is 51.23897744824567
At time: 359.3809976577759 and batch: 100, loss is 3.9309676265716553 and perplexity is 50.956260453297226
At time: 360.4231045246124 and batch: 150, loss is 3.9016480255126953 and perplexity is 49.483932727146986
At time: 361.4795162677765 and batch: 200, loss is 3.905063662528992 and perplexity is 49.653240862444974
At time: 362.50874972343445 and batch: 250, loss is 3.897859573364258 and perplexity is 49.29681987373213
At time: 363.53610467910767 and batch: 300, loss is 3.900680298805237 and perplexity is 49.43606896711165
At time: 364.5660605430603 and batch: 350, loss is 3.9214073848724365 and perplexity is 50.471427539926346
At time: 365.611380815506 and batch: 400, loss is 3.8701231384277346 and perplexity is 47.948289994354944
At time: 366.6561498641968 and batch: 450, loss is 3.900530858039856 and perplexity is 49.428681755116834
At time: 367.70330691337585 and batch: 500, loss is 3.9146184587478636 and perplexity is 50.12994122122846
At time: 368.75010776519775 and batch: 550, loss is 3.8715502405166626 and perplexity is 48.016765948633484
At time: 369.7969355583191 and batch: 600, loss is 3.8523304319381713 and perplexity is 47.10270507381083
At time: 370.84267830848694 and batch: 650, loss is 3.8840502643585206 and perplexity is 48.620743671465206
At time: 371.89778900146484 and batch: 700, loss is 3.9134015941619875 and perplexity is 50.06897697120551
At time: 372.95525074005127 and batch: 750, loss is 3.8783413553237915 and perplexity is 48.343963077986736
At time: 374.0290741920471 and batch: 800, loss is 3.8508510208129882 and perplexity is 47.033072328327776
At time: 375.11738204956055 and batch: 850, loss is 3.849488821029663 and perplexity is 46.969047504593824
At time: 376.1739435195923 and batch: 900, loss is 3.8100018453598024 and perplexity is 45.150522185200536
At time: 377.2316110134125 and batch: 950, loss is 3.9046192502975465 and perplexity is 49.631179257461454
At time: 378.2886571884155 and batch: 1000, loss is 3.8738426065444944 and perplexity is 48.1269642107796
At time: 379.3458788394928 and batch: 1050, loss is 3.8220989656448365 and perplexity is 45.700030515941954
At time: 380.40247082710266 and batch: 1100, loss is 3.840638976097107 and perplexity is 46.555212605839614
At time: 381.4843671321869 and batch: 1150, loss is 3.809685354232788 and perplexity is 45.136234706598216
At time: 382.54630398750305 and batch: 1200, loss is 3.869180498123169 and perplexity is 47.903113299703094
At time: 383.6089074611664 and batch: 1250, loss is 3.844428071975708 and perplexity is 46.731949394916896
At time: 384.6940677165985 and batch: 1300, loss is 3.850999083518982 and perplexity is 47.04003668785614
At time: 385.75646924972534 and batch: 1350, loss is 3.721889624595642 and perplexity is 41.342442040064455
At time: 386.8175194263458 and batch: 1400, loss is 3.749072313308716 and perplexity is 42.48165404941251
At time: 387.87877130508423 and batch: 1450, loss is 3.6797209405899047 and perplexity is 39.63533191680142
At time: 388.96485137939453 and batch: 1500, loss is 3.679693174362183 and perplexity is 39.634231408428136
At time: 390.02803206443787 and batch: 1550, loss is 3.6756789255142213 and perplexity is 39.47544865062959
At time: 391.0909309387207 and batch: 1600, loss is 3.7620621395111082 and perplexity is 43.037083005074955
At time: 392.1540160179138 and batch: 1650, loss is 3.7038222312927247 and perplexity is 40.602199145770015
At time: 393.2170464992523 and batch: 1700, loss is 3.7253428411483767 and perplexity is 41.48545322743359
At time: 394.29388523101807 and batch: 1750, loss is 3.710054316520691 and perplexity is 40.85602562388406
At time: 395.3566617965698 and batch: 1800, loss is 3.667287974357605 and perplexity is 39.145597905207225
At time: 396.4189279079437 and batch: 1850, loss is 3.6840718173980713 and perplexity is 39.80815605886616
At time: 397.4810321331024 and batch: 1900, loss is 3.756684513092041 and perplexity is 42.80626682833717
At time: 398.5428171157837 and batch: 1950, loss is 3.69247492313385 and perplexity is 40.14407761889179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2813019508539245 and perplexity of 72.33455476297972
finished 9 epochs...
Completing Train Step...
At time: 401.87724232673645 and batch: 50, loss is 3.852808518409729 and perplexity is 47.12522962379268
At time: 402.942684173584 and batch: 100, loss is 3.830248031616211 and perplexity is 46.07396461701301
At time: 403.97778153419495 and batch: 150, loss is 3.7965591239929197 and perplexity is 44.54763757953036
At time: 405.0221128463745 and batch: 200, loss is 3.8011212491989137 and perplexity is 44.75133377026877
At time: 406.05409121513367 and batch: 250, loss is 3.791615810394287 and perplexity is 44.32796803195401
At time: 407.1114091873169 and batch: 300, loss is 3.796599349975586 and perplexity is 44.54942958806986
At time: 408.1617558002472 and batch: 350, loss is 3.8174714469909667 and perplexity is 45.48904132695972
At time: 409.20172023773193 and batch: 400, loss is 3.768366131782532 and perplexity is 43.30924539721412
At time: 410.2408437728882 and batch: 450, loss is 3.809090156555176 and perplexity is 45.1093777179262
At time: 411.28023409843445 and batch: 500, loss is 3.8228938150405884 and perplexity is 45.73636959771878
At time: 412.32582664489746 and batch: 550, loss is 3.7835774850845336 and perplexity is 43.973073693610345
At time: 413.3943281173706 and batch: 600, loss is 3.768864994049072 and perplexity is 43.33085613547788
At time: 414.4431471824646 and batch: 650, loss is 3.7996573400497438 and perplexity is 44.68586981165983
At time: 415.5000321865082 and batch: 700, loss is 3.83620171546936 and perplexity is 46.34909263613649
At time: 416.55642342567444 and batch: 750, loss is 3.8024007272720337 and perplexity is 44.80862876660016
At time: 417.61052560806274 and batch: 800, loss is 3.7754919862747194 and perplexity is 43.61896296869143
At time: 418.671514749527 and batch: 850, loss is 3.778814606666565 and perplexity is 43.76413326385957
At time: 419.7280650138855 and batch: 900, loss is 3.7397116518020628 and perplexity is 42.08585303533987
At time: 420.7859408855438 and batch: 950, loss is 3.835484714508057 and perplexity is 46.31587220312524
At time: 421.86428594589233 and batch: 1000, loss is 3.8086307716369627 and perplexity is 45.088659909221384
At time: 422.9223392009735 and batch: 1050, loss is 3.7584325313568114 and perplexity is 42.88115840144888
At time: 423.9792551994324 and batch: 1100, loss is 3.7796489238739013 and perplexity is 43.80066166932548
At time: 425.03623628616333 and batch: 1150, loss is 3.7516836643218996 and perplexity is 42.592733530391435
At time: 426.0927150249481 and batch: 1200, loss is 3.812283606529236 and perplexity is 45.25366251955791
At time: 427.19193625450134 and batch: 1250, loss is 3.7923667192459107 and perplexity is 44.36126679612742
At time: 428.2467656135559 and batch: 1300, loss is 3.8020539712905883 and perplexity is 44.793093800131906
At time: 429.3049292564392 and batch: 1350, loss is 3.673973593711853 and perplexity is 39.40818728041032
At time: 430.3625509738922 and batch: 1400, loss is 3.7035880374908445 and perplexity is 40.59269147574952
At time: 431.41990756988525 and batch: 1450, loss is 3.6363528633117674 and perplexity is 37.953163623748544
At time: 432.4775450229645 and batch: 1500, loss is 3.6375076484680178 and perplexity is 37.997016689295286
At time: 433.5350093841553 and batch: 1550, loss is 3.637095236778259 and perplexity is 37.98134950632343
At time: 434.59320640563965 and batch: 1600, loss is 3.7278487920761108 and perplexity is 41.58954410628115
At time: 435.6506927013397 and batch: 1650, loss is 3.672623438835144 and perplexity is 39.35501602696221
At time: 436.7082233428955 and batch: 1700, loss is 3.6986646127700804 and perplexity is 40.39332759430336
At time: 437.7658178806305 and batch: 1750, loss is 3.686079730987549 and perplexity is 39.888167697735284
At time: 438.82223868370056 and batch: 1800, loss is 3.646997194290161 and perplexity is 38.35930738863889
At time: 439.8788330554962 and batch: 1850, loss is 3.666964430809021 and perplexity is 39.13293464821756
At time: 440.9369134902954 and batch: 1900, loss is 3.7439978456497194 and perplexity is 42.266628301852215
At time: 441.9935245513916 and batch: 1950, loss is 3.682237453460693 and perplexity is 39.73520034709893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284138524255087 and perplexity of 72.54002831964551
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 445.34088492393494 and batch: 50, loss is 3.83173668384552 and perplexity is 46.14260380441704
At time: 446.3809678554535 and batch: 100, loss is 3.8335231590270995 and perplexity is 46.22511009670565
At time: 447.41064286231995 and batch: 150, loss is 3.8128570747375488 and perplexity is 45.27962149893587
At time: 448.4416172504425 and batch: 200, loss is 3.828209571838379 and perplexity is 45.98014035431795
At time: 449.47675943374634 and batch: 250, loss is 3.825690145492554 and perplexity is 45.864442584528604
At time: 450.51556491851807 and batch: 300, loss is 3.8307851266860964 and perplexity is 46.09871736295274
At time: 451.55519366264343 and batch: 350, loss is 3.8556593465805054 and perplexity is 47.259767236648806
At time: 452.6087522506714 and batch: 400, loss is 3.8029940605163572 and perplexity is 44.83522310455215
At time: 453.65146565437317 and batch: 450, loss is 3.842338652610779 and perplexity is 46.63440869209286
At time: 454.69799041748047 and batch: 500, loss is 3.863808889389038 and perplexity is 47.646486384662445
At time: 455.73680329322815 and batch: 550, loss is 3.827137212753296 and perplexity is 45.93085956115129
At time: 456.7757227420807 and batch: 600, loss is 3.7951467084884642 and perplexity is 44.48476221904576
At time: 457.81454706192017 and batch: 650, loss is 3.8227305746078493 and perplexity is 45.728904182299125
At time: 458.85416173934937 and batch: 700, loss is 3.8497267055511473 and perplexity is 46.9802220430562
At time: 459.8962399959564 and batch: 750, loss is 3.8116665172576902 and perplexity is 45.22574558442541
At time: 460.943302154541 and batch: 800, loss is 3.7808726453781127 and perplexity is 43.85429428991161
At time: 461.99051094055176 and batch: 850, loss is 3.782652564048767 and perplexity is 43.93242087596504
At time: 463.03965735435486 and batch: 900, loss is 3.746263608932495 and perplexity is 42.362503050071524
At time: 464.1169126033783 and batch: 950, loss is 3.843214874267578 and perplexity is 46.675288678289995
At time: 465.16496872901917 and batch: 1000, loss is 3.803732886314392 and perplexity is 44.86836076401391
At time: 466.2118170261383 and batch: 1050, loss is 3.7512607336044312 and perplexity is 42.574723563792986
At time: 467.25921154022217 and batch: 1100, loss is 3.7649693965911863 and perplexity is 43.16238492353636
At time: 468.3279666900635 and batch: 1150, loss is 3.741122770309448 and perplexity is 42.14528308301552
At time: 469.3747835159302 and batch: 1200, loss is 3.798669013977051 and perplexity is 44.64172741857615
At time: 470.42152214050293 and batch: 1250, loss is 3.7669050693511963 and perplexity is 43.24601408952717
At time: 471.46892952919006 and batch: 1300, loss is 3.776134519577026 and perplexity is 43.646998610963266
At time: 472.5176348686218 and batch: 1350, loss is 3.6466176509857178 and perplexity is 38.34475113289589
At time: 473.5752832889557 and batch: 1400, loss is 3.67663631439209 and perplexity is 39.51326010336058
At time: 474.64933133125305 and batch: 1450, loss is 3.6061511278152465 and perplexity is 36.824048655594616
At time: 475.70666694641113 and batch: 1500, loss is 3.607607822418213 and perplexity is 36.87772913707211
At time: 476.7642798423767 and batch: 1550, loss is 3.6072000074386597 and perplexity is 36.86269291292522
At time: 477.8211500644684 and batch: 1600, loss is 3.690736393928528 and perplexity is 40.074346599800634
At time: 478.87934708595276 and batch: 1650, loss is 3.6328476810455324 and perplexity is 37.82036374752088
At time: 479.93745493888855 and batch: 1700, loss is 3.6556071138381956 and perplexity is 38.69100382993839
At time: 480.99642968177795 and batch: 1750, loss is 3.634320659637451 and perplexity is 37.8761133825892
At time: 482.0753653049469 and batch: 1800, loss is 3.5949645376205446 and perplexity is 36.414408623405514
At time: 483.1349687576294 and batch: 1850, loss is 3.606895327568054 and perplexity is 36.85146330322323
At time: 484.19281697273254 and batch: 1900, loss is 3.6882181406021117 and perplexity is 39.97355620431045
At time: 485.24958062171936 and batch: 1950, loss is 3.6273408937454223 and perplexity is 37.6126674432962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259492244276889 and perplexity of 70.77403840634845
finished 11 epochs...
Completing Train Step...
At time: 488.61892223358154 and batch: 50, loss is 3.8272493839263917 and perplexity is 45.93601196851995
At time: 489.643652677536 and batch: 100, loss is 3.8058739471435548 and perplexity is 44.964529568607105
At time: 490.6679379940033 and batch: 150, loss is 3.771951823234558 and perplexity is 43.46481773875108
At time: 491.6973536014557 and batch: 200, loss is 3.7781891059875488 and perplexity is 43.736767328384325
At time: 492.7337348461151 and batch: 250, loss is 3.7737847852706907 and perplexity is 43.54456015966253
At time: 493.77307772636414 and batch: 300, loss is 3.777865991592407 and perplexity is 43.72263763214062
At time: 494.8141007423401 and batch: 350, loss is 3.8045711946487426 and perplexity is 44.905990055061466
At time: 495.8538374900818 and batch: 400, loss is 3.75367609500885 and perplexity is 42.677681197786185
At time: 496.89464950561523 and batch: 450, loss is 3.79528431892395 and perplexity is 44.49088420776231
At time: 497.934072971344 and batch: 500, loss is 3.815773377418518 and perplexity is 45.411863315363966
At time: 498.9735448360443 and batch: 550, loss is 3.7804796266555787 and perplexity is 43.83706211769712
At time: 500.0126211643219 and batch: 600, loss is 3.7527964305877686 and perplexity is 42.640155667419
At time: 501.0521275997162 and batch: 650, loss is 3.780528826713562 and perplexity is 43.839218956753
At time: 502.1159851551056 and batch: 700, loss is 3.811050329208374 and perplexity is 45.197886604541594
At time: 503.1551115512848 and batch: 750, loss is 3.776839575767517 and perplexity is 43.67778304863419
At time: 504.1939673423767 and batch: 800, loss is 3.7474901819229127 and perplexity is 42.41449563194906
At time: 505.25593876838684 and batch: 850, loss is 3.750774927139282 and perplexity is 42.55404551100631
At time: 506.30797839164734 and batch: 900, loss is 3.714762358665466 and perplexity is 41.048831026231184
At time: 507.37275433540344 and batch: 950, loss is 3.8117655181884764 and perplexity is 45.230223196974016
At time: 508.41934299468994 and batch: 1000, loss is 3.7751982975006104 and perplexity is 43.60615444988041
At time: 509.4662787914276 and batch: 1050, loss is 3.72533326625824 and perplexity is 41.48505601067832
At time: 510.51382756233215 and batch: 1100, loss is 3.7398914241790773 and perplexity is 42.09341958928703
At time: 511.57582330703735 and batch: 1150, loss is 3.7178344106674195 and perplexity is 41.17512906751027
At time: 512.6327674388885 and batch: 1200, loss is 3.7757545280456544 and perplexity is 43.630416271895044
At time: 513.6794717311859 and batch: 1250, loss is 3.7480375623703 and perplexity is 42.43771885293248
At time: 514.7269387245178 and batch: 1300, loss is 3.7601039457321166 and perplexity is 42.95289051637544
At time: 515.7732348442078 and batch: 1350, loss is 3.6318038415908815 and perplexity is 37.780905957033994
At time: 516.8199334144592 and batch: 1400, loss is 3.6644674921035767 and perplexity is 39.03534399867592
At time: 517.8666305541992 and batch: 1450, loss is 3.5949645900726317 and perplexity is 36.414410533417296
At time: 518.9433755874634 and batch: 1500, loss is 3.598291826248169 and perplexity is 36.53577166406637
At time: 519.9883437156677 and batch: 1550, loss is 3.60037672996521 and perplexity is 36.61202469270361
At time: 521.0311348438263 and batch: 1600, loss is 3.6857537698745726 and perplexity is 39.87516782503953
At time: 522.0789983272552 and batch: 1650, loss is 3.629270462989807 and perplexity is 37.68531375509858
At time: 523.1259059906006 and batch: 1700, loss is 3.6547852659225466 and perplexity is 38.65921877211721
At time: 524.176108121872 and batch: 1750, loss is 3.6353581094741823 and perplexity is 37.915428340356
At time: 525.2264387607574 and batch: 1800, loss is 3.5979075384140016 and perplexity is 36.52173410890753
At time: 526.2759490013123 and batch: 1850, loss is 3.6112669849395753 and perplexity is 37.01291792944245
At time: 527.3283321857452 and batch: 1900, loss is 3.693516707420349 and perplexity is 40.18592088019279
At time: 528.3781366348267 and batch: 1950, loss is 3.632164812088013 and perplexity is 37.79454621115592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258782533157704 and perplexity of 70.72382710420911
finished 12 epochs...
Completing Train Step...
At time: 531.7385623455048 and batch: 50, loss is 3.810536503791809 and perplexity is 45.174668747102615
At time: 532.7680423259735 and batch: 100, loss is 3.7868974351882936 and perplexity is 44.119304709706626
At time: 533.7956733703613 and batch: 150, loss is 3.7524068546295166 and perplexity is 42.62354732323071
At time: 534.8285801410675 and batch: 200, loss is 3.7570564556121826 and perplexity is 42.82219126040226
At time: 535.8735013008118 and batch: 250, loss is 3.7520392036437986 and perplexity is 42.60787961434331
At time: 536.9180371761322 and batch: 300, loss is 3.7557963371276855 and perplexity is 42.768264210020746
At time: 537.9645025730133 and batch: 350, loss is 3.7832400894165037 and perplexity is 43.95823987161052
At time: 539.011029958725 and batch: 400, loss is 3.731948528289795 and perplexity is 41.76040025963378
At time: 540.0583455562592 and batch: 450, loss is 3.774328284263611 and perplexity is 43.56823301676073
At time: 541.1156644821167 and batch: 500, loss is 3.7948271512985228 and perplexity is 44.47054906451464
At time: 542.1672420501709 and batch: 550, loss is 3.7593183374404906 and perplexity is 42.91915962080693
At time: 543.2240419387817 and batch: 600, loss is 3.7330425453186034 and perplexity is 41.80611184871686
At time: 544.2816059589386 and batch: 650, loss is 3.760861539840698 and perplexity is 42.98544370267128
At time: 545.3396379947662 and batch: 700, loss is 3.7922666263580322 and perplexity is 44.35682677103502
At time: 546.3966083526611 and batch: 750, loss is 3.759466972351074 and perplexity is 42.925539380375234
At time: 547.4538114070892 and batch: 800, loss is 3.730574359893799 and perplexity is 41.703053848230056
At time: 548.5117681026459 and batch: 850, loss is 3.7346641635894775 and perplexity is 41.87396040088273
At time: 549.5686690807343 and batch: 900, loss is 3.6986028003692626 and perplexity is 40.390830862913006
At time: 550.6271696090698 and batch: 950, loss is 3.7956634330749512 and perplexity is 44.507754529242774
At time: 551.6841235160828 and batch: 1000, loss is 3.7604428339004516 and perplexity is 42.967449209512324
At time: 552.7416617870331 and batch: 1050, loss is 3.7113932085037233 and perplexity is 40.91076406530348
At time: 553.7996029853821 and batch: 1100, loss is 3.726077604293823 and perplexity is 41.51594641079903
At time: 554.8592789173126 and batch: 1150, loss is 3.7047352743148805 and perplexity is 40.63928762949831
At time: 555.9196105003357 and batch: 1200, loss is 3.762467360496521 and perplexity is 43.054526068168485
At time: 556.9784669876099 and batch: 1250, loss is 3.7366663932800295 and perplexity is 41.957885678462155
At time: 558.0373165607452 and batch: 1300, loss is 3.7497572994232176 and perplexity is 42.510763361156414
At time: 559.0951247215271 and batch: 1350, loss is 3.6220834016799928 and perplexity is 37.41543806290955
At time: 560.1531364917755 and batch: 1400, loss is 3.655707769393921 and perplexity is 38.694898490436785
At time: 561.2109882831573 and batch: 1450, loss is 3.586372094154358 and perplexity is 36.102860273546916
At time: 562.2719078063965 and batch: 1500, loss is 3.590337009429932 and perplexity is 36.246289209628756
At time: 563.3369669914246 and batch: 1550, loss is 3.5934290313720703 and perplexity is 36.35853697803781
At time: 564.3947420120239 and batch: 1600, loss is 3.6797198963165285 and perplexity is 39.635290526701155
At time: 565.4511110782623 and batch: 1650, loss is 3.623588981628418 and perplexity is 37.471812423623184
At time: 566.5098884105682 and batch: 1700, loss is 3.6502804279327394 and perplexity is 38.48545693305703
At time: 567.5676190853119 and batch: 1750, loss is 3.6316616201400755 and perplexity is 37.775533083853986
At time: 568.6241912841797 and batch: 1800, loss is 3.59524112701416 and perplexity is 36.42448185561591
At time: 569.682436466217 and batch: 1850, loss is 3.6092278146743775 and perplexity is 36.93751918933397
At time: 570.7403230667114 and batch: 1900, loss is 3.6918516874313356 and perplexity is 40.1190661912921
At time: 571.7942996025085 and batch: 1950, loss is 3.6301833248138426 and perplexity is 37.719730946032236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2599237486373545 and perplexity of 70.80458430239823
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 575.1673154830933 and batch: 50, loss is 3.8073790454864502 and perplexity is 45.032256562657864
At time: 576.1943809986115 and batch: 100, loss is 3.8006827068328857 and perplexity is 44.731712717120246
At time: 577.2212324142456 and batch: 150, loss is 3.7698100566864015 and perplexity is 43.37182586508605
At time: 578.2485055923462 and batch: 200, loss is 3.77670289516449 and perplexity is 43.67181355087478
At time: 579.2745544910431 and batch: 250, loss is 3.773373370170593 and perplexity is 43.526648954808444
At time: 580.3019316196442 and batch: 300, loss is 3.7777380418777464 and perplexity is 43.717043691010595
At time: 581.3280894756317 and batch: 350, loss is 3.8129386472702027 and perplexity is 45.28331522299031
At time: 582.3569617271423 and batch: 400, loss is 3.7687679290771485 and perplexity is 43.32665043126025
At time: 583.394451379776 and batch: 450, loss is 3.8134840297698975 and perplexity is 45.3080186864471
At time: 584.4192097187042 and batch: 500, loss is 3.8349600267410278 and perplexity is 46.2915772057623
At time: 585.4522089958191 and batch: 550, loss is 3.8017008543014525 and perplexity is 44.777279390047894
At time: 586.490070104599 and batch: 600, loss is 3.7657680177688597 and perplexity is 43.196869086273686
At time: 587.5283744335175 and batch: 650, loss is 3.7913401699066163 and perplexity is 44.315751133041566
At time: 588.5659351348877 and batch: 700, loss is 3.819317560195923 and perplexity is 45.57309681093098
At time: 589.6036341190338 and batch: 750, loss is 3.785568799972534 and perplexity is 44.06072517181037
At time: 590.6412992477417 and batch: 800, loss is 3.753679838180542 and perplexity is 42.677840947973294
At time: 591.6793804168701 and batch: 850, loss is 3.7509588289260862 and perplexity is 42.561871995641724
At time: 592.7202208042145 and batch: 900, loss is 3.713418493270874 and perplexity is 40.99370397269285
At time: 593.7659363746643 and batch: 950, loss is 3.818298535346985 and perplexity is 45.52668034661947
At time: 594.8133594989777 and batch: 1000, loss is 3.782632713317871 and perplexity is 43.93154879395639
At time: 595.8610796928406 and batch: 1050, loss is 3.7337463426589967 and perplexity is 41.83554523540287
At time: 596.9069383144379 and batch: 1100, loss is 3.7408608055114745 and perplexity is 42.1342439484426
At time: 597.9528341293335 and batch: 1150, loss is 3.7209931421279907 and perplexity is 41.305395873706075
At time: 599.0000910758972 and batch: 1200, loss is 3.7763919687271117 and perplexity is 43.65823694024653
At time: 600.0459446907043 and batch: 1250, loss is 3.74438805103302 and perplexity is 42.283124185931634
At time: 601.1105799674988 and batch: 1300, loss is 3.749885926246643 and perplexity is 42.51623173729133
At time: 602.1616077423096 and batch: 1350, loss is 3.6185966205596922 and perplexity is 37.285205797509235
At time: 603.2071027755737 and batch: 1400, loss is 3.6503894758224487 and perplexity is 38.489653919752186
At time: 604.2534697055817 and batch: 1450, loss is 3.5743914222717286 and perplexity is 35.67290447311983
At time: 605.3001697063446 and batch: 1500, loss is 3.576810278892517 and perplexity is 35.75929655719729
At time: 606.3475227355957 and batch: 1550, loss is 3.5789729261398318 and perplexity is 35.836714985664116
At time: 607.3943102359772 and batch: 1600, loss is 3.670254416465759 and perplexity is 39.261893461919065
At time: 608.4411265850067 and batch: 1650, loss is 3.6088924646377563 and perplexity is 36.92513426767916
At time: 609.4880540370941 and batch: 1700, loss is 3.6351667404174806 and perplexity is 37.90817319482739
At time: 610.5352551937103 and batch: 1750, loss is 3.6143895387649536 and perplexity is 37.12867339018522
At time: 611.5817313194275 and batch: 1800, loss is 3.581016221046448 and perplexity is 35.910014823954725
At time: 612.6286251544952 and batch: 1850, loss is 3.5932017517089845 and perplexity is 36.35027436100113
At time: 613.6750509738922 and batch: 1900, loss is 3.6762306976318357 and perplexity is 39.49723611282963
At time: 614.7238042354584 and batch: 1950, loss is 3.6196025371551515 and perplexity is 37.322730474969795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246262945130814 and perplexity of 69.84391349622942
finished 14 epochs...
Completing Train Step...
At time: 618.065970659256 and batch: 50, loss is 3.8118609857559203 and perplexity is 45.23454142247954
At time: 619.105078458786 and batch: 100, loss is 3.7937079858779907 and perplexity is 44.42080700375869
At time: 620.1258726119995 and batch: 150, loss is 3.757106719017029 and perplexity is 42.824343703632096
At time: 621.1539621353149 and batch: 200, loss is 3.759867687225342 and perplexity is 42.94274372927996
At time: 622.1833024024963 and batch: 250, loss is 3.751498064994812 and perplexity is 42.58482908126228
At time: 623.2109825611115 and batch: 300, loss is 3.7546840858459474 and perplexity is 42.720721597902326
At time: 624.2475242614746 and batch: 350, loss is 3.7892375707626345 and perplexity is 44.222670762290015
At time: 625.2852234840393 and batch: 400, loss is 3.7431543684005737 and perplexity is 42.230992393633194
At time: 626.3212430477142 and batch: 450, loss is 3.789268774986267 and perplexity is 44.22405071792822
At time: 627.3596949577332 and batch: 500, loss is 3.809301218986511 and perplexity is 45.118899617685685
At time: 628.3976125717163 and batch: 550, loss is 3.7764789724349974 and perplexity is 43.662035533983556
At time: 629.4353787899017 and batch: 600, loss is 3.743748178482056 and perplexity is 42.25607702968533
At time: 630.4732413291931 and batch: 650, loss is 3.770057911872864 and perplexity is 43.38257712939633
At time: 631.5108213424683 and batch: 700, loss is 3.8010302686691286 and perplexity is 44.74726245542176
At time: 632.5511269569397 and batch: 750, loss is 3.7678771877288817 and perplexity is 43.2880747752557
At time: 633.5976254940033 and batch: 800, loss is 3.7371880769729615 and perplexity is 41.97978013370409
At time: 634.6431140899658 and batch: 850, loss is 3.735804171562195 and perplexity is 41.9217242700119
At time: 635.7255833148956 and batch: 900, loss is 3.6990664863586424 and perplexity is 40.40956386806393
At time: 636.7714745998383 and batch: 950, loss is 3.803401131629944 and perplexity is 44.85347794400605
At time: 637.8209261894226 and batch: 1000, loss is 3.7682891035079957 and perplexity is 43.30590948925098
At time: 638.878529548645 and batch: 1050, loss is 3.7204843759536743 and perplexity is 41.28438643036902
At time: 639.9353115558624 and batch: 1100, loss is 3.7291838455200197 and perplexity is 41.64510545080046
At time: 640.9925220012665 and batch: 1150, loss is 3.7105816125869753 and perplexity is 40.877574526306
At time: 642.0502841472626 and batch: 1200, loss is 3.7667026042938234 and perplexity is 43.23725916911602
At time: 643.107362985611 and batch: 1250, loss is 3.7357464981079103 and perplexity is 41.91930656908293
At time: 644.1651005744934 and batch: 1300, loss is 3.7434667253494265 and perplexity is 42.24418559795155
At time: 645.2224514484406 and batch: 1350, loss is 3.612994418144226 and perplexity is 37.07691052843199
At time: 646.2811858654022 and batch: 1400, loss is 3.6462287092208863 and perplexity is 38.32984015765672
At time: 647.3415350914001 and batch: 1450, loss is 3.5728076314926147 and perplexity is 35.61645077317647
At time: 648.4004240036011 and batch: 1500, loss is 3.577502155303955 and perplexity is 35.78404613181097
At time: 649.4824850559235 and batch: 1550, loss is 3.581411418914795 and perplexity is 35.92420918987231
At time: 650.5534312725067 and batch: 1600, loss is 3.6730631589889526 and perplexity is 39.37232502594168
At time: 651.6243097782135 and batch: 1650, loss is 3.6125797700881956 and perplexity is 37.06153984648969
At time: 652.6811435222626 and batch: 1700, loss is 3.6400920009613036 and perplexity is 38.09534137220854
At time: 653.7380375862122 and batch: 1750, loss is 3.619862241744995 and perplexity is 37.33242461813189
At time: 654.7959427833557 and batch: 1800, loss is 3.5870872259140016 and perplexity is 36.12868780948741
At time: 655.8648431301117 and batch: 1850, loss is 3.5996715450286865 and perplexity is 36.58621554557513
At time: 656.9344189167023 and batch: 1900, loss is 3.6831588411331175 and perplexity is 39.771828742744844
At time: 657.9917333126068 and batch: 1950, loss is 3.6258145570755005 and perplexity is 37.555301640625146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245050190770349 and perplexity of 69.75926132710386
finished 15 epochs...
Completing Train Step...
At time: 661.3640072345734 and batch: 50, loss is 3.808154640197754 and perplexity is 45.06719689070123
At time: 662.4054048061371 and batch: 100, loss is 3.787995791435242 and perplexity is 44.167790045857124
At time: 663.431755065918 and batch: 150, loss is 3.7503564739227295 and perplexity is 42.536242358937805
At time: 664.4591133594513 and batch: 200, loss is 3.752221746444702 and perplexity is 42.61565808595907
At time: 665.4860029220581 and batch: 250, loss is 3.7429061126708985 and perplexity is 42.22050960906111
At time: 666.5136330127716 and batch: 300, loss is 3.7456413984298704 and perplexity is 42.3361528542907
At time: 667.5396094322205 and batch: 350, loss is 3.7800929307937623 and perplexity is 43.82011378431841
At time: 668.5658230781555 and batch: 400, loss is 3.7332416915893556 and perplexity is 41.81443820904047
At time: 669.5955150127411 and batch: 450, loss is 3.7796306514739992 and perplexity is 43.79986133343153
At time: 670.6341185569763 and batch: 500, loss is 3.799356575012207 and perplexity is 44.67243188527908
At time: 671.6741044521332 and batch: 550, loss is 3.7664721822738647 and perplexity is 43.22729750025881
At time: 672.7138650417328 and batch: 600, loss is 3.7348315000534056 and perplexity is 41.88096802764627
At time: 673.7834804058075 and batch: 650, loss is 3.7612146806716917 and perplexity is 43.00062629862056
At time: 674.862473487854 and batch: 700, loss is 3.7930677318573 and perplexity is 44.39237550613377
At time: 675.9023675918579 and batch: 750, loss is 3.760246295928955 and perplexity is 42.959005304005515
At time: 676.9377615451813 and batch: 800, loss is 3.7299793338775635 and perplexity is 41.67824682737721
At time: 677.9754686355591 and batch: 850, loss is 3.7288532876968383 and perplexity is 41.63134161039438
At time: 679.0130360126495 and batch: 900, loss is 3.692345185279846 and perplexity is 40.138869750246705
At time: 680.0500183105469 and batch: 950, loss is 3.796763300895691 and perplexity is 44.5567341068159
At time: 681.08704829216 and batch: 1000, loss is 3.762157654762268 and perplexity is 43.04119389919079
At time: 682.1257882118225 and batch: 1050, loss is 3.714718804359436 and perplexity is 41.04704321181627
At time: 683.1644012928009 and batch: 1100, loss is 3.7239355278015136 and perplexity is 41.42711125775127
At time: 684.2018949985504 and batch: 1150, loss is 3.705786118507385 and perplexity is 40.682015635197665
At time: 685.2478110790253 and batch: 1200, loss is 3.762234482765198 and perplexity is 43.044500795191254
At time: 686.2942998409271 and batch: 1250, loss is 3.7318891954421995 and perplexity is 41.75792256967458
At time: 687.3402934074402 and batch: 1300, loss is 3.740481400489807 and perplexity is 42.11826103689458
At time: 688.3857352733612 and batch: 1350, loss is 3.610357232093811 and perplexity is 36.97926063425751
At time: 689.4310665130615 and batch: 1400, loss is 3.6441336822509767 and perplexity is 38.24962216754114
At time: 690.4768190383911 and batch: 1450, loss is 3.5714831876754762 and perplexity is 35.56931000969888
At time: 691.5232288837433 and batch: 1500, loss is 3.5768973779678346 and perplexity is 35.76241129450482
At time: 692.5690176486969 and batch: 1550, loss is 3.5814261054992675 and perplexity is 35.92473679767955
At time: 693.615805387497 and batch: 1600, loss is 3.6732850790023805 and perplexity is 39.38106350242567
At time: 694.6628663539886 and batch: 1650, loss is 3.6131716203689574 and perplexity is 37.08348122161733
At time: 695.7090396881104 and batch: 1700, loss is 3.6411403799057007 and perplexity is 38.135300668565314
At time: 696.7551653385162 and batch: 1750, loss is 3.621122899055481 and perplexity is 37.37951769002066
At time: 697.8039336204529 and batch: 1800, loss is 3.5885902214050294 and perplexity is 36.1830298920845
At time: 698.8513309955597 and batch: 1850, loss is 3.601237568855286 and perplexity is 36.64355531685013
At time: 699.8993101119995 and batch: 1900, loss is 3.6847476959228516 and perplexity is 39.83507063112357
At time: 700.9470024108887 and batch: 1950, loss is 3.6271080112457277 and perplexity is 37.603909131150225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244932378724564 and perplexity of 69.75104332991351
finished 16 epochs...
Completing Train Step...
At time: 704.2883217334747 and batch: 50, loss is 3.8036152839660646 and perplexity is 44.863084449682006
At time: 705.3197650909424 and batch: 100, loss is 3.7826777935028075 and perplexity is 43.9335292809406
At time: 706.3415894508362 and batch: 150, loss is 3.7446832704544066 and perplexity is 42.295608828151984
At time: 707.3713383674622 and batch: 200, loss is 3.7462061166763307 and perplexity is 42.36006760420472
At time: 708.4067945480347 and batch: 250, loss is 3.736561141014099 and perplexity is 41.95346974831825
At time: 709.4450151920319 and batch: 300, loss is 3.7391139221191407 and perplexity is 42.06070458848489
At time: 710.4842698574066 and batch: 350, loss is 3.773623056411743 and perplexity is 43.537518317084455
At time: 711.5227692127228 and batch: 400, loss is 3.7263622522354125 and perplexity is 41.527765521550975
At time: 712.5626554489136 and batch: 450, loss is 3.7730285263061525 and perplexity is 43.51164164471484
At time: 713.602047920227 and batch: 500, loss is 3.792585544586182 and perplexity is 44.37097522761561
At time: 714.675660610199 and batch: 550, loss is 3.7597430753707886 and perplexity is 42.937392887740316
At time: 715.715594291687 and batch: 600, loss is 3.7287168979644774 and perplexity is 41.62566391005312
At time: 716.7551407814026 and batch: 650, loss is 3.7551179218292234 and perplexity is 42.73925940505616
At time: 717.8163509368896 and batch: 700, loss is 3.787448344230652 and perplexity is 44.143617129964944
At time: 718.8588109016418 and batch: 750, loss is 3.7548222494125367 and perplexity is 42.72662445293593
At time: 719.8976085186005 and batch: 800, loss is 3.7248391199111937 and perplexity is 41.464561385882654
At time: 720.944048166275 and batch: 850, loss is 3.723848652839661 and perplexity is 41.42351243536713
At time: 722.0172188282013 and batch: 900, loss is 3.687450385093689 and perplexity is 39.94287806450569
At time: 723.0658416748047 and batch: 950, loss is 3.792012028694153 and perplexity is 44.34553506404412
At time: 724.1309349536896 and batch: 1000, loss is 3.757763319015503 and perplexity is 42.852471400955025
At time: 725.1838984489441 and batch: 1050, loss is 3.7105422735214235 and perplexity is 40.87596647235198
At time: 726.227136850357 and batch: 1100, loss is 3.720039949417114 and perplexity is 41.266042630031514
At time: 727.2730522155762 and batch: 1150, loss is 3.7021640300750733 and perplexity is 40.534928319404436
At time: 728.3191330432892 and batch: 1200, loss is 3.7587882041931153 and perplexity is 42.89641277730427
At time: 729.3664832115173 and batch: 1250, loss is 3.7288671731948853 and perplexity is 41.63191968632042
At time: 730.4281475543976 and batch: 1300, loss is 3.7379508686065672 and perplexity is 42.01181417486673
At time: 731.4832170009613 and batch: 1350, loss is 3.607993874549866 and perplexity is 36.89196861142886
At time: 732.5300850868225 and batch: 1400, loss is 3.6420616722106933 and perplexity is 38.17045061682205
At time: 733.6037828922272 and batch: 1450, loss is 3.569799394607544 and perplexity is 35.50946904611148
At time: 734.6520953178406 and batch: 1500, loss is 3.575545916557312 and perplexity is 35.714112420076816
At time: 735.6989171504974 and batch: 1550, loss is 3.5804349040985106 and perplexity is 35.88914579008611
At time: 736.7467851638794 and batch: 1600, loss is 3.6724385356903078 and perplexity is 39.34773983345001
At time: 737.7935273647308 and batch: 1650, loss is 3.6125580406188966 and perplexity is 37.06073452764703
At time: 738.8414213657379 and batch: 1700, loss is 3.640813045501709 and perplexity is 38.12281971548404
At time: 739.888662815094 and batch: 1750, loss is 3.6209363031387327 and perplexity is 37.372543475349914
At time: 740.9463512897491 and batch: 1800, loss is 3.5886134624481203 and perplexity is 36.18387083321352
At time: 741.999507188797 and batch: 1850, loss is 3.6013072443008425 and perplexity is 36.64610856184182
At time: 743.0460057258606 and batch: 1900, loss is 3.6848068857192993 and perplexity is 39.83742853062681
At time: 744.0927937030792 and batch: 1950, loss is 3.6270251846313477 and perplexity is 37.600794655651946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245148982558139 and perplexity of 69.76615330967533
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 747.4956712722778 and batch: 50, loss is 3.80314621925354 and perplexity is 44.84204569452622
At time: 748.5048546791077 and batch: 100, loss is 3.788657937049866 and perplexity is 44.19704523887363
At time: 749.5294754505157 and batch: 150, loss is 3.7530170106887817 and perplexity is 42.649562274680385
At time: 750.5535645484924 and batch: 200, loss is 3.754641542434692 and perplexity is 42.71890415133473
At time: 751.5829231739044 and batch: 250, loss is 3.743798828125 and perplexity is 42.258217339101606
At time: 752.6144638061523 and batch: 300, loss is 3.744592156410217 and perplexity is 42.29175527973905
At time: 753.650393486023 and batch: 350, loss is 3.7808921480178834 and perplexity is 43.85514957275565
At time: 754.6897931098938 and batch: 400, loss is 3.7372086334228514 and perplexity is 41.980643097820504
At time: 755.7299053668976 and batch: 450, loss is 3.7873071146011354 and perplexity is 44.137383183491494
At time: 756.777188539505 and batch: 500, loss is 3.807522349357605 and perplexity is 45.038710321763425
At time: 757.8229758739471 and batch: 550, loss is 3.7752336072921753 and perplexity is 43.60769420128897
At time: 758.8916528224945 and batch: 600, loss is 3.7429913234710694 and perplexity is 42.224107405751916
At time: 759.9393045902252 and batch: 650, loss is 3.766505537033081 and perplexity is 43.228739360404816
At time: 760.9860849380493 and batch: 700, loss is 3.7983014726638795 and perplexity is 44.62532275433908
At time: 762.0321035385132 and batch: 750, loss is 3.7636231708526613 and perplexity is 43.10431770457824
At time: 763.0777113437653 and batch: 800, loss is 3.7342955255508423 and perplexity is 41.858526911111134
At time: 764.124186038971 and batch: 850, loss is 3.7312345790863035 and perplexity is 41.730596095726455
At time: 765.1707830429077 and batch: 900, loss is 3.690903134346008 and perplexity is 40.08102917019474
At time: 766.2431640625 and batch: 950, loss is 3.796714220046997 and perplexity is 44.55454727815707
At time: 767.3056976795197 and batch: 1000, loss is 3.762389426231384 and perplexity is 43.05117077606636
At time: 768.3515529632568 and batch: 1050, loss is 3.716579418182373 and perplexity is 41.12348700193988
At time: 769.39794921875 and batch: 1100, loss is 3.722305006980896 and perplexity is 41.359618529409865
At time: 770.4436945915222 and batch: 1150, loss is 3.705338091850281 and perplexity is 40.66379309012616
At time: 771.4895763397217 and batch: 1200, loss is 3.764131169319153 and perplexity is 43.12622019461599
At time: 772.5359921455383 and batch: 1250, loss is 3.7329643630981444 and perplexity is 41.80284348182953
At time: 773.5820305347443 and batch: 1300, loss is 3.738353061676025 and perplexity is 42.02871443371889
At time: 774.6278088092804 and batch: 1350, loss is 3.6067501735687255 and perplexity is 36.846114554149196
At time: 775.6738066673279 and batch: 1400, loss is 3.6382753467559814 and perplexity is 38.02619813379468
At time: 776.7191083431244 and batch: 1450, loss is 3.561499762535095 and perplexity is 35.21597315664906
At time: 777.7626254558563 and batch: 1500, loss is 3.56515212059021 and perplexity is 35.34482967169937
At time: 778.8090798854828 and batch: 1550, loss is 3.569126400947571 and perplexity is 35.48557943825342
At time: 779.8540282249451 and batch: 1600, loss is 3.6637893438339235 and perplexity is 39.008881221545316
At time: 780.8987946510315 and batch: 1650, loss is 3.6026523876190186 and perplexity is 36.69543599870919
At time: 781.9533858299255 and batch: 1700, loss is 3.6295396518707275 and perplexity is 37.6954595880469
At time: 783.0022192001343 and batch: 1750, loss is 3.6086397886276247 and perplexity is 36.91580535072522
At time: 784.0490388870239 and batch: 1800, loss is 3.575637764930725 and perplexity is 35.71739285385944
At time: 785.0945785045624 and batch: 1850, loss is 3.588706111907959 and perplexity is 36.18722340460565
At time: 786.1390073299408 and batch: 1900, loss is 3.6732034826278688 and perplexity is 39.377850281514824
At time: 787.2037332057953 and batch: 1950, loss is 3.6186293077468874 and perplexity is 37.2864245659297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242674361827762 and perplexity of 69.59372197948247
finished 18 epochs...
Completing Train Step...
At time: 790.5300624370575 and batch: 50, loss is 3.8026625061035157 and perplexity is 44.82036025253934
At time: 791.5417721271515 and batch: 100, loss is 3.7849178075790406 and perplexity is 44.03205130911761
At time: 792.5763511657715 and batch: 150, loss is 3.7481232213974 and perplexity is 42.44135418233893
At time: 793.5997266769409 and batch: 200, loss is 3.7491480016708376 and perplexity is 42.48486953791373
At time: 794.6244983673096 and batch: 250, loss is 3.738741784095764 and perplexity is 42.04505511308052
At time: 795.6499376296997 and batch: 300, loss is 3.739225916862488 and perplexity is 42.065415430090106
At time: 796.6840205192566 and batch: 350, loss is 3.774181437492371 and perplexity is 43.56183563214271
At time: 797.722811460495 and batch: 400, loss is 3.7298491287231443 and perplexity is 41.67282045809142
At time: 798.7620351314545 and batch: 450, loss is 3.7801731634140014 and perplexity is 43.8236297279113
At time: 799.8000357151031 and batch: 500, loss is 3.799797005653381 and perplexity is 44.69211132649346
At time: 800.8386924266815 and batch: 550, loss is 3.767526397705078 and perplexity is 43.27289241354107
At time: 801.8797540664673 and batch: 600, loss is 3.7358689212799074 and perplexity is 41.924438777705255
At time: 802.9429385662079 and batch: 650, loss is 3.7599248266220093 and perplexity is 42.94519752185135
At time: 803.9807894229889 and batch: 700, loss is 3.792585778236389 and perplexity is 44.370985594904376
At time: 805.018232345581 and batch: 750, loss is 3.758425498008728 and perplexity is 42.88085680439624
At time: 806.0575063228607 and batch: 800, loss is 3.7292488479614256 and perplexity is 41.647812572311175
At time: 807.0952398777008 and batch: 850, loss is 3.726211667060852 and perplexity is 41.52151252654679
At time: 808.1329853534698 and batch: 900, loss is 3.686567311286926 and perplexity is 39.90762112465141
At time: 809.171080827713 and batch: 950, loss is 3.7924888849258425 and perplexity is 44.366686551495505
At time: 810.2160351276398 and batch: 1000, loss is 3.7581382989883423 and perplexity is 42.868543232636235
At time: 811.2618219852448 and batch: 1050, loss is 3.7125938177108764 and perplexity is 40.959911402781216
At time: 812.3067498207092 and batch: 1100, loss is 3.7191573905944826 and perplexity is 41.22963898657458
At time: 813.3528480529785 and batch: 1150, loss is 3.7026921558380126 and perplexity is 40.55634151328078
At time: 814.3981635570526 and batch: 1200, loss is 3.7615340995788573 and perplexity is 43.01436370555726
At time: 815.4449369907379 and batch: 1250, loss is 3.7307664346694946 and perplexity is 41.71106472226256
At time: 816.4911365509033 and batch: 1300, loss is 3.7365693759918215 and perplexity is 41.95381523562954
At time: 817.5370659828186 and batch: 1350, loss is 3.6052372550964353 and perplexity is 36.79041153449679
At time: 818.5839147567749 and batch: 1400, loss is 3.637197313308716 and perplexity is 37.98522670858541
At time: 819.6307055950165 and batch: 1450, loss is 3.5613545274734495 and perplexity is 35.21085893400796
At time: 820.6784944534302 and batch: 1500, loss is 3.5660106706619263 and perplexity is 35.37518800795991
At time: 821.7552802562714 and batch: 1550, loss is 3.5708069705963137 and perplexity is 35.545265565324506
At time: 822.8020761013031 and batch: 1600, loss is 3.665700521469116 and perplexity is 39.08350541023569
At time: 823.8489034175873 and batch: 1650, loss is 3.6051778984069824 and perplexity is 36.78822784227351
At time: 824.8942592144012 and batch: 1700, loss is 3.6325561666488646 and perplexity is 37.80934017384455
At time: 825.9405107498169 and batch: 1750, loss is 3.6115629959106443 and perplexity is 37.02387578096297
At time: 826.9866545200348 and batch: 1800, loss is 3.5790198993682862 and perplexity is 35.838398391401384
At time: 828.0321130752563 and batch: 1850, loss is 3.5921675729751588 and perplexity is 36.3127011123644
At time: 829.0755069255829 and batch: 1900, loss is 3.67681077003479 and perplexity is 39.52015401587057
At time: 830.1208477020264 and batch: 1950, loss is 3.621809763908386 and perplexity is 37.40520118647624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241941939952762 and perplexity of 69.54276867707645
finished 19 epochs...
Completing Train Step...
At time: 833.5063307285309 and batch: 50, loss is 3.80212637424469 and perplexity is 44.79633706985612
At time: 834.5322740077972 and batch: 100, loss is 3.7832744884490968 and perplexity is 43.95975201854465
At time: 835.5468239784241 and batch: 150, loss is 3.74592716217041 and perplexity is 42.34825272045957
At time: 836.5807011127472 and batch: 200, loss is 3.7465788555145263 and perplexity is 42.375859789586976
At time: 837.6093933582306 and batch: 250, loss is 3.736073203086853 and perplexity is 41.933004052649075
At time: 838.645379781723 and batch: 300, loss is 3.736315732002258 and perplexity is 41.94317525199677
At time: 839.6831569671631 and batch: 350, loss is 3.770763325691223 and perplexity is 43.41319059509084
At time: 840.7191994190216 and batch: 400, loss is 3.7260140943527222 and perplexity is 41.51330981921351
At time: 841.7597229480743 and batch: 450, loss is 3.7763111782073975 and perplexity is 43.6547099110715
At time: 842.7961010932922 and batch: 500, loss is 3.79564350605011 and perplexity is 44.50686763094929
At time: 843.8701434135437 and batch: 550, loss is 3.7633576583862305 and perplexity is 43.09287449009596
At time: 844.9130825996399 and batch: 600, loss is 3.732105951309204 and perplexity is 41.7669748254148
At time: 845.9508647918701 and batch: 650, loss is 3.756421933174133 and perplexity is 42.795028237886086
At time: 846.9891123771667 and batch: 700, loss is 3.789513850212097 and perplexity is 44.23489026534305
At time: 848.0256090164185 and batch: 750, loss is 3.7555804777145387 and perplexity is 42.75903327393513
At time: 849.0654768943787 and batch: 800, loss is 3.726443719863892 and perplexity is 41.53114882793716
At time: 850.1095612049103 and batch: 850, loss is 3.723511219024658 and perplexity is 41.4095370995433
At time: 851.1536786556244 and batch: 900, loss is 3.6841191816329957 and perplexity is 39.81004158637457
At time: 852.1988432407379 and batch: 950, loss is 3.790100865364075 and perplexity is 44.26086443904578
At time: 853.243292093277 and batch: 1000, loss is 3.755846676826477 and perplexity is 42.77041720574904
At time: 854.2892732620239 and batch: 1050, loss is 3.710429449081421 and perplexity is 40.87135492447772
At time: 855.333811044693 and batch: 1100, loss is 3.7174051809310913 and perplexity is 41.157459270189854
At time: 856.378297328949 and batch: 1150, loss is 3.70118700504303 and perplexity is 40.495344020338685
At time: 857.4269678592682 and batch: 1200, loss is 3.7601450729370116 and perplexity is 42.95465708503131
At time: 858.4748756885529 and batch: 1250, loss is 3.7295545721054078 and perplexity is 41.66054726071023
At time: 859.5226686000824 and batch: 1300, loss is 3.735703535079956 and perplexity is 41.9175056274302
At time: 860.5680415630341 and batch: 1350, loss is 3.6044331932067872 and perplexity is 36.760841656276625
At time: 861.614901304245 and batch: 1400, loss is 3.636650786399841 and perplexity is 37.964472431951386
At time: 862.6603763103485 and batch: 1450, loss is 3.5612672328948975 and perplexity is 35.20778535107238
At time: 863.7061381340027 and batch: 1500, loss is 3.5664564180374145 and perplexity is 35.390959920054925
At time: 864.7512309551239 and batch: 1550, loss is 3.5716871786117554 and perplexity is 35.57656656666133
At time: 865.7955961227417 and batch: 1600, loss is 3.6666472816467284 and perplexity is 39.12052563863333
At time: 866.8395056724548 and batch: 1650, loss is 3.6065477752685546 and perplexity is 36.83865771784649
At time: 867.8839349746704 and batch: 1700, loss is 3.633981103897095 and perplexity is 37.863254514142604
At time: 868.9281499385834 and batch: 1750, loss is 3.612983856201172 and perplexity is 37.07651892628242
At time: 869.9726662635803 and batch: 1800, loss is 3.5806660413742066 and perplexity is 35.89744206822372
At time: 871.0168249607086 and batch: 1850, loss is 3.59384325504303 and perplexity is 36.37360066434791
At time: 872.0617709159851 and batch: 1900, loss is 3.6785135507583617 and perplexity is 39.58750549845091
At time: 873.1057286262512 and batch: 1950, loss is 3.6232942008972167 and perplexity is 37.46076808326685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241636480287064 and perplexity of 69.5215294102395
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f0afa1ddb38>
ELAPSED
5408.536060333252


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56731245050365}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.6765022317192798, 'rnn_dropout': 0.40821417681898475, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.08080462170798}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.9990387741788632, 'rnn_dropout': 0.09278654931862784, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -602.5551858822912}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.604511707161204, 'rnn_dropout': 0.4360814554105134, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.5215294102395}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.8002625769705947, 'rnn_dropout': 0.04053625313464093, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -68.54759180420825}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.1479013803455841, 'rnn_dropout': 0.28770350955148094, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56514008583451}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.5320105602272489, 'rnn_dropout': 0.4641471433713693, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.56731245050365}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.6765022317192798, 'rnn_dropout': 0.40821417681898475, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.08080462170798}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.9990387741788632, 'rnn_dropout': 0.09278654931862784, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -602.5551858822912}, {'params': {'tie_weights': 'FALSE', 'num_layers': 3, 'seq_len': 35, 'batch_size': 32, 'data': 'wikitext', 'dropout': 0.604511707161204, 'rnn_dropout': 0.4360814554105134, 'tune_wordvecs': 'TRUE', 'wordvec_source': 'glove', 'wordvec_dim': 300}, 'best_accuracy': -69.5215294102395}]
