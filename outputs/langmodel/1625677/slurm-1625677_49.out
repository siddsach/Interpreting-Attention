FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8266243934631348 and batch: 50, loss is 7.221736869812012 and perplexity is 1368.864536655288
At time: 2.8754544258117676 and batch: 100, loss is 6.438843660354614 and perplexity is 625.6828794243136
At time: 3.927180051803589 and batch: 150, loss is 6.1790229606628415 and perplexity is 482.5202846703135
At time: 4.977322340011597 and batch: 200, loss is 6.059079666137695 and perplexity is 427.98136980340837
At time: 6.023233413696289 and batch: 250, loss is 5.973100700378418 and perplexity is 392.72149651292335
At time: 7.075751304626465 and batch: 300, loss is 5.918416500091553 and perplexity is 371.82246662096867
At time: 8.13530158996582 and batch: 350, loss is 5.867111854553222 and perplexity is 353.227333730439
At time: 9.188231468200684 and batch: 400, loss is 5.812337894439697 and perplexity is 334.4000044238279
At time: 10.238319158554077 and batch: 450, loss is 5.742168951034546 and perplexity is 311.739826664391
At time: 11.291203022003174 and batch: 500, loss is 5.718717737197876 and perplexity is 304.51420527092864
At time: 12.342851400375366 and batch: 550, loss is 5.671748037338257 and perplexity is 290.5419689653149
At time: 13.392672061920166 and batch: 600, loss is 5.707440328598023 and perplexity is 301.09936561619
At time: 14.444000244140625 and batch: 650, loss is 5.791998643875122 and perplexity is 327.66726052898207
At time: 15.496593475341797 and batch: 700, loss is 5.6937782669067385 and perplexity is 297.013700362883
At time: 16.548672914505005 and batch: 750, loss is 5.6424480819702145 and perplexity is 282.1526063882
At time: 17.601091384887695 and batch: 800, loss is 5.642819776535034 and perplexity is 282.2575004715168
At time: 18.653987646102905 and batch: 850, loss is 5.66407509803772 and perplexity is 288.32118892392003
At time: 19.705825567245483 and batch: 900, loss is 5.664737787246704 and perplexity is 288.5123195876609
At time: 20.758492469787598 and batch: 950, loss is 5.692143077850342 and perplexity is 296.52842367814134
At time: 21.81313705444336 and batch: 1000, loss is 5.6651974868774415 and perplexity is 288.6449790838631
At time: 22.865030527114868 and batch: 1050, loss is 5.573482275009155 and perplexity is 263.34955996352164
At time: 23.917786836624146 and batch: 1100, loss is 5.658017597198486 and perplexity is 286.5799621456588
At time: 24.969883680343628 and batch: 1150, loss is 5.56546706199646 and perplexity is 261.2471938550019
At time: 26.02087950706482 and batch: 1200, loss is 5.647278318405151 and perplexity is 283.51876697092234
At time: 27.078214168548584 and batch: 1250, loss is 5.58348385810852 and perplexity is 265.99668814155194
At time: 28.128832578659058 and batch: 1300, loss is 5.597757196426391 and perplexity is 269.82057375009964
At time: 29.180370092391968 and batch: 1350, loss is 5.558815231323242 and perplexity is 259.5151886466208
At time: 30.23267412185669 and batch: 1400, loss is 5.582230005264282 and perplexity is 265.6633764431462
At time: 31.282832145690918 and batch: 1450, loss is 5.531097211837769 and perplexity is 252.4207181377602
At time: 32.332040786743164 and batch: 1500, loss is 5.524741325378418 and perplexity is 250.82144848529674
At time: 33.393486738204956 and batch: 1550, loss is 5.507351379394532 and perplexity is 246.49738364114063
At time: 34.45624089241028 and batch: 1600, loss is 5.541658592224121 and perplexity is 255.10075690230119
At time: 35.50751733779907 and batch: 1650, loss is 5.518075952529907 and perplexity is 249.15518930103192
At time: 36.558085441589355 and batch: 1700, loss is 5.531734275817871 and perplexity is 252.5815775185356
At time: 37.60805320739746 and batch: 1750, loss is 5.549634027481079 and perplexity is 257.14343125404736
At time: 38.659223318099976 and batch: 1800, loss is 5.538104667663574 and perplexity is 254.1957571598785
At time: 39.71023368835449 and batch: 1850, loss is 5.508428173065186 and perplexity is 246.76295341994629
At time: 40.761393547058105 and batch: 1900, loss is 5.518248920440674 and perplexity is 249.19828888089668
At time: 41.81331539154053 and batch: 1950, loss is 5.453825550079346 and perplexity is 233.65029929016626
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.022371230014535 and perplexity of 151.7707608313795
finished 1 epochs...
Completing Train Step...
At time: 45.20243191719055 and batch: 50, loss is 5.246563959121704 and perplexity is 189.91259863142795
At time: 46.24442911148071 and batch: 100, loss is 5.181484661102295 and perplexity is 177.9468056742178
At time: 47.28697657585144 and batch: 150, loss is 5.101246042251587 and perplexity is 164.22641291143964
At time: 48.33036804199219 and batch: 200, loss is 5.076638679504395 and perplexity is 160.23455003333063
At time: 49.37233376502991 and batch: 250, loss is 5.076829977035523 and perplexity is 160.26520543921163
At time: 50.415669441223145 and batch: 300, loss is 5.10320258140564 and perplexity is 164.5480428566198
At time: 51.46151375770569 and batch: 350, loss is 5.092480840682984 and perplexity is 162.79322556320065
At time: 52.56431722640991 and batch: 400, loss is 5.062541494369507 and perplexity is 157.99154111856188
At time: 53.60765290260315 and batch: 450, loss is 5.023073034286499 and perplexity is 151.87731158420368
At time: 54.652989864349365 and batch: 500, loss is 5.018478832244873 and perplexity is 151.18115689136224
At time: 55.69945979118347 and batch: 550, loss is 4.973058347702026 and perplexity is 144.4680459352168
At time: 56.74371123313904 and batch: 600, loss is 4.969125595092773 and perplexity is 143.90100459810768
At time: 57.787927865982056 and batch: 650, loss is 5.043223390579223 and perplexity is 154.96873557083185
At time: 58.83259892463684 and batch: 700, loss is 5.0254796028137205 and perplexity is 152.2432548994783
At time: 59.87959861755371 and batch: 750, loss is 4.9800325202941895 and perplexity is 145.47911260022386
At time: 60.925668478012085 and batch: 800, loss is 4.961706161499023 and perplexity is 142.83729160398062
At time: 61.970813274383545 and batch: 850, loss is 4.960526704788208 and perplexity is 142.66892051456793
At time: 63.01771855354309 and batch: 900, loss is 4.9810011768341065 and perplexity is 145.62010016730585
At time: 64.06303882598877 and batch: 950, loss is 5.032843313217163 and perplexity is 153.36846792639207
At time: 65.10921716690063 and batch: 1000, loss is 5.00952332496643 and perplexity is 149.8332973318136
At time: 66.15685272216797 and batch: 1050, loss is 4.9289709663391115 and perplexity is 138.23718840440472
At time: 67.20384907722473 and batch: 1100, loss is 5.002165222167969 and perplexity is 148.7348547102336
At time: 68.25221228599548 and batch: 1150, loss is 4.923659248352051 and perplexity is 137.5048581320673
At time: 69.29866814613342 and batch: 1200, loss is 4.998808698654175 and perplexity is 148.23645957848763
At time: 70.3446888923645 and batch: 1250, loss is 4.952346029281617 and perplexity is 141.50655332781122
At time: 71.39147710800171 and batch: 1300, loss is 4.980981855392456 and perplexity is 145.6172866042185
At time: 72.43877625465393 and batch: 1350, loss is 4.895853128433227 and perplexity is 133.7340502814681
At time: 73.48469877243042 and batch: 1400, loss is 4.913193864822388 and perplexity is 136.07332091318608
At time: 74.53014707565308 and batch: 1450, loss is 4.852040147781372 and perplexity is 128.0012651405568
At time: 75.57855081558228 and batch: 1500, loss is 4.841324243545532 and perplexity is 126.63693889146906
At time: 76.6256971359253 and batch: 1550, loss is 4.834702939987182 and perplexity is 125.80120714747366
At time: 77.67249274253845 and batch: 1600, loss is 4.896466674804688 and perplexity is 133.81612749927382
At time: 78.7204942703247 and batch: 1650, loss is 4.863395404815674 and perplexity is 129.46303609246382
At time: 79.76715660095215 and batch: 1700, loss is 4.890938892364502 and perplexity is 133.07846176567924
At time: 80.81486511230469 and batch: 1750, loss is 4.899648389816284 and perplexity is 134.2425703309605
At time: 81.86223649978638 and batch: 1800, loss is 4.864737291336059 and perplexity is 129.63687740705706
At time: 82.90848183631897 and batch: 1850, loss is 4.872193841934204 and perplexity is 130.60713423185095
At time: 83.95489478111267 and batch: 1900, loss is 4.931118288040161 and perplexity is 138.53434705238138
At time: 85.0013484954834 and batch: 1950, loss is 4.855962915420532 and perplexity is 128.5043704987779
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.740422590388808 and perplexity of 114.48257069335983
finished 2 epochs...
Completing Train Step...
At time: 88.41754150390625 and batch: 50, loss is 4.780338335037231 and perplexity is 119.14465403726258
At time: 89.50300884246826 and batch: 100, loss is 4.7378648662567135 and perplexity is 114.19013001031709
At time: 90.55573081970215 and batch: 150, loss is 4.677762584686279 and perplexity is 107.529215709562
At time: 91.60683512687683 and batch: 200, loss is 4.669201974868774 and perplexity is 106.6126289184233
At time: 92.65891695022583 and batch: 250, loss is 4.671909284591675 and perplexity is 106.90165338812228
At time: 93.71130442619324 and batch: 300, loss is 4.711902017593384 and perplexity is 111.26358407012472
At time: 94.7640175819397 and batch: 350, loss is 4.722760276794434 and perplexity is 112.47829579829468
At time: 95.81546759605408 and batch: 400, loss is 4.681504554748535 and perplexity is 107.93234058578328
At time: 96.86735439300537 and batch: 450, loss is 4.6759852695465085 and perplexity is 107.3382721402255
At time: 97.91928243637085 and batch: 500, loss is 4.6862356472015385 and perplexity is 108.44418831248841
At time: 98.97206425666809 and batch: 550, loss is 4.642854509353637 and perplexity is 103.84033814490408
At time: 100.02499532699585 and batch: 600, loss is 4.626229581832885 and perplexity is 102.12827097854111
At time: 101.08092641830444 and batch: 650, loss is 4.699449977874756 and perplexity is 109.88671570246589
At time: 102.13310766220093 and batch: 700, loss is 4.703603181838989 and perplexity is 110.34404668277926
At time: 103.18571519851685 and batch: 750, loss is 4.664425630569458 and perplexity is 106.10462446392187
At time: 104.23732805252075 and batch: 800, loss is 4.638299732208252 and perplexity is 103.36844404800217
At time: 105.37210202217102 and batch: 850, loss is 4.64068489074707 and perplexity is 103.61528843944718
At time: 106.42407321929932 and batch: 900, loss is 4.655089530944824 and perplexity is 105.11863094795518
At time: 107.47504806518555 and batch: 950, loss is 4.7203365993499755 and perplexity is 112.20601478374039
At time: 108.52707314491272 and batch: 1000, loss is 4.702416772842407 and perplexity is 110.21321114065432
At time: 109.58018183708191 and batch: 1050, loss is 4.633849258422852 and perplexity is 102.90942767532943
At time: 110.63197898864746 and batch: 1100, loss is 4.6952291679382325 and perplexity is 109.42388221415403
At time: 111.6883544921875 and batch: 1150, loss is 4.629391870498657 and perplexity is 102.45174123591535
At time: 112.7411425113678 and batch: 1200, loss is 4.70086787223816 and perplexity is 110.04263396896717
At time: 113.79329705238342 and batch: 1250, loss is 4.67408971786499 and perplexity is 107.13499961563186
At time: 114.84606671333313 and batch: 1300, loss is 4.688117408752442 and perplexity is 108.64844653883851
At time: 115.89785242080688 and batch: 1350, loss is 4.5950991153717045 and perplexity is 98.99794727975575
At time: 116.95063304901123 and batch: 1400, loss is 4.604802837371826 and perplexity is 99.96327188479768
At time: 118.00385761260986 and batch: 1450, loss is 4.545745973587036 and perplexity is 94.23069460660172
At time: 119.05622005462646 and batch: 1500, loss is 4.537081279754639 and perplexity is 93.41774156896808
At time: 120.10830187797546 and batch: 1550, loss is 4.5425699424743655 and perplexity is 93.93188974670309
At time: 121.15961980819702 and batch: 1600, loss is 4.627704191207886 and perplexity is 102.2789813765519
At time: 122.21121740341187 and batch: 1650, loss is 4.586103792190552 and perplexity is 98.11142201814177
At time: 123.26523685455322 and batch: 1700, loss is 4.614639797210693 and perplexity is 100.95145898555688
At time: 124.31605815887451 and batch: 1750, loss is 4.622939119338989 and perplexity is 101.7927740061281
At time: 125.3693835735321 and batch: 1800, loss is 4.58443977355957 and perplexity is 97.94829854188343
At time: 126.424569606781 and batch: 1850, loss is 4.6073870182037355 and perplexity is 100.22192912049002
At time: 127.4749755859375 and batch: 1900, loss is 4.680375595092773 and perplexity is 107.81055808441016
At time: 128.5282711982727 and batch: 1950, loss is 4.612345743179321 and perplexity is 100.72013631889432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.654598360283431 and perplexity of 105.0670124382542
finished 3 epochs...
Completing Train Step...
At time: 131.9401388168335 and batch: 50, loss is 4.547968864440918 and perplexity is 94.44039213681145
At time: 132.98989844322205 and batch: 100, loss is 4.510494241714477 and perplexity is 90.96676697278113
At time: 134.03221011161804 and batch: 150, loss is 4.456080513000488 and perplexity is 86.14918588863394
At time: 135.07373356819153 and batch: 200, loss is 4.449496746063232 and perplexity is 85.58386274685301
At time: 136.115656375885 and batch: 250, loss is 4.452256278991699 and perplexity is 85.8203603956952
At time: 137.15699934959412 and batch: 300, loss is 4.48868989944458 and perplexity is 89.00476427192109
At time: 138.1988799571991 and batch: 350, loss is 4.500941400527954 and perplexity is 90.10191337613699
At time: 139.24174118041992 and batch: 400, loss is 4.460853357315063 and perplexity is 86.56134534474893
At time: 140.29020261764526 and batch: 450, loss is 4.468400220870972 and perplexity is 87.21708327733312
At time: 141.33355975151062 and batch: 500, loss is 4.48961254119873 and perplexity is 89.08692167885555
At time: 142.37633967399597 and batch: 550, loss is 4.444869356155396 and perplexity is 85.18874772477825
At time: 143.41661477088928 and batch: 600, loss is 4.429938249588012 and perplexity is 83.92623427071263
At time: 144.45781183242798 and batch: 650, loss is 4.4916328430175785 and perplexity is 89.26708608071309
At time: 145.49981045722961 and batch: 700, loss is 4.507249717712402 and perplexity is 90.6721013972068
At time: 146.54466462135315 and batch: 750, loss is 4.465938844680786 and perplexity is 87.00267320534789
At time: 147.60866689682007 and batch: 800, loss is 4.444686689376831 and perplexity is 85.17318799182785
At time: 148.6698443889618 and batch: 850, loss is 4.4462142753601075 and perplexity is 85.30339678720009
At time: 149.72005772590637 and batch: 900, loss is 4.453687725067138 and perplexity is 85.9432955803286
At time: 150.77306842803955 and batch: 950, loss is 4.524419975280762 and perplexity is 92.24240743268899
At time: 151.82781147956848 and batch: 1000, loss is 4.512293176651001 and perplexity is 91.13055754807404
At time: 152.87532377243042 and batch: 1050, loss is 4.4449192142486575 and perplexity is 85.1929951791913
At time: 153.92400813102722 and batch: 1100, loss is 4.506396760940552 and perplexity is 90.59479498850149
At time: 154.97304797172546 and batch: 1150, loss is 4.444178485870362 and perplexity is 85.1299136760441
At time: 156.02275729179382 and batch: 1200, loss is 4.511385564804077 and perplexity is 91.04788389789404
At time: 157.0734281539917 and batch: 1250, loss is 4.492129373550415 and perplexity is 89.31142092041941
At time: 158.12243342399597 and batch: 1300, loss is 4.502465534210205 and perplexity is 90.23934544296549
At time: 159.18159556388855 and batch: 1350, loss is 4.397557411193848 and perplexity is 81.2521604649233
At time: 160.2412748336792 and batch: 1400, loss is 4.415416841506958 and perplexity is 82.71631331353555
At time: 161.2939474582672 and batch: 1450, loss is 4.356909074783325 and perplexity is 78.01562091528827
At time: 162.35436034202576 and batch: 1500, loss is 4.353747110366822 and perplexity is 77.76932788812016
At time: 163.40609645843506 and batch: 1550, loss is 4.356820421218872 and perplexity is 78.00870485898216
At time: 164.45821857452393 and batch: 1600, loss is 4.453213157653809 and perplexity is 85.90251936914787
At time: 165.50970435142517 and batch: 1650, loss is 4.409977970123291 and perplexity is 82.2676511380269
At time: 166.56087374687195 and batch: 1700, loss is 4.433879842758179 and perplexity is 84.2576901454889
At time: 167.61195158958435 and batch: 1750, loss is 4.447070951461792 and perplexity is 85.37650547938374
At time: 168.6661877632141 and batch: 1800, loss is 4.401063804626465 and perplexity is 81.53756258040183
At time: 169.7244143486023 and batch: 1850, loss is 4.430132102966309 and perplexity is 83.94250523179313
At time: 170.78436040878296 and batch: 1900, loss is 4.510873708724976 and perplexity is 91.00129241011696
At time: 171.83648419380188 and batch: 1950, loss is 4.4393534755706785 and perplexity is 84.72015031692548
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.626272370094477 and perplexity of 102.132640963207
finished 4 epochs...
Completing Train Step...
At time: 175.17967534065247 and batch: 50, loss is 4.383308477401734 and perplexity is 80.10261317115129
At time: 176.253990650177 and batch: 100, loss is 4.343165130615234 and perplexity is 76.95071335522663
At time: 177.30244708061218 and batch: 150, loss is 4.298759813308716 and perplexity is 73.60844885034021
At time: 178.3508858680725 and batch: 200, loss is 4.294041090011596 and perplexity is 73.26192915613939
At time: 179.396484375 and batch: 250, loss is 4.293638782501221 and perplexity is 73.23246125979072
At time: 180.44511461257935 and batch: 300, loss is 4.329700469970703 and perplexity is 75.92154238126001
At time: 181.49167561531067 and batch: 350, loss is 4.341100101470947 and perplexity is 76.79197184880371
At time: 182.5389792919159 and batch: 400, loss is 4.299951868057251 and perplexity is 73.69624647071304
At time: 183.5871696472168 and batch: 450, loss is 4.313938140869141 and perplexity is 74.73422407770786
At time: 184.66270542144775 and batch: 500, loss is 4.349043006896973 and perplexity is 77.40435203806831
At time: 185.7085726261139 and batch: 550, loss is 4.298557033538819 and perplexity is 73.59352405929381
At time: 186.75626969337463 and batch: 600, loss is 4.2867710447311405 and perplexity is 72.73124300739181
At time: 187.8036711215973 and batch: 650, loss is 4.338448715209961 and perplexity is 76.58863634928281
At time: 188.85275721549988 and batch: 700, loss is 4.3654353809356685 and perplexity is 78.68364984645008
At time: 189.89930629730225 and batch: 750, loss is 4.319410619735717 and perplexity is 75.144326654947
At time: 190.94533514976501 and batch: 800, loss is 4.295590887069702 and perplexity is 73.37555830673482
At time: 191.9906632900238 and batch: 850, loss is 4.299552621841431 and perplexity is 73.66682939590811
At time: 193.0379900932312 and batch: 900, loss is 4.307843322753906 and perplexity is 74.28011782818459
At time: 194.0847852230072 and batch: 950, loss is 4.384136800765991 and perplexity is 80.16899152475432
At time: 195.13379216194153 and batch: 1000, loss is 4.362252540588379 and perplexity is 78.43361047982378
At time: 196.18224835395813 and batch: 1050, loss is 4.308704490661621 and perplexity is 74.34411303319294
At time: 197.22850513458252 and batch: 1100, loss is 4.364909353256226 and perplexity is 78.64227095288712
At time: 198.27436518669128 and batch: 1150, loss is 4.308588008880616 and perplexity is 74.33545380283063
At time: 199.32104682922363 and batch: 1200, loss is 4.368272695541382 and perplexity is 78.90721713076788
At time: 200.3669786453247 and batch: 1250, loss is 4.353898553848267 and perplexity is 77.78110643775496
At time: 201.41348910331726 and batch: 1300, loss is 4.364493770599365 and perplexity is 78.6095953791541
At time: 202.45953178405762 and batch: 1350, loss is 4.260090804100036 and perplexity is 70.81641358303433
At time: 203.5041892528534 and batch: 1400, loss is 4.276130475997925 and perplexity is 71.9614440297346
At time: 204.5517234802246 and batch: 1450, loss is 4.211551442146301 and perplexity is 67.46112068942197
At time: 205.5994827747345 and batch: 1500, loss is 4.21468936920166 and perplexity is 67.67314124376186
At time: 206.64663982391357 and batch: 1550, loss is 4.217394323348999 and perplexity is 67.85644178584927
At time: 207.69470977783203 and batch: 1600, loss is 4.320796813964844 and perplexity is 75.2485635164844
At time: 208.7425045967102 and batch: 1650, loss is 4.269148135185242 and perplexity is 71.46073479765765
At time: 209.79113793373108 and batch: 1700, loss is 4.296789684295654 and perplexity is 73.46357346811064
At time: 210.840678691864 and batch: 1750, loss is 4.307488594055176 and perplexity is 74.2537732115179
At time: 211.8887038230896 and batch: 1800, loss is 4.260627932548523 and perplexity is 70.85446131073331
At time: 212.93622660636902 and batch: 1850, loss is 4.290133714675903 and perplexity is 72.97622583965529
At time: 213.98345923423767 and batch: 1900, loss is 4.375588226318359 and perplexity is 79.48658190280482
At time: 215.0312705039978 and batch: 1950, loss is 4.305084190368652 and perplexity is 74.07545162991268
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.613216524345931 and perplexity of 100.80787971380269
finished 5 epochs...
Completing Train Step...
At time: 218.37447333335876 and batch: 50, loss is 4.251516041755676 and perplexity is 70.21177568436293
At time: 219.45566248893738 and batch: 100, loss is 4.212824139595032 and perplexity is 67.54703294416922
At time: 220.50989198684692 and batch: 150, loss is 4.175629024505615 and perplexity is 65.08076418391953
At time: 221.56404948234558 and batch: 200, loss is 4.16930046081543 and perplexity is 64.67019694353246
At time: 222.61789059638977 and batch: 250, loss is 4.165352010726929 and perplexity is 64.415353348385
At time: 223.67141580581665 and batch: 300, loss is 4.2023708581924435 and perplexity is 66.84462244428684
At time: 224.72718262672424 and batch: 350, loss is 4.210877323150635 and perplexity is 67.41565919144763
At time: 225.78105783462524 and batch: 400, loss is 4.1750187587738035 and perplexity is 65.04105974010095
At time: 226.83474016189575 and batch: 450, loss is 4.195320777893066 and perplexity is 66.37501980172064
At time: 227.88902020454407 and batch: 500, loss is 4.232983875274658 and perplexity is 68.9225820407069
At time: 228.9474265575409 and batch: 550, loss is 4.181417121887207 and perplexity is 65.4585502612696
At time: 230.00431299209595 and batch: 600, loss is 4.173252825736999 and perplexity is 64.92630294019185
At time: 231.06406807899475 and batch: 650, loss is 4.217928810119629 and perplexity is 67.892719850495
At time: 232.12054443359375 and batch: 700, loss is 4.240236735343933 and perplexity is 69.4242850755191
At time: 233.17337679862976 and batch: 750, loss is 4.203707451820374 and perplexity is 66.93402627569309
At time: 234.2267472743988 and batch: 800, loss is 4.174371113777161 and perplexity is 64.99894986078215
At time: 235.2801649570465 and batch: 850, loss is 4.182501111030579 and perplexity is 65.52954509095422
At time: 236.33365511894226 and batch: 900, loss is 4.1912018585205075 and perplexity is 66.10218871715134
At time: 237.43485569953918 and batch: 950, loss is 4.264934720993042 and perplexity is 71.16027454971487
At time: 238.48806142807007 and batch: 1000, loss is 4.245821228027344 and perplexity is 69.81306905782435
At time: 239.54047679901123 and batch: 1050, loss is 4.190600824356079 and perplexity is 66.06247098044284
At time: 240.59250354766846 and batch: 1100, loss is 4.245979480743408 and perplexity is 69.82411803986216
At time: 241.64646935462952 and batch: 1150, loss is 4.190058097839356 and perplexity is 66.02662685334043
At time: 242.70103073120117 and batch: 1200, loss is 4.252008752822876 and perplexity is 70.2463783271429
At time: 243.75520372390747 and batch: 1250, loss is 4.24128942489624 and perplexity is 69.4974057750403
At time: 244.8098349571228 and batch: 1300, loss is 4.255012426376343 and perplexity is 70.45769271679866
At time: 245.8637318611145 and batch: 1350, loss is 4.142891540527343 and perplexity is 62.98468115329506
At time: 246.9177589416504 and batch: 1400, loss is 4.163875679969788 and perplexity is 64.32032514479445
At time: 247.97318387031555 and batch: 1450, loss is 4.0966788053512575 and perplexity is 60.14021817573894
At time: 249.02873754501343 and batch: 1500, loss is 4.0996844720840455 and perplexity is 60.32125155552752
At time: 250.08247542381287 and batch: 1550, loss is 4.109715452194214 and perplexity is 60.92937778198418
At time: 251.13559913635254 and batch: 1600, loss is 4.20812903881073 and perplexity is 67.23063615544119
At time: 252.1885313987732 and batch: 1650, loss is 4.15780020236969 and perplexity is 63.9307331272997
At time: 253.25202250480652 and batch: 1700, loss is 4.185057854652404 and perplexity is 65.69730170134393
At time: 254.304838180542 and batch: 1750, loss is 4.193346796035766 and perplexity is 66.24412595040144
At time: 255.36761784553528 and batch: 1800, loss is 4.1446125078201295 and perplexity is 63.09316905479554
At time: 256.42357659339905 and batch: 1850, loss is 4.1766201877594 and perplexity is 65.14530182429216
At time: 257.4804894924164 and batch: 1900, loss is 4.263851156234741 and perplexity is 71.08320954402416
At time: 258.5305800437927 and batch: 1950, loss is 4.192607436180115 and perplexity is 66.19516580481445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6131952330123545 and perplexity of 100.80573340245759
finished 6 epochs...
Completing Train Step...
At time: 261.8502013683319 and batch: 50, loss is 4.143003244400024 and perplexity is 62.99171717906778
At time: 262.89485025405884 and batch: 100, loss is 4.104807124137879 and perplexity is 60.63104915388582
At time: 263.978883266449 and batch: 150, loss is 4.074505944252014 and perplexity is 58.821412351397015
At time: 265.02194261550903 and batch: 200, loss is 4.064375267028809 and perplexity is 58.22851988091013
At time: 266.0676691532135 and batch: 250, loss is 4.052688007354736 and perplexity is 57.551949377367556
At time: 267.1130738258362 and batch: 300, loss is 4.095090718269348 and perplexity is 60.04478606945523
At time: 268.15844535827637 and batch: 350, loss is 4.102664008140564 and perplexity is 60.50124892066871
At time: 269.2021644115448 and batch: 400, loss is 4.063057169914246 and perplexity is 58.151819597185956
At time: 270.2474699020386 and batch: 450, loss is 4.090608997344971 and perplexity is 59.77628421992984
At time: 271.2917220592499 and batch: 500, loss is 4.129227094650268 and perplexity is 62.12988385271255
At time: 272.3358633518219 and batch: 550, loss is 4.08261164188385 and perplexity is 59.30013851785588
At time: 273.37965655326843 and batch: 600, loss is 4.07409010887146 and perplexity is 58.7969574119741
At time: 274.423691034317 and batch: 650, loss is 4.121195960044861 and perplexity is 61.63290870084542
At time: 275.46755027770996 and batch: 700, loss is 4.140937852859497 and perplexity is 62.861748883194295
At time: 276.5127205848694 and batch: 750, loss is 4.103976449966431 and perplexity is 60.580705419880495
At time: 277.55798268318176 and batch: 800, loss is 4.074785280227661 and perplexity is 58.83784558309469
At time: 278.60154581069946 and batch: 850, loss is 4.080893549919129 and perplexity is 59.198342898519655
At time: 279.6470613479614 and batch: 900, loss is 4.089576663970948 and perplexity is 59.71460700795421
At time: 280.6924946308136 and batch: 950, loss is 4.167089524269104 and perplexity is 64.5273731869632
At time: 281.736704826355 and batch: 1000, loss is 4.142136354446411 and perplexity is 62.937133954527155
At time: 282.7814862728119 and batch: 1050, loss is 4.094794397354126 and perplexity is 60.02699617938124
At time: 283.8292624950409 and batch: 1100, loss is 4.145959782600403 and perplexity is 63.178230177756895
At time: 284.8796224594116 and batch: 1150, loss is 4.095031476020813 and perplexity is 60.04122898668149
At time: 285.92334604263306 and batch: 1200, loss is 4.15499517917633 and perplexity is 63.75165721157404
At time: 286.9676249027252 and batch: 1250, loss is 4.142633366584778 and perplexity is 62.96842224874352
At time: 288.01321363449097 and batch: 1300, loss is 4.153782448768616 and perplexity is 63.67439049964668
At time: 289.06498646736145 and batch: 1350, loss is 4.045739178657532 and perplexity is 57.15341701016288
At time: 290.11225414276123 and batch: 1400, loss is 4.071255764961243 and perplexity is 58.630542563657954
At time: 291.15747332572937 and batch: 1450, loss is 4.000722036361695 and perplexity is 54.63758611817982
At time: 292.2023570537567 and batch: 1500, loss is 4.001190881729126 and perplexity is 54.66320870336481
At time: 293.2575435638428 and batch: 1550, loss is 4.008460364341736 and perplexity is 55.06202980379149
At time: 294.3025395870209 and batch: 1600, loss is 4.111489925384522 and perplexity is 61.0375913119695
At time: 295.34794640541077 and batch: 1650, loss is 4.060498323440552 and perplexity is 58.00320823658728
At time: 296.39413118362427 and batch: 1700, loss is 4.090839443206787 and perplexity is 59.79006100460361
At time: 297.44037914276123 and batch: 1750, loss is 4.097610149383545 and perplexity is 60.19625550000058
At time: 298.4875133037567 and batch: 1800, loss is 4.047576632499695 and perplexity is 57.25853031669148
At time: 299.53266501426697 and batch: 1850, loss is 4.07971116065979 and perplexity is 59.128388778355884
At time: 300.5771839618683 and batch: 1900, loss is 4.166893520355225 and perplexity is 64.51472680867649
At time: 301.6230959892273 and batch: 1950, loss is 4.0935594177246095 and perplexity is 59.9529098188679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.617695653161337 and perplexity of 101.26042393798548
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 304.90380668640137 and batch: 50, loss is 4.074872207641602 and perplexity is 58.84296042715994
At time: 305.9753394126892 and batch: 100, loss is 4.066600179672241 and perplexity is 58.35821748041317
At time: 307.0194227695465 and batch: 150, loss is 4.034390816688537 and perplexity is 56.50848572446292
At time: 308.06497740745544 and batch: 200, loss is 4.023636469841003 and perplexity is 55.90402995836665
At time: 309.11459708213806 and batch: 250, loss is 4.013757681846618 and perplexity is 55.354484787683006
At time: 310.16138076782227 and batch: 300, loss is 4.051143207550049 and perplexity is 57.463111773033816
At time: 311.20936465263367 and batch: 350, loss is 4.057211213111877 and perplexity is 57.81285831369105
At time: 312.2556803226471 and batch: 400, loss is 4.0141712045669555 and perplexity is 55.37737985830496
At time: 313.29985451698303 and batch: 450, loss is 4.033583488464355 and perplexity is 56.46288323959523
At time: 314.3456332683563 and batch: 500, loss is 4.0641279220581055 and perplexity is 58.2141191304161
At time: 315.39164423942566 and batch: 550, loss is 4.017990608215332 and perplexity is 55.589292858002615
At time: 316.470175743103 and batch: 600, loss is 3.9957591819763185 and perplexity is 54.36709948237207
At time: 317.516939163208 and batch: 650, loss is 4.027413506507873 and perplexity is 56.1155807954808
At time: 318.5633108615875 and batch: 700, loss is 4.041365189552307 and perplexity is 56.90397451390439
At time: 319.6059021949768 and batch: 750, loss is 3.9922922134399412 and perplexity is 54.17893682453401
At time: 320.6495370864868 and batch: 800, loss is 3.956753931045532 and perplexity is 52.28732192357314
At time: 321.6937596797943 and batch: 850, loss is 3.962777924537659 and perplexity is 52.60325103262779
At time: 322.73825335502625 and batch: 900, loss is 3.9614542627334597 and perplexity is 52.533668180700424
At time: 323.78196263313293 and batch: 950, loss is 4.0344596862792965 and perplexity is 56.512377574762716
At time: 324.8266570568085 and batch: 1000, loss is 3.998651704788208 and perplexity is 54.524585213573296
At time: 325.8693690299988 and batch: 1050, loss is 3.9469550609588624 and perplexity is 51.77746732792594
At time: 326.91379499435425 and batch: 1100, loss is 3.9797967958450315 and perplexity is 53.50616044861049
At time: 327.95773696899414 and batch: 1150, loss is 3.931581025123596 and perplexity is 50.98752653797679
At time: 329.0037603378296 and batch: 1200, loss is 3.980640187263489 and perplexity is 53.551306120227416
At time: 330.0498626232147 and batch: 1250, loss is 3.9542341136932375 and perplexity is 52.155733281783185
At time: 331.0984163284302 and batch: 1300, loss is 3.9646592998504637 and perplexity is 52.7023106454298
At time: 332.14729714393616 and batch: 1350, loss is 3.8466100454330445 and perplexity is 46.83402859465841
At time: 333.1972014904022 and batch: 1400, loss is 3.8680185174942014 and perplexity is 47.84748313682674
At time: 334.24772548675537 and batch: 1450, loss is 3.791970663070679 and perplexity is 44.34370072127753
At time: 335.297842502594 and batch: 1500, loss is 3.7882500791549685 and perplexity is 44.17902280058852
At time: 336.34779477119446 and batch: 1550, loss is 3.785346188545227 and perplexity is 44.050917842543974
At time: 337.39583587646484 and batch: 1600, loss is 3.87484721660614 and perplexity is 48.17533733725865
At time: 338.4453270435333 and batch: 1650, loss is 3.812461395263672 and perplexity is 45.26170882619599
At time: 339.494754076004 and batch: 1700, loss is 3.832026929855347 and perplexity is 46.15599845483218
At time: 340.5453128814697 and batch: 1750, loss is 3.8294241714477537 and perplexity is 46.036021744718845
At time: 341.5960168838501 and batch: 1800, loss is 3.7702943181991575 and perplexity is 43.39283425745785
At time: 342.6464190483093 and batch: 1850, loss is 3.7962882804870604 and perplexity is 44.535573774965876
At time: 343.69610118865967 and batch: 1900, loss is 3.8690192127227783 and perplexity is 47.89538784991247
At time: 344.7465064525604 and batch: 1950, loss is 3.8017093420028685 and perplexity is 44.77765944783848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.536925417877907 and perplexity of 93.4031824390832
finished 8 epochs...
Completing Train Step...
At time: 348.03757786750793 and batch: 50, loss is 3.9746965742111207 and perplexity is 53.2339618980525
At time: 349.11058378219604 and batch: 100, loss is 3.952485694885254 and perplexity is 52.06462288954097
At time: 350.1547746658325 and batch: 150, loss is 3.9176288509368895 and perplexity is 50.28107938314793
At time: 351.1989414691925 and batch: 200, loss is 3.9070193719863893 and perplexity is 49.750443193967996
At time: 352.24279260635376 and batch: 250, loss is 3.8937597942352293 and perplexity is 49.09512753002378
At time: 353.288813829422 and batch: 300, loss is 3.933432550430298 and perplexity is 51.082018683993404
At time: 354.3329496383667 and batch: 350, loss is 3.9427483606338503 and perplexity is 51.56011253306405
At time: 355.3773703575134 and batch: 400, loss is 3.903123893737793 and perplexity is 49.55701841026438
At time: 356.42253255844116 and batch: 450, loss is 3.931063241958618 and perplexity is 50.96113288879483
At time: 357.46510076522827 and batch: 500, loss is 3.9650448608398436 and perplexity is 52.72263451825934
At time: 358.5081169605255 and batch: 550, loss is 3.9203218603134156 and perplexity is 50.41666929189153
At time: 359.55243849754333 and batch: 600, loss is 3.90233868598938 and perplexity is 49.518121128642356
At time: 360.5960156917572 and batch: 650, loss is 3.935651421546936 and perplexity is 51.1954889412142
At time: 361.6399805545807 and batch: 700, loss is 3.952405104637146 and perplexity is 52.060427157734445
At time: 362.68279504776 and batch: 750, loss is 3.909082083702087 and perplexity is 49.853169927400344
At time: 363.725448846817 and batch: 800, loss is 3.877641882896423 and perplexity is 48.31015963245125
At time: 364.76898884773254 and batch: 850, loss is 3.8868663358688353 and perplexity is 48.75785613116304
At time: 365.811710357666 and batch: 900, loss is 3.8838192892074583 and perplexity is 48.60951478469776
At time: 366.8564622402191 and batch: 950, loss is 3.958669176101685 and perplexity is 52.387560918865724
At time: 367.9032745361328 and batch: 1000, loss is 3.9265436697006226 and perplexity is 50.73133006276608
At time: 368.9939856529236 and batch: 1050, loss is 3.8806886577606203 and perplexity is 48.457574268072484
At time: 370.03638792037964 and batch: 1100, loss is 3.9124917697906496 and perplexity is 50.02344371248435
At time: 371.0801405906677 and batch: 1150, loss is 3.8715775489807127 and perplexity is 48.01807723066466
At time: 372.12419390678406 and batch: 1200, loss is 3.920951704978943 and perplexity is 50.448433964453365
At time: 373.16802310943604 and batch: 1250, loss is 3.9027954578399657 and perplexity is 49.54074477899779
At time: 374.21024894714355 and batch: 1300, loss is 3.9144427490234377 and perplexity is 50.121133676879246
At time: 375.25435161590576 and batch: 1350, loss is 3.798458948135376 and perplexity is 44.632350701430624
At time: 376.298752784729 and batch: 1400, loss is 3.8240172052383423 and perplexity is 45.78777825759149
At time: 377.34291887283325 and batch: 1450, loss is 3.7519241189956665 and perplexity is 42.60297638365894
At time: 378.38696217536926 and batch: 1500, loss is 3.7513796138763427 and perplexity is 42.57978515936277
At time: 379.43203234672546 and batch: 1550, loss is 3.750498161315918 and perplexity is 42.54226963521812
At time: 380.4760386943817 and batch: 1600, loss is 3.8444285583496094 and perplexity is 46.73197212412298
At time: 381.5204837322235 and batch: 1650, loss is 3.7852876377105713 and perplexity is 44.04833870004315
At time: 382.5636656284332 and batch: 1700, loss is 3.8102887296676635 and perplexity is 45.16347701968772
At time: 383.6079134941101 and batch: 1750, loss is 3.8120228052139282 and perplexity is 45.24186184373309
At time: 384.65071392059326 and batch: 1800, loss is 3.757429151535034 and perplexity is 42.83815389091146
At time: 385.69215059280396 and batch: 1850, loss is 3.7862824010849 and perplexity is 44.09217817541907
At time: 386.7355558872223 and batch: 1900, loss is 3.8615583419799804 and perplexity is 47.5393762815703
At time: 387.7786636352539 and batch: 1950, loss is 3.7992087602615356 and perplexity is 44.66582912890249
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.537334211482558 and perplexity of 93.44137286818814
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 391.0732858181 and batch: 50, loss is 3.9406519889831544 and perplexity is 51.45213659323681
At time: 392.12071895599365 and batch: 100, loss is 3.9405926132202147 and perplexity is 51.44908167406668
At time: 393.16897892951965 and batch: 150, loss is 3.9138927555084226 and perplexity is 50.09357495764488
At time: 394.21726846694946 and batch: 200, loss is 3.9060732030868532 and perplexity is 49.70339313404151
At time: 395.29120445251465 and batch: 250, loss is 3.8986908054351805 and perplexity is 49.33781400686437
At time: 396.3408613204956 and batch: 300, loss is 3.935090670585632 and perplexity is 51.16678906906848
At time: 397.3898346424103 and batch: 350, loss is 3.944634294509888 and perplexity is 51.65744324673913
At time: 398.43888449668884 and batch: 400, loss is 3.915139174461365 and perplexity is 50.156051466756836
At time: 399.48699975013733 and batch: 450, loss is 3.9450943231582642 and perplexity is 51.681212617411056
At time: 400.5353591442108 and batch: 500, loss is 3.9743886470794676 and perplexity is 53.21757224039834
At time: 401.5838894844055 and batch: 550, loss is 3.9325953912734986 and perplexity is 51.03927279935515
At time: 402.63223576545715 and batch: 600, loss is 3.9053980255126954 and perplexity is 49.669845844101204
At time: 403.6812882423401 and batch: 650, loss is 3.930597152709961 and perplexity is 50.937385987173634
At time: 404.7304689884186 and batch: 700, loss is 3.9431300020217894 and perplexity is 51.579793761320225
At time: 405.78034806251526 and batch: 750, loss is 3.89370653629303 and perplexity is 49.09251289418519
At time: 406.8288154602051 and batch: 800, loss is 3.8565136098861696 and perplexity is 47.30015677082555
At time: 407.87720799446106 and batch: 850, loss is 3.8652502346038817 and perplexity is 47.715210935820764
At time: 408.93178129196167 and batch: 900, loss is 3.852154784202576 and perplexity is 47.09443231689098
At time: 409.98468232154846 and batch: 950, loss is 3.9351051378250124 and perplexity is 51.16752931660891
At time: 411.03668785095215 and batch: 1000, loss is 3.8965410661697386 and perplexity is 49.23186449353995
At time: 412.08445167541504 and batch: 1050, loss is 3.853122215270996 and perplexity is 47.14001497935072
At time: 413.13247656822205 and batch: 1100, loss is 3.8821609449386596 and perplexity is 48.528970278164685
At time: 414.18025374412537 and batch: 1150, loss is 3.8406890439987182 and perplexity is 46.55754358599702
At time: 415.2443308830261 and batch: 1200, loss is 3.885409994125366 and perplexity is 48.6868997108967
At time: 416.29290223121643 and batch: 1250, loss is 3.8598919248580934 and perplexity is 47.460221821461964
At time: 417.34275817871094 and batch: 1300, loss is 3.867267107963562 and perplexity is 47.81154358633201
At time: 418.39112663269043 and batch: 1350, loss is 3.7479520082473754 and perplexity is 42.43408828642427
At time: 419.4422290325165 and batch: 1400, loss is 3.774281210899353 and perplexity is 43.56618216172855
At time: 420.49146580696106 and batch: 1450, loss is 3.697217035293579 and perplexity is 40.334897424379136
At time: 421.53945994377136 and batch: 1500, loss is 3.6952270078659057 and perplexity is 40.25470968657438
At time: 422.58770203590393 and batch: 1550, loss is 3.6962552642822266 and perplexity is 40.29612313827154
At time: 423.63645911216736 and batch: 1600, loss is 3.7853840160369874 and perplexity is 44.05258420979274
At time: 424.68621850013733 and batch: 1650, loss is 3.7188177061080934 and perplexity is 41.21563629621439
At time: 425.7373061180115 and batch: 1700, loss is 3.7344637537002563 and perplexity is 41.865569285976825
At time: 426.78695273399353 and batch: 1750, loss is 3.7356880140304565 and perplexity is 41.91685502879947
At time: 427.83714175224304 and batch: 1800, loss is 3.6777081060409547 and perplexity is 39.555632788847745
At time: 428.89189052581787 and batch: 1850, loss is 3.6987726163864134 and perplexity is 40.397690455357406
At time: 429.94804406166077 and batch: 1900, loss is 3.7768499088287353 and perplexity is 43.6782343761721
At time: 431.00000047683716 and batch: 1950, loss is 3.721600170135498 and perplexity is 41.33047701757083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504372956031977 and perplexity of 90.41163420107837
finished 10 epochs...
Completing Train Step...
At time: 434.29871439933777 and batch: 50, loss is 3.923417625427246 and perplexity is 50.57298929800721
At time: 435.36875772476196 and batch: 100, loss is 3.9098382902145388 and perplexity is 49.8908834769845
At time: 436.4114911556244 and batch: 150, loss is 3.8744976854324342 and perplexity is 48.158501497552294
At time: 437.4531726837158 and batch: 200, loss is 3.861548662185669 and perplexity is 47.538916112413375
At time: 438.49451780319214 and batch: 250, loss is 3.8530363130569456 and perplexity is 47.135965721616216
At time: 439.5360703468323 and batch: 300, loss is 3.8875041151046754 and perplexity is 48.78896279792623
At time: 440.5801923274994 and batch: 350, loss is 3.8985342025756835 and perplexity is 49.3300881690695
At time: 441.62270522117615 and batch: 400, loss is 3.8672631931304933 and perplexity is 47.81135641248648
At time: 442.6644694805145 and batch: 450, loss is 3.90067400932312 and perplexity is 49.43575804081774
At time: 443.7072491645813 and batch: 500, loss is 3.9304474449157714 and perplexity is 50.929760834262375
At time: 444.7497408390045 and batch: 550, loss is 3.8893250799179078 and perplexity is 48.87788672155135
At time: 445.7923638820648 and batch: 600, loss is 3.86404492855072 and perplexity is 47.65773414876996
At time: 446.83502554893494 and batch: 650, loss is 3.8907700681686403 and perplexity is 48.94856574646682
At time: 447.9225881099701 and batch: 700, loss is 3.9063442850112917 and perplexity is 49.71686865190555
At time: 448.97415494918823 and batch: 750, loss is 3.8592523622512815 and perplexity is 47.42987774277732
At time: 450.01584553718567 and batch: 800, loss is 3.8244179010391237 and perplexity is 45.806128904334436
At time: 451.0571780204773 and batch: 850, loss is 3.835004382133484 and perplexity is 46.2936305323744
At time: 452.1009635925293 and batch: 900, loss is 3.824528708457947 and perplexity is 45.81120484446533
At time: 453.14431524276733 and batch: 950, loss is 3.907352089881897 and perplexity is 49.76699881075033
At time: 454.18735933303833 and batch: 1000, loss is 3.8699895000457762 and perplexity is 47.94188269060282
At time: 455.2305235862732 and batch: 1050, loss is 3.8288256311416626 and perplexity is 46.008475574741425
At time: 456.27361607551575 and batch: 1100, loss is 3.8587946462631226 and perplexity is 47.40817329703288
At time: 457.31705689430237 and batch: 1150, loss is 3.8193713283538817 and perplexity is 45.575547258276416
At time: 458.3609745502472 and batch: 1200, loss is 3.865324239730835 and perplexity is 47.71874223672925
At time: 459.4051887989044 and batch: 1250, loss is 3.8425211238861086 and perplexity is 46.64291890853256
At time: 460.45148611068726 and batch: 1300, loss is 3.8521149730682374 and perplexity is 47.09255747143953
At time: 461.4959270954132 and batch: 1350, loss is 3.734556345939636 and perplexity is 41.86944589225898
At time: 462.5398733615875 and batch: 1400, loss is 3.763100752830505 and perplexity is 43.08180511318038
At time: 463.582505941391 and batch: 1450, loss is 3.688894896507263 and perplexity is 40.000617700502445
At time: 464.62385988235474 and batch: 1500, loss is 3.6887204456329346 and perplexity is 39.99364016640707
At time: 465.6661536693573 and batch: 1550, loss is 3.6916073894500734 and perplexity is 40.10926638149705
At time: 466.7073104381561 and batch: 1600, loss is 3.7826805782318114 and perplexity is 43.93365162408417
At time: 467.74890780448914 and batch: 1650, loss is 3.7179862117767333 and perplexity is 41.18137997221399
At time: 468.79289388656616 and batch: 1700, loss is 3.7363629722595215 and perplexity is 41.94515670518793
At time: 469.8340849876404 and batch: 1750, loss is 3.739496936798096 and perplexity is 42.076817541301224
At time: 470.87558913230896 and batch: 1800, loss is 3.683626503944397 and perplexity is 39.79043289788108
At time: 471.91754388809204 and batch: 1850, loss is 3.7060267734527588 and perplexity is 40.69180714158801
At time: 472.9592032432556 and batch: 1900, loss is 3.7848387956619263 and perplexity is 44.02857238976905
At time: 474.00793266296387 and batch: 1950, loss is 3.7300319385528566 and perplexity is 41.68043935568646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504065225290698 and perplexity of 90.38381604233624
finished 11 epochs...
Completing Train Step...
At time: 477.2843699455261 and batch: 50, loss is 3.906774377822876 and perplexity is 49.73825611869539
At time: 478.36494159698486 and batch: 100, loss is 3.8911936330795287 and perplexity is 48.969303032838724
At time: 479.4109764099121 and batch: 150, loss is 3.854753532409668 and perplexity is 47.21697805222588
At time: 480.45415210723877 and batch: 200, loss is 3.8404692125320437 and perplexity is 46.54730989779029
At time: 481.4977033138275 and batch: 250, loss is 3.8314242219924926 and perplexity is 46.12818825320101
At time: 482.54182291030884 and batch: 300, loss is 3.866270008087158 and perplexity is 47.76389446154737
At time: 483.5858817100525 and batch: 350, loss is 3.877316370010376 and perplexity is 48.294436612125594
At time: 484.6302421092987 and batch: 400, loss is 3.8457226276397707 and perplexity is 46.79248568003992
At time: 485.67591404914856 and batch: 450, loss is 3.880253767967224 and perplexity is 48.43650514531585
At time: 486.72051787376404 and batch: 500, loss is 3.9103548431396487 and perplexity is 49.91666141604257
At time: 487.76391100883484 and batch: 550, loss is 3.8690919971466062 and perplexity is 47.898874014988856
At time: 488.80993127822876 and batch: 600, loss is 3.8444635677337646 and perplexity is 46.73360821032642
At time: 489.8541114330292 and batch: 650, loss is 3.8715501165390016 and perplexity is 48.01675999562752
At time: 490.8991057872772 and batch: 700, loss is 3.8880152893066406 and perplexity is 48.8139088323906
At time: 491.94430589675903 and batch: 750, loss is 3.841803617477417 and perplexity is 46.60946431867215
At time: 492.98753929138184 and batch: 800, loss is 3.8079935121536255 and perplexity is 45.0599358864033
At time: 494.02950501441956 and batch: 850, loss is 3.8192286920547485 and perplexity is 45.56904699448233
At time: 495.0723421573639 and batch: 900, loss is 3.809488158226013 and perplexity is 45.12733489888534
At time: 496.1153562068939 and batch: 950, loss is 3.89242723941803 and perplexity is 49.02974915114386
At time: 497.1583390235901 and batch: 1000, loss is 3.855434956550598 and perplexity is 47.24916380576174
At time: 498.20169401168823 and batch: 1050, loss is 3.8155628490447997 and perplexity is 45.40230383593881
At time: 499.24473905563354 and batch: 1100, loss is 3.8457372283935545 and perplexity is 46.793168890589946
At time: 500.31305027008057 and batch: 1150, loss is 3.8071659851074218 and perplexity is 45.022662995046986
At time: 501.3573319911957 and batch: 1200, loss is 3.8537373781204223 and perplexity is 47.16902268660456
At time: 502.4003655910492 and batch: 1250, loss is 3.8323443365097045 and perplexity is 46.170651001165105
At time: 503.44446206092834 and batch: 1300, loss is 3.842734303474426 and perplexity is 46.652863286714975
At time: 504.4881434440613 and batch: 1350, loss is 3.726022710800171 and perplexity is 41.51366751800704
At time: 505.53197860717773 and batch: 1400, loss is 3.7556065559387206 and perplexity is 42.76014836813042
At time: 506.5738003253937 and batch: 1450, loss is 3.6823958015441893 and perplexity is 39.741492838110034
At time: 507.61530447006226 and batch: 1500, loss is 3.6827943754196166 and perplexity is 39.75733591603453
At time: 508.6585042476654 and batch: 1550, loss is 3.6865993547439575 and perplexity is 39.908899923282604
At time: 509.7029535770416 and batch: 1600, loss is 3.7784911441802977 and perplexity is 43.7499794977343
At time: 510.7471430301666 and batch: 1650, loss is 3.714526882171631 and perplexity is 41.03916612939777
At time: 511.79096841812134 and batch: 1700, loss is 3.7338418483734133 and perplexity is 41.8395409598428
At time: 512.8348145484924 and batch: 1750, loss is 3.7379660415649414 and perplexity is 42.0124516232104
At time: 513.8797063827515 and batch: 1800, loss is 3.6831809091567993 and perplexity is 39.77270643808787
At time: 514.9239566326141 and batch: 1850, loss is 3.7061949968338013 and perplexity is 40.698653030769265
At time: 515.9688718318939 and batch: 1900, loss is 3.785283522605896 and perplexity is 44.048157436891586
At time: 517.0135443210602 and batch: 1950, loss is 3.7307850551605224 and perplexity is 41.71184141000011
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.505076137808866 and perplexity of 90.47523237258439
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 520.3247857093811 and batch: 50, loss is 3.8984140157699585 and perplexity is 49.324159699615365
At time: 521.3734998703003 and batch: 100, loss is 3.8920108127593993 and perplexity is 49.00933610709421
At time: 522.4241774082184 and batch: 150, loss is 3.860436053276062 and perplexity is 47.486053304062665
At time: 523.4735019207001 and batch: 200, loss is 3.846923532485962 and perplexity is 46.84871275778605
At time: 524.5230433940887 and batch: 250, loss is 3.842273335456848 and perplexity is 46.63136276471858
At time: 525.5729830265045 and batch: 300, loss is 3.8757204532623293 and perplexity is 48.21742418095874
At time: 526.6482479572296 and batch: 350, loss is 3.887384867668152 and perplexity is 48.78314518605648
At time: 527.6980490684509 and batch: 400, loss is 3.8582244300842286 and perplexity is 47.38114809544295
At time: 528.7470669746399 and batch: 450, loss is 3.8943569374084475 and perplexity is 49.1244531051787
At time: 529.8037912845612 and batch: 500, loss is 3.9262937784194945 and perplexity is 50.71865432954692
At time: 530.859979391098 and batch: 550, loss is 3.8882239294052123 and perplexity is 48.82409443366654
At time: 531.9085128307343 and batch: 600, loss is 3.8593939685821534 and perplexity is 47.43659458930095
At time: 532.9579529762268 and batch: 650, loss is 3.88087760925293 and perplexity is 48.46673126413092
At time: 534.0071134567261 and batch: 700, loss is 3.895049638748169 and perplexity is 49.15849346819912
At time: 535.0665898323059 and batch: 750, loss is 3.848975782394409 and perplexity is 46.94495674883553
At time: 536.1172332763672 and batch: 800, loss is 3.8120818853378298 and perplexity is 45.244534817495385
At time: 537.1669690608978 and batch: 850, loss is 3.825272765159607 and perplexity is 45.845303662594894
At time: 538.2176458835602 and batch: 900, loss is 3.8057788801193237 and perplexity is 44.960255127767475
At time: 539.2674627304077 and batch: 950, loss is 3.8919368743896485 and perplexity is 49.00571257064072
At time: 540.3169679641724 and batch: 1000, loss is 3.854687533378601 and perplexity is 47.213861880257824
At time: 541.3665015697479 and batch: 1050, loss is 3.8180128717422486 and perplexity is 45.51367688839578
At time: 542.415057182312 and batch: 1100, loss is 3.8434577083587644 and perplexity is 46.6866244058919
At time: 543.4644911289215 and batch: 1150, loss is 3.804110198020935 and perplexity is 44.885293316007704
At time: 544.5149834156036 and batch: 1200, loss is 3.8486526584625245 and perplexity is 46.92979016030451
At time: 545.5648155212402 and batch: 1250, loss is 3.8240356922149656 and perplexity is 45.78862474300223
At time: 546.6147933006287 and batch: 1300, loss is 3.8308684635162353 and perplexity is 46.10255924401412
At time: 547.6640827655792 and batch: 1350, loss is 3.7113268995285034 and perplexity is 40.908051404400716
At time: 548.7169578075409 and batch: 1400, loss is 3.7399219036102296 and perplexity is 42.09470259232387
At time: 549.7667944431305 and batch: 1450, loss is 3.661464648246765 and perplexity is 38.91830277196269
At time: 550.8158707618713 and batch: 1500, loss is 3.659903244972229 and perplexity is 38.85758302291879
At time: 551.8653109073639 and batch: 1550, loss is 3.6656081867218018 and perplexity is 39.07989681124158
At time: 552.9155435562134 and batch: 1600, loss is 3.754925265312195 and perplexity is 42.73102620131445
At time: 553.9647402763367 and batch: 1650, loss is 3.6911163234710695 and perplexity is 40.08957492063326
At time: 555.0149323940277 and batch: 1700, loss is 3.7064721822738647 and perplexity is 40.70993566843879
At time: 556.0639476776123 and batch: 1750, loss is 3.7105424499511717 and perplexity is 40.87597368408909
At time: 557.1139464378357 and batch: 1800, loss is 3.6569334745407103 and perplexity is 38.742356105250856
At time: 558.1643149852753 and batch: 1850, loss is 3.6788066101074217 and perplexity is 39.59910868717162
At time: 559.2147498130798 and batch: 1900, loss is 3.7585864543914793 and perplexity is 42.88775930748282
At time: 560.2660853862762 and batch: 1950, loss is 3.7054909467697144 and perplexity is 40.67000922601418
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496911337209302 and perplexity of 89.73952766924288
finished 13 epochs...
Completing Train Step...
At time: 563.5573389530182 and batch: 50, loss is 3.8955396127700808 and perplexity is 49.182585754770145
At time: 564.6368317604065 and batch: 100, loss is 3.8818165636062623 and perplexity is 48.5122606841217
At time: 565.690247297287 and batch: 150, loss is 3.8465840911865232 and perplexity is 46.832813068508784
At time: 566.7417044639587 and batch: 200, loss is 3.831783022880554 and perplexity is 46.14474205769321
At time: 567.7874119281769 and batch: 250, loss is 3.825588049888611 and perplexity is 45.859760265589586
At time: 568.8325731754303 and batch: 300, loss is 3.857798252105713 and perplexity is 47.36095959578044
At time: 569.8772492408752 and batch: 350, loss is 3.8689602041244506 and perplexity is 47.89256169359366
At time: 570.9224483966827 and batch: 400, loss is 3.839179825782776 and perplexity is 46.48733108944405
At time: 571.9664933681488 and batch: 450, loss is 3.8765811491012574 and perplexity is 48.25894258210961
At time: 573.0101733207703 and batch: 500, loss is 3.907765464782715 and perplexity is 49.78757549159642
At time: 574.0549745559692 and batch: 550, loss is 3.8696645498275757 and perplexity is 47.926306496242496
At time: 575.0996723175049 and batch: 600, loss is 3.842435960769653 and perplexity is 46.6389468213378
At time: 576.1439273357391 and batch: 650, loss is 3.865497317314148 and perplexity is 47.72700199608328
At time: 577.1869311332703 and batch: 700, loss is 3.8809845638275147 and perplexity is 48.47191527997696
At time: 578.2304320335388 and batch: 750, loss is 3.8361152267456053 and perplexity is 46.34508413561475
At time: 579.3357286453247 and batch: 800, loss is 3.7996611070632933 and perplexity is 44.686038144253935
At time: 580.3893637657166 and batch: 850, loss is 3.811909008026123 and perplexity is 45.23671374000961
At time: 581.43714594841 and batch: 900, loss is 3.7944812679290774 and perplexity is 44.455170100980304
At time: 582.4784164428711 and batch: 950, loss is 3.88075129032135 and perplexity is 48.46060938508323
At time: 583.5231781005859 and batch: 1000, loss is 3.8434937477111815 and perplexity is 46.6883069919215
At time: 584.5677647590637 and batch: 1050, loss is 3.807266697883606 and perplexity is 45.02719758076994
At time: 585.6120874881744 and batch: 1100, loss is 3.8338903045654296 and perplexity is 46.242084555494195
At time: 586.6569941043854 and batch: 1150, loss is 3.7962796688079834 and perplexity is 44.53519025054841
At time: 587.7014486789703 and batch: 1200, loss is 3.8413881731033324 and perplexity is 46.59010470064251
At time: 588.7449116706848 and batch: 1250, loss is 3.8181687211990356 and perplexity is 45.520770722985986
At time: 589.7927660942078 and batch: 1300, loss is 3.826216778755188 and perplexity is 45.88860268676414
At time: 590.837482213974 and batch: 1350, loss is 3.7079357862472535 and perplexity is 40.76956251644128
At time: 591.8824172019958 and batch: 1400, loss is 3.7379319524765013 and perplexity is 42.01101948144178
At time: 592.9269313812256 and batch: 1450, loss is 3.661491861343384 and perplexity is 38.91936187390692
At time: 593.9719004631042 and batch: 1500, loss is 3.661127247810364 and perplexity is 38.90517393458571
At time: 595.0178213119507 and batch: 1550, loss is 3.6680635261535643 and perplexity is 39.17596911966917
At time: 596.0625429153442 and batch: 1600, loss is 3.7588048219680785 and perplexity is 42.8971256261615
At time: 597.1105165481567 and batch: 1650, loss is 3.695438027381897 and perplexity is 40.26320511224759
At time: 598.155558347702 and batch: 1700, loss is 3.711958951950073 and perplexity is 40.9339156102585
At time: 599.1997907161713 and batch: 1750, loss is 3.7165497398376464 and perplexity is 41.12226654302696
At time: 600.2480683326721 and batch: 1800, loss is 3.663305039405823 and perplexity is 38.98999362167777
At time: 601.2943716049194 and batch: 1850, loss is 3.685354223251343 and perplexity is 39.85923901874661
At time: 602.339855670929 and batch: 1900, loss is 3.7648274374008177 and perplexity is 43.15625806121073
At time: 603.3854806423187 and batch: 1950, loss is 3.7112254667282105 and perplexity is 40.903902196628685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496245912063953 and perplexity of 89.67983259450463
finished 14 epochs...
Completing Train Step...
At time: 606.6926031112671 and batch: 50, loss is 3.8920596170425417 and perplexity is 49.011728030977785
At time: 607.7651398181915 and batch: 100, loss is 3.8765592908859254 and perplexity is 48.2578877392795
At time: 608.8096439838409 and batch: 150, loss is 3.840504174232483 and perplexity is 46.548937299343386
At time: 609.8543591499329 and batch: 200, loss is 3.824927372932434 and perplexity is 45.82947178531852
At time: 610.8980948925018 and batch: 250, loss is 3.8180978107452392 and perplexity is 45.51754293892003
At time: 611.9420659542084 and batch: 300, loss is 3.849841904640198 and perplexity is 46.9856344335842
At time: 612.9876399040222 and batch: 350, loss is 3.8609604597091676 and perplexity is 47.51096182642196
At time: 614.0314626693726 and batch: 400, loss is 3.8306305408477783 and perplexity is 46.09159170486091
At time: 615.0764305591583 and batch: 450, loss is 3.8683514308929445 and perplexity is 47.86341485685351
At time: 616.1211924552917 and batch: 500, loss is 3.899504179954529 and perplexity is 49.37796045245251
At time: 617.1656978130341 and batch: 550, loss is 3.861296911239624 and perplexity is 47.52694965165524
At time: 618.2117528915405 and batch: 600, loss is 3.8344672822952273 and perplexity is 46.26877290701399
At time: 619.2574491500854 and batch: 650, loss is 3.8577928590774535 and perplexity is 47.36070417747568
At time: 620.3033781051636 and batch: 700, loss is 3.8738510751724244 and perplexity is 48.12737178185868
At time: 621.3474433422089 and batch: 750, loss is 3.829547433853149 and perplexity is 46.04169660523524
At time: 622.3909730911255 and batch: 800, loss is 3.793342638015747 and perplexity is 44.404580921143506
At time: 623.4363176822662 and batch: 850, loss is 3.805558166503906 and perplexity is 44.95033288233574
At time: 624.4812474250793 and batch: 900, loss is 3.789025378227234 and perplexity is 44.21328803716611
At time: 625.5227346420288 and batch: 950, loss is 3.875364594459534 and perplexity is 48.200268638772215
At time: 626.5672421455383 and batch: 1000, loss is 3.83833083152771 and perplexity is 46.44788036150608
At time: 627.620055437088 and batch: 1050, loss is 3.8024449872970583 and perplexity is 44.81061204152026
At time: 628.6655502319336 and batch: 1100, loss is 3.8295499420166017 and perplexity is 46.04181208548077
At time: 629.7118828296661 and batch: 1150, loss is 3.79241753578186 and perplexity is 44.36352113931479
At time: 630.7576858997345 and batch: 1200, loss is 3.8378225898742677 and perplexity is 46.42427961194228
At time: 631.8473229408264 and batch: 1250, loss is 3.8152622604370117 and perplexity is 45.388658471561676
At time: 632.8909709453583 and batch: 1300, loss is 3.823849573135376 and perplexity is 45.78010339932631
At time: 633.9373128414154 and batch: 1350, loss is 3.706071572303772 and perplexity is 40.69363012862716
At time: 634.9812090396881 and batch: 1400, loss is 3.7366505336761473 and perplexity is 41.9572202482923
At time: 636.0268626213074 and batch: 1450, loss is 3.6609206104278567 and perplexity is 38.89713550182684
At time: 637.0726046562195 and batch: 1500, loss is 3.661008367538452 and perplexity is 38.90054915183275
At time: 638.1176884174347 and batch: 1550, loss is 3.6684553623199463 and perplexity is 39.19132268906876
At time: 639.1614496707916 and batch: 1600, loss is 3.7597830200195315 and perplexity is 42.93910804107252
At time: 640.2056977748871 and batch: 1650, loss is 3.6966370058059694 and perplexity is 40.31150877820125
At time: 641.2510030269623 and batch: 1700, loss is 3.713617033958435 and perplexity is 41.00184369887194
At time: 642.2920925617218 and batch: 1750, loss is 3.7185176372528077 and perplexity is 41.20327062278064
At time: 643.3347952365875 and batch: 1800, loss is 3.6656074285507203 and perplexity is 39.07986718200519
At time: 644.3773522377014 and batch: 1850, loss is 3.687780327796936 and perplexity is 39.956059100043426
At time: 645.4227464199066 and batch: 1900, loss is 3.7670621490478515 and perplexity is 43.25280769385659
At time: 646.4661023616791 and batch: 1950, loss is 3.713263201713562 and perplexity is 40.98733849082853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496313760446948 and perplexity of 89.68591743255426
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 649.7654242515564 and batch: 50, loss is 3.8900664472579956 and perplexity is 48.91413662600652
At time: 650.808751821518 and batch: 100, loss is 3.8765964698791504 and perplexity is 48.25968195231412
At time: 651.8543300628662 and batch: 150, loss is 3.841782598495483 and perplexity is 46.60848464547961
At time: 652.8993268013 and batch: 200, loss is 3.825835771560669 and perplexity is 45.87112212931459
At time: 653.945633649826 and batch: 250, loss is 3.820258264541626 and perplexity is 45.615987791851296
At time: 654.989194393158 and batch: 300, loss is 3.8509647989273073 and perplexity is 47.038423967051834
At time: 656.0344734191895 and batch: 350, loss is 3.8622615575790404 and perplexity is 47.57281846969713
At time: 657.0809049606323 and batch: 400, loss is 3.8326460266113282 and perplexity is 46.18458233092416
At time: 658.1708900928497 and batch: 450, loss is 3.870849542617798 and perplexity is 47.98313248644725
At time: 659.217437505722 and batch: 500, loss is 3.90166229724884 and perplexity is 49.48463895381781
At time: 660.262354850769 and batch: 550, loss is 3.864983162879944 and perplexity is 47.70246925372531
At time: 661.3069994449615 and batch: 600, loss is 3.836291823387146 and perplexity is 46.35326924453512
At time: 662.3517827987671 and batch: 650, loss is 3.8584994411468507 and perplexity is 47.39418022723701
At time: 663.3966023921967 and batch: 700, loss is 3.8744893884658813 and perplexity is 48.15810192973373
At time: 664.4420392513275 and batch: 750, loss is 3.830890989303589 and perplexity is 46.103597752156666
At time: 665.485755443573 and batch: 800, loss is 3.794633316993713 and perplexity is 44.46192998191615
At time: 666.530680179596 and batch: 850, loss is 3.8080935859680176 and perplexity is 45.06444543170365
At time: 667.5753543376923 and batch: 900, loss is 3.7881468772888183 and perplexity is 44.17446367824982
At time: 668.6214208602905 and batch: 950, loss is 3.8758564233779906 and perplexity is 48.22398075544051
At time: 669.665776014328 and batch: 1000, loss is 3.8399210596084594 and perplexity is 46.52180184558024
At time: 670.7088904380798 and batch: 1050, loss is 3.8032084608078005 and perplexity is 44.84483682000756
At time: 671.7538464069366 and batch: 1100, loss is 3.8280211019515993 and perplexity is 45.971475299047896
At time: 672.7986650466919 and batch: 1150, loss is 3.7908391189575195 and perplexity is 44.29355224572762
At time: 673.8432886600494 and batch: 1200, loss is 3.835540795326233 and perplexity is 46.318469707967346
At time: 674.8885383605957 and batch: 1250, loss is 3.8133535385131836 and perplexity is 45.30210677188446
At time: 675.9368693828583 and batch: 1300, loss is 3.8195742893218996 and perplexity is 45.58479825422969
At time: 676.9818947315216 and batch: 1350, loss is 3.69952446937561 and perplexity is 40.42807500060718
At time: 678.0299394130707 and batch: 1400, loss is 3.728894634246826 and perplexity is 41.63306295832698
At time: 679.0771505832672 and batch: 1450, loss is 3.6502152347564696 and perplexity is 38.482948025662076
At time: 680.1239292621613 and batch: 1500, loss is 3.648419432640076 and perplexity is 38.413902280955256
At time: 681.1691751480103 and batch: 1550, loss is 3.656678247451782 and perplexity is 38.73246926823188
At time: 682.2152383327484 and batch: 1600, loss is 3.7472928094863893 and perplexity is 42.406125005694896
At time: 683.260345697403 and batch: 1650, loss is 3.6846684885025023 and perplexity is 39.83191552289509
At time: 684.3040978908539 and batch: 1700, loss is 3.700109977722168 and perplexity is 40.451752907084796
At time: 685.3549478054047 and batch: 1750, loss is 3.7058440828323365 and perplexity is 40.68437380911595
At time: 686.4078524112701 and batch: 1800, loss is 3.6540622520446777 and perplexity is 38.631277722537874
At time: 687.452719449997 and batch: 1850, loss is 3.6769810199737547 and perplexity is 39.52688289245881
At time: 688.497659444809 and batch: 1900, loss is 3.755672936439514 and perplexity is 42.762986902403725
At time: 689.5411713123322 and batch: 1950, loss is 3.7048843908309936 and perplexity is 40.64534807033163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495523426144622 and perplexity of 89.61506357837558
finished 16 epochs...
Completing Train Step...
At time: 692.8197932243347 and batch: 50, loss is 3.889703779220581 and perplexity is 48.89640024847754
At time: 693.8969550132751 and batch: 100, loss is 3.8748045063018797 and perplexity is 48.1732797978825
At time: 694.9470453262329 and batch: 150, loss is 3.8389037370681764 and perplexity is 46.47449823354326
At time: 695.997088432312 and batch: 200, loss is 3.823125982284546 and perplexity is 45.74698931732471
At time: 697.0473289489746 and batch: 250, loss is 3.8165958404541014 and perplexity is 45.44922825785356
At time: 698.0979406833649 and batch: 300, loss is 3.847340145111084 and perplexity is 46.86823458923003
At time: 699.1518323421478 and batch: 350, loss is 3.8582710218429566 and perplexity is 47.38335571789138
At time: 700.2140111923218 and batch: 400, loss is 3.8283759117126466 and perplexity is 45.987789321229755
At time: 701.2776865959167 and batch: 450, loss is 3.866787147521973 and perplexity is 47.78860144286032
At time: 702.3418710231781 and batch: 500, loss is 3.897352547645569 and perplexity is 49.27183145362774
At time: 703.3958718776703 and batch: 550, loss is 3.860203809738159 and perplexity is 47.47502625557221
At time: 704.4456830024719 and batch: 600, loss is 3.832420449256897 and perplexity is 46.17416530999262
At time: 705.495110988617 and batch: 650, loss is 3.8554827117919923 and perplexity is 47.25142025486316
At time: 706.5463950634003 and batch: 700, loss is 3.8714230251312256 and perplexity is 48.01065786577518
At time: 707.5989820957184 and batch: 750, loss is 3.827930612564087 and perplexity is 45.96731555661415
At time: 708.6521029472351 and batch: 800, loss is 3.7915750312805176 and perplexity is 44.32616041355926
At time: 709.7061793804169 and batch: 850, loss is 3.8046032428741454 and perplexity is 44.907429235414156
At time: 710.8009223937988 and batch: 900, loss is 3.785120978355408 and perplexity is 44.040998244014204
At time: 711.8517544269562 and batch: 950, loss is 3.872801594734192 and perplexity is 48.07688954132551
At time: 712.9010479450226 and batch: 1000, loss is 3.8366685628890993 and perplexity is 46.37073564203857
At time: 713.9511375427246 and batch: 1050, loss is 3.800376305580139 and perplexity is 44.71800896383701
At time: 715.001012802124 and batch: 1100, loss is 3.825842733383179 and perplexity is 45.87144147703681
At time: 716.0519409179688 and batch: 1150, loss is 3.7889357948303224 and perplexity is 44.209327438039715
At time: 717.1022319793701 and batch: 1200, loss is 3.8340581941604612 and perplexity is 46.24984877209099
At time: 718.1520614624023 and batch: 1250, loss is 3.8118609619140624 and perplexity is 45.234540344004046
At time: 719.204087972641 and batch: 1300, loss is 3.818539843559265 and perplexity is 45.53766763407299
At time: 720.254816532135 and batch: 1350, loss is 3.6990050315856933 and perplexity is 40.407080583797054
At time: 721.3039736747742 and batch: 1400, loss is 3.7287968730926515 and perplexity is 41.62899306098252
At time: 722.3560631275177 and batch: 1450, loss is 3.6508480596542356 and perplexity is 38.50730870051997
At time: 723.4060661792755 and batch: 1500, loss is 3.6496400928497312 and perplexity is 38.46082123319043
At time: 724.4574983119965 and batch: 1550, loss is 3.6581867933273315 and perplexity is 38.79094306911277
At time: 725.5076396465302 and batch: 1600, loss is 3.7491547203063966 and perplexity is 42.485154979227815
At time: 726.55890417099 and batch: 1650, loss is 3.686671562194824 and perplexity is 39.91178174725628
At time: 727.609472990036 and batch: 1700, loss is 3.7024663496017456 and perplexity is 40.547184672321706
At time: 728.6612997055054 and batch: 1750, loss is 3.708332996368408 and perplexity is 40.78575981596055
At time: 729.7116281986237 and batch: 1800, loss is 3.6567771577835084 and perplexity is 38.736300499086816
At time: 730.7619421482086 and batch: 1850, loss is 3.679706587791443 and perplexity is 39.634763042952926
At time: 731.8218214511871 and batch: 1900, loss is 3.758170189857483 and perplexity is 42.86991036953819
At time: 732.8756976127625 and batch: 1950, loss is 3.707141056060791 and perplexity is 40.73717458595829
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495381200036337 and perplexity of 89.60231888297479
finished 17 epochs...
Completing Train Step...
At time: 736.16965508461 and batch: 50, loss is 3.8889861345291137 and perplexity is 48.861322594558885
At time: 737.2382333278656 and batch: 100, loss is 3.873364109992981 and perplexity is 48.103941133040856
At time: 738.2817561626434 and batch: 150, loss is 3.836984133720398 and perplexity is 46.38537120278964
At time: 739.3246190547943 and batch: 200, loss is 3.821050429344177 and perplexity is 45.65213748818174
At time: 740.3677265644073 and batch: 250, loss is 3.814118514060974 and perplexity is 45.33677503432424
At time: 741.4114513397217 and batch: 300, loss is 3.844767436981201 and perplexity is 46.74781127451121
At time: 742.4546117782593 and batch: 350, loss is 3.8555648374557494 and perplexity is 47.25530096846597
At time: 743.4983739852905 and batch: 400, loss is 3.8254825830459596 and perplexity is 45.85492383651557
At time: 744.5411908626556 and batch: 450, loss is 3.8639728355407716 and perplexity is 47.654298483113074
At time: 745.5841126441956 and batch: 500, loss is 3.8944639348983765 and perplexity is 49.12970957956486
At time: 746.6310925483704 and batch: 550, loss is 3.8572067642211914 and perplexity is 47.33295444515036
At time: 747.6731543540955 and batch: 600, loss is 3.829822564125061 and perplexity is 46.054365812502816
At time: 748.7393035888672 and batch: 650, loss is 3.8531557083129884 and perplexity is 47.14159386829269
At time: 749.7882883548737 and batch: 700, loss is 3.8691768884658813 and perplexity is 47.902940386193144
At time: 750.8411855697632 and batch: 750, loss is 3.825820999145508 and perplexity is 45.87044450705967
At time: 751.8838999271393 and batch: 800, loss is 3.78950891494751 and perplexity is 44.23467195499431
At time: 752.9273538589478 and batch: 850, loss is 3.802348175048828 and perplexity is 44.8062740354134
At time: 753.9697549343109 and batch: 900, loss is 3.78315758228302 and perplexity is 43.954613152862876
At time: 755.0140357017517 and batch: 950, loss is 3.8708186388015746 and perplexity is 47.981649647451874
At time: 756.0572988986969 and batch: 1000, loss is 3.8346609687805175 and perplexity is 46.27773541094697
At time: 757.099769115448 and batch: 1050, loss is 3.7985598421096802 and perplexity is 44.636854063852674
At time: 758.1411912441254 and batch: 1100, loss is 3.824307990074158 and perplexity is 45.80109458517372
At time: 759.1849477291107 and batch: 1150, loss is 3.7876363945007325 and perplexity is 44.15191912966074
At time: 760.2259120941162 and batch: 1200, loss is 3.8329619121551515 and perplexity is 46.19917367730637
At time: 761.2697525024414 and batch: 1250, loss is 3.8109051418304443 and perplexity is 45.191324918246046
At time: 762.3175325393677 and batch: 1300, loss is 3.8178596258163453 and perplexity is 45.50670263724119
At time: 763.371132850647 and batch: 1350, loss is 3.698641471862793 and perplexity is 40.392392866869734
At time: 764.4221606254578 and batch: 1400, loss is 3.7287296152114866 and perplexity is 41.62619327726903
At time: 765.4654757976532 and batch: 1450, loss is 3.651230640411377 and perplexity is 38.52204367431707
At time: 766.5090091228485 and batch: 1500, loss is 3.650329146385193 and perplexity is 38.48733193063389
At time: 767.551962852478 and batch: 1550, loss is 3.659087824821472 and perplexity is 38.82591068159979
At time: 768.5950019359589 and batch: 1600, loss is 3.750301833152771 and perplexity is 42.53391820940141
At time: 769.6555547714233 and batch: 1650, loss is 3.687907781600952 and perplexity is 39.96115197631555
At time: 770.7075397968292 and batch: 1700, loss is 3.7039062643051146 and perplexity is 40.605611214235076
At time: 771.7497398853302 and batch: 1750, loss is 3.7098461961746216 and perplexity is 40.84752353845137
At time: 772.7917909622192 and batch: 1800, loss is 3.65840802192688 and perplexity is 38.79952568444809
At time: 773.8336155414581 and batch: 1850, loss is 3.6813370990753174 and perplexity is 39.69944068581224
At time: 774.8756022453308 and batch: 1900, loss is 3.7596434354782104 and perplexity is 42.93311482366186
At time: 775.9185287952423 and batch: 1950, loss is 3.7084366369247435 and perplexity is 40.78998709385336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49532839752907 and perplexity of 89.59758778078896
finished 18 epochs...
Completing Train Step...
At time: 779.247716665268 and batch: 50, loss is 3.8880674934387205 and perplexity is 48.816457186651355
At time: 780.292243719101 and batch: 100, loss is 3.8719790983200073 and perplexity is 48.037362729631376
At time: 781.337099313736 and batch: 150, loss is 3.835331497192383 and perplexity is 46.308776353130604
At time: 782.38148021698 and batch: 200, loss is 3.8192478227615356 and perplexity is 45.56991877089777
At time: 783.4257683753967 and batch: 250, loss is 3.8120842742919923 and perplexity is 45.244642904744275
At time: 784.4684808254242 and batch: 300, loss is 3.842667570114136 and perplexity is 46.64975008825895
At time: 785.5131721496582 and batch: 350, loss is 3.853422384262085 and perplexity is 47.15416707399071
At time: 786.5578279495239 and batch: 400, loss is 3.823196392059326 and perplexity is 45.75021046593827
At time: 787.6015021800995 and batch: 450, loss is 3.861744275093079 and perplexity is 47.548216247592826
At time: 788.6500442028046 and batch: 500, loss is 3.892213292121887 and perplexity is 49.019260490932666
At time: 789.7386770248413 and batch: 550, loss is 3.8549075365066527 and perplexity is 47.224250220250624
At time: 790.7840781211853 and batch: 600, loss is 3.827740364074707 and perplexity is 45.95857117609764
At time: 791.8294899463654 and batch: 650, loss is 3.8512120628356934 and perplexity is 47.050056309676236
At time: 792.87353515625 and batch: 700, loss is 3.8673392152786255 and perplexity is 47.81499127266926
At time: 793.917976140976 and batch: 750, loss is 3.82411066532135 and perplexity is 45.79205778712767
At time: 794.9635643959045 and batch: 800, loss is 3.7878526878356933 and perplexity is 44.16146992834403
At time: 796.0164377689362 and batch: 850, loss is 3.800598702430725 and perplexity is 44.727955214161426
At time: 797.0613503456116 and batch: 900, loss is 3.7816469621658326 and perplexity is 43.88826455637041
At time: 798.1130740642548 and batch: 950, loss is 3.869309277534485 and perplexity is 47.909282631666976
At time: 799.170501947403 and batch: 1000, loss is 3.833179168701172 and perplexity is 46.20921184059737
At time: 800.2144997119904 and batch: 1050, loss is 3.797215948104858 and perplexity is 44.57690715345115
At time: 801.2703077793121 and batch: 1100, loss is 3.8231261157989502 and perplexity is 45.74699542520715
At time: 802.3234837055206 and batch: 1150, loss is 3.7866245460510255 and perplexity is 44.10726667330691
At time: 803.3787136077881 and batch: 1200, loss is 3.83207848072052 and perplexity is 46.158377897816095
At time: 804.4269857406616 and batch: 1250, loss is 3.810161476135254 and perplexity is 45.15773017336206
At time: 805.4757635593414 and batch: 1300, loss is 3.8173073291778565 and perplexity is 45.481576377559
At time: 806.5250186920166 and batch: 1350, loss is 3.6983075857162477 and perplexity is 40.37890865768625
At time: 807.5738813877106 and batch: 1400, loss is 3.728609170913696 and perplexity is 41.62117994156997
At time: 808.6219956874847 and batch: 1450, loss is 3.6514041137695314 and perplexity is 38.528726802251796
At time: 809.6698241233826 and batch: 1500, loss is 3.6506952667236328 and perplexity is 38.50142550544074
At time: 810.718198299408 and batch: 1550, loss is 3.6596153783798218 and perplexity is 38.846398832759384
At time: 811.7660336494446 and batch: 1600, loss is 3.751021857261658 and perplexity is 42.56455468413423
At time: 812.8129580020905 and batch: 1650, loss is 3.688698801994324 and perplexity is 39.99277456787997
At time: 813.8635675907135 and batch: 1700, loss is 3.7048215866088867 and perplexity is 40.64279545102228
At time: 814.9125344753265 and batch: 1750, loss is 3.7108273458480836 and perplexity is 40.88762074029445
At time: 815.9611482620239 and batch: 1800, loss is 3.6594799280166628 and perplexity is 38.84113743026755
At time: 817.0090823173523 and batch: 1850, loss is 3.6824071836471557 and perplexity is 39.741945182447864
At time: 818.054931640625 and batch: 1900, loss is 3.760598273277283 and perplexity is 42.97412856214523
At time: 819.1038868427277 and batch: 1950, loss is 3.7092661476135254 and perplexity is 40.823836861574094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495332655795785 and perplexity of 89.5979693120271
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 822.5443422794342 and batch: 50, loss is 3.887646727561951 and perplexity is 48.795921207964945
At time: 823.6516652107239 and batch: 100, loss is 3.8720095014572142 and perplexity is 48.03882323836342
At time: 824.7050714492798 and batch: 150, loss is 3.8355254411697386 and perplexity is 46.317758532394635
At time: 825.7570538520813 and batch: 200, loss is 3.8193935918807984 and perplexity is 45.57656194199472
At time: 826.8076956272125 and batch: 250, loss is 3.81231595993042 and perplexity is 45.25512665314117
At time: 827.8606946468353 and batch: 300, loss is 3.8426687240600588 and perplexity is 46.649803919578915
At time: 828.9137434959412 and batch: 350, loss is 3.8533132171630857 and perplexity is 47.14901967133414
At time: 829.9649620056152 and batch: 400, loss is 3.823278741836548 and perplexity is 45.75397814070944
At time: 831.0150620937347 and batch: 450, loss is 3.861909351348877 and perplexity is 47.556065976984996
At time: 832.0668926239014 and batch: 500, loss is 3.8919676685333253 and perplexity is 49.00722168283039
At time: 833.1200304031372 and batch: 550, loss is 3.85497239112854 and perplexity is 47.22731303046019
At time: 834.171560049057 and batch: 600, loss is 3.827304334640503 and perplexity is 45.938536254536075
At time: 835.2263548374176 and batch: 650, loss is 3.8507349777221678 and perplexity is 47.02761478190542
At time: 836.284590959549 and batch: 700, loss is 3.8669524002075195 and perplexity is 47.796499290139536
At time: 837.3371071815491 and batch: 750, loss is 3.8239865827560426 and perplexity is 45.78637614363047
At time: 838.3900015354156 and batch: 800, loss is 3.7878405952453615 and perplexity is 44.16093590500861
At time: 839.4422132968903 and batch: 850, loss is 3.8007898569107055 and perplexity is 44.736505980413575
At time: 840.4927382469177 and batch: 900, loss is 3.78085955619812 and perplexity is 43.85372027691688
At time: 841.5442669391632 and batch: 950, loss is 3.868929343223572 and perplexity is 47.891083708800494
At time: 842.6403584480286 and batch: 1000, loss is 3.8331698179244995 and perplexity is 46.20877975059742
At time: 843.691543340683 and batch: 1050, loss is 3.7966284275054933 and perplexity is 44.55072499427459
At time: 844.755537033081 and batch: 1100, loss is 3.821951036453247 and perplexity is 45.693270647375385
At time: 845.8079090118408 and batch: 1150, loss is 3.78545027256012 and perplexity is 44.05550307755343
At time: 846.8588290214539 and batch: 1200, loss is 3.8308802795410157 and perplexity is 46.103103996214976
At time: 847.9122588634491 and batch: 1250, loss is 3.809263768196106 and perplexity is 45.117209910873406
At time: 848.9677019119263 and batch: 1300, loss is 3.8157347106933592 and perplexity is 45.41010742127377
At time: 850.0189619064331 and batch: 1350, loss is 3.6959203481674194 and perplexity is 40.282629576999966
At time: 851.069949388504 and batch: 1400, loss is 3.7258061933517457 and perplexity is 41.50468005764736
At time: 852.1211810112 and batch: 1450, loss is 3.6477264881134035 and perplexity is 38.38729279813404
At time: 853.17200756073 and batch: 1500, loss is 3.646279902458191 and perplexity is 38.331802436487045
At time: 854.2241654396057 and batch: 1550, loss is 3.6553749942779543 and perplexity is 38.682023933389225
At time: 855.2748444080353 and batch: 1600, loss is 3.74669114112854 and perplexity is 42.38061825617149
At time: 856.325677394867 and batch: 1650, loss is 3.684478883743286 and perplexity is 39.824363918075974
At time: 857.3766703605652 and batch: 1700, loss is 3.7003282356262206 and perplexity is 40.46058278544987
At time: 858.4275386333466 and batch: 1750, loss is 3.706492443084717 and perplexity is 40.710760493100956
At time: 859.4790632724762 and batch: 1800, loss is 3.655322232246399 and perplexity is 38.67998304506301
At time: 860.5311472415924 and batch: 1850, loss is 3.678682956695557 and perplexity is 39.59421242500164
At time: 861.5825431346893 and batch: 1900, loss is 3.756623706817627 and perplexity is 42.80366401786416
At time: 862.6345443725586 and batch: 1950, loss is 3.7064051389694215 and perplexity is 40.707206431317466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495162609011628 and perplexity of 89.58273476080855
Finished Training.
Improved accuracyfrom -10000000 to -89.58273476080855
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
895.665736913681


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5294630527496338 and batch: 50, loss is 8.811798439025878 and perplexity is 6712.981304905915
At time: 2.5794055461883545 and batch: 100, loss is 7.442630453109741 and perplexity is 1707.2351218395488
At time: 3.6288654804229736 and batch: 150, loss is 7.1196764373779295 and perplexity is 1236.050429038052
At time: 4.678950071334839 and batch: 200, loss is 7.007074565887451 and perplexity is 1104.4188697534573
At time: 5.754936933517456 and batch: 250, loss is 6.942251605987549 and perplexity is 1035.098226458948
At time: 6.806784152984619 and batch: 300, loss is 6.836676969528198 and perplexity is 931.3889527114147
At time: 7.862157106399536 and batch: 350, loss is 6.801505880355835 and perplexity is 899.2003607738668
At time: 8.917034149169922 and batch: 400, loss is 6.768704156875611 and perplexity is 870.1835417054166
At time: 9.976302862167358 and batch: 450, loss is 6.680047674179077 and perplexity is 796.3570767808166
At time: 11.025548219680786 and batch: 500, loss is 6.664610834121704 and perplexity is 784.1582379634591
At time: 12.075048446655273 and batch: 550, loss is 6.6236144638061525 and perplexity is 752.6606512015687
At time: 13.124555110931396 and batch: 600, loss is 6.6789803981781 and perplexity is 795.5075973796849
At time: 14.174803972244263 and batch: 650, loss is 6.774005355834961 and perplexity is 874.8088066842271
At time: 15.22460412979126 and batch: 700, loss is 6.639243659973144 and perplexity is 764.5165398336945
At time: 16.27350163459778 and batch: 750, loss is 6.577489595413208 and perplexity is 718.732752580001
At time: 17.323184967041016 and batch: 800, loss is 6.583587980270385 and perplexity is 723.1292536669283
At time: 18.372490882873535 and batch: 850, loss is 6.6393023872375485 and perplexity is 764.561439117064
At time: 19.421464920043945 and batch: 900, loss is 6.624512958526611 and perplexity is 753.3372167227292
At time: 20.474935054779053 and batch: 950, loss is 6.641100959777832 and perplexity is 765.9377956943653
At time: 21.525404930114746 and batch: 1000, loss is 6.631010570526123 and perplexity is 758.2480467182392
At time: 22.574501276016235 and batch: 1050, loss is 6.521234731674195 and perplexity is 679.4167650457208
At time: 23.624118089675903 and batch: 1100, loss is 6.597702856063843 and perplexity is 733.4085078022281
At time: 24.673146963119507 and batch: 1150, loss is 6.503233947753906 and perplexity is 667.2961482516481
At time: 25.735265016555786 and batch: 1200, loss is 6.601165809631348 and perplexity is 735.9526700261092
At time: 26.79090142250061 and batch: 1250, loss is 6.518824625015259 and perplexity is 677.7812698267136
At time: 27.85147976875305 and batch: 1300, loss is 6.5404097366333005 and perplexity is 692.5702913281507
At time: 28.9107186794281 and batch: 1350, loss is 6.551022958755493 and perplexity is 699.9598377506535
At time: 29.960819721221924 and batch: 1400, loss is 6.569795875549317 and perplexity is 713.2242417664095
At time: 31.01117968559265 and batch: 1450, loss is 6.56522536277771 and perplexity is 709.9718794039612
At time: 32.06267309188843 and batch: 1500, loss is 6.557563762664795 and perplexity is 704.553143373522
At time: 33.11310958862305 and batch: 1550, loss is 6.522658233642578 and perplexity is 680.3846048456137
At time: 34.163126707077026 and batch: 1600, loss is 6.51315767288208 and perplexity is 673.9511785359139
At time: 35.21236968040466 and batch: 1650, loss is 6.50639723777771 and perplexity is 669.4103416408077
At time: 36.26530694961548 and batch: 1700, loss is 6.533175802230835 and perplexity is 687.5783606898539
At time: 37.31590795516968 and batch: 1750, loss is 6.548566741943359 and perplexity is 698.2426943309139
At time: 38.373844385147095 and batch: 1800, loss is 6.546974668502807 and perplexity is 697.131925129904
At time: 39.42548394203186 and batch: 1850, loss is 6.497434558868409 and perplexity is 663.4374382809651
At time: 40.47578716278076 and batch: 1900, loss is 6.434515752792358 and perplexity is 622.9808330799021
At time: 41.52694845199585 and batch: 1950, loss is 6.388770675659179 and perplexity is 595.1245287471801
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.731360147165698 and perplexity of 308.38843690573754
finished 1 epochs...
Completing Train Step...
At time: 44.856080532073975 and batch: 50, loss is 5.94951358795166 and perplexity is 383.56672220342534
At time: 45.92892575263977 and batch: 100, loss is 5.762327632904053 and perplexity is 318.08785967445675
At time: 46.9738507270813 and batch: 150, loss is 5.630408496856689 and perplexity is 278.7759734854671
At time: 48.01896119117737 and batch: 200, loss is 5.5715365219116215 and perplexity is 262.8376449331237
At time: 49.06248879432678 and batch: 250, loss is 5.55202353477478 and perplexity is 257.75861205535165
At time: 50.10945773124695 and batch: 300, loss is 5.537133102416992 and perplexity is 253.9489093301971
At time: 51.15363001823425 and batch: 350, loss is 5.484950017929077 and perplexity is 241.03689617370273
At time: 52.19876527786255 and batch: 400, loss is 5.4463529300689695 and perplexity is 231.91082669147988
At time: 53.242456674575806 and batch: 450, loss is 5.3689342212677005 and perplexity is 214.6339934159143
At time: 54.28733515739441 and batch: 500, loss is 5.348182315826416 and perplexity is 210.22582620846316
At time: 55.33220338821411 and batch: 550, loss is 5.297069435119629 and perplexity is 199.75056938284214
At time: 56.377984285354614 and batch: 600, loss is 5.318627605438232 and perplexity is 204.10357905191896
At time: 57.42225003242493 and batch: 650, loss is 5.385113792419434 and perplexity is 218.13492479609533
At time: 58.46518349647522 and batch: 700, loss is 5.328484268188476 and perplexity is 206.12530657173653
At time: 59.5103018283844 and batch: 750, loss is 5.271664934158325 and perplexity is 194.73992183288212
At time: 60.55493426322937 and batch: 800, loss is 5.255348539352417 and perplexity is 191.58825026336672
At time: 61.626036405563354 and batch: 850, loss is 5.257135000228882 and perplexity is 191.93082108042574
At time: 62.66993308067322 and batch: 900, loss is 5.274103136062622 and perplexity is 195.21531639959497
At time: 63.71399426460266 and batch: 950, loss is 5.310942211151123 and perplexity is 202.54097487739034
At time: 64.75736904144287 and batch: 1000, loss is 5.277294397354126 and perplexity is 195.8392945914979
At time: 65.80255460739136 and batch: 1050, loss is 5.177169094085693 and perplexity is 177.18051897901822
At time: 66.84827041625977 and batch: 1100, loss is 5.269694919586182 and perplexity is 194.35665898973846
At time: 67.8953812122345 and batch: 1150, loss is 5.174105892181396 and perplexity is 176.6386096884
At time: 68.9455955028534 and batch: 1200, loss is 5.25220724105835 and perplexity is 190.98735870358774
At time: 69.99128222465515 and batch: 1250, loss is 5.187434587478638 and perplexity is 179.008732126163
At time: 71.03512716293335 and batch: 1300, loss is 5.218994836807251 and perplexity is 184.7483884288881
At time: 72.07742881774902 and batch: 1350, loss is 5.16887487411499 and perplexity is 175.71702245112962
At time: 73.12609767913818 and batch: 1400, loss is 5.178099184036255 and perplexity is 177.3453894594591
At time: 74.1700382232666 and batch: 1450, loss is 5.109815587997437 and perplexity is 165.63980608868994
At time: 75.2150514125824 and batch: 1500, loss is 5.094858531951904 and perplexity is 163.1807581280861
At time: 76.2590594291687 and batch: 1550, loss is 5.084112300872802 and perplexity is 161.4365685110153
At time: 77.30352306365967 and batch: 1600, loss is 5.135974807739258 and perplexity is 170.02998566134747
At time: 78.34792876243591 and batch: 1650, loss is 5.107737560272216 and perplexity is 165.2959593644838
At time: 79.39397072792053 and batch: 1700, loss is 5.121470975875854 and perplexity is 167.58169703942252
At time: 80.43844413757324 and batch: 1750, loss is 5.13966625213623 and perplexity is 170.65880180508913
At time: 81.48850417137146 and batch: 1800, loss is 5.109585390090943 and perplexity is 165.6016805404753
At time: 82.53253483772278 and batch: 1850, loss is 5.0882542610168455 and perplexity is 162.10661904694683
At time: 83.5753755569458 and batch: 1900, loss is 5.1387024974823 and perplexity is 170.49440782107334
At time: 84.62059593200684 and batch: 1950, loss is 5.066750478744507 and perplexity is 158.65792646548704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.869075899345931 and perplexity of 130.2005428793361
finished 2 epochs...
Completing Train Step...
At time: 87.95280075073242 and batch: 50, loss is 5.0200204753875735 and perplexity is 151.4144040309201
At time: 88.9982419013977 and batch: 100, loss is 4.982624845504761 and perplexity is 145.85673101482604
At time: 90.04490280151367 and batch: 150, loss is 4.92966812133789 and perplexity is 138.33359475249708
At time: 91.08846807479858 and batch: 200, loss is 4.914064254760742 and perplexity is 136.19180932066587
At time: 92.13428330421448 and batch: 250, loss is 4.913868942260742 and perplexity is 136.16521195539144
At time: 93.17978525161743 and batch: 300, loss is 4.941505460739136 and perplexity is 139.98082665121527
At time: 94.22621059417725 and batch: 350, loss is 4.923757705688477 and perplexity is 137.51839716064205
At time: 95.27040696144104 and batch: 400, loss is 4.90857967376709 and perplexity is 135.4468989397134
At time: 96.31736421585083 and batch: 450, loss is 4.8804370784759525 and perplexity is 131.68820939082477
At time: 97.36247062683105 and batch: 500, loss is 4.877304487228393 and perplexity is 131.27632952113683
At time: 98.40667605400085 and batch: 550, loss is 4.840248317718506 and perplexity is 126.500760210477
At time: 99.45111918449402 and batch: 600, loss is 4.838515663146973 and perplexity is 126.2817678638275
At time: 100.49549412727356 and batch: 650, loss is 4.900150003433228 and perplexity is 134.30992512384037
At time: 101.53944945335388 and batch: 700, loss is 4.898267574310303 and perplexity is 134.05733402629735
At time: 102.58362197875977 and batch: 750, loss is 4.850082769393921 and perplexity is 127.75096327824784
At time: 103.62782073020935 and batch: 800, loss is 4.823477840423584 and perplexity is 124.3969721555908
At time: 104.6728024482727 and batch: 850, loss is 4.838100290298462 and perplexity is 126.229324738674
At time: 105.71738386154175 and batch: 900, loss is 4.849236469268799 and perplexity is 127.64289335828467
At time: 106.7631185054779 and batch: 950, loss is 4.900790338516235 and perplexity is 134.3959560222549
At time: 107.80748844146729 and batch: 1000, loss is 4.8798921680450436 and perplexity is 131.61647065926664
At time: 108.85136198997498 and batch: 1050, loss is 4.801031761169433 and perplexity is 121.63585194727128
At time: 109.8972818851471 and batch: 1100, loss is 4.880308494567871 and perplexity is 131.67127749482108
At time: 110.94313502311707 and batch: 1150, loss is 4.799245119094849 and perplexity is 121.418726237126
At time: 111.98753666877747 and batch: 1200, loss is 4.885871686935425 and perplexity is 132.40583147888347
At time: 113.03264904022217 and batch: 1250, loss is 4.8421095180511475 and perplexity is 126.73642270698943
At time: 114.07973217964172 and batch: 1300, loss is 4.867733182907105 and perplexity is 130.02583778601615
At time: 115.12380504608154 and batch: 1350, loss is 4.784621162414551 and perplexity is 119.6560242970537
At time: 116.16916370391846 and batch: 1400, loss is 4.79445068359375 and perplexity is 120.83798526057252
At time: 117.2141489982605 and batch: 1450, loss is 4.720619163513184 and perplexity is 112.23772466224132
At time: 118.25923037528992 and batch: 1500, loss is 4.725960607528687 and perplexity is 112.83884016816025
At time: 119.3056788444519 and batch: 1550, loss is 4.723109045028687 and perplexity is 112.51753149659692
At time: 120.3511118888855 and batch: 1600, loss is 4.798976917266845 and perplexity is 121.38616587936427
At time: 121.39695286750793 and batch: 1650, loss is 4.761882019042969 and perplexity is 116.96585084127112
At time: 122.44334959983826 and batch: 1700, loss is 4.788118076324463 and perplexity is 120.07518356762733
At time: 123.48984050750732 and batch: 1750, loss is 4.790932683944702 and perplexity is 120.41362415960538
At time: 124.53537940979004 and batch: 1800, loss is 4.765527935028076 and perplexity is 117.39307684838029
At time: 125.58122110366821 and batch: 1850, loss is 4.772480039596558 and perplexity is 118.21204928673232
At time: 126.62651371955872 and batch: 1900, loss is 4.8364075183868405 and perplexity is 126.01582803492595
At time: 127.6719582080841 and batch: 1950, loss is 4.771476202011108 and perplexity is 118.0934431292245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.737533214480378 and perplexity of 114.15226493021683
finished 3 epochs...
Completing Train Step...
At time: 130.959819316864 and batch: 50, loss is 4.726436386108398 and perplexity is 112.89253924469398
At time: 132.05374121665955 and batch: 100, loss is 4.704493818283081 and perplexity is 110.44236688942384
At time: 133.10459733009338 and batch: 150, loss is 4.653580579757691 and perplexity is 104.96013167890085
At time: 134.15509295463562 and batch: 200, loss is 4.648263788223266 and perplexity is 104.40356143442645
At time: 135.20476698875427 and batch: 250, loss is 4.647483282089233 and perplexity is 104.32210560683369
At time: 136.25526452064514 and batch: 300, loss is 4.681713609695435 and perplexity is 107.95490673421347
At time: 137.30551314353943 and batch: 350, loss is 4.675220460891723 and perplexity is 107.25621028551139
At time: 138.35801148414612 and batch: 400, loss is 4.651341314315796 and perplexity is 104.72536103824783
At time: 139.41768717765808 and batch: 450, loss is 4.64937240600586 and perplexity is 104.51936926064552
At time: 140.49778842926025 and batch: 500, loss is 4.651176071166992 and perplexity is 104.70805731953007
At time: 141.54899215698242 and batch: 550, loss is 4.609501743316651 and perplexity is 100.43409520827457
At time: 142.59940242767334 and batch: 600, loss is 4.603843936920166 and perplexity is 99.86746300117004
At time: 143.6504189968109 and batch: 650, loss is 4.6607567310333256 and perplexity is 105.71605051171825
At time: 144.70058393478394 and batch: 700, loss is 4.675650291442871 and perplexity is 107.3023221909353
At time: 145.75116872787476 and batch: 750, loss is 4.63052077293396 and perplexity is 102.56746456398102
At time: 146.80272102355957 and batch: 800, loss is 4.605961275100708 and perplexity is 100.07914021061387
At time: 147.85258436203003 and batch: 850, loss is 4.605632019042969 and perplexity is 100.04619397161821
At time: 148.90332555770874 and batch: 900, loss is 4.621143646240235 and perplexity is 101.61017179648503
At time: 149.95352220535278 and batch: 950, loss is 4.682898006439209 and perplexity is 108.08284392346327
At time: 151.0036976337433 and batch: 1000, loss is 4.653406190872192 and perplexity is 104.94182939441949
At time: 152.05359721183777 and batch: 1050, loss is 4.587929964065552 and perplexity is 98.29075403335086
At time: 153.10564470291138 and batch: 1100, loss is 4.661881647109985 and perplexity is 105.83503911004574
At time: 154.1562831401825 and batch: 1150, loss is 4.584303817749023 and perplexity is 97.93498280675982
At time: 155.20664072036743 and batch: 1200, loss is 4.664718999862671 and perplexity is 106.13575686903003
At time: 156.25672054290771 and batch: 1250, loss is 4.637521724700928 and perplexity is 103.28805389863727
At time: 157.3073000907898 and batch: 1300, loss is 4.662809381484985 and perplexity is 105.93327147363216
At time: 158.35810780525208 and batch: 1350, loss is 4.57157943725586 and perplexity is 96.69671562060992
At time: 159.4096875190735 and batch: 1400, loss is 4.577734622955322 and perplexity is 97.29373736672845
At time: 160.46168518066406 and batch: 1450, loss is 4.500885992050171 and perplexity is 90.09692110457986
At time: 161.5114209651947 and batch: 1500, loss is 4.510999011993408 and perplexity is 91.01269588391885
At time: 162.56297063827515 and batch: 1550, loss is 4.516987009048462 and perplexity is 91.55931458111816
At time: 163.6197168827057 and batch: 1600, loss is 4.602171106338501 and perplexity is 99.7005413097291
At time: 164.6727273464203 and batch: 1650, loss is 4.554228630065918 and perplexity is 95.03342103159743
At time: 165.72337245941162 and batch: 1700, loss is 4.583540658950806 and perplexity is 97.8602713749469
At time: 166.77406239509583 and batch: 1750, loss is 4.587205123901367 and perplexity is 98.21953476147206
At time: 167.82488822937012 and batch: 1800, loss is 4.555938320159912 and perplexity is 95.19603770257804
At time: 168.8758852481842 and batch: 1850, loss is 4.574614324569702 and perplexity is 96.99062502150456
At time: 169.9351224899292 and batch: 1900, loss is 4.64363112449646 and perplexity is 103.92101344671899
At time: 170.98632264137268 and batch: 1950, loss is 4.58086483001709 and perplexity is 97.59876405979462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.682648414789244 and perplexity of 108.05587071439943
finished 4 epochs...
Completing Train Step...
At time: 174.28100299835205 and batch: 50, loss is 4.544819192886353 and perplexity is 94.14340387335977
At time: 175.35122323036194 and batch: 100, loss is 4.5109681797027585 and perplexity is 91.00988979728584
At time: 176.3956322669983 and batch: 150, loss is 4.4663788604736325 and perplexity is 87.04096417927691
At time: 177.43868780136108 and batch: 200, loss is 4.461463441848755 and perplexity is 86.61417119523803
At time: 178.48098635673523 and batch: 250, loss is 4.461270780563354 and perplexity is 86.59748560506686
At time: 179.52386379241943 and batch: 300, loss is 4.492826986312866 and perplexity is 89.37374744484792
At time: 180.57597661018372 and batch: 350, loss is 4.495865850448609 and perplexity is 89.64575520862829
At time: 181.61830019950867 and batch: 400, loss is 4.463646574020386 and perplexity is 86.80346793360984
At time: 182.66113758087158 and batch: 450, loss is 4.47596700668335 and perplexity is 87.87953943679757
At time: 183.71001482009888 and batch: 500, loss is 4.485981369018555 and perplexity is 88.76401834084778
At time: 184.75919818878174 and batch: 550, loss is 4.439849882125855 and perplexity is 84.76221639497294
At time: 185.80929350852966 and batch: 600, loss is 4.437964811325073 and perplexity is 84.60258412217638
At time: 186.85359239578247 and batch: 650, loss is 4.492321214675903 and perplexity is 89.32855616749775
At time: 187.89739537239075 and batch: 700, loss is 4.51143214225769 and perplexity is 91.05212477524674
At time: 188.94125533103943 and batch: 750, loss is 4.4678928184509275 and perplexity is 87.172840343644
At time: 189.98533535003662 and batch: 800, loss is 4.441103382110596 and perplexity is 84.86853245159746
At time: 191.02865481376648 and batch: 850, loss is 4.446693706512451 and perplexity is 85.34430369826079
At time: 192.07219886779785 and batch: 900, loss is 4.453001537322998 and perplexity is 85.88434257293912
At time: 193.16009402275085 and batch: 950, loss is 4.521290483474732 and perplexity is 91.95418680174063
At time: 194.20411229133606 and batch: 1000, loss is 4.490936632156372 and perplexity is 89.2049589951208
At time: 195.24795794487 and batch: 1050, loss is 4.4330066967010495 and perplexity is 84.18415298456854
At time: 196.29106330871582 and batch: 1100, loss is 4.5024325561523435 and perplexity is 90.23636957367957
At time: 197.33522701263428 and batch: 1150, loss is 4.430983390808105 and perplexity is 84.01399489072831
At time: 198.37817811965942 and batch: 1200, loss is 4.502390203475952 and perplexity is 90.2325479028498
At time: 199.427889585495 and batch: 1250, loss is 4.483240432739258 and perplexity is 88.52105494837953
At time: 200.47276210784912 and batch: 1300, loss is 4.507034683227539 and perplexity is 90.65260586477244
At time: 201.5170750617981 and batch: 1350, loss is 4.40616548538208 and perplexity is 81.95460409608246
At time: 202.56095910072327 and batch: 1400, loss is 4.422819910049438 and perplexity is 83.330940105641
At time: 203.60631346702576 and batch: 1450, loss is 4.3370679759979245 and perplexity is 76.48296038813935
At time: 204.64961981773376 and batch: 1500, loss is 4.351821994781494 and perplexity is 77.61975695979824
At time: 205.69384121894836 and batch: 1550, loss is 4.356505584716797 and perplexity is 77.98414873699755
At time: 206.73701429367065 and batch: 1600, loss is 4.440130310058594 and perplexity is 84.78598942124547
At time: 207.78144478797913 and batch: 1650, loss is 4.401386442184449 and perplexity is 81.5638739047592
At time: 208.8263566493988 and batch: 1700, loss is 4.432091312408447 and perplexity is 84.10712739262745
At time: 209.86971616744995 and batch: 1750, loss is 4.437530660629273 and perplexity is 84.56586182349582
At time: 210.9137523174286 and batch: 1800, loss is 4.398719797134399 and perplexity is 81.34666174672745
At time: 211.9573073387146 and batch: 1850, loss is 4.429295206069947 and perplexity is 83.87228339800775
At time: 212.99995756149292 and batch: 1900, loss is 4.496666679382324 and perplexity is 89.71757487698001
At time: 214.04312801361084 and batch: 1950, loss is 4.431858034133911 and perplexity is 84.08750931539764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.654178495185319 and perplexity of 105.02290772643104
finished 5 epochs...
Completing Train Step...
At time: 217.34795117378235 and batch: 50, loss is 4.400544409751892 and perplexity is 81.49522338464487
At time: 218.39341163635254 and batch: 100, loss is 4.366426782608032 and perplexity is 78.76169562946299
At time: 219.46657037734985 and batch: 150, loss is 4.319399461746216 and perplexity is 75.14348820001683
At time: 220.51148796081543 and batch: 200, loss is 4.322864646911621 and perplexity is 75.40432596518062
At time: 221.5558168888092 and batch: 250, loss is 4.315301942825317 and perplexity is 74.83621629148028
At time: 222.5999948978424 and batch: 300, loss is 4.348661804199219 and perplexity is 77.37485091356488
At time: 223.64548087120056 and batch: 350, loss is 4.360606079101562 and perplexity is 78.3045788128805
At time: 224.69111609458923 and batch: 400, loss is 4.329706745147705 and perplexity is 75.92201880387154
At time: 225.736647605896 and batch: 450, loss is 4.340436420440674 and perplexity is 76.74102338244582
At time: 226.78299140930176 and batch: 500, loss is 4.353808259963989 and perplexity is 77.77408359659583
At time: 227.83096432685852 and batch: 550, loss is 4.308572320938111 and perplexity is 74.33428764165264
At time: 228.885639667511 and batch: 600, loss is 4.306962532997131 and perplexity is 74.21472146572039
At time: 229.93199229240417 and batch: 650, loss is 4.366492729187012 and perplexity is 78.76688986511355
At time: 230.975998878479 and batch: 700, loss is 4.383336219787598 and perplexity is 80.10483543957999
At time: 232.02059721946716 and batch: 750, loss is 4.339874362945556 and perplexity is 76.69790263437574
At time: 233.0656042098999 and batch: 800, loss is 4.309737410545349 and perplexity is 74.42094421918179
At time: 234.11079144477844 and batch: 850, loss is 4.319841709136963 and perplexity is 75.17672756107349
At time: 235.15609574317932 and batch: 900, loss is 4.324614820480346 and perplexity is 75.53641217663427
At time: 236.2010042667389 and batch: 950, loss is 4.396056528091431 and perplexity is 81.13030194082187
At time: 237.2451148033142 and batch: 1000, loss is 4.364157485961914 and perplexity is 78.58316462424932
At time: 238.28860592842102 and batch: 1050, loss is 4.308820533752441 and perplexity is 74.35274065443181
At time: 239.3351559638977 and batch: 1100, loss is 4.371729650497437 and perplexity is 79.18046786170646
At time: 240.38197469711304 and batch: 1150, loss is 4.30696328163147 and perplexity is 74.2147770254301
At time: 241.42899227142334 and batch: 1200, loss is 4.371262378692627 and perplexity is 79.14347770448488
At time: 242.47959852218628 and batch: 1250, loss is 4.35884467124939 and perplexity is 78.166773913843
At time: 243.53431177139282 and batch: 1300, loss is 4.38017050743103 and perplexity is 79.85164754368184
At time: 244.58808302879333 and batch: 1350, loss is 4.281762661933899 and perplexity is 72.3678877716777
At time: 245.6391305923462 and batch: 1400, loss is 4.304803438186646 and perplexity is 74.05465770434104
At time: 246.69080710411072 and batch: 1450, loss is 4.211574788093567 and perplexity is 67.46269565157252
At time: 247.74186158180237 and batch: 1500, loss is 4.224628124237061 and perplexity is 68.34908145510857
At time: 248.794047832489 and batch: 1550, loss is 4.234135360717773 and perplexity is 69.00199110104305
At time: 249.84633040428162 and batch: 1600, loss is 4.318287258148193 and perplexity is 75.05995980097613
At time: 250.89705801010132 and batch: 1650, loss is 4.2755834674835205 and perplexity is 71.92209127126972
At time: 251.95593190193176 and batch: 1700, loss is 4.309547424316406 and perplexity is 74.40680660765351
At time: 253.00777006149292 and batch: 1750, loss is 4.317000904083252 and perplexity is 74.96346819106458
At time: 254.0594871044159 and batch: 1800, loss is 4.272933220863342 and perplexity is 71.73173235242287
At time: 255.11194014549255 and batch: 1850, loss is 4.302774906158447 and perplexity is 73.90458772169441
At time: 256.16424584388733 and batch: 1900, loss is 4.379350566864014 and perplexity is 79.78620077341533
At time: 257.2164545059204 and batch: 1950, loss is 4.308325386047363 and perplexity is 74.3159341786035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6424469703851745 and perplexity of 103.79802778275796
finished 6 epochs...
Completing Train Step...
At time: 260.5735309123993 and batch: 50, loss is 4.283409929275512 and perplexity is 72.48719526847874
At time: 261.6525173187256 and batch: 100, loss is 4.249176669120788 and perplexity is 70.04771615069208
At time: 262.705810546875 and batch: 150, loss is 4.207169418334961 and perplexity is 67.16615120587495
At time: 263.76362109184265 and batch: 200, loss is 4.205165281295776 and perplexity is 67.03167583301233
At time: 264.8186731338501 and batch: 250, loss is 4.200211911201477 and perplexity is 66.70046411888401
At time: 265.8716530799866 and batch: 300, loss is 4.23372133731842 and perplexity is 68.97342857531028
At time: 266.9249978065491 and batch: 350, loss is 4.2409290599822995 and perplexity is 69.4723658604134
At time: 267.9772410392761 and batch: 400, loss is 4.200977501869201 and perplexity is 66.75154892427624
At time: 269.0285987854004 and batch: 450, loss is 4.227253184318543 and perplexity is 68.52873760136468
At time: 270.0817666053772 and batch: 500, loss is 4.240550317764282 and perplexity is 69.44605872460248
At time: 271.1332097053528 and batch: 550, loss is 4.19945924282074 and perplexity is 66.65027967705164
At time: 272.2113194465637 and batch: 600, loss is 4.201897401809692 and perplexity is 66.81298192193265
At time: 273.26424908638 and batch: 650, loss is 4.255669231414795 and perplexity is 70.50398488517331
At time: 274.3164050579071 and batch: 700, loss is 4.271878986358643 and perplexity is 71.65615013278729
At time: 275.37038946151733 and batch: 750, loss is 4.23002287864685 and perplexity is 68.71880434911846
At time: 276.42368054389954 and batch: 800, loss is 4.202841548919678 and perplexity is 66.87609299410381
At time: 277.47898864746094 and batch: 850, loss is 4.212648944854736 and perplexity is 67.5352000958315
At time: 278.53599095344543 and batch: 900, loss is 4.209163699150086 and perplexity is 67.30023302661328
At time: 279.59032464027405 and batch: 950, loss is 4.288500347137451 and perplexity is 72.85712613456484
At time: 280.64301204681396 and batch: 1000, loss is 4.250994281768799 and perplexity is 70.17515154453947
At time: 281.69514298439026 and batch: 1050, loss is 4.196710696220398 and perplexity is 66.4673398019877
At time: 282.747798204422 and batch: 1100, loss is 4.255779752731323 and perplexity is 70.51177750902087
At time: 283.8005027770996 and batch: 1150, loss is 4.197638130187988 and perplexity is 66.52901246489607
At time: 284.8533458709717 and batch: 1200, loss is 4.265145606994629 and perplexity is 71.1752828379498
At time: 285.9076120853424 and batch: 1250, loss is 4.253935151100158 and perplexity is 70.38183125559272
At time: 286.9597680568695 and batch: 1300, loss is 4.271584992408752 and perplexity is 71.63508675458039
At time: 288.01133251190186 and batch: 1350, loss is 4.171267457008362 and perplexity is 64.79752816367468
At time: 289.0635085105896 and batch: 1400, loss is 4.202252893447876 and perplexity is 66.83673760055044
At time: 290.1162922382355 and batch: 1450, loss is 4.106443095207214 and perplexity is 60.730320976979385
At time: 291.1688623428345 and batch: 1500, loss is 4.117255420684814 and perplexity is 61.390519683615295
At time: 292.22093391418457 and batch: 1550, loss is 4.129115161895752 and perplexity is 62.12292987287143
At time: 293.27367424964905 and batch: 1600, loss is 4.212074451446533 and perplexity is 67.49641271116994
At time: 294.3261196613312 and batch: 1650, loss is 4.1702146100997926 and perplexity is 64.72934218746035
At time: 295.3788652420044 and batch: 1700, loss is 4.210729336738586 and perplexity is 67.40568332809228
At time: 296.4316165447235 and batch: 1750, loss is 4.2143553495407104 and perplexity is 67.6505408587648
At time: 297.4847602844238 and batch: 1800, loss is 4.166951847076416 and perplexity is 64.51848985090169
At time: 298.5372495651245 and batch: 1850, loss is 4.200917296409607 and perplexity is 66.74753023756925
At time: 299.5897626876831 and batch: 1900, loss is 4.272637758255005 and perplexity is 71.71054143839703
At time: 300.65776538848877 and batch: 1950, loss is 4.208753747940063 and perplexity is 67.27264886911493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.642332281068314 and perplexity of 103.7861239404949
finished 7 epochs...
Completing Train Step...
At time: 303.9823372364044 and batch: 50, loss is 4.18365355014801 and perplexity is 65.60510743420166
At time: 305.054327249527 and batch: 100, loss is 4.143049578666687 and perplexity is 62.99463592170752
At time: 306.10040283203125 and batch: 150, loss is 4.109736442565918 and perplexity is 60.93065672569421
At time: 307.14555525779724 and batch: 200, loss is 4.110727915763855 and perplexity is 60.99109779667017
At time: 308.19122076034546 and batch: 250, loss is 4.104172258377075 and perplexity is 60.59256879296071
At time: 309.23678755760193 and batch: 300, loss is 4.133584957122803 and perplexity is 62.40122815312514
At time: 310.2823977470398 and batch: 350, loss is 4.14370138168335 and perplexity is 63.03570939988917
At time: 311.328341960907 and batch: 400, loss is 4.10461685180664 and perplexity is 60.61951384027819
At time: 312.37375593185425 and batch: 450, loss is 4.129241452217102 and perplexity is 62.13077589307611
At time: 313.4199471473694 and batch: 500, loss is 4.147589402198792 and perplexity is 63.28127059538473
At time: 314.46581506729126 and batch: 550, loss is 4.109996147155762 and perplexity is 60.946482751864956
At time: 315.51239585876465 and batch: 600, loss is 4.109122748374939 and perplexity is 60.89327540713137
At time: 316.5601851940155 and batch: 650, loss is 4.161125826835632 and perplexity is 64.14369665960275
At time: 317.60476064682007 and batch: 700, loss is 4.177766904830933 and perplexity is 65.22004790213533
At time: 318.6491792201996 and batch: 750, loss is 4.131235504150391 and perplexity is 62.254791492542346
At time: 319.70195627212524 and batch: 800, loss is 4.10546865940094 and perplexity is 60.67117200081333
At time: 320.7611801624298 and batch: 850, loss is 4.115067381858825 and perplexity is 61.25634168986145
At time: 321.8165280818939 and batch: 900, loss is 4.111107969284058 and perplexity is 61.014282083444684
At time: 322.8615839481354 and batch: 950, loss is 4.190588612556457 and perplexity is 66.06166424371054
At time: 323.9075303077698 and batch: 1000, loss is 4.154730343818665 and perplexity is 63.734775754136734
At time: 324.9972059726715 and batch: 1050, loss is 4.109571776390076 and perplexity is 60.920624333480134
At time: 326.0428674221039 and batch: 1100, loss is 4.16518340587616 and perplexity is 64.40449352288182
At time: 327.0893154144287 and batch: 1150, loss is 4.1110877466201785 and perplexity is 61.013048224602265
At time: 328.1356177330017 and batch: 1200, loss is 4.174904198646545 and perplexity is 65.03360905480397
At time: 329.1817271709442 and batch: 1250, loss is 4.16229549407959 and perplexity is 64.2187673357885
At time: 330.2343327999115 and batch: 1300, loss is 4.183588562011718 and perplexity is 65.60084401907547
At time: 331.28288674354553 and batch: 1350, loss is 4.081072759628296 and perplexity is 59.20895276700102
At time: 332.3278155326843 and batch: 1400, loss is 4.111079216003418 and perplexity is 61.012527747890466
At time: 333.3746337890625 and batch: 1450, loss is 4.013541297912598 and perplexity is 55.342508262309536
At time: 334.42095589637756 and batch: 1500, loss is 4.027306575775146 and perplexity is 56.109580636115375
At time: 335.4677166938782 and batch: 1550, loss is 4.032314977645874 and perplexity is 56.39130486992948
At time: 336.51351141929626 and batch: 1600, loss is 4.125267610549927 and perplexity is 61.88436794436594
At time: 337.55930161476135 and batch: 1650, loss is 4.0773333024978635 and perplexity is 58.98795688622742
At time: 338.60625648498535 and batch: 1700, loss is 4.120158982276917 and perplexity is 61.56902987093635
At time: 339.652090549469 and batch: 1750, loss is 4.122324662208557 and perplexity is 61.70251317222021
At time: 340.69858860969543 and batch: 1800, loss is 4.076226043701172 and perplexity is 58.92267809899141
At time: 341.74457716941833 and batch: 1850, loss is 4.111468868255615 and perplexity is 61.03630604907313
At time: 342.7892620563507 and batch: 1900, loss is 4.186477284431458 and perplexity is 65.79062062194161
At time: 343.8420944213867 and batch: 1950, loss is 4.120369200706482 and perplexity is 61.58197417622376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.649898937136628 and perplexity of 104.57441645308803
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 347.15942311286926 and batch: 50, loss is 4.12630211353302 and perplexity is 61.94842063324767
At time: 348.20489501953125 and batch: 100, loss is 4.107883586883545 and perplexity is 60.8178655373148
At time: 349.25108909606934 and batch: 150, loss is 4.068620581626892 and perplexity is 58.47624372716152
At time: 350.29678678512573 and batch: 200, loss is 4.065839366912842 and perplexity is 58.313834689575934
At time: 351.3675870895386 and batch: 250, loss is 4.063746466636657 and perplexity is 58.19191727384747
At time: 352.41433358192444 and batch: 300, loss is 4.094122495651245 and perplexity is 59.98667748504601
At time: 353.4610393047333 and batch: 350, loss is 4.09303304195404 and perplexity is 59.921360363926915
At time: 354.50646138191223 and batch: 400, loss is 4.053876824378968 and perplexity is 57.620408799365514
At time: 355.5530652999878 and batch: 450, loss is 4.074073662757874 and perplexity is 58.795990438485454
At time: 356.59987330436707 and batch: 500, loss is 4.087152643203735 and perplexity is 59.57003285662526
At time: 357.64628410339355 and batch: 550, loss is 4.046356596946716 and perplexity is 57.18871547095066
At time: 358.69155526161194 and batch: 600, loss is 4.032459831237793 and perplexity is 56.399473944638494
At time: 359.7401223182678 and batch: 650, loss is 4.067275075912476 and perplexity is 58.3976165156124
At time: 360.78984451293945 and batch: 700, loss is 4.079412217140198 and perplexity is 59.11071537151351
At time: 361.83609223365784 and batch: 750, loss is 4.025545964241028 and perplexity is 56.01088037317909
At time: 362.87952518463135 and batch: 800, loss is 4.002323970794678 and perplexity is 54.72518209148819
At time: 363.9245252609253 and batch: 850, loss is 4.0051297760009765 and perplexity is 54.878945907097304
At time: 364.96785497665405 and batch: 900, loss is 4.0027833700180055 and perplexity is 54.75032857333233
At time: 366.0156571865082 and batch: 950, loss is 4.07378206729889 and perplexity is 58.778848294074315
At time: 367.0719439983368 and batch: 1000, loss is 4.015200581550598 and perplexity is 55.43441340802107
At time: 368.1263175010681 and batch: 1050, loss is 3.968581004142761 and perplexity is 52.909399328175446
At time: 369.17095017433167 and batch: 1100, loss is 4.006176195144653 and perplexity is 54.936402343193755
At time: 370.21507930755615 and batch: 1150, loss is 3.952490758895874 and perplexity is 52.0648865460118
At time: 371.25939178466797 and batch: 1200, loss is 4.008932585716248 and perplexity is 55.08803741137965
At time: 372.30421447753906 and batch: 1250, loss is 3.9920912408828735 and perplexity is 54.16804943913066
At time: 373.349374294281 and batch: 1300, loss is 3.9989600944519044 and perplexity is 54.54140262509515
At time: 374.39529061317444 and batch: 1350, loss is 3.896791434288025 and perplexity is 49.2441921259716
At time: 375.44175267219543 and batch: 1400, loss is 3.9154532814025877 and perplexity is 50.17180830520349
At time: 376.485178232193 and batch: 1450, loss is 3.8164097595214845 and perplexity is 45.440771809888886
At time: 377.5285608768463 and batch: 1500, loss is 3.8247142744064333 and perplexity is 45.819706632940424
At time: 378.57357811927795 and batch: 1550, loss is 3.8224308681488037 and perplexity is 45.71520098792112
At time: 379.6264772415161 and batch: 1600, loss is 3.8994171524047854 and perplexity is 49.37366339652684
At time: 380.6735906600952 and batch: 1650, loss is 3.847225980758667 and perplexity is 46.86288421299616
At time: 381.71689224243164 and batch: 1700, loss is 3.879207763671875 and perplexity is 48.38586684144089
At time: 382.7607958316803 and batch: 1750, loss is 3.869034547805786 and perplexity is 47.89612233529252
At time: 383.8047549724579 and batch: 1800, loss is 3.8162251138687133 and perplexity is 45.43238214349717
At time: 384.8492212295532 and batch: 1850, loss is 3.837902765274048 and perplexity is 46.428001846333494
At time: 385.89541387557983 and batch: 1900, loss is 3.8995496654510498 and perplexity is 49.380206484581436
At time: 386.94028329849243 and batch: 1950, loss is 3.8435001087188723 and perplexity is 46.68860397754591
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.568278467932413 and perplexity of 96.37804897244308
finished 9 epochs...
Completing Train Step...
At time: 390.2467260360718 and batch: 50, loss is 4.026977863311767 and perplexity is 56.09113974868615
At time: 391.31710624694824 and batch: 100, loss is 3.998804335594177 and perplexity is 54.532907980098706
At time: 392.3619930744171 and batch: 150, loss is 3.95467098236084 and perplexity is 52.178523465285906
At time: 393.40768933296204 and batch: 200, loss is 3.9533337116241456 and perplexity is 52.10879328722665
At time: 394.45246958732605 and batch: 250, loss is 3.952411241531372 and perplexity is 52.06074664804962
At time: 395.49761724472046 and batch: 300, loss is 3.981122784614563 and perplexity is 53.577156075765934
At time: 396.54527473449707 and batch: 350, loss is 3.9842310667037966 and perplexity is 53.74394807439204
At time: 397.59221267700195 and batch: 400, loss is 3.944993748664856 and perplexity is 51.676015067008215
At time: 398.6380925178528 and batch: 450, loss is 3.9737526845932005 and perplexity is 53.1837386204401
At time: 399.68247079849243 and batch: 500, loss is 3.9912710094451906 and perplexity is 54.1236373186614
At time: 400.7292249202728 and batch: 550, loss is 3.9530517768859865 and perplexity is 52.094104079031766
At time: 401.77511048316956 and batch: 600, loss is 3.9437627840042113 and perplexity is 51.61244285425887
At time: 402.82857370376587 and batch: 650, loss is 3.981991310119629 and perplexity is 53.62370941576178
At time: 403.91303420066833 and batch: 700, loss is 3.998684253692627 and perplexity is 54.52635995796873
At time: 404.9581425189972 and batch: 750, loss is 3.9465033626556396 and perplexity is 51.75408481510699
At time: 406.00241327285767 and batch: 800, loss is 3.92399432182312 and perplexity is 50.60216297003115
At time: 407.04743123054504 and batch: 850, loss is 3.931154646873474 and perplexity is 50.96579119970052
At time: 408.0921165943146 and batch: 900, loss is 3.9267067193984984 and perplexity is 50.73960246519368
At time: 409.13680267333984 and batch: 950, loss is 4.001304931640625 and perplexity is 54.669443393005814
At time: 410.1814775466919 and batch: 1000, loss is 3.9466344499588013 and perplexity is 51.76086956320045
At time: 411.22493052482605 and batch: 1050, loss is 3.906996560096741 and perplexity is 49.74930830529242
At time: 412.2717881202698 and batch: 1100, loss is 3.944689326286316 and perplexity is 51.66028612583037
At time: 413.316260099411 and batch: 1150, loss is 3.8958027601242065 and perplexity is 49.19552972509165
At time: 414.36073207855225 and batch: 1200, loss is 3.953264741897583 and perplexity is 52.10519948193542
At time: 415.4056406021118 and batch: 1250, loss is 3.9400743675231933 and perplexity is 51.42242531674125
At time: 416.4507532119751 and batch: 1300, loss is 3.9539996194839477 and perplexity is 52.14350449819285
At time: 417.49532866477966 and batch: 1350, loss is 3.8505368709564207 and perplexity is 47.018299216008955
At time: 418.5412595272064 and batch: 1400, loss is 3.8757777786254883 and perplexity is 48.220188341538
At time: 419.5870065689087 and batch: 1450, loss is 3.779681568145752 and perplexity is 43.80209153337055
At time: 420.6323096752167 and batch: 1500, loss is 3.790704941749573 and perplexity is 44.287609459259414
At time: 421.6770815849304 and batch: 1550, loss is 3.790596947669983 and perplexity is 44.28282691788635
At time: 422.73095178604126 and batch: 1600, loss is 3.871832113265991 and perplexity is 48.0303024741645
At time: 423.78367853164673 and batch: 1650, loss is 3.82354453086853 and perplexity is 45.766140662529644
At time: 424.83168029785156 and batch: 1700, loss is 3.857527856826782 and perplexity is 47.34815514710936
At time: 425.8854706287384 and batch: 1750, loss is 3.8540965700149536 and perplexity is 47.18596846043667
At time: 426.9304792881012 and batch: 1800, loss is 3.803988561630249 and perplexity is 44.8798339629686
At time: 427.97848558425903 and batch: 1850, loss is 3.828830962181091 and perplexity is 46.00872084839254
At time: 429.0240023136139 and batch: 1900, loss is 3.894980673789978 and perplexity is 49.155103371652636
At time: 430.06927371025085 and batch: 1950, loss is 3.843767886161804 and perplexity is 46.70110780658004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.568584779251453 and perplexity of 96.40757518162552
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 433.38044595718384 and batch: 50, loss is 3.996235909461975 and perplexity is 54.393023951973355
At time: 434.45778226852417 and batch: 100, loss is 3.9913649225234984 and perplexity is 54.12872047473489
At time: 435.5075714588165 and batch: 150, loss is 3.95874746799469 and perplexity is 52.3916626007421
At time: 436.5585582256317 and batch: 200, loss is 3.961087498664856 and perplexity is 52.51440425169423
At time: 437.61797404289246 and batch: 250, loss is 3.9632157373428343 and perplexity is 52.626286451756506
At time: 438.6748352050781 and batch: 300, loss is 3.9824905681610105 and perplexity is 53.650488168093794
At time: 439.7269639968872 and batch: 350, loss is 3.9886823081970215 and perplexity is 53.983708586164255
At time: 440.7764837741852 and batch: 400, loss is 3.9498648023605347 and perplexity is 51.928345770456964
At time: 441.82644486427307 and batch: 450, loss is 3.981190218925476 and perplexity is 53.580769136187335
At time: 442.87807989120483 and batch: 500, loss is 4.000741171836853 and perplexity is 54.63863164435497
At time: 443.9307134151459 and batch: 550, loss is 3.957235927581787 and perplexity is 52.3125303063189
At time: 444.98867201805115 and batch: 600, loss is 3.9431496143341063 and perplexity is 51.58080537026467
At time: 446.0427360534668 and batch: 650, loss is 3.9755109310150147 and perplexity is 53.277330993684686
At time: 447.10208201408386 and batch: 700, loss is 3.987822594642639 and perplexity is 53.9373180043402
At time: 448.1519491672516 and batch: 750, loss is 3.9329274988174436 and perplexity is 51.05622614189994
At time: 449.1999046802521 and batch: 800, loss is 3.9056280565261843 and perplexity is 49.68127276330307
At time: 450.2502112388611 and batch: 850, loss is 3.909663052558899 and perplexity is 49.882141481511965
At time: 451.31629490852356 and batch: 900, loss is 3.9012052822113037 and perplexity is 49.462028896650445
At time: 452.3727014064789 and batch: 950, loss is 3.9856098461151124 and perplexity is 53.81810023146643
At time: 453.42256355285645 and batch: 1000, loss is 3.9238662576675414 and perplexity is 50.59568306169079
At time: 454.48460960388184 and batch: 1050, loss is 3.8812633180618286 and perplexity is 48.485428915010544
At time: 455.53524899482727 and batch: 1100, loss is 3.913867835998535 and perplexity is 50.09232666586189
At time: 456.6312720775604 and batch: 1150, loss is 3.858579273223877 and perplexity is 47.39796395411289
At time: 457.68210673332214 and batch: 1200, loss is 3.911187143325806 and perplexity is 49.958224356653794
At time: 458.73261547088623 and batch: 1250, loss is 3.893055806159973 and perplexity is 49.060577308588314
At time: 459.7823498249054 and batch: 1300, loss is 3.903986430168152 and perplexity is 49.599781583769506
At time: 460.8325333595276 and batch: 1350, loss is 3.8000957012176513 and perplexity is 44.7054626557967
At time: 461.8859374523163 and batch: 1400, loss is 3.827819056510925 and perplexity is 45.96218791033153
At time: 462.9376790523529 and batch: 1450, loss is 3.7213651180267333 and perplexity is 41.3207633434461
At time: 463.98907947540283 and batch: 1500, loss is 3.729001536369324 and perplexity is 41.63751385902444
At time: 465.04029393196106 and batch: 1550, loss is 3.7311191892623903 and perplexity is 41.725781087398005
At time: 466.09129548072815 and batch: 1600, loss is 3.808615245819092 and perplexity is 45.0879598763339
At time: 467.1448791027069 and batch: 1650, loss is 3.7545084381103515 and perplexity is 42.71321845886462
At time: 468.1970024108887 and batch: 1700, loss is 3.782807641029358 and perplexity is 43.9392343114344
At time: 469.2471294403076 and batch: 1750, loss is 3.7757972145080565 and perplexity is 43.632278739769625
At time: 470.2980182170868 and batch: 1800, loss is 3.7281539392471315 and perplexity is 41.60223697450715
At time: 471.3497018814087 and batch: 1850, loss is 3.747143769264221 and perplexity is 42.399805258362726
At time: 472.400755405426 and batch: 1900, loss is 3.8111257410049437 and perplexity is 45.20129518689363
At time: 473.45303320884705 and batch: 1950, loss is 3.765080156326294 and perplexity is 43.16716584261887
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5395680982013085 and perplexity of 93.65034363162535
finished 11 epochs...
Completing Train Step...
At time: 476.8001661300659 and batch: 50, loss is 3.976226887702942 and perplexity is 53.3154889132034
At time: 477.8485209941864 and batch: 100, loss is 3.956912841796875 and perplexity is 52.2956316014168
At time: 478.89339876174927 and batch: 150, loss is 3.9189551210403444 and perplexity is 50.34780991707777
At time: 479.93986320495605 and batch: 200, loss is 3.918603916168213 and perplexity is 50.330130625642106
At time: 480.9845972061157 and batch: 250, loss is 3.919221591949463 and perplexity is 50.36122793143435
At time: 482.0281367301941 and batch: 300, loss is 3.9382478475570677 and perplexity is 51.32858695510261
At time: 483.1181218624115 and batch: 350, loss is 3.9453486251831054 and perplexity is 51.69435692566717
At time: 484.1626920700073 and batch: 400, loss is 3.9071849536895753 and perplexity is 49.75868163913538
At time: 485.2082841396332 and batch: 450, loss is 3.941336908340454 and perplexity is 51.48738922879206
At time: 486.25278520584106 and batch: 500, loss is 3.959435405731201 and perplexity is 52.427717202762445
At time: 487.29767537117004 and batch: 550, loss is 3.9176784467697146 and perplexity is 50.28357317699566
At time: 488.3417532444 and batch: 600, loss is 3.9062489604949953 and perplexity is 49.71212964132506
At time: 489.38689255714417 and batch: 650, loss is 3.9409816026687623 and perplexity is 51.46909871693219
At time: 490.4318959712982 and batch: 700, loss is 3.955240330696106 and perplexity is 52.208239679393294
At time: 491.47664070129395 and batch: 750, loss is 3.901757345199585 and perplexity is 49.4893425908757
At time: 492.52067255973816 and batch: 800, loss is 3.8758860445022583 and perplexity is 48.22540922512348
At time: 493.56475353240967 and batch: 850, loss is 3.881018109321594 and perplexity is 48.47354132159703
At time: 494.60797810554504 and batch: 900, loss is 3.874003472328186 and perplexity is 48.13470681533744
At time: 495.65286898612976 and batch: 950, loss is 3.961005439758301 and perplexity is 52.51009515390528
At time: 496.6974685192108 and batch: 1000, loss is 3.897936487197876 and perplexity is 49.300611626951074
At time: 497.74263215065 and batch: 1050, loss is 3.858096399307251 and perplexity is 47.375082238554675
At time: 498.7876355648041 and batch: 1100, loss is 3.8923471784591674 and perplexity is 49.02582393954423
At time: 499.85443925857544 and batch: 1150, loss is 3.8394197702407835 and perplexity is 46.498486805229085
At time: 500.90440917015076 and batch: 1200, loss is 3.8938368940353394 and perplexity is 49.0989129004665
At time: 501.9548428058624 and batch: 1250, loss is 3.878239116668701 and perplexity is 48.33902070887479
At time: 503.0047266483307 and batch: 1300, loss is 3.890959801673889 and perplexity is 48.9578538105234
At time: 504.0571234226227 and batch: 1350, loss is 3.7890458250045778 and perplexity is 44.21419206566444
At time: 505.1010022163391 and batch: 1400, loss is 3.818286828994751 and perplexity is 45.52614739838274
At time: 506.145222902298 and batch: 1450, loss is 3.713955578804016 and perplexity is 41.01572701164491
At time: 507.1893129348755 and batch: 1500, loss is 3.723633551597595 and perplexity is 41.41460314462566
At time: 508.2318181991577 and batch: 1550, loss is 3.7271664810180662 and perplexity is 41.56117677920941
At time: 509.27533531188965 and batch: 1600, loss is 3.8071694278717043 and perplexity is 45.02281799772987
At time: 510.32063460350037 and batch: 1650, loss is 3.7547233724594116 and perplexity is 42.72239998334748
At time: 511.36545586586 and batch: 1700, loss is 3.7847642135620116 and perplexity is 44.025288768835175
At time: 512.408442735672 and batch: 1750, loss is 3.77977436542511 and perplexity is 43.80615643689812
At time: 513.4520163536072 and batch: 1800, loss is 3.733792405128479 and perplexity is 41.837472328311534
At time: 514.4957044124603 and batch: 1850, loss is 3.754229254722595 and perplexity is 42.70129530228436
At time: 515.5405013561249 and batch: 1900, loss is 3.8190445280075074 and perplexity is 45.5606555870804
At time: 516.5851867198944 and batch: 1950, loss is 3.7732063817977903 and perplexity is 43.519381117364986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.538834540788518 and perplexity of 93.58167091861223
finished 12 epochs...
Completing Train Step...
At time: 519.8935122489929 and batch: 50, loss is 3.9606368255615236 and perplexity is 52.490742754361165
At time: 520.9654104709625 and batch: 100, loss is 3.9390174293518068 and perplexity is 51.36810370490822
At time: 522.0108468532562 and batch: 150, loss is 3.900402989387512 and perplexity is 49.42236178026562
At time: 523.0566649436951 and batch: 200, loss is 3.898827815055847 and perplexity is 49.344574225142864
At time: 524.1027355194092 and batch: 250, loss is 3.899005484580994 and perplexity is 49.35334203107691
At time: 525.1486263275146 and batch: 300, loss is 3.918137998580933 and perplexity is 50.306686394577405
At time: 526.19495677948 and batch: 350, loss is 3.9254852962493896 and perplexity is 50.677665773320875
At time: 527.2413029670715 and batch: 400, loss is 3.887244439125061 and perplexity is 48.7762951210342
At time: 528.2872548103333 and batch: 450, loss is 3.92230073928833 and perplexity is 50.51653655876612
At time: 529.3312621116638 and batch: 500, loss is 3.940581450462341 and perplexity is 51.44850736363058
At time: 530.3771216869354 and batch: 550, loss is 3.898629903793335 and perplexity is 49.33480934448165
At time: 531.4215841293335 and batch: 600, loss is 3.8882705926895142 and perplexity is 48.82637277942302
At time: 532.4662094116211 and batch: 650, loss is 3.923586435317993 and perplexity is 50.581527239429555
At time: 533.5102128982544 and batch: 700, loss is 3.938367414474487 and perplexity is 51.334724522938046
At time: 534.5555183887482 and batch: 750, loss is 3.885542941093445 and perplexity is 48.693372916885444
At time: 535.6523141860962 and batch: 800, loss is 3.86002552986145 and perplexity is 47.466563168166125
At time: 536.6974377632141 and batch: 850, loss is 3.865864243507385 and perplexity is 47.74451749649176
At time: 537.7417573928833 and batch: 900, loss is 3.8593718147277833 and perplexity is 47.435543697533305
At time: 538.7848768234253 and batch: 950, loss is 3.947657036781311 and perplexity is 51.813826618316085
At time: 539.8338754177094 and batch: 1000, loss is 3.884207968711853 and perplexity is 48.6284119790513
At time: 540.8857750892639 and batch: 1050, loss is 3.8457216882705687 and perplexity is 46.792441724640625
At time: 541.9455645084381 and batch: 1100, loss is 3.880514078140259 and perplexity is 48.44911530155619
At time: 542.9958803653717 and batch: 1150, loss is 3.8285413694381716 and perplexity is 45.9953989857743
At time: 544.0511593818665 and batch: 1200, loss is 3.8833972215652466 and perplexity is 48.58900261047054
At time: 545.097498178482 and batch: 1250, loss is 3.8688093423843384 and perplexity is 47.88533708337047
At time: 546.1419892311096 and batch: 1300, loss is 3.8824303436279295 and perplexity is 48.54204568031826
At time: 547.1881611347198 and batch: 1350, loss is 3.7815014791488646 and perplexity is 43.88188002366506
At time: 548.2323741912842 and batch: 1400, loss is 3.8111886548995972 and perplexity is 45.204139065876035
At time: 549.2777898311615 and batch: 1450, loss is 3.708126606941223 and perplexity is 40.77734293496233
At time: 550.3223598003387 and batch: 1500, loss is 3.718615026473999 and perplexity is 41.20728357262299
At time: 551.3668706417084 and batch: 1550, loss is 3.722610330581665 and perplexity is 41.37224852508547
At time: 552.4123713970184 and batch: 1600, loss is 3.8036483335494995 and perplexity is 44.86456718043635
At time: 553.4585256576538 and batch: 1650, loss is 3.751966705322266 and perplexity is 42.60479072655814
At time: 554.5035533905029 and batch: 1700, loss is 3.7827911281585695 and perplexity is 43.9385087545262
At time: 555.5488657951355 and batch: 1750, loss is 3.778729310035706 and perplexity is 43.76040048993847
At time: 556.5941307544708 and batch: 1800, loss is 3.733618474006653 and perplexity is 41.83019612261276
At time: 557.6403479576111 and batch: 1850, loss is 3.7547272443771362 and perplexity is 42.72256540128546
At time: 558.6868104934692 and batch: 1900, loss is 3.820016222000122 and perplexity is 45.60494811832217
At time: 559.7348959445953 and batch: 1950, loss is 3.7742054224014283 and perplexity is 43.562880471338865
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.539538858103198 and perplexity of 93.6476053264238
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 563.0966372489929 and batch: 50, loss is 3.9533621501922607 and perplexity is 52.110275207765696
At time: 564.1744232177734 and batch: 100, loss is 3.940529532432556 and perplexity is 51.44583632783094
At time: 565.2261128425598 and batch: 150, loss is 3.9077107286453248 and perplexity is 49.784850386605534
At time: 566.2780876159668 and batch: 200, loss is 3.909151668548584 and perplexity is 49.856639073275716
At time: 567.3298807144165 and batch: 250, loss is 3.9138113498687743 and perplexity is 50.08949722411069
At time: 568.3916687965393 and batch: 300, loss is 3.9293890810012817 and perplexity is 50.87588712724434
At time: 569.4505453109741 and batch: 350, loss is 3.9382593059539794 and perplexity is 51.32917510179446
At time: 570.5025391578674 and batch: 400, loss is 3.899891481399536 and perplexity is 49.397088311771924
At time: 571.5536105632782 and batch: 450, loss is 3.9358287048339844 and perplexity is 51.20456585034412
At time: 572.6040794849396 and batch: 500, loss is 3.9558450984954834 and perplexity is 52.239823090966105
At time: 573.6545493602753 and batch: 550, loss is 3.910364603996277 and perplexity is 49.91714864779591
At time: 574.7058424949646 and batch: 600, loss is 3.896164884567261 and perplexity is 49.21334785488957
At time: 575.7575876712799 and batch: 650, loss is 3.9281797361373902 and perplexity is 50.81439782283241
At time: 576.8080637454987 and batch: 700, loss is 3.9420520782470705 and perplexity is 51.52422463035408
At time: 577.8590776920319 and batch: 750, loss is 3.8881614875793455 and perplexity is 48.82104586324395
At time: 578.909952878952 and batch: 800, loss is 3.8619121742248534 and perplexity is 47.55620022205066
At time: 579.9609196186066 and batch: 850, loss is 3.8660310029983522 and perplexity is 47.75248001182
At time: 581.0146307945251 and batch: 900, loss is 3.8532228660583496 and perplexity is 47.14475989776013
At time: 582.066773891449 and batch: 950, loss is 3.9486762857437134 and perplexity is 51.86666473035602
At time: 583.118705034256 and batch: 1000, loss is 3.8818148374557495 and perplexity is 48.512176944730314
At time: 584.1763803958893 and batch: 1050, loss is 3.844428391456604 and perplexity is 46.731964324884366
At time: 585.2396740913391 and batch: 1100, loss is 3.87762113571167 and perplexity is 48.30915734304127
At time: 586.2942378520966 and batch: 1150, loss is 3.8276496601104735 and perplexity is 45.954402740551124
At time: 587.3488202095032 and batch: 1200, loss is 3.877271251678467 and perplexity is 48.292257696860034
At time: 588.4442956447601 and batch: 1250, loss is 3.8582273626327517 and perplexity is 47.38128704316256
At time: 589.4956328868866 and batch: 1300, loss is 3.869618182182312 and perplexity is 47.92408431778306
At time: 590.5611040592194 and batch: 1350, loss is 3.7651541090011595 and perplexity is 43.17035828804279
At time: 591.6195011138916 and batch: 1400, loss is 3.7934247875213623 and perplexity is 44.40822888535041
At time: 592.6715271472931 and batch: 1450, loss is 3.6891188526153567 and perplexity is 40.009577086381135
At time: 593.7224423885345 and batch: 1500, loss is 3.6953078079223634 and perplexity is 40.257962400797716
At time: 594.774209022522 and batch: 1550, loss is 3.701118965148926 and perplexity is 40.49258881515282
At time: 595.8274145126343 and batch: 1600, loss is 3.780387668609619 and perplexity is 43.83303113246777
At time: 596.8794388771057 and batch: 1650, loss is 3.7261045932769776 and perplexity is 41.517066899097706
At time: 597.9307065010071 and batch: 1700, loss is 3.7531819009780882 and perplexity is 42.65659535316989
At time: 598.9837210178375 and batch: 1750, loss is 3.7494683837890626 and perplexity is 42.498483111065056
At time: 600.0357854366302 and batch: 1800, loss is 3.7069682550430296 and perplexity is 40.730135768904
At time: 601.096607208252 and batch: 1850, loss is 3.7279442739486695 and perplexity is 41.593515343418844
At time: 602.1577653884888 and batch: 1900, loss is 3.7938037586212157 and perplexity is 44.42506151003132
At time: 603.2195463180542 and batch: 1950, loss is 3.7506092500686647 and perplexity is 42.54699586540157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.530938862645349 and perplexity of 92.84568952456799
finished 14 epochs...
Completing Train Step...
At time: 606.5692551136017 and batch: 50, loss is 3.9496568918228148 and perplexity is 51.91755044243503
At time: 607.6151745319366 and batch: 100, loss is 3.9313052129745483 and perplexity is 50.973465497899696
At time: 608.6616172790527 and batch: 150, loss is 3.8939738988876345 and perplexity is 49.10564015059871
At time: 609.7081134319305 and batch: 200, loss is 3.894129137992859 and perplexity is 49.1132638579706
At time: 610.7541041374207 and batch: 250, loss is 3.8974045085906983 and perplexity is 49.274391731074964
At time: 611.7996559143066 and batch: 300, loss is 3.911050715446472 and perplexity is 49.95140912695378
At time: 612.8459198474884 and batch: 350, loss is 3.9209947633743285 and perplexity is 50.4506062398366
At time: 613.8924973011017 and batch: 400, loss is 3.883272285461426 and perplexity is 48.582932468993654
At time: 614.9836189746857 and batch: 450, loss is 3.920008683204651 and perplexity is 50.40088241734204
At time: 616.0292663574219 and batch: 500, loss is 3.9385309171676637 and perplexity is 51.34311857485737
At time: 617.0744903087616 and batch: 550, loss is 3.894807481765747 and perplexity is 49.14659083697126
At time: 618.1200819015503 and batch: 600, loss is 3.881905608177185 and perplexity is 48.51658062988982
At time: 619.1653366088867 and batch: 650, loss is 3.914501495361328 and perplexity is 50.124078196422694
At time: 620.2114098072052 and batch: 700, loss is 3.930961422920227 and perplexity is 50.95594433939983
At time: 621.2564299106598 and batch: 750, loss is 3.87727822303772 and perplexity is 48.29259436071108
At time: 622.3076808452606 and batch: 800, loss is 3.85161669254303 and perplexity is 47.06909801235048
At time: 623.3533957004547 and batch: 850, loss is 3.855148310661316 and perplexity is 47.23562196813357
At time: 624.3983292579651 and batch: 900, loss is 3.843544774055481 and perplexity is 46.69068938633076
At time: 625.4441876411438 and batch: 950, loss is 3.938753118515015 and perplexity is 51.35452835256896
At time: 626.4902386665344 and batch: 1000, loss is 3.8730449199676515 and perplexity is 48.08858928506087
At time: 627.5339150428772 and batch: 1050, loss is 3.836421151161194 and perplexity is 46.35926439732788
At time: 628.5797693729401 and batch: 1100, loss is 3.870027618408203 and perplexity is 47.943710191493096
At time: 629.6256942749023 and batch: 1150, loss is 3.8211679792404176 and perplexity is 45.6575042076291
At time: 630.6730933189392 and batch: 1200, loss is 3.8713344669342042 and perplexity is 48.00640631673432
At time: 631.7184867858887 and batch: 1250, loss is 3.853075122833252 and perplexity is 47.137795093400385
At time: 632.7636981010437 and batch: 1300, loss is 3.865412588119507 and perplexity is 47.722958296953635
At time: 633.8083982467651 and batch: 1350, loss is 3.7624733781814577 and perplexity is 43.05478515752102
At time: 634.8551094532013 and batch: 1400, loss is 3.7918933725357054 and perplexity is 44.34027350537346
At time: 635.9088633060455 and batch: 1450, loss is 3.6892286205291747 and perplexity is 40.013969095237066
At time: 636.9535980224609 and batch: 1500, loss is 3.696622018814087 and perplexity is 40.31090463447357
At time: 637.9988787174225 and batch: 1550, loss is 3.703094692230225 and perplexity is 40.57267020290028
At time: 639.0445640087128 and batch: 1600, loss is 3.783207368850708 and perplexity is 43.956801556661915
At time: 640.0901155471802 and batch: 1650, loss is 3.7291832065582273 and perplexity is 41.64507884117774
At time: 641.1373152732849 and batch: 1700, loss is 3.7567913007736204 and perplexity is 42.810838254410484
At time: 642.183013677597 and batch: 1750, loss is 3.75400710105896 and perplexity is 42.69181010671547
At time: 643.2288062572479 and batch: 1800, loss is 3.7121763229370117 and perplexity is 40.94281442303078
At time: 644.2742402553558 and batch: 1850, loss is 3.733591275215149 and perplexity is 41.82905840730216
At time: 645.3201928138733 and batch: 1900, loss is 3.7993202924728395 and perplexity is 44.6708110854141
At time: 646.3653004169464 and batch: 1950, loss is 3.7559334421157837 and perplexity is 42.77412835436878
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.530161870912064 and perplexity of 92.77357721030023
finished 15 epochs...
Completing Train Step...
At time: 649.6861848831177 and batch: 50, loss is 3.946058530807495 and perplexity is 51.73106806957992
At time: 650.7614958286285 and batch: 100, loss is 3.9258158683776854 and perplexity is 50.694421166433024
At time: 651.8078324794769 and batch: 150, loss is 3.8876860618591307 and perplexity is 48.797840598979604
At time: 652.8631720542908 and batch: 200, loss is 3.8871379327774047 and perplexity is 48.771100412628265
At time: 653.918384552002 and batch: 250, loss is 3.889889841079712 and perplexity is 48.9054988500377
At time: 654.9719614982605 and batch: 300, loss is 3.903329305648804 and perplexity is 49.56719905769735
At time: 656.017168045044 and batch: 350, loss is 3.91347797870636 and perplexity is 50.07280161326855
At time: 657.06209897995 and batch: 400, loss is 3.875400605201721 and perplexity is 48.202004397472315
At time: 658.1080331802368 and batch: 450, loss is 3.9125256824493406 and perplexity is 50.02514016922304
At time: 659.1551840305328 and batch: 500, loss is 3.931059174537659 and perplexity is 50.96092560883637
At time: 660.2011573314667 and batch: 550, loss is 3.887333855628967 and perplexity is 48.780656721814054
At time: 661.2476985454559 and batch: 600, loss is 3.8751074361801146 and perplexity is 48.187875134235966
At time: 662.2941734790802 and batch: 650, loss is 3.9079259061813354 and perplexity is 49.79556412067849
At time: 663.3391046524048 and batch: 700, loss is 3.925006613731384 and perplexity is 50.65341306579852
At time: 664.3848392963409 and batch: 750, loss is 3.8716840600967406 and perplexity is 48.02319196204305
At time: 665.4293036460876 and batch: 800, loss is 3.8461749744415283 and perplexity is 46.81365689928923
At time: 666.4733254909515 and batch: 850, loss is 3.8498504734039307 and perplexity is 46.98603704410943
At time: 667.5641705989838 and batch: 900, loss is 3.8386764097213746 and perplexity is 46.463934509923
At time: 668.6092765331268 and batch: 950, loss is 3.9347790384292605 and perplexity is 51.15084633651935
At time: 669.6623203754425 and batch: 1000, loss is 3.8686603307724 and perplexity is 47.87820214371109
At time: 670.7118813991547 and batch: 1050, loss is 3.832459487915039 and perplexity is 46.175967922632715
At time: 671.7584722042084 and batch: 1100, loss is 3.866589388847351 and perplexity is 47.77915176678546
At time: 672.8035299777985 and batch: 1150, loss is 3.818005771636963 and perplexity is 45.51335373764514
At time: 673.8483743667603 and batch: 1200, loss is 3.868279619216919 and perplexity is 47.859977828223194
At time: 674.8926458358765 and batch: 1250, loss is 3.8505288410186767 and perplexity is 47.017921663509284
At time: 675.9409503936768 and batch: 1300, loss is 3.8632986450195315 and perplexity is 47.62218123456821
At time: 676.9929795265198 and batch: 1350, loss is 3.760905704498291 and perplexity is 42.98734218199642
At time: 678.0487117767334 and batch: 1400, loss is 3.790858964920044 and perplexity is 44.294431302628404
At time: 679.0943470001221 and batch: 1450, loss is 3.688849730491638 and perplexity is 39.99881107277777
At time: 680.1418681144714 and batch: 1500, loss is 3.6967612409591677 and perplexity is 40.31651719577428
At time: 681.1881711483002 and batch: 1550, loss is 3.7036874055862428 and perplexity is 40.59672529460168
At time: 682.2344028949738 and batch: 1600, loss is 3.7842160749435423 and perplexity is 44.00116342049332
At time: 683.2802562713623 and batch: 1650, loss is 3.730350303649902 and perplexity is 41.6937110653193
At time: 684.326122045517 and batch: 1700, loss is 3.7581773614883422 and perplexity is 42.87021781781279
At time: 685.3730449676514 and batch: 1750, loss is 3.7557451343536377 and perplexity is 42.76607441231432
At time: 686.4182970523834 and batch: 1800, loss is 3.7142180967330933 and perplexity is 41.026495788796296
At time: 687.4652624130249 and batch: 1850, loss is 3.7357500219345092 and perplexity is 41.91945428571069
At time: 688.5108389854431 and batch: 1900, loss is 3.8014587497711183 and perplexity is 44.766439920046864
At time: 689.5556209087372 and batch: 1950, loss is 3.757880001068115 and perplexity is 42.857471807000735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.530067905159884 and perplexity of 92.76486008089745
finished 16 epochs...
Completing Train Step...
At time: 692.8645288944244 and batch: 50, loss is 3.9422432231903075 and perplexity is 51.534074166660915
At time: 693.9367334842682 and batch: 100, loss is 3.921016602516174 and perplexity is 50.45170804981372
At time: 694.9828147888184 and batch: 150, loss is 3.882651672363281 and perplexity is 48.55279061893805
At time: 696.0356419086456 and batch: 200, loss is 3.881780786514282 and perplexity is 48.51052508755652
At time: 697.0818223953247 and batch: 250, loss is 3.8842576503753663 and perplexity is 48.6308279794674
At time: 698.1262233257294 and batch: 300, loss is 3.8977069997787477 and perplexity is 49.28929905492349
At time: 699.1697323322296 and batch: 350, loss is 3.9079939270019532 and perplexity is 49.79895137101357
At time: 700.2156701087952 and batch: 400, loss is 3.869660511016846 and perplexity is 47.92611293135246
At time: 701.2601141929626 and batch: 450, loss is 3.9071795034408567 and perplexity is 49.758410442683584
At time: 702.3043971061707 and batch: 500, loss is 3.925750002861023 and perplexity is 50.69108226215152
At time: 703.3501069545746 and batch: 550, loss is 3.8818949937820433 and perplexity is 48.51606565846514
At time: 704.3943228721619 and batch: 600, loss is 3.870145072937012 and perplexity is 47.949341728101246
At time: 705.4407856464386 and batch: 650, loss is 3.903062171936035 and perplexity is 49.55395975619213
At time: 706.4845292568207 and batch: 700, loss is 3.9204890012741087 and perplexity is 50.425096686693735
At time: 707.5286059379578 and batch: 750, loss is 3.86742338180542 and perplexity is 47.81901586377894
At time: 708.5717852115631 and batch: 800, loss is 3.8420147609710695 and perplexity is 46.61930664284047
At time: 709.6167986392975 and batch: 850, loss is 3.845834741592407 and perplexity is 46.79773206465415
At time: 710.6625754833221 and batch: 900, loss is 3.8349005651473997 and perplexity is 46.2888247166446
At time: 711.7081029415131 and batch: 950, loss is 3.931624159812927 and perplexity is 50.98972591652818
At time: 712.752685546875 and batch: 1000, loss is 3.865241174697876 and perplexity is 47.71477864245291
At time: 713.7973608970642 and batch: 1050, loss is 3.829353313446045 and perplexity is 46.03275983977879
At time: 714.8420689105988 and batch: 1100, loss is 3.863775472640991 and perplexity is 47.64489422063423
At time: 715.887815952301 and batch: 1150, loss is 3.8154761934280397 and perplexity is 45.398369641760056
At time: 716.9346013069153 and batch: 1200, loss is 3.865830340385437 and perplexity is 47.74289883573171
At time: 717.9798269271851 and batch: 1250, loss is 3.848447017669678 and perplexity is 46.92014047326648
At time: 719.0255589485168 and batch: 1300, loss is 3.861496410369873 and perplexity is 47.53643218262101
At time: 720.0720920562744 and batch: 1350, loss is 3.7593780612945555 and perplexity is 42.92172299497924
At time: 721.1250066757202 and batch: 1400, loss is 3.7895814180374146 and perplexity is 44.237879221658936
At time: 722.1769359111786 and batch: 1450, loss is 3.688086748123169 and perplexity is 39.9683043247049
At time: 723.2262306213379 and batch: 1500, loss is 3.6962573099136353 and perplexity is 40.296205569371
At time: 724.2714736461639 and batch: 1550, loss is 3.7034687852859496 and perplexity is 40.58785099641307
At time: 725.3172256946564 and batch: 1600, loss is 3.7842807531356812 and perplexity is 44.00400942823169
At time: 726.3625001907349 and batch: 1650, loss is 3.7305603075027465 and perplexity is 41.70246782472682
At time: 727.409576177597 and batch: 1700, loss is 3.7585023784637452 and perplexity is 42.88415363090803
At time: 728.4591042995453 and batch: 1750, loss is 3.7563431215286256 and perplexity is 42.79165562419348
At time: 729.5088593959808 and batch: 1800, loss is 3.7150100660324097 and perplexity is 41.05900038354117
At time: 730.5541355609894 and batch: 1850, loss is 3.73665714263916 and perplexity is 41.95749754292536
At time: 731.5981471538544 and batch: 1900, loss is 3.8023993301391603 and perplexity is 44.80856616303563
At time: 732.6418092250824 and batch: 1950, loss is 3.7586904048919676 and perplexity is 42.89221774325195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.53020757630814 and perplexity of 92.77781756029471
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 735.9619557857513 and batch: 50, loss is 3.940533437728882 and perplexity is 51.44603723945884
At time: 737.0109302997589 and batch: 100, loss is 3.9218504333496096 and perplexity is 50.49379378333784
At time: 738.0605020523071 and batch: 150, loss is 3.8853147554397585 and perplexity is 48.68226305535991
At time: 739.1165933609009 and batch: 200, loss is 3.8845462656021117 and perplexity is 48.64486560254995
At time: 740.1669836044312 and batch: 250, loss is 3.8887282323837282 and perplexity is 48.84872277946489
At time: 741.216671705246 and batch: 300, loss is 3.9003394174575807 and perplexity is 49.419220005210896
At time: 742.269278049469 and batch: 350, loss is 3.91122190952301 and perplexity is 49.95996124432607
At time: 743.319709777832 and batch: 400, loss is 3.8734919738769533 and perplexity is 48.11009228303509
At time: 744.3725528717041 and batch: 450, loss is 3.9106404829025267 and perplexity is 49.93092163591907
At time: 745.4225904941559 and batch: 500, loss is 3.9295328187942506 and perplexity is 50.88320044056252
At time: 746.4995241165161 and batch: 550, loss is 3.8851305770874025 and perplexity is 48.67329766200245
At time: 747.5503499507904 and batch: 600, loss is 3.8721603870391847 and perplexity is 48.046072151029364
At time: 748.6032762527466 and batch: 650, loss is 3.904007005691528 and perplexity is 49.60080213573409
At time: 749.6537370681763 and batch: 700, loss is 3.9216129398345947 and perplexity is 50.48180325865809
At time: 750.7035737037659 and batch: 750, loss is 3.8679544878005983 and perplexity is 47.844419575222304
At time: 751.7532346248627 and batch: 800, loss is 3.84367552280426 and perplexity is 46.6967945346592
At time: 752.8170046806335 and batch: 850, loss is 3.8468718671798707 and perplexity is 46.84629236722709
At time: 753.8722705841064 and batch: 900, loss is 3.8315390443801878 and perplexity is 46.13348510600912
At time: 754.9231827259064 and batch: 950, loss is 3.9292322254180907 and perplexity is 50.86790758613279
At time: 755.9742693901062 and batch: 1000, loss is 3.8634245204925537 and perplexity is 47.628176076451325
At time: 757.0248463153839 and batch: 1050, loss is 3.8279944181442263 and perplexity is 45.970248621422655
At time: 758.0759329795837 and batch: 1100, loss is 3.8613450956344604 and perplexity is 47.529239764136015
At time: 759.1270854473114 and batch: 1150, loss is 3.8148900127410887 and perplexity is 45.37176579235013
At time: 760.1791129112244 and batch: 1200, loss is 3.864554328918457 and perplexity is 47.682017200443475
At time: 761.2313759326935 and batch: 1250, loss is 3.846675443649292 and perplexity is 46.83709155674322
At time: 762.2832262516022 and batch: 1300, loss is 3.8582691240310667 and perplexity is 47.38326579328084
At time: 763.335604429245 and batch: 1350, loss is 3.753855657577515 and perplexity is 42.685345199910074
At time: 764.3878197669983 and batch: 1400, loss is 3.781693253517151 and perplexity is 43.89029625046832
At time: 765.4390156269073 and batch: 1450, loss is 3.6793103075027465 and perplexity is 39.61905967928409
At time: 766.4908316135406 and batch: 1500, loss is 3.6858777475357054 and perplexity is 39.88011176154627
At time: 767.5407047271729 and batch: 1550, loss is 3.6941919422149656 and perplexity is 40.21306497551227
At time: 768.5921123027802 and batch: 1600, loss is 3.774740791320801 and perplexity is 43.58620892768959
At time: 769.6423814296722 and batch: 1650, loss is 3.720429105758667 and perplexity is 41.28210469733675
At time: 770.6934790611267 and batch: 1700, loss is 3.7478848838806154 and perplexity is 42.43124002071409
At time: 771.7429556846619 and batch: 1750, loss is 3.744419379234314 and perplexity is 42.284448860907204
At time: 772.8007431030273 and batch: 1800, loss is 3.7033440542221068 and perplexity is 40.58278874629568
At time: 773.8554224967957 and batch: 1850, loss is 3.7256811380386354 and perplexity is 41.49949000141603
At time: 774.9068918228149 and batch: 1900, loss is 3.791009864807129 and perplexity is 44.30111583164511
At time: 775.9578890800476 and batch: 1950, loss is 3.749866399765015 and perplexity is 42.51540155297873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528804335483285 and perplexity of 92.64771924003814
finished 18 epochs...
Completing Train Step...
At time: 779.2782988548279 and batch: 50, loss is 3.9396243858337403 and perplexity is 51.39929137223752
At time: 780.3493301868439 and batch: 100, loss is 3.9195271635055544 and perplexity is 50.37661924167358
At time: 781.3932504653931 and batch: 150, loss is 3.882532863616943 and perplexity is 48.547022465413725
At time: 782.4373977184296 and batch: 200, loss is 3.881627893447876 and perplexity is 48.503108731592064
At time: 783.4813480377197 and batch: 250, loss is 3.885322165489197 and perplexity is 48.68262379467248
At time: 784.5269453525543 and batch: 300, loss is 3.8965275144577025 and perplexity is 49.231197322010004
At time: 785.5712802410126 and batch: 350, loss is 3.907437219619751 and perplexity is 49.77123564265051
At time: 786.6152067184448 and batch: 400, loss is 3.870105195045471 and perplexity is 47.94742964757748
At time: 787.6603121757507 and batch: 450, loss is 3.907453484535217 and perplexity is 49.77204517417434
At time: 788.7061793804169 and batch: 500, loss is 3.9262347507476805 and perplexity is 50.715660613821214
At time: 789.7497668266296 and batch: 550, loss is 3.881595869064331 and perplexity is 48.50155547430611
At time: 790.7933928966522 and batch: 600, loss is 3.868919429779053 and perplexity is 47.890608945552465
At time: 791.8383004665375 and batch: 650, loss is 3.900989990234375 and perplexity is 49.45138126488235
At time: 792.8832750320435 and batch: 700, loss is 3.9189690256118777 and perplexity is 50.34850998666938
At time: 793.9276211261749 and batch: 750, loss is 3.865434727668762 and perplexity is 47.72401487343548
At time: 794.9721901416779 and batch: 800, loss is 3.8410750675201415 and perplexity is 46.5755193622339
At time: 796.0157563686371 and batch: 850, loss is 3.8441134166717528 and perplexity is 46.717247252350504
At time: 797.0587630271912 and batch: 900, loss is 3.8295024394989015 and perplexity is 46.039625035432834
At time: 798.1011023521423 and batch: 950, loss is 3.927397747039795 and perplexity is 50.77467705036372
At time: 799.1769170761108 and batch: 1000, loss is 3.8615270709991454 and perplexity is 47.53788970188921
At time: 800.2216637134552 and batch: 1050, loss is 3.8261211824417116 and perplexity is 45.88421611519008
At time: 801.264586687088 and batch: 1100, loss is 3.8598863554000853 and perplexity is 47.45995749448556
At time: 802.3145360946655 and batch: 1150, loss is 3.813447437286377 and perplexity is 45.306360783853535
At time: 803.3597877025604 and batch: 1200, loss is 3.8633133697509767 and perplexity is 47.622882463560416
At time: 804.4038755893707 and batch: 1250, loss is 3.845325198173523 and perplexity is 46.773892662382956
At time: 805.4530880451202 and batch: 1300, loss is 3.8572745323181152 and perplexity is 47.336162218085995
At time: 806.496129989624 and batch: 1350, loss is 3.7532701539993285 and perplexity is 42.66036009270801
At time: 807.5390954017639 and batch: 1400, loss is 3.7815706396102904 and perplexity is 43.88491501968538
At time: 808.582923412323 and batch: 1450, loss is 3.6795122528076174 and perplexity is 39.6270613702945
At time: 809.6259958744049 and batch: 1500, loss is 3.686539988517761 and perplexity is 39.906530752827564
At time: 810.669380903244 and batch: 1550, loss is 3.6950648641586303 and perplexity is 40.24818316784177
At time: 811.7117686271667 and batch: 1600, loss is 3.7757097578048704 and perplexity is 43.62846297137824
At time: 812.754453420639 and batch: 1650, loss is 3.7215849781036376 and perplexity is 41.32984912841663
At time: 813.7980592250824 and batch: 1700, loss is 3.74912823677063 and perplexity is 42.48402983700531
At time: 814.8426713943481 and batch: 1750, loss is 3.7460093879699707 and perplexity is 42.351734982563435
At time: 815.8919022083282 and batch: 1800, loss is 3.7050186157226563 and perplexity is 40.65080405392917
At time: 816.937450170517 and batch: 1850, loss is 3.727442698478699 and perplexity is 41.57265828754381
At time: 817.9805631637573 and batch: 1900, loss is 3.7927646589279176 and perplexity is 44.37892341743182
At time: 819.0254690647125 and batch: 1950, loss is 3.7515759801864625 and perplexity is 42.588147215646416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528505121275436 and perplexity of 92.62000187303853
finished 19 epochs...
Completing Train Step...
At time: 822.3094222545624 and batch: 50, loss is 3.9387522745132446 and perplexity is 51.35448500927441
At time: 823.3825876712799 and batch: 100, loss is 3.9179430484771727 and perplexity is 50.2968800567493
At time: 824.4283313751221 and batch: 150, loss is 3.880611000061035 and perplexity is 48.45381131044056
At time: 825.4996325969696 and batch: 200, loss is 3.879482045173645 and perplexity is 48.39914000987167
At time: 826.5454494953156 and batch: 250, loss is 3.88295663356781 and perplexity is 48.56759959441516
At time: 827.5917174816132 and batch: 300, loss is 3.8939396429061888 and perplexity is 49.103958017512554
At time: 828.6365342140198 and batch: 350, loss is 3.9049084901809694 and perplexity is 49.64553665022924
At time: 829.6838984489441 and batch: 400, loss is 3.867637748718262 and perplexity is 47.82926777738108
At time: 830.7294144630432 and batch: 450, loss is 3.905130295753479 and perplexity is 49.65654952822218
At time: 831.7747128009796 and batch: 500, loss is 3.9239506578445433 and perplexity is 50.59995352650819
At time: 832.8206963539124 and batch: 550, loss is 3.879248857498169 and perplexity is 48.38785524270317
At time: 833.8659906387329 and batch: 600, loss is 3.866802940368652 and perplexity is 47.78935616687553
At time: 834.9107372760773 and batch: 650, loss is 3.8990122413635255 and perplexity is 49.35367550200282
At time: 835.955372095108 and batch: 700, loss is 3.9172022104263307 and perplexity is 50.2596320132522
At time: 837.0007684230804 and batch: 750, loss is 3.8637654256820677 and perplexity is 47.64441553674374
At time: 838.0453488826752 and batch: 800, loss is 3.8393666744232178 and perplexity is 46.4960179955989
At time: 839.0904796123505 and batch: 850, loss is 3.842344126701355 and perplexity is 46.63466397376872
At time: 840.1369304656982 and batch: 900, loss is 3.8280392265319825 and perplexity is 45.972308520298164
At time: 841.1811275482178 and batch: 950, loss is 3.9261225128173827 and perplexity is 50.70996871246982
At time: 842.2254881858826 and batch: 1000, loss is 3.8602724504470824 and perplexity is 47.47828508687352
At time: 843.2715010643005 and batch: 1050, loss is 3.824968204498291 and perplexity is 45.83134311261826
At time: 844.31596326828 and batch: 1100, loss is 3.8589689207077025 and perplexity is 47.4164360500752
At time: 845.3612389564514 and batch: 1150, loss is 3.8125871133804323 and perplexity is 45.26739940068764
At time: 846.4075074195862 and batch: 1200, loss is 3.8625302934646606 and perplexity is 47.58560471118405
At time: 847.452791929245 and batch: 1250, loss is 3.844550652503967 and perplexity is 46.73767817307147
At time: 848.498726606369 and batch: 1300, loss is 3.8567182445526123 and perplexity is 47.309837013051826
At time: 849.5434775352478 and batch: 1350, loss is 3.752948799133301 and perplexity is 42.64665318091509
At time: 850.5879826545715 and batch: 1400, loss is 3.7814944553375245 and perplexity is 43.881571806700954
At time: 851.6330881118774 and batch: 1450, loss is 3.6796923542022704 and perplexity is 39.6341989020337
At time: 852.6796677112579 and batch: 1500, loss is 3.6870032358169555 and perplexity is 39.925021628012345
At time: 853.7247970104218 and batch: 1550, loss is 3.695687246322632 and perplexity is 40.2732407160556
At time: 854.7687110900879 and batch: 1600, loss is 3.7764292192459106 and perplexity is 43.659863262512886
At time: 855.8144626617432 and batch: 1650, loss is 3.7223653411865234 and perplexity is 41.36211400441939
At time: 856.8602426052094 and batch: 1700, loss is 3.749934253692627 and perplexity is 42.51828648783408
At time: 857.90544962883 and batch: 1750, loss is 3.746997399330139 and perplexity is 42.39359965582987
At time: 858.9511187076569 and batch: 1800, loss is 3.7060690402984617 and perplexity is 40.693527092270024
At time: 860.0041620731354 and batch: 1850, loss is 3.728575654029846 and perplexity is 41.61978495269413
At time: 861.0534572601318 and batch: 1900, loss is 3.7938504600524903 and perplexity is 44.42713627243511
At time: 862.1058964729309 and batch: 1950, loss is 3.752594304084778 and perplexity is 42.631537832842696
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528370560047239 and perplexity of 92.60753965031566
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
1784.131948709488


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5152356624603271 and batch: 50, loss is 7.424964570999146 and perplexity is 1677.3401454791926
At time: 2.5706558227539062 and batch: 100, loss is 6.57428653717041 and perplexity is 716.4342927279708
At time: 3.6262621879577637 and batch: 150, loss is 6.393695850372314 and perplexity is 598.0628509628139
At time: 4.682326793670654 and batch: 200, loss is 6.306035823822022 and perplexity is 547.8687899175707
At time: 5.738464117050171 and batch: 250, loss is 6.237514934539795 and perplexity is 511.58560625212704
At time: 6.794936180114746 and batch: 300, loss is 6.171091537475586 and perplexity is 478.70834911642737
At time: 7.851060390472412 and batch: 350, loss is 6.127478065490723 and perplexity is 458.2789525863537
At time: 8.906618595123291 and batch: 400, loss is 6.084045915603638 and perplexity is 438.8009597455341
At time: 9.962177753448486 and batch: 450, loss is 6.011957845687866 and perplexity is 408.2818912196309
At time: 11.044297456741333 and batch: 500, loss is 5.994499273300171 and perplexity is 401.21573425413595
At time: 12.101018190383911 and batch: 550, loss is 5.945915927886963 and perplexity is 382.18925883301324
At time: 13.168987274169922 and batch: 600, loss is 5.988680305480957 and perplexity is 398.8878523115824
At time: 14.226139068603516 and batch: 650, loss is 6.079402713775635 and perplexity is 436.7682411404874
At time: 15.282618522644043 and batch: 700, loss is 5.972747917175293 and perplexity is 392.582975400845
At time: 16.339632034301758 and batch: 750, loss is 5.915247611999511 and perplexity is 370.64606775675134
At time: 17.397902250289917 and batch: 800, loss is 5.925576629638672 and perplexity is 374.49431763529384
At time: 18.455440044403076 and batch: 850, loss is 5.9550493049621585 and perplexity is 385.69592693230084
At time: 19.522924184799194 and batch: 900, loss is 5.968025970458984 and perplexity is 390.733589296871
At time: 20.580109119415283 and batch: 950, loss is 5.984917964935303 and perplexity is 397.38992000434973
At time: 21.638381481170654 and batch: 1000, loss is 5.964450168609619 and perplexity is 389.33889846077415
At time: 22.69608974456787 and batch: 1050, loss is 5.862429494857788 and perplexity is 351.57726242808116
At time: 23.752384901046753 and batch: 1100, loss is 5.946541633605957 and perplexity is 382.4284716686183
At time: 24.811745643615723 and batch: 1150, loss is 5.861757898330689 and perplexity is 351.34122362991786
At time: 25.874220848083496 and batch: 1200, loss is 5.938831310272217 and perplexity is 379.4911628520579
At time: 26.940260648727417 and batch: 1250, loss is 5.874749574661255 and perplexity is 355.93551423725785
At time: 27.996880769729614 and batch: 1300, loss is 5.89401424407959 and perplexity is 362.8589691661238
At time: 29.05463743209839 and batch: 1350, loss is 5.876438951492309 and perplexity is 356.53733165342743
At time: 30.113734483718872 and batch: 1400, loss is 5.890982675552368 and perplexity is 361.7606030626376
At time: 31.17380714416504 and batch: 1450, loss is 5.867465381622314 and perplexity is 353.35223123047865
At time: 32.236209869384766 and batch: 1500, loss is 5.859057865142822 and perplexity is 350.3938701842547
At time: 33.29377245903015 and batch: 1550, loss is 5.839984140396118 and perplexity is 343.7738885040355
At time: 34.35263776779175 and batch: 1600, loss is 5.841957111358642 and perplexity is 344.45281393357413
At time: 35.41074013710022 and batch: 1650, loss is 5.830992069244385 and perplexity is 340.69650599545815
At time: 36.468610525131226 and batch: 1700, loss is 5.844882326126099 and perplexity is 345.46188755056403
At time: 37.5268132686615 and batch: 1750, loss is 5.864095344543457 and perplexity is 352.16342539432884
At time: 38.58448767662048 and batch: 1800, loss is 5.865928392410279 and perplexity is 352.80954981760027
At time: 39.64259314537048 and batch: 1850, loss is 5.828710870742798 and perplexity is 339.9201954323835
At time: 40.701077938079834 and batch: 1900, loss is 5.807870082855224 and perplexity is 332.90930078141946
At time: 41.75917029380798 and batch: 1950, loss is 5.74898323059082 and perplexity is 313.8713631869349
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.222535315225291 and perplexity of 185.40364538797945
finished 1 epochs...
Completing Train Step...
At time: 45.06819701194763 and batch: 50, loss is 5.472733945846557 and perplexity is 238.110284321526
At time: 46.138044357299805 and batch: 100, loss is 5.3854407787323 and perplexity is 218.20626359363135
At time: 47.18316650390625 and batch: 150, loss is 5.302090902328491 and perplexity is 200.7561329061283
At time: 48.227574825286865 and batch: 200, loss is 5.266843738555909 and perplexity is 193.80330220556647
At time: 49.27189016342163 and batch: 250, loss is 5.269758987426758 and perplexity is 194.36911140007675
At time: 50.31649088859558 and batch: 300, loss is 5.279273862838745 and perplexity is 196.2273356459063
At time: 51.361475229263306 and batch: 350, loss is 5.247077217102051 and perplexity is 190.01009780721864
At time: 52.406206369400024 and batch: 400, loss is 5.220142345428467 and perplexity is 184.96051048003076
At time: 53.45161294937134 and batch: 450, loss is 5.1681639671325685 and perplexity is 175.5921483851207
At time: 54.49657702445984 and batch: 500, loss is 5.160992755889892 and perplexity is 174.33744424776197
At time: 55.54134726524353 and batch: 550, loss is 5.111681051254273 and perplexity is 165.94908944949964
At time: 56.586233615875244 and batch: 600, loss is 5.12199670791626 and perplexity is 167.6698232703035
At time: 57.630112171173096 and batch: 650, loss is 5.189908571243286 and perplexity is 179.45214509525414
At time: 58.6747145652771 and batch: 700, loss is 5.146978282928467 and perplexity is 171.91123756306695
At time: 59.71896052360535 and batch: 750, loss is 5.099474954605102 and perplexity is 163.93581095703365
At time: 60.763019323349 and batch: 800, loss is 5.081014680862427 and perplexity is 160.93727307898848
At time: 61.80736494064331 and batch: 850, loss is 5.080097074508667 and perplexity is 160.78966374864146
At time: 62.852402687072754 and batch: 900, loss is 5.103603620529174 and perplexity is 164.61404629360197
At time: 63.89699840545654 and batch: 950, loss is 5.157539978027343 and perplexity is 173.73653378181518
At time: 64.95011901855469 and batch: 1000, loss is 5.128156023025513 and perplexity is 168.70574154469645
At time: 65.99788212776184 and batch: 1050, loss is 5.037148847579956 and perplexity is 154.03022472124502
At time: 67.05315470695496 and batch: 1100, loss is 5.123724060058594 and perplexity is 167.95969838485811
At time: 68.09995222091675 and batch: 1150, loss is 5.0336598300933835 and perplexity is 153.49374700801593
At time: 69.14472317695618 and batch: 1200, loss is 5.101683540344238 and perplexity is 164.2982773729875
At time: 70.18912053108215 and batch: 1250, loss is 5.043718013763428 and perplexity is 155.04540566011076
At time: 71.23336887359619 and batch: 1300, loss is 5.077878818511963 and perplexity is 160.43338641608102
At time: 72.28915882110596 and batch: 1350, loss is 5.007839956283569 and perplexity is 149.58128482592676
At time: 73.33595013618469 and batch: 1400, loss is 5.009440498352051 and perplexity is 149.8208876610069
At time: 74.38157963752747 and batch: 1450, loss is 4.954119729995727 and perplexity is 141.7577663249764
At time: 75.42898726463318 and batch: 1500, loss is 4.941797170639038 and perplexity is 140.0216664005359
At time: 76.47451400756836 and batch: 1550, loss is 4.930372037887573 and perplexity is 138.43100433930843
At time: 77.52904391288757 and batch: 1600, loss is 4.988752965927124 and perplexity is 146.75330297154645
At time: 78.57728481292725 and batch: 1650, loss is 4.9595228099823 and perplexity is 142.5257677934579
At time: 79.62688040733337 and batch: 1700, loss is 4.977610130310058 and perplexity is 145.12713194428628
At time: 80.67443251609802 and batch: 1750, loss is 5.004647474288941 and perplexity is 149.10451071870074
At time: 81.72012901306152 and batch: 1800, loss is 4.95573395729065 and perplexity is 141.98678037127857
At time: 82.76657891273499 and batch: 1850, loss is 4.959703092575073 and perplexity is 142.55146502472488
At time: 83.81310081481934 and batch: 1900, loss is 5.012516088485718 and perplexity is 150.2823846288902
At time: 84.85929107666016 and batch: 1950, loss is 4.939199657440185 and perplexity is 139.65843023353597
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.779789130632268 and perplexity of 119.07923723368009
finished 2 epochs...
Completing Train Step...
At time: 88.20923948287964 and batch: 50, loss is 4.86020523071289 and perplexity is 129.0506845537695
At time: 89.25518202781677 and batch: 100, loss is 4.810544233322144 and perplexity is 122.79843033242979
At time: 90.30129837989807 and batch: 150, loss is 4.758476591110229 and perplexity is 116.56820951935713
At time: 91.34985208511353 and batch: 200, loss is 4.7514119052886965 and perplexity is 115.74759385132157
At time: 92.40202760696411 and batch: 250, loss is 4.757130842208863 and perplexity is 116.41144348697925
At time: 93.44679284095764 and batch: 300, loss is 4.785177679061889 and perplexity is 119.7226333993474
At time: 94.49224352836609 and batch: 350, loss is 4.782080144882202 and perplexity is 119.35236221019672
At time: 95.5382513999939 and batch: 400, loss is 4.763142366409301 and perplexity is 117.11336138106351
At time: 96.58313274383545 and batch: 450, loss is 4.750460147857666 and perplexity is 115.63748262664978
At time: 97.6267569065094 and batch: 500, loss is 4.755126085281372 and perplexity is 116.1783006146881
At time: 98.7177939414978 and batch: 550, loss is 4.717246036529541 and perplexity is 111.8597703668798
At time: 99.77410125732422 and batch: 600, loss is 4.701353454589844 and perplexity is 110.09608170554398
At time: 100.82668328285217 and batch: 650, loss is 4.764326438903809 and perplexity is 117.25211422151384
At time: 101.87357473373413 and batch: 700, loss is 4.7690887451171875 and perplexity is 117.81183642000047
At time: 102.91803908348083 and batch: 750, loss is 4.726312742233277 and perplexity is 112.87858163657361
At time: 103.96279525756836 and batch: 800, loss is 4.700573062896728 and perplexity is 110.01019715409033
At time: 105.00889086723328 and batch: 850, loss is 4.709999465942383 and perplexity is 111.05210059746315
At time: 106.0534131526947 and batch: 900, loss is 4.725613832473755 and perplexity is 112.79971725697939
At time: 107.09996271133423 and batch: 950, loss is 4.788428287506104 and perplexity is 120.11243801028118
At time: 108.14594602584839 and batch: 1000, loss is 4.763776254653931 and perplexity is 117.18762169801641
At time: 109.19190049171448 and batch: 1050, loss is 4.686184492111206 and perplexity is 108.43864098212755
At time: 110.23875117301941 and batch: 1100, loss is 4.767517852783203 and perplexity is 117.62691199552425
At time: 111.28488349914551 and batch: 1150, loss is 4.69432074546814 and perplexity is 109.32452423712816
At time: 112.33292841911316 and batch: 1200, loss is 4.7627331638336186 and perplexity is 117.06544809572797
At time: 113.37902641296387 and batch: 1250, loss is 4.72781156539917 and perplexity is 113.04789352225578
At time: 114.42535257339478 and batch: 1300, loss is 4.74867917060852 and perplexity is 115.43171818622513
At time: 115.47059345245361 and batch: 1350, loss is 4.6530837726593015 and perplexity is 104.90799969127792
At time: 116.51530742645264 and batch: 1400, loss is 4.660688428878784 and perplexity is 105.70883012428553
At time: 117.56049299240112 and batch: 1450, loss is 4.596718997955322 and perplexity is 99.15844228680628
At time: 118.60549068450928 and batch: 1500, loss is 4.593826112747192 and perplexity is 98.8720028138732
At time: 119.65066266059875 and batch: 1550, loss is 4.605364389419556 and perplexity is 100.01942222901718
At time: 120.69855284690857 and batch: 1600, loss is 4.6844552135467525 and perplexity is 108.25128240899072
At time: 121.74423003196716 and batch: 1650, loss is 4.644201154708862 and perplexity is 103.98026845105392
At time: 122.79234027862549 and batch: 1700, loss is 4.662785911560059 and perplexity is 105.93078525687926
At time: 123.83706283569336 and batch: 1750, loss is 4.68268630027771 and perplexity is 108.05996454139084
At time: 124.88423728942871 and batch: 1800, loss is 4.635391159057617 and perplexity is 103.06822618148269
At time: 125.93004536628723 and batch: 1850, loss is 4.662633476257324 and perplexity is 105.91463889622861
At time: 126.9774112701416 and batch: 1900, loss is 4.729684295654297 and perplexity is 113.2598000927244
At time: 128.0232756137848 and batch: 1950, loss is 4.666993227005005 and perplexity is 106.37740836912002
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.678707814771076 and perplexity of 107.63090361090586
finished 3 epochs...
Completing Train Step...
At time: 131.34725713729858 and batch: 50, loss is 4.600264539718628 and perplexity is 99.51063667612763
At time: 132.42327690124512 and batch: 100, loss is 4.549965314865112 and perplexity is 94.62912603400041
At time: 133.475084066391 and batch: 150, loss is 4.507063865661621 and perplexity is 90.65525136706833
At time: 134.52054047584534 and batch: 200, loss is 4.5059410667419435 and perplexity is 90.55352087090333
At time: 135.5651559829712 and batch: 250, loss is 4.505880346298218 and perplexity is 90.54802258786592
At time: 136.60998487472534 and batch: 300, loss is 4.537218046188355 and perplexity is 93.43051885406021
At time: 137.65757203102112 and batch: 350, loss is 4.538105659484863 and perplexity is 93.51348584074783
At time: 138.70401668548584 and batch: 400, loss is 4.515571546554566 and perplexity is 91.42980748320429
At time: 139.7499361038208 and batch: 450, loss is 4.520680751800537 and perplexity is 91.89813651102807
At time: 140.7957100868225 and batch: 500, loss is 4.535508460998535 and perplexity is 93.2709278788035
At time: 141.84342789649963 and batch: 550, loss is 4.495930366516113 and perplexity is 89.65153898679411
At time: 142.89061045646667 and batch: 600, loss is 4.477250366210938 and perplexity is 87.99239288129621
At time: 143.93592166900635 and batch: 650, loss is 4.537354812622071 and perplexity is 93.44329788677555
At time: 144.98046493530273 and batch: 700, loss is 4.556109600067138 and perplexity is 95.21234426753763
At time: 146.02577352523804 and batch: 750, loss is 4.522651958465576 and perplexity is 92.0794653898554
At time: 147.07289123535156 and batch: 800, loss is 4.489271478652954 and perplexity is 89.05654264742176
At time: 148.11881923675537 and batch: 850, loss is 4.498718109130859 and perplexity is 89.90181309031311
At time: 149.16519594192505 and batch: 900, loss is 4.507538223266602 and perplexity is 90.69826457600058
At time: 150.2118899822235 and batch: 950, loss is 4.583421478271484 and perplexity is 97.84860901630353
At time: 151.30344367027283 and batch: 1000, loss is 4.549802474975586 and perplexity is 94.61371789213516
At time: 152.35421776771545 and batch: 1050, loss is 4.479708566665649 and perplexity is 88.20896189745913
At time: 153.39915347099304 and batch: 1100, loss is 4.558028326034546 and perplexity is 95.3952060396162
At time: 154.4450557231903 and batch: 1150, loss is 4.490004510879516 and perplexity is 89.12184789567006
At time: 155.4922001361847 and batch: 1200, loss is 4.559821157455445 and perplexity is 95.56638696582723
At time: 156.54132914543152 and batch: 1250, loss is 4.539839143753052 and perplexity is 93.67573058104037
At time: 157.59350895881653 and batch: 1300, loss is 4.545510473251343 and perplexity is 94.20850585922057
At time: 158.64859223365784 and batch: 1350, loss is 4.442489652633667 and perplexity is 84.9862647820468
At time: 159.69757676124573 and batch: 1400, loss is 4.454529705047608 and perplexity is 86.01568858711724
At time: 160.74422526359558 and batch: 1450, loss is 4.385631580352783 and perplexity is 80.28891610485672
At time: 161.78903484344482 and batch: 1500, loss is 4.3895715236663815 and perplexity is 80.60587387082028
At time: 162.83597612380981 and batch: 1550, loss is 4.404395589828491 and perplexity is 81.80968129363974
At time: 163.8870668411255 and batch: 1600, loss is 4.488748779296875 and perplexity is 89.01000501358052
At time: 164.94391989707947 and batch: 1650, loss is 4.447614736557007 and perplexity is 85.42294457584488
At time: 166.00390815734863 and batch: 1700, loss is 4.469038143157959 and perplexity is 87.27273874860707
At time: 167.0492024421692 and batch: 1750, loss is 4.489235982894898 and perplexity is 89.0533815740333
At time: 168.09446549415588 and batch: 1800, loss is 4.43975378036499 and perplexity is 84.75407098812282
At time: 169.1409592628479 and batch: 1850, loss is 4.47067702293396 and perplexity is 87.41588554329164
At time: 170.18570852279663 and batch: 1900, loss is 4.545497350692749 and perplexity is 94.20726961069373
At time: 171.23985409736633 and batch: 1950, loss is 4.486351776123047 and perplexity is 88.79690325389119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.637138898982558 and perplexity of 103.2485201429565
finished 4 epochs...
Completing Train Step...
At time: 174.5512614250183 and batch: 50, loss is 4.426276798248291 and perplexity is 83.6195043288568
At time: 175.64918780326843 and batch: 100, loss is 4.382029294967651 and perplexity is 80.00021282378466
At time: 176.6992838382721 and batch: 150, loss is 4.337418060302735 and perplexity is 76.509740559542
At time: 177.77719736099243 and batch: 200, loss is 4.341585855484009 and perplexity is 76.8292829185675
At time: 178.8280644416809 and batch: 250, loss is 4.338262872695923 and perplexity is 76.57440424706269
At time: 179.87888407707214 and batch: 300, loss is 4.363753633499146 and perplexity is 78.5514350271529
At time: 180.93042540550232 and batch: 350, loss is 4.369755535125733 and perplexity is 79.02431066983216
At time: 181.9829125404358 and batch: 400, loss is 4.339502878189087 and perplexity is 76.66941582422938
At time: 183.03521394729614 and batch: 450, loss is 4.356712303161621 and perplexity is 78.00027116528963
At time: 184.08765268325806 and batch: 500, loss is 4.378489637374878 and perplexity is 79.71754004060914
At time: 185.13898229599 and batch: 550, loss is 4.3393590545654295 and perplexity is 76.65838974394623
At time: 186.18972086906433 and batch: 600, loss is 4.321215124130249 and perplexity is 75.2800473400781
At time: 187.2405138015747 and batch: 650, loss is 4.379869232177734 and perplexity is 79.8275938419165
At time: 188.29035568237305 and batch: 700, loss is 4.4013352394104 and perplexity is 81.55969771507033
At time: 189.34236359596252 and batch: 750, loss is 4.367296466827392 and perplexity is 78.83022322760807
At time: 190.39413857460022 and batch: 800, loss is 4.3366403484344485 and perplexity is 76.45026115818546
At time: 191.44609546661377 and batch: 850, loss is 4.344149980545044 and perplexity is 77.02653559050638
At time: 192.49760365486145 and batch: 900, loss is 4.349735012054444 and perplexity is 77.4579347865202
At time: 193.54756116867065 and batch: 950, loss is 4.423209762573242 and perplexity is 83.36343321630119
At time: 194.59957575798035 and batch: 1000, loss is 4.390076656341552 and perplexity is 80.64660081691275
At time: 195.6503689289093 and batch: 1050, loss is 4.33362419128418 and perplexity is 76.2200225488112
At time: 196.70262670516968 and batch: 1100, loss is 4.402816743850708 and perplexity is 81.68061831947456
At time: 197.75433349609375 and batch: 1150, loss is 4.338813080787658 and perplexity is 76.61654769666957
At time: 198.80804109573364 and batch: 1200, loss is 4.405950303077698 and perplexity is 81.93697081277165
At time: 199.85992908477783 and batch: 1250, loss is 4.390520076751709 and perplexity is 80.68236909533104
At time: 200.91033029556274 and batch: 1300, loss is 4.3922630786895756 and perplexity is 80.82312125102149
At time: 201.96104311943054 and batch: 1350, loss is 4.287935471534729 and perplexity is 72.81598254312648
At time: 203.01236009597778 and batch: 1400, loss is 4.306409959793091 and perplexity is 74.17372372746208
At time: 204.06291151046753 and batch: 1450, loss is 4.235532040596008 and perplexity is 69.09843212651448
At time: 205.11467242240906 and batch: 1500, loss is 4.238348917961121 and perplexity is 69.29334833457865
At time: 206.17407035827637 and batch: 1550, loss is 4.2579112720489505 and perplexity is 70.66223501948122
At time: 207.22403526306152 and batch: 1600, loss is 4.346699190139771 and perplexity is 77.22314286418596
At time: 208.2745726108551 and batch: 1650, loss is 4.301460084915161 and perplexity is 73.80748025325236
At time: 209.3285014629364 and batch: 1700, loss is 4.3286045551300045 and perplexity is 75.83838441158514
At time: 210.37931442260742 and batch: 1750, loss is 4.341642055511475 and perplexity is 76.83360084771041
At time: 211.4333038330078 and batch: 1800, loss is 4.291818399429321 and perplexity is 73.09927139207043
At time: 212.48332929611206 and batch: 1850, loss is 4.321969242095947 and perplexity is 75.33683878726977
At time: 213.53406524658203 and batch: 1900, loss is 4.40207760810852 and perplexity is 81.6202675614794
At time: 214.58482384681702 and batch: 1950, loss is 4.34497633934021 and perplexity is 77.09021345240974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.618577114371366 and perplexity of 101.34972042371032
finished 5 epochs...
Completing Train Step...
At time: 217.91933298110962 and batch: 50, loss is 4.292454805374145 and perplexity is 73.14580700914773
At time: 218.96367740631104 and batch: 100, loss is 4.248829030990601 and perplexity is 70.02336912584785
At time: 220.00773978233337 and batch: 150, loss is 4.209656724929809 and perplexity is 67.33342195730376
At time: 221.05277633666992 and batch: 200, loss is 4.209105892181396 and perplexity is 67.29634271659454
At time: 222.09664249420166 and batch: 250, loss is 4.1987888145446775 and perplexity is 66.60561042038822
At time: 223.13988161087036 and batch: 300, loss is 4.2265265417099 and perplexity is 68.47895978823726
At time: 224.1833152770996 and batch: 350, loss is 4.232526473999023 and perplexity is 68.89106397251324
At time: 225.2282419204712 and batch: 400, loss is 4.198026223182678 and perplexity is 66.55483691939817
At time: 226.27217411994934 and batch: 450, loss is 4.223485951423645 and perplexity is 68.27105955817538
At time: 227.31577610969543 and batch: 500, loss is 4.249860458374023 and perplexity is 70.09563040596905
At time: 228.3584225177765 and batch: 550, loss is 4.2155903673171995 and perplexity is 67.73414209319361
At time: 229.4010136127472 and batch: 600, loss is 4.1995065927505495 and perplexity is 66.65343563783284
At time: 230.46980953216553 and batch: 650, loss is 4.24858211517334 and perplexity is 70.00608138282921
At time: 231.51231050491333 and batch: 700, loss is 4.2722403049469 and perplexity is 71.68204550975199
At time: 232.55533385276794 and batch: 750, loss is 4.244225945472717 and perplexity is 69.70178627401381
At time: 233.59885597229004 and batch: 800, loss is 4.212050800323486 and perplexity is 67.49481636408547
At time: 234.64197182655334 and batch: 850, loss is 4.22115800857544 and perplexity is 68.11231328115905
At time: 235.68537521362305 and batch: 900, loss is 4.2250536346435545 and perplexity is 68.37817088903154
At time: 236.7275800704956 and batch: 950, loss is 4.298690614700317 and perplexity is 73.60335542434439
At time: 237.7713222503662 and batch: 1000, loss is 4.265797929763794 and perplexity is 71.22172724227103
At time: 238.81524801254272 and batch: 1050, loss is 4.211428194046021 and perplexity is 67.45280674680357
At time: 239.85890984535217 and batch: 1100, loss is 4.270518336296082 and perplexity is 71.55871748852495
At time: 240.90245985984802 and batch: 1150, loss is 4.2115064001083375 and perplexity is 67.45808217149387
At time: 241.94690942764282 and batch: 1200, loss is 4.277312870025635 and perplexity is 72.04658113426385
At time: 242.99000120162964 and batch: 1250, loss is 4.272157363891601 and perplexity is 71.67610037180287
At time: 244.03329253196716 and batch: 1300, loss is 4.271860637664795 and perplexity is 71.65483534808851
At time: 245.07725882530212 and batch: 1350, loss is 4.165667796134949 and perplexity is 64.43569798912614
At time: 246.1213035583496 and batch: 1400, loss is 4.1857111501693725 and perplexity is 65.74023547671682
At time: 247.16495871543884 and batch: 1450, loss is 4.1135871744155885 and perplexity is 61.16573667060169
At time: 248.20860385894775 and batch: 1500, loss is 4.119518570899963 and perplexity is 61.52961298659675
At time: 249.2520580291748 and batch: 1550, loss is 4.1379643821716305 and perplexity is 62.67510893722154
At time: 250.2960593700409 and batch: 1600, loss is 4.229637823104858 and perplexity is 68.6923488864029
At time: 251.33940196037292 and batch: 1650, loss is 4.180095191001892 and perplexity is 65.37207575122697
At time: 252.39535403251648 and batch: 1700, loss is 4.210280313491821 and perplexity is 67.3754234035271
At time: 253.4478645324707 and batch: 1750, loss is 4.217868738174438 and perplexity is 67.888641525247
At time: 254.49071168899536 and batch: 1800, loss is 4.170852022171021 and perplexity is 64.77061460390412
At time: 255.5346622467041 and batch: 1850, loss is 4.2017139720916745 and perplexity is 66.80072755944029
At time: 256.5781514644623 and batch: 1900, loss is 4.285713567733764 and perplexity is 72.65437204272283
At time: 257.62088203430176 and batch: 1950, loss is 4.227796196937561 and perplexity is 68.56595967576104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614512172965116 and perplexity of 100.93857595387503
finished 6 epochs...
Completing Train Step...
At time: 260.91049790382385 and batch: 50, loss is 4.175548005104065 and perplexity is 65.07549159294688
At time: 261.98058104515076 and batch: 100, loss is 4.140805554389954 and perplexity is 62.85343292013096
At time: 263.02558851242065 and batch: 150, loss is 4.1000717782974245 and perplexity is 60.344618875915856
At time: 264.0689091682434 and batch: 200, loss is 4.102250165939331 and perplexity is 60.47621613080778
At time: 265.1128933429718 and batch: 250, loss is 4.08732385635376 and perplexity is 59.58023290276382
At time: 266.1571066379547 and batch: 300, loss is 4.118828821182251 and perplexity is 61.48718758654416
At time: 267.20291352272034 and batch: 350, loss is 4.1219893741607665 and perplexity is 61.6818285248862
At time: 268.24834299087524 and batch: 400, loss is 4.081820287704468 and perplexity is 59.2532296686068
At time: 269.29392313957214 and batch: 450, loss is 4.11665036201477 and perplexity is 61.353386052567785
At time: 270.33818912506104 and batch: 500, loss is 4.142738537788391 and perplexity is 62.975045061759566
At time: 271.38462018966675 and batch: 550, loss is 4.111184186935425 and perplexity is 61.0189326259494
At time: 272.4294650554657 and batch: 600, loss is 4.1037566232681275 and perplexity is 60.56738962706418
At time: 273.4737515449524 and batch: 650, loss is 4.146347918510437 and perplexity is 63.202756677120966
At time: 274.5191807746887 and batch: 700, loss is 4.164359431266785 and perplexity is 64.35144771269088
At time: 275.56418347358704 and batch: 750, loss is 4.139110794067383 and perplexity is 62.747001629119545
At time: 276.60756063461304 and batch: 800, loss is 4.107327198982238 and perplexity is 60.78403662461814
At time: 277.6517231464386 and batch: 850, loss is 4.114341473579406 and perplexity is 61.21189133965238
At time: 278.69562673568726 and batch: 900, loss is 4.116759262084961 and perplexity is 61.36006780443038
At time: 279.74398398399353 and batch: 950, loss is 4.195023822784424 and perplexity is 66.35531232676678
At time: 280.79456758499146 and batch: 1000, loss is 4.160658226013184 and perplexity is 64.11371002572356
At time: 281.8453209400177 and batch: 1050, loss is 4.107670454978943 and perplexity is 60.80490469103302
At time: 282.93817257881165 and batch: 1100, loss is 4.163496060371399 and perplexity is 64.29591252284278
At time: 283.98748540878296 and batch: 1150, loss is 4.106622424125671 and perplexity is 60.74121265632509
At time: 285.0393178462982 and batch: 1200, loss is 4.175731039047241 and perplexity is 65.0874037069046
At time: 286.08950638771057 and batch: 1250, loss is 4.1738884115219115 and perplexity is 64.9675822923026
At time: 287.14039373397827 and batch: 1300, loss is 4.170301856994629 and perplexity is 64.73498986793875
At time: 288.19126868247986 and batch: 1350, loss is 4.065103087425232 and perplexity is 58.27091521155469
At time: 289.2426061630249 and batch: 1400, loss is 4.086139240264893 and perplexity is 59.50969498871158
At time: 290.2950177192688 and batch: 1450, loss is 4.01041886806488 and perplexity is 55.16997466486824
At time: 291.3474853038788 and batch: 1500, loss is 4.0174714469909665 and perplexity is 55.56044054281055
At time: 292.39961528778076 and batch: 1550, loss is 4.038712725639344 and perplexity is 56.753238773933305
At time: 293.4501187801361 and batch: 1600, loss is 4.129817471504212 and perplexity is 62.16657472773337
At time: 294.5021605491638 and batch: 1650, loss is 4.082425165176391 and perplexity is 59.28908145424768
At time: 295.55402755737305 and batch: 1700, loss is 4.11044150352478 and perplexity is 60.97363170115774
At time: 296.6061089038849 and batch: 1750, loss is 4.115819211006165 and perplexity is 61.30241330982649
At time: 297.65675163269043 and batch: 1800, loss is 4.06873589515686 and perplexity is 58.48298721804537
At time: 298.70820355415344 and batch: 1850, loss is 4.103024754524231 and perplexity is 60.523078464651995
At time: 299.7587170600891 and batch: 1900, loss is 4.186034588813782 and perplexity is 65.76150184836038
At time: 300.81056356430054 and batch: 1950, loss is 4.130668034553528 and perplexity is 62.21947381291375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614828988008721 and perplexity of 100.97055987944414
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 304.11286544799805 and batch: 50, loss is 4.105166158676147 and perplexity is 60.65282170293819
At time: 305.1911451816559 and batch: 100, loss is 4.097913331985474 and perplexity is 60.21450872425964
At time: 306.24294662475586 and batch: 150, loss is 4.061663975715637 and perplexity is 58.0708592293373
At time: 307.29416060447693 and batch: 200, loss is 4.059771809577942 and perplexity is 57.96108340571723
At time: 308.34563302993774 and batch: 250, loss is 4.046611447334289 and perplexity is 57.20329189457794
At time: 309.4236590862274 and batch: 300, loss is 4.067378454208374 and perplexity is 58.4036538737528
At time: 310.47428727149963 and batch: 350, loss is 4.068689060211182 and perplexity is 58.48024823465649
At time: 311.5257177352905 and batch: 400, loss is 4.020198941230774 and perplexity is 55.71218817567578
At time: 312.57949924468994 and batch: 450, loss is 4.046397733688354 and perplexity is 57.191068076752536
At time: 313.6316306591034 and batch: 500, loss is 4.065065898895264 and perplexity is 58.26874824217151
At time: 314.6841721534729 and batch: 550, loss is 4.031680164337158 and perplexity is 56.35551827920601
At time: 315.7352876663208 and batch: 600, loss is 4.0147583246231076 and perplexity is 55.40990257511233
At time: 316.7884900569916 and batch: 650, loss is 4.049560704231262 and perplexity is 57.372248122921725
At time: 317.84121966362 and batch: 700, loss is 4.056530475616455 and perplexity is 57.77351632562188
At time: 318.89312648773193 and batch: 750, loss is 4.023185596466065 and perplexity is 55.87883000112845
At time: 319.94471406936646 and batch: 800, loss is 3.9896751403808595 and perplexity is 54.03733196455468
At time: 320.99700260162354 and batch: 850, loss is 3.992688708305359 and perplexity is 54.20042275404762
At time: 322.04829239845276 and batch: 900, loss is 3.973175039291382 and perplexity is 53.15302615500254
At time: 323.1003601551056 and batch: 950, loss is 4.056930842399598 and perplexity is 57.79665155348334
At time: 324.15176153182983 and batch: 1000, loss is 4.014204587936401 and perplexity is 55.37922857269369
At time: 325.2037932872772 and batch: 1050, loss is 3.9602032041549684 and perplexity is 52.46798657879588
At time: 326.25608944892883 and batch: 1100, loss is 3.9939908027648925 and perplexity is 54.27104279122187
At time: 327.3089051246643 and batch: 1150, loss is 3.9442374753952025 and perplexity is 51.636948652435365
At time: 328.3610715866089 and batch: 1200, loss is 3.9931406784057617 and perplexity is 54.224925261344865
At time: 329.41359186172485 and batch: 1250, loss is 3.9866458654403685 and perplexity is 53.873885715785
At time: 330.4744927883148 and batch: 1300, loss is 3.975797815322876 and perplexity is 53.29261761655277
At time: 331.531103849411 and batch: 1350, loss is 3.8689732789993285 and perplexity is 47.89318788693908
At time: 332.58349680900574 and batch: 1400, loss is 3.8755328607559205 and perplexity is 48.20837980185945
At time: 333.6350657939911 and batch: 1450, loss is 3.797495403289795 and perplexity is 44.589366142067036
At time: 334.6860041618347 and batch: 1500, loss is 3.8002112817764284 and perplexity is 44.71063003676949
At time: 335.73797631263733 and batch: 1550, loss is 3.8081626796722414 and perplexity is 45.06755920873728
At time: 336.79062843322754 and batch: 1600, loss is 3.8923628997802733 and perplexity is 49.02659469632351
At time: 337.84307837486267 and batch: 1650, loss is 3.8391157484054563 and perplexity is 46.48435239862361
At time: 338.8974435329437 and batch: 1700, loss is 3.8625513315200806 and perplexity is 47.58660583030392
At time: 339.9506661891937 and batch: 1750, loss is 3.8460233306884763 and perplexity is 46.806558438895124
At time: 341.0033268928528 and batch: 1800, loss is 3.7914397048950197 and perplexity is 44.32016232034678
At time: 342.0557038784027 and batch: 1850, loss is 3.8164531135559083 and perplexity is 45.4427418933794
At time: 343.1092667579651 and batch: 1900, loss is 3.8931040954589844 and perplexity is 49.06294646667768
At time: 344.16258335113525 and batch: 1950, loss is 3.835439190864563 and perplexity is 46.31376378386278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.529946402616279 and perplexity of 92.75358959915043
finished 8 epochs...
Completing Train Step...
At time: 347.4927906990051 and batch: 50, loss is 4.002840480804443 and perplexity is 54.75345549694456
At time: 348.5387513637543 and batch: 100, loss is 3.9818580389022826 and perplexity is 53.616563394919346
At time: 349.5857048034668 and batch: 150, loss is 3.9453538465499878 and perplexity is 51.694626841575094
At time: 350.6318402290344 and batch: 200, loss is 3.941970553398132 and perplexity is 51.52002429694252
At time: 351.6771149635315 and batch: 250, loss is 3.9318761920928953 and perplexity is 51.002578592982516
At time: 352.7225730419159 and batch: 300, loss is 3.9543481159210203 and perplexity is 52.16167949050303
At time: 353.7677779197693 and batch: 350, loss is 3.958598880767822 and perplexity is 52.38387844721248
At time: 354.81302762031555 and batch: 400, loss is 3.9123414850234983 and perplexity is 50.01592651576814
At time: 355.85843110084534 and batch: 450, loss is 3.9446074676513674 and perplexity is 51.656057458405876
At time: 356.90381693840027 and batch: 500, loss is 3.966348557472229 and perplexity is 52.7914136631595
At time: 357.94939827919006 and batch: 550, loss is 3.935037546157837 and perplexity is 51.16407093487737
At time: 358.99374175071716 and batch: 600, loss is 3.9200661611557006 and perplexity is 50.40377944005116
At time: 360.0388596057892 and batch: 650, loss is 3.9604273939132693 and perplexity is 52.47975068267204
At time: 361.0851571559906 and batch: 700, loss is 3.970450587272644 and perplexity is 53.00841037442272
At time: 362.15826177597046 and batch: 750, loss is 3.9398326444625855 and perplexity is 51.4099968328959
At time: 363.20479226112366 and batch: 800, loss is 3.9067401361465453 and perplexity is 49.73655302658665
At time: 364.2499408721924 and batch: 850, loss is 3.9127444362640382 and perplexity is 50.03608455648543
At time: 365.29485058784485 and batch: 900, loss is 3.8951754426956176 and perplexity is 49.16467818975109
At time: 366.34060502052307 and batch: 950, loss is 3.9819720220565795 and perplexity is 53.62267512824836
At time: 367.3866546154022 and batch: 1000, loss is 3.941407732963562 and perplexity is 51.49103593286571
At time: 368.43261337280273 and batch: 1050, loss is 3.892293190956116 and perplexity is 49.023177229169974
At time: 369.4796531200409 and batch: 1100, loss is 3.928332962989807 and perplexity is 50.82218454962085
At time: 370.52519130706787 and batch: 1150, loss is 3.884102325439453 and perplexity is 48.62327498582739
At time: 371.57139587402344 and batch: 1200, loss is 3.934433169364929 and perplexity is 51.13315790027496
At time: 372.6164581775665 and batch: 1250, loss is 3.9328244352340698 and perplexity is 51.050964375433125
At time: 373.66143918037415 and batch: 1300, loss is 3.924882788658142 and perplexity is 50.64714129152515
At time: 374.7059829235077 and batch: 1350, loss is 3.819467124938965 and perplexity is 45.5799134491968
At time: 375.7515821456909 and batch: 1400, loss is 3.8325769233703615 and perplexity is 46.1813909368715
At time: 376.7975113391876 and batch: 1450, loss is 3.757038016319275 and perplexity is 42.82140165675455
At time: 377.84245467185974 and batch: 1500, loss is 3.7644247961044313 and perplexity is 43.13888506729488
At time: 378.8875069618225 and batch: 1550, loss is 3.7762792921066284 and perplexity is 43.65331795478438
At time: 379.9361779689789 and batch: 1600, loss is 3.862653651237488 and perplexity is 47.59147512747315
At time: 380.98841619491577 and batch: 1650, loss is 3.8117933559417723 and perplexity is 45.23148232229442
At time: 382.0363049507141 and batch: 1700, loss is 3.839863896369934 and perplexity is 46.51914258473142
At time: 383.0825684070587 and batch: 1750, loss is 3.8290873193740844 and perplexity is 46.02051702687544
At time: 384.12792015075684 and batch: 1800, loss is 3.777139410972595 and perplexity is 43.69088114920964
At time: 385.17286825180054 and batch: 1850, loss is 3.806476058959961 and perplexity is 44.991611395505316
At time: 386.21809458732605 and batch: 1900, loss is 3.8853443574905397 and perplexity is 48.683704171512915
At time: 387.2639231681824 and batch: 1950, loss is 3.832267174720764 and perplexity is 46.16708852858245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.529650595021803 and perplexity of 92.72615644060043
finished 9 epochs...
Completing Train Step...
At time: 390.5834000110626 and batch: 50, loss is 3.951392126083374 and perplexity is 52.00771776277402
At time: 391.65502190589905 and batch: 100, loss is 3.9285336208343504 and perplexity is 50.8323834428373
At time: 392.70095014572144 and batch: 150, loss is 3.892436189651489 and perplexity is 49.030187980809025
At time: 393.7458300590515 and batch: 200, loss is 3.8891698837280275 and perplexity is 48.87030164836522
At time: 394.7910621166229 and batch: 250, loss is 3.87830020904541 and perplexity is 48.34197394474687
At time: 395.837464094162 and batch: 300, loss is 3.900986795425415 and perplexity is 49.45122327741877
At time: 396.88344264030457 and batch: 350, loss is 3.906941838264465 and perplexity is 49.746586006472775
At time: 397.9275391101837 and batch: 400, loss is 3.8609896802902224 and perplexity is 47.51235014461663
At time: 398.9739718437195 and batch: 450, loss is 3.8950819540023804 and perplexity is 49.16008206307999
At time: 400.01865696907043 and batch: 500, loss is 3.9171910572052 and perplexity is 50.259071459588405
At time: 401.06285285949707 and batch: 550, loss is 3.8869307231903076 and perplexity is 48.76099561999061
At time: 402.10656929016113 and batch: 600, loss is 3.8728289270401 and perplexity is 48.078203611535756
At time: 403.1502182483673 and batch: 650, loss is 3.914318895339966 and perplexity is 50.114926374260165
At time: 404.1963241100311 and batch: 700, loss is 3.926374440193176 and perplexity is 50.72274555116427
At time: 405.24147939682007 and batch: 750, loss is 3.8952871322631837 and perplexity is 49.1701696780629
At time: 406.2855579853058 and batch: 800, loss is 3.8622742795944216 and perplexity is 47.57342369567527
At time: 407.3315632343292 and batch: 850, loss is 3.869045767784119 and perplexity is 47.89665973176212
At time: 408.37713170051575 and batch: 900, loss is 3.8521166467666625 and perplexity is 47.09263629024476
At time: 409.4231581687927 and batch: 950, loss is 3.940867500305176 and perplexity is 51.46322630615127
At time: 410.469521522522 and batch: 1000, loss is 3.900912809371948 and perplexity is 49.44756471191245
At time: 411.5152995586395 and batch: 1050, loss is 3.854347491264343 and perplexity is 47.19780990816972
At time: 412.5614116191864 and batch: 1100, loss is 3.8904339504241943 and perplexity is 48.932116029629974
At time: 413.6078405380249 and batch: 1150, loss is 3.84820463180542 and perplexity is 46.908769072655815
At time: 414.6532847881317 and batch: 1200, loss is 3.8986919689178468 and perplexity is 49.33787141058915
At time: 415.7435064315796 and batch: 1250, loss is 3.8994952487945556 and perplexity is 49.37751945195788
At time: 416.7888102531433 and batch: 1300, loss is 3.892000427246094 and perplexity is 49.008827122625014
At time: 417.8344521522522 and batch: 1350, loss is 3.7875043630599974 and perplexity is 44.14609007298468
At time: 418.8793320655823 and batch: 1400, loss is 3.8033471488952637 and perplexity is 44.851056695960104
At time: 419.92459058761597 and batch: 1450, loss is 3.7282056283950804 and perplexity is 41.60438741426586
At time: 420.96996998786926 and batch: 1500, loss is 3.7371337842941283 and perplexity is 41.977501000854474
At time: 422.02261185646057 and batch: 1550, loss is 3.7510506296157837 and perplexity is 42.565779384193476
At time: 423.067316532135 and batch: 1600, loss is 3.8385283374786376 and perplexity is 46.457055000278515
At time: 424.1116843223572 and batch: 1650, loss is 3.7881278228759765 and perplexity is 44.173621967801004
At time: 425.15770149230957 and batch: 1700, loss is 3.8174160814285276 and perplexity is 45.48652287032037
At time: 426.20360684394836 and batch: 1750, loss is 3.809040002822876 and perplexity is 45.10711537100497
At time: 427.2514498233795 and batch: 1800, loss is 3.757519416809082 and perplexity is 42.84202086313617
At time: 428.29720664024353 and batch: 1850, loss is 3.7884512090682985 and perplexity is 44.18790941726767
At time: 429.3430268764496 and batch: 1900, loss is 3.867763013839722 and perplexity is 47.83525949168713
At time: 430.3879222869873 and batch: 1950, loss is 3.8160892295837403 and perplexity is 45.42620901615998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.532776446675145 and perplexity of 93.01645813365509
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 433.69534063339233 and batch: 50, loss is 3.9292849826812746 and perplexity is 50.87059130851322
At time: 434.7651264667511 and batch: 100, loss is 3.9292288875579833 and perplexity is 50.86773779645667
At time: 435.8111982345581 and batch: 150, loss is 3.905715742111206 and perplexity is 49.68562928576927
At time: 436.85572600364685 and batch: 200, loss is 3.903006091117859 and perplexity is 49.55118080750873
At time: 437.8998074531555 and batch: 250, loss is 3.8954447507858276 and perplexity is 49.177920418379784
At time: 438.95162057876587 and batch: 300, loss is 3.914864525794983 and perplexity is 50.14227806562021
At time: 439.9990396499634 and batch: 350, loss is 3.916673974990845 and perplexity is 50.233090105453606
At time: 441.0440239906311 and batch: 400, loss is 3.8766824913024904 and perplexity is 48.26383349740394
At time: 442.11480164527893 and batch: 450, loss is 3.9095476198196413 and perplexity is 49.87638378160064
At time: 443.1594891548157 and batch: 500, loss is 3.9310174036026 and perplexity is 50.958796967780195
At time: 444.20457434654236 and batch: 550, loss is 3.8984589433670043 and perplexity is 49.32637576536786
At time: 445.24989199638367 and batch: 600, loss is 3.87799943447113 and perplexity is 48.32743609453124
At time: 446.2940933704376 and batch: 650, loss is 3.9108427429199217 and perplexity is 49.94102168638146
At time: 447.3384253978729 and batch: 700, loss is 3.920830430984497 and perplexity is 50.44231625232015
At time: 448.3837170600891 and batch: 750, loss is 3.8867403173446657 and perplexity is 48.751712125229126
At time: 449.42685198783875 and batch: 800, loss is 3.8538584756851195 and perplexity is 47.17473508625292
At time: 450.4718382358551 and batch: 850, loss is 3.8567325830459596 and perplexity is 47.31051536969839
At time: 451.51731634140015 and batch: 900, loss is 3.8283340167999267 and perplexity is 45.985862707167904
At time: 452.5639579296112 and batch: 950, loss is 3.9196464014053345 and perplexity is 50.38262640208345
At time: 453.60949420928955 and batch: 1000, loss is 3.875133767127991 and perplexity is 48.18914398336933
At time: 454.6558310985565 and batch: 1050, loss is 3.8317527103424074 and perplexity is 46.143343314639154
At time: 455.7009494304657 and batch: 1100, loss is 3.8601350498199465 and perplexity is 47.47176198887638
At time: 456.75998973846436 and batch: 1150, loss is 3.8197498989105223 and perplexity is 45.592804084828295
At time: 457.810364484787 and batch: 1200, loss is 3.863970928192139 and perplexity is 47.6542075898387
At time: 458.87335753440857 and batch: 1250, loss is 3.8601728820800782 and perplexity is 47.47355798689798
At time: 459.929172039032 and batch: 1300, loss is 3.8481857633590697 and perplexity is 46.90788398541335
At time: 460.9759991168976 and batch: 1350, loss is 3.7350771903991697 and perplexity is 41.8912590413115
At time: 462.02401304244995 and batch: 1400, loss is 3.750538930892944 and perplexity is 42.54400410091337
At time: 463.0709419250488 and batch: 1450, loss is 3.6668788385391236 and perplexity is 39.129585314853834
At time: 464.11590003967285 and batch: 1500, loss is 3.6742122030258177 and perplexity is 39.41759156287196
At time: 465.16102051734924 and batch: 1550, loss is 3.6890766525268557 and perplexity is 40.00788871431218
At time: 466.20483660697937 and batch: 1600, loss is 3.773117337226868 and perplexity is 43.515506125272644
At time: 467.2494947910309 and batch: 1650, loss is 3.720077142715454 and perplexity is 41.26757747880923
At time: 468.2931685447693 and batch: 1700, loss is 3.7443211460113526 and perplexity is 42.280295327225296
At time: 469.33810472488403 and batch: 1750, loss is 3.733637137413025 and perplexity is 41.83097682384686
At time: 470.3840138912201 and batch: 1800, loss is 3.6810823345184325 and perplexity is 39.68932796363364
At time: 471.4284996986389 and batch: 1850, loss is 3.7052822303771973 and perplexity is 40.66152161418756
At time: 472.4732177257538 and batch: 1900, loss is 3.784945750236511 and perplexity is 44.03328169883517
At time: 473.51670122146606 and batch: 1950, loss is 3.7345677995681763 and perplexity is 41.86992545208576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503211868640989 and perplexity of 90.30671931207274
finished 11 epochs...
Completing Train Step...
At time: 476.84646582603455 and batch: 50, loss is 3.913056607246399 and perplexity is 50.051706808434915
At time: 477.89750361442566 and batch: 100, loss is 3.899867506027222 and perplexity is 49.395904012385486
At time: 478.94864320755005 and batch: 150, loss is 3.8708302927017213 and perplexity is 47.98220882406403
At time: 480.0008306503296 and batch: 200, loss is 3.8636269903182985 and perplexity is 47.6378203212634
At time: 481.0507187843323 and batch: 250, loss is 3.8536414957046508 and perplexity is 47.164500223575594
At time: 482.10116505622864 and batch: 300, loss is 3.8709103870391846 and perplexity is 47.986052081199325
At time: 483.1517059803009 and batch: 350, loss is 3.8751855373382567 and perplexity is 48.19163881006417
At time: 484.20301032066345 and batch: 400, loss is 3.834766345024109 and perplexity is 46.282612241813034
At time: 485.2557919025421 and batch: 450, loss is 3.8699794244766235 and perplexity is 47.941399651281905
At time: 486.307669878006 and batch: 500, loss is 3.891788239479065 and perplexity is 48.998429152233236
At time: 487.3579742908478 and batch: 550, loss is 3.8603045034408567 and perplexity is 47.479806932439544
At time: 488.40820956230164 and batch: 600, loss is 3.8421488618850708 and perplexity is 46.6255587536689
At time: 489.4587574005127 and batch: 650, loss is 3.876315417289734 and perplexity is 48.24612034958805
At time: 490.51011300086975 and batch: 700, loss is 3.88819890499115 and perplexity is 48.822872654598434
At time: 491.5629303455353 and batch: 750, loss is 3.855143275260925 and perplexity is 47.23538411846308
At time: 492.61374616622925 and batch: 800, loss is 3.8232774114608765 and perplexity is 45.75391727077054
At time: 493.6913299560547 and batch: 850, loss is 3.8272896671295165 and perplexity is 45.93786245549234
At time: 494.741578578949 and batch: 900, loss is 3.800944976806641 and perplexity is 44.743446040822576
At time: 495.79160618782043 and batch: 950, loss is 3.894539265632629 and perplexity is 49.13341069606327
At time: 496.84272050857544 and batch: 1000, loss is 3.8509591102600096 and perplexity is 47.03815638186878
At time: 497.89882493019104 and batch: 1050, loss is 3.8093458557128907 and perplexity is 45.12091362261142
At time: 498.9506721496582 and batch: 1100, loss is 3.839473857879639 and perplexity is 46.50100186660697
At time: 500.0021846294403 and batch: 1150, loss is 3.8015165662765504 and perplexity is 44.76902823398659
At time: 501.05302834510803 and batch: 1200, loss is 3.8462005043029786 and perplexity is 46.814852060719936
At time: 502.1037609577179 and batch: 1250, loss is 3.844647002220154 and perplexity is 46.74218155204483
At time: 503.154580116272 and batch: 1300, loss is 3.8347723579406736 and perplexity is 46.28289053613552
At time: 504.2054262161255 and batch: 1350, loss is 3.723272967338562 and perplexity is 41.399672382698235
At time: 505.25722193717957 and batch: 1400, loss is 3.7411821031570436 and perplexity is 42.14778375685887
At time: 506.3086452484131 and batch: 1450, loss is 3.659957323074341 and perplexity is 38.859684424080704
At time: 507.3591613769531 and batch: 1500, loss is 3.669183225631714 and perplexity is 39.21985899900047
At time: 508.4099667072296 and batch: 1550, loss is 3.6853507947921753 and perplexity is 39.859102363207434
At time: 509.46114563941956 and batch: 1600, loss is 3.77095196723938 and perplexity is 43.42138089906665
At time: 510.51233434677124 and batch: 1650, loss is 3.719772610664368 and perplexity is 41.25501209217484
At time: 511.5652883052826 and batch: 1700, loss is 3.7459365129470825 and perplexity is 42.34864871136463
At time: 512.6216239929199 and batch: 1750, loss is 3.736854004859924 and perplexity is 41.96575820214854
At time: 513.6737892627716 and batch: 1800, loss is 3.6856316041946413 and perplexity is 39.87029674559523
At time: 514.7257082462311 and batch: 1850, loss is 3.7115237522125244 and perplexity is 40.91610505678328
At time: 515.7857410907745 and batch: 1900, loss is 3.791702733039856 and perplexity is 44.3318213036739
At time: 516.8355302810669 and batch: 1950, loss is 3.7416266012191772 and perplexity is 42.16652252942754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503186319040697 and perplexity of 90.30441204096574
finished 12 epochs...
Completing Train Step...
At time: 520.137866973877 and batch: 50, loss is 3.8987553310394287 and perplexity is 49.340997661837974
At time: 521.2078137397766 and batch: 100, loss is 3.8834950494766236 and perplexity is 48.59375620362506
At time: 522.2514219284058 and batch: 150, loss is 3.853339557647705 and perplexity is 47.15026161571824
At time: 523.2964451313019 and batch: 200, loss is 3.845161237716675 and perplexity is 46.766224222251125
At time: 524.3407385349274 and batch: 250, loss is 3.834348244667053 and perplexity is 46.26326550982886
At time: 525.3850026130676 and batch: 300, loss is 3.85193724155426 and perplexity is 47.084188383650414
At time: 526.4291844367981 and batch: 350, loss is 3.8563877868652345 and perplexity is 47.29420569660886
At time: 527.4736242294312 and batch: 400, loss is 3.8162506675720214 and perplexity is 45.43354312394465
At time: 528.5167262554169 and batch: 450, loss is 3.85190842628479 and perplexity is 47.08283165962164
At time: 529.5610766410828 and batch: 500, loss is 3.873773765563965 and perplexity is 48.12365121740959
At time: 530.6047489643097 and batch: 550, loss is 3.8427112913131714 and perplexity is 46.65178971585466
At time: 531.6488616466522 and batch: 600, loss is 3.825206756591797 and perplexity is 45.842277579634114
At time: 532.6939964294434 and batch: 650, loss is 3.8597499895095826 and perplexity is 47.45348601637306
At time: 533.737813949585 and batch: 700, loss is 3.8725263595581056 and perplexity is 48.06365891101787
At time: 534.7828588485718 and batch: 750, loss is 3.8396926355361938 and perplexity is 46.51117635975811
At time: 535.8280432224274 and batch: 800, loss is 3.8081108379364013 and perplexity is 45.065222888797784
At time: 536.8734111785889 and batch: 850, loss is 3.8127108812332153 and perplexity is 45.27300239624075
At time: 537.9184005260468 and batch: 900, loss is 3.7870771741867064 and perplexity is 44.12723538205002
At time: 538.9626755714417 and batch: 950, loss is 3.881485357284546 and perplexity is 48.49619577724858
At time: 540.0078287124634 and batch: 1000, loss is 3.838080840110779 and perplexity is 46.43627024135672
At time: 541.052125453949 and batch: 1050, loss is 3.797287220954895 and perplexity is 44.58008438989382
At time: 542.0979056358337 and batch: 1100, loss is 3.8278715419769287 and perplexity is 45.96460032049023
At time: 543.1416442394257 and batch: 1150, loss is 3.7911959981918333 and perplexity is 44.309362515748845
At time: 544.1868860721588 and batch: 1200, loss is 3.835820641517639 and perplexity is 46.33143356916587
At time: 545.2320675849915 and batch: 1250, loss is 3.8354541635513306 and perplexity is 46.31445723053232
At time: 546.2769389152527 and batch: 1300, loss is 3.8263343143463135 and perplexity is 45.89399654778597
At time: 547.3216059207916 and batch: 1350, loss is 3.7154439640045167 and perplexity is 41.076819666140054
At time: 548.3663318157196 and batch: 1400, loss is 3.734679880142212 and perplexity is 41.87461852036124
At time: 549.4111802577972 and batch: 1450, loss is 3.6542041969299315 and perplexity is 38.636761624018085
At time: 550.4560790061951 and batch: 1500, loss is 3.6642246437072754 and perplexity is 39.02586547895501
At time: 551.5013692378998 and batch: 1550, loss is 3.680923523902893 and perplexity is 39.68302537750142
At time: 552.554277420044 and batch: 1600, loss is 3.76723708152771 and perplexity is 43.26037467660355
At time: 553.6004657745361 and batch: 1650, loss is 3.7165460205078125 and perplexity is 41.1221135960386
At time: 554.6449649333954 and batch: 1700, loss is 3.7432700252532958 and perplexity is 42.23587697976326
At time: 555.6898558139801 and batch: 1750, loss is 3.735173473358154 and perplexity is 41.895292649868345
At time: 556.7346920967102 and batch: 1800, loss is 3.6843911170959474 and perplexity is 39.82086882055123
At time: 557.7785184383392 and batch: 1850, loss is 3.710956025123596 and perplexity is 40.89288246823915
At time: 558.822934627533 and batch: 1900, loss is 3.791449546813965 and perplexity is 44.32059851793848
At time: 559.8673450946808 and batch: 1950, loss is 3.7415293312072753 and perplexity is 42.162421190751104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5041413063226745 and perplexity of 90.39069279792675
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 563.1643028259277 and batch: 50, loss is 3.892750468254089 and perplexity is 49.04559954140787
At time: 564.2375137805939 and batch: 100, loss is 3.887018504142761 and perplexity is 48.76527609449803
At time: 565.2835638523102 and batch: 150, loss is 3.8634052371978758 and perplexity is 47.62725765715217
At time: 566.3297295570374 and batch: 200, loss is 3.8579535913467407 and perplexity is 47.36831718274458
At time: 567.3754503726959 and batch: 250, loss is 3.8508518028259275 and perplexity is 47.03310910881329
At time: 568.4208452701569 and batch: 300, loss is 3.8664189434051512 and perplexity is 47.77100872212677
At time: 569.4674599170685 and batch: 350, loss is 3.869838833808899 and perplexity is 47.9346600116696
At time: 570.5136139392853 and batch: 400, loss is 3.830531597137451 and perplexity is 46.08703145737037
At time: 571.5680818557739 and batch: 450, loss is 3.8666681671142578 and perplexity is 47.78291587381889
At time: 572.6143012046814 and batch: 500, loss is 3.88838014125824 and perplexity is 48.83172193166771
At time: 573.6849849224091 and batch: 550, loss is 3.8576591873168944 and perplexity is 47.354373811871945
At time: 574.7308239936829 and batch: 600, loss is 3.836503882408142 and perplexity is 46.363099915735496
At time: 575.7785060405731 and batch: 650, loss is 3.867861156463623 and perplexity is 47.83995439995017
At time: 576.8240852355957 and batch: 700, loss is 3.879083113670349 and perplexity is 48.37983591895032
At time: 577.8771154880524 and batch: 750, loss is 3.8442755222320555 and perplexity is 46.724820991748196
At time: 578.9206624031067 and batch: 800, loss is 3.8127382802963257 and perplexity is 45.27424285108417
At time: 579.9651033878326 and batch: 850, loss is 3.8190375328063966 and perplexity is 45.560336882246524
At time: 581.0112025737762 and batch: 900, loss is 3.7862607192993165 and perplexity is 44.09122218862976
At time: 582.0693018436432 and batch: 950, loss is 3.8829651069641113 and perplexity is 48.568011128677476
At time: 583.1231338977814 and batch: 1000, loss is 3.8368468618392946 and perplexity is 46.37900423264193
At time: 584.1742510795593 and batch: 1050, loss is 3.7966051149368285 and perplexity is 44.549686414545114
At time: 585.219598531723 and batch: 1100, loss is 3.8194107532501222 and perplexity is 45.57734410491819
At time: 586.2661015987396 and batch: 1150, loss is 3.7866052341461183 and perplexity is 44.10641488619204
At time: 587.3125712871552 and batch: 1200, loss is 3.830853514671326 and perplexity is 46.10187006915724
At time: 588.3593592643738 and batch: 1250, loss is 3.830348210334778 and perplexity is 46.07858047894934
At time: 589.4044978618622 and batch: 1300, loss is 3.818688278198242 and perplexity is 45.54442750301505
At time: 590.449958562851 and batch: 1350, loss is 3.7020655822753907 and perplexity is 40.53093794132629
At time: 591.4954245090485 and batch: 1400, loss is 3.721010284423828 and perplexity is 41.30610394909083
At time: 592.5407912731171 and batch: 1450, loss is 3.6350474739074707 and perplexity is 37.90365228891129
At time: 593.5865819454193 and batch: 1500, loss is 3.641490797996521 and perplexity is 38.14866630946287
At time: 594.6326942443848 and batch: 1550, loss is 3.6606760835647583 and perplexity is 38.88762527010002
At time: 595.6789171695709 and batch: 1600, loss is 3.744886989593506 and perplexity is 42.30422613089508
At time: 596.7259850502014 and batch: 1650, loss is 3.690614604949951 and perplexity is 40.06946628325153
At time: 597.7710816860199 and batch: 1700, loss is 3.71462103843689 and perplexity is 41.04303040592992
At time: 598.8162877559662 and batch: 1750, loss is 3.7064580965042113 and perplexity is 40.70936224170095
At time: 599.861608505249 and batch: 1800, loss is 3.656185884475708 and perplexity is 38.713403528409636
At time: 600.908730506897 and batch: 1850, loss is 3.6810139656066894 and perplexity is 39.686614540230906
At time: 601.9551167488098 and batch: 1900, loss is 3.762337589263916 and perplexity is 43.04893919176715
At time: 603.0010232925415 and batch: 1950, loss is 3.7180663537979126 and perplexity is 41.18468046349217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4943844817405525 and perplexity of 89.51305510520955
finished 14 epochs...
Completing Train Step...
At time: 606.3043518066406 and batch: 50, loss is 3.891149153709412 and perplexity is 48.96712495752483
At time: 607.3546421527863 and batch: 100, loss is 3.8762492513656617 and perplexity is 48.24292820605895
At time: 608.4064831733704 and batch: 150, loss is 3.8481609201431275 and perplexity is 46.906718657197416
At time: 609.4574563503265 and batch: 200, loss is 3.8410588693618775 and perplexity is 46.57476493071026
At time: 610.5088458061218 and batch: 250, loss is 3.833125853538513 and perplexity is 46.20674825462557
At time: 611.561719417572 and batch: 300, loss is 3.84936408996582 and perplexity is 46.96318937068413
At time: 612.6205766201019 and batch: 350, loss is 3.8522645139694216 and perplexity is 47.09960026150234
At time: 613.6729073524475 and batch: 400, loss is 3.813494257926941 and perplexity is 45.30848210634752
At time: 614.7252566814423 and batch: 450, loss is 3.850105857849121 and perplexity is 46.9980380794853
At time: 615.7772536277771 and batch: 500, loss is 3.872265019416809 and perplexity is 48.05109958880584
At time: 616.8281352519989 and batch: 550, loss is 3.8421335506439207 and perplexity is 46.62484486396035
At time: 617.8786287307739 and batch: 600, loss is 3.822391610145569 and perplexity is 45.71340633564032
At time: 618.9356310367584 and batch: 650, loss is 3.8539872646331785 and perplexity is 47.18081106201051
At time: 619.9888534545898 and batch: 700, loss is 3.8661739683151244 and perplexity is 47.759307448283224
At time: 621.0412769317627 and batch: 750, loss is 3.8319834756851194 and perplexity is 46.15399282779505
At time: 622.0927131175995 and batch: 800, loss is 3.7998111200332643 and perplexity is 44.69274213238221
At time: 623.144161939621 and batch: 850, loss is 3.8060212993621825 and perplexity is 44.9711556799727
At time: 624.196291923523 and batch: 900, loss is 3.7755721616744995 and perplexity is 43.622460276682595
At time: 625.2489211559296 and batch: 950, loss is 3.872660531997681 and perplexity is 48.07010816203506
At time: 626.3451972007751 and batch: 1000, loss is 3.8272676420211793 and perplexity is 45.93685068023725
At time: 627.3965938091278 and batch: 1050, loss is 3.787814249992371 and perplexity is 44.15977248930519
At time: 628.4480683803558 and batch: 1100, loss is 3.812468867301941 and perplexity is 45.26204702467998
At time: 629.4996509552002 and batch: 1150, loss is 3.780050096511841 and perplexity is 43.81823682141021
At time: 630.5518107414246 and batch: 1200, loss is 3.8242933130264283 and perplexity is 45.80042236525554
At time: 631.6120848655701 and batch: 1250, loss is 3.8249075031280517 and perplexity is 45.82856117172609
At time: 632.6724359989166 and batch: 1300, loss is 3.814067997932434 and perplexity is 45.33448485381504
At time: 633.7337007522583 and batch: 1350, loss is 3.6989174842834474 and perplexity is 40.40354320774643
At time: 634.7857103347778 and batch: 1400, loss is 3.7191359996795654 and perplexity is 41.228757056307636
At time: 635.8378691673279 and batch: 1450, loss is 3.6350150299072266 and perplexity is 37.9024225627559
At time: 636.8887722492218 and batch: 1500, loss is 3.64254741191864 and perplexity is 38.18899602411259
At time: 637.9404411315918 and batch: 1550, loss is 3.662534122467041 and perplexity is 38.959947158303684
At time: 638.9918696880341 and batch: 1600, loss is 3.7478526973724366 and perplexity is 42.42987432923867
At time: 640.0436725616455 and batch: 1650, loss is 3.694617018699646 and perplexity is 40.23016223737482
At time: 641.0986700057983 and batch: 1700, loss is 3.71908682346344 and perplexity is 41.22672963189099
At time: 642.1551785469055 and batch: 1750, loss is 3.711890015602112 and perplexity is 40.93109387286983
At time: 643.2074224948883 and batch: 1800, loss is 3.6615714263916015 and perplexity is 38.92245861800568
At time: 644.2590296268463 and batch: 1850, loss is 3.686923704147339 and perplexity is 39.92184645064804
At time: 645.3201177120209 and batch: 1900, loss is 3.7680485582351686 and perplexity is 43.29549371022129
At time: 646.3727071285248 and batch: 1950, loss is 3.7234311580657957 and perplexity is 41.40622194500605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493860714934593 and perplexity of 89.46618341423489
finished 15 epochs...
Completing Train Step...
At time: 649.6573674678802 and batch: 50, loss is 3.8879870557785035 and perplexity is 48.81253066297748
At time: 650.7282552719116 and batch: 100, loss is 3.8713882780075073 and perplexity is 48.00898966248933
At time: 651.7743055820465 and batch: 150, loss is 3.842046689987183 and perplexity is 46.62079517519702
At time: 652.8469965457916 and batch: 200, loss is 3.8343394994735718 and perplexity is 46.26286093038997
At time: 653.8935587406158 and batch: 250, loss is 3.8256052923202515 and perplexity is 45.860551006188146
At time: 654.9391205310822 and batch: 300, loss is 3.8415541553497317 and perplexity is 46.59783847269738
At time: 655.9845128059387 and batch: 350, loss is 3.8445352506637573 and perplexity is 46.73695833236392
At time: 657.0294198989868 and batch: 400, loss is 3.805659589767456 and perplexity is 44.954892122996945
At time: 658.0741147994995 and batch: 450, loss is 3.8425237464904787 and perplexity is 46.64304123461593
At time: 659.1203052997589 and batch: 500, loss is 3.864681181907654 and perplexity is 47.68806619051441
At time: 660.1643607616425 and batch: 550, loss is 3.834787063598633 and perplexity is 46.283571161497626
At time: 661.2094237804413 and batch: 600, loss is 3.8156435108184814 and perplexity is 45.40596621400042
At time: 662.2552638053894 and batch: 650, loss is 3.8472752571105957 and perplexity is 46.865193501867225
At time: 663.3062059879303 and batch: 700, loss is 3.859883494377136 and perplexity is 47.459821710652236
At time: 664.3543801307678 and batch: 750, loss is 3.825965051651001 and perplexity is 45.87705273547349
At time: 665.399240732193 and batch: 800, loss is 3.7938317680358886 and perplexity is 44.42630584742753
At time: 666.4445703029633 and batch: 850, loss is 3.800083627700806 and perplexity is 44.70492290689859
At time: 667.4900670051575 and batch: 900, loss is 3.7703376483917235 and perplexity is 43.39471451805794
At time: 668.5341284275055 and batch: 950, loss is 3.867756099700928 and perplexity is 47.834928753207144
At time: 669.5796632766724 and batch: 1000, loss is 3.8227097177505494 and perplexity is 45.727950431016275
At time: 670.6245849132538 and batch: 1050, loss is 3.783643808364868 and perplexity is 43.975990228820116
At time: 671.6773526668549 and batch: 1100, loss is 3.8088479375839235 and perplexity is 45.09845269403897
At time: 672.7360098361969 and batch: 1150, loss is 3.7768013715744018 and perplexity is 43.67611440605053
At time: 673.7907140254974 and batch: 1200, loss is 3.821089906692505 and perplexity is 45.65393974908926
At time: 674.8363883495331 and batch: 1250, loss is 3.822192306518555 and perplexity is 45.70429639580664
At time: 675.8813462257385 and batch: 1300, loss is 3.8118323993682863 and perplexity is 45.23324834882624
At time: 676.925567150116 and batch: 1350, loss is 3.697299613952637 and perplexity is 40.338228363652036
At time: 677.9704489707947 and batch: 1400, loss is 3.718076705932617 and perplexity is 41.185106815058916
At time: 679.0157029628754 and batch: 1450, loss is 3.634690008163452 and perplexity is 37.89010545305394
At time: 680.0628204345703 and batch: 1500, loss is 3.642682590484619 and perplexity is 38.194158706765464
At time: 681.1095132827759 and batch: 1550, loss is 3.6629858875274657 and perplexity is 38.9775518774849
At time: 682.155296087265 and batch: 1600, loss is 3.748752975463867 and perplexity is 42.46809021540079
At time: 683.202686548233 and batch: 1650, loss is 3.695891466140747 and perplexity is 40.28146614981924
At time: 684.2484476566315 and batch: 1700, loss is 3.7205230474472044 and perplexity is 41.285982990122235
At time: 685.2940278053284 and batch: 1750, loss is 3.7137603044509886 and perplexity is 41.007718474045205
At time: 686.3381733894348 and batch: 1800, loss is 3.6633983707427977 and perplexity is 38.99363277973222
At time: 687.3830163478851 and batch: 1850, loss is 3.6890005826950074 and perplexity is 40.00484543669736
At time: 688.4287552833557 and batch: 1900, loss is 3.76995623588562 and perplexity is 43.3781663872746
At time: 689.4740929603577 and batch: 1950, loss is 3.725151357650757 and perplexity is 41.47751020825208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493956383993459 and perplexity of 89.47474296923822
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 692.7800335884094 and batch: 50, loss is 3.886499495506287 and perplexity is 48.73997306185915
At time: 693.8526248931885 and batch: 100, loss is 3.872103362083435 and perplexity is 48.043332404008716
At time: 694.8997669219971 and batch: 150, loss is 3.844378824234009 and perplexity is 46.729648008613516
At time: 695.9465880393982 and batch: 200, loss is 3.836970844268799 and perplexity is 46.38475477074016
At time: 696.9915878772736 and batch: 250, loss is 3.8292275285720825 and perplexity is 46.02696997903029
At time: 698.03875041008 and batch: 300, loss is 3.845195479393005 and perplexity is 46.767825603580974
At time: 699.0862166881561 and batch: 350, loss is 3.8480210638046266 and perplexity is 46.90015891399646
At time: 700.1331815719604 and batch: 400, loss is 3.809545373916626 and perplexity is 45.129916964383725
At time: 701.1792235374451 and batch: 450, loss is 3.8469275283813475 and perplexity is 46.84889996071521
At time: 702.223883152008 and batch: 500, loss is 3.867990083694458 and perplexity is 47.846122670414694
At time: 703.2695517539978 and batch: 550, loss is 3.8389908409118654 and perplexity is 46.47854651728089
At time: 704.3130834102631 and batch: 600, loss is 3.818161382675171 and perplexity is 45.520436668949436
At time: 705.3853938579559 and batch: 650, loss is 3.8491554498672484 and perplexity is 46.95339198832354
At time: 706.4290680885315 and batch: 700, loss is 3.8609022998809817 and perplexity is 47.508198677398106
At time: 707.474761724472 and batch: 750, loss is 3.82633828163147 and perplexity is 45.89417862271841
At time: 708.5199799537659 and batch: 800, loss is 3.7943283843994142 and perplexity is 44.44837415717067
At time: 709.5674686431885 and batch: 850, loss is 3.8011031675338747 and perplexity is 44.75052459895709
At time: 710.6123411655426 and batch: 900, loss is 3.7684800386428834 and perplexity is 43.31417889835599
At time: 711.6578688621521 and batch: 950, loss is 3.865937271118164 and perplexity is 47.74800429184695
At time: 712.7039451599121 and batch: 1000, loss is 3.820439348220825 and perplexity is 45.624248850699836
At time: 713.7508199214935 and batch: 1050, loss is 3.781390972137451 and perplexity is 43.87703103617693
At time: 714.7960247993469 and batch: 1100, loss is 3.802761821746826 and perplexity is 44.82481183650352
At time: 715.8420174121857 and batch: 1150, loss is 3.7723864459991456 and perplexity is 43.4837126437795
At time: 716.8886647224426 and batch: 1200, loss is 3.8176418256759646 and perplexity is 45.49679235028865
At time: 717.9341168403625 and batch: 1250, loss is 3.8188674783706666 and perplexity is 45.55258980359756
At time: 718.980144739151 and batch: 1300, loss is 3.807846398353577 and perplexity is 45.05330743558535
At time: 720.025475025177 and batch: 1350, loss is 3.6918847608566283 and perplexity is 40.120393088172975
At time: 721.0702528953552 and batch: 1400, loss is 3.7123285961151122 and perplexity is 40.94904939020044
At time: 722.115462064743 and batch: 1450, loss is 3.6275778245925903 and perplexity is 37.62158010025778
At time: 723.1609981060028 and batch: 1500, loss is 3.6341587829589845 and perplexity is 37.869982619388786
At time: 724.2075119018555 and batch: 1550, loss is 3.6548173379898072 and perplexity is 38.660458673064895
At time: 725.2531616687775 and batch: 1600, loss is 3.7390793895721437 and perplexity is 42.0592521503053
At time: 726.299103975296 and batch: 1650, loss is 3.6849687767028807 and perplexity is 39.843878373186584
At time: 727.3437781333923 and batch: 1700, loss is 3.708329691886902 and perplexity is 40.7856250403942
At time: 728.3896880149841 and batch: 1750, loss is 3.701370906829834 and perplexity is 40.50279187127683
At time: 729.4361279010773 and batch: 1800, loss is 3.6517044353485106 and perplexity is 38.540299548006764
At time: 730.4822494983673 and batch: 1850, loss is 3.677675371170044 and perplexity is 39.55433796150773
At time: 731.529205083847 and batch: 1900, loss is 3.7582360315322876 and perplexity is 42.87273308916092
At time: 732.5750365257263 and batch: 1950, loss is 3.7158213520050047 and perplexity is 41.09232449046357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493685558230378 and perplexity of 89.45051418473469
finished 17 epochs...
Completing Train Step...
At time: 735.8902101516724 and batch: 50, loss is 3.8857778120040893 and perplexity is 48.704810916898936
At time: 736.9347620010376 and batch: 100, loss is 3.8693517589569093 and perplexity is 47.91131792937136
At time: 737.9808542728424 and batch: 150, loss is 3.8401681089401247 and perplexity is 46.533296445442204
At time: 739.0243611335754 and batch: 200, loss is 3.8331158447265623 and perplexity is 46.20628578228583
At time: 740.06986784935 and batch: 250, loss is 3.825145001411438 and perplexity is 45.839446668926726
At time: 741.1140458583832 and batch: 300, loss is 3.8413024806976317 and perplexity is 46.58611245354395
At time: 742.1593992710114 and batch: 350, loss is 3.8437100982666017 and perplexity is 46.69840912583257
At time: 743.2048065662384 and batch: 400, loss is 3.8051698303222654 and perplexity is 44.93288043062929
At time: 744.2498650550842 and batch: 450, loss is 3.8426322460174562 and perplexity is 46.648102257080986
At time: 745.29474401474 and batch: 500, loss is 3.86435733795166 and perplexity is 47.67262519887644
At time: 746.337229013443 and batch: 550, loss is 3.835134172439575 and perplexity is 46.29963938678835
At time: 747.3800053596497 and batch: 600, loss is 3.8145514917373657 and perplexity is 45.35640909608219
At time: 748.4254896640778 and batch: 650, loss is 3.8458184576034546 and perplexity is 46.796970017106815
At time: 749.4687271118164 and batch: 700, loss is 3.857963786125183 and perplexity is 47.36880009470504
At time: 750.5119950771332 and batch: 750, loss is 3.823609528541565 and perplexity is 45.76911545185264
At time: 751.5573778152466 and batch: 800, loss is 3.7913573741912843 and perplexity is 44.31651356039783
At time: 752.601156949997 and batch: 850, loss is 3.798029146194458 and perplexity is 44.61317175234142
At time: 753.6454062461853 and batch: 900, loss is 3.7660217905044555 and perplexity is 43.20783266498073
At time: 754.6894361972809 and batch: 950, loss is 3.863792119026184 and perplexity is 47.64568734249719
At time: 755.735410451889 and batch: 1000, loss is 3.818354926109314 and perplexity is 45.52924770321744
At time: 756.780487537384 and batch: 1050, loss is 3.7794707202911377 and perplexity is 43.792856929925506
At time: 757.8504474163055 and batch: 1100, loss is 3.80164945602417 and perplexity is 44.774977974170746
At time: 758.8940198421478 and batch: 1150, loss is 3.771226305961609 and perplexity is 43.433294699353574
At time: 759.9388399124146 and batch: 1200, loss is 3.816547164916992 and perplexity is 45.44701604609764
At time: 760.9836053848267 and batch: 1250, loss is 3.817914352416992 and perplexity is 45.50919313253072
At time: 762.0285911560059 and batch: 1300, loss is 3.8070055484771728 and perplexity is 45.01544029011993
At time: 763.0712292194366 and batch: 1350, loss is 3.691360898017883 and perplexity is 40.099381009362396
At time: 764.1164193153381 and batch: 1400, loss is 3.712176742553711 and perplexity is 40.94283160332303
At time: 765.159702539444 and batch: 1450, loss is 3.6278567123413086 and perplexity is 37.632073761243895
At time: 766.2049272060394 and batch: 1500, loss is 3.6348637533187866 and perplexity is 37.89668924724614
At time: 767.2514371871948 and batch: 1550, loss is 3.6558436012268065 and perplexity is 38.70015484640421
At time: 768.2967345714569 and batch: 1600, loss is 3.74057119846344 and perplexity is 42.12204334120772
At time: 769.3419058322906 and batch: 1650, loss is 3.6867003059387207 and perplexity is 39.91292897777705
At time: 770.3954875469208 and batch: 1700, loss is 3.710148687362671 and perplexity is 40.8598814233568
At time: 771.4427585601807 and batch: 1750, loss is 3.7034634447097776 and perplexity is 40.58763423448198
At time: 772.4890942573547 and batch: 1800, loss is 3.653738508224487 and perplexity is 38.61877310936397
At time: 773.5342135429382 and batch: 1850, loss is 3.6797976112365722 and perplexity is 39.63837089982927
At time: 774.5800974369049 and batch: 1900, loss is 3.760236520767212 and perplexity is 42.95858537483278
At time: 775.6255400180817 and batch: 1950, loss is 3.717640175819397 and perplexity is 41.16713219923393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49346185728561 and perplexity of 89.43050625818111
finished 18 epochs...
Completing Train Step...
At time: 778.9211721420288 and batch: 50, loss is 3.8848912143707275 and perplexity is 48.66164848348967
At time: 779.9976358413696 and batch: 100, loss is 3.8675955009460448 and perplexity is 47.82724714005472
At time: 781.0483424663544 and batch: 150, loss is 3.8377311563491823 and perplexity is 46.42003507045746
At time: 782.0999052524567 and batch: 200, loss is 3.830534806251526 and perplexity is 46.087179356149
At time: 783.1499044895172 and batch: 250, loss is 3.822496871948242 and perplexity is 45.71821846445978
At time: 784.2262332439423 and batch: 300, loss is 3.8386088752746583 and perplexity is 46.46079669976994
At time: 785.2772874832153 and batch: 350, loss is 3.840864338874817 and perplexity is 46.565705600190114
At time: 786.3283529281616 and batch: 400, loss is 3.8022726583480835 and perplexity is 44.80289054118236
At time: 787.3795850276947 and batch: 450, loss is 3.8397925186157225 and perplexity is 46.51582227130554
At time: 788.4296772480011 and batch: 500, loss is 3.8617234373092653 and perplexity is 47.547225458464894
At time: 789.4791822433472 and batch: 550, loss is 3.8324921417236326 and perplexity is 46.1774757684692
At time: 790.5289285182953 and batch: 600, loss is 3.8121547937393188 and perplexity is 45.24783364445968
At time: 791.5794444084167 and batch: 650, loss is 3.843514013290405 and perplexity is 46.68925316709302
At time: 792.6290457248688 and batch: 700, loss is 3.8558662271499635 and perplexity is 47.26954537562579
At time: 793.6781334877014 and batch: 750, loss is 3.8216632652282714 and perplexity is 45.68012333070849
At time: 794.7279069423676 and batch: 800, loss is 3.7893359994888307 and perplexity is 44.227023757668526
At time: 795.7772703170776 and batch: 850, loss is 3.7959436893463137 and perplexity is 44.52022985463629
At time: 796.8279318809509 and batch: 900, loss is 3.7643636989593507 and perplexity is 43.13624948508941
At time: 797.877197265625 and batch: 950, loss is 3.8623282718658447 and perplexity is 47.57599236222342
At time: 798.9281568527222 and batch: 1000, loss is 3.8169984865188598 and perplexity is 45.46753189545443
At time: 799.9793870449066 and batch: 1050, loss is 3.778272829055786 and perplexity is 43.74042925803169
At time: 801.0303583145142 and batch: 1100, loss is 3.800803198814392 and perplexity is 44.737102854549356
At time: 802.0805759429932 and batch: 1150, loss is 3.7704450702667236 and perplexity is 43.3993763100413
At time: 803.1301307678223 and batch: 1200, loss is 3.8157474851608275 and perplexity is 45.41068751491894
At time: 804.1791703701019 and batch: 1250, loss is 3.8172568559646605 and perplexity is 45.47928083419022
At time: 805.2291300296783 and batch: 1300, loss is 3.8064840602874757 and perplexity is 44.99197138956372
At time: 806.2792327404022 and batch: 1350, loss is 3.691082448959351 and perplexity is 40.08821692885859
At time: 807.3288516998291 and batch: 1400, loss is 3.7121306085586547 and perplexity is 40.940942790501836
At time: 808.3781309127808 and batch: 1450, loss is 3.6281199789047243 and perplexity is 37.64198233221771
At time: 809.4270496368408 and batch: 1500, loss is 3.6354173755645753 and perplexity is 37.917675506149024
At time: 810.477383852005 and batch: 1550, loss is 3.65662663936615 and perplexity is 38.730470411220175
At time: 811.5339331626892 and batch: 1600, loss is 3.741578178405762 and perplexity is 42.1644807572093
At time: 812.5841956138611 and batch: 1650, loss is 3.687823910713196 and perplexity is 39.95780053956949
At time: 813.6346158981323 and batch: 1700, loss is 3.711337995529175 and perplexity is 40.90850532268491
At time: 814.6866934299469 and batch: 1750, loss is 3.7048127126693724 and perplexity is 40.642434790913995
At time: 815.7375104427338 and batch: 1800, loss is 3.655013861656189 and perplexity is 38.66805711475968
At time: 816.7896704673767 and batch: 1850, loss is 3.6811360692977906 and perplexity is 39.691460718215666
At time: 817.8409328460693 and batch: 1900, loss is 3.7614473485946656 and perplexity is 43.010632329024055
At time: 818.8923301696777 and batch: 1950, loss is 3.718710336685181 and perplexity is 41.2112112346927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493353129542151 and perplexity of 89.42078320963138
finished 19 epochs...
Completing Train Step...
At time: 822.1968021392822 and batch: 50, loss is 3.8839438343048096 and perplexity is 48.61556923846726
At time: 823.2694888114929 and batch: 100, loss is 3.866105523109436 and perplexity is 47.75603866452895
At time: 824.3141057491302 and batch: 150, loss is 3.835831003189087 and perplexity is 46.331913642745405
At time: 825.3598568439484 and batch: 200, loss is 3.828506360054016 and perplexity is 45.993788743368775
At time: 826.4039969444275 and batch: 250, loss is 3.820378985404968 and perplexity is 45.62149492568602
At time: 827.4482200145721 and batch: 300, loss is 3.836436243057251 and perplexity is 46.359964051807
At time: 828.4925262928009 and batch: 350, loss is 3.838644142150879 and perplexity is 46.462435255829476
At time: 829.5370767116547 and batch: 400, loss is 3.800015802383423 and perplexity is 44.70189088413896
At time: 830.5811290740967 and batch: 450, loss is 3.8375980615615846 and perplexity is 46.413857216878654
At time: 831.624838590622 and batch: 500, loss is 3.8596318054199217 and perplexity is 47.447878100716714
At time: 832.6686127185822 and batch: 550, loss is 3.8304165410995483 and perplexity is 46.08172917116805
At time: 833.7127389907837 and batch: 600, loss is 3.810271224975586 and perplexity is 45.162686453848664
At time: 834.7572712898254 and batch: 650, loss is 3.8416793727874756 and perplexity is 46.60367369996382
At time: 835.8019230365753 and batch: 700, loss is 3.8541839504241944 and perplexity is 47.19009176981677
At time: 836.8709712028503 and batch: 750, loss is 3.8200882863998413 and perplexity is 45.608234729954965
At time: 837.9145197868347 and batch: 800, loss is 3.7877351951599123 and perplexity is 44.156281583877934
At time: 838.9590494632721 and batch: 850, loss is 3.7943191146850586 and perplexity is 44.44796213534832
At time: 840.0025701522827 and batch: 900, loss is 3.7630361461639406 and perplexity is 43.079021831272684
At time: 841.0461463928223 and batch: 950, loss is 3.8611378622055055 and perplexity is 47.519391137321676
At time: 842.089791059494 and batch: 1000, loss is 3.8158979654312133 and perplexity is 45.41752144162726
At time: 843.1333286762238 and batch: 1050, loss is 3.7773139476776123 and perplexity is 43.69850747716244
At time: 844.1767828464508 and batch: 1100, loss is 3.8000534677505495 and perplexity is 44.7035746289796
At time: 845.2220237255096 and batch: 1150, loss is 3.769781565666199 and perplexity is 43.370590175122224
At time: 846.2662000656128 and batch: 1200, loss is 3.8150685310363768 and perplexity is 45.379866205648064
At time: 847.3106505870819 and batch: 1250, loss is 3.8166968917846678 and perplexity is 45.453821194899525
At time: 848.3539333343506 and batch: 1300, loss is 3.8060434436798096 and perplexity is 44.97215154655449
At time: 849.3974707126617 and batch: 1350, loss is 3.690837655067444 and perplexity is 40.07840477924312
At time: 850.4420266151428 and batch: 1400, loss is 3.7120546960830687 and perplexity is 40.93783498014406
At time: 851.4873397350311 and batch: 1450, loss is 3.628276700973511 and perplexity is 37.64788212386374
At time: 852.5312433242798 and batch: 1500, loss is 3.635772914886475 and perplexity is 37.93115912762327
At time: 853.5744683742523 and batch: 1550, loss is 3.657143120765686 and perplexity is 38.75047914540759
At time: 854.6170942783356 and batch: 1600, loss is 3.7422451829910277 and perplexity is 42.19261404068122
At time: 855.6612651348114 and batch: 1650, loss is 3.6885656547546386 and perplexity is 39.98744999482287
At time: 856.7051696777344 and batch: 1700, loss is 3.7121305322647093 and perplexity is 40.9409396669559
At time: 857.7484955787659 and batch: 1750, loss is 3.7057256412506105 and perplexity is 40.6795553728877
At time: 858.7928636074066 and batch: 1800, loss is 3.655866684913635 and perplexity is 38.7010481989698
At time: 859.8372027873993 and batch: 1850, loss is 3.6820391273498534 and perplexity is 39.72732060075621
At time: 860.8819720745087 and batch: 1900, loss is 3.7622465896606445 and perplexity is 43.04502193361661
At time: 861.9254324436188 and batch: 1950, loss is 3.7193943643569947 and perplexity is 41.23941048700112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493321334484012 and perplexity of 89.41794011582878
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
2672.1299951076508


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.41794011582878}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6360119204925818, 'rnn_dropout': 0.965771331349581, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5172982215881348 and batch: 50, loss is 7.462851810455322 and perplexity is 1742.1091450197846
At time: 2.5690627098083496 and batch: 100, loss is 6.6370032691955565 and perplexity is 762.8056412848363
At time: 3.6468756198883057 and batch: 150, loss is 6.4151445007324215 and perplexity is 611.0290485841668
At time: 4.697908401489258 and batch: 200, loss is 6.323128700256348 and perplexity is 557.3139358401785
At time: 5.755067348480225 and batch: 250, loss is 6.256615953445435 and perplexity is 521.451335371654
At time: 6.815913677215576 and batch: 300, loss is 6.20077145576477 and perplexity is 493.1293218476227
At time: 7.870800495147705 and batch: 350, loss is 6.1505594825744625 and perplexity is 468.9796993654864
At time: 8.921336650848389 and batch: 400, loss is 6.113512134552002 and perplexity is 451.9231460678456
At time: 9.971588611602783 and batch: 450, loss is 6.039776639938355 and perplexity is 419.79925802591055
At time: 11.02060079574585 and batch: 500, loss is 6.020885801315307 and perplexity is 411.94333410713216
At time: 12.071357011795044 and batch: 550, loss is 5.977285299301148 and perplexity is 394.3683217125313
At time: 13.120773553848267 and batch: 600, loss is 6.0249796485900875 and perplexity is 413.6332239180754
At time: 14.172674179077148 and batch: 650, loss is 6.105753602981568 and perplexity is 448.43045267778575
At time: 15.223272562026978 and batch: 700, loss is 6.008279466629029 and perplexity is 406.7828344007166
At time: 16.27491331100464 and batch: 750, loss is 5.949208335876465 and perplexity is 383.44965553382775
At time: 17.325069665908813 and batch: 800, loss is 5.957305011749267 and perplexity is 386.56692584219957
At time: 18.374792098999023 and batch: 850, loss is 5.993307256698609 and perplexity is 400.7377633693077
At time: 19.424748420715332 and batch: 900, loss is 5.995830392837524 and perplexity is 401.7501559673759
At time: 20.474827527999878 and batch: 950, loss is 6.015467147827149 and perplexity is 409.7171927142191
At time: 21.5235755443573 and batch: 1000, loss is 5.999438714981079 and perplexity is 403.202418491138
At time: 22.57384967803955 and batch: 1050, loss is 5.898578653335571 and perplexity is 364.51899163250545
At time: 23.626057863235474 and batch: 1100, loss is 5.9812806129455565 and perplexity is 395.9470986035133
At time: 24.674975872039795 and batch: 1150, loss is 5.8889354228973385 and perplexity is 361.0207453038234
At time: 25.72586750984192 and batch: 1200, loss is 5.97597674369812 and perplexity is 393.85260633021346
At time: 26.775959014892578 and batch: 1250, loss is 5.902824125289917 and perplexity is 366.06983649311593
At time: 27.82582139968872 and batch: 1300, loss is 5.923480806350708 and perplexity is 373.710265627406
At time: 28.877302646636963 and batch: 1350, loss is 5.909988451004028 and perplexity is 368.70189724804214
At time: 29.92767643928528 and batch: 1400, loss is 5.925550203323365 and perplexity is 374.48442126113804
At time: 30.977394104003906 and batch: 1450, loss is 5.909114389419556 and perplexity is 368.3797698836212
At time: 32.029059171676636 and batch: 1500, loss is 5.885248384475708 and perplexity is 359.69209883533415
At time: 33.08626127243042 and batch: 1550, loss is 5.8684682941436765 and perplexity is 353.7067903738142
At time: 34.137282609939575 and batch: 1600, loss is 5.880231103897095 and perplexity is 357.891942374883
At time: 35.187007665634155 and batch: 1650, loss is 5.866840772628784 and perplexity is 353.1315931624021
At time: 36.23780608177185 and batch: 1700, loss is 5.8866550254821775 and perplexity is 360.1984125085621
At time: 37.28805494308472 and batch: 1750, loss is 5.89626690864563 and perplexity is 363.67729006363163
At time: 38.33863711357117 and batch: 1800, loss is 5.898298377990723 and perplexity is 364.4168402623459
At time: 39.3894464969635 and batch: 1850, loss is 5.853302631378174 and perplexity is 348.38306343337655
At time: 40.43900489807129 and batch: 1900, loss is 5.834428977966309 and perplexity is 341.8694633074369
At time: 41.48977756500244 and batch: 1950, loss is 5.777612209320068 and perplexity is 322.98704346933425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.235469090661337 and perplexity of 187.8171889726002
finished 1 epochs...
Completing Train Step...
At time: 44.84026503562927 and batch: 50, loss is 5.499792747497558 and perplexity is 244.64122450376797
At time: 45.89132046699524 and batch: 100, loss is 5.41694730758667 and perplexity is 225.1906344242719
At time: 46.9418408870697 and batch: 150, loss is 5.328821439743042 and perplexity is 206.19481787974792
At time: 47.99312996864319 and batch: 200, loss is 5.292432250976563 and perplexity is 198.82643355993417
At time: 49.044694662094116 and batch: 250, loss is 5.291508197784424 and perplexity is 198.64279221957207
At time: 50.103111267089844 and batch: 300, loss is 5.297557334899903 and perplexity is 199.84805142055225
At time: 51.154399156570435 and batch: 350, loss is 5.26624267578125 and perplexity is 193.68684925627713
At time: 52.20490074157715 and batch: 400, loss is 5.2355064868927 and perplexity is 187.82421275898375
At time: 53.25415253639221 and batch: 450, loss is 5.1837801837921145 and perplexity is 178.3557558017947
At time: 54.30422854423523 and batch: 500, loss is 5.1707814502716065 and perplexity is 176.0523599080663
At time: 55.35583519935608 and batch: 550, loss is 5.129548997879028 and perplexity is 168.94090815287163
At time: 56.406906843185425 and batch: 600, loss is 5.1334740352630615 and perplexity is 169.6053105822737
At time: 57.45728373527527 and batch: 650, loss is 5.207111759185791 and perplexity is 182.56600140667075
At time: 58.53382754325867 and batch: 700, loss is 5.161330766677857 and perplexity is 174.39638214492524
At time: 59.58402490615845 and batch: 750, loss is 5.110010805130005 and perplexity is 165.6721449731232
At time: 60.633824825286865 and batch: 800, loss is 5.095710248947143 and perplexity is 163.31980115732992
At time: 61.684693336486816 and batch: 850, loss is 5.091777820587158 and perplexity is 162.6788188739782
At time: 62.735595703125 and batch: 900, loss is 5.123227090835571 and perplexity is 167.8762483218267
At time: 63.78636884689331 and batch: 950, loss is 5.172062759399414 and perplexity is 176.27808198278424
At time: 64.83718299865723 and batch: 1000, loss is 5.136216449737549 and perplexity is 170.07107701135007
At time: 65.88821959495544 and batch: 1050, loss is 5.0500928497314455 and perplexity is 156.03695180288332
At time: 66.93896460533142 and batch: 1100, loss is 5.1391534328460695 and perplexity is 170.57130711588746
At time: 67.99374294281006 and batch: 1150, loss is 5.044727964401245 and perplexity is 155.20207296625398
At time: 69.05239939689636 and batch: 1200, loss is 5.1279254913330075 and perplexity is 168.66685400713993
At time: 70.11086440086365 and batch: 1250, loss is 5.0606116199493405 and perplexity is 157.68693130863582
At time: 71.16941833496094 and batch: 1300, loss is 5.090367460250855 and perplexity is 162.44954483778952
At time: 72.22724962234497 and batch: 1350, loss is 5.026775436401367 and perplexity is 152.44066470017088
At time: 73.28666234016418 and batch: 1400, loss is 5.034242105484009 and perplexity is 153.5831486651801
At time: 74.34555768966675 and batch: 1450, loss is 4.972329139709473 and perplexity is 144.36273708214733
At time: 75.40369534492493 and batch: 1500, loss is 4.961347484588623 and perplexity is 142.78606835238617
At time: 76.46219301223755 and batch: 1550, loss is 4.950760440826416 and perplexity is 141.2823599567001
At time: 77.52093362808228 and batch: 1600, loss is 5.011844377517701 and perplexity is 150.18147219862254
At time: 78.57813286781311 and batch: 1650, loss is 4.973289480209351 and perplexity is 144.5014410561024
At time: 79.63685035705566 and batch: 1700, loss is 4.9958919906616215 and perplexity is 147.80472703699346
At time: 80.69595575332642 and batch: 1750, loss is 5.010611591339111 and perplexity is 149.9964446285645
At time: 81.75473976135254 and batch: 1800, loss is 4.9714156532287594 and perplexity is 144.23092388745576
At time: 82.81325030326843 and batch: 1850, loss is 4.976271982192993 and perplexity is 144.93306022325342
At time: 83.87736868858337 and batch: 1900, loss is 5.029150047302246 and perplexity is 152.8030820941531
At time: 84.93600344657898 and batch: 1950, loss is 4.950122594833374 and perplexity is 141.19227230359283
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7825439453125 and perplexity of 119.40773072612511
finished 2 epochs...
Completing Train Step...
At time: 88.22478818893433 and batch: 50, loss is 4.878598947525024 and perplexity is 131.4463715501731
At time: 89.31186079978943 and batch: 100, loss is 4.827362394332885 and perplexity is 124.8811386767298
At time: 90.35738492012024 and batch: 150, loss is 4.775770130157471 and perplexity is 118.60161814126874
At time: 91.40179347991943 and batch: 200, loss is 4.760615186691284 and perplexity is 116.81776853491561
At time: 92.44685292243958 and batch: 250, loss is 4.767884683609009 and perplexity is 117.67006908798056
At time: 93.49202275276184 and batch: 300, loss is 4.804660921096802 and perplexity is 122.07808989762792
At time: 94.5362651348114 and batch: 350, loss is 4.8008777523040775 and perplexity is 121.61712039017624
At time: 95.58103060722351 and batch: 400, loss is 4.776993026733399 and perplexity is 118.7467443730931
At time: 96.62523865699768 and batch: 450, loss is 4.76217661857605 and perplexity is 117.00031400248176
At time: 97.67007327079773 and batch: 500, loss is 4.765032930374145 and perplexity is 117.33498110901807
At time: 98.71420383453369 and batch: 550, loss is 4.731688785552978 and perplexity is 113.48705590783737
At time: 99.75900053977966 and batch: 600, loss is 4.714187240600586 and perplexity is 111.51813691653798
At time: 100.8044056892395 and batch: 650, loss is 4.779256906509399 and perplexity is 119.01587725344213
At time: 101.84876132011414 and batch: 700, loss is 4.779453601837158 and perplexity is 119.03928942288368
At time: 102.89731860160828 and batch: 750, loss is 4.732044105529785 and perplexity is 113.52738729075911
At time: 103.94151568412781 and batch: 800, loss is 4.7184281826019285 and perplexity is 111.99208314618473
At time: 104.98623538017273 and batch: 850, loss is 4.719165086746216 and perplexity is 112.07464099125568
At time: 106.02995038032532 and batch: 900, loss is 4.736032791137696 and perplexity is 113.98111663685107
At time: 107.07502007484436 and batch: 950, loss is 4.804402322769165 and perplexity is 122.04652478925732
At time: 108.11996245384216 and batch: 1000, loss is 4.772639369964599 and perplexity is 118.23088555660716
At time: 109.16498732566833 and batch: 1050, loss is 4.699332294464111 and perplexity is 109.87378461987934
At time: 110.21022844314575 and batch: 1100, loss is 4.777178869247437 and perplexity is 118.76881461733255
At time: 111.2820692062378 and batch: 1150, loss is 4.702546119689941 and perplexity is 110.22746779407868
At time: 112.32718181610107 and batch: 1200, loss is 4.772507905960083 and perplexity is 118.21534347256907
At time: 113.37150168418884 and batch: 1250, loss is 4.741213350296021 and perplexity is 114.57313472282144
At time: 114.41614317893982 and batch: 1300, loss is 4.759896364212036 and perplexity is 116.73382746989373
At time: 115.4602563381195 and batch: 1350, loss is 4.672877759933471 and perplexity is 107.00523515352262
At time: 116.50540494918823 and batch: 1400, loss is 4.6838040447235105 and perplexity is 108.18081549422895
At time: 117.55006337165833 and batch: 1450, loss is 4.616464653015137 and perplexity is 101.13584903290804
At time: 118.59512138366699 and batch: 1500, loss is 4.613310813903809 and perplexity is 100.81738529234286
At time: 119.6406524181366 and batch: 1550, loss is 4.619276494979858 and perplexity is 101.42062724538859
At time: 120.68566679954529 and batch: 1600, loss is 4.698617792129516 and perplexity is 109.79530758360913
At time: 121.72999382019043 and batch: 1650, loss is 4.65091305732727 and perplexity is 104.68052127266411
At time: 122.77587962150574 and batch: 1700, loss is 4.679687566757202 and perplexity is 107.73640687756527
At time: 123.82095503807068 and batch: 1750, loss is 4.688901424407959 and perplexity is 108.73366202264427
At time: 124.86579155921936 and batch: 1800, loss is 4.654279193878174 and perplexity is 105.03348392845479
At time: 125.91120028495789 and batch: 1850, loss is 4.674722280502319 and perplexity is 107.20279065231699
At time: 126.95616245269775 and batch: 1900, loss is 4.7494262599945065 and perplexity is 115.51798821938867
At time: 128.00238180160522 and batch: 1950, loss is 4.674570932388305 and perplexity is 107.18656693987985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6800363939861915 and perplexity of 107.7739948253063
finished 3 epochs...
Completing Train Step...
At time: 131.3056457042694 and batch: 50, loss is 4.616631679534912 and perplexity is 101.15274281261185
At time: 132.35141324996948 and batch: 100, loss is 4.572738552093506 and perplexity is 96.80886320184386
At time: 133.39592385292053 and batch: 150, loss is 4.524955816268921 and perplexity is 92.2918479403802
At time: 134.4426350593567 and batch: 200, loss is 4.513610143661499 and perplexity is 91.25065254923267
At time: 135.48827028274536 and batch: 250, loss is 4.525427560806275 and perplexity is 92.33539638655152
At time: 136.53235960006714 and batch: 300, loss is 4.5585683250427245 and perplexity is 95.44673326733637
At time: 137.57607054710388 and batch: 350, loss is 4.5636466598510745 and perplexity is 95.93267658230499
At time: 138.6472885608673 and batch: 400, loss is 4.533920974731445 and perplexity is 93.12297902613369
At time: 139.69159865379333 and batch: 450, loss is 4.536167573928833 and perplexity is 93.33242421767903
At time: 140.7367000579834 and batch: 500, loss is 4.546705436706543 and perplexity is 94.32114886962785
At time: 141.7808542251587 and batch: 550, loss is 4.513597526550293 and perplexity is 91.249501236865
At time: 142.82651662826538 and batch: 600, loss is 4.487690401077271 and perplexity is 88.91584859828608
At time: 143.88302087783813 and batch: 650, loss is 4.549924001693726 and perplexity is 94.6252166854528
At time: 144.93643641471863 and batch: 700, loss is 4.559517240524292 and perplexity is 95.53734713585074
At time: 145.98290395736694 and batch: 750, loss is 4.521689596176148 and perplexity is 91.99089421035083
At time: 147.02759075164795 and batch: 800, loss is 4.508167839050293 and perplexity is 90.75538761582769
At time: 148.07137393951416 and batch: 850, loss is 4.504975280761719 and perplexity is 90.46610776795536
At time: 149.11739897727966 and batch: 900, loss is 4.513374528884888 and perplexity is 91.22915507977686
At time: 150.16203379631042 and batch: 950, loss is 4.592687625885009 and perplexity is 98.75950238991072
At time: 151.20629453659058 and batch: 1000, loss is 4.557460947036743 and perplexity is 95.34109615507583
At time: 152.25041127204895 and batch: 1050, loss is 4.495696487426758 and perplexity is 89.63057381824945
At time: 153.2931261062622 and batch: 1100, loss is 4.566045904159546 and perplexity is 96.16311884369095
At time: 154.33647418022156 and batch: 1150, loss is 4.4969922637939455 and perplexity is 89.74679027658969
At time: 155.38348937034607 and batch: 1200, loss is 4.569242496490478 and perplexity is 96.47100496293879
At time: 156.4269654750824 and batch: 1250, loss is 4.549766521453858 and perplexity is 94.61031625692392
At time: 157.4719910621643 and batch: 1300, loss is 4.560568218231201 and perplexity is 95.63780753944309
At time: 158.51746249198914 and batch: 1350, loss is 4.461456327438355 and perplexity is 86.61355498866963
At time: 159.56285953521729 and batch: 1400, loss is 4.47313889503479 and perplexity is 87.63135739632388
At time: 160.60804176330566 and batch: 1450, loss is 4.400911340713501 and perplexity is 81.52513199218942
At time: 161.6530249118805 and batch: 1500, loss is 4.408542757034302 and perplexity is 82.14966421675291
At time: 162.69800066947937 and batch: 1550, loss is 4.419960508346557 and perplexity is 83.09300381343728
At time: 163.74628281593323 and batch: 1600, loss is 4.506400623321533 and perplexity is 90.5951449007904
At time: 164.7959361076355 and batch: 1650, loss is 4.454379816055297 and perplexity is 86.00279674842852
At time: 165.84686589241028 and batch: 1700, loss is 4.494261646270752 and perplexity is 89.50206040231602
At time: 166.89758682250977 and batch: 1750, loss is 4.493409557342529 and perplexity is 89.42582917010088
At time: 167.94820261001587 and batch: 1800, loss is 4.458613529205322 and perplexity is 86.36767977998228
At time: 168.99958872795105 and batch: 1850, loss is 4.484756507873535 and perplexity is 88.65536130218335
At time: 170.05092239379883 and batch: 1900, loss is 4.562822437286377 and perplexity is 95.85363928221153
At time: 171.10203099250793 and batch: 1950, loss is 4.489203014373779 and perplexity is 89.05044566413876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.632993618277617 and perplexity of 102.82141189797335
finished 4 epochs...
Completing Train Step...
At time: 174.40753769874573 and batch: 50, loss is 4.445415115356445 and perplexity is 85.23525295684976
At time: 175.4812924861908 and batch: 100, loss is 4.400017223358154 and perplexity is 81.45227153453214
At time: 176.53164839744568 and batch: 150, loss is 4.3549369430541995 and perplexity is 77.8619154474461
At time: 177.5762906074524 and batch: 200, loss is 4.34696135520935 and perplexity is 77.24339072883355
At time: 178.6215353012085 and batch: 250, loss is 4.34664363861084 and perplexity is 77.21885311968306
At time: 179.66595602035522 and batch: 300, loss is 4.380432615280151 and perplexity is 79.87258003043297
At time: 180.7108232975006 and batch: 350, loss is 4.392366924285889 and perplexity is 80.83151481205333
At time: 181.75420331954956 and batch: 400, loss is 4.363351497650147 and perplexity is 78.51985302969047
At time: 182.79866743087769 and batch: 450, loss is 4.374679851531982 and perplexity is 79.4144110799895
At time: 183.843523979187 and batch: 500, loss is 4.383797903060913 and perplexity is 80.14182704075877
At time: 184.8880569934845 and batch: 550, loss is 4.353066291809082 and perplexity is 77.71639910596397
At time: 185.9316282272339 and batch: 600, loss is 4.329586224555969 and perplexity is 75.91286918860911
At time: 186.9770646095276 and batch: 650, loss is 4.389439220428467 and perplexity is 80.59521015814964
At time: 188.02143692970276 and batch: 700, loss is 4.403219270706177 and perplexity is 81.7135035800757
At time: 189.06503129005432 and batch: 750, loss is 4.365926685333252 and perplexity is 78.72231696752311
At time: 190.11018872261047 and batch: 800, loss is 4.349117221832276 and perplexity is 77.41009681021829
At time: 191.18148398399353 and batch: 850, loss is 4.347657289505005 and perplexity is 77.29716576332939
At time: 192.22597241401672 and batch: 900, loss is 4.352904872894287 and perplexity is 77.70385522159587
At time: 193.26941680908203 and batch: 950, loss is 4.436217432022095 and perplexity is 84.45488040249658
At time: 194.31472063064575 and batch: 1000, loss is 4.400748338699341 and perplexity is 81.51184431445856
At time: 195.36067867279053 and batch: 1050, loss is 4.342883234024048 and perplexity is 76.92902426862585
At time: 196.40661239624023 and batch: 1100, loss is 4.411082963943482 and perplexity is 82.35860662750817
At time: 197.4510498046875 and batch: 1150, loss is 4.346017627716065 and perplexity is 77.17052840382556
At time: 198.49687790870667 and batch: 1200, loss is 4.416576833724975 and perplexity is 82.81231926559566
At time: 199.54264092445374 and batch: 1250, loss is 4.399050436019897 and perplexity is 81.37356256328933
At time: 200.5861964225769 and batch: 1300, loss is 4.410390758514405 and perplexity is 82.301617279313
At time: 201.62961649894714 and batch: 1350, loss is 4.310762529373169 and perplexity is 74.49727364696743
At time: 202.6737585067749 and batch: 1400, loss is 4.325596027374267 and perplexity is 75.61056539888112
At time: 203.72354936599731 and batch: 1450, loss is 4.24592493057251 and perplexity is 69.82030922617697
At time: 204.7686698436737 and batch: 1500, loss is 4.264172644615173 and perplexity is 71.10606564372473
At time: 205.81457614898682 and batch: 1550, loss is 4.269554948806762 and perplexity is 71.48981191205928
At time: 206.8679039478302 and batch: 1600, loss is 4.360290470123291 and perplexity is 78.27986908427863
At time: 207.91292476654053 and batch: 1650, loss is 4.30917809009552 and perplexity is 74.37933070191485
At time: 208.95889496803284 and batch: 1700, loss is 4.3459990692138675 and perplexity is 77.16909624769399
At time: 210.00490474700928 and batch: 1750, loss is 4.352621583938599 and perplexity is 77.68184569527226
At time: 211.0556013584137 and batch: 1800, loss is 4.312123775482178 and perplexity is 74.59875182356781
At time: 212.10017108917236 and batch: 1850, loss is 4.338107986450195 and perplexity is 76.56254484352299
At time: 213.14592266082764 and batch: 1900, loss is 4.42188681602478 and perplexity is 83.25322076872268
At time: 214.19284439086914 and batch: 1950, loss is 4.349727563858032 and perplexity is 77.45735786675678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.61479009583939 and perplexity of 100.96663299169491
finished 5 epochs...
Completing Train Step...
At time: 217.52238869667053 and batch: 50, loss is 4.30590057849884 and perplexity is 74.1359506413389
At time: 218.57284212112427 and batch: 100, loss is 4.259413542747498 and perplexity is 70.76846860046366
At time: 219.62382197380066 and batch: 150, loss is 4.219925136566162 and perplexity is 68.02839125981302
At time: 220.6743130683899 and batch: 200, loss is 4.218387351036072 and perplexity is 67.92385857912005
At time: 221.72481417655945 and batch: 250, loss is 4.213756108283997 and perplexity is 67.6100140075366
At time: 222.77929615974426 and batch: 300, loss is 4.24639139175415 and perplexity is 69.85288528726437
At time: 223.83127355575562 and batch: 350, loss is 4.25784628868103 and perplexity is 70.65764329865922
At time: 224.88116645812988 and batch: 400, loss is 4.221516752243042 and perplexity is 68.13675252568443
At time: 225.9385027885437 and batch: 450, loss is 4.239429244995117 and perplexity is 69.3682482629847
At time: 226.9883735179901 and batch: 500, loss is 4.2577272605896 and perplexity is 70.64923355474023
At time: 228.03861379623413 and batch: 550, loss is 4.226962385177612 and perplexity is 68.50881240059717
At time: 229.08963441848755 and batch: 600, loss is 4.203543772697449 and perplexity is 66.92307146953945
At time: 230.13943696022034 and batch: 650, loss is 4.263300514221191 and perplexity is 71.0440789168636
At time: 231.19065523147583 and batch: 700, loss is 4.276034479141235 and perplexity is 71.95453628887091
At time: 232.24034786224365 and batch: 750, loss is 4.239364576339722 and perplexity is 69.3637624566895
At time: 233.29210758209229 and batch: 800, loss is 4.221369209289551 and perplexity is 68.12670016957088
At time: 234.34227585792542 and batch: 850, loss is 4.222540159225463 and perplexity is 68.20651984807185
At time: 235.39339423179626 and batch: 900, loss is 4.2208207321166995 and perplexity is 68.0893444749755
At time: 236.44315028190613 and batch: 950, loss is 4.306849946975708 and perplexity is 74.2063663958404
At time: 237.49475479125977 and batch: 1000, loss is 4.274168491363525 and perplexity is 71.82039519534787
At time: 238.54454398155212 and batch: 1050, loss is 4.22990161895752 and perplexity is 68.71047203344912
At time: 239.59493494033813 and batch: 1100, loss is 4.283138093948364 and perplexity is 72.46749336599673
At time: 240.64511632919312 and batch: 1150, loss is 4.223275985717773 and perplexity is 68.25672648174456
At time: 241.69640040397644 and batch: 1200, loss is 4.29069531917572 and perplexity is 73.01722112695789
At time: 242.74707078933716 and batch: 1250, loss is 4.2788777351379395 and perplexity is 72.1594125755095
At time: 243.79690718650818 and batch: 1300, loss is 4.286684770584106 and perplexity is 72.72496845210843
At time: 244.8473916053772 and batch: 1350, loss is 4.182234568595886 and perplexity is 65.51208101402356
At time: 245.89802718162537 and batch: 1400, loss is 4.2049762773513795 and perplexity is 67.01900777907417
At time: 246.94932675361633 and batch: 1450, loss is 4.123262548446656 and perplexity is 61.76041025637574
At time: 247.99890899658203 and batch: 1500, loss is 4.140816564559937 and perplexity is 62.854124950921104
At time: 249.04901337623596 and batch: 1550, loss is 4.142871794700622 and perplexity is 62.98343748097362
At time: 250.0991039276123 and batch: 1600, loss is 4.242580542564392 and perplexity is 69.58719305402548
At time: 251.1509974002838 and batch: 1650, loss is 4.192418775558472 and perplexity is 66.1826785616465
At time: 252.20217967033386 and batch: 1700, loss is 4.233585147857666 and perplexity is 68.96403576088193
At time: 253.25235414505005 and batch: 1750, loss is 4.23370728969574 and perplexity is 68.97245966941612
At time: 254.30273914337158 and batch: 1800, loss is 4.194145765304565 and perplexity is 66.297074120438
At time: 255.35317277908325 and batch: 1850, loss is 4.21902829170227 and perplexity is 67.96740769699795
At time: 256.4036591053009 and batch: 1900, loss is 4.304165554046631 and perplexity is 74.00743447577273
At time: 257.4536395072937 and batch: 1950, loss is 4.231138105392456 and perplexity is 68.79548414738817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.610000113553779 and perplexity of 100.48416104674494
finished 6 epochs...
Completing Train Step...
At time: 260.7341456413269 and batch: 50, loss is 4.1894285678863525 and perplexity is 65.9850741947344
At time: 261.8039741516113 and batch: 100, loss is 4.146549468040466 and perplexity is 63.21549644682996
At time: 262.8517563343048 and batch: 150, loss is 4.117876620292663 and perplexity is 61.428667297783164
At time: 263.9064447879791 and batch: 200, loss is 4.107072439193725 and perplexity is 60.76855326865467
At time: 264.9519054889679 and batch: 250, loss is 4.104260220527649 and perplexity is 60.59789888004002
At time: 265.99700832366943 and batch: 300, loss is 4.13259105682373 and perplexity is 62.33923836473883
At time: 267.040509223938 and batch: 350, loss is 4.142967548370361 and perplexity is 62.9894686649946
At time: 268.08185505867004 and batch: 400, loss is 4.115033960342407 and perplexity is 61.25429444424315
At time: 269.12538504600525 and batch: 450, loss is 4.131413669586181 and perplexity is 62.26588413273185
At time: 270.16808676719666 and batch: 500, loss is 4.151569089889526 and perplexity is 63.533612076122814
At time: 271.2546706199646 and batch: 550, loss is 4.125741376876831 and perplexity is 61.91369362027005
At time: 272.297682762146 and batch: 600, loss is 4.10021559715271 and perplexity is 60.35329819403506
At time: 273.34133553504944 and batch: 650, loss is 4.155544047355652 and perplexity is 63.78665807214711
At time: 274.38492345809937 and batch: 700, loss is 4.1684233093261716 and perplexity is 64.61349625515486
At time: 275.4280686378479 and batch: 750, loss is 4.134776282310486 and perplexity is 62.4756126072056
At time: 276.4704239368439 and batch: 800, loss is 4.115598068237305 and perplexity is 61.28885822326931
At time: 277.51336789131165 and batch: 850, loss is 4.112968997955322 and perplexity is 61.12793713661188
At time: 278.5556700229645 and batch: 900, loss is 4.113470678329468 and perplexity is 61.15861151670919
At time: 279.5992081165314 and batch: 950, loss is 4.207421684265137 and perplexity is 67.18309707482808
At time: 280.64275908470154 and batch: 1000, loss is 4.167528429031372 and perplexity is 64.55570077445336
At time: 281.6867697238922 and batch: 1050, loss is 4.125787625312805 and perplexity is 61.91655709798055
At time: 282.73824548721313 and batch: 1100, loss is 4.180712385177612 and perplexity is 65.41243546924562
At time: 283.78734707832336 and batch: 1150, loss is 4.1171630859375 and perplexity is 61.38485146718354
At time: 284.8310053348541 and batch: 1200, loss is 4.188457531929016 and perplexity is 65.92103141399747
At time: 285.87288331985474 and batch: 1250, loss is 4.176660928726196 and perplexity is 65.14795596093643
At time: 286.91596031188965 and batch: 1300, loss is 4.182574243545532 and perplexity is 65.53433760663269
At time: 287.958060503006 and batch: 1350, loss is 4.082997546195984 and perplexity is 59.32302711313983
At time: 289.0040991306305 and batch: 1400, loss is 4.104072904586792 and perplexity is 60.58654899063814
At time: 290.0470666885376 and batch: 1450, loss is 4.0231716299057005 and perplexity is 55.87804957152613
At time: 291.09092688560486 and batch: 1500, loss is 4.040143871307373 and perplexity is 56.8345190738528
At time: 292.1339313983917 and batch: 1550, loss is 4.040972137451172 and perplexity is 56.881612682129145
At time: 293.1768686771393 and batch: 1600, loss is 4.141688356399536 and perplexity is 62.908944556308775
At time: 294.218816280365 and batch: 1650, loss is 4.0934801769256595 and perplexity is 59.94815929061478
At time: 295.2608358860016 and batch: 1700, loss is 4.136316957473755 and perplexity is 62.57194141850863
At time: 296.30232214927673 and batch: 1750, loss is 4.136974148750305 and perplexity is 62.61307666794867
At time: 297.34570717811584 and batch: 1800, loss is 4.093488874435425 and perplexity is 59.948680692583096
At time: 298.3895456790924 and batch: 1850, loss is 4.12039083480835 and perplexity is 61.58330646133768
At time: 299.4327697753906 and batch: 1900, loss is 4.204159054756165 and perplexity is 66.96426070492817
At time: 300.47674036026 and batch: 1950, loss is 4.134236240386963 and perplexity is 62.44188226591893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.613782589934593 and perplexity of 100.86495973956971
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 303.783976316452 and batch: 50, loss is 4.124359841346741 and perplexity is 61.8282167110235
At time: 304.8286259174347 and batch: 100, loss is 4.109674196243287 and perplexity is 60.92686413441618
At time: 305.8731014728546 and batch: 150, loss is 4.081490688323974 and perplexity is 59.233703058971784
At time: 306.9260723590851 and batch: 200, loss is 4.062385787963867 and perplexity is 58.11279061826877
At time: 307.9778699874878 and batch: 250, loss is 4.068814806938171 and perplexity is 58.48760239683674
At time: 309.0224995613098 and batch: 300, loss is 4.086908388137817 and perplexity is 59.55548435116854
At time: 310.0667562484741 and batch: 350, loss is 4.08947500705719 and perplexity is 59.70853691383825
At time: 311.1110510826111 and batch: 400, loss is 4.0510973405838016 and perplexity is 57.46047617486957
At time: 312.15465569496155 and batch: 450, loss is 4.0650749778747555 and perplexity is 58.2692772653433
At time: 313.19970750808716 and batch: 500, loss is 4.084095740318299 and perplexity is 59.388211098617084
At time: 314.25104451179504 and batch: 550, loss is 4.05276029586792 and perplexity is 57.55610987259505
At time: 315.2971670627594 and batch: 600, loss is 4.011196169853211 and perplexity is 55.21287505595272
At time: 316.3412275314331 and batch: 650, loss is 4.051460523605346 and perplexity is 57.48134863425816
At time: 317.38613986968994 and batch: 700, loss is 4.063090243339539 and perplexity is 58.15374290885211
At time: 318.4313859939575 and batch: 750, loss is 4.014426565170288 and perplexity is 55.39152286514306
At time: 319.4759657382965 and batch: 800, loss is 3.994072480201721 and perplexity is 54.2754756919226
At time: 320.5214309692383 and batch: 850, loss is 3.988551516532898 and perplexity is 53.97664842879764
At time: 321.56561374664307 and batch: 900, loss is 3.9771887922286986 and perplexity is 53.36679799654549
At time: 322.6095349788666 and batch: 950, loss is 4.066988878250122 and perplexity is 58.3809056456986
At time: 323.6818208694458 and batch: 1000, loss is 4.016772952079773 and perplexity is 55.521645408506984
At time: 324.7253592014313 and batch: 1050, loss is 3.9767191076278685 and perplexity is 53.341738318863946
At time: 325.77104783058167 and batch: 1100, loss is 4.019898386001587 and perplexity is 55.695446102275
At time: 326.8147602081299 and batch: 1150, loss is 3.9569280481338502 and perplexity is 52.29642683245953
At time: 327.8585276603699 and batch: 1200, loss is 4.017143025398254 and perplexity is 55.54219629050286
At time: 328.90268778800964 and batch: 1250, loss is 3.996069321632385 and perplexity is 54.38396349087059
At time: 329.9480333328247 and batch: 1300, loss is 3.9866580963134766 and perplexity is 53.87454464447466
At time: 330.9930462837219 and batch: 1350, loss is 3.8865156984329223 and perplexity is 48.74076279846489
At time: 332.0371787548065 and batch: 1400, loss is 3.902236590385437 and perplexity is 49.513065804227196
At time: 333.0827305316925 and batch: 1450, loss is 3.8081529092788697 and perplexity is 45.06711888310659
At time: 334.1276526451111 and batch: 1500, loss is 3.823993306159973 and perplexity is 45.78668398496667
At time: 335.1718804836273 and batch: 1550, loss is 3.8195138216018676 and perplexity is 45.582041928746335
At time: 336.21704268455505 and batch: 1600, loss is 3.9067255640029908 and perplexity is 49.73582826367672
At time: 337.26127195358276 and batch: 1650, loss is 3.851017827987671 and perplexity is 47.0409184366149
At time: 338.30626106262207 and batch: 1700, loss is 3.887005777359009 and perplexity is 48.76465547332382
At time: 339.352002620697 and batch: 1750, loss is 3.8691274642944338 and perplexity is 47.90057288156112
At time: 340.3966293334961 and batch: 1800, loss is 3.8226563119888306 and perplexity is 45.72550836020258
At time: 341.4423339366913 and batch: 1850, loss is 3.8402946043014525 and perplexity is 46.53918306389696
At time: 342.48720359802246 and batch: 1900, loss is 3.908924980163574 and perplexity is 49.84533843319249
At time: 343.53029584884644 and batch: 1950, loss is 3.841836915016174 and perplexity is 46.61101632495562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.53017578125 and perplexity of 92.7748677310865
finished 8 epochs...
Completing Train Step...
At time: 346.82207798957825 and batch: 50, loss is 4.019389629364014 and perplexity is 55.66711788108418
At time: 347.9003448486328 and batch: 100, loss is 3.992423720359802 and perplexity is 54.18606219814484
At time: 348.9508776664734 and batch: 150, loss is 3.9641098546981812 and perplexity is 52.67336157002444
At time: 350.0266969203949 and batch: 200, loss is 3.9444780778884887 and perplexity is 51.649374125766826
At time: 351.07740926742554 and batch: 250, loss is 3.9478959035873413 and perplexity is 51.82620469988617
At time: 352.12787199020386 and batch: 300, loss is 3.968873629570007 and perplexity is 52.92488422928659
At time: 353.1783571243286 and batch: 350, loss is 3.9778660011291502 and perplexity is 53.40295070722441
At time: 354.22779273986816 and batch: 400, loss is 3.941771774291992 and perplexity is 51.509784210355804
At time: 355.27986431121826 and batch: 450, loss is 3.964968328475952 and perplexity is 52.71859968480871
At time: 356.33224844932556 and batch: 500, loss is 3.9851429939270018 and perplexity is 53.79298099755431
At time: 357.38383507728577 and batch: 550, loss is 3.9567271661758423 and perplexity is 52.28592247894348
At time: 358.43509101867676 and batch: 600, loss is 3.921522927284241 and perplexity is 50.47725946730251
At time: 359.48590898513794 and batch: 650, loss is 3.9616287422180174 and perplexity is 52.542835027736636
At time: 360.53734970092773 and batch: 700, loss is 3.978034329414368 and perplexity is 53.41194069095557
At time: 361.58852982521057 and batch: 750, loss is 3.9347609090805054 and perplexity is 51.14991901339291
At time: 362.6402049064636 and batch: 800, loss is 3.9151183652877806 and perplexity is 50.15500777163482
At time: 363.6917369365692 and batch: 850, loss is 3.912420616149902 and perplexity is 50.01988448896884
At time: 364.7438452243805 and batch: 900, loss is 3.9008336591720583 and perplexity is 49.443651082165765
At time: 365.795284986496 and batch: 950, loss is 3.994185199737549 and perplexity is 54.28159394316617
At time: 366.84599351882935 and batch: 1000, loss is 3.945061731338501 and perplexity is 51.67952826009255
At time: 367.8985605239868 and batch: 1050, loss is 3.910498118400574 and perplexity is 49.92381375109557
At time: 368.9502875804901 and batch: 1100, loss is 3.9556161975860595 and perplexity is 52.227866716417154
At time: 370.0030233860016 and batch: 1150, loss is 3.8973358154296873 and perplexity is 49.27100703360418
At time: 371.0547637939453 and batch: 1200, loss is 3.958395185470581 and perplexity is 52.373209184197776
At time: 372.1060252189636 and batch: 1250, loss is 3.9424923133850096 and perplexity is 51.546912398101284
At time: 373.1566834449768 and batch: 1300, loss is 3.9357328748703004 and perplexity is 51.19965915376626
At time: 374.2078700065613 and batch: 1350, loss is 3.838318214416504 and perplexity is 46.44729432713131
At time: 375.2601718902588 and batch: 1400, loss is 3.85767361164093 and perplexity is 47.35505687163064
At time: 376.3135368824005 and batch: 1450, loss is 3.7675951290130616 and perplexity is 43.275866718249645
At time: 377.36488676071167 and batch: 1500, loss is 3.786805205345154 and perplexity is 44.11523578079504
At time: 378.4168395996094 and batch: 1550, loss is 3.7856783771514895 and perplexity is 44.065553486309135
At time: 379.4688994884491 and batch: 1600, loss is 3.876241159439087 and perplexity is 48.24253782940561
At time: 380.5206141471863 and batch: 1650, loss is 3.8224861145019533 and perplexity is 45.71772665582554
At time: 381.5730664730072 and batch: 1700, loss is 3.8641843938827516 and perplexity is 47.664381213993686
At time: 382.6243574619293 and batch: 1750, loss is 3.850786108970642 and perplexity is 47.03001942403764
At time: 383.67747473716736 and batch: 1800, loss is 3.808295798301697 and perplexity is 45.07355893978118
At time: 384.7295660972595 and batch: 1850, loss is 3.829659867286682 and perplexity is 46.04687352229406
At time: 385.780375957489 and batch: 1900, loss is 3.903265199661255 and perplexity is 49.56402160529967
At time: 386.83145451545715 and batch: 1950, loss is 3.8391470193862913 and perplexity is 46.48580603264475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52879269622093 and perplexity of 92.64664089520292
finished 9 epochs...
Completing Train Step...
At time: 390.14822721481323 and batch: 50, loss is 3.9685445261001586 and perplexity is 52.907469332054134
At time: 391.19154024124146 and batch: 100, loss is 3.939497919082642 and perplexity is 51.392791481867576
At time: 392.2370183467865 and batch: 150, loss is 3.9114523124694824 and perplexity is 49.97147349277946
At time: 393.2823979854584 and batch: 200, loss is 3.892236785888672 and perplexity is 49.02041215153498
At time: 394.3275752067566 and batch: 250, loss is 3.8939435338974 and perplexity is 49.10414908095334
At time: 395.37268018722534 and batch: 300, loss is 3.9163129901885987 and perplexity is 50.21495999589956
At time: 396.41695761680603 and batch: 350, loss is 3.9256876420974733 and perplexity is 50.68792122611984
At time: 397.4623534679413 and batch: 400, loss is 3.888884253501892 and perplexity is 48.85634480639693
At time: 398.50692081451416 and batch: 450, loss is 3.914954776763916 and perplexity is 50.146803659016676
At time: 399.5518870353699 and batch: 500, loss is 3.9370743656158447 and perplexity is 51.26838911269079
At time: 400.5956463813782 and batch: 550, loss is 3.9079905939102173 and perplexity is 49.798785386816924
At time: 401.6400249004364 and batch: 600, loss is 3.8759705591201783 and perplexity is 48.22948514939334
At time: 402.6874713897705 and batch: 650, loss is 3.9163315105438232 and perplexity is 50.215890003408276
At time: 403.7709186077118 and batch: 700, loss is 3.9329966163635253 and perplexity is 51.05975514491967
At time: 404.8145241737366 and batch: 750, loss is 3.8917109060287474 and perplexity is 48.9946400811596
At time: 405.8589913845062 and batch: 800, loss is 3.871412205696106 and perplexity is 48.0101384203874
At time: 406.9030251502991 and batch: 850, loss is 3.8707164096832276 and perplexity is 47.97674477642617
At time: 407.94795656204224 and batch: 900, loss is 3.859056677818298 and perplexity is 47.42059736208739
At time: 408.993230342865 and batch: 950, loss is 3.953090481758118 and perplexity is 52.096120413689675
At time: 410.03896379470825 and batch: 1000, loss is 3.9046161127090455 and perplexity is 49.631023535488424
At time: 411.08301615715027 and batch: 1050, loss is 3.8721289300918578 and perplexity is 48.04456079203994
At time: 412.1274359226227 and batch: 1100, loss is 3.918721890449524 and perplexity is 50.33606863689038
At time: 413.17248940467834 and batch: 1150, loss is 3.8615588331222535 and perplexity is 47.53939963017336
At time: 414.2169225215912 and batch: 1200, loss is 3.923014440536499 and perplexity is 50.552603142813375
At time: 415.25955295562744 and batch: 1250, loss is 3.9090684509277343 and perplexity is 49.852490295016594
At time: 416.3027105331421 and batch: 1300, loss is 3.903369789123535 and perplexity is 49.569205750766585
At time: 417.34667325019836 and batch: 1350, loss is 3.805646061897278 and perplexity is 44.95428398316586
At time: 418.3908107280731 and batch: 1400, loss is 3.828347201347351 and perplexity is 45.98646901395256
At time: 419.436527967453 and batch: 1450, loss is 3.738852024078369 and perplexity is 42.049690414717915
At time: 420.48084354400635 and batch: 1500, loss is 3.759540238380432 and perplexity is 42.928684479416745
At time: 421.52522110939026 and batch: 1550, loss is 3.7592513132095338 and perplexity is 42.91628309353962
At time: 422.56927132606506 and batch: 1600, loss is 3.8514348602294923 and perplexity is 47.060540107438165
At time: 423.6131944656372 and batch: 1650, loss is 3.798084006309509 and perplexity is 44.615619303212405
At time: 424.6575274467468 and batch: 1700, loss is 3.841470031738281 and perplexity is 46.593918659116014
At time: 425.7016191482544 and batch: 1750, loss is 3.8304121780395506 and perplexity is 46.08152811425749
At time: 426.7446048259735 and batch: 1800, loss is 3.789855818748474 and perplexity is 44.250019792787626
At time: 427.7892007827759 and batch: 1850, loss is 3.8111349153518677 and perplexity is 45.20170988115936
At time: 428.83448934555054 and batch: 1900, loss is 3.8869371461868285 and perplexity is 48.76130881270164
At time: 429.8789162635803 and batch: 1950, loss is 3.8236693811416624 and perplexity is 45.771854934398355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.531963685501453 and perplexity of 92.94088868208777
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 433.1470100879669 and batch: 50, loss is 3.9467571926116944 and perplexity is 51.76722321957104
At time: 434.2177588939667 and batch: 100, loss is 3.9418117666244505 and perplexity is 51.51184424796339
At time: 435.2629134654999 and batch: 150, loss is 3.922719745635986 and perplexity is 50.53770774336647
At time: 436.3090727329254 and batch: 200, loss is 3.9079378271102905 and perplexity is 49.796157733598854
At time: 437.35343289375305 and batch: 250, loss is 3.9132014417648318 and perplexity is 50.05895654828087
At time: 438.3985185623169 and batch: 300, loss is 3.93647931098938 and perplexity is 51.237890695569924
At time: 439.443852186203 and batch: 350, loss is 3.942303624153137 and perplexity is 51.53718696836628
At time: 440.4875371456146 and batch: 400, loss is 3.903578448295593 and perplexity is 49.57954989936132
At time: 441.53348875045776 and batch: 450, loss is 3.927420482635498 and perplexity is 50.775831456016085
At time: 442.58001232147217 and batch: 500, loss is 3.9502527952194213 and perplexity is 51.94849750690181
At time: 443.62657403945923 and batch: 550, loss is 3.921259799003601 and perplexity is 50.4639792200884
At time: 444.6712317466736 and batch: 600, loss is 3.8836829710006713 and perplexity is 48.602888874435884
At time: 445.7153067588806 and batch: 650, loss is 3.9132812070846557 and perplexity is 50.06294967621444
At time: 446.75970101356506 and batch: 700, loss is 3.925852656364441 and perplexity is 50.69628614643169
At time: 447.80347657203674 and batch: 750, loss is 3.878722319602966 and perplexity is 48.36238390964982
At time: 448.8493194580078 and batch: 800, loss is 3.857010803222656 and perplexity is 47.323679940883906
At time: 449.89537143707275 and batch: 850, loss is 3.853113899230957 and perplexity is 47.139622962728716
At time: 450.93918085098267 and batch: 900, loss is 3.833420600891113 and perplexity is 46.220369578671864
At time: 451.98393082618713 and batch: 950, loss is 3.9342148065567017 and perplexity is 51.1219935393073
At time: 453.0282459259033 and batch: 1000, loss is 3.8800112581253052 and perplexity is 48.42476024029504
At time: 454.07277059555054 and batch: 1050, loss is 3.8438202285766603 and perplexity is 46.70355231931438
At time: 455.1171498298645 and batch: 1100, loss is 3.887084183692932 and perplexity is 48.76847908108009
At time: 456.2072560787201 and batch: 1150, loss is 3.8306445837020875 and perplexity is 46.09223896691279
At time: 457.2532117366791 and batch: 1200, loss is 3.886453366279602 and perplexity is 48.73772477644941
At time: 458.29856729507446 and batch: 1250, loss is 3.8634561824798586 and perplexity is 47.629684103031046
At time: 459.34439873695374 and batch: 1300, loss is 3.857493352890015 and perplexity is 47.34652147754229
At time: 460.39140486717224 and batch: 1350, loss is 3.7546596002578734 and perplexity is 42.71967556871743
At time: 461.4373641014099 and batch: 1400, loss is 3.7796587419509886 and perplexity is 43.801091709709304
At time: 462.48364305496216 and batch: 1450, loss is 3.683660960197449 and perplexity is 39.79180395072658
At time: 463.5302188396454 and batch: 1500, loss is 3.699876127243042 and perplexity is 40.442294351273
At time: 464.57574224472046 and batch: 1550, loss is 3.704113693237305 and perplexity is 40.614034866434565
At time: 465.62391662597656 and batch: 1600, loss is 3.7954336738586427 and perplexity is 44.497529637119065
At time: 466.6717939376831 and batch: 1650, loss is 3.731962308883667 and perplexity is 41.76097574671495
At time: 467.717346906662 and batch: 1700, loss is 3.768859763145447 and perplexity is 43.33062947653825
At time: 468.76263999938965 and batch: 1750, loss is 3.754151711463928 and perplexity is 42.69798423307452
At time: 469.80829429626465 and batch: 1800, loss is 3.710924973487854 and perplexity is 40.891612697062655
At time: 470.8541142940521 and batch: 1850, loss is 3.7322232913970947 and perplexity is 41.77187605346138
At time: 471.89967465400696 and batch: 1900, loss is 3.803850293159485 and perplexity is 44.87362892594877
At time: 472.9440743923187 and batch: 1950, loss is 3.7447878170013427 and perplexity is 42.30003091915867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503784747456395 and perplexity of 90.35846894017298
finished 11 epochs...
Completing Train Step...
At time: 476.39111161231995 and batch: 50, loss is 3.9307091665267944 and perplexity is 50.94309199776763
At time: 477.4360647201538 and batch: 100, loss is 3.9122724533081055 and perplexity is 50.01247394973345
At time: 478.4832856655121 and batch: 150, loss is 3.888152642250061 and perplexity is 48.820614026927146
At time: 479.5292854309082 and batch: 200, loss is 3.867394766807556 and perplexity is 47.817647542319506
At time: 480.57365679740906 and batch: 250, loss is 3.8707573556900026 and perplexity is 47.9787092727617
At time: 481.61805486679077 and batch: 300, loss is 3.8926955795288087 and perplexity is 49.042907564848676
At time: 482.66139960289 and batch: 350, loss is 3.899878420829773 and perplexity is 49.39644316186696
At time: 483.7358663082123 and batch: 400, loss is 3.860714249610901 and perplexity is 47.499265587767056
At time: 484.78134512901306 and batch: 450, loss is 3.886846761703491 and perplexity is 48.75690174616597
At time: 485.8249695301056 and batch: 500, loss is 3.911751585006714 and perplexity is 49.986430820487904
At time: 486.87859988212585 and batch: 550, loss is 3.883019127845764 and perplexity is 48.570634886326985
At time: 487.92339849472046 and batch: 600, loss is 3.847261176109314 and perplexity is 46.86453359766352
At time: 488.9689347743988 and batch: 650, loss is 3.879161639213562 and perplexity is 48.38363512101165
At time: 490.0146601200104 and batch: 700, loss is 3.893493819236755 and perplexity is 49.08207118996088
At time: 491.05887627601624 and batch: 750, loss is 3.8500598955154417 and perplexity is 46.99587798961857
At time: 492.10429763793945 and batch: 800, loss is 3.8290032243728636 and perplexity is 46.01664709416316
At time: 493.1492190361023 and batch: 850, loss is 3.8263889074325563 and perplexity is 45.89650211109012
At time: 494.1926727294922 and batch: 900, loss is 3.8084656953811646 and perplexity is 45.081217456367646
At time: 495.2381136417389 and batch: 950, loss is 3.9098941469192505 and perplexity is 49.89367029516119
At time: 496.2834231853485 and batch: 1000, loss is 3.8563233041763305 and perplexity is 47.29115613737891
At time: 497.330570936203 and batch: 1050, loss is 3.821856026649475 and perplexity is 45.688929544924385
At time: 498.3757619857788 and batch: 1100, loss is 3.866401629447937 and perplexity is 47.77018162408587
At time: 499.4203941822052 and batch: 1150, loss is 3.8119773769378664 and perplexity is 45.23980663062645
At time: 500.4651834964752 and batch: 1200, loss is 3.869393382072449 and perplexity is 47.91331218919655
At time: 501.510586977005 and batch: 1250, loss is 3.848337244987488 and perplexity is 46.91499020628248
At time: 502.55636978149414 and batch: 1300, loss is 3.8435368299484254 and perplexity is 46.69031847196906
At time: 503.6134376525879 and batch: 1350, loss is 3.742620377540588 and perplexity is 42.20844744961962
At time: 504.6723403930664 and batch: 1400, loss is 3.769592590332031 and perplexity is 43.3623949777203
At time: 505.7239146232605 and batch: 1450, loss is 3.675588059425354 and perplexity is 39.471861833966884
At time: 506.76959896087646 and batch: 1500, loss is 3.6939164686203 and perplexity is 40.20198886360917
At time: 507.81564593315125 and batch: 1550, loss is 3.6998892259597778 and perplexity is 40.44282409690034
At time: 508.85973167419434 and batch: 1600, loss is 3.792500796318054 and perplexity is 44.36721502364757
At time: 509.90741896629333 and batch: 1650, loss is 3.7309938955307005 and perplexity is 41.7205534360807
At time: 510.9507279396057 and batch: 1700, loss is 3.770018153190613 and perplexity is 43.380852329585124
At time: 511.99591279029846 and batch: 1750, loss is 3.7571849966049196 and perplexity is 42.82769602116417
At time: 513.041054725647 and batch: 1800, loss is 3.7152703332901003 and perplexity is 41.069688087743906
At time: 514.0855302810669 and batch: 1850, loss is 3.7375134801864625 and perplexity is 41.993442711864525
At time: 515.1291162967682 and batch: 1900, loss is 3.8104096603393556 and perplexity is 45.168938999553454
At time: 516.17258644104 and batch: 1950, loss is 3.7514953327178957 and perplexity is 42.584712727875754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503762036700581 and perplexity of 90.35641685435148
finished 12 epochs...
Completing Train Step...
At time: 519.4754090309143 and batch: 50, loss is 3.915860319137573 and perplexity is 50.19223428120565
At time: 520.5512776374817 and batch: 100, loss is 3.8953047466278075 and perplexity is 49.17103578698818
At time: 521.6022017002106 and batch: 150, loss is 3.870566644668579 and perplexity is 47.96956007656372
At time: 522.6521723270416 and batch: 200, loss is 3.8485150384902953 and perplexity is 46.923332128273216
At time: 523.7115550041199 and batch: 250, loss is 3.8516305541992186 and perplexity is 47.069750472526316
At time: 524.7638506889343 and batch: 300, loss is 3.8732642269134523 and perplexity is 48.099136603212635
At time: 525.8134925365448 and batch: 350, loss is 3.880993127822876 and perplexity is 48.47233039501209
At time: 526.8630640506744 and batch: 400, loss is 3.8418082904815676 and perplexity is 46.609682125401285
At time: 527.9126863479614 and batch: 450, loss is 3.8685545825958254 and perplexity is 47.87313937883053
At time: 528.9627058506012 and batch: 500, loss is 3.8940034532546997 and perplexity is 49.10709145815882
At time: 530.0142996311188 and batch: 550, loss is 3.8652503442764283 and perplexity is 47.71521616886975
At time: 531.0640740394592 and batch: 600, loss is 3.8304125022888185 and perplexity is 46.081543056161664
At time: 532.114506483078 and batch: 650, loss is 3.8628517055511473 and perplexity is 47.60090175787716
At time: 533.1732680797577 and batch: 700, loss is 3.877601103782654 and perplexity is 48.30818962712319
At time: 534.2298772335052 and batch: 750, loss is 3.8353288745880127 and perplexity is 46.30865490369062
At time: 535.2791192531586 and batch: 800, loss is 3.8145510387420654 and perplexity is 45.35638854984668
At time: 536.3726346492767 and batch: 850, loss is 3.8123866367340087 and perplexity is 45.25832525387112
At time: 537.421334028244 and batch: 900, loss is 3.794974002838135 and perplexity is 44.47708011264766
At time: 538.4711599349976 and batch: 950, loss is 3.896775817871094 and perplexity is 49.24342311414055
At time: 539.5228793621063 and batch: 1000, loss is 3.843858823776245 and perplexity is 46.70535488702247
At time: 540.5731785297394 and batch: 1050, loss is 3.8100359725952146 and perplexity is 45.152063073993126
At time: 541.6241166591644 and batch: 1100, loss is 3.8552262926101686 and perplexity is 47.2393056376179
At time: 542.6747827529907 and batch: 1150, loss is 3.8013309955596926 and perplexity is 44.76072118412062
At time: 543.7261765003204 and batch: 1200, loss is 3.859446816444397 and perplexity is 47.439101578161036
At time: 544.7764766216278 and batch: 1250, loss is 3.8391702556610108 and perplexity is 46.48688620215379
At time: 545.8275728225708 and batch: 1300, loss is 3.8349885368347167 and perplexity is 46.29289700177911
At time: 546.8779671192169 and batch: 1350, loss is 3.73458767414093 and perplexity is 41.87075760723469
At time: 547.9288196563721 and batch: 1400, loss is 3.7625888442993163 and perplexity is 43.05975681344177
At time: 548.9815375804901 and batch: 1450, loss is 3.6693441390991213 and perplexity is 39.22617051029319
At time: 550.0310928821564 and batch: 1500, loss is 3.688407645225525 and perplexity is 39.98113209583599
At time: 551.0811240673065 and batch: 1550, loss is 3.6950014781951905 and perplexity is 40.245632078827455
At time: 552.1326739788055 and batch: 1600, loss is 3.78818932056427 and perplexity is 44.17633862696884
At time: 553.1821513175964 and batch: 1650, loss is 3.7272721195220946 and perplexity is 41.56556747165904
At time: 554.2316601276398 and batch: 1700, loss is 3.7671990489959715 and perplexity is 43.258729406317734
At time: 555.2814626693726 and batch: 1750, loss is 3.755355272293091 and perplexity is 42.74940479205983
At time: 556.3314018249512 and batch: 1800, loss is 3.7140527868270876 and perplexity is 41.01971426317583
At time: 557.3804836273193 and batch: 1850, loss is 3.7366407108306885 and perplexity is 41.956808111026106
At time: 558.4309356212616 and batch: 1900, loss is 3.8101752758026124 and perplexity is 45.158353339316854
At time: 559.4797165393829 and batch: 1950, loss is 3.7513152074813845 and perplexity is 42.57704283721505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504816667423692 and perplexity of 90.45175977454566
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 562.799295425415 and batch: 50, loss is 3.9095262813568117 and perplexity is 49.87531950759426
At time: 563.8431627750397 and batch: 100, loss is 3.898743329048157 and perplexity is 49.34040547516841
At time: 564.887419462204 and batch: 150, loss is 3.880988149642944 and perplexity is 48.472089091630295
At time: 565.9304203987122 and batch: 200, loss is 3.8603826570510864 and perplexity is 47.48351779577112
At time: 566.9741706848145 and batch: 250, loss is 3.8661521959304808 and perplexity is 47.758267625590896
At time: 568.0161306858063 and batch: 300, loss is 3.8861462545394896 and perplexity is 48.72275914716204
At time: 569.0588874816895 and batch: 350, loss is 3.898090057373047 and perplexity is 49.30818331189228
At time: 570.1022319793701 and batch: 400, loss is 3.861159610748291 and perplexity is 47.52042462607135
At time: 571.1508438587189 and batch: 450, loss is 3.8896607255935667 and perplexity is 48.894295126415805
At time: 572.1930592060089 and batch: 500, loss is 3.9126173639297486 and perplexity is 50.0297267583808
At time: 573.2350039482117 and batch: 550, loss is 3.882004113197327 and perplexity is 48.52135999203369
At time: 574.2771718502045 and batch: 600, loss is 3.8460675716400146 and perplexity is 46.80862925138571
At time: 575.319908618927 and batch: 650, loss is 3.8740119695663453 and perplexity is 48.13511582914272
At time: 576.3646352291107 and batch: 700, loss is 3.8874975776672365 and perplexity is 48.7886438441768
At time: 577.4133276939392 and batch: 750, loss is 3.8427580881118772 and perplexity is 46.65397292135038
At time: 578.4586908817291 and batch: 800, loss is 3.8213481521606445 and perplexity is 45.665731194610345
At time: 579.5087223052979 and batch: 850, loss is 3.8192215871810915 and perplexity is 45.568723233310905
At time: 580.5517809391022 and batch: 900, loss is 3.793361954689026 and perplexity is 44.40543867820974
At time: 581.5953764915466 and batch: 950, loss is 3.898642077445984 and perplexity is 49.33540993296979
At time: 582.6409590244293 and batch: 1000, loss is 3.8458758068084715 and perplexity is 46.799653863091976
At time: 583.6898095607758 and batch: 1050, loss is 3.8109729146957396 and perplexity is 45.19438776761012
At time: 584.7439069747925 and batch: 1100, loss is 3.8500813007354737 and perplexity is 46.99688395749398
At time: 585.7867317199707 and batch: 1150, loss is 3.7984071731567384 and perplexity is 44.63003992224729
At time: 586.8321142196655 and batch: 1200, loss is 3.852877540588379 and perplexity is 47.128482422067
At time: 587.8759944438934 and batch: 1250, loss is 3.829042077064514 and perplexity is 46.018434999495746
At time: 588.9238739013672 and batch: 1300, loss is 3.8239840364456175 and perplexity is 45.786259557452
At time: 589.9687733650208 and batch: 1350, loss is 3.7193781661987306 and perplexity is 41.23874248991352
At time: 591.0139584541321 and batch: 1400, loss is 3.7476110744476316 and perplexity is 42.41962353736716
At time: 592.0585412979126 and batch: 1450, loss is 3.652081322669983 and perplexity is 38.55482763582624
At time: 593.1020650863647 and batch: 1500, loss is 3.667694578170776 and perplexity is 39.16151789092847
At time: 594.1454818248749 and batch: 1550, loss is 3.6740406703948976 and perplexity is 39.41083073955413
At time: 595.1908254623413 and batch: 1600, loss is 3.766318292617798 and perplexity is 43.22064577814254
At time: 596.2346358299255 and batch: 1650, loss is 3.704855718612671 and perplexity is 40.644182694744984
At time: 597.2788650989532 and batch: 1700, loss is 3.7409966659545897 and perplexity is 42.13996871437157
At time: 598.3225717544556 and batch: 1750, loss is 3.7286766004562377 and perplexity is 41.62398653331601
At time: 599.3656883239746 and batch: 1800, loss is 3.688221468925476 and perplexity is 39.97368924945293
At time: 600.409420967102 and batch: 1850, loss is 3.7091527080535887 and perplexity is 40.81920608614712
At time: 601.4527430534363 and batch: 1900, loss is 3.784719877243042 and perplexity is 44.02333689285941
At time: 602.4961888790131 and batch: 1950, loss is 3.72998694896698 and perplexity is 41.67856421216197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4949525345203485 and perplexity of 89.5639176899387
finished 14 epochs...
Completing Train Step...
At time: 605.7980043888092 and batch: 50, loss is 3.9081089878082276 and perplexity is 49.80468160816647
At time: 606.8687908649445 and batch: 100, loss is 3.8891718053817748 and perplexity is 48.87039556025374
At time: 607.9149956703186 and batch: 150, loss is 3.8685469579696656 and perplexity is 47.87277436543121
At time: 608.9599974155426 and batch: 200, loss is 3.8459732913970948 and perplexity is 46.80421633047804
At time: 610.0044937133789 and batch: 250, loss is 3.848963050842285 and perplexity is 46.94435907047641
At time: 611.0504233837128 and batch: 300, loss is 3.86820707321167 and perplexity is 47.8565059039591
At time: 612.0952644348145 and batch: 350, loss is 3.8799585103988647 and perplexity is 48.42220601165441
At time: 613.1416668891907 and batch: 400, loss is 3.8417600631713866 and perplexity is 46.60743432000723
At time: 614.1877479553223 and batch: 450, loss is 3.8687002420425416 and perplexity is 47.88011306170408
At time: 615.2326476573944 and batch: 500, loss is 3.893945813179016 and perplexity is 49.10426100326518
At time: 616.3229038715363 and batch: 550, loss is 3.864782662391663 and perplexity is 47.692905844113916
At time: 617.3680765628815 and batch: 600, loss is 3.82988422870636 and perplexity is 46.05720582325077
At time: 618.4142498970032 and batch: 650, loss is 3.8588411903381346 and perplexity is 47.41037991795916
At time: 619.4591720104218 and batch: 700, loss is 3.873879747390747 and perplexity is 48.12875172015256
At time: 620.5055210590363 and batch: 750, loss is 3.830247330665588 and perplexity is 46.07393232145013
At time: 621.5508289337158 and batch: 800, loss is 3.808624572753906 and perplexity is 45.088380410757715
At time: 622.5972957611084 and batch: 850, loss is 3.8065490245819094 and perplexity is 44.99489435618343
At time: 623.6431822776794 and batch: 900, loss is 3.7822557401657106 and perplexity is 43.91499090066495
At time: 624.6885335445404 and batch: 950, loss is 3.8880260515213014 and perplexity is 48.81443418098284
At time: 625.7331812381744 and batch: 1000, loss is 3.835125823020935 and perplexity is 46.299252813330064
At time: 626.7773036956787 and batch: 1050, loss is 3.801161217689514 and perplexity is 44.75312244927708
At time: 627.8213121891022 and batch: 1100, loss is 3.84204909324646 and perplexity is 46.62090721719017
At time: 628.8654191493988 and batch: 1150, loss is 3.7911695575714113 and perplexity is 44.30819096420176
At time: 629.9084122180939 and batch: 1200, loss is 3.8462326669692994 and perplexity is 46.816357775399396
At time: 630.9686000347137 and batch: 1250, loss is 3.823884992599487 and perplexity is 45.78172493477245
At time: 632.0144963264465 and batch: 1300, loss is 3.8195534896850587 and perplexity is 45.58385011684103
At time: 633.0594508647919 and batch: 1350, loss is 3.715966329574585 and perplexity is 41.098282387666885
At time: 634.1036293506622 and batch: 1400, loss is 3.7455818367004396 and perplexity is 42.33363131490362
At time: 635.148384809494 and batch: 1450, loss is 3.6513572406768797 and perplexity is 38.52692088399546
At time: 636.1938428878784 and batch: 1500, loss is 3.668316478729248 and perplexity is 39.18588003540589
At time: 637.2373013496399 and batch: 1550, loss is 3.676426205635071 and perplexity is 39.50495889350348
At time: 638.2828454971313 and batch: 1600, loss is 3.7697541236877443 and perplexity is 43.369400016651305
At time: 639.3284132480621 and batch: 1650, loss is 3.708895411491394 and perplexity is 40.80870479578052
At time: 640.3733577728271 and batch: 1700, loss is 3.7458088874816893 and perplexity is 42.34324429024229
At time: 641.4172186851501 and batch: 1750, loss is 3.7346643877029417 and perplexity is 41.87396978540211
At time: 642.4640009403229 and batch: 1800, loss is 3.6944034481048584 and perplexity is 40.22157117512918
At time: 643.5104403495789 and batch: 1850, loss is 3.715671043395996 and perplexity is 41.08614842449805
At time: 644.5556185245514 and batch: 1900, loss is 3.791148581504822 and perplexity is 44.30726156238527
At time: 645.5999383926392 and batch: 1950, loss is 3.7357937049865724 and perplexity is 41.921285495410835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494309536246366 and perplexity of 89.50634675644193
finished 15 epochs...
Completing Train Step...
At time: 648.9295451641083 and batch: 50, loss is 3.9048527908325195 and perplexity is 49.64277150319353
At time: 649.9812822341919 and batch: 100, loss is 3.8839210176467898 and perplexity is 48.614460006304036
At time: 651.0345408916473 and batch: 150, loss is 3.8624265384674072 and perplexity is 47.580667723020966
At time: 652.0855038166046 and batch: 200, loss is 3.839222288131714 and perplexity is 46.489305092628065
At time: 653.1375470161438 and batch: 250, loss is 3.841531400680542 and perplexity is 46.59677816636148
At time: 654.1887440681458 and batch: 300, loss is 3.86037588596344 and perplexity is 47.483196281798854
At time: 655.2484784126282 and batch: 350, loss is 3.8720522022247312 and perplexity is 48.04087457678286
At time: 656.3006298542023 and batch: 400, loss is 3.833552317619324 and perplexity is 46.22645797549251
At time: 657.3530404567719 and batch: 450, loss is 3.860610747337341 and perplexity is 47.4943495602007
At time: 658.4048919677734 and batch: 500, loss is 3.886177144050598 and perplexity is 48.72426419261689
At time: 659.4554305076599 and batch: 550, loss is 3.8570668506622314 and perplexity is 47.32633238630656
At time: 660.5127396583557 and batch: 600, loss is 3.8225805377960205 and perplexity is 45.72204367798416
At time: 661.5756907463074 and batch: 650, loss is 3.85192289352417 and perplexity is 47.083512823145206
At time: 662.6272563934326 and batch: 700, loss is 3.8674205636978147 and perplexity is 47.81888110483655
At time: 663.6780784130096 and batch: 750, loss is 3.8243439197540283 and perplexity is 45.80274023340351
At time: 664.7295613288879 and batch: 800, loss is 3.8026959180831907 and perplexity is 44.82185781452324
At time: 665.7807738780975 and batch: 850, loss is 3.800728759765625 and perplexity is 44.733772791113175
At time: 666.8317730426788 and batch: 900, loss is 3.777087516784668 and perplexity is 43.688613905241475
At time: 667.8832335472107 and batch: 950, loss is 3.8831831359863282 and perplexity is 48.57860151911916
At time: 668.9798283576965 and batch: 1000, loss is 3.8303236198425292 and perplexity is 46.07744739790481
At time: 670.0320675373077 and batch: 1050, loss is 3.79673855304718 and perplexity is 44.555631437154496
At time: 671.0837233066559 and batch: 1100, loss is 3.8382588815689087 and perplexity is 46.4445385586504
At time: 672.1350266933441 and batch: 1150, loss is 3.787718262672424 and perplexity is 44.15553391452246
At time: 673.1862273216248 and batch: 1200, loss is 3.8430341625213624 and perplexity is 46.66685466745319
At time: 674.2371430397034 and batch: 1250, loss is 3.8212613105773925 and perplexity is 45.66176568240121
At time: 675.286639213562 and batch: 1300, loss is 3.817292308807373 and perplexity is 45.4808932325622
At time: 676.3375535011292 and batch: 1350, loss is 3.7141991567611696 and perplexity is 41.02571875547645
At time: 677.3893427848816 and batch: 1400, loss is 3.7444668006896973 and perplexity is 42.28645409855754
At time: 678.4408731460571 and batch: 1450, loss is 3.6507203435897826 and perplexity is 38.502391012640615
At time: 679.492879152298 and batch: 1500, loss is 3.6681774950027464 and perplexity is 39.18043421422134
At time: 680.5435864925385 and batch: 1550, loss is 3.6770084857940675 and perplexity is 39.52796854563097
At time: 681.5949802398682 and batch: 1600, loss is 3.7706872415542603 and perplexity is 43.40988766560348
At time: 682.6453535556793 and batch: 1650, loss is 3.71011999130249 and perplexity is 40.85870892256365
At time: 683.7002635002136 and batch: 1700, loss is 3.747197976112366 and perplexity is 42.40210368046228
At time: 684.7511842250824 and batch: 1750, loss is 3.736519479751587 and perplexity is 41.95172195020975
At time: 685.8027009963989 and batch: 1800, loss is 3.6963007402420045 and perplexity is 40.297955684814674
At time: 686.8548581600189 and batch: 1850, loss is 3.717699899673462 and perplexity is 41.16959093245145
At time: 687.9051868915558 and batch: 1900, loss is 3.7931099843978884 and perplexity is 44.39425123640857
At time: 688.9568679332733 and batch: 1950, loss is 3.7375216579437254 and perplexity is 41.99378612544983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494377100744913 and perplexity of 89.51239441217842
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 692.2411592006683 and batch: 50, loss is 3.9032264518737794 and perplexity is 49.56210114633109
At time: 693.3137540817261 and batch: 100, loss is 3.8846366024017334 and perplexity is 48.64926022252147
At time: 694.3585207462311 and batch: 150, loss is 3.8654031229019163 and perplexity is 47.72250659090704
At time: 695.4291386604309 and batch: 200, loss is 3.8426399564743043 and perplexity is 46.64846193664713
At time: 696.4732248783112 and batch: 250, loss is 3.8452412033081056 and perplexity is 46.76996406055724
At time: 697.5175406932831 and batch: 300, loss is 3.863065142631531 and perplexity is 47.61106263968788
At time: 698.5619223117828 and batch: 350, loss is 3.875232286453247 and perplexity is 48.19389177919022
At time: 699.6078662872314 and batch: 400, loss is 3.839055643081665 and perplexity is 46.48155852553562
At time: 700.653030872345 and batch: 450, loss is 3.867128767967224 and perplexity is 47.804929795053845
At time: 701.6982958316803 and batch: 500, loss is 3.8935584735870363 and perplexity is 49.085244661972396
At time: 702.7480063438416 and batch: 550, loss is 3.863225288391113 and perplexity is 47.6186879600439
At time: 703.7916753292084 and batch: 600, loss is 3.8288613462448122 and perplexity is 46.01011880153616
At time: 704.8377270698547 and batch: 650, loss is 3.8570988321304323 and perplexity is 47.327845976104115
At time: 705.8813107013702 and batch: 700, loss is 3.8718334341049196 and perplexity is 48.03036591449965
At time: 706.925728559494 and batch: 750, loss is 3.8281532192230223 and perplexity is 45.97754932616081
At time: 707.9714388847351 and batch: 800, loss is 3.8059916591644285 and perplexity is 44.96982274577944
At time: 709.0167605876923 and batch: 850, loss is 3.804454207420349 and perplexity is 44.90073693502663
At time: 710.0604178905487 and batch: 900, loss is 3.776940622329712 and perplexity is 43.682196761447045
At time: 711.1046514511108 and batch: 950, loss is 3.8832789564132693 and perplexity is 48.58325656447758
At time: 712.1493799686432 and batch: 1000, loss is 3.8296487522125244 and perplexity is 46.046361710724554
At time: 713.1950314044952 and batch: 1050, loss is 3.7968275785446166 and perplexity is 44.55959820097573
At time: 714.2404811382294 and batch: 1100, loss is 3.8345802450180053 and perplexity is 46.27399984880039
At time: 715.2863941192627 and batch: 1150, loss is 3.7851317310333252 and perplexity is 44.041471805229506
At time: 716.3314273357391 and batch: 1200, loss is 3.839731330871582 and perplexity is 46.51297616014837
At time: 717.3769638538361 and batch: 1250, loss is 3.816951398849487 and perplexity is 45.465390985750965
At time: 718.4222350120544 and batch: 1300, loss is 3.8117437744140625 and perplexity is 45.22923973189629
At time: 719.4667546749115 and batch: 1350, loss is 3.7072670745849607 and perplexity is 40.74230854805882
At time: 720.5098633766174 and batch: 1400, loss is 3.7372951984405516 and perplexity is 41.9842773102289
At time: 721.5535161495209 and batch: 1450, loss is 3.6428585147857664 and perplexity is 38.2008785785209
At time: 722.5973610877991 and batch: 1500, loss is 3.6589830780029295 and perplexity is 38.821844003968366
At time: 723.6419644355774 and batch: 1550, loss is 3.6670943784713743 and perplexity is 39.13802021201752
At time: 724.686418056488 and batch: 1600, loss is 3.759002242088318 and perplexity is 42.905595217866946
At time: 725.731342792511 and batch: 1650, loss is 3.699400577545166 and perplexity is 40.42306660265022
At time: 726.7764518260956 and batch: 1700, loss is 3.7351757955551146 and perplexity is 41.89538993910256
At time: 727.8215036392212 and batch: 1750, loss is 3.723474326133728 and perplexity is 41.40800941018823
At time: 728.867684841156 and batch: 1800, loss is 3.683924551010132 and perplexity is 39.80229408715914
At time: 729.9131169319153 and batch: 1850, loss is 3.7061074352264405 and perplexity is 40.69508954730692
At time: 730.9578692913055 and batch: 1900, loss is 3.7825946235656738 and perplexity is 43.92987548401737
At time: 732.0041644573212 and batch: 1950, loss is 3.7301113557815553 and perplexity is 41.683749632115784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493025526889535 and perplexity of 89.39149352180456
finished 17 epochs...
Completing Train Step...
At time: 735.3279519081116 and batch: 50, loss is 3.904316630363464 and perplexity is 49.61616214561944
At time: 736.3738238811493 and batch: 100, loss is 3.883527512550354 and perplexity is 48.595333731921116
At time: 737.4252259731293 and batch: 150, loss is 3.862949905395508 and perplexity is 47.60557638854145
At time: 738.4717884063721 and batch: 200, loss is 3.839856171607971 and perplexity is 46.51878323681617
At time: 739.5168254375458 and batch: 250, loss is 3.8408769750595093 and perplexity is 46.56629401676407
At time: 740.5670101642609 and batch: 300, loss is 3.858370261192322 and perplexity is 47.388058244617554
At time: 741.6121726036072 and batch: 350, loss is 3.8700633573532106 and perplexity is 47.94542367973403
At time: 742.65740275383 and batch: 400, loss is 3.8333695554733276 and perplexity is 46.218010300812196
At time: 743.7027335166931 and batch: 450, loss is 3.8611050415039063 and perplexity is 47.51783154315861
At time: 744.7649028301239 and batch: 500, loss is 3.8875057697296143 and perplexity is 48.7890435254276
At time: 745.8139615058899 and batch: 550, loss is 3.8578790044784546 and perplexity is 47.3647842600664
At time: 746.8596847057343 and batch: 600, loss is 3.8234183406829834 and perplexity is 45.76036578912152
At time: 747.9039790630341 and batch: 650, loss is 3.8522938776016233 and perplexity is 47.10098329714664
At time: 748.9761414527893 and batch: 700, loss is 3.8675997734069822 and perplexity is 47.82745148053639
At time: 750.0189347267151 and batch: 750, loss is 3.824122443199158 and perplexity is 45.79259712356496
At time: 751.0627045631409 and batch: 800, loss is 3.802261004447937 and perplexity is 44.80236841581211
At time: 752.1073405742645 and batch: 850, loss is 3.8005165243148804 and perplexity is 44.724279706101576
At time: 753.1517224311829 and batch: 900, loss is 3.773838996887207 and perplexity is 43.54692084464697
At time: 754.1957430839539 and batch: 950, loss is 3.8805231857299805 and perplexity is 48.44955655823012
At time: 755.2408266067505 and batch: 1000, loss is 3.827307744026184 and perplexity is 45.93869287699078
At time: 756.2853055000305 and batch: 1050, loss is 3.794532537460327 and perplexity is 44.45744935514066
At time: 757.3306202888489 and batch: 1100, loss is 3.832953066825867 and perplexity is 46.19876503220982
At time: 758.3758728504181 and batch: 1150, loss is 3.783770275115967 and perplexity is 43.981552081118
At time: 759.4206292629242 and batch: 1200, loss is 3.8386427211761474 and perplexity is 46.46236923392991
At time: 760.4661786556244 and batch: 1250, loss is 3.81604612827301 and perplexity is 45.424251129203924
At time: 761.5103976726532 and batch: 1300, loss is 3.811233811378479 and perplexity is 45.20618037171589
At time: 762.5560631752014 and batch: 1350, loss is 3.7070262479782103 and perplexity is 40.73249789752027
At time: 763.6089737415314 and batch: 1400, loss is 3.7372629737854 and perplexity is 41.98292440316939
At time: 764.6549491882324 and batch: 1450, loss is 3.643247752189636 and perplexity is 38.215750683526345
At time: 765.7008864879608 and batch: 1500, loss is 3.6596933937072755 and perplexity is 38.849429565504984
At time: 766.7462105751038 and batch: 1550, loss is 3.668431453704834 and perplexity is 39.19038569002007
At time: 767.7927305698395 and batch: 1600, loss is 3.760791344642639 and perplexity is 42.98242643683694
At time: 768.8371334075928 and batch: 1650, loss is 3.7013953495025635 and perplexity is 40.503781879862345
At time: 769.8815987110138 and batch: 1700, loss is 3.7373052549362185 and perplexity is 41.98469952705475
At time: 770.9279811382294 and batch: 1750, loss is 3.7258407878875732 and perplexity is 41.50611591762494
At time: 771.9736838340759 and batch: 1800, loss is 3.686504635810852 and perplexity is 39.90511997387968
At time: 773.0195279121399 and batch: 1850, loss is 3.708675479888916 and perplexity is 40.799730658824075
At time: 774.0665640830994 and batch: 1900, loss is 3.78501106262207 and perplexity is 44.0361577114255
At time: 775.1134815216064 and batch: 1950, loss is 3.732439079284668 and perplexity is 41.780890890966326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492732558139535 and perplexity of 89.36530844357894
finished 18 epochs...
Completing Train Step...
At time: 778.4117479324341 and batch: 50, loss is 3.904130792617798 and perplexity is 49.60694244660826
At time: 779.4836926460266 and batch: 100, loss is 3.882708649635315 and perplexity is 48.55555710330976
At time: 780.5307464599609 and batch: 150, loss is 3.861564874649048 and perplexity is 47.539686841597614
At time: 781.5780198574066 and batch: 200, loss is 3.8379440927505493 and perplexity is 46.42992063813794
At time: 782.6237995624542 and batch: 250, loss is 3.838224244117737 and perplexity is 46.44292986607455
At time: 783.6688830852509 and batch: 300, loss is 3.855315589904785 and perplexity is 47.24352416815978
At time: 784.7154428958893 and batch: 350, loss is 3.866833891868591 and perplexity is 47.790835342021246
At time: 785.7608726024628 and batch: 400, loss is 3.8300105047225954 and perplexity is 46.06302211094216
At time: 786.806120634079 and batch: 450, loss is 3.8578253555297852 and perplexity is 47.36224325734857
At time: 787.8526337146759 and batch: 500, loss is 3.8844476985931395 and perplexity is 48.6400710599414
At time: 788.8975534439087 and batch: 550, loss is 3.854930033683777 and perplexity is 47.22531264452312
At time: 789.9424903392792 and batch: 600, loss is 3.820528059005737 and perplexity is 45.62829639315409
At time: 790.9873015880585 and batch: 650, loss is 3.849722204208374 and perplexity is 46.980010569449185
At time: 792.031103849411 and batch: 700, loss is 3.8651552772521973 and perplexity is 47.71068024087004
At time: 793.076085805893 and batch: 750, loss is 3.8218275260925294 and perplexity is 45.68762740354207
At time: 794.119236946106 and batch: 800, loss is 3.8000373029708863 and perplexity is 44.70285201138606
At time: 795.1648871898651 and batch: 850, loss is 3.7982625436782835 and perplexity is 44.623585569606
At time: 796.2082016468048 and batch: 900, loss is 3.771976351737976 and perplexity is 43.46588387875691
At time: 797.2527039051056 and batch: 950, loss is 3.8788273906707764 and perplexity is 48.36746566393706
At time: 798.2957215309143 and batch: 1000, loss is 3.825723099708557 and perplexity is 45.86595403618061
At time: 799.3409996032715 and batch: 1050, loss is 3.7930670976638794 and perplexity is 44.39234735279023
At time: 800.3857769966125 and batch: 1100, loss is 3.831837739944458 and perplexity is 46.147267031572156
At time: 801.4572329521179 and batch: 1150, loss is 3.782774119377136 and perplexity is 43.93776142038991
At time: 802.5013263225555 and batch: 1200, loss is 3.8378319787979125 and perplexity is 46.42471548800502
At time: 803.5469336509705 and batch: 1250, loss is 3.8154500770568847 and perplexity is 45.39718401657084
At time: 804.5909543037415 and batch: 1300, loss is 3.810911922454834 and perplexity is 45.191631344684865
At time: 805.6359541416168 and batch: 1350, loss is 3.706873164176941 and perplexity is 40.726262889158484
At time: 806.6801104545593 and batch: 1400, loss is 3.737260313034058 and perplexity is 41.98281269719554
At time: 807.7257590293884 and batch: 1450, loss is 3.64355628490448 and perplexity is 38.22754331194681
At time: 808.7706570625305 and batch: 1500, loss is 3.6602054738998415 and perplexity is 38.8693286834152
At time: 809.8163132667542 and batch: 1550, loss is 3.669340353012085 and perplexity is 39.22602199687868
At time: 810.8692555427551 and batch: 1600, loss is 3.7618942213058473 and perplexity is 43.02985690205118
At time: 811.9219794273376 and batch: 1650, loss is 3.7026080751419066 and perplexity is 40.552931651208624
At time: 812.9819896221161 and batch: 1700, loss is 3.738590593338013 and perplexity is 42.038698769860574
At time: 814.029269695282 and batch: 1750, loss is 3.7273065853118896 and perplexity is 41.56700008645818
At time: 815.0781092643738 and batch: 1800, loss is 3.687983889579773 and perplexity is 39.96419345456274
At time: 816.1232516765594 and batch: 1850, loss is 3.7101098346710204 and perplexity is 40.858293937822225
At time: 817.1676516532898 and batch: 1900, loss is 3.7863116455078125 and perplexity is 44.09346764457957
At time: 818.2119562625885 and batch: 1950, loss is 3.7336630535125734 and perplexity is 41.83206093365433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492615313862645 and perplexity of 89.35483148680505
finished 19 epochs...
Completing Train Step...
At time: 821.5293622016907 and batch: 50, loss is 3.903369903564453 and perplexity is 49.56921142351232
At time: 822.5790519714355 and batch: 100, loss is 3.8815768432617186 and perplexity is 48.50063270206352
At time: 823.6343193054199 and batch: 150, loss is 3.860144910812378 and perplexity is 47.47223010987013
At time: 824.6843667030334 and batch: 200, loss is 3.8362700223922728 and perplexity is 46.352258708165344
At time: 825.7352945804596 and batch: 250, loss is 3.8361211824417114 and perplexity is 46.34536015367381
At time: 826.7884249687195 and batch: 300, loss is 3.852965722084045 and perplexity is 47.132638465375834
At time: 827.8428289890289 and batch: 350, loss is 3.8644337272644043 and perplexity is 47.67626701704832
At time: 828.920597076416 and batch: 400, loss is 3.827576518058777 and perplexity is 45.95104166416969
At time: 829.9712586402893 and batch: 450, loss is 3.8554283952713013 and perplexity is 47.24885379181851
At time: 831.0256700515747 and batch: 500, loss is 3.8821926879882813 and perplexity is 48.530510760125985
At time: 832.0756421089172 and batch: 550, loss is 3.8527241134643555 and perplexity is 47.1212521892205
At time: 833.125871181488 and batch: 600, loss is 3.8184166431427 and perplexity is 45.532057720030046
At time: 834.176022529602 and batch: 650, loss is 3.8477933692932127 and perplexity is 46.88948122089949
At time: 835.2251029014587 and batch: 700, loss is 3.863304786682129 and perplexity is 47.62247371483567
At time: 836.2739779949188 and batch: 750, loss is 3.820122218132019 and perplexity is 45.60978232261703
At time: 837.3225736618042 and batch: 800, loss is 3.7983551359176637 and perplexity is 44.62771755861517
At time: 838.372663974762 and batch: 850, loss is 3.796576919555664 and perplexity is 44.548430336863774
At time: 839.4231216907501 and batch: 900, loss is 3.7705514192581178 and perplexity is 43.40399203537353
At time: 840.4733428955078 and batch: 950, loss is 3.877519574165344 and perplexity is 48.30425123945977
At time: 841.5233995914459 and batch: 1000, loss is 3.824474492073059 and perplexity is 45.808721193879194
At time: 842.5737116336823 and batch: 1050, loss is 3.791918783187866 and perplexity is 44.34140023495562
At time: 843.6257674694061 and batch: 1100, loss is 3.8309264850616453 and perplexity is 46.105234263352436
At time: 844.6766209602356 and batch: 1150, loss is 3.7819445276260377 and perplexity is 43.901326131251125
At time: 845.728132724762 and batch: 1200, loss is 3.8371317863464354 and perplexity is 46.392220630312984
At time: 846.7782804965973 and batch: 1250, loss is 3.8149268674850463 and perplexity is 45.373437987975294
At time: 847.8297579288483 and batch: 1300, loss is 3.8105726194381715 and perplexity is 45.17630028892554
At time: 848.8806519508362 and batch: 1350, loss is 3.7066673707962035 and perplexity is 40.71788255617183
At time: 849.9318339824677 and batch: 1400, loss is 3.7371957111358642 and perplexity is 41.98010061540755
At time: 850.9827830791473 and batch: 1450, loss is 3.643712215423584 and perplexity is 38.233504617382174
At time: 852.0337090492249 and batch: 1500, loss is 3.660511360168457 and perplexity is 38.88122009594694
At time: 853.08558177948 and batch: 1550, loss is 3.6699283838272097 and perplexity is 39.249094889688735
At time: 854.136880159378 and batch: 1600, loss is 3.762608699798584 and perplexity is 43.06061179489967
At time: 855.1884398460388 and batch: 1650, loss is 3.703386640548706 and perplexity is 40.58451705499244
At time: 856.2395639419556 and batch: 1700, loss is 3.739412155151367 and perplexity is 42.07325035063925
At time: 857.294668674469 and batch: 1750, loss is 3.728277158737183 and perplexity is 41.60736349676939
At time: 858.351166009903 and batch: 1800, loss is 3.6889387273788454 and perplexity is 40.00237100086415
At time: 859.4030282497406 and batch: 1850, loss is 3.7110344886779787 and perplexity is 40.896091195028966
At time: 860.4547493457794 and batch: 1900, loss is 3.787127585411072 and perplexity is 44.12945994608452
At time: 861.5063407421112 and batch: 1950, loss is 3.7344077968597413 and perplexity is 41.863226686536066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492574718386628 and perplexity of 89.35120415851347
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
3560.07400226593


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.41794011582878}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6360119204925818, 'rnn_dropout': 0.965771331349581, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.35120415851347}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.3686534261327181, 'rnn_dropout': 0.8565517612572858, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4937493801116943 and batch: 50, loss is 7.2542123603820805 and perplexity is 1414.0488035329413
At time: 2.541508674621582 and batch: 100, loss is 6.433226251602173 and perplexity is 622.1780162820357
At time: 3.5881192684173584 and batch: 150, loss is 6.16346230506897 and perplexity is 475.0700681587421
At time: 4.635310173034668 and batch: 200, loss is 6.0511075878143314 and perplexity is 424.58303270530274
At time: 5.681814670562744 and batch: 250, loss is 5.975564670562744 and perplexity is 393.69034368618134
At time: 6.728774070739746 and batch: 300, loss is 5.916309747695923 and perplexity is 371.03995331897875
At time: 7.776890993118286 and batch: 350, loss is 5.85972692489624 and perplexity is 350.62838306345566
At time: 8.825470447540283 and batch: 400, loss is 5.8095320701599125 and perplexity is 333.4630518490887
At time: 9.873282670974731 and batch: 450, loss is 5.730880966186524 and perplexity is 308.24069843213516
At time: 10.921034574508667 and batch: 500, loss is 5.706993560791016 and perplexity is 300.96487415838646
At time: 11.994834184646606 and batch: 550, loss is 5.658651237487793 and perplexity is 286.76160829886516
At time: 13.042365789413452 and batch: 600, loss is 5.686246023178101 and perplexity is 294.78492515743403
At time: 14.091160297393799 and batch: 650, loss is 5.769523544311523 and perplexity is 320.3850469981267
At time: 15.139219999313354 and batch: 700, loss is 5.676240367889404 and perplexity is 291.8501156425514
At time: 16.18553876876831 and batch: 750, loss is 5.626274337768555 and perplexity is 277.6258482994651
At time: 17.23350429534912 and batch: 800, loss is 5.6278074359893795 and perplexity is 278.051802424874
At time: 18.280694246292114 and batch: 850, loss is 5.642999639511109 and perplexity is 282.3082727114572
At time: 19.32907509803772 and batch: 900, loss is 5.658994607925415 and perplexity is 286.8600906647988
At time: 20.376692295074463 and batch: 950, loss is 5.683437776565552 and perplexity is 293.9582576762824
At time: 21.424809217453003 and batch: 1000, loss is 5.655947856903076 and perplexity is 285.9874294560662
At time: 22.47247838973999 and batch: 1050, loss is 5.561588010787964 and perplexity is 260.23576557126523
At time: 23.521353006362915 and batch: 1100, loss is 5.641590662002564 and perplexity is 281.9107867948469
At time: 24.569592714309692 and batch: 1150, loss is 5.554139518737793 and perplexity is 258.3046025946843
At time: 25.617045879364014 and batch: 1200, loss is 5.633520755767822 and perplexity is 279.6449480286214
At time: 26.66493797302246 and batch: 1250, loss is 5.5681369018554685 and perplexity is 261.9456139462449
At time: 27.713218927383423 and batch: 1300, loss is 5.588588409423828 and perplexity is 267.3579532538727
At time: 28.761279582977295 and batch: 1350, loss is 5.551829061508179 and perplexity is 257.7084897699508
At time: 29.809001684188843 and batch: 1400, loss is 5.564715375900269 and perplexity is 261.05089175973296
At time: 30.857104778289795 and batch: 1450, loss is 5.5197881317138675 and perplexity is 249.58215304464022
At time: 31.90536117553711 and batch: 1500, loss is 5.505770931243896 and perplexity is 246.10811499750926
At time: 32.95285701751709 and batch: 1550, loss is 5.5010659122467045 and perplexity is 244.95289144657698
At time: 34.00322890281677 and batch: 1600, loss is 5.526586589813232 and perplexity is 251.28470767007425
At time: 35.0510790348053 and batch: 1650, loss is 5.505914258956909 and perplexity is 246.14339163878552
At time: 36.102479696273804 and batch: 1700, loss is 5.523695764541626 and perplexity is 250.5593364526494
At time: 37.15037512779236 and batch: 1750, loss is 5.532564029693604 and perplexity is 252.79124503560826
At time: 38.19894742965698 and batch: 1800, loss is 5.529797306060791 and perplexity is 252.09280816023517
At time: 39.24756598472595 and batch: 1850, loss is 5.491452236175537 and perplexity is 242.60927712024724
At time: 40.29572510719299 and batch: 1900, loss is 5.507590827941894 and perplexity is 246.55641414868472
At time: 41.34440875053406 and batch: 1950, loss is 5.440620222091675 and perplexity is 230.58515312556742
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.016518100472384 and perplexity of 150.88502160944535
finished 1 epochs...
Completing Train Step...
At time: 44.64089274406433 and batch: 50, loss is 5.246304864883423 and perplexity is 189.86339974519478
At time: 45.710450649261475 and batch: 100, loss is 5.180950326919556 and perplexity is 177.8517480117777
At time: 46.75340294837952 and batch: 150, loss is 5.110992794036865 and perplexity is 165.83491308682372
At time: 47.82237219810486 and batch: 200, loss is 5.082288656234741 and perplexity is 161.14243385852063
At time: 48.863051652908325 and batch: 250, loss is 5.095736751556396 and perplexity is 163.32412961556074
At time: 49.90495204925537 and batch: 300, loss is 5.1099940776824955 and perplexity is 165.66937372419238
At time: 50.947635889053345 and batch: 350, loss is 5.090667219161987 and perplexity is 162.49824783567814
At time: 51.99166512489319 and batch: 400, loss is 5.060094585418701 and perplexity is 157.605422793293
At time: 53.03598475456238 and batch: 450, loss is 5.029964704513549 and perplexity is 152.92761494579594
At time: 54.082338094711304 and batch: 500, loss is 5.026575746536255 and perplexity is 152.41022688356222
At time: 55.1324999332428 and batch: 550, loss is 4.989931840896606 and perplexity is 146.92640878211424
At time: 56.177303075790405 and batch: 600, loss is 4.986180181503296 and perplexity is 146.3762236394296
At time: 57.22099232673645 and batch: 650, loss is 5.049354238510132 and perplexity is 155.92174371157427
At time: 58.26530694961548 and batch: 700, loss is 5.029032983779907 and perplexity is 152.78519547409473
At time: 59.31659936904907 and batch: 750, loss is 4.98455623626709 and perplexity is 146.1387095754705
At time: 60.36000061035156 and batch: 800, loss is 4.964131155014038 and perplexity is 143.18409143354233
At time: 61.404361963272095 and batch: 850, loss is 4.971497068405151 and perplexity is 144.24266695159054
At time: 62.44782280921936 and batch: 900, loss is 4.983229665756226 and perplexity is 145.94497480268126
At time: 63.490415811538696 and batch: 950, loss is 5.0430198001861575 and perplexity is 154.93718863647942
At time: 64.53536462783813 and batch: 1000, loss is 5.019554033279419 and perplexity is 151.34379444602095
At time: 65.58781361579895 and batch: 1050, loss is 4.942578992843628 and perplexity is 140.131181253445
At time: 66.6358630657196 and batch: 1100, loss is 5.019139957427979 and perplexity is 151.28113960829842
At time: 67.68431305885315 and batch: 1150, loss is 4.937830991744995 and perplexity is 139.4674152786574
At time: 68.73285508155823 and batch: 1200, loss is 5.0068911266326905 and perplexity is 149.4394249787248
At time: 69.78101658821106 and batch: 1250, loss is 4.970622262954712 and perplexity is 144.11653785760853
At time: 70.82687854766846 and batch: 1300, loss is 4.9807142162322995 and perplexity is 145.57831893079774
At time: 71.87466406822205 and batch: 1350, loss is 4.900441856384277 and perplexity is 134.3491295925346
At time: 72.93570804595947 and batch: 1400, loss is 4.919905757904052 and perplexity is 136.9897023814322
At time: 73.99272847175598 and batch: 1450, loss is 4.855076951980591 and perplexity is 128.39057074329844
At time: 75.0478241443634 and batch: 1500, loss is 4.849261636734009 and perplexity is 127.64610584678745
At time: 76.10360765457153 and batch: 1550, loss is 4.845917510986328 and perplexity is 127.21995416718016
At time: 77.15860986709595 and batch: 1600, loss is 4.910798606872558 and perplexity is 135.74778024209192
At time: 78.21702814102173 and batch: 1650, loss is 4.8723225593566895 and perplexity is 130.6239467275348
At time: 79.27569627761841 and batch: 1700, loss is 4.8976864528656 and perplexity is 133.9794530660148
At time: 80.32950520515442 and batch: 1750, loss is 4.907240390777588 and perplexity is 135.26561863189553
At time: 81.38610196113586 and batch: 1800, loss is 4.869031238555908 and perplexity is 130.19472815007592
At time: 82.4400200843811 and batch: 1850, loss is 4.8795567226409915 and perplexity is 131.57232792323933
At time: 83.49511170387268 and batch: 1900, loss is 4.936217336654663 and perplexity is 139.24254445482708
At time: 84.54954767227173 and batch: 1950, loss is 4.858730516433716 and perplexity is 128.86051192613093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7392217591751455 and perplexity of 114.34517895770314
finished 2 epochs...
Completing Train Step...
At time: 88.00274729728699 and batch: 50, loss is 4.7874291801452635 and perplexity is 119.99249271842622
At time: 89.05893993377686 and batch: 100, loss is 4.739951944351196 and perplexity is 114.4287026024835
At time: 90.11683130264282 and batch: 150, loss is 4.691336050033569 and perplexity is 108.99871029831237
At time: 91.17361998558044 and batch: 200, loss is 4.679003562927246 and perplexity is 107.6627399597344
At time: 92.22882318496704 and batch: 250, loss is 4.688621215820312 and perplexity is 108.70319818509302
At time: 93.28747653961182 and batch: 300, loss is 4.717729835510254 and perplexity is 111.91390110290769
At time: 94.34703159332275 and batch: 350, loss is 4.718176927566528 and perplexity is 111.96394810605254
At time: 95.40562629699707 and batch: 400, loss is 4.679094018936158 and perplexity is 107.6724791419768
At time: 96.46139621734619 and batch: 450, loss is 4.676661138534546 and perplexity is 107.41084327112046
At time: 97.52099704742432 and batch: 500, loss is 4.686726751327515 and perplexity is 108.49745878040949
At time: 98.57842183113098 and batch: 550, loss is 4.650461483001709 and perplexity is 104.63326090845764
At time: 99.63600182533264 and batch: 600, loss is 4.641554307937622 and perplexity is 103.70541252445788
At time: 100.73300695419312 and batch: 650, loss is 4.704247465133667 and perplexity is 110.41516241560345
At time: 101.79198884963989 and batch: 700, loss is 4.709377918243408 and perplexity is 110.9830978663363
At time: 102.85022377967834 and batch: 750, loss is 4.668956432342529 and perplexity is 106.58645419782407
At time: 103.91008424758911 and batch: 800, loss is 4.6473953151702885 and perplexity is 104.31292911624536
At time: 104.96674656867981 and batch: 850, loss is 4.653659782409668 and perplexity is 104.96844512890101
At time: 106.0169928073883 and batch: 900, loss is 4.6553606510162355 and perplexity is 105.14713458246355
At time: 107.06750130653381 and batch: 950, loss is 4.725329351425171 and perplexity is 112.76763243911186
At time: 108.11884069442749 and batch: 1000, loss is 4.694004545211792 and perplexity is 109.28996125923845
At time: 109.1706714630127 and batch: 1050, loss is 4.630010347366333 and perplexity is 102.51512486655716
At time: 110.22262525558472 and batch: 1100, loss is 4.704116086959839 and perplexity is 110.40065722605588
At time: 111.27339625358582 and batch: 1150, loss is 4.629747943878174 and perplexity is 102.48822806926411
At time: 112.32476568222046 and batch: 1200, loss is 4.70164342880249 and perplexity is 110.12801135931633
At time: 113.37756657600403 and batch: 1250, loss is 4.682721405029297 and perplexity is 108.0637580261869
At time: 114.43633151054382 and batch: 1300, loss is 4.689104261398316 and perplexity is 108.75571946835674
At time: 115.4956603050232 and batch: 1350, loss is 4.591017980575561 and perplexity is 98.5947466300971
At time: 116.5521514415741 and batch: 1400, loss is 4.610965633392334 and perplexity is 100.58122734987614
At time: 117.61366057395935 and batch: 1450, loss is 4.545384178161621 and perplexity is 94.19660853882286
At time: 118.66471862792969 and batch: 1500, loss is 4.548374118804932 and perplexity is 94.47867227393651
At time: 119.71600294113159 and batch: 1550, loss is 4.5535527610778805 and perplexity is 94.96921259018643
At time: 120.76761436462402 and batch: 1600, loss is 4.635012531280518 and perplexity is 103.0292090750603
At time: 121.81854033470154 and batch: 1650, loss is 4.584380397796631 and perplexity is 97.94248295958293
At time: 122.8687858581543 and batch: 1700, loss is 4.620306844711304 and perplexity is 101.52517981504036
At time: 123.92204928398132 and batch: 1750, loss is 4.6234241771698 and perplexity is 101.84216136517402
At time: 124.97265934944153 and batch: 1800, loss is 4.582203502655029 and perplexity is 97.72950434443469
At time: 126.02417874336243 and batch: 1850, loss is 4.6070897579193115 and perplexity is 100.19214154888448
At time: 127.07408857345581 and batch: 1900, loss is 4.682016849517822 and perplexity is 107.98764792492294
At time: 128.12510657310486 and batch: 1950, loss is 4.612575607299805 and perplexity is 100.74329092554895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.655528649618459 and perplexity of 105.16480063799597
finished 3 epochs...
Completing Train Step...
At time: 131.40989518165588 and batch: 50, loss is 4.5561586856842045 and perplexity is 95.2170179389124
At time: 132.4834930896759 and batch: 100, loss is 4.50380805015564 and perplexity is 90.36057456093215
At time: 133.5275490283966 and batch: 150, loss is 4.463327503204345 and perplexity is 86.77577589835622
At time: 134.57174277305603 and batch: 200, loss is 4.452117671966553 and perplexity is 85.80846591519209
At time: 135.6146080493927 and batch: 250, loss is 4.460928544998169 and perplexity is 86.56785393643186
At time: 136.6582100391388 and batch: 300, loss is 4.493408041000366 and perplexity is 89.42569357004845
At time: 137.70159029960632 and batch: 350, loss is 4.49451018333435 and perplexity is 89.52430774612462
At time: 138.7455768585205 and batch: 400, loss is 4.446948137283325 and perplexity is 85.36602067785722
At time: 139.78982996940613 and batch: 450, loss is 4.467303285598755 and perplexity is 87.12146423588386
At time: 140.8346598148346 and batch: 500, loss is 4.485834655761718 and perplexity is 88.75099643789333
At time: 141.8792507648468 and batch: 550, loss is 4.450113821029663 and perplexity is 85.63669070381307
At time: 142.9239456653595 and batch: 600, loss is 4.440350894927978 and perplexity is 84.80469399054425
At time: 143.97518181800842 and batch: 650, loss is 4.49244462966919 and perplexity is 89.33958133097867
At time: 145.02617001533508 and batch: 700, loss is 4.511338615417481 and perplexity is 91.0436093559385
At time: 146.07772374153137 and batch: 750, loss is 4.47847412109375 and perplexity is 88.10013991626853
At time: 147.12772154808044 and batch: 800, loss is 4.449114112854004 and perplexity is 85.55112178308151
At time: 148.19489192962646 and batch: 850, loss is 4.457215938568115 and perplexity is 86.24705742933237
At time: 149.2457151412964 and batch: 900, loss is 4.448860721588135 and perplexity is 85.52944662230055
At time: 150.29493045806885 and batch: 950, loss is 4.528000402450561 and perplexity is 92.57326660960904
At time: 151.34520983695984 and batch: 1000, loss is 4.492331333160401 and perplexity is 89.32946004168141
At time: 152.39589548110962 and batch: 1050, loss is 4.438239440917969 and perplexity is 84.62582168612713
At time: 153.4997580051422 and batch: 1100, loss is 4.511649751663208 and perplexity is 91.07194072998111
At time: 154.5490918159485 and batch: 1150, loss is 4.445589466094971 and perplexity is 85.25011508172479
At time: 155.6030843257904 and batch: 1200, loss is 4.5117711353302 and perplexity is 91.08299604706085
At time: 156.66313791275024 and batch: 1250, loss is 4.495750246047973 and perplexity is 89.63539236383465
At time: 157.71494841575623 and batch: 1300, loss is 4.506214590072632 and perplexity is 90.57829275922772
At time: 158.7651607990265 and batch: 1350, loss is 4.399385175704956 and perplexity is 81.40080608348315
At time: 159.8197340965271 and batch: 1400, loss is 4.425606670379639 and perplexity is 83.56348734001213
At time: 160.8649320602417 and batch: 1450, loss is 4.353283367156982 and perplexity is 77.73327125153466
At time: 161.90954113006592 and batch: 1500, loss is 4.361371002197266 and perplexity is 78.36449870784793
At time: 162.9542076587677 and batch: 1550, loss is 4.364002647399903 and perplexity is 78.5709978620069
At time: 163.99794459342957 and batch: 1600, loss is 4.45276891708374 and perplexity is 85.86436646013546
At time: 165.04207801818848 and batch: 1650, loss is 4.400469293594361 and perplexity is 81.48910200651713
At time: 166.0852508544922 and batch: 1700, loss is 4.442649431228638 and perplexity is 84.99984485289892
At time: 167.1302444934845 and batch: 1750, loss is 4.442161989212036 and perplexity is 84.95842245344213
At time: 168.17494773864746 and batch: 1800, loss is 4.394201784133911 and perplexity is 80.97996546445837
At time: 169.21945357322693 and batch: 1850, loss is 4.425709953308106 and perplexity is 83.57211846741389
At time: 170.26330137252808 and batch: 1900, loss is 4.506075582504272 and perplexity is 90.56570256609147
At time: 171.3077893257141 and batch: 1950, loss is 4.437302322387695 and perplexity is 84.54655440770411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.620735771711483 and perplexity of 101.56873604641513
finished 4 epochs...
Completing Train Step...
At time: 174.57426142692566 and batch: 50, loss is 4.392581377029419 and perplexity is 80.8488512110212
At time: 175.65457797050476 and batch: 100, loss is 4.34317831993103 and perplexity is 76.95172828917893
At time: 176.69913029670715 and batch: 150, loss is 4.3100741100311275 and perplexity is 74.44600593172764
At time: 177.74311423301697 and batch: 200, loss is 4.294832820892334 and perplexity is 73.31995585556854
At time: 178.78702449798584 and batch: 250, loss is 4.292506465911865 and perplexity is 73.14958585847762
At time: 179.8594617843628 and batch: 300, loss is 4.330682621002198 and perplexity is 75.99614543215714
At time: 180.9037733078003 and batch: 350, loss is 4.328117895126343 and perplexity is 75.8014858823971
At time: 181.9556303024292 and batch: 400, loss is 4.282761468887329 and perplexity is 72.44020543086738
At time: 183.00663995742798 and batch: 450, loss is 4.311575975418091 and perplexity is 74.55789781347436
At time: 184.0563006401062 and batch: 500, loss is 4.340253410339355 and perplexity is 76.72698028503483
At time: 185.10616755485535 and batch: 550, loss is 4.302423210144043 and perplexity is 73.87860034284313
At time: 186.15576004981995 and batch: 600, loss is 4.291342105865478 and perplexity is 73.0644629697566
At time: 187.2058744430542 and batch: 650, loss is 4.336728706359863 and perplexity is 76.45701644309587
At time: 188.2557933330536 and batch: 700, loss is 4.359755373001098 and perplexity is 78.23799295650291
At time: 189.30590748786926 and batch: 750, loss is 4.336123771667481 and perplexity is 76.41077892812189
At time: 190.3607199192047 and batch: 800, loss is 4.304232406616211 and perplexity is 74.01238222831859
At time: 191.41115140914917 and batch: 850, loss is 4.311474189758301 and perplexity is 74.55030927486165
At time: 192.46886348724365 and batch: 900, loss is 4.295838618278504 and perplexity is 73.39373797423318
At time: 193.52429270744324 and batch: 950, loss is 4.382354192733764 and perplexity is 80.02620893703056
At time: 194.5796399116516 and batch: 1000, loss is 4.341585512161255 and perplexity is 76.82925654133102
At time: 195.6361916065216 and batch: 1050, loss is 4.296502237319946 and perplexity is 73.44245962079367
At time: 196.69409227371216 and batch: 1100, loss is 4.359940814971924 and perplexity is 78.25250290944574
At time: 197.7502362728119 and batch: 1150, loss is 4.300220232009888 and perplexity is 73.7160265407206
At time: 198.80514287948608 and batch: 1200, loss is 4.363665542602539 and perplexity is 78.5445156655825
At time: 199.85949802398682 and batch: 1250, loss is 4.355082702636719 and perplexity is 77.87326539489757
At time: 200.9130539894104 and batch: 1300, loss is 4.3665353965759275 and perplexity is 78.7702507143359
At time: 201.97031044960022 and batch: 1350, loss is 4.2541786432266235 and perplexity is 70.39897076393262
At time: 203.02342462539673 and batch: 1400, loss is 4.2833270072937015 and perplexity is 72.48118473579726
At time: 204.08066153526306 and batch: 1450, loss is 4.205456557273865 and perplexity is 67.05120339377017
At time: 205.1334183216095 and batch: 1500, loss is 4.216071615219116 and perplexity is 67.76674685182064
At time: 206.18695092201233 and batch: 1550, loss is 4.218836793899536 and perplexity is 67.95439333391718
At time: 207.24195909500122 and batch: 1600, loss is 4.316109876632691 and perplexity is 74.89670343215074
At time: 208.29690027236938 and batch: 1650, loss is 4.26322494506836 and perplexity is 71.03871037885666
At time: 209.35351061820984 and batch: 1700, loss is 4.30308629989624 and perplexity is 73.92760473099537
At time: 210.40972995758057 and batch: 1750, loss is 4.303164935111999 and perplexity is 73.93341827271553
At time: 211.4657130241394 and batch: 1800, loss is 4.2535143566131595 and perplexity is 70.3522211993266
At time: 212.5218789577484 and batch: 1850, loss is 4.288024158477783 and perplexity is 72.82244065639465
At time: 213.57843732833862 and batch: 1900, loss is 4.374417610168457 and perplexity is 79.39358806699136
At time: 214.63337111473083 and batch: 1950, loss is 4.305617351531982 and perplexity is 74.11495631412375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6090184411337205 and perplexity of 100.38556691867855
finished 5 epochs...
Completing Train Step...
At time: 218.06172490119934 and batch: 50, loss is 4.263789386749267 and perplexity is 71.07881890634988
At time: 219.1081805229187 and batch: 100, loss is 4.214963603019714 and perplexity is 67.69170205254925
At time: 220.1598560810089 and batch: 150, loss is 4.183915839195252 and perplexity is 65.62231719219159
At time: 221.20697402954102 and batch: 200, loss is 4.168085885047913 and perplexity is 64.59169777069096
At time: 222.25964069366455 and batch: 250, loss is 4.168434615135193 and perplexity is 64.61422676713323
At time: 223.31128454208374 and batch: 300, loss is 4.198162522315979 and perplexity is 66.56390890422503
At time: 224.36211776733398 and batch: 350, loss is 4.198715691566467 and perplexity is 66.60074019785353
At time: 225.4114909172058 and batch: 400, loss is 4.1541970920562745 and perplexity is 63.70079813275868
At time: 226.458815574646 and batch: 450, loss is 4.1888486099243165 and perplexity is 65.94681672051534
At time: 227.50708675384521 and batch: 500, loss is 4.217697877883911 and perplexity is 67.87704304312071
At time: 228.55492854118347 and batch: 550, loss is 4.187728686332703 and perplexity is 65.873002665444
At time: 229.60514068603516 and batch: 600, loss is 4.17327317237854 and perplexity is 64.92762398584368
At time: 230.65488266944885 and batch: 650, loss is 4.213332600593567 and perplexity is 67.58138670902277
At time: 231.7038233280182 and batch: 700, loss is 4.240923385620118 and perplexity is 69.47197165016632
At time: 232.78063893318176 and batch: 750, loss is 4.2176839637756345 and perplexity is 67.87609860116488
At time: 233.8316605091095 and batch: 800, loss is 4.1816033840179445 and perplexity is 65.47074384588254
At time: 234.88296341896057 and batch: 850, loss is 4.1923021841049195 and perplexity is 66.17496267676488
At time: 235.93687558174133 and batch: 900, loss is 4.177056035995483 and perplexity is 65.17370147770126
At time: 236.9982705116272 and batch: 950, loss is 4.267845525741577 and perplexity is 71.36770997032191
At time: 238.04397201538086 and batch: 1000, loss is 4.2252891683578495 and perplexity is 68.39427815042481
At time: 239.08752942085266 and batch: 1050, loss is 4.179953451156616 and perplexity is 65.36281057996212
At time: 240.1381757259369 and batch: 1100, loss is 4.2398498916625975 and perplexity is 69.39743392344053
At time: 241.18382024765015 and batch: 1150, loss is 4.183284606933594 and perplexity is 65.5809073394876
At time: 242.229350566864 and batch: 1200, loss is 4.245364956855774 and perplexity is 69.78122263286973
At time: 243.27583503723145 and batch: 1250, loss is 4.244733505249023 and perplexity is 69.73717307676233
At time: 244.31989359855652 and batch: 1300, loss is 4.25092791557312 and perplexity is 70.17049444123911
At time: 245.3636155128479 and batch: 1350, loss is 4.139451608657837 and perplexity is 62.76839036737201
At time: 246.40941262245178 and batch: 1400, loss is 4.166669578552246 and perplexity is 64.50028088202006
At time: 247.45497632026672 and batch: 1450, loss is 4.089164915084839 and perplexity is 59.690024646261605
At time: 248.49863815307617 and batch: 1500, loss is 4.097860126495362 and perplexity is 60.21130506703793
At time: 249.54305386543274 and batch: 1550, loss is 4.10554407119751 and perplexity is 60.67574749541488
At time: 250.58841514587402 and batch: 1600, loss is 4.200086703300476 and perplexity is 66.69211321658628
At time: 251.63346815109253 and batch: 1650, loss is 4.1459547758102415 and perplexity is 63.177913858407514
At time: 252.6784336566925 and batch: 1700, loss is 4.190485539436341 and perplexity is 66.05485541276661
At time: 253.72232246398926 and batch: 1750, loss is 4.1922728538513185 and perplexity is 66.17302177679122
At time: 254.7669780254364 and batch: 1800, loss is 4.1394714784622195 and perplexity is 62.76963757540084
At time: 255.81102561950684 and batch: 1850, loss is 4.174428815841675 and perplexity is 65.00270054259036
At time: 256.8563060760498 and batch: 1900, loss is 4.264804773330688 and perplexity is 71.15102803917887
At time: 257.9008209705353 and batch: 1950, loss is 4.19263879776001 and perplexity is 66.19724182234891
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.611283271257268 and perplexity of 100.61318083073299
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 261.2128486633301 and batch: 50, loss is 4.185489239692688 and perplexity is 65.72564864826974
At time: 262.30297660827637 and batch: 100, loss is 4.166144170761108 and perplexity is 64.46640083311432
At time: 263.35325479507446 and batch: 150, loss is 4.1386107110977175 and perplexity is 62.715630766878
At time: 264.4024386405945 and batch: 200, loss is 4.116229729652405 and perplexity is 61.32758425976835
At time: 265.45225524902344 and batch: 250, loss is 4.116610264778137 and perplexity is 61.35092600064996
At time: 266.50362038612366 and batch: 300, loss is 4.140524005889892 and perplexity is 62.83573912131672
At time: 267.5542709827423 and batch: 350, loss is 4.133411588668824 and perplexity is 62.39041068640464
At time: 268.60394310951233 and batch: 400, loss is 4.085816903114319 and perplexity is 59.490515894430764
At time: 269.65369486808777 and batch: 450, loss is 4.108320560455322 and perplexity is 60.844447144553484
At time: 270.70413184165955 and batch: 500, loss is 4.139966421127319 and perplexity is 62.8007126366622
At time: 271.7545886039734 and batch: 550, loss is 4.09896607875824 and perplexity is 60.27793273284536
At time: 272.80361819267273 and batch: 600, loss is 4.082180452346802 and perplexity is 59.27457443046106
At time: 273.8547434806824 and batch: 650, loss is 4.102506823539734 and perplexity is 60.491739803370415
At time: 274.90631198883057 and batch: 700, loss is 4.122976899147034 and perplexity is 61.74277095788821
At time: 275.9652535915375 and batch: 750, loss is 4.090140242576599 and perplexity is 59.74827036799249
At time: 277.02469396591187 and batch: 800, loss is 4.049212441444397 and perplexity is 57.3522709827509
At time: 278.08525800704956 and batch: 850, loss is 4.0532286262512205 and perplexity is 57.583071460565606
At time: 279.14126348495483 and batch: 900, loss is 4.027991094589233 and perplexity is 56.14800184823239
At time: 280.19693875312805 and batch: 950, loss is 4.123255319595337 and perplexity is 61.759963801166315
At time: 281.2538502216339 and batch: 1000, loss is 4.067157154083252 and perplexity is 58.39073056786032
At time: 282.30952739715576 and batch: 1050, loss is 4.024209632873535 and perplexity is 55.93608126614326
At time: 283.365905046463 and batch: 1100, loss is 4.061883149147033 and perplexity is 58.083588213695336
At time: 284.42183542251587 and batch: 1150, loss is 4.009964466094971 and perplexity is 55.14491101461797
At time: 285.477196931839 and batch: 1200, loss is 4.059032130241394 and perplexity is 57.918226642083326
At time: 286.56716442108154 and batch: 1250, loss is 4.0486409378051755 and perplexity is 57.31950331547905
At time: 287.6324212551117 and batch: 1300, loss is 4.050031666755676 and perplexity is 57.399274665473804
At time: 288.6876895427704 and batch: 1350, loss is 3.9289354705810546 and perplexity is 50.85281452808645
At time: 289.7479910850525 and batch: 1400, loss is 3.954374132156372 and perplexity is 52.16303655868583
At time: 290.80484437942505 and batch: 1450, loss is 3.8634253263473513 and perplexity is 47.62821445786098
At time: 291.85447883605957 and batch: 1500, loss is 3.870173707008362 and perplexity is 47.950714732630736
At time: 292.90470123291016 and batch: 1550, loss is 3.8726543378829956 and perplexity is 48.06981041119433
At time: 293.9541027545929 and batch: 1600, loss is 3.9554061222076418 and perplexity is 52.2168960799234
At time: 295.0036561489105 and batch: 1650, loss is 3.890385375022888 and perplexity is 48.9297391901855
At time: 296.0556333065033 and batch: 1700, loss is 3.92273118019104 and perplexity is 50.53828562287185
At time: 297.1049757003784 and batch: 1750, loss is 3.912218675613403 and perplexity is 50.00978446649582
At time: 298.15561270713806 and batch: 1800, loss is 3.8596302032470704 and perplexity is 47.447802081075466
At time: 299.20700693130493 and batch: 1850, loss is 3.8785702848434447 and perplexity is 48.35503170515172
At time: 300.2573027610779 and batch: 1900, loss is 3.956872181892395 and perplexity is 52.29350530925888
At time: 301.3073196411133 and batch: 1950, loss is 3.895627474784851 and perplexity is 49.18690722568997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.521881813226744 and perplexity of 92.00857812823848
finished 7 epochs...
Completing Train Step...
At time: 304.64642357826233 and batch: 50, loss is 4.074820194244385 and perplexity is 58.83989988448113
At time: 305.7319939136505 and batch: 100, loss is 4.04224997997284 and perplexity is 56.95434488576972
At time: 306.7746183872223 and batch: 150, loss is 4.01466432094574 and perplexity is 55.40469408532013
At time: 307.81669521331787 and batch: 200, loss is 3.993257384300232 and perplexity is 54.23125399904339
At time: 308.8588535785675 and batch: 250, loss is 3.992761001586914 and perplexity is 54.20434122210792
At time: 309.9009654521942 and batch: 300, loss is 4.019070229530334 and perplexity is 55.64934065206469
At time: 310.9440667629242 and batch: 350, loss is 4.017577471733094 and perplexity is 55.56633163648689
At time: 311.9872045516968 and batch: 400, loss is 3.973654384613037 and perplexity is 53.178510916934485
At time: 313.0590558052063 and batch: 450, loss is 4.004057927131653 and perplexity is 54.82015548382995
At time: 314.10809659957886 and batch: 500, loss is 4.040478086471557 and perplexity is 56.853517206531556
At time: 315.15211153030396 and batch: 550, loss is 4.001186108589172 and perplexity is 54.662947788842004
At time: 316.1955814361572 and batch: 600, loss is 3.9874279069900513 and perplexity is 53.91603381149054
At time: 317.2386450767517 and batch: 650, loss is 4.007538194656372 and perplexity is 55.011276674187314
At time: 318.28239703178406 and batch: 700, loss is 4.035699582099914 and perplexity is 56.58249049290563
At time: 319.32575368881226 and batch: 750, loss is 4.007451004981995 and perplexity is 55.00648046797988
At time: 320.36800360679626 and batch: 800, loss is 3.9671987962722777 and perplexity is 52.83631805838977
At time: 321.4118449687958 and batch: 850, loss is 3.97305712223053 and perplexity is 53.14675887589978
At time: 322.4551293849945 and batch: 900, loss is 3.9498784589767455 and perplexity is 51.92905494078803
At time: 323.49921131134033 and batch: 950, loss is 4.047478647232055 and perplexity is 57.25292009913759
At time: 324.5446879863739 and batch: 1000, loss is 3.993610768318176 and perplexity is 54.250421844085295
At time: 325.5879008769989 and batch: 1050, loss is 3.956229319572449 and perplexity is 52.25989858852228
At time: 326.6314322948456 and batch: 1100, loss is 3.994852075576782 and perplexity is 54.31780509951257
At time: 327.67453360557556 and batch: 1150, loss is 3.947511568069458 and perplexity is 51.80628987589515
At time: 328.7181701660156 and batch: 1200, loss is 3.9977410984039308 and perplexity is 54.47495737731931
At time: 329.76180243492126 and batch: 1250, loss is 3.9926296997070314 and perplexity is 54.197224557433614
At time: 330.804438829422 and batch: 1300, loss is 3.997498269081116 and perplexity is 54.461730866266365
At time: 331.8476011753082 and batch: 1350, loss is 3.877789468765259 and perplexity is 48.3172900554961
At time: 332.8895354270935 and batch: 1400, loss is 3.90817430973053 and perplexity is 49.807935051968215
At time: 333.94159841537476 and batch: 1450, loss is 3.818025941848755 and perplexity is 45.51427176088772
At time: 334.9844048023224 and batch: 1500, loss is 3.8283651304244994 and perplexity is 45.98729351629454
At time: 336.03640389442444 and batch: 1550, loss is 3.8347349262237547 and perplexity is 46.28115812050263
At time: 337.08116269111633 and batch: 1600, loss is 3.9210297775268557 and perplexity is 50.452372755984925
At time: 338.1280653476715 and batch: 1650, loss is 3.8594336557388305 and perplexity is 47.438477250221126
At time: 339.17545342445374 and batch: 1700, loss is 3.8964274501800538 and perplexity is 49.22627128427651
At time: 340.2172062397003 and batch: 1750, loss is 3.892171845436096 and perplexity is 49.01722884714813
At time: 341.26203083992004 and batch: 1800, loss is 3.843685312271118 and perplexity is 46.69725167361924
At time: 342.3049693107605 and batch: 1850, loss is 3.8668779039382937 and perplexity is 47.79293876188505
At time: 343.35977602005005 and batch: 1900, loss is 3.94766047000885 and perplexity is 51.81400450727791
At time: 344.40277194976807 and batch: 1950, loss is 3.8917394733428954 and perplexity is 48.99603974642661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.521626884992733 and perplexity of 91.98512553339366
finished 8 epochs...
Completing Train Step...
At time: 347.70502948760986 and batch: 50, loss is 4.019952716827393 and perplexity is 55.698472164058856
At time: 348.7499701976776 and batch: 100, loss is 3.9850816249847414 and perplexity is 53.78967988050352
At time: 349.7978684902191 and batch: 150, loss is 3.959539895057678 and perplexity is 52.43319562583507
At time: 350.8421664237976 and batch: 200, loss is 3.9371442937850953 and perplexity is 51.27197434263469
At time: 351.8889331817627 and batch: 250, loss is 3.9360840702056885 and perplexity is 51.21764339304015
At time: 352.9430179595947 and batch: 300, loss is 3.9629317855834962 and perplexity is 52.611345246522255
At time: 353.9889802932739 and batch: 350, loss is 3.9625949668884277 and perplexity is 52.59362774583075
At time: 355.0361702442169 and batch: 400, loss is 3.9195402812957765 and perplexity is 50.377280075931225
At time: 356.08113861083984 and batch: 450, loss is 3.9520061779022218 and perplexity is 52.039663003473166
At time: 357.12679147720337 and batch: 500, loss is 3.9908426237106323 and perplexity is 54.10045649005432
At time: 358.18526887893677 and batch: 550, loss is 3.9501521015167236 and perplexity is 51.94326688368808
At time: 359.2389762401581 and batch: 600, loss is 3.9376192331314086 and perplexity is 51.29633120417128
At time: 360.28811526298523 and batch: 650, loss is 3.958407883644104 and perplexity is 52.37387423251839
At time: 361.3323104381561 and batch: 700, loss is 3.986712484359741 and perplexity is 53.87747485538476
At time: 362.37867188453674 and batch: 750, loss is 3.9625362491607667 and perplexity is 52.5905396581837
At time: 363.42438197135925 and batch: 800, loss is 3.9208163452148437 and perplexity is 50.44160573847672
At time: 364.4963285923004 and batch: 850, loss is 3.928236970901489 and perplexity is 50.81730625613557
At time: 365.5404062271118 and batch: 900, loss is 3.9056875944137572 and perplexity is 49.68423076939118
At time: 366.5839309692383 and batch: 950, loss is 4.005005059242248 and perplexity is 54.87210200962456
At time: 367.6297595500946 and batch: 1000, loss is 3.951187744140625 and perplexity is 51.99708941053835
At time: 368.6747374534607 and batch: 1050, loss is 3.9163749170303346 and perplexity is 50.21806974606751
At time: 369.7194724082947 and batch: 1100, loss is 3.95499080657959 and perplexity is 52.195214089679396
At time: 370.76478481292725 and batch: 1150, loss is 3.9093792963027956 and perplexity is 49.86798911980429
At time: 371.8181872367859 and batch: 1200, loss is 3.960445399284363 and perplexity is 52.48069560856483
At time: 372.86315846443176 and batch: 1250, loss is 3.956378908157349 and perplexity is 52.26771665753151
At time: 373.90980076789856 and batch: 1300, loss is 3.9624774408340455 and perplexity is 52.58744698748332
At time: 374.95634150505066 and batch: 1350, loss is 3.8424186372756957 and perplexity is 46.638138878822566
At time: 376.0023045539856 and batch: 1400, loss is 3.8758066654205323 and perplexity is 48.22158128835439
At time: 377.04741883277893 and batch: 1450, loss is 3.7856832122802735 and perplexity is 44.065766549450274
At time: 378.0926733016968 and batch: 1500, loss is 3.797836351394653 and perplexity is 44.604571393903605
At time: 379.13795042037964 and batch: 1550, loss is 3.8046617603302 and perplexity is 44.91005718082055
At time: 380.1818869113922 and batch: 1600, loss is 3.8928391408920286 and perplexity is 49.04994873692299
At time: 381.2273576259613 and batch: 1650, loss is 3.832928328514099 and perplexity is 46.1976221668935
At time: 382.2724013328552 and batch: 1700, loss is 3.871691093444824 and perplexity is 48.02352972705601
At time: 383.3175814151764 and batch: 1750, loss is 3.869325428009033 and perplexity is 47.91005639556504
At time: 384.3626353740692 and batch: 1800, loss is 3.822371644973755 and perplexity is 45.71249366873943
At time: 385.4086582660675 and batch: 1850, loss is 3.847630653381348 and perplexity is 46.881852176906015
At time: 386.455313205719 and batch: 1900, loss is 3.9280839586257934 and perplexity is 50.80953117931687
At time: 387.5018081665039 and batch: 1950, loss is 3.8746879482269287 and perplexity is 48.16766514034838
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52481689453125 and perplexity of 92.27902748703191
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 390.7907841205597 and batch: 50, loss is 3.9938917684555055 and perplexity is 54.26566836211017
At time: 391.872563123703 and batch: 100, loss is 3.979497470855713 and perplexity is 53.49014711442083
At time: 392.92474579811096 and batch: 150, loss is 3.9645351123809816 and perplexity is 52.695766085219475
At time: 393.97674584388733 and batch: 200, loss is 3.9434862327575684 and perplexity is 51.598171342338404
At time: 395.0288836956024 and batch: 250, loss is 3.9473144817352295 and perplexity is 51.796080570223886
At time: 396.0847408771515 and batch: 300, loss is 3.9742050552368164 and perplexity is 53.20780282506923
At time: 397.1408483982086 and batch: 350, loss is 3.9742655038833616 and perplexity is 53.211019261949296
At time: 398.19216203689575 and batch: 400, loss is 3.9340975761413572 and perplexity is 51.116000838041735
At time: 399.26501870155334 and batch: 450, loss is 3.968298468589783 and perplexity is 52.89445265336146
At time: 400.3170256614685 and batch: 500, loss is 4.002201843261719 and perplexity is 54.718499048108704
At time: 401.36836767196655 and batch: 550, loss is 3.9580644226074218 and perplexity is 52.35588893618049
At time: 402.4197642803192 and batch: 600, loss is 3.9389947509765624 and perplexity is 51.36693877298624
At time: 403.4786956310272 and batch: 650, loss is 3.9524854707717894 and perplexity is 52.06461122115926
At time: 404.53012704849243 and batch: 700, loss is 3.979344425201416 and perplexity is 53.48196130627443
At time: 405.58020853996277 and batch: 750, loss is 3.9492686223983764 and perplexity is 51.897396357867095
At time: 406.6302659511566 and batch: 800, loss is 3.9043650388717652 and perplexity is 49.61856404815232
At time: 407.68086862564087 and batch: 850, loss is 3.909439969062805 and perplexity is 49.87101484012878
At time: 408.7316801548004 and batch: 900, loss is 3.8792739868164063 and perplexity is 48.389071211794565
At time: 409.7819836139679 and batch: 950, loss is 3.983205213546753 and perplexity is 53.688842945305865
At time: 410.83295369148254 and batch: 1000, loss is 3.927268285751343 and perplexity is 50.76810412073119
At time: 411.8835394382477 and batch: 1050, loss is 3.8916261911392214 and perplexity is 48.99048968144057
At time: 412.93427872657776 and batch: 1100, loss is 3.9208978986740113 and perplexity is 50.44571959365794
At time: 413.98626613616943 and batch: 1150, loss is 3.8796706438064574 and perplexity is 48.4082688823262
At time: 415.04165625572205 and batch: 1200, loss is 3.923397922515869 and perplexity is 50.571992872697265
At time: 416.0937237739563 and batch: 1250, loss is 3.9093279790878297 and perplexity is 49.865430099148185
At time: 417.15008211135864 and batch: 1300, loss is 3.9103931283950804 and perplexity is 49.918572524758595
At time: 418.2121057510376 and batch: 1350, loss is 3.787483353614807 and perplexity is 44.14516259786783
At time: 419.26781940460205 and batch: 1400, loss is 3.819127678871155 and perplexity is 45.56444415244986
At time: 420.3241183757782 and batch: 1450, loss is 3.72168514251709 and perplexity is 41.3339891158489
At time: 421.38098764419556 and batch: 1500, loss is 3.7353381299972535 and perplexity is 41.902191555909916
At time: 422.43742537498474 and batch: 1550, loss is 3.7427374076843263 and perplexity is 42.21338739934748
At time: 423.4947192668915 and batch: 1600, loss is 3.8290989208221435 and perplexity is 46.02105093461043
At time: 424.552752494812 and batch: 1650, loss is 3.7614340019226074 and perplexity is 43.010058284050146
At time: 425.61001205444336 and batch: 1700, loss is 3.795638999938965 and perplexity is 44.50666707850888
At time: 426.66784834861755 and batch: 1750, loss is 3.7894715785980226 and perplexity is 44.233020424654
At time: 427.7237820625305 and batch: 1800, loss is 3.7399590492248533 and perplexity is 42.09626625496549
At time: 428.7832534313202 and batch: 1850, loss is 3.7596846342086794 and perplexity is 42.93488364992412
At time: 429.84166169166565 and batch: 1900, loss is 3.842021932601929 and perplexity is 46.61964098049751
At time: 430.89928150177 and batch: 1950, loss is 3.7919179010391235 and perplexity is 44.341361119262416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496476142351018 and perplexity of 89.70048198507308
finished 10 epochs...
Completing Train Step...
At time: 434.2904303073883 and batch: 50, loss is 3.9759627914428712 and perplexity is 53.301410351107215
At time: 435.3798713684082 and batch: 100, loss is 3.947501893043518 and perplexity is 51.80578865112143
At time: 436.4349408149719 and batch: 150, loss is 3.925482087135315 and perplexity is 50.67750314317133
At time: 437.48550367355347 and batch: 200, loss is 3.9034338426589965 and perplexity is 49.57238093533475
At time: 438.53503370285034 and batch: 250, loss is 3.9036057710647585 and perplexity is 49.580904568465115
At time: 439.5867655277252 and batch: 300, loss is 3.9286595392227173 and perplexity is 50.838784577639096
At time: 440.63641333580017 and batch: 350, loss is 3.9313477897644042 and perplexity is 50.975635830631006
At time: 441.6872055530548 and batch: 400, loss is 3.8911847257614136 and perplexity is 48.96886684962135
At time: 442.73841619491577 and batch: 450, loss is 3.9269061279296875 and perplexity is 50.74972138366019
At time: 443.78745436668396 and batch: 500, loss is 3.9613920402526857 and perplexity is 52.5303995072356
At time: 444.8745958805084 and batch: 550, loss is 3.918712100982666 and perplexity is 50.33557587602663
At time: 445.9258494377136 and batch: 600, loss is 3.901746325492859 and perplexity is 49.48879723583913
At time: 446.97592401504517 and batch: 650, loss is 3.917555947303772 and perplexity is 50.277413843401035
At time: 448.025039434433 and batch: 700, loss is 3.9467185735702515 and perplexity is 51.765224057635244
At time: 449.07412123680115 and batch: 750, loss is 3.918800363540649 and perplexity is 50.34001881878087
At time: 450.13067960739136 and batch: 800, loss is 3.8751197910308837 and perplexity is 48.1884704919199
At time: 451.175185918808 and batch: 850, loss is 3.8812372636795045 and perplexity is 48.48416567356501
At time: 452.2185890674591 and batch: 900, loss is 3.8533633041381834 and perplexity is 47.151381282250775
At time: 453.2631719112396 and batch: 950, loss is 3.957072606086731 and perplexity is 52.303987243311006
At time: 454.30802273750305 and batch: 1000, loss is 3.9024545621871947 and perplexity is 49.523859432701684
At time: 455.35319662094116 and batch: 1050, loss is 3.8688604640960693 and perplexity is 47.88778512634253
At time: 456.40705943107605 and batch: 1100, loss is 3.898963327407837 and perplexity is 49.35126147754647
At time: 457.4525578022003 and batch: 1150, loss is 3.859525451660156 and perplexity is 47.442832108822664
At time: 458.4967300891876 and batch: 1200, loss is 3.905242877006531 and perplexity is 49.66214023948904
At time: 459.54191493988037 and batch: 1250, loss is 3.8941071891784667 and perplexity is 49.112185891888075
At time: 460.5855929851532 and batch: 1300, loss is 3.8970207929611207 and perplexity is 49.25548800388955
At time: 461.6294231414795 and batch: 1350, loss is 3.77478835105896 and perplexity is 43.58828192566878
At time: 462.6739420890808 and batch: 1400, loss is 3.8090259981155397 and perplexity is 45.10648366347886
At time: 463.7268371582031 and batch: 1450, loss is 3.713827648162842 and perplexity is 41.01048017901257
At time: 464.7766709327698 and batch: 1500, loss is 3.7291898632049563 and perplexity is 41.64535605867825
At time: 465.8269407749176 and batch: 1550, loss is 3.7380838203430176 and perplexity is 42.017400089833025
At time: 466.8764126300812 and batch: 1600, loss is 3.82617534160614 and perplexity is 45.88670123329068
At time: 467.9242033958435 and batch: 1650, loss is 3.7601664066314697 and perplexity is 42.955573476336085
At time: 468.9744019508362 and batch: 1700, loss is 3.7967249250411985 and perplexity is 44.555024236880236
At time: 470.02460837364197 and batch: 1750, loss is 3.7920920944213865 and perplexity is 44.34908576370136
At time: 471.07531118392944 and batch: 1800, loss is 3.744581480026245 and perplexity is 42.29130375913114
At time: 472.1275362968445 and batch: 1850, loss is 3.765674562454224 and perplexity is 43.19283229791455
At time: 473.17801904678345 and batch: 1900, loss is 3.848462533950806 and perplexity is 46.92086850500478
At time: 474.228036403656 and batch: 1950, loss is 3.7987884140014647 and perplexity is 44.64705796014687
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4964778456577035 and perplexity of 89.7006347726339
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 477.6449146270752 and batch: 50, loss is 3.9671226358413696 and perplexity is 52.832294174871144
At time: 478.69570446014404 and batch: 100, loss is 3.945757327079773 and perplexity is 51.71548882541931
At time: 479.7471046447754 and batch: 150, loss is 3.927960786819458 and perplexity is 50.803273262989805
At time: 480.806147813797 and batch: 200, loss is 3.907840595245361 and perplexity is 49.7913161956958
At time: 481.85986137390137 and batch: 250, loss is 3.9114896869659423 and perplexity is 49.97334118634044
At time: 482.90533089637756 and batch: 300, loss is 3.934321041107178 and perplexity is 51.12742474979638
At time: 483.9499306678772 and batch: 350, loss is 3.938804478645325 and perplexity is 51.35716599557143
At time: 484.9941861629486 and batch: 400, loss is 3.9010463333129883 and perplexity is 49.45416758643873
At time: 486.0386130809784 and batch: 450, loss is 3.9401101207733156 and perplexity is 51.424263868442395
At time: 487.0836718082428 and batch: 500, loss is 3.9741582345962523 and perplexity is 53.205311659977376
At time: 488.12941336631775 and batch: 550, loss is 3.932633571624756 and perplexity is 51.04122153392
At time: 489.17562985420227 and batch: 600, loss is 3.912163038253784 and perplexity is 50.0070021315346
At time: 490.2212951183319 and batch: 650, loss is 3.9238932943344116 and perplexity is 50.597051018811214
At time: 491.2656395435333 and batch: 700, loss is 3.953167405128479 and perplexity is 52.100127976990294
At time: 492.3106937408447 and batch: 750, loss is 3.920934672355652 and perplexity is 50.447574702599795
At time: 493.35599422454834 and batch: 800, loss is 3.8765575742721556 and perplexity is 48.257804899196
At time: 494.40159273147583 and batch: 850, loss is 3.882792229652405 and perplexity is 48.559615547202306
At time: 495.4460427761078 and batch: 900, loss is 3.8470364665985106 and perplexity is 46.85400387435356
At time: 496.48995566368103 and batch: 950, loss is 3.9550334358215333 and perplexity is 52.197439179515726
At time: 497.5741319656372 and batch: 1000, loss is 3.9020901346206665 and perplexity is 49.50581486129287
At time: 498.61794924736023 and batch: 1050, loss is 3.869088497161865 and perplexity is 47.89870636995406
At time: 499.6644172668457 and batch: 1100, loss is 3.8953548192977907 and perplexity is 49.173497973679495
At time: 500.7111511230469 and batch: 1150, loss is 3.859590630531311 and perplexity is 47.445924479841445
At time: 501.75648164749146 and batch: 1200, loss is 3.9032804918289186 and perplexity is 49.56477955242346
At time: 502.8000822067261 and batch: 1250, loss is 3.8861596822738647 and perplexity is 48.72341338782236
At time: 503.8445694446564 and batch: 1300, loss is 3.8847897911071776 and perplexity is 48.65671331056566
At time: 504.88948130607605 and batch: 1350, loss is 3.7577850437164306 and perplexity is 42.853402368192675
At time: 505.93468618392944 and batch: 1400, loss is 3.7897462749481203 and perplexity is 44.245172742940774
At time: 506.9793736934662 and batch: 1450, loss is 3.6920870399475096 and perplexity is 40.128509425667666
At time: 508.02591848373413 and batch: 1500, loss is 3.7061933183670046 and perplexity is 40.698584719488814
At time: 509.0778193473816 and batch: 1550, loss is 3.7171108102798462 and perplexity is 41.145345505156826
At time: 510.1256444454193 and batch: 1600, loss is 3.8042665195465086 and perplexity is 44.89231040198119
At time: 511.1694073677063 and batch: 1650, loss is 3.736200547218323 and perplexity is 41.93834431464838
At time: 512.2145829200745 and batch: 1700, loss is 3.7687765169143677 and perplexity is 43.3270225150791
At time: 513.2588438987732 and batch: 1750, loss is 3.7641740083694457 and perplexity is 43.128067720504696
At time: 514.3047595024109 and batch: 1800, loss is 3.7173647022247316 and perplexity is 41.155793303199864
At time: 515.3499021530151 and batch: 1850, loss is 3.734636664390564 and perplexity is 41.872808916348895
At time: 516.4036684036255 and batch: 1900, loss is 3.81930468082428 and perplexity is 45.572509861860006
At time: 517.4500417709351 and batch: 1950, loss is 3.77404176235199 and perplexity is 43.55575155154284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4878355514171515 and perplexity of 88.92875570064339
finished 12 epochs...
Completing Train Step...
At time: 520.7765340805054 and batch: 50, loss is 3.963330512046814 and perplexity is 52.63232696484798
At time: 521.8595154285431 and batch: 100, loss is 3.935546326637268 and perplexity is 51.19010883864416
At time: 522.9032728672028 and batch: 150, loss is 3.9142176580429076 and perplexity is 50.10985313137679
At time: 523.9919323921204 and batch: 200, loss is 3.8923518228530884 and perplexity is 49.02605163531167
At time: 525.0392115116119 and batch: 250, loss is 3.89491982460022 and perplexity is 49.152112414439586
At time: 526.0837836265564 and batch: 300, loss is 3.915405068397522 and perplexity is 50.16938942986661
At time: 527.1280355453491 and batch: 350, loss is 3.919687337875366 and perplexity is 50.38468893117532
At time: 528.1726243495941 and batch: 400, loss is 3.8818247270584108 and perplexity is 48.51265671325689
At time: 529.217099905014 and batch: 450, loss is 3.9206912231445314 and perplexity is 50.435294775165474
At time: 530.2616651058197 and batch: 500, loss is 3.9555930948257445 and perplexity is 52.226660122468516
At time: 531.306633234024 and batch: 550, loss is 3.914565019607544 and perplexity is 50.12726239184313
At time: 532.3509151935577 and batch: 600, loss is 3.895102620124817 and perplexity is 49.16109802185282
At time: 533.3962044715881 and batch: 650, loss is 3.9082855653762816 and perplexity is 49.81347677421421
At time: 534.4401280879974 and batch: 700, loss is 3.9383287382125856 and perplexity is 51.33273912608187
At time: 535.4861228466034 and batch: 750, loss is 3.9078617668151856 and perplexity is 49.79237036718248
At time: 536.5315029621124 and batch: 800, loss is 3.8637829542160036 and perplexity is 47.64525068081774
At time: 537.5746829509735 and batch: 850, loss is 3.8703104400634767 and perplexity is 47.95727162861306
At time: 538.6212985515594 and batch: 900, loss is 3.8368178462982176 and perplexity is 46.37765854026261
At time: 539.6650624275208 and batch: 950, loss is 3.9445344686508177 and perplexity is 51.652286755469525
At time: 540.7095034122467 and batch: 1000, loss is 3.891353740692139 and perplexity is 48.977144018722505
At time: 541.7525589466095 and batch: 1050, loss is 3.858873748779297 and perplexity is 47.41192355115321
At time: 542.7975075244904 and batch: 1100, loss is 3.8864431238174437 and perplexity is 48.73722558470418
At time: 543.8413238525391 and batch: 1150, loss is 3.851318974494934 and perplexity is 47.055086778166746
At time: 544.8860805034637 and batch: 1200, loss is 3.895369691848755 and perplexity is 49.174229314472626
At time: 545.931077003479 and batch: 1250, loss is 3.8802455711364745 and perplexity is 48.43610812110824
At time: 546.9778001308441 and batch: 1300, loss is 3.8800685691833494 and perplexity is 48.42753559406842
At time: 548.0229196548462 and batch: 1350, loss is 3.754430694580078 and perplexity is 42.70989791154949
At time: 549.067889213562 and batch: 1400, loss is 3.787799458503723 and perplexity is 44.15911930536252
At time: 550.1138679981232 and batch: 1450, loss is 3.691385278701782 and perplexity is 40.100358671613314
At time: 551.1584520339966 and batch: 1500, loss is 3.707142696380615 and perplexity is 40.73724140800814
At time: 552.2038805484772 and batch: 1550, loss is 3.71927255153656 and perplexity is 41.2343873040469
At time: 553.2486140727997 and batch: 1600, loss is 3.807349042892456 and perplexity is 45.03090549841539
At time: 554.292848110199 and batch: 1650, loss is 3.7399532079696653 and perplexity is 42.09602036065
At time: 555.3378391265869 and batch: 1700, loss is 3.7737484550476075 and perplexity is 43.542978204814425
At time: 556.3834087848663 and batch: 1750, loss is 3.7702514219284056 and perplexity is 43.39097290661364
At time: 557.4291484355927 and batch: 1800, loss is 3.7235874366760253 and perplexity is 41.41269335748498
At time: 558.475040435791 and batch: 1850, loss is 3.7410652923583982 and perplexity is 42.14286072811416
At time: 559.5207269191742 and batch: 1900, loss is 3.8256238889694214 and perplexity is 45.861403866696094
At time: 560.5673942565918 and batch: 1950, loss is 3.7801381969451904 and perplexity is 43.822097397119485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487123285337936 and perplexity of 88.86543731693634
finished 13 epochs...
Completing Train Step...
At time: 563.9337944984436 and batch: 50, loss is 3.9593334007263183 and perplexity is 52.42236958595966
At time: 565.0218641757965 and batch: 100, loss is 3.929844479560852 and perplexity is 50.89906120928024
At time: 566.0712430477142 and batch: 150, loss is 3.907271046638489 and perplexity is 49.76296569518261
At time: 567.1210973262787 and batch: 200, loss is 3.8848853969573973 and perplexity is 48.661365399390526
At time: 568.170019865036 and batch: 250, loss is 3.886752333641052 and perplexity is 48.75229794377104
At time: 569.2191381454468 and batch: 300, loss is 3.9065944242477415 and perplexity is 49.72930634698174
At time: 570.2791433334351 and batch: 350, loss is 3.911007037162781 and perplexity is 49.94922738278292
At time: 571.3396208286285 and batch: 400, loss is 3.872880163192749 and perplexity is 48.080667016822254
At time: 572.3916642665863 and batch: 450, loss is 3.91179790019989 and perplexity is 49.98874600530125
At time: 573.4411342144012 and batch: 500, loss is 3.9467097234725954 and perplexity is 51.764765932374374
At time: 574.4908311367035 and batch: 550, loss is 3.906052746772766 and perplexity is 49.70237639621976
At time: 575.541305065155 and batch: 600, loss is 3.886912703514099 and perplexity is 48.76011697055444
At time: 576.6313829421997 and batch: 650, loss is 3.9004573440551757 and perplexity is 49.425048189324116
At time: 577.6855657100677 and batch: 700, loss is 3.9309505558013917 and perplexity is 50.955390598106106
At time: 578.7406468391418 and batch: 750, loss is 3.9009822845458983 and perplexity is 49.45100020941174
At time: 579.7969710826874 and batch: 800, loss is 3.8572221755981446 and perplexity is 47.33368391677469
At time: 580.8578941822052 and batch: 850, loss is 3.8637702465057373 and perplexity is 47.644645222623524
At time: 581.9156353473663 and batch: 900, loss is 3.831169638633728 and perplexity is 46.11644627882085
At time: 582.9708523750305 and batch: 950, loss is 3.938820457458496 and perplexity is 51.35798662868823
At time: 584.0330018997192 and batch: 1000, loss is 3.8856743240356444 and perplexity is 48.69977081576306
At time: 585.0900962352753 and batch: 1050, loss is 3.8537333679199217 and perplexity is 47.168833529745456
At time: 586.145830154419 and batch: 1100, loss is 3.881801223754883 and perplexity is 48.511516518960434
At time: 587.2007944583893 and batch: 1150, loss is 3.8470782089233397 and perplexity is 46.85595971022311
At time: 588.2566344738007 and batch: 1200, loss is 3.89139142036438 and perplexity is 48.978989496224706
At time: 589.3130898475647 and batch: 1250, loss is 3.8771709775924683 and perplexity is 48.28741547763729
At time: 590.3686890602112 and batch: 1300, loss is 3.877663264274597 and perplexity is 48.31119258128688
At time: 591.4242739677429 and batch: 1350, loss is 3.752436866760254 and perplexity is 42.62482656590177
At time: 592.4799299240112 and batch: 1400, loss is 3.7864669513702394 and perplexity is 44.10031615039229
At time: 593.5350556373596 and batch: 1450, loss is 3.690775032043457 and perplexity is 40.075895026924236
At time: 594.5912659168243 and batch: 1500, loss is 3.7071397733688354 and perplexity is 40.73712233274566
At time: 595.650351524353 and batch: 1550, loss is 3.7196508550643923 and perplexity is 41.24998936920409
At time: 596.7059645652771 and batch: 1600, loss is 3.8082258796691892 and perplexity is 45.07040756834893
At time: 597.7606613636017 and batch: 1650, loss is 3.7411827278137206 and perplexity is 42.147810084761645
At time: 598.8168172836304 and batch: 1700, loss is 3.7754318714141846 and perplexity is 43.61634089962934
At time: 599.8721845149994 and batch: 1750, loss is 3.7724854516983033 and perplexity is 43.48801799227527
At time: 600.9276738166809 and batch: 1800, loss is 3.725899200439453 and perplexity is 41.508540466585664
At time: 601.9833068847656 and batch: 1850, loss is 3.7435340166091917 and perplexity is 42.24702835806358
At time: 603.038923740387 and batch: 1900, loss is 3.8280192518234255 and perplexity is 45.97139024600494
At time: 604.0950946807861 and batch: 1950, loss is 3.782426886558533 and perplexity is 43.92250743614404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487137763444768 and perplexity of 88.86672392954529
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 607.4732110500336 and batch: 50, loss is 3.9570370531082153 and perplexity is 52.302127713832355
At time: 608.520494222641 and batch: 100, loss is 3.929438214302063 and perplexity is 50.878386888919344
At time: 609.5706505775452 and batch: 150, loss is 3.907941918373108 and perplexity is 49.79636146318419
At time: 610.6174314022064 and batch: 200, loss is 3.886000871658325 and perplexity is 48.71567620694055
At time: 611.6634061336517 and batch: 250, loss is 3.889670367240906 and perplexity is 48.89476655023896
At time: 612.7118926048279 and batch: 300, loss is 3.9075314521789553 and perplexity is 49.775925934545505
At time: 613.7599713802338 and batch: 350, loss is 3.9118365097045897 and perplexity is 49.990676083284505
At time: 614.8074479103088 and batch: 400, loss is 3.8740875911712647 and perplexity is 48.13875602149156
At time: 615.8576519489288 and batch: 450, loss is 3.913969192504883 and perplexity is 50.097404106399054
At time: 616.904703617096 and batch: 500, loss is 3.9487364864349366 and perplexity is 51.86978723341171
At time: 617.9513683319092 and batch: 550, loss is 3.909964666366577 and perplexity is 49.89718889327884
At time: 619.0018041133881 and batch: 600, loss is 3.8892785358428954 and perplexity is 48.87561179846784
At time: 620.050488948822 and batch: 650, loss is 3.9016772365570067 and perplexity is 49.48537822561074
At time: 621.0980799198151 and batch: 700, loss is 3.932328362464905 and perplexity is 51.02564566264806
At time: 622.1462070941925 and batch: 750, loss is 3.900935320854187 and perplexity is 49.448677862416496
At time: 623.1958591938019 and batch: 800, loss is 3.8577255630493164 and perplexity is 47.35751709743488
At time: 624.2479794025421 and batch: 850, loss is 3.864575119018555 and perplexity is 47.683008524658774
At time: 625.2921361923218 and batch: 900, loss is 3.8278594636917114 and perplexity is 45.96404515029042
At time: 626.3333847522736 and batch: 950, loss is 3.9368820428848266 and perplexity is 51.25852998417939
At time: 627.3765394687653 and batch: 1000, loss is 3.883618392944336 and perplexity is 48.59975029568284
At time: 628.4187390804291 and batch: 1050, loss is 3.8523226261138914 and perplexity is 47.10233739980692
At time: 629.5010414123535 and batch: 1100, loss is 3.879672999382019 and perplexity is 48.40838291179566
At time: 630.551999092102 and batch: 1150, loss is 3.845757870674133 and perplexity is 46.79413481828079
At time: 631.5951986312866 and batch: 1200, loss is 3.8900838708877563 and perplexity is 48.91498889523795
At time: 632.6376724243164 and batch: 1250, loss is 3.875103244781494 and perplexity is 48.18767316006588
At time: 633.6811993122101 and batch: 1300, loss is 3.8739217281341554 and perplexity is 48.13077224334032
At time: 634.7249026298523 and batch: 1350, loss is 3.746788458824158 and perplexity is 42.38474284097332
At time: 635.7701539993286 and batch: 1400, loss is 3.779728260040283 and perplexity is 43.80413678375661
At time: 636.8315088748932 and batch: 1450, loss is 3.6832096767425537 and perplexity is 39.7738506192886
At time: 637.8796870708466 and batch: 1500, loss is 3.6962574434280397 and perplexity is 40.29621094949524
At time: 638.9271667003632 and batch: 1550, loss is 3.708700032234192 and perplexity is 40.800732400195876
At time: 639.9769423007965 and batch: 1600, loss is 3.7968408727645873 and perplexity is 44.56019059001368
At time: 641.0242869853973 and batch: 1650, loss is 3.7302869749069214 and perplexity is 41.691070738612495
At time: 642.073545217514 and batch: 1700, loss is 3.763545651435852 and perplexity is 43.10097641251701
At time: 643.1221222877502 and batch: 1750, loss is 3.7601211071014404 and perplexity is 42.95362765311823
At time: 644.1771290302277 and batch: 1800, loss is 3.7138907527923584 and perplexity is 41.01306821182813
At time: 645.227136850357 and batch: 1850, loss is 3.7319674110412597 and perplexity is 41.761188818338006
At time: 646.2759518623352 and batch: 1900, loss is 3.8168240451812743 and perplexity is 45.45960117011715
At time: 647.3233804702759 and batch: 1950, loss is 3.7736079835891725 and perplexity is 43.53686208874132
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486638978470204 and perplexity of 88.82240959549124
finished 15 epochs...
Completing Train Step...
At time: 650.6602725982666 and batch: 50, loss is 3.956067581176758 and perplexity is 52.251446839870155
At time: 651.744133234024 and batch: 100, loss is 3.9271223640441892 and perplexity is 50.760696492788945
At time: 652.7955911159515 and batch: 150, loss is 3.904695763587952 and perplexity is 49.63497684757434
At time: 653.8460221290588 and batch: 200, loss is 3.882449760437012 and perplexity is 48.54298822110224
At time: 654.8979780673981 and batch: 250, loss is 3.885378942489624 and perplexity is 48.68538792649327
At time: 655.9771738052368 and batch: 300, loss is 3.903065323829651 and perplexity is 49.55411594524767
At time: 657.0294439792633 and batch: 350, loss is 3.9072245836257933 and perplexity is 49.76065361158934
At time: 658.0811610221863 and batch: 400, loss is 3.8698764514923094 and perplexity is 47.93646323645066
At time: 659.1329605579376 and batch: 450, loss is 3.9095591354370116 and perplexity is 49.876958142259134
At time: 660.1813032627106 and batch: 500, loss is 3.9446712732315063 and perplexity is 51.65935350827177
At time: 661.2290365695953 and batch: 550, loss is 3.905515775680542 and perplexity is 49.67569482113851
At time: 662.2761342525482 and batch: 600, loss is 3.885403118133545 and perplexity is 48.686564941323425
At time: 663.321527004242 and batch: 650, loss is 3.8984040784835816 and perplexity is 49.3236695537505
At time: 664.3692619800568 and batch: 700, loss is 3.9292432832717896 and perplexity is 50.86847007912282
At time: 665.4147253036499 and batch: 750, loss is 3.897931890487671 and perplexity is 49.30038500684735
At time: 666.465122461319 and batch: 800, loss is 3.8547119522094726 and perplexity is 47.21501480164231
At time: 667.5129919052124 and batch: 850, loss is 3.8615805768966673 and perplexity is 47.54043332739289
At time: 668.5617797374725 and batch: 900, loss is 3.825860242843628 and perplexity is 45.872244668258794
At time: 669.609983921051 and batch: 950, loss is 3.934631099700928 and perplexity is 51.14327970507191
At time: 670.6588745117188 and batch: 1000, loss is 3.881199655532837 and perplexity is 48.48234230823821
At time: 671.7070000171661 and batch: 1050, loss is 3.8498758029937745 and perplexity is 46.987227196229114
At time: 672.7546052932739 and batch: 1100, loss is 3.8775177907943728 and perplexity is 48.30416509513713
At time: 673.8038232326508 and batch: 1150, loss is 3.8438716173171996 and perplexity is 46.705952417715274
At time: 674.853212594986 and batch: 1200, loss is 3.8884748458862304 and perplexity is 48.83634674071933
At time: 675.9007031917572 and batch: 1250, loss is 3.873762607574463 and perplexity is 48.123114257210204
At time: 676.9475438594818 and batch: 1300, loss is 3.8728264999389648 and perplexity is 48.0780869210148
At time: 677.994523525238 and batch: 1350, loss is 3.7460990142822266 and perplexity is 42.35553098249576
At time: 679.0412831306458 and batch: 1400, loss is 3.7794270753860473 and perplexity is 43.79094563655057
At time: 680.0898010730743 and batch: 1450, loss is 3.6832010459899904 and perplexity is 39.77350734250679
At time: 681.1447207927704 and batch: 1500, loss is 3.6971820640563964 and perplexity is 40.33348688777882
At time: 682.1930541992188 and batch: 1550, loss is 3.710078310966492 and perplexity is 40.85700595333772
At time: 683.2403872013092 and batch: 1600, loss is 3.798397240638733 and perplexity is 44.62959663577366
At time: 684.2887651920319 and batch: 1650, loss is 3.732006368637085 and perplexity is 41.76281576554394
At time: 685.3386421203613 and batch: 1700, loss is 3.765450291633606 and perplexity is 43.18314649213269
At time: 686.3888845443726 and batch: 1750, loss is 3.7623008584976194 and perplexity is 43.04735800028175
At time: 687.4406478404999 and batch: 1800, loss is 3.7161108112335204 and perplexity is 41.10422076466861
At time: 688.4926614761353 and batch: 1850, loss is 3.7341318225860594 and perplexity is 41.85167510699996
At time: 689.5432105064392 and batch: 1900, loss is 3.8188964414596556 and perplexity is 45.55390916641604
At time: 690.5928275585175 and batch: 1950, loss is 3.7755266857147216 and perplexity is 43.620476548539955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486507539970931 and perplexity of 88.81073567849006
finished 16 epochs...
Completing Train Step...
At time: 693.9296064376831 and batch: 50, loss is 3.955070219039917 and perplexity is 52.19935920463227
At time: 695.0151541233063 and batch: 100, loss is 3.925460262298584 and perplexity is 50.67639712700864
At time: 696.0753149986267 and batch: 150, loss is 3.902557454109192 and perplexity is 49.528955299940726
At time: 697.1339240074158 and batch: 200, loss is 3.8800519371032713 and perplexity is 48.426730150116555
At time: 698.1924364566803 and batch: 250, loss is 3.8827268505096435 and perplexity is 48.556440864945145
At time: 699.2509291172028 and batch: 300, loss is 3.900205760002136 and perplexity is 49.412615199415534
At time: 700.309680223465 and batch: 350, loss is 3.9042975807189944 and perplexity is 49.61521698437313
At time: 701.3683717250824 and batch: 400, loss is 3.866905369758606 and perplexity is 47.794251452180255
At time: 702.427729845047 and batch: 450, loss is 3.9066090869903562 and perplexity is 49.73003552034694
At time: 703.4861857891083 and batch: 500, loss is 3.9418211555480958 and perplexity is 51.5123278910063
At time: 704.5443112850189 and batch: 550, loss is 3.9026819372177126 and perplexity is 49.535121202025614
At time: 705.6016614437103 and batch: 600, loss is 3.8827481031417848 and perplexity is 48.55747282808686
At time: 706.6607263088226 and batch: 650, loss is 3.8958589172363283 and perplexity is 49.1982924815438
At time: 707.7198271751404 and batch: 700, loss is 3.9268669080734253 and perplexity is 50.7477310259132
At time: 708.8218531608582 and batch: 750, loss is 3.89578679561615 and perplexity is 49.19474434893011
At time: 709.8832547664642 and batch: 800, loss is 3.8526315593719485 and perplexity is 47.116891126311266
At time: 710.9352052211761 and batch: 850, loss is 3.8594928646087645 and perplexity is 47.44128611200445
At time: 711.9857935905457 and batch: 900, loss is 3.824294242858887 and perplexity is 45.80046495199467
At time: 713.0363836288452 and batch: 950, loss is 3.9329945993423463 and perplexity is 51.059652156416014
At time: 714.0873091220856 and batch: 1000, loss is 3.879566674232483 and perplexity is 48.40323615686335
At time: 715.1489975452423 and batch: 1050, loss is 3.8482981634140017 and perplexity is 46.91315673047292
At time: 716.2072048187256 and batch: 1100, loss is 3.8761200141906738 and perplexity is 48.23669382916976
At time: 717.2715871334076 and batch: 1150, loss is 3.842655243873596 and perplexity is 46.64917507576211
At time: 718.325644493103 and batch: 1200, loss is 3.887316541671753 and perplexity is 48.77981214292222
At time: 719.3769955635071 and batch: 1250, loss is 3.872892394065857 and perplexity is 48.0812550889558
At time: 720.4282011985779 and batch: 1300, loss is 3.872190399169922 and perplexity is 48.0475141376666
At time: 721.4798231124878 and batch: 1350, loss is 3.7457394409179687 and perplexity is 42.34030379953422
At time: 722.5312991142273 and batch: 1400, loss is 3.779297351837158 and perplexity is 43.78526528811883
At time: 723.582704782486 and batch: 1450, loss is 3.6832989978790285 and perplexity is 39.777403423495784
At time: 724.6331663131714 and batch: 1500, loss is 3.6977633476257323 and perplexity is 40.35693889647403
At time: 725.6856217384338 and batch: 1550, loss is 3.710940022468567 and perplexity is 40.892228078783866
At time: 726.7426567077637 and batch: 1600, loss is 3.7993959331512452 and perplexity is 44.67419014366506
At time: 727.806723356247 and batch: 1650, loss is 3.733128409385681 and perplexity is 41.809701645623974
At time: 728.8636419773102 and batch: 1700, loss is 3.7667211580276487 and perplexity is 43.23806138915605
At time: 729.9222235679626 and batch: 1750, loss is 3.763736505508423 and perplexity is 43.109203194429554
At time: 730.9849569797516 and batch: 1800, loss is 3.717518033981323 and perplexity is 41.16210427710496
At time: 732.0452854633331 and batch: 1850, loss is 3.735545959472656 and perplexity is 41.91090097140448
At time: 733.1034822463989 and batch: 1900, loss is 3.8201456451416016 and perplexity is 45.61085083594054
At time: 734.159108877182 and batch: 1950, loss is 3.776691727638245 and perplexity is 43.67132584747401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486451046965843 and perplexity of 88.80571863486284
finished 17 epochs...
Completing Train Step...
At time: 737.5144422054291 and batch: 50, loss is 3.953988137245178 and perplexity is 52.14290577746125
At time: 738.5677633285522 and batch: 100, loss is 3.9239306020736695 and perplexity is 50.59893871561048
At time: 739.6137306690216 and batch: 150, loss is 3.9007391357421874 and perplexity is 49.43897771955476
At time: 740.6584966182709 and batch: 200, loss is 3.878050503730774 and perplexity is 48.32990420393479
At time: 741.7034957408905 and batch: 250, loss is 3.880551633834839 and perplexity is 48.45093487590061
At time: 742.7474994659424 and batch: 300, loss is 3.8979056453704835 and perplexity is 49.29909112944451
At time: 743.7915909290314 and batch: 350, loss is 3.9019867753982544 and perplexity is 49.50069824319332
At time: 744.843400478363 and batch: 400, loss is 3.8645197916030884 and perplexity is 47.68037042001587
At time: 745.8957705497742 and batch: 450, loss is 3.9042619371414187 and perplexity is 49.61344855205442
At time: 746.9513282775879 and batch: 500, loss is 3.9395226287841796 and perplexity is 51.39406139809585
At time: 748.009241104126 and batch: 550, loss is 3.9004426050186156 and perplexity is 49.42431971710037
At time: 749.0538115501404 and batch: 600, loss is 3.8806183624267576 and perplexity is 48.454168046433274
At time: 750.1036939620972 and batch: 650, loss is 3.8937841272354126 and perplexity is 49.09632217630557
At time: 751.1600251197815 and batch: 700, loss is 3.9249335861206056 and perplexity is 50.64971410312939
At time: 752.2047464847565 and batch: 750, loss is 3.894032154083252 and perplexity is 49.10850089259734
At time: 753.24915599823 and batch: 800, loss is 3.8509277391433714 and perplexity is 47.036680765524466
At time: 754.2940425872803 and batch: 850, loss is 3.857787222862244 and perplexity is 47.36043724310671
At time: 755.3383498191833 and batch: 900, loss is 3.82293984413147 and perplexity is 45.738474849682625
At time: 756.3840434551239 and batch: 950, loss is 3.931635355949402 and perplexity is 50.99029680765423
At time: 757.4280967712402 and batch: 1000, loss is 3.8782206535339356 and perplexity is 48.33812822726004
At time: 758.4719407558441 and batch: 1050, loss is 3.847043709754944 and perplexity is 46.85434324646221
At time: 759.5158264636993 and batch: 1100, loss is 3.8750041246414186 and perplexity is 48.182897027861706
At time: 760.5604810714722 and batch: 1150, loss is 3.8416728258132933 and perplexity is 46.60336858791408
At time: 761.645902633667 and batch: 1200, loss is 3.8863613319396975 and perplexity is 48.73323943852687
At time: 762.690705537796 and batch: 1250, loss is 3.8721805143356325 and perplexity is 48.04703919829869
At time: 763.7399425506592 and batch: 1300, loss is 3.87168833732605 and perplexity is 48.023397368686524
At time: 764.7893023490906 and batch: 1350, loss is 3.745407190322876 and perplexity is 42.326238545124376
At time: 765.8406558036804 and batch: 1400, loss is 3.7791355991363527 and perplexity is 43.778183475969556
At time: 766.8912060260773 and batch: 1450, loss is 3.6833159732818603 and perplexity is 39.77807866667375
At time: 767.9406912326813 and batch: 1500, loss is 3.6980932998657225 and perplexity is 40.37025695590301
At time: 768.9896709918976 and batch: 1550, loss is 3.7114573907852173 and perplexity is 40.91338989574385
At time: 770.0409555435181 and batch: 1600, loss is 3.800036940574646 and perplexity is 44.702835811243496
At time: 771.0914669036865 and batch: 1650, loss is 3.7338634157180786 and perplexity is 41.84044333737423
At time: 772.1431357860565 and batch: 1700, loss is 3.767572364807129 and perplexity is 43.27488158872064
At time: 773.194581747055 and batch: 1750, loss is 3.7647145557403565 and perplexity is 43.151386786085475
At time: 774.257123708725 and batch: 1800, loss is 3.718483734130859 and perplexity is 41.20187372695174
At time: 775.3123686313629 and batch: 1850, loss is 3.736531639099121 and perplexity is 41.95223205887789
At time: 776.358363866806 and batch: 1900, loss is 3.8210039043426516 and perplexity is 45.65001357182344
At time: 777.4009213447571 and batch: 1950, loss is 3.777490234375 and perplexity is 43.706211621775516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486449627543605 and perplexity of 88.80559258214038
finished 18 epochs...
Completing Train Step...
At time: 780.733154296875 and batch: 50, loss is 3.952880940437317 and perplexity is 52.085205267436606
At time: 781.804030418396 and batch: 100, loss is 3.922499408721924 and perplexity is 50.52657364746973
At time: 782.8635671138763 and batch: 150, loss is 3.8991061210632325 and perplexity is 49.358309027731984
At time: 783.9120733737946 and batch: 200, loss is 3.876285352706909 and perplexity is 48.24466987191094
At time: 784.9616494178772 and batch: 250, loss is 3.878647255897522 and perplexity is 48.358753786156406
At time: 786.0162711143494 and batch: 300, loss is 3.8959255981445313 and perplexity is 49.2015731777472
At time: 787.0694849491119 and batch: 350, loss is 3.9000191640853883 and perplexity is 49.40339586735511
At time: 788.1466565132141 and batch: 400, loss is 3.86249005317688 and perplexity is 47.583689891282965
At time: 789.1967775821686 and batch: 450, loss is 3.9022728538513185 and perplexity is 49.51486135215588
At time: 790.2418553829193 and batch: 500, loss is 3.937563629150391 and perplexity is 51.29347900324232
At time: 791.2873635292053 and batch: 550, loss is 3.8985411643981935 and perplexity is 49.33043159758318
At time: 792.3305103778839 and batch: 600, loss is 3.8787968444824217 and perplexity is 48.36598824478553
At time: 793.3733732700348 and batch: 650, loss is 3.892008123397827 and perplexity is 49.00920430344624
At time: 794.4166963100433 and batch: 700, loss is 3.923278546333313 and perplexity is 50.565956141572
At time: 795.4611535072327 and batch: 750, loss is 3.8925123167037965 and perplexity is 49.0339206465707
At time: 796.5047197341919 and batch: 800, loss is 3.8494519996643066 and perplexity is 46.96731807197545
At time: 797.548202753067 and batch: 850, loss is 3.8563108110427855 and perplexity is 47.29056532634034
At time: 798.5920820236206 and batch: 900, loss is 3.8217258405685426 and perplexity is 45.68298186940562
At time: 799.635814666748 and batch: 950, loss is 3.9304306650161744 and perplexity is 50.92890624515906
At time: 800.6810629367828 and batch: 1000, loss is 3.877032370567322 and perplexity is 48.28072296645117
At time: 801.7257544994354 and batch: 1050, loss is 3.8459575462341307 and perplexity is 46.8034793962661
At time: 802.7708542346954 and batch: 1100, loss is 3.87402907371521 and perplexity is 48.13593914637053
At time: 803.815895318985 and batch: 1150, loss is 3.840804271697998 and perplexity is 46.56290861372252
At time: 804.8600082397461 and batch: 1200, loss is 3.8855199337005617 and perplexity is 48.69225262221151
At time: 805.9041283130646 and batch: 1250, loss is 3.87153920173645 and perplexity is 48.01623590503318
At time: 806.9468212127686 and batch: 1300, loss is 3.8712127780914307 and perplexity is 48.00056482813312
At time: 807.9897983074188 and batch: 1350, loss is 3.7450528049468996 and perplexity is 42.31124140270484
At time: 809.033910036087 and batch: 1400, loss is 3.7789229774475097 and perplexity is 43.768876274155964
At time: 810.0780737400055 and batch: 1450, loss is 3.683254771232605 and perplexity is 39.77564424124059
At time: 811.1346116065979 and batch: 1500, loss is 3.6982545232772828 and perplexity is 40.376766111155014
At time: 812.1821155548096 and batch: 1550, loss is 3.7117489194869995 and perplexity is 40.925319061948336
At time: 813.2302665710449 and batch: 1600, loss is 3.800437026023865 and perplexity is 44.720724343622535
At time: 814.2787444591522 and batch: 1650, loss is 3.7343408823013307 and perplexity is 41.86042552092911
At time: 815.3238804340363 and batch: 1700, loss is 3.7681458044052123 and perplexity is 43.29970423589018
At time: 816.3754661083221 and batch: 1750, loss is 3.7653944301605224 and perplexity is 43.1807342853326
At time: 817.4242730140686 and batch: 1800, loss is 3.7191662645339965 and perplexity is 41.23000485752048
At time: 818.469945192337 and batch: 1850, loss is 3.7372466373443602 and perplexity is 41.98223855720235
At time: 819.5159492492676 and batch: 1900, loss is 3.8216222095489503 and perplexity is 45.67824794071164
At time: 820.5642609596252 and batch: 1950, loss is 3.7780643367767333 and perplexity is 43.73131066685989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486474041606105 and perplexity of 88.80776071389434
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 823.8518164157867 and batch: 50, loss is 3.952333884239197 and perplexity is 52.056719525425976
At time: 824.9220957756042 and batch: 100, loss is 3.922415566444397 and perplexity is 50.522337562043504
At time: 825.9674332141876 and batch: 150, loss is 3.899210786819458 and perplexity is 49.36347542284
At time: 827.0119504928589 and batch: 200, loss is 3.876455011367798 and perplexity is 48.25285569237446
At time: 828.0564248561859 and batch: 250, loss is 3.8790514612197877 and perplexity is 48.37830460282081
At time: 829.1000790596008 and batch: 300, loss is 3.895834412574768 and perplexity is 49.19708690880833
At time: 830.1463069915771 and batch: 350, loss is 3.8997474002838133 and perplexity is 49.389971636876055
At time: 831.1921582221985 and batch: 400, loss is 3.862504315376282 and perplexity is 47.584368544196
At time: 832.2366652488708 and batch: 450, loss is 3.902423663139343 and perplexity is 49.52232921624052
At time: 833.2830979824066 and batch: 500, loss is 3.937667450904846 and perplexity is 51.29880465867922
At time: 834.3281345367432 and batch: 550, loss is 3.8992645072937013 and perplexity is 49.36612732338005
At time: 835.375403881073 and batch: 600, loss is 3.878912606239319 and perplexity is 48.371587500642406
At time: 836.4199783802032 and batch: 650, loss is 3.8917727661132813 and perplexity is 48.997670987481825
At time: 837.465325832367 and batch: 700, loss is 3.9231629371643066 and perplexity is 50.56011059130858
At time: 838.5104899406433 and batch: 750, loss is 3.8921195030212403 and perplexity is 49.01466323416651
At time: 839.5550954341888 and batch: 800, loss is 3.849250497817993 and perplexity is 46.95785502411038
At time: 840.6260018348694 and batch: 850, loss is 3.856031069755554 and perplexity is 47.277338052915546
At time: 841.6713032722473 and batch: 900, loss is 3.820395965576172 and perplexity is 45.62226959305741
At time: 842.7160367965698 and batch: 950, loss is 3.929345669746399 and perplexity is 50.87367858907892
At time: 843.7622768878937 and batch: 1000, loss is 3.875688977241516 and perplexity is 48.21590651219687
At time: 844.8063571453094 and batch: 1050, loss is 3.844697608947754 and perplexity is 46.7445470807494
At time: 845.8521237373352 and batch: 1100, loss is 3.8727414131164553 and perplexity is 48.0739962833985
At time: 846.8965153694153 and batch: 1150, loss is 3.839536261558533 and perplexity is 46.50390379074014
At time: 847.941948890686 and batch: 1200, loss is 3.8844207954406738 and perplexity is 48.63876250629591
At time: 849.0037672519684 and batch: 1250, loss is 3.870252499580383 and perplexity is 47.95449304162416
At time: 850.0495409965515 and batch: 1300, loss is 3.86966712474823 and perplexity is 47.92642990283787
At time: 851.0962817668915 and batch: 1350, loss is 3.742968158721924 and perplexity is 42.22312930622473
At time: 852.141215801239 and batch: 1400, loss is 3.776600947380066 and perplexity is 43.66736153318203
At time: 853.1846489906311 and batch: 1450, loss is 3.680878748893738 and perplexity is 39.68124860945454
At time: 854.2329018115997 and batch: 1500, loss is 3.6948202657699585 and perplexity is 40.23833973098542
At time: 855.2797453403473 and batch: 1550, loss is 3.707970628738403 and perplexity is 40.77098305430983
At time: 856.3230319023132 and batch: 1600, loss is 3.7965742349624634 and perplexity is 44.54831074261113
At time: 857.3664443492889 and batch: 1650, loss is 3.7306394290924074 and perplexity is 41.705767520810774
At time: 858.4119143486023 and batch: 1700, loss is 3.7644556093215944 and perplexity is 43.14021433560804
At time: 859.4575674533844 and batch: 1750, loss is 3.761531491279602 and perplexity is 43.01425151137076
At time: 860.5030016899109 and batch: 1800, loss is 3.7151754474639893 and perplexity is 41.06579134133751
At time: 861.5484976768494 and batch: 1850, loss is 3.733604612350464 and perplexity is 41.82961629083451
At time: 862.5934150218964 and batch: 1900, loss is 3.8177412223815916 and perplexity is 45.50131480631976
At time: 863.6384780406952 and batch: 1950, loss is 3.775110754966736 and perplexity is 43.602337223714606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486390295694041 and perplexity of 88.80032373838752
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
4449.817974805832


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.41794011582878}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6360119204925818, 'rnn_dropout': 0.965771331349581, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.35120415851347}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.3686534261327181, 'rnn_dropout': 0.8565517612572858, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -88.80032373838752}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.32275736599723115, 'rnn_dropout': 1.0, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6266937255859375 and batch: 50, loss is 7.16801381111145 and perplexity is 1297.2654281090486
At time: 2.7282629013061523 and batch: 100, loss is 6.405640621185302 and perplexity is 605.2494101037456
At time: 3.7896854877471924 and batch: 150, loss is 6.14520975112915 and perplexity is 466.4774829811204
At time: 4.850493431091309 and batch: 200, loss is 5.999622087478638 and perplexity is 403.27636150498887
At time: 5.912854194641113 and batch: 250, loss is 5.941094532012939 and perplexity is 380.35100814549446
At time: 6.9745893478393555 and batch: 300, loss is 5.892114944458008 and perplexity is 362.1704453268111
At time: 8.029633522033691 and batch: 350, loss is 5.821352853775024 and perplexity is 337.4282360493804
At time: 9.084180355072021 and batch: 400, loss is 5.7680378341674805 and perplexity is 319.9094011072569
At time: 10.138420581817627 and batch: 450, loss is 5.68811297416687 and perplexity is 295.3357882220996
At time: 11.193003177642822 and batch: 500, loss is 5.668248376846313 and perplexity is 289.52694786586176
At time: 12.246771812438965 and batch: 550, loss is 5.613163204193115 and perplexity is 274.0096169673485
At time: 13.300915718078613 and batch: 600, loss is 5.639571323394775 and perplexity is 281.3420878502375
At time: 14.35482931137085 and batch: 650, loss is 5.722166500091553 and perplexity is 305.56621558702113
At time: 15.408469676971436 and batch: 700, loss is 5.640937433242798 and perplexity is 281.72669469489756
At time: 16.462504625320435 and batch: 750, loss is 5.583562622070312 and perplexity is 266.0176399196452
At time: 17.516419172286987 and batch: 800, loss is 5.572803153991699 and perplexity is 263.1707744577812
At time: 18.569672107696533 and batch: 850, loss is 5.5941484260559085 and perplexity is 268.84860811344254
At time: 19.623220443725586 and batch: 900, loss is 5.596767282485962 and perplexity is 269.55360676170216
At time: 20.677667140960693 and batch: 950, loss is 5.625727605819702 and perplexity is 277.4741028641912
At time: 21.732490062713623 and batch: 1000, loss is 5.6146249580383305 and perplexity is 274.4104444627714
At time: 22.786710739135742 and batch: 1050, loss is 5.504601964950561 and perplexity is 245.8205909922377
At time: 23.84122133255005 and batch: 1100, loss is 5.594950466156006 and perplexity is 269.06432197202383
At time: 24.895487308502197 and batch: 1150, loss is 5.494627408981323 and perplexity is 243.3808277544738
At time: 25.950218200683594 and batch: 1200, loss is 5.571431722640991 and perplexity is 262.8101011829482
At time: 27.004233360290527 and batch: 1250, loss is 5.513916339874267 and perplexity is 248.1209527254004
At time: 28.057701587677002 and batch: 1300, loss is 5.531986351013184 and perplexity is 252.6452550944525
At time: 29.11211585998535 and batch: 1350, loss is 5.493299951553345 and perplexity is 243.05796440792844
At time: 30.16624665260315 and batch: 1400, loss is 5.512749462127686 and perplexity is 247.83159476272078
At time: 31.22044348716736 and batch: 1450, loss is 5.459928321838379 and perplexity is 235.0805736179807
At time: 32.27423286437988 and batch: 1500, loss is 5.443347997665406 and perplexity is 231.2149963188246
At time: 33.328452348709106 and batch: 1550, loss is 5.424498777389527 and perplexity is 226.89759160626835
At time: 34.38350701332092 and batch: 1600, loss is 5.46558123588562 and perplexity is 236.4132270336343
At time: 35.437047243118286 and batch: 1650, loss is 5.444021167755127 and perplexity is 231.37069573885816
At time: 36.49268960952759 and batch: 1700, loss is 5.4562497806549075 and perplexity is 234.21740861383893
At time: 37.54808306694031 and batch: 1750, loss is 5.472487831115723 and perplexity is 238.05168908386264
At time: 38.60298252105713 and batch: 1800, loss is 5.453633966445923 and perplexity is 233.60554000458816
At time: 39.65870118141174 and batch: 1850, loss is 5.434182415008545 and perplexity is 229.10545849832323
At time: 40.713706254959106 and batch: 1900, loss is 5.451177892684936 and perplexity is 233.03249158002788
At time: 41.76953125 and batch: 1950, loss is 5.382691431045532 and perplexity is 217.60716265335333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.9762235419694765 and perplexity of 144.92603980345797
finished 1 epochs...
Completing Train Step...
At time: 45.10247278213501 and batch: 50, loss is 5.196998558044434 and perplexity is 180.72897945615466
At time: 46.144890546798706 and batch: 100, loss is 5.125298471450805 and perplexity is 168.22434432355166
At time: 47.18679761886597 and batch: 150, loss is 5.058011245727539 and perplexity is 157.27741895079367
At time: 48.22743511199951 and batch: 200, loss is 5.033432216644287 and perplexity is 153.458813742636
At time: 49.26836442947388 and batch: 250, loss is 5.04271092414856 and perplexity is 154.88933964166125
At time: 50.30981183052063 and batch: 300, loss is 5.072370853424072 and perplexity is 159.5521540511968
At time: 51.350356340408325 and batch: 350, loss is 5.054998912811279 and perplexity is 156.80435986814413
At time: 52.391650438308716 and batch: 400, loss is 5.029302501678467 and perplexity is 152.826379368559
At time: 53.43375086784363 and batch: 450, loss is 4.987901630401612 and perplexity is 146.62841983750744
At time: 54.47451853752136 and batch: 500, loss is 4.982298774719238 and perplexity is 145.8091791490287
At time: 55.541178941726685 and batch: 550, loss is 4.936532344818115 and perplexity is 139.28641390228444
At time: 56.58248162269592 and batch: 600, loss is 4.9348485565185545 and perplexity is 139.0520824059475
At time: 57.62494516372681 and batch: 650, loss is 5.005721273422242 and perplexity is 149.2647050059325
At time: 58.66635513305664 and batch: 700, loss is 4.991566095352173 and perplexity is 147.16672023185052
At time: 59.70691776275635 and batch: 750, loss is 4.9448575687408445 and perplexity is 140.45084483605953
At time: 60.74678134918213 and batch: 800, loss is 4.916380796432495 and perplexity is 136.50766903214915
At time: 61.78890776634216 and batch: 850, loss is 4.923289213180542 and perplexity is 137.45398591114113
At time: 62.83122634887695 and batch: 900, loss is 4.946596641540527 and perplexity is 140.6953115911352
At time: 63.87303066253662 and batch: 950, loss is 5.000859880447388 and perplexity is 148.54083155988215
At time: 64.91966938972473 and batch: 1000, loss is 4.979365110397339 and perplexity is 145.38205079429727
At time: 65.97450137138367 and batch: 1050, loss is 4.889078407287598 and perplexity is 132.83110144994606
At time: 67.02029395103455 and batch: 1100, loss is 4.973886041641236 and perplexity is 144.58767076078897
At time: 68.0701048374176 and batch: 1150, loss is 4.892653112411499 and perplexity is 133.30678317331743
At time: 69.1167094707489 and batch: 1200, loss is 4.966686820983886 and perplexity is 143.55049014037033
At time: 70.16299939155579 and batch: 1250, loss is 4.924783239364624 and perplexity is 137.65949924812466
At time: 71.22926235198975 and batch: 1300, loss is 4.9420442867279055 and perplexity is 140.05627228275253
At time: 72.28137969970703 and batch: 1350, loss is 4.8633049201965335 and perplexity is 129.45132220892137
At time: 73.33962416648865 and batch: 1400, loss is 4.8811180210113525 and perplexity is 131.77791203171535
At time: 74.39279222488403 and batch: 1450, loss is 4.813929481506348 and perplexity is 123.21483791958397
At time: 75.4490053653717 and batch: 1500, loss is 4.803832044601441 and perplexity is 121.97694416276522
At time: 76.49502038955688 and batch: 1550, loss is 4.801998300552368 and perplexity is 121.75347462287237
At time: 77.5432801246643 and batch: 1600, loss is 4.876531772613525 and perplexity is 131.17492956438926
At time: 78.59074425697327 and batch: 1650, loss is 4.839701080322266 and perplexity is 126.43155320189578
At time: 79.63793396949768 and batch: 1700, loss is 4.861661720275879 and perplexity is 129.23878247699764
At time: 80.68590092658997 and batch: 1750, loss is 4.8691552734375 and perplexity is 130.21087783930764
At time: 81.73418712615967 and batch: 1800, loss is 4.8342116260528565 and perplexity is 125.7394144424986
At time: 82.78225255012512 and batch: 1850, loss is 4.84655873298645 and perplexity is 127.3015565604756
At time: 83.82854175567627 and batch: 1900, loss is 4.9069705581665035 and perplexity is 135.2291244807076
At time: 84.87536764144897 and batch: 1950, loss is 4.834179401397705 and perplexity is 125.73536259851424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.724479355922965 and perplexity of 112.67182118408074
finished 2 epochs...
Completing Train Step...
At time: 88.16477346420288 and batch: 50, loss is 4.755855093002319 and perplexity is 116.26302637195603
At time: 89.2352831363678 and batch: 100, loss is 4.715303344726562 and perplexity is 111.64267225354584
At time: 90.27886390686035 and batch: 150, loss is 4.663432207107544 and perplexity is 105.99926998003436
At time: 91.32443904876709 and batch: 200, loss is 4.6519139289855955 and perplexity is 104.78534548862748
At time: 92.36686897277832 and batch: 250, loss is 4.664060707092285 and perplexity is 106.06591145949014
At time: 93.40957570075989 and batch: 300, loss is 4.689580059051513 and perplexity is 108.80747749664937
At time: 94.45404767990112 and batch: 350, loss is 4.70643012046814 and perplexity is 110.65642385836354
At time: 95.49727940559387 and batch: 400, loss is 4.671692686080933 and perplexity is 106.87850115666247
At time: 96.54147148132324 and batch: 450, loss is 4.656454858779907 and perplexity is 105.26225036225587
At time: 97.58613204956055 and batch: 500, loss is 4.667164297103882 and perplexity is 106.39560791954305
At time: 98.62963318824768 and batch: 550, loss is 4.626399040222168 and perplexity is 102.14557893728933
At time: 99.67221713066101 and batch: 600, loss is 4.608561124801636 and perplexity is 100.3396694550508
At time: 100.71695637702942 and batch: 650, loss is 4.678821363449097 and perplexity is 107.64312565161023
At time: 101.76027035713196 and batch: 700, loss is 4.680505838394165 and perplexity is 107.82460060187204
At time: 102.80466365814209 and batch: 750, loss is 4.643161888122559 and perplexity is 103.87226136621634
At time: 103.84816122055054 and batch: 800, loss is 4.615014686584472 and perplexity is 100.98931170964673
At time: 104.89073181152344 and batch: 850, loss is 4.620657796859741 and perplexity is 101.56081654804518
At time: 105.93572354316711 and batch: 900, loss is 4.638125238418579 and perplexity is 103.35040847006152
At time: 106.97838282585144 and batch: 950, loss is 4.702302207946778 and perplexity is 110.2005852988759
At time: 108.0210177898407 and batch: 1000, loss is 4.682880506515503 and perplexity is 108.08095249849066
At time: 109.09033823013306 and batch: 1050, loss is 4.607551507949829 and perplexity is 100.23841595608455
At time: 110.13367629051208 and batch: 1100, loss is 4.684642381668091 and perplexity is 108.27154549439436
At time: 111.17962384223938 and batch: 1150, loss is 4.6156243896484375 and perplexity is 101.05090397701288
At time: 112.22988224029541 and batch: 1200, loss is 4.680012102127075 and perplexity is 107.77137682640577
At time: 113.27434492111206 and batch: 1250, loss is 4.652420625686646 and perplexity is 104.83845333115305
At time: 114.3175265789032 and batch: 1300, loss is 4.663543472290039 and perplexity is 106.0110646643097
At time: 115.36114573478699 and batch: 1350, loss is 4.5748566627502445 and perplexity is 97.01413240135471
At time: 116.40534806251526 and batch: 1400, loss is 4.5911466503143314 and perplexity is 98.6074336065876
At time: 117.45035552978516 and batch: 1450, loss is 4.518486957550049 and perplexity is 91.6967518865029
At time: 118.49394178390503 and batch: 1500, loss is 4.517231912612915 and perplexity is 91.58174052960321
At time: 119.53751921653748 and batch: 1550, loss is 4.523061084747314 and perplexity is 92.11714522653496
At time: 120.5820701122284 and batch: 1600, loss is 4.615480861663818 and perplexity is 101.0364013852099
At time: 121.62563562393188 and batch: 1650, loss is 4.565381383895874 and perplexity is 96.09923773009933
At time: 122.66968560218811 and batch: 1700, loss is 4.591786441802978 and perplexity is 98.67054198927674
At time: 123.71390533447266 and batch: 1750, loss is 4.605838441848755 and perplexity is 100.06684791933566
At time: 124.75905179977417 and batch: 1800, loss is 4.565972528457642 and perplexity is 96.15606306621292
At time: 125.80897855758667 and batch: 1850, loss is 4.5889011669158934 and perplexity is 98.38626066447938
At time: 126.85371088981628 and batch: 1900, loss is 4.664277391433716 and perplexity is 106.08889677185168
At time: 127.89733672142029 and batch: 1950, loss is 4.594429416656494 and perplexity is 98.93167067680902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.64821408293968 and perplexity of 104.39837215476635
finished 3 epochs...
Completing Train Step...
At time: 131.21077823638916 and batch: 50, loss is 4.526086711883545 and perplexity is 92.39627942590603
At time: 132.26173543930054 and batch: 100, loss is 4.494798860549927 and perplexity is 89.55015510460342
At time: 133.31322050094604 and batch: 150, loss is 4.45031322479248 and perplexity is 85.65376868482488
At time: 134.3639464378357 and batch: 200, loss is 4.442523422241211 and perplexity is 84.98913478331427
At time: 135.44167590141296 and batch: 250, loss is 4.450182838439941 and perplexity is 85.64260133039599
At time: 136.49182152748108 and batch: 300, loss is 4.472975721359253 and perplexity is 87.61705943220265
At time: 137.54167318344116 and batch: 350, loss is 4.48970700263977 and perplexity is 89.09533735532735
At time: 138.59206748008728 and batch: 400, loss is 4.456020641326904 and perplexity is 86.1440281470997
At time: 139.64272022247314 and batch: 450, loss is 4.457623805999756 and perplexity is 86.28224196995896
At time: 140.69384908676147 and batch: 500, loss is 4.473644762039185 and perplexity is 87.6756984229666
At time: 141.74334502220154 and batch: 550, loss is 4.43364857673645 and perplexity is 84.23820645773323
At time: 142.79454350471497 and batch: 600, loss is 4.416402015686035 and perplexity is 82.79784344369584
At time: 143.84531354904175 and batch: 650, loss is 4.482698707580567 and perplexity is 88.47311385246141
At time: 144.89607548713684 and batch: 700, loss is 4.4878629875183105 and perplexity is 88.93119559245115
At time: 145.9462184906006 and batch: 750, loss is 4.4556547546386716 and perplexity is 86.11251495940945
At time: 146.99676609039307 and batch: 800, loss is 4.424212884902954 and perplexity is 83.44709889408101
At time: 148.04706001281738 and batch: 850, loss is 4.430263938903809 and perplexity is 83.95357260018889
At time: 149.09821844100952 and batch: 900, loss is 4.441207342147827 and perplexity is 84.87735584602314
At time: 150.14945936203003 and batch: 950, loss is 4.515342636108398 and perplexity is 91.40888064045816
At time: 151.20034337043762 and batch: 1000, loss is 4.490393629074097 and perplexity is 89.15653357619794
At time: 152.25147771835327 and batch: 1050, loss is 4.42806303024292 and perplexity is 83.7690016415564
At time: 153.30207777023315 and batch: 1100, loss is 4.4998892974853515 and perplexity is 90.00716672928712
At time: 154.3527135848999 and batch: 1150, loss is 4.4329673957824705 and perplexity is 84.18084453503943
At time: 155.40398001670837 and batch: 1200, loss is 4.491703310012817 and perplexity is 89.27337668568035
At time: 156.45476031303406 and batch: 1250, loss is 4.473573360443115 and perplexity is 87.66943846165097
At time: 157.50667667388916 and batch: 1300, loss is 4.477843084335327 and perplexity is 88.04456302693343
At time: 158.55653429031372 and batch: 1350, loss is 4.387104921340942 and perplexity is 80.40729624158841
At time: 159.6073031425476 and batch: 1400, loss is 4.405936574935913 and perplexity is 81.93584597813985
At time: 160.65945291519165 and batch: 1450, loss is 4.332191276550293 and perplexity is 76.11088396729855
At time: 161.7103419303894 and batch: 1500, loss is 4.336971788406372 and perplexity is 76.47560403018568
At time: 162.76067519187927 and batch: 1550, loss is 4.345014057159424 and perplexity is 77.09312118198015
At time: 163.81128787994385 and batch: 1600, loss is 4.439780178070069 and perplexity is 84.75630833062321
At time: 164.8615779876709 and batch: 1650, loss is 4.3840252304077145 and perplexity is 80.16004754059827
At time: 165.91422295570374 and batch: 1700, loss is 4.4127756786346435 and perplexity is 82.4981343078518
At time: 166.96528124809265 and batch: 1750, loss is 4.4280545616149904 and perplexity is 83.76829223605331
At time: 168.01582193374634 and batch: 1800, loss is 4.384845399856568 and perplexity is 80.22581933092927
At time: 169.066064119339 and batch: 1850, loss is 4.418052711486816 and perplexity is 82.93463036191812
At time: 170.11696791648865 and batch: 1900, loss is 4.492703237533569 and perplexity is 89.36268823699629
At time: 171.16893434524536 and batch: 1950, loss is 4.427591629028321 and perplexity is 83.72952213851072
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.61830203034157 and perplexity of 101.32184456847457
finished 4 epochs...
Completing Train Step...
At time: 174.47098851203918 and batch: 50, loss is 4.365729608535767 and perplexity is 78.70680415406251
At time: 175.5419156551361 and batch: 100, loss is 4.336287784576416 and perplexity is 76.423312310038
At time: 176.58695602416992 and batch: 150, loss is 4.2942847156524655 and perplexity is 73.27977981493216
At time: 177.63446688652039 and batch: 200, loss is 4.295859270095825 and perplexity is 73.39525370395357
At time: 178.68795895576477 and batch: 250, loss is 4.293758096694947 and perplexity is 73.24119945314538
At time: 179.7313528060913 and batch: 300, loss is 4.314435997009277 and perplexity is 74.77144023342042
At time: 180.77647590637207 and batch: 350, loss is 4.334403591156006 and perplexity is 76.27945158109797
At time: 181.82025480270386 and batch: 400, loss is 4.295384187698364 and perplexity is 73.36039319232503
At time: 182.8646125793457 and batch: 450, loss is 4.30821982383728 and perplexity is 74.30808963839804
At time: 183.90982055664062 and batch: 500, loss is 4.332128190994263 and perplexity is 76.10608262131295
At time: 184.95409393310547 and batch: 550, loss is 4.288237714767456 and perplexity is 72.83799400732504
At time: 186.00124430656433 and batch: 600, loss is 4.269391088485718 and perplexity is 71.4780985282336
At time: 187.04590010643005 and batch: 650, loss is 4.332245836257934 and perplexity is 76.11503666816019
At time: 188.09047865867615 and batch: 700, loss is 4.3427259349823 and perplexity is 76.9169243585029
At time: 189.16667580604553 and batch: 750, loss is 4.3119793796539305 and perplexity is 74.58798085267239
At time: 190.2113058567047 and batch: 800, loss is 4.2848483657836915 and perplexity is 72.5915385241112
At time: 191.2550163269043 and batch: 850, loss is 4.289495220184326 and perplexity is 72.92964579357447
At time: 192.29901099205017 and batch: 900, loss is 4.295247688293457 and perplexity is 73.35038022570807
At time: 193.34378504753113 and batch: 950, loss is 4.369477310180664 and perplexity is 79.0023271936545
At time: 194.38952827453613 and batch: 1000, loss is 4.346274309158325 and perplexity is 77.19033918877788
At time: 195.43477582931519 and batch: 1050, loss is 4.288449373245239 and perplexity is 72.85341241792247
At time: 196.47897458076477 and batch: 1100, loss is 4.3528956604003906 and perplexity is 77.70313937860126
At time: 197.53039503097534 and batch: 1150, loss is 4.29360680103302 and perplexity is 73.23011921561088
At time: 198.58139824867249 and batch: 1200, loss is 4.350058193206787 and perplexity is 77.48297177666642
At time: 199.63299822807312 and batch: 1250, loss is 4.335563640594483 and perplexity is 76.36799086111394
At time: 200.6837215423584 and batch: 1300, loss is 4.339947729110718 and perplexity is 76.70352987178985
At time: 201.73349785804749 and batch: 1350, loss is 4.247912168502808 and perplexity is 69.95919674854568
At time: 202.78346943855286 and batch: 1400, loss is 4.266848878860474 and perplexity is 71.29661699794785
At time: 203.83418798446655 and batch: 1450, loss is 4.188390870094299 and perplexity is 65.91663714356365
At time: 204.88431215286255 and batch: 1500, loss is 4.200717148780822 and perplexity is 66.7341722144979
At time: 205.9346182346344 and batch: 1550, loss is 4.203091974258423 and perplexity is 66.89284255951607
At time: 206.98414373397827 and batch: 1600, loss is 4.30243676662445 and perplexity is 73.87960188342988
At time: 208.03399181365967 and batch: 1650, loss is 4.248483462333679 and perplexity is 69.99917542475904
At time: 209.08472061157227 and batch: 1700, loss is 4.2758262348175045 and perplexity is 71.93955372519314
At time: 210.13471746444702 and batch: 1750, loss is 4.291824369430542 and perplexity is 73.09970779611258
At time: 211.18568348884583 and batch: 1800, loss is 4.249296455383301 and perplexity is 70.05610740737592
At time: 212.23532915115356 and batch: 1850, loss is 4.283576507568359 and perplexity is 72.49927106747487
At time: 213.28612232208252 and batch: 1900, loss is 4.356915960311889 and perplexity is 78.01615809592391
At time: 214.3360733985901 and batch: 1950, loss is 4.290538606643676 and perplexity is 73.00577930991378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6033756699672965 and perplexity of 99.82070931603685
finished 5 epochs...
Completing Train Step...
At time: 217.66463565826416 and batch: 50, loss is 4.238891892433166 and perplexity is 69.33098307023262
At time: 218.70921206474304 and batch: 100, loss is 4.209039549827576 and perplexity is 67.2918782669079
At time: 219.75362873077393 and batch: 150, loss is 4.170983295440674 and perplexity is 64.77911781237043
At time: 220.79850697517395 and batch: 200, loss is 4.1738255596160885 and perplexity is 64.96349908425886
At time: 221.84383368492126 and batch: 250, loss is 4.166516790390014 and perplexity is 64.49042675545681
At time: 222.88951635360718 and batch: 300, loss is 4.187472357749939 and perplexity is 65.85611969591463
At time: 223.93378281593323 and batch: 350, loss is 4.207103066444397 and perplexity is 67.16169475260921
At time: 224.98026776313782 and batch: 400, loss is 4.16760057926178 and perplexity is 64.5603586511698
At time: 226.0274829864502 and batch: 450, loss is 4.182231116294861 and perplexity is 65.5118548469895
At time: 227.07039642333984 and batch: 500, loss is 4.213148560523987 and perplexity is 67.56895017035632
At time: 228.11655282974243 and batch: 550, loss is 4.172747368812561 and perplexity is 64.89349378329884
At time: 229.16407132148743 and batch: 600, loss is 4.153288440704346 and perplexity is 63.64294260564856
At time: 230.20807576179504 and batch: 650, loss is 4.21415144443512 and perplexity is 67.63674797435532
At time: 231.25257921218872 and batch: 700, loss is 4.227583336830139 and perplexity is 68.55136627145087
At time: 232.29918694496155 and batch: 750, loss is 4.194310026168823 and perplexity is 66.30796502958138
At time: 233.34911036491394 and batch: 800, loss is 4.167043824195861 and perplexity is 64.52442434866396
At time: 234.39719533920288 and batch: 850, loss is 4.169284882545472 and perplexity is 64.66918950159332
At time: 235.44698452949524 and batch: 900, loss is 4.17256884098053 and perplexity is 64.88190952262799
At time: 236.49161005020142 and batch: 950, loss is 4.253819608688355 and perplexity is 70.37369963884464
At time: 237.53635549545288 and batch: 1000, loss is 4.226395373344421 and perplexity is 68.46997810408146
At time: 238.58098936080933 and batch: 1050, loss is 4.171227893829346 and perplexity is 64.79496461817946
At time: 239.62538409233093 and batch: 1100, loss is 4.229958128929138 and perplexity is 68.71435496998492
At time: 240.670019865036 and batch: 1150, loss is 4.179332919120789 and perplexity is 65.32226344374511
At time: 241.73917484283447 and batch: 1200, loss is 4.238438277244568 and perplexity is 69.29954061519827
At time: 242.78382062911987 and batch: 1250, loss is 4.2225689029693605 and perplexity is 68.20848038698695
At time: 243.8284454345703 and batch: 1300, loss is 4.224808769226074 and perplexity is 68.36142948944881
At time: 244.87248253822327 and batch: 1350, loss is 4.133843288421631 and perplexity is 62.41735042579656
At time: 245.9257230758667 and batch: 1400, loss is 4.156661405563354 and perplexity is 63.85797045140267
At time: 246.97230696678162 and batch: 1450, loss is 4.073882627487182 and perplexity is 58.78475940333255
At time: 248.017329454422 and batch: 1500, loss is 4.08588816165924 and perplexity is 59.49475525307351
At time: 249.0629861354828 and batch: 1550, loss is 4.090111246109009 and perplexity is 59.74653790432501
At time: 250.10840129852295 and batch: 1600, loss is 4.1933149766922 and perplexity is 66.24201813933335
At time: 251.15336847305298 and batch: 1650, loss is 4.136203756332398 and perplexity is 62.56485860422199
At time: 252.19869256019592 and batch: 1700, loss is 4.169516768455505 and perplexity is 64.68418711425237
At time: 253.24360752105713 and batch: 1750, loss is 4.179500222206116 and perplexity is 65.33319297420637
At time: 254.28984761238098 and batch: 1800, loss is 4.133244605064392 and perplexity is 62.379993380530095
At time: 255.33617305755615 and batch: 1850, loss is 4.172361221313476 and perplexity is 64.86844016047576
At time: 256.38101077079773 and batch: 1900, loss is 4.243832397460937 and perplexity is 69.67436067160779
At time: 257.4251358509064 and batch: 1950, loss is 4.18103178024292 and perplexity is 65.4333312151657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.604530795784884 and perplexity of 99.93608141631495
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 260.71450090408325 and batch: 50, loss is 4.158302507400513 and perplexity is 63.96285392271693
At time: 261.78620290756226 and batch: 100, loss is 4.1548083400726314 and perplexity is 63.73974702176056
At time: 262.8315043449402 and batch: 150, loss is 4.120475192070007 and perplexity is 61.58850167955865
At time: 263.87722301483154 and batch: 200, loss is 4.117608199119568 and perplexity is 61.41218075561287
At time: 264.92175126075745 and batch: 250, loss is 4.105662941932678 and perplexity is 60.68296049482531
At time: 265.96657252311707 and batch: 300, loss is 4.1289685392379765 and perplexity is 62.11382191151776
At time: 267.0110206604004 and batch: 350, loss is 4.145538220405578 and perplexity is 63.15160223743888
At time: 268.05589509010315 and batch: 400, loss is 4.095323634147644 and perplexity is 60.058773082375176
At time: 269.12932896614075 and batch: 450, loss is 4.108805022239685 and perplexity is 60.87393109533275
At time: 270.1786320209503 and batch: 500, loss is 4.128523483276367 and perplexity is 62.08618393545689
At time: 271.2229359149933 and batch: 550, loss is 4.081092195510864 and perplexity is 59.21010355643726
At time: 272.26793122291565 and batch: 600, loss is 4.058906855583191 and perplexity is 57.91097141049486
At time: 273.3106746673584 and batch: 650, loss is 4.110082769393921 and perplexity is 60.95176230126875
At time: 274.36523270606995 and batch: 700, loss is 4.113376712799072 and perplexity is 61.15286498533192
At time: 275.4211447238922 and batch: 750, loss is 4.066884684562683 and perplexity is 58.37482304075338
At time: 276.4714810848236 and batch: 800, loss is 4.043117341995239 and perplexity is 57.003766351587146
At time: 277.5166230201721 and batch: 850, loss is 4.041046595573425 and perplexity is 56.885848137880245
At time: 278.5626218318939 and batch: 900, loss is 4.028691973686218 and perplexity is 56.18736860312156
At time: 279.606805562973 and batch: 950, loss is 4.10490840435028 and perplexity is 60.63719019039975
At time: 280.65243768692017 and batch: 1000, loss is 4.071090693473816 and perplexity is 58.62086513154438
At time: 281.6968126296997 and batch: 1050, loss is 4.016975355148316 and perplexity is 55.53288429726263
At time: 282.7424886226654 and batch: 1100, loss is 4.0582590007781985 and perplexity is 57.87346565985696
At time: 283.7875807285309 and batch: 1150, loss is 4.007784104347229 and perplexity is 55.02480614367353
At time: 284.83249521255493 and batch: 1200, loss is 4.0545580863952635 and perplexity is 57.65967676961351
At time: 285.877064704895 and batch: 1250, loss is 4.03086669921875 and perplexity is 56.30969367174289
At time: 286.9213378429413 and batch: 1300, loss is 4.022043747901916 and perplexity is 55.81506125338046
At time: 287.9678795337677 and batch: 1350, loss is 3.923467674255371 and perplexity is 50.57552048019718
At time: 289.01399183273315 and batch: 1400, loss is 3.9376608324050903 and perplexity is 51.29846513867667
At time: 290.05880069732666 and batch: 1450, loss is 3.8483933496475218 and perplexity is 46.9176224296978
At time: 291.1030457019806 and batch: 1500, loss is 3.8570607709884643 and perplexity is 47.326044658519706
At time: 292.14816331863403 and batch: 1550, loss is 3.8597414922714233 and perplexity is 47.45308279451403
At time: 293.1942460536957 and batch: 1600, loss is 3.9500501346588135 and perplexity is 51.9379706619985
At time: 294.2409791946411 and batch: 1650, loss is 3.8822750425338746 and perplexity is 48.53450763286511
At time: 295.2866623401642 and batch: 1700, loss is 3.9012822771072386 and perplexity is 49.465837367032584
At time: 296.33318066596985 and batch: 1750, loss is 3.9015880584716798 and perplexity is 49.480965411095
At time: 297.37953662872314 and batch: 1800, loss is 3.8460793256759644 and perplexity is 46.80917944493019
At time: 298.4249041080475 and batch: 1850, loss is 3.8719194459915163 and perplexity is 48.03449727455637
At time: 299.469277381897 and batch: 1900, loss is 3.9361696004867555 and perplexity is 51.22202423982
At time: 300.51430678367615 and batch: 1950, loss is 3.8729020977020263 and perplexity is 48.081721654225426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.517710982921511 and perplexity of 91.62562513336655
finished 7 epochs...
Completing Train Step...
At time: 303.8148670196533 and batch: 50, loss is 4.0498033094406125 and perplexity is 57.386168617712485
At time: 304.8646078109741 and batch: 100, loss is 4.038162331581116 and perplexity is 56.722010723182095
At time: 305.91717171669006 and batch: 150, loss is 4.001102976799011 and perplexity is 54.658403749016536
At time: 306.9724497795105 and batch: 200, loss is 3.9998509454727174 and perplexity is 54.590012538180844
At time: 308.0269412994385 and batch: 250, loss is 3.986888065338135 and perplexity is 53.88693554566758
At time: 309.07824182510376 and batch: 300, loss is 4.011650614738464 and perplexity is 55.237971966771504
At time: 310.1344110965729 and batch: 350, loss is 4.032468123435974 and perplexity is 56.399941622192806
At time: 311.1841049194336 and batch: 400, loss is 3.984790048599243 and perplexity is 53.77399836635756
At time: 312.23502564430237 and batch: 450, loss is 4.004550566673279 and perplexity is 54.84716871344558
At time: 313.2851574420929 and batch: 500, loss is 4.027224283218384 and perplexity is 56.10496342524964
At time: 314.33799409866333 and batch: 550, loss is 3.981524705886841 and perplexity is 53.59869420252664
At time: 315.3937175273895 and batch: 600, loss is 3.9642415714263914 and perplexity is 52.68029998981722
At time: 316.44447135925293 and batch: 650, loss is 4.013760523796082 and perplexity is 55.35464210255488
At time: 317.4948101043701 and batch: 700, loss is 4.025668420791626 and perplexity is 56.01773969236128
At time: 318.5447015762329 and batch: 750, loss is 3.982880744934082 and perplexity is 53.67142542679134
At time: 319.59579253196716 and batch: 800, loss is 3.9620559644699096 and perplexity is 52.56528729174988
At time: 320.65163493156433 and batch: 850, loss is 3.961641607284546 and perplexity is 52.543510999153064
At time: 321.7494406700134 and batch: 900, loss is 3.948088512420654 and perplexity is 51.83618784609865
At time: 322.80379009246826 and batch: 950, loss is 4.028701939582825 and perplexity is 56.18792856341791
At time: 323.8533709049225 and batch: 1000, loss is 3.9971254301071166 and perplexity is 54.44142919527023
At time: 324.9042372703552 and batch: 1050, loss is 3.947097325325012 and perplexity is 51.784833940487
At time: 325.95471358299255 and batch: 1100, loss is 3.989295825958252 and perplexity is 54.01683871212011
At time: 327.0057728290558 and batch: 1150, loss is 3.9450971460342408 and perplexity is 51.6813585072705
At time: 328.0562193393707 and batch: 1200, loss is 3.99324369430542 and perplexity is 54.23051157853937
At time: 329.1059744358063 and batch: 1250, loss is 3.973993248939514 and perplexity is 53.196534270782756
At time: 330.1552448272705 and batch: 1300, loss is 3.970013446807861 and perplexity is 52.98524331727224
At time: 331.20613169670105 and batch: 1350, loss is 3.871814088821411 and perplexity is 48.0294367624414
At time: 332.25646805763245 and batch: 1400, loss is 3.8910376834869385 and perplexity is 48.96166688542384
At time: 333.3198125362396 and batch: 1450, loss is 3.8045948219299315 and perplexity is 44.90705107405001
At time: 334.37461376190186 and batch: 1500, loss is 3.8160383701324463 and perplexity is 45.42389872284567
At time: 335.42543721199036 and batch: 1550, loss is 3.8232195377349854 and perplexity is 45.75126939772585
At time: 336.4759075641632 and batch: 1600, loss is 3.9162991666793823 and perplexity is 50.21426585373501
At time: 337.5252573490143 and batch: 1650, loss is 3.8515998792648314 and perplexity is 47.0683066331639
At time: 338.57449865341187 and batch: 1700, loss is 3.8752879524230956 and perplexity is 48.19657461358749
At time: 339.6255841255188 and batch: 1750, loss is 3.8805711555480955 and perplexity is 48.451880730390585
At time: 340.6766791343689 and batch: 1800, loss is 3.8290294504165647 and perplexity is 46.01785394458622
At time: 341.72716546058655 and batch: 1850, loss is 3.859284963607788 and perplexity is 47.43142404633633
At time: 342.7791814804077 and batch: 1900, loss is 3.928056364059448 and perplexity is 50.80812913168231
At time: 343.8302035331726 and batch: 1950, loss is 3.867683596611023 and perplexity is 47.831460698791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5173002021257265 and perplexity of 91.58799481559507
finished 8 epochs...
Completing Train Step...
At time: 347.16399693489075 and batch: 50, loss is 3.995453143119812 and perplexity is 54.35046358316053
At time: 348.23426055908203 and batch: 100, loss is 3.982735552787781 and perplexity is 53.66363332302839
At time: 349.2785134315491 and batch: 150, loss is 3.9459386920928954 and perplexity is 51.7248690563259
At time: 350.3233530521393 and batch: 200, loss is 3.9439859199523926 and perplexity is 51.62396073061145
At time: 351.36754298210144 and batch: 250, loss is 3.9299246883392334 and perplexity is 50.903143924533204
At time: 352.41205883026123 and batch: 300, loss is 3.956260251998901 and perplexity is 52.26151513899356
At time: 353.45591139793396 and batch: 350, loss is 3.9781845951080324 and perplexity is 53.419967276318566
At time: 354.4993758201599 and batch: 400, loss is 3.9310356426239013 and perplexity is 50.95972641483965
At time: 355.5422406196594 and batch: 450, loss is 3.951788082122803 and perplexity is 52.02831461017305
At time: 356.5866780281067 and batch: 500, loss is 3.9762257623672483 and perplexity is 53.315428915414465
At time: 357.630384683609 and batch: 550, loss is 3.9304431676864624 and perplexity is 50.92954299646251
At time: 358.67325162887573 and batch: 600, loss is 3.9148530054092405 and perplexity is 50.14170041056231
At time: 359.7177224159241 and batch: 650, loss is 3.963764066696167 and perplexity is 52.65515090226444
At time: 360.7744743824005 and batch: 700, loss is 3.977530016899109 and perplexity is 53.38501117181837
At time: 361.827495098114 and batch: 750, loss is 3.936938099861145 and perplexity is 51.26140346291935
At time: 362.8712594509125 and batch: 800, loss is 3.9163401031494143 and perplexity is 50.21632149059928
At time: 363.91347455978394 and batch: 850, loss is 3.917408752441406 and perplexity is 50.27001381102698
At time: 364.9574236869812 and batch: 900, loss is 3.9028836154937743 and perplexity is 49.54511236734078
At time: 366.0013749599457 and batch: 950, loss is 3.9854503536224364 and perplexity is 53.809517332981564
At time: 367.0448558330536 and batch: 1000, loss is 3.954819121360779 and perplexity is 52.18625371213172
At time: 368.08774757385254 and batch: 1050, loss is 3.9067119216918944 and perplexity is 49.73514975666313
At time: 369.12991094589233 and batch: 1100, loss is 3.9489494800567626 and perplexity is 51.880836343911156
At time: 370.1738188266754 and batch: 1150, loss is 3.9065170526504516 and perplexity is 49.72545885996257
At time: 371.21632170677185 and batch: 1200, loss is 3.9560606813430788 and perplexity is 52.25108631482125
At time: 372.2603838443756 and batch: 1250, loss is 3.9380464696884157 and perplexity is 51.31825155435608
At time: 373.30436658859253 and batch: 1300, loss is 3.9352071475982666 and perplexity is 51.17274917090603
At time: 374.3486695289612 and batch: 1350, loss is 3.8377755069732666 and perplexity is 46.42209387363712
At time: 375.3919599056244 and batch: 1400, loss is 3.8587039804458616 and perplexity is 47.40387519110464
At time: 376.4345018863678 and batch: 1450, loss is 3.7729290914535523 and perplexity is 43.50731528614048
At time: 377.4767973423004 and batch: 1500, loss is 3.7862498331069947 and perplexity is 44.0907422057179
At time: 378.519779920578 and batch: 1550, loss is 3.7946506452560427 and perplexity is 44.462700436577855
At time: 379.5625534057617 and batch: 1600, loss is 3.8889379024505617 and perplexity is 48.8589659682423
At time: 380.60546827316284 and batch: 1650, loss is 3.824391179084778 and perplexity is 45.80490489140318
At time: 381.64922285079956 and batch: 1700, loss is 3.8505627059936525 and perplexity is 47.019513951211074
At time: 382.6918058395386 and batch: 1750, loss is 3.8578604793548585 and perplexity is 47.36390682971116
At time: 383.73595809936523 and batch: 1800, loss is 3.807569088935852 and perplexity is 45.04081546128493
At time: 384.77999663352966 and batch: 1850, loss is 3.8387184619903563 and perplexity is 46.46588846487879
At time: 385.83102893829346 and batch: 1900, loss is 3.9098509407043456 and perplexity is 49.891514625089535
At time: 386.8749051094055 and batch: 1950, loss is 3.8497318506240843 and perplexity is 46.980463760347035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.520522574491279 and perplexity of 91.88360146065683
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 390.18897318840027 and batch: 50, loss is 3.970666742324829 and perplexity is 53.01986964857885
At time: 391.2352523803711 and batch: 100, loss is 3.9823002672195433 and perplexity is 53.64027940108503
At time: 392.28203654289246 and batch: 150, loss is 3.952939190864563 and perplexity is 52.08823934126383
At time: 393.32725644111633 and batch: 200, loss is 3.955298891067505 and perplexity is 52.21129710282007
At time: 394.37113523483276 and batch: 250, loss is 3.942593469619751 and perplexity is 51.552126953409974
At time: 395.41559314727783 and batch: 300, loss is 3.9650541067123415 and perplexity is 52.72312198726939
At time: 396.46039605140686 and batch: 350, loss is 3.9877255582809448 and perplexity is 53.932084377171684
At time: 397.50628113746643 and batch: 400, loss is 3.9422641038894652 and perplexity is 51.53515024539456
At time: 398.5512571334839 and batch: 450, loss is 3.9634238862991333 and perplexity is 52.63724169847737
At time: 399.5965487957001 and batch: 500, loss is 3.986703510284424 and perplexity is 53.87699135703699
At time: 400.6419644355774 and batch: 550, loss is 3.9390359926223755 and perplexity is 51.36905727376654
At time: 401.7137441635132 and batch: 600, loss is 3.912192077636719 and perplexity is 50.00845432510421
At time: 402.7580146789551 and batch: 650, loss is 3.952442693710327 and perplexity is 52.062384097720276
At time: 403.80366921424866 and batch: 700, loss is 3.960009069442749 and perplexity is 52.457801709970965
At time: 404.8490741252899 and batch: 750, loss is 3.9186407709121704 and perplexity is 50.33198556390109
At time: 405.8952798843384 and batch: 800, loss is 3.8990768957138062 and perplexity is 49.35686653498234
At time: 406.9389567375183 and batch: 850, loss is 3.8999057388305665 and perplexity is 49.39779259237224
At time: 407.98995900154114 and batch: 900, loss is 3.880643343925476 and perplexity is 48.45537851928989
At time: 409.0351858139038 and batch: 950, loss is 3.9649069833755495 and perplexity is 52.71536575621181
At time: 410.08649802207947 and batch: 1000, loss is 3.9304846715927124 and perplexity is 50.931656815305956
At time: 411.1360604763031 and batch: 1050, loss is 3.8791351747512817 and perplexity is 48.38235469106803
At time: 412.18827652931213 and batch: 1100, loss is 3.9152329397201537 and perplexity is 50.16075458239343
At time: 413.232786655426 and batch: 1150, loss is 3.872942929267883 and perplexity is 48.083684946291534
At time: 414.27852392196655 and batch: 1200, loss is 3.9177493190765382 and perplexity is 50.28713701610931
At time: 415.32276606559753 and batch: 1250, loss is 3.894162583351135 and perplexity is 49.11490649614561
At time: 416.3660430908203 and batch: 1300, loss is 3.8838617324829103 and perplexity is 48.61157797550733
At time: 417.4114546775818 and batch: 1350, loss is 3.784987835884094 and perplexity is 44.03513490700712
At time: 418.4568781852722 and batch: 1400, loss is 3.8027339124679567 and perplexity is 44.8235608257872
At time: 419.5021812915802 and batch: 1450, loss is 3.71101900100708 and perplexity is 40.8954578147323
At time: 420.54924178123474 and batch: 1500, loss is 3.7219578647613525 and perplexity is 41.34526335142243
At time: 421.59387254714966 and batch: 1550, loss is 3.7306526613235476 and perplexity is 41.706319384817675
At time: 422.63850688934326 and batch: 1600, loss is 3.822865014076233 and perplexity is 45.735052365137115
At time: 423.6840658187866 and batch: 1650, loss is 3.7509636974334715 and perplexity is 42.56207920893427
At time: 424.7296769618988 and batch: 1700, loss is 3.773369393348694 and perplexity is 43.526475857421865
At time: 425.7780966758728 and batch: 1750, loss is 3.777247276306152 and perplexity is 43.69559413485752
At time: 426.82336258888245 and batch: 1800, loss is 3.7234650659561157 and perplexity is 41.4076259664419
At time: 427.8687138557434 and batch: 1850, loss is 3.7490240955352783 and perplexity is 42.47960572802545
At time: 428.91449308395386 and batch: 1900, loss is 3.820811276435852 and perplexity is 45.641220952142874
At time: 429.9584619998932 and batch: 1950, loss is 3.7649505233764646 and perplexity is 43.16157031826493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494286257721657 and perplexity of 89.50426320498848
finished 10 epochs...
Completing Train Step...
At time: 433.2551534175873 and batch: 50, loss is 3.9520918989181517 and perplexity is 52.04412408745607
At time: 434.332985162735 and batch: 100, loss is 3.9517398262023926 and perplexity is 52.02580399654062
At time: 435.38365960121155 and batch: 150, loss is 3.9156793785095214 and perplexity is 50.18315328839654
At time: 436.43411111831665 and batch: 200, loss is 3.9156419372558595 and perplexity is 50.18127440339884
At time: 437.4844226837158 and batch: 250, loss is 3.900296034812927 and perplexity is 49.417076115254496
At time: 438.53547739982605 and batch: 300, loss is 3.9221165370941162 and perplexity is 50.50723215885966
At time: 439.5865306854248 and batch: 350, loss is 3.945206422805786 and perplexity is 51.687006387862716
At time: 440.6373951435089 and batch: 400, loss is 3.9006432151794432 and perplexity is 49.43423573242107
At time: 441.68928146362305 and batch: 450, loss is 3.9233157062530517 and perplexity is 50.56783520335641
At time: 442.75024938583374 and batch: 500, loss is 3.948666477203369 and perplexity is 51.86615599657746
At time: 443.80102467536926 and batch: 550, loss is 3.9014871168136596 and perplexity is 49.47597097248366
At time: 444.85261726379395 and batch: 600, loss is 3.8775818157196045 and perplexity is 48.30725786470184
At time: 445.90431904792786 and batch: 650, loss is 3.919593482017517 and perplexity is 50.37996025488368
At time: 446.9557616710663 and batch: 700, loss is 3.9300938272476196 and perplexity is 50.91175435488889
At time: 448.0077269077301 and batch: 750, loss is 3.89047908782959 and perplexity is 48.9343247482356
At time: 449.05869913101196 and batch: 800, loss is 3.8706571102142333 and perplexity is 47.97389986528855
At time: 450.1127438545227 and batch: 850, loss is 3.8726202774047853 and perplexity is 48.068173158347214
At time: 451.1654863357544 and batch: 900, loss is 3.854319682121277 and perplexity is 47.19649739577158
At time: 452.217515707016 and batch: 950, loss is 3.939685592651367 and perplexity is 51.40243745557057
At time: 453.2682750225067 and batch: 1000, loss is 3.905838646888733 and perplexity is 49.691736262263525
At time: 454.36518001556396 and batch: 1050, loss is 3.8555150985717774 and perplexity is 47.25295060098685
At time: 455.4177520275116 and batch: 1100, loss is 3.8934941911697387 and perplexity is 49.08208944520545
At time: 456.4696640968323 and batch: 1150, loss is 3.853635768890381 and perplexity is 47.16423012201609
At time: 457.5223534107208 and batch: 1200, loss is 3.8997531509399415 and perplexity is 49.390255662435784
At time: 458.5827853679657 and batch: 1250, loss is 3.8787208366394044 and perplexity is 48.362312190049906
At time: 459.63334035873413 and batch: 1300, loss is 3.8706884384155273 and perplexity is 47.97540282482278
At time: 460.685311794281 and batch: 1350, loss is 3.7727140855789183 and perplexity is 43.49796196331012
At time: 461.73714327812195 and batch: 1400, loss is 3.7927301597595213 and perplexity is 44.377392407889026
At time: 462.7874879837036 and batch: 1450, loss is 3.703366603851318 and perplexity is 40.58370388345224
At time: 463.83772349357605 and batch: 1500, loss is 3.7159673976898193 and perplexity is 41.09832628539186
At time: 464.88928031921387 and batch: 1550, loss is 3.7265388917922975 and perplexity is 41.53510161555425
At time: 465.9432671070099 and batch: 1600, loss is 3.8201272439956666 and perplexity is 45.61001155174001
At time: 466.9933259487152 and batch: 1650, loss is 3.750402045249939 and perplexity is 42.53818083612577
At time: 468.0461046695709 and batch: 1700, loss is 3.774321265220642 and perplexity is 43.567927210534336
At time: 469.0978932380676 and batch: 1750, loss is 3.779349489212036 and perplexity is 43.78754819642119
At time: 470.1510648727417 and batch: 1800, loss is 3.727301850318909 and perplexity is 41.56680326747051
At time: 471.2036089897156 and batch: 1850, loss is 3.75407648563385 and perplexity is 42.694772362577254
At time: 472.25613808631897 and batch: 1900, loss is 3.8271922969818117 and perplexity is 45.933389696799935
At time: 473.3085026741028 and batch: 1950, loss is 3.7713320541381834 and perplexity is 43.43788793392946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494081577034883 and perplexity of 89.4859452856526
finished 11 epochs...
Completing Train Step...
At time: 476.61109709739685 and batch: 50, loss is 3.9361873960494993 and perplexity is 51.22293577267682
At time: 477.6558609008789 and batch: 100, loss is 3.93399694442749 and perplexity is 51.11085720608195
At time: 478.70126509666443 and batch: 150, loss is 3.8971986198425292 and perplexity is 49.26424773254807
At time: 479.74620819091797 and batch: 200, loss is 3.8967515802383423 and perplexity is 49.242229584599905
At time: 480.7907712459564 and batch: 250, loss is 3.8807519245147706 and perplexity is 48.4606401184926
At time: 481.86011362075806 and batch: 300, loss is 3.9028777551651 and perplexity is 49.544822017548874
At time: 482.90437626838684 and batch: 350, loss is 3.92594162940979 and perplexity is 50.70079695006502
At time: 483.9499795436859 and batch: 400, loss is 3.881427483558655 and perplexity is 48.49338920292165
At time: 484.99519872665405 and batch: 450, loss is 3.904513611793518 and perplexity is 49.625936570851195
At time: 486.04167222976685 and batch: 500, loss is 3.930424609184265 and perplexity is 50.92859782919737
At time: 487.0870716571808 and batch: 550, loss is 3.8833198022842406 and perplexity is 48.58524103043492
At time: 488.13149976730347 and batch: 600, loss is 3.8605464601516726 and perplexity is 47.49129638027354
At time: 489.17569732666016 and batch: 650, loss is 3.90284396648407 and perplexity is 49.543147991642755
At time: 490.21898913383484 and batch: 700, loss is 3.914292364120483 and perplexity is 50.1135967817871
At time: 491.26297664642334 and batch: 750, loss is 3.8752950286865233 and perplexity is 48.19691566645245
At time: 492.3076226711273 and batch: 800, loss is 3.855678315162659 and perplexity is 47.260663695928436
At time: 493.3524751663208 and batch: 850, loss is 3.8577876234054567 and perplexity is 47.360456213012206
At time: 494.3964424133301 and batch: 900, loss is 3.8398019552230833 and perplexity is 46.51626122492749
At time: 495.44098234176636 and batch: 950, loss is 3.9256940841674806 and perplexity is 50.68824776230868
At time: 496.4848048686981 and batch: 1000, loss is 3.8921866607666016 and perplexity is 49.01795505897349
At time: 497.52828311920166 and batch: 1050, loss is 3.842781662940979 and perplexity is 46.65507279375352
At time: 498.57266497612 and batch: 1100, loss is 3.881500267982483 and perplexity is 48.49691889476598
At time: 499.61725425720215 and batch: 1150, loss is 3.8425653076171873 and perplexity is 46.644979812247215
At time: 500.6624684333801 and batch: 1200, loss is 3.8891828203201295 and perplexity is 48.87093386761292
At time: 501.70651507377625 and batch: 1250, loss is 3.869206280708313 and perplexity is 47.904348381722144
At time: 502.7512876987457 and batch: 1300, loss is 3.8620635938644408 and perplexity is 47.563401709958015
At time: 503.7948989868164 and batch: 1350, loss is 3.7644950008392333 and perplexity is 43.14191372759259
At time: 504.83869552612305 and batch: 1400, loss is 3.7855089139938354 and perplexity is 44.05808663116786
At time: 505.88228607177734 and batch: 1450, loss is 3.69704065322876 and perplexity is 40.32778369927236
At time: 506.92607855796814 and batch: 1500, loss is 3.710152893066406 and perplexity is 40.860053268274086
At time: 507.9702317714691 and batch: 1550, loss is 3.721350064277649 and perplexity is 41.320141315724705
At time: 509.013614654541 and batch: 1600, loss is 3.815634126663208 and perplexity is 45.405540119362406
At time: 510.057404756546 and batch: 1650, loss is 3.7467484951019285 and perplexity is 42.38304902272953
At time: 511.1012313365936 and batch: 1700, loss is 3.7713761854171755 and perplexity is 43.43980494578048
At time: 512.1457319259644 and batch: 1750, loss is 3.7767911624908446 and perplexity is 43.675668515225176
At time: 513.1907269954681 and batch: 1800, loss is 3.7253117084503176 and perplexity is 41.48416169344899
At time: 514.2355377674103 and batch: 1850, loss is 3.752850866317749 and perplexity is 42.64247687859708
At time: 515.278933763504 and batch: 1900, loss is 3.826757311820984 and perplexity is 45.913413698841616
At time: 516.326257944107 and batch: 1950, loss is 3.7706564807891847 and perplexity is 43.408552364784576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4950200990188955 and perplexity of 89.56996923555786
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 519.6113996505737 and batch: 50, loss is 3.9290972423553465 and perplexity is 50.86104174356807
At time: 520.6822330951691 and batch: 100, loss is 3.936874952316284 and perplexity is 51.25816653334768
At time: 521.7269752025604 and batch: 150, loss is 3.9052399826049804 and perplexity is 49.66199649752136
At time: 522.7732625007629 and batch: 200, loss is 3.908420524597168 and perplexity is 49.820200015900824
At time: 523.8183195590973 and batch: 250, loss is 3.895624933242798 and perplexity is 49.18678221525565
At time: 524.8647758960724 and batch: 300, loss is 3.9154911136627195 and perplexity is 50.17370645401198
At time: 525.9115996360779 and batch: 350, loss is 3.939365334510803 and perplexity is 51.38597804230182
At time: 526.9577565193176 and batch: 400, loss is 3.8958010387420656 and perplexity is 49.19544504085826
At time: 528.0030784606934 and batch: 450, loss is 3.9195344829559327 and perplexity is 50.37698797218779
At time: 529.0550038814545 and batch: 500, loss is 3.947254486083984 and perplexity is 51.79297312385569
At time: 530.106235742569 and batch: 550, loss is 3.900222520828247 and perplexity is 49.41344340260725
At time: 531.1509783267975 and batch: 600, loss is 3.8737197732925415 and perplexity is 48.121052982314104
At time: 532.1952602863312 and batch: 650, loss is 3.9115011882781983 and perplexity is 49.973915948647154
At time: 533.2400324344635 and batch: 700, loss is 3.9191530561447143 and perplexity is 50.35777650242452
At time: 534.3102571964264 and batch: 750, loss is 3.8810460567474365 and perplexity is 48.47489605122895
At time: 535.3549311161041 and batch: 800, loss is 3.859315390586853 and perplexity is 47.432867263239075
At time: 536.3992621898651 and batch: 850, loss is 3.860652108192444 and perplexity is 47.496314007736395
At time: 537.4447205066681 and batch: 900, loss is 3.8374996995925903 and perplexity is 46.40929208301564
At time: 538.4903657436371 and batch: 950, loss is 3.928481912612915 and perplexity is 50.82975505865328
At time: 539.5355610847473 and batch: 1000, loss is 3.890809540748596 and perplexity is 48.95049791077547
At time: 540.580244064331 and batch: 1050, loss is 3.841702103614807 and perplexity is 46.60473305206364
At time: 541.6246688365936 and batch: 1100, loss is 3.8755333948135378 and perplexity is 48.20840554791877
At time: 542.6698045730591 and batch: 1150, loss is 3.8376983642578124 and perplexity is 46.41851288538399
At time: 543.722386598587 and batch: 1200, loss is 3.8820181035995485 and perplexity is 48.52203883012491
At time: 544.770491361618 and batch: 1250, loss is 3.8610075664520265 and perplexity is 47.51319996579901
At time: 545.8175003528595 and batch: 1300, loss is 3.852273874282837 and perplexity is 47.10004113058586
At time: 546.8622980117798 and batch: 1350, loss is 3.7497203826904295 and perplexity is 42.50919403163223
At time: 547.9167275428772 and batch: 1400, loss is 3.770923738479614 and perplexity is 43.42015518463683
At time: 548.9626400470734 and batch: 1450, loss is 3.678098649978638 and perplexity is 39.571084018430284
At time: 550.0094153881073 and batch: 1500, loss is 3.687180209159851 and perplexity is 39.93208791780904
At time: 551.0536894798279 and batch: 1550, loss is 3.6983511447906494 and perplexity is 40.38066756388062
At time: 552.0977783203125 and batch: 1600, loss is 3.7894739723205566 and perplexity is 44.233126306358464
At time: 553.1422121524811 and batch: 1650, loss is 3.719935293197632 and perplexity is 41.261724108000905
At time: 554.1879599094391 and batch: 1700, loss is 3.741786813735962 and perplexity is 42.17327867532116
At time: 555.2332017421722 and batch: 1750, loss is 3.7468615341186524 and perplexity is 42.38784023170849
At time: 556.278561592102 and batch: 1800, loss is 3.6964719772338865 and perplexity is 40.304856776369355
At time: 557.3213543891907 and batch: 1850, loss is 3.7248546838760377 and perplexity is 41.465206743880486
At time: 558.3663573265076 and batch: 1900, loss is 3.7977954053878786 and perplexity is 44.602745052212086
At time: 559.4112701416016 and batch: 1950, loss is 3.7450750207901002 and perplexity is 42.312181393050764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4856223882630815 and perplexity of 88.73215948518508
finished 13 epochs...
Completing Train Step...
At time: 562.7127778530121 and batch: 50, loss is 3.925730838775635 and perplexity is 50.69011082323104
At time: 563.7596926689148 and batch: 100, loss is 3.926899619102478 and perplexity is 50.74939106356776
At time: 564.8188745975494 and batch: 150, loss is 3.8903646945953367 and perplexity is 48.92872731272214
At time: 565.8759093284607 and batch: 200, loss is 3.8906280422210693 and perplexity is 48.94161427369087
At time: 566.9201323986053 and batch: 250, loss is 3.877345633506775 and perplexity is 48.295849896876206
At time: 567.9655473232269 and batch: 300, loss is 3.8970728731155395 and perplexity is 49.2580533041108
At time: 569.0115394592285 and batch: 350, loss is 3.9205364036560058 and perplexity is 50.42748701303721
At time: 570.0569484233856 and batch: 400, loss is 3.8771892547607423 and perplexity is 48.28829804292086
At time: 571.1015243530273 and batch: 450, loss is 3.9015958881378174 and perplexity is 49.48135283205102
At time: 572.1452276706696 and batch: 500, loss is 3.9294733142852785 and perplexity is 50.880172750786855
At time: 573.1907124519348 and batch: 550, loss is 3.8828718423843385 and perplexity is 48.56348166475171
At time: 574.2368788719177 and batch: 600, loss is 3.858015341758728 and perplexity is 47.37124228615801
At time: 575.2837100028992 and batch: 650, loss is 3.8972774028778074 and perplexity is 49.268129072404996
At time: 576.3284709453583 and batch: 700, loss is 3.9066293096542357 and perplexity is 49.73104120430875
At time: 577.3734266757965 and batch: 750, loss is 3.869119634628296 and perplexity is 47.900197837535885
At time: 578.4195671081543 and batch: 800, loss is 3.8479941129684447 and perplexity is 46.898894932529416
At time: 579.4664590358734 and batch: 850, loss is 3.8496240329742433 and perplexity is 46.97539871021176
At time: 580.5129497051239 and batch: 900, loss is 3.8281214427948 and perplexity is 45.97608834707727
At time: 581.5575466156006 and batch: 950, loss is 3.9190525007247925 and perplexity is 50.352713009647076
At time: 582.6027493476868 and batch: 1000, loss is 3.8814316272735594 and perplexity is 48.49359014611758
At time: 583.6499557495117 and batch: 1050, loss is 3.832586479187012 and perplexity is 46.18183223988446
At time: 584.696665763855 and batch: 1100, loss is 3.8672496032714845 and perplexity is 47.8107066673088
At time: 585.7419877052307 and batch: 1150, loss is 3.830466480255127 and perplexity is 46.08403051127348
At time: 586.8294837474823 and batch: 1200, loss is 3.875033001899719 and perplexity is 48.18428843791481
At time: 587.8742673397064 and batch: 1250, loss is 3.855359649658203 and perplexity is 47.24560575204194
At time: 588.9182908535004 and batch: 1300, loss is 3.84746826171875 and perplexity is 46.87423957311376
At time: 589.9624965190887 and batch: 1350, loss is 3.746065979003906 and perplexity is 42.35413177885301
At time: 591.0072588920593 and batch: 1400, loss is 3.7684743499755857 and perplexity is 43.31393249910381
At time: 592.050196647644 and batch: 1450, loss is 3.677136769294739 and perplexity is 39.533039657073445
At time: 593.0966498851776 and batch: 1500, loss is 3.687631983757019 and perplexity is 39.95013229643123
At time: 594.1425302028656 and batch: 1550, loss is 3.7000591135025025 and perplexity is 40.449695412565944
At time: 595.186977148056 and batch: 1600, loss is 3.7925684785842897 and perplexity is 44.37021799892987
At time: 596.2308180332184 and batch: 1650, loss is 3.7236530447006224 and perplexity is 41.415410451620026
At time: 597.2756085395813 and batch: 1700, loss is 3.7463905477523802 and perplexity is 42.36788083753386
At time: 598.320946931839 and batch: 1750, loss is 3.7520138216018677 and perplexity is 42.60679815308126
At time: 599.3677384853363 and batch: 1800, loss is 3.7020245599746704 and perplexity is 40.52927530310444
At time: 600.4143934249878 and batch: 1850, loss is 3.730327773094177 and perplexity is 41.69277169342108
At time: 601.4596631526947 and batch: 1900, loss is 3.8031546831130982 and perplexity is 44.842425232909456
At time: 602.5063984394073 and batch: 1950, loss is 3.7504173946380615 and perplexity is 42.53883377618454
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485075910701308 and perplexity of 88.68368259799072
finished 14 epochs...
Completing Train Step...
At time: 605.7790849208832 and batch: 50, loss is 3.9221443939208984 and perplexity is 50.50863914967422
At time: 606.8541963100433 and batch: 100, loss is 3.9218319940567015 and perplexity is 50.49286272206831
At time: 607.9047734737396 and batch: 150, loss is 3.8839284563064576 and perplexity is 48.614821634071966
At time: 608.9534735679626 and batch: 200, loss is 3.883682017326355 and perplexity is 48.60284252313116
At time: 610.0027966499329 and batch: 250, loss is 3.869817199707031 and perplexity is 47.933622999569366
At time: 611.051744222641 and batch: 300, loss is 3.8892655038833617 and perplexity is 48.874974857622995
At time: 612.110205411911 and batch: 350, loss is 3.9126092100143435 and perplexity is 50.02931882188421
At time: 613.1594688892365 and batch: 400, loss is 3.8692297077178956 and perplexity is 47.905470650496376
At time: 614.2335653305054 and batch: 450, loss is 3.8937806987762453 and perplexity is 49.096153851858276
At time: 615.2832975387573 and batch: 500, loss is 3.9216707372665405 and perplexity is 50.484721061566376
At time: 616.3331310749054 and batch: 550, loss is 3.8751569032669066 and perplexity is 48.19025890699622
At time: 617.3822605609894 and batch: 600, loss is 3.8510552835464478 and perplexity is 47.042680413498026
At time: 618.4328465461731 and batch: 650, loss is 3.8907344818115233 and perplexity is 48.946823876319385
At time: 619.4827237129211 and batch: 700, loss is 3.900615134239197 and perplexity is 49.432847592091576
At time: 620.5320956707001 and batch: 750, loss is 3.8632798910140993 and perplexity is 47.62128813629725
At time: 621.5809552669525 and batch: 800, loss is 3.8422499895095825 and perplexity is 46.63027412409028
At time: 622.6321978569031 and batch: 850, loss is 3.843965172767639 and perplexity is 46.71032221853808
At time: 623.6812605857849 and batch: 900, loss is 3.8230778980255127 and perplexity is 45.74478966012526
At time: 624.7297203540802 and batch: 950, loss is 3.9140352392196656 and perplexity is 50.10071298462848
At time: 625.779078245163 and batch: 1000, loss is 3.8765610027313233 and perplexity is 48.25797034939324
At time: 626.828901052475 and batch: 1050, loss is 3.8280425119400023 and perplexity is 45.97245955833738
At time: 627.8784370422363 and batch: 1100, loss is 3.863150367736816 and perplexity is 47.61512047042617
At time: 628.9285624027252 and batch: 1150, loss is 3.826819667816162 and perplexity is 45.91627676470856
At time: 629.9774014949799 and batch: 1200, loss is 3.8715848875045777 and perplexity is 48.01842961376335
At time: 631.0270187854767 and batch: 1250, loss is 3.85250376701355 and perplexity is 47.110870332387755
At time: 632.0767159461975 and batch: 1300, loss is 3.8451170110702515 and perplexity is 46.7641559547245
At time: 633.1256713867188 and batch: 1350, loss is 3.7441818571090697 and perplexity is 42.274406561430354
At time: 634.1751372814178 and batch: 1400, loss is 3.767141523361206 and perplexity is 43.256240992023976
At time: 635.2247269153595 and batch: 1450, loss is 3.676420817375183 and perplexity is 39.50474603109157
At time: 636.2735784053802 and batch: 1500, loss is 3.6874333572387696 and perplexity is 39.94219792876358
At time: 637.3242654800415 and batch: 1550, loss is 3.7004159927368163 and perplexity is 40.46413364509245
At time: 638.3748826980591 and batch: 1600, loss is 3.793316307067871 and perplexity is 44.403411721830956
At time: 639.4243738651276 and batch: 1650, loss is 3.7247461795806887 and perplexity is 41.46070783492113
At time: 640.4743766784668 and batch: 1700, loss is 3.74776065826416 and perplexity is 42.425969301151525
At time: 641.5247488021851 and batch: 1750, loss is 3.7535959482192993 and perplexity is 42.674260855719254
At time: 642.5755019187927 and batch: 1800, loss is 3.703779706954956 and perplexity is 40.60047260084973
At time: 643.6257164478302 and batch: 1850, loss is 3.7321546411514284 and perplexity is 41.76900850233854
At time: 644.6751770973206 and batch: 1900, loss is 3.8049742221832275 and perplexity is 44.92409205307375
At time: 645.7259411811829 and batch: 1950, loss is 3.752127389907837 and perplexity is 42.61163720974681
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485153978924418 and perplexity of 88.69060624576494
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 649.0755252838135 and batch: 50, loss is 3.920408034324646 and perplexity is 50.42101408571875
At time: 650.1186480522156 and batch: 100, loss is 3.9224489545822143 and perplexity is 50.52402443697352
At time: 651.1605606079102 and batch: 150, loss is 3.8856338357925413 and perplexity is 48.697799087519385
At time: 652.2014517784119 and batch: 200, loss is 3.8860806465148925 and perplexity is 48.719562648040615
At time: 653.2424156665802 and batch: 250, loss is 3.873767156600952 and perplexity is 48.12333317102963
At time: 654.2861924171448 and batch: 300, loss is 3.8917117881774903 and perplexity is 48.994683301738824
At time: 655.3296544551849 and batch: 350, loss is 3.915483303070068 and perplexity is 50.17331456915949
At time: 656.3732452392578 and batch: 400, loss is 3.8731002187728882 and perplexity is 48.091248600121645
At time: 657.4160914421082 and batch: 450, loss is 3.8974721956253053 and perplexity is 49.27772708141202
At time: 658.4584226608276 and batch: 500, loss is 3.9259647035598757 and perplexity is 50.70196684136038
At time: 659.5013747215271 and batch: 550, loss is 3.8797894811630247 and perplexity is 48.41402193486818
At time: 660.5445744991302 and batch: 600, loss is 3.8562296533584597 and perplexity is 47.286727489305086
At time: 661.5890402793884 and batch: 650, loss is 3.894282774925232 and perplexity is 49.12081004884054
At time: 662.6338307857513 and batch: 700, loss is 3.9040484714508055 and perplexity is 49.60285891329804
At time: 663.6814048290253 and batch: 750, loss is 3.8666933584213257 and perplexity is 47.78411960308696
At time: 664.7243795394897 and batch: 800, loss is 3.8437024354934692 and perplexity is 46.69805128788881
At time: 665.7701225280762 and batch: 850, loss is 3.844511046409607 and perplexity is 46.73582711283645
At time: 666.8394756317139 and batch: 900, loss is 3.8188152599334715 and perplexity is 45.550211180652354
At time: 667.8820321559906 and batch: 950, loss is 3.9110405921936033 and perplexity is 49.95090345876754
At time: 668.9321348667145 and batch: 1000, loss is 3.873351230621338 and perplexity is 48.10332158849519
At time: 669.9771032333374 and batch: 1050, loss is 3.8261286449432372 and perplexity is 45.88455852750047
At time: 671.0199654102325 and batch: 1100, loss is 3.8599313735961913 and perplexity is 47.462094104252024
At time: 672.0637233257294 and batch: 1150, loss is 3.8238827896118166 and perplexity is 45.78162407830798
At time: 673.1076791286469 and batch: 1200, loss is 3.8682566356658934 and perplexity is 47.85887784862147
At time: 674.150171995163 and batch: 1250, loss is 3.848749375343323 and perplexity is 46.93432928272669
At time: 675.1916983127594 and batch: 1300, loss is 3.842033181190491 and perplexity is 46.62016538860722
At time: 676.2346291542053 and batch: 1350, loss is 3.7393734312057494 and perplexity is 42.07162113992565
At time: 677.2781612873077 and batch: 1400, loss is 3.7617170143127443 and perplexity is 43.02223238607464
At time: 678.3225181102753 and batch: 1450, loss is 3.669226355552673 and perplexity is 39.22155058489785
At time: 679.3653538227081 and batch: 1500, loss is 3.6780285024642945 and perplexity is 39.56830830260244
At time: 680.4086713790894 and batch: 1550, loss is 3.691450333595276 and perplexity is 40.102967481032756
At time: 681.4541747570038 and batch: 1600, loss is 3.7821611070632937 and perplexity is 43.910835285465886
At time: 682.4983332157135 and batch: 1650, loss is 3.7138297605514525 and perplexity is 41.010566809175316
At time: 683.5419325828552 and batch: 1700, loss is 3.7346793365478517 and perplexity is 41.87459575756096
At time: 684.5854361057281 and batch: 1750, loss is 3.740640163421631 and perplexity is 42.12494838633767
At time: 685.6284930706024 and batch: 1800, loss is 3.691982388496399 and perplexity is 40.12431013865993
At time: 686.6713528633118 and batch: 1850, loss is 3.7215191555023193 and perplexity is 41.3271287797661
At time: 687.7151370048523 and batch: 1900, loss is 3.794831166267395 and perplexity is 44.47072761274329
At time: 688.7569861412048 and batch: 1950, loss is 3.744182114601135 and perplexity is 42.27441744675602
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4839392373728195 and perplexity of 88.5829354904318
finished 16 epochs...
Completing Train Step...
At time: 692.0416083335876 and batch: 50, loss is 3.920123281478882 and perplexity is 50.40665860245089
At time: 693.1142566204071 and batch: 100, loss is 3.919067177772522 and perplexity is 50.353452044242644
At time: 694.1595392227173 and batch: 150, loss is 3.8814915561676027 and perplexity is 48.49649640042666
At time: 695.203863620758 and batch: 200, loss is 3.8809148693084716 and perplexity is 48.46853717087364
At time: 696.2477653026581 and batch: 250, loss is 3.8681977367401124 and perplexity is 47.85605909513869
At time: 697.2911837100983 and batch: 300, loss is 3.887223792076111 and perplexity is 48.77528804487784
At time: 698.3361082077026 and batch: 350, loss is 3.910639305114746 and perplexity is 49.93086282792432
At time: 699.3804020881653 and batch: 400, loss is 3.8681596183776854 and perplexity is 47.854234935300994
At time: 700.4237339496613 and batch: 450, loss is 3.8927699899673462 and perplexity is 49.046557004884264
At time: 701.467431306839 and batch: 500, loss is 3.9212295961380006 and perplexity is 50.46245508632307
At time: 702.5118546485901 and batch: 550, loss is 3.8748009538650514 and perplexity is 48.17310866565318
At time: 703.5565409660339 and batch: 600, loss is 3.851069936752319 and perplexity is 47.04336974462931
At time: 704.6015429496765 and batch: 650, loss is 3.889990792274475 and perplexity is 48.91043616778697
At time: 705.6465787887573 and batch: 700, loss is 3.900093059539795 and perplexity is 49.40704668862984
At time: 706.6994588375092 and batch: 750, loss is 3.8629563093185424 and perplexity is 47.60588125196482
At time: 707.7445905208588 and batch: 800, loss is 3.8405177927017213 and perplexity is 46.54957122893065
At time: 708.7897877693176 and batch: 850, loss is 3.841620488166809 and perplexity is 46.6009295411115
At time: 709.8350193500519 and batch: 900, loss is 3.8172366714477537 and perplexity is 45.478362866141715
At time: 710.8815724849701 and batch: 950, loss is 3.909896297454834 and perplexity is 49.89377759338993
At time: 711.9274456501007 and batch: 1000, loss is 3.871927189826965 and perplexity is 48.03486924723938
At time: 712.972677230835 and batch: 1050, loss is 3.8243939113616943 and perplexity is 45.80503004325845
At time: 714.0190613269806 and batch: 1100, loss is 3.858131127357483 and perplexity is 47.376727511358794
At time: 715.0643072128296 and batch: 1150, loss is 3.822435750961304 and perplexity is 45.71542420722092
At time: 716.109311580658 and batch: 1200, loss is 3.8665987920761107 and perplexity is 47.779601047191804
At time: 717.1526448726654 and batch: 1250, loss is 3.847167978286743 and perplexity is 46.86016612869887
At time: 718.1973466873169 and batch: 1300, loss is 3.840378441810608 and perplexity is 46.54308495664336
At time: 719.2431707382202 and batch: 1350, loss is 3.738352084159851 and perplexity is 42.02867334999083
At time: 720.2876522541046 and batch: 1400, loss is 3.7611724090576173 and perplexity is 42.998808631158845
At time: 721.3317968845367 and batch: 1450, loss is 3.669364776611328 and perplexity is 39.22698004921932
At time: 722.3767006397247 and batch: 1500, loss is 3.6785582971572874 and perplexity is 39.58927693639686
At time: 723.4211857318878 and batch: 1550, loss is 3.6923339271545412 and perplexity is 40.13841786436516
At time: 724.4660670757294 and batch: 1600, loss is 3.7835777759552003 and perplexity is 43.97308648408947
At time: 725.5256476402283 and batch: 1650, loss is 3.71550021648407 and perplexity is 41.079130404090186
At time: 726.5711224079132 and batch: 1700, loss is 3.736704397201538 and perplexity is 41.95948027295636
At time: 727.6145741939545 and batch: 1750, loss is 3.743005690574646 and perplexity is 42.22471404823428
At time: 728.6589860916138 and batch: 1800, loss is 3.694424419403076 and perplexity is 40.22241468253776
At time: 729.7038669586182 and batch: 1850, loss is 3.7240049839019775 and perplexity is 41.42998872328033
At time: 730.7473933696747 and batch: 1900, loss is 3.7970453548431395 and perplexity is 44.56930328206557
At time: 731.7902886867523 and batch: 1950, loss is 3.7463437700271607 and perplexity is 42.36589901079895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4837649323219475 and perplexity of 88.56749638295103
finished 17 epochs...
Completing Train Step...
At time: 735.0872209072113 and batch: 50, loss is 3.919408016204834 and perplexity is 50.37061736103256
At time: 736.1463799476624 and batch: 100, loss is 3.9171663236618044 and perplexity is 50.25782839003626
At time: 737.206545829773 and batch: 150, loss is 3.879146890640259 and perplexity is 48.38292153668459
At time: 738.2574849128723 and batch: 200, loss is 3.878205156326294 and perplexity is 48.3373791270544
At time: 739.3082156181335 and batch: 250, loss is 3.865283350944519 and perplexity is 47.71679111516443
At time: 740.3587651252747 and batch: 300, loss is 3.884416928291321 and perplexity is 48.63857441330066
At time: 741.4088318347931 and batch: 350, loss is 3.9077546548843385 and perplexity is 49.78703729587387
At time: 742.4598045349121 and batch: 400, loss is 3.865184283256531 and perplexity is 47.712064157138705
At time: 743.510504245758 and batch: 450, loss is 3.8898976755142214 and perplexity is 48.90588199846647
At time: 744.5619459152222 and batch: 500, loss is 3.918313536643982 and perplexity is 50.315517907976236
At time: 745.6122567653656 and batch: 550, loss is 3.8719037199020385 and perplexity is 48.033741885693885
At time: 746.7058145999908 and batch: 600, loss is 3.8482959699630737 and perplexity is 46.91305382887861
At time: 747.755960226059 and batch: 650, loss is 3.8874984979629517 and perplexity is 48.788688744177335
At time: 748.8074333667755 and batch: 700, loss is 3.897763423919678 and perplexity is 49.292080239741956
At time: 749.8572781085968 and batch: 750, loss is 3.8607974100112914 and perplexity is 47.50321580996034
At time: 750.9084632396698 and batch: 800, loss is 3.8384981870651247 and perplexity is 46.45565432197528
At time: 751.9599204063416 and batch: 850, loss is 3.8396669244766235 and perplexity is 46.50998052350521
At time: 753.0121703147888 and batch: 900, loss is 3.8158534288406374 and perplexity is 45.41549874511218
At time: 754.0647177696228 and batch: 950, loss is 3.908539776802063 and perplexity is 49.826141538863844
At time: 755.1160287857056 and batch: 1000, loss is 3.870613007545471 and perplexity is 47.971784134928576
At time: 756.1679890155792 and batch: 1050, loss is 3.8230302715301514 and perplexity is 45.74261104799295
At time: 757.2203314304352 and batch: 1100, loss is 3.856849236488342 and perplexity is 47.31603462609104
At time: 758.2704572677612 and batch: 1150, loss is 3.821399936676025 and perplexity is 45.66809603360025
At time: 759.3224606513977 and batch: 1200, loss is 3.865587840080261 and perplexity is 47.73132257187454
At time: 760.3724975585938 and batch: 1250, loss is 3.846336064338684 and perplexity is 46.821198713903385
At time: 761.4223113059998 and batch: 1300, loss is 3.839643106460571 and perplexity is 46.50887276123491
At time: 762.4725451469421 and batch: 1350, loss is 3.737908763885498 and perplexity is 42.01004531638819
At time: 763.5233643054962 and batch: 1400, loss is 3.7609890794754026 and perplexity is 42.99092640008191
At time: 764.5734424591064 and batch: 1450, loss is 3.669527168273926 and perplexity is 39.23335070098457
At time: 765.6240782737732 and batch: 1500, loss is 3.678934683799744 and perplexity is 39.604180616017246
At time: 766.6877245903015 and batch: 1550, loss is 3.6929502153396605 and perplexity is 40.16316232113934
At time: 767.7379302978516 and batch: 1600, loss is 3.784489493370056 and perplexity is 44.013195794221915
At time: 768.7879185676575 and batch: 1650, loss is 3.716552700996399 and perplexity is 41.122388312766745
At time: 769.838770866394 and batch: 1700, loss is 3.7379518127441407 and perplexity is 42.011853839817746
At time: 770.8900909423828 and batch: 1750, loss is 3.7443412923812867 and perplexity is 42.281147130276224
At time: 771.9431841373444 and batch: 1800, loss is 3.695795707702637 and perplexity is 40.277609044214095
At time: 772.9946384429932 and batch: 1850, loss is 3.7253542137145996 and perplexity is 41.48592502618048
At time: 774.0531837940216 and batch: 1900, loss is 3.7982110595703125 and perplexity is 44.6212882232474
At time: 775.1061861515045 and batch: 1950, loss is 3.7474924898147584 and perplexity is 42.41459352013062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483721214117006 and perplexity of 88.56362445563049
finished 18 epochs...
Completing Train Step...
At time: 778.3768634796143 and batch: 50, loss is 3.918459529876709 and perplexity is 50.32286416933113
At time: 779.4485845565796 and batch: 100, loss is 3.915602617263794 and perplexity is 50.17930131487863
At time: 780.4949214458466 and batch: 150, loss is 3.8772882509231565 and perplexity is 48.293078635742894
At time: 781.5406317710876 and batch: 200, loss is 3.8761805295944214 and perplexity is 48.2396129804982
At time: 782.58398270607 and batch: 250, loss is 3.8630972146987914 and perplexity is 47.61258964937826
At time: 783.6281564235687 and batch: 300, loss is 3.8822340774536133 and perplexity is 48.532519453587724
At time: 784.6711220741272 and batch: 350, loss is 3.905536689758301 and perplexity is 49.676733753346845
At time: 785.7178099155426 and batch: 400, loss is 3.862915110588074 and perplexity is 47.60391999049542
At time: 786.7606530189514 and batch: 450, loss is 3.8876975059509276 and perplexity is 48.79839904914238
At time: 787.8037693500519 and batch: 500, loss is 3.9160916948318483 and perplexity is 50.20384888787671
At time: 788.8466703891754 and batch: 550, loss is 3.8697218990325926 and perplexity is 47.929055110634124
At time: 789.8899307250977 and batch: 600, loss is 3.8462880992889406 and perplexity is 46.81895298663666
At time: 790.9336836338043 and batch: 650, loss is 3.8856371307373045 and perplexity is 48.69795954434181
At time: 791.9766809940338 and batch: 700, loss is 3.896016254425049 and perplexity is 49.20603381155629
At time: 793.019544839859 and batch: 750, loss is 3.8591654920578002 and perplexity is 47.42575767907897
At time: 794.0610783100128 and batch: 800, loss is 3.8369221591949465 and perplexity is 46.38249658049905
At time: 795.1031682491302 and batch: 850, loss is 3.838114628791809 and perplexity is 46.437839288187995
At time: 796.1454954147339 and batch: 900, loss is 3.814630165100098 and perplexity is 45.35997757767761
At time: 797.1888380050659 and batch: 950, loss is 3.9073010587692263 and perplexity is 49.764459210226605
At time: 798.2321410179138 and batch: 1000, loss is 3.869454140663147 and perplexity is 47.91622342296119
At time: 799.3025968074799 and batch: 1050, loss is 3.82189857006073 and perplexity is 45.69087334919156
At time: 800.3466193675995 and batch: 1100, loss is 3.8558110189437866 and perplexity is 47.266935780854986
At time: 801.3895947933197 and batch: 1150, loss is 3.820537075996399 and perplexity is 45.62870782493151
At time: 802.4338006973267 and batch: 1200, loss is 3.8647814702987673 and perplexity is 47.69284898977358
At time: 803.4768631458282 and batch: 1250, loss is 3.845692205429077 and perplexity is 46.791062170834934
At time: 804.5296859741211 and batch: 1300, loss is 3.8391087102890014 and perplexity is 46.48402523748939
At time: 805.5730679035187 and batch: 1350, loss is 3.7375595951080323 and perplexity is 41.995379280833646
At time: 806.6165668964386 and batch: 1400, loss is 3.7608246755599977 and perplexity is 42.98385910441631
At time: 807.6666524410248 and batch: 1450, loss is 3.6695763540267943 and perplexity is 39.235280470334544
At time: 808.7172544002533 and batch: 1500, loss is 3.6791397190093993 and perplexity is 39.61230170001871
At time: 809.7673525810242 and batch: 1550, loss is 3.693335576057434 and perplexity is 40.17864260875527
At time: 810.8178768157959 and batch: 1600, loss is 3.7850605773925783 and perplexity is 44.03833820565154
At time: 811.8624820709229 and batch: 1650, loss is 3.717224578857422 and perplexity is 41.15002681887695
At time: 812.9054536819458 and batch: 1700, loss is 3.7387399291992187 and perplexity is 42.04497712392538
At time: 813.948714017868 and batch: 1750, loss is 3.7451744985580446 and perplexity is 42.31639072377654
At time: 814.993234872818 and batch: 1800, loss is 3.6966585969924926 and perplexity is 40.31237916090257
At time: 816.0359065532684 and batch: 1850, loss is 3.726201868057251 and perplexity is 41.52110565908948
At time: 817.078640460968 and batch: 1900, loss is 3.79893789768219 and perplexity is 44.65373246555669
At time: 818.1229453086853 and batch: 1950, loss is 3.748201861381531 and perplexity is 42.44469190099567
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48372689180596 and perplexity of 88.56412729377023
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 821.4892358779907 and batch: 50, loss is 3.9181053495407103 and perplexity is 50.30504395636201
At time: 822.5466105937958 and batch: 100, loss is 3.915578660964966 and perplexity is 50.17809921894028
At time: 823.6024355888367 and batch: 150, loss is 3.8773858737945557 and perplexity is 48.29779337487746
At time: 824.6471788883209 and batch: 200, loss is 3.8763093757629394 and perplexity is 48.24582887023972
At time: 825.69029712677 and batch: 250, loss is 3.8634003257751464 and perplexity is 47.62702374013081
At time: 826.7828953266144 and batch: 300, loss is 3.8823157787322997 and perplexity is 48.53648478446905
At time: 827.8279745578766 and batch: 350, loss is 3.90557825088501 and perplexity is 49.67879841727744
At time: 828.8733320236206 and batch: 400, loss is 3.8633169078826906 and perplexity is 47.62305095988925
At time: 829.9162192344666 and batch: 450, loss is 3.8880991744995117 and perplexity is 48.81800376829764
At time: 830.96164894104 and batch: 500, loss is 3.9165248680114746 and perplexity is 50.22560055950921
At time: 832.0060908794403 and batch: 550, loss is 3.870169849395752 and perplexity is 47.950529757705716
At time: 833.0506258010864 and batch: 600, loss is 3.8468678188323975 and perplexity is 46.84610271754164
At time: 834.0933241844177 and batch: 650, loss is 3.8858880519866945 and perplexity is 48.7101804303693
At time: 835.1385962963104 and batch: 700, loss is 3.8963449716567995 and perplexity is 49.22221134154701
At time: 836.1823592185974 and batch: 750, loss is 3.8598662281036376 and perplexity is 47.45900226346481
At time: 837.225667476654 and batch: 800, loss is 3.8371367502212523 and perplexity is 46.39245091606023
At time: 838.2739281654358 and batch: 850, loss is 3.8379689502716063 and perplexity is 46.431074785212445
At time: 839.3210780620575 and batch: 900, loss is 3.8128383016586302 and perplexity is 45.278771469006934
At time: 840.3647520542145 and batch: 950, loss is 3.905439953804016 and perplexity is 49.67192845952755
At time: 841.4093177318573 and batch: 1000, loss is 3.867722053527832 and perplexity is 47.83330018466621
At time: 842.4524912834167 and batch: 1050, loss is 3.8206111288070677 and perplexity is 45.632086884106
At time: 843.4966282844543 and batch: 1100, loss is 3.8542713594436644 and perplexity is 47.19421678974641
At time: 844.5486783981323 and batch: 1150, loss is 3.819099521636963 and perplexity is 45.563161201787295
At time: 845.6021237373352 and batch: 1200, loss is 3.8633466148376465 and perplexity is 47.62446571673293
At time: 846.6467442512512 and batch: 1250, loss is 3.8442015790939332 and perplexity is 46.72136613958874
At time: 847.6901063919067 and batch: 1300, loss is 3.8376921606063843 and perplexity is 46.41822492200345
At time: 848.73393201828 and batch: 1350, loss is 3.7357973623275758 and perplexity is 41.92143881612756
At time: 849.7766590118408 and batch: 1400, loss is 3.758661985397339 and perplexity is 42.890998785421345
At time: 850.8228671550751 and batch: 1450, loss is 3.666986165046692 and perplexity is 39.13378518196278
At time: 851.8685038089752 and batch: 1500, loss is 3.676112699508667 and perplexity is 39.492575788058154
At time: 852.913008928299 and batch: 1550, loss is 3.6902854681015014 and perplexity is 40.05628011554588
At time: 853.9570121765137 and batch: 1600, loss is 3.7814747524261474 and perplexity is 43.880707220498024
At time: 855.0022966861725 and batch: 1650, loss is 3.7135524702072145 and perplexity is 40.999196551491586
At time: 856.0457272529602 and batch: 1700, loss is 3.7346641397476197 and perplexity is 41.87395940252973
At time: 857.0896968841553 and batch: 1750, loss is 3.740653295516968 and perplexity is 42.125501578808226
At time: 858.134115934372 and batch: 1800, loss is 3.6924521780014037 and perplexity is 40.143164546913425
At time: 859.1795988082886 and batch: 1850, loss is 3.7223694372177123 and perplexity is 41.362283425275365
At time: 860.2239789962769 and batch: 1900, loss is 3.7953131198883057 and perplexity is 44.4921656065852
At time: 861.268673658371 and batch: 1950, loss is 3.7454917812347412 and perplexity is 42.3298191116783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483619867369186 and perplexity of 88.55464927512715
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f2c7be9ab38>
ELAPSED
5337.281303405762


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.41794011582878}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6360119204925818, 'rnn_dropout': 0.965771331349581, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.35120415851347}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.3686534261327181, 'rnn_dropout': 0.8565517612572858, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -88.80032373838752}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.32275736599723115, 'rnn_dropout': 1.0, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -88.55464927512715}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.38935121651442495, 'rnn_dropout': 0.1109913976745851, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.58273476080855}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.8764242141488479, 'rnn_dropout': 0.3671472023130916, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -92.60753965031566}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6166729316005771, 'rnn_dropout': 0.022010211046501915, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.41794011582878}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.6360119204925818, 'rnn_dropout': 0.965771331349581, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -89.35120415851347}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.3686534261327181, 'rnn_dropout': 0.8565517612572858, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -88.80032373838752}, {'params': {'wordvec_dim': 300, 'tie_weights': 'TRUE', 'num_layers': 1, 'dropout': 0.32275736599723115, 'rnn_dropout': 1.0, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'seq_len': 35, 'wordvec_source': 'None', 'data': 'wikitext'}, 'best_accuracy': -88.55464927512715}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7f2c6fd0b4e0>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7f2c6fd0b2b0>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
