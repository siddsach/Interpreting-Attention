Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'domain': [0, 30], 'name': 'lr'}, {'type': 'continuous', 'domain': [0, 1], 'name': 'dropout'}, {'type': 'continuous', 'domain': [2, 8], 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'dropout': 0.20871861831774086, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 4.680527966079749, 'wordvec_dim': 200, 'lr': 9.727146940782237, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7934677600860596 and batch: 50, loss is 7.010940198898315 and perplexity is 1108.696410168266
At time: 2.8693015575408936 and batch: 100, loss is 6.120363454818726 and perplexity is 455.03004731192715
At time: 3.945261240005493 and batch: 150, loss is 5.887079524993896 and perplexity is 360.351349017234
At time: 5.026223421096802 and batch: 200, loss is 5.7597838973999025 and perplexity is 317.2797565284375
At time: 6.099522352218628 and batch: 250, loss is 5.758945121765136 and perplexity is 317.01374157828235
At time: 7.174088001251221 and batch: 300, loss is 5.706843566894531 and perplexity is 300.9197346496165
At time: 8.249490022659302 and batch: 350, loss is 5.6844739246368405 and perplexity is 294.2629998097356
At time: 9.324076890945435 and batch: 400, loss is 5.700586748123169 and perplexity is 299.0428123097597
At time: 10.400148153305054 and batch: 450, loss is 5.659705324172974 and perplexity is 287.06403925821513
At time: 11.476024627685547 and batch: 500, loss is 5.661562147140503 and perplexity is 287.59756153438025
At time: 12.551139116287231 and batch: 550, loss is 5.6193367290496825 and perplexity is 275.70645449374797
At time: 13.62668228149414 and batch: 600, loss is 5.558895263671875 and perplexity is 259.53595908781654
At time: 14.702045440673828 and batch: 650, loss is 5.576340007781982 and perplexity is 264.10321899689364
At time: 15.778048038482666 and batch: 700, loss is 5.580731353759766 and perplexity is 265.2655378095388
At time: 16.854405403137207 and batch: 750, loss is 5.539532480239868 and perplexity is 254.55896029008682
At time: 17.929781436920166 and batch: 800, loss is 5.47962836265564 and perplexity is 239.75758794195343
At time: 19.006255865097046 and batch: 850, loss is 5.485976972579956 and perplexity is 241.28455728185912
At time: 20.08168363571167 and batch: 900, loss is 5.523756704330444 and perplexity is 250.57460595095466
At time: 21.157620191574097 and batch: 950, loss is 5.480303773880005 and perplexity is 239.91957760663692
At time: 22.240285634994507 and batch: 1000, loss is 5.498893413543701 and perplexity is 244.42130924750936
At time: 23.3230082988739 and batch: 1050, loss is 5.453617057800293 and perplexity is 233.60159008468895
At time: 24.407407760620117 and batch: 1100, loss is 5.433567504882813 and perplexity is 228.96462253719915
At time: 25.491849660873413 and batch: 1150, loss is 5.443582448959351 and perplexity is 231.2692113290324
At time: 26.576601266860962 and batch: 1200, loss is 5.420697574615478 and perplexity is 226.03674501439724
At time: 27.66028094291687 and batch: 1250, loss is 5.44579852104187 and perplexity is 231.7822888702366
At time: 28.745364665985107 and batch: 1300, loss is 5.418619937896729 and perplexity is 225.56761028769037
At time: 29.828741550445557 and batch: 1350, loss is 5.386983394622803 and perplexity is 218.54313180558376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.034896240234375 and perplexity of 153.68364560547965
Finished 1 epochs...
Completing Train Step...
At time: 33.03528881072998 and batch: 50, loss is 5.287252912521362 and perplexity is 197.79930638243417
At time: 34.111977338790894 and batch: 100, loss is 5.269753761291504 and perplexity is 194.3680956034658
At time: 35.186864137649536 and batch: 150, loss is 5.19684458732605 and perplexity is 180.7011546275144
At time: 36.26275587081909 and batch: 200, loss is 5.17155837059021 and perplexity is 176.18919171043805
At time: 37.33938431739807 and batch: 250, loss is 5.194624490737915 and perplexity is 180.3004256038168
At time: 38.41687798500061 and batch: 300, loss is 5.168145914077758 and perplexity is 175.58897843905535
At time: 39.494157791137695 and batch: 350, loss is 5.160932912826538 and perplexity is 174.3270116732025
At time: 40.57171058654785 and batch: 400, loss is 5.180956296920776 and perplexity is 177.85280979009977
At time: 41.649370193481445 and batch: 450, loss is 5.144204864501953 and perplexity is 171.43511631599233
At time: 42.72652292251587 and batch: 500, loss is 5.191207466125488 and perplexity is 179.6853860130434
At time: 43.80342102050781 and batch: 550, loss is 5.17161449432373 and perplexity is 176.19908038317476
At time: 44.881678104400635 and batch: 600, loss is 5.114433994293213 and perplexity is 166.40656725636637
At time: 45.96000862121582 and batch: 650, loss is 5.136027717590332 and perplexity is 170.03898216056663
At time: 47.038602113723755 and batch: 700, loss is 5.137676496505737 and perplexity is 170.3195700993243
At time: 48.11628007888794 and batch: 750, loss is 5.100484428405761 and perplexity is 164.10138341965575
At time: 49.19370102882385 and batch: 800, loss is 5.0522005653381346 and perplexity is 156.36618015940897
At time: 50.27137494087219 and batch: 850, loss is 5.0422787094116215 and perplexity is 154.82240865179548
At time: 51.39247250556946 and batch: 900, loss is 5.09060375213623 and perplexity is 162.48793488246704
At time: 52.46924948692322 and batch: 950, loss is 5.043348655700684 and perplexity is 154.98814896420086
At time: 53.547292709350586 and batch: 1000, loss is 5.064046249389649 and perplexity is 158.2294586421012
At time: 54.62439775466919 and batch: 1050, loss is 5.006603260040283 and perplexity is 149.3964125519022
At time: 55.70272469520569 and batch: 1100, loss is 4.983265781402588 and perplexity is 145.95024579496166
At time: 56.78134250640869 and batch: 1150, loss is 5.016480121612549 and perplexity is 150.8792912771749
At time: 57.860167503356934 and batch: 1200, loss is 4.980103826522827 and perplexity is 145.48948653694765
At time: 58.943482398986816 and batch: 1250, loss is 5.025448684692383 and perplexity is 152.23854789681667
At time: 60.023420095443726 and batch: 1300, loss is 4.992525825500488 and perplexity is 147.3080283680786
At time: 61.10277843475342 and batch: 1350, loss is 4.97084831237793 and perplexity is 144.14911900020294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.903369140625 and perplexity of 134.74298386280046
Finished 2 epochs...
Completing Train Step...
At time: 64.32267904281616 and batch: 50, loss is 4.9965354347229 and perplexity is 147.89986171447364
At time: 65.43256974220276 and batch: 100, loss is 5.005826482772827 and perplexity is 149.28040987474654
At time: 66.51840949058533 and batch: 150, loss is 4.93984395980835 and perplexity is 139.74844148498698
At time: 67.60357403755188 and batch: 200, loss is 4.932065820693969 and perplexity is 138.6656750788585
At time: 68.68673157691956 and batch: 250, loss is 4.95002519607544 and perplexity is 141.17852102133028
At time: 69.76955103874207 and batch: 300, loss is 4.937814054489135 and perplexity is 139.46505310336514
At time: 70.85009169578552 and batch: 350, loss is 4.947404317855835 and perplexity is 140.8089937650019
At time: 71.93102383613586 and batch: 400, loss is 4.958201570510864 and perplexity is 142.3375814703276
At time: 73.0098044872284 and batch: 450, loss is 4.915261001586914 and perplexity is 136.35489400229434
At time: 74.08913350105286 and batch: 500, loss is 4.9785984516143795 and perplexity is 145.27063508254537
At time: 75.16883444786072 and batch: 550, loss is 4.953873653411865 and perplexity is 141.7228873497287
At time: 76.24863815307617 and batch: 600, loss is 4.899658098220825 and perplexity is 134.24387361846627
At time: 77.33528184890747 and batch: 650, loss is 4.918050794601441 and perplexity is 136.73582704818867
At time: 78.46170949935913 and batch: 700, loss is 4.923846540451049 and perplexity is 137.5306141174404
At time: 79.54206037521362 and batch: 750, loss is 4.875006103515625 and perplexity is 130.97495261604882
At time: 80.62239146232605 and batch: 800, loss is 4.82163028717041 and perplexity is 124.16735430591817
At time: 81.7068338394165 and batch: 850, loss is 4.826507072448731 and perplexity is 124.77437077287287
At time: 82.78756618499756 and batch: 900, loss is 4.866284704208374 and perplexity is 129.8376344668535
At time: 83.86788201332092 and batch: 950, loss is 4.832318506240845 and perplexity is 125.50159984265738
At time: 84.94880318641663 and batch: 1000, loss is 4.8484146022796635 and perplexity is 127.53803097520382
At time: 86.0295205116272 and batch: 1050, loss is 4.782247295379639 and perplexity is 119.3723136843134
At time: 87.11089158058167 and batch: 1100, loss is 4.768517990112304 and perplexity is 117.74461391034606
At time: 88.19162607192993 and batch: 1150, loss is 4.816328105926513 and perplexity is 123.51073877438314
At time: 89.27176785469055 and batch: 1200, loss is 4.775859346389771 and perplexity is 118.61219980280491
At time: 90.350426197052 and batch: 1250, loss is 4.810471782684326 and perplexity is 122.78953383011168
At time: 91.43086433410645 and batch: 1300, loss is 4.7895636463165285 and perplexity is 120.24888616917015
At time: 92.51284861564636 and batch: 1350, loss is 4.774651136398315 and perplexity is 118.46897789638642
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.858806559244791 and perplexity of 128.87031121427242
Finished 3 epochs...
Completing Train Step...
At time: 95.72698163986206 and batch: 50, loss is 4.816723251342774 and perplexity is 123.55955312041617
At time: 96.83428144454956 and batch: 100, loss is 4.834896507263184 and perplexity is 125.82556050138906
At time: 97.9144287109375 and batch: 150, loss is 4.775461320877075 and perplexity is 118.5649985154479
At time: 98.99544310569763 and batch: 200, loss is 4.7624123096466064 and perplexity is 117.0278931816999
At time: 100.07597923278809 and batch: 250, loss is 4.790124673843383 and perplexity is 120.31636803220604
At time: 101.16050100326538 and batch: 300, loss is 4.775281009674072 and perplexity is 118.54362184521598
At time: 102.24403762817383 and batch: 350, loss is 4.787282886505127 and perplexity is 119.97493986384423
At time: 103.32878088951111 and batch: 400, loss is 4.797766246795654 and perplexity is 121.23929615608078
At time: 104.4128987789154 and batch: 450, loss is 4.753961029052735 and perplexity is 116.04302517897037
At time: 105.49297976493835 and batch: 500, loss is 4.8175825595855715 and perplexity is 123.66577449480398
At time: 106.60025930404663 and batch: 550, loss is 4.805986833572388 and perplexity is 122.24006211678244
At time: 107.6805989742279 and batch: 600, loss is 4.749501142501831 and perplexity is 115.52663881987293
At time: 108.75994658470154 and batch: 650, loss is 4.7647244834899904 and perplexity is 117.29879508071335
At time: 109.83694362640381 and batch: 700, loss is 4.777079820632935 and perplexity is 118.75705131337773
At time: 110.91373586654663 and batch: 750, loss is 4.736115207672119 and perplexity is 113.99051095259219
At time: 111.98965740203857 and batch: 800, loss is 4.687931985855102 and perplexity is 108.6283024967309
At time: 113.06642699241638 and batch: 850, loss is 4.681847801208496 and perplexity is 107.96939433852557
At time: 114.14372897148132 and batch: 900, loss is 4.722652368545532 and perplexity is 112.46615911719141
At time: 115.22288775444031 and batch: 950, loss is 4.685908260345459 and perplexity is 108.40869092162339
At time: 116.30855059623718 and batch: 1000, loss is 4.706374425888061 and perplexity is 110.6502610669224
At time: 117.39283037185669 and batch: 1050, loss is 4.64362606048584 and perplexity is 103.92048719093567
At time: 118.47652888298035 and batch: 1100, loss is 4.63238862991333 and perplexity is 102.75922495326131
At time: 119.5584282875061 and batch: 1150, loss is 4.662898159027099 and perplexity is 105.94267638656805
At time: 120.64042592048645 and batch: 1200, loss is 4.625809125900268 and perplexity is 102.08533956713603
At time: 121.72251415252686 and batch: 1250, loss is 4.666571893692017 and perplexity is 106.33259746405123
At time: 122.80359053611755 and batch: 1300, loss is 4.657212562561035 and perplexity is 105.34203819131807
At time: 123.8849093914032 and batch: 1350, loss is 4.63887225151062 and perplexity is 103.427641421678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.846378987630208 and perplexity of 127.27867675317268
Finished 4 epochs...
Completing Train Step...
At time: 127.13042879104614 and batch: 50, loss is 4.692700080871582 and perplexity is 109.14748934700017
At time: 128.21873664855957 and batch: 100, loss is 4.7199407482147215 and perplexity is 112.16160669548188
At time: 129.3066737651825 and batch: 150, loss is 4.6563831615448 and perplexity is 105.25470362048723
At time: 130.3945620059967 and batch: 200, loss is 4.64171145439148 and perplexity is 103.72171074285203
At time: 131.47952938079834 and batch: 250, loss is 4.664748315811157 and perplexity is 106.13886838501928
At time: 132.56466460227966 and batch: 300, loss is 4.654289722442627 and perplexity is 105.03458978608161
At time: 133.67631030082703 and batch: 350, loss is 4.663721208572388 and perplexity is 106.0299083513848
At time: 134.76414728164673 and batch: 400, loss is 4.670709257125854 and perplexity is 106.7734454098482
At time: 135.84552931785583 and batch: 450, loss is 4.639819602966309 and perplexity is 103.52567017484674
At time: 136.92969512939453 and batch: 500, loss is 4.69869174003601 and perplexity is 109.80342701695167
At time: 138.01566767692566 and batch: 550, loss is 4.681841716766358 and perplexity is 107.96873740699151
At time: 139.102224111557 and batch: 600, loss is 4.62594970703125 and perplexity is 102.09969184843534
At time: 140.18917846679688 and batch: 650, loss is 4.6499668216705325 and perplexity is 104.58151567956838
At time: 141.2759017944336 and batch: 700, loss is 4.656120805740357 and perplexity is 105.22709306010124
At time: 142.36277723312378 and batch: 750, loss is 4.616961793899536 and perplexity is 101.18614029822702
At time: 143.44919228553772 and batch: 800, loss is 4.571979665756226 and perplexity is 96.73542414770426
At time: 144.53823590278625 and batch: 850, loss is 4.5764951992034915 and perplexity is 97.1732238967877
At time: 145.62606477737427 and batch: 900, loss is 4.625708599090576 and perplexity is 102.0750777694345
At time: 146.71143770217896 and batch: 950, loss is 4.594468374252319 and perplexity is 98.93552489192452
At time: 147.7973597049713 and batch: 1000, loss is 4.600798397064209 and perplexity is 99.56377534345252
At time: 148.88302731513977 and batch: 1050, loss is 4.540474462509155 and perplexity is 93.73526343883833
At time: 149.96870279312134 and batch: 1100, loss is 4.519982814788818 and perplexity is 91.83401977757242
At time: 151.05298805236816 and batch: 1150, loss is 4.56438214302063 and perplexity is 96.00325940439882
At time: 152.13813400268555 and batch: 1200, loss is 4.517406911849975 and perplexity is 91.59776866673955
At time: 153.22108602523804 and batch: 1250, loss is 4.558145942687989 and perplexity is 95.40642676436414
At time: 154.30454874038696 and batch: 1300, loss is 4.557359199523926 and perplexity is 95.33139592916811
At time: 155.39194560050964 and batch: 1350, loss is 4.541778697967529 and perplexity is 93.8575960510396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.836871337890625 and perplexity of 126.07429019065009
Finished 5 epochs...
Completing Train Step...
At time: 158.67317581176758 and batch: 50, loss is 4.596607637405396 and perplexity is 99.14740056296101
At time: 159.75157618522644 and batch: 100, loss is 4.618807859420777 and perplexity is 101.37310906826046
At time: 160.8630690574646 and batch: 150, loss is 4.575081949234009 and perplexity is 97.03599083623136
At time: 161.94256138801575 and batch: 200, loss is 4.554527959823608 and perplexity is 95.0618716203288
At time: 163.0218379497528 and batch: 250, loss is 4.572944631576538 and perplexity is 96.8288155781425
At time: 164.10150527954102 and batch: 300, loss is 4.560811281204224 and perplexity is 95.66105637462802
At time: 165.1808841228485 and batch: 350, loss is 4.574779167175293 and perplexity is 97.00661452669058
At time: 166.26229047775269 and batch: 400, loss is 4.58447979927063 and perplexity is 97.95221907064017
At time: 167.34395146369934 and batch: 450, loss is 4.542403078079223 and perplexity is 93.91621716637012
At time: 168.42543387413025 and batch: 500, loss is 4.606012086868287 and perplexity is 100.08422553782184
At time: 169.5115089416504 and batch: 550, loss is 4.587335300445557 and perplexity is 98.23232147332612
At time: 170.59387469291687 and batch: 600, loss is 4.532868137359619 and perplexity is 93.02498726738384
At time: 171.67439723014832 and batch: 650, loss is 4.551649122238159 and perplexity is 94.78859747603856
At time: 172.75588870048523 and batch: 700, loss is 4.570669221878052 and perplexity is 96.6087408271473
At time: 173.83696508407593 and batch: 750, loss is 4.529054927825928 and perplexity is 92.6709389582633
At time: 174.91768836975098 and batch: 800, loss is 4.492211465835571 and perplexity is 89.3187530000028
At time: 175.99912452697754 and batch: 850, loss is 4.491774377822876 and perplexity is 89.27972137450679
At time: 177.08052372932434 and batch: 900, loss is 4.54041597366333 and perplexity is 93.72978113179514
At time: 178.16254115104675 and batch: 950, loss is 4.497416257858276 and perplexity is 89.78485045103356
At time: 179.24380540847778 and batch: 1000, loss is 4.51524133682251 and perplexity is 91.39962145510778
At time: 180.3240876197815 and batch: 1050, loss is 4.453940181732178 and perplexity is 85.96499527711462
At time: 181.40528440475464 and batch: 1100, loss is 4.44028528213501 and perplexity is 84.79912990025444
At time: 182.48501348495483 and batch: 1150, loss is 4.485286540985108 and perplexity is 88.7023640345938
At time: 183.57049655914307 and batch: 1200, loss is 4.442984361648559 and perplexity is 85.02831865473377
At time: 184.64976167678833 and batch: 1250, loss is 4.488445291519165 and perplexity is 88.98299566367606
At time: 185.73336601257324 and batch: 1300, loss is 4.473277730941772 and perplexity is 87.64352461991233
At time: 186.81277799606323 and batch: 1350, loss is 4.4604620933532715 and perplexity is 86.52748363469674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.8419791666666665 and perplexity of 126.71990351549853
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 190.05375933647156 and batch: 50, loss is 4.509308032989502 and perplexity is 90.85892537408309
At time: 191.16031336784363 and batch: 100, loss is 4.522255706787109 and perplexity is 92.04298597513433
At time: 192.2440686225891 and batch: 150, loss is 4.466497497558594 and perplexity is 87.05129107810384
At time: 193.3284342288971 and batch: 200, loss is 4.447011365890503 and perplexity is 85.37141842308914
At time: 194.4171643257141 and batch: 250, loss is 4.446309785842896 and perplexity is 85.31154454490267
At time: 195.51452374458313 and batch: 300, loss is 4.424859800338745 and perplexity is 83.50109957548146
At time: 196.60466814041138 and batch: 350, loss is 4.425472049713135 and perplexity is 83.55223872481605
At time: 197.69023609161377 and batch: 400, loss is 4.436062755584717 and perplexity is 84.44181823270777
At time: 198.77830004692078 and batch: 450, loss is 4.374904403686523 and perplexity is 79.43224575943204
At time: 199.86586785316467 and batch: 500, loss is 4.429120492935181 and perplexity is 83.85763108846805
At time: 200.95038270950317 and batch: 550, loss is 4.402299575805664 and perplexity is 81.63838663516039
At time: 202.03487586975098 and batch: 600, loss is 4.3336826610565184 and perplexity is 76.22447924646704
At time: 203.12359380722046 and batch: 650, loss is 4.3388125705719 and perplexity is 76.61650860570954
At time: 204.21186137199402 and batch: 700, loss is 4.34207221031189 and perplexity is 76.86665829934925
At time: 205.30161094665527 and batch: 750, loss is 4.291973381042481 and perplexity is 73.11060131301362
At time: 206.38862681388855 and batch: 800, loss is 4.249783029556275 and perplexity is 70.09020319429139
At time: 207.47369980812073 and batch: 850, loss is 4.228805198669433 and perplexity is 68.63517776253359
At time: 208.55703401565552 and batch: 900, loss is 4.256691150665283 and perplexity is 70.57607109143109
At time: 209.64199447631836 and batch: 950, loss is 4.212260017395019 and perplexity is 67.50893890919608
At time: 210.72398495674133 and batch: 1000, loss is 4.202196321487427 and perplexity is 66.832956622224
At time: 211.80566811561584 and batch: 1050, loss is 4.134268569946289 and perplexity is 62.44390101708854
At time: 212.88568019866943 and batch: 1100, loss is 4.101777811050415 and perplexity is 60.447656640093754
At time: 213.96687030792236 and batch: 1150, loss is 4.134506831169128 and perplexity is 62.458780749865
At time: 215.04896569252014 and batch: 1200, loss is 4.074491753578186 and perplexity is 58.820577641842796
At time: 216.17917275428772 and batch: 1250, loss is 4.100600137710571 and perplexity is 60.37651094782795
At time: 217.26431488990784 and batch: 1300, loss is 4.061267657279968 and perplexity is 58.047849237192786
At time: 218.35165286064148 and batch: 1350, loss is 4.034006810188293 and perplexity is 56.4867902644912
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6801171875 and perplexity of 107.78270261680717
Finished 7 epochs...
Completing Train Step...
At time: 221.60493755340576 and batch: 50, loss is 4.337925262451172 and perplexity is 76.54855630721336
At time: 222.71840167045593 and batch: 100, loss is 4.357053861618042 and perplexity is 78.02691736786815
At time: 223.81068301200867 and batch: 150, loss is 4.306412181854248 and perplexity is 74.17388854619557
At time: 224.90209317207336 and batch: 200, loss is 4.295384006500244 and perplexity is 73.36037989956094
At time: 225.99147772789001 and batch: 250, loss is 4.293309183120727 and perplexity is 73.20832786332222
At time: 227.07644629478455 and batch: 300, loss is 4.279974660873413 and perplexity is 72.23860952086288
At time: 228.16892385482788 and batch: 350, loss is 4.295032367706299 and perplexity is 73.3345880790178
At time: 229.25409173965454 and batch: 400, loss is 4.3081435871124265 and perplexity is 74.3024248489491
At time: 230.33958268165588 and batch: 450, loss is 4.2514837455749515 and perplexity is 70.20950814878302
At time: 231.42469310760498 and batch: 500, loss is 4.3088203716278075 and perplexity is 74.35272860002195
At time: 232.50944876670837 and batch: 550, loss is 4.291204051971436 and perplexity is 73.05437683235878
At time: 233.5940477848053 and batch: 600, loss is 4.224472241401672 and perplexity is 68.33842783687486
At time: 234.67535781860352 and batch: 650, loss is 4.236838269233703 and perplexity is 69.18874945207466
At time: 235.76208329200745 and batch: 700, loss is 4.242634296417236 and perplexity is 69.59093373429785
At time: 236.84971952438354 and batch: 750, loss is 4.199842524528504 and perplexity is 66.67583040632
At time: 237.9384515285492 and batch: 800, loss is 4.162104568481445 and perplexity is 64.20650749961831
At time: 239.02839279174805 and batch: 850, loss is 4.148833928108215 and perplexity is 63.3600748029897
At time: 240.11286687850952 and batch: 900, loss is 4.176190705299377 and perplexity is 65.11732906714
At time: 241.19852089881897 and batch: 950, loss is 4.146682167053223 and perplexity is 63.22388563740573
At time: 242.284081697464 and batch: 1000, loss is 4.140443243980408 and perplexity is 62.83066459195852
At time: 243.41795349121094 and batch: 1050, loss is 4.081867842674256 and perplexity is 59.256047521154436
At time: 244.50446438789368 and batch: 1100, loss is 4.052387480735779 and perplexity is 57.53465608328452
At time: 245.59259271621704 and batch: 1150, loss is 4.092833647727966 and perplexity is 59.9094135817511
At time: 246.67737770080566 and batch: 1200, loss is 4.03985182762146 and perplexity is 56.8179233348737
At time: 247.76372647285461 and batch: 1250, loss is 4.072192702293396 and perplexity is 58.68550145028609
At time: 248.85302710533142 and batch: 1300, loss is 4.044326629638672 and perplexity is 57.07274199915871
At time: 249.94365572929382 and batch: 1350, loss is 4.021802439689636 and perplexity is 55.801594245646214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.671298828125 and perplexity of 106.83641449729062
Finished 8 epochs...
Completing Train Step...
At time: 253.25070309638977 and batch: 50, loss is 4.270208292007446 and perplexity is 71.53653455588902
At time: 254.3356900215149 and batch: 100, loss is 4.286951160430908 and perplexity is 72.74434422595318
At time: 255.42204070091248 and batch: 150, loss is 4.237733602523804 and perplexity is 69.25072418263919
At time: 256.50814962387085 and batch: 200, loss is 4.224568982124328 and perplexity is 68.34503926556098
At time: 257.5924105644226 and batch: 250, loss is 4.225410361289978 and perplexity is 68.40256755583317
At time: 258.6760792732239 and batch: 300, loss is 4.214066839218139 and perplexity is 67.63102579468361
At time: 259.76036834716797 and batch: 350, loss is 4.232150382995606 and perplexity is 68.86515953465567
At time: 260.8462338447571 and batch: 400, loss is 4.243069000244141 and perplexity is 69.62119175567237
At time: 261.9413855075836 and batch: 450, loss is 4.1895478200912475 and perplexity is 65.9929435295307
At time: 263.03751397132874 and batch: 500, loss is 4.246736488342285 and perplexity is 69.87699543957477
At time: 264.1278853416443 and batch: 550, loss is 4.236084780693054 and perplexity is 69.13663615807117
At time: 265.2174208164215 and batch: 600, loss is 4.168496050834656 and perplexity is 64.61819650929061
At time: 266.30749893188477 and batch: 650, loss is 4.18296868801117 and perplexity is 65.56019236220826
At time: 267.3928952217102 and batch: 700, loss is 4.190667023658753 and perplexity is 66.06684441471218
At time: 268.48490166664124 and batch: 750, loss is 4.149795365333557 and perplexity is 63.421020830700975
At time: 269.56950306892395 and batch: 800, loss is 4.115362224578857 and perplexity is 61.274405339101364
At time: 270.68423104286194 and batch: 850, loss is 4.10394877910614 and perplexity is 60.579029122836936
At time: 271.77186393737793 and batch: 900, loss is 4.132321462631226 and perplexity is 62.32243433334697
At time: 272.8605213165283 and batch: 950, loss is 4.104106340408325 and perplexity is 60.5885747855444
At time: 273.9496192932129 and batch: 1000, loss is 4.103841619491577 and perplexity is 60.572537845233136
At time: 275.0413553714752 and batch: 1050, loss is 4.045991621017456 and perplexity is 57.16784677489597
At time: 276.13728189468384 and batch: 1100, loss is 4.018985123634338 and perplexity is 55.644604766595634
At time: 277.235497713089 and batch: 1150, loss is 4.058288254737854 and perplexity is 57.87515871265063
At time: 278.3303909301758 and batch: 1200, loss is 4.01227267742157 and perplexity is 55.272344137536464
At time: 279.4262206554413 and batch: 1250, loss is 4.044833483695984 and perplexity is 57.10167688226494
At time: 280.5208387374878 and batch: 1300, loss is 4.019785733222961 and perplexity is 55.68917220890719
At time: 281.6139512062073 and batch: 1350, loss is 4.003934798240661 and perplexity is 54.81340595442081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.669861246744792 and perplexity of 106.68293880041477
Finished 9 epochs...
Completing Train Step...
At time: 284.9336721897125 and batch: 50, loss is 4.219944095611572 and perplexity is 68.0296810253984
At time: 286.02280735969543 and batch: 100, loss is 4.235966262817382 and perplexity is 69.12844271636688
At time: 287.11079931259155 and batch: 150, loss is 4.189479904174805 and perplexity is 65.9884617104873
At time: 288.2012903690338 and batch: 200, loss is 4.177237968444825 and perplexity is 65.18555976751489
At time: 289.2925863265991 and batch: 250, loss is 4.176349201202393 and perplexity is 65.1276507149603
At time: 290.38197112083435 and batch: 300, loss is 4.168139443397522 and perplexity is 64.59515728806421
At time: 291.4726126194 and batch: 350, loss is 4.1877986478805544 and perplexity is 65.87761140388749
At time: 292.5609714984894 and batch: 400, loss is 4.1968594169616695 and perplexity is 66.47722560912746
At time: 293.64782905578613 and batch: 450, loss is 4.146688532829285 and perplexity is 63.224288107784474
At time: 294.73470854759216 and batch: 500, loss is 4.20433856010437 and perplexity is 66.97628222679475
At time: 295.8218867778778 and batch: 550, loss is 4.195048370361328 and perplexity is 66.35694120889161
At time: 296.91041922569275 and batch: 600, loss is 4.1274078702926635 and perplexity is 62.01695840418045
At time: 297.999320268631 and batch: 650, loss is 4.142744288444519 and perplexity is 62.97540721062967
At time: 299.1474087238312 and batch: 700, loss is 4.152559723854065 and perplexity is 63.59658181496661
At time: 300.23843717575073 and batch: 750, loss is 4.111796398162841 and perplexity is 61.05630053894877
At time: 301.32874178886414 and batch: 800, loss is 4.078946390151978 and perplexity is 59.08318641736315
At time: 302.41914558410645 and batch: 850, loss is 4.071037015914917 and perplexity is 58.617718591053624
At time: 303.5058183670044 and batch: 900, loss is 4.098786187171936 and perplexity is 60.26709021517504
At time: 304.59836316108704 and batch: 950, loss is 4.071293029785156 and perplexity is 58.63272746121222
At time: 305.6862554550171 and batch: 1000, loss is 4.071187071800232 and perplexity is 58.62651518468575
At time: 306.77269887924194 and batch: 1050, loss is 4.014592604637146 and perplexity is 55.40072080765766
At time: 307.8596770763397 and batch: 1100, loss is 3.987623105049133 and perplexity is 53.92655914387274
At time: 308.94922518730164 and batch: 1150, loss is 4.033339405059815 and perplexity is 56.44910326862347
At time: 310.0410304069519 and batch: 1200, loss is 3.988672695159912 and perplexity is 53.98318964126464
At time: 311.1315088272095 and batch: 1250, loss is 4.0226392602920535 and perplexity is 55.848309712865316
At time: 312.22348284721375 and batch: 1300, loss is 3.9961183977127077 and perplexity is 54.38663250812305
At time: 313.3140935897827 and batch: 1350, loss is 3.9835210180282594 and perplexity is 53.70580080005721
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.673039143880208 and perplexity of 107.02250547423198
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 316.59605073928833 and batch: 50, loss is 4.192554063796997 and perplexity is 66.19163290534506
At time: 317.7118306159973 and batch: 100, loss is 4.215109205245971 and perplexity is 67.70155883263438
At time: 318.799218416214 and batch: 150, loss is 4.179999532699585 and perplexity is 65.36582266852675
At time: 319.88693928718567 and batch: 200, loss is 4.172337236404419 and perplexity is 64.8668843154963
At time: 320.9757034778595 and batch: 250, loss is 4.170021543502807 and perplexity is 64.71684631994526
At time: 322.07181787490845 and batch: 300, loss is 4.166969237327575 and perplexity is 64.51961185340053
At time: 323.1635763645172 and batch: 350, loss is 4.178290638923645 and perplexity is 65.25421481115656
At time: 324.25393629074097 and batch: 400, loss is 4.178484773635864 and perplexity is 65.26688414910933
At time: 325.34508514404297 and batch: 450, loss is 4.119740409851074 and perplexity is 61.54326416552959
At time: 326.4643518924713 and batch: 500, loss is 4.178723840713501 and perplexity is 65.28248917761931
At time: 327.55396270751953 and batch: 550, loss is 4.161103820800781 and perplexity is 64.14228512670975
At time: 328.6417553424835 and batch: 600, loss is 4.09314875125885 and perplexity is 59.9282942240262
At time: 329.7289505004883 and batch: 650, loss is 4.100881767272949 and perplexity is 60.393517152796754
At time: 330.81612157821655 and batch: 700, loss is 4.102698950767517 and perplexity is 60.50336303017603
At time: 331.9038202762604 and batch: 750, loss is 4.062780232429504 and perplexity is 58.13571740828631
At time: 332.9911947250366 and batch: 800, loss is 4.023787727355957 and perplexity is 55.91248650255587
At time: 334.07857155799866 and batch: 850, loss is 4.003826603889466 and perplexity is 54.80747577433853
At time: 335.1672215461731 and batch: 900, loss is 4.025901226997376 and perplexity is 56.03078248795671
At time: 336.25828552246094 and batch: 950, loss is 3.994684405326843 and perplexity is 54.30869838303945
At time: 337.3505311012268 and batch: 1000, loss is 3.9882744932174683 and perplexity is 53.96169770963862
At time: 338.44171380996704 and batch: 1050, loss is 3.9268549633026124 and perplexity is 50.747124859517086
At time: 339.53340792655945 and batch: 1100, loss is 3.894143834114075 and perplexity is 49.11398563775324
At time: 340.62609028816223 and batch: 1150, loss is 3.9370234918594362 and perplexity is 51.26578096349535
At time: 341.71517848968506 and batch: 1200, loss is 3.886038579940796 and perplexity is 48.71751322605491
At time: 342.8047866821289 and batch: 1250, loss is 3.918120765686035 and perplexity is 50.30581947220793
At time: 343.8941342830658 and batch: 1300, loss is 3.8822825860977175 and perplexity is 48.534873757402956
At time: 344.9852957725525 and batch: 1350, loss is 3.8676136207580565 and perplexity is 47.828113768633486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6353243001302085 and perplexity of 103.06133538078862
Finished 11 epochs...
Completing Train Step...
At time: 348.2123098373413 and batch: 50, loss is 4.159704933166504 and perplexity is 64.05262000754696
At time: 349.3272545337677 and batch: 100, loss is 4.175017957687378 and perplexity is 65.04100763661175
At time: 350.40974259376526 and batch: 150, loss is 4.139417185783386 and perplexity is 62.76622973613866
At time: 351.4910624027252 and batch: 200, loss is 4.131204977035522 and perplexity is 62.25289106237879
At time: 352.5868344306946 and batch: 250, loss is 4.127056350708008 and perplexity is 61.995162059866004
At time: 353.69718289375305 and batch: 300, loss is 4.124604368209839 and perplexity is 61.843337219516734
At time: 354.7815418243408 and batch: 350, loss is 4.13808090209961 and perplexity is 62.68241226188415
At time: 355.86418294906616 and batch: 400, loss is 4.141528043746948 and perplexity is 62.898860264876824
At time: 356.94537448883057 and batch: 450, loss is 4.084193067550659 and perplexity is 59.393991470127375
At time: 358.0336673259735 and batch: 500, loss is 4.146889414787292 and perplexity is 63.23699000232121
At time: 359.11574387550354 and batch: 550, loss is 4.129651708602905 and perplexity is 62.156270669981055
At time: 360.1972427368164 and batch: 600, loss is 4.0628467512130735 and perplexity is 58.13958465411106
At time: 361.27985167503357 and batch: 650, loss is 4.07285849571228 and perplexity is 58.724586880903026
At time: 362.3612287044525 and batch: 700, loss is 4.079309220314026 and perplexity is 59.104627468960196
At time: 363.4425456523895 and batch: 750, loss is 4.041591019630432 and perplexity is 56.916826594052985
At time: 364.5290689468384 and batch: 800, loss is 4.0046222257614135 and perplexity is 54.8510991523665
At time: 365.6254816055298 and batch: 850, loss is 3.9876156854629516 and perplexity is 53.92615903260403
At time: 366.7094807624817 and batch: 900, loss is 4.013629970550537 and perplexity is 55.347415846088296
At time: 367.7935209274292 and batch: 950, loss is 3.9826138734817507 and perplexity is 53.65710396661843
At time: 368.8825662136078 and batch: 1000, loss is 3.9785839128494263 and perplexity is 53.44130307659496
At time: 369.96857833862305 and batch: 1050, loss is 3.920709466934204 and perplexity is 50.43621491446883
At time: 371.05181980133057 and batch: 1100, loss is 3.890240797996521 and perplexity is 48.92266558534516
At time: 372.1300575733185 and batch: 1150, loss is 3.9354099798202515 and perplexity is 51.18312970604336
At time: 373.2094097137451 and batch: 1200, loss is 3.8872374391555784 and perplexity is 48.77595368965188
At time: 374.2880721092224 and batch: 1250, loss is 3.9231741189956666 and perplexity is 50.56067594909961
At time: 375.3678779602051 and batch: 1300, loss is 3.8890006351470947 and perplexity is 48.86203111906889
At time: 376.4476056098938 and batch: 1350, loss is 3.8749636125564577 and perplexity is 48.1809450777827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.633543701171875 and perplexity of 102.87798775710145
Finished 12 epochs...
Completing Train Step...
At time: 379.6815309524536 and batch: 50, loss is 4.1442818927764895 and perplexity is 63.072312951815775
At time: 380.76305866241455 and batch: 100, loss is 4.156733388900757 and perplexity is 63.86256732668276
At time: 381.8750412464142 and batch: 150, loss is 4.120446729660034 and perplexity is 61.58674874732068
At time: 382.95689153671265 and batch: 200, loss is 4.112274146080017 and perplexity is 61.08547702831026
At time: 384.04001450538635 and batch: 250, loss is 4.108714423179626 and perplexity is 60.86841622421828
At time: 385.12122988700867 and batch: 300, loss is 4.105588870048523 and perplexity is 60.67846576007413
At time: 386.20121669769287 and batch: 350, loss is 4.119980883598328 and perplexity is 61.55806548447469
At time: 387.2803854942322 and batch: 400, loss is 4.124003686904907 and perplexity is 61.806200237876304
At time: 388.3615834712982 and batch: 450, loss is 4.068469095230102 and perplexity is 58.46738604262781
At time: 389.44311809539795 and batch: 500, loss is 4.131824979782104 and perplexity is 62.291499993405
At time: 390.52375984191895 and batch: 550, loss is 4.115270977020264 and perplexity is 61.268814454291075
At time: 391.60527777671814 and batch: 600, loss is 4.048720750808716 and perplexity is 57.324078339770885
At time: 392.686772108078 and batch: 650, loss is 4.059474716186523 and perplexity is 57.943866108577154
At time: 393.76693892478943 and batch: 700, loss is 4.067417888641358 and perplexity is 58.40595703413912
At time: 394.84769439697266 and batch: 750, loss is 4.030499930381775 and perplexity is 56.289044817794036
At time: 395.92867732048035 and batch: 800, loss is 3.9942279386520387 and perplexity is 54.28391392914457
At time: 397.010333776474 and batch: 850, loss is 3.978271541595459 and perplexity is 53.42461215675678
At time: 398.0933656692505 and batch: 900, loss is 4.005166945457458 and perplexity is 54.88098576559893
At time: 399.17721462249756 and batch: 950, loss is 3.9760949325561525 and perplexity is 53.30845412418623
At time: 400.25890851020813 and batch: 1000, loss is 3.9724631452560426 and perplexity is 53.11520029832092
At time: 401.34156489372253 and batch: 1050, loss is 3.9157942724227905 and perplexity is 50.188919358494864
At time: 402.4249427318573 and batch: 1100, loss is 3.886771068572998 and perplexity is 48.75321132331125
At time: 403.50601267814636 and batch: 1150, loss is 3.932744975090027 and perplexity is 51.04690801961177
At time: 404.59076476097107 and batch: 1200, loss is 3.8859176731109617 and perplexity is 48.71162330204654
At time: 405.6737141609192 and batch: 1250, loss is 3.9232481956481933 and perplexity is 50.56442145344891
At time: 406.75683879852295 and batch: 1300, loss is 3.889884033203125 and perplexity is 48.905214813760786
At time: 407.8402523994446 and batch: 1350, loss is 3.8759754610061647 and perplexity is 48.22972156541017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6333837890625 and perplexity of 102.8615376363928
Finished 13 epochs...
Completing Train Step...
At time: 411.1183650493622 and batch: 50, loss is 4.131452980041504 and perplexity is 62.26833188109892
At time: 412.20180583000183 and batch: 100, loss is 4.14225323677063 and perplexity is 62.944490622947335
At time: 413.28572702407837 and batch: 150, loss is 4.106043124198914 and perplexity is 60.706035466337674
At time: 414.3700201511383 and batch: 200, loss is 4.0980906629562375 and perplexity is 60.22518756836267
At time: 415.4542305469513 and batch: 250, loss is 4.095071482658386 and perplexity is 60.043631082418585
At time: 416.5373475551605 and batch: 300, loss is 4.092207326889038 and perplexity is 59.87190281569033
At time: 417.6212387084961 and batch: 350, loss is 4.107047548294068 and perplexity is 60.767040703517544
At time: 418.70579743385315 and batch: 400, loss is 4.110963864326477 and perplexity is 61.00549025640136
At time: 419.79450392723083 and batch: 450, loss is 4.057021098136902 and perplexity is 57.801868268298705
At time: 420.88017892837524 and batch: 500, loss is 4.120805444717408 and perplexity is 61.60884480428826
At time: 421.96504259109497 and batch: 550, loss is 4.104352440834045 and perplexity is 60.60348749452964
At time: 423.04912209510803 and batch: 600, loss is 4.037788195610046 and perplexity is 56.700792948033104
At time: 424.1334664821625 and batch: 650, loss is 4.049292325973511 and perplexity is 57.35685272491467
At time: 425.22297716140747 and batch: 700, loss is 4.058192486763001 and perplexity is 57.86961639129908
At time: 426.3055696487427 and batch: 750, loss is 4.021669149398804 and perplexity is 55.794156930592266
At time: 427.3941116333008 and batch: 800, loss is 3.985751328468323 and perplexity is 53.825715081603256
At time: 428.47160506248474 and batch: 850, loss is 3.9706156206130983 and perplexity is 53.017159251367325
At time: 429.5481550693512 and batch: 900, loss is 3.9978557634353638 and perplexity is 54.48120410815324
At time: 430.6248643398285 and batch: 950, loss is 3.9704684352874757 and perplexity is 53.009356477760306
At time: 431.7018938064575 and batch: 1000, loss is 3.9669352388381958 and perplexity is 52.82239448888669
At time: 432.7788598537445 and batch: 1050, loss is 3.9107474422454835 and perplexity is 49.936262500113045
At time: 433.85601329803467 and batch: 1100, loss is 3.8825453472137452 and perplexity is 48.54762851065093
At time: 434.9323434829712 and batch: 1150, loss is 3.9291665077209474 and perplexity is 50.86456477422988
At time: 436.06802701950073 and batch: 1200, loss is 3.8832059478759766 and perplexity is 48.57970970145611
At time: 437.1461772918701 and batch: 1250, loss is 3.921343364715576 and perplexity is 50.46819645464667
At time: 438.2248969078064 and batch: 1300, loss is 3.8885243272781373 and perplexity is 48.83876329091835
At time: 439.302428483963 and batch: 1350, loss is 3.8746519756317137 and perplexity is 48.16593245559261
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.633848470052083 and perplexity of 102.9093465445768
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 442.54184579849243 and batch: 50, loss is 4.125338759422302 and perplexity is 61.88877110400089
At time: 443.6582205295563 and batch: 100, loss is 4.1405660963058475 and perplexity is 62.83838395937397
At time: 444.7351417541504 and batch: 150, loss is 4.108359160423279 and perplexity is 60.846795783592036
At time: 445.8119807243347 and batch: 200, loss is 4.103525881767273 and perplexity is 60.553415828908356
At time: 446.8886249065399 and batch: 250, loss is 4.1019553232193 and perplexity is 60.458387787154365
At time: 447.9652602672577 and batch: 300, loss is 4.10579487323761 and perplexity is 60.690967005133565
At time: 449.04096126556396 and batch: 350, loss is 4.12116051197052 and perplexity is 61.6307239716384
At time: 450.1177728176117 and batch: 400, loss is 4.122284369468689 and perplexity is 61.70002705899424
At time: 451.19529461860657 and batch: 450, loss is 4.066292204856873 and perplexity is 58.340247386469635
At time: 452.27271032333374 and batch: 500, loss is 4.132006182670593 and perplexity is 62.30278841584858
At time: 453.3496799468994 and batch: 550, loss is 4.117394156455994 and perplexity is 61.39903733554457
At time: 454.426296710968 and batch: 600, loss is 4.051664395332336 and perplexity is 57.49306865072335
At time: 455.50259923934937 and batch: 650, loss is 4.056786274909973 and perplexity is 57.78829664059848
At time: 456.58001160621643 and batch: 700, loss is 4.062151393890381 and perplexity is 58.09917092080462
At time: 457.65643191337585 and batch: 750, loss is 4.021671347618103 and perplexity is 55.79427957851961
At time: 458.7331893444061 and batch: 800, loss is 3.984212136268616 and perplexity is 53.74293068769647
At time: 459.8105080127716 and batch: 850, loss is 3.9643215131759644 and perplexity is 52.68451151350248
At time: 460.90780663490295 and batch: 900, loss is 3.986992931365967 and perplexity is 53.89258675085484
At time: 461.9858627319336 and batch: 950, loss is 3.958852615356445 and perplexity is 52.39717173547296
At time: 463.069463968277 and batch: 1000, loss is 3.955353741645813 and perplexity is 52.21416100120288
At time: 464.20326924324036 and batch: 1050, loss is 3.897285804748535 and perplexity is 49.268543018595416
At time: 465.28438782691956 and batch: 1100, loss is 3.862933235168457 and perplexity is 47.60478279938884
At time: 466.3653030395508 and batch: 1150, loss is 3.908467311859131 and perplexity is 49.82253102118027
At time: 467.44446778297424 and batch: 1200, loss is 3.859242362976074 and perplexity is 47.429403480747865
At time: 468.52666187286377 and batch: 1250, loss is 3.89680419921875 and perplexity is 49.24482072868472
At time: 469.60772013664246 and batch: 1300, loss is 3.8673627948760987 and perplexity is 47.81611874420927
At time: 470.68877243995667 and batch: 1350, loss is 3.8502382230758667 and perplexity is 47.00425939718626
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.622058512369792 and perplexity of 101.70317403689324
Finished 15 epochs...
Completing Train Step...
At time: 473.907443523407 and batch: 50, loss is 4.122140288352966 and perplexity is 61.69113789065148
At time: 475.01473450660706 and batch: 100, loss is 4.132290043830872 and perplexity is 62.32047626798525
At time: 476.0960953235626 and batch: 150, loss is 4.096429986953735 and perplexity is 60.12525604452976
At time: 477.17735385894775 and batch: 200, loss is 4.090492749214173 and perplexity is 59.769335742504815
At time: 478.2593958377838 and batch: 250, loss is 4.088801655769348 and perplexity is 59.668345626558285
At time: 479.3402235507965 and batch: 300, loss is 4.090164127349854 and perplexity is 59.749697458925425
At time: 480.4205684661865 and batch: 350, loss is 4.105593318939209 and perplexity is 60.6787357125358
At time: 481.50184988975525 and batch: 400, loss is 4.106720857620239 and perplexity is 60.74719192042623
At time: 482.5831079483032 and batch: 450, loss is 4.050463743209839 and perplexity is 57.42408089925163
At time: 483.66714119911194 and batch: 500, loss is 4.113048624992371 and perplexity is 61.132804766921865
At time: 484.74924182891846 and batch: 550, loss is 4.0988692998886105 and perplexity is 60.27209938492884
At time: 485.8322265148163 and batch: 600, loss is 4.034059224128723 and perplexity is 56.48975103734339
At time: 486.913290977478 and batch: 650, loss is 4.041389875411987 and perplexity is 56.90537925477301
At time: 487.99504470825195 and batch: 700, loss is 4.048706488609314 and perplexity is 57.3232607781652
At time: 489.0770959854126 and batch: 750, loss is 4.012521276473999 and perplexity is 55.28608649801271
At time: 490.1627621650696 and batch: 800, loss is 3.9782709789276125 and perplexity is 53.42458209645376
At time: 491.29765248298645 and batch: 850, loss is 3.9598091506958006 and perplexity is 52.44731546021931
At time: 492.37372946739197 and batch: 900, loss is 3.982323293685913 and perplexity is 53.641514561395354
At time: 493.4506185054779 and batch: 950, loss is 3.955131645202637 and perplexity is 52.20256570944528
At time: 494.5372290611267 and batch: 1000, loss is 3.952908592224121 and perplexity is 52.08664553634123
At time: 495.618248462677 and batch: 1050, loss is 3.895780658721924 and perplexity is 49.194442446913925
At time: 496.70009541511536 and batch: 1100, loss is 3.8625065803527834 and perplexity is 47.584476321794654
At time: 497.7823486328125 and batch: 1150, loss is 3.9072063302993776 and perplexity is 49.759745322425985
At time: 498.86291694641113 and batch: 1200, loss is 3.861146273612976 and perplexity is 47.51979084396433
At time: 499.9451358318329 and batch: 1250, loss is 3.902010235786438 and perplexity is 49.501859562411916
At time: 501.02693915367126 and batch: 1300, loss is 3.8737502765655516 and perplexity is 48.1225208543181
At time: 502.1084794998169 and batch: 1350, loss is 3.858644652366638 and perplexity is 47.401062893666726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.620992431640625 and perplexity of 101.59480801668371
Finished 16 epochs...
Completing Train Step...
At time: 505.3841414451599 and batch: 50, loss is 4.119939641952515 and perplexity is 61.555526780891554
At time: 506.46252608299255 and batch: 100, loss is 4.127894906997681 and perplexity is 62.04717029580969
At time: 507.54712104797363 and batch: 150, loss is 4.090915026664734 and perplexity is 59.79458031495563
At time: 508.62518787384033 and batch: 200, loss is 4.084665660858154 and perplexity is 59.42206730670526
At time: 509.70613646507263 and batch: 250, loss is 4.082484941482544 and perplexity is 59.2926256424604
At time: 510.78469038009644 and batch: 300, loss is 4.083503670692444 and perplexity is 59.35305954980079
At time: 511.8628008365631 and batch: 350, loss is 4.09917290687561 and perplexity is 60.290401193561166
At time: 512.9407451152802 and batch: 400, loss is 4.100512762069702 and perplexity is 60.37123574195604
At time: 514.0187327861786 and batch: 450, loss is 4.044498343467712 and perplexity is 57.08254301968251
At time: 515.0959649085999 and batch: 500, loss is 4.107186193466187 and perplexity is 60.77546634440876
At time: 516.1736047267914 and batch: 550, loss is 4.092957196235656 and perplexity is 59.916815757650205
At time: 517.2510011196136 and batch: 600, loss is 4.028290414810181 and perplexity is 56.16481059602492
At time: 518.3840115070343 and batch: 650, loss is 4.036476225852966 and perplexity is 56.62645199968416
At time: 519.4609217643738 and batch: 700, loss is 4.044532852172852 and perplexity is 57.08451289831699
At time: 520.5379037857056 and batch: 750, loss is 4.008955044746399 and perplexity is 55.08927464916638
At time: 521.6148769855499 and batch: 800, loss is 3.975172071456909 and perplexity is 53.259280519307715
At time: 522.6920745372772 and batch: 850, loss is 3.957130513191223 and perplexity is 52.307016103461066
At time: 523.7684679031372 and batch: 900, loss is 3.9805431175231933 and perplexity is 53.54610816113619
At time: 524.8467950820923 and batch: 950, loss is 3.9542565155029297 and perplexity is 52.15690167768156
At time: 525.9246490001678 and batch: 1000, loss is 3.95257532119751 and perplexity is 52.069289458810125
At time: 527.0019736289978 and batch: 1050, loss is 3.8955955791473387 and perplexity is 49.18533840294617
At time: 528.0788681507111 and batch: 1100, loss is 3.8619487619400026 and perplexity is 47.55794022658916
At time: 529.1639504432678 and batch: 1150, loss is 3.907422242164612 and perplexity is 49.770490201783865
At time: 530.2495563030243 and batch: 1200, loss is 3.8624068832397462 and perplexity is 47.57973252335542
At time: 531.3319506645203 and batch: 1250, loss is 3.9037745285034178 and perplexity is 49.58927242097532
At time: 532.4148256778717 and batch: 1300, loss is 3.8760069513320925 and perplexity is 48.2312403589752
At time: 533.4981184005737 and batch: 1350, loss is 3.861459188461304 and perplexity is 47.53466281881836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.620863850911459 and perplexity of 101.58174572198712
Finished 17 epochs...
Completing Train Step...
At time: 536.7570037841797 and batch: 50, loss is 4.11761579990387 and perplexity is 61.412647538126286
At time: 537.8404762744904 and batch: 100, loss is 4.124297752380371 and perplexity is 61.82437798012806
At time: 538.924652338028 and batch: 150, loss is 4.086508169174194 and perplexity is 59.531653885963564
At time: 540.0073008537292 and batch: 200, loss is 4.080284566879272 and perplexity is 59.16230308663776
At time: 541.0926909446716 and batch: 250, loss is 4.077917137145996 and perplexity is 59.02240615463987
At time: 542.1767349243164 and batch: 300, loss is 4.079049615859986 and perplexity is 59.089285635905114
At time: 543.2601170539856 and batch: 350, loss is 4.094996328353882 and perplexity is 60.03911871464874
At time: 544.3439743518829 and batch: 400, loss is 4.096352381706238 and perplexity is 60.12059019020331
At time: 545.4272730350494 and batch: 450, loss is 4.040514330863953 and perplexity is 56.855577865061704
At time: 546.5390903949738 and batch: 500, loss is 4.103321981430054 and perplexity is 60.54107022568019
At time: 547.6215577125549 and batch: 550, loss is 4.089187450408936 and perplexity is 59.69136979546897
At time: 548.704980134964 and batch: 600, loss is 4.024742112159729 and perplexity is 55.965874002071814
At time: 549.7884140014648 and batch: 650, loss is 4.033143515586853 and perplexity is 56.43804656651614
At time: 550.8718976974487 and batch: 700, loss is 4.041632924079895 and perplexity is 56.91921171230979
At time: 551.9546148777008 and batch: 750, loss is 4.0063720178604125 and perplexity is 54.947161192073764
At time: 553.0379106998444 and batch: 800, loss is 3.9729764318466185 and perplexity is 53.142470616535405
At time: 554.1217787265778 and batch: 850, loss is 3.955404086112976 and perplexity is 52.216789761488066
At time: 555.2065801620483 and batch: 900, loss is 3.9789998388290404 and perplexity is 53.46353532609352
At time: 556.2896628379822 and batch: 950, loss is 3.953264422416687 and perplexity is 52.10518283532227
At time: 557.3731055259705 and batch: 1000, loss is 3.952034101486206 and perplexity is 52.041116157662096
At time: 558.4560742378235 and batch: 1050, loss is 3.8952643728256224 and perplexity is 49.169050605391014
At time: 559.5394310951233 and batch: 1100, loss is 3.86158477306366 and perplexity is 47.54063281540857
At time: 560.6231207847595 and batch: 1150, loss is 3.9073289585113526 and perplexity is 49.76584764517403
At time: 561.7073798179626 and batch: 1200, loss is 3.86282591342926 and perplexity is 47.5996740454498
At time: 562.7891383171082 and batch: 1250, loss is 3.904475812911987 and perplexity is 49.62406080140511
At time: 563.8728849887848 and batch: 1300, loss is 3.877043843269348 and perplexity is 48.281276879976815
At time: 564.9560005664825 and batch: 1350, loss is 3.8629039907455445 and perplexity is 47.60339064534447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.620858561197917 and perplexity of 101.58120838507234
Finished 18 epochs...
Completing Train Step...
At time: 568.1715993881226 and batch: 50, loss is 4.115279393196106 and perplexity is 61.26933010557708
At time: 569.2811210155487 and batch: 100, loss is 4.121149315834045 and perplexity is 61.63003394950458
At time: 570.3641483783722 and batch: 150, loss is 4.082721810340882 and perplexity is 59.3066718824969
At time: 571.4476075172424 and batch: 200, loss is 4.07657573223114 and perplexity is 58.943286286691055
At time: 572.5301985740662 and batch: 250, loss is 4.0741333532333375 and perplexity is 58.79950010385585
At time: 573.6400661468506 and batch: 300, loss is 4.07541597366333 and perplexity is 58.87496593062215
At time: 574.7230191230774 and batch: 350, loss is 4.091559543609619 and perplexity is 59.833131357246366
At time: 575.8061590194702 and batch: 400, loss is 4.092938556671142 and perplexity is 59.915698944705895
At time: 576.8886520862579 and batch: 450, loss is 4.037264752388 and perplexity is 56.67112106872936
At time: 577.9715299606323 and batch: 500, loss is 4.10021276473999 and perplexity is 60.35312724882768
At time: 579.0540935993195 and batch: 550, loss is 4.086174020767212 and perplexity is 59.511764801790505
At time: 580.137145280838 and batch: 600, loss is 4.021910471916199 and perplexity is 55.80762294175919
At time: 581.2198495864868 and batch: 650, loss is 4.030412883758545 and perplexity is 56.284145259765864
At time: 582.3012435436249 and batch: 700, loss is 4.039202189445495 and perplexity is 56.781024229627754
At time: 583.3841164112091 and batch: 750, loss is 4.004142985343933 and perplexity is 54.82481858656713
At time: 584.4669909477234 and batch: 800, loss is 3.971098470687866 and perplexity is 53.04276477199212
At time: 585.5503206253052 and batch: 850, loss is 3.953916473388672 and perplexity is 52.13916914963597
At time: 586.6337018013 and batch: 900, loss is 3.9775199842453004 and perplexity is 53.38447558116942
At time: 587.716801404953 and batch: 950, loss is 3.9522201871871947 and perplexity is 52.0508011663354
At time: 588.799097776413 and batch: 1000, loss is 3.9513504838943483 and perplexity is 52.00555209265207
At time: 589.8821382522583 and batch: 1050, loss is 3.894842095375061 and perplexity is 49.14829200730725
At time: 590.9646291732788 and batch: 1100, loss is 3.860915389060974 and perplexity is 47.50882052483143
At time: 592.0472321510315 and batch: 1150, loss is 3.906951551437378 and perplexity is 49.74706920601117
At time: 593.1308550834656 and batch: 1200, loss is 3.862837815284729 and perplexity is 47.60024057326201
At time: 594.2209272384644 and batch: 1250, loss is 3.9046902799606324 and perplexity is 49.63470466860557
At time: 595.303644657135 and batch: 1300, loss is 3.877522892951965 and perplexity is 48.30441155122854
At time: 596.3870561122894 and batch: 1350, loss is 3.86373432636261 and perplexity is 47.64293385088441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.620902099609375 and perplexity of 101.58563116579917
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 599.6105170249939 and batch: 50, loss is 4.1157601451873775 and perplexity is 61.29879253952365
At time: 600.7197852134705 and batch: 100, loss is 4.125274252891541 and perplexity is 61.884779002843565
At time: 601.8033969402313 and batch: 150, loss is 4.087797026634217 and perplexity is 59.60843116904077
At time: 602.8854284286499 and batch: 200, loss is 4.082318286895752 and perplexity is 59.28274507777772
At time: 603.9681520462036 and batch: 250, loss is 4.0794748878479 and perplexity is 59.11441999796321
At time: 605.05100440979 and batch: 300, loss is 4.080611686706543 and perplexity is 59.18165941475118
At time: 606.1322960853577 and batch: 350, loss is 4.097261681556701 and perplexity is 60.1752826960483
At time: 607.2141401767731 and batch: 400, loss is 4.099267301559448 and perplexity is 60.29609255553319
At time: 608.2965652942657 and batch: 450, loss is 4.044049372673035 and perplexity is 57.05692037732023
At time: 609.379629611969 and batch: 500, loss is 4.110166540145874 and perplexity is 60.956868490101236
At time: 610.461145401001 and batch: 550, loss is 4.0960038375854495 and perplexity is 60.09963916334491
At time: 611.542382478714 and batch: 600, loss is 4.0362085390090945 and perplexity is 56.6112958721072
At time: 612.6223168373108 and batch: 650, loss is 4.040325326919556 and perplexity is 56.844832952031666
At time: 613.7091505527496 and batch: 700, loss is 4.0470121431350705 and perplexity is 57.22621760624242
At time: 614.785727262497 and batch: 750, loss is 4.007366480827332 and perplexity is 55.0018312882041
At time: 615.8618772029877 and batch: 800, loss is 3.972133412361145 and perplexity is 53.09768935668889
At time: 616.9378786087036 and batch: 850, loss is 3.9533518171310424 and perplexity is 52.10973675188383
At time: 618.0139498710632 and batch: 900, loss is 3.972929301261902 and perplexity is 53.13996603984351
At time: 619.091016292572 and batch: 950, loss is 3.946327261924744 and perplexity is 51.74497168538216
At time: 620.1674525737762 and batch: 1000, loss is 3.94513147354126 and perplexity is 51.68313262991785
At time: 621.2447736263275 and batch: 1050, loss is 3.8898730278015137 and perplexity is 48.904676595192534
At time: 622.3211753368378 and batch: 1100, loss is 3.856010985374451 and perplexity is 47.27638852637591
At time: 623.3972671031952 and batch: 1150, loss is 3.900315914154053 and perplexity is 49.41805850393261
At time: 624.473459482193 and batch: 1200, loss is 3.854317264556885 and perplexity is 47.19638329533796
At time: 625.549477815628 and batch: 1250, loss is 3.8969202280044555 and perplexity is 49.25053487693259
At time: 626.6250948905945 and batch: 1300, loss is 3.8672625398635865 and perplexity is 47.81132517891977
At time: 627.7015860080719 and batch: 1350, loss is 3.8559009647369384 and perplexity is 47.271187434089946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.618142496744792 and perplexity of 101.30568161947932
Finished 20 epochs...
Completing Train Step...
At time: 630.9557113647461 and batch: 50, loss is 4.1172181224823 and perplexity is 61.38822997028105
At time: 632.031402349472 and batch: 100, loss is 4.124190106391906 and perplexity is 61.81772319203625
At time: 633.1072947978973 and batch: 150, loss is 4.08431713104248 and perplexity is 59.40136055321
At time: 634.1834666728973 and batch: 200, loss is 4.078842697143554 and perplexity is 59.07706022164363
At time: 635.2598340511322 and batch: 250, loss is 4.075579080581665 and perplexity is 58.884569628075646
At time: 636.3359084129333 and batch: 300, loss is 4.075109438896179 and perplexity is 58.856921472417795
At time: 637.412148475647 and batch: 350, loss is 4.091989741325379 and perplexity is 59.858876971138095
At time: 638.4885158538818 and batch: 400, loss is 4.093372712135315 and perplexity is 59.94171732039376
At time: 639.5665609836578 and batch: 450, loss is 4.038903789520264 and perplexity is 56.764083303954244
At time: 640.642765045166 and batch: 500, loss is 4.103891634941101 and perplexity is 60.575567483706024
At time: 641.7187097072601 and batch: 550, loss is 4.089648370742798 and perplexity is 59.71888910318082
At time: 642.7954378128052 and batch: 600, loss is 4.029275112152099 and perplexity is 56.22014317417848
At time: 643.8720409870148 and batch: 650, loss is 4.034948468208313 and perplexity is 56.54000655541018
At time: 644.9494209289551 and batch: 700, loss is 4.041771340370178 and perplexity is 56.927090803725555
At time: 646.0270807743073 and batch: 750, loss is 4.00270601272583 and perplexity is 54.74609339998106
At time: 647.1091845035553 and batch: 800, loss is 3.9688939905166625 and perplexity is 52.92596184100168
At time: 648.1853818893433 and batch: 850, loss is 3.9506849575042726 and perplexity is 51.97095254003872
At time: 649.2620294094086 and batch: 900, loss is 3.971283688545227 and perplexity is 53.05259014912126
At time: 650.3383991718292 and batch: 950, loss is 3.945398087501526 and perplexity is 51.69691391164668
At time: 651.4143795967102 and batch: 1000, loss is 3.944729332923889 and perplexity is 51.66235292151681
At time: 652.4902155399323 and batch: 1050, loss is 3.890451316833496 and perplexity is 48.93296581216376
At time: 653.5671555995941 and batch: 1100, loss is 3.857437047958374 and perplexity is 47.34385570993571
At time: 654.6430566310883 and batch: 1150, loss is 3.9029751682281493 and perplexity is 49.549648565500426
At time: 655.7788169384003 and batch: 1200, loss is 3.857613139152527 and perplexity is 47.35219328008827
At time: 656.8546011447906 and batch: 1250, loss is 3.900332326889038 and perplexity is 49.41886959608643
At time: 657.9308676719666 and batch: 1300, loss is 3.8703211402893065 and perplexity is 47.957784784995106
At time: 659.0068633556366 and batch: 1350, loss is 3.8589995861053468 and perplexity is 47.417890116236194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.617270914713542 and perplexity of 101.21742387523538
Finished 21 epochs...
Completing Train Step...
At time: 662.2744343280792 and batch: 50, loss is 4.117503137588501 and perplexity is 61.40572903679619
At time: 663.349817276001 and batch: 100, loss is 4.123946952819824 and perplexity is 61.802693819121004
At time: 664.4330680370331 and batch: 150, loss is 4.083440260887146 and perplexity is 59.34929610317186
At time: 665.5149564743042 and batch: 200, loss is 4.0776617097854615 and perplexity is 59.007332142462914
At time: 666.5970044136047 and batch: 250, loss is 4.0739582872390745 and perplexity is 58.78920721190197
At time: 667.6783833503723 and batch: 300, loss is 4.072868871688843 and perplexity is 58.72519620900132
At time: 668.760363817215 and batch: 350, loss is 4.089581980705261 and perplexity is 59.71492449549829
At time: 669.8422555923462 and batch: 400, loss is 4.090659747123718 and perplexity is 59.77931793010776
At time: 670.9241390228271 and batch: 450, loss is 4.036483283042908 and perplexity is 56.62685162472176
At time: 672.007399559021 and batch: 500, loss is 4.101139531135559 and perplexity is 60.4090864255664
At time: 673.0893290042877 and batch: 550, loss is 4.087101802825928 and perplexity is 59.56700437063418
At time: 674.1720385551453 and batch: 600, loss is 4.026545805931091 and perplexity is 56.066910392380215
At time: 675.2542843818665 and batch: 650, loss is 4.03288209438324 and perplexity is 56.42329439280266
At time: 676.3365228176117 and batch: 700, loss is 4.039976716041565 and perplexity is 56.825019678669
At time: 677.4179403781891 and batch: 750, loss is 4.001362643241882 and perplexity is 54.672598545167425
At time: 678.5029683113098 and batch: 800, loss is 3.9679120779037476 and perplexity is 52.87401867751647
At time: 679.587087392807 and batch: 850, loss is 3.950085701942444 and perplexity is 51.939817987384195
At time: 680.6692337989807 and batch: 900, loss is 3.9709693384170532 and perplexity is 53.03591568155574
At time: 681.7502617835999 and batch: 950, loss is 3.9451696348190306 and perplexity is 51.685104961931316
At time: 682.8652839660645 and batch: 1000, loss is 3.944760251045227 and perplexity is 51.663950249106094
At time: 683.947193145752 and batch: 1050, loss is 3.890806574821472 and perplexity is 48.950352727381286
At time: 685.0298118591309 and batch: 1100, loss is 3.8580804014205934 and perplexity is 47.374324343421
At time: 686.1119570732117 and batch: 1150, loss is 3.9040152835845947 and perplexity is 49.6012127275696
At time: 687.194096326828 and batch: 1200, loss is 3.8589632177352904 and perplexity is 47.41616563621961
At time: 688.2842812538147 and batch: 1250, loss is 3.9018745899200438 and perplexity is 49.495145295175035
At time: 689.3655679225922 and batch: 1300, loss is 3.871637406349182 and perplexity is 48.02095155243045
At time: 690.447124004364 and batch: 1350, loss is 3.8603144121170043 and perplexity is 47.48027739680082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616871337890625 and perplexity of 101.17698781777322
Finished 22 epochs...
Completing Train Step...
At time: 693.6766607761383 and batch: 50, loss is 4.117005958557129 and perplexity is 61.375206984004016
At time: 694.786295413971 and batch: 100, loss is 4.123280487060547 and perplexity is 61.76151816246621
At time: 695.8750200271606 and batch: 150, loss is 4.08261091709137 and perplexity is 59.30009553757698
At time: 696.9575362205505 and batch: 200, loss is 4.076621680259705 and perplexity is 58.945994676715195
At time: 698.039315700531 and batch: 250, loss is 4.0727478837966915 and perplexity is 58.718091601090265
At time: 699.1288003921509 and batch: 300, loss is 4.071437926292419 and perplexity is 58.64122375415936
At time: 700.2139573097229 and batch: 350, loss is 4.088091015815735 and perplexity is 59.62595797915178
At time: 701.295428276062 and batch: 400, loss is 4.089149293899536 and perplexity is 59.68909222460862
At time: 702.3781547546387 and batch: 450, loss is 4.0350651979446415 and perplexity is 56.54660684068469
At time: 703.4598340988159 and batch: 500, loss is 4.099681119918824 and perplexity is 60.32104934906483
At time: 704.5422511100769 and batch: 550, loss is 4.085754480361938 and perplexity is 59.486802448591064
At time: 705.6308200359344 and batch: 600, loss is 4.02525716304779 and perplexity is 55.99470669969356
At time: 706.7138388156891 and batch: 650, loss is 4.031811676025391 and perplexity is 56.36293017592098
At time: 707.7957904338837 and batch: 700, loss is 4.039061694145203 and perplexity is 56.77304732294977
At time: 708.8777372837067 and batch: 750, loss is 4.000621118545532 and perplexity is 54.6320724905247
At time: 710.0973453521729 and batch: 800, loss is 3.9673049354553225 and perplexity is 52.841926359648575
At time: 711.1734058856964 and batch: 850, loss is 3.9497097396850585 and perplexity is 51.92029424649029
At time: 712.2499945163727 and batch: 900, loss is 3.9706843185424803 and perplexity is 53.02080154553721
At time: 713.3261182308197 and batch: 950, loss is 3.944958095550537 and perplexity is 51.674172688978935
At time: 714.4023530483246 and batch: 1000, loss is 3.9446906042099 and perplexity is 51.66035214377054
At time: 715.4788813591003 and batch: 1050, loss is 3.890923933982849 and perplexity is 48.9560978368405
At time: 716.5552959442139 and batch: 1100, loss is 3.8583695936203 and perplexity is 47.388026609686264
At time: 717.6318860054016 and batch: 1150, loss is 3.9045259046554563 and perplexity is 49.626546619387625
At time: 718.708010673523 and batch: 1200, loss is 3.859643802642822 and perplexity is 47.44844734690112
At time: 719.7835178375244 and batch: 1250, loss is 3.902680025100708 and perplexity is 49.535026485168586
At time: 720.859813451767 and batch: 1300, loss is 3.872306437492371 and perplexity is 48.0530898140948
At time: 721.9366452693939 and batch: 1350, loss is 3.8609211683273315 and perplexity is 47.50909509175297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616669108072917 and perplexity of 101.1565288827436
Finished 23 epochs...
Completing Train Step...
At time: 725.1410887241364 and batch: 50, loss is 4.116360521316528 and perplexity is 61.33560592114212
At time: 726.2454373836517 and batch: 100, loss is 4.122547030448914 and perplexity is 61.716235377134616
At time: 727.3232758045197 and batch: 150, loss is 4.081809315681458 and perplexity is 59.25257954437404
At time: 728.4003791809082 and batch: 200, loss is 4.075701751708984 and perplexity is 58.8917935076853
At time: 729.477706193924 and batch: 250, loss is 4.071739540100098 and perplexity is 58.65891342453311
At time: 730.5563561916351 and batch: 300, loss is 4.070319881439209 and perplexity is 58.575696873576724
At time: 731.6327655315399 and batch: 350, loss is 4.086961522102356 and perplexity is 59.55864885423267
At time: 732.7101559638977 and batch: 400, loss is 4.088070182800293 and perplexity is 59.624715803587655
At time: 733.7874293327332 and batch: 450, loss is 4.034026761054992 and perplexity is 56.487917236156015
At time: 734.8666150569916 and batch: 500, loss is 4.098678488731384 and perplexity is 60.26059989304729
At time: 735.9465503692627 and batch: 550, loss is 4.084832921028137 and perplexity is 59.432007083024864
At time: 737.026839017868 and batch: 600, loss is 4.024446744918823 and perplexity is 55.94934595732455
At time: 738.134290933609 and batch: 650, loss is 4.031067066192627 and perplexity is 56.32097740506982
At time: 739.2147409915924 and batch: 700, loss is 4.0384193658828735 and perplexity is 56.73659209947926
At time: 740.2955865859985 and batch: 750, loss is 4.000046038627625 and perplexity is 54.60066371490541
At time: 741.3758194446564 and batch: 800, loss is 3.9667987775802613 and perplexity is 52.81518677028598
At time: 742.4562182426453 and batch: 850, loss is 3.949359974861145 and perplexity is 51.90213752939122
At time: 743.5360355377197 and batch: 900, loss is 3.970371150970459 and perplexity is 53.004199749558325
At time: 744.616836309433 and batch: 950, loss is 3.9447149229049683 and perplexity is 51.66160847139751
At time: 745.6962857246399 and batch: 1000, loss is 3.94454363822937 and perplexity is 51.65276038734184
At time: 746.7765667438507 and batch: 1050, loss is 3.890919394493103 and perplexity is 48.95587560164077
At time: 747.8568429946899 and batch: 1100, loss is 3.8584946250915526 and perplexity is 47.393951974793865
At time: 748.9369442462921 and batch: 1150, loss is 3.9048088216781616 and perplexity is 49.6405888004967
At time: 750.0172572135925 and batch: 1200, loss is 3.8600396728515625 and perplexity is 47.46723449204693
At time: 751.0975658893585 and batch: 1250, loss is 3.903157548904419 and perplexity is 49.55868628804266
At time: 752.1765739917755 and batch: 1300, loss is 3.8727015686035156 and perplexity is 48.0720808365918
At time: 753.2554540634155 and batch: 1350, loss is 3.861242928504944 and perplexity is 47.52438408619077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616550699869792 and perplexity of 101.14455182902891
Finished 24 epochs...
Completing Train Step...
At time: 756.448977470398 and batch: 50, loss is 4.115690212249756 and perplexity is 61.29450588477965
At time: 757.5298140048981 and batch: 100, loss is 4.121823954582214 and perplexity is 61.671625986680326
At time: 758.6111288070679 and batch: 150, loss is 4.081049499511718 and perplexity is 59.207575575874095
At time: 759.6949050426483 and batch: 200, loss is 4.074875645637512 and perplexity is 58.84316272936499
At time: 760.7753489017487 and batch: 250, loss is 4.070854511260986 and perplexity is 58.60702156076655
At time: 761.8555624485016 and batch: 300, loss is 4.069357008934021 and perplexity is 58.51932309032332
At time: 762.9363913536072 and batch: 350, loss is 4.086000151634217 and perplexity is 59.50141844232375
At time: 764.016842842102 and batch: 400, loss is 4.087174077033996 and perplexity is 59.57130968428175
At time: 765.13911652565 and batch: 450, loss is 4.033154330253601 and perplexity is 56.43865692848209
At time: 766.2198958396912 and batch: 500, loss is 4.09786627292633 and perplexity is 60.2116751528054
At time: 767.3009197711945 and batch: 550, loss is 4.084094085693359 and perplexity is 59.3881128334832
At time: 768.383204460144 and batch: 600, loss is 4.023827152252197 and perplexity is 55.91469088998835
At time: 769.4657595157623 and batch: 650, loss is 4.030461368560791 and perplexity is 56.28687425157515
At time: 770.5490655899048 and batch: 700, loss is 4.037894144058227 and perplexity is 56.7068006273031
At time: 771.6323940753937 and batch: 750, loss is 3.999540376663208 and perplexity is 54.573061215388066
At time: 772.7158131599426 and batch: 800, loss is 3.9663348817825317 and perplexity is 52.790691709104195
At time: 773.7982547283173 and batch: 850, loss is 3.9490144872665405 and perplexity is 51.88420908194777
At time: 774.8810842037201 and batch: 900, loss is 3.9700459146499636 and perplexity is 52.98696366171381
At time: 775.9636061191559 and batch: 950, loss is 3.944452877044678 and perplexity is 51.64807253435722
At time: 777.0458931922913 and batch: 1000, loss is 3.944357461929321 and perplexity is 51.643144762654096
At time: 778.1289336681366 and batch: 1050, loss is 3.890853090286255 and perplexity is 48.952629728747155
At time: 779.2121913433075 and batch: 1100, loss is 3.858533902168274 and perplexity is 47.39581350723924
At time: 780.2947652339935 and batch: 1150, loss is 3.9049746799468994 and perplexity is 49.64882278543264
At time: 781.3772802352905 and batch: 1200, loss is 3.86028883934021 and perplexity is 47.479063209789956
At time: 782.4607946872711 and batch: 1250, loss is 3.9034650897979737 and perplexity is 49.573929954612346
At time: 783.5441102981567 and batch: 1300, loss is 3.8729561138153077 and perplexity is 48.08431891209532
At time: 784.6352214813232 and batch: 1350, loss is 3.8614290857315066 and perplexity is 47.533231917244656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616471354166666 and perplexity of 101.13652676182826
Finished 25 epochs...
Completing Train Step...
At time: 787.9503357410431 and batch: 50, loss is 4.115023155212402 and perplexity is 61.253632587204045
At time: 789.0325558185577 and batch: 100, loss is 4.121122713088989 and perplexity is 61.62839444323142
At time: 790.1148507595062 and batch: 150, loss is 4.080326523780823 and perplexity is 59.16478540563871
At time: 791.1976132392883 and batch: 200, loss is 4.0741151380538945 and perplexity is 58.79842907016486
At time: 792.320690870285 and batch: 250, loss is 4.070048427581787 and perplexity is 58.55979843265337
At time: 793.4030816555023 and batch: 300, loss is 4.068484969139099 and perplexity is 58.46831415595952
At time: 794.4858055114746 and batch: 350, loss is 4.085131783485412 and perplexity is 59.44977173316377
At time: 795.5684630870819 and batch: 400, loss is 4.086372575759888 and perplexity is 59.52358233299095
At time: 796.6504557132721 and batch: 450, loss is 4.0323685264587406 and perplexity is 56.39432463821304
At time: 797.7330791950226 and batch: 500, loss is 4.097151775360107 and perplexity is 60.16866942302469
At time: 798.8145360946655 and batch: 550, loss is 4.083448791503907 and perplexity is 59.349802391431396
At time: 799.8984622955322 and batch: 600, loss is 4.023299164772034 and perplexity is 55.88517642556073
At time: 800.9943869113922 and batch: 650, loss is 4.029927587509155 and perplexity is 56.25683740190764
At time: 802.0804996490479 and batch: 700, loss is 4.037430267333985 and perplexity is 56.68050176257304
At time: 803.1611847877502 and batch: 750, loss is 3.9990721797943114 and perplexity is 54.54751625950175
At time: 804.2378754615784 and batch: 800, loss is 3.9658940172195436 and perplexity is 52.767423293360864
At time: 805.3170070648193 and batch: 850, loss is 3.9486715030670165 and perplexity is 51.86641666946047
At time: 806.4000787734985 and batch: 900, loss is 3.969718141555786 and perplexity is 52.96959880670493
At time: 807.4772021770477 and batch: 950, loss is 3.9441823673248293 and perplexity is 51.63410311824184
At time: 808.5544414520264 and batch: 1000, loss is 3.94415150642395 and perplexity is 51.632509667891306
At time: 809.631103515625 and batch: 1050, loss is 3.890751461982727 and perplexity is 48.94765500882505
At time: 810.708339214325 and batch: 1100, loss is 3.85852144241333 and perplexity is 47.39522297069655
At time: 811.7862203121185 and batch: 1150, loss is 3.9050692319869995 and perplexity is 49.653517404855
At time: 812.8641295433044 and batch: 1200, loss is 3.860448966026306 and perplexity is 47.48666648356795
At time: 813.9410572052002 and batch: 1250, loss is 3.903670282363892 and perplexity is 49.58410320020387
At time: 815.0192608833313 and batch: 1300, loss is 3.873126120567322 and perplexity is 48.09249426588937
At time: 816.0959973335266 and batch: 1350, loss is 3.861539726257324 and perplexity is 47.538491309963405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616414794921875 and perplexity of 101.13080671801598
Finished 26 epochs...
Completing Train Step...
At time: 819.2915320396423 and batch: 50, loss is 4.114366917610169 and perplexity is 61.21344883671307
At time: 820.3944492340088 and batch: 100, loss is 4.120442519187927 and perplexity is 61.58648943857882
At time: 821.4704711437225 and batch: 150, loss is 4.079634413719178 and perplexity is 59.1238510295452
At time: 822.5468339920044 and batch: 200, loss is 4.073400835990906 and perplexity is 58.756444227694516
At time: 823.6224875450134 and batch: 250, loss is 4.069296522140503 and perplexity is 58.51578355115951
At time: 824.699028968811 and batch: 300, loss is 4.06767403125763 and perplexity is 58.42091920492269
At time: 825.7752993106842 and batch: 350, loss is 4.084323167800903 and perplexity is 59.401719145956015
At time: 826.8560853004456 and batch: 400, loss is 4.085629301071167 and perplexity is 59.47935639890563
At time: 827.9428596496582 and batch: 450, loss is 4.031637172698975 and perplexity is 56.353095515234216
At time: 829.020557641983 and batch: 500, loss is 4.0964960193634035 and perplexity is 60.129226391152635
At time: 830.0968341827393 and batch: 550, loss is 4.082858819961547 and perplexity is 59.31479802378152
At time: 831.173054933548 and batch: 600, loss is 4.022822937965393 and perplexity is 55.85856874260183
At time: 832.2488644123077 and batch: 650, loss is 4.029437618255615 and perplexity is 56.22928003296238
At time: 833.3255503177643 and batch: 700, loss is 4.037003092765808 and perplexity is 56.656294464447726
At time: 834.4020504951477 and batch: 750, loss is 3.998627562522888 and perplexity is 54.52326888246029
At time: 835.47869348526 and batch: 800, loss is 3.965467939376831 and perplexity is 52.744945052558755
At time: 836.5546982288361 and batch: 850, loss is 3.9483312940597535 and perplexity is 51.848774248560474
At time: 837.6309788227081 and batch: 900, loss is 3.9693916702270506 and perplexity is 52.95230857393613
At time: 838.7070899009705 and batch: 950, loss is 3.943908815383911 and perplexity is 51.61998044084724
At time: 839.7826697826385 and batch: 1000, loss is 3.943934860229492 and perplexity is 51.62132489277467
At time: 840.8605570793152 and batch: 1050, loss is 3.890627188682556 and perplexity is 48.94157250015601
At time: 841.9354557991028 and batch: 1100, loss is 3.858474407196045 and perplexity is 47.39299377851154
At time: 843.0108034610748 and batch: 1150, loss is 3.9051149225234987 and perplexity is 49.655786152534056
At time: 844.0942406654358 and batch: 1200, loss is 3.8605486011505126 and perplexity is 47.491398059192846
At time: 845.1755743026733 and batch: 1250, loss is 3.903806881904602 and perplexity is 49.59087682855428
At time: 846.2571506500244 and batch: 1300, loss is 3.8732396745681763 and perplexity is 48.097955671100664
At time: 847.3378376960754 and batch: 1350, loss is 3.8616024541854856 and perplexity is 47.54147339456022
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616373291015625 and perplexity of 101.12660948159646
Finished 27 epochs...
Completing Train Step...
At time: 850.6778814792633 and batch: 50, loss is 4.113722805976868 and perplexity is 61.17403323758855
At time: 851.7991490364075 and batch: 100, loss is 4.119781346321106 and perplexity is 61.54578358108639
At time: 852.8872406482697 and batch: 150, loss is 4.0789678144454955 and perplexity is 59.08445224645063
At time: 853.9693641662598 and batch: 200, loss is 4.072720789909363 and perplexity is 58.71650072128395
At time: 855.0500555038452 and batch: 250, loss is 4.068584198951721 and perplexity is 58.47411624368281
At time: 856.1311540603638 and batch: 300, loss is 4.066907324790955 and perplexity is 58.37614467503334
At time: 857.2250580787659 and batch: 350, loss is 4.083556900024414 and perplexity is 59.35621895759682
At time: 858.3046894073486 and batch: 400, loss is 4.084926133155823 and perplexity is 59.43754712505325
At time: 859.3805015087128 and batch: 450, loss is 4.030942912101746 and perplexity is 56.313985359377085
At time: 860.4565737247467 and batch: 500, loss is 4.095880160331726 and perplexity is 60.092206664648394
At time: 861.5325009822845 and batch: 550, loss is 4.08230583190918 and perplexity is 59.28200671658193
At time: 862.6089596748352 and batch: 600, loss is 4.022379627227783 and perplexity is 55.83381152726588
At time: 863.6855928897858 and batch: 650, loss is 4.02897864818573 and perplexity is 56.203478397918126
At time: 864.7619595527649 and batch: 700, loss is 4.036599836349487 and perplexity is 56.633452056163385
At time: 865.8379085063934 and batch: 750, loss is 3.998199100494385 and perplexity is 54.499912736042525
At time: 866.9137494564056 and batch: 800, loss is 3.96505313873291 and perplexity is 52.72307095239645
At time: 867.9896583557129 and batch: 850, loss is 3.9479939556121826 and perplexity is 51.831286613338705
At time: 869.0669198036194 and batch: 900, loss is 3.9690679693222046 and perplexity is 52.935170637669444
At time: 870.1454222202301 and batch: 950, loss is 3.9436343908309937 and perplexity is 51.60581659433567
At time: 871.222962141037 and batch: 1000, loss is 3.9437122344970703 and perplexity is 51.60983393665055
At time: 872.3006837368011 and batch: 1050, loss is 3.890487494468689 and perplexity is 48.934736123172456
At time: 873.3778810501099 and batch: 1100, loss is 3.8584023904800415 and perplexity is 47.389580813634765
At time: 874.4927358627319 and batch: 1150, loss is 3.905125131607056 and perplexity is 49.656293095191685
At time: 875.5701768398285 and batch: 1200, loss is 3.8606044387817384 and perplexity is 47.49404994040077
At time: 876.6468200683594 and batch: 1250, loss is 3.903894166946411 and perplexity is 49.595205559225576
At time: 877.7231781482697 and batch: 1300, loss is 3.8733127975463866 and perplexity is 48.10147286545745
At time: 878.8122174739838 and batch: 1350, loss is 3.861632080078125 and perplexity is 47.54288187401056
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6163407389322915 and perplexity of 101.12331765335558
Finished 28 epochs...
Completing Train Step...
At time: 882.1258339881897 and batch: 50, loss is 4.113090572357177 and perplexity is 61.13536918076989
At time: 883.2064201831818 and batch: 100, loss is 4.119136581420898 and perplexity is 61.50611381028974
At time: 884.2872796058655 and batch: 150, loss is 4.0783232402801515 and perplexity is 59.04638020640395
At time: 885.3686463832855 and batch: 200, loss is 4.072067317962646 and perplexity is 58.67814366924688
At time: 886.449809551239 and batch: 250, loss is 4.067902293205261 and perplexity is 58.434255999806304
At time: 887.5314221382141 and batch: 300, loss is 4.066174778938294 and perplexity is 58.333397131536756
At time: 888.6198034286499 and batch: 350, loss is 4.082822656631469 and perplexity is 59.31265304194715
At time: 889.6994166374207 and batch: 400, loss is 4.084252223968506 and perplexity is 59.397505109830526
At time: 890.7755198478699 and batch: 450, loss is 4.030276403427124 and perplexity is 56.276464105142296
At time: 891.8517506122589 and batch: 500, loss is 4.09529314994812 and perplexity is 60.056942266659
At time: 892.9267196655273 and batch: 550, loss is 4.08177864074707 and perplexity is 59.25076200326087
At time: 894.0030603408813 and batch: 600, loss is 4.021958856582642 and perplexity is 55.81032324030621
At time: 895.0791404247284 and batch: 650, loss is 4.028542242050171 and perplexity is 56.178956206312115
At time: 896.1553766727448 and batch: 700, loss is 4.036213312149048 and perplexity is 56.611566086390226
At time: 897.2306549549103 and batch: 750, loss is 3.9977838373184205 and perplexity is 54.47728562761758
At time: 898.3071570396423 and batch: 800, loss is 3.964646873474121 and perplexity is 52.701655750752586
At time: 899.3851556777954 and batch: 850, loss is 3.9476597690582276 and perplexity is 51.813968188231925
At time: 900.4616944789886 and batch: 900, loss is 3.9687471103668215 and perplexity is 52.918188638674536
At time: 901.5861110687256 and batch: 950, loss is 3.9433606624603272 and perplexity is 51.59169255140621
At time: 902.6622838973999 and batch: 1000, loss is 3.9434859132766724 and perplexity is 51.59815485771103
At time: 903.7381300926208 and batch: 1050, loss is 3.8903367948532104 and perplexity is 48.92736223289032
At time: 905.0143918991089 and batch: 1100, loss is 3.858312101364136 and perplexity is 47.38530224343703
At time: 906.0914344787598 and batch: 1150, loss is 3.905108342170715 and perplexity is 49.6554594010185
At time: 907.1679277420044 and batch: 1200, loss is 3.860627155303955 and perplexity is 47.49512885229592
At time: 908.2445800304413 and batch: 1250, loss is 3.9039440250396726 and perplexity is 49.59767834325331
At time: 909.3287460803986 and batch: 1300, loss is 3.8733556127548217 and perplexity is 48.10353238413327
At time: 910.4046812057495 and batch: 1350, loss is 3.861637439727783 and perplexity is 47.54313668788399
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616319173177083 and perplexity of 101.12113687615636
Finished 29 epochs...
Completing Train Step...
At time: 913.6047496795654 and batch: 50, loss is 4.112469534873963 and perplexity is 61.09741361209382
At time: 914.7068617343903 and batch: 100, loss is 4.118506841659546 and perplexity is 61.46739315810388
At time: 915.7830557823181 and batch: 150, loss is 4.077697486877441 and perplexity is 59.0094432909776
At time: 916.8589015007019 and batch: 200, loss is 4.071435070037841 and perplexity is 58.64105626013477
At time: 917.9344029426575 and batch: 250, loss is 4.067244548797607 and perplexity is 58.39583383207519
At time: 919.010409116745 and batch: 300, loss is 4.065469408035279 and perplexity is 58.292264958950454
At time: 920.0863735675812 and batch: 350, loss is 4.082113723754883 and perplexity is 59.2706192535359
At time: 921.1630198955536 and batch: 400, loss is 4.083600749969483 and perplexity is 59.35882178160403
At time: 922.2391729354858 and batch: 450, loss is 4.029631404876709 and perplexity is 56.240177571010946
At time: 923.3193528652191 and batch: 500, loss is 4.0947283744812015 and perplexity is 60.02303315546701
At time: 924.3991794586182 and batch: 550, loss is 4.081270785331726 and perplexity is 59.220678822513925
At time: 925.4759900569916 and batch: 600, loss is 4.021554379463196 and perplexity is 55.78775380624417
At time: 926.5513079166412 and batch: 650, loss is 4.028123064041138 and perplexity is 56.15541215821833
At time: 927.6376576423645 and batch: 700, loss is 4.03583936214447 and perplexity is 56.590400148740954
At time: 928.7211112976074 and batch: 750, loss is 3.99738121509552 and perplexity is 54.45535627669885
At time: 929.7967829704285 and batch: 800, loss is 3.964247007369995 and perplexity is 52.680586357735336
At time: 930.8731634616852 and batch: 850, loss is 3.9473280811309817 and perplexity is 51.79678497041167
At time: 931.9497182369232 and batch: 900, loss is 3.9684296798706056 and perplexity is 52.90139345758847
At time: 933.0263726711273 and batch: 950, loss is 3.943088245391846 and perplexity is 51.577640007926625
At time: 934.1024935245514 and batch: 1000, loss is 3.943257656097412 and perplexity is 51.5863785524924
At time: 935.1783857345581 and batch: 1050, loss is 3.890178017616272 and perplexity is 48.91959429820623
At time: 936.2540502548218 and batch: 1100, loss is 3.8582078552246095 and perplexity is 47.38036276607306
At time: 937.3298816680908 and batch: 1150, loss is 3.9050706100463866 and perplexity is 49.65358583039791
At time: 938.4056203365326 and batch: 1200, loss is 3.860624170303345 and perplexity is 47.49498707951891
At time: 939.4813787937164 and batch: 1250, loss is 3.903964786529541 and perplexity is 49.59870807563907
At time: 940.5584008693695 and batch: 1300, loss is 3.873375277519226 and perplexity is 48.104478338065576
At time: 941.6344239711761 and batch: 1350, loss is 3.8616243267059325 and perplexity is 47.542513257781295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6163033040364585 and perplexity of 101.11953218334773
Finished 30 epochs...
Completing Train Step...
At time: 944.8219969272614 and batch: 50, loss is 4.1118589115142825 and perplexity is 61.060117492226084
At time: 945.911226272583 and batch: 100, loss is 4.117890024185181 and perplexity is 61.42949068655542
At time: 947.0030238628387 and batch: 150, loss is 4.077088146209717 and perplexity is 58.973497390162464
At time: 948.0818796157837 and batch: 200, loss is 4.070820469856262 and perplexity is 58.60502652938293
At time: 949.1585586071014 and batch: 250, loss is 4.0666067409515385 and perplexity is 58.35860038623354
At time: 950.2770414352417 and batch: 300, loss is 4.064786520004272 and perplexity is 58.25247145770902
At time: 951.35404753685 and batch: 350, loss is 4.081425628662109 and perplexity is 59.22984945963805
At time: 952.4300825595856 and batch: 400, loss is 4.082967376708984 and perplexity is 59.32123739484211
At time: 953.5068562030792 and batch: 450, loss is 4.029004325866699 and perplexity is 56.20492159143463
At time: 954.5845110416412 and batch: 500, loss is 4.094181590080261 and perplexity is 59.9902224682439
At time: 955.6620211601257 and batch: 550, loss is 4.080777997970581 and perplexity is 59.19150280984735
At time: 956.7384095191956 and batch: 600, loss is 4.02116238117218 and perplexity is 55.765889387779836
At time: 957.8149569034576 and batch: 650, loss is 4.027716827392578 and perplexity is 56.13260440477103
At time: 958.8929455280304 and batch: 700, loss is 4.035474963188172 and perplexity is 56.5697824227573
At time: 959.9701218605042 and batch: 750, loss is 3.996991152763367 and perplexity is 54.43411943554649
At time: 961.0465385913849 and batch: 800, loss is 3.963852496147156 and perplexity is 52.65980737423206
At time: 962.1253714561462 and batch: 850, loss is 3.946999444961548 and perplexity is 51.77976547017487
At time: 963.2075684070587 and batch: 900, loss is 3.968115015029907 and perplexity is 52.884749867757016
At time: 964.2916586399078 and batch: 950, loss is 3.942817420959473 and perplexity is 51.56367341418111
At time: 965.3750751018524 and batch: 1000, loss is 3.943028254508972 and perplexity is 51.57454591257569
At time: 966.4667770862579 and batch: 1050, loss is 3.8900128602981567 and perplexity is 48.91151553636033
At time: 967.5574147701263 and batch: 1100, loss is 3.858092494010925 and perplexity is 47.374897225181336
At time: 968.6345348358154 and batch: 1150, loss is 3.90501624584198 and perplexity is 49.65088652608173
At time: 969.7116520404816 and batch: 1200, loss is 3.860600972175598 and perplexity is 47.493885297521
At time: 970.7886235713959 and batch: 1250, loss is 3.903962664604187 and perplexity is 49.59860283099455
At time: 971.8652782440186 and batch: 1300, loss is 3.8733760499954224 and perplexity is 48.10451549764438
At time: 972.9418649673462 and batch: 1350, loss is 3.8615964603424073 and perplexity is 47.541188439282976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6162931315104165 and perplexity of 101.11850354750516
Finished 31 epochs...
Completing Train Step...
At time: 976.0996670722961 and batch: 50, loss is 4.111257824897766 and perplexity is 61.02342610125536
At time: 977.2037484645844 and batch: 100, loss is 4.117284922599793 and perplexity is 61.39233084822377
At time: 978.2813591957092 and batch: 150, loss is 4.07649341583252 and perplexity is 58.938434487335165
At time: 979.3588578701019 and batch: 200, loss is 4.070220899581909 and perplexity is 58.569899229243084
At time: 980.4367110729218 and batch: 250, loss is 4.065985836982727 and perplexity is 58.32237654656611
At time: 981.5167734622955 and batch: 300, loss is 4.064122762680054 and perplexity is 58.213818782542354
At time: 982.5942981243134 and batch: 350, loss is 4.080755505561829 and perplexity is 59.190171465344115
At time: 983.6719465255737 and batch: 400, loss is 4.082348909378052 and perplexity is 59.284560490385594
At time: 984.750955581665 and batch: 450, loss is 4.0283920955657955 and perplexity is 56.17052176675843
At time: 985.8285746574402 and batch: 500, loss is 4.093649497032166 and perplexity is 59.958310578715064
At time: 986.905565738678 and batch: 550, loss is 4.0802974510192875 and perplexity is 59.16306534694488
At time: 987.9833948612213 and batch: 600, loss is 4.020780234336853 and perplexity is 55.744582701031845
At time: 989.0618324279785 and batch: 650, loss is 4.027320594787597 and perplexity is 56.110367242538665
At time: 990.1394979953766 and batch: 700, loss is 4.035118317604065 and perplexity is 56.54961065696174
At time: 991.2285907268524 and batch: 750, loss is 3.9966107749938966 and perplexity is 54.41341784407472
At time: 992.3111824989319 and batch: 800, loss is 3.9634628295898438 and perplexity is 52.63929160579784
At time: 993.394305229187 and batch: 850, loss is 3.94667329788208 and perplexity is 51.76288040454833
At time: 994.4779436588287 and batch: 900, loss is 3.967803092002869 and perplexity is 52.86825646896327
At time: 995.5609395503998 and batch: 950, loss is 3.9425482892990114 and perplexity is 51.54979786439429
At time: 996.6436851024628 and batch: 1000, loss is 3.942798194885254 and perplexity is 51.56268205669904
At time: 997.7284815311432 and batch: 1050, loss is 3.8898427295684814 and perplexity is 48.90319489235129
At time: 998.8116447925568 and batch: 1100, loss is 3.857968320846558 and perplexity is 47.36901489950237
At time: 999.8957562446594 and batch: 1150, loss is 3.9049481964111328 and perplexity is 49.64750792646977
At time: 1000.9798154830933 and batch: 1200, loss is 3.8605610036849978 and perplexity is 47.49198707654767
At time: 1002.0630049705505 and batch: 1250, loss is 3.9039409589767455 and perplexity is 49.597526273883595
At time: 1003.146009683609 and batch: 1300, loss is 3.873361749649048 and perplexity is 48.10382759132924
At time: 1004.2292728424072 and batch: 1350, loss is 3.8615564346313476 and perplexity is 47.53928560749242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616285400390625 and perplexity of 101.11772179126304
Finished 32 epochs...
Completing Train Step...
At time: 1007.5480530261993 and batch: 50, loss is 4.110665769577026 and perplexity is 60.98730755028751
At time: 1008.6298944950104 and batch: 100, loss is 4.116690225601197 and perplexity is 61.355831867324405
At time: 1009.7146048545837 and batch: 150, loss is 4.075910897254944 and perplexity is 58.904111752099055
At time: 1010.7964701652527 and batch: 200, loss is 4.069633936882019 and perplexity is 58.535530970488864
At time: 1011.8792097568512 and batch: 250, loss is 4.065379490852356 and perplexity is 58.2870237183415
At time: 1012.9650254249573 and batch: 300, loss is 4.063475542068481 and perplexity is 58.17615378924276
At time: 1014.0476536750793 and batch: 350, loss is 4.080100655555725 and perplexity is 59.151423469646055
At time: 1015.1302065849304 and batch: 400, loss is 4.081743083000183 and perplexity is 59.24865521711918
At time: 1016.2128114700317 and batch: 450, loss is 4.027792859077453 and perplexity is 56.136872423510624
At time: 1017.2951595783234 and batch: 500, loss is 4.093129858970642 and perplexity is 59.927162052114625
At time: 1018.3782849311829 and batch: 550, loss is 4.079826912879944 and perplexity is 59.1352334167645
At time: 1019.4608108997345 and batch: 600, loss is 4.020405950546265 and perplexity is 55.72372231141012
At time: 1020.5431609153748 and batch: 650, loss is 4.026932611465454 and perplexity is 56.08860157847956
At time: 1021.6249761581421 and batch: 700, loss is 4.034767823219299 and perplexity is 56.52979380901565
At time: 1022.7054986953735 and batch: 750, loss is 3.996237416267395 and perplexity is 54.3931059117384
At time: 1023.7822260856628 and batch: 800, loss is 3.963077621459961 and perplexity is 52.61901842766722
At time: 1024.8653011322021 and batch: 850, loss is 3.9463496589660645 and perplexity is 51.74613063262958
At time: 1025.949108839035 and batch: 900, loss is 3.9674937772750853 and perplexity is 52.85190606744554
At time: 1027.0268695354462 and batch: 950, loss is 3.9422806978225706 and perplexity is 51.53600542332567
At time: 1028.1040036678314 and batch: 1000, loss is 3.9425678491592406 and perplexity is 51.5508061810966
At time: 1029.1811583042145 and batch: 1050, loss is 3.889668526649475 and perplexity is 48.894676555033456
At time: 1030.259088754654 and batch: 1100, loss is 3.857836961746216 and perplexity is 47.362792956984414
At time: 1031.391221523285 and batch: 1150, loss is 3.9048687744140627 and perplexity is 49.64356497882115
At time: 1032.4709339141846 and batch: 1200, loss is 3.8605072116851806 and perplexity is 47.48943245629722
At time: 1033.5480880737305 and batch: 1250, loss is 3.9039037466049193 and perplexity is 49.59568066663416
At time: 1034.6255304813385 and batch: 1300, loss is 3.873334274291992 and perplexity is 48.10250593964693
At time: 1035.7048172950745 and batch: 1350, loss is 3.861506028175354 and perplexity is 47.53688938097763
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616282145182292 and perplexity of 101.11739263254817
Finished 33 epochs...
Completing Train Step...
At time: 1038.9206864833832 and batch: 50, loss is 4.110081882476806 and perplexity is 60.95170824213156
At time: 1039.9981079101562 and batch: 100, loss is 4.116105051040649 and perplexity is 61.31993849834188
At time: 1041.0751135349274 and batch: 150, loss is 4.075340056419373 and perplexity is 58.870496475127155
At time: 1042.15301156044 and batch: 200, loss is 4.06905812740326 and perplexity is 58.50183535896911
At time: 1043.2294266223907 and batch: 250, loss is 4.0647859954833985 and perplexity is 58.2524409030798
At time: 1044.3069677352905 and batch: 300, loss is 4.062842712402344 and perplexity is 58.13934983980694
At time: 1045.3839211463928 and batch: 350, loss is 4.079459214210511 and perplexity is 59.11349346724073
At time: 1046.4669783115387 and batch: 400, loss is 4.081148238182068 and perplexity is 59.21342194178751
At time: 1047.5478687286377 and batch: 450, loss is 4.027205028533936 and perplexity is 56.10388315228308
At time: 1048.6238543987274 and batch: 500, loss is 4.092621083259583 and perplexity is 59.89668032246912
At time: 1049.7007675170898 and batch: 550, loss is 4.079365210533142 and perplexity is 59.10793684264838
At time: 1050.7777724266052 and batch: 600, loss is 4.020038352012635 and perplexity is 55.7032421172753
At time: 1051.8544518947601 and batch: 650, loss is 4.026550989151001 and perplexity is 56.06720100025961
At time: 1052.9313209056854 and batch: 700, loss is 4.034422836303711 and perplexity is 56.51029513339799
At time: 1054.0086817741394 and batch: 750, loss is 3.9958690881729124 and perplexity is 54.37307509186826
At time: 1055.0848121643066 and batch: 800, loss is 3.9626964855194093 and perplexity is 52.59896724994285
At time: 1056.1614198684692 and batch: 850, loss is 3.946028261184692 and perplexity is 51.72950221336132
At time: 1057.2379732131958 and batch: 900, loss is 3.9671867990493777 and perplexity is 52.835684173107246
At time: 1058.3140864372253 and batch: 950, loss is 3.942014694213867 and perplexity is 51.522298483033524
At time: 1059.4360330104828 and batch: 1000, loss is 3.9423370885849 and perplexity is 51.538911659900585
At time: 1060.5122702121735 and batch: 1050, loss is 3.8894907951354982 and perplexity is 48.8859872023527
At time: 1061.5893876552582 and batch: 1100, loss is 3.8576995134353638 and perplexity is 47.35628346846459
At time: 1062.665391921997 and batch: 1150, loss is 3.9047798252105714 and perplexity is 49.63914941964097
At time: 1063.7422664165497 and batch: 1200, loss is 3.8604420375823976 and perplexity is 47.48633747600258
At time: 1064.8285014629364 and batch: 1250, loss is 3.903853106498718 and perplexity is 49.593169199689086
At time: 1065.910655260086 and batch: 1300, loss is 3.8732947874069215 and perplexity is 48.100606559023845
At time: 1066.9957416057587 and batch: 1350, loss is 3.8614468574523926 and perplexity is 47.53407667208145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.61628173828125 and perplexity of 101.11735148778415
Finished 34 epochs...
Completing Train Step...
At time: 1070.3034858703613 and batch: 50, loss is 4.109506072998047 and perplexity is 60.91662177330927
At time: 1071.4285070896149 and batch: 100, loss is 4.115529041290284 and perplexity is 61.28462778650847
At time: 1072.5108542442322 and batch: 150, loss is 4.0747792482376095 and perplexity is 58.83749067486589
At time: 1073.595819234848 and batch: 200, loss is 4.068492045402527 and perplexity is 58.46872789461652
At time: 1074.6772863864899 and batch: 250, loss is 4.064203562736512 and perplexity is 58.21852265242054
At time: 1075.7595088481903 and batch: 300, loss is 4.062222418785095 and perplexity is 58.10329755484738
At time: 1076.8408997058868 and batch: 350, loss is 4.078830132484436 and perplexity is 59.07631794318347
At time: 1077.9231190681458 and batch: 400, loss is 4.080563125610351 and perplexity is 59.1787855582749
At time: 1079.0042052268982 and batch: 450, loss is 4.026627345085144 and perplexity is 56.0714822272132
At time: 1080.086245059967 and batch: 500, loss is 4.092121834754944 and perplexity is 59.86678445773915
At time: 1081.16787981987 and batch: 550, loss is 4.078910684585571 and perplexity is 59.08107685638877
At time: 1082.252590894699 and batch: 600, loss is 4.019676513671875 and perplexity is 55.683090194661666
At time: 1083.329377412796 and batch: 650, loss is 4.026175036430359 and perplexity is 56.04612634528989
At time: 1084.4070520401 and batch: 700, loss is 4.0340822982788085 and perplexity is 56.49105450537528
At time: 1085.4880003929138 and batch: 750, loss is 3.9955048418045043 and perplexity is 54.35327350327416
At time: 1086.616821527481 and batch: 800, loss is 3.962319350242615 and perplexity is 52.57913406400205
At time: 1087.6930165290833 and batch: 850, loss is 3.94570924282074 and perplexity is 51.71300218424323
At time: 1088.769231557846 and batch: 900, loss is 3.966881742477417 and perplexity is 52.81956875859774
At time: 1089.845713376999 and batch: 950, loss is 3.9417499494552612 and perplexity is 51.508660029992946
At time: 1090.9235756397247 and batch: 1000, loss is 3.9421062326431273 and perplexity is 51.527014969175106
At time: 1092.0052444934845 and batch: 1050, loss is 3.8893101835250854 and perplexity is 48.87715862277345
At time: 1093.081771850586 and batch: 1100, loss is 3.857556982040405 and perplexity is 47.34953419232507
At time: 1094.15784573555 and batch: 1150, loss is 3.904682683944702 and perplexity is 49.63432764403015
At time: 1095.2349166870117 and batch: 1200, loss is 3.860366954803467 and perplexity is 47.4827722036706
At time: 1096.3130168914795 and batch: 1250, loss is 3.9037911605834963 and perplexity is 49.59009720058415
At time: 1097.3897297382355 and batch: 1300, loss is 3.8732448863983153 and perplexity is 48.0982063501289
At time: 1098.4662652015686 and batch: 1350, loss is 3.8613800573349 and perplexity is 47.53090149622709
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616282552083334 and perplexity of 101.11743377732894
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 1101.6556713581085 and batch: 50, loss is 4.109581203460693 and perplexity is 60.92119863921479
At time: 1102.759160041809 and batch: 100, loss is 4.1167884349823 and perplexity is 61.36185788149987
At time: 1103.83545255661 and batch: 150, loss is 4.077034358978271 and perplexity is 58.97032545431477
At time: 1104.912572145462 and batch: 200, loss is 4.0719025468826295 and perplexity is 58.66847600463878
At time: 1105.9896433353424 and batch: 250, loss is 4.068126573562622 and perplexity is 58.447363125404515
At time: 1107.0659801959991 and batch: 300, loss is 4.065038685798645 and perplexity is 58.26716259067108
At time: 1108.1424760818481 and batch: 350, loss is 4.0803115272521975 and perplexity is 59.1638981458937
At time: 1109.2195315361023 and batch: 400, loss is 4.081481070518493 and perplexity is 59.233133363477464
At time: 1110.2961313724518 and batch: 450, loss is 4.028290200233459 and perplexity is 56.16479854436528
At time: 1111.3719320297241 and batch: 500, loss is 4.093897376060486 and perplexity is 59.973174828672846
At time: 1112.448460817337 and batch: 550, loss is 4.080211186408997 and perplexity is 59.157961888296235
At time: 1113.5251986980438 and batch: 600, loss is 4.022254528999329 and perplexity is 55.82682725322522
At time: 1114.6478621959686 and batch: 650, loss is 4.028413219451904 and perplexity is 56.17170831899515
At time: 1115.7295281887054 and batch: 700, loss is 4.036429524421692 and perplexity is 56.62380752507865
At time: 1116.8061244487762 and batch: 750, loss is 3.9972021436691283 and perplexity is 54.44560575142201
At time: 1117.8817291259766 and batch: 800, loss is 3.9628998231887818 and perplexity is 52.609663688812475
At time: 1118.9576857089996 and batch: 850, loss is 3.9448765563964843 and perplexity is 51.669959392428154
At time: 1120.0334708690643 and batch: 900, loss is 3.964374690055847 and perplexity is 52.68731318593434
At time: 1121.1101443767548 and batch: 950, loss is 3.9385030460357666 and perplexity is 51.34168760396905
At time: 1122.1862318515778 and batch: 1000, loss is 3.938980207443237 and perplexity is 51.366191721632774
At time: 1123.2630376815796 and batch: 1050, loss is 3.885689477920532 and perplexity is 48.70050881207581
At time: 1124.3396997451782 and batch: 1100, loss is 3.853919072151184 and perplexity is 47.17759379509963
At time: 1125.4169754981995 and batch: 1150, loss is 3.90098925113678 and perplexity is 49.45134471549889
At time: 1126.4934210777283 and batch: 1200, loss is 3.856775441169739 and perplexity is 47.31254305307321
At time: 1127.5707731246948 and batch: 1250, loss is 3.9005350732803343 and perplexity is 49.428890109336095
At time: 1128.6463644504547 and batch: 1300, loss is 3.8698917055130004 and perplexity is 47.937194465829805
At time: 1129.7234523296356 and batch: 1350, loss is 3.85843590259552 and perplexity is 47.39116896535049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.61666259765625 and perplexity of 101.15587031373576
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 1132.9299337863922 and batch: 50, loss is 4.109048109054566 and perplexity is 60.88873054405454
At time: 1134.0057880878448 and batch: 100, loss is 4.116485185623169 and perplexity is 61.34325275856064
At time: 1135.0818617343903 and batch: 150, loss is 4.076973004341125 and perplexity is 58.966707462385564
At time: 1136.1572654247284 and batch: 200, loss is 4.071974329948425 and perplexity is 58.672687558869264
At time: 1137.2338774204254 and batch: 250, loss is 4.068319973945617 and perplexity is 58.45866796096257
At time: 1138.3098390102386 and batch: 300, loss is 4.064994506835937 and perplexity is 58.26458846472943
At time: 1139.3865172863007 and batch: 350, loss is 4.080168285369873 and perplexity is 59.15542400469809
At time: 1140.4625918865204 and batch: 400, loss is 4.081269178390503 and perplexity is 59.22058365844035
At time: 1141.568327665329 and batch: 450, loss is 4.028164229393005 and perplexity is 56.15772386309985
At time: 1142.6443688869476 and batch: 500, loss is 4.093557233810425 and perplexity is 59.95277888700071
At time: 1143.7225940227509 and batch: 550, loss is 4.079901909828186 and perplexity is 59.13966854511279
At time: 1144.7987747192383 and batch: 600, loss is 4.022044811248779 and perplexity is 55.81512060418231
At time: 1145.8753628730774 and batch: 650, loss is 4.027964391708374 and perplexity is 56.14650255484636
At time: 1146.9524228572845 and batch: 700, loss is 4.036209220886231 and perplexity is 56.611334474068656
At time: 1148.0287482738495 and batch: 750, loss is 3.997077031135559 and perplexity is 54.43879434984947
At time: 1149.1050827503204 and batch: 800, loss is 3.962802042961121 and perplexity is 52.6045197554114
At time: 1150.1816842556 and batch: 850, loss is 3.944806818962097 and perplexity is 51.66635618766582
At time: 1151.2580997943878 and batch: 900, loss is 3.9640639495849608 and perplexity is 52.670943648895765
At time: 1152.3345329761505 and batch: 950, loss is 3.937965779304504 and perplexity is 51.314110831996985
At time: 1153.42196059227 and batch: 1000, loss is 3.9384161472320556 and perplexity is 51.337226266581006
At time: 1154.5054404735565 and batch: 1050, loss is 3.885031280517578 and perplexity is 48.668464810449336
At time: 1155.5913288593292 and batch: 1100, loss is 3.8531923294067383 and perplexity is 47.14332027663255
At time: 1156.6812372207642 and batch: 1150, loss is 3.9001367568969725 and perplexity is 49.40920569316714
At time: 1157.75994181633 and batch: 1200, loss is 3.8558962965011596 and perplexity is 47.27096676155654
At time: 1158.8408091068268 and batch: 1250, loss is 3.8997255420684813 and perplexity is 49.388892072039496
At time: 1159.9200949668884 and batch: 1300, loss is 3.869099726676941 and perplexity is 47.89924425221944
At time: 1161.0001487731934 and batch: 1350, loss is 3.8577859163284303 and perplexity is 47.36037536513445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6167203776041665 and perplexity of 101.16171526351279
Annealing...
Finished 37 epochs...
Completing Train Step...
At time: 1164.1980557441711 and batch: 50, loss is 4.1089607620239255 and perplexity is 60.88341232651069
At time: 1165.2739129066467 and batch: 100, loss is 4.1164166498184205 and perplexity is 61.339048693433064
At time: 1166.3510155677795 and batch: 150, loss is 4.076947050094605 and perplexity is 58.96517704578405
At time: 1167.4277465343475 and batch: 200, loss is 4.071966123580933 and perplexity is 58.67220607120904
At time: 1168.5318229198456 and batch: 250, loss is 4.068328533172608 and perplexity is 58.459168324112554
At time: 1169.6084258556366 and batch: 300, loss is 4.064952125549317 and perplexity is 58.26211918883179
At time: 1170.6850481033325 and batch: 350, loss is 4.080113091468811 and perplexity is 59.15215907618119
At time: 1171.7626626491547 and batch: 400, loss is 4.081207184791565 and perplexity is 59.21691247512427
At time: 1172.8397426605225 and batch: 450, loss is 4.0281220722198485 and perplexity is 56.15535646211268
At time: 1173.9174273014069 and batch: 500, loss is 4.093466076850891 and perplexity is 59.947314023045756
At time: 1174.9943392276764 and batch: 550, loss is 4.079817523956299 and perplexity is 59.13467820317967
At time: 1176.072680234909 and batch: 600, loss is 4.021963305473328 and perplexity is 55.81057153488578
At time: 1177.149052143097 and batch: 650, loss is 4.027822623252868 and perplexity is 56.13854331609494
At time: 1178.2261033058167 and batch: 700, loss is 4.03614333152771 and perplexity is 56.60760451243892
At time: 1179.3131923675537 and batch: 750, loss is 3.9970300912857057 and perplexity is 54.43623906098941
At time: 1180.3918161392212 and batch: 800, loss is 3.962771234512329 and perplexity is 52.602899116723115
At time: 1181.4687185287476 and batch: 850, loss is 3.9447868728637694 and perplexity is 51.66532565572265
At time: 1182.545786857605 and batch: 900, loss is 3.964003129005432 and perplexity is 52.66774026899541
At time: 1183.6226177215576 and batch: 950, loss is 3.9378514862060547 and perplexity is 51.30824631841892
At time: 1184.6991755962372 and batch: 1000, loss is 3.9382945489883423 and perplexity is 51.33098412955402
At time: 1185.785756111145 and batch: 1050, loss is 3.8848984241485596 and perplexity is 48.66199932442892
At time: 1186.8731019496918 and batch: 1100, loss is 3.8530400943756105 and perplexity is 47.13614395806017
At time: 1187.9611036777496 and batch: 1150, loss is 3.8999535179138185 and perplexity is 49.400152830001524
At time: 1189.041867017746 and batch: 1200, loss is 3.855704355239868 and perplexity is 47.26189438328356
At time: 1190.1176788806915 and batch: 1250, loss is 3.8995470333099367 and perplexity is 49.38007650908083
At time: 1191.1931624412537 and batch: 1300, loss is 3.8689262199401857 and perplexity is 47.89093413160799
At time: 1192.2724080085754 and batch: 1350, loss is 3.857645173072815 and perplexity is 47.353710180769276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.616735432942709 and perplexity of 101.16323829884846
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 1195.4860351085663 and batch: 50, loss is 4.108943285942078 and perplexity is 60.88234833231097
At time: 1196.6081676483154 and batch: 100, loss is 4.116402602195739 and perplexity is 61.33818703167357
At time: 1197.6854021549225 and batch: 150, loss is 4.076942396163941 and perplexity is 58.96490262657706
At time: 1198.7639031410217 and batch: 200, loss is 4.071964869499206 and perplexity is 58.672132491513686
At time: 1199.8416574001312 and batch: 250, loss is 4.068330473899842 and perplexity is 58.45928177752269
At time: 1200.9194920063019 and batch: 300, loss is 4.064943151473999 and perplexity is 58.261596342532066
At time: 1201.9978291988373 and batch: 350, loss is 4.080100860595703 and perplexity is 59.15143559805386
At time: 1203.075602531433 and batch: 400, loss is 4.081194186210633 and perplexity is 59.2161427442976
At time: 1204.1544466018677 and batch: 450, loss is 4.028113307952881 and perplexity is 56.15486430373371
At time: 1205.2324554920197 and batch: 500, loss is 4.093446626663208 and perplexity is 59.946148047876136
At time: 1206.3105795383453 and batch: 550, loss is 4.079799656867981 and perplexity is 59.13362164810035
At time: 1207.3906729221344 and batch: 600, loss is 4.021946010589599 and perplexity is 55.80960630588704
At time: 1208.4677021503448 and batch: 650, loss is 4.027791485786438 and perplexity is 56.136795331301045
At time: 1209.5486557483673 and batch: 700, loss is 4.0361294841766355 and perplexity is 56.60682065249294
At time: 1210.6264612674713 and batch: 750, loss is 3.997019805908203 and perplexity is 54.43567916660021
At time: 1211.7037885189056 and batch: 800, loss is 3.9627648258209227 and perplexity is 52.602562002055826
At time: 1212.786406993866 and batch: 850, loss is 3.9447829723358154 and perplexity is 51.6651241340687
At time: 1213.868043422699 and batch: 900, loss is 3.9639905166625975 and perplexity is 52.66707600958776
At time: 1214.947313785553 and batch: 950, loss is 3.937827115058899 and perplexity is 51.30699589283479
At time: 1216.0269582271576 and batch: 1000, loss is 3.9382682418823243 and perplexity is 51.329633777674516
At time: 1217.106248140335 and batch: 1050, loss is 3.884869866371155 and perplexity is 48.66060966572702
At time: 1218.1854419708252 and batch: 1100, loss is 3.8530072832107543 and perplexity is 47.13459739164254
At time: 1219.263372182846 and batch: 1150, loss is 3.899913640022278 and perplexity is 49.39818289534357
At time: 1220.3417479991913 and batch: 1200, loss is 3.855662474632263 and perplexity is 47.259915067877984
At time: 1221.420104265213 and batch: 1250, loss is 3.8995080471038817 and perplexity is 49.37815140476954
At time: 1222.4977753162384 and batch: 1300, loss is 3.868888659477234 and perplexity is 47.88913535973237
At time: 1223.5758357048035 and batch: 1350, loss is 3.857614860534668 and perplexity is 47.35227479137827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.61673828125 and perplexity of 101.16352644324809
Annealing...
Model not improving. Stopping early with 101.11735148778415loss at 38 epochs.
Finished Training.
Improved accuracyfrom -10000000 to -101.11735148778415
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
SETTINGS FOR THIS RUN
{'dropout': 0.22207062611395245, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 6.608335587856741, 'wordvec_dim': 200, 'lr': 25.10613924621522, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7584478855133057 and batch: 50, loss is 7.014612531661987 and perplexity is 1112.775397435474
At time: 2.837916851043701 and batch: 100, loss is 6.1559929847717285 and perplexity is 471.53483697911815
At time: 3.9199466705322266 and batch: 150, loss is 5.996438255310059 and perplexity is 401.99443904826046
At time: 5.002898454666138 and batch: 200, loss is 5.9435183048248295 and perplexity is 381.2740107003999
At time: 6.085317373275757 and batch: 250, loss is 5.955795497894287 and perplexity is 385.98383791213837
At time: 7.166863441467285 and batch: 300, loss is 5.929209661483765 and perplexity is 375.8573418730962
At time: 8.249576807022095 and batch: 350, loss is 5.911007995605469 and perplexity is 369.0779969695639
At time: 9.338582277297974 and batch: 400, loss is 5.94413872718811 and perplexity is 381.51063501909556
At time: 10.426422119140625 and batch: 450, loss is 5.908745546340942 and perplexity is 368.2439206102705
At time: 11.509141683578491 and batch: 500, loss is 5.919717540740967 and perplexity is 372.3065375941322
At time: 12.605724096298218 and batch: 550, loss is 5.884199390411377 and perplexity is 359.31498179002136
At time: 13.69443941116333 and batch: 600, loss is 5.840202560424805 and perplexity is 343.8489838074849
At time: 14.786401987075806 and batch: 650, loss is 5.858053827285767 and perplexity is 350.0422380292471
At time: 15.876310110092163 and batch: 700, loss is 5.875024242401123 and perplexity is 356.0332916680304
At time: 16.964497327804565 and batch: 750, loss is 5.860858297348022 and perplexity is 351.02529884431885
At time: 18.054341077804565 and batch: 800, loss is 5.820668745040893 and perplexity is 337.19747738696464
At time: 19.144999504089355 and batch: 850, loss is 5.822331562042236 and perplexity is 337.75864151249806
At time: 20.235334634780884 and batch: 900, loss is 5.8658020877838135 and perplexity is 352.7649911532391
At time: 21.32451367378235 and batch: 950, loss is 5.823204736709595 and perplexity is 338.05369259876903
At time: 22.41379451751709 and batch: 1000, loss is 5.843735036849975 and perplexity is 345.065770105766
At time: 23.50303864479065 and batch: 1050, loss is 5.829012565612793 and perplexity is 340.02276308284206
At time: 24.592607259750366 and batch: 1100, loss is 5.817827024459839 and perplexity is 336.24061658502893
At time: 25.681933164596558 and batch: 1150, loss is 5.811589403152466 and perplexity is 334.14980258269674
At time: 26.771420001983643 and batch: 1200, loss is 5.80930835723877 and perplexity is 333.38846019953536
At time: 27.86171865463257 and batch: 1250, loss is 5.806004600524902 and perplexity is 332.2888432694085
At time: 28.95056653022766 and batch: 1300, loss is 5.7884250831604005 and perplexity is 326.4984113998029
At time: 30.040393352508545 and batch: 1350, loss is 5.76372127532959 and perplexity is 318.5314694556534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.368506266276042 and perplexity of 214.54215937887122
Finished 1 epochs...
Completing Train Step...
At time: 33.34508991241455 and batch: 50, loss is 5.7056951999664305 and perplexity is 300.5743667208401
At time: 34.430766344070435 and batch: 100, loss is 5.755310668945312 and perplexity is 315.8636613134851
At time: 35.51099109649658 and batch: 150, loss is 5.718147325515747 and perplexity is 304.34055634126526
At time: 36.587706327438354 and batch: 200, loss is 5.6983457374572755 and perplexity is 298.3734045329528
At time: 37.666836977005005 and batch: 250, loss is 5.7331279945373534 and perplexity is 308.93410277824614
At time: 38.74653673171997 and batch: 300, loss is 5.746139154434204 and perplexity is 312.9799573405718
At time: 39.82268476486206 and batch: 350, loss is 5.738108539581299 and perplexity is 310.47660104521594
At time: 40.898695945739746 and batch: 400, loss is 5.771152467727661 and perplexity is 320.907354987729
At time: 41.97505021095276 and batch: 450, loss is 5.717708654403687 and perplexity is 304.2070802091721
At time: 43.05144286155701 and batch: 500, loss is 5.782281847000122 and perplexity is 324.49880287497274
At time: 44.127281665802 and batch: 550, loss is 5.747289686203003 and perplexity is 313.3402579533952
At time: 45.20376467704773 and batch: 600, loss is 5.715828609466553 and perplexity is 303.6356945118784
At time: 46.28020977973938 and batch: 650, loss is 5.741847791671753 and perplexity is 311.63972457552427
At time: 47.357216596603394 and batch: 700, loss is 5.754026050567627 and perplexity is 315.4581575638684
At time: 48.43323516845703 and batch: 750, loss is 5.742504224777222 and perplexity is 311.8443623658767
At time: 49.51554012298584 and batch: 800, loss is 5.678674249649048 and perplexity is 292.56130944529616
At time: 50.59172344207764 and batch: 850, loss is 5.682103252410888 and perplexity is 293.5662249277195
At time: 51.668174505233765 and batch: 900, loss is 5.693504314422608 and perplexity is 296.93234386626375
At time: 52.74610376358032 and batch: 950, loss is 5.6796908283233645 and perplexity is 292.85887225578614
At time: 53.88445448875427 and batch: 1000, loss is 5.719211273193359 and perplexity is 304.6645310849146
At time: 54.961164712905884 and batch: 1050, loss is 5.696523628234863 and perplexity is 297.8302306122178
At time: 56.037986040115356 and batch: 1100, loss is 5.6871859741210935 and perplexity is 295.062138789013
At time: 57.12252497673035 and batch: 1150, loss is 5.7150672245025635 and perplexity is 303.40459884709276
At time: 58.20524263381958 and batch: 1200, loss is 5.704165067672729 and perplexity is 300.1147998643713
At time: 59.286463499069214 and batch: 1250, loss is 5.688270826339721 and perplexity is 295.38241129767124
At time: 60.36753296852112 and batch: 1300, loss is 5.6912775802612305 and perplexity is 296.27189007296715
At time: 61.45116901397705 and batch: 1350, loss is 5.662456884384155 and perplexity is 287.85500093700466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.505626220703125 and perplexity of 246.07250313586772
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 64.68350338935852 and batch: 50, loss is 5.640352220535278 and perplexity is 281.561872885727
At time: 65.79173874855042 and batch: 100, loss is 5.619090518951416 and perplexity is 275.6385811363902
At time: 66.872230052948 and batch: 150, loss is 5.566109790802002 and perplexity is 261.41515892407125
At time: 67.95411419868469 and batch: 200, loss is 5.559651727676392 and perplexity is 259.7323629756141
At time: 69.03511333465576 and batch: 250, loss is 5.5654809856414795 and perplexity is 261.2508313935152
At time: 70.11641907691956 and batch: 300, loss is 5.560585432052612 and perplexity is 259.9749894726546
At time: 71.19868159294128 and batch: 350, loss is 5.5450113487243655 and perplexity is 255.95748301771246
At time: 72.28110265731812 and batch: 400, loss is 5.583977317810058 and perplexity is 266.12797917864617
At time: 73.36139512062073 and batch: 450, loss is 5.5445332431793215 and perplexity is 255.83513757513396
At time: 74.4457471370697 and batch: 500, loss is 5.559331436157226 and perplexity is 259.64918622361535
At time: 75.52848601341248 and batch: 550, loss is 5.53139874458313 and perplexity is 252.4968427263376
At time: 76.60929727554321 and batch: 600, loss is 5.490358057022095 and perplexity is 242.3439642831485
At time: 77.69188404083252 and batch: 650, loss is 5.517218570709229 and perplexity is 248.94165972246756
At time: 78.77313423156738 and batch: 700, loss is 5.5001797866821285 and perplexity is 244.73592856972218
At time: 79.85453486442566 and batch: 750, loss is 5.474681692123413 and perplexity is 238.57451469602293
At time: 80.9352080821991 and batch: 800, loss is 5.426218814849854 and perplexity is 227.28819979754763
At time: 82.04272222518921 and batch: 850, loss is 5.4257426357269285 and perplexity is 227.17999566623553
At time: 83.12392258644104 and batch: 900, loss is 5.447117280960083 and perplexity is 232.0881557006801
At time: 84.20526576042175 and batch: 950, loss is 5.4138618755340575 and perplexity is 224.4968948164425
At time: 85.28631782531738 and batch: 1000, loss is 5.417955379486084 and perplexity is 225.4177572336735
At time: 86.36784195899963 and batch: 1050, loss is 5.392462310791015 and perplexity is 219.7437974736399
At time: 87.44887900352478 and batch: 1100, loss is 5.353919534683228 and perplexity is 211.43540427197397
At time: 88.5302300453186 and batch: 1150, loss is 5.36128646850586 and perplexity is 212.99878649909735
At time: 89.61122441291809 and batch: 1200, loss is 5.354860277175903 and perplexity is 211.63440413036383
At time: 90.69310903549194 and batch: 1250, loss is 5.366758594512939 and perplexity is 214.1675375582709
At time: 91.7732949256897 and batch: 1300, loss is 5.303614959716797 and perplexity is 201.06233004546965
At time: 92.8528618812561 and batch: 1350, loss is 5.288030128479004 and perplexity is 197.95309891702948
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23719970703125 and perplexity of 188.1425098960494
Finished 3 epochs...
Completing Train Step...
At time: 96.11899757385254 and batch: 50, loss is 5.456982250213623 and perplexity is 234.38902858129774
At time: 97.19993901252747 and batch: 100, loss is 5.467674751281738 and perplexity is 236.90868020273768
At time: 98.28564381599426 and batch: 150, loss is 5.431552753448487 and perplexity is 228.50378013286843
At time: 99.36985754966736 and batch: 200, loss is 5.428273468017578 and perplexity is 227.75567830588818
At time: 100.44978022575378 and batch: 250, loss is 5.449193410873413 and perplexity is 232.57050139616808
At time: 101.52907466888428 and batch: 300, loss is 5.4476635456085205 and perplexity is 232.21497188990733
At time: 102.60973167419434 and batch: 350, loss is 5.432552375793457 and perplexity is 228.73231182106056
At time: 103.6905906200409 and batch: 400, loss is 5.470495777130127 and perplexity is 237.57794928213633
At time: 104.77128195762634 and batch: 450, loss is 5.43259220123291 and perplexity is 228.74142136729054
At time: 105.85238099098206 and batch: 500, loss is 5.45332013130188 and perplexity is 233.53223787928474
At time: 106.9332902431488 and batch: 550, loss is 5.434855394363403 and perplexity is 229.25969363468815
At time: 108.01586055755615 and batch: 600, loss is 5.390119667053223 and perplexity is 219.2296185467414
At time: 109.1241226196289 and batch: 650, loss is 5.42096399307251 and perplexity is 226.09697339785666
At time: 110.205561876297 and batch: 700, loss is 5.416141119003296 and perplexity is 225.00916146625855
At time: 111.28739905357361 and batch: 750, loss is 5.39511703491211 and perplexity is 220.32793164773497
At time: 112.36843800544739 and batch: 800, loss is 5.355844783782959 and perplexity is 211.84286219684495
At time: 113.45018458366394 and batch: 850, loss is 5.355893840789795 and perplexity is 211.8532548284976
At time: 114.53208112716675 and batch: 900, loss is 5.377409324645996 and perplexity is 216.46076881944683
At time: 115.61300730705261 and batch: 950, loss is 5.348659267425537 and perplexity is 210.32611766763455
At time: 116.69442176818848 and batch: 1000, loss is 5.353894538879395 and perplexity is 211.4301193401363
At time: 117.77705383300781 and batch: 1050, loss is 5.326596336364746 and perplexity is 205.73652315954976
At time: 118.85861325263977 and batch: 1100, loss is 5.304916286468506 and perplexity is 201.32414815282434
At time: 119.93703961372375 and batch: 1150, loss is 5.319184112548828 and perplexity is 204.21719575627907
At time: 121.01832914352417 and batch: 1200, loss is 5.3081128025054936 and perplexity is 201.96871365417653
At time: 122.09954452514648 and batch: 1250, loss is 5.323110570907593 and perplexity is 205.02062234988483
At time: 123.1807873249054 and batch: 1300, loss is 5.272877960205078 and perplexity is 194.9762897616519
At time: 124.26164102554321 and batch: 1350, loss is 5.256717929840088 and perplexity is 191.85078910889905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.216883544921875 and perplexity of 184.35874212883664
Finished 4 epochs...
Completing Train Step...
At time: 127.50997066497803 and batch: 50, loss is 5.393039493560791 and perplexity is 219.8706664170688
At time: 128.59021997451782 and batch: 100, loss is 5.406966753005982 and perplexity is 222.95428557103835
At time: 129.67147397994995 and batch: 150, loss is 5.3734534740447994 and perplexity is 215.60617379653974
At time: 130.75334525108337 and batch: 200, loss is 5.370843172073364 and perplexity is 215.04411047266933
At time: 131.8345353603363 and batch: 250, loss is 5.387634449005127 and perplexity is 218.68546159646215
At time: 132.91790461540222 and batch: 300, loss is 5.377768030166626 and perplexity is 216.53842841985312
At time: 133.99897241592407 and batch: 350, loss is 5.376986284255981 and perplexity is 216.36921653790424
At time: 135.0830385684967 and batch: 400, loss is 5.417642431259155 and perplexity is 225.34722418340107
At time: 136.16417455673218 and batch: 450, loss is 5.379254732131958 and perplexity is 216.8605959511657
At time: 137.29107975959778 and batch: 500, loss is 5.40058500289917 and perplexity is 221.53597749273118
At time: 138.3726990222931 and batch: 550, loss is 5.380578908920288 and perplexity is 217.14794792904928
At time: 139.4545738697052 and batch: 600, loss is 5.341926803588867 and perplexity is 208.91486063555354
At time: 140.54069352149963 and batch: 650, loss is 5.369367198944092 and perplexity is 214.72694526524384
At time: 141.62220168113708 and batch: 700, loss is 5.3683344268798825 and perplexity is 214.50529575115527
At time: 142.70446467399597 and batch: 750, loss is 5.34986837387085 and perplexity is 210.58057813601977
At time: 143.78588485717773 and batch: 800, loss is 5.308800086975098 and perplexity is 202.1075713263119
At time: 144.86752939224243 and batch: 850, loss is 5.308227519989014 and perplexity is 201.99188432577196
At time: 145.94987297058105 and batch: 900, loss is 5.329357013702393 and perplexity is 206.30528003244333
At time: 147.03092193603516 and batch: 950, loss is 5.298641300201416 and perplexity is 200.0647972251101
At time: 148.11353397369385 and batch: 1000, loss is 5.312440071105957 and perplexity is 202.84458021524736
At time: 149.1944043636322 and batch: 1050, loss is 5.2857504653930665 and perplexity is 197.5023465216878
At time: 150.2750277519226 and batch: 1100, loss is 5.267495193481445 and perplexity is 193.92959745473806
At time: 151.3565592765808 and batch: 1150, loss is 5.276118993759155 and perplexity is 195.60923961081068
At time: 152.4373905658722 and batch: 1200, loss is 5.272626838684082 and perplexity is 194.92733316649333
At time: 153.5192949771881 and batch: 1250, loss is 5.289867467880249 and perplexity is 198.31714027662372
At time: 154.60202932357788 and batch: 1300, loss is 5.244802742004395 and perplexity is 189.57841568267355
At time: 155.68313312530518 and batch: 1350, loss is 5.229396562576294 and perplexity is 186.68011975426518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.211788736979167 and perplexity of 183.42185839304227
Finished 5 epochs...
Completing Train Step...
At time: 158.9118514060974 and batch: 50, loss is 5.34843258857727 and perplexity is 210.27844658873795
At time: 160.0200138092041 and batch: 100, loss is 5.36176700592041 and perplexity is 213.10116498163964
At time: 161.10230088233948 and batch: 150, loss is 5.3283049011230466 and perplexity is 206.08833779597546
At time: 162.1819145679474 and batch: 200, loss is 5.328720035552979 and perplexity is 206.1739099213409
At time: 163.25983381271362 and batch: 250, loss is 5.345011320114136 and perplexity is 209.56025683146927
At time: 164.36950254440308 and batch: 300, loss is 5.3337788581848145 and perplexity is 207.21954978627875
At time: 165.45318365097046 and batch: 350, loss is 5.3341268825531 and perplexity is 207.29167978996105
At time: 166.5367419719696 and batch: 400, loss is 5.373009281158447 and perplexity is 215.5104243350749
At time: 167.6209921836853 and batch: 450, loss is 5.337560033798217 and perplexity is 208.00456650228162
At time: 168.7047176361084 and batch: 500, loss is 5.359652376174926 and perplexity is 212.6510110415726
At time: 169.79565334320068 and batch: 550, loss is 5.341814985275269 and perplexity is 208.89150143416916
At time: 170.8802468776703 and batch: 600, loss is 5.302127628326416 and perplexity is 200.76350601084042
At time: 171.96874046325684 and batch: 650, loss is 5.33007568359375 and perplexity is 206.45359871533287
At time: 173.05312085151672 and batch: 700, loss is 5.330655107498169 and perplexity is 206.5732575288224
At time: 174.1353178024292 and batch: 750, loss is 5.312525873184204 and perplexity is 202.86198544848287
At time: 175.2180483341217 and batch: 800, loss is 5.274441604614258 and perplexity is 195.28140182828264
At time: 176.29984402656555 and batch: 850, loss is 5.281154794692993 and perplexity is 196.59677322673426
At time: 177.38230800628662 and batch: 900, loss is 5.314971561431885 and perplexity is 203.35872981552387
At time: 178.46521997451782 and batch: 950, loss is 5.272463264465332 and perplexity is 194.89545068790454
At time: 179.54937839508057 and batch: 1000, loss is 5.279321022033692 and perplexity is 196.23658978728903
At time: 180.63272380828857 and batch: 1050, loss is 5.249221506118775 and perplexity is 190.4179715162878
At time: 181.71500658988953 and batch: 1100, loss is 5.234177684783935 and perplexity is 187.5747972975877
At time: 182.79799389839172 and batch: 1150, loss is 5.245906896591187 and perplexity is 189.7878551654108
At time: 183.87808203697205 and batch: 1200, loss is 5.24308331489563 and perplexity is 189.2527294925832
At time: 184.96031403541565 and batch: 1250, loss is 5.265121841430664 and perplexity is 193.469879998387
At time: 186.04244589805603 and batch: 1300, loss is 5.222434844970703 and perplexity is 185.38501877225187
At time: 187.12462639808655 and batch: 1350, loss is 5.2049634075164795 and perplexity is 182.17420644016573
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.201592610677083 and perplexity of 181.5611679953627
Finished 6 epochs...
Completing Train Step...
At time: 190.37034511566162 and batch: 50, loss is 5.312389631271362 and perplexity is 202.83434902620468
At time: 191.47806453704834 and batch: 100, loss is 5.3263471317291256 and perplexity is 205.68525905215384
At time: 192.5604486465454 and batch: 150, loss is 5.2970929622650145 and perplexity is 199.75526899881294
At time: 193.64417552947998 and batch: 200, loss is 5.289853219985962 and perplexity is 198.314314695103
At time: 194.72587823867798 and batch: 250, loss is 5.307591733932495 and perplexity is 201.86350151851155
At time: 195.80887818336487 and batch: 300, loss is 5.296868934631347 and perplexity is 199.71052331090902
At time: 196.8917191028595 and batch: 350, loss is 5.298978414535522 and perplexity is 200.13225330557182
At time: 197.97455835342407 and batch: 400, loss is 5.337405366897583 and perplexity is 207.97239756846167
At time: 199.05775547027588 and batch: 450, loss is 5.301982889175415 and perplexity is 200.73444977426658
At time: 200.13962411880493 and batch: 500, loss is 5.3273774433135985 and perplexity is 205.89728816658052
At time: 201.22184109687805 and batch: 550, loss is 5.311937265396118 and perplexity is 202.7426144387407
At time: 202.3014850616455 and batch: 600, loss is 5.268554487228394 and perplexity is 194.13513470761393
At time: 203.38320779800415 and batch: 650, loss is 5.2958299255371095 and perplexity is 199.5031300213884
At time: 204.46546697616577 and batch: 700, loss is 5.300656595230103 and perplexity is 200.4683933624201
At time: 205.5469880104065 and batch: 750, loss is 5.28316478729248 and perplexity is 196.99232868460192
At time: 206.6252932548523 and batch: 800, loss is 5.251080513000488 and perplexity is 190.772289073086
At time: 207.7064814567566 and batch: 850, loss is 5.248034067153931 and perplexity is 190.1919959899277
At time: 208.78732562065125 and batch: 900, loss is 5.283712081909179 and perplexity is 197.10017103369873
At time: 209.8688838481903 and batch: 950, loss is 5.248622989654541 and perplexity is 190.3040373243952
At time: 210.94936323165894 and batch: 1000, loss is 5.254624357223511 and perplexity is 191.44955570254027
At time: 212.0297417640686 and batch: 1050, loss is 5.224616022109985 and perplexity is 185.78981764570068
At time: 213.1102910041809 and batch: 1100, loss is 5.207609672546386 and perplexity is 182.65692609239105
At time: 214.19031739234924 and batch: 1150, loss is 5.225057039260864 and perplexity is 185.87177221209754
At time: 215.2697720527649 and batch: 1200, loss is 5.220443172454834 and perplexity is 185.0161599704094
At time: 216.35159969329834 and batch: 1250, loss is 5.237493515014648 and perplexity is 188.1977957887941
At time: 217.43150854110718 and batch: 1300, loss is 5.197420482635498 and perplexity is 180.80524954588694
At time: 218.51135802268982 and batch: 1350, loss is 5.1806606006622316 and perplexity is 177.8002271543007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.208307698567708 and perplexity of 182.78446988904395
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 221.77068877220154 and batch: 50, loss is 5.282289342880249 and perplexity is 196.8199483169268
At time: 222.85094022750854 and batch: 100, loss is 5.294806604385376 and perplexity is 199.2990786714383
At time: 223.93087792396545 and batch: 150, loss is 5.268441371917724 and perplexity is 194.11317629347948
At time: 225.01298189163208 and batch: 200, loss is 5.256597652435302 and perplexity is 191.82771518154289
At time: 226.0912220478058 and batch: 250, loss is 5.265350408554077 and perplexity is 193.51410590642703
At time: 227.17221307754517 and batch: 300, loss is 5.260276975631714 and perplexity is 192.5348113637297
At time: 228.2566854953766 and batch: 350, loss is 5.256279039382934 and perplexity is 191.76660610327204
At time: 229.34045433998108 and batch: 400, loss is 5.290746202468872 and perplexity is 198.49148499745112
At time: 230.41701698303223 and batch: 450, loss is 5.248837823867798 and perplexity is 190.34492553446944
At time: 231.4935712814331 and batch: 500, loss is 5.271532907485962 and perplexity is 194.71421266621138
At time: 232.57025980949402 and batch: 550, loss is 5.25034049987793 and perplexity is 190.63116729817412
At time: 233.64694595336914 and batch: 600, loss is 5.204349679946899 and perplexity is 182.06243540919692
At time: 234.72371125221252 and batch: 650, loss is 5.223116493225097 and perplexity is 185.5114292255266
At time: 235.80022192001343 and batch: 700, loss is 5.217282733917236 and perplexity is 184.43235080080157
At time: 236.88902711868286 and batch: 750, loss is 5.201690435409546 and perplexity is 181.57893003681684
At time: 237.97507572174072 and batch: 800, loss is 5.166969261169434 and perplexity is 175.38249266177397
At time: 239.05100440979004 and batch: 850, loss is 5.147105379104614 and perplexity is 171.9330882125355
At time: 240.1267728805542 and batch: 900, loss is 5.1762216186523435 and perplexity is 177.01272429324135
At time: 241.20845746994019 and batch: 950, loss is 5.138128099441528 and perplexity is 170.39650428774897
At time: 242.29472708702087 and batch: 1000, loss is 5.140922746658325 and perplexity is 170.87336842736784
At time: 243.38029718399048 and batch: 1050, loss is 5.104358196258545 and perplexity is 164.7383069337842
At time: 244.46960830688477 and batch: 1100, loss is 5.085106725692749 and perplexity is 161.59718488881012
At time: 245.5583598613739 and batch: 1150, loss is 5.094677429199219 and perplexity is 163.15120831946047
At time: 246.69217038154602 and batch: 1200, loss is 5.074376125335693 and perplexity is 159.87242050749975
At time: 247.7824878692627 and batch: 1250, loss is 5.086640110015869 and perplexity is 161.8451655550229
At time: 248.8740689754486 and batch: 1300, loss is 5.048469152450561 and perplexity is 155.78380060459688
At time: 249.95953583717346 and batch: 1350, loss is 5.045373020172119 and perplexity is 155.3022192555708
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.124513346354167 and perplexity of 168.09231900393556
Finished 8 epochs...
Completing Train Step...
At time: 253.22726845741272 and batch: 50, loss is 5.229778728485107 and perplexity is 186.7514761660139
At time: 254.31339383125305 and batch: 100, loss is 5.2440026664733885 and perplexity is 189.42679929144902
At time: 255.39539527893066 and batch: 150, loss is 5.2189562797546385 and perplexity is 184.7412652128813
At time: 256.4758276939392 and batch: 200, loss is 5.212239170074463 and perplexity is 183.5044962784853
At time: 257.5567488670349 and batch: 250, loss is 5.223114233016968 and perplexity is 185.51100993156007
At time: 258.6403429508209 and batch: 300, loss is 5.221576528549194 and perplexity is 185.2259680340327
At time: 259.72299218177795 and batch: 350, loss is 5.219366998672485 and perplexity is 184.81715752954938
At time: 260.80492210388184 and batch: 400, loss is 5.253884534835816 and perplexity is 191.3079694159275
At time: 261.88620829582214 and batch: 450, loss is 5.213413038253784 and perplexity is 183.72003284843925
At time: 262.96918511390686 and batch: 500, loss is 5.238561010360717 and perplexity is 188.39880332815738
At time: 264.0537152290344 and batch: 550, loss is 5.22098237991333 and perplexity is 185.11594896487512
At time: 265.13761472702026 and batch: 600, loss is 5.176303482055664 and perplexity is 177.02721575043486
At time: 266.22086572647095 and batch: 650, loss is 5.197214155197144 and perplexity is 180.7679483101737
At time: 267.3040237426758 and batch: 700, loss is 5.194623584747315 and perplexity is 180.30026225339986
At time: 268.38725328445435 and batch: 750, loss is 5.1809107780456545 and perplexity is 177.84471431451078
At time: 269.47150802612305 and batch: 800, loss is 5.146668481826782 and perplexity is 171.85798752116457
At time: 270.5546977519989 and batch: 850, loss is 5.130691452026367 and perplexity is 169.13402568700522
At time: 271.63898515701294 and batch: 900, loss is 5.162174558639526 and perplexity is 174.54359851158208
At time: 272.72389340400696 and batch: 950, loss is 5.128079385757446 and perplexity is 168.69281289297192
At time: 273.85356640815735 and batch: 1000, loss is 5.134321537017822 and perplexity is 169.74911230810912
At time: 274.9366738796234 and batch: 1050, loss is 5.101952867507935 and perplexity is 164.3425333214296
At time: 276.0203619003296 and batch: 1100, loss is 5.08565131187439 and perplexity is 161.6852124498137
At time: 277.1033375263214 and batch: 1150, loss is 5.097102842330933 and perplexity is 163.5473976697803
At time: 278.1872992515564 and batch: 1200, loss is 5.0803664016723635 and perplexity is 160.8329746048638
At time: 279.2701292037964 and batch: 1250, loss is 5.098150157928467 and perplexity is 163.71877313673113
At time: 280.3533787727356 and batch: 1300, loss is 5.061429624557495 and perplexity is 157.81597271612955
At time: 281.43662452697754 and batch: 1350, loss is 5.05409990310669 and perplexity is 156.66345457400433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120110677083333 and perplexity of 167.35389083667033
Finished 9 epochs...
Completing Train Step...
At time: 284.67274498939514 and batch: 50, loss is 5.217242631912232 and perplexity is 184.4249548420441
At time: 285.7985415458679 and batch: 100, loss is 5.228653898239136 and perplexity is 186.5415305558647
At time: 286.88156747817993 and batch: 150, loss is 5.20252197265625 and perplexity is 181.72998247451935
At time: 287.9667372703552 and batch: 200, loss is 5.195426902770996 and perplexity is 180.44515889499235
At time: 289.04924178123474 and batch: 250, loss is 5.208062105178833 and perplexity is 182.7395847436232
At time: 290.132878780365 and batch: 300, loss is 5.206875610351562 and perplexity is 182.52289374838074
At time: 291.21647238731384 and batch: 350, loss is 5.20571870803833 and perplexity is 182.3118546897113
At time: 292.30159425735474 and batch: 400, loss is 5.239912948608398 and perplexity is 188.653679125543
At time: 293.38363218307495 and batch: 450, loss is 5.2001975154876705 and perplexity is 181.3080494865688
At time: 294.46670746803284 and batch: 500, loss is 5.226350154876709 and perplexity is 186.11228137285153
At time: 295.5481119155884 and batch: 550, loss is 5.209601650238037 and perplexity is 183.02113724420556
At time: 296.6310188770294 and batch: 600, loss is 5.165291442871093 and perplexity is 175.08847942574363
At time: 297.71223187446594 and batch: 650, loss is 5.186953821182251 and perplexity is 178.9226914453848
At time: 298.79454350471497 and batch: 700, loss is 5.185570774078369 and perplexity is 178.67540397968708
At time: 299.87581634521484 and batch: 750, loss is 5.172810287475586 and perplexity is 176.4099040624944
At time: 300.98315620422363 and batch: 800, loss is 5.138599815368653 and perplexity is 170.4769019936963
At time: 302.0646061897278 and batch: 850, loss is 5.12372447013855 and perplexity is 167.95976726177793
At time: 303.1466426849365 and batch: 900, loss is 5.157151184082031 and perplexity is 173.6689991987705
At time: 304.22788405418396 and batch: 950, loss is 5.125137405395508 and perplexity is 168.19725127395034
At time: 305.3079869747162 and batch: 1000, loss is 5.13292501449585 and perplexity is 169.51221930139621
At time: 306.3896679878235 and batch: 1050, loss is 5.102223949432373 and perplexity is 164.38708965056435
At time: 307.47142815589905 and batch: 1100, loss is 5.086233587265014 and perplexity is 161.77938518462338
At time: 308.5542802810669 and batch: 1150, loss is 5.098054313659668 and perplexity is 163.70308238257763
At time: 309.63701486587524 and batch: 1200, loss is 5.082897491455078 and perplexity is 161.24057291997158
At time: 310.72041869163513 and batch: 1250, loss is 5.101957216262817 and perplexity is 164.3432480083778
At time: 311.80365896224976 and batch: 1300, loss is 5.065137548446655 and perplexity is 158.40222855578344
At time: 312.88765358924866 and batch: 1350, loss is 5.055391235351562 and perplexity is 156.86588982193976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.118504638671875 and perplexity of 167.08532977709476
Finished 10 epochs...
Completing Train Step...
At time: 316.1232738494873 and batch: 50, loss is 5.20753662109375 and perplexity is 182.6435832259697
At time: 317.2345471382141 and batch: 100, loss is 5.217926902770996 and perplexity is 184.55119465045678
At time: 318.31827902793884 and batch: 150, loss is 5.191766996383667 and perplexity is 179.7859535561381
At time: 319.4020802974701 and batch: 200, loss is 5.1845113468170165 and perplexity is 178.48621062177406
At time: 320.48666191101074 and batch: 250, loss is 5.198110103607178 and perplexity is 180.92997964106505
At time: 321.57143783569336 and batch: 300, loss is 5.197473506927491 and perplexity is 180.81483687041097
At time: 322.6553568840027 and batch: 350, loss is 5.197106685638428 and perplexity is 180.7485223024097
At time: 323.7384042739868 and batch: 400, loss is 5.231259794235229 and perplexity is 187.028272307193
At time: 324.8220007419586 and batch: 450, loss is 5.191835231781006 and perplexity is 179.79822174067257
At time: 325.90560030937195 and batch: 500, loss is 5.218698034286499 and perplexity is 184.69356277809558
At time: 326.98805570602417 and batch: 550, loss is 5.20243465423584 and perplexity is 181.7141147922891
At time: 328.0714602470398 and batch: 600, loss is 5.158213682174683 and perplexity is 173.85362024155657
At time: 329.18274188041687 and batch: 650, loss is 5.18056203842163 and perplexity is 177.7827036291261
At time: 330.26630306243896 and batch: 700, loss is 5.179917039871216 and perplexity is 177.66807101590544
At time: 331.3501260280609 and batch: 750, loss is 5.167262582778931 and perplexity is 175.43394368227834
At time: 332.43172574043274 and batch: 800, loss is 5.133537502288818 and perplexity is 169.61607526848655
At time: 333.515198469162 and batch: 850, loss is 5.119435968399048 and perplexity is 167.24101379701557
At time: 334.5984332561493 and batch: 900, loss is 5.153408479690552 and perplexity is 173.0202223201716
At time: 335.6828317642212 and batch: 950, loss is 5.122538805007935 and perplexity is 167.7607412348155
At time: 336.7665681838989 and batch: 1000, loss is 5.1313843917846675 and perplexity is 169.25126599342872
At time: 337.84956097602844 and batch: 1050, loss is 5.101381120681762 and perplexity is 164.24859785580907
At time: 338.9333484172821 and batch: 1100, loss is 5.085688285827636 and perplexity is 161.6911907018186
At time: 340.01769042015076 and batch: 1150, loss is 5.097981567382813 and perplexity is 163.69117402597405
At time: 341.10141801834106 and batch: 1200, loss is 5.083428220748901 and perplexity is 161.3261707279959
At time: 342.1849398612976 and batch: 1250, loss is 5.103249435424805 and perplexity is 164.55575277439223
At time: 343.2678427696228 and batch: 1300, loss is 5.06602373123169 and perplexity is 158.54266410043115
At time: 344.35197043418884 and batch: 1350, loss is 5.054633913040161 and perplexity is 156.7471367565285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117660725911458 and perplexity of 166.94438381662965
Finished 11 epochs...
Completing Train Step...
At time: 347.5965054035187 and batch: 50, loss is 5.199525289535522 and perplexity is 181.18621046663424
At time: 348.6796073913574 and batch: 100, loss is 5.209510068893433 and perplexity is 183.00437668985458
At time: 349.7625484466553 and batch: 150, loss is 5.183590278625489 and perplexity is 178.3218883381754
At time: 350.84588050842285 and batch: 200, loss is 5.1762909317016605 and perplexity is 177.02499401015086
At time: 351.92942547798157 and batch: 250, loss is 5.190488920211792 and perplexity is 179.55632018858643
At time: 353.0124773979187 and batch: 300, loss is 5.190102691650391 and perplexity is 179.48698380005814
At time: 354.0974643230438 and batch: 350, loss is 5.190515766143799 and perplexity is 179.56114061005357
At time: 355.1811029911041 and batch: 400, loss is 5.2246580410003665 and perplexity is 185.79762449169866
At time: 356.31068086624146 and batch: 450, loss is 5.185463466644287 and perplexity is 178.65623180922913
At time: 357.3940041065216 and batch: 500, loss is 5.213006572723389 and perplexity is 183.64537216236883
At time: 358.47807097435 and batch: 550, loss is 5.196941204071045 and perplexity is 180.7186142283228
At time: 359.5606098175049 and batch: 600, loss is 5.152857971191406 and perplexity is 172.9249994301703
At time: 360.6432235240936 and batch: 650, loss is 5.17566349029541 and perplexity is 176.91395603752125
At time: 361.7261550426483 and batch: 700, loss is 5.175124826431275 and perplexity is 176.81868454430168
At time: 362.8089921474457 and batch: 750, loss is 5.162818269729614 and perplexity is 174.6559903316975
At time: 363.8923692703247 and batch: 800, loss is 5.129600877761841 and perplexity is 168.94967301474693
At time: 364.97597789764404 and batch: 850, loss is 5.115892992019654 and perplexity is 166.64953125852227
At time: 366.0589575767517 and batch: 900, loss is 5.150175104141235 and perplexity is 172.46168642854306
At time: 367.1425085067749 and batch: 950, loss is 5.1200933837890625 and perplexity is 167.35099676161292
At time: 368.22542905807495 and batch: 1000, loss is 5.129809904098511 and perplexity is 168.98499163711128
At time: 369.3080508708954 and batch: 1050, loss is 5.100475416183472 and perplexity is 164.09990450817452
At time: 370.3916001319885 and batch: 1100, loss is 5.084662036895752 and perplexity is 161.52534040646592
At time: 371.47527980804443 and batch: 1150, loss is 5.097105445861817 and perplexity is 163.54782347103546
At time: 372.5593218803406 and batch: 1200, loss is 5.082765102386475 and perplexity is 161.21922784366012
At time: 373.6409933567047 and batch: 1250, loss is 5.102937822341919 and perplexity is 164.50448303753888
At time: 374.7238712310791 and batch: 1300, loss is 5.065344886779785 and perplexity is 158.43507481484292
At time: 375.8046841621399 and batch: 1350, loss is 5.052633533477783 and perplexity is 156.43389639196428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11723876953125 and perplexity of 166.87395542863712
Finished 12 epochs...
Completing Train Step...
At time: 379.0250446796417 and batch: 50, loss is 5.192741317749023 and perplexity is 179.96120821519412
At time: 380.1063506603241 and batch: 100, loss is 5.2025016498565675 and perplexity is 181.72628925001771
At time: 381.18868374824524 and batch: 150, loss is 5.176810674667358 and perplexity is 177.11702541980745
At time: 382.27033948898315 and batch: 200, loss is 5.169468688964844 and perplexity is 175.82139681488974
At time: 383.37917470932007 and batch: 250, loss is 5.184041395187378 and perplexity is 178.40235044288156
At time: 384.45965099334717 and batch: 300, loss is 5.1839916706085205 and perplexity is 178.39347968168792
At time: 385.541335105896 and batch: 350, loss is 5.185069303512574 and perplexity is 178.58582598600051
At time: 386.6231601238251 and batch: 400, loss is 5.219379062652588 and perplexity is 184.81938717350965
At time: 387.70480513572693 and batch: 450, loss is 5.180191974639893 and perplexity is 177.71692486141407
At time: 388.78682041168213 and batch: 500, loss is 5.208052549362183 and perplexity is 182.73783852599996
At time: 389.86879682540894 and batch: 550, loss is 5.19225546836853 and perplexity is 179.87379541011802
At time: 390.95052313804626 and batch: 600, loss is 5.148027429580688 and perplexity is 172.09169230762865
At time: 392.032497882843 and batch: 650, loss is 5.171285705566406 and perplexity is 176.1411576291909
At time: 393.1165928840637 and batch: 700, loss is 5.170905542373657 and perplexity is 176.07420797103632
At time: 394.20029401779175 and batch: 750, loss is 5.1587217330932615 and perplexity is 173.9419691739963
At time: 395.28343200683594 and batch: 800, loss is 5.125858669281006 and perplexity is 168.31860963737552
At time: 396.367084980011 and batch: 850, loss is 5.112328767776489 and perplexity is 166.05661223496605
At time: 397.4509086608887 and batch: 900, loss is 5.1469169616699215 and perplexity is 171.90069607283348
At time: 398.534677028656 and batch: 950, loss is 5.117413511276245 and perplexity is 166.9031178226726
At time: 399.6185691356659 and batch: 1000, loss is 5.128023719787597 and perplexity is 168.68342270529507
At time: 400.70144963264465 and batch: 1050, loss is 5.098870944976807 and perplexity is 163.83682204693005
At time: 401.7847709655762 and batch: 1100, loss is 5.0830012226104735 and perplexity is 161.2572994584137
At time: 402.8694248199463 and batch: 1150, loss is 5.095580291748047 and perplexity is 163.29857795249856
At time: 403.953320980072 and batch: 1200, loss is 5.081375608444214 and perplexity is 160.99537026358777
At time: 405.0356206893921 and batch: 1250, loss is 5.101994609832763 and perplexity is 164.34939350401768
At time: 406.1194894313812 and batch: 1300, loss is 5.06402551651001 and perplexity is 158.22617812378726
At time: 407.20364141464233 and batch: 1350, loss is 5.050525197982788 and perplexity is 156.1044286918465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116875 and perplexity of 166.81326280782548
Finished 13 epochs...
Completing Train Step...
At time: 410.4361038208008 and batch: 50, loss is 5.186717796325683 and perplexity is 178.8804662260964
At time: 411.56501603126526 and batch: 100, loss is 5.196336917877197 and perplexity is 180.60944145389553
At time: 412.6483323574066 and batch: 150, loss is 5.170851526260376 and perplexity is 176.06469738353735
At time: 413.732460975647 and batch: 200, loss is 5.163480129241943 and perplexity is 174.77162632345303
At time: 414.81506156921387 and batch: 250, loss is 5.178355159759522 and perplexity is 177.3907913844414
At time: 415.8982484340668 and batch: 300, loss is 5.178530015945435 and perplexity is 177.42181197363084
At time: 416.98181653022766 and batch: 350, loss is 5.180287704467774 and perplexity is 177.73393848638526
At time: 418.06624817848206 and batch: 400, loss is 5.214323434829712 and perplexity is 183.88736709597927
At time: 419.14948320388794 and batch: 450, loss is 5.175556993484497 and perplexity is 176.8951162686027
At time: 420.23232412338257 and batch: 500, loss is 5.203721952438355 and perplexity is 181.94818567282073
At time: 421.3159909248352 and batch: 550, loss is 5.1879480266571045 and perplexity is 179.10066582168514
At time: 422.399694442749 and batch: 600, loss is 5.143696088790893 and perplexity is 171.34791647724902
At time: 423.48247718811035 and batch: 650, loss is 5.167220420837403 and perplexity is 175.4265472025288
At time: 424.5659806728363 and batch: 700, loss is 5.167123718261719 and perplexity is 175.4095838237854
At time: 425.64807963371277 and batch: 750, loss is 5.154739809036255 and perplexity is 173.25072262140853
At time: 426.72937417030334 and batch: 800, loss is 5.122434043884278 and perplexity is 167.74316735160417
At time: 427.8115482330322 and batch: 850, loss is 5.108996896743775 and perplexity is 165.50425372352595
At time: 428.8949942588806 and batch: 900, loss is 5.1438820362091064 and perplexity is 171.3797811424185
At time: 429.9790825843811 and batch: 950, loss is 5.114881811141967 and perplexity is 166.48110360899878
At time: 431.0624349117279 and batch: 1000, loss is 5.126111335754395 and perplexity is 168.36114348009008
At time: 432.14658761024475 and batch: 1050, loss is 5.097185802459717 and perplexity is 163.56096614576683
At time: 433.228547334671 and batch: 1100, loss is 5.081240577697754 and perplexity is 160.9736324062371
At time: 434.31434750556946 and batch: 1150, loss is 5.093492269515991 and perplexity is 162.95796262121505
At time: 435.397917509079 and batch: 1200, loss is 5.07984185218811 and perplexity is 160.74863187388587
At time: 436.48009490966797 and batch: 1250, loss is 5.100396089553833 and perplexity is 164.086887532129
At time: 437.562753200531 and batch: 1300, loss is 5.06223352432251 and perplexity is 157.94289194784673
At time: 438.64629197120667 and batch: 1350, loss is 5.04806848526001 and perplexity is 155.72139564951902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116885579427083 and perplexity of 166.81502760591104
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 441.87662959098816 and batch: 50, loss is 5.184237060546875 and perplexity is 178.43726101819982
At time: 442.98740673065186 and batch: 100, loss is 5.197445449829101 and perplexity is 180.80976380191075
At time: 444.07059717178345 and batch: 150, loss is 5.172404069900512 and perplexity is 176.33825781201548
At time: 445.1547553539276 and batch: 200, loss is 5.165261554718017 and perplexity is 175.08324643267133
At time: 446.2381558418274 and batch: 250, loss is 5.1801104164123535 and perplexity is 177.70243117506632
At time: 447.3215491771698 and batch: 300, loss is 5.180156803131103 and perplexity is 177.71067439894892
At time: 448.40390038490295 and batch: 350, loss is 5.179941158294678 and perplexity is 177.67235614135288
At time: 449.48788118362427 and batch: 400, loss is 5.212910795211792 and perplexity is 183.62778390789998
At time: 450.572350025177 and batch: 450, loss is 5.1724769115448 and perplexity is 176.35110304849377
At time: 451.6560060977936 and batch: 500, loss is 5.197688779830933 and perplexity is 180.85376559532892
At time: 452.7391083240509 and batch: 550, loss is 5.17898720741272 and perplexity is 177.50294625771346
At time: 453.82298493385315 and batch: 600, loss is 5.13803997039795 and perplexity is 170.38148806848923
At time: 454.9075560569763 and batch: 650, loss is 5.159213457107544 and perplexity is 174.0275216497103
At time: 455.99109840393066 and batch: 700, loss is 5.156788368225097 and perplexity is 173.60600076111047
At time: 457.0753297805786 and batch: 750, loss is 5.141813764572143 and perplexity is 171.02568750906894
At time: 458.1587450504303 and batch: 800, loss is 5.108864202499389 and perplexity is 165.4822937186509
At time: 459.2424900531769 and batch: 850, loss is 5.088427648544312 and perplexity is 162.1347287496748
At time: 460.3258547782898 and batch: 900, loss is 5.116450424194336 and perplexity is 166.74245296550998
At time: 461.409316778183 and batch: 950, loss is 5.088236093521118 and perplexity is 162.10367400239002
At time: 462.4930040836334 and batch: 1000, loss is 5.101779317855835 and perplexity is 164.31401420675925
At time: 463.57732224464417 and batch: 1050, loss is 5.068431663513183 and perplexity is 158.9248840945635
At time: 464.66032671928406 and batch: 1100, loss is 5.0481821632385255 and perplexity is 155.73909874919536
At time: 465.7713050842285 and batch: 1150, loss is 5.0583167552948 and perplexity is 157.3254760475748
At time: 466.8553795814514 and batch: 1200, loss is 5.041596851348877 and perplexity is 154.71687772680747
At time: 467.9388418197632 and batch: 1250, loss is 5.059970035552978 and perplexity is 157.58579428143648
At time: 469.0220742225647 and batch: 1300, loss is 5.0271687412261965 and perplexity is 152.50063214106652
At time: 470.1058921813965 and batch: 1350, loss is 5.020051393508911 and perplexity is 151.41908555220778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1018379720052085 and perplexity of 164.3236521881438
Finished 15 epochs...
Completing Train Step...
At time: 473.355295419693 and batch: 50, loss is 5.177241744995118 and perplexity is 177.19339177245874
At time: 474.4389269351959 and batch: 100, loss is 5.18896788597107 and perplexity is 179.28341647800013
At time: 475.52304792404175 and batch: 150, loss is 5.163581285476685 and perplexity is 174.7893064573244
At time: 476.60658049583435 and batch: 200, loss is 5.157002410888672 and perplexity is 173.64316382902504
At time: 477.6896412372589 and batch: 250, loss is 5.171690301895142 and perplexity is 176.21243811384568
At time: 478.7728762626648 and batch: 300, loss is 5.171737108230591 and perplexity is 176.22068616536342
At time: 479.8557960987091 and batch: 350, loss is 5.172065372467041 and perplexity is 176.27854260993547
At time: 480.9402651786804 and batch: 400, loss is 5.2051820468902585 and perplexity is 182.21404124915065
At time: 482.02436566352844 and batch: 450, loss is 5.1649385261535645 and perplexity is 175.0266986766784
At time: 483.10822057724 and batch: 500, loss is 5.191215448379516 and perplexity is 179.68682031316422
At time: 484.1923017501831 and batch: 550, loss is 5.173580026626587 and perplexity is 176.54574594697684
At time: 485.27548003196716 and batch: 600, loss is 5.1321915340423585 and perplexity is 169.38793098900672
At time: 486.3592185974121 and batch: 650, loss is 5.154195384979248 and perplexity is 173.15642643100594
At time: 487.4427492618561 and batch: 700, loss is 5.152526769638062 and perplexity is 172.86773588515786
At time: 488.5269875526428 and batch: 750, loss is 5.138514013290405 and perplexity is 170.46227534871923
At time: 489.6102764606476 and batch: 800, loss is 5.105845346450805 and perplexity is 164.98347979786374
At time: 490.69455885887146 and batch: 850, loss is 5.086229095458984 and perplexity is 161.7786585046375
At time: 491.7783639431 and batch: 900, loss is 5.114947443008423 and perplexity is 166.49203043312818
At time: 492.88901925086975 and batch: 950, loss is 5.087130441665649 and perplexity is 161.92454282106092
At time: 493.97205209732056 and batch: 1000, loss is 5.101465682983399 and perplexity is 164.2624876825539
At time: 495.0579719543457 and batch: 1050, loss is 5.068998365402222 and perplexity is 159.01497265086164
At time: 496.14254426956177 and batch: 1100, loss is 5.049742279052734 and perplexity is 155.9822594101205
At time: 497.2264823913574 and batch: 1150, loss is 5.0607586765289305 and perplexity is 157.7101219145239
At time: 498.3109791278839 and batch: 1200, loss is 5.045203619003296 and perplexity is 155.2759131063172
At time: 499.3947100639343 and batch: 1250, loss is 5.064507684707642 and perplexity is 158.30248815056697
At time: 500.4785964488983 and batch: 1300, loss is 5.03166425704956 and perplexity is 153.18774445086834
At time: 501.56397128105164 and batch: 1350, loss is 5.02272521018982 and perplexity is 151.82449418161096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.10005859375 and perplexity of 164.03151824010035
Finished 16 epochs...
Completing Train Step...
At time: 504.78944301605225 and batch: 50, loss is 5.174545574188232 and perplexity is 176.71629158320675
At time: 505.8711426258087 and batch: 100, loss is 5.1855607509613035 and perplexity is 178.6736131041714
At time: 506.95301938056946 and batch: 150, loss is 5.159578790664673 and perplexity is 174.09111135825287
At time: 508.0352838039398 and batch: 200, loss is 5.153168773651123 and perplexity is 172.9787532983241
At time: 509.117121219635 and batch: 250, loss is 5.167707605361938 and perplexity is 175.51203312353667
At time: 510.19928526878357 and batch: 300, loss is 5.167611150741577 and perplexity is 175.49510499342426
At time: 511.2822961807251 and batch: 350, loss is 5.168212060928345 and perplexity is 175.60059348112176
At time: 512.3667411804199 and batch: 400, loss is 5.201304349899292 and perplexity is 181.5088385744819
At time: 513.4533700942993 and batch: 450, loss is 5.161293830871582 and perplexity is 174.3899407928983
At time: 514.5370783805847 and batch: 500, loss is 5.187685823440551 and perplexity is 179.0537112071144
At time: 515.6196706295013 and batch: 550, loss is 5.170726633071899 and perplexity is 176.04270947520152
At time: 516.703428030014 and batch: 600, loss is 5.129576177597046 and perplexity is 168.94549998151888
At time: 517.7872583866119 and batch: 650, loss is 5.151725778579712 and perplexity is 172.72932581445133
At time: 518.8711800575256 and batch: 700, loss is 5.150599536895752 and perplexity is 172.53490035325726
At time: 519.9553525447845 and batch: 750, loss is 5.137190742492676 and perplexity is 170.2368567754366
At time: 521.0842909812927 and batch: 800, loss is 5.1046381855010985 and perplexity is 164.78443834541028
At time: 522.167887210846 and batch: 850, loss is 5.085512018203735 and perplexity is 161.66269229157513
At time: 523.2512311935425 and batch: 900, loss is 5.114422674179077 and perplexity is 166.4046835256941
At time: 524.3332719802856 and batch: 950, loss is 5.087043285369873 and perplexity is 161.91043069270276
At time: 525.4175696372986 and batch: 1000, loss is 5.101751785278321 and perplexity is 164.30949028070444
At time: 526.5014092922211 and batch: 1050, loss is 5.0698266696929934 and perplexity is 159.1467399992016
At time: 527.585202217102 and batch: 1100, loss is 5.051061334609986 and perplexity is 156.18814443326832
At time: 528.6689076423645 and batch: 1150, loss is 5.062627201080322 and perplexity is 158.00508263417893
At time: 529.7524375915527 and batch: 1200, loss is 5.047624244689941 and perplexity is 155.6522332514528
At time: 530.8356831073761 and batch: 1250, loss is 5.0672222518920895 and perplexity is 158.7327946738611
At time: 531.9195437431335 and batch: 1300, loss is 5.0343303298950195 and perplexity is 153.5966990457406
At time: 533.0027577877045 and batch: 1350, loss is 5.0240702724456785 and perplexity is 152.02884497971309
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099270833333334 and perplexity of 163.90235158581353
Finished 17 epochs...
Completing Train Step...
At time: 536.2490782737732 and batch: 50, loss is 5.172627506256103 and perplexity is 176.37766259175848
At time: 537.3590772151947 and batch: 100, loss is 5.183082094192505 and perplexity is 178.231290952502
At time: 538.4431023597717 and batch: 150, loss is 5.156702976226807 and perplexity is 173.59117683072185
At time: 539.5265622138977 and batch: 200, loss is 5.150456171035767 and perplexity is 172.51016651192737
At time: 540.6101891994476 and batch: 250, loss is 5.1649107837677 and perplexity is 175.02184308582034
At time: 541.6933188438416 and batch: 300, loss is 5.164683380126953 and perplexity is 174.98204700655046
At time: 542.7764728069305 and batch: 350, loss is 5.16553750038147 and perplexity is 175.13156656182608
At time: 543.860068321228 and batch: 400, loss is 5.19862117767334 and perplexity is 181.02247189463375
At time: 544.9437167644501 and batch: 450, loss is 5.158834714889526 and perplexity is 173.96162256033588
At time: 546.0270218849182 and batch: 500, loss is 5.185221223831177 and perplexity is 178.61295886254777
At time: 547.1105618476868 and batch: 550, loss is 5.168761501312256 and perplexity is 175.69710204904345
At time: 548.2403092384338 and batch: 600, loss is 5.127919101715088 and perplexity is 168.6657762938303
At time: 549.3243255615234 and batch: 650, loss is 5.150119571685791 and perplexity is 172.45210947354406
At time: 550.4082181453705 and batch: 700, loss is 5.1494271850585935 and perplexity is 172.3327472662791
At time: 551.4915738105774 and batch: 750, loss is 5.136422538757325 and perplexity is 170.10613040483926
At time: 552.5752747058868 and batch: 800, loss is 5.1039525985717775 and perplexity is 164.67150300624493
At time: 553.6610498428345 and batch: 850, loss is 5.085084228515625 and perplexity is 161.59354944921267
At time: 554.7399916648865 and batch: 900, loss is 5.1140187549591065 and perplexity is 166.33748304842075
At time: 555.8227922916412 and batch: 950, loss is 5.086976222991943 and perplexity is 161.89957295828566
At time: 556.9067332744598 and batch: 1000, loss is 5.1020346450805665 and perplexity is 164.355973404426
At time: 557.9907169342041 and batch: 1050, loss is 5.070443172454834 and perplexity is 159.24488465406583
At time: 559.0762257575989 and batch: 1100, loss is 5.0519679737091066 and perplexity is 156.32981492412938
At time: 560.1614952087402 and batch: 1150, loss is 5.063964977264404 and perplexity is 158.21659952027218
At time: 561.2461891174316 and batch: 1200, loss is 5.0492757797241214 and perplexity is 155.90951076074757
At time: 562.3301000595093 and batch: 1250, loss is 5.0691099452972415 and perplexity is 159.03271651472738
At time: 563.4126062393188 and batch: 1300, loss is 5.036079177856445 and perplexity is 153.86555134212063
At time: 564.496258020401 and batch: 1350, loss is 5.024817171096802 and perplexity is 152.14243753474267
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09885498046875 and perplexity of 163.83420649354252
Finished 18 epochs...
Completing Train Step...
At time: 567.7396385669708 and batch: 50, loss is 5.171068878173828 and perplexity is 176.10296954151775
At time: 568.8506412506104 and batch: 100, loss is 5.181094074249268 and perplexity is 177.87731556322865
At time: 569.9340267181396 and batch: 150, loss is 5.1543274974823 and perplexity is 173.17930407109915
At time: 571.0174870491028 and batch: 200, loss is 5.148228225708007 and perplexity is 172.1262511225098
At time: 572.1008462905884 and batch: 250, loss is 5.162674064636231 and perplexity is 174.63080586420958
At time: 573.1852900981903 and batch: 300, loss is 5.162395410537719 and perplexity is 174.58215105367523
At time: 574.2679057121277 and batch: 350, loss is 5.163472623825073 and perplexity is 174.77031459446295
At time: 575.3490915298462 and batch: 400, loss is 5.196569509506226 and perplexity is 180.65145458386306
At time: 576.4752192497253 and batch: 450, loss is 5.156896743774414 and perplexity is 173.62481642636828
At time: 577.558646440506 and batch: 500, loss is 5.183330030441284 and perplexity is 178.27548642879967
At time: 578.6431074142456 and batch: 550, loss is 5.167173738479614 and perplexity is 175.41835806883225
At time: 579.725103855133 and batch: 600, loss is 5.126669387817383 and perplexity is 168.45512398410435
At time: 580.8067648410797 and batch: 650, loss is 5.148915147781372 and perplexity is 172.24452906302446
At time: 581.8917396068573 and batch: 700, loss is 5.148586359024048 and perplexity is 172.1879063073308
At time: 582.9733879566193 and batch: 750, loss is 5.13587724685669 and perplexity is 170.01339819504037
At time: 584.0538282394409 and batch: 800, loss is 5.103381013870239 and perplexity is 164.57740618905964
At time: 585.1358623504639 and batch: 850, loss is 5.0847487449646 and perplexity is 161.5393465640172
At time: 586.2168478965759 and batch: 900, loss is 5.1136798000335695 and perplexity is 166.281111693454
At time: 587.2988939285278 and batch: 950, loss is 5.086877746582031 and perplexity is 161.8836304545676
At time: 588.380690574646 and batch: 1000, loss is 5.102215013504028 and perplexity is 164.38562070587363
At time: 589.4629929065704 and batch: 1050, loss is 5.07081934928894 and perplexity is 159.30480015932866
At time: 590.5439465045929 and batch: 1100, loss is 5.0525735664367675 and perplexity is 156.42451579534924
At time: 591.6244170665741 and batch: 1150, loss is 5.064898557662964 and perplexity is 158.36437640638007
At time: 592.705290555954 and batch: 1200, loss is 5.050474548339844 and perplexity is 156.096522258502
At time: 593.7863306999207 and batch: 1250, loss is 5.070442018508911 and perplexity is 159.24470089418648
At time: 594.8685314655304 and batch: 1300, loss is 5.037291860580444 and perplexity is 154.05225462109178
At time: 595.9500734806061 and batch: 1350, loss is 5.0252479076385494 and perplexity is 152.20798495796117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.098612060546875 and perplexity of 163.79441273444482
Finished 19 epochs...
Completing Train Step...
At time: 599.2383937835693 and batch: 50, loss is 5.169645481109619 and perplexity is 175.85248340458148
At time: 600.3229269981384 and batch: 100, loss is 5.179424390792847 and perplexity is 177.58056456122077
At time: 601.4070203304291 and batch: 150, loss is 5.152363843917847 and perplexity is 172.83957357903117
At time: 602.49085521698 and batch: 200, loss is 5.146396770477295 and perplexity is 171.81129809876523
At time: 603.6146082878113 and batch: 250, loss is 5.160801086425781 and perplexity is 174.30403228537728
At time: 604.6980376243591 and batch: 300, loss is 5.160486545562744 and perplexity is 174.24921516619528
At time: 605.7816202640533 and batch: 350, loss is 5.161747417449951 and perplexity is 174.46905967171884
At time: 606.8646008968353 and batch: 400, loss is 5.194890756607055 and perplexity is 180.3484398453397
At time: 607.9486384391785 and batch: 450, loss is 5.155300359725953 and perplexity is 173.34786565771887
At time: 609.0323338508606 and batch: 500, loss is 5.181754417419434 and perplexity is 177.9948144242038
At time: 610.1163394451141 and batch: 550, loss is 5.165821294784546 and perplexity is 175.18127497336917
At time: 611.1998627185822 and batch: 600, loss is 5.125669460296631 and perplexity is 168.28676525691117
At time: 612.2837026119232 and batch: 650, loss is 5.14795563697815 and perplexity is 172.0793378406476
At time: 613.3671143054962 and batch: 700, loss is 5.147912836074829 and perplexity is 172.07197284716045
At time: 614.4522995948792 and batch: 750, loss is 5.135394334793091 and perplexity is 169.93131649479534
At time: 615.534095287323 and batch: 800, loss is 5.102931518554687 and perplexity is 164.50344603954764
At time: 616.6155877113342 and batch: 850, loss is 5.084428558349609 and perplexity is 161.48763210703336
At time: 617.6975901126862 and batch: 900, loss is 5.113326549530029 and perplexity is 166.22238318056813
At time: 618.7844502925873 and batch: 950, loss is 5.08675986289978 and perplexity is 161.86454814088222
At time: 619.8663423061371 and batch: 1000, loss is 5.102351179122925 and perplexity is 164.40800589966707
At time: 620.9466998577118 and batch: 1050, loss is 5.071074256896972 and perplexity is 159.3454133409699
At time: 622.026816368103 and batch: 1100, loss is 5.052978105545044 and perplexity is 156.48780843079172
At time: 623.1077666282654 and batch: 1150, loss is 5.065540571212768 and perplexity is 158.46608112624995
At time: 624.1932446956635 and batch: 1200, loss is 5.051299180984497 and perplexity is 156.22529763536548
At time: 625.2825195789337 and batch: 1250, loss is 5.071405725479126 and perplexity is 159.39824009392348
At time: 626.3632469177246 and batch: 1300, loss is 5.038220672607422 and perplexity is 154.19540667835184
At time: 627.4498746395111 and batch: 1350, loss is 5.025477123260498 and perplexity is 152.24287740469305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0984488932291665 and perplexity of 163.76768901974097
Finished 20 epochs...
Completing Train Step...
At time: 630.7491428852081 and batch: 50, loss is 5.168355569839478 and perplexity is 175.6257955394033
At time: 631.8303241729736 and batch: 100, loss is 5.177959394454956 and perplexity is 177.32060015440493
At time: 632.9111258983612 and batch: 150, loss is 5.150647459030151 and perplexity is 172.54316879205962
At time: 633.9913592338562 and batch: 200, loss is 5.144735984802246 and perplexity is 171.52619317069306
At time: 635.0733082294464 and batch: 250, loss is 5.159160127639771 and perplexity is 174.01824110206834
At time: 636.1533944606781 and batch: 300, loss is 5.158839492797852 and perplexity is 173.96245373500633
At time: 637.2478022575378 and batch: 350, loss is 5.160299348831177 and perplexity is 174.21659933552166
At time: 638.3320562839508 and batch: 400, loss is 5.193442487716675 and perplexity is 180.08743585808156
At time: 639.4120614528656 and batch: 450, loss is 5.153949546813965 and perplexity is 173.1138632048722
At time: 640.4937591552734 and batch: 500, loss is 5.180389699935913 and perplexity is 177.75206746716657
At time: 641.5829060077667 and batch: 550, loss is 5.164667463302612 and perplexity is 174.97926187021073
At time: 642.6643691062927 and batch: 600, loss is 5.124848756790161 and perplexity is 168.1487083782036
At time: 643.7449493408203 and batch: 650, loss is 5.147104654312134 and perplexity is 171.93296359677123
At time: 644.8271656036377 and batch: 700, loss is 5.147307729721069 and perplexity is 171.96788249912822
At time: 645.9084520339966 and batch: 750, loss is 5.134863471984863 and perplexity is 169.84113021930278
At time: 646.992193698883 and batch: 800, loss is 5.102481260299682 and perplexity is 164.42939367758632
At time: 648.0869822502136 and batch: 850, loss is 5.084137086868286 and perplexity is 161.44056992666265
At time: 649.2021155357361 and batch: 900, loss is 5.1129861831665036 and perplexity is 166.16581629974624
At time: 650.2965731620789 and batch: 950, loss is 5.086597204208374 and perplexity is 161.8382216064745
At time: 651.381756067276 and batch: 1000, loss is 5.102382469177246 and perplexity is 164.41315031558656
At time: 652.473518371582 and batch: 1050, loss is 5.071251907348633 and perplexity is 159.3737236402142
At time: 653.5645222663879 and batch: 1100, loss is 5.053262548446655 and perplexity is 156.53232660822815
At time: 654.6547026634216 and batch: 1150, loss is 5.065993070602417 and perplexity is 158.5378031571034
At time: 655.7453289031982 and batch: 1200, loss is 5.051899690628051 and perplexity is 156.31914060714735
At time: 656.8383486270905 and batch: 1250, loss is 5.07201226234436 and perplexity is 159.49495032899046
At time: 657.9214270114899 and batch: 1300, loss is 5.038855295181275 and perplexity is 154.29329362156093
At time: 659.0029990673065 and batch: 1350, loss is 5.02552303314209 and perplexity is 152.24986701761276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.098370361328125 and perplexity of 163.75482853677875
Finished 21 epochs...
Completing Train Step...
At time: 662.2423377037048 and batch: 50, loss is 5.167142448425293 and perplexity is 175.41286930475155
At time: 663.3693392276764 and batch: 100, loss is 5.176650886535644 and perplexity is 177.08872648219833
At time: 664.4531674385071 and batch: 150, loss is 5.1491397190093995 and perplexity is 172.28321457210077
At time: 665.5344042778015 and batch: 200, loss is 5.143275804519654 and perplexity is 171.27591677427515
At time: 666.6149735450745 and batch: 250, loss is 5.157725439071656 and perplexity is 173.7687581288937
At time: 667.6946730613708 and batch: 300, loss is 5.157379484176635 and perplexity is 173.708652373957
At time: 668.7748272418976 and batch: 350, loss is 5.159039011001587 and perplexity is 173.9971658740296
At time: 669.856552362442 and batch: 400, loss is 5.1922397041320805 and perplexity is 179.8709598594263
At time: 670.9355492591858 and batch: 450, loss is 5.152760553359985 and perplexity is 172.90815427224996
At time: 672.0170104503632 and batch: 500, loss is 5.179191598892212 and perplexity is 177.53923005543643
At time: 673.0980195999146 and batch: 550, loss is 5.16369520187378 and perplexity is 174.80921895952542
At time: 674.1862752437592 and batch: 600, loss is 5.124049530029297 and perplexity is 168.01437311998038
At time: 675.2699983119965 and batch: 650, loss is 5.146375894546509 and perplexity is 171.8077114154357
At time: 676.361225605011 and batch: 700, loss is 5.146778011322022 and perplexity is 171.87681207069357
At time: 677.4508321285248 and batch: 750, loss is 5.134428253173828 and perplexity is 169.76722824747463
At time: 678.5546486377716 and batch: 800, loss is 5.1021146488189695 and perplexity is 164.36912302272953
At time: 679.6517806053162 and batch: 850, loss is 5.083874950408935 and perplexity is 161.3982560135185
At time: 680.736554145813 and batch: 900, loss is 5.112642784118652 and perplexity is 166.10876491290003
At time: 681.8160736560822 and batch: 950, loss is 5.086442174911499 and perplexity is 161.8131338854875
At time: 682.9006490707397 and batch: 1000, loss is 5.102425956726075 and perplexity is 164.42030039595758
At time: 683.9849846363068 and batch: 1050, loss is 5.071287498474121 and perplexity is 159.37939603135467
At time: 685.0642838478088 and batch: 1100, loss is 5.053382415771484 and perplexity is 156.55109084405478
At time: 686.1909334659576 and batch: 1150, loss is 5.066295719146728 and perplexity is 158.58579165390526
At time: 687.2711038589478 and batch: 1200, loss is 5.052333469390869 and perplexity is 156.38696323950998
At time: 688.3537836074829 and batch: 1250, loss is 5.072532014846802 and perplexity is 159.57786977547897
At time: 689.4344310760498 and batch: 1300, loss is 5.039397487640381 and perplexity is 154.37697296495767
At time: 690.513952255249 and batch: 1350, loss is 5.025497398376465 and perplexity is 152.24596417797974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.098376871744792 and perplexity of 163.7558946524142
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 693.7362525463104 and batch: 50, loss is 5.166682138442993 and perplexity is 175.3321435908381
At time: 694.8416833877563 and batch: 100, loss is 5.17660548210144 and perplexity is 177.0806860513054
At time: 695.9196174144745 and batch: 150, loss is 5.149323139190674 and perplexity is 172.31481768878422
At time: 696.9981801509857 and batch: 200, loss is 5.1438899421691895 and perplexity is 171.38113606948323
At time: 698.0757892131805 and batch: 250, loss is 5.1575467395782475 and perplexity is 173.73770851420375
At time: 699.1554052829742 and batch: 300, loss is 5.157682228088379 and perplexity is 173.76124957221938
At time: 700.2335090637207 and batch: 350, loss is 5.159008121490478 and perplexity is 173.9917912696513
At time: 701.3124508857727 and batch: 400, loss is 5.1925599193573 and perplexity is 179.9285665021179
At time: 702.3903999328613 and batch: 450, loss is 5.152568464279175 and perplexity is 172.87494369362807
At time: 703.4675600528717 and batch: 500, loss is 5.178156080245972 and perplexity is 177.35548002698494
At time: 704.5463678836823 and batch: 550, loss is 5.161650123596192 and perplexity is 174.45208573028506
At time: 705.6279890537262 and batch: 600, loss is 5.121380634307862 and perplexity is 167.56655812999182
At time: 706.7131974697113 and batch: 650, loss is 5.144066534042358 and perplexity is 171.41140325771863
At time: 707.8021619319916 and batch: 700, loss is 5.143841810226441 and perplexity is 171.3728873609685
At time: 708.8890392780304 and batch: 750, loss is 5.131717233657837 and perplexity is 169.30760927802035
At time: 709.9797842502594 and batch: 800, loss is 5.099470272064209 and perplexity is 163.93504332269214
At time: 711.0604736804962 and batch: 850, loss is 5.079667301177978 and perplexity is 160.72057548652154
At time: 712.1483311653137 and batch: 900, loss is 5.107185773849487 and perplexity is 165.204776457433
At time: 713.3011422157288 and batch: 950, loss is 5.080227241516114 and perplexity is 160.81059462022486
At time: 714.40154337883 and batch: 1000, loss is 5.096401147842407 and perplexity is 163.4326776161445
At time: 715.4863460063934 and batch: 1050, loss is 5.06464017868042 and perplexity is 158.32346366565667
At time: 716.5762729644775 and batch: 1100, loss is 5.04656720161438 and perplexity is 155.48778906370538
At time: 717.6672463417053 and batch: 1150, loss is 5.059548358917237 and perplexity is 157.5193580421526
At time: 718.7537150382996 and batch: 1200, loss is 5.045194072723389 and perplexity is 155.27443080606312
At time: 719.8437049388885 and batch: 1250, loss is 5.064764366149903 and perplexity is 158.34312667689363
At time: 720.9247150421143 and batch: 1300, loss is 5.0317997646331785 and perplexity is 153.20850395846236
At time: 722.0103936195374 and batch: 1350, loss is 5.0196806335449216 and perplexity is 151.36295582347216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096406656901042 and perplexity of 163.43357797882845
Finished 23 epochs...
Completing Train Step...
At time: 725.2915115356445 and batch: 50, loss is 5.1657586193084715 and perplexity is 175.17029574762853
At time: 726.3754320144653 and batch: 100, loss is 5.175569715499878 and perplexity is 176.89736674530806
At time: 727.4551231861115 and batch: 150, loss is 5.148280429840088 and perplexity is 172.13523705860734
At time: 728.5406537055969 and batch: 200, loss is 5.142741584777832 and perplexity is 171.1844422341639
At time: 729.6192216873169 and batch: 250, loss is 5.156590261459351 and perplexity is 173.5716116442563
At time: 730.6970620155334 and batch: 300, loss is 5.1567682361602785 and perplexity is 173.60250574903125
At time: 731.7831780910492 and batch: 350, loss is 5.158008852005005 and perplexity is 173.8180134218233
At time: 732.8726570606232 and batch: 400, loss is 5.1916382789611815 and perplexity is 179.762813460896
At time: 733.9573411941528 and batch: 450, loss is 5.1517857074737545 and perplexity is 172.73967760209862
At time: 735.0378034114838 and batch: 500, loss is 5.177461185455322 and perplexity is 177.23227943850213
At time: 736.1140291690826 and batch: 550, loss is 5.161093883514404 and perplexity is 174.35507547084902
At time: 737.1912767887115 and batch: 600, loss is 5.121104459762574 and perplexity is 167.5202869017566
At time: 738.2702212333679 and batch: 650, loss is 5.14362585067749 and perplexity is 171.33588174551355
At time: 739.3486993312836 and batch: 700, loss is 5.14345552444458 and perplexity is 171.30670123538712
At time: 740.4518568515778 and batch: 750, loss is 5.131416645050049 and perplexity is 169.25672498746164
At time: 741.5281500816345 and batch: 800, loss is 5.09916672706604 and perplexity is 163.88528921195467
At time: 742.6049149036407 and batch: 850, loss is 5.0795298671722415 and perplexity is 160.69848853181222
At time: 743.6897211074829 and batch: 900, loss is 5.10715311050415 and perplexity is 165.19938040489532
At time: 744.7672665119171 and batch: 950, loss is 5.0801840496063235 and perplexity is 160.80364905352596
At time: 745.8536353111267 and batch: 1000, loss is 5.096457042694092 and perplexity is 163.44181291672606
At time: 746.9315278530121 and batch: 1050, loss is 5.064726076126099 and perplexity is 158.33706383087795
At time: 748.0106427669525 and batch: 1100, loss is 5.046834297180176 and perplexity is 155.52932470944623
At time: 749.0889282226562 and batch: 1150, loss is 5.059907751083374 and perplexity is 157.5759794394818
At time: 750.1681883335114 and batch: 1200, loss is 5.045719194412231 and perplexity is 155.35599018982856
At time: 751.2467634677887 and batch: 1250, loss is 5.065305318832397 and perplexity is 158.42880598816134
At time: 752.3250348567963 and batch: 1300, loss is 5.032182130813599 and perplexity is 153.26709691019656
At time: 753.4082398414612 and batch: 1350, loss is 5.020038614273071 and perplexity is 151.4171505443668
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096207275390625 and perplexity of 163.40099559346865
Finished 24 epochs...
Completing Train Step...
At time: 756.6681208610535 and batch: 50, loss is 5.16532675743103 and perplexity is 175.09466270752384
At time: 757.755877494812 and batch: 100, loss is 5.174993572235107 and perplexity is 176.79547787301416
At time: 758.8368072509766 and batch: 150, loss is 5.147669277191162 and perplexity is 172.03006829286386
At time: 759.91907954216 and batch: 200, loss is 5.142120304107666 and perplexity is 171.07812168004313
At time: 761.0004453659058 and batch: 250, loss is 5.156035299301148 and perplexity is 173.47531269166424
At time: 762.0808670520782 and batch: 300, loss is 5.15624924659729 and perplexity is 173.51243123632665
At time: 763.1605427265167 and batch: 350, loss is 5.157498617172241 and perplexity is 173.72934803882066
At time: 764.2414557933807 and batch: 400, loss is 5.1911855316162105 and perplexity is 179.68144474550192
At time: 765.3221895694733 and batch: 450, loss is 5.151373805999756 and perplexity is 172.66854052601536
At time: 766.4057669639587 and batch: 500, loss is 5.1770854187011714 and perplexity is 177.1656939512165
At time: 767.486741065979 and batch: 550, loss is 5.1607836246490475 and perplexity is 174.30098865385537
At time: 768.5950825214386 and batch: 600, loss is 5.1208850765228275 and perplexity is 167.48353978949055
At time: 769.6767601966858 and batch: 650, loss is 5.143365983963013 and perplexity is 171.2913630375679
At time: 770.7775297164917 and batch: 700, loss is 5.143235340118408 and perplexity is 171.268986337074
At time: 771.8842527866364 and batch: 750, loss is 5.1312571144104 and perplexity is 169.22972550753894
At time: 772.9940099716187 and batch: 800, loss is 5.0990456867218015 and perplexity is 163.86545368060686
At time: 774.0932943820953 and batch: 850, loss is 5.079495735168457 and perplexity is 160.6930036639988
At time: 775.1841189861298 and batch: 900, loss is 5.107176141738892 and perplexity is 165.20318519441892
At time: 776.27001786232 and batch: 950, loss is 5.080201330184937 and perplexity is 160.80642785763433
At time: 777.3565769195557 and batch: 1000, loss is 5.09654821395874 and perplexity is 163.4567147928072
At time: 778.445529460907 and batch: 1050, loss is 5.06484504699707 and perplexity is 158.35590244987026
At time: 779.5307075977325 and batch: 1100, loss is 5.047076177597046 and perplexity is 155.56694875741923
At time: 780.6183619499207 and batch: 1150, loss is 5.060209579467774 and perplexity is 157.6235475211137
At time: 781.7123563289642 and batch: 1200, loss is 5.046114854812622 and perplexity is 155.417470564983
At time: 782.7989130020142 and batch: 1250, loss is 5.065686731338501 and perplexity is 158.48924424131246
At time: 783.8906319141388 and batch: 1300, loss is 5.032420120239258 and perplexity is 153.303577199352
At time: 784.9741058349609 and batch: 1350, loss is 5.020243673324585 and perplexity is 151.44820318534414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096112060546875 and perplexity of 163.38543813386696
Finished 25 epochs...
Completing Train Step...
At time: 788.2333085536957 and batch: 50, loss is 5.164991064071655 and perplexity is 175.03589445659858
At time: 789.3400812149048 and batch: 100, loss is 5.174524393081665 and perplexity is 176.7125485762432
At time: 790.418919801712 and batch: 150, loss is 5.147192726135254 and perplexity is 171.9481067131607
At time: 791.5045518875122 and batch: 200, loss is 5.1416512298583985 and perplexity is 170.99789215682264
At time: 792.5971221923828 and batch: 250, loss is 5.1555823230743405 and perplexity is 173.3967502938696
At time: 793.6774985790253 and batch: 300, loss is 5.15583794593811 and perplexity is 173.44108013336694
At time: 794.7572913169861 and batch: 350, loss is 5.15711820602417 and perplexity is 173.6632720269022
At time: 795.8639121055603 and batch: 400, loss is 5.190860719680786 and perplexity is 179.62309154509526
At time: 796.9487733840942 and batch: 450, loss is 5.151063108444214 and perplexity is 172.6149011657955
At time: 798.3714554309845 and batch: 500, loss is 5.176800746917724 and perplexity is 177.1152670550515
At time: 799.4524025917053 and batch: 550, loss is 5.160552625656128 and perplexity is 174.26072995105037
At time: 800.5359125137329 and batch: 600, loss is 5.120693788528443 and perplexity is 167.45150526307958
At time: 801.615960597992 and batch: 650, loss is 5.143158073425293 and perplexity is 171.25575346010353
At time: 802.7030944824219 and batch: 700, loss is 5.143058576583862 and perplexity is 171.23871490121286
At time: 803.7897925376892 and batch: 750, loss is 5.13113263130188 and perplexity is 169.20866057639506
At time: 804.8816180229187 and batch: 800, loss is 5.098981790542602 and perplexity is 163.85498363871534
At time: 805.9632737636566 and batch: 850, loss is 5.079494132995605 and perplexity is 160.69274620623705
At time: 807.0438632965088 and batch: 900, loss is 5.107199831008911 and perplexity is 165.2070987836359
At time: 808.1274766921997 and batch: 950, loss is 5.080209817886352 and perplexity is 160.80779274037204
At time: 809.2100517749786 and batch: 1000, loss is 5.096632890701294 and perplexity is 163.47055636098557
At time: 810.2974615097046 and batch: 1050, loss is 5.064951200485229 and perplexity is 158.37271337353914
At time: 811.3839631080627 and batch: 1100, loss is 5.047272329330444 and perplexity is 155.5974664770314
At time: 812.4695990085602 and batch: 1150, loss is 5.060456981658936 and perplexity is 157.66254875644577
At time: 813.5544612407684 and batch: 1200, loss is 5.046431818008423 and perplexity is 155.46673999102148
At time: 814.6336197853088 and batch: 1250, loss is 5.065981149673462 and perplexity is 158.53591325048004
At time: 815.7201626300812 and batch: 1300, loss is 5.032590255737305 and perplexity is 153.32966179870644
At time: 816.8078746795654 and batch: 1350, loss is 5.020382862091065 and perplexity is 151.469284541041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096045735677083 and perplexity of 163.37460197531422
Finished 26 epochs...
Completing Train Step...
At time: 820.0648143291473 and batch: 50, loss is 5.164699325561523 and perplexity is 174.98483719357725
At time: 821.1464145183563 and batch: 100, loss is 5.174113178253174 and perplexity is 176.63989669467753
At time: 822.2308480739594 and batch: 150, loss is 5.146789846420288 and perplexity is 171.87884626169148
At time: 823.3517861366272 and batch: 200, loss is 5.14125057220459 and perplexity is 170.9293942655634
At time: 824.4319682121277 and batch: 250, loss is 5.155188627243042 and perplexity is 173.32849815229162
At time: 825.5175933837891 and batch: 300, loss is 5.15548418045044 and perplexity is 173.37973351686915
At time: 826.5992805957794 and batch: 350, loss is 5.156802196502685 and perplexity is 173.60840144967858
At time: 827.6871433258057 and batch: 400, loss is 5.190594577789307 and perplexity is 179.57529267668093
At time: 828.7756218910217 and batch: 450, loss is 5.150801906585693 and perplexity is 172.56981972073746
At time: 829.877204656601 and batch: 500, loss is 5.176560621261597 and perplexity is 177.07274224119354
At time: 830.9598274230957 and batch: 550, loss is 5.160356903076172 and perplexity is 174.22662652891313
At time: 832.0476701259613 and batch: 600, loss is 5.120524702072143 and perplexity is 167.4231938750562
At time: 833.1403379440308 and batch: 650, loss is 5.142974586486816 and perplexity is 171.22433314890108
At time: 834.2313008308411 and batch: 700, loss is 5.142906017303467 and perplexity is 171.2125928387239
At time: 835.3144776821136 and batch: 750, loss is 5.131010112762451 and perplexity is 169.18793064836862
At time: 836.3949117660522 and batch: 800, loss is 5.098939094543457 and perplexity is 163.84798783582144
At time: 837.475476026535 and batch: 850, loss is 5.07950306892395 and perplexity is 160.69418215151845
At time: 838.5555362701416 and batch: 900, loss is 5.1072256469726565 and perplexity is 165.21136381916136
At time: 839.6351454257965 and batch: 950, loss is 5.080216865539551 and perplexity is 160.80892606192057
At time: 840.7143807411194 and batch: 1000, loss is 5.096703052520752 and perplexity is 163.4820261550138
At time: 841.7929203510284 and batch: 1050, loss is 5.0650327682495115 and perplexity is 158.3856320085573
At time: 842.871372461319 and batch: 1100, loss is 5.047434310913086 and perplexity is 155.62267244230242
At time: 843.949061870575 and batch: 1150, loss is 5.060664577484131 and perplexity is 157.695282240907
At time: 845.0268776416779 and batch: 1200, loss is 5.0467002487182615 and perplexity is 155.50847763997632
At time: 846.1050679683685 and batch: 1250, loss is 5.0662216949462895 and perplexity is 158.57405290195837
At time: 847.1929724216461 and batch: 1300, loss is 5.032724132537842 and perplexity is 153.3501904573804
At time: 848.2763185501099 and batch: 1350, loss is 5.020487060546875 and perplexity is 151.48506822889652
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095995686848958 and perplexity of 163.36642547255394
Finished 27 epochs...
Completing Train Step...
At time: 851.5025618076324 and batch: 50, loss is 5.164436759948731 and perplexity is 174.93889822383096
At time: 852.582808971405 and batch: 100, loss is 5.173753690719605 and perplexity is 176.5764082662178
At time: 853.6643264293671 and batch: 150, loss is 5.146426954269409 and perplexity is 171.8164840935361
At time: 854.7455317974091 and batch: 200, loss is 5.1408911800384525 and perplexity is 170.86797461783294
At time: 855.8364005088806 and batch: 250, loss is 5.1548279285430905 and perplexity is 173.2659900623146
At time: 856.9202222824097 and batch: 300, loss is 5.155167446136475 and perplexity is 173.32482690178182
At time: 858.0037934780121 and batch: 350, loss is 5.156524648666382 and perplexity is 173.56022349964434
At time: 859.0972728729248 and batch: 400, loss is 5.1903605461120605 and perplexity is 179.5332712871037
At time: 860.1864454746246 and batch: 450, loss is 5.1505711555480955 and perplexity is 172.5300036497554
At time: 861.2754642963409 and batch: 500, loss is 5.176348934173584 and perplexity is 177.0352621951828
At time: 862.3567540645599 and batch: 550, loss is 5.160178709030151 and perplexity is 174.19558314736238
At time: 863.4424300193787 and batch: 600, loss is 5.120374221801757 and perplexity is 167.39800188306947
At time: 864.5330636501312 and batch: 650, loss is 5.1428068733215335 and perplexity is 171.19561898195448
At time: 865.6357583999634 and batch: 700, loss is 5.142766227722168 and perplexity is 171.18866077482346
At time: 866.7246129512787 and batch: 750, loss is 5.13090874671936 and perplexity is 169.17078160648003
At time: 867.8060014247894 and batch: 800, loss is 5.098907222747803 and perplexity is 163.8427657894532
At time: 868.8911807537079 and batch: 850, loss is 5.079511661529541 and perplexity is 160.69556293917864
At time: 869.9784274101257 and batch: 900, loss is 5.1072407150268555 and perplexity is 165.2138532517011
At time: 871.0704655647278 and batch: 950, loss is 5.0802296447753905 and perplexity is 160.8109810902426
At time: 872.185135602951 and batch: 1000, loss is 5.096760482788086 and perplexity is 163.49141524108643
At time: 873.2747006416321 and batch: 1050, loss is 5.0650950050354 and perplexity is 158.39548972797763
At time: 874.3607838153839 and batch: 1100, loss is 5.0475695514678955 and perplexity is 155.6437203620985
At time: 875.4455785751343 and batch: 1150, loss is 5.060839281082154 and perplexity is 157.7228345807821
At time: 876.5380387306213 and batch: 1200, loss is 5.046935033798218 and perplexity is 155.54499299679568
At time: 877.6407263278961 and batch: 1250, loss is 5.066428937911987 and perplexity is 158.60691966454954
At time: 878.7263276576996 and batch: 1300, loss is 5.032834424972534 and perplexity is 153.36710475598883
At time: 879.8188471794128 and batch: 1350, loss is 5.020567541122436 and perplexity is 151.4972603249834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09595947265625 and perplexity of 163.36050939646336
Finished 28 epochs...
Completing Train Step...
At time: 883.0341465473175 and batch: 50, loss is 5.164188318252563 and perplexity is 174.89544150568443
At time: 884.1141550540924 and batch: 100, loss is 5.173422870635986 and perplexity is 176.5180029054359
At time: 885.1940772533417 and batch: 150, loss is 5.146091785430908 and perplexity is 171.758906211822
At time: 886.274974822998 and batch: 200, loss is 5.140560684204101 and perplexity is 170.81151279471032
At time: 887.3532848358154 and batch: 250, loss is 5.154486904144287 and perplexity is 173.2069122062882
At time: 888.4329330921173 and batch: 300, loss is 5.154876279830932 and perplexity is 173.27436789861127
At time: 889.5198345184326 and batch: 350, loss is 5.156272029876709 and perplexity is 173.51638446356367
At time: 890.6005938053131 and batch: 400, loss is 5.190147151947022 and perplexity is 179.4949640219995
At time: 891.6829721927643 and batch: 450, loss is 5.150361652374268 and perplexity is 172.49386185245305
At time: 892.76327252388 and batch: 500, loss is 5.176156024932862 and perplexity is 177.00111375105283
At time: 893.841245174408 and batch: 550, loss is 5.160012435913086 and perplexity is 174.16662151261087
At time: 894.919823884964 and batch: 600, loss is 5.120236845016479 and perplexity is 167.37500686323588
At time: 895.9989278316498 and batch: 650, loss is 5.142647848129273 and perplexity is 171.16839673030094
At time: 897.0800986289978 and batch: 700, loss is 5.142635021209717 and perplexity is 171.1662011811267
At time: 898.1661534309387 and batch: 750, loss is 5.130823612213135 and perplexity is 169.15637994856795
At time: 899.3093440532684 and batch: 800, loss is 5.098882703781128 and perplexity is 163.838748583388
At time: 900.390908241272 and batch: 850, loss is 5.079518642425537 and perplexity is 160.69668474210619
At time: 901.4715514183044 and batch: 900, loss is 5.107248668670654 and perplexity is 165.21516730906623
At time: 902.549548625946 and batch: 950, loss is 5.080237493515015 and perplexity is 160.8122432587151
At time: 903.6314976215363 and batch: 1000, loss is 5.096809453964234 and perplexity is 163.4994218040247
At time: 904.709981918335 and batch: 1050, loss is 5.06514533996582 and perplexity is 158.40346275459115
At time: 905.7888433933258 and batch: 1100, loss is 5.0476861095428465 and perplexity is 155.66186295183422
At time: 906.8751502037048 and batch: 1150, loss is 5.060992498397827 and perplexity is 157.7470023015263
At time: 907.9529466629028 and batch: 1200, loss is 5.047142639160156 and perplexity is 155.57728832358993
At time: 909.0310196876526 and batch: 1250, loss is 5.066609220504761 and perplexity is 158.63551630891962
At time: 910.1090905666351 and batch: 1300, loss is 5.032927322387695 and perplexity is 153.3813528253856
At time: 911.189738035202 and batch: 1350, loss is 5.0206297016143795 and perplexity is 151.50667776190645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095932210286458 and perplexity of 163.35605586255403
Finished 29 epochs...
Completing Train Step...
At time: 914.4033133983612 and batch: 50, loss is 5.163952007293701 and perplexity is 174.85411667914858
At time: 915.5080246925354 and batch: 100, loss is 5.173113403320312 and perplexity is 176.4633848046031
At time: 916.5854339599609 and batch: 150, loss is 5.145777654647827 and perplexity is 171.70495992565074
At time: 917.6635699272156 and batch: 200, loss is 5.140250101089477 and perplexity is 170.75846986059915
At time: 918.741578578949 and batch: 250, loss is 5.1541731071472165 and perplexity is 173.15256892419134
At time: 919.8211963176727 and batch: 300, loss is 5.154606657028198 and perplexity is 173.22765547554667
At time: 920.8992943763733 and batch: 350, loss is 5.1560415840148925 and perplexity is 173.47640293777226
At time: 921.9776225090027 and batch: 400, loss is 5.189950551986694 and perplexity is 179.45967878784526
At time: 923.0558648109436 and batch: 450, loss is 5.1501695346832275 and perplexity is 172.46072591309735
At time: 924.1342585086823 and batch: 500, loss is 5.17597508430481 and perplexity is 176.96908995565497
At time: 925.212541103363 and batch: 550, loss is 5.159859027862549 and perplexity is 174.13990500005238
At time: 926.3348298072815 and batch: 600, loss is 5.1201083374023435 and perplexity is 167.3534992824115
At time: 927.4129405021667 and batch: 650, loss is 5.142496786117554 and perplexity is 171.1425416408582
At time: 928.4915013313293 and batch: 700, loss is 5.1425138854980466 and perplexity is 171.14546809731647
At time: 929.5692074298859 and batch: 750, loss is 5.130745506286621 and perplexity is 169.14316834874515
At time: 930.647967338562 and batch: 800, loss is 5.098862628936768 and perplexity is 163.83545957902325
At time: 931.726156949997 and batch: 850, loss is 5.079522867202758 and perplexity is 160.69736365123356
At time: 932.8042056560516 and batch: 900, loss is 5.107251167297363 and perplexity is 165.21558012061175
At time: 933.8887946605682 and batch: 950, loss is 5.080239305496216 and perplexity is 160.81253464774073
At time: 934.9661507606506 and batch: 1000, loss is 5.096851787567139 and perplexity is 163.50634347013104
At time: 936.0498054027557 and batch: 1050, loss is 5.065188007354736 and perplexity is 158.41022156093146
At time: 937.1273391246796 and batch: 1100, loss is 5.047789239883423 and perplexity is 155.67791724060316
At time: 938.2051060199738 and batch: 1150, loss is 5.061132307052612 and perplexity is 157.76905823948414
At time: 939.2834506034851 and batch: 1200, loss is 5.04732684135437 and perplexity is 155.60594864103467
At time: 940.3623366355896 and batch: 1250, loss is 5.066764936447144 and perplexity is 158.66022031119067
At time: 941.4406213760376 and batch: 1300, loss is 5.033006410598755 and perplexity is 153.39348396189916
At time: 942.5195984840393 and batch: 1350, loss is 5.020675210952759 and perplexity is 151.51357288746658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095910237630208 and perplexity of 163.35246653552585
Finished 30 epochs...
Completing Train Step...
At time: 945.7120642662048 and batch: 50, loss is 5.163723154067993 and perplexity is 174.81410532905616
At time: 946.8211450576782 and batch: 100, loss is 5.172820072174073 and perplexity is 176.41163018866055
At time: 947.9055223464966 and batch: 150, loss is 5.145480766296386 and perplexity is 171.65399028968417
At time: 948.98299908638 and batch: 200, loss is 5.139957523345947 and perplexity is 170.70851704069665
At time: 950.0604348182678 and batch: 250, loss is 5.1538802528381344 and perplexity is 173.10186787262631
At time: 951.138251543045 and batch: 300, loss is 5.154354124069214 and perplexity is 173.18391530628116
At time: 952.215585231781 and batch: 350, loss is 5.155828294754028 and perplexity is 173.43940622965275
At time: 953.2941093444824 and batch: 400, loss is 5.189772024154663 and perplexity is 179.42764310017023
At time: 954.4156606197357 and batch: 450, loss is 5.149990777969361 and perplexity is 172.4299001556997
At time: 955.4929945468903 and batch: 500, loss is 5.175805149078369 and perplexity is 176.93901922839063
At time: 956.5709352493286 and batch: 550, loss is 5.159719200134277 and perplexity is 174.1155571150292
At time: 957.6553153991699 and batch: 600, loss is 5.1199891567230225 and perplexity is 167.33355516718046
At time: 958.7357814311981 and batch: 650, loss is 5.142352542877197 and perplexity is 171.11785726640898
At time: 959.8148846626282 and batch: 700, loss is 5.142400054931641 and perplexity is 171.12598762050308
At time: 960.8933725357056 and batch: 750, loss is 5.13067398071289 and perplexity is 169.1310707192365
At time: 961.9714200496674 and batch: 800, loss is 5.0988432312011716 and perplexity is 163.83228157292018
At time: 963.0531435012817 and batch: 850, loss is 5.079522457122803 and perplexity is 160.6972977524793
At time: 964.1351523399353 and batch: 900, loss is 5.1072483253479 and perplexity is 165.2151105869497
At time: 965.2179999351501 and batch: 950, loss is 5.080234451293945 and perplexity is 160.81175403306457
At time: 966.2955117225647 and batch: 1000, loss is 5.096886110305786 and perplexity is 163.51195555193564
At time: 967.3734755516052 and batch: 1050, loss is 5.06522463798523 and perplexity is 158.41602433350278
At time: 968.4519617557526 and batch: 1100, loss is 5.047881126403809 and perplexity is 155.69222259994402
At time: 969.529224395752 and batch: 1150, loss is 5.061257858276367 and perplexity is 157.7888675813342
At time: 970.6076400279999 and batch: 1200, loss is 5.047489881515503 and perplexity is 155.63132072825272
At time: 971.6896421909332 and batch: 1250, loss is 5.066897754669189 and perplexity is 158.6812946790608
At time: 972.7718675136566 and batch: 1300, loss is 5.033072509765625 and perplexity is 153.4036234784954
At time: 973.8510129451752 and batch: 1350, loss is 5.020704374313355 and perplexity is 151.51799159685973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095892333984375 and perplexity of 163.34954195699953
Finished 31 epochs...
Completing Train Step...
At time: 977.0684416294098 and batch: 50, loss is 5.163498029708863 and perplexity is 174.7747548451694
At time: 978.1467366218567 and batch: 100, loss is 5.172538995742798 and perplexity is 176.3620520051676
At time: 979.2266535758972 and batch: 150, loss is 5.145198192596435 and perplexity is 171.6054922389962
At time: 980.3034529685974 and batch: 200, loss is 5.139681272506714 and perplexity is 170.66136518276988
At time: 981.4099028110504 and batch: 250, loss is 5.153602657318115 and perplexity is 173.05382223853277
At time: 982.4890937805176 and batch: 300, loss is 5.154113788604736 and perplexity is 173.14229807080503
At time: 983.5663895606995 and batch: 350, loss is 5.155628108978272 and perplexity is 173.4046896025734
At time: 984.6435959339142 and batch: 400, loss is 5.189605588912964 and perplexity is 179.39778250202028
At time: 985.7210536003113 and batch: 450, loss is 5.149821748733521 and perplexity is 172.40075692453883
At time: 986.7987475395203 and batch: 500, loss is 5.175642614364624 and perplexity is 176.91026283256963
At time: 987.877019405365 and batch: 550, loss is 5.159589700698852 and perplexity is 174.09301070858908
At time: 988.9545681476593 and batch: 600, loss is 5.119877090454102 and perplexity is 167.3148037707068
At time: 990.0311591625214 and batch: 650, loss is 5.142213354110718 and perplexity is 171.0940412404335
At time: 991.1158699989319 and batch: 700, loss is 5.1422918510437015 and perplexity is 171.10747212505743
At time: 992.1962904930115 and batch: 750, loss is 5.130605564117432 and perplexity is 169.1194997430196
At time: 993.2736301422119 and batch: 800, loss is 5.098823556900024 and perplexity is 163.8290583189826
At time: 994.351496219635 and batch: 850, loss is 5.079519109725952 and perplexity is 160.69675983575124
At time: 995.4295585155487 and batch: 900, loss is 5.107240877151489 and perplexity is 165.2138800369387
At time: 996.5120449066162 and batch: 950, loss is 5.080223484039307 and perplexity is 160.80999037928044
At time: 997.5917699337006 and batch: 1000, loss is 5.09691367149353 and perplexity is 163.51646219774491
At time: 998.6719076633453 and batch: 1050, loss is 5.065254907608033 and perplexity is 158.42081959938037
At time: 999.757926940918 and batch: 1100, loss is 5.047962436676025 and perplexity is 155.70488249162827
At time: 1000.8363089561462 and batch: 1150, loss is 5.061370372772217 and perplexity is 157.80662211502334
At time: 1001.9239909648895 and batch: 1200, loss is 5.047633924484253 and perplexity is 155.65373994034707
At time: 1003.0043823719025 and batch: 1250, loss is 5.067010803222656 and perplexity is 158.69923438389625
At time: 1004.0892765522003 and batch: 1300, loss is 5.033128166198731 and perplexity is 153.4121616146026
At time: 1005.1666307449341 and batch: 1350, loss is 5.020722618103028 and perplexity is 151.52075588444555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09587646484375 and perplexity of 163.3469497607151
Finished 32 epochs...
Completing Train Step...
At time: 1008.4091432094574 and batch: 50, loss is 5.1632781505584715 and perplexity is 174.73632974515823
At time: 1009.4870874881744 and batch: 100, loss is 5.172268629074097 and perplexity is 176.3143760299694
At time: 1010.5704216957092 and batch: 150, loss is 5.144927339553833 and perplexity is 171.5590186633348
At time: 1011.6470522880554 and batch: 200, loss is 5.139417953491211 and perplexity is 170.61643271615173
At time: 1012.7304844856262 and batch: 250, loss is 5.153337564468384 and perplexity is 173.0079529877125
At time: 1013.8132967948914 and batch: 300, loss is 5.1538832473754885 and perplexity is 173.10238623341186
At time: 1014.8903758525848 and batch: 350, loss is 5.155438604354859 and perplexity is 173.37183172563033
At time: 1015.9725720882416 and batch: 400, loss is 5.18944827079773 and perplexity is 179.36956220084033
At time: 1017.0523910522461 and batch: 450, loss is 5.149660310745239 and perplexity is 172.3729271396154
At time: 1018.1366541385651 and batch: 500, loss is 5.175486869812012 and perplexity is 176.88271216832095
At time: 1019.2136108875275 and batch: 550, loss is 5.159468698501587 and perplexity is 174.07194634620754
At time: 1020.2916839122772 and batch: 600, loss is 5.119770088195801 and perplexity is 167.296901666656
At time: 1021.3749089241028 and batch: 650, loss is 5.142077941894531 and perplexity is 171.07087458569222
At time: 1022.4518473148346 and batch: 700, loss is 5.142188644409179 and perplexity is 171.08981360997146
At time: 1023.5295035839081 and batch: 750, loss is 5.130539112091064 and perplexity is 169.1082617829601
At time: 1024.6065661907196 and batch: 800, loss is 5.098803281784058 and perplexity is 163.82573669949969
At time: 1025.6891930103302 and batch: 850, loss is 5.07951322555542 and perplexity is 160.69581427139434
At time: 1026.7662947177887 and batch: 900, loss is 5.107229738235474 and perplexity is 165.21203974365386
At time: 1027.8430252075195 and batch: 950, loss is 5.0802075386047365 and perplexity is 160.80742621454405
At time: 1028.923621892929 and batch: 1000, loss is 5.096936416625977 and perplexity is 163.52018144363205
At time: 1030.0052571296692 and batch: 1050, loss is 5.065280332565307 and perplexity is 158.4248474931544
At time: 1031.0867402553558 and batch: 1100, loss is 5.048034725189209 and perplexity is 155.71613857291678
At time: 1032.173789024353 and batch: 1150, loss is 5.061473665237426 and perplexity is 157.8229231919227
At time: 1033.256607055664 and batch: 1200, loss is 5.047763833999634 and perplexity is 155.67396215577057
At time: 1034.3393206596375 and batch: 1250, loss is 5.067115669250488 and perplexity is 158.7158774148551
At time: 1035.417031288147 and batch: 1300, loss is 5.033177661895752 and perplexity is 153.41975504439273
At time: 1036.4941129684448 and batch: 1350, loss is 5.020738286972046 and perplexity is 151.52313006192333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095862223307292 and perplexity of 163.3446234657399
Finished 33 epochs...
Completing Train Step...
At time: 1039.6773102283478 and batch: 50, loss is 5.163066816329956 and perplexity is 174.6994058794937
At time: 1040.7874326705933 and batch: 100, loss is 5.172007513046265 and perplexity is 176.26834353062404
At time: 1041.8664376735687 and batch: 150, loss is 5.1446646881103515 and perplexity is 171.51396435648894
At time: 1042.9445495605469 and batch: 200, loss is 5.13916467666626 and perplexity is 170.57322499977647
At time: 1044.0221436023712 and batch: 250, loss is 5.153083152770996 and perplexity is 172.9639433392535
At time: 1045.1000876426697 and batch: 300, loss is 5.153662757873535 and perplexity is 173.06422318191505
At time: 1046.1782801151276 and batch: 350, loss is 5.155258684158325 and perplexity is 173.34064143755842
At time: 1047.2625634670258 and batch: 400, loss is 5.189298067092896 and perplexity is 179.34262225135407
At time: 1048.3430678844452 and batch: 450, loss is 5.149504919052124 and perplexity is 172.34614389962027
At time: 1049.4218719005585 and batch: 500, loss is 5.175337772369385 and perplexity is 176.85634137424958
At time: 1050.4993603229523 and batch: 550, loss is 5.1593535614013675 and perplexity is 174.0519053608283
At time: 1051.5777275562286 and batch: 600, loss is 5.119667177200317 and perplexity is 167.27968586182718
At time: 1052.6559720039368 and batch: 650, loss is 5.141945247650146 and perplexity is 171.04817597127396
At time: 1053.7329528331757 and batch: 700, loss is 5.142089920043945 and perplexity is 171.07292371046083
At time: 1054.8111522197723 and batch: 750, loss is 5.130475120544434 and perplexity is 169.09744062997547
At time: 1055.8894035816193 and batch: 800, loss is 5.098781671524048 and perplexity is 163.82219642098661
At time: 1056.9673645496368 and batch: 850, loss is 5.079503316879272 and perplexity is 160.69422199650106
At time: 1058.0453906059265 and batch: 900, loss is 5.107215747833252 and perplexity is 165.2097283769345
At time: 1059.1236906051636 and batch: 950, loss is 5.080188617706299 and perplexity is 160.80438362234906
At time: 1060.2022993564606 and batch: 1000, loss is 5.0969555473327635 and perplexity is 163.52330973020003
At time: 1061.281254529953 and batch: 1050, loss is 5.065302066802978 and perplexity is 158.4282907738612
At time: 1062.360135793686 and batch: 1100, loss is 5.048099813461303 and perplexity is 155.7262741971653
At time: 1063.482126235962 and batch: 1150, loss is 5.061569633483887 and perplexity is 157.838069907903
At time: 1064.5600898265839 and batch: 1200, loss is 5.047884969711304 and perplexity is 155.69282097418
At time: 1065.646193265915 and batch: 1250, loss is 5.067217655181885 and perplexity is 158.73206502688103
At time: 1066.7248034477234 and batch: 1300, loss is 5.0332216548919675 and perplexity is 153.42650458756103
At time: 1067.8030138015747 and batch: 1350, loss is 5.020752582550049 and perplexity is 151.5252961881314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095850830078125 and perplexity of 163.342762453613
Finished 34 epochs...
Completing Train Step...
At time: 1070.9967546463013 and batch: 50, loss is 5.16286262512207 and perplexity is 174.66373743850514
At time: 1072.101185798645 and batch: 100, loss is 5.171754951477051 and perplexity is 176.22383054255087
At time: 1073.1849558353424 and batch: 150, loss is 5.144408721923828 and perplexity is 171.4700681993027
At time: 1074.2634348869324 and batch: 200, loss is 5.138919448852539 and perplexity is 170.53140082916494
At time: 1075.3421325683594 and batch: 250, loss is 5.152837810516357 and perplexity is 172.92151318059155
At time: 1076.4255516529083 and batch: 300, loss is 5.1534514808654786 and perplexity is 173.02766255298567
At time: 1077.503799200058 and batch: 350, loss is 5.155087118148804 and perplexity is 173.31090462640498
At time: 1078.5824704170227 and batch: 400, loss is 5.189153594970703 and perplexity is 179.31671411366472
At time: 1079.6607904434204 and batch: 450, loss is 5.1493534660339355 and perplexity is 172.3200435324932
At time: 1080.7397317886353 and batch: 500, loss is 5.175194091796875 and perplexity is 176.8309323793021
At time: 1081.8315148353577 and batch: 550, loss is 5.159243068695068 and perplexity is 174.0326749571977
At time: 1082.9105455875397 and batch: 600, loss is 5.1195673084259035 and perplexity is 167.2629806787928
At time: 1083.990383863449 and batch: 650, loss is 5.141813592910767 and perplexity is 171.0256581505665
At time: 1085.0672631263733 and batch: 700, loss is 5.1419949626922605 and perplexity is 171.0566798499295
At time: 1086.1459624767303 and batch: 750, loss is 5.130413551330566 and perplexity is 169.08702975398685
At time: 1087.2242922782898 and batch: 800, loss is 5.098759622573852 and perplexity is 163.81858435335812
At time: 1088.3037059307098 and batch: 850, loss is 5.07948977470398 and perplexity is 160.69204586191316
At time: 1089.3811793327332 and batch: 900, loss is 5.107198705673218 and perplexity is 165.2069128702955
At time: 1090.4940881729126 and batch: 950, loss is 5.080167512893677 and perplexity is 160.80098991177587
At time: 1091.5800278186798 and batch: 1000, loss is 5.09697078704834 and perplexity is 163.52580179791963
At time: 1092.6671080589294 and batch: 1050, loss is 5.065320806503296 and perplexity is 158.43125970037048
At time: 1093.7461664676666 and batch: 1100, loss is 5.0481586933135985 and perplexity is 155.73544360713262
At time: 1094.826877117157 and batch: 1150, loss is 5.061658058166504 and perplexity is 157.85202730621964
At time: 1095.905089378357 and batch: 1200, loss is 5.047998275756836 and perplexity is 155.71046291149247
At time: 1096.983268737793 and batch: 1250, loss is 5.067315130233765 and perplexity is 158.74753819726632
At time: 1098.0615539550781 and batch: 1300, loss is 5.033259449005127 and perplexity is 153.4323033158152
At time: 1099.140236377716 and batch: 1350, loss is 5.0207642078399655 and perplexity is 151.5270577238684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095841471354166 and perplexity of 163.3412337809418
Finished 35 epochs...
Completing Train Step...
At time: 1102.3843822479248 and batch: 50, loss is 5.162664175033569 and perplexity is 174.62907884346694
At time: 1103.4640123844147 and batch: 100, loss is 5.171509294509888 and perplexity is 176.18054524768274
At time: 1104.5435807704926 and batch: 150, loss is 5.144158229827881 and perplexity is 171.42712168163354
At time: 1105.6227450370789 and batch: 200, loss is 5.1386809921264645 and perplexity is 170.49074131759005
At time: 1106.700712442398 and batch: 250, loss is 5.15260066986084 and perplexity is 172.88051132139896
At time: 1107.779556274414 and batch: 300, loss is 5.153248338699341 and perplexity is 172.99251690871495
At time: 1108.8583600521088 and batch: 350, loss is 5.154921751022339 and perplexity is 173.28224706969618
At time: 1109.9371101856232 and batch: 400, loss is 5.189014434814453 and perplexity is 179.29176210791323
At time: 1111.0200860500336 and batch: 450, loss is 5.149205741882324 and perplexity is 172.2945895803847
At time: 1112.103399515152 and batch: 500, loss is 5.175053949356079 and perplexity is 176.80615259722035
At time: 1113.182286977768 and batch: 550, loss is 5.1591371822357175 and perplexity is 174.01424822902285
At time: 1114.260300397873 and batch: 600, loss is 5.119469709396363 and perplexity is 167.24665677081217
At time: 1115.3391604423523 and batch: 650, loss is 5.141681814193726 and perplexity is 171.00312209367334
At time: 1116.4251236915588 and batch: 700, loss is 5.1419025421142575 and perplexity is 171.0408714232297
At time: 1117.5702588558197 and batch: 750, loss is 5.13035439491272 and perplexity is 169.07702746685504
At time: 1118.6497519016266 and batch: 800, loss is 5.098738193511963 and perplexity is 163.81507391238824
At time: 1119.7312941551208 and batch: 850, loss is 5.079472398757934 and perplexity is 160.68925370985252
At time: 1120.8126711845398 and batch: 900, loss is 5.107178277969361 and perplexity is 165.20353810687365
At time: 1121.8928344249725 and batch: 950, loss is 5.080145215988159 and perplexity is 160.7974045872675
At time: 1122.9729166030884 and batch: 1000, loss is 5.096982831954956 and perplexity is 163.5277714627938
At time: 1124.0532448291779 and batch: 1050, loss is 5.065335464477539 and perplexity is 158.43358199871454
At time: 1125.1421074867249 and batch: 1100, loss is 5.048212623596191 and perplexity is 155.74384269009647
At time: 1126.2299840450287 and batch: 1150, loss is 5.061739053726196 and perplexity is 157.86481313731062
At time: 1127.3077056407928 and batch: 1200, loss is 5.048104515075684 and perplexity is 155.7270063637767
At time: 1128.389597415924 and batch: 1250, loss is 5.067406997680664 and perplexity is 158.76212259820767
At time: 1129.4681301116943 and batch: 1300, loss is 5.033291549682617 and perplexity is 153.43722867575383
At time: 1130.546305656433 and batch: 1350, loss is 5.020773077011109 and perplexity is 151.52840164923595
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09583251953125 and perplexity of 163.33977158568666
Finished 36 epochs...
Completing Train Step...
At time: 1133.7562959194183 and batch: 50, loss is 5.1624703788757325 and perplexity is 174.59523967799655
At time: 1134.8339583873749 and batch: 100, loss is 5.17127031326294 and perplexity is 176.13844643190558
At time: 1135.9123232364655 and batch: 150, loss is 5.143913469314575 and perplexity is 171.38516822582028
At time: 1136.9902503490448 and batch: 200, loss is 5.138448553085327 and perplexity is 170.4511172184276
At time: 1138.0684897899628 and batch: 250, loss is 5.152370252609253 and perplexity is 172.84068125807036
At time: 1139.1532752513885 and batch: 300, loss is 5.153052282333374 and perplexity is 172.95860394904483
At time: 1140.23100066185 and batch: 350, loss is 5.1547616100311275 and perplexity is 173.25449970069593
At time: 1141.309636592865 and batch: 400, loss is 5.188879842758179 and perplexity is 179.2676324848423
At time: 1142.3939797878265 and batch: 450, loss is 5.149062395095825 and perplexity is 172.26989347473324
At time: 1143.4737448692322 and batch: 500, loss is 5.17491662979126 and perplexity is 176.781875320199
At time: 1144.5514492988586 and batch: 550, loss is 5.159035062789917 and perplexity is 173.99647889774482
At time: 1145.6555547714233 and batch: 600, loss is 5.119375104904175 and perplexity is 167.2308352341843
At time: 1146.7324895858765 and batch: 650, loss is 5.141550617218018 and perplexity is 170.98068847286174
At time: 1147.8100423812866 and batch: 700, loss is 5.141812429428101 and perplexity is 171.0254591652936
At time: 1148.8869998455048 and batch: 750, loss is 5.130297594070434 and perplexity is 169.06742402202823
At time: 1149.9681289196014 and batch: 800, loss is 5.098717088699341 and perplexity is 163.8116166624311
At time: 1151.0482604503632 and batch: 850, loss is 5.079452657699585 and perplexity is 160.68608156522984
At time: 1152.1321830749512 and batch: 900, loss is 5.10715497970581 and perplexity is 165.19968919614
At time: 1153.2116088867188 and batch: 950, loss is 5.080121526718139 and perplexity is 160.79359545924973
At time: 1154.294770002365 and batch: 1000, loss is 5.096992139816284 and perplexity is 163.52929356369756
At time: 1155.3720569610596 and batch: 1050, loss is 5.065346956253052 and perplexity is 158.43540269233398
At time: 1156.4501221179962 and batch: 1100, loss is 5.048262205123901 and perplexity is 155.75156489918638
At time: 1157.5279850959778 and batch: 1150, loss is 5.061813526153564 and perplexity is 157.8765701509222
At time: 1158.6106808185577 and batch: 1200, loss is 5.0482046508789065 and perplexity is 155.74260099341973
At time: 1159.6886956691742 and batch: 1250, loss is 5.0674933910369875 and perplexity is 158.7758391833383
At time: 1160.766723871231 and batch: 1300, loss is 5.0333183479309085 and perplexity is 153.4413405798007
At time: 1161.8446962833405 and batch: 1350, loss is 5.0207791423797605 and perplexity is 151.52932072764045
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095824788411458 and perplexity of 163.33850879122724
Finished 37 epochs...
Completing Train Step...
At time: 1165.049420118332 and batch: 50, loss is 5.162280883789062 and perplexity is 174.56215787244037
At time: 1166.1531965732574 and batch: 100, loss is 5.171037216186523 and perplexity is 176.09739385980083
At time: 1167.2327659130096 and batch: 150, loss is 5.143674564361572 and perplexity is 171.34422835082412
At time: 1168.3154089450836 and batch: 200, loss is 5.138221397399902 and perplexity is 170.41240267534513
At time: 1169.392602443695 and batch: 250, loss is 5.152145929336548 and perplexity is 172.80191341922085
At time: 1170.4783663749695 and batch: 300, loss is 5.1528616142272945 and perplexity is 172.92562940329665
At time: 1171.5568187236786 and batch: 350, loss is 5.154605550765991 and perplexity is 173.2274638404442
At time: 1172.6611018180847 and batch: 400, loss is 5.18874924659729 and perplexity is 179.2442223489383
At time: 1173.738438129425 and batch: 450, loss is 5.148923196792603 and perplexity is 172.24591546675293
At time: 1174.8160078525543 and batch: 500, loss is 5.174781465530396 and perplexity is 176.75798234346186
At time: 1175.8937923908234 and batch: 550, loss is 5.158934621810913 and perplexity is 173.979003398704
At time: 1176.97189950943 and batch: 600, loss is 5.1192825889587406 and perplexity is 167.21536443101587
At time: 1178.050117969513 and batch: 650, loss is 5.141422519683838 and perplexity is 170.95878767102528
At time: 1179.1287333965302 and batch: 700, loss is 5.141723175048828 and perplexity is 171.01019507529946
At time: 1180.208217382431 and batch: 750, loss is 5.130241603851318 and perplexity is 169.057958164912
At time: 1181.2902994155884 and batch: 800, loss is 5.098693809509277 and perplexity is 163.8078033050583
At time: 1182.384358882904 and batch: 850, loss is 5.079430599212646 and perplexity is 160.6825371124911
At time: 1183.4632465839386 and batch: 900, loss is 5.107129173278809 and perplexity is 165.19542603742877
At time: 1184.549379825592 and batch: 950, loss is 5.08009596824646 and perplexity is 160.78948587321153
At time: 1185.625988960266 and batch: 1000, loss is 5.09699857711792 and perplexity is 163.53034625447475
At time: 1186.703185558319 and batch: 1050, loss is 5.065353555679321 and perplexity is 158.43644827854266
At time: 1187.7799799442291 and batch: 1100, loss is 5.048307905197143 and perplexity is 155.7586829197556
At time: 1188.8679065704346 and batch: 1150, loss is 5.061880731582642 and perplexity is 157.8871806700988
At time: 1189.952784538269 and batch: 1200, loss is 5.048297510147095 and perplexity is 155.7570638088666
At time: 1191.029685974121 and batch: 1250, loss is 5.067574691772461 and perplexity is 158.78874830059257
At time: 1192.1114122867584 and batch: 1300, loss is 5.033341388702393 and perplexity is 153.44487602739486
At time: 1193.1878321170807 and batch: 1350, loss is 5.020780248641968 and perplexity is 151.52948835889396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095816243489583 and perplexity of 163.33711308239356
Finished 38 epochs...
Completing Train Step...
At time: 1196.3762674331665 and batch: 50, loss is 5.162094345092774 and perplexity is 174.52959831199288
At time: 1197.47935795784 and batch: 100, loss is 5.170809326171875 and perplexity is 176.05726759449584
At time: 1198.5556855201721 and batch: 150, loss is 5.143440885543823 and perplexity is 171.30419351194402
At time: 1199.6585235595703 and batch: 200, loss is 5.137998380661011 and perplexity is 170.37440209457415
At time: 1200.7415895462036 and batch: 250, loss is 5.15192720413208 and perplexity is 172.76412141855792
At time: 1201.8181328773499 and batch: 300, loss is 5.1526722240447995 and perplexity is 172.8928820878938
At time: 1202.8951833248138 and batch: 350, loss is 5.154451379776001 and perplexity is 173.2007592494399
At time: 1203.9716084003448 and batch: 400, loss is 5.188621463775635 and perplexity is 179.22131947976905
At time: 1205.0485825538635 and batch: 450, loss is 5.148787021636963 and perplexity is 172.22246144936943
At time: 1206.1253197193146 and batch: 500, loss is 5.1746478939056395 and perplexity is 176.73437406930447
At time: 1207.2020931243896 and batch: 550, loss is 5.158833866119385 and perplexity is 173.9614749069676
At time: 1208.278063774109 and batch: 600, loss is 5.119191980361938 and perplexity is 167.20021396787243
At time: 1209.3593380451202 and batch: 650, loss is 5.141296548843384 and perplexity is 170.9372532052452
At time: 1210.435919046402 and batch: 700, loss is 5.141633100509644 and perplexity is 170.99479210450048
At time: 1211.5123019218445 and batch: 750, loss is 5.130184841156006 and perplexity is 169.04836225189013
At time: 1212.5896744728088 and batch: 800, loss is 5.09866455078125 and perplexity is 163.80301056720774
At time: 1213.6707949638367 and batch: 850, loss is 5.079407453536987 and perplexity is 160.67881804964335
At time: 1214.7499177455902 and batch: 900, loss is 5.107101345062256 and perplexity is 165.19082900730342
At time: 1215.831699371338 and batch: 950, loss is 5.080065622329712 and perplexity is 160.78460664289196
At time: 1216.9089186191559 and batch: 1000, loss is 5.09700273513794 and perplexity is 163.531026218342
At time: 1217.9860320091248 and batch: 1050, loss is 5.065351333618164 and perplexity is 158.4360962234562
At time: 1219.0620503425598 and batch: 1100, loss is 5.048349523544312 and perplexity is 155.76516547359154
At time: 1220.138926744461 and batch: 1150, loss is 5.06193736076355 and perplexity is 157.89612194498216
At time: 1221.2159960269928 and batch: 1200, loss is 5.048380336761475 and perplexity is 155.7699651734084
At time: 1222.2959983348846 and batch: 1250, loss is 5.067651309967041 and perplexity is 158.80091487389146
At time: 1223.3740980625153 and batch: 1300, loss is 5.033360643386841 and perplexity is 153.44783058850737
At time: 1224.4600403308868 and batch: 1350, loss is 5.020779390335083 and perplexity is 151.5293583001466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095810139973958 and perplexity of 163.33611615481405
Finished 39 epochs...
Completing Train Step...
At time: 1227.6618835926056 and batch: 50, loss is 5.161909494400025 and perplexity is 174.49733937647483
At time: 1228.7381799221039 and batch: 100, loss is 5.170585021972657 and perplexity is 176.01778163866993
At time: 1229.8272125720978 and batch: 150, loss is 5.143209352493286 and perplexity is 171.26453552069538
At time: 1230.9045956134796 and batch: 200, loss is 5.13777907371521 and perplexity is 170.3370419016328
At time: 1231.984810590744 and batch: 250, loss is 5.151714324951172 and perplexity is 172.72734744824527
At time: 1233.066171169281 and batch: 300, loss is 5.152478971481323 and perplexity is 172.85947332349218
At time: 1234.14328789711 and batch: 350, loss is 5.1542950534820555 and perplexity is 173.17368553285993
At time: 1235.221116065979 and batch: 400, loss is 5.188496131896972 and perplexity is 179.1988587426548
At time: 1236.3038864135742 and batch: 450, loss is 5.1486548233032225 and perplexity is 172.1996954317811
At time: 1237.3807654380798 and batch: 500, loss is 5.174517040252685 and perplexity is 176.7112492438719
At time: 1238.4558656215668 and batch: 550, loss is 5.158732814788818 and perplexity is 173.94389675662364
At time: 1239.5343182086945 and batch: 600, loss is 5.119102935791016 and perplexity is 167.18532635940178
At time: 1240.6107261180878 and batch: 650, loss is 5.141171903610229 and perplexity is 170.91594801928719
At time: 1241.6875705718994 and batch: 700, loss is 5.141542768478393 and perplexity is 170.97934649522352
At time: 1242.7663321495056 and batch: 750, loss is 5.130126581192017 and perplexity is 169.0385137872813
At time: 1243.8476614952087 and batch: 800, loss is 5.098628311157227 and perplexity is 163.79707451525167
At time: 1244.9241213798523 and batch: 850, loss is 5.079391078948975 and perplexity is 160.6761870217365
At time: 1246.0004312992096 and batch: 900, loss is 5.1070751953125 and perplexity is 165.18650936494194
At time: 1247.077074766159 and batch: 950, loss is 5.080031232833862 and perplexity is 160.77907743640304
At time: 1248.155746936798 and batch: 1000, loss is 5.097004432678222 and perplexity is 163.53130381908207
At time: 1249.2326354980469 and batch: 1050, loss is 5.065346431732178 and perplexity is 158.43531958967992
At time: 1250.3092918395996 and batch: 1100, loss is 5.048388175964355 and perplexity is 155.77118629055437
At time: 1251.3853254318237 and batch: 1150, loss is 5.061989240646362 and perplexity is 157.90431378977925
At time: 1252.4613585472107 and batch: 1200, loss is 5.048458700180054 and perplexity is 155.7821723186819
At time: 1253.5447716712952 and batch: 1250, loss is 5.067724275588989 and perplexity is 158.81250230414804
At time: 1254.6208040714264 and batch: 1300, loss is 5.0333791351318355 and perplexity is 153.4506681328961
At time: 1255.6969468593597 and batch: 1350, loss is 5.020780544281006 and perplexity is 151.52953315693284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095806070963541 and perplexity of 163.33545153980816
Finished 40 epochs...
Completing Train Step...
At time: 1258.8903675079346 and batch: 50, loss is 5.161729793548584 and perplexity is 174.46598487331468
At time: 1259.966565132141 and batch: 100, loss is 5.170368490219116 and perplexity is 175.97967232584443
At time: 1261.043740272522 and batch: 150, loss is 5.142984256744385 and perplexity is 171.22598894031066
At time: 1262.1210916042328 and batch: 200, loss is 5.137566089630127 and perplexity is 170.30076668576658
At time: 1263.1982734203339 and batch: 250, loss is 5.151507053375244 and perplexity is 172.69154968879104
At time: 1264.2749726772308 and batch: 300, loss is 5.152296752929687 and perplexity is 172.82797799023078
At time: 1265.3516483306885 and batch: 350, loss is 5.154145088195801 and perplexity is 173.1477174387422
At time: 1266.4283080101013 and batch: 400, loss is 5.188371667861938 and perplexity is 179.17655631757592
At time: 1267.5047018527985 and batch: 450, loss is 5.148528146743774 and perplexity is 172.17788314840743
At time: 1268.5817549228668 and batch: 500, loss is 5.1743901920318605 and perplexity is 176.68883515792905
At time: 1269.6598873138428 and batch: 550, loss is 5.158634338378906 and perplexity is 173.92676822953675
At time: 1270.7380411624908 and batch: 600, loss is 5.1190181159973145 and perplexity is 167.17114633589188
At time: 1271.8150613307953 and batch: 650, loss is 5.141050615310669 and perplexity is 170.89521917169296
At time: 1272.8918573856354 and batch: 700, loss is 5.141455478668213 and perplexity is 170.9644223918938
At time: 1273.9701299667358 and batch: 750, loss is 5.1300718784332275 and perplexity is 169.0292671671456
At time: 1275.0473232269287 and batch: 800, loss is 5.098596553802491 and perplexity is 163.79187283604776
At time: 1276.1248376369476 and batch: 850, loss is 5.0793720149993895 and perplexity is 160.67312392820497
At time: 1277.2029027938843 and batch: 900, loss is 5.107047233581543 and perplexity is 165.18189052878495
At time: 1278.2852308750153 and batch: 950, loss is 5.079999809265137 and perplexity is 160.77402526339262
At time: 1279.3628206253052 and batch: 1000, loss is 5.097004461288452 and perplexity is 163.5313084977503
At time: 1280.4393980503082 and batch: 1050, loss is 5.065344066619873 and perplexity is 158.43494487279912
At time: 1281.54247713089 and batch: 1100, loss is 5.048421831130981 and perplexity is 155.7764288840042
At time: 1282.6195986270905 and batch: 1150, loss is 5.062043151855469 and perplexity is 157.91282683173097
At time: 1283.696558713913 and batch: 1200, loss is 5.048537988662719 and perplexity is 155.7945245404394
At time: 1284.7731912136078 and batch: 1250, loss is 5.067792062759399 and perplexity is 158.82326811919296
At time: 1285.8497488498688 and batch: 1300, loss is 5.0333970928192135 and perplexity is 153.45342377676482
At time: 1286.9267423152924 and batch: 1350, loss is 5.020783824920654 and perplexity is 151.53003027154259
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0958040364583335 and perplexity of 163.33511923331943
Finished 41 epochs...
Completing Train Step...
At time: 1290.0987360477448 and batch: 50, loss is 5.161554441452027 and perplexity is 174.43539457920363
At time: 1291.2019057273865 and batch: 100, loss is 5.170157051086425 and perplexity is 175.9424672699977
At time: 1292.280036687851 and batch: 150, loss is 5.142767286300659 and perplexity is 171.18884199155352
At time: 1293.3570914268494 and batch: 200, loss is 5.137357244491577 and perplexity is 170.26520391223835
At time: 1294.4346733093262 and batch: 250, loss is 5.1513035774230955 and perplexity is 172.65641468597536
At time: 1295.5123255252838 and batch: 300, loss is 5.152124042510986 and perplexity is 172.79813137527373
At time: 1296.589566230774 and batch: 350, loss is 5.154001922607422 and perplexity is 173.12293041826513
At time: 1297.6667926311493 and batch: 400, loss is 5.188248405456543 and perplexity is 179.1544719453681
At time: 1298.7448925971985 and batch: 450, loss is 5.148406057357788 and perplexity is 172.15686333954739
At time: 1299.8223373889923 and batch: 500, loss is 5.174266338348389 and perplexity is 176.66695294999042
At time: 1300.8992233276367 and batch: 550, loss is 5.158538646697998 and perplexity is 173.91012568101937
At time: 1301.9767985343933 and batch: 600, loss is 5.118936338424683 and perplexity is 167.1574760442997
At time: 1303.0533289909363 and batch: 650, loss is 5.140931339263916 and perplexity is 170.87483668113674
At time: 1304.1305527687073 and batch: 700, loss is 5.141370010375977 and perplexity is 170.94981097909394
At time: 1305.208622455597 and batch: 750, loss is 5.130018558502197 and perplexity is 169.02025477855022
At time: 1306.2854170799255 and batch: 800, loss is 5.098564720153808 and perplexity is 163.78665882610179
At time: 1307.3622951507568 and batch: 850, loss is 5.079349422454834 and perplexity is 160.66949395449916
At time: 1308.4647572040558 and batch: 900, loss is 5.107017030715943 and perplexity is 165.17690163768543
At time: 1309.542025089264 and batch: 950, loss is 5.079968614578247 and perplexity is 160.76901004623903
At time: 1310.6189754009247 and batch: 1000, loss is 5.097002744674683 and perplexity is 163.53102777789536
At time: 1311.6964511871338 and batch: 1050, loss is 5.06534031867981 and perplexity is 158.4343510692346
At time: 1312.7740664482117 and batch: 1100, loss is 5.048449907302857 and perplexity is 155.78080255119332
At time: 1313.8518450260162 and batch: 1150, loss is 5.062095994949341 and perplexity is 157.92117165454405
At time: 1314.9293718338013 and batch: 1200, loss is 5.0486156940460205 and perplexity is 155.80663108405074
At time: 1316.0072882175446 and batch: 1250, loss is 5.067855663299561 and perplexity is 158.8333696860647
At time: 1317.084491968155 and batch: 1300, loss is 5.0334140491485595 and perplexity is 153.456025805618
At time: 1318.1622354984283 and batch: 1350, loss is 5.0207859325408934 and perplexity is 151.5303496396378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095802001953125 and perplexity of 163.3347869275066
Finished 42 epochs...
Completing Train Step...
At time: 1321.3361852169037 and batch: 50, loss is 5.161381692886352 and perplexity is 174.4052637175937
At time: 1322.4466154575348 and batch: 100, loss is 5.16994909286499 and perplexity is 175.9058823916243
At time: 1323.5236368179321 and batch: 150, loss is 5.142556114196777 and perplexity is 171.15269550032872
At time: 1324.600891828537 and batch: 200, loss is 5.137151918411255 and perplexity is 170.23024761414646
At time: 1325.6779844760895 and batch: 250, loss is 5.151103219985962 and perplexity is 172.62182515447486
At time: 1326.762155532837 and batch: 300, loss is 5.151955442428589 and perplexity is 172.7690000519265
At time: 1327.8392610549927 and batch: 350, loss is 5.15386287689209 and perplexity is 173.09886009004154
At time: 1328.9176564216614 and batch: 400, loss is 5.188127098083496 and perplexity is 179.13274050512538
At time: 1329.9944672584534 and batch: 450, loss is 5.148287200927735 and perplexity is 172.13640260533063
At time: 1331.0715692043304 and batch: 500, loss is 5.174145517349243 and perplexity is 176.6456091616338
At time: 1332.156358242035 and batch: 550, loss is 5.158445272445679 and perplexity is 173.89388771117908
At time: 1333.2337877750397 and batch: 600, loss is 5.118857164382934 and perplexity is 167.1442420352147
At time: 1334.3133852481842 and batch: 650, loss is 5.140814247131348 and perplexity is 170.85482975345735
At time: 1335.390154838562 and batch: 700, loss is 5.141285171508789 and perplexity is 170.9353084059842
At time: 1336.4926264286041 and batch: 750, loss is 5.1299653816223145 and perplexity is 169.011267047736
At time: 1337.569592475891 and batch: 800, loss is 5.0985315322875975 and perplexity is 163.7812231865807
At time: 1338.6464960575104 and batch: 850, loss is 5.07932490348816 and perplexity is 160.66555455282645
At time: 1339.7232422828674 and batch: 900, loss is 5.106984739303589 and perplexity is 165.1715679283603
At time: 1340.800094127655 and batch: 950, loss is 5.0799361419677735 and perplexity is 160.76378954156175
At time: 1341.8770732879639 and batch: 1000, loss is 5.096998853683472 and perplexity is 163.53039148134147
At time: 1342.9533734321594 and batch: 1050, loss is 5.065334186553955 and perplexity is 158.433379532833
At time: 1344.0311851501465 and batch: 1100, loss is 5.048473043441772 and perplexity is 155.7844067591751
At time: 1345.108600139618 and batch: 1150, loss is 5.062146644592286 and perplexity is 157.92917050806957
At time: 1346.1859526634216 and batch: 1200, loss is 5.048690633773804 and perplexity is 155.81830762808406
At time: 1347.2633264064789 and batch: 1250, loss is 5.067916021347046 and perplexity is 158.84295684746274
At time: 1348.3397512435913 and batch: 1300, loss is 5.033430109024048 and perplexity is 153.45849031007512
At time: 1349.4169776439667 and batch: 1350, loss is 5.0207854175567626 and perplexity is 151.53027160393245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09579833984375 and perplexity of 163.3341887787474
Finished 43 epochs...
Completing Train Step...
At time: 1352.6144421100616 and batch: 50, loss is 5.161211013793945 and perplexity is 174.3754989256575
At time: 1353.6919405460358 and batch: 100, loss is 5.169743967056275 and perplexity is 175.8698032557483
At time: 1354.7694387435913 and batch: 150, loss is 5.142348918914795 and perplexity is 171.11723714285156
At time: 1355.846152305603 and batch: 200, loss is 5.136949605941773 and perplexity is 170.19581139592674
At time: 1356.922672510147 and batch: 250, loss is 5.15090579032898 and perplexity is 172.58774785079288
At time: 1358.000065088272 and batch: 300, loss is 5.151789531707764 and perplexity is 172.74033820031164
At time: 1359.0812983512878 and batch: 350, loss is 5.153727016448975 and perplexity is 173.0753443996692
At time: 1360.1621577739716 and batch: 400, loss is 5.188009014129639 and perplexity is 179.11158905170956
At time: 1361.2396657466888 and batch: 450, loss is 5.148170423507691 and perplexity is 172.11630213400213
At time: 1362.3161749839783 and batch: 500, loss is 5.174026556015015 and perplexity is 176.62459641415947
At time: 1363.4285850524902 and batch: 550, loss is 5.158353586196899 and perplexity is 173.87794476381478
At time: 1364.5064387321472 and batch: 600, loss is 5.118779954910278 and perplexity is 167.13133741461553
At time: 1365.5894360542297 and batch: 650, loss is 5.140699205398559 and perplexity is 170.83517544834152
At time: 1366.6664781570435 and batch: 700, loss is 5.1411998844146725 and perplexity is 170.9207304519128
At time: 1367.7438464164734 and batch: 750, loss is 5.129911403656006 and perplexity is 169.00214440947053
At time: 1368.8213250637054 and batch: 800, loss is 5.098497133255005 and perplexity is 163.7755893678458
At time: 1369.9023873806 and batch: 850, loss is 5.079299249649048 and perplexity is 160.66143291740727
At time: 1370.9834282398224 and batch: 900, loss is 5.10695050239563 and perplexity is 165.16591306139492
At time: 1372.060269355774 and batch: 950, loss is 5.079902067184448 and perplexity is 160.75831164359613
At time: 1373.1372904777527 and batch: 1000, loss is 5.096992826461792 and perplexity is 163.5294058503909
At time: 1374.2147488594055 and batch: 1050, loss is 5.065325660705566 and perplexity is 158.43202875961757
At time: 1375.292840719223 and batch: 1100, loss is 5.048491792678833 and perplexity is 155.7873276253297
At time: 1376.370445728302 and batch: 1150, loss is 5.062194890975952 and perplexity is 157.936790203232
At time: 1377.4476749897003 and batch: 1200, loss is 5.0487626266479495 and perplexity is 155.82952583970552
At time: 1378.5238816738129 and batch: 1250, loss is 5.067973222732544 and perplexity is 158.85204314454288
At time: 1379.6020379066467 and batch: 1300, loss is 5.033444862365723 and perplexity is 153.4607543523167
At time: 1380.6790282726288 and batch: 1350, loss is 5.020782098770142 and perplexity is 151.52976870812896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095796305338542 and perplexity of 163.33385647482774
Finished 44 epochs...
Completing Train Step...
At time: 1383.865650653839 and batch: 50, loss is 5.161042518615723 and perplexity is 174.34611997006408
At time: 1384.941620349884 and batch: 100, loss is 5.169541397094727 and perplexity is 175.83418092459428
At time: 1386.018581867218 and batch: 150, loss is 5.142145404815674 and perplexity is 171.0824159159158
At time: 1387.0943064689636 and batch: 200, loss is 5.13674898147583 and perplexity is 170.16166937713643
At time: 1388.1721484661102 and batch: 250, loss is 5.150711641311646 and perplexity is 172.55424336168082
At time: 1389.2508087158203 and batch: 300, loss is 5.151625890731811 and perplexity is 172.71207311550822
At time: 1390.3519270420074 and batch: 350, loss is 5.153593702316284 and perplexity is 173.05227254817657
At time: 1391.4288847446442 and batch: 400, loss is 5.187892665863037 and perplexity is 179.09075094105765
At time: 1392.5050485134125 and batch: 450, loss is 5.1480551528930665 and perplexity is 172.0964633255061
At time: 1393.5812544822693 and batch: 500, loss is 5.173909368515015 and perplexity is 176.60389943200468
At time: 1394.661378622055 and batch: 550, loss is 5.158263559341431 and perplexity is 173.86229178381726
At time: 1395.7437815666199 and batch: 600, loss is 5.11870397567749 and perplexity is 167.11863938622326
At time: 1396.8231308460236 and batch: 650, loss is 5.140587177276611 and perplexity is 170.8160381764497
At time: 1397.9069740772247 and batch: 700, loss is 5.141114692687989 and perplexity is 170.90617003998167
At time: 1398.9836466312408 and batch: 750, loss is 5.129855861663819 and perplexity is 168.99275795435966
At time: 1400.0604212284088 and batch: 800, loss is 5.098462362289428 and perplexity is 163.7698948314684
At time: 1401.1369352340698 and batch: 850, loss is 5.079272356033325 and perplexity is 160.6571122086689
At time: 1402.213662147522 and batch: 900, loss is 5.1069145774841305 and perplexity is 165.15997959716563
At time: 1403.291000843048 and batch: 950, loss is 5.079866514205933 and perplexity is 160.75259630839537
At time: 1404.3679659366608 and batch: 1000, loss is 5.09698447227478 and perplexity is 163.5280397008591
At time: 1405.4441468715668 and batch: 1050, loss is 5.065315504074096 and perplexity is 158.43041963206008
At time: 1406.5207378864288 and batch: 1100, loss is 5.048507137298584 and perplexity is 155.78971814097486
At time: 1407.5970311164856 and batch: 1150, loss is 5.0622403049469 and perplexity is 157.94396290290294
At time: 1408.673421382904 and batch: 1200, loss is 5.048831214904785 and perplexity is 155.84021428179307
At time: 1409.7503914833069 and batch: 1250, loss is 5.068027658462524 and perplexity is 158.86069060683366
At time: 1410.8279786109924 and batch: 1300, loss is 5.033457841873169 and perplexity is 153.46274621024708
At time: 1411.9042184352875 and batch: 1350, loss is 5.020775709152222 and perplexity is 151.52880049389663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095791422526042 and perplexity of 163.33305894817875
Finished 45 epochs...
Completing Train Step...
At time: 1415.0671248435974 and batch: 50, loss is 5.160875854492187 and perplexity is 174.31706514805288
At time: 1416.1699132919312 and batch: 100, loss is 5.1693405914306645 and perplexity is 175.79887596996497
At time: 1417.2473187446594 and batch: 150, loss is 5.14194432258606 and perplexity is 171.04801774082244
At time: 1418.3490061759949 and batch: 200, loss is 5.1365492725372315 and perplexity is 170.12768996386413
At time: 1419.425698518753 and batch: 250, loss is 5.150521154403687 and perplexity is 172.5213771677968
At time: 1420.502118587494 and batch: 300, loss is 5.151464223861694 and perplexity is 172.6841535521113
At time: 1421.582712173462 and batch: 350, loss is 5.153462963104248 and perplexity is 173.02964930932703
At time: 1422.6590449810028 and batch: 400, loss is 5.187777070999146 and perplexity is 179.07005016655305
At time: 1423.7353332042694 and batch: 450, loss is 5.147940416336059 and perplexity is 172.0767187025677
At time: 1424.8121316432953 and batch: 500, loss is 5.173793354034424 and perplexity is 176.58341201078346
At time: 1425.8887169361115 and batch: 550, loss is 5.158174772262573 and perplexity is 173.8468557440768
At time: 1426.9653446674347 and batch: 600, loss is 5.118628387451172 and perplexity is 167.1060076620982
At time: 1428.0415852069855 and batch: 650, loss is 5.140479335784912 and perplexity is 170.79761811332799
At time: 1429.1185870170593 and batch: 700, loss is 5.141030616760254 and perplexity is 170.89180154921056
At time: 1430.1948235034943 and batch: 750, loss is 5.129799098968506 and perplexity is 168.98316574217228
At time: 1431.2770025730133 and batch: 800, loss is 5.098427629470825 and perplexity is 163.7642067402008
At time: 1432.3535091876984 and batch: 850, loss is 5.079244947433471 and perplexity is 160.65270888251152
At time: 1433.4299747943878 and batch: 900, loss is 5.1068767738342284 and perplexity is 165.15373606513398
At time: 1434.505630493164 and batch: 950, loss is 5.079829330444336 and perplexity is 160.74661903330764
At time: 1435.582192659378 and batch: 1000, loss is 5.09697359085083 and perplexity is 163.5262602926126
At time: 1436.6591329574585 and batch: 1050, loss is 5.065304470062256 and perplexity is 158.42867151857837
At time: 1437.7362387180328 and batch: 1100, loss is 5.048520269393921 and perplexity is 155.79176399983925
At time: 1438.8130021095276 and batch: 1150, loss is 5.062282514572144 and perplexity is 157.95062979908923
At time: 1439.8897943496704 and batch: 1200, loss is 5.048896198272705 and perplexity is 155.85034163282552
At time: 1440.9659786224365 and batch: 1250, loss is 5.068079414367676 and perplexity is 158.8689127984407
At time: 1442.0422413349152 and batch: 1300, loss is 5.033468570709228 and perplexity is 153.46439269572485
At time: 1443.1188485622406 and batch: 1350, loss is 5.020767126083374 and perplexity is 151.52749991735107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095787353515625 and perplexity of 163.33239434561267
Finished 46 epochs...
Completing Train Step...
At time: 1446.285078048706 and batch: 50, loss is 5.160711584091186 and perplexity is 174.2884323656834
At time: 1447.3869466781616 and batch: 100, loss is 5.169141702651977 and perplexity is 175.763915023014
At time: 1448.463228225708 and batch: 150, loss is 5.1417460536956785 and perplexity is 171.01410760191698
At time: 1449.5403237342834 and batch: 200, loss is 5.136351327896119 and perplexity is 170.09401743208943
At time: 1450.6170024871826 and batch: 250, loss is 5.150333099365234 and perplexity is 172.48893670397158
At time: 1451.6941039562225 and batch: 300, loss is 5.151304521560669 and perplexity is 172.65657769746073
At time: 1452.7698981761932 and batch: 350, loss is 5.153334283828736 and perplexity is 173.00738541189355
At time: 1453.849142074585 and batch: 400, loss is 5.187663021087647 and perplexity is 179.04962840775147
At time: 1454.9252665042877 and batch: 450, loss is 5.147826309204102 and perplexity is 172.05708464193435
At time: 1456.0016040802002 and batch: 500, loss is 5.173678598403931 and perplexity is 176.5631492326597
At time: 1457.0775265693665 and batch: 550, loss is 5.158087072372436 and perplexity is 173.8316100624595
At time: 1458.154444694519 and batch: 600, loss is 5.118553295135498 and perplexity is 167.09345975615133
At time: 1459.2311577796936 and batch: 650, loss is 5.140375919342041 and perplexity is 170.77995574451737
At time: 1460.3075156211853 and batch: 700, loss is 5.140947923660279 and perplexity is 170.87767056065573
At time: 1461.38449883461 and batch: 750, loss is 5.129742736816406 and perplexity is 168.97364175568123
At time: 1462.460718870163 and batch: 800, loss is 5.098393402099609 and perplexity is 163.75860161782975
At time: 1463.5371205806732 and batch: 850, loss is 5.079217500686646 and perplexity is 160.6482995487952
At time: 1464.6131377220154 and batch: 900, loss is 5.106837902069092 and perplexity is 165.14731637266746
At time: 1465.6895496845245 and batch: 950, loss is 5.079790678024292 and perplexity is 160.740405907545
At time: 1466.7656321525574 and batch: 1000, loss is 5.096958980560303 and perplexity is 163.5238711438941
At time: 1467.8425974845886 and batch: 1050, loss is 5.065292692184448 and perplexity is 158.42680557603236
At time: 1468.919250011444 and batch: 1100, loss is 5.048531141281128 and perplexity is 155.79345775953232
At time: 1469.9952597618103 and batch: 1150, loss is 5.0623225975036625 and perplexity is 157.9569610502535
At time: 1471.0766999721527 and batch: 1200, loss is 5.04895938873291 and perplexity is 155.8601901988008
At time: 1472.1817994117737 and batch: 1250, loss is 5.068128824234009 and perplexity is 158.8767626841158
At time: 1473.2577052116394 and batch: 1300, loss is 5.033477621078491 and perplexity is 153.46578161143253
At time: 1474.3342468738556 and batch: 1350, loss is 5.020756492614746 and perplexity is 151.525888663001
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095784912109375 and perplexity of 163.33199558537095
Finished 47 epochs...
Completing Train Step...
At time: 1477.510088443756 and batch: 50, loss is 5.160548868179322 and perplexity is 174.2600751716295
At time: 1478.5871737003326 and batch: 100, loss is 5.168946075439453 and perplexity is 175.72953418127943
At time: 1479.6717031002045 and batch: 150, loss is 5.1415513896942135 and perplexity is 170.98082055142456
At time: 1480.7483298778534 and batch: 200, loss is 5.136156005859375 and perplexity is 170.0607975665582
At time: 1481.8247423171997 and batch: 250, loss is 5.150146894454956 and perplexity is 172.4568214070944
At time: 1482.9014451503754 and batch: 300, loss is 5.151146440505982 and perplexity is 172.62928612075706
At time: 1483.9784896373749 and batch: 350, loss is 5.153207912445068 and perplexity is 172.98552361059646
At time: 1485.0550546646118 and batch: 400, loss is 5.18755166053772 and perplexity is 179.02969045283913
At time: 1486.1320984363556 and batch: 450, loss is 5.147713747024536 and perplexity is 172.0377186114391
At time: 1487.209421634674 and batch: 500, loss is 5.173565301895142 and perplexity is 176.54314637741908
At time: 1488.2862784862518 and batch: 550, loss is 5.158000173568726 and perplexity is 173.81650495981526
At time: 1489.3631055355072 and batch: 600, loss is 5.118478384017944 and perplexity is 167.08094306717055
At time: 1490.440298318863 and batch: 650, loss is 5.140275249481201 and perplexity is 170.76276421548718
At time: 1491.5172836780548 and batch: 700, loss is 5.14086805343628 and perplexity is 170.86402306785303
At time: 1492.5947771072388 and batch: 750, loss is 5.129687852859497 and perplexity is 168.964368068099
At time: 1493.671583890915 and batch: 800, loss is 5.098359069824219 and perplexity is 163.75297950893187
At time: 1494.7488358020782 and batch: 850, loss is 5.0791890335083005 and perplexity is 160.64372641009356
At time: 1495.8257775306702 and batch: 900, loss is 5.106797370910645 and perplexity is 165.1406228962685
At time: 1496.9033205509186 and batch: 950, loss is 5.079749937057495 and perplexity is 160.73385732140383
At time: 1497.9801235198975 and batch: 1000, loss is 5.096939935684204 and perplexity is 163.52075688168435
At time: 1499.057410955429 and batch: 1050, loss is 5.065279417037964 and perplexity is 158.424702450941
At time: 1500.16073012352 and batch: 1100, loss is 5.048540124893188 and perplexity is 155.7948573538051
At time: 1501.2378387451172 and batch: 1150, loss is 5.062362260818482 and perplexity is 157.96322627117644
At time: 1502.3228068351746 and batch: 1200, loss is 5.049021263122558 and perplexity is 155.86983425129668
At time: 1503.3998672962189 and batch: 1250, loss is 5.068176107406616 and perplexity is 158.88427505911218
At time: 1504.4765319824219 and batch: 1300, loss is 5.033484888076782 and perplexity is 153.46689685105747
At time: 1505.5542664527893 and batch: 1350, loss is 5.020745000839233 and perplexity is 151.52414737150943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095779622395833 and perplexity of 163.3311316081872
Finished 48 epochs...
Completing Train Step...
At time: 1508.7417941093445 and batch: 50, loss is 5.160387735366822 and perplexity is 174.23199841771455
At time: 1509.818365573883 and batch: 100, loss is 5.168754529953003 and perplexity is 175.69587720569487
At time: 1510.8952684402466 and batch: 150, loss is 5.141359643936157 and perplexity is 170.94803884735163
At time: 1511.9720361232758 and batch: 200, loss is 5.135963401794434 and perplexity is 170.02804631977259
At time: 1513.0493121147156 and batch: 250, loss is 5.149960975646973 and perplexity is 172.42476142079946
At time: 1514.1305992603302 and batch: 300, loss is 5.1509903526306156 and perplexity is 172.6023428850714
At time: 1515.2079272270203 and batch: 350, loss is 5.153082609176636 and perplexity is 172.96384931705484
At time: 1516.2848029136658 and batch: 400, loss is 5.18744197845459 and perplexity is 179.01005518028668
At time: 1517.361492395401 and batch: 450, loss is 5.147602519989014 and perplexity is 172.01858443013876
At time: 1518.4379060268402 and batch: 500, loss is 5.17345235824585 and perplexity is 176.5232080761832
At time: 1519.5149767398834 and batch: 550, loss is 5.157913627624512 and perplexity is 173.801462497215
At time: 1520.5984344482422 and batch: 600, loss is 5.1184031105041505 and perplexity is 167.06836677083487
At time: 1521.6759498119354 and batch: 650, loss is 5.14017617225647 and perplexity is 170.74584635282255
At time: 1522.7534625530243 and batch: 700, loss is 5.140791921615601 and perplexity is 170.85101537384438
At time: 1523.8300540447235 and batch: 750, loss is 5.129633741378784 and perplexity is 168.95522540331888
At time: 1524.9070844650269 and batch: 800, loss is 5.09832459449768 and perplexity is 163.74733416880468
At time: 1525.984421491623 and batch: 850, loss is 5.079158945083618 and perplexity is 160.63889296614647
At time: 1527.0881354808807 and batch: 900, loss is 5.1067548274993895 and perplexity is 165.13359740027903
At time: 1528.171647310257 and batch: 950, loss is 5.079706907272339 and perplexity is 160.72694112685818
At time: 1529.250149011612 and batch: 1000, loss is 5.096918210983277 and perplexity is 163.51720448073328
At time: 1530.327728509903 and batch: 1050, loss is 5.065264692306519 and perplexity is 158.42236970691772
At time: 1531.4156739711761 and batch: 1100, loss is 5.048547649383545 and perplexity is 155.79602963511732
At time: 1532.495548248291 and batch: 1150, loss is 5.062401828765869 and perplexity is 157.96947667545965
At time: 1533.5728800296783 and batch: 1200, loss is 5.049081468582154 and perplexity is 155.87921874880104
At time: 1534.6566669940948 and batch: 1250, loss is 5.068220520019532 and perplexity is 158.89133168161908
At time: 1535.7340853214264 and batch: 1300, loss is 5.033490390777588 and perplexity is 153.46774133579783
At time: 1536.8122642040253 and batch: 1350, loss is 5.0207319164276125 and perplexity is 151.52216478016527
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095777180989583 and perplexity of 163.3307328510285
Finished 49 epochs...
Completing Train Step...
At time: 1539.9826776981354 and batch: 50, loss is 5.160227298736572 and perplexity is 174.20404746524505
At time: 1541.0836782455444 and batch: 100, loss is 5.168567352294922 and perplexity is 175.66299394046723
At time: 1542.160486459732 and batch: 150, loss is 5.141170063018799 and perplexity is 170.91563343314746
At time: 1543.2370789051056 and batch: 200, loss is 5.135772542953491 and perplexity is 169.9955980605414
At time: 1544.3132710456848 and batch: 250, loss is 5.1497749328613285 and perplexity is 172.39268602166146
At time: 1545.3895902633667 and batch: 300, loss is 5.150835571289062 and perplexity is 172.57562933031764
At time: 1546.46559882164 and batch: 350, loss is 5.15295823097229 and perplexity is 172.9423377218746
At time: 1547.5419170856476 and batch: 400, loss is 5.187333068847656 and perplexity is 178.99056032714748
At time: 1548.618569135666 and batch: 450, loss is 5.147492589950562 and perplexity is 171.99967545988892
At time: 1549.6949210166931 and batch: 500, loss is 5.173339710235596 and perplexity is 176.5033242079899
At time: 1550.7712571620941 and batch: 550, loss is 5.157827138900757 and perplexity is 173.78643128056157
At time: 1551.8480064868927 and batch: 600, loss is 5.118326959609985 and perplexity is 167.05564484971748
At time: 1552.9244558811188 and batch: 650, loss is 5.140078039169311 and perplexity is 170.72909135792358
At time: 1554.0259311199188 and batch: 700, loss is 5.140719394683838 and perplexity is 170.8386245232514
At time: 1555.1021237373352 and batch: 750, loss is 5.129579792022705 and perplexity is 168.9461106235726
At time: 1556.1779947280884 and batch: 800, loss is 5.0982890224456785 and perplexity is 163.7415094437178
At time: 1557.2543411254883 and batch: 850, loss is 5.079126749038696 and perplexity is 160.63372111238945
At time: 1558.330538034439 and batch: 900, loss is 5.106710758209228 and perplexity is 165.12632024021067
At time: 1559.4064872264862 and batch: 950, loss is 5.079661455154419 and perplexity is 160.71963591299715
At time: 1560.4826259613037 and batch: 1000, loss is 5.096894807815552 and perplexity is 163.51337770495047
At time: 1561.5621325969696 and batch: 1050, loss is 5.065248355865479 and perplexity is 158.41978167035532
At time: 1562.6455686092377 and batch: 1100, loss is 5.0485540294647215 and perplexity is 155.7970236296042
At time: 1563.7264013290405 and batch: 1150, loss is 5.062441635131836 and perplexity is 157.97576499141647
At time: 1564.8064212799072 and batch: 1200, loss is 5.049139280319213 and perplexity is 155.88823065770296
At time: 1565.884167432785 and batch: 1250, loss is 5.068261327743531 and perplexity is 158.89781580752847
At time: 1566.9706270694733 and batch: 1300, loss is 5.033494234085083 and perplexity is 153.46833116065184
At time: 1568.0488123893738 and batch: 1350, loss is 5.020717315673828 and perplexity is 151.51995245849523
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.095774739583334 and perplexity of 163.33033409484332
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
SETTINGS FOR THIS RUN
{'dropout': 0.5449135763513986, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 5.7852021323182194, 'wordvec_dim': 200, 'lr': 28.288861634932207, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5823726654052734 and batch: 50, loss is 7.106727228164673 and perplexity is 1220.147739278319
At time: 2.6557233333587646 and batch: 100, loss is 6.514035482406616 and perplexity is 674.5430390318901
At time: 3.729889154434204 and batch: 150, loss is 6.357241144180298 and perplexity is 576.6532566448861
At time: 4.805246591567993 and batch: 200, loss is 6.31613865852356 and perplexity is 553.4318718716447
At time: 5.886830806732178 and batch: 250, loss is 6.310949983596802 and perplexity is 550.56773076874
At time: 6.9679577350616455 and batch: 300, loss is 6.308110132217407 and perplexity is 549.0064182361409
At time: 8.075682163238525 and batch: 350, loss is 6.290389175415039 and perplexity is 539.363195139965
At time: 9.158745765686035 and batch: 400, loss is 6.323698453903198 and perplexity is 557.6315579621529
At time: 10.240164995193481 and batch: 450, loss is 6.280822877883911 and perplexity is 534.2280874829148
At time: 11.326632499694824 and batch: 500, loss is 6.267591676712036 and perplexity is 527.2061648617594
At time: 12.416218042373657 and batch: 550, loss is 6.237054986953735 and perplexity is 511.35035779259636
At time: 13.504196882247925 and batch: 600, loss is 6.183458452224731 and perplexity is 484.66525279882666
At time: 14.588429689407349 and batch: 650, loss is 6.216869440078735 and perplexity is 501.13195020898416
At time: 15.671306848526001 and batch: 700, loss is 6.242971286773682 and perplexity is 514.3846267943042
At time: 16.755213737487793 and batch: 750, loss is 6.2057195568084715 and perplexity is 495.57542234515097
At time: 17.838460445404053 and batch: 800, loss is 6.165718936920166 and perplexity is 476.14333693689565
At time: 18.92215847969055 and batch: 850, loss is 6.1840964126586915 and perplexity is 484.97454870261197
At time: 20.005695343017578 and batch: 900, loss is 6.214552936553955 and perplexity is 499.9724198265754
At time: 21.089244842529297 and batch: 950, loss is 6.179434232711792 and perplexity is 482.71877258991884
At time: 22.172733545303345 and batch: 1000, loss is 6.190018424987793 and perplexity is 487.8550948557996
At time: 23.261662244796753 and batch: 1050, loss is 6.182057962417603 and perplexity is 483.9869591349593
At time: 24.34641456604004 and batch: 1100, loss is 6.176410894393921 and perplexity is 481.2615543698177
At time: 25.431098222732544 and batch: 1150, loss is 6.181671285629273 and perplexity is 483.7998487899524
At time: 26.516728162765503 and batch: 1200, loss is 6.157711868286133 and perplexity is 472.34604742526926
At time: 27.600427627563477 and batch: 1250, loss is 6.155725841522217 and perplexity is 471.40888645467476
At time: 28.684213638305664 and batch: 1300, loss is 6.129037380218506 and perplexity is 458.9941111402806
At time: 29.76826024055481 and batch: 1350, loss is 6.140565271377564 and perplexity is 464.3159612144311
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.580264485677083 and perplexity of 265.1417227014099
Finished 1 epochs...
Completing Train Step...
At time: 33.01777458190918 and batch: 50, loss is 5.995473051071167 and perplexity is 401.60661950432245
At time: 34.09408402442932 and batch: 100, loss is 6.10733341217041 and perplexity is 449.13944711798985
At time: 35.17105984687805 and batch: 150, loss is 6.0358857250213624 and perplexity is 418.16902842974196
At time: 36.24714016914368 and batch: 200, loss is 5.979297780990601 and perplexity is 395.16277988700773
At time: 37.32400155067444 and batch: 250, loss is 5.990784530639648 and perplexity is 399.7280858761859
At time: 38.400431871414185 and batch: 300, loss is 5.982834539413452 and perplexity is 396.5628495718796
At time: 39.47741770744324 and batch: 350, loss is 5.95898663520813 and perplexity is 387.2175327377066
At time: 40.55615568161011 and batch: 400, loss is 5.977415971755981 and perplexity is 394.41985815636156
At time: 41.675681591033936 and batch: 450, loss is 5.975995635986328 and perplexity is 393.86004717745067
At time: 42.75221848487854 and batch: 500, loss is 5.9481540870666505 and perplexity is 383.04561720674224
At time: 43.828842639923096 and batch: 550, loss is 5.894486331939698 and perplexity is 363.03031092139753
At time: 44.906012296676636 and batch: 600, loss is 5.897160739898681 and perplexity is 364.00250151194194
At time: 45.98231053352356 and batch: 650, loss is 5.972474184036255 and perplexity is 392.4755271374016
At time: 47.05924153327942 and batch: 700, loss is 5.93302206993103 and perplexity is 377.29299849406056
At time: 48.136106967926025 and batch: 750, loss is 5.904264612197876 and perplexity is 366.59753528033207
At time: 49.212183713912964 and batch: 800, loss is 5.834325952529907 and perplexity is 341.8342438710673
At time: 50.28793525695801 and batch: 850, loss is 5.857573652267456 and perplexity is 349.87419683901146
At time: 51.36248064041138 and batch: 900, loss is 5.868945579528809 and perplexity is 353.87564974933224
At time: 52.43714189529419 and batch: 950, loss is 5.897298183441162 and perplexity is 364.0525347435151
At time: 53.51148223876953 and batch: 1000, loss is 5.895350532531738 and perplexity is 363.3441775333464
At time: 54.58669376373291 and batch: 1050, loss is 5.857519493103028 and perplexity is 349.85524845797437
At time: 55.661741971969604 and batch: 1100, loss is 5.869063901901245 and perplexity is 353.9175236330177
At time: 56.73681712150574 and batch: 1150, loss is 5.9380042934417725 and perplexity is 379.17744701539334
At time: 57.811108350753784 and batch: 1200, loss is 5.925345506668091 and perplexity is 374.40777339770193
At time: 58.88580083847046 and batch: 1250, loss is 5.918781385421753 and perplexity is 371.9581639399526
At time: 59.96088171005249 and batch: 1300, loss is 5.87324215888977 and perplexity is 355.39937562288895
At time: 61.03589987754822 and batch: 1350, loss is 5.849180660247803 and perplexity is 346.9499940679339
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.672323811848958 and perplexity of 290.70930379427585
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 64.21663022041321 and batch: 50, loss is 5.85917552947998 and perplexity is 350.4351014724127
At time: 65.31834053993225 and batch: 100, loss is 5.843901948928833 and perplexity is 345.1233705577689
At time: 66.39321517944336 and batch: 150, loss is 5.776416749954223 and perplexity is 322.60115628535306
At time: 67.50386905670166 and batch: 200, loss is 5.760579271316528 and perplexity is 317.53221295637337
At time: 68.57954049110413 and batch: 250, loss is 5.777639122009277 and perplexity is 322.99573603622326
At time: 69.65688037872314 and batch: 300, loss is 5.780554265975952 and perplexity is 323.93868886123755
At time: 70.73585534095764 and batch: 350, loss is 5.772762870788574 and perplexity is 321.42456151818374
At time: 71.81046509742737 and batch: 400, loss is 5.798955821990967 and perplexity is 329.95484837422026
At time: 72.8921492099762 and batch: 450, loss is 5.775681562423706 and perplexity is 322.36407109963653
At time: 73.96739864349365 and batch: 500, loss is 5.782269983291626 and perplexity is 324.4949531386044
At time: 75.04643487930298 and batch: 550, loss is 5.75436074256897 and perplexity is 315.56375655654676
At time: 76.12446761131287 and batch: 600, loss is 5.697489805221558 and perplexity is 298.11812638371595
At time: 77.19891571998596 and batch: 650, loss is 5.727911043167114 and perplexity is 307.3266053512761
At time: 78.28307008743286 and batch: 700, loss is 5.735891704559326 and perplexity is 309.7890879755982
At time: 79.35732817649841 and batch: 750, loss is 5.708437833786011 and perplexity is 301.39986364474663
At time: 80.43263339996338 and batch: 800, loss is 5.658369741439819 and perplexity is 286.680897399851
At time: 81.51036071777344 and batch: 850, loss is 5.658807859420777 and perplexity is 286.8065249736389
At time: 82.58803224563599 and batch: 900, loss is 5.680322914123535 and perplexity is 293.044042706034
At time: 83.671541929245 and batch: 950, loss is 5.647136993408203 and perplexity is 283.4787015132376
At time: 84.74838757514954 and batch: 1000, loss is 5.678148956298828 and perplexity is 292.40766929152124
At time: 85.83057355880737 and batch: 1050, loss is 5.635790510177612 and perplexity is 280.28039426322454
At time: 86.90727519989014 and batch: 1100, loss is 5.604284563064575 and perplexity is 271.58755214567833
At time: 87.98323011398315 and batch: 1150, loss is 5.604994382858276 and perplexity is 271.7803988010036
At time: 89.05977249145508 and batch: 1200, loss is 5.577272024154663 and perplexity is 264.3494822639484
At time: 90.1370460987091 and batch: 1250, loss is 5.580671920776367 and perplexity is 265.24977275572064
At time: 91.21194458007812 and batch: 1300, loss is 5.5755218887329105 and perplexity is 263.887239483035
At time: 92.28914403915405 and batch: 1350, loss is 5.517322883605957 and perplexity is 248.96762890254624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4100944010416665 and perplexity of 223.65269973185673
Finished 3 epochs...
Completing Train Step...
At time: 95.51800394058228 and batch: 50, loss is 5.664637632369995 and perplexity is 288.48342511884886
At time: 96.59421563148499 and batch: 100, loss is 5.687916488647461 and perplexity is 295.2777647169265
At time: 97.67038631439209 and batch: 150, loss is 5.627988739013672 and perplexity is 278.10221862773045
At time: 98.74633288383484 and batch: 200, loss is 5.618614616394043 and perplexity is 275.5074352395259
At time: 99.82453680038452 and batch: 250, loss is 5.64091908454895 and perplexity is 281.7215254254526
At time: 100.9009997844696 and batch: 300, loss is 5.647224950790405 and perplexity is 283.5036366543314
At time: 101.97805523872375 and batch: 350, loss is 5.640375957489014 and perplexity is 281.5685563862001
At time: 103.05525040626526 and batch: 400, loss is 5.668280572891235 and perplexity is 289.5362696385426
At time: 104.13180923461914 and batch: 450, loss is 5.644953937530517 and perplexity is 282.86052666831927
At time: 105.20851278305054 and batch: 500, loss is 5.657112169265747 and perplexity is 286.3206020766129
At time: 106.28509211540222 and batch: 550, loss is 5.634535074234009 and perplexity is 279.9287409672601
At time: 107.36224317550659 and batch: 600, loss is 5.578834400177002 and perplexity is 264.76281836568256
At time: 108.43803977966309 and batch: 650, loss is 5.618136615753174 and perplexity is 275.3757739785074
At time: 109.51424312591553 and batch: 700, loss is 5.634968748092652 and perplexity is 280.0501650718274
At time: 110.59300136566162 and batch: 750, loss is 5.611163263320923 and perplexity is 273.4621615567018
At time: 111.67369365692139 and batch: 800, loss is 5.5891380119323735 and perplexity is 267.5049342425209
At time: 112.7516930103302 and batch: 850, loss is 5.564205884933472 and perplexity is 260.9179225646853
At time: 113.83544254302979 and batch: 900, loss is 5.582765474319458 and perplexity is 265.80566905356983
At time: 114.91359496116638 and batch: 950, loss is 5.558066997528076 and perplexity is 259.32108323928514
At time: 115.99424839019775 and batch: 1000, loss is 5.586625423431396 and perplexity is 266.83364810685924
At time: 117.07121586799622 and batch: 1050, loss is 5.543889589309693 and perplexity is 255.67052128248685
At time: 118.15217685699463 and batch: 1100, loss is 5.524203243255616 and perplexity is 250.68652225180392
At time: 119.2279543876648 and batch: 1150, loss is 5.526698226928711 and perplexity is 251.31276193592205
At time: 120.30472087860107 and batch: 1200, loss is 5.505421257019043 and perplexity is 246.02207237748726
At time: 121.3817777633667 and batch: 1250, loss is 5.5217658805847165 and perplexity is 250.07625230708214
At time: 122.45716428756714 and batch: 1300, loss is 5.507195043563843 and perplexity is 246.4588502800574
At time: 123.53303718566895 and batch: 1350, loss is 5.4628333568573 and perplexity is 235.76448382718996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.370840657552083 and perplexity of 215.04356974035704
Finished 4 epochs...
Completing Train Step...
At time: 126.81036186218262 and batch: 50, loss is 5.579754247665405 and perplexity is 265.0064718240095
At time: 127.88697409629822 and batch: 100, loss is 5.604210023880005 and perplexity is 271.5673089854656
At time: 128.96300745010376 and batch: 150, loss is 5.552310400009155 and perplexity is 257.8325646467176
At time: 130.0408535003662 and batch: 200, loss is 5.5413159656524655 and perplexity is 255.01336757634445
At time: 131.1177327632904 and batch: 250, loss is 5.557971429824829 and perplexity is 259.29630170313254
At time: 132.19510293006897 and batch: 300, loss is 5.566236305236816 and perplexity is 261.4482338073355
At time: 133.272625207901 and batch: 350, loss is 5.566144676208496 and perplexity is 261.42427865722595
At time: 134.34994840621948 and batch: 400, loss is 5.593351898193359 and perplexity is 268.63454797002447
At time: 135.42567777633667 and batch: 450, loss is 5.582968835830688 and perplexity is 265.8597291928117
At time: 136.50799584388733 and batch: 500, loss is 5.604114227294922 and perplexity is 271.54129501068945
At time: 137.5886127948761 and batch: 550, loss is 5.584106359481812 and perplexity is 266.16232299382375
At time: 138.66888308525085 and batch: 600, loss is 5.52476170539856 and perplexity is 250.82656028355794
At time: 139.74771904945374 and batch: 650, loss is 5.559697227478027 and perplexity is 259.744181015465
At time: 140.83198952674866 and batch: 700, loss is 5.5729501438140865 and perplexity is 263.2094607263506
At time: 141.91014552116394 and batch: 750, loss is 5.548956823348999 and perplexity is 256.9693516102448
At time: 142.98866963386536 and batch: 800, loss is 5.5255007076263425 and perplexity is 251.0119901785083
At time: 144.07374906539917 and batch: 850, loss is 5.509151468276977 and perplexity is 246.941500445923
At time: 145.15634274482727 and batch: 900, loss is 5.534728956222534 and perplexity is 253.33911234051502
At time: 146.23709654808044 and batch: 950, loss is 5.507188243865967 and perplexity is 246.45717444003427
At time: 147.31506824493408 and batch: 1000, loss is 5.543120651245117 and perplexity is 255.47400205192426
At time: 148.39281177520752 and batch: 1050, loss is 5.498935708999634 and perplexity is 244.43164737684995
At time: 149.5034520626068 and batch: 1100, loss is 5.488896789550782 and perplexity is 241.99009354414076
At time: 150.5834846496582 and batch: 1150, loss is 5.499240674972534 and perplexity is 244.50620207974586
At time: 151.66219353675842 and batch: 1200, loss is 5.468698635101318 and perplexity is 237.15137138970326
At time: 152.74741077423096 and batch: 1250, loss is 5.4814157390594485 and perplexity is 240.186508204063
At time: 153.82595992088318 and batch: 1300, loss is 5.463210983276367 and perplexity is 235.85353153728659
At time: 154.90291738510132 and batch: 1350, loss is 5.440672788619995 and perplexity is 230.59727450513608
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.372519124348958 and perplexity of 215.40481631743006
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 158.116281747818 and batch: 50, loss is 5.53213604927063 and perplexity is 252.68307847986895
At time: 159.22619128227234 and batch: 100, loss is 5.545338525772094 and perplexity is 256.0412401323059
At time: 160.30587196350098 and batch: 150, loss is 5.503260068893432 and perplexity is 245.49094653418882
At time: 161.38413643836975 and batch: 200, loss is 5.497860231399536 and perplexity is 244.16890792586318
At time: 162.4679777622223 and batch: 250, loss is 5.515928068161011 and perplexity is 248.62060708042105
At time: 163.55401492118835 and batch: 300, loss is 5.527610569000244 and perplexity is 251.54214976592218
At time: 164.6321976184845 and batch: 350, loss is 5.516402378082275 and perplexity is 248.73855827148884
At time: 165.72187519073486 and batch: 400, loss is 5.528610248565673 and perplexity is 251.7937370452661
At time: 166.80070233345032 and batch: 450, loss is 5.501715049743653 and perplexity is 245.111951173632
At time: 167.8791720867157 and batch: 500, loss is 5.522973947525024 and perplexity is 250.3785437174156
At time: 168.95863556861877 and batch: 550, loss is 5.497968549728394 and perplexity is 244.19535732638025
At time: 170.04572010040283 and batch: 600, loss is 5.442336196899414 and perplexity is 230.98117112064588
At time: 171.13174843788147 and batch: 650, loss is 5.472203893661499 and perplexity is 237.98410688830276
At time: 172.21107482910156 and batch: 700, loss is 5.476856851577759 and perplexity is 239.09401710268807
At time: 173.28952765464783 and batch: 750, loss is 5.449483728408813 and perplexity is 232.6380304929064
At time: 174.36812567710876 and batch: 800, loss is 5.429328308105469 and perplexity is 227.9960508806356
At time: 175.45637321472168 and batch: 850, loss is 5.390370302200317 and perplexity is 219.28457208078916
At time: 176.58346819877625 and batch: 900, loss is 5.415099544525146 and perplexity is 224.77491967763683
At time: 177.6654772758484 and batch: 950, loss is 5.3836118030548095 and perplexity is 217.80753438900192
At time: 178.74757599830627 and batch: 1000, loss is 5.408002195358276 and perplexity is 223.18526144140682
At time: 179.83270382881165 and batch: 1050, loss is 5.360113506317139 and perplexity is 212.74909344517408
At time: 180.91169428825378 and batch: 1100, loss is 5.3477439689636235 and perplexity is 210.13369457134897
At time: 181.99010467529297 and batch: 1150, loss is 5.351697597503662 and perplexity is 210.96612962860195
At time: 183.06787371635437 and batch: 1200, loss is 5.313585090637207 and perplexity is 203.07697424386242
At time: 184.1464147567749 and batch: 1250, loss is 5.325357933044433 and perplexity is 205.48189606422173
At time: 185.23001217842102 and batch: 1300, loss is 5.309825143814087 and perplexity is 202.31484929221
At time: 186.31086468696594 and batch: 1350, loss is 5.29685809135437 and perplexity is 199.70835780613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.270940755208334 and perplexity of 194.59894633267362
Finished 6 epochs...
Completing Train Step...
At time: 189.56195187568665 and batch: 50, loss is 5.4692493915557865 and perplexity is 237.28202001266587
At time: 190.67367458343506 and batch: 100, loss is 5.486310043334961 and perplexity is 241.36493549659727
At time: 191.75803923606873 and batch: 150, loss is 5.449917593002319 and perplexity is 232.7389857963225
At time: 192.83652329444885 and batch: 200, loss is 5.446161632537842 and perplexity is 231.86646696598027
At time: 193.920512676239 and batch: 250, loss is 5.464545812606811 and perplexity is 236.1685659606891
At time: 194.99894165992737 and batch: 300, loss is 5.479690332412719 and perplexity is 239.77244612181033
At time: 196.08257484436035 and batch: 350, loss is 5.471355876922607 and perplexity is 237.78237792892762
At time: 197.16066098213196 and batch: 400, loss is 5.486627521514893 and perplexity is 241.4415757621804
At time: 198.2400894165039 and batch: 450, loss is 5.462171115875244 and perplexity is 235.60840261127953
At time: 199.3193347454071 and batch: 500, loss is 5.485434846878052 and perplexity is 241.15378617227663
At time: 200.40116357803345 and batch: 550, loss is 5.464746170043945 and perplexity is 236.2158888298826
At time: 201.479966878891 and batch: 600, loss is 5.4110575199127195 and perplexity is 223.86820763073385
At time: 202.55785369873047 and batch: 650, loss is 5.4402280616760255 and perplexity is 230.4947444845789
At time: 203.63618636131287 and batch: 700, loss is 5.449436912536621 and perplexity is 232.6271395955392
At time: 204.74227166175842 and batch: 750, loss is 5.423273048400879 and perplexity is 226.61964702794452
At time: 205.82017302513123 and batch: 800, loss is 5.402207469940185 and perplexity is 221.89570405794808
At time: 206.89887619018555 and batch: 850, loss is 5.368213520050049 and perplexity is 214.47936216366904
At time: 207.9771363735199 and batch: 900, loss is 5.39695912361145 and perplexity is 220.73416928878265
At time: 209.05602884292603 and batch: 950, loss is 5.3676347732543945 and perplexity is 214.3552688328553
At time: 210.13439059257507 and batch: 1000, loss is 5.396267948150634 and perplexity is 220.58165596041337
At time: 211.21344780921936 and batch: 1050, loss is 5.353680791854859 and perplexity is 211.3849316107734
At time: 212.29180192947388 and batch: 1100, loss is 5.345028963088989 and perplexity is 209.56395413042642
At time: 213.37007975578308 and batch: 1150, loss is 5.350844202041626 and perplexity is 210.7861688906939
At time: 214.44814491271973 and batch: 1200, loss is 5.31699158668518 and perplexity is 203.76993476759617
At time: 215.52586364746094 and batch: 1250, loss is 5.334389944076538 and perplexity is 207.34621742810506
At time: 216.6023166179657 and batch: 1300, loss is 5.317936697006226 and perplexity is 203.96261087180906
At time: 217.68420362472534 and batch: 1350, loss is 5.2992112255096435 and perplexity is 200.17885171451698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2651375325520835 and perplexity of 193.47291578158234
Finished 7 epochs...
Completing Train Step...
At time: 220.8907458782196 and batch: 50, loss is 5.450980710983276 and perplexity is 232.98654636672262
At time: 221.9708800315857 and batch: 100, loss is 5.466024684906006 and perplexity is 236.51808749598493
At time: 223.0503215789795 and batch: 150, loss is 5.429394731521606 and perplexity is 228.0111956601793
At time: 224.12639570236206 and batch: 200, loss is 5.4247556400299075 and perplexity is 226.95588060655714
At time: 225.20275259017944 and batch: 250, loss is 5.4435474395751955 and perplexity is 231.2611148780964
At time: 226.27958393096924 and batch: 300, loss is 5.460269279479981 and perplexity is 235.16073980180778
At time: 227.35642337799072 and batch: 350, loss is 5.4526682472229 and perplexity is 233.3800515407975
At time: 228.4334363937378 and batch: 400, loss is 5.46873363494873 and perplexity is 237.15967179677114
At time: 229.5101146697998 and batch: 450, loss is 5.444861497879028 and perplexity is 231.565205218917
At time: 230.58713746070862 and batch: 500, loss is 5.469003219604492 and perplexity is 237.22361502392215
At time: 231.7068600654602 and batch: 550, loss is 5.449144382476806 and perplexity is 232.55909911690665
At time: 232.78245973587036 and batch: 600, loss is 5.395601921081543 and perplexity is 220.4347915198741
At time: 233.85828137397766 and batch: 650, loss is 5.425855102539063 and perplexity is 227.205547312958
At time: 234.93435382843018 and batch: 700, loss is 5.437123365402222 and perplexity is 229.7802380469191
At time: 236.0112018585205 and batch: 750, loss is 5.410858182907105 and perplexity is 223.82358686000555
At time: 237.087744474411 and batch: 800, loss is 5.390388240814209 and perplexity is 219.28850577734264
At time: 238.1642529964447 and batch: 850, loss is 5.356617622375488 and perplexity is 212.00664581730183
At time: 239.24029278755188 and batch: 900, loss is 5.387891883850098 and perplexity is 218.74176610142547
At time: 240.31612730026245 and batch: 950, loss is 5.359738845825195 and perplexity is 212.66939969514536
At time: 241.3918378353119 and batch: 1000, loss is 5.389905614852905 and perplexity is 219.18269698652745
At time: 242.46839022636414 and batch: 1050, loss is 5.349288301467896 and perplexity is 210.4584615756924
At time: 243.54655599594116 and batch: 1100, loss is 5.341784944534302 and perplexity is 208.88522627294014
At time: 244.6226885318756 and batch: 1150, loss is 5.3481213569641115 and perplexity is 210.21301147186028
At time: 245.70671916007996 and batch: 1200, loss is 5.316885662078858 and perplexity is 203.74835166058674
At time: 246.78237557411194 and batch: 1250, loss is 5.3343973636627195 and perplexity is 207.347755856942
At time: 247.8587303161621 and batch: 1300, loss is 5.316525850296021 and perplexity is 203.67505379043513
At time: 248.9350085258484 and batch: 1350, loss is 5.2949341297149655 and perplexity is 199.3244959727732
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.262377522786458 and perplexity of 192.93966487201024
Finished 8 epochs...
Completing Train Step...
At time: 252.14152765274048 and batch: 50, loss is 5.437258729934692 and perplexity is 229.8113442467038
At time: 253.21764278411865 and batch: 100, loss is 5.451110048294067 and perplexity is 233.01668216888
At time: 254.3003442287445 and batch: 150, loss is 5.414671974182129 and perplexity is 224.67883313147115
At time: 255.38087368011475 and batch: 200, loss is 5.409253358840942 and perplexity is 223.46467745149576
At time: 256.4703302383423 and batch: 250, loss is 5.428427076339721 and perplexity is 227.7906661606353
At time: 257.5513036251068 and batch: 300, loss is 5.4458967876434325 and perplexity is 231.80506644718548
At time: 258.66209721565247 and batch: 350, loss is 5.439341058731079 and perplexity is 230.29038561428504
At time: 259.7461085319519 and batch: 400, loss is 5.456683282852173 and perplexity is 234.31896438584556
At time: 260.8302643299103 and batch: 450, loss is 5.432881870269775 and perplexity is 228.80769027207077
At time: 261.9118883609772 and batch: 500, loss is 5.45761661529541 and perplexity is 234.53776396786364
At time: 262.9973261356354 and batch: 550, loss is 5.4382897472381595 and perplexity is 230.0484059054917
At time: 264.0826950073242 and batch: 600, loss is 5.384468584060669 and perplexity is 217.99422771362623
At time: 265.1662311553955 and batch: 650, loss is 5.415228548049927 and perplexity is 224.80391830497993
At time: 266.2435896396637 and batch: 700, loss is 5.42768931388855 and perplexity is 227.6226727376542
At time: 267.32260489463806 and batch: 750, loss is 5.401195812225342 and perplexity is 221.67133506849268
At time: 268.41125440597534 and batch: 800, loss is 5.381212177276612 and perplexity is 217.28550440359757
At time: 269.4970817565918 and batch: 850, loss is 5.347963027954101 and perplexity is 210.17973128854143
At time: 270.5828311443329 and batch: 900, loss is 5.3802308750152585 and perplexity is 217.07238623054155
At time: 271.662175655365 and batch: 950, loss is 5.352758626937867 and perplexity is 211.1900896948584
At time: 272.741117477417 and batch: 1000, loss is 5.3843252563476565 and perplexity is 217.9629853385206
At time: 273.8197958469391 and batch: 1050, loss is 5.344190225601197 and perplexity is 209.38825867748847
At time: 274.89864921569824 and batch: 1100, loss is 5.337383766174316 and perplexity is 207.96790526277331
At time: 275.9773302078247 and batch: 1150, loss is 5.3438413619995115 and perplexity is 209.31522347581816
At time: 277.0564286708832 and batch: 1200, loss is 5.314107551574707 and perplexity is 203.183101751535
At time: 278.14031291007996 and batch: 1250, loss is 5.331317214965821 and perplexity is 206.71007651468722
At time: 279.221449136734 and batch: 1300, loss is 5.31250415802002 and perplexity is 202.8575803149914
At time: 280.30426120758057 and batch: 1350, loss is 5.289308300018311 and perplexity is 198.2062787033125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2599560546875 and perplexity of 192.47303282381657
Finished 9 epochs...
Completing Train Step...
At time: 283.5282778739929 and batch: 50, loss is 5.42548734664917 and perplexity is 227.12200649697246
At time: 284.63398122787476 and batch: 100, loss is 5.439380912780762 and perplexity is 230.29956380164748
At time: 285.7147867679596 and batch: 150, loss is 5.403677158355713 and perplexity is 222.22206136669146
At time: 286.81799817085266 and batch: 200, loss is 5.397169542312622 and perplexity is 220.78062077294786
At time: 287.8937876224518 and batch: 250, loss is 5.416529760360718 and perplexity is 225.0966263273335
At time: 289.15506863594055 and batch: 300, loss is 5.434016208648682 and perplexity is 229.0673828783343
At time: 290.2300751209259 and batch: 350, loss is 5.428925476074219 and perplexity is 227.90422526473372
At time: 291.30587339401245 and batch: 400, loss is 5.446257314682007 and perplexity is 231.8886535081106
At time: 292.3819627761841 and batch: 450, loss is 5.422957353591919 and perplexity is 226.54811567340215
At time: 293.46432614326477 and batch: 500, loss is 5.447991924285889 and perplexity is 232.29123885677916
At time: 294.5405824184418 and batch: 550, loss is 5.429363603591919 and perplexity is 228.00409825417725
At time: 295.6163578033447 and batch: 600, loss is 5.375116939544678 and perplexity is 215.96512569749092
At time: 296.6938214302063 and batch: 650, loss is 5.405780534744263 and perplexity is 222.68996992498217
At time: 297.7695314884186 and batch: 700, loss is 5.419674110412598 and perplexity is 225.80552284133125
At time: 298.8456892967224 and batch: 750, loss is 5.392995185852051 and perplexity is 219.86092466743958
At time: 299.9214837551117 and batch: 800, loss is 5.373468837738037 and perplexity is 215.6094863291004
At time: 300.9960570335388 and batch: 850, loss is 5.340334892272949 and perplexity is 208.58255127853494
At time: 302.07135343551636 and batch: 900, loss is 5.373481922149658 and perplexity is 215.61230747082533
At time: 303.1467254161835 and batch: 950, loss is 5.346428728103637 and perplexity is 209.85749982131398
At time: 304.22268629074097 and batch: 1000, loss is 5.378477764129639 and perplexity is 216.69216764732218
At time: 305.2990610599518 and batch: 1050, loss is 5.339246187210083 and perplexity is 208.35558996831392
At time: 306.3757345676422 and batch: 1100, loss is 5.332755270004273 and perplexity is 207.00755082266693
At time: 307.45175099372864 and batch: 1150, loss is 5.339847011566162 and perplexity is 208.48081269615747
At time: 308.5273246765137 and batch: 1200, loss is 5.310815982818603 and perplexity is 202.51541008139935
At time: 309.6027743816376 and batch: 1250, loss is 5.327501611709595 and perplexity is 205.92285568989848
At time: 310.67925214767456 and batch: 1300, loss is 5.307805166244507 and perplexity is 201.90659031045826
At time: 311.75827383995056 and batch: 1350, loss is 5.284015645980835 and perplexity is 197.16001264656404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.258265380859375 and perplexity of 192.14789862998396
Finished 10 epochs...
Completing Train Step...
At time: 314.9683768749237 and batch: 50, loss is 5.415530843734741 and perplexity is 224.87188583204028
At time: 316.07622051239014 and batch: 100, loss is 5.429046382904053 and perplexity is 227.93178210798803
At time: 317.1539521217346 and batch: 150, loss is 5.393989515304566 and perplexity is 220.07964758359145
At time: 318.22896790504456 and batch: 200, loss is 5.387005367279053 and perplexity is 218.54793383145116
At time: 319.304815530777 and batch: 250, loss is 5.4061955547332765 and perplexity is 222.7824098947446
At time: 320.38055086135864 and batch: 300, loss is 5.423277559280396 and perplexity is 226.62066928417408
At time: 321.45574736595154 and batch: 350, loss is 5.419787702560424 and perplexity is 225.83117403252126
At time: 322.53270506858826 and batch: 400, loss is 5.437327165603637 and perplexity is 229.8270720779447
At time: 323.6080832481384 and batch: 450, loss is 5.414136772155762 and perplexity is 224.5586167375957
At time: 324.6839597225189 and batch: 500, loss is 5.439874048233032 and perplexity is 230.41316068822445
At time: 325.7598247528076 and batch: 550, loss is 5.421582040786743 and perplexity is 226.23675530695533
At time: 326.8365476131439 and batch: 600, loss is 5.366793928146362 and perplexity is 214.175105009226
At time: 327.9125351905823 and batch: 650, loss is 5.397587881088257 and perplexity is 220.8730011893338
At time: 328.9884352684021 and batch: 700, loss is 5.41217679977417 and perplexity is 224.11891908912315
At time: 330.06403374671936 and batch: 750, loss is 5.385023880004883 and perplexity is 218.1153126400104
At time: 331.1386065483093 and batch: 800, loss is 5.366540107727051 and perplexity is 214.12074989277764
At time: 332.21426248550415 and batch: 850, loss is 5.333265104293823 and perplexity is 207.11311727868508
At time: 333.29002475738525 and batch: 900, loss is 5.367272443771363 and perplexity is 214.277615667979
At time: 334.41111278533936 and batch: 950, loss is 5.340225334167481 and perplexity is 208.55970062114326
At time: 335.48721170425415 and batch: 1000, loss is 5.372668151855469 and perplexity is 215.43691995219908
At time: 336.56243872642517 and batch: 1050, loss is 5.33437484741211 and perplexity is 207.3430872154681
At time: 337.6391396522522 and batch: 1100, loss is 5.327608585357666 and perplexity is 205.94488518725973
At time: 338.7154586315155 and batch: 1150, loss is 5.335240917205811 and perplexity is 207.5227385843207
At time: 339.8024263381958 and batch: 1200, loss is 5.306642255783081 and perplexity is 201.67192749672157
At time: 340.8822989463806 and batch: 1250, loss is 5.323572301864624 and perplexity is 205.11530857615233
At time: 341.95844197273254 and batch: 1300, loss is 5.302603464126587 and perplexity is 200.85905920638095
At time: 343.0366654396057 and batch: 1350, loss is 5.278390617370605 and perplexity is 196.0540952591275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.257413736979166 and perplexity of 191.98432671041945
Finished 11 epochs...
Completing Train Step...
At time: 346.25474739074707 and batch: 50, loss is 5.406311197280884 and perplexity is 222.80817450990108
At time: 347.3320093154907 and batch: 100, loss is 5.420150279998779 and perplexity is 225.9130701670508
At time: 348.40970516204834 and batch: 150, loss is 5.385826435089111 and perplexity is 218.29043245536732
At time: 349.4869647026062 and batch: 200, loss is 5.378226957321167 and perplexity is 216.63782659117197
At time: 350.56418442726135 and batch: 250, loss is 5.397462768554687 and perplexity is 220.84536893716444
At time: 351.6458032131195 and batch: 300, loss is 5.414790515899658 and perplexity is 224.70546852491447
At time: 352.7223460674286 and batch: 350, loss is 5.411290674209595 and perplexity is 223.92040955059124
At time: 353.79958319664 and batch: 400, loss is 5.429776401519775 and perplexity is 228.0982373023445
At time: 354.8767411708832 and batch: 450, loss is 5.406422300338745 and perplexity is 222.8329305546163
At time: 355.95479226112366 and batch: 500, loss is 5.432487840652466 and perplexity is 228.7175510253681
At time: 357.0337212085724 and batch: 550, loss is 5.414432983398438 and perplexity is 224.62514337699608
At time: 358.1105799674988 and batch: 600, loss is 5.359382276535034 and perplexity is 212.59358183622052
At time: 359.18775177001953 and batch: 650, loss is 5.389978008270264 and perplexity is 219.19856494534912
At time: 360.2635807991028 and batch: 700, loss is 5.405399627685547 and perplexity is 222.60516189654624
At time: 361.36779975891113 and batch: 750, loss is 5.378467054367065 and perplexity is 216.68984693808224
At time: 362.44455742836 and batch: 800, loss is 5.359968147277832 and perplexity is 212.7181706888431
At time: 363.5295147895813 and batch: 850, loss is 5.32699423789978 and perplexity is 205.8184023267703
At time: 364.60746240615845 and batch: 900, loss is 5.3614693450927735 and perplexity is 213.03774255215552
At time: 365.68549036979675 and batch: 950, loss is 5.33430438041687 and perplexity is 207.32847688590732
At time: 366.76214814186096 and batch: 1000, loss is 5.367134952545166 and perplexity is 214.24815640109617
At time: 367.83956146240234 and batch: 1050, loss is 5.329432706832886 and perplexity is 206.32089651594907
At time: 368.9172856807709 and batch: 1100, loss is 5.3224586009979244 and perplexity is 204.88699863730432
At time: 369.99472761154175 and batch: 1150, loss is 5.330531282424927 and perplexity is 206.5476801636713
At time: 371.07288885116577 and batch: 1200, loss is 5.30236964225769 and perplexity is 200.81209945609464
At time: 372.1565592288971 and batch: 1250, loss is 5.31956301689148 and perplexity is 204.2945892000253
At time: 373.2360415458679 and batch: 1300, loss is 5.297525177001953 and perplexity is 199.84162483064256
At time: 374.313649892807 and batch: 1350, loss is 5.272785577774048 and perplexity is 194.95827820999872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.256360677083333 and perplexity of 191.78226212705982
Finished 12 epochs...
Completing Train Step...
At time: 377.52193689346313 and batch: 50, loss is 5.397821998596191 and perplexity is 220.9247174795504
At time: 378.59853196144104 and batch: 100, loss is 5.411548080444336 and perplexity is 223.9780554789878
At time: 379.68362379074097 and batch: 150, loss is 5.378301839828492 and perplexity is 216.65404958221004
At time: 380.7636978626251 and batch: 200, loss is 5.370034370422363 and perplexity is 214.8702527587616
At time: 381.8478021621704 and batch: 250, loss is 5.388886079788208 and perplexity is 218.95934641759007
At time: 382.92492961883545 and batch: 300, loss is 5.406849212646485 and perplexity is 222.92808098423936
At time: 384.00226283073425 and batch: 350, loss is 5.403976240158081 and perplexity is 222.2885338811953
At time: 385.0823299884796 and batch: 400, loss is 5.422426815032959 and perplexity is 226.42795504032082
At time: 386.1648681163788 and batch: 450, loss is 5.399542398452759 and perplexity is 221.30512346318804
At time: 387.2456691265106 and batch: 500, loss is 5.426040592193604 and perplexity is 227.2476955003444
At time: 388.3223977088928 and batch: 550, loss is 5.407692251205444 and perplexity is 223.11609719370554
At time: 389.42806124687195 and batch: 600, loss is 5.352513170242309 and perplexity is 211.13825803478164
At time: 390.5049638748169 and batch: 650, loss is 5.3829600048065185 and perplexity is 217.66561407635263
At time: 391.59070324897766 and batch: 700, loss is 5.398626747131348 and perplexity is 221.10257787917124
At time: 392.66798520088196 and batch: 750, loss is 5.37174355506897 and perplexity is 215.23781972621654
At time: 393.7455530166626 and batch: 800, loss is 5.353726844787598 and perplexity is 211.39466673097468
At time: 394.8274688720703 and batch: 850, loss is 5.320760755538941 and perplexity is 204.53942732174778
At time: 395.90566301345825 and batch: 900, loss is 5.355912523269653 and perplexity is 211.85721280963617
At time: 396.9825761318207 and batch: 950, loss is 5.32880124092102 and perplexity is 206.19065302938253
At time: 398.06044912338257 and batch: 1000, loss is 5.361928195953369 and perplexity is 213.13551753401669
At time: 399.1361155509949 and batch: 1050, loss is 5.324693040847778 and perplexity is 205.3453181647961
At time: 400.228839635849 and batch: 1100, loss is 5.317296953201294 and perplexity is 203.83216878427362
At time: 401.3079605102539 and batch: 1150, loss is 5.325576496124268 and perplexity is 205.52681172854992
At time: 402.3876094818115 and batch: 1200, loss is 5.297832736968994 and perplexity is 199.9030975669807
At time: 403.467276096344 and batch: 1250, loss is 5.315547714233398 and perplexity is 203.47592927657615
At time: 404.5459291934967 and batch: 1300, loss is 5.292521162033081 and perplexity is 198.84411221410795
At time: 405.6231360435486 and batch: 1350, loss is 5.267107706069947 and perplexity is 193.85446673405164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.255489908854167 and perplexity of 191.61533691341566
Finished 13 epochs...
Completing Train Step...
At time: 408.8301808834076 and batch: 50, loss is 5.389732942581177 and perplexity is 219.14485347967147
At time: 409.93463492393494 and batch: 100, loss is 5.403895387649536 and perplexity is 222.2705620221549
At time: 411.01091504096985 and batch: 150, loss is 5.370712432861328 and perplexity is 215.01599761287977
At time: 412.08776473999023 and batch: 200, loss is 5.361933946609497 and perplexity is 213.13674320661093
At time: 413.1649913787842 and batch: 250, loss is 5.381172828674316 and perplexity is 217.27695469091094
At time: 414.24168586730957 and batch: 300, loss is 5.399235801696777 and perplexity is 221.23728243070377
At time: 415.3266122341156 and batch: 350, loss is 5.39684949874878 and perplexity is 220.70997266208792
At time: 416.4495930671692 and batch: 400, loss is 5.4154479122161865 and perplexity is 224.85323763834018
At time: 417.53040766716003 and batch: 450, loss is 5.392815570831299 and perplexity is 219.82143788920834
At time: 418.6076467037201 and batch: 500, loss is 5.419191331863403 and perplexity is 225.69653508920504
At time: 419.6837089061737 and batch: 550, loss is 5.401363821029663 and perplexity is 221.70858093317884
At time: 420.76051664352417 and batch: 600, loss is 5.3457496643066404 and perplexity is 209.71504156525347
At time: 421.84294962882996 and batch: 650, loss is 5.376314582824707 and perplexity is 216.22392982558105
At time: 422.92028403282166 and batch: 700, loss is 5.392181921005249 and perplexity is 219.68219219449188
At time: 423.99730944633484 and batch: 750, loss is 5.365214357376098 and perplexity is 213.8370673211459
At time: 425.0742721557617 and batch: 800, loss is 5.34769344329834 and perplexity is 210.12307769484687
At time: 426.1513743400574 and batch: 850, loss is 5.314714527130127 and perplexity is 203.30646636343698
At time: 427.23491191864014 and batch: 900, loss is 5.350422677993774 and perplexity is 210.69733617543014
At time: 428.31205916404724 and batch: 950, loss is 5.323277616500855 and perplexity is 205.0548730020068
At time: 429.38941287994385 and batch: 1000, loss is 5.356562147140503 and perplexity is 211.99488502502604
At time: 430.4709358215332 and batch: 1050, loss is 5.319509868621826 and perplexity is 204.28373158464402
At time: 431.54848313331604 and batch: 1100, loss is 5.3123459815979 and perplexity is 202.82549556632964
At time: 432.6255986690521 and batch: 1150, loss is 5.320436620712281 and perplexity is 204.47313971356925
At time: 433.70311975479126 and batch: 1200, loss is 5.293582038879395 and perplexity is 199.05517326387707
At time: 434.7800335884094 and batch: 1250, loss is 5.311232852935791 and perplexity is 202.599850303212
At time: 435.8619074821472 and batch: 1300, loss is 5.287267198562622 and perplexity is 197.802132171671
At time: 436.9424571990967 and batch: 1350, loss is 5.261929893493653 and perplexity is 192.85331875323723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.254896647135417 and perplexity of 191.50169258304808
Finished 14 epochs...
Completing Train Step...
At time: 440.1543252468109 and batch: 50, loss is 5.382401638031006 and perplexity is 217.5441107541467
At time: 441.2599310874939 and batch: 100, loss is 5.396485776901245 and perplexity is 220.62971022054853
At time: 442.34096097946167 and batch: 150, loss is 5.363696556091309 and perplexity is 213.51275133150423
At time: 443.4445378780365 and batch: 200, loss is 5.354893789291382 and perplexity is 211.641496565795
At time: 444.5217080116272 and batch: 250, loss is 5.373822422027588 and perplexity is 215.68573593568152
At time: 445.59881591796875 and batch: 300, loss is 5.392141561508179 and perplexity is 219.67332611061627
At time: 446.67587327957153 and batch: 350, loss is 5.390149917602539 and perplexity is 219.23625046343787
At time: 447.7549874782562 and batch: 400, loss is 5.409043617248535 and perplexity is 223.4178125291339
At time: 448.83395552635193 and batch: 450, loss is 5.386403398513794 and perplexity is 218.41641439084194
At time: 449.9099967479706 and batch: 500, loss is 5.41283878326416 and perplexity is 224.26733123112862
At time: 450.98699712753296 and batch: 550, loss is 5.395368528366089 and perplexity is 220.38334964861335
At time: 452.0633490085602 and batch: 600, loss is 5.339273481369019 and perplexity is 208.3612769365118
At time: 453.1406536102295 and batch: 650, loss is 5.370019445419311 and perplexity is 214.86704584351506
At time: 454.221718788147 and batch: 700, loss is 5.3860953998565675 and perplexity is 218.34915278726683
At time: 455.30298137664795 and batch: 750, loss is 5.35904375076294 and perplexity is 212.52162560999278
At time: 456.3834710121155 and batch: 800, loss is 5.341870326995849 and perplexity is 208.90306216916568
At time: 457.46061849594116 and batch: 850, loss is 5.308996505737305 and perplexity is 202.14727294424816
At time: 458.5389292240143 and batch: 900, loss is 5.3452401542663575 and perplexity is 209.60821686241792
At time: 459.617618560791 and batch: 950, loss is 5.318090372085571 and perplexity is 203.9939572507352
At time: 460.70714497566223 and batch: 1000, loss is 5.351450443267822 and perplexity is 210.9139948989705
At time: 461.7872648239136 and batch: 1050, loss is 5.3146944332122805 and perplexity is 203.3023811810481
At time: 462.8647038936615 and batch: 1100, loss is 5.307581787109375 and perplexity is 201.8614936279537
At time: 463.9418394565582 and batch: 1150, loss is 5.315744638442993 and perplexity is 203.51600255869073
At time: 465.01866340637207 and batch: 1200, loss is 5.289298524856568 and perplexity is 198.2043412143493
At time: 466.09906554222107 and batch: 1250, loss is 5.307140302658081 and perplexity is 201.7723945865699
At time: 467.1775858402252 and batch: 1300, loss is 5.282425451278686 and perplexity is 196.84673898804903
At time: 468.2567672729492 and batch: 1350, loss is 5.256906394958496 and perplexity is 191.886949697983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.254319661458333 and perplexity of 191.39123071981138
Finished 15 epochs...
Completing Train Step...
At time: 471.503280878067 and batch: 50, loss is 5.375664806365966 and perplexity is 216.08347824217185
At time: 472.5912320613861 and batch: 100, loss is 5.389787492752075 and perplexity is 219.15680819494304
At time: 473.6839425563812 and batch: 150, loss is 5.35746771812439 and perplexity is 212.18694839201805
At time: 474.7616364955902 and batch: 200, loss is 5.348241491317749 and perplexity is 210.2382667931051
At time: 475.83879590034485 and batch: 250, loss is 5.36743724822998 and perplexity is 214.31293248452755
At time: 476.9158363342285 and batch: 300, loss is 5.3856688976287845 and perplexity is 218.25604624365405
At time: 477.99224948883057 and batch: 350, loss is 5.384379205703735 and perplexity is 217.9747446184285
At time: 479.0691578388214 and batch: 400, loss is 5.403033113479614 and perplexity is 222.07898646498637
At time: 480.14521193504333 and batch: 450, loss is 5.380446090698242 and perplexity is 217.11910863991827
At time: 481.22191739082336 and batch: 500, loss is 5.40719048500061 and perplexity is 223.00417315857678
At time: 482.2984275817871 and batch: 550, loss is 5.389645576477051 and perplexity is 219.12570848390763
At time: 483.3750479221344 and batch: 600, loss is 5.333716211318969 and perplexity is 207.20656853756432
At time: 484.4594204425812 and batch: 650, loss is 5.36413724899292 and perplexity is 213.6068656216461
At time: 485.5436112880707 and batch: 700, loss is 5.380759077072144 and perplexity is 217.18707459809082
At time: 486.62114095687866 and batch: 750, loss is 5.353790769577026 and perplexity is 211.4081805224602
At time: 487.6992521286011 and batch: 800, loss is 5.336598453521728 and perplexity is 207.804649547218
At time: 488.7769708633423 and batch: 850, loss is 5.303837642669678 and perplexity is 201.10710818431633
At time: 489.8546905517578 and batch: 900, loss is 5.3405555057525635 and perplexity is 208.62857247722104
At time: 490.9312791824341 and batch: 950, loss is 5.3131203365325925 and perplexity is 202.9826153150781
At time: 492.012823343277 and batch: 1000, loss is 5.346777448654175 and perplexity is 209.9306942056373
At time: 493.10086464881897 and batch: 1050, loss is 5.310216913223266 and perplexity is 202.3941255891855
At time: 494.1768333911896 and batch: 1100, loss is 5.303169231414795 and perplexity is 200.97273084443523
At time: 495.25341296195984 and batch: 1150, loss is 5.3115396976470945 and perplexity is 202.6620265345245
At time: 496.32977390289307 and batch: 1200, loss is 5.2853865146636965 and perplexity is 197.43047847762577
At time: 497.40586972236633 and batch: 1250, loss is 5.302878160476684 and perplexity is 200.91424203574272
At time: 498.4884533882141 and batch: 1300, loss is 5.2777135372161865 and perplexity is 195.92139585117238
At time: 499.5662395954132 and batch: 1350, loss is 5.252248106002807 and perplexity is 190.99516355086453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253987223307291 and perplexity of 191.32761554758625
Finished 16 epochs...
Completing Train Step...
At time: 502.78487157821655 and batch: 50, loss is 5.369406118392944 and perplexity is 214.73530248223534
At time: 503.8615081310272 and batch: 100, loss is 5.383687686920166 and perplexity is 217.82406309373823
At time: 504.9434554576874 and batch: 150, loss is 5.351856994628906 and perplexity is 210.999759703386
At time: 506.0192461013794 and batch: 200, loss is 5.341842937469482 and perplexity is 208.89734049159364
At time: 507.0951442718506 and batch: 250, loss is 5.3610050487518315 and perplexity is 212.93885286664207
At time: 508.1712634563446 and batch: 300, loss is 5.379525804519654 and perplexity is 216.91938883891146
At time: 509.256254196167 and batch: 350, loss is 5.378718709945678 and perplexity is 216.74438500901013
At time: 510.33639550209045 and batch: 400, loss is 5.397306594848633 and perplexity is 220.81088139052665
At time: 511.4182274341583 and batch: 450, loss is 5.3749316215515135 and perplexity is 215.92510718199318
At time: 512.4985234737396 and batch: 500, loss is 5.401686954498291 and perplexity is 221.78023397208437
At time: 513.5790312290192 and batch: 550, loss is 5.384642066955567 and perplexity is 218.03204926392212
At time: 514.6605317592621 and batch: 600, loss is 5.328268537521362 and perplexity is 206.08084381800288
At time: 515.7419431209564 and batch: 650, loss is 5.358424291610718 and perplexity is 212.390017910969
At time: 516.8255431652069 and batch: 700, loss is 5.37513014793396 and perplexity is 215.96797826778132
At time: 517.9118950366974 and batch: 750, loss is 5.348194551467896 and perplexity is 210.228398472039
At time: 518.9925277233124 and batch: 800, loss is 5.331630640029907 and perplexity is 206.77487478783715
At time: 520.0771813392639 and batch: 850, loss is 5.298699769973755 and perplexity is 200.07649531024583
At time: 521.1588282585144 and batch: 900, loss is 5.335529584884643 and perplexity is 207.58265233873897
At time: 522.2394771575928 and batch: 950, loss is 5.30858808517456 and perplexity is 202.06472869880594
At time: 523.3213047981262 and batch: 1000, loss is 5.342072496414184 and perplexity is 208.94530024921303
At time: 524.4087088108063 and batch: 1050, loss is 5.306053743362427 and perplexity is 201.55327597986278
At time: 525.5161714553833 and batch: 1100, loss is 5.298648290634155 and perplexity is 200.06619576950683
At time: 526.5965497493744 and batch: 1150, loss is 5.307224702835083 and perplexity is 201.78942493105907
At time: 527.6773910522461 and batch: 1200, loss is 5.281107501983643 and perplexity is 196.58747585252954
At time: 528.7578086853027 and batch: 1250, loss is 5.298851518630982 and perplexity is 200.10685895351457
At time: 529.8382496833801 and batch: 1300, loss is 5.27294394493103 and perplexity is 194.98915564317005
At time: 530.9265630245209 and batch: 1350, loss is 5.24775580406189 and perplexity is 190.13907993967538
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253810221354167 and perplexity of 191.2937531828884
Finished 17 epochs...
Completing Train Step...
At time: 534.1168694496155 and batch: 50, loss is 5.363337593078613 and perplexity is 213.436121905425
At time: 535.2188627719879 and batch: 100, loss is 5.3776537036895755 and perplexity is 216.51367375926932
At time: 536.2956926822662 and batch: 150, loss is 5.346275796890259 and perplexity is 209.82540851317367
At time: 537.3834619522095 and batch: 200, loss is 5.335886898040772 and perplexity is 207.6568376043001
At time: 538.4607138633728 and batch: 250, loss is 5.355094728469848 and perplexity is 211.68402790720754
At time: 539.5368201732635 and batch: 300, loss is 5.37371187210083 and perplexity is 215.66189321130113
At time: 540.6122691631317 and batch: 350, loss is 5.373339376449585 and perplexity is 215.58157505395152
At time: 541.6906161308289 and batch: 400, loss is 5.39188967704773 and perplexity is 219.61800078148164
At time: 542.7685718536377 and batch: 450, loss is 5.36951361656189 and perplexity is 214.75838737482985
At time: 543.8456907272339 and batch: 500, loss is 5.396493158340454 and perplexity is 220.63133879135285
At time: 544.9228324890137 and batch: 550, loss is 5.379668397903442 and perplexity is 216.95032231397738
At time: 546.0000693798065 and batch: 600, loss is 5.3229736328125 and perplexity is 204.99254913859542
At time: 547.0759313106537 and batch: 650, loss is 5.352875089645385 and perplexity is 211.21468689680594
At time: 548.1527554988861 and batch: 700, loss is 5.370089406967163 and perplexity is 214.88207880048296
At time: 549.2283170223236 and batch: 750, loss is 5.342988615036011 and perplexity is 209.13680663760488
At time: 550.3042984008789 and batch: 800, loss is 5.326485805511474 and perplexity is 205.71378418279815
At time: 551.3805665969849 and batch: 850, loss is 5.2939451217651365 and perplexity is 199.127459912836
At time: 552.501357793808 and batch: 900, loss is 5.330956888198853 and perplexity is 206.63560675864596
At time: 553.5769376754761 and batch: 950, loss is 5.304002332687378 and perplexity is 201.1402312449666
At time: 554.6534497737885 and batch: 1000, loss is 5.337896299362183 and perplexity is 208.0745230364714
At time: 555.7370147705078 and batch: 1050, loss is 5.301914720535279 and perplexity is 200.7207664461892
At time: 556.8176233768463 and batch: 1100, loss is 5.294181938171387 and perplexity is 199.17462214645323
At time: 557.8965885639191 and batch: 1150, loss is 5.302989320755005 and perplexity is 200.93657696016123
At time: 558.9748258590698 and batch: 1200, loss is 5.277695045471192 and perplexity is 195.9177729561782
At time: 560.0531897544861 and batch: 1250, loss is 5.29449987411499 and perplexity is 199.23795698556464
At time: 561.131297826767 and batch: 1300, loss is 5.268717479705811 and perplexity is 194.1667798530639
At time: 562.2093992233276 and batch: 1350, loss is 5.243398761749267 and perplexity is 189.312438087593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253750406901042 and perplexity of 191.28231139385116
Finished 18 epochs...
Completing Train Step...
At time: 565.4201059341431 and batch: 50, loss is 5.357361011505127 and perplexity is 212.16430784807278
At time: 566.5233774185181 and batch: 100, loss is 5.371970224380493 and perplexity is 215.28661306439488
At time: 567.599668264389 and batch: 150, loss is 5.340786056518555 and perplexity is 208.6766774995251
At time: 568.6757433414459 and batch: 200, loss is 5.32984564781189 and perplexity is 206.40611246231256
At time: 569.7510879039764 and batch: 250, loss is 5.349279851913452 and perplexity is 210.45668330297602
At time: 570.8334925174713 and batch: 300, loss is 5.367927865982056 and perplexity is 214.41810401110314
At time: 571.909636259079 and batch: 350, loss is 5.368011083602905 and perplexity is 214.43594811804775
At time: 572.9865667819977 and batch: 400, loss is 5.386865139007568 and perplexity is 218.51728938111285
At time: 574.0644216537476 and batch: 450, loss is 5.364261674880981 and perplexity is 213.6334454991752
At time: 575.140955209732 and batch: 500, loss is 5.391560020446778 and perplexity is 219.54561418985057
At time: 576.2170214653015 and batch: 550, loss is 5.374770469665528 and perplexity is 215.8903132473685
At time: 577.2940502166748 and batch: 600, loss is 5.317911834716797 and perplexity is 203.9575399573824
At time: 578.3710975646973 and batch: 650, loss is 5.347810640335083 and perplexity is 210.1477049399959
At time: 579.4493842124939 and batch: 700, loss is 5.365205745697022 and perplexity is 213.8352258328766
At time: 580.5654394626617 and batch: 750, loss is 5.337999801635743 and perplexity is 208.0960603372361
At time: 581.6449661254883 and batch: 800, loss is 5.321999912261963 and perplexity is 204.79304082922587
At time: 582.7215144634247 and batch: 850, loss is 5.289081087112427 and perplexity is 198.16124879464584
At time: 583.805017709732 and batch: 900, loss is 5.326231060028076 and perplexity is 205.6613861997629
At time: 584.8812835216522 and batch: 950, loss is 5.298985481262207 and perplexity is 200.1336675905039
At time: 585.9592709541321 and batch: 1000, loss is 5.333203077316284 and perplexity is 207.10027107642125
At time: 587.0430114269257 and batch: 1050, loss is 5.297724485397339 and perplexity is 199.8814589137206
At time: 588.1220173835754 and batch: 1100, loss is 5.289982919692993 and perplexity is 198.34003767171427
At time: 589.2002213001251 and batch: 1150, loss is 5.299019632339477 and perplexity is 200.14050248755902
At time: 590.2790849208832 and batch: 1200, loss is 5.274163131713867 and perplexity is 195.2270288209791
At time: 591.357586145401 and batch: 1250, loss is 5.291131572723389 and perplexity is 198.56799245244582
At time: 592.4365029335022 and batch: 1300, loss is 5.264516077041626 and perplexity is 193.35271832450005
At time: 593.5158267021179 and batch: 1350, loss is 5.239024381637574 and perplexity is 188.48612215116862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.25357421875 and perplexity of 191.24861268582333
Finished 19 epochs...
Completing Train Step...
At time: 596.7584936618805 and batch: 50, loss is 5.352151594161987 and perplexity is 211.06192929119098
At time: 597.8350479602814 and batch: 100, loss is 5.366653938293457 and perplexity is 214.14512476629363
At time: 598.9114956855774 and batch: 150, loss is 5.3364684200286865 and perplexity is 207.77762973954512
At time: 599.9871306419373 and batch: 200, loss is 5.325097579956054 and perplexity is 205.42840518153585
At time: 601.0642702579498 and batch: 250, loss is 5.344229097366333 and perplexity is 209.39639812689848
At time: 602.1415569782257 and batch: 300, loss is 5.36287015914917 and perplexity is 213.33637793395206
At time: 603.2194120883942 and batch: 350, loss is 5.363129415512085 and perplexity is 213.39169391757315
At time: 604.2970876693726 and batch: 400, loss is 5.3820172309875485 and perplexity is 217.46050133676422
At time: 605.373621225357 and batch: 450, loss is 5.359525842666626 and perplexity is 212.6241052653789
At time: 606.4493451118469 and batch: 500, loss is 5.387000589370728 and perplexity is 218.54688963195323
At time: 607.5704779624939 and batch: 550, loss is 5.370301103591919 and perplexity is 214.92757342664495
At time: 608.6466538906097 and batch: 600, loss is 5.3132945728302 and perplexity is 203.01798533573054
At time: 609.7225162982941 and batch: 650, loss is 5.343047065734863 and perplexity is 209.1490311873719
At time: 610.7978098392487 and batch: 700, loss is 5.360737380981445 and perplexity is 212.88186362609832
At time: 611.8742196559906 and batch: 750, loss is 5.333310823440552 and perplexity is 207.12258653014482
At time: 612.9498021602631 and batch: 800, loss is 5.3170738029479985 and perplexity is 203.7866886588192
At time: 614.0262804031372 and batch: 850, loss is 5.284670095443726 and perplexity is 197.28908614237724
At time: 615.1033508777618 and batch: 900, loss is 5.32204267501831 and perplexity is 204.80179853138293
At time: 616.1798048019409 and batch: 950, loss is 5.294747686386108 and perplexity is 199.28733671437678
At time: 617.2561392784119 and batch: 1000, loss is 5.329060010910034 and perplexity is 206.24401588645685
At time: 618.3329186439514 and batch: 1050, loss is 5.293504619598389 and perplexity is 199.03976315201012
At time: 619.4092969894409 and batch: 1100, loss is 5.286029863357544 and perplexity is 197.55753598483827
At time: 620.4859976768494 and batch: 1150, loss is 5.295273113250732 and perplexity is 199.39207514864984
At time: 621.5623483657837 and batch: 1200, loss is 5.270144538879395 and perplexity is 194.44406514165829
At time: 622.6387984752655 and batch: 1250, loss is 5.2870100975036625 and perplexity is 197.7512835709198
At time: 623.7154195308685 and batch: 1300, loss is 5.259999685287475 and perplexity is 192.4814307209191
At time: 624.7912731170654 and batch: 1350, loss is 5.234772396087647 and perplexity is 187.68638332727974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2534619140625 and perplexity of 191.2271357761423
Finished 20 epochs...
Completing Train Step...
At time: 627.9796371459961 and batch: 50, loss is 5.346775646209717 and perplexity is 209.93031581756205
At time: 629.0555076599121 and batch: 100, loss is 5.361335229873657 and perplexity is 213.00917286449092
At time: 630.1308217048645 and batch: 150, loss is 5.3312804317474365 and perplexity is 206.7024731926388
At time: 631.2072358131409 and batch: 200, loss is 5.31966703414917 and perplexity is 204.31584046818494
At time: 632.2903575897217 and batch: 250, loss is 5.338898963928223 and perplexity is 208.28325661521006
At time: 633.3715953826904 and batch: 300, loss is 5.357435455322266 and perplexity is 212.18010275691904
At time: 634.4729497432709 and batch: 350, loss is 5.358223266601563 and perplexity is 212.34732649683866
At time: 635.5499231815338 and batch: 400, loss is 5.377008399963379 and perplexity is 216.37400174910107
At time: 636.6269290447235 and batch: 450, loss is 5.354723663330078 and perplexity is 211.60549391531944
At time: 637.7029838562012 and batch: 500, loss is 5.3825013637542725 and perplexity is 217.56580657973208
At time: 638.7789924144745 and batch: 550, loss is 5.365634717941284 and perplexity is 213.92697488709638
At time: 639.8603599071503 and batch: 600, loss is 5.308768472671509 and perplexity is 202.10118193719288
At time: 640.9427301883698 and batch: 650, loss is 5.338391389846802 and perplexity is 208.17756425817782
At time: 642.0214579105377 and batch: 700, loss is 5.356306810379028 and perplexity is 211.94076184774698
At time: 643.1043136119843 and batch: 750, loss is 5.3290614318847656 and perplexity is 206.2443089542002
At time: 644.1806838512421 and batch: 800, loss is 5.312984638214111 and perplexity is 202.95507278427868
At time: 645.2572767734528 and batch: 850, loss is 5.280168361663819 and perplexity is 196.4029392940085
At time: 646.3334770202637 and batch: 900, loss is 5.317693119049072 and perplexity is 203.91293612579938
At time: 647.4093351364136 and batch: 950, loss is 5.290513944625855 and perplexity is 198.44538914655692
At time: 648.4906303882599 and batch: 1000, loss is 5.325018901824951 and perplexity is 205.41224309435034
At time: 649.5719118118286 and batch: 1050, loss is 5.289675388336182 and perplexity is 198.27905126891534
At time: 650.6535818576813 and batch: 1100, loss is 5.2819538593292235 and perplexity is 196.7539295364794
At time: 651.7346279621124 and batch: 1150, loss is 5.291165971755982 and perplexity is 198.57482311677356
At time: 652.8153214454651 and batch: 1200, loss is 5.2663704204559325 and perplexity is 193.71159330025196
At time: 653.8957433700562 and batch: 1250, loss is 5.283339319229126 and perplexity is 197.0267131377368
At time: 654.9763581752777 and batch: 1300, loss is 5.255804510116577 and perplexity is 191.67562882376401
At time: 656.0566155910492 and batch: 1350, loss is 5.230609550476074 and perplexity is 186.90669787113245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253330078125 and perplexity of 191.20192682918085
Finished 21 epochs...
Completing Train Step...
At time: 659.2379081249237 and batch: 50, loss is 5.341451110839844 and perplexity is 208.81550498444093
At time: 660.3445353507996 and batch: 100, loss is 5.356270418167115 and perplexity is 211.9330489949735
At time: 661.4266822338104 and batch: 150, loss is 5.326518669128418 and perplexity is 205.72054479288994
At time: 662.5332345962524 and batch: 200, loss is 5.314633178710937 and perplexity is 203.28992837646604
At time: 663.6133024692535 and batch: 250, loss is 5.333701772689819 and perplexity is 207.20357678036223
At time: 664.6931800842285 and batch: 300, loss is 5.352339305877686 and perplexity is 211.10155180674568
At time: 665.7728064060211 and batch: 350, loss is 5.353841743469238 and perplexity is 211.4189570949265
At time: 666.8531856536865 and batch: 400, loss is 5.372337141036987 and perplexity is 215.36561980220614
At time: 667.9330725669861 and batch: 450, loss is 5.349853639602661 and perplexity is 210.57747540816445
At time: 669.0132093429565 and batch: 500, loss is 5.378195953369141 and perplexity is 216.63111006650925
At time: 670.0935068130493 and batch: 550, loss is 5.361546678543091 and perplexity is 213.05421813288342
At time: 671.1746227741241 and batch: 600, loss is 5.303976564407349 and perplexity is 201.1350482739412
At time: 672.2557430267334 and batch: 650, loss is 5.333575572967529 and perplexity is 207.17742939644603
At time: 673.3370487689972 and batch: 700, loss is 5.351838598251343 and perplexity is 210.99587810784442
At time: 674.4174003601074 and batch: 750, loss is 5.324931221008301 and perplexity is 205.3942331706999
At time: 675.4980926513672 and batch: 800, loss is 5.308658628463745 and perplexity is 202.07898351218148
At time: 676.5848937034607 and batch: 850, loss is 5.276086387634277 and perplexity is 195.60286165549735
At time: 677.6651091575623 and batch: 900, loss is 5.314110164642334 and perplexity is 203.18363268341426
At time: 678.7453122138977 and batch: 950, loss is 5.286494607925415 and perplexity is 197.64937111481524
At time: 679.8255088329315 and batch: 1000, loss is 5.321301164627076 and perplexity is 204.64999215958514
At time: 680.9063909053802 and batch: 1050, loss is 5.285859184265137 and perplexity is 197.52381992129364
At time: 681.9867181777954 and batch: 1100, loss is 5.278040542602539 and perplexity is 195.98547367924382
At time: 683.0675275325775 and batch: 1150, loss is 5.287344236373901 and perplexity is 197.8173710019753
At time: 684.1478366851807 and batch: 1200, loss is 5.262628755569458 and perplexity is 192.9881437304513
At time: 685.2289066314697 and batch: 1250, loss is 5.279708938598633 and perplexity is 196.312727977793
At time: 686.3102564811707 and batch: 1300, loss is 5.251647720336914 and perplexity is 190.8805272088654
At time: 687.3915185928345 and batch: 1350, loss is 5.226653814315796 and perplexity is 186.16880470530782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253198649088541 and perplexity of 191.17679899546835
Finished 22 epochs...
Completing Train Step...
At time: 690.5787930488586 and batch: 50, loss is 5.3366695022583 and perplexity is 207.81941432952553
At time: 691.6800549030304 and batch: 100, loss is 5.3516703128814695 and perplexity is 210.96037357598578
At time: 692.756520986557 and batch: 150, loss is 5.321910829544067 and perplexity is 204.77479812110977
At time: 693.8320195674896 and batch: 200, loss is 5.3097760868072506 and perplexity is 202.30492457470564
At time: 694.9084665775299 and batch: 250, loss is 5.328689670562744 and perplexity is 206.16764954762797
At time: 695.9847786426544 and batch: 300, loss is 5.347607774734497 and perplexity is 210.10507752358595
At time: 697.0599527359009 and batch: 350, loss is 5.348903741836548 and perplexity is 210.3775433072418
At time: 698.1358227729797 and batch: 400, loss is 5.367605028152465 and perplexity is 214.34889290836156
At time: 699.2112221717834 and batch: 450, loss is 5.345321273803711 and perplexity is 209.62522087366463
At time: 700.2901961803436 and batch: 500, loss is 5.373681182861328 and perplexity is 215.6552748133663
At time: 701.3661203384399 and batch: 550, loss is 5.357488288879394 and perplexity is 212.1913132826429
At time: 702.447163105011 and batch: 600, loss is 5.299286727905273 and perplexity is 200.19396626796117
At time: 703.5226645469666 and batch: 650, loss is 5.328937597274781 and perplexity is 206.21877035195328
At time: 704.5980076789856 and batch: 700, loss is 5.3473922157287594 and perplexity is 210.05979236296199
At time: 705.6737356185913 and batch: 750, loss is 5.320548133850098 and perplexity is 204.4959424263554
At time: 706.749847650528 and batch: 800, loss is 5.304320459365845 and perplexity is 201.20422949787468
At time: 707.8336255550385 and batch: 850, loss is 5.272087268829345 and perplexity is 194.8221846236955
At time: 708.9090421199799 and batch: 900, loss is 5.310229415893555 and perplexity is 202.3966560720249
At time: 709.9840798377991 and batch: 950, loss is 5.282236404418946 and perplexity is 196.80952924749624
At time: 711.0595667362213 and batch: 1000, loss is 5.317758550643921 and perplexity is 203.92627891093554
At time: 712.1353919506073 and batch: 1050, loss is 5.282343349456787 and perplexity is 196.83057817556832
At time: 713.2104589939117 and batch: 1100, loss is 5.27419903755188 and perplexity is 195.2340387368994
At time: 714.2855577468872 and batch: 1150, loss is 5.283452768325805 and perplexity is 197.0490669083476
At time: 715.3616466522217 and batch: 1200, loss is 5.259105291366577 and perplexity is 192.30935346329403
At time: 716.4671010971069 and batch: 1250, loss is 5.276590766906739 and perplexity is 195.70154456926664
At time: 717.5477709770203 and batch: 1300, loss is 5.2477062225341795 and perplexity is 190.1296527873228
At time: 718.6238112449646 and batch: 1350, loss is 5.222857437133789 and perplexity is 185.46337758408237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.253489583333334 and perplexity of 191.23242696475413
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 721.8111703395844 and batch: 50, loss is 5.334949378967285 and perplexity is 207.46224658895318
At time: 722.8867626190186 and batch: 100, loss is 5.35340220451355 and perplexity is 211.32605064680968
At time: 723.9619812965393 and batch: 150, loss is 5.3234450721740725 and perplexity is 205.0892134789855
At time: 725.0372269153595 and batch: 200, loss is 5.311475028991699 and perplexity is 202.64892107752956
At time: 726.1131386756897 and batch: 250, loss is 5.329449548721313 and perplexity is 206.3243713787299
At time: 727.1886942386627 and batch: 300, loss is 5.347422304153443 and perplexity is 210.0661128262894
At time: 728.2642922401428 and batch: 350, loss is 5.349030799865723 and perplexity is 210.40427516148955
At time: 729.339607000351 and batch: 400, loss is 5.366027002334595 and perplexity is 214.0109115631003
At time: 730.4152443408966 and batch: 450, loss is 5.339276466369629 and perplexity is 208.36189889597887
At time: 731.4907133579254 and batch: 500, loss is 5.364559736251831 and perplexity is 213.69713086740262
At time: 732.566752910614 and batch: 550, loss is 5.345132484436035 and perplexity is 209.58564959620279
At time: 733.6422109603882 and batch: 600, loss is 5.2889520454406735 and perplexity is 198.13567938561977
At time: 734.7181220054626 and batch: 650, loss is 5.318289089202881 and perplexity is 204.03449836984242
At time: 735.7932183742523 and batch: 700, loss is 5.330286779403687 and perplexity is 206.49718480522654
At time: 736.868723154068 and batch: 750, loss is 5.30132381439209 and perplexity is 200.60219434817128
At time: 737.9439601898193 and batch: 800, loss is 5.285612783432007 and perplexity is 197.475155883178
At time: 739.0195281505585 and batch: 850, loss is 5.242818899154663 and perplexity is 189.2026947071684
At time: 740.0951242446899 and batch: 900, loss is 5.274786815643311 and perplexity is 195.34882675920804
At time: 741.1703453063965 and batch: 950, loss is 5.246299953460693 and perplexity is 189.86246724806767
At time: 742.250730752945 and batch: 1000, loss is 5.284448184967041 and perplexity is 197.24531048454486
At time: 743.329512834549 and batch: 1050, loss is 5.244171409606934 and perplexity is 189.45876646018317
At time: 744.4482746124268 and batch: 1100, loss is 5.232521724700928 and perplexity is 187.26443796294188
At time: 745.5232095718384 and batch: 1150, loss is 5.238907260894775 and perplexity is 188.46404780924198
At time: 746.5998704433441 and batch: 1200, loss is 5.211078653335571 and perplexity is 183.29165976294894
At time: 747.6764278411865 and batch: 1250, loss is 5.225185041427612 and perplexity is 185.89556572445602
At time: 748.7527928352356 and batch: 1300, loss is 5.202311754226685 and perplexity is 181.6917834982037
At time: 749.828042268753 and batch: 1350, loss is 5.186609392166138 and perplexity is 178.86107589051147
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.235569661458333 and perplexity of 187.8360788468537
Finished 24 epochs...
Completing Train Step...
At time: 753.0162863731384 and batch: 50, loss is 5.324567136764526 and perplexity is 205.3194659782445
At time: 754.0928161144257 and batch: 100, loss is 5.340680046081543 and perplexity is 208.65455676628423
At time: 755.1684386730194 and batch: 150, loss is 5.310895290374756 and perplexity is 202.53147172055236
At time: 756.2437431812286 and batch: 200, loss is 5.299782848358154 and perplexity is 200.29331123066623
At time: 757.3191401958466 and batch: 250, loss is 5.318019618988037 and perplexity is 203.97952455696648
At time: 758.393972158432 and batch: 300, loss is 5.335993938446045 and perplexity is 207.6790664660269
At time: 759.4692499637604 and batch: 350, loss is 5.3376967716217045 and perplexity is 208.033010538624
At time: 760.5538992881775 and batch: 400, loss is 5.355340127944946 and perplexity is 211.73598143096558
At time: 761.6293296813965 and batch: 450, loss is 5.328783159255981 and perplexity is 206.18692479276675
At time: 762.7054686546326 and batch: 500, loss is 5.355771064758301 and perplexity is 211.82724592327833
At time: 763.7817816734314 and batch: 550, loss is 5.3376638698577885 and perplexity is 208.0261659982239
At time: 764.8574888706207 and batch: 600, loss is 5.281717586517334 and perplexity is 196.70744742374345
At time: 765.9402871131897 and batch: 650, loss is 5.311131181716919 and perplexity is 202.57925277659407
At time: 767.0153059959412 and batch: 700, loss is 5.324682931900025 and perplexity is 205.34324235019554
At time: 768.0902743339539 and batch: 750, loss is 5.2965114974975585 and perplexity is 199.63915210998792
At time: 769.165604352951 and batch: 800, loss is 5.281148767471313 and perplexity is 196.59558829797137
At time: 770.2406899929047 and batch: 850, loss is 5.239693384170533 and perplexity is 188.61226203356114
At time: 771.3420922756195 and batch: 900, loss is 5.272906398773193 and perplexity is 194.98183468699352
At time: 772.4172356128693 and batch: 950, loss is 5.245056505203247 and perplexity is 189.6265298124101
At time: 773.4925124645233 and batch: 1000, loss is 5.2842576122283935 and perplexity is 197.2077244870874
At time: 774.5678102970123 and batch: 1050, loss is 5.245310869216919 and perplexity is 189.6747701126699
At time: 775.6443758010864 and batch: 1100, loss is 5.234943485260009 and perplexity is 187.71849718235507
At time: 776.7212564945221 and batch: 1150, loss is 5.242192783355713 and perplexity is 189.0842689887837
At time: 777.7981643676758 and batch: 1200, loss is 5.215259952545166 and perplexity is 184.059661538719
At time: 778.8731660842896 and batch: 1250, loss is 5.23075535774231 and perplexity is 186.93395221268244
At time: 779.9485929012299 and batch: 1300, loss is 5.20801025390625 and perplexity is 182.73010970925134
At time: 781.023717880249 and batch: 1350, loss is 5.190061464309692 and perplexity is 179.4795841815604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.233695068359375 and perplexity of 187.48429246089538
Finished 25 epochs...
Completing Train Step...
At time: 784.2054002285004 and batch: 50, loss is 5.321065101623535 and perplexity is 204.6016875694491
At time: 785.3083081245422 and batch: 100, loss is 5.336036949157715 and perplexity is 207.6879990825724
At time: 786.3832859992981 and batch: 150, loss is 5.305398855209351 and perplexity is 201.42132433870907
At time: 787.4641945362091 and batch: 200, loss is 5.294691591262818 and perplexity is 199.27615798019272
At time: 788.5439832210541 and batch: 250, loss is 5.312786684036255 and perplexity is 202.91490095592582
At time: 789.620329618454 and batch: 300, loss is 5.330902986526489 and perplexity is 206.62446905404494
At time: 790.6973943710327 and batch: 350, loss is 5.332835264205933 and perplexity is 207.0241108887784
At time: 791.7745792865753 and batch: 400, loss is 5.35050220489502 and perplexity is 210.71409294797516
At time: 792.850821018219 and batch: 450, loss is 5.324129304885864 and perplexity is 205.22959024739518
At time: 793.9284815788269 and batch: 500, loss is 5.351456060409546 and perplexity is 210.91517963609869
At time: 795.004962682724 and batch: 550, loss is 5.334053211212158 and perplexity is 207.27640889646523
At time: 796.0814590454102 and batch: 600, loss is 5.278594989776611 and perplexity is 196.0941674009634
At time: 797.163506269455 and batch: 650, loss is 5.307949848175049 and perplexity is 201.93580465907675
At time: 798.2693588733673 and batch: 700, loss is 5.322380771636963 and perplexity is 204.8710530336572
At time: 799.3456315994263 and batch: 750, loss is 5.294598360061645 and perplexity is 199.2575800906521
At time: 800.4225432872772 and batch: 800, loss is 5.279296445846557 and perplexity is 196.23176709939773
At time: 801.4995467662811 and batch: 850, loss is 5.238461170196533 and perplexity is 188.37999449965488
At time: 802.5814888477325 and batch: 900, loss is 5.271954545974731 and perplexity is 194.79632898306525
At time: 803.6570253372192 and batch: 950, loss is 5.244848432540894 and perplexity is 189.5870778200821
At time: 804.7339339256287 and batch: 1000, loss is 5.284659376144409 and perplexity is 197.28697135294553
At time: 805.8117518424988 and batch: 1050, loss is 5.246483316421509 and perplexity is 189.89728418418076
At time: 806.8882386684418 and batch: 1100, loss is 5.236577405929565 and perplexity is 188.02546502721998
At time: 807.9640755653381 and batch: 1150, loss is 5.24401083946228 and perplexity is 189.42834748090212
At time: 809.0397410392761 and batch: 1200, loss is 5.217713527679443 and perplexity is 184.5118202233124
At time: 810.1195929050446 and batch: 1250, loss is 5.233665933609009 and perplexity is 187.4788302324077
At time: 811.1993005275726 and batch: 1300, loss is 5.210855855941772 and perplexity is 183.25082740768875
At time: 812.2758996486664 and batch: 1350, loss is 5.191443853378296 and perplexity is 179.72786636852217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23310546875 and perplexity of 187.37378437625952
Finished 26 epochs...
Completing Train Step...
At time: 815.4433927536011 and batch: 50, loss is 5.318542976379394 and perplexity is 204.0863066890005
At time: 816.5512280464172 and batch: 100, loss is 5.332802076339721 and perplexity is 207.01724031429413
At time: 817.6277527809143 and batch: 150, loss is 5.301647443771362 and perplexity is 200.66712561807537
At time: 818.703476190567 and batch: 200, loss is 5.291164865493775 and perplexity is 198.57460344107298
At time: 819.7863893508911 and batch: 250, loss is 5.309224281311035 and perplexity is 202.19332239959252
At time: 820.8626239299774 and batch: 300, loss is 5.327538890838623 and perplexity is 205.93053245769633
At time: 821.938526391983 and batch: 350, loss is 5.329680223464965 and perplexity is 206.37197068997529
At time: 823.0144245624542 and batch: 400, loss is 5.3474398040771485 and perplexity is 210.06978899940333
At time: 824.0912067890167 and batch: 450, loss is 5.321102085113526 and perplexity is 204.60925459383998
At time: 825.1678113937378 and batch: 500, loss is 5.348616733551025 and perplexity is 210.31717187319003
At time: 826.2698035240173 and batch: 550, loss is 5.331698627471924 and perplexity is 206.78893336054506
At time: 827.3465161323547 and batch: 600, loss is 5.276730184555054 and perplexity is 195.7288307204234
At time: 828.4227616786957 and batch: 650, loss is 5.306211376190186 and perplexity is 201.58504989693995
At time: 829.4993455410004 and batch: 700, loss is 5.3211234664916995 and perplexity is 204.61362946846057
At time: 830.5750117301941 and batch: 750, loss is 5.293350296020508 and perplexity is 199.00904899364025
At time: 831.6514847278595 and batch: 800, loss is 5.278056936264038 and perplexity is 195.98868662509403
At time: 832.7284755706787 and batch: 850, loss is 5.237713508605957 and perplexity is 188.2392026522213
At time: 833.8110539913177 and batch: 900, loss is 5.271342611312866 and perplexity is 194.67716282202724
At time: 834.8900668621063 and batch: 950, loss is 5.244802703857422 and perplexity is 189.57840845083106
At time: 835.9663515090942 and batch: 1000, loss is 5.284863481521606 and perplexity is 197.3272427943186
At time: 837.0509390830994 and batch: 1050, loss is 5.247229719161988 and perplexity is 190.0390769481762
At time: 838.1265997886658 and batch: 1100, loss is 5.237569084167481 and perplexity is 188.2120182741706
At time: 839.2024350166321 and batch: 1150, loss is 5.245162734985351 and perplexity is 189.6466748673367
At time: 840.2784495353699 and batch: 1200, loss is 5.219230127334595 and perplexity is 184.7918630890147
At time: 841.3551774024963 and batch: 1250, loss is 5.235398025512695 and perplexity is 187.80384219039945
At time: 842.4344108104706 and batch: 1300, loss is 5.21252776145935 and perplexity is 183.55746173751933
At time: 843.5108826160431 and batch: 1350, loss is 5.192058382034301 and perplexity is 179.83834823634834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232793375651042 and perplexity of 187.31531543558108
Finished 27 epochs...
Completing Train Step...
At time: 846.7175569534302 and batch: 50, loss is 5.316311941146851 and perplexity is 203.63149049243182
At time: 847.793048620224 and batch: 100, loss is 5.330319375991821 and perplexity is 206.50391601861725
At time: 848.8696801662445 and batch: 150, loss is 5.29879433631897 and perplexity is 200.09541670782036
At time: 849.9459772109985 and batch: 200, loss is 5.288532857894897 and perplexity is 198.05264078203757
At time: 851.0218639373779 and batch: 250, loss is 5.3066021347045895 and perplexity is 201.66383636380252
At time: 852.0973012447357 and batch: 300, loss is 5.325124711990356 and perplexity is 205.4339789476853
At time: 853.1997926235199 and batch: 350, loss is 5.327439546585083 and perplexity is 205.9100754588277
At time: 854.2759754657745 and batch: 400, loss is 5.345144758224487 and perplexity is 209.58822202191521
At time: 855.3532552719116 and batch: 450, loss is 5.318844995498657 and perplexity is 204.1479539644597
At time: 856.4292898178101 and batch: 500, loss is 5.346521854400635 and perplexity is 209.87704398319306
At time: 857.5111649036407 and batch: 550, loss is 5.3299691772460935 and perplexity is 206.43161126749524
At time: 858.5869107246399 and batch: 600, loss is 5.275313377380371 and perplexity is 195.45171706343035
At time: 859.6631698608398 and batch: 650, loss is 5.304871892929077 and perplexity is 201.31521085969572
At time: 860.7390866279602 and batch: 700, loss is 5.3201260471344 and perplexity is 204.40964561929223
At time: 861.8152508735657 and batch: 750, loss is 5.29247787475586 and perplexity is 198.83550498019193
At time: 862.8915271759033 and batch: 800, loss is 5.2772024059295655 and perplexity is 195.82127988441547
At time: 863.9687247276306 and batch: 850, loss is 5.2370396900177 and perplexity is 188.1124063021019
At time: 865.0447850227356 and batch: 900, loss is 5.2708750915527345 and perplexity is 194.58616867400016
At time: 866.1217274665833 and batch: 950, loss is 5.24466251373291 and perplexity is 189.55183329297645
At time: 867.1982035636902 and batch: 1000, loss is 5.284978904724121 and perplexity is 197.3500202511236
At time: 868.2747509479523 and batch: 1050, loss is 5.247593736648559 and perplexity is 190.10826708776355
At time: 869.3512599468231 and batch: 1100, loss is 5.238209676742554 and perplexity is 188.3326241210973
At time: 870.4268357753754 and batch: 1150, loss is 5.245851354598999 and perplexity is 189.77731426257597
At time: 871.5024421215057 and batch: 1200, loss is 5.220063133239746 and perplexity is 184.94585993342724
At time: 872.5787634849548 and batch: 1250, loss is 5.236189050674438 and perplexity is 187.9524585269256
At time: 873.654825925827 and batch: 1300, loss is 5.213644113540649 and perplexity is 183.76249091304837
At time: 874.7307887077332 and batch: 1350, loss is 5.192224321365356 and perplexity is 179.86819296769156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232589518229167 and perplexity of 187.27713371024498
Finished 28 epochs...
Completing Train Step...
At time: 877.9152593612671 and batch: 50, loss is 5.31435658454895 and perplexity is 203.23370734464925
At time: 878.9904446601868 and batch: 100, loss is 5.328193349838257 and perplexity is 206.06534965931607
At time: 880.0942449569702 and batch: 150, loss is 5.296451845169067 and perplexity is 199.62724352489752
At time: 881.1700966358185 and batch: 200, loss is 5.286334657669068 and perplexity is 197.61775957544282
At time: 882.2459616661072 and batch: 250, loss is 5.30446756362915 and perplexity is 201.23382967493168
At time: 883.3218765258789 and batch: 300, loss is 5.323107204437256 and perplexity is 205.01993215520295
At time: 884.406266450882 and batch: 350, loss is 5.325505657196045 and perplexity is 205.5122529451564
At time: 885.4901452064514 and batch: 400, loss is 5.343300094604492 and perplexity is 209.2019586261199
At time: 886.5649983882904 and batch: 450, loss is 5.317005681991577 and perplexity is 203.77280698750351
At time: 887.6407401561737 and batch: 500, loss is 5.344752721786499 and perplexity is 209.50607190588102
At time: 888.7165656089783 and batch: 550, loss is 5.328536605834961 and perplexity is 206.1360949674805
At time: 889.7928800582886 and batch: 600, loss is 5.274231033325195 and perplexity is 195.24028550088073
At time: 890.8685927391052 and batch: 650, loss is 5.303844728469849 and perplexity is 201.10853319414647
At time: 891.945036649704 and batch: 700, loss is 5.3192596530914305 and perplexity is 204.23262301673972
At time: 893.0224387645721 and batch: 750, loss is 5.2916456317901615 and perplexity is 198.6700943702967
At time: 894.0977122783661 and batch: 800, loss is 5.276359453201294 and perplexity is 195.6562813550337
At time: 895.1741619110107 and batch: 850, loss is 5.236451120376587 and perplexity is 188.00172162665078
At time: 896.250284910202 and batch: 900, loss is 5.270256786346436 and perplexity is 194.46589222044585
At time: 897.3350648880005 and batch: 950, loss is 5.244432344436645 and perplexity is 189.50820930154595
At time: 898.4111475944519 and batch: 1000, loss is 5.28492169380188 and perplexity is 197.33872999742664
At time: 899.4870338439941 and batch: 1050, loss is 5.247750730514526 and perplexity is 190.1381152624948
At time: 900.5626246929169 and batch: 1100, loss is 5.238507795333862 and perplexity is 188.38877794753157
At time: 901.6378390789032 and batch: 1150, loss is 5.246114149093628 and perplexity is 189.8271932496441
At time: 902.7136373519897 and batch: 1200, loss is 5.220665922164917 and perplexity is 185.05737685675788
At time: 903.7898874282837 and batch: 1250, loss is 5.236730508804321 and perplexity is 188.05425447025996
At time: 904.8662710189819 and batch: 1300, loss is 5.214154987335205 and perplexity is 183.85639433843548
At time: 905.9453172683716 and batch: 1350, loss is 5.1922287940979 and perplexity is 179.8689974718111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232420247395833 and perplexity of 187.24543583659587
Finished 29 epochs...
Completing Train Step...
At time: 909.1412193775177 and batch: 50, loss is 5.312687950134277 and perplexity is 202.8948673649986
At time: 910.2445435523987 and batch: 100, loss is 5.32633378982544 and perplexity is 205.68251483754452
At time: 911.3224017620087 and batch: 150, loss is 5.294453477859497 and perplexity is 199.22871330484608
At time: 912.3991091251373 and batch: 200, loss is 5.2844071865081785 and perplexity is 197.2372238965671
At time: 913.4753277301788 and batch: 250, loss is 5.302662963867188 and perplexity is 200.87101062385054
At time: 914.5515007972717 and batch: 300, loss is 5.32144118309021 and perplexity is 204.67864894316034
At time: 915.6282322406769 and batch: 350, loss is 5.323917760848999 and perplexity is 205.18617974316854
At time: 916.7053864002228 and batch: 400, loss is 5.341783151626587 and perplexity is 208.8848517613422
At time: 917.7823569774628 and batch: 450, loss is 5.315461711883545 and perplexity is 203.45843062099334
At time: 918.8589961528778 and batch: 500, loss is 5.343181095123291 and perplexity is 209.17706518275986
At time: 919.9357118606567 and batch: 550, loss is 5.32727988243103 and perplexity is 205.8772016252749
At time: 921.012640953064 and batch: 600, loss is 5.273273477554321 and perplexity is 195.0534215194123
At time: 922.0912053585052 and batch: 650, loss is 5.302827816009522 and perplexity is 200.904127369893
At time: 923.1736850738525 and batch: 700, loss is 5.318501996994018 and perplexity is 204.07794352894857
At time: 924.2498605251312 and batch: 750, loss is 5.290910987854004 and perplexity is 198.5241961883409
At time: 925.3278777599335 and batch: 800, loss is 5.275607261657715 and perplexity is 195.50916569126593
At time: 926.4038603305817 and batch: 850, loss is 5.235980777740479 and perplexity is 187.91331719312498
At time: 927.4804229736328 and batch: 900, loss is 5.269701271057129 and perplexity is 194.35789344433178
At time: 928.5571632385254 and batch: 950, loss is 5.244131288528442 and perplexity is 189.45116532262705
At time: 929.633368730545 and batch: 1000, loss is 5.284767713546753 and perplexity is 197.3083460687578
At time: 930.7102506160736 and batch: 1050, loss is 5.247758836746216 and perplexity is 190.1396565723572
At time: 931.7868521213531 and batch: 1100, loss is 5.238642845153809 and perplexity is 188.41422153611072
At time: 932.8631901741028 and batch: 1150, loss is 5.246354169845581 and perplexity is 189.87276118371528
At time: 933.9392762184143 and batch: 1200, loss is 5.221035604476929 and perplexity is 185.12580194268173
At time: 935.0420894622803 and batch: 1250, loss is 5.237250804901123 and perplexity is 188.15212382316116
At time: 936.1185538768768 and batch: 1300, loss is 5.214614486694336 and perplexity is 183.94089564646762
At time: 937.1964249610901 and batch: 1350, loss is 5.192046632766724 and perplexity is 179.8362352798871
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23233154296875 and perplexity of 187.2288270741324
Finished 30 epochs...
Completing Train Step...
At time: 940.4041104316711 and batch: 50, loss is 5.311271800994873 and perplexity is 202.60774132782066
At time: 941.5096890926361 and batch: 100, loss is 5.324681739807129 and perplexity is 205.34299756212107
At time: 942.5875062942505 and batch: 150, loss is 5.292715826034546 and perplexity is 198.8828237724105
At time: 943.6656541824341 and batch: 200, loss is 5.28276460647583 and perplexity is 196.91351190516843
At time: 944.7433323860168 and batch: 250, loss is 5.30112774848938 and perplexity is 200.56286695335743
At time: 945.8227350711823 and batch: 300, loss is 5.320033416748047 and perplexity is 204.39071195177436
At time: 946.9009339809418 and batch: 350, loss is 5.322649240493774 and perplexity is 204.9260619148142
At time: 947.9789502620697 and batch: 400, loss is 5.340488996505737 and perplexity is 208.61469720942105
At time: 949.0581233501434 and batch: 450, loss is 5.314126520156861 and perplexity is 203.18695588344644
At time: 950.1343333721161 and batch: 500, loss is 5.341857194900513 and perplexity is 208.90031885225
At time: 951.2121307849884 and batch: 550, loss is 5.326177606582641 and perplexity is 205.65039318388762
At time: 952.2886981964111 and batch: 600, loss is 5.272430953979492 and perplexity is 194.88915362293585
At time: 953.3654627799988 and batch: 650, loss is 5.30205361366272 and perplexity is 200.74864711735526
At time: 954.4424259662628 and batch: 700, loss is 5.3179143524169925 and perplexity is 203.95805346196713
At time: 955.5202233791351 and batch: 750, loss is 5.290248174667358 and perplexity is 198.3926553315619
At time: 956.5973317623138 and batch: 800, loss is 5.275005941390991 and perplexity is 195.39163740721645
At time: 957.6740574836731 and batch: 850, loss is 5.235527467727661 and perplexity is 187.82815350913327
At time: 958.7501862049103 and batch: 900, loss is 5.269123649597168 and perplexity is 194.24566057134388
At time: 959.8268051147461 and batch: 950, loss is 5.243791666030884 and perplexity is 189.38683436943262
At time: 960.903174161911 and batch: 1000, loss is 5.284563703536987 and perplexity is 197.26809729686525
At time: 962.0239675045013 and batch: 1050, loss is 5.247655658721924 and perplexity is 190.12003935030313
At time: 963.1002104282379 and batch: 1100, loss is 5.23861008644104 and perplexity is 188.40804942984147
At time: 964.1765913963318 and batch: 1150, loss is 5.246300067901611 and perplexity is 189.86248897610398
At time: 965.2601146697998 and batch: 1200, loss is 5.221082286834717 and perplexity is 185.13444425332403
At time: 966.3372292518616 and batch: 1250, loss is 5.237401599884033 and perplexity is 188.18049835877267
At time: 967.4136672019958 and batch: 1300, loss is 5.2148017311096195 and perplexity is 183.97534077664824
At time: 968.4897882938385 and batch: 1350, loss is 5.191828346252441 and perplexity is 179.79698373914297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232249348958334 and perplexity of 187.2134386183977
Finished 31 epochs...
Completing Train Step...
At time: 971.6913142204285 and batch: 50, loss is 5.309947662353515 and perplexity is 202.3396381305651
At time: 972.7676041126251 and batch: 100, loss is 5.3232083415985105 and perplexity is 205.0406683377234
At time: 973.8442163467407 and batch: 150, loss is 5.2911336135864255 and perplexity is 198.5683977029354
At time: 974.9279325008392 and batch: 200, loss is 5.281279859542846 and perplexity is 196.62136211022994
At time: 976.0047559738159 and batch: 250, loss is 5.299624967575073 and perplexity is 200.26169126200168
At time: 977.080513715744 and batch: 300, loss is 5.318774423599243 and perplexity is 204.1335473639435
At time: 978.1651926040649 and batch: 350, loss is 5.3214904308319095 and perplexity is 204.6887291526067
At time: 979.2414617538452 and batch: 400, loss is 5.339316539764404 and perplexity is 208.37024883191341
At time: 980.3190302848816 and batch: 450, loss is 5.312878980636596 and perplexity is 202.93363017575098
At time: 981.3953447341919 and batch: 500, loss is 5.3406446743011475 and perplexity is 208.64717641365266
At time: 982.4716801643372 and batch: 550, loss is 5.325064191818237 and perplexity is 205.42154642413328
At time: 983.5477893352509 and batch: 600, loss is 5.2717209815979 and perplexity is 194.75083681275933
At time: 984.6237046718597 and batch: 650, loss is 5.301229467391968 and perplexity is 200.58326902570442
At time: 985.6999156475067 and batch: 700, loss is 5.317283296585083 and perplexity is 203.8293851455808
At time: 986.7762866020203 and batch: 750, loss is 5.289635210037232 and perplexity is 198.2710849139563
At time: 987.851949930191 and batch: 800, loss is 5.27435269355774 and perplexity is 195.26403992437182
At time: 988.9550695419312 and batch: 850, loss is 5.235024900436401 and perplexity is 187.73378093907158
At time: 990.0324733257294 and batch: 900, loss is 5.268472175598145 and perplexity is 194.1191557858222
At time: 991.1087226867676 and batch: 950, loss is 5.243408899307251 and perplexity is 189.3143572631391
At time: 992.1844141483307 and batch: 1000, loss is 5.284276542663574 and perplexity is 197.21145775046892
At time: 993.2605237960815 and batch: 1050, loss is 5.247509536743164 and perplexity is 190.09226066353904
At time: 994.3371472358704 and batch: 1100, loss is 5.238461856842041 and perplexity is 188.38012384997623
At time: 995.4134213924408 and batch: 1150, loss is 5.246268043518066 and perplexity is 189.85640884429296
At time: 996.4970285892487 and batch: 1200, loss is 5.22098105430603 and perplexity is 185.1157035739844
At time: 997.5810360908508 and batch: 1250, loss is 5.237431583404541 and perplexity is 188.18614075719333
At time: 998.6578104496002 and batch: 1300, loss is 5.214838857650757 and perplexity is 183.9821712715014
At time: 999.7356436252594 and batch: 1350, loss is 5.191537485122681 and perplexity is 179.74469539001794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23216064453125 and perplexity of 187.19683269410308
Finished 32 epochs...
Completing Train Step...
At time: 1002.9333121776581 and batch: 50, loss is 5.308682546615601 and perplexity is 202.08381692579886
At time: 1004.0097308158875 and batch: 100, loss is 5.321803827285766 and perplexity is 204.75288792750868
At time: 1005.0866491794586 and batch: 150, loss is 5.289780750274658 and perplexity is 198.29994343471645
At time: 1006.1688821315765 and batch: 200, loss is 5.27990683555603 and perplexity is 196.35158151372963
At time: 1007.2463586330414 and batch: 250, loss is 5.298341197967529 and perplexity is 200.0047663406926
At time: 1008.3237273693085 and batch: 300, loss is 5.317592678070068 and perplexity is 203.8924559394055
At time: 1009.401116847992 and batch: 350, loss is 5.320483293533325 and perplexity is 204.4826832745382
At time: 1010.478874206543 and batch: 400, loss is 5.338222131729126 and perplexity is 208.14233149730873
At time: 1011.5555441379547 and batch: 450, loss is 5.311785955429077 and perplexity is 202.71193978118137
At time: 1012.6316814422607 and batch: 500, loss is 5.339534549713135 and perplexity is 208.41568057128399
At time: 1013.7081346511841 and batch: 550, loss is 5.324166507720947 and perplexity is 205.23722551202113
At time: 1014.7853016853333 and batch: 600, loss is 5.27096734046936 and perplexity is 194.6041198652269
At time: 1015.8631763458252 and batch: 650, loss is 5.300496425628662 and perplexity is 200.4362869910548
At time: 1016.9929580688477 and batch: 700, loss is 5.316692867279053 and perplexity is 203.70907382432074
At time: 1018.0694243907928 and batch: 750, loss is 5.288997812271118 and perplexity is 198.14474763517416
At time: 1019.1511812210083 and batch: 800, loss is 5.273731393814087 and perplexity is 195.14276010588355
At time: 1020.2312908172607 and batch: 850, loss is 5.2345570373535155 and perplexity is 187.64596777742975
At time: 1021.3082630634308 and batch: 900, loss is 5.267885494232178 and perplexity is 194.00530309523697
At time: 1022.3910129070282 and batch: 950, loss is 5.243005275726318 and perplexity is 189.23796094305382
At time: 1023.4681234359741 and batch: 1000, loss is 5.283986501693725 and perplexity is 197.1542666422809
At time: 1024.545107126236 and batch: 1050, loss is 5.247315492630005 and perplexity is 190.05537795795186
At time: 1025.6223313808441 and batch: 1100, loss is 5.23830207824707 and perplexity is 188.3500271429359
At time: 1026.6991515159607 and batch: 1150, loss is 5.246177606582641 and perplexity is 189.83923958888542
At time: 1027.7761731147766 and batch: 1200, loss is 5.220853710174561 and perplexity is 185.09213167639476
At time: 1028.8532285690308 and batch: 1250, loss is 5.237388658523559 and perplexity is 188.1780630628673
At time: 1029.9315559864044 and batch: 1300, loss is 5.2148917865753175 and perplexity is 183.99190950768002
At time: 1031.0085806846619 and batch: 1350, loss is 5.191215219497681 and perplexity is 179.6867791861197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232124837239583 and perplexity of 187.19012980252262
Finished 33 epochs...
Completing Train Step...
At time: 1034.192673444748 and batch: 50, loss is 5.30754433631897 and perplexity is 201.85393389702486
At time: 1035.2955658435822 and batch: 100, loss is 5.320609045028687 and perplexity is 204.5083988945905
At time: 1036.3732314109802 and batch: 150, loss is 5.2885082340240475 and perplexity is 198.0477640194321
At time: 1037.4519727230072 and batch: 200, loss is 5.278620414733886 and perplexity is 196.09915315017253
At time: 1038.5289425849915 and batch: 250, loss is 5.297119207382202 and perplexity is 199.76051166805365
At time: 1039.6067519187927 and batch: 300, loss is 5.316558074951172 and perplexity is 203.68161725455857
At time: 1040.6833791732788 and batch: 350, loss is 5.319526109695435 and perplexity is 204.2870493987081
At time: 1041.7603559494019 and batch: 400, loss is 5.3372854900360105 and perplexity is 207.94746798441747
At time: 1042.8378694057465 and batch: 450, loss is 5.310756340026855 and perplexity is 202.50333185716318
At time: 1043.9408206939697 and batch: 500, loss is 5.338527593612671 and perplexity is 208.20592075748647
At time: 1045.0177729129791 and batch: 550, loss is 5.323297109603882 and perplexity is 205.0588701967311
At time: 1046.094923734665 and batch: 600, loss is 5.270334272384644 and perplexity is 194.48096119581066
At time: 1047.171455860138 and batch: 650, loss is 5.2997777557373045 and perplexity is 200.29229121537074
At time: 1048.2481191158295 and batch: 700, loss is 5.316138067245483 and perplexity is 203.59608736866744
At time: 1049.3253355026245 and batch: 750, loss is 5.288357563018799 and perplexity is 198.01792621164282
At time: 1050.4023900032043 and batch: 800, loss is 5.27304895401001 and perplexity is 195.00963234991644
At time: 1051.4794328212738 and batch: 850, loss is 5.234043684005737 and perplexity is 187.54966381277035
At time: 1052.556216955185 and batch: 900, loss is 5.267206373214722 and perplexity is 193.87359474442383
At time: 1053.639889717102 and batch: 950, loss is 5.242569189071656 and perplexity is 189.15545478495574
At time: 1054.7163066864014 and batch: 1000, loss is 5.2835501766204835 and perplexity is 197.06826205679127
At time: 1055.7970035076141 and batch: 1050, loss is 5.246953639984131 and perplexity is 189.98661835774715
At time: 1056.877762556076 and batch: 1100, loss is 5.237944030761719 and perplexity is 188.28260096095934
At time: 1057.955946445465 and batch: 1150, loss is 5.246013984680176 and perplexity is 189.80818027240286
At time: 1059.0330173969269 and batch: 1200, loss is 5.220656328201294 and perplexity is 185.05560143153272
At time: 1060.1132073402405 and batch: 1250, loss is 5.237252235412598 and perplexity is 188.1523929771258
At time: 1061.1921226978302 and batch: 1300, loss is 5.214756288528442 and perplexity is 183.96698065224467
At time: 1062.2777643203735 and batch: 1350, loss is 5.190827140808105 and perplexity is 179.6170601054388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23206298828125 and perplexity of 187.17855264600524
Finished 34 epochs...
Completing Train Step...
At time: 1065.4526646137238 and batch: 50, loss is 5.306372241973877 and perplexity is 201.61748064240075
At time: 1066.5645744800568 and batch: 100, loss is 5.319328174591065 and perplexity is 204.24661782181013
At time: 1067.641039609909 and batch: 150, loss is 5.287263011932373 and perplexity is 197.80130404901453
At time: 1068.720451116562 and batch: 200, loss is 5.277331457138062 and perplexity is 195.84655248792882
At time: 1069.797610282898 and batch: 250, loss is 5.295889015197754 and perplexity is 199.51491894193708
At time: 1070.9140298366547 and batch: 300, loss is 5.315162162780762 and perplexity is 203.39749395786424
At time: 1071.9913005828857 and batch: 350, loss is 5.3185517120361325 and perplexity is 204.08808952470787
At time: 1073.0747230052948 and batch: 400, loss is 5.33629487991333 and perplexity is 207.7415751142641
At time: 1074.153216600418 and batch: 450, loss is 5.309619588851929 and perplexity is 202.27326674491556
At time: 1075.2296407222748 and batch: 500, loss is 5.337532033920288 and perplexity is 207.99874248134716
At time: 1076.306279182434 and batch: 550, loss is 5.322397937774658 and perplexity is 204.87456990854886
At time: 1077.3835940361023 and batch: 600, loss is 5.269555635452271 and perplexity is 194.3295900760001
At time: 1078.4608881473541 and batch: 650, loss is 5.298965864181518 and perplexity is 200.1297415907067
At time: 1079.5373423099518 and batch: 700, loss is 5.315439949035644 and perplexity is 203.4540028342944
At time: 1080.6136980056763 and batch: 750, loss is 5.287600574493408 and perplexity is 197.86808563463282
At time: 1081.6902959346771 and batch: 800, loss is 5.272322044372559 and perplexity is 194.86792947759693
At time: 1082.7671132087708 and batch: 850, loss is 5.233458957672119 and perplexity is 187.44003064130268
At time: 1083.8439638614655 and batch: 900, loss is 5.266483173370362 and perplexity is 193.7334360783506
At time: 1084.920821905136 and batch: 950, loss is 5.2420725440979 and perplexity is 189.06153500340258
At time: 1085.999116897583 and batch: 1000, loss is 5.283194437026977 and perplexity is 196.99816954143483
At time: 1087.0758066177368 and batch: 1050, loss is 5.246585988998413 and perplexity is 189.9167824286455
At time: 1088.1519830226898 and batch: 1100, loss is 5.237638282775879 and perplexity is 188.225042734551
At time: 1089.2286303043365 and batch: 1150, loss is 5.245722408294678 and perplexity is 189.75284475691785
At time: 1090.3054223060608 and batch: 1200, loss is 5.220415563583374 and perplexity is 185.01105195354435
At time: 1091.3823871612549 and batch: 1250, loss is 5.237120275497436 and perplexity is 188.12756604142734
At time: 1092.4590337276459 and batch: 1300, loss is 5.214702625274658 and perplexity is 183.95710865035818
At time: 1093.5358374118805 and batch: 1350, loss is 5.1905246925354005 and perplexity is 179.56274345026492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232060546875 and perplexity of 187.17809566767485
Finished 35 epochs...
Completing Train Step...
At time: 1096.7375810146332 and batch: 50, loss is 5.305274381637573 and perplexity is 201.39625426734943
At time: 1097.8140738010406 and batch: 100, loss is 5.318197526931763 and perplexity is 204.01581736303604
At time: 1098.9165513515472 and batch: 150, loss is 5.286116685867309 and perplexity is 197.57468917056613
At time: 1099.9928092956543 and batch: 200, loss is 5.276138973236084 and perplexity is 195.61314782014242
At time: 1101.0692265033722 and batch: 250, loss is 5.294857273101806 and perplexity is 199.30917715577684
At time: 1102.146225452423 and batch: 300, loss is 5.314189872741699 and perplexity is 203.19982871006627
At time: 1103.2225394248962 and batch: 350, loss is 5.3176571559906005 and perplexity is 203.90560292481732
At time: 1104.2992436885834 and batch: 400, loss is 5.335411329269409 and perplexity is 207.55810597587592
At time: 1105.3754506111145 and batch: 450, loss is 5.3086652755737305 and perplexity is 202.0803267578749
At time: 1106.4519891738892 and batch: 500, loss is 5.33656002998352 and perplexity is 207.79666511072244
At time: 1107.5287947654724 and batch: 550, loss is 5.32152756690979 and perplexity is 204.6963306303374
At time: 1108.6060292720795 and batch: 600, loss is 5.268904657363891 and perplexity is 194.20312693776884
At time: 1109.6828491687775 and batch: 650, loss is 5.298253726959229 and perplexity is 199.98727248722955
At time: 1110.7653665542603 and batch: 700, loss is 5.314892158508301 and perplexity is 203.3425831788938
At time: 1111.8436124324799 and batch: 750, loss is 5.286915473937988 and perplexity is 197.73257252461855
At time: 1112.9243783950806 and batch: 800, loss is 5.271697931289673 and perplexity is 194.74634779768002
At time: 1114.001259803772 and batch: 850, loss is 5.232934875488281 and perplexity is 187.3418223975488
At time: 1115.084302663803 and batch: 900, loss is 5.265793809890747 and perplexity is 193.599929345358
At time: 1116.1606135368347 and batch: 950, loss is 5.241572456359863 and perplexity is 188.96701128505913
At time: 1117.2369558811188 and batch: 1000, loss is 5.282774887084961 and perplexity is 196.91553630642298
At time: 1118.3132100105286 and batch: 1050, loss is 5.246239166259766 and perplexity is 189.8509263908943
At time: 1119.3946468830109 and batch: 1100, loss is 5.237237329483032 and perplexity is 188.1495884117109
At time: 1120.4720075130463 and batch: 1150, loss is 5.245379371643066 and perplexity is 189.687763739644
At time: 1121.5492715835571 and batch: 1200, loss is 5.220113830566406 and perplexity is 184.95523643178245
At time: 1122.6266045570374 and batch: 1250, loss is 5.2368958377838135 and perplexity is 188.085347858489
At time: 1123.7104098796844 and batch: 1300, loss is 5.214529819488526 and perplexity is 183.9253225440739
At time: 1124.7878761291504 and batch: 1350, loss is 5.1900722026824955 and perplexity is 179.48151151059412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.23201171875 and perplexity of 187.16895633535233
Finished 36 epochs...
Completing Train Step...
At time: 1127.989441394806 and batch: 50, loss is 5.304235477447509 and perplexity is 201.18713150299527
At time: 1129.0688269138336 and batch: 100, loss is 5.317135105133056 and perplexity is 203.79918161103842
At time: 1130.148877620697 and batch: 150, loss is 5.284931468963623 and perplexity is 197.34065902485884
At time: 1131.224859237671 and batch: 200, loss is 5.274938592910766 and perplexity is 195.37847852050893
At time: 1132.3098599910736 and batch: 250, loss is 5.29376745223999 and perplexity is 199.09208417427809
At time: 1133.3857414722443 and batch: 300, loss is 5.313170557022095 and perplexity is 202.9928094573549
At time: 1134.4621908664703 and batch: 350, loss is 5.316888799667359 and perplexity is 203.74899094007492
At time: 1135.538969039917 and batch: 400, loss is 5.334630842208862 and perplexity is 207.39617276145975
At time: 1136.616250038147 and batch: 450, loss is 5.307742738723755 and perplexity is 201.89398617602822
At time: 1137.6928622722626 and batch: 500, loss is 5.3356622695922855 and perplexity is 207.61019720962733
At time: 1138.76899600029 and batch: 550, loss is 5.32070876121521 and perplexity is 204.52879270902
At time: 1139.8532717227936 and batch: 600, loss is 5.26826470375061 and perplexity is 194.07888570352802
At time: 1140.9292330741882 and batch: 650, loss is 5.297586994171143 and perplexity is 199.85397885601736
At time: 1142.0054743289948 and batch: 700, loss is 5.314323291778565 and perplexity is 203.2269412441279
At time: 1143.0819728374481 and batch: 750, loss is 5.286275024414063 and perplexity is 197.60597533656227
At time: 1144.1581106185913 and batch: 800, loss is 5.271163578033447 and perplexity is 194.64231225093843
At time: 1145.234275341034 and batch: 850, loss is 5.232351264953613 and perplexity is 187.23251963463807
At time: 1146.3111443519592 and batch: 900, loss is 5.265146675109864 and perplexity is 193.47468462697967
At time: 1147.3907406330109 and batch: 950, loss is 5.24108024597168 and perplexity is 188.87402264594505
At time: 1148.4708890914917 and batch: 1000, loss is 5.282310466766358 and perplexity is 196.82410596301165
At time: 1149.5477411746979 and batch: 1050, loss is 5.245865383148193 and perplexity is 189.77997658163926
At time: 1150.624085187912 and batch: 1100, loss is 5.236835355758667 and perplexity is 188.0739724197584
At time: 1151.7006795406342 and batch: 1150, loss is 5.245112648010254 and perplexity is 189.63717627693515
At time: 1152.8366396427155 and batch: 1200, loss is 5.2199122333526615 and perplexity is 184.917953729621
At time: 1153.9121766090393 and batch: 1250, loss is 5.2366397190094 and perplexity is 188.03718183808468
At time: 1154.9959032535553 and batch: 1300, loss is 5.214435834884643 and perplexity is 183.9080372077811
At time: 1156.0726099014282 and batch: 1350, loss is 5.189650459289551 and perplexity is 179.405832328678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.232018636067708 and perplexity of 187.17025104696634
Annealing...
Finished 37 epochs...
Completing Train Step...
At time: 1159.2470026016235 and batch: 50, loss is 5.304456195831299 and perplexity is 201.23154210243743
At time: 1160.349482536316 and batch: 100, loss is 5.317362432479858 and perplexity is 203.8455160046123
At time: 1161.4259469509125 and batch: 150, loss is 5.28541262626648 and perplexity is 197.43563377116325
At time: 1162.5102286338806 and batch: 200, loss is 5.27614987373352 and perplexity is 195.61528011238022
At time: 1163.5876257419586 and batch: 250, loss is 5.293380708694458 and perplexity is 199.0151014829961
At time: 1164.6701979637146 and batch: 300, loss is 5.313235063552856 and perplexity is 203.0059042416075
At time: 1165.7466361522675 and batch: 350, loss is 5.316660785675049 and perplexity is 203.70253861531293
At time: 1166.8233087062836 and batch: 400, loss is 5.334527406692505 and perplexity is 207.37472174065746
At time: 1167.8994162082672 and batch: 450, loss is 5.3065762424469 and perplexity is 201.6586148993827
At time: 1168.9762511253357 and batch: 500, loss is 5.3333940505981445 and perplexity is 207.139825471659
At time: 1170.052256822586 and batch: 550, loss is 5.316942176818848 and perplexity is 203.75986677108793
At time: 1171.1286239624023 and batch: 600, loss is 5.2642849349975585 and perplexity is 193.30803154665605
At time: 1172.2042517662048 and batch: 650, loss is 5.2938447761535645 and perplexity is 199.10747934858802
At time: 1173.2804656028748 and batch: 700, loss is 5.309198846817017 and perplexity is 202.1881797801436
At time: 1174.3566892147064 and batch: 750, loss is 5.281563291549682 and perplexity is 196.6770987958869
At time: 1175.4324057102203 and batch: 800, loss is 5.266748628616333 and perplexity is 193.78487046173905
At time: 1176.5089781284332 and batch: 850, loss is 5.225460176467895 and perplexity is 185.94671914514663
At time: 1177.5865108966827 and batch: 900, loss is 5.256224679946899 and perplexity is 191.75618206203896
At time: 1178.6627416610718 and batch: 950, loss is 5.231469593048096 and perplexity is 187.06751473305874
At time: 1179.7463018894196 and batch: 1000, loss is 5.272868318557739 and perplexity is 194.97440987808912
At time: 1180.853835105896 and batch: 1050, loss is 5.235677824020386 and perplexity is 187.8563967771876
At time: 1181.9373393058777 and batch: 1100, loss is 5.22659821510315 and perplexity is 186.1584541540908
At time: 1183.014240026474 and batch: 1150, loss is 5.234651279449463 and perplexity is 187.66365276005104
At time: 1184.0916996002197 and batch: 1200, loss is 5.208481311798096 and perplexity is 182.81620644618945
At time: 1185.1689615249634 and batch: 1250, loss is 5.225210580825806 and perplexity is 185.9003134459582
At time: 1186.2453792095184 and batch: 1300, loss is 5.203759202957153 and perplexity is 181.95496346336878
At time: 1187.3229975700378 and batch: 1350, loss is 5.181143388748169 and perplexity is 177.8860877102068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227928873697917 and perplexity of 186.40633238517339
Finished 38 epochs...
Completing Train Step...
At time: 1190.5109536647797 and batch: 50, loss is 5.30284782409668 and perplexity is 200.90814711739736
At time: 1191.6165523529053 and batch: 100, loss is 5.315642929077148 and perplexity is 203.49530412776116
At time: 1192.6923847198486 and batch: 150, loss is 5.283807926177978 and perplexity is 197.11906286079378
At time: 1193.7685899734497 and batch: 200, loss is 5.274591388702393 and perplexity is 195.31065406569044
At time: 1194.8449065685272 and batch: 250, loss is 5.2919798183441165 and perplexity is 198.73649833954707
At time: 1195.921656370163 and batch: 300, loss is 5.311951227188111 and perplexity is 202.74544510871212
At time: 1197.0057444572449 and batch: 350, loss is 5.315270566940308 and perplexity is 203.4195442874026
At time: 1198.085193157196 and batch: 400, loss is 5.333191804885864 and perplexity is 207.09793656618336
At time: 1199.166955947876 and batch: 450, loss is 5.30554612159729 and perplexity is 201.45098911385693
At time: 1200.2427933216095 and batch: 500, loss is 5.332509059906005 and perplexity is 206.95658974705995
At time: 1201.318779706955 and batch: 550, loss is 5.316207046508789 and perplexity is 203.61013176116643
At time: 1202.394734621048 and batch: 600, loss is 5.26366774559021 and perplexity is 193.18876068737163
At time: 1203.4709587097168 and batch: 650, loss is 5.293160390853882 and perplexity is 198.97125973533232
At time: 1204.546733379364 and batch: 700, loss is 5.308743238449097 and perplexity is 202.09608213536316
At time: 1205.6241087913513 and batch: 750, loss is 5.28110258102417 and perplexity is 196.58650845590827
At time: 1206.7025198936462 and batch: 800, loss is 5.266292886734009 and perplexity is 193.6965747016751
At time: 1207.8116347789764 and batch: 850, loss is 5.225247163772583 and perplexity is 185.9071143516286
At time: 1208.888239145279 and batch: 900, loss is 5.256198244094849 and perplexity is 191.75111289098442
At time: 1209.9649424552917 and batch: 950, loss is 5.231380138397217 and perplexity is 187.05078142228496
At time: 1211.0424604415894 and batch: 1000, loss is 5.272874584197998 and perplexity is 194.97563152142834
At time: 1212.1192638874054 and batch: 1050, loss is 5.235789842605591 and perplexity is 187.87744136364668
At time: 1213.1965794563293 and batch: 1100, loss is 5.226930990219116 and perplexity is 186.22041336392988
At time: 1214.2736325263977 and batch: 1150, loss is 5.235259876251221 and perplexity is 187.77789902035502
At time: 1215.349624156952 and batch: 1200, loss is 5.209172801971436 and perplexity is 182.9426657741266
At time: 1216.425980091095 and batch: 1250, loss is 5.2258107948303225 and perplexity is 186.01192691016388
At time: 1217.506718158722 and batch: 1300, loss is 5.204271020889283 and perplexity is 182.04811511281812
At time: 1218.5858483314514 and batch: 1350, loss is 5.18145793914795 and perplexity is 177.94205065133272
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.22765625 and perplexity of 186.35552052809626
Finished 39 epochs...
Completing Train Step...
At time: 1221.7807760238647 and batch: 50, loss is 5.30213770866394 and perplexity is 200.76552978494362
At time: 1222.8579366207123 and batch: 100, loss is 5.314740800857544 and perplexity is 203.31180805228922
At time: 1223.9349875450134 and batch: 150, loss is 5.282880630493164 and perplexity is 196.93635992732106
At time: 1225.0117197036743 and batch: 200, loss is 5.273647031784058 and perplexity is 195.12629816088685
At time: 1226.0957326889038 and batch: 250, loss is 5.291133451461792 and perplexity is 198.5683655101093
At time: 1227.176676273346 and batch: 300, loss is 5.311074504852295 and perplexity is 202.56777154507185
At time: 1228.2573380470276 and batch: 350, loss is 5.314460744857788 and perplexity is 203.2548773328898
At time: 1229.3383343219757 and batch: 400, loss is 5.3324081993103025 and perplexity is 206.9357170347682
At time: 1230.418699979782 and batch: 450, loss is 5.304948825836181 and perplexity is 201.33069921988616
At time: 1231.4952733516693 and batch: 500, loss is 5.33192174911499 and perplexity is 206.83507759482166
At time: 1232.5717468261719 and batch: 550, loss is 5.3157723903656 and perplexity is 203.52165059741463
At time: 1233.6489584445953 and batch: 600, loss is 5.263269824981689 and perplexity is 193.11190219096355
At time: 1234.7521393299103 and batch: 650, loss is 5.292774085998535 and perplexity is 198.89441101609444
At time: 1235.8296966552734 and batch: 700, loss is 5.308477201461792 and perplexity is 202.04232425363531
At time: 1236.9064321517944 and batch: 750, loss is 5.280855283737183 and perplexity is 196.53789915643057
At time: 1237.9909415245056 and batch: 800, loss is 5.26614107131958 and perplexity is 193.6671708079519
At time: 1239.0682246685028 and batch: 850, loss is 5.225201120376587 and perplexity is 185.89855475380213
At time: 1240.1526265144348 and batch: 900, loss is 5.256280126571656 and perplexity is 191.76681458987665
At time: 1241.2303376197815 and batch: 950, loss is 5.231413631439209 and perplexity is 187.05704642687826
At time: 1242.3139991760254 and batch: 1000, loss is 5.272953939437866 and perplexity is 194.99110447335795
At time: 1243.3913288116455 and batch: 1050, loss is 5.2359117412567135 and perplexity is 187.90034476624382
At time: 1244.4682812690735 and batch: 1100, loss is 5.227195472717285 and perplexity is 186.26967191779198
At time: 1245.544807434082 and batch: 1150, loss is 5.235693464279175 and perplexity is 187.85933492282487
At time: 1246.6219644546509 and batch: 1200, loss is 5.209604320526123 and perplexity is 183.0216259640203
At time: 1247.6989555358887 and batch: 1250, loss is 5.226166801452637 and perplexity is 186.0781601770146
At time: 1248.7758021354675 and batch: 1300, loss is 5.20455924987793 and perplexity is 182.10059421955881
At time: 1249.85200381279 and batch: 1350, loss is 5.181570291519165 and perplexity is 177.9620439857906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227483317057292 and perplexity of 186.32329630593654
Finished 40 epochs...
Completing Train Step...
At time: 1253.070538520813 and batch: 50, loss is 5.301549263000489 and perplexity is 200.64742493212336
At time: 1254.147411108017 and batch: 100, loss is 5.314030313491822 and perplexity is 203.16740888433236
At time: 1255.2247490882874 and batch: 150, loss is 5.282147722244263 and perplexity is 196.79207652432842
At time: 1256.3017137050629 and batch: 200, loss is 5.272947750091553 and perplexity is 194.9898976096191
At time: 1257.387403011322 and batch: 250, loss is 5.290478973388672 and perplexity is 198.438449387132
At time: 1258.4652335643768 and batch: 300, loss is 5.310453338623047 and perplexity is 202.4419823582961
At time: 1259.5481541156769 and batch: 350, loss is 5.313874530792236 and perplexity is 203.13576138203925
At time: 1260.6252980232239 and batch: 400, loss is 5.331832313537598 and perplexity is 206.8165800074156
At time: 1261.702525138855 and batch: 450, loss is 5.304516925811767 and perplexity is 201.24376326115055
At time: 1262.8064632415771 and batch: 500, loss is 5.331468887329102 and perplexity is 206.74143109825806
At time: 1263.891014099121 and batch: 550, loss is 5.315488529205322 and perplexity is 203.46388690435674
At time: 1264.9780044555664 and batch: 600, loss is 5.262944355010986 and perplexity is 193.0490602929451
At time: 1266.0588328838348 and batch: 650, loss is 5.292505559921264 and perplexity is 198.84100985023687
At time: 1267.137734413147 and batch: 700, loss is 5.308239192962646 and perplexity is 201.9942421854732
At time: 1268.215894460678 and batch: 750, loss is 5.280696086883545 and perplexity is 196.50661343162474
At time: 1269.2987508773804 and batch: 800, loss is 5.266069965362549 and perplexity is 193.65340040801067
At time: 1270.376616716385 and batch: 850, loss is 5.225247173309326 and perplexity is 185.90711612457713
At time: 1271.459635734558 and batch: 900, loss is 5.256380910873413 and perplexity is 191.78614264835142
At time: 1272.5444922447205 and batch: 950, loss is 5.231472330093384 and perplexity is 187.06802674601923
At time: 1273.6230521202087 and batch: 1000, loss is 5.273043918609619 and perplexity is 195.00865040080973
At time: 1274.7037315368652 and batch: 1050, loss is 5.236028461456299 and perplexity is 187.92227781197695
At time: 1275.7882890701294 and batch: 1100, loss is 5.227418403625489 and perplexity is 186.3112018139002
At time: 1276.8709030151367 and batch: 1150, loss is 5.23602596282959 and perplexity is 187.921808264941
At time: 1277.9590339660645 and batch: 1200, loss is 5.209964609146118 and perplexity is 183.0875784533204
At time: 1279.0430302619934 and batch: 1250, loss is 5.22644160270691 and perplexity is 186.12930171538164
At time: 1280.1272699832916 and batch: 1300, loss is 5.204762983322143 and perplexity is 182.13769798032268
At time: 1281.2070229053497 and batch: 1350, loss is 5.181628656387329 and perplexity is 177.97243102014204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227389322916666 and perplexity of 186.30578383086967
Finished 41 epochs...
Completing Train Step...
At time: 1284.4114096164703 and batch: 50, loss is 5.301073799133301 and perplexity is 200.55204700769903
At time: 1285.5161793231964 and batch: 100, loss is 5.313433456420898 and perplexity is 203.04618316057253
At time: 1286.5950331687927 and batch: 150, loss is 5.28158242225647 and perplexity is 196.68086140378637
At time: 1287.6745595932007 and batch: 200, loss is 5.272385416030883 and perplexity is 194.88027897274205
At time: 1288.7525539398193 and batch: 250, loss is 5.28995114326477 and perplexity is 198.33373523387846
At time: 1289.857946395874 and batch: 300, loss is 5.309961977005005 and perplexity is 202.34253457269827
At time: 1290.936087846756 and batch: 350, loss is 5.313429470062256 and perplexity is 203.0453737472788
At time: 1292.0239057540894 and batch: 400, loss is 5.331427593231201 and perplexity is 206.73289407362765
At time: 1293.1048781871796 and batch: 450, loss is 5.3042231464385985 and perplexity is 201.18465067797953
At time: 1294.188306570053 and batch: 500, loss is 5.3311439037323 and perplexity is 206.67425444061885
At time: 1295.2733857631683 and batch: 550, loss is 5.315255098342895 and perplexity is 203.41639769670286
At time: 1296.3541526794434 and batch: 600, loss is 5.262720460891724 and perplexity is 193.0058425818926
At time: 1297.432772397995 and batch: 650, loss is 5.292284603118897 and perplexity is 198.79707943006213
At time: 1298.5156285762787 and batch: 700, loss is 5.3080611991882325 and perplexity is 201.9582916674759
At time: 1299.599177122116 and batch: 750, loss is 5.2805805587768555 and perplexity is 196.48391270593427
At time: 1300.692504644394 and batch: 800, loss is 5.266041917800903 and perplexity is 193.64796897849436
At time: 1301.7713503837585 and batch: 850, loss is 5.225318994522095 and perplexity is 185.92046867861202
At time: 1302.8480894565582 and batch: 900, loss is 5.2564848613739015 and perplexity is 191.80607995009473
At time: 1303.9251310825348 and batch: 950, loss is 5.231518440246582 and perplexity is 187.07665268026096
At time: 1305.0015180110931 and batch: 1000, loss is 5.2731133079528805 and perplexity is 195.02218239247395
At time: 1306.079778432846 and batch: 1050, loss is 5.2361194610595705 and perplexity is 187.93937944281274
At time: 1307.1569304466248 and batch: 1100, loss is 5.227588148117065 and perplexity is 186.34282979838923
At time: 1308.2339925765991 and batch: 1150, loss is 5.236280574798584 and perplexity is 187.96966149830465
At time: 1309.310491323471 and batch: 1200, loss is 5.210250959396363 and perplexity is 183.14001313421093
At time: 1310.387391090393 and batch: 1250, loss is 5.226638116836548 and perplexity is 186.16588234729622
At time: 1311.465371131897 and batch: 1300, loss is 5.204904842376709 and perplexity is 182.16353769471428
At time: 1312.5422451496124 and batch: 1350, loss is 5.181641454696655 and perplexity is 177.97470878094148
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227320963541667 and perplexity of 186.29304851922208
Finished 42 epochs...
Completing Train Step...
At time: 1315.734146118164 and batch: 50, loss is 5.300653610229492 and perplexity is 200.4677949650367
At time: 1316.839860200882 and batch: 100, loss is 5.31290771484375 and perplexity is 202.93946139649614
At time: 1317.92129778862 and batch: 150, loss is 5.281100463867188 and perplexity is 196.5860922518499
At time: 1318.9998874664307 and batch: 200, loss is 5.271906080245972 and perplexity is 194.78688826579895
At time: 1320.079938173294 and batch: 250, loss is 5.289496698379517 and perplexity is 198.24362395918297
At time: 1321.1591596603394 and batch: 300, loss is 5.309537200927735 and perplexity is 202.25660255682186
At time: 1322.2370994091034 and batch: 350, loss is 5.313069334030152 and perplexity is 202.97226295774533
At time: 1323.3173899650574 and batch: 400, loss is 5.331100387573242 and perplexity is 206.66526096657165
At time: 1324.3959443569183 and batch: 450, loss is 5.303962249755859 and perplexity is 201.13216911642988
At time: 1325.474775314331 and batch: 500, loss is 5.330874090194702 and perplexity is 206.6184984510965
At time: 1326.554220199585 and batch: 550, loss is 5.315058097839356 and perplexity is 203.37632851088293
At time: 1327.6331162452698 and batch: 600, loss is 5.262531156539917 and perplexity is 192.9693091940415
At time: 1328.712102651596 and batch: 650, loss is 5.292094526290893 and perplexity is 198.75929630274996
At time: 1329.7911202907562 and batch: 700, loss is 5.307911043167114 and perplexity is 201.92796869061297
At time: 1330.869472026825 and batch: 750, loss is 5.280476264953613 and perplexity is 196.46342171603294
At time: 1331.9472353458405 and batch: 800, loss is 5.266018886566162 and perplexity is 193.6435090780223
At time: 1333.02747964859 and batch: 850, loss is 5.225379238128662 and perplexity is 185.93166953556653
At time: 1334.1055264472961 and batch: 900, loss is 5.256579036712647 and perplexity is 191.82414420323764
At time: 1335.1838405132294 and batch: 950, loss is 5.2315452098846436 and perplexity is 187.08166072157445
At time: 1336.2633128166199 and batch: 1000, loss is 5.273157472610474 and perplexity is 195.03079567058225
At time: 1337.3413593769073 and batch: 1050, loss is 5.23617712020874 and perplexity is 187.95021617994243
At time: 1338.4197387695312 and batch: 1100, loss is 5.227724685668945 and perplexity is 186.36827432920768
At time: 1339.498826265335 and batch: 1150, loss is 5.236480484008789 and perplexity is 188.00724212110848
At time: 1340.5778243541718 and batch: 1200, loss is 5.210468301773071 and perplexity is 183.17982154580662
At time: 1341.655972480774 and batch: 1250, loss is 5.226785049438477 and perplexity is 186.1932381944636
At time: 1342.734139919281 and batch: 1300, loss is 5.205005025863647 and perplexity is 182.1817883873073
At time: 1343.8139741420746 and batch: 1350, loss is 5.181622619628906 and perplexity is 177.9713566468129
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.22727294921875 and perplexity of 186.2841039993676
Finished 43 epochs...
Completing Train Step...
At time: 1347.049021244049 and batch: 50, loss is 5.3002706718444825 and perplexity is 200.39104284799012
At time: 1348.1297097206116 and batch: 100, loss is 5.312427339553833 and perplexity is 202.8419977053409
At time: 1349.211818933487 and batch: 150, loss is 5.28067214012146 and perplexity is 196.50190779084753
At time: 1350.2899038791656 and batch: 200, loss is 5.271473617553711 and perplexity is 194.7026684159664
At time: 1351.368093252182 and batch: 250, loss is 5.289096870422363 and perplexity is 198.16437645973534
At time: 1352.4473383426666 and batch: 300, loss is 5.309160480499267 and perplexity is 202.180422712999
At time: 1353.526865720749 and batch: 350, loss is 5.312753858566285 and perplexity is 202.90824028825827
At time: 1354.605073928833 and batch: 400, loss is 5.330816450119019 and perplexity is 206.6065892884341
At time: 1355.6843547821045 and batch: 450, loss is 5.303730669021607 and perplexity is 201.08559617393044
At time: 1356.7632019519806 and batch: 500, loss is 5.330633811950683 and perplexity is 206.56885848504766
At time: 1357.8417298793793 and batch: 550, loss is 5.314887399673462 and perplexity is 203.3416155074272
At time: 1358.921264410019 and batch: 600, loss is 5.262371444702149 and perplexity is 192.93849217202435
At time: 1360.001697063446 and batch: 650, loss is 5.291935224533081 and perplexity is 198.72763611929574
At time: 1361.0819561481476 and batch: 700, loss is 5.307774038314819 and perplexity is 201.900305474129
At time: 1362.1616990566254 and batch: 750, loss is 5.280385046005249 and perplexity is 196.4455013466631
At time: 1363.2390847206116 and batch: 800, loss is 5.26599687576294 and perplexity is 193.6392468757562
At time: 1364.3178362846375 and batch: 850, loss is 5.225442495346069 and perplexity is 185.94343142761758
At time: 1365.4007828235626 and batch: 900, loss is 5.256646299362183 and perplexity is 191.83704723736307
At time: 1366.481309890747 and batch: 950, loss is 5.231553602218628 and perplexity is 187.08323077994174
At time: 1367.5603139400482 and batch: 1000, loss is 5.273183336257935 and perplexity is 195.03583994355688
At time: 1368.6456472873688 and batch: 1050, loss is 5.23620867729187 and perplexity is 187.95614743412472
At time: 1369.7242379188538 and batch: 1100, loss is 5.227832260131836 and perplexity is 186.38832387460886
At time: 1370.8022065162659 and batch: 1150, loss is 5.236637372970581 and perplexity is 188.03674069607408
At time: 1371.9270780086517 and batch: 1200, loss is 5.210636434555053 and perplexity is 183.21062266807277
At time: 1373.0051860809326 and batch: 1250, loss is 5.226897439956665 and perplexity is 186.21416572499336
At time: 1374.0847568511963 and batch: 1300, loss is 5.205077047348023 and perplexity is 182.19490986264154
At time: 1375.1629695892334 and batch: 1350, loss is 5.181579856872559 and perplexity is 177.96374626377343
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227231852213541 and perplexity of 186.27644843788664
Finished 44 epochs...
Completing Train Step...
At time: 1378.416591644287 and batch: 50, loss is 5.299905319213867 and perplexity is 200.3178428260583
At time: 1379.495695590973 and batch: 100, loss is 5.311976280212402 and perplexity is 202.75052455890096
At time: 1380.574009180069 and batch: 150, loss is 5.28028377532959 and perplexity is 196.4256081853254
At time: 1381.6561877727509 and batch: 200, loss is 5.271111831665039 and perplexity is 194.63224047873197
At time: 1382.7373504638672 and batch: 250, loss is 5.288736629486084 and perplexity is 198.0930023959239
At time: 1383.814762353897 and batch: 300, loss is 5.308815965652466 and perplexity is 202.1107805527096
At time: 1384.894835472107 and batch: 350, loss is 5.312467775344849 and perplexity is 202.85019994780032
At time: 1385.9732835292816 and batch: 400, loss is 5.330558443069458 and perplexity is 206.55329020797691
At time: 1387.0503723621368 and batch: 450, loss is 5.303516387939453 and perplexity is 201.04251195100858
At time: 1388.129516363144 and batch: 500, loss is 5.3304088687896725 and perplexity is 206.5223974587946
At time: 1389.2076346874237 and batch: 550, loss is 5.314715595245361 and perplexity is 203.30668351828695
At time: 1390.2874364852905 and batch: 600, loss is 5.262226657867432 and perplexity is 192.91055924065685
At time: 1391.3697888851166 and batch: 650, loss is 5.291765327453613 and perplexity is 198.6938757422856
At time: 1392.4487328529358 and batch: 700, loss is 5.30765700340271 and perplexity is 201.87667747230054
At time: 1393.5343072414398 and batch: 750, loss is 5.280284442901611 and perplexity is 196.4257393136095
At time: 1394.6125338077545 and batch: 800, loss is 5.265959596633911 and perplexity is 193.63202830783865
At time: 1395.6908180713654 and batch: 850, loss is 5.22546690940857 and perplexity is 185.94797111758993
At time: 1396.7770042419434 and batch: 900, loss is 5.256689023971558 and perplexity is 191.8452435753613
At time: 1397.8547887802124 and batch: 950, loss is 5.231534566879272 and perplexity is 187.0796696210502
At time: 1398.9597556591034 and batch: 1000, loss is 5.273175573348999 and perplexity is 195.0343259039688
At time: 1400.0422835350037 and batch: 1050, loss is 5.236210479736328 and perplexity is 187.95648621494627
At time: 1401.1235964298248 and batch: 1100, loss is 5.227896137237549 and perplexity is 186.40023020154334
At time: 1402.206297636032 and batch: 1150, loss is 5.236757383346558 and perplexity is 188.05930841017542
At time: 1403.2839822769165 and batch: 1200, loss is 5.210746231079102 and perplexity is 183.2307396619783
At time: 1404.3661923408508 and batch: 1250, loss is 5.226975660324097 and perplexity is 186.22873203514106
At time: 1405.4460399150848 and batch: 1300, loss is 5.205121164321899 and perplexity is 182.20294792802667
At time: 1406.524620294571 and batch: 1350, loss is 5.1815087032318115 and perplexity is 177.95108394579606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227196044921875 and perplexity of 186.2697785021838
Finished 45 epochs...
Completing Train Step...
At time: 1409.741450548172 and batch: 50, loss is 5.299544172286987 and perplexity is 200.24551171458802
At time: 1410.8480491638184 and batch: 100, loss is 5.311595821380616 and perplexity is 202.6734010032824
At time: 1411.9272830486298 and batch: 150, loss is 5.279972763061523 and perplexity is 196.3645269104226
At time: 1413.005334854126 and batch: 200, loss is 5.270746698379517 and perplexity is 194.5611867421289
At time: 1414.0840220451355 and batch: 250, loss is 5.288414802551269 and perplexity is 198.0292609895555
At time: 1415.1655187606812 and batch: 300, loss is 5.308511447906494 and perplexity is 202.0492436034013
At time: 1416.2423357963562 and batch: 350, loss is 5.312210559844971 and perplexity is 202.7980304419108
At time: 1417.3190953731537 and batch: 400, loss is 5.330327205657959 and perplexity is 206.50553288166554
At time: 1418.3981585502625 and batch: 450, loss is 5.303320779800415 and perplexity is 201.00319024532644
At time: 1419.475436925888 and batch: 500, loss is 5.330208234786987 and perplexity is 206.48096619994686
At time: 1420.5632774829865 and batch: 550, loss is 5.314558486938477 and perplexity is 203.27474485844127
At time: 1421.6461820602417 and batch: 600, loss is 5.262097148895264 and perplexity is 192.88557721014274
At time: 1422.7213370800018 and batch: 650, loss is 5.291623487472534 and perplexity is 198.66569500533453
At time: 1423.7969250679016 and batch: 700, loss is 5.307518587112427 and perplexity is 201.8487363853056
At time: 1424.8719353675842 and batch: 750, loss is 5.280217323303223 and perplexity is 196.41255573931667
At time: 1425.9910295009613 and batch: 800, loss is 5.265941181182861 and perplexity is 193.62846251953263
At time: 1427.0657186508179 and batch: 850, loss is 5.225504884719848 and perplexity is 185.9550326837565
At time: 1428.1403090953827 and batch: 900, loss is 5.25671802520752 and perplexity is 191.85080740521704
At time: 1429.2164463996887 and batch: 950, loss is 5.2314918327331545 and perplexity is 187.07167510193364
At time: 1430.2926633358002 and batch: 1000, loss is 5.273118858337402 and perplexity is 195.0232648435805
At time: 1431.367919921875 and batch: 1050, loss is 5.236182527542114 and perplexity is 187.95123249216678
At time: 1432.4435267448425 and batch: 1100, loss is 5.227926502227783 and perplexity is 186.4058903286475
At time: 1433.51846909523 and batch: 1150, loss is 5.23684021949768 and perplexity is 188.0748871647
At time: 1434.593546628952 and batch: 1200, loss is 5.210838050842285 and perplexity is 183.24756463752271
At time: 1435.6708245277405 and batch: 1250, loss is 5.227011022567749 and perplexity is 186.235317617378
At time: 1436.7471208572388 and batch: 1300, loss is 5.205129489898682 and perplexity is 182.2044648789744
At time: 1437.8395366668701 and batch: 1350, loss is 5.181392974853516 and perplexity is 177.93049114704365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227160237630208 and perplexity of 186.26310880530886
Finished 46 epochs...
Completing Train Step...
At time: 1441.0348119735718 and batch: 50, loss is 5.299193077087402 and perplexity is 200.17521881715803
At time: 1442.156681060791 and batch: 100, loss is 5.311187906265259 and perplexity is 202.59074431913393
At time: 1443.2335498332977 and batch: 150, loss is 5.279630527496338 and perplexity is 196.29733548387688
At time: 1444.3114264011383 and batch: 200, loss is 5.270387258529663 and perplexity is 194.4912662652346
At time: 1445.3878803253174 and batch: 250, loss is 5.288097639083862 and perplexity is 197.96646330158455
At time: 1446.464509487152 and batch: 300, loss is 5.308213262557984 and perplexity is 201.98900446094228
At time: 1447.5403821468353 and batch: 350, loss is 5.31196629524231 and perplexity is 202.74850011108404
At time: 1448.6175184249878 and batch: 400, loss is 5.330103511810303 and perplexity is 206.45934403072653
At time: 1449.6941299438477 and batch: 450, loss is 5.303138723373413 and perplexity is 200.96659965357176
At time: 1450.7715735435486 and batch: 500, loss is 5.33002049446106 and perplexity is 206.4422050346855
At time: 1451.848248720169 and batch: 550, loss is 5.314421510696411 and perplexity is 203.24690295466678
At time: 1452.9245302677155 and batch: 600, loss is 5.2620089149475096 and perplexity is 192.86855890500777
At time: 1454.0287606716156 and batch: 650, loss is 5.291530504226684 and perplexity is 198.64722328296762
At time: 1455.1067032814026 and batch: 700, loss is 5.307463045120239 and perplexity is 201.83752561570333
At time: 1456.183480978012 and batch: 750, loss is 5.280176343917847 and perplexity is 196.40450703841893
At time: 1457.2611627578735 and batch: 800, loss is 5.2659229564666745 and perplexity is 193.62493372791323
At time: 1458.3376989364624 and batch: 850, loss is 5.225541143417359 and perplexity is 185.96177529327548
At time: 1459.4144487380981 and batch: 900, loss is 5.256739025115967 and perplexity is 191.85483629691103
At time: 1460.4909915924072 and batch: 950, loss is 5.231478204727173 and perplexity is 187.06912570539802
At time: 1461.5683243274689 and batch: 1000, loss is 5.273101043701172 and perplexity is 195.01979060600712
At time: 1462.6448757648468 and batch: 1050, loss is 5.236168994903564 and perplexity is 187.9486890332823
At time: 1463.7211797237396 and batch: 1100, loss is 5.227965631484985 and perplexity is 186.41318439537898
At time: 1464.8000662326813 and batch: 1150, loss is 5.236919183731079 and perplexity is 188.08973894035825
At time: 1465.8767862319946 and batch: 1200, loss is 5.21091670036316 and perplexity is 183.2619775374593
At time: 1466.9532692432404 and batch: 1250, loss is 5.227057189941406 and perplexity is 186.24391581135114
At time: 1468.0284597873688 and batch: 1300, loss is 5.205144205093384 and perplexity is 182.20714607287775
At time: 1469.1047856807709 and batch: 1350, loss is 5.181310586929321 and perplexity is 177.91583242708612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227143961588542 and perplexity of 186.26007720386033
Finished 47 epochs...
Completing Train Step...
At time: 1472.3252868652344 and batch: 50, loss is 5.298874416351318 and perplexity is 200.11144099686732
At time: 1473.4025037288666 and batch: 100, loss is 5.310808572769165 and perplexity is 202.5139094377586
At time: 1474.4785904884338 and batch: 150, loss is 5.279312705993652 and perplexity is 196.2349578827366
At time: 1475.5551178455353 and batch: 200, loss is 5.27006872177124 and perplexity is 194.42932351378232
At time: 1476.6352558135986 and batch: 250, loss is 5.28781325340271 and perplexity is 197.91017247860475
At time: 1477.7122395038605 and batch: 300, loss is 5.307940082550049 and perplexity is 201.93383263936335
At time: 1478.7883565425873 and batch: 350, loss is 5.311750240325928 and perplexity is 202.70470003262756
At time: 1479.8708202838898 and batch: 400, loss is 5.329902381896972 and perplexity is 206.41782305645032
At time: 1480.992118358612 and batch: 450, loss is 5.3029662609100345 and perplexity is 200.9319434472719
At time: 1482.0688126087189 and batch: 500, loss is 5.329840879440308 and perplexity is 206.40512824361812
At time: 1483.146271944046 and batch: 550, loss is 5.314284152984619 and perplexity is 203.21898734240446
At time: 1484.2227625846863 and batch: 600, loss is 5.261888885498047 and perplexity is 192.84541038734352
At time: 1485.3014135360718 and batch: 650, loss is 5.291383953094482 and perplexity is 198.61811344057898
At time: 1486.37877368927 and batch: 700, loss is 5.307341651916504 and perplexity is 201.8130253989448
At time: 1487.455018043518 and batch: 750, loss is 5.280087356567383 and perplexity is 196.3870302993342
At time: 1488.533234834671 and batch: 800, loss is 5.265881061553955 and perplexity is 193.6168219981357
At time: 1489.609349489212 and batch: 850, loss is 5.225544700622558 and perplexity is 185.96243679864605
At time: 1490.692702293396 and batch: 900, loss is 5.25674747467041 and perplexity is 191.85645739164434
At time: 1491.7750947475433 and batch: 950, loss is 5.231420574188232 and perplexity is 187.0583451215128
At time: 1492.8519339561462 and batch: 1000, loss is 5.273049764633178 and perplexity is 195.0097904293066
At time: 1493.9303569793701 and batch: 1050, loss is 5.23613694190979 and perplexity is 187.9426648116706
At time: 1495.0112977027893 and batch: 1100, loss is 5.227980976104736 and perplexity is 186.41604485675637
At time: 1496.0921964645386 and batch: 1150, loss is 5.236954193115235 and perplexity is 188.0963239615527
At time: 1497.16907954216 and batch: 1200, loss is 5.210953989028931 and perplexity is 183.26881125949765
At time: 1498.2467422485352 and batch: 1250, loss is 5.227057447433472 and perplexity is 186.24396376768794
At time: 1499.3236088752747 and batch: 1300, loss is 5.205117015838623 and perplexity is 182.2021920637122
At time: 1500.4009630680084 and batch: 1350, loss is 5.181181716918945 and perplexity is 177.89290588921853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227069498697917 and perplexity of 186.24620825647105
Finished 48 epochs...
Completing Train Step...
At time: 1503.6043722629547 and batch: 50, loss is 5.298566360473632 and perplexity is 200.04980498543125
At time: 1504.6899571418762 and batch: 100, loss is 5.310351552963257 and perplexity is 202.42137771619898
At time: 1505.7664365768433 and batch: 150, loss is 5.278967990875244 and perplexity is 196.1673243838088
At time: 1506.8448331356049 and batch: 200, loss is 5.269884357452392 and perplexity is 194.39348098813159
At time: 1507.9501461982727 and batch: 250, loss is 5.287500495910645 and perplexity is 197.8482842679113
At time: 1509.0282039642334 and batch: 300, loss is 5.307655696868896 and perplexity is 201.87641371376756
At time: 1510.114104270935 and batch: 350, loss is 5.311498556137085 and perplexity is 202.65368888424425
At time: 1511.1919524669647 and batch: 400, loss is 5.329653797149658 and perplexity is 206.3665171112665
At time: 1512.2704186439514 and batch: 450, loss is 5.302701530456543 and perplexity is 200.87875768301845
At time: 1513.350394487381 and batch: 500, loss is 5.329585657119751 and perplexity is 206.3524557696944
At time: 1514.4286210536957 and batch: 550, loss is 5.314077224731445 and perplexity is 203.17693994288936
At time: 1515.5095298290253 and batch: 600, loss is 5.26169716835022 and perplexity is 192.8084421591273
At time: 1516.5909764766693 and batch: 650, loss is 5.291135444641113 and perplexity is 198.56876129286368
At time: 1517.6695742607117 and batch: 700, loss is 5.307174797058106 and perplexity is 201.77935472430485
At time: 1518.748242855072 and batch: 750, loss is 5.279882431030273 and perplexity is 196.34678970497237
At time: 1519.8267459869385 and batch: 800, loss is 5.265732870101929 and perplexity is 193.5881317660232
At time: 1520.9049293994904 and batch: 850, loss is 5.2254594039916995 and perplexity is 185.94657550578785
At time: 1521.9853248596191 and batch: 900, loss is 5.256688327789306 and perplexity is 191.84511001615422
At time: 1523.063337802887 and batch: 950, loss is 5.2312821102142335 and perplexity is 187.03244607276167
At time: 1524.1421551704407 and batch: 1000, loss is 5.272901573181152 and perplexity is 194.98089378647418
At time: 1525.2221858501434 and batch: 1050, loss is 5.236046667098999 and perplexity is 187.92569908896536
At time: 1526.3051371574402 and batch: 1100, loss is 5.227954082489013 and perplexity is 186.41103152269505
At time: 1527.3875229358673 and batch: 1150, loss is 5.236926832199097 and perplexity is 188.0911775442126
At time: 1528.4702990055084 and batch: 1200, loss is 5.210961132049561 and perplexity is 183.27012035707278
At time: 1529.5471358299255 and batch: 1250, loss is 5.226986560821533 and perplexity is 186.23076203202115
At time: 1530.6238803863525 and batch: 1300, loss is 5.205085964202881 and perplexity is 182.19653447545184
At time: 1531.7017769813538 and batch: 1350, loss is 5.181082611083984 and perplexity is 177.875276537847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.22706298828125 and perplexity of 186.2449957199997
Finished 49 epochs...
Completing Train Step...
At time: 1534.897386789322 and batch: 50, loss is 5.298309354782105 and perplexity is 199.99839765323244
At time: 1536.0249209403992 and batch: 100, loss is 5.310134649276733 and perplexity is 202.3774765344773
At time: 1537.105649471283 and batch: 150, loss is 5.2787949657440185 and perplexity is 196.13338544299467
At time: 1538.1921622753143 and batch: 200, loss is 5.269689216613769 and perplexity is 194.35555058223466
At time: 1539.274445772171 and batch: 250, loss is 5.287220258712768 and perplexity is 197.79284758719623
At time: 1540.3586711883545 and batch: 300, loss is 5.307443981170654 and perplexity is 201.8336778319677
At time: 1541.4410781860352 and batch: 350, loss is 5.311298599243164 and perplexity is 202.61317093313016
At time: 1542.5233073234558 and batch: 400, loss is 5.32945258140564 and perplexity is 206.32499709636602
At time: 1543.6031148433685 and batch: 450, loss is 5.302521963119506 and perplexity is 200.8426896578507
At time: 1544.681411266327 and batch: 500, loss is 5.329413805007935 and perplexity is 206.31699671133615
At time: 1545.7597482204437 and batch: 550, loss is 5.313959054946899 and perplexity is 203.15293198620705
At time: 1546.8387713432312 and batch: 600, loss is 5.261596574783325 and perplexity is 192.78904784569102
At time: 1547.9182703495026 and batch: 650, loss is 5.291013126373291 and perplexity is 198.54447419134715
At time: 1548.9970240592957 and batch: 700, loss is 5.307085561752319 and perplexity is 201.76134968523917
At time: 1550.0763239860535 and batch: 750, loss is 5.279781942367554 and perplexity is 196.3270600699645
At time: 1551.1542773246765 and batch: 800, loss is 5.265679769515991 and perplexity is 193.57785239571848
At time: 1552.232540845871 and batch: 850, loss is 5.2254699611663815 and perplexity is 185.94853858662927
At time: 1553.3118200302124 and batch: 900, loss is 5.256674308776855 and perplexity is 191.84242055602
At time: 1554.393266916275 and batch: 950, loss is 5.23123797416687 and perplexity is 187.02419138202933
At time: 1555.4782395362854 and batch: 1000, loss is 5.2728705310821535 and perplexity is 194.97484126420838
At time: 1556.5577521324158 and batch: 1050, loss is 5.2360231304168705 and perplexity is 187.92127599357482
At time: 1557.6358902454376 and batch: 1100, loss is 5.227962923049927 and perplexity is 186.41267950805874
At time: 1558.7126557826996 and batch: 1150, loss is 5.2368949508666995 and perplexity is 188.08518104244908
At time: 1559.7901237010956 and batch: 1200, loss is 5.210951766967773 and perplexity is 183.26840402544326
At time: 1560.8670010566711 and batch: 1250, loss is 5.2268588161468506 and perplexity is 186.2069735633669
At time: 1561.9433863162994 and batch: 1300, loss is 5.205123977661133 and perplexity is 182.2034605274496
At time: 1563.0209577083588 and batch: 1350, loss is 5.180995683670044 and perplexity is 177.85981497208041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227044677734375 and perplexity of 186.24158550349685
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
SETTINGS FOR THIS RUN
{'dropout': 0.2808414031148949, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 5.117491396780094, 'wordvec_dim': 200, 'lr': 24.99135641797138, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.774545669555664 and batch: 50, loss is 6.986387577056885 and perplexity is 1081.8064666081652
At time: 2.875333547592163 and batch: 100, loss is 6.210292053222656 and perplexity is 497.84662776896727
At time: 3.956139326095581 and batch: 150, loss is 6.056600341796875 and perplexity is 426.921579500666
At time: 5.03809118270874 and batch: 200, loss is 6.015795059204102 and perplexity is 409.85156567305023
At time: 6.116190433502197 and batch: 250, loss is 6.006193170547485 and perplexity is 405.9350496397874
At time: 7.194171905517578 and batch: 300, loss is 5.973148794174194 and perplexity is 392.7403844345658
At time: 8.272523880004883 and batch: 350, loss is 5.97060004234314 and perplexity is 391.7406612249845
At time: 9.352285146713257 and batch: 400, loss is 5.9995660400390625 and perplexity is 403.25375953088246
At time: 10.431735515594482 and batch: 450, loss is 5.962927827835083 and perplexity is 388.74664290230754
At time: 11.512051582336426 and batch: 500, loss is 5.971091928482056 and perplexity is 391.93340042527535
At time: 12.594549417495728 and batch: 550, loss is 5.928173303604126 and perplexity is 375.4680209279859
At time: 13.675554752349854 and batch: 600, loss is 5.883867292404175 and perplexity is 359.1956738126785
At time: 14.756062507629395 and batch: 650, loss is 5.90605450630188 and perplexity is 367.2542936358876
At time: 15.838934898376465 and batch: 700, loss is 5.915137243270874 and perplexity is 370.6051622788629
At time: 16.919676542282104 and batch: 750, loss is 5.900815725326538 and perplexity is 365.33535965542245
At time: 18.009847402572632 and batch: 800, loss is 5.862841920852661 and perplexity is 351.72229193522645
At time: 19.09054136276245 and batch: 850, loss is 5.868319759368896 and perplexity is 353.6542565170167
At time: 20.17335820198059 and batch: 900, loss is 5.90742748260498 and perplexity is 367.7588713856449
At time: 21.255048990249634 and batch: 950, loss is 5.874011888504028 and perplexity is 355.6730423583781
At time: 22.336557388305664 and batch: 1000, loss is 5.873762340545654 and perplexity is 355.5842959505119
At time: 23.41931962966919 and batch: 1050, loss is 5.86723066329956 and perplexity is 353.269302720224
At time: 24.500839710235596 and batch: 1100, loss is 5.855065269470215 and perplexity is 348.997678204181
At time: 25.582245588302612 and batch: 1150, loss is 5.853348093032837 and perplexity is 348.3989018639147
At time: 26.663986921310425 and batch: 1200, loss is 5.846008205413819 and perplexity is 345.8510549711138
At time: 27.74683666229248 and batch: 1250, loss is 5.852886562347412 and perplexity is 348.23814218055315
At time: 28.836974382400513 and batch: 1300, loss is 5.839829273223877 and perplexity is 343.72065333632895
At time: 29.919641256332397 and batch: 1350, loss is 5.82431625366211 and perplexity is 338.4296539139329
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.396409098307291 and perplexity of 220.61279329317586
Finished 1 epochs...
Completing Train Step...
At time: 33.16984462738037 and batch: 50, loss is 5.731324901580811 and perplexity is 308.3775677664521
At time: 34.24467706680298 and batch: 100, loss is 5.785308723449707 and perplexity is 325.48250868623256
At time: 35.32035779953003 and batch: 150, loss is 5.680631189346314 and perplexity is 293.13439484953113
At time: 36.39472246170044 and batch: 200, loss is 5.714585638046264 and perplexity is 303.2585184794957
At time: 37.46924662590027 and batch: 250, loss is 5.741922235488891 and perplexity is 311.6629250897503
At time: 38.54585671424866 and batch: 300, loss is 5.746230087280273 and perplexity is 313.00841879287617
At time: 39.62042260169983 and batch: 350, loss is 5.738807201385498 and perplexity is 310.6935949813244
At time: 40.69532108306885 and batch: 400, loss is 5.795512590408325 and perplexity is 328.82069112301826
At time: 41.77143836021423 and batch: 450, loss is 5.789005489349365 and perplexity is 326.6879681030869
At time: 42.84535455703735 and batch: 500, loss is 5.79567400932312 and perplexity is 328.8737732862587
At time: 43.91993021965027 and batch: 550, loss is 5.756457014083862 and perplexity is 316.22595770475516
At time: 44.99608063697815 and batch: 600, loss is 5.739796361923218 and perplexity is 311.0010728722295
At time: 46.07164645195007 and batch: 650, loss is 5.725814638137817 and perplexity is 306.6829991755089
At time: 47.14589262008667 and batch: 700, loss is 5.764163322448731 and perplexity is 318.67230650009355
At time: 48.221819162368774 and batch: 750, loss is 5.7366121387481686 and perplexity is 310.0123510394217
At time: 49.29641151428223 and batch: 800, loss is 5.698089628219605 and perplexity is 298.2969981323868
At time: 50.37034296989441 and batch: 850, loss is 5.697168693542481 and perplexity is 298.02241253982857
At time: 51.44603753089905 and batch: 900, loss is 5.725243072509766 and perplexity is 306.50775979964527
At time: 52.51980495452881 and batch: 950, loss is 5.667214117050171 and perplexity is 289.227656582934
At time: 53.594016551971436 and batch: 1000, loss is 5.689519004821777 and perplexity is 295.75133145863754
At time: 54.669936180114746 and batch: 1050, loss is 5.68313289642334 and perplexity is 293.86864930147874
At time: 55.744503021240234 and batch: 1100, loss is 5.709890012741089 and perplexity is 301.83786813727517
At time: 56.81910467147827 and batch: 1150, loss is 5.705879898071289 and perplexity is 300.62988736386336
At time: 57.89488673210144 and batch: 1200, loss is 5.692882566452027 and perplexity is 296.7477841648203
At time: 58.96969175338745 and batch: 1250, loss is 5.689633111953736 and perplexity is 295.78508072032224
At time: 60.04535746574402 and batch: 1300, loss is 5.689862270355224 and perplexity is 295.8528701235632
At time: 61.119873046875 and batch: 1350, loss is 5.673984336853027 and perplexity is 291.19243487674987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.515564371744792 and perplexity of 248.5302010977902
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 64.30032682418823 and batch: 50, loss is 5.682872266769409 and perplexity is 293.79206839717096
At time: 65.40123462677002 and batch: 100, loss is 5.684095449447632 and perplexity is 294.1516496381734
At time: 66.47697710990906 and batch: 150, loss is 5.623065547943115 and perplexity is 276.7364330386253
At time: 67.55434918403625 and batch: 200, loss is 5.602987174987793 and perplexity is 271.2354261651384
At time: 68.64073896408081 and batch: 250, loss is 5.611207647323608 and perplexity is 273.4742991713707
At time: 69.7198235988617 and batch: 300, loss is 5.60642526626587 and perplexity is 272.16956322221483
At time: 70.79964590072632 and batch: 350, loss is 5.586857166290283 and perplexity is 266.89549206498975
At time: 71.87540411949158 and batch: 400, loss is 5.629548301696778 and perplexity is 278.53627485095797
At time: 72.95805478096008 and batch: 450, loss is 5.587161130905152 and perplexity is 266.9766311815309
At time: 74.03367185592651 and batch: 500, loss is 5.608221340179443 and perplexity is 272.6588391311064
At time: 75.1076934337616 and batch: 550, loss is 5.57132381439209 and perplexity is 262.7817433351865
At time: 76.18294286727905 and batch: 600, loss is 5.53660104751587 and perplexity is 253.81383050621497
At time: 77.25635576248169 and batch: 650, loss is 5.575448360443115 and perplexity is 263.8678370189407
At time: 78.33019423484802 and batch: 700, loss is 5.555021924972534 and perplexity is 258.53263277930824
At time: 79.40630269050598 and batch: 750, loss is 5.526364545822144 and perplexity is 251.2289176048374
At time: 80.48124027252197 and batch: 800, loss is 5.4913159847259525 and perplexity is 242.57622350640958
At time: 81.5551393032074 and batch: 850, loss is 5.482169218063355 and perplexity is 240.36755189276008
At time: 82.62992858886719 and batch: 900, loss is 5.5091711616516115 and perplexity is 246.94636360528986
At time: 83.74593544006348 and batch: 950, loss is 5.486811208724975 and perplexity is 241.48592956511854
At time: 84.82027626037598 and batch: 1000, loss is 5.496446266174316 and perplexity is 243.8239055491379
At time: 85.89439654350281 and batch: 1050, loss is 5.440720176696777 and perplexity is 230.60820232540814
At time: 86.96899700164795 and batch: 1100, loss is 5.425658750534057 and perplexity is 227.16093942776192
At time: 88.04416346549988 and batch: 1150, loss is 5.436044807434082 and perplexity is 229.53254034243093
At time: 89.11764025688171 and batch: 1200, loss is 5.4080379199981685 and perplexity is 223.19323479692292
At time: 90.19080543518066 and batch: 1250, loss is 5.408387050628662 and perplexity is 223.27117199604962
At time: 91.2699761390686 and batch: 1300, loss is 5.387283964157104 and perplexity is 218.60882908574123
At time: 92.34791922569275 and batch: 1350, loss is 5.356306810379028 and perplexity is 211.94076184774698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.270638427734375 and perplexity of 194.54012261725455
Finished 3 epochs...
Completing Train Step...
At time: 95.54851603507996 and batch: 50, loss is 5.4959218788146975 and perplexity is 243.69608089284122
At time: 96.62461280822754 and batch: 100, loss is 5.531217632293701 and perplexity is 252.45111658598583
At time: 97.70026135444641 and batch: 150, loss is 5.476384525299072 and perplexity is 238.98111338112997
At time: 98.77606105804443 and batch: 200, loss is 5.455457649230957 and perplexity is 234.0319511074964
At time: 99.85124588012695 and batch: 250, loss is 5.475213708877564 and perplexity is 238.70147410422615
At time: 100.92613554000854 and batch: 300, loss is 5.479209775924683 and perplexity is 239.6572495986093
At time: 102.00270462036133 and batch: 350, loss is 5.468169164657593 and perplexity is 237.02583998338085
At time: 103.07788276672363 and batch: 400, loss is 5.509928855895996 and perplexity is 247.13354434759583
At time: 104.15373063087463 and batch: 450, loss is 5.471590232849121 and perplexity is 237.8381101687511
At time: 105.22981572151184 and batch: 500, loss is 5.501581583023071 and perplexity is 245.07923906837084
At time: 106.30538249015808 and batch: 550, loss is 5.4610320091247555 and perplexity is 235.34017228988188
At time: 107.38145184516907 and batch: 600, loss is 5.431548538208008 and perplexity is 228.502816936515
At time: 108.45705509185791 and batch: 650, loss is 5.472603130340576 and perplexity is 238.0791378414688
At time: 109.53335857391357 and batch: 700, loss is 5.464826698303223 and perplexity is 236.23491165015085
At time: 110.63559913635254 and batch: 750, loss is 5.439615049362183 and perplexity is 230.35349166721537
At time: 111.7097680568695 and batch: 800, loss is 5.408679761886597 and perplexity is 223.33653554752203
At time: 112.78569865226746 and batch: 850, loss is 5.406394805908203 and perplexity is 222.8268039743085
At time: 113.8609766960144 and batch: 900, loss is 5.443606510162353 and perplexity is 231.2747760114206
At time: 114.94406986236572 and batch: 950, loss is 5.427995986938477 and perplexity is 227.69248918179898
At time: 116.02021026611328 and batch: 1000, loss is 5.425899772644043 and perplexity is 227.215696835297
At time: 117.10120868682861 and batch: 1050, loss is 5.365253286361694 and perplexity is 213.845391943293
At time: 118.18172192573547 and batch: 1100, loss is 5.360297956466675 and perplexity is 212.78833866655597
At time: 119.26339888572693 and batch: 1150, loss is 5.375721025466919 and perplexity is 216.095626602531
At time: 120.34213376045227 and batch: 1200, loss is 5.353456573486328 and perplexity is 211.33754053944858
At time: 121.42505383491516 and batch: 1250, loss is 5.363101425170899 and perplexity is 213.38572109484517
At time: 122.50895524024963 and batch: 1300, loss is 5.346737327575684 and perplexity is 209.92227172873805
At time: 123.59230947494507 and batch: 1350, loss is 5.316365852355957 and perplexity is 203.64246880822077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.250417073567708 and perplexity of 190.64576518894094
Finished 4 epochs...
Completing Train Step...
At time: 126.8673357963562 and batch: 50, loss is 5.427147970199585 and perplexity is 227.4994839870372
At time: 127.9457139968872 and batch: 100, loss is 5.459604148864746 and perplexity is 235.00437920014042
At time: 129.02554559707642 and batch: 150, loss is 5.409360761642456 and perplexity is 223.48867947281252
At time: 130.10284185409546 and batch: 200, loss is 5.384711666107178 and perplexity is 218.0472246376653
At time: 131.17906093597412 and batch: 250, loss is 5.412635154724121 and perplexity is 224.2216686511517
At time: 132.26083493232727 and batch: 300, loss is 5.410872249603272 and perplexity is 223.82673534054123
At time: 133.34242296218872 and batch: 350, loss is 5.407099075317383 and perplexity is 222.98378934940297
At time: 134.4199583530426 and batch: 400, loss is 5.4471540451049805 and perplexity is 232.09668838011257
At time: 135.49768948554993 and batch: 450, loss is 5.407739887237549 and perplexity is 223.12672581242512
At time: 136.57365942001343 and batch: 500, loss is 5.441303472518921 and perplexity is 230.74275436438293
At time: 137.64935088157654 and batch: 550, loss is 5.401900777816772 and perplexity is 221.82766082798904
At time: 138.75274920463562 and batch: 600, loss is 5.373500537872315 and perplexity is 215.61632128710252
At time: 139.83493995666504 and batch: 650, loss is 5.407240991592407 and perplexity is 223.0154366237567
At time: 140.91349816322327 and batch: 700, loss is 5.407581825256347 and perplexity is 223.0914607471907
At time: 141.99189257621765 and batch: 750, loss is 5.386958446502685 and perplexity is 218.53767963329165
At time: 143.0681447982788 and batch: 800, loss is 5.353139486312866 and perplexity is 211.2705387393396
At time: 144.14491295814514 and batch: 850, loss is 5.345841131210327 and perplexity is 209.73422442804713
At time: 145.22328972816467 and batch: 900, loss is 5.376302804946899 and perplexity is 216.22138318155342
At time: 146.29887175559998 and batch: 950, loss is 5.365528831481933 and perplexity is 213.90432411639208
At time: 147.37337636947632 and batch: 1000, loss is 5.374341192245484 and perplexity is 215.7976562998758
At time: 148.45255374908447 and batch: 1050, loss is 5.321198425292969 and perplexity is 204.62896763570697
At time: 149.53373432159424 and batch: 1100, loss is 5.319744853973389 and perplexity is 204.33174090965215
At time: 150.61017084121704 and batch: 1150, loss is 5.335258808135986 and perplexity is 207.52645139235926
At time: 151.68800854682922 and batch: 1200, loss is 5.315487756729126 and perplexity is 203.46372973340792
At time: 152.76369762420654 and batch: 1250, loss is 5.324858818054199 and perplexity is 205.37936255980748
At time: 153.8403022289276 and batch: 1300, loss is 5.300274467468261 and perplexity is 200.3918034584409
At time: 154.91646075248718 and batch: 1350, loss is 5.279570627212524 and perplexity is 196.2855775699242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2339095052083335 and perplexity of 187.52450031266835
Finished 5 epochs...
Completing Train Step...
At time: 158.1023280620575 and batch: 50, loss is 5.375430889129639 and perplexity is 216.03293850341387
At time: 159.20496439933777 and batch: 100, loss is 5.408380441665649 and perplexity is 223.269696410008
At time: 160.28224420547485 and batch: 150, loss is 5.36017617225647 and perplexity is 212.76242598470034
At time: 161.35808086395264 and batch: 200, loss is 5.332113847732544 and perplexity is 206.87481414383524
At time: 162.4349913597107 and batch: 250, loss is 5.35888521194458 and perplexity is 212.48793535327002
At time: 163.51346468925476 and batch: 300, loss is 5.357635107040405 and perplexity is 212.2224691081061
At time: 164.5898129940033 and batch: 350, loss is 5.359316701889038 and perplexity is 212.57964154442044
At time: 165.69500637054443 and batch: 400, loss is 5.4029990005493165 and perplexity is 222.07141082921487
At time: 166.77197289466858 and batch: 450, loss is 5.359774713516235 and perplexity is 212.67702779226767
At time: 167.84901094436646 and batch: 500, loss is 5.392068510055542 and perplexity is 219.65727924116894
At time: 168.92560958862305 and batch: 550, loss is 5.356118288040161 and perplexity is 211.90081004564414
At time: 170.0025384426117 and batch: 600, loss is 5.3322436714172365 and perplexity is 206.90167313790647
At time: 171.08049249649048 and batch: 650, loss is 5.361396474838257 and perplexity is 213.02221900324344
At time: 172.1575117111206 and batch: 700, loss is 5.367606620788575 and perplexity is 214.3492342884202
At time: 173.2336835861206 and batch: 750, loss is 5.34822265625 and perplexity is 210.23430697839845
At time: 174.3098602294922 and batch: 800, loss is 5.321987447738647 and perplexity is 204.79048819750224
At time: 175.38627076148987 and batch: 850, loss is 5.325934534072876 and perplexity is 205.60041130153903
At time: 176.46439838409424 and batch: 900, loss is 5.34924280166626 and perplexity is 210.4488859752838
At time: 177.54036617279053 and batch: 950, loss is 5.328782358169556 and perplexity is 206.1867596192863
At time: 178.6210596561432 and batch: 1000, loss is 5.337854452133179 and perplexity is 208.06581587644257
At time: 179.70079517364502 and batch: 1050, loss is 5.2795899295806885 and perplexity is 196.28936638297418
At time: 180.7770652770996 and batch: 1100, loss is 5.281976995468139 and perplexity is 196.7584817153851
At time: 181.85397911071777 and batch: 1150, loss is 5.301884021759033 and perplexity is 200.7146046588724
At time: 182.9309697151184 and batch: 1200, loss is 5.283417825698852 and perplexity is 197.04218161660702
At time: 184.0079152584076 and batch: 1250, loss is 5.297693157196045 and perplexity is 199.8751970852273
At time: 185.08374619483948 and batch: 1300, loss is 5.273317623138428 and perplexity is 195.06203245670326
At time: 186.16096448898315 and batch: 1350, loss is 5.248477897644043 and perplexity is 190.27642773202805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.236575113932291 and perplexity of 188.0250340738606
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 189.36224484443665 and batch: 50, loss is 5.330601291656494 and perplexity is 206.5621409142287
At time: 190.46506571769714 and batch: 100, loss is 5.354143695831299 and perplexity is 211.4828051874618
At time: 191.54512810707092 and batch: 150, loss is 5.307521486282349 and perplexity is 201.84932157993921
At time: 192.65281128883362 and batch: 200, loss is 5.280532341003418 and perplexity is 196.4744389175517
At time: 193.72946882247925 and batch: 250, loss is 5.296988544464111 and perplexity is 199.73441208184084
At time: 194.8056662082672 and batch: 300, loss is 5.298563594818115 and perplexity is 200.04925171734948
At time: 195.88220167160034 and batch: 350, loss is 5.297193632125855 and perplexity is 199.77537934618113
At time: 196.9599792957306 and batch: 400, loss is 5.329665279388427 and perplexity is 206.36888667449395
At time: 198.03589940071106 and batch: 450, loss is 5.286791467666626 and perplexity is 197.70805396583197
At time: 199.1142246723175 and batch: 500, loss is 5.317876605987549 and perplexity is 203.95035491898986
At time: 200.19054198265076 and batch: 550, loss is 5.276653251647949 and perplexity is 195.71377331168446
At time: 201.2672016620636 and batch: 600, loss is 5.2445458984375 and perplexity is 189.52972993876105
At time: 202.34406518936157 and batch: 650, loss is 5.258621768951416 and perplexity is 192.21639005700598
At time: 203.42187452316284 and batch: 700, loss is 5.263983545303344 and perplexity is 193.2497792768969
At time: 204.49813675880432 and batch: 750, loss is 5.247849607467652 and perplexity is 190.15691646949273
At time: 205.57557892799377 and batch: 800, loss is 5.220886154174805 and perplexity is 185.09813690297622
At time: 206.65352582931519 and batch: 850, loss is 5.202279663085937 and perplexity is 181.68595289516267
At time: 207.7374083995819 and batch: 900, loss is 5.223087921142578 and perplexity is 185.50612885338415
At time: 208.81752276420593 and batch: 950, loss is 5.202114839553833 and perplexity is 181.6560092424498
At time: 209.90122652053833 and batch: 1000, loss is 5.201767444610596 and perplexity is 181.59291382357966
At time: 210.97939896583557 and batch: 1050, loss is 5.143460845947265 and perplexity is 171.3076128468834
At time: 212.0569713115692 and batch: 1100, loss is 5.142339744567871 and perplexity is 171.11566726115467
At time: 213.13702058792114 and batch: 1150, loss is 5.154744110107422 and perplexity is 173.25146778669873
At time: 214.21618127822876 and batch: 1200, loss is 5.128184366226196 and perplexity is 168.71052327314993
At time: 215.2943093776703 and batch: 1250, loss is 5.1423566532135006 and perplexity is 171.11856061979535
At time: 216.37506556510925 and batch: 1300, loss is 5.118395729064941 and perplexity is 167.0671335703932
At time: 217.45981001853943 and batch: 1350, loss is 5.114209537506103 and perplexity is 166.36922036446452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.147647298177083 and perplexity of 172.02628728312243
Finished 7 epochs...
Completing Train Step...
At time: 220.71534943580627 and batch: 50, loss is 5.271144428253174 and perplexity is 194.6385849291157
At time: 221.79370498657227 and batch: 100, loss is 5.29787425994873 and perplexity is 199.91139831158483
At time: 222.87313961982727 and batch: 150, loss is 5.255472049713135 and perplexity is 191.61191485864742
At time: 223.95080542564392 and batch: 200, loss is 5.232967300415039 and perplexity is 187.34789704090315
At time: 225.02880716323853 and batch: 250, loss is 5.251666288375855 and perplexity is 190.88407151883305
At time: 226.1081726551056 and batch: 300, loss is 5.257329616546631 and perplexity is 191.9681775850618
At time: 227.18849349021912 and batch: 350, loss is 5.256476783752442 and perplexity is 191.80453061944468
At time: 228.2683129310608 and batch: 400, loss is 5.2900755405426025 and perplexity is 198.35840894528334
At time: 229.3469979763031 and batch: 450, loss is 5.250550727844239 and perplexity is 190.6712475136338
At time: 230.42469692230225 and batch: 500, loss is 5.284284982681275 and perplexity is 197.21312222568721
At time: 231.50196862220764 and batch: 550, loss is 5.24792290687561 and perplexity is 190.17085536973946
At time: 232.57923531532288 and batch: 600, loss is 5.2177551746368405 and perplexity is 184.5195047392458
At time: 233.65583848953247 and batch: 650, loss is 5.232838106155396 and perplexity is 187.32369433150842
At time: 234.7327151298523 and batch: 700, loss is 5.241399946212769 and perplexity is 188.93441536979026
At time: 235.8092303276062 and batch: 750, loss is 5.226766080856323 and perplexity is 186.189706406225
At time: 236.88631939888 and batch: 800, loss is 5.200221948623657 and perplexity is 181.31247946491624
At time: 237.96245288848877 and batch: 850, loss is 5.183943529129028 and perplexity is 178.38489176236345
At time: 239.03976464271545 and batch: 900, loss is 5.208277072906494 and perplexity is 182.77887207951267
At time: 240.11634039878845 and batch: 950, loss is 5.189342947006225 and perplexity is 179.3506713133163
At time: 241.19954872131348 and batch: 1000, loss is 5.193771314620972 and perplexity is 180.14666318935383
At time: 242.27792048454285 and batch: 1050, loss is 5.140188302993774 and perplexity is 170.74791763839357
At time: 243.35388255119324 and batch: 1100, loss is 5.142003021240234 and perplexity is 171.05805832394455
At time: 244.42990851402283 and batch: 1150, loss is 5.156555128097534 and perplexity is 173.56551359714646
At time: 245.5142879486084 and batch: 1200, loss is 5.130180425643921 and perplexity is 169.04761581845162
At time: 246.59129333496094 and batch: 1250, loss is 5.149621028900146 and perplexity is 172.3661561459827
At time: 247.66941738128662 and batch: 1300, loss is 5.125109987258911 and perplexity is 168.19263968196066
At time: 248.74975967407227 and batch: 1350, loss is 5.117069578170776 and perplexity is 166.84572418539906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1439697265625 and perplexity of 171.3948101549315
Finished 8 epochs...
Completing Train Step...
At time: 251.98827528953552 and batch: 50, loss is 5.253112535476685 and perplexity is 191.1603367796243
At time: 253.0640950202942 and batch: 100, loss is 5.278273983001709 and perplexity is 196.03122994692396
At time: 254.1417863368988 and batch: 150, loss is 5.236305570602417 and perplexity is 187.9743600098113
At time: 255.2172372341156 and batch: 200, loss is 5.213434152603149 and perplexity is 183.72391201835106
At time: 256.29336524009705 and batch: 250, loss is 5.233703231811523 and perplexity is 187.48582298619257
At time: 257.3700370788574 and batch: 300, loss is 5.239537229537964 and perplexity is 188.58281165455176
At time: 258.4461598396301 and batch: 350, loss is 5.239944658279419 and perplexity is 188.6596613664918
At time: 259.529580116272 and batch: 400, loss is 5.273878078460694 and perplexity is 195.17138665217368
At time: 260.6066951751709 and batch: 450, loss is 5.235095338821411 and perplexity is 187.74700506915048
At time: 261.6836817264557 and batch: 500, loss is 5.270333547592163 and perplexity is 194.48082023752335
At time: 262.7597396373749 and batch: 550, loss is 5.235085792541504 and perplexity is 187.7452127922432
At time: 263.84590339660645 and batch: 600, loss is 5.205186767578125 and perplexity is 182.2149014267946
At time: 264.92215275764465 and batch: 650, loss is 5.22082181930542 and perplexity is 185.08622902156532
At time: 265.99854922294617 and batch: 700, loss is 5.2312095260620115 and perplexity is 187.01887097389994
At time: 267.07605624198914 and batch: 750, loss is 5.216396551132203 and perplexity is 184.2689824243314
At time: 268.152224779129 and batch: 800, loss is 5.1907418346405025 and perplexity is 179.601738315936
At time: 269.2337317466736 and batch: 850, loss is 5.173957948684692 and perplexity is 176.61247908780365
At time: 270.31123781204224 and batch: 900, loss is 5.20035608291626 and perplexity is 181.3368013172501
At time: 271.3874831199646 and batch: 950, loss is 5.1824351406097415 and perplexity is 178.11602087147617
At time: 272.4634864330292 and batch: 1000, loss is 5.189375009536743 and perplexity is 179.3564218418764
At time: 273.54026317596436 and batch: 1050, loss is 5.137464208602905 and perplexity is 170.28341715252913
At time: 274.6426475048065 and batch: 1100, loss is 5.139967908859253 and perplexity is 170.7102899454781
At time: 275.71828722953796 and batch: 1150, loss is 5.154945001602173 and perplexity is 173.28627602925312
At time: 276.7946879863739 and batch: 1200, loss is 5.1291012191772465 and perplexity is 168.86527694662652
At time: 277.87179803848267 and batch: 1250, loss is 5.149135437011719 and perplexity is 172.28247685735496
At time: 278.94808197021484 and batch: 1300, loss is 5.12339524269104 and perplexity is 167.90447939795857
At time: 280.0247132778168 and batch: 1350, loss is 5.11357608795166 and perplexity is 166.26386722742328
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.142503255208333 and perplexity of 171.14364878107742
Finished 9 epochs...
Completing Train Step...
At time: 283.21100783348083 and batch: 50, loss is 5.2394829368591305 and perplexity is 188.57257326646234
At time: 284.31439208984375 and batch: 100, loss is 5.26389295578003 and perplexity is 193.23227366443606
At time: 285.38939929008484 and batch: 150, loss is 5.223131608963013 and perplexity is 185.51423338886457
At time: 286.4644250869751 and batch: 200, loss is 5.200847063064575 and perplexity is 181.42585594709462
At time: 287.5412812232971 and batch: 250, loss is 5.222255239486694 and perplexity is 185.3517255961353
At time: 288.6171922683716 and batch: 300, loss is 5.228137369155884 and perplexity is 186.44520131066835
At time: 289.6933403015137 and batch: 350, loss is 5.229133272171021 and perplexity is 186.6309751398152
At time: 290.7704658508301 and batch: 400, loss is 5.26250880241394 and perplexity is 192.9649955820078
At time: 291.8466353416443 and batch: 450, loss is 5.224701766967773 and perplexity is 185.80574885019288
At time: 292.9221398830414 and batch: 500, loss is 5.2608482456207275 and perplexity is 192.64483214609558
At time: 293.9999921321869 and batch: 550, loss is 5.226855926513672 and perplexity is 186.20643549429533
At time: 295.0767788887024 and batch: 600, loss is 5.197531890869141 and perplexity is 180.82539386147266
At time: 296.15235471725464 and batch: 650, loss is 5.2127054405212405 and perplexity is 183.59007895273606
At time: 297.22958302497864 and batch: 700, loss is 5.223448123931885 and perplexity is 185.5729607142194
At time: 298.30757451057434 and batch: 750, loss is 5.208770713806152 and perplexity is 182.86912147992945
At time: 299.3898000717163 and batch: 800, loss is 5.18333158493042 and perplexity is 178.27576355632186
At time: 300.4669392108917 and batch: 850, loss is 5.166219406127929 and perplexity is 175.25103051039835
At time: 301.5873260498047 and batch: 900, loss is 5.194162158966065 and perplexity is 180.21708625528078
At time: 302.66286039352417 and batch: 950, loss is 5.176758737564087 and perplexity is 177.10782671344623
At time: 303.74027824401855 and batch: 1000, loss is 5.18472840309143 and perplexity is 178.52495637853852
At time: 304.8170051574707 and batch: 1050, loss is 5.133479766845703 and perplexity is 169.60628269191355
At time: 305.89867091178894 and batch: 1100, loss is 5.136801128387451 and perplexity is 170.17054301403505
At time: 306.9760537147522 and batch: 1150, loss is 5.152290954589843 and perplexity is 172.82697587778515
At time: 308.0518250465393 and batch: 1200, loss is 5.126386699676513 and perplexity is 168.40751044849327
At time: 309.133323431015 and batch: 1250, loss is 5.146579790115356 and perplexity is 171.8427458180455
At time: 310.2121012210846 and batch: 1300, loss is 5.119470539093018 and perplexity is 167.2467955348615
At time: 311.2975962162018 and batch: 1350, loss is 5.108419361114502 and perplexity is 165.40869671664862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.142060546875 and perplexity of 171.06789883036944
Finished 10 epochs...
Completing Train Step...
At time: 314.500848531723 and batch: 50, loss is 5.228152046203613 and perplexity is 186.44793779586857
At time: 315.60515785217285 and batch: 100, loss is 5.251763381958008 and perplexity is 190.90260603688955
At time: 316.681574344635 and batch: 150, loss is 5.212321290969848 and perplexity is 183.51956645080645
At time: 317.7585368156433 and batch: 200, loss is 5.190072469711303 and perplexity is 179.48155943733457
At time: 318.84404253959656 and batch: 250, loss is 5.212211570739746 and perplexity is 183.4994317463596
At time: 319.9212338924408 and batch: 300, loss is 5.217452907562256 and perplexity is 184.46373899684303
At time: 320.9969913959503 and batch: 350, loss is 5.219982748031616 and perplexity is 184.9309936195076
At time: 322.0732123851776 and batch: 400, loss is 5.252761793136597 and perplexity is 191.09330051268597
At time: 323.1519250869751 and batch: 450, loss is 5.216084547042847 and perplexity is 184.2114987163159
At time: 324.22827768325806 and batch: 500, loss is 5.252471084594727 and perplexity is 191.03775613193693
At time: 325.3050081729889 and batch: 550, loss is 5.219208993911743 and perplexity is 184.7879578456982
At time: 326.38205194473267 and batch: 600, loss is 5.190370502471924 and perplexity is 179.53505879385867
At time: 327.4591157436371 and batch: 650, loss is 5.205319108963013 and perplexity is 182.239017594945
At time: 328.5361545085907 and batch: 700, loss is 5.216371221542358 and perplexity is 184.26431502569747
At time: 329.6410849094391 and batch: 750, loss is 5.201775817871094 and perplexity is 181.59443435471763
At time: 330.7173466682434 and batch: 800, loss is 5.176643304824829 and perplexity is 177.08738385177517
At time: 331.7935383319855 and batch: 850, loss is 5.159569664001465 and perplexity is 174.0895224945625
At time: 332.87029933929443 and batch: 900, loss is 5.18796591758728 and perplexity is 179.10387012785569
At time: 333.9469916820526 and batch: 950, loss is 5.170807266235352 and perplexity is 176.05690492807378
At time: 335.0231223106384 and batch: 1000, loss is 5.180363187789917 and perplexity is 177.74735494087267
At time: 336.1009612083435 and batch: 1050, loss is 5.129589548110962 and perplexity is 168.94775888477884
At time: 337.1770830154419 and batch: 1100, loss is 5.132735214233398 and perplexity is 169.48004889075682
At time: 338.2530999183655 and batch: 1150, loss is 5.1486639976501465 and perplexity is 172.20127525877413
At time: 339.3414218425751 and batch: 1200, loss is 5.123072099685669 and perplexity is 167.85023100533704
At time: 340.417982339859 and batch: 1250, loss is 5.143166999816895 and perplexity is 171.25728216284588
At time: 341.4946331977844 and batch: 1300, loss is 5.114940462112426 and perplexity is 166.49086817363633
At time: 342.5708348751068 and batch: 1350, loss is 5.103563718795776 and perplexity is 164.6074780388564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.141599527994791 and perplexity of 170.98905147566705
Finished 11 epochs...
Completing Train Step...
At time: 345.78141236305237 and batch: 50, loss is 5.219314250946045 and perplexity is 184.80740910178855
At time: 346.8587610721588 and batch: 100, loss is 5.241305704116821 and perplexity is 188.9166106334802
At time: 347.93635416030884 and batch: 150, loss is 5.203334808349609 and perplexity is 181.87775914176677
At time: 349.01495695114136 and batch: 200, loss is 5.181475467681885 and perplexity is 177.94516974194258
At time: 350.0972800254822 and batch: 250, loss is 5.2038864898681645 and perplexity is 181.97812542268707
At time: 351.1735291481018 and batch: 300, loss is 5.208846836090088 and perplexity is 182.88304242495818
At time: 352.2497742176056 and batch: 350, loss is 5.212043075561524 and perplexity is 183.4685155815893
At time: 353.327693939209 and batch: 400, loss is 5.2443240356445315 and perplexity is 189.48768500780167
At time: 354.40842866897583 and batch: 450, loss is 5.208814659118652 and perplexity is 182.87715789719965
At time: 355.4874758720398 and batch: 500, loss is 5.245635004043579 and perplexity is 189.73626027641558
At time: 356.60854935646057 and batch: 550, loss is 5.212255659103394 and perplexity is 183.50752211437984
At time: 357.6854078769684 and batch: 600, loss is 5.183853263854981 and perplexity is 178.36879052792472
At time: 358.76452565193176 and batch: 650, loss is 5.198439273834229 and perplexity is 180.98954620677597
At time: 359.84101033210754 and batch: 700, loss is 5.210127916336059 and perplexity is 183.11748041280686
At time: 360.9186701774597 and batch: 750, loss is 5.195622854232788 and perplexity is 180.48052085215153
At time: 361.99537444114685 and batch: 800, loss is 5.170658369064331 and perplexity is 176.0306925045175
At time: 363.0732102394104 and batch: 850, loss is 5.152907381057739 and perplexity is 172.93354384236508
At time: 364.14911007881165 and batch: 900, loss is 5.182226619720459 and perplexity is 178.07888383246734
At time: 365.22641468048096 and batch: 950, loss is 5.165244617462158 and perplexity is 175.08028102804283
At time: 366.3045778274536 and batch: 1000, loss is 5.176004838943482 and perplexity is 176.97435568532228
At time: 367.38119649887085 and batch: 1050, loss is 5.125900316238403 and perplexity is 168.32561974131403
At time: 368.45892882347107 and batch: 1100, loss is 5.128743619918823 and perplexity is 168.80490164454193
At time: 369.53705859184265 and batch: 1150, loss is 5.145024204254151 and perplexity is 171.5756374811398
At time: 370.6136450767517 and batch: 1200, loss is 5.119368991851807 and perplexity is 167.22981294645558
At time: 371.68990111351013 and batch: 1250, loss is 5.1393031406402585 and perplexity is 170.5968448815813
At time: 372.769788980484 and batch: 1300, loss is 5.10998703956604 and perplexity is 165.66820772795015
At time: 373.84552025794983 and batch: 1350, loss is 5.098087472915649 and perplexity is 163.70851074499097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.141415201822917 and perplexity of 170.95753662297142
Finished 12 epochs...
Completing Train Step...
At time: 377.0458707809448 and batch: 50, loss is 5.210227432250977 and perplexity is 183.135704423182
At time: 378.1228687763214 and batch: 100, loss is 5.232337913513184 and perplexity is 187.23001982749372
At time: 379.19908714294434 and batch: 150, loss is 5.1952981281280515 and perplexity is 180.42192363017315
At time: 380.2750492095947 and batch: 200, loss is 5.1738686275482175 and perplexity is 176.59670456496553
At time: 381.35294795036316 and batch: 250, loss is 5.1964512538909915 and perplexity is 180.6300927980587
At time: 382.42943930625916 and batch: 300, loss is 5.200993909835815 and perplexity is 181.45249970448685
At time: 383.5325343608856 and batch: 350, loss is 5.204802331924438 and perplexity is 182.14486498516825
At time: 384.60906410217285 and batch: 400, loss is 5.23702977180481 and perplexity is 188.1105405724613
At time: 385.6849720478058 and batch: 450, loss is 5.201405954360962 and perplexity is 181.52728161924554
At time: 386.7629203796387 and batch: 500, loss is 5.23906979560852 and perplexity is 188.49468224881633
At time: 387.83931732177734 and batch: 550, loss is 5.20624587059021 and perplexity is 182.40798800898406
At time: 388.91712975502014 and batch: 600, loss is 5.177988920211792 and perplexity is 177.32583575661928
At time: 389.9950430393219 and batch: 650, loss is 5.192276983261109 and perplexity is 179.8776654171352
At time: 391.0711724758148 and batch: 700, loss is 5.204435014724732 and perplexity is 182.0779723295846
At time: 392.1471312046051 and batch: 750, loss is 5.19007643699646 and perplexity is 179.48227149327363
At time: 393.2258484363556 and batch: 800, loss is 5.16525541305542 and perplexity is 175.0821711337474
At time: 394.30132007598877 and batch: 850, loss is 5.146602144241333 and perplexity is 171.84658725536957
At time: 395.3785328865051 and batch: 900, loss is 5.176313314437866 and perplexity is 177.02895635823754
At time: 396.4560706615448 and batch: 950, loss is 5.159803743362427 and perplexity is 174.13027802856678
At time: 397.5322804450989 and batch: 1000, loss is 5.171384944915771 and perplexity is 176.15863863045763
At time: 398.60895919799805 and batch: 1050, loss is 5.120998640060424 and perplexity is 167.50256089278972
At time: 399.68655347824097 and batch: 1100, loss is 5.124369258880615 and perplexity is 168.06810075118216
At time: 400.76286697387695 and batch: 1150, loss is 5.140973014831543 and perplexity is 170.8819581353429
At time: 401.8398606777191 and batch: 1200, loss is 5.1150135326385495 and perplexity is 166.50303419345178
At time: 402.91757249832153 and batch: 1250, loss is 5.13522084236145 and perplexity is 169.90183725477124
At time: 403.99369263648987 and batch: 1300, loss is 5.1051037311553955 and perplexity is 164.86117088444195
At time: 405.07029724121094 and batch: 1350, loss is 5.092435531616211 and perplexity is 162.7858497211709
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.14129638671875 and perplexity of 170.9372254921079
Finished 13 epochs...
Completing Train Step...
At time: 408.2657141685486 and batch: 50, loss is 5.202023210525513 and perplexity is 181.63936504139215
At time: 409.36827397346497 and batch: 100, loss is 5.22416823387146 and perplexity is 185.70664177449942
At time: 410.44500613212585 and batch: 150, loss is 5.188026485443115 and perplexity is 179.11471839376583
At time: 411.5484781265259 and batch: 200, loss is 5.166682710647583 and perplexity is 175.3322439167242
At time: 412.624000787735 and batch: 250, loss is 5.189686307907104 and perplexity is 179.41226389502873
At time: 413.6996982097626 and batch: 300, loss is 5.193670120239258 and perplexity is 180.12843428150157
At time: 414.7782151699066 and batch: 350, loss is 5.197917490005493 and perplexity is 180.89513342206934
At time: 415.85463428497314 and batch: 400, loss is 5.23006160736084 and perplexity is 186.8043116863071
At time: 416.9312856197357 and batch: 450, loss is 5.194793109893799 and perplexity is 180.33083027272028
At time: 418.0096151828766 and batch: 500, loss is 5.232888326644898 and perplexity is 187.33310205536137
At time: 419.0853850841522 and batch: 550, loss is 5.200376281738281 and perplexity is 181.34046414401806
At time: 420.1635992527008 and batch: 600, loss is 5.172456998825073 and perplexity is 176.34759145336795
At time: 421.2398455142975 and batch: 650, loss is 5.185788974761963 and perplexity is 178.71439532879177
At time: 422.3164048194885 and batch: 700, loss is 5.198503103256225 and perplexity is 181.001099033599
At time: 423.3945004940033 and batch: 750, loss is 5.184285345077515 and perplexity is 178.44587698560414
At time: 424.4707419872284 and batch: 800, loss is 5.159847602844239 and perplexity is 174.13791545981454
At time: 425.54667711257935 and batch: 850, loss is 5.1403293037414555 and perplexity is 170.77199491986306
At time: 426.62217807769775 and batch: 900, loss is 5.1706374073028565 and perplexity is 176.02700262980235
At time: 427.7003495693207 and batch: 950, loss is 5.154154033660888 and perplexity is 173.14926633253134
At time: 428.7759962081909 and batch: 1000, loss is 5.16657711982727 and perplexity is 175.31373141865382
At time: 429.85436725616455 and batch: 1050, loss is 5.116668767929077 and perplexity is 166.77886411035843
At time: 430.9307384490967 and batch: 1100, loss is 5.119913940429687 and perplexity is 167.32096943074237
At time: 432.00757908821106 and batch: 1150, loss is 5.136656312942505 and perplexity is 170.14590147541256
At time: 433.0915529727936 and batch: 1200, loss is 5.11056529045105 and perplexity is 165.7640332186042
At time: 434.1675820350647 and batch: 1250, loss is 5.131106023788452 and perplexity is 169.20415841458257
At time: 435.24442195892334 and batch: 1300, loss is 5.100085115432739 and perplexity is 164.03586868967668
At time: 436.32049322128296 and batch: 1350, loss is 5.086712770462036 and perplexity is 161.85692572420643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.141295979817708 and perplexity of 170.93715593758694
Finished 14 epochs...
Completing Train Step...
At time: 439.50059604644775 and batch: 50, loss is 5.194364213943482 and perplexity is 180.2535036936127
At time: 440.6039569377899 and batch: 100, loss is 5.216696557998657 and perplexity is 184.32427267764635
At time: 441.6795485019684 and batch: 150, loss is 5.181711826324463 and perplexity is 177.98723359159746
At time: 442.7574391365051 and batch: 200, loss is 5.160133666992188 and perplexity is 174.18773719999325
At time: 443.83334255218506 and batch: 250, loss is 5.183427000045777 and perplexity is 178.29277457040803
At time: 444.91046500205994 and batch: 300, loss is 5.1867171573638915 and perplexity is 178.88035192834965
At time: 445.98799443244934 and batch: 350, loss is 5.191572198867798 and perplexity is 179.75093510986116
At time: 447.0634219646454 and batch: 400, loss is 5.2238748741149905 and perplexity is 185.65217090946425
At time: 448.1389183998108 and batch: 450, loss is 5.188631610870361 and perplexity is 179.22313806470146
At time: 449.2169008255005 and batch: 500, loss is 5.227057409286499 and perplexity is 186.24395666304468
At time: 450.2929883003235 and batch: 550, loss is 5.195003833770752 and perplexity is 180.36883428844567
At time: 451.3686866760254 and batch: 600, loss is 5.16699743270874 and perplexity is 175.38743352615523
At time: 452.4532833099365 and batch: 650, loss is 5.1800139617919925 and perplexity is 177.68529178113025
At time: 453.52961468696594 and batch: 700, loss is 5.193121738433838 and perplexity is 180.02968220489868
At time: 454.6074242591858 and batch: 750, loss is 5.178761043548584 and perplexity is 177.4628060447962
At time: 455.682998418808 and batch: 800, loss is 5.1537634372711185 and perplexity is 173.08164806079665
At time: 456.7606248855591 and batch: 850, loss is 5.134652013778687 and perplexity is 169.8052197154908
At time: 457.83541107177734 and batch: 900, loss is 5.165424346923828 and perplexity is 175.11175094065155
At time: 458.91273522377014 and batch: 950, loss is 5.1486781978607175 and perplexity is 172.2037205705053
At time: 459.9905438423157 and batch: 1000, loss is 5.16190770149231 and perplexity is 174.49702651912932
At time: 461.0727972984314 and batch: 1050, loss is 5.112465181350708 and perplexity is 166.07926615607974
At time: 462.1532597541809 and batch: 1100, loss is 5.115355930328369 and perplexity is 166.5600542089113
At time: 463.23333716392517 and batch: 1150, loss is 5.132573518753052 and perplexity is 169.4526469482871
At time: 464.31217646598816 and batch: 1200, loss is 5.106520080566407 and perplexity is 165.094837344337
At time: 465.43772983551025 and batch: 1250, loss is 5.126505699157715 and perplexity is 168.42755204731336
At time: 466.51395869255066 and batch: 1300, loss is 5.095111541748047 and perplexity is 163.22204968179796
At time: 467.5900101661682 and batch: 1350, loss is 5.081732139587403 and perplexity is 161.05278036063163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.141613362630208 and perplexity of 170.99141706321797
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 470.8048589229584 and batch: 50, loss is 5.191149883270263 and perplexity is 179.675039513368
At time: 471.88186621665955 and batch: 100, loss is 5.21547565460205 and perplexity is 184.0993678685169
At time: 472.9607036113739 and batch: 150, loss is 5.182691297531128 and perplexity is 178.16165236719442
At time: 474.03754901885986 and batch: 200, loss is 5.1607935333251955 and perplexity is 174.30271575446085
At time: 475.1152517795563 and batch: 250, loss is 5.181171207427979 and perplexity is 177.89103633515515
At time: 476.1915023326874 and batch: 300, loss is 5.184572362899781 and perplexity is 178.49710148342908
At time: 477.26816391944885 and batch: 350, loss is 5.189190473556518 and perplexity is 179.32332718243384
At time: 478.3458890914917 and batch: 400, loss is 5.219822368621826 and perplexity is 184.90133687412828
At time: 479.42202138900757 and batch: 450, loss is 5.180873155593872 and perplexity is 177.8380234861852
At time: 480.49854493141174 and batch: 500, loss is 5.213814744949341 and perplexity is 183.79384924101925
At time: 481.57635855674744 and batch: 550, loss is 5.180797576904297 and perplexity is 177.82458322931836
At time: 482.65216732025146 and batch: 600, loss is 5.1537377071380615 and perplexity is 173.07719470425528
At time: 483.728333234787 and batch: 650, loss is 5.1650864696502685 and perplexity is 175.05259465402065
At time: 484.80637097358704 and batch: 700, loss is 5.174037132263184 and perplexity is 176.62646444960225
At time: 485.8827419281006 and batch: 750, loss is 5.156464414596558 and perplexity is 173.54976957586769
At time: 486.958044052124 and batch: 800, loss is 5.131273040771484 and perplexity is 169.23242074271616
At time: 488.0362460613251 and batch: 850, loss is 5.100211944580078 and perplexity is 164.05667453840175
At time: 489.1122524738312 and batch: 900, loss is 5.126046876907349 and perplexity is 168.350291464652
At time: 490.18937587738037 and batch: 950, loss is 5.110763473510742 and perplexity is 165.79688809742703
At time: 491.26964807510376 and batch: 1000, loss is 5.125704984664917 and perplexity is 168.2927436441264
At time: 492.351925611496 and batch: 1050, loss is 5.070745191574097 and perplexity is 159.29298691741215
At time: 493.4570574760437 and batch: 1100, loss is 5.069498462677002 and perplexity is 159.0945154932551
At time: 494.53529167175293 and batch: 1150, loss is 5.084035692214965 and perplexity is 161.4242015458902
At time: 495.6112778186798 and batch: 1200, loss is 5.055484819412231 and perplexity is 156.88057065582504
At time: 496.68705439567566 and batch: 1250, loss is 5.072035341262818 and perplexity is 159.4986313424202
At time: 497.76438879966736 and batch: 1300, loss is 5.047725076675415 and perplexity is 155.6679287664667
At time: 498.8409352302551 and batch: 1350, loss is 5.0437154293060305 and perplexity is 155.04500495238298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125751139322917 and perplexity of 168.30051131740888
Finished 16 epochs...
Completing Train Step...
At time: 502.1594133377075 and batch: 50, loss is 5.178796072006225 and perplexity is 177.4690224020547
At time: 503.2353687286377 and batch: 100, loss is 5.201008462905884 and perplexity is 181.45514041464443
At time: 504.31199979782104 and batch: 150, loss is 5.167779788970948 and perplexity is 175.52470267277346
At time: 505.38815093040466 and batch: 200, loss is 5.1476050472259525 and perplexity is 172.01901916240885
At time: 506.46812319755554 and batch: 250, loss is 5.168163747787475 and perplexity is 175.59210986984877
At time: 507.54713249206543 and batch: 300, loss is 5.172072334289551 and perplexity is 176.27976983413322
At time: 508.62972378730774 and batch: 350, loss is 5.176612777709961 and perplexity is 177.0819779673801
At time: 509.70976281166077 and batch: 400, loss is 5.207769393920898 and perplexity is 182.6861026376876
At time: 510.7884886264801 and batch: 450, loss is 5.16841890335083 and perplexity is 175.63691888995547
At time: 511.8644480705261 and batch: 500, loss is 5.203671569824219 and perplexity is 181.93901887851473
At time: 512.9404020309448 and batch: 550, loss is 5.17235125541687 and perplexity is 176.32894484391468
At time: 514.0173485279083 and batch: 600, loss is 5.145389013290405 and perplexity is 171.63824124260864
At time: 515.0939660072327 and batch: 650, loss is 5.157211866378784 and perplexity is 173.67953815227736
At time: 516.1694753170013 and batch: 700, loss is 5.167421007156372 and perplexity is 175.46173889725
At time: 517.2536709308624 and batch: 750, loss is 5.151025886535645 and perplexity is 172.6084762293015
At time: 518.3306770324707 and batch: 800, loss is 5.1262103462219235 and perplexity is 168.37781382087522
At time: 519.407623052597 and batch: 850, loss is 5.096282539367675 and perplexity is 163.41329426506874
At time: 520.5163495540619 and batch: 900, loss is 5.123728790283203 and perplexity is 167.96049287383585
At time: 521.5964167118073 and batch: 950, loss is 5.10976411819458 and perplexity is 165.63128085992307
At time: 522.6734712123871 and batch: 1000, loss is 5.125684051513672 and perplexity is 168.28922078354265
At time: 523.7512111663818 and batch: 1050, loss is 5.072327995300293 and perplexity is 159.54531609176138
At time: 524.8269374370575 and batch: 1100, loss is 5.072571439743042 and perplexity is 159.58416124045644
At time: 525.9041860103607 and batch: 1150, loss is 5.087320623397827 and perplexity is 161.95534083961414
At time: 526.9827446937561 and batch: 1200, loss is 5.060596494674683 and perplexity is 157.6845462685271
At time: 528.05943775177 and batch: 1250, loss is 5.078304376602173 and perplexity is 160.50167467088917
At time: 529.135772228241 and batch: 1300, loss is 5.053632669448852 and perplexity is 156.59027323279847
At time: 530.2137660980225 and batch: 1350, loss is 5.04699673652649 and perplexity is 155.5545908433362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.123818359375 and perplexity of 167.97553761640222
Finished 17 epochs...
Completing Train Step...
At time: 533.4835569858551 and batch: 50, loss is 5.174691772460937 and perplexity is 176.74212908844834
At time: 534.5879499912262 and batch: 100, loss is 5.195597457885742 and perplexity is 180.47593736441112
At time: 535.6654176712036 and batch: 150, loss is 5.161531372070312 and perplexity is 174.43137050891818
At time: 536.7429959774017 and batch: 200, loss is 5.141688346862793 and perplexity is 171.00423920412825
At time: 537.8210320472717 and batch: 250, loss is 5.162281761169433 and perplexity is 174.5623110299184
At time: 538.9007966518402 and batch: 300, loss is 5.1666077041625975 and perplexity is 175.31909335459824
At time: 539.9799830913544 and batch: 350, loss is 5.17117693901062 and perplexity is 176.122000403995
At time: 541.0590507984161 and batch: 400, loss is 5.202467079162598 and perplexity is 181.72000695467807
At time: 542.1357963085175 and batch: 450, loss is 5.163138103485108 and perplexity is 174.71186014705486
At time: 543.2139580249786 and batch: 500, loss is 5.198794794082642 and perplexity is 181.05390309461407
At time: 544.2917633056641 and batch: 550, loss is 5.1684607315063475 and perplexity is 175.64426561196234
At time: 545.3682069778442 and batch: 600, loss is 5.1417959117889405 and perplexity is 171.02263425180237
At time: 546.4464406967163 and batch: 650, loss is 5.153674240112305 and perplexity is 173.06621035805668
At time: 547.5504643917084 and batch: 700, loss is 5.164583654403686 and perplexity is 174.96459766544257
At time: 548.6305394172668 and batch: 750, loss is 5.148661766052246 and perplexity is 172.20089097519863
At time: 549.7083916664124 and batch: 800, loss is 5.1240477371215825 and perplexity is 168.01407188598466
At time: 550.7864718437195 and batch: 850, loss is 5.094580993652344 and perplexity is 163.13547550207647
At time: 551.8668565750122 and batch: 900, loss is 5.122785997390747 and perplexity is 167.80221553803847
At time: 552.942754983902 and batch: 950, loss is 5.109711322784424 and perplexity is 165.62253651934802
At time: 554.0198285579681 and batch: 1000, loss is 5.1262417411804195 and perplexity is 168.3831001183329
At time: 555.096527338028 and batch: 1050, loss is 5.07360728263855 and perplexity is 159.74955100423065
At time: 556.1734080314636 and batch: 1100, loss is 5.074426851272583 and perplexity is 159.88053039150188
At time: 557.2511870861053 and batch: 1150, loss is 5.089272375106812 and perplexity is 162.27174612471393
At time: 558.3275256156921 and batch: 1200, loss is 5.063333978652954 and perplexity is 158.11679655674376
At time: 559.4142248630524 and batch: 1250, loss is 5.081377849578858 and perplexity is 160.99573107629394
At time: 560.4920787811279 and batch: 1300, loss is 5.0563829803466795 and perplexity is 157.02153795194482
At time: 561.568736076355 and batch: 1350, loss is 5.048175849914551 and perplexity is 155.73811552091314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.123175862630208 and perplexity of 167.86764854317957
Finished 18 epochs...
Completing Train Step...
At time: 564.7580895423889 and batch: 50, loss is 5.1718370056152345 and perplexity is 176.23829103035678
At time: 565.8641579151154 and batch: 100, loss is 5.192244873046875 and perplexity is 179.87188959949475
At time: 566.9503047466278 and batch: 150, loss is 5.157317571640014 and perplexity is 173.69789796357534
At time: 568.0267441272736 and batch: 200, loss is 5.137693014144897 and perplexity is 170.32238339975964
At time: 569.1046073436737 and batch: 250, loss is 5.1583577919006345 and perplexity is 173.87867604447436
At time: 570.1834874153137 and batch: 300, loss is 5.163078136444092 and perplexity is 174.7013835079012
At time: 571.2616364955902 and batch: 350, loss is 5.1678379535675045 and perplexity is 175.53491229320656
At time: 572.338095664978 and batch: 400, loss is 5.1991180896759035 and perplexity is 181.1124464865278
At time: 573.4155111312866 and batch: 450, loss is 5.159725151062012 and perplexity is 174.11659326721008
At time: 574.4907042980194 and batch: 500, loss is 5.195561361312866 and perplexity is 180.46942291916105
At time: 575.5946912765503 and batch: 550, loss is 5.166027917861938 and perplexity is 175.21747520727868
At time: 576.6719117164612 and batch: 600, loss is 5.13960412979126 and perplexity is 170.64820040942635
At time: 577.750195980072 and batch: 650, loss is 5.151439962387085 and perplexity is 172.67996403072655
At time: 578.8269698619843 and batch: 700, loss is 5.162908573150634 and perplexity is 174.6717630772818
At time: 579.905590057373 and batch: 750, loss is 5.147080593109131 and perplexity is 171.9288267326003
At time: 580.9816999435425 and batch: 800, loss is 5.122637434005737 and perplexity is 167.77728812458227
At time: 582.0583174228668 and batch: 850, loss is 5.093521194458008 and perplexity is 162.96267623900525
At time: 583.1347403526306 and batch: 900, loss is 5.1219948387146 and perplexity is 167.6695098618844
At time: 584.2185411453247 and batch: 950, loss is 5.109611186981201 and perplexity is 165.60595260395758
At time: 585.2948386669159 and batch: 1000, loss is 5.126524477005005 and perplexity is 168.4307147838598
At time: 586.3715713024139 and batch: 1050, loss is 5.074375562667846 and perplexity is 159.87233055245449
At time: 587.4486427307129 and batch: 1100, loss is 5.075484704971314 and perplexity is 160.04975009099354
At time: 588.5255451202393 and batch: 1150, loss is 5.090242137908936 and perplexity is 162.42918755602452
At time: 589.6084096431732 and batch: 1200, loss is 5.064803609848022 and perplexity is 158.34934076868743
At time: 590.6854062080383 and batch: 1250, loss is 5.082976999282837 and perplexity is 161.25339331732525
At time: 591.7635612487793 and batch: 1300, loss is 5.057888593673706 and perplexity is 157.25812973529287
At time: 592.8419759273529 and batch: 1350, loss is 5.0485748767852785 and perplexity is 155.8002716139534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122902425130208 and perplexity of 167.82175350802888
Finished 19 epochs...
Completing Train Step...
At time: 596.0679244995117 and batch: 50, loss is 5.169241094589234 and perplexity is 175.7813854072212
At time: 597.147586107254 and batch: 100, loss is 5.189270515441894 and perplexity is 179.3376811340844
At time: 598.2233829498291 and batch: 150, loss is 5.154109449386596 and perplexity is 173.14154677023456
At time: 599.2985515594482 and batch: 200, loss is 5.1346343231201175 and perplexity is 169.80221577589649
At time: 600.3761193752289 and batch: 250, loss is 5.155507164001465 and perplexity is 173.38371844461486
At time: 601.4515488147736 and batch: 300, loss is 5.160446081161499 and perplexity is 174.2421644186893
At time: 602.552095413208 and batch: 350, loss is 5.165425062179565 and perplexity is 175.11187619038085
At time: 603.6292533874512 and batch: 400, loss is 5.196612300872803 and perplexity is 180.65918507187675
At time: 604.7050485610962 and batch: 450, loss is 5.157074394226075 and perplexity is 173.65566369336022
At time: 605.7815203666687 and batch: 500, loss is 5.1932359790802005 and perplexity is 180.05025008697987
At time: 606.8628952503204 and batch: 550, loss is 5.164201078414917 and perplexity is 174.89767321415135
At time: 607.940710067749 and batch: 600, loss is 5.1380703830718994 and perplexity is 170.3866699039293
At time: 609.0165569782257 and batch: 650, loss is 5.149733171463013 and perplexity is 172.3854868123594
At time: 610.0941174030304 and batch: 700, loss is 5.1615572357177735 and perplexity is 174.43588199873273
At time: 611.1706821918488 and batch: 750, loss is 5.14580153465271 and perplexity is 171.70906028989035
At time: 612.2559669017792 and batch: 800, loss is 5.121614055633545 and perplexity is 167.60567630346105
At time: 613.3374004364014 and batch: 850, loss is 5.092528038024902 and perplexity is 162.8009091520506
At time: 614.4135723114014 and batch: 900, loss is 5.12119758605957 and perplexity is 167.53588817218056
At time: 615.4892890453339 and batch: 950, loss is 5.109443359375 and perplexity is 165.5781616854662
At time: 616.5663838386536 and batch: 1000, loss is 5.126766767501831 and perplexity is 168.47152888966082
At time: 617.6426916122437 and batch: 1050, loss is 5.07467321395874 and perplexity is 159.9199238407721
At time: 618.7206697463989 and batch: 1100, loss is 5.076064281463623 and perplexity is 160.14253805000877
At time: 619.7967977523804 and batch: 1150, loss is 5.090751161575318 and perplexity is 162.5118889032875
At time: 620.8747684955597 and batch: 1200, loss is 5.0655832862854 and perplexity is 158.47285016098382
At time: 621.9501705169678 and batch: 1250, loss is 5.0838533306121825 and perplexity is 161.39476665374698
At time: 623.0272355079651 and batch: 1300, loss is 5.058792495727539 and perplexity is 157.40033994410993
At time: 624.1041946411133 and batch: 1350, loss is 5.048549242019654 and perplexity is 155.79627776169724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122698567708333 and perplexity of 167.78754528494278
Finished 20 epochs...
Completing Train Step...
At time: 627.3158764839172 and batch: 50, loss is 5.166898641586304 and perplexity is 175.37010766057088
At time: 628.3926436901093 and batch: 100, loss is 5.186773738861084 and perplexity is 178.89047353282515
At time: 629.4964070320129 and batch: 150, loss is 5.151452541351318 and perplexity is 172.68213617947964
At time: 630.5723462104797 and batch: 200, loss is 5.132133560180664 and perplexity is 169.37811120117115
At time: 631.6572875976562 and batch: 250, loss is 5.1532407474517825 and perplexity is 172.99120368467783
At time: 632.7335679531097 and batch: 300, loss is 5.158257207870483 and perplexity is 173.86118750602904
At time: 633.8101961612701 and batch: 350, loss is 5.163454179763794 and perplexity is 174.76709114979758
At time: 634.8887455463409 and batch: 400, loss is 5.194760704040528 and perplexity is 180.32498659297946
At time: 635.9654638767242 and batch: 450, loss is 5.155045204162597 and perplexity is 173.3036406277717
At time: 637.0431408882141 and batch: 500, loss is 5.191183109283447 and perplexity is 179.68100949777843
At time: 638.1194519996643 and batch: 550, loss is 5.1626831150054935 and perplexity is 174.6323863446393
At time: 639.1954333782196 and batch: 600, loss is 5.13671690940857 and perplexity is 170.1562120281457
At time: 640.2729165554047 and batch: 650, loss is 5.148236780166626 and perplexity is 172.12772357570026
At time: 641.3491771221161 and batch: 700, loss is 5.1602989673614506 and perplexity is 174.21653287717592
At time: 642.426873922348 and batch: 750, loss is 5.144692487716675 and perplexity is 171.51873244345222
At time: 643.5028140544891 and batch: 800, loss is 5.120600595474243 and perplexity is 167.43590067300474
At time: 644.5797231197357 and batch: 850, loss is 5.091550512313843 and perplexity is 162.6418448349667
At time: 645.6579287052155 and batch: 900, loss is 5.120408334732056 and perplexity is 167.40371241684073
At time: 646.7348425388336 and batch: 950, loss is 5.10917724609375 and perplexity is 165.53410499985134
At time: 647.8123586177826 and batch: 1000, loss is 5.126732454299927 and perplexity is 168.4657481912527
At time: 648.8886008262634 and batch: 1050, loss is 5.074756803512574 and perplexity is 159.93329203456793
At time: 649.96484208107 and batch: 1100, loss is 5.07633710861206 and perplexity is 160.1862352426277
At time: 651.0427372455597 and batch: 1150, loss is 5.090823497772217 and perplexity is 162.5236448204657
At time: 652.1196548938751 and batch: 1200, loss is 5.065945835113525 and perplexity is 158.53031472332478
At time: 653.2043628692627 and batch: 1250, loss is 5.084354066848755 and perplexity is 161.47560309898336
At time: 654.2898328304291 and batch: 1300, loss is 5.059305419921875 and perplexity is 157.48109509552893
At time: 655.3711447715759 and batch: 1350, loss is 5.0482817649841305 and perplexity is 155.75461140782082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122580159505208 and perplexity of 167.76767903938523
Finished 21 epochs...
Completing Train Step...
At time: 658.5746812820435 and batch: 50, loss is 5.164801683425903 and perplexity is 175.0027491845122
At time: 659.6781458854675 and batch: 100, loss is 5.1845245456695555 and perplexity is 178.48856645049537
At time: 660.7534327507019 and batch: 150, loss is 5.1491203880310055 and perplexity is 172.279884201192
At time: 661.8302154541016 and batch: 200, loss is 5.129887790679931 and perplexity is 168.9981538129931
At time: 662.9073479175568 and batch: 250, loss is 5.151134653091431 and perplexity is 172.62725127979067
At time: 663.9835388660431 and batch: 300, loss is 5.15626859664917 and perplexity is 173.51578874335675
At time: 665.0606656074524 and batch: 350, loss is 5.161756744384766 and perplexity is 174.47068694085428
At time: 666.1366145610809 and batch: 400, loss is 5.192909803390503 and perplexity is 179.99153164926156
At time: 667.2122824192047 and batch: 450, loss is 5.153196630477905 and perplexity is 172.98357200460836
At time: 668.2896254062653 and batch: 500, loss is 5.189349718093872 and perplexity is 179.3518857165427
At time: 669.3655638694763 and batch: 550, loss is 5.161439256668091 and perplexity is 174.41530343308764
At time: 670.4428269863129 and batch: 600, loss is 5.135364437103272 and perplexity is 169.9262360169519
At time: 671.5194344520569 and batch: 650, loss is 5.146722536087037 and perplexity is 171.86727742862615
At time: 672.5972621440887 and batch: 700, loss is 5.159195556640625 and perplexity is 174.02440650369732
At time: 673.680239200592 and batch: 750, loss is 5.143517112731933 and perplexity is 171.31725204662825
At time: 674.7567489147186 and batch: 800, loss is 5.119628276824951 and perplexity is 167.27317874582147
At time: 675.8326683044434 and batch: 850, loss is 5.0904363346099855 and perplexity is 162.46073383139424
At time: 676.9102697372437 and batch: 900, loss is 5.11954924583435 and perplexity is 167.25995950317605
At time: 677.9865438938141 and batch: 950, loss is 5.108683309555054 and perplexity is 165.45236184661857
At time: 679.0623178482056 and batch: 1000, loss is 5.1263196086883545 and perplexity is 168.39621220121344
At time: 680.1399159431458 and batch: 1050, loss is 5.0745040130615235 and perplexity is 159.89286753521557
At time: 681.2162969112396 and batch: 1100, loss is 5.0761618900299075 and perplexity is 160.15817009644744
At time: 682.2935056686401 and batch: 1150, loss is 5.0905543804168705 and perplexity is 162.47991277178096
At time: 683.3690614700317 and batch: 1200, loss is 5.065973625183106 and perplexity is 158.53472035301766
At time: 684.4711649417877 and batch: 1250, loss is 5.084321823120117 and perplexity is 161.47039660739415
At time: 685.5485215187073 and batch: 1300, loss is 5.059598550796509 and perplexity is 157.52726443317115
At time: 686.6254312992096 and batch: 1350, loss is 5.047773666381836 and perplexity is 155.67549280919044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.12251708984375 and perplexity of 167.75709832232928
Finished 22 epochs...
Completing Train Step...
At time: 689.8091723918915 and batch: 50, loss is 5.162868919372559 and perplexity is 174.66483681927977
At time: 690.9134578704834 and batch: 100, loss is 5.182359981536865 and perplexity is 178.10263433954898
At time: 691.9897239208221 and batch: 150, loss is 5.1470299911499025 and perplexity is 171.92012701723303
At time: 693.0659003257751 and batch: 200, loss is 5.127803630828858 and perplexity is 168.64630143157632
At time: 694.1429133415222 and batch: 250, loss is 5.149143390655517 and perplexity is 172.283847136258
At time: 695.2238483428955 and batch: 300, loss is 5.154483880996704 and perplexity is 173.20638857702173
At time: 696.3008823394775 and batch: 350, loss is 5.160131778717041 and perplexity is 174.18740828592874
At time: 697.3765380382538 and batch: 400, loss is 5.191213827133179 and perplexity is 179.6865289968011
At time: 698.453245639801 and batch: 450, loss is 5.151387777328491 and perplexity is 172.67095295180957
At time: 699.5301625728607 and batch: 500, loss is 5.187728242874146 and perplexity is 179.0613067252244
At time: 700.6062278747559 and batch: 550, loss is 5.160076007843018 and perplexity is 174.17769397281523
At time: 701.6823723316193 and batch: 600, loss is 5.13410795211792 and perplexity is 169.7128603325234
At time: 702.759560585022 and batch: 650, loss is 5.145432224273682 and perplexity is 171.6456580600235
At time: 703.8363091945648 and batch: 700, loss is 5.158078422546387 and perplexity is 173.8301064557736
At time: 704.914139509201 and batch: 750, loss is 5.142570762634278 and perplexity is 171.15520263825456
At time: 705.9899678230286 and batch: 800, loss is 5.118647499084473 and perplexity is 167.1092013613573
At time: 707.0659658908844 and batch: 850, loss is 5.089399557113648 and perplexity is 162.2923854834886
At time: 708.1432893276215 and batch: 900, loss is 5.118715124130249 and perplexity is 167.1205025108651
At time: 709.2204277515411 and batch: 950, loss is 5.108048057556152 and perplexity is 165.3472912797097
At time: 710.297632932663 and batch: 1000, loss is 5.125923929214477 and perplexity is 168.32959445707286
At time: 711.4187586307526 and batch: 1050, loss is 5.074256086349488 and perplexity is 159.85323073600324
At time: 712.4948501586914 and batch: 1100, loss is 5.076091976165771 and perplexity is 160.14697321131632
At time: 713.57257604599 and batch: 1150, loss is 5.090289430618286 and perplexity is 162.43686945402908
At time: 714.6496434211731 and batch: 1200, loss is 5.065854501724243 and perplexity is 158.5158362735702
At time: 715.7261176109314 and batch: 1250, loss is 5.084268808364868 and perplexity is 161.46183652074552
At time: 716.8029997348785 and batch: 1300, loss is 5.059600915908813 and perplexity is 157.5276370032831
At time: 717.8781454563141 and batch: 1350, loss is 5.04730146408081 and perplexity is 155.60199983641363
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122484537760417 and perplexity of 167.75163756816482
Finished 23 epochs...
Completing Train Step...
At time: 721.0927224159241 and batch: 50, loss is 5.161107835769653 and perplexity is 174.35750813433646
At time: 722.1733820438385 and batch: 100, loss is 5.180558338165283 and perplexity is 177.7820457887656
At time: 723.2504098415375 and batch: 150, loss is 5.14515417098999 and perplexity is 171.59793805582783
At time: 724.3262784481049 and batch: 200, loss is 5.1260531139373775 and perplexity is 168.35134147374964
At time: 725.4021582603455 and batch: 250, loss is 5.147474613189697 and perplexity is 171.99658349064623
At time: 726.4798276424408 and batch: 300, loss is 5.1527816104888915 and perplexity is 172.91179525987766
At time: 727.5554389953613 and batch: 350, loss is 5.158690671920777 and perplexity is 173.93656641639788
At time: 728.6318819522858 and batch: 400, loss is 5.189781122207641 and perplexity is 179.42927554979903
At time: 729.7082917690277 and batch: 450, loss is 5.149819707870483 and perplexity is 172.4004050785654
At time: 730.7843413352966 and batch: 500, loss is 5.186227178573608 and perplexity is 178.79272581912693
At time: 731.8617012500763 and batch: 550, loss is 5.158808584213257 and perplexity is 173.95707688488457
At time: 732.9485292434692 and batch: 600, loss is 5.132955923080444 and perplexity is 169.517458765138
At time: 734.026472568512 and batch: 650, loss is 5.144314765930176 and perplexity is 171.45395831548538
At time: 735.1036429405212 and batch: 700, loss is 5.157098236083985 and perplexity is 173.6598040163756
At time: 736.179746389389 and batch: 750, loss is 5.141511468887329 and perplexity is 170.9739949953482
At time: 737.2550673484802 and batch: 800, loss is 5.117667512893677 and perplexity is 166.94551686903915
At time: 738.3593215942383 and batch: 850, loss is 5.088331422805786 and perplexity is 162.1191279662707
At time: 739.4355804920197 and batch: 900, loss is 5.117785844802857 and perplexity is 166.96527301964773
At time: 740.5166966915131 and batch: 950, loss is 5.107400112152099 and perplexity is 165.2401899639022
At time: 741.5995128154755 and batch: 1000, loss is 5.125407886505127 and perplexity is 168.24275160632263
At time: 742.6751892566681 and batch: 1050, loss is 5.073948125839234 and perplexity is 159.8040098329363
At time: 743.7520351409912 and batch: 1100, loss is 5.075888595581055 and perplexity is 160.11440573817214
At time: 744.827474117279 and batch: 1150, loss is 5.089927520751953 and perplexity is 162.37809258492334
At time: 745.9045963287354 and batch: 1200, loss is 5.065596733093262 and perplexity is 158.47498112927858
At time: 746.9796180725098 and batch: 1250, loss is 5.084087362289429 and perplexity is 161.43254256189292
At time: 748.0562002658844 and batch: 1300, loss is 5.059522533416748 and perplexity is 157.5152900784234
At time: 749.1339783668518 and batch: 1350, loss is 5.046774559020996 and perplexity is 155.5200339513987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122427571614583 and perplexity of 167.74208167609908
Finished 24 epochs...
Completing Train Step...
At time: 752.3389403820038 and batch: 50, loss is 5.159561271667481 and perplexity is 174.08806148327722
At time: 753.4147624969482 and batch: 100, loss is 5.178844556808472 and perplexity is 177.47762716110913
At time: 754.4909834861755 and batch: 150, loss is 5.143366422653198 and perplexity is 171.2914381814242
At time: 755.5685565471649 and batch: 200, loss is 5.124348735809326 and perplexity is 168.06465151296356
At time: 756.6481940746307 and batch: 250, loss is 5.1458110523223874 and perplexity is 171.71069456778403
At time: 757.7339355945587 and batch: 300, loss is 5.151336393356323 and perplexity is 172.66208066031766
At time: 758.8101763725281 and batch: 350, loss is 5.157388515472412 and perplexity is 173.71022119525983
At time: 759.8869795799255 and batch: 400, loss is 5.1883558082580565 and perplexity is 179.17371467090157
At time: 760.9642333984375 and batch: 450, loss is 5.1483308219909665 and perplexity is 172.14391154200587
At time: 762.0424287319183 and batch: 500, loss is 5.1848666286468506 and perplexity is 178.54963479534499
At time: 763.1190040111542 and batch: 550, loss is 5.157606191635132 and perplexity is 173.74803788538148
At time: 764.1973164081573 and batch: 600, loss is 5.131819057464599 and perplexity is 169.32484970103872
At time: 765.2738027572632 and batch: 650, loss is 5.143183040618896 and perplexity is 171.26002928903333
At time: 766.385231256485 and batch: 700, loss is 5.15606722831726 and perplexity is 173.48085167614505
At time: 767.4636971950531 and batch: 750, loss is 5.140512886047364 and perplexity is 170.8033485143695
At time: 768.5401923656464 and batch: 800, loss is 5.11684549331665 and perplexity is 166.80834077431803
At time: 769.6163816452026 and batch: 850, loss is 5.087295360565186 and perplexity is 161.9512494406236
At time: 770.6942281723022 and batch: 900, loss is 5.1168998432159425 and perplexity is 166.8174070372132
At time: 771.7708446979523 and batch: 950, loss is 5.106707792282105 and perplexity is 165.12583048830496
At time: 772.8473479747772 and batch: 1000, loss is 5.12485405921936 and perplexity is 168.14959997718847
At time: 773.9249737262726 and batch: 1050, loss is 5.073562412261963 and perplexity is 159.74238314253108
At time: 775.0014960765839 and batch: 1100, loss is 5.075512237548828 and perplexity is 160.05415673380696
At time: 776.0774960517883 and batch: 1150, loss is 5.089510860443116 and perplexity is 162.3104501716515
At time: 777.1561212539673 and batch: 1200, loss is 5.065316362380981 and perplexity is 158.4305556140384
At time: 778.2350962162018 and batch: 1250, loss is 5.083739461898804 and perplexity is 161.37638988561145
At time: 779.318359375 and batch: 1300, loss is 5.059273519515991 and perplexity is 157.4760714648047
At time: 780.39399933815 and batch: 1350, loss is 5.0461204051971436 and perplexity is 155.4183331941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122385660807292 and perplexity of 167.73505161735804
Finished 25 epochs...
Completing Train Step...
At time: 783.5962066650391 and batch: 50, loss is 5.1579816532135006 and perplexity is 173.81328584620903
At time: 784.6984965801239 and batch: 100, loss is 5.177152118682861 and perplexity is 177.17751129386298
At time: 785.7760889530182 and batch: 150, loss is 5.141881656646729 and perplexity is 171.0372991919675
At time: 786.851838350296 and batch: 200, loss is 5.122853174209594 and perplexity is 167.81348833570493
At time: 787.9285378456116 and batch: 250, loss is 5.144287509918213 and perplexity is 171.44928522803158
At time: 789.006489276886 and batch: 300, loss is 5.149958829879761 and perplexity is 172.42439143779683
At time: 790.0825176239014 and batch: 350, loss is 5.156202688217163 and perplexity is 173.50435296665339
At time: 791.1590979099274 and batch: 400, loss is 5.1870352268219 and perplexity is 178.93725735439511
At time: 792.2383975982666 and batch: 450, loss is 5.146861343383789 and perplexity is 171.8911355166063
At time: 793.3425710201263 and batch: 500, loss is 5.183374452590942 and perplexity is 178.28340598503877
At time: 794.4324164390564 and batch: 550, loss is 5.156455621719361 and perplexity is 173.5482435807652
At time: 795.513721704483 and batch: 600, loss is 5.130617208480835 and perplexity is 169.12146904339878
At time: 796.5902009010315 and batch: 650, loss is 5.14213788986206 and perplexity is 171.08113024432703
At time: 797.6688470840454 and batch: 700, loss is 5.1551389980316165 and perplexity is 173.3198962090663
At time: 798.745768070221 and batch: 750, loss is 5.139478235244751 and perplexity is 170.6267180839055
At time: 799.821938753128 and batch: 800, loss is 5.116058731079102 and perplexity is 166.67715388410133
At time: 800.8981997966766 and batch: 850, loss is 5.086295804977417 and perplexity is 161.7894510410175
At time: 801.9756853580475 and batch: 900, loss is 5.115974359512329 and perplexity is 166.66309166471692
At time: 803.0519151687622 and batch: 950, loss is 5.106019716262818 and perplexity is 165.01225044451448
At time: 804.128279209137 and batch: 1000, loss is 5.124281759262085 and perplexity is 168.05339549984066
At time: 805.2064361572266 and batch: 1050, loss is 5.073182029724121 and perplexity is 159.6816314845978
At time: 806.2834742069244 and batch: 1100, loss is 5.0750831127166744 and perplexity is 159.98548825539143
At time: 807.360050201416 and batch: 1150, loss is 5.08908109664917 and perplexity is 162.24071000376162
At time: 808.4380631446838 and batch: 1200, loss is 5.065041408538819 and perplexity is 158.38700051215207
At time: 809.5151402950287 and batch: 1250, loss is 5.083530216217041 and perplexity is 161.3426261054752
At time: 810.5916795730591 and batch: 1300, loss is 5.05904860496521 and perplexity is 157.4406567877198
At time: 811.66881108284 and batch: 1350, loss is 5.045507259368897 and perplexity is 155.3230683000897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122335205078125 and perplexity of 167.72658863652651
Finished 26 epochs...
Completing Train Step...
At time: 814.8478314876556 and batch: 50, loss is 5.15650372505188 and perplexity is 173.55659203042677
At time: 815.9518759250641 and batch: 100, loss is 5.175634994506836 and perplexity is 176.90891480666144
At time: 817.0281703472137 and batch: 150, loss is 5.140233993530273 and perplexity is 170.75571938058812
At time: 818.1050188541412 and batch: 200, loss is 5.121341066360474 and perplexity is 167.559927996407
At time: 819.1823027133942 and batch: 250, loss is 5.1428446769714355 and perplexity is 171.20209092352997
At time: 820.28520154953 and batch: 300, loss is 5.148568086624145 and perplexity is 172.1847600497933
At time: 821.3609826564789 and batch: 350, loss is 5.1550334930419925 and perplexity is 173.30161105981935
At time: 822.4367911815643 and batch: 400, loss is 5.185831804275512 and perplexity is 178.72204974332416
At time: 823.5145361423492 and batch: 450, loss is 5.145507164001465 and perplexity is 171.65852162090354
At time: 824.5904853343964 and batch: 500, loss is 5.182039194107055 and perplexity is 178.04551041604503
At time: 825.6685736179352 and batch: 550, loss is 5.155348482131958 and perplexity is 173.35620777481006
At time: 826.7448327541351 and batch: 600, loss is 5.129575834274292 and perplexity is 168.94544197869462
At time: 827.8206889629364 and batch: 650, loss is 5.1410917472839355 and perplexity is 170.9022485738449
At time: 828.8981492519379 and batch: 700, loss is 5.154242496490479 and perplexity is 173.16458428409734
At time: 829.9754073619843 and batch: 750, loss is 5.138598518371582 and perplexity is 170.47668088579718
At time: 831.0517690181732 and batch: 800, loss is 5.115218391418457 and perplexity is 166.53714729595256
At time: 832.1290719509125 and batch: 850, loss is 5.08535548210144 and perplexity is 161.63738822438904
At time: 833.2039008140564 and batch: 900, loss is 5.1150720500946045 and perplexity is 166.51277781252136
At time: 834.2803614139557 and batch: 950, loss is 5.105305404663086 and perplexity is 164.89442236791507
At time: 835.3578300476074 and batch: 1000, loss is 5.1236967182159425 and perplexity is 167.9551061199939
At time: 836.4344730377197 and batch: 1050, loss is 5.07279333114624 and perplexity is 159.6195755228394
At time: 837.5119767189026 and batch: 1100, loss is 5.074781894683838 and perplexity is 159.937304998534
At time: 838.5882589817047 and batch: 1150, loss is 5.088586893081665 and perplexity is 162.16054987542546
At time: 839.6641144752502 and batch: 1200, loss is 5.064621267318725 and perplexity is 158.32046958168175
At time: 840.741537809372 and batch: 1250, loss is 5.083031272888183 and perplexity is 161.2621453578551
At time: 841.817599773407 and batch: 1300, loss is 5.0587467765808105 and perplexity is 157.3931438993726
At time: 842.8933613300323 and batch: 1350, loss is 5.044851531982422 and perplexity is 155.221252095939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.122352294921875 and perplexity of 167.72945508221252
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 846.1225180625916 and batch: 50, loss is 5.15638334274292 and perplexity is 173.53570014467496
At time: 847.1995289325714 and batch: 100, loss is 5.175725831985473 and perplexity is 176.92498549633044
At time: 848.3018591403961 and batch: 150, loss is 5.140832443237304 and perplexity is 170.85793867432773
At time: 849.3794429302216 and batch: 200, loss is 5.1226136684417725 and perplexity is 167.7733008500896
At time: 850.4564394950867 and batch: 250, loss is 5.14284158706665 and perplexity is 171.20156192618725
At time: 851.534396648407 and batch: 300, loss is 5.148922500610351 and perplexity is 172.24579555224545
At time: 852.6152594089508 and batch: 350, loss is 5.155384941101074 and perplexity is 173.36252827865417
At time: 853.6918113231659 and batch: 400, loss is 5.184537172317505 and perplexity is 178.49082017701542
At time: 854.7678866386414 and batch: 450, loss is 5.143647651672364 and perplexity is 171.33961707890995
At time: 855.8457012176514 and batch: 500, loss is 5.179184999465942 and perplexity is 177.53805840224388
At time: 856.9218451976776 and batch: 550, loss is 5.150872507095337 and perplexity is 172.58200366805028
At time: 858.0055954456329 and batch: 600, loss is 5.124756145477295 and perplexity is 168.1331366266352
At time: 859.0833208560944 and batch: 650, loss is 5.136710319519043 and perplexity is 170.15509072120082
At time: 860.1593618392944 and batch: 700, loss is 5.148030242919922 and perplexity is 172.09217646061944
At time: 861.239560842514 and batch: 750, loss is 5.132715139389038 and perplexity is 169.47664663930314
At time: 862.3171558380127 and batch: 800, loss is 5.109374618530273 and perplexity is 165.56678009395827
At time: 863.396237373352 and batch: 850, loss is 5.07642746925354 and perplexity is 160.20071042758406
At time: 864.4759442806244 and batch: 900, loss is 5.103916444778442 and perplexity is 164.66554961437657
At time: 865.55455327034 and batch: 950, loss is 5.0939202308654785 and perplexity is 163.0277172558873
At time: 866.6329622268677 and batch: 1000, loss is 5.112993679046631 and perplexity is 166.16706186345476
At time: 867.7130858898163 and batch: 1050, loss is 5.060877199172974 and perplexity is 157.72881524293507
At time: 868.7919795513153 and batch: 1100, loss is 5.0619589042663575 and perplexity is 157.89952361717042
At time: 869.8680198192596 and batch: 1150, loss is 5.075697145462036 and perplexity is 160.08375475029823
At time: 870.9459011554718 and batch: 1200, loss is 5.049869546890259 and perplexity is 156.00211219825172
At time: 872.0218806266785 and batch: 1250, loss is 5.06802656173706 and perplexity is 158.86051638036454
At time: 873.0987703800201 and batch: 1300, loss is 5.04589693069458 and perplexity is 155.38360503997322
At time: 874.1762733459473 and batch: 1350, loss is 5.035286340713501 and perplexity is 153.74360936444927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117667643229167 and perplexity of 166.94553862796633
Finished 28 epochs...
Completing Train Step...
At time: 877.4044842720032 and batch: 50, loss is 5.153872537612915 and perplexity is 173.10053235788166
At time: 878.4806363582611 and batch: 100, loss is 5.1733847332000735 and perplexity is 176.51127108978062
At time: 879.558438539505 and batch: 150, loss is 5.138478593826294 and perplexity is 170.45623777319972
At time: 880.6344587802887 and batch: 200, loss is 5.120509662628174 and perplexity is 167.42067594224696
At time: 881.7151811122894 and batch: 250, loss is 5.140842304229737 and perplexity is 170.85962351147506
At time: 882.794825553894 and batch: 300, loss is 5.1469591617584225 and perplexity is 171.90795045048773
At time: 883.8703668117523 and batch: 350, loss is 5.153290948867798 and perplexity is 172.99988830604931
At time: 884.9463367462158 and batch: 400, loss is 5.182701692581177 and perplexity is 178.16350437611345
At time: 886.0242078304291 and batch: 450, loss is 5.142075223922729 and perplexity is 171.07040962051096
At time: 887.1006681919098 and batch: 500, loss is 5.1777425956726075 and perplexity is 177.28216143109088
At time: 888.1774153709412 and batch: 550, loss is 5.149739599227905 and perplexity is 172.38659486930058
At time: 889.2536120414734 and batch: 600, loss is 5.123773813247681 and perplexity is 167.9680551233763
At time: 890.3288917541504 and batch: 650, loss is 5.135799407958984 and perplexity is 170.00016505456298
At time: 891.4041204452515 and batch: 700, loss is 5.147253770828247 and perplexity is 171.95860355293067
At time: 892.4813199043274 and batch: 750, loss is 5.132064390182495 and perplexity is 169.36639572271395
At time: 893.557779788971 and batch: 800, loss is 5.108856840133667 and perplexity is 165.48107538196888
At time: 894.6354908943176 and batch: 850, loss is 5.076289024353027 and perplexity is 160.17853299137875
At time: 895.7115113735199 and batch: 900, loss is 5.104076414108277 and perplexity is 164.69189315901858
At time: 896.787403345108 and batch: 950, loss is 5.093800868988037 and perplexity is 163.00825912278336
At time: 897.8657367229462 and batch: 1000, loss is 5.113090476989746 and perplexity is 166.18314727176133
At time: 898.9413189888 and batch: 1050, loss is 5.0610819339752195 and perplexity is 157.76111112666518
At time: 900.0183715820312 and batch: 1100, loss is 5.062438449859619 and perplexity is 157.97526179640275
At time: 901.0946388244629 and batch: 1150, loss is 5.076399784088135 and perplexity is 160.19627530581175
At time: 902.1993296146393 and batch: 1200, loss is 5.050891494750976 and perplexity is 156.16161971337993
At time: 903.2817907333374 and batch: 1250, loss is 5.069020099639893 and perplexity is 159.01842875762824
At time: 904.3685693740845 and batch: 1300, loss is 5.046838073730469 and perplexity is 155.5299120748721
At time: 905.453197479248 and batch: 1350, loss is 5.035686464309692 and perplexity is 153.80513811905195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117245279947917 and perplexity of 166.87504185115435
Finished 29 epochs...
Completing Train Step...
At time: 908.6363370418549 and batch: 50, loss is 5.152749271392822 and perplexity is 172.9062035391353
At time: 909.740131855011 and batch: 100, loss is 5.172188739776612 and perplexity is 176.30029096096249
At time: 910.8168499469757 and batch: 150, loss is 5.137256631851196 and perplexity is 170.24807394226798
At time: 911.8967323303223 and batch: 200, loss is 5.119296197891235 and perplexity is 167.21764006910695
At time: 912.9750454425812 and batch: 250, loss is 5.139766273498535 and perplexity is 170.67587218462202
At time: 914.0513799190521 and batch: 300, loss is 5.14585599899292 and perplexity is 171.71841256524746
At time: 915.1282505989075 and batch: 350, loss is 5.1521608352661135 and perplexity is 172.80448921156827
At time: 916.2049398422241 and batch: 400, loss is 5.181718235015869 and perplexity is 177.98837426050684
At time: 917.2803995609283 and batch: 450, loss is 5.141200952529907 and perplexity is 170.92091301504638
At time: 918.3554282188416 and batch: 500, loss is 5.176898746490479 and perplexity is 177.1326251260791
At time: 919.4316897392273 and batch: 550, loss is 5.149107618331909 and perplexity is 172.27768425295676
At time: 920.5078277587891 and batch: 600, loss is 5.123228673934936 and perplexity is 167.87651408681924
At time: 921.5844595432281 and batch: 650, loss is 5.135304555892945 and perplexity is 169.91606093292407
At time: 922.6620035171509 and batch: 700, loss is 5.146871709823609 and perplexity is 171.89291742495413
At time: 923.7386000156403 and batch: 750, loss is 5.131756191253662 and perplexity is 169.31420522391292
At time: 924.8170778751373 and batch: 800, loss is 5.108739490509033 and perplexity is 165.4616573792588
At time: 925.8923525810242 and batch: 850, loss is 5.076309509277344 and perplexity is 160.1818142701125
At time: 926.9687430858612 and batch: 900, loss is 5.104317064285278 and perplexity is 164.7315310615009
At time: 928.0464870929718 and batch: 950, loss is 5.093841123580932 and perplexity is 163.01482108596664
At time: 929.12961769104 and batch: 1000, loss is 5.113264970779419 and perplexity is 166.21214772903474
At time: 930.2520189285278 and batch: 1050, loss is 5.061283988952637 and perplexity is 157.79299076502252
At time: 931.3286135196686 and batch: 1100, loss is 5.0628177928924565 and perplexity is 158.03519997917311
At time: 932.405483007431 and batch: 1150, loss is 5.076923789978028 and perplexity is 160.28024109497358
At time: 933.4822747707367 and batch: 1200, loss is 5.051592807769776 and perplexity is 156.27117630256254
At time: 934.5580289363861 and batch: 1250, loss is 5.069633598327637 and perplexity is 159.1160162868479
At time: 935.6384088993073 and batch: 1300, loss is 5.04736436843872 and perplexity is 155.6117881881646
At time: 936.7179992198944 and batch: 1350, loss is 5.035820350646973 and perplexity is 153.82573190423216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117032877604166 and perplexity of 166.83960096514855
Finished 30 epochs...
Completing Train Step...
At time: 939.90851354599 and batch: 50, loss is 5.151856060028076 and perplexity is 172.75183070714664
At time: 941.01060962677 and batch: 100, loss is 5.171235609054565 and perplexity is 176.1323337926256
At time: 942.0869302749634 and batch: 150, loss is 5.136353330612183 and perplexity is 170.09435808245166
At time: 943.1646642684937 and batch: 200, loss is 5.118383979797363 and perplexity is 167.06517066546868
At time: 944.2405247688293 and batch: 250, loss is 5.138943862915039 and perplexity is 170.53556424426583
At time: 945.3171725273132 and batch: 300, loss is 5.145014524459839 and perplexity is 171.57397667229822
At time: 946.3936834335327 and batch: 350, loss is 5.15135290145874 and perplexity is 172.6649310071555
At time: 947.4691791534424 and batch: 400, loss is 5.1810030746459965 and perplexity is 177.86112953455367
At time: 948.5445606708527 and batch: 450, loss is 5.140580062866211 and perplexity is 170.81482292537405
At time: 949.6212484836578 and batch: 500, loss is 5.176274795532226 and perplexity is 177.0221375278998
At time: 950.6970133781433 and batch: 550, loss is 5.148644094467163 and perplexity is 172.19784793939004
At time: 951.7730348110199 and batch: 600, loss is 5.122827968597412 and perplexity is 167.8092585473064
At time: 952.8503923416138 and batch: 650, loss is 5.134957752227783 and perplexity is 169.85714363718031
At time: 953.9261453151703 and batch: 700, loss is 5.1466028594970705 and perplexity is 171.84671016967098
At time: 955.0108668804169 and batch: 750, loss is 5.13154390335083 and perplexity is 169.27826568126636
At time: 956.0870735645294 and batch: 800, loss is 5.1087001609802245 and perplexity is 165.4551499782055
At time: 957.2064735889435 and batch: 850, loss is 5.076358013153076 and perplexity is 160.18958389735337
At time: 958.2815818786621 and batch: 900, loss is 5.104516506195068 and perplexity is 164.7643887091455
At time: 959.359179019928 and batch: 950, loss is 5.09387396812439 and perplexity is 163.02017532127024
At time: 960.4354228973389 and batch: 1000, loss is 5.113404121398926 and perplexity is 166.23527786160966
At time: 961.5110938549042 and batch: 1050, loss is 5.0614441299438475 and perplexity is 157.8182619143892
At time: 962.5877203941345 and batch: 1100, loss is 5.063097877502441 and perplexity is 158.07946940582633
At time: 963.6744587421417 and batch: 1150, loss is 5.077310571670532 and perplexity is 160.3422465484134
At time: 964.7493855953217 and batch: 1200, loss is 5.052099504470825 and perplexity is 156.35037845610458
At time: 965.8243296146393 and batch: 1250, loss is 5.070051879882812 and perplexity is 159.1825855029607
At time: 966.90096616745 and batch: 1300, loss is 5.047712535858154 and perplexity is 155.66597657565967
At time: 967.977053642273 and batch: 1350, loss is 5.035849866867065 and perplexity is 153.83027232539857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116893310546875 and perplexity of 166.8163172778578
Finished 31 epochs...
Completing Train Step...
At time: 971.2035067081451 and batch: 50, loss is 5.151093559265137 and perplexity is 172.62015751126904
At time: 972.2858076095581 and batch: 100, loss is 5.1704152393341065 and perplexity is 175.98789941208503
At time: 973.3628039360046 and batch: 150, loss is 5.135600948333741 and perplexity is 169.9664302331256
At time: 974.440037727356 and batch: 200, loss is 5.117633848190308 and perplexity is 166.93989679233462
At time: 975.5170707702637 and batch: 250, loss is 5.138257656097412 and perplexity is 170.41858171912708
At time: 976.5935118198395 and batch: 300, loss is 5.14431339263916 and perplexity is 171.45372285946644
At time: 977.6698408126831 and batch: 350, loss is 5.1507059097290036 and perplexity is 172.553254355609
At time: 978.7480363845825 and batch: 400, loss is 5.180428590774536 and perplexity is 177.75898052856388
At time: 979.824759721756 and batch: 450, loss is 5.140088853836059 and perplexity is 170.73093774613483
At time: 980.9030146598816 and batch: 500, loss is 5.1757683753967285 and perplexity is 176.93251264886396
At time: 981.9794728755951 and batch: 550, loss is 5.148287010192871 and perplexity is 172.1363697729205
At time: 983.0558152198792 and batch: 600, loss is 5.122509212493896 and perplexity is 167.75577684618014
At time: 984.160080909729 and batch: 650, loss is 5.134697427749634 and perplexity is 169.81293141991392
At time: 985.2365591526031 and batch: 700, loss is 5.146363039016723 and perplexity is 171.80550275048103
At time: 986.3134829998016 and batch: 750, loss is 5.13137731552124 and perplexity is 169.25006833112258
At time: 987.3913238048553 and batch: 800, loss is 5.108683547973633 and perplexity is 165.4524012935403
At time: 988.4680633544922 and batch: 850, loss is 5.076385765075684 and perplexity is 160.1940295279754
At time: 989.5468988418579 and batch: 900, loss is 5.104668188095093 and perplexity is 164.78938238017707
At time: 990.6249282360077 and batch: 950, loss is 5.0938850784301755 and perplexity is 163.02198653532884
At time: 991.701101064682 and batch: 1000, loss is 5.113478002548217 and perplexity is 166.2475599686934
At time: 992.779759645462 and batch: 1050, loss is 5.061538000106811 and perplexity is 157.8330770356918
At time: 993.8569769859314 and batch: 1100, loss is 5.06330174446106 and perplexity is 158.11169987172602
At time: 994.9338839054108 and batch: 1150, loss is 5.077582378387451 and perplexity is 160.38583457152149
At time: 996.0123805999756 and batch: 1200, loss is 5.052470712661743 and perplexity is 156.4084277707646
At time: 997.0891735553741 and batch: 1250, loss is 5.0703373050689695 and perplexity is 159.22802670678442
At time: 998.1654958724976 and batch: 1300, loss is 5.0479507160186765 and perplexity is 155.7030575387479
At time: 999.2439258098602 and batch: 1350, loss is 5.035813627243042 and perplexity is 153.8246976751783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116806233723958 and perplexity of 166.801792075352
Finished 32 epochs...
Completing Train Step...
At time: 1002.4700615406036 and batch: 50, loss is 5.150405941009521 and perplexity is 172.5015015393585
At time: 1003.5463027954102 and batch: 100, loss is 5.169648599624634 and perplexity is 175.85303180404654
At time: 1004.6230890750885 and batch: 150, loss is 5.134903860092163 and perplexity is 169.8479899196183
At time: 1005.700930595398 and batch: 200, loss is 5.116918106079101 and perplexity is 166.82045362851005
At time: 1006.7777917385101 and batch: 250, loss is 5.137589025497436 and perplexity is 170.304672726348
At time: 1007.8558752536774 and batch: 300, loss is 5.143688106536866 and perplexity is 171.34654874011144
At time: 1008.9334228038788 and batch: 350, loss is 5.150060949325561 and perplexity is 172.4420002201771
At time: 1010.010332107544 and batch: 400, loss is 5.179713287353516 and perplexity is 177.6318743868233
At time: 1011.0872821807861 and batch: 450, loss is 5.139564456939698 and perplexity is 170.641430442995
At time: 1012.1930029392242 and batch: 500, loss is 5.1752769470214846 and perplexity is 176.84558435291015
At time: 1013.2699465751648 and batch: 550, loss is 5.14790636062622 and perplexity is 172.07085860755095
At time: 1014.3485283851624 and batch: 600, loss is 5.122227478027344 and perplexity is 167.70852091900355
At time: 1015.4258120059967 and batch: 650, loss is 5.134455423355103 and perplexity is 169.77184091650386
At time: 1016.5032889842987 and batch: 700, loss is 5.146102113723755 and perplexity is 171.7606801972655
At time: 1017.5814199447632 and batch: 750, loss is 5.131139316558838 and perplexity is 169.2097917835517
At time: 1018.6585068702698 and batch: 800, loss is 5.108676567077636 and perplexity is 165.45124629156598
At time: 1019.7353672981262 and batch: 850, loss is 5.076401453018189 and perplexity is 160.1965426624132
At time: 1020.8140172958374 and batch: 900, loss is 5.104814672470093 and perplexity is 164.81352321794634
At time: 1021.8970875740051 and batch: 950, loss is 5.093872747421265 and perplexity is 163.0199763221542
At time: 1022.9749603271484 and batch: 1000, loss is 5.1135280418396 and perplexity is 166.25587908692796
At time: 1024.0530469417572 and batch: 1050, loss is 5.061579751968384 and perplexity is 157.83966699804637
At time: 1025.131168603897 and batch: 1100, loss is 5.063448638916015 and perplexity is 158.1349273096499
At time: 1026.2149710655212 and batch: 1150, loss is 5.077763538360596 and perplexity is 160.4148926970105
At time: 1027.2914810180664 and batch: 1200, loss is 5.052791595458984 and perplexity is 156.45862459779815
At time: 1028.371991634369 and batch: 1250, loss is 5.070539846420288 and perplexity is 159.26028023270746
At time: 1029.4555118083954 and batch: 1300, loss is 5.048136758804321 and perplexity is 155.73202766406365
At time: 1030.5324788093567 and batch: 1350, loss is 5.035730066299439 and perplexity is 153.81184447531137
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11675048828125 and perplexity of 166.79249389477624
Finished 33 epochs...
Completing Train Step...
At time: 1033.7458941936493 and batch: 50, loss is 5.149784965515137 and perplexity is 172.39441558647542
At time: 1034.8476526737213 and batch: 100, loss is 5.1687716865539555 and perplexity is 175.69889157560715
At time: 1035.9249167442322 and batch: 150, loss is 5.134300203323364 and perplexity is 169.745490971041
At time: 1037.0019309520721 and batch: 200, loss is 5.116321697235107 and perplexity is 166.72099009801983
At time: 1038.079624414444 and batch: 250, loss is 5.1370625400543215 and perplexity is 170.21503339423546
At time: 1039.1841492652893 and batch: 300, loss is 5.143141975402832 and perplexity is 171.2529966033278
At time: 1040.261975288391 and batch: 350, loss is 5.149594488143921 and perplexity is 172.36158147855886
At time: 1041.338704109192 and batch: 400, loss is 5.179300527572632 and perplexity is 177.55857022281958
At time: 1042.4160103797913 and batch: 450, loss is 5.139191951751709 and perplexity is 170.5778774625115
At time: 1043.4949839115143 and batch: 500, loss is 5.174892501831055 and perplexity is 176.77760998560345
At time: 1044.5770409107208 and batch: 550, loss is 5.147628002166748 and perplexity is 172.02296789413066
At time: 1045.6537165641785 and batch: 600, loss is 5.1219876194000244 and perplexity is 167.66829940731733
At time: 1046.7320206165314 and batch: 650, loss is 5.134274930953979 and perplexity is 169.74120115449892
At time: 1047.8082587718964 and batch: 700, loss is 5.145926160812378 and perplexity is 171.73046106417488
At time: 1048.8861215114594 and batch: 750, loss is 5.130996170043946 and perplexity is 169.1855717251221
At time: 1049.9643177986145 and batch: 800, loss is 5.108652229309082 and perplexity is 165.44721962642694
At time: 1051.040424823761 and batch: 850, loss is 5.076396970748902 and perplexity is 160.19582461997933
At time: 1052.1176452636719 and batch: 900, loss is 5.104905366897583 and perplexity is 164.8284715639328
At time: 1053.195235490799 and batch: 950, loss is 5.093843355178833 and perplexity is 163.015184869905
At time: 1054.271103143692 and batch: 1000, loss is 5.113566617965699 and perplexity is 166.26229271839003
At time: 1055.3483817577362 and batch: 1050, loss is 5.061567821502686 and perplexity is 157.83778390854656
At time: 1056.4251856803894 and batch: 1100, loss is 5.063546943664551 and perplexity is 158.1504734880328
At time: 1057.502501964569 and batch: 1150, loss is 5.0778858089447025 and perplexity is 160.4345079187978
At time: 1058.5797078609467 and batch: 1200, loss is 5.053017807006836 and perplexity is 156.49402134886915
At time: 1059.6565675735474 and batch: 1250, loss is 5.070670585632325 and perplexity is 159.28110315741057
At time: 1060.7329423427582 and batch: 1300, loss is 5.0482424545288085 and perplexity is 155.74848874347103
At time: 1061.8111770153046 and batch: 1350, loss is 5.035636148452759 and perplexity is 153.7973994764166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116703287760417 and perplexity of 166.784621387988
Finished 34 epochs...
Completing Train Step...
At time: 1064.9995090961456 and batch: 50, loss is 5.149180736541748 and perplexity is 172.29028134935746
At time: 1066.1051313877106 and batch: 100, loss is 5.168142490386963 and perplexity is 175.58837727771515
At time: 1067.187982559204 and batch: 150, loss is 5.133760051727295 and perplexity is 169.65382743149974
At time: 1068.2643716335297 and batch: 200, loss is 5.115752820968628 and perplexity is 166.62617345565494
At time: 1069.341558933258 and batch: 250, loss is 5.136544647216797 and perplexity is 170.12690307060313
At time: 1070.4197371006012 and batch: 300, loss is 5.142633037567139 and perplexity is 171.16586164889884
At time: 1071.4961876869202 and batch: 350, loss is 5.149176721572876 and perplexity is 172.28958961062955
At time: 1072.573937177658 and batch: 400, loss is 5.178934831619262 and perplexity is 177.493649643523
At time: 1073.6505756378174 and batch: 450, loss is 5.13883111000061 and perplexity is 170.51633694637079
At time: 1074.7268035411835 and batch: 500, loss is 5.174546413421631 and perplexity is 176.7164398894829
At time: 1075.8040645122528 and batch: 550, loss is 5.147344770431519 and perplexity is 171.97425242964323
At time: 1076.880707502365 and batch: 600, loss is 5.121738443374634 and perplexity is 167.62652569160733
At time: 1077.9571917057037 and batch: 650, loss is 5.13410192489624 and perplexity is 169.71183743857483
At time: 1079.033703804016 and batch: 700, loss is 5.145718774795532 and perplexity is 171.6948502606027
At time: 1080.112066745758 and batch: 750, loss is 5.130832004547119 and perplexity is 169.15779957136098
At time: 1081.1886661052704 and batch: 800, loss is 5.108617782592773 and perplexity is 165.44152061114517
At time: 1082.2655301094055 and batch: 850, loss is 5.076368799209595 and perplexity is 160.19131172057723
At time: 1083.3429613113403 and batch: 900, loss is 5.104979543685913 and perplexity is 164.8406984640493
At time: 1084.4196646213531 and batch: 950, loss is 5.0937917137146 and perplexity is 163.00676674443017
At time: 1085.4956967830658 and batch: 1000, loss is 5.113599662780762 and perplexity is 166.26778691588171
At time: 1086.572991847992 and batch: 1050, loss is 5.061549100875855 and perplexity is 157.83482911395208
At time: 1087.6496744155884 and batch: 1100, loss is 5.0636052322387695 and perplexity is 158.15969212231235
At time: 1088.7260341644287 and batch: 1150, loss is 5.077980699539185 and perplexity is 160.44973236694676
At time: 1089.803944826126 and batch: 1200, loss is 5.0531987380981445 and perplexity is 156.52233854458837
At time: 1090.8798270225525 and batch: 1250, loss is 5.070766544342041 and perplexity is 159.29638829991126
At time: 1091.9605457782745 and batch: 1300, loss is 5.048327960968018 and perplexity is 155.76180681153787
At time: 1093.0369381904602 and batch: 1350, loss is 5.035524225234985 and perplexity is 153.78018693984114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116663411458333 and perplexity of 166.77797076664464
Finished 35 epochs...
Completing Train Step...
At time: 1096.2615175247192 and batch: 50, loss is 5.148633775711059 and perplexity is 172.19607108096307
At time: 1097.3390936851501 and batch: 100, loss is 5.16757134437561 and perplexity is 175.48811931008774
At time: 1098.414398908615 and batch: 150, loss is 5.133265972137451 and perplexity is 169.5700256421086
At time: 1099.4896335601807 and batch: 200, loss is 5.115257902145386 and perplexity is 166.5437274296949
At time: 1100.5672912597656 and batch: 250, loss is 5.136094350814819 and perplexity is 170.0503127837302
At time: 1101.6451194286346 and batch: 300, loss is 5.14216911315918 and perplexity is 171.08647204468204
At time: 1102.722781419754 and batch: 350, loss is 5.148799734115601 and perplexity is 172.2246508376478
At time: 1103.8057162761688 and batch: 400, loss is 5.1785910987854 and perplexity is 177.43264973277522
At time: 1104.8840577602386 and batch: 450, loss is 5.138517436981201 and perplexity is 170.4628589598414
At time: 1105.9641032218933 and batch: 500, loss is 5.174213018417358 and perplexity is 176.6575333313727
At time: 1107.0425662994385 and batch: 550, loss is 5.147076139450073 and perplexity is 171.92806102192898
At time: 1108.1212372779846 and batch: 600, loss is 5.121509571075439 and perplexity is 167.58816501328207
At time: 1109.2009992599487 and batch: 650, loss is 5.133922185897827 and perplexity is 169.68133634409503
At time: 1110.279155254364 and batch: 700, loss is 5.145551099777221 and perplexity is 171.66606373689928
At time: 1111.3585216999054 and batch: 750, loss is 5.1306924152374265 and perplexity is 169.13418859884774
At time: 1112.440325975418 and batch: 800, loss is 5.108578672409058 and perplexity is 165.43505028940842
At time: 1113.5303666591644 and batch: 850, loss is 5.076346855163575 and perplexity is 160.18779651362985
At time: 1114.6138355731964 and batch: 900, loss is 5.105018396377563 and perplexity is 164.84710309329577
At time: 1115.6989750862122 and batch: 950, loss is 5.0937347412109375 and perplexity is 162.99748010535887
At time: 1116.7822909355164 and batch: 1000, loss is 5.1136220359802245 and perplexity is 166.27150689985643
At time: 1117.8670942783356 and batch: 1050, loss is 5.061514291763306 and perplexity is 157.82933511924242
At time: 1118.9485538005829 and batch: 1100, loss is 5.063663148880005 and perplexity is 158.16885246572457
At time: 1120.0293757915497 and batch: 1150, loss is 5.078054256439209 and perplexity is 160.46153498594612
At time: 1121.1573984622955 and batch: 1200, loss is 5.053356657028198 and perplexity is 156.54705833663098
At time: 1122.2376191616058 and batch: 1250, loss is 5.070828943252564 and perplexity is 159.306328531118
At time: 1123.3181173801422 and batch: 1300, loss is 5.0483946609497075 and perplexity is 155.77219646769126
At time: 1124.4008340835571 and batch: 1350, loss is 5.035410661697387 and perplexity is 153.76272410938898
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116639811197917 and perplexity of 166.77403480954789
Finished 36 epochs...
Completing Train Step...
At time: 1127.617525100708 and batch: 50, loss is 5.148117208480835 and perplexity is 172.10714320406035
At time: 1128.6926448345184 and batch: 100, loss is 5.167056303024292 and perplexity is 175.3977589436381
At time: 1129.7687635421753 and batch: 150, loss is 5.132814798355103 and perplexity is 169.4935373483206
At time: 1130.846037864685 and batch: 200, loss is 5.114795570373535 and perplexity is 166.4667467697754
At time: 1131.9221177101135 and batch: 250, loss is 5.13568006515503 and perplexity is 169.97987796877553
At time: 1133.0065259933472 and batch: 300, loss is 5.141742763519287 and perplexity is 171.01354493626312
At time: 1134.0906581878662 and batch: 350, loss is 5.148444671630859 and perplexity is 172.1635111800293
At time: 1135.1687152385712 and batch: 400, loss is 5.1782714462280275 and perplexity is 177.37594199639605
At time: 1136.2443614006042 and batch: 450, loss is 5.1382238388061525 and perplexity is 170.41281872175804
At time: 1137.3210031986237 and batch: 500, loss is 5.173914527893066 and perplexity is 176.60481060063768
At time: 1138.398252248764 and batch: 550, loss is 5.1468408489227295 and perplexity is 171.88761273652182
At time: 1139.4748175144196 and batch: 600, loss is 5.121315622329712 and perplexity is 167.55566465068324
At time: 1140.5523505210876 and batch: 650, loss is 5.133767337799072 and perplexity is 169.65506354596687
At time: 1141.6293714046478 and batch: 700, loss is 5.145401859283448 and perplexity is 171.6404461204234
At time: 1142.7080237865448 and batch: 750, loss is 5.130559997558594 and perplexity is 169.11179372495357
At time: 1143.7849740982056 and batch: 800, loss is 5.10853943824768 and perplexity is 165.42855971127491
At time: 1144.862117767334 and batch: 850, loss is 5.076332902908325 and perplexity is 160.18556154819643
At time: 1145.9382560253143 and batch: 900, loss is 5.105045824050904 and perplexity is 164.85162452779647
At time: 1147.0160989761353 and batch: 950, loss is 5.093674774169922 and perplexity is 162.98770592185133
At time: 1148.118712425232 and batch: 1000, loss is 5.11362021446228 and perplexity is 166.2712040335988
At time: 1149.1960287094116 and batch: 1050, loss is 5.061495819091797 and perplexity is 157.82641961670893
At time: 1150.2735583782196 and batch: 1100, loss is 5.063691539764404 and perplexity is 158.17334308307642
At time: 1151.3483951091766 and batch: 1150, loss is 5.078116331100464 and perplexity is 160.47149589053146
At time: 1152.4272372722626 and batch: 1200, loss is 5.053477840423584 and perplexity is 156.56603039022363
At time: 1153.5049374103546 and batch: 1250, loss is 5.0708780765533445 and perplexity is 159.31415596916636
At time: 1154.5812928676605 and batch: 1300, loss is 5.048442363739014 and perplexity is 155.77962741319612
At time: 1155.6581585407257 and batch: 1350, loss is 5.035295543670654 and perplexity is 153.7450242668094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116628011067708 and perplexity of 166.77206686583267
Finished 37 epochs...
Completing Train Step...
At time: 1158.8369998931885 and batch: 50, loss is 5.147620639801025 and perplexity is 172.02170140279057
At time: 1159.9402995109558 and batch: 100, loss is 5.166560068130493 and perplexity is 175.31074204755177
At time: 1161.0173213481903 and batch: 150, loss is 5.132392559051514 and perplexity is 169.42198562218638
At time: 1162.0937073230743 and batch: 200, loss is 5.114342575073242 and perplexity is 166.3913551931378
At time: 1163.1713857650757 and batch: 250, loss is 5.135265665054321 and perplexity is 169.90945288331596
At time: 1164.2473154067993 and batch: 300, loss is 5.1413469409942625 and perplexity is 170.94586731813956
At time: 1165.3224294185638 and batch: 350, loss is 5.148092060089112 and perplexity is 172.102815040628
At time: 1166.4003367424011 and batch: 400, loss is 5.177957201004029 and perplexity is 177.32021121079663
At time: 1167.4762461185455 and batch: 450, loss is 5.137942132949829 and perplexity is 170.36481919392295
At time: 1168.5524806976318 and batch: 500, loss is 5.173613424301148 and perplexity is 176.55164226280618
At time: 1169.6315882205963 and batch: 550, loss is 5.146583786010742 and perplexity is 171.84343248505257
At time: 1170.7079985141754 and batch: 600, loss is 5.121131267547607 and perplexity is 167.524777809792
At time: 1171.7841129302979 and batch: 650, loss is 5.133612766265869 and perplexity is 169.62884172930427
At time: 1172.8615868091583 and batch: 700, loss is 5.145243740081787 and perplexity is 171.61330861564696
At time: 1173.9373581409454 and batch: 750, loss is 5.130402870178223 and perplexity is 169.08522371930812
At time: 1175.0580122470856 and batch: 800, loss is 5.1084718418121335 and perplexity is 165.4173777082368
At time: 1176.1362380981445 and batch: 850, loss is 5.076265888214111 and perplexity is 160.17482712145807
At time: 1177.212346315384 and batch: 900, loss is 5.105060815811157 and perplexity is 164.85409596235436
At time: 1178.2882461547852 and batch: 950, loss is 5.093598766326904 and perplexity is 162.97531804867953
At time: 1179.364235162735 and batch: 1000, loss is 5.113584241867065 and perplexity is 166.26522293445873
At time: 1180.4399480819702 and batch: 1050, loss is 5.061451463699341 and perplexity is 157.81941931917856
At time: 1181.5155415534973 and batch: 1100, loss is 5.063721561431885 and perplexity is 158.17809178186837
At time: 1182.5977442264557 and batch: 1150, loss is 5.078150367736816 and perplexity is 160.47695789343553
At time: 1183.6753869056702 and batch: 1200, loss is 5.053564863204956 and perplexity is 156.57965579450826
At time: 1184.7514309883118 and batch: 1250, loss is 5.070922021865845 and perplexity is 159.32115723337137
At time: 1185.8288078308105 and batch: 1300, loss is 5.048468647003173 and perplexity is 155.78372186410166
At time: 1186.9055728912354 and batch: 1350, loss is 5.035126371383667 and perplexity is 153.71901706935188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116604817708334 and perplexity of 166.76819890620789
Finished 38 epochs...
Completing Train Step...
At time: 1190.089604139328 and batch: 50, loss is 5.147140436172485 and perplexity is 171.93911578813217
At time: 1191.1924753189087 and batch: 100, loss is 5.166066980361938 and perplexity is 175.22431977358602
At time: 1192.2686760425568 and batch: 150, loss is 5.131994342803955 and perplexity is 169.35453246618061
At time: 1193.3464057445526 and batch: 200, loss is 5.113916063308716 and perplexity is 166.32040245479692
At time: 1194.423843383789 and batch: 250, loss is 5.134872360229492 and perplexity is 169.84263981552508
At time: 1195.5005178451538 and batch: 300, loss is 5.140961055755615 and perplexity is 170.87991455725057
At time: 1196.5781326293945 and batch: 350, loss is 5.147768230438232 and perplexity is 172.04709206898022
At time: 1197.6553647518158 and batch: 400, loss is 5.177663240432739 and perplexity is 177.2680937208268
At time: 1198.7319192886353 and batch: 450, loss is 5.137671184539795 and perplexity is 170.31866536997165
At time: 1199.8091342449188 and batch: 500, loss is 5.173329544067383 and perplexity is 176.5015298546267
At time: 1200.8866543769836 and batch: 550, loss is 5.146366624832154 and perplexity is 171.80611881440836
At time: 1201.9636204242706 and batch: 600, loss is 5.120948791503906 and perplexity is 167.49421134002444
At time: 1203.0663521289825 and batch: 650, loss is 5.133475513458252 and perplexity is 169.6055612922133
At time: 1204.1429936885834 and batch: 700, loss is 5.145097074508667 and perplexity is 171.5881406970625
At time: 1205.2210161685944 and batch: 750, loss is 5.130267181396484 and perplexity is 169.06228230777293
At time: 1206.297712802887 and batch: 800, loss is 5.108416814804077 and perplexity is 165.4082755352959
At time: 1207.3745791912079 and batch: 850, loss is 5.0762355995178225 and perplexity is 160.16997570823813
At time: 1208.4516816139221 and batch: 900, loss is 5.105061235427857 and perplexity is 164.85416513790054
At time: 1209.5284333229065 and batch: 950, loss is 5.093498125076294 and perplexity is 162.95891683418566
At time: 1210.6054265499115 and batch: 1000, loss is 5.113540134429932 and perplexity is 166.2578895633199
At time: 1211.684826374054 and batch: 1050, loss is 5.061419687271118 and perplexity is 157.81440446140593
At time: 1212.7667787075043 and batch: 1100, loss is 5.063713417053223 and perplexity is 158.1768035248389
At time: 1213.8450424671173 and batch: 1150, loss is 5.0781682682037355 and perplexity is 160.47983053162235
At time: 1214.921974658966 and batch: 1200, loss is 5.053630542755127 and perplexity is 156.5899402136011
At time: 1215.9984154701233 and batch: 1250, loss is 5.07093189239502 and perplexity is 159.32272982526322
At time: 1217.0766491889954 and batch: 1300, loss is 5.048478403091431 and perplexity is 155.78524171125508
At time: 1218.153730392456 and batch: 1350, loss is 5.034993143081665 and perplexity is 153.6985387099011
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116597086588541 and perplexity of 166.76690960626848
Finished 39 epochs...
Completing Train Step...
At time: 1221.375791311264 and batch: 50, loss is 5.1466868019104 and perplexity is 171.86113600270656
At time: 1222.4587292671204 and batch: 100, loss is 5.165623273849487 and perplexity is 175.14658884789694
At time: 1223.5411632061005 and batch: 150, loss is 5.1316109466552735 and perplexity is 169.28961503601292
At time: 1224.6240348815918 and batch: 200, loss is 5.11351863861084 and perplexity is 166.2543157522144
At time: 1225.7067158222198 and batch: 250, loss is 5.13449652671814 and perplexity is 169.77881925353003
At time: 1226.7889142036438 and batch: 300, loss is 5.140588331222534 and perplexity is 170.81623528903424
At time: 1227.8733756542206 and batch: 350, loss is 5.147463970184326 and perplexity is 171.9947529398256
At time: 1228.9616022109985 and batch: 400, loss is 5.177393350601196 and perplexity is 177.22025732044395
At time: 1230.0914914608002 and batch: 450, loss is 5.137409343719482 and perplexity is 170.27407482898326
At time: 1231.1728854179382 and batch: 500, loss is 5.173057537078858 and perplexity is 176.453526733909
At time: 1232.2565338611603 and batch: 550, loss is 5.146151828765869 and perplexity is 171.76921949897917
At time: 1233.3423297405243 and batch: 600, loss is 5.120762243270874 and perplexity is 167.4629685050942
At time: 1234.4275047779083 and batch: 650, loss is 5.1333459281921385 and perplexity is 169.58358433439471
At time: 1235.5103430747986 and batch: 700, loss is 5.144959268569946 and perplexity is 171.56449646145586
At time: 1236.5921030044556 and batch: 750, loss is 5.130138292312622 and perplexity is 169.04049342929503
At time: 1237.6743597984314 and batch: 800, loss is 5.108363494873047 and perplexity is 165.39945621257758
At time: 1238.7564888000488 and batch: 850, loss is 5.076189165115356 and perplexity is 160.16253848379594
At time: 1239.8382291793823 and batch: 900, loss is 5.1050506114959715 and perplexity is 164.85241374778244
At time: 1240.9264166355133 and batch: 950, loss is 5.0934113502502445 and perplexity is 162.94477671603624
At time: 1242.0099577903748 and batch: 1000, loss is 5.113491821289062 and perplexity is 166.2498573165139
At time: 1243.0922222137451 and batch: 1050, loss is 5.0613786983489994 and perplexity is 157.80793595164178
At time: 1244.176061630249 and batch: 1100, loss is 5.063676719665527 and perplexity is 158.1709989558624
At time: 1245.2573065757751 and batch: 1150, loss is 5.0781826877594 and perplexity is 160.4821445961555
At time: 1246.3446023464203 and batch: 1200, loss is 5.053680400848389 and perplexity is 156.59774768407533
At time: 1247.4279098510742 and batch: 1250, loss is 5.07092137336731 and perplexity is 159.32105391386781
At time: 1248.5097196102142 and batch: 1300, loss is 5.048470411300659 and perplexity is 155.78399671317297
At time: 1249.5923311710358 and batch: 1350, loss is 5.034854850769043 and perplexity is 153.67728485319267
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116603190104167 and perplexity of 166.76792747381333
Annealing...
Finished 40 epochs...
Completing Train Step...
At time: 1252.812120437622 and batch: 50, loss is 5.146521005630493 and perplexity is 171.83264442766057
At time: 1253.8883514404297 and batch: 100, loss is 5.1654956340789795 and perplexity is 175.12423460416682
At time: 1254.9654834270477 and batch: 150, loss is 5.131743278503418 and perplexity is 169.31201892598366
At time: 1256.0429208278656 and batch: 200, loss is 5.1138106727600094 and perplexity is 166.30287477996296
At time: 1257.1456995010376 and batch: 250, loss is 5.134424438476563 and perplexity is 169.76658063812846
At time: 1258.2232718467712 and batch: 300, loss is 5.1406725311279295 and perplexity is 170.83061860541403
At time: 1259.299362897873 and batch: 350, loss is 5.147495403289795 and perplexity is 172.00015935400458
At time: 1260.3763682842255 and batch: 400, loss is 5.17793685913086 and perplexity is 177.31660422223644
At time: 1261.4541597366333 and batch: 450, loss is 5.1375033569335935 and perplexity is 170.29008359454372
At time: 1262.5304124355316 and batch: 500, loss is 5.173071565628052 and perplexity is 176.45600213825242
At time: 1263.60693359375 and batch: 550, loss is 5.145134210586548 and perplexity is 171.594512925938
At time: 1264.684692144394 and batch: 600, loss is 5.1192646312713626 and perplexity is 167.21236165673812
At time: 1265.763432264328 and batch: 650, loss is 5.132147998809814 and perplexity is 169.38055680656046
At time: 1266.8463289737701 and batch: 700, loss is 5.143373260498047 and perplexity is 171.29260944970684
At time: 1267.9226462841034 and batch: 750, loss is 5.128859767913818 and perplexity is 168.82450913407655
At time: 1268.9993734359741 and batch: 800, loss is 5.106914529800415 and perplexity is 165.1599717217243
At time: 1270.077247619629 and batch: 850, loss is 5.074059667587281 and perplexity is 159.8218356456806
At time: 1271.1536886692047 and batch: 900, loss is 5.102418985366821 and perplexity is 164.41915416697037
At time: 1272.2373046875 and batch: 950, loss is 5.091135606765747 and perplexity is 162.57437782837775
At time: 1273.3213891983032 and batch: 1000, loss is 5.111010808944702 and perplexity is 165.83790061440902
At time: 1274.3983402252197 and batch: 1050, loss is 5.058613710403442 and perplexity is 157.37220158875743
At time: 1275.4755001068115 and batch: 1100, loss is 5.060479383468628 and perplexity is 157.66608072241974
At time: 1276.5529129505157 and batch: 1150, loss is 5.075247354507447 and perplexity is 160.01176671643174
At time: 1277.6289706230164 and batch: 1200, loss is 5.050436735153198 and perplexity is 156.09061986316598
At time: 1278.7061831951141 and batch: 1250, loss is 5.067799005508423 and perplexity is 158.82437079311043
At time: 1279.783545255661 and batch: 1300, loss is 5.0451703453063965 and perplexity is 155.27074658860383
At time: 1280.8622372150421 and batch: 1350, loss is 5.03248064994812 and perplexity is 153.31285690109337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11699951171875 and perplexity of 166.8340343070086
Annealing...
Finished 41 epochs...
Completing Train Step...
At time: 1284.0620114803314 and batch: 50, loss is 5.14626482963562 and perplexity is 171.7886306668978
At time: 1285.1661109924316 and batch: 100, loss is 5.165347671508789 and perplexity is 175.09832468920817
At time: 1286.2430925369263 and batch: 150, loss is 5.1315371036529545 and perplexity is 169.27711464411615
At time: 1287.3195178508759 and batch: 200, loss is 5.113560514450073 and perplexity is 166.26127793698538
At time: 1288.3970799446106 and batch: 250, loss is 5.13420952796936 and perplexity is 169.73009993636092
At time: 1289.4749901294708 and batch: 300, loss is 5.1404340457916256 and perplexity is 170.7898828655163
At time: 1290.5511050224304 and batch: 350, loss is 5.147328653335571 and perplexity is 171.97148072645226
At time: 1291.6275222301483 and batch: 400, loss is 5.17794900894165 and perplexity is 177.31875859851533
At time: 1292.7042775154114 and batch: 450, loss is 5.137472677230835 and perplexity is 170.28485922553776
At time: 1293.7812898159027 and batch: 500, loss is 5.172931642532348 and perplexity is 176.43131359546666
At time: 1294.8644995689392 and batch: 550, loss is 5.144992065429688 and perplexity is 171.5701233304543
At time: 1295.9427478313446 and batch: 600, loss is 5.118847742080688 and perplexity is 167.14266715906706
At time: 1297.0289475917816 and batch: 650, loss is 5.131888923645019 and perplexity is 169.33668019480837
At time: 1298.1063871383667 and batch: 700, loss is 5.143045482635498 and perplexity is 171.2364727250014
At time: 1299.1838369369507 and batch: 750, loss is 5.12875654220581 and perplexity is 168.80708300401986
At time: 1300.2742764949799 and batch: 800, loss is 5.106724691390991 and perplexity is 165.12862099127278
At time: 1301.3598821163177 and batch: 850, loss is 5.073520202636718 and perplexity is 159.73564061870363
At time: 1302.4458978176117 and batch: 900, loss is 5.101750593185425 and perplexity is 164.30929440864517
At time: 1303.5248942375183 and batch: 950, loss is 5.090620002746582 and perplexity is 162.49057543203887
At time: 1304.6099817752838 and batch: 1000, loss is 5.110444040298462 and perplexity is 165.74393552273173
At time: 1305.6874151229858 and batch: 1050, loss is 5.058028793334961 and perplexity is 157.28017881741212
At time: 1306.7642636299133 and batch: 1100, loss is 5.0598202991485595 and perplexity is 157.56219971773996
At time: 1307.839498758316 and batch: 1150, loss is 5.074642934799194 and perplexity is 159.91508167319233
At time: 1308.9162130355835 and batch: 1200, loss is 5.049798078536988 and perplexity is 155.99096338258462
At time: 1309.9919230937958 and batch: 1250, loss is 5.067178411483765 and perplexity is 158.72583591586655
At time: 1311.066400051117 and batch: 1300, loss is 5.044530115127563 and perplexity is 155.17136938628437
At time: 1312.142597913742 and batch: 1350, loss is 5.032007055282593 and perplexity is 153.24026594061093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117653401692708 and perplexity of 166.94316108392132
Annealing...
Finished 42 epochs...
Completing Train Step...
At time: 1315.3342714309692 and batch: 50, loss is 5.146162204742431 and perplexity is 171.77100178162127
At time: 1316.4392166137695 and batch: 100, loss is 5.165275554656983 and perplexity is 175.08569760459335
At time: 1317.5192375183105 and batch: 150, loss is 5.131459932327271 and perplexity is 169.26405180881582
At time: 1318.6077609062195 and batch: 200, loss is 5.113505868911743 and perplexity is 166.25219274818386
At time: 1319.68905544281 and batch: 250, loss is 5.134165868759156 and perplexity is 169.72268981601096
At time: 1320.7683880329132 and batch: 300, loss is 5.140376281738281 and perplexity is 170.78001763454242
At time: 1321.8476748466492 and batch: 350, loss is 5.147239580154419 and perplexity is 171.95616336178975
At time: 1322.9251103401184 and batch: 400, loss is 5.177866039276123 and perplexity is 177.30404713073392
At time: 1324.005870103836 and batch: 450, loss is 5.137388019561768 and perplexity is 170.27044391647016
At time: 1325.0827586650848 and batch: 500, loss is 5.172876443862915 and perplexity is 176.42157509048852
At time: 1326.1597681045532 and batch: 550, loss is 5.14493182182312 and perplexity is 171.55978763877846
At time: 1327.2403619289398 and batch: 600, loss is 5.118738775253296 and perplexity is 167.12445514517555
At time: 1328.3182694911957 and batch: 650, loss is 5.131819753646851 and perplexity is 169.32496758203482
At time: 1329.395791053772 and batch: 700, loss is 5.14297739982605 and perplexity is 171.22481486171287
At time: 1330.4759094715118 and batch: 750, loss is 5.128724899291992 and perplexity is 168.80174154055067
At time: 1331.5527424812317 and batch: 800, loss is 5.106638965606689 and perplexity is 165.1144658174679
At time: 1332.6374979019165 and batch: 850, loss is 5.073404159545898 and perplexity is 159.7171054767105
At time: 1333.7168769836426 and batch: 900, loss is 5.101617727279663 and perplexity is 164.28746475565887
At time: 1334.7953112125397 and batch: 950, loss is 5.090506553649902 and perplexity is 162.4721420686811
At time: 1335.8732843399048 and batch: 1000, loss is 5.110329570770264 and perplexity is 165.7249639784834
At time: 1336.9504218101501 and batch: 1050, loss is 5.057911672592163 and perplexity is 157.2617591247268
At time: 1338.0306475162506 and batch: 1100, loss is 5.059697542190552 and perplexity is 157.54285904853077
At time: 1339.1538481712341 and batch: 1150, loss is 5.074524974822998 and perplexity is 159.8962192064946
At time: 1340.2314524650574 and batch: 1200, loss is 5.0496627235412594 and perplexity is 155.96985065529114
At time: 1341.308744430542 and batch: 1250, loss is 5.067022552490235 and perplexity is 158.7010989946194
At time: 1342.3882451057434 and batch: 1300, loss is 5.044397039413452 and perplexity is 155.1507212194089
At time: 1343.4654886722565 and batch: 1350, loss is 5.031913061141967 and perplexity is 153.2258629304145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117727864583333 and perplexity of 166.95559261710392
Annealing...
Finished 43 epochs...
Completing Train Step...
At time: 1346.7327399253845 and batch: 50, loss is 5.146147136688232 and perplexity is 171.7684135463565
At time: 1347.8075273036957 and batch: 100, loss is 5.165264358520508 and perplexity is 175.08373733220196
At time: 1348.8849802017212 and batch: 150, loss is 5.131447248458862 and perplexity is 169.26190489947192
At time: 1349.9599449634552 and batch: 200, loss is 5.113494358062744 and perplexity is 166.25027905531147
At time: 1351.0360360145569 and batch: 250, loss is 5.13415753364563 and perplexity is 169.72127516401912
At time: 1352.1131966114044 and batch: 300, loss is 5.140364313125611 and perplexity is 170.77797364689133
At time: 1353.190493106842 and batch: 350, loss is 5.147221031188965 and perplexity is 171.95297378243782
At time: 1354.2684009075165 and batch: 400, loss is 5.177845134735107 and perplexity is 177.3003407097491
At time: 1355.347073316574 and batch: 450, loss is 5.137370777130127 and perplexity is 170.26750806529117
At time: 1356.4240341186523 and batch: 500, loss is 5.1728665733337404 and perplexity is 176.4198337247787
At time: 1357.5026383399963 and batch: 550, loss is 5.1449202537536625 and perplexity is 171.55780303471792
At time: 1358.5798997879028 and batch: 600, loss is 5.118715839385986 and perplexity is 167.12062204480608
At time: 1359.658493757248 and batch: 650, loss is 5.131806592941285 and perplexity is 169.3227391606553
At time: 1360.7362909317017 and batch: 700, loss is 5.1429617214202885 and perplexity is 171.22213035063356
At time: 1361.8128941059113 and batch: 750, loss is 5.1287162971496585 and perplexity is 168.80028949018916
At time: 1362.891538143158 and batch: 800, loss is 5.106622972488403 and perplexity is 165.11182514340177
At time: 1363.970660686493 and batch: 850, loss is 5.07338059425354 and perplexity is 159.71334174077225
At time: 1365.046977519989 and batch: 900, loss is 5.1015925693511965 and perplexity is 164.28333167536266
At time: 1366.1691961288452 and batch: 950, loss is 5.090484371185303 and perplexity is 162.46853807611416
At time: 1367.2438969612122 and batch: 1000, loss is 5.110307807922363 and perplexity is 165.72135737054418
At time: 1368.3195083141327 and batch: 1050, loss is 5.057888460159302 and perplexity is 157.25810873906883
At time: 1369.3957035541534 and batch: 1100, loss is 5.059673013687134 and perplexity is 157.5389948053664
At time: 1370.4708580970764 and batch: 1150, loss is 5.0745021343231205 and perplexity is 159.89256713862713
At time: 1371.5478043556213 and batch: 1200, loss is 5.049635925292969 and perplexity is 155.9656709925115
At time: 1372.6247243881226 and batch: 1250, loss is 5.066991853713989 and perplexity is 158.6962271398718
At time: 1373.701946735382 and batch: 1300, loss is 5.044370937347412 and perplexity is 155.14667151789047
At time: 1374.781456232071 and batch: 1350, loss is 5.031894598007202 and perplexity is 153.22303392677395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.117741292317708 and perplexity of 166.95783446750548
Annealing...
Model not improving. Stopping early with 166.76690960626848loss at 43 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
SETTINGS FOR THIS RUN
{'dropout': 0.42163053845107057, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 2.451644449031984, 'wordvec_dim': 200, 'lr': 29.419371226210124, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7319762706756592 and batch: 50, loss is 7.03611310005188 and perplexity is 1136.9597580767875
At time: 2.8090784549713135 and batch: 100, loss is 6.4142047309875485 and perplexity is 610.4550917069646
At time: 3.890977382659912 and batch: 150, loss is 6.229081268310547 and perplexity is 507.2892066670593
At time: 4.970421314239502 and batch: 200, loss is 6.186077098846436 and perplexity is 485.9360830271617
At time: 6.051462650299072 and batch: 250, loss is 6.1741334819793705 and perplexity is 480.1667704416889
At time: 7.133828163146973 and batch: 300, loss is 6.177009572982788 and perplexity is 481.54976162121085
At time: 8.214861154556274 and batch: 350, loss is 6.146611089706421 and perplexity is 467.131634110007
At time: 9.29481816291809 and batch: 400, loss is 6.190404920578003 and perplexity is 488.04368514093227
At time: 10.377954721450806 and batch: 450, loss is 6.155287847518921 and perplexity is 471.2024573999515
At time: 11.461012363433838 and batch: 500, loss is 6.151444807052612 and perplexity is 469.39508242035157
At time: 12.568944215774536 and batch: 550, loss is 6.122568998336792 and perplexity is 456.0347434265307
At time: 13.652327060699463 and batch: 600, loss is 6.076874952316285 and perplexity is 435.6655894212469
At time: 14.74193525314331 and batch: 650, loss is 6.115272130966186 and perplexity is 452.7192295309375
At time: 15.825064182281494 and batch: 700, loss is 6.115800371170044 and perplexity is 452.9584372030277
At time: 16.907507181167603 and batch: 750, loss is 6.092330732345581 and perplexity is 442.45144620869013
At time: 17.99208116531372 and batch: 800, loss is 6.044042882919311 and perplexity is 421.5940494498081
At time: 19.075621604919434 and batch: 850, loss is 6.062381315231323 and perplexity is 429.3967493626883
At time: 20.169322967529297 and batch: 900, loss is 6.090035543441773 and perplexity is 441.43710106103015
At time: 21.258059978485107 and batch: 950, loss is 6.063926887512207 and perplexity is 430.06092621045264
At time: 22.339882612228394 and batch: 1000, loss is 6.064251766204834 and perplexity is 430.20066654000857
At time: 23.423863649368286 and batch: 1050, loss is 6.0638093090057374 and perplexity is 430.01036326167406
At time: 24.507436752319336 and batch: 1100, loss is 6.065215787887573 and perplexity is 430.61558927560515
At time: 25.5887393951416 and batch: 1150, loss is 6.062396974563598 and perplexity is 429.40347348171196
At time: 26.67329692840576 and batch: 1200, loss is 6.040793676376342 and perplexity is 420.22642635401996
At time: 27.75546145439148 and batch: 1250, loss is 6.043099594116211 and perplexity is 421.1965520104246
At time: 28.8374981880188 and batch: 1300, loss is 6.01735559463501 and perplexity is 410.4916528721739
At time: 29.92229962348938 and batch: 1350, loss is 6.017019472122192 and perplexity is 410.3537005720556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4825040690104165 and perplexity of 240.44805267228324
Finished 1 epochs...
Completing Train Step...
At time: 33.15786695480347 and batch: 50, loss is 5.897154493331909 and perplexity is 364.00022775311254
At time: 34.23261499404907 and batch: 100, loss is 5.933351240158081 and perplexity is 377.4172125587039
At time: 35.310020208358765 and batch: 150, loss is 5.9053730869293215 and perplexity is 367.0041246902121
At time: 36.387059688568115 and batch: 200, loss is 5.848510465621948 and perplexity is 346.71754794724023
At time: 37.46272897720337 and batch: 250, loss is 5.864445285797119 and perplexity is 352.2866834701904
At time: 38.538164138793945 and batch: 300, loss is 5.917881307601928 and perplexity is 371.62352327060165
At time: 39.61197090148926 and batch: 350, loss is 5.868035984039307 and perplexity is 353.55391240207837
At time: 40.687273025512695 and batch: 400, loss is 5.930424547195434 and perplexity is 376.31424307253644
At time: 41.76086235046387 and batch: 450, loss is 5.935831851959229 and perplexity is 378.3546003170216
At time: 42.83525037765503 and batch: 500, loss is 5.949660024642944 and perplexity is 383.62289455785793
At time: 43.91012191772461 and batch: 550, loss is 5.927116193771362 and perplexity is 375.0713197064978
At time: 44.983787536621094 and batch: 600, loss is 5.8500213527679445 and perplexity is 347.241794973043
At time: 46.06550478935242 and batch: 650, loss is 5.922066984176635 and perplexity is 373.1822790946664
At time: 47.13943529129028 and batch: 700, loss is 5.928093547821045 and perplexity is 375.43807637609643
At time: 48.21372723579407 and batch: 750, loss is 5.85117883682251 and perplexity is 347.6439545155318
At time: 49.35344123840332 and batch: 800, loss is 5.83099760055542 and perplexity is 340.69839049901327
At time: 50.433125734329224 and batch: 850, loss is 5.867661800384521 and perplexity is 353.42164305502916
At time: 51.511194705963135 and batch: 900, loss is 5.892107505798339 and perplexity is 362.1677512741463
At time: 52.58749961853027 and batch: 950, loss is 5.847908277511596 and perplexity is 346.5088216147814
At time: 53.665140867233276 and batch: 1000, loss is 5.878756160736084 and perplexity is 357.3644612000981
At time: 54.74262046813965 and batch: 1050, loss is 5.843706674575806 and perplexity is 345.05598339457515
At time: 55.818403482437134 and batch: 1100, loss is 5.813814992904663 and perplexity is 334.8943111370167
At time: 56.89718723297119 and batch: 1150, loss is 5.804851865768432 and perplexity is 331.90602305805703
At time: 57.972076177597046 and batch: 1200, loss is 5.8371342849731445 and perplexity is 342.7955773084657
At time: 59.05343699455261 and batch: 1250, loss is 5.8196490859985355 and perplexity is 336.85382616340013
At time: 60.13510060310364 and batch: 1300, loss is 5.825639724731445 and perplexity is 338.87785229326636
At time: 61.2108256816864 and batch: 1350, loss is 5.78809455871582 and perplexity is 326.3905135261433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.608466389973958 and perplexity of 272.72566231077695
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 64.41524291038513 and batch: 50, loss is 5.775227098464966 and perplexity is 322.2176015328195
At time: 65.52060317993164 and batch: 100, loss is 5.762848396301269 and perplexity is 318.2535513282038
At time: 66.59704780578613 and batch: 150, loss is 5.69734393119812 and perplexity is 298.0746418648687
At time: 67.67487001419067 and batch: 200, loss is 5.687248620986939 and perplexity is 295.0806240862546
At time: 68.7526445388794 and batch: 250, loss is 5.727568197250366 and perplexity is 307.2212577395545
At time: 69.83055973052979 and batch: 300, loss is 5.732176151275635 and perplexity is 308.64018583782206
At time: 70.908775806427 and batch: 350, loss is 5.7117962074279784 and perplexity is 302.41377860217005
At time: 71.98757338523865 and batch: 400, loss is 5.757197341918945 and perplexity is 316.46015526420916
At time: 73.06385517120361 and batch: 450, loss is 5.727991304397583 and perplexity is 307.3512727526822
At time: 74.14008665084839 and batch: 500, loss is 5.7639487361907955 and perplexity is 318.6039311388029
At time: 75.21693634986877 and batch: 550, loss is 5.724898338317871 and perplexity is 306.4021143056145
At time: 76.29425024986267 and batch: 600, loss is 5.686838207244873 and perplexity is 294.9595437913202
At time: 77.41584706306458 and batch: 650, loss is 5.717859048843383 and perplexity is 304.25283470307636
At time: 78.492591381073 and batch: 700, loss is 5.714096403121948 and perplexity is 303.11019010782746
At time: 79.57004189491272 and batch: 750, loss is 5.69294677734375 and perplexity is 296.76683921642297
At time: 80.64489912986755 and batch: 800, loss is 5.659195117950439 and perplexity is 286.91761475564226
At time: 81.72302103042603 and batch: 850, loss is 5.653020601272583 and perplexity is 285.1514952364309
At time: 82.79893517494202 and batch: 900, loss is 5.696642589569092 and perplexity is 297.86566300132546
At time: 83.87527275085449 and batch: 950, loss is 5.635310316085816 and perplexity is 280.14583758309993
At time: 84.95338082313538 and batch: 1000, loss is 5.643181924819946 and perplexity is 282.35973805268117
At time: 86.0355658531189 and batch: 1050, loss is 5.6021206760406494 and perplexity is 271.0005027490834
At time: 87.11264085769653 and batch: 1100, loss is 5.631565647125244 and perplexity is 279.0987458901239
At time: 88.18969702720642 and batch: 1150, loss is 5.629695720672608 and perplexity is 278.57733941010133
At time: 89.2651937007904 and batch: 1200, loss is 5.591930713653564 and perplexity is 268.2530398645185
At time: 90.34354400634766 and batch: 1250, loss is 5.609971151351929 and perplexity is 273.13635827642224
At time: 91.42002511024475 and batch: 1300, loss is 5.592226009368897 and perplexity is 268.3322655347402
At time: 92.49537658691406 and batch: 1350, loss is 5.554842205047607 and perplexity is 258.4861734889091
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.422789306640625 and perplexity of 226.5100481518969
Finished 3 epochs...
Completing Train Step...
At time: 95.76058793067932 and batch: 50, loss is 5.658251457214355 and perplexity is 286.64698957736647
At time: 96.8358154296875 and batch: 100, loss is 5.6699216842651365 and perplexity is 290.0118210134571
At time: 97.90960335731506 and batch: 150, loss is 5.612589139938354 and perplexity is 273.8523629820513
At time: 98.98537230491638 and batch: 200, loss is 5.604762268066406 and perplexity is 271.71732187112906
At time: 100.06074094772339 and batch: 250, loss is 5.62826548576355 and perplexity is 278.1791931636047
At time: 101.13812208175659 and batch: 300, loss is 5.6374307632446286 and perplexity is 280.7405022831774
At time: 102.22341251373291 and batch: 350, loss is 5.622358207702637 and perplexity is 276.54075543701003
At time: 103.29869842529297 and batch: 400, loss is 5.666692657470703 and perplexity is 289.0768753673332
At time: 104.4009473323822 and batch: 450, loss is 5.6312901973724365 and perplexity is 279.0218787965565
At time: 105.47733187675476 and batch: 500, loss is 5.658617258071899 and perplexity is 286.75186447246017
At time: 106.55321788787842 and batch: 550, loss is 5.628331317901611 and perplexity is 278.19750689746417
At time: 107.62870597839355 and batch: 600, loss is 5.591209373474121 and perplexity is 268.0596079421026
At time: 108.70700430870056 and batch: 650, loss is 5.618134632110595 and perplexity is 275.37522773193893
At time: 109.78100991249084 and batch: 700, loss is 5.639388580322265 and perplexity is 281.290679230105
At time: 110.85437726974487 and batch: 750, loss is 5.618221445083618 and perplexity is 275.39913491186684
At time: 111.93043518066406 and batch: 800, loss is 5.590379505157471 and perplexity is 267.8372460448059
At time: 113.0044493675232 and batch: 850, loss is 5.582688970565796 and perplexity is 265.7853346999797
At time: 114.08295583724976 and batch: 900, loss is 5.637728252410889 and perplexity is 280.82403196510876
At time: 115.15798473358154 and batch: 950, loss is 5.619514427185059 and perplexity is 275.75545136982043
At time: 116.23228693008423 and batch: 1000, loss is 5.634054336547852 and perplexity is 279.7942010138427
At time: 117.30544257164001 and batch: 1050, loss is 5.591052513122559 and perplexity is 268.0175633154149
At time: 118.38904762268066 and batch: 1100, loss is 5.570250825881958 and perplexity is 262.499932760707
At time: 119.46330451965332 and batch: 1150, loss is 5.557555274963379 and perplexity is 259.18841673660637
At time: 120.53708672523499 and batch: 1200, loss is 5.556686820983887 and perplexity is 258.96342123791254
At time: 121.61232042312622 and batch: 1250, loss is 5.561139764785767 and perplexity is 260.1191420696811
At time: 122.68816614151001 and batch: 1300, loss is 5.551519813537598 and perplexity is 257.62880626410436
At time: 123.76881432533264 and batch: 1350, loss is 5.515709314346314 and perplexity is 248.56622632242588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.416914469401042 and perplexity of 225.18323969383232
Finished 4 epochs...
Completing Train Step...
At time: 126.97382354736328 and batch: 50, loss is 5.602221479415894 and perplexity is 271.02782189136116
At time: 128.04654049873352 and batch: 100, loss is 5.635970010757446 and perplexity is 280.3307092721623
At time: 129.12212300300598 and batch: 150, loss is 5.589915189743042 and perplexity is 267.7129139497969
At time: 130.19834566116333 and batch: 200, loss is 5.5660093402862545 and perplexity is 261.38890095536857
At time: 131.3023018836975 and batch: 250, loss is 5.592187690734863 and perplexity is 268.3219836058537
At time: 132.3848593235016 and batch: 300, loss is 5.628784971237183 and perplexity is 278.3237407554564
At time: 133.46163654327393 and batch: 350, loss is 5.6027913093566895 and perplexity is 271.18230566962444
At time: 134.53643250465393 and batch: 400, loss is 5.644142189025879 and perplexity is 282.6310082270039
At time: 135.6097230911255 and batch: 450, loss is 5.620181255340576 and perplexity is 275.9393941911414
At time: 136.68330812454224 and batch: 500, loss is 5.6396535301208495 and perplexity is 281.3652170128599
At time: 137.75825381278992 and batch: 550, loss is 5.600477924346924 and perplexity is 270.5556816795087
At time: 138.83196353912354 and batch: 600, loss is 5.569961605072021 and perplexity is 262.4240232953732
At time: 139.906973361969 and batch: 650, loss is 5.58932596206665 and perplexity is 267.5552165559672
At time: 140.9807050228119 and batch: 700, loss is 5.604756278991699 and perplexity is 271.71569454066224
At time: 142.05314779281616 and batch: 750, loss is 5.5769366359710695 and perplexity is 264.26083743730265
At time: 143.12749242782593 and batch: 800, loss is 5.554705162048339 and perplexity is 258.45075219560056
At time: 144.20074439048767 and batch: 850, loss is 5.534752159118653 and perplexity is 253.34499060981753
At time: 145.27660632133484 and batch: 900, loss is 5.601859693527222 and perplexity is 270.92978558510873
At time: 146.36470222473145 and batch: 950, loss is 5.562259578704834 and perplexity is 260.41059025900023
At time: 147.44488620758057 and batch: 1000, loss is 5.587370357513428 and perplexity is 267.0324956405238
At time: 148.51925587654114 and batch: 1050, loss is 5.564478616714478 and perplexity is 260.98909287916496
At time: 149.59358477592468 and batch: 1100, loss is 5.577408638000488 and perplexity is 264.3855985302972
At time: 150.66792392730713 and batch: 1150, loss is 5.532509260177612 and perplexity is 252.7774001606127
At time: 151.7413866519928 and batch: 1200, loss is 5.523110885620117 and perplexity is 250.41283242590598
At time: 152.8141975402832 and batch: 1250, loss is 5.542912683486938 and perplexity is 255.420877220762
At time: 153.89206337928772 and batch: 1300, loss is 5.535369472503662 and perplexity is 253.501432145305
At time: 154.96761846542358 and batch: 1350, loss is 5.500202932357788 and perplexity is 244.74159321370286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.420201416015625 and perplexity of 225.92462275698676
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 158.2051796913147 and batch: 50, loss is 5.550567846298218 and perplexity is 257.38366878055996
At time: 159.30814385414124 and batch: 100, loss is 5.552133226394654 and perplexity is 257.78688756580925
At time: 160.3922061920166 and batch: 150, loss is 5.506204080581665 and perplexity is 246.21473965507286
At time: 161.4700644016266 and batch: 200, loss is 5.479592761993408 and perplexity is 239.7490525649811
At time: 162.55201625823975 and batch: 250, loss is 5.49344804763794 and perplexity is 243.09396300634677
At time: 163.6329324245453 and batch: 300, loss is 5.511864814758301 and perplexity is 247.61244814239612
At time: 164.70831060409546 and batch: 350, loss is 5.494336709976197 and perplexity is 243.3100874725417
At time: 165.78641605377197 and batch: 400, loss is 5.534967355728149 and perplexity is 253.39951545940065
At time: 166.86292505264282 and batch: 450, loss is 5.505393743515015 and perplexity is 246.01530354132558
At time: 167.93819093704224 and batch: 500, loss is 5.52084376335144 and perplexity is 249.84575897246694
At time: 169.01410222053528 and batch: 550, loss is 5.492375898361206 and perplexity is 242.83346965856154
At time: 170.09054613113403 and batch: 600, loss is 5.460010251998901 and perplexity is 235.09983459612968
At time: 171.16646027565002 and batch: 650, loss is 5.479096260070801 and perplexity is 239.63004624531723
At time: 172.246737241745 and batch: 700, loss is 5.500969066619873 and perplexity is 244.9291699789393
At time: 173.3243007659912 and batch: 750, loss is 5.465687341690064 and perplexity is 236.43831318013926
At time: 174.39933443069458 and batch: 800, loss is 5.457424020767212 and perplexity is 234.49259762740218
At time: 175.47615599632263 and batch: 850, loss is 5.420765647888183 and perplexity is 226.05213259911764
At time: 176.55312156677246 and batch: 900, loss is 5.45464859008789 and perplexity is 233.84268199296122
At time: 177.62883806228638 and batch: 950, loss is 5.424753475189209 and perplexity is 226.9553892837618
At time: 178.71051907539368 and batch: 1000, loss is 5.4383844375610355 and perplexity is 230.07019029469316
At time: 179.78792881965637 and batch: 1050, loss is 5.413405504226684 and perplexity is 224.39446425001748
At time: 180.86375951766968 and batch: 1100, loss is 5.42667366027832 and perplexity is 227.39160431092225
At time: 181.93959546089172 and batch: 1150, loss is 5.410951833724976 and perplexity is 223.84454910352417
At time: 183.01634097099304 and batch: 1200, loss is 5.390467939376831 and perplexity is 219.30598345251605
At time: 184.0928750038147 and batch: 1250, loss is 5.391002349853515 and perplexity is 219.4232141895497
At time: 185.16746592521667 and batch: 1300, loss is 5.368107528686523 and perplexity is 214.45663040833128
At time: 186.24348092079163 and batch: 1350, loss is 5.34834475517273 and perplexity is 210.25997792796707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.31162841796875 and perplexity of 202.68000757233594
Finished 6 epochs...
Completing Train Step...
At time: 189.4913272857666 and batch: 50, loss is 5.456626024246216 and perplexity is 234.30554799270118
At time: 190.5932056903839 and batch: 100, loss is 5.476914787292481 and perplexity is 239.1078695867275
At time: 191.66781949996948 and batch: 150, loss is 5.441895008087158 and perplexity is 230.87928728876167
At time: 192.74837613105774 and batch: 200, loss is 5.421505641937256 and perplexity is 226.21947173936903
At time: 193.82556867599487 and batch: 250, loss is 5.441810665130615 and perplexity is 230.85981506825098
At time: 194.89983367919922 and batch: 300, loss is 5.457002439498901 and perplexity is 234.3937607760315
At time: 195.97597885131836 and batch: 350, loss is 5.443291416168213 and perplexity is 231.20191419826602
At time: 197.05296325683594 and batch: 400, loss is 5.47975419998169 and perplexity is 239.78776029408448
At time: 198.12754154205322 and batch: 450, loss is 5.443083238601685 and perplexity is 231.15378815594653
At time: 199.2043480873108 and batch: 500, loss is 5.4634559535980225 and perplexity is 235.91131573018802
At time: 200.28002953529358 and batch: 550, loss is 5.434974222183228 and perplexity is 229.2869376828998
At time: 201.35562252998352 and batch: 600, loss is 5.408050746917724 and perplexity is 223.1960976969521
At time: 202.43220329284668 and batch: 650, loss is 5.431110563278199 and perplexity is 228.40276034404488
At time: 203.50782823562622 and batch: 700, loss is 5.4526745796203615 and perplexity is 233.38152940072263
At time: 204.5824019908905 and batch: 750, loss is 5.424310111999512 and perplexity is 226.85478792156846
At time: 205.65844106674194 and batch: 800, loss is 5.412560710906982 and perplexity is 224.2049773555416
At time: 206.73445296287537 and batch: 850, loss is 5.382991819381714 and perplexity is 217.67253912555734
At time: 207.8092555999756 and batch: 900, loss is 5.420688714981079 and perplexity is 226.0347424203467
At time: 208.88581371307373 and batch: 950, loss is 5.390153694152832 and perplexity is 219.23707842172718
At time: 209.96212005615234 and batch: 1000, loss is 5.404711685180664 and perplexity is 222.45207500739775
At time: 211.0373067855835 and batch: 1050, loss is 5.374784469604492 and perplexity is 215.89333571973418
At time: 212.11468362808228 and batch: 1100, loss is 5.38220477104187 and perplexity is 217.50128771541802
At time: 213.23538780212402 and batch: 1150, loss is 5.385645599365234 and perplexity is 218.25096131600242
At time: 214.31060767173767 and batch: 1200, loss is 5.3641985988616945 and perplexity is 213.61997077681698
At time: 215.3869605064392 and batch: 1250, loss is 5.379886560440063 and perplexity is 216.99765790985322
At time: 216.45884370803833 and batch: 1300, loss is 5.3581122875213625 and perplexity is 212.32376169348532
At time: 217.53258228302002 and batch: 1350, loss is 5.325354890823364 and perplexity is 205.4812709438191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.304864095052083 and perplexity of 201.3136410345651
Finished 7 epochs...
Completing Train Step...
At time: 220.7625811100006 and batch: 50, loss is 5.412377119064331 and perplexity is 224.1638189289086
At time: 221.8389527797699 and batch: 100, loss is 5.4342959594726565 and perplexity is 229.13147363174278
At time: 222.91340279579163 and batch: 150, loss is 5.401903705596924 and perplexity is 221.82831029156225
At time: 223.98907613754272 and batch: 200, loss is 5.380296983718872 and perplexity is 217.08673707893834
At time: 225.06588983535767 and batch: 250, loss is 5.3988447093963625 and perplexity is 221.1507751502487
At time: 226.1405382156372 and batch: 300, loss is 5.410599088668823 and perplexity is 223.7656029702288
At time: 227.21603536605835 and batch: 350, loss is 5.408840932846069 and perplexity is 223.372533812101
At time: 228.2933430671692 and batch: 400, loss is 5.449336175918579 and perplexity is 232.6037067045265
At time: 229.3665726184845 and batch: 450, loss is 5.419035730361938 and perplexity is 225.66141910159075
At time: 230.440123796463 and batch: 500, loss is 5.434747095108032 and perplexity is 229.23486632499484
At time: 231.52061486244202 and batch: 550, loss is 5.4063740158081055 and perplexity is 222.82217143090514
At time: 232.5962746143341 and batch: 600, loss is 5.380897550582886 and perplexity is 217.21715133716606
At time: 233.67057824134827 and batch: 650, loss is 5.4003201103210445 and perplexity is 221.47730202819616
At time: 234.7431480884552 and batch: 700, loss is 5.418822412490845 and perplexity is 225.61328662202163
At time: 235.8165237903595 and batch: 750, loss is 5.389536695480347 and perplexity is 219.10185115719275
At time: 236.89830446243286 and batch: 800, loss is 5.378055772781372 and perplexity is 216.60074471853702
At time: 237.97186374664307 and batch: 850, loss is 5.346171054840088 and perplexity is 209.80343212065432
At time: 239.05213856697083 and batch: 900, loss is 5.382122001647949 and perplexity is 217.48328601066217
At time: 240.17192196846008 and batch: 950, loss is 5.359318590164184 and perplexity is 212.5800429536531
At time: 241.2442762851715 and batch: 1000, loss is 5.3770576763153075 and perplexity is 216.384664133259
At time: 242.3191840648651 and batch: 1050, loss is 5.348358736038208 and perplexity is 210.26291756498333
At time: 243.393079996109 and batch: 1100, loss is 5.352881965637207 and perplexity is 211.21613921225864
At time: 244.46800875663757 and batch: 1150, loss is 5.362670469284057 and perplexity is 213.29378107464086
At time: 245.5404908657074 and batch: 1200, loss is 5.346632461547852 and perplexity is 209.90025916815347
At time: 246.61282587051392 and batch: 1250, loss is 5.35764446258545 and perplexity is 212.22445457426284
At time: 247.6881980895996 and batch: 1300, loss is 5.331486625671387 and perplexity is 206.745098381053
At time: 248.7661623954773 and batch: 1350, loss is 5.30787148475647 and perplexity is 201.9199808991002
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2993391927083335 and perplexity of 200.20446968050257
Finished 8 epochs...
Completing Train Step...
At time: 251.99818301200867 and batch: 50, loss is 5.3938157272338865 and perplexity is 220.0414036895047
At time: 253.07664275169373 and batch: 100, loss is 5.4110636711120605 and perplexity is 223.8695846929404
At time: 254.15060782432556 and batch: 150, loss is 5.378855638504028 and perplexity is 216.7740655371894
At time: 255.22725319862366 and batch: 200, loss is 5.354392375946045 and perplexity is 211.5354032955033
At time: 256.30843114852905 and batch: 250, loss is 5.368373804092407 and perplexity is 214.51374253807805
At time: 257.38494539260864 and batch: 300, loss is 5.382063531875611 and perplexity is 217.47057018419108
At time: 258.460422039032 and batch: 350, loss is 5.37920202255249 and perplexity is 216.84916562159646
At time: 259.5385766029358 and batch: 400, loss is 5.421785583496094 and perplexity is 226.28280883585637
At time: 260.6134874820709 and batch: 450, loss is 5.394714584350586 and perplexity is 220.23927838839762
At time: 261.68890047073364 and batch: 500, loss is 5.407562303543091 and perplexity is 223.08710566217349
At time: 262.76644372940063 and batch: 550, loss is 5.377526168823242 and perplexity is 216.48606247756507
At time: 263.84112548828125 and batch: 600, loss is 5.351019554138183 and perplexity is 210.82313392818793
At time: 264.91604495048523 and batch: 650, loss is 5.372790842056275 and perplexity is 215.463353572709
At time: 265.99193501472473 and batch: 700, loss is 5.397542839050293 and perplexity is 220.86305284327753
At time: 267.0652015209198 and batch: 750, loss is 5.37245397567749 and perplexity is 215.39078343693586
At time: 268.16357922554016 and batch: 800, loss is 5.366409082412719 and perplexity is 214.09269649211095
At time: 269.2383120059967 and batch: 850, loss is 5.343356275558472 and perplexity is 209.21371212188814
At time: 270.31238198280334 and batch: 900, loss is 5.371833791732788 and perplexity is 215.25724294532625
At time: 271.39312386512756 and batch: 950, loss is 5.3432516098022464 and perplexity is 209.19181575641593
At time: 272.4651131629944 and batch: 1000, loss is 5.355518369674683 and perplexity is 211.77372498218134
At time: 273.53939986228943 and batch: 1050, loss is 5.326940536499023 and perplexity is 205.8073498870323
At time: 274.61659049987793 and batch: 1100, loss is 5.331176328659057 and perplexity is 206.68095594682916
At time: 275.6899402141571 and batch: 1150, loss is 5.338238859176636 and perplexity is 208.14581321635347
At time: 276.76264357566833 and batch: 1200, loss is 5.3208348846435545 and perplexity is 204.554590208352
At time: 277.8365728855133 and batch: 1250, loss is 5.3324262809753415 and perplexity is 206.9394588109169
At time: 278.9098048210144 and batch: 1300, loss is 5.313060007095337 and perplexity is 202.97036985750796
At time: 279.9828610420227 and batch: 1350, loss is 5.29012279510498 and perplexity is 198.367782506562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.306665852864583 and perplexity of 201.67668642177955
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 283.15866112709045 and batch: 50, loss is 5.354068231582642 and perplexity is 211.466846398631
At time: 284.2572524547577 and batch: 100, loss is 5.361900930404663 and perplexity is 213.12970635640522
At time: 285.3329679965973 and batch: 150, loss is 5.32801477432251 and perplexity is 206.02855471865857
At time: 286.4069766998291 and batch: 200, loss is 5.305425043106079 and perplexity is 201.42659920861834
At time: 287.481486082077 and batch: 250, loss is 5.3099110889434815 and perplexity is 202.3322380153382
At time: 288.55662083625793 and batch: 300, loss is 5.32720913887024 and perplexity is 205.86263765410595
At time: 289.6386659145355 and batch: 350, loss is 5.321583061218262 and perplexity is 204.7076904268516
At time: 290.71260023117065 and batch: 400, loss is 5.354501314163208 and perplexity is 211.55844884045277
At time: 291.7941632270813 and batch: 450, loss is 5.318022079467774 and perplexity is 203.98002644507073
At time: 292.87174916267395 and batch: 500, loss is 5.339801034927368 and perplexity is 208.47122766948203
At time: 293.94358110427856 and batch: 550, loss is 5.313601160049439 and perplexity is 203.0802375976964
At time: 295.04462599754333 and batch: 600, loss is 5.277724075317383 and perplexity is 195.92346050154708
At time: 296.11807441711426 and batch: 650, loss is 5.289404859542847 and perplexity is 198.225418331386
At time: 297.1922912597656 and batch: 700, loss is 5.31134635925293 and perplexity is 202.62284797123849
At time: 298.2665870189667 and batch: 750, loss is 5.28711669921875 and perplexity is 197.77236532056455
At time: 299.3419804573059 and batch: 800, loss is 5.278229846954345 and perplexity is 196.022578094205
At time: 300.41549491882324 and batch: 850, loss is 5.2456709575653075 and perplexity is 189.74308208580547
At time: 301.4913115501404 and batch: 900, loss is 5.275698957443237 and perplexity is 195.52709387974784
At time: 302.5655210018158 and batch: 950, loss is 5.245691280364991 and perplexity is 189.74693823563769
At time: 303.6399312019348 and batch: 1000, loss is 5.2568932056427 and perplexity is 191.88441885709636
At time: 304.7159643173218 and batch: 1050, loss is 5.226566066741944 and perplexity is 186.15246956106304
At time: 305.7900357246399 and batch: 1100, loss is 5.2286197948455815 and perplexity is 186.53516896511044
At time: 306.86600947380066 and batch: 1150, loss is 5.232274837493897 and perplexity is 187.21821047559936
At time: 307.9397130012512 and batch: 1200, loss is 5.205975580215454 and perplexity is 182.35869154802626
At time: 309.01337242126465 and batch: 1250, loss is 5.222179393768311 and perplexity is 185.3376679944651
At time: 310.0888421535492 and batch: 1300, loss is 5.203179636001587 and perplexity is 181.8495389323824
At time: 311.1617202758789 and batch: 1350, loss is 5.189692459106445 and perplexity is 179.4133674990224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.245841471354167 and perplexity of 189.77543865618404
Finished 10 epochs...
Completing Train Step...
At time: 314.3268229961395 and batch: 50, loss is 5.302912282943725 and perplexity is 200.92109784231255
At time: 315.42827224731445 and batch: 100, loss is 5.319417314529419 and perplexity is 204.26482516422047
At time: 316.5045897960663 and batch: 150, loss is 5.288685064315796 and perplexity is 198.08278795987943
At time: 317.5944242477417 and batch: 200, loss is 5.267061452865601 and perplexity is 193.8455005511474
At time: 318.66809463500977 and batch: 250, loss is 5.276034154891968 and perplexity is 195.5926450484526
At time: 319.74186277389526 and batch: 300, loss is 5.296740341186523 and perplexity is 199.68484349791206
At time: 320.8162112236023 and batch: 350, loss is 5.292065553665161 and perplexity is 198.75353780746713
At time: 321.89110493659973 and batch: 400, loss is 5.32635235786438 and perplexity is 205.68633399394636
At time: 322.9974112510681 and batch: 450, loss is 5.291694774627685 and perplexity is 198.6798578223651
At time: 324.0730571746826 and batch: 500, loss is 5.318544788360596 and perplexity is 204.08667648988677
At time: 325.15454506874084 and batch: 550, loss is 5.294246492385864 and perplexity is 199.18748012274347
At time: 326.22845673561096 and batch: 600, loss is 5.2570911884307865 and perplexity is 191.92241243024472
At time: 327.303138256073 and batch: 650, loss is 5.269107055664063 and perplexity is 194.2424372985899
At time: 328.37683272361755 and batch: 700, loss is 5.293682451248169 and perplexity is 199.0751618688761
At time: 329.45093750953674 and batch: 750, loss is 5.271620759963989 and perplexity is 194.73131954373105
At time: 330.52599024772644 and batch: 800, loss is 5.261217107772827 and perplexity is 192.71590464064272
At time: 331.59927916526794 and batch: 850, loss is 5.229656753540039 and perplexity is 186.72869855414427
At time: 332.6728985309601 and batch: 900, loss is 5.263842515945434 and perplexity is 193.22252730631837
At time: 333.7489974498749 and batch: 950, loss is 5.238361597061157 and perplexity is 188.3612378468053
At time: 334.82229471206665 and batch: 1000, loss is 5.2471252536773685 and perplexity is 190.0192254608219
At time: 335.8966064453125 and batch: 1050, loss is 5.2186032485961915 and perplexity is 184.67605730089983
At time: 336.9716124534607 and batch: 1100, loss is 5.22220440864563 and perplexity is 185.34230425148
At time: 338.0464699268341 and batch: 1150, loss is 5.227227754592896 and perplexity is 186.2756851492296
At time: 339.11938071250916 and batch: 1200, loss is 5.202782096862793 and perplexity is 181.7772609908924
At time: 340.1943054199219 and batch: 1250, loss is 5.220378532409668 and perplexity is 185.0042009039939
At time: 341.26759147644043 and batch: 1300, loss is 5.201806688308716 and perplexity is 181.6000403409051
At time: 342.3410370349884 and batch: 1350, loss is 5.185801334381104 and perplexity is 178.71660418430326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.245746663411459 and perplexity of 189.7574472901442
Finished 11 epochs...
Completing Train Step...
At time: 345.54005432128906 and batch: 50, loss is 5.284223279953003 and perplexity is 197.20095401340473
At time: 346.61471796035767 and batch: 100, loss is 5.301719493865967 and perplexity is 200.68158422432603
At time: 347.6881458759308 and batch: 150, loss is 5.272858448028565 and perplexity is 194.97248538698605
At time: 348.7619743347168 and batch: 200, loss is 5.251018476486206 and perplexity is 190.76045459233904
At time: 349.8622975349426 and batch: 250, loss is 5.26150372505188 and perplexity is 192.77114826537152
At time: 350.9395008087158 and batch: 300, loss is 5.281881504058838 and perplexity is 196.73969386772734
At time: 352.01651978492737 and batch: 350, loss is 5.278031682968139 and perplexity is 195.98373732729115
At time: 353.0901668071747 and batch: 400, loss is 5.3121448802948 and perplexity is 202.78471119590168
At time: 354.16348671913147 and batch: 450, loss is 5.277660388946533 and perplexity is 195.9109832447032
At time: 355.23778200149536 and batch: 500, loss is 5.307524347305298 and perplexity is 201.84989907630666
At time: 356.31008791923523 and batch: 550, loss is 5.28376127243042 and perplexity is 197.1098667323147
At time: 357.38343262672424 and batch: 600, loss is 5.245346412658692 and perplexity is 189.68151192663012
At time: 358.4589772224426 and batch: 650, loss is 5.256903629302979 and perplexity is 191.88641900551576
At time: 359.5320818424225 and batch: 700, loss is 5.283745059967041 and perplexity is 197.1066711217231
At time: 360.6063075065613 and batch: 750, loss is 5.262609844207764 and perplexity is 192.98449409637237
At time: 361.68098998069763 and batch: 800, loss is 5.2519152641296385 and perplexity is 190.93160294126506
At time: 362.7539789676666 and batch: 850, loss is 5.220164613723755 and perplexity is 184.96462928115386
At time: 363.8294644355774 and batch: 900, loss is 5.2548907852172855 and perplexity is 191.50057001909434
At time: 364.903520822525 and batch: 950, loss is 5.229728145599365 and perplexity is 186.74202997634256
At time: 365.9773452281952 and batch: 1000, loss is 5.238818807601929 and perplexity is 188.44737828087824
At time: 367.0523729324341 and batch: 1050, loss is 5.2108144950866695 and perplexity is 183.2432481535122
At time: 368.12665343284607 and batch: 1100, loss is 5.215039920806885 and perplexity is 184.01916702664553
At time: 369.19985699653625 and batch: 1150, loss is 5.22032060623169 and perplexity is 184.99348462810514
At time: 370.27293825149536 and batch: 1200, loss is 5.196724042892456 and perplexity is 180.6793734220081
At time: 371.34842824935913 and batch: 1250, loss is 5.214516525268555 and perplexity is 183.92287741663083
At time: 372.42240262031555 and batch: 1300, loss is 5.1961901569366455 and perplexity is 180.58293698735307
At time: 373.4955370426178 and batch: 1350, loss is 5.179102907180786 and perplexity is 177.52348449553824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.244700113932292 and perplexity of 189.55896061369492
Finished 12 epochs...
Completing Train Step...
At time: 376.6833782196045 and batch: 50, loss is 5.270393810272217 and perplexity is 194.49254052611442
At time: 377.75783467292786 and batch: 100, loss is 5.2887019920349125 and perplexity is 198.086141078056
At time: 378.8313307762146 and batch: 150, loss is 5.259193019866943 and perplexity is 192.3262252145357
At time: 379.90428495407104 and batch: 200, loss is 5.237881622314453 and perplexity is 188.2708509028414
At time: 380.9801199436188 and batch: 250, loss is 5.249329423904419 and perplexity is 190.438522110988
At time: 382.05320048332214 and batch: 300, loss is 5.270344581604004 and perplexity is 194.48296615303573
At time: 383.1270046234131 and batch: 350, loss is 5.2673579025268555 and perplexity is 193.90297450276736
At time: 384.20238733291626 and batch: 400, loss is 5.301144313812256 and perplexity is 200.5661893695238
At time: 385.27587366104126 and batch: 450, loss is 5.266635313034057 and perplexity is 193.76291286039915
At time: 386.34966111183167 and batch: 500, loss is 5.297623958587646 and perplexity is 199.86136647827047
At time: 387.4232177734375 and batch: 550, loss is 5.273392305374146 and perplexity is 195.07660066937746
At time: 388.4970223903656 and batch: 600, loss is 5.2352049350738525 and perplexity is 187.76758256490075
At time: 389.57009077072144 and batch: 650, loss is 5.246614685058594 and perplexity is 189.9222323702589
At time: 390.643132686615 and batch: 700, loss is 5.2750430679321285 and perplexity is 195.39889175754416
At time: 391.71745014190674 and batch: 750, loss is 5.254359130859375 and perplexity is 191.39878496613233
At time: 392.79127860069275 and batch: 800, loss is 5.242336521148681 and perplexity is 189.1114494976796
At time: 393.8658926486969 and batch: 850, loss is 5.211430721282959 and perplexity is 183.3562022423774
At time: 394.9404971599579 and batch: 900, loss is 5.246573028564453 and perplexity is 189.91432104067917
At time: 396.0135495662689 and batch: 950, loss is 5.222870121002197 and perplexity is 185.46572999207692
At time: 397.0865890979767 and batch: 1000, loss is 5.231213455200195 and perplexity is 187.0196057983306
At time: 398.16161155700684 and batch: 1050, loss is 5.202357273101807 and perplexity is 181.7000540920402
At time: 399.2356925010681 and batch: 1100, loss is 5.206329584121704 and perplexity is 182.42325866500445
At time: 400.3092143535614 and batch: 1150, loss is 5.212501573562622 and perplexity is 183.55265481660945
At time: 401.38230419158936 and batch: 1200, loss is 5.189461574554444 and perplexity is 179.37194850573113
At time: 402.45670986175537 and batch: 1250, loss is 5.206391363143921 and perplexity is 182.43452894368423
At time: 403.52945137023926 and batch: 1300, loss is 5.188635149002075 and perplexity is 179.22377218089187
At time: 404.6025195121765 and batch: 1350, loss is 5.171482515335083 and perplexity is 176.17582734123548
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.244051920572916 and perplexity of 189.43612956764986
Finished 13 epochs...
Completing Train Step...
At time: 407.77956080436707 and batch: 50, loss is 5.257957086563111 and perplexity is 192.08866965924324
At time: 408.879239320755 and batch: 100, loss is 5.2765421867370605 and perplexity is 195.69203758595248
At time: 409.9522330760956 and batch: 150, loss is 5.247830762863159 and perplexity is 190.15333307137425
At time: 411.02695631980896 and batch: 200, loss is 5.226465139389038 and perplexity is 186.13368263314686
At time: 412.1017367839813 and batch: 250, loss is 5.238734083175659 and perplexity is 188.4314128612115
At time: 413.1750295162201 and batch: 300, loss is 5.259185066223145 and perplexity is 192.32469552633052
At time: 414.2485656738281 and batch: 350, loss is 5.258081254959106 and perplexity is 192.11252248209644
At time: 415.32372665405273 and batch: 400, loss is 5.29024411201477 and perplexity is 198.3918493327646
At time: 416.3966851234436 and batch: 450, loss is 5.256290731430053 and perplexity is 191.76884826057412
At time: 417.46962785720825 and batch: 500, loss is 5.288679819107056 and perplexity is 198.08174897703356
At time: 418.5483832359314 and batch: 550, loss is 5.264255781173706 and perplexity is 193.30239596050484
At time: 419.6212348937988 and batch: 600, loss is 5.225623683929443 and perplexity is 185.97712530692667
At time: 420.69434213638306 and batch: 650, loss is 5.236239051818847 and perplexity is 187.96185659990167
At time: 421.7696397304535 and batch: 700, loss is 5.266763353347779 and perplexity is 193.78772391292296
At time: 422.8423194885254 and batch: 750, loss is 5.2460965728759765 and perplexity is 189.8238568349003
At time: 423.9167914390564 and batch: 800, loss is 5.2333482646942135 and perplexity is 187.4192834944352
At time: 424.9900071620941 and batch: 850, loss is 5.202962465286255 and perplexity is 181.81005082591506
At time: 426.0632872581482 and batch: 900, loss is 5.239513788223267 and perplexity is 188.5783910773295
At time: 427.1369388103485 and batch: 950, loss is 5.215705642700195 and perplexity is 184.14171340130025
At time: 428.2122747898102 and batch: 1000, loss is 5.224032535552978 and perplexity is 185.6814434052066
At time: 429.29309010505676 and batch: 1050, loss is 5.194833555221558 and perplexity is 180.3381239597525
At time: 430.3680384159088 and batch: 1100, loss is 5.199109439849853 and perplexity is 181.11087990214554
At time: 431.46691036224365 and batch: 1150, loss is 5.205641260147095 and perplexity is 182.29773556777357
At time: 432.5397937297821 and batch: 1200, loss is 5.183218288421631 and perplexity is 178.25556667884874
At time: 433.6144337654114 and batch: 1250, loss is 5.200096645355225 and perplexity is 181.28976184195764
At time: 434.6874237060547 and batch: 1300, loss is 5.182205905914307 and perplexity is 178.075195179191
At time: 435.7617938518524 and batch: 1350, loss is 5.16420955657959 and perplexity is 174.89915603171164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.244717610677084 and perplexity of 189.56227730746735
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 438.943660736084 and batch: 50, loss is 5.244504337310791 and perplexity is 189.5218530333276
At time: 440.0429277420044 and batch: 100, loss is 5.263301753997803 and perplexity is 193.11806816243654
At time: 441.11528277397156 and batch: 150, loss is 5.232323684692383 and perplexity is 187.2273557840462
At time: 442.1894359588623 and batch: 200, loss is 5.215269565582275 and perplexity is 184.06143091958026
At time: 443.2615542411804 and batch: 250, loss is 5.220497817993164 and perplexity is 185.02627055431736
At time: 444.3348865509033 and batch: 300, loss is 5.238381977081299 and perplexity is 188.36507669174426
At time: 445.4091217517853 and batch: 350, loss is 5.236543483734131 and perplexity is 188.0190868988294
At time: 446.48190426826477 and batch: 400, loss is 5.265772476196289 and perplexity is 193.59579918767415
At time: 447.556764125824 and batch: 450, loss is 5.23190468788147 and perplexity is 187.14892455142268
At time: 448.6294355392456 and batch: 500, loss is 5.2619287109375 and perplexity is 192.85309069349344
At time: 449.70292139053345 and batch: 550, loss is 5.232615480422973 and perplexity is 187.28199589860213
At time: 450.7768039703369 and batch: 600, loss is 5.198040618896484 and perplexity is 180.91740821054006
At time: 451.8497016429901 and batch: 650, loss is 5.202780256271362 and perplexity is 181.77692641353133
At time: 452.9278004169464 and batch: 700, loss is 5.230049467086792 and perplexity is 186.80204384453594
At time: 454.0014774799347 and batch: 750, loss is 5.2075266265869145 and perplexity is 182.6417578025508
At time: 455.0741763114929 and batch: 800, loss is 5.194144763946533 and perplexity is 180.21395140281095
At time: 456.1494493484497 and batch: 850, loss is 5.158556184768677 and perplexity is 173.9131757558414
At time: 457.22157740592957 and batch: 900, loss is 5.191999225616455 and perplexity is 179.82770995853966
At time: 458.3190734386444 and batch: 950, loss is 5.169722261428833 and perplexity is 175.86598593274954
At time: 459.3932592868805 and batch: 1000, loss is 5.173685064315796 and perplexity is 176.5642908781122
At time: 460.4658818244934 and batch: 1050, loss is 5.144023666381836 and perplexity is 171.40405540936774
At time: 461.53976678848267 and batch: 1100, loss is 5.1487603282928465 and perplexity is 172.21786431729805
At time: 462.6147859096527 and batch: 1150, loss is 5.152150821685791 and perplexity is 172.80275882859917
At time: 463.6875522136688 and batch: 1200, loss is 5.128319864273071 and perplexity is 168.7333847683497
At time: 464.76000118255615 and batch: 1250, loss is 5.145710477828979 and perplexity is 171.69342572008247
At time: 465.83456444740295 and batch: 1300, loss is 5.12745228767395 and perplexity is 168.58705911576837
At time: 466.90684032440186 and batch: 1350, loss is 5.116887140274048 and perplexity is 166.81528797884374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.196524658203125 and perplexity of 180.643352312418
Finished 15 epochs...
Completing Train Step...
At time: 470.1014983654022 and batch: 50, loss is 5.221417179107666 and perplexity is 185.19645473099658
At time: 471.1754927635193 and batch: 100, loss is 5.2422815036773684 and perplexity is 189.10104535013946
At time: 472.25533294677734 and batch: 150, loss is 5.210331439971924 and perplexity is 183.15475294100236
At time: 473.3285753726959 and batch: 200, loss is 5.1951773071289065 and perplexity is 180.40012618991327
At time: 474.40357995033264 and batch: 250, loss is 5.202818984985352 and perplexity is 181.78396653645086
At time: 475.4768192768097 and batch: 300, loss is 5.222936582565308 and perplexity is 185.47805674401874
At time: 476.5580053329468 and batch: 350, loss is 5.221369323730468 and perplexity is 185.18759229685898
At time: 477.6322855949402 and batch: 400, loss is 5.251415700912475 and perplexity is 190.83624435624552
At time: 478.7146940231323 and batch: 450, loss is 5.219039850234985 and perplexity is 184.75670477429176
At time: 479.79128527641296 and batch: 500, loss is 5.249350872039795 and perplexity is 190.4426067059944
At time: 480.86775159835815 and batch: 550, loss is 5.22249433517456 and perplexity is 185.39604769286385
At time: 481.9461362361908 and batch: 600, loss is 5.188756713867187 and perplexity is 179.24556081892152
At time: 483.0236668586731 and batch: 650, loss is 5.193965349197388 and perplexity is 180.18162126226628
At time: 484.09997487068176 and batch: 700, loss is 5.222044849395752 and perplexity is 185.31273353164673
At time: 485.2198965549469 and batch: 750, loss is 5.2001054573059085 and perplexity is 181.2913593654371
At time: 486.29595828056335 and batch: 800, loss is 5.187875089645385 and perplexity is 179.08760323070217
At time: 487.3786368370056 and batch: 850, loss is 5.153586769104004 and perplexity is 173.05107274419473
At time: 488.45521116256714 and batch: 900, loss is 5.188441905975342 and perplexity is 179.1891417828423
At time: 489.5322699546814 and batch: 950, loss is 5.166293630599975 and perplexity is 175.26403890837827
At time: 490.60699462890625 and batch: 1000, loss is 5.172929849624634 and perplexity is 176.430997270687
At time: 491.68533205986023 and batch: 1050, loss is 5.145793170928955 and perplexity is 171.70762416874948
At time: 492.76078963279724 and batch: 1100, loss is 5.151463584899902 and perplexity is 172.68404321357033
At time: 493.8352620601654 and batch: 1150, loss is 5.155391073226928 and perplexity is 173.36359136275547
At time: 494.9082598686218 and batch: 1200, loss is 5.132549123764038 and perplexity is 169.44851320324798
At time: 495.98212361335754 and batch: 1250, loss is 5.149127521514893 and perplexity is 172.2811131613534
At time: 497.05707144737244 and batch: 1300, loss is 5.129242076873779 and perplexity is 168.88906459585894
At time: 498.1304099559784 and batch: 1350, loss is 5.115371742248535 and perplexity is 166.56268786401282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.195806477864584 and perplexity of 180.5136643837335
Finished 16 epochs...
Completing Train Step...
At time: 501.31845211982727 and batch: 50, loss is 5.213856019973755 and perplexity is 183.80143549319416
At time: 502.39134335517883 and batch: 100, loss is 5.234043998718262 and perplexity is 187.5497228370078
At time: 503.46711349487305 and batch: 150, loss is 5.202300806045532 and perplexity is 181.689794314533
At time: 504.54391384124756 and batch: 200, loss is 5.187187089920044 and perplexity is 178.9644333841361
At time: 505.61952900886536 and batch: 250, loss is 5.195703344345093 and perplexity is 180.49504833419527
At time: 506.69354486465454 and batch: 300, loss is 5.216340856552124 and perplexity is 184.25871992651918
At time: 507.7679748535156 and batch: 350, loss is 5.215359334945679 and perplexity is 184.07795473871627
At time: 508.84156012535095 and batch: 400, loss is 5.245068044662475 and perplexity is 189.62871801264475
At time: 509.9149396419525 and batch: 450, loss is 5.213315830230713 and perplexity is 183.7021746552414
At time: 510.99043321609497 and batch: 500, loss is 5.243435287475586 and perplexity is 189.3193529881805
At time: 512.0646934509277 and batch: 550, loss is 5.218432178497315 and perplexity is 184.64446745163355
At time: 513.1694588661194 and batch: 600, loss is 5.184717893600464 and perplexity is 178.52308018198116
At time: 514.2467863559723 and batch: 650, loss is 5.1901091194152835 and perplexity is 179.4881375038992
At time: 515.3208255767822 and batch: 700, loss is 5.21808424949646 and perplexity is 184.58023546129382
At time: 516.3997130393982 and batch: 750, loss is 5.1960827732086186 and perplexity is 180.5635463594989
At time: 517.4796862602234 and batch: 800, loss is 5.184813489913941 and perplexity is 178.54014714607348
At time: 518.5544016361237 and batch: 850, loss is 5.150519752502442 and perplexity is 172.52113531003292
At time: 519.6280317306519 and batch: 900, loss is 5.186094093322754 and perplexity is 178.76893272765025
At time: 520.7029716968536 and batch: 950, loss is 5.163798494338989 and perplexity is 174.82727636727415
At time: 521.776932477951 and batch: 1000, loss is 5.172039184570313 and perplexity is 176.27392630611206
At time: 522.8508083820343 and batch: 1050, loss is 5.145636053085327 and perplexity is 171.68064795638324
At time: 523.9256196022034 and batch: 1100, loss is 5.151188755035401 and perplexity is 172.63659100231342
At time: 525.0007700920105 and batch: 1150, loss is 5.155784254074097 and perplexity is 173.43176800847297
At time: 526.0752327442169 and batch: 1200, loss is 5.133086318969727 and perplexity is 169.5395645861454
At time: 527.1486067771912 and batch: 1250, loss is 5.1490084743499756 and perplexity is 172.2606048040179
At time: 528.2317764759064 and batch: 1300, loss is 5.128112630844116 and perplexity is 168.69842119338088
At time: 529.3057601451874 and batch: 1350, loss is 5.112646713256836 and perplexity is 166.1094175784731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.195635579427083 and perplexity of 180.48281751645865
Finished 17 epochs...
Completing Train Step...
At time: 532.4926943778992 and batch: 50, loss is 5.208072509765625 and perplexity is 182.74148608338433
At time: 533.6026599407196 and batch: 100, loss is 5.227894887924195 and perplexity is 186.39999732939202
At time: 534.6782832145691 and batch: 150, loss is 5.196558265686035 and perplexity is 180.64942338280983
At time: 535.7549450397491 and batch: 200, loss is 5.181855154037476 and perplexity is 178.012745923002
At time: 536.8311641216278 and batch: 250, loss is 5.190610637664795 and perplexity is 179.57817665668017
At time: 537.9062743186951 and batch: 300, loss is 5.211339673995972 and perplexity is 183.33950891756348
At time: 538.9835329055786 and batch: 350, loss is 5.210847854614258 and perplexity is 183.24936116366734
At time: 540.1048970222473 and batch: 400, loss is 5.240336198806762 and perplexity is 188.73354373281813
At time: 541.1808440685272 and batch: 450, loss is 5.209098606109619 and perplexity is 182.92909268891614
At time: 542.2574355602264 and batch: 500, loss is 5.239351387023926 and perplexity is 188.54776820711152
At time: 543.3343987464905 and batch: 550, loss is 5.215272846221924 and perplexity is 184.06203475979885
At time: 544.4164733886719 and batch: 600, loss is 5.181311674118042 and perplexity is 177.9160258552776
At time: 545.4935920238495 and batch: 650, loss is 5.186559953689575 and perplexity is 178.85223348998235
At time: 546.5700514316559 and batch: 700, loss is 5.214554920196533 and perplexity is 183.92993925783136
At time: 547.6507396697998 and batch: 750, loss is 5.192488021850586 and perplexity is 179.9156305518367
At time: 548.7360553741455 and batch: 800, loss is 5.181710615158081 and perplexity is 177.9870180195742
At time: 549.8113949298859 and batch: 850, loss is 5.147675056457519 and perplexity is 172.03106250332286
At time: 550.8873906135559 and batch: 900, loss is 5.183491039276123 and perplexity is 178.30419266806697
At time: 551.9649901390076 and batch: 950, loss is 5.1609604549407955 and perplexity is 174.33181307379627
At time: 553.0395522117615 and batch: 1000, loss is 5.170368013381958 and perplexity is 175.9795884122176
At time: 554.1156895160675 and batch: 1050, loss is 5.1445888233184816 and perplexity is 171.50095297883922
At time: 555.191388130188 and batch: 1100, loss is 5.150175628662109 and perplexity is 172.46177688832125
At time: 556.2663061618805 and batch: 1150, loss is 5.15508469581604 and perplexity is 173.31048481023086
At time: 557.3438060283661 and batch: 1200, loss is 5.132410020828247 and perplexity is 169.42494405690266
At time: 558.4198095798492 and batch: 1250, loss is 5.1475848293304445 and perplexity is 172.01554133501133
At time: 559.496090888977 and batch: 1300, loss is 5.126275177001953 and perplexity is 168.38873023974108
At time: 560.5713632106781 and batch: 1350, loss is 5.110057516098022 and perplexity is 165.67988386013243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.19592041015625 and perplexity of 180.53423189082326
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 563.7739715576172 and batch: 50, loss is 5.205443344116211 and perplexity is 182.2616594936453
At time: 564.8976907730103 and batch: 100, loss is 5.224860963821411 and perplexity is 185.83533089541936
At time: 565.9764075279236 and batch: 150, loss is 5.194431428909302 and perplexity is 180.2656198338908
At time: 567.0937733650208 and batch: 200, loss is 5.178876905441284 and perplexity is 177.4833684125629
At time: 568.1707396507263 and batch: 250, loss is 5.187143697738647 and perplexity is 178.95666789546115
At time: 569.2489154338837 and batch: 300, loss is 5.2066765308380125 and perplexity is 182.48656079617484
At time: 570.3217051029205 and batch: 350, loss is 5.20524567604065 and perplexity is 182.22563574265467
At time: 571.3945333957672 and batch: 400, loss is 5.233256025314331 and perplexity is 187.40199685321446
At time: 572.4674360752106 and batch: 450, loss is 5.200947971343994 and perplexity is 181.444164241774
At time: 573.5477151870728 and batch: 500, loss is 5.229016599655151 and perplexity is 186.60920170461182
At time: 574.6264643669128 and batch: 550, loss is 5.205120353698731 and perplexity is 182.20280023015556
At time: 575.7007222175598 and batch: 600, loss is 5.17072003364563 and perplexity is 176.0415476981536
At time: 576.7749788761139 and batch: 650, loss is 5.174975481033325 and perplexity is 176.79227945928147
At time: 577.8485305309296 and batch: 700, loss is 5.199727792739868 and perplexity is 181.22290497008882
At time: 578.9248859882355 and batch: 750, loss is 5.1764822101593015 and perplexity is 177.05885831662192
At time: 580.0016357898712 and batch: 800, loss is 5.166443996429443 and perplexity is 175.29039461241356
At time: 581.0773169994354 and batch: 850, loss is 5.124514770507813 and perplexity is 168.09255839339494
At time: 582.157870054245 and batch: 900, loss is 5.160365896224976 and perplexity is 174.2281933819365
At time: 583.237286567688 and batch: 950, loss is 5.137384834289551 and perplexity is 170.26990155961963
At time: 584.3123438358307 and batch: 1000, loss is 5.148603401184082 and perplexity is 172.19084078619093
At time: 585.3863468170166 and batch: 1050, loss is 5.120630331039429 and perplexity is 167.44087954816817
At time: 586.4599497318268 and batch: 1100, loss is 5.123774137496948 and perplexity is 167.96810958690398
At time: 587.5342853069305 and batch: 1150, loss is 5.126494178771972 and perplexity is 168.4256117081209
At time: 588.6077342033386 and batch: 1200, loss is 5.104167461395264 and perplexity is 164.70688859171585
At time: 589.6812477111816 and batch: 1250, loss is 5.116454591751099 and perplexity is 166.74314787559553
At time: 590.7547628879547 and batch: 1300, loss is 5.100867729187012 and perplexity is 164.1642956645109
At time: 591.8331933021545 and batch: 1350, loss is 5.087623119354248 and perplexity is 162.004339085851
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1824951171875 and perplexity of 178.126703981217
Finished 19 epochs...
Completing Train Step...
At time: 595.0754687786102 and batch: 50, loss is 5.196664304733276 and perplexity is 180.66858029122213
At time: 596.1508295536041 and batch: 100, loss is 5.214640531539917 and perplexity is 183.94568642107808
At time: 597.2284171581268 and batch: 150, loss is 5.183796949386597 and perplexity is 178.3587460671368
At time: 598.301362991333 and batch: 200, loss is 5.169009199142456 and perplexity is 175.7406272303175
At time: 599.3755209445953 and batch: 250, loss is 5.177923421859742 and perplexity is 177.3142215869599
At time: 600.448323726654 and batch: 300, loss is 5.197727241516113 and perplexity is 180.86072166969532
At time: 601.5216000080109 and batch: 350, loss is 5.196585302352905 and perplexity is 180.6543076071163
At time: 602.596800327301 and batch: 400, loss is 5.225354719161987 and perplexity is 185.9271107390461
At time: 603.6709311008453 and batch: 450, loss is 5.193496809005738 and perplexity is 180.09721870544735
At time: 604.7452955245972 and batch: 500, loss is 5.222852258682251 and perplexity is 185.46241717345623
At time: 605.8180379867554 and batch: 550, loss is 5.20019024848938 and perplexity is 181.3067319260705
At time: 606.891250371933 and batch: 600, loss is 5.165995397567749 and perplexity is 175.21177717608919
At time: 607.9665689468384 and batch: 650, loss is 5.170805959701538 and perplexity is 176.05667490392463
At time: 609.0407638549805 and batch: 700, loss is 5.196468162536621 and perplexity is 180.63314703410927
At time: 610.1154642105103 and batch: 750, loss is 5.173931894302368 and perplexity is 176.6078776186947
At time: 611.1887311935425 and batch: 800, loss is 5.164324054718017 and perplexity is 174.9191828059821
At time: 612.261527299881 and batch: 850, loss is 5.12329023361206 and perplexity is 167.88684882892153
At time: 613.3361389636993 and batch: 900, loss is 5.16062068939209 and perplexity is 174.27259119101785
At time: 614.4091463088989 and batch: 950, loss is 5.138030767440796 and perplexity is 170.37992006216993
At time: 615.4838767051697 and batch: 1000, loss is 5.149479694366455 and perplexity is 172.34179657714444
At time: 616.557302236557 and batch: 1050, loss is 5.122166633605957 and perplexity is 167.6983171015125
At time: 617.6304926872253 and batch: 1100, loss is 5.125751008987427 and perplexity is 168.3004893818807
At time: 618.704763174057 and batch: 1150, loss is 5.128998022079468 and perplexity is 168.84785143927647
At time: 619.7808752059937 and batch: 1200, loss is 5.1075229072570805 and perplexity is 165.2604818962254
At time: 620.8560466766357 and batch: 1250, loss is 5.120006427764893 and perplexity is 167.3364452169751
At time: 621.9304294586182 and batch: 1300, loss is 5.104154500961304 and perplexity is 164.70475393279662
At time: 623.0035877227783 and batch: 1350, loss is 5.088768005371094 and perplexity is 162.18992180359672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1817236328125 and perplexity of 177.98933500814675
Finished 20 epochs...
Completing Train Step...
At time: 626.2058410644531 and batch: 50, loss is 5.192749185562134 and perplexity is 179.96262412191751
At time: 627.2845125198364 and batch: 100, loss is 5.21047212600708 and perplexity is 183.18052206964936
At time: 628.3617420196533 and batch: 150, loss is 5.179203643798828 and perplexity is 177.54136851176187
At time: 629.4347381591797 and batch: 200, loss is 5.164529685974121 and perplexity is 174.95515535567264
At time: 630.5100483894348 and batch: 250, loss is 5.173607234954834 and perplexity is 176.55054952693163
At time: 631.5834579467773 and batch: 300, loss is 5.193620872497559 and perplexity is 180.11956358133023
At time: 632.6563079357147 and batch: 350, loss is 5.192721757888794 and perplexity is 179.95768823354004
At time: 633.7307605743408 and batch: 400, loss is 5.22185938835144 and perplexity is 185.27836842535436
At time: 634.8040065765381 and batch: 450, loss is 5.190273694992065 and perplexity is 179.51767929851664
At time: 635.876590013504 and batch: 500, loss is 5.219961414337158 and perplexity is 184.9270484002771
At time: 636.9510960578918 and batch: 550, loss is 5.197821388244629 and perplexity is 180.87774991652174
At time: 638.0264618396759 and batch: 600, loss is 5.163716516494751 and perplexity is 174.81294499147918
At time: 639.0987377166748 and batch: 650, loss is 5.168835458755493 and perplexity is 175.71009663801254
At time: 640.1743273735046 and batch: 700, loss is 5.1949679565429685 and perplexity is 180.36236327077467
At time: 641.2524859905243 and batch: 750, loss is 5.172769088745117 and perplexity is 176.4026363481162
At time: 642.3253796100616 and batch: 800, loss is 5.163242425918579 and perplexity is 174.73008746420422
At time: 643.4000260829926 and batch: 850, loss is 5.122431049346924 and perplexity is 167.74266503917573
At time: 644.472770690918 and batch: 900, loss is 5.16049563407898 and perplexity is 174.25079884021295
At time: 645.5473277568817 and batch: 950, loss is 5.138274374008179 and perplexity is 170.42143078558442
At time: 646.6199290752411 and batch: 1000, loss is 5.14975866317749 and perplexity is 172.3898812699801
At time: 647.6925826072693 and batch: 1050, loss is 5.122608375549317 and perplexity is 167.7724128464013
At time: 648.8081040382385 and batch: 1100, loss is 5.126267127990722 and perplexity is 168.38737488241486
At time: 649.8818550109863 and batch: 1150, loss is 5.129848527908325 and perplexity is 168.99151860733718
At time: 650.9595403671265 and batch: 1200, loss is 5.108600645065308 and perplexity is 165.43868537683628
At time: 652.0375909805298 and batch: 1250, loss is 5.121140003204346 and perplexity is 167.52624125513822
At time: 653.1109399795532 and batch: 1300, loss is 5.10532844543457 and perplexity is 164.8982217063896
At time: 654.1844475269318 and batch: 1350, loss is 5.088496341705322 and perplexity is 162.14586667924755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.18142333984375 and perplexity of 177.93589408669942
Finished 21 epochs...
Completing Train Step...
At time: 657.3463251590729 and batch: 50, loss is 5.18984167098999 and perplexity is 179.4401401028657
At time: 658.4469764232635 and batch: 100, loss is 5.207377319335937 and perplexity is 182.61449009946327
At time: 659.5236003398895 and batch: 150, loss is 5.175903148651123 and perplexity is 176.95636002636013
At time: 660.5961267948151 and batch: 200, loss is 5.161446504592895 and perplexity is 174.4165675866729
At time: 661.6699204444885 and batch: 250, loss is 5.170542669296265 and perplexity is 176.01032697238867
At time: 662.7421472072601 and batch: 300, loss is 5.190677652359009 and perplexity is 179.59021143652527
At time: 663.8142907619476 and batch: 350, loss is 5.1901480579376225 and perplexity is 179.49512664282346
At time: 664.8887724876404 and batch: 400, loss is 5.219403219223023 and perplexity is 184.82385182997876
At time: 665.9617547988892 and batch: 450, loss is 5.188042821884156 and perplexity is 179.11764451470353
At time: 667.0344703197479 and batch: 500, loss is 5.217910537719726 and perplexity is 184.5481744854071
At time: 668.1084623336792 and batch: 550, loss is 5.196047792434692 and perplexity is 180.55723021737677
At time: 669.1809983253479 and batch: 600, loss is 5.162062168121338 and perplexity is 174.5239825684426
At time: 670.2525599002838 and batch: 650, loss is 5.167443819046021 and perplexity is 175.46574155672917
At time: 671.3278338909149 and batch: 700, loss is 5.193917627334595 and perplexity is 180.17302286482598
At time: 672.4002251625061 and batch: 750, loss is 5.171628093719482 and perplexity is 176.2014766004935
At time: 673.4742317199707 and batch: 800, loss is 5.162338018417358 and perplexity is 174.57213170136774
At time: 674.5466499328613 and batch: 850, loss is 5.121651439666748 and perplexity is 167.6119421967505
At time: 675.6456444263458 and batch: 900, loss is 5.160115890502929 and perplexity is 174.18464078107579
At time: 676.7189404964447 and batch: 950, loss is 5.138127069473267 and perplexity is 170.39632878484818
At time: 677.7928066253662 and batch: 1000, loss is 5.14971212387085 and perplexity is 172.3818585511213
At time: 678.8651614189148 and batch: 1050, loss is 5.122503938674927 and perplexity is 167.75489213491494
At time: 679.9390635490417 and batch: 1100, loss is 5.126184167861939 and perplexity is 168.3734060235463
At time: 681.0124504566193 and batch: 1150, loss is 5.12997612953186 and perplexity is 169.01308357530831
At time: 682.0847165584564 and batch: 1200, loss is 5.108917264938355 and perplexity is 165.49107484573315
At time: 683.158590555191 and batch: 1250, loss is 5.121589727401734 and perplexity is 167.60159880331443
At time: 684.2309520244598 and batch: 1300, loss is 5.105826921463013 and perplexity is 164.98044000726665
At time: 685.3036086559296 and batch: 1350, loss is 5.087810888290405 and perplexity is 162.03476132434025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.181603597005208 and perplexity of 177.96797119686647
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 688.4798729419708 and batch: 50, loss is 5.18851152420044 and perplexity is 179.20161704709784
At time: 689.5799336433411 and batch: 100, loss is 5.206793231964111 and perplexity is 182.50785842602215
At time: 690.6528306007385 and batch: 150, loss is 5.174956750869751 and perplexity is 176.78896814197947
At time: 691.725754737854 and batch: 200, loss is 5.160738973617554 and perplexity is 174.29320610867228
At time: 692.7988913059235 and batch: 250, loss is 5.1690600490570064 and perplexity is 175.74956385340647
At time: 693.8743588924408 and batch: 300, loss is 5.1889401626586915 and perplexity is 179.27844621673725
At time: 694.9485409259796 and batch: 350, loss is 5.188090553283692 and perplexity is 179.1261942546017
At time: 696.0337147712708 and batch: 400, loss is 5.216979722976685 and perplexity is 184.37647424674844
At time: 697.1128087043762 and batch: 450, loss is 5.183830051422119 and perplexity is 178.36465020240377
At time: 698.1903731822968 and batch: 500, loss is 5.2127348327636716 and perplexity is 183.59547515614744
At time: 699.263765335083 and batch: 550, loss is 5.1900198268890385 and perplexity is 179.47211127019256
At time: 700.338339805603 and batch: 600, loss is 5.156566801071167 and perplexity is 173.56753963463518
At time: 701.4111115932465 and batch: 650, loss is 5.1624971199035645 and perplexity is 174.59990859658566
At time: 702.484236240387 and batch: 700, loss is 5.187382669448852 and perplexity is 178.9994385867298
At time: 703.5841112136841 and batch: 750, loss is 5.164935970306397 and perplexity is 175.02625133575796
At time: 704.6572499275208 and batch: 800, loss is 5.155218801498413 and perplexity is 173.33372828956524
At time: 705.7304656505585 and batch: 850, loss is 5.111568307876587 and perplexity is 165.9303808432867
At time: 706.8048760890961 and batch: 900, loss is 5.146461172103882 and perplexity is 171.82236338213616
At time: 707.8777775764465 and batch: 950, loss is 5.125952425003052 and perplexity is 168.33439120995072
At time: 708.9522678852081 and batch: 1000, loss is 5.138268375396729 and perplexity is 170.4204084967045
At time: 710.026205778122 and batch: 1050, loss is 5.110172929763794 and perplexity is 165.69900668636993
At time: 711.1021642684937 and batch: 1100, loss is 5.112365484237671 and perplexity is 166.06270935805483
At time: 712.1779761314392 and batch: 1150, loss is 5.116114110946655 and perplexity is 166.68638469840585
At time: 713.2505464553833 and batch: 1200, loss is 5.093892498016357 and perplexity is 163.02319609549468
At time: 714.3234097957611 and batch: 1250, loss is 5.106858711242676 and perplexity is 165.15075298759726
At time: 715.3979678153992 and batch: 1300, loss is 5.094191656112671 and perplexity is 163.07197310014777
At time: 716.471349477768 and batch: 1350, loss is 5.078333301544189 and perplexity is 160.5063172396653
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.176515706380209 and perplexity of 177.0647892185845
Finished 23 epochs...
Completing Train Step...
At time: 719.6569318771362 and batch: 50, loss is 5.1849221420288085 and perplexity is 178.5595469645463
At time: 720.7362258434296 and batch: 100, loss is 5.20263560295105 and perplexity is 181.75063367928095
At time: 721.8134934902191 and batch: 150, loss is 5.170377101898193 and perplexity is 175.98118781283208
At time: 722.8893918991089 and batch: 200, loss is 5.156720237731934 and perplexity is 173.59417330157237
At time: 723.9659435749054 and batch: 250, loss is 5.16538146018982 and perplexity is 175.10424113060392
At time: 725.0424890518188 and batch: 300, loss is 5.185161952972412 and perplexity is 178.60237263282
At time: 726.117508649826 and batch: 350, loss is 5.184544925689697 and perplexity is 178.49220408814213
At time: 727.194057226181 and batch: 400, loss is 5.213459777832031 and perplexity is 183.7286200459695
At time: 728.2706768512726 and batch: 450, loss is 5.180480585098267 and perplexity is 177.76822322682543
At time: 729.348913192749 and batch: 500, loss is 5.209816770553589 and perplexity is 183.06051304411764
At time: 730.4490802288055 and batch: 550, loss is 5.187892303466797 and perplexity is 179.09068603925465
At time: 731.5258996486664 and batch: 600, loss is 5.154349632263184 and perplexity is 173.18313739947317
At time: 732.6032898426056 and batch: 650, loss is 5.160502500534058 and perplexity is 174.25199532960337
At time: 733.6790201663971 and batch: 700, loss is 5.185840120315552 and perplexity is 178.72353600922574
At time: 734.7545387744904 and batch: 750, loss is 5.163807964324951 and perplexity is 174.8289319869664
At time: 735.8318908214569 and batch: 800, loss is 5.15442759513855 and perplexity is 173.19663978116517
At time: 736.9071872234344 and batch: 850, loss is 5.11118143081665 and perplexity is 165.86619860151094
At time: 737.9849586486816 and batch: 900, loss is 5.146443767547607 and perplexity is 171.8193729161674
At time: 739.059668302536 and batch: 950, loss is 5.126233100891113 and perplexity is 168.38164524591883
At time: 740.135381937027 and batch: 1000, loss is 5.139033460617066 and perplexity is 170.55084452346463
At time: 741.2115745544434 and batch: 1050, loss is 5.111365537643433 and perplexity is 165.89673851222278
At time: 742.2879889011383 and batch: 1100, loss is 5.1138705635070805 and perplexity is 166.31283508163557
At time: 743.3639967441559 and batch: 1150, loss is 5.117760543823242 and perplexity is 166.9610486881188
At time: 744.4414343833923 and batch: 1200, loss is 5.095947198867798 and perplexity is 163.3585043564343
At time: 745.5173487663269 and batch: 1250, loss is 5.1089146709442135 and perplexity is 165.49064556341136
At time: 746.5918312072754 and batch: 1300, loss is 5.09600757598877 and perplexity is 163.36836777037294
At time: 747.6651346683502 and batch: 1350, loss is 5.079018144607544 and perplexity is 160.61627652578102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.176078287760417 and perplexity of 176.98735471975124
Finished 24 epochs...
Completing Train Step...
At time: 750.8657655715942 and batch: 50, loss is 5.183238210678101 and perplexity is 178.25911796734007
At time: 751.9402086734772 and batch: 100, loss is 5.200633773803711 and perplexity is 181.38716388682508
At time: 753.013106584549 and batch: 150, loss is 5.16801721572876 and perplexity is 175.56638188152897
At time: 754.0876085758209 and batch: 200, loss is 5.1546250915527345 and perplexity is 173.2308488744462
At time: 755.161214351654 and batch: 250, loss is 5.163464708328247 and perplexity is 174.7689312060676
At time: 756.2341268062592 and batch: 300, loss is 5.183212690353393 and perplexity is 178.25456879481587
At time: 757.334969997406 and batch: 350, loss is 5.182715091705322 and perplexity is 178.16589162702027
At time: 758.4087650775909 and batch: 400, loss is 5.211553230285644 and perplexity is 183.37866640385323
At time: 759.4832899570465 and batch: 450, loss is 5.178655424118042 and perplexity is 177.44406351408452
At time: 760.5569913387299 and batch: 500, loss is 5.208165416717529 and perplexity is 182.7584648265522
At time: 761.6299767494202 and batch: 550, loss is 5.1866085243225095 and perplexity is 178.86092066713383
At time: 762.7039079666138 and batch: 600, loss is 5.153153524398804 and perplexity is 172.97611552178142
At time: 763.7785205841064 and batch: 650, loss is 5.159243841171264 and perplexity is 174.03280939334834
At time: 764.8522176742554 and batch: 700, loss is 5.184982519149781 and perplexity is 178.57032820138087
At time: 765.927102804184 and batch: 750, loss is 5.163197479248047 and perplexity is 174.7222341050234
At time: 767.0002083778381 and batch: 800, loss is 5.154027481079101 and perplexity is 173.1273552323248
At time: 768.0735185146332 and batch: 850, loss is 5.110910997390747 and perplexity is 165.82134890188397
At time: 769.1484713554382 and batch: 900, loss is 5.146295795440674 and perplexity is 171.79395032250872
At time: 770.2216076850891 and batch: 950, loss is 5.126220293045044 and perplexity is 168.37948865353636
At time: 771.2998161315918 and batch: 1000, loss is 5.139369401931763 and perplexity is 170.60814922336573
At time: 772.3758201599121 and batch: 1050, loss is 5.111877737045288 and perplexity is 165.98173248753187
At time: 773.4492673873901 and batch: 1100, loss is 5.114686269760131 and perplexity is 166.44855284656376
At time: 774.5249757766724 and batch: 1150, loss is 5.11861135482788 and perplexity is 167.1031614326594
At time: 775.5980002880096 and batch: 1200, loss is 5.097035684585571 and perplexity is 163.53641456409753
At time: 776.6787650585175 and batch: 1250, loss is 5.1099754905700685 and perplexity is 165.66629443753487
At time: 777.7534816265106 and batch: 1300, loss is 5.096973152160644 and perplexity is 163.52618855526288
At time: 778.8269648551941 and batch: 1350, loss is 5.079131984710694 and perplexity is 160.63456214006655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.175933837890625 and perplexity of 176.96179076580654
Finished 25 epochs...
Completing Train Step...
At time: 781.9899411201477 and batch: 50, loss is 5.181921319961548 and perplexity is 178.02452469050485
At time: 783.1019992828369 and batch: 100, loss is 5.1990750217437744 and perplexity is 181.1046465159403
At time: 784.1753795146942 and batch: 150, loss is 5.166260814666748 and perplexity is 175.25828754974884
At time: 785.2913198471069 and batch: 200, loss is 5.15301194190979 and perplexity is 172.95162686642922
At time: 786.3658609390259 and batch: 250, loss is 5.162023220062256 and perplexity is 174.5171853304288
At time: 787.4389054775238 and batch: 300, loss is 5.181721897125244 and perplexity is 177.98902607459436
At time: 788.5127823352814 and batch: 350, loss is 5.18135175704956 and perplexity is 177.92315739408346
At time: 789.5880727767944 and batch: 400, loss is 5.210151233673096 and perplexity is 183.1217502745956
At time: 790.6624965667725 and batch: 450, loss is 5.177275218963623 and perplexity is 177.19932323774862
At time: 791.7524104118347 and batch: 500, loss is 5.2069034767150875 and perplexity is 182.5279800685579
At time: 792.8277251720428 and batch: 550, loss is 5.185623817443847 and perplexity is 178.6848817758073
At time: 793.901264667511 and batch: 600, loss is 5.152390985488892 and perplexity is 172.84426478025983
At time: 794.9754121303558 and batch: 650, loss is 5.158458271026611 and perplexity is 173.89614809964303
At time: 796.048101902008 and batch: 700, loss is 5.184345312118531 and perplexity is 178.4565781776846
At time: 797.1218404769897 and batch: 750, loss is 5.162738637924194 and perplexity is 174.6420827136117
At time: 798.1960825920105 and batch: 800, loss is 5.153750171661377 and perplexity is 173.07935204242918
At time: 799.269378900528 and batch: 850, loss is 5.110725231170655 and perplexity is 165.79054775768242
At time: 800.3429036140442 and batch: 900, loss is 5.146147270202636 and perplexity is 171.76843647991538
At time: 801.4178490638733 and batch: 950, loss is 5.126254005432129 and perplexity is 168.38516522371978
At time: 802.4911525249481 and batch: 1000, loss is 5.139544582366943 and perplexity is 170.63803905117203
At time: 803.5644130706787 and batch: 1050, loss is 5.112300882339477 and perplexity is 166.05198173832716
At time: 804.6389462947845 and batch: 1100, loss is 5.115203323364258 and perplexity is 166.5346379240967
At time: 805.7122800350189 and batch: 1150, loss is 5.1192225742340085 and perplexity is 167.20532934807795
At time: 806.7854883670807 and batch: 1200, loss is 5.097819766998291 and perplexity is 163.66469087362375
At time: 807.8607337474823 and batch: 1250, loss is 5.110749559402466 and perplexity is 165.79458119762344
At time: 808.9334239959717 and batch: 1300, loss is 5.097564191818237 and perplexity is 163.6228675855101
At time: 810.007566690445 and batch: 1350, loss is 5.07913990020752 and perplexity is 160.63583364746563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.175860595703125 and perplexity of 176.9488301717839
Finished 26 epochs...
Completing Train Step...
At time: 813.1567091941833 and batch: 50, loss is 5.180692710876465 and perplexity is 177.8059364493482
At time: 814.2571165561676 and batch: 100, loss is 5.197859601974487 and perplexity is 180.8846620620631
At time: 815.3290388584137 and batch: 150, loss is 5.164808511734009 and perplexity is 175.0039441612828
At time: 816.403317451477 and batch: 200, loss is 5.151706943511963 and perplexity is 172.72607247653588
At time: 817.476434469223 and batch: 250, loss is 5.16086443901062 and perplexity is 174.3150752461667
At time: 818.5493757724762 and batch: 300, loss is 5.180559606552124 and perplexity is 177.78227128531606
At time: 819.6234741210938 and batch: 350, loss is 5.180273780822754 and perplexity is 177.7314637993461
At time: 820.696784734726 and batch: 400, loss is 5.209010124206543 and perplexity is 182.9129074907261
At time: 821.7692844867706 and batch: 450, loss is 5.176135196685791 and perplexity is 176.99742716651645
At time: 822.8435275554657 and batch: 500, loss is 5.205888996124267 and perplexity is 182.34290286998262
At time: 823.9162230491638 and batch: 550, loss is 5.184816951751709 and perplexity is 178.5407652241679
At time: 824.9898571968079 and batch: 600, loss is 5.151693677902221 and perplexity is 172.72378117506403
At time: 826.0647461414337 and batch: 650, loss is 5.157807731628418 and perplexity is 173.7830585926884
At time: 827.1374819278717 and batch: 700, loss is 5.183805904388428 and perplexity is 178.36034327718585
At time: 828.2104654312134 and batch: 750, loss is 5.16230767250061 and perplexity is 174.56683423037128
At time: 829.2849032878876 and batch: 800, loss is 5.153318948745728 and perplexity is 173.0047323496198
At time: 830.3582353591919 and batch: 850, loss is 5.1105013179779055 and perplexity is 165.75342922262632
At time: 831.4328908920288 and batch: 900, loss is 5.145758581161499 and perplexity is 171.70168494467788
At time: 832.508171081543 and batch: 950, loss is 5.1260754489898686 and perplexity is 168.35510165179014
At time: 833.586907863617 and batch: 1000, loss is 5.13969295501709 and perplexity is 170.6633589475855
At time: 834.6618399620056 and batch: 1050, loss is 5.112399587631225 and perplexity is 166.0683727565568
At time: 835.7373929023743 and batch: 1100, loss is 5.115391092300415 and perplexity is 166.56591089184704
At time: 836.8106951713562 and batch: 1150, loss is 5.119415512084961 and perplexity is 167.23759269730076
At time: 837.8851351737976 and batch: 1200, loss is 5.098259601593018 and perplexity is 163.73669209975952
At time: 839.0009872913361 and batch: 1250, loss is 5.111156139373779 and perplexity is 165.86200365907314
At time: 840.0732085704803 and batch: 1300, loss is 5.098019390106201 and perplexity is 163.69736538905678
At time: 841.1507380008698 and batch: 1350, loss is 5.079091358184814 and perplexity is 160.6280362484337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.175838623046875 and perplexity of 176.9449421786796
Finished 27 epochs...
Completing Train Step...
At time: 844.3218622207642 and batch: 50, loss is 5.179659881591797 and perplexity is 177.62238807458027
At time: 845.3943982124329 and batch: 100, loss is 5.196807689666748 and perplexity is 180.69448730088075
At time: 846.4666864871979 and batch: 150, loss is 5.163595142364502 and perplexity is 174.7917285099167
At time: 847.5408980846405 and batch: 200, loss is 5.150613613128662 and perplexity is 172.53732901179302
At time: 848.6145248413086 and batch: 250, loss is 5.159888410568238 and perplexity is 174.1450217768017
At time: 849.6886885166168 and batch: 300, loss is 5.1796747589111325 and perplexity is 177.6250306392259
At time: 850.7632327079773 and batch: 350, loss is 5.179390869140625 and perplexity is 177.57461186706678
At time: 851.8356518745422 and batch: 400, loss is 5.208010902404785 and perplexity is 182.73022820949836
At time: 852.9096369743347 and batch: 450, loss is 5.175140361785889 and perplexity is 176.82143150660596
At time: 853.9834969043732 and batch: 500, loss is 5.204875841140747 and perplexity is 182.15825480357947
At time: 855.0566782951355 and batch: 550, loss is 5.184087476730347 and perplexity is 178.41057168788163
At time: 856.1312389373779 and batch: 600, loss is 5.151064138412476 and perplexity is 172.61507895375675
At time: 857.2041628360748 and batch: 650, loss is 5.157009191513062 and perplexity is 173.64434124208864
At time: 858.2775509357452 and batch: 700, loss is 5.183222818374634 and perplexity is 178.25637417001724
At time: 859.3515980243683 and batch: 750, loss is 5.161822967529297 and perplexity is 174.4822413209514
At time: 860.4239726066589 and batch: 800, loss is 5.153046531677246 and perplexity is 172.95760932644896
At time: 861.5050387382507 and batch: 850, loss is 5.11015456199646 and perplexity is 165.69596319351868
At time: 862.5796272754669 and batch: 900, loss is 5.145466661453247 and perplexity is 171.65156915415176
At time: 863.6527490615845 and batch: 950, loss is 5.125987339019775 and perplexity is 168.34026854230055
At time: 864.7251143455505 and batch: 1000, loss is 5.139648056030273 and perplexity is 170.65569650770124
At time: 865.8076815605164 and batch: 1050, loss is 5.112550039291381 and perplexity is 166.0933598985688
At time: 866.9063816070557 and batch: 1100, loss is 5.115549840927124 and perplexity is 166.592355100393
At time: 867.9788579940796 and batch: 1150, loss is 5.119730987548828 and perplexity is 167.29036037744947
At time: 869.0561106204987 and batch: 1200, loss is 5.098644895553589 and perplexity is 163.79979101338404
At time: 870.1304616928101 and batch: 1250, loss is 5.11152606010437 and perplexity is 165.92337080243337
At time: 871.2027018070221 and batch: 1300, loss is 5.098292427062988 and perplexity is 163.74206692184418
At time: 872.2775304317474 and batch: 1350, loss is 5.079003190994262 and perplexity is 160.61387475005273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.175855305989583 and perplexity of 176.9478941656363
Annealing...
Finished 28 epochs...
Completing Train Step...
At time: 875.4495978355408 and batch: 50, loss is 5.179373931884766 and perplexity is 177.57160426590184
At time: 876.5218155384064 and batch: 100, loss is 5.196659517288208 and perplexity is 180.6677153523889
At time: 877.5956993103027 and batch: 150, loss is 5.16333722114563 and perplexity is 174.74665182761694
At time: 878.6684198379517 and batch: 200, loss is 5.150717172622681 and perplexity is 172.55519781551095
At time: 879.741379737854 and batch: 250, loss is 5.159457216262817 and perplexity is 174.06994762203144
At time: 880.8222897052765 and batch: 300, loss is 5.179399356842041 and perplexity is 177.5761190737478
At time: 881.8958218097687 and batch: 350, loss is 5.178759555816651 and perplexity is 177.46254202790908
At time: 882.9688041210175 and batch: 400, loss is 5.206873216629028 and perplexity is 182.52245683973993
At time: 884.0425560474396 and batch: 450, loss is 5.173661985397339 and perplexity is 176.5602160122625
At time: 885.1222672462463 and batch: 500, loss is 5.202898569107056 and perplexity is 181.79843422945928
At time: 886.1953022480011 and batch: 550, loss is 5.181084470748901 and perplexity is 177.87560732656598
At time: 887.2695136070251 and batch: 600, loss is 5.148232679367066 and perplexity is 172.12701771585438
At time: 888.3417000770569 and batch: 650, loss is 5.154553031921386 and perplexity is 173.2183663730858
At time: 889.4150371551514 and batch: 700, loss is 5.179681320190429 and perplexity is 177.62619609048545
At time: 890.4892632961273 and batch: 750, loss is 5.158441190719604 and perplexity is 173.89317792541198
At time: 891.5625240802765 and batch: 800, loss is 5.14988447189331 and perplexity is 172.41157078389944
At time: 892.6421751976013 and batch: 850, loss is 5.105570077896118 and perplexity is 164.93807128388724
At time: 893.7600636482239 and batch: 900, loss is 5.13956036567688 and perplexity is 170.64073230548365
At time: 894.8345401287079 and batch: 950, loss is 5.119848384857177 and perplexity is 167.31000096832426
At time: 895.910918712616 and batch: 1000, loss is 5.133681468963623 and perplexity is 169.64049608868635
At time: 896.98534989357 and batch: 1050, loss is 5.10623929977417 and perplexity is 165.04848839236558
At time: 898.0583896636963 and batch: 1100, loss is 5.108980312347412 and perplexity is 165.50150895814267
At time: 899.1322264671326 and batch: 1150, loss is 5.113200206756591 and perplexity is 166.20138351027586
At time: 900.2053165435791 and batch: 1200, loss is 5.091461458206177 and perplexity is 162.62736155551312
At time: 901.2786433696747 and batch: 1250, loss is 5.104221343994141 and perplexity is 164.71576366603
At time: 902.3511972427368 and batch: 1300, loss is 5.092350130081177 and perplexity is 162.77194815333897
At time: 903.4262843132019 and batch: 1350, loss is 5.074272956848144 and perplexity is 159.85592756246598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1726302083333335 and perplexity of 176.37813917846842
Finished 29 epochs...
Completing Train Step...
At time: 906.5797810554504 and batch: 50, loss is 5.177532920837402 and perplexity is 177.244993719811
At time: 907.678169965744 and batch: 100, loss is 5.1948598194122315 and perplexity is 180.3428604568258
At time: 908.7604944705963 and batch: 150, loss is 5.161413984298706 and perplexity is 174.41089560081133
At time: 909.844277381897 and batch: 200, loss is 5.1490160083770755 and perplexity is 172.26190262497167
At time: 910.9177913665771 and batch: 250, loss is 5.157950201034546 and perplexity is 173.8078191256085
At time: 911.9911754131317 and batch: 300, loss is 5.177931289672852 and perplexity is 177.31561666760524
At time: 913.0658416748047 and batch: 350, loss is 5.177349252700806 and perplexity is 177.21244245150032
At time: 914.1394815444946 and batch: 400, loss is 5.205561246871948 and perplexity is 182.28314991242974
At time: 915.212860584259 and batch: 450, loss is 5.172624378204346 and perplexity is 176.37711087416398
At time: 916.2868540287018 and batch: 500, loss is 5.2018193340301515 and perplexity is 181.60233681894817
At time: 917.3596158027649 and batch: 550, loss is 5.18050326347351 and perplexity is 177.77225476701236
At time: 918.4390144348145 and batch: 600, loss is 5.147720727920532 and perplexity is 172.03891959305213
At time: 919.5167725086212 and batch: 650, loss is 5.154122457504273 and perplexity is 173.1437990304984
At time: 920.6156389713287 and batch: 700, loss is 5.179366855621338 and perplexity is 177.57034772689858
At time: 921.6896905899048 and batch: 750, loss is 5.158221225738526 and perplexity is 173.8549317223868
At time: 922.7626953125 and batch: 800, loss is 5.149831342697143 and perplexity is 172.40241093906354
At time: 923.8359708786011 and batch: 850, loss is 5.105689687728882 and perplexity is 164.95780067890118
At time: 924.9175145626068 and batch: 900, loss is 5.139871501922608 and perplexity is 170.69383308266123
At time: 925.991726398468 and batch: 950, loss is 5.119984226226807 and perplexity is 167.33273013175386
At time: 927.0641896724701 and batch: 1000, loss is 5.133971872329712 and perplexity is 169.68976741370864
At time: 928.1381833553314 and batch: 1050, loss is 5.106679019927978 and perplexity is 165.1210794977836
At time: 929.2120461463928 and batch: 1100, loss is 5.109556522369385 and perplexity is 165.59690006627292
At time: 930.2872474193573 and batch: 1150, loss is 5.113872966766357 and perplexity is 166.31323477497963
At time: 931.3601427078247 and batch: 1200, loss is 5.092325792312622 and perplexity is 162.7679866955444
At time: 932.4376695156097 and batch: 1250, loss is 5.104930267333985 and perplexity is 164.83257591590603
At time: 933.5122027397156 and batch: 1300, loss is 5.093029994964599 and perplexity is 162.88264871134172
At time: 934.5861074924469 and batch: 1350, loss is 5.0743791866302494 and perplexity is 159.8729099248195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172438557942709 and perplexity of 176.3443394781635
Finished 30 epochs...
Completing Train Step...
At time: 937.7334620952606 and batch: 50, loss is 5.176595287322998 and perplexity is 177.07888076214707
At time: 938.8323686122894 and batch: 100, loss is 5.193794059753418 and perplexity is 180.15076069566675
At time: 939.9074244499207 and batch: 150, loss is 5.160267095565796 and perplexity is 174.2109803719251
At time: 940.9809567928314 and batch: 200, loss is 5.147964124679565 and perplexity is 172.0807984048854
At time: 942.0545516014099 and batch: 250, loss is 5.157047071456909 and perplexity is 173.65091900456616
At time: 943.1290147304535 and batch: 300, loss is 5.17705078125 and perplexity is 177.15955748941934
At time: 944.2034223079681 and batch: 350, loss is 5.176517810821533 and perplexity is 177.06516184143612
At time: 945.2773590087891 and batch: 400, loss is 5.204753370285034 and perplexity is 182.13594709228866
At time: 946.3523106575012 and batch: 450, loss is 5.171944427490234 and perplexity is 176.25722389490969
At time: 947.4266300201416 and batch: 500, loss is 5.201119890213013 and perplexity is 181.47536059882492
At time: 948.5261852741241 and batch: 550, loss is 5.180113935470581 and perplexity is 177.70305652136918
At time: 949.609105348587 and batch: 600, loss is 5.14741325378418 and perplexity is 171.98603020630713
At time: 950.6827988624573 and batch: 650, loss is 5.153885564804077 and perplexity is 173.1027873862953
At time: 951.7595400810242 and batch: 700, loss is 5.179177322387695 and perplexity is 177.53669543390953
At time: 952.8353922367096 and batch: 750, loss is 5.1581706619262695 and perplexity is 173.84614117650298
At time: 953.9090468883514 and batch: 800, loss is 5.149871091842652 and perplexity is 172.4092639237812
At time: 954.9827547073364 and batch: 850, loss is 5.105824317932129 and perplexity is 164.98001047615494
At time: 956.0576519966125 and batch: 900, loss is 5.140117225646972 and perplexity is 170.73578176073397
At time: 957.1318802833557 and batch: 950, loss is 5.120072221755981 and perplexity is 167.3474553117555
At time: 958.2065906524658 and batch: 1000, loss is 5.1341617393493655 and perplexity is 169.72198896292107
At time: 959.2851374149323 and batch: 1050, loss is 5.106952257156372 and perplexity is 165.16620288830936
At time: 960.359453201294 and batch: 1100, loss is 5.109908065795898 and perplexity is 165.65512480160413
At time: 961.4351952075958 and batch: 1150, loss is 5.114280548095703 and perplexity is 166.38103476036247
At time: 962.5085551738739 and batch: 1200, loss is 5.092856101989746 and perplexity is 162.85432702554778
At time: 963.5835769176483 and batch: 1250, loss is 5.105361347198486 and perplexity is 164.90364723800465
At time: 964.6567988395691 and batch: 1300, loss is 5.0933851051330565 and perplexity is 162.94050026739436
At time: 965.7308509349823 and batch: 1350, loss is 5.074349575042724 and perplexity is 159.86817590424565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1723486328125 and perplexity of 176.32848240345976
Finished 31 epochs...
Completing Train Step...
At time: 968.9099080562592 and batch: 50, loss is 5.175812664031983 and perplexity is 176.94034892190894
At time: 969.9842615127563 and batch: 100, loss is 5.192984418869019 and perplexity is 180.00496230458552
At time: 971.0582399368286 and batch: 150, loss is 5.1593918800354 and perplexity is 174.05857491987595
At time: 972.1331775188446 and batch: 200, loss is 5.147156839370727 and perplexity is 171.94193616266557
At time: 973.2146971225739 and batch: 250, loss is 5.156331672668457 and perplexity is 173.52673377377494
At time: 974.2881338596344 and batch: 300, loss is 5.176301012039184 and perplexity is 177.0267784908347
At time: 975.3892803192139 and batch: 350, loss is 5.175866937637329 and perplexity is 176.94995237318068
At time: 976.4631505012512 and batch: 400, loss is 5.204145097732544 and perplexity is 182.02519248276013
At time: 977.5389275550842 and batch: 450, loss is 5.171405925750732 and perplexity is 176.16233462455406
At time: 978.6122353076935 and batch: 500, loss is 5.200558433532715 and perplexity is 181.37349864352066
At time: 979.6864218711853 and batch: 550, loss is 5.179777526855469 and perplexity is 177.64328573649078
At time: 980.7605423927307 and batch: 600, loss is 5.147165021896362 and perplexity is 171.943343087722
At time: 981.8351833820343 and batch: 650, loss is 5.15368465423584 and perplexity is 173.068012700336
At time: 982.909425497055 and batch: 700, loss is 5.179004955291748 and perplexity is 177.50609658648645
At time: 983.9841423034668 and batch: 750, loss is 5.15812271118164 and perplexity is 173.83780532443942
At time: 985.0574645996094 and batch: 800, loss is 5.149911499023437 and perplexity is 172.4162306368293
At time: 986.1314649581909 and batch: 850, loss is 5.105908184051514 and perplexity is 164.99384728962153
At time: 987.206634759903 and batch: 900, loss is 5.140241718292236 and perplexity is 170.75703843296876
At time: 988.2811291217804 and batch: 950, loss is 5.120095376968384 and perplexity is 167.35133032249146
At time: 989.3630883693695 and batch: 1000, loss is 5.134273471832276 and perplexity is 169.74095348160904
At time: 990.445729970932 and batch: 1050, loss is 5.107138023376465 and perplexity is 165.19688803955106
At time: 991.5195822715759 and batch: 1100, loss is 5.110133934020996 and perplexity is 165.69254525650817
At time: 992.5997793674469 and batch: 1150, loss is 5.114565391540527 and perplexity is 166.42843405782608
At time: 993.6797821521759 and batch: 1200, loss is 5.093245601654052 and perplexity is 162.91777108617316
At time: 994.7582631111145 and batch: 1250, loss is 5.105676965713501 and perplexity is 164.95570209657288
At time: 995.8329384326935 and batch: 1300, loss is 5.093681259155273 and perplexity is 162.98876289816394
At time: 996.9064793586731 and batch: 1350, loss is 5.074273538589478 and perplexity is 159.85602055729348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1723095703125 and perplexity of 176.3215947066421
Finished 32 epochs...
Completing Train Step...
At time: 1000.0817742347717 and batch: 50, loss is 5.175148439407349 and perplexity is 176.82285980896427
At time: 1001.1543323993683 and batch: 100, loss is 5.19228835105896 and perplexity is 179.87971024169624
At time: 1002.253829240799 and batch: 150, loss is 5.158665990829467 and perplexity is 173.93227352509695
At time: 1003.3340878486633 and batch: 200, loss is 5.14645824432373 and perplexity is 171.82186032476744
At time: 1004.4066021442413 and batch: 250, loss is 5.1556956005096435 and perplexity is 173.41639334556902
At time: 1005.4818489551544 and batch: 300, loss is 5.175658979415894 and perplexity is 176.91315800178074
At time: 1006.5549364089966 and batch: 350, loss is 5.1753448867797855 and perplexity is 176.85759960731983
At time: 1007.6285226345062 and batch: 400, loss is 5.203642435073853 and perplexity is 181.93371820783508
At time: 1008.70352602005 and batch: 450, loss is 5.170941133499145 and perplexity is 176.08047476178777
At time: 1009.7765522003174 and batch: 500, loss is 5.200061702728272 and perplexity is 181.2834272121142
At time: 1010.8499913215637 and batch: 550, loss is 5.179480285644531 and perplexity is 177.59049067794572
At time: 1011.9265880584717 and batch: 600, loss is 5.146961936950683 and perplexity is 171.9084275287634
At time: 1012.9996643066406 and batch: 650, loss is 5.153513298034668 and perplexity is 173.03835896388372
At time: 1014.0733547210693 and batch: 700, loss is 5.178859605789184 and perplexity is 177.48029803859407
At time: 1015.1477515697479 and batch: 750, loss is 5.158076763153076 and perplexity is 173.82981800349708
At time: 1016.2268731594086 and batch: 800, loss is 5.149943256378174 and perplexity is 172.42170620717243
At time: 1017.3023614883423 and batch: 850, loss is 5.105983018875122 and perplexity is 165.00619503709487
At time: 1018.3771557807922 and batch: 900, loss is 5.140333957672119 and perplexity is 170.77278968273615
At time: 1019.4500019550323 and batch: 950, loss is 5.120075693130493 and perplexity is 167.34803623845488
At time: 1020.5233683586121 and batch: 1000, loss is 5.134339962005615 and perplexity is 169.75223996224472
At time: 1021.5982563495636 and batch: 1050, loss is 5.107254238128662 and perplexity is 165.21608747056518
At time: 1022.6717903614044 and batch: 1100, loss is 5.110291070938111 and perplexity is 165.71858371800687
At time: 1023.7464509010315 and batch: 1150, loss is 5.114806585311889 and perplexity is 166.46858040082776
At time: 1024.8200047016144 and batch: 1200, loss is 5.093502445220947 and perplexity is 162.95962084179968
At time: 1025.89297580719 and batch: 1250, loss is 5.1059034633636475 and perplexity is 164.99306840700703
At time: 1026.9678692817688 and batch: 1300, loss is 5.09391978263855 and perplexity is 163.0276441824907
At time: 1028.0418128967285 and batch: 1350, loss is 5.074177017211914 and perplexity is 159.84059177859294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172285563151042 and perplexity of 176.31736177645996
Finished 33 epochs...
Completing Train Step...
At time: 1031.1831767559052 and batch: 50, loss is 5.1745407676696775 and perplexity is 176.71544219511364
At time: 1032.2829070091248 and batch: 100, loss is 5.191666469573975 and perplexity is 179.76788115619533
At time: 1033.355234861374 and batch: 150, loss is 5.158009719848633 and perplexity is 173.81816426874417
At time: 1034.428115606308 and batch: 200, loss is 5.145820732116699 and perplexity is 171.71235670003313
At time: 1035.5017311573029 and batch: 250, loss is 5.155152530670166 and perplexity is 173.3222417004454
At time: 1036.5747306346893 and batch: 300, loss is 5.175094451904297 and perplexity is 176.81331384196443
At time: 1037.6494870185852 and batch: 350, loss is 5.174874458312988 and perplexity is 176.77442032438037
At time: 1038.723364830017 and batch: 400, loss is 5.203188552856445 and perplexity is 181.85116046555655
At time: 1039.7957952022552 and batch: 450, loss is 5.170525970458985 and perplexity is 176.00738782911912
At time: 1040.8692889213562 and batch: 500, loss is 5.199584636688233 and perplexity is 181.1969636714187
At time: 1041.9417848587036 and batch: 550, loss is 5.179202833175659 and perplexity is 177.5412245926735
At time: 1043.016618013382 and batch: 600, loss is 5.146787281036377 and perplexity is 171.87840532703026
At time: 1044.0894510746002 and batch: 650, loss is 5.153368082046509 and perplexity is 173.013232851998
At time: 1045.163771390915 and batch: 700, loss is 5.178717317581177 and perplexity is 177.4550464815716
At time: 1046.2386791706085 and batch: 750, loss is 5.158018980026245 and perplexity is 173.8197738632701
At time: 1047.311321258545 and batch: 800, loss is 5.149961814880371 and perplexity is 172.42490612547866
At time: 1048.3845257759094 and batch: 850, loss is 5.106035623550415 and perplexity is 165.014875362717
At time: 1049.4595017433167 and batch: 900, loss is 5.140407133102417 and perplexity is 170.78528651232912
At time: 1050.5334508419037 and batch: 950, loss is 5.1200314807891845 and perplexity is 167.34063755351713
At time: 1051.6073274612427 and batch: 1000, loss is 5.134363012313843 and perplexity is 169.7561528487946
At time: 1052.6845209598541 and batch: 1050, loss is 5.107342777252197 and perplexity is 165.23071620574186
At time: 1053.7583980560303 and batch: 1100, loss is 5.110418195724487 and perplexity is 165.7396519966825
At time: 1054.8328604698181 and batch: 1150, loss is 5.114995965957641 and perplexity is 166.50010931347018
At time: 1055.9060504436493 and batch: 1200, loss is 5.093680791854858 and perplexity is 162.98868673346513
At time: 1057.0038828849792 and batch: 1250, loss is 5.106089906692505 and perplexity is 165.02383313176895
At time: 1058.0778486728668 and batch: 1300, loss is 5.094113140106201 and perplexity is 163.0591698426897
At time: 1059.1509277820587 and batch: 1350, loss is 5.074074726104737 and perplexity is 159.82424234370316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1722794596354165 and perplexity of 176.3162856239715
Finished 34 epochs...
Completing Train Step...
At time: 1062.294626235962 and batch: 50, loss is 5.173981981277466 and perplexity is 176.61672359459533
At time: 1063.3952496051788 and batch: 100, loss is 5.191111373901367 and perplexity is 179.66812047421467
At time: 1064.4677648544312 and batch: 150, loss is 5.157415180206299 and perplexity is 173.71485319383663
At time: 1065.540599822998 and batch: 200, loss is 5.145242691040039 and perplexity is 171.6131285862162
At time: 1066.615473985672 and batch: 250, loss is 5.1546351146698 and perplexity is 173.23258519622541
At time: 1067.6890580654144 and batch: 300, loss is 5.174577350616455 and perplexity is 176.7219070849819
At time: 1068.7612998485565 and batch: 350, loss is 5.174445734024048 and perplexity is 176.69864908037093
At time: 1069.8353326320648 and batch: 400, loss is 5.202766590118408 and perplexity is 181.774442239226
At time: 1070.9088821411133 and batch: 450, loss is 5.170131931304931 and perplexity is 175.93804768917406
At time: 1071.9917764663696 and batch: 500, loss is 5.199149932861328 and perplexity is 181.11821377556788
At time: 1073.0654735565186 and batch: 550, loss is 5.178951921463013 and perplexity is 177.49668300818198
At time: 1074.1451394557953 and batch: 600, loss is 5.146634454727173 and perplexity is 171.8521397917958
At time: 1075.221779346466 and batch: 650, loss is 5.1532332229614255 and perplexity is 172.98990201893105
At time: 1076.294667005539 and batch: 700, loss is 5.178576059341431 and perplexity is 177.42998126444743
At time: 1077.3692688941956 and batch: 750, loss is 5.157949514389038 and perplexity is 173.80769978129126
At time: 1078.4422302246094 and batch: 800, loss is 5.149973373413086 and perplexity is 172.426899115915
At time: 1079.5154206752777 and batch: 850, loss is 5.1060710048675535 and perplexity is 165.02071390964187
At time: 1080.5903210639954 and batch: 900, loss is 5.1404461097717284 and perplexity is 170.79194328369334
At time: 1081.6637346744537 and batch: 950, loss is 5.119971704483032 and perplexity is 167.33063484730044
At time: 1082.7454195022583 and batch: 1000, loss is 5.134364633560181 and perplexity is 169.75642806555888
At time: 1083.8434889316559 and batch: 1050, loss is 5.10738956451416 and perplexity is 165.23844707939716
At time: 1084.9174528121948 and batch: 1100, loss is 5.11049819946289 and perplexity is 165.75291231887448
At time: 1085.9908094406128 and batch: 1150, loss is 5.11511004447937 and perplexity is 166.51910448325816
At time: 1087.0655014514923 and batch: 1200, loss is 5.093868064880371 and perplexity is 163.0192129762358
At time: 1088.1421213150024 and batch: 1250, loss is 5.1062342548370365 and perplexity is 165.04765573521797
At time: 1089.216035604477 and batch: 1300, loss is 5.0942693710327145 and perplexity is 163.08464671795676
At time: 1090.2907297611237 and batch: 1350, loss is 5.0739508056640625 and perplexity is 159.80443808026337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172280680338542 and perplexity of 176.31650085394375
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 1093.4579548835754 and batch: 50, loss is 5.173748455047607 and perplexity is 176.57548377248185
At time: 1094.5351326465607 and batch: 100, loss is 5.19088547706604 and perplexity is 179.6275385982216
At time: 1095.6154072284698 and batch: 150, loss is 5.157394790649414 and perplexity is 173.71131126106508
At time: 1096.6882519721985 and batch: 200, loss is 5.145363159179688 and perplexity is 171.63380374588027
At time: 1097.7681045532227 and batch: 250, loss is 5.154353837966919 and perplexity is 173.18386575797268
At time: 1098.8433804512024 and batch: 300, loss is 5.174336929321289 and perplexity is 176.67942448226205
At time: 1099.9167551994324 and batch: 350, loss is 5.174207191467286 and perplexity is 176.65650395974507
At time: 1100.9900856018066 and batch: 400, loss is 5.20277883529663 and perplexity is 181.7766681132956
At time: 1102.0642657279968 and batch: 450, loss is 5.169770879745483 and perplexity is 175.87453644879574
At time: 1103.1366333961487 and batch: 500, loss is 5.198636331558228 and perplexity is 181.02521510911998
At time: 1104.2151358127594 and batch: 550, loss is 5.17786283493042 and perplexity is 177.30347898818272
At time: 1105.288557767868 and batch: 600, loss is 5.1451804828643795 and perplexity is 171.60245317861987
At time: 1106.3625371456146 and batch: 650, loss is 5.151978721618653 and perplexity is 172.77302202112972
At time: 1107.4365193843842 and batch: 700, loss is 5.176793394088745 and perplexity is 177.11396476157097
At time: 1108.509705543518 and batch: 750, loss is 5.1563161182403565 and perplexity is 173.52403468566243
At time: 1109.5820908546448 and batch: 800, loss is 5.148445043563843 and perplexity is 172.16357521332964
At time: 1110.6844215393066 and batch: 850, loss is 5.104192171096802 and perplexity is 164.71095850005713
At time: 1111.7615089416504 and batch: 900, loss is 5.137902317047119 and perplexity is 170.35803609989512
At time: 1112.8395857810974 and batch: 950, loss is 5.117176322937012 and perplexity is 166.86353504381574
At time: 1113.9141852855682 and batch: 1000, loss is 5.131782636642456 and perplexity is 169.31868286310467
At time: 1114.9869725704193 and batch: 1050, loss is 5.104510612487793 and perplexity is 164.7634176389307
At time: 1116.0611379146576 and batch: 1100, loss is 5.107590026855469 and perplexity is 165.2715744856607
At time: 1117.1338758468628 and batch: 1150, loss is 5.11220266342163 and perplexity is 166.03567309329634
At time: 1118.2076330184937 and batch: 1200, loss is 5.090769033432007 and perplexity is 162.51479331842992
At time: 1119.2807371616364 and batch: 1250, loss is 5.102920894622803 and perplexity is 164.50169837542572
At time: 1120.3542137145996 and batch: 1300, loss is 5.0910405254364015 and perplexity is 162.55892077526647
At time: 1121.427333831787 and batch: 1350, loss is 5.071519508361816 and perplexity is 159.41637791704443
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171423746744792 and perplexity of 176.1654740404467
Finished 36 epochs...
Completing Train Step...
At time: 1124.5976786613464 and batch: 50, loss is 5.173105392456055 and perplexity is 176.4619711860432
At time: 1125.670266866684 and batch: 100, loss is 5.1901177978515625 and perplexity is 179.48969518702248
At time: 1126.7438442707062 and batch: 150, loss is 5.15680154800415 and perplexity is 173.6082888649211
At time: 1127.8183994293213 and batch: 200, loss is 5.144779272079468 and perplexity is 171.53361823327194
At time: 1128.8924057483673 and batch: 250, loss is 5.153903617858886 and perplexity is 173.105912448612
At time: 1129.966369152069 and batch: 300, loss is 5.173997364044189 and perplexity is 176.61944046935034
At time: 1131.0416967868805 and batch: 350, loss is 5.1737415599823 and perplexity is 176.57426627718695
At time: 1132.1234409809113 and batch: 400, loss is 5.202407159805298 and perplexity is 181.70911873486364
At time: 1133.1984174251556 and batch: 450, loss is 5.1694693279266355 and perplexity is 175.8215091580804
At time: 1134.2720246315002 and batch: 500, loss is 5.198315105438232 and perplexity is 180.96707442030308
At time: 1135.3454959392548 and batch: 550, loss is 5.177713394165039 and perplexity is 177.2769846002981
At time: 1136.4204301834106 and batch: 600, loss is 5.145055303573608 and perplexity is 171.58097344967302
At time: 1137.4933094978333 and batch: 650, loss is 5.151764917373657 and perplexity is 172.73608636424171
At time: 1138.5914857387543 and batch: 700, loss is 5.176659679412841 and perplexity is 177.09028360846906
At time: 1139.6665296554565 and batch: 750, loss is 5.156213369369507 and perplexity is 173.50620620297707
At time: 1140.740932226181 and batch: 800, loss is 5.148436403274536 and perplexity is 172.16208767665805
At time: 1141.814003944397 and batch: 850, loss is 5.104195203781128 and perplexity is 164.71145801715673
At time: 1142.889271736145 and batch: 900, loss is 5.137996511459351 and perplexity is 170.37408363075656
At time: 1143.962450504303 and batch: 950, loss is 5.117258348464966 and perplexity is 166.87722267473387
At time: 1145.0361986160278 and batch: 1000, loss is 5.13190242767334 and perplexity is 169.33896693757347
At time: 1146.1114339828491 and batch: 1050, loss is 5.104622240066528 and perplexity is 164.78181080687915
At time: 1147.1855890750885 and batch: 1100, loss is 5.107803430557251 and perplexity is 165.3068478150509
At time: 1148.2646083831787 and batch: 1150, loss is 5.112404994964599 and perplexity is 166.06927074603902
At time: 1149.3421046733856 and batch: 1200, loss is 5.091043376922608 and perplexity is 162.55938431044765
At time: 1150.4154229164124 and batch: 1250, loss is 5.103109493255615 and perplexity is 164.53272609663554
At time: 1151.489012479782 and batch: 1300, loss is 5.091153497695923 and perplexity is 162.5772864612388
At time: 1152.5641174316406 and batch: 1350, loss is 5.071560525894165 and perplexity is 159.42291691758857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171364339192708 and perplexity of 176.1550087917327
Finished 37 epochs...
Completing Train Step...
At time: 1155.7151386737823 and batch: 50, loss is 5.172719316482544 and perplexity is 176.39385660827693
At time: 1156.8245482444763 and batch: 100, loss is 5.18965594291687 and perplexity is 179.4068161260988
At time: 1157.8983211517334 and batch: 150, loss is 5.156404628753662 and perplexity is 173.53939406676656
At time: 1158.9723167419434 and batch: 200, loss is 5.144416427612304 and perplexity is 171.47138949932204
At time: 1160.0447640419006 and batch: 250, loss is 5.153601732254028 and perplexity is 173.05366215273082
At time: 1161.1203231811523 and batch: 300, loss is 5.173749408721924 and perplexity is 176.57565216806591
At time: 1162.1935467720032 and batch: 350, loss is 5.173490934371948 and perplexity is 176.5300177890625
At time: 1163.267966747284 and batch: 400, loss is 5.202204780578613 and perplexity is 181.67234830484364
At time: 1164.343067407608 and batch: 450, loss is 5.169317979812622 and perplexity is 175.79490091787054
At time: 1165.4418873786926 and batch: 500, loss is 5.198130388259887 and perplexity is 180.93364978009043
At time: 1166.5154304504395 and batch: 550, loss is 5.17763521194458 and perplexity is 177.2631252337908
At time: 1167.5910441875458 and batch: 600, loss is 5.144956064224243 and perplexity is 171.56394671037972
At time: 1168.664642572403 and batch: 650, loss is 5.151611366271973 and perplexity is 172.70956458415623
At time: 1169.7393572330475 and batch: 700, loss is 5.176549119949341 and perplexity is 177.07070568400448
At time: 1170.8143997192383 and batch: 750, loss is 5.156136178970337 and perplexity is 173.4928137065546
At time: 1171.8883256912231 and batch: 800, loss is 5.148444051742554 and perplexity is 172.16340445791522
At time: 1172.9636421203613 and batch: 850, loss is 5.104201545715332 and perplexity is 164.71250260969856
At time: 1174.0373060703278 and batch: 900, loss is 5.138048820495605 and perplexity is 170.38299596796986
At time: 1175.1110150814056 and batch: 950, loss is 5.117307481765747 and perplexity is 166.8854221049399
At time: 1176.1856100559235 and batch: 1000, loss is 5.131992950439453 and perplexity is 169.35429666310554
At time: 1177.259435415268 and batch: 1050, loss is 5.104700803756714 and perplexity is 164.79475718256245
At time: 1178.3335525989532 and batch: 1100, loss is 5.107940502166748 and perplexity is 165.32950824375712
At time: 1179.4091091156006 and batch: 1150, loss is 5.112540760040283 and perplexity is 166.09181868372724
At time: 1180.4870510101318 and batch: 1200, loss is 5.091215496063232 and perplexity is 162.58736630002454
At time: 1181.5746140480042 and batch: 1250, loss is 5.1032239818573 and perplexity is 164.55156429673684
At time: 1182.6484591960907 and batch: 1300, loss is 5.091213512420654 and perplexity is 162.58704378512195
At time: 1183.7469515800476 and batch: 1350, loss is 5.071545934677124 and perplexity is 159.42059076017716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1713330078125 and perplexity of 176.1494896986375
Finished 38 epochs...
Completing Train Step...
At time: 1186.878381729126 and batch: 50, loss is 5.172392225265503 and perplexity is 176.3361691620831
At time: 1187.9760267734528 and batch: 100, loss is 5.1892431640625 and perplexity is 179.33277606820846
At time: 1189.0528845787048 and batch: 150, loss is 5.156064453125 and perplexity is 173.48037023409626
At time: 1190.1289477348328 and batch: 200, loss is 5.144130172729493 and perplexity is 171.42231200148717
At time: 1191.2030582427979 and batch: 250, loss is 5.153322305679321 and perplexity is 173.0053131159924
At time: 1192.3050181865692 and batch: 300, loss is 5.173454809188843 and perplexity is 176.5236407250333
At time: 1193.3811285495758 and batch: 350, loss is 5.173277292251587 and perplexity is 176.4923075701437
At time: 1194.4547398090363 and batch: 400, loss is 5.202043466567993 and perplexity is 181.64304437335065
At time: 1195.5283472537994 and batch: 450, loss is 5.1691845035552975 and perplexity is 175.77143803834284
At time: 1196.6023089885712 and batch: 500, loss is 5.1979624462127685 and perplexity is 180.90326596398526
At time: 1197.6760342121124 and batch: 550, loss is 5.177572917938233 and perplexity is 177.25208314747383
At time: 1198.7512681484222 and batch: 600, loss is 5.144827671051026 and perplexity is 171.54192048489057
At time: 1199.8250586986542 and batch: 650, loss is 5.1515312671661375 and perplexity is 172.69573125648984
At time: 1200.8994262218475 and batch: 700, loss is 5.176444969177246 and perplexity is 177.0522645936357
At time: 1201.9744806289673 and batch: 750, loss is 5.156059608459473 and perplexity is 173.47952978176278
At time: 1203.0479333400726 and batch: 800, loss is 5.148444538116455 and perplexity is 172.16348819372226
At time: 1204.1238260269165 and batch: 850, loss is 5.104209594726562 and perplexity is 164.71382838781736
At time: 1205.1974618434906 and batch: 900, loss is 5.13805817604065 and perplexity is 170.38459000121998
At time: 1206.2720789909363 and batch: 950, loss is 5.117310619354248 and perplexity is 166.88594572354273
At time: 1207.3464312553406 and batch: 1000, loss is 5.132053966522217 and perplexity is 169.36463031414343
At time: 1208.4203233718872 and batch: 1050, loss is 5.104710702896118 and perplexity is 164.79638851691126
At time: 1209.4951751232147 and batch: 1100, loss is 5.107993011474609 and perplexity is 165.3381898097335
At time: 1210.5685865879059 and batch: 1150, loss is 5.112575788497924 and perplexity is 166.09763672586047
At time: 1211.6414375305176 and batch: 1200, loss is 5.091286640167237 and perplexity is 162.5989338439988
At time: 1212.7168138027191 and batch: 1250, loss is 5.10327543258667 and perplexity is 164.56003081254113
At time: 1213.790275335312 and batch: 1300, loss is 5.091246290206909 and perplexity is 162.59237311583232
At time: 1214.8637325763702 and batch: 1350, loss is 5.071486082077026 and perplexity is 159.41104930885427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17131591796875 and perplexity of 176.1464793571051
Finished 39 epochs...
Completing Train Step...
At time: 1218.059194803238 and batch: 50, loss is 5.1721127986907955 and perplexity is 176.28690303379048
At time: 1219.1332788467407 and batch: 100, loss is 5.18888150215149 and perplexity is 179.26792996059928
At time: 1220.2325220108032 and batch: 150, loss is 5.155777959823609 and perplexity is 173.43067638891802
At time: 1221.305385351181 and batch: 200, loss is 5.1438652038574215 and perplexity is 171.37689644194884
At time: 1222.3778760433197 and batch: 250, loss is 5.153089866638184 and perplexity is 172.96510460009557
At time: 1223.452829837799 and batch: 300, loss is 5.173273248672485 and perplexity is 176.49159391098004
At time: 1224.5262799263 and batch: 350, loss is 5.1731045627593994 and perplexity is 176.46182477619664
At time: 1225.5996026992798 and batch: 400, loss is 5.2019017314910885 and perplexity is 181.61730100689937
At time: 1226.675193309784 and batch: 450, loss is 5.169066915512085 and perplexity is 175.75077063403486
At time: 1227.748696088791 and batch: 500, loss is 5.19783724784851 and perplexity is 180.88061858873436
At time: 1228.8219487667084 and batch: 550, loss is 5.177516088485718 and perplexity is 177.24201029485158
At time: 1229.896767616272 and batch: 600, loss is 5.144756155014038 and perplexity is 171.52965292522913
At time: 1230.970056772232 and batch: 650, loss is 5.151425704956055 and perplexity is 172.67750207559982
At time: 1232.0432748794556 and batch: 700, loss is 5.17633623123169 and perplexity is 177.03301334081752
At time: 1233.1190121173859 and batch: 750, loss is 5.155984020233154 and perplexity is 173.466417267386
At time: 1234.1938474178314 and batch: 800, loss is 5.148446779251099 and perplexity is 172.16387403571244
At time: 1235.2680628299713 and batch: 850, loss is 5.104218835830689 and perplexity is 164.71535053248968
At time: 1236.3422646522522 and batch: 900, loss is 5.138085660934448 and perplexity is 170.3892730679375
At time: 1237.4156165122986 and batch: 950, loss is 5.117326221466064 and perplexity is 166.88854951704084
At time: 1238.4890131950378 and batch: 1000, loss is 5.132099618911743 and perplexity is 169.3723623907111
At time: 1239.5622744560242 and batch: 1050, loss is 5.104751272201538 and perplexity is 164.80307432754756
At time: 1240.6376085281372 and batch: 1100, loss is 5.108069238662719 and perplexity is 165.35079355539784
At time: 1241.7115678787231 and batch: 1150, loss is 5.1126572704315185 and perplexity is 166.11117123386776
At time: 1242.7862122058868 and batch: 1200, loss is 5.0913842678070065 and perplexity is 162.61480876904216
At time: 1243.8592607975006 and batch: 1250, loss is 5.103337697982788 and perplexity is 164.57027752704946
At time: 1244.9323048591614 and batch: 1300, loss is 5.091267642974853 and perplexity is 162.59584495011143
At time: 1246.013240814209 and batch: 1350, loss is 5.071441993713379 and perplexity is 159.40402129147103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171296793619792 and perplexity of 176.14311070257799
Finished 40 epochs...
Completing Train Step...
At time: 1249.1789257526398 and batch: 50, loss is 5.171846485137939 and perplexity is 176.23996169315654
At time: 1250.2539484500885 and batch: 100, loss is 5.188547286987305 and perplexity is 179.20802591093295
At time: 1251.332323551178 and batch: 150, loss is 5.155514364242554 and perplexity is 173.38496685368293
At time: 1252.40633559227 and batch: 200, loss is 5.143622751235962 and perplexity is 171.33535070078935
At time: 1253.481079339981 and batch: 250, loss is 5.152870712280273 and perplexity is 172.92720269699126
At time: 1254.554217338562 and batch: 300, loss is 5.173087167739868 and perplexity is 176.45875524600544
At time: 1255.6325025558472 and batch: 350, loss is 5.172948970794677 and perplexity is 176.43437087004025
At time: 1256.7100629806519 and batch: 400, loss is 5.20177451133728 and perplexity is 181.5941970956038
At time: 1257.7839488983154 and batch: 450, loss is 5.168950004577637 and perplexity is 175.73022464825866
At time: 1258.8579223155975 and batch: 500, loss is 5.1977238273620605 and perplexity is 180.86010418438352
At time: 1259.932074546814 and batch: 550, loss is 5.177461566925049 and perplexity is 177.23234704726428
At time: 1261.0055270195007 and batch: 600, loss is 5.1446816349029545 and perplexity is 171.51687099270043
At time: 1262.0793142318726 and batch: 650, loss is 5.151324796676636 and perplexity is 172.66007836508405
At time: 1263.1550920009613 and batch: 700, loss is 5.176232433319091 and perplexity is 177.0146386372162
At time: 1264.227962255478 and batch: 750, loss is 5.155909395217895 and perplexity is 173.45347281634648
At time: 1265.3030483722687 and batch: 800, loss is 5.1484448432922365 and perplexity is 172.16354073385733
At time: 1266.376256942749 and batch: 850, loss is 5.104217739105224 and perplexity is 164.71516988506949
At time: 1267.449999332428 and batch: 900, loss is 5.13810604095459 and perplexity is 170.39274564014
At time: 1268.5258932113647 and batch: 950, loss is 5.117333393096924 and perplexity is 166.88974638440445
At time: 1269.6000633239746 and batch: 1000, loss is 5.132130460739136 and perplexity is 169.37758622443286
At time: 1270.6734538078308 and batch: 1050, loss is 5.104779539108276 and perplexity is 164.80773286652064
At time: 1271.7483661174774 and batch: 1100, loss is 5.1081294822692875 and perplexity is 165.36075518360974
At time: 1272.8217811584473 and batch: 1150, loss is 5.112725143432617 and perplexity is 166.1224460801999
At time: 1273.922126531601 and batch: 1200, loss is 5.091471614837647 and perplexity is 162.6290133100795
At time: 1274.9966535568237 and batch: 1250, loss is 5.1033956241607665 and perplexity is 164.57981073034384
At time: 1276.069904088974 and batch: 1300, loss is 5.091292123794556 and perplexity is 162.5998254783992
At time: 1277.1450316905975 and batch: 1350, loss is 5.07141077041626 and perplexity is 159.39904425005247
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171306966145833 and perplexity of 176.14490253207225
Annealing...
Finished 41 epochs...
Completing Train Step...
At time: 1280.2897021770477 and batch: 50, loss is 5.17177749633789 and perplexity is 176.2278035290721
At time: 1281.3878405094147 and batch: 100, loss is 5.188396472930908 and perplexity is 179.18100085953645
At time: 1282.463306427002 and batch: 150, loss is 5.155456266403198 and perplexity is 173.3748938543446
At time: 1283.536194562912 and batch: 200, loss is 5.143751974105835 and perplexity is 171.35749257710518
At time: 1284.6093354225159 and batch: 250, loss is 5.152775173187256 and perplexity is 172.91068217807782
At time: 1285.682945728302 and batch: 300, loss is 5.172963438034057 and perplexity is 176.4369234067825
At time: 1286.7571687698364 and batch: 350, loss is 5.172953882217407 and perplexity is 176.43523741594765
At time: 1287.831163406372 and batch: 400, loss is 5.202067556381226 and perplexity is 181.6474201730706
At time: 1288.9056251049042 and batch: 450, loss is 5.169032697677612 and perplexity is 175.7447569261455
At time: 1289.9788029193878 and batch: 500, loss is 5.197773208618164 and perplexity is 180.86903550402528
At time: 1291.0518097877502 and batch: 550, loss is 5.177145462036133 and perplexity is 177.1763318896876
At time: 1292.127056837082 and batch: 600, loss is 5.144123973846436 and perplexity is 171.42124937791533
At time: 1293.200156211853 and batch: 650, loss is 5.150726289749145 and perplexity is 172.5567710302431
At time: 1294.2825455665588 and batch: 700, loss is 5.175448169708252 and perplexity is 176.87586692146346
At time: 1295.3565318584442 and batch: 750, loss is 5.155251340866089 and perplexity is 173.33936855124549
At time: 1296.430061340332 and batch: 800, loss is 5.1476898288726805 and perplexity is 172.03360383636956
At time: 1297.5037033557892 and batch: 850, loss is 5.1031727123260495 and perplexity is 164.5431280314323
At time: 1298.5780806541443 and batch: 900, loss is 5.13686674118042 and perplexity is 170.18170874494658
At time: 1299.6508955955505 and batch: 950, loss is 5.116226758956909 and perplexity is 166.70516264560788
At time: 1300.7251484394073 and batch: 1000, loss is 5.131069631576538 and perplexity is 169.19800081303782
At time: 1301.8236520290375 and batch: 1050, loss is 5.10352352142334 and perplexity is 164.6008613837429
At time: 1302.8979218006134 and batch: 1100, loss is 5.106890802383423 and perplexity is 165.15605294869624
At time: 1303.9726717472076 and batch: 1150, loss is 5.111468420028687 and perplexity is 165.91380724240753
At time: 1305.0462851524353 and batch: 1200, loss is 5.090103168487548 and perplexity is 162.40661643419762
At time: 1306.1197972297668 and batch: 1250, loss is 5.102148323059082 and perplexity is 164.37465812123992
At time: 1307.1949210166931 and batch: 1300, loss is 5.089746065139771 and perplexity is 162.34863084180853
At time: 1308.2689034938812 and batch: 1350, loss is 5.070342035293579 and perplexity is 159.2287798928962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171783447265625 and perplexity of 176.22885225111617
Annealing...
Finished 42 epochs...
Completing Train Step...
At time: 1311.4102728366852 and batch: 50, loss is 5.171598243713379 and perplexity is 176.19621706384055
At time: 1312.5175201892853 and batch: 100, loss is 5.1882781887054445 and perplexity is 179.15980782705748
At time: 1313.592745065689 and batch: 150, loss is 5.155314655303955 and perplexity is 173.35034378336698
At time: 1314.672031402588 and batch: 200, loss is 5.143598051071167 and perplexity is 171.33111874165704
At time: 1315.7472558021545 and batch: 250, loss is 5.152608880996704 and perplexity is 172.88193087259367
At time: 1316.821609735489 and batch: 300, loss is 5.172748832702637 and perplexity is 176.39906316501018
At time: 1317.895363330841 and batch: 350, loss is 5.172840337753296 and perplexity is 176.41520530875394
At time: 1318.9684505462646 and batch: 400, loss is 5.202134027481079 and perplexity is 181.65949487817994
At time: 1320.042184829712 and batch: 450, loss is 5.169011373519897 and perplexity is 175.7410093571882
At time: 1321.1163351535797 and batch: 500, loss is 5.197684669494629 and perplexity is 180.85302222705835
At time: 1322.1895492076874 and batch: 550, loss is 5.176977672576904 and perplexity is 177.14660606268163
At time: 1323.2637798786163 and batch: 600, loss is 5.143819351196289 and perplexity is 171.36903853534463
At time: 1324.3376846313477 and batch: 650, loss is 5.150511226654053 and perplexity is 172.51966442725964
At time: 1325.4115555286407 and batch: 700, loss is 5.175131692886352 and perplexity is 176.81989866602427
At time: 1326.486011505127 and batch: 750, loss is 5.155082845687867 and perplexity is 173.3101641639168
At time: 1327.55916762352 and batch: 800, loss is 5.147506599426269 and perplexity is 172.00208510204283
At time: 1328.6598136425018 and batch: 850, loss is 5.102685899734497 and perplexity is 164.46304585893964
At time: 1329.7327444553375 and batch: 900, loss is 5.136296653747559 and perplexity is 170.08471794073444
At time: 1330.8059587478638 and batch: 950, loss is 5.115803365707397 and perplexity is 166.63459574491384
At time: 1331.8810360431671 and batch: 1000, loss is 5.13059247970581 and perplexity is 169.11728692834842
At time: 1332.9546558856964 and batch: 1050, loss is 5.1030138492584225 and perplexity is 164.51699028157282
At time: 1334.0291180610657 and batch: 1100, loss is 5.106360292434692 and perplexity is 165.06845925623088
At time: 1335.10227060318 and batch: 1150, loss is 5.110959796905518 and perplexity is 165.82944110069505
At time: 1336.1749346256256 and batch: 1200, loss is 5.089554100036621 and perplexity is 162.3174685612737
At time: 1337.2508282661438 and batch: 1250, loss is 5.101658811569214 and perplexity is 164.29421452808432
At time: 1338.3236894607544 and batch: 1300, loss is 5.089131870269775 and perplexity is 162.24894776114678
At time: 1339.3977897167206 and batch: 1350, loss is 5.0699030208587645 and perplexity is 159.158891502214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172389322916667 and perplexity of 176.3356573737505
Annealing...
Finished 43 epochs...
Completing Train Step...
At time: 1342.5640187263489 and batch: 50, loss is 5.171471214294433 and perplexity is 176.17383638229913
At time: 1343.644863128662 and batch: 100, loss is 5.188200254440307 and perplexity is 179.1458456831641
At time: 1344.7198812961578 and batch: 150, loss is 5.155211696624756 and perplexity is 173.33249677970005
At time: 1345.7939896583557 and batch: 200, loss is 5.1435067749023435 and perplexity is 171.3154810072252
At time: 1346.868441104889 and batch: 250, loss is 5.152566814422608 and perplexity is 172.87465847500224
At time: 1347.943529367447 and batch: 300, loss is 5.172672548294067 and perplexity is 176.38560718005186
At time: 1349.018375635147 and batch: 350, loss is 5.172781763076782 and perplexity is 176.40487214780447
At time: 1350.0935938358307 and batch: 400, loss is 5.202156257629395 and perplexity is 181.66353324058062
At time: 1351.1680972576141 and batch: 450, loss is 5.1689725112915035 and perplexity is 175.73417980265117
At time: 1352.2420103549957 and batch: 500, loss is 5.19764121055603 and perplexity is 180.84516271745417
At time: 1353.3183557987213 and batch: 550, loss is 5.176893682479858 and perplexity is 177.1317281268554
At time: 1354.3920891284943 and batch: 600, loss is 5.143649635314941 and perplexity is 171.33995695580666
At time: 1355.5023872852325 and batch: 650, loss is 5.150419082641601 and perplexity is 172.5037685055208
At time: 1356.5770614147186 and batch: 700, loss is 5.175005521774292 and perplexity is 176.7975905101272
At time: 1357.6507992744446 and batch: 750, loss is 5.155018892288208 and perplexity is 173.29908074413808
At time: 1358.7260944843292 and batch: 800, loss is 5.147394475936889 and perplexity is 171.98280070921743
At time: 1359.8004925251007 and batch: 850, loss is 5.102469367980957 and perplexity is 164.42743824245625
At time: 1360.8751482963562 and batch: 900, loss is 5.136038942337036 and perplexity is 170.04089081578323
At time: 1361.9503231048584 and batch: 950, loss is 5.115605945587158 and perplexity is 166.60170197003922
At time: 1363.0291256904602 and batch: 1000, loss is 5.130390386581421 and perplexity is 169.08311294072516
At time: 1364.109121799469 and batch: 1050, loss is 5.102792978286743 and perplexity is 164.48065726667343
At time: 1365.1914641857147 and batch: 1100, loss is 5.106119298934937 and perplexity is 165.0286836235625
At time: 1366.2720940113068 and batch: 1150, loss is 5.110750284194946 and perplexity is 165.7947013643327
At time: 1367.3526558876038 and batch: 1200, loss is 5.089328632354737 and perplexity is 162.28087534335683
At time: 1368.4333457946777 and batch: 1250, loss is 5.101435194015503 and perplexity is 164.25747956518697
At time: 1369.513928413391 and batch: 1300, loss is 5.0888840866088865 and perplexity is 162.20875010326222
At time: 1370.5937113761902 and batch: 1350, loss is 5.069716272354126 and perplexity is 159.1291715923867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1726611328125 and perplexity of 176.38359366489703
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 1373.8025074005127 and batch: 50, loss is 5.171409454345703 and perplexity is 176.16295623117878
At time: 1374.879629611969 and batch: 100, loss is 5.188157215118408 and perplexity is 179.1381355333658
At time: 1375.955084323883 and batch: 150, loss is 5.155170965194702 and perplexity is 173.32543684301308
At time: 1377.0298566818237 and batch: 200, loss is 5.1434712314605715 and perplexity is 171.30939197361462
At time: 1378.1067037582397 and batch: 250, loss is 5.1525436210632325 and perplexity is 172.87064897741837
At time: 1379.181629896164 and batch: 300, loss is 5.172629146575928 and perplexity is 176.37795190777237
At time: 1380.2581207752228 and batch: 350, loss is 5.172740478515625 and perplexity is 176.39758950040334
At time: 1381.3330550193787 and batch: 400, loss is 5.202123527526855 and perplexity is 181.65758747181332
At time: 1382.4081401824951 and batch: 450, loss is 5.168928470611572 and perplexity is 175.72644052030836
At time: 1383.5104322433472 and batch: 500, loss is 5.197610502243042 and perplexity is 180.83960935286265
At time: 1384.5856020450592 and batch: 550, loss is 5.176848669052124 and perplexity is 177.1237550000621
At time: 1385.6605534553528 and batch: 600, loss is 5.143574934005738 and perplexity is 171.32715811475427
At time: 1386.7371690273285 and batch: 650, loss is 5.150375213623047 and perplexity is 172.496201100488
At time: 1387.8121755123138 and batch: 700, loss is 5.174956846237182 and perplexity is 176.78898500189004
At time: 1388.8887581825256 and batch: 750, loss is 5.154991874694824 and perplexity is 173.29439868329
At time: 1389.9653992652893 and batch: 800, loss is 5.147330169677734 and perplexity is 171.971741494257
At time: 1391.040501832962 and batch: 850, loss is 5.102376308441162 and perplexity is 164.41213741267885
At time: 1392.116685628891 and batch: 900, loss is 5.135931749343872 and perplexity is 170.02266460061506
At time: 1393.192406654358 and batch: 950, loss is 5.115517292022705 and perplexity is 166.58693278999553
At time: 1394.268114566803 and batch: 1000, loss is 5.1303048419952395 and perplexity is 169.06864941444533
At time: 1395.3442203998566 and batch: 1050, loss is 5.102698574066162 and perplexity is 164.4651303313391
At time: 1396.4209773540497 and batch: 1100, loss is 5.106021995544434 and perplexity is 165.01262655433194
At time: 1397.4957857131958 and batch: 1150, loss is 5.110664100646972 and perplexity is 165.78041320444487
At time: 1398.570654630661 and batch: 1200, loss is 5.089228839874267 and perplexity is 162.26468174028693
At time: 1399.6453337669373 and batch: 1250, loss is 5.101327753067016 and perplexity is 164.23983253381036
At time: 1400.7199573516846 and batch: 1300, loss is 5.088778896331787 and perplexity is 162.19168821727888
At time: 1401.7949736118317 and batch: 1350, loss is 5.069640274047852 and perplexity is 159.11707850439984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172746988932292 and perplexity of 176.3987379259484
Annealing...
Model not improving. Stopping early with 176.14311070257799loss at 44 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
SETTINGS FOR THIS RUN
{'dropout': 0.0, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 8.0, 'wordvec_dim': 200, 'lr': 12.46522061517186, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7432138919830322 and batch: 50, loss is 6.943029127120972 and perplexity is 1035.9033501649758
At time: 2.8129918575286865 and batch: 100, loss is 5.920387229919434 and perplexity is 372.5559507587585
At time: 3.910341262817383 and batch: 150, loss is 5.663203411102295 and perplexity is 288.06997261722205
At time: 4.982407093048096 and batch: 200, loss is 5.572762641906738 and perplexity is 263.16011307696607
At time: 6.057698726654053 and batch: 250, loss is 5.566050615310669 and perplexity is 261.39969001129487
At time: 7.130521774291992 and batch: 300, loss is 5.510803689956665 and perplexity is 247.34983978723898
At time: 8.203370332717896 and batch: 350, loss is 5.501110687255859 and perplexity is 244.96385946007857
At time: 9.278712749481201 and batch: 400, loss is 5.5112627983093265 and perplexity is 247.4634262369635
At time: 10.35143494606018 and batch: 450, loss is 5.464325151443481 and perplexity is 236.1164584794424
At time: 11.425128698348999 and batch: 500, loss is 5.486097640991211 and perplexity is 241.31367446277338
At time: 12.498354196548462 and batch: 550, loss is 5.448724746704102 and perplexity is 232.4615294729375
At time: 13.571285486221313 and batch: 600, loss is 5.390438604354858 and perplexity is 219.29955020103304
At time: 14.645395517349243 and batch: 650, loss is 5.410268144607544 and perplexity is 223.69156132530443
At time: 15.718687772750854 and batch: 700, loss is 5.415060873031616 and perplexity is 224.76622746385632
At time: 16.79218292236328 and batch: 750, loss is 5.374451513290405 and perplexity is 215.82146463606654
At time: 17.866631507873535 and batch: 800, loss is 5.31478910446167 and perplexity is 203.32162898257064
At time: 18.939793825149536 and batch: 850, loss is 5.316852445602417 and perplexity is 203.74158397066407
At time: 20.012449264526367 and batch: 900, loss is 5.359871072769165 and perplexity is 212.6975221791771
At time: 21.086533308029175 and batch: 950, loss is 5.316624011993408 and perplexity is 203.69504786074054
At time: 22.160702228546143 and batch: 1000, loss is 5.3394359111785885 and perplexity is 208.39512376783907
At time: 23.233861446380615 and batch: 1050, loss is 5.284457445144653 and perplexity is 197.24713701961014
At time: 24.30867648124695 and batch: 1100, loss is 5.27089768409729 and perplexity is 194.59056492034676
At time: 25.382270097732544 and batch: 1150, loss is 5.277635507583618 and perplexity is 195.90610877307208
At time: 26.456247091293335 and batch: 1200, loss is 5.256010036468506 and perplexity is 191.7150272650802
At time: 27.53841280937195 and batch: 1250, loss is 5.2942898654937744 and perplexity is 199.19611969017438
At time: 28.611010789871216 and batch: 1300, loss is 5.255313110351563 and perplexity is 191.58146260332524
At time: 29.683770895004272 and batch: 1350, loss is 5.234375114440918 and perplexity is 187.61183378140663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.086381022135416 and perplexity of 161.80323886570076
Finished 1 epochs...
Completing Train Step...
At time: 32.94428873062134 and batch: 50, loss is 5.285418510437012 and perplexity is 197.43679551951945
At time: 34.01775670051575 and batch: 100, loss is 5.281868619918823 and perplexity is 196.73715906229458
At time: 35.115004777908325 and batch: 150, loss is 5.211530809402466 and perplexity is 183.3745549382879
At time: 36.18710541725159 and batch: 200, loss is 5.193920764923096 and perplexity is 180.17358817451756
At time: 37.2590606212616 and batch: 250, loss is 5.216637525558472 and perplexity is 184.3133918872078
At time: 38.33330488204956 and batch: 300, loss is 5.197099695205688 and perplexity is 180.74725879643805
At time: 39.40638279914856 and batch: 350, loss is 5.1912547302246095 and perplexity is 179.69387888164093
At time: 40.480371713638306 and batch: 400, loss is 5.214980430603028 and perplexity is 184.00822001450868
At time: 41.55421590805054 and batch: 450, loss is 5.192125787734986 and perplexity is 179.8504707747806
At time: 42.627132177352905 and batch: 500, loss is 5.234512510299683 and perplexity is 187.63761264133726
At time: 43.70841455459595 and batch: 550, loss is 5.212944889068604 and perplexity is 183.63404459399604
At time: 44.78236532211304 and batch: 600, loss is 5.16413592338562 and perplexity is 174.88627812235706
At time: 45.855470180511475 and batch: 650, loss is 5.174808797836303 and perplexity is 176.76281361273143
At time: 46.92878818511963 and batch: 700, loss is 5.194081535339356 and perplexity is 180.20255708589698
At time: 48.00189208984375 and batch: 750, loss is 5.153556270599365 and perplexity is 173.0457950257315
At time: 49.07718014717102 and batch: 800, loss is 5.107508449554444 and perplexity is 165.25809262659226
At time: 50.1495463848114 and batch: 850, loss is 5.106367988586426 and perplexity is 165.06972965302833
At time: 51.22219491004944 and batch: 900, loss is 5.1527024936676025 and perplexity is 172.8981155694273
At time: 52.297141790390015 and batch: 950, loss is 5.108129138946533 and perplexity is 165.36069841150956
At time: 53.37025189399719 and batch: 1000, loss is 5.120751476287841 and perplexity is 167.46116544386055
At time: 54.45268511772156 and batch: 1050, loss is 5.06806939125061 and perplexity is 158.86732044470975
At time: 55.52659726142883 and batch: 1100, loss is 5.0548789691925045 and perplexity is 156.78555331366752
At time: 56.599506855010986 and batch: 1150, loss is 5.083430881500244 and perplexity is 161.32659997739236
At time: 57.672879457473755 and batch: 1200, loss is 5.061470937728882 and perplexity is 157.82249272913825
At time: 58.74604916572571 and batch: 1250, loss is 5.108163976669312 and perplexity is 165.36645930202687
At time: 59.82070207595825 and batch: 1300, loss is 5.080637941360473 and perplexity is 160.87665307057588
At time: 60.895052433013916 and batch: 1350, loss is 5.042748336791992 and perplexity is 154.8951345696978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.02178955078125 and perplexity of 151.68250460248026
Finished 2 epochs...
Completing Train Step...
At time: 64.06440901756287 and batch: 50, loss is 5.107836627960205 and perplexity is 165.31233566417964
At time: 65.16250085830688 and batch: 100, loss is 5.119747829437256 and perplexity is 167.29317788676005
At time: 66.23877382278442 and batch: 150, loss is 5.065651330947876 and perplexity is 158.48363375946366
At time: 67.31226205825806 and batch: 200, loss is 5.044882946014404 and perplexity is 155.2261282979068
At time: 68.38553166389465 and batch: 250, loss is 5.0696784782409665 and perplexity is 159.12315756011688
At time: 69.46079206466675 and batch: 300, loss is 5.069514303207398 and perplexity is 159.09703565472387
At time: 70.53303718566895 and batch: 350, loss is 5.06380539894104 and perplexity is 158.1913535949971
At time: 71.60630655288696 and batch: 400, loss is 5.081188077926636 and perplexity is 160.9651815492157
At time: 72.6856632232666 and batch: 450, loss is 5.047337875366211 and perplexity is 155.607665608387
At time: 73.7589819431305 and batch: 500, loss is 5.08921064376831 and perplexity is 162.2617291818075
At time: 74.83213543891907 and batch: 550, loss is 5.078477506637573 and perplexity is 160.5294647370849
At time: 75.90608787536621 and batch: 600, loss is 5.037783317565918 and perplexity is 154.12798328491948
At time: 76.98105478286743 and batch: 650, loss is 5.047040739059448 and perplexity is 155.56143578994303
At time: 78.05366563796997 and batch: 700, loss is 5.054805908203125 and perplexity is 156.7740988244653
At time: 79.12674474716187 and batch: 750, loss is 5.017492799758911 and perplexity is 151.0321608289529
At time: 80.20170664787292 and batch: 800, loss is 4.978409605026245 and perplexity is 145.24320380898664
At time: 81.2750186920166 and batch: 850, loss is 4.966979064941406 and perplexity is 143.59244803438474
At time: 82.34929943084717 and batch: 900, loss is 5.01530725479126 and perplexity is 150.70243369788375
At time: 83.42464089393616 and batch: 950, loss is 4.975275030136109 and perplexity is 144.78864091227953
At time: 84.49796152114868 and batch: 1000, loss is 4.992943983078003 and perplexity is 147.36963921699345
At time: 85.60370969772339 and batch: 1050, loss is 4.943625278472901 and perplexity is 140.27787522311735
At time: 86.67879462242126 and batch: 1100, loss is 4.934940032958984 and perplexity is 139.06480297728774
At time: 87.75220608711243 and batch: 1150, loss is 4.954281482696533 and perplexity is 141.78069788111023
At time: 88.82633900642395 and batch: 1200, loss is 4.930570411682129 and perplexity is 138.45846814688315
At time: 89.90091848373413 and batch: 1250, loss is 4.990362892150879 and perplexity is 146.9897552467112
At time: 90.97427654266357 and batch: 1300, loss is 4.953838090896607 and perplexity is 141.7178474170018
At time: 92.04938077926636 and batch: 1350, loss is 4.92914740562439 and perplexity is 138.26158102697082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0103377278645835 and perplexity of 149.95537170551518
Finished 3 epochs...
Completing Train Step...
At time: 95.23749995231628 and batch: 50, loss is 4.994681310653687 and perplexity is 147.62589108729003
At time: 96.31128787994385 and batch: 100, loss is 5.021134195327758 and perplexity is 151.58313121189315
At time: 97.38450765609741 and batch: 150, loss is 4.971553678512573 and perplexity is 144.2508327755934
At time: 98.45930457115173 and batch: 200, loss is 4.957123651504516 and perplexity is 142.1842357479253
At time: 99.53314423561096 and batch: 250, loss is 4.970197687149048 and perplexity is 144.05536245015603
At time: 100.60679411888123 and batch: 300, loss is 4.9728941726684575 and perplexity is 144.44432983577474
At time: 101.68205332756042 and batch: 350, loss is 4.975705842971802 and perplexity is 144.851031155541
At time: 102.7558228969574 and batch: 400, loss is 4.982120323181152 and perplexity is 145.78316159824752
At time: 103.82908034324646 and batch: 450, loss is 4.949173812866211 and perplexity is 141.0583751513745
At time: 104.90404224395752 and batch: 500, loss is 5.004560794830322 and perplexity is 149.09158698055344
At time: 105.9768717288971 and batch: 550, loss is 4.99228440284729 and perplexity is 147.27246916560387
At time: 107.04985904693604 and batch: 600, loss is 4.948693552017212 and perplexity is 140.99064660135315
At time: 108.1245629787445 and batch: 650, loss is 4.970764398574829 and perplexity is 144.13702340691472
At time: 109.20128107070923 and batch: 700, loss is 4.978838958740234 and perplexity is 145.3055779072909
At time: 110.28230905532837 and batch: 750, loss is 4.93984486579895 and perplexity is 139.74856809581865
At time: 111.35774970054626 and batch: 800, loss is 4.9121118259429934 and perplexity is 135.92616391866216
At time: 112.45858383178711 and batch: 850, loss is 4.900958909988403 and perplexity is 134.41861325604293
At time: 113.53305149078369 and batch: 900, loss is 4.947025346755981 and perplexity is 140.75564133591843
At time: 114.60995197296143 and batch: 950, loss is 4.89850001335144 and perplexity is 134.0884978061751
At time: 115.69179248809814 and batch: 1000, loss is 4.911135711669922 and perplexity is 135.79354918407452
At time: 116.76899480819702 and batch: 1050, loss is 4.8643437767028805 and perplexity is 129.58587343486067
At time: 117.84684753417969 and batch: 1100, loss is 4.86528790473938 and perplexity is 129.7082768642672
At time: 118.92123627662659 and batch: 1150, loss is 4.877588930130005 and perplexity is 131.31367545235952
At time: 119.997398853302 and batch: 1200, loss is 4.855443954467773 and perplexity is 128.4376990496659
At time: 121.07288789749146 and batch: 1250, loss is 4.8952701377868655 and perplexity is 133.65610730327512
At time: 122.14789915084839 and batch: 1300, loss is 4.875743293762207 and perplexity is 131.07154167154448
At time: 123.22260618209839 and batch: 1350, loss is 4.854475269317627 and perplexity is 128.31334359824112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.010226236979166 and perplexity of 149.938653980305
Finished 4 epochs...
Completing Train Step...
At time: 126.40226340293884 and batch: 50, loss is 4.924956188201905 and perplexity is 137.68330935736628
At time: 127.47964215278625 and batch: 100, loss is 4.945221576690674 and perplexity is 140.50197936626327
At time: 128.55439925193787 and batch: 150, loss is 4.9005838394165036 and perplexity is 134.3682062435795
At time: 129.62928175926208 and batch: 200, loss is 4.888596134185791 and perplexity is 132.76705602756698
At time: 130.70570969581604 and batch: 250, loss is 4.901034030914307 and perplexity is 134.42871128601135
At time: 131.7823987007141 and batch: 300, loss is 4.900517463684082 and perplexity is 134.3592877514649
At time: 132.85870814323425 and batch: 350, loss is 4.903213787078857 and perplexity is 134.72205268834767
At time: 133.93394017219543 and batch: 400, loss is 4.915762519836425 and perplexity is 136.42329562094304
At time: 135.00933074951172 and batch: 450, loss is 4.8816016578674315 and perplexity is 131.84166010100637
At time: 136.0850315093994 and batch: 500, loss is 4.943058347702026 and perplexity is 140.1983699183118
At time: 137.16502213478088 and batch: 550, loss is 4.925482807159423 and perplexity is 137.7558350932454
At time: 138.248633146286 and batch: 600, loss is 4.874310445785523 and perplexity is 130.88387056245216
At time: 139.33064532279968 and batch: 650, loss is 4.900306262969971 and perplexity is 134.33091397033118
At time: 140.43934512138367 and batch: 700, loss is 4.908999223709106 and perplexity is 135.50373760080458
At time: 141.5226345062256 and batch: 750, loss is 4.858544836044311 and perplexity is 128.8365872773354
At time: 142.60479354858398 and batch: 800, loss is 4.840390176773071 and perplexity is 126.51870676163256
At time: 143.68766045570374 and batch: 850, loss is 4.83206018447876 and perplexity is 125.4691842352502
At time: 144.76952838897705 and batch: 900, loss is 4.869273672103882 and perplexity is 130.2262955462921
At time: 145.85097289085388 and batch: 950, loss is 4.832159614562988 and perplexity is 125.48166026704293
At time: 146.93289971351624 and batch: 1000, loss is 4.844958276748657 and perplexity is 127.09797894218681
At time: 148.01547718048096 and batch: 1050, loss is 4.792890882492065 and perplexity is 120.64964895980728
At time: 149.0979495048523 and batch: 1100, loss is 4.78788200378418 and perplexity is 120.04684045966393
At time: 150.18018341064453 and batch: 1150, loss is 4.801323261260986 and perplexity is 121.67131397759145
At time: 151.26185822486877 and batch: 1200, loss is 4.782026653289795 and perplexity is 119.34597803303598
At time: 152.34566402435303 and batch: 1250, loss is 4.820103101730346 and perplexity is 123.9778724540809
At time: 153.42746686935425 and batch: 1300, loss is 4.794469299316407 and perplexity is 120.84023476793057
At time: 154.5092101097107 and batch: 1350, loss is 4.77062728881836 and perplexity is 117.9932345875695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.019075520833334 and perplexity of 151.2713918808866
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 157.73783349990845 and batch: 50, loss is 4.829527912139892 and perplexity is 125.15186403078458
At time: 158.84218645095825 and batch: 100, loss is 4.835868225097657 and perplexity is 125.94788686629057
At time: 159.9203155040741 and batch: 150, loss is 4.78729281425476 and perplexity is 119.97613095092183
At time: 160.99778246879578 and batch: 200, loss is 4.76087682723999 and perplexity is 116.84833679874794
At time: 162.07446718215942 and batch: 250, loss is 4.755033264160156 and perplexity is 116.1675173150308
At time: 163.15294647216797 and batch: 300, loss is 4.7517924308776855 and perplexity is 115.79164715381877
At time: 164.2297327518463 and batch: 350, loss is 4.731147298812866 and perplexity is 113.42562080653636
At time: 165.3073182106018 and batch: 400, loss is 4.73377121925354 and perplexity is 113.7236314185524
At time: 166.38502287864685 and batch: 450, loss is 4.684715261459351 and perplexity is 108.27943658957655
At time: 167.48826122283936 and batch: 500, loss is 4.72863953590393 and perplexity is 113.14153260356679
At time: 168.5653054714203 and batch: 550, loss is 4.700339212417602 and perplexity is 109.98447422455403
At time: 169.6428027153015 and batch: 600, loss is 4.646577806472778 and perplexity is 104.22768723716622
At time: 170.72044610977173 and batch: 650, loss is 4.646303367614746 and perplexity is 104.19908703438855
At time: 171.797598361969 and batch: 700, loss is 4.639497747421265 and perplexity is 103.49235522543475
At time: 172.87500095367432 and batch: 750, loss is 4.583408536911011 and perplexity is 97.84734273037621
At time: 173.95336508750916 and batch: 800, loss is 4.5598688888549805 and perplexity is 95.57094859209124
At time: 175.02992248535156 and batch: 850, loss is 4.524587831497192 and perplexity is 92.25789219376543
At time: 176.10665273666382 and batch: 900, loss is 4.5432875537872315 and perplexity is 93.99932052507518
At time: 177.18427205085754 and batch: 950, loss is 4.497161703109741 and perplexity is 89.76199819970269
At time: 178.2615978717804 and batch: 1000, loss is 4.491320219039917 and perplexity is 89.23918341093733
At time: 179.33869767189026 and batch: 1050, loss is 4.429418478012085 and perplexity is 83.88262313456042
At time: 180.41617560386658 and batch: 1100, loss is 4.394126224517822 and perplexity is 80.97384688051879
At time: 181.49437403678894 and batch: 1150, loss is 4.386704177856445 and perplexity is 80.37507999716973
At time: 182.57181429862976 and batch: 1200, loss is 4.345653114318847 and perplexity is 77.14240383855383
At time: 183.65017890930176 and batch: 1250, loss is 4.36232102394104 and perplexity is 78.43898206036054
At time: 184.72828078269958 and batch: 1300, loss is 4.303200969696045 and perplexity is 73.93608248069157
At time: 185.81433200836182 and batch: 1350, loss is 4.260606079101563 and perplexity is 70.85291291344012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.808423258463542 and perplexity of 122.53825396032524
Finished 6 epochs...
Completing Train Step...
At time: 189.0108778476715 and batch: 50, loss is 4.647224321365356 and perplexity is 104.2950937765019
At time: 190.11504912376404 and batch: 100, loss is 4.667549324035645 and perplexity is 106.43658098137335
At time: 191.19190430641174 and batch: 150, loss is 4.627206802368164 and perplexity is 102.22812160226772
At time: 192.26790022850037 and batch: 200, loss is 4.611418046951294 and perplexity is 100.62674195584215
At time: 193.3438012599945 and batch: 250, loss is 4.60862455368042 and perplexity is 100.34603408963056
At time: 194.4472804069519 and batch: 300, loss is 4.61573278427124 and perplexity is 101.06185794529827
At time: 195.52338290214539 and batch: 350, loss is 4.603636236190796 and perplexity is 99.84672261023607
At time: 196.60063362121582 and batch: 400, loss is 4.605898656845093 and perplexity is 100.07287362563375
At time: 197.67713856697083 and batch: 450, loss is 4.562678937911987 and perplexity is 95.83988533180683
At time: 198.7534544467926 and batch: 500, loss is 4.613974962234497 and perplexity is 100.88436523033414
At time: 199.83140778541565 and batch: 550, loss is 4.589738712310791 and perplexity is 98.46869814176583
At time: 200.9077718257904 and batch: 600, loss is 4.53917329788208 and perplexity is 93.61337774361606
At time: 201.98528385162354 and batch: 650, loss is 4.545186834335327 and perplexity is 94.17802125377322
At time: 203.06505489349365 and batch: 700, loss is 4.546974620819092 and perplexity is 94.34654204194683
At time: 204.14264798164368 and batch: 750, loss is 4.493109254837036 and perplexity is 89.39897840142366
At time: 205.22047328948975 and batch: 800, loss is 4.474350681304932 and perplexity is 87.73761223812758
At time: 206.29922699928284 and batch: 850, loss is 4.447327013015747 and perplexity is 85.3983699192498
At time: 207.37640237808228 and batch: 900, loss is 4.468652448654175 and perplexity is 87.23908462346431
At time: 208.4612636566162 and batch: 950, loss is 4.429001569747925 and perplexity is 83.84765906466745
At time: 209.54015636444092 and batch: 1000, loss is 4.429321823120117 and perplexity is 83.87451586049349
At time: 210.6189045906067 and batch: 1050, loss is 4.374533319473267 and perplexity is 79.40277517537965
At time: 211.69705390930176 and batch: 1100, loss is 4.348254108428955 and perplexity is 77.34331194371181
At time: 212.7750792503357 and batch: 1150, loss is 4.348316097259522 and perplexity is 77.3481065137747
At time: 213.85310530662537 and batch: 1200, loss is 4.317956876754761 and perplexity is 75.03516548288232
At time: 214.9381766319275 and batch: 1250, loss is 4.343580064773559 and perplexity is 76.98264945993735
At time: 216.01678156852722 and batch: 1300, loss is 4.298457984924316 and perplexity is 73.58623508368683
At time: 217.09920454025269 and batch: 1350, loss is 4.265462999343872 and perplexity is 71.19787691358145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.793831787109375 and perplexity of 120.76322219400173
Finished 7 epochs...
Completing Train Step...
At time: 220.32625341415405 and batch: 50, loss is 4.585031661987305 and perplexity is 98.00629016689955
At time: 221.40317821502686 and batch: 100, loss is 4.6017068672180175 and perplexity is 99.65426716008609
At time: 222.50603365898132 and batch: 150, loss is 4.560381460189819 and perplexity is 95.61994807757593
At time: 223.58739233016968 and batch: 200, loss is 4.54526346206665 and perplexity is 94.18523817838712
At time: 224.6689269542694 and batch: 250, loss is 4.543969345092774 and perplexity is 94.06343029679513
At time: 225.7458097934723 and batch: 300, loss is 4.553125972747803 and perplexity is 94.92868948654524
At time: 226.82551980018616 and batch: 350, loss is 4.54283989906311 and perplexity is 93.95725070225794
At time: 227.90329909324646 and batch: 400, loss is 4.54427698135376 and perplexity is 94.09237207032844
At time: 228.98071336746216 and batch: 450, loss is 4.502896490097046 and perplexity is 90.27824300107267
At time: 230.05831670761108 and batch: 500, loss is 4.558941707611084 and perplexity is 95.48237806790476
At time: 231.1348421573639 and batch: 550, loss is 4.535854406356812 and perplexity is 93.30320010525692
At time: 232.21343231201172 and batch: 600, loss is 4.486203584671021 and perplexity is 88.78374528683578
At time: 233.29003620147705 and batch: 650, loss is 4.495384693145752 and perplexity is 89.60263187422515
At time: 234.36670970916748 and batch: 700, loss is 4.499066390991211 and perplexity is 89.93312971421466
At time: 235.445072889328 and batch: 750, loss is 4.446746196746826 and perplexity is 85.34878355833791
At time: 236.52291011810303 and batch: 800, loss is 4.43248929977417 and perplexity is 84.1406076286105
At time: 237.60113406181335 and batch: 850, loss is 4.408307008743286 and perplexity is 82.1302998564534
At time: 238.68457698822021 and batch: 900, loss is 4.427757196426391 and perplexity is 83.74338616531665
At time: 239.76183700561523 and batch: 950, loss is 4.393524074554444 and perplexity is 80.92510315857308
At time: 240.84016752243042 and batch: 1000, loss is 4.395772285461426 and perplexity is 81.10724452753027
At time: 241.91788148880005 and batch: 1050, loss is 4.3426431369781495 and perplexity is 76.91055605432568
At time: 242.9957399368286 and batch: 1100, loss is 4.319709415435791 and perplexity is 75.16678281137084
At time: 244.07339811325073 and batch: 1150, loss is 4.324863615036011 and perplexity is 75.55520756273619
At time: 245.15699458122253 and batch: 1200, loss is 4.29685489654541 and perplexity is 73.46836434922196
At time: 246.2414801120758 and batch: 1250, loss is 4.327691516876221 and perplexity is 75.76917266680562
At time: 247.3199439048767 and batch: 1300, loss is 4.288583526611328 and perplexity is 72.86318660403472
At time: 248.3971450328827 and batch: 1350, loss is 4.257611427307129 and perplexity is 70.64105049605797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7875358072916665 and perplexity of 120.00528785765704
Finished 8 epochs...
Completing Train Step...
At time: 251.6273422241211 and batch: 50, loss is 4.540578060150146 and perplexity is 93.74497469403116
At time: 252.70363664627075 and batch: 100, loss is 4.553432302474976 and perplexity is 94.95777342050587
At time: 253.7826051712036 and batch: 150, loss is 4.5137184143066404 and perplexity is 91.26053285111746
At time: 254.85971975326538 and batch: 200, loss is 4.497958374023438 and perplexity is 89.83353746566611
At time: 255.93812155723572 and batch: 250, loss is 4.499042558670044 and perplexity is 89.93098642452362
At time: 257.0152020454407 and batch: 300, loss is 4.509106035232544 and perplexity is 90.84057392849576
At time: 258.09254789352417 and batch: 350, loss is 4.501472606658935 and perplexity is 90.1497887796637
At time: 259.1714859008789 and batch: 400, loss is 4.502127056121826 and perplexity is 90.20880657048455
At time: 260.2561001777649 and batch: 450, loss is 4.4620836734771725 and perplexity is 86.66790870681196
At time: 261.3336443901062 and batch: 500, loss is 4.521246767044067 and perplexity is 91.95016698077573
At time: 262.4123742580414 and batch: 550, loss is 4.497769756317139 and perplexity is 89.8165948677678
At time: 263.49082016944885 and batch: 600, loss is 4.447909498214722 and perplexity is 85.44812769592171
At time: 264.5680103302002 and batch: 650, loss is 4.459245681762695 and perplexity is 86.42229459025684
At time: 265.6466341018677 and batch: 700, loss is 4.464079599380494 and perplexity is 86.84106417604615
At time: 266.7234356403351 and batch: 750, loss is 4.414031181335449 and perplexity is 82.601775985876
At time: 267.8015284538269 and batch: 800, loss is 4.3999169731140135 and perplexity is 81.4441063337135
At time: 268.87861251831055 and batch: 850, loss is 4.379138040542602 and perplexity is 79.76924590740701
At time: 269.95598316192627 and batch: 900, loss is 4.399574909210205 and perplexity is 81.41625200900994
At time: 271.0501880645752 and batch: 950, loss is 4.367636203765869 and perplexity is 78.85700931616108
At time: 272.1303298473358 and batch: 1000, loss is 4.369602451324463 and perplexity is 79.01221425386838
At time: 273.2094442844391 and batch: 1050, loss is 4.318162431716919 and perplexity is 75.05059091881682
At time: 274.28667163848877 and batch: 1100, loss is 4.298483142852783 and perplexity is 73.58808638421254
At time: 275.3667106628418 and batch: 1150, loss is 4.3051777172088626 and perplexity is 74.08237999682986
At time: 276.4933080673218 and batch: 1200, loss is 4.278418827056885 and perplexity is 72.12630563505671
At time: 277.57088232040405 and batch: 1250, loss is 4.31143012046814 and perplexity is 74.54702396804171
At time: 278.64868211746216 and batch: 1300, loss is 4.276081886291504 and perplexity is 71.95794752924321
At time: 279.7258460521698 and batch: 1350, loss is 4.246067714691162 and perplexity is 69.83027916925167
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.783939208984375 and perplexity of 119.5744522781635
Finished 9 epochs...
Completing Train Step...
At time: 282.94627237319946 and batch: 50, loss is 4.5061612319946285 and perplexity is 90.57345980455702
At time: 284.0672812461853 and batch: 100, loss is 4.517012386322022 and perplexity is 91.56163813637386
At time: 285.14533400535583 and batch: 150, loss is 4.478923864364624 and perplexity is 88.13977127265882
At time: 286.222199678421 and batch: 200, loss is 4.462890501022339 and perplexity is 86.73786297956082
At time: 287.2990255355835 and batch: 250, loss is 4.464410123825073 and perplexity is 86.86977201460945
At time: 288.37818598747253 and batch: 300, loss is 4.476072158813476 and perplexity is 87.88878064342168
At time: 289.4559452533722 and batch: 350, loss is 4.468485937118531 and perplexity is 87.22455951884776
At time: 290.53704810142517 and batch: 400, loss is 4.469464826583862 and perplexity is 87.30998452527702
At time: 291.62208318710327 and batch: 450, loss is 4.4299234199523925 and perplexity is 83.92498968446785
At time: 292.6971900463104 and batch: 500, loss is 4.490571327209473 and perplexity is 89.17237793368572
At time: 293.7740652561188 and batch: 550, loss is 4.468280172348022 and perplexity is 87.20661362375547
At time: 294.85079169273376 and batch: 600, loss is 4.418821973800659 and perplexity is 82.99845339274685
At time: 295.92600536346436 and batch: 650, loss is 4.42899561882019 and perplexity is 83.84716009479232
At time: 297.00326323509216 and batch: 700, loss is 4.436191167831421 and perplexity is 84.45266229254291
At time: 298.08010172843933 and batch: 750, loss is 4.386730098724366 and perplexity is 80.37716341600434
At time: 299.1578073501587 and batch: 800, loss is 4.374296951293945 and perplexity is 79.38400910391678
At time: 300.2361102104187 and batch: 850, loss is 4.355552339553833 and perplexity is 77.90984614434612
At time: 301.3134047985077 and batch: 900, loss is 4.375512943267823 and perplexity is 79.4805981356834
At time: 302.39118814468384 and batch: 950, loss is 4.344774761199951 and perplexity is 77.07467531667672
At time: 303.4677541255951 and batch: 1000, loss is 4.348282232284546 and perplexity is 77.34548716643546
At time: 304.5897078514099 and batch: 1050, loss is 4.297298002243042 and perplexity is 73.50092581361321
At time: 305.66890048980713 and batch: 1100, loss is 4.2795067977905275 and perplexity is 72.20481964744263
At time: 306.75042033195496 and batch: 1150, loss is 4.286946897506714 and perplexity is 72.74403412298918
At time: 307.82719016075134 and batch: 1200, loss is 4.26124077796936 and perplexity is 70.89789745135391
At time: 308.9056797027588 and batch: 1250, loss is 4.295694017410279 and perplexity is 73.38312594327276
At time: 309.98222517967224 and batch: 1300, loss is 4.263094301223755 and perplexity is 71.02943021482835
At time: 311.06557393074036 and batch: 1350, loss is 4.234695339202881 and perplexity is 69.0406415521898
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7834989420572915 and perplexity of 119.52181918865578
Finished 10 epochs...
Completing Train Step...
At time: 314.23927330970764 and batch: 50, loss is 4.476386432647705 and perplexity is 87.9164061282563
At time: 315.34310507774353 and batch: 100, loss is 4.485734624862671 and perplexity is 88.74211903994275
At time: 316.4198224544525 and batch: 150, loss is 4.449266834259033 and perplexity is 85.56418826834263
At time: 317.49706268310547 and batch: 200, loss is 4.433498420715332 and perplexity is 84.22555853343015
At time: 318.57482719421387 and batch: 250, loss is 4.435691881179809 and perplexity is 84.4105067302977
At time: 319.65286207199097 and batch: 300, loss is 4.446621246337891 and perplexity is 85.33811985916084
At time: 320.7298963069916 and batch: 350, loss is 4.4408274841308595 and perplexity is 84.84512062473726
At time: 321.80863070487976 and batch: 400, loss is 4.441274242401123 and perplexity is 84.883034352573
At time: 322.88557744026184 and batch: 450, loss is 4.403095464706421 and perplexity is 81.70338758429487
At time: 323.9612567424774 and batch: 500, loss is 4.464172620773315 and perplexity is 86.84914262851852
At time: 325.04712176322937 and batch: 550, loss is 4.442988128662109 and perplexity is 85.02863895816556
At time: 326.12274527549744 and batch: 600, loss is 4.393331718444824 and perplexity is 80.90953821761269
At time: 327.19854044914246 and batch: 650, loss is 4.403609809875488 and perplexity is 81.74542213620289
At time: 328.27387022972107 and batch: 700, loss is 4.411014299392701 and perplexity is 82.3529517049297
At time: 329.3486406803131 and batch: 750, loss is 4.362714109420776 and perplexity is 78.46982134609436
At time: 330.4235677719116 and batch: 800, loss is 4.3523468399047855 and perplexity is 77.66050600324265
At time: 331.5480623245239 and batch: 850, loss is 4.333598957061768 and perplexity is 76.21809922007691
At time: 332.6228573322296 and batch: 900, loss is 4.35359377861023 and perplexity is 77.75740429462222
At time: 333.6995871067047 and batch: 950, loss is 4.32544246673584 and perplexity is 75.59895548362243
At time: 334.77426958084106 and batch: 1000, loss is 4.328868675231933 and perplexity is 75.85841749886012
At time: 335.84927439689636 and batch: 1050, loss is 4.279910316467285 and perplexity is 72.2339615199718
At time: 336.9253478050232 and batch: 1100, loss is 4.261715688705444 and perplexity is 70.93157562044843
At time: 338.0002999305725 and batch: 1150, loss is 4.270457925796509 and perplexity is 71.55439472122428
At time: 339.0748460292816 and batch: 1200, loss is 4.245596218109131 and perplexity is 69.797362192032
At time: 340.153333902359 and batch: 1250, loss is 4.280207042694092 and perplexity is 72.25539841110752
At time: 341.23064708709717 and batch: 1300, loss is 4.250254507064819 and perplexity is 70.12325694010339
At time: 342.3090343475342 and batch: 1350, loss is 4.2216237449645995 and perplexity is 68.1440430522849
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.783890787760416 and perplexity of 119.56866247700579
Annealing...
Finished 11 epochs...
Completing Train Step...
At time: 345.5431115627289 and batch: 50, loss is 4.459247131347656 and perplexity is 86.42241986680614
At time: 346.6206843852997 and batch: 100, loss is 4.4752505493164065 and perplexity is 87.81660004275307
At time: 347.69761633872986 and batch: 150, loss is 4.442803373336792 and perplexity is 85.01293091543054
At time: 348.77452635765076 and batch: 200, loss is 4.431765766143799 and perplexity is 84.07975108784309
At time: 349.8519892692566 and batch: 250, loss is 4.427655620574951 and perplexity is 83.73488029156742
At time: 350.9281995296478 and batch: 300, loss is 4.439592895507812 and perplexity is 84.74043643834236
At time: 352.0042805671692 and batch: 350, loss is 4.430359697341919 and perplexity is 83.96161224810074
At time: 353.081670999527 and batch: 400, loss is 4.425114393234253 and perplexity is 83.52236106859817
At time: 354.15870428085327 and batch: 450, loss is 4.383644332885742 and perplexity is 80.12952059131763
At time: 355.235488653183 and batch: 500, loss is 4.437065553665161 and perplexity is 84.52653879765109
At time: 356.3127644062042 and batch: 550, loss is 4.4147922229766845 and perplexity is 82.66466330393982
At time: 357.3892123699188 and batch: 600, loss is 4.367313508987427 and perplexity is 78.83156667633547
At time: 358.491112947464 and batch: 650, loss is 4.3698521327972415 and perplexity is 79.0319446029396
At time: 359.56875920295715 and batch: 700, loss is 4.372068967819214 and perplexity is 79.20733972478484
At time: 360.6447808742523 and batch: 750, loss is 4.320768394470215 and perplexity is 75.24642502072534
At time: 361.7220687866211 and batch: 800, loss is 4.305896663665772 and perplexity is 74.13566041203586
At time: 362.799170255661 and batch: 850, loss is 4.276016283035278 and perplexity is 71.95322700841645
At time: 363.8814558982849 and batch: 900, loss is 4.284922924041748 and perplexity is 72.59695102454398
At time: 364.95883536338806 and batch: 950, loss is 4.258436393737793 and perplexity is 70.69935103603179
At time: 366.0459406375885 and batch: 1000, loss is 4.257046937942505 and perplexity is 70.60118562705293
At time: 367.12358808517456 and batch: 1050, loss is 4.205076131820679 and perplexity is 67.02570026066046
At time: 368.2006015777588 and batch: 1100, loss is 4.177261896133423 and perplexity is 65.18711952595075
At time: 369.277370929718 and batch: 1150, loss is 4.17812349319458 and perplexity is 65.24330875932273
At time: 370.3539307117462 and batch: 1200, loss is 4.147687296867371 and perplexity is 63.287465797630645
At time: 371.43139362335205 and batch: 1250, loss is 4.174738893508911 and perplexity is 65.0228595536067
At time: 372.5078752040863 and batch: 1300, loss is 4.142356028556824 and perplexity is 62.95096113212144
At time: 373.58526134490967 and batch: 1350, loss is 4.114674062728882 and perplexity is 61.23225313639944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.748402913411458 and perplexity of 115.39983374766251
Finished 12 epochs...
Completing Train Step...
At time: 376.8281059265137 and batch: 50, loss is 4.436988592147827 and perplexity is 84.52003375729231
At time: 377.9052686691284 and batch: 100, loss is 4.4482403755187985 and perplexity is 85.4764052199896
At time: 378.98367261886597 and batch: 150, loss is 4.4155641746521 and perplexity is 82.72850106593847
At time: 380.0600173473358 and batch: 200, loss is 4.405425243377685 and perplexity is 81.8939603039873
At time: 381.1370611190796 and batch: 250, loss is 4.401627616882324 and perplexity is 81.5835474196874
At time: 382.2155866622925 and batch: 300, loss is 4.413537874221801 and perplexity is 82.56103799117965
At time: 383.2958195209503 and batch: 350, loss is 4.406677713394165 and perplexity is 81.99659429337937
At time: 384.3728630542755 and batch: 400, loss is 4.402205591201782 and perplexity is 81.6307142442799
At time: 385.4509000778198 and batch: 450, loss is 4.361490917205811 and perplexity is 78.37389635082808
At time: 386.55389618873596 and batch: 500, loss is 4.417491016387939 and perplexity is 82.88805946706276
At time: 387.63148021698 and batch: 550, loss is 4.396615839004516 and perplexity is 81.17569169638884
At time: 388.7085630893707 and batch: 600, loss is 4.348789319992066 and perplexity is 77.38471805812054
At time: 389.7854323387146 and batch: 650, loss is 4.352815914154053 and perplexity is 77.69694309197573
At time: 390.86413860321045 and batch: 700, loss is 4.356473073959351 and perplexity is 77.98161345446553
At time: 391.9404616355896 and batch: 750, loss is 4.306940450668335 and perplexity is 74.21308264993394
At time: 393.01713013648987 and batch: 800, loss is 4.293565177917481 and perplexity is 73.22707121333194
At time: 394.0949294567108 and batch: 850, loss is 4.265752649307251 and perplexity is 71.21850236295823
At time: 395.1739721298218 and batch: 900, loss is 4.276524000167846 and perplexity is 71.98976817001413
At time: 396.2534317970276 and batch: 950, loss is 4.251214513778686 and perplexity is 70.19060806115567
At time: 397.3317985534668 and batch: 1000, loss is 4.251550750732422 and perplexity is 70.21421270554548
At time: 398.4091019630432 and batch: 1050, loss is 4.201659288406372 and perplexity is 66.79707474935192
At time: 399.48619389533997 and batch: 1100, loss is 4.175932259559631 and perplexity is 65.10050194540159
At time: 400.5643243789673 and batch: 1150, loss is 4.1788228368759155 and perplexity is 65.28895221342334
At time: 401.6414363384247 and batch: 1200, loss is 4.151606297492981 and perplexity is 63.53597605354565
At time: 402.7192316055298 and batch: 1250, loss is 4.180600414276123 and perplexity is 65.40511158991586
At time: 403.80374002456665 and batch: 1300, loss is 4.149925556182861 and perplexity is 63.42927820477225
At time: 404.88125014305115 and batch: 1350, loss is 4.123853716850281 and perplexity is 61.796931853657796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7452197265625 and perplexity of 115.0330785493513
Finished 13 epochs...
Completing Train Step...
At time: 408.0856592655182 and batch: 50, loss is 4.428495140075683 and perplexity is 83.80520687260129
At time: 409.1898946762085 and batch: 100, loss is 4.437278881072998 and perplexity is 84.54457254854444
At time: 410.2678892612457 and batch: 150, loss is 4.403825635910034 and perplexity is 81.76306683052857
At time: 411.34595131874084 and batch: 200, loss is 4.393732194900513 and perplexity is 80.94194707176783
At time: 412.4231114387512 and batch: 250, loss is 4.389895582199097 and perplexity is 80.63199912486222
At time: 413.52741169929504 and batch: 300, loss is 4.401469383239746 and perplexity is 81.57063917909065
At time: 414.6114091873169 and batch: 350, loss is 4.3951924037933345 and perplexity is 81.06022555731634
At time: 415.6936457157135 and batch: 400, loss is 4.39101095199585 and perplexity is 80.72198379510078
At time: 416.77198028564453 and batch: 450, loss is 4.350714712142945 and perplexity is 77.5338575167658
At time: 417.8515923023224 and batch: 500, loss is 4.40739818572998 and perplexity is 82.05569185772256
At time: 418.9294481277466 and batch: 550, loss is 4.3870335292816165 and perplexity is 80.40155600403104
At time: 420.0050754547119 and batch: 600, loss is 4.33972900390625 and perplexity is 76.6867547111773
At time: 421.0806531906128 and batch: 650, loss is 4.34403431892395 and perplexity is 77.01762709172837
At time: 422.1582922935486 and batch: 700, loss is 4.348612270355225 and perplexity is 77.37101833469261
At time: 423.234911441803 and batch: 750, loss is 4.299995574951172 and perplexity is 73.69946757513162
At time: 424.31438970565796 and batch: 800, loss is 4.287277631759643 and perplexity is 72.76809704576698
At time: 425.3977994918823 and batch: 850, loss is 4.260583944320679 and perplexity is 70.85134461709481
At time: 426.4737949371338 and batch: 900, loss is 4.272348127365112 and perplexity is 71.68977485793229
At time: 427.54978013038635 and batch: 950, loss is 4.247812118530273 and perplexity is 69.95219768296646
At time: 428.6267600059509 and batch: 1000, loss is 4.248853940963745 and perplexity is 70.02511342781737
At time: 429.7024586200714 and batch: 1050, loss is 4.199828758239746 and perplexity is 66.67491253390332
At time: 430.7789816856384 and batch: 1100, loss is 4.175537919998169 and perplexity is 65.0748353030323
At time: 431.8565390110016 and batch: 1150, loss is 4.1794994974136355 and perplexity is 65.33314562121656
At time: 432.9325969219208 and batch: 1200, loss is 4.15403254032135 and perplexity is 63.69031691828453
At time: 434.0103635787964 and batch: 1250, loss is 4.183912715911865 and perplexity is 65.62211223541858
At time: 435.085613489151 and batch: 1300, loss is 4.153969564437866 and perplexity is 63.68630609060126
At time: 436.16219758987427 and batch: 1350, loss is 4.128190279006958 and perplexity is 62.06550000007745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.744075113932292 and perplexity of 114.90148556061757
Finished 14 epochs...
Completing Train Step...
At time: 439.3548934459686 and batch: 50, loss is 4.4216554069519045 and perplexity is 83.23395744703036
At time: 440.4574770927429 and batch: 100, loss is 4.429309949874878 and perplexity is 83.87352000370946
At time: 441.5336308479309 and batch: 150, loss is 4.395310659408569 and perplexity is 81.06981195097192
At time: 442.60955262184143 and batch: 200, loss is 4.3853443908691405 and perplexity is 80.265861283208
At time: 443.6861312389374 and batch: 250, loss is 4.381580152511597 and perplexity is 79.96428939968347
At time: 444.76151037216187 and batch: 300, loss is 4.393105812072754 and perplexity is 80.89126230176872
At time: 445.8365499973297 and batch: 350, loss is 4.3869169807434085 and perplexity is 80.39218586625766
At time: 446.91445899009705 and batch: 400, loss is 4.383065395355224 and perplexity is 80.08314403040606
At time: 447.99069833755493 and batch: 450, loss is 4.343119688034058 and perplexity is 76.94721659563992
At time: 449.0663387775421 and batch: 500, loss is 4.400168600082398 and perplexity is 81.46460244586217
At time: 450.1431202888489 and batch: 550, loss is 4.380206823348999 and perplexity is 79.85454748222035
At time: 451.2187922000885 and batch: 600, loss is 4.333268518447876 and perplexity is 76.1929179776737
At time: 452.29467391967773 and batch: 650, loss is 4.337853708267212 and perplexity is 76.54307913369314
At time: 453.37205266952515 and batch: 700, loss is 4.343252277374267 and perplexity is 76.95741965271263
At time: 454.44766497612 and batch: 750, loss is 4.295222377777099 and perplexity is 73.34852371320429
At time: 455.5225555896759 and batch: 800, loss is 4.282866287231445 and perplexity is 72.44779889120811
At time: 456.6005823612213 and batch: 850, loss is 4.256907663345337 and perplexity is 70.59135336007354
At time: 457.67645263671875 and batch: 900, loss is 4.269249153137207 and perplexity is 71.46795397936017
At time: 458.7528941631317 and batch: 950, loss is 4.245351057052613 and perplexity is 69.78025269435179
At time: 459.8302366733551 and batch: 1000, loss is 4.246995153427124 and perplexity is 69.89507251638197
At time: 460.9066061973572 and batch: 1050, loss is 4.1986163711547855 and perplexity is 66.59412571340086
At time: 461.98367166519165 and batch: 1100, loss is 4.175180926322937 and perplexity is 65.05160814463336
At time: 463.05974435806274 and batch: 1150, loss is 4.179283146858215 and perplexity is 65.31901228780644
At time: 464.1363158226013 and batch: 1200, loss is 4.15533263206482 and perplexity is 63.77317402269692
At time: 465.21212911605835 and batch: 1250, loss is 4.185588655471801 and perplexity is 65.73218313964821
At time: 466.2896177768707 and batch: 1300, loss is 4.156242332458496 and perplexity is 63.83121490011321
At time: 467.3660497665405 and batch: 1350, loss is 4.13046516418457 and perplexity is 62.20685260558273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.743526611328125 and perplexity of 114.8384790777546
Finished 15 epochs...
Completing Train Step...
At time: 470.567405462265 and batch: 50, loss is 4.4159049129486085 and perplexity is 82.7566946375064
At time: 471.642192363739 and batch: 100, loss is 4.422684650421143 and perplexity is 83.3196695558992
At time: 472.7193593978882 and batch: 150, loss is 4.388616619110107 and perplexity is 80.52893969284307
At time: 473.7951776981354 and batch: 200, loss is 4.378648643493652 and perplexity is 79.73021662504974
At time: 474.8707900047302 and batch: 250, loss is 4.374792366027832 and perplexity is 79.4233468551081
At time: 475.9474561214447 and batch: 300, loss is 4.386567535400391 and perplexity is 80.36409809914723
At time: 477.02288246154785 and batch: 350, loss is 4.380587377548218 and perplexity is 79.8849422486526
At time: 478.09842705726624 and batch: 400, loss is 4.376847877502441 and perplexity is 79.5867703578227
At time: 479.1756489276886 and batch: 450, loss is 4.33716124534607 and perplexity is 76.4900942366785
At time: 480.25070357322693 and batch: 500, loss is 4.394376287460327 and perplexity is 80.99409797085376
At time: 481.326523065567 and batch: 550, loss is 4.374733409881592 and perplexity is 79.4186644986842
At time: 482.4033772945404 and batch: 600, loss is 4.328125457763672 and perplexity is 75.80205914371156
At time: 483.47983407974243 and batch: 650, loss is 4.332959413528442 and perplexity is 76.16937001148438
At time: 484.5547933578491 and batch: 700, loss is 4.338958311080932 and perplexity is 76.62767554839223
At time: 485.63218903541565 and batch: 750, loss is 4.291211290359497 and perplexity is 73.0549056302017
At time: 486.7096333503723 and batch: 800, loss is 4.279245853424072 and perplexity is 72.18598066459484
At time: 487.7856912612915 and batch: 850, loss is 4.2538087272644045 and perplexity is 70.37293387695021
At time: 488.86088514328003 and batch: 900, loss is 4.2664632320404055 and perplexity is 71.26912698537964
At time: 489.93739223480225 and batch: 950, loss is 4.243197841644287 and perplexity is 69.63016242538242
At time: 491.01240634918213 and batch: 1000, loss is 4.24524621963501 and perplexity is 69.77293749631956
At time: 492.08857703208923 and batch: 1050, loss is 4.197431001663208 and perplexity is 66.51523383571198
At time: 493.16577553749084 and batch: 1100, loss is 4.174545149803162 and perplexity is 65.01026300412887
At time: 494.2421832084656 and batch: 1150, loss is 4.178983058929443 and perplexity is 65.29941378148422
At time: 495.3645086288452 and batch: 1200, loss is 4.155817065238953 and perplexity is 63.80407534802252
At time: 496.4462819099426 and batch: 1250, loss is 4.186322784423828 and perplexity is 65.78045675573244
At time: 497.52678894996643 and batch: 1300, loss is 4.157427248954773 and perplexity is 63.906894387707695
At time: 498.6026759147644 and batch: 1350, loss is 4.1315826797485355 and perplexity is 62.27640858926325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.743037109375 and perplexity of 114.78227917405559
Finished 16 epochs...
Completing Train Step...
At time: 502.1178159713745 and batch: 50, loss is 4.4106130027771 and perplexity is 82.31991037425628
At time: 503.2051146030426 and batch: 100, loss is 4.416751966476441 and perplexity is 82.82682368498624
At time: 504.29375767707825 and batch: 150, loss is 4.382792205810547 and perplexity is 80.06126914088364
At time: 505.3743245601654 and batch: 200, loss is 4.372632169723511 and perplexity is 79.25196201385175
At time: 506.4541394710541 and batch: 250, loss is 4.368959398269653 and perplexity is 78.96142154108001
At time: 507.53555130958557 and batch: 300, loss is 4.380839900970459 and perplexity is 79.90511761492384
At time: 508.6152913570404 and batch: 350, loss is 4.37503867149353 and perplexity is 79.44291166890389
At time: 509.6948847770691 and batch: 400, loss is 4.371537322998047 and perplexity is 79.16524074466574
At time: 510.7746412754059 and batch: 450, loss is 4.331886539459228 and perplexity is 76.08769369156806
At time: 511.8576440811157 and batch: 500, loss is 4.3894300365448 and perplexity is 80.59446998451428
At time: 512.93674659729 and batch: 550, loss is 4.3698094367980955 and perplexity is 79.02857032713489
At time: 514.0183207988739 and batch: 600, loss is 4.323759546279907 and perplexity is 75.47183545144584
At time: 515.0966236591339 and batch: 650, loss is 4.3287311363220216 and perplexity is 75.8479847322818
At time: 516.1777808666229 and batch: 700, loss is 4.335335302352905 and perplexity is 76.35055511906698
At time: 517.257976770401 and batch: 750, loss is 4.2878083324432374 and perplexity is 72.80672537374643
At time: 518.3389019966125 and batch: 800, loss is 4.27611005783081 and perplexity is 71.95997472394492
At time: 519.4186794757843 and batch: 850, loss is 4.2509964656829835 and perplexity is 70.17530480121569
At time: 520.4990322589874 and batch: 900, loss is 4.263970155715942 and perplexity is 71.0916689124022
At time: 521.5785698890686 and batch: 950, loss is 4.241197271347046 and perplexity is 69.49100163752487
At time: 522.7042782306671 and batch: 1000, loss is 4.243534460067749 and perplexity is 69.65360516629131
At time: 523.7851028442383 and batch: 1050, loss is 4.1962151527404785 and perplexity is 66.43441050474436
At time: 524.8648884296417 and batch: 1100, loss is 4.173701543807983 and perplexity is 64.95544308296864
At time: 525.9429397583008 and batch: 1150, loss is 4.178275666236877 and perplexity is 65.25323778755227
At time: 527.0234498977661 and batch: 1200, loss is 4.155699524879456 and perplexity is 63.796576234801606
At time: 528.098301410675 and batch: 1250, loss is 4.186414813995361 and perplexity is 65.78651078155336
At time: 529.176335811615 and batch: 1300, loss is 4.157938170433044 and perplexity is 63.9395541352328
At time: 530.2518422603607 and batch: 1350, loss is 4.131825222969055 and perplexity is 62.29151514188677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7429496256510415 and perplexity of 114.77223803205366
Finished 17 epochs...
Completing Train Step...
At time: 533.507287979126 and batch: 50, loss is 4.40581431388855 and perplexity is 81.9258290281479
At time: 534.630565404892 and batch: 100, loss is 4.411349153518676 and perplexity is 82.38053254811624
At time: 535.7102212905884 and batch: 150, loss is 4.377412691116333 and perplexity is 79.63173474626048
At time: 536.7907662391663 and batch: 200, loss is 4.367443704605103 and perplexity is 78.84183086901324
At time: 537.8701984882355 and batch: 250, loss is 4.363747463226319 and perplexity is 78.55095034486315
At time: 538.949639081955 and batch: 300, loss is 4.376088972091675 and perplexity is 79.52639443987589
At time: 540.0295600891113 and batch: 350, loss is 4.37002161026001 and perplexity is 79.04533987145457
At time: 541.1092612743378 and batch: 400, loss is 4.36677508354187 and perplexity is 78.78913317958614
At time: 542.1909801959991 and batch: 450, loss is 4.3274782943725585 and perplexity is 75.7530186963654
At time: 543.2774555683136 and batch: 500, loss is 4.385169515609741 and perplexity is 80.25182599714309
At time: 544.3537936210632 and batch: 550, loss is 4.365589427947998 and perplexity is 78.6957717612765
At time: 545.4386606216431 and batch: 600, loss is 4.319858722686767 and perplexity is 75.17800659495242
At time: 546.5148694515228 and batch: 650, loss is 4.324884185791015 and perplexity is 75.55676180638618
At time: 547.5998117923737 and batch: 700, loss is 4.332048463821411 and perplexity is 76.10001514038346
At time: 548.6760106086731 and batch: 750, loss is 4.284679126739502 and perplexity is 72.57925424103462
At time: 549.8883464336395 and batch: 800, loss is 4.273170700073242 and perplexity is 71.74876917041168
At time: 550.9642531871796 and batch: 850, loss is 4.248337144851685 and perplexity is 69.98893407093203
At time: 552.0419557094574 and batch: 900, loss is 4.261522006988526 and perplexity is 70.9178388014268
At time: 553.1261456012726 and batch: 950, loss is 4.239097490310669 and perplexity is 69.34523883862467
At time: 554.2137520313263 and batch: 1000, loss is 4.241606893539429 and perplexity is 69.51947252472206
At time: 555.2960803508759 and batch: 1050, loss is 4.194222440719605 and perplexity is 66.30215767100125
At time: 556.3751027584076 and batch: 1100, loss is 4.172406849861145 and perplexity is 64.87140008071769
At time: 557.4561367034912 and batch: 1150, loss is 4.17686635017395 and perplexity is 65.16134012301801
At time: 558.5356805324554 and batch: 1200, loss is 4.155123319625854 and perplexity is 63.759826901009696
At time: 559.6151587963104 and batch: 1250, loss is 4.186102485656738 and perplexity is 65.76596699830701
At time: 560.6942992210388 and batch: 1300, loss is 4.157966899871826 and perplexity is 63.94139110912655
At time: 561.7785549163818 and batch: 1350, loss is 4.131287846565247 and perplexity is 62.2580501439475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.742762451171875 and perplexity of 114.75075760853349
Finished 18 epochs...
Completing Train Step...
At time: 565.0785007476807 and batch: 50, loss is 4.40128113746643 and perplexity is 81.55528529623561
At time: 566.1949899196625 and batch: 100, loss is 4.406290397644043 and perplexity is 81.96484187045688
At time: 567.2717752456665 and batch: 150, loss is 4.372412023544311 and perplexity is 79.2345169175264
At time: 568.3488068580627 and batch: 200, loss is 4.362638778686524 and perplexity is 78.46391037947726
At time: 569.4471845626831 and batch: 250, loss is 4.359041442871094 and perplexity is 78.18215643008111
At time: 570.5225179195404 and batch: 300, loss is 4.3716152477264405 and perplexity is 79.17140991491131
At time: 571.5979087352753 and batch: 350, loss is 4.3656059265136715 and perplexity is 78.69707013934581
At time: 572.6746435165405 and batch: 400, loss is 4.362366752624512 and perplexity is 78.44256905375666
At time: 573.7490746974945 and batch: 450, loss is 4.323479261398315 and perplexity is 75.450684801225
At time: 574.8263754844666 and batch: 500, loss is 4.3813016223907475 and perplexity is 79.94202003798132
At time: 575.9015824794769 and batch: 550, loss is 4.361639957427979 and perplexity is 78.38557808425483
At time: 576.976793050766 and batch: 600, loss is 4.316223545074463 and perplexity is 74.90521730759404
At time: 578.1023917198181 and batch: 650, loss is 4.321311330795288 and perplexity is 75.28729013077346
At time: 579.1775279045105 and batch: 700, loss is 4.328955745697021 and perplexity is 75.86502281411232
At time: 580.2543489933014 and batch: 750, loss is 4.281807365417481 and perplexity is 72.37112294067165
At time: 581.3288457393646 and batch: 800, loss is 4.270372762680053 and perplexity is 71.54830118544965
At time: 582.4041814804077 and batch: 850, loss is 4.245817537307739 and perplexity is 69.8128113978372
At time: 583.4799196720123 and batch: 900, loss is 4.259143009185791 and perplexity is 70.74932594407888
At time: 584.5548403263092 and batch: 950, loss is 4.237141933441162 and perplexity is 69.20976278917978
At time: 585.6296832561493 and batch: 1000, loss is 4.239873628616333 and perplexity is 69.39908122666986
At time: 586.7063670158386 and batch: 1050, loss is 4.192815799713134 and perplexity is 66.20895990047369
At time: 587.7819373607635 and batch: 1100, loss is 4.1712688541412355 and perplexity is 64.79761869449464
At time: 588.8565671443939 and batch: 1150, loss is 4.175744094848633 and perplexity is 65.08825348066775
At time: 589.9324288368225 and batch: 1200, loss is 4.154513192176819 and perplexity is 63.720937145531714
At time: 591.0071222782135 and batch: 1250, loss is 4.185647811889648 and perplexity is 65.73607173515656
At time: 592.0830843448639 and batch: 1300, loss is 4.1576924133300786 and perplexity is 63.9238424663498
At time: 593.1580791473389 and batch: 1350, loss is 4.130861291885376 and perplexity is 62.23149934438544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.742732747395833 and perplexity of 114.7473491283515
Finished 19 epochs...
Completing Train Step...
At time: 596.4253921508789 and batch: 50, loss is 4.397082509994507 and perplexity is 81.21358287746583
At time: 597.5024905204773 and batch: 100, loss is 4.401752319335937 and perplexity is 81.59372172259218
At time: 598.5782179832458 and batch: 150, loss is 4.3679917049407955 and perplexity is 78.88504805923192
At time: 599.654531955719 and batch: 200, loss is 4.358225803375245 and perplexity is 78.1184139743921
At time: 600.731960773468 and batch: 250, loss is 4.354737939834595 and perplexity is 77.84642221723996
At time: 601.8075387477875 and batch: 300, loss is 4.367518262863159 and perplexity is 78.84770939772851
At time: 602.8840463161469 and batch: 350, loss is 4.3616037940979 and perplexity is 78.38274345197632
At time: 603.9612212181091 and batch: 400, loss is 4.358449954986572 and perplexity is 78.13592630539407
At time: 605.0815477371216 and batch: 450, loss is 4.319679555892944 and perplexity is 75.16453839910753
At time: 606.1617004871368 and batch: 500, loss is 4.377666454315186 and perplexity is 79.6519449141899
At time: 607.2392492294312 and batch: 550, loss is 4.3579640960693355 and perplexity is 78.09797248968859
At time: 608.3164458274841 and batch: 600, loss is 4.312833776473999 and perplexity is 74.65173581846987
At time: 609.4004971981049 and batch: 650, loss is 4.317970037460327 and perplexity is 75.03615300510059
At time: 610.4795141220093 and batch: 700, loss is 4.3259666061401365 and perplexity is 75.63859026128205
At time: 611.5599308013916 and batch: 750, loss is 4.279061412811279 and perplexity is 72.17266786583409
At time: 612.6358323097229 and batch: 800, loss is 4.267739038467408 and perplexity is 71.36011062204759
At time: 613.7109682559967 and batch: 850, loss is 4.243422956466675 and perplexity is 69.64583897147487
At time: 614.7882635593414 and batch: 900, loss is 4.2568867397308345 and perplexity is 70.58987634926089
At time: 615.8644325733185 and batch: 950, loss is 4.2352291870117185 and perplexity is 69.0775085872205
At time: 616.9403231143951 and batch: 1000, loss is 4.238141851425171 and perplexity is 69.279001486402
At time: 618.0167925357819 and batch: 1050, loss is 4.191344833374023 and perplexity is 66.11164034355657
At time: 619.0926778316498 and batch: 1100, loss is 4.170037956237793 and perplexity is 64.71790850910968
At time: 620.1696012020111 and batch: 1150, loss is 4.174546065330506 and perplexity is 65.01032252282953
At time: 621.245640039444 and batch: 1200, loss is 4.153739261627197 and perplexity is 63.67164064411905
At time: 622.3282792568207 and batch: 1250, loss is 4.185002737045288 and perplexity is 65.69368072307088
At time: 623.4064254760742 and batch: 1300, loss is 4.157246890068055 and perplexity is 63.895369250744004
At time: 624.481853723526 and batch: 1350, loss is 4.130226311683654 and perplexity is 62.191996117589085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.742730305989583 and perplexity of 114.74706898379809
Finished 20 epochs...
Completing Train Step...
At time: 627.6868958473206 and batch: 50, loss is 4.393092374801636 and perplexity is 80.89017535124893
At time: 628.7625033855438 and batch: 100, loss is 4.397468605041504 and perplexity is 81.24494509357223
At time: 629.8395142555237 and batch: 150, loss is 4.363842096328735 and perplexity is 78.5583842167317
At time: 630.9148116111755 and batch: 200, loss is 4.3539807319641115 and perplexity is 77.78749860517486
At time: 632.0172624588013 and batch: 250, loss is 4.350715932846069 and perplexity is 77.53395216264569
At time: 633.0931384563446 and batch: 300, loss is 4.363631763458252 and perplexity is 78.54186254386521
At time: 634.1692554950714 and batch: 350, loss is 4.357838592529297 and perplexity is 78.08817153271154
At time: 635.2465405464172 and batch: 400, loss is 4.354762964248657 and perplexity is 77.8483703027175
At time: 636.3228363990784 and batch: 450, loss is 4.316141119003296 and perplexity is 74.89904341926967
At time: 637.3987765312195 and batch: 500, loss is 4.374254503250122 and perplexity is 79.38063947953698
At time: 638.4763691425323 and batch: 550, loss is 4.3545377063751225 and perplexity is 77.83083631927305
At time: 639.5533626079559 and batch: 600, loss is 4.309622812271118 and perplexity is 74.41241619606534
At time: 640.6299431324005 and batch: 650, loss is 4.314791603088379 and perplexity is 74.79803414030782
At time: 641.7072994709015 and batch: 700, loss is 4.323103790283203 and perplexity is 75.4223605662655
At time: 642.783608675003 and batch: 750, loss is 4.276461038589478 and perplexity is 71.98523572327024
At time: 643.8598477840424 and batch: 800, loss is 4.265272874832153 and perplexity is 71.18434173872285
At time: 644.937356710434 and batch: 850, loss is 4.241087465286255 and perplexity is 69.48337152329871
At time: 646.0133516788483 and batch: 900, loss is 4.254636192321778 and perplexity is 70.4311891194831
At time: 647.0895290374756 and batch: 950, loss is 4.233344354629517 and perplexity is 68.94743168723932
At time: 648.176881313324 and batch: 1000, loss is 4.236386499404907 and perplexity is 69.15749912208969
At time: 649.2530889511108 and batch: 1050, loss is 4.189749794006348 and perplexity is 66.00627372883531
At time: 650.3314664363861 and batch: 1100, loss is 4.168739652633667 and perplexity is 64.63393953564604
At time: 651.4089500904083 and batch: 1150, loss is 4.173222031593323 and perplexity is 64.92430362107451
At time: 652.4846448898315 and batch: 1200, loss is 4.152881240844726 and perplexity is 63.61703248401072
At time: 653.5603640079498 and batch: 1250, loss is 4.184210681915284 and perplexity is 65.64166830731484
At time: 654.6380372047424 and batch: 1300, loss is 4.156600041389465 and perplexity is 63.854051980027805
At time: 655.714358329773 and batch: 1350, loss is 4.129376921653748 and perplexity is 62.13919328442144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.742750244140625 and perplexity of 114.74935685099898
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 658.8905408382416 and batch: 50, loss is 4.391204538345337 and perplexity is 80.73761198192008
At time: 659.9913110733032 and batch: 100, loss is 4.396956243515015 and perplexity is 81.20332897164482
At time: 661.0678601264954 and batch: 150, loss is 4.363780908584594 and perplexity is 78.55357755347407
At time: 662.143381357193 and batch: 200, loss is 4.3549454975128175 and perplexity is 77.86258151682863
At time: 663.2197806835175 and batch: 250, loss is 4.35051962852478 and perplexity is 77.5187334065922
At time: 664.296891450882 and batch: 300, loss is 4.364324903488159 and perplexity is 78.59632192462583
At time: 665.373908996582 and batch: 350, loss is 4.357795152664185 and perplexity is 78.0847794667493
At time: 666.4515550136566 and batch: 400, loss is 4.354678153991699 and perplexity is 77.84176824239356
At time: 667.5281925201416 and batch: 450, loss is 4.3142822265625 and perplexity is 74.75994347960267
At time: 668.6042280197144 and batch: 500, loss is 4.370697345733642 and perplexity is 79.09877166247618
At time: 669.6797921657562 and batch: 550, loss is 4.349345979690551 and perplexity is 77.42780700376925
At time: 670.7566256523132 and batch: 600, loss is 4.304990396499634 and perplexity is 74.06850413252646
At time: 671.8317975997925 and batch: 650, loss is 4.309319629669189 and perplexity is 74.38985906574472
At time: 672.9092960357666 and batch: 700, loss is 4.316666564941406 and perplexity is 74.9384091587809
At time: 673.9854419231415 and batch: 750, loss is 4.268988008499146 and perplexity is 71.44929294310606
At time: 675.0613968372345 and batch: 800, loss is 4.257319793701172 and perplexity is 70.62045219549755
At time: 676.1384980678558 and batch: 850, loss is 4.231355247497558 and perplexity is 68.81042416563224
At time: 677.2144496440887 and batch: 900, loss is 4.241931414604187 and perplexity is 69.54203671904733
At time: 678.291978597641 and batch: 950, loss is 4.220800981521607 and perplexity is 68.08799968318291
At time: 679.3668525218964 and batch: 1000, loss is 4.222822046279907 and perplexity is 68.22574909315595
At time: 680.4429938793182 and batch: 1050, loss is 4.175792760848999 and perplexity is 65.09142114271357
At time: 681.5201258659363 and batch: 1100, loss is 4.152866315841675 and perplexity is 63.61608300669228
At time: 682.5968201160431 and batch: 1150, loss is 4.155872693061829 and perplexity is 63.80762472854599
At time: 683.6743998527527 and batch: 1200, loss is 4.134408106803894 and perplexity is 62.45261485074943
At time: 684.7500565052032 and batch: 1250, loss is 4.164517607688904 and perplexity is 64.36162739952023
At time: 685.8261759281158 and batch: 1300, loss is 4.137025218009949 and perplexity is 62.61627435306916
At time: 686.9025416374207 and batch: 1350, loss is 4.110814213752747 and perplexity is 60.996361432867666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738666585286459 and perplexity of 114.28171511841188
Finished 22 epochs...
Completing Train Step...
At time: 690.052426815033 and batch: 50, loss is 4.388795251846314 and perplexity is 80.54332608258605
At time: 691.1712996959686 and batch: 100, loss is 4.394208030700684 and perplexity is 80.98047131279976
At time: 692.2511298656464 and batch: 150, loss is 4.361168594360351 and perplexity is 78.34863872432022
At time: 693.3313348293304 and batch: 200, loss is 4.35200309753418 and perplexity is 77.63381538441774
At time: 694.4142029285431 and batch: 250, loss is 4.347990312576294 and perplexity is 77.32291178964627
At time: 695.4945743083954 and batch: 300, loss is 4.3617777824401855 and perplexity is 78.39638232204112
At time: 696.5755438804626 and batch: 350, loss is 4.35514928817749 and perplexity is 77.87845080102011
At time: 697.6554849147797 and batch: 400, loss is 4.352198619842529 and perplexity is 77.6489960112349
At time: 698.7360489368439 and batch: 450, loss is 4.312222738265991 and perplexity is 74.60613468902568
At time: 699.8227660655975 and batch: 500, loss is 4.368698263168335 and perplexity is 78.94080463428187
At time: 700.8999710083008 and batch: 550, loss is 4.3475643920898435 and perplexity is 77.28998538995491
At time: 701.9757175445557 and batch: 600, loss is 4.303417816162109 and perplexity is 73.95211699734345
At time: 703.051230430603 and batch: 650, loss is 4.307709846496582 and perplexity is 74.27020385771783
At time: 704.1276757717133 and batch: 700, loss is 4.315314874649048 and perplexity is 74.8371840664956
At time: 705.2035300731659 and batch: 750, loss is 4.267781200408936 and perplexity is 71.3631193662859
At time: 706.2794146537781 and batch: 800, loss is 4.2563244819641115 and perplexity is 70.55019779886338
At time: 707.3613390922546 and batch: 850, loss is 4.230685148239136 and perplexity is 68.76432979705305
At time: 708.443781375885 and batch: 900, loss is 4.241290979385376 and perplexity is 69.4975138080865
At time: 709.5202448368073 and batch: 950, loss is 4.220202302932739 and perplexity is 68.04724905509515
At time: 710.6040313243866 and batch: 1000, loss is 4.222557277679443 and perplexity is 68.20768744823671
At time: 711.681357383728 and batch: 1050, loss is 4.175693674087524 and perplexity is 65.08497176412205
At time: 712.7617635726929 and batch: 1100, loss is 4.152945322990417 and perplexity is 63.62110933057995
At time: 713.8943145275116 and batch: 1150, loss is 4.156315188407898 and perplexity is 63.83586555328808
At time: 714.9715783596039 and batch: 1200, loss is 4.135203819274903 and perplexity is 62.50232895167523
At time: 716.0481400489807 and batch: 1250, loss is 4.165680685043335 and perplexity is 64.43652850028649
At time: 717.1247749328613 and batch: 1300, loss is 4.13828173160553 and perplexity is 62.69500200392213
At time: 718.2021706104279 and batch: 1350, loss is 4.112096672058105 and perplexity is 61.07463690497026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738118896484375 and perplexity of 114.21914143977429
Finished 23 epochs...
Completing Train Step...
At time: 721.4413959980011 and batch: 50, loss is 4.387606954574585 and perplexity is 80.44767351104655
At time: 722.5186641216278 and batch: 100, loss is 4.392708520889283 and perplexity is 80.85913129954092
At time: 723.5980455875397 and batch: 150, loss is 4.359646348953247 and perplexity is 78.22946359877605
At time: 724.6840977668762 and batch: 200, loss is 4.350404062271118 and perplexity is 77.50977537461686
At time: 725.7663216590881 and batch: 250, loss is 4.346500177383422 and perplexity is 77.20777600282211
At time: 726.8458364009857 and batch: 300, loss is 4.36025408744812 and perplexity is 78.27702110503816
At time: 727.927588224411 and batch: 350, loss is 4.3536545944213865 and perplexity is 77.76213331803609
At time: 729.0045840740204 and batch: 400, loss is 4.350780420303344 and perplexity is 77.53895229129424
At time: 730.0808217525482 and batch: 450, loss is 4.311018686294556 and perplexity is 74.51635908356556
At time: 731.1574757099152 and batch: 500, loss is 4.367470979690552 and perplexity is 78.84398131601381
At time: 732.2359480857849 and batch: 550, loss is 4.346510419845581 and perplexity is 77.20856680459603
At time: 733.3135845661163 and batch: 600, loss is 4.302496690750122 and perplexity is 73.8840291866275
At time: 734.3909015655518 and batch: 650, loss is 4.306696977615356 and perplexity is 74.19501596359511
At time: 735.4681851863861 and batch: 700, loss is 4.3145103931427 and perplexity is 74.77700314639127
At time: 736.5458495616913 and batch: 750, loss is 4.267053327560425 and perplexity is 71.31119498877885
At time: 737.6223483085632 and batch: 800, loss is 4.255773057937622 and perplexity is 70.51130544879716
At time: 738.7004196643829 and batch: 850, loss is 4.230317192077637 and perplexity is 68.739032192703
At time: 739.776953458786 and batch: 900, loss is 4.2410094261169435 and perplexity is 69.47794931027931
At time: 740.8980917930603 and batch: 950, loss is 4.219923601150513 and perplexity is 68.0282868080367
At time: 741.9748766422272 and batch: 1000, loss is 4.222516441345215 and perplexity is 68.20490215318617
At time: 743.0532646179199 and batch: 1050, loss is 4.175761995315551 and perplexity is 65.08941860122403
At time: 744.1307828426361 and batch: 1100, loss is 4.153164606094361 and perplexity is 63.63506189463514
At time: 745.2073860168457 and batch: 1150, loss is 4.156710095405579 and perplexity is 63.86107976160404
At time: 746.2842757701874 and batch: 1200, loss is 4.1358638048172 and perplexity is 62.54359320054926
At time: 747.3618719577789 and batch: 1250, loss is 4.166495099067688 and perplexity is 64.48902788799475
At time: 748.4392788410187 and batch: 1300, loss is 4.139095191955566 and perplexity is 62.74602265102105
At time: 749.515900850296 and batch: 1350, loss is 4.112868180274964 and perplexity is 61.121774670432636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737860107421875 and perplexity of 114.18958659964123
Finished 24 epochs...
Completing Train Step...
At time: 752.7486164569855 and batch: 50, loss is 4.38666262626648 and perplexity is 80.37174035418649
At time: 753.8269703388214 and batch: 100, loss is 4.391534833908081 and perplexity is 80.76428366143047
At time: 754.9072630405426 and batch: 150, loss is 4.358413372039795 and perplexity is 78.13306791524516
At time: 755.9836614131927 and batch: 200, loss is 4.349176969528198 and perplexity is 77.41472202331536
At time: 757.0667507648468 and batch: 250, loss is 4.345324649810791 and perplexity is 77.11706945777694
At time: 758.1431958675385 and batch: 300, loss is 4.359065847396851 and perplexity is 78.18406445181351
At time: 759.2203493118286 and batch: 350, loss is 4.352524309158325 and perplexity is 77.67428957831677
At time: 760.2966442108154 and batch: 400, loss is 4.349692125320434 and perplexity is 77.45461293990618
At time: 761.3736221790314 and batch: 450, loss is 4.310078401565551 and perplexity is 74.44632542001037
At time: 762.451681137085 and batch: 500, loss is 4.366509532928466 and perplexity is 78.7682134546866
At time: 763.5286145210266 and batch: 550, loss is 4.34568772315979 and perplexity is 77.14507369393823
At time: 764.6057386398315 and batch: 600, loss is 4.301772260665894 and perplexity is 73.83052475559042
At time: 765.6820759773254 and batch: 650, loss is 4.3059108924865725 and perplexity is 74.13671528256758
At time: 766.76051902771 and batch: 700, loss is 4.313886842727661 and perplexity is 74.7303904492376
At time: 767.8368904590607 and batch: 750, loss is 4.266496648788452 and perplexity is 71.27150860763244
At time: 768.9386115074158 and batch: 800, loss is 4.25536696434021 and perplexity is 70.48267707240282
At time: 770.0166623592377 and batch: 850, loss is 4.230055847167969 and perplexity is 68.72106994381731
At time: 771.0933547019958 and batch: 900, loss is 4.240826525688171 and perplexity is 69.46524292559728
At time: 772.1696832180023 and batch: 950, loss is 4.219732856750488 and perplexity is 68.01531203075716
At time: 773.2472622394562 and batch: 1000, loss is 4.222495756149292 and perplexity is 68.20349133601377
At time: 774.3239574432373 and batch: 1050, loss is 4.175826749801636 and perplexity is 65.09363356954266
At time: 775.4009485244751 and batch: 1100, loss is 4.153342685699463 and perplexity is 63.646395010396425
At time: 776.4777057170868 and batch: 1150, loss is 4.1570143175125125 and perplexity is 63.88051066934615
At time: 777.5557630062103 and batch: 1200, loss is 4.136372108459472 and perplexity is 62.57539241791822
At time: 778.6324081420898 and batch: 1250, loss is 4.167085580825805 and perplexity is 64.52711872742752
At time: 779.7092273235321 and batch: 1300, loss is 4.139665565490723 and perplexity is 62.78182153017361
At time: 780.7871813774109 and batch: 1350, loss is 4.11338936328888 and perplexity is 61.15363860392044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7377091471354165 and perplexity of 114.17234980800576
Finished 25 epochs...
Completing Train Step...
At time: 784.0016498565674 and batch: 50, loss is 4.385838365554809 and perplexity is 80.30552038129412
At time: 785.1086027622223 and batch: 100, loss is 4.390530681610107 and perplexity is 80.68322472496739
At time: 786.1850719451904 and batch: 150, loss is 4.357374534606934 and perplexity is 78.0519425049028
At time: 787.2635977268219 and batch: 200, loss is 4.3481365585327145 and perplexity is 77.33422077976105
At time: 788.3429443836212 and batch: 250, loss is 4.344313449859619 and perplexity is 77.03912809469945
At time: 789.4210052490234 and batch: 300, loss is 4.358055906295776 and perplexity is 78.105143011386
At time: 790.4989802837372 and batch: 350, loss is 4.351579780578613 and perplexity is 77.60095862894171
At time: 791.5779731273651 and batch: 400, loss is 4.348773794174194 and perplexity is 77.38351660640872
At time: 792.654305934906 and batch: 450, loss is 4.3092743682861325 and perplexity is 74.38649215403413
At time: 793.7326512336731 and batch: 500, loss is 4.36569281578064 and perplexity is 78.70390836716275
At time: 794.8094093799591 and batch: 550, loss is 4.3449784278869625 and perplexity is 77.09037445909283
At time: 795.9129490852356 and batch: 600, loss is 4.301144914627075 and perplexity is 73.78422199378679
At time: 796.9902188777924 and batch: 650, loss is 4.305246200561523 and perplexity is 74.08745358031115
At time: 798.0678899288177 and batch: 700, loss is 4.313358144760132 and perplexity is 74.69089108623098
At time: 799.1442310810089 and batch: 750, loss is 4.266026077270507 and perplexity is 71.23797815549734
At time: 800.2223570346832 and batch: 800, loss is 4.255025806427002 and perplexity is 70.45863545060345
At time: 801.2991349697113 and batch: 850, loss is 4.229837923049927 and perplexity is 68.70609559695386
At time: 802.3777642250061 and batch: 900, loss is 4.240665798187256 and perplexity is 69.45407884791254
At time: 803.457605600357 and batch: 950, loss is 4.219563341140747 and perplexity is 68.00378335083973
At time: 804.5357902050018 and batch: 1000, loss is 4.222459049224853 and perplexity is 68.20098784155891
At time: 805.6147062778473 and batch: 1050, loss is 4.175864200592041 and perplexity is 65.09607142321971
At time: 806.6979169845581 and batch: 1100, loss is 4.15346595287323 and perplexity is 63.65424100519668
At time: 807.7797088623047 and batch: 1150, loss is 4.157241353988647 and perplexity is 63.895015521885206
At time: 808.8596830368042 and batch: 1200, loss is 4.136759939193726 and perplexity is 62.59966578498051
At time: 809.9423582553864 and batch: 1250, loss is 4.167527213096618 and perplexity is 64.55562227898096
At time: 811.023063659668 and batch: 1300, loss is 4.140087418556213 and perplexity is 62.80831182115557
At time: 812.1017596721649 and batch: 1350, loss is 4.113758811950683 and perplexity is 61.17623590788192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737616373697917 and perplexity of 114.16175813796711
Finished 26 epochs...
Completing Train Step...
At time: 815.2987132072449 and batch: 50, loss is 4.385088291168213 and perplexity is 80.24530785211478
At time: 816.401707649231 and batch: 100, loss is 4.389632511138916 and perplexity is 80.61078996924776
At time: 817.4799253940582 and batch: 150, loss is 4.356448955535889 and perplexity is 77.97973268357069
At time: 818.55699467659 and batch: 200, loss is 4.347213201522827 and perplexity is 77.2628466418762
At time: 819.6336903572083 and batch: 250, loss is 4.343407764434814 and perplexity is 76.9693864659999
At time: 820.7189331054688 and batch: 300, loss is 4.357159938812256 and perplexity is 78.0351946833451
At time: 821.7956998348236 and batch: 350, loss is 4.350748662948608 and perplexity is 77.5364898983802
At time: 822.8742485046387 and batch: 400, loss is 4.34796100616455 and perplexity is 77.32064576576083
At time: 823.9772591590881 and batch: 450, loss is 4.3085566425323485 and perplexity is 74.33312220766506
At time: 825.053840637207 and batch: 500, loss is 4.364966220855713 and perplexity is 78.64674327721839
At time: 826.132054567337 and batch: 550, loss is 4.344336528778076 and perplexity is 77.04090609497177
At time: 827.2087450027466 and batch: 600, loss is 4.300576772689819 and perplexity is 73.7423139889391
At time: 828.2912087440491 and batch: 650, loss is 4.304653902053833 and perplexity is 74.04358468513999
At time: 829.3765580654144 and batch: 700, loss is 4.312884225845337 and perplexity is 74.65550204661228
At time: 830.4533989429474 and batch: 750, loss is 4.265601558685303 and perplexity is 71.20774272800246
At time: 831.5304346084595 and batch: 800, loss is 4.2547164630889895 and perplexity is 70.43684291198345
At time: 832.6084728240967 and batch: 850, loss is 4.22963472366333 and perplexity is 68.69213597881404
At time: 833.6853880882263 and batch: 900, loss is 4.240504727363587 and perplexity is 69.4428927231287
At time: 834.7634124755859 and batch: 950, loss is 4.219396190643311 and perplexity is 67.99241743456085
At time: 835.8395574092865 and batch: 1000, loss is 4.222404155731201 and perplexity is 68.19724415381876
At time: 836.9172711372375 and batch: 1050, loss is 4.175874099731446 and perplexity is 65.09671582149488
At time: 837.9946937561035 and batch: 1100, loss is 4.153541307449341 and perplexity is 63.659037824274186
At time: 839.0735111236572 and batch: 1150, loss is 4.157407426834107 and perplexity is 63.90562763009072
At time: 840.1512813568115 and batch: 1200, loss is 4.137058730125427 and perplexity is 62.61837279204746
At time: 841.231734752655 and batch: 1250, loss is 4.167865204811096 and perplexity is 64.57744523221514
At time: 842.309529542923 and batch: 1300, loss is 4.140409045219421 and perplexity is 62.82851589781905
At time: 843.3872785568237 and batch: 1350, loss is 4.114028978347778 and perplexity is 61.192765903949166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737556966145833 and perplexity of 114.15497626882365
Finished 27 epochs...
Completing Train Step...
At time: 846.6211671829224 and batch: 50, loss is 4.384386777877808 and perplexity is 80.18903444274393
At time: 847.6990060806274 and batch: 100, loss is 4.388807878494263 and perplexity is 80.5443430812298
At time: 848.776079416275 and batch: 150, loss is 4.355599384307862 and perplexity is 77.9135114801111
At time: 849.8538453578949 and batch: 200, loss is 4.346370620727539 and perplexity is 77.19777386949046
At time: 850.9579610824585 and batch: 250, loss is 4.342576427459717 and perplexity is 76.90542555929723
At time: 852.0347516536713 and batch: 300, loss is 4.356342821121216 and perplexity is 77.97145678947233
At time: 853.1118850708008 and batch: 350, loss is 4.349994220733643 and perplexity is 77.47801515788053
At time: 854.1889226436615 and batch: 400, loss is 4.347221965789795 and perplexity is 77.26352379705827
At time: 855.2671730518341 and batch: 450, loss is 4.307898349761963 and perplexity is 74.28420535328789
At time: 856.3436450958252 and batch: 500, loss is 4.3643010711669925 and perplexity is 78.59444881415959
At time: 857.4208714962006 and batch: 550, loss is 4.343739910125732 and perplexity is 76.99495576217791
At time: 858.4988377094269 and batch: 600, loss is 4.3000483894348145 and perplexity is 73.70336007724566
At time: 859.5758938789368 and batch: 650, loss is 4.304108066558838 and perplexity is 74.00318009657465
At time: 860.6536464691162 and batch: 700, loss is 4.312444314956665 and perplexity is 74.62266750102934
At time: 861.7325322628021 and batch: 750, loss is 4.265204486846923 and perplexity is 71.17947375146927
At time: 862.8097417354584 and batch: 800, loss is 4.2544237232208255 and perplexity is 70.41622625768106
At time: 863.8900995254517 and batch: 850, loss is 4.229435720443726 and perplexity is 68.67846738268517
At time: 864.9683074951172 and batch: 900, loss is 4.240336971282959 and perplexity is 69.43124423269788
At time: 866.046021938324 and batch: 950, loss is 4.2192251586914065 and perplexity is 67.9807895530903
At time: 867.1242399215698 and batch: 1000, loss is 4.222331743240357 and perplexity is 68.19230600029502
At time: 868.2019443511963 and batch: 1050, loss is 4.175859689712524 and perplexity is 65.09577778334678
At time: 869.2800755500793 and batch: 1100, loss is 4.153577785491944 and perplexity is 63.66136002372237
At time: 870.3589816093445 and batch: 1150, loss is 4.157525634765625 and perplexity is 63.913182228643166
At time: 871.4385693073273 and batch: 1200, loss is 4.137290692329406 and perplexity is 62.63289957257676
At time: 872.5159616470337 and batch: 1250, loss is 4.168127379417419 and perplexity is 64.5943780180725
At time: 873.5941536426544 and batch: 1300, loss is 4.140659022331238 and perplexity is 62.844223551958116
At time: 874.6727778911591 and batch: 1350, loss is 4.114228949546814 and perplexity is 61.20500391830374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737518310546875 and perplexity of 114.15056362512917
Finished 28 epochs...
Completing Train Step...
At time: 877.917533159256 and batch: 50, loss is 4.383719692230224 and perplexity is 80.13555932699778
At time: 878.9934697151184 and batch: 100, loss is 4.388037233352661 and perplexity is 80.4822958858064
At time: 880.0711624622345 and batch: 150, loss is 4.3548064613342286 and perplexity is 77.85175655358765
At time: 881.1478590965271 and batch: 200, loss is 4.345586366653443 and perplexity is 77.13725493503446
At time: 882.2245142459869 and batch: 250, loss is 4.341799039840698 and perplexity is 76.84566346579751
At time: 883.302267074585 and batch: 300, loss is 4.355581607818603 and perplexity is 77.91212646372159
At time: 884.3788573741913 and batch: 350, loss is 4.349293508529663 and perplexity is 77.42374438343685
At time: 885.4562289714813 and batch: 400, loss is 4.3465378379821775 and perplexity is 77.21068374864831
At time: 886.5341517925262 and batch: 450, loss is 4.3072818088531495 and perplexity is 74.23842021746383
At time: 887.6109430789948 and batch: 500, loss is 4.363679008483887 and perplexity is 78.54557334383223
At time: 888.6881816387177 and batch: 550, loss is 4.34317572593689 and perplexity is 76.95152867710554
At time: 889.7663083076477 and batch: 600, loss is 4.299547033309937 and perplexity is 73.6664177076623
At time: 890.8479096889496 and batch: 650, loss is 4.303592824935913 and perplexity is 73.96506039923081
At time: 891.9255936145782 and batch: 700, loss is 4.312027454376221 and perplexity is 74.59156673533253
At time: 893.0031991004944 and batch: 750, loss is 4.264823493957519 and perplexity is 71.15236004349137
At time: 894.0798261165619 and batch: 800, loss is 4.254139318466186 and perplexity is 70.39620239570537
At time: 895.1577606201172 and batch: 850, loss is 4.229235239028931 and perplexity is 68.66470000647601
At time: 896.234411239624 and batch: 900, loss is 4.240159363746643 and perplexity is 69.41891381548626
At time: 897.3111310005188 and batch: 950, loss is 4.219047794342041 and perplexity is 67.96873325379231
At time: 898.3958036899567 and batch: 1000, loss is 4.222240629196167 and perplexity is 68.18609300656252
At time: 899.4732871055603 and batch: 1050, loss is 4.1758246421813965 and perplexity is 65.09349637702768
At time: 900.5530760288239 and batch: 1100, loss is 4.153581523895264 and perplexity is 63.661598016006906
At time: 901.6458311080933 and batch: 1150, loss is 4.157606616020202 and perplexity is 63.91835820789991
At time: 902.7318866252899 and batch: 1200, loss is 4.137469186782837 and perplexity is 62.64408019556263
At time: 903.8067955970764 and batch: 1250, loss is 4.1683320760726925 and perplexity is 64.6076016245701
At time: 904.8846967220306 and batch: 1300, loss is 4.140854778289795 and perplexity is 62.85652688736566
At time: 905.968663930893 and batch: 1350, loss is 4.114376521110534 and perplexity is 61.214036702914136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737494303385417 and perplexity of 114.14782322701242
Finished 29 epochs...
Completing Train Step...
At time: 909.205263376236 and batch: 50, loss is 4.383078956604004 and perplexity is 80.08423006520931
At time: 910.3173551559448 and batch: 100, loss is 4.387308731079101 and perplexity is 80.42368570169054
At time: 911.3939316272736 and batch: 150, loss is 4.354058208465577 and perplexity is 77.79352554189448
At time: 912.4715218544006 and batch: 200, loss is 4.344843626022339 and perplexity is 77.07998323326525
At time: 913.5482022762299 and batch: 250, loss is 4.341061611175537 and perplexity is 76.78901616000513
At time: 914.6264185905457 and batch: 300, loss is 4.354859800338745 and perplexity is 77.85590919953009
At time: 915.7033619880676 and batch: 350, loss is 4.3486301136016845 and perplexity is 77.37239889715842
At time: 916.7818627357483 and batch: 400, loss is 4.345899057388306 and perplexity is 77.1613788114252
At time: 917.8585112094879 and batch: 450, loss is 4.306694746017456 and perplexity is 74.19485039033802
At time: 918.9362065792084 and batch: 500, loss is 4.3630892848968506 and perplexity is 78.4992668219402
At time: 920.0134391784668 and batch: 550, loss is 4.342635641098022 and perplexity is 76.90997954417772
At time: 921.0909883975983 and batch: 600, loss is 4.299064254760742 and perplexity is 73.6308617249205
At time: 922.1735055446625 and batch: 650, loss is 4.303096942901611 and perplexity is 73.92839154707664
At time: 923.2526571750641 and batch: 700, loss is 4.311627063751221 and perplexity is 74.56170694949571
At time: 924.329865694046 and batch: 750, loss is 4.264450998306274 and perplexity is 71.12586103448857
At time: 925.4061799049377 and batch: 800, loss is 4.253856859207153 and perplexity is 70.37632114449187
At time: 926.4840550422668 and batch: 850, loss is 4.229027547836304 and perplexity is 68.65044043388535
At time: 927.560629606247 and batch: 900, loss is 4.2399708271026615 and perplexity is 69.40582704015377
At time: 928.6382851600647 and batch: 950, loss is 4.21886399269104 and perplexity is 67.95624163642896
At time: 929.7173871994019 and batch: 1000, loss is 4.222128086090088 and perplexity is 68.17841956366875
At time: 930.7973141670227 and batch: 1050, loss is 4.175775127410889 and perplexity is 65.09027336728697
At time: 931.8748474121094 and batch: 1100, loss is 4.153560266494751 and perplexity is 63.6602447503041
At time: 932.9974222183228 and batch: 1150, loss is 4.157659602165222 and perplexity is 63.92174508502534
At time: 934.0737719535828 and batch: 1200, loss is 4.13760133266449 and perplexity is 62.65235889975671
At time: 935.1517519950867 and batch: 1250, loss is 4.168490834236145 and perplexity is 64.61785942298218
At time: 936.2281851768494 and batch: 1300, loss is 4.141008076667785 and perplexity is 62.866163429597854
At time: 937.3052487373352 and batch: 1350, loss is 4.1144822263717655 and perplexity is 61.220507690657534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737480875651042 and perplexity of 114.14629049065326
Finished 30 epochs...
Completing Train Step...
At time: 940.4702785015106 and batch: 50, loss is 4.382459211349487 and perplexity is 80.03461362003104
At time: 941.5717942714691 and batch: 100, loss is 4.386616954803467 and perplexity is 80.36806974304132
At time: 942.646683216095 and batch: 150, loss is 4.3533477783203125 and perplexity is 77.7382783032187
At time: 943.7226541042328 and batch: 200, loss is 4.34413330078125 and perplexity is 77.02525081680174
At time: 944.7989473342896 and batch: 250, loss is 4.340354909896851 and perplexity is 76.73476843482193
At time: 945.8740544319153 and batch: 300, loss is 4.354165449142456 and perplexity is 77.80186861958107
At time: 946.9492115974426 and batch: 350, loss is 4.3479964065551755 and perplexity is 77.32338299527353
At time: 948.0275928974152 and batch: 400, loss is 4.345297498703003 and perplexity is 77.11497567233623
At time: 949.1048114299774 and batch: 450, loss is 4.306130723953247 and perplexity is 74.15301465691462
At time: 950.180980682373 and batch: 500, loss is 4.3625259113311765 and perplexity is 78.45505486518115
At time: 951.2593569755554 and batch: 550, loss is 4.342114019393921 and perplexity is 76.8698720909539
At time: 952.3357353210449 and batch: 600, loss is 4.298600234985352 and perplexity is 73.59670347466582
At time: 953.4124796390533 and batch: 650, loss is 4.302615823745728 and perplexity is 73.89283173667863
At time: 954.4900920391083 and batch: 700, loss is 4.311237335205078 and perplexity is 74.53265378563977
At time: 955.567066192627 and batch: 750, loss is 4.264085903167724 and perplexity is 71.09989806816449
At time: 956.6432867050171 and batch: 800, loss is 4.2535743904113765 and perplexity is 70.35644483715744
At time: 957.7207119464874 and batch: 850, loss is 4.228813743591308 and perplexity is 68.63576424727118
At time: 958.798299074173 and batch: 900, loss is 4.239776463508606 and perplexity is 69.39233838505604
At time: 959.9215352535248 and batch: 950, loss is 4.218677053451538 and perplexity is 67.94353913563292
At time: 961.0046453475952 and batch: 1000, loss is 4.221999340057373 and perplexity is 68.16964242765602
At time: 962.0846798419952 and batch: 1050, loss is 4.175714330673218 and perplexity is 65.08631621130444
At time: 963.1616201400757 and batch: 1100, loss is 4.153521928787232 and perplexity is 63.657804209242904
At time: 964.2390580177307 and batch: 1150, loss is 4.15769070148468 and perplexity is 63.92373303870786
At time: 965.3165547847748 and batch: 1200, loss is 4.137696447372437 and perplexity is 62.658318343986565
At time: 966.4000449180603 and batch: 1250, loss is 4.168613986968994 and perplexity is 64.62581777899754
At time: 967.4769241809845 and batch: 1300, loss is 4.141124067306518 and perplexity is 62.873455738960374
At time: 968.5543439388275 and batch: 1350, loss is 4.114553198814392 and perplexity is 61.22485281381738
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7374755859375 and perplexity of 114.14568669107166
Finished 31 epochs...
Completing Train Step...
At time: 971.7742326259613 and batch: 50, loss is 4.3818588542938235 and perplexity is 79.98657869554262
At time: 972.8540089130402 and batch: 100, loss is 4.385956411361694 and perplexity is 80.31500067078805
At time: 973.9328191280365 and batch: 150, loss is 4.352668771743774 and perplexity is 77.6855114175606
At time: 975.0103707313538 and batch: 200, loss is 4.343456125259399 and perplexity is 76.97310885900546
At time: 976.0874025821686 and batch: 250, loss is 4.339672574996948 and perplexity is 76.6824274833426
At time: 977.1636636257172 and batch: 300, loss is 4.353497543334961 and perplexity is 77.74992164946873
At time: 978.2405395507812 and batch: 350, loss is 4.347392511367798 and perplexity is 77.27670187308213
At time: 979.3188853263855 and batch: 400, loss is 4.344721508026123 and perplexity is 77.07057095488047
At time: 980.3952345848083 and batch: 450, loss is 4.30559063911438 and perplexity is 74.11297655090236
At time: 981.4717171192169 and batch: 500, loss is 4.361983680725098 and perplexity is 78.4125256645908
At time: 982.5497682094574 and batch: 550, loss is 4.341607942581176 and perplexity is 76.83097987314494
At time: 983.6266243457794 and batch: 600, loss is 4.298158082962036 and perplexity is 73.56416973627431
At time: 984.7032907009125 and batch: 650, loss is 4.302150249481201 and perplexity is 73.85843714312911
At time: 985.7809906005859 and batch: 700, loss is 4.310852746963501 and perplexity is 74.50399491466592
At time: 986.901535987854 and batch: 750, loss is 4.263730010986328 and perplexity is 71.07459867253954
At time: 987.9771046638489 and batch: 800, loss is 4.2532954597473145 and perplexity is 70.33682300397068
At time: 989.0555531978607 and batch: 850, loss is 4.22860239982605 and perplexity is 68.62126003916475
At time: 990.1359302997589 and batch: 900, loss is 4.2395813941955565 and perplexity is 69.37880338945045
At time: 991.2129533290863 and batch: 950, loss is 4.2184872055053715 and perplexity is 67.93064141861402
At time: 992.290070772171 and batch: 1000, loss is 4.221864233016968 and perplexity is 68.16043285117544
At time: 993.3750705718994 and batch: 1050, loss is 4.175640430450439 and perplexity is 65.0815064957583
At time: 994.4522149562836 and batch: 1100, loss is 4.153465523719787 and perplexity is 63.65421368776588
At time: 995.5288355350494 and batch: 1150, loss is 4.157701940536499 and perplexity is 63.92445148489327
At time: 996.6074929237366 and batch: 1200, loss is 4.1377661991119385 and perplexity is 62.66268902311477
At time: 997.6832873821259 and batch: 1250, loss is 4.1687092781066895 and perplexity is 64.63197634012168
At time: 998.7594187259674 and batch: 1300, loss is 4.141210651397705 and perplexity is 62.878899815667104
At time: 999.8376929759979 and batch: 1350, loss is 4.114598789215088 and perplexity is 61.227644143018104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.73747314453125 and perplexity of 114.14540801541888
Finished 32 epochs...
Completing Train Step...
At time: 1003.0530469417572 and batch: 50, loss is 4.38127477645874 and perplexity is 79.93987394875387
At time: 1004.1295347213745 and batch: 100, loss is 4.385319242477417 and perplexity is 80.26384275126793
At time: 1005.205141544342 and batch: 150, loss is 4.352013378143311 and perplexity is 77.63461351143167
At time: 1006.2807369232178 and batch: 200, loss is 4.342810087203979 and perplexity is 76.92339736092734
At time: 1007.3590576648712 and batch: 250, loss is 4.339014139175415 and perplexity is 76.6319536449206
At time: 1008.435875415802 and batch: 300, loss is 4.352859697341919 and perplexity is 77.7003449863041
At time: 1009.5116629600525 and batch: 350, loss is 4.346816339492798 and perplexity is 77.232190035336
At time: 1010.5895843505859 and batch: 400, loss is 4.3441621112823485 and perplexity is 77.02746998484254
At time: 1011.6653923988342 and batch: 450, loss is 4.305071773529053 and perplexity is 74.07453185262193
At time: 1012.7418594360352 and batch: 500, loss is 4.36145791053772 and perplexity is 78.37130953233557
At time: 1013.8185133934021 and batch: 550, loss is 4.341114540100097 and perplexity is 76.79308062761154
At time: 1014.9231266975403 and batch: 600, loss is 4.29772946357727 and perplexity is 73.53264546354094
At time: 1015.9989292621613 and batch: 650, loss is 4.301701145172119 and perplexity is 73.8252744480581
At time: 1017.0769395828247 and batch: 700, loss is 4.310476245880127 and perplexity is 74.47594935978705
At time: 1018.1527616977692 and batch: 750, loss is 4.263384561538697 and perplexity is 71.05005023205422
At time: 1019.2296659946442 and batch: 800, loss is 4.253023414611817 and perplexity is 70.31769081595341
At time: 1020.3165855407715 and batch: 850, loss is 4.228396863937378 and perplexity is 68.6071573568541
At time: 1021.3949284553528 and batch: 900, loss is 4.239383144378662 and perplexity is 69.36505041768925
At time: 1022.4731323719025 and batch: 950, loss is 4.218294353485107 and perplexity is 67.91754212033226
At time: 1023.5495681762695 and batch: 1000, loss is 4.221725673675537 and perplexity is 68.15098924075329
At time: 1024.6265273094177 and batch: 1050, loss is 4.175552816390991 and perplexity is 65.075804690562
At time: 1025.7033729553223 and batch: 1100, loss is 4.1533916425704955 and perplexity is 63.649511015022945
At time: 1026.7809960842133 and batch: 1150, loss is 4.1576924228668215 and perplexity is 63.92384307597506
At time: 1027.857560634613 and batch: 1200, loss is 4.137818417549133 and perplexity is 62.665961256240685
At time: 1028.9343349933624 and batch: 1250, loss is 4.168782787322998 and perplexity is 64.63672756067804
At time: 1030.0102026462555 and batch: 1300, loss is 4.141280946731567 and perplexity is 62.883320064282145
At time: 1031.0862617492676 and batch: 1350, loss is 4.114626526832581 and perplexity is 61.22934247554506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.737474772135417 and perplexity of 114.14559379911181
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 1034.2957513332367 and batch: 50, loss is 4.380971517562866 and perplexity is 79.91563514634583
At time: 1035.3991913795471 and batch: 100, loss is 4.38532787322998 and perplexity is 80.26453549162393
At time: 1036.4788641929626 and batch: 150, loss is 4.351989231109619 and perplexity is 77.63273888843696
At time: 1037.555935382843 and batch: 200, loss is 4.342843246459961 and perplexity is 76.92594812584193
At time: 1038.6338250637054 and batch: 250, loss is 4.338860206604004 and perplexity is 76.62015839910332
At time: 1039.710586309433 and batch: 300, loss is 4.3529328441619874 and perplexity is 77.70602872732934
At time: 1040.788993358612 and batch: 350, loss is 4.346881341934204 and perplexity is 77.23721047941225
At time: 1041.8934662342072 and batch: 400, loss is 4.344441976547241 and perplexity is 77.04903031498688
At time: 1042.9705264568329 and batch: 450, loss is 4.3050868034362795 and perplexity is 74.07564519433019
At time: 1044.0492599010468 and batch: 500, loss is 4.3612080001831055 and perplexity is 78.35172617772224
At time: 1045.1259746551514 and batch: 550, loss is 4.3406947898864745 and perplexity is 76.76085347976263
At time: 1046.203978061676 and batch: 600, loss is 4.297202110290527 and perplexity is 73.49387800424482
At time: 1047.280885219574 and batch: 650, loss is 4.3010749244689945 and perplexity is 73.77905800514188
At time: 1048.3594136238098 and batch: 700, loss is 4.309421653747559 and perplexity is 74.39744900972788
At time: 1049.438331604004 and batch: 750, loss is 4.262325067520141 and perplexity is 70.97481299255588
At time: 1050.5177590847015 and batch: 800, loss is 4.251812963485718 and perplexity is 70.23262618159814
At time: 1051.5945224761963 and batch: 850, loss is 4.226466569900513 and perplexity is 68.47485310425769
At time: 1052.6731531620026 and batch: 900, loss is 4.237263746261597 and perplexity is 69.21819393908741
At time: 1053.7501947879791 and batch: 950, loss is 4.216161661148071 and perplexity is 67.77284924623693
At time: 1054.8267159461975 and batch: 1000, loss is 4.219555988311767 and perplexity is 68.00328333248908
At time: 1055.9053587913513 and batch: 1050, loss is 4.173118228912354 and perplexity is 64.91756465406607
At time: 1056.9827082157135 and batch: 1100, loss is 4.150970964431763 and perplexity is 63.495622367754855
At time: 1058.0608186721802 and batch: 1150, loss is 4.154905185699463 and perplexity is 63.74592023643458
At time: 1059.1377341747284 and batch: 1200, loss is 4.1348674106597905 and perplexity is 62.48130616607266
At time: 1060.2146725654602 and batch: 1250, loss is 4.16587306022644 and perplexity is 64.44892568167218
At time: 1061.2982585430145 and batch: 1300, loss is 4.138276686668396 and perplexity is 62.69468571237625
At time: 1062.3764970302582 and batch: 1350, loss is 4.111867823600769 and perplexity is 61.06066166769892
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738189290364583 and perplexity of 114.22718205133592
Annealing...
Finished 34 epochs...
Completing Train Step...
At time: 1065.562799692154 and batch: 50, loss is 4.380799808502197 and perplexity is 79.90191408575103
At time: 1066.667364358902 and batch: 100, loss is 4.385227661132813 and perplexity is 80.25649241720757
At time: 1067.7458319664001 and batch: 150, loss is 4.351876592636108 and perplexity is 77.6239949476954
At time: 1068.848864555359 and batch: 200, loss is 4.3427078151702885 and perplexity is 76.9155306509199
At time: 1069.9330866336823 and batch: 250, loss is 4.3387424659729 and perplexity is 76.61113762436443
At time: 1071.0109674930573 and batch: 300, loss is 4.352754316329956 and perplexity is 77.69215727674172
At time: 1072.0861885547638 and batch: 350, loss is 4.346702632904052 and perplexity is 77.22340872572158
At time: 1073.1631367206573 and batch: 400, loss is 4.344237127304077 and perplexity is 77.03324849594237
At time: 1074.2394182682037 and batch: 450, loss is 4.304886779785156 and perplexity is 74.06082979508363
At time: 1075.3149464130402 and batch: 500, loss is 4.3610311698913575 and perplexity is 78.33787244403926
At time: 1076.3924117088318 and batch: 550, loss is 4.3405453395843505 and perplexity is 76.74938240421798
At time: 1077.4686992168427 and batch: 600, loss is 4.297053632736206 and perplexity is 73.48296662304878
At time: 1078.5454015731812 and batch: 650, loss is 4.300922126770019 and perplexity is 73.76778559606714
At time: 1079.6227502822876 and batch: 700, loss is 4.3092663288116455 and perplexity is 74.3858941281322
At time: 1080.699090719223 and batch: 750, loss is 4.262196598052978 and perplexity is 70.96569548182215
At time: 1081.7762207984924 and batch: 800, loss is 4.251618795394897 and perplexity is 70.21899057050226
At time: 1082.8530106544495 and batch: 850, loss is 4.226220703125 and perplexity is 68.45801948242017
At time: 1083.9364023208618 and batch: 900, loss is 4.236974501609803 and perplexity is 69.19817584188701
At time: 1085.0155546665192 and batch: 950, loss is 4.215865888595581 and perplexity is 67.75280686176558
At time: 1086.0924677848816 and batch: 1000, loss is 4.219273595809937 and perplexity is 67.98408242639968
At time: 1087.1685252189636 and batch: 1050, loss is 4.172814846038818 and perplexity is 64.89787276400055
At time: 1088.2461268901825 and batch: 1100, loss is 4.150674157142639 and perplexity is 63.47677920074163
At time: 1089.322414636612 and batch: 1150, loss is 4.154545373916626 and perplexity is 63.72298782914831
At time: 1090.3986899852753 and batch: 1200, loss is 4.134469795227051 and perplexity is 62.45646757291452
At time: 1091.4765474796295 and batch: 1250, loss is 4.1654811239242555 and perplexity is 64.42367075754481
At time: 1092.5522606372833 and batch: 1300, loss is 4.137891554832459 and perplexity is 62.6705446420101
At time: 1093.6290183067322 and batch: 1350, loss is 4.111509909629822 and perplexity is 61.0388111143552
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738245849609375 and perplexity of 114.23364283719428
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 1096.830001115799 and batch: 50, loss is 4.3807847118377685 and perplexity is 79.90070784247202
At time: 1097.9051191806793 and batch: 100, loss is 4.385216445922851 and perplexity is 80.25559232884169
At time: 1098.9817695617676 and batch: 150, loss is 4.351863651275635 and perplexity is 77.62299039409558
At time: 1100.0571155548096 and batch: 200, loss is 4.34268669128418 and perplexity is 76.9139059131709
At time: 1101.1325075626373 and batch: 250, loss is 4.338728742599487 and perplexity is 76.61008626832933
At time: 1102.2097313404083 and batch: 300, loss is 4.352730627059937 and perplexity is 77.69031682804913
At time: 1103.286913394928 and batch: 350, loss is 4.346679830551148 and perplexity is 77.22164787037921
At time: 1104.364096879959 and batch: 400, loss is 4.344202890396118 and perplexity is 77.03061116085117
At time: 1105.4429495334625 and batch: 450, loss is 4.3048586177825925 and perplexity is 74.05874412317357
At time: 1106.5202322006226 and batch: 500, loss is 4.361010189056397 and perplexity is 78.3362288673082
At time: 1107.5976114273071 and batch: 550, loss is 4.340525798797607 and perplexity is 76.74788267555672
At time: 1108.6768963336945 and batch: 600, loss is 4.297028179168701 and perplexity is 73.48109624320143
At time: 1109.7564392089844 and batch: 650, loss is 4.30090087890625 and perplexity is 73.76621820486018
At time: 1110.8342278003693 and batch: 700, loss is 4.3092427062988286 and perplexity is 74.3841369671491
At time: 1111.9186894893646 and batch: 750, loss is 4.26217625617981 and perplexity is 70.96425192132779
At time: 1112.995911359787 and batch: 800, loss is 4.251595325469971 and perplexity is 70.21734255540464
At time: 1114.0726327896118 and batch: 850, loss is 4.226188097000122 and perplexity is 68.45578736807856
At time: 1115.1501398086548 and batch: 900, loss is 4.236939182281494 and perplexity is 69.19573185195641
At time: 1116.2270059585571 and batch: 950, loss is 4.215828714370727 and perplexity is 67.75028825050282
At time: 1117.3115286827087 and batch: 1000, loss is 4.21923791885376 and perplexity is 67.98165700453632
At time: 1118.3882913589478 and batch: 1050, loss is 4.172776288986206 and perplexity is 64.89537054154545
At time: 1119.466474056244 and batch: 1100, loss is 4.150636434555054 and perplexity is 63.47438473754156
At time: 1120.5439960956573 and batch: 1150, loss is 4.15450089931488 and perplexity is 63.72015383766332
At time: 1121.6206030845642 and batch: 1200, loss is 4.1344193983078 and perplexity is 62.45332003867527
At time: 1122.697294473648 and batch: 1250, loss is 4.165430765151978 and perplexity is 64.42042654226788
At time: 1123.7755649089813 and batch: 1300, loss is 4.137843174934387 and perplexity is 62.66751272079083
At time: 1124.8524384498596 and batch: 1350, loss is 4.111465048789978 and perplexity is 61.03607292344477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738253580729166 and perplexity of 114.23452599458516
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 1128.084442615509 and batch: 50, loss is 4.3807834815979 and perplexity is 79.9006095454962
At time: 1129.1611359119415 and batch: 100, loss is 4.385215587615967 and perplexity is 80.25552344494385
At time: 1130.2389941215515 and batch: 150, loss is 4.351862735748291 and perplexity is 77.6229193281579
At time: 1131.3160157203674 and batch: 200, loss is 4.342684936523438 and perplexity is 76.91377094778669
At time: 1132.3953974246979 and batch: 250, loss is 4.338727760314941 and perplexity is 76.61001101546246
At time: 1133.472604751587 and batch: 300, loss is 4.352728404998779 and perplexity is 77.69014419560561
At time: 1134.5509266853333 and batch: 350, loss is 4.346677665710449 and perplexity is 77.22148069799404
At time: 1135.627863407135 and batch: 400, loss is 4.344199142456055 and perplexity is 77.03032245527852
At time: 1136.7044532299042 and batch: 450, loss is 4.304855842590332 and perplexity is 74.05853859620521
At time: 1137.7832200527191 and batch: 500, loss is 4.361008548736573 and perplexity is 78.33610037094444
At time: 1138.8617165088654 and batch: 550, loss is 4.340524454116821 and perplexity is 76.7477794742229
At time: 1139.940916776657 and batch: 600, loss is 4.297025880813599 and perplexity is 73.48092735774301
At time: 1141.0182814598083 and batch: 650, loss is 4.300899181365967 and perplexity is 73.7660929838395
At time: 1142.0963513851166 and batch: 700, loss is 4.3092409324646 and perplexity is 74.3840050221379
At time: 1143.1736772060394 and batch: 750, loss is 4.262174835205078 and perplexity is 70.9641510829906
At time: 1144.250344991684 and batch: 800, loss is 4.251593408584594 and perplexity is 70.2172079569365
At time: 1145.3340377807617 and batch: 850, loss is 4.226185140609741 and perplexity is 68.4555849863464
At time: 1146.420906305313 and batch: 900, loss is 4.2369360971450805 and perplexity is 69.19551837401369
At time: 1147.4982199668884 and batch: 950, loss is 4.2158253955841065 and perplexity is 67.75006340212573
At time: 1148.5766654014587 and batch: 1000, loss is 4.219234790802002 and perplexity is 67.9814443547272
At time: 1149.6570856571198 and batch: 1050, loss is 4.172772855758667 and perplexity is 64.89514774135458
At time: 1150.7696542739868 and batch: 1100, loss is 4.1506331396102905 and perplexity is 63.47417559329453
At time: 1151.8498542308807 and batch: 1150, loss is 4.154496860504151 and perplexity is 63.71989648454202
At time: 1152.92809009552 and batch: 1200, loss is 4.13441433429718 and perplexity is 62.45300377520009
At time: 1154.0139374732971 and batch: 1250, loss is 4.165425834655761 and perplexity is 64.42010891838156
At time: 1155.0959544181824 and batch: 1300, loss is 4.137838449478149 and perplexity is 62.66721658890161
At time: 1156.1726381778717 and batch: 1350, loss is 4.111460843086243 and perplexity is 61.03581622434468
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.738253580729166 and perplexity of 114.23452599458516
Annealing...
Model not improving. Stopping early with 114.14540801541888loss at 36 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea66240860>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'dropout': 0.20871861831774086, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 4.680527966079749, 'wordvec_dim': 200, 'lr': 9.727146940782237, 'num_layers': 1}, 'best_accuracy': -101.11735148778415}, {'params': {'dropout': 0.22207062611395245, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 6.608335587856741, 'wordvec_dim': 200, 'lr': 25.10613924621522, 'num_layers': 1}, 'best_accuracy': -163.33033409484332}, {'params': {'dropout': 0.5449135763513986, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 5.7852021323182194, 'wordvec_dim': 200, 'lr': 28.288861634932207, 'num_layers': 1}, 'best_accuracy': -186.24158550349685}, {'params': {'dropout': 0.2808414031148949, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 5.117491396780094, 'wordvec_dim': 200, 'lr': 24.99135641797138, 'num_layers': 1}, 'best_accuracy': -166.76690960626848}, {'params': {'dropout': 0.42163053845107057, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 2.451644449031984, 'wordvec_dim': 200, 'lr': 29.419371226210124, 'num_layers': 1}, 'best_accuracy': -176.14311070257799}, {'params': {'dropout': 0.0, 'tune_wordvecs': True, 'wordvec_source': '', 'data': 'wikitext', 'batch_size': 80, 'seq_len': 20, 'anneal': 8.0, 'wordvec_dim': 200, 'lr': 12.46522061517186, 'num_layers': 1}, 'best_accuracy': -114.14540801541888}]
