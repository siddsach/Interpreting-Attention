Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.421328067779541 and batch: 50, loss is 7.726166305541992 and perplexity is 2266.894938397684
At time: 3.917355537414551 and batch: 100, loss is 7.039582815170288 and perplexity is 1140.9115363462156
At time: 5.412198305130005 and batch: 150, loss is 6.807285919189453 and perplexity is 904.4128233846408
At time: 6.910906791687012 and batch: 200, loss is 6.64360538482666 and perplexity is 767.8584335386336
At time: 8.40708065032959 and batch: 250, loss is 6.566964159011841 and perplexity is 711.2074497254152
At time: 9.904544115066528 and batch: 300, loss is 6.482345085144043 and perplexity is 653.5016677862558
At time: 11.398496866226196 and batch: 350, loss is 6.443959903717041 and perplexity is 628.8922282072147
At time: 12.897847652435303 and batch: 400, loss is 6.412522621154785 and perplexity is 609.4291023500559
At time: 14.395987510681152 and batch: 450, loss is 6.315955505371094 and perplexity is 553.3305183615272
At time: 15.893259048461914 and batch: 500, loss is 6.298511419296265 and perplexity is 543.761873940415
At time: 17.39428162574768 and batch: 550, loss is 6.251015548706055 and perplexity is 518.5391591360617
At time: 18.891154289245605 and batch: 600, loss is 6.28763750076294 and perplexity is 537.8810831877453
At time: 20.38905358314514 and batch: 650, loss is 6.359001007080078 and perplexity is 577.6689808227899
At time: 21.886102199554443 and batch: 700, loss is 6.247871189117432 and perplexity is 516.9112462719316
At time: 23.38494110107422 and batch: 750, loss is 6.174470252990723 and perplexity is 480.3285039226338
At time: 24.886471033096313 and batch: 800, loss is 6.178900470733643 and perplexity is 482.4611844144743
At time: 26.386085510253906 and batch: 850, loss is 6.216968088150025 and perplexity is 501.1813883477823
At time: 27.887110233306885 and batch: 900, loss is 6.198474950790406 and perplexity is 491.9981472781523
At time: 29.38529109954834 and batch: 950, loss is 6.200973072052002 and perplexity is 493.2287547739305
At time: 30.884954690933228 and batch: 1000, loss is 6.182943477630615 and perplexity is 484.41572676228344
At time: 32.38452363014221 and batch: 1050, loss is 6.074447031021118 and perplexity is 434.6091107016881
At time: 33.8856999874115 and batch: 1100, loss is 6.149396648406983 and perplexity is 468.4346706976033
At time: 35.38325572013855 and batch: 1150, loss is 6.052026929855347 and perplexity is 424.9735492187899
At time: 36.885825395584106 and batch: 1200, loss is 6.134049253463745 and perplexity is 461.3003057958577
At time: 38.38921856880188 and batch: 1250, loss is 6.064878730773926 and perplexity is 430.4704716858243
At time: 39.88956165313721 and batch: 1300, loss is 6.079366416931152 and perplexity is 436.7523881192727
At time: 41.38979482650757 and batch: 1350, loss is 6.064695558547974 and perplexity is 430.3916286724644
At time: 42.89006018638611 and batch: 1400, loss is 6.083324546813965 and perplexity is 438.4845365709179
At time: 44.38628053665161 and batch: 1450, loss is 6.065788974761963 and perplexity is 430.8624832307132
At time: 45.886112213134766 and batch: 1500, loss is 6.044740400314331 and perplexity is 421.88822121597127
At time: 47.38479208946228 and batch: 1550, loss is 6.009631900787354 and perplexity is 407.33335358754505
At time: 48.88410663604736 and batch: 1600, loss is 6.008142910003662 and perplexity is 406.7272893022057
At time: 50.38384819030762 and batch: 1650, loss is 5.999526634216308 and perplexity is 403.2378692977953
At time: 51.883371114730835 and batch: 1700, loss is 6.0197672939300535 and perplexity is 411.4828300322414
At time: 53.381694316864014 and batch: 1750, loss is 6.023975591659546 and perplexity is 413.2181210412317
At time: 54.88367295265198 and batch: 1800, loss is 6.035632629394531 and perplexity is 418.06320506964965
At time: 56.38186860084534 and batch: 1850, loss is 5.979653215408325 and perplexity is 395.3032593037139
At time: 57.881393909454346 and batch: 1900, loss is 5.9568939113616945 and perplexity is 386.4080406902745
At time: 59.38197422027588 and batch: 1950, loss is 5.897805824279785 and perplexity is 364.23738959352085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.381628134084302 and perplexity of 217.37590458834939
finished 1 epochs...
Completing Train Step...
At time: 63.59005308151245 and batch: 50, loss is 5.653545370101929 and perplexity is 285.3011731224819
At time: 64.86788868904114 and batch: 100, loss is 5.563053636550904 and perplexity is 260.6174534511959
At time: 66.14507484436035 and batch: 150, loss is 5.440832223892212 and perplexity is 230.6340427753709
At time: 67.42072653770447 and batch: 200, loss is 5.382363271713257 and perplexity is 217.5357645477768
At time: 68.69493007659912 and batch: 250, loss is 5.3821354007720945 and perplexity is 217.48620011573416
At time: 69.96957778930664 and batch: 300, loss is 5.357676887512207 and perplexity is 212.23133604822365
At time: 71.28662848472595 and batch: 350, loss is 5.3062042713165285 and perplexity is 201.58361766571713
At time: 72.56354546546936 and batch: 400, loss is 5.25058533668518 and perplexity is 190.67784653870277
At time: 73.84016513824463 and batch: 450, loss is 5.175022296905517 and perplexity is 176.80055633778437
At time: 75.11461353302002 and batch: 500, loss is 5.159690608978272 and perplexity is 174.11057902113782
At time: 76.39374780654907 and batch: 550, loss is 5.1110731220245365 and perplexity is 165.84823480672395
At time: 77.67015433311462 and batch: 600, loss is 5.094873027801514 and perplexity is 163.18312358895975
At time: 78.94412016868591 and batch: 650, loss is 5.155994911193847 and perplexity is 173.46830649360578
At time: 80.22158885002136 and batch: 700, loss is 5.140782022476197 and perplexity is 170.8493241041969
At time: 81.49850988388062 and batch: 750, loss is 5.0636243152618405 and perplexity is 158.16271031616407
At time: 82.77511382102966 and batch: 800, loss is 5.064696674346924 and perplexity is 158.33240850792973
At time: 84.05245184898376 and batch: 850, loss is 5.058406715393066 and perplexity is 157.3396296994823
At time: 85.32794904708862 and batch: 900, loss is 5.059842739105225 and perplexity is 157.56573544634435
At time: 86.61087989807129 and batch: 950, loss is 5.091864957809448 and perplexity is 162.6929948719999
At time: 87.88854479789734 and batch: 1000, loss is 5.051055841445923 and perplexity is 156.1872864685227
At time: 89.16483402252197 and batch: 1050, loss is 4.964321985244751 and perplexity is 143.2114178940194
At time: 90.44277048110962 and batch: 1100, loss is 5.02736234664917 and perplexity is 152.53015994873553
At time: 91.71945524215698 and batch: 1150, loss is 4.950364389419556 and perplexity is 141.2264159583556
At time: 92.9986686706543 and batch: 1200, loss is 5.020239019393921 and perplexity is 151.44749835754743
At time: 94.27712488174438 and batch: 1250, loss is 4.978920555114746 and perplexity is 145.31743479937754
At time: 95.55498957633972 and batch: 1300, loss is 4.988941173553467 and perplexity is 146.7809256616757
At time: 96.83360004425049 and batch: 1350, loss is 4.906734914779663 and perplexity is 135.19726238600887
At time: 98.11152577400208 and batch: 1400, loss is 4.9112632369995115 and perplexity is 135.81086740542284
At time: 99.39077711105347 and batch: 1450, loss is 4.863746938705444 and perplexity is 129.50855473732722
At time: 100.66832423210144 and batch: 1500, loss is 4.819529132843018 and perplexity is 123.90673343032121
At time: 101.94795441627502 and batch: 1550, loss is 4.822284097671509 and perplexity is 124.24856277063772
At time: 103.22299647331238 and batch: 1600, loss is 4.878566513061523 and perplexity is 131.44210822677243
At time: 104.49947881698608 and batch: 1650, loss is 4.848419237136841 and perplexity is 127.53862209713193
At time: 105.77717781066895 and batch: 1700, loss is 4.859249296188355 and perplexity is 128.92737949416122
At time: 107.05616903305054 and batch: 1750, loss is 4.855640535354614 and perplexity is 128.4629499282876
At time: 108.33542346954346 and batch: 1800, loss is 4.8123143196105955 and perplexity is 123.01598664011915
At time: 109.61310863494873 and batch: 1850, loss is 4.817310981750488 and perplexity is 123.6321941715349
At time: 110.88983249664307 and batch: 1900, loss is 4.903880548477173 and perplexity is 134.81191010598184
At time: 112.16875863075256 and batch: 1950, loss is 4.823631534576416 and perplexity is 124.41609271216238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.631797329215116 and perplexity of 102.69848131244699
finished 2 epochs...
Completing Train Step...
At time: 116.30837559700012 and batch: 50, loss is 4.79849606513977 and perplexity is 121.3278111144345
At time: 117.58943724632263 and batch: 100, loss is 4.730315408706665 and perplexity is 113.3313023915152
At time: 118.86875796318054 and batch: 150, loss is 4.670026683807373 and perplexity is 106.70058957244318
At time: 120.14609622955322 and batch: 200, loss is 4.6526429271698 and perplexity is 104.86176166546278
At time: 121.42360758781433 and batch: 250, loss is 4.668400573730469 and perplexity is 106.52722366275577
At time: 122.7002227306366 and batch: 300, loss is 4.6811717510223385 and perplexity is 107.89642627719851
At time: 123.97563695907593 and batch: 350, loss is 4.688922300338745 and perplexity is 108.73593196274021
At time: 125.24992513656616 and batch: 400, loss is 4.633241100311279 and perplexity is 102.84686149912355
At time: 126.53003859519958 and batch: 450, loss is 4.613743553161621 and perplexity is 100.86102237388702
At time: 127.805330991745 and batch: 500, loss is 4.6225700950622555 and perplexity is 101.75521693148615
At time: 129.08437037467957 and batch: 550, loss is 4.594832830429077 and perplexity is 98.9715891265895
At time: 130.36227893829346 and batch: 600, loss is 4.5617888641357425 and perplexity is 95.75461871557347
At time: 131.64119052886963 and batch: 650, loss is 4.619731550216675 and perplexity is 101.46678973538263
At time: 132.91922450065613 and batch: 700, loss is 4.652779579162598 and perplexity is 104.87609221328933
At time: 134.19677543640137 and batch: 750, loss is 4.596267261505127 and perplexity is 99.11365891998192
At time: 135.48891520500183 and batch: 800, loss is 4.593315868377686 and perplexity is 98.82156679957603
At time: 136.7702386379242 and batch: 850, loss is 4.589967651367187 and perplexity is 98.49124405332434
At time: 138.04950308799744 and batch: 900, loss is 4.565973405838013 and perplexity is 96.15614743169222
At time: 139.32771158218384 and batch: 950, loss is 4.627352046966553 and perplexity is 102.24297076308794
At time: 140.6045835018158 and batch: 1000, loss is 4.601554889678955 and perplexity is 99.63912310061359
At time: 141.88146352767944 and batch: 1050, loss is 4.536224212646484 and perplexity is 93.33771059620742
At time: 143.1603081226349 and batch: 1100, loss is 4.589834938049316 and perplexity is 98.4781738208609
At time: 144.43834114074707 and batch: 1150, loss is 4.545056715011596 and perplexity is 94.16576767056864
At time: 145.71572637557983 and batch: 1200, loss is 4.609292287826538 and perplexity is 100.4130609385872
At time: 146.99545288085938 and batch: 1250, loss is 4.59074312210083 and perplexity is 98.56765075235823
At time: 148.27384901046753 and batch: 1300, loss is 4.587111091613769 and perplexity is 98.21029938815005
At time: 149.55533480644226 and batch: 1350, loss is 4.478776941299438 and perplexity is 88.12682245856168
At time: 150.83196091651917 and batch: 1400, loss is 4.486896247863769 and perplexity is 88.84526382266343
At time: 152.10800981521606 and batch: 1450, loss is 4.443065900802612 and perplexity is 85.03525207457615
At time: 153.38860964775085 and batch: 1500, loss is 4.4220717239379885 and perplexity is 83.26861637138343
At time: 154.66899871826172 and batch: 1550, loss is 4.429235391616821 and perplexity is 83.86726677327873
At time: 155.95017504692078 and batch: 1600, loss is 4.50689435005188 and perplexity is 90.63988518929689
At time: 157.23137187957764 and batch: 1650, loss is 4.4714194107055665 and perplexity is 87.48080612290367
At time: 158.50896692276 and batch: 1700, loss is 4.481054878234863 and perplexity is 88.32779862104809
At time: 159.7855052947998 and batch: 1750, loss is 4.476528625488282 and perplexity is 87.92890810060139
At time: 161.06414604187012 and batch: 1800, loss is 4.4417793083190915 and perplexity is 84.92591670853488
At time: 162.3427596092224 and batch: 1850, loss is 4.466265649795532 and perplexity is 87.03111077046573
At time: 163.62193489074707 and batch: 1900, loss is 4.5704030418396 and perplexity is 96.58302893094773
At time: 164.90082836151123 and batch: 1950, loss is 4.495815801620483 and perplexity is 89.64126865590796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469382494549419 and perplexity of 87.30279641253387
finished 3 epochs...
Completing Train Step...
At time: 169.0120837688446 and batch: 50, loss is 4.476291828155517 and perplexity is 87.90808923471351
At time: 170.30492424964905 and batch: 100, loss is 4.409040374755859 and perplexity is 82.19055351826395
At time: 171.58101391792297 and batch: 150, loss is 4.363158216476441 and perplexity is 78.50467808690028
At time: 172.85919189453125 and batch: 200, loss is 4.362356519699096 and perplexity is 78.44176636090509
At time: 174.13658332824707 and batch: 250, loss is 4.367273979187011 and perplexity is 78.82845054182883
At time: 175.41268634796143 and batch: 300, loss is 4.381315965652465 and perplexity is 79.94316667552022
At time: 176.69300198554993 and batch: 350, loss is 4.393468208312989 and perplexity is 80.92058230350301
At time: 177.9728775024414 and batch: 400, loss is 4.3406822299957275 and perplexity is 76.7598893778838
At time: 179.2512788772583 and batch: 450, loss is 4.344725847244263 and perplexity is 77.07090538162554
At time: 180.52982091903687 and batch: 500, loss is 4.359247894287109 and perplexity is 78.19829891324514
At time: 181.80483889579773 and batch: 550, loss is 4.33235836982727 and perplexity is 76.12360264688763
At time: 183.08210396766663 and batch: 600, loss is 4.301654739379883 and perplexity is 73.8218486072003
At time: 184.36471390724182 and batch: 650, loss is 4.353887310028076 and perplexity is 77.78023188589661
At time: 185.64715147018433 and batch: 700, loss is 4.39851595878601 and perplexity is 81.33008186741506
At time: 186.92658352851868 and batch: 750, loss is 4.345077848434448 and perplexity is 77.09803920733783
At time: 188.20602297782898 and batch: 800, loss is 4.343077592849731 and perplexity is 76.94397755654833
At time: 189.4827880859375 and batch: 850, loss is 4.34480580329895 and perplexity is 77.07706791351363
At time: 190.75863790512085 and batch: 900, loss is 4.305931167602539 and perplexity is 74.13821842830549
At time: 192.036682844162 and batch: 950, loss is 4.38498670578003 and perplexity is 80.2371565154021
At time: 193.3176290988922 and batch: 1000, loss is 4.361098041534424 and perplexity is 78.34311120144415
At time: 194.5964868068695 and batch: 1050, loss is 4.304443273544312 and perplexity is 74.02799063759132
At time: 195.87578058242798 and batch: 1100, loss is 4.346719245910645 and perplexity is 77.22469164937642
At time: 197.15780687332153 and batch: 1150, loss is 4.310280194282532 and perplexity is 74.46134966212642
At time: 198.47081995010376 and batch: 1200, loss is 4.3736354970932005 and perplexity is 79.33151757990643
At time: 199.748544216156 and batch: 1250, loss is 4.364415979385376 and perplexity is 78.60348048114408
At time: 201.0293185710907 and batch: 1300, loss is 4.355252714157104 and perplexity is 77.88650587262971
At time: 202.31039881706238 and batch: 1350, loss is 4.242260293960571 and perplexity is 69.56491142062755
At time: 203.58913135528564 and batch: 1400, loss is 4.25694507598877 and perplexity is 70.59399441861045
At time: 204.86802101135254 and batch: 1450, loss is 4.211743497848511 and perplexity is 67.47407822657249
At time: 206.1490159034729 and batch: 1500, loss is 4.196651430130005 and perplexity is 66.46340065934874
At time: 207.42699599266052 and batch: 1550, loss is 4.209727096557617 and perplexity is 67.3381604865398
At time: 208.706223487854 and batch: 1600, loss is 4.289411392211914 and perplexity is 72.92353250547468
At time: 209.98446822166443 and batch: 1650, loss is 4.248473105430603 and perplexity is 69.99845045383798
At time: 211.26307320594788 and batch: 1700, loss is 4.262112741470337 and perplexity is 70.95974479062008
At time: 212.54221844673157 and batch: 1750, loss is 4.255930795669555 and perplexity is 70.52242861944308
At time: 213.82368779182434 and batch: 1800, loss is 4.218794312477112 and perplexity is 67.95150659594518
At time: 215.10225296020508 and batch: 1850, loss is 4.254340620040893 and perplexity is 70.4103746885056
At time: 216.379816532135 and batch: 1900, loss is 4.3581769657135006 and perplexity is 78.1145989468737
At time: 217.66284346580505 and batch: 1950, loss is 4.283998718261719 and perplexity is 72.5298874978177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425511275890262 and perplexity of 83.55551622401308
finished 4 epochs...
Completing Train Step...
At time: 221.66587257385254 and batch: 50, loss is 4.270881948471069 and perplexity is 71.58474184052913
At time: 222.95713353157043 and batch: 100, loss is 4.208332033157348 and perplexity is 67.24428497977051
At time: 224.23526096343994 and batch: 150, loss is 4.163591318130493 and perplexity is 64.30203749910973
At time: 225.5050995349884 and batch: 200, loss is 4.169675312042236 and perplexity is 64.69444319027829
At time: 226.78101634979248 and batch: 250, loss is 4.16659336566925 and perplexity is 64.49536531697709
At time: 228.06010842323303 and batch: 300, loss is 4.186093697547912 and perplexity is 65.76538904237158
At time: 229.32564902305603 and batch: 350, loss is 4.199386582374573 and perplexity is 66.64543701393035
At time: 230.61145949363708 and batch: 400, loss is 4.1484544515609745 and perplexity is 63.33603570199656
At time: 231.89329981803894 and batch: 450, loss is 4.164613218307495 and perplexity is 64.36778134871619
At time: 233.17241764068604 and batch: 500, loss is 4.176607937812805 and perplexity is 65.14450380271178
At time: 234.451078414917 and batch: 550, loss is 4.153976221084594 and perplexity is 63.686730029253326
At time: 235.72673296928406 and batch: 600, loss is 4.125602326393127 and perplexity is 61.90508508974833
At time: 237.006028175354 and batch: 650, loss is 4.171092324256897 and perplexity is 64.78618098793929
At time: 238.2898712158203 and batch: 700, loss is 4.226735458374024 and perplexity is 68.49326767860522
At time: 239.56979537010193 and batch: 750, loss is 4.172110314369202 and perplexity is 64.85216626007791
At time: 240.8486578464508 and batch: 800, loss is 4.167936015129089 and perplexity is 64.58201814354996
At time: 242.13012027740479 and batch: 850, loss is 4.168256125450134 and perplexity is 64.60269482334438
At time: 243.40898060798645 and batch: 900, loss is 4.1281071424484255 and perplexity is 62.060340302486566
At time: 244.68917894363403 and batch: 950, loss is 4.216029682159424 and perplexity is 67.76390524435882
At time: 245.97033953666687 and batch: 1000, loss is 4.1924951457977295 and perplexity is 66.18773314165027
At time: 247.2487597465515 and batch: 1050, loss is 4.140301356315613 and perplexity is 62.821750328109026
At time: 248.5272080898285 and batch: 1100, loss is 4.175445957183838 and perplexity is 65.0688511132014
At time: 249.80952167510986 and batch: 1150, loss is 4.1445092725753785 and perplexity is 63.0866559522427
At time: 251.0882830619812 and batch: 1200, loss is 4.2070155572891235 and perplexity is 67.15581774658435
At time: 252.36732625961304 and batch: 1250, loss is 4.2006715345382695 and perplexity is 66.73112825520442
At time: 253.64590525627136 and batch: 1300, loss is 4.187318267822266 and perplexity is 65.8459727129879
At time: 254.9257640838623 and batch: 1350, loss is 4.07374454498291 and perplexity is 58.77664281693327
At time: 256.2046649456024 and batch: 1400, loss is 4.096365146636963 and perplexity is 60.121357630270374
At time: 257.4874792098999 and batch: 1450, loss is 4.052430591583252 and perplexity is 57.53713650453349
At time: 258.7697718143463 and batch: 1500, loss is 4.037215776443482 and perplexity is 56.668345615013884
At time: 260.0489168167114 and batch: 1550, loss is 4.054973568916321 and perplexity is 57.68363833494218
At time: 261.330677986145 and batch: 1600, loss is 4.130357995033264 and perplexity is 62.20018630720071
At time: 262.6067202091217 and batch: 1650, loss is 4.093513669967652 and perplexity is 59.95016717045608
At time: 263.88425040245056 and batch: 1700, loss is 4.104525880813599 and perplexity is 60.613999473733934
At time: 265.16272163391113 and batch: 1750, loss is 4.100707597732544 and perplexity is 60.38299935763716
At time: 266.44290566444397 and batch: 1800, loss is 4.0599912166595455 and perplexity is 57.97380187308374
At time: 267.724004983902 and batch: 1850, loss is 4.09797728061676 and perplexity is 60.21835948280019
At time: 269.00257992744446 and batch: 1900, loss is 4.203232173919678 and perplexity is 66.90222157083501
At time: 270.28262186050415 and batch: 1950, loss is 4.127974557876587 and perplexity is 62.05211260428437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411023516987646 and perplexity of 82.35371080457958
finished 5 epochs...
Completing Train Step...
At time: 274.41397762298584 and batch: 50, loss is 4.119026064872742 and perplexity is 61.49931674250206
At time: 275.7069330215454 and batch: 100, loss is 4.06214973449707 and perplexity is 58.09907451150902
At time: 276.9862253665924 and batch: 150, loss is 4.019575157165527 and perplexity is 55.677446637187344
At time: 278.2681403160095 and batch: 200, loss is 4.024171376228333 and perplexity is 55.93394138026096
At time: 279.5470190048218 and batch: 250, loss is 4.020255618095398 and perplexity is 55.715345857305806
At time: 280.8246409893036 and batch: 300, loss is 4.042111949920654 and perplexity is 56.946484017103494
At time: 282.10393714904785 and batch: 350, loss is 4.054563579559326 and perplexity is 57.65999350454772
At time: 283.3817038536072 and batch: 400, loss is 4.003993062973023 and perplexity is 54.816599735890065
At time: 284.6599688529968 and batch: 450, loss is 4.027288074493408 and perplexity is 56.108542546558866
At time: 285.937940120697 and batch: 500, loss is 4.043171172142029 and perplexity is 57.006834955288376
At time: 287.21695852279663 and batch: 550, loss is 4.021069149971009 and perplexity is 55.760690509280415
At time: 288.4974572658539 and batch: 600, loss is 3.992604737281799 and perplexity is 54.19587168015343
At time: 289.776736497879 and batch: 650, loss is 4.036981635093689 and perplexity is 56.65507876530071
At time: 291.0543007850647 and batch: 700, loss is 4.09018042087555 and perplexity is 59.75067100008747
At time: 292.33510971069336 and batch: 750, loss is 4.0413212394714355 and perplexity is 56.901473634579915
At time: 293.61173963546753 and batch: 800, loss is 4.034300808906555 and perplexity is 56.50339974989176
At time: 294.91712951660156 and batch: 850, loss is 4.034793996810913 and perplexity is 56.531273416116065
At time: 296.19593358039856 and batch: 900, loss is 3.9938810539245604 and perplexity is 54.26508693404212
At time: 297.4785647392273 and batch: 950, loss is 4.086524848937988 and perplexity is 59.53264686816999
At time: 298.7571177482605 and batch: 1000, loss is 4.063235516548157 and perplexity is 58.16219170335452
At time: 300.03447461128235 and batch: 1050, loss is 4.013181266784668 and perplexity is 55.32258682302169
At time: 301.31421732902527 and batch: 1100, loss is 4.047398157119751 and perplexity is 57.24831199062514
At time: 302.59180998802185 and batch: 1150, loss is 4.019151344299316 and perplexity is 55.65385481855597
At time: 303.87250685691833 and batch: 1200, loss is 4.079986305236816 and perplexity is 59.14465987222551
At time: 305.149649143219 and batch: 1250, loss is 4.079853124618531 and perplexity is 59.13678347435885
At time: 306.4306814670563 and batch: 1300, loss is 4.06156729221344 and perplexity is 58.06524500669714
At time: 307.70779156684875 and batch: 1350, loss is 3.9500993299484253 and perplexity is 51.94052582835762
At time: 308.9884192943573 and batch: 1400, loss is 3.9711234188079834 and perplexity is 53.04408810576628
At time: 310.26626896858215 and batch: 1450, loss is 3.9258188009262085 and perplexity is 50.694569830500924
At time: 311.5436906814575 and batch: 1500, loss is 3.9142720127105712 and perplexity is 50.112576909814784
At time: 312.8268086910248 and batch: 1550, loss is 3.933800654411316 and perplexity is 51.10082563967468
At time: 314.1059877872467 and batch: 1600, loss is 4.008447785377502 and perplexity is 55.06133718484417
At time: 315.3831932544708 and batch: 1650, loss is 3.9730830717086794 and perplexity is 53.14813802445195
At time: 316.6648223400116 and batch: 1700, loss is 3.9805462980270385 and perplexity is 53.54627846500991
At time: 317.94696617126465 and batch: 1750, loss is 3.979586763381958 and perplexity is 53.494923598034866
At time: 319.2265193462372 and batch: 1800, loss is 3.9386461687088015 and perplexity is 51.34903628940626
At time: 320.5054683685303 and batch: 1850, loss is 3.9775474166870115 and perplexity is 53.3859400677712
At time: 321.78615713119507 and batch: 1900, loss is 4.081771216392517 and perplexity is 59.25032210622918
At time: 323.0707354545593 and batch: 1950, loss is 4.004773063659668 and perplexity is 54.85937340089903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418095078579215 and perplexity of 82.93814413549939
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 327.17837023735046 and batch: 50, loss is 4.045978307723999 and perplexity is 57.16708568764186
At time: 328.4581186771393 and batch: 100, loss is 4.024514660835266 and perplexity is 55.95314593746777
At time: 329.7391080856323 and batch: 150, loss is 3.985192608833313 and perplexity is 53.795649997477256
At time: 331.017151594162 and batch: 200, loss is 3.9924800062179564 and perplexity is 54.18911219299065
At time: 332.2958507537842 and batch: 250, loss is 3.9971958589553833 and perplexity is 54.445263577450426
At time: 333.5754132270813 and batch: 300, loss is 4.007714896202088 and perplexity is 55.020998110678555
At time: 334.85380029678345 and batch: 350, loss is 4.021876630783081 and perplexity is 55.805734380517926
At time: 336.13202357292175 and batch: 400, loss is 3.968588285446167 and perplexity is 52.909784578967546
At time: 337.41247391700745 and batch: 450, loss is 3.981465344429016 and perplexity is 53.59551260033447
At time: 338.69259881973267 and batch: 500, loss is 3.992332739830017 and perplexity is 54.181132545753684
At time: 339.97027349472046 and batch: 550, loss is 3.9577409553527834 and perplexity is 52.33895625925305
At time: 341.2473568916321 and batch: 600, loss is 3.915844774246216 and perplexity is 50.19145405444106
At time: 342.5258116722107 and batch: 650, loss is 3.9506890773773193 and perplexity is 51.97116665420636
At time: 343.80337285995483 and batch: 700, loss is 4.001538228988648 and perplexity is 54.6821991170477
At time: 345.0867953300476 and batch: 750, loss is 3.950186014175415 and perplexity is 51.94502844783872
At time: 346.36631298065186 and batch: 800, loss is 3.9363281965255736 and perplexity is 51.23014849418494
At time: 347.643488407135 and batch: 850, loss is 3.9361986446380617 and perplexity is 51.223511961646935
At time: 348.9214873313904 and batch: 900, loss is 3.885210938453674 and perplexity is 48.67720927187257
At time: 350.19822096824646 and batch: 950, loss is 3.9805159854888914 and perplexity is 53.54465536600156
At time: 351.47628355026245 and batch: 1000, loss is 3.9518412256240847 and perplexity is 52.03107965044854
At time: 352.7590045928955 and batch: 1050, loss is 3.897620701789856 and perplexity is 49.285045671073036
At time: 354.039053440094 and batch: 1100, loss is 3.917060151100159 and perplexity is 50.25249267091184
At time: 355.3154249191284 and batch: 1150, loss is 3.889583959579468 and perplexity is 48.89054185033065
At time: 356.5950825214386 and batch: 1200, loss is 3.93142306804657 and perplexity is 50.979473333367125
At time: 357.8733549118042 and batch: 1250, loss is 3.9240488767623902 and perplexity is 50.60492364326242
At time: 359.14974641799927 and batch: 1300, loss is 3.9121681594848634 and perplexity is 50.007258229603856
At time: 360.42861771583557 and batch: 1350, loss is 3.791526131629944 and perplexity is 44.323992932798724
At time: 361.7053744792938 and batch: 1400, loss is 3.806023511886597 and perplexity is 44.97125517986266
At time: 362.983603477478 and batch: 1450, loss is 3.743941478729248 and perplexity is 42.26424592932027
At time: 364.2624547481537 and batch: 1500, loss is 3.7313969278335573 and perplexity is 41.73737155570359
At time: 365.53873562812805 and batch: 1550, loss is 3.745749373435974 and perplexity is 42.340724347452614
At time: 366.8181183338165 and batch: 1600, loss is 3.812649130821228 and perplexity is 45.27020685600464
At time: 368.0945382118225 and batch: 1650, loss is 3.768315715789795 and perplexity is 43.30706197365292
At time: 369.3746452331543 and batch: 1700, loss is 3.7603769874572754 and perplexity is 42.964620048955624
At time: 370.6525022983551 and batch: 1750, loss is 3.744687657356262 and perplexity is 42.29579437524382
At time: 371.9315941333771 and batch: 1800, loss is 3.7031200695037843 and perplexity is 40.57369983971569
At time: 373.2085907459259 and batch: 1850, loss is 3.7327181768417357 and perplexity is 41.79255346296807
At time: 374.4870958328247 and batch: 1900, loss is 3.832870144844055 and perplexity is 46.19493429788434
At time: 375.764750957489 and batch: 1950, loss is 3.754942789077759 and perplexity is 42.73177501636092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354765000454215 and perplexity of 77.84852881816317
finished 7 epochs...
Completing Train Step...
At time: 379.89969635009766 and batch: 50, loss is 3.9675465297698973 and perplexity is 52.85469421088628
At time: 381.17773604393005 and batch: 100, loss is 3.920476403236389 and perplexity is 50.42446143342514
At time: 382.45666456222534 and batch: 150, loss is 3.870040912628174 and perplexity is 47.944347569959305
At time: 383.7321081161499 and batch: 200, loss is 3.874923186302185 and perplexity is 48.17899734201599
At time: 385.01263070106506 and batch: 250, loss is 3.878625817298889 and perplexity is 48.357717053356694
At time: 386.2956237792969 and batch: 300, loss is 3.8880836725234986 and perplexity is 48.817246998639945
At time: 387.5733025074005 and batch: 350, loss is 3.9063395977020265 and perplexity is 49.71663561411264
At time: 388.8516380786896 and batch: 400, loss is 3.85705913066864 and perplexity is 47.325967028734105
At time: 390.14459896087646 and batch: 450, loss is 3.875188183784485 and perplexity is 48.191766346813694
At time: 391.42105531692505 and batch: 500, loss is 3.888868269920349 and perplexity is 48.85556391326659
At time: 392.7020528316498 and batch: 550, loss is 3.8552955770492554 and perplexity is 47.24257869979669
At time: 393.9803252220154 and batch: 600, loss is 3.8198403692245484 and perplexity is 45.59692906672257
At time: 395.2596085071564 and batch: 650, loss is 3.85493510723114 and perplexity is 47.22555224499138
At time: 396.53946018218994 and batch: 700, loss is 3.9109715843200683 and perplexity is 49.947456572071225
At time: 397.8170657157898 and batch: 750, loss is 3.8586242055892943 and perplexity is 47.40009370459631
At time: 399.0936529636383 and batch: 800, loss is 3.8472804737091066 and perplexity is 46.86543797940353
At time: 400.37477254867554 and batch: 850, loss is 3.8498224782943726 and perplexity is 46.984721683266606
At time: 401.6553854942322 and batch: 900, loss is 3.8014971685409544 and perplexity is 44.76815982463663
At time: 402.93230271339417 and batch: 950, loss is 3.8988402891159057 and perplexity is 49.345189756164395
At time: 404.213928937912 and batch: 1000, loss is 3.8713066720962526 and perplexity is 48.00507200499368
At time: 405.4941670894623 and batch: 1050, loss is 3.8216068887710573 and perplexity is 45.677548119781314
At time: 406.77244448661804 and batch: 1100, loss is 3.8411394643783567 and perplexity is 46.57851877592594
At time: 408.0551960468292 and batch: 1150, loss is 3.8183631563186644 and perplexity is 45.529622419999605
At time: 409.3350462913513 and batch: 1200, loss is 3.8618020677566527 and perplexity is 47.55096426506482
At time: 410.6139178276062 and batch: 1250, loss is 3.8574646711349487 and perplexity is 47.3451635156845
At time: 411.892945766449 and batch: 1300, loss is 3.847946915626526 and perplexity is 46.89668148158459
At time: 413.1776773929596 and batch: 1350, loss is 3.729709014892578 and perplexity is 41.66698192862545
At time: 414.4577066898346 and batch: 1400, loss is 3.74866895198822 and perplexity is 42.46452204876378
At time: 415.73767828941345 and batch: 1450, loss is 3.687971911430359 and perplexity is 39.96371476034926
At time: 417.0202429294586 and batch: 1500, loss is 3.6780760192871096 and perplexity is 39.57018850756748
At time: 418.29984307289124 and batch: 1550, loss is 3.6954253482818604 and perplexity is 40.262694614278516
At time: 419.5787386894226 and batch: 1600, loss is 3.7672519636154176 and perplexity is 43.261018486084346
At time: 420.85954332351685 and batch: 1650, loss is 3.723753261566162 and perplexity is 41.41956118222365
At time: 422.1398754119873 and batch: 1700, loss is 3.721254563331604 and perplexity is 41.31619539156108
At time: 423.4177339076996 and batch: 1750, loss is 3.709866313934326 and perplexity is 40.848345307380484
At time: 424.6966600418091 and batch: 1800, loss is 3.6713303565979003 and perplexity is 39.30415964262118
At time: 425.9758388996124 and batch: 1850, loss is 3.7056707191467284 and perplexity is 40.677321227474174
At time: 427.2542428970337 and batch: 1900, loss is 3.8111774635314943 and perplexity is 45.2036331725468
At time: 428.5337462425232 and batch: 1950, loss is 3.734512529373169 and perplexity is 41.86761135709191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359183945766715 and perplexity of 78.19329840762151
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 432.67647552490234 and batch: 50, loss is 3.938620686531067 and perplexity is 51.347727820808416
At time: 433.9543013572693 and batch: 100, loss is 3.924968876838684 and perplexity is 50.651501599451386
At time: 435.2305715084076 and batch: 150, loss is 3.887841348648071 and perplexity is 48.80541884733915
At time: 436.511687040329 and batch: 200, loss is 3.900034399032593 and perplexity is 49.40414853121626
At time: 437.7924427986145 and batch: 250, loss is 3.909788131713867 and perplexity is 49.88838108783068
At time: 439.07009196281433 and batch: 300, loss is 3.9213558292388915 and perplexity is 50.468825520578555
At time: 440.34886479377747 and batch: 350, loss is 3.9459805870056153 and perplexity is 51.72703611059442
At time: 441.62825655937195 and batch: 400, loss is 3.8959353590011596 and perplexity is 49.2020534295927
At time: 442.9098882675171 and batch: 450, loss is 3.9189247703552246 and perplexity is 50.346281849741565
At time: 444.18872332572937 and batch: 500, loss is 3.9285516786575316 and perplexity is 50.833301373317276
At time: 445.46787118911743 and batch: 550, loss is 3.902839436531067 and perplexity is 49.54292356401906
At time: 446.74753999710083 and batch: 600, loss is 3.851994743347168 and perplexity is 47.0868958867425
At time: 448.02653098106384 and batch: 650, loss is 3.8698670768737795 and perplexity is 47.93601385250056
At time: 449.3058702945709 and batch: 700, loss is 3.9234158039093017 and perplexity is 50.57289717848359
At time: 450.5828654766083 and batch: 750, loss is 3.8659212493896487 and perplexity is 47.74723929241335
At time: 451.8609194755554 and batch: 800, loss is 3.852810888290405 and perplexity is 47.12534130509605
At time: 453.1381311416626 and batch: 850, loss is 3.8528993463516237 and perplexity is 47.129510105801465
At time: 454.43321919441223 and batch: 900, loss is 3.7964145517349244 and perplexity is 44.54119769250285
At time: 455.7096242904663 and batch: 950, loss is 3.9018313884735107 and perplexity is 49.49300707948926
At time: 456.9875259399414 and batch: 1000, loss is 3.8699064826965333 and perplexity is 47.93790284778441
At time: 458.26508831977844 and batch: 1050, loss is 3.8130732345581055 and perplexity is 45.28941019171688
At time: 459.5417683124542 and batch: 1100, loss is 3.8357567977905274 and perplexity is 46.32847569218634
At time: 460.82314348220825 and batch: 1150, loss is 3.81780433177948 and perplexity is 45.50418645751346
At time: 462.0993950366974 and batch: 1200, loss is 3.845806884765625 and perplexity is 46.79642844649564
At time: 463.3755462169647 and batch: 1250, loss is 3.8388389348983765 and perplexity is 46.47148668279592
At time: 464.65395736694336 and batch: 1300, loss is 3.8238781785964964 and perplexity is 45.78141297902466
At time: 465.9328911304474 and batch: 1350, loss is 3.700970664024353 and perplexity is 40.48658416395395
At time: 467.21169424057007 and batch: 1400, loss is 3.720066533088684 and perplexity is 41.26713964753709
At time: 468.4886784553528 and batch: 1450, loss is 3.649395980834961 and perplexity is 38.4514336304894
At time: 469.76693081855774 and batch: 1500, loss is 3.636849899291992 and perplexity is 37.97203240047492
At time: 471.0445702075958 and batch: 1550, loss is 3.6548179054260252 and perplexity is 38.660480610415576
At time: 472.3237428665161 and batch: 1600, loss is 3.726753420829773 and perplexity is 41.54401305677254
At time: 473.601633310318 and batch: 1650, loss is 3.6828988790512085 and perplexity is 39.76149091912285
At time: 474.878297328949 and batch: 1700, loss is 3.6732513380050658 and perplexity is 39.37973476848431
At time: 476.15845561027527 and batch: 1750, loss is 3.6581621599197387 and perplexity is 38.78998752777041
At time: 477.4345672130585 and batch: 1800, loss is 3.6156333541870116 and perplexity is 37.17488333911452
At time: 478.7155110836029 and batch: 1850, loss is 3.644824800491333 and perplexity is 38.27606631607199
At time: 479.9921796321869 and batch: 1900, loss is 3.7559608840942382 and perplexity is 42.77530217718343
At time: 481.2686619758606 and batch: 1950, loss is 3.686702299118042 and perplexity is 39.91300853148102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3341677643531975 and perplexity of 76.26146496285831
finished 9 epochs...
Completing Train Step...
At time: 485.3569498062134 and batch: 50, loss is 3.941739592552185 and perplexity is 51.50812656255598
At time: 486.66754937171936 and batch: 100, loss is 3.9005312490463258 and perplexity is 49.42870108205498
At time: 487.94351291656494 and batch: 150, loss is 3.847529444694519 and perplexity is 46.87710756631305
At time: 489.22154545783997 and batch: 200, loss is 3.8528890228271484 and perplexity is 47.12902356566179
At time: 490.4982168674469 and batch: 250, loss is 3.8579345464706423 and perplexity is 47.36741506760321
At time: 491.7745130062103 and batch: 300, loss is 3.8657687759399413 and perplexity is 47.73995966111379
At time: 493.05316138267517 and batch: 350, loss is 3.8903959941864015 and perplexity is 48.93025878584546
At time: 494.33159828186035 and batch: 400, loss is 3.8388023376464844 and perplexity is 46.46978598521261
At time: 495.60801100730896 and batch: 450, loss is 3.865823521614075 and perplexity is 47.742573288930295
At time: 496.88568592071533 and batch: 500, loss is 3.8753858375549317 and perplexity is 48.20129257255283
At time: 498.16132497787476 and batch: 550, loss is 3.8507441091537475 and perplexity is 47.02804421331282
At time: 499.43525552749634 and batch: 600, loss is 3.8049713706970216 and perplexity is 44.923963952827584
At time: 500.71046209335327 and batch: 650, loss is 3.8247190809249876 and perplexity is 45.819926866739785
At time: 501.9880106449127 and batch: 700, loss is 3.8809172773361205 and perplexity is 48.46865388459177
At time: 503.2638235092163 and batch: 750, loss is 3.824819655418396 and perplexity is 45.824535414419714
At time: 504.5409984588623 and batch: 800, loss is 3.8133039331436156 and perplexity is 45.29985959987219
At time: 505.817800283432 and batch: 850, loss is 3.814062762260437 and perplexity is 45.33424749794354
At time: 507.0935640335083 and batch: 900, loss is 3.7605713844299316 and perplexity is 42.972973052897494
At time: 508.3702402114868 and batch: 950, loss is 3.8668013525009157 and perplexity is 47.78928028375898
At time: 509.64702248573303 and batch: 1000, loss is 3.835430450439453 and perplexity is 46.31335898364794
At time: 510.9230239391327 and batch: 1050, loss is 3.782102470397949 and perplexity is 43.90826057599918
At time: 512.2017669677734 and batch: 1100, loss is 3.80477237701416 and perplexity is 44.915025257193356
At time: 513.4761853218079 and batch: 1150, loss is 3.7879762077331542 and perplexity is 44.16692508548459
At time: 514.7532806396484 and batch: 1200, loss is 3.8192620515823363 and perplexity is 45.570567181718914
At time: 516.0289361476898 and batch: 1250, loss is 3.81492130279541 and perplexity is 45.37318549957767
At time: 517.3057391643524 and batch: 1300, loss is 3.8013600397109983 and perplexity is 44.76202124015867
At time: 518.5830545425415 and batch: 1350, loss is 3.6807796144485474 and perplexity is 39.67731502586921
At time: 519.8625814914703 and batch: 1400, loss is 3.702105374336243 and perplexity is 40.53255078296418
At time: 521.1404588222504 and batch: 1450, loss is 3.634002184867859 and perplexity is 37.86405271671747
At time: 522.416832447052 and batch: 1500, loss is 3.6234927797317504 and perplexity is 37.46820773758806
At time: 523.6942856311798 and batch: 1550, loss is 3.6445755910873414 and perplexity is 38.2665287488733
At time: 524.9685225486755 and batch: 1600, loss is 3.718749175071716 and perplexity is 41.21281184272653
At time: 526.2393710613251 and batch: 1650, loss is 3.6754416942596437 and perplexity is 39.466084951146186
At time: 527.5105354785919 and batch: 1700, loss is 3.668578267097473 and perplexity is 39.19613978588089
At time: 528.7862358093262 and batch: 1750, loss is 3.655375809669495 and perplexity is 38.68205547439717
At time: 530.0633895397186 and batch: 1800, loss is 3.6156443786621093 and perplexity is 37.17529317494927
At time: 531.3399920463562 and batch: 1850, loss is 3.647228231430054 and perplexity is 38.3681708371597
At time: 532.617849111557 and batch: 1900, loss is 3.758782272338867 and perplexity is 42.8961583227906
At time: 533.8942143917084 and batch: 1950, loss is 3.689126582145691 and perplexity is 40.009886342816095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334848235374273 and perplexity of 76.31337633988107
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 537.9686000347137 and batch: 50, loss is 3.9363782024383545 and perplexity is 51.232710368576186
At time: 539.2602074146271 and batch: 100, loss is 3.9147716760635376 and perplexity is 50.13762258470119
At time: 540.5361914634705 and batch: 150, loss is 3.8704972505569457 and perplexity is 47.96623138705382
At time: 541.8128468990326 and batch: 200, loss is 3.8847927474975585 and perplexity is 48.65685715901749
At time: 543.0908725261688 and batch: 250, loss is 3.8906639623641968 and perplexity is 48.94337229505447
At time: 544.3703713417053 and batch: 300, loss is 3.897465286254883 and perplexity is 49.27738660451828
At time: 545.6456882953644 and batch: 350, loss is 3.926442232131958 and perplexity is 50.7261842609826
At time: 546.9245686531067 and batch: 400, loss is 3.8773471450805665 and perplexity is 48.29592289967232
At time: 548.2047915458679 and batch: 450, loss is 3.9079469060897827 and perplexity is 49.79660983394601
At time: 549.500519990921 and batch: 500, loss is 3.918492612838745 and perplexity is 50.32452902627504
At time: 550.7766506671906 and batch: 550, loss is 3.901990032196045 and perplexity is 49.500859457220514
At time: 552.055196762085 and batch: 600, loss is 3.847468681335449 and perplexity is 46.874259242331576
At time: 553.33132147789 and batch: 650, loss is 3.8575717544555665 and perplexity is 47.35023366446829
At time: 554.607367515564 and batch: 700, loss is 3.9107327604293824 and perplexity is 49.935529350472244
At time: 555.8844680786133 and batch: 750, loss is 3.854378833770752 and perplexity is 47.19928922901194
At time: 557.1653962135315 and batch: 800, loss is 3.8392552661895754 and perplexity is 46.490838244901404
At time: 558.4458248615265 and batch: 850, loss is 3.8402369022369385 and perplexity is 46.53649773442864
At time: 559.7241108417511 and batch: 900, loss is 3.777542996406555 and perplexity is 43.70851771112869
At time: 561.0010352134705 and batch: 950, loss is 3.8851230573654174 and perplexity is 48.67293165371208
At time: 562.2794806957245 and batch: 1000, loss is 3.849957675933838 and perplexity is 46.991074336151286
At time: 563.557475566864 and batch: 1050, loss is 3.7916070413589478 and perplexity is 44.32757932014014
At time: 564.8347873687744 and batch: 1100, loss is 3.80885630607605 and perplexity is 45.09883010166442
At time: 566.1100523471832 and batch: 1150, loss is 3.801461944580078 and perplexity is 44.76658294049867
At time: 567.3878943920135 and batch: 1200, loss is 3.827525143623352 and perplexity is 45.94868101598601
At time: 568.6655969619751 and batch: 1250, loss is 3.822386088371277 and perplexity is 45.71315391722531
At time: 569.941529750824 and batch: 1300, loss is 3.8072234201431274 and perplexity is 45.025248947565096
At time: 571.2157418727875 and batch: 1350, loss is 3.674673094749451 and perplexity is 39.435762991797766
At time: 572.4979281425476 and batch: 1400, loss is 3.6951227521896364 and perplexity is 40.25051312335455
At time: 573.7762808799744 and batch: 1450, loss is 3.6275109815597535 and perplexity is 37.61906544378834
At time: 575.054018497467 and batch: 1500, loss is 3.6139192390441894 and perplexity is 37.111215890907765
At time: 576.332081079483 and batch: 1550, loss is 3.6349154615402224 and perplexity is 37.89864886830924
At time: 577.6106069087982 and batch: 1600, loss is 3.7086505270004273 and perplexity is 40.79871260039637
At time: 578.8875946998596 and batch: 1650, loss is 3.667003970146179 and perplexity is 39.13448196910442
At time: 580.1656115055084 and batch: 1700, loss is 3.6582072973251343 and perplexity is 38.79173844667841
At time: 581.4452650547028 and batch: 1750, loss is 3.645811104774475 and perplexity is 38.31383678774844
At time: 582.7229845523834 and batch: 1800, loss is 3.6063982391357423 and perplexity is 36.83314941928846
At time: 583.9984085559845 and batch: 1850, loss is 3.6276554012298585 and perplexity is 37.62449876913947
At time: 585.276358127594 and batch: 1900, loss is 3.7361050844192505 and perplexity is 41.934340954000696
At time: 586.5560026168823 and batch: 1950, loss is 3.6755575275421144 and perplexity is 39.470656702087695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319706122819768 and perplexity of 75.16653531642478
finished 11 epochs...
Completing Train Step...
At time: 590.6645560264587 and batch: 50, loss is 3.937847990989685 and perplexity is 51.308066985309885
At time: 591.9569053649902 and batch: 100, loss is 3.9034389448165894 and perplexity is 49.57263386207977
At time: 593.2335541248322 and batch: 150, loss is 3.85327730178833 and perplexity is 47.14732632703201
At time: 594.5120956897736 and batch: 200, loss is 3.862629656791687 and perplexity is 47.590333210102514
At time: 595.7872955799103 and batch: 250, loss is 3.867061748504639 and perplexity is 47.801726041708164
At time: 597.0625538825989 and batch: 300, loss is 3.869560914039612 and perplexity is 47.921339873068966
At time: 598.338894367218 and batch: 350, loss is 3.8973484420776368 and perplexity is 49.27162916519181
At time: 599.6159036159515 and batch: 400, loss is 3.8472275018692015 and perplexity is 46.86295549667722
At time: 600.8930950164795 and batch: 450, loss is 3.8777733421325684 and perplexity is 48.31651086658963
At time: 602.1715066432953 and batch: 500, loss is 3.8893107652664183 and perplexity is 48.87718705664513
At time: 603.4506149291992 and batch: 550, loss is 3.872465786933899 and perplexity is 48.06074765724068
At time: 604.7333519458771 and batch: 600, loss is 3.822131247520447 and perplexity is 45.70150582245516
At time: 606.0113050937653 and batch: 650, loss is 3.833779649734497 and perplexity is 46.236967928540714
At time: 607.2881639003754 and batch: 700, loss is 3.8882568502426147 and perplexity is 48.82570179019832
At time: 608.5631506443024 and batch: 750, loss is 3.8336444520950317 and perplexity is 46.230717222170625
At time: 609.8394541740417 and batch: 800, loss is 3.8191971254348753 and perplexity is 45.567608556401304
At time: 611.114289522171 and batch: 850, loss is 3.8207809782028197 and perplexity is 45.639838124743314
At time: 612.3911552429199 and batch: 900, loss is 3.7591260623931886 and perplexity is 42.91090813066393
At time: 613.681608915329 and batch: 950, loss is 3.86751980304718 and perplexity is 47.82362685496345
At time: 614.9470748901367 and batch: 1000, loss is 3.833305792808533 and perplexity is 46.21506341126566
At time: 616.2078461647034 and batch: 1050, loss is 3.7767081451416016 and perplexity is 43.6720428274982
At time: 617.4632878303528 and batch: 1100, loss is 3.795591502189636 and perplexity is 44.50455316219605
At time: 618.7175228595734 and batch: 1150, loss is 3.7886561822891234 and perplexity is 44.19696768370176
At time: 619.9670839309692 and batch: 1200, loss is 3.816560831069946 and perplexity is 45.447637136214176
At time: 621.2165992259979 and batch: 1250, loss is 3.8124013328552246 and perplexity is 45.258990380592465
At time: 622.4775190353394 and batch: 1300, loss is 3.7984935569763185 and perplexity is 44.63389540208693
At time: 623.7428851127625 and batch: 1350, loss is 3.6683031511306763 and perplexity is 39.185357785207266
At time: 625.0039196014404 and batch: 1400, loss is 3.6905382871627808 and perplexity is 40.06640838693912
At time: 626.2563681602478 and batch: 1450, loss is 3.6245524787902834 and perplexity is 37.5079338071742
At time: 627.5073716640472 and batch: 1500, loss is 3.6134782218933106 and perplexity is 37.09485281667331
At time: 628.7569093704224 and batch: 1550, loss is 3.636557903289795 and perplexity is 37.96094633744048
At time: 630.0284616947174 and batch: 1600, loss is 3.710916166305542 and perplexity is 40.891252558760485
At time: 631.3021855354309 and batch: 1650, loss is 3.670105390548706 and perplexity is 39.25604285819729
At time: 632.5841000080109 and batch: 1700, loss is 3.662403917312622 and perplexity is 38.9548747026049
At time: 633.8629295825958 and batch: 1750, loss is 3.6513639450073243 and perplexity is 38.527179182069936
At time: 635.1393783092499 and batch: 1800, loss is 3.612456750869751 and perplexity is 37.05698084525156
At time: 636.4171695709229 and batch: 1850, loss is 3.634461159706116 and perplexity is 37.881435352980056
At time: 637.692836523056 and batch: 1900, loss is 3.7434596729278566 and perplexity is 42.24388767519638
At time: 638.9694247245789 and batch: 1950, loss is 3.6822150850296023 and perplexity is 39.7343115429487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318226517078489 and perplexity of 75.05540071718904
finished 12 epochs...
Completing Train Step...
At time: 643.1157274246216 and batch: 50, loss is 3.9330299282073975 and perplexity is 51.06145606784149
At time: 644.3906869888306 and batch: 100, loss is 3.89559317111969 and perplexity is 49.18521996343399
At time: 645.6844074726105 and batch: 150, loss is 3.8443123435974123 and perplexity is 46.72654149512861
At time: 646.9601557254791 and batch: 200, loss is 3.852667140960693 and perplexity is 47.11856764998077
At time: 648.239330291748 and batch: 250, loss is 3.856371159553528 and perplexity is 47.29341932764645
At time: 649.5177114009857 and batch: 300, loss is 3.8578768968582153 and perplexity is 47.364684433193666
At time: 650.7968027591705 and batch: 350, loss is 3.8853747129440306 and perplexity is 48.685182009860775
At time: 652.0723748207092 and batch: 400, loss is 3.8346956634521483 and perplexity is 46.27934102963391
At time: 653.3483304977417 and batch: 450, loss is 3.865487370491028 and perplexity is 47.72652726639742
At time: 654.6246836185455 and batch: 500, loss is 3.876803984642029 and perplexity is 48.26969758793123
At time: 655.9006071090698 and batch: 550, loss is 3.8597612237930297 and perplexity is 47.45401912528007
At time: 657.1791808605194 and batch: 600, loss is 3.8107742071151733 and perplexity is 45.185408192346024
At time: 658.4562304019928 and batch: 650, loss is 3.822933702468872 and perplexity is 45.73819394026498
At time: 659.7310774326324 and batch: 700, loss is 3.878057656288147 and perplexity is 48.330249887583705
At time: 661.0073981285095 and batch: 750, loss is 3.824012489318848 and perplexity is 45.78756232662456
At time: 662.2846918106079 and batch: 800, loss is 3.809832663536072 and perplexity is 45.1428841836386
At time: 663.5640225410461 and batch: 850, loss is 3.811312313079834 and perplexity is 45.2097292730824
At time: 664.8440186977386 and batch: 900, loss is 3.7503283262252807 and perplexity is 42.5350450785077
At time: 666.1226975917816 and batch: 950, loss is 3.8591413784027098 and perplexity is 47.42461408450407
At time: 667.4004783630371 and batch: 1000, loss is 3.8252295780181886 and perplexity is 45.84332377773535
At time: 668.6781034469604 and batch: 1050, loss is 3.769442009925842 and perplexity is 43.35586594225597
At time: 669.9577684402466 and batch: 1100, loss is 3.788884048461914 and perplexity is 44.20703982508336
At time: 671.2345986366272 and batch: 1150, loss is 3.7818327379226684 and perplexity is 43.89641868933124
At time: 672.5125198364258 and batch: 1200, loss is 3.8106406211853026 and perplexity is 45.17937246072945
At time: 673.7916035652161 and batch: 1250, loss is 3.806921944618225 and perplexity is 45.01167698291514
At time: 675.0701138973236 and batch: 1300, loss is 3.793642158508301 and perplexity is 44.417882995115086
At time: 676.3486478328705 and batch: 1350, loss is 3.6642226123809816 and perplexity is 39.02578620476884
At time: 677.6275622844696 and batch: 1400, loss is 3.687278232574463 and perplexity is 39.936002389271124
At time: 678.9065141677856 and batch: 1450, loss is 3.622005987167358 and perplexity is 37.4125416771195
At time: 680.1853952407837 and batch: 1500, loss is 3.6119126987457277 and perplexity is 37.036825399416514
At time: 681.4631078243256 and batch: 1550, loss is 3.635951237678528 and perplexity is 37.937923720947374
At time: 682.7410569190979 and batch: 1600, loss is 3.7108020257949828 and perplexity is 40.886585476672664
At time: 684.0187954902649 and batch: 1650, loss is 3.66983446598053 and perplexity is 39.24540887230669
At time: 685.3031301498413 and batch: 1700, loss is 3.662483644485474 and perplexity is 38.957980588443824
At time: 686.5812051296234 and batch: 1750, loss is 3.65204345703125 and perplexity is 38.55336776029131
At time: 687.8572509288788 and batch: 1800, loss is 3.6133379983901976 and perplexity is 37.089651611138045
At time: 689.137983083725 and batch: 1850, loss is 3.6355814027786253 and perplexity is 37.92389554693958
At time: 690.4165630340576 and batch: 1900, loss is 3.7447585821151734 and perplexity is 42.29879430064608
At time: 691.6943306922913 and batch: 1950, loss is 3.683142957687378 and perplexity is 39.771197034077915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318168604651163 and perplexity of 75.05105420260944
finished 13 epochs...
Completing Train Step...
At time: 695.8368704319 and batch: 50, loss is 3.9274274778366087 and perplexity is 50.776186644411
At time: 697.1170778274536 and batch: 100, loss is 3.8886996793746946 and perplexity is 48.84732802135446
At time: 698.394900560379 and batch: 150, loss is 3.836926164627075 and perplexity is 46.38268236281313
At time: 699.6727895736694 and batch: 200, loss is 3.844811420440674 and perplexity is 46.74986745019237
At time: 700.9506795406342 and batch: 250, loss is 3.8482449054718018 and perplexity is 46.9106582988146
At time: 702.2288162708282 and batch: 300, loss is 3.849289879798889 and perplexity is 46.95970435387475
At time: 703.5047643184662 and batch: 350, loss is 3.87669858455658 and perplexity is 48.26461022578977
At time: 704.7840640544891 and batch: 400, loss is 3.825775671005249 and perplexity is 45.86836533224023
At time: 706.0641980171204 and batch: 450, loss is 3.8568832540512084 and perplexity is 47.317644229650746
At time: 707.3424396514893 and batch: 500, loss is 3.8679958820343017 and perplexity is 47.846400099298464
At time: 708.6415727138519 and batch: 550, loss is 3.850868053436279 and perplexity is 47.033873431753385
At time: 709.9221770763397 and batch: 600, loss is 3.802715015411377 and perplexity is 44.82271380042534
At time: 711.199373960495 and batch: 650, loss is 3.815133409500122 and perplexity is 45.38281047716133
At time: 712.4812655448914 and batch: 700, loss is 3.8707550764083862 and perplexity is 47.978599915896304
At time: 713.7603657245636 and batch: 750, loss is 3.8169572305679322 and perplexity is 45.46565612788331
At time: 715.0379629135132 and batch: 800, loss is 3.8029456186294555 and perplexity is 44.83305125434998
At time: 716.3150174617767 and batch: 850, loss is 3.8043566608428954 and perplexity is 44.89635723542929
At time: 717.5947473049164 and batch: 900, loss is 3.743767595291138 and perplexity is 42.256897515831156
At time: 718.8736445903778 and batch: 950, loss is 3.85280020236969 and perplexity is 47.12483773012579
At time: 720.1524248123169 and batch: 1000, loss is 3.819044451713562 and perplexity is 45.560652111078355
At time: 721.4307532310486 and batch: 1050, loss is 3.7637641954422 and perplexity is 43.11039690193795
At time: 722.707985162735 and batch: 1100, loss is 3.783550224304199 and perplexity is 43.971874969646905
At time: 723.9889438152313 and batch: 1150, loss is 3.7763548040390016 and perplexity is 43.65661442563752
At time: 725.2693297863007 and batch: 1200, loss is 3.805790510177612 and perplexity is 44.96077802119591
At time: 726.5476040840149 and batch: 1250, loss is 3.802376937866211 and perplexity is 44.807562808625384
At time: 727.827553987503 and batch: 1300, loss is 3.7895186233520506 and perplexity is 44.23510140516901
At time: 729.1073260307312 and batch: 1350, loss is 3.660484504699707 and perplexity is 38.88017593657646
At time: 730.3892874717712 and batch: 1400, loss is 3.6840545129776 and perplexity is 39.807467207755636
At time: 731.6699521541595 and batch: 1450, loss is 3.619206166267395 and perplexity is 37.30793976265547
At time: 732.9538536071777 and batch: 1500, loss is 3.609660997390747 and perplexity is 36.95352335034507
At time: 734.2327818870544 and batch: 1550, loss is 3.6342501211166383 and perplexity is 37.873441751804606
At time: 735.5128555297852 and batch: 1600, loss is 3.709481244087219 and perplexity is 40.832618869381264
At time: 736.7914111614227 and batch: 1650, loss is 3.668301959037781 and perplexity is 39.18531107264849
At time: 738.068925857544 and batch: 1700, loss is 3.661099410057068 and perplexity is 38.904090917026245
At time: 739.3465826511383 and batch: 1750, loss is 3.650991826057434 and perplexity is 38.512845155757276
At time: 740.6293542385101 and batch: 1800, loss is 3.6125377368927003 and perplexity is 37.059982064279474
At time: 741.9073641300201 and batch: 1850, loss is 3.6349191761016844 and perplexity is 37.89878964543124
At time: 743.1892178058624 and batch: 1900, loss is 3.7442602157592773 and perplexity is 42.2777192566543
At time: 744.4696786403656 and batch: 1950, loss is 3.68240882396698 and perplexity is 39.74201037200187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318606070585029 and perplexity of 75.08389366467308
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 748.6084005832672 and batch: 50, loss is 3.9263310623168945 and perplexity is 50.720545353903375
At time: 749.8868243694305 and batch: 100, loss is 3.89490581035614 and perplexity is 49.15142358956586
At time: 751.1631391048431 and batch: 150, loss is 3.8478938293457032 and perplexity is 46.89419197726165
At time: 752.4418358802795 and batch: 200, loss is 3.859094009399414 and perplexity is 47.422367681008566
At time: 753.7201313972473 and batch: 250, loss is 3.863606433868408 and perplexity is 47.63684106686212
At time: 754.9976360797882 and batch: 300, loss is 3.8633562898635865 and perplexity is 47.62492648690309
At time: 756.277129650116 and batch: 350, loss is 3.892661099433899 and perplexity is 49.041216589893835
At time: 757.5569288730621 and batch: 400, loss is 3.8442228269577026 and perplexity is 46.72235887935835
At time: 758.8385834693909 and batch: 450, loss is 3.8754169797897338 and perplexity is 48.202793691897874
At time: 760.1166889667511 and batch: 500, loss is 3.885986285209656 and perplexity is 48.714965623412624
At time: 761.3968305587769 and batch: 550, loss is 3.874125065803528 and perplexity is 48.14056003747327
At time: 762.6759128570557 and batch: 600, loss is 3.8213959312438965 and perplexity is 45.66791311350748
At time: 763.9545676708221 and batch: 650, loss is 3.832062315940857 and perplexity is 46.157631763838346
At time: 765.2317781448364 and batch: 700, loss is 3.8867369890213013 and perplexity is 48.751549864036626
At time: 766.5106861591339 and batch: 750, loss is 3.8327516317367554 and perplexity is 46.18945991707853
At time: 767.786482334137 and batch: 800, loss is 3.8175789165496825 and perplexity is 45.49393027685947
At time: 769.0650942325592 and batch: 850, loss is 3.818506383895874 and perplexity is 45.536143984532885
At time: 770.3453876972198 and batch: 900, loss is 3.757234468460083 and perplexity is 42.829814839149215
At time: 771.6259911060333 and batch: 950, loss is 3.8668579912185668 and perplexity is 47.791987083965836
At time: 772.9233515262604 and batch: 1000, loss is 3.830887894630432 and perplexity is 46.10345507681104
At time: 774.2043399810791 and batch: 1050, loss is 3.773868751525879 and perplexity is 43.54821658681906
At time: 775.4820063114166 and batch: 1100, loss is 3.7867069625854493 and perplexity is 44.11090199117212
At time: 776.7647280693054 and batch: 1150, loss is 3.7783416891098023 and perplexity is 43.74344133005762
At time: 778.0448186397552 and batch: 1200, loss is 3.8080365085601806 and perplexity is 45.06187334337757
At time: 779.3232314586639 and batch: 1250, loss is 3.8031998920440673 and perplexity is 44.844452556842526
At time: 780.6045129299164 and batch: 1300, loss is 3.7875551128387452 and perplexity is 44.14833053413944
At time: 781.883291721344 and batch: 1350, loss is 3.654922299385071 and perplexity is 38.6645167417153
At time: 783.1608822345734 and batch: 1400, loss is 3.677910261154175 and perplexity is 39.56362997058103
At time: 784.4430975914001 and batch: 1450, loss is 3.6136557817459107 and perplexity is 37.10143995806028
At time: 785.7220804691315 and batch: 1500, loss is 3.601296248435974 and perplexity is 36.64570560839954
At time: 786.9993045330048 and batch: 1550, loss is 3.625431680679321 and perplexity is 37.5409253544215
At time: 788.2837569713593 and batch: 1600, loss is 3.700370831489563 and perplexity is 40.46230627561147
At time: 789.5643699169159 and batch: 1650, loss is 3.6551399421691895 and perplexity is 38.67293271058979
At time: 790.8429989814758 and batch: 1700, loss is 3.646661615371704 and perplexity is 38.34643697339345
At time: 792.1230049133301 and batch: 1750, loss is 3.637589302062988 and perplexity is 38.0001194089785
At time: 793.4041728973389 and batch: 1800, loss is 3.601229166984558 and perplexity is 36.64324744372872
At time: 794.6803104877472 and batch: 1850, loss is 3.6242020606994627 and perplexity is 37.49479265120272
At time: 795.9597043991089 and batch: 1900, loss is 3.7327104806900024 and perplexity is 41.792231822373004
At time: 797.2419822216034 and batch: 1950, loss is 3.675579299926758 and perplexity is 39.471516081762886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314175769894622 and perplexity of 74.75198520874213
finished 15 epochs...
Completing Train Step...
At time: 801.3336889743805 and batch: 50, loss is 3.9265939664840697 and perplexity is 50.73388174965851
At time: 802.6310684680939 and batch: 100, loss is 3.8915530252456665 and perplexity is 48.986905379613255
At time: 803.9109144210815 and batch: 150, loss is 3.8422220373153686 and perplexity is 46.628970723828246
At time: 805.2108263969421 and batch: 200, loss is 3.8516295623779295 and perplexity is 47.06970378776887
At time: 806.4929029941559 and batch: 250, loss is 3.8555976247787473 and perplexity is 47.25685036868239
At time: 807.7706072330475 and batch: 300, loss is 3.854176607131958 and perplexity is 47.18974524045457
At time: 809.0511362552643 and batch: 350, loss is 3.8818884754180907 and perplexity is 48.515749414122325
At time: 810.3293483257294 and batch: 400, loss is 3.832844967842102 and perplexity is 46.19377126257423
At time: 811.60631108284 and batch: 450, loss is 3.8641489124298096 and perplexity is 47.662690042497424
At time: 812.8876895904541 and batch: 500, loss is 3.8761195135116577 and perplexity is 48.2366696780754
At time: 814.1690318584442 and batch: 550, loss is 3.863774981498718 and perplexity is 47.64487082021833
At time: 815.4476056098938 and batch: 600, loss is 3.811825656890869 and perplexity is 45.2329433656989
At time: 816.7257127761841 and batch: 650, loss is 3.822693123817444 and perplexity is 45.72719163076154
At time: 818.0064888000488 and batch: 700, loss is 3.8777596139907837 and perplexity is 48.315847575230805
At time: 819.2830159664154 and batch: 750, loss is 3.824304528236389 and perplexity is 45.80093602948908
At time: 820.5626549720764 and batch: 800, loss is 3.809881067276001 and perplexity is 45.14506932094826
At time: 821.8406858444214 and batch: 850, loss is 3.8115836334228517 and perplexity is 45.22199725653798
At time: 823.1240088939667 and batch: 900, loss is 3.749598574638367 and perplexity is 42.50401638485842
At time: 824.4086449146271 and batch: 950, loss is 3.8592750024795532 and perplexity is 47.430951578192214
At time: 825.6888175010681 and batch: 1000, loss is 3.824074664115906 and perplexity is 45.79040924752244
At time: 826.9670352935791 and batch: 1050, loss is 3.767573208808899 and perplexity is 43.27491811281272
At time: 828.2441391944885 and batch: 1100, loss is 3.781813497543335 and perplexity is 43.89557411370929
At time: 829.5212996006012 and batch: 1150, loss is 3.7740979290008543 and perplexity is 43.55819800085005
At time: 830.7988090515137 and batch: 1200, loss is 3.804100217819214 and perplexity is 44.88484535396149
At time: 832.079626083374 and batch: 1250, loss is 3.800085463523865 and perplexity is 44.70500497730224
At time: 833.3619649410248 and batch: 1300, loss is 3.7854876136779785 and perplexity is 44.05714819000115
At time: 834.6420226097107 and batch: 1350, loss is 3.6530171489715575 and perplexity is 38.590925145445546
At time: 835.9199163913727 and batch: 1400, loss is 3.6765472364425658 and perplexity is 39.509740499933415
At time: 837.1962776184082 and batch: 1450, loss is 3.612924795150757 and perplexity is 37.07432921279292
At time: 838.4742212295532 and batch: 1500, loss is 3.6019181966781617 and perplexity is 36.668504429694906
At time: 839.7505486011505 and batch: 1550, loss is 3.62753005027771 and perplexity is 37.61978279797657
At time: 841.0305275917053 and batch: 1600, loss is 3.7027886438369753 and perplexity is 40.56025490231314
At time: 842.3092753887177 and batch: 1650, loss is 3.6590334796905517 and perplexity is 38.82380073973375
At time: 843.5892324447632 and batch: 1700, loss is 3.6512910985946654 and perplexity is 38.52437271749833
At time: 844.869402885437 and batch: 1750, loss is 3.642687563896179 and perplexity is 38.19434866250826
At time: 846.1468584537506 and batch: 1800, loss is 3.606269245147705 and perplexity is 36.82839847088137
At time: 847.4276123046875 and batch: 1850, loss is 3.628861064910889 and perplexity is 37.66988861777006
At time: 848.7090992927551 and batch: 1900, loss is 3.737162461280823 and perplexity is 41.97870480635282
At time: 849.9888000488281 and batch: 1950, loss is 3.679559226036072 and perplexity is 39.628922825020155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312939453125 and perplexity of 74.65962518075591
finished 16 epochs...
Completing Train Step...
At time: 854.0977988243103 and batch: 50, loss is 3.925901799201965 and perplexity is 50.698777567002104
At time: 855.3919017314911 and batch: 100, loss is 3.8893481302261352 and perplexity is 48.879013384890705
At time: 856.6700913906097 and batch: 150, loss is 3.8392884731292725 and perplexity is 46.49238208899649
At time: 857.9501039981842 and batch: 200, loss is 3.847878475189209 and perplexity is 46.893471962026986
At time: 859.2277548313141 and batch: 250, loss is 3.851596670150757 and perplexity is 47.068155585840984
At time: 860.5075368881226 and batch: 300, loss is 3.8493859577178955 and perplexity is 46.9642163612949
At time: 861.7845702171326 and batch: 350, loss is 3.876604928970337 and perplexity is 48.26009018709103
At time: 863.0633254051208 and batch: 400, loss is 3.827147750854492 and perplexity is 45.931343587747726
At time: 864.3421533107758 and batch: 450, loss is 3.858486351966858 and perplexity is 47.39355988034133
At time: 865.6215081214905 and batch: 500, loss is 3.8706509113311767 and perplexity is 47.97360248161524
At time: 866.8998229503632 and batch: 550, loss is 3.858005108833313 and perplexity is 47.37075754224905
At time: 868.1960277557373 and batch: 600, loss is 3.806660170555115 and perplexity is 44.9998956354368
At time: 869.4771659374237 and batch: 650, loss is 3.817700171470642 and perplexity is 45.49944697423592
At time: 870.7554438114166 and batch: 700, loss is 3.8729722118377685 and perplexity is 48.085092980771655
At time: 872.0332095623016 and batch: 750, loss is 3.819861388206482 and perplexity is 45.59788747782323
At time: 873.312637090683 and batch: 800, loss is 3.8058577823638915 and perplexity is 44.96380273276855
At time: 874.5902051925659 and batch: 850, loss is 3.8078021097183226 and perplexity is 45.05131213027034
At time: 875.8678841590881 and batch: 900, loss is 3.745616521835327 and perplexity is 42.335099688081264
At time: 877.1530990600586 and batch: 950, loss is 3.8554249238967895 and perplexity is 47.248689773636436
At time: 878.4325218200684 and batch: 1000, loss is 3.8205950355529783 and perplexity is 45.63135252124631
At time: 879.7104501724243 and batch: 1050, loss is 3.764379119873047 and perplexity is 43.13691469059892
At time: 880.9889171123505 and batch: 1100, loss is 3.7793525743484495 and perplexity is 43.787683287188976
At time: 882.2691361904144 and batch: 1150, loss is 3.77195463180542 and perplexity is 43.464939812943136
At time: 883.5470068454742 and batch: 1200, loss is 3.8021626758575437 and perplexity is 44.79796327865853
At time: 884.8249931335449 and batch: 1250, loss is 3.7984816789627076 and perplexity is 44.633365243218456
At time: 886.10262799263 and batch: 1300, loss is 3.7844184398651124 and perplexity is 44.01006861349685
At time: 887.3776876926422 and batch: 1350, loss is 3.652207446098328 and perplexity is 38.55969060952793
At time: 888.6575636863708 and batch: 1400, loss is 3.676049656867981 and perplexity is 39.49008615027048
At time: 889.9367065429688 and batch: 1450, loss is 3.6128569078445434 and perplexity is 37.07181242188304
At time: 891.2145638465881 and batch: 1500, loss is 3.602486042976379 and perplexity is 36.68933241718461
At time: 892.4946296215057 and batch: 1550, loss is 3.628840866088867 and perplexity is 37.66912773807876
At time: 893.7735741138458 and batch: 1600, loss is 3.704183826446533 and perplexity is 40.61688335892524
At time: 895.0519847869873 and batch: 1650, loss is 3.6608845233917235 and perplexity is 38.89573184481957
At time: 896.330178976059 and batch: 1700, loss is 3.6533702278137206 and perplexity is 38.60455319035949
At time: 897.6079378128052 and batch: 1750, loss is 3.644976406097412 and perplexity is 38.28186962219991
At time: 898.888879776001 and batch: 1800, loss is 3.608552851676941 and perplexity is 36.9125961426774
At time: 900.1659691333771 and batch: 1850, loss is 3.630899486541748 and perplexity is 37.74675404902376
At time: 901.4435548782349 and batch: 1900, loss is 3.7391365432739256 and perplexity is 42.061656060955414
At time: 902.7242929935455 and batch: 1950, loss is 3.681228585243225 and perplexity is 39.6951329810985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312464798328488 and perplexity of 74.62419604052894
finished 17 epochs...
Completing Train Step...
At time: 906.8189351558685 and batch: 50, loss is 3.924679675102234 and perplexity is 50.636855215216976
At time: 908.1135513782501 and batch: 100, loss is 3.8872567510604856 and perplexity is 48.77689565532684
At time: 909.3918805122375 and batch: 150, loss is 3.836853127479553 and perplexity is 46.37929482770839
At time: 910.6673767566681 and batch: 200, loss is 3.8450153827667237 and perplexity is 46.75940363437813
At time: 911.9425284862518 and batch: 250, loss is 3.8485726070404054 and perplexity is 46.926033514226866
At time: 913.2221915721893 and batch: 300, loss is 3.8459245586395263 and perplexity is 46.80193548752676
At time: 914.4991784095764 and batch: 350, loss is 3.8729666757583616 and perplexity is 48.08482677861548
At time: 915.7747619152069 and batch: 400, loss is 3.8232547998428346 and perplexity is 45.75288271236586
At time: 917.0559279918671 and batch: 450, loss is 3.854653615951538 and perplexity is 47.21226053469805
At time: 918.3342900276184 and batch: 500, loss is 3.8668428897857665 and perplexity is 47.79126536193403
At time: 919.6117765903473 and batch: 550, loss is 3.8540422201156614 and perplexity is 47.183403977493164
At time: 920.890278339386 and batch: 600, loss is 3.80311758518219 and perplexity is 44.84076170257337
At time: 922.1671357154846 and batch: 650, loss is 3.814259662628174 and perplexity is 45.34317470680348
At time: 923.4437153339386 and batch: 700, loss is 3.8697128438949586 and perplexity is 47.92862110840841
At time: 924.7238533496857 and batch: 750, loss is 3.816835656166077 and perplexity is 45.460129003919796
At time: 926.0019941329956 and batch: 800, loss is 3.8030593252182006 and perplexity is 44.838149357509614
At time: 927.2790186405182 and batch: 850, loss is 3.8050929737091064 and perplexity is 44.9294271743244
At time: 928.5543205738068 and batch: 900, loss is 3.7428899145126344 and perplexity is 42.21982572010336
At time: 929.8338854312897 and batch: 950, loss is 3.8528344774246217 and perplexity is 47.12645296420859
At time: 931.1100478172302 and batch: 1000, loss is 3.818211431503296 and perplexity is 45.52271497047314
At time: 932.4027681350708 and batch: 1050, loss is 3.7622060918807985 and perplexity is 43.04327874109283
At time: 933.6808619499207 and batch: 1100, loss is 3.777622275352478 and perplexity is 43.71198301370165
At time: 934.9591317176819 and batch: 1150, loss is 3.770382089614868 and perplexity is 43.39664307510253
At time: 936.2371571063995 and batch: 1200, loss is 3.8007466793060303 and perplexity is 44.73457440694446
At time: 937.5147161483765 and batch: 1250, loss is 3.7972559833526613 and perplexity is 44.57869183670022
At time: 938.7918260097504 and batch: 1300, loss is 3.7834855699539185 and perplexity is 43.96903208854342
At time: 940.0696029663086 and batch: 1350, loss is 3.651517405509949 and perplexity is 38.533092036035086
At time: 941.3468294143677 and batch: 1400, loss is 3.6755632400512694 and perplexity is 39.47088217921948
At time: 942.6238486766815 and batch: 1450, loss is 3.6126525020599365 and perplexity is 37.06423550338751
At time: 943.9008264541626 and batch: 1500, loss is 3.6026555585861204 and perplexity is 36.69555235891402
At time: 945.1804733276367 and batch: 1550, loss is 3.6294489526748657 and perplexity is 37.69204079521785
At time: 946.4557452201843 and batch: 1600, loss is 3.7048129558563234 and perplexity is 40.642444674625
At time: 947.7311792373657 and batch: 1650, loss is 3.6616777420043944 and perplexity is 38.92659690302332
At time: 949.0072610378265 and batch: 1700, loss is 3.6542506551742555 and perplexity is 38.638556661826335
At time: 950.2771039009094 and batch: 1750, loss is 3.645990071296692 and perplexity is 38.320694295484984
At time: 951.5473318099976 and batch: 1800, loss is 3.609579839706421 and perplexity is 36.95052440965745
At time: 952.817978143692 and batch: 1850, loss is 3.631798548698425 and perplexity is 37.78070598729107
At time: 954.0964419841766 and batch: 1900, loss is 3.740008444786072 and perplexity is 42.098345675019004
At time: 955.3739864826202 and batch: 1950, loss is 3.6818874073028565 and perplexity is 39.721293627025524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312280557321948 and perplexity of 74.6104484700102
finished 18 epochs...
Completing Train Step...
At time: 959.4443492889404 and batch: 50, loss is 3.923253436088562 and perplexity is 50.56468643397862
At time: 960.7207326889038 and batch: 100, loss is 3.885259189605713 and perplexity is 48.67955805996338
At time: 962.0025992393494 and batch: 150, loss is 3.8346608781814577 and perplexity is 46.27773121822784
At time: 963.2801723480225 and batch: 200, loss is 3.8425649309158327 and perplexity is 46.64496224102344
At time: 964.5748739242554 and batch: 250, loss is 3.846017069816589 and perplexity is 46.80626538994663
At time: 965.851071357727 and batch: 300, loss is 3.8431024599075316 and perplexity is 46.67004200048973
At time: 967.1289746761322 and batch: 350, loss is 3.870080327987671 and perplexity is 47.94623735089758
At time: 968.4049968719482 and batch: 400, loss is 3.820204243659973 and perplexity is 45.613523642531675
At time: 969.682359457016 and batch: 450, loss is 3.8516818857192994 and perplexity is 47.07216669638158
At time: 970.9594337940216 and batch: 500, loss is 3.863854012489319 and perplexity is 47.6486363903527
At time: 972.2379562854767 and batch: 550, loss is 3.8509660148620606 and perplexity is 47.03848116274105
At time: 973.5164985656738 and batch: 600, loss is 3.8003564643859864 and perplexity is 44.71712171394112
At time: 974.794016122818 and batch: 650, loss is 3.8115697717666626 and perplexity is 45.22137040910441
At time: 976.0700445175171 and batch: 700, loss is 3.8671835041046143 and perplexity is 47.80754652387319
At time: 977.3466222286224 and batch: 750, loss is 3.8144826745986937 and perplexity is 45.3532879051847
At time: 978.6263248920441 and batch: 800, loss is 3.8008336210250855 and perplexity is 44.73846387682075
At time: 979.9024705886841 and batch: 850, loss is 3.8029022932052614 and perplexity is 44.831108885463756
At time: 981.1765642166138 and batch: 900, loss is 3.7407463502883913 and perplexity is 42.12942174012077
At time: 982.4529867172241 and batch: 950, loss is 3.8508101415634157 and perplexity is 47.03114969092416
At time: 983.7297875881195 and batch: 1000, loss is 3.8163078594207764 and perplexity is 45.43614162657728
At time: 985.0078628063202 and batch: 1050, loss is 3.7604720163345338 and perplexity is 42.96870312256258
At time: 986.2855815887451 and batch: 1100, loss is 3.776175594329834 and perplexity is 43.64879143746172
At time: 987.5611989498138 and batch: 1150, loss is 3.769011516571045 and perplexity is 43.337205546952625
At time: 988.8384211063385 and batch: 1200, loss is 3.7995081615447996 and perplexity is 44.679204137609204
At time: 990.1162233352661 and batch: 1250, loss is 3.79614981174469 and perplexity is 44.52940741700828
At time: 991.3918161392212 and batch: 1300, loss is 3.7825601720809936 and perplexity is 43.928362060655125
At time: 992.6702363491058 and batch: 1350, loss is 3.65079505443573 and perplexity is 38.50526766630145
At time: 993.9482560157776 and batch: 1400, loss is 3.6749923753738405 and perplexity is 39.44835607708616
At time: 995.2225363254547 and batch: 1450, loss is 3.6122828245162966 and perplexity is 37.050536220164425
At time: 996.5040459632874 and batch: 1500, loss is 3.6025355291366576 and perplexity is 36.69114807629374
At time: 997.7816083431244 and batch: 1550, loss is 3.629621887207031 and perplexity is 37.69855961430735
At time: 999.0591194629669 and batch: 1600, loss is 3.7049904108047484 and perplexity is 40.649657517507
At time: 1000.3381073474884 and batch: 1650, loss is 3.6619064521789553 and perplexity is 38.9355008299666
At time: 1001.6161673069 and batch: 1700, loss is 3.65452052116394 and perplexity is 38.648985301264126
At time: 1002.8941857814789 and batch: 1750, loss is 3.646354703903198 and perplexity is 38.33466981793981
At time: 1004.1715519428253 and batch: 1800, loss is 3.60997043132782 and perplexity is 36.964959793884695
At time: 1005.4503843784332 and batch: 1850, loss is 3.632129726409912 and perplexity is 37.79322018713596
At time: 1006.7277553081512 and batch: 1900, loss is 3.74033269405365 and perplexity is 42.11199824606884
At time: 1008.0035955905914 and batch: 1950, loss is 3.6820539236068726 and perplexity is 39.727908420751255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312236839117006 and perplexity of 74.60718670643288
finished 19 epochs...
Completing Train Step...
At time: 1012.0871942043304 and batch: 50, loss is 3.921766128540039 and perplexity is 50.48953709310069
At time: 1013.3646469116211 and batch: 100, loss is 3.8833631563186644 and perplexity is 48.58734744230744
At time: 1014.6409232616425 and batch: 150, loss is 3.832637219429016 and perplexity is 46.18417557667873
At time: 1015.9128851890564 and batch: 200, loss is 3.8403691148757932 and perplexity is 46.54265085434832
At time: 1017.1808013916016 and batch: 250, loss is 3.843746476173401 and perplexity is 46.700107947107014
At time: 1018.4579236507416 and batch: 300, loss is 3.84064968585968 and perplexity is 46.5557112037831
At time: 1019.7274742126465 and batch: 350, loss is 3.867606291770935 and perplexity is 47.82776323828814
At time: 1021.0083339214325 and batch: 400, loss is 3.8176164722442625 and perplexity is 45.4956388650936
At time: 1022.2904717922211 and batch: 450, loss is 3.8491823863983154 and perplexity is 46.95465676685983
At time: 1023.5680768489838 and batch: 500, loss is 3.861326150894165 and perplexity is 47.5283393435614
At time: 1024.8476974964142 and batch: 550, loss is 3.848383655548096 and perplexity is 46.917167607805695
At time: 1026.1248977184296 and batch: 600, loss is 3.7980278158187866 and perplexity is 44.61311240010258
At time: 1027.4209434986115 and batch: 650, loss is 3.8092965984344485 and perplexity is 45.11869114394262
At time: 1028.691764831543 and batch: 700, loss is 3.8650544548034667 and perplexity is 47.705870175742895
At time: 1029.966718196869 and batch: 750, loss is 3.8124939727783205 and perplexity is 45.26318336419656
At time: 1031.2465362548828 and batch: 800, loss is 3.7989199018478392 and perplexity is 44.652928891614614
At time: 1032.5222005844116 and batch: 850, loss is 3.8010030031204223 and perplexity is 44.74604241339044
At time: 1033.8012042045593 and batch: 900, loss is 3.7389121437072754 and perplexity is 42.05221850249436
At time: 1035.0818846225739 and batch: 950, loss is 3.8490770769119265 and perplexity is 46.94971225642863
At time: 1036.3577952384949 and batch: 1000, loss is 3.8146482944488525 and perplexity is 45.36079993198497
At time: 1037.6298196315765 and batch: 1050, loss is 3.758954334259033 and perplexity is 42.903539753172694
At time: 1038.907837152481 and batch: 1100, loss is 3.774857988357544 and perplexity is 43.591317401561945
At time: 1040.1843917369843 and batch: 1150, loss is 3.767725954055786 and perplexity is 43.28152865571552
At time: 1041.4525692462921 and batch: 1200, loss is 3.798341460227966 and perplexity is 44.62710724797114
At time: 1042.721809387207 and batch: 1250, loss is 3.7950876712799073 and perplexity is 44.482136040382926
At time: 1043.9933676719666 and batch: 1300, loss is 3.7816242361068726 and perplexity is 43.88726716041593
At time: 1045.267967224121 and batch: 1350, loss is 3.6500255250930786 and perplexity is 38.47564813099801
At time: 1046.544763803482 and batch: 1400, loss is 3.6743466377258303 and perplexity is 39.42289101117582
At time: 1047.8207716941833 and batch: 1450, loss is 3.6117901945114137 and perplexity is 37.032288509379335
At time: 1049.0969710350037 and batch: 1500, loss is 3.6022247648239136 and perplexity is 36.679747548408386
At time: 1050.3741228580475 and batch: 1550, loss is 3.629526662826538 and perplexity is 37.69496996323645
At time: 1051.6498744487762 and batch: 1600, loss is 3.7048979997634888 and perplexity is 40.645901213893595
At time: 1052.9299211502075 and batch: 1650, loss is 3.6618159341812135 and perplexity is 38.93197662589475
At time: 1054.210830450058 and batch: 1700, loss is 3.6544544172286986 and perplexity is 38.64643053568357
At time: 1055.485817193985 and batch: 1750, loss is 3.646365361213684 and perplexity is 38.33507836459545
At time: 1056.763652086258 and batch: 1800, loss is 3.610011701583862 and perplexity is 36.96648537872041
At time: 1058.0405492782593 and batch: 1850, loss is 3.632149329185486 and perplexity is 37.79396104641093
At time: 1059.3160400390625 and batch: 1900, loss is 3.740359625816345 and perplexity is 42.113132411684695
At time: 1060.5970284938812 and batch: 1950, loss is 3.681959128379822 and perplexity is 39.724142583146794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312274027979651 and perplexity of 74.6099613144436
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -74.60718670643288
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
1099.78910946846


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.077113628387451 and batch: 50, loss is 7.721302814483643 and perplexity is 2255.8966817749133
At time: 3.5738372802734375 and batch: 100, loss is 7.053531303405761 and perplexity is 1156.9370333908385
At time: 5.070931673049927 and batch: 150, loss is 6.838470411300659 and perplexity is 933.0608433367327
At time: 6.571473598480225 and batch: 200, loss is 6.707670469284057 and perplexity is 818.6613197143575
At time: 8.07137656211853 and batch: 250, loss is 6.629596176147461 and perplexity is 757.1763430278302
At time: 9.566863536834717 and batch: 300, loss is 6.557471475601196 and perplexity is 704.4881252329833
At time: 11.064970970153809 and batch: 350, loss is 6.5320749092102055 and perplexity is 686.8218269791836
At time: 12.562439680099487 and batch: 400, loss is 6.523975191116333 and perplexity is 681.2812327167899
At time: 14.058584690093994 and batch: 450, loss is 6.433676500320434 and perplexity is 622.4582142110426
At time: 15.55464482307434 and batch: 500, loss is 6.43113826751709 and perplexity is 620.8802737902631
At time: 17.050554037094116 and batch: 550, loss is 6.391114673614502 and perplexity is 596.5211356080879
At time: 18.549456357955933 and batch: 600, loss is 6.445640707015992 and perplexity is 629.95016117862
At time: 20.048236846923828 and batch: 650, loss is 6.526942663192749 and perplexity is 683.3059183643614
At time: 21.545843601226807 and batch: 700, loss is 6.411326055526733 and perplexity is 608.7003165404286
At time: 23.044734716415405 and batch: 750, loss is 6.353185815811157 and perplexity is 574.3194736606165
At time: 24.54170250892639 and batch: 800, loss is 6.356591339111328 and perplexity is 576.2786661542609
At time: 26.038220643997192 and batch: 850, loss is 6.4081543445587155 and perplexity is 606.7727535225042
At time: 27.538759231567383 and batch: 900, loss is 6.396445817947388 and perplexity is 599.7097678569705
At time: 29.037378787994385 and batch: 950, loss is 6.4132595634460445 and perplexity is 609.8783819553396
At time: 30.53655481338501 and batch: 1000, loss is 6.398132419586181 and perplexity is 600.7220927887092
At time: 32.03590202331543 and batch: 1050, loss is 6.304232902526856 and perplexity is 546.8819155050401
At time: 33.531026124954224 and batch: 1100, loss is 6.380598249435425 and perplexity is 590.2807371658397
At time: 35.027209520339966 and batch: 1150, loss is 6.283649225234985 and perplexity is 535.7401374054368
At time: 36.521933794021606 and batch: 1200, loss is 6.38440390586853 and perplexity is 592.5314228023152
At time: 38.01935362815857 and batch: 1250, loss is 6.310202589035034 and perplexity is 550.1563931757664
At time: 39.51746869087219 and batch: 1300, loss is 6.320155115127563 and perplexity is 555.6591769110815
At time: 41.01319742202759 and batch: 1350, loss is 6.320126390457153 and perplexity is 555.6432160136012
At time: 42.509721517562866 and batch: 1400, loss is 6.343830461502075 and perplexity is 568.971566287258
At time: 44.008498668670654 and batch: 1450, loss is 6.342570962905884 and perplexity is 568.2553984990822
At time: 45.50652861595154 and batch: 1500, loss is 6.325304441452026 and perplexity is 558.5278268067384
At time: 47.0041184425354 and batch: 1550, loss is 6.296287231445312 and perplexity is 542.5537893881116
At time: 48.502965211868286 and batch: 1600, loss is 6.279134531021118 and perplexity is 533.3268861516912
At time: 49.99932384490967 and batch: 1650, loss is 6.276151075363159 and perplexity is 531.7381002502865
At time: 51.49722623825073 and batch: 1700, loss is 6.299069051742554 and perplexity is 544.0651777625457
At time: 52.99523997306824 and batch: 1750, loss is 6.306661300659179 and perplexity is 548.211576346776
At time: 54.49252104759216 and batch: 1800, loss is 6.324870414733887 and perplexity is 558.2854634069803
At time: 55.989482164382935 and batch: 1850, loss is 6.275749139785766 and perplexity is 531.524418735919
At time: 57.48429346084595 and batch: 1900, loss is 6.229466981887818 and perplexity is 507.48491274249255
At time: 58.98082756996155 and batch: 1950, loss is 6.171544876098633 and perplexity is 478.92541529878116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.671212981468023 and perplexity of 290.3865543607266
finished 1 epochs...
Completing Train Step...
At time: 63.188135862350464 and batch: 50, loss is 5.951434574127197 and perplexity is 384.3042567441991
At time: 64.46550059318542 and batch: 100, loss is 5.85088433265686 and perplexity is 347.54158699733415
At time: 65.74356055259705 and batch: 150, loss is 5.708438291549682 and perplexity is 301.40000161468635
At time: 67.02307796478271 and batch: 200, loss is 5.640324306488037 and perplexity is 281.5540134640007
At time: 68.30227470397949 and batch: 250, loss is 5.616913166046142 and perplexity is 275.03907157973435
At time: 69.57968974113464 and batch: 300, loss is 5.590169553756714 and perplexity is 267.78101914248884
At time: 70.8765516281128 and batch: 350, loss is 5.527533388137817 and perplexity is 251.52273627505102
At time: 72.15933132171631 and batch: 400, loss is 5.467634191513062 and perplexity is 236.8990714363373
At time: 73.43536591529846 and batch: 450, loss is 5.394296827316285 and perplexity is 220.14729109612836
At time: 74.71541929244995 and batch: 500, loss is 5.370250902175903 and perplexity is 214.91678402894198
At time: 75.99369668960571 and batch: 550, loss is 5.317247581481934 and perplexity is 203.82210548806304
At time: 77.27078151702881 and batch: 600, loss is 5.309251270294189 and perplexity is 202.19877946540464
At time: 78.54857063293457 and batch: 650, loss is 5.375112266540527 and perplexity is 215.96411649392013
At time: 79.82829594612122 and batch: 700, loss is 5.331237878799438 and perplexity is 206.6936775801869
At time: 81.10799288749695 and batch: 750, loss is 5.2479229831695555 and perplexity is 190.17086987862487
At time: 82.388747215271 and batch: 800, loss is 5.243803176879883 and perplexity is 189.3890143852324
At time: 83.66775679588318 and batch: 850, loss is 5.24221661567688 and perplexity is 189.0887753595083
At time: 84.94547414779663 and batch: 900, loss is 5.251287307739258 and perplexity is 190.8117438581497
At time: 86.22658896446228 and batch: 950, loss is 5.267105178833008 and perplexity is 193.85397681850162
At time: 87.50450801849365 and batch: 1000, loss is 5.233532657623291 and perplexity is 187.45384547147856
At time: 88.78511595726013 and batch: 1050, loss is 5.134075574874878 and perplexity is 169.70736558694986
At time: 90.06673812866211 and batch: 1100, loss is 5.210153112411499 and perplexity is 183.12209431278345
At time: 91.34679985046387 and batch: 1150, loss is 5.110998592376709 and perplexity is 165.8358746567955
At time: 92.62609601020813 and batch: 1200, loss is 5.175821084976196 and perplexity is 176.94183893298987
At time: 93.90398406982422 and batch: 1250, loss is 5.1386544895172115 and perplexity is 170.48622292796648
At time: 95.18434882164001 and batch: 1300, loss is 5.15328839302063 and perplexity is 172.99944614533985
At time: 96.46453595161438 and batch: 1350, loss is 5.074807672500611 and perplexity is 159.94142788621664
At time: 97.74263739585876 and batch: 1400, loss is 5.062503633499145 and perplexity is 157.9855595345401
At time: 99.02438998222351 and batch: 1450, loss is 5.022404136657715 and perplexity is 151.77575517982453
At time: 100.30437755584717 and batch: 1500, loss is 4.9841733741760255 and perplexity is 146.08276931292326
At time: 101.58239102363586 and batch: 1550, loss is 4.980644817352295 and perplexity is 145.56821630907038
At time: 102.86583971977234 and batch: 1600, loss is 5.0214262962341305 and perplexity is 151.62741524929973
At time: 104.14410328865051 and batch: 1650, loss is 5.003895025253296 and perplexity is 148.99235937277774
At time: 105.42185044288635 and batch: 1700, loss is 5.011406183242798 and perplexity is 150.11567795369214
At time: 106.70507168769836 and batch: 1750, loss is 5.010089797973633 and perplexity is 149.91819789500056
At time: 107.98528265953064 and batch: 1800, loss is 4.96928563117981 and perplexity is 143.9240357946663
At time: 109.26476430892944 and batch: 1850, loss is 4.9649380111694335 and perplexity is 143.2996670192364
At time: 110.54959893226624 and batch: 1900, loss is 5.037722644805908 and perplexity is 154.1186321984598
At time: 111.82942032814026 and batch: 1950, loss is 4.958604011535645 and perplexity is 142.39487548043607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.752620253452035 and perplexity of 115.88754177964549
finished 2 epochs...
Completing Train Step...
At time: 115.96657156944275 and batch: 50, loss is 4.953274364471436 and perplexity is 141.63797983534266
At time: 117.26215600967407 and batch: 100, loss is 4.890838851928711 and perplexity is 133.06514920427819
At time: 118.54464793205261 and batch: 150, loss is 4.825589933395386 and perplexity is 124.65998778515076
At time: 119.82531023025513 and batch: 200, loss is 4.811998996734619 and perplexity is 122.97720300042648
At time: 121.10504746437073 and batch: 250, loss is 4.830253772735595 and perplexity is 125.24273981494875
At time: 122.38597178459167 and batch: 300, loss is 4.8519609260559085 and perplexity is 127.99112506113349
At time: 123.66624164581299 and batch: 350, loss is 4.841110248565673 and perplexity is 126.60984212167133
At time: 124.94451522827148 and batch: 400, loss is 4.799542980194092 and perplexity is 121.45489753913616
At time: 126.22391939163208 and batch: 450, loss is 4.785788717269898 and perplexity is 119.79581085755241
At time: 127.50148963928223 and batch: 500, loss is 4.792321243286133 and perplexity is 120.5809417605929
At time: 128.78069615364075 and batch: 550, loss is 4.747383823394776 and perplexity is 115.28229083274181
At time: 130.06049013137817 and batch: 600, loss is 4.721208658218384 and perplexity is 112.30390771201554
At time: 131.33897233009338 and batch: 650, loss is 4.786149883270264 and perplexity is 119.83908484549664
At time: 132.61826372146606 and batch: 700, loss is 4.809453439712525 and perplexity is 122.66455561746768
At time: 133.8980906009674 and batch: 750, loss is 4.745651397705078 and perplexity is 115.0827457289759
At time: 135.19467115402222 and batch: 800, loss is 4.749930849075318 and perplexity is 115.57629204338086
At time: 136.4730944633484 and batch: 850, loss is 4.7435422611236575 and perplexity is 114.84027629053438
At time: 137.75176906585693 and batch: 900, loss is 4.728987922668457 and perplexity is 113.1809564830243
At time: 139.0336399078369 and batch: 950, loss is 4.785425148010254 and perplexity is 119.75226469979232
At time: 140.31308245658875 and batch: 1000, loss is 4.74936017036438 and perplexity is 115.5103539305507
At time: 141.5909628868103 and batch: 1050, loss is 4.675331783294678 and perplexity is 107.26815096919263
At time: 142.87024569511414 and batch: 1100, loss is 4.735779047012329 and perplexity is 113.95219826719013
At time: 144.14870643615723 and batch: 1150, loss is 4.673879776000977 and perplexity is 107.11250985496523
At time: 145.42679953575134 and batch: 1200, loss is 4.7456263256073 and perplexity is 115.07986039929315
At time: 146.71021461486816 and batch: 1250, loss is 4.724167232513428 and perplexity is 112.636659158825
At time: 147.99041414260864 and batch: 1300, loss is 4.733265390396118 and perplexity is 113.66612127038265
At time: 149.26961159706116 and batch: 1350, loss is 4.617368621826172 and perplexity is 101.22731402063098
At time: 150.55169916152954 and batch: 1400, loss is 4.627213792800903 and perplexity is 102.2288362235736
At time: 151.8319272994995 and batch: 1450, loss is 4.57529356956482 and perplexity is 97.05652779765533
At time: 153.11546206474304 and batch: 1500, loss is 4.565596017837525 and perplexity is 96.11986610197819
At time: 154.3948516845703 and batch: 1550, loss is 4.566874656677246 and perplexity is 96.24284730356013
At time: 155.67469835281372 and batch: 1600, loss is 4.635538368225098 and perplexity is 103.08339988607939
At time: 156.95319414138794 and batch: 1650, loss is 4.609079818725586 and perplexity is 100.39172853212466
At time: 158.23322296142578 and batch: 1700, loss is 4.619218626022339 and perplexity is 101.4147583092352
At time: 159.51402020454407 and batch: 1750, loss is 4.609751796722412 and perplexity is 100.45921223600422
At time: 160.79354453086853 and batch: 1800, loss is 4.575228023529053 and perplexity is 97.05016633549947
At time: 162.0724995136261 and batch: 1850, loss is 4.598443822860718 and perplexity is 99.32962082170464
At time: 163.35392594337463 and batch: 1900, loss is 4.697176170349121 and perplexity is 109.63713831433647
At time: 164.64013385772705 and batch: 1950, loss is 4.61103497505188 and perplexity is 100.58820206091598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.568343193586482 and perplexity of 96.3842873065887
finished 3 epochs...
Completing Train Step...
At time: 168.73704552650452 and batch: 50, loss is 4.612835664749145 and perplexity is 100.76949337574871
At time: 170.03259897232056 and batch: 100, loss is 4.5473009300231935 and perplexity is 94.37733321043791
At time: 171.31374311447144 and batch: 150, loss is 4.497164611816406 and perplexity is 89.76225929140482
At time: 172.59870672225952 and batch: 200, loss is 4.492827339172363 and perplexity is 89.37377898122907
At time: 173.87798428535461 and batch: 250, loss is 4.506226482391358 and perplexity is 90.57936995156004
At time: 175.15952324867249 and batch: 300, loss is 4.539764862060547 and perplexity is 93.66877244766037
At time: 176.43938517570496 and batch: 350, loss is 4.537322416305542 and perplexity is 93.44027071715455
At time: 177.7192726135254 and batch: 400, loss is 4.492226419448852 and perplexity is 89.32008864808026
At time: 179.00041317939758 and batch: 450, loss is 4.499023904800415 and perplexity is 89.9293088792737
At time: 180.28097820281982 and batch: 500, loss is 4.505944652557373 and perplexity is 90.55384557969782
At time: 181.55736112594604 and batch: 550, loss is 4.463656635284424 and perplexity is 86.80434129061366
At time: 182.84123539924622 and batch: 600, loss is 4.441706485748291 and perplexity is 84.91973241013359
At time: 184.1213414669037 and batch: 650, loss is 4.5071070194244385 and perplexity is 90.65916356669644
At time: 185.40338015556335 and batch: 700, loss is 4.5360837650299075 and perplexity is 93.3246024577424
At time: 186.68331050872803 and batch: 750, loss is 4.481409101486206 and perplexity is 88.35909192314004
At time: 187.96316814422607 and batch: 800, loss is 4.485058221817017 and perplexity is 88.68211389646504
At time: 189.24266290664673 and batch: 850, loss is 4.478843307495117 and perplexity is 88.13267129458583
At time: 190.52087664604187 and batch: 900, loss is 4.453784503936768 and perplexity is 85.95161347781895
At time: 191.80150604248047 and batch: 950, loss is 4.522558097839355 and perplexity is 92.0708231591608
At time: 193.08303499221802 and batch: 1000, loss is 4.490317888259888 and perplexity is 89.14978104347723
At time: 194.36226749420166 and batch: 1050, loss is 4.4257181453704835 and perplexity is 83.57280309822568
At time: 195.640319108963 and batch: 1100, loss is 4.476526832580566 and perplexity is 87.92875045232495
At time: 196.9213318824768 and batch: 1150, loss is 4.428596916198731 and perplexity is 83.81373667570577
At time: 198.20326805114746 and batch: 1200, loss is 4.50217679977417 and perplexity is 90.21329399760653
At time: 199.52409958839417 and batch: 1250, loss is 4.491240091323853 and perplexity is 89.23203316545744
At time: 200.8070788383484 and batch: 1300, loss is 4.486184463500977 and perplexity is 88.78204765397544
At time: 202.08687376976013 and batch: 1350, loss is 4.360592293739319 and perplexity is 78.30349936333654
At time: 203.3685965538025 and batch: 1400, loss is 4.3808338165283205 and perplexity is 79.9046314383382
At time: 204.6502652168274 and batch: 1450, loss is 4.33099549293518 and perplexity is 76.0199262130532
At time: 205.92862701416016 and batch: 1500, loss is 4.327431058883667 and perplexity is 75.74944055000066
At time: 207.20962977409363 and batch: 1550, loss is 4.338547878265381 and perplexity is 76.59623148904602
At time: 208.49516677856445 and batch: 1600, loss is 4.411107740402222 and perplexity is 82.3606472074062
At time: 209.77531147003174 and batch: 1650, loss is 4.374496850967407 and perplexity is 79.39987952760819
At time: 211.05734014511108 and batch: 1700, loss is 4.391365041732788 and perplexity is 80.75057168214795
At time: 212.33526849746704 and batch: 1750, loss is 4.382904939651489 and perplexity is 80.07029526402981
At time: 213.6118562221527 and batch: 1800, loss is 4.3438123607635495 and perplexity is 77.00053429791338
At time: 214.8916471004486 and batch: 1850, loss is 4.377508554458618 and perplexity is 79.63936887641603
At time: 216.1775255203247 and batch: 1900, loss is 4.47702033996582 and perplexity is 87.97215464931432
At time: 217.4585268497467 and batch: 1950, loss is 4.394648952484131 and perplexity is 81.01618523958093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495458132721657 and perplexity of 89.60921249514601
finished 4 epochs...
Completing Train Step...
At time: 221.56752228736877 and batch: 50, loss is 4.40343240737915 and perplexity is 81.73092158050719
At time: 222.8653655052185 and batch: 100, loss is 4.342116661071778 and perplexity is 76.8700751566611
At time: 224.1452395915985 and batch: 150, loss is 4.2970797634124756 and perplexity is 73.48488680774871
At time: 225.42602276802063 and batch: 200, loss is 4.2975149250030515 and perplexity is 73.51687156673982
At time: 226.70883774757385 and batch: 250, loss is 4.3019841861724855 and perplexity is 73.84617298502206
At time: 227.9889612197876 and batch: 300, loss is 4.332695693969726 and perplexity is 76.14928530731834
At time: 229.27131342887878 and batch: 350, loss is 4.335236930847168 and perplexity is 76.34304476940433
At time: 230.56972336769104 and batch: 400, loss is 4.289119291305542 and perplexity is 72.90223458625617
At time: 231.8489649295807 and batch: 450, loss is 4.305555906295776 and perplexity is 74.11040244303491
At time: 233.12886476516724 and batch: 500, loss is 4.311953067779541 and perplexity is 74.58601832890818
At time: 234.40944004058838 and batch: 550, loss is 4.273068733215332 and perplexity is 71.74145354684238
At time: 235.6872124671936 and batch: 600, loss is 4.253544106483459 and perplexity is 70.35431419991568
At time: 236.96926069259644 and batch: 650, loss is 4.317307367324829 and perplexity is 74.98644525915981
At time: 238.24936509132385 and batch: 700, loss is 4.349878215789795 and perplexity is 77.4690278463791
At time: 239.53244304656982 and batch: 750, loss is 4.301001501083374 and perplexity is 73.7736410957816
At time: 240.81327056884766 and batch: 800, loss is 4.298890371322631 and perplexity is 73.61805965059935
At time: 242.09384202957153 and batch: 850, loss is 4.296012296676635 and perplexity is 73.4064859880727
At time: 243.37354564666748 and batch: 900, loss is 4.271647367477417 and perplexity is 71.63955513739191
At time: 244.65597295761108 and batch: 950, loss is 4.347634563446045 and perplexity is 77.29540912334363
At time: 245.9346582889557 and batch: 1000, loss is 4.318839159011841 and perplexity is 75.10139689114676
At time: 247.21654272079468 and batch: 1050, loss is 4.258498926162719 and perplexity is 70.70377217612365
At time: 248.4973165988922 and batch: 1100, loss is 4.294470281600952 and perplexity is 73.29337930854084
At time: 249.77522134780884 and batch: 1150, loss is 4.25740065574646 and perplexity is 70.62616294058941
At time: 251.05697631835938 and batch: 1200, loss is 4.329898924827575 and perplexity is 75.93661087524526
At time: 252.33709049224854 and batch: 1250, loss is 4.324867324829102 and perplexity is 75.55548785744307
At time: 253.62039160728455 and batch: 1300, loss is 4.314635620117188 and perplexity is 74.78636783059986
At time: 254.89980578422546 and batch: 1350, loss is 4.184199652671814 and perplexity is 65.64094433336578
At time: 256.17943930625916 and batch: 1400, loss is 4.2148952293396 and perplexity is 67.68707387999112
At time: 257.4584310054779 and batch: 1450, loss is 4.160778965950012 and perplexity is 64.12145157836977
At time: 258.7376549243927 and batch: 1500, loss is 4.162277626991272 and perplexity is 64.21761994365113
At time: 260.01750111579895 and batch: 1550, loss is 4.177271227836609 and perplexity is 65.18772783564
At time: 261.2984902858734 and batch: 1600, loss is 4.256330289840698 and perplexity is 70.55060754689525
At time: 262.58264112472534 and batch: 1650, loss is 4.219037985801696 and perplexity is 67.96806658299957
At time: 263.86178183555603 and batch: 1700, loss is 4.22800057888031 and perplexity is 68.57997475197146
At time: 265.1399381160736 and batch: 1750, loss is 4.222829718589782 and perplexity is 68.22627254425251
At time: 266.42264342308044 and batch: 1800, loss is 4.182009234428405 and perplexity is 65.49732056686733
At time: 267.70181608200073 and batch: 1850, loss is 4.22211829662323 and perplexity is 68.17775213655692
At time: 268.9826970100403 and batch: 1900, loss is 4.320857305526733 and perplexity is 75.25311555730008
At time: 270.261164188385 and batch: 1950, loss is 4.2405910444259645 and perplexity is 69.44888708833584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454253724563953 and perplexity of 85.99195321118
finished 5 epochs...
Completing Train Step...
At time: 274.3871557712555 and batch: 50, loss is 4.252418637275696 and perplexity is 70.2751771271731
At time: 275.66746068000793 and batch: 100, loss is 4.190658802986145 and perplexity is 66.0663013030464
At time: 276.9477400779724 and batch: 150, loss is 4.146140794754029 and perplexity is 63.189667240356094
At time: 278.2292981147766 and batch: 200, loss is 4.151136503219605 and perplexity is 63.506134226151026
At time: 279.5105345249176 and batch: 250, loss is 4.154007377624512 and perplexity is 63.68871431831135
At time: 280.7909848690033 and batch: 300, loss is 4.182710604667664 and perplexity is 65.54327455175897
At time: 282.06928396224976 and batch: 350, loss is 4.187219142913818 and perplexity is 65.83944606045334
At time: 283.3501603603363 and batch: 400, loss is 4.135786652565002 and perplexity is 62.53876800761295
At time: 284.63353180885315 and batch: 450, loss is 4.165684790611267 and perplexity is 64.4367930493746
At time: 285.91382479667664 and batch: 500, loss is 4.170045437812806 and perplexity is 64.71839270280813
At time: 287.198725938797 and batch: 550, loss is 4.128214221000672 and perplexity is 62.066985989677
At time: 288.47908067703247 and batch: 600, loss is 4.115367269515991 and perplexity is 61.27471446540397
At time: 289.75973629951477 and batch: 650, loss is 4.17245505809784 and perplexity is 64.87452749191041
At time: 291.0414068698883 and batch: 700, loss is 4.21426796913147 and perplexity is 67.64462978507899
At time: 292.3216984272003 and batch: 750, loss is 4.168853411674499 and perplexity is 64.64129264884646
At time: 293.6015565395355 and batch: 800, loss is 4.161458430290222 and perplexity is 64.16503462304536
At time: 294.9010286331177 and batch: 850, loss is 4.162208414077758 and perplexity is 64.21317540888731
At time: 296.1820328235626 and batch: 900, loss is 4.133345527648926 and perplexity is 62.38628924837755
At time: 297.4644832611084 and batch: 950, loss is 4.21529037475586 and perplexity is 67.7138254019974
At time: 298.74478483200073 and batch: 1000, loss is 4.189127750396729 and perplexity is 65.96522771559617
At time: 300.0253391265869 and batch: 1050, loss is 4.130800929069519 and perplexity is 62.227742989223245
At time: 301.305703163147 and batch: 1100, loss is 4.164658703804016 and perplexity is 64.37070921579804
At time: 302.58708119392395 and batch: 1150, loss is 4.127027554512024 and perplexity is 61.99337686073285
At time: 303.8663613796234 and batch: 1200, loss is 4.200286436080932 and perplexity is 66.70543514816245
At time: 305.1438584327698 and batch: 1250, loss is 4.195100951194763 and perplexity is 66.36043040389615
At time: 306.4251506328583 and batch: 1300, loss is 4.184625639915466 and perplexity is 65.66891249493017
At time: 307.70520663261414 and batch: 1350, loss is 4.05494086265564 and perplexity is 57.6817517496815
At time: 308.98461866378784 and batch: 1400, loss is 4.090646157264709 and perplexity is 59.77850554312557
At time: 310.26354932785034 and batch: 1450, loss is 4.033184380531311 and perplexity is 56.44035295127921
At time: 311.5437214374542 and batch: 1500, loss is 4.03631697177887 and perplexity is 56.617434724539564
At time: 312.82450580596924 and batch: 1550, loss is 4.05200343132019 and perplexity is 57.51256417470348
At time: 314.1071813106537 and batch: 1600, loss is 4.13496123790741 and perplexity is 62.48716889009523
At time: 315.3870167732239 and batch: 1650, loss is 4.099289336204529 and perplexity is 60.29742117317018
At time: 316.6686465740204 and batch: 1700, loss is 4.101706342697144 and perplexity is 60.443336699985935
At time: 317.94900131225586 and batch: 1750, loss is 4.102153992652893 and perplexity is 60.470400214023506
At time: 319.23056983947754 and batch: 1800, loss is 4.058154349327087 and perplexity is 57.86740943459673
At time: 320.5114860534668 and batch: 1850, loss is 4.102261009216309 and perplexity is 60.47687189472515
At time: 321.7910461425781 and batch: 1900, loss is 4.19870126247406 and perplexity is 66.59977921655188
At time: 323.067654132843 and batch: 1950, loss is 4.122610268592834 and perplexity is 61.720138320715776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.444020257994186 and perplexity of 85.11644481620677
finished 6 epochs...
Completing Train Step...
At time: 327.1819860935211 and batch: 50, loss is 4.129801597595215 and perplexity is 62.16558790901584
At time: 328.45108795166016 and batch: 100, loss is 4.073053250312805 and perplexity is 58.73602487812713
At time: 329.71856594085693 and batch: 150, loss is 4.031052784919739 and perplexity is 56.32017307556563
At time: 330.99476146698 and batch: 200, loss is 4.03781412601471 and perplexity is 56.70226324160156
At time: 332.26091718673706 and batch: 250, loss is 4.032376384735107 and perplexity is 56.3947678021428
At time: 333.5550229549408 and batch: 300, loss is 4.066448106765747 and perplexity is 58.349343451429895
At time: 334.83266520500183 and batch: 350, loss is 4.072323570251465 and perplexity is 58.693182004587385
At time: 336.11638379096985 and batch: 400, loss is 4.019912366867065 and perplexity is 55.696224778258
At time: 337.39537739753723 and batch: 450, loss is 4.053145613670349 and perplexity is 57.57829153958868
At time: 338.6791739463806 and batch: 500, loss is 4.05786548614502 and perplexity is 57.8506960846214
At time: 339.959511756897 and batch: 550, loss is 4.017449426651001 and perplexity is 55.55921709649155
At time: 341.24063658714294 and batch: 600, loss is 4.004656562805176 and perplexity is 54.85298260929448
At time: 342.5216884613037 and batch: 650, loss is 4.064960441589355 and perplexity is 58.262603700962316
At time: 343.8048253059387 and batch: 700, loss is 4.103792524337768 and perplexity is 60.569564100169856
At time: 345.08431601524353 and batch: 750, loss is 4.0589809370040895 and perplexity is 57.915261696455815
At time: 346.36935567855835 and batch: 800, loss is 4.055692238807678 and perplexity is 57.72510872901435
At time: 347.64997386932373 and batch: 850, loss is 4.052702512741089 and perplexity is 57.55278419668329
At time: 348.9300184249878 and batch: 900, loss is 4.028917112350464 and perplexity is 56.20001997633955
At time: 350.2100660800934 and batch: 950, loss is 4.112047519683838 and perplexity is 61.07163501533446
At time: 351.4917857646942 and batch: 1000, loss is 4.08763710975647 and perplexity is 59.598899536995546
At time: 352.7772891521454 and batch: 1050, loss is 4.02842294216156 and perplexity is 56.17225446286101
At time: 354.0576136112213 and batch: 1100, loss is 4.057689619064331 and perplexity is 57.8405229461715
At time: 355.3388388156891 and batch: 1150, loss is 4.01954294681549 and perplexity is 55.67565327602455
At time: 356.6172511577606 and batch: 1200, loss is 4.095599498748779 and perplexity is 60.075343457341056
At time: 357.8963496685028 and batch: 1250, loss is 4.092589073181152 and perplexity is 59.89476305572037
At time: 359.17679357528687 and batch: 1300, loss is 4.078377118110657 and perplexity is 59.04956158297074
At time: 360.4596288204193 and batch: 1350, loss is 3.950369062423706 and perplexity is 51.95453776460886
At time: 361.7367670536041 and batch: 1400, loss is 3.988615837097168 and perplexity is 53.98012034893871
At time: 363.0167033672333 and batch: 1450, loss is 3.932091555595398 and perplexity is 51.01356386981635
At time: 364.2952182292938 and batch: 1500, loss is 3.933751497268677 and perplexity is 51.09831373083937
At time: 365.57480478286743 and batch: 1550, loss is 3.954011206626892 and perplexity is 52.14410869593354
At time: 366.85537815093994 and batch: 1600, loss is 4.036558933258057 and perplexity is 56.63113562027093
At time: 368.1357271671295 and batch: 1650, loss is 4.000677070617676 and perplexity is 54.63512935370415
At time: 369.4139757156372 and batch: 1700, loss is 4.006671390533447 and perplexity is 54.96361333313335
At time: 370.69759917259216 and batch: 1750, loss is 4.001715908050537 and perplexity is 54.69191586209437
At time: 371.97765159606934 and batch: 1800, loss is 3.9643543767929077 and perplexity is 52.686242945558114
At time: 373.25660276412964 and batch: 1850, loss is 4.004624171257019 and perplexity is 54.85120586504266
At time: 374.53946256637573 and batch: 1900, loss is 4.096917572021485 and perplexity is 60.15457936979852
At time: 375.8203818798065 and batch: 1950, loss is 4.023739256858826 and perplexity is 55.90977646221827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.448259788335756 and perplexity of 85.47806457390463
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 379.9716317653656 and batch: 50, loss is 4.064297680854797 and perplexity is 58.22400232808629
At time: 381.2517182826996 and batch: 100, loss is 4.050992245674133 and perplexity is 57.45443768862912
At time: 382.5332567691803 and batch: 150, loss is 4.005981769561767 and perplexity is 54.92572233941315
At time: 383.81387066841125 and batch: 200, loss is 4.00588604927063 and perplexity is 54.92046508489685
At time: 385.0944564342499 and batch: 250, loss is 3.9977390432357787 and perplexity is 54.47484542223687
At time: 386.37470984458923 and batch: 300, loss is 4.0313586282730105 and perplexity is 56.33740086052337
At time: 387.6538579463959 and batch: 350, loss is 4.02812059879303 and perplexity is 56.155273721365404
At time: 388.9361810684204 and batch: 400, loss is 3.9783392477035524 and perplexity is 53.42822945177741
At time: 390.2336440086365 and batch: 450, loss is 4.004102244377136 and perplexity is 54.82258501595264
At time: 391.5132267475128 and batch: 500, loss is 3.995177974700928 and perplexity is 54.33551010948695
At time: 392.7950174808502 and batch: 550, loss is 3.9507120656967163 and perplexity is 51.97236139771736
At time: 394.0717751979828 and batch: 600, loss is 3.922311644554138 and perplexity is 50.51708745802885
At time: 395.3576045036316 and batch: 650, loss is 3.976238670349121 and perplexity is 53.316117114446065
At time: 396.6335480213165 and batch: 700, loss is 4.017527899742126 and perplexity is 55.56357717106966
At time: 397.9210469722748 and batch: 750, loss is 3.9603562688827516 and perplexity is 52.47601819154153
At time: 399.2019476890564 and batch: 800, loss is 3.956426587104797 and perplexity is 52.27020878665785
At time: 400.4834358692169 and batch: 850, loss is 3.954970898628235 and perplexity is 52.19417500023944
At time: 401.7620027065277 and batch: 900, loss is 3.9135497570037843 and perplexity is 50.07639588270935
At time: 403.0433974266052 and batch: 950, loss is 4.0017519330978395 and perplexity is 54.69388617644049
At time: 404.3238568305969 and batch: 1000, loss is 3.9786963272094726 and perplexity is 53.447310984161575
At time: 405.6041181087494 and batch: 1050, loss is 3.921384782791138 and perplexity is 50.4702867935095
At time: 406.88240933418274 and batch: 1100, loss is 3.9335529518127443 and perplexity is 51.088169399931026
At time: 408.1616859436035 and batch: 1150, loss is 3.8949142599105837 and perplexity is 49.151838898950054
At time: 409.4413504600525 and batch: 1200, loss is 3.953012261390686 and perplexity is 52.092045595378124
At time: 410.72169733047485 and batch: 1250, loss is 3.9419287252426147 and perplexity is 51.51786935442291
At time: 412.0028004646301 and batch: 1300, loss is 3.9314063882827757 and perplexity is 50.97862301488515
At time: 413.2826132774353 and batch: 1350, loss is 3.789671769142151 and perplexity is 44.241876343487284
At time: 414.564133644104 and batch: 1400, loss is 3.817571873664856 and perplexity is 45.49360986947653
At time: 415.8457245826721 and batch: 1450, loss is 3.751201043128967 and perplexity is 42.57218233414507
At time: 417.1268353462219 and batch: 1500, loss is 3.750986685752869 and perplexity is 42.56305765085167
At time: 418.40855646133423 and batch: 1550, loss is 3.7716490840911865 and perplexity is 43.45166122865784
At time: 419.68863010406494 and batch: 1600, loss is 3.8551753664016726 and perplexity is 47.23689998014582
At time: 420.9677276611328 and batch: 1650, loss is 3.8175071382522585 and perplexity is 45.490664917193456
At time: 422.2470164299011 and batch: 1700, loss is 3.8055259656906126 and perplexity is 44.948885468363194
At time: 423.52869057655334 and batch: 1750, loss is 3.7873022603988646 and perplexity is 44.13716893222583
At time: 424.8100793361664 and batch: 1800, loss is 3.738638687133789 and perplexity is 42.040720619072715
At time: 426.09179067611694 and batch: 1850, loss is 3.766709632873535 and perplexity is 43.237563066706585
At time: 427.3733100891113 and batch: 1900, loss is 3.8579876136779787 and perplexity is 47.36992879073714
At time: 428.65248346328735 and batch: 1950, loss is 3.7791013669967652 and perplexity is 43.77668488073213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385186057867005 and perplexity of 80.25315355447505
finished 8 epochs...
Completing Train Step...
At time: 432.77366518974304 and batch: 50, loss is 3.9826138544082643 and perplexity is 53.657102943190395
At time: 434.06960892677307 and batch: 100, loss is 3.9529947948455813 and perplexity is 52.0911357352602
At time: 435.3503291606903 and batch: 150, loss is 3.9034438133239746 and perplexity is 49.57287520740133
At time: 436.6319513320923 and batch: 200, loss is 3.9015793228149414 and perplexity is 49.48053316425406
At time: 437.91351985931396 and batch: 250, loss is 3.8901474475860596 and perplexity is 48.918098847588645
At time: 439.19767713546753 and batch: 300, loss is 3.9200450372695923 and perplexity is 50.40271472760031
At time: 440.4785485267639 and batch: 350, loss is 3.9216948318481446 and perplexity is 50.48593748445229
At time: 441.7589373588562 and batch: 400, loss is 3.8774688053131103 and perplexity is 48.30179895031681
At time: 443.0385775566101 and batch: 450, loss is 3.9100893688201905 and perplexity is 49.90341158314653
At time: 444.31719517707825 and batch: 500, loss is 3.904266653060913 and perplexity is 49.61368252563534
At time: 445.597772359848 and batch: 550, loss is 3.8599528455734253 and perplexity is 47.463113220197286
At time: 446.8780553340912 and batch: 600, loss is 3.834835638999939 and perplexity is 46.28581945914622
At time: 448.161257982254 and batch: 650, loss is 3.889403190612793 and perplexity is 48.88170475636041
At time: 449.44100975990295 and batch: 700, loss is 3.9347041273117065 and perplexity is 51.14701471297385
At time: 450.7225618362427 and batch: 750, loss is 3.8807957983016967 and perplexity is 48.46276631693331
At time: 452.00405287742615 and batch: 800, loss is 3.8751143550872804 and perplexity is 48.18820854282395
At time: 453.2847111225128 and batch: 850, loss is 3.8775654220581055 and perplexity is 48.306465938359764
At time: 454.6065216064453 and batch: 900, loss is 3.837353720664978 and perplexity is 46.40251779878953
At time: 455.8882882595062 and batch: 950, loss is 3.9281466817855835 and perplexity is 50.81271821360927
At time: 457.1673102378845 and batch: 1000, loss is 3.90604079246521 and perplexity is 49.701782242277396
At time: 458.45022225379944 and batch: 1050, loss is 3.853493390083313 and perplexity is 47.157515413222505
At time: 459.7306110858917 and batch: 1100, loss is 3.8665295696258544 and perplexity is 47.7762937406063
At time: 461.0126347541809 and batch: 1150, loss is 3.8325525617599485 and perplexity is 46.18026589752111
At time: 462.2921152114868 and batch: 1200, loss is 3.892569327354431 and perplexity is 49.03671618197681
At time: 463.5730867385864 and batch: 1250, loss is 3.8836435222625734 and perplexity is 48.600971589619355
At time: 464.8541224002838 and batch: 1300, loss is 3.87514732837677 and perplexity is 48.18979749277052
At time: 466.1356384754181 and batch: 1350, loss is 3.734537110328674 and perplexity is 41.86864051563259
At time: 467.41860461235046 and batch: 1400, loss is 3.7654321241378783 and perplexity is 43.18236196962971
At time: 468.70135736465454 and batch: 1450, loss is 3.702201499938965 and perplexity is 40.536447186107104
At time: 469.98398637771606 and batch: 1500, loss is 3.7035004234313966 and perplexity is 40.58913514106015
At time: 471.26427817344666 and batch: 1550, loss is 3.7266455411911013 and perplexity is 41.53953154539128
At time: 472.54605293273926 and batch: 1600, loss is 3.8129796743392945 and perplexity is 45.285173102804094
At time: 473.8267436027527 and batch: 1650, loss is 3.776256594657898 and perplexity is 43.65232714708264
At time: 475.1060552597046 and batch: 1700, loss is 3.771014394760132 and perplexity is 43.42409167283636
At time: 476.3871932029724 and batch: 1750, loss is 3.7546677112579347 and perplexity is 42.72002206941382
At time: 477.6683301925659 and batch: 1800, loss is 3.7090646553039552 and perplexity is 40.81561200105024
At time: 478.9485957622528 and batch: 1850, loss is 3.740996632575989 and perplexity is 42.1399673077984
At time: 480.229474067688 and batch: 1900, loss is 3.8359336614608766 and perplexity is 46.336670241076575
At time: 481.5081377029419 and batch: 1950, loss is 3.7609745597839357 and perplexity is 42.990302189626384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386984181958575 and perplexity of 80.39758850036755
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 485.63597416877747 and batch: 50, loss is 3.9550888204574584 and perplexity is 52.200330195739106
At time: 486.9353656768799 and batch: 100, loss is 3.9641293239593507 and perplexity is 52.674387091440565
At time: 488.2172267436981 and batch: 150, loss is 3.9310556936264036 and perplexity is 50.96074821868557
At time: 489.49729108810425 and batch: 200, loss is 3.939426860809326 and perplexity is 51.389139728589186
At time: 490.77738404273987 and batch: 250, loss is 3.9333083963394166 and perplexity is 51.07567703608222
At time: 492.0570466518402 and batch: 300, loss is 3.952403812408447 and perplexity is 52.060359883799876
At time: 493.33570981025696 and batch: 350, loss is 3.952416262626648 and perplexity is 52.06100805067494
At time: 494.6186318397522 and batch: 400, loss is 3.9050308084487915 and perplexity is 49.6516095776848
At time: 495.89678287506104 and batch: 450, loss is 3.9433367919921873 and perplexity is 51.59046104825122
At time: 497.1724088191986 and batch: 500, loss is 3.941563467979431 and perplexity is 51.49905551461246
At time: 498.45788621902466 and batch: 550, loss is 3.8936349296569825 and perplexity is 49.08899767033991
At time: 499.7383370399475 and batch: 600, loss is 3.8320212078094484 and perplexity is 46.155734348846146
At time: 501.01843190193176 and batch: 650, loss is 3.887849555015564 and perplexity is 48.80581936418523
At time: 502.3001835346222 and batch: 700, loss is 3.944431114196777 and perplexity is 51.64694853744103
At time: 503.58228182792664 and batch: 750, loss is 3.8941152715682983 and perplexity is 49.11258283732406
At time: 504.8640625476837 and batch: 800, loss is 3.885285077095032 and perplexity is 48.68081826781444
At time: 506.1453094482422 and batch: 850, loss is 3.878023705482483 and perplexity is 48.32860906451586
At time: 507.4262888431549 and batch: 900, loss is 3.832182402610779 and perplexity is 46.16317501295685
At time: 508.70622539520264 and batch: 950, loss is 3.9185218715667727 and perplexity is 50.32600147952388
At time: 509.9846341609955 and batch: 1000, loss is 3.8960289907455445 and perplexity is 49.20666051936419
At time: 511.26524114608765 and batch: 1050, loss is 3.8420093059539795 and perplexity is 46.619052334419635
At time: 512.5467834472656 and batch: 1100, loss is 3.8625383806228637 and perplexity is 47.58598954505364
At time: 513.8287084102631 and batch: 1150, loss is 3.839032769203186 and perplexity is 46.480495324174214
At time: 515.1111297607422 and batch: 1200, loss is 3.887761836051941 and perplexity is 48.80153835605738
At time: 516.3911018371582 and batch: 1250, loss is 3.872032461166382 and perplexity is 48.03992620843562
At time: 517.6721155643463 and batch: 1300, loss is 3.859587526321411 and perplexity is 47.44577719796156
At time: 518.9516673088074 and batch: 1350, loss is 3.711185598373413 and perplexity is 40.90227145785096
At time: 520.2305603027344 and batch: 1400, loss is 3.7312097787857055 and perplexity is 41.72956117723235
At time: 521.5103914737701 and batch: 1450, loss is 3.6636417436599733 and perplexity is 39.00312392879057
At time: 522.7919058799744 and batch: 1500, loss is 3.6596340131759644 and perplexity is 38.84712273422736
At time: 524.0724713802338 and batch: 1550, loss is 3.6824027967453 and perplexity is 39.74177083881721
At time: 525.3535535335541 and batch: 1600, loss is 3.768219714164734 and perplexity is 43.302904624886146
At time: 526.6351680755615 and batch: 1650, loss is 3.739243688583374 and perplexity is 42.06616301155497
At time: 527.9145455360413 and batch: 1700, loss is 3.7309769010543823 and perplexity is 41.71984442314802
At time: 529.194004535675 and batch: 1750, loss is 3.7153401470184324 and perplexity is 41.07255541587902
At time: 530.4752168655396 and batch: 1800, loss is 3.6694371461868287 and perplexity is 39.229818991838954
At time: 531.756329536438 and batch: 1850, loss is 3.696259331703186 and perplexity is 40.29628703990071
At time: 533.0354468822479 and batch: 1900, loss is 3.787526559829712 and perplexity is 44.14706998445523
At time: 534.3124289512634 and batch: 1950, loss is 3.715099949836731 and perplexity is 41.06269108856209
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359115529614826 and perplexity of 78.18794890603915
finished 10 epochs...
Completing Train Step...
At time: 538.421263217926 and batch: 50, loss is 3.9509346437454225 and perplexity is 51.983930591980496
At time: 539.7206773757935 and batch: 100, loss is 3.9292443943023683 and perplexity is 50.868526595579965
At time: 541.0030791759491 and batch: 150, loss is 3.88512638092041 and perplexity is 48.6730934211459
At time: 542.2827141284943 and batch: 200, loss is 3.889331159591675 and perplexity is 48.87818388406036
At time: 543.5626151561737 and batch: 250, loss is 3.8801544809341433 and perplexity is 48.43169626716073
At time: 544.8429172039032 and batch: 300, loss is 3.898348960876465 and perplexity is 49.32095102603054
At time: 546.124968290329 and batch: 350, loss is 3.8999618816375734 and perplexity is 49.400566000961064
At time: 547.4051446914673 and batch: 400, loss is 3.8565022134780884 and perplexity is 47.29961772200831
At time: 548.6913363933563 and batch: 450, loss is 3.899776048660278 and perplexity is 49.391386599645195
At time: 549.9703023433685 and batch: 500, loss is 3.8990210247039796 and perplexity is 49.35410899404116
At time: 551.2645671367645 and batch: 550, loss is 3.850091462135315 and perplexity is 46.99736151404947
At time: 552.5439813137054 and batch: 600, loss is 3.7935671281814574 and perplexity is 44.41455043185949
At time: 553.8224534988403 and batch: 650, loss is 3.8501014947891234 and perplexity is 46.997833024672715
At time: 555.1032147407532 and batch: 700, loss is 3.9100893545150757 and perplexity is 49.9034108692725
At time: 556.3820209503174 and batch: 750, loss is 3.861654496192932 and perplexity is 47.543947612653724
At time: 557.6609683036804 and batch: 800, loss is 3.8527179956436157 and perplexity is 47.12096391072839
At time: 558.9391920566559 and batch: 850, loss is 3.846026077270508 and perplexity is 46.80668699712404
At time: 560.2196884155273 and batch: 900, loss is 3.800605716705322 and perplexity is 44.728268949421775
At time: 561.4994738101959 and batch: 950, loss is 3.8867393350601196 and perplexity is 48.75166423719922
At time: 562.7828900814056 and batch: 1000, loss is 3.8654350423812867 and perplexity is 47.724029892783044
At time: 564.063889503479 and batch: 1050, loss is 3.812971873283386 and perplexity is 45.28481983201485
At time: 565.3450937271118 and batch: 1100, loss is 3.832556619644165 and perplexity is 46.18045329207342
At time: 566.6258592605591 and batch: 1150, loss is 3.810569248199463 and perplexity is 45.17614798909001
At time: 567.9080250263214 and batch: 1200, loss is 3.8617225217819215 and perplexity is 47.547181927699796
At time: 569.1895952224731 and batch: 1250, loss is 3.8489828729629516 and perplexity is 46.945289616449195
At time: 570.4714334011078 and batch: 1300, loss is 3.8379346752166748 and perplexity is 46.42948338484647
At time: 571.7562437057495 and batch: 1350, loss is 3.690799584388733 and perplexity is 40.076878996215505
At time: 573.0367290973663 and batch: 1400, loss is 3.7136663722991945 and perplexity is 41.00386671171376
At time: 574.3172526359558 and batch: 1450, loss is 3.6490730667114257 and perplexity is 38.43901912401755
At time: 575.5971345901489 and batch: 1500, loss is 3.6479056215286256 and perplexity is 38.394169860931584
At time: 576.8789463043213 and batch: 1550, loss is 3.6730193185806272 and perplexity is 39.370598964971705
At time: 578.1621465682983 and batch: 1600, loss is 3.7600464725494387 and perplexity is 42.95042194799117
At time: 579.4427003860474 and batch: 1650, loss is 3.7314690017700194 and perplexity is 41.740379840777365
At time: 580.722797870636 and batch: 1700, loss is 3.725895447731018 and perplexity is 41.508384697428006
At time: 582.0033710002899 and batch: 1750, loss is 3.7132824563980105 and perplexity is 40.988127696695486
At time: 583.2879898548126 and batch: 1800, loss is 3.6691854190826416 and perplexity is 39.21994502593092
At time: 584.5715177059174 and batch: 1850, loss is 3.698470644950867 and perplexity is 40.38549334845946
At time: 585.853113412857 and batch: 1900, loss is 3.790117554664612 and perplexity is 44.26160312807852
At time: 587.1325900554657 and batch: 1950, loss is 3.71825635433197 and perplexity is 41.19250631820997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35777218840843 and perplexity of 78.08298632849218
finished 11 epochs...
Completing Train Step...
At time: 591.2706575393677 and batch: 50, loss is 3.9318932104110718 and perplexity is 51.00344657847863
At time: 592.550787448883 and batch: 100, loss is 3.9067557048797608 and perplexity is 49.73732736773952
At time: 593.8308880329132 and batch: 150, loss is 3.8620193719863893 and perplexity is 47.56129841351409
At time: 595.1092903614044 and batch: 200, loss is 3.86478235244751 and perplexity is 47.692891061978905
At time: 596.3911278247833 and batch: 250, loss is 3.854949836730957 and perplexity is 47.22624785887752
At time: 597.6694571971893 and batch: 300, loss is 3.872990083694458 and perplexity is 48.08595235834163
At time: 598.9530966281891 and batch: 350, loss is 3.8757854747772216 and perplexity is 48.22055945285214
At time: 600.2354884147644 and batch: 400, loss is 3.8323373413085937 and perplexity is 46.17032802930556
At time: 601.5136475563049 and batch: 450, loss is 3.8780231618881227 and perplexity is 48.32858279336367
At time: 602.7928841114044 and batch: 500, loss is 3.8778437185287475 and perplexity is 48.31991132815509
At time: 604.0717680454254 and batch: 550, loss is 3.828340005874634 and perplexity is 45.986138120759875
At time: 605.3505160808563 and batch: 600, loss is 3.7736656618118287 and perplexity is 43.53937328998675
At time: 606.6302556991577 and batch: 650, loss is 3.8300991106033324 and perplexity is 46.06710374641148
At time: 607.9102623462677 and batch: 700, loss is 3.8908684492111205 and perplexity is 48.953381594283044
At time: 609.1880967617035 and batch: 750, loss is 3.843261489868164 and perplexity is 46.67746452561807
At time: 610.468519449234 and batch: 800, loss is 3.8340771102905276 and perplexity is 46.25072364852053
At time: 611.7489831447601 and batch: 850, loss is 3.8273475408554076 and perplexity is 45.94052112768501
At time: 613.0277924537659 and batch: 900, loss is 3.7826511335372923 and perplexity is 43.932358030177824
At time: 614.3279876708984 and batch: 950, loss is 3.8687508869171143 and perplexity is 47.88253800542958
At time: 615.6090471744537 and batch: 1000, loss is 3.8477173948287966 and perplexity is 46.88591895299939
At time: 616.8901026248932 and batch: 1050, loss is 3.79609028339386 and perplexity is 44.52675673371749
At time: 618.1697323322296 and batch: 1100, loss is 3.8152861738204957 and perplexity is 45.38974388093539
At time: 619.451507806778 and batch: 1150, loss is 3.79380392074585 and perplexity is 44.425068712428754
At time: 620.7308859825134 and batch: 1200, loss is 3.8456552457809448 and perplexity is 46.78933282159963
At time: 622.01122879982 and batch: 1250, loss is 3.834251480102539 and perplexity is 46.25878908167211
At time: 623.2929487228394 and batch: 1300, loss is 3.823959035873413 and perplexity is 45.7851148890727
At time: 624.5751638412476 and batch: 1350, loss is 3.6769505882263185 and perplexity is 39.525680038644246
At time: 625.8557648658752 and batch: 1400, loss is 3.7007631206512452 and perplexity is 40.47818231361528
At time: 627.1379842758179 and batch: 1450, loss is 3.6377157497406007 and perplexity is 38.00492473963182
At time: 628.4196221828461 and batch: 1500, loss is 3.6373566198349 and perplexity is 37.99127848512962
At time: 629.6984913349152 and batch: 1550, loss is 3.663923363685608 and perplexity is 39.01410953636216
At time: 630.982241153717 and batch: 1600, loss is 3.751052861213684 and perplexity is 42.565874374003364
At time: 632.266348361969 and batch: 1650, loss is 3.7223816776275633 and perplexity is 41.36278971967548
At time: 633.5476863384247 and batch: 1700, loss is 3.7178367614746093 and perplexity is 41.1752258624135
At time: 634.8314282894135 and batch: 1750, loss is 3.706494393348694 and perplexity is 40.71083988990804
At time: 636.1123745441437 and batch: 1800, loss is 3.6630534076690675 and perplexity is 38.98018373615769
At time: 637.3922348022461 and batch: 1850, loss is 3.69416729927063 and perplexity is 40.21207401940059
At time: 638.6719958782196 and batch: 1900, loss is 3.785527439117432 and perplexity is 44.058902820228106
At time: 639.9527592658997 and batch: 1950, loss is 3.7141530179977416 and perplexity is 41.02382592321113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358855491460756 and perplexity of 78.16761969943433
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 644.0646319389343 and batch: 50, loss is 3.929063482284546 and perplexity is 50.85932470018173
At time: 645.3459758758545 and batch: 100, loss is 3.9240194368362427 and perplexity is 50.603433859977315
At time: 646.667195558548 and batch: 150, loss is 3.889162359237671 and perplexity is 48.86993392563521
At time: 647.9471180438995 and batch: 200, loss is 3.8959160375595094 and perplexity is 49.20110278417224
At time: 649.2262749671936 and batch: 250, loss is 3.8974675369262695 and perplexity is 49.27749751184712
At time: 650.5082521438599 and batch: 300, loss is 3.911238555908203 and perplexity is 49.96079290400721
At time: 651.7893786430359 and batch: 350, loss is 3.9150924682617188 and perplexity is 50.15370892290966
At time: 653.0699331760406 and batch: 400, loss is 3.871700716018677 and perplexity is 48.02399183924083
At time: 654.3476233482361 and batch: 450, loss is 3.917744770050049 and perplexity is 50.286908259111264
At time: 655.6294507980347 and batch: 500, loss is 3.9201556491851806 and perplexity is 50.40829017677705
At time: 656.9083523750305 and batch: 550, loss is 3.9038748359680175 and perplexity is 49.59424684464496
At time: 658.1895809173584 and batch: 600, loss is 3.8396449518203735 and perplexity is 46.50895858691835
At time: 659.4718782901764 and batch: 650, loss is 3.8670191860198972 and perplexity is 47.799691524770246
At time: 660.7538182735443 and batch: 700, loss is 3.9107755041122436 and perplexity is 49.93766382451962
At time: 662.0357341766357 and batch: 750, loss is 3.856820068359375 and perplexity is 47.31465452601841
At time: 663.3160398006439 and batch: 800, loss is 3.8561595392227175 and perplexity is 47.283412137502964
At time: 664.5991716384888 and batch: 850, loss is 3.8582033824920656 and perplexity is 47.3801508468565
At time: 665.877189874649 and batch: 900, loss is 3.8116054105758668 and perplexity is 45.22298207361511
At time: 667.1571519374847 and batch: 950, loss is 3.897040076255798 and perplexity is 49.25643782113699
At time: 668.4373199939728 and batch: 1000, loss is 3.8648768949508665 and perplexity is 47.697400280445265
At time: 669.7154145240784 and batch: 1050, loss is 3.807919158935547 and perplexity is 45.05658565971535
At time: 670.9945042133331 and batch: 1100, loss is 3.8287515783309938 and perplexity is 46.00506864395848
At time: 672.2748792171478 and batch: 1150, loss is 3.817381052970886 and perplexity is 45.484929575486234
At time: 673.5518505573273 and batch: 1200, loss is 3.8672284269332886 and perplexity is 47.809694222335004
At time: 674.8336658477783 and batch: 1250, loss is 3.855848455429077 and perplexity is 47.26870532192356
At time: 676.1141932010651 and batch: 1300, loss is 3.85032208442688 and perplexity is 47.00820140317135
At time: 677.3911864757538 and batch: 1350, loss is 3.6936390161514283 and perplexity is 40.190836269774294
At time: 678.6771583557129 and batch: 1400, loss is 3.710057783126831 and perplexity is 40.85616725587883
At time: 679.9584906101227 and batch: 1450, loss is 3.6394804430007937 and perplexity is 38.072050985370645
At time: 681.2375767230988 and batch: 1500, loss is 3.6292470788955686 and perplexity is 37.68443252847372
At time: 682.5175800323486 and batch: 1550, loss is 3.650400743484497 and perplexity is 38.49008761060824
At time: 683.7973115444183 and batch: 1600, loss is 3.7354077339172362 and perplexity is 41.90510821420232
At time: 685.0749843120575 and batch: 1650, loss is 3.7030847215652467 and perplexity is 40.572265668415156
At time: 686.3536427021027 and batch: 1700, loss is 3.7046471309661864 and perplexity is 40.635705704461856
At time: 687.6325838565826 and batch: 1750, loss is 3.69991530418396 and perplexity is 40.44387878768587
At time: 688.9117443561554 and batch: 1800, loss is 3.662664337158203 and perplexity is 38.96502064610475
At time: 690.194582939148 and batch: 1850, loss is 3.7015171909332274 and perplexity is 40.50871721925218
At time: 691.4775431156158 and batch: 1900, loss is 3.796426010131836 and perplexity is 44.54170806614896
At time: 692.7562534809113 and batch: 1950, loss is 3.738386240005493 and perplexity is 42.03010889938638
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3367746752361915 and perplexity of 76.46053116701253
finished 13 epochs...
Completing Train Step...
At time: 696.8702094554901 and batch: 50, loss is 3.948446497917175 and perplexity is 51.85474777143633
At time: 698.1552774906158 and batch: 100, loss is 3.918501443862915 and perplexity is 50.32497344536954
At time: 699.4359872341156 and batch: 150, loss is 3.869986710548401 and perplexity is 47.941748957033404
At time: 700.7149958610535 and batch: 200, loss is 3.868398084640503 and perplexity is 47.86564791661743
At time: 701.9937529563904 and batch: 250, loss is 3.864017252922058 and perplexity is 47.656415209268104
At time: 703.273708820343 and batch: 300, loss is 3.8772156190872193 and perplexity is 48.28957114815769
At time: 704.5532128810883 and batch: 350, loss is 3.8812385845184325 and perplexity is 48.484229713380714
At time: 705.8321945667267 and batch: 400, loss is 3.841155686378479 and perplexity is 46.5792743787919
At time: 707.1099698543549 and batch: 450, loss is 3.890419373512268 and perplexity is 48.93140275568291
At time: 708.3863761425018 and batch: 500, loss is 3.8982769536972044 and perplexity is 49.31739969133104
At time: 709.6791157722473 and batch: 550, loss is 3.8821991539001464 and perplexity is 48.53082455514581
At time: 710.9604642391205 and batch: 600, loss is 3.819689168930054 and perplexity is 45.59003531880113
At time: 712.2409243583679 and batch: 650, loss is 3.8447711086273193 and perplexity is 46.747982916246116
At time: 713.5220170021057 and batch: 700, loss is 3.8919454860687255 and perplexity is 49.00613459392748
At time: 714.8014495372772 and batch: 750, loss is 3.841830163002014 and perplexity is 46.61070160777586
At time: 716.0828640460968 and batch: 800, loss is 3.8414311456680297 and perplexity is 46.59210683994924
At time: 717.3605892658234 and batch: 850, loss is 3.8432491397857667 and perplexity is 46.6768880586448
At time: 718.6431126594543 and batch: 900, loss is 3.7967366552352906 and perplexity is 44.55554687902765
At time: 719.919997215271 and batch: 950, loss is 3.8829869079589843 and perplexity is 48.569069971180944
At time: 721.1990461349487 and batch: 1000, loss is 3.8517255926132203 and perplexity is 47.07422411953947
At time: 722.4825081825256 and batch: 1050, loss is 3.795331349372864 and perplexity is 44.49297668322383
At time: 723.7834179401398 and batch: 1100, loss is 3.816245265007019 and perplexity is 45.43329766693768
At time: 725.0828504562378 and batch: 1150, loss is 3.804592752456665 and perplexity is 44.906958140204495
At time: 726.3709714412689 and batch: 1200, loss is 3.8549975824356078 and perplexity is 47.22850276319013
At time: 727.6525149345398 and batch: 1250, loss is 3.8452021884918213 and perplexity is 46.76813937459692
At time: 728.9296238422394 and batch: 1300, loss is 3.8400801324844362 and perplexity is 46.52920279102467
At time: 730.2190475463867 and batch: 1350, loss is 3.6850622606277468 and perplexity is 39.84760330942691
At time: 731.5089752674103 and batch: 1400, loss is 3.7034323740005495 and perplexity is 40.58637316749165
At time: 732.7983865737915 and batch: 1450, loss is 3.634336247444153 and perplexity is 37.87670379272481
At time: 734.079512834549 and batch: 1500, loss is 3.626310420036316 and perplexity is 37.57392854150443
At time: 735.3606059551239 and batch: 1550, loss is 3.6487849378585815 and perplexity is 38.427945328949434
At time: 736.6408905982971 and batch: 1600, loss is 3.73525981426239 and perplexity is 41.89891008348297
At time: 737.9196352958679 and batch: 1650, loss is 3.7041522550582884 and perplexity is 40.61560104777371
At time: 739.202451467514 and batch: 1700, loss is 3.7064838886260985 and perplexity is 40.71041223607457
At time: 740.4804530143738 and batch: 1750, loss is 3.7024216079711914 and perplexity is 40.54537056574843
At time: 741.7644636631012 and batch: 1800, loss is 3.665725975036621 and perplexity is 39.08450023753987
At time: 743.045289516449 and batch: 1850, loss is 3.705520601272583 and perplexity is 40.67121529280202
At time: 744.3271203041077 and batch: 1900, loss is 3.80108642578125 and perplexity is 44.749775403015875
At time: 745.606288433075 and batch: 1950, loss is 3.742763524055481 and perplexity is 42.214489874236754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335590025436047 and perplexity of 76.37000584503576
finished 14 epochs...
Completing Train Step...
At time: 749.7312586307526 and batch: 50, loss is 3.9441141366958616 and perplexity is 51.63058021109635
At time: 751.0300619602203 and batch: 100, loss is 3.9113210153579714 and perplexity is 49.964912813360456
At time: 752.3098170757294 and batch: 150, loss is 3.861785526275635 and perplexity is 47.550177708197474
At time: 753.5886299610138 and batch: 200, loss is 3.8592556810379026 and perplexity is 47.43003515268222
At time: 754.870444059372 and batch: 250, loss is 3.854293260574341 and perplexity is 47.19525040777417
At time: 756.1508514881134 and batch: 300, loss is 3.8676779794692995 and perplexity is 47.83119202345201
At time: 757.4325504302979 and batch: 350, loss is 3.8725029468536376 and perplexity is 48.06253362394919
At time: 758.7129888534546 and batch: 400, loss is 3.832080626487732 and perplexity is 46.15847694305621
At time: 759.9960379600525 and batch: 450, loss is 3.881845760345459 and perplexity is 48.513677104622055
At time: 761.2751216888428 and batch: 500, loss is 3.8898540210723875 and perplexity is 48.90374708608498
At time: 762.5558483600616 and batch: 550, loss is 3.8736624002456663 and perplexity is 48.11829221008338
At time: 763.8380239009857 and batch: 600, loss is 3.812210636138916 and perplexity is 45.250360462618104
At time: 765.1163239479065 and batch: 650, loss is 3.836961703300476 and perplexity is 46.38433077110403
At time: 766.3991601467133 and batch: 700, loss is 3.883912582397461 and perplexity is 48.614049932942436
At time: 767.6781203746796 and batch: 750, loss is 3.8342056322097777 and perplexity is 46.25666826228895
At time: 768.9544861316681 and batch: 800, loss is 3.833015604019165 and perplexity is 46.20165426365005
At time: 770.2370066642761 and batch: 850, loss is 3.8345008993148806 and perplexity is 46.2703283514067
At time: 771.5175061225891 and batch: 900, loss is 3.788842549324036 and perplexity is 44.20520530910816
At time: 772.798285484314 and batch: 950, loss is 3.8759968996047975 and perplexity is 48.23075555413658
At time: 774.0950882434845 and batch: 1000, loss is 3.844855670928955 and perplexity is 46.75193620042539
At time: 775.3758492469788 and batch: 1050, loss is 3.78882390499115 and perplexity is 44.20438114022814
At time: 776.6531748771667 and batch: 1100, loss is 3.809815583229065 and perplexity is 45.14211313590245
At time: 777.9334857463837 and batch: 1150, loss is 3.798396806716919 and perplexity is 44.62957727002233
At time: 779.2156608104706 and batch: 1200, loss is 3.8492384004592894 and perplexity is 46.95728696153024
At time: 780.4959828853607 and batch: 1250, loss is 3.8404519367218017 and perplexity is 46.54650576224329
At time: 781.773998260498 and batch: 1300, loss is 3.8355470848083497 and perplexity is 46.31876102807038
At time: 783.0522668361664 and batch: 1350, loss is 3.680793023109436 and perplexity is 39.67784704909822
At time: 784.3316836357117 and batch: 1400, loss is 3.699639139175415 and perplexity is 40.43271114568183
At time: 785.6093935966492 and batch: 1450, loss is 3.631584448814392 and perplexity is 37.77261800836907
At time: 786.8892858028412 and batch: 1500, loss is 3.624141526222229 and perplexity is 37.492522992227606
At time: 788.171318769455 and batch: 1550, loss is 3.6474521732330323 and perplexity is 38.37676403666634
At time: 789.4539015293121 and batch: 1600, loss is 3.7343966150283814 and perplexity is 41.86275858161221
At time: 790.7394299507141 and batch: 1650, loss is 3.7034970235824587 and perplexity is 40.58899714436673
At time: 792.0193183422089 and batch: 1700, loss is 3.7061163234710692 and perplexity is 40.695451256825486
At time: 793.2988879680634 and batch: 1750, loss is 3.7019872999191286 and perplexity is 40.52776520818886
At time: 794.5784251689911 and batch: 1800, loss is 3.6654281187057496 and perplexity is 39.0728604052901
At time: 795.857982635498 and batch: 1850, loss is 3.705194716453552 and perplexity is 40.65796332059212
At time: 797.135987997055 and batch: 1900, loss is 3.8011321353912355 and perplexity is 44.75182094454659
At time: 798.4174842834473 and batch: 1950, loss is 3.742202863693237 and perplexity is 42.190828516664396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335499466297239 and perplexity of 76.3630901562198
finished 15 epochs...
Completing Train Step...
At time: 802.5567274093628 and batch: 50, loss is 3.9384793615341187 and perplexity is 51.34047161608448
At time: 803.8526093959808 and batch: 100, loss is 3.9043815088272096 and perplexity is 49.619381270421194
At time: 805.1310157775879 and batch: 150, loss is 3.85484317779541 and perplexity is 47.22121102616741
At time: 806.4263799190521 and batch: 200, loss is 3.8521593141555788 and perplexity is 47.09464565293927
At time: 807.703161239624 and batch: 250, loss is 3.846805200576782 and perplexity is 46.843169388148034
At time: 808.9863986968994 and batch: 300, loss is 3.8604544258117675 and perplexity is 47.486925751287
At time: 810.2664341926575 and batch: 350, loss is 3.866076560020447 and perplexity is 47.754655522161485
At time: 811.5448758602142 and batch: 400, loss is 3.8252617931365966 and perplexity is 45.844800649627736
At time: 812.8243429660797 and batch: 450, loss is 3.8752812719345093 and perplexity is 48.19625263799636
At time: 814.1033761501312 and batch: 500, loss is 3.883366708755493 and perplexity is 48.587520046096486
At time: 815.3810138702393 and batch: 550, loss is 3.8673490953445433 and perplexity is 47.81546369026865
At time: 816.6628947257996 and batch: 600, loss is 3.8068208837509157 and perplexity is 45.00712829365131
At time: 817.9424755573273 and batch: 650, loss is 3.831585192680359 and perplexity is 46.13561413705293
At time: 819.2224206924438 and batch: 700, loss is 3.8780180978775025 and perplexity is 48.32833805752683
At time: 820.5072340965271 and batch: 750, loss is 3.8283596229553223 and perplexity is 45.98704024339041
At time: 821.786375284195 and batch: 800, loss is 3.826332015991211 and perplexity is 45.893891067206035
At time: 823.0658369064331 and batch: 850, loss is 3.8275853872299193 and perplexity is 45.951449213629694
At time: 824.3462114334106 and batch: 900, loss is 3.7825893783569335 and perplexity is 43.92964506325483
At time: 825.6239566802979 and batch: 950, loss is 3.8704429149627684 and perplexity is 47.96362518417639
At time: 826.9031493663788 and batch: 1000, loss is 3.8391948318481446 and perplexity is 46.488028686607265
At time: 828.1835222244263 and batch: 1050, loss is 3.783571319580078 and perplexity is 43.97280257826435
At time: 829.4627845287323 and batch: 1100, loss is 3.8045988512039184 and perplexity is 44.907232017227265
At time: 830.7444105148315 and batch: 1150, loss is 3.7932108497619628 and perplexity is 44.39872930455953
At time: 832.0251262187958 and batch: 1200, loss is 3.8445043420791625 and perplexity is 46.73551378145822
At time: 833.3066818714142 and batch: 1250, loss is 3.836392517089844 and perplexity is 46.357936961848424
At time: 834.5897731781006 and batch: 1300, loss is 3.8315949630737305 and perplexity is 46.13606490235357
At time: 835.8726878166199 and batch: 1350, loss is 3.676956810951233 and perplexity is 39.52592599684345
At time: 837.1540100574493 and batch: 1400, loss is 3.6960023164749147 and perplexity is 40.28593161129709
At time: 838.435905456543 and batch: 1450, loss is 3.6288412904739378 and perplexity is 37.66914372429759
At time: 839.7196774482727 and batch: 1500, loss is 3.621706638336182 and perplexity is 37.401343952593606
At time: 841.002447605133 and batch: 1550, loss is 3.6457205963134767 and perplexity is 38.310369218270395
At time: 842.2841446399689 and batch: 1600, loss is 3.7328987407684324 and perplexity is 41.800100371857276
At time: 843.5671727657318 and batch: 1650, loss is 3.7021045446395875 and perplexity is 40.532517153256315
At time: 844.8486874103546 and batch: 1700, loss is 3.704918174743652 and perplexity is 40.64672125241641
At time: 846.1302206516266 and batch: 1750, loss is 3.7005914211273194 and perplexity is 40.471232825611615
At time: 847.4106938838959 and batch: 1800, loss is 3.6640775537490846 and perplexity is 39.020125588183845
At time: 848.6931471824646 and batch: 1850, loss is 3.703736891746521 and perplexity is 40.598734320365466
At time: 849.9723596572876 and batch: 1900, loss is 3.7999467611312867 and perplexity is 44.69880471615714
At time: 851.255179643631 and batch: 1950, loss is 3.740238976478577 and perplexity is 42.10805179664046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335753826762355 and perplexity of 76.3825163778763
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 855.3908333778381 and batch: 50, loss is 3.939070234298706 and perplexity is 51.37081626651437
At time: 856.6891317367554 and batch: 100, loss is 3.915736126899719 and perplexity is 50.18600118236663
At time: 857.9671955108643 and batch: 150, loss is 3.8727453756332397 and perplexity is 48.07418677779309
At time: 859.2483599185944 and batch: 200, loss is 3.871604313850403 and perplexity is 48.01936244544375
At time: 860.5303177833557 and batch: 250, loss is 3.8710578870773316 and perplexity is 47.99313054773604
At time: 861.8085572719574 and batch: 300, loss is 3.881399450302124 and perplexity is 48.49202979435649
At time: 863.0916357040405 and batch: 350, loss is 3.886377453804016 and perplexity is 48.73402511553418
At time: 864.3748724460602 and batch: 400, loss is 3.846788988113403 and perplexity is 46.84240995113597
At time: 865.6520802974701 and batch: 450, loss is 3.8948815441131592 and perplexity is 49.150230883649485
At time: 866.9316821098328 and batch: 500, loss is 3.9019644355773924 and perplexity is 49.499592418814025
At time: 868.2120862007141 and batch: 550, loss is 3.8978176593780516 and perplexity is 49.294753690805216
At time: 869.4925835132599 and batch: 600, loss is 3.8476741123199463 and perplexity is 46.88388965671419
At time: 870.7935883998871 and batch: 650, loss is 3.881213331222534 and perplexity is 48.48300534224112
At time: 872.0743567943573 and batch: 700, loss is 3.925737051963806 and perplexity is 50.69042577140641
At time: 873.3502950668335 and batch: 750, loss is 3.8662038803100587 and perplexity is 47.760736045811676
At time: 874.6274478435516 and batch: 800, loss is 3.8597553634643553 and perplexity is 47.45374102994594
At time: 875.9081058502197 and batch: 850, loss is 3.8553045082092283 and perplexity is 47.24300063270876
At time: 877.1865878105164 and batch: 900, loss is 3.804045920372009 and perplexity is 44.88240828760443
At time: 878.4670701026917 and batch: 950, loss is 3.894545931816101 and perplexity is 49.13373822948527
At time: 879.7472760677338 and batch: 1000, loss is 3.8543863487243653 and perplexity is 47.199643930813856
At time: 881.0268752574921 and batch: 1050, loss is 3.7938733673095704 and perplexity is 44.42815398792353
At time: 882.3069860935211 and batch: 1100, loss is 3.808451747894287 and perplexity is 45.08058869106361
At time: 883.5883848667145 and batch: 1150, loss is 3.797136845588684 and perplexity is 44.57338114739187
At time: 884.8687925338745 and batch: 1200, loss is 3.851968388557434 and perplexity is 47.08565493785471
At time: 886.1492879390717 and batch: 1250, loss is 3.849411954879761 and perplexity is 46.965437313500104
At time: 887.4305303096771 and batch: 1300, loss is 3.8504372787475587 and perplexity is 47.0136167929034
At time: 888.7104804515839 and batch: 1350, loss is 3.69845769405365 and perplexity is 40.384970323472885
At time: 889.9909586906433 and batch: 1400, loss is 3.722670168876648 and perplexity is 41.374724243967485
At time: 891.2720174789429 and batch: 1450, loss is 3.6608720302581785 and perplexity is 38.89524591828268
At time: 892.5546879768372 and batch: 1500, loss is 3.649428906440735 and perplexity is 38.452699688077296
At time: 893.8310286998749 and batch: 1550, loss is 3.6685053443908693 and perplexity is 39.193281601493815
At time: 895.1171464920044 and batch: 1600, loss is 3.74750684261322 and perplexity is 42.41520229261204
At time: 896.3967065811157 and batch: 1650, loss is 3.701124658584595 and perplexity is 40.492819357758606
At time: 897.6766016483307 and batch: 1700, loss is 3.6913748359680176 and perplexity is 40.09993991643033
At time: 898.9589278697968 and batch: 1750, loss is 3.685654377937317 and perplexity is 39.87120475181303
At time: 900.2396750450134 and batch: 1800, loss is 3.6487934732437135 and perplexity is 38.428273327662446
At time: 901.5209395885468 and batch: 1850, loss is 3.691952624320984 and perplexity is 40.12311588942757
At time: 902.8033163547516 and batch: 1900, loss is 3.795077233314514 and perplexity is 44.48167173980949
At time: 904.0853452682495 and batch: 1950, loss is 3.7494110107421874 and perplexity is 42.496044913545475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33199462890625 and perplexity of 76.0959184127991
finished 17 epochs...
Completing Train Step...
At time: 908.2039923667908 and batch: 50, loss is 3.957151460647583 and perplexity is 52.30811181387433
At time: 909.4821059703827 and batch: 100, loss is 3.9288160371780396 and perplexity is 50.846741366070894
At time: 910.7611739635468 and batch: 150, loss is 3.879652404785156 and perplexity is 48.40738597093064
At time: 912.0424990653992 and batch: 200, loss is 3.87567946434021 and perplexity is 48.21544784121849
At time: 913.3213820457458 and batch: 250, loss is 3.8733802604675294 and perplexity is 48.104718040791504
At time: 914.6018133163452 and batch: 300, loss is 3.8846806478500366 and perplexity is 48.65140304818811
At time: 915.8819556236267 and batch: 350, loss is 3.890248212814331 and perplexity is 48.923028339342146
At time: 917.1593391895294 and batch: 400, loss is 3.846377272605896 and perplexity is 46.82312817412575
At time: 918.4445297718048 and batch: 450, loss is 3.890924167633057 and perplexity is 48.95610927544426
At time: 919.7235715389252 and batch: 500, loss is 3.8956632804870606 and perplexity is 49.18866842897307
At time: 921.0065665245056 and batch: 550, loss is 3.8871506452560425 and perplexity is 48.7717204181413
At time: 922.2840456962585 and batch: 600, loss is 3.8348876905441283 and perplexity is 46.28822877022676
At time: 923.5671186447144 and batch: 650, loss is 3.8656602811813356 and perplexity is 47.73478040668057
At time: 924.8483035564423 and batch: 700, loss is 3.911073956489563 and perplexity is 49.952570063296385
At time: 926.1292178630829 and batch: 750, loss is 3.854010348320007 and perplexity is 47.18190018164779
At time: 927.4078471660614 and batch: 800, loss is 3.8478718996047974 and perplexity is 46.89316361105754
At time: 928.6889915466309 and batch: 850, loss is 3.8461478328704835 and perplexity is 46.81238632033746
At time: 929.9736595153809 and batch: 900, loss is 3.797820181846619 and perplexity is 44.6038501639749
At time: 931.255960226059 and batch: 950, loss is 3.8893971395492555 and perplexity is 48.88140897095403
At time: 932.5354175567627 and batch: 1000, loss is 3.8503203916549684 and perplexity is 47.008121829075755
At time: 933.8547968864441 and batch: 1050, loss is 3.790130715370178 and perplexity is 44.26218564583834
At time: 935.1356630325317 and batch: 1100, loss is 3.8048860311508177 and perplexity is 44.9201303257125
At time: 936.4176547527313 and batch: 1150, loss is 3.7942874956130983 and perplexity is 44.44655675425362
At time: 937.6970705986023 and batch: 1200, loss is 3.8487436676025393 and perplexity is 46.934061394505804
At time: 938.9764280319214 and batch: 1250, loss is 3.8461674308776854 and perplexity is 46.813303758811664
At time: 940.2560939788818 and batch: 1300, loss is 3.846818437576294 and perplexity is 46.843789455262275
At time: 941.5341742038727 and batch: 1350, loss is 3.695961208343506 and perplexity is 40.28427556596519
At time: 942.8152601718903 and batch: 1400, loss is 3.7216400480270386 and perplexity is 41.332125222713906
At time: 944.0948438644409 and batch: 1450, loss is 3.6605351114273073 and perplexity is 38.88214358483682
At time: 945.3730230331421 and batch: 1500, loss is 3.6502511405944826 and perplexity is 38.48432981296712
At time: 946.6551127433777 and batch: 1550, loss is 3.6698992919921873 and perplexity is 39.24795307810421
At time: 947.9360671043396 and batch: 1600, loss is 3.749622187614441 and perplexity is 42.505020043029994
At time: 949.2216668128967 and batch: 1650, loss is 3.703871865272522 and perplexity is 40.60421444451538
At time: 950.5024650096893 and batch: 1700, loss is 3.6941050148010253 and perplexity is 40.209569509695434
At time: 951.7829966545105 and batch: 1750, loss is 3.689311399459839 and perplexity is 40.01728154590908
At time: 953.0623080730438 and batch: 1800, loss is 3.6531216144561767 and perplexity is 38.59495677572221
At time: 954.3433678150177 and batch: 1850, loss is 3.697427167892456 and perplexity is 40.34337399177075
At time: 955.6246008872986 and batch: 1900, loss is 3.8007640075683593 and perplexity is 44.7353495861012
At time: 956.902595281601 and batch: 1950, loss is 3.7546910524368284 and perplexity is 42.721019216728536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330804301417151 and perplexity of 76.00539323729518
finished 18 epochs...
Completing Train Step...
At time: 961.0116345882416 and batch: 50, loss is 3.9575968647003172 and perplexity is 52.33141524820391
At time: 962.2897005081177 and batch: 100, loss is 3.926709060668945 and perplexity is 50.73972126046448
At time: 963.5700128078461 and batch: 150, loss is 3.8763564014434815 and perplexity is 48.24809771652226
At time: 964.8510591983795 and batch: 200, loss is 3.871771869659424 and perplexity is 48.02740904267519
At time: 966.1493117809296 and batch: 250, loss is 3.8684984922409056 and perplexity is 47.870454232757744
At time: 967.4284498691559 and batch: 300, loss is 3.879988169670105 and perplexity is 48.423642200294616
At time: 968.7123558521271 and batch: 350, loss is 3.8863097190856934 and perplexity is 48.73072424186339
At time: 969.9907398223877 and batch: 400, loss is 3.8419209861755372 and perplexity is 46.61493513186416
At time: 971.2705678939819 and batch: 450, loss is 3.886250920295715 and perplexity is 48.72785901847986
At time: 972.5494599342346 and batch: 500, loss is 3.890959439277649 and perplexity is 48.95783606838447
At time: 973.8302953243256 and batch: 550, loss is 3.8821611642837524 and perplexity is 48.52898092275734
At time: 975.1112067699432 and batch: 600, loss is 3.8297334623336794 and perplexity is 46.05026246881833
At time: 976.389434337616 and batch: 650, loss is 3.860451169013977 and perplexity is 47.48677109622398
At time: 977.6660621166229 and batch: 700, loss is 3.9067361688613893 and perplexity is 49.73635570788953
At time: 978.947327375412 and batch: 750, loss is 3.8507604455947875 and perplexity is 47.02881249045977
At time: 980.2280602455139 and batch: 800, loss is 3.844785990715027 and perplexity is 46.74867862900484
At time: 981.5060985088348 and batch: 850, loss is 3.8435992193222046 and perplexity is 46.69323154257146
At time: 982.7846426963806 and batch: 900, loss is 3.7958479070663453 and perplexity is 44.51596580972933
At time: 984.067883014679 and batch: 950, loss is 3.887907695770264 and perplexity is 48.808657053848734
At time: 985.3467884063721 and batch: 1000, loss is 3.849048237800598 and perplexity is 46.948358287973754
At time: 986.6281290054321 and batch: 1050, loss is 3.788733968734741 and perplexity is 44.200405742440395
At time: 987.9082872867584 and batch: 1100, loss is 3.8032349443435667 and perplexity is 44.84602448557413
At time: 989.1888902187347 and batch: 1150, loss is 3.7924672889709474 and perplexity is 44.36572842087981
At time: 990.4692902565002 and batch: 1200, loss is 3.8465511655807494 and perplexity is 46.83127109515375
At time: 991.7494728565216 and batch: 1250, loss is 3.8440893125534057 and perplexity is 46.71612118786533
At time: 993.0299682617188 and batch: 1300, loss is 3.844703793525696 and perplexity is 46.74483617693814
At time: 994.309916973114 and batch: 1350, loss is 3.694149866104126 and perplexity is 40.21137300172925
At time: 995.5884115695953 and batch: 1400, loss is 3.7203773641586304 and perplexity is 41.27996875044597
At time: 996.8672866821289 and batch: 1450, loss is 3.659489870071411 and perplexity is 38.84152359290199
At time: 998.1483323574066 and batch: 1500, loss is 3.6499298191070557 and perplexity is 38.471965957361604
At time: 999.4269089698792 and batch: 1550, loss is 3.6699043893814087 and perplexity is 39.24815314070709
At time: 1000.7079200744629 and batch: 1600, loss is 3.750199346542358 and perplexity is 42.52955927566654
At time: 1001.9868783950806 and batch: 1650, loss is 3.7046923875808715 and perplexity is 40.63754478055225
At time: 1003.2662994861603 and batch: 1700, loss is 3.694959421157837 and perplexity is 40.24393950236842
At time: 1004.5463478565216 and batch: 1750, loss is 3.6904959058761597 and perplexity is 40.064710356984
At time: 1005.8248229026794 and batch: 1800, loss is 3.6543940496444702 and perplexity is 38.6440976144502
At time: 1007.105320930481 and batch: 1850, loss is 3.6989331436157227 and perplexity is 40.40417590520842
At time: 1008.3864858150482 and batch: 1900, loss is 3.802228741645813 and perplexity is 44.800922989182126
At time: 1009.6649360656738 and batch: 1950, loss is 3.7558638620376588 and perplexity is 42.771152230716815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330400901617006 and perplexity of 75.97473886025378
finished 19 epochs...
Completing Train Step...
At time: 1013.8093066215515 and batch: 50, loss is 3.956514139175415 and perplexity is 52.27478535200971
At time: 1015.0882663726807 and batch: 100, loss is 3.9247441911697387 and perplexity is 50.64012221137201
At time: 1016.36772108078 and batch: 150, loss is 3.874012131690979 and perplexity is 48.13512363303138
At time: 1017.6441864967346 and batch: 200, loss is 3.869169430732727 and perplexity is 47.90258314017857
At time: 1018.9249267578125 and batch: 250, loss is 3.86555823802948 and perplexity is 47.72990964775276
At time: 1020.20587849617 and batch: 300, loss is 3.877058672904968 and perplexity is 48.2819928790292
At time: 1021.488775730133 and batch: 350, loss is 3.8836924123764036 and perplexity is 48.60334775473765
At time: 1022.765463590622 and batch: 400, loss is 3.838964123725891 and perplexity is 46.477304757898004
At time: 1024.0445387363434 and batch: 450, loss is 3.8833523654937743 and perplexity is 48.58682314757811
At time: 1025.3245935440063 and batch: 500, loss is 3.8879995012283324 and perplexity is 48.81313816065915
At time: 1026.605711221695 and batch: 550, loss is 3.8792219734191895 and perplexity is 48.386554397267275
At time: 1027.8851356506348 and batch: 600, loss is 3.8268172979354858 and perplexity is 45.91616794874048
At time: 1029.1628584861755 and batch: 650, loss is 3.857528257369995 and perplexity is 47.348174112095336
At time: 1030.4593722820282 and batch: 700, loss is 3.9040692901611327 and perplexity is 49.60389159159864
At time: 1031.741415977478 and batch: 750, loss is 3.8487143659591676 and perplexity is 46.93268616952511
At time: 1033.020717382431 and batch: 800, loss is 3.842738618850708 and perplexity is 46.653064611809086
At time: 1034.3036205768585 and batch: 850, loss is 3.8415585422515868 and perplexity is 46.59804289328981
At time: 1035.583990573883 and batch: 900, loss is 3.7940539836883547 and perplexity is 44.43617916493029
At time: 1036.8650963306427 and batch: 950, loss is 3.8863626670837403 and perplexity is 48.73330450446464
At time: 1038.1483108997345 and batch: 1000, loss is 3.8476769590377806 and perplexity is 46.884023122108985
At time: 1039.4298617839813 and batch: 1050, loss is 3.7873964643478395 and perplexity is 44.14132702368706
At time: 1040.710319519043 and batch: 1100, loss is 3.8018110847473143 and perplexity is 44.78221548156832
At time: 1041.9889211654663 and batch: 1150, loss is 3.7909393978118895 and perplexity is 44.29799417511487
At time: 1043.2688281536102 and batch: 1200, loss is 3.844916162490845 and perplexity is 46.754764383607274
At time: 1044.5504822731018 and batch: 1250, loss is 3.842603349685669 and perplexity is 46.64675431751626
At time: 1045.830025434494 and batch: 1300, loss is 3.8432947778701783 and perplexity is 46.67901835101295
At time: 1047.1121606826782 and batch: 1350, loss is 3.692901177406311 and perplexity is 40.1611928509521
At time: 1048.3936533927917 and batch: 1400, loss is 3.719366903305054 and perplexity is 41.238278024957104
At time: 1049.6701662540436 and batch: 1450, loss is 3.6585914993286135 and perplexity is 38.8066451737219
At time: 1050.950317144394 and batch: 1500, loss is 3.6495010900497435 and perplexity is 38.45547544289771
At time: 1052.230180978775 and batch: 1550, loss is 3.6696938371658323 and perplexity is 39.23989022502416
At time: 1053.5098242759705 and batch: 1600, loss is 3.7503781652450563 and perplexity is 42.53716503628839
At time: 1054.7886798381805 and batch: 1650, loss is 3.7049017190933227 and perplexity is 40.64605238968774
At time: 1056.0757465362549 and batch: 1700, loss is 3.695151519775391 and perplexity is 40.251671050097784
At time: 1057.354445695877 and batch: 1750, loss is 3.690811424255371 and perplexity is 40.07735350392713
At time: 1058.6353573799133 and batch: 1800, loss is 3.654707865715027 and perplexity is 38.65622665635838
At time: 1059.9151844978333 and batch: 1850, loss is 3.6992652559280397 and perplexity is 40.41759685800404
At time: 1061.1965999603271 and batch: 1900, loss is 3.802530517578125 and perplexity is 44.81444486967205
At time: 1062.4769237041473 and batch: 1950, loss is 3.755956950187683 and perplexity is 42.77513390347278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330228583757267 and perplexity of 75.96164818377025
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
2195.630336999893


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.0889270305633545 and batch: 50, loss is 7.95266996383667 and perplexity is 2843.155949040895
At time: 3.586881160736084 and batch: 100, loss is 7.275675382614136 and perplexity is 1444.7266059540302
At time: 5.081372022628784 and batch: 150, loss is 7.047205381393432 and perplexity is 1149.641439951139
At time: 6.5793445110321045 and batch: 200, loss is 6.953158140182495 and perplexity is 1046.4493488430362
At time: 8.07567834854126 and batch: 250, loss is 6.847200155258179 and perplexity is 941.2418828306116
At time: 9.568753480911255 and batch: 300, loss is 6.730471668243408 and perplexity is 837.5422148696578
At time: 11.066025257110596 and batch: 350, loss is 6.678922252655029 and perplexity is 795.4613435190687
At time: 12.563821077346802 and batch: 400, loss is 6.650518484115601 and perplexity is 773.1851058228532
At time: 14.058685541152954 and batch: 450, loss is 6.556955986022949 and perplexity is 704.1250625319857
At time: 15.557862043380737 and batch: 500, loss is 6.546709871292114 and perplexity is 696.9473509790828
At time: 17.05439329147339 and batch: 550, loss is 6.509957504272461 and perplexity is 671.7978684453113
At time: 18.54752516746521 and batch: 600, loss is 6.555747604370117 and perplexity is 703.2747245949747
At time: 20.04391050338745 and batch: 650, loss is 6.635023050308227 and perplexity is 761.2966137421317
At time: 21.54164171218872 and batch: 700, loss is 6.509406623840332 and perplexity is 671.4278900615209
At time: 23.0443913936615 and batch: 750, loss is 6.445103912353516 and perplexity is 629.6120980378361
At time: 24.544874668121338 and batch: 800, loss is 6.441716499328614 and perplexity is 627.4829500041178
At time: 26.0449001789093 and batch: 850, loss is 6.493393230438232 and perplexity is 660.7616801504801
At time: 27.548408031463623 and batch: 900, loss is 6.474466981887818 and perplexity is 648.3735406497307
At time: 29.036158561706543 and batch: 950, loss is 6.48365948677063 and perplexity is 654.361196200397
At time: 30.524977207183838 and batch: 1000, loss is 6.475406217575073 and perplexity is 648.9828022931312
At time: 32.0223925113678 and batch: 1050, loss is 6.372860555648804 and perplexity is 585.7309507010812
At time: 33.5240843296051 and batch: 1100, loss is 6.4439287185668945 and perplexity is 628.8726164144518
At time: 35.02365231513977 and batch: 1150, loss is 6.347188453674317 and perplexity is 570.8853798401794
At time: 36.52002811431885 and batch: 1200, loss is 6.446368541717529 and perplexity is 630.4088276626087
At time: 38.01736855506897 and batch: 1250, loss is 6.369995250701904 and perplexity is 584.055055033147
At time: 39.517200231552124 and batch: 1300, loss is 6.382650413513184 and perplexity is 591.4933338886033
At time: 41.015583753585815 and batch: 1350, loss is 6.38411584854126 and perplexity is 592.3607643652258
At time: 42.51614308357239 and batch: 1400, loss is 6.407774982452392 and perplexity is 606.5426105891823
At time: 44.01213312149048 and batch: 1450, loss is 6.409008340835571 and perplexity is 607.2911565205187
At time: 45.50831985473633 and batch: 1500, loss is 6.389017744064331 and perplexity is 595.2715833808932
At time: 47.0102961063385 and batch: 1550, loss is 6.357680406570434 and perplexity is 576.9066143738669
At time: 48.509801626205444 and batch: 1600, loss is 6.342860260009766 and perplexity is 568.419816921873
At time: 50.008378982543945 and batch: 1650, loss is 6.34050555229187 and perplexity is 567.0829289998308
At time: 51.50499415397644 and batch: 1700, loss is 6.364903478622437 and perplexity is 581.0887381246246
At time: 53.002331495285034 and batch: 1750, loss is 6.382253713607788 and perplexity is 591.258735074748
At time: 54.4990291595459 and batch: 1800, loss is 6.388159599304199 and perplexity is 594.7609733107724
At time: 55.99999737739563 and batch: 1850, loss is 6.326234464645386 and perplexity is 559.0475122621106
At time: 57.497838258743286 and batch: 1900, loss is 6.278175268173218 and perplexity is 532.8155307853341
At time: 58.99676465988159 and batch: 1950, loss is 6.224705152511596 and perplexity is 505.0741006703116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.945747978742733 and perplexity of 382.12507586394656
finished 1 epochs...
Completing Train Step...
At time: 63.23065376281738 and batch: 50, loss is 6.036386461257934 and perplexity is 418.37847324921785
At time: 64.50907921791077 and batch: 100, loss is 5.884340400695801 and perplexity is 359.365652470261
At time: 65.78716993331909 and batch: 150, loss is 5.721199817657471 and perplexity is 305.27097281995407
At time: 67.06677436828613 and batch: 200, loss is 5.641615133285523 and perplexity is 281.9176855978907
At time: 68.34475302696228 and batch: 250, loss is 5.604612665176392 and perplexity is 271.67667521501454
At time: 69.62223267555237 and batch: 300, loss is 5.575853290557862 and perplexity is 263.9747066883762
At time: 70.91612768173218 and batch: 350, loss is 5.518619022369385 and perplexity is 249.29053471737103
At time: 72.19560956954956 and batch: 400, loss is 5.455525226593018 and perplexity is 234.0477669037791
At time: 73.47271680831909 and batch: 450, loss is 5.363716020584106 and perplexity is 213.5169072893613
At time: 74.7547767162323 and batch: 500, loss is 5.34438006401062 and perplexity is 209.42801238473862
At time: 76.0346839427948 and batch: 550, loss is 5.288733158111572 and perplexity is 198.09231474211805
At time: 77.31045579910278 and batch: 600, loss is 5.279364614486695 and perplexity is 196.2451444080639
At time: 78.58621048927307 and batch: 650, loss is 5.339421300888062 and perplexity is 208.39207907677843
At time: 79.8668851852417 and batch: 700, loss is 5.288384323120117 and perplexity is 198.02322526231225
At time: 81.14697504043579 and batch: 750, loss is 5.204916467666626 and perplexity is 182.16565541096188
At time: 82.42512440681458 and batch: 800, loss is 5.205675802230835 and perplexity is 182.30403262017717
At time: 83.7036714553833 and batch: 850, loss is 5.198090829849243 and perplexity is 180.92649247403986
At time: 84.98462581634521 and batch: 900, loss is 5.200759506225586 and perplexity is 181.40997156804002
At time: 86.26145100593567 and batch: 950, loss is 5.220555658340454 and perplexity is 185.03697284757328
At time: 87.53925466537476 and batch: 1000, loss is 5.1769525337219235 and perplexity is 177.14215285581597
At time: 88.81767082214355 and batch: 1050, loss is 5.08482738494873 and perplexity is 161.55205051518018
At time: 90.09681344032288 and batch: 1100, loss is 5.1614524841308596 and perplexity is 174.41761052027852
At time: 91.38094329833984 and batch: 1150, loss is 5.058259344100952 and perplexity is 157.31644406344319
At time: 92.66306376457214 and batch: 1200, loss is 5.137202768325806 and perplexity is 170.23890402777872
At time: 93.94215154647827 and batch: 1250, loss is 5.087173881530762 and perplexity is 161.93157695413936
At time: 95.2238974571228 and batch: 1300, loss is 5.1001130390167235 and perplexity is 164.04044922298468
At time: 96.5051941871643 and batch: 1350, loss is 5.032983703613281 and perplexity is 153.3900008978321
At time: 97.78443121910095 and batch: 1400, loss is 5.025651168823242 and perplexity is 152.2693769079583
At time: 99.06380105018616 and batch: 1450, loss is 4.980666532516479 and perplexity is 145.571377381109
At time: 100.3437750339508 and batch: 1500, loss is 4.937419042587281 and perplexity is 139.4099736267371
At time: 101.62242722511292 and batch: 1550, loss is 4.93402850151062 and perplexity is 138.93809879221118
At time: 102.90489315986633 and batch: 1600, loss is 4.975750322341919 and perplexity is 144.85747418145738
At time: 104.18445038795471 and batch: 1650, loss is 4.950851612091064 and perplexity is 141.29524143533126
At time: 105.46371364593506 and batch: 1700, loss is 4.966632308959961 and perplexity is 143.54266512589797
At time: 106.7454206943512 and batch: 1750, loss is 4.9657221698760985 and perplexity is 143.41208077014218
At time: 108.02611994743347 and batch: 1800, loss is 4.924072418212891 and perplexity is 137.56168273346452
At time: 109.30450701713562 and batch: 1850, loss is 4.9181038188934325 and perplexity is 136.74307756083275
At time: 110.58547306060791 and batch: 1900, loss is 4.995854721069336 and perplexity is 147.79921851772974
At time: 111.86672496795654 and batch: 1950, loss is 4.9177962493896485 and perplexity is 136.7010260275376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.704839662063954 and perplexity of 110.48056930080986
finished 2 epochs...
Completing Train Step...
At time: 116.00221371650696 and batch: 50, loss is 4.913827247619629 and perplexity is 136.159534714103
At time: 117.29866981506348 and batch: 100, loss is 4.842908020019531 and perplexity is 126.83766240465657
At time: 118.58180522918701 and batch: 150, loss is 4.785606184005737 and perplexity is 119.77394613274433
At time: 119.86053085327148 and batch: 200, loss is 4.7596260452270505 and perplexity is 116.70227636476207
At time: 121.14011120796204 and batch: 250, loss is 4.773459091186523 and perplexity is 118.32784165564168
At time: 122.42583870887756 and batch: 300, loss is 4.797700252532959 and perplexity is 121.23129532212872
At time: 123.70703887939453 and batch: 350, loss is 4.797006711959839 and perplexity is 121.14724564938905
At time: 124.98828339576721 and batch: 400, loss is 4.740691270828247 and perplexity is 114.51333405333332
At time: 126.26967787742615 and batch: 450, loss is 4.729628620147705 and perplexity is 113.25349447151362
At time: 127.55164885520935 and batch: 500, loss is 4.731639823913574 and perplexity is 113.48149953155473
At time: 128.83200478553772 and batch: 550, loss is 4.69408091545105 and perplexity is 109.29830807844854
At time: 130.11151456832886 and batch: 600, loss is 4.6698016262054445 and perplexity is 106.67657849566862
At time: 131.39178133010864 and batch: 650, loss is 4.732734413146972 and perplexity is 113.60578316648724
At time: 132.67238450050354 and batch: 700, loss is 4.752873916625976 and perplexity is 115.91694191002112
At time: 133.94962906837463 and batch: 750, loss is 4.694375324249267 and perplexity is 109.33049119924164
At time: 135.2496349811554 and batch: 800, loss is 4.703086767196655 and perplexity is 110.28707811234591
At time: 136.52963542938232 and batch: 850, loss is 4.692656888961792 and perplexity is 109.14277516029458
At time: 137.80822086334229 and batch: 900, loss is 4.6728675365448 and perplexity is 107.00414120300569
At time: 139.0857698917389 and batch: 950, loss is 4.722633981704712 and perplexity is 112.46409123883706
At time: 140.36280584335327 and batch: 1000, loss is 4.697073001861572 and perplexity is 109.62582780005168
At time: 141.64131832122803 and batch: 1050, loss is 4.628373041152954 and perplexity is 102.34741355050397
At time: 142.92328214645386 and batch: 1100, loss is 4.678935575485229 and perplexity is 107.65542049426273
At time: 144.20309233665466 and batch: 1150, loss is 4.62168888092041 and perplexity is 101.66558829213186
At time: 145.4817225933075 and batch: 1200, loss is 4.69868634223938 and perplexity is 109.80283432198297
At time: 146.76223492622375 and batch: 1250, loss is 4.674214839935303 and perplexity is 107.14840540724943
At time: 148.04087042808533 and batch: 1300, loss is 4.677785634994507 and perplexity is 107.53169431969381
At time: 149.32052946090698 and batch: 1350, loss is 4.5763893318176265 and perplexity is 97.16293696613252
At time: 150.6023862361908 and batch: 1400, loss is 4.568603277206421 and perplexity is 96.40935854110398
At time: 151.88273549079895 and batch: 1450, loss is 4.528301858901978 and perplexity is 92.60117762482363
At time: 153.16689491271973 and batch: 1500, loss is 4.512451400756836 and perplexity is 91.14497773983722
At time: 154.44805240631104 and batch: 1550, loss is 4.521302032470703 and perplexity is 91.95524878640595
At time: 155.7347707748413 and batch: 1600, loss is 4.587486219406128 and perplexity is 98.2471477119295
At time: 157.01260614395142 and batch: 1650, loss is 4.5530428791046145 and perplexity is 94.92080184360374
At time: 158.2961995601654 and batch: 1700, loss is 4.569534330368042 and perplexity is 96.49916257886291
At time: 159.5752992630005 and batch: 1750, loss is 4.559125747680664 and perplexity is 95.49995226853696
At time: 160.8554723262787 and batch: 1800, loss is 4.520883235931397 and perplexity is 91.91674630935798
At time: 162.13510394096375 and batch: 1850, loss is 4.5432798957824705 and perplexity is 93.99860068058736
At time: 163.41474437713623 and batch: 1900, loss is 4.648303165435791 and perplexity is 104.40767263659667
At time: 164.69418478012085 and batch: 1950, loss is 4.567161998748779 and perplexity is 96.27050589622293
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506944665243459 and perplexity of 90.64444586721964
finished 3 epochs...
Completing Train Step...
At time: 168.8270766735077 and batch: 50, loss is 4.570478019714355 and perplexity is 96.5902707926807
At time: 170.1396028995514 and batch: 100, loss is 4.489574308395386 and perplexity is 89.08351570120887
At time: 171.41845202445984 and batch: 150, loss is 4.445291948318482 and perplexity is 85.22475542970095
At time: 172.69652485847473 and batch: 200, loss is 4.442780351638794 and perplexity is 85.01097379593722
At time: 173.97548055648804 and batch: 250, loss is 4.45507890701294 and perplexity is 86.06294154686012
At time: 175.2563397884369 and batch: 300, loss is 4.473578157424927 and perplexity is 87.6698590113614
At time: 176.53816485404968 and batch: 350, loss is 4.482645120620727 and perplexity is 88.4683729742883
At time: 177.81724762916565 and batch: 400, loss is 4.428017063140869 and perplexity is 83.76515111180875
At time: 179.09803295135498 and batch: 450, loss is 4.43853081703186 and perplexity is 84.65048322190161
At time: 180.3775680065155 and batch: 500, loss is 4.445231523513794 and perplexity is 85.21960589608089
At time: 181.65479731559753 and batch: 550, loss is 4.418885879516601 and perplexity is 83.003757637817
At time: 182.93737173080444 and batch: 600, loss is 4.3866720867156985 and perplexity is 80.37250071055138
At time: 184.21778345108032 and batch: 650, loss is 4.448039655685425 and perplexity is 85.45925013191726
At time: 185.49675846099854 and batch: 700, loss is 4.4782510757446286 and perplexity is 88.08049178109725
At time: 186.77837491035461 and batch: 750, loss is 4.433657255172729 and perplexity is 84.23893751681244
At time: 188.05735158920288 and batch: 800, loss is 4.432864942550659 and perplexity is 84.17222037725418
At time: 189.3374981880188 and batch: 850, loss is 4.425525074005127 and perplexity is 83.55666914057755
At time: 190.61853337287903 and batch: 900, loss is 4.395775413513183 and perplexity is 81.10749823558585
At time: 191.8989131450653 and batch: 950, loss is 4.462739429473877 and perplexity is 86.72476034603268
At time: 193.1798324584961 and batch: 1000, loss is 4.442070436477661 and perplexity is 84.95064463360409
At time: 194.4621183872223 and batch: 1050, loss is 4.381809949874878 and perplexity is 79.98266709403615
At time: 195.74071264266968 and batch: 1100, loss is 4.423004026412964 and perplexity is 83.34628410780005
At time: 197.02026271820068 and batch: 1150, loss is 4.380179853439331 and perplexity is 79.85239384133004
At time: 198.2987790107727 and batch: 1200, loss is 4.457609615325928 and perplexity is 86.28101757549352
At time: 199.60124850273132 and batch: 1250, loss is 4.445559110641479 and perplexity is 85.24752731509791
At time: 200.88203954696655 and batch: 1300, loss is 4.43557993888855 and perplexity is 84.40105815362544
At time: 202.162095785141 and batch: 1350, loss is 4.327041511535644 and perplexity is 75.71993830295436
At time: 203.44393658638 and batch: 1400, loss is 4.326731977462768 and perplexity is 75.69650402909373
At time: 204.7221119403839 and batch: 1450, loss is 4.283442778587341 and perplexity is 72.48957646206979
At time: 206.0002338886261 and batch: 1500, loss is 4.275355501174927 and perplexity is 71.90569732632082
At time: 207.28123235702515 and batch: 1550, loss is 4.292065124511719 and perplexity is 73.11730904090659
At time: 208.56111526489258 and batch: 1600, loss is 4.364935932159423 and perplexity is 78.64436120597219
At time: 209.83775281906128 and batch: 1650, loss is 4.329589033126831 and perplexity is 75.91308239558097
At time: 211.1198399066925 and batch: 1700, loss is 4.3417730712890625 and perplexity is 76.84366792112867
At time: 212.3968529701233 and batch: 1750, loss is 4.3302449703216555 and perplexity is 75.96289294440788
At time: 213.67547059059143 and batch: 1800, loss is 4.291071538925171 and perplexity is 73.04469681572016
At time: 214.95869326591492 and batch: 1850, loss is 4.323573188781738 and perplexity is 75.45777201946258
At time: 216.2405080795288 and batch: 1900, loss is 4.429056701660156 and perplexity is 83.85228187387878
At time: 217.52123498916626 and batch: 1950, loss is 4.3506942653656 and perplexity is 77.53227221545173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436405057685319 and perplexity of 84.47072779208666
finished 4 epochs...
Completing Train Step...
At time: 221.64078426361084 and batch: 50, loss is 4.358977355957031 and perplexity is 78.17714613748956
At time: 222.9427661895752 and batch: 100, loss is 4.279364433288574 and perplexity is 72.19454097593122
At time: 224.2227439880371 and batch: 150, loss is 4.239945096969604 and perplexity is 69.40404124196361
At time: 225.49948692321777 and batch: 200, loss is 4.243669772148133 and perplexity is 69.66303077819781
At time: 226.78028392791748 and batch: 250, loss is 4.244621806144714 and perplexity is 69.72938393202095
At time: 228.05946016311646 and batch: 300, loss is 4.265003247261047 and perplexity is 71.16515106484275
At time: 229.33958530426025 and batch: 350, loss is 4.279176406860351 and perplexity is 72.18096777035501
At time: 230.6373474597931 and batch: 400, loss is 4.226968040466309 and perplexity is 68.50919983880512
At time: 231.91682815551758 and batch: 450, loss is 4.244391465187073 and perplexity is 69.71332424862277
At time: 233.19833135604858 and batch: 500, loss is 4.256965503692627 and perplexity is 70.59543650655176
At time: 234.47665977478027 and batch: 550, loss is 4.228884210586548 and perplexity is 68.64060097375646
At time: 235.75835943222046 and batch: 600, loss is 4.204561648368835 and perplexity is 66.99122551613132
At time: 237.0423562526703 and batch: 650, loss is 4.262468357086181 and perplexity is 70.98498367136804
At time: 238.32475662231445 and batch: 700, loss is 4.297923555374146 and perplexity is 73.54691893196473
At time: 239.60560131072998 and batch: 750, loss is 4.254787635803223 and perplexity is 70.4418562716806
At time: 240.88374376296997 and batch: 800, loss is 4.251022877693177 and perplexity is 70.17715829655856
At time: 242.16328716278076 and batch: 850, loss is 4.24456524848938 and perplexity is 69.72544031307983
At time: 243.44360780715942 and batch: 900, loss is 4.214606142044067 and perplexity is 67.66750923494203
At time: 244.7221167087555 and batch: 950, loss is 4.2866918659210205 and perplexity is 72.72548446209233
At time: 246.00055170059204 and batch: 1000, loss is 4.264396305084229 and perplexity is 71.121971038357
At time: 247.27829360961914 and batch: 1050, loss is 4.212464094161987 and perplexity is 67.52271732106917
At time: 248.54877829551697 and batch: 1100, loss is 4.245191869735717 and perplexity is 69.76914544724299
At time: 249.8212366104126 and batch: 1150, loss is 4.208909707069397 and perplexity is 67.28314147104778
At time: 251.10226702690125 and batch: 1200, loss is 4.286602735519409 and perplexity is 72.71900269932019
At time: 252.38917326927185 and batch: 1250, loss is 4.281022081375122 and perplexity is 72.31431336144615
At time: 253.66921305656433 and batch: 1300, loss is 4.26848879814148 and perplexity is 71.41363361751385
At time: 254.95060181617737 and batch: 1350, loss is 4.1560452270507815 and perplexity is 63.818634662332585
At time: 256.23289489746094 and batch: 1400, loss is 4.168985633850098 and perplexity is 64.6498402262712
At time: 257.5100681781769 and batch: 1450, loss is 4.116911993026734 and perplexity is 61.36944010107502
At time: 258.789395570755 and batch: 1500, loss is 4.106247944831848 and perplexity is 60.718470588386126
At time: 260.07064509391785 and batch: 1550, loss is 4.128284177780151 and perplexity is 62.071328148008774
At time: 261.35043954849243 and batch: 1600, loss is 4.2088642406463626 and perplexity is 67.28008241681724
At time: 262.6302502155304 and batch: 1650, loss is 4.166056070327759 and perplexity is 64.46072156544109
At time: 263.9079399108887 and batch: 1700, loss is 4.179290709495544 and perplexity is 65.31950627367497
At time: 265.18646359443665 and batch: 1750, loss is 4.168084707260132 and perplexity is 64.59162169542336
At time: 266.4656128883362 and batch: 1800, loss is 4.130311875343323 and perplexity is 62.19731772004364
At time: 267.7470805644989 and batch: 1850, loss is 4.164996910095215 and perplexity is 64.39248347651217
At time: 269.0283582210541 and batch: 1900, loss is 4.269926633834839 and perplexity is 71.51638854356905
At time: 270.3077895641327 and batch: 1950, loss is 4.193041052818298 and perplexity is 66.223875354094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419101448946221 and perplexity of 83.0216526392456
finished 5 epochs...
Completing Train Step...
At time: 274.44980692863464 and batch: 50, loss is 4.2016121196746825 and perplexity is 66.79392409036231
At time: 275.73021364212036 and batch: 100, loss is 4.129632983207703 and perplexity is 62.15510678014564
At time: 277.01171946525574 and batch: 150, loss is 4.09117271900177 and perplexity is 59.80999090560937
At time: 278.29236245155334 and batch: 200, loss is 4.096498856544494 and perplexity is 60.129396988898776
At time: 279.5741174221039 and batch: 250, loss is 4.091678743362427 and perplexity is 59.84026387680271
At time: 280.8529386520386 and batch: 300, loss is 4.109981679916382 and perplexity is 60.94560103088768
At time: 282.13048219680786 and batch: 350, loss is 4.130345735549927 and perplexity is 62.19942376972729
At time: 283.41072392463684 and batch: 400, loss is 4.077119283676147 and perplexity is 58.97533370404665
At time: 284.69265270233154 and batch: 450, loss is 4.103528270721435 and perplexity is 60.55356048841595
At time: 285.97299003601074 and batch: 500, loss is 4.116394424438477 and perplexity is 61.33768542492011
At time: 287.252965927124 and batch: 550, loss is 4.09090877532959 and perplexity is 59.79420652016261
At time: 288.53263783454895 and batch: 600, loss is 4.069505715370179 and perplexity is 58.52802593737509
At time: 289.81190037727356 and batch: 650, loss is 4.1207484531402585 and perplexity is 61.60533371910862
At time: 291.0922350883484 and batch: 700, loss is 4.159028162956238 and perplexity is 64.00928576775166
At time: 292.3724145889282 and batch: 750, loss is 4.116574792861939 and perplexity is 61.348749804341345
At time: 293.65145897865295 and batch: 800, loss is 4.111852011680603 and perplexity is 61.0596961890244
At time: 294.95137119293213 and batch: 850, loss is 4.109239492416382 and perplexity is 60.90038474917768
At time: 296.23211789131165 and batch: 900, loss is 4.078747148513794 and perplexity is 59.07141575915381
At time: 297.5110709667206 and batch: 950, loss is 4.152741460800171 and perplexity is 63.60814071383614
At time: 298.7919714450836 and batch: 1000, loss is 4.12900173664093 and perplexity is 62.115883963319945
At time: 300.07168531417847 and batch: 1050, loss is 4.08263358592987 and perplexity is 59.301439817102356
At time: 301.3511550426483 and batch: 1100, loss is 4.109926509857178 and perplexity is 60.942238751219975
At time: 302.6327712535858 and batch: 1150, loss is 4.080487990379334 and perplexity is 59.17433931358756
At time: 303.9129288196564 and batch: 1200, loss is 4.156536564826966 and perplexity is 63.84999887294646
At time: 305.194402217865 and batch: 1250, loss is 4.152658224105835 and perplexity is 63.60284640281378
At time: 306.4777934551239 and batch: 1300, loss is 4.1373539686203005 and perplexity is 62.63686287553989
At time: 307.75848484039307 and batch: 1350, loss is 4.024483256340027 and perplexity is 55.95138878475391
At time: 309.0406725406647 and batch: 1400, loss is 4.045918679237365 and perplexity is 57.16367700246543
At time: 310.3214740753174 and batch: 1450, loss is 3.9883924674987794 and perplexity is 53.9680641776766
At time: 311.60227251052856 and batch: 1500, loss is 3.9795859336853026 and perplexity is 53.49487921349409
At time: 312.8855867385864 and batch: 1550, loss is 4.004531607627869 and perplexity is 54.846128873340554
At time: 314.1646728515625 and batch: 1600, loss is 4.085657076835632 and perplexity is 59.481008506443686
At time: 315.44436144828796 and batch: 1650, loss is 4.0422058057785035 and perplexity is 56.95182902903883
At time: 316.7236623764038 and batch: 1700, loss is 4.053560056686401 and perplexity is 57.60215940598713
At time: 318.0044996738434 and batch: 1750, loss is 4.0437168645858765 and perplexity is 57.037951643669864
At time: 319.2847044467926 and batch: 1800, loss is 4.003922967910767 and perplexity is 54.812757497581465
At time: 320.565110206604 and batch: 1850, loss is 4.038264904022217 and perplexity is 56.72782913668546
At time: 321.84627747535706 and batch: 1900, loss is 4.1437390470504765 and perplexity is 63.038083707740114
At time: 323.1268537044525 and batch: 1950, loss is 4.068950839042664 and perplexity is 58.49555912965081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413619640261628 and perplexity of 82.56778895629625
finished 6 epochs...
Completing Train Step...
At time: 327.29138588905334 and batch: 50, loss is 4.076789236068725 and perplexity is 58.955872248040876
At time: 328.5763337612152 and batch: 100, loss is 4.011489534378052 and perplexity is 55.22907493092678
At time: 329.857784986496 and batch: 150, loss is 3.9718354988098143 and perplexity is 53.08187319152712
At time: 331.137318611145 and batch: 200, loss is 3.980488600730896 and perplexity is 53.54318907864946
At time: 332.4153745174408 and batch: 250, loss is 3.975219955444336 and perplexity is 53.26183084708593
At time: 333.69499111175537 and batch: 300, loss is 3.991472682952881 and perplexity is 54.13455372318621
At time: 334.9751477241516 and batch: 350, loss is 4.011040377616882 and perplexity is 55.20427398868078
At time: 336.2553126811981 and batch: 400, loss is 3.958590884208679 and perplexity is 52.38345955810518
At time: 337.53733253479004 and batch: 450, loss is 3.990953779220581 and perplexity is 54.106470388116705
At time: 338.8171720504761 and batch: 500, loss is 3.9998975372314454 and perplexity is 54.59255604212668
At time: 340.0981991291046 and batch: 550, loss is 3.9765924644470214 and perplexity is 53.334983379193886
At time: 341.37655115127563 and batch: 600, loss is 3.957923150062561 and perplexity is 52.34849300894507
At time: 342.6566352844238 and batch: 650, loss is 4.008671879768372 and perplexity is 55.07367750430762
At time: 343.93610167503357 and batch: 700, loss is 4.049426317214966 and perplexity is 57.36453855572274
At time: 345.2172095775604 and batch: 750, loss is 4.008241539001465 and perplexity is 55.049982154597195
At time: 346.50064611434937 and batch: 800, loss is 4.002795300483704 and perplexity is 54.75098177414582
At time: 347.78134512901306 and batch: 850, loss is 3.9984452295303345 and perplexity is 54.51332839794783
At time: 349.0618941783905 and batch: 900, loss is 3.967939977645874 and perplexity is 52.8754938695814
At time: 350.3416361808777 and batch: 950, loss is 4.049198875427246 and perplexity is 57.35149294613652
At time: 351.62457728385925 and batch: 1000, loss is 4.0213997936248775 and perplexity is 55.77913047609366
At time: 352.9050381183624 and batch: 1050, loss is 3.976471643447876 and perplexity is 53.32853978248134
At time: 354.1856722831726 and batch: 1100, loss is 4.001219158172607 and perplexity is 54.66475440634959
At time: 355.4701225757599 and batch: 1150, loss is 3.976046953201294 and perplexity is 53.305896480306394
At time: 356.7472834587097 and batch: 1200, loss is 4.049421696662903 and perplexity is 57.36427350049814
At time: 358.0250794887543 and batch: 1250, loss is 4.0466845512390135 and perplexity is 57.20747383143461
At time: 359.3096113204956 and batch: 1300, loss is 4.0320066690444945 and perplexity is 56.37392162543466
At time: 360.5889239311218 and batch: 1350, loss is 3.918829097747803 and perplexity is 50.341465320091665
At time: 361.87103486061096 and batch: 1400, loss is 3.9462435483932494 and perplexity is 51.74064011237346
At time: 363.15105628967285 and batch: 1450, loss is 3.8833217573165895 and perplexity is 48.58533601624566
At time: 364.4332642555237 and batch: 1500, loss is 3.8758310508728027 and perplexity is 48.22275720776091
At time: 365.7105884552002 and batch: 1550, loss is 3.90495512008667 and perplexity is 49.647851670895875
At time: 366.99287486076355 and batch: 1600, loss is 3.9860015439987184 and perplexity is 53.83918479654698
At time: 368.2713348865509 and batch: 1650, loss is 3.941930718421936 and perplexity is 51.51797203887712
At time: 369.55279326438904 and batch: 1700, loss is 3.9536998224258424 and perplexity is 52.12787437199498
At time: 370.835084438324 and batch: 1750, loss is 3.9432988119125367 and perplexity is 51.588501675640195
At time: 372.12659335136414 and batch: 1800, loss is 3.900737648010254 and perplexity is 49.43890416766355
At time: 373.4052879810333 and batch: 1850, loss is 3.9384765338897707 and perplexity is 51.34032644369533
At time: 374.689834356308 and batch: 1900, loss is 4.043411016464233 and perplexity is 57.02050936077797
At time: 375.9726793766022 and batch: 1950, loss is 3.97074499130249 and perplexity is 53.02401856149655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.422888751362645 and perplexity of 83.33667691445113
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 380.1266677379608 and batch: 50, loss is 4.012473759651184 and perplexity is 55.28345954124925
At time: 381.4058532714844 and batch: 100, loss is 3.989822659492493 and perplexity is 54.045304091767235
At time: 382.6885166168213 and batch: 150, loss is 3.954129276275635 and perplexity is 52.15026569600154
At time: 383.97074818611145 and batch: 200, loss is 3.957700562477112 and perplexity is 52.336842180997245
At time: 385.25080943107605 and batch: 250, loss is 3.954643201828003 and perplexity is 52.177073938235814
At time: 386.53042125701904 and batch: 300, loss is 3.9610340213775634 and perplexity is 52.511595998900596
At time: 387.8110680580139 and batch: 350, loss is 3.965514688491821 and perplexity is 52.747410889697576
At time: 389.090696811676 and batch: 400, loss is 3.9183258295059202 and perplexity is 50.31613643349294
At time: 390.3888580799103 and batch: 450, loss is 3.934334855079651 and perplexity is 51.12813102751273
At time: 391.6692113876343 and batch: 500, loss is 3.947155165672302 and perplexity is 51.78782927989136
At time: 392.9515507221222 and batch: 550, loss is 3.923915777206421 and perplexity is 50.59818859862131
At time: 394.23136377334595 and batch: 600, loss is 3.9005452728271486 and perplexity is 49.42939426418581
At time: 395.5111496448517 and batch: 650, loss is 3.941305537223816 and perplexity is 51.485774037234485
At time: 396.7911491394043 and batch: 700, loss is 3.974096155166626 and perplexity is 53.20200880709711
At time: 398.07052302360535 and batch: 750, loss is 3.9213866138458253 and perplexity is 50.47037920744932
At time: 399.35501646995544 and batch: 800, loss is 3.910949263572693 and perplexity is 49.94634171995325
At time: 400.6345491409302 and batch: 850, loss is 3.9087517738342283 and perplexity is 49.83670565273517
At time: 401.91327714920044 and batch: 900, loss is 3.872292137145996 and perplexity is 48.052402643179484
At time: 403.1938545703888 and batch: 950, loss is 3.9671000337600706 and perplexity is 52.83110006855769
At time: 404.47471833229065 and batch: 1000, loss is 3.922197518348694 and perplexity is 50.5113224635019
At time: 405.7590539455414 and batch: 1050, loss is 3.861342844963074 and perplexity is 47.529132791556435
At time: 407.04139041900635 and batch: 1100, loss is 3.873284840583801 and perplexity is 48.10012811317793
At time: 408.32255959510803 and batch: 1150, loss is 3.8549607515335085 and perplexity is 47.22676332686127
At time: 409.6032819747925 and batch: 1200, loss is 3.9068873500823975 and perplexity is 49.74387547928373
At time: 410.88318037986755 and batch: 1250, loss is 3.89766619682312 and perplexity is 49.28728794687109
At time: 412.1658022403717 and batch: 1300, loss is 3.8865897417068482 and perplexity is 48.74437185772777
At time: 413.4453990459442 and batch: 1350, loss is 3.7695716857910155 and perplexity is 43.361488516230565
At time: 414.72843861579895 and batch: 1400, loss is 3.7867798137664797 and perplexity is 44.11411563953612
At time: 416.012797832489 and batch: 1450, loss is 3.7122621059417726 and perplexity is 40.9463267713231
At time: 417.2927324771881 and batch: 1500, loss is 3.7022130918502807 and perplexity is 40.53691708373144
At time: 418.5737223625183 and batch: 1550, loss is 3.7272565937042237 and perplexity is 41.564922137238455
At time: 419.8566086292267 and batch: 1600, loss is 3.796808500289917 and perplexity is 44.558748089721284
At time: 421.13809728622437 and batch: 1650, loss is 3.7491672086715697 and perplexity is 42.485685552670624
At time: 422.42073488235474 and batch: 1700, loss is 3.75214910030365 and perplexity is 42.612562335299266
At time: 423.7004084587097 and batch: 1750, loss is 3.730629858970642 and perplexity is 41.70536839344714
At time: 424.9853837490082 and batch: 1800, loss is 3.6758274984359742 and perplexity is 39.48131406908351
At time: 426.2635848522186 and batch: 1850, loss is 3.70115517616272 and perplexity is 40.49405511939299
At time: 427.543564081192 and batch: 1900, loss is 3.795789556503296 and perplexity is 44.51336835384189
At time: 428.82217383384705 and batch: 1950, loss is 3.7150258874893187 and perplexity is 41.0596500018854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374237202489099 and perplexity of 79.37926614594339
finished 8 epochs...
Completing Train Step...
At time: 432.9512815475464 and batch: 50, loss is 3.9261635637283323 and perplexity is 50.71205044560793
At time: 434.24824118614197 and batch: 100, loss is 3.8924159002304077 and perplexity is 49.02919319677121
At time: 435.527170419693 and batch: 150, loss is 3.854046130180359 and perplexity is 47.18358846801604
At time: 436.8092272281647 and batch: 200, loss is 3.8523712301254274 and perplexity is 47.10462681799427
At time: 438.09072041511536 and batch: 250, loss is 3.8479830694198607 and perplexity is 46.898377005164576
At time: 439.36990451812744 and batch: 300, loss is 3.852059426307678 and perplexity is 47.089941705074885
At time: 440.6480886936188 and batch: 350, loss is 3.860133547782898 and perplexity is 47.47169068458467
At time: 441.9268546104431 and batch: 400, loss is 3.8146014738082887 and perplexity is 45.358676159994246
At time: 443.2090299129486 and batch: 450, loss is 3.8366245317459104 and perplexity is 46.36869393048752
At time: 444.50839257240295 and batch: 500, loss is 3.8505283641815184 and perplexity is 47.01789924362248
At time: 445.7999618053436 and batch: 550, loss is 3.829920926094055 and perplexity is 46.058896033401986
At time: 447.0812785625458 and batch: 600, loss is 3.80830454826355 and perplexity is 45.07395333342794
At time: 448.36697602272034 and batch: 650, loss is 3.850383038520813 and perplexity is 47.011066832824255
At time: 449.66134428977966 and batch: 700, loss is 3.8865443420410157 and perplexity is 48.74215892976769
At time: 450.9513282775879 and batch: 750, loss is 3.8352810382843017 and perplexity is 46.30643972179368
At time: 452.23092579841614 and batch: 800, loss is 3.825907802581787 and perplexity is 45.87442639208469
At time: 453.51014971733093 and batch: 850, loss is 3.824692378044128 and perplexity is 45.81870335902734
At time: 454.81048941612244 and batch: 900, loss is 3.7904270696640014 and perplexity is 44.275304878482935
At time: 456.0986728668213 and batch: 950, loss is 3.8865493631362913 and perplexity is 48.742403669406045
At time: 457.38061141967773 and batch: 1000, loss is 3.8452248430252074 and perplexity is 46.769198896973236
At time: 458.6607735157013 and batch: 1050, loss is 3.7919504404067994 and perplexity is 44.34280398258993
At time: 459.9401640892029 and batch: 1100, loss is 3.801821303367615 and perplexity is 44.782673096362636
At time: 461.2196946144104 and batch: 1150, loss is 3.787669472694397 and perplexity is 44.15337961954743
At time: 462.501704454422 and batch: 1200, loss is 3.8407821321487425 and perplexity is 46.561877743325326
At time: 463.78036069869995 and batch: 1250, loss is 3.836805214881897 and perplexity is 46.37707272844944
At time: 465.06054496765137 and batch: 1300, loss is 3.825784215927124 and perplexity is 45.86875727551309
At time: 466.34083366394043 and batch: 1350, loss is 3.711124963760376 and perplexity is 40.899791439637006
At time: 467.62183952331543 and batch: 1400, loss is 3.731409120559692 and perplexity is 41.737880451146964
At time: 468.9031491279602 and batch: 1450, loss is 3.658843517303467 and perplexity is 38.816426378317345
At time: 470.184867143631 and batch: 1500, loss is 3.6518895053863525 and perplexity is 38.54743286276361
At time: 471.4668080806732 and batch: 1550, loss is 3.67997275352478 and perplexity is 39.645313862794964
At time: 472.7476136684418 and batch: 1600, loss is 3.754391689300537 and perplexity is 42.708232032531534
At time: 474.03084325790405 and batch: 1650, loss is 3.7078842687606812 and perplexity is 40.76746222515311
At time: 475.31031823158264 and batch: 1700, loss is 3.715006642341614 and perplexity is 41.058859810460106
At time: 476.5908749103546 and batch: 1750, loss is 3.6988069725036623 and perplexity is 40.39907838698911
At time: 477.87335419654846 and batch: 1800, loss is 3.6452134323120116 and perplexity is 38.290944504294245
At time: 479.1541042327881 and batch: 1850, loss is 3.676121301651001 and perplexity is 39.492915510277385
At time: 480.43782925605774 and batch: 1900, loss is 3.7752321434020994 and perplexity is 43.607630364464924
At time: 481.7168319225311 and batch: 1950, loss is 3.697024173736572 and perplexity is 40.32711912335189
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38160769440407 and perplexity of 79.96649179787278
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 485.85338258743286 and batch: 50, loss is 3.896842985153198 and perplexity is 49.24673077211459
At time: 487.1501739025116 and batch: 100, loss is 3.9001835203170776 and perplexity is 49.411516290635326
At time: 488.4295816421509 and batch: 150, loss is 3.881843075752258 and perplexity is 48.51354686530918
At time: 489.71193838119507 and batch: 200, loss is 3.895702428817749 and perplexity is 49.19059412092441
At time: 490.9929897785187 and batch: 250, loss is 3.8962762641906736 and perplexity is 49.218829524308
At time: 492.2732484340668 and batch: 300, loss is 3.900548210144043 and perplexity is 49.42953945419391
At time: 493.55323123931885 and batch: 350, loss is 3.9016151905059813 and perplexity is 49.482307948558606
At time: 494.8361072540283 and batch: 400, loss is 3.8432027673721314 and perplexity is 46.67472358887077
At time: 496.1188254356384 and batch: 450, loss is 3.8661809492111208 and perplexity is 47.75964085220511
At time: 497.39677715301514 and batch: 500, loss is 3.865371837615967 and perplexity is 47.72101360199653
At time: 498.6754562854767 and batch: 550, loss is 3.8495891904830932 and perplexity is 46.973761998811646
At time: 499.9572923183441 and batch: 600, loss is 3.816570177078247 and perplexity is 45.448061892193
At time: 501.23720264434814 and batch: 650, loss is 3.8703920650482178 and perplexity is 47.961186299943286
At time: 502.5187020301819 and batch: 700, loss is 3.912020936012268 and perplexity is 49.99989652931317
At time: 503.80076122283936 and batch: 750, loss is 3.84850884437561 and perplexity is 46.92304148067276
At time: 505.0801603794098 and batch: 800, loss is 3.83730610370636 and perplexity is 46.40030830462483
At time: 506.3618848323822 and batch: 850, loss is 3.828857674598694 and perplexity is 46.00994986897219
At time: 507.64424991607666 and batch: 900, loss is 3.7890103960037234 and perplexity is 44.21262562876478
At time: 508.92556405067444 and batch: 950, loss is 3.899132924079895 and perplexity is 49.35963199704099
At time: 510.2065181732178 and batch: 1000, loss is 3.859545135498047 and perplexity is 47.443765975029976
At time: 511.4905619621277 and batch: 1050, loss is 3.7998727226257323 and perplexity is 44.69549540596559
At time: 512.7722084522247 and batch: 1100, loss is 3.801628999710083 and perplexity is 44.77406205252631
At time: 514.0582077503204 and batch: 1150, loss is 3.7853689622879028 and perplexity is 44.051921058234996
At time: 515.3383951187134 and batch: 1200, loss is 3.8249274778366087 and perplexity is 45.82947659302169
At time: 516.6207242012024 and batch: 1250, loss is 3.819434094429016 and perplexity is 45.57840794627605
At time: 517.89169049263 and batch: 1300, loss is 3.810068225860596 and perplexity is 45.15351939895145
At time: 519.1655979156494 and batch: 1350, loss is 3.6936816930770875 and perplexity is 40.19255152770667
At time: 520.4423358440399 and batch: 1400, loss is 3.705650362968445 and perplexity is 40.676493201098936
At time: 521.7249047756195 and batch: 1450, loss is 3.6215534257888793 and perplexity is 37.395614036372834
At time: 523.0060427188873 and batch: 1500, loss is 3.6149670934677123 and perplexity is 37.15012342379655
At time: 524.2876808643341 and batch: 1550, loss is 3.64582567691803 and perplexity is 38.31439510654619
At time: 525.5675349235535 and batch: 1600, loss is 3.7195609188079835 and perplexity is 41.24627966640421
At time: 526.8467364311218 and batch: 1650, loss is 3.6716658592224123 and perplexity is 39.31734850366055
At time: 528.1267147064209 and batch: 1700, loss is 3.6694551515579223 and perplexity is 39.2305253456469
At time: 529.4079489707947 and batch: 1750, loss is 3.65998113155365 and perplexity is 38.86060962508704
At time: 530.687166929245 and batch: 1800, loss is 3.6063121795654296 and perplexity is 36.82997971067001
At time: 531.9699075222015 and batch: 1850, loss is 3.623648476600647 and perplexity is 37.4740418743826
At time: 533.2538387775421 and batch: 1900, loss is 3.7275923442840577 and perplexity is 41.57887992698367
At time: 534.5341401100159 and batch: 1950, loss is 3.6460398960113527 and perplexity is 38.32260366071025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363161734647529 and perplexity of 78.5049542802749
finished 10 epochs...
Completing Train Step...
At time: 538.6693711280823 and batch: 50, loss is 3.8850119304656983 and perplexity is 48.667523082241615
At time: 539.9703500270844 and batch: 100, loss is 3.8645034408569336 and perplexity is 47.679590816756125
At time: 541.2525367736816 and batch: 150, loss is 3.8389582204818726 and perplexity is 46.47703039183652
At time: 542.5335876941681 and batch: 200, loss is 3.8472680950164797 and perplexity is 46.864857850142585
At time: 543.8165059089661 and batch: 250, loss is 3.847936749458313 and perplexity is 46.896204724455416
At time: 545.0981075763702 and batch: 300, loss is 3.8498983907699587 and perplexity is 46.988288545187245
At time: 546.3805928230286 and batch: 350, loss is 3.855145230293274 and perplexity is 47.23547646525732
At time: 547.6620543003082 and batch: 400, loss is 3.797191228866577 and perplexity is 44.57580525988043
At time: 548.9481246471405 and batch: 450, loss is 3.819276976585388 and perplexity is 45.57124732764875
At time: 550.2287743091583 and batch: 500, loss is 3.822157940864563 and perplexity is 45.702725764758796
At time: 551.5261905193329 and batch: 550, loss is 3.8062753868103028 and perplexity is 44.98258373796001
At time: 552.8077051639557 and batch: 600, loss is 3.774542179107666 and perplexity is 43.577553033883866
At time: 554.0890171527863 and batch: 650, loss is 3.8293757820129395 and perplexity is 46.03379414154219
At time: 555.3683521747589 and batch: 700, loss is 3.873287944793701 and perplexity is 48.100277426303556
At time: 556.6480994224548 and batch: 750, loss is 3.8115351724624635 and perplexity is 45.219805808220535
At time: 557.9285888671875 and batch: 800, loss is 3.8009254360198974 and perplexity is 44.74257172722774
At time: 559.2075035572052 and batch: 850, loss is 3.7922722768783568 and perplexity is 44.35707741089434
At time: 560.4872598648071 and batch: 900, loss is 3.7534135484695437 and perplexity is 42.66647779105427
At time: 561.7687757015228 and batch: 950, loss is 3.8637260675430296 and perplexity is 47.642540378114276
At time: 563.0491664409637 and batch: 1000, loss is 3.82769980430603 and perplexity is 45.956707144884604
At time: 564.330587387085 and batch: 1050, loss is 3.7708926820755004 and perplexity is 43.4188067316899
At time: 565.6124472618103 and batch: 1100, loss is 3.772592067718506 and perplexity is 43.49265475885251
At time: 566.8912909030914 and batch: 1150, loss is 3.7587004041671754 and perplexity is 42.89264663648575
At time: 568.1735551357269 and batch: 1200, loss is 3.7994493770599367 and perplexity is 44.67657777080545
At time: 569.4557459354401 and batch: 1250, loss is 3.7969590854644775 and perplexity is 44.56545848181067
At time: 570.7354919910431 and batch: 1300, loss is 3.789523916244507 and perplexity is 44.23533553742316
At time: 572.0168130397797 and batch: 1350, loss is 3.6743488121032715 and perplexity is 39.4229767315139
At time: 573.2991855144501 and batch: 1400, loss is 3.6881000709533693 and perplexity is 39.96883681918398
At time: 574.5805811882019 and batch: 1450, loss is 3.6071006536483763 and perplexity is 36.8590306465973
At time: 575.8588299751282 and batch: 1500, loss is 3.601854510307312 and perplexity is 36.66616922008458
At time: 577.1379075050354 and batch: 1550, loss is 3.635176410675049 and perplexity is 37.90853977839861
At time: 578.4188024997711 and batch: 1600, loss is 3.7114998149871825 and perplexity is 40.91512565047861
At time: 579.7013828754425 and batch: 1650, loss is 3.666160888671875 and perplexity is 39.10150231657027
At time: 580.9799716472626 and batch: 1700, loss is 3.6650145387649538 and perplexity is 39.05670399521081
At time: 582.2578408718109 and batch: 1750, loss is 3.656818652153015 and perplexity is 38.73790787080125
At time: 583.5406746864319 and batch: 1800, loss is 3.60537887096405 and perplexity is 36.79562200948042
At time: 584.8202056884766 and batch: 1850, loss is 3.6252351713180544 and perplexity is 37.53354893595012
At time: 586.1000771522522 and batch: 1900, loss is 3.7295501804351807 and perplexity is 41.660364301726936
At time: 587.3832511901855 and batch: 1950, loss is 3.648640360832214 and perplexity is 38.422389932485395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364410542332849 and perplexity of 78.60305311105375
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 591.5100004673004 and batch: 50, loss is 3.8796654510498048 and perplexity is 48.40801751061857
At time: 592.7966320514679 and batch: 100, loss is 3.8809764051437377 and perplexity is 48.47151981456136
At time: 594.0763545036316 and batch: 150, loss is 3.864529333114624 and perplexity is 47.680825364990675
At time: 595.356043100357 and batch: 200, loss is 3.8843250560760496 and perplexity is 48.63410608498242
At time: 596.6406481266022 and batch: 250, loss is 3.8956654500961303 and perplexity is 49.188775149269986
At time: 597.9200451374054 and batch: 300, loss is 3.90528865814209 and perplexity is 49.66441388070803
At time: 599.2036373615265 and batch: 350, loss is 3.925272459983826 and perplexity is 50.66688087593955
At time: 600.4823002815247 and batch: 400, loss is 3.867463912963867 and perplexity is 47.82095406316617
At time: 601.7619047164917 and batch: 450, loss is 3.8950622367858885 and perplexity is 49.15911277265508
At time: 603.0483620166779 and batch: 500, loss is 3.885550217628479 and perplexity is 48.69372723720851
At time: 604.3298268318176 and batch: 550, loss is 3.866846175193787 and perplexity is 47.79142237599848
At time: 605.6104907989502 and batch: 600, loss is 3.8062967348098753 and perplexity is 44.98354403638861
At time: 606.8907968997955 and batch: 650, loss is 3.8487835359573364 and perplexity is 46.935932615618555
At time: 608.170845746994 and batch: 700, loss is 3.8901536083221435 and perplexity is 48.918400220013716
At time: 609.4517691135406 and batch: 750, loss is 3.8301691722869875 and perplexity is 46.07033139832712
At time: 610.7354552745819 and batch: 800, loss is 3.8237126541137694 and perplexity is 45.77383566145588
At time: 612.0178418159485 and batch: 850, loss is 3.8190630006790163 and perplexity is 45.56149722187838
At time: 613.2961437702179 and batch: 900, loss is 3.7708030223846434 and perplexity is 43.41491398941459
At time: 614.6183602809906 and batch: 950, loss is 3.8841501808166505 and perplexity is 48.625601926670285
At time: 615.8996298313141 and batch: 1000, loss is 3.848082332611084 and perplexity is 46.90303251878604
At time: 617.1784515380859 and batch: 1050, loss is 3.793649845123291 and perplexity is 44.418224419592555
At time: 618.4600310325623 and batch: 1100, loss is 3.798142251968384 and perplexity is 44.6182180450368
At time: 619.7418079376221 and batch: 1150, loss is 3.78656879901886 and perplexity is 44.104807892628436
At time: 621.0230617523193 and batch: 1200, loss is 3.8233150005340577 and perplexity is 45.755637150439306
At time: 622.3046398162842 and batch: 1250, loss is 3.813283772468567 and perplexity is 45.29894633332912
At time: 623.5853362083435 and batch: 1300, loss is 3.801489486694336 and perplexity is 44.76781592382037
At time: 624.8637299537659 and batch: 1350, loss is 3.675841202735901 and perplexity is 39.48185513656048
At time: 626.1415445804596 and batch: 1400, loss is 3.689222903251648 and perplexity is 40.01374032492478
At time: 627.4236450195312 and batch: 1450, loss is 3.602537980079651 and perplexity is 36.69123800431625
At time: 628.7064621448517 and batch: 1500, loss is 3.5955484247207643 and perplexity is 36.43567673534672
At time: 629.9882235527039 and batch: 1550, loss is 3.626772174835205 and perplexity is 37.59128248964765
At time: 631.2708637714386 and batch: 1600, loss is 3.7025399255752562 and perplexity is 40.55016808065933
At time: 632.5517916679382 and batch: 1650, loss is 3.6581330251693727 and perplexity is 38.78885740763005
At time: 633.8354723453522 and batch: 1700, loss is 3.6515348768234253 and perplexity is 38.53376526564635
At time: 635.1160442829132 and batch: 1750, loss is 3.643632516860962 and perplexity is 38.23045758344388
At time: 636.3986241817474 and batch: 1800, loss is 3.5982710409164427 and perplexity is 36.53501226382467
At time: 637.6767084598541 and batch: 1850, loss is 3.6140653705596923 and perplexity is 37.1166394053916
At time: 638.9602172374725 and batch: 1900, loss is 3.729421977996826 and perplexity is 41.655023683788144
At time: 640.242290019989 and batch: 1950, loss is 3.662283363342285 and perplexity is 38.950178820854795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339032692132994 and perplexity of 76.63337540749468
finished 12 epochs...
Completing Train Step...
At time: 644.3606491088867 and batch: 50, loss is 3.8896968269348147 and perplexity is 48.89606030791176
At time: 645.6407506465912 and batch: 100, loss is 3.871737279891968 and perplexity is 48.025747814495794
At time: 646.9422194957733 and batch: 150, loss is 3.842996206283569 and perplexity is 46.66508340283585
At time: 648.2218451499939 and batch: 200, loss is 3.8521217918395996 and perplexity is 47.09287858591659
At time: 649.5029215812683 and batch: 250, loss is 3.8603183317184446 and perplexity is 47.480463500929226
At time: 650.7854368686676 and batch: 300, loss is 3.866203980445862 and perplexity is 47.76074082837158
At time: 652.0697340965271 and batch: 350, loss is 3.887408061027527 and perplexity is 48.78427664419532
At time: 653.3478784561157 and batch: 400, loss is 3.83289794921875 and perplexity is 46.19621873700298
At time: 654.6317534446716 and batch: 450, loss is 3.863662667274475 and perplexity is 47.63951992400949
At time: 655.9182462692261 and batch: 500, loss is 3.858157744407654 and perplexity is 47.377988556874485
At time: 657.2064244747162 and batch: 550, loss is 3.8407393169403075 and perplexity is 46.55988422950127
At time: 658.4969248771667 and batch: 600, loss is 3.7838894891738892 and perplexity is 43.98679561296045
At time: 659.7870926856995 and batch: 650, loss is 3.8278774929046633 and perplexity is 45.96487385331897
At time: 661.0725355148315 and batch: 700, loss is 3.8711939954757693 and perplexity is 47.99966326043935
At time: 662.364364862442 and batch: 750, loss is 3.8135541105270385 and perplexity is 45.31119401796472
At time: 663.649810552597 and batch: 800, loss is 3.8066008281707764 and perplexity is 44.99722531356723
At time: 664.9374258518219 and batch: 850, loss is 3.801983985900879 and perplexity is 44.789959047700734
At time: 666.2267293930054 and batch: 900, loss is 3.7545794820785523 and perplexity is 42.716253083193166
At time: 667.5187084674835 and batch: 950, loss is 3.866654510498047 and perplexity is 47.78226332533118
At time: 668.806369304657 and batch: 1000, loss is 3.8308785009384154 and perplexity is 46.10302199718725
At time: 670.0929872989655 and batch: 1050, loss is 3.778114104270935 and perplexity is 43.73348711876777
At time: 671.3830888271332 and batch: 1100, loss is 3.783951926231384 and perplexity is 43.989542104787695
At time: 672.6696894168854 and batch: 1150, loss is 3.772750883102417 and perplexity is 43.49956261003734
At time: 673.9561698436737 and batch: 1200, loss is 3.809925174713135 and perplexity is 45.14706059816998
At time: 675.2430057525635 and batch: 1250, loss is 3.8025221824645996 and perplexity is 44.814071337743194
At time: 676.5267498493195 and batch: 1300, loss is 3.792226805686951 and perplexity is 44.355060487593484
At time: 677.8201198577881 and batch: 1350, loss is 3.669318661689758 and perplexity is 39.22517114182006
At time: 679.1140756607056 and batch: 1400, loss is 3.6835366535186767 and perplexity is 39.78685787115685
At time: 680.4019787311554 and batch: 1450, loss is 3.5986792707443236 and perplexity is 36.549929990316045
At time: 681.6925342082977 and batch: 1500, loss is 3.5936397981643675 and perplexity is 36.36620095787715
At time: 682.9804356098175 and batch: 1550, loss is 3.626689944267273 and perplexity is 37.58819146422937
At time: 684.2697308063507 and batch: 1600, loss is 3.7040961313247682 and perplexity is 40.61332161256955
At time: 685.5578196048737 and batch: 1650, loss is 3.660542063713074 and perplexity is 38.88241390554991
At time: 686.8439683914185 and batch: 1700, loss is 3.655643515586853 and perplexity is 38.692412275769904
At time: 688.1314978599548 and batch: 1750, loss is 3.6493729972839355 and perplexity is 38.450549890158335
At time: 689.4183483123779 and batch: 1800, loss is 3.605492148399353 and perplexity is 36.79979035925756
At time: 690.7043852806091 and batch: 1850, loss is 3.621418604850769 and perplexity is 37.390572664456116
At time: 691.993748664856 and batch: 1900, loss is 3.736312756538391 and perplexity is 41.943050451779996
At time: 693.2803180217743 and batch: 1950, loss is 3.667136583328247 and perplexity is 39.139672061416654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337919013444767 and perplexity of 76.54807795628933
finished 13 epochs...
Completing Train Step...
At time: 697.4493079185486 and batch: 50, loss is 3.8830598163604737 and perplexity is 48.57261119352523
At time: 698.7329888343811 and batch: 100, loss is 3.8624164485931396 and perplexity is 47.58018764248805
At time: 700.0167722702026 and batch: 150, loss is 3.8327570390701293 and perplexity is 46.189709679561936
At time: 701.2977352142334 and batch: 200, loss is 3.8411766862869263 and perplexity is 46.58025254956011
At time: 702.5819232463837 and batch: 250, loss is 3.8487445735931396 and perplexity is 46.934103916343524
At time: 703.8634819984436 and batch: 300, loss is 3.8539745664596556 and perplexity is 47.18021195568848
At time: 705.1420707702637 and batch: 350, loss is 3.8755435943603516 and perplexity is 48.208897254315566
At time: 706.4217534065247 and batch: 400, loss is 3.821128878593445 and perplexity is 45.65571900457695
At time: 707.7043128013611 and batch: 450, loss is 3.852041082382202 and perplexity is 47.0890778986164
At time: 708.9845066070557 and batch: 500, loss is 3.8474290943145752 and perplexity is 46.872403666781096
At time: 710.280891418457 and batch: 550, loss is 3.8298514080047608 and perplexity is 46.05569421824806
At time: 711.5592858791351 and batch: 600, loss is 3.773766083717346 and perplexity is 43.5437458163626
At time: 712.8380517959595 and batch: 650, loss is 3.817686882019043 and perplexity is 45.49884231555537
At time: 714.1182527542114 and batch: 700, loss is 3.8616174411773683 and perplexity is 47.542185903575245
At time: 715.3999207019806 and batch: 750, loss is 3.804689745903015 and perplexity is 44.911314032082686
At time: 716.6787526607513 and batch: 800, loss is 3.7975497007369996 and perplexity is 44.59178729655168
At time: 717.9606280326843 and batch: 850, loss is 3.7928511476516724 and perplexity is 44.38276185986841
At time: 719.2413594722748 and batch: 900, loss is 3.7458667612075804 and perplexity is 42.34569492246861
At time: 720.5258660316467 and batch: 950, loss is 3.857993412017822 and perplexity is 47.37020345847893
At time: 721.8081443309784 and batch: 1000, loss is 3.822664484977722 and perplexity is 45.72588207580165
At time: 723.0901396274567 and batch: 1050, loss is 3.7706698083877566 and perplexity is 43.40913090040032
At time: 724.3718178272247 and batch: 1100, loss is 3.7772764492034914 and perplexity is 43.69686888053331
At time: 725.6522314548492 and batch: 1150, loss is 3.766542558670044 and perplexity is 43.23033978872483
At time: 726.9300880432129 and batch: 1200, loss is 3.803934540748596 and perplexity is 44.87740958025372
At time: 728.2096982002258 and batch: 1250, loss is 3.7976302433013918 and perplexity is 44.595378978091055
At time: 729.4866380691528 and batch: 1300, loss is 3.787753200531006 and perplexity is 44.157076641271594
At time: 730.7619981765747 and batch: 1350, loss is 3.665816445350647 and perplexity is 39.08803638450567
At time: 732.0438332557678 and batch: 1400, loss is 3.6800743770599365 and perplexity is 39.64934296446439
At time: 733.3260569572449 and batch: 1450, loss is 3.596112837791443 and perplexity is 36.4562473121403
At time: 734.6075482368469 and batch: 1500, loss is 3.5918641757965086 and perplexity is 36.30168561241804
At time: 735.8929691314697 and batch: 1550, loss is 3.6257046127319335 and perplexity is 37.551172874610195
At time: 737.17182970047 and batch: 1600, loss is 3.703895163536072 and perplexity is 40.605160463225
At time: 738.450407743454 and batch: 1650, loss is 3.6605182218551637 and perplexity is 38.881486887613335
At time: 739.7351455688477 and batch: 1700, loss is 3.655829610824585 and perplexity is 38.69961341945927
At time: 741.0156917572021 and batch: 1750, loss is 3.65000910282135 and perplexity is 38.4750162786377
At time: 742.2975239753723 and batch: 1800, loss is 3.606539397239685 and perplexity is 36.83834908380148
At time: 743.5778665542603 and batch: 1850, loss is 3.622491331100464 and perplexity is 37.43070403438299
At time: 744.8573794364929 and batch: 1900, loss is 3.736994996070862 and perplexity is 41.9716754223436
At time: 746.1365196704865 and batch: 1950, loss is 3.6666455125808715 and perplexity is 39.12045643190834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338276991733285 and perplexity of 76.57548541156974
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 750.2738027572632 and batch: 50, loss is 3.8823372411727903 and perplexity is 48.53752650706428
At time: 751.5760667324066 and batch: 100, loss is 3.871630530357361 and perplexity is 48.02062136189553
At time: 752.8582317829132 and batch: 150, loss is 3.8458254098892213 and perplexity is 46.797295364146336
At time: 754.139524936676 and batch: 200, loss is 3.8552452373504638 and perplexity is 47.240200582472156
At time: 755.4189147949219 and batch: 250, loss is 3.8670505332946776 and perplexity is 47.801189938320356
At time: 756.6983280181885 and batch: 300, loss is 3.872586646080017 and perplexity is 48.066556589188544
At time: 757.9783773422241 and batch: 350, loss is 3.902636137008667 and perplexity is 49.532852535072564
At time: 759.2591862678528 and batch: 400, loss is 3.859322304725647 and perplexity is 47.4331952218005
At time: 760.5365283489227 and batch: 450, loss is 3.898875994682312 and perplexity is 49.346951685569216
At time: 761.8152325153351 and batch: 500, loss is 3.8982657623291015 and perplexity is 49.316847765245626
At time: 763.0995764732361 and batch: 550, loss is 3.887721791267395 and perplexity is 48.79958414809659
At time: 764.3818581104279 and batch: 600, loss is 3.824743432998657 and perplexity is 45.82104269056063
At time: 765.6618602275848 and batch: 650, loss is 3.860727548599243 and perplexity is 47.49989728414682
At time: 766.941733121872 and batch: 700, loss is 3.8920215797424316 and perplexity is 49.00986379262528
At time: 768.2213592529297 and batch: 750, loss is 3.8320999145507812 and perplexity is 46.15936725925596
At time: 769.5019583702087 and batch: 800, loss is 3.8211438512802123 and perplexity is 45.65640259847435
At time: 770.783047914505 and batch: 850, loss is 3.816887130737305 and perplexity is 45.462469104795574
At time: 772.0649018287659 and batch: 900, loss is 3.7598803853988647 and perplexity is 42.94328902715352
At time: 773.3438808917999 and batch: 950, loss is 3.86966516494751 and perplexity is 47.92633597667806
At time: 774.6418151855469 and batch: 1000, loss is 3.832387990951538 and perplexity is 46.17266659915823
At time: 775.9199960231781 and batch: 1050, loss is 3.778500690460205 and perplexity is 43.750397149278044
At time: 777.1980364322662 and batch: 1100, loss is 3.7781636619567873 and perplexity is 43.73565450288846
At time: 778.4798009395599 and batch: 1150, loss is 3.768722152709961 and perplexity is 43.324667139995384
At time: 779.7608859539032 and batch: 1200, loss is 3.8071333742141724 and perplexity is 45.021194789730124
At time: 781.042551279068 and batch: 1250, loss is 3.8012293720245363 and perplexity is 44.75617267251957
At time: 782.3241276741028 and batch: 1300, loss is 3.7921976947784426 and perplexity is 44.35376929027981
At time: 783.6067504882812 and batch: 1350, loss is 3.6635217237472535 and perplexity is 38.99844305816529
At time: 784.8872792720795 and batch: 1400, loss is 3.6771499490737916 and perplexity is 39.53356069723499
At time: 786.1663818359375 and batch: 1450, loss is 3.5902592658996584 and perplexity is 36.24347140468076
At time: 787.4475226402283 and batch: 1500, loss is 3.586775984764099 and perplexity is 36.1174448248796
At time: 788.7282857894897 and batch: 1550, loss is 3.6206044483184816 and perplexity is 37.36014327429962
At time: 790.0102653503418 and batch: 1600, loss is 3.6973962783813477 and perplexity is 40.342127823918524
At time: 791.2915499210358 and batch: 1650, loss is 3.6501109170913697 and perplexity is 38.478933783759686
At time: 792.5729074478149 and batch: 1700, loss is 3.6419914102554323 and perplexity is 38.16776878054515
At time: 793.8525941371918 and batch: 1750, loss is 3.638252854347229 and perplexity is 38.02534284262177
At time: 795.1335306167603 and batch: 1800, loss is 3.5959982538223265 and perplexity is 36.45207024994093
At time: 796.415994644165 and batch: 1850, loss is 3.614371113777161 and perplexity is 37.127989301133425
At time: 797.6963913440704 and batch: 1900, loss is 3.7354031372070313 and perplexity is 41.90491558900648
At time: 798.978893995285 and batch: 1950, loss is 3.678771553039551 and perplexity is 39.59772048286408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326312681686047 and perplexity of 75.66477145777324
finished 15 epochs...
Completing Train Step...
At time: 803.1023375988007 and batch: 50, loss is 3.900139961242676 and perplexity is 49.40936401759677
At time: 804.3989818096161 and batch: 100, loss is 3.8795680809020996 and perplexity is 48.40330424427289
At time: 805.6780393123627 and batch: 150, loss is 3.8445185136795046 and perplexity is 46.73617610317439
At time: 806.9754621982574 and batch: 200, loss is 3.8440774297714233 and perplexity is 46.71556607368035
At time: 808.2582151889801 and batch: 250, loss is 3.8505168104171754 and perplexity is 47.0173560130329
At time: 809.5372190475464 and batch: 300, loss is 3.854030256271362 and perplexity is 47.18283948597122
At time: 810.8164060115814 and batch: 350, loss is 3.8791479682922363 and perplexity is 48.38297367666375
At time: 812.0974326133728 and batch: 400, loss is 3.8340488386154177 and perplexity is 46.24941608157158
At time: 813.3793623447418 and batch: 450, loss is 3.8729185342788695 and perplexity is 48.08251195963309
At time: 814.6611595153809 and batch: 500, loss is 3.873895802497864 and perplexity is 48.12952443861984
At time: 815.9447765350342 and batch: 550, loss is 3.8637066793441774 and perplexity is 47.64161668402202
At time: 817.2246615886688 and batch: 600, loss is 3.8024258995056153 and perplexity is 44.80975671406636
At time: 818.5071465969086 and batch: 650, loss is 3.8400621509552 and perplexity is 46.52836613232657
At time: 819.7889137268066 and batch: 700, loss is 3.8747585105895994 and perplexity is 48.17106408452237
At time: 821.0697145462036 and batch: 750, loss is 3.816933789253235 and perplexity is 45.464590365621575
At time: 822.3520171642303 and batch: 800, loss is 3.8076997327804567 and perplexity is 45.046700150971795
At time: 823.6338098049164 and batch: 850, loss is 3.8044239139556884 and perplexity is 44.899376756741404
At time: 824.9133837223053 and batch: 900, loss is 3.749683656692505 and perplexity is 42.507632867728276
At time: 826.1925909519196 and batch: 950, loss is 3.859861898422241 and perplexity is 47.45879678155045
At time: 827.4722120761871 and batch: 1000, loss is 3.8229836893081663 and perplexity is 45.74048030515869
At time: 828.752366065979 and batch: 1050, loss is 3.7699718284606933 and perplexity is 43.37884276986379
At time: 830.0364308357239 and batch: 1100, loss is 3.77133403301239 and perplexity is 43.437973892130536
At time: 831.3160891532898 and batch: 1150, loss is 3.763050355911255 and perplexity is 43.07963397763667
At time: 832.5959982872009 and batch: 1200, loss is 3.802049226760864 and perplexity is 44.79288127847109
At time: 833.8755905628204 and batch: 1250, loss is 3.797124495506287 and perplexity is 44.57283066586123
At time: 835.1576201915741 and batch: 1300, loss is 3.7883981370925905 and perplexity is 44.18556433984199
At time: 836.4400787353516 and batch: 1350, loss is 3.661575026512146 and perplexity is 38.92259874380082
At time: 837.7214119434357 and batch: 1400, loss is 3.6765486860275267 and perplexity is 39.509797772700566
At time: 839.002970457077 and batch: 1450, loss is 3.5913432359695436 and perplexity is 36.28277954348627
At time: 840.2833471298218 and batch: 1500, loss is 3.589378252029419 and perplexity is 36.21155446536519
At time: 841.5648770332336 and batch: 1550, loss is 3.623695049285889 and perplexity is 37.475787181781065
At time: 842.8459191322327 and batch: 1600, loss is 3.700843915939331 and perplexity is 40.481452892138385
At time: 844.1287605762482 and batch: 1650, loss is 3.654493374824524 and perplexity is 38.647936137031586
At time: 845.4086775779724 and batch: 1700, loss is 3.6473348331451416 and perplexity is 38.37226116798999
At time: 846.6889486312866 and batch: 1750, loss is 3.644691200256348 and perplexity is 38.27095296619783
At time: 847.9692120552063 and batch: 1800, loss is 3.602788891792297 and perplexity is 36.700445420759024
At time: 849.2492878437042 and batch: 1850, loss is 3.6213678884506226 and perplexity is 37.388676397297495
At time: 850.5324146747589 and batch: 1900, loss is 3.743659415245056 and perplexity is 42.2523264099663
At time: 851.8141446113586 and batch: 1950, loss is 3.6864244318008423 and perplexity is 39.901919551582914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324469987736192 and perplexity of 75.5254728229826
finished 16 epochs...
Completing Train Step...
At time: 855.9376487731934 and batch: 50, loss is 3.9020113945007324 and perplexity is 49.50191692095742
At time: 857.235319852829 and batch: 100, loss is 3.8787276315689088 and perplexity is 48.36264080966838
At time: 858.5151767730713 and batch: 150, loss is 3.8415538263320923 and perplexity is 46.59782314118909
At time: 859.7961623668671 and batch: 200, loss is 3.8391272163391115 and perplexity is 46.48488548114959
At time: 861.0603718757629 and batch: 250, loss is 3.844062032699585 and perplexity is 46.71484679629094
At time: 862.3516359329224 and batch: 300, loss is 3.846923818588257 and perplexity is 46.84872616131222
At time: 863.6182563304901 and batch: 350, loss is 3.8714413022994996 and perplexity is 48.01153537266708
At time: 864.8945353031158 and batch: 400, loss is 3.826383137702942 and perplexity is 45.896237301446625
At time: 866.182333946228 and batch: 450, loss is 3.8650716972351074 and perplexity is 47.70669274803981
At time: 867.4663784503937 and batch: 500, loss is 3.8662888860702513 and perplexity is 47.764796156050544
At time: 868.736236333847 and batch: 550, loss is 3.8560439491271974 and perplexity is 47.2779469592438
At time: 870.014636516571 and batch: 600, loss is 3.7956689691543577 and perplexity is 44.50800092838809
At time: 871.3081336021423 and batch: 650, loss is 3.833879494667053 and perplexity is 46.241584685961215
At time: 872.578450679779 and batch: 700, loss is 3.8695215368270874 and perplexity is 47.91945290143641
At time: 873.8520920276642 and batch: 750, loss is 3.8122605657577515 and perplexity is 45.252619852272936
At time: 875.1262907981873 and batch: 800, loss is 3.8035564041137695 and perplexity is 44.86044299566108
At time: 876.4014983177185 and batch: 850, loss is 3.8003775835037232 and perplexity is 44.71806611007182
At time: 877.6800863742828 and batch: 900, loss is 3.7461432456970214 and perplexity is 42.357404468988676
At time: 878.9640550613403 and batch: 950, loss is 3.8562987422943116 and perplexity is 47.28999459184626
At time: 880.2451605796814 and batch: 1000, loss is 3.8193969440460207 and perplexity is 45.57671472241668
At time: 881.5257167816162 and batch: 1050, loss is 3.766820945739746 and perplexity is 43.24237623165815
At time: 882.8081319332123 and batch: 1100, loss is 3.7686716222763064 and perplexity is 43.3224779810869
At time: 884.0911688804626 and batch: 1150, loss is 3.760457434654236 and perplexity is 42.96807657123893
At time: 885.3696191310883 and batch: 1200, loss is 3.799579281806946 and perplexity is 44.68238184731839
At time: 886.6477563381195 and batch: 1250, loss is 3.795328960418701 and perplexity is 44.49287039166892
At time: 887.9233667850494 and batch: 1300, loss is 3.786838622093201 and perplexity is 44.11670999314571
At time: 889.2010927200317 and batch: 1350, loss is 3.660818567276001 and perplexity is 38.89316651802933
At time: 890.4822986125946 and batch: 1400, loss is 3.676114225387573 and perplexity is 39.49263604899248
At time: 891.7624535560608 and batch: 1450, loss is 3.591485996246338 and perplexity is 36.287959652884894
At time: 893.0433573722839 and batch: 1500, loss is 3.590228261947632 and perplexity is 36.2423477312513
At time: 894.3241586685181 and batch: 1550, loss is 3.6249122714996336 and perplexity is 37.52143131630789
At time: 895.6040720939636 and batch: 1600, loss is 3.702375917434692 and perplexity is 40.54351806833584
At time: 896.886198759079 and batch: 1650, loss is 3.6563413763046264 and perplexity is 38.719423614352884
At time: 898.1672160625458 and batch: 1700, loss is 3.649447650909424 and perplexity is 38.45342047025793
At time: 899.4468863010406 and batch: 1750, loss is 3.647220244407654 and perplexity is 38.36786439094358
At time: 900.7253954410553 and batch: 1800, loss is 3.6055458116531374 and perplexity is 36.801765208734764
At time: 902.0041317939758 and batch: 1850, loss is 3.6239727115631104 and perplexity is 37.48619423894736
At time: 903.285498380661 and batch: 1900, loss is 3.746360354423523 and perplexity is 42.36660162948663
At time: 904.5649924278259 and batch: 1950, loss is 3.6885420942306517 and perplexity is 39.986507880646485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3238093886264535 and perplexity of 75.47559723857024
finished 17 epochs...
Completing Train Step...
At time: 908.7130110263824 and batch: 50, loss is 3.900963134765625 and perplexity is 49.45005324269055
At time: 909.991114616394 and batch: 100, loss is 3.876505126953125 and perplexity is 48.25527397307747
At time: 911.2681529521942 and batch: 150, loss is 3.838575563430786 and perplexity is 46.45924903074209
At time: 912.5491843223572 and batch: 200, loss is 3.835511121749878 and perplexity is 46.31709529371182
At time: 913.8298602104187 and batch: 250, loss is 3.839839015007019 and perplexity is 46.51798513946174
At time: 915.1107249259949 and batch: 300, loss is 3.8424362993240355 and perplexity is 46.6389626111603
At time: 916.3926620483398 and batch: 350, loss is 3.8668753051757814 and perplexity is 47.79281455954883
At time: 917.6711027622223 and batch: 400, loss is 3.821967406272888 and perplexity is 45.694018644096964
At time: 918.9550466537476 and batch: 450, loss is 3.860643367767334 and perplexity is 47.49589887157505
At time: 920.2363107204437 and batch: 500, loss is 3.862038288116455 and perplexity is 47.56219809773023
At time: 921.5145671367645 and batch: 550, loss is 3.851737127304077 and perplexity is 47.07476710929361
At time: 922.7983748912811 and batch: 600, loss is 3.7919690656661986 and perplexity is 44.343629886507905
At time: 924.0802586078644 and batch: 650, loss is 3.830479474067688 and perplexity is 46.084629322418415
At time: 925.3593871593475 and batch: 700, loss is 3.8665601682662962 and perplexity is 47.77775565260626
At time: 926.6385540962219 and batch: 750, loss is 3.8095879316329957 and perplexity is 45.13183763145899
At time: 927.9181900024414 and batch: 800, loss is 3.8010574626922606 and perplexity is 44.748479330057854
At time: 929.197913646698 and batch: 850, loss is 3.79785662651062 and perplexity is 44.60547576592937
At time: 930.4779706001282 and batch: 900, loss is 3.74383695602417 and perplexity is 42.25982858686796
At time: 931.7591934204102 and batch: 950, loss is 3.854010763168335 and perplexity is 47.181919754984236
At time: 933.039666891098 and batch: 1000, loss is 3.817095470428467 and perplexity is 45.471941728295796
At time: 934.3414506912231 and batch: 1050, loss is 3.764753375053406 and perplexity is 43.15306192579131
At time: 935.6245105266571 and batch: 1100, loss is 3.7667934131622314 and perplexity is 43.24118567397227
At time: 936.9042701721191 and batch: 1150, loss is 3.7586018562316896 and perplexity is 42.88841986298552
At time: 938.1840589046478 and batch: 1200, loss is 3.7977521562576295 and perplexity is 44.60081606399569
At time: 939.465832233429 and batch: 1250, loss is 3.7939848279953003 and perplexity is 44.43310625641924
At time: 940.7459425926208 and batch: 1300, loss is 3.7856785535812376 and perplexity is 44.06556126078432
At time: 942.0248603820801 and batch: 1350, loss is 3.6601135683059693 and perplexity is 38.86575653883168
At time: 943.3100206851959 and batch: 1400, loss is 3.675501670837402 and perplexity is 39.468452062844
At time: 944.5916020870209 and batch: 1450, loss is 3.5911525535583495 and perplexity is 36.27586171517314
At time: 945.8708250522614 and batch: 1500, loss is 3.5902981472015383 and perplexity is 36.244880625429616
At time: 947.1503965854645 and batch: 1550, loss is 3.6252560091018675 and perplexity is 37.53433106007743
At time: 948.4315273761749 and batch: 1600, loss is 3.702957272529602 and perplexity is 40.567095101780666
At time: 949.7117455005646 and batch: 1650, loss is 3.6570427513122556 and perplexity is 38.74658997617576
At time: 950.9940433502197 and batch: 1700, loss is 3.650283784866333 and perplexity is 38.48558612639712
At time: 952.2774412631989 and batch: 1750, loss is 3.6482510566711426 and perplexity is 38.40743484743366
At time: 953.5593082904816 and batch: 1800, loss is 3.60676353931427 and perplexity is 36.846607033231805
At time: 954.8381521701813 and batch: 1850, loss is 3.6250638580322265 and perplexity is 37.52711949109351
At time: 956.1188817024231 and batch: 1900, loss is 3.7473683643341062 and perplexity is 42.40932911505344
At time: 957.3952276706696 and batch: 1950, loss is 3.689127163887024 and perplexity is 40.009909618227475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323525504178779 and perplexity of 75.454173931351
finished 18 epochs...
Completing Train Step...
At time: 961.5159692764282 and batch: 50, loss is 3.8993814420700073 and perplexity is 49.371900277958694
At time: 962.7964277267456 and batch: 100, loss is 3.8742648935317994 and perplexity is 48.14729189326012
At time: 964.0744140148163 and batch: 150, loss is 3.8359811401367185 and perplexity is 46.33887029705001
At time: 965.3520247936249 and batch: 200, loss is 3.8326228046417237 and perplexity is 46.18350984640972
At time: 966.648989200592 and batch: 250, loss is 3.8366042280197146 and perplexity is 46.36775248277937
At time: 967.931111574173 and batch: 300, loss is 3.8390467071533205 and perplexity is 46.481143171515086
At time: 969.2096471786499 and batch: 350, loss is 3.8634927654266358 and perplexity is 47.63142656910168
At time: 970.4912321567535 and batch: 400, loss is 3.81868953704834 and perplexity is 45.544484836658164
At time: 971.772388458252 and batch: 450, loss is 3.857389392852783 and perplexity is 47.341599587251075
At time: 973.054680109024 and batch: 500, loss is 3.8589299392700194 and perplexity is 47.414587725253575
At time: 974.3369960784912 and batch: 550, loss is 3.8485698175430296 and perplexity is 46.925902614362094
At time: 975.6168739795685 and batch: 600, loss is 3.7892355585098265 and perplexity is 44.222581775186136
At time: 976.9012253284454 and batch: 650, loss is 3.8279299259185793 and perplexity is 45.967283993374274
At time: 978.1799886226654 and batch: 700, loss is 3.864277801513672 and perplexity is 47.66883363886416
At time: 979.4584159851074 and batch: 750, loss is 3.8075051879882813 and perplexity is 45.03793740245392
At time: 980.7384350299835 and batch: 800, loss is 3.79904417514801 and perplexity is 44.6584784032712
At time: 982.0200428962708 and batch: 850, loss is 3.7958033180236814 and perplexity is 44.513980929682894
At time: 983.3018267154694 and batch: 900, loss is 3.741912384033203 and perplexity is 42.17857471896598
At time: 984.5827989578247 and batch: 950, loss is 3.852123107910156 and perplexity is 47.0929405635083
At time: 985.8620758056641 and batch: 1000, loss is 3.815235733985901 and perplexity is 45.387454487500534
At time: 987.1431837081909 and batch: 1050, loss is 3.763056583404541 and perplexity is 43.079902256603376
At time: 988.4229562282562 and batch: 1100, loss is 3.765212173461914 and perplexity is 43.17286502439281
At time: 989.7022042274475 and batch: 1150, loss is 3.757059016227722 and perplexity is 42.822300911711025
At time: 990.983624458313 and batch: 1200, loss is 3.7962113285064696 and perplexity is 44.532146806214854
At time: 992.2666308879852 and batch: 1250, loss is 3.792804756164551 and perplexity is 44.38070292530205
At time: 993.5471312999725 and batch: 1300, loss is 3.7846397161483765 and perplexity is 44.01980807542207
At time: 994.8287310600281 and batch: 1350, loss is 3.659378080368042 and perplexity is 38.837181753192134
At time: 996.108921289444 and batch: 1400, loss is 3.6747948217391966 and perplexity is 39.44056368069587
At time: 997.3882234096527 and batch: 1450, loss is 3.5906217432022096 and perplexity is 36.25661122172947
At time: 998.673618555069 and batch: 1500, loss is 3.590044584274292 and perplexity is 36.235691432469096
At time: 999.955560207367 and batch: 1550, loss is 3.625199236869812 and perplexity is 37.53220021281149
At time: 1001.2328701019287 and batch: 1600, loss is 3.703086428642273 and perplexity is 40.572334928456904
At time: 1002.5178744792938 and batch: 1650, loss is 3.6572320365905764 and perplexity is 38.753924829411346
At time: 1003.7997703552246 and batch: 1700, loss is 3.6505623483657836 and perplexity is 38.496308299280564
At time: 1005.0800914764404 and batch: 1750, loss is 3.648635926246643 and perplexity is 38.42221954548719
At time: 1006.3613157272339 and batch: 1800, loss is 3.6072913074493407 and perplexity is 36.8660586308246
At time: 1007.6423659324646 and batch: 1850, loss is 3.625507845878601 and perplexity is 37.54378477537508
At time: 1008.9229629039764 and batch: 1900, loss is 3.747716293334961 and perplexity is 42.424087117779045
At time: 1010.2068612575531 and batch: 1950, loss is 3.6891592741012573 and perplexity is 40.011194365623425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323409963208576 and perplexity of 75.4454563865156
finished 19 epochs...
Completing Train Step...
At time: 1014.364846944809 and batch: 50, loss is 3.897723217010498 and perplexity is 49.290098397390615
At time: 1015.6482174396515 and batch: 100, loss is 3.8721715784072877 and perplexity is 48.04660985531753
At time: 1016.9289979934692 and batch: 150, loss is 3.833690881729126 and perplexity is 46.232863747285975
At time: 1018.2097618579865 and batch: 200, loss is 3.830159239768982 and perplexity is 46.06987380620351
At time: 1019.4917204380035 and batch: 250, loss is 3.8338963842391967 and perplexity is 46.24236569313722
At time: 1020.7724199295044 and batch: 300, loss is 3.8362253522872924 and perplexity is 46.35018819414816
At time: 1022.0533237457275 and batch: 350, loss is 3.8606937599182127 and perplexity is 47.498292352382926
At time: 1023.335902929306 and batch: 400, loss is 3.8159579277038573 and perplexity is 45.42024486108115
At time: 1024.6171116828918 and batch: 450, loss is 3.854687337875366 and perplexity is 47.213852649795996
At time: 1025.8966975212097 and batch: 500, loss is 3.856349229812622 and perplexity is 47.292382206585984
At time: 1027.1801459789276 and batch: 550, loss is 3.8459272670745848 and perplexity is 46.8020622477013
At time: 1028.4610440731049 and batch: 600, loss is 3.7869228887557984 and perplexity is 44.120427717699535
At time: 1029.7440135478973 and batch: 650, loss is 3.825745038986206 and perplexity is 45.866960313119314
At time: 1031.0417084693909 and batch: 700, loss is 3.8622838735580443 and perplexity is 47.573880115561046
At time: 1032.322425365448 and batch: 750, loss is 3.8056690311431884 and perplexity is 44.95531656102812
At time: 1033.6033210754395 and batch: 800, loss is 3.7972482204437257 and perplexity is 44.57834577771823
At time: 1034.8848214149475 and batch: 850, loss is 3.793968334197998 and perplexity is 44.43237339181501
At time: 1036.1686491966248 and batch: 900, loss is 3.740164566040039 and perplexity is 42.10491863461172
At time: 1037.4481408596039 and batch: 950, loss is 3.8504182291030884 and perplexity is 47.01272120874854
At time: 1038.7282509803772 and batch: 1000, loss is 3.813584704399109 and perplexity is 45.312580284043385
At time: 1040.0075166225433 and batch: 1050, loss is 3.7615374612808226 and perplexity is 43.01450830727131
At time: 1041.2845084667206 and batch: 1100, loss is 3.763786506652832 and perplexity is 43.11135875781372
At time: 1042.5643701553345 and batch: 1150, loss is 3.7556797218322755 and perplexity is 42.76327706704995
At time: 1043.8445854187012 and batch: 1200, loss is 3.794825496673584 and perplexity is 44.47047548249599
At time: 1045.1234300136566 and batch: 1250, loss is 3.7917022848129274 and perplexity is 44.33180143296226
At time: 1046.402839899063 and batch: 1300, loss is 3.783647918701172 and perplexity is 43.97617098530073
At time: 1047.6833941936493 and batch: 1350, loss is 3.658609528541565 and perplexity is 38.8073448332988
At time: 1048.9617946147919 and batch: 1400, loss is 3.67403094291687 and perplexity is 39.41044737342865
At time: 1050.2446682453156 and batch: 1450, loss is 3.5899925422668457 and perplexity is 36.233805703414745
At time: 1051.5251414775848 and batch: 1500, loss is 3.5896297979354856 and perplexity is 36.22066447938859
At time: 1052.8058552742004 and batch: 1550, loss is 3.624928674697876 and perplexity is 37.522046792831986
At time: 1054.0871183872223 and batch: 1600, loss is 3.7029699182510374 and perplexity is 40.56760810520841
At time: 1055.371301651001 and batch: 1650, loss is 3.657157130241394 and perplexity is 38.75102202310655
At time: 1056.652425289154 and batch: 1700, loss is 3.650554184913635 and perplexity is 38.4959940377926
At time: 1057.937028169632 and batch: 1750, loss is 3.6486935901641844 and perplexity is 38.42443518506743
At time: 1059.2148756980896 and batch: 1800, loss is 3.6074592208862306 and perplexity is 36.87224945718081
At time: 1060.498557806015 and batch: 1850, loss is 3.625621838569641 and perplexity is 37.54806473637095
At time: 1061.7784504890442 and batch: 1900, loss is 3.7477507305145266 and perplexity is 42.42554810884109
At time: 1063.061202764511 and batch: 1950, loss is 3.6889433336257933 and perplexity is 40.00255526208786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323387252452761 and perplexity of 75.4437429826347
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
3292.2849991321564


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}, {'best_accuracy': -75.4437429826347, 'params': {'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.9151261589557308, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.09244881843629082}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.071828603744507 and batch: 50, loss is 7.690627489089966 and perplexity is 2187.746918937019
At time: 3.566793918609619 and batch: 100, loss is 6.9857617855072025 and perplexity is 1081.1296930446451
At time: 5.063276767730713 and batch: 150, loss is 6.719360446929931 and perplexity is 828.2876081661833
At time: 6.559200763702393 and batch: 200, loss is 6.4927980422973635 and perplexity is 660.3685196483544
At time: 8.057729482650757 and batch: 250, loss is 6.373599119186402 and perplexity is 586.1637100145647
At time: 9.553891897201538 and batch: 300, loss is 6.287308158874512 and perplexity is 537.7039655837829
At time: 11.050841569900513 and batch: 350, loss is 6.2168550777435305 and perplexity is 501.1247528356192
At time: 12.55126166343689 and batch: 400, loss is 6.168279905319213 and perplexity is 477.36428771708387
At time: 14.051006555557251 and batch: 450, loss is 6.073209838867188 and perplexity is 434.07174819877997
At time: 15.549659013748169 and batch: 500, loss is 6.057731218338013 and perplexity is 427.40464819387313
At time: 17.04759979248047 and batch: 550, loss is 5.996315507888794 and perplexity is 401.9450982957916
At time: 18.5472309589386 and batch: 600, loss is 6.037316131591797 and perplexity is 418.7676081596883
At time: 20.0430691242218 and batch: 650, loss is 6.1040058612823485 and perplexity is 447.647396565678
At time: 21.54127311706543 and batch: 700, loss is 6.009438219070435 and perplexity is 407.2544682038388
At time: 23.040035247802734 and batch: 750, loss is 5.940307941436767 and perplexity is 380.0519452622924
At time: 24.537487983703613 and batch: 800, loss is 5.946892013549805 and perplexity is 382.56249041241625
At time: 26.037906169891357 and batch: 850, loss is 5.975379133224488 and perplexity is 393.617306203516
At time: 27.537107467651367 and batch: 900, loss is 5.95304015159607 and perplexity is 384.92178261016886
At time: 29.032208919525146 and batch: 950, loss is 5.965414533615112 and perplexity is 389.7145443704993
At time: 30.53070569038391 and batch: 1000, loss is 5.947038068771362 and perplexity is 382.6183697423475
At time: 32.02872633934021 and batch: 1050, loss is 5.83970160484314 and perplexity is 343.67677387816076
At time: 33.527092695236206 and batch: 1100, loss is 5.917643928527832 and perplexity is 371.5353180921814
At time: 35.025821924209595 and batch: 1150, loss is 5.818338041305542 and perplexity is 336.41248511443024
At time: 36.52450633049011 and batch: 1200, loss is 5.886677274703979 and perplexity is 360.2064267320895
At time: 38.02378988265991 and batch: 1250, loss is 5.841103248596191 and perplexity is 344.1588240337107
At time: 39.524742126464844 and batch: 1300, loss is 5.8463577461242675 and perplexity is 345.9719651248573
At time: 41.02439618110657 and batch: 1350, loss is 5.809133548736572 and perplexity is 333.33018615570535
At time: 42.52619552612305 and batch: 1400, loss is 5.821149654388428 and perplexity is 337.35967780452756
At time: 44.02529859542847 and batch: 1450, loss is 5.78994462966919 and perplexity is 326.99491805791314
At time: 45.52562189102173 and batch: 1500, loss is 5.764059839248657 and perplexity is 318.63933097627773
At time: 47.02564263343811 and batch: 1550, loss is 5.746063451766968 and perplexity is 312.95626481981446
At time: 48.525068044662476 and batch: 1600, loss is 5.748776798248291 and perplexity is 313.8065766734253
At time: 50.02612113952637 and batch: 1650, loss is 5.740139656066894 and perplexity is 311.1078560471942
At time: 51.52746558189392 and batch: 1700, loss is 5.755578908920288 and perplexity is 315.94839993872694
At time: 53.02796292304993 and batch: 1750, loss is 5.759648733139038 and perplexity is 317.2368745427802
At time: 54.52820062637329 and batch: 1800, loss is 5.765053577423096 and perplexity is 318.9561324261233
At time: 56.02909708023071 and batch: 1850, loss is 5.7308411693573 and perplexity is 308.2284316737904
At time: 57.529202938079834 and batch: 1900, loss is 5.729732580184937 and perplexity is 307.88692230359294
At time: 59.03020167350769 and batch: 1950, loss is 5.6605461311340335 and perplexity is 287.30550620001065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.27354367278343 and perplexity of 195.10613114395207
finished 1 epochs...
Completing Train Step...
At time: 63.29288077354431 and batch: 50, loss is 5.576122989654541 and perplexity is 264.0459100296231
At time: 64.56957912445068 and batch: 100, loss is 5.54407338142395 and perplexity is 255.7175158266277
At time: 65.84879040718079 and batch: 150, loss is 5.449340076446533 and perplexity is 232.60461398355613
At time: 67.12948060035706 and batch: 200, loss is 5.418900823593139 and perplexity is 225.63097790210531
At time: 68.40866494178772 and batch: 250, loss is 5.420350999832153 and perplexity is 225.95841995200007
At time: 69.68830108642578 and batch: 300, loss is 5.418280181884765 and perplexity is 225.49098535361898
At time: 70.98650479316711 and batch: 350, loss is 5.390354108810425 and perplexity is 219.28102114896703
At time: 72.26390266418457 and batch: 400, loss is 5.354300394058227 and perplexity is 211.51594676460587
At time: 73.54472970962524 and batch: 450, loss is 5.293450365066528 and perplexity is 199.02896463577548
At time: 74.82116222381592 and batch: 500, loss is 5.2706828117370605 and perplexity is 194.54875727819825
At time: 76.10215926170349 and batch: 550, loss is 5.235514726638794 and perplexity is 187.8257603891831
At time: 77.38221144676208 and batch: 600, loss is 5.226874027252197 and perplexity is 186.20980599880025
At time: 78.66284942626953 and batch: 650, loss is 5.300571002960205 and perplexity is 200.45123555188798
At time: 79.94253492355347 and batch: 700, loss is 5.265545043945313 and perplexity is 193.5517742658187
At time: 81.2242636680603 and batch: 750, loss is 5.202382984161377 and perplexity is 181.70472585301258
At time: 82.50368070602417 and batch: 800, loss is 5.206262235641479 and perplexity is 182.41097314948576
At time: 83.78690218925476 and batch: 850, loss is 5.198796186447144 and perplexity is 181.05415518781717
At time: 85.06412720680237 and batch: 900, loss is 5.190385341644287 and perplexity is 179.5377229653083
At time: 86.34612822532654 and batch: 950, loss is 5.217043142318726 and perplexity is 184.38816765222313
At time: 87.62803888320923 and batch: 1000, loss is 5.178481864929199 and perplexity is 177.4132691387567
At time: 88.90812945365906 and batch: 1050, loss is 5.094051618576049 and perplexity is 163.04913850163052
At time: 90.19117403030396 and batch: 1100, loss is 5.15965124130249 and perplexity is 174.1037248272305
At time: 91.47114539146423 and batch: 1150, loss is 5.06898416519165 and perplexity is 159.0127146207982
At time: 92.75337362289429 and batch: 1200, loss is 5.134500875473022 and perplexity is 169.7795575816046
At time: 94.03320598602295 and batch: 1250, loss is 5.096673707962037 and perplexity is 163.47722891748515
At time: 95.31365036964417 and batch: 1300, loss is 5.10398386001587 and perplexity is 164.67665095569546
At time: 96.59381890296936 and batch: 1350, loss is 5.0250983238220215 and perplexity is 152.18521880943126
At time: 97.87307786941528 and batch: 1400, loss is 5.020327177047729 and perplexity is 151.46085020220275
At time: 99.15258765220642 and batch: 1450, loss is 4.97484525680542 and perplexity is 144.7264279855147
At time: 100.43063187599182 and batch: 1500, loss is 4.9370271015167235 and perplexity is 139.3553438389556
At time: 101.71197271347046 and batch: 1550, loss is 4.944856195449829 and perplexity is 140.4506519563087
At time: 102.99505066871643 and batch: 1600, loss is 4.987857389450073 and perplexity is 146.62193300018419
At time: 104.27366828918457 and batch: 1650, loss is 4.962399539947509 and perplexity is 142.93636624776096
At time: 105.56129884719849 and batch: 1700, loss is 4.967692651748657 and perplexity is 143.69495027869803
At time: 106.84389972686768 and batch: 1750, loss is 4.9718152523040775 and perplexity is 144.28856994816266
At time: 108.124520778656 and batch: 1800, loss is 4.928573026657104 and perplexity is 138.18218928550124
At time: 109.40451550483704 and batch: 1850, loss is 4.927525882720947 and perplexity is 138.0375683765748
At time: 110.68489623069763 and batch: 1900, loss is 5.0105126953125 and perplexity is 149.98161130967526
At time: 111.96583390235901 and batch: 1950, loss is 4.931722288131714 and perplexity is 138.61804708555343
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.765207689861919 and perplexity of 117.35548830207567
finished 2 epochs...
Completing Train Step...
At time: 116.07268333435059 and batch: 50, loss is 4.920645847320556 and perplexity is 137.09112453643715
At time: 117.36775493621826 and batch: 100, loss is 4.857588586807251 and perplexity is 128.7134462751741
At time: 118.64700031280518 and batch: 150, loss is 4.792340240478516 and perplexity is 120.58323248169978
At time: 119.92486357688904 and batch: 200, loss is 4.787871656417846 and perplexity is 120.04559829745507
At time: 121.20456552505493 and batch: 250, loss is 4.804238605499267 and perplexity is 122.02654530095663
At time: 122.4851553440094 and batch: 300, loss is 4.824415130615234 and perplexity is 124.51362287671174
At time: 123.76471519470215 and batch: 350, loss is 4.823314018249512 and perplexity is 124.3765948423378
At time: 125.04363965988159 and batch: 400, loss is 4.776954717636109 and perplexity is 118.74219537964451
At time: 126.32397294044495 and batch: 450, loss is 4.758227653503418 and perplexity is 116.53919491981148
At time: 127.60502243041992 and batch: 500, loss is 4.753785152435302 and perplexity is 116.0226177188754
At time: 128.88337635993958 and batch: 550, loss is 4.724287633895874 and perplexity is 112.65022158475287
At time: 130.16267251968384 and batch: 600, loss is 4.69604266166687 and perplexity is 109.51293407275166
At time: 131.44444036483765 and batch: 650, loss is 4.758725814819336 and perplexity is 116.59726470136717
At time: 132.72469806671143 and batch: 700, loss is 4.784165296554566 and perplexity is 119.60148963182559
At time: 134.0099949836731 and batch: 750, loss is 4.738952159881592 and perplexity is 114.31435573338132
At time: 135.33376717567444 and batch: 800, loss is 4.736442441940308 and perplexity is 114.02781865787108
At time: 136.61265587806702 and batch: 850, loss is 4.723302993774414 and perplexity is 112.53935624707613
At time: 137.89330053329468 and batch: 900, loss is 4.709104423522949 and perplexity is 110.95274872536373
At time: 139.17286133766174 and batch: 950, loss is 4.757246742248535 and perplexity is 116.42493635979484
At time: 140.45695805549622 and batch: 1000, loss is 4.737491178512573 and perplexity is 114.14746653013674
At time: 141.73735451698303 and batch: 1050, loss is 4.6594947242736815 and perplexity is 105.58272029088538
At time: 143.02309441566467 and batch: 1100, loss is 4.717874135971069 and perplexity is 111.93005149563497
At time: 144.3036403656006 and batch: 1150, loss is 4.656720209121704 and perplexity is 105.29018544249546
At time: 145.58329486846924 and batch: 1200, loss is 4.729223651885986 and perplexity is 113.20763968621698
At time: 146.86736488342285 and batch: 1250, loss is 4.705497884750367 and perplexity is 110.55331405642927
At time: 148.15003061294556 and batch: 1300, loss is 4.705263891220093 and perplexity is 110.52744832251496
At time: 149.43004894256592 and batch: 1350, loss is 4.5855562782287596 and perplexity is 98.05771934759804
At time: 150.712735414505 and batch: 1400, loss is 4.606346759796143 and perplexity is 100.11772662425544
At time: 151.99090242385864 and batch: 1450, loss is 4.551491012573242 and perplexity is 94.77361166738548
At time: 153.2699840068817 and batch: 1500, loss is 4.533989582061768 and perplexity is 93.12936816428473
At time: 154.55257606506348 and batch: 1550, loss is 4.546716146469116 and perplexity is 94.32215903214713
At time: 155.8348948955536 and batch: 1600, loss is 4.610948371887207 and perplexity is 100.579491181489
At time: 157.11322164535522 and batch: 1650, loss is 4.576923847198486 and perplexity is 97.21488593291446
At time: 158.3933916091919 and batch: 1700, loss is 4.597515516281128 and perplexity is 99.23745526671188
At time: 159.67280077934265 and batch: 1750, loss is 4.59503026008606 and perplexity is 98.9911309824893
At time: 160.9523162841797 and batch: 1800, loss is 4.544019641876221 and perplexity is 94.06816150376035
At time: 162.23335456848145 and batch: 1850, loss is 4.5732497882843015 and perplexity is 96.85836804955905
At time: 163.51423931121826 and batch: 1900, loss is 4.675229635238647 and perplexity is 107.25719429570812
At time: 164.7978172302246 and batch: 1950, loss is 4.594113683700561 and perplexity is 98.90043961858746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.576002963753634 and perplexity of 97.12540356160643
finished 3 epochs...
Completing Train Step...
At time: 168.9069094657898 and batch: 50, loss is 4.598006391525269 and perplexity is 99.28618043480488
At time: 170.19719195365906 and batch: 100, loss is 4.5347256565094 and perplexity is 93.19794354771209
At time: 171.49338698387146 and batch: 150, loss is 4.4800936889648435 and perplexity is 88.24293967805517
At time: 172.79203295707703 and batch: 200, loss is 4.476870336532593 and perplexity is 87.95895951377105
At time: 174.08800554275513 and batch: 250, loss is 4.488653192520141 and perplexity is 89.00149724072598
At time: 175.37687015533447 and batch: 300, loss is 4.5077151012420655 and perplexity is 90.7143085202852
At time: 176.67597937583923 and batch: 350, loss is 4.515222110748291 and perplexity is 91.39786421609456
At time: 177.96513271331787 and batch: 400, loss is 4.461125640869141 and perplexity is 86.58491778455337
At time: 179.24303531646729 and batch: 450, loss is 4.462687158584595 and perplexity is 86.72022728416127
At time: 180.52721643447876 and batch: 500, loss is 4.465688486099243 and perplexity is 86.9808940659047
At time: 181.82295441627502 and batch: 550, loss is 4.438972511291504 and perplexity is 84.68788111302571
At time: 183.11743021011353 and batch: 600, loss is 4.423136339187622 and perplexity is 83.35731261549795
At time: 184.39602661132812 and batch: 650, loss is 4.483708305358887 and perplexity is 88.56248121660313
At time: 185.68106818199158 and batch: 700, loss is 4.512014970779419 and perplexity is 91.10520801824116
At time: 186.96164226531982 and batch: 750, loss is 4.461482210159302 and perplexity is 86.61579681215575
At time: 188.24186778068542 and batch: 800, loss is 4.46305064201355 and perplexity is 86.75175437917544
At time: 189.52343106269836 and batch: 850, loss is 4.458464040756225 and perplexity is 86.35476977445228
At time: 190.80518341064453 and batch: 900, loss is 4.43163125038147 and perplexity is 84.06844179668511
At time: 192.08535194396973 and batch: 950, loss is 4.497781400680542 and perplexity is 89.8176407309273
At time: 193.36662411689758 and batch: 1000, loss is 4.472240333557129 and perplexity is 87.55265060107524
At time: 194.64947748184204 and batch: 1050, loss is 4.411979370117187 and perplexity is 82.43246649021948
At time: 195.93275380134583 and batch: 1100, loss is 4.46129467010498 and perplexity is 86.59955440401514
At time: 197.2147388458252 and batch: 1150, loss is 4.414505825042725 and perplexity is 82.64099170506842
At time: 198.49562883377075 and batch: 1200, loss is 4.481260604858399 and perplexity is 88.34597187011924
At time: 199.81811690330505 and batch: 1250, loss is 4.465805826187133 and perplexity is 86.99110101048937
At time: 201.10053277015686 and batch: 1300, loss is 4.457837352752685 and perplexity is 86.30066923003788
At time: 202.37811183929443 and batch: 1350, loss is 4.3364205026626585 and perplexity is 76.43345573888546
At time: 203.65809202194214 and batch: 1400, loss is 4.366044702529908 and perplexity is 78.73160810293192
At time: 204.9397168159485 and batch: 1450, loss is 4.30174334526062 and perplexity is 73.82838994691011
At time: 206.2263433933258 and batch: 1500, loss is 4.298906922340393 and perplexity is 73.61927811449559
At time: 207.50666403770447 and batch: 1550, loss is 4.313172292709351 and perplexity is 74.67701092081649
At time: 208.78809475898743 and batch: 1600, loss is 4.383011589050293 and perplexity is 80.07883516826149
At time: 210.0705761909485 and batch: 1650, loss is 4.347095355987549 and perplexity is 77.25374209683213
At time: 211.35154175758362 and batch: 1700, loss is 4.368364839553833 and perplexity is 78.91448829335756
At time: 212.6321041584015 and batch: 1750, loss is 4.36377965927124 and perplexity is 78.55347941550191
At time: 213.91502356529236 and batch: 1800, loss is 4.3146266269683835 and perplexity is 74.78569526868965
At time: 215.1946246623993 and batch: 1850, loss is 4.356975402832031 and perplexity is 78.0207957108073
At time: 216.47294116020203 and batch: 1900, loss is 4.457025508880616 and perplexity is 86.23063499284768
At time: 217.752779006958 and batch: 1950, loss is 4.376465721130371 and perplexity is 79.5563615772227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4994333666424415 and perplexity of 89.9661390394976
finished 4 epochs...
Completing Train Step...
At time: 221.88258576393127 and batch: 50, loss is 4.3820191717147825 and perplexity is 79.9994029654999
At time: 223.17937302589417 and batch: 100, loss is 4.320281953811645 and perplexity is 75.20983100131429
At time: 224.4588623046875 and batch: 150, loss is 4.2806110668182376 and perplexity is 72.28459723328247
At time: 225.74009442329407 and batch: 200, loss is 4.278201370239258 and perplexity is 72.11062298337771
At time: 227.0191147327423 and batch: 250, loss is 4.286680583953857 and perplexity is 72.72466398019303
At time: 228.29732584953308 and batch: 300, loss is 4.302180633544922 and perplexity is 73.86068129668269
At time: 229.58011960983276 and batch: 350, loss is 4.310489683151245 and perplexity is 74.4769501200341
At time: 230.87683749198914 and batch: 400, loss is 4.25504964351654 and perplexity is 70.4603149994231
At time: 232.15590596199036 and batch: 450, loss is 4.272667274475098 and perplexity is 71.71265809375878
At time: 233.43564462661743 and batch: 500, loss is 4.277224102020264 and perplexity is 72.04018598680919
At time: 234.72032809257507 and batch: 550, loss is 4.251806602478028 and perplexity is 70.23217943274378
At time: 235.9991328716278 and batch: 600, loss is 4.241793818473816 and perplexity is 69.5324686621756
At time: 237.27948141098022 and batch: 650, loss is 4.302280139923096 and perplexity is 73.86803127124656
At time: 238.55696392059326 and batch: 700, loss is 4.33872501373291 and perplexity is 76.60980060007176
At time: 239.8347532749176 and batch: 750, loss is 4.276844244003296 and perplexity is 72.01282614137557
At time: 241.1133451461792 and batch: 800, loss is 4.275883731842041 and perplexity is 71.94369015439383
At time: 242.39458298683167 and batch: 850, loss is 4.275043630599976 and perplexity is 71.88327555168104
At time: 243.675226688385 and batch: 900, loss is 4.246926288604737 and perplexity is 69.89025937035748
At time: 244.957581281662 and batch: 950, loss is 4.32028862953186 and perplexity is 75.21033308277933
At time: 246.23918628692627 and batch: 1000, loss is 4.293181190490722 and perplexity is 73.19895833652872
At time: 247.51979517936707 and batch: 1050, loss is 4.240815496444702 and perplexity is 69.46447678074539
At time: 248.79821920394897 and batch: 1100, loss is 4.28697883605957 and perplexity is 72.74635749927046
At time: 250.07831811904907 and batch: 1150, loss is 4.2430453824996945 and perplexity is 69.61954747957455
At time: 251.36197471618652 and batch: 1200, loss is 4.308049507141114 and perplexity is 74.29543480776742
At time: 252.64202690124512 and batch: 1250, loss is 4.29593641281128 and perplexity is 73.40091583151892
At time: 253.92450046539307 and batch: 1300, loss is 4.284621124267578 and perplexity is 72.57504458696458
At time: 255.2099266052246 and batch: 1350, loss is 4.159775743484497 and perplexity is 64.05715575452494
At time: 256.4886968135834 and batch: 1400, loss is 4.197087969779968 and perplexity is 66.49242090279054
At time: 257.7711498737335 and batch: 1450, loss is 4.133730802536011 and perplexity is 62.41032974972673
At time: 259.05464816093445 and batch: 1500, loss is 4.134845805168152 and perplexity is 62.47995624131768
At time: 260.3337335586548 and batch: 1550, loss is 4.156409468650818 and perplexity is 63.84188429791931
At time: 261.61997866630554 and batch: 1600, loss is 4.226927299499511 and perplexity is 68.50640876462506
At time: 262.90385723114014 and batch: 1650, loss is 4.186502423286438 and perplexity is 65.79227454360122
At time: 264.1801495552063 and batch: 1700, loss is 4.2079988288879395 and perplexity is 67.22188262940857
At time: 265.46078991889954 and batch: 1750, loss is 4.201658802032471 and perplexity is 66.79704226100598
At time: 266.7455565929413 and batch: 1800, loss is 4.156000709533691 and perplexity is 63.815793678410564
At time: 268.02529883384705 and batch: 1850, loss is 4.199091644287109 and perplexity is 66.62578363460679
At time: 269.3035008907318 and batch: 1900, loss is 4.299286241531372 and perplexity is 73.64720861646325
At time: 270.58683490753174 and batch: 1950, loss is 4.219924583435058 and perplexity is 68.02835363120428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47472661927689 and perplexity of 87.77060233886405
finished 5 epochs...
Completing Train Step...
At time: 274.75716280937195 and batch: 50, loss is 4.224414439201355 and perplexity is 68.33447783954
At time: 276.03807187080383 and batch: 100, loss is 4.170487856864929 and perplexity is 64.74703168751175
At time: 277.32135367393494 and batch: 150, loss is 4.129153819084167 and perplexity is 62.125331417094635
At time: 278.59868454933167 and batch: 200, loss is 4.130559153556824 and perplexity is 62.21269966338537
At time: 279.8817369937897 and batch: 250, loss is 4.134151334762573 and perplexity is 62.436580823981366
At time: 281.1621980667114 and batch: 300, loss is 4.150407438278198 and perplexity is 63.459851003909925
At time: 282.4391305446625 and batch: 350, loss is 4.1592192029953 and perplexity is 64.02151527233039
At time: 283.7202925682068 and batch: 400, loss is 4.106731815338135 and perplexity is 60.747857574665275
At time: 285.0008716583252 and batch: 450, loss is 4.129921479225159 and perplexity is 62.173040867748284
At time: 286.27919268608093 and batch: 500, loss is 4.139716339111328 and perplexity is 62.78500927148682
At time: 287.5630462169647 and batch: 550, loss is 4.115881934165954 and perplexity is 61.30625851148235
At time: 288.8422772884369 and batch: 600, loss is 4.107022094726562 and perplexity is 60.76549398522973
At time: 290.1233627796173 and batch: 650, loss is 4.165264072418213 and perplexity is 64.40968902021558
At time: 291.4023060798645 and batch: 700, loss is 4.203429574966431 and perplexity is 66.91542944298422
At time: 292.68173384666443 and batch: 750, loss is 4.140004687309265 and perplexity is 62.80311582613843
At time: 293.96066784858704 and batch: 800, loss is 4.134717445373536 and perplexity is 62.47193684166216
At time: 295.2595717906952 and batch: 850, loss is 4.137610621452332 and perplexity is 62.652940866929214
At time: 296.5396959781647 and batch: 900, loss is 4.1085446119308475 and perplexity is 60.85808095999495
At time: 297.82340717315674 and batch: 950, loss is 4.188982601165772 and perplexity is 65.9556536083773
At time: 299.10436177253723 and batch: 1000, loss is 4.158264508247376 and perplexity is 63.960423434614185
At time: 300.3870906829834 and batch: 1050, loss is 4.113550419807434 and perplexity is 61.16348858923182
At time: 301.66581869125366 and batch: 1100, loss is 4.15604941368103 and perplexity is 63.8189018479182
At time: 302.9449517726898 and batch: 1150, loss is 4.113437314033508 and perplexity is 61.15657103673384
At time: 304.22389793395996 and batch: 1200, loss is 4.176866712570191 and perplexity is 65.161363737247
At time: 305.5047059059143 and batch: 1250, loss is 4.1695954751968385 and perplexity is 64.68927839619239
At time: 306.7841923236847 and batch: 1300, loss is 4.15485541343689 and perplexity is 63.74274753671145
At time: 308.0614595413208 and batch: 1350, loss is 4.02899911403656 and perplexity is 56.20462866169367
At time: 309.33942461013794 and batch: 1400, loss is 4.071960878372193 and perplexity is 58.671898324048044
At time: 310.61882758140564 and batch: 1450, loss is 4.006775712966919 and perplexity is 54.96934757012822
At time: 311.898246049881 and batch: 1500, loss is 4.005243406295777 and perplexity is 54.88518217220666
At time: 313.1772949695587 and batch: 1550, loss is 4.029823207855225 and perplexity is 56.25096563914005
At time: 314.45828008651733 and batch: 1600, loss is 4.104808888435364 and perplexity is 60.631156125187715
At time: 315.73835587501526 and batch: 1650, loss is 4.063876209259033 and perplexity is 58.199467735593394
At time: 317.0175745487213 and batch: 1700, loss is 4.082982978820801 and perplexity is 59.32216293864125
At time: 318.2972345352173 and batch: 1750, loss is 4.07530574798584 and perplexity is 58.868476755258676
At time: 319.5780818462372 and batch: 1800, loss is 4.027456359863281 and perplexity is 56.11798558793492
At time: 320.85783982276917 and batch: 1850, loss is 4.0778744554519655 and perplexity is 59.01988703212001
At time: 322.14060068130493 and batch: 1900, loss is 4.174688429832458 and perplexity is 65.01957834385179
At time: 323.42250084877014 and batch: 1950, loss is 4.098216910362243 and perplexity is 60.23279132203638
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463886491642442 and perplexity of 86.82429611364651
finished 6 epochs...
Completing Train Step...
At time: 327.5976779460907 and batch: 50, loss is 4.101202850341797 and perplexity is 60.412911602070686
At time: 328.87673258781433 and batch: 100, loss is 4.053185782432556 and perplexity is 57.58060443474259
At time: 330.15741872787476 and batch: 150, loss is 4.0113644647598266 and perplexity is 55.22216788355011
At time: 331.4399127960205 and batch: 200, loss is 4.015494675636291 and perplexity is 55.450718738681374
At time: 332.71901845932007 and batch: 250, loss is 4.014817094802856 and perplexity is 55.41315912073947
At time: 334.00093626976013 and batch: 300, loss is 4.03638946056366 and perplexity is 56.62153900233592
At time: 335.283579826355 and batch: 350, loss is 4.043943037986756 and perplexity is 57.050853570153585
At time: 336.5625419616699 and batch: 400, loss is 3.9895887851715086 and perplexity is 54.03266576091852
At time: 337.84456491470337 and batch: 450, loss is 4.016733827590943 and perplexity is 55.51947319500503
At time: 339.1271870136261 and batch: 500, loss is 4.033089551925659 and perplexity is 56.435001045067274
At time: 340.40529894828796 and batch: 550, loss is 4.004026021957397 and perplexity is 54.81840646511805
At time: 341.68457651138306 and batch: 600, loss is 3.9972386598587035 and perplexity is 54.44759393378337
At time: 342.96696639060974 and batch: 650, loss is 4.0550353050231935 and perplexity is 57.68719960813168
At time: 344.2444734573364 and batch: 700, loss is 4.094224171638489 and perplexity is 59.99277699978262
At time: 345.5250861644745 and batch: 750, loss is 4.033506398200989 and perplexity is 56.458530668828416
At time: 346.8056552410126 and batch: 800, loss is 4.024575552940369 and perplexity is 55.95655314604599
At time: 348.08720779418945 and batch: 850, loss is 4.030897879600525 and perplexity is 56.31144945686211
At time: 349.3679633140564 and batch: 900, loss is 4.000413761138916 and perplexity is 54.62074530008401
At time: 350.6455764770508 and batch: 950, loss is 4.083813595771789 and perplexity is 59.37145740232183
At time: 351.92218017578125 and batch: 1000, loss is 4.054420342445374 and perplexity is 57.651735044960716
At time: 353.20140385627747 and batch: 1050, loss is 4.0116985893249515 and perplexity is 55.240622049202805
At time: 354.482394695282 and batch: 1100, loss is 4.04883496761322 and perplexity is 57.330626086744246
At time: 355.76295590400696 and batch: 1150, loss is 4.009899244308472 and perplexity is 55.141314482292685
At time: 357.041405916214 and batch: 1200, loss is 4.070122961997986 and perplexity is 58.56416331570726
At time: 358.32216691970825 and batch: 1250, loss is 4.071637172698974 and perplexity is 58.652908971348474
At time: 359.60212326049805 and batch: 1300, loss is 4.050288934707641 and perplexity is 57.414043559011304
At time: 360.88165616989136 and batch: 1350, loss is 3.9305644607543946 and perplexity is 50.93572077163401
At time: 362.16363883018494 and batch: 1400, loss is 3.9714558792114256 and perplexity is 53.06172609650245
At time: 363.4437563419342 and batch: 1450, loss is 3.9107791137695314 and perplexity is 49.93784408269711
At time: 364.72624492645264 and batch: 1500, loss is 3.902813401222229 and perplexity is 49.5416337154942
At time: 366.007999420166 and batch: 1550, loss is 3.9326505947113035 and perplexity is 51.04209042044721
At time: 367.29075360298157 and batch: 1600, loss is 4.008678412437439 and perplexity is 55.07403728359221
At time: 368.5689878463745 and batch: 1650, loss is 3.9661928606033325 and perplexity is 52.78319484518626
At time: 369.8480920791626 and batch: 1700, loss is 3.9802500104904173 and perplexity is 53.530415720151126
At time: 371.1335413455963 and batch: 1750, loss is 3.9721959400177003 and perplexity is 53.101009534573244
At time: 372.4132261276245 and batch: 1800, loss is 3.9290651082992554 and perplexity is 50.859407398259044
At time: 373.6936333179474 and batch: 1850, loss is 3.980742154121399 and perplexity is 53.556766857051834
At time: 374.97368121147156 and batch: 1900, loss is 4.073645877838135 and perplexity is 58.77084377949898
At time: 376.25607991218567 and batch: 1950, loss is 4.002313904762268 and perplexity is 54.72463122880411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.458197447311046 and perplexity of 86.33175122730368
finished 7 epochs...
Completing Train Step...
At time: 380.4144940376282 and batch: 50, loss is 3.9977342319488525 and perplexity is 54.474583328755784
At time: 381.696444272995 and batch: 100, loss is 3.9588425970077514 and perplexity is 52.39664680496542
At time: 382.97941303253174 and batch: 150, loss is 3.917062020301819 and perplexity is 50.25258660304235
At time: 384.25918889045715 and batch: 200, loss is 3.922473692893982 and perplexity is 50.52527433150187
At time: 385.5423090457916 and batch: 250, loss is 3.9184361362457274 and perplexity is 50.3216869485866
At time: 386.82480025291443 and batch: 300, loss is 3.9445724964141844 and perplexity is 51.65425101375555
At time: 388.10481882095337 and batch: 350, loss is 3.94733145236969 and perplexity is 51.796959590032465
At time: 389.3842854499817 and batch: 400, loss is 3.897190504074097 and perplexity is 49.26384791694389
At time: 390.70664644241333 and batch: 450, loss is 3.9262645626068116 and perplexity is 50.717172564488095
At time: 391.9882535934448 and batch: 500, loss is 3.945480341911316 and perplexity is 51.70116638567843
At time: 393.2683746814728 and batch: 550, loss is 3.9161470222473143 and perplexity is 50.20662661392362
At time: 394.5492033958435 and batch: 600, loss is 3.906191029548645 and perplexity is 49.70924985402507
At time: 395.83005714416504 and batch: 650, loss is 3.960370397567749 and perplexity is 52.476759613910126
At time: 397.1095447540283 and batch: 700, loss is 4.009437727928161 and perplexity is 55.11587173400141
At time: 398.3931875228882 and batch: 750, loss is 3.95028018951416 and perplexity is 51.949920618846235
At time: 399.6736304759979 and batch: 800, loss is 3.933280200958252 and perplexity is 51.074236958201816
At time: 400.95182275772095 and batch: 850, loss is 3.9386728620529174 and perplexity is 51.350406985196095
At time: 402.2317223548889 and batch: 900, loss is 3.906661491394043 and perplexity is 49.73264166148974
At time: 403.51174116134644 and batch: 950, loss is 3.9977157354354858 and perplexity is 54.473575748215495
At time: 404.79010105133057 and batch: 1000, loss is 3.969251117706299 and perplexity is 52.94486651649865
At time: 406.06960010528564 and batch: 1050, loss is 3.92481981754303 and perplexity is 50.64395208497579
At time: 407.3481557369232 and batch: 1100, loss is 3.9596303606033327 and perplexity is 52.43793923805127
At time: 408.62585186958313 and batch: 1150, loss is 3.9231186723709106 and perplexity is 50.55787260799147
At time: 409.9062819480896 and batch: 1200, loss is 3.9844058895111085 and perplexity is 53.75334456360681
At time: 411.187548160553 and batch: 1250, loss is 3.991578664779663 and perplexity is 54.14029130611621
At time: 412.46933341026306 and batch: 1300, loss is 3.961934595108032 and perplexity is 52.55890786351577
At time: 413.7518787384033 and batch: 1350, loss is 3.843760380744934 and perplexity is 46.70075729661301
At time: 415.03932428359985 and batch: 1400, loss is 3.890241665840149 and perplexity is 48.922708042587175
At time: 416.3194053173065 and batch: 1450, loss is 3.823485264778137 and perplexity is 45.763428362674695
At time: 417.60375785827637 and batch: 1500, loss is 3.818833360671997 and perplexity is 45.55103568057672
At time: 418.8760986328125 and batch: 1550, loss is 3.8489265727996824 and perplexity is 46.94264666337911
At time: 420.1605386734009 and batch: 1600, loss is 3.926982870101929 and perplexity is 50.75361617696535
At time: 421.4347357749939 and batch: 1650, loss is 3.881174073219299 and perplexity is 48.48110203362085
At time: 422.71279430389404 and batch: 1700, loss is 3.893257460594177 and perplexity is 49.070471589126456
At time: 423.98720145225525 and batch: 1750, loss is 3.885781569480896 and perplexity is 48.704993924440146
At time: 425.26849603652954 and batch: 1800, loss is 3.843635754585266 and perplexity is 46.6949375232331
At time: 426.5449523925781 and batch: 1850, loss is 3.8979620838165285 and perplexity is 49.30187357205692
At time: 427.8179507255554 and batch: 1900, loss is 3.9899313831329346 and perplexity is 54.05118041341863
At time: 429.0839970111847 and batch: 1950, loss is 3.9151499605178834 and perplexity is 50.15659245568027
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469204215116279 and perplexity of 87.28723350679215
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 433.0953781604767 and batch: 50, loss is 3.959360971450806 and perplexity is 52.42381492859297
At time: 434.36847949028015 and batch: 100, loss is 3.9362405014038084 and perplexity is 51.22565605705998
At time: 435.6168110370636 and batch: 150, loss is 3.8906054306030273 and perplexity is 48.940507637114024
At time: 436.8684425354004 and batch: 200, loss is 3.906760458946228 and perplexity is 49.73756382286178
At time: 438.1393013000488 and batch: 250, loss is 3.90723904132843 and perplexity is 49.761373041522916
At time: 439.4079751968384 and batch: 300, loss is 3.9296034669876097 and perplexity is 50.886795373732234
At time: 440.67233204841614 and batch: 350, loss is 3.9234662580490114 and perplexity is 50.57544885487414
At time: 441.94197368621826 and batch: 400, loss is 3.8678475427627563 and perplexity is 47.839303125554636
At time: 443.1878414154053 and batch: 450, loss is 3.89307062625885 and perplexity is 49.061304396582734
At time: 444.472455739975 and batch: 500, loss is 3.906422662734985 and perplexity is 49.720765499610685
At time: 445.7325077056885 and batch: 550, loss is 3.860052146911621 and perplexity is 47.46782660487382
At time: 446.97797441482544 and batch: 600, loss is 3.8416468620300295 and perplexity is 46.60215860386065
At time: 448.22309136390686 and batch: 650, loss is 3.889436798095703 and perplexity is 48.88334757502299
At time: 449.47131752967834 and batch: 700, loss is 3.9501583623886107 and perplexity is 51.94359209484549
At time: 450.71677565574646 and batch: 750, loss is 3.897499055862427 and perplexity is 49.279050710622656
At time: 451.9623522758484 and batch: 800, loss is 3.8668782472610475 and perplexity is 47.792955170291215
At time: 453.20836782455444 and batch: 850, loss is 3.8477463865280153 and perplexity is 46.8872782751637
At time: 454.5007736682892 and batch: 900, loss is 3.808393049240112 and perplexity is 45.07794259883981
At time: 455.7869248390198 and batch: 950, loss is 3.9111824083328246 and perplexity is 49.95798780537214
At time: 457.0682096481323 and batch: 1000, loss is 3.8810574340820314 and perplexity is 48.47544756947818
At time: 458.3504436016083 and batch: 1050, loss is 3.8281223154067994 and perplexity is 45.97612846638116
At time: 459.63078451156616 and batch: 1100, loss is 3.854388132095337 and perplexity is 47.199728105363775
At time: 460.91030168533325 and batch: 1150, loss is 3.8212590789794922 and perplexity is 45.66166378381449
At time: 462.1899447441101 and batch: 1200, loss is 3.8624954557418825 and perplexity is 47.58394696595509
At time: 463.4696900844574 and batch: 1250, loss is 3.840975956916809 and perplexity is 46.57090346315544
At time: 464.75358033180237 and batch: 1300, loss is 3.830069761276245 and perplexity is 46.06575172775619
At time: 466.03736424446106 and batch: 1350, loss is 3.725713167190552 and perplexity is 41.50081921617244
At time: 467.3205318450928 and batch: 1400, loss is 3.748472604751587 and perplexity is 42.45618507570216
At time: 468.6070830821991 and batch: 1450, loss is 3.677237281799316 and perplexity is 39.53701342160609
At time: 469.8999590873718 and batch: 1500, loss is 3.6557763957977296 and perplexity is 38.697554073286426
At time: 471.17607736587524 and batch: 1550, loss is 3.678107533454895 and perplexity is 39.57143554877704
At time: 472.45166754722595 and batch: 1600, loss is 3.7597766447067262 and perplexity is 42.938834291699806
At time: 473.7363398075104 and batch: 1650, loss is 3.711899924278259 and perplexity is 40.93149944783272
At time: 475.0167660713196 and batch: 1700, loss is 3.699940547943115 and perplexity is 40.444899756107766
At time: 476.30532479286194 and batch: 1750, loss is 3.687145862579346 and perplexity is 39.93071641069007
At time: 477.58514428138733 and batch: 1800, loss is 3.640196294784546 and perplexity is 38.09931468820053
At time: 478.8644242286682 and batch: 1850, loss is 3.6798188161849974 and perplexity is 39.639211438351616
At time: 480.14385318756104 and batch: 1900, loss is 3.775947427749634 and perplexity is 43.63883337808094
At time: 481.41606187820435 and batch: 1950, loss is 3.6861297559738158 and perplexity is 39.89016315268746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.40415890715843 and perplexity of 81.79032065108899
finished 9 epochs...
Completing Train Step...
At time: 485.4312529563904 and batch: 50, loss is 3.889215531349182 and perplexity is 48.872532512297
At time: 486.7446434497833 and batch: 100, loss is 3.8457128763198853 and perplexity is 46.792029393768516
At time: 488.01873445510864 and batch: 150, loss is 3.793313784599304 and perplexity is 44.40329971576189
At time: 489.2921483516693 and batch: 200, loss is 3.8114121341705323 and perplexity is 45.21424238281663
At time: 490.56590509414673 and batch: 250, loss is 3.807536144256592 and perplexity is 45.03933163050824
At time: 491.8384461402893 and batch: 300, loss is 3.825512251853943 and perplexity is 45.85628431762778
At time: 493.10631585121155 and batch: 350, loss is 3.824350914955139 and perplexity is 45.8030606339035
At time: 494.37178921699524 and batch: 400, loss is 3.772380542755127 and perplexity is 43.4834559495706
At time: 495.6387755870819 and batch: 450, loss is 3.8030707168579103 and perplexity is 44.83866014046167
At time: 496.91365671157837 and batch: 500, loss is 3.8209767532348633 and perplexity is 45.64877414021046
At time: 498.19051241874695 and batch: 550, loss is 3.7725547790527343 and perplexity is 43.49103300602237
At time: 499.465106010437 and batch: 600, loss is 3.757308216094971 and perplexity is 42.8329735531687
At time: 500.737694978714 and batch: 650, loss is 3.8061873722076416 and perplexity is 44.978624787950906
At time: 502.0135691165924 and batch: 700, loss is 3.869363741874695 and perplexity is 47.91189205019492
At time: 503.2888150215149 and batch: 750, loss is 3.8175541496276857 and perplexity is 45.49280354618986
At time: 504.56412959098816 and batch: 800, loss is 3.788056755065918 and perplexity is 44.170482756775144
At time: 505.840300321579 and batch: 850, loss is 3.774205346107483 and perplexity is 43.56287714775497
At time: 507.1138792037964 and batch: 900, loss is 3.73687442779541 and perplexity is 41.96661527487286
At time: 508.3870825767517 and batch: 950, loss is 3.8421536779403684 and perplexity is 46.62578330547887
At time: 509.6607573032379 and batch: 1000, loss is 3.810048050880432 and perplexity is 45.1526084367826
At time: 510.93886160850525 and batch: 1050, loss is 3.7618973779678346 and perplexity is 43.02999273297917
At time: 512.2146763801575 and batch: 1100, loss is 3.7891994094848633 and perplexity is 44.22098320086723
At time: 513.4643995761871 and batch: 1150, loss is 3.7605917119979857 and perplexity is 42.97384659781021
At time: 514.7109711170197 and batch: 1200, loss is 3.803596692085266 and perplexity is 44.86225036831726
At time: 515.9567847251892 and batch: 1250, loss is 3.7883329010009765 and perplexity is 44.18268194033796
At time: 517.2048180103302 and batch: 1300, loss is 3.7729804039001467 and perplexity is 43.509547810210215
At time: 518.4525105953217 and batch: 1350, loss is 3.6718528175354006 and perplexity is 39.32469989598851
At time: 519.6997330188751 and batch: 1400, loss is 3.6995913982391357 and perplexity is 40.43078089627175
At time: 520.9440867900848 and batch: 1450, loss is 3.626419172286987 and perplexity is 37.578015013002336
At time: 522.1892068386078 and batch: 1500, loss is 3.607335829734802 and perplexity is 36.86770002854992
At time: 523.436437368393 and batch: 1550, loss is 3.6349289321899416 and perplexity is 37.8991593911715
At time: 524.6819341182709 and batch: 1600, loss is 3.717833685874939 and perplexity is 41.175099224097146
At time: 525.927188873291 and batch: 1650, loss is 3.6701390743255615 and perplexity is 39.25736517225529
At time: 527.1730990409851 and batch: 1700, loss is 3.66144766330719 and perplexity is 38.91764175255545
At time: 528.4194416999817 and batch: 1750, loss is 3.6542771673202514 and perplexity is 38.63958106646115
At time: 529.6663191318512 and batch: 1800, loss is 3.609946622848511 and perplexity is 36.96407972488088
At time: 530.9156746864319 and batch: 1850, loss is 3.6518234539031984 and perplexity is 38.544886831736726
At time: 532.1607830524445 and batch: 1900, loss is 3.751260032653809 and perplexity is 42.57469372102447
At time: 533.4057059288025 and batch: 1950, loss is 3.6669055604934693 and perplexity is 39.130630947816805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.408633777707122 and perplexity of 82.15714187476745
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 537.3429889678955 and batch: 50, loss is 3.8676696825027466 and perplexity is 47.83079517129794
At time: 538.6159996986389 and batch: 100, loss is 3.8675868463516236 and perplexity is 47.826833216419615
At time: 539.869814157486 and batch: 150, loss is 3.839364948272705 and perplexity is 46.495937736542864
At time: 541.1199345588684 and batch: 200, loss is 3.849633049964905 and perplexity is 46.97582228885296
At time: 542.3704845905304 and batch: 250, loss is 3.8477487802505492 and perplexity is 46.887390510432596
At time: 543.617924451828 and batch: 300, loss is 3.8669058418273927 and perplexity is 47.79427401435988
At time: 544.8780696392059 and batch: 350, loss is 3.8750955200195314 and perplexity is 48.18730092319891
At time: 546.1356289386749 and batch: 400, loss is 3.7999420070648195 and perplexity is 44.69859221557364
At time: 547.3835005760193 and batch: 450, loss is 3.824970188140869 and perplexity is 45.83143402571204
At time: 548.6347804069519 and batch: 500, loss is 3.8583706283569335 and perplexity is 47.38807564383875
At time: 550.012060880661 and batch: 550, loss is 3.811433115005493 and perplexity is 45.215191025325566
At time: 551.2616667747498 and batch: 600, loss is 3.767508234977722 and perplexity is 43.27210646693175
At time: 552.5136442184448 and batch: 650, loss is 3.8172846031188965 and perplexity is 45.480542772317584
At time: 553.7627263069153 and batch: 700, loss is 3.893933458328247 and perplexity is 49.10365433119603
At time: 555.0172278881073 and batch: 750, loss is 3.8502039098739624 and perplexity is 47.002646558214195
At time: 556.2665259838104 and batch: 800, loss is 3.829588737487793 and perplexity is 46.04359833392407
At time: 557.5147612094879 and batch: 850, loss is 3.8228888177871703 and perplexity is 45.736141042060545
At time: 558.764625787735 and batch: 900, loss is 3.7613699769973756 and perplexity is 43.007304656435636
At time: 560.0208077430725 and batch: 950, loss is 3.8568310928344727 and perplexity is 47.31517614812429
At time: 561.2697296142578 and batch: 1000, loss is 3.808377022743225 and perplexity is 45.077220163122156
At time: 562.5167722702026 and batch: 1050, loss is 3.7628186416625975 and perplexity is 43.06965296903271
At time: 563.8175835609436 and batch: 1100, loss is 3.791818814277649 and perplexity is 44.33696769505842
At time: 565.1013624668121 and batch: 1150, loss is 3.7732861709594725 and perplexity is 43.52285363083389
At time: 566.3749563694 and batch: 1200, loss is 3.8182144927978516 and perplexity is 45.52285432912595
At time: 567.6518156528473 and batch: 1250, loss is 3.7907852506637574 and perplexity is 44.29116629190769
At time: 568.9286539554596 and batch: 1300, loss is 3.7557192707061766 and perplexity is 42.76496833994602
At time: 570.2064933776855 and batch: 1350, loss is 3.651351637840271 and perplexity is 38.526705024557415
At time: 571.4758729934692 and batch: 1400, loss is 3.697202415466309 and perplexity is 40.334307739456385
At time: 572.7450981140137 and batch: 1450, loss is 3.625707912445068 and perplexity is 37.551296782912985
At time: 574.0140063762665 and batch: 1500, loss is 3.6065103578567506 and perplexity is 36.837279336408244
At time: 575.2873899936676 and batch: 1550, loss is 3.6080430555343628 and perplexity is 36.89378303938251
At time: 576.5553908348083 and batch: 1600, loss is 3.6830872917175292 and perplexity is 39.768983193441336
At time: 577.8390810489655 and batch: 1650, loss is 3.6460045766830445 and perplexity is 38.32125015599251
At time: 579.1047677993774 and batch: 1700, loss is 3.634766821861267 and perplexity is 37.89301604394958
At time: 580.3572950363159 and batch: 1750, loss is 3.6236503601074217 and perplexity is 37.47411245706081
At time: 581.6115555763245 and batch: 1800, loss is 3.5670340394973756 and perplexity is 35.41140840316616
At time: 582.8647713661194 and batch: 1850, loss is 3.6033059644699095 and perplexity is 36.719427125379795
At time: 584.1186928749084 and batch: 1900, loss is 3.710446472167969 and perplexity is 40.87205068701193
At time: 585.3715567588806 and batch: 1950, loss is 3.6277311515808104 and perplexity is 37.62734894607521
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379164868731832 and perplexity of 79.77138600053817
finished 11 epochs...
Completing Train Step...
At time: 589.2887659072876 and batch: 50, loss is 3.8760303688049316 and perplexity is 48.23236982596088
At time: 590.5570485591888 and batch: 100, loss is 3.8502585315704345 and perplexity is 47.00521399262606
At time: 591.8481743335724 and batch: 150, loss is 3.807941517829895 and perplexity is 45.057593086416226
At time: 593.1257750988007 and batch: 200, loss is 3.808762493133545 and perplexity is 45.09459944615727
At time: 594.4023864269257 and batch: 250, loss is 3.8019015312194826 and perplexity is 44.78626605815193
At time: 595.6817398071289 and batch: 300, loss is 3.818765640258789 and perplexity is 45.54795105006579
At time: 596.9500939846039 and batch: 350, loss is 3.8269173192977903 and perplexity is 45.92076077609711
At time: 598.2145943641663 and batch: 400, loss is 3.7508825397491456 and perplexity is 42.55862510931084
At time: 599.4733464717865 and batch: 450, loss is 3.7802661085128784 and perplexity is 43.82770310880697
At time: 600.7241199016571 and batch: 500, loss is 3.8184530305862427 and perplexity is 45.53371454535335
At time: 602.0145792961121 and batch: 550, loss is 3.7760610580444336 and perplexity is 43.64379235332198
At time: 603.2870552539825 and batch: 600, loss is 3.7261200618743895 and perplexity is 41.51770911485837
At time: 604.5382568836212 and batch: 650, loss is 3.7762250518798828 and perplexity is 43.65095025313323
At time: 605.7913143634796 and batch: 700, loss is 3.856759533882141 and perplexity is 47.311790444829875
At time: 607.0418329238892 and batch: 750, loss is 3.8160026693344116 and perplexity is 45.42227708235852
At time: 608.2947556972504 and batch: 800, loss is 3.7926495122909545 and perplexity is 44.37381362784145
At time: 609.5483953952789 and batch: 850, loss is 3.7849218463897705 and perplexity is 44.03222914659802
At time: 610.798800945282 and batch: 900, loss is 3.725899887084961 and perplexity is 41.508568968248305
At time: 612.0874471664429 and batch: 950, loss is 3.8243493461608886 and perplexity is 45.80298877838169
At time: 613.3400633335114 and batch: 1000, loss is 3.776652498245239 and perplexity is 43.669612681472714
At time: 614.5913076400757 and batch: 1050, loss is 3.734511981010437 and perplexity is 41.867588398460455
At time: 615.8795309066772 and batch: 1100, loss is 3.762010793685913 and perplexity is 43.03487328726444
At time: 617.1564054489136 and batch: 1150, loss is 3.743906216621399 and perplexity is 42.26275562919786
At time: 618.4332394599915 and batch: 1200, loss is 3.7904622030258177 and perplexity is 44.27686044611475
At time: 619.7104814052582 and batch: 1250, loss is 3.766212749481201 and perplexity is 43.216084376337925
At time: 620.9868938922882 and batch: 1300, loss is 3.7328226709365846 and perplexity is 41.796920766188336
At time: 622.2640616893768 and batch: 1350, loss is 3.631172876358032 and perplexity is 37.757075037940886
At time: 623.5420165061951 and batch: 1400, loss is 3.678767032623291 and perplexity is 39.59754148508912
At time: 624.8208396434784 and batch: 1450, loss is 3.6094968938827514 and perplexity is 36.947459645081736
At time: 626.0912301540375 and batch: 1500, loss is 3.5924872064590456 and perplexity is 36.32430972268173
At time: 627.3694200515747 and batch: 1550, loss is 3.5967969036102296 and perplexity is 36.481194316531436
At time: 628.6492953300476 and batch: 1600, loss is 3.6721392488479614 and perplexity is 39.33596533470595
At time: 629.9692680835724 and batch: 1650, loss is 3.635479893684387 and perplexity is 37.92004612203175
At time: 631.2332901954651 and batch: 1700, loss is 3.6277091550827025 and perplexity is 37.62652128526817
At time: 632.5280044078827 and batch: 1750, loss is 3.6201122856140135 and perplexity is 37.34176052916827
At time: 633.7808713912964 and batch: 1800, loss is 3.5649094772338867 and perplexity is 35.33625452399254
At time: 635.0365138053894 and batch: 1850, loss is 3.602107605934143 and perplexity is 36.67545044163559
At time: 636.2896223068237 and batch: 1900, loss is 3.7083952808380127 and perplexity is 40.788300214490974
At time: 637.5417287349701 and batch: 1950, loss is 3.6268014907836914 and perplexity is 37.592384529902255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379078567859739 and perplexity of 79.764501957412
finished 12 epochs...
Completing Train Step...
At time: 641.4476034641266 and batch: 50, loss is 3.8564740991592408 and perplexity is 47.298287944167285
At time: 642.6977653503418 and batch: 100, loss is 3.8305625343322753 and perplexity is 46.08845728289684
At time: 643.9846563339233 and batch: 150, loss is 3.7874521923065188 and perplexity is 44.14378699827952
At time: 645.2488920688629 and batch: 200, loss is 3.7867615938186647 and perplexity is 44.11331188997342
At time: 646.5092852115631 and batch: 250, loss is 3.7777207708358764 and perplexity is 43.71628865863869
At time: 647.7611172199249 and batch: 300, loss is 3.7927235174179077 and perplexity is 44.37709763906771
At time: 649.0141632556915 and batch: 350, loss is 3.8019059324264526 and perplexity is 44.78646317221203
At time: 650.2680475711823 and batch: 400, loss is 3.7270205307006834 and perplexity is 41.55511135490375
At time: 651.5229065418243 and batch: 450, loss is 3.7584505558013914 and perplexity is 42.88193131747769
At time: 652.7786886692047 and batch: 500, loss is 3.8001836156845092 and perplexity is 44.70939308548001
At time: 654.0553650856018 and batch: 550, loss is 3.7565496158599854 and perplexity is 42.800492770888326
At time: 655.3300287723541 and batch: 600, loss is 3.703762936592102 and perplexity is 40.59979172190148
At time: 656.6106791496277 and batch: 650, loss is 3.75512659072876 and perplexity is 42.73962990900813
At time: 657.8814387321472 and batch: 700, loss is 3.8388512706756592 and perplexity is 46.47205994824147
At time: 659.1537458896637 and batch: 750, loss is 3.800418095588684 and perplexity is 44.71987776886215
At time: 660.4268474578857 and batch: 800, loss is 3.775417056083679 and perplexity is 43.61569471391021
At time: 661.7103400230408 and batch: 850, loss is 3.765898699760437 and perplexity is 43.20251450802524
At time: 662.981746673584 and batch: 900, loss is 3.7070720529556276 and perplexity is 40.73436369139761
At time: 664.2583408355713 and batch: 950, loss is 3.8066858768463137 and perplexity is 45.00105243072632
At time: 665.533575296402 and batch: 1000, loss is 3.7589579820632935 and perplexity is 42.90369625717324
At time: 666.8073093891144 and batch: 1050, loss is 3.7180567264556883 and perplexity is 41.18428396638756
At time: 668.081169128418 and batch: 1100, loss is 3.74325544834137 and perplexity is 42.235261315591664
At time: 669.3539125919342 and batch: 1150, loss is 3.726304488182068 and perplexity is 41.525366778769325
At time: 670.6307969093323 and batch: 1200, loss is 3.7742607498168947 and perplexity is 43.56529075960251
At time: 671.9018959999084 and batch: 1250, loss is 3.7518330907821653 and perplexity is 42.59909848733057
At time: 673.1802649497986 and batch: 1300, loss is 3.718364644050598 and perplexity is 41.19696728466278
At time: 674.4503307342529 and batch: 1350, loss is 3.617257809638977 and perplexity is 37.23532135717431
At time: 675.7282078266144 and batch: 1400, loss is 3.665021800994873 and perplexity is 39.05698763500504
At time: 677.0052263736725 and batch: 1450, loss is 3.5975184726715086 and perplexity is 36.50752751713761
At time: 678.2741596698761 and batch: 1500, loss is 3.5812784242630005 and perplexity is 35.919431779872134
At time: 679.5482766628265 and batch: 1550, loss is 3.5859433031082153 and perplexity is 36.08738300881489
At time: 680.8220367431641 and batch: 1600, loss is 3.6615910816192625 and perplexity is 38.92322365530941
At time: 682.090794801712 and batch: 1650, loss is 3.6246344947814944 and perplexity is 37.51101018369798
At time: 683.3615922927856 and batch: 1700, loss is 3.6189720678329467 and perplexity is 37.299207054561066
At time: 684.6421110630035 and batch: 1750, loss is 3.6132168436050414 and perplexity is 37.08515829456448
At time: 685.9080572128296 and batch: 1800, loss is 3.5581494998931884 and perplexity is 35.09818781347255
At time: 687.1846475601196 and batch: 1850, loss is 3.5956971549987795 and perplexity is 36.44109622668847
At time: 688.4596793651581 and batch: 1900, loss is 3.7017476320266725 and perplexity is 40.51805316799405
At time: 689.7288184165955 and batch: 1950, loss is 3.621326069831848 and perplexity is 37.3871128871849
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380613814952762 and perplexity of 79.88705422710528
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 693.8211662769318 and batch: 50, loss is 3.8565155982971193 and perplexity is 47.30025082306871
At time: 695.0921018123627 and batch: 100, loss is 3.858258080482483 and perplexity is 47.382742516772424
At time: 696.3692901134491 and batch: 150, loss is 3.8379550409317016 and perplexity is 46.430428964102596
At time: 697.6409337520599 and batch: 200, loss is 3.8529249954223634 and perplexity is 47.13071894944289
At time: 698.913738489151 and batch: 250, loss is 3.8492409706115724 and perplexity is 46.95740764906361
At time: 700.1917748451233 and batch: 300, loss is 3.856619610786438 and perplexity is 47.305170895772285
At time: 701.4641513824463 and batch: 350, loss is 3.8709860754013063 and perplexity is 47.989684204339035
At time: 702.7343821525574 and batch: 400, loss is 3.8025637435913087 and perplexity is 44.81593389974523
At time: 704.009181022644 and batch: 450, loss is 3.824174795150757 and perplexity is 45.79499451814677
At time: 705.2817559242249 and batch: 500, loss is 3.840911087989807 and perplexity is 46.567882556600814
At time: 706.5941572189331 and batch: 550, loss is 3.811841969490051 and perplexity is 45.233681238592155
At time: 707.867579460144 and batch: 600, loss is 3.7747083854675294 and perplexity is 43.58479650228397
At time: 709.1423561573029 and batch: 650, loss is 3.7899572896957396 and perplexity is 44.25451011202714
At time: 710.4099299907684 and batch: 700, loss is 3.8548124170303346 and perplexity is 47.21975848792916
At time: 711.6797182559967 and batch: 750, loss is 3.8178651762008666 and perplexity is 45.50695521764008
At time: 712.9496011734009 and batch: 800, loss is 3.8135364055633545 and perplexity is 45.31039179202187
At time: 714.2240290641785 and batch: 850, loss is 3.8303435182571413 and perplexity is 46.07836427517957
At time: 715.4995288848877 and batch: 900, loss is 3.7907251119613647 and perplexity is 44.28850275873096
At time: 716.7676217556 and batch: 950, loss is 3.9061639165878295 and perplexity is 49.70790210735239
At time: 718.0395185947418 and batch: 1000, loss is 3.831134724617004 and perplexity is 46.11483619655161
At time: 719.3126668930054 and batch: 1050, loss is 3.770283842086792 and perplexity is 43.39237967163146
At time: 720.5848903656006 and batch: 1100, loss is 3.767246437072754 and perplexity is 43.26077940288067
At time: 721.8605127334595 and batch: 1150, loss is 3.7325579786300658 and perplexity is 41.785858906884464
At time: 723.1296479701996 and batch: 1200, loss is 3.775770583152771 and perplexity is 43.63111676852509
At time: 724.4093203544617 and batch: 1250, loss is 3.765096278190613 and perplexity is 43.167861783419546
At time: 725.684957742691 and batch: 1300, loss is 3.7389466333389283 and perplexity is 42.053668893032274
At time: 726.9567255973816 and batch: 1350, loss is 3.625917468070984 and perplexity is 37.55916669297745
At time: 728.2283473014832 and batch: 1400, loss is 3.6771020030975343 and perplexity is 39.53166526751191
At time: 729.5038120746613 and batch: 1450, loss is 3.6205130052566528 and perplexity is 37.35672710460314
At time: 730.7792794704437 and batch: 1500, loss is 3.6233233499526976 and perplexity is 37.461860045188814
At time: 732.0494120121002 and batch: 1550, loss is 3.641278929710388 and perplexity is 38.14058467306508
At time: 733.3220744132996 and batch: 1600, loss is 3.708502993583679 and perplexity is 40.79269387092029
At time: 734.5953042507172 and batch: 1650, loss is 3.6458447074890135 and perplexity is 38.315124258300024
At time: 735.8648171424866 and batch: 1700, loss is 3.619938268661499 and perplexity is 37.33526299515639
At time: 737.1368324756622 and batch: 1750, loss is 3.615991916656494 and perplexity is 37.188215247105404
At time: 738.4131896495819 and batch: 1800, loss is 3.562994704246521 and perplexity is 35.26865835466748
At time: 739.6854183673859 and batch: 1850, loss is 3.589750037193298 and perplexity is 36.22501988704331
At time: 740.9517457485199 and batch: 1900, loss is 3.698214168548584 and perplexity is 40.375136750589284
At time: 742.2314281463623 and batch: 1950, loss is 3.619653968811035 and perplexity is 37.32465009416439
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363125681322674 and perplexity of 78.50212396667689
finished 14 epochs...
Completing Train Step...
At time: 746.2914907932281 and batch: 50, loss is 3.8628966331481935 and perplexity is 47.603040400052045
At time: 747.5809061527252 and batch: 100, loss is 3.8479983472824095 and perplexity is 46.899093517595595
At time: 748.8458564281464 and batch: 150, loss is 3.8156398916244507 and perplexity is 45.40580188129592
At time: 750.1278729438782 and batch: 200, loss is 3.822796721458435 and perplexity is 45.73192910533499
At time: 751.3975751399994 and batch: 250, loss is 3.8192669582366943 and perplexity is 45.57079078128953
At time: 752.663740158081 and batch: 300, loss is 3.828328471183777 and perplexity is 45.98560768793213
At time: 753.9416522979736 and batch: 350, loss is 3.847123556137085 and perplexity is 46.858084545620656
At time: 755.2143278121948 and batch: 400, loss is 3.783927402496338 and perplexity is 43.988463330140156
At time: 756.4817276000977 and batch: 450, loss is 3.810308966636658 and perplexity is 45.16439100081992
At time: 757.7633666992188 and batch: 500, loss is 3.828575892448425 and perplexity is 45.99698691281496
At time: 759.0364511013031 and batch: 550, loss is 3.7981799173355104 and perplexity is 44.61989863824988
At time: 760.302948474884 and batch: 600, loss is 3.756579566001892 and perplexity is 42.80177467091693
At time: 761.5874791145325 and batch: 650, loss is 3.769923062324524 and perplexity is 43.37672740288997
At time: 762.8598515987396 and batch: 700, loss is 3.833431906700134 and perplexity is 46.22089214029719
At time: 764.1262593269348 and batch: 750, loss is 3.7983561420440672 and perplexity is 44.62776245976272
At time: 765.4012291431427 and batch: 800, loss is 3.7939727020263674 and perplexity is 44.43256746521986
At time: 766.6821119785309 and batch: 850, loss is 3.811701855659485 and perplexity is 45.227343818233685
At time: 767.9485013484955 and batch: 900, loss is 3.7725849676132204 and perplexity is 43.49234595752084
At time: 769.2214441299438 and batch: 950, loss is 3.8883844232559204 and perplexity is 48.831931029435424
At time: 770.5353875160217 and batch: 1000, loss is 3.815791654586792 and perplexity is 45.41269332321649
At time: 771.805623292923 and batch: 1050, loss is 3.7556061363220214 and perplexity is 42.76013042526188
At time: 773.0764892101288 and batch: 1100, loss is 3.755419912338257 and perplexity is 42.752168204829005
At time: 774.3499703407288 and batch: 1150, loss is 3.723558440208435 and perplexity is 41.41149255307385
At time: 775.625173330307 and batch: 1200, loss is 3.7687354612350465 and perplexity is 43.32524373125162
At time: 776.8950474262238 and batch: 1250, loss is 3.7586212253570555 and perplexity is 42.889250582211716
At time: 778.1677145957947 and batch: 1300, loss is 3.732085471153259 and perplexity is 41.766119440016276
At time: 779.4375455379486 and batch: 1350, loss is 3.619701614379883 and perplexity is 37.326428490716204
At time: 780.7149415016174 and batch: 1400, loss is 3.6707656478881834 and perplexity is 39.28197050713159
At time: 781.9895925521851 and batch: 1450, loss is 3.6144260025024413 and perplexity is 37.130027265068506
At time: 783.2622191905975 and batch: 1500, loss is 3.6185355949401856 and perplexity is 37.28293051415301
At time: 784.5331540107727 and batch: 1550, loss is 3.6394944286346433 and perplexity is 38.07258345085906
At time: 785.8100173473358 and batch: 1600, loss is 3.710423092842102 and perplexity is 40.871095137190174
At time: 787.0802085399628 and batch: 1650, loss is 3.6505754709243776 and perplexity is 38.49681347265645
At time: 788.3496074676514 and batch: 1700, loss is 3.624590301513672 and perplexity is 37.509352486208435
At time: 789.6258828639984 and batch: 1750, loss is 3.620853214263916 and perplexity is 37.36943836176548
At time: 790.9009747505188 and batch: 1800, loss is 3.566956067085266 and perplexity is 35.408647397879285
At time: 792.175541639328 and batch: 1850, loss is 3.5927987718582153 and perplexity is 36.33562888397798
At time: 793.4508829116821 and batch: 1900, loss is 3.7012909698486327 and perplexity is 40.49955432976578
At time: 794.7266952991486 and batch: 1950, loss is 3.622040524482727 and perplexity is 37.41383382818374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361689226017442 and perplexity of 78.38944012625922
finished 15 epochs...
Completing Train Step...
At time: 798.8139495849609 and batch: 50, loss is 3.8551939392089842 and perplexity is 47.23777731013437
At time: 800.1022148132324 and batch: 100, loss is 3.8378099250793456 and perplexity is 46.423691661684735
At time: 801.3747458457947 and batch: 150, loss is 3.805919246673584 and perplexity is 44.96656648679992
At time: 802.6668512821198 and batch: 200, loss is 3.8131188774108886 and perplexity is 45.291477376774644
At time: 803.9365148544312 and batch: 250, loss is 3.809494609832764 and perplexity is 45.127626043642984
At time: 805.2080109119415 and batch: 300, loss is 3.8188103580474855 and perplexity is 45.54998789925776
At time: 806.4835810661316 and batch: 350, loss is 3.83956139087677 and perplexity is 46.505072416821086
At time: 807.7563259601593 and batch: 400, loss is 3.7777263498306275 and perplexity is 43.71653255226399
At time: 809.0269572734833 and batch: 450, loss is 3.8066189527511596 and perplexity is 44.998040876785296
At time: 810.3062431812286 and batch: 500, loss is 3.8249083375930786 and perplexity is 45.82859941407357
At time: 811.5783135890961 and batch: 550, loss is 3.7927069091796874 and perplexity is 44.37636061977891
At time: 812.8528966903687 and batch: 600, loss is 3.747943663597107 and perplexity is 42.43373419027546
At time: 814.1251969337463 and batch: 650, loss is 3.758787293434143 and perplexity is 42.89637370902925
At time: 815.3960044384003 and batch: 700, loss is 3.8227595281600952 and perplexity is 45.73022821568316
At time: 816.6716980934143 and batch: 750, loss is 3.7890479946136475 and perplexity is 44.21428799328062
At time: 817.941903591156 and batch: 800, loss is 3.784043951034546 and perplexity is 43.99359042001091
At time: 819.2176163196564 and batch: 850, loss is 3.8028443574905397 and perplexity is 44.82851163836612
At time: 820.4906103610992 and batch: 900, loss is 3.7633999824523925 and perplexity is 43.094698394364244
At time: 821.7619705200195 and batch: 950, loss is 3.8795410633087157 and perplexity is 48.40199652114623
At time: 823.0380997657776 and batch: 1000, loss is 3.8074871110916138 and perplexity is 45.037123263671944
At time: 824.3077266216278 and batch: 1050, loss is 3.7480436515808107 and perplexity is 42.437977265922925
At time: 825.5811655521393 and batch: 1100, loss is 3.7487244606018066 and perplexity is 42.466879260931506
At time: 826.8520843982697 and batch: 1150, loss is 3.7186430358886717 and perplexity is 41.20843778068038
At time: 828.1192481517792 and batch: 1200, loss is 3.7649366569519045 and perplexity is 43.160971825755695
At time: 829.3938899040222 and batch: 1250, loss is 3.754481620788574 and perplexity is 42.71207302009992
At time: 830.6700603961945 and batch: 1300, loss is 3.7280043745040894 and perplexity is 41.596015211913844
At time: 831.9387202262878 and batch: 1350, loss is 3.6152169370651244 and perplexity is 37.15940630386284
At time: 833.2079629898071 and batch: 1400, loss is 3.6661352491378785 and perplexity is 39.10049978512459
At time: 834.4870896339417 and batch: 1450, loss is 3.6100622415542603 and perplexity is 36.9683537110095
At time: 835.7585160732269 and batch: 1500, loss is 3.61443452835083 and perplexity is 37.13034383140113
At time: 837.029346704483 and batch: 1550, loss is 3.6370808601379396 and perplexity is 37.98080346604785
At time: 838.3030300140381 and batch: 1600, loss is 3.7104905796051026 and perplexity is 40.873853488176316
At time: 839.5768570899963 and batch: 1650, loss is 3.652485475540161 and perplexity is 38.570412829262665
At time: 840.8522353172302 and batch: 1700, loss is 3.627389907836914 and perplexity is 37.61451103920024
At time: 842.1257400512695 and batch: 1750, loss is 3.623410549163818 and perplexity is 37.46512683226043
At time: 843.4031529426575 and batch: 1800, loss is 3.5685567903518676 and perplexity is 35.46537223187651
At time: 844.6770701408386 and batch: 1850, loss is 3.5930195474624633 and perplexity is 36.343651789998944
At time: 845.9510037899017 and batch: 1900, loss is 3.7017487049102784 and perplexity is 40.518096639172356
At time: 847.2264893054962 and batch: 1950, loss is 3.622161445617676 and perplexity is 37.418358224975115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3611975381540695 and perplexity of 78.3509064639759
finished 16 epochs...
Completing Train Step...
At time: 851.315797328949 and batch: 50, loss is 3.848062505722046 and perplexity is 46.90210258678362
At time: 852.6089327335358 and batch: 100, loss is 3.8294434690475465 and perplexity is 46.036910138014434
At time: 853.8781356811523 and batch: 150, loss is 3.798102593421936 and perplexity is 44.616448586451355
At time: 855.1473391056061 and batch: 200, loss is 3.80559431552887 and perplexity is 44.95195782241105
At time: 856.4241662025452 and batch: 250, loss is 3.8018864488601682 and perplexity is 44.7855905806888
At time: 857.6974124908447 and batch: 300, loss is 3.8113615465164186 and perplexity is 45.211955158215105
At time: 858.9695339202881 and batch: 350, loss is 3.8331105756759642 and perplexity is 46.20604231966951
At time: 860.2448787689209 and batch: 400, loss is 3.772266082763672 and perplexity is 43.47847911840363
At time: 861.5171813964844 and batch: 450, loss is 3.8041857719421386 and perplexity is 44.888685601810536
At time: 862.7855477333069 and batch: 500, loss is 3.821918969154358 and perplexity is 45.69180541110152
At time: 864.0584030151367 and batch: 550, loss is 3.788553318977356 and perplexity is 44.1924216710487
At time: 865.3313543796539 and batch: 600, loss is 3.741105761528015 and perplexity is 42.14456624920338
At time: 866.6232056617737 and batch: 650, loss is 3.7503984069824217 and perplexity is 42.53802607112572
At time: 867.8956942558289 and batch: 700, loss is 3.8144942235946657 and perplexity is 45.35381169314864
At time: 869.1673922538757 and batch: 750, loss is 3.781909031867981 and perplexity is 43.899767848056776
At time: 870.4450836181641 and batch: 800, loss is 3.7776523351669313 and perplexity is 43.71329700754953
At time: 871.7153244018555 and batch: 850, loss is 3.796359896659851 and perplexity is 44.53876335652413
At time: 872.9832186698914 and batch: 900, loss is 3.7560600996017457 and perplexity is 42.77954636103867
At time: 874.2601356506348 and batch: 950, loss is 3.8725183153152467 and perplexity is 48.063272276827995
At time: 875.5323839187622 and batch: 1000, loss is 3.8002772617340086 and perplexity is 44.71358013956545
At time: 876.805438041687 and batch: 1050, loss is 3.7419998025894166 and perplexity is 42.182262070240164
At time: 878.0795300006866 and batch: 1100, loss is 3.743301720619202 and perplexity is 42.237215682553725
At time: 879.3547410964966 and batch: 1150, loss is 3.7143819522857666 and perplexity is 41.03321875872095
At time: 880.6249878406525 and batch: 1200, loss is 3.761424922943115 and perplexity is 43.009667798385635
At time: 881.8991482257843 and batch: 1250, loss is 3.75088707447052 and perplexity is 42.558818101255376
At time: 883.1693012714386 and batch: 1300, loss is 3.724484086036682 and perplexity is 41.44984267497399
At time: 884.4388751983643 and batch: 1350, loss is 3.6111652946472166 and perplexity is 37.0091542663644
At time: 885.7128663063049 and batch: 1400, loss is 3.661999850273132 and perplexity is 38.93913750136638
At time: 886.9855134487152 and batch: 1450, loss is 3.6060632276535034 and perplexity is 36.82081195801696
At time: 888.2574906349182 and batch: 1500, loss is 3.610646200180054 and perplexity is 36.989948004513764
At time: 889.5274021625519 and batch: 1550, loss is 3.634264979362488 and perplexity is 37.87400448889396
At time: 890.7990267276764 and batch: 1600, loss is 3.7092537832260133 and perplexity is 40.82333210295593
At time: 892.0777490139008 and batch: 1650, loss is 3.652648811340332 and perplexity is 38.57671327303506
At time: 893.3495390415192 and batch: 1700, loss is 3.6285453462600707 and perplexity is 37.65799740859623
At time: 894.6186189651489 and batch: 1750, loss is 3.6242979764938354 and perplexity is 37.49838916650325
At time: 895.8867950439453 and batch: 1800, loss is 3.5691484451293944 and perplexity is 35.48636169744077
At time: 897.1576106548309 and batch: 1850, loss is 3.5924745273590086 and perplexity is 36.32384916604471
At time: 898.4311759471893 and batch: 1900, loss is 3.7014739227294924 and perplexity is 40.5069645177409
At time: 899.710084438324 and batch: 1950, loss is 3.6215684938430788 and perplexity is 37.396177519757245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361115495548692 and perplexity of 78.34447861515822
finished 17 epochs...
Completing Train Step...
At time: 903.778333902359 and batch: 50, loss is 3.8415414333343505 and perplexity is 46.59724565805051
At time: 905.0504381656647 and batch: 100, loss is 3.8219931745529174 and perplexity is 45.695196115535694
At time: 906.3253371715546 and batch: 150, loss is 3.7910976648330688 and perplexity is 44.3050056415245
At time: 907.5979924201965 and batch: 200, loss is 3.7990746784210203 and perplexity is 44.65984065380659
At time: 908.8702983856201 and batch: 250, loss is 3.7952401399612428 and perplexity is 44.488918690065674
At time: 910.1434404850006 and batch: 300, loss is 3.804764275550842 and perplexity is 44.91466138123778
At time: 911.4132506847382 and batch: 350, loss is 3.8269608879089354 and perplexity is 45.92276152345143
At time: 912.6845288276672 and batch: 400, loss is 3.767067804336548 and perplexity is 43.25305230166269
At time: 913.9590878486633 and batch: 450, loss is 3.801481728553772 and perplexity is 44.767468610158936
At time: 915.2282118797302 and batch: 500, loss is 3.819114365577698 and perplexity is 45.563837543671646
At time: 916.5013873577118 and batch: 550, loss is 3.784179491996765 and perplexity is 43.99955375771705
At time: 917.7786927223206 and batch: 600, loss is 3.7345503425598143 and perplexity is 41.86919453482686
At time: 919.0521218776703 and batch: 650, loss is 3.7432450246810913 and perplexity is 42.234821071870414
At time: 920.3260958194733 and batch: 700, loss is 3.807574362754822 and perplexity is 45.0410529990183
At time: 921.6052377223969 and batch: 750, loss is 3.7753085899353027 and perplexity is 43.61096414405382
At time: 922.8750340938568 and batch: 800, loss is 3.771931128501892 and perplexity is 43.463918255274926
At time: 924.148332118988 and batch: 850, loss is 3.7906462478637697 and perplexity is 44.28501012365062
At time: 925.4305596351624 and batch: 900, loss is 3.7502499294281004 and perplexity is 42.53171059791364
At time: 926.7040340900421 and batch: 950, loss is 3.8670117473602295 and perplexity is 47.79933596045523
At time: 927.9747817516327 and batch: 1000, loss is 3.7943256092071533 and perplexity is 44.44825080455786
At time: 929.2962408065796 and batch: 1050, loss is 3.7369462347030638 and perplexity is 41.969628875937836
At time: 930.5702805519104 and batch: 1100, loss is 3.7386153030395506 and perplexity is 42.039737546394086
At time: 931.8420634269714 and batch: 1150, loss is 3.710373501777649 and perplexity is 40.869068346332725
At time: 933.1149661540985 and batch: 1200, loss is 3.7578997659683226 and perplexity is 42.85831888902537
At time: 934.3903656005859 and batch: 1250, loss is 3.747385330200195 and perplexity is 42.41004863215572
At time: 935.6665573120117 and batch: 1300, loss is 3.7211461162567137 and perplexity is 41.31171501397158
At time: 936.9363317489624 and batch: 1350, loss is 3.6073701667785643 and perplexity is 36.868965978113565
At time: 938.2134969234467 and batch: 1400, loss is 3.6581204080581666 and perplexity is 38.78836800739
At time: 939.4870147705078 and batch: 1450, loss is 3.602140536308289 and perplexity is 36.67665819782642
At time: 940.7597985267639 and batch: 1500, loss is 3.606841468811035 and perplexity is 36.849478582663146
At time: 942.034019947052 and batch: 1550, loss is 3.631124777793884 and perplexity is 37.7552590205194
At time: 943.307888507843 and batch: 1600, loss is 3.707251009941101 and perplexity is 40.74165404263919
At time: 944.5816905498505 and batch: 1650, loss is 3.651667823791504 and perplexity is 38.53888855346233
At time: 945.8594152927399 and batch: 1700, loss is 3.628482756614685 and perplexity is 37.65564048165287
At time: 947.1324574947357 and batch: 1750, loss is 3.6238752126693727 and perplexity is 37.48253955464536
At time: 948.404536485672 and batch: 1800, loss is 3.568679790496826 and perplexity is 35.46973474609148
At time: 949.679470539093 and batch: 1850, loss is 3.5913691616058347 and perplexity is 36.28372020982598
At time: 950.9512529373169 and batch: 1900, loss is 3.700854306221008 and perplexity is 40.48187350802179
At time: 952.2233667373657 and batch: 1950, loss is 3.620563516616821 and perplexity is 37.35861409135736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361297749364099 and perplexity of 78.35875849654384
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 956.2960913181305 and batch: 50, loss is 3.841785020828247 and perplexity is 46.60859754687577
At time: 957.5702233314514 and batch: 100, loss is 3.832611713409424 and perplexity is 46.18299761721423
At time: 958.843590259552 and batch: 150, loss is 3.8121045780181886 and perplexity is 45.24556154891158
At time: 960.1177544593811 and batch: 200, loss is 3.82903181552887 and perplexity is 46.017962782107546
At time: 961.4097318649292 and batch: 250, loss is 3.835072422027588 and perplexity is 46.296780453252424
At time: 962.6856491565704 and batch: 300, loss is 3.850255184173584 and perplexity is 47.00505664778414
At time: 963.9657652378082 and batch: 350, loss is 3.8837191581726076 and perplexity is 48.60464770735558
At time: 965.2410297393799 and batch: 400, loss is 3.829516234397888 and perplexity is 46.04026015179026
At time: 966.519229888916 and batch: 450, loss is 3.867914514541626 and perplexity is 47.84250711607212
At time: 967.7894558906555 and batch: 500, loss is 3.8864089584350587 and perplexity is 48.7355604872002
At time: 969.0581293106079 and batch: 550, loss is 3.8699308967590333 and perplexity is 47.939073221027385
At time: 970.3316519260406 and batch: 600, loss is 3.8402714490890504 and perplexity is 46.538105451704304
At time: 971.6064171791077 and batch: 650, loss is 3.858605456352234 and perplexity is 47.39920499733408
At time: 972.8783257007599 and batch: 700, loss is 3.901403560638428 and perplexity is 49.47183712229008
At time: 974.1524848937988 and batch: 750, loss is 3.8378576898574828 and perplexity is 46.425909131975324
At time: 975.4236509799957 and batch: 800, loss is 3.810144748687744 and perplexity is 45.156974806118626
At time: 976.6929578781128 and batch: 850, loss is 3.8063992404937745 and perplexity is 44.98815534167274
At time: 977.9657943248749 and batch: 900, loss is 3.75690158367157 and perplexity is 42.81555981806589
At time: 979.2412822246552 and batch: 950, loss is 3.880188446044922 and perplexity is 48.43334128302606
At time: 980.5149486064911 and batch: 1000, loss is 3.8338960313797 and perplexity is 46.24234937608221
At time: 981.7935528755188 and batch: 1050, loss is 3.79145423412323 and perplexity is 44.32080626277743
At time: 983.0675060749054 and batch: 1100, loss is 3.8020657205581667 and perplexity is 44.79362008926838
At time: 984.3409767150879 and batch: 1150, loss is 3.7760610294342043 and perplexity is 43.643791104663094
At time: 985.6141932010651 and batch: 1200, loss is 3.824001317024231 and perplexity is 45.787050777346046
At time: 986.88409948349 and batch: 1250, loss is 3.8141817903518676 and perplexity is 45.339643868053116
At time: 988.1555180549622 and batch: 1300, loss is 3.7947303247451782 and perplexity is 44.46624334298084
At time: 989.4323992729187 and batch: 1350, loss is 3.6494304943084717 and perplexity is 38.452760745927
At time: 990.7081291675568 and batch: 1400, loss is 3.6742541646957396 and perplexity is 39.419245625541606
At time: 991.9799611568451 and batch: 1450, loss is 3.588590064048767 and perplexity is 36.183024198458604
At time: 993.2544777393341 and batch: 1500, loss is 3.585157217979431 and perplexity is 36.05902640050916
At time: 994.528422832489 and batch: 1550, loss is 3.6154556941986082 and perplexity is 37.168279436413606
At time: 995.8016347885132 and batch: 1600, loss is 3.704031295776367 and perplexity is 40.61068851095062
At time: 997.0695950984955 and batch: 1650, loss is 3.6575704193115235 and perplexity is 38.767040706910514
At time: 998.3442358970642 and batch: 1700, loss is 3.640060753822327 and perplexity is 38.094151020379954
At time: 999.6157224178314 and batch: 1750, loss is 3.6436511278152466 and perplexity is 38.231169095363185
At time: 1000.8904464244843 and batch: 1800, loss is 3.5994069480896 and perplexity is 36.57653622554471
At time: 1002.1639983654022 and batch: 1850, loss is 3.6207797861099245 and perplexity is 37.3666944936307
At time: 1003.4347167015076 and batch: 1900, loss is 3.741791844367981 and perplexity is 42.17349083410085
At time: 1004.7047567367554 and batch: 1950, loss is 3.6797331047058104 and perplexity is 39.63581404850516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340107762536337 and perplexity of 76.71580598270013
finished 19 epochs...
Completing Train Step...
At time: 1008.8084402084351 and batch: 50, loss is 3.886101508140564 and perplexity is 48.72057902792108
At time: 1010.0815114974976 and batch: 100, loss is 3.855329360961914 and perplexity is 47.24417476590977
At time: 1011.3553531169891 and batch: 150, loss is 3.8136548805236816 and perplexity is 45.315760256899885
At time: 1012.6236155033112 and batch: 200, loss is 3.817242994308472 and perplexity is 45.47865042040489
At time: 1013.8921678066254 and batch: 250, loss is 3.81614031791687 and perplexity is 45.42852982474163
At time: 1015.1679108142853 and batch: 300, loss is 3.8208230686187745 and perplexity is 45.6417591649425
At time: 1016.4371531009674 and batch: 350, loss is 3.8489923763275145 and perplexity is 46.94573575677084
At time: 1017.7052328586578 and batch: 400, loss is 3.7979136657714845 and perplexity is 44.60802010186039
At time: 1018.9830989837646 and batch: 450, loss is 3.836245937347412 and perplexity is 46.35114232537908
At time: 1020.2622880935669 and batch: 500, loss is 3.8565963077545167 and perplexity is 47.30406855470885
At time: 1021.531167268753 and batch: 550, loss is 3.8364770460128783 and perplexity is 46.36185571395552
At time: 1022.8100419044495 and batch: 600, loss is 3.8038575887680053 and perplexity is 44.87395630757253
At time: 1024.0836646556854 and batch: 650, loss is 3.819520602226257 and perplexity is 45.58235100449942
At time: 1025.3730471134186 and batch: 700, loss is 3.867140974998474 and perplexity is 47.80551335488751
At time: 1026.6477980613708 and batch: 750, loss is 3.808238410949707 and perplexity is 45.070972361808
At time: 1027.9157235622406 and batch: 800, loss is 3.787904291152954 and perplexity is 44.16374886548729
At time: 1029.1915354728699 and batch: 850, loss is 3.789459671974182 and perplexity is 44.23249376185386
At time: 1030.4639973640442 and batch: 900, loss is 3.7466179609298704 and perplexity is 42.37751694758633
At time: 1031.743263721466 and batch: 950, loss is 3.8709532403945923 and perplexity is 47.98810848860544
At time: 1033.0103571414948 and batch: 1000, loss is 3.822692422866821 and perplexity is 45.727159578269315
At time: 1034.285474538803 and batch: 1050, loss is 3.7780949687957763 and perplexity is 43.73265026571822
At time: 1035.556828737259 and batch: 1100, loss is 3.7889661836624144 and perplexity is 44.21067092828158
At time: 1036.8314723968506 and batch: 1150, loss is 3.7606130695343016 and perplexity is 42.974764423100765
At time: 1038.1045994758606 and batch: 1200, loss is 3.805775647163391 and perplexity is 44.960109773478884
At time: 1039.3778402805328 and batch: 1250, loss is 3.797210841178894 and perplexity is 44.5766795030679
At time: 1040.6483972072601 and batch: 1300, loss is 3.7778635358810426 and perplexity is 43.72253026209434
At time: 1041.9203894138336 and batch: 1350, loss is 3.6374463748931887 and perplexity is 37.994688547577404
At time: 1043.1955518722534 and batch: 1400, loss is 3.6672991704940796 and perplexity is 39.14603618711729
At time: 1044.4639637470245 and batch: 1450, loss is 3.5897704648971556 and perplexity is 36.22575988858003
At time: 1045.742826461792 and batch: 1500, loss is 3.591195878982544 and perplexity is 36.27743341631704
At time: 1047.0100660324097 and batch: 1550, loss is 3.6241921901702883 and perplexity is 37.49442255958447
At time: 1048.2912213802338 and batch: 1600, loss is 3.7144181394577025 and perplexity is 41.03470366173031
At time: 1049.5596475601196 and batch: 1650, loss is 3.6714881372451784 and perplexity is 39.31036156762932
At time: 1050.839494228363 and batch: 1700, loss is 3.6533354759216308 and perplexity is 38.60321163240381
At time: 1052.11261343956 and batch: 1750, loss is 3.656735601425171 and perplexity is 38.7346907929496
At time: 1053.3818836212158 and batch: 1800, loss is 3.6097157764434815 and perplexity is 36.95554768479445
At time: 1054.6549091339111 and batch: 1850, loss is 3.6300753211975096 and perplexity is 37.71565729867124
At time: 1055.927964925766 and batch: 1900, loss is 3.7531944704055786 and perplexity is 42.657131525521855
At time: 1057.2019982337952 and batch: 1950, loss is 3.6901649808883668 and perplexity is 40.05145413672643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336644656159157 and perplexity of 76.45059048557374
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
4383.102392435074


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}, {'best_accuracy': -75.4437429826347, 'params': {'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}}, {'best_accuracy': -76.45059048557374, 'params': {'rnn_dropout': 0.9151261589557308, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.09244881843629082}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.35399849893854385, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7881908157668892}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.040009021759033 and batch: 50, loss is 7.6752972984313965 and perplexity is 2154.464109292469
At time: 3.5435397624969482 and batch: 100, loss is 7.034718322753906 and perplexity is 1135.3750578263855
At time: 5.032260179519653 and batch: 150, loss is 6.740005006790161 and perplexity is 845.5649694068079
At time: 6.523827075958252 and batch: 200, loss is 6.554578151702881 and perplexity is 702.4527588112145
At time: 8.013676166534424 and batch: 250, loss is 6.477584981918335 and perplexity is 650.3983243667097
At time: 9.501329183578491 and batch: 300, loss is 6.401122436523438 and perplexity is 602.5209499872988
At time: 10.984621524810791 and batch: 350, loss is 6.358571968078613 and perplexity is 577.421191459532
At time: 12.45871114730835 and batch: 400, loss is 6.311096143722534 and perplexity is 550.6482076986091
At time: 13.957830429077148 and batch: 450, loss is 6.2097822952270505 and perplexity is 497.5929111424102
At time: 15.445115089416504 and batch: 500, loss is 6.191763153076172 and perplexity is 488.7070123088998
At time: 16.926295042037964 and batch: 550, loss is 6.135135431289672 and perplexity is 461.80163217461666
At time: 18.4140043258667 and batch: 600, loss is 6.170583562850952 and perplexity is 478.4652391745441
At time: 19.89164423942566 and batch: 650, loss is 6.240435533523559 and perplexity is 513.0819266661742
At time: 21.369224786758423 and batch: 700, loss is 6.134398384094238 and perplexity is 461.46138798019285
At time: 22.851319789886475 and batch: 750, loss is 6.060680160522461 and perplexity is 428.6669000298653
At time: 24.320122957229614 and batch: 800, loss is 6.07300820350647 and perplexity is 433.9842328086498
At time: 25.789275407791138 and batch: 850, loss is 6.100089168548584 and perplexity is 445.89752834531686
At time: 27.260651350021362 and batch: 900, loss is 6.0806459617614745 and perplexity is 437.3115900653059
At time: 28.749138116836548 and batch: 950, loss is 6.083143997192383 and perplexity is 438.405375500236
At time: 30.237562894821167 and batch: 1000, loss is 6.064387216567993 and perplexity is 430.25894132310367
At time: 31.73183846473694 and batch: 1050, loss is 5.95672423362732 and perplexity is 386.3424814115182
At time: 33.221025705337524 and batch: 1100, loss is 6.026565046310425 and perplexity is 414.28951719379705
At time: 34.709420919418335 and batch: 1150, loss is 5.937791996002197 and perplexity is 379.0969571584448
At time: 36.203550815582275 and batch: 1200, loss is 6.0174017429351805 and perplexity is 410.5105968012999
At time: 37.69446516036987 and batch: 1250, loss is 5.949374094009399 and perplexity is 383.51322070087946
At time: 39.185094118118286 and batch: 1300, loss is 5.960816402435302 and perplexity is 387.9266992958997
At time: 40.676992893218994 and batch: 1350, loss is 5.939140863418579 and perplexity is 379.60865371943106
At time: 42.17059302330017 and batch: 1400, loss is 5.956568584442139 and perplexity is 386.2823521987387
At time: 43.6609320640564 and batch: 1450, loss is 5.934278554916382 and perplexity is 377.76735943303726
At time: 45.151737213134766 and batch: 1500, loss is 5.905076274871826 and perplexity is 366.89520960530825
At time: 46.641103982925415 and batch: 1550, loss is 5.875330715179444 and perplexity is 356.1424229021246
At time: 48.131553411483765 and batch: 1600, loss is 5.873216781616211 and perplexity is 355.39035667014974
At time: 49.62361240386963 and batch: 1650, loss is 5.867277517318725 and perplexity is 353.28585519467595
At time: 51.114266872406006 and batch: 1700, loss is 5.883061809539795 and perplexity is 358.90646434473484
At time: 52.60867118835449 and batch: 1750, loss is 5.882709140777588 and perplexity is 358.7799115631245
At time: 54.09978127479553 and batch: 1800, loss is 5.888575210571289 and perplexity is 360.8907246003412
At time: 55.59184408187866 and batch: 1850, loss is 5.840700159072876 and perplexity is 344.0201251732929
At time: 57.08711385726929 and batch: 1900, loss is 5.828019313812256 and perplexity is 339.68520253025144
At time: 58.575756788253784 and batch: 1950, loss is 5.767939949035645 and perplexity is 319.87808826590987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.235102311954942 and perplexity of 187.74831425865145
finished 1 epochs...
Completing Train Step...
At time: 62.72776651382446 and batch: 50, loss is 5.531978893280029 and perplexity is 252.643370940583
At time: 64.00126838684082 and batch: 100, loss is 5.4370823097229 and perplexity is 229.77080445680386
At time: 65.2717432975769 and batch: 150, loss is 5.314641714096069 and perplexity is 203.29166354170334
At time: 66.54069662094116 and batch: 200, loss is 5.260897960662842 and perplexity is 192.6544097301118
At time: 67.81210088729858 and batch: 250, loss is 5.269129896163941 and perplexity is 194.24687394362275
At time: 69.08690023422241 and batch: 300, loss is 5.258904180526733 and perplexity is 192.27068185647926
At time: 70.35973000526428 and batch: 350, loss is 5.222943201065063 and perplexity is 185.4792843345543
At time: 71.63024282455444 and batch: 400, loss is 5.177090454101562 and perplexity is 177.1665860536671
At time: 72.9075756072998 and batch: 450, loss is 5.114869165420532 and perplexity is 166.47899834864958
At time: 74.21514439582825 and batch: 500, loss is 5.101569900512695 and perplexity is 164.27960760525875
At time: 75.4831931591034 and batch: 550, loss is 5.056238164901734 and perplexity is 156.99880045447034
At time: 76.76802349090576 and batch: 600, loss is 5.033134346008301 and perplexity is 153.4131096754765
At time: 78.04056167602539 and batch: 650, loss is 5.1037348365783695 and perplexity is 164.63564771559427
At time: 79.30885028839111 and batch: 700, loss is 5.08707106590271 and perplexity is 161.91492871321765
At time: 80.5784797668457 and batch: 750, loss is 5.0235328865051265 and perplexity is 151.94716876365328
At time: 81.84924578666687 and batch: 800, loss is 5.021781053543091 and perplexity is 151.68121572559
At time: 83.11976790428162 and batch: 850, loss is 5.015011930465699 and perplexity is 150.65793417451073
At time: 84.39294242858887 and batch: 900, loss is 5.012057027816772 and perplexity is 150.21341172945566
At time: 85.66171026229858 and batch: 950, loss is 5.049871091842651 and perplexity is 156.00235321427442
At time: 86.93031334877014 and batch: 1000, loss is 5.002323951721191 and perplexity is 148.75846520106208
At time: 88.20131278038025 and batch: 1050, loss is 4.9223551845550535 and perplexity is 137.32565989302918
At time: 89.4739978313446 and batch: 1100, loss is 4.988810081481933 and perplexity is 146.76168510723863
At time: 90.74315762519836 and batch: 1150, loss is 4.906673421859741 and perplexity is 135.18894896719019
At time: 92.01209831237793 and batch: 1200, loss is 4.981828823089599 and perplexity is 145.7406719864585
At time: 93.28620719909668 and batch: 1250, loss is 4.942551393508911 and perplexity is 140.12731377943936
At time: 94.55645394325256 and batch: 1300, loss is 4.958160123825073 and perplexity is 142.33168217156617
At time: 95.8304512500763 and batch: 1350, loss is 4.865765333175659 and perplexity is 129.77021806913274
At time: 97.1016149520874 and batch: 1400, loss is 4.866610898971557 and perplexity is 129.8799937315903
At time: 98.37194037437439 and batch: 1450, loss is 4.823639869689941 and perplexity is 124.41712973874141
At time: 99.64201331138611 and batch: 1500, loss is 4.786375093460083 and perplexity is 119.86607686786756
At time: 100.91362881660461 and batch: 1550, loss is 4.7846965408325195 and perplexity is 119.66504411881134
At time: 102.18515706062317 and batch: 1600, loss is 4.8348206615448 and perplexity is 125.81601753326298
At time: 103.4593095779419 and batch: 1650, loss is 4.815469446182251 and perplexity is 123.40473059400534
At time: 104.73135304450989 and batch: 1700, loss is 4.822462739944458 and perplexity is 124.27076079899587
At time: 105.9976806640625 and batch: 1750, loss is 4.821738491058349 and perplexity is 124.18079042331618
At time: 107.27090358734131 and batch: 1800, loss is 4.783310661315918 and perplexity is 119.49931765029824
At time: 108.54136276245117 and batch: 1850, loss is 4.787595920562744 and perplexity is 120.01250198488695
At time: 109.8116443157196 and batch: 1900, loss is 4.878485794067383 and perplexity is 131.43149878020637
At time: 111.08542370796204 and batch: 1950, loss is 4.788192930221558 and perplexity is 120.08417199946715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.619693915788518 and perplexity of 101.46297116262937
finished 2 epochs...
Completing Train Step...
At time: 115.14686322212219 and batch: 50, loss is 4.77229585647583 and perplexity is 118.19027862754263
At time: 116.4416766166687 and batch: 100, loss is 4.697345542907715 and perplexity is 109.65570940964218
At time: 117.7123851776123 and batch: 150, loss is 4.634591569900513 and perplexity is 102.98584688457136
At time: 118.98415565490723 and batch: 200, loss is 4.623687839508056 and perplexity is 101.86901684780676
At time: 120.25583696365356 and batch: 250, loss is 4.635683288574219 and perplexity is 103.09833985090579
At time: 121.52672791481018 and batch: 300, loss is 4.64432222366333 and perplexity is 103.99285799552669
At time: 122.79979848861694 and batch: 350, loss is 4.64814902305603 and perplexity is 104.391580229764
At time: 124.07170152664185 and batch: 400, loss is 4.599093046188354 and perplexity is 99.39412886646532
At time: 125.3428385257721 and batch: 450, loss is 4.592808637619019 and perplexity is 98.77145417168316
At time: 126.61379384994507 and batch: 500, loss is 4.597150707244873 and perplexity is 99.20125914903254
At time: 127.88485360145569 and batch: 550, loss is 4.566518545150757 and perplexity is 96.20858021810736
At time: 129.15909576416016 and batch: 600, loss is 4.5288676738739015 and perplexity is 92.65358758331287
At time: 130.42759203910828 and batch: 650, loss is 4.595983762741088 and perplexity is 99.08556430276155
At time: 131.69587874412537 and batch: 700, loss is 4.626900730133056 and perplexity is 102.19683720048565
At time: 132.96618819236755 and batch: 750, loss is 4.581446018218994 and perplexity is 97.65550379662228
At time: 134.23703742027283 and batch: 800, loss is 4.5786395931243895 and perplexity is 97.38182514907825
At time: 135.51140904426575 and batch: 850, loss is 4.569222927093506 and perplexity is 96.46911710201857
At time: 136.79894304275513 and batch: 900, loss is 4.547561006546021 and perplexity is 94.40188173120157
At time: 138.06909894943237 and batch: 950, loss is 4.610380601882935 and perplexity is 100.52240137182558
At time: 139.35063910484314 and batch: 1000, loss is 4.581929416656494 and perplexity is 97.70272172618806
At time: 140.62519192695618 and batch: 1050, loss is 4.523687753677368 and perplexity is 92.17489027099654
At time: 141.89330911636353 and batch: 1100, loss is 4.564300193786621 and perplexity is 95.99539233318286
At time: 143.17298579216003 and batch: 1150, loss is 4.515944881439209 and perplexity is 91.46394779232163
At time: 144.44377875328064 and batch: 1200, loss is 4.581804065704346 and perplexity is 97.69047536455481
At time: 145.71296644210815 and batch: 1250, loss is 4.563356370925903 and perplexity is 95.90483243035109
At time: 146.98746705055237 and batch: 1300, loss is 4.563826971054077 and perplexity is 95.94997587820833
At time: 148.2621829509735 and batch: 1350, loss is 4.45181755065918 and perplexity is 85.78271683033572
At time: 149.53084444999695 and batch: 1400, loss is 4.465944776535034 and perplexity is 87.00318929405519
At time: 150.79910039901733 and batch: 1450, loss is 4.419889831542969 and perplexity is 83.08713127305583
At time: 152.07218956947327 and batch: 1500, loss is 4.412305102348328 and perplexity is 82.45932177502625
At time: 153.3492500782013 and batch: 1550, loss is 4.412710552215576 and perplexity is 82.49276167473666
At time: 154.6191382408142 and batch: 1600, loss is 4.4777629184722905 and perplexity is 88.03750514145722
At time: 155.88800811767578 and batch: 1650, loss is 4.452172269821167 and perplexity is 85.81315100123547
At time: 157.16259670257568 and batch: 1700, loss is 4.459855794906616 and perplexity is 86.47503805621899
At time: 158.43629455566406 and batch: 1750, loss is 4.460543985366821 and perplexity is 86.53456983470663
At time: 159.70494484901428 and batch: 1800, loss is 4.420644197463989 and perplexity is 83.1498330204208
At time: 160.97691202163696 and batch: 1850, loss is 4.446394929885864 and perplexity is 85.31880862395921
At time: 162.2514135837555 and batch: 1900, loss is 4.555810632705689 and perplexity is 95.18388313888082
At time: 163.52701807022095 and batch: 1950, loss is 4.466554746627808 and perplexity is 87.05627482614806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470906386264535 and perplexity of 87.4359378414881
finished 3 epochs...
Completing Train Step...
At time: 167.5938868522644 and batch: 50, loss is 4.461274032592773 and perplexity is 86.59776722309559
At time: 168.8822033405304 and batch: 100, loss is 4.392733955383301 and perplexity is 80.86118793678696
At time: 170.15000438690186 and batch: 150, loss is 4.339537916183471 and perplexity is 76.67210221385304
At time: 171.4245593547821 and batch: 200, loss is 4.341239442825318 and perplexity is 76.8026728916975
At time: 172.69475507736206 and batch: 250, loss is 4.348289155960083 and perplexity is 77.34602268334677
At time: 173.96694016456604 and batch: 300, loss is 4.354285259246826 and perplexity is 77.81119062800481
At time: 175.24004650115967 and batch: 350, loss is 4.359644117355347 and perplexity is 78.22928902226414
At time: 176.51887559890747 and batch: 400, loss is 4.314260129928589 and perplexity is 74.75829155475144
At time: 177.78807020187378 and batch: 450, loss is 4.330945091247559 and perplexity is 76.0160947770354
At time: 179.06165409088135 and batch: 500, loss is 4.33853120803833 and perplexity is 76.59495462311875
At time: 180.3327386379242 and batch: 550, loss is 4.310215492248535 and perplexity is 74.4565320172065
At time: 181.60161447525024 and batch: 600, loss is 4.273983283042908 and perplexity is 71.80709469228758
At time: 182.8722801208496 and batch: 650, loss is 4.334551515579224 and perplexity is 76.2907360095772
At time: 184.14533829689026 and batch: 700, loss is 4.377429780960083 and perplexity is 79.63309565179362
At time: 185.41419744491577 and batch: 750, loss is 4.335334510803222 and perplexity is 76.35049468383322
At time: 186.68402433395386 and batch: 800, loss is 4.325170402526855 and perplexity is 75.57839051122204
At time: 187.9580533504486 and batch: 850, loss is 4.323400936126709 and perplexity is 75.44477533727826
At time: 189.23154854774475 and batch: 900, loss is 4.293860387802124 and perplexity is 73.24869175972009
At time: 190.5036816596985 and batch: 950, loss is 4.368242731094361 and perplexity is 78.90485275506433
At time: 191.77395844459534 and batch: 1000, loss is 4.342521352767944 and perplexity is 76.90119013332239
At time: 193.04540586471558 and batch: 1050, loss is 4.292161741256714 and perplexity is 73.12437373858745
At time: 194.32090425491333 and batch: 1100, loss is 4.324890069961548 and perplexity is 75.55720639656553
At time: 195.59278011322021 and batch: 1150, loss is 4.287688436508179 and perplexity is 72.79799666660792
At time: 196.8647701740265 and batch: 1200, loss is 4.3486851215362545 and perplexity is 77.37665511007616
At time: 198.1352264881134 and batch: 1250, loss is 4.342250461578369 and perplexity is 76.88036109977564
At time: 199.4111180305481 and batch: 1300, loss is 4.332424716949463 and perplexity is 76.12865339640369
At time: 200.68781924247742 and batch: 1350, loss is 4.216287388801574 and perplexity is 67.78137070322407
At time: 201.96242952346802 and batch: 1400, loss is 4.2410717821121215 and perplexity is 69.48228181202882
At time: 203.23415112495422 and batch: 1450, loss is 4.191357760429383 and perplexity is 66.11249497791515
At time: 204.50515174865723 and batch: 1500, loss is 4.186125783920288 and perplexity is 65.7674992489881
At time: 205.7739236354828 and batch: 1550, loss is 4.191501712799072 and perplexity is 66.12201271326714
At time: 207.04739499092102 and batch: 1600, loss is 4.265736217498779 and perplexity is 71.2173321237824
At time: 208.32168173789978 and batch: 1650, loss is 4.233855113983155 and perplexity is 68.98265622774889
At time: 209.59337091445923 and batch: 1700, loss is 4.244016394615174 and perplexity is 69.68718173517804
At time: 210.8674395084381 and batch: 1750, loss is 4.243323440551758 and perplexity is 69.63890844694394
At time: 212.13832688331604 and batch: 1800, loss is 4.199077539443969 and perplexity is 66.62484389500702
At time: 213.4078392982483 and batch: 1850, loss is 4.235374250411987 and perplexity is 69.0875299323459
At time: 214.68145442008972 and batch: 1900, loss is 4.343115129470825 and perplexity is 76.94686582768698
At time: 215.95005011558533 and batch: 1950, loss is 4.259147911071778 and perplexity is 70.74967275005831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421574934138808 and perplexity of 83.2272596458285
finished 4 epochs...
Completing Train Step...
At time: 219.9820520877838 and batch: 50, loss is 4.260111918449402 and perplexity is 70.8179088413172
At time: 221.27056980133057 and batch: 100, loss is 4.196531291007996 and perplexity is 66.45541628437529
At time: 222.54506993293762 and batch: 150, loss is 4.147393364906311 and perplexity is 63.26886632232224
At time: 223.81368327140808 and batch: 200, loss is 4.155367732048035 and perplexity is 63.7754124993197
At time: 225.08902382850647 and batch: 250, loss is 4.161041421890259 and perplexity is 64.13828284286981
At time: 226.35651016235352 and batch: 300, loss is 4.160688700675965 and perplexity is 64.1156638991879
At time: 227.63692116737366 and batch: 350, loss is 4.169062957763672 and perplexity is 64.65483939820471
At time: 228.9045226573944 and batch: 400, loss is 4.123618011474609 and perplexity is 61.78236770111182
At time: 230.18154215812683 and batch: 450, loss is 4.154912071228027 and perplexity is 63.74635916230034
At time: 231.45051550865173 and batch: 500, loss is 4.162442460060119 and perplexity is 64.22820600346293
At time: 232.76483988761902 and batch: 550, loss is 4.133129205703735 and perplexity is 62.37279518451782
At time: 234.0330491065979 and batch: 600, loss is 4.1031682538986205 and perplexity is 60.531764111725344
At time: 235.31074166297913 and batch: 650, loss is 4.159360585212707 and perplexity is 64.03056741601235
At time: 236.5810694694519 and batch: 700, loss is 4.203997750282287 and perplexity is 66.95345994121573
At time: 237.84955883026123 and batch: 750, loss is 4.159841003417969 and perplexity is 64.06133625665606
At time: 239.12767219543457 and batch: 800, loss is 4.150567560195923 and perplexity is 63.4700131305191
At time: 240.39868903160095 and batch: 850, loss is 4.153207492828369 and perplexity is 63.637791053130165
At time: 241.66945910453796 and batch: 900, loss is 4.119918246269226 and perplexity is 61.554209772425054
At time: 242.9403522014618 and batch: 950, loss is 4.204425930976868 and perplexity is 66.98213425865441
At time: 244.22069835662842 and batch: 1000, loss is 4.17447491645813 and perplexity is 65.00569727623171
At time: 245.4966688156128 and batch: 1050, loss is 4.131886539459228 and perplexity is 62.295334756064314
At time: 246.76830339431763 and batch: 1100, loss is 4.157277269363403 and perplexity is 63.89731037652275
At time: 248.04106211662292 and batch: 1150, loss is 4.12521538734436 and perplexity is 61.88113622868341
At time: 249.313330411911 and batch: 1200, loss is 4.182064547538757 and perplexity is 65.50094352758526
At time: 250.58910655975342 and batch: 1250, loss is 4.184567742347717 and perplexity is 65.66511053468317
At time: 251.85878729820251 and batch: 1300, loss is 4.165015969276428 and perplexity is 64.39371075621898
At time: 253.1365144252777 and batch: 1350, loss is 4.051505942344665 and perplexity is 57.48395942393642
At time: 254.41105127334595 and batch: 1400, loss is 4.084540038108826 and perplexity is 59.414603012091845
At time: 255.68416452407837 and batch: 1450, loss is 4.029976329803467 and perplexity is 56.259579556062235
At time: 256.95521664619446 and batch: 1500, loss is 4.024324669837951 and perplexity is 55.94251635326282
At time: 258.2266869544983 and batch: 1550, loss is 4.032742223739624 and perplexity is 56.41540298220222
At time: 259.50255727767944 and batch: 1600, loss is 4.1133597946166995 and perplexity is 61.15183039876119
At time: 260.7703547477722 and batch: 1650, loss is 4.081109857559204 and perplexity is 59.211149337383745
At time: 262.0404636859894 and batch: 1700, loss is 4.0878792572021485 and perplexity is 59.61333300572697
At time: 263.3132264614105 and batch: 1750, loss is 4.086512217521667 and perplexity is 59.53189489127199
At time: 264.5841987133026 and batch: 1800, loss is 4.040955395698547 and perplexity is 56.88066039221223
At time: 265.86000061035156 and batch: 1850, loss is 4.086484231948853 and perplexity is 59.530228880404955
At time: 267.1381390094757 and batch: 1900, loss is 4.18832193851471 and perplexity is 65.91209356224405
At time: 268.4061596393585 and batch: 1950, loss is 4.109969358444214 and perplexity is 60.94485009598714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.408549464026163 and perplexity of 82.15021519572994
finished 5 epochs...
Completing Train Step...
At time: 272.47313380241394 and batch: 50, loss is 4.10492781162262 and perplexity is 60.638367004283005
At time: 273.74995613098145 and batch: 100, loss is 4.049499535560608 and perplexity is 57.368738846101614
At time: 275.02772521972656 and batch: 150, loss is 4.006352477073669 and perplexity is 54.946087491805265
At time: 276.3002700805664 and batch: 200, loss is 4.013674602508545 and perplexity is 55.34988616475539
At time: 277.57137656211853 and batch: 250, loss is 4.0144611358642575 and perplexity is 55.39343782162904
At time: 278.8552350997925 and batch: 300, loss is 4.017555723190307 and perplexity is 55.56512316288714
At time: 280.1290383338928 and batch: 350, loss is 4.024929990768433 and perplexity is 55.97638978042817
At time: 281.4005482196808 and batch: 400, loss is 3.9803142023086546 and perplexity is 53.533852045158
At time: 282.67729234695435 and batch: 450, loss is 4.01663031578064 and perplexity is 55.5137265712544
At time: 283.94696044921875 and batch: 500, loss is 4.031660413742065 and perplexity is 56.35440523517491
At time: 285.21497988700867 and batch: 550, loss is 3.9990276527404784 and perplexity is 54.54508747338256
At time: 286.48947763442993 and batch: 600, loss is 3.978228139877319 and perplexity is 53.42229348711571
At time: 287.7575697898865 and batch: 650, loss is 4.025540175437928 and perplexity is 56.01055613815962
At time: 289.03042364120483 and batch: 700, loss is 4.073230257034302 and perplexity is 58.74642246951921
At time: 290.3051393032074 and batch: 750, loss is 4.024354481697083 and perplexity is 55.944184128539426
At time: 291.5770721435547 and batch: 800, loss is 4.0150052928924564 and perplexity is 55.42358875281235
At time: 292.84929490089417 and batch: 850, loss is 4.020081100463867 and perplexity is 55.705623395502045
At time: 294.1192729473114 and batch: 900, loss is 3.98809814453125 and perplexity is 53.95218247416572
At time: 295.4297046661377 and batch: 950, loss is 4.07694254398346 and perplexity is 58.96491134274127
At time: 296.703125 and batch: 1000, loss is 4.04759991645813 and perplexity is 57.259863537452695
At time: 297.97635316848755 and batch: 1050, loss is 4.004611339569092 and perplexity is 54.85050203600223
At time: 299.2464301586151 and batch: 1100, loss is 4.02959255695343 and perplexity is 56.23799279934466
At time: 300.52072978019714 and batch: 1150, loss is 4.000813488960266 and perplexity is 54.64258309589981
At time: 301.7939291000366 and batch: 1200, loss is 4.0570436239242555 and perplexity is 57.80317031555672
At time: 303.0642240047455 and batch: 1250, loss is 4.060483293533325 and perplexity is 58.00233646030003
At time: 304.33863377571106 and batch: 1300, loss is 4.038484911918641 and perplexity is 56.7403110800552
At time: 305.6135907173157 and batch: 1350, loss is 3.923206162452698 and perplexity is 50.562296113904566
At time: 306.8867335319519 and batch: 1400, loss is 3.963144073486328 and perplexity is 52.62251518424917
At time: 308.1583197116852 and batch: 1450, loss is 3.9094466733932496 and perplexity is 49.87134919301268
At time: 309.4363703727722 and batch: 1500, loss is 3.902182350158691 and perplexity is 49.51038027714356
At time: 310.7125651836395 and batch: 1550, loss is 3.91417649269104 and perplexity is 50.10779038409774
At time: 311.9823100566864 and batch: 1600, loss is 3.9928156566619872 and perplexity is 54.20730384540718
At time: 313.25498604774475 and batch: 1650, loss is 3.9633138227462767 and perplexity is 52.63144857545516
At time: 314.53321838378906 and batch: 1700, loss is 3.964409589767456 and perplexity is 52.68915199005667
At time: 315.8044822216034 and batch: 1750, loss is 3.963581666946411 and perplexity is 52.64554749177296
At time: 317.0776250362396 and batch: 1800, loss is 3.9207458114624023 and perplexity is 50.43804802821562
At time: 318.3493628501892 and batch: 1850, loss is 3.966681537628174 and perplexity is 52.808995083283186
At time: 319.621036529541 and batch: 1900, loss is 4.06805935382843 and perplexity is 58.44343444123507
At time: 320.89293599128723 and batch: 1950, loss is 3.9902695655822753 and perplexity is 54.06946266519469
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4174631517986915 and perplexity of 82.88574985751049
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 324.953248500824 and batch: 50, loss is 4.033040294647217 and perplexity is 56.432221278969294
At time: 326.22343397140503 and batch: 100, loss is 4.019960918426514 and perplexity is 55.6989289824725
At time: 327.511093378067 and batch: 150, loss is 3.9856126260757447 and perplexity is 53.81824984387435
At time: 328.7779805660248 and batch: 200, loss is 3.991473536491394 and perplexity is 54.13459992913242
At time: 330.04758739471436 and batch: 250, loss is 3.9804489707946775 and perplexity is 53.54106720752643
At time: 331.3238763809204 and batch: 300, loss is 3.9857693767547606 and perplexity is 53.82668655229343
At time: 332.600590467453 and batch: 350, loss is 3.9931246185302736 and perplexity is 54.224054422789614
At time: 333.87002873420715 and batch: 400, loss is 3.938844151496887 and perplexity is 51.359203521211576
At time: 335.14907908439636 and batch: 450, loss is 3.964453864097595 and perplexity is 52.69148481860845
At time: 336.42181730270386 and batch: 500, loss is 3.978713450431824 and perplexity is 53.44822618218718
At time: 337.69077253341675 and batch: 550, loss is 3.935949749946594 and perplexity is 51.21076428792132
At time: 338.9677324295044 and batch: 600, loss is 3.898540096282959 and perplexity is 49.33037890702581
At time: 340.2410192489624 and batch: 650, loss is 3.9471637487411497 and perplexity is 51.78827378030313
At time: 341.5121765136719 and batch: 700, loss is 3.9896435260772707 and perplexity is 54.035623638940734
At time: 342.7935881614685 and batch: 750, loss is 3.9357137060165406 and perplexity is 51.19867772439385
At time: 344.0625216960907 and batch: 800, loss is 3.9251933240890504 and perplexity is 50.66287146563218
At time: 345.3354654312134 and batch: 850, loss is 3.930921778678894 and perplexity is 50.9539242696874
At time: 346.61017370224 and batch: 900, loss is 3.880149326324463 and perplexity is 48.43144662131373
At time: 347.87938046455383 and batch: 950, loss is 3.974473738670349 and perplexity is 53.2221008009516
At time: 349.15867733955383 and batch: 1000, loss is 3.9310381841659545 and perplexity is 50.95985593129194
At time: 350.4346525669098 and batch: 1050, loss is 3.880503315925598 and perplexity is 48.448593884583
At time: 351.70444774627686 and batch: 1100, loss is 3.90099485874176 and perplexity is 49.45162201988331
At time: 352.97383642196655 and batch: 1150, loss is 3.8677716732025145 and perplexity is 47.835673716346804
At time: 354.24810671806335 and batch: 1200, loss is 3.910738482475281 and perplexity is 49.93581508468064
At time: 355.52728390693665 and batch: 1250, loss is 3.9047577142715455 and perplexity is 49.6380518635689
At time: 356.8027741909027 and batch: 1300, loss is 3.887691788673401 and perplexity is 48.79812005594971
At time: 358.07614398002625 and batch: 1350, loss is 3.760486602783203 and perplexity is 42.969329887916196
At time: 359.3539960384369 and batch: 1400, loss is 3.7914758062362672 and perplexity is 44.32176236653259
At time: 360.62694787979126 and batch: 1450, loss is 3.721893005371094 and perplexity is 41.34258180981389
At time: 361.9010968208313 and batch: 1500, loss is 3.720265474319458 and perplexity is 41.2753501997707
At time: 363.177330493927 and batch: 1550, loss is 3.73243905544281 and perplexity is 41.78088989483228
At time: 364.4525122642517 and batch: 1600, loss is 3.7970850372314455 and perplexity is 44.571071933556865
At time: 365.7309675216675 and batch: 1650, loss is 3.758009433746338 and perplexity is 42.863019323365776
At time: 367.00100922584534 and batch: 1700, loss is 3.7471278619766237 and perplexity is 42.39913079783084
At time: 368.27911615371704 and batch: 1750, loss is 3.7400004386901857 and perplexity is 42.098008632976075
At time: 369.5513665676117 and batch: 1800, loss is 3.6863249015808104 and perplexity is 39.89794830238318
At time: 370.8258321285248 and batch: 1850, loss is 3.7171263027191164 and perplexity is 41.1459829518611
At time: 372.0975604057312 and batch: 1900, loss is 3.8176493215560914 and perplexity is 45.49713339006846
At time: 373.36854910850525 and batch: 1950, loss is 3.7383690786361696 and perplexity is 42.02938761135401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351823389807413 and perplexity of 77.61986524144653
finished 7 epochs...
Completing Train Step...
At time: 377.43498706817627 and batch: 50, loss is 3.951281776428223 and perplexity is 52.00197904569224
At time: 378.7040710449219 and batch: 100, loss is 3.9130715799331663 and perplexity is 50.05245622257348
At time: 379.97505235671997 and batch: 150, loss is 3.8734395790100096 and perplexity is 48.10757162718656
At time: 381.2473614215851 and batch: 200, loss is 3.87794144153595 and perplexity is 48.32463352592775
At time: 382.52132773399353 and batch: 250, loss is 3.8648003053665163 and perplexity is 47.693747296275255
At time: 383.79535126686096 and batch: 300, loss is 3.868538851737976 and perplexity is 47.87238629920347
At time: 385.0658688545227 and batch: 350, loss is 3.8780442667007446 and perplexity is 48.32960276981098
At time: 386.33828043937683 and batch: 400, loss is 3.8284794187545774 and perplexity is 45.9925496276257
At time: 387.61440443992615 and batch: 450, loss is 3.8604041290283204 and perplexity is 47.48453737173034
At time: 388.88323402404785 and batch: 500, loss is 3.8774904203414917 and perplexity is 48.3028430063556
At time: 390.168181180954 and batch: 550, loss is 3.838198208808899 and perplexity is 46.44172072579237
At time: 391.44158148765564 and batch: 600, loss is 3.8023440170288088 and perplexity is 44.8060877304163
At time: 392.7186703681946 and batch: 650, loss is 3.8498612022399903 and perplexity is 46.98654115230221
At time: 393.99296855926514 and batch: 700, loss is 3.8929588270187376 and perplexity is 49.055819686631196
At time: 395.26748752593994 and batch: 750, loss is 3.8429912996292113 and perplexity is 46.664854433962745
At time: 396.5423266887665 and batch: 800, loss is 3.8341329145431517 and perplexity is 46.25330470760343
At time: 397.8191306591034 and batch: 850, loss is 3.845658507347107 and perplexity is 46.789485428353174
At time: 399.09345984458923 and batch: 900, loss is 3.7951870822906493 and perplexity is 44.486558274292385
At time: 400.36791491508484 and batch: 950, loss is 3.891780376434326 and perplexity is 48.998043876907396
At time: 401.64042353630066 and batch: 1000, loss is 3.850659976005554 and perplexity is 47.024087762336436
At time: 402.9126009941101 and batch: 1050, loss is 3.803826208114624 and perplexity is 44.87254815559828
At time: 404.1834194660187 and batch: 1100, loss is 3.826278734207153 and perplexity is 45.89144582395666
At time: 405.4571840763092 and batch: 1150, loss is 3.7943894910812377 and perplexity is 44.451090332815255
At time: 406.7325825691223 and batch: 1200, loss is 3.8407659912109375 and perplexity is 46.561126197017934
At time: 408.004723072052 and batch: 1250, loss is 3.8379995441436767 and perplexity is 46.43249531330413
At time: 409.27564239501953 and batch: 1300, loss is 3.8232439088821413 and perplexity is 45.75238442223207
At time: 410.5480225086212 and batch: 1350, loss is 3.698285894393921 and perplexity is 40.3780327952627
At time: 411.82273530960083 and batch: 1400, loss is 3.7321235847473146 and perplexity is 41.767711327273965
At time: 413.08995938301086 and batch: 1450, loss is 3.664147686958313 and perplexity is 39.022862290781596
At time: 414.3598585128784 and batch: 1500, loss is 3.663898000717163 and perplexity is 39.013120035281474
At time: 415.6346116065979 and batch: 1550, loss is 3.6833194875717163 and perplexity is 39.77821845861774
At time: 416.90311765670776 and batch: 1600, loss is 3.7512645149230956 and perplexity is 42.57488455269421
At time: 418.1718113422394 and batch: 1650, loss is 3.714295859336853 and perplexity is 41.029686239979256
At time: 419.45170998573303 and batch: 1700, loss is 3.7097531604766845 and perplexity is 40.843723437365234
At time: 420.7187554836273 and batch: 1750, loss is 3.706018671989441 and perplexity is 40.691477479740485
At time: 421.99238634109497 and batch: 1800, loss is 3.6534779262542725 and perplexity is 38.60871106443055
At time: 423.26318073272705 and batch: 1850, loss is 3.689732999801636 and perplexity is 40.0341564024593
At time: 424.535560131073 and batch: 1900, loss is 3.794207983016968 and perplexity is 44.443022833634494
At time: 425.80340933799744 and batch: 1950, loss is 3.7180083131790163 and perplexity is 41.182290148517374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358191485737645 and perplexity of 78.115733180971
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 429.8616888523102 and batch: 50, loss is 3.9201369524002074 and perplexity is 50.4073477126253
At time: 431.1525733470917 and batch: 100, loss is 3.911015191078186 and perplexity is 49.949634666218024
At time: 432.41988587379456 and batch: 150, loss is 3.894672322273254 and perplexity is 49.13994865758289
At time: 433.69015312194824 and batch: 200, loss is 3.9145299100875857 and perplexity is 50.12550247861876
At time: 434.95970940589905 and batch: 250, loss is 3.9046555042266844 and perplexity is 49.63297861533398
At time: 436.23638129234314 and batch: 300, loss is 3.9058880043029784 and perplexity is 49.69418897840416
At time: 437.50618958473206 and batch: 350, loss is 3.9172562980651855 and perplexity is 50.26235051159543
At time: 438.7792146205902 and batch: 400, loss is 3.8688090467453002 and perplexity is 47.88532292659757
At time: 440.04932928085327 and batch: 450, loss is 3.899949131011963 and perplexity is 49.39993611685476
At time: 441.3170049190521 and batch: 500, loss is 3.9051257801055907 and perplexity is 49.65632529723545
At time: 442.58505177497864 and batch: 550, loss is 3.8742715454101564 and perplexity is 48.14761216425421
At time: 443.85841965675354 and batch: 600, loss is 3.822461609840393 and perplexity is 45.71660637213267
At time: 445.13053464889526 and batch: 650, loss is 3.8609488868713377 and perplexity is 47.510411992947176
At time: 446.39821195602417 and batch: 700, loss is 3.899935359954834 and perplexity is 49.39925583219647
At time: 447.67049741744995 and batch: 750, loss is 3.8481747245788576 and perplexity is 46.90736618244978
At time: 448.9482765197754 and batch: 800, loss is 3.8387627744674684 and perplexity is 46.46794752911867
At time: 450.2156021595001 and batch: 850, loss is 3.8491873502731324 and perplexity is 46.954889844476575
At time: 451.48530197143555 and batch: 900, loss is 3.791698307991028 and perplexity is 44.331625133634034
At time: 452.75797939300537 and batch: 950, loss is 3.89551540851593 and perplexity is 49.18139534137134
At time: 454.0449116230011 and batch: 1000, loss is 3.852094135284424 and perplexity is 47.09157617713174
At time: 455.3149063587189 and batch: 1050, loss is 3.8007629919052124 and perplexity is 44.735304150078335
At time: 456.5857672691345 and batch: 1100, loss is 3.8208653926849365 and perplexity is 45.64369095065737
At time: 457.8560485839844 and batch: 1150, loss is 3.7912328147888186 and perplexity is 44.31099386572145
At time: 459.12820386886597 and batch: 1200, loss is 3.8258823442459104 and perplexity is 45.87325852039555
At time: 460.3966386318207 and batch: 1250, loss is 3.814947371482849 and perplexity is 45.37436833438598
At time: 461.66810750961304 and batch: 1300, loss is 3.8096643018722536 and perplexity is 45.13528449231417
At time: 462.94163727760315 and batch: 1350, loss is 3.6796769094467163 and perplexity is 39.63358676624724
At time: 464.21278715133667 and batch: 1400, loss is 3.7068029928207396 and perplexity is 40.72340517232465
At time: 465.48534536361694 and batch: 1450, loss is 3.625823893547058 and perplexity is 37.5556522762676
At time: 466.7542896270752 and batch: 1500, loss is 3.6196650457382202 and perplexity is 37.325063538885544
At time: 468.02108359336853 and batch: 1550, loss is 3.638874487876892 and perplexity is 38.04898801926556
At time: 469.27206802368164 and batch: 1600, loss is 3.7109749698638916 and perplexity is 40.89365718061579
At time: 470.5246124267578 and batch: 1650, loss is 3.6682206630706786 and perplexity is 39.18212559437366
At time: 471.78049635887146 and batch: 1700, loss is 3.6548388624191284 and perplexity is 38.661290826330905
At time: 473.03341603279114 and batch: 1750, loss is 3.6504367113113405 and perplexity is 38.49147204031193
At time: 474.3016972541809 and batch: 1800, loss is 3.59744610786438 and perplexity is 36.50488575253663
At time: 475.56207299232483 and batch: 1850, loss is 3.6257200050354004 and perplexity is 37.551750878107015
At time: 476.8304512500763 and batch: 1900, loss is 3.734969177246094 and perplexity is 41.88673447869667
At time: 478.08831000328064 and batch: 1950, loss is 3.6706978988647463 and perplexity is 39.279309282139764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330625170330668 and perplexity of 75.99177952798168
finished 9 epochs...
Completing Train Step...
At time: 481.929740190506 and batch: 50, loss is 3.91736918926239 and perplexity is 50.26802500881336
At time: 483.18975019454956 and batch: 100, loss is 3.880250782966614 and perplexity is 48.43636056253422
At time: 484.4363236427307 and batch: 150, loss is 3.852936429977417 and perplexity is 47.131257871324586
At time: 485.6948573589325 and batch: 200, loss is 3.8644197463989256 and perplexity is 47.67560046623211
At time: 486.9520561695099 and batch: 250, loss is 3.849341268539429 and perplexity is 46.96211761594434
At time: 488.22793984413147 and batch: 300, loss is 3.8475603246688843 and perplexity is 46.878555152543605
At time: 489.5104765892029 and batch: 350, loss is 3.8614280128479006 and perplexity is 47.533180919646746
At time: 490.78481221199036 and batch: 400, loss is 3.8130747652053834 and perplexity is 45.289479513882355
At time: 492.05423736572266 and batch: 450, loss is 3.847916760444641 and perplexity is 46.89526732494689
At time: 493.32807636260986 and batch: 500, loss is 3.8558664608001707 and perplexity is 47.26955642016615
At time: 494.6004116535187 and batch: 550, loss is 3.823456435203552 and perplexity is 45.76210904152128
At time: 495.8731646537781 and batch: 600, loss is 3.7762233877182005 and perplexity is 43.65087761095487
At time: 497.14713168144226 and batch: 650, loss is 3.8165082502365113 and perplexity is 45.44524752440035
At time: 498.4279866218567 and batch: 700, loss is 3.858347887992859 and perplexity is 47.38699803399848
At time: 499.70555782318115 and batch: 750, loss is 3.807705240249634 and perplexity is 45.046948244967595
At time: 500.98315477371216 and batch: 800, loss is 3.8000702142715452 and perplexity is 44.70432326459921
At time: 502.25175166130066 and batch: 850, loss is 3.811915578842163 and perplexity is 45.23701098311042
At time: 503.52358317375183 and batch: 900, loss is 3.754608392715454 and perplexity is 42.71748805512768
At time: 504.7982521057129 and batch: 950, loss is 3.859025363922119 and perplexity is 47.41911246167397
At time: 506.0737359523773 and batch: 1000, loss is 3.8171356678009034 and perplexity is 45.473769617610785
At time: 507.34739542007446 and batch: 1050, loss is 3.769274559020996 and perplexity is 43.348606571084645
At time: 508.6189227104187 and batch: 1100, loss is 3.790487914085388 and perplexity is 44.27799886574619
At time: 509.893492937088 and batch: 1150, loss is 3.761806011199951 and perplexity is 43.02606140122038
At time: 511.17374658584595 and batch: 1200, loss is 3.798648681640625 and perplexity is 44.64081975718311
At time: 512.4502127170563 and batch: 1250, loss is 3.7906317567825316 and perplexity is 44.284368390621005
At time: 513.7210352420807 and batch: 1300, loss is 3.7865239238739012 and perplexity is 44.10282872738888
At time: 514.9965801239014 and batch: 1350, loss is 3.658082866668701 and perplexity is 38.78691186549286
At time: 516.2669336795807 and batch: 1400, loss is 3.6878920221328735 and perplexity is 39.96052221477896
At time: 517.5442590713501 and batch: 1450, loss is 3.608906264305115 and perplexity is 36.925643825765086
At time: 518.8181104660034 and batch: 1500, loss is 3.606238760948181 and perplexity is 36.82727580374613
At time: 520.0949120521545 and batch: 1550, loss is 3.6280253410339354 and perplexity is 37.63842014371914
At time: 521.3649008274078 and batch: 1600, loss is 3.7026597309112548 and perplexity is 40.55502649819739
At time: 522.6426978111267 and batch: 1650, loss is 3.661029496192932 and perplexity is 38.90137107677793
At time: 523.9211201667786 and batch: 1700, loss is 3.651368989944458 and perplexity is 38.52737354975714
At time: 525.1969439983368 and batch: 1750, loss is 3.648891611099243 and perplexity is 38.432044781056675
At time: 526.4685716629028 and batch: 1800, loss is 3.5977935791015625 and perplexity is 36.517572354339244
At time: 527.7457747459412 and batch: 1850, loss is 3.628171696662903 and perplexity is 37.64392914149921
At time: 529.0242910385132 and batch: 1900, loss is 3.7385346269607544 and perplexity is 42.036346082022085
At time: 530.293612241745 and batch: 1950, loss is 3.6735325479507446 and perplexity is 39.39081029876105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330918422965116 and perplexity of 76.01406758538067
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 534.3120882511139 and batch: 50, loss is 3.9113093614578247 and perplexity is 49.96433053064863
At time: 535.6038632392883 and batch: 100, loss is 3.8900060653686523 and perplexity is 48.91118318718945
At time: 536.8789799213409 and batch: 150, loss is 3.870372052192688 and perplexity is 47.960226469255346
At time: 538.1509544849396 and batch: 200, loss is 3.890623254776001 and perplexity is 48.94137996896184
At time: 539.4220893383026 and batch: 250, loss is 3.882765254974365 and perplexity is 48.55830568487383
At time: 540.6940085887909 and batch: 300, loss is 3.885134229660034 and perplexity is 48.673475445082055
At time: 541.9623920917511 and batch: 350, loss is 3.8980712509155273 and perplexity is 49.30725600835712
At time: 543.2332811355591 and batch: 400, loss is 3.856601524353027 and perplexity is 47.304315321686055
At time: 544.5103635787964 and batch: 450, loss is 3.899453525543213 and perplexity is 49.375459304281435
At time: 545.7811768054962 and batch: 500, loss is 3.905655469894409 and perplexity is 49.68263471299493
At time: 547.0552456378937 and batch: 550, loss is 3.8756305837631224 and perplexity is 48.21309109990338
At time: 548.3307189941406 and batch: 600, loss is 3.819692463874817 and perplexity is 45.59018553569673
At time: 549.6481564044952 and batch: 650, loss is 3.849479036331177 and perplexity is 46.96858792887422
At time: 550.9177808761597 and batch: 700, loss is 3.8825719165802 and perplexity is 48.548918407519146
At time: 552.191967010498 and batch: 750, loss is 3.8276660537719724 and perplexity is 45.955156107649245
At time: 553.4651553630829 and batch: 800, loss is 3.818593602180481 and perplexity is 45.54011574210125
At time: 554.7379240989685 and batch: 850, loss is 3.82882972240448 and perplexity is 46.008663807891885
At time: 556.0122385025024 and batch: 900, loss is 3.7715311098098754 and perplexity is 43.446535352519334
At time: 557.2836480140686 and batch: 950, loss is 3.877648768424988 and perplexity is 48.31049227458057
At time: 558.5557849407196 and batch: 1000, loss is 3.8305827713012697 and perplexity is 46.08938998301535
At time: 559.8340766429901 and batch: 1050, loss is 3.7803284788131712 and perplexity is 43.83043674105886
At time: 561.1056079864502 and batch: 1100, loss is 3.801144909858704 and perplexity is 44.75239262887886
At time: 562.3816356658936 and batch: 1150, loss is 3.779489107131958 and perplexity is 43.79366214961763
At time: 563.6565413475037 and batch: 1200, loss is 3.8098828744888307 and perplexity is 45.14515090777045
At time: 564.9279413223267 and batch: 1250, loss is 3.798417887687683 and perplexity is 44.6305181147529
At time: 566.2000775337219 and batch: 1300, loss is 3.790817461013794 and perplexity is 44.292592948853915
At time: 567.4741742610931 and batch: 1350, loss is 3.657540211677551 and perplexity is 38.76586966402195
At time: 568.7420597076416 and batch: 1400, loss is 3.684658637046814 and perplexity is 39.8315231224772
At time: 570.0158045291901 and batch: 1450, loss is 3.605486469268799 and perplexity is 36.79958136903718
At time: 571.28728556633 and batch: 1500, loss is 3.599354510307312 and perplexity is 36.57461828338802
At time: 572.5585777759552 and batch: 1550, loss is 3.6216935873031617 and perplexity is 37.40085582960395
At time: 573.8315913677216 and batch: 1600, loss is 3.6986631631851195 and perplexity is 40.39326904078559
At time: 575.1036217212677 and batch: 1650, loss is 3.651950659751892 and perplexity is 38.54979027864591
At time: 576.3729319572449 and batch: 1700, loss is 3.6334495067596437 and perplexity is 37.8431318654734
At time: 577.6427958011627 and batch: 1750, loss is 3.631737060546875 and perplexity is 37.77838299293469
At time: 578.9193768501282 and batch: 1800, loss is 3.5817759084701537 and perplexity is 35.937305575509434
At time: 580.187789440155 and batch: 1850, loss is 3.6105292510986327 and perplexity is 36.985622317020336
At time: 581.4559361934662 and batch: 1900, loss is 3.7244756984710694 and perplexity is 41.44949501315694
At time: 582.7344615459442 and batch: 1950, loss is 3.6647847366333006 and perplexity is 39.0477297125715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31578851744186 and perplexity of 74.87263855508174
finished 11 epochs...
Completing Train Step...
At time: 586.7751846313477 and batch: 50, loss is 3.9182836961746217 and perplexity is 50.31401649170735
At time: 588.0426077842712 and batch: 100, loss is 3.8822692584991456 and perplexity is 48.53422690839926
At time: 589.3145296573639 and batch: 150, loss is 3.8515962314605714 and perplexity is 47.06813493750761
At time: 590.5952453613281 and batch: 200, loss is 3.8632592010498046 and perplexity is 47.62030286373871
At time: 591.8606617450714 and batch: 250, loss is 3.8540751361846923 and perplexity is 47.184957095236726
At time: 593.135710477829 and batch: 300, loss is 3.853061842918396 and perplexity is 47.13716911165153
At time: 594.4059875011444 and batch: 350, loss is 3.8657187843322753 and perplexity is 47.737573123434345
At time: 595.6739420890808 and batch: 400, loss is 3.82378445148468 and perplexity is 45.77712222049461
At time: 596.9550938606262 and batch: 450, loss is 3.8669609355926515 and perplexity is 47.79690725341
At time: 598.2266297340393 and batch: 500, loss is 3.874376950263977 and perplexity is 48.152687423749995
At time: 599.4960279464722 and batch: 550, loss is 3.8453591012954713 and perplexity is 46.77547847025166
At time: 600.77476978302 and batch: 600, loss is 3.792460265159607 and perplexity is 44.36541680546776
At time: 602.039760351181 and batch: 650, loss is 3.824900035858154 and perplexity is 45.8282189587685
At time: 603.3105080127716 and batch: 700, loss is 3.860883116722107 and perplexity is 47.507287328816325
At time: 604.5895450115204 and batch: 750, loss is 3.8074067544937136 and perplexity is 45.03350437906984
At time: 605.8529236316681 and batch: 800, loss is 3.8002655792236326 and perplexity is 44.713057775752794
At time: 607.1283843517303 and batch: 850, loss is 3.81077534198761 and perplexity is 45.18545947204941
At time: 608.403647184372 and batch: 900, loss is 3.754281587600708 and perplexity is 42.70353004244135
At time: 609.685996055603 and batch: 950, loss is 3.8611681699752807 and perplexity is 47.52083136591307
At time: 610.9594705104828 and batch: 1000, loss is 3.8148643922805787 and perplexity is 45.370603361707445
At time: 612.272524356842 and batch: 1050, loss is 3.7669425201416016 and perplexity is 43.247633717264684
At time: 613.5453457832336 and batch: 1100, loss is 3.788544702529907 and perplexity is 44.192040891010215
At time: 614.8200581073761 and batch: 1150, loss is 3.7677284812927248 and perplexity is 43.281638038531725
At time: 616.0929477214813 and batch: 1200, loss is 3.798442997932434 and perplexity is 44.63163881205656
At time: 617.3627452850342 and batch: 1250, loss is 3.7883456134796143 and perplexity is 44.18324361530842
At time: 618.6416945457458 and batch: 1300, loss is 3.781777234077454 and perplexity is 43.89398233691692
At time: 619.9154117107391 and batch: 1350, loss is 3.650172243118286 and perplexity is 38.481293616247456
At time: 621.1900472640991 and batch: 1400, loss is 3.678995451927185 and perplexity is 39.60658736103807
At time: 622.4611415863037 and batch: 1450, loss is 3.6015881729125976 and perplexity is 36.65640494845341
At time: 623.7360270023346 and batch: 1500, loss is 3.5984831476211547 and perplexity is 36.542762406782145
At time: 625.0098643302917 and batch: 1550, loss is 3.6227952432632446 and perplexity is 37.442081409374225
At time: 626.2790684700012 and batch: 1600, loss is 3.7011561679840086 and perplexity is 40.49409528227884
At time: 627.5500538349152 and batch: 1650, loss is 3.6549441146850588 and perplexity is 38.665360228947335
At time: 628.8235414028168 and batch: 1700, loss is 3.638307590484619 and perplexity is 38.02742425997576
At time: 630.0948014259338 and batch: 1750, loss is 3.6381464767456055 and perplexity is 38.02129801299271
At time: 631.3653967380524 and batch: 1800, loss is 3.5887277555465698 and perplexity is 36.18800663626731
At time: 632.6399064064026 and batch: 1850, loss is 3.6184694290161135 and perplexity is 37.28046373621264
At time: 633.9102323055267 and batch: 1900, loss is 3.732443904876709 and perplexity is 41.781092508987335
At time: 635.1913831233978 and batch: 1950, loss is 3.671575264930725 and perplexity is 39.31378673766211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314441769622093 and perplexity of 74.77187186124034
finished 12 epochs...
Completing Train Step...
At time: 639.2283556461334 and batch: 50, loss is 3.9134486055374147 and perplexity is 50.07133083800798
At time: 640.5065975189209 and batch: 100, loss is 3.8748524665832518 and perplexity is 48.17559025734093
At time: 641.7758553028107 and batch: 150, loss is 3.8421900510787963 and perplexity is 46.6274792623928
At time: 643.0485711097717 and batch: 200, loss is 3.8524874591827394 and perplexity is 47.11010206254946
At time: 644.3439998626709 and batch: 250, loss is 3.84239577293396 and perplexity is 46.63707254066794
At time: 645.6146366596222 and batch: 300, loss is 3.8408221912384035 and perplexity is 46.56374300712076
At time: 646.8931300640106 and batch: 350, loss is 3.853460636138916 and perplexity is 47.15597084388026
At time: 648.1702139377594 and batch: 400, loss is 3.8111613368988038 and perplexity is 45.20290419603633
At time: 649.4433715343475 and batch: 450, loss is 3.854626331329346 and perplexity is 47.21097238357996
At time: 650.7186379432678 and batch: 500, loss is 3.8621825408935546 and perplexity is 47.56905957177222
At time: 651.9928240776062 and batch: 550, loss is 3.832950406074524 and perplexity is 46.19864210894726
At time: 653.2632477283478 and batch: 600, loss is 3.7810017013549806 and perplexity is 43.859954313923154
At time: 654.5343115329742 and batch: 650, loss is 3.8138514804840087 and perplexity is 45.32467020938804
At time: 655.8066816329956 and batch: 700, loss is 3.850828433036804 and perplexity is 47.032009967815
At time: 657.0794994831085 and batch: 750, loss is 3.7977860450744627 and perplexity is 44.60232755849313
At time: 658.3554348945618 and batch: 800, loss is 3.79110520362854 and perplexity is 44.3053396491594
At time: 659.6264300346375 and batch: 850, loss is 3.801797699928284 and perplexity is 44.781616083729745
At time: 660.8969459533691 and batch: 900, loss is 3.7457388496398925 and perplexity is 42.34027876464824
At time: 662.1753528118134 and batch: 950, loss is 3.8528050899505617 and perplexity is 47.12506805714413
At time: 663.4467611312866 and batch: 1000, loss is 3.807000584602356 and perplexity is 45.0152168396641
At time: 664.7225866317749 and batch: 1050, loss is 3.7599030494689942 and perplexity is 42.944262307896835
At time: 665.9954705238342 and batch: 1100, loss is 3.78211528301239 and perplexity is 43.90882315921678
At time: 667.2650892734528 and batch: 1150, loss is 3.7614648294448854 and perplexity is 43.01138419801729
At time: 668.5352828502655 and batch: 1200, loss is 3.792402868270874 and perplexity is 44.362870441653165
At time: 669.8075459003448 and batch: 1250, loss is 3.783109354972839 and perplexity is 43.95249339121608
At time: 671.0863516330719 and batch: 1300, loss is 3.7769474601745605 and perplexity is 43.68249545455235
At time: 672.3594343662262 and batch: 1350, loss is 3.6460456800460816 and perplexity is 38.322825320621774
At time: 673.6340794563293 and batch: 1400, loss is 3.6752372694015505 and perplexity is 39.45801792690879
At time: 674.9150884151459 and batch: 1450, loss is 3.59868510723114 and perplexity is 36.550143314123105
At time: 676.1929469108582 and batch: 1500, loss is 3.596809606552124 and perplexity is 36.48165773796647
At time: 677.4647936820984 and batch: 1550, loss is 3.6219709491729737 and perplexity is 37.411230839659
At time: 678.7367243766785 and batch: 1600, loss is 3.7008814287185667 and perplexity is 40.48297149242715
At time: 680.0079779624939 and batch: 1650, loss is 3.6547357988357545 and perplexity is 38.65730646048552
At time: 681.2824544906616 and batch: 1700, loss is 3.63880419254303 and perplexity is 38.0463134469557
At time: 682.557379245758 and batch: 1750, loss is 3.6392402172088625 and perplexity is 38.06290619522345
At time: 683.8329455852509 and batch: 1800, loss is 3.5899495840072633 and perplexity is 36.23224919561635
At time: 685.1143472194672 and batch: 1850, loss is 3.6200551748275758 and perplexity is 37.33962797275404
At time: 686.3859896659851 and batch: 1900, loss is 3.7340389919281005 and perplexity is 41.84779016878658
At time: 687.6623034477234 and batch: 1950, loss is 3.6724707174301146 and perplexity is 39.34900613255106
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314442053506541 and perplexity of 74.77189308781495
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 691.7238519191742 and batch: 50, loss is 3.9125038814544677 and perplexity is 50.02404958328667
At time: 692.996839761734 and batch: 100, loss is 3.8804857969284057 and perplexity is 48.44774512123752
At time: 694.2671892642975 and batch: 150, loss is 3.849333572387695 and perplexity is 46.96175618975222
At time: 695.5395607948303 and batch: 200, loss is 3.8589597797393798 and perplexity is 47.41600261991628
At time: 696.8176486492157 and batch: 250, loss is 3.852261128425598 and perplexity is 47.09944080401151
At time: 698.091418504715 and batch: 300, loss is 3.852914752960205 and perplexity is 47.130236217309736
At time: 699.362496137619 and batch: 350, loss is 3.867081809043884 and perplexity is 47.802684979727786
At time: 700.637476682663 and batch: 400, loss is 3.826107802391052 and perplexity is 45.8836021861612
At time: 701.9066572189331 and batch: 450, loss is 3.8736547899246214 and perplexity is 48.11792601582496
At time: 703.1801853179932 and batch: 500, loss is 3.884170961380005 and perplexity is 48.626612404570885
At time: 704.4515814781189 and batch: 550, loss is 3.8615107583999633 and perplexity is 47.53711424167344
At time: 705.7203695774078 and batch: 600, loss is 3.807860016822815 and perplexity is 45.05392099684462
At time: 707.0012848377228 and batch: 650, loss is 3.8367818355560304 and perplexity is 46.37598847642796
At time: 708.2914552688599 and batch: 700, loss is 3.872864465713501 and perplexity is 48.07991227747329
At time: 709.5729558467865 and batch: 750, loss is 3.8184445810317995 and perplexity is 45.533329807378735
At time: 710.847650051117 and batch: 800, loss is 3.8076997709274294 and perplexity is 45.04670186936707
At time: 712.1179690361023 and batch: 850, loss is 3.816918873786926 and perplexity is 45.463912245112994
At time: 713.3953683376312 and batch: 900, loss is 3.7559708738327027 and perplexity is 42.7757294933993
At time: 714.6646182537079 and batch: 950, loss is 3.8635542678833006 and perplexity is 47.63435610893615
At time: 715.9421055316925 and batch: 1000, loss is 3.816267547607422 and perplexity is 45.43431005023381
At time: 717.2134339809418 and batch: 1050, loss is 3.770501947402954 and perplexity is 43.40184481248002
At time: 718.4840364456177 and batch: 1100, loss is 3.787664337158203 and perplexity is 44.15315286885055
At time: 719.75688123703 and batch: 1150, loss is 3.7656342124938966 and perplexity is 43.19108950400597
At time: 721.0322051048279 and batch: 1200, loss is 3.7958407545089723 and perplexity is 44.515647407868556
At time: 722.3029384613037 and batch: 1250, loss is 3.784814167022705 and perplexity is 44.027488039297324
At time: 723.5744099617004 and batch: 1300, loss is 3.7716242504119872 and perplexity is 43.45058217744067
At time: 724.8495721817017 and batch: 1350, loss is 3.638336009979248 and perplexity is 38.02850499551217
At time: 726.1258988380432 and batch: 1400, loss is 3.666741900444031 and perplexity is 39.12422735084212
At time: 727.4020237922668 and batch: 1450, loss is 3.5907269525527954 and perplexity is 36.26042595691994
At time: 728.6734457015991 and batch: 1500, loss is 3.589164481163025 and perplexity is 36.203814317332196
At time: 729.9455251693726 and batch: 1550, loss is 3.6159483861923216 and perplexity is 37.18659646206744
At time: 731.227169752121 and batch: 1600, loss is 3.6951845836639405 and perplexity is 40.253001948865546
At time: 732.5083923339844 and batch: 1650, loss is 3.648599920272827 and perplexity is 38.42083614096185
At time: 733.7827658653259 and batch: 1700, loss is 3.6285906791687013 and perplexity is 37.6597045938475
At time: 735.0606067180634 and batch: 1750, loss is 3.6293870115280153 and perplexity is 37.689706179289004
At time: 736.3400583267212 and batch: 1800, loss is 3.5793181848526 and perplexity is 35.84909005992809
At time: 737.6109414100647 and batch: 1850, loss is 3.6096478128433227 and perplexity is 36.9530361380758
At time: 738.8799910545349 and batch: 1900, loss is 3.7238791942596436 and perplexity is 41.42477758757725
At time: 740.1567766666412 and batch: 1950, loss is 3.6660948038101195 and perplexity is 39.09891838457559
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308494674327761 and perplexity of 74.3285160602593
finished 14 epochs...
Completing Train Step...
At time: 744.2098917961121 and batch: 50, loss is 3.9138479471206664 and perplexity is 50.091330395602064
At time: 745.5065224170685 and batch: 100, loss is 3.876849718093872 and perplexity is 48.27190517830132
At time: 746.7747373580933 and batch: 150, loss is 3.843686590194702 and perplexity is 46.69731134917659
At time: 748.052544593811 and batch: 200, loss is 3.850125060081482 and perplexity is 46.99894055539774
At time: 749.3185214996338 and batch: 250, loss is 3.842640175819397 and perplexity is 46.64847216875946
At time: 750.5958776473999 and batch: 300, loss is 3.8410368967056274 and perplexity is 46.57374157065352
At time: 751.8637087345123 and batch: 350, loss is 3.855087161064148 and perplexity is 47.232733617189886
At time: 753.1456451416016 and batch: 400, loss is 3.8143027353286745 and perplexity is 45.34512780184961
At time: 754.4159364700317 and batch: 450, loss is 3.8614729833602905 and perplexity is 47.535318559213245
At time: 755.6941151618958 and batch: 500, loss is 3.87250440120697 and perplexity is 48.06260352390596
At time: 756.9623384475708 and batch: 550, loss is 3.8487565469741822 and perplexity is 46.9346658796179
At time: 758.2384343147278 and batch: 600, loss is 3.7963884973526003 and perplexity is 44.540037214226835
At time: 759.508189201355 and batch: 650, loss is 3.8259816408157348 and perplexity is 45.87781380377155
At time: 760.7814226150513 and batch: 700, loss is 3.8629046201705934 and perplexity is 47.60342060812038
At time: 762.0532624721527 and batch: 750, loss is 3.8085177612304686 and perplexity is 45.08356470934749
At time: 763.3234622478485 and batch: 800, loss is 3.798378643989563 and perplexity is 44.62876668253963
At time: 764.5986042022705 and batch: 850, loss is 3.808065776824951 and perplexity is 45.06319224551853
At time: 765.8757827281952 and batch: 900, loss is 3.7482644939422607 and perplexity is 42.447350403992374
At time: 767.146299123764 and batch: 950, loss is 3.8561008644104002 and perplexity is 47.280637873560586
At time: 768.4180498123169 and batch: 1000, loss is 3.8094281482696535 and perplexity is 45.124626890741965
At time: 769.6963911056519 and batch: 1050, loss is 3.7637710094451906 and perplexity is 43.1106906573122
At time: 770.9903647899628 and batch: 1100, loss is 3.782109146118164 and perplexity is 43.9085536962403
At time: 772.2649507522583 and batch: 1150, loss is 3.7614469718933106 and perplexity is 43.010616126863624
At time: 773.5393302440643 and batch: 1200, loss is 3.7917700719833376 and perplexity is 44.33480666219743
At time: 774.8178434371948 and batch: 1250, loss is 3.781533331871033 and perplexity is 43.883277803259105
At time: 776.0880575180054 and batch: 1300, loss is 3.769856629371643 and perplexity is 43.37384585451822
At time: 777.3620808124542 and batch: 1350, loss is 3.6372958755493165 and perplexity is 37.98897080214963
At time: 778.6320388317108 and batch: 1400, loss is 3.6666878271102905 and perplexity is 39.12211183063637
At time: 779.9018726348877 and batch: 1450, loss is 3.5915446519851684 and perplexity is 36.29008821239449
At time: 781.179477930069 and batch: 1500, loss is 3.5909387922286986 and perplexity is 36.26810816747253
At time: 782.4470520019531 and batch: 1550, loss is 3.6188641738891603 and perplexity is 37.295182913106
At time: 783.7246236801147 and batch: 1600, loss is 3.6989865684509278 and perplexity is 40.40633454930985
At time: 784.9997487068176 and batch: 1650, loss is 3.6527064275741576 and perplexity is 38.578935981998676
At time: 786.2681000232697 and batch: 1700, loss is 3.633031487464905 and perplexity is 37.82731601207653
At time: 787.5394444465637 and batch: 1750, loss is 3.6345460748672487 and perplexity is 37.88465219774451
At time: 788.812335729599 and batch: 1800, loss is 3.5845657920837404 and perplexity is 36.037706463725314
At time: 790.078727722168 and batch: 1850, loss is 3.615218997001648 and perplexity is 37.15948284995992
At time: 791.3520843982697 and batch: 1900, loss is 3.7289944791793825 and perplexity is 41.637220016217306
At time: 792.6242554187775 and batch: 1950, loss is 3.6705183601379394 and perplexity is 39.27225775799117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307185967023982 and perplexity of 74.23130541242911
finished 15 epochs...
Completing Train Step...
At time: 796.6621468067169 and batch: 50, loss is 3.9136792469024657 and perplexity is 50.08288068998799
At time: 797.9486906528473 and batch: 100, loss is 3.874710268974304 and perplexity is 48.16874029063268
At time: 799.221373796463 and batch: 150, loss is 3.8405498933792113 and perplexity is 46.551065525687804
At time: 800.4930739402771 and batch: 200, loss is 3.8456835174560546 and perplexity is 46.79065565311502
At time: 801.765364408493 and batch: 250, loss is 3.837965431213379 and perplexity is 46.430911391844205
At time: 803.0534422397614 and batch: 300, loss is 3.8355494689941407 and perplexity is 46.318871460733924
At time: 804.3265452384949 and batch: 350, loss is 3.8492330503463745 and perplexity is 46.957035735414856
At time: 805.6008269786835 and batch: 400, loss is 3.8080950021743774 and perplexity is 45.06450925230307
At time: 806.8732929229736 and batch: 450, loss is 3.855121040344238 and perplexity is 47.23433385530883
At time: 808.1427819728851 and batch: 500, loss is 3.8662835121154786 and perplexity is 47.76453947088598
At time: 809.4161746501923 and batch: 550, loss is 3.8421522331237794 and perplexity is 46.625715939822335
At time: 810.6900506019592 and batch: 600, loss is 3.790470013618469 and perplexity is 44.277206275986146
At time: 811.9626858234406 and batch: 650, loss is 3.82064151763916 and perplexity is 45.633473611002756
At time: 813.2370126247406 and batch: 700, loss is 3.8581513023376464 and perplexity is 47.37768334553847
At time: 814.5043609142303 and batch: 750, loss is 3.8039033031463623 and perplexity is 44.87600773947916
At time: 815.7824687957764 and batch: 800, loss is 3.794105439186096 and perplexity is 44.43846570947408
At time: 817.0541138648987 and batch: 850, loss is 3.803836236000061 and perplexity is 44.8729981346266
At time: 818.3280596733093 and batch: 900, loss is 3.7445720529556272 and perplexity is 42.29090507790328
At time: 819.6128718852997 and batch: 950, loss is 3.8524698209762573 and perplexity is 47.10927113216997
At time: 820.8822677135468 and batch: 1000, loss is 3.806074619293213 and perplexity is 44.97355360281989
At time: 822.1552321910858 and batch: 1050, loss is 3.760687780380249 and perplexity is 42.97797522404454
At time: 823.4279541969299 and batch: 1100, loss is 3.779522066116333 and perplexity is 43.79510556803082
At time: 824.6985237598419 and batch: 1150, loss is 3.759338583946228 and perplexity is 42.920028592615225
At time: 825.9696321487427 and batch: 1200, loss is 3.7897774600982665 and perplexity is 44.24655255681075
At time: 827.2431621551514 and batch: 1250, loss is 3.7800262117385866 and perplexity is 43.81719024525799
At time: 828.5186350345612 and batch: 1300, loss is 3.768935451507568 and perplexity is 43.333909225030844
At time: 829.7878823280334 and batch: 1350, loss is 3.636568613052368 and perplexity is 37.96135289233986
At time: 831.0602757930756 and batch: 1400, loss is 3.6664535903930666 and perplexity is 39.112949068759825
At time: 832.3385212421417 and batch: 1450, loss is 3.591748766899109 and perplexity is 36.29749631665342
At time: 833.6123356819153 and batch: 1500, loss is 3.5916916847229006 and perplexity is 36.29542443570704
At time: 834.8942332267761 and batch: 1550, loss is 3.620165319442749 and perplexity is 37.343740958215264
At time: 836.1709597110748 and batch: 1600, loss is 3.700658664703369 and perplexity is 40.473954347535354
At time: 837.446704864502 and batch: 1650, loss is 3.654525918960571 and perplexity is 38.64919392118982
At time: 838.7198996543884 and batch: 1700, loss is 3.6350955533981324 and perplexity is 37.90547472101801
At time: 839.9985773563385 and batch: 1750, loss is 3.63693772315979 and perplexity is 37.9753673976725
At time: 841.2793979644775 and batch: 1800, loss is 3.5869544172286987 and perplexity is 36.123889924565155
At time: 842.5483002662659 and batch: 1850, loss is 3.617803120613098 and perplexity is 37.255631723764886
At time: 843.8211793899536 and batch: 1900, loss is 3.731274585723877 and perplexity is 41.73226562995619
At time: 845.0898716449738 and batch: 1950, loss is 3.6723911428451537 and perplexity is 39.34587507629734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306733455214389 and perplexity of 74.19772246900078
finished 16 epochs...
Completing Train Step...
At time: 849.1100080013275 and batch: 50, loss is 3.9126571369171144 and perplexity is 50.031716629642375
At time: 850.3969480991364 and batch: 100, loss is 3.8726481437683105 and perplexity is 48.0695126621979
At time: 851.6715683937073 and batch: 150, loss is 3.837942748069763 and perplexity is 46.42985820475773
At time: 852.9484314918518 and batch: 200, loss is 3.842428297996521 and perplexity is 46.63858943903846
At time: 854.2163808345795 and batch: 250, loss is 3.8344572448730467 and perplexity is 46.26830849013732
At time: 855.4921629428864 and batch: 300, loss is 3.8316771602630615 and perplexity is 46.13985731307595
At time: 856.7683067321777 and batch: 350, loss is 3.845179696083069 and perplexity is 46.76708745831963
At time: 858.0358848571777 and batch: 400, loss is 3.803856706619263 and perplexity is 44.87391672208586
At time: 859.3107697963715 and batch: 450, loss is 3.850841007232666 and perplexity is 47.03260136123825
At time: 860.5837380886078 and batch: 500, loss is 3.8621009683609007 and perplexity is 47.5651794013668
At time: 861.8582491874695 and batch: 550, loss is 3.8378121995925905 and perplexity is 46.42379725310638
At time: 863.1304225921631 and batch: 600, loss is 3.7865570068359373 and perplexity is 44.104287803732504
At time: 864.4045007228851 and batch: 650, loss is 3.817081904411316 and perplexity is 45.47132485933866
At time: 865.6710512638092 and batch: 700, loss is 3.8549871492385863 and perplexity is 47.22801002148621
At time: 866.9854166507721 and batch: 750, loss is 3.800857787132263 and perplexity is 44.73954504439752
At time: 868.2574377059937 and batch: 800, loss is 3.7912488842010497 and perplexity is 44.311705923069404
At time: 869.529018163681 and batch: 850, loss is 3.8009720277786254 and perplexity is 44.74465641089869
At time: 870.8047108650208 and batch: 900, loss is 3.742020010948181 and perplexity is 42.18311451313879
At time: 872.0800507068634 and batch: 950, loss is 3.8499474477767945 and perplexity is 46.99059370652131
At time: 873.3538160324097 and batch: 1000, loss is 3.8037742662429808 and perplexity is 44.870217451992744
At time: 874.6271369457245 and batch: 1050, loss is 3.7586109590530397 and perplexity is 42.88881027038642
At time: 875.8965764045715 and batch: 1100, loss is 3.777747325897217 and perplexity is 43.71744956277947
At time: 877.1706080436707 and batch: 1150, loss is 3.7577853441238402 and perplexity is 42.853415241674206
At time: 878.4436719417572 and batch: 1200, loss is 3.7882917022705076 and perplexity is 44.18086170742921
At time: 879.7155091762543 and batch: 1250, loss is 3.778869004249573 and perplexity is 43.766513991683894
At time: 880.9857912063599 and batch: 1300, loss is 3.7680661344528197 and perplexity is 43.29625468792958
At time: 882.2572710514069 and batch: 1350, loss is 3.6358327150344847 and perplexity is 37.933427484376644
At time: 883.5278289318085 and batch: 1400, loss is 3.665979905128479 and perplexity is 39.094426228475974
At time: 884.7987973690033 and batch: 1450, loss is 3.5915591526031494 and perplexity is 36.29061444491549
At time: 886.0714526176453 and batch: 1500, loss is 3.591876983642578 and perplexity is 36.30215056179692
At time: 887.3465864658356 and batch: 1550, loss is 3.6206612730026246 and perplexity is 37.36226631296065
At time: 888.6168658733368 and batch: 1600, loss is 3.7013720989227297 and perplexity is 40.50284015439605
At time: 889.894024848938 and batch: 1650, loss is 3.65531379699707 and perplexity is 38.67965677113809
At time: 891.1651804447174 and batch: 1700, loss is 3.636061706542969 and perplexity is 37.94211491179386
At time: 892.4355578422546 and batch: 1750, loss is 3.638101191520691 and perplexity is 38.01957624894619
At time: 893.704745054245 and batch: 1800, loss is 3.588079767227173 and perplexity is 36.16456482649446
At time: 894.976569890976 and batch: 1850, loss is 3.619069905281067 and perplexity is 37.30285649231913
At time: 896.252445936203 and batch: 1900, loss is 3.73233980178833 and perplexity is 41.77674319461376
At time: 897.5285749435425 and batch: 1950, loss is 3.673169755935669 and perplexity is 39.376522219274584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3065622728924415 and perplexity of 74.18502221764558
finished 17 epochs...
Completing Train Step...
At time: 901.5746395587921 and batch: 50, loss is 3.9112729358673097 and perplexity is 49.962510583550895
At time: 902.8465881347656 and batch: 100, loss is 3.8706327724456786 and perplexity is 47.97273230182496
At time: 904.1239113807678 and batch: 150, loss is 3.835603394508362 and perplexity is 46.32136929704353
At time: 905.3971707820892 and batch: 200, loss is 3.839721384048462 and perplexity is 46.512513506102685
At time: 906.6704287528992 and batch: 250, loss is 3.8315270137786865 and perplexity is 46.13293009577251
At time: 907.9463822841644 and batch: 300, loss is 3.8285690212249754 and perplexity is 45.99667085832571
At time: 909.218204498291 and batch: 350, loss is 3.841974148750305 and perplexity is 46.617413367712516
At time: 910.4913189411163 and batch: 400, loss is 3.8005581426620485 and perplexity is 44.72614109543493
At time: 911.7620775699615 and batch: 450, loss is 3.8475488567352296 and perplexity is 46.87801755546586
At time: 913.0388171672821 and batch: 500, loss is 3.858890109062195 and perplexity is 47.4126992299804
At time: 914.3114008903503 and batch: 550, loss is 3.8345293045043944 and perplexity is 46.27164268751928
At time: 915.5843367576599 and batch: 600, loss is 3.7835669994354246 and perplexity is 43.97261260980674
At time: 916.8566422462463 and batch: 650, loss is 3.8143053388595582 and perplexity is 45.34524585944395
At time: 918.1226906776428 and batch: 700, loss is 3.852497935295105 and perplexity is 47.11059559585737
At time: 919.3987994194031 and batch: 750, loss is 3.798455777168274 and perplexity is 44.632209173939245
At time: 920.6730098724365 and batch: 800, loss is 3.78896354675293 and perplexity is 44.210554348897794
At time: 921.9503421783447 and batch: 850, loss is 3.798678698539734 and perplexity is 44.64215975627711
At time: 923.2270820140839 and batch: 900, loss is 3.7399349451065063 and perplexity is 42.09525157381076
At time: 924.4967670440674 and batch: 950, loss is 3.8478831958770754 and perplexity is 46.893693331993596
At time: 925.768266916275 and batch: 1000, loss is 3.8019044399261475 and perplexity is 44.786396328451964
At time: 927.0403478145599 and batch: 1050, loss is 3.7569172382354736 and perplexity is 42.81623008222948
At time: 928.3122918605804 and batch: 1100, loss is 3.776266784667969 and perplexity is 43.65277196700224
At time: 929.6246905326843 and batch: 1150, loss is 3.756427035331726 and perplexity is 42.79524658542137
At time: 930.9012639522552 and batch: 1200, loss is 3.786978507041931 and perplexity is 44.12288168851483
At time: 932.1742506027222 and batch: 1250, loss is 3.7777958917617798 and perplexity is 43.71957279007174
At time: 933.4506397247314 and batch: 1300, loss is 3.767172441482544 and perplexity is 43.25757841440677
At time: 934.7236135005951 and batch: 1350, loss is 3.6350570011138914 and perplexity is 37.90401340655096
At time: 935.996798992157 and batch: 1400, loss is 3.6653641653060913 and perplexity is 39.070361642935836
At time: 937.2563049793243 and batch: 1450, loss is 3.5911545085906984 and perplexity is 36.27593263572561
At time: 938.5162739753723 and batch: 1500, loss is 3.5917484283447267 and perplexity is 36.29748402797905
At time: 939.7751910686493 and batch: 1550, loss is 3.6207369136810303 and perplexity is 37.36509252701836
At time: 941.0285198688507 and batch: 1600, loss is 3.7016002368927 and perplexity is 40.51208144423138
At time: 942.280757188797 and batch: 1650, loss is 3.6555758810043333 and perplexity is 38.689795419114944
At time: 943.5282075405121 and batch: 1700, loss is 3.636468186378479 and perplexity is 37.957540751356085
At time: 944.7760932445526 and batch: 1750, loss is 3.6386514568328856 and perplexity is 38.04050286000636
At time: 946.0303778648376 and batch: 1800, loss is 3.5885844945907595 and perplexity is 36.18282267918592
At time: 947.2871661186218 and batch: 1850, loss is 3.619682960510254 and perplexity is 37.325732214879565
At time: 948.5407259464264 and batch: 1900, loss is 3.732810688018799 and perplexity is 41.79641992012391
At time: 949.7891376018524 and batch: 1950, loss is 3.6734201765060424 and perplexity is 39.38638414519108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306524800145349 and perplexity of 74.18224235315485
finished 18 epochs...
Completing Train Step...
At time: 953.6857995986938 and batch: 50, loss is 3.909751629829407 and perplexity is 49.886560101143225
At time: 954.9636991024017 and batch: 100, loss is 3.868689160346985 and perplexity is 47.87958247180783
At time: 956.2382173538208 and batch: 150, loss is 3.83345148563385 and perplexity is 46.22179710493979
At time: 957.5155665874481 and batch: 200, loss is 3.837335238456726 and perplexity is 46.40166018571745
At time: 958.7843418121338 and batch: 250, loss is 3.8289528608322145 and perplexity is 46.01432959124602
At time: 960.0557053089142 and batch: 300, loss is 3.825904564857483 and perplexity is 45.87427786357987
At time: 961.3474113941193 and batch: 350, loss is 3.8392472076416015 and perplexity is 46.490463597760616
At time: 962.6203339099884 and batch: 400, loss is 3.7977837467193605 and perplexity is 44.602225046623815
At time: 963.8908383846283 and batch: 450, loss is 3.8448029804229735 and perplexity is 46.74947288214869
At time: 965.1627979278564 and batch: 500, loss is 3.8562125158309937 and perplexity is 47.285917118657856
At time: 966.4391491413116 and batch: 550, loss is 3.831812081336975 and perplexity is 46.14608297215172
At time: 967.7110629081726 and batch: 600, loss is 3.781071176528931 and perplexity is 43.86300159773263
At time: 968.9837307929993 and batch: 650, loss is 3.8119441938400267 and perplexity is 45.23830545860368
At time: 970.255001783371 and batch: 700, loss is 3.850358819961548 and perplexity is 47.00992830630284
At time: 971.5261611938477 and batch: 750, loss is 3.7963787364959716 and perplexity is 44.5396024674311
At time: 972.7969045639038 and batch: 800, loss is 3.7869662189483644 and perplexity is 44.12233950574741
At time: 974.068615436554 and batch: 850, loss is 3.7966816425323486 and perplexity is 44.55309582538294
At time: 975.3372874259949 and batch: 900, loss is 3.7380904722213746 and perplexity is 42.017679585396884
At time: 976.6148602962494 and batch: 950, loss is 3.846055245399475 and perplexity is 46.80805228051818
At time: 977.8892338275909 and batch: 1000, loss is 3.800248770713806 and perplexity is 44.71230622219805
At time: 979.1596086025238 and batch: 1050, loss is 3.7554042768478393 and perplexity is 42.751499758938465
At time: 980.4442574977875 and batch: 1100, loss is 3.774918761253357 and perplexity is 43.59396665265324
At time: 981.7131562232971 and batch: 1150, loss is 3.7551551961898806 and perplexity is 42.740852513316305
At time: 982.9830298423767 and batch: 1200, loss is 3.785741758346558 and perplexity is 44.06834650226185
At time: 984.2573325634003 and batch: 1250, loss is 3.776745767593384 and perplexity is 43.67368590773188
At time: 985.527911901474 and batch: 1300, loss is 3.7662560987472533 and perplexity is 43.21795780248283
At time: 986.7991926670074 and batch: 1350, loss is 3.6342447662353514 and perplexity is 37.873238944563106
At time: 988.0778369903564 and batch: 1400, loss is 3.6646623945236207 and perplexity is 39.04295282315358
At time: 989.3486144542694 and batch: 1450, loss is 3.5906229400634766 and perplexity is 36.25665461588908
At time: 990.6200244426727 and batch: 1500, loss is 3.591428518295288 and perplexity is 36.28587395525765
At time: 991.9000434875488 and batch: 1550, loss is 3.620564775466919 and perplexity is 37.35866112028197
At time: 993.1761798858643 and batch: 1600, loss is 3.7015496587753294 and perplexity is 40.51003247123819
At time: 994.4456887245178 and batch: 1650, loss is 3.6555381870269774 and perplexity is 38.688337074328096
At time: 995.72034740448 and batch: 1700, loss is 3.6365574407577514 and perplexity is 37.96092877929047
At time: 996.9925315380096 and batch: 1750, loss is 3.6388571882247924 and perplexity is 38.048329790703654
At time: 998.2616987228394 and batch: 1800, loss is 3.588748197555542 and perplexity is 36.188746399384755
At time: 999.5321035385132 and batch: 1850, loss is 3.6199346208572387 and perplexity is 37.33512680367337
At time: 1000.815137386322 and batch: 1900, loss is 3.732958607673645 and perplexity is 41.80260288941237
At time: 1002.0834429264069 and batch: 1950, loss is 3.673390245437622 and perplexity is 39.38520528627475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306559717932413 and perplexity of 74.18483267812124
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 1006.1494588851929 and batch: 50, loss is 3.9096001052856444 and perplexity is 49.879001635545
At time: 1007.4210956096649 and batch: 100, loss is 3.8705265140533447 and perplexity is 47.96763506723148
At time: 1008.6948323249817 and batch: 150, loss is 3.8359789276123046 and perplexity is 46.33876777128158
At time: 1009.9684989452362 and batch: 200, loss is 3.8393101119995117 and perplexity is 46.49338814250452
At time: 1011.2427871227264 and batch: 250, loss is 3.8307903480529784 and perplexity is 46.09895806189727
At time: 1012.5132126808167 and batch: 300, loss is 3.827763442993164 and perplexity is 45.959631862453904
At time: 1013.7855515480042 and batch: 350, loss is 3.8419861078262327 and perplexity is 46.61797087223215
At time: 1015.056086063385 and batch: 400, loss is 3.8009844827651977 and perplexity is 44.745213708464036
At time: 1016.3267469406128 and batch: 450, loss is 3.8491985988616944 and perplexity is 46.95541802368404
At time: 1017.6017408370972 and batch: 500, loss is 3.8619156455993653 and perplexity is 47.55636530771853
At time: 1018.8753795623779 and batch: 550, loss is 3.839641127586365 and perplexity is 46.50878072611731
At time: 1020.1468667984009 and batch: 600, loss is 3.788948540687561 and perplexity is 44.209890927406924
At time: 1021.4168457984924 and batch: 650, loss is 3.8187257862091064 and perplexity is 45.54613581593416
At time: 1022.6925921440125 and batch: 700, loss is 3.8581843328475953 and perplexity is 47.37924828042473
At time: 1023.9685401916504 and batch: 750, loss is 3.8037207651138307 and perplexity is 44.867816908910314
At time: 1025.2541790008545 and batch: 800, loss is 3.7925115442276 and perplexity is 44.36769188102405
At time: 1026.5281286239624 and batch: 850, loss is 3.8022355699539183 and perplexity is 44.80122890473213
At time: 1027.8032031059265 and batch: 900, loss is 3.742011113166809 and perplexity is 42.182739178678084
At time: 1029.080060005188 and batch: 950, loss is 3.8498414945602417 and perplexity is 46.98561516572124
At time: 1030.3529646396637 and batch: 1000, loss is 3.8039208316802977 and perplexity is 44.87679435699781
At time: 1031.6241474151611 and batch: 1050, loss is 3.7592581272125245 and perplexity is 42.91657552621729
At time: 1032.898708820343 and batch: 1100, loss is 3.776860446929932 and perplexity is 43.678694664251324
At time: 1034.1775443553925 and batch: 1150, loss is 3.7552988004684447 and perplexity is 42.74699072333276
At time: 1035.4494061470032 and batch: 1200, loss is 3.786962184906006 and perplexity is 44.122161514719906
At time: 1036.7221765518188 and batch: 1250, loss is 3.776721558570862 and perplexity is 43.67262862328407
At time: 1037.9914619922638 and batch: 1300, loss is 3.7632077884674073 and perplexity is 43.08641664842447
At time: 1039.2630274295807 and batch: 1350, loss is 3.6298823738098145 and perplexity is 37.708380863127445
At time: 1040.5420234203339 and batch: 1400, loss is 3.6598381662368773 and perplexity is 38.85505430284067
At time: 1041.8156127929688 and batch: 1450, loss is 3.58494695186615 and perplexity is 36.05144520624128
At time: 1043.086296081543 and batch: 1500, loss is 3.5847185134887694 and perplexity is 36.04321061318049
At time: 1044.3585050106049 and batch: 1550, loss is 3.6144267082214356 and perplexity is 37.13005346844325
At time: 1045.6312096118927 and batch: 1600, loss is 3.6946338033676147 and perplexity is 40.230837492957264
At time: 1046.8991031646729 and batch: 1650, loss is 3.648876552581787 and perplexity is 38.43146605579685
At time: 1048.1705963611603 and batch: 1700, loss is 3.630517168045044 and perplexity is 37.73232552508181
At time: 1049.4436781406403 and batch: 1750, loss is 3.6327231979370116 and perplexity is 37.81565604409706
At time: 1050.7203967571259 and batch: 1800, loss is 3.5833688163757325 and perplexity is 35.99459601074561
At time: 1051.9968039989471 and batch: 1850, loss is 3.6147168016433717 and perplexity is 37.14082621518652
At time: 1053.2682769298553 and batch: 1900, loss is 3.726807026863098 and perplexity is 41.546240126212574
At time: 1054.5382091999054 and batch: 1950, loss is 3.6697292947769165 and perplexity is 39.24128160245806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304929369549418 and perplexity of 74.06398409553563
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
5471.0660400390625


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}, {'best_accuracy': -75.4437429826347, 'params': {'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}}, {'best_accuracy': -76.45059048557374, 'params': {'rnn_dropout': 0.9151261589557308, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.09244881843629082}}, {'best_accuracy': -74.06398409553563, 'params': {'rnn_dropout': 0.35399849893854385, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7881908157668892}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.061622740297387506, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7177030139734627}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.0469508171081543 and batch: 50, loss is 7.639783401489257 and perplexity is 2079.293395939954
At time: 3.533572196960449 and batch: 100, loss is 6.988886003494263 and perplexity is 1084.5126596889327
At time: 5.020840883255005 and batch: 150, loss is 6.687394323348999 and perplexity is 802.2291765550389
At time: 6.510563611984253 and batch: 200, loss is 6.472271499633789 and perplexity is 646.9516095306806
At time: 8.004455089569092 and batch: 250, loss is 6.395927410125733 and perplexity is 599.3989541936685
At time: 9.49658751487732 and batch: 300, loss is 6.322002573013306 and perplexity is 556.686682683824
At time: 10.99008059501648 and batch: 350, loss is 6.25878119468689 and perplexity is 522.5816265433499
At time: 12.482736825942993 and batch: 400, loss is 6.192992143630981 and perplexity is 489.30799783822096
At time: 13.972212314605713 and batch: 450, loss is 6.0910616302490235 and perplexity is 441.89028631060125
At time: 15.462775230407715 and batch: 500, loss is 6.066693048477173 and perplexity is 431.25219081231893
At time: 16.953487873077393 and batch: 550, loss is 6.006785850524903 and perplexity is 406.1757105262406
At time: 18.443728923797607 and batch: 600, loss is 6.03513385772705 and perplexity is 417.854738980556
At time: 19.93329358100891 and batch: 650, loss is 6.096072616577149 and perplexity is 444.11014970132646
At time: 21.424813508987427 and batch: 700, loss is 5.9972281169891355 and perplexity is 402.31208448233014
At time: 22.91644811630249 and batch: 750, loss is 5.917574300765991 and perplexity is 371.50944982012294
At time: 24.40508008003235 and batch: 800, loss is 5.927470598220825 and perplexity is 375.2042702088009
At time: 25.894213438034058 and batch: 850, loss is 5.949438896179199 and perplexity is 383.5380739949929
At time: 27.386491775512695 and batch: 900, loss is 5.918352966308594 and perplexity is 371.7988440834976
At time: 28.87839150428772 and batch: 950, loss is 5.939928102493286 and perplexity is 379.90761414596057
At time: 30.366694927215576 and batch: 1000, loss is 5.908298683166504 and perplexity is 368.0794027241692
At time: 31.85733127593994 and batch: 1050, loss is 5.809664916992188 and perplexity is 333.50735430186273
At time: 33.349127531051636 and batch: 1100, loss is 5.869425544738769 and perplexity is 354.04553851695164
At time: 34.84349966049194 and batch: 1150, loss is 5.77615065574646 and perplexity is 322.51532540630416
At time: 36.33654546737671 and batch: 1200, loss is 5.85078948020935 and perplexity is 347.5086233905601
At time: 37.826075315475464 and batch: 1250, loss is 5.7893038082122805 and perplexity is 326.78543982436327
At time: 39.31736207008362 and batch: 1300, loss is 5.797131414413452 and perplexity is 329.3534250360742
At time: 40.80711317062378 and batch: 1350, loss is 5.767673788070678 and perplexity is 319.79296053460746
At time: 42.295005798339844 and batch: 1400, loss is 5.78399130821228 and perplexity is 325.0539953967186
At time: 43.78823447227478 and batch: 1450, loss is 5.747320470809936 and perplexity is 313.3499041585492
At time: 45.27949905395508 and batch: 1500, loss is 5.709631185531617 and perplexity is 301.75975439356944
At time: 46.77094388008118 and batch: 1550, loss is 5.683041658401489 and perplexity is 293.84183853033204
At time: 48.26139783859253 and batch: 1600, loss is 5.690713472366333 and perplexity is 296.1048078913604
At time: 49.75248050689697 and batch: 1650, loss is 5.689127187728882 and perplexity is 295.6354737307268
At time: 51.24718761444092 and batch: 1700, loss is 5.6975986099243165 and perplexity is 298.1505648025383
At time: 52.743568420410156 and batch: 1750, loss is 5.692058897018432 and perplexity is 296.50346271938315
At time: 54.23149108886719 and batch: 1800, loss is 5.697460765838623 and perplexity is 298.10946934298227
At time: 55.719990491867065 and batch: 1850, loss is 5.649274282455444 and perplexity is 284.0852253646164
At time: 57.21259903907776 and batch: 1900, loss is 5.65521164894104 and perplexity is 285.7769607173453
At time: 58.70504927635193 and batch: 1950, loss is 5.585723581314087 and perplexity is 266.593114762534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.089302666242733 and perplexity of 162.27666159467918
finished 1 epochs...
Completing Train Step...
At time: 62.874064683914185 and batch: 50, loss is 5.37635181427002 and perplexity is 216.23198030486418
At time: 64.14812183380127 and batch: 100, loss is 5.292000141143799 and perplexity is 198.74053726263335
At time: 65.41723918914795 and batch: 150, loss is 5.1819422149658205 and perplexity is 178.028244552572
At time: 66.68645095825195 and batch: 200, loss is 5.134571390151978 and perplexity is 169.79152995470972
At time: 67.96248960494995 and batch: 250, loss is 5.155664644241333 and perplexity is 173.41102510425796
At time: 69.23655676841736 and batch: 300, loss is 5.154853744506836 and perplexity is 173.27046314857063
At time: 70.5267391204834 and batch: 350, loss is 5.135720224380493 and perplexity is 169.98670436608958
At time: 71.79634618759155 and batch: 400, loss is 5.084138212203979 and perplexity is 161.4407516016005
At time: 73.06827020645142 and batch: 450, loss is 5.030662641525269 and perplexity is 153.03438604379699
At time: 74.34126472473145 and batch: 500, loss is 5.019190425872803 and perplexity is 151.28877472481028
At time: 75.61302828788757 and batch: 550, loss is 4.974549674987793 and perplexity is 144.68365580652278
At time: 76.88669395446777 and batch: 600, loss is 4.9512480449676515 and perplexity is 141.35126661872013
At time: 78.15447950363159 and batch: 650, loss is 5.0229146194458005 and perplexity is 151.85325386968316
At time: 79.43043899536133 and batch: 700, loss is 5.015680856704712 and perplexity is 150.75874693418658
At time: 80.70031690597534 and batch: 750, loss is 4.9549856281280515 and perplexity is 141.88056726896085
At time: 81.97012376785278 and batch: 800, loss is 4.955100946426391 and perplexity is 141.89692963796793
At time: 83.24539923667908 and batch: 850, loss is 4.951176414489746 and perplexity is 141.34114192256243
At time: 84.51893711090088 and batch: 900, loss is 4.938901300430298 and perplexity is 139.6167683772484
At time: 85.79042458534241 and batch: 950, loss is 4.987304277420044 and perplexity is 146.54085706927907
At time: 87.06144165992737 and batch: 1000, loss is 4.94718918800354 and perplexity is 140.77870480511797
At time: 88.33548092842102 and batch: 1050, loss is 4.866117753982544 and perplexity is 129.81595985379917
At time: 89.61145615577698 and batch: 1100, loss is 4.924894857406616 and perplexity is 137.6748653894457
At time: 90.88231754302979 and batch: 1150, loss is 4.846405649185181 and perplexity is 127.28207024584746
At time: 92.15836429595947 and batch: 1200, loss is 4.924179735183716 and perplexity is 137.57644622872976
At time: 93.42854714393616 and batch: 1250, loss is 4.891985073089599 and perplexity is 133.2177587395037
At time: 94.70356106758118 and batch: 1300, loss is 4.894487791061401 and perplexity is 133.55158277792947
At time: 95.9744348526001 and batch: 1350, loss is 4.795557060241699 and perplexity is 120.97175156996563
At time: 97.2487735748291 and batch: 1400, loss is 4.802601613998413 and perplexity is 121.8269522940198
At time: 98.52250838279724 and batch: 1450, loss is 4.756008148193359 and perplexity is 116.28082239352031
At time: 99.7929253578186 and batch: 1500, loss is 4.72990740776062 and perplexity is 113.28507254447489
At time: 101.06985521316528 and batch: 1550, loss is 4.73372223854065 and perplexity is 113.71806129042862
At time: 102.34026408195496 and batch: 1600, loss is 4.7902106761932375 and perplexity is 120.32671596754973
At time: 103.61409068107605 and batch: 1650, loss is 4.761542539596558 and perplexity is 116.92615007815637
At time: 104.88884663581848 and batch: 1700, loss is 4.770675106048584 and perplexity is 117.99887683212985
At time: 106.15755128860474 and batch: 1750, loss is 4.764080505371094 and perplexity is 117.22328154045195
At time: 107.43681812286377 and batch: 1800, loss is 4.724162836074829 and perplexity is 112.63616395975757
At time: 108.70305228233337 and batch: 1850, loss is 4.733715124130249 and perplexity is 113.71725225634857
At time: 109.97557187080383 and batch: 1900, loss is 4.831399908065796 and perplexity is 125.38636723641012
At time: 111.24649691581726 and batch: 1950, loss is 4.743329439163208 and perplexity is 114.81583835835224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.587782181140988 and perplexity of 98.27622941153423
finished 2 epochs...
Completing Train Step...
At time: 115.32549548149109 and batch: 50, loss is 4.721744785308838 and perplexity is 112.36413302207139
At time: 116.61395001411438 and batch: 100, loss is 4.644648160934448 and perplexity is 104.02675866832377
At time: 117.88625264167786 and batch: 150, loss is 4.580874767303467 and perplexity is 97.59973393148205
At time: 119.15964841842651 and batch: 200, loss is 4.572004632949829 and perplexity is 96.73783938991804
At time: 120.43598365783691 and batch: 250, loss is 4.583587112426758 and perplexity is 97.8648174302991
At time: 121.70592594146729 and batch: 300, loss is 4.599626817703247 and perplexity is 99.44719678301296
At time: 122.97616696357727 and batch: 350, loss is 4.6062782096862795 and perplexity is 100.1108637783232
At time: 124.25190806388855 and batch: 400, loss is 4.557317781448364 and perplexity is 95.3274475679754
At time: 125.52393078804016 and batch: 450, loss is 4.545508089065552 and perplexity is 94.20828124890726
At time: 126.79994177818298 and batch: 500, loss is 4.554623699188232 and perplexity is 95.07097321920138
At time: 128.07357168197632 and batch: 550, loss is 4.5238700866699215 and perplexity is 92.19169832686292
At time: 129.3450803756714 and batch: 600, loss is 4.49541711807251 and perplexity is 89.60553728010451
At time: 130.61464262008667 and batch: 650, loss is 4.56201810836792 and perplexity is 95.77657242590298
At time: 131.8855893611908 and batch: 700, loss is 4.587558298110962 and perplexity is 98.25422949431
At time: 133.1592767238617 and batch: 750, loss is 4.54098274230957 and perplexity is 93.78291929005813
At time: 134.44697904586792 and batch: 800, loss is 4.538014802932739 and perplexity is 93.50498991380844
At time: 135.718585729599 and batch: 850, loss is 4.534726572036743 and perplexity is 93.19802887301684
At time: 136.9904477596283 and batch: 900, loss is 4.506594123840332 and perplexity is 90.61267680449093
At time: 138.26369762420654 and batch: 950, loss is 4.583699588775635 and perplexity is 97.87582552671077
At time: 139.53845882415771 and batch: 1000, loss is 4.548603401184082 and perplexity is 94.50033705227548
At time: 140.81299591064453 and batch: 1050, loss is 4.4816412830352785 and perplexity is 88.37960965580469
At time: 142.08794856071472 and batch: 1100, loss is 4.526917381286621 and perplexity is 92.47306207426644
At time: 143.36253190040588 and batch: 1150, loss is 4.476340951919556 and perplexity is 87.91240771701537
At time: 144.63092494010925 and batch: 1200, loss is 4.550492296218872 and perplexity is 94.67900696094776
At time: 145.90121126174927 and batch: 1250, loss is 4.539911069869995 and perplexity is 93.68246855490814
At time: 147.17580008506775 and batch: 1300, loss is 4.527937107086181 and perplexity is 92.5674073364015
At time: 148.45014262199402 and batch: 1350, loss is 4.414385004043579 and perplexity is 82.63100754104069
At time: 149.71827101707458 and batch: 1400, loss is 4.429794044494629 and perplexity is 83.91413255284793
At time: 150.99555587768555 and batch: 1450, loss is 4.381259927749634 and perplexity is 79.93868695363227
At time: 152.271746635437 and batch: 1500, loss is 4.3729106187820435 and perplexity is 79.27403272070252
At time: 153.54675579071045 and batch: 1550, loss is 4.381509733200073 and perplexity is 79.95865856773946
At time: 154.82513093948364 and batch: 1600, loss is 4.452080392837525 and perplexity is 85.80526710994424
At time: 156.0972774028778 and batch: 1650, loss is 4.420533876419068 and perplexity is 83.14066034993553
At time: 157.37025833129883 and batch: 1700, loss is 4.431806116104126 and perplexity is 84.0831437709107
At time: 158.64089798927307 and batch: 1750, loss is 4.423793087005615 and perplexity is 83.41207532934997
At time: 159.91110277175903 and batch: 1800, loss is 4.381573009490967 and perplexity is 79.9637182151546
At time: 161.18128848075867 and batch: 1850, loss is 4.415022029876709 and perplexity is 82.68366239693296
At time: 162.45546007156372 and batch: 1900, loss is 4.520379962921143 and perplexity is 91.87049873030544
At time: 163.73533082008362 and batch: 1950, loss is 4.434753561019898 and perplexity is 84.33133979789716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463934751998546 and perplexity of 86.82848638620668
finished 3 epochs...
Completing Train Step...
At time: 167.81021070480347 and batch: 50, loss is 4.423378825187683 and perplexity is 83.37752804769049
At time: 169.10143423080444 and batch: 100, loss is 4.360284290313721 and perplexity is 78.27938533108922
At time: 170.37110376358032 and batch: 150, loss is 4.30696964263916 and perplexity is 74.21524910769895
At time: 171.64294719696045 and batch: 200, loss is 4.306308269500732 and perplexity is 74.16618136331003
At time: 172.9207148551941 and batch: 250, loss is 4.3106913661956785 and perplexity is 74.49197237289033
At time: 174.19219946861267 and batch: 300, loss is 4.326404829025268 and perplexity is 75.67174408638552
At time: 175.46517086029053 and batch: 350, loss is 4.3336528968811034 and perplexity is 76.22221052145936
At time: 176.7352511882782 and batch: 400, loss is 4.285817546844482 and perplexity is 72.66192697248825
At time: 178.0062608718872 and batch: 450, loss is 4.293804044723511 and perplexity is 73.2445648191853
At time: 179.2800691127777 and batch: 500, loss is 4.30739047050476 and perplexity is 74.24648752511318
At time: 180.55325198173523 and batch: 550, loss is 4.2788576316833495 and perplexity is 72.15796193661703
At time: 181.8251175880432 and batch: 600, loss is 4.2508620262146 and perplexity is 70.16587110468934
At time: 183.09820985794067 and batch: 650, loss is 4.3095455074310305 and perplexity is 74.40666397847076
At time: 184.36753678321838 and batch: 700, loss is 4.351569890975952 and perplexity is 77.60019119008959
At time: 185.64241576194763 and batch: 750, loss is 4.301344270706177 and perplexity is 73.79893279327796
At time: 186.92014741897583 and batch: 800, loss is 4.2989544010162355 and perplexity is 73.62277354331545
At time: 188.190434217453 and batch: 850, loss is 4.294483108520508 and perplexity is 73.2943194428507
At time: 189.46017622947693 and batch: 900, loss is 4.26224937915802 and perplexity is 70.96944122850122
At time: 190.73505187034607 and batch: 950, loss is 4.355059823989868 and perplexity is 77.87148378034003
At time: 192.00556588172913 and batch: 1000, loss is 4.317663774490357 and perplexity is 75.01317572875014
At time: 193.28361439704895 and batch: 1050, loss is 4.2611171245574955 and perplexity is 70.88913122643801
At time: 194.5533266067505 and batch: 1100, loss is 4.2919109916687015 and perplexity is 73.10604013066721
At time: 195.84516310691833 and batch: 1150, loss is 4.253668484687805 and perplexity is 70.36306528739482
At time: 197.12517762184143 and batch: 1200, loss is 4.328942899703979 and perplexity is 75.86404825881672
At time: 198.41523432731628 and batch: 1250, loss is 4.322748413085938 and perplexity is 75.39556194124849
At time: 199.68937230110168 and batch: 1300, loss is 4.304114484786988 and perplexity is 74.00365506739256
At time: 200.9638557434082 and batch: 1350, loss is 4.190563349723816 and perplexity is 66.05999536002322
At time: 202.2354817390442 and batch: 1400, loss is 4.212748012542725 and perplexity is 67.54189098338271
At time: 203.5111653804779 and batch: 1450, loss is 4.160592813491821 and perplexity is 64.10951632345866
At time: 204.784006357193 and batch: 1500, loss is 4.157411456108093 and perplexity is 63.905885123892475
At time: 206.05611371994019 and batch: 1550, loss is 4.167706880569458 and perplexity is 64.56722186649651
At time: 207.32680702209473 and batch: 1600, loss is 4.245677452087403 and perplexity is 69.80303233973696
At time: 208.59891939163208 and batch: 1650, loss is 4.209441003799438 and perplexity is 67.3188982819955
At time: 209.8698410987854 and batch: 1700, loss is 4.223901691436768 and perplexity is 68.29944847016645
At time: 211.1522343158722 and batch: 1750, loss is 4.216405429840088 and perplexity is 67.78937215885453
At time: 212.4272165298462 and batch: 1800, loss is 4.170261192321777 and perplexity is 64.73235749427634
At time: 213.69895315170288 and batch: 1850, loss is 4.209785151481628 and perplexity is 67.3420699118095
At time: 214.96863794326782 and batch: 1900, loss is 4.315363616943359 and perplexity is 74.84083189144772
At time: 216.24047470092773 and batch: 1950, loss is 4.237277903556824 and perplexity is 69.21917388843077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421341013353924 and perplexity of 83.20779333680434
finished 4 epochs...
Completing Train Step...
At time: 220.3294496536255 and batch: 50, loss is 4.225774145126342 and perplexity is 68.42745583097748
At time: 221.64103317260742 and batch: 100, loss is 4.170148882865906 and perplexity is 64.72508784666162
At time: 222.9160966873169 and batch: 150, loss is 4.125171394348144 and perplexity is 61.87841395197247
At time: 224.1901454925537 and batch: 200, loss is 4.129014539718628 and perplexity is 62.116679242899586
At time: 225.4617738723755 and batch: 250, loss is 4.127289032936096 and perplexity is 62.00958891067556
At time: 226.73309183120728 and batch: 300, loss is 4.141282534599304 and perplexity is 62.88341991475654
At time: 228.00258231163025 and batch: 350, loss is 4.150494532585144 and perplexity is 63.46537823634375
At time: 229.2970917224884 and batch: 400, loss is 4.102861886024475 and perplexity is 60.51322196434033
At time: 230.57389664649963 and batch: 450, loss is 4.120969643592835 and perplexity is 61.61896173789332
At time: 231.8440718650818 and batch: 500, loss is 4.136760215759278 and perplexity is 62.599683097894015
At time: 233.11644411087036 and batch: 550, loss is 4.106134071350097 and perplexity is 60.711556758392064
At time: 234.3896770477295 and batch: 600, loss is 4.083642244338989 and perplexity is 59.36128488959072
At time: 235.66384720802307 and batch: 650, loss is 4.139899430274963 and perplexity is 62.796505704308665
At time: 236.94066667556763 and batch: 700, loss is 4.183989696502685 and perplexity is 65.627164058833
At time: 238.2114553451538 and batch: 750, loss is 4.134307885169983 and perplexity is 62.446356061285364
At time: 239.4829523563385 and batch: 800, loss is 4.1309008264541625 and perplexity is 62.23395968851097
At time: 240.75408554077148 and batch: 850, loss is 4.122871155738831 and perplexity is 61.73624241203665
At time: 242.0272889137268 and batch: 900, loss is 4.094893727302551 and perplexity is 60.032958953952026
At time: 243.30258679389954 and batch: 950, loss is 4.194279632568359 and perplexity is 66.30594972241107
At time: 244.57246232032776 and batch: 1000, loss is 4.15614944934845 and perplexity is 63.82528633369139
At time: 245.84407210350037 and batch: 1050, loss is 4.103707308769226 and perplexity is 60.564402850241265
At time: 247.11847305297852 and batch: 1100, loss is 4.1267981481552125 and perplexity is 61.979156817147356
At time: 248.39123821258545 and batch: 1150, loss is 4.094426536560059 and perplexity is 60.004918661876765
At time: 249.66649770736694 and batch: 1200, loss is 4.171121068000794 and perplexity is 64.7880432120972
At time: 250.94087886810303 and batch: 1250, loss is 4.16407630443573 and perplexity is 64.3332306702146
At time: 252.21642017364502 and batch: 1300, loss is 4.142584276199341 and perplexity is 62.96533118049648
At time: 253.48974061012268 and batch: 1350, loss is 4.0303989696502684 and perplexity is 56.283362121522835
At time: 254.76206588745117 and batch: 1400, loss is 4.055119733810425 and perplexity is 57.6920702740427
At time: 256.0392577648163 and batch: 1450, loss is 4.001572122573853 and perplexity is 54.68405252423181
At time: 257.3134753704071 and batch: 1500, loss is 4.000236563682556 and perplexity is 54.61106750041839
At time: 258.58439540863037 and batch: 1550, loss is 4.015879468917847 and perplexity is 55.47205990841549
At time: 259.85727524757385 and batch: 1600, loss is 4.10044557094574 and perplexity is 60.36717946704595
At time: 261.13336062431335 and batch: 1650, loss is 4.057020392417908 and perplexity is 57.80182747643675
At time: 262.40824580192566 and batch: 1700, loss is 4.070952882766724 and perplexity is 58.61278710530228
At time: 263.68221831321716 and batch: 1750, loss is 4.066349806785584 and perplexity is 58.343607994028396
At time: 264.95666551589966 and batch: 1800, loss is 4.019307842254639 and perplexity is 55.662565214602715
At time: 266.2285866737366 and batch: 1850, loss is 4.060481181144715 and perplexity is 58.002213936954504
At time: 267.50455594062805 and batch: 1900, loss is 4.164625735282898 and perplexity is 64.36858704369449
At time: 268.78296065330505 and batch: 1950, loss is 4.087289438247681 and perplexity is 59.578182299276705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.414820187590843 and perplexity of 82.66697502167666
finished 5 epochs...
Completing Train Step...
At time: 272.85301876068115 and batch: 50, loss is 4.078131356239319 and perplexity is 59.035051235332546
At time: 274.1227717399597 and batch: 100, loss is 4.0307553148269655 and perplexity is 56.30342200005134
At time: 275.397709608078 and batch: 150, loss is 3.9905521726608275 and perplexity is 54.08474523745723
At time: 276.6720769405365 and batch: 200, loss is 3.994178237915039 and perplexity is 54.28121604565901
At time: 277.9471158981323 and batch: 250, loss is 3.9909733819961546 and perplexity is 54.10753103550857
At time: 279.2253448963165 and batch: 300, loss is 4.001898913383484 and perplexity is 54.70192569026427
At time: 280.4988434314728 and batch: 350, loss is 4.011169085502624 and perplexity is 55.21137967133868
At time: 281.776734828949 and batch: 400, loss is 3.964478349685669 and perplexity is 52.69277501639629
At time: 283.052449464798 and batch: 450, loss is 3.9902487134933473 and perplexity is 54.06833521570579
At time: 284.32129096984863 and batch: 500, loss is 4.002867698669434 and perplexity is 54.754945789385225
At time: 285.5904760360718 and batch: 550, loss is 3.9782593488693236 and perplexity is 53.423960769062965
At time: 286.87128734588623 and batch: 600, loss is 3.9534922313690184 and perplexity is 52.11705421458692
At time: 288.13455533981323 and batch: 650, loss is 4.007328891754151 and perplexity is 54.99976385919933
At time: 289.3933832645416 and batch: 700, loss is 4.057605156898498 and perplexity is 57.835637816637764
At time: 290.6485056877136 and batch: 750, loss is 4.008188786506653 and perplexity is 55.04707820729512
At time: 291.9025402069092 and batch: 800, loss is 4.002990012168884 and perplexity is 54.76164346801686
At time: 293.18822956085205 and batch: 850, loss is 3.9957713222503664 and perplexity is 54.367759517865466
At time: 294.43923568725586 and batch: 900, loss is 3.968727707862854 and perplexity is 52.91716190327017
At time: 295.69654512405396 and batch: 950, loss is 4.069007172584533 and perplexity is 58.49885448449885
At time: 296.95403814315796 and batch: 1000, loss is 4.03435830116272 and perplexity is 56.50664835120817
At time: 298.2158055305481 and batch: 1050, loss is 3.983531951904297 and perplexity is 53.70638801583591
At time: 299.4682710170746 and batch: 1100, loss is 4.0015732955932615 and perplexity is 54.68411666972439
At time: 300.7211673259735 and batch: 1150, loss is 3.96966326713562 and perplexity is 52.96669221043361
At time: 301.97961807250977 and batch: 1200, loss is 4.0437912130355835 and perplexity is 57.04219248459705
At time: 303.24841952323914 and batch: 1250, loss is 4.037628154754639 and perplexity is 56.69171923072954
At time: 304.5181393623352 and batch: 1300, loss is 4.01863139629364 and perplexity is 55.62492522932772
At time: 305.7949137687683 and batch: 1350, loss is 3.9066631746292115 and perplexity is 49.732725373291665
At time: 307.0666534900665 and batch: 1400, loss is 3.9371345901489256 and perplexity is 51.27147682046386
At time: 308.3390386104584 and batch: 1450, loss is 3.8827584266662596 and perplexity is 48.55797411493356
At time: 309.6189765930176 and batch: 1500, loss is 3.882114653587341 and perplexity is 48.52672385854772
At time: 310.89815735816956 and batch: 1550, loss is 3.8956061601638794 and perplexity is 49.18585883657873
At time: 312.17228078842163 and batch: 1600, loss is 3.9824010372161864 and perplexity is 53.64568500421694
At time: 313.4429714679718 and batch: 1650, loss is 3.9397552585601807 and perplexity is 51.40601857783077
At time: 314.7152543067932 and batch: 1700, loss is 3.952343053817749 and perplexity is 52.05719686579332
At time: 315.98345470428467 and batch: 1750, loss is 3.9491340351104736 and perplexity is 51.890412098048905
At time: 317.25695061683655 and batch: 1800, loss is 3.901941566467285 and perplexity is 49.49846042012868
At time: 318.53516840934753 and batch: 1850, loss is 3.9464975452423094 and perplexity is 51.75378374107983
At time: 319.8099377155304 and batch: 1900, loss is 4.046894431114197 and perplexity is 57.21948178897214
At time: 321.0803234577179 and batch: 1950, loss is 3.971950287818909 and perplexity is 53.08796675688213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.423464752906977 and perplexity of 83.38469279633682
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 325.14852714538574 and batch: 50, loss is 4.005916318893433 and perplexity is 54.922127531819825
At time: 326.42464089393616 and batch: 100, loss is 3.995725841522217 and perplexity is 54.36528688880366
At time: 327.6965560913086 and batch: 150, loss is 3.966360778808594 and perplexity is 52.79205884872558
At time: 328.9697856903076 and batch: 200, loss is 3.9752481889724733 and perplexity is 53.263334637714344
At time: 330.24126744270325 and batch: 250, loss is 3.960678300857544 and perplexity is 52.49291986860314
At time: 331.51602816581726 and batch: 300, loss is 3.9823187255859374 and perplexity is 53.64126952215367
At time: 332.7870497703552 and batch: 350, loss is 3.986457042694092 and perplexity is 53.863714061081666
At time: 334.06628155708313 and batch: 400, loss is 3.925954933166504 and perplexity is 50.70147146561963
At time: 335.34223079681396 and batch: 450, loss is 3.938775086402893 and perplexity is 51.35565651548148
At time: 336.6155662536621 and batch: 500, loss is 3.9444832944869996 and perplexity is 51.649643560517745
At time: 337.89138984680176 and batch: 550, loss is 3.9227845907211303 and perplexity is 50.54098497158299
At time: 339.1618845462799 and batch: 600, loss is 3.8884047412872316 and perplexity is 48.832923208218595
At time: 340.4344742298126 and batch: 650, loss is 3.930512638092041 and perplexity is 50.93308121536975
At time: 341.71143341064453 and batch: 700, loss is 3.9864150190353396 and perplexity is 53.861450558303495
At time: 342.98785638809204 and batch: 750, loss is 3.912764015197754 and perplexity is 50.037064219258696
At time: 344.2634263038635 and batch: 800, loss is 3.910333762168884 and perplexity is 49.91560913545418
At time: 345.53223276138306 and batch: 850, loss is 3.910273480415344 and perplexity is 49.91260022569857
At time: 346.8046054840088 and batch: 900, loss is 3.861325588226318 and perplexity is 47.528312600900556
At time: 348.0756845474243 and batch: 950, loss is 3.9635908126831056 and perplexity is 52.646028976290225
At time: 349.35610699653625 and batch: 1000, loss is 3.9206726694107057 and perplexity is 50.43435902081169
At time: 350.6313352584839 and batch: 1050, loss is 3.8669670724868777 and perplexity is 47.797200578874204
At time: 351.8983345031738 and batch: 1100, loss is 3.8779706239700316 and perplexity is 48.32604377693732
At time: 353.1674265861511 and batch: 1150, loss is 3.8392029428482055 and perplexity is 46.48840575253996
At time: 354.43903398513794 and batch: 1200, loss is 3.895659246444702 and perplexity is 49.188470000201306
At time: 355.7142605781555 and batch: 1250, loss is 3.888550043106079 and perplexity is 48.8400192363008
At time: 356.9864032268524 and batch: 1300, loss is 3.8677120113372805 and perplexity is 47.83281983596292
At time: 358.25640511512756 and batch: 1350, loss is 3.752286891937256 and perplexity is 42.61843439442659
At time: 359.53859090805054 and batch: 1400, loss is 3.7723553228378295 and perplexity is 43.48235931423631
At time: 360.8117980957031 and batch: 1450, loss is 3.7097423028945924 and perplexity is 40.84327997569253
At time: 362.0850896835327 and batch: 1500, loss is 3.6918054580688477 and perplexity is 40.11721155530812
At time: 363.35809206962585 and batch: 1550, loss is 3.7055959367752074 and perplexity is 40.674279394664815
At time: 364.6300559043884 and batch: 1600, loss is 3.7888228845596315 and perplexity is 44.20433603270739
At time: 365.90213441848755 and batch: 1650, loss is 3.741708240509033 and perplexity is 42.16996511490574
At time: 367.1745615005493 and batch: 1700, loss is 3.7321933841705324 and perplexity is 41.7706267911814
At time: 368.4473400115967 and batch: 1750, loss is 3.719304738044739 and perplexity is 41.23571451635015
At time: 369.7204473018646 and batch: 1800, loss is 3.6640756702423096 and perplexity is 39.02005209358215
At time: 370.99575185775757 and batch: 1850, loss is 3.6965305280685423 and perplexity is 40.3072167284622
At time: 372.26986837387085 and batch: 1900, loss is 3.796776156425476 and perplexity is 44.55730691092018
At time: 373.538076877594 and batch: 1950, loss is 3.7174207401275634 and perplexity is 41.15809965216683
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3585202239280525 and perplexity of 78.1414170271385
finished 7 epochs...
Completing Train Step...
At time: 377.6140637397766 and batch: 50, loss is 3.9260025215148926 and perplexity is 50.703884322319034
At time: 378.8840732574463 and batch: 100, loss is 3.894276671409607 and perplexity is 49.12051024012384
At time: 380.1596624851227 and batch: 150, loss is 3.851806640625 and perplexity is 47.07803954642472
At time: 381.4305806159973 and batch: 200, loss is 3.858594913482666 and perplexity is 47.39870527633242
At time: 382.70130157470703 and batch: 250, loss is 3.8407955598831176 and perplexity is 46.56250296804933
At time: 383.9793932437897 and batch: 300, loss is 3.8601351261138914 and perplexity is 47.471765610684514
At time: 385.2488172054291 and batch: 350, loss is 3.86858820438385 and perplexity is 47.874748986433595
At time: 386.518550157547 and batch: 400, loss is 3.8136557579040526 and perplexity is 45.315800016075876
At time: 387.8094115257263 and batch: 450, loss is 3.8329369974136354 and perplexity is 46.19802265117476
At time: 389.07952904701233 and batch: 500, loss is 3.8412670516967773 and perplexity is 46.584461983363454
At time: 390.3529706001282 and batch: 550, loss is 3.819692497253418 and perplexity is 45.59018705743336
At time: 391.62359857559204 and batch: 600, loss is 3.790202775001526 and perplexity is 44.265375277539086
At time: 392.8983111381531 and batch: 650, loss is 3.833462424278259 and perplexity is 46.22230271150758
At time: 394.1729648113251 and batch: 700, loss is 3.891068286895752 and perplexity is 48.96316530225993
At time: 395.4457154273987 and batch: 750, loss is 3.8197392082214354 and perplexity is 45.59231666894064
At time: 396.71986413002014 and batch: 800, loss is 3.819202742576599 and perplexity is 45.567864516835456
At time: 397.992653131485 and batch: 850, loss is 3.8218733501434325 and perplexity is 45.68972104367503
At time: 399.26477551460266 and batch: 900, loss is 3.774052176475525 and perplexity is 43.55620514888207
At time: 400.54082465171814 and batch: 950, loss is 3.880417895317078 and perplexity is 48.44445555296334
At time: 401.81777000427246 and batch: 1000, loss is 3.8398962926864626 and perplexity is 46.52064965801091
At time: 403.09305596351624 and batch: 1050, loss is 3.790434284210205 and perplexity is 44.275624305867915
At time: 404.3642838001251 and batch: 1100, loss is 3.799123487472534 and perplexity is 44.662020511467624
At time: 405.6379382610321 and batch: 1150, loss is 3.7656507873535157 and perplexity is 43.191805396184186
At time: 406.91406869888306 and batch: 1200, loss is 3.8243047332763673 and perplexity is 45.80094542051297
At time: 408.1914801597595 and batch: 1250, loss is 3.8219951820373534 and perplexity is 45.69528784802277
At time: 409.4614288806915 and batch: 1300, loss is 3.8028927183151247 and perplexity is 44.83067963457649
At time: 410.73203897476196 and batch: 1350, loss is 3.6892509269714355 and perplexity is 40.01486167448341
At time: 412.0069432258606 and batch: 1400, loss is 3.7144212198257445 and perplexity is 41.03483006391477
At time: 413.2835943698883 and batch: 1450, loss is 3.65278769493103 and perplexity is 38.582071317555375
At time: 414.55522894859314 and batch: 1500, loss is 3.636737518310547 and perplexity is 37.96776530598091
At time: 415.8260428905487 and batch: 1550, loss is 3.6556573629379274 and perplexity is 38.69294806689623
At time: 417.10766434669495 and batch: 1600, loss is 3.742203426361084 and perplexity is 42.19085225609372
At time: 418.38395404815674 and batch: 1650, loss is 3.6969115781784057 and perplexity is 40.322578724484124
At time: 419.65583968162537 and batch: 1700, loss is 3.6930508327484133 and perplexity is 40.167203637769404
At time: 420.9256868362427 and batch: 1750, loss is 3.6830580615997315 and perplexity is 39.76782075836703
At time: 422.19937443733215 and batch: 1800, loss is 3.632552704811096 and perplexity is 37.80920928426929
At time: 423.4675772190094 and batch: 1850, loss is 3.668396735191345 and perplexity is 39.18902508170514
At time: 424.73944568634033 and batch: 1900, loss is 3.7735300254821778 and perplexity is 43.53346816968187
At time: 426.0115818977356 and batch: 1950, loss is 3.6961653232574463 and perplexity is 40.29249902664241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36403439543968 and perplexity of 78.57349237677016
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 430.05819606781006 and batch: 50, loss is 3.8958131456375122 and perplexity is 49.196040648573295
At time: 431.3395571708679 and batch: 100, loss is 3.8989180517196655 and perplexity is 49.349027115802464
At time: 432.6123421192169 and batch: 150, loss is 3.8745004606246947 and perplexity is 48.15863514683837
At time: 433.88915061950684 and batch: 200, loss is 3.8934016704559324 and perplexity is 49.07754854532176
At time: 435.158549785614 and batch: 250, loss is 3.882593593597412 and perplexity is 48.54997081466556
At time: 436.4316680431366 and batch: 300, loss is 3.8944063329696657 and perplexity is 49.12687969504026
At time: 437.6973719596863 and batch: 350, loss is 3.917278361320496 and perplexity is 50.263459474900884
At time: 438.9740619659424 and batch: 400, loss is 3.86621919631958 and perplexity is 47.7614675553016
At time: 440.242733001709 and batch: 450, loss is 3.878290786743164 and perplexity is 48.34151845420308
At time: 441.5142869949341 and batch: 500, loss is 3.866655855178833 and perplexity is 47.782327577265775
At time: 442.7883269786835 and batch: 550, loss is 3.842655553817749 and perplexity is 46.64918953440341
At time: 444.0582466125488 and batch: 600, loss is 3.8081487464904784 and perplexity is 45.06693127861775
At time: 445.3350808620453 and batch: 650, loss is 3.844610571861267 and perplexity is 46.740478748612794
At time: 446.6014156341553 and batch: 700, loss is 3.9025120687484742 and perplexity is 49.52670746144834
At time: 447.8746976852417 and batch: 750, loss is 3.8286223936080934 and perplexity is 45.99912587577939
At time: 449.14373898506165 and batch: 800, loss is 3.830810532569885 and perplexity is 46.09988855648642
At time: 450.415176153183 and batch: 850, loss is 3.830692458152771 and perplexity is 46.094445660355795
At time: 451.7311475276947 and batch: 900, loss is 3.7739020919799806 and perplexity is 43.54966852833944
At time: 453.00477051734924 and batch: 950, loss is 3.8896057748794557 and perplexity is 48.89160842380144
At time: 454.27444410324097 and batch: 1000, loss is 3.839045481681824 and perplexity is 46.4810862102339
At time: 455.5506708621979 and batch: 1050, loss is 3.7859355449676513 and perplexity is 44.07688718573607
At time: 456.8222305774689 and batch: 1100, loss is 3.7926278638839723 and perplexity is 44.37285301586258
At time: 458.09334087371826 and batch: 1150, loss is 3.768845362663269 and perplexity is 43.330005499073515
At time: 459.3703234195709 and batch: 1200, loss is 3.8100855493545533 and perplexity is 45.15430162244732
At time: 460.63869524002075 and batch: 1250, loss is 3.799143385887146 and perplexity is 44.662909223711125
At time: 461.91157269477844 and batch: 1300, loss is 3.787597031593323 and perplexity is 44.15018121596098
At time: 463.1868486404419 and batch: 1350, loss is 3.667312216758728 and perplexity is 39.14654689999677
At time: 464.4571831226349 and batch: 1400, loss is 3.6901088333129883 and perplexity is 40.0492054078172
At time: 465.72979736328125 and batch: 1450, loss is 3.625582580566406 and perplexity is 37.54659070325805
At time: 467.00959753990173 and batch: 1500, loss is 3.604151964187622 and perplexity is 36.75050489440078
At time: 468.28901648521423 and batch: 1550, loss is 3.6268593311309814 and perplexity is 37.594558949362906
At time: 469.5627987384796 and batch: 1600, loss is 3.70352548122406 and perplexity is 40.590152227935825
At time: 470.8334131240845 and batch: 1650, loss is 3.6519874954223632 and perplexity is 38.55121031217113
At time: 472.1071102619171 and batch: 1700, loss is 3.6400718545913695 and perplexity is 38.09457389709943
At time: 473.38424468040466 and batch: 1750, loss is 3.6300751829147337 and perplexity is 37.715652083245814
At time: 474.6589341163635 and batch: 1800, loss is 3.5778184700012208 and perplexity is 35.795366941905016
At time: 475.9324004650116 and batch: 1850, loss is 3.606227407455444 and perplexity is 36.826857687911314
At time: 477.2051610946655 and batch: 1900, loss is 3.7148522329330445 and perplexity is 41.052520425643166
At time: 478.4821481704712 and batch: 1950, loss is 3.6461083459854127 and perplexity is 38.32522693171713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334324184683866 and perplexity of 76.27339473943054
finished 9 epochs...
Completing Train Step...
At time: 482.5418162345886 and batch: 50, loss is 3.8934070014953615 and perplexity is 49.07781018036553
At time: 483.82925510406494 and batch: 100, loss is 3.871008062362671 and perplexity is 47.99073936327136
At time: 485.1041555404663 and batch: 150, loss is 3.8363460969924925 and perplexity is 46.35578507184751
At time: 486.37714529037476 and batch: 200, loss is 3.8440746021270753 and perplexity is 46.71543397886074
At time: 487.6495056152344 and batch: 250, loss is 3.8292222356796266 and perplexity is 46.02672636387283
At time: 488.9232051372528 and batch: 300, loss is 3.8389227914810182 and perplexity is 46.475383786256025
At time: 490.1921434402466 and batch: 350, loss is 3.8609535360336302 and perplexity is 47.510632877076574
At time: 491.464821100235 and batch: 400, loss is 3.809929552078247 and perplexity is 45.14725822377049
At time: 492.73822355270386 and batch: 450, loss is 3.8254796075820923 and perplexity is 45.854787397049535
At time: 494.0078842639923 and batch: 500, loss is 3.8162349033355714 and perplexity is 45.43282690447343
At time: 495.27988362312317 and batch: 550, loss is 3.79410249710083 and perplexity is 44.438334967911196
At time: 496.5549237728119 and batch: 600, loss is 3.7609716987609865 and perplexity is 42.990179193561175
At time: 497.8277838230133 and batch: 650, loss is 3.797554364204407 and perplexity is 44.59199524938327
At time: 499.10279297828674 and batch: 700, loss is 3.8595710372924805 and perplexity is 47.44499486961864
At time: 500.3777301311493 and batch: 750, loss is 3.7883116674423216 and perplexity is 44.18174379472957
At time: 501.6505801677704 and batch: 800, loss is 3.7904316759109498 and perplexity is 44.27550882194062
At time: 502.92360186576843 and batch: 850, loss is 3.791466546058655 and perplexity is 44.32135194104129
At time: 504.1962220668793 and batch: 900, loss is 3.736078405380249 and perplexity is 41.93322220100657
At time: 505.46532559394836 and batch: 950, loss is 3.8521828651428223 and perplexity is 47.09575479139888
At time: 506.73567271232605 and batch: 1000, loss is 3.8032472419738768 and perplexity is 44.846575988795216
At time: 508.0093936920166 and batch: 1050, loss is 3.754193706512451 and perplexity is 42.6997773746455
At time: 509.27941727638245 and batch: 1100, loss is 3.7609245586395263 and perplexity is 42.98815267905784
At time: 510.5503053665161 and batch: 1150, loss is 3.7394082355499267 and perplexity is 42.073085440589765
At time: 511.82335114479065 and batch: 1200, loss is 3.783549914360046 and perplexity is 43.97186134082347
At time: 513.1020410060883 and batch: 1250, loss is 3.7757445430755614 and perplexity is 43.62998062566839
At time: 514.3783624172211 and batch: 1300, loss is 3.7650442552566528 and perplexity is 43.16561612301021
At time: 515.648336648941 and batch: 1350, loss is 3.646029005050659 and perplexity is 38.32218629301287
At time: 516.9215340614319 and batch: 1400, loss is 3.670321378707886 and perplexity is 39.26452261436141
At time: 518.1948556900024 and batch: 1450, loss is 3.607807507514954 and perplexity is 36.8850938052652
At time: 519.4671239852905 and batch: 1500, loss is 3.5891401863098142 and perplexity is 36.20293476166207
At time: 520.7393293380737 and batch: 1550, loss is 3.6143047761917115 and perplexity is 37.12552640166291
At time: 522.0174534320831 and batch: 1600, loss is 3.6943380403518677 and perplexity is 40.218940458572426
At time: 523.2882657051086 and batch: 1650, loss is 3.6444861268997193 and perplexity is 38.2631054181007
At time: 524.5614931583405 and batch: 1700, loss is 3.6355487871170045 and perplexity is 37.92265865416623
At time: 525.8466854095459 and batch: 1750, loss is 3.627716326713562 and perplexity is 37.62679112975696
At time: 527.1187925338745 and batch: 1800, loss is 3.5780799531936647 and perplexity is 35.8047280525609
At time: 528.3918061256409 and batch: 1850, loss is 3.6080573987960816 and perplexity is 36.894312220363524
At time: 529.6647908687592 and batch: 1900, loss is 3.7180039930343627 and perplexity is 41.18211223545107
At time: 530.9492011070251 and batch: 1950, loss is 3.6489001226425173 and perplexity is 38.43237189846108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334434331849564 and perplexity of 76.28179650038582
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 535.0257675647736 and batch: 50, loss is 3.88528902053833 and perplexity is 48.681010238239494
At time: 536.3185739517212 and batch: 100, loss is 3.8809278917312624 and perplexity is 48.46916835276648
At time: 537.5880625247955 and batch: 150, loss is 3.8588426971435545 and perplexity is 47.4104513562304
At time: 538.866485118866 and batch: 200, loss is 3.875681481361389 and perplexity is 48.21554509289602
At time: 540.1382830142975 and batch: 250, loss is 3.8679838228225707 and perplexity is 47.84582311290811
At time: 541.4140508174896 and batch: 300, loss is 3.8767952060699464 and perplexity is 48.269273850771455
At time: 542.6838850975037 and batch: 350, loss is 3.904822869300842 and perplexity is 49.64128613765577
At time: 543.9641366004944 and batch: 400, loss is 3.8589982891082766 and perplexity is 47.41782861541152
At time: 545.231388092041 and batch: 450, loss is 3.88943754196167 and perplexity is 48.88338393769511
At time: 546.5060114860535 and batch: 500, loss is 3.8788931369781494 and perplexity is 48.37064575073979
At time: 547.7951753139496 and batch: 550, loss is 3.854126896858215 and perplexity is 47.18739948360541
At time: 549.070318698883 and batch: 600, loss is 3.8033333730697634 and perplexity is 44.8504388398853
At time: 550.3377959728241 and batch: 650, loss is 3.824958848953247 and perplexity is 45.83091433742906
At time: 551.6196720600128 and batch: 700, loss is 3.8828185844421386 and perplexity is 48.5608953425239
At time: 552.8908517360687 and batch: 750, loss is 3.8113349437713624 and perplexity is 45.21075241209678
At time: 554.1692667007446 and batch: 800, loss is 3.811010870933533 and perplexity is 45.196103209094794
At time: 555.4479355812073 and batch: 850, loss is 3.807219591140747 and perplexity is 45.02507654610976
At time: 556.730742931366 and batch: 900, loss is 3.747183747291565 and perplexity is 42.40150035281975
At time: 558.0006711483002 and batch: 950, loss is 3.872070803642273 and perplexity is 48.04176821346137
At time: 559.2813730239868 and batch: 1000, loss is 3.8192686367034914 and perplexity is 45.57086727041297
At time: 560.560352563858 and batch: 1050, loss is 3.770888466835022 and perplexity is 43.41862371136397
At time: 561.8330729007721 and batch: 1100, loss is 3.7746941614151 and perplexity is 43.584176554262505
At time: 563.1063051223755 and batch: 1150, loss is 3.758192286491394 and perplexity is 42.87085766071936
At time: 564.377513885498 and batch: 1200, loss is 3.799590950012207 and perplexity is 44.68290321356304
At time: 565.6511373519897 and batch: 1250, loss is 3.784823784828186 and perplexity is 44.027911489149425
At time: 566.927844285965 and batch: 1300, loss is 3.769716491699219 and perplexity is 43.36776797059628
At time: 568.2030940055847 and batch: 1350, loss is 3.6449313354492188 and perplexity is 38.280144272403604
At time: 569.4761111736298 and batch: 1400, loss is 3.671046462059021 and perplexity is 39.29300299007469
At time: 570.7508101463318 and batch: 1450, loss is 3.6043511486053466 and perplexity is 36.757825751395366
At time: 572.0287797451019 and batch: 1500, loss is 3.583178334236145 and perplexity is 35.98774033604643
At time: 573.3018245697021 and batch: 1550, loss is 3.61394935131073 and perplexity is 37.11233341055776
At time: 574.5740132331848 and batch: 1600, loss is 3.6897303247451783 and perplexity is 40.034049308973934
At time: 575.852944612503 and batch: 1650, loss is 3.636519947052002 and perplexity is 37.95950551007883
At time: 577.1302707195282 and batch: 1700, loss is 3.6195684766769407 and perplexity is 37.32145926657079
At time: 578.4037261009216 and batch: 1750, loss is 3.61189266204834 and perplexity is 37.0360833111883
At time: 579.6750915050507 and batch: 1800, loss is 3.564611349105835 and perplexity is 35.325721362772775
At time: 580.951975107193 and batch: 1850, loss is 3.590772490501404 and perplexity is 36.262077219930966
At time: 582.2237675189972 and batch: 1900, loss is 3.701113181114197 and perplexity is 40.49235460529019
At time: 583.4982249736786 and batch: 1950, loss is 3.6399863529205323 and perplexity is 38.091316886623304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311749977289244 and perplexity of 74.57087215595037
finished 11 epochs...
Completing Train Step...
At time: 587.5939803123474 and batch: 50, loss is 3.893378915786743 and perplexity is 49.07643181464546
At time: 588.87091755867 and batch: 100, loss is 3.870527901649475 and perplexity is 47.96770162698247
At time: 590.1348652839661 and batch: 150, loss is 3.83725528717041 and perplexity is 46.397950461599
At time: 591.4106070995331 and batch: 200, loss is 3.8462549114227294 and perplexity is 46.81739919127251
At time: 592.6801805496216 and batch: 250, loss is 3.8363569688797 and perplexity is 46.35628904945381
At time: 593.954843044281 and batch: 300, loss is 3.8434171628952027 and perplexity is 46.68473151343759
At time: 595.2267487049103 and batch: 350, loss is 3.869804196357727 and perplexity is 47.93299970597856
At time: 596.5011241436005 and batch: 400, loss is 3.826616435050964 and perplexity is 45.906946021002625
At time: 597.7732858657837 and batch: 450, loss is 3.857206063270569 and perplexity is 47.3329212670981
At time: 599.048947095871 and batch: 500, loss is 3.8484211921691895 and perplexity is 46.91892875280248
At time: 600.3196229934692 and batch: 550, loss is 3.8242548370361327 and perplexity is 45.79866018255016
At time: 601.5970487594604 and batch: 600, loss is 3.776556119918823 and perplexity is 43.66540408009947
At time: 602.8702306747437 and batch: 650, loss is 3.7996595764160155 and perplexity is 44.68596974574364
At time: 604.1487584114075 and batch: 700, loss is 3.858755693435669 and perplexity is 47.406326650604825
At time: 605.4203541278839 and batch: 750, loss is 3.789823598861694 and perplexity is 44.24859408512808
At time: 606.6923673152924 and batch: 800, loss is 3.7901111698150634 and perplexity is 44.26132052530396
At time: 607.9677445888519 and batch: 850, loss is 3.7878775072097777 and perplexity is 44.162566001988175
At time: 609.2397167682648 and batch: 900, loss is 3.729829649925232 and perplexity is 41.67200872954905
At time: 610.5316255092621 and batch: 950, loss is 3.8559803199768066 and perplexity is 47.274938799350906
At time: 611.8100078105927 and batch: 1000, loss is 3.802741780281067 and perplexity is 44.823913490574064
At time: 613.0867211818695 and batch: 1050, loss is 3.756000838279724 and perplexity is 42.77701126368318
At time: 614.3539361953735 and batch: 1100, loss is 3.7606172704696657 and perplexity is 42.9749449576876
At time: 615.6363594532013 and batch: 1150, loss is 3.7452392292022707 and perplexity is 42.319129979665355
At time: 616.9090485572815 and batch: 1200, loss is 3.787029504776001 and perplexity is 44.12513191287926
At time: 618.1792178153992 and batch: 1250, loss is 3.7736753320693968 and perplexity is 43.53979432897659
At time: 619.4581639766693 and batch: 1300, loss is 3.7601729965209962 and perplexity is 42.955856549752546
At time: 620.7287349700928 and batch: 1350, loss is 3.636842350959778 and perplexity is 37.971745776041274
At time: 622.0120279788971 and batch: 1400, loss is 3.6650012063980104 and perplexity is 39.056183280372736
At time: 623.286821603775 and batch: 1450, loss is 3.600974984169006 and perplexity is 36.63393454356223
At time: 624.5601522922516 and batch: 1500, loss is 3.581512622833252 and perplexity is 35.92784504458806
At time: 625.8326256275177 and batch: 1550, loss is 3.6140007638931273 and perplexity is 37.11424150050668
At time: 627.101455450058 and batch: 1600, loss is 3.691196150779724 and perplexity is 40.09277529124106
At time: 628.3752648830414 and batch: 1650, loss is 3.63930326461792 and perplexity is 38.06530603849141
At time: 629.6499285697937 and batch: 1700, loss is 3.62424298286438 and perplexity is 37.49632705068639
At time: 630.9259979724884 and batch: 1750, loss is 3.6179955911636354 and perplexity is 37.262803025823466
At time: 632.199227809906 and batch: 1800, loss is 3.5715798854827883 and perplexity is 35.57274965028459
At time: 633.4751040935516 and batch: 1850, loss is 3.5981623983383177 and perplexity is 36.5310432215079
At time: 634.755108833313 and batch: 1900, loss is 3.708353810310364 and perplexity is 40.78660873723265
At time: 636.023238658905 and batch: 1950, loss is 3.6459468460083007 and perplexity is 38.31903790822187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310208200853924 and perplexity of 74.45598912722943
finished 12 epochs...
Completing Train Step...
At time: 640.0865340232849 and batch: 50, loss is 3.8877135944366454 and perplexity is 48.79918414780404
At time: 641.3619809150696 and batch: 100, loss is 3.8623567533493044 and perplexity is 47.57734741635984
At time: 642.6565816402435 and batch: 150, loss is 3.8277593660354614 and perplexity is 45.959444487360734
At time: 643.9364945888519 and batch: 200, loss is 3.835188374519348 and perplexity is 46.30214899154814
At time: 645.2072093486786 and batch: 250, loss is 3.824797396659851 and perplexity is 45.82351542850233
At time: 646.4849035739899 and batch: 300, loss is 3.8313842391967774 and perplexity is 46.12634395614369
At time: 647.7615869045258 and batch: 350, loss is 3.8570035028457643 and perplexity is 47.32333446144549
At time: 649.0322301387787 and batch: 400, loss is 3.813851137161255 and perplexity is 45.32465464840012
At time: 650.3043835163116 and batch: 450, loss is 3.8445494270324705 and perplexity is 46.737620897414146
At time: 651.5853803157806 and batch: 500, loss is 3.835646162033081 and perplexity is 46.32335038971288
At time: 652.8597319126129 and batch: 550, loss is 3.811781854629517 and perplexity is 45.23096210388406
At time: 654.1324026584625 and batch: 600, loss is 3.7651254749298095 and perplexity is 43.1691221626211
At time: 655.4147853851318 and batch: 650, loss is 3.7885602855682374 and perplexity is 44.19272954264295
At time: 656.6836864948273 and batch: 700, loss is 3.848323254585266 and perplexity is 46.9143338512906
At time: 657.9641468524933 and batch: 750, loss is 3.780298800468445 and perplexity is 43.82913594555058
At time: 659.2366416454315 and batch: 800, loss is 3.7805990171432495 and perplexity is 43.84229615836253
At time: 660.5086472034454 and batch: 850, loss is 3.7784790992736816 and perplexity is 43.7494525364904
At time: 661.7859389781952 and batch: 900, loss is 3.721044993400574 and perplexity is 41.30753766657354
At time: 663.0614190101624 and batch: 950, loss is 3.8475852155685426 and perplexity is 46.87972201647812
At time: 664.3356037139893 and batch: 1000, loss is 3.794343280792236 and perplexity is 44.449036282544036
At time: 665.6093859672546 and batch: 1050, loss is 3.748597707748413 and perplexity is 42.46149680393856
At time: 666.8832247257233 and batch: 1100, loss is 3.753625998497009 and perplexity is 42.67554324837706
At time: 668.15842461586 and batch: 1150, loss is 3.7387909364700316 and perplexity is 42.047121778155876
At time: 669.4307231903076 and batch: 1200, loss is 3.780946717262268 and perplexity is 43.85754278042738
At time: 670.705705165863 and batch: 1250, loss is 3.7684058809280394 and perplexity is 43.31096693692587
At time: 671.9797964096069 and batch: 1300, loss is 3.755452136993408 and perplexity is 42.75354590090415
At time: 673.2557113170624 and batch: 1350, loss is 3.6326483058929444 and perplexity is 37.8128240583661
At time: 674.528938293457 and batch: 1400, loss is 3.6613423728942873 and perplexity is 38.91354431370042
At time: 675.7999243736267 and batch: 1450, loss is 3.5980877590179445 and perplexity is 36.52831667102453
At time: 677.0788052082062 and batch: 1500, loss is 3.5791932201385497 and perplexity is 35.844610468541035
At time: 678.351357460022 and batch: 1550, loss is 3.6123269605636597 and perplexity is 37.05217152047344
At time: 679.6227397918701 and batch: 1600, loss is 3.690434398651123 and perplexity is 40.06224616361167
At time: 680.8958368301392 and batch: 1650, loss is 3.6388319444656374 and perplexity is 38.04736931995316
At time: 682.1725568771362 and batch: 1700, loss is 3.62433669090271 and perplexity is 37.499840922575345
At time: 683.4471352100372 and batch: 1750, loss is 3.6185134553909304 and perplexity is 37.28210509601374
At time: 684.7188429832458 and batch: 1800, loss is 3.572663526535034 and perplexity is 35.61131863584073
At time: 685.9904506206512 and batch: 1850, loss is 3.599392638206482 and perplexity is 36.57601282333138
At time: 687.2646622657776 and batch: 1900, loss is 3.7095582771301268 and perplexity is 40.83576445141798
At time: 688.5471475124359 and batch: 1950, loss is 3.6466536855697633 and perplexity is 38.34613289494875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310183219022529 and perplexity of 74.45412910349623
finished 13 epochs...
Completing Train Step...
At time: 692.6522862911224 and batch: 50, loss is 3.8814915370941163 and perplexity is 48.496495475429406
At time: 693.9264736175537 and batch: 100, loss is 3.855215983390808 and perplexity is 47.23881863976394
At time: 695.197324514389 and batch: 150, loss is 3.820082788467407 and perplexity is 45.60798397965128
At time: 696.4666166305542 and batch: 200, loss is 3.8269576358795168 and perplexity is 45.9226121815228
At time: 697.7420973777771 and batch: 250, loss is 3.8162663984298706 and perplexity is 45.434257838174645
At time: 699.0180673599243 and batch: 300, loss is 3.822557029724121 and perplexity is 45.720968853527566
At time: 700.2883110046387 and batch: 350, loss is 3.8477593088150024 and perplexity is 46.887884169944385
At time: 701.5634543895721 and batch: 400, loss is 3.8045863246917726 and perplexity is 44.90666948976323
At time: 702.837230682373 and batch: 450, loss is 3.83557071685791 and perplexity is 46.31985564826058
At time: 704.1129627227783 and batch: 500, loss is 3.826592197418213 and perplexity is 45.90583335878845
At time: 705.403401851654 and batch: 550, loss is 3.802918357849121 and perplexity is 44.83182908704671
At time: 706.6794834136963 and batch: 600, loss is 3.7568796348571776 and perplexity is 42.81462007760348
At time: 707.9605555534363 and batch: 650, loss is 3.7805585765838625 and perplexity is 43.84052318723129
At time: 709.2435719966888 and batch: 700, loss is 3.8407878637313844 and perplexity is 46.56214461734037
At time: 710.5152876377106 and batch: 750, loss is 3.7732686233520507 and perplexity is 43.52208991558521
At time: 711.7886345386505 and batch: 800, loss is 3.773544454574585 and perplexity is 43.534096322648715
At time: 713.0693888664246 and batch: 850, loss is 3.7714519453048707 and perplexity is 43.443096065190524
At time: 714.3421726226807 and batch: 900, loss is 3.7144062232971193 and perplexity is 41.034214688525346
At time: 715.6164677143097 and batch: 950, loss is 3.8411246967315673 and perplexity is 46.57783092589166
At time: 716.8936111927032 and batch: 1000, loss is 3.7879582691192626 and perplexity is 44.16613279917498
At time: 718.1703245639801 and batch: 1050, loss is 3.7429118824005125 and perplexity is 42.22075321068848
At time: 719.4427728652954 and batch: 1100, loss is 3.748176627159119 and perplexity is 42.44362085571358
At time: 720.7166023254395 and batch: 1150, loss is 3.7336891078948975 and perplexity is 41.83315085636187
At time: 721.9891481399536 and batch: 1200, loss is 3.7761406564712523 and perplexity is 43.64726646879893
At time: 723.2629754543304 and batch: 1250, loss is 3.7641544008255003 and perplexity is 43.12722209331195
At time: 724.5364520549774 and batch: 1300, loss is 3.751474447250366 and perplexity is 42.583823335528535
At time: 725.8075296878815 and batch: 1350, loss is 3.6289064836502076 and perplexity is 37.67159957547584
At time: 727.0828673839569 and batch: 1400, loss is 3.6578822803497313 and perplexity is 38.77913252185859
At time: 728.3588826656342 and batch: 1450, loss is 3.59495231628418 and perplexity is 36.41396359338864
At time: 729.6290316581726 and batch: 1500, loss is 3.5763356924057006 and perplexity is 35.74232970471109
At time: 730.896568775177 and batch: 1550, loss is 3.6098236083984374 and perplexity is 36.95953288861007
At time: 732.1731061935425 and batch: 1600, loss is 3.6885534858703615 and perplexity is 39.98696339513204
At time: 733.4332528114319 and batch: 1650, loss is 3.6370729398727417 and perplexity is 37.980502649203245
At time: 734.6851553916931 and batch: 1700, loss is 3.622879104614258 and perplexity is 37.4452214845696
At time: 735.9346966743469 and batch: 1750, loss is 3.617252836227417 and perplexity is 37.235136171057114
At time: 737.1876299381256 and batch: 1800, loss is 3.571865510940552 and perplexity is 35.58291158437182
At time: 738.4410674571991 and batch: 1850, loss is 3.598713126182556 and perplexity is 36.55116742516006
At time: 739.695374250412 and batch: 1900, loss is 3.70895254611969 and perplexity is 40.81103645256881
At time: 740.9587469100952 and batch: 1950, loss is 3.6457869625091552 and perplexity is 38.312911816100794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3106345952943315 and perplexity of 74.48774351651474
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 744.9291336536407 and batch: 50, loss is 3.8802407598495483 and perplexity is 48.43587508165509
At time: 746.2026071548462 and batch: 100, loss is 3.860667042732239 and perplexity is 47.497023348624886
At time: 747.460245847702 and batch: 150, loss is 3.8283238410949707 and perplexity is 45.98539477097765
At time: 748.7170736789703 and batch: 200, loss is 3.8378596544265746 and perplexity is 46.42600033897106
At time: 749.988710641861 and batch: 250, loss is 3.830303068161011 and perplexity is 46.076500438611546
At time: 751.2602746486664 and batch: 300, loss is 3.8364454984664915 and perplexity is 46.36039313423233
At time: 752.5353412628174 and batch: 350, loss is 3.864906768798828 and perplexity is 47.698825206613314
At time: 753.8098208904266 and batch: 400, loss is 3.8228187942504883 and perplexity is 45.732938547836895
At time: 755.0815124511719 and batch: 450, loss is 3.858035159111023 and perplexity is 47.3721810680571
At time: 756.3535001277924 and batch: 500, loss is 3.855916213989258 and perplexity is 47.27190828985081
At time: 757.6290924549103 and batch: 550, loss is 3.8425007247924805 and perplexity is 46.641967444967186
At time: 758.904675245285 and batch: 600, loss is 3.79284215927124 and perplexity is 44.382362932513026
At time: 760.1780135631561 and batch: 650, loss is 3.8084518623352053 and perplexity is 45.08059385012786
At time: 761.457216501236 and batch: 700, loss is 3.8659568881988524 and perplexity is 47.74894097748733
At time: 762.7298324108124 and batch: 750, loss is 3.795741949081421 and perplexity is 44.511249237578824
At time: 764.0093598365784 and batch: 800, loss is 3.7907258462905884 and perplexity is 44.28853528108474
At time: 765.2841055393219 and batch: 850, loss is 3.784004421234131 and perplexity is 43.99185139653393
At time: 766.5576274394989 and batch: 900, loss is 3.723245716094971 and perplexity is 41.39854420551373
At time: 767.8318145275116 and batch: 950, loss is 3.8479557704925536 and perplexity is 46.8970967472548
At time: 769.1305470466614 and batch: 1000, loss is 3.7934941482543945 and perplexity is 44.411309179483055
At time: 770.4017763137817 and batch: 1050, loss is 3.74634889125824 and perplexity is 42.36611597691322
At time: 771.6780850887299 and batch: 1100, loss is 3.749165167808533 and perplexity is 42.485598845293865
At time: 772.9534571170807 and batch: 1150, loss is 3.736239013671875 and perplexity is 41.93995756504983
At time: 774.2238528728485 and batch: 1200, loss is 3.782595810890198 and perplexity is 43.92992764306684
At time: 775.5030584335327 and batch: 1250, loss is 3.7668285274505617 and perplexity is 43.24270408409256
At time: 776.777271270752 and batch: 1300, loss is 3.752597222328186 and perplexity is 42.63166224222847
At time: 778.0516700744629 and batch: 1350, loss is 3.6252997159957885 and perplexity is 37.53597160495476
At time: 779.3305821418762 and batch: 1400, loss is 3.6534294176101683 and perplexity is 38.60683825363032
At time: 780.6024219989777 and batch: 1450, loss is 3.5871812295913696 and perplexity is 36.13208419863401
At time: 781.8784039020538 and batch: 1500, loss is 3.5675252580642702 and perplexity is 35.42880741746326
At time: 783.1498537063599 and batch: 1550, loss is 3.601952862739563 and perplexity is 36.66977560435414
At time: 784.4332156181335 and batch: 1600, loss is 3.6813726806640625 and perplexity is 39.70085328011517
At time: 785.7023673057556 and batch: 1650, loss is 3.6291422748565676 and perplexity is 37.68048325469081
At time: 786.9746749401093 and batch: 1700, loss is 3.6137527513504026 and perplexity is 37.10503784445908
At time: 788.2515819072723 and batch: 1750, loss is 3.607027778625488 and perplexity is 36.85634464176781
At time: 789.5254702568054 and batch: 1800, loss is 3.561462607383728 and perplexity is 35.2146647261435
At time: 790.7984046936035 and batch: 1850, loss is 3.5887259578704835 and perplexity is 36.187941582011646
At time: 792.0812993049622 and batch: 1900, loss is 3.6980046606063843 and perplexity is 40.366678724815365
At time: 793.3584561347961 and batch: 1950, loss is 3.639185752868652 and perplexity is 38.060833180604234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.305580316587936 and perplexity of 74.11221152169064
finished 15 epochs...
Completing Train Step...
At time: 797.4310743808746 and batch: 50, loss is 3.883659520149231 and perplexity is 48.60174910867361
At time: 798.7219803333282 and batch: 100, loss is 3.858894248008728 and perplexity is 47.41289546901361
At time: 799.9933547973633 and batch: 150, loss is 3.8228654766082766 and perplexity is 45.735073519069246
At time: 801.2865102291107 and batch: 200, loss is 3.829935793876648 and perplexity is 46.05958083214537
At time: 802.5599212646484 and batch: 250, loss is 3.8210212850570677 and perplexity is 45.650807008567654
At time: 803.834766626358 and batch: 300, loss is 3.825300168991089 and perplexity is 45.84656001678509
At time: 805.1173613071442 and batch: 350, loss is 3.8517586612701415 and perplexity is 47.075780826645676
At time: 806.3921194076538 and batch: 400, loss is 3.810141096115112 and perplexity is 45.15680986728954
At time: 807.673565864563 and batch: 450, loss is 3.8445197486877443 and perplexity is 46.73623382277261
At time: 808.9431977272034 and batch: 500, loss is 3.8416346597671507 and perplexity is 46.60158995554006
At time: 810.2150635719299 and batch: 550, loss is 3.8270281600952147 and perplexity is 45.92585095193424
At time: 811.4877488613129 and batch: 600, loss is 3.7792557287216186 and perplexity is 43.78344284689092
At time: 812.7601327896118 and batch: 650, loss is 3.7969484996795653 and perplexity is 44.56498672394964
At time: 814.0305669307709 and batch: 700, loss is 3.854563694000244 and perplexity is 47.20801530697821
At time: 815.3045704364777 and batch: 750, loss is 3.785563282966614 and perplexity is 44.0604820891993
At time: 816.5813765525818 and batch: 800, loss is 3.7811817359924316 and perplexity is 43.86785133574408
At time: 817.8499467372894 and batch: 850, loss is 3.7754518795013428 and perplexity is 43.617213587909966
At time: 819.1412217617035 and batch: 900, loss is 3.715907883644104 and perplexity is 41.09588043050458
At time: 820.4122383594513 and batch: 950, loss is 3.8413965940475463 and perplexity is 46.59049703496703
At time: 821.6925888061523 and batch: 1000, loss is 3.787311110496521 and perplexity is 44.13755955220967
At time: 822.9621300697327 and batch: 1050, loss is 3.7411998510360718 and perplexity is 42.14853179726434
At time: 824.2384278774261 and batch: 1100, loss is 3.744848971366882 and perplexity is 42.30261782981147
At time: 825.5102939605713 and batch: 1150, loss is 3.7321965217590334 and perplexity is 41.7707578504253
At time: 826.7842755317688 and batch: 1200, loss is 3.7783827114105226 and perplexity is 43.74523582346928
At time: 828.0563225746155 and batch: 1250, loss is 3.763319239616394 and perplexity is 43.0912189466715
At time: 829.336621761322 and batch: 1300, loss is 3.7497233533859253 and perplexity is 42.50932031369104
At time: 830.6222305297852 and batch: 1350, loss is 3.6237673997879027 and perplexity is 37.47849867188469
At time: 831.891939163208 and batch: 1400, loss is 3.6535358381271363 and perplexity is 38.61094703194106
At time: 833.1734392642975 and batch: 1450, loss is 3.588158278465271 and perplexity is 36.16740426271663
At time: 834.4524202346802 and batch: 1500, loss is 3.569702968597412 and perplexity is 35.50604517476723
At time: 835.7243778705597 and batch: 1550, loss is 3.605268607139587 and perplexity is 36.79156500714856
At time: 836.997035741806 and batch: 1600, loss is 3.6849367094039915 and perplexity is 39.84260070811563
At time: 838.2722856998444 and batch: 1650, loss is 3.632864546775818 and perplexity is 37.82100162095424
At time: 839.5535922050476 and batch: 1700, loss is 3.6183873462677 and perplexity is 37.27740377887362
At time: 840.8255333900452 and batch: 1750, loss is 3.6122466278076173 and perplexity is 37.04919513696999
At time: 842.0972151756287 and batch: 1800, loss is 3.566739740371704 and perplexity is 35.4009883900099
At time: 843.3788769245148 and batch: 1850, loss is 3.5939502573013304 and perplexity is 36.37749292999841
At time: 844.6503930091858 and batch: 1900, loss is 3.7029600715637208 and perplexity is 40.56720865062287
At time: 845.9202795028687 and batch: 1950, loss is 3.6429660511016846 and perplexity is 38.2049867811546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304566849109738 and perplexity of 74.03713925365282
finished 16 epochs...
Completing Train Step...
At time: 849.9846498966217 and batch: 50, loss is 3.883306174278259 and perplexity is 48.58457891499121
At time: 851.2911853790283 and batch: 100, loss is 3.8568378925323485 and perplexity is 47.31549787812087
At time: 852.5701560974121 and batch: 150, loss is 3.8199277448654176 and perplexity is 45.60091330168145
At time: 853.8409569263458 and batch: 200, loss is 3.826049942970276 and perplexity is 45.880947464316655
At time: 855.1158220767975 and batch: 250, loss is 3.816564793586731 and perplexity is 45.44781722359596
At time: 856.3935432434082 and batch: 300, loss is 3.8201893615722655 and perplexity is 45.61284482312332
At time: 857.6692562103271 and batch: 350, loss is 3.8459286880493164 and perplexity is 46.8021287522964
At time: 858.9473288059235 and batch: 400, loss is 3.8041609287261964 and perplexity is 44.88757043635297
At time: 860.2218358516693 and batch: 450, loss is 3.8382207345962525 and perplexity is 46.44276687390039
At time: 861.4934713840485 and batch: 500, loss is 3.835286464691162 and perplexity is 46.306691000057626
At time: 862.7668831348419 and batch: 550, loss is 3.820084614753723 and perplexity is 45.608067272964384
At time: 864.0386164188385 and batch: 600, loss is 3.773321132659912 and perplexity is 43.52437529040456
At time: 865.3554382324219 and batch: 650, loss is 3.7917110681533814 and perplexity is 44.33219081597722
At time: 866.6301438808441 and batch: 700, loss is 3.849402332305908 and perplexity is 46.964985387285374
At time: 867.9095258712769 and batch: 750, loss is 3.7809512567520143 and perplexity is 43.85774187174502
At time: 869.1821382045746 and batch: 800, loss is 3.7768981409072877 and perplexity is 43.68034111900945
At time: 870.4552874565125 and batch: 850, loss is 3.771501178741455 and perplexity is 43.44523497075809
At time: 871.7275214195251 and batch: 900, loss is 3.7124562883377075 and perplexity is 40.954278599187795
At time: 873.007556438446 and batch: 950, loss is 3.8383329343795776 and perplexity is 46.447978034620746
At time: 874.2847144603729 and batch: 1000, loss is 3.784306092262268 and perplexity is 44.00512446552389
At time: 875.5610175132751 and batch: 1050, loss is 3.7386584949493407 and perplexity is 42.04155336215978
At time: 876.8357083797455 and batch: 1100, loss is 3.742468876838684 and perplexity is 42.20205332457416
At time: 878.1067588329315 and batch: 1150, loss is 3.7300261640548706 and perplexity is 41.680198672768256
At time: 879.3829276561737 and batch: 1200, loss is 3.776202459335327 and perplexity is 43.64996407823488
At time: 880.6550843715668 and batch: 1250, loss is 3.761571478843689 and perplexity is 43.01597158090019
At time: 881.9344968795776 and batch: 1300, loss is 3.7482985639572144 and perplexity is 42.44879661049138
At time: 883.210821390152 and batch: 1350, loss is 3.6228576707839966 and perplexity is 37.44441889864948
At time: 884.4842343330383 and batch: 1400, loss is 3.6533175039291383 and perplexity is 38.60251786200841
At time: 885.7582461833954 and batch: 1450, loss is 3.5884482145309446 and perplexity is 36.17789201792997
At time: 887.0353014469147 and batch: 1500, loss is 3.5705643272399903 and perplexity is 35.536641789079646
At time: 888.3134725093842 and batch: 1550, loss is 3.6067489051818846 and perplexity is 36.846067819051996
At time: 889.5862340927124 and batch: 1600, loss is 3.686500434875488 and perplexity is 39.90495233540209
At time: 890.8591520786285 and batch: 1650, loss is 3.634570736885071 and perplexity is 37.8855865212333
At time: 892.1367430686951 and batch: 1700, loss is 3.6205356693267823 and perplexity is 37.35757376968045
At time: 893.4093382358551 and batch: 1750, loss is 3.614576997756958 and perplexity is 37.13563414628118
At time: 894.6793830394745 and batch: 1800, loss is 3.569069938659668 and perplexity is 35.483575897813544
At time: 895.9528968334198 and batch: 1850, loss is 3.5962827157974244 and perplexity is 36.46244095280601
At time: 897.2323155403137 and batch: 1900, loss is 3.7050831747055053 and perplexity is 40.65342851320619
At time: 898.5077860355377 and batch: 1950, loss is 3.644354362487793 and perplexity is 38.258064034661565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304179630723111 and perplexity of 74.00847626181735
finished 17 epochs...
Completing Train Step...
At time: 902.5914418697357 and batch: 50, loss is 3.8820196056365965 and perplexity is 48.52211171207962
At time: 903.8634173870087 and batch: 100, loss is 3.85469407081604 and perplexity is 47.214170538935036
At time: 905.1342833042145 and batch: 150, loss is 3.8173490858078 and perplexity is 45.48347557456481
At time: 906.4073951244354 and batch: 200, loss is 3.8230325603485107 and perplexity is 45.74271574464073
At time: 907.6794242858887 and batch: 250, loss is 3.813252806663513 and perplexity is 45.29754363670574
At time: 908.9530484676361 and batch: 300, loss is 3.816615996360779 and perplexity is 45.450144337489064
At time: 910.2223773002625 and batch: 350, loss is 3.842052450180054 and perplexity is 46.62106372074247
At time: 911.4971616268158 and batch: 400, loss is 3.80022714138031 and perplexity is 44.711339135274166
At time: 912.7737181186676 and batch: 450, loss is 3.834198274612427 and perplexity is 46.256327925601106
At time: 914.0455412864685 and batch: 500, loss is 3.831272144317627 and perplexity is 46.121173718976245
At time: 915.3174057006836 and batch: 550, loss is 3.815830488204956 and perplexity is 45.414456896651565
At time: 916.5937759876251 and batch: 600, loss is 3.7696893930435182 and perplexity is 43.36659277830668
At time: 917.8662831783295 and batch: 650, loss is 3.7884037590026853 and perplexity is 44.18581274781046
At time: 919.1415495872498 and batch: 700, loss is 3.846185884475708 and perplexity is 46.814167640672174
At time: 920.4146664142609 and batch: 750, loss is 3.7780218601226805 and perplexity is 43.729453146556324
At time: 921.6911616325378 and batch: 800, loss is 3.7741613292694094 and perplexity is 43.560959689846065
At time: 922.9661984443665 and batch: 850, loss is 3.768868112564087 and perplexity is 43.33099126361404
At time: 924.2383170127869 and batch: 900, loss is 3.7100936555862427 and perplexity is 40.8576328933683
At time: 925.5092415809631 and batch: 950, loss is 3.836180362701416 and perplexity is 46.34810296528316
At time: 926.795487165451 and batch: 1000, loss is 3.782165470123291 and perplexity is 43.911026871492716
At time: 928.0925784111023 and batch: 1050, loss is 3.7367782402038574 and perplexity is 41.9625788013564
At time: 929.3665308952332 and batch: 1100, loss is 3.74070472240448 and perplexity is 42.12766801794544
At time: 930.6353621482849 and batch: 1150, loss is 3.7284165048599243 and perplexity is 41.613161725521124
At time: 931.9193994998932 and batch: 1200, loss is 3.7746230602264403 and perplexity is 43.58107777766739
At time: 933.199390411377 and batch: 1250, loss is 3.7602725505828856 and perplexity is 42.960133192629065
At time: 934.4708113670349 and batch: 1300, loss is 3.7472133255004882 and perplexity is 42.40275453180395
At time: 935.7450115680695 and batch: 1350, loss is 3.6220085859298705 and perplexity is 37.41263890355663
At time: 937.0209777355194 and batch: 1400, loss is 3.652842321395874 and perplexity is 38.58417897728428
At time: 938.2936794757843 and batch: 1450, loss is 3.588262929916382 and perplexity is 36.17118943211393
At time: 939.574319601059 and batch: 1500, loss is 3.5707283449172973 and perplexity is 35.5424709045511
At time: 940.8507738113403 and batch: 1550, loss is 3.6072515487670898 and perplexity is 36.86459291405133
At time: 942.1208639144897 and batch: 1600, loss is 3.6870911073684693 and perplexity is 39.92853005575026
At time: 943.392331123352 and batch: 1650, loss is 3.6352506113052367 and perplexity is 37.911352720299405
At time: 944.6690027713776 and batch: 1700, loss is 3.6214530086517334 and perplexity is 37.39185906440441
At time: 945.9435231685638 and batch: 1750, loss is 3.615593628883362 and perplexity is 37.17340658491818
At time: 947.2174224853516 and batch: 1800, loss is 3.5700963878631593 and perplexity is 35.52001668513995
At time: 948.489538192749 and batch: 1850, loss is 3.5973516273498536 and perplexity is 36.50143691507454
At time: 949.7644534111023 and batch: 1900, loss is 3.7060008430480957 and perplexity is 40.69075200024254
At time: 951.0366747379303 and batch: 1950, loss is 3.6448316383361816 and perplexity is 38.2763280427697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304024062045785 and perplexity of 73.99696375657021
finished 18 epochs...
Completing Train Step...
At time: 955.1180024147034 and batch: 50, loss is 3.8804559659957887 and perplexity is 48.4462999013736
At time: 956.3928563594818 and batch: 100, loss is 3.852628078460693 and perplexity is 47.116727116880085
At time: 957.6664865016937 and batch: 150, loss is 3.815020651817322 and perplexity is 45.377693505107345
At time: 958.9381721019745 and batch: 200, loss is 3.820464987754822 and perplexity is 45.62541865017582
At time: 960.223025560379 and batch: 250, loss is 3.8105130338668824 and perplexity is 45.17360851346039
At time: 961.4948308467865 and batch: 300, loss is 3.8137415838241577 and perplexity is 45.319689453212426
At time: 962.7697718143463 and batch: 350, loss is 3.8390134239196776 and perplexity is 46.479596154511924
At time: 964.0418696403503 and batch: 400, loss is 3.7971608066558837 and perplexity is 44.57444918596848
At time: 965.3153614997864 and batch: 450, loss is 3.8311329221725465 and perplexity is 46.114753077195594
At time: 966.587206363678 and batch: 500, loss is 3.8282296800613405 and perplexity is 45.98106494252787
At time: 967.8564279079437 and batch: 550, loss is 3.812676429748535 and perplexity is 45.27144270095933
At time: 969.1326413154602 and batch: 600, loss is 3.7669576168060304 and perplexity is 43.248286617206546
At time: 970.407692193985 and batch: 650, loss is 3.785865697860718 and perplexity is 44.073808650198174
At time: 971.6795954704285 and batch: 700, loss is 3.8437426471710205 and perplexity is 46.69992913262486
At time: 972.9497907161713 and batch: 750, loss is 3.77575475692749 and perplexity is 43.630426258105956
At time: 974.2242290973663 and batch: 800, loss is 3.772035908699036 and perplexity is 43.468472651799466
At time: 975.4942924976349 and batch: 850, loss is 3.766769070625305 and perplexity is 43.24013308662464
At time: 976.7683289051056 and batch: 900, loss is 3.7081681585311888 and perplexity is 40.77903733359808
At time: 978.048525094986 and batch: 950, loss is 3.834382209777832 and perplexity is 46.26483687345252
At time: 979.3229379653931 and batch: 1000, loss is 3.7803785371780396 and perplexity is 43.83263087597053
At time: 980.5987792015076 and batch: 1050, loss is 3.735177073478699 and perplexity is 41.89544347824365
At time: 981.8723707199097 and batch: 1100, loss is 3.739206762313843 and perplexity is 42.064609693760765
At time: 983.1446409225464 and batch: 1150, loss is 3.7270398855209352 and perplexity is 41.555915654398085
At time: 984.4167516231537 and batch: 1200, loss is 3.7732840251922606 and perplexity is 43.5227602410218
At time: 985.6871554851532 and batch: 1250, loss is 3.7591367673873903 and perplexity is 42.911367494145395
At time: 986.9612510204315 and batch: 1300, loss is 3.7462363386154176 and perplexity is 42.36134782693288
At time: 988.2380454540253 and batch: 1350, loss is 3.6211523532867433 and perplexity is 37.380618691193675
At time: 989.5124526023865 and batch: 1400, loss is 3.6522261905670166 and perplexity is 38.560413397215314
At time: 990.7894916534424 and batch: 1450, loss is 3.5878197526931763 and perplexity is 36.15516273641691
At time: 992.0646576881409 and batch: 1500, loss is 3.570524868965149 and perplexity is 35.53523960216511
At time: 993.3417916297913 and batch: 1550, loss is 3.6072542381286623 and perplexity is 36.864692056404216
At time: 994.6242680549622 and batch: 1600, loss is 3.6871951103210447 and perplexity is 39.93268295672129
At time: 995.894350528717 and batch: 1650, loss is 3.635410122871399 and perplexity is 37.91740050187988
At time: 997.1661722660065 and batch: 1700, loss is 3.6217552852630615 and perplexity is 37.40316345729437
At time: 998.4389290809631 and batch: 1750, loss is 3.6159690856933593 and perplexity is 37.18736621402621
At time: 999.7139387130737 and batch: 1800, loss is 3.570490026473999 and perplexity is 35.534001487463385
At time: 1000.9920489788055 and batch: 1850, loss is 3.59780179977417 and perplexity is 36.51787255457992
At time: 1002.2631981372833 and batch: 1900, loss is 3.706342730522156 and perplexity is 40.70466603704343
At time: 1003.5416834354401 and batch: 1950, loss is 3.6448885726928713 and perplexity is 38.27850734292119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303993118640989 and perplexity of 73.9946740739925
finished 19 epochs...
Completing Train Step...
At time: 1007.6397187709808 and batch: 50, loss is 3.8788281297683715 and perplexity is 48.367501412227824
At time: 1008.9092347621918 and batch: 100, loss is 3.8506742477416993 and perplexity is 47.02475888249847
At time: 1010.1825091838837 and batch: 150, loss is 3.8128918552398683 and perplexity is 45.28119637430376
At time: 1011.4558563232422 and batch: 200, loss is 3.818188714981079 and perplexity is 45.521680864452826
At time: 1012.7313230037689 and batch: 250, loss is 3.8081202793121336 and perplexity is 45.06564836850809
At time: 1014.0020792484283 and batch: 300, loss is 3.8112568998336793 and perplexity is 45.207224124635445
At time: 1015.2792239189148 and batch: 350, loss is 3.83642080783844 and perplexity is 46.35924848114029
At time: 1016.5569698810577 and batch: 400, loss is 3.794546375274658 and perplexity is 44.45806455332695
At time: 1017.8306927680969 and batch: 450, loss is 3.8285534954071045 and perplexity is 45.99595672793504
At time: 1019.1091918945312 and batch: 500, loss is 3.8256718254089357 and perplexity is 45.863602351801944
At time: 1020.3887436389923 and batch: 550, loss is 3.810057530403137 and perplexity is 45.153036463988215
At time: 1021.6644902229309 and batch: 600, loss is 3.76464732170105 and perplexity is 43.148485641579086
At time: 1022.9364624023438 and batch: 650, loss is 3.7836978960037233 and perplexity is 43.978368850624356
At time: 1024.227581501007 and batch: 700, loss is 3.8416684007644655 and perplexity is 46.60316236618881
At time: 1025.5026803016663 and batch: 750, loss is 3.773803377151489 and perplexity is 43.545369742460245
At time: 1026.7794103622437 and batch: 800, loss is 3.770202498435974 and perplexity is 43.38885012060652
At time: 1028.0534298419952 and batch: 850, loss is 3.7649354124069214 and perplexity is 43.16091811001817
At time: 1029.3261938095093 and batch: 900, loss is 3.7064591455459595 and perplexity is 40.70940494754388
At time: 1030.6023845672607 and batch: 950, loss is 3.832760257720947 and perplexity is 46.18985834834803
At time: 1031.873381614685 and batch: 1000, loss is 3.778775062561035 and perplexity is 43.762402684572685
At time: 1033.149598121643 and batch: 1050, loss is 3.7337244081497194 and perplexity is 41.83462760331172
At time: 1034.4214262962341 and batch: 1100, loss is 3.737844786643982 and perplexity is 42.00735771554644
At time: 1035.690237045288 and batch: 1150, loss is 3.725776414871216 and perplexity is 41.50344412974248
At time: 1036.9677956104279 and batch: 1200, loss is 3.772059049606323 and perplexity is 43.46947856333383
At time: 1038.2424716949463 and batch: 1250, loss is 3.758071765899658 and perplexity is 42.865691150927525
At time: 1039.5175721645355 and batch: 1300, loss is 3.74529709815979 and perplexity is 42.321579014461264
At time: 1040.7861113548279 and batch: 1350, loss is 3.62028302192688 and perplexity is 37.34813666798068
At time: 1042.0576491355896 and batch: 1400, loss is 3.65152925491333 and perplexity is 38.53354863289134
At time: 1043.3308928012848 and batch: 1450, loss is 3.5872323369979857 and perplexity is 36.13393086294175
At time: 1044.6072435379028 and batch: 1500, loss is 3.5701142168045044 and perplexity is 35.52064997507943
At time: 1045.8762011528015 and batch: 1550, loss is 3.6069820737838745 and perplexity is 36.85466016686812
At time: 1047.1528356075287 and batch: 1600, loss is 3.687031669616699 and perplexity is 39.92615686422154
At time: 1048.4281225204468 and batch: 1650, loss is 3.635283031463623 and perplexity is 37.91258183228313
At time: 1049.7000200748444 and batch: 1700, loss is 3.6217242956161497 and perplexity is 37.40200436442548
At time: 1050.9772934913635 and batch: 1750, loss is 3.6159986782073976 and perplexity is 37.188466697965914
At time: 1052.254757642746 and batch: 1800, loss is 3.570543293952942 and perplexity is 35.53589434455279
At time: 1053.5286066532135 and batch: 1850, loss is 3.597916407585144 and perplexity is 36.5220580278542
At time: 1054.8064665794373 and batch: 1900, loss is 3.706379418373108 and perplexity is 40.70615943115858
At time: 1056.082389831543 and batch: 1950, loss is 3.644723901748657 and perplexity is 38.272204503935384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30403314634811 and perplexity of 73.99763597041344
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fbc812c5b38>
ELAPSED
6560.716993093491


RESULTS SO FAR:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}, {'best_accuracy': -75.4437429826347, 'params': {'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}}, {'best_accuracy': -76.45059048557374, 'params': {'rnn_dropout': 0.9151261589557308, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.09244881843629082}}, {'best_accuracy': -74.06398409553563, 'params': {'rnn_dropout': 0.35399849893854385, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7881908157668892}}, {'best_accuracy': -73.9946740739925, 'params': {'rnn_dropout': 0.061622740297387506, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7177030139734627}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -74.60718670643288, 'params': {'rnn_dropout': 0.45747503760342356, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8423092782277234}}, {'best_accuracy': -75.96164818377025, 'params': {'rnn_dropout': 0.9143604400228823, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.8021110645912815}}, {'best_accuracy': -75.4437429826347, 'params': {'rnn_dropout': 0.6120280864929537, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.940575456726517}}, {'best_accuracy': -76.45059048557374, 'params': {'rnn_dropout': 0.9151261589557308, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.09244881843629082}}, {'best_accuracy': -74.06398409553563, 'params': {'rnn_dropout': 0.35399849893854385, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7881908157668892}}, {'best_accuracy': -73.9946740739925, 'params': {'rnn_dropout': 0.061622740297387506, 'batch_size': 32, 'wordvec_source': 'gigavec', 'tune_wordvecs': True, 'seq_len': 35, 'data': 'wikitext', 'wordvec_dim': 300, 'num_layers': 3, 'tie_weights': True, 'dropout': 0.7177030139734627}}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7fbc7c485780>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7fbc79724550>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
