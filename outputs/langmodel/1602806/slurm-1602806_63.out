Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 30], 'name': 'lr', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [2, 8], 'name': 'anneal', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'dropout': 0.6035230574493423, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.993531646404836, 'wordvec_dim': 200, 'anneal': 4.377480264653539, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.9212501049041748 and batch: 50, loss is 7.201265411376953 and perplexity is 1341.1267681672457
At time: 3.040264368057251 and batch: 100, loss is 6.553507108688354 and perplexity is 701.7008044504701
At time: 4.109445333480835 and batch: 150, loss is 6.403771743774414 and perplexity is 604.1193294732504
At time: 5.180670261383057 and batch: 200, loss is 6.350706357955932 and perplexity is 572.8972366472326
At time: 6.2559654712677 and batch: 250, loss is 6.354562644958496 and perplexity is 575.1107580585477
At time: 7.329044342041016 and batch: 300, loss is 6.344534530639648 and perplexity is 569.3723026637407
At time: 8.400747537612915 and batch: 350, loss is 6.322850313186645 and perplexity is 557.1588084404086
At time: 9.471308708190918 and batch: 400, loss is 6.354959230422974 and perplexity is 575.3388838583569
At time: 10.541952133178711 and batch: 450, loss is 6.3159569644927975 and perplexity is 553.3313257386848
At time: 11.61459231376648 and batch: 500, loss is 6.303820295333862 and perplexity is 546.6563146384555
At time: 12.685154438018799 and batch: 550, loss is 6.257613592147827 and perplexity is 521.9718149873703
At time: 13.756488561630249 and batch: 600, loss is 6.207305784225464 and perplexity is 496.3621414600207
At time: 14.828171968460083 and batch: 650, loss is 6.23128870010376 and perplexity is 508.41024984817574
At time: 15.900005578994751 and batch: 700, loss is 6.2447141456604 and perplexity is 515.2819083027007
At time: 16.97187829017639 and batch: 750, loss is 6.225247592926025 and perplexity is 505.3481475951405
At time: 18.043906211853027 and batch: 800, loss is 6.183995876312256 and perplexity is 484.925793584243
At time: 19.117709636688232 and batch: 850, loss is 6.188145437240601 and perplexity is 486.9422034248367
At time: 20.190508365631104 and batch: 900, loss is 6.239643697738647 and perplexity is 512.6758108457877
At time: 21.263531923294067 and batch: 950, loss is 6.1992956638336185 and perplexity is 492.40210231777075
At time: 22.335673332214355 and batch: 1000, loss is 6.220393772125244 and perplexity is 502.9012215190933
At time: 23.408811330795288 and batch: 1050, loss is 6.2020919895172115 and perplexity is 493.7809459125343
At time: 24.482194662094116 and batch: 1100, loss is 6.19962929725647 and perplexity is 492.56641152458366
At time: 25.555484294891357 and batch: 1150, loss is 6.20897367477417 and perplexity is 497.1907099732135
At time: 26.628312826156616 and batch: 1200, loss is 6.1839337730407715 and perplexity is 484.8956790411498
At time: 27.701904296875 and batch: 1250, loss is 6.184472007751465 and perplexity is 485.1567369755935
At time: 28.777094841003418 and batch: 1300, loss is 6.1611587429046635 and perplexity is 473.9769742126312
At time: 29.85028839111328 and batch: 1350, loss is 6.156861114501953 and perplexity is 471.9443681272986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.600052897135416 and perplexity of 270.4407125867941
Finished 1 epochs...
Completing Train Step...
At time: 33.152079343795776 and batch: 50, loss is 5.971283779144287 and perplexity is 392.00860032104174
At time: 34.21938920021057 and batch: 100, loss is 6.0226781368255615 and perplexity is 412.68233684565496
At time: 35.285218477249146 and batch: 150, loss is 5.920516805648804 and perplexity is 372.6042280955273
At time: 36.351670026779175 and batch: 200, loss is 5.902349233627319 and perplexity is 365.8960342517209
At time: 37.418208360672 and batch: 250, loss is 5.899251441955567 and perplexity is 364.764318379116
At time: 38.48431158065796 and batch: 300, loss is 5.8856125831604 and perplexity is 359.82312208242297
At time: 39.55061411857605 and batch: 350, loss is 5.9255477142333985 and perplexity is 374.48348913688267
At time: 40.616984605789185 and batch: 400, loss is 5.894399461746215 and perplexity is 362.9987757777997
At time: 41.68362212181091 and batch: 450, loss is 5.868286151885986 and perplexity is 353.64237128735203
At time: 42.7506000995636 and batch: 500, loss is 5.915691032409668 and perplexity is 370.81045623204784
At time: 43.820897817611694 and batch: 550, loss is 5.8392538356781 and perplexity is 343.52292046405586
At time: 44.892656087875366 and batch: 600, loss is 5.795824337005615 and perplexity is 328.923215834629
At time: 45.96477651596069 and batch: 650, loss is 5.845454311370849 and perplexity is 345.65954317552826
At time: 47.0380744934082 and batch: 700, loss is 5.841903038024903 and perplexity is 344.43418872517685
At time: 48.11072850227356 and batch: 750, loss is 5.805021572113037 and perplexity is 331.96235439574
At time: 49.1835823059082 and batch: 800, loss is 5.8236281776428225 and perplexity is 338.1968686810116
At time: 50.256027936935425 and batch: 850, loss is 5.821337280273437 and perplexity is 337.42298115112953
At time: 51.32838535308838 and batch: 900, loss is 5.933927335739136 and perplexity is 377.6347035888685
At time: 52.400553941726685 and batch: 950, loss is 5.860693244934082 and perplexity is 350.9673660524958
At time: 53.472671031951904 and batch: 1000, loss is 5.90854658126831 and perplexity is 368.1706602202311
At time: 54.543715476989746 and batch: 1050, loss is 5.865841169357299 and perplexity is 352.77877803356887
At time: 55.616697788238525 and batch: 1100, loss is 5.82276554107666 and perplexity is 337.90525349257183
At time: 56.69115328788757 and batch: 1150, loss is 5.817493944168091 and perplexity is 336.12864011197274
At time: 57.76546025276184 and batch: 1200, loss is 5.845451402664184 and perplexity is 345.6585377547735
At time: 58.8388569355011 and batch: 1250, loss is 5.823236627578735 and perplexity is 338.0644735967488
At time: 59.912638902664185 and batch: 1300, loss is 5.823265018463135 and perplexity is 338.07407168238683
At time: 60.98618984222412 and batch: 1350, loss is 5.8068285655975345 and perplexity is 332.5627504997866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.54622802734375 and perplexity of 256.2690905394366
Finished 2 epochs...
Completing Train Step...
At time: 64.28835940361023 and batch: 50, loss is 5.803925361633301 and perplexity is 331.5986531669437
At time: 65.38984322547913 and batch: 100, loss is 5.860987424850464 and perplexity is 351.0706287910609
At time: 66.46415138244629 and batch: 150, loss is 5.846226491928101 and perplexity is 345.9265578326926
At time: 67.53818678855896 and batch: 200, loss is 5.783731317520141 and perplexity is 324.9694953685593
At time: 68.61862111091614 and batch: 250, loss is 5.860616006851196 and perplexity is 350.94025905284616
At time: 69.69232630729675 and batch: 300, loss is 5.804360237121582 and perplexity is 331.74288865311865
At time: 70.7666003704071 and batch: 350, loss is 5.8332837867736815 and perplexity is 341.47818149803265
At time: 71.83961725234985 and batch: 400, loss is 5.886761150360107 and perplexity is 360.23664054955736
At time: 72.91242718696594 and batch: 450, loss is 5.850545854568481 and perplexity is 347.42397169156
At time: 73.9855284690857 and batch: 500, loss is 5.8473091983795165 and perplexity is 346.30129757853683
At time: 75.05763554573059 and batch: 550, loss is 5.857761611938477 and perplexity is 349.93996525865947
At time: 76.13059711456299 and batch: 600, loss is 5.810762720108032 and perplexity is 333.8736807549427
At time: 77.20321369171143 and batch: 650, loss is 5.825579204559326 and perplexity is 338.8573439679082
At time: 78.27985644340515 and batch: 700, loss is 5.878714609146118 and perplexity is 357.34961244703464
At time: 79.35627937316895 and batch: 750, loss is 5.836150121688843 and perplexity is 342.4583764448295
At time: 80.42971587181091 and batch: 800, loss is 5.808556995391846 and perplexity is 333.1380589131034
At time: 81.50154328346252 and batch: 850, loss is 5.813553428649902 and perplexity is 334.80672621114263
At time: 82.5736448764801 and batch: 900, loss is 5.851482152938843 and perplexity is 347.74941652303676
At time: 83.6930902004242 and batch: 950, loss is 5.818057117462158 and perplexity is 336.31799209944137
At time: 84.76512551307678 and batch: 1000, loss is 5.8344050216674805 and perplexity is 341.86127347851306
At time: 85.83826661109924 and batch: 1050, loss is 5.836786584854126 and perplexity is 342.67640796423467
At time: 86.91008710861206 and batch: 1100, loss is 5.787383222579956 and perplexity is 326.1584227165453
At time: 87.98553442955017 and batch: 1150, loss is 5.818406839370727 and perplexity is 336.4356304386779
At time: 89.05802297592163 and batch: 1200, loss is 5.8451761054992675 and perplexity is 345.5633920365744
At time: 90.13056778907776 and batch: 1250, loss is 5.792990865707398 and perplexity is 327.9925404868523
At time: 91.20309042930603 and batch: 1300, loss is 5.813132257461548 and perplexity is 334.6657449551008
At time: 92.27612900733948 and batch: 1350, loss is 5.772887697219849 and perplexity is 321.46468630338694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.564669189453125 and perplexity of 261.0388350249498
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 95.45820951461792 and batch: 50, loss is 5.735294542312622 and perplexity is 309.60414885264515
At time: 96.55930161476135 and batch: 100, loss is 5.710565567016602 and perplexity is 302.0418448905334
At time: 97.63400745391846 and batch: 150, loss is 5.656103782653808 and perplexity is 286.03202573746813
At time: 98.7088406085968 and batch: 200, loss is 5.632045373916626 and perplexity is 279.2326691566896
At time: 99.78331804275513 and batch: 250, loss is 5.660443639755249 and perplexity is 287.27606137149405
At time: 100.86028146743774 and batch: 300, loss is 5.668625812530518 and perplexity is 289.63624629279093
At time: 101.93293714523315 and batch: 350, loss is 5.637696657180786 and perplexity is 280.81515940536656
At time: 103.00750422477722 and batch: 400, loss is 5.677601203918457 and perplexity is 292.247546152547
At time: 104.08136487007141 and batch: 450, loss is 5.652982864379883 and perplexity is 285.1407347080875
At time: 105.15378522872925 and batch: 500, loss is 5.673733167648315 and perplexity is 291.1193054887733
At time: 106.22611331939697 and batch: 550, loss is 5.636720743179321 and perplexity is 280.5412416413099
At time: 107.29826664924622 and batch: 600, loss is 5.585836496353149 and perplexity is 266.6232188340703
At time: 108.37164974212646 and batch: 650, loss is 5.5967363834381105 and perplexity is 269.5452779405854
At time: 109.44553518295288 and batch: 700, loss is 5.608669309616089 and perplexity is 272.78100931988075
At time: 110.56619620323181 and batch: 750, loss is 5.5732426261901855 and perplexity is 263.28645611418364
At time: 111.64069533348083 and batch: 800, loss is 5.530712509155274 and perplexity is 252.32362988662805
At time: 112.71439099311829 and batch: 850, loss is 5.529790077209473 and perplexity is 252.09098582539323
At time: 113.78750348091125 and batch: 900, loss is 5.557063388824463 and perplexity is 259.06095689747997
At time: 114.86026406288147 and batch: 950, loss is 5.522930498123169 and perplexity is 250.36766515578896
At time: 115.93419289588928 and batch: 1000, loss is 5.537832460403442 and perplexity is 254.1265726459756
At time: 117.00840616226196 and batch: 1050, loss is 5.503375606536865 and perplexity is 245.51931161822145
At time: 118.08124494552612 and batch: 1100, loss is 5.4946130275726315 and perplexity is 243.3773276204907
At time: 119.1530556678772 and batch: 1150, loss is 5.480974693298339 and perplexity is 240.0805983200135
At time: 120.22853875160217 and batch: 1200, loss is 5.471879711151123 and perplexity is 237.9069691071375
At time: 121.30582070350647 and batch: 1250, loss is 5.481754579544067 and perplexity is 240.2679069067109
At time: 122.3800458908081 and batch: 1300, loss is 5.47489218711853 and perplexity is 238.6247387230966
At time: 123.4611074924469 and batch: 1350, loss is 5.411818256378174 and perplexity is 224.03857713466527
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.325382486979167 and perplexity of 205.48694151522918
Finished 4 epochs...
Completing Train Step...
At time: 126.65154218673706 and batch: 50, loss is 5.55003737449646 and perplexity is 257.24717020956115
At time: 127.72414183616638 and batch: 100, loss is 5.567606620788574 and perplexity is 261.80674596939673
At time: 128.79696798324585 and batch: 150, loss is 5.537768573760986 and perplexity is 254.1103378710885
At time: 129.87089109420776 and batch: 200, loss is 5.498055953979492 and perplexity is 244.21670197150175
At time: 130.94364213943481 and batch: 250, loss is 5.5318813896179195 and perplexity is 252.6187384876053
At time: 132.0164225101471 and batch: 300, loss is 5.535803098678588 and perplexity is 253.61138083825725
At time: 133.08935809135437 and batch: 350, loss is 5.516300230026245 and perplexity is 248.71315140895467
At time: 134.1623055934906 and batch: 400, loss is 5.562322931289673 and perplexity is 260.42708846560896
At time: 135.23580932617188 and batch: 450, loss is 5.535917539596557 and perplexity is 253.64040601829015
At time: 136.30694556236267 and batch: 500, loss is 5.5581666851043705 and perplexity is 259.34693561811434
At time: 137.41331148147583 and batch: 550, loss is 5.5261281299591065 and perplexity is 251.16953012380978
At time: 138.48592352867126 and batch: 600, loss is 5.476617841720581 and perplexity is 239.0368781044722
At time: 139.5605411529541 and batch: 650, loss is 5.491657218933105 and perplexity is 242.65901293620132
At time: 140.63330793380737 and batch: 700, loss is 5.513964109420776 and perplexity is 248.13280563389316
At time: 141.70639634132385 and batch: 750, loss is 5.483585081100464 and perplexity is 240.70812046713957
At time: 142.77931928634644 and batch: 800, loss is 5.443881368637085 and perplexity is 231.3383525804781
At time: 143.85303831100464 and batch: 850, loss is 5.447889194488526 and perplexity is 232.26737685057273
At time: 144.92629957199097 and batch: 900, loss is 5.476530694961548 and perplexity is 239.01604772291932
At time: 146.00057554244995 and batch: 950, loss is 5.437721557617188 and perplexity is 229.91773191625288
At time: 147.073627948761 and batch: 1000, loss is 5.470651836395263 and perplexity is 237.6150284155098
At time: 148.1488115787506 and batch: 1050, loss is 5.434093933105469 and perplexity is 229.08518770816258
At time: 149.22225332260132 and batch: 1100, loss is 5.4269231414794925 and perplexity is 227.4483413186164
At time: 150.29792141914368 and batch: 1150, loss is 5.426282548904419 and perplexity is 227.30268625771114
At time: 151.3734426498413 and batch: 1200, loss is 5.41655782699585 and perplexity is 225.10294412087316
At time: 152.44564080238342 and batch: 1250, loss is 5.433785495758056 and perplexity is 229.01454017626304
At time: 153.5182876586914 and batch: 1300, loss is 5.416760368347168 and perplexity is 225.1485413928718
At time: 154.5913074016571 and batch: 1350, loss is 5.360377378463745 and perplexity is 212.8052394125028
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.288901774088542 and perplexity of 198.12571908747242
Finished 5 epochs...
Completing Train Step...
At time: 157.793927192688 and batch: 50, loss is 5.471470003128052 and perplexity is 237.80951667803393
At time: 158.86642289161682 and batch: 100, loss is 5.494062652587891 and perplexity is 243.24341568178625
At time: 159.9396858215332 and batch: 150, loss is 5.464383449554443 and perplexity is 236.13022402418747
At time: 161.01325106620789 and batch: 200, loss is 5.428076391220093 and perplexity is 227.7107973688394
At time: 162.08646774291992 and batch: 250, loss is 5.462852029800415 and perplexity is 235.76888628508837
At time: 163.15955686569214 and batch: 300, loss is 5.465419597625733 and perplexity is 236.37501669921147
At time: 164.25848007202148 and batch: 350, loss is 5.4655556392669675 and perplexity is 236.40717573186436
At time: 165.33055353164673 and batch: 400, loss is 5.505892572402954 and perplexity is 246.138053694723
At time: 166.4025433063507 and batch: 450, loss is 5.473749866485596 and perplexity is 238.35230839154352
At time: 167.47439050674438 and batch: 500, loss is 5.494575920104981 and perplexity is 243.36829667173797
At time: 168.54657363891602 and batch: 550, loss is 5.4702255916595455 and perplexity is 237.51376784294635
At time: 169.61864829063416 and batch: 600, loss is 5.427323036193847 and perplexity is 227.5393148968127
At time: 170.69107747077942 and batch: 650, loss is 5.43875244140625 and perplexity is 230.15487259014037
At time: 171.76528000831604 and batch: 700, loss is 5.464080829620361 and perplexity is 236.058777122532
At time: 172.83778023719788 and batch: 750, loss is 5.4355201911926265 and perplexity is 229.41215542452736
At time: 173.91138672828674 and batch: 800, loss is 5.392725677490234 and perplexity is 219.80167829386005
At time: 174.98455572128296 and batch: 850, loss is 5.396554470062256 and perplexity is 220.6448664933167
At time: 176.05748176574707 and batch: 900, loss is 5.42467586517334 and perplexity is 226.9377759558921
At time: 177.12998270988464 and batch: 950, loss is 5.382990121841431 and perplexity is 217.6721696179672
At time: 178.20347237586975 and batch: 1000, loss is 5.413332071304321 and perplexity is 224.37798691374235
At time: 179.27666187286377 and batch: 1050, loss is 5.377825345993042 and perplexity is 216.55083985451117
At time: 180.3500006198883 and batch: 1100, loss is 5.368341379165649 and perplexity is 214.50678705845377
At time: 181.42232418060303 and batch: 1150, loss is 5.379455471038819 and perplexity is 216.90413267974952
At time: 182.49554347991943 and batch: 1200, loss is 5.366032981872559 and perplexity is 214.01219125329675
At time: 183.56695008277893 and batch: 1250, loss is 5.388357076644898 and perplexity is 218.84354686694152
At time: 184.63828253746033 and batch: 1300, loss is 5.382289800643921 and perplexity is 217.5197825496511
At time: 185.711261510849 and batch: 1350, loss is 5.338651027679443 and perplexity is 208.23162204718633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.305909423828125 and perplexity of 201.52419000382412
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 188.8963258266449 and batch: 50, loss is 5.4106518840789795 and perplexity is 223.77741707887915
At time: 189.99543523788452 and batch: 100, loss is 5.419556579589844 and perplexity is 225.77898529196983
At time: 191.06828212738037 and batch: 150, loss is 5.386937313079834 and perplexity is 218.5330612329004
At time: 192.16781735420227 and batch: 200, loss is 5.36041220664978 and perplexity is 212.81265116203838
At time: 193.24097800254822 and batch: 250, loss is 5.3856844806671145 and perplexity is 218.25944736248823
At time: 194.31424808502197 and batch: 300, loss is 5.416233377456665 and perplexity is 225.0299214211153
At time: 195.3874957561493 and batch: 350, loss is 5.389949073791504 and perplexity is 219.19222264088364
At time: 196.46084570884705 and batch: 400, loss is 5.405067510604859 and perplexity is 222.531243195542
At time: 197.5353217124939 and batch: 450, loss is 5.371336097717285 and perplexity is 215.15013735883423
At time: 198.60909247398376 and batch: 500, loss is 5.392709369659424 and perplexity is 219.79809383450612
At time: 199.68219184875488 and batch: 550, loss is 5.359406862258911 and perplexity is 212.59880866757405
At time: 200.75537967681885 and batch: 600, loss is 5.314290561676025 and perplexity is 203.22028971435543
At time: 201.8284044265747 and batch: 650, loss is 5.3191711044311525 and perplexity is 204.21453929224313
At time: 202.90207719802856 and batch: 700, loss is 5.3326318645477295 and perplexity is 206.98200653753426
At time: 203.97548055648804 and batch: 750, loss is 5.311305112838745 and perplexity is 202.61449067768316
At time: 205.0489785671234 and batch: 800, loss is 5.280355043411255 and perplexity is 196.4396075604591
At time: 206.12240266799927 and batch: 850, loss is 5.259851579666138 and perplexity is 192.45292524998857
At time: 207.19631958007812 and batch: 900, loss is 5.281063089370727 and perplexity is 196.5787450829401
At time: 208.27572536468506 and batch: 950, loss is 5.242789268493652 and perplexity is 189.19708858931608
At time: 209.3540539741516 and batch: 1000, loss is 5.274540605545044 and perplexity is 195.30073582585504
At time: 210.42706894874573 and batch: 1050, loss is 5.234261474609375 and perplexity is 187.590514815585
At time: 211.4998071193695 and batch: 1100, loss is 5.214698114395142 and perplexity is 183.9562788438765
At time: 212.57308721542358 and batch: 1150, loss is 5.2220569896698 and perplexity is 185.31498329267262
At time: 213.64737129211426 and batch: 1200, loss is 5.197830648422241 and perplexity is 180.8794248843673
At time: 214.72198724746704 and batch: 1250, loss is 5.21855486869812 and perplexity is 184.66712290819558
At time: 215.79555702209473 and batch: 1300, loss is 5.20040638923645 and perplexity is 181.3459239339002
At time: 216.87000608444214 and batch: 1350, loss is 5.177832050323486 and perplexity is 177.29802085428773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.202294921875 and perplexity of 181.68872522394466
Finished 7 epochs...
Completing Train Step...
At time: 220.05621719360352 and batch: 50, loss is 5.343767986297608 and perplexity is 209.2998653878386
At time: 221.15760493278503 and batch: 100, loss is 5.3576827716827395 and perplexity is 212.23258485727135
At time: 222.23363280296326 and batch: 150, loss is 5.3308548259735105 and perplexity is 206.61451814497894
At time: 223.30957555770874 and batch: 200, loss is 5.307037115097046 and perplexity is 201.75157525945454
At time: 224.38358283042908 and batch: 250, loss is 5.335337419509887 and perplexity is 207.54276597307143
At time: 225.45865750312805 and batch: 300, loss is 5.364811515808105 and perplexity is 213.75094221020322
At time: 226.53333830833435 and batch: 350, loss is 5.3410294723510745 and perplexity is 208.7274788893866
At time: 227.60831832885742 and batch: 400, loss is 5.361744699478149 and perplexity is 213.0964115058239
At time: 228.68366622924805 and batch: 450, loss is 5.331822671890259 and perplexity is 206.81458596450022
At time: 229.75831413269043 and batch: 500, loss is 5.358679494857788 and perplexity is 212.4442274501161
At time: 230.83221197128296 and batch: 550, loss is 5.3256219959259035 and perplexity is 205.5361633704617
At time: 231.90644431114197 and batch: 600, loss is 5.281325216293335 and perplexity is 196.63028041854315
At time: 232.98077702522278 and batch: 650, loss is 5.2881722831726075 and perplexity is 197.98124087936242
At time: 234.0526430606842 and batch: 700, loss is 5.306345977783203 and perplexity is 201.612185391984
At time: 235.12490439414978 and batch: 750, loss is 5.285189094543457 and perplexity is 197.39150557596992
At time: 236.19848203659058 and batch: 800, loss is 5.254706163406372 and perplexity is 191.46521810053443
At time: 237.27953696250916 and batch: 850, loss is 5.237650833129883 and perplexity is 188.22740504029363
At time: 238.35210251808167 and batch: 900, loss is 5.264476919174195 and perplexity is 193.34514719262407
At time: 239.42504262924194 and batch: 950, loss is 5.229761781692505 and perplexity is 186.74831135429596
At time: 240.49730157852173 and batch: 1000, loss is 5.2637029552459715 and perplexity is 193.19556291688383
At time: 241.57052421569824 and batch: 1050, loss is 5.224465236663819 and perplexity is 185.7618053571296
At time: 242.64427042007446 and batch: 1100, loss is 5.208013210296631 and perplexity is 182.73064993158863
At time: 243.71914291381836 and batch: 1150, loss is 5.217797346115113 and perplexity is 184.52728636361087
At time: 244.79524064064026 and batch: 1200, loss is 5.195336942672729 and perplexity is 180.42892676089954
At time: 245.91696667671204 and batch: 1250, loss is 5.220031242370606 and perplexity is 184.9399619432566
At time: 246.99141716957092 and batch: 1300, loss is 5.203507528305054 and perplexity is 181.9091757732836
At time: 248.0658905506134 and batch: 1350, loss is 5.177995491027832 and perplexity is 177.3270009358932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.197708740234375 and perplexity of 180.85737554548214
Finished 8 epochs...
Completing Train Step...
At time: 251.28332114219666 and batch: 50, loss is 5.3229279136657714 and perplexity is 204.98317726840162
At time: 252.35594081878662 and batch: 100, loss is 5.33498628616333 and perplexity is 207.46990358005817
At time: 253.42826890945435 and batch: 150, loss is 5.309172124862671 and perplexity is 202.18277698902108
At time: 254.50089645385742 and batch: 200, loss is 5.284425010681153 and perplexity is 197.24073951829416
At time: 255.57561326026917 and batch: 250, loss is 5.313781223297119 and perplexity is 203.11680817722777
At time: 256.6501622200012 and batch: 300, loss is 5.341078872680664 and perplexity is 208.73779035033084
At time: 257.7252151966095 and batch: 350, loss is 5.318843231201172 and perplexity is 204.14759378705568
At time: 258.79995131492615 and batch: 400, loss is 5.3431641960144045 and perplexity is 209.17353030662701
At time: 259.8753411769867 and batch: 450, loss is 5.313659324645996 and perplexity is 203.09205002131407
At time: 260.9540784358978 and batch: 500, loss is 5.340620050430298 and perplexity is 208.642038775782
At time: 262.0285224914551 and batch: 550, loss is 5.309616184234619 and perplexity is 202.2725780830226
At time: 263.1033158302307 and batch: 600, loss is 5.2653266716003415 and perplexity is 193.50951252556456
At time: 264.1779260635376 and batch: 650, loss is 5.272375030517578 and perplexity is 194.87825505152156
At time: 265.2525532245636 and batch: 700, loss is 5.2927329540252686 and perplexity is 198.88623026474406
At time: 266.3270580768585 and batch: 750, loss is 5.272745733261108 and perplexity is 194.95051034711426
At time: 267.40181255340576 and batch: 800, loss is 5.242253580093384 and perplexity is 189.0957650449409
At time: 268.48096466064453 and batch: 850, loss is 5.226965551376343 and perplexity is 186.22684946813396
At time: 269.5548484325409 and batch: 900, loss is 5.254623231887817 and perplexity is 191.44934025764286
At time: 270.6299858093262 and batch: 950, loss is 5.221407384872436 and perplexity is 185.19464088223785
At time: 271.7043011188507 and batch: 1000, loss is 5.256206607818603 and perplexity is 191.75271665102895
At time: 272.77921772003174 and batch: 1050, loss is 5.217196969985962 and perplexity is 184.416533835615
At time: 273.88096356391907 and batch: 1100, loss is 5.2017655944824215 and perplexity is 181.59257785372435
At time: 274.9546523094177 and batch: 1150, loss is 5.211706371307373 and perplexity is 183.40675135061338
At time: 276.02998542785645 and batch: 1200, loss is 5.190399398803711 and perplexity is 179.5402467734414
At time: 277.10429525375366 and batch: 1250, loss is 5.215535907745362 and perplexity is 184.11046076830027
At time: 278.1796455383301 and batch: 1300, loss is 5.1979734897613525 and perplexity is 180.90526378902345
At time: 279.2554705142975 and batch: 1350, loss is 5.171625080108643 and perplexity is 176.20094559861388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.195260009765625 and perplexity of 180.41504637297425
Finished 9 epochs...
Completing Train Step...
At time: 282.4659676551819 and batch: 50, loss is 5.3064320850372315 and perplexity is 201.62954641109087
At time: 283.5406765937805 and batch: 100, loss is 5.318123569488526 and perplexity is 204.00072943274319
At time: 284.6159248352051 and batch: 150, loss is 5.293237504959106 and perplexity is 198.98660381760712
At time: 285.69036746025085 and batch: 200, loss is 5.267874231338501 and perplexity is 194.00311804644056
At time: 286.7656011581421 and batch: 250, loss is 5.297056493759155 and perplexity is 199.74798435544582
At time: 287.8400921821594 and batch: 300, loss is 5.322834014892578 and perplexity is 204.96393050316883
At time: 288.91532588005066 and batch: 350, loss is 5.302079334259033 and perplexity is 200.7538105586713
At time: 289.9910089969635 and batch: 400, loss is 5.327508974075317 and perplexity is 205.92437177485365
At time: 291.0658826828003 and batch: 450, loss is 5.299300832748413 and perplexity is 200.19678999236694
At time: 292.1412281990051 and batch: 500, loss is 5.327860622406006 and perplexity is 205.9967974698775
At time: 293.21566128730774 and batch: 550, loss is 5.2973674774169925 and perplexity is 199.81011237416493
At time: 294.2914125919342 and batch: 600, loss is 5.252440376281738 and perplexity is 191.03188977480244
At time: 295.36616468429565 and batch: 650, loss is 5.261047067642212 and perplexity is 192.68313798894783
At time: 296.44788002967834 and batch: 700, loss is 5.281541013717652 and perplexity is 196.67271730532087
At time: 297.52112579345703 and batch: 750, loss is 5.2626485252380375 and perplexity is 192.9919590798066
At time: 298.5946226119995 and batch: 800, loss is 5.2319035243988035 and perplexity is 187.14870680701955
At time: 299.6672852039337 and batch: 850, loss is 5.217124652862549 and perplexity is 184.40319784459425
At time: 300.7866590023041 and batch: 900, loss is 5.245767593383789 and perplexity is 189.76141894982868
At time: 301.85990476608276 and batch: 950, loss is 5.214047060012818 and perplexity is 183.83655228086002
At time: 302.9329032897949 and batch: 1000, loss is 5.249210472106934 and perplexity is 190.4158704537269
At time: 304.00594425201416 and batch: 1050, loss is 5.209849128723144 and perplexity is 183.0664366430755
At time: 305.0790927410126 and batch: 1100, loss is 5.194373197555542 and perplexity is 180.25512302843615
At time: 306.15193033218384 and batch: 1150, loss is 5.205361938476562 and perplexity is 182.24682297056728
At time: 307.225382566452 and batch: 1200, loss is 5.184435214996338 and perplexity is 178.4726226588381
At time: 308.29824018478394 and batch: 1250, loss is 5.21012315750122 and perplexity is 183.11660898903492
At time: 309.3708724975586 and batch: 1300, loss is 5.191790256500244 and perplexity is 179.79013544701232
At time: 310.4454336166382 and batch: 1350, loss is 5.164871025085449 and perplexity is 175.01488458630533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.193392333984375 and perplexity of 180.07840402752473
Finished 10 epochs...
Completing Train Step...
At time: 313.5986797809601 and batch: 50, loss is 5.29317795753479 and perplexity is 198.97475503066227
At time: 314.6980473995209 and batch: 100, loss is 5.304391126632691 and perplexity is 201.21844855325617
At time: 315.77083444595337 and batch: 150, loss is 5.280263261795044 and perplexity is 196.42157884315438
At time: 316.8442883491516 and batch: 200, loss is 5.254306259155274 and perplexity is 191.3886656537233
At time: 317.91796708106995 and batch: 250, loss is 5.283315162658692 and perplexity is 197.02195370554958
At time: 318.9910559654236 and batch: 300, loss is 5.308501739501953 and perplexity is 202.0472820371289
At time: 320.06462693214417 and batch: 350, loss is 5.288685903549195 and perplexity is 198.08295419764045
At time: 321.1386981010437 and batch: 400, loss is 5.3156429958343505 and perplexity is 203.49531771253882
At time: 322.2122631072998 and batch: 450, loss is 5.2879700756073 and perplexity is 197.9412116219133
At time: 323.28571915626526 and batch: 500, loss is 5.317382316589356 and perplexity is 203.8495693314714
At time: 324.35863876342773 and batch: 550, loss is 5.286647844314575 and perplexity is 197.6796605114242
At time: 325.43244457244873 and batch: 600, loss is 5.241851825714111 and perplexity is 189.01981025183915
At time: 326.50576877593994 and batch: 650, loss is 5.250630140304565 and perplexity is 190.6863897877471
At time: 327.6062476634979 and batch: 700, loss is 5.271829910278321 and perplexity is 194.77205191986997
At time: 328.68162536621094 and batch: 750, loss is 5.2534169101715085 and perplexity is 191.21853000461724
At time: 329.75608015060425 and batch: 800, loss is 5.223202714920044 and perplexity is 185.52742502496892
At time: 330.83138275146484 and batch: 850, loss is 5.208518962860108 and perplexity is 182.82308980009716
At time: 331.90714383125305 and batch: 900, loss is 5.2379256439208985 and perplexity is 188.27913907057288
At time: 332.98295497894287 and batch: 950, loss is 5.207453050613403 and perplexity is 182.62832025176323
At time: 334.0583755970001 and batch: 1000, loss is 5.242207345962524 and perplexity is 189.08702256869674
At time: 335.1337718963623 and batch: 1050, loss is 5.202978553771973 and perplexity is 181.81297589785106
At time: 336.20696806907654 and batch: 1100, loss is 5.187513408660888 and perplexity is 179.02284236214777
At time: 337.2806806564331 and batch: 1150, loss is 5.19946364402771 and perplexity is 181.17504149494346
At time: 338.3546516895294 and batch: 1200, loss is 5.178462247848511 and perplexity is 177.40978884247764
At time: 339.427782535553 and batch: 1250, loss is 5.204561042785644 and perplexity is 182.10092070941172
At time: 340.5026626586914 and batch: 1300, loss is 5.185222063064575 and perplexity is 178.61310876057112
At time: 341.5758538246155 and batch: 1350, loss is 5.158362531661988 and perplexity is 173.87950018985634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192799479166666 and perplexity of 179.9716753185725
Finished 11 epochs...
Completing Train Step...
At time: 344.73330664634705 and batch: 50, loss is 5.281150255203247 and perplexity is 196.59588077972376
At time: 345.83325576782227 and batch: 100, loss is 5.29274432182312 and perplexity is 198.8884911760559
At time: 346.9063799381256 and batch: 150, loss is 5.27000693321228 and perplexity is 194.41731037720388
At time: 347.9803156852722 and batch: 200, loss is 5.243020315170288 and perplexity is 189.24080699816577
At time: 349.0539560317993 and batch: 250, loss is 5.272126083374023 and perplexity is 194.82974670484325
At time: 350.12765073776245 and batch: 300, loss is 5.29640302658081 and perplexity is 199.61749824256836
At time: 351.2016456127167 and batch: 350, loss is 5.277454881668091 and perplexity is 195.87072624841431
At time: 352.2751488685608 and batch: 400, loss is 5.304903631210327 and perplexity is 201.3216003598733
At time: 353.3488538265228 and batch: 450, loss is 5.277533292770386 and perplexity is 195.88608529011853
At time: 354.42288064956665 and batch: 500, loss is 5.3077604198455814 and perplexity is 201.89755591975222
At time: 355.53659081459045 and batch: 550, loss is 5.277767381668091 and perplexity is 195.93194541536351
At time: 356.61009407043457 and batch: 600, loss is 5.232178945541381 and perplexity is 187.2002586165836
At time: 357.6846890449524 and batch: 650, loss is 5.240898132324219 and perplexity is 188.83962924061967
At time: 358.75807642936707 and batch: 700, loss is 5.262879524230957 and perplexity is 193.0365451774692
At time: 359.8316423892975 and batch: 750, loss is 5.245128135681153 and perplexity is 189.64011333785555
At time: 360.9054145812988 and batch: 800, loss is 5.214934091567994 and perplexity is 183.99969344871283
At time: 361.9791440963745 and batch: 850, loss is 5.200037841796875 and perplexity is 181.2791016723
At time: 363.0527708530426 and batch: 900, loss is 5.229986162185669 and perplexity is 186.7902187339185
At time: 364.1263897418976 and batch: 950, loss is 5.2005813026428225 and perplexity is 181.37764654146096
At time: 365.199542760849 and batch: 1000, loss is 5.234977197647095 and perplexity is 187.72482572766978
At time: 366.2733631134033 and batch: 1050, loss is 5.195651683807373 and perplexity is 180.48572410379205
At time: 367.3460373878479 and batch: 1100, loss is 5.180558643341064 and perplexity is 177.78210004354867
At time: 368.420095205307 and batch: 1150, loss is 5.193118658065796 and perplexity is 180.02912764807306
At time: 369.49383068084717 and batch: 1200, loss is 5.172619190216064 and perplexity is 176.37619583415324
At time: 370.5676758289337 and batch: 1250, loss is 5.198860750198365 and perplexity is 181.06584510061847
At time: 371.6412172317505 and batch: 1300, loss is 5.178001747131348 and perplexity is 177.32811031543744
At time: 372.7146632671356 and batch: 1350, loss is 5.150469694137573 and perplexity is 172.51249940024564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192358805338542 and perplexity of 179.89238398354715
Finished 12 epochs...
Completing Train Step...
At time: 375.8945107460022 and batch: 50, loss is 5.2706334686279295 and perplexity is 194.5391578744707
At time: 376.9661431312561 and batch: 100, loss is 5.281937828063965 and perplexity is 196.75077534732725
At time: 378.0393075942993 and batch: 150, loss is 5.259775915145874 and perplexity is 192.43836394262033
At time: 379.11156821250916 and batch: 200, loss is 5.231962518692017 and perplexity is 187.15974783837913
At time: 380.18556785583496 and batch: 250, loss is 5.261776885986328 and perplexity is 192.82381300501356
At time: 381.25928020477295 and batch: 300, loss is 5.2840452480316165 and perplexity is 197.16584907365512
At time: 382.3586881160736 and batch: 350, loss is 5.267128477096557 and perplexity is 193.85849333215694
At time: 383.431884765625 and batch: 400, loss is 5.295814914703369 and perplexity is 199.50013533554937
At time: 384.50508093833923 and batch: 450, loss is 5.268423471450806 and perplexity is 194.10970160808813
At time: 385.5785517692566 and batch: 500, loss is 5.299065437316894 and perplexity is 200.14967012871594
At time: 386.65140748023987 and batch: 550, loss is 5.269244632720947 and perplexity is 194.2691624397765
At time: 387.7242705821991 and batch: 600, loss is 5.22279839515686 and perplexity is 185.45242778287403
At time: 388.79862213134766 and batch: 650, loss is 5.231445960998535 and perplexity is 187.0630939965151
At time: 389.8711862564087 and batch: 700, loss is 5.254575138092041 and perplexity is 191.4401329535799
At time: 390.9530668258667 and batch: 750, loss is 5.2364373302459715 and perplexity is 187.9991290762295
At time: 392.0263829231262 and batch: 800, loss is 5.207011041641235 and perplexity is 182.54761473323552
At time: 393.09960436820984 and batch: 850, loss is 5.192634611129761 and perplexity is 179.94200618757705
At time: 394.17266392707825 and batch: 900, loss is 5.2221542263031 and perplexity is 185.3330035738497
At time: 395.24582505226135 and batch: 950, loss is 5.193818988800049 and perplexity is 180.15525173835928
At time: 396.31926584243774 and batch: 1000, loss is 5.228691272735595 and perplexity is 186.5485025819252
At time: 397.3927307128906 and batch: 1050, loss is 5.188715858459473 and perplexity is 179.23823781804631
At time: 398.4658238887787 and batch: 1100, loss is 5.173459110260009 and perplexity is 176.52439996740742
At time: 399.53871607780457 and batch: 1150, loss is 5.186477394104004 and perplexity is 178.83746813322614
At time: 400.61255145072937 and batch: 1200, loss is 5.165758104324341 and perplexity is 175.17020553772923
At time: 401.6873149871826 and batch: 1250, loss is 5.192446622848511 and perplexity is 179.90818237844863
At time: 402.7607457637787 and batch: 1300, loss is 5.170505657196045 and perplexity is 176.00381258108337
At time: 403.8338613510132 and batch: 1350, loss is 5.1433448982238765 and perplexity is 171.28775127064915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192282307942708 and perplexity of 179.8786232109804
Finished 13 epochs...
Completing Train Step...
At time: 407.0245897769928 and batch: 50, loss is 5.260647096633911 and perplexity is 192.60608573032576
At time: 408.0972864627838 and batch: 100, loss is 5.2721131229400635 and perplexity is 194.82722164314066
At time: 409.19628071784973 and batch: 150, loss is 5.2501799011230466 and perplexity is 190.60055462830823
At time: 410.2689518928528 and batch: 200, loss is 5.2224652957916256 and perplexity is 185.39066398421048
At time: 411.34218764305115 and batch: 250, loss is 5.252991704940796 and perplexity is 191.13724016910655
At time: 412.4189205169678 and batch: 300, loss is 5.274153871536255 and perplexity is 195.2252209923879
At time: 413.4955024719238 and batch: 350, loss is 5.257649402618409 and perplexity is 192.02957615115793
At time: 414.5691113471985 and batch: 400, loss is 5.28653338432312 and perplexity is 197.65703539403137
At time: 415.64190697669983 and batch: 450, loss is 5.259350214004517 and perplexity is 192.35646014595577
At time: 416.71529817581177 and batch: 500, loss is 5.290778474807739 and perplexity is 198.49789088528314
At time: 417.7882993221283 and batch: 550, loss is 5.261060571670532 and perplexity is 192.68574000506874
At time: 418.8613498210907 and batch: 600, loss is 5.214645309448242 and perplexity is 183.9465652988042
At time: 419.9343571662903 and batch: 650, loss is 5.223717088699341 and perplexity is 185.62288001540975
At time: 421.00730991363525 and batch: 700, loss is 5.246951103210449 and perplexity is 189.9861364053051
At time: 422.08023047447205 and batch: 750, loss is 5.228845319747925 and perplexity is 186.57724203495906
At time: 423.15366888046265 and batch: 800, loss is 5.200125617980957 and perplexity is 181.2950143584658
At time: 424.22664880752563 and batch: 850, loss is 5.185780849456787 and perplexity is 178.71294322568974
At time: 425.2997512817383 and batch: 900, loss is 5.214700727462769 and perplexity is 183.9567595347016
At time: 426.3740074634552 and batch: 950, loss is 5.187084102630616 and perplexity is 178.94600327128782
At time: 427.44644045829773 and batch: 1000, loss is 5.22172812461853 and perplexity is 185.25404969120623
At time: 428.5194215774536 and batch: 1050, loss is 5.181909799575806 and perplexity is 178.02247379112242
At time: 429.592351436615 and batch: 1100, loss is 5.166243829727173 and perplexity is 175.25531082360467
At time: 430.6653468608856 and batch: 1150, loss is 5.180196876525879 and perplexity is 177.71779601165267
At time: 431.738605260849 and batch: 1200, loss is 5.159565820693969 and perplexity is 174.08885341628155
At time: 432.8109619617462 and batch: 1250, loss is 5.1861322975158695 and perplexity is 178.77576258094297
At time: 433.88409638404846 and batch: 1300, loss is 5.163720312118531 and perplexity is 174.81360851690945
At time: 434.95680499076843 and batch: 1350, loss is 5.136623268127441 and perplexity is 170.14027912845964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1918562825520835 and perplexity of 179.80200667171627
Finished 14 epochs...
Completing Train Step...
At time: 438.12542390823364 and batch: 50, loss is 5.251603584289551 and perplexity is 190.87210268278992
At time: 439.22510957717896 and batch: 100, loss is 5.26282036781311 and perplexity is 193.02512616470023
At time: 440.29779076576233 and batch: 150, loss is 5.24180890083313 and perplexity is 189.01169677311728
At time: 441.370263338089 and batch: 200, loss is 5.213345527648926 and perplexity is 183.70763021655634
At time: 442.4425525665283 and batch: 250, loss is 5.244248275756836 and perplexity is 189.47332998584005
At time: 443.51590180397034 and batch: 300, loss is 5.264558277130127 and perplexity is 193.36087799849352
At time: 444.5891001224518 and batch: 350, loss is 5.248636598587036 and perplexity is 190.3066271768153
At time: 445.66229248046875 and batch: 400, loss is 5.278599147796631 and perplexity is 196.0949827661324
At time: 446.7352468967438 and batch: 450, loss is 5.251770839691162 and perplexity is 190.9040297428927
At time: 447.80951619148254 and batch: 500, loss is 5.28389313697815 and perplexity is 197.1358602495185
At time: 448.88363909721375 and batch: 550, loss is 5.25380431175232 and perplexity is 191.29262271631157
At time: 449.9569890499115 and batch: 600, loss is 5.207324733734131 and perplexity is 182.60488745908535
At time: 451.0300829410553 and batch: 650, loss is 5.216285877227783 and perplexity is 184.24858978507038
At time: 452.10535740852356 and batch: 700, loss is 5.239762306213379 and perplexity is 188.62526202395415
At time: 453.1855137348175 and batch: 750, loss is 5.222065601348877 and perplexity is 185.31657917270854
At time: 454.26680970191956 and batch: 800, loss is 5.19282338142395 and perplexity is 179.97597709927066
At time: 455.3472692966461 and batch: 850, loss is 5.179334774017334 and perplexity is 177.5646510766992
At time: 456.4282898902893 and batch: 900, loss is 5.208536319732666 and perplexity is 182.82626306470635
At time: 457.50860714912415 and batch: 950, loss is 5.180713195800781 and perplexity is 177.8095788278061
At time: 458.585666179657 and batch: 1000, loss is 5.2156726741790775 and perplexity is 184.13564262140622
At time: 459.6601173877716 and batch: 1050, loss is 5.175129032135009 and perplexity is 176.81942819286738
At time: 460.73458433151245 and batch: 1100, loss is 5.160015993118286 and perplexity is 174.16724106012447
At time: 461.8096282482147 and batch: 1150, loss is 5.173907346725464 and perplexity is 176.6035423764471
At time: 462.8837287425995 and batch: 1200, loss is 5.153686618804931 and perplexity is 173.06835270473843
At time: 463.99040627479553 and batch: 1250, loss is 5.17998438835144 and perplexity is 177.6800370934167
At time: 465.06433176994324 and batch: 1300, loss is 5.15687575340271 and perplexity is 173.6211720151834
At time: 466.138610124588 and batch: 1350, loss is 5.13037899017334 and perplexity is 169.0811860115505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.191583251953125 and perplexity of 179.75292192326472
Finished 15 epochs...
Completing Train Step...
At time: 469.3211088180542 and batch: 50, loss is 5.2427594852447506 and perplexity is 189.19145376924718
At time: 470.42151856422424 and batch: 100, loss is 5.2544075393676755 and perplexity is 191.4080505200671
At time: 471.4958448410034 and batch: 150, loss is 5.2337704944610595 and perplexity is 187.4984342035243
At time: 472.5702350139618 and batch: 200, loss is 5.204622869491577 and perplexity is 182.11217975753783
At time: 473.64306354522705 and batch: 250, loss is 5.236143465042114 and perplexity is 187.9438907905411
At time: 474.7168445587158 and batch: 300, loss is 5.25578761100769 and perplexity is 191.67238970381084
At time: 475.7910614013672 and batch: 350, loss is 5.240373115539551 and perplexity is 188.7405112872293
At time: 476.864928483963 and batch: 400, loss is 5.27070460319519 and perplexity is 194.55299682548943
At time: 477.9390707015991 and batch: 450, loss is 5.243877677917481 and perplexity is 189.4031245889196
At time: 479.01263332366943 and batch: 500, loss is 5.276883478164673 and perplexity is 195.75883699921775
At time: 480.0860996246338 and batch: 550, loss is 5.246685943603516 and perplexity is 189.93576643438902
At time: 481.16059398651123 and batch: 600, loss is 5.1996673965454105 and perplexity is 181.21196012679692
At time: 482.23386788368225 and batch: 650, loss is 5.208748531341553 and perplexity is 182.86506503710703
At time: 483.30883169174194 and batch: 700, loss is 5.232536516189575 and perplexity is 187.26720790323574
At time: 484.3838617801666 and batch: 750, loss is 5.215039920806885 and perplexity is 184.01916702664553
At time: 485.4578685760498 and batch: 800, loss is 5.185742683410645 and perplexity is 178.70612258941156
At time: 486.53220772743225 and batch: 850, loss is 5.172468509674072 and perplexity is 176.34962137554763
At time: 487.60660433769226 and batch: 900, loss is 5.201660985946655 and perplexity is 181.5735827135933
At time: 488.681143283844 and batch: 950, loss is 5.17403938293457 and perplexity is 176.62686197817916
At time: 489.75471901893616 and batch: 1000, loss is 5.209528226852417 and perplexity is 183.0076997059898
At time: 490.85518980026245 and batch: 1050, loss is 5.169132823944092 and perplexity is 175.76235447348355
At time: 491.92872738838196 and batch: 1100, loss is 5.1535921382904055 and perplexity is 173.05200189015562
At time: 493.00305461883545 and batch: 1150, loss is 5.168051605224609 and perplexity is 175.5724196247068
At time: 494.077002286911 and batch: 1200, loss is 5.147571210861206 and perplexity is 172.01319876260428
At time: 495.15081548690796 and batch: 1250, loss is 5.174266386032104 and perplexity is 176.66696137412737
At time: 496.22430896759033 and batch: 1300, loss is 5.150236234664917 and perplexity is 172.47222942399569
At time: 497.2987997531891 and batch: 1350, loss is 5.1239157390594485 and perplexity is 167.9918958177157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1915885416666665 and perplexity of 179.75387276724487
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 500.4813756942749 and batch: 50, loss is 5.238275260925293 and perplexity is 188.34497616737832
At time: 501.5562493801117 and batch: 100, loss is 5.251137914657593 and perplexity is 190.7832400329071
At time: 502.6309621334076 and batch: 150, loss is 5.230831708908081 and perplexity is 186.94822538273573
At time: 503.70575976371765 and batch: 200, loss is 5.2031572151184085 and perplexity is 181.8454617508211
At time: 504.7806205749512 and batch: 250, loss is 5.232492656707763 and perplexity is 187.25899464065282
At time: 505.85462641716003 and batch: 300, loss is 5.249059104919434 and perplexity is 190.3870499202576
At time: 506.92895126342773 and batch: 350, loss is 5.232377433776856 and perplexity is 187.2374193534593
At time: 508.00534677505493 and batch: 400, loss is 5.262899675369263 and perplexity is 193.04043512278238
At time: 509.0812575817108 and batch: 450, loss is 5.231145191192627 and perplexity is 187.00683952628833
At time: 510.156094789505 and batch: 500, loss is 5.261873950958252 and perplexity is 192.84253035139383
At time: 511.23132944107056 and batch: 550, loss is 5.227714757919312 and perplexity is 186.36642412082483
At time: 512.3058815002441 and batch: 600, loss is 5.185315799713135 and perplexity is 178.62985213949702
At time: 513.3805537223816 and batch: 650, loss is 5.1890784358978275 and perplexity is 179.303237342138
At time: 514.4556677341461 and batch: 700, loss is 5.2077639770507815 and perplexity is 182.6851130534777
At time: 515.5282559394836 and batch: 750, loss is 5.186621341705322 and perplexity is 178.86321321071645
At time: 516.6003122329712 and batch: 800, loss is 5.15864426612854 and perplexity is 173.92849493951752
At time: 517.7061755657196 and batch: 850, loss is 5.134074020385742 and perplexity is 169.70710177889887
At time: 518.7793533802032 and batch: 900, loss is 5.157276077270508 and perplexity is 173.69069062834765
At time: 519.8528017997742 and batch: 950, loss is 5.132661447525025 and perplexity is 169.46754736651894
At time: 520.9254841804504 and batch: 1000, loss is 5.165355081558228 and perplexity is 175.099622181258
At time: 521.9988760948181 and batch: 1050, loss is 5.1216641044616695 and perplexity is 167.61406498106706
At time: 523.0719652175903 and batch: 1100, loss is 5.103032484054565 and perplexity is 164.5200560507136
At time: 524.1447162628174 and batch: 1150, loss is 5.112866859436036 and perplexity is 166.14598995756918
At time: 525.2204988002777 and batch: 1200, loss is 5.091810684204102 and perplexity is 162.68416517621554
At time: 526.2960395812988 and batch: 1250, loss is 5.115142135620117 and perplexity is 166.5244483570223
At time: 527.3725440502167 and batch: 1300, loss is 5.093863887786865 and perplexity is 163.01853203116212
At time: 528.4486408233643 and batch: 1350, loss is 5.07494176864624 and perplexity is 159.96287685330242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168302408854166 and perplexity of 175.61645934722907
Finished 17 epochs...
Completing Train Step...
At time: 531.6847190856934 and batch: 50, loss is 5.222649374008179 and perplexity is 185.42479350815688
At time: 532.7609176635742 and batch: 100, loss is 5.232721567153931 and perplexity is 187.30186508722417
At time: 533.8372347354889 and batch: 150, loss is 5.211402502059936 and perplexity is 183.35102814581865
At time: 534.9133131504059 and batch: 200, loss is 5.18590446472168 and perplexity is 178.73503623899504
At time: 535.989447593689 and batch: 250, loss is 5.216121263504029 and perplexity is 184.21826243482687
At time: 537.0648777484894 and batch: 300, loss is 5.232663974761963 and perplexity is 187.2910782354171
At time: 538.1389472484589 and batch: 350, loss is 5.216823568344116 and perplexity is 184.34768525398397
At time: 539.2139592170715 and batch: 400, loss is 5.248223276138305 and perplexity is 190.22798542898036
At time: 540.2884304523468 and batch: 450, loss is 5.216835031509399 and perplexity is 184.34979847408158
At time: 541.3631176948547 and batch: 500, loss is 5.248755941390991 and perplexity is 190.32934025860825
At time: 542.4378337860107 and batch: 550, loss is 5.216948871612549 and perplexity is 184.37078606874778
At time: 543.5128920078278 and batch: 600, loss is 5.174953479766845 and perplexity is 176.78838984801789
At time: 544.5943124294281 and batch: 650, loss is 5.179383220672608 and perplexity is 177.57325369852123
At time: 545.7017285823822 and batch: 700, loss is 5.199365959167481 and perplexity is 181.15734430072604
At time: 546.7777915000916 and batch: 750, loss is 5.179525346755981 and perplexity is 177.59849328314044
At time: 547.8524370193481 and batch: 800, loss is 5.151964054107666 and perplexity is 172.77048788951583
At time: 548.9274117946625 and batch: 850, loss is 5.129123067855835 and perplexity is 168.8689664700927
At time: 550.0032308101654 and batch: 900, loss is 5.154495716094971 and perplexity is 173.20843850378148
At time: 551.0802125930786 and batch: 950, loss is 5.130531187057495 and perplexity is 169.1069215996192
At time: 552.1557250022888 and batch: 1000, loss is 5.1640230083465575 and perplexity is 174.8665319462724
At time: 553.2383353710175 and batch: 1050, loss is 5.122310523986816 and perplexity is 167.72244901236294
At time: 554.3135418891907 and batch: 1100, loss is 5.105208139419556 and perplexity is 164.87838465173562
At time: 555.3888969421387 and batch: 1150, loss is 5.116700468063354 and perplexity is 166.78415110654404
At time: 556.4641473293304 and batch: 1200, loss is 5.096997165679932 and perplexity is 163.5301154416948
At time: 557.5396614074707 and batch: 1250, loss is 5.122067880630493 and perplexity is 167.6817572114011
At time: 558.6150643825531 and batch: 1300, loss is 5.100979642868042 and perplexity is 164.1826689232227
At time: 559.6898772716522 and batch: 1350, loss is 5.079360847473144 and perplexity is 160.67132961689566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.166363118489583 and perplexity of 175.276218059713
Finished 18 epochs...
Completing Train Step...
At time: 562.8758096694946 and batch: 50, loss is 5.217638549804687 and perplexity is 184.49798643778513
At time: 563.9766561985016 and batch: 100, loss is 5.226095676422119 and perplexity is 186.0649258328455
At time: 565.0511429309845 and batch: 150, loss is 5.203796739578247 and perplexity is 181.96179356607718
At time: 566.1257722377777 and batch: 200, loss is 5.17885238647461 and perplexity is 177.47901675711674
At time: 567.2003734111786 and batch: 250, loss is 5.209208374023437 and perplexity is 182.94917353589338
At time: 568.2766242027283 and batch: 300, loss is 5.225741500854492 and perplexity is 185.99903785076867
At time: 569.3513503074646 and batch: 350, loss is 5.210586662292481 and perplexity is 183.20150408778326
At time: 570.4258422851562 and batch: 400, loss is 5.242152614593506 and perplexity is 189.07667386029004
At time: 571.5001575946808 and batch: 450, loss is 5.210671977996826 and perplexity is 183.21713471990142
At time: 572.6018085479736 and batch: 500, loss is 5.242985200881958 and perplexity is 189.23416205857197
At time: 573.6761243343353 and batch: 550, loss is 5.212392854690552 and perplexity is 183.53270026375017
At time: 574.7506802082062 and batch: 600, loss is 5.170752868652344 and perplexity is 176.04732811845386
At time: 575.8252277374268 and batch: 650, loss is 5.175469551086426 and perplexity is 176.87964881169478
At time: 576.899646282196 and batch: 700, loss is 5.19600848197937 and perplexity is 180.55013256995204
At time: 577.9818081855774 and batch: 750, loss is 5.176782331466675 and perplexity is 177.1120054275532
At time: 579.0562863349915 and batch: 800, loss is 5.14942234992981 and perplexity is 172.33191401726688
At time: 580.1309959888458 and batch: 850, loss is 5.12707275390625 and perplexity is 168.52308677463645
At time: 581.2053301334381 and batch: 900, loss is 5.1532416343688965 and perplexity is 172.99135711360498
At time: 582.2798364162445 and batch: 950, loss is 5.12982250213623 and perplexity is 168.9871205298199
At time: 583.3548200130463 and batch: 1000, loss is 5.163563661575317 and perplexity is 174.78622601497204
At time: 584.4299221038818 and batch: 1050, loss is 5.122606143951416 and perplexity is 167.77203844625484
At time: 585.5043830871582 and batch: 1100, loss is 5.106311597824097 and perplexity is 165.06042150758492
At time: 586.5778889656067 and batch: 1150, loss is 5.118501272201538 and perplexity is 167.08476729023508
At time: 587.652987241745 and batch: 1200, loss is 5.099299535751343 and perplexity is 163.90705604713585
At time: 588.7271540164948 and batch: 1250, loss is 5.124712514877319 and perplexity is 168.12580103703766
At time: 589.8018896579742 and batch: 1300, loss is 5.103881731033325 and perplexity is 164.6598335556711
At time: 590.875926733017 and batch: 1350, loss is 5.080597190856934 and perplexity is 160.87009739952987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.165749104817708 and perplexity of 175.1686290993963
Finished 19 epochs...
Completing Train Step...
At time: 594.0577657222748 and batch: 50, loss is 5.213763227462769 and perplexity is 183.78438088775394
At time: 595.1580808162689 and batch: 100, loss is 5.22133939743042 and perplexity is 185.18205040033126
At time: 596.2323362827301 and batch: 150, loss is 5.199422397613525 and perplexity is 181.16756882825345
At time: 597.3061945438385 and batch: 200, loss is 5.1745061016082765 and perplexity is 176.7093162729254
At time: 598.3811249732971 and batch: 250, loss is 5.204650335311889 and perplexity is 182.11718168663447
At time: 599.482340335846 and batch: 300, loss is 5.221349220275879 and perplexity is 185.18386942392823
At time: 600.5563504695892 and batch: 350, loss is 5.206560878753662 and perplexity is 182.46545706542162
At time: 601.6308240890503 and batch: 400, loss is 5.237912740707397 and perplexity is 188.27670968031714
At time: 602.7060589790344 and batch: 450, loss is 5.206509532928467 and perplexity is 182.45608846648025
At time: 603.7802243232727 and batch: 500, loss is 5.2389280796051025 and perplexity is 188.46797142850264
At time: 604.85413813591 and batch: 550, loss is 5.20910249710083 and perplexity is 182.92980446579278
At time: 605.9281392097473 and batch: 600, loss is 5.1675874137878415 and perplexity is 175.4909393236765
At time: 607.0028088092804 and batch: 650, loss is 5.172728624343872 and perplexity is 176.39549846547442
At time: 608.0773124694824 and batch: 700, loss is 5.193827438354492 and perplexity is 180.1567739763981
At time: 609.1522674560547 and batch: 750, loss is 5.174724426269531 and perplexity is 176.74790048633062
At time: 610.2260820865631 and batch: 800, loss is 5.147510251998901 and perplexity is 172.00271335329887
At time: 611.3006336688995 and batch: 850, loss is 5.125390329360962 and perplexity is 168.23979777000847
At time: 612.3747565746307 and batch: 900, loss is 5.151971616744995 and perplexity is 172.77179449499755
At time: 613.449223279953 and batch: 950, loss is 5.1289182472229005 and perplexity is 168.83438216340804
At time: 614.5230689048767 and batch: 1000, loss is 5.1628079605102535 and perplexity is 174.65418977406168
At time: 615.5976929664612 and batch: 1050, loss is 5.1225309085845945 and perplexity is 167.75941653021306
At time: 616.672399520874 and batch: 1100, loss is 5.1065169715881344 and perplexity is 165.09432406887274
At time: 617.7466332912445 and batch: 1150, loss is 5.119090633392334 and perplexity is 167.18326959151474
At time: 618.8206284046173 and batch: 1200, loss is 5.100193967819214 and perplexity is 164.05372535730388
At time: 619.8956277370453 and batch: 1250, loss is 5.125949945449829 and perplexity is 168.3339738163859
At time: 620.9689235687256 and batch: 1300, loss is 5.105028533935547 and perplexity is 164.8487742488326
At time: 622.0448520183563 and batch: 1350, loss is 5.080736207962036 and perplexity is 160.89246264930796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.165382080078125 and perplexity of 175.10434967570885
Finished 20 epochs...
Completing Train Step...
At time: 625.2139599323273 and batch: 50, loss is 5.210352210998535 and perplexity is 183.15855729275975
At time: 626.286242723465 and batch: 100, loss is 5.217371644973755 and perplexity is 184.44874960497424
At time: 627.384997844696 and batch: 150, loss is 5.19558837890625 and perplexity is 180.47429883451514
At time: 628.468658208847 and batch: 200, loss is 5.170941181182862 and perplexity is 176.0804831579594
At time: 629.5454585552216 and batch: 250, loss is 5.200932407379151 and perplexity is 181.44134027315687
At time: 630.6192412376404 and batch: 300, loss is 5.217650966644287 and perplexity is 184.50027733391207
At time: 631.6922118663788 and batch: 350, loss is 5.2031945133209225 and perplexity is 181.85224438616902
At time: 632.7658593654633 and batch: 400, loss is 5.234937925338745 and perplexity is 187.71745348519224
At time: 633.8392148017883 and batch: 450, loss is 5.20318265914917 and perplexity is 181.85008869120747
At time: 634.9137132167816 and batch: 500, loss is 5.23572229385376 and perplexity is 187.86475090560245
At time: 635.9861333370209 and batch: 550, loss is 5.206642827987671 and perplexity is 182.4804105825674
At time: 637.0592412948608 and batch: 600, loss is 5.165445079803467 and perplexity is 175.1153815491435
At time: 638.1333112716675 and batch: 650, loss is 5.170806770324707 and perplexity is 176.05681761960213
At time: 639.2067577838898 and batch: 700, loss is 5.192141094207764 and perplexity is 179.85322367218419
At time: 640.2818772792816 and batch: 750, loss is 5.17298005104065 and perplexity is 176.43985457890196
At time: 641.3548717498779 and batch: 800, loss is 5.145974750518799 and perplexity is 171.73880559958917
At time: 642.4288010597229 and batch: 850, loss is 5.123985090255737 and perplexity is 168.00354666065275
At time: 643.5022673606873 and batch: 900, loss is 5.150695562362671 and perplexity is 172.55146889311172
At time: 644.5784487724304 and batch: 950, loss is 5.1279918384552 and perplexity is 168.67804493875155
At time: 645.6534988880157 and batch: 1000, loss is 5.162054224014282 and perplexity is 174.52259613674826
At time: 646.7275354862213 and batch: 1050, loss is 5.122371368408203 and perplexity is 167.73265429819085
At time: 647.8032100200653 and batch: 1100, loss is 5.106765785217285 and perplexity is 165.1354068975684
At time: 648.8803968429565 and batch: 1150, loss is 5.119147186279297 and perplexity is 167.19272455541224
At time: 649.9570899009705 and batch: 1200, loss is 5.100542030334473 and perplexity is 164.11083624809285
At time: 651.0324652194977 and batch: 1250, loss is 5.126570539474487 and perplexity is 168.43847329720617
At time: 652.1060836315155 and batch: 1300, loss is 5.105754413604736 and perplexity is 164.96847806257693
At time: 653.1801607608795 and batch: 1350, loss is 5.080600042343139 and perplexity is 160.87055611904748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.165206298828125 and perplexity of 175.07357231936285
Finished 21 epochs...
Completing Train Step...
At time: 656.3957943916321 and batch: 50, loss is 5.207384557723999 and perplexity is 182.6158119387922
At time: 657.4704029560089 and batch: 100, loss is 5.214176321029663 and perplexity is 183.86031671641572
At time: 658.5455820560455 and batch: 150, loss is 5.192475414276123 and perplexity is 179.9133622664262
At time: 659.6202948093414 and batch: 200, loss is 5.167844018936157 and perplexity is 175.53597698038988
At time: 660.6952049732208 and batch: 250, loss is 5.198136930465698 and perplexity is 180.93483348913745
At time: 661.770406961441 and batch: 300, loss is 5.21499192237854 and perplexity is 184.01033460781574
At time: 662.8454787731171 and batch: 350, loss is 5.200599403381347 and perplexity is 181.38092964052845
At time: 663.9203317165375 and batch: 400, loss is 5.2323419380187985 and perplexity is 187.23077333727605
At time: 664.9948737621307 and batch: 450, loss is 5.200613880157471 and perplexity is 181.38355547064668
At time: 666.0702755451202 and batch: 500, loss is 5.2331441879272464 and perplexity is 187.381039475483
At time: 667.1443381309509 and batch: 550, loss is 5.204612646102905 and perplexity is 182.11031796345927
At time: 668.2189698219299 and batch: 600, loss is 5.163485698699951 and perplexity is 174.7725997093974
At time: 669.2934012413025 and batch: 650, loss is 5.16888201713562 and perplexity is 175.71827760592885
At time: 670.3689234256744 and batch: 700, loss is 5.190469636917114 and perplexity is 179.55285778453626
At time: 671.4441909790039 and batch: 750, loss is 5.1711271953582765 and perplexity is 176.11323967033405
At time: 672.5190625190735 and batch: 800, loss is 5.144556970596313 and perplexity is 171.49549029363354
At time: 673.5939242839813 and batch: 850, loss is 5.122603502273559 and perplexity is 167.77159524716126
At time: 674.6687552928925 and batch: 900, loss is 5.149368591308594 and perplexity is 172.32264994019206
At time: 675.7432062625885 and batch: 950, loss is 5.126822719573974 and perplexity is 168.48095548451568
At time: 676.8178277015686 and batch: 1000, loss is 5.160993061065674 and perplexity is 174.33749745133588
At time: 677.8927080631256 and batch: 1050, loss is 5.121554327011109 and perplexity is 167.5956657462643
At time: 678.9683794975281 and batch: 1100, loss is 5.106007919311524 and perplexity is 165.01030381451523
At time: 680.0432064533234 and batch: 1150, loss is 5.118909454345703 and perplexity is 167.15298222991794
At time: 681.1454284191132 and batch: 1200, loss is 5.100272998809815 and perplexity is 164.0666911980755
At time: 682.219799041748 and batch: 1250, loss is 5.12663501739502 and perplexity is 168.44933420984282
At time: 683.2949509620667 and batch: 1300, loss is 5.105969667434692 and perplexity is 165.00399198141832
At time: 684.3692812919617 and batch: 1350, loss is 5.080123796463012 and perplexity is 160.79396042010282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1649178059895835 and perplexity of 175.02307213235218
Finished 22 epochs...
Completing Train Step...
At time: 687.5352165699005 and batch: 50, loss is 5.204578905105591 and perplexity is 182.10417348337097
At time: 688.6408355236053 and batch: 100, loss is 5.211181259155273 and perplexity is 183.31046751881956
At time: 689.7149231433868 and batch: 150, loss is 5.189652185440064 and perplexity is 179.4061420104148
At time: 690.7960329055786 and batch: 200, loss is 5.165262899398804 and perplexity is 175.0834818639071
At time: 691.870635509491 and batch: 250, loss is 5.195489168167114 and perplexity is 180.45639473408693
At time: 692.9451389312744 and batch: 300, loss is 5.211691741943359 and perplexity is 183.40406824611145
At time: 694.0191400051117 and batch: 350, loss is 5.197717199325561 and perplexity is 180.85890544098442
At time: 695.0940840244293 and batch: 400, loss is 5.229661817550659 and perplexity is 186.72964415265116
At time: 696.1685409545898 and batch: 450, loss is 5.198081741333008 and perplexity is 180.92484812814791
At time: 697.2429540157318 and batch: 500, loss is 5.230579767227173 and perplexity is 186.90113126532472
At time: 698.3168797492981 and batch: 550, loss is 5.202571744918823 and perplexity is 181.73902781202614
At time: 699.3904089927673 and batch: 600, loss is 5.161572437286377 and perplexity is 174.438533717915
At time: 700.4643716812134 and batch: 650, loss is 5.166748371124267 and perplexity is 175.34375669340096
At time: 701.5389161109924 and batch: 700, loss is 5.188924055099488 and perplexity is 179.27555850180795
At time: 702.6133918762207 and batch: 750, loss is 5.169323263168335 and perplexity is 175.79582970731815
At time: 703.6876740455627 and batch: 800, loss is 5.142936191558838 and perplexity is 171.217759129167
At time: 704.761647939682 and batch: 850, loss is 5.120969333648682 and perplexity is 167.49765206570265
At time: 705.836457490921 and batch: 900, loss is 5.1479942321777346 and perplexity is 172.0859794052014
At time: 706.9107460975647 and batch: 950, loss is 5.125513830184937 and perplexity is 168.26057680674606
At time: 707.9853858947754 and batch: 1000, loss is 5.159897928237915 and perplexity is 174.1466792394825
At time: 709.1019487380981 and batch: 1050, loss is 5.1204101181030275 and perplexity is 167.40401096002824
At time: 710.1762802600861 and batch: 1100, loss is 5.104944562911987 and perplexity is 164.83493230969532
At time: 711.250335931778 and batch: 1150, loss is 5.11838885307312 and perplexity is 167.06598482209856
At time: 712.3253517150879 and batch: 1200, loss is 5.099759721755982 and perplexity is 163.98250113844642
At time: 713.3996682167053 and batch: 1250, loss is 5.126206254959106 and perplexity is 168.37712494439543
At time: 714.4742298126221 and batch: 1300, loss is 5.105454416275024 and perplexity is 164.91899538237854
At time: 715.5469958782196 and batch: 1350, loss is 5.079210271835327 and perplexity is 160.6471382503206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1648246256510415 and perplexity of 175.00676418304013
Finished 23 epochs...
Completing Train Step...
At time: 718.7019512653351 and batch: 50, loss is 5.202106208801269 and perplexity is 181.65444142114814
At time: 719.8029446601868 and batch: 100, loss is 5.208564758300781 and perplexity is 182.83146245577308
At time: 720.8774054050446 and batch: 150, loss is 5.187098741531372 and perplexity is 178.94862286324442
At time: 721.9517953395844 and batch: 200, loss is 5.162737789154053 and perplexity is 174.6419344826894
At time: 723.0258791446686 and batch: 250, loss is 5.193166608810425 and perplexity is 180.03776038577016
At time: 724.1034090518951 and batch: 300, loss is 5.209286279678345 and perplexity is 182.9634268662728
At time: 725.1834826469421 and batch: 350, loss is 5.195589151382446 and perplexity is 180.4744382466688
At time: 726.2581491470337 and batch: 400, loss is 5.227664165496826 and perplexity is 186.35699563046558
At time: 727.3324389457703 and batch: 450, loss is 5.195949382781983 and perplexity is 180.53946251732782
At time: 728.4052367210388 and batch: 500, loss is 5.228469133377075 and perplexity is 186.5070674195893
At time: 729.4780926704407 and batch: 550, loss is 5.200886554718018 and perplexity is 181.4330208956001
At time: 730.5515789985657 and batch: 600, loss is 5.159980344772339 and perplexity is 174.16103239672742
At time: 731.6240944862366 and batch: 650, loss is 5.165162391662598 and perplexity is 175.06588550379792
At time: 732.6964247226715 and batch: 700, loss is 5.187633066177368 and perplexity is 179.04426507252666
At time: 733.7733871936798 and batch: 750, loss is 5.167829494476319 and perplexity is 175.53342743365747
At time: 734.8496434688568 and batch: 800, loss is 5.141570129394531 and perplexity is 170.98402471078418
At time: 735.9498901367188 and batch: 850, loss is 5.119563808441162 and perplexity is 167.26239526193714
At time: 737.0236887931824 and batch: 900, loss is 5.146534423828125 and perplexity is 171.8349501275123
At time: 738.0973107814789 and batch: 950, loss is 5.124336023330688 and perplexity is 168.0625150082516
At time: 739.170581817627 and batch: 1000, loss is 5.158747014999389 and perplexity is 173.94636681412277
At time: 740.2462599277496 and batch: 1050, loss is 5.119414167404175 and perplexity is 167.23736781627431
At time: 741.3213279247284 and batch: 1100, loss is 5.104108486175537 and perplexity is 164.69717525319663
At time: 742.3955736160278 and batch: 1150, loss is 5.117909603118896 and perplexity is 166.98593763935662
At time: 743.4691691398621 and batch: 1200, loss is 5.099363183975219 and perplexity is 163.91748877214275
At time: 744.5423674583435 and batch: 1250, loss is 5.1257563400268555 and perplexity is 168.301386600817
At time: 745.6157600879669 and batch: 1300, loss is 5.10528377532959 and perplexity is 164.89085585003292
At time: 746.6888446807861 and batch: 1350, loss is 5.078411684036255 and perplexity is 160.5188986178763
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.164730224609375 and perplexity of 174.9902441419694
Finished 24 epochs...
Completing Train Step...
At time: 749.8933148384094 and batch: 50, loss is 5.199798069000244 and perplexity is 181.2356410856627
At time: 750.9733622074127 and batch: 100, loss is 5.2060400390625 and perplexity is 182.37044655788534
At time: 752.0463132858276 and batch: 150, loss is 5.184795646667481 and perplexity is 178.53696143864673
At time: 753.1195259094238 and batch: 200, loss is 5.160417184829712 and perplexity is 174.2371295320402
At time: 754.1926491260529 and batch: 250, loss is 5.190933837890625 and perplexity is 179.63622574416345
At time: 755.2653753757477 and batch: 300, loss is 5.207035236358642 and perplexity is 182.55203147461808
At time: 756.3397197723389 and batch: 350, loss is 5.19352463722229 and perplexity is 180.10223055958514
At time: 757.4131071567535 and batch: 400, loss is 5.225854654312133 and perplexity is 186.02008547580272
At time: 758.4872176647186 and batch: 450, loss is 5.193893852233887 and perplexity is 180.16873928398402
At time: 759.5649380683899 and batch: 500, loss is 5.226480226516724 and perplexity is 186.13649087696749
At time: 760.6390345096588 and batch: 550, loss is 5.199191427230835 and perplexity is 181.12572931757992
At time: 761.7129669189453 and batch: 600, loss is 5.158511438369751 and perplexity is 173.90539394160595
At time: 762.8131439685822 and batch: 650, loss is 5.163603229522705 and perplexity is 174.79314208399356
At time: 763.8891227245331 and batch: 700, loss is 5.186388397216797 and perplexity is 178.82155286346165
At time: 764.9632084369659 and batch: 750, loss is 5.16645809173584 and perplexity is 175.29286540164728
At time: 766.0377085208893 and batch: 800, loss is 5.1401144313812255 and perplexity is 170.7353046802538
At time: 767.1132953166962 and batch: 850, loss is 5.118237018585205 and perplexity is 167.04062036949313
At time: 768.1879198551178 and batch: 900, loss is 5.1453471374511714 and perplexity is 171.63105389770115
At time: 769.2627427577972 and batch: 950, loss is 5.123213853836059 and perplexity is 167.87402615871707
At time: 770.337860584259 and batch: 1000, loss is 5.1576895236969 and perplexity is 173.76251727089667
At time: 771.4123845100403 and batch: 1050, loss is 5.118429183959961 and perplexity is 167.0727228773023
At time: 772.4871215820312 and batch: 1100, loss is 5.103006267547608 and perplexity is 164.5157429660568
At time: 773.562313079834 and batch: 1150, loss is 5.117194681167603 and perplexity is 166.866598391188
At time: 774.6378552913666 and batch: 1200, loss is 5.098734741210937 and perplexity is 163.8145083744168
At time: 775.7120728492737 and batch: 1250, loss is 5.125155477523804 and perplexity is 168.20029098372135
At time: 776.7879736423492 and batch: 1300, loss is 5.104648504257202 and perplexity is 164.78613872461216
At time: 777.8628890514374 and batch: 1350, loss is 5.077484865188598 and perplexity is 160.3701955982573
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.164755452473958 and perplexity of 174.99465882783832
Annealing...
Finished 25 epochs...
Completing Train Step...
At time: 781.0431101322174 and batch: 50, loss is 5.199471416473389 and perplexity is 181.17644967358436
At time: 782.1186983585358 and batch: 100, loss is 5.206356143951416 and perplexity is 182.4281038600335
At time: 783.2022807598114 and batch: 150, loss is 5.18527455329895 and perplexity is 178.62248445057637
At time: 784.2776894569397 and batch: 200, loss is 5.161912298202514 and perplexity is 174.49782863323532
At time: 785.3526842594147 and batch: 250, loss is 5.191547155380249 and perplexity is 179.7464335759232
At time: 786.4276840686798 and batch: 300, loss is 5.2069212913513185 and perplexity is 182.53123176708863
At time: 787.5032451152802 and batch: 350, loss is 5.192525653839112 and perplexity is 179.922401262178
At time: 788.5788021087646 and batch: 400, loss is 5.224812040328979 and perplexity is 185.82623940441036
At time: 789.6532657146454 and batch: 450, loss is 5.191254482269287 and perplexity is 179.69383432559283
At time: 790.7563765048981 and batch: 500, loss is 5.222557125091552 and perplexity is 185.40768906078557
At time: 791.836309671402 and batch: 550, loss is 5.193111419677734 and perplexity is 180.02782453210102
At time: 792.9151537418365 and batch: 600, loss is 5.153720054626465 and perplexity is 173.07413948403493
At time: 793.9897241592407 and batch: 650, loss is 5.158526191711426 and perplexity is 173.90795964622814
At time: 795.0645995140076 and batch: 700, loss is 5.179132413864136 and perplexity is 177.5287227020631
At time: 796.1385130882263 and batch: 750, loss is 5.158736696243286 and perplexity is 173.9445719132492
At time: 797.2161703109741 and batch: 800, loss is 5.132590236663819 and perplexity is 169.45547986619817
At time: 798.2945821285248 and batch: 850, loss is 5.10739800453186 and perplexity is 165.2398417007005
At time: 799.3705897331238 and batch: 900, loss is 5.129812507629395 and perplexity is 168.9854315953287
At time: 800.446061372757 and batch: 950, loss is 5.108178806304932 and perplexity is 165.3689116445457
At time: 801.5206382274628 and batch: 1000, loss is 5.143369073867798 and perplexity is 171.29189231238794
At time: 802.597229719162 and batch: 1050, loss is 5.101901664733886 and perplexity is 164.33411874325617
At time: 803.6714787483215 and batch: 1100, loss is 5.085978584289551 and perplexity is 161.73813621956057
At time: 804.7483031749725 and batch: 1150, loss is 5.099480047225952 and perplexity is 163.9366458220883
At time: 805.8235204219818 and batch: 1200, loss is 5.079277601242065 and perplexity is 160.65795489096809
At time: 806.8994727134705 and batch: 1250, loss is 5.1055353736877445 and perplexity is 164.93234733801575
At time: 807.9758858680725 and batch: 1300, loss is 5.087943210601806 and perplexity is 162.05620355709766
At time: 809.0500693321228 and batch: 1350, loss is 5.0631331443786625 and perplexity is 158.08504447321397
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1591109212239585 and perplexity of 174.009678498807
Finished 26 epochs...
Completing Train Step...
At time: 812.231645822525 and batch: 50, loss is 5.195788879394531 and perplexity is 180.51048764736964
At time: 813.3441216945648 and batch: 100, loss is 5.202289543151855 and perplexity is 181.68774797322143
At time: 814.4181258678436 and batch: 150, loss is 5.180950632095337 and perplexity is 177.85180228783216
At time: 815.4923341274261 and batch: 200, loss is 5.157755184173584 and perplexity is 173.77392697518974
At time: 816.5686197280884 and batch: 250, loss is 5.18771240234375 and perplexity is 179.05847032161762
At time: 817.6694781780243 and batch: 300, loss is 5.202913866043091 and perplexity is 181.8012152097492
At time: 818.7431581020355 and batch: 350, loss is 5.189161739349365 and perplexity is 179.31817454283205
At time: 819.8184659481049 and batch: 400, loss is 5.221674795150757 and perplexity is 185.2441704547629
At time: 820.8940377235413 and batch: 450, loss is 5.188384294509888 and perplexity is 179.17881873115664
At time: 821.9691200256348 and batch: 500, loss is 5.219873790740967 and perplexity is 184.91084513716768
At time: 823.043267250061 and batch: 550, loss is 5.191008214950561 and perplexity is 179.6495870553738
At time: 824.1173827648163 and batch: 600, loss is 5.151496639251709 and perplexity is 172.68975126702364
At time: 825.191112279892 and batch: 650, loss is 5.1565492153167725 and perplexity is 173.56448734535073
At time: 826.2654721736908 and batch: 700, loss is 5.177608308792114 and perplexity is 177.2583563610552
At time: 827.3393061161041 and batch: 750, loss is 5.1577199268341065 and perplexity is 173.76780027686024
At time: 828.415322303772 and batch: 800, loss is 5.131847400665283 and perplexity is 169.32964897724756
At time: 829.4909188747406 and batch: 850, loss is 5.1069896697998045 and perplexity is 165.17238230815857
At time: 830.5649862289429 and batch: 900, loss is 5.129728517532349 and perplexity is 168.97123908855298
At time: 831.6393461227417 and batch: 950, loss is 5.108065357208252 and perplexity is 165.35015175506712
At time: 832.7132971286774 and batch: 1000, loss is 5.143843450546265 and perplexity is 171.37316846754348
At time: 833.7875611782074 and batch: 1050, loss is 5.102660341262817 and perplexity is 164.4588424885558
At time: 834.8611097335815 and batch: 1100, loss is 5.087177743911743 and perplexity is 161.9322023967903
At time: 835.9355843067169 and batch: 1150, loss is 5.1009282207489015 and perplexity is 164.17422651952552
At time: 837.0102274417877 and batch: 1200, loss is 5.081253223419189 and perplexity is 160.97566804682197
At time: 838.0845417976379 and batch: 1250, loss is 5.10740400314331 and perplexity is 165.24083291327992
At time: 839.1580808162689 and batch: 1300, loss is 5.089598798751831 and perplexity is 162.3247241057301
At time: 840.2317991256714 and batch: 1350, loss is 5.063980894088745 and perplexity is 158.2191178461364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.158468017578125 and perplexity of 173.89784299566816
Finished 27 epochs...
Completing Train Step...
At time: 843.4052412509918 and batch: 50, loss is 5.1941953372955325 and perplexity is 180.223065656337
At time: 844.5057611465454 and batch: 100, loss is 5.200297327041626 and perplexity is 181.32614702788945
At time: 845.5796055793762 and batch: 150, loss is 5.178709278106689 and perplexity is 177.45361984198738
At time: 846.6538889408112 and batch: 200, loss is 5.155713872909546 and perplexity is 173.41956210820823
At time: 847.7277991771698 and batch: 250, loss is 5.185787944793701 and perplexity is 178.71421125873144
At time: 848.8019149303436 and batch: 300, loss is 5.200778074264527 and perplexity is 181.41334002672914
At time: 849.8759498596191 and batch: 350, loss is 5.18731520652771 and perplexity is 178.98736316904606
At time: 850.9513144493103 and batch: 400, loss is 5.220001621246338 and perplexity is 184.93448389479514
At time: 852.0252327919006 and batch: 450, loss is 5.186771230697632 and perplexity is 178.8900248468402
At time: 853.0993528366089 and batch: 500, loss is 5.218277425765991 and perplexity is 184.61589542682805
At time: 854.1739475727081 and batch: 550, loss is 5.189756908416748 and perplexity is 179.42493093944069
At time: 855.2479219436646 and batch: 600, loss is 5.150280313491821 and perplexity is 172.47983196509654
At time: 856.3227438926697 and batch: 650, loss is 5.155518579483032 and perplexity is 173.38569771455394
At time: 857.3970422744751 and batch: 700, loss is 5.176814470291138 and perplexity is 177.11769769067678
At time: 858.4725341796875 and batch: 750, loss is 5.157251214981079 and perplexity is 173.6863723338077
At time: 859.5469655990601 and batch: 800, loss is 5.1316297912597655 and perplexity is 169.29280526191206
At time: 860.6212146282196 and batch: 850, loss is 5.106947431564331 and perplexity is 165.16540586551824
At time: 861.6949872970581 and batch: 900, loss is 5.129806070327759 and perplexity is 168.98434378863473
At time: 862.7696290016174 and batch: 950, loss is 5.108116750717163 and perplexity is 165.35864989793757
At time: 863.845921754837 and batch: 1000, loss is 5.144251346588135 and perplexity is 171.44308516304642
At time: 864.9214136600494 and batch: 1050, loss is 5.103344449996948 and perplexity is 164.57138871164503
At time: 865.9955885410309 and batch: 1100, loss is 5.088028354644775 and perplexity is 162.07000226488728
At time: 867.0696637630463 and batch: 1150, loss is 5.101889896392822 and perplexity is 164.33218481467787
At time: 868.1455175876617 and batch: 1200, loss is 5.08244179725647 and perplexity is 161.1671132651521
At time: 869.21919298172 and batch: 1250, loss is 5.108457927703857 and perplexity is 165.41507608894514
At time: 870.2925660610199 and batch: 1300, loss is 5.090477170944214 and perplexity is 162.46736826768213
At time: 871.3668878078461 and batch: 1350, loss is 5.064295148849487 and perplexity is 158.2688467705263
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.158165690104167 and perplexity of 173.8452768465645
Finished 28 epochs...
Completing Train Step...
At time: 874.5639672279358 and batch: 50, loss is 5.192967662811279 and perplexity is 180.00194615631318
At time: 875.637882232666 and batch: 100, loss is 5.198822088241577 and perplexity is 181.05884487606164
At time: 876.71258020401 and batch: 150, loss is 5.1770079135894775 and perplexity is 177.15196323642564
At time: 877.7866771221161 and batch: 200, loss is 5.154197673797608 and perplexity is 173.15682275506742
At time: 878.8613424301147 and batch: 250, loss is 5.1843961811065675 and perplexity is 178.4656563141209
At time: 879.9353606700897 and batch: 300, loss is 5.199187507629395 and perplexity is 181.12501937830186
At time: 881.0093405246735 and batch: 350, loss is 5.186011304855347 and perplexity is 178.75413333430777
At time: 882.0834383964539 and batch: 400, loss is 5.2187892436981205 and perplexity is 184.7104093375576
At time: 883.1573164463043 and batch: 450, loss is 5.185618057250976 and perplexity is 178.68385251938946
At time: 884.2306756973267 and batch: 500, loss is 5.217139654159546 and perplexity is 184.4059641524813
At time: 885.3052554130554 and batch: 550, loss is 5.188829879760743 and perplexity is 179.25867596032933
At time: 886.3798379898071 and batch: 600, loss is 5.14944935798645 and perplexity is 172.33656843021458
At time: 887.4543304443359 and batch: 650, loss is 5.154804267883301 and perplexity is 173.2618905231697
At time: 888.528472661972 and batch: 700, loss is 5.176251592636109 and perplexity is 177.01803014928396
At time: 889.6026310920715 and batch: 750, loss is 5.156959686279297 and perplexity is 173.63574515116102
At time: 890.6764035224915 and batch: 800, loss is 5.131481800079346 and perplexity is 169.26775327360718
At time: 891.7508330345154 and batch: 850, loss is 5.106945171356201 and perplexity is 165.165032557747
At time: 892.8244106769562 and batch: 900, loss is 5.129847478866577 and perplexity is 168.99134132827214
At time: 893.89861369133 and batch: 950, loss is 5.108159084320068 and perplexity is 165.36565027353376
At time: 894.9729602336884 and batch: 1000, loss is 5.144604177474975 and perplexity is 171.5035862515259
At time: 896.0471396446228 and batch: 1050, loss is 5.103836393356323 and perplexity is 164.65236843054913
At time: 897.1216115951538 and batch: 1100, loss is 5.088566541671753 and perplexity is 162.15724971318497
At time: 898.1971914768219 and batch: 1150, loss is 5.10251823425293 and perplexity is 164.43547339469555
At time: 899.2979011535645 and batch: 1200, loss is 5.083227930068969 and perplexity is 161.293861835263
At time: 900.3718991279602 and batch: 1250, loss is 5.1091341876983645 and perplexity is 165.5269775203585
At time: 901.445050239563 and batch: 1300, loss is 5.091000919342041 and perplexity is 162.55248257880783
At time: 902.5192718505859 and batch: 1350, loss is 5.064402265548706 and perplexity is 158.28580091500135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157984619140625 and perplexity of 173.81380136451259
Finished 29 epochs...
Completing Train Step...
At time: 905.6901526451111 and batch: 50, loss is 5.191923780441284 and perplexity is 179.8141433372357
At time: 906.7639057636261 and batch: 100, loss is 5.197600517272949 and perplexity is 180.83780368378652
At time: 907.8383960723877 and batch: 150, loss is 5.1756195545196535 and perplexity is 176.90618335637126
At time: 908.9116764068604 and batch: 200, loss is 5.152991781234741 and perplexity is 172.94814008002882
At time: 909.9862282276154 and batch: 250, loss is 5.183299732208252 and perplexity is 178.2700850783941
At time: 911.0602390766144 and batch: 300, loss is 5.197979984283447 and perplexity is 180.9064386860713
At time: 912.1340093612671 and batch: 350, loss is 5.184913997650146 and perplexity is 178.55809271390407
At time: 913.2083089351654 and batch: 400, loss is 5.217820167541504 and perplexity is 184.53149758754668
At time: 914.2822914123535 and batch: 450, loss is 5.184701290130615 and perplexity is 178.5201161040091
At time: 915.3561511039734 and batch: 500, loss is 5.2162202453613284 and perplexity is 184.23649760305176
At time: 916.4294288158417 and batch: 550, loss is 5.18806565284729 and perplexity is 179.1217339897253
At time: 917.5034065246582 and batch: 600, loss is 5.148798389434814 and perplexity is 172.22441925062458
At time: 918.5764939785004 and batch: 650, loss is 5.154226016998291 and perplexity is 173.16173064319676
At time: 919.6496860980988 and batch: 700, loss is 5.175821990966797 and perplexity is 176.94199924070546
At time: 920.7229266166687 and batch: 750, loss is 5.156756772994995 and perplexity is 173.60051572622018
At time: 921.7963788509369 and batch: 800, loss is 5.131411666870117 and perplexity is 169.25588239912733
At time: 922.8700749874115 and batch: 850, loss is 5.106920566558838 and perplexity is 165.16096875558415
At time: 923.9439415931702 and batch: 900, loss is 5.129834718704224 and perplexity is 168.98918498507814
At time: 925.0171236991882 and batch: 950, loss is 5.10815842628479 and perplexity is 165.36554145713794
At time: 926.1368119716644 and batch: 1000, loss is 5.144844827651977 and perplexity is 171.54486358641353
At time: 927.2108964920044 and batch: 1050, loss is 5.104132328033447 and perplexity is 164.70110198665736
At time: 928.2888159751892 and batch: 1100, loss is 5.0888982677459715 and perplexity is 162.21105042409437
At time: 929.368554353714 and batch: 1150, loss is 5.102953109741211 and perplexity is 164.50699790247927
At time: 930.4444687366486 and batch: 1200, loss is 5.083763589859009 and perplexity is 161.38028361569832
At time: 931.5214047431946 and batch: 1250, loss is 5.109623670578003 and perplexity is 165.60801997480192
At time: 932.5949342250824 and batch: 1300, loss is 5.091349744796753 and perplexity is 162.60919491323588
At time: 933.6686391830444 and batch: 1350, loss is 5.064399251937866 and perplexity is 158.28532390391467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1578377278645835 and perplexity of 173.788271508539
Finished 30 epochs...
Completing Train Step...
At time: 936.8256800174713 and batch: 50, loss is 5.190989027023315 and perplexity is 179.64613998523873
At time: 937.9256958961487 and batch: 100, loss is 5.196551189422608 and perplexity is 180.64814506442477
At time: 938.9998772144318 and batch: 150, loss is 5.174520149230957 and perplexity is 176.7117986361601
At time: 940.0742361545563 and batch: 200, loss is 5.151952590942383 and perplexity is 172.76850740420835
At time: 941.1485106945038 and batch: 250, loss is 5.182307624816895 and perplexity is 178.09330971390247
At time: 942.2236278057098 and batch: 300, loss is 5.196832113265991 and perplexity is 180.6989005645176
At time: 943.2982878684998 and batch: 350, loss is 5.184033489227295 and perplexity is 178.40094000659568
At time: 944.3732852935791 and batch: 400, loss is 5.217013883590698 and perplexity is 184.38277276789836
At time: 945.4480347633362 and batch: 450, loss is 5.183917751312256 and perplexity is 178.38029344857623
At time: 946.5227739810944 and batch: 500, loss is 5.215405263900757 and perplexity is 184.0864094409867
At time: 947.5971949100494 and batch: 550, loss is 5.187410907745361 and perplexity is 179.00449329731947
At time: 948.6730010509491 and batch: 600, loss is 5.14824948310852 and perplexity is 172.12991011805892
At time: 949.7473104000092 and batch: 650, loss is 5.153727579116821 and perplexity is 173.07544178362792
At time: 950.821763753891 and batch: 700, loss is 5.1754318046569825 and perplexity is 176.87297236251777
At time: 951.8957326412201 and batch: 750, loss is 5.156542854309082 and perplexity is 173.56338330382337
At time: 952.9961190223694 and batch: 800, loss is 5.131310787200928 and perplexity is 169.23880878290734
At time: 954.0698025226593 and batch: 850, loss is 5.106830596923828 and perplexity is 165.14610995193797
At time: 955.1441838741302 and batch: 900, loss is 5.129799861907959 and perplexity is 168.9832946661455
At time: 956.2190008163452 and batch: 950, loss is 5.108099803924561 and perplexity is 165.35584762293763
At time: 957.2931959629059 and batch: 1000, loss is 5.144988098144531 and perplexity is 171.56944266420092
At time: 958.3676843643188 and batch: 1050, loss is 5.104369411468506 and perplexity is 164.74015451884554
At time: 959.4424405097961 and batch: 1100, loss is 5.089130268096924 and perplexity is 162.24868781049577
At time: 960.5174744129181 and batch: 1150, loss is 5.103270196914673 and perplexity is 164.55916923245155
At time: 961.5924036502838 and batch: 1200, loss is 5.084099273681641 and perplexity is 161.43446545967535
At time: 962.6677055358887 and batch: 1250, loss is 5.109973201751709 and perplexity is 165.6659152579125
At time: 963.7419152259827 and batch: 1300, loss is 5.091608123779297 and perplexity is 162.65121513990772
At time: 964.8161354064941 and batch: 1350, loss is 5.064335536956787 and perplexity is 158.27523907877773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1577681477864585 and perplexity of 173.77617972770864
Finished 31 epochs...
Completing Train Step...
At time: 967.9611463546753 and batch: 50, loss is 5.190174856185913 and perplexity is 179.49993686224664
At time: 969.0614037513733 and batch: 100, loss is 5.195620594024658 and perplexity is 180.480112929072
At time: 970.1445949077606 and batch: 150, loss is 5.173454933166504 and perplexity is 176.52366261002274
At time: 971.2189106941223 and batch: 200, loss is 5.1510426902771 and perplexity is 172.61137672187851
At time: 972.293298959732 and batch: 250, loss is 5.181440382003784 and perplexity is 177.93892652452186
At time: 973.3681254386902 and batch: 300, loss is 5.195799531936646 and perplexity is 180.51241055318343
At time: 974.4427907466888 and batch: 350, loss is 5.183277730941772 and perplexity is 178.26616295389292
At time: 975.5182774066925 and batch: 400, loss is 5.216305456161499 and perplexity is 184.2521972113117
At time: 976.5932459831238 and batch: 450, loss is 5.1831920337677 and perplexity is 178.25088670207018
At time: 977.6679735183716 and batch: 500, loss is 5.214664926528931 and perplexity is 183.95017382881235
At time: 978.7431683540344 and batch: 550, loss is 5.186805725097656 and perplexity is 178.89619565734623
At time: 979.8178129196167 and batch: 600, loss is 5.14774827003479 and perplexity is 172.04365797388454
At time: 980.9378445148468 and batch: 650, loss is 5.153267068862915 and perplexity is 172.99575711719845
At time: 982.0120468139648 and batch: 700, loss is 5.175053339004517 and perplexity is 176.80604468334184
At time: 983.0871601104736 and batch: 750, loss is 5.156337366104126 and perplexity is 173.52772173988308
At time: 984.16681599617 and batch: 800, loss is 5.131189584732056 and perplexity is 169.218297864466
At time: 985.2438714504242 and batch: 850, loss is 5.106775197982788 and perplexity is 165.13696128574531
At time: 986.320306301117 and batch: 900, loss is 5.129696903228759 and perplexity is 168.96589726494204
At time: 987.3934307098389 and batch: 950, loss is 5.107986831665039 and perplexity is 165.337168054363
At time: 988.4682931900024 and batch: 1000, loss is 5.145062932968139 and perplexity is 171.5822825136072
At time: 989.5411596298218 and batch: 1050, loss is 5.1045542812347415 and perplexity is 164.77061280802278
At time: 990.61470079422 and batch: 1100, loss is 5.089267463684082 and perplexity is 162.27094914152875
At time: 991.6883993148804 and batch: 1150, loss is 5.103503713607788 and perplexity is 164.5976010325312
At time: 992.7617645263672 and batch: 1200, loss is 5.084367265701294 and perplexity is 161.47773440572266
At time: 993.8349957466125 and batch: 1250, loss is 5.110217447280884 and perplexity is 165.70638335892616
At time: 994.9075174331665 and batch: 1300, loss is 5.09179084777832 and perplexity is 162.6809381358537
At time: 995.9806027412415 and batch: 1350, loss is 5.0642298412323 and perplexity is 158.25851094677645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157720947265625 and perplexity of 173.76797759509108
Finished 32 epochs...
Completing Train Step...
At time: 999.1598663330078 and batch: 50, loss is 5.189398622512817 and perplexity is 179.36065703077657
At time: 1000.231415271759 and batch: 100, loss is 5.194756956100464 and perplexity is 180.32431074700415
At time: 1001.3045628070831 and batch: 150, loss is 5.172460947036743 and perplexity is 176.3482877123611
At time: 1002.3767371177673 and batch: 200, loss is 5.150209980010986 and perplexity is 172.46770128474208
At time: 1003.4507331848145 and batch: 250, loss is 5.18068223953247 and perplexity is 177.80407459197144
At time: 1004.5243704319 and batch: 300, loss is 5.194840784072876 and perplexity is 180.33942760194955
At time: 1005.5984134674072 and batch: 350, loss is 5.182593851089478 and perplexity is 178.14429199399976
At time: 1006.6727266311646 and batch: 400, loss is 5.215686349868775 and perplexity is 184.13816082053592
At time: 1007.7843651771545 and batch: 450, loss is 5.182523832321167 and perplexity is 178.13181898677018
At time: 1008.8597383499146 and batch: 500, loss is 5.214004135131836 and perplexity is 183.82866128809437
At time: 1009.9347109794617 and batch: 550, loss is 5.186276273727417 and perplexity is 178.80150389097957
At time: 1011.0095956325531 and batch: 600, loss is 5.147312879562378 and perplexity is 171.9687681087137
At time: 1012.0841941833496 and batch: 650, loss is 5.152848463058472 and perplexity is 172.9233552441046
At time: 1013.1585209369659 and batch: 700, loss is 5.17472014427185 and perplexity is 176.74714365385103
At time: 1014.2330181598663 and batch: 750, loss is 5.156130933761597 and perplexity is 173.4919037029184
At time: 1015.3075988292694 and batch: 800, loss is 5.131036338806152 and perplexity is 169.19236783661623
At time: 1016.3829572200775 and batch: 850, loss is 5.1066748142242435 and perplexity is 165.12038504890322
At time: 1017.457923412323 and batch: 900, loss is 5.129538526535034 and perplexity is 168.93913912376982
At time: 1018.5324239730835 and batch: 950, loss is 5.107838068008423 and perplexity is 165.31257372208538
At time: 1019.6083462238312 and batch: 1000, loss is 5.145093193054199 and perplexity is 171.58747468679982
At time: 1020.682623386383 and batch: 1050, loss is 5.1046320247650145 and perplexity is 164.78342315510207
At time: 1021.756674528122 and batch: 1100, loss is 5.089358072280884 and perplexity is 162.28565295066795
At time: 1022.8293673992157 and batch: 1150, loss is 5.103662633895874 and perplexity is 164.6237610093261
At time: 1023.906094789505 and batch: 1200, loss is 5.084590854644776 and perplexity is 161.5138430783538
At time: 1024.98042345047 and batch: 1250, loss is 5.110328254699707 and perplexity is 165.72474587288121
At time: 1026.054675579071 and batch: 1300, loss is 5.09190863609314 and perplexity is 162.70010117797912
At time: 1027.1296532154083 and batch: 1350, loss is 5.064084949493409 and perplexity is 158.23558225706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15765869140625 and perplexity of 173.75715985705128
Finished 33 epochs...
Completing Train Step...
At time: 1030.3410279750824 and batch: 50, loss is 5.188650426864624 and perplexity is 179.22651035796537
At time: 1031.4156186580658 and batch: 100, loss is 5.193930435180664 and perplexity is 180.17533050794657
At time: 1032.4905924797058 and batch: 150, loss is 5.1715818119049075 and perplexity is 176.19332186513515
At time: 1033.565183877945 and batch: 200, loss is 5.149430685043335 and perplexity is 172.33335042932046
At time: 1034.6661603450775 and batch: 250, loss is 5.179946241378784 and perplexity is 177.67325926717774
At time: 1035.7398509979248 and batch: 300, loss is 5.193953409194946 and perplexity is 180.17946990611205
At time: 1036.8168742656708 and batch: 350, loss is 5.181956624984741 and perplexity is 178.0308099614281
At time: 1037.8948826789856 and batch: 400, loss is 5.215100269317627 and perplexity is 184.03027264442403
At time: 1038.9695842266083 and batch: 450, loss is 5.181918134689331 and perplexity is 178.02395763483557
At time: 1040.0443675518036 and batch: 500, loss is 5.213393306732177 and perplexity is 183.7164078084054
At time: 1041.1185491085052 and batch: 550, loss is 5.185776252746582 and perplexity is 178.71212173596786
At time: 1042.1932656764984 and batch: 600, loss is 5.1468915843963625 and perplexity is 171.89633375719632
At time: 1043.2681469917297 and batch: 650, loss is 5.152488374710083 and perplexity is 172.8610987683054
At time: 1044.3443818092346 and batch: 700, loss is 5.174433765411377 and perplexity is 176.69653425533627
At time: 1045.422107219696 and batch: 750, loss is 5.155906667709351 and perplexity is 173.4529997211625
At time: 1046.496738433838 and batch: 800, loss is 5.130881137847901 and perplexity is 169.16611105659058
At time: 1047.5711736679077 and batch: 850, loss is 5.106547117233276 and perplexity is 165.09930101879738
At time: 1048.6522617340088 and batch: 900, loss is 5.12942419052124 and perplexity is 168.91982440023384
At time: 1049.7262663841248 and batch: 950, loss is 5.107648963928223 and perplexity is 165.28131539551782
At time: 1050.8008935451508 and batch: 1000, loss is 5.14507230758667 and perplexity is 171.58389103959198
At time: 1051.8749177455902 and batch: 1050, loss is 5.104663877487183 and perplexity is 164.78867203929295
At time: 1052.9499232769012 and batch: 1100, loss is 5.08937177658081 and perplexity is 162.28787697716902
At time: 1054.0232329368591 and batch: 1150, loss is 5.103767499923706 and perplexity is 164.64102535443573
At time: 1055.0965900421143 and batch: 1200, loss is 5.084765625 and perplexity is 161.54207337692006
At time: 1056.1701982021332 and batch: 1250, loss is 5.110389471054077 and perplexity is 165.7348912481808
At time: 1057.2441017627716 and batch: 1300, loss is 5.091946573257446 and perplexity is 162.7062736755329
At time: 1058.3192472457886 and batch: 1350, loss is 5.063861865997314 and perplexity is 158.20028644726625
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15760009765625 and perplexity of 173.74697907173396
Finished 34 epochs...
Completing Train Step...
At time: 1061.5036568641663 and batch: 50, loss is 5.187895545959472 and perplexity is 179.09126674043378
At time: 1062.6052222251892 and batch: 100, loss is 5.193093938827515 and perplexity is 180.02467752017128
At time: 1063.6803212165833 and batch: 150, loss is 5.170732707977295 and perplexity is 176.04377892125555
At time: 1064.7553644180298 and batch: 200, loss is 5.14873740196228 and perplexity is 172.21391603887122
At time: 1065.8296475410461 and batch: 250, loss is 5.179100980758667 and perplexity is 177.52314251070052
At time: 1066.9045777320862 and batch: 300, loss is 5.193101243972778 and perplexity is 180.02599263139516
At time: 1067.9791748523712 and batch: 350, loss is 5.181277055740356 and perplexity is 177.90986679770702
At time: 1069.0548205375671 and batch: 400, loss is 5.21449878692627 and perplexity is 183.91961495861258
At time: 1070.1298649311066 and batch: 450, loss is 5.181301422119141 and perplexity is 177.9142018697258
At time: 1071.2039382457733 and batch: 500, loss is 5.212781238555908 and perplexity is 183.60399524731235
At time: 1072.2780787944794 and batch: 550, loss is 5.185303115844727 and perplexity is 178.6275864363277
At time: 1073.3526294231415 and batch: 600, loss is 5.146475210189819 and perplexity is 171.82477545616968
At time: 1074.4269411563873 and batch: 650, loss is 5.152142658233642 and perplexity is 172.8013481673042
At time: 1075.5016701221466 and batch: 700, loss is 5.174170818328857 and perplexity is 176.6500785251296
At time: 1076.5761244297028 and batch: 750, loss is 5.155685338973999 and perplexity is 173.41461383619765
At time: 1077.6509051322937 and batch: 800, loss is 5.130779647827149 and perplexity is 169.1489432556639
At time: 1078.7257437705994 and batch: 850, loss is 5.106471538543701 and perplexity is 165.08682350149974
At time: 1079.800597667694 and batch: 900, loss is 5.129270210266113 and perplexity is 168.8938160850116
At time: 1080.8759381771088 and batch: 950, loss is 5.107446718215942 and perplexity is 165.24789133820906
At time: 1081.950656414032 and batch: 1000, loss is 5.14501579284668 and perplexity is 171.5741942946105
At time: 1083.0259184837341 and batch: 1050, loss is 5.104725332260132 and perplexity is 164.7987994009018
At time: 1084.1006536483765 and batch: 1100, loss is 5.08929256439209 and perplexity is 162.27502230836083
At time: 1085.1748802661896 and batch: 1150, loss is 5.1038393211364745 and perplexity is 164.65285049719105
At time: 1086.2501590251923 and batch: 1200, loss is 5.084847145080566 and perplexity is 161.55524283653693
At time: 1087.3248002529144 and batch: 1250, loss is 5.110408115386963 and perplexity is 165.7379812934698
At time: 1088.3969776630402 and batch: 1300, loss is 5.0919442653656 and perplexity is 162.70589816748398
At time: 1089.4695377349854 and batch: 1350, loss is 5.0635710716247555 and perplexity is 158.15428938239816
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157527669270833 and perplexity of 173.73439531428494
Finished 35 epochs...
Completing Train Step...
At time: 1092.605720758438 and batch: 50, loss is 5.187222232818604 and perplexity is 178.9707228235783
At time: 1093.7051575183868 and batch: 100, loss is 5.192393188476562 and perplexity is 179.8985693545501
At time: 1094.7786910533905 and batch: 150, loss is 5.169968891143799 and perplexity is 175.9093650598032
At time: 1095.8512048721313 and batch: 200, loss is 5.148082914352417 and perplexity is 172.101241040795
At time: 1096.9239149093628 and batch: 250, loss is 5.17843955039978 and perplexity is 177.4057621385891
At time: 1097.996813774109 and batch: 300, loss is 5.192354755401611 and perplexity is 179.891655432213
At time: 1099.0694818496704 and batch: 350, loss is 5.18072130203247 and perplexity is 177.8110201992907
At time: 1100.1430158615112 and batch: 400, loss is 5.213941116333007 and perplexity is 183.81707699168786
At time: 1101.2149443626404 and batch: 450, loss is 5.180796985626221 and perplexity is 177.82447808557197
At time: 1102.2872457504272 and batch: 500, loss is 5.212184925079345 and perplexity is 183.49454234795846
At time: 1103.3616716861725 and batch: 550, loss is 5.18483263015747 and perplexity is 178.5435644806739
At time: 1104.4360263347626 and batch: 600, loss is 5.1460861968994145 and perplexity is 171.7579463344475
At time: 1105.5096306800842 and batch: 650, loss is 5.15178876876831 and perplexity is 172.74020640994263
At time: 1106.5836353302002 and batch: 700, loss is 5.173873205184936 and perplexity is 176.597512962375
At time: 1107.6579685211182 and batch: 750, loss is 5.155443134307862 and perplexity is 173.3726170936589
At time: 1108.7371406555176 and batch: 800, loss is 5.130569868087768 and perplexity is 169.11346295608536
At time: 1109.8115711212158 and batch: 850, loss is 5.106320142745972 and perplexity is 165.06183194201736
At time: 1110.8862631320953 and batch: 900, loss is 5.129085311889648 and perplexity is 168.86259077946565
At time: 1111.9603080749512 and batch: 950, loss is 5.107275857925415 and perplexity is 165.21965944740916
At time: 1113.0347859859467 and batch: 1000, loss is 5.1449336910247805 and perplexity is 171.56010831891805
At time: 1114.1096572875977 and batch: 1050, loss is 5.104713363647461 and perplexity is 164.79682699970667
At time: 1115.1836609840393 and batch: 1100, loss is 5.089247436523437 and perplexity is 162.26769934770454
At time: 1116.3045072555542 and batch: 1150, loss is 5.103830842971802 and perplexity is 164.6514545491283
At time: 1117.378491640091 and batch: 1200, loss is 5.084903402328491 and perplexity is 161.5643317455429
At time: 1118.4518692493439 and batch: 1250, loss is 5.11042067527771 and perplexity is 165.7400629574802
At time: 1119.5258572101593 and batch: 1300, loss is 5.091913137435913 and perplexity is 162.70083354855208
At time: 1120.6064233779907 and batch: 1350, loss is 5.063335609436035 and perplexity is 158.11705441115066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157477213541667 and perplexity of 173.7256296398292
Finished 36 epochs...
Completing Train Step...
At time: 1123.787145614624 and batch: 50, loss is 5.186539068222046 and perplexity is 178.84849811647484
At time: 1124.8608133792877 and batch: 100, loss is 5.1917055797576905 and perplexity is 179.77491204854235
At time: 1125.9352498054504 and batch: 150, loss is 5.1691996860504155 and perplexity is 175.77410670760122
At time: 1127.0091755390167 and batch: 200, loss is 5.147457427978516 and perplexity is 171.99362771843434
At time: 1128.084370136261 and batch: 250, loss is 5.177781963348389 and perplexity is 177.28914075512293
At time: 1129.159004688263 and batch: 300, loss is 5.191609592437744 and perplexity is 179.75765676469865
At time: 1130.233950138092 and batch: 350, loss is 5.18016547203064 and perplexity is 177.71221496160942
At time: 1131.308209657669 and batch: 400, loss is 5.213332939147949 and perplexity is 183.70531762742996
At time: 1132.3831253051758 and batch: 450, loss is 5.180298500061035 and perplexity is 177.73585724005088
At time: 1133.4571709632874 and batch: 500, loss is 5.21159951210022 and perplexity is 183.387153697691
At time: 1134.530978679657 and batch: 550, loss is 5.184358167648315 and perplexity is 178.458872346287
At time: 1135.6053552627563 and batch: 600, loss is 5.145712747573852 and perplexity is 171.69381542079748
At time: 1136.6796386241913 and batch: 650, loss is 5.151448421478271 and perplexity is 172.68142475246657
At time: 1137.7540743350983 and batch: 700, loss is 5.173551225662232 and perplexity is 176.5406613324621
At time: 1138.8287720680237 and batch: 750, loss is 5.155212316513062 and perplexity is 173.33260422652117
At time: 1139.9030213356018 and batch: 800, loss is 5.130447444915771 and perplexity is 169.0927608167595
At time: 1140.977499961853 and batch: 850, loss is 5.106190156936646 and perplexity is 165.04037764061113
At time: 1142.051189661026 and batch: 900, loss is 5.128893737792969 and perplexity is 168.83024417965834
At time: 1143.1535437107086 and batch: 950, loss is 5.107041940689087 and perplexity is 165.18101624111648
At time: 1144.228420972824 and batch: 1000, loss is 5.144812679290771 and perplexity is 171.53934878882225
At time: 1145.3030960559845 and batch: 1050, loss is 5.104667730331421 and perplexity is 164.78930694560165
At time: 1146.377678155899 and batch: 1100, loss is 5.089161224365235 and perplexity is 162.25371050215014
At time: 1147.4516198635101 and batch: 1150, loss is 5.103771543502807 and perplexity is 164.64169109479099
At time: 1148.5259573459625 and batch: 1200, loss is 5.084947576522827 and perplexity is 161.57146887736857
At time: 1149.5996441841125 and batch: 1250, loss is 5.110423545837403 and perplexity is 165.7405387249073
At time: 1150.6739616394043 and batch: 1300, loss is 5.0918872356414795 and perplexity is 162.69661935958507
At time: 1151.7481217384338 and batch: 1350, loss is 5.06307957649231 and perplexity is 158.07657641832753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157442220052084 and perplexity of 173.71955048018415
Finished 37 epochs...
Completing Train Step...
At time: 1154.9195523262024 and batch: 50, loss is 5.185915002822876 and perplexity is 178.73691977681867
At time: 1155.9931182861328 and batch: 100, loss is 5.191078596115112 and perplexity is 179.66223144748008
At time: 1157.0676658153534 and batch: 150, loss is 5.168504419326783 and perplexity is 175.65193929472085
At time: 1158.1412658691406 and batch: 200, loss is 5.1468501663208 and perplexity is 171.88921428929427
At time: 1159.2162425518036 and batch: 250, loss is 5.177216196060181 and perplexity is 177.18886472785198
At time: 1160.2911891937256 and batch: 300, loss is 5.19093804359436 and perplexity is 179.6369812424978
At time: 1161.3651599884033 and batch: 350, loss is 5.1796572971343995 and perplexity is 177.6219290176787
At time: 1162.440644979477 and batch: 400, loss is 5.212858772277832 and perplexity is 183.6182313003039
At time: 1163.514816045761 and batch: 450, loss is 5.17981689453125 and perplexity is 177.65027927742707
At time: 1164.5894260406494 and batch: 500, loss is 5.211072950363159 and perplexity is 183.2906144586507
At time: 1165.6636416912079 and batch: 550, loss is 5.183910360336304 and perplexity is 178.37897504898916
At time: 1166.7379760742188 and batch: 600, loss is 5.145348587036133 and perplexity is 171.6313026916761
At time: 1167.813479423523 and batch: 650, loss is 5.151154155731201 and perplexity is 172.63061799971683
At time: 1168.8875799179077 and batch: 700, loss is 5.173261651992798 and perplexity is 176.48954720636542
At time: 1169.9616396427155 and batch: 750, loss is 5.155006361007691 and perplexity is 173.29690909835065
At time: 1171.0823283195496 and batch: 800, loss is 5.130300245285034 and perplexity is 169.06787225664533
At time: 1172.1563880443573 and batch: 850, loss is 5.106035051345825 and perplexity is 165.01478094047485
At time: 1173.230173587799 and batch: 900, loss is 5.1287308692932125 and perplexity is 168.8027492901618
At time: 1174.3040311336517 and batch: 950, loss is 5.106864051818848 and perplexity is 165.15163499012857
At time: 1175.3780994415283 and batch: 1000, loss is 5.144706773757934 and perplexity is 171.52118278464346
At time: 1176.4530432224274 and batch: 1050, loss is 5.104598941802979 and perplexity is 164.777971721545
At time: 1177.5275394916534 and batch: 1100, loss is 5.089094877243042 and perplexity is 162.24294579250093
At time: 1178.6022264957428 and batch: 1150, loss is 5.103725471496582 and perplexity is 164.63410589650795
At time: 1179.6766376495361 and batch: 1200, loss is 5.084974327087402 and perplexity is 161.57579106319045
At time: 1180.750658273697 and batch: 1250, loss is 5.110401391983032 and perplexity is 165.73686697382095
At time: 1181.8258471488953 and batch: 1300, loss is 5.091852025985718 and perplexity is 162.69089096847176
At time: 1182.9005844593048 and batch: 1350, loss is 5.062864875793457 and perplexity is 158.0426409100172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157425130208333 and perplexity of 173.71658166557836
Finished 38 epochs...
Completing Train Step...
At time: 1186.0526993274689 and batch: 50, loss is 5.185316572189331 and perplexity is 178.62999012685896
At time: 1187.160624742508 and batch: 100, loss is 5.190504198074341 and perplexity is 179.55906344632146
At time: 1188.2346458435059 and batch: 150, loss is 5.167831897735596 and perplexity is 175.5338492865023
At time: 1189.309128522873 and batch: 200, loss is 5.146269578933715 and perplexity is 171.78944654425163
At time: 1190.3846118450165 and batch: 250, loss is 5.176656808853149 and perplexity is 177.08977526096868
At time: 1191.4595575332642 and batch: 300, loss is 5.190336647033692 and perplexity is 179.52898065865466
At time: 1192.5342016220093 and batch: 350, loss is 5.179168472290039 and perplexity is 177.53512422377003
At time: 1193.60968375206 and batch: 400, loss is 5.212395086288452 and perplexity is 183.5331098353957
At time: 1194.6850111484528 and batch: 450, loss is 5.17934404373169 and perplexity is 177.5662970579233
At time: 1195.7583742141724 and batch: 500, loss is 5.210544176101685 and perplexity is 183.19372071907054
At time: 1196.83393907547 and batch: 550, loss is 5.183487377166748 and perplexity is 178.30353969980706
At time: 1197.9356141090393 and batch: 600, loss is 5.144983892440796 and perplexity is 171.56872109547237
At time: 1199.0101952552795 and batch: 650, loss is 5.150825395584106 and perplexity is 172.57387326056562
At time: 1200.0850489139557 and batch: 700, loss is 5.172982683181763 and perplexity is 176.4403189941084
At time: 1201.159945011139 and batch: 750, loss is 5.154769344329834 and perplexity is 173.25583970793085
At time: 1202.2342591285706 and batch: 800, loss is 5.130172176361084 and perplexity is 169.04622130260768
At time: 1203.30966091156 and batch: 850, loss is 5.105909910202026 and perplexity is 164.99413209408135
At time: 1204.3846468925476 and batch: 900, loss is 5.128522739410401 and perplexity is 168.76762004958292
At time: 1205.458776473999 and batch: 950, loss is 5.106654863357544 and perplexity is 165.1170907869736
At time: 1206.533254623413 and batch: 1000, loss is 5.14458327293396 and perplexity is 171.50000108524603
At time: 1207.608258485794 and batch: 1050, loss is 5.104503879547119 and perplexity is 164.762308300349
At time: 1208.6832916736603 and batch: 1100, loss is 5.089011754989624 and perplexity is 162.22946035372328
At time: 1209.7583520412445 and batch: 1150, loss is 5.103679332733154 and perplexity is 164.6265100576765
At time: 1210.832148551941 and batch: 1200, loss is 5.084973745346069 and perplexity is 161.57569706790167
At time: 1211.9064617156982 and batch: 1250, loss is 5.110354948043823 and perplexity is 165.72916967959424
At time: 1212.9813237190247 and batch: 1300, loss is 5.0918212890625 and perplexity is 162.68589042789878
At time: 1214.0565085411072 and batch: 1350, loss is 5.062642440795899 and perplexity is 158.00749060504629
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157419840494792 and perplexity of 173.71566275705442
Finished 39 epochs...
Completing Train Step...
At time: 1217.2340965270996 and batch: 50, loss is 5.184748668670654 and perplexity is 178.5285743268452
At time: 1218.3359107971191 and batch: 100, loss is 5.189928798675537 and perplexity is 179.45577498807293
At time: 1219.410914182663 and batch: 150, loss is 5.167233934402466 and perplexity is 175.42891785660623
At time: 1220.4867703914642 and batch: 200, loss is 5.145688886642456 and perplexity is 171.68971869532263
At time: 1221.562262058258 and batch: 250, loss is 5.1760976696014405 and perplexity is 176.990785093767
At time: 1222.6406569480896 and batch: 300, loss is 5.189767475128174 and perplexity is 179.42682688092543
At time: 1223.7188212871552 and batch: 350, loss is 5.178765563964844 and perplexity is 177.46360825236334
At time: 1224.7937171459198 and batch: 400, loss is 5.21201111793518 and perplexity is 183.4626524570088
At time: 1225.8950531482697 and batch: 450, loss is 5.178904762268067 and perplexity is 177.48831260487793
At time: 1226.9699103832245 and batch: 500, loss is 5.210046806335449 and perplexity is 183.10262835619213
At time: 1228.0476915836334 and batch: 550, loss is 5.183083124160767 and perplexity is 178.2314745251695
At time: 1229.123334646225 and batch: 600, loss is 5.144639873504639 and perplexity is 171.50970835789494
At time: 1230.1973242759705 and batch: 650, loss is 5.150491933822632 and perplexity is 172.51633606656398
At time: 1231.2739615440369 and batch: 700, loss is 5.172719793319702 and perplexity is 176.3939407194423
At time: 1232.3494215011597 and batch: 750, loss is 5.154555063247681 and perplexity is 173.21871823646552
At time: 1233.424251317978 and batch: 800, loss is 5.130061292648316 and perplexity is 169.02747786915015
At time: 1234.4994115829468 and batch: 850, loss is 5.1057351779937745 and perplexity is 164.96530482363164
At time: 1235.5740714073181 and batch: 900, loss is 5.128343982696533 and perplexity is 168.73745440065207
At time: 1236.6494636535645 and batch: 950, loss is 5.106416025161743 and perplexity is 165.07765922798274
At time: 1237.7214312553406 and batch: 1000, loss is 5.144452409744263 and perplexity is 171.47755951649063
At time: 1238.7954759597778 and batch: 1050, loss is 5.104406414031982 and perplexity is 164.7462504396519
At time: 1239.869432926178 and batch: 1100, loss is 5.088903951644897 and perplexity is 162.21197241792987
At time: 1240.9421255588531 and batch: 1150, loss is 5.103643121719361 and perplexity is 164.62054887278094
At time: 1242.0161764621735 and batch: 1200, loss is 5.084979324340821 and perplexity is 161.57659850038212
At time: 1243.0887703895569 and batch: 1250, loss is 5.1102914714813235 and perplexity is 165.71865009547412
At time: 1244.1612355709076 and batch: 1300, loss is 5.0917542362213135 and perplexity is 162.6749822424412
At time: 1245.2347648143768 and batch: 1350, loss is 5.062406721115113 and perplexity is 157.97024951919994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157420654296875 and perplexity of 173.71580412728005
Annealing...
Finished 40 epochs...
Completing Train Step...
At time: 1248.4064412117004 and batch: 50, loss is 5.1846422100067135 and perplexity is 178.50956942498337
At time: 1249.479264497757 and batch: 100, loss is 5.189973049163818 and perplexity is 179.46371616944023
At time: 1250.552886724472 and batch: 150, loss is 5.167382802963257 and perplexity is 175.4550356511396
At time: 1251.6254584789276 and batch: 200, loss is 5.146113414764404 and perplexity is 171.76262128266242
At time: 1252.724455356598 and batch: 250, loss is 5.176132230758667 and perplexity is 176.99690220582494
At time: 1253.7971034049988 and batch: 300, loss is 5.1898606014251705 and perplexity is 179.44353701495908
At time: 1254.8701045513153 and batch: 350, loss is 5.178695278167725 and perplexity is 177.4511355195308
At time: 1255.9428873062134 and batch: 400, loss is 5.212401437759399 and perplexity is 183.5342755443127
At time: 1257.0154752731323 and batch: 450, loss is 5.1786440563201905 and perplexity is 177.44204637730576
At time: 1258.0877850055695 and batch: 500, loss is 5.2094138240814205 and perplexity is 182.98676431558602
At time: 1259.1602308750153 and batch: 550, loss is 5.181551465988159 and perplexity is 177.95869378734835
At time: 1260.233116388321 and batch: 600, loss is 5.142645168304443 and perplexity is 171.16793802959597
At time: 1261.3061127662659 and batch: 650, loss is 5.148543863296509 and perplexity is 172.18058921245265
At time: 1262.3782920837402 and batch: 700, loss is 5.170224733352661 and perplexity is 175.95437585790523
At time: 1263.4579520225525 and batch: 750, loss is 5.152151069641113 and perplexity is 172.8028016759682
At time: 1264.533477306366 and batch: 800, loss is 5.127782821655273 and perplexity is 168.642792077929
At time: 1265.6072795391083 and batch: 850, loss is 5.102614631652832 and perplexity is 164.451325310812
At time: 1266.6803336143494 and batch: 900, loss is 5.124533233642578 and perplexity is 168.09566193760404
At time: 1267.753882408142 and batch: 950, loss is 5.102342395782471 and perplexity is 164.40656185451965
At time: 1268.8345394134521 and batch: 1000, loss is 5.140443534851074 and perplexity is 170.79150350855716
At time: 1269.9073553085327 and batch: 1050, loss is 5.0998751831054685 and perplexity is 164.00143587241402
At time: 1270.979995250702 and batch: 1100, loss is 5.08419792175293 and perplexity is 161.45039144385333
At time: 1272.0597219467163 and batch: 1150, loss is 5.098833255767822 and perplexity is 163.8306472830662
At time: 1273.1322824954987 and batch: 1200, loss is 5.079704504013062 and perplexity is 160.72655485881003
At time: 1274.2042956352234 and batch: 1250, loss is 5.105000143051147 and perplexity is 164.84409411277636
At time: 1275.2848114967346 and batch: 1300, loss is 5.086410932540893 and perplexity is 161.80807853856064
At time: 1276.3577671051025 and batch: 1350, loss is 5.057982578277588 and perplexity is 157.27291027288382
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156094563802084 and perplexity of 173.4855939241487
Finished 41 epochs...
Completing Train Step...
At time: 1279.571548461914 and batch: 50, loss is 5.183971500396728 and perplexity is 178.3898814837087
At time: 1280.6478011608124 and batch: 100, loss is 5.189206104278565 and perplexity is 179.3261301574237
At time: 1281.727455854416 and batch: 150, loss is 5.166744318008423 and perplexity is 175.34304600628266
At time: 1282.8003437519073 and batch: 200, loss is 5.145488986968994 and perplexity is 171.65540140674028
At time: 1283.8732588291168 and batch: 250, loss is 5.175612630844117 and perplexity is 176.90495851959741
At time: 1284.9461479187012 and batch: 300, loss is 5.189391136169434 and perplexity is 179.35931428033473
At time: 1286.0186557769775 and batch: 350, loss is 5.17805253982544 and perplexity is 177.33711751664663
At time: 1287.093193769455 and batch: 400, loss is 5.211797218322754 and perplexity is 183.4234140634418
At time: 1288.1736590862274 and batch: 450, loss is 5.178123083114624 and perplexity is 177.34962790146736
At time: 1289.2481939792633 and batch: 500, loss is 5.208933582305908 and perplexity is 182.898907524935
At time: 1290.3225519657135 and batch: 550, loss is 5.181293201446533 and perplexity is 177.91273930133164
At time: 1291.3970966339111 and batch: 600, loss is 5.142485322952271 and perplexity is 171.14057981686085
At time: 1292.4712064266205 and batch: 650, loss is 5.148268184661865 and perplexity is 172.1331292448565
At time: 1293.5451288223267 and batch: 700, loss is 5.170036687850952 and perplexity is 175.92129153979513
At time: 1294.6188027858734 and batch: 750, loss is 5.151987438201904 and perplexity is 172.77452801812336
At time: 1295.6925609111786 and batch: 800, loss is 5.127692823410034 and perplexity is 168.6276152055259
At time: 1296.7664244174957 and batch: 850, loss is 5.102602958679199 and perplexity is 164.4494056860316
At time: 1297.840773820877 and batch: 900, loss is 5.124563570022583 and perplexity is 168.1007614288315
At time: 1298.9150552749634 and batch: 950, loss is 5.102309713363647 and perplexity is 164.40118873821146
At time: 1299.9893889427185 and batch: 1000, loss is 5.140449447631836 and perplexity is 170.79251336425892
At time: 1301.0644717216492 and batch: 1050, loss is 5.099986438751221 and perplexity is 164.01968297309395
At time: 1302.1386415958405 and batch: 1100, loss is 5.084393482208252 and perplexity is 161.48196784336304
At time: 1303.2122066020966 and batch: 1150, loss is 5.099054727554321 and perplexity is 163.86693516742633
At time: 1304.286092042923 and batch: 1200, loss is 5.080029125213623 and perplexity is 160.77873857552248
At time: 1305.359860420227 and batch: 1250, loss is 5.1052503490448 and perplexity is 164.88534425344264
At time: 1306.4340732097626 and batch: 1300, loss is 5.086549282073975 and perplexity is 161.83046615929797
At time: 1307.5086102485657 and batch: 1350, loss is 5.05812141418457 and perplexity is 157.29474691584534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155998942057292 and perplexity of 173.4690057220705
Finished 42 epochs...
Completing Train Step...
At time: 1310.8376352787018 and batch: 50, loss is 5.183612871170044 and perplexity is 178.325917128893
At time: 1311.911583662033 and batch: 100, loss is 5.1887939834594725 and perplexity is 179.2522413523818
At time: 1312.9867794513702 and batch: 150, loss is 5.1663620662689205 and perplexity is 175.27603363055172
At time: 1314.061678647995 and batch: 200, loss is 5.14513165473938 and perplexity is 171.5940743571486
At time: 1315.1360399723053 and batch: 250, loss is 5.175308513641357 and perplexity is 176.85116685835754
At time: 1316.2089211940765 and batch: 300, loss is 5.189125757217408 and perplexity is 179.31172240869472
At time: 1317.2820818424225 and batch: 350, loss is 5.177772216796875 and perplexity is 177.28741280580041
At time: 1318.3553414344788 and batch: 400, loss is 5.211537284851074 and perplexity is 183.37574237463906
At time: 1319.4580736160278 and batch: 450, loss is 5.177899150848389 and perplexity is 177.30991804370063
At time: 1320.5328662395477 and batch: 500, loss is 5.208681707382202 and perplexity is 182.85284567771183
At time: 1321.6053738594055 and batch: 550, loss is 5.18112964630127 and perplexity is 177.8836431368895
At time: 1322.678328037262 and batch: 600, loss is 5.142369222640991 and perplexity is 171.120711495653
At time: 1323.750560283661 and batch: 650, loss is 5.148075218200684 and perplexity is 172.09991652862723
At time: 1324.8231246471405 and batch: 700, loss is 5.169907836914063 and perplexity is 175.89862537687102
At time: 1325.8979125022888 and batch: 750, loss is 5.151873054504395 and perplexity is 172.75476655898916
At time: 1326.9745919704437 and batch: 800, loss is 5.127664375305176 and perplexity is 168.62281813768055
At time: 1328.0471317768097 and batch: 850, loss is 5.102604532241822 and perplexity is 164.4496644576733
At time: 1329.1196639537811 and batch: 900, loss is 5.1245890140533445 and perplexity is 168.1050386441909
At time: 1330.1924624443054 and batch: 950, loss is 5.102329988479614 and perplexity is 164.40452202516946
At time: 1331.2646403312683 and batch: 1000, loss is 5.140481920242309 and perplexity is 170.798059533066
At time: 1332.3371288776398 and batch: 1050, loss is 5.100081129074097 and perplexity is 164.03521478517723
At time: 1333.4098463058472 and batch: 1100, loss is 5.084531726837159 and perplexity is 161.50429340124126
At time: 1334.4821026325226 and batch: 1150, loss is 5.099189929962158 and perplexity is 163.88909186941171
At time: 1335.5551233291626 and batch: 1200, loss is 5.0802468490600585 and perplexity is 160.81374775193817
At time: 1336.627648115158 and batch: 1250, loss is 5.105398044586182 and perplexity is 164.90969888211885
At time: 1337.707858800888 and batch: 1300, loss is 5.086610813140869 and perplexity is 161.84042406689392
At time: 1338.7797305583954 and batch: 1350, loss is 5.058169345855713 and perplexity is 157.30228649661797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15596435546875 and perplexity of 173.4630061246983
Finished 43 epochs...
Completing Train Step...
At time: 1341.9808247089386 and batch: 50, loss is 5.183313827514649 and perplexity is 178.27259786757386
At time: 1343.053383588791 and batch: 100, loss is 5.188462562561035 and perplexity is 179.19284325693468
At time: 1344.125652551651 and batch: 150, loss is 5.166057987213135 and perplexity is 175.22274396229008
At time: 1345.1979479789734 and batch: 200, loss is 5.144847269058228 and perplexity is 171.54528239762698
At time: 1346.277257680893 and batch: 250, loss is 5.175056591033935 and perplexity is 176.8066196627354
At time: 1347.3494639396667 and batch: 300, loss is 5.188914747238159 and perplexity is 179.27388983753562
At time: 1348.426260471344 and batch: 350, loss is 5.17757477760315 and perplexity is 177.25241277726087
At time: 1349.499495267868 and batch: 400, loss is 5.211362581253052 and perplexity is 183.34370877093068
At time: 1350.5746684074402 and batch: 450, loss is 5.177732238769531 and perplexity is 177.28032534643583
At time: 1351.6503958702087 and batch: 500, loss is 5.208488302230835 and perplexity is 182.81748441505104
At time: 1352.728307723999 and batch: 550, loss is 5.18099627494812 and perplexity is 177.85992013672058
At time: 1353.8308110237122 and batch: 600, loss is 5.142257490158081 and perplexity is 171.10159282178859
At time: 1354.9026112556458 and batch: 650, loss is 5.147919244766236 and perplexity is 172.07307560686783
At time: 1355.9748544692993 and batch: 700, loss is 5.169783391952515 and perplexity is 175.87673704117444
At time: 1357.0479938983917 and batch: 750, loss is 5.151775245666504 and perplexity is 172.7378704423401
At time: 1358.1196477413177 and batch: 800, loss is 5.127655820846558 and perplexity is 168.62137566693056
At time: 1359.1993565559387 and batch: 850, loss is 5.102594318389893 and perplexity is 164.4479848017287
At time: 1360.2718172073364 and batch: 900, loss is 5.124565963745117 and perplexity is 168.10116381589373
At time: 1361.3436782360077 and batch: 950, loss is 5.102315998077392 and perplexity is 164.40222195586875
At time: 1362.4158935546875 and batch: 1000, loss is 5.140504570007324 and perplexity is 170.80192811279042
At time: 1363.494989156723 and batch: 1050, loss is 5.1001490783691406 and perplexity is 164.04636124107688
At time: 1364.5670790672302 and batch: 1100, loss is 5.084638452529907 and perplexity is 161.52153097866616
At time: 1365.6392586231232 and batch: 1150, loss is 5.0992576599121096 and perplexity is 163.90019244531814
At time: 1366.7113721370697 and batch: 1200, loss is 5.080407829284668 and perplexity is 160.83963766899794
At time: 1367.7836372852325 and batch: 1250, loss is 5.105490503311157 and perplexity is 164.92494692751004
At time: 1368.8555839061737 and batch: 1300, loss is 5.086623039245605 and perplexity is 161.842402756965
At time: 1369.928278684616 and batch: 1350, loss is 5.058178606033326 and perplexity is 157.30374315047416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155948079427083 and perplexity of 173.46018285655873
Finished 44 epochs...
Completing Train Step...
At time: 1373.0758538246155 and batch: 50, loss is 5.183044891357422 and perplexity is 178.22466036651716
At time: 1374.1739246845245 and batch: 100, loss is 5.188165349960327 and perplexity is 179.1395927997074
At time: 1375.2457416057587 and batch: 150, loss is 5.165794506072998 and perplexity is 175.17658215558276
At time: 1376.3177626132965 and batch: 200, loss is 5.144610071182251 and perplexity is 171.5045970464387
At time: 1377.3899354934692 and batch: 250, loss is 5.174836454391479 and perplexity is 176.7677023308414
At time: 1378.4625086784363 and batch: 300, loss is 5.188734149932861 and perplexity is 179.2415163794883
At time: 1379.540094614029 and batch: 350, loss is 5.177415723800659 and perplexity is 177.22422234896487
At time: 1380.6493685245514 and batch: 400, loss is 5.211233911514282 and perplexity is 183.32011950146304
At time: 1381.7212193012238 and batch: 450, loss is 5.177609586715699 and perplexity is 177.25858288383412
At time: 1382.8018417358398 and batch: 500, loss is 5.208340120315552 and perplexity is 182.79039617710623
At time: 1383.8786220550537 and batch: 550, loss is 5.180879812240601 and perplexity is 177.83920729502262
At time: 1384.955265045166 and batch: 600, loss is 5.142150583267212 and perplexity is 171.08330186020964
At time: 1386.0323102474213 and batch: 650, loss is 5.147788038253784 and perplexity is 172.05049997979773
At time: 1387.1045637130737 and batch: 700, loss is 5.169671974182129 and perplexity is 175.85714233888987
At time: 1388.176946401596 and batch: 750, loss is 5.151690378189087 and perplexity is 172.72321123707493
At time: 1389.2487218379974 and batch: 800, loss is 5.127644453048706 and perplexity is 168.6194588241137
At time: 1390.3206579685211 and batch: 850, loss is 5.102593603134156 and perplexity is 164.44786717940613
At time: 1391.392828464508 and batch: 900, loss is 5.124563465118408 and perplexity is 168.1007437943607
At time: 1392.4648439884186 and batch: 950, loss is 5.102329368591309 and perplexity is 164.4044201127605
At time: 1393.5369334220886 and batch: 1000, loss is 5.140522346496582 and perplexity is 170.804964398418
At time: 1394.6089498996735 and batch: 1050, loss is 5.100197191238403 and perplexity is 164.05425417208258
At time: 1395.6807324886322 and batch: 1100, loss is 5.084710912704468 and perplexity is 161.533235281039
At time: 1396.7526857852936 and batch: 1150, loss is 5.099331665039062 and perplexity is 163.91232234869963
At time: 1397.8271379470825 and batch: 1200, loss is 5.080533542633057 and perplexity is 160.85985862939864
At time: 1398.8988828659058 and batch: 1250, loss is 5.105558633804321 and perplexity is 164.93618372825938
At time: 1399.9783437252045 and batch: 1300, loss is 5.086632194519043 and perplexity is 161.84388447519885
At time: 1401.0506234169006 and batch: 1350, loss is 5.0581679534912105 and perplexity is 157.30206747465053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155933430989584 and perplexity of 173.4576419545217
Finished 45 epochs...
Completing Train Step...
At time: 1404.2322907447815 and batch: 50, loss is 5.182808618545533 and perplexity is 178.18255569915425
At time: 1405.3313119411469 and batch: 100, loss is 5.187896146774292 and perplexity is 179.09137434115317
At time: 1406.4049201011658 and batch: 150, loss is 5.165560626983643 and perplexity is 175.13561680672788
At time: 1407.503823041916 and batch: 200, loss is 5.144398880004883 and perplexity is 171.46838061309458
At time: 1408.579653263092 and batch: 250, loss is 5.174643764495849 and perplexity is 176.73364426215676
At time: 1409.6518931388855 and batch: 300, loss is 5.18857234954834 and perplexity is 179.212517379304
At time: 1410.7243113517761 and batch: 350, loss is 5.177270879745484 and perplexity is 177.19855433289914
At time: 1411.7967660427094 and batch: 400, loss is 5.211113481521607 and perplexity is 183.29804359014187
At time: 1412.8705205917358 and batch: 450, loss is 5.177486333847046 and perplexity is 177.23673660133656
At time: 1413.9446856975555 and batch: 500, loss is 5.208197269439697 and perplexity is 182.76428627387023
At time: 1415.018214225769 and batch: 550, loss is 5.180786809921265 and perplexity is 177.8226686053554
At time: 1416.0913083553314 and batch: 600, loss is 5.142060699462891 and perplexity is 171.06792493326128
At time: 1417.1644086837769 and batch: 650, loss is 5.147660913467408 and perplexity is 172.0286294869121
At time: 1418.2373836040497 and batch: 700, loss is 5.169589605331421 and perplexity is 175.84265778473284
At time: 1419.309597492218 and batch: 750, loss is 5.151612253189087 and perplexity is 172.70971776329273
At time: 1420.3817856311798 and batch: 800, loss is 5.127628574371338 and perplexity is 168.61678139138607
At time: 1421.454154253006 and batch: 850, loss is 5.102589569091797 and perplexity is 164.4472037910822
At time: 1422.5269422531128 and batch: 900, loss is 5.1245583820343015 and perplexity is 168.0998893263133
At time: 1423.5993990898132 and batch: 950, loss is 5.10233359336853 and perplexity is 164.4051146862769
At time: 1424.671927690506 and batch: 1000, loss is 5.140533485412598 and perplexity is 170.80686699116782
At time: 1425.744916677475 and batch: 1050, loss is 5.100231246948242 and perplexity is 164.05984125129592
At time: 1426.8169391155243 and batch: 1100, loss is 5.084762411117554 and perplexity is 161.54155420052035
At time: 1427.897120475769 and batch: 1150, loss is 5.099386882781983 and perplexity is 163.9213734670654
At time: 1428.9697515964508 and batch: 1200, loss is 5.080635347366333 and perplexity is 160.87623575802175
At time: 1430.0425539016724 and batch: 1250, loss is 5.105603475570678 and perplexity is 164.94357992390195
At time: 1431.1157848834991 and batch: 1300, loss is 5.086623935699463 and perplexity is 161.8425478412763
At time: 1432.193992137909 and batch: 1350, loss is 5.058145923614502 and perplexity is 157.29860216766832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155919189453125 and perplexity of 173.45517166878014
Finished 46 epochs...
Completing Train Step...
At time: 1435.3734216690063 and batch: 50, loss is 5.182587404251098 and perplexity is 178.143143530243
At time: 1436.4456520080566 and batch: 100, loss is 5.187644147872925 and perplexity is 179.04624919755707
At time: 1437.5183136463165 and batch: 150, loss is 5.1653459358215335 and perplexity is 175.09802077354132
At time: 1438.5959422588348 and batch: 200, loss is 5.1442052841186525 and perplexity is 171.43518825304514
At time: 1439.6763756275177 and batch: 250, loss is 5.1744670486450195 and perplexity is 176.70241538524076
At time: 1440.7484385967255 and batch: 300, loss is 5.188424682617187 and perplexity is 179.18605557065348
At time: 1441.8210289478302 and batch: 350, loss is 5.177141857147217 and perplexity is 177.17569318984377
At time: 1442.8938467502594 and batch: 400, loss is 5.211006727218628 and perplexity is 183.27847677970018
At time: 1443.9658057689667 and batch: 450, loss is 5.1773731136322025 and perplexity is 177.21667095588018
At time: 1445.0388145446777 and batch: 500, loss is 5.20806324005127 and perplexity is 182.73979212985873
At time: 1446.1114180088043 and batch: 550, loss is 5.180702915191651 and perplexity is 177.80775084642295
At time: 1447.183918952942 and batch: 600, loss is 5.141974430084229 and perplexity is 171.05316764622845
At time: 1448.2568817138672 and batch: 650, loss is 5.147544317245483 and perplexity is 172.00857276794264
At time: 1449.329924583435 and batch: 700, loss is 5.169517469406128 and perplexity is 175.8299736694033
At time: 1450.4028906822205 and batch: 750, loss is 5.151532964706421 and perplexity is 172.69602441469925
At time: 1451.4753668308258 and batch: 800, loss is 5.127613840103149 and perplexity is 168.6142969648111
At time: 1452.5488500595093 and batch: 850, loss is 5.102584476470947 and perplexity is 164.44636632595598
At time: 1453.621723651886 and batch: 900, loss is 5.124546880722046 and perplexity is 168.09795596811415
At time: 1454.6942780017853 and batch: 950, loss is 5.102327041625976 and perplexity is 164.40403754981952
At time: 1455.7675909996033 and batch: 1000, loss is 5.140535860061646 and perplexity is 170.80727259801353
At time: 1456.840618133545 and batch: 1050, loss is 5.100253791809082 and perplexity is 164.06353999928
At time: 1457.9136373996735 and batch: 1100, loss is 5.08478533744812 and perplexity is 161.54525779804698
At time: 1458.9863600730896 and batch: 1150, loss is 5.099405498504638 and perplexity is 163.92442501029447
At time: 1460.0592346191406 and batch: 1200, loss is 5.080717096328735 and perplexity is 160.8893877609441
At time: 1461.1325917243958 and batch: 1250, loss is 5.105621166229248 and perplexity is 164.94649791026816
At time: 1462.2052385807037 and batch: 1300, loss is 5.0865813159942626 and perplexity is 161.8356503065849
At time: 1463.2775175571442 and batch: 1350, loss is 5.058105535507202 and perplexity is 157.29224930313688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155878092447916 and perplexity of 173.44804332716436
Finished 47 epochs...
Completing Train Step...
At time: 1466.475070476532 and batch: 50, loss is 5.182377471923828 and perplexity is 178.10574945078486
At time: 1467.5472695827484 and batch: 100, loss is 5.187375955581665 and perplexity is 178.9982368123068
At time: 1468.6213448047638 and batch: 150, loss is 5.165127429962158 and perplexity is 175.0597650097438
At time: 1469.6931688785553 and batch: 200, loss is 5.143969430923462 and perplexity is 171.3947594839421
At time: 1470.7718789577484 and batch: 250, loss is 5.174270582199097 and perplexity is 176.6677026997547
At time: 1471.8457894325256 and batch: 300, loss is 5.188286170959473 and perplexity is 179.16123793186296
At time: 1472.926425933838 and batch: 350, loss is 5.17699179649353 and perplexity is 177.14910808424528
At time: 1474.0100848674774 and batch: 400, loss is 5.210922470092774 and perplexity is 183.26303491256863
At time: 1475.0873138904572 and batch: 450, loss is 5.177280015945435 and perplexity is 177.200173261718
At time: 1476.159705877304 and batch: 500, loss is 5.207905759811402 and perplexity is 182.71101648941752
At time: 1477.231305360794 and batch: 550, loss is 5.180505561828613 and perplexity is 177.77266335125074
At time: 1478.30353140831 and batch: 600, loss is 5.141788387298584 and perplexity is 171.02134739848174
At time: 1479.375571489334 and batch: 650, loss is 5.1474430370330815 and perplexity is 171.99115258533257
At time: 1480.44961810112 and batch: 700, loss is 5.169437561035156 and perplexity is 175.8159239439922
At time: 1481.5223150253296 and batch: 750, loss is 5.151475868225098 and perplexity is 172.6861643608565
At time: 1482.594722032547 and batch: 800, loss is 5.127511005401612 and perplexity is 168.5969584554233
At time: 1483.66659283638 and batch: 850, loss is 5.102551107406616 and perplexity is 164.44087899613305
At time: 1484.738688468933 and batch: 900, loss is 5.124525899887085 and perplexity is 168.09442916964042
At time: 1485.8111262321472 and batch: 950, loss is 5.102262783050537 and perplexity is 164.39347351998848
At time: 1486.8834722042084 and batch: 1000, loss is 5.140560531616211 and perplexity is 170.811486730944
At time: 1487.9556007385254 and batch: 1050, loss is 5.100096826553345 and perplexity is 164.0377897447674
At time: 1489.054437637329 and batch: 1100, loss is 5.0847977256774906 and perplexity is 161.54725907015035
At time: 1490.1277248859406 and batch: 1150, loss is 5.099386672973633 and perplexity is 163.9213390749962
At time: 1491.2002131938934 and batch: 1200, loss is 5.080738706588745 and perplexity is 160.89286466001465
At time: 1492.2718815803528 and batch: 1250, loss is 5.105667724609375 and perplexity is 164.954177730797
At time: 1493.343554019928 and batch: 1300, loss is 5.0864902591705325 and perplexity is 161.82091473719896
At time: 1494.4148044586182 and batch: 1350, loss is 5.0580661010742185 and perplexity is 157.2860466947718
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15580322265625 and perplexity of 173.43505779441355
Finished 48 epochs...
Completing Train Step...
At time: 1497.554945230484 and batch: 50, loss is 5.182150812149048 and perplexity is 178.0653846164422
At time: 1498.656867980957 and batch: 100, loss is 5.187155780792236 and perplexity is 178.9588302515333
At time: 1499.7312078475952 and batch: 150, loss is 5.1649235820770265 and perplexity is 175.02408308384102
At time: 1500.8032486438751 and batch: 200, loss is 5.143787174224854 and perplexity is 171.3635244874
At time: 1501.8748512268066 and batch: 250, loss is 5.174094219207763 and perplexity is 176.63654780260072
At time: 1502.9499299526215 and batch: 300, loss is 5.188144016265869 and perplexity is 179.13577113113456
At time: 1504.0221548080444 and batch: 350, loss is 5.176866617202759 and perplexity is 177.12693407242702
At time: 1505.0956299304962 and batch: 400, loss is 5.210841827392578 and perplexity is 183.2482566824734
At time: 1506.1671962738037 and batch: 450, loss is 5.177175092697143 and perplexity is 177.1815818192959
At time: 1507.238795042038 and batch: 500, loss is 5.207782278060913 and perplexity is 182.6884564061758
At time: 1508.3106341362 and batch: 550, loss is 5.180410842895508 and perplexity is 177.75582571167712
At time: 1509.3833980560303 and batch: 600, loss is 5.141705837249756 and perplexity is 171.0072301606006
At time: 1510.4553592205048 and batch: 650, loss is 5.147337532043457 and perplexity is 171.97300761777265
At time: 1511.5274031162262 and batch: 700, loss is 5.169368171691895 and perplexity is 175.80372461575138
At time: 1512.599062204361 and batch: 750, loss is 5.151413459777832 and perplexity is 172.6753876217577
At time: 1513.6715471744537 and batch: 800, loss is 5.127468814849854 and perplexity is 168.58984540677412
At time: 1514.7438430786133 and batch: 850, loss is 5.102531137466431 and perplexity is 164.43759515440468
At time: 1515.8606476783752 and batch: 900, loss is 5.124515771865845 and perplexity is 168.09272671431268
At time: 1516.9383783340454 and batch: 950, loss is 5.102232675552369 and perplexity is 164.38852411829302
At time: 1518.0095353126526 and batch: 1000, loss is 5.140563745498657 and perplexity is 170.81203569986485
At time: 1519.082312822342 and batch: 1050, loss is 5.100079927444458 and perplexity is 164.0350176757198
At time: 1520.1563041210175 and batch: 1100, loss is 5.084828338623047 and perplexity is 161.552204583295
At time: 1521.2356042861938 and batch: 1150, loss is 5.099412250518799 and perplexity is 163.92553183407
At time: 1522.3131325244904 and batch: 1200, loss is 5.080757646560669 and perplexity is 160.89591199521226
At time: 1523.3891770839691 and batch: 1250, loss is 5.10569935798645 and perplexity is 164.95939587103453
At time: 1524.4724516868591 and batch: 1300, loss is 5.086448392868042 and perplexity is 161.81414003565013
At time: 1525.5449540615082 and batch: 1350, loss is 5.058033666610718 and perplexity is 157.28094528896224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15576904296875 and perplexity of 173.4291299396433
Finished 49 epochs...
Completing Train Step...
At time: 1528.6931128501892 and batch: 50, loss is 5.181927728652954 and perplexity is 178.02566559840213
At time: 1529.7913677692413 and batch: 100, loss is 5.186974048614502 and perplexity is 178.9263106286074
At time: 1530.8634872436523 and batch: 150, loss is 5.164744424819946 and perplexity is 174.99272905792722
At time: 1531.9348978996277 and batch: 200, loss is 5.143622007369995 and perplexity is 171.3352232503004
At time: 1533.0064096450806 and batch: 250, loss is 5.173940124511719 and perplexity is 176.60933114448198
At time: 1534.0779354572296 and batch: 300, loss is 5.187970590591431 and perplexity is 179.10470708293974
At time: 1535.1492652893066 and batch: 350, loss is 5.176761693954468 and perplexity is 177.1083503140956
At time: 1536.2240283489227 and batch: 400, loss is 5.210773162841797 and perplexity is 183.23567445522826
At time: 1537.298835515976 and batch: 450, loss is 5.177045383453369 and perplexity is 177.15860122073764
At time: 1538.3707902431488 and batch: 500, loss is 5.207671918869019 and perplexity is 182.66829616821263
At time: 1539.4423599243164 and batch: 550, loss is 5.1803285598754885 and perplexity is 177.74120002724246
At time: 1540.5147428512573 and batch: 600, loss is 5.141638889312744 and perplexity is 170.99578196254814
At time: 1541.58562707901 and batch: 650, loss is 5.147238521575928 and perplexity is 171.95598133279023
At time: 1542.6574103832245 and batch: 700, loss is 5.169297428131103 and perplexity is 175.79128807417945
At time: 1543.7558405399323 and batch: 750, loss is 5.151359977722168 and perplexity is 172.66615283401515
At time: 1544.8278231620789 and batch: 800, loss is 5.12740725517273 and perplexity is 168.57946738976148
At time: 1545.9002368450165 and batch: 850, loss is 5.102497091293335 and perplexity is 164.43199677887876
At time: 1546.9713020324707 and batch: 900, loss is 5.1244954586029055 and perplexity is 168.08931223723647
At time: 1548.0426969528198 and batch: 950, loss is 5.102206716537475 and perplexity is 164.38425680953497
At time: 1549.1140460968018 and batch: 1000, loss is 5.140541000366211 and perplexity is 170.80815060167322
At time: 1550.186270236969 and batch: 1050, loss is 5.100077686309814 and perplexity is 164.0346500515708
At time: 1551.2581346035004 and batch: 1100, loss is 5.084826221466065 and perplexity is 161.55186255227915
At time: 1552.330006122589 and batch: 1150, loss is 5.099416217803955 and perplexity is 163.92618217468925
At time: 1553.4014332294464 and batch: 1200, loss is 5.080761308670044 and perplexity is 160.89650121471882
At time: 1554.473567724228 and batch: 1250, loss is 5.105700750350952 and perplexity is 164.9596255548015
At time: 1555.5452136993408 and batch: 1300, loss is 5.086419343948364 and perplexity is 161.80943957796543
At time: 1556.6160898208618 and batch: 1350, loss is 5.057983665466309 and perplexity is 157.27308125831098
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.155751139322916 and perplexity of 173.42602495371904
Finished Training.
Improved accuracyfrom -10000000 to -173.42602495371904
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc20533f860>
SETTINGS FOR THIS RUN
{'dropout': 0.7510165480743217, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.89367160872679, 'wordvec_dim': 200, 'anneal': 4.723259686697794, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7269034385681152 and batch: 50, loss is 7.359927597045899 and perplexity is 1571.722761467029
At time: 2.7952346801757812 and batch: 100, loss is 6.813743286132812 and perplexity is 910.2718454222183
At time: 3.8659777641296387 and batch: 150, loss is 6.654252519607544 and perplexity is 776.0776034333612
At time: 4.941300630569458 and batch: 200, loss is 6.593652696609497 and perplexity is 730.4440936278041
At time: 6.0137505531311035 and batch: 250, loss is 6.590314922332763 and perplexity is 728.0101004411316
At time: 7.083956241607666 and batch: 300, loss is 6.586227226257324 and perplexity is 725.040290386407
At time: 8.180484771728516 and batch: 350, loss is 6.572162895202637 and perplexity is 714.9144571612651
At time: 9.254400968551636 and batch: 400, loss is 6.599623384475708 and perplexity is 734.8183931080046
At time: 10.32234001159668 and batch: 450, loss is 6.5528414440155025 and perplexity is 701.2338624446768
At time: 11.40042757987976 and batch: 500, loss is 6.515792264938354 and perplexity is 675.7291059855748
At time: 12.472673416137695 and batch: 550, loss is 6.474237051010132 and perplexity is 648.2244766903209
At time: 13.544620752334595 and batch: 600, loss is 6.4248494625091555 and perplexity is 616.9879307365709
At time: 14.621961832046509 and batch: 650, loss is 6.456858139038086 and perplexity is 637.0563664615062
At time: 15.695456743240356 and batch: 700, loss is 6.455993852615356 and perplexity is 636.5060051626184
At time: 16.772269248962402 and batch: 750, loss is 6.426422519683838 and perplexity is 617.9592517991964
At time: 17.84903049468994 and batch: 800, loss is 6.38361252784729 and perplexity is 592.0626919535239
At time: 18.926141500473022 and batch: 850, loss is 6.378684024810791 and perplexity is 589.1518880234221
At time: 20.00334334373474 and batch: 900, loss is 6.415787801742554 and perplexity is 611.4222506484238
At time: 21.080574989318848 and batch: 950, loss is 6.400874137878418 and perplexity is 602.3713634236599
At time: 22.157629013061523 and batch: 1000, loss is 6.4070768070220945 and perplexity is 606.1192852359165
At time: 23.235238790512085 and batch: 1050, loss is 6.391891107559204 and perplexity is 596.9844747193364
At time: 24.31791067123413 and batch: 1100, loss is 6.392616386413574 and perplexity is 597.4176119889019
At time: 25.396999835968018 and batch: 1150, loss is 6.389707508087159 and perplexity is 595.6823219429774
At time: 26.481024265289307 and batch: 1200, loss is 6.352694311141968 and perplexity is 574.0372623174836
At time: 27.558557987213135 and batch: 1250, loss is 6.346906366348267 and perplexity is 570.724363021369
At time: 28.634389877319336 and batch: 1300, loss is 6.311028118133545 and perplexity is 550.6107508039827
At time: 29.709884881973267 and batch: 1350, loss is 6.315669260025024 and perplexity is 553.1721527425999
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.678978271484375 and perplexity of 292.6502679935248
Finished 1 epochs...
Completing Train Step...
At time: 32.88334321975708 and batch: 50, loss is 6.096458148956299 and perplexity is 444.2814015533914
At time: 33.951375246047974 and batch: 100, loss is 6.130435638427734 and perplexity is 459.63635232903863
At time: 35.019699573516846 and batch: 150, loss is 6.033001108169556 and perplexity is 416.9645091270044
At time: 36.09745454788208 and batch: 200, loss is 5.944356479644775 and perplexity is 381.59371894265075
At time: 37.171947956085205 and batch: 250, loss is 5.997257051467895 and perplexity is 402.3237253412036
At time: 38.24095869064331 and batch: 300, loss is 5.980276651382447 and perplexity is 395.5497824139544
At time: 39.3100483417511 and batch: 350, loss is 5.943247108459473 and perplexity is 381.1706245940948
At time: 40.379103899002075 and batch: 400, loss is 5.995259113311768 and perplexity is 401.5207098739703
At time: 41.49108052253723 and batch: 450, loss is 5.998311367034912 and perplexity is 402.74812519418396
At time: 42.5596649646759 and batch: 500, loss is 5.972821521759033 and perplexity is 392.6118723707944
At time: 43.628260135650635 and batch: 550, loss is 5.9219207859039305 and perplexity is 373.1277244780512
At time: 44.6991069316864 and batch: 600, loss is 5.923817873001099 and perplexity is 373.8362521265886
At time: 45.7689573764801 and batch: 650, loss is 5.9411836433410645 and perplexity is 380.3849032391801
At time: 46.83828783035278 and batch: 700, loss is 5.9622054862976075 and perplexity is 388.4659364497559
At time: 47.90922665596008 and batch: 750, loss is 5.910663633346558 and perplexity is 368.950922317926
At time: 48.978620290756226 and batch: 800, loss is 5.852569026947021 and perplexity is 348.1275817969914
At time: 50.04806399345398 and batch: 850, loss is 5.878285360336304 and perplexity is 357.1962534681386
At time: 51.117258071899414 and batch: 900, loss is 5.942756929397583 and perplexity is 380.9838285204136
At time: 52.18852090835571 and batch: 950, loss is 5.886146297454834 and perplexity is 360.0152160832435
At time: 53.26024842262268 and batch: 1000, loss is 5.904407873153686 and perplexity is 366.65005815578286
At time: 54.332270860672 and batch: 1050, loss is 5.87115062713623 and perplexity is 354.6568233501055
At time: 55.40296387672424 and batch: 1100, loss is 5.893616714477539 and perplexity is 362.7147506519742
At time: 56.47764492034912 and batch: 1150, loss is 5.902757978439331 and perplexity is 366.0456229271717
At time: 57.550567626953125 and batch: 1200, loss is 5.8429333782196045 and perplexity is 344.7892560028823
At time: 58.62305021286011 and batch: 1250, loss is 5.877192602157593 and perplexity is 356.80613753076744
At time: 59.696974754333496 and batch: 1300, loss is 5.820773553848267 and perplexity is 337.2328205045215
At time: 60.77065348625183 and batch: 1350, loss is 5.812968492507935 and perplexity is 334.61094292235106
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.585802815755208 and perplexity of 266.6142389558598
Finished 2 epochs...
Completing Train Step...
At time: 63.97806000709534 and batch: 50, loss is 5.851231746673584 and perplexity is 347.6623487920068
At time: 65.07831501960754 and batch: 100, loss is 5.919320659637451 and perplexity is 372.1588054826266
At time: 66.15399813652039 and batch: 150, loss is 5.828997154235839 and perplexity is 340.0175229042468
At time: 67.25479364395142 and batch: 200, loss is 5.849967308044434 and perplexity is 347.2230288933507
At time: 68.32853960990906 and batch: 250, loss is 5.8498602390289305 and perplexity is 347.18585405565915
At time: 69.40100049972534 and batch: 300, loss is 5.874912872314453 and perplexity is 355.9936424173911
At time: 70.47130012512207 and batch: 350, loss is 5.836439504623413 and perplexity is 342.5574923953138
At time: 71.5417230129242 and batch: 400, loss is 5.887119703292846 and perplexity is 360.36582761232256
At time: 72.61311912536621 and batch: 450, loss is 5.854960870742798 and perplexity is 348.9612451925182
At time: 73.68378758430481 and batch: 500, loss is 5.932087726593018 and perplexity is 376.94064193107647
At time: 74.75441884994507 and batch: 550, loss is 5.884172773361206 and perplexity is 359.3054180124042
At time: 75.82586288452148 and batch: 600, loss is 5.8294096851348876 and perplexity is 340.1578195750288
At time: 76.89610314369202 and batch: 650, loss is 5.885846242904663 and perplexity is 359.9072080844831
At time: 77.96655869483948 and batch: 700, loss is 5.910828113555908 and perplexity is 369.01161243389345
At time: 79.03676867485046 and batch: 750, loss is 5.857818269729615 and perplexity is 349.95979264580455
At time: 80.11503529548645 and batch: 800, loss is 5.833322286605835 and perplexity is 341.4913286037834
At time: 81.185866355896 and batch: 850, loss is 5.836517972946167 and perplexity is 342.58437336182726
At time: 82.25638270378113 and batch: 900, loss is 5.85647871017456 and perplexity is 349.4913145089171
At time: 83.32827186584473 and batch: 950, loss is 5.865775480270385 and perplexity is 352.75560507887064
At time: 84.39944958686829 and batch: 1000, loss is 5.823173294067383 and perplexity is 338.04306346456895
At time: 85.47033476829529 and batch: 1050, loss is 5.8054052925109865 and perplexity is 332.0897595648908
At time: 86.5502860546112 and batch: 1100, loss is 5.8195634460449215 and perplexity is 336.8249792525945
At time: 87.62094736099243 and batch: 1150, loss is 5.760506801605224 and perplexity is 317.5092023223678
At time: 88.69202089309692 and batch: 1200, loss is 5.776537714004516 and perplexity is 322.64018178814035
At time: 89.76289463043213 and batch: 1250, loss is 5.788602485656738 and perplexity is 326.5563381710604
At time: 90.83456087112427 and batch: 1300, loss is 5.817514715194702 and perplexity is 336.1356219214105
At time: 91.91389918327332 and batch: 1350, loss is 5.79231819152832 and perplexity is 327.77198256406325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.619178466796875 and perplexity of 275.6628240217656
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 95.11763715744019 and batch: 50, loss is 5.762231092453003 and perplexity is 318.0571528112615
At time: 96.19394254684448 and batch: 100, loss is 5.740090036392212 and perplexity is 311.092419359571
At time: 97.26594305038452 and batch: 150, loss is 5.678812866210937 and perplexity is 292.6018660990003
At time: 98.33789420127869 and batch: 200, loss is 5.674294395446777 and perplexity is 291.2827355921514
At time: 99.410715341568 and batch: 250, loss is 5.676971273422241 and perplexity is 292.06350848233734
At time: 100.48298192024231 and batch: 300, loss is 5.682200469970703 and perplexity is 293.59476610708043
At time: 101.56138300895691 and batch: 350, loss is 5.6595832633972165 and perplexity is 287.02900213726394
At time: 102.63196444511414 and batch: 400, loss is 5.690491266250611 and perplexity is 296.0390189017807
At time: 103.70275807380676 and batch: 450, loss is 5.667275314331055 and perplexity is 289.2453570706786
At time: 104.77275276184082 and batch: 500, loss is 5.670679540634155 and perplexity is 290.23169162375046
At time: 105.84310412406921 and batch: 550, loss is 5.633058366775512 and perplexity is 279.5156731728362
At time: 106.92135763168335 and batch: 600, loss is 5.5955008602142335 and perplexity is 269.2124541379107
At time: 107.99148035049438 and batch: 650, loss is 5.612392930984497 and perplexity is 273.79863596743246
At time: 109.06142163276672 and batch: 700, loss is 5.627303047180176 and perplexity is 277.91159157071735
At time: 110.13208198547363 and batch: 750, loss is 5.596995306015015 and perplexity is 269.61507833460115
At time: 111.20244216918945 and batch: 800, loss is 5.551293106079101 and perplexity is 257.57040651228044
At time: 112.27356791496277 and batch: 850, loss is 5.543359575271606 and perplexity is 255.5350482215656
At time: 113.34366989135742 and batch: 900, loss is 5.560947723388672 and perplexity is 260.06919322250366
At time: 114.41382503509521 and batch: 950, loss is 5.545145750045776 and perplexity is 255.99188635353016
At time: 115.48358869552612 and batch: 1000, loss is 5.549429731369019 and perplexity is 257.0909032166199
At time: 116.55401396751404 and batch: 1050, loss is 5.514728775024414 and perplexity is 248.32261681728846
At time: 117.62441349029541 and batch: 1100, loss is 5.506456050872803 and perplexity is 246.27678627132983
At time: 118.69468331336975 and batch: 1150, loss is 5.503287086486816 and perplexity is 245.49757919836063
At time: 119.76511669158936 and batch: 1200, loss is 5.45803391456604 and perplexity is 234.635656829592
At time: 120.84300112724304 and batch: 1250, loss is 5.47488245010376 and perplexity is 238.62241524180297
At time: 121.91425609588623 and batch: 1300, loss is 5.4269009208679195 and perplexity is 227.44328733352256
At time: 122.98507809638977 and batch: 1350, loss is 5.411485719680786 and perplexity is 223.96408847193075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.312015380859375 and perplexity of 202.75845239057594
Finished 4 epochs...
Completing Train Step...
At time: 126.17371225357056 and batch: 50, loss is 5.5601043701171875 and perplexity is 259.84995547801594
At time: 127.247309923172 and batch: 100, loss is 5.562751312255859 and perplexity is 260.53867437231975
At time: 128.31809210777283 and batch: 150, loss is 5.53521162033081 and perplexity is 253.46141955154027
At time: 129.38937830924988 and batch: 200, loss is 5.537720584869385 and perplexity is 254.09814369022467
At time: 130.45945358276367 and batch: 250, loss is 5.543543395996093 and perplexity is 255.58202517679828
At time: 131.52894973754883 and batch: 300, loss is 5.55269757270813 and perplexity is 257.93240970404844
At time: 132.59899401664734 and batch: 350, loss is 5.541570625305176 and perplexity is 255.07831746167452
At time: 133.66843581199646 and batch: 400, loss is 5.572313709259033 and perplexity is 263.0419984253774
At time: 134.73867321014404 and batch: 450, loss is 5.5484102344512936 and perplexity is 256.82893339461884
At time: 135.80885529518127 and batch: 500, loss is 5.5674710369110105 and perplexity is 261.7712516018923
At time: 136.8788652420044 and batch: 550, loss is 5.537966480255127 and perplexity is 254.1606329338772
At time: 137.94944620132446 and batch: 600, loss is 5.4949197101593015 and perplexity is 243.4519786553633
At time: 139.02060627937317 and batch: 650, loss is 5.5178460693359375 and perplexity is 249.09791929327966
At time: 140.09194159507751 and batch: 700, loss is 5.53386061668396 and perplexity is 253.1192234555254
At time: 141.16192078590393 and batch: 750, loss is 5.510984582901001 and perplexity is 247.39458767520563
At time: 142.23778128623962 and batch: 800, loss is 5.471204223632813 and perplexity is 237.7463201832665
At time: 143.30798363685608 and batch: 850, loss is 5.465041027069092 and perplexity is 236.28554901354804
At time: 144.37829899787903 and batch: 900, loss is 5.479313344955444 and perplexity is 239.68207195305658
At time: 145.4525113105774 and batch: 950, loss is 5.468825054168701 and perplexity is 237.18135374003347
At time: 146.5274622440338 and batch: 1000, loss is 5.479709949493408 and perplexity is 239.77714980336893
At time: 147.5995192527771 and batch: 1050, loss is 5.453132371902466 and perplexity is 233.48839412272423
At time: 148.6977858543396 and batch: 1100, loss is 5.441913766860962 and perplexity is 230.88361834171036
At time: 149.7698004245758 and batch: 1150, loss is 5.447848567962646 and perplexity is 232.25794082565392
At time: 150.83991241455078 and batch: 1200, loss is 5.411167736053467 and perplexity is 223.89288288039538
At time: 151.9094111919403 and batch: 1250, loss is 5.4219455909729 and perplexity is 226.31901867398793
At time: 152.97945141792297 and batch: 1300, loss is 5.388647241592407 and perplexity is 218.9070568069646
At time: 154.04917669296265 and batch: 1350, loss is 5.383882856369018 and perplexity is 217.86657984492945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.308307291666667 and perplexity of 202.00799819996374
Finished 5 epochs...
Completing Train Step...
At time: 157.20818948745728 and batch: 50, loss is 5.513582315444946 and perplexity is 248.0380881059377
At time: 158.30456614494324 and batch: 100, loss is 5.513958139419556 and perplexity is 248.13132428516252
At time: 159.3738260269165 and batch: 150, loss is 5.478709993362426 and perplexity is 239.53750301046247
At time: 160.4423635005951 and batch: 200, loss is 5.476342878341675 and perplexity is 238.971160752132
At time: 161.5118911266327 and batch: 250, loss is 5.478625421524048 and perplexity is 239.51724574008162
At time: 162.5804407596588 and batch: 300, loss is 5.487162561416626 and perplexity is 241.57079120377648
At time: 163.64963030815125 and batch: 350, loss is 5.47228590965271 and perplexity is 238.0036261911582
At time: 164.72261762619019 and batch: 400, loss is 5.508046131134034 and perplexity is 246.66869763066327
At time: 165.79136681556702 and batch: 450, loss is 5.4848885917663575 and perplexity is 241.0220906568246
At time: 166.86029720306396 and batch: 500, loss is 5.504054174423218 and perplexity is 245.68596967657336
At time: 167.92934727668762 and batch: 550, loss is 5.47485164642334 and perplexity is 238.61506490639215
At time: 168.99851727485657 and batch: 600, loss is 5.433128118515015 and perplexity is 228.86404070211003
At time: 170.06760835647583 and batch: 650, loss is 5.4601829051971436 and perplexity is 235.140428838741
At time: 171.13753461837769 and batch: 700, loss is 5.475390195846558 and perplexity is 238.74360552159885
At time: 172.2101891040802 and batch: 750, loss is 5.453189630508422 and perplexity is 233.5017637254374
At time: 173.281644821167 and batch: 800, loss is 5.4126170635223385 and perplexity is 224.21761224839275
At time: 174.35242009162903 and batch: 850, loss is 5.4101173877716064 and perplexity is 223.65784083515416
At time: 175.469801902771 and batch: 900, loss is 5.422152338027954 and perplexity is 226.36581430186388
At time: 176.5386278629303 and batch: 950, loss is 5.4161403846740725 and perplexity is 225.00899623551646
At time: 177.61101531982422 and batch: 1000, loss is 5.42295132637024 and perplexity is 226.54675022180294
At time: 178.68259835243225 and batch: 1050, loss is 5.397021427154541 and perplexity is 220.74792223803485
At time: 179.75363636016846 and batch: 1100, loss is 5.391090211868286 and perplexity is 219.442494002205
At time: 180.82510447502136 and batch: 1150, loss is 5.39594409942627 and perplexity is 220.51023243834487
At time: 181.89610505104065 and batch: 1200, loss is 5.363736705780029 and perplexity is 213.52132397410134
At time: 182.96677494049072 and batch: 1250, loss is 5.382294082641602 and perplexity is 217.52071397084967
At time: 184.03739500045776 and batch: 1300, loss is 5.349744853973388 and perplexity is 210.5545688509662
At time: 185.1086401939392 and batch: 1350, loss is 5.343569478988647 and perplexity is 209.25832195826834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3033251953125 and perplexity of 201.00407777930153
Finished 6 epochs...
Completing Train Step...
At time: 188.2789499759674 and batch: 50, loss is 5.4586795043945315 and perplexity is 234.78718413002164
At time: 189.3756809234619 and batch: 100, loss is 5.461068105697632 and perplexity is 235.34866741688327
At time: 190.44529390335083 and batch: 150, loss is 5.434715957641601 and perplexity is 229.22772864316505
At time: 191.51525235176086 and batch: 200, loss is 5.424886302947998 and perplexity is 226.98553726166537
At time: 192.59103894233704 and batch: 250, loss is 5.432376909255981 and perplexity is 228.6921804752536
At time: 193.66576099395752 and batch: 300, loss is 5.4383393669128415 and perplexity is 230.05982111576103
At time: 194.74049472808838 and batch: 350, loss is 5.416701040267944 and perplexity is 225.1351841586044
At time: 195.81145119667053 and batch: 400, loss is 5.449134979248047 and perplexity is 232.55691232077913
At time: 196.88261938095093 and batch: 450, loss is 5.434820909500122 and perplexity is 229.25178778181413
At time: 197.95277285575867 and batch: 500, loss is 5.457685041427612 and perplexity is 234.55381302898863
At time: 199.0230700969696 and batch: 550, loss is 5.428629007339477 and perplexity is 227.8366688021116
At time: 200.0928099155426 and batch: 600, loss is 5.382904376983642 and perplexity is 217.65350614889854
At time: 201.16587114334106 and batch: 650, loss is 5.40178448677063 and perplexity is 221.80186575714507
At time: 202.2419102191925 and batch: 700, loss is 5.41683331489563 and perplexity is 225.16496580090234
At time: 203.35773158073425 and batch: 750, loss is 5.397907695770264 and perplexity is 220.94365091478053
At time: 204.42768049240112 and batch: 800, loss is 5.366908445358276 and perplexity is 214.19963314953338
At time: 205.50560474395752 and batch: 850, loss is 5.364026174545288 and perplexity is 213.58314067467896
At time: 206.5761992931366 and batch: 900, loss is 5.378440046310425 and perplexity is 216.6839946454527
At time: 207.6457097530365 and batch: 950, loss is 5.369756126403809 and perplexity is 214.8104747129937
At time: 208.71567630767822 and batch: 1000, loss is 5.38306489944458 and perplexity is 217.6884472296764
At time: 209.7865617275238 and batch: 1050, loss is 5.35671516418457 and perplexity is 212.0273263376636
At time: 210.8636302947998 and batch: 1100, loss is 5.346074275970459 and perplexity is 209.7831285641428
At time: 211.93426275253296 and batch: 1150, loss is 5.353732967376709 and perplexity is 211.39596101762157
At time: 213.01126670837402 and batch: 1200, loss is 5.317479248046875 and perplexity is 203.86932972502777
At time: 214.0833821296692 and batch: 1250, loss is 5.339503793716431 and perplexity is 208.40927063787169
At time: 215.15286421775818 and batch: 1300, loss is 5.308763303756714 and perplexity is 202.10013729610336
At time: 216.22424173355103 and batch: 1350, loss is 5.2995662593841555 and perplexity is 200.24993460550698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.291413981119792 and perplexity of 198.6240776398625
Finished 7 epochs...
Completing Train Step...
At time: 219.41175889968872 and batch: 50, loss is 5.408968296051025 and perplexity is 223.4009850656894
At time: 220.49376940727234 and batch: 100, loss is 5.414122438430786 and perplexity is 224.55539799921075
At time: 221.5632302761078 and batch: 150, loss is 5.389449119567871 and perplexity is 219.0826639528333
At time: 222.6329002380371 and batch: 200, loss is 5.381881046295166 and perplexity is 217.4308885617334
At time: 223.70059180259705 and batch: 250, loss is 5.384512233734131 and perplexity is 218.00374329815696
At time: 224.77111268043518 and batch: 300, loss is 5.390297145843506 and perplexity is 219.26853060716581
At time: 225.84139347076416 and batch: 350, loss is 5.382615547180176 and perplexity is 217.59065040723652
At time: 226.91138458251953 and batch: 400, loss is 5.411612920761108 and perplexity is 223.9925787578969
At time: 227.98292231559753 and batch: 450, loss is 5.392127141952515 and perplexity is 219.67015854170003
At time: 229.05138230323792 and batch: 500, loss is 5.420413084030152 and perplexity is 225.9724488347653
At time: 230.14690351486206 and batch: 550, loss is 5.391334571838379 and perplexity is 219.49612351566284
At time: 231.21655416488647 and batch: 600, loss is 5.352806844711304 and perplexity is 211.200273056263
At time: 232.285542011261 and batch: 650, loss is 5.38355052947998 and perplexity is 217.7941889516107
At time: 233.35525012016296 and batch: 700, loss is 5.3928906440734865 and perplexity is 219.83794121672435
At time: 234.43030834197998 and batch: 750, loss is 5.367053670883179 and perplexity is 214.23074266258448
At time: 235.50174474716187 and batch: 800, loss is 5.329736080169678 and perplexity is 206.3834982701463
At time: 236.5723099708557 and batch: 850, loss is 5.326040420532227 and perplexity is 205.62218275376347
At time: 237.6494119167328 and batch: 900, loss is 5.338935298919678 and perplexity is 208.29082472305208
At time: 238.71782231330872 and batch: 950, loss is 5.333179721832275 and perplexity is 207.0954342058358
At time: 239.78701615333557 and batch: 1000, loss is 5.351699848175048 and perplexity is 210.96660444456768
At time: 240.86349821090698 and batch: 1050, loss is 5.321375131607056 and perplexity is 204.66513006130367
At time: 241.93386554718018 and batch: 1100, loss is 5.311228704452515 and perplexity is 202.59900982286467
At time: 243.00365662574768 and batch: 1150, loss is 5.329203910827637 and perplexity is 206.2736965188181
At time: 244.07382488250732 and batch: 1200, loss is 5.287908773422242 and perplexity is 197.92907776504765
At time: 245.14425015449524 and batch: 1250, loss is 5.306560249328613 and perplexity is 201.65538977509107
At time: 246.22067666053772 and batch: 1300, loss is 5.278021469116211 and perplexity is 195.98173558864042
At time: 247.29356455802917 and batch: 1350, loss is 5.269808120727539 and perplexity is 194.3786616307051
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.28719970703125 and perplexity of 197.78878265335678
Finished 8 epochs...
Completing Train Step...
At time: 250.49364185333252 and batch: 50, loss is 5.377018480300904 and perplexity is 216.37618288306354
At time: 251.5636854171753 and batch: 100, loss is 5.382396640777588 and perplexity is 217.5430236338121
At time: 252.63356614112854 and batch: 150, loss is 5.360732297897339 and perplexity is 212.88078153243112
At time: 253.7034285068512 and batch: 200, loss is 5.353526849746704 and perplexity is 211.35239307335883
At time: 254.77378344535828 and batch: 250, loss is 5.354798126220703 and perplexity is 211.62125125872993
At time: 255.84461331367493 and batch: 300, loss is 5.351780166625977 and perplexity is 210.98354963593093
At time: 256.94139313697815 and batch: 350, loss is 5.350271730422974 and perplexity is 210.66553432462683
At time: 258.0121536254883 and batch: 400, loss is 5.384843950271606 and perplexity is 218.07607074048173
At time: 259.082643032074 and batch: 450, loss is 5.363755893707276 and perplexity is 213.52542104503829
At time: 260.15340423583984 and batch: 500, loss is 5.389981603622436 and perplexity is 219.19935304280253
At time: 261.22415828704834 and batch: 550, loss is 5.362260570526123 and perplexity is 213.206370134745
At time: 262.29530906677246 and batch: 600, loss is 5.321300592422485 and perplexity is 204.64987505795372
At time: 263.36636686325073 and batch: 650, loss is 5.347606678009033 and perplexity is 210.10484709612362
At time: 264.4378967285156 and batch: 700, loss is 5.360229454040527 and perplexity is 212.77376264835343
At time: 265.5088188648224 and batch: 750, loss is 5.335964708328247 and perplexity is 207.67299607116968
At time: 266.58065009117126 and batch: 800, loss is 5.301353120803833 and perplexity is 200.60807336482154
At time: 267.6514229774475 and batch: 850, loss is 5.299086380004883 and perplexity is 200.15386184470114
At time: 268.7222406864166 and batch: 900, loss is 5.310870962142944 and perplexity is 202.52654454789422
At time: 269.7904510498047 and batch: 950, loss is 5.30444369316101 and perplexity is 201.22902618654277
At time: 270.86075949668884 and batch: 1000, loss is 5.318748197555542 and perplexity is 204.12819381881093
At time: 271.93126463890076 and batch: 1050, loss is 5.292151908874512 and perplexity is 198.7707019519298
At time: 273.0024027824402 and batch: 1100, loss is 5.280130796432495 and perplexity is 196.39556151073617
At time: 274.0724050998688 and batch: 1150, loss is 5.29492431640625 and perplexity is 199.32253994955713
At time: 275.1429741382599 and batch: 1200, loss is 5.257864837646484 and perplexity is 192.07095050486993
At time: 276.2133033275604 and batch: 1250, loss is 5.28247239112854 and perplexity is 196.8559791612857
At time: 277.2847192287445 and batch: 1300, loss is 5.246906652450561 and perplexity is 189.97769156486487
At time: 278.3554549217224 and batch: 1350, loss is 5.241448211669922 and perplexity is 188.94353459579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.288534749348958 and perplexity of 198.05301538986353
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 281.49667096138 and batch: 50, loss is 5.331093654632569 and perplexity is 206.66386950631463
At time: 282.59382700920105 and batch: 100, loss is 5.329473457336426 and perplexity is 206.32930436768376
At time: 283.6642768383026 and batch: 150, loss is 5.309720811843872 and perplexity is 202.293742486456
At time: 284.7609384059906 and batch: 200, loss is 5.288735675811767 and perplexity is 198.09281347980533
At time: 285.83162927627563 and batch: 250, loss is 5.284217653274536 and perplexity is 197.1998444301647
At time: 286.9018955230713 and batch: 300, loss is 5.287907581329346 and perplexity is 197.92884181534086
At time: 287.97210240364075 and batch: 350, loss is 5.28151237487793 and perplexity is 196.66708490754536
At time: 289.04289293289185 and batch: 400, loss is 5.307352027893066 and perplexity is 201.81511941703005
At time: 290.1137571334839 and batch: 450, loss is 5.277513589859009 and perplexity is 195.88222580196174
At time: 291.1853177547455 and batch: 500, loss is 5.308317384719849 and perplexity is 202.01003708772197
At time: 292.2563853263855 and batch: 550, loss is 5.276598310470581 and perplexity is 195.70302086193033
At time: 293.3271265029907 and batch: 600, loss is 5.231073617935181 and perplexity is 186.99345531660018
At time: 294.39934730529785 and batch: 650, loss is 5.240986490249634 and perplexity is 188.8563154556644
At time: 295.4765422344208 and batch: 700, loss is 5.249140634536743 and perplexity is 190.4025727363542
At time: 296.5496475696564 and batch: 750, loss is 5.231828365325928 and perplexity is 187.13464141230372
At time: 297.6246135234833 and batch: 800, loss is 5.199760179519654 and perplexity is 181.22877429144796
At time: 298.69960618019104 and batch: 850, loss is 5.178022956848144 and perplexity is 177.33187143432323
At time: 299.7705411911011 and batch: 900, loss is 5.192965860366821 and perplexity is 180.00162171309537
At time: 300.8410584926605 and batch: 950, loss is 5.173731060028076 and perplexity is 176.5724122652074
At time: 301.91157126426697 and batch: 1000, loss is 5.189608955383301 and perplexity is 179.39838644035018
At time: 302.98215532302856 and batch: 1050, loss is 5.155578956604004 and perplexity is 173.3961665598359
At time: 304.05298113822937 and batch: 1100, loss is 5.139053888320923 and perplexity is 170.5543285211941
At time: 305.12358808517456 and batch: 1150, loss is 5.148151626586914 and perplexity is 172.11306690791284
At time: 306.19895911216736 and batch: 1200, loss is 5.097595834732056 and perplexity is 163.62804517172444
At time: 307.2702512741089 and batch: 1250, loss is 5.11810998916626 and perplexity is 167.0194026442135
At time: 308.342036485672 and batch: 1300, loss is 5.080651435852051 and perplexity is 160.87882403386376
At time: 309.4166374206543 and batch: 1350, loss is 5.089327344894409 and perplexity is 162.28066641330238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1940576171875 and perplexity of 180.1982470253164
Finished 10 epochs...
Completing Train Step...
At time: 312.6172442436218 and batch: 50, loss is 5.264502601623535 and perplexity is 193.35011283333674
At time: 313.715252161026 and batch: 100, loss is 5.267360677719116 and perplexity is 193.90351262154826
At time: 314.7862813472748 and batch: 150, loss is 5.252746782302856 and perplexity is 191.09043206445202
At time: 315.8569846153259 and batch: 200, loss is 5.2362886333465575 and perplexity is 187.97117626694288
At time: 316.92725253105164 and batch: 250, loss is 5.234776229858398 and perplexity is 187.6871028752259
At time: 317.9981429576874 and batch: 300, loss is 5.2429733562469485 and perplexity is 189.2319206622653
At time: 319.0687463283539 and batch: 350, loss is 5.240635614395142 and perplexity is 188.79006195865858
At time: 320.1468732357025 and batch: 400, loss is 5.266984939575195 and perplexity is 193.83066936146872
At time: 321.217081785202 and batch: 450, loss is 5.239269962310791 and perplexity is 188.53241638419047
At time: 322.2872338294983 and batch: 500, loss is 5.273861379623413 and perplexity is 195.1681275441578
At time: 323.35790371894836 and batch: 550, loss is 5.246816987991333 and perplexity is 189.96065808154577
At time: 324.42843532562256 and batch: 600, loss is 5.202395372390747 and perplexity is 181.70697686677696
At time: 325.50638818740845 and batch: 650, loss is 5.21334358215332 and perplexity is 183.7072728145167
At time: 326.57836294174194 and batch: 700, loss is 5.226048278808594 and perplexity is 186.05610700839748
At time: 327.6569848060608 and batch: 750, loss is 5.208799753189087 and perplexity is 182.87443196348127
At time: 328.72798800468445 and batch: 800, loss is 5.176669864654541 and perplexity is 177.09208732499593
At time: 329.7994155883789 and batch: 850, loss is 5.157877206802368 and perplexity is 173.7951326203314
At time: 330.8709409236908 and batch: 900, loss is 5.178537712097168 and perplexity is 177.4231774440711
At time: 331.94230604171753 and batch: 950, loss is 5.162553176879883 and perplexity is 174.60969641386225
At time: 333.01450657844543 and batch: 1000, loss is 5.182249956130981 and perplexity is 178.08303960289598
At time: 334.0930678844452 and batch: 1050, loss is 5.14962100982666 and perplexity is 172.36615285835927
At time: 335.16360211372375 and batch: 1100, loss is 5.1351198482513425 and perplexity is 169.8846790363661
At time: 336.2347354888916 and batch: 1150, loss is 5.146059255599976 and perplexity is 171.75331901451764
At time: 337.3052785396576 and batch: 1200, loss is 5.098338146209716 and perplexity is 163.7495532405601
At time: 338.40137934684753 and batch: 1250, loss is 5.1264723205566405 and perplexity is 168.42193026506777
At time: 339.47168588638306 and batch: 1300, loss is 5.091178607940674 and perplexity is 162.5813688679477
At time: 340.5428376197815 and batch: 1350, loss is 5.094851398468018 and perplexity is 163.17959408492928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.19104736328125 and perplexity of 179.65662017448238
Finished 11 epochs...
Completing Train Step...
At time: 343.71436381340027 and batch: 50, loss is 5.245920963287354 and perplexity is 189.79052487228253
At time: 344.7860507965088 and batch: 100, loss is 5.2471091842651365 and perplexity is 190.01617198808978
At time: 345.8569483757019 and batch: 150, loss is 5.233338785171509 and perplexity is 187.4175068575029
At time: 346.9279029369354 and batch: 200, loss is 5.216551570892334 and perplexity is 184.2975499719965
At time: 348.0074055194855 and batch: 250, loss is 5.216734628677369 and perplexity is 184.33129016138957
At time: 349.07858967781067 and batch: 300, loss is 5.225662765502929 and perplexity is 185.98439372764577
At time: 350.1493082046509 and batch: 350, loss is 5.2250964546203615 and perplexity is 185.879098559204
At time: 351.2205767631531 and batch: 400, loss is 5.250728797912598 and perplexity is 190.70520337888456
At time: 352.29202222824097 and batch: 450, loss is 5.224448919296265 and perplexity is 185.75877423820407
At time: 353.36287689208984 and batch: 500, loss is 5.260836420059204 and perplexity is 192.64255402625085
At time: 354.433256149292 and batch: 550, loss is 5.2353567695617675 and perplexity is 187.79609432412596
At time: 355.509548664093 and batch: 600, loss is 5.190699014663696 and perplexity is 179.59404793831905
At time: 356.5813572406769 and batch: 650, loss is 5.2011446762084965 and perplexity is 181.47985870203786
At time: 357.6523892879486 and batch: 700, loss is 5.215992040634156 and perplexity is 184.1944587602947
At time: 358.72374057769775 and batch: 750, loss is 5.1990875720977785 and perplexity is 181.10691945762895
At time: 359.7954547405243 and batch: 800, loss is 5.167640771865845 and perplexity is 175.500303432729
At time: 360.8673646450043 and batch: 850, loss is 5.149364576339722 and perplexity is 172.32195807150552
At time: 361.94569396972656 and batch: 900, loss is 5.171653785705566 and perplexity is 176.20600362453223
At time: 363.01735043525696 and batch: 950, loss is 5.157584199905395 and perplexity is 173.74421690750512
At time: 364.0876729488373 and batch: 1000, loss is 5.178964776992798 and perplexity is 177.4989648367441
At time: 365.1592140197754 and batch: 1050, loss is 5.145454053878784 and perplexity is 171.64940505785404
At time: 366.28562092781067 and batch: 1100, loss is 5.1321367835998535 and perplexity is 169.378657178705
At time: 367.35644149780273 and batch: 1150, loss is 5.143807144165039 and perplexity is 171.3669466409039
At time: 368.42707562446594 and batch: 1200, loss is 5.09814902305603 and perplexity is 163.71858733691352
At time: 369.4981360435486 and batch: 1250, loss is 5.127045497894287 and perplexity is 168.5184935699638
At time: 370.5689787864685 and batch: 1300, loss is 5.0921650218963626 and perplexity is 162.74182052199927
At time: 371.6400980949402 and batch: 1350, loss is 5.093169450759888 and perplexity is 162.90536522459436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.189495442708333 and perplexity of 179.3780236053622
Finished 12 epochs...
Completing Train Step...
At time: 374.80856347084045 and batch: 50, loss is 5.2326356887817385 and perplexity is 187.28578059860666
At time: 375.879248380661 and batch: 100, loss is 5.232964210510254 and perplexity is 187.34731815463388
At time: 376.9503879547119 and batch: 150, loss is 5.219888706207275 and perplexity is 184.91360318921713
At time: 378.0213441848755 and batch: 200, loss is 5.203100528717041 and perplexity is 181.8351538781503
At time: 379.0926139354706 and batch: 250, loss is 5.204589338302612 and perplexity is 182.10607342200248
At time: 380.16390919685364 and batch: 300, loss is 5.213801279067993 and perplexity is 183.7913743115165
At time: 381.234751701355 and batch: 350, loss is 5.213799819946289 and perplexity is 183.79110613772897
At time: 382.30571126937866 and batch: 400, loss is 5.23974531173706 and perplexity is 188.62205646364407
At time: 383.37660241127014 and batch: 450, loss is 5.2131844425201415 and perplexity is 183.67804003261753
At time: 384.44750928878784 and batch: 500, loss is 5.2509746074676515 and perplexity is 190.75208630197272
At time: 385.51804661750793 and batch: 550, loss is 5.227222146987915 and perplexity is 186.27464059169859
At time: 386.58952260017395 and batch: 600, loss is 5.18186050415039 and perplexity is 178.0136983138406
At time: 387.6600339412689 and batch: 650, loss is 5.192162656784058 and perplexity is 179.8571018128526
At time: 388.7305805683136 and batch: 700, loss is 5.208261909484864 and perplexity is 182.7761005474232
At time: 389.80151867866516 and batch: 750, loss is 5.191814908981323 and perplexity is 179.7945677745583
At time: 390.8722298145294 and batch: 800, loss is 5.160425910949707 and perplexity is 174.2386499527737
At time: 391.9436619281769 and batch: 850, loss is 5.142961921691895 and perplexity is 171.2221646415681
At time: 393.0411114692688 and batch: 900, loss is 5.166115798950195 and perplexity is 175.23287418631116
At time: 394.11211013793945 and batch: 950, loss is 5.152755680084229 and perplexity is 172.90731164518687
At time: 395.1830384731293 and batch: 1000, loss is 5.174707775115967 and perplexity is 176.74495745439995
At time: 396.255078792572 and batch: 1050, loss is 5.141120548248291 and perplexity is 170.90717079429638
At time: 397.32703924179077 and batch: 1100, loss is 5.128332023620605 and perplexity is 168.73543646868936
At time: 398.39852929115295 and batch: 1150, loss is 5.13985239982605 and perplexity is 170.69057250372188
At time: 399.4699618816376 and batch: 1200, loss is 5.095920705795288 and perplexity is 163.3541765450622
At time: 400.540860414505 and batch: 1250, loss is 5.125045852661133 and perplexity is 168.18185306056688
At time: 401.61283445358276 and batch: 1300, loss is 5.0900553035736085 and perplexity is 162.39884304151659
At time: 402.68362951278687 and batch: 1350, loss is 5.089065113067627 and perplexity is 162.23811683686782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.18859130859375 and perplexity of 179.2159151097678
Finished 13 epochs...
Completing Train Step...
At time: 405.82758474349976 and batch: 50, loss is 5.221539258956909 and perplexity is 185.21906486636337
At time: 406.9415762424469 and batch: 100, loss is 5.221454353332519 and perplexity is 185.20333939361194
At time: 408.0121531486511 and batch: 150, loss is 5.209292488098145 and perplexity is 182.9645627835609
At time: 409.0831980705261 and batch: 200, loss is 5.19247239112854 and perplexity is 179.91281836260205
At time: 410.15399837493896 and batch: 250, loss is 5.194501686096191 and perplexity is 180.27828523414573
At time: 411.22499990463257 and batch: 300, loss is 5.203822278976441 and perplexity is 181.96644082012287
At time: 412.29611015319824 and batch: 350, loss is 5.204679098129272 and perplexity is 182.1224199652071
At time: 413.36769461631775 and batch: 400, loss is 5.2302195167541505 and perplexity is 186.8338121709738
At time: 414.4390275478363 and batch: 450, loss is 5.203738594055176 and perplexity is 181.95121361000287
At time: 415.510281085968 and batch: 500, loss is 5.243080768585205 and perplexity is 189.2522475969987
At time: 416.5812957286835 and batch: 550, loss is 5.2198713016510006 and perplexity is 184.91038487801123
At time: 417.6531186103821 and batch: 600, loss is 5.174209775924683 and perplexity is 176.6569605215435
At time: 418.7246038913727 and batch: 650, loss is 5.184180402755738 and perplexity is 178.4271514435298
At time: 419.82148694992065 and batch: 700, loss is 5.201142854690552 and perplexity is 181.47952813351975
At time: 420.892680644989 and batch: 750, loss is 5.1855306053161625 and perplexity is 178.6682269540196
At time: 421.9692873954773 and batch: 800, loss is 5.154563331604004 and perplexity is 173.22015047647085
At time: 423.03998947143555 and batch: 850, loss is 5.137247552871704 and perplexity is 170.2465282705127
At time: 424.1108076572418 and batch: 900, loss is 5.160846729278564 and perplexity is 174.31198820022624
At time: 425.18214654922485 and batch: 950, loss is 5.147593297958374 and perplexity is 172.01699807679728
At time: 426.2547838687897 and batch: 1000, loss is 5.170275144577026 and perplexity is 175.963246157004
At time: 427.326354265213 and batch: 1050, loss is 5.136989250183105 and perplexity is 170.2025588134947
At time: 428.3978695869446 and batch: 1100, loss is 5.12379077911377 and perplexity is 167.9709048710809
At time: 429.47638154029846 and batch: 1150, loss is 5.135168724060058 and perplexity is 169.8929824903598
At time: 430.5476825237274 and batch: 1200, loss is 5.092817420959473 and perplexity is 162.84802777422556
At time: 431.61788845062256 and batch: 1250, loss is 5.121989555358887 and perplexity is 167.66862400656174
At time: 432.69753646850586 and batch: 1300, loss is 5.086759214401245 and perplexity is 161.86444317199394
At time: 433.76864433288574 and batch: 1350, loss is 5.084469299316407 and perplexity is 161.49421140331378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.187711181640625 and perplexity of 179.05825174451687
Finished 14 epochs...
Completing Train Step...
At time: 436.92141819000244 and batch: 50, loss is 5.211485977172852 and perplexity is 183.36633403241765
At time: 438.0227065086365 and batch: 100, loss is 5.211898441314697 and perplexity is 183.44198166992422
At time: 439.0926914215088 and batch: 150, loss is 5.200627660751342 and perplexity is 181.38605506098247
At time: 440.16337180137634 and batch: 200, loss is 5.18364875793457 and perplexity is 178.3323167839207
At time: 441.23364186286926 and batch: 250, loss is 5.185599670410157 and perplexity is 178.68056711804033
At time: 442.3041043281555 and batch: 300, loss is 5.195585041046143 and perplexity is 180.473696437558
At time: 443.3740999698639 and batch: 350, loss is 5.196768198013306 and perplexity is 180.68735151771216
At time: 444.44432735443115 and batch: 400, loss is 5.221955938339233 and perplexity is 185.2962579131652
At time: 445.51565408706665 and batch: 450, loss is 5.195986185073853 and perplexity is 180.54610690558505
At time: 446.58573150634766 and batch: 500, loss is 5.236012649536133 and perplexity is 187.91930642341453
At time: 447.68297052383423 and batch: 550, loss is 5.214122047424317 and perplexity is 183.85033822493412
At time: 448.75313210487366 and batch: 600, loss is 5.167511520385742 and perplexity is 175.4776212246379
At time: 449.8235991001129 and batch: 650, loss is 5.177283306121826 and perplexity is 177.20075628250365
At time: 450.8935317993164 and batch: 700, loss is 5.1950516033172605 and perplexity is 180.37745063166167
At time: 451.96432995796204 and batch: 750, loss is 5.179607954025268 and perplexity is 177.61316481567937
At time: 453.034428358078 and batch: 800, loss is 5.148688821792603 and perplexity is 172.20555006082122
At time: 454.1045618057251 and batch: 850, loss is 5.13174108505249 and perplexity is 169.31164754878603
At time: 455.1801519393921 and batch: 900, loss is 5.156053943634033 and perplexity is 173.47854705329266
At time: 456.25288820266724 and batch: 950, loss is 5.1425940990448 and perplexity is 171.15919683293123
At time: 457.32295989990234 and batch: 1000, loss is 5.166096649169922 and perplexity is 175.22951854740379
At time: 458.39868330955505 and batch: 1050, loss is 5.13276403427124 and perplexity is 169.48493338256452
At time: 459.47097611427307 and batch: 1100, loss is 5.119239616394043 and perplexity is 167.20817891234057
At time: 460.54156255722046 and batch: 1150, loss is 5.130762958526612 and perplexity is 169.146120301671
At time: 461.61855697631836 and batch: 1200, loss is 5.0891890048980715 and perplexity is 162.2582180592935
At time: 462.6891219615936 and batch: 1250, loss is 5.118693437576294 and perplexity is 167.11687828236902
At time: 463.7599287033081 and batch: 1300, loss is 5.083615274429321 and perplexity is 161.35635020448163
At time: 464.83052372932434 and batch: 1350, loss is 5.080256958007812 and perplexity is 160.8153734179291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.187755533854166 and perplexity of 179.06619355045154
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 468.0252480506897 and batch: 50, loss is 5.208020105361938 and perplexity is 182.73190987569723
At time: 469.09583377838135 and batch: 100, loss is 5.2110206890106205 and perplexity is 183.2810356935332
At time: 470.1668984889984 and batch: 150, loss is 5.1994883155822755 and perplexity is 181.17951142000538
At time: 471.23840260505676 and batch: 200, loss is 5.182808132171631 and perplexity is 178.18246903583042
At time: 472.30952048301697 and batch: 250, loss is 5.182265024185181 and perplexity is 178.08572298800544
At time: 473.3805425167084 and batch: 300, loss is 5.192954273223877 and perplexity is 179.99953602065793
At time: 474.4766342639923 and batch: 350, loss is 5.192093181610107 and perplexity is 179.84460664347492
At time: 475.54699420928955 and batch: 400, loss is 5.215591373443604 and perplexity is 184.12067286676847
At time: 476.6175949573517 and batch: 450, loss is 5.18604284286499 and perplexity is 178.75977097278806
At time: 477.68890857696533 and batch: 500, loss is 5.22337628364563 and perplexity is 185.55962957846253
At time: 478.7598123550415 and batch: 550, loss is 5.197673072814942 and perplexity is 180.85092494464982
At time: 479.8303687572479 and batch: 600, loss is 5.153034887313843 and perplexity is 172.95559535691834
At time: 480.90164732933044 and batch: 650, loss is 5.161067180633545 and perplexity is 174.35041975020232
At time: 481.97242069244385 and batch: 700, loss is 5.173036794662476 and perplexity is 176.44986669934454
At time: 483.0433690547943 and batch: 750, loss is 5.155490198135376 and perplexity is 173.38077686461904
At time: 484.114280462265 and batch: 800, loss is 5.1251891040802 and perplexity is 168.20594707538888
At time: 485.1850953102112 and batch: 850, loss is 5.098493146896362 and perplexity is 163.77493650091088
At time: 486.25907611846924 and batch: 900, loss is 5.117491540908813 and perplexity is 166.91614171974908
At time: 487.33390712738037 and batch: 950, loss is 5.106233558654785 and perplexity is 165.0475408320094
At time: 488.4051101207733 and batch: 1000, loss is 5.12907151222229 and perplexity is 168.8602605479619
At time: 489.4804472923279 and batch: 1050, loss is 5.089650707244873 and perplexity is 162.33315035623693
At time: 490.5510630607605 and batch: 1100, loss is 5.072133855819702 and perplexity is 159.5143450534125
At time: 491.621723651886 and batch: 1150, loss is 5.081636304855347 and perplexity is 161.03734665013346
At time: 492.6926951408386 and batch: 1200, loss is 5.036832427978515 and perplexity is 153.98149424897383
At time: 493.7632794380188 and batch: 1250, loss is 5.063921222686767 and perplexity is 158.20967697123277
At time: 494.83373045921326 and batch: 1300, loss is 5.03256233215332 and perplexity is 153.32538034479492
At time: 495.9047317504883 and batch: 1350, loss is 5.035210914611817 and perplexity is 153.73201352065615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.163440348307292 and perplexity of 174.76467388309558
Finished 16 epochs...
Completing Train Step...
At time: 499.0706536769867 and batch: 50, loss is 5.1932768058776855 and perplexity is 180.05760111213567
At time: 500.14677834510803 and batch: 100, loss is 5.1944153690338135 and perplexity is 180.26272481372837
At time: 501.2475824356079 and batch: 150, loss is 5.183412418365479 and perplexity is 178.2901747811245
At time: 502.31885957717896 and batch: 200, loss is 5.167647037506104 and perplexity is 175.5014030579406
At time: 503.39899158477783 and batch: 250, loss is 5.16725902557373 and perplexity is 175.43331962885145
At time: 504.4808785915375 and batch: 300, loss is 5.177918863296509 and perplexity is 177.31341329071105
At time: 505.555951833725 and batch: 350, loss is 5.177774801254272 and perplexity is 177.287870998158
At time: 506.6299750804901 and batch: 400, loss is 5.2022511005401615 and perplexity is 181.68076355592703
At time: 507.7008080482483 and batch: 450, loss is 5.172705211639404 and perplexity is 176.39136861814507
At time: 508.7723925113678 and batch: 500, loss is 5.211773233413696 and perplexity is 183.41901472229551
At time: 509.8434612751007 and batch: 550, loss is 5.187778387069702 and perplexity is 179.0702858355287
At time: 510.91439867019653 and batch: 600, loss is 5.1434433650970455 and perplexity is 171.30461827033565
At time: 511.9848163127899 and batch: 650, loss is 5.152367715835571 and perplexity is 172.84024280093516
At time: 513.0556263923645 and batch: 700, loss is 5.165387411117553 and perplexity is 175.1052831663893
At time: 514.1263518333435 and batch: 750, loss is 5.149111080169678 and perplexity is 172.27828065138308
At time: 515.1968991756439 and batch: 800, loss is 5.119207820892334 and perplexity is 167.20286252892123
At time: 516.268440246582 and batch: 850, loss is 5.094072217941284 and perplexity is 163.05249724497963
At time: 517.3395829200745 and batch: 900, loss is 5.115350284576416 and perplexity is 166.55911385481446
At time: 518.4124712944031 and batch: 950, loss is 5.104634933471679 and perplexity is 164.78390246244032
At time: 519.4887371063232 and batch: 1000, loss is 5.1286099338531494 and perplexity is 168.78233628974502
At time: 520.559502363205 and batch: 1050, loss is 5.090512247085571 and perplexity is 162.47306709600323
At time: 521.6404809951782 and batch: 1100, loss is 5.074828510284424 and perplexity is 159.9447607458383
At time: 522.7202277183533 and batch: 1150, loss is 5.085412454605103 and perplexity is 161.64659737341327
At time: 523.7992856502533 and batch: 1200, loss is 5.042116575241089 and perplexity is 154.79730868382507
At time: 524.8718709945679 and batch: 1250, loss is 5.070364017486572 and perplexity is 159.23228012913714
At time: 525.9442980289459 and batch: 1300, loss is 5.039519529342652 and perplexity is 154.39581454323556
At time: 527.0159153938293 and batch: 1350, loss is 5.039617109298706 and perplexity is 154.41088121512425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.16163818359375 and perplexity of 174.45000278439068
Finished 17 epochs...
Completing Train Step...
At time: 530.2310302257538 and batch: 50, loss is 5.188646516799927 and perplexity is 179.22580957208453
At time: 531.3304040431976 and batch: 100, loss is 5.188421277999878 and perplexity is 179.18544551174568
At time: 532.4056351184845 and batch: 150, loss is 5.176429319381714 and perplexity is 177.04949378357765
At time: 533.4855544567108 and batch: 200, loss is 5.161122922897339 and perplexity is 174.3601387081685
At time: 534.5583486557007 and batch: 250, loss is 5.1609306907653805 and perplexity is 174.32662430835157
At time: 535.6318142414093 and batch: 300, loss is 5.17179443359375 and perplexity is 176.2307883697474
At time: 536.7035965919495 and batch: 350, loss is 5.171846485137939 and perplexity is 176.23996169315654
At time: 537.7829945087433 and batch: 400, loss is 5.19650242805481 and perplexity is 180.63933662853873
At time: 538.8613910675049 and batch: 450, loss is 5.167090797424317 and perplexity is 175.4038092884494
At time: 539.941015958786 and batch: 500, loss is 5.206391410827637 and perplexity is 182.43453764284064
At time: 541.0126466751099 and batch: 550, loss is 5.18332537651062 and perplexity is 178.27465674897738
At time: 542.083854675293 and batch: 600, loss is 5.139617099761963 and perplexity is 170.65041372593944
At time: 543.1544852256775 and batch: 650, loss is 5.148643579483032 and perplexity is 172.19775926025383
At time: 544.2258050441742 and batch: 700, loss is 5.162317113876343 and perplexity is 174.56848238922416
At time: 545.3040425777435 and batch: 750, loss is 5.146412544250488 and perplexity is 171.81400823258798
At time: 546.3775684833527 and batch: 800, loss is 5.116808958053589 and perplexity is 166.80224649903568
At time: 547.4480588436127 and batch: 850, loss is 5.092391653060913 and perplexity is 162.778707069968
At time: 548.5259211063385 and batch: 900, loss is 5.114443969726563 and perplexity is 166.4082272422665
At time: 549.5968859195709 and batch: 950, loss is 5.104281406402588 and perplexity is 164.7256571886165
At time: 550.667384147644 and batch: 1000, loss is 5.128823719024658 and perplexity is 168.8184233077536
At time: 551.7376456260681 and batch: 1050, loss is 5.091259784698487 and perplexity is 162.5945672320461
At time: 552.808420419693 and batch: 1100, loss is 5.076242551803589 and perplexity is 160.17108925955134
At time: 553.8830559253693 and batch: 1150, loss is 5.087268362045288 and perplexity is 161.94687705561728
At time: 554.957065820694 and batch: 1200, loss is 5.0447657012939455 and perplexity is 155.20792992073933
At time: 556.0533154010773 and batch: 1250, loss is 5.073165311813354 and perplexity is 159.678961963646
At time: 557.1237168312073 and batch: 1300, loss is 5.04247260093689 and perplexity is 154.8524303151337
At time: 558.1941974163055 and batch: 1350, loss is 5.041107244491577 and perplexity is 154.64114582347491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.160921630859375 and perplexity of 174.32504493267552
Finished 18 epochs...
Completing Train Step...
At time: 561.3357455730438 and batch: 50, loss is 5.184985113143921 and perplexity is 178.57079141236665
At time: 562.432434797287 and batch: 100, loss is 5.184170160293579 and perplexity is 178.4253239195423
At time: 563.5028982162476 and batch: 150, loss is 5.171680631637574 and perplexity is 176.21073410242155
At time: 564.5737254619598 and batch: 200, loss is 5.156664905548095 and perplexity is 173.58456822259942
At time: 565.6442403793335 and batch: 250, loss is 5.156591672897338 and perplexity is 173.5718566299955
At time: 566.7148413658142 and batch: 300, loss is 5.167597408294678 and perplexity is 175.49269327783423
At time: 567.7855222225189 and batch: 350, loss is 5.168103456497192 and perplexity is 175.58152351411695
At time: 568.8558084964752 and batch: 400, loss is 5.192833499908447 and perplexity is 179.97779819261817
At time: 569.9317581653595 and batch: 450, loss is 5.1633909320831295 and perplexity is 174.75603788617624
At time: 571.0035884380341 and batch: 500, loss is 5.202885551452637 and perplexity is 181.79606765567218
At time: 572.074428319931 and batch: 550, loss is 5.180342035293579 and perplexity is 177.74359518036258
At time: 573.1451559066772 and batch: 600, loss is 5.136963586807251 and perplexity is 170.19819089730458
At time: 574.2151777744293 and batch: 650, loss is 5.146033802032471 and perplexity is 171.74894733545548
At time: 575.2856242656708 and batch: 700, loss is 5.1600626277923585 and perplexity is 174.1753634820372
At time: 576.3566083908081 and batch: 750, loss is 5.1442522621154785 and perplexity is 171.44324212395063
At time: 577.4268479347229 and batch: 800, loss is 5.115141429901123 and perplexity is 166.52433083759755
At time: 578.4979083538055 and batch: 850, loss is 5.090955266952514 and perplexity is 162.54506183894318
At time: 579.5683958530426 and batch: 900, loss is 5.113388366699219 and perplexity is 166.23265889535685
At time: 580.639137506485 and batch: 950, loss is 5.1037865734100345 and perplexity is 164.6441656627301
At time: 581.7108542919159 and batch: 1000, loss is 5.128587827682495 and perplexity is 168.77860519985583
At time: 582.8440606594086 and batch: 1050, loss is 5.09132833480835 and perplexity is 162.60571348952723
At time: 583.9147436618805 and batch: 1100, loss is 5.076657676696778 and perplexity is 160.23759406881797
At time: 584.9849753379822 and batch: 1150, loss is 5.087973031997681 and perplexity is 162.06103637135814
At time: 586.0556514263153 and batch: 1200, loss is 5.046115837097168 and perplexity is 155.41762322923753
At time: 587.1264343261719 and batch: 1250, loss is 5.074566612243652 and perplexity is 159.9028770112407
At time: 588.1983296871185 and batch: 1300, loss is 5.043948192596435 and perplexity is 155.08109793829462
At time: 589.2689061164856 and batch: 1350, loss is 5.041506271362305 and perplexity is 154.7028641087868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.160590006510417 and perplexity of 174.26724408775624
Finished 19 epochs...
Completing Train Step...
At time: 592.4419102668762 and batch: 50, loss is 5.182105941772461 and perplexity is 178.05739493482875
At time: 593.5122389793396 and batch: 100, loss is 5.180752763748169 and perplexity is 177.8166145270594
At time: 594.589437007904 and batch: 150, loss is 5.168026390075684 and perplexity is 175.56799259581314
At time: 595.660807132721 and batch: 200, loss is 5.153136472702027 and perplexity is 172.973166010657
At time: 596.7311880588531 and batch: 250, loss is 5.153452091217041 and perplexity is 173.02776816072202
At time: 597.8028466701508 and batch: 300, loss is 5.164653539657593 and perplexity is 174.97682553804407
At time: 598.8744277954102 and batch: 350, loss is 5.165421133041382 and perplexity is 175.1111881529734
At time: 599.9452185630798 and batch: 400, loss is 5.19014952659607 and perplexity is 179.49539026005104
At time: 601.0231611728668 and batch: 450, loss is 5.16071946144104 and perplexity is 174.28980530204822
At time: 602.0938982963562 and batch: 500, loss is 5.200253276824951 and perplexity is 181.31815974774617
At time: 603.1702847480774 and batch: 550, loss is 5.177989501953125 and perplexity is 177.32593891441724
At time: 604.2422733306885 and batch: 600, loss is 5.135025501251221 and perplexity is 169.86865168261062
At time: 605.3135557174683 and batch: 650, loss is 5.144150266647339 and perplexity is 171.42575658194897
At time: 606.3846380710602 and batch: 700, loss is 5.158459901809692 and perplexity is 173.89643168677046
At time: 607.4577462673187 and batch: 750, loss is 5.142746305465698 and perplexity is 171.18525034439054
At time: 608.5285739898682 and batch: 800, loss is 5.113813705444336 and perplexity is 166.30337912484956
At time: 609.6257133483887 and batch: 850, loss is 5.089786386489868 and perplexity is 162.35517708976636
At time: 610.6961731910706 and batch: 900, loss is 5.112553243637085 and perplexity is 166.0938921199657
At time: 611.7675142288208 and batch: 950, loss is 5.103278923034668 and perplexity is 164.56060520177368
At time: 612.8376359939575 and batch: 1000, loss is 5.128338012695313 and perplexity is 168.73644704085032
At time: 613.9079730510712 and batch: 1050, loss is 5.091318416595459 and perplexity is 162.60410073944138
At time: 614.9793462753296 and batch: 1100, loss is 5.07673412322998 and perplexity is 160.2498441456052
At time: 616.0495913028717 and batch: 1150, loss is 5.08813141822815 and perplexity is 162.0867066408698
At time: 617.1203012466431 and batch: 1200, loss is 5.046889152526855 and perplexity is 155.53785655847858
At time: 618.1911132335663 and batch: 1250, loss is 5.075291366577148 and perplexity is 160.0188093204402
At time: 619.261830329895 and batch: 1300, loss is 5.044751615524292 and perplexity is 155.20574371298727
At time: 620.3329465389252 and batch: 1350, loss is 5.041608343124389 and perplexity is 154.71865570865037
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.160378011067708 and perplexity of 174.23030414188463
Finished 20 epochs...
Completing Train Step...
At time: 623.5000383853912 and batch: 50, loss is 5.179341096878051 and perplexity is 177.56577379680573
At time: 624.5708117485046 and batch: 100, loss is 5.177784404754639 and perplexity is 177.2895735904675
At time: 625.6416819095612 and batch: 150, loss is 5.164943790435791 and perplexity is 175.02762006904257
At time: 626.7129135131836 and batch: 200, loss is 5.150227384567261 and perplexity is 172.4707030346766
At time: 627.7841420173645 and batch: 250, loss is 5.150834712982178 and perplexity is 172.57548120753052
At time: 628.8552582263947 and batch: 300, loss is 5.162080507278443 and perplexity is 174.52718322052604
At time: 629.9258861541748 and batch: 350, loss is 5.1630972957611085 and perplexity is 174.70473069915587
At time: 631.0004169940948 and batch: 400, loss is 5.187736654281617 and perplexity is 179.06281288917202
At time: 632.074737071991 and batch: 450, loss is 5.158448219299316 and perplexity is 173.89440015176967
At time: 633.1454775333405 and batch: 500, loss is 5.198003082275391 and perplexity is 180.91061730979342
At time: 634.2160563468933 and batch: 550, loss is 5.176023645401001 and perplexity is 176.97768397732108
At time: 635.2867901325226 and batch: 600, loss is 5.1334326171875 and perplexity is 169.5982860021777
At time: 636.3572523593903 and batch: 650, loss is 5.142650194168091 and perplexity is 171.1687982984752
At time: 637.4625072479248 and batch: 700, loss is 5.157072334289551 and perplexity is 173.65530597408448
At time: 638.5333886146545 and batch: 750, loss is 5.141297378540039 and perplexity is 170.93739503137132
At time: 639.6040699481964 and batch: 800, loss is 5.112443056106567 and perplexity is 166.0755916524191
At time: 640.6749114990234 and batch: 850, loss is 5.088724040985108 and perplexity is 162.182791380015
At time: 641.7465708255768 and batch: 900, loss is 5.111610450744629 and perplexity is 165.93737377278083
At time: 642.817759513855 and batch: 950, loss is 5.102736511230469 and perplexity is 164.4713697903642
At time: 643.8886892795563 and batch: 1000, loss is 5.1278773784637455 and perplexity is 168.65873915606022
At time: 644.9668626785278 and batch: 1050, loss is 5.0910171699523925 and perplexity is 162.55512417732763
At time: 646.0383188724518 and batch: 1100, loss is 5.076530103683472 and perplexity is 160.21715337996554
At time: 647.109222650528 and batch: 1150, loss is 5.0878750705719 and perplexity is 162.04516141875084
At time: 648.1805009841919 and batch: 1200, loss is 5.047209806442261 and perplexity is 155.58773837815085
At time: 649.2513027191162 and batch: 1250, loss is 5.075519313812256 and perplexity is 160.05528932318995
At time: 650.3221080303192 and batch: 1300, loss is 5.045146579742432 and perplexity is 155.2670565355922
At time: 651.3930287361145 and batch: 1350, loss is 5.04131700515747 and perplexity is 154.67358685550457
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.160205485026042 and perplexity of 174.20024747002657
Finished 21 epochs...
Completing Train Step...
At time: 654.5540585517883 and batch: 50, loss is 5.176890478134156 and perplexity is 177.13116053647298
At time: 655.6503553390503 and batch: 100, loss is 5.1750861930847165 and perplexity is 176.81185357873605
At time: 656.7209084033966 and batch: 150, loss is 5.162119703292847 and perplexity is 174.53402412458064
At time: 657.7912747859955 and batch: 200, loss is 5.147684831619262 and perplexity is 172.03274414300282
At time: 658.8620314598083 and batch: 250, loss is 5.148596706390381 and perplexity is 172.1896880078935
At time: 659.9333729743958 and batch: 300, loss is 5.159796571731567 and perplexity is 174.1290292349692
At time: 661.0033848285675 and batch: 350, loss is 5.161174545288086 and perplexity is 174.36913982770724
At time: 662.0736827850342 and batch: 400, loss is 5.185721549987793 and perplexity is 178.70234595726342
At time: 663.144079208374 and batch: 450, loss is 5.15634976387024 and perplexity is 173.52987310932744
At time: 664.2407286167145 and batch: 500, loss is 5.196110763549805 and perplexity is 180.56860046550003
At time: 665.3128690719604 and batch: 550, loss is 5.17437786102295 and perplexity is 176.68665641976133
At time: 666.3929710388184 and batch: 600, loss is 5.1319067096710205 and perplexity is 169.33969204818965
At time: 667.4632694721222 and batch: 650, loss is 5.141194238662719 and perplexity is 170.91976547858903
At time: 668.5333342552185 and batch: 700, loss is 5.155637331008911 and perplexity is 173.40628875330765
At time: 669.6041893959045 and batch: 750, loss is 5.13994704246521 and perplexity is 170.70672787446483
At time: 670.6742961406708 and batch: 800, loss is 5.111188907623291 and perplexity is 165.86743875564227
At time: 671.7448544502258 and batch: 850, loss is 5.087779960632324 and perplexity is 162.02975004613876
At time: 672.8216261863708 and batch: 900, loss is 5.110747632980346 and perplexity is 165.79426180758253
At time: 673.8911144733429 and batch: 950, loss is 5.102053623199463 and perplexity is 164.35909260122884
At time: 674.965550661087 and batch: 1000, loss is 5.127325286865235 and perplexity is 168.56564978245177
At time: 676.0371024608612 and batch: 1050, loss is 5.090532989501953 and perplexity is 162.47643721496385
At time: 677.1083972454071 and batch: 1100, loss is 5.076225280761719 and perplexity is 160.16832296185078
At time: 678.1782817840576 and batch: 1150, loss is 5.087545928955078 and perplexity is 161.99183438887712
At time: 679.2485229969025 and batch: 1200, loss is 5.047218570709228 and perplexity is 155.58910199660238
At time: 680.3189718723297 and batch: 1250, loss is 5.075555419921875 and perplexity is 160.0610684013407
At time: 681.3895692825317 and batch: 1300, loss is 5.045256977081299 and perplexity is 155.28419855164648
At time: 682.4666891098022 and batch: 1350, loss is 5.040938911437988 and perplexity is 154.61511679802197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.160062662760416 and perplexity of 174.1753695726115
Finished 22 epochs...
Completing Train Step...
At time: 685.6064460277557 and batch: 50, loss is 5.174752683639526 and perplexity is 176.7528949877159
At time: 686.7105634212494 and batch: 100, loss is 5.172830667495727 and perplexity is 176.41349933652813
At time: 687.7906012535095 and batch: 150, loss is 5.159707937240601 and perplexity is 174.11359608106548
At time: 688.8614101409912 and batch: 200, loss is 5.145354738235474 and perplexity is 171.63235843327917
At time: 689.9340155124664 and batch: 250, loss is 5.146498432159424 and perplexity is 171.82876561221215
At time: 691.0357885360718 and batch: 300, loss is 5.157896823883057 and perplexity is 173.79854200691233
At time: 692.1111574172974 and batch: 350, loss is 5.15935209274292 and perplexity is 174.05164973821493
At time: 693.1849751472473 and batch: 400, loss is 5.183905248641968 and perplexity is 178.37806323252315
At time: 694.2637794017792 and batch: 450, loss is 5.1544340705871585 and perplexity is 173.19776131073644
At time: 695.3365347385406 and batch: 500, loss is 5.194240617752075 and perplexity is 180.23122642378965
At time: 696.4098720550537 and batch: 550, loss is 5.172738084793091 and perplexity is 176.3971672540238
At time: 697.4822843074799 and batch: 600, loss is 5.130414590835572 and perplexity is 169.08720552089204
At time: 698.5614500045776 and batch: 650, loss is 5.139709796905517 and perplexity is 170.66623326504
At time: 699.6361739635468 and batch: 700, loss is 5.154255199432373 and perplexity is 173.16678399772096
At time: 700.715626001358 and batch: 750, loss is 5.138634233474732 and perplexity is 170.48276958676826
At time: 701.7893924713135 and batch: 800, loss is 5.110032930374145 and perplexity is 165.6758105503287
At time: 702.861447095871 and batch: 850, loss is 5.086704511642456 and perplexity is 161.855588982579
At time: 703.9409475326538 and batch: 900, loss is 5.109797868728638 and perplexity is 165.63687109844508
At time: 705.0148520469666 and batch: 950, loss is 5.10135085105896 and perplexity is 164.24362618795183
At time: 706.0899934768677 and batch: 1000, loss is 5.126632452011108 and perplexity is 168.44890207318522
At time: 707.1708505153656 and batch: 1050, loss is 5.090031957626342 and perplexity is 162.39505173094693
At time: 708.2424640655518 and batch: 1100, loss is 5.07577410697937 and perplexity is 160.0960755130706
At time: 709.3140947818756 and batch: 1150, loss is 5.087034111022949 and perplexity is 161.90894527705484
At time: 710.3924882411957 and batch: 1200, loss is 5.047137832641601 and perplexity is 155.57654054026403
At time: 711.4641153812408 and batch: 1250, loss is 5.0753936767578125 and perplexity is 160.0351817112483
At time: 712.5346314907074 and batch: 1300, loss is 5.045342941284179 and perplexity is 155.29754800777437
At time: 713.6134634017944 and batch: 1350, loss is 5.040371961593628 and perplexity is 154.52748262605513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1599943033854165 and perplexity of 174.163463460159
Finished 23 epochs...
Completing Train Step...
At time: 716.8034112453461 and batch: 50, loss is 5.172638206481934 and perplexity is 176.3795498826769
At time: 717.8777530193329 and batch: 100, loss is 5.170695991516113 and perplexity is 176.03731533534125
At time: 718.9743921756744 and batch: 150, loss is 5.157479848861694 and perplexity is 173.72608746306346
At time: 720.0455346107483 and batch: 200, loss is 5.1431011295318605 and perplexity is 171.24600176838106
At time: 721.116260766983 and batch: 250, loss is 5.144553489685059 and perplexity is 171.4948933340903
At time: 722.1927759647369 and batch: 300, loss is 5.156031141281128 and perplexity is 173.47459137934075
At time: 723.2643077373505 and batch: 350, loss is 5.157657804489136 and perplexity is 173.75700574892088
At time: 724.3355667591095 and batch: 400, loss is 5.1821253204345705 and perplexity is 178.06084548235472
At time: 725.4063296318054 and batch: 450, loss is 5.152689695358276 and perplexity is 172.89590278002234
At time: 726.4813525676727 and batch: 500, loss is 5.19257420539856 and perplexity is 179.93113698740382
At time: 727.5548095703125 and batch: 550, loss is 5.17117748260498 and perplexity is 176.12209614294707
At time: 728.6258952617645 and batch: 600, loss is 5.129148063659668 and perplexity is 168.8731875384063
At time: 729.6968057155609 and batch: 650, loss is 5.138370227813721 and perplexity is 170.43776711120807
At time: 730.7676711082458 and batch: 700, loss is 5.152987060546875 and perplexity is 172.94732364776948
At time: 731.841272354126 and batch: 750, loss is 5.137434139251709 and perplexity is 170.27829691763728
At time: 732.9178910255432 and batch: 800, loss is 5.108838367462158 and perplexity is 165.4780185326566
At time: 733.9888272285461 and batch: 850, loss is 5.0857009601593015 and perplexity is 161.69324004258388
At time: 735.0594019889832 and batch: 900, loss is 5.108727884292603 and perplexity is 165.45973700659644
At time: 736.1299548149109 and batch: 950, loss is 5.100592136383057 and perplexity is 164.11905939964018
At time: 737.2002792358398 and batch: 1000, loss is 5.125839738845825 and perplexity is 168.3154233230054
At time: 738.2781729698181 and batch: 1050, loss is 5.0893738746643065 and perplexity is 162.28821747104254
At time: 739.3486177921295 and batch: 1100, loss is 5.075127267837525 and perplexity is 159.9925525899218
At time: 740.4236557483673 and batch: 1150, loss is 5.086530275344849 and perplexity is 161.8273903206943
At time: 741.4971714019775 and batch: 1200, loss is 5.046836185455322 and perplexity is 155.52961839188183
At time: 742.5702543258667 and batch: 1250, loss is 5.075146436691284 and perplexity is 159.99561949315938
At time: 743.6469616889954 and batch: 1300, loss is 5.045191144943237 and perplexity is 155.27397619733205
At time: 744.7180354595184 and batch: 1350, loss is 5.039734268188477 and perplexity is 154.4289728823151
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159861653645834 and perplexity of 174.1403622543045
Finished 24 epochs...
Completing Train Step...
At time: 747.8870203495026 and batch: 50, loss is 5.170771722793579 and perplexity is 176.05064737093295
At time: 748.9567847251892 and batch: 100, loss is 5.168680458068848 and perplexity is 175.68286356301041
At time: 750.0281844139099 and batch: 150, loss is 5.155399513244629 and perplexity is 173.36505456070992
At time: 751.098712682724 and batch: 200, loss is 5.141033611297607 and perplexity is 170.89231329185986
At time: 752.1748061180115 and batch: 250, loss is 5.142717571258545 and perplexity is 171.18033154261485
At time: 753.2525582313538 and batch: 300, loss is 5.154216270446778 and perplexity is 173.16004292169364
At time: 754.3234195709229 and batch: 350, loss is 5.156026544570923 and perplexity is 173.47379396874908
At time: 755.4025931358337 and batch: 400, loss is 5.180530939102173 and perplexity is 177.77717479400388
At time: 756.4731991291046 and batch: 450, loss is 5.151062278747559 and perplexity is 172.61475794784872
At time: 757.5446650981903 and batch: 500, loss is 5.190912666320801 and perplexity is 179.63242260352666
At time: 758.6153450012207 and batch: 550, loss is 5.169853954315186 and perplexity is 175.88914775713852
At time: 759.6867537498474 and batch: 600, loss is 5.127819147109985 and perplexity is 168.64891821530176
At time: 760.7576003074646 and batch: 650, loss is 5.1371275997161865 and perplexity is 170.2261078869999
At time: 761.8292441368103 and batch: 700, loss is 5.151788568496704 and perplexity is 172.74017181498746
At time: 762.8997416496277 and batch: 750, loss is 5.136251907348633 and perplexity is 170.077107432367
At time: 763.9706783294678 and batch: 800, loss is 5.107696142196655 and perplexity is 165.28911326572597
At time: 765.0408442020416 and batch: 850, loss is 5.084750232696533 and perplexity is 161.5395868914403
At time: 766.1122200489044 and batch: 900, loss is 5.107813425064087 and perplexity is 165.30849998372778
At time: 767.183000087738 and batch: 950, loss is 5.099866189956665 and perplexity is 163.99996098972917
At time: 768.2541098594666 and batch: 1000, loss is 5.125211753845215 and perplexity is 168.20975694371037
At time: 769.3250575065613 and batch: 1050, loss is 5.088836889266968 and perplexity is 162.20109446208582
At time: 770.3962893486023 and batch: 1100, loss is 5.074530239105225 and perplexity is 159.89706094753512
At time: 771.4673879146576 and batch: 1150, loss is 5.086136684417725 and perplexity is 161.763709061109
At time: 772.5828840732574 and batch: 1200, loss is 5.04650839805603 and perplexity is 155.47864609725062
At time: 773.6541965007782 and batch: 1250, loss is 5.074728946685791 and perplexity is 159.92883686260876
At time: 774.7256391048431 and batch: 1300, loss is 5.044939241409302 and perplexity is 155.2348670600715
At time: 775.7969129085541 and batch: 1350, loss is 5.0390979766845705 and perplexity is 154.3307422938717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159759114583333 and perplexity of 174.12250698026264
Finished 25 epochs...
Completing Train Step...
At time: 778.9313609600067 and batch: 50, loss is 5.168823928833008 and perplexity is 175.70807072589776
At time: 780.0297152996063 and batch: 100, loss is 5.166639785766602 and perplexity is 175.3247179625484
At time: 781.1007714271545 and batch: 150, loss is 5.153383502960205 and perplexity is 173.01590089470187
At time: 782.1712667942047 and batch: 200, loss is 5.139119300842285 and perplexity is 170.56548527474362
At time: 783.2418854236603 and batch: 250, loss is 5.140888833999634 and perplexity is 170.8675737554019
At time: 784.3124063014984 and batch: 300, loss is 5.152392015457154 and perplexity is 172.84444280445848
At time: 785.3821651935577 and batch: 350, loss is 5.1544424533844 and perplexity is 173.19921319853756
At time: 786.4541149139404 and batch: 400, loss is 5.178990516662598 and perplexity is 177.50353366028858
At time: 787.524692773819 and batch: 450, loss is 5.149358282089233 and perplexity is 172.32087343735017
At time: 788.5958986282349 and batch: 500, loss is 5.189321508407593 and perplexity is 179.34682632747527
At time: 789.6672713756561 and batch: 550, loss is 5.168607025146485 and perplexity is 175.66996313059386
At time: 790.7387270927429 and batch: 600, loss is 5.126545734405518 and perplexity is 168.43429522107786
At time: 791.8096942901611 and batch: 650, loss is 5.135748815536499 and perplexity is 169.99156455195194
At time: 792.8808987140656 and batch: 700, loss is 5.150633726119995 and perplexity is 172.54079928849475
At time: 793.9520606994629 and batch: 750, loss is 5.134981050491333 and perplexity is 169.8611010597789
At time: 795.0230376720428 and batch: 800, loss is 5.10651686668396 and perplexity is 165.09430674978992
At time: 796.0939588546753 and batch: 850, loss is 5.08370195388794 and perplexity is 161.37033709174122
At time: 797.165522813797 and batch: 900, loss is 5.106795482635498 and perplexity is 165.14031106562896
At time: 798.2368149757385 and batch: 950, loss is 5.099164123535156 and perplexity is 163.8848625320983
At time: 799.3078186511993 and batch: 1000, loss is 5.124376010894776 and perplexity is 168.0692355532094
At time: 800.4046573638916 and batch: 1050, loss is 5.088035926818848 and perplexity is 162.07122949180277
At time: 801.47474193573 and batch: 1100, loss is 5.073854370117187 and perplexity is 159.789027994936
At time: 802.5460820198059 and batch: 1150, loss is 5.085616760253906 and perplexity is 161.67962606022525
At time: 803.6236906051636 and batch: 1200, loss is 5.046008567810059 and perplexity is 155.40095258572958
At time: 804.6939966678619 and batch: 1250, loss is 5.074344205856323 and perplexity is 159.86731754451395
At time: 805.7644941806793 and batch: 1300, loss is 5.044605913162232 and perplexity is 155.1831315168882
At time: 806.8367230892181 and batch: 1350, loss is 5.0383379268646244 and perplexity is 154.21348780624982
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159749755859375 and perplexity of 174.12087742341015
Finished 26 epochs...
Completing Train Step...
At time: 809.9817893505096 and batch: 50, loss is 5.16707932472229 and perplexity is 175.40179694435463
At time: 811.0780522823334 and batch: 100, loss is 5.164809494018555 and perplexity is 175.0041160650371
At time: 812.1480977535248 and batch: 150, loss is 5.151587800979614 and perplexity is 172.70549468072812
At time: 813.2189605236053 and batch: 200, loss is 5.137193717956543 and perplexity is 170.2373633098064
At time: 814.2894220352173 and batch: 250, loss is 5.139153976440429 and perplexity is 170.57139983751313
At time: 815.3603570461273 and batch: 300, loss is 5.150722913742065 and perplexity is 172.55618847834575
At time: 816.43088722229 and batch: 350, loss is 5.153007001876831 and perplexity is 172.95077248180243
At time: 817.501317024231 and batch: 400, loss is 5.177609128952026 and perplexity is 177.25850174131284
At time: 818.5712306499481 and batch: 450, loss is 5.147878084182739 and perplexity is 172.06599312443242
At time: 819.6416125297546 and batch: 500, loss is 5.187912845611573 and perplexity is 179.09436498384176
At time: 820.7202577590942 and batch: 550, loss is 5.167308940887451 and perplexity is 175.44207665659084
At time: 821.7975873947144 and batch: 600, loss is 5.125260419845581 and perplexity is 168.21794323899894
At time: 822.8720264434814 and batch: 650, loss is 5.1345357418060305 and perplexity is 169.78547727539566
At time: 823.9467277526855 and batch: 700, loss is 5.149474420547485 and perplexity is 172.340887680105
At time: 825.0177676677704 and batch: 750, loss is 5.1338310813903805 and perplexity is 169.66587831368335
At time: 826.0882685184479 and batch: 800, loss is 5.105501260757446 and perplexity is 164.9267211083112
At time: 827.2029981613159 and batch: 850, loss is 5.082606687545776 and perplexity is 161.19369034817626
At time: 828.2736682891846 and batch: 900, loss is 5.105746793746948 and perplexity is 164.96722103102374
At time: 829.3445773124695 and batch: 950, loss is 5.098319778442383 and perplexity is 163.74654555448748
At time: 830.4153892993927 and batch: 1000, loss is 5.1236463642120365 and perplexity is 167.94664912084798
At time: 831.486279964447 and batch: 1050, loss is 5.0874051761627195 and perplexity is 161.96903519041072
At time: 832.5569036006927 and batch: 1100, loss is 5.07311297416687 and perplexity is 159.6706049612786
At time: 833.6280245780945 and batch: 1150, loss is 5.0850795555114745 and perplexity is 161.5927943236497
At time: 834.6987829208374 and batch: 1200, loss is 5.045538921356201 and perplexity is 155.3279862149613
At time: 835.773827791214 and batch: 1250, loss is 5.0739435291290285 and perplexity is 159.80327526190175
At time: 836.8435411453247 and batch: 1300, loss is 5.04415675163269 and perplexity is 155.11344487562783
At time: 837.9143207073212 and batch: 1350, loss is 5.037693138122559 and perplexity is 154.11408473587193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159717203776042 and perplexity of 174.11520951834984
Finished 27 epochs...
Completing Train Step...
At time: 841.0805442333221 and batch: 50, loss is 5.165408887863159 and perplexity is 175.10904389839413
At time: 842.1510055065155 and batch: 100, loss is 5.163041124343872 and perplexity is 174.69491756244602
At time: 843.2217445373535 and batch: 150, loss is 5.149765863418579 and perplexity is 172.39112252315516
At time: 844.2930061817169 and batch: 200, loss is 5.135503787994384 and perplexity is 169.9499170393117
At time: 845.3639006614685 and batch: 250, loss is 5.13751145362854 and perplexity is 170.29146238698485
At time: 846.4444231987 and batch: 300, loss is 5.149128131866455 and perplexity is 172.28121831343205
At time: 847.5146105289459 and batch: 350, loss is 5.151672964096069 and perplexity is 172.72020344519726
At time: 848.5862827301025 and batch: 400, loss is 5.176293716430664 and perplexity is 177.02548697747247
At time: 849.6573088169098 and batch: 450, loss is 5.146407985687256 and perplexity is 171.81322500935252
At time: 850.7271213531494 and batch: 500, loss is 5.1864433860778805 and perplexity is 178.83138632735375
At time: 851.7978827953339 and batch: 550, loss is 5.16594554901123 and perplexity is 175.20304333959822
At time: 852.8684384822845 and batch: 600, loss is 5.124166984558105 and perplexity is 168.03410832798022
At time: 853.9646897315979 and batch: 650, loss is 5.133342142105103 and perplexity is 169.5829422774
At time: 855.0351188182831 and batch: 700, loss is 5.148361845016479 and perplexity is 172.14925204980446
At time: 856.1054978370667 and batch: 750, loss is 5.132681264877319 and perplexity is 169.47090579788505
At time: 857.1762845516205 and batch: 800, loss is 5.104448118209839 and perplexity is 164.75312118985
At time: 858.2470490932465 and batch: 850, loss is 5.081520709991455 and perplexity is 161.01873263582894
At time: 859.3180272579193 and batch: 900, loss is 5.104735822677612 and perplexity is 164.8005282181758
At time: 860.388906955719 and batch: 950, loss is 5.097496118545532 and perplexity is 163.61172962052734
At time: 861.4663395881653 and batch: 1000, loss is 5.122824687957763 and perplexity is 167.8087080265024
At time: 862.5375580787659 and batch: 1050, loss is 5.0865613460540775 and perplexity is 161.83241849059817
At time: 863.6091773509979 and batch: 1100, loss is 5.072305908203125 and perplexity is 159.54179223777814
At time: 864.6851897239685 and batch: 1150, loss is 5.084366216659546 and perplexity is 161.47756500892666
At time: 865.7554075717926 and batch: 1200, loss is 5.045033073425293 and perplexity is 155.2494337439998
At time: 866.8259408473969 and batch: 1250, loss is 5.073477954864502 and perplexity is 159.7288922862959
At time: 867.8963680267334 and batch: 1300, loss is 5.0437470817565915 and perplexity is 155.04991258440583
At time: 868.9666192531586 and batch: 1350, loss is 5.036870861053467 and perplexity is 153.98741234500807
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159715983072917 and perplexity of 174.11499697549914
Finished 28 epochs...
Completing Train Step...
At time: 872.1474945545197 and batch: 50, loss is 5.1638736820220945 and perplexity is 174.8404217193059
At time: 873.2172684669495 and batch: 100, loss is 5.161558027267456 and perplexity is 174.43602007345442
At time: 874.2878782749176 and batch: 150, loss is 5.148076944351196 and perplexity is 172.10021359924272
At time: 875.3654797077179 and batch: 200, loss is 5.134001331329346 and perplexity is 169.69476637813656
At time: 876.4405810832977 and batch: 250, loss is 5.136277980804444 and perplexity is 170.08154198812383
At time: 877.5107443332672 and batch: 300, loss is 5.147809925079346 and perplexity is 172.05426566028783
At time: 878.5813944339752 and batch: 350, loss is 5.150577802658081 and perplexity is 172.53115047947693
At time: 879.6517362594604 and batch: 400, loss is 5.1749613571166995 and perplexity is 176.78978247749998
At time: 880.7218301296234 and batch: 450, loss is 5.144955444335937 and perplexity is 171.56384035992838
At time: 881.8233535289764 and batch: 500, loss is 5.185123052597046 and perplexity is 178.59542506861558
At time: 882.8931665420532 and batch: 550, loss is 5.1647711181640625 and perplexity is 174.99740026140657
At time: 884.1698079109192 and batch: 600, loss is 5.123007707595825 and perplexity is 167.83942312615648
At time: 885.2388834953308 and batch: 650, loss is 5.132120103836059 and perplexity is 169.37583200627316
At time: 886.3081345558167 and batch: 700, loss is 5.147261791229248 and perplexity is 171.95998273541753
At time: 887.3771092891693 and batch: 750, loss is 5.131583585739135 and perplexity is 169.28498318041906
At time: 888.447057723999 and batch: 800, loss is 5.103397188186645 and perplexity is 164.58006813762822
At time: 889.5161199569702 and batch: 850, loss is 5.0804636096954345 and perplexity is 160.84860962028193
At time: 890.5855515003204 and batch: 900, loss is 5.103734350204467 and perplexity is 164.63556764113136
At time: 891.6549398899078 and batch: 950, loss is 5.096682567596435 and perplexity is 163.4786772723818
At time: 892.724109172821 and batch: 1000, loss is 5.122099103927613 and perplexity is 167.68699287046488
At time: 893.7936375141144 and batch: 1050, loss is 5.085750102996826 and perplexity is 161.7011863024574
At time: 894.8713743686676 and batch: 1100, loss is 5.0714523887634275 and perplexity is 159.40567831286265
At time: 895.9412121772766 and batch: 1150, loss is 5.083624544143677 and perplexity is 161.35784593869008
At time: 897.0113837718964 and batch: 1200, loss is 5.044511137008667 and perplexity is 155.16842455353057
At time: 898.0810103416443 and batch: 1250, loss is 5.072898235321045 and perplexity is 159.63632116102062
At time: 899.1508345603943 and batch: 1300, loss is 5.043521709442139 and perplexity is 155.01497256415556
At time: 900.2206928730011 and batch: 1350, loss is 5.036121006011963 and perplexity is 153.87198738893406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159663899739583 and perplexity of 174.10592872222782
Finished 29 epochs...
Completing Train Step...
At time: 903.3802347183228 and batch: 50, loss is 5.162175302505493 and perplexity is 174.54372834867308
At time: 904.4500951766968 and batch: 100, loss is 5.1597358512878415 and perplexity is 174.11845636404652
At time: 905.5205640792847 and batch: 150, loss is 5.146525201797485 and perplexity is 171.833365467644
At time: 906.5990929603577 and batch: 200, loss is 5.132357454299926 and perplexity is 169.4160382098595
At time: 907.6738407611847 and batch: 250, loss is 5.134654521942139 and perplexity is 169.80564561527098
At time: 908.7696697711945 and batch: 300, loss is 5.146283473968506 and perplexity is 171.79183358117191
At time: 909.8406965732574 and batch: 350, loss is 5.149223260879516 and perplexity is 172.2976080352559
At time: 910.911463022232 and batch: 400, loss is 5.173656616210938 and perplexity is 176.55926803009663
At time: 911.9827220439911 and batch: 450, loss is 5.143569440841675 and perplexity is 171.32621698915113
At time: 913.0530123710632 and batch: 500, loss is 5.1837921047210695 and perplexity is 178.3578819807613
At time: 914.122873544693 and batch: 550, loss is 5.163481788635254 and perplexity is 174.7719163385613
At time: 915.1979372501373 and batch: 600, loss is 5.121928491592407 and perplexity is 167.65838584145305
At time: 916.2725739479065 and batch: 650, loss is 5.131037216186524 and perplexity is 169.19251628274395
At time: 917.3515951633453 and batch: 700, loss is 5.146227703094483 and perplexity is 171.78225286762796
At time: 918.4226250648499 and batch: 750, loss is 5.130515842437744 and perplexity is 169.10432673811866
At time: 919.4934000968933 and batch: 800, loss is 5.102368307113648 and perplexity is 164.410821902583
At time: 920.5643484592438 and batch: 850, loss is 5.079401912689209 and perplexity is 160.6779277552379
At time: 921.6356053352356 and batch: 900, loss is 5.1027805519104 and perplexity is 164.47861338082416
At time: 922.7061445713043 and batch: 950, loss is 5.095848817825317 and perplexity is 163.3424337670113
At time: 923.7768876552582 and batch: 1000, loss is 5.1213015270233155 and perplexity is 167.5533029188962
At time: 924.8480379581451 and batch: 1050, loss is 5.084804592132568 and perplexity is 161.54836833095595
At time: 925.9187080860138 and batch: 1100, loss is 5.070687017440796 and perplexity is 159.28372045549415
At time: 926.9887037277222 and batch: 1150, loss is 5.082874536514282 and perplexity is 161.2368716946471
At time: 928.0597147941589 and batch: 1200, loss is 5.043828248977661 and perplexity is 155.06249806569477
At time: 929.1302716732025 and batch: 1250, loss is 5.0723200607299805 and perplexity is 159.54405017325504
At time: 930.2009494304657 and batch: 1300, loss is 5.042929544448852 and perplexity is 154.9232052973308
At time: 931.2719945907593 and batch: 1350, loss is 5.035445127487183 and perplexity is 153.76802375444424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159623616536458 and perplexity of 174.0989153189979
Finished 30 epochs...
Completing Train Step...
At time: 934.4088969230652 and batch: 50, loss is 5.160597410202026 and perplexity is 174.26853431346524
At time: 935.5081930160522 and batch: 100, loss is 5.158275995254517 and perplexity is 173.86445393361095
At time: 936.5814456939697 and batch: 150, loss is 5.144947338104248 and perplexity is 171.5624496293257
At time: 937.6516783237457 and batch: 200, loss is 5.130770664215088 and perplexity is 169.14742369400284
At time: 938.722291469574 and batch: 250, loss is 5.13318528175354 and perplexity is 169.55634352365476
At time: 939.7933239936829 and batch: 300, loss is 5.144748592376709 and perplexity is 171.5283557135781
At time: 940.8715736865997 and batch: 350, loss is 5.1480091381073 and perplexity is 172.08854452580732
At time: 941.9430296421051 and batch: 400, loss is 5.17226019859314 and perplexity is 176.3128896212454
At time: 943.0141990184784 and batch: 450, loss is 5.142138614654541 and perplexity is 171.0812542426887
At time: 944.0843677520752 and batch: 500, loss is 5.1824801158905025 and perplexity is 178.12403186966998
At time: 945.1548247337341 and batch: 550, loss is 5.162301244735718 and perplexity is 174.56571215940912
At time: 946.2293303012848 and batch: 600, loss is 5.1209394645690915 and perplexity is 167.4926491397187
At time: 947.3026359081268 and batch: 650, loss is 5.129940881729126 and perplexity is 169.00712634046928
At time: 948.3726933002472 and batch: 700, loss is 5.145180768966675 and perplexity is 171.60250227448267
At time: 949.4431703090668 and batch: 750, loss is 5.129365005493164 and perplexity is 168.9098271715302
At time: 950.5125966072083 and batch: 800, loss is 5.1012776088714595 and perplexity is 164.23159706601174
At time: 951.5833461284637 and batch: 850, loss is 5.078336315155029 and perplexity is 160.50680094397165
At time: 952.6532938480377 and batch: 900, loss is 5.101699666976929 and perplexity is 164.3009269723229
At time: 953.724570274353 and batch: 950, loss is 5.094943952560425 and perplexity is 163.19469772310015
At time: 954.7949774265289 and batch: 1000, loss is 5.120471773147583 and perplexity is 167.4143325799694
At time: 955.8908712863922 and batch: 1050, loss is 5.084040279388428 and perplexity is 161.4249420284021
At time: 956.9617109298706 and batch: 1100, loss is 5.069810800552368 and perplexity is 159.14421449724327
At time: 958.032372713089 and batch: 1150, loss is 5.082100963592529 and perplexity is 161.11219144756498
At time: 959.1032435894012 and batch: 1200, loss is 5.0431078338623045 and perplexity is 154.95082892716061
At time: 960.1735973358154 and batch: 1250, loss is 5.071618585586548 and perplexity is 159.43217323181034
At time: 961.244631767273 and batch: 1300, loss is 5.042566080093383 and perplexity is 154.86690646629918
At time: 962.315122127533 and batch: 1350, loss is 5.034789810180664 and perplexity is 153.6672899172071
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1595365397135415 and perplexity of 174.08375599860102
Finished 31 epochs...
Completing Train Step...
At time: 965.4766602516174 and batch: 50, loss is 5.15898099899292 and perplexity is 173.98707224171363
At time: 966.5489046573639 and batch: 100, loss is 5.156620025634766 and perplexity is 173.5767779370372
At time: 967.6226904392242 and batch: 150, loss is 5.1433220386505125 and perplexity is 171.28383575048636
At time: 968.6914258003235 and batch: 200, loss is 5.129343185424805 and perplexity is 168.90614158776475
At time: 969.7626926898956 and batch: 250, loss is 5.131781921386719 and perplexity is 169.31856175698863
At time: 970.8378496170044 and batch: 300, loss is 5.143452758789063 and perplexity is 171.3062274607189
At time: 971.9128310680389 and batch: 350, loss is 5.146932640075684 and perplexity is 171.90339122282506
At time: 972.985057592392 and batch: 400, loss is 5.170990228652954 and perplexity is 176.0891196719888
At time: 974.0556809902191 and batch: 450, loss is 5.140881929397583 and perplexity is 170.86639398687464
At time: 975.1260104179382 and batch: 500, loss is 5.181152429580688 and perplexity is 177.8876959558032
At time: 976.203510761261 and batch: 550, loss is 5.16108585357666 and perplexity is 174.3536754160688
At time: 977.273820400238 and batch: 600, loss is 5.119820213317871 and perplexity is 167.30528765444654
At time: 978.3453326225281 and batch: 650, loss is 5.128776178359986 and perplexity is 168.81039775847208
At time: 979.4161057472229 and batch: 700, loss is 5.144091215133667 and perplexity is 171.41563393042236
At time: 980.4870178699493 and batch: 750, loss is 5.128199157714843 and perplexity is 168.7130187713956
At time: 981.5582318305969 and batch: 800, loss is 5.100172805786133 and perplexity is 164.0502536836747
At time: 982.6540334224701 and batch: 850, loss is 5.077205467224121 and perplexity is 160.32539475096854
At time: 983.723965883255 and batch: 900, loss is 5.100680751800537 and perplexity is 164.13360352301262
At time: 984.7949023246765 and batch: 950, loss is 5.094030275344848 and perplexity is 163.04565854330727
At time: 985.8652431964874 and batch: 1000, loss is 5.1195610237121585 and perplexity is 167.26192948214234
At time: 986.9398708343506 and batch: 1050, loss is 5.083154249191284 and perplexity is 161.2819779997688
At time: 988.0165042877197 and batch: 1100, loss is 5.068884782791137 and perplexity is 158.99691234075442
At time: 989.0877158641815 and batch: 1150, loss is 5.081292705535889 and perplexity is 160.9820238324027
At time: 990.158007144928 and batch: 1200, loss is 5.042421703338623 and perplexity is 154.84454889891916
At time: 991.2282419204712 and batch: 1250, loss is 5.07103271484375 and perplexity is 159.3387939428208
At time: 992.2994627952576 and batch: 1300, loss is 5.04196722984314 and perplexity is 154.7741921443756
At time: 993.370424747467 and batch: 1350, loss is 5.0339819431304935 and perplexity is 153.54319730890782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.159571126302083 and perplexity of 174.08977706596502
Annealing...
Finished 32 epochs...
Completing Train Step...
At time: 996.5417861938477 and batch: 50, loss is 5.159057521820069 and perplexity is 174.00038673379368
At time: 997.6122357845306 and batch: 100, loss is 5.15786039352417 and perplexity is 173.79221057898178
At time: 998.6828033924103 and batch: 150, loss is 5.144902973175049 and perplexity is 171.55483844223085
At time: 999.7525811195374 and batch: 200, loss is 5.131315011978149 and perplexity is 169.23952378068202
At time: 1000.8228530883789 and batch: 250, loss is 5.13341121673584 and perplexity is 169.59465656109236
At time: 1001.8953492641449 and batch: 300, loss is 5.145201244354248 and perplexity is 171.60601593819692
At time: 1002.9651696681976 and batch: 350, loss is 5.1475933647155765 and perplexity is 172.01700956017123
At time: 1004.0354080200195 and batch: 400, loss is 5.1713367938995365 and perplexity is 176.15015661719949
At time: 1005.1053383350372 and batch: 450, loss is 5.139490432739258 and perplexity is 170.62879931505492
At time: 1006.1753351688385 and batch: 500, loss is 5.178063869476318 and perplexity is 177.33912669565757
At time: 1007.2454705238342 and batch: 550, loss is 5.1556446075439455 and perplexity is 173.40755055483365
At time: 1008.315996170044 and batch: 600, loss is 5.115275993347168 and perplexity is 166.5467404331277
At time: 1009.3862471580505 and batch: 650, loss is 5.124452610015869 and perplexity is 168.082110002015
At time: 1010.4810798168182 and batch: 700, loss is 5.138229846954346 and perplexity is 170.41384259030272
At time: 1011.5510802268982 and batch: 750, loss is 5.122404441833496 and perplexity is 167.7382018833404
At time: 1012.6210825443268 and batch: 800, loss is 5.094328317642212 and perplexity is 163.09426028828278
At time: 1013.6913874149323 and batch: 850, loss is 5.067982158660889 and perplexity is 158.8534626413601
At time: 1014.7616546154022 and batch: 900, loss is 5.087888851165771 and perplexity is 162.04739451269583
At time: 1015.8316781520844 and batch: 950, loss is 5.081416940689087 and perplexity is 161.0020247011754
At time: 1016.9021875858307 and batch: 1000, loss is 5.107168684005737 and perplexity is 165.20195315774157
At time: 1017.9725480079651 and batch: 1050, loss is 5.0692722129821775 and perplexity is 159.058524479308
At time: 1019.0440218448639 and batch: 1100, loss is 5.054245319366455 and perplexity is 156.68623764408466
At time: 1020.1128280162811 and batch: 1150, loss is 5.066115741729736 and perplexity is 158.5572523610429
At time: 1021.1862766742706 and batch: 1200, loss is 5.025504207611084 and perplexity is 152.2470008599991
At time: 1022.2639889717102 and batch: 1250, loss is 5.053637771606446 and perplexity is 156.59107218308827
At time: 1023.3351938724518 and batch: 1300, loss is 5.027052021026611 and perplexity is 152.48283327560986
At time: 1024.4062867164612 and batch: 1350, loss is 5.021385240554809 and perplexity is 151.62119021055042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.154912516276042 and perplexity of 173.28064685949542
Finished 33 epochs...
Completing Train Step...
At time: 1027.5678679943085 and batch: 50, loss is 5.156280536651611 and perplexity is 173.51786053466645
At time: 1028.6655898094177 and batch: 100, loss is 5.154623413085938 and perplexity is 173.2305581124622
At time: 1029.7403857707977 and batch: 150, loss is 5.141603355407715 and perplexity is 170.98970592262486
At time: 1030.8106286525726 and batch: 200, loss is 5.128307847976685 and perplexity is 168.73135723016983
At time: 1031.8809599876404 and batch: 250, loss is 5.130202884674072 and perplexity is 169.0514125065871
At time: 1032.9509749412537 and batch: 300, loss is 5.142150144577027 and perplexity is 171.08322680766068
At time: 1034.0212745666504 and batch: 350, loss is 5.144855031967163 and perplexity is 171.5466140932014
At time: 1035.0923717021942 and batch: 400, loss is 5.16872010231018 and perplexity is 175.68982851491066
At time: 1036.1645226478577 and batch: 450, loss is 5.137149753570557 and perplexity is 170.22987909317732
At time: 1037.2615349292755 and batch: 500, loss is 5.175918140411377 and perplexity is 176.95901293357085
At time: 1038.3331475257874 and batch: 550, loss is 5.154096813201904 and perplexity is 173.1393589354946
At time: 1039.4057097434998 and batch: 600, loss is 5.113685026168823 and perplexity is 166.28198070330458
At time: 1040.4774549007416 and batch: 650, loss is 5.123224754333496 and perplexity is 167.87585607908233
At time: 1041.5504188537598 and batch: 700, loss is 5.137175512313843 and perplexity is 170.2342640574078
At time: 1042.6223983764648 and batch: 750, loss is 5.121518602371216 and perplexity is 167.58967855840365
At time: 1043.6954970359802 and batch: 800, loss is 5.093691024780274 and perplexity is 162.99035459307356
At time: 1044.768427848816 and batch: 850, loss is 5.067618894577026 and perplexity is 158.79576736373085
At time: 1045.8424398899078 and batch: 900, loss is 5.087804136276245 and perplexity is 162.0336672670309
At time: 1046.9255726337433 and batch: 950, loss is 5.081131639480591 and perplexity is 160.956097180858
At time: 1047.9988346099854 and batch: 1000, loss is 5.1074129009246825 and perplexity is 165.24230319662604
At time: 1049.0692224502563 and batch: 1050, loss is 5.069753522872925 and perplexity is 159.13509934698993
At time: 1050.139704465866 and batch: 1100, loss is 5.054981880187988 and perplexity is 156.80168910129723
At time: 1051.2161355018616 and batch: 1150, loss is 5.067129507064819 and perplexity is 158.71807371089406
At time: 1052.3012580871582 and batch: 1200, loss is 5.026884899139405 and perplexity is 152.45735218602948
At time: 1053.3777215480804 and batch: 1250, loss is 5.055202178955078 and perplexity is 156.8362361252775
At time: 1054.4494106769562 and batch: 1300, loss is 5.028485460281372 and perplexity is 152.70156488628962
At time: 1055.5224375724792 and batch: 1350, loss is 5.02218373298645 and perplexity is 151.74230693236757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.154376627604167 and perplexity of 173.18781260042383
Finished 34 epochs...
Completing Train Step...
At time: 1058.6881275177002 and batch: 50, loss is 5.15507625579834 and perplexity is 173.30902207284427
At time: 1059.7895357608795 and batch: 100, loss is 5.153097848892212 and perplexity is 172.9664852570089
At time: 1060.8611929416656 and batch: 150, loss is 5.140012598037719 and perplexity is 170.71791901855872
At time: 1061.9356079101562 and batch: 200, loss is 5.126817283630371 and perplexity is 168.4800396340326
At time: 1063.0069270133972 and batch: 250, loss is 5.128697910308838 and perplexity is 168.79718581466932
At time: 1064.1038386821747 and batch: 300, loss is 5.140607538223267 and perplexity is 170.81951618809865
At time: 1065.1743240356445 and batch: 350, loss is 5.143409023284912 and perplexity is 171.29873546033113
At time: 1066.2443821430206 and batch: 400, loss is 5.167375860214233 and perplexity is 175.45381751509075
At time: 1067.3148293495178 and batch: 450, loss is 5.135897302627564 and perplexity is 170.01680797899294
At time: 1068.385353565216 and batch: 500, loss is 5.174689102172851 and perplexity is 176.7416571366769
At time: 1069.4555704593658 and batch: 550, loss is 5.153197765350342 and perplexity is 172.98376831900768
At time: 1070.5261960029602 and batch: 600, loss is 5.1128236675262455 and perplexity is 166.13881394993282
At time: 1071.5966472625732 and batch: 650, loss is 5.122564697265625 and perplexity is 167.76508499539258
At time: 1072.6664757728577 and batch: 700, loss is 5.13667142868042 and perplexity is 170.14847337570453
At time: 1073.736528635025 and batch: 750, loss is 5.121154260635376 and perplexity is 167.52862976599567
At time: 1074.8079438209534 and batch: 800, loss is 5.0935282897949214 and perplexity is 162.9638325181996
At time: 1075.8867971897125 and batch: 850, loss is 5.067548818588257 and perplexity is 158.78463998320612
At time: 1076.96018242836 and batch: 900, loss is 5.08789909362793 and perplexity is 162.04905428550205
At time: 1078.0331642627716 and batch: 950, loss is 5.081064739227295 and perplexity is 160.94532953737007
At time: 1079.1072645187378 and batch: 1000, loss is 5.107644987106323 and perplexity is 165.28065810247017
At time: 1080.1796536445618 and batch: 1050, loss is 5.070137786865234 and perplexity is 159.19626098593673
At time: 1081.2590038776398 and batch: 1100, loss is 5.055533685684204 and perplexity is 156.88823701176955
At time: 1082.3318526744843 and batch: 1150, loss is 5.06784990310669 and perplexity is 158.83245477785596
At time: 1083.4049699306488 and batch: 1200, loss is 5.0278057289123534 and perplexity is 152.5978041112601
At time: 1084.4765815734863 and batch: 1250, loss is 5.056173477172852 and perplexity is 156.9886448871056
At time: 1085.5491425991058 and batch: 1300, loss is 5.029299983978271 and perplexity is 152.8259945980381
At time: 1086.6241002082825 and batch: 1350, loss is 5.022518854141236 and perplexity is 151.79316751124853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.154132486979167 and perplexity of 173.1455355805922
Finished 35 epochs...
Completing Train Step...
At time: 1089.8103182315826 and batch: 50, loss is 5.154161443710327 and perplexity is 173.15054938190892
At time: 1090.8878455162048 and batch: 100, loss is 5.151973218917846 and perplexity is 172.77207130549792
At time: 1091.9853780269623 and batch: 150, loss is 5.1388688659667965 and perplexity is 170.5227750769609
At time: 1093.0668840408325 and batch: 200, loss is 5.125706510543823 and perplexity is 168.29300043866988
At time: 1094.140570640564 and batch: 250, loss is 5.127627573013306 and perplexity is 168.61661254570222
At time: 1095.2118000984192 and batch: 300, loss is 5.139458599090577 and perplexity is 170.62336766425767
At time: 1096.2866711616516 and batch: 350, loss is 5.142375507354736 and perplexity is 171.12178694372005
At time: 1097.3686344623566 and batch: 400, loss is 5.166399335861206 and perplexity is 175.28256621859518
At time: 1098.4414367675781 and batch: 450, loss is 5.13497501373291 and perplexity is 169.86007565244142
At time: 1099.5128784179688 and batch: 500, loss is 5.173776054382325 and perplexity is 176.58035720561276
At time: 1100.590369939804 and batch: 550, loss is 5.1525099563598635 and perplexity is 172.86482943625646
At time: 1101.6654057502747 and batch: 600, loss is 5.112216739654541 and perplexity is 166.03801026655157
At time: 1102.7377452850342 and batch: 650, loss is 5.122119941711426 and perplexity is 167.69048713217677
At time: 1103.8095626831055 and batch: 700, loss is 5.136333208084107 and perplexity is 170.09093538839235
At time: 1104.8810946941376 and batch: 750, loss is 5.120903558731079 and perplexity is 167.48663528375738
At time: 1105.952576637268 and batch: 800, loss is 5.093457136154175 and perplexity is 162.95223746072608
At time: 1107.0247712135315 and batch: 850, loss is 5.067493991851807 and perplexity is 158.77593457824406
At time: 1108.0974082946777 and batch: 900, loss is 5.0879104042053225 and perplexity is 162.05088716423742
At time: 1109.176067352295 and batch: 950, loss is 5.080935497283935 and perplexity is 160.9245299943216
At time: 1110.2483804225922 and batch: 1000, loss is 5.107766284942627 and perplexity is 165.30070750463074
At time: 1111.3278772830963 and batch: 1050, loss is 5.070396823883057 and perplexity is 159.23750405214082
At time: 1112.4007651805878 and batch: 1100, loss is 5.05590817451477 and perplexity is 156.94700090670204
At time: 1113.4729759693146 and batch: 1150, loss is 5.068307838439941 and perplexity is 158.90520642746995
At time: 1114.5450451374054 and batch: 1200, loss is 5.028428220748902 and perplexity is 152.69282457025622
At time: 1115.6218655109406 and batch: 1250, loss is 5.057088947296142 and perplexity is 157.13242910623205
At time: 1116.7018859386444 and batch: 1300, loss is 5.029887857437134 and perplexity is 152.9158633572276
At time: 1117.7737369537354 and batch: 1350, loss is 5.022658185958862 and perplexity is 151.81431860265695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153979085286458 and perplexity of 173.11897679948228
Finished 36 epochs...
Completing Train Step...
At time: 1120.9665071964264 and batch: 50, loss is 5.153406715393066 and perplexity is 173.01991706129763
At time: 1122.0389864444733 and batch: 100, loss is 5.151030702590942 and perplexity is 172.60930752326962
At time: 1123.1115410327911 and batch: 150, loss is 5.137891664505005 and perplexity is 170.3562213634069
At time: 1124.1820855140686 and batch: 200, loss is 5.124788303375244 and perplexity is 168.1385435218214
At time: 1125.2563879489899 and batch: 250, loss is 5.126748886108398 and perplexity is 168.46851641090427
At time: 1126.3281879425049 and batch: 300, loss is 5.138496761322021 and perplexity is 170.45933456430154
At time: 1127.4002928733826 and batch: 350, loss is 5.1415173435211186 and perplexity is 170.97499940790652
At time: 1128.4728307724 and batch: 400, loss is 5.165622997283935 and perplexity is 175.14654040839065
At time: 1129.5450203418732 and batch: 450, loss is 5.134236364364624 and perplexity is 169.73465494153075
At time: 1130.617006778717 and batch: 500, loss is 5.173006029129028 and perplexity is 176.44443820857435
At time: 1131.6879587173462 and batch: 550, loss is 5.151974267959595 and perplexity is 172.77225255070877
At time: 1132.7600021362305 and batch: 600, loss is 5.111757354736328 and perplexity is 165.961752425977
At time: 1133.8312876224518 and batch: 650, loss is 5.121751890182495 and perplexity is 167.62877974844577
At time: 1134.902340888977 and batch: 700, loss is 5.136051530838013 and perplexity is 170.0430313891766
At time: 1135.972974061966 and batch: 750, loss is 5.120709085464478 and perplexity is 167.4540667776362
At time: 1137.0440187454224 and batch: 800, loss is 5.093407850265503 and perplexity is 162.94420641280212
At time: 1138.1158530712128 and batch: 850, loss is 5.067421503067017 and perplexity is 158.76442552083643
At time: 1139.1870007514954 and batch: 900, loss is 5.087919874191284 and perplexity is 162.0524217911304
At time: 1140.2575914859772 and batch: 950, loss is 5.080825271606446 and perplexity is 160.9067929565348
At time: 1141.3282363414764 and batch: 1000, loss is 5.107830610275268 and perplexity is 165.3113408696206
At time: 1142.4010384082794 and batch: 1050, loss is 5.0705781745910645 and perplexity is 159.26638450490822
At time: 1143.4720578193665 and batch: 1100, loss is 5.056160869598389 and perplexity is 156.98666565355208
At time: 1144.5425469875336 and batch: 1150, loss is 5.0686536693573 and perplexity is 158.96017026433103
At time: 1145.6380286216736 and batch: 1200, loss is 5.028923749923706 and perplexity is 152.76850706950862
At time: 1146.7189133167267 and batch: 1250, loss is 5.0576565551757815 and perplexity is 157.22164402829074
At time: 1147.7899897098541 and batch: 1300, loss is 5.030367364883423 and perplexity is 152.98920523494604
At time: 1148.8615639209747 and batch: 1350, loss is 5.022714519500733 and perplexity is 151.82287108182393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15388427734375 and perplexity of 173.10256452346752
Finished 37 epochs...
Completing Train Step...
At time: 1152.0268511772156 and batch: 50, loss is 5.152733650207519 and perplexity is 172.90350256038616
At time: 1153.1357018947601 and batch: 100, loss is 5.150234251022339 and perplexity is 172.47188730107717
At time: 1154.211693763733 and batch: 150, loss is 5.13707573890686 and perplexity is 170.21728005218776
At time: 1155.2927215099335 and batch: 200, loss is 5.124043073654175 and perplexity is 168.01328835966333
At time: 1156.3651118278503 and batch: 250, loss is 5.126018228530884 and perplexity is 168.34546857120853
At time: 1157.4367377758026 and batch: 300, loss is 5.137727241516114 and perplexity is 170.3282131869713
At time: 1158.5082602500916 and batch: 350, loss is 5.1408170795440675 and perplexity is 170.8553136855357
At time: 1159.5809063911438 and batch: 400, loss is 5.165020990371704 and perplexity is 175.0411327116758
At time: 1160.6532247066498 and batch: 450, loss is 5.133643722534179 and perplexity is 169.63409288651974
At time: 1161.725557088852 and batch: 500, loss is 5.172348289489746 and perplexity is 176.32842186589008
At time: 1162.7968592643738 and batch: 550, loss is 5.1515483570098874 and perplexity is 172.69868262477243
At time: 1163.869188785553 and batch: 600, loss is 5.111366529464721 and perplexity is 165.8969030522213
At time: 1164.9412033557892 and batch: 650, loss is 5.121459913253784 and perplexity is 167.57984315669674
At time: 1166.0139224529266 and batch: 700, loss is 5.135833110809326 and perplexity is 170.00589464123502
At time: 1167.0857899188995 and batch: 750, loss is 5.120525569915771 and perplexity is 167.42333917227126
At time: 1168.157485961914 and batch: 800, loss is 5.093359050750732 and perplexity is 162.93625500860827
At time: 1169.229453086853 and batch: 850, loss is 5.067349281311035 and perplexity is 158.7529596892841
At time: 1170.3025314807892 and batch: 900, loss is 5.08790431022644 and perplexity is 162.0498996325622
At time: 1171.375563621521 and batch: 950, loss is 5.080718297958374 and perplexity is 160.8895810905171
At time: 1172.4486739635468 and batch: 1000, loss is 5.107856693267823 and perplexity is 165.31565274032664
At time: 1173.5622437000275 and batch: 1050, loss is 5.070707921981811 and perplexity is 159.28705024336526
At time: 1174.6358120441437 and batch: 1100, loss is 5.056346035003662 and perplexity is 157.0157368445266
At time: 1175.7081801891327 and batch: 1150, loss is 5.068891277313233 and perplexity is 158.99794495306784
At time: 1176.7803823947906 and batch: 1200, loss is 5.029288721084595 and perplexity is 152.82427334480315
At time: 1177.8525824546814 and batch: 1250, loss is 5.05804762840271 and perplexity is 157.28314122813424
At time: 1178.9245874881744 and batch: 1300, loss is 5.030700597763062 and perplexity is 153.040194763582
At time: 1179.9973123073578 and batch: 1350, loss is 5.022729597091675 and perplexity is 151.82516022222705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153815104166667 and perplexity of 173.09059088325034
Finished 38 epochs...
Completing Train Step...
At time: 1183.167846918106 and batch: 50, loss is 5.152094459533691 and perplexity is 172.7930195676882
At time: 1184.2654976844788 and batch: 100, loss is 5.14956883430481 and perplexity is 172.35715979899533
At time: 1185.3379752635956 and batch: 150, loss is 5.136378870010376 and perplexity is 170.09870224546663
At time: 1186.4107019901276 and batch: 200, loss is 5.1234004688262935 and perplexity is 167.9053568917705
At time: 1187.4830207824707 and batch: 250, loss is 5.125392608642578 and perplexity is 168.2401812363236
At time: 1188.5557041168213 and batch: 300, loss is 5.13705135345459 and perplexity is 170.21312927743887
At time: 1189.6275267601013 and batch: 350, loss is 5.14022894859314 and perplexity is 170.7548579308916
At time: 1190.7040283679962 and batch: 400, loss is 5.164489345550537 and perplexity is 174.94809773295214
At time: 1191.7775990962982 and batch: 450, loss is 5.1331274032592775 and perplexity is 169.54653014179362
At time: 1192.849684715271 and batch: 500, loss is 5.171758737564087 and perplexity is 176.22449774257413
At time: 1193.9208476543427 and batch: 550, loss is 5.151161375045777 and perplexity is 172.63186427895218
At time: 1194.9938416481018 and batch: 600, loss is 5.111040630340576 and perplexity is 165.84284620583608
At time: 1196.0672626495361 and batch: 650, loss is 5.121192588806152 and perplexity is 167.5350509549826
At time: 1197.139589548111 and batch: 700, loss is 5.135647783279419 and perplexity is 169.9743907880673
At time: 1198.2123029232025 and batch: 750, loss is 5.120343046188355 and perplexity is 167.39278322902615
At time: 1199.2843034267426 and batch: 800, loss is 5.093299045562744 and perplexity is 162.9264782813265
At time: 1200.3826456069946 and batch: 850, loss is 5.067289819717407 and perplexity is 158.74352026595224
At time: 1201.4568648338318 and batch: 900, loss is 5.087855758666993 and perplexity is 162.04203204822
At time: 1202.5302736759186 and batch: 950, loss is 5.080541114807129 and perplexity is 160.8610766928612
At time: 1203.6042478084564 and batch: 1000, loss is 5.107840662002563 and perplexity is 165.3130025424891
At time: 1204.6785743236542 and batch: 1050, loss is 5.070741395950318 and perplexity is 159.29238230231064
At time: 1205.7558898925781 and batch: 1100, loss is 5.056461801528931 and perplexity is 157.03391506298797
At time: 1206.8360347747803 and batch: 1150, loss is 5.069030599594116 and perplexity is 159.02009845261674
At time: 1207.9051463603973 and batch: 1200, loss is 5.0295423316955565 and perplexity is 152.86303611725333
At time: 1208.9750633239746 and batch: 1250, loss is 5.058346490859986 and perplexity is 157.33015427907782
At time: 1210.0446746349335 and batch: 1300, loss is 5.030910711288453 and perplexity is 153.0723539568527
At time: 1211.1213080883026 and batch: 1350, loss is 5.022725257873535 and perplexity is 151.82450142116716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15378173828125 and perplexity of 173.0848156587764
Finished 39 epochs...
Completing Train Step...
At time: 1214.2815866470337 and batch: 50, loss is 5.15146053314209 and perplexity is 172.68351622449646
At time: 1215.3514080047607 and batch: 100, loss is 5.148952198028565 and perplexity is 172.25091088362717
At time: 1216.4285457134247 and batch: 150, loss is 5.135741643905639 and perplexity is 169.99034543957322
At time: 1217.4986996650696 and batch: 200, loss is 5.122809906005859 and perplexity is 167.80622750458474
At time: 1218.5686349868774 and batch: 250, loss is 5.124836416244507 and perplexity is 168.14663334419464
At time: 1219.6391298770905 and batch: 300, loss is 5.136444749832154 and perplexity is 170.10990868679028
At time: 1220.7089958190918 and batch: 350, loss is 5.139695434570313 and perplexity is 170.66378211699188
At time: 1221.7789545059204 and batch: 400, loss is 5.164009523391724 and perplexity is 174.86417389488633
At time: 1222.8489146232605 and batch: 450, loss is 5.132663726806641 and perplexity is 169.46793363122435
At time: 1223.918585062027 and batch: 500, loss is 5.171228065490722 and perplexity is 176.13100513213226
At time: 1224.9887070655823 and batch: 550, loss is 5.150794839859008 and perplexity is 172.5686002212964
At time: 1226.0584976673126 and batch: 600, loss is 5.110768413543701 and perplexity is 165.7977071415417
At time: 1227.1530592441559 and batch: 650, loss is 5.120966939926148 and perplexity is 167.49725112327837
At time: 1228.2228198051453 and batch: 700, loss is 5.135482063293457 and perplexity is 169.94622496829618
At time: 1229.293800830841 and batch: 750, loss is 5.120178899765015 and perplexity is 167.3653085573624
At time: 1230.363759279251 and batch: 800, loss is 5.093253116607666 and perplexity is 162.91899541026615
At time: 1231.4357244968414 and batch: 850, loss is 5.067253818511963 and perplexity is 158.73780541073765
At time: 1232.5065433979034 and batch: 900, loss is 5.087809600830078 and perplexity is 162.03455271114777
At time: 1233.577717781067 and batch: 950, loss is 5.080399827957153 and perplexity is 160.83835074352822
At time: 1234.648143529892 and batch: 1000, loss is 5.107791566848755 and perplexity is 165.30488667442933
At time: 1235.7252542972565 and batch: 1050, loss is 5.070787553787231 and perplexity is 159.29973506380702
At time: 1236.7974643707275 and batch: 1100, loss is 5.056518392562866 and perplexity is 157.04280202606316
At time: 1237.8676612377167 and batch: 1150, loss is 5.069124460220337 and perplexity is 159.03502487913008
At time: 1238.9389877319336 and batch: 1200, loss is 5.029773530960083 and perplexity is 152.8983820245933
At time: 1240.01464676857 and batch: 1250, loss is 5.058578081130982 and perplexity is 157.36659463159583
At time: 1241.085501909256 and batch: 1300, loss is 5.0310684299469 and perplexity is 153.09649822711503
At time: 1242.1549038887024 and batch: 1350, loss is 5.022688474655151 and perplexity is 151.81891693008373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153740641276042 and perplexity of 173.07770253737087
Finished 40 epochs...
Completing Train Step...
At time: 1245.3185412883759 and batch: 50, loss is 5.150944061279297 and perplexity is 172.59435307430954
At time: 1246.391098022461 and batch: 100, loss is 5.148408765792847 and perplexity is 172.15732961586303
At time: 1247.4656364917755 and batch: 150, loss is 5.135165367126465 and perplexity is 169.89241217185688
At time: 1248.5359361171722 and batch: 200, loss is 5.1222696876525875 and perplexity is 167.715599982223
At time: 1249.606219291687 and batch: 250, loss is 5.12433970451355 and perplexity is 168.06313367824023
At time: 1250.6778857707977 and batch: 300, loss is 5.135899639129638 and perplexity is 170.01720522408155
At time: 1251.748869419098 and batch: 350, loss is 5.139200687408447 and perplexity is 170.57936757880475
At time: 1252.8195469379425 and batch: 400, loss is 5.163581247329712 and perplexity is 174.7892997896416
At time: 1253.8896930217743 and batch: 450, loss is 5.132245426177978 and perplexity is 169.39705991234234
At time: 1254.9851925373077 and batch: 500, loss is 5.170728359222412 and perplexity is 176.0430133516771
At time: 1256.0561361312866 and batch: 550, loss is 5.150436677932739 and perplexity is 172.5068037862533
At time: 1257.1271967887878 and batch: 600, loss is 5.1105153465271 and perplexity is 165.75575451907252
At time: 1258.1970055103302 and batch: 650, loss is 5.120745286941529 and perplexity is 167.46012897192122
At time: 1259.267158985138 and batch: 700, loss is 5.135309743881225 and perplexity is 169.91694245774357
At time: 1260.3368380069733 and batch: 750, loss is 5.120022039413453 and perplexity is 167.33905763514107
At time: 1261.4075169563293 and batch: 800, loss is 5.093186883926392 and perplexity is 162.9082052057056
At time: 1262.4771962165833 and batch: 850, loss is 5.067154359817505 and perplexity is 158.72201834094403
At time: 1263.5489625930786 and batch: 900, loss is 5.087750635147095 and perplexity is 162.02499851476787
At time: 1264.619048833847 and batch: 950, loss is 5.080226974487305 and perplexity is 160.81055167916904
At time: 1265.6895639896393 and batch: 1000, loss is 5.107709579467773 and perplexity is 165.29133431527615
At time: 1266.7672500610352 and batch: 1050, loss is 5.070799226760864 and perplexity is 159.30159457626715
At time: 1267.837725162506 and batch: 1100, loss is 5.056533994674683 and perplexity is 157.0452522445346
At time: 1268.9093971252441 and batch: 1150, loss is 5.0691930770874025 and perplexity is 159.04593773868982
At time: 1269.9814667701721 and batch: 1200, loss is 5.02992844581604 and perplexity is 152.92207009019
At time: 1271.0527532100677 and batch: 1250, loss is 5.058756132125854 and perplexity is 157.39461640490794
At time: 1272.1245152950287 and batch: 1300, loss is 5.031183109283448 and perplexity is 153.11405623871084
At time: 1273.1960632801056 and batch: 1350, loss is 5.022609233856201 and perplexity is 151.80688715444126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153697102864584 and perplexity of 173.07016717318362
Finished 41 epochs...
Completing Train Step...
At time: 1276.3569240570068 and batch: 50, loss is 5.150459613800049 and perplexity is 172.5107604247892
At time: 1277.4580776691437 and batch: 100, loss is 5.147893486022949 and perplexity is 172.06864327777257
At time: 1278.5315670967102 and batch: 150, loss is 5.134597816467285 and perplexity is 169.79601697850435
At time: 1279.6031370162964 and batch: 200, loss is 5.121765117645264 and perplexity is 167.63099706655353
At time: 1280.6752018928528 and batch: 250, loss is 5.123892936706543 and perplexity is 167.98806525089515
At time: 1281.7722806930542 and batch: 300, loss is 5.135390748977661 and perplexity is 169.9307071535512
At time: 1282.8438749313354 and batch: 350, loss is 5.138757572174073 and perplexity is 170.50379800661145
At time: 1283.9221222400665 and batch: 400, loss is 5.1631818294525145 and perplexity is 174.71949975918074
At time: 1284.9938991069794 and batch: 450, loss is 5.131848154067993 and perplexity is 169.32977655071204
At time: 1286.06587600708 and batch: 500, loss is 5.170263423919677 and perplexity is 175.96118376417616
At time: 1287.136059999466 and batch: 550, loss is 5.150083179473877 and perplexity is 172.44583367402686
At time: 1288.2069876194 and batch: 600, loss is 5.110279960632324 and perplexity is 165.71674254409527
At time: 1289.2777814865112 and batch: 650, loss is 5.120543746948242 and perplexity is 167.4263824594027
At time: 1290.348300933838 and batch: 700, loss is 5.1351229858398435 and perplexity is 169.88521206541776
At time: 1291.4235754013062 and batch: 750, loss is 5.1198592853546145 and perplexity is 167.311824740501
At time: 1292.4959659576416 and batch: 800, loss is 5.093118953704834 and perplexity is 162.89713919109502
At time: 1293.5655789375305 and batch: 850, loss is 5.067015371322632 and perplexity is 158.6999593395208
At time: 1294.6359016895294 and batch: 900, loss is 5.087644805908203 and perplexity is 162.0078524397877
At time: 1295.7055575847626 and batch: 950, loss is 5.080006704330445 and perplexity is 160.7751338146184
At time: 1296.7754080295563 and batch: 1000, loss is 5.107596092224121 and perplexity is 165.27257692172768
At time: 1297.8464488983154 and batch: 1050, loss is 5.070779848098755 and perplexity is 159.2985075544036
At time: 1298.9181184768677 and batch: 1100, loss is 5.056543397903442 and perplexity is 157.04672898391004
At time: 1299.991173028946 and batch: 1150, loss is 5.069187831878662 and perplexity is 159.04510351173494
At time: 1301.0681364536285 and batch: 1200, loss is 5.030031681060791 and perplexity is 152.93785785243634
At time: 1302.1382503509521 and batch: 1250, loss is 5.058892612457275 and perplexity is 157.4160991402709
At time: 1303.2093000411987 and batch: 1300, loss is 5.031212863922119 and perplexity is 153.11861215990928
At time: 1304.281429052353 and batch: 1350, loss is 5.022506694793702 and perplexity is 151.79132181659267
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153663330078125 and perplexity of 173.06432221008615
Finished 42 epochs...
Completing Train Step...
At time: 1307.4490954875946 and batch: 50, loss is 5.149967269897461 and perplexity is 172.4258467088537
At time: 1308.5452182292938 and batch: 100, loss is 5.147398118972778 and perplexity is 171.98342724987396
At time: 1309.616529226303 and batch: 150, loss is 5.134063730239868 and perplexity is 169.70535547705057
At time: 1310.6882388591766 and batch: 200, loss is 5.121292772293091 and perplexity is 167.55183604135203
At time: 1311.7591428756714 and batch: 250, loss is 5.123439054489136 and perplexity is 167.91183575625587
At time: 1312.830369234085 and batch: 300, loss is 5.134920234680176 and perplexity is 169.85077113324857
At time: 1313.9015963077545 and batch: 350, loss is 5.138354425430298 and perplexity is 170.43507380954276
At time: 1314.973351240158 and batch: 400, loss is 5.1628265380859375 and perplexity is 174.6574344556298
At time: 1316.0447833538055 and batch: 450, loss is 5.131468200683594 and perplexity is 169.26545135009482
At time: 1317.121506690979 and batch: 500, loss is 5.1698173141479495 and perplexity is 175.88270326741397
At time: 1318.1933314800262 and batch: 550, loss is 5.14977879524231 and perplexity is 172.39335186917913
At time: 1319.2649283409119 and batch: 600, loss is 5.110052518844604 and perplexity is 165.6790559178352
At time: 1320.3366491794586 and batch: 650, loss is 5.1203539848327635 and perplexity is 167.39461428917315
At time: 1321.4081518650055 and batch: 700, loss is 5.134942541122436 and perplexity is 169.854559941925
At time: 1322.4796822071075 and batch: 750, loss is 5.119684886932373 and perplexity is 167.28264836647472
At time: 1323.5506439208984 and batch: 800, loss is 5.093055505752563 and perplexity is 162.88680402905848
At time: 1324.6224715709686 and batch: 850, loss is 5.066967315673828 and perplexity is 158.69233309325324
At time: 1325.6950330734253 and batch: 900, loss is 5.087555885314941 and perplexity is 161.99344724590435
At time: 1326.769207239151 and batch: 950, loss is 5.079839677810669 and perplexity is 160.74828234606693
At time: 1327.8415703773499 and batch: 1000, loss is 5.107486505508422 and perplexity is 165.25446623519127
At time: 1328.919869184494 and batch: 1050, loss is 5.070758934020996 and perplexity is 159.29517600786804
At time: 1329.991243839264 and batch: 1100, loss is 5.056519832611084 and perplexity is 157.0430281754331
At time: 1331.0624113082886 and batch: 1150, loss is 5.069174518585205 and perplexity is 159.0429861116938
At time: 1332.1336388587952 and batch: 1200, loss is 5.030114965438843 and perplexity is 152.95059571723337
At time: 1333.2055368423462 and batch: 1250, loss is 5.058987836837769 and perplexity is 157.4310897045135
At time: 1334.2773275375366 and batch: 1300, loss is 5.031263246536255 and perplexity is 153.12632687020474
At time: 1335.3488972187042 and batch: 1350, loss is 5.022394456863403 and perplexity is 151.77428602884342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153645426432291 and perplexity of 173.0612237554918
Finished 43 epochs...
Completing Train Step...
At time: 1338.5318517684937 and batch: 50, loss is 5.149526243209839 and perplexity is 172.34981907515927
At time: 1339.6033749580383 and batch: 100, loss is 5.146937322616577 and perplexity is 171.90419616936882
At time: 1340.6754350662231 and batch: 150, loss is 5.133578062057495 and perplexity is 169.6229549967825
At time: 1341.747311115265 and batch: 200, loss is 5.120843553543091 and perplexity is 167.47658551824372
At time: 1342.8202095031738 and batch: 250, loss is 5.123040838241577 and perplexity is 167.84498384674194
At time: 1343.8923680782318 and batch: 300, loss is 5.13447943687439 and perplexity is 169.77591778482983
At time: 1344.964593887329 and batch: 350, loss is 5.138004274368286 and perplexity is 170.3754062343863
At time: 1346.0363569259644 and batch: 400, loss is 5.162487306594849 and perplexity is 174.5981952021879
At time: 1347.1083798408508 and batch: 450, loss is 5.131106986999511 and perplexity is 169.20432139397772
At time: 1348.1857669353485 and batch: 500, loss is 5.16942099571228 and perplexity is 175.81301152056798
At time: 1349.2588319778442 and batch: 550, loss is 5.14948278427124 and perplexity is 172.34232909770896
At time: 1350.3315923213959 and batch: 600, loss is 5.109822826385498 and perplexity is 165.64100505822412
At time: 1351.4040207862854 and batch: 650, loss is 5.120156993865967 and perplexity is 167.36164230996545
At time: 1352.4835965633392 and batch: 700, loss is 5.134756622314453 and perplexity is 169.82298372000776
At time: 1353.5620834827423 and batch: 750, loss is 5.119514770507813 and perplexity is 167.25419326085265
At time: 1354.6390523910522 and batch: 800, loss is 5.092974634170532 and perplexity is 162.87363164816747
At time: 1355.7123217582703 and batch: 850, loss is 5.066863927841187 and perplexity is 158.6759270849833
At time: 1356.782853603363 and batch: 900, loss is 5.087466382980347 and perplexity is 161.97894910300536
At time: 1357.8531017303467 and batch: 950, loss is 5.0796495532989505 and perplexity is 160.71772306250284
At time: 1358.9234149456024 and batch: 1000, loss is 5.107375259399414 and perplexity is 165.23608334135804
At time: 1359.993979692459 and batch: 1050, loss is 5.070727033615112 and perplexity is 159.2900945081494
At time: 1361.064879655838 and batch: 1100, loss is 5.056485862731933 and perplexity is 157.03769353335366
At time: 1362.135337114334 and batch: 1150, loss is 5.069110612869263 and perplexity is 159.0328226805549
At time: 1363.2313215732574 and batch: 1200, loss is 5.030184049606323 and perplexity is 152.96116254680015
At time: 1364.3014078140259 and batch: 1250, loss is 5.059061975479126 and perplexity is 157.44276186428522
At time: 1365.3720755577087 and batch: 1300, loss is 5.0312888813018795 and perplexity is 153.13025227801828
At time: 1366.442366361618 and batch: 1350, loss is 5.022278528213501 and perplexity is 151.75669206061644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153623860677083 and perplexity of 173.05749159974778
Finished 44 epochs...
Completing Train Step...
At time: 1369.6026940345764 and batch: 50, loss is 5.149105339050293 and perplexity is 172.2772915840457
At time: 1370.6731116771698 and batch: 100, loss is 5.146493244171142 and perplexity is 171.8278741689021
At time: 1371.7436773777008 and batch: 150, loss is 5.133116331100464 and perplexity is 169.5446529060781
At time: 1372.8146862983704 and batch: 200, loss is 5.120405797958374 and perplexity is 167.40328775204748
At time: 1373.886042356491 and batch: 250, loss is 5.122659387588501 and perplexity is 167.7809714775943
At time: 1374.9560115337372 and batch: 300, loss is 5.134066162109375 and perplexity is 169.70576817883148
At time: 1376.0267820358276 and batch: 350, loss is 5.137670869827271 and perplexity is 170.31861176856296
At time: 1377.0975325107574 and batch: 400, loss is 5.162158203125 and perplexity is 174.54074378456656
At time: 1378.1677000522614 and batch: 450, loss is 5.130777940750122 and perplexity is 169.1486545056353
At time: 1379.2381837368011 and batch: 500, loss is 5.168989877700806 and perplexity is 175.73723170084625
At time: 1380.3089227676392 and batch: 550, loss is 5.149185266494751 and perplexity is 172.2910618180026
At time: 1381.3855826854706 and batch: 600, loss is 5.109583187103271 and perplexity is 165.60131572241656
At time: 1382.457273721695 and batch: 650, loss is 5.119952087402344 and perplexity is 167.32735234093164
At time: 1383.5283069610596 and batch: 700, loss is 5.134575223922729 and perplexity is 169.7921808977589
At time: 1384.5993657112122 and batch: 750, loss is 5.1193255519866945 and perplexity is 167.22254866371932
At time: 1385.6724631786346 and batch: 800, loss is 5.092893857955932 and perplexity is 162.86047586408918
At time: 1386.7470252513885 and batch: 850, loss is 5.066742839813233 and perplexity is 158.65671449311975
At time: 1387.8175513744354 and batch: 900, loss is 5.087361240386963 and perplexity is 161.96191911152752
At time: 1388.8881199359894 and batch: 950, loss is 5.079444971084595 and perplexity is 160.68484643793346
At time: 1389.9828708171844 and batch: 1000, loss is 5.107247581481934 and perplexity is 165.21498768909754
At time: 1391.0527892112732 and batch: 1050, loss is 5.070680332183838 and perplexity is 159.28265560645312
At time: 1392.1237215995789 and batch: 1100, loss is 5.056450328826904 and perplexity is 157.03211347000695
At time: 1393.1947553157806 and batch: 1150, loss is 5.068991470336914 and perplexity is 159.01387623602017
At time: 1394.2651484012604 and batch: 1200, loss is 5.030189256668091 and perplexity is 152.96195902709536
At time: 1395.335019826889 and batch: 1250, loss is 5.0591163825988765 and perplexity is 157.45132810451398
At time: 1396.4055438041687 and batch: 1300, loss is 5.031288108825684 and perplexity is 153.13013398858922
At time: 1397.475477695465 and batch: 1350, loss is 5.022145595550537 and perplexity is 151.73651998021205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.153610432942708 and perplexity of 173.05516784532037
Finished 45 epochs...
Completing Train Step...
At time: 1400.6069066524506 and batch: 50, loss is 5.148707675933838 and perplexity is 172.2087968791914
At time: 1401.702537059784 and batch: 100, loss is 5.146057739257812 and perplexity is 171.75305857791568
At time: 1402.7742476463318 and batch: 150, loss is 5.1326789379119875 and perplexity is 169.47051144542138
At time: 1403.8454580307007 and batch: 200, loss is 5.120009841918946 and perplexity is 167.337016530353
At time: 1404.9167137145996 and batch: 250, loss is 5.122299308776856 and perplexity is 167.72056798043025
At time: 1405.9874930381775 and batch: 300, loss is 5.1336705780029295 and perplexity is 169.6386485507722
At time: 1407.0584523677826 and batch: 350, loss is 5.13734450340271 and perplexity is 170.2630345619644
At time: 1408.129712343216 and batch: 400, loss is 5.161846055984497 and perplexity is 174.48626989286993
At time: 1409.2007880210876 and batch: 450, loss is 5.130455141067505 and perplexity is 169.09406218531157
At time: 1410.2719638347626 and batch: 500, loss is 5.168584251403809 and perplexity is 175.66596251361236
At time: 1411.3422524929047 and batch: 550, loss is 5.148893823623657 and perplexity is 172.24085613268252
At time: 1412.41264128685 and batch: 600, loss is 5.109335441589355 and perplexity is 165.56029382105353
At time: 1413.4833731651306 and batch: 650, loss is 5.119767932891846 and perplexity is 167.29654109137078
At time: 1414.5560266971588 and batch: 700, loss is 5.134398450851441 and perplexity is 169.7621688651986
At time: 1415.627340555191 and batch: 750, loss is 5.119137725830078 and perplexity is 167.1911428446137
At time: 1416.7231855392456 and batch: 800, loss is 5.092802362442017 and perplexity is 162.84557554282014
At time: 1417.79438829422 and batch: 850, loss is 5.066609954833984 and perplexity is 158.63563279965786
At time: 1418.8657395839691 and batch: 900, loss is 5.087244596481323 and perplexity is 161.94302834248532
At time: 1419.9360928535461 and batch: 950, loss is 5.079263916015625 and perplexity is 160.65575626552038
At time: 1421.0070478916168 and batch: 1000, loss is 5.1071116161346435 and perplexity is 165.19252570297928
At time: 1422.0840163230896 and batch: 1050, loss is 5.070617218017578 and perplexity is 159.2726029316812
At time: 1423.1545810699463 and batch: 1100, loss is 5.056385316848755 and perplexity is 157.0219048335227
At time: 1424.2251019477844 and batch: 1150, loss is 5.068918333053589 and perplexity is 159.00224681837855
At time: 1425.2957048416138 and batch: 1200, loss is 5.030218076705933 and perplexity is 152.96636746006814
At time: 1426.3659105300903 and batch: 1250, loss is 5.059158239364624 and perplexity is 157.4579186457995
At time: 1427.4368014335632 and batch: 1300, loss is 5.031282758712768 and perplexity is 153.1293147272732
At time: 1428.5070729255676 and batch: 1350, loss is 5.022009658813476 and perplexity is 151.71589481468362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15361572265625 and perplexity of 173.05608326000635
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 1431.6378514766693 and batch: 50, loss is 5.148694190979004 and perplexity is 172.20647466700103
At time: 1432.7325901985168 and batch: 100, loss is 5.146168012619018 and perplexity is 171.77199940929785
At time: 1433.8026461601257 and batch: 150, loss is 5.13299786567688 and perplexity is 169.5245689166079
At time: 1434.8737721443176 and batch: 200, loss is 5.120562467575073 and perplexity is 167.42951681556883
At time: 1435.9431574344635 and batch: 250, loss is 5.122449712753296 and perplexity is 167.7457957179138
At time: 1437.015293598175 and batch: 300, loss is 5.133980932235718 and perplexity is 169.69130479401582
At time: 1438.0864233970642 and batch: 350, loss is 5.13743480682373 and perplexity is 170.27841059070212
At time: 1439.1572165489197 and batch: 400, loss is 5.162628450393677 and perplexity is 174.62284039394436
At time: 1440.2278609275818 and batch: 450, loss is 5.130551052093506 and perplexity is 169.11028094807313
At time: 1441.2983708381653 and batch: 500, loss is 5.168256072998047 and perplexity is 175.608322196759
At time: 1442.3690254688263 and batch: 550, loss is 5.1478093814849855 and perplexity is 172.0541721325847
At time: 1443.446055173874 and batch: 600, loss is 5.1077713203430175 and perplexity is 165.30153986197354
At time: 1444.5455009937286 and batch: 650, loss is 5.118296594619751 and perplexity is 167.05057228370765
At time: 1445.6164548397064 and batch: 700, loss is 5.132463169097901 and perplexity is 169.43394893881032
At time: 1446.688903093338 and batch: 750, loss is 5.117363929748535 and perplexity is 166.8948427162593
At time: 1447.759164094925 and batch: 800, loss is 5.091161336898804 and perplexity is 162.5785609425666
At time: 1448.830417394638 and batch: 850, loss is 5.064054155349732 and perplexity is 158.2307096028302
At time: 1449.9017798900604 and batch: 900, loss is 5.083993062973023 and perplexity is 161.4173203012193
At time: 1450.9726166725159 and batch: 950, loss is 5.076128845214844 and perplexity is 160.15287778677782
At time: 1452.0510966777802 and batch: 1000, loss is 5.103827323913574 and perplexity is 164.6508751320919
At time: 1453.1214616298676 and batch: 1050, loss is 5.0670300960540775 and perplexity is 158.70229617100708
At time: 1454.1920585632324 and batch: 1100, loss is 5.052647218704224 and perplexity is 156.43603723990842
At time: 1455.2622265815735 and batch: 1150, loss is 5.0650664329528805 and perplexity is 158.39096410362797
At time: 1456.3312683105469 and batch: 1200, loss is 5.026127223968506 and perplexity is 152.34188278533006
At time: 1457.4013969898224 and batch: 1250, loss is 5.054976148605347 and perplexity is 156.80079038203337
At time: 1458.4711375236511 and batch: 1300, loss is 5.026797962188721 and perplexity is 152.4440985848433
At time: 1459.541431427002 and batch: 1350, loss is 5.01839129447937 and perplexity is 151.16792340992495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.152845052083333 and perplexity of 172.9227654078449
Finished 47 epochs...
Completing Train Step...
At time: 1462.6927869319916 and batch: 50, loss is 5.148177633285522 and perplexity is 172.1175430587751
At time: 1463.7629926204681 and batch: 100, loss is 5.145712270736694 and perplexity is 171.69373355082598
At time: 1464.836885690689 and batch: 150, loss is 5.132386083602905 and perplexity is 169.4208885423774
At time: 1465.9082086086273 and batch: 200, loss is 5.120026788711548 and perplexity is 167.339852380096
At time: 1466.9785096645355 and batch: 250, loss is 5.1219589805603025 and perplexity is 167.66349765052286
At time: 1468.0480544567108 and batch: 300, loss is 5.133438053131104 and perplexity is 169.59920793140145
At time: 1469.1184136867523 and batch: 350, loss is 5.136855478286743 and perplexity is 170.1797920172493
At time: 1470.1886653900146 and batch: 400, loss is 5.162085905075073 and perplexity is 174.52812528531004
At time: 1471.2849614620209 and batch: 450, loss is 5.13004768371582 and perplexity is 169.02517760126608
At time: 1472.3537533283234 and batch: 500, loss is 5.16779727935791 and perplexity is 175.52777269459258
At time: 1473.4250161647797 and batch: 550, loss is 5.1475258064270015 and perplexity is 172.00538877794406
At time: 1474.495136499405 and batch: 600, loss is 5.107532510757446 and perplexity is 165.2620689829445
At time: 1475.5654933452606 and batch: 650, loss is 5.117885475158691 and perplexity is 166.98190865790423
At time: 1476.634557723999 and batch: 700, loss is 5.132226543426514 and perplexity is 169.39386125996094
At time: 1477.7099845409393 and batch: 750, loss is 5.1171660995483395 and perplexity is 166.8618291417618
At time: 1478.7816789150238 and batch: 800, loss is 5.091011123657227 and perplexity is 162.55414132403746
At time: 1479.8520159721375 and batch: 850, loss is 5.0639018630981445 and perplexity is 158.20661412661826
At time: 1480.9229962825775 and batch: 900, loss is 5.0839404296875 and perplexity is 161.40882460089182
At time: 1481.99475979805 and batch: 950, loss is 5.076038084030151 and perplexity is 160.13834278147513
At time: 1483.0650470256805 and batch: 1000, loss is 5.103727998733521 and perplexity is 164.6345219664275
At time: 1484.1340188980103 and batch: 1050, loss is 5.066915531158447 and perplexity is 158.68411550046312
At time: 1485.2023804187775 and batch: 1100, loss is 5.052647981643677 and perplexity is 156.43615659117862
At time: 1486.2673416137695 and batch: 1150, loss is 5.065320386886596 and perplexity is 158.4311932199821
At time: 1487.3371307849884 and batch: 1200, loss is 5.026312160491943 and perplexity is 152.3700589688287
At time: 1488.4070069789886 and batch: 1250, loss is 5.055220489501953 and perplexity is 156.8391079088227
At time: 1489.4761662483215 and batch: 1300, loss is 5.026856937408447 and perplexity is 152.45308927416465
At time: 1490.54483294487 and batch: 1350, loss is 5.018564519882202 and perplexity is 151.19411180253482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1527006022135415 and perplexity of 172.89778854089374
Finished 48 epochs...
Completing Train Step...
At time: 1493.6961922645569 and batch: 50, loss is 5.147881517410278 and perplexity is 172.06658386715256
At time: 1494.765777349472 and batch: 100, loss is 5.1453775215148925 and perplexity is 171.63626882580422
At time: 1495.841911315918 and batch: 150, loss is 5.131996421813965 and perplexity is 169.35488455631491
At time: 1496.9114191532135 and batch: 200, loss is 5.119684886932373 and perplexity is 167.28264836647472
At time: 1498.005969285965 and batch: 250, loss is 5.121686515808105 and perplexity is 167.61782148003874
At time: 1499.0760672092438 and batch: 300, loss is 5.133261575698852 and perplexity is 169.5692801395414
At time: 1500.1463441848755 and batch: 350, loss is 5.136642532348633 and perplexity is 170.14355678000098
At time: 1501.2158575057983 and batch: 400, loss is 5.1618233489990235 and perplexity is 174.48230788065706
At time: 1502.2862136363983 and batch: 450, loss is 5.129829196929932 and perplexity is 168.9882518675171
At time: 1503.3534326553345 and batch: 500, loss is 5.167622623443603 and perplexity is 175.49711840802047
At time: 1504.4225089550018 and batch: 550, loss is 5.147404546737671 and perplexity is 171.98453272246263
At time: 1505.492873430252 and batch: 600, loss is 5.107527332305908 and perplexity is 165.2612131835451
At time: 1506.569097518921 and batch: 650, loss is 5.117988538742066 and perplexity is 166.99911929864913
At time: 1507.6398854255676 and batch: 700, loss is 5.13208044052124 and perplexity is 169.369114132553
At time: 1508.710921049118 and batch: 750, loss is 5.1170533180236815 and perplexity is 166.84301127143797
At time: 1509.7803881168365 and batch: 800, loss is 5.090934457778931 and perplexity is 162.5416794457288
At time: 1510.85098862648 and batch: 850, loss is 5.063883066177368 and perplexity is 158.20364035737518
At time: 1511.9203209877014 and batch: 900, loss is 5.083920249938965 and perplexity is 161.4055674442644
At time: 1512.998479604721 and batch: 950, loss is 5.076022672653198 and perplexity is 160.13587484812703
At time: 1514.0661952495575 and batch: 1000, loss is 5.103801631927491 and perplexity is 164.64664497844015
At time: 1515.1341123580933 and batch: 1050, loss is 5.0670900058746335 and perplexity is 158.71180428190428
At time: 1516.2026615142822 and batch: 1100, loss is 5.052936305999756 and perplexity is 156.48126744826217
At time: 1517.2677450180054 and batch: 1150, loss is 5.0655037212371825 and perplexity is 158.46024176262017
At time: 1518.3371884822845 and batch: 1200, loss is 5.026496572494507 and perplexity is 152.39816042757738
At time: 1519.4071485996246 and batch: 1250, loss is 5.0553899669647215 and perplexity is 156.8656908554355
At time: 1520.4762716293335 and batch: 1300, loss is 5.026909818649292 and perplexity is 152.46115139586175
At time: 1521.5450985431671 and batch: 1350, loss is 5.018725881576538 and perplexity is 151.2185107090604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.152664388020833 and perplexity of 172.8915273004342
Finished 49 epochs...
Completing Train Step...
At time: 1524.6680655479431 and batch: 50, loss is 5.147705774307251 and perplexity is 172.03634700881403
At time: 1525.767352104187 and batch: 100, loss is 5.145125217437744 and perplexity is 171.5929697578884
At time: 1526.8376803398132 and batch: 150, loss is 5.1317593955993654 and perplexity is 169.3147477660282
At time: 1527.9076795578003 and batch: 200, loss is 5.119412212371826 and perplexity is 167.23704086212996
At time: 1528.9855778217316 and batch: 250, loss is 5.121417589187622 and perplexity is 167.57275064642056
At time: 1530.0558712482452 and batch: 300, loss is 5.133012742996216 and perplexity is 169.5270910065158
At time: 1531.1268348693848 and batch: 350, loss is 5.136475229263306 and perplexity is 170.1150936190569
At time: 1532.1961560249329 and batch: 400, loss is 5.161698837280273 and perplexity is 174.46058414106943
At time: 1533.2661354541779 and batch: 450, loss is 5.129724788665771 and perplexity is 168.97060901852174
At time: 1534.3334259986877 and batch: 500, loss is 5.167536249160767 and perplexity is 175.48196062490888
At time: 1535.4026610851288 and batch: 550, loss is 5.147309579849243 and perplexity is 171.96820066204702
At time: 1536.4733765125275 and batch: 600, loss is 5.107373352050781 and perplexity is 165.23576817884094
At time: 1537.5431673526764 and batch: 650, loss is 5.117773714065552 and perplexity is 166.9632476200666
At time: 1538.61372590065 and batch: 700, loss is 5.131915674209595 and perplexity is 169.34121010719556
At time: 1539.6823410987854 and batch: 750, loss is 5.1169532203674315 and perplexity is 166.8263115128653
At time: 1540.7523310184479 and batch: 800, loss is 5.090930070877075 and perplexity is 162.5409663928976
At time: 1541.8230402469635 and batch: 850, loss is 5.063863515853882 and perplexity is 158.20054745526318
At time: 1542.8936643600464 and batch: 900, loss is 5.083851041793824 and perplexity is 161.39439725086478
At time: 1543.9622857570648 and batch: 950, loss is 5.076010370254517 and perplexity is 160.13390480486964
At time: 1545.0315811634064 and batch: 1000, loss is 5.103851871490479 and perplexity is 164.65491696171998
At time: 1546.1062049865723 and batch: 1050, loss is 5.0671399879455565 and perplexity is 158.71973722481303
At time: 1547.1804893016815 and batch: 1100, loss is 5.053137121200561 and perplexity is 156.51269442080832
At time: 1548.2461211681366 and batch: 1150, loss is 5.0656470108032225 and perplexity is 158.48294908871952
At time: 1549.3141162395477 and batch: 1200, loss is 5.026637411117553 and perplexity is 152.41962548616598
At time: 1550.383174419403 and batch: 1250, loss is 5.055524702072144 and perplexity is 156.88682759504223
At time: 1551.4520518779755 and batch: 1300, loss is 5.026955804824829 and perplexity is 152.4681626623418
At time: 1552.5209481716156 and batch: 1350, loss is 5.018861436843872 and perplexity is 151.2390105641058
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.152637939453125 and perplexity of 172.88695462763891
Finished Training.
Improved accuracyfrom -173.42602495371904 to -172.88695462763891
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1fcab0630>
SETTINGS FOR THIS RUN
{'dropout': 0.7815882339172517, 'data': 'wikitext', 'wordvec_source': '', 'lr': 21.625570823395684, 'wordvec_dim': 200, 'anneal': 2.8742957455685825, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5307385921478271 and batch: 50, loss is 7.4618181800842285 and perplexity is 1740.3093784046873
At time: 2.600144386291504 and batch: 100, loss is 6.868643064498901 and perplexity is 961.6427928425372
At time: 3.6697959899902344 and batch: 150, loss is 6.712876758575439 and perplexity is 822.9346217472855
At time: 4.739517688751221 and batch: 200, loss is 6.655168905258178 and perplexity is 776.7891157729835
At time: 5.813645124435425 and batch: 250, loss is 6.638986377716065 and perplexity is 764.3198685938466
At time: 6.883573293685913 and batch: 300, loss is 6.638847208023071 and perplexity is 764.2135058337934
At time: 7.953051805496216 and batch: 350, loss is 6.6255380725860595 and perplexity is 754.1098692559224
At time: 9.02276873588562 and batch: 400, loss is 6.650202112197876 and perplexity is 772.9405304585963
At time: 10.092222929000854 and batch: 450, loss is 6.598953475952149 and perplexity is 734.3262968513349
At time: 11.170065641403198 and batch: 500, loss is 6.574978799819946 and perplexity is 716.9304251368276
At time: 12.244728326797485 and batch: 550, loss is 6.531602659225464 and perplexity is 686.4975519573361
At time: 13.31650424003601 and batch: 600, loss is 6.46785493850708 and perplexity is 644.1006086453103
At time: 14.385830879211426 and batch: 650, loss is 6.497636842727661 and perplexity is 663.571654540787
At time: 15.460001945495605 and batch: 700, loss is 6.497229089736939 and perplexity is 663.301136370134
At time: 16.535401344299316 and batch: 750, loss is 6.469102001190185 and perplexity is 644.9043435282454
At time: 17.61890149116516 and batch: 800, loss is 6.431933879852295 and perplexity is 621.3744503551937
At time: 18.69421887397766 and batch: 850, loss is 6.419707975387573 and perplexity is 613.8238362821658
At time: 19.769294261932373 and batch: 900, loss is 6.456402482986451 and perplexity is 636.766153996449
At time: 20.84471297264099 and batch: 950, loss is 6.438082971572876 and perplexity is 625.2071104560102
At time: 21.919967889785767 and batch: 1000, loss is 6.45083137512207 and perplexity is 633.2285244758208
At time: 22.99613380432129 and batch: 1050, loss is 6.435018863677978 and perplexity is 623.2943403764111
At time: 24.073836088180542 and batch: 1100, loss is 6.433467235565185 and perplexity is 622.3279692735059
At time: 25.15027403831482 and batch: 1150, loss is 6.426686601638794 and perplexity is 618.1224652364082
At time: 26.22641897201538 and batch: 1200, loss is 6.392767906188965 and perplexity is 597.5081394294604
At time: 27.306381702423096 and batch: 1250, loss is 6.398755779266358 and perplexity is 601.0966754580818
At time: 28.39141058921814 and batch: 1300, loss is 6.35473331451416 and perplexity is 575.2089203325008
At time: 29.476826906204224 and batch: 1350, loss is 6.349466466903687 and perplexity is 572.1873466737153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.716982828776041 and perplexity of 303.98635902648067
Finished 1 epochs...
Completing Train Step...
At time: 32.69782567024231 and batch: 50, loss is 6.133636569976806 and perplexity is 461.1099740532207
At time: 33.77616214752197 and batch: 100, loss is 6.10304783821106 and perplexity is 447.21874539360687
At time: 34.846097230911255 and batch: 150, loss is 6.0424869346618655 and perplexity is 420.93858099295824
At time: 35.91683840751648 and batch: 200, loss is 5.98310791015625 and perplexity is 396.6712730718644
At time: 36.98701357841492 and batch: 250, loss is 5.975260524749756 and perplexity is 393.5706226237881
At time: 38.05810570716858 and batch: 300, loss is 5.944112491607666 and perplexity is 381.50062599743706
At time: 39.12845849990845 and batch: 350, loss is 5.924647350311279 and perplexity is 374.1464694567821
At time: 40.199931383132935 and batch: 400, loss is 5.966307878494263 and perplexity is 390.06284941814437
At time: 41.271252155303955 and batch: 450, loss is 5.949063415527344 and perplexity is 383.3940899022701
At time: 42.34295606613159 and batch: 500, loss is 5.9513192653656 and perplexity is 384.2599456510553
At time: 43.414525270462036 and batch: 550, loss is 5.9001484203338626 and perplexity is 365.09165086901197
At time: 44.48611521720886 and batch: 600, loss is 5.844774541854858 and perplexity is 345.4246541993938
At time: 45.55757975578308 and batch: 650, loss is 5.868328065872192 and perplexity is 353.6571941594648
At time: 46.629034996032715 and batch: 700, loss is 5.874798669815063 and perplexity is 355.9529893750439
At time: 47.70072817802429 and batch: 750, loss is 5.866139888763428 and perplexity is 352.8841756420095
At time: 48.7779803276062 and batch: 800, loss is 5.826040334701538 and perplexity is 339.0136373361438
At time: 49.85020565986633 and batch: 850, loss is 5.807782316207886 and perplexity is 332.88008373038224
At time: 50.921486139297485 and batch: 900, loss is 5.818965034484863 and perplexity is 336.623479587171
At time: 51.993138790130615 and batch: 950, loss is 5.81400710105896 and perplexity is 334.9586532451375
At time: 53.090572118759155 and batch: 1000, loss is 5.86031982421875 and perplexity is 350.83633203453707
At time: 54.16875195503235 and batch: 1050, loss is 5.8287812519073485 and perplexity is 339.9441202535108
At time: 55.240251779556274 and batch: 1100, loss is 5.826398210525513 and perplexity is 339.1349838331377
At time: 56.31416058540344 and batch: 1150, loss is 5.805821723937989 and perplexity is 332.2280809760516
At time: 57.39045214653015 and batch: 1200, loss is 5.804298486709595 and perplexity is 331.7224040255441
At time: 58.46174073219299 and batch: 1250, loss is 5.816963157653809 and perplexity is 335.95027490384837
At time: 59.53363227844238 and batch: 1300, loss is 5.792194118499756 and perplexity is 327.73131742428376
At time: 60.6047682762146 and batch: 1350, loss is 5.767293519973755 and perplexity is 319.67137659280775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.531765543619792 and perplexity of 252.58947531274302
Finished 2 epochs...
Completing Train Step...
At time: 63.74972581863403 and batch: 50, loss is 5.822657823562622 and perplexity is 337.8688571389827
At time: 64.84672427177429 and batch: 100, loss is 5.84045557975769 and perplexity is 343.93599525530624
At time: 65.91899561882019 and batch: 150, loss is 5.796921548843383 and perplexity is 329.2843123442158
At time: 66.99030780792236 and batch: 200, loss is 5.806692972183227 and perplexity is 332.51766023801525
At time: 68.06192946434021 and batch: 250, loss is 5.826998109817505 and perplexity is 339.33849170584017
At time: 69.1332745552063 and batch: 300, loss is 5.77783974647522 and perplexity is 323.06054338401964
At time: 70.20401668548584 and batch: 350, loss is 5.781900081634522 and perplexity is 324.3749441148531
At time: 71.27553796768188 and batch: 400, loss is 5.844575366973877 and perplexity is 345.3558611361582
At time: 72.34634065628052 and batch: 450, loss is 5.861944284439087 and perplexity is 351.4067148564478
At time: 73.41726875305176 and batch: 500, loss is 5.843704309463501 and perplexity is 345.05516729938796
At time: 74.48859024047852 and batch: 550, loss is 5.805340948104859 and perplexity is 332.06839213397524
At time: 75.56015276908875 and batch: 600, loss is 5.7937492084503175 and perplexity is 328.24136558509144
At time: 76.63163900375366 and batch: 650, loss is 5.808569355010986 and perplexity is 333.142176398078
At time: 77.70265412330627 and batch: 700, loss is 5.784338054656982 and perplexity is 325.1667262573417
At time: 78.77391076087952 and batch: 750, loss is 5.765707654953003 and perplexity is 319.1648227077411
At time: 79.84457063674927 and batch: 800, loss is 5.753492240905762 and perplexity is 315.28980788878573
At time: 80.96104955673218 and batch: 850, loss is 5.7453034973144534 and perplexity is 312.7185226609703
At time: 82.03191781044006 and batch: 900, loss is 5.804528217315674 and perplexity is 331.79861956865733
At time: 83.10360479354858 and batch: 950, loss is 5.7458766746520995 and perplexity is 312.8978172100992
At time: 84.17433428764343 and batch: 1000, loss is 5.804945850372315 and perplexity is 331.93721858008684
At time: 85.24564099311829 and batch: 1050, loss is 5.783729791641235 and perplexity is 324.9689995048396
At time: 86.31702280044556 and batch: 1100, loss is 5.779953155517578 and perplexity is 323.7440244407623
At time: 87.38779830932617 and batch: 1150, loss is 5.7721359920501705 and perplexity is 321.22313043759465
At time: 88.45858001708984 and batch: 1200, loss is 5.723910713195801 and perplexity is 306.09965326371776
At time: 89.5294885635376 and batch: 1250, loss is 5.734831304550171 and perplexity is 309.4607617332133
At time: 90.60066604614258 and batch: 1300, loss is 5.74987533569336 and perplexity is 314.15149436622363
At time: 91.6727385520935 and batch: 1350, loss is 5.695885210037232 and perplexity is 297.6401510547704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.498861897786458 and perplexity of 244.41360624624568
Finished 3 epochs...
Completing Train Step...
At time: 94.8710618019104 and batch: 50, loss is 5.733148107528686 and perplexity is 308.94031642966513
At time: 95.94257235527039 and batch: 100, loss is 5.818837728500366 and perplexity is 336.5806281313785
At time: 97.0142605304718 and batch: 150, loss is 5.74554256439209 and perplexity is 312.79329230142923
At time: 98.09022784233093 and batch: 200, loss is 5.749990158081054 and perplexity is 314.18756806189896
At time: 99.16166162490845 and batch: 250, loss is 5.781121091842651 and perplexity is 324.12235773852655
At time: 100.23288106918335 and batch: 300, loss is 5.781904859542847 and perplexity is 324.3764939523015
At time: 101.30553889274597 and batch: 350, loss is 5.749168787002564 and perplexity is 313.92960943465215
At time: 102.37714147567749 and batch: 400, loss is 5.816321907043457 and perplexity is 335.7349156420271
At time: 103.44892501831055 and batch: 450, loss is 5.772685441970825 and perplexity is 321.39967495787096
At time: 104.52514505386353 and batch: 500, loss is 5.768988723754883 and perplexity is 320.21374430113696
At time: 105.59719610214233 and batch: 550, loss is 5.765703725814819 and perplexity is 319.16356866751295
At time: 106.66898274421692 and batch: 600, loss is 5.750400686264038 and perplexity is 314.3165773925027
At time: 107.77035474777222 and batch: 650, loss is 5.78471420288086 and perplexity is 325.2890601502834
At time: 108.85215783119202 and batch: 700, loss is 5.775114679336548 and perplexity is 322.18138014692073
At time: 109.9260082244873 and batch: 750, loss is 5.718129386901856 and perplexity is 304.33509694250074
At time: 110.99608635902405 and batch: 800, loss is 5.677943305969238 and perplexity is 292.34754174079416
At time: 112.0663468837738 and batch: 850, loss is 5.688533554077148 and perplexity is 295.4600266456731
At time: 113.13578915596008 and batch: 900, loss is 5.776101894378662 and perplexity is 322.499599501313
At time: 114.20610356330872 and batch: 950, loss is 5.726732883453369 and perplexity is 306.9647387360809
At time: 115.27552342414856 and batch: 1000, loss is 5.705975742340088 and perplexity is 300.6587023964526
At time: 116.3451280593872 and batch: 1050, loss is 5.726412649154663 and perplexity is 306.86645383618213
At time: 117.41526699066162 and batch: 1100, loss is 5.725561208724976 and perplexity is 306.6052865308504
At time: 118.48521995544434 and batch: 1150, loss is 5.732541055679321 and perplexity is 308.752830551815
At time: 119.5548300743103 and batch: 1200, loss is 5.70425687789917 and perplexity is 300.14235473699534
At time: 120.63354110717773 and batch: 1250, loss is 5.7077657508850095 and perplexity is 301.19736600524965
At time: 121.70536398887634 and batch: 1300, loss is 5.712758436203003 and perplexity is 302.7049098868918
At time: 122.78329515457153 and batch: 1350, loss is 5.674296989440918 and perplexity is 291.28349117884073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.493550211588541 and perplexity of 243.1187997146614
Finished 4 epochs...
Completing Train Step...
At time: 125.9676616191864 and batch: 50, loss is 5.718589115142822 and perplexity is 304.4750405468312
At time: 127.04496502876282 and batch: 100, loss is 5.730610990524292 and perplexity is 308.15749217778654
At time: 128.11667442321777 and batch: 150, loss is 5.688174600601196 and perplexity is 295.35398927448387
At time: 129.18833565711975 and batch: 200, loss is 5.705816993713379 and perplexity is 300.61097702860764
At time: 130.26037693023682 and batch: 250, loss is 5.749857692718506 and perplexity is 314.1459518482017
At time: 131.33120012283325 and batch: 300, loss is 5.772944688796997 and perplexity is 321.4830076049318
At time: 132.40124702453613 and batch: 350, loss is 5.741722297668457 and perplexity is 311.6006181127659
At time: 133.47201442718506 and batch: 400, loss is 5.754545860290527 and perplexity is 315.6221784074596
At time: 134.54685807228088 and batch: 450, loss is 5.799814491271973 and perplexity is 330.2382921414505
At time: 135.6465756893158 and batch: 500, loss is 5.796424055099488 and perplexity is 329.12053620104274
At time: 136.7184419631958 and batch: 550, loss is 5.767318124771118 and perplexity is 319.6792421390163
At time: 137.79114365577698 and batch: 600, loss is 5.699497232437134 and perplexity is 298.7171778990631
At time: 138.86224937438965 and batch: 650, loss is 5.756838274002075 and perplexity is 316.34654497361197
At time: 139.93140530586243 and batch: 700, loss is 5.8033108901977535 and perplexity is 331.3949578553911
At time: 141.00197005271912 and batch: 750, loss is 5.767195701599121 and perplexity is 319.64010838765984
At time: 142.07163453102112 and batch: 800, loss is 5.723797969818115 and perplexity is 306.065144500254
At time: 143.14205288887024 and batch: 850, loss is 5.707392158508301 and perplexity is 301.0848619820567
At time: 144.21250939369202 and batch: 900, loss is 5.741207160949707 and perplexity is 311.4401425297721
At time: 145.28285098075867 and batch: 950, loss is 5.731432991027832 and perplexity is 308.4109019287289
At time: 146.35301613807678 and batch: 1000, loss is 5.764553661346436 and perplexity is 318.7967209772671
At time: 147.42298436164856 and batch: 1050, loss is 5.719359722137451 and perplexity is 304.7097615699822
At time: 148.4930408000946 and batch: 1100, loss is 5.694291734695435 and perplexity is 297.16624649123094
At time: 149.5623016357422 and batch: 1150, loss is 5.717798309326172 and perplexity is 304.23435509401327
At time: 150.63201570510864 and batch: 1200, loss is 5.690890588760376 and perplexity is 296.1572575519031
At time: 151.70115160942078 and batch: 1250, loss is 5.688454446792602 and perplexity is 295.4366545297378
At time: 152.77042865753174 and batch: 1300, loss is 5.670935697555542 and perplexity is 290.3060460031537
At time: 153.83975911140442 and batch: 1350, loss is 5.6514647006988525 and perplexity is 284.70817283361663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.554331868489584 and perplexity of 258.35429219961804
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 156.98392605781555 and batch: 50, loss is 5.688072452545166 and perplexity is 295.3238209794812
At time: 158.07949328422546 and batch: 100, loss is 5.683516626358032 and perplexity is 293.9814371377339
At time: 159.14897298812866 and batch: 150, loss is 5.618598346710205 and perplexity is 275.502952857123
At time: 160.2181568145752 and batch: 200, loss is 5.60285647392273 and perplexity is 271.1999777226807
At time: 161.28756523132324 and batch: 250, loss is 5.6289222240448 and perplexity is 278.3619440919992
At time: 162.38320207595825 and batch: 300, loss is 5.635333652496338 and perplexity is 280.1523752576545
At time: 163.45300102233887 and batch: 350, loss is 5.624941339492798 and perplexity is 277.25602006733607
At time: 164.5234513282776 and batch: 400, loss is 5.659835376739502 and perplexity is 287.10137510103715
At time: 165.59286618232727 and batch: 450, loss is 5.622822198867798 and perplexity is 276.66909767687
At time: 166.66253542900085 and batch: 500, loss is 5.611188707351684 and perplexity is 273.46911962487286
At time: 167.73480534553528 and batch: 550, loss is 5.597436065673828 and perplexity is 269.73393997732313
At time: 168.81112670898438 and batch: 600, loss is 5.564583034515381 and perplexity is 261.0163462091446
At time: 169.88135051727295 and batch: 650, loss is 5.597295942306519 and perplexity is 269.6961465973056
At time: 170.95168375968933 and batch: 700, loss is 5.598314161300659 and perplexity is 269.97089619030686
At time: 172.02231240272522 and batch: 750, loss is 5.560041131973267 and perplexity is 259.83352356870085
At time: 173.09165120124817 and batch: 800, loss is 5.532292613983154 and perplexity is 252.7226428305207
At time: 174.16129755973816 and batch: 850, loss is 5.53184103012085 and perplexity is 252.6085431281107
At time: 175.23689031600952 and batch: 900, loss is 5.5362708950042725 and perplexity is 253.73004706401323
At time: 176.31075501441956 and batch: 950, loss is 5.502793502807617 and perplexity is 245.3764354997212
At time: 177.38084387779236 and batch: 1000, loss is 5.529422826766968 and perplexity is 251.99842229733608
At time: 178.4511730670929 and batch: 1050, loss is 5.51070161819458 and perplexity is 247.3245936417216
At time: 179.52128338813782 and batch: 1100, loss is 5.4792712116241455 and perplexity is 239.67197356165357
At time: 180.59122848510742 and batch: 1150, loss is 5.5023546886444095 and perplexity is 245.2687844656331
At time: 181.66120719909668 and batch: 1200, loss is 5.468798570632934 and perplexity is 237.17507242234453
At time: 182.73005652427673 and batch: 1250, loss is 5.484211683273315 and perplexity is 240.85899596296753
At time: 183.7996120452881 and batch: 1300, loss is 5.467099609375 and perplexity is 236.7724632684718
At time: 184.86993956565857 and batch: 1350, loss is 5.431249265670776 and perplexity is 228.43444255052407
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3553068033854165 and perplexity of 211.7289255402157
Finished 6 epochs...
Completing Train Step...
At time: 188.02831625938416 and batch: 50, loss is 5.538926248550415 and perplexity is 254.40468534942863
At time: 189.12374258041382 and batch: 100, loss is 5.56272174835205 and perplexity is 260.5309719458696
At time: 190.19316506385803 and batch: 150, loss is 5.512496728897094 and perplexity is 247.7689673974753
At time: 191.26142239570618 and batch: 200, loss is 5.498159513473511 and perplexity is 244.24199423919362
At time: 192.33113503456116 and batch: 250, loss is 5.521552839279175 and perplexity is 250.02298141045782
At time: 193.40070796012878 and batch: 300, loss is 5.521367797851562 and perplexity is 249.97672108121236
At time: 194.47069001197815 and batch: 350, loss is 5.534751510620117 and perplexity is 253.34482631601534
At time: 195.53990292549133 and batch: 400, loss is 5.580263004302979 and perplexity is 265.14132992761887
At time: 196.60997891426086 and batch: 450, loss is 5.5563556098937985 and perplexity is 258.8776638835487
At time: 197.67946934700012 and batch: 500, loss is 5.548949155807495 and perplexity is 256.96738129462983
At time: 198.75742149353027 and batch: 550, loss is 5.515760107040405 and perplexity is 248.57885199136413
At time: 199.83350896835327 and batch: 600, loss is 5.464813499450684 and perplexity is 236.23179364096453
At time: 200.9040970802307 and batch: 650, loss is 5.49885368347168 and perplexity is 244.41159856419367
At time: 201.97390389442444 and batch: 700, loss is 5.513760776519775 and perplexity is 248.08235719977716
At time: 203.0526683330536 and batch: 750, loss is 5.483325023651123 and perplexity is 240.6455306661199
At time: 204.12269854545593 and batch: 800, loss is 5.453918666839599 and perplexity is 233.6720570620593
At time: 205.19403100013733 and batch: 850, loss is 5.46399847984314 and perplexity is 236.0393385352175
At time: 206.26332592964172 and batch: 900, loss is 5.471552753448487 and perplexity is 237.82919630597806
At time: 207.33293628692627 and batch: 950, loss is 5.449883632659912 and perplexity is 232.73108203488127
At time: 208.40216040611267 and batch: 1000, loss is 5.469301567077637 and perplexity is 237.29440064886603
At time: 209.4715452194214 and batch: 1050, loss is 5.4553225803375245 and perplexity is 234.0003428055297
At time: 210.54071879386902 and batch: 1100, loss is 5.431157636642456 and perplexity is 228.4135122834429
At time: 211.60910868644714 and batch: 1150, loss is 5.454151268005371 and perplexity is 233.72641577664538
At time: 212.6772608757019 and batch: 1200, loss is 5.424764261245728 and perplexity is 226.95783725061986
At time: 213.74536800384521 and batch: 1250, loss is 5.442419881820679 and perplexity is 231.00050157058703
At time: 214.81329655647278 and batch: 1300, loss is 5.433229932785034 and perplexity is 228.88734351360702
At time: 215.88380908966064 and batch: 1350, loss is 5.411785459518432 and perplexity is 224.03122949336466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.348472086588542 and perplexity of 210.28675233322056
Finished 7 epochs...
Completing Train Step...
At time: 219.0340917110443 and batch: 50, loss is 5.499808559417724 and perplexity is 244.64509278186154
At time: 220.10896182060242 and batch: 100, loss is 5.510853805541992 and perplexity is 247.3622361798641
At time: 221.17853569984436 and batch: 150, loss is 5.460022840499878 and perplexity is 235.1027941692554
At time: 222.24658131599426 and batch: 200, loss is 5.438685131072998 and perplexity is 230.13938131033422
At time: 223.31874704360962 and batch: 250, loss is 5.466826257705688 and perplexity is 236.70774996553783
At time: 224.38836216926575 and batch: 300, loss is 5.467473287582397 and perplexity is 236.86095651107524
At time: 225.45727062225342 and batch: 350, loss is 5.472551622390747 and perplexity is 238.0668751889963
At time: 226.52758884429932 and batch: 400, loss is 5.518948497772217 and perplexity is 249.372683348953
At time: 227.5995752811432 and batch: 450, loss is 5.500941686630249 and perplexity is 244.92246391261313
At time: 228.67733573913574 and batch: 500, loss is 5.517440948486328 and perplexity is 248.99702497115638
At time: 229.7468774318695 and batch: 550, loss is 5.487976589202881 and perplexity is 241.7675165992699
At time: 230.8191361427307 and batch: 600, loss is 5.42442795753479 and perplexity is 226.88152332077416
At time: 231.88973903656006 and batch: 650, loss is 5.454951553344727 and perplexity is 233.9135384663972
At time: 232.96064925193787 and batch: 700, loss is 5.468775463104248 and perplexity is 237.16959195587518
At time: 234.03490257263184 and batch: 750, loss is 5.443021945953369 and perplexity is 231.1396205622913
At time: 235.10542345046997 and batch: 800, loss is 5.415048370361328 and perplexity is 224.76341730338967
At time: 236.18364715576172 and batch: 850, loss is 5.414216556549072 and perplexity is 224.57653372533332
At time: 237.25710153579712 and batch: 900, loss is 5.427290897369385 and perplexity is 227.53200216822486
At time: 238.32857275009155 and batch: 950, loss is 5.413843822479248 and perplexity is 224.49284199827883
At time: 239.40041971206665 and batch: 1000, loss is 5.435998153686524 and perplexity is 229.5218320390305
At time: 240.4720675945282 and batch: 1050, loss is 5.421021308898926 and perplexity is 226.10993270412018
At time: 241.54228496551514 and batch: 1100, loss is 5.418171157836914 and perplexity is 225.46640275371345
At time: 242.61218404769897 and batch: 1150, loss is 5.431695499420166 and perplexity is 228.53640045515033
At time: 243.7285349369049 and batch: 1200, loss is 5.399912090301513 and perplexity is 221.38695328839765
At time: 244.79969358444214 and batch: 1250, loss is 5.402720155715943 and perplexity is 222.00949599638193
At time: 245.87706089019775 and batch: 1300, loss is 5.397403917312622 and perplexity is 220.8323722953361
At time: 246.95016956329346 and batch: 1350, loss is 5.371774778366089 and perplexity is 215.24454026553133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.335802408854167 and perplexity of 207.63929358814818
Finished 8 epochs...
Completing Train Step...
At time: 250.1241376399994 and batch: 50, loss is 5.460997142791748 and perplexity is 235.3319669841101
At time: 251.19943690299988 and batch: 100, loss is 5.4707677459716795 and perplexity is 237.6425718690477
At time: 252.27123975753784 and batch: 150, loss is 5.423543214797974 and perplexity is 226.68088031270847
At time: 253.34171962738037 and batch: 200, loss is 5.410448522567749 and perplexity is 223.73191399210776
At time: 254.41322088241577 and batch: 250, loss is 5.440624332427978 and perplexity is 230.58610091004115
At time: 255.4842939376831 and batch: 300, loss is 5.445086793899536 and perplexity is 231.61738181551004
At time: 256.55581974983215 and batch: 350, loss is 5.451268939971924 and perplexity is 233.05370952206968
At time: 257.62852907180786 and batch: 400, loss is 5.490790185928344 and perplexity is 242.44871074572742
At time: 258.7002124786377 and batch: 450, loss is 5.462886571884155 and perplexity is 235.77703037435782
At time: 259.77081537246704 and batch: 500, loss is 5.49971848487854 and perplexity is 244.6230574802901
At time: 260.8422338962555 and batch: 550, loss is 5.46759292602539 and perplexity is 236.88929588232347
At time: 261.9143304824829 and batch: 600, loss is 5.407117013931274 and perplexity is 222.98778940538173
At time: 262.9853484630585 and batch: 650, loss is 5.430286407470703 and perplexity is 228.21459843067663
At time: 264.0582492351532 and batch: 700, loss is 5.429453134536743 and perplexity is 228.0245125903615
At time: 265.13669753074646 and batch: 750, loss is 5.394394130706787 and perplexity is 220.16871321616748
At time: 266.2082221508026 and batch: 800, loss is 5.373529329299926 and perplexity is 215.6225292781768
At time: 267.27991676330566 and batch: 850, loss is 5.388371238708496 and perplexity is 218.8466461651165
At time: 268.3512465953827 and batch: 900, loss is 5.404750852584839 and perplexity is 222.46078804836165
At time: 269.42217206954956 and batch: 950, loss is 5.3867326354980465 and perplexity is 218.48833699156762
At time: 270.51950097084045 and batch: 1000, loss is 5.403882894515991 and perplexity is 222.26778518368627
At time: 271.5908713340759 and batch: 1050, loss is 5.3887868499755855 and perplexity is 218.93762020063508
At time: 272.66250252723694 and batch: 1100, loss is 5.382210712432862 and perplexity is 217.50257997944846
At time: 273.7325508594513 and batch: 1150, loss is 5.404446067810059 and perplexity is 222.39299571873866
At time: 274.80299043655396 and batch: 1200, loss is 5.3839473628997805 and perplexity is 217.8806341154555
At time: 275.8738474845886 and batch: 1250, loss is 5.390656499862671 and perplexity is 219.347339794267
At time: 276.94536447525024 and batch: 1300, loss is 5.371140031814575 and perplexity is 215.10795788804796
At time: 278.016809463501 and batch: 1350, loss is 5.341924123764038 and perplexity is 208.91430078107288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3412353515625 and perplexity of 208.7704559620343
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 281.1686899662018 and batch: 50, loss is 5.407245931625366 and perplexity is 223.01653833008515
At time: 282.2753963470459 and batch: 100, loss is 5.401379375457764 and perplexity is 221.7120295101806
At time: 283.34713101387024 and batch: 150, loss is 5.348698530197144 and perplexity is 210.33437581607325
At time: 284.4186067581177 and batch: 200, loss is 5.3175967502593995 and perplexity is 203.8932862297799
At time: 285.49027585983276 and batch: 250, loss is 5.341004858016968 and perplexity is 208.72234126471378
At time: 286.56279850006104 and batch: 300, loss is 5.342843227386474 and perplexity is 209.106402939071
At time: 287.63470911979675 and batch: 350, loss is 5.348895149230957 and perplexity is 210.3757356237534
At time: 288.71120595932007 and batch: 400, loss is 5.379353437423706 and perplexity is 216.88200229600008
At time: 289.7828347682953 and batch: 450, loss is 5.351889162063599 and perplexity is 211.00654713354297
At time: 290.85965514183044 and batch: 500, loss is 5.373329067230225 and perplexity is 215.5793525876603
At time: 291.9364449977875 and batch: 550, loss is 5.341999864578247 and perplexity is 208.93012471956536
At time: 293.0083155632019 and batch: 600, loss is 5.281854238510132 and perplexity is 196.73432972515027
At time: 294.0790448188782 and batch: 650, loss is 5.301459302902222 and perplexity is 200.62937548193685
At time: 295.1518123149872 and batch: 700, loss is 5.314925346374512 and perplexity is 203.3493317973248
At time: 296.22966742515564 and batch: 750, loss is 5.292848997116089 and perplexity is 198.9093109767782
At time: 297.32880902290344 and batch: 800, loss is 5.274071187973022 and perplexity is 195.20907974280058
At time: 298.40062165260315 and batch: 850, loss is 5.267196683883667 and perplexity is 193.87171624808224
At time: 299.47265100479126 and batch: 900, loss is 5.2845722103118895 and perplexity is 197.26977541930205
At time: 300.5437994003296 and batch: 950, loss is 5.2636283588409425 and perplexity is 193.18115175993958
At time: 301.61537647247314 and batch: 1000, loss is 5.276842803955078 and perplexity is 195.7508748251802
At time: 302.68668127059937 and batch: 1050, loss is 5.250069732666016 and perplexity is 190.5795576159211
At time: 303.75825786590576 and batch: 1100, loss is 5.23391487121582 and perplexity is 187.5255065732407
At time: 304.82944440841675 and batch: 1150, loss is 5.2573470115661625 and perplexity is 191.971516904304
At time: 305.90089893341064 and batch: 1200, loss is 5.2260091018676755 and perplexity is 186.0488180420664
At time: 306.9723129272461 and batch: 1250, loss is 5.2302318286895755 and perplexity is 186.836112470965
At time: 308.0442178249359 and batch: 1300, loss is 5.206516628265381 and perplexity is 182.45738305849264
At time: 309.1156680583954 and batch: 1350, loss is 5.195706481933594 and perplexity is 180.49561465427186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2629248046875 and perplexity of 193.04528615826052
Finished 10 epochs...
Completing Train Step...
At time: 312.2857038974762 and batch: 50, loss is 5.33440411567688 and perplexity is 207.3491558766521
At time: 313.3821527957916 and batch: 100, loss is 5.341813116073609 and perplexity is 208.89111097419283
At time: 314.4536352157593 and batch: 150, loss is 5.29814003944397 and perplexity is 199.96453772349096
At time: 315.5314311981201 and batch: 200, loss is 5.270061988830566 and perplexity is 194.42801443708873
At time: 316.6040267944336 and batch: 250, loss is 5.297152290344238 and perplexity is 199.7671204467958
At time: 317.67573165893555 and batch: 300, loss is 5.300427923202514 and perplexity is 200.42255708937907
At time: 318.7522990703583 and batch: 350, loss is 5.311604814529419 and perplexity is 202.67522368353193
At time: 319.8242356777191 and batch: 400, loss is 5.344441957473755 and perplexity is 209.4409750108494
At time: 320.89566564559937 and batch: 450, loss is 5.319021453857422 and perplexity is 204.18398075588226
At time: 321.9712791442871 and batch: 500, loss is 5.342392902374268 and perplexity is 209.01225829505
At time: 323.0428035259247 and batch: 550, loss is 5.315108022689819 and perplexity is 203.38648229713266
At time: 324.1148633956909 and batch: 600, loss is 5.254806795120239 and perplexity is 191.48448654306986
At time: 325.2123079299927 and batch: 650, loss is 5.276561574935913 and perplexity is 195.69583173887185
At time: 326.28324937820435 and batch: 700, loss is 5.291474390029907 and perplexity is 198.63607666633573
At time: 327.35417199134827 and batch: 750, loss is 5.268352012634278 and perplexity is 194.09583125412004
At time: 328.42561626434326 and batch: 800, loss is 5.250606069564819 and perplexity is 190.6817998805268
At time: 329.49756813049316 and batch: 850, loss is 5.24746335029602 and perplexity is 190.08348118013768
At time: 330.5691912174225 and batch: 900, loss is 5.267839498519898 and perplexity is 193.99637988835124
At time: 331.64936351776123 and batch: 950, loss is 5.246189403533935 and perplexity is 189.84147912635837
At time: 332.71992015838623 and batch: 1000, loss is 5.262343502044677 and perplexity is 192.93310103314627
At time: 333.79099583625793 and batch: 1050, loss is 5.2372532558441165 and perplexity is 188.15258497385588
At time: 334.86216259002686 and batch: 1100, loss is 5.2265191078186035 and perplexity is 186.14372824675834
At time: 335.93345284461975 and batch: 1150, loss is 5.249905576705933 and perplexity is 190.54827541331872
At time: 337.0046901702881 and batch: 1200, loss is 5.215296888351441 and perplexity is 184.0664600562742
At time: 338.0790584087372 and batch: 1250, loss is 5.224946928024292 and perplexity is 185.85130676817374
At time: 339.1540906429291 and batch: 1300, loss is 5.201421566009522 and perplexity is 181.53011558149154
At time: 340.22500824928284 and batch: 1350, loss is 5.189036540985107 and perplexity is 179.29572560601196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.260609537760416 and perplexity of 192.5988517985675
Finished 11 epochs...
Completing Train Step...
At time: 343.4051022529602 and batch: 50, loss is 5.310249071121216 and perplexity is 202.40063426347393
At time: 344.4760916233063 and batch: 100, loss is 5.317167415618896 and perplexity is 203.80576656799101
At time: 345.5475640296936 and batch: 150, loss is 5.278948545455933 and perplexity is 196.16350986501857
At time: 346.6194894313812 and batch: 200, loss is 5.251278743743897 and perplexity is 190.81010975425772
At time: 347.69947695732117 and batch: 250, loss is 5.277744626998901 and perplexity is 195.9274870994858
At time: 348.7747447490692 and batch: 300, loss is 5.280646266937256 and perplexity is 196.4968237265616
At time: 349.84627771377563 and batch: 350, loss is 5.29153657913208 and perplexity is 198.64843004972167
At time: 350.91802620887756 and batch: 400, loss is 5.323997383117676 and perplexity is 205.2025177827281
At time: 352.0157747268677 and batch: 450, loss is 5.30055419921875 and perplexity is 200.44786724945152
At time: 353.08633303642273 and batch: 500, loss is 5.325799369812012 and perplexity is 205.57262335192328
At time: 354.15723848342896 and batch: 550, loss is 5.299525356292724 and perplexity is 200.2417439316358
At time: 355.22901248931885 and batch: 600, loss is 5.23992151260376 and perplexity is 188.65529476169414
At time: 356.2999818325043 and batch: 650, loss is 5.261875629425049 and perplexity is 192.84285403144966
At time: 357.37166237831116 and batch: 700, loss is 5.277259883880615 and perplexity is 195.83253561383015
At time: 358.4432797431946 and batch: 750, loss is 5.254145984649658 and perplexity is 191.35799338801198
At time: 359.5143482685089 and batch: 800, loss is 5.236627855300903 and perplexity is 188.03495103300568
At time: 360.59339594841003 and batch: 850, loss is 5.234872035980224 and perplexity is 187.70508531006905
At time: 361.66525197029114 and batch: 900, loss is 5.25751501083374 and perplexity is 192.0037706877698
At time: 362.7367653846741 and batch: 950, loss is 5.233262157440185 and perplexity is 187.40314602936792
At time: 363.8074297904968 and batch: 1000, loss is 5.25086859703064 and perplexity is 190.73186566176133
At time: 364.8798978328705 and batch: 1050, loss is 5.22627459526062 and perplexity is 186.09821933158958
At time: 365.9542601108551 and batch: 1100, loss is 5.217415828704834 and perplexity is 184.4568994189678
At time: 367.02600479125977 and batch: 1150, loss is 5.240349035263062 and perplexity is 188.73596641825387
At time: 368.09747099876404 and batch: 1200, loss is 5.206032915115356 and perplexity is 182.36914736509124
At time: 369.1692509651184 and batch: 1250, loss is 5.216728420257568 and perplexity is 184.33014575891036
At time: 370.2456204891205 and batch: 1300, loss is 5.193222551345825 and perplexity is 180.04783243627938
At time: 371.3177709579468 and batch: 1350, loss is 5.1804626846313475 and perplexity is 177.7650411211069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.260926920572917 and perplexity of 192.65998906528137
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 374.50690841674805 and batch: 50, loss is 5.288897905349732 and perplexity is 198.12495259229638
At time: 375.5784330368042 and batch: 100, loss is 5.2958423614501955 and perplexity is 199.50561104040057
At time: 376.650511264801 and batch: 150, loss is 5.255855379104614 and perplexity is 191.68537941703292
At time: 377.72258734703064 and batch: 200, loss is 5.2286116409301755 and perplexity is 186.53364797932346
At time: 378.82046270370483 and batch: 250, loss is 5.247170810699463 and perplexity is 190.0278823680645
At time: 379.89166831970215 and batch: 300, loss is 5.25064374923706 and perplexity is 190.6889848436113
At time: 381.14246106147766 and batch: 350, loss is 5.25955283164978 and perplexity is 192.3954389077209
At time: 382.214515209198 and batch: 400, loss is 5.287043685913086 and perplexity is 197.75792583354732
At time: 383.286705493927 and batch: 450, loss is 5.258875465393066 and perplexity is 192.26516085741792
At time: 384.35828399658203 and batch: 500, loss is 5.283529357910156 and perplexity is 197.06415939243504
At time: 385.43008041381836 and batch: 550, loss is 5.257979040145874 and perplexity is 192.0928867400403
At time: 386.5020477771759 and batch: 600, loss is 5.199594326019287 and perplexity is 181.19871935729154
At time: 387.57289123535156 and batch: 650, loss is 5.212597360610962 and perplexity is 183.5702376257186
At time: 388.64434790611267 and batch: 700, loss is 5.225538196563721 and perplexity is 185.96122729194894
At time: 389.7164969444275 and batch: 750, loss is 5.202033596038818 and perplexity is 181.6412514692303
At time: 390.7875051498413 and batch: 800, loss is 5.183951807022095 and perplexity is 178.38636841953402
At time: 391.8590226173401 and batch: 850, loss is 5.172022151947021 and perplexity is 176.2709239242985
At time: 392.9303467273712 and batch: 900, loss is 5.1876084423065185 and perplexity is 179.03985636394705
At time: 394.0020561218262 and batch: 950, loss is 5.1690852832794185 and perplexity is 175.75399881294572
At time: 395.07392716407776 and batch: 1000, loss is 5.185503187179566 and perplexity is 178.66332827132416
At time: 396.14525079727173 and batch: 1050, loss is 5.158097085952758 and perplexity is 173.83335074796466
At time: 397.21686339378357 and batch: 1100, loss is 5.147583465576172 and perplexity is 172.0153067482419
At time: 398.2882273197174 and batch: 1150, loss is 5.1645489597320555 and perplexity is 174.95852743148254
At time: 399.36058044433594 and batch: 1200, loss is 5.1265849781036374 and perplexity is 168.4409053354143
At time: 400.4325478076935 and batch: 1250, loss is 5.135607576370239 and perplexity is 169.96755678056206
At time: 401.5039336681366 and batch: 1300, loss is 5.1183056640625 and perplexity is 167.05208734617966
At time: 402.5762598514557 and batch: 1350, loss is 5.111973161697388 and perplexity is 165.99757199233707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2018509928385415 and perplexity of 181.60808622354187
Finished 13 epochs...
Completing Train Step...
At time: 405.72550201416016 and batch: 50, loss is 5.25654354095459 and perplexity is 191.8173353806685
At time: 406.8220636844635 and batch: 100, loss is 5.264242677688599 and perplexity is 193.29986304203334
At time: 407.8982102870941 and batch: 150, loss is 5.225626411437989 and perplexity is 185.97763256181693
At time: 408.9755473136902 and batch: 200, loss is 5.200487298965454 and perplexity is 181.36059717705768
At time: 410.0470530986786 and batch: 250, loss is 5.222222194671631 and perplexity is 185.3456007838386
At time: 411.118567943573 and batch: 300, loss is 5.227887573242188 and perplexity is 186.3986338776721
At time: 412.1900577545166 and batch: 350, loss is 5.237233743667603 and perplexity is 188.14891374322335
At time: 413.26661014556885 and batch: 400, loss is 5.265720510482788 and perplexity is 193.58573910523066
At time: 414.3403363227844 and batch: 450, loss is 5.238579263687134 and perplexity is 188.40224226439693
At time: 415.4172456264496 and batch: 500, loss is 5.265932149887085 and perplexity is 193.62671381151353
At time: 416.4951524734497 and batch: 550, loss is 5.2434119129180905 and perplexity is 189.3149277837978
At time: 417.56718015670776 and batch: 600, loss is 5.186467294692993 and perplexity is 178.83566198925186
At time: 418.6380121707916 and batch: 650, loss is 5.200198163986206 and perplexity is 181.30816706461152
At time: 419.70942878723145 and batch: 700, loss is 5.214676895141602 and perplexity is 183.9523754703689
At time: 420.78120374679565 and batch: 750, loss is 5.190502023696899 and perplexity is 179.55867301756894
At time: 421.85224413871765 and batch: 800, loss is 5.173833599090576 and perplexity is 176.5905187631203
At time: 422.9229805469513 and batch: 850, loss is 5.1647742652893065 and perplexity is 174.9979510010092
At time: 423.9944179058075 and batch: 900, loss is 5.183680286407471 and perplexity is 178.33793941817385
At time: 425.0728738307953 and batch: 950, loss is 5.166426153182983 and perplexity is 175.28726689060488
At time: 426.1434688568115 and batch: 1000, loss is 5.185158748626709 and perplexity is 178.60180032999156
At time: 427.21428775787354 and batch: 1050, loss is 5.158751707077027 and perplexity is 173.94718298589538
At time: 428.28519797325134 and batch: 1100, loss is 5.148623352050781 and perplexity is 172.19427617697167
At time: 429.356281042099 and batch: 1150, loss is 5.166959743499756 and perplexity is 175.3808234370852
At time: 430.42768359184265 and batch: 1200, loss is 5.130386161804199 and perplexity is 169.0823986037499
At time: 431.49952006340027 and batch: 1250, loss is 5.141501111984253 and perplexity is 170.9722242434232
At time: 432.5691192150116 and batch: 1300, loss is 5.122614898681641 and perplexity is 167.7735072516201
At time: 433.64843702316284 and batch: 1350, loss is 5.112388963699341 and perplexity is 166.06660846684835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2009269205729165 and perplexity of 181.44034474241107
Finished 14 epochs...
Completing Train Step...
At time: 436.8110044002533 and batch: 50, loss is 5.24579478263855 and perplexity is 189.76657849153395
At time: 437.9195182323456 and batch: 100, loss is 5.253007154464722 and perplexity is 191.14019317128285
At time: 438.9959328174591 and batch: 150, loss is 5.214737596511841 and perplexity is 183.96354197052628
At time: 440.0673816204071 and batch: 200, loss is 5.189367008209229 and perplexity is 179.35498675814475
At time: 441.1437039375305 and batch: 250, loss is 5.212395486831665 and perplexity is 183.53318334835188
At time: 442.2152171134949 and batch: 300, loss is 5.218619089126587 and perplexity is 184.6789826907687
At time: 443.2882492542267 and batch: 350, loss is 5.2286470508575436 and perplexity is 186.54025323919532
At time: 444.3604552745819 and batch: 400, loss is 5.256928977966308 and perplexity is 191.89128313139787
At time: 445.43216705322266 and batch: 450, loss is 5.230450248718261 and perplexity is 186.87692567705903
At time: 446.5038204193115 and batch: 500, loss is 5.258878507614136 and perplexity is 192.26574577143097
At time: 447.57557249069214 and batch: 550, loss is 5.237503719329834 and perplexity is 188.19971622821797
At time: 448.6469087600708 and batch: 600, loss is 5.1810666370391845 and perplexity is 177.87243517290491
At time: 449.7185266017914 and batch: 650, loss is 5.194788856506348 and perplexity is 180.33006325746095
At time: 450.7898516654968 and batch: 700, loss is 5.209783601760864 and perplexity is 183.054441248602
At time: 451.8614602088928 and batch: 750, loss is 5.185393114089965 and perplexity is 178.64366332909339
At time: 452.9324207305908 and batch: 800, loss is 5.1692486763000485 and perplexity is 175.78271813590413
At time: 454.02978682518005 and batch: 850, loss is 5.160398015975952 and perplexity is 174.23378963799567
At time: 455.1015512943268 and batch: 900, loss is 5.181367225646973 and perplexity is 177.9259096370622
At time: 456.1733877658844 and batch: 950, loss is 5.164093217849731 and perplexity is 174.8788096696035
At time: 457.2458305358887 and batch: 1000, loss is 5.183959665298462 and perplexity is 178.38777023442515
At time: 458.32564401626587 and batch: 1050, loss is 5.15809232711792 and perplexity is 173.83252350572744
At time: 459.39703845977783 and batch: 1100, loss is 5.147631206512451 and perplexity is 172.02351911607187
At time: 460.4687900543213 and batch: 1150, loss is 5.16646183013916 and perplexity is 175.2935207183022
At time: 461.54715037345886 and batch: 1200, loss is 5.131032648086548 and perplexity is 169.19174339617976
At time: 462.62073516845703 and batch: 1250, loss is 5.142235412597656 and perplexity is 171.09781535773297
At time: 463.69225335121155 and batch: 1300, loss is 5.122327013015747 and perplexity is 167.72521461547805
At time: 464.77171087265015 and batch: 1350, loss is 5.1100355243682865 and perplexity is 165.676240312968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.200555419921875 and perplexity of 181.37295205520266
Finished 15 epochs...
Completing Train Step...
At time: 467.9331543445587 and batch: 50, loss is 5.238028078079224 and perplexity is 188.29842627353113
At time: 469.00629472732544 and batch: 100, loss is 5.245037984848023 and perplexity is 189.62301789423907
At time: 470.0789933204651 and batch: 150, loss is 5.206808156967163 and perplexity is 182.51058237669363
At time: 471.15162777900696 and batch: 200, loss is 5.181653280258178 and perplexity is 177.97681344425408
At time: 472.22667598724365 and batch: 250, loss is 5.205410385131836 and perplexity is 182.25565243345181
At time: 473.303275346756 and batch: 300, loss is 5.212015962600708 and perplexity is 183.46354127434975
At time: 474.37556433677673 and batch: 350, loss is 5.22215895652771 and perplexity is 185.33388024265756
At time: 475.44795751571655 and batch: 400, loss is 5.249843463897705 and perplexity is 190.53644029239
At time: 476.51977014541626 and batch: 450, loss is 5.223765268325805 and perplexity is 185.6318234718766
At time: 477.5945494174957 and batch: 500, loss is 5.2533001041412355 and perplexity is 191.1961958316212
At time: 478.67219638824463 and batch: 550, loss is 5.232736616134644 and perplexity is 187.3046838105888
At time: 479.74320459365845 and batch: 600, loss is 5.176897287368774 and perplexity is 177.13236666820978
At time: 480.8413596153259 and batch: 650, loss is 5.189914255142212 and perplexity is 179.45316508600763
At time: 481.91285157203674 and batch: 700, loss is 5.2051429271698 and perplexity is 182.2069132262174
At time: 482.9845254421234 and batch: 750, loss is 5.180417003631592 and perplexity is 177.75692082178006
At time: 484.05598855018616 and batch: 800, loss is 5.164611597061157 and perplexity is 174.96948670957073
At time: 485.1277298927307 and batch: 850, loss is 5.156044235229492 and perplexity is 173.47686286155414
At time: 486.20700216293335 and batch: 900, loss is 5.17829740524292 and perplexity is 177.3805465608806
At time: 487.2792854309082 and batch: 950, loss is 5.161345205307007 and perplexity is 174.39890020779077
At time: 488.35165572166443 and batch: 1000, loss is 5.181698665618897 and perplexity is 177.98489116943563
At time: 489.4237585067749 and batch: 1050, loss is 5.156185750961304 and perplexity is 173.50141430392102
At time: 490.4958293437958 and batch: 1100, loss is 5.145536499023438 and perplexity is 171.6635573012676
At time: 491.56831789016724 and batch: 1150, loss is 5.164770946502686 and perplexity is 174.99737022111452
At time: 492.64170694351196 and batch: 1200, loss is 5.1295677757263185 and perplexity is 168.94408052923114
At time: 493.71359968185425 and batch: 1250, loss is 5.1410359764099125 and perplexity is 170.89271747185086
At time: 494.78558373451233 and batch: 1300, loss is 5.1205722427368165 and perplexity is 167.43115347417557
At time: 495.85888838768005 and batch: 1350, loss is 5.106806535720825 and perplexity is 165.1421363856658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2005126953125 and perplexity of 181.36520313221098
Finished 16 epochs...
Completing Train Step...
At time: 499.0768210887909 and batch: 50, loss is 5.231258354187012 and perplexity is 187.02800297765674
At time: 500.1484706401825 and batch: 100, loss is 5.238075141906738 and perplexity is 188.30728852673064
At time: 501.219913482666 and batch: 150, loss is 5.199999780654907 and perplexity is 181.27220211397878
At time: 502.2920591831207 and batch: 200, loss is 5.175016927719116 and perplexity is 176.79960706518995
At time: 503.3651762008667 and batch: 250, loss is 5.199575624465942 and perplexity is 181.19533069146217
At time: 504.43719005584717 and batch: 300, loss is 5.205982084274292 and perplexity is 182.35987762354287
At time: 505.51165318489075 and batch: 350, loss is 5.2162692260742185 and perplexity is 184.24552185905014
At time: 506.5867519378662 and batch: 400, loss is 5.243768653869629 and perplexity is 189.382476219206
At time: 507.6582317352295 and batch: 450, loss is 5.217875862121582 and perplexity is 184.54177527801923
At time: 508.7555305957794 and batch: 500, loss is 5.248297004699707 and perplexity is 190.24201118172735
At time: 509.8333902359009 and batch: 550, loss is 5.228369970321655 and perplexity is 186.48857372588725
At time: 510.904842376709 and batch: 600, loss is 5.172897396087646 and perplexity is 176.4252715537017
At time: 511.9758710861206 and batch: 650, loss is 5.185696334838867 and perplexity is 178.69784000780598
At time: 513.0485212802887 and batch: 700, loss is 5.2012098693847655 and perplexity is 181.4916903361222
At time: 514.1195979118347 and batch: 750, loss is 5.175976076126099 and perplexity is 176.96926547745295
At time: 515.1909382343292 and batch: 800, loss is 5.160973806381225 and perplexity is 174.33414067015187
At time: 516.2623944282532 and batch: 850, loss is 5.1521376037597655 and perplexity is 172.80047474961137
At time: 517.3399000167847 and batch: 900, loss is 5.175552949905396 and perplexity is 176.89440098065367
At time: 518.4111840724945 and batch: 950, loss is 5.158614301681519 and perplexity is 173.92328334642704
At time: 519.482754945755 and batch: 1000, loss is 5.179440622329712 and perplexity is 177.583446990094
At time: 520.5542144775391 and batch: 1050, loss is 5.153918466567993 and perplexity is 173.10848286703424
At time: 521.6262466907501 and batch: 1100, loss is 5.142968015670776 and perplexity is 171.2232080690028
At time: 522.6990089416504 and batch: 1150, loss is 5.162320823669433 and perplexity is 174.5691300033752
At time: 523.7718760967255 and batch: 1200, loss is 5.127529544830322 and perplexity is 168.60008417568983
At time: 524.8435566425323 and batch: 1250, loss is 5.139367742538452 and perplexity is 170.60786611757902
At time: 525.9150614738464 and batch: 1300, loss is 5.118245859146118 and perplexity is 167.0420971088
At time: 526.9863474369049 and batch: 1350, loss is 5.103536386489868 and perplexity is 164.6029789983967
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2005521647135415 and perplexity of 181.37236164941868
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 530.131546497345 and batch: 50, loss is 5.2278107738494874 and perplexity is 186.38431912547927
At time: 531.2298853397369 and batch: 100, loss is 5.235347890853882 and perplexity is 187.79442694486454
At time: 532.3071916103363 and batch: 150, loss is 5.1982573223114015 and perplexity is 180.95661787899837
At time: 533.3780491352081 and batch: 200, loss is 5.173429174423218 and perplexity is 176.519115640876
At time: 534.4488461017609 and batch: 250, loss is 5.196831712722778 and perplexity is 180.6988281868139
At time: 535.545912027359 and batch: 300, loss is 5.201260232925415 and perplexity is 181.50083113042552
At time: 536.6180212497711 and batch: 350, loss is 5.209667463302612 and perplexity is 183.03318282250348
At time: 537.6897592544556 and batch: 400, loss is 5.236427593231201 and perplexity is 187.99729853484487
At time: 538.7621867656708 and batch: 450, loss is 5.208067550659179 and perplexity is 182.74057985114987
At time: 539.8338916301727 and batch: 500, loss is 5.236354160308838 and perplexity is 187.9834938506824
At time: 540.9046528339386 and batch: 550, loss is 5.214181509017944 and perplexity is 183.86127058405845
At time: 541.9762952327728 and batch: 600, loss is 5.161056737899781 and perplexity is 174.34859906469373
At time: 543.0480558872223 and batch: 650, loss is 5.1708119773864745 and perplexity is 176.05773436071286
At time: 544.119387626648 and batch: 700, loss is 5.183824701309204 and perplexity is 178.36369593393778
At time: 545.1913118362427 and batch: 750, loss is 5.156320161819458 and perplexity is 173.52473634524134
At time: 546.2630395889282 and batch: 800, loss is 5.143154029846191 and perplexity is 171.25506097531783
At time: 547.3354249000549 and batch: 850, loss is 5.124335775375366 and perplexity is 168.06247333626172
At time: 548.4146919250488 and batch: 900, loss is 5.147993021011352 and perplexity is 172.08577098057452
At time: 549.4860372543335 and batch: 950, loss is 5.130206718444824 and perplexity is 169.05206061219022
At time: 550.5577340126038 and batch: 1000, loss is 5.15261552810669 and perplexity is 172.8830800416221
At time: 551.6291377544403 and batch: 1050, loss is 5.122551918029785 and perplexity is 167.76294109950436
At time: 552.700954914093 and batch: 1100, loss is 5.1100006198883055 and perplexity is 165.67045757087706
At time: 553.773713350296 and batch: 1150, loss is 5.126876163482666 and perplexity is 168.48996000593309
At time: 554.8458299636841 and batch: 1200, loss is 5.092112607955933 and perplexity is 162.73329080545298
At time: 555.9176616668701 and batch: 1250, loss is 5.102989320755005 and perplexity is 164.51295497550464
At time: 556.9964292049408 and batch: 1300, loss is 5.084924554824829 and perplexity is 161.5677492706229
At time: 558.0695602893829 and batch: 1350, loss is 5.077018814086914 and perplexity is 160.29547230571038
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.186914876302083 and perplexity of 178.91572345829172
Finished 18 epochs...
Completing Train Step...
At time: 561.2767300605774 and batch: 50, loss is 5.217366256713867 and perplexity is 184.44775574985292
At time: 562.374404668808 and batch: 100, loss is 5.222464065551758 and perplexity is 185.3904359093649
At time: 563.4521412849426 and batch: 150, loss is 5.1854242420196535 and perplexity is 178.6492242230338
At time: 564.5248637199402 and batch: 200, loss is 5.161353359222412 and perplexity is 174.40032224746741
At time: 565.5962822437286 and batch: 250, loss is 5.185472497940063 and perplexity is 178.65784531378685
At time: 566.6675553321838 and batch: 300, loss is 5.190408201217651 and perplexity is 179.541827167968
At time: 567.7387351989746 and batch: 350, loss is 5.199201889038086 and perplexity is 181.12762422996045
At time: 568.8102693557739 and batch: 400, loss is 5.227046365737915 and perplexity is 186.24189988021791
At time: 569.8819122314453 and batch: 450, loss is 5.199127054214477 and perplexity is 181.1140700833179
At time: 570.9544723033905 and batch: 500, loss is 5.228635921478271 and perplexity is 186.53817717352013
At time: 572.02694272995 and batch: 550, loss is 5.207552528381347 and perplexity is 182.64648861308427
At time: 573.0994968414307 and batch: 600, loss is 5.154668111801147 and perplexity is 173.23830146890256
At time: 574.1710121631622 and batch: 650, loss is 5.165270309448243 and perplexity is 175.08477924597048
At time: 575.243250131607 and batch: 700, loss is 5.179586725234985 and perplexity is 177.6093943430734
At time: 576.3220508098602 and batch: 750, loss is 5.153027935028076 and perplexity is 172.9543929243743
At time: 577.3938972949982 and batch: 800, loss is 5.140315294265747 and perplexity is 170.7696025105068
At time: 578.4727566242218 and batch: 850, loss is 5.1224535465240475 and perplexity is 167.74643881807188
At time: 579.5439548492432 and batch: 900, loss is 5.147682294845581 and perplexity is 172.03230773541875
At time: 580.6161873340607 and batch: 950, loss is 5.130290794372558 and perplexity is 169.0662744185327
At time: 581.6874580383301 and batch: 1000, loss is 5.152821130752564 and perplexity is 172.9186289146514
At time: 582.7589511871338 and batch: 1050, loss is 5.123836107254029 and perplexity is 167.97851885237884
At time: 583.8311915397644 and batch: 1100, loss is 5.112613391876221 and perplexity is 166.1038826755621
At time: 584.9028849601746 and batch: 1150, loss is 5.1300946235656735 and perplexity is 169.03311180393777
At time: 585.974680185318 and batch: 1200, loss is 5.09615044593811 and perplexity is 163.39170986820258
At time: 587.0462100505829 and batch: 1250, loss is 5.107462577819824 and perplexity is 165.25051212509024
At time: 588.121312379837 and batch: 1300, loss is 5.08947229385376 and perplexity is 162.30419053187882
At time: 589.1940748691559 and batch: 1350, loss is 5.079341783523559 and perplexity is 160.6682666159646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.18617919921875 and perplexity of 178.7841476652776
Finished 19 epochs...
Completing Train Step...
At time: 592.3658473491669 and batch: 50, loss is 5.213314256668091 and perplexity is 183.70188558859314
At time: 593.4374783039093 and batch: 100, loss is 5.217609272003174 and perplexity is 184.49258482143276
At time: 594.5089900493622 and batch: 150, loss is 5.180051383972168 and perplexity is 177.69194127655228
At time: 595.5810928344727 and batch: 200, loss is 5.156283826828003 and perplexity is 173.51843143997394
At time: 596.6545042991638 and batch: 250, loss is 5.180621109008789 and perplexity is 177.79320566799387
At time: 597.7322525978088 and batch: 300, loss is 5.185551748275757 and perplexity is 178.67200456905778
At time: 598.8036830425262 and batch: 350, loss is 5.194729261398315 and perplexity is 180.31931678808132
At time: 599.8750936985016 and batch: 400, loss is 5.223059463500976 and perplexity is 185.50084986156855
At time: 600.9465379714966 and batch: 450, loss is 5.195068149566651 and perplexity is 180.38043522663605
At time: 602.0182180404663 and batch: 500, loss is 5.224699850082398 and perplexity is 185.80539268221153
At time: 603.0901832580566 and batch: 550, loss is 5.204240436553955 and perplexity is 182.04254737736298
At time: 604.1625304222107 and batch: 600, loss is 5.15173602104187 and perplexity is 172.731094997095
At time: 605.2352492809296 and batch: 650, loss is 5.162612085342407 and perplexity is 174.6199827055916
At time: 606.3088495731354 and batch: 700, loss is 5.1775475597381595 and perplexity is 177.24758841067546
At time: 607.3809733390808 and batch: 750, loss is 5.151532506942749 and perplexity is 172.695945360751
At time: 608.4633641242981 and batch: 800, loss is 5.138950052261353 and perplexity is 170.53661975119817
At time: 609.5384440422058 and batch: 850, loss is 5.1213004016876225 and perplexity is 167.55311436529
At time: 610.6114196777344 and batch: 900, loss is 5.14730209350586 and perplexity is 171.96691325386485
At time: 611.6846144199371 and batch: 950, loss is 5.130066623687744 and perplexity is 169.02837896370107
At time: 612.7576613426208 and batch: 1000, loss is 5.152752962112427 and perplexity is 172.90684168862808
At time: 613.8320450782776 and batch: 1050, loss is 5.124006242752075 and perplexity is 168.00710039264322
At time: 614.9061691761017 and batch: 1100, loss is 5.113478565216065 and perplexity is 166.24765351087643
At time: 615.9801833629608 and batch: 1150, loss is 5.131154623031616 and perplexity is 169.21238180844546
At time: 617.1014106273651 and batch: 1200, loss is 5.097534837722779 and perplexity is 163.618064654729
At time: 618.1775426864624 and batch: 1250, loss is 5.109059906005859 and perplexity is 165.51468235297156
At time: 619.2504045963287 and batch: 1300, loss is 5.091380882263183 and perplexity is 162.61425823041273
At time: 620.3242421150208 and batch: 1350, loss is 5.079876527786255 and perplexity is 160.75420602549002
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185957438151042 and perplexity of 178.74450469759793
Finished 20 epochs...
Completing Train Step...
At time: 623.5235376358032 and batch: 50, loss is 5.210142002105713 and perplexity is 183.12005978162168
At time: 624.5989489555359 and batch: 100, loss is 5.213883571624756 and perplexity is 183.80649959596016
At time: 625.6738448143005 and batch: 150, loss is 5.1765797901153565 and perplexity is 177.07613655522678
At time: 626.7465171813965 and batch: 200, loss is 5.152683267593384 and perplexity is 172.89479144938002
At time: 627.8203892707825 and batch: 250, loss is 5.177280673980713 and perplexity is 177.2002898657216
At time: 628.8909215927124 and batch: 300, loss is 5.182273082733154 and perplexity is 178.08715810612992
At time: 629.9623453617096 and batch: 350, loss is 5.191861200332641 and perplexity is 179.80289090070318
At time: 631.033903837204 and batch: 400, loss is 5.220217180252075 and perplexity is 184.97435248513256
At time: 632.1051912307739 and batch: 450, loss is 5.192314405441284 and perplexity is 179.8843969574936
At time: 633.1762640476227 and batch: 500, loss is 5.222222671508789 and perplexity is 185.34568916352922
At time: 634.2475192546844 and batch: 550, loss is 5.201945772171021 and perplexity is 181.62529973245654
At time: 635.3192596435547 and batch: 600, loss is 5.149707765579223 and perplexity is 172.38110726234783
At time: 636.391126871109 and batch: 650, loss is 5.1608579730987545 and perplexity is 174.31394814389722
At time: 637.463267326355 and batch: 700, loss is 5.176332664489746 and perplexity is 177.03238191086953
At time: 638.5354111194611 and batch: 750, loss is 5.1502102184295655 and perplexity is 172.46774240425128
At time: 639.6067004203796 and batch: 800, loss is 5.137810354232788 and perplexity is 170.34237021580196
At time: 640.679557800293 and batch: 850, loss is 5.120312490463257 and perplexity is 167.387668499301
At time: 641.7517952919006 and batch: 900, loss is 5.146646404266358 and perplexity is 171.85419335794379
At time: 642.8234441280365 and batch: 950, loss is 5.1296172523498536 and perplexity is 168.95243951868756
At time: 643.9411017894745 and batch: 1000, loss is 5.152305707931519 and perplexity is 172.82952567201997
At time: 645.0129046440125 and batch: 1050, loss is 5.1236319160461425 and perplexity is 167.94422261732944
At time: 646.0843081474304 and batch: 1100, loss is 5.113527889251709 and perplexity is 166.25585371829598
At time: 647.1556296348572 and batch: 1150, loss is 5.131303329467773 and perplexity is 169.23754664973836
At time: 648.2291643619537 and batch: 1200, loss is 5.097971382141114 and perplexity is 163.68950680029317
At time: 649.3016774654388 and batch: 1250, loss is 5.109670162200928 and perplexity is 165.61571953940114
At time: 650.3748083114624 and batch: 1300, loss is 5.092274036407471 and perplexity is 162.75956270906065
At time: 651.4472761154175 and batch: 1350, loss is 5.0797929763793945 and perplexity is 160.7407753465017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185648600260417 and perplexity of 178.6893101453296
Finished 21 epochs...
Completing Train Step...
At time: 654.6471757888794 and batch: 50, loss is 5.207294187545776 and perplexity is 182.5993096609892
At time: 655.7473306655884 and batch: 100, loss is 5.2109602928161625 and perplexity is 183.2699665507314
At time: 656.8203825950623 and batch: 150, loss is 5.17375675201416 and perplexity is 176.57694881944246
At time: 657.8937828540802 and batch: 200, loss is 5.149570150375366 and perplexity is 172.35738663332782
At time: 658.9660820960999 and batch: 250, loss is 5.174595184326172 and perplexity is 176.72505872027608
At time: 660.0377600193024 and batch: 300, loss is 5.179618473052979 and perplexity is 177.61503314330824
At time: 661.1088762283325 and batch: 350, loss is 5.1895991230010985 and perplexity is 179.39662253551987
At time: 662.1804993152618 and batch: 400, loss is 5.217649803161621 and perplexity is 184.50006267116242
At time: 663.2520098686218 and batch: 450, loss is 5.189904146194458 and perplexity is 179.45135101250662
At time: 664.3235697746277 and batch: 500, loss is 5.220110206604004 and perplexity is 184.95456616217405
At time: 665.3967742919922 and batch: 550, loss is 5.199906673431396 and perplexity is 181.25532514823618
At time: 666.4701797962189 and batch: 600, loss is 5.147900228500366 and perplexity is 172.0698034506253
At time: 667.5436072349548 and batch: 650, loss is 5.1592309856414795 and perplexity is 174.03057212376436
At time: 668.6170485019684 and batch: 700, loss is 5.174967870712281 and perplexity is 176.79093401839626
At time: 669.6904821395874 and batch: 750, loss is 5.14909333229065 and perplexity is 172.27522310443155
At time: 670.8096206188202 and batch: 800, loss is 5.136733732223511 and perplexity is 170.15907455868955
At time: 671.8835570812225 and batch: 850, loss is 5.119341011047363 and perplexity is 167.22513378722607
At time: 672.9579870700836 and batch: 900, loss is 5.146128206253052 and perplexity is 171.76516192631522
At time: 674.031379699707 and batch: 950, loss is 5.129302806854248 and perplexity is 168.8993215369021
At time: 675.1062371730804 and batch: 1000, loss is 5.15177056312561 and perplexity is 172.7370615920916
At time: 676.180999994278 and batch: 1050, loss is 5.12332181930542 and perplexity is 167.89215173519526
At time: 677.2550086975098 and batch: 1100, loss is 5.1132818126678465 and perplexity is 166.21494707905526
At time: 678.327882528305 and batch: 1150, loss is 5.13112286567688 and perplexity is 169.20700815613756
At time: 679.3997530937195 and batch: 1200, loss is 5.098077411651611 and perplexity is 163.7068636387251
At time: 680.4722635746002 and batch: 1250, loss is 5.1097527122497555 and perplexity is 165.62939168944632
At time: 681.5446786880493 and batch: 1300, loss is 5.09280647277832 and perplexity is 162.84624489427677
At time: 682.6164891719818 and batch: 1350, loss is 5.07950945854187 and perplexity is 160.69520892922472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185585530598958 and perplexity of 178.67804062641855
Finished 22 epochs...
Completing Train Step...
At time: 685.7655675411224 and batch: 50, loss is 5.20494197845459 and perplexity is 182.1703026596486
At time: 686.8641428947449 and batch: 100, loss is 5.208576889038086 and perplexity is 182.83368034966745
At time: 687.936320066452 and batch: 150, loss is 5.171387224197388 and perplexity is 176.1590401460619
At time: 689.0085999965668 and batch: 200, loss is 5.147168073654175 and perplexity is 171.9438678179633
At time: 690.0806457996368 and batch: 250, loss is 5.172315073013306 and perplexity is 176.32256495429291
At time: 691.1529936790466 and batch: 300, loss is 5.177453050613403 and perplexity is 177.23083768779014
At time: 692.2244834899902 and batch: 350, loss is 5.187896862030029 and perplexity is 179.09150243733197
At time: 693.2967290878296 and batch: 400, loss is 5.215759572982788 and perplexity is 184.1516444837317
At time: 694.3684492111206 and batch: 450, loss is 5.187819232940674 and perplexity is 179.07760026669996
At time: 695.4402134418488 and batch: 500, loss is 5.218261194229126 and perplexity is 184.61289885143518
At time: 696.5120315551758 and batch: 550, loss is 5.198228902816773 and perplexity is 180.95147525644424
At time: 697.5842876434326 and batch: 600, loss is 5.146206502914429 and perplexity is 171.77861109154034
At time: 698.7012057304382 and batch: 650, loss is 5.157737607955933 and perplexity is 173.7708727136684
At time: 699.7734379768372 and batch: 700, loss is 5.173818874359131 and perplexity is 176.58791853429952
At time: 700.8456258773804 and batch: 750, loss is 5.14773627281189 and perplexity is 172.04159394015258
At time: 701.9174706935883 and batch: 800, loss is 5.135682258605957 and perplexity is 169.98025081170542
At time: 702.9900150299072 and batch: 850, loss is 5.118370313644409 and perplexity is 167.06288754289383
At time: 704.0635929107666 and batch: 900, loss is 5.145493154525757 and perplexity is 171.65611679186
At time: 705.1361722946167 and batch: 950, loss is 5.128622674942017 and perplexity is 168.7844867741907
At time: 706.2081718444824 and batch: 1000, loss is 5.151101369857788 and perplexity is 172.6215057822681
At time: 707.2810349464417 and batch: 1050, loss is 5.122659072875977 and perplexity is 167.7809186748295
At time: 708.360345363617 and batch: 1100, loss is 5.112909631729126 and perplexity is 166.1530965545291
At time: 709.4359290599823 and batch: 1150, loss is 5.130835094451904 and perplexity is 169.1583222536629
At time: 710.5092532634735 and batch: 1200, loss is 5.0978694343566895 and perplexity is 163.6728198683537
At time: 711.5843806266785 and batch: 1250, loss is 5.1096572589874265 and perplexity is 165.61358257819964
At time: 712.6547012329102 and batch: 1300, loss is 5.093005523681641 and perplexity is 162.87866281272633
At time: 713.7267577648163 and batch: 1350, loss is 5.078904495239258 and perplexity is 160.59802362465237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185561930338542 and perplexity of 178.6738238278881
Finished 23 epochs...
Completing Train Step...
At time: 716.9137046337128 and batch: 50, loss is 5.20277045249939 and perplexity is 181.77514432273063
At time: 717.9835348129272 and batch: 100, loss is 5.206242189407349 and perplexity is 182.40731653306088
At time: 719.0537533760071 and batch: 150, loss is 5.1692210388183595 and perplexity is 175.7778600113839
At time: 720.1243691444397 and batch: 200, loss is 5.144877815246582 and perplexity is 171.55052253216712
At time: 721.1945135593414 and batch: 250, loss is 5.1701616859436035 and perplexity is 175.94328274009484
At time: 722.2648663520813 and batch: 300, loss is 5.175349912643433 and perplexity is 176.85848847173403
At time: 723.3353095054626 and batch: 350, loss is 5.18604344367981 and perplexity is 178.75987837434
At time: 724.406836271286 and batch: 400, loss is 5.213951435089111 and perplexity is 183.81897376505918
At time: 725.5246341228485 and batch: 450, loss is 5.185817556381226 and perplexity is 178.71950334859318
At time: 726.5962197780609 and batch: 500, loss is 5.2165165138244625 and perplexity is 184.29108915352785
At time: 727.6693041324615 and batch: 550, loss is 5.196625528335571 and perplexity is 180.6615747503256
At time: 728.74294090271 and batch: 600, loss is 5.1447369003295895 and perplexity is 171.52635020768497
At time: 729.8163249492645 and batch: 650, loss is 5.156237087249756 and perplexity is 173.51032145120058
At time: 730.8881311416626 and batch: 700, loss is 5.172622919082642 and perplexity is 176.37685351868112
At time: 731.9590837955475 and batch: 750, loss is 5.1466559791564945 and perplexity is 171.85583885084242
At time: 733.0292105674744 and batch: 800, loss is 5.134579305648804 and perplexity is 169.79287394434533
At time: 734.1003983020782 and batch: 850, loss is 5.1172026348114015 and perplexity is 166.86792559395155
At time: 735.1723077297211 and batch: 900, loss is 5.14467604637146 and perplexity is 171.51591246794342
At time: 736.2439076900482 and batch: 950, loss is 5.127798814773559 and perplexity is 168.64548922361854
At time: 737.3146374225616 and batch: 1000, loss is 5.150185165405273 and perplexity is 172.46342161983574
At time: 738.3865113258362 and batch: 1050, loss is 5.1219376182556156 and perplexity is 167.65991601005734
At time: 739.4582459926605 and batch: 1100, loss is 5.112276611328125 and perplexity is 166.04795153770198
At time: 740.5289499759674 and batch: 1150, loss is 5.130216665267945 and perplexity is 169.05374215149828
At time: 741.6002213954926 and batch: 1200, loss is 5.0973458671569825 and perplexity is 163.587148577683
At time: 742.670313835144 and batch: 1250, loss is 5.10932770729065 and perplexity is 165.5590133332392
At time: 743.7412297725677 and batch: 1300, loss is 5.092866382598877 and perplexity is 162.85600127583538
At time: 744.8123018741608 and batch: 1350, loss is 5.078281888961792 and perplexity is 160.4980654075307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185590413411458 and perplexity of 178.67891307991883
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 748.0055894851685 and batch: 50, loss is 5.202045993804932 and perplexity is 181.64350342894215
At time: 749.0769629478455 and batch: 100, loss is 5.205894908905029 and perplexity is 182.34398102677824
At time: 750.1478550434113 and batch: 150, loss is 5.169141941070556 and perplexity is 175.76395692840185
At time: 751.2188441753387 and batch: 200, loss is 5.145286111831665 and perplexity is 171.6205803258919
At time: 752.3162863254547 and batch: 250, loss is 5.169809246063233 and perplexity is 175.88128423658821
At time: 753.3876469135284 and batch: 300, loss is 5.1746227741241455 and perplexity is 176.72993459620488
At time: 754.4584672451019 and batch: 350, loss is 5.185050067901611 and perplexity is 178.58239081156734
At time: 755.5299136638641 and batch: 400, loss is 5.211859321594238 and perplexity is 183.43480561124437
At time: 756.601315498352 and batch: 450, loss is 5.182075271606445 and perplexity is 178.05193396871059
At time: 757.6728932857513 and batch: 500, loss is 5.211874990463257 and perplexity is 183.43767984970503
At time: 758.7438168525696 and batch: 550, loss is 5.189904394149781 and perplexity is 179.4513955084298
At time: 759.8152673244476 and batch: 600, loss is 5.139054632186889 and perplexity is 170.55445539080165
At time: 760.8862473964691 and batch: 650, loss is 5.150770502090454 and perplexity is 172.5644003377526
At time: 761.9572186470032 and batch: 700, loss is 5.16536039352417 and perplexity is 175.100552306958
At time: 763.0279774665833 and batch: 750, loss is 5.138985710144043 and perplexity is 170.54270083439826
At time: 764.0994694232941 and batch: 800, loss is 5.126958484649658 and perplexity is 168.5038308669922
At time: 765.1705129146576 and batch: 850, loss is 5.107058563232422 and perplexity is 165.18376199253763
At time: 766.2437014579773 and batch: 900, loss is 5.130331983566284 and perplexity is 169.0732382654789
At time: 767.3147134780884 and batch: 950, loss is 5.114216747283936 and perplexity is 166.37041985390553
At time: 768.3860909938812 and batch: 1000, loss is 5.1373331832885745 and perplexity is 170.26110717588918
At time: 769.4592521190643 and batch: 1050, loss is 5.107640800476074 and perplexity is 165.27996613491578
At time: 770.5301723480225 and batch: 1100, loss is 5.097553625106811 and perplexity is 163.6211386390203
At time: 771.6024601459503 and batch: 1150, loss is 5.114432201385498 and perplexity is 166.4062689050156
At time: 772.6733102798462 and batch: 1200, loss is 5.07996111869812 and perplexity is 160.76780494552818
At time: 773.7442290782928 and batch: 1250, loss is 5.093015403747558 and perplexity is 162.88027207260126
At time: 774.8150999546051 and batch: 1300, loss is 5.079690742492676 and perplexity is 160.7243430322678
At time: 775.8863399028778 and batch: 1350, loss is 5.0670869922637936 and perplexity is 158.71132598701118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.18091064453125 and perplexity of 177.84469056968118
Finished 25 epochs...
Completing Train Step...
At time: 779.0400338172913 and batch: 50, loss is 5.198259592056274 and perplexity is 180.95702860482015
At time: 780.1410052776337 and batch: 100, loss is 5.201721563339233 and perplexity is 181.58458230095488
At time: 781.213573217392 and batch: 150, loss is 5.164508590698242 and perplexity is 174.95146466733215
At time: 782.2872676849365 and batch: 200, loss is 5.141193866729736 and perplexity is 170.9197019079026
At time: 783.3592128753662 and batch: 250, loss is 5.165917320251465 and perplexity is 175.1980976447834
At time: 784.4362862110138 and batch: 300, loss is 5.1707516956329345 and perplexity is 176.04712161164207
At time: 785.508059501648 and batch: 350, loss is 5.181597623825073 and perplexity is 177.9669081652912
At time: 786.5793082714081 and batch: 400, loss is 5.208540840148926 and perplexity is 182.8270895173866
At time: 787.6502380371094 and batch: 450, loss is 5.178986406326294 and perplexity is 177.5028040625695
At time: 788.7265388965607 and batch: 500, loss is 5.20913818359375 and perplexity is 182.93633270544896
At time: 789.7979049682617 and batch: 550, loss is 5.187599325180054 and perplexity is 179.03822404237545
At time: 790.8692727088928 and batch: 600, loss is 5.136919012069702 and perplexity is 170.19060452669552
At time: 791.9402987957001 and batch: 650, loss is 5.148759078979492 and perplexity is 172.21764916335476
At time: 793.0118298530579 and batch: 700, loss is 5.164054346084595 and perplexity is 174.87201195370713
At time: 794.0824995040894 and batch: 750, loss is 5.138053369522095 and perplexity is 170.38377104649484
At time: 795.1538887023926 and batch: 800, loss is 5.1263796329498295 and perplexity is 168.40632036285044
At time: 796.2251799106598 and batch: 850, loss is 5.106764144897461 and perplexity is 165.135136022909
At time: 797.2975459098816 and batch: 900, loss is 5.130461750030517 and perplexity is 169.09517972540704
At time: 798.3762056827545 and batch: 950, loss is 5.114442653656006 and perplexity is 166.40800823744235
At time: 799.4472930431366 and batch: 1000, loss is 5.138040943145752 and perplexity is 170.3816538067879
At time: 800.5190834999084 and batch: 1050, loss is 5.1088440799713135 and perplexity is 165.4789638300525
At time: 801.5897123813629 and batch: 1100, loss is 5.0991192817687985 and perplexity is 163.87751381014914
At time: 802.6611034870148 and batch: 1150, loss is 5.116076374053955 and perplexity is 166.6800945908773
At time: 803.7325863838196 and batch: 1200, loss is 5.082110795974732 and perplexity is 161.11377557199665
At time: 804.803325176239 and batch: 1250, loss is 5.095102710723877 and perplexity is 163.22060827029676
At time: 805.8735914230347 and batch: 1300, loss is 5.081474313735962 and perplexity is 161.0112621428731
At time: 806.944411277771 and batch: 1350, loss is 5.0678637504577635 and perplexity is 158.83465420184726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180425211588542 and perplexity of 177.75837984892146
Finished 26 epochs...
Completing Train Step...
At time: 810.1021330356598 and batch: 50, loss is 5.1965940475463865 and perplexity is 180.65588747089768
At time: 811.2011909484863 and batch: 100, loss is 5.1996935272216795 and perplexity is 181.21669537973048
At time: 812.2733564376831 and batch: 150, loss is 5.162196502685547 and perplexity is 174.5474287463658
At time: 813.3488686084747 and batch: 200, loss is 5.1390920257568355 and perplexity is 170.5608331500018
At time: 814.421459197998 and batch: 250, loss is 5.1639534282684325 and perplexity is 174.8543651426066
At time: 815.4947454929352 and batch: 300, loss is 5.16881760597229 and perplexity is 175.70695975175187
At time: 816.5663545131683 and batch: 350, loss is 5.179756774902343 and perplexity is 177.63959932960228
At time: 817.6390404701233 and batch: 400, loss is 5.206816377639771 and perplexity is 182.51208274260577
At time: 818.712076663971 and batch: 450, loss is 5.1773159885406494 and perplexity is 177.20654772647504
At time: 819.784589767456 and batch: 500, loss is 5.207580318450928 and perplexity is 182.65156444224
At time: 820.8634691238403 and batch: 550, loss is 5.186270141601563 and perplexity is 178.80040746101653
At time: 821.9355733394623 and batch: 600, loss is 5.135853471755982 and perplexity is 170.00935615742674
At time: 823.0077397823334 and batch: 650, loss is 5.147658348083496 and perplexity is 172.02818816799976
At time: 824.0795888900757 and batch: 700, loss is 5.163232975006103 and perplexity is 174.72843611324413
At time: 825.1513576507568 and batch: 750, loss is 5.137618436813354 and perplexity is 170.30968168453953
At time: 826.2234938144684 and batch: 800, loss is 5.126185560226441 and perplexity is 168.37364046086313
At time: 827.295253276825 and batch: 850, loss is 5.106630582809448 and perplexity is 165.11308170218075
At time: 828.3723139762878 and batch: 900, loss is 5.130454835891723 and perplexity is 169.09401058190684
At time: 829.4475872516632 and batch: 950, loss is 5.114533643722535 and perplexity is 166.4231504020656
At time: 830.5204637050629 and batch: 1000, loss is 5.1384295463562015 and perplexity is 170.4478775310015
At time: 831.59219622612 and batch: 1050, loss is 5.109538412094116 and perplexity is 165.59390108798533
At time: 832.6640694141388 and batch: 1100, loss is 5.099980945587158 and perplexity is 164.01878198854055
At time: 833.7704200744629 and batch: 1150, loss is 5.116990365982056 and perplexity is 166.83250849383654
At time: 834.8437085151672 and batch: 1200, loss is 5.0832971096038815 and perplexity is 161.30502045557859
At time: 835.9152503013611 and batch: 1250, loss is 5.096259336471558 and perplexity is 163.40950264736614
At time: 836.9866111278534 and batch: 1300, loss is 5.082382669448853 and perplexity is 161.15758408880717
At time: 838.0582957267761 and batch: 1350, loss is 5.068129062652588 and perplexity is 158.87680056329233
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180225423177084 and perplexity of 177.72286933200107
Finished 27 epochs...
Completing Train Step...
At time: 841.2537021636963 and batch: 50, loss is 5.19526445388794 and perplexity is 180.41584816128935
At time: 842.3253724575043 and batch: 100, loss is 5.198256616592407 and perplexity is 180.95649017452104
At time: 843.4034752845764 and batch: 150, loss is 5.160513391494751 and perplexity is 174.25389311156954
At time: 844.4744908809662 and batch: 200, loss is 5.137553129196167 and perplexity is 170.29855952822953
At time: 845.5505003929138 and batch: 250, loss is 5.162481231689453 and perplexity is 174.59713453789152
At time: 846.6280529499054 and batch: 300, loss is 5.167407140731812 and perplexity is 175.45930588715294
At time: 847.6995987892151 and batch: 350, loss is 5.178490829467774 and perplexity is 177.4148595739803
At time: 848.7717673778534 and batch: 400, loss is 5.205535774230957 and perplexity is 182.2785067383305
At time: 849.8433568477631 and batch: 450, loss is 5.176064777374267 and perplexity is 176.98496356839814
At time: 850.9150595664978 and batch: 500, loss is 5.2063615608215335 and perplexity is 182.42909205205441
At time: 851.9897749423981 and batch: 550, loss is 5.185263128280639 and perplexity is 178.6204436970786
At time: 853.0638358592987 and batch: 600, loss is 5.135044012069702 and perplexity is 169.8717961194906
At time: 854.1403007507324 and batch: 650, loss is 5.146756591796875 and perplexity is 171.87313059042327
At time: 855.2096984386444 and batch: 700, loss is 5.162696990966797 and perplexity is 174.6348095536867
At time: 856.2805755138397 and batch: 750, loss is 5.1372298240661625 and perplexity is 170.2435100296738
At time: 857.3536331653595 and batch: 800, loss is 5.126038637161255 and perplexity is 168.34890430671035
At time: 858.4239127635956 and batch: 850, loss is 5.106491861343383 and perplexity is 165.09017856203593
At time: 859.4981665611267 and batch: 900, loss is 5.1303564453125 and perplexity is 169.07737414271034
At time: 860.6076595783234 and batch: 950, loss is 5.114484739303589 and perplexity is 166.41501177360516
At time: 861.6787643432617 and batch: 1000, loss is 5.138627920150757 and perplexity is 170.4816932772093
At time: 862.7500510215759 and batch: 1050, loss is 5.109933261871338 and perplexity is 165.65929871320844
At time: 863.8225610256195 and batch: 1100, loss is 5.100467624664307 and perplexity is 164.09862592560464
At time: 864.8982119560242 and batch: 1150, loss is 5.117534341812134 and perplexity is 166.92328603428402
At time: 865.9709823131561 and batch: 1200, loss is 5.084031286239624 and perplexity is 161.4234903164056
At time: 867.0419344902039 and batch: 1250, loss is 5.097000494003296 and perplexity is 163.53065972370442
At time: 868.1133425235748 and batch: 1300, loss is 5.082937183380127 and perplexity is 161.2469729957216
At time: 869.1841921806335 and batch: 1350, loss is 5.068192930221557 and perplexity is 158.88694796235134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180140380859375 and perplexity of 177.7077560099283
Finished 28 epochs...
Completing Train Step...
At time: 872.3622288703918 and batch: 50, loss is 5.194126539230346 and perplexity is 180.2106670846217
At time: 873.4340546131134 and batch: 100, loss is 5.197085609436035 and perplexity is 180.7447128501161
At time: 874.506251335144 and batch: 150, loss is 5.159175958633423 and perplexity is 174.02099600554493
At time: 875.5783395767212 and batch: 200, loss is 5.1362944602966305 and perplexity is 170.08434486866113
At time: 876.6500387191772 and batch: 250, loss is 5.161329975128174 and perplexity is 174.39624410157893
At time: 877.724038362503 and batch: 300, loss is 5.166266469955445 and perplexity is 175.25927868876406
At time: 878.7964823246002 and batch: 350, loss is 5.1775361442565915 and perplexity is 177.2455650556458
At time: 879.8684630393982 and batch: 400, loss is 5.204519033432007 and perplexity is 182.09327092811824
At time: 880.9418025016785 and batch: 450, loss is 5.175043811798096 and perplexity is 176.80436022368175
At time: 882.0127346515656 and batch: 500, loss is 5.205365190505981 and perplexity is 182.24741564356083
At time: 883.0849785804749 and batch: 550, loss is 5.184432249069214 and perplexity is 178.47209332283074
At time: 884.1665768623352 and batch: 600, loss is 5.134416379928589 and perplexity is 169.76521257150637
At time: 885.2381539344788 and batch: 650, loss is 5.146038589477539 and perplexity is 171.74976957607456
At time: 886.3107004165649 and batch: 700, loss is 5.1621604251861575 and perplexity is 174.5411316252046
At time: 887.3847615718842 and batch: 750, loss is 5.1368352317810055 and perplexity is 170.17634650599368
At time: 888.4856691360474 and batch: 800, loss is 5.125872249603272 and perplexity is 168.3208954738589
At time: 889.555558681488 and batch: 850, loss is 5.106317987442017 and perplexity is 165.06147618398157
At time: 890.6258461475372 and batch: 900, loss is 5.130163259506226 and perplexity is 169.04471394870845
At time: 891.7052597999573 and batch: 950, loss is 5.1143638610839846 and perplexity is 166.39489703900765
At time: 892.7762980461121 and batch: 1000, loss is 5.13864670753479 and perplexity is 170.48489621233884
At time: 893.8473663330078 and batch: 1050, loss is 5.110086116790772 and perplexity is 165.68462248734915
At time: 894.9188401699066 and batch: 1100, loss is 5.100745220184326 and perplexity is 164.14418529224827
At time: 895.9899525642395 and batch: 1150, loss is 5.117864828109742 and perplexity is 166.97846100985447
At time: 897.0610899925232 and batch: 1200, loss is 5.084513435363769 and perplexity is 161.501339276774
At time: 898.1319015026093 and batch: 1250, loss is 5.097438583374023 and perplexity is 163.6023164623992
At time: 899.2021911144257 and batch: 1300, loss is 5.083311576843261 and perplexity is 161.3073541108034
At time: 900.2730770111084 and batch: 1350, loss is 5.068154010772705 and perplexity is 158.8807642902402
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180059814453125 and perplexity of 177.69343931139412
Finished 29 epochs...
Completing Train Step...
At time: 903.4302232265472 and batch: 50, loss is 5.193122892379761 and perplexity is 180.0298899495363
At time: 904.5269351005554 and batch: 100, loss is 5.196078968048096 and perplexity is 180.56285928752766
At time: 905.5983457565308 and batch: 150, loss is 5.157985706329345 and perplexity is 173.81399033301958
At time: 906.669775724411 and batch: 200, loss is 5.135185012817383 and perplexity is 169.8957498584611
At time: 907.7411270141602 and batch: 250, loss is 5.16023699760437 and perplexity is 174.2057370554648
At time: 908.8129503726959 and batch: 300, loss is 5.165138330459595 and perplexity is 175.0616732586639
At time: 909.88645195961 and batch: 350, loss is 5.176657991409302 and perplexity is 177.0899846796958
At time: 910.9579017162323 and batch: 400, loss is 5.203585882186889 and perplexity is 181.92342962176178
At time: 912.0296499729156 and batch: 450, loss is 5.173978357315064 and perplexity is 176.6160835433892
At time: 913.1009323596954 and batch: 500, loss is 5.204468250274658 and perplexity is 182.0840238916874
At time: 914.1720991134644 and batch: 550, loss is 5.183612289428711 and perplexity is 178.32581338936654
At time: 915.2700123786926 and batch: 600, loss is 5.133815069198608 and perplexity is 169.66316161285278
At time: 916.3396127223969 and batch: 650, loss is 5.145417423248291 and perplexity is 171.6431175470814
At time: 917.4100790023804 and batch: 700, loss is 5.161645383834839 and perplexity is 174.4512588709907
At time: 918.4808619022369 and batch: 750, loss is 5.136433753967285 and perplexity is 170.10803819150544
At time: 919.5518798828125 and batch: 800, loss is 5.125640382766724 and perplexity is 168.28187196460414
At time: 920.6228966712952 and batch: 850, loss is 5.106090412139893 and perplexity is 165.02391654265546
At time: 921.6935687065125 and batch: 900, loss is 5.1299388885498045 and perplexity is 169.00678947929563
At time: 922.7648799419403 and batch: 950, loss is 5.1140851879119875 and perplexity is 166.3485337056543
At time: 923.8359050750732 and batch: 1000, loss is 5.138571243286133 and perplexity is 170.47203118316978
At time: 924.9070611000061 and batch: 1050, loss is 5.110225992202759 and perplexity is 165.70779931307572
At time: 925.9784631729126 and batch: 1100, loss is 5.1009113979339595 and perplexity is 164.17146467012566
At time: 927.0502483844757 and batch: 1150, loss is 5.118043069839477 and perplexity is 167.0082261921935
At time: 928.1221959590912 and batch: 1200, loss is 5.084801464080811 and perplexity is 161.54786300008888
At time: 929.1927132606506 and batch: 1250, loss is 5.09778787612915 and perplexity is 163.65947154760894
At time: 930.2641928195953 and batch: 1300, loss is 5.083603353500366 and perplexity is 161.35442669835942
At time: 931.3355686664581 and batch: 1350, loss is 5.068060655593872 and perplexity is 158.8659326403931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.18001708984375 and perplexity of 177.68584759078874
Finished 30 epochs...
Completing Train Step...
At time: 934.4751410484314 and batch: 50, loss is 5.192171602249146 and perplexity is 179.85871072547388
At time: 935.5724177360535 and batch: 100, loss is 5.195178213119507 and perplexity is 180.40028963080601
At time: 936.6430416107178 and batch: 150, loss is 5.157006788253784 and perplexity is 173.64392393021598
At time: 937.7144594192505 and batch: 200, loss is 5.134172887802124 and perplexity is 169.72388111104434
At time: 938.7859222888947 and batch: 250, loss is 5.159354286193848 and perplexity is 174.0520315123862
At time: 939.8572642803192 and batch: 300, loss is 5.164209814071655 and perplexity is 174.8992010668623
At time: 940.9287016391754 and batch: 350, loss is 5.1759534740448 and perplexity is 176.9652656489296
At time: 942.0018911361694 and batch: 400, loss is 5.202800626754761 and perplexity is 181.78062933510813
At time: 943.1017110347748 and batch: 450, loss is 5.173065137863159 and perplexity is 176.45486792420198
At time: 944.1790449619293 and batch: 500, loss is 5.203638076782227 and perplexity is 181.93292528936237
At time: 945.2504773139954 and batch: 550, loss is 5.182948961257934 and perplexity is 178.20756407715447
At time: 946.3211317062378 and batch: 600, loss is 5.133238162994385 and perplexity is 169.56531011057345
At time: 947.3918840885162 and batch: 650, loss is 5.144808921813965 and perplexity is 171.53870423490878
At time: 948.4656958580017 and batch: 700, loss is 5.161269445419311 and perplexity is 174.38568826717068
At time: 949.5443263053894 and batch: 750, loss is 5.136107025146484 and perplexity is 170.05246807145255
At time: 950.6140093803406 and batch: 800, loss is 5.125406970977783 and perplexity is 168.24259757555365
At time: 951.6870801448822 and batch: 850, loss is 5.1058961868286135 and perplexity is 164.9918678335324
At time: 952.7572200298309 and batch: 900, loss is 5.129670476913452 and perplexity is 168.96143217786283
At time: 953.8279886245728 and batch: 950, loss is 5.113869485855102 and perplexity is 166.3126558543764
At time: 954.8986947536469 and batch: 1000, loss is 5.138400239944458 and perplexity is 170.44288238851695
At time: 955.9697842597961 and batch: 1050, loss is 5.110249614715576 and perplexity is 165.71171379392362
At time: 957.0410921573639 and batch: 1100, loss is 5.101035394668579 and perplexity is 164.19182265779838
At time: 958.1122784614563 and batch: 1150, loss is 5.118163194656372 and perplexity is 167.02828922979492
At time: 959.1828303337097 and batch: 1200, loss is 5.084977779388428 and perplexity is 161.5763488724225
At time: 960.2535936832428 and batch: 1250, loss is 5.098020439147949 and perplexity is 163.69753711451716
At time: 961.3241021633148 and batch: 1300, loss is 5.083821268081665 and perplexity is 161.38959201207226
At time: 962.395435333252 and batch: 1350, loss is 5.067848224639892 and perplexity is 158.832188183078
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180018717447917 and perplexity of 177.68613679325003
Annealing...
Finished 31 epochs...
Completing Train Step...
At time: 965.5791733264923 and batch: 50, loss is 5.191896753311157 and perplexity is 179.8092835426585
At time: 966.6495752334595 and batch: 100, loss is 5.195025014877319 and perplexity is 180.37265474040672
At time: 967.7269756793976 and batch: 150, loss is 5.1569504737854 and perplexity is 173.6341455402868
At time: 968.7977538108826 and batch: 200, loss is 5.134616546630859 and perplexity is 169.7991973154606
At time: 969.9047582149506 and batch: 250, loss is 5.159030523300171 and perplexity is 173.9956890443058
At time: 970.9761061668396 and batch: 300, loss is 5.163907794952393 and perplexity is 174.8463861401567
At time: 972.0532872676849 and batch: 350, loss is 5.1753808212280275 and perplexity is 176.8639550017672
At time: 973.1254386901855 and batch: 400, loss is 5.202104940414428 and perplexity is 181.65421101319117
At time: 974.197779417038 and batch: 450, loss is 5.172002859115601 and perplexity is 176.2675231918839
At time: 975.2698612213135 and batch: 500, loss is 5.201847944259644 and perplexity is 181.60753257780647
At time: 976.3418929576874 and batch: 550, loss is 5.180226516723633 and perplexity is 177.72306368033782
At time: 977.4166507720947 and batch: 600, loss is 5.130492277145386 and perplexity is 169.1003417921734
At time: 978.4880425930023 and batch: 650, loss is 5.142490892410279 and perplexity is 171.14153297978785
At time: 979.567262172699 and batch: 700, loss is 5.157806015014648 and perplexity is 173.78276027455306
At time: 980.6387073993683 and batch: 750, loss is 5.132990427017212 and perplexity is 169.5233078857246
At time: 981.7093815803528 and batch: 800, loss is 5.122522220611573 and perplexity is 167.7579590472594
At time: 982.7803647518158 and batch: 850, loss is 5.101811819076538 and perplexity is 164.3193546995854
At time: 983.8516933917999 and batch: 900, loss is 5.124333534240723 and perplexity is 168.06209668605257
At time: 984.9220545291901 and batch: 950, loss is 5.108019428253174 and perplexity is 165.3425575697728
At time: 985.9918057918549 and batch: 1000, loss is 5.132807054519653 and perplexity is 169.49222482333963
At time: 987.0629644393921 and batch: 1050, loss is 5.104473972320557 and perplexity is 164.75738079035023
At time: 988.1344680786133 and batch: 1100, loss is 5.095046710968018 and perplexity is 163.21146821200537
At time: 989.2110588550568 and batch: 1150, loss is 5.112113809585571 and perplexity is 166.02092084222605
At time: 990.2835445404053 and batch: 1200, loss is 5.07810923576355 and perplexity is 160.4703572952423
At time: 991.354542016983 and batch: 1250, loss is 5.090990171432495 and perplexity is 162.55073548881748
At time: 992.4264175891876 and batch: 1300, loss is 5.077820844650269 and perplexity is 160.42408574272636
At time: 993.4977009296417 and batch: 1350, loss is 5.062925491333008 and perplexity is 158.05222104031753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17748046875 and perplexity of 177.23569709372464
Finished 32 epochs...
Completing Train Step...
At time: 996.6615409851074 and batch: 50, loss is 5.190366106033325 and perplexity is 179.5342694807314
At time: 997.7327077388763 and batch: 100, loss is 5.193575773239136 and perplexity is 180.11144050575896
At time: 998.8038902282715 and batch: 150, loss is 5.155602779388428 and perplexity is 173.40029738853542
At time: 999.8748724460602 and batch: 200, loss is 5.133408536911011 and perplexity is 169.59420207772988
At time: 1000.9462480545044 and batch: 250, loss is 5.1579507637023925 and perplexity is 173.8079169217073
At time: 1002.0172753334045 and batch: 300, loss is 5.162831039428711 and perplexity is 174.65822065037963
At time: 1003.0877592563629 and batch: 350, loss is 5.174335460662842 and perplexity is 176.67916500072351
At time: 1004.158506155014 and batch: 400, loss is 5.201242933273315 and perplexity is 181.49769125635052
At time: 1005.2304351329803 and batch: 450, loss is 5.171237297058106 and perplexity is 176.13263110487955
At time: 1006.3018207550049 and batch: 500, loss is 5.201049318313599 and perplexity is 181.46255398982927
At time: 1007.3807101249695 and batch: 550, loss is 5.179701595306397 and perplexity is 177.6297975187196
At time: 1008.458258152008 and batch: 600, loss is 5.130105094909668 and perplexity is 169.03488181706516
At time: 1009.5293357372284 and batch: 650, loss is 5.142155494689941 and perplexity is 171.08414212469037
At time: 1010.6001873016357 and batch: 700, loss is 5.157564811706543 and perplexity is 173.74084835273342
At time: 1011.6716792583466 and batch: 750, loss is 5.132844848632812 and perplexity is 169.49863075271665
At time: 1012.7439546585083 and batch: 800, loss is 5.122495069503784 and perplexity is 167.75340429466445
At time: 1013.8150949478149 and batch: 850, loss is 5.101863660812378 and perplexity is 164.3278735209785
At time: 1014.8924400806427 and batch: 900, loss is 5.1246111202239994 and perplexity is 168.1087548439384
At time: 1015.9652535915375 and batch: 950, loss is 5.108083715438843 and perplexity is 165.35318731914495
At time: 1017.036749124527 and batch: 1000, loss is 5.1330186557769775 and perplexity is 169.52809338600156
At time: 1018.1084227561951 and batch: 1050, loss is 5.104790954589844 and perplexity is 164.80961423689578
At time: 1019.1801295280457 and batch: 1100, loss is 5.095488996505737 and perplexity is 163.28367024976703
At time: 1020.2503340244293 and batch: 1150, loss is 5.1125875759124755 and perplexity is 166.09959459909962
At time: 1021.322361946106 and batch: 1200, loss is 5.07874454498291 and perplexity is 160.57233798387176
At time: 1022.3936357498169 and batch: 1250, loss is 5.09154260635376 and perplexity is 162.6405590001165
At time: 1023.4652409553528 and batch: 1300, loss is 5.078254337310791 and perplexity is 160.49364348176226
At time: 1024.5366795063019 and batch: 1350, loss is 5.063042278289795 and perplexity is 158.07068055612064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17732421875 and perplexity of 177.20800617946279
Finished 33 epochs...
Completing Train Step...
At time: 1027.6983256340027 and batch: 50, loss is 5.1895684814453125 and perplexity is 179.39112562811997
At time: 1028.795392036438 and batch: 100, loss is 5.1927072715759275 and perplexity is 179.9550813290478
At time: 1029.8661758899689 and batch: 150, loss is 5.154795427322387 and perplexity is 173.2603587976432
At time: 1030.9368438720703 and batch: 200, loss is 5.132617301940918 and perplexity is 169.46006628778287
At time: 1032.0145490169525 and batch: 250, loss is 5.15724404335022 and perplexity is 173.68512672372663
At time: 1033.0852208137512 and batch: 300, loss is 5.1621022796630855 and perplexity is 174.53098313485617
At time: 1034.1557619571686 and batch: 350, loss is 5.173708992004395 and perplexity is 176.5685157040269
At time: 1035.2268934249878 and batch: 400, loss is 5.200746192932129 and perplexity is 181.40755641992934
At time: 1036.29776263237 and batch: 450, loss is 5.170744705200195 and perplexity is 176.04589097038087
At time: 1037.369435787201 and batch: 500, loss is 5.200483417510986 and perplexity is 181.3598932355236
At time: 1038.4500918388367 and batch: 550, loss is 5.179365720748901 and perplexity is 177.57014620731968
At time: 1039.5234851837158 and batch: 600, loss is 5.1298279953002925 and perplexity is 168.98804880634697
At time: 1040.600507736206 and batch: 650, loss is 5.14195595741272 and perplexity is 171.05000786643683
At time: 1041.6735277175903 and batch: 700, loss is 5.157445545196533 and perplexity is 173.7201281237436
At time: 1042.7442314624786 and batch: 750, loss is 5.132801504135132 and perplexity is 169.49128407892917
At time: 1043.815815448761 and batch: 800, loss is 5.122554674148559 and perplexity is 167.7634034747331
At time: 1044.8946025371552 and batch: 850, loss is 5.101944522857666 and perplexity is 164.34116194618665
At time: 1045.9735140800476 and batch: 900, loss is 5.124844245910644 and perplexity is 168.14794988134992
At time: 1047.0447716712952 and batch: 950, loss is 5.108144931793213 and perplexity is 165.3633099482881
At time: 1048.1158246994019 and batch: 1000, loss is 5.133180265426636 and perplexity is 169.5554929757403
At time: 1049.1867332458496 and batch: 1050, loss is 5.105002670288086 and perplexity is 164.84451071338657
At time: 1050.2579798698425 and batch: 1100, loss is 5.095784797668457 and perplexity is 163.3319768935085
At time: 1051.3551704883575 and batch: 1150, loss is 5.112919130325317 and perplexity is 166.15467478319468
At time: 1052.4264566898346 and batch: 1200, loss is 5.079157772064209 and perplexity is 160.63870453371774
At time: 1053.4975790977478 and batch: 1250, loss is 5.09189694404602 and perplexity is 162.69819889185058
At time: 1054.5674154758453 and batch: 1300, loss is 5.078487043380737 and perplexity is 160.53099567266045
At time: 1055.6395027637482 and batch: 1350, loss is 5.0630005264282225 and perplexity is 158.06408094872128
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177231038411458 and perplexity of 177.1914946467417
Finished 34 epochs...
Completing Train Step...
At time: 1058.7773253917694 and batch: 50, loss is 5.188924980163574 and perplexity is 179.27572434326544
At time: 1059.8746149539948 and batch: 100, loss is 5.192008581161499 and perplexity is 179.82939235265007
At time: 1060.9468169212341 and batch: 150, loss is 5.1541589164733885 and perplexity is 173.15011178999748
At time: 1062.0236401557922 and batch: 200, loss is 5.132004423141479 and perplexity is 169.35623962563358
At time: 1063.0942649841309 and batch: 250, loss is 5.156661958694458 and perplexity is 173.58405669503682
At time: 1064.1652047634125 and batch: 300, loss is 5.161523246765137 and perplexity is 174.42995320655865
At time: 1065.2361378669739 and batch: 350, loss is 5.17321967124939 and perplexity is 176.4821381994889
At time: 1066.3068716526031 and batch: 400, loss is 5.200360555648803 and perplexity is 181.33761239007652
At time: 1067.377406835556 and batch: 450, loss is 5.170357646942139 and perplexity is 175.97776413986062
At time: 1068.4541456699371 and batch: 500, loss is 5.200044641494751 and perplexity is 181.28033431961336
At time: 1069.5249998569489 and batch: 550, loss is 5.179098176956177 and perplexity is 177.5226447715692
At time: 1070.599826335907 and batch: 600, loss is 5.129618377685547 and perplexity is 168.95262964700515
At time: 1071.6766214370728 and batch: 650, loss is 5.141811876296997 and perplexity is 171.0253645658188
At time: 1072.7472531795502 and batch: 700, loss is 5.157342653274537 and perplexity is 173.70225464540545
At time: 1073.8177156448364 and batch: 750, loss is 5.132778549194336 and perplexity is 169.48739346119243
At time: 1074.8890647888184 and batch: 800, loss is 5.122616128921509 and perplexity is 167.7737136534045
At time: 1075.960518836975 and batch: 850, loss is 5.102009105682373 and perplexity is 164.35177590537677
At time: 1077.030514717102 and batch: 900, loss is 5.125019426345825 and perplexity is 168.17740869261328
At time: 1078.1527354717255 and batch: 950, loss is 5.108177156448364 and perplexity is 165.36863880978578
At time: 1079.2241036891937 and batch: 1000, loss is 5.133282852172852 and perplexity is 169.5728880143027
At time: 1080.2952826023102 and batch: 1050, loss is 5.1051460552215575 and perplexity is 164.86814862720817
At time: 1081.3665273189545 and batch: 1100, loss is 5.095992336273193 and perplexity is 163.36587810188487
At time: 1082.4374845027924 and batch: 1150, loss is 5.113183307647705 and perplexity is 166.1985748787306
At time: 1083.508610010147 and batch: 1200, loss is 5.079481182098388 and perplexity is 160.69066510447354
At time: 1084.5797672271729 and batch: 1250, loss is 5.092139806747436 and perplexity is 162.73771701449377
At time: 1085.6508402824402 and batch: 1300, loss is 5.078652820587158 and perplexity is 160.55761025865195
At time: 1086.722731590271 and batch: 1350, loss is 5.0629222965240475 and perplexity is 158.05171609447214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177176513671875 and perplexity of 177.18183359002546
Finished 35 epochs...
Completing Train Step...
At time: 1089.877506017685 and batch: 50, loss is 5.188365898132324 and perplexity is 179.17552252027514
At time: 1090.9474694728851 and batch: 100, loss is 5.19141001701355 and perplexity is 179.72178513376477
At time: 1092.0183384418488 and batch: 150, loss is 5.153603439331055 and perplexity is 173.05395756891394
At time: 1093.0895414352417 and batch: 200, loss is 5.131479654312134 and perplexity is 169.26739006480184
At time: 1094.1623198986053 and batch: 250, loss is 5.156151418685913 and perplexity is 173.4954577078368
At time: 1095.2332966327667 and batch: 300, loss is 5.161015939712525 and perplexity is 174.34148610300022
At time: 1096.3049466609955 and batch: 350, loss is 5.172806568145752 and perplexity is 176.40924793709547
At time: 1097.3759291172028 and batch: 400, loss is 5.20001633644104 and perplexity is 181.27520324263182
At time: 1098.447675228119 and batch: 450, loss is 5.170008449554444 and perplexity is 175.9163238923418
At time: 1099.5185644626617 and batch: 500, loss is 5.199662923812866 and perplexity is 181.21114961597806
At time: 1100.5899851322174 and batch: 550, loss is 5.178857479095459 and perplexity is 177.47992059275927
At time: 1101.6608881950378 and batch: 600, loss is 5.129426298141479 and perplexity is 168.92018041944974
At time: 1102.733865737915 and batch: 650, loss is 5.141652784347534 and perplexity is 170.99815797139485
At time: 1103.8099150657654 and batch: 700, loss is 5.157240419387818 and perplexity is 173.68449729649808
At time: 1104.9271657466888 and batch: 750, loss is 5.132767963409424 and perplexity is 169.4855993135961
At time: 1105.9985463619232 and batch: 800, loss is 5.1226660251617435 and perplexity is 167.78208513977714
At time: 1107.0701377391815 and batch: 850, loss is 5.1020406723022464 and perplexity is 164.35696401729746
At time: 1108.1407580375671 and batch: 900, loss is 5.125142021179199 and perplexity is 168.19802763787146
At time: 1109.212163925171 and batch: 950, loss is 5.108176870346069 and perplexity is 165.36859149744552
At time: 1110.2835857868195 and batch: 1000, loss is 5.133331775665283 and perplexity is 169.5811843151464
At time: 1111.3544778823853 and batch: 1050, loss is 5.105253477096557 and perplexity is 164.88586002414013
At time: 1112.4257307052612 and batch: 1100, loss is 5.0961540412902835 and perplexity is 163.39229731999782
At time: 1113.5035541057587 and batch: 1150, loss is 5.113391761779785 and perplexity is 166.23322326958456
At time: 1114.5761716365814 and batch: 1200, loss is 5.0797404956817624 and perplexity is 160.73233977982773
At time: 1115.6471636295319 and batch: 1250, loss is 5.092311582565308 and perplexity is 162.76567382001525
At time: 1116.7182672023773 and batch: 1300, loss is 5.078750066757202 and perplexity is 160.5732246305276
At time: 1117.7895526885986 and batch: 1350, loss is 5.062840003967285 and perplexity is 158.03871014980754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1771484375 and perplexity of 177.1768590722454
Finished 36 epochs...
Completing Train Step...
At time: 1120.9740376472473 and batch: 50, loss is 5.187859554290771 and perplexity is 179.08482106289
At time: 1122.0445029735565 and batch: 100, loss is 5.19085880279541 and perplexity is 179.62274722854792
At time: 1123.1151907444 and batch: 150, loss is 5.153104343414307 and perplexity is 172.96760859531676
At time: 1124.1846787929535 and batch: 200, loss is 5.130997648239136 and perplexity is 169.1858218146053
At time: 1125.2561087608337 and batch: 250, loss is 5.155694179534912 and perplexity is 173.4161469254311
At time: 1126.32674574852 and batch: 300, loss is 5.160545015335083 and perplexity is 174.2594037759963
At time: 1127.397293806076 and batch: 350, loss is 5.172442102432251 and perplexity is 176.34496452993844
At time: 1128.470008134842 and batch: 400, loss is 5.199712905883789 and perplexity is 181.2202071508655
At time: 1129.54673910141 and batch: 450, loss is 5.169686479568481 and perplexity is 175.85969323318315
At time: 1130.620195865631 and batch: 500, loss is 5.199304494857788 and perplexity is 181.14620993179952
At time: 1131.6996138095856 and batch: 550, loss is 5.178633403778076 and perplexity is 177.4401561785016
At time: 1132.8159267902374 and batch: 600, loss is 5.129223461151123 and perplexity is 168.8859206331365
At time: 1133.8872482776642 and batch: 650, loss is 5.141532773971558 and perplexity is 170.9776376495158
At time: 1134.9596073627472 and batch: 700, loss is 5.157141427993775 and perplexity is 173.6673048769519
At time: 1136.0333061218262 and batch: 750, loss is 5.132733135223389 and perplexity is 169.47969654040503
At time: 1137.10551071167 and batch: 800, loss is 5.122706928253174 and perplexity is 167.7889480861029
At time: 1138.1767086982727 and batch: 850, loss is 5.102057962417603 and perplexity is 164.35980579273217
At time: 1139.2477927207947 and batch: 900, loss is 5.1252392578125 and perplexity is 168.21438344298562
At time: 1140.319272518158 and batch: 950, loss is 5.108163232803345 and perplexity is 165.36633629159144
At time: 1141.3903143405914 and batch: 1000, loss is 5.133363723754883 and perplexity is 169.58660219656232
At time: 1142.4618878364563 and batch: 1050, loss is 5.105338554382325 and perplexity is 164.8998886623232
At time: 1143.533317565918 and batch: 1100, loss is 5.096274719238282 and perplexity is 163.4120163569596
At time: 1144.6042816638947 and batch: 1150, loss is 5.113567562103271 and perplexity is 166.26244969294157
At time: 1145.6843838691711 and batch: 1200, loss is 5.079966611862183 and perplexity is 160.7686880718824
At time: 1146.7555842399597 and batch: 1250, loss is 5.09246753692627 and perplexity is 162.79105981613938
At time: 1147.8281302452087 and batch: 1300, loss is 5.0788535881042485 and perplexity is 160.58984824747571
At time: 1148.9001669883728 and batch: 1350, loss is 5.062746286392212 and perplexity is 158.02389983912872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177135823567708 and perplexity of 177.1746241894368
Finished 37 epochs...
Completing Train Step...
At time: 1152.0617744922638 and batch: 50, loss is 5.187390308380127 and perplexity is 179.0008059563621
At time: 1153.1591064929962 and batch: 100, loss is 5.190367412567139 and perplexity is 179.53450404847842
At time: 1154.229703426361 and batch: 150, loss is 5.152644376754761 and perplexity is 172.88806755669688
At time: 1155.3009672164917 and batch: 200, loss is 5.130552978515625 and perplexity is 169.11060672617265
At time: 1156.3719038963318 and batch: 250, loss is 5.1552814102172855 and perplexity is 173.34458083195918
At time: 1157.4448289871216 and batch: 300, loss is 5.160118951797485 and perplexity is 174.18517401238446
At time: 1158.5199964046478 and batch: 350, loss is 5.172115392684937 and perplexity is 176.28736032157724
At time: 1159.617300271988 and batch: 400, loss is 5.199430589675903 and perplexity is 181.16905297035723
At time: 1160.688637971878 and batch: 450, loss is 5.169399957656861 and perplexity is 175.80931279559528
At time: 1161.7630219459534 and batch: 500, loss is 5.198976049423218 and perplexity is 181.08672305578884
At time: 1162.8402798175812 and batch: 550, loss is 5.178431310653687 and perplexity is 177.4043003661759
At time: 1163.9179999828339 and batch: 600, loss is 5.129046764373779 and perplexity is 168.85608167152367
At time: 1164.9900460243225 and batch: 650, loss is 5.141409492492675 and perplexity is 170.95656057272387
At time: 1166.0625176429749 and batch: 700, loss is 5.157029876708984 and perplexity is 173.64793314645755
At time: 1167.1345479488373 and batch: 750, loss is 5.132665910720825 and perplexity is 169.4683037350526
At time: 1168.213104724884 and batch: 800, loss is 5.122734041213989 and perplexity is 167.79349740295
At time: 1169.2881016731262 and batch: 850, loss is 5.102065563201904 and perplexity is 164.36105506091155
At time: 1170.3617565631866 and batch: 900, loss is 5.125326375961304 and perplexity is 168.22903860702954
At time: 1171.4333369731903 and batch: 950, loss is 5.108117542266846 and perplexity is 165.35878078757622
At time: 1172.5055911540985 and batch: 1000, loss is 5.133375930786133 and perplexity is 169.58867235815012
At time: 1173.5778307914734 and batch: 1050, loss is 5.10540319442749 and perplexity is 164.91054814308504
At time: 1174.6515810489655 and batch: 1100, loss is 5.096348552703858 and perplexity is 163.42408207786553
At time: 1175.7288522720337 and batch: 1150, loss is 5.1137150955200195 and perplexity is 166.286980769754
At time: 1176.8003356456757 and batch: 1200, loss is 5.080138492584228 and perplexity is 160.79632348499985
At time: 1177.8755490779877 and batch: 1250, loss is 5.092582378387451 and perplexity is 162.80975605284698
At time: 1178.957772731781 and batch: 1300, loss is 5.078930778503418 and perplexity is 160.6022447204027
At time: 1180.0372536182404 and batch: 1350, loss is 5.062636308670044 and perplexity is 158.00652168619862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177127278645833 and perplexity of 177.17311025258311
Finished 38 epochs...
Completing Train Step...
At time: 1183.221143245697 and batch: 50, loss is 5.186941995620727 and perplexity is 178.92057559659966
At time: 1184.3369398117065 and batch: 100, loss is 5.189907693862915 and perplexity is 179.45198764753357
At time: 1185.4085335731506 and batch: 150, loss is 5.152220220565796 and perplexity is 172.8147515626599
At time: 1186.5065228939056 and batch: 200, loss is 5.13012957572937 and perplexity is 169.03901998018287
At time: 1187.5785248279572 and batch: 250, loss is 5.154876766204834 and perplexity is 173.27445217476205
At time: 1188.6528685092926 and batch: 300, loss is 5.159709005355835 and perplexity is 174.1137820545493
At time: 1189.7378883361816 and batch: 350, loss is 5.171794357299805 and perplexity is 176.23077492440592
At time: 1190.8140439987183 and batch: 400, loss is 5.199151859283448 and perplexity is 181.11856268603725
At time: 1191.8866901397705 and batch: 450, loss is 5.169111223220825 and perplexity is 175.7585579205081
At time: 1192.9637687206268 and batch: 500, loss is 5.198671140670776 and perplexity is 181.03151654587998
At time: 1194.0343887805939 and batch: 550, loss is 5.1782082748413085 and perplexity is 177.36473726608247
At time: 1195.104005098343 and batch: 600, loss is 5.128881978988647 and perplexity is 168.8282589495255
At time: 1196.1733560562134 and batch: 650, loss is 5.141283655166626 and perplexity is 170.93504920976542
At time: 1197.2433931827545 and batch: 700, loss is 5.156891326904297 and perplexity is 173.62387592583593
At time: 1198.3214466571808 and batch: 750, loss is 5.132584638595581 and perplexity is 169.4545312455139
At time: 1199.3937327861786 and batch: 800, loss is 5.1227494239807125 and perplexity is 167.79607855103083
At time: 1200.46599984169 and batch: 850, loss is 5.102071647644043 and perplexity is 164.36205510928326
At time: 1201.5379540920258 and batch: 900, loss is 5.125382614135742 and perplexity is 168.23849976708496
At time: 1202.6174409389496 and batch: 950, loss is 5.107990665435791 and perplexity is 165.33780192037705
At time: 1203.6999707221985 and batch: 1000, loss is 5.1333729267120365 and perplexity is 169.58816290197774
At time: 1204.7802283763885 and batch: 1050, loss is 5.105452060699463 and perplexity is 164.918606903681
At time: 1205.8518280982971 and batch: 1100, loss is 5.0964195346832275 and perplexity is 163.4356826543992
At time: 1206.9232988357544 and batch: 1150, loss is 5.113786745071411 and perplexity is 166.29889558416886
At time: 1208.0020997524261 and batch: 1200, loss is 5.080231590270996 and perplexity is 160.81129394760396
At time: 1209.0794842243195 and batch: 1250, loss is 5.092664480209351 and perplexity is 162.82312357918352
At time: 1210.1617939472198 and batch: 1300, loss is 5.078974647521973 and perplexity is 160.6092903377973
At time: 1211.2331476211548 and batch: 1350, loss is 5.062550935745239 and perplexity is 157.99303278310586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1771333821614585 and perplexity of 177.17419163473005
Annealing...
Finished 39 epochs...
Completing Train Step...
At time: 1214.4075818061829 and batch: 50, loss is 5.186735906600952 and perplexity is 178.88370582991493
At time: 1215.478934764862 and batch: 100, loss is 5.189646739959716 and perplexity is 179.40516506045427
At time: 1216.5507113933563 and batch: 150, loss is 5.152135391235351 and perplexity is 172.80009242476513
At time: 1217.6217873096466 and batch: 200, loss is 5.130294218063354 and perplexity is 169.0668532501712
At time: 1218.6935482025146 and batch: 250, loss is 5.15476770401001 and perplexity is 173.25555551317544
At time: 1219.7653815746307 and batch: 300, loss is 5.159710187911987 and perplexity is 174.1139879539951
At time: 1220.8370196819305 and batch: 350, loss is 5.171687803268433 and perplexity is 176.2119978252914
At time: 1221.9083759784698 and batch: 400, loss is 5.199349422454834 and perplexity is 181.1543485785492
At time: 1222.9799089431763 and batch: 450, loss is 5.169032592773437 and perplexity is 175.7447384897877
At time: 1224.0513288974762 and batch: 500, loss is 5.1983903217315675 and perplexity is 180.9806866047793
At time: 1225.1232883930206 and batch: 550, loss is 5.177323207855225 and perplexity is 177.20782704090578
At time: 1226.1941981315613 and batch: 600, loss is 5.127766838073731 and perplexity is 168.6400965836521
At time: 1227.2648975849152 and batch: 650, loss is 5.14019193649292 and perplexity is 170.74853805193362
At time: 1228.3374679088593 and batch: 700, loss is 5.155553789138794 and perplexity is 173.39180267276058
At time: 1229.4112169742584 and batch: 750, loss is 5.131385889053345 and perplexity is 169.25151940823756
At time: 1230.4822359085083 and batch: 800, loss is 5.1214759731292725 and perplexity is 167.58253448972334
At time: 1231.5540120601654 and batch: 850, loss is 5.100411100387573 and perplexity is 164.08935063160328
At time: 1232.626533985138 and batch: 900, loss is 5.123252544403076 and perplexity is 167.88052142562853
At time: 1233.6986074447632 and batch: 950, loss is 5.105793151855469 and perplexity is 164.97486877662482
At time: 1234.7723898887634 and batch: 1000, loss is 5.131354656219482 and perplexity is 169.24623328620166
At time: 1235.847895860672 and batch: 1050, loss is 5.1031443214416505 and perplexity is 164.53845657281946
At time: 1236.9192938804626 and batch: 1100, loss is 5.0940808582305905 and perplexity is 163.05390607181425
At time: 1237.990226984024 and batch: 1150, loss is 5.111597967147827 and perplexity is 165.9353022904421
At time: 1239.0698764324188 and batch: 1200, loss is 5.077688608169556 and perplexity is 160.40287322877114
At time: 1240.1401689052582 and batch: 1250, loss is 5.090175256729126 and perplexity is 162.41832446359754
At time: 1241.2108302116394 and batch: 1300, loss is 5.076176738739013 and perplexity is 160.16054825618238
At time: 1242.2815699577332 and batch: 1350, loss is 5.060477018356323 and perplexity is 157.66570782487307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177022705078125 and perplexity of 177.15458359705815
Finished 40 epochs...
Completing Train Step...
At time: 1245.4642250537872 and batch: 50, loss is 5.186347761154175 and perplexity is 178.81428640728234
At time: 1246.541954278946 and batch: 100, loss is 5.189241342544555 and perplexity is 179.33244941063634
At time: 1247.6131949424744 and batch: 150, loss is 5.151762342453003 and perplexity is 172.7356415830978
At time: 1248.6878561973572 and batch: 200, loss is 5.12985200881958 and perplexity is 168.99210685284015
At time: 1249.7590103149414 and batch: 250, loss is 5.154419975280762 and perplexity is 173.1953200524287
At time: 1250.8355660438538 and batch: 300, loss is 5.159397449493408 and perplexity is 174.05954433449938
At time: 1251.9089982509613 and batch: 350, loss is 5.171376218795777 and perplexity is 176.15710145574565
At time: 1252.9805479049683 and batch: 400, loss is 5.1990642166137695 and perplexity is 181.1026896672622
At time: 1254.053982257843 and batch: 450, loss is 5.168768215179443 and perplexity is 175.69828166001173
At time: 1255.1310603618622 and batch: 500, loss is 5.198136997222901 and perplexity is 180.93484556784117
At time: 1256.2018139362335 and batch: 550, loss is 5.17719895362854 and perplexity is 177.18580958730354
At time: 1257.2724118232727 and batch: 600, loss is 5.127703399658203 and perplexity is 168.62939866246356
At time: 1258.3429424762726 and batch: 650, loss is 5.139998178482056 and perplexity is 170.71545735977077
At time: 1259.4137091636658 and batch: 700, loss is 5.1554223251342775 and perplexity is 173.36900939031185
At time: 1260.4844326972961 and batch: 750, loss is 5.13133059501648 and perplexity is 169.2421610672166
At time: 1261.554592370987 and batch: 800, loss is 5.121469116210937 and perplexity is 167.58138539390956
At time: 1262.623542547226 and batch: 850, loss is 5.10045334815979 and perplexity is 164.09628318755344
At time: 1263.6957120895386 and batch: 900, loss is 5.1232947254180905 and perplexity is 167.88760294577517
At time: 1264.766722202301 and batch: 950, loss is 5.105824518203735 and perplexity is 164.98004351697
At time: 1265.8525879383087 and batch: 1000, loss is 5.13141547203064 and perplexity is 169.25652644615462
At time: 1266.9233009815216 and batch: 1050, loss is 5.103263359069825 and perplexity is 164.558044006231
At time: 1268.0242247581482 and batch: 1100, loss is 5.0942811679840085 and perplexity is 163.08657063093904
At time: 1269.0949063301086 and batch: 1150, loss is 5.111814479827881 and perplexity is 165.97123327707334
At time: 1270.166265487671 and batch: 1200, loss is 5.077884893417359 and perplexity is 160.43436103668617
At time: 1271.237036705017 and batch: 1250, loss is 5.090322246551514 and perplexity is 162.4422000589547
At time: 1272.3079807758331 and batch: 1300, loss is 5.076219997406006 and perplexity is 160.1674767378621
At time: 1273.378354549408 and batch: 1350, loss is 5.060512962341309 and perplexity is 157.6713750605588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1769970703125 and perplexity of 177.15004233903556
Finished 41 epochs...
Completing Train Step...
At time: 1276.5171954631805 and batch: 50, loss is 5.186115169525147 and perplexity is 178.77270053756345
At time: 1277.6162893772125 and batch: 100, loss is 5.18896255493164 and perplexity is 179.28246071358546
At time: 1278.6888344287872 and batch: 150, loss is 5.151485471725464 and perplexity is 172.68782276046244
At time: 1279.7608075141907 and batch: 200, loss is 5.129587678909302 and perplexity is 168.9474430876426
At time: 1280.8319156169891 and batch: 250, loss is 5.154197378158569 and perplexity is 173.1567715631584
At time: 1281.9033498764038 and batch: 300, loss is 5.159224643707275 and perplexity is 174.02946843682614
At time: 1282.9744291305542 and batch: 350, loss is 5.171212902069092 and perplexity is 176.128334403688
At time: 1284.0546174049377 and batch: 400, loss is 5.198940677642822 and perplexity is 181.08031780927155
At time: 1285.129516363144 and batch: 450, loss is 5.16865026473999 and perplexity is 175.67755919261492
At time: 1286.201102733612 and batch: 500, loss is 5.198017578125 and perplexity is 180.91323978190215
At time: 1287.2713887691498 and batch: 550, loss is 5.177126741409301 and perplexity is 177.17301506874142
At time: 1288.3548719882965 and batch: 600, loss is 5.127646570205688 and perplexity is 168.6198158183562
At time: 1289.426683664322 and batch: 650, loss is 5.139856081008912 and perplexity is 170.69120084808856
At time: 1290.4965221881866 and batch: 700, loss is 5.1553271389007564 and perplexity is 173.35250783267173
At time: 1291.5660104751587 and batch: 750, loss is 5.1312805271148685 and perplexity is 169.23368767947193
At time: 1292.6413855552673 and batch: 800, loss is 5.121460256576538 and perplexity is 167.57990069067978
At time: 1293.7155799865723 and batch: 850, loss is 5.100480842590332 and perplexity is 164.10079498343808
At time: 1294.8128509521484 and batch: 900, loss is 5.123304920196533 and perplexity is 167.8893145314151
At time: 1295.883790254593 and batch: 950, loss is 5.105854082107544 and perplexity is 164.98492104320587
At time: 1296.9538788795471 and batch: 1000, loss is 5.131456890106201 and perplexity is 169.26353687093433
At time: 1298.0314574241638 and batch: 1050, loss is 5.103343076705933 and perplexity is 164.57116270739073
At time: 1299.1030838489532 and batch: 1100, loss is 5.094415311813354 and perplexity is 163.10844915544007
At time: 1300.1745421886444 and batch: 1150, loss is 5.111969022750855 and perplexity is 165.99688493868382
At time: 1301.246841430664 and batch: 1200, loss is 5.078032102584839 and perplexity is 160.4579801838444
At time: 1302.318415403366 and batch: 1250, loss is 5.090422496795655 and perplexity is 162.45848574547776
At time: 1303.3891515731812 and batch: 1300, loss is 5.0762356185913085 and perplexity is 160.1699787632379
At time: 1304.4614312648773 and batch: 1350, loss is 5.060518388748169 and perplexity is 157.67223065191143
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.176986083984375 and perplexity of 177.14809612123406
Finished 42 epochs...
Completing Train Step...
At time: 1307.6347193717957 and batch: 50, loss is 5.185924997329712 and perplexity is 178.73870617311235
At time: 1308.7343075275421 and batch: 100, loss is 5.188727712631225 and perplexity is 179.2403625514955
At time: 1309.8055515289307 and batch: 150, loss is 5.151245260238648 and perplexity is 172.6463461435814
At time: 1310.8775744438171 and batch: 200, loss is 5.1293714809417725 and perplexity is 168.91092094197683
At time: 1311.9492917060852 and batch: 250, loss is 5.154005556106568 and perplexity is 173.12355946142776
At time: 1313.0213508605957 and batch: 300, loss is 5.159073858261109 and perplexity is 174.00322930407117
At time: 1314.0928304195404 and batch: 350, loss is 5.171086044311523 and perplexity is 176.1059925752883
At time: 1315.1642112731934 and batch: 400, loss is 5.1988543510437015 and perplexity is 181.06468643597873
At time: 1316.2363379001617 and batch: 450, loss is 5.16855863571167 and perplexity is 175.66146276602962
At time: 1317.3073403835297 and batch: 500, loss is 5.197921895980835 and perplexity is 180.89593044332247
At time: 1318.384537935257 and batch: 550, loss is 5.177076597213745 and perplexity is 177.1641310931682
At time: 1319.4592502117157 and batch: 600, loss is 5.127595891952515 and perplexity is 168.6112706771683
At time: 1320.5365133285522 and batch: 650, loss is 5.139732990264893 and perplexity is 170.67019163422512
At time: 1321.6088862419128 and batch: 700, loss is 5.155240802764893 and perplexity is 173.3375418930632
At time: 1322.7069437503815 and batch: 750, loss is 5.131229085922241 and perplexity is 169.22498232065394
At time: 1323.7786104679108 and batch: 800, loss is 5.121451253890991 and perplexity is 167.578392028321
At time: 1324.8499805927277 and batch: 850, loss is 5.100497274398804 and perplexity is 164.10349147842547
At time: 1325.921160697937 and batch: 900, loss is 5.1233008861541744 and perplexity is 167.88863726017473
At time: 1326.9927155971527 and batch: 950, loss is 5.105880889892578 and perplexity is 164.98934398278746
At time: 1328.0636439323425 and batch: 1000, loss is 5.131483364105224 and perplexity is 169.26801801296074
At time: 1329.1352977752686 and batch: 1050, loss is 5.103401708602905 and perplexity is 164.5808121097258
At time: 1330.206335067749 and batch: 1100, loss is 5.094515800476074 and perplexity is 163.12484052893382
At time: 1331.2771091461182 and batch: 1150, loss is 5.112094888687134 and perplexity is 166.01777960696188
At time: 1332.3468623161316 and batch: 1200, loss is 5.07815673828125 and perplexity is 160.47798022228287
At time: 1333.4165952205658 and batch: 1250, loss is 5.0905030250549315 and perplexity is 162.47156877130917
At time: 1334.4870657920837 and batch: 1300, loss is 5.076233539581299 and perplexity is 160.169645768595
At time: 1335.5587611198425 and batch: 1350, loss is 5.060509309768677 and perplexity is 157.6707991554612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.176982014973959 and perplexity of 177.14737530525215
Finished 43 epochs...
Completing Train Step...
At time: 1338.7450602054596 and batch: 50, loss is 5.185751352310181 and perplexity is 178.70767178154966
At time: 1339.8215553760529 and batch: 100, loss is 5.188511896133423 and perplexity is 179.20168369810224
At time: 1340.8991703987122 and batch: 150, loss is 5.151027345657349 and perplexity is 172.60872808625925
At time: 1341.971188545227 and batch: 200, loss is 5.129175853729248 and perplexity is 168.87788060124828
At time: 1343.043377161026 and batch: 250, loss is 5.153829860687256 and perplexity is 173.09314511696414
At time: 1344.1232326030731 and batch: 300, loss is 5.158936061859131 and perplexity is 173.97925393703815
At time: 1345.1982867717743 and batch: 350, loss is 5.170976800918579 and perplexity is 176.08675520993825
At time: 1346.2758967876434 and batch: 400, loss is 5.198783760070801 and perplexity is 181.05190535472502
At time: 1347.3476855754852 and batch: 450, loss is 5.168478736877441 and perplexity is 175.64742818061666
At time: 1348.4190526008606 and batch: 500, loss is 5.197839403152466 and perplexity is 180.88100844186727
At time: 1349.5169398784637 and batch: 550, loss is 5.177034177780151 and perplexity is 177.15661605046725
At time: 1350.5890684127808 and batch: 600, loss is 5.127546968460083 and perplexity is 168.6030218267264
At time: 1351.6604323387146 and batch: 650, loss is 5.139619064331055 and perplexity is 170.65074898079715
At time: 1352.733537197113 and batch: 700, loss is 5.155157775878906 and perplexity is 173.3231508141667
At time: 1353.8067164421082 and batch: 750, loss is 5.131180372238159 and perplexity is 169.2167389491105
At time: 1354.8788945674896 and batch: 800, loss is 5.1214408111572265 and perplexity is 167.57664206092554
At time: 1355.9512825012207 and batch: 850, loss is 5.100512523651123 and perplexity is 164.10599395305377
At time: 1357.0307447910309 and batch: 900, loss is 5.123294162750244 and perplexity is 167.88750848084572
At time: 1358.1022441387177 and batch: 950, loss is 5.105897216796875 and perplexity is 164.99203777000724
At time: 1359.1739041805267 and batch: 1000, loss is 5.131502723693847 and perplexity is 169.271295003877
At time: 1360.2457957267761 and batch: 1050, loss is 5.1034488868713375 and perplexity is 164.5885769306223
At time: 1361.3177247047424 and batch: 1100, loss is 5.094598712921143 and perplexity is 163.1383661690277
At time: 1362.3897743225098 and batch: 1150, loss is 5.112204046249389 and perplexity is 166.03590269219282
At time: 1363.461606502533 and batch: 1200, loss is 5.078265018463135 and perplexity is 160.49535774797369
At time: 1364.53319978714 and batch: 1250, loss is 5.090573263168335 and perplexity is 162.4829808685588
At time: 1365.603718996048 and batch: 1300, loss is 5.0762235546112064 and perplexity is 160.16804648745668
At time: 1366.6778628826141 and batch: 1350, loss is 5.060494441986084 and perplexity is 157.66845495772455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.176982421875 and perplexity of 177.14744738671823
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 1369.893530368805 and batch: 50, loss is 5.18570032119751 and perplexity is 178.69855236290488
At time: 1370.965693950653 and batch: 100, loss is 5.1884854125976565 and perplexity is 179.19693786674614
At time: 1372.037982225418 and batch: 150, loss is 5.150938720703125 and perplexity is 172.59343132348135
At time: 1373.109030008316 and batch: 200, loss is 5.129158840179444 and perplexity is 168.8750074134574
At time: 1374.1807720661163 and batch: 250, loss is 5.153709497451782 and perplexity is 173.07231231975615
At time: 1375.2520372867584 and batch: 300, loss is 5.158858804702759 and perplexity is 173.96581331381012
At time: 1376.3509006500244 and batch: 350, loss is 5.1710019779205325 and perplexity is 176.09118860232766
At time: 1377.4230179786682 and batch: 400, loss is 5.199038410186768 and perplexity is 181.09801611422563
At time: 1378.4948983192444 and batch: 450, loss is 5.168617401123047 and perplexity is 175.67178588747043
At time: 1379.5672376155853 and batch: 500, loss is 5.197855348587036 and perplexity is 180.8838926911476
At time: 1380.645523071289 and batch: 550, loss is 5.176762084960938 and perplexity is 177.10841956461996
At time: 1381.7165098190308 and batch: 600, loss is 5.127038621902466 and perplexity is 168.517334842164
At time: 1382.7878985404968 and batch: 650, loss is 5.139276208877564 and perplexity is 170.59225046970658
At time: 1383.8601701259613 and batch: 700, loss is 5.154681034088135 and perplexity is 173.24054011841565
At time: 1384.9328532218933 and batch: 750, loss is 5.130862655639649 and perplexity is 169.16298452218962
At time: 1386.0105724334717 and batch: 800, loss is 5.121050701141358 and perplexity is 167.51128148416865
At time: 1387.0821824073792 and batch: 850, loss is 5.099824295043946 and perplexity is 163.99309036960054
At time: 1388.1538834571838 and batch: 900, loss is 5.122374181747436 and perplexity is 167.73312618771175
At time: 1389.2252597808838 and batch: 950, loss is 5.105131568908692 and perplexity is 164.86576031292455
At time: 1390.2966854572296 and batch: 1000, loss is 5.130719165802002 and perplexity is 169.13871309439799
At time: 1391.3676962852478 and batch: 1050, loss is 5.102571592330933 and perplexity is 164.44424758959644
At time: 1392.4460723400116 and batch: 1100, loss is 5.0936941814422605 and perplexity is 162.9908690993422
At time: 1393.5167825222015 and batch: 1150, loss is 5.1113589477539065 and perplexity is 165.89564527464535
At time: 1394.5885610580444 and batch: 1200, loss is 5.077305126190185 and perplexity is 160.34137341023842
At time: 1395.6598477363586 and batch: 1250, loss is 5.089773082733155 and perplexity is 162.3530171703568
At time: 1396.7320263385773 and batch: 1300, loss is 5.075197620391846 and perplexity is 160.0038088706182
At time: 1397.804232120514 and batch: 1350, loss is 5.059773502349853 and perplexity is 157.55482648371927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.177663167317708 and perplexity of 177.26808075986506
Annealing...
Finished 45 epochs...
Completing Train Step...
At time: 1400.9394264221191 and batch: 50, loss is 5.185575008392334 and perplexity is 178.67616054904715
At time: 1402.0453255176544 and batch: 100, loss is 5.188514490127563 and perplexity is 179.20214854682263
At time: 1403.118032693863 and batch: 150, loss is 5.150846290588379 and perplexity is 172.57747923005797
At time: 1404.22047996521 and batch: 200, loss is 5.12901123046875 and perplexity is 168.85008166215647
At time: 1405.2937860488892 and batch: 250, loss is 5.153639030456543 and perplexity is 173.06011686364155
At time: 1406.3713545799255 and batch: 300, loss is 5.158782873153687 and perplexity is 173.95260432161552
At time: 1407.442390680313 and batch: 350, loss is 5.170939960479736 and perplexity is 176.0802682160945
At time: 1408.5141456127167 and batch: 400, loss is 5.199116468429565 and perplexity is 181.11215285887516
At time: 1409.5853037834167 and batch: 450, loss is 5.168610906600952 and perplexity is 175.6706449868803
At time: 1410.6561088562012 and batch: 500, loss is 5.197837028503418 and perplexity is 180.88057891346273
At time: 1411.7308526039124 and batch: 550, loss is 5.176658592224121 and perplexity is 177.0900910780149
At time: 1412.8102564811707 and batch: 600, loss is 5.126797008514404 and perplexity is 168.47662371632018
At time: 1413.883437871933 and batch: 650, loss is 5.139153976440429 and perplexity is 170.57139983751313
At time: 1414.9554297924042 and batch: 700, loss is 5.154517908096313 and perplexity is 173.21228238833285
At time: 1416.0270471572876 and batch: 750, loss is 5.130797414779663 and perplexity is 169.15194854360394
At time: 1417.0990772247314 and batch: 800, loss is 5.120939102172851 and perplexity is 167.4925884410234
At time: 1418.1746773719788 and batch: 850, loss is 5.099538278579712 and perplexity is 163.94619235285646
At time: 1419.246328830719 and batch: 900, loss is 5.122022171020507 and perplexity is 167.67409271884904
At time: 1420.3246347904205 and batch: 950, loss is 5.104864311218262 and perplexity is 164.82170455797424
At time: 1421.405365228653 and batch: 1000, loss is 5.130431032180786 and perplexity is 169.08998556486307
At time: 1422.4767582416534 and batch: 1050, loss is 5.102237844467163 and perplexity is 164.38937383076347
At time: 1423.54776263237 and batch: 1100, loss is 5.093339672088623 and perplexity is 162.93309755257093
At time: 1424.6186583042145 and batch: 1150, loss is 5.111053228378296 and perplexity is 165.84493551342868
At time: 1425.6898317337036 and batch: 1200, loss is 5.076957197189331 and perplexity is 160.28559570029626
At time: 1426.7605085372925 and batch: 1250, loss is 5.0894365406036375 and perplexity is 162.2983877332939
At time: 1427.8316822052002 and batch: 1300, loss is 5.074861917495728 and perplexity is 159.950104143511
At time: 1428.9076435565948 and batch: 1350, loss is 5.059512166976929 and perplexity is 157.51365721411165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.178053792317709 and perplexity of 177.33733963015442
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 1432.0678305625916 and batch: 50, loss is 5.185525112152099 and perplexity is 178.6672455028317
At time: 1433.1650803089142 and batch: 100, loss is 5.188502912521362 and perplexity is 179.20007382692657
At time: 1434.235140323639 and batch: 150, loss is 5.150806922912597 and perplexity is 172.5706853895382
At time: 1435.3046555519104 and batch: 200, loss is 5.1289684009552 and perplexity is 168.84285005016034
At time: 1436.3752582073212 and batch: 250, loss is 5.153612279891968 and perplexity is 173.05548746972977
At time: 1437.4467370510101 and batch: 300, loss is 5.158749446868897 and perplexity is 173.9467898295025
At time: 1438.5182332992554 and batch: 350, loss is 5.170902004241944 and perplexity is 176.07358499839918
At time: 1439.5895292758942 and batch: 400, loss is 5.199086399078369 and perplexity is 181.1067070158218
At time: 1440.6617424488068 and batch: 450, loss is 5.168559160232544 and perplexity is 175.66155490415773
At time: 1441.7322545051575 and batch: 500, loss is 5.197813510894775 and perplexity is 180.87632508481693
At time: 1442.8036425113678 and batch: 550, loss is 5.176600093841553 and perplexity is 177.0797318971186
At time: 1443.875018119812 and batch: 600, loss is 5.126699647903442 and perplexity is 168.46022152777886
At time: 1444.9462831020355 and batch: 650, loss is 5.1390972995758055 and perplexity is 170.56173265933114
At time: 1446.017154932022 and batch: 700, loss is 5.154464960098267 and perplexity is 173.20311138753854
At time: 1447.0883400440216 and batch: 750, loss is 5.130776844024658 and perplexity is 169.14846899610038
At time: 1448.1668875217438 and batch: 800, loss is 5.120878667831421 and perplexity is 167.4824664426077
At time: 1449.239752292633 and batch: 850, loss is 5.099417400360108 and perplexity is 163.92637602671917
At time: 1450.3124470710754 and batch: 900, loss is 5.121890773773194 and perplexity is 167.652062252023
At time: 1451.3837475776672 and batch: 950, loss is 5.104764261245728 and perplexity is 164.80521497586503
At time: 1452.4584794044495 and batch: 1000, loss is 5.130329751968384 and perplexity is 169.0728609624164
At time: 1453.5302593708038 and batch: 1050, loss is 5.102120389938355 and perplexity is 164.37006668819689
At time: 1454.6011316776276 and batch: 1100, loss is 5.093218927383423 and perplexity is 162.91342543141567
At time: 1455.6717309951782 and batch: 1150, loss is 5.110946731567383 and perplexity is 165.8272744971281
At time: 1456.742460012436 and batch: 1200, loss is 5.076829719543457 and perplexity is 160.2651641721981
At time: 1457.8488097190857 and batch: 1250, loss is 5.089296064376831 and perplexity is 162.2755902694567
At time: 1458.9200899600983 and batch: 1300, loss is 5.074737071990967 and perplexity is 159.93013633849392
At time: 1459.990794658661 and batch: 1350, loss is 5.059418497085571 and perplexity is 157.49890361794766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17815673828125 and perplexity of 177.3555967331859
Annealing...
Finished 47 epochs...
Completing Train Step...
At time: 1463.1662290096283 and batch: 50, loss is 5.185510330200195 and perplexity is 178.66460447172165
At time: 1464.2435703277588 and batch: 100, loss is 5.188495264053345 and perplexity is 179.19870322613474
At time: 1465.3150796890259 and batch: 150, loss is 5.1507933235168455 and perplexity is 172.5683385484503
At time: 1466.3852500915527 and batch: 200, loss is 5.128953008651734 and perplexity is 168.8402511897755
At time: 1467.4566860198975 and batch: 250, loss is 5.153603477478027 and perplexity is 173.05396417039867
At time: 1468.5268385410309 and batch: 300, loss is 5.158737392425537 and perplexity is 173.9446930104149
At time: 1469.5968837738037 and batch: 350, loss is 5.170886735916138 and perplexity is 176.07089667006088
At time: 1470.6672387123108 and batch: 400, loss is 5.199066581726075 and perplexity is 181.10311799596855
At time: 1471.7382593154907 and batch: 450, loss is 5.1685362148284915 and perplexity is 175.6575243250458
At time: 1472.8088128566742 and batch: 500, loss is 5.197803058624268 and perplexity is 180.874434526419
At time: 1473.8793938159943 and batch: 550, loss is 5.176577339172363 and perplexity is 177.07570255224243
At time: 1474.950540304184 and batch: 600, loss is 5.126662893295288 and perplexity is 168.4540299521322
At time: 1476.0216448307037 and batch: 650, loss is 5.139076433181763 and perplexity is 170.5581736881404
At time: 1477.0925908088684 and batch: 700, loss is 5.154444169998169 and perplexity is 173.19951051494698
At time: 1478.1644639968872 and batch: 750, loss is 5.130767288208008 and perplexity is 169.1468526520668
At time: 1479.2356083393097 and batch: 800, loss is 5.120855360031128 and perplexity is 167.47856284021972
At time: 1480.3068296909332 and batch: 850, loss is 5.099374256134033 and perplexity is 163.91930370265837
At time: 1481.3790719509125 and batch: 900, loss is 5.121845397949219 and perplexity is 167.64445507414953
At time: 1482.4599044322968 and batch: 950, loss is 5.104728202819825 and perplexity is 164.7992724663718
At time: 1483.530723810196 and batch: 1000, loss is 5.130294733047485 and perplexity is 169.06694031694008
At time: 1484.6078369617462 and batch: 1050, loss is 5.102079029083252 and perplexity is 164.36326834227904
At time: 1485.7239618301392 and batch: 1100, loss is 5.093176288604736 and perplexity is 162.90647915001517
At time: 1486.7948234081268 and batch: 1150, loss is 5.110909576416016 and perplexity is 165.82111327410462
At time: 1487.8657133579254 and batch: 1200, loss is 5.07678373336792 and perplexity is 160.2577943596821
At time: 1488.943915605545 and batch: 1250, loss is 5.089244728088379 and perplexity is 162.26725985677393
At time: 1490.0158245563507 and batch: 1300, loss is 5.074692850112915 and perplexity is 159.9230640838833
At time: 1491.087287902832 and batch: 1350, loss is 5.059385766983032 and perplexity is 157.49374874704273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.178190104166666 and perplexity of 177.36151445842899
Annealing...
Model not improving. Stopping early with 177.14737530525215loss at 47 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1fcab0630>
SETTINGS FOR THIS RUN
{'dropout': 0.07444705983629185, 'data': 'wikitext', 'wordvec_source': '', 'lr': 3.543538552399709, 'wordvec_dim': 200, 'anneal': 5.777949298810614, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5391550064086914 and batch: 50, loss is 7.325371723175049 and perplexity is 1518.3381952708348
At time: 2.608193874359131 and batch: 100, loss is 6.426853322982788 and perplexity is 618.2255280357109
At time: 3.67681884765625 and batch: 150, loss is 6.1831129455566405 and perplexity is 484.49782664728417
At time: 4.746114253997803 and batch: 200, loss is 5.994308815002442 and perplexity is 401.1393266648283
At time: 5.8149940967559814 and batch: 250, loss is 5.924761791229248 and perplexity is 374.1892895723414
At time: 6.884066343307495 and batch: 300, loss is 5.833066873550415 and perplexity is 341.4041183979319
At time: 7.95347785949707 and batch: 350, loss is 5.7810377025604245 and perplexity is 324.09533053466623
At time: 9.022423267364502 and batch: 400, loss is 5.777774124145508 and perplexity is 323.0393440941059
At time: 10.091570377349854 and batch: 450, loss is 5.6956949806213375 and perplexity is 297.58353652773354
At time: 11.16046404838562 and batch: 500, loss is 5.676709432601928 and perplexity is 291.98704434484597
At time: 12.262655258178711 and batch: 550, loss is 5.618723030090332 and perplexity is 275.53730563808614
At time: 13.334748983383179 and batch: 600, loss is 5.538982667922974 and perplexity is 254.41903910706324
At time: 14.409285545349121 and batch: 650, loss is 5.546931324005127 and perplexity is 256.44938712879014
At time: 15.484509944915771 and batch: 700, loss is 5.537536993026733 and perplexity is 254.0514976258596
At time: 16.559402227401733 and batch: 750, loss is 5.496675138473511 and perplexity is 243.8797164735432
At time: 17.633535861968994 and batch: 800, loss is 5.43574854850769 and perplexity is 229.4645493504235
At time: 18.713077306747437 and batch: 850, loss is 5.417110300064087 and perplexity is 225.22734179509905
At time: 19.79012703895569 and batch: 900, loss is 5.447224941253662 and perplexity is 232.11314372474385
At time: 20.86499524116516 and batch: 950, loss is 5.400811309814453 and perplexity is 221.58611828981233
At time: 21.93923568725586 and batch: 1000, loss is 5.414521894454956 and perplexity is 224.6451159236912
At time: 23.013123512268066 and batch: 1050, loss is 5.36379153251648 and perplexity is 213.53303097238273
At time: 24.08820652961731 and batch: 1100, loss is 5.329790048599243 and perplexity is 206.39463676399694
At time: 25.163459062576294 and batch: 1150, loss is 5.331433382034302 and perplexity is 206.73409081310976
At time: 26.238765239715576 and batch: 1200, loss is 5.310000810623169 and perplexity is 202.35039241799745
At time: 27.315189838409424 and batch: 1250, loss is 5.336658115386963 and perplexity is 207.8170479300661
At time: 28.397323846817017 and batch: 1300, loss is 5.289725999832154 and perplexity is 198.28908672227246
At time: 29.473399877548218 and batch: 1350, loss is 5.2552798557281495 and perplexity is 191.57509173986435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.988420003255208 and perplexity of 146.70444773361322
Finished 1 epochs...
Completing Train Step...
At time: 32.669504165649414 and batch: 50, loss is 5.260953168869019 and perplexity is 192.6650461280907
At time: 33.74110984802246 and batch: 100, loss is 5.253234205245971 and perplexity is 191.18359662867852
At time: 34.81146287918091 and batch: 150, loss is 5.178150463104248 and perplexity is 177.35448379891602
At time: 35.881359338760376 and batch: 200, loss is 5.157160043716431 and perplexity is 173.67053784942584
At time: 36.9514274597168 and batch: 250, loss is 5.180480194091797 and perplexity is 177.76815371831358
At time: 38.021085262298584 and batch: 300, loss is 5.14021297454834 and perplexity is 170.7521303069269
At time: 39.09143400192261 and batch: 350, loss is 5.138301439285279 and perplexity is 170.42604335125225
At time: 40.161508560180664 and batch: 400, loss is 5.163265180587769 and perplexity is 174.73406343477774
At time: 41.23096704483032 and batch: 450, loss is 5.112588272094727 and perplexity is 166.0997102347296
At time: 42.30077505111694 and batch: 500, loss is 5.149581003189087 and perplexity is 172.35925720608878
At time: 43.37028908729553 and batch: 550, loss is 5.118646545410156 and perplexity is 167.1090419936799
At time: 44.4407901763916 and batch: 600, loss is 5.052447948455811 and perplexity is 156.40486729763103
At time: 45.50989317893982 and batch: 650, loss is 5.082907361984253 and perplexity is 161.24216445760533
At time: 46.579505920410156 and batch: 700, loss is 5.0825010013580325 and perplexity is 161.17665530175546
At time: 47.64903974533081 and batch: 750, loss is 5.04081805229187 and perplexity is 154.59643127620973
At time: 48.74562382698059 and batch: 800, loss is 4.993451166152954 and perplexity is 147.4444015612611
At time: 49.815582036972046 and batch: 850, loss is 4.974082078933716 and perplexity is 144.6160181147694
At time: 50.8858003616333 and batch: 900, loss is 5.023211688995361 and perplexity is 151.898371548622
At time: 51.95605158805847 and batch: 950, loss is 4.977527780532837 and perplexity is 145.11518124937717
At time: 53.03374528884888 and batch: 1000, loss is 5.001027593612671 and perplexity is 148.56574590209
At time: 54.10399127006531 and batch: 1050, loss is 4.945238265991211 and perplexity is 140.50432426559027
At time: 55.173471212387085 and batch: 1100, loss is 4.907463293075562 and perplexity is 135.29577300974066
At time: 56.24455165863037 and batch: 1150, loss is 4.927147159576416 and perplexity is 137.9853002528146
At time: 57.31264019012451 and batch: 1200, loss is 4.904771032333374 and perplexity is 134.93201140175108
At time: 58.38218545913696 and batch: 1250, loss is 4.953457584381104 and perplexity is 141.66393311071946
At time: 59.452783823013306 and batch: 1300, loss is 4.9196609687805175 and perplexity is 136.95617289624704
At time: 60.52377128601074 and batch: 1350, loss is 4.890465602874756 and perplexity is 133.01549203104628
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.799916585286458 and perplexity of 121.50028218478906
Finished 2 epochs...
Completing Train Step...
At time: 63.67689514160156 and batch: 50, loss is 4.947812566757202 and perplexity is 140.866490617724
At time: 64.79779481887817 and batch: 100, loss is 4.957544565200806 and perplexity is 142.24409563718788
At time: 65.86844110488892 and batch: 150, loss is 4.894555339813232 and perplexity is 133.56060432534488
At time: 66.94006967544556 and batch: 200, loss is 4.884570817947388 and perplexity is 132.2337008228677
At time: 68.01527118682861 and batch: 250, loss is 4.912677745819092 and perplexity is 136.00310900682942
At time: 69.08992147445679 and batch: 300, loss is 4.8816123294830325 and perplexity is 131.84306707203046
At time: 70.16029191017151 and batch: 350, loss is 4.882111091613769 and perplexity is 131.90884180269504
At time: 71.23113822937012 and batch: 400, loss is 4.910797777175904 and perplexity is 135.7476676126595
At time: 72.30148363113403 and batch: 450, loss is 4.858823556900024 and perplexity is 128.8725017260089
At time: 73.372483253479 and batch: 500, loss is 4.912545299530029 and perplexity is 135.98509709257232
At time: 74.44312119483948 and batch: 550, loss is 4.891188154220581 and perplexity is 133.11163728458703
At time: 75.5134482383728 and batch: 600, loss is 4.830662021636963 and perplexity is 125.29388046422908
At time: 76.63503670692444 and batch: 650, loss is 4.857994441986084 and perplexity is 128.76569589610278
At time: 77.70570206642151 and batch: 700, loss is 4.8681793117523195 and perplexity is 130.08385900438296
At time: 78.77654790878296 and batch: 750, loss is 4.821128931045532 and perplexity is 124.10511784494611
At time: 79.84643292427063 and batch: 800, loss is 4.784410371780395 and perplexity is 119.63080458594443
At time: 80.91729998588562 and batch: 850, loss is 4.761042547225952 and perplexity is 116.86770250808017
At time: 81.98796796798706 and batch: 900, loss is 4.81135326385498 and perplexity is 122.89781821044599
At time: 83.05880093574524 and batch: 950, loss is 4.769636573791504 and perplexity is 117.87639480401765
At time: 84.12962818145752 and batch: 1000, loss is 4.792411241531372 and perplexity is 120.5917943221091
At time: 85.20071864128113 and batch: 1050, loss is 4.73672080039978 and perplexity is 114.05956368385299
At time: 86.27123641967773 and batch: 1100, loss is 4.70509126663208 and perplexity is 110.5083702140069
At time: 87.34217524528503 and batch: 1150, loss is 4.7284158420562745 and perplexity is 113.11622636933899
At time: 88.41320419311523 and batch: 1200, loss is 4.704279737472534 and perplexity is 110.4187258286405
At time: 89.48396635055542 and batch: 1250, loss is 4.761418352127075 and perplexity is 116.91163021707284
At time: 90.55477213859558 and batch: 1300, loss is 4.736070337295533 and perplexity is 113.98539627018815
At time: 91.62458920478821 and batch: 1350, loss is 4.706904897689819 and perplexity is 110.70897348153895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.720762125651041 and perplexity of 112.25377155432898
Finished 3 epochs...
Completing Train Step...
At time: 94.83908271789551 and batch: 50, loss is 4.772862148284912 and perplexity is 118.25722776882853
At time: 95.91161632537842 and batch: 100, loss is 4.7815772151947025 and perplexity is 119.29235145582791
At time: 96.98285675048828 and batch: 150, loss is 4.729460830688477 and perplexity is 113.23449332306134
At time: 98.05407118797302 and batch: 200, loss is 4.719776592254639 and perplexity is 112.14319621038712
At time: 99.12482857704163 and batch: 250, loss is 4.745388097763062 and perplexity is 115.05244843751093
At time: 100.19570064544678 and batch: 300, loss is 4.718755655288696 and perplexity is 112.02876350012853
At time: 101.26616525650024 and batch: 350, loss is 4.72742036819458 and perplexity is 113.00367815135371
At time: 102.33684182167053 and batch: 400, loss is 4.750605936050415 and perplexity is 115.65434243520663
At time: 103.43325018882751 and batch: 450, loss is 4.6950041198730466 and perplexity is 109.39925935194427
At time: 104.50316786766052 and batch: 500, loss is 4.758184938430786 and perplexity is 116.53421704595189
At time: 105.57348680496216 and batch: 550, loss is 4.74626522064209 and perplexity is 115.15340784275303
At time: 106.64369440078735 and batch: 600, loss is 4.688405313491821 and perplexity is 108.67973144484354
At time: 107.7141923904419 and batch: 650, loss is 4.713056240081787 and perplexity is 111.39208114383926
At time: 108.78477740287781 and batch: 700, loss is 4.72494255065918 and perplexity is 112.72402226727309
At time: 109.85666155815125 and batch: 750, loss is 4.675966415405274 and perplexity is 107.33624838836077
At time: 110.92659544944763 and batch: 800, loss is 4.641076231002808 and perplexity is 103.65584520815395
At time: 111.99752283096313 and batch: 850, loss is 4.616577405929565 and perplexity is 101.14725303754497
At time: 113.0687747001648 and batch: 900, loss is 4.66787091255188 and perplexity is 106.47081526790598
At time: 114.139657497406 and batch: 950, loss is 4.628785133361816 and perplexity is 102.38959881373754
At time: 115.21077418327332 and batch: 1000, loss is 4.653522624969482 and perplexity is 104.95404891296347
At time: 116.28165054321289 and batch: 1050, loss is 4.595081777572632 and perplexity is 98.99623088811646
At time: 117.35256624221802 and batch: 1100, loss is 4.569320592880249 and perplexity is 96.4785392943422
At time: 118.42347407341003 and batch: 1150, loss is 4.591639757156372 and perplexity is 98.65606959715943
At time: 119.49432730674744 and batch: 1200, loss is 4.567051467895507 and perplexity is 96.25986562311137
At time: 120.56755018234253 and batch: 1250, loss is 4.628987646102905 and perplexity is 102.41033611176492
At time: 121.6401116847992 and batch: 1300, loss is 4.606975774765015 and perplexity is 100.18072198338643
At time: 122.71187710762024 and batch: 1350, loss is 4.577879247665405 and perplexity is 97.30780946284983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.680737711588542 and perplexity of 107.84960513527447
Finished 4 epochs...
Completing Train Step...
At time: 125.90030694007874 and batch: 50, loss is 4.648643131256104 and perplexity is 104.44317371090554
At time: 126.96869492530823 and batch: 100, loss is 4.6560262966156 and perplexity is 105.21714860956352
At time: 128.03836107254028 and batch: 150, loss is 4.610230646133423 and perplexity is 100.50732858993852
At time: 129.1077060699463 and batch: 200, loss is 4.600332918167115 and perplexity is 99.51744129171333
At time: 130.2030098438263 and batch: 250, loss is 4.622907142639161 and perplexity is 101.78951906119048
At time: 131.2726776599884 and batch: 300, loss is 4.6038901996612545 and perplexity is 99.87208325062592
At time: 132.34418106079102 and batch: 350, loss is 4.6134865093231205 and perplexity is 100.83510000127679
At time: 133.4157280921936 and batch: 400, loss is 4.635338773727417 and perplexity is 103.06282705983968
At time: 134.48691201210022 and batch: 450, loss is 4.572608623504639 and perplexity is 96.79628577995922
At time: 135.557608127594 and batch: 500, loss is 4.641923351287842 and perplexity is 103.74369138017595
At time: 136.62873125076294 and batch: 550, loss is 4.636172943115234 and perplexity is 103.14883478271234
At time: 137.69942212104797 and batch: 600, loss is 4.580123872756958 and perplexity is 97.52647433209124
At time: 138.77024865150452 and batch: 650, loss is 4.599660625457764 and perplexity is 99.45055892626212
At time: 139.8410723209381 and batch: 700, loss is 4.614311723709107 and perplexity is 100.91834491913808
At time: 140.91180181503296 and batch: 750, loss is 4.567252607345581 and perplexity is 96.27922922687397
At time: 141.98903012275696 and batch: 800, loss is 4.533373212814331 and perplexity is 93.07198377251895
At time: 143.05963587760925 and batch: 850, loss is 4.5103201484680175 and perplexity is 90.95093165145013
At time: 144.13066220283508 and batch: 900, loss is 4.560779867172241 and perplexity is 95.6580513223442
At time: 145.2013680934906 and batch: 950, loss is 4.523822717666626 and perplexity is 92.1873314014303
At time: 146.27232265472412 and batch: 1000, loss is 4.5461892318725585 and perplexity is 94.27247240122941
At time: 147.34494757652283 and batch: 1050, loss is 4.4887184810638425 and perplexity is 89.0073082085608
At time: 148.41621327400208 and batch: 1100, loss is 4.464154329299927 and perplexity is 86.84755404426615
At time: 149.4867970943451 and batch: 1150, loss is 4.484498615264893 and perplexity is 88.63250068770544
At time: 150.55771660804749 and batch: 1200, loss is 4.46213191986084 and perplexity is 86.67209022085775
At time: 151.63377404212952 and batch: 1250, loss is 4.5248244094848635 and perplexity is 92.27972096224866
At time: 152.7081880569458 and batch: 1300, loss is 4.506308860778809 and perplexity is 90.58683204134623
At time: 153.77892565727234 and batch: 1350, loss is 4.4763319778442385 and perplexity is 87.91161878798714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6604911295572915 and perplexity of 105.68797590115588
Finished 5 epochs...
Completing Train Step...
At time: 156.9470841884613 and batch: 50, loss is 4.549138164520263 and perplexity is 94.55088588241368
At time: 158.0434455871582 and batch: 100, loss is 4.555369215011597 and perplexity is 95.14187656057646
At time: 159.114577293396 and batch: 150, loss is 4.516250057220459 and perplexity is 91.49186463360063
At time: 160.1852867603302 and batch: 200, loss is 4.50308126449585 and perplexity is 90.29492565036402
At time: 161.25519132614136 and batch: 250, loss is 4.526167659759522 and perplexity is 92.40375901119788
At time: 162.32725548744202 and batch: 300, loss is 4.509572067260742 and perplexity is 90.88291841158262
At time: 163.39840006828308 and batch: 350, loss is 4.5210706615448 and perplexity is 91.93397547646023
At time: 164.46943187713623 and batch: 400, loss is 4.54439902305603 and perplexity is 94.10385596432928
At time: 165.54050993919373 and batch: 450, loss is 4.476127128601075 and perplexity is 87.89361200381413
At time: 166.61240005493164 and batch: 500, loss is 4.549045152664185 and perplexity is 94.54209193800078
At time: 167.68360233306885 and batch: 550, loss is 4.547366046905518 and perplexity is 94.38347896823281
At time: 168.75544810295105 and batch: 600, loss is 4.487809419631958 and perplexity is 88.92643186386503
At time: 169.8266785144806 and batch: 650, loss is 4.507908325195313 and perplexity is 90.73183839113453
At time: 170.8985254764557 and batch: 700, loss is 4.525148544311524 and perplexity is 92.30963688174077
At time: 171.9699101448059 and batch: 750, loss is 4.478003435134887 and perplexity is 88.05868217498983
At time: 173.04175972938538 and batch: 800, loss is 4.448454399108886 and perplexity is 85.49470114491251
At time: 174.11256289482117 and batch: 850, loss is 4.421111335754395 and perplexity is 83.188684565081
At time: 175.18367099761963 and batch: 900, loss is 4.472634878158569 and perplexity is 87.58720084206904
At time: 176.25456595420837 and batch: 950, loss is 4.437155389785767 and perplexity is 84.53413267508202
At time: 177.32598614692688 and batch: 1000, loss is 4.4612123394012455 and perplexity is 86.59242489525073
At time: 178.39726090431213 and batch: 1050, loss is 4.401672525405884 and perplexity is 81.58721129861785
At time: 179.46842288970947 and batch: 1100, loss is 4.375396375656128 and perplexity is 79.47133381215316
At time: 180.54000186920166 and batch: 1150, loss is 4.400012655258179 and perplexity is 81.45189945326239
At time: 181.61131501197815 and batch: 1200, loss is 4.378071193695068 and perplexity is 79.68418971791164
At time: 182.68272161483765 and batch: 1250, loss is 4.4395942115783695 and perplexity is 84.74054796280917
At time: 183.75408458709717 and batch: 1300, loss is 4.421982288360596 and perplexity is 83.2611695276109
At time: 184.8252534866333 and batch: 1350, loss is 4.393788442611695 and perplexity is 80.94649999907391
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.648221028645834 and perplexity of 104.39909727770046
Finished 6 epochs...
Completing Train Step...
At time: 188.15823817253113 and batch: 50, loss is 4.465606651306152 and perplexity is 86.97377629368067
At time: 189.22967386245728 and batch: 100, loss is 4.474497747421265 and perplexity is 87.75051641687624
At time: 190.30100274085999 and batch: 150, loss is 4.4387539291381835 and perplexity is 84.66937187657996
At time: 191.37283372879028 and batch: 200, loss is 4.424739980697632 and perplexity is 83.4910951030759
At time: 192.44484734535217 and batch: 250, loss is 4.447295045852661 and perplexity is 85.39564001926509
At time: 193.5175383090973 and batch: 300, loss is 4.4309465694427494 and perplexity is 84.01090143768036
At time: 194.58807706832886 and batch: 350, loss is 4.44303599357605 and perplexity is 85.03270894405578
At time: 195.65877652168274 and batch: 400, loss is 4.4656795883178715 and perplexity is 86.98012013236898
At time: 196.72957468032837 and batch: 450, loss is 4.3964556789398195 and perplexity is 81.1626916334282
At time: 197.83117294311523 and batch: 500, loss is 4.469994802474975 and perplexity is 87.356268975867
At time: 198.90304589271545 and batch: 550, loss is 4.47119647026062 and perplexity is 87.46130528690563
At time: 199.97431182861328 and batch: 600, loss is 4.411595344543457 and perplexity is 82.40081639259401
At time: 201.04575777053833 and batch: 650, loss is 4.428993330001831 and perplexity is 83.84696818409257
At time: 202.11700558662415 and batch: 700, loss is 4.450512809753418 and perplexity is 85.67086559498834
At time: 203.19184255599976 and batch: 750, loss is 4.403721179962158 and perplexity is 81.75452663792625
At time: 204.26249313354492 and batch: 800, loss is 4.374575281143189 and perplexity is 79.40610711832889
At time: 205.33465123176575 and batch: 850, loss is 4.346891756057739 and perplexity is 77.23801484145204
At time: 206.40553998947144 and batch: 900, loss is 4.397405223846436 and perplexity is 81.2397958550431
At time: 207.47724080085754 and batch: 950, loss is 4.362991123199463 and perplexity is 78.49156157885135
At time: 208.54868865013123 and batch: 1000, loss is 4.388128623962403 and perplexity is 80.48965154801488
At time: 209.62009954452515 and batch: 1050, loss is 4.326062650680542 and perplexity is 75.64585528379789
At time: 210.69101476669312 and batch: 1100, loss is 4.3027222633361815 and perplexity is 73.90069727802121
At time: 211.76198053359985 and batch: 1150, loss is 4.328410091400147 and perplexity is 75.8236380303507
At time: 212.84270429611206 and batch: 1200, loss is 4.304559516906738 and perplexity is 74.03659640030841
At time: 213.9167640209198 and batch: 1250, loss is 4.366094446182251 and perplexity is 78.73552459808337
At time: 214.98855257034302 and batch: 1300, loss is 4.350704040527344 and perplexity is 77.53303010965722
At time: 216.06019520759583 and batch: 1350, loss is 4.324970054626465 and perplexity is 75.56325005609806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.643063557942709 and perplexity of 103.86204809021962
Finished 7 epochs...
Completing Train Step...
At time: 219.22026801109314 and batch: 50, loss is 4.3951631450653075 and perplexity is 81.05785387291935
At time: 220.3168306350708 and batch: 100, loss is 4.404741487503052 and perplexity is 81.83798396678799
At time: 221.38753175735474 and batch: 150, loss is 4.372855262756348 and perplexity is 79.26964454676728
At time: 222.4579381942749 and batch: 200, loss is 4.358287382125854 and perplexity is 78.12322455683756
At time: 223.52729392051697 and batch: 250, loss is 4.378547487258911 and perplexity is 79.72215182445014
At time: 224.59642601013184 and batch: 300, loss is 4.364014339447022 and perplexity is 78.5719165231866
At time: 225.66541290283203 and batch: 350, loss is 4.376922054290771 and perplexity is 79.59267406779784
At time: 226.7353174686432 and batch: 400, loss is 4.397859468460083 and perplexity is 81.27670697742863
At time: 227.80469799041748 and batch: 450, loss is 4.3291401672363286 and perplexity is 75.87901524861279
At time: 228.87887740135193 and batch: 500, loss is 4.403657522201538 and perplexity is 81.74932249348377
At time: 229.95239877700806 and batch: 550, loss is 4.404581689834595 and perplexity is 81.82490749258177
At time: 231.0217924118042 and batch: 600, loss is 4.345058851242065 and perplexity is 77.09657457496667
At time: 232.1188759803772 and batch: 650, loss is 4.3609617233276365 and perplexity is 78.33243233688938
At time: 233.18867826461792 and batch: 700, loss is 4.384883308410645 and perplexity is 80.22886063338508
At time: 234.25909519195557 and batch: 750, loss is 4.3375872611999515 and perplexity is 76.52268717154878
At time: 235.3287057876587 and batch: 800, loss is 4.309578304290771 and perplexity is 74.40910432341066
At time: 236.3993821144104 and batch: 850, loss is 4.283992757797241 and perplexity is 72.5294551872881
At time: 237.46990299224854 and batch: 900, loss is 4.333168907165527 and perplexity is 76.18532868140409
At time: 238.54042220115662 and batch: 950, loss is 4.300986127853394 and perplexity is 73.77250696534817
At time: 239.6108169555664 and batch: 1000, loss is 4.327842435836792 and perplexity is 75.78060853451078
At time: 240.68193173408508 and batch: 1050, loss is 4.261109170913696 and perplexity is 70.88856740178122
At time: 241.75316405296326 and batch: 1100, loss is 4.240690298080445 and perplexity is 69.45578048627074
At time: 242.83118557929993 and batch: 1150, loss is 4.264193849563599 and perplexity is 71.10757346016598
At time: 243.90168499946594 and batch: 1200, loss is 4.242704811096192 and perplexity is 69.59584108966659
At time: 244.97321343421936 and batch: 1250, loss is 4.301720838546753 and perplexity is 73.82672833116115
At time: 246.04372692108154 and batch: 1300, loss is 4.2888901424407955 and perplexity is 72.88553103583615
At time: 247.1139154434204 and batch: 1350, loss is 4.26052791595459 and perplexity is 70.84737504322612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.642168375651042 and perplexity of 103.76911422657356
Finished 8 epochs...
Completing Train Step...
At time: 250.28501987457275 and batch: 50, loss is 4.334061460494995 and perplexity is 76.25335850578207
At time: 251.3562822341919 and batch: 100, loss is 4.342250204086303 and perplexity is 76.88034130369519
At time: 252.42847394943237 and batch: 150, loss is 4.313870315551758 and perplexity is 74.72915537713548
At time: 253.49990248680115 and batch: 200, loss is 4.3000596284866335 and perplexity is 73.7041884377838
At time: 254.57158613204956 and batch: 250, loss is 4.317318801879883 and perplexity is 74.98730270069863
At time: 255.64275002479553 and batch: 300, loss is 4.304093523025513 and perplexity is 74.00210383668508
At time: 256.71568536758423 and batch: 350, loss is 4.316919775009155 and perplexity is 74.95738672099449
At time: 257.790185213089 and batch: 400, loss is 4.339758634567261 and perplexity is 76.68902702407509
At time: 258.9043424129486 and batch: 450, loss is 4.270102467536926 and perplexity is 71.52896464054503
At time: 259.9758131504059 and batch: 500, loss is 4.344781951904297 and perplexity is 77.07522953987208
At time: 261.047705411911 and batch: 550, loss is 4.345733814239502 and perplexity is 77.14862947562352
At time: 262.11976623535156 and batch: 600, loss is 4.286052474975586 and perplexity is 72.67899930850173
At time: 263.19119930267334 and batch: 650, loss is 4.30068950176239 and perplexity is 73.75062736017482
At time: 264.2691147327423 and batch: 700, loss is 4.3299205493927 and perplexity is 75.93825298918739
At time: 265.33999395370483 and batch: 750, loss is 4.284030590057373 and perplexity is 72.53219919240958
At time: 266.41144847869873 and batch: 800, loss is 4.251833047866821 and perplexity is 70.23403677459363
At time: 267.48976850509644 and batch: 850, loss is 4.230344657897949 and perplexity is 68.74092019253726
At time: 268.5669593811035 and batch: 900, loss is 4.275881686210632 and perplexity is 71.94354298427216
At time: 269.638484954834 and batch: 950, loss is 4.246028890609741 and perplexity is 69.8275681254348
At time: 270.7100772857666 and batch: 1000, loss is 4.273148641586304 and perplexity is 71.74718651857961
At time: 271.781368970871 and batch: 1050, loss is 4.202301712036133 and perplexity is 66.84000055536953
At time: 272.85673427581787 and batch: 1100, loss is 4.185954456329346 and perplexity is 65.75623242696574
At time: 273.92758345603943 and batch: 1150, loss is 4.2070331954956055 and perplexity is 67.1570022652106
At time: 274.9989833831787 and batch: 1200, loss is 4.184012174606323 and perplexity is 65.62863924960787
At time: 276.07090640068054 and batch: 1250, loss is 4.246302042007446 and perplexity is 69.8466442284801
At time: 277.14241433143616 and batch: 1300, loss is 4.233243618011475 and perplexity is 68.94048650597138
At time: 278.2140986919403 and batch: 1350, loss is 4.204718542098999 and perplexity is 67.00173684394997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.64416748046875 and perplexity of 103.97676705348088
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 281.40106439590454 and batch: 50, loss is 4.296021814346314 and perplexity is 73.4071846500834
At time: 282.472861289978 and batch: 100, loss is 4.322330636978149 and perplexity is 75.36407005557291
At time: 283.5451581478119 and batch: 150, loss is 4.299803781509399 and perplexity is 73.68533385600921
At time: 284.6168489456177 and batch: 200, loss is 4.284731211662293 and perplexity is 72.5830346243376
At time: 285.7148127555847 and batch: 250, loss is 4.293797106742859 and perplexity is 73.24405665157454
At time: 286.786794424057 and batch: 300, loss is 4.284705724716186 and perplexity is 72.58118472802009
At time: 287.85886430740356 and batch: 350, loss is 4.286988868713379 and perplexity is 72.74708734195218
At time: 288.93249797821045 and batch: 400, loss is 4.303829851150513 and perplexity is 73.98259413540534
At time: 290.00683069229126 and batch: 450, loss is 4.225564103126526 and perplexity is 68.41308470063572
At time: 291.08053755760193 and batch: 500, loss is 4.299275360107422 and perplexity is 73.64640723432363
At time: 292.1529235839844 and batch: 550, loss is 4.289745445251465 and perplexity is 72.9478969024368
At time: 293.2260105609894 and batch: 600, loss is 4.224911823272705 and perplexity is 68.36847477440746
At time: 294.30169892311096 and batch: 650, loss is 4.230528221130371 and perplexity is 68.75353965624682
At time: 295.377183675766 and batch: 700, loss is 4.242536554336548 and perplexity is 69.58413210404575
At time: 296.44978380203247 and batch: 750, loss is 4.194516925811768 and perplexity is 66.32168554320612
At time: 297.521680355072 and batch: 800, loss is 4.155181903839111 and perplexity is 63.76356232972358
At time: 298.5930480957031 and batch: 850, loss is 4.118188786506653 and perplexity is 61.44784624563795
At time: 299.66467571258545 and batch: 900, loss is 4.152728786468506 and perplexity is 63.60733452827308
At time: 300.74492621421814 and batch: 950, loss is 4.116884627342224 and perplexity is 61.36776070731767
At time: 301.8184988498688 and batch: 1000, loss is 4.135122199058532 and perplexity is 62.49722770624775
At time: 302.8912341594696 and batch: 1050, loss is 4.055485591888428 and perplexity is 57.71318124556342
At time: 303.9638342857361 and batch: 1100, loss is 4.025746173858643 and perplexity is 56.02209541276283
At time: 305.0361137390137 and batch: 1150, loss is 4.033325037956238 and perplexity is 56.448292264335876
At time: 306.10913467407227 and batch: 1200, loss is 3.9975009775161743 and perplexity is 54.46187837252734
At time: 307.19207882881165 and batch: 1250, loss is 4.047592959403992 and perplexity is 57.25946517886783
At time: 308.2725124359131 and batch: 1300, loss is 4.0260575485229495 and perplexity is 56.039541989985835
At time: 309.3450951576233 and batch: 1350, loss is 3.985673770904541 and perplexity is 53.821540652154084
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5803214518229165 and perplexity of 97.54574542551566
Finished 10 epochs...
Completing Train Step...
At time: 312.49610233306885 and batch: 50, loss is 4.23626070022583 and perplexity is 69.14879971267383
At time: 313.5948760509491 and batch: 100, loss is 4.253976354598999 and perplexity is 70.38473129304067
At time: 314.667023897171 and batch: 150, loss is 4.228401260375977 and perplexity is 68.60745898467191
At time: 315.7390878200531 and batch: 200, loss is 4.213163757324219 and perplexity is 67.5699770099963
At time: 316.8115267753601 and batch: 250, loss is 4.223576936721802 and perplexity is 68.27727150347835
At time: 317.88375663757324 and batch: 300, loss is 4.214780058860779 and perplexity is 67.67927877617389
At time: 318.95545530319214 and batch: 350, loss is 4.220646514892578 and perplexity is 68.07748317164048
At time: 320.0291874408722 and batch: 400, loss is 4.239228372573852 and perplexity is 69.35431549439855
At time: 321.10215640068054 and batch: 450, loss is 4.162996792793274 and perplexity is 64.26381967044118
At time: 322.1761198043823 and batch: 500, loss is 4.241338272094726 and perplexity is 69.50080061152791
At time: 323.2490248680115 and batch: 550, loss is 4.234494276046753 and perplexity is 69.02676141833673
At time: 324.32254672050476 and batch: 600, loss is 4.172415127754212 and perplexity is 64.87193708145328
At time: 325.39496755599976 and batch: 650, loss is 4.1799699354171755 and perplexity is 65.3638880464432
At time: 326.4677298069 and batch: 700, loss is 4.1976104164123536 and perplexity is 66.52716872032012
At time: 327.53990387916565 and batch: 750, loss is 4.152245092391968 and perplexity is 63.576575476922514
At time: 328.612642288208 and batch: 800, loss is 4.1161481428146365 and perplexity is 61.32258094020591
At time: 329.6845734119415 and batch: 850, loss is 4.083649501800537 and perplexity is 59.36171570339656
At time: 330.7568383216858 and batch: 900, loss is 4.12238245010376 and perplexity is 61.70607893361306
At time: 331.829167842865 and batch: 950, loss is 4.091440229415894 and perplexity is 59.82599284129204
At time: 332.9053735733032 and batch: 1000, loss is 4.112441058158875 and perplexity is 61.09567378322618
At time: 333.97650146484375 and batch: 1050, loss is 4.036870408058166 and perplexity is 56.64877753928219
At time: 335.05504059791565 and batch: 1100, loss is 4.012410259246826 and perplexity is 55.279949130671504
At time: 336.130122423172 and batch: 1150, loss is 4.023863844871521 and perplexity is 55.916742584096546
At time: 337.2018723487854 and batch: 1200, loss is 3.9933903503417967 and perplexity is 54.238465393641405
At time: 338.2736735343933 and batch: 1250, loss is 4.049964332580567 and perplexity is 57.39540986278043
At time: 339.3453712463379 and batch: 1300, loss is 4.032890710830689 and perplexity is 56.423780563248215
At time: 340.4172570705414 and batch: 1350, loss is 3.9976869010925293 and perplexity is 54.47200506109528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.576084391276042 and perplexity of 97.13331256458217
Finished 11 epochs...
Completing Train Step...
At time: 343.5846326351166 and batch: 50, loss is 4.211129426956177 and perplexity is 67.43265707820883
At time: 344.68215560913086 and batch: 100, loss is 4.225033187866211 and perplexity is 68.37677279008959
At time: 345.75366735458374 and batch: 150, loss is 4.199401597976685 and perplexity is 66.64643774280839
At time: 346.82479786872864 and batch: 200, loss is 4.182955632209778 and perplexity is 65.55933642694502
At time: 347.89583444595337 and batch: 250, loss is 4.193345956802368 and perplexity is 66.24407035614183
At time: 348.96722960472107 and batch: 300, loss is 4.185443897247314 and perplexity is 65.7226685541991
At time: 350.03789138793945 and batch: 350, loss is 4.191788215637207 and perplexity is 66.14095957160741
At time: 351.1156122684479 and batch: 400, loss is 4.210497169494629 and perplexity is 67.39003575286446
At time: 352.186714887619 and batch: 450, loss is 4.135275106430054 and perplexity is 62.506784723714304
At time: 353.25831270217896 and batch: 500, loss is 4.215090885162353 and perplexity is 67.70031854577661
At time: 354.3320894241333 and batch: 550, loss is 4.20952648639679 and perplexity is 67.32465312223735
At time: 355.4034342765808 and batch: 600, loss is 4.148476095199585 and perplexity is 63.33740653909919
At time: 356.47618889808655 and batch: 650, loss is 4.156195621490479 and perplexity is 63.828233351911564
At time: 357.5470287799835 and batch: 700, loss is 4.175716581344605 and perplexity is 65.08646269937887
At time: 358.6187036037445 and batch: 750, loss is 4.132116889953613 and perplexity is 62.30968617008744
At time: 359.6897339820862 and batch: 800, loss is 4.096884226799011 and perplexity is 60.15257353540929
At time: 360.76117491722107 and batch: 850, loss is 4.066136293411255 and perplexity is 58.331152183203464
At time: 361.8330202102661 and batch: 900, loss is 4.106575946807862 and perplexity is 60.7383896332841
At time: 362.9045932292938 and batch: 950, loss is 4.0777299690246585 and perplexity is 59.01136007553226
At time: 363.9763536453247 and batch: 1000, loss is 4.0995083951950075 and perplexity is 60.31063131222788
At time: 365.0479462146759 and batch: 1050, loss is 4.026023030281067 and perplexity is 56.03760763690586
At time: 366.1193091869354 and batch: 1100, loss is 4.0031912136077885 and perplexity is 54.77266269798468
At time: 367.2167909145355 and batch: 1150, loss is 4.016465291976929 and perplexity is 55.50456624079452
At time: 368.2911880016327 and batch: 1200, loss is 3.9878536081314087 and perplexity is 53.93899081468609
At time: 369.3644218444824 and batch: 1250, loss is 4.046902618408203 and perplexity is 57.21995026361021
At time: 370.43557238578796 and batch: 1300, loss is 4.0315244054794315 and perplexity is 56.34674109163236
At time: 371.5062139034271 and batch: 1350, loss is 3.99799120426178 and perplexity is 54.48858358719188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.575419514973959 and perplexity of 97.06875239155801
Finished 12 epochs...
Completing Train Step...
At time: 374.6917989253998 and batch: 50, loss is 4.191557455062866 and perplexity is 66.12569860667146
At time: 375.7628254890442 and batch: 100, loss is 4.203805251121521 and perplexity is 66.94057269679831
At time: 376.8415310382843 and batch: 150, loss is 4.178656053543091 and perplexity is 65.27806401238703
At time: 377.9125874042511 and batch: 200, loss is 4.161584858894348 and perplexity is 64.17314743164118
At time: 378.98377776145935 and batch: 250, loss is 4.171909918785095 and perplexity is 64.83917147443198
At time: 380.05597591400146 and batch: 300, loss is 4.164869260787964 and perplexity is 64.38426434519862
At time: 381.1271333694458 and batch: 350, loss is 4.171713380813599 and perplexity is 64.82642936739182
At time: 382.19781970977783 and batch: 400, loss is 4.190382204055786 and perplexity is 66.04802996180642
At time: 383.26880145072937 and batch: 450, loss is 4.1158359384536745 and perplexity is 61.303438751303844
At time: 384.339772939682 and batch: 500, loss is 4.196441659927368 and perplexity is 66.44946008053464
At time: 385.41152119636536 and batch: 550, loss is 4.191647982597351 and perplexity is 66.13168507409839
At time: 386.4838786125183 and batch: 600, loss is 4.131253027915955 and perplexity is 62.255882440472426
At time: 387.5604112148285 and batch: 650, loss is 4.139151759147644 and perplexity is 62.74957211772722
At time: 388.634565114975 and batch: 700, loss is 4.159712824821472 and perplexity is 64.05312549071844
At time: 389.7062621116638 and batch: 750, loss is 4.117221546173096 and perplexity is 61.38844014495876
At time: 390.77708530426025 and batch: 800, loss is 4.082307434082031 and perplexity is 59.282101696679746
At time: 391.85112714767456 and batch: 850, loss is 4.052677259445191 and perplexity is 57.5513308175456
At time: 392.92219591140747 and batch: 900, loss is 4.094120817184448 and perplexity is 59.98657679948411
At time: 394.02307415008545 and batch: 950, loss is 4.066360683441162 and perplexity is 58.34424258080881
At time: 395.0948314666748 and batch: 1000, loss is 4.088630809783935 and perplexity is 59.65815240001246
At time: 396.16529536247253 and batch: 1050, loss is 4.016369066238403 and perplexity is 55.49922552987749
At time: 397.24111318588257 and batch: 1100, loss is 3.9942846632003786 and perplexity is 54.28699324697995
At time: 398.3127951622009 and batch: 1150, loss is 4.0087413358688355 and perplexity is 55.077502840030185
At time: 399.3834629058838 and batch: 1200, loss is 3.980960474014282 and perplexity is 53.56846064110162
At time: 400.454265832901 and batch: 1250, loss is 4.041381688117981 and perplexity is 56.90491335560974
At time: 401.52597069740295 and batch: 1300, loss is 4.026825728416443 and perplexity is 56.08260697809441
At time: 402.5965111255646 and batch: 1350, loss is 3.994251365661621 and perplexity is 54.285185653812654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5757132975260415 and perplexity of 97.0972736866874
Annealing...
Finished 13 epochs...
Completing Train Step...
At time: 405.76644945144653 and batch: 50, loss is 4.184013619422912 and perplexity is 65.62873407102308
At time: 406.839008808136 and batch: 100, loss is 4.206739406585694 and perplexity is 67.13727518066338
At time: 407.91067934036255 and batch: 150, loss is 4.188096694946289 and perplexity is 65.89724895897646
At time: 408.98180413246155 and batch: 200, loss is 4.174422311782837 and perplexity is 65.0022777625763
At time: 410.05279660224915 and batch: 250, loss is 4.184745593070984 and perplexity is 65.67679016066934
At time: 411.1238944530487 and batch: 300, loss is 4.180798525810242 and perplexity is 65.41807038051272
At time: 412.1948654651642 and batch: 350, loss is 4.186801242828369 and perplexity is 65.81193749863425
At time: 413.26577734947205 and batch: 400, loss is 4.203292336463928 and perplexity is 66.90624669978051
At time: 414.33617186546326 and batch: 450, loss is 4.126275749206543 and perplexity is 61.94678742639063
At time: 415.40684056282043 and batch: 500, loss is 4.20588794708252 and perplexity is 67.08013483948899
At time: 416.47701358795166 and batch: 550, loss is 4.200655345916748 and perplexity is 66.73004797896951
At time: 417.5492584705353 and batch: 600, loss is 4.144165511131287 and perplexity is 63.06497291939851
At time: 418.62114691734314 and batch: 650, loss is 4.149112567901612 and perplexity is 63.377731901013235
At time: 419.69394087791443 and batch: 700, loss is 4.161073250770569 and perplexity is 64.14032432508658
At time: 420.7657458782196 and batch: 750, loss is 4.116648941040039 and perplexity is 61.3532988710185
At time: 421.86324310302734 and batch: 800, loss is 4.078842802047729 and perplexity is 59.07706641907422
At time: 422.93532609939575 and batch: 850, loss is 4.041036567687988 and perplexity is 56.88527769597232
At time: 424.0070106983185 and batch: 900, loss is 4.071791005134583 and perplexity is 58.66193238522013
At time: 425.0782382488251 and batch: 950, loss is 4.041383004188537 and perplexity is 56.904988246540015
At time: 426.1496539115906 and batch: 1000, loss is 4.060934224128723 and perplexity is 58.02849738635223
At time: 427.2210023403168 and batch: 1050, loss is 3.9859305381774903 and perplexity is 53.83536203673695
At time: 428.29315733909607 and batch: 1100, loss is 3.9576291942596438 and perplexity is 52.33310712714652
At time: 429.3635540008545 and batch: 1150, loss is 3.967591471672058 and perplexity is 52.85706965476032
At time: 430.4357485771179 and batch: 1200, loss is 3.9367308759689332 and perplexity is 51.25078197592446
At time: 431.5063292980194 and batch: 1250, loss is 3.9940427589416503 and perplexity is 54.273862580366064
At time: 432.57776737213135 and batch: 1300, loss is 3.978206629753113 and perplexity is 53.421144379306185
At time: 433.64826583862305 and batch: 1350, loss is 3.9452533769607543 and perplexity is 51.689433364548364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.556979573567708 and perplexity of 95.29521252534508
Finished 14 epochs...
Completing Train Step...
At time: 436.8059813976288 and batch: 50, loss is 4.1784068202972415 and perplexity is 65.26179657588766
At time: 437.90192770957947 and batch: 100, loss is 4.194913830757141 and perplexity is 66.34801417281972
At time: 438.97080731391907 and batch: 150, loss is 4.172345180511474 and perplexity is 64.86739962701647
At time: 440.04285430908203 and batch: 200, loss is 4.156080417633056 and perplexity is 63.82088051676257
At time: 441.1142039299011 and batch: 250, loss is 4.166440215110779 and perplexity is 64.48548857209377
At time: 442.1837615966797 and batch: 300, loss is 4.16106153011322 and perplexity is 64.13957256272853
At time: 443.2536611557007 and batch: 350, loss is 4.166838006973267 and perplexity is 64.51114547741206
At time: 444.330997467041 and batch: 400, loss is 4.182617297172547 and perplexity is 65.53715915829923
At time: 445.4008049964905 and batch: 450, loss is 4.106666631698609 and perplexity is 60.743897937268336
At time: 446.47040843963623 and batch: 500, loss is 4.187507123947143 and perplexity is 65.85840930255934
At time: 447.5467779636383 and batch: 550, loss is 4.1830840492248536 and perplexity is 65.56775590182968
At time: 448.64489483833313 and batch: 600, loss is 4.125985622406006 and perplexity is 61.92881761003978
At time: 449.71431851387024 and batch: 650, loss is 4.132123641967773 and perplexity is 62.31010688739112
At time: 450.7835068702698 and batch: 700, loss is 4.146137857437134 and perplexity is 63.18948163255154
At time: 451.8553783893585 and batch: 750, loss is 4.103009643554688 and perplexity is 60.52216390916658
At time: 452.9287643432617 and batch: 800, loss is 4.0663480377197265 and perplexity is 58.34350478043479
At time: 453.9981851577759 and batch: 850, loss is 4.030673055648804 and perplexity is 56.298790717315306
At time: 455.06836342811584 and batch: 900, loss is 4.064485778808594 and perplexity is 58.234955173857706
At time: 456.1377856731415 and batch: 950, loss is 4.035738229751587 and perplexity is 56.58467731554648
At time: 457.20727801322937 and batch: 1000, loss is 4.057859292030335 and perplexity is 57.850337751885014
At time: 458.2773451805115 and batch: 1050, loss is 3.984958624839783 and perplexity is 53.78306414895725
At time: 459.3475093841553 and batch: 1100, loss is 3.959363131523132 and perplexity is 52.42392816794714
At time: 460.4168598651886 and batch: 1150, loss is 3.9711426496505737 and perplexity is 53.045108198083575
At time: 461.4880874156952 and batch: 1200, loss is 3.942258291244507 and perplexity is 51.53485069073392
At time: 462.56198620796204 and batch: 1250, loss is 4.001230149269104 and perplexity is 54.665355235242124
At time: 463.63477969169617 and batch: 1300, loss is 3.9861156368255615 and perplexity is 53.845327811765664
At time: 464.7080852985382 and batch: 1350, loss is 3.9534374237060548 and perplexity is 52.11419787892013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5555908203125 and perplexity of 95.16296284108965
Finished 15 epochs...
Completing Train Step...
At time: 467.86829829216003 and batch: 50, loss is 4.174381008148194 and perplexity is 64.99959298769048
At time: 468.9680120944977 and batch: 100, loss is 4.188955698013306 and perplexity is 65.95387921724075
At time: 470.0435194969177 and batch: 150, loss is 4.165173263549804 and perplexity is 64.40384031480227
At time: 471.11876344680786 and batch: 200, loss is 4.14818169593811 and perplexity is 63.318762797876836
At time: 472.1957881450653 and batch: 250, loss is 4.158173203468323 and perplexity is 63.95458380888128
At time: 473.2693626880646 and batch: 300, loss is 4.152212109565735 and perplexity is 63.574478576362125
At time: 474.3451957702637 and batch: 350, loss is 4.158146600723267 and perplexity is 63.95288246402339
At time: 475.42107796669006 and batch: 400, loss is 4.17386824131012 and perplexity is 64.9662718956237
At time: 476.5230700969696 and batch: 450, loss is 4.098269605636597 and perplexity is 60.23596538912862
At time: 477.59768080711365 and batch: 500, loss is 4.179602069854736 and perplexity is 65.33984734514793
At time: 478.67050790786743 and batch: 550, loss is 4.1753767347335815 and perplexity is 65.06434704378515
At time: 479.742671251297 and batch: 600, loss is 4.118394379615784 and perplexity is 61.46048079814095
At time: 480.8149781227112 and batch: 650, loss is 4.124926548004151 and perplexity is 61.86326510319002
At time: 481.8877468109131 and batch: 700, loss is 4.139938769340515 and perplexity is 62.798976108754374
At time: 482.96526312828064 and batch: 750, loss is 4.097348766326904 and perplexity is 60.18052327489778
At time: 484.03885197639465 and batch: 800, loss is 4.061241593360901 and perplexity is 58.046336302464816
At time: 485.11169362068176 and batch: 850, loss is 4.02659924030304 and perplexity is 56.06990637256757
At time: 486.18309569358826 and batch: 900, loss is 4.06148473739624 and perplexity is 58.060451638870454
At time: 487.2581353187561 and batch: 950, loss is 4.033474984169007 and perplexity is 56.45675710659785
At time: 488.33622121810913 and batch: 1000, loss is 4.056437668800354 and perplexity is 57.7681547983137
At time: 489.4080274105072 and batch: 1050, loss is 3.984414105415344 and perplexity is 53.7537861977523
At time: 490.4798195362091 and batch: 1100, loss is 3.9599194717407227 and perplexity is 52.453101822037105
At time: 491.55169677734375 and batch: 1150, loss is 3.9723454475402833 and perplexity is 53.10894912845514
At time: 492.6237704753876 and batch: 1200, loss is 3.9442832469940186 and perplexity is 51.639312212224716
At time: 493.69471287727356 and batch: 1250, loss is 4.003966698646545 and perplexity is 54.81515455220897
At time: 494.76543951034546 and batch: 1300, loss is 3.989257674217224 and perplexity is 54.01477791499018
At time: 495.83877897262573 and batch: 1350, loss is 3.9565915393829347 and perplexity is 52.278831587831725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.555218098958333 and perplexity of 95.12750018196868
Finished 16 epochs...
Completing Train Step...
At time: 499.046181678772 and batch: 50, loss is 4.170192794799805 and perplexity is 64.72793011284499
At time: 500.1196856498718 and batch: 100, loss is 4.183814558982849 and perplexity is 65.61567128652307
At time: 501.1921977996826 and batch: 150, loss is 4.159592237472534 and perplexity is 64.04540195981373
At time: 502.26446199417114 and batch: 200, loss is 4.14233567237854 and perplexity is 62.949679704176
At time: 503.3633043766022 and batch: 250, loss is 4.152171854972839 and perplexity is 63.57191946311686
At time: 504.4353997707367 and batch: 300, loss is 4.146046729087829 and perplexity is 63.18372354176358
At time: 505.51250886917114 and batch: 350, loss is 4.152119159698486 and perplexity is 63.56856961164106
At time: 506.58824944496155 and batch: 400, loss is 4.16790994644165 and perplexity is 64.58033459704882
At time: 507.660808801651 and batch: 450, loss is 4.0925466823577885 and perplexity is 59.89222412121341
At time: 508.7331702709198 and batch: 500, loss is 4.174286708831787 and perplexity is 64.9934638594959
At time: 509.80545139312744 and batch: 550, loss is 4.17020432472229 and perplexity is 64.72867642516428
At time: 510.8775010108948 and batch: 600, loss is 4.113402466773987 and perplexity is 61.15443993496327
At time: 511.94986605644226 and batch: 650, loss is 4.120151495933532 and perplexity is 61.568568945762216
At time: 513.0322225093842 and batch: 700, loss is 4.135842018127441 and perplexity is 62.542230597531145
At time: 514.1101951599121 and batch: 750, loss is 4.093580865859986 and perplexity is 59.954195710783836
At time: 515.1861000061035 and batch: 800, loss is 4.0577814626693725 and perplexity is 57.84583547227338
At time: 516.2650053501129 and batch: 850, loss is 4.023730854988099 and perplexity is 55.90930671747742
At time: 517.3382823467255 and batch: 900, loss is 4.059184670448303 and perplexity is 57.92706217422895
At time: 518.411652803421 and batch: 950, loss is 4.031680717468261 and perplexity is 56.355549451204645
At time: 519.4841799736023 and batch: 1000, loss is 4.055032324790955 and perplexity is 57.687027687135824
At time: 520.5573496818542 and batch: 1050, loss is 3.9835792493820192 and perplexity is 53.70892825259956
At time: 521.6306746006012 and batch: 1100, loss is 3.9596961069107057 and perplexity is 52.44138695225842
At time: 522.7030029296875 and batch: 1150, loss is 3.972469186782837 and perplexity is 53.11552119619607
At time: 523.775824546814 and batch: 1200, loss is 3.944907841682434 and perplexity is 51.671575927169506
At time: 524.8482131958008 and batch: 1250, loss is 4.005018405914306 and perplexity is 54.872834374462535
At time: 525.9210288524628 and batch: 1300, loss is 3.99062216758728 and perplexity is 54.08853102771384
At time: 526.9939420223236 and batch: 1350, loss is 3.957951850891113 and perplexity is 52.349995475628795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.555150146484375 and perplexity of 95.12103625261236
Finished 17 epochs...
Completing Train Step...
At time: 530.1523063182831 and batch: 50, loss is 4.16622682094574 and perplexity is 64.47172921323846
At time: 531.2248167991638 and batch: 100, loss is 4.179237442016602 and perplexity is 65.31602696091794
At time: 532.2978045940399 and batch: 150, loss is 4.154833669662476 and perplexity is 63.741361543856904
At time: 533.3700098991394 and batch: 200, loss is 4.137439427375793 and perplexity is 62.64221597262045
At time: 534.4424011707306 and batch: 250, loss is 4.147190551757813 and perplexity is 63.25603586547818
At time: 535.5195062160492 and batch: 300, loss is 4.141065716743469 and perplexity is 62.86978714445049
At time: 536.594162940979 and batch: 350, loss is 4.147248601913452 and perplexity is 63.25970799478808
At time: 537.6661229133606 and batch: 400, loss is 4.163117980957031 and perplexity is 64.27160815666967
At time: 538.7382125854492 and batch: 450, loss is 4.087939443588257 and perplexity is 59.61692102477834
At time: 539.8113086223602 and batch: 500, loss is 4.170015268325805 and perplexity is 64.71644021155379
At time: 540.8834693431854 and batch: 550, loss is 4.166069130897522 and perplexity is 64.46156346468992
At time: 541.955682516098 and batch: 600, loss is 4.109431347846985 and perplexity is 60.91206993961539
At time: 543.0274431705475 and batch: 650, loss is 4.116320395469666 and perplexity is 61.3331448273888
At time: 544.0996716022491 and batch: 700, loss is 4.132523684501648 and perplexity is 62.33503856697002
At time: 545.1782639026642 and batch: 750, loss is 4.090498290061951 and perplexity is 59.76966691621344
At time: 546.2501077651978 and batch: 800, loss is 4.054913697242736 and perplexity is 57.68018482236146
At time: 547.323258638382 and batch: 850, loss is 4.021260166168213 and perplexity is 55.77134272167516
At time: 548.4093894958496 and batch: 900, loss is 4.0570906639099125 and perplexity is 57.805889439812574
At time: 549.48406291008 and batch: 950, loss is 4.029976553916931 and perplexity is 56.259592164592945
At time: 550.5569865703583 and batch: 1000, loss is 4.053545470237732 and perplexity is 57.60131920117353
At time: 551.6291682720184 and batch: 1050, loss is 3.9825113248825073 and perplexity is 53.651601787892375
At time: 552.7013833522797 and batch: 1100, loss is 3.95903706073761 and perplexity is 52.40683704311894
At time: 553.7817306518555 and batch: 1150, loss is 3.9720417070388794 and perplexity is 53.092820239240275
At time: 554.8541827201843 and batch: 1200, loss is 3.9448475503921507 and perplexity is 51.6684606750981
At time: 555.926025390625 and batch: 1250, loss is 4.005262718200684 and perplexity is 54.886242119860356
At time: 556.9983415603638 and batch: 1300, loss is 3.9911288261413573 and perplexity is 54.115942388150245
At time: 558.0704646110535 and batch: 1350, loss is 3.9584605407714846 and perplexity is 52.376632162896975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.555210367838542 and perplexity of 95.1267647427122
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 561.2383165359497 and batch: 50, loss is 4.1650896072387695 and perplexity is 64.39845275245999
At time: 562.3356759548187 and batch: 100, loss is 4.181447315216064 and perplexity is 65.46052670264169
At time: 563.4059009552002 and batch: 150, loss is 4.159183244705201 and perplexity is 64.01921320950099
At time: 564.4759593009949 and batch: 200, loss is 4.143657999038696 and perplexity is 63.03297480342523
At time: 565.5468530654907 and batch: 250, loss is 4.154018874168396 and perplexity is 63.68944652261932
At time: 566.620551109314 and batch: 300, loss is 4.147742080688476 and perplexity is 63.29093302180814
At time: 567.6957340240479 and batch: 350, loss is 4.154231495857239 and perplexity is 63.70298972003817
At time: 568.767676115036 and batch: 400, loss is 4.169087448120117 and perplexity is 64.65642283765689
At time: 569.839346408844 and batch: 450, loss is 4.093265824317932 and perplexity is 59.935310623464225
At time: 570.9109930992126 and batch: 500, loss is 4.174982223510742 and perplexity is 65.03868349128227
At time: 571.9821853637695 and batch: 550, loss is 4.168454265594482 and perplexity is 64.61549647884098
At time: 573.055230140686 and batch: 600, loss is 4.113636016845703 and perplexity is 61.16872422677959
At time: 574.126074552536 and batch: 650, loss is 4.120072050094604 and perplexity is 61.563677773444944
At time: 575.2020838260651 and batch: 700, loss is 4.13588053226471 and perplexity is 62.54463940397173
At time: 576.2765426635742 and batch: 750, loss is 4.092728943824768 and perplexity is 59.90314116068999
At time: 577.3477566242218 and batch: 800, loss is 4.058269357681274 and perplexity is 57.87406505283537
At time: 578.4189109802246 and batch: 850, loss is 4.021716656684876 and perplexity is 55.79680762252981
At time: 579.4986484050751 and batch: 900, loss is 4.0529721021652225 and perplexity is 57.56830191024392
At time: 580.5715222358704 and batch: 950, loss is 4.024263033866882 and perplexity is 55.93906838820376
At time: 581.6425750255585 and batch: 1000, loss is 4.044809188842773 and perplexity is 57.100289622258686
At time: 582.7141461372375 and batch: 1050, loss is 3.9725445127487182 and perplexity is 53.11952232482601
At time: 583.7862772941589 and batch: 1100, loss is 3.947720546722412 and perplexity is 51.81711741589092
At time: 584.8835694789886 and batch: 1150, loss is 3.9590570974349975 and perplexity is 52.40788711357374
At time: 585.9546959400177 and batch: 1200, loss is 3.9302444887161254 and perplexity is 50.91942537241308
At time: 587.0256698131561 and batch: 1250, loss is 3.990076503753662 and perplexity is 54.05902492345759
At time: 588.0964436531067 and batch: 1300, loss is 3.976361427307129 and perplexity is 53.32266244052977
At time: 589.1675043106079 and batch: 1350, loss is 3.9456097888946533 and perplexity is 51.70785937888662
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.551581217447917 and perplexity of 94.78216109474262
Finished 19 epochs...
Completing Train Step...
At time: 592.3131377696991 and batch: 50, loss is 4.164259686470031 and perplexity is 64.3450293107244
At time: 593.4215388298035 and batch: 100, loss is 4.179222373962403 and perplexity is 65.31504278289847
At time: 594.4928872585297 and batch: 150, loss is 4.155844416618347 and perplexity is 63.80582050136033
At time: 595.5641264915466 and batch: 200, loss is 4.139952149391174 and perplexity is 62.79981636785741
At time: 596.6352028846741 and batch: 250, loss is 4.150419807434082 and perplexity is 63.46063595355391
At time: 597.7056970596313 and batch: 300, loss is 4.144021291732788 and perplexity is 63.055878382757776
At time: 598.7754371166229 and batch: 350, loss is 4.149910645484924 and perplexity is 63.42833243701564
At time: 599.8462884426117 and batch: 400, loss is 4.164381694793701 and perplexity is 64.35288041882762
At time: 600.9175617694855 and batch: 450, loss is 4.088581671714783 and perplexity is 59.65522098561694
At time: 601.9887516498566 and batch: 500, loss is 4.170306406021118 and perplexity is 64.73528434979221
At time: 603.0598843097687 and batch: 550, loss is 4.164438648223877 and perplexity is 64.35654564048164
At time: 604.1309123039246 and batch: 600, loss is 4.109486756324768 and perplexity is 60.91544507819413
At time: 605.2019505500793 and batch: 650, loss is 4.116392216682434 and perplexity is 61.337550006423946
At time: 606.2724807262421 and batch: 700, loss is 4.1324700307846065 and perplexity is 62.331694150169966
At time: 607.3444068431854 and batch: 750, loss is 4.089938802719116 and perplexity is 59.73623589707648
At time: 608.4155237674713 and batch: 800, loss is 4.055573630332947 and perplexity is 57.71826244793579
At time: 609.4871301651001 and batch: 850, loss is 4.019843330383301 and perplexity is 55.69237983946241
At time: 610.5585377216339 and batch: 900, loss is 4.051830372810364 and perplexity is 57.50261199723044
At time: 611.6728625297546 and batch: 950, loss is 4.023652400970459 and perplexity is 55.90492057979929
At time: 612.7544755935669 and batch: 1000, loss is 4.044784665107727 and perplexity is 57.09888932705523
At time: 613.8268053531647 and batch: 1050, loss is 3.973359990119934 and perplexity is 53.1628577603837
At time: 614.898740530014 and batch: 1100, loss is 3.949128565788269 and perplexity is 51.89012829344193
At time: 615.9698951244354 and batch: 1150, loss is 3.9608015060424804 and perplexity is 52.49938766692837
At time: 617.0415279865265 and batch: 1200, loss is 3.9325646638870237 and perplexity is 51.03770451998914
At time: 618.1181421279907 and batch: 1250, loss is 3.9928778171539308 and perplexity is 54.21067350280984
At time: 619.1968924999237 and batch: 1300, loss is 3.978975944519043 and perplexity is 53.46225786706895
At time: 620.2679059505463 and batch: 1350, loss is 3.948067922592163 and perplexity is 51.83512055886894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550727132161458 and perplexity of 94.70124360567006
Finished 20 epochs...
Completing Train Step...
At time: 623.441712141037 and batch: 50, loss is 4.163842697143554 and perplexity is 64.3182037136725
At time: 624.5129773616791 and batch: 100, loss is 4.1779454326629635 and perplexity is 65.23169253530685
At time: 625.5844461917877 and batch: 150, loss is 4.154087805747986 and perplexity is 63.69383688808702
At time: 626.6557738780975 and batch: 200, loss is 4.137915258407593 and perplexity is 62.672030175579856
At time: 627.7278027534485 and batch: 250, loss is 4.148290410041809 and perplexity is 63.3256468146098
At time: 628.7990131378174 and batch: 300, loss is 4.141783375740051 and perplexity is 62.91492240673421
At time: 629.8704297542572 and batch: 350, loss is 4.147450499534607 and perplexity is 63.2724812687506
At time: 630.941831111908 and batch: 400, loss is 4.161823835372925 and perplexity is 64.188485137036
At time: 632.0173037052155 and batch: 450, loss is 4.086080112457275 and perplexity is 59.506176414938736
At time: 633.0980880260468 and batch: 500, loss is 4.1678660869598385 and perplexity is 64.57750219915238
At time: 634.1687598228455 and batch: 550, loss is 4.162217388153076 and perplexity is 64.2137516653455
At time: 635.2412075996399 and batch: 600, loss is 4.107248764038086 and perplexity is 60.77926921906818
At time: 636.3130323886871 and batch: 650, loss is 4.114320006370544 and perplexity is 61.21057730530053
At time: 637.3841969966888 and batch: 700, loss is 4.130661931037903 and perplexity is 62.219094056542055
At time: 638.4812417030334 and batch: 750, loss is 4.088437008857727 and perplexity is 59.646591715093365
At time: 639.5516993999481 and batch: 800, loss is 4.0541896772384645 and perplexity is 57.6384383291717
At time: 640.622631072998 and batch: 850, loss is 4.0188969707489015 and perplexity is 55.63969975032533
At time: 641.693345785141 and batch: 900, loss is 4.05131350517273 and perplexity is 57.47289843765982
At time: 642.7650887966156 and batch: 950, loss is 4.023435006141662 and perplexity is 55.89276846011281
At time: 643.8365061283112 and batch: 1000, loss is 4.044902000427246 and perplexity is 57.10558943655067
At time: 644.9090092182159 and batch: 1050, loss is 3.973890061378479 and perplexity is 53.19104533335575
At time: 645.9821484088898 and batch: 1100, loss is 3.9500565481185914 and perplexity is 51.938303765152455
At time: 647.0537672042847 and batch: 1150, loss is 3.961965341567993 and perplexity is 52.560523888715394
At time: 648.1259117126465 and batch: 1200, loss is 3.9340103244781495 and perplexity is 51.11154107651572
At time: 649.1973302364349 and batch: 1250, loss is 3.9945030546188356 and perplexity is 54.29885035513713
At time: 650.2685394287109 and batch: 1300, loss is 3.980483021736145 and perplexity is 53.54289036231191
At time: 651.3405077457428 and batch: 1350, loss is 3.949466209411621 and perplexity is 51.90765162252882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550379231770833 and perplexity of 94.66830273642988
Finished 21 epochs...
Completing Train Step...
At time: 654.5078356266022 and batch: 50, loss is 4.16326322555542 and perplexity is 64.28094393855375
At time: 655.5794260501862 and batch: 100, loss is 4.17681887626648 and perplexity is 65.15824673301461
At time: 656.6510484218597 and batch: 150, loss is 4.152687582969666 and perplexity is 63.604713737531846
At time: 657.7233195304871 and batch: 200, loss is 4.136337494850158 and perplexity is 62.57322649521782
At time: 658.795211315155 and batch: 250, loss is 4.146652946472168 and perplexity is 63.22203822572219
At time: 659.8674473762512 and batch: 300, loss is 4.140079197883606 and perplexity is 62.807795496709325
At time: 660.9396221637726 and batch: 350, loss is 4.145649280548096 and perplexity is 63.15861625286512
At time: 662.0128238201141 and batch: 400, loss is 4.159999303817749 and perplexity is 64.07147799449531
At time: 663.0827610492706 and batch: 450, loss is 4.08431758403778 and perplexity is 59.40138746175323
At time: 664.1524658203125 and batch: 500, loss is 4.166200065612793 and perplexity is 64.4700042737335
At time: 665.2224204540253 and batch: 550, loss is 4.160671353340149 and perplexity is 64.11455167288229
At time: 666.3331618309021 and batch: 600, loss is 4.105714473724365 and perplexity is 60.686087677078454
At time: 667.4076879024506 and batch: 650, loss is 4.112874002456665 and perplexity is 61.12213053354662
At time: 668.484100818634 and batch: 700, loss is 4.129437847137451 and perplexity is 62.142979260159265
At time: 669.5597767829895 and batch: 750, loss is 4.087404193878174 and perplexity is 59.58501962345332
At time: 670.630223274231 and batch: 800, loss is 4.0532594442367555 and perplexity is 57.58484608217393
At time: 671.7012548446655 and batch: 850, loss is 4.018247294425964 and perplexity is 55.60356369442319
At time: 672.7715005874634 and batch: 900, loss is 4.05094612121582 and perplexity is 57.45178769492828
At time: 673.8418533802032 and batch: 950, loss is 4.023269677162171 and perplexity is 55.88352852957753
At time: 674.9121768474579 and batch: 1000, loss is 4.044945125579834 and perplexity is 57.10805217691137
At time: 675.9831268787384 and batch: 1050, loss is 3.9741959238052367 and perplexity is 53.20731696387653
At time: 677.0540933609009 and batch: 1100, loss is 3.950639581680298 and perplexity is 51.96859436874685
At time: 678.1254091262817 and batch: 1150, loss is 3.9627177715301514 and perplexity is 52.600086884040984
At time: 679.1962139606476 and batch: 1200, loss is 3.934934206008911 and perplexity is 51.15878390535321
At time: 680.2658224105835 and batch: 1250, loss is 3.995518321990967 and perplexity is 54.354006200474274
At time: 681.3360381126404 and batch: 1300, loss is 3.9814314699172972 and perplexity is 53.59369710926443
At time: 682.4062581062317 and batch: 1350, loss is 3.950349545478821 and perplexity is 51.95352378065375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550216471354167 and perplexity of 94.65289573789019
Finished 22 epochs...
Completing Train Step...
At time: 685.5580952167511 and batch: 50, loss is 4.16259831905365 and perplexity is 64.23821732716407
At time: 686.6556577682495 and batch: 100, loss is 4.175778770446778 and perplexity is 65.0905104939208
At time: 687.7274014949799 and batch: 150, loss is 4.151473917961121 and perplexity is 63.52756574746789
At time: 688.7995455265045 and batch: 200, loss is 4.135006260871887 and perplexity is 62.48998231101426
At time: 689.8706367015839 and batch: 250, loss is 4.145280146598816 and perplexity is 63.13530656587977
At time: 690.9421002864838 and batch: 300, loss is 4.138668746948242 and perplexity is 62.71927062747091
At time: 692.0127332210541 and batch: 350, loss is 4.144193229675293 and perplexity is 63.066721012852796
At time: 693.1189250946045 and batch: 400, loss is 4.158545398712159 and perplexity is 63.97839183113793
At time: 694.1910207271576 and batch: 450, loss is 4.082919936180115 and perplexity is 59.318423230720185
At time: 695.2634708881378 and batch: 500, loss is 4.164902877807617 and perplexity is 64.38642878865934
At time: 696.3346252441406 and batch: 550, loss is 4.159456653594971 and perplexity is 64.03671902452223
At time: 697.4062938690186 and batch: 600, loss is 4.104528179168701 and perplexity is 60.61413878638901
At time: 698.4848055839539 and batch: 650, loss is 4.111747612953186 and perplexity is 61.05332196718193
At time: 699.5568404197693 and batch: 700, loss is 4.12849458694458 and perplexity is 62.084389898407174
At time: 700.6287009716034 and batch: 750, loss is 4.086599659919739 and perplexity is 59.53710073052525
At time: 701.7003548145294 and batch: 800, loss is 4.05253897190094 and perplexity is 57.543372735602986
At time: 702.7725222110748 and batch: 850, loss is 4.01772762298584 and perplexity is 55.574675617206516
At time: 703.8487870693207 and batch: 900, loss is 4.05062668800354 and perplexity is 57.433438616642164
At time: 704.9238352775574 and batch: 950, loss is 4.023099436759948 and perplexity is 55.874015704959575
At time: 705.9957120418549 and batch: 1000, loss is 4.044915871620178 and perplexity is 57.10638156469311
At time: 707.0678806304932 and batch: 1050, loss is 3.9743579912185667 and perplexity is 53.21594083491245
At time: 708.1401031017303 and batch: 1100, loss is 3.9510027408599853 and perplexity is 51.98747066819056
At time: 709.2122864723206 and batch: 1150, loss is 3.96320921421051 and perplexity is 52.62594316464591
At time: 710.2864582538605 and batch: 1200, loss is 3.935546040534973 and perplexity is 51.19009419303865
At time: 711.3587539196014 and batch: 1250, loss is 3.9961936044692994 and perplexity is 54.39072290416671
At time: 712.4312212467194 and batch: 1300, loss is 3.982072534561157 and perplexity is 53.628065148505335
At time: 713.5061664581299 and batch: 1350, loss is 3.950947895050049 and perplexity is 51.98461945144458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550136311848958 and perplexity of 94.64530871269143
Finished 23 epochs...
Completing Train Step...
At time: 716.6575446128845 and batch: 50, loss is 4.161897525787354 and perplexity is 64.19321538739224
At time: 717.7558279037476 and batch: 100, loss is 4.174803533554077 and perplexity is 65.02706277003166
At time: 718.8279774188995 and batch: 150, loss is 4.150381150245667 and perplexity is 63.45818279120942
At time: 719.9261283874512 and batch: 200, loss is 4.133833260536194 and perplexity is 62.41672451489546
At time: 720.9998290538788 and batch: 250, loss is 4.144073476791382 and perplexity is 63.05916904332681
At time: 722.079029083252 and batch: 300, loss is 4.137443218231201 and perplexity is 62.64245344065375
At time: 723.1524288654327 and batch: 350, loss is 4.142947645187378 and perplexity is 62.98821498654986
At time: 724.2248885631561 and batch: 400, loss is 4.157311611175537 and perplexity is 63.899504763630944
At time: 725.2974617481232 and batch: 450, loss is 4.081736006736755 and perplexity is 59.24823595951052
At time: 726.373560667038 and batch: 500, loss is 4.163813829421997 and perplexity is 64.31634702047602
At time: 727.4474995136261 and batch: 550, loss is 4.1584309530258174 and perplexity is 63.9710701991464
At time: 728.522896528244 and batch: 600, loss is 4.103540711402893 and perplexity is 60.554313820659075
At time: 729.597907781601 and batch: 650, loss is 4.110806255340576 and perplexity is 60.99587600061414
At time: 730.6701600551605 and batch: 700, loss is 4.127706317901612 and perplexity is 62.03546997936068
At time: 731.7418994903564 and batch: 750, loss is 4.085921068191528 and perplexity is 59.49671305137018
At time: 732.813392162323 and batch: 800, loss is 4.051930069923401 and perplexity is 57.508345127422174
At time: 733.8848793506622 and batch: 850, loss is 4.017273592948913 and perplexity is 55.54944877248985
At time: 734.9567861557007 and batch: 900, loss is 4.050322685241699 and perplexity is 57.41598134634435
At time: 736.0281145572662 and batch: 950, loss is 4.02291350364685 and perplexity is 55.86362784103213
At time: 737.0991866588593 and batch: 1000, loss is 4.044832434654236 and perplexity is 57.10161698025339
At time: 738.171195268631 and batch: 1050, loss is 3.9744245052337646 and perplexity is 53.21948055852923
At time: 739.2430624961853 and batch: 1100, loss is 3.951223077774048 and perplexity is 51.9989266890933
At time: 740.3157360553741 and batch: 1150, loss is 3.9635306453704833 and perplexity is 52.64286150149666
At time: 741.3888499736786 and batch: 1200, loss is 3.9359603214263914 and perplexity is 51.211305664342966
At time: 742.4631915092468 and batch: 1250, loss is 3.9966616249084472 and perplexity is 54.41618483207245
At time: 743.535190820694 and batch: 1300, loss is 3.9825267791748047 and perplexity is 53.652430941835604
At time: 744.6140005588531 and batch: 1350, loss is 3.9513710069656374 and perplexity is 52.00661941725745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550097249348958 and perplexity of 94.64161170252754
Finished 24 epochs...
Completing Train Step...
At time: 747.8060312271118 and batch: 50, loss is 4.161185693740845 and perplexity is 64.14753685915996
At time: 748.8813350200653 and batch: 100, loss is 4.17387966632843 and perplexity is 64.96701414070974
At time: 749.9571459293365 and batch: 150, loss is 4.14937379360199 and perplexity is 63.39428995601807
At time: 751.028781414032 and batch: 200, loss is 4.132769618034363 and perplexity is 62.35037072848575
At time: 752.1056785583496 and batch: 250, loss is 4.142980728149414 and perplexity is 62.99029885774514
At time: 753.1782531738281 and batch: 300, loss is 4.136343693733215 and perplexity is 62.57361438053357
At time: 754.2504811286926 and batch: 350, loss is 4.141841769218445 and perplexity is 62.918596335162114
At time: 755.3231444358826 and batch: 400, loss is 4.156221976280213 and perplexity is 63.82991555374757
At time: 756.3960347175598 and batch: 450, loss is 4.08069046497345 and perplexity is 59.186321826958476
At time: 757.4680469036102 and batch: 500, loss is 4.162855920791626 and perplexity is 64.25476733515588
At time: 758.5468575954437 and batch: 550, loss is 4.157524080276489 and perplexity is 63.91308287637298
At time: 759.6197054386139 and batch: 600, loss is 4.1026770830154415 and perplexity is 60.502039972099745
At time: 760.6922273635864 and batch: 650, loss is 4.109980597496032 and perplexity is 60.945535062164595
At time: 761.7645471096039 and batch: 700, loss is 4.127011413574219 and perplexity is 61.99237623756814
At time: 762.8371555805206 and batch: 750, loss is 4.08531765460968 and perplexity is 59.4608227560745
At time: 763.908860206604 and batch: 800, loss is 4.0513857555389405 and perplexity is 57.47705102563033
At time: 764.9813268184662 and batch: 850, loss is 4.016854524612427 and perplexity is 55.52617463446778
At time: 766.0533714294434 and batch: 900, loss is 4.0500215148925784 and perplexity is 57.39869195885327
At time: 767.132405757904 and batch: 950, loss is 4.022711005210876 and perplexity is 55.852316689050426
At time: 768.2054674625397 and batch: 1000, loss is 4.044709095954895 and perplexity is 57.09457457539424
At time: 769.285626411438 and batch: 1050, loss is 3.9744242334365847 and perplexity is 53.21946609362646
At time: 770.3606145381927 and batch: 1100, loss is 3.951346263885498 and perplexity is 52.00533262922504
At time: 771.4366219043732 and batch: 1150, loss is 3.963736925125122 and perplexity is 52.65372177813977
At time: 772.5086243152618 and batch: 1200, loss is 3.936242184638977 and perplexity is 51.225742281958354
At time: 773.5811285972595 and batch: 1250, loss is 3.996994037628174 and perplexity is 54.43427647084847
At time: 774.6620151996613 and batch: 1300, loss is 3.982858171463013 and perplexity is 53.67021389009657
At time: 775.7350845336914 and batch: 1350, loss is 3.9516780614852904 and perplexity is 52.02259073670882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550083414713542 and perplexity of 94.6403023793914
Finished 25 epochs...
Completing Train Step...
At time: 778.9106419086456 and batch: 50, loss is 4.160474133491516 and perplexity is 64.10190825751343
At time: 779.9821691513062 and batch: 100, loss is 4.172997274398804 and perplexity is 64.90971305646515
At time: 781.0539305210114 and batch: 150, loss is 4.148430056571961 and perplexity is 63.33449063894741
At time: 782.1338312625885 and batch: 200, loss is 4.131785569190979 and perplexity is 62.28904509694293
At time: 783.2053070068359 and batch: 250, loss is 4.1419702243804934 and perplexity is 62.926679072773794
At time: 784.2760004997253 and batch: 300, loss is 4.1353354120254515 and perplexity is 62.51055434624696
At time: 785.346508026123 and batch: 350, loss is 4.140834412574768 and perplexity is 62.85524678228664
At time: 786.4188761711121 and batch: 400, loss is 4.155232915878296 and perplexity is 63.76681512202878
At time: 787.4973137378693 and batch: 450, loss is 4.079740738868713 and perplexity is 59.13013771605755
At time: 788.5753984451294 and batch: 500, loss is 4.161987094879151 and perplexity is 64.19896537290064
At time: 789.6459362506866 and batch: 550, loss is 4.156698107719421 and perplexity is 63.86031421961073
At time: 790.7203640937805 and batch: 600, loss is 4.101896395683289 and perplexity is 60.45482522829832
At time: 791.7951529026031 and batch: 650, loss is 4.109232096672058 and perplexity is 60.8999343471684
At time: 792.8665945529938 and batch: 700, loss is 4.126376352310181 and perplexity is 61.95301977895787
At time: 793.9374318122864 and batch: 750, loss is 4.084762015342712 and perplexity is 59.427793165223626
At time: 795.0083832740784 and batch: 800, loss is 4.050880661010742 and perplexity is 57.448027012212556
At time: 796.0795888900757 and batch: 850, loss is 4.016455073356628 and perplexity is 55.503999063605015
At time: 797.1581671237946 and batch: 900, loss is 4.049718384742737 and perplexity is 57.38129532161491
At time: 798.2301604747772 and batch: 950, loss is 4.0224935245513915 and perplexity is 55.84017121113428
At time: 799.3014090061188 and batch: 1000, loss is 4.044555644989014 and perplexity is 57.08581402995337
At time: 800.3723969459534 and batch: 1050, loss is 3.9743751096725464 and perplexity is 53.2168518173439
At time: 801.4897313117981 and batch: 1100, loss is 3.95140052318573 and perplexity is 52.00815447873693
At time: 802.5605361461639 and batch: 1150, loss is 3.9638615608215333 and perplexity is 52.66028472040217
At time: 803.6321966648102 and batch: 1200, loss is 3.93643057346344 and perplexity is 51.23539354839592
At time: 804.7029929161072 and batch: 1250, loss is 3.9972321605682373 and perplexity is 54.447240064205154
At time: 805.7742619514465 and batch: 1300, loss is 3.9831035137176514 and perplexity is 53.68338307679221
At time: 806.8462424278259 and batch: 1350, loss is 3.951903643608093 and perplexity is 52.03432742690488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550084635416667 and perplexity of 94.64041790717481
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 810.0239198207855 and batch: 50, loss is 4.1602793264389035 and perplexity is 64.08942196994686
At time: 811.1215150356293 and batch: 100, loss is 4.17345685005188 and perplexity is 64.93955083606744
At time: 812.2005603313446 and batch: 150, loss is 4.149201488494873 and perplexity is 63.38336773710064
At time: 813.2745022773743 and batch: 200, loss is 4.1331373310089115 and perplexity is 62.373301984572336
At time: 814.3452825546265 and batch: 250, loss is 4.1435775518417355 and perplexity is 63.0279041812476
At time: 815.4165160655975 and batch: 300, loss is 4.136944761276245 and perplexity is 62.6112366548191
At time: 816.4946389198303 and batch: 350, loss is 4.1425208568573 and perplexity is 62.96133808724263
At time: 817.5664494037628 and batch: 400, loss is 4.156623916625977 and perplexity is 63.85557652882045
At time: 818.6373534202576 and batch: 450, loss is 4.08071126461029 and perplexity is 59.18755289376123
At time: 819.7083647251129 and batch: 500, loss is 4.162672824859619 and perplexity is 64.24300362562136
At time: 820.7788419723511 and batch: 550, loss is 4.156401352882385 and perplexity is 63.84136617407255
At time: 821.8496685028076 and batch: 600, loss is 4.101269707679749 and perplexity is 60.41695078354129
At time: 822.9231815338135 and batch: 650, loss is 4.108673677444458 and perplexity is 60.86593614637735
At time: 824.006840467453 and batch: 700, loss is 4.12551516532898 and perplexity is 61.89968961179699
At time: 825.0783236026764 and batch: 750, loss is 4.083954529762268 and perplexity is 59.379825448391294
At time: 826.1527638435364 and batch: 800, loss is 4.049939484596252 and perplexity is 57.393983720254894
At time: 827.2281808853149 and batch: 850, loss is 4.014621114730835 and perplexity is 55.402300309914075
At time: 828.3255257606506 and batch: 900, loss is 4.047367386817932 and perplexity is 57.24655046988794
At time: 829.3971984386444 and batch: 950, loss is 4.01996826171875 and perplexity is 55.69933799748704
At time: 830.4682965278625 and batch: 1000, loss is 4.041419091224671 and perplexity is 56.90704181596044
At time: 831.5401256084442 and batch: 1050, loss is 3.970598368644714 and perplexity is 53.01624460890182
At time: 832.6115498542786 and batch: 1100, loss is 3.9475269603729246 and perplexity is 51.807087300167474
At time: 833.6830840110779 and batch: 1150, loss is 3.9600890254974366 and perplexity is 52.46199619651833
At time: 834.7657694816589 and batch: 1200, loss is 3.9325278568267823 and perplexity is 51.03582600669578
At time: 835.8381662368774 and batch: 1250, loss is 3.9932680130004883 and perplexity is 54.23183040984991
At time: 836.909366607666 and batch: 1300, loss is 3.979496536254883 and perplexity is 53.490097122508296
At time: 837.9815649986267 and batch: 1350, loss is 3.9488260650634768 and perplexity is 51.874433865931124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550316162109375 and perplexity of 94.66233222690649
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 841.1458342075348 and batch: 50, loss is 4.160190305709839 and perplexity is 64.08371693681462
At time: 842.2448258399963 and batch: 100, loss is 4.1733998107910155 and perplexity is 64.93584683772454
At time: 843.3155860900879 and batch: 150, loss is 4.149089503288269 and perplexity is 63.376270134989994
At time: 844.3863725662231 and batch: 200, loss is 4.1330953884124755 and perplexity is 62.370685941201025
At time: 845.4573657512665 and batch: 250, loss is 4.143596220016479 and perplexity is 63.0290808081593
At time: 846.5282664299011 and batch: 300, loss is 4.1370477199554445 and perplexity is 62.61768335691438
At time: 847.600593328476 and batch: 350, loss is 4.142632913589478 and perplexity is 62.968393724350655
At time: 848.6730306148529 and batch: 400, loss is 4.156696157455444 and perplexity is 63.86018967526179
At time: 849.7442665100098 and batch: 450, loss is 4.080699529647827 and perplexity is 59.186858334125056
At time: 850.8153593540192 and batch: 500, loss is 4.16263720035553 and perplexity is 64.24071504124103
At time: 851.886883020401 and batch: 550, loss is 4.156283497810364 and perplexity is 63.83384258861921
At time: 852.9582471847534 and batch: 600, loss is 4.101011710166931 and perplexity is 60.40136537109238
At time: 854.0298676490784 and batch: 650, loss is 4.108484992980957 and perplexity is 60.85445277327117
At time: 855.1006238460541 and batch: 700, loss is 4.125282616615295 and perplexity is 61.885296592204234
At time: 856.1979994773865 and batch: 750, loss is 4.083790102005005 and perplexity is 59.37006255953309
At time: 857.2686033248901 and batch: 800, loss is 4.049691872596741 and perplexity is 57.379774040502205
At time: 858.340202331543 and batch: 850, loss is 4.014263277053833 and perplexity is 55.38247882611899
At time: 859.4112694263458 and batch: 900, loss is 4.046930809020996 and perplexity is 57.22156335180896
At time: 860.4827716350555 and batch: 950, loss is 4.0195049285888675 and perplexity is 55.673536626656805
At time: 861.5610721111298 and batch: 1000, loss is 4.040908393859863 and perplexity is 56.87798695941684
At time: 862.6323096752167 and batch: 1050, loss is 3.9699849224090578 and perplexity is 52.983731966616446
At time: 863.7032356262207 and batch: 1100, loss is 3.9468695020675657 and perplexity is 51.773037494735725
At time: 864.7824540138245 and batch: 1150, loss is 3.9594532537460325 and perplexity is 52.42865294178717
At time: 865.8539795875549 and batch: 1200, loss is 3.931866641044617 and perplexity is 51.00209146721833
At time: 866.9247949123383 and batch: 1250, loss is 3.9925778818130495 and perplexity is 54.194416244158454
At time: 868.0002245903015 and batch: 1300, loss is 3.9788728857040407 and perplexity is 53.456748394030576
At time: 869.0721342563629 and batch: 1350, loss is 3.94828857421875 and perplexity is 51.846559324479294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5503328450520835 and perplexity of 94.66391148634497
Annealing...
Finished 28 epochs...
Completing Train Step...
At time: 872.2521131038666 and batch: 50, loss is 4.160172991752624 and perplexity is 64.08260740368667
At time: 873.3269762992859 and batch: 100, loss is 4.173384256362915 and perplexity is 64.93483680561903
At time: 874.3969526290894 and batch: 150, loss is 4.149064960479737 and perplexity is 63.37471472241376
At time: 875.4661848545074 and batch: 200, loss is 4.133077373504639 and perplexity is 62.36956234916283
At time: 876.5356450080872 and batch: 250, loss is 4.143593168258667 and perplexity is 63.02888845896302
At time: 877.6061871051788 and batch: 300, loss is 4.137053747177124 and perplexity is 62.61806076871037
At time: 878.6767468452454 and batch: 350, loss is 4.1426400327682495 and perplexity is 62.96884200919826
At time: 879.7471690177917 and batch: 400, loss is 4.15669692993164 and perplexity is 63.860239005757236
At time: 880.8184385299683 and batch: 450, loss is 4.080692739486694 and perplexity is 59.18645644718446
At time: 881.8885371685028 and batch: 500, loss is 4.162629203796387 and perplexity is 64.24020133861777
At time: 882.9850282669067 and batch: 550, loss is 4.1562610912323 and perplexity is 63.83241230666604
At time: 884.0554959774017 and batch: 600, loss is 4.100960869789123 and perplexity is 60.3982946209165
At time: 885.1265001296997 and batch: 650, loss is 4.10844997882843 and perplexity is 60.8523220434829
At time: 886.2065732479095 and batch: 700, loss is 4.12523717880249 and perplexity is 61.882484723565376
At time: 887.2811334133148 and batch: 750, loss is 4.083757605552673 and perplexity is 59.36813327447282
At time: 888.3515706062317 and batch: 800, loss is 4.049648866653443 and perplexity is 57.37730642225487
At time: 889.4226694107056 and batch: 850, loss is 4.014201383590699 and perplexity is 55.379051118784915
At time: 890.4965319633484 and batch: 900, loss is 4.046856927871704 and perplexity is 57.2173359131102
At time: 891.575804233551 and batch: 950, loss is 4.019423937797546 and perplexity is 55.66902776546033
At time: 892.6508033275604 and batch: 1000, loss is 4.0408193349838255 and perplexity is 56.872921695383674
At time: 893.7220180034637 and batch: 1050, loss is 3.9698785591125487 and perplexity is 52.97809674191898
At time: 894.7935035228729 and batch: 1100, loss is 3.9467533016204834 and perplexity is 51.76702179415234
At time: 895.8645470142365 and batch: 1150, loss is 3.9593437719345093 and perplexity is 52.42291327208783
At time: 896.9364039897919 and batch: 1200, loss is 3.931751184463501 and perplexity is 50.9962032800293
At time: 898.0085446834564 and batch: 1250, loss is 3.992457504272461 and perplexity is 54.18789284626053
At time: 899.0867373943329 and batch: 1300, loss is 3.9787648010253904 and perplexity is 53.450970850796296
At time: 900.1585628986359 and batch: 1350, loss is 3.9481952142715455 and perplexity is 51.841719158380364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550338134765625 and perplexity of 94.66441223264388
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 903.3617939949036 and batch: 50, loss is 4.1601701784133915 and perplexity is 64.08242711782673
At time: 904.4351217746735 and batch: 100, loss is 4.173382072448731 and perplexity is 64.9346949936627
At time: 905.506767988205 and batch: 150, loss is 4.149061775207519 and perplexity is 63.37451285701716
At time: 906.5790810585022 and batch: 200, loss is 4.13307520866394 and perplexity is 62.36942732914204
At time: 907.6565184593201 and batch: 250, loss is 4.143593754768371 and perplexity is 63.02892542602862
At time: 908.7333450317383 and batch: 300, loss is 4.1370559453964235 and perplexity is 62.61819841709137
At time: 909.8343305587769 and batch: 350, loss is 4.14264175415039 and perplexity is 62.96895040273162
At time: 910.9052693843842 and batch: 400, loss is 4.15669810295105 and perplexity is 63.860313915101024
At time: 911.9770855903625 and batch: 450, loss is 4.080692377090454 and perplexity is 59.186434998239065
At time: 913.0494654178619 and batch: 500, loss is 4.162628817558288 and perplexity is 64.24017652660935
At time: 914.1211290359497 and batch: 550, loss is 4.156257886886596 and perplexity is 63.832207765877634
At time: 915.1934378147125 and batch: 600, loss is 4.100952348709106 and perplexity is 60.39777996440788
At time: 916.2675030231476 and batch: 650, loss is 4.108444094657898 and perplexity is 60.851963979096176
At time: 917.3439831733704 and batch: 700, loss is 4.125229258537292 and perplexity is 61.88199459981619
At time: 918.4159092903137 and batch: 750, loss is 4.083752040863037 and perplexity is 59.36780291015606
At time: 919.4879546165466 and batch: 800, loss is 4.049641256332397 and perplexity is 57.376869764193835
At time: 920.5671212673187 and batch: 850, loss is 4.014190158843994 and perplexity is 55.37842950645209
At time: 921.6392858028412 and batch: 900, loss is 4.046843571662903 and perplexity is 57.216571711528125
At time: 922.7141304016113 and batch: 950, loss is 4.019408984184265 and perplexity is 55.668195318571456
At time: 923.788604259491 and batch: 1000, loss is 4.040802898406983 and perplexity is 56.87198690691834
At time: 924.8605072498322 and batch: 1050, loss is 3.9698586797714235 and perplexity is 52.97704358272977
At time: 925.9326214790344 and batch: 1100, loss is 3.946731266975403 and perplexity is 51.76588113876725
At time: 927.0042436122894 and batch: 1150, loss is 3.9593232536315917 and perplexity is 52.421837653908455
At time: 928.0760028362274 and batch: 1200, loss is 3.9317293548583985 and perplexity is 50.99509006520052
At time: 929.1476285457611 and batch: 1250, loss is 3.992435154914856 and perplexity is 54.1866817951986
At time: 930.2193696498871 and batch: 1300, loss is 3.9787448167800905 and perplexity is 53.449902684156584
At time: 931.2913503646851 and batch: 1350, loss is 3.9481779813766478 and perplexity is 51.840825783180534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.550338541666667 and perplexity of 94.66445075169968
Annealing...
Model not improving. Stopping early with 94.6403023793914loss at 29 epochs.
Finished Training.
Improved accuracyfrom -172.88695462763891 to -94.6403023793914
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc203461c50>
SETTINGS FOR THIS RUN
{'dropout': 0.9946054317887449, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.746236205741887, 'wordvec_dim': 200, 'anneal': 5.251549236760035, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5484368801116943 and batch: 50, loss is 11.906815662384034 and perplexity is 148273.77312984873
At time: 2.6190502643585205 and batch: 100, loss is 11.280027980804443 and perplexity is 79223.47859714393
At time: 3.7155137062072754 and batch: 150, loss is 10.62419553756714 and perplexity is 41117.764672214
At time: 4.786278009414673 and batch: 200, loss is 10.145327625274659 and perplexity is 25471.809893762766
At time: 5.85680627822876 and batch: 250, loss is 9.69688325881958 and perplexity is 16266.828612655085
At time: 6.927091836929321 and batch: 300, loss is 9.586144218444824 and perplexity is 14561.61474540009
At time: 7.997474670410156 and batch: 350, loss is 9.380960979461669 and perplexity is 11860.406886931514
At time: 9.068145990371704 and batch: 400, loss is 9.384206886291503 and perplexity is 11898.967210403403
At time: 10.138445854187012 and batch: 450, loss is 9.169741744995116 and perplexity is 9602.144567880721
At time: 11.208496332168579 and batch: 500, loss is 9.131618232727051 and perplexity is 9242.967145466188
At time: 12.280438423156738 and batch: 550, loss is 9.031793117523193 and perplexity is 8364.845283246297
At time: 13.351015567779541 and batch: 600, loss is 9.000541877746581 and perplexity is 8107.475998309643
At time: 14.421353101730347 and batch: 650, loss is 8.947952098846436 and perplexity is 7692.123012507306
At time: 15.492111444473267 and batch: 700, loss is 8.92758270263672 and perplexity is 7537.024109343283
At time: 16.57211399078369 and batch: 750, loss is 8.857897891998292 and perplexity is 7029.690034404551
At time: 17.65497088432312 and batch: 800, loss is 8.8908913230896 and perplexity is 7265.492199246439
At time: 18.73189949989319 and batch: 850, loss is 8.84212070465088 and perplexity is 6919.651628560288
At time: 19.809090852737427 and batch: 900, loss is 8.863855838775635 and perplexity is 7071.697568554943
At time: 20.886359930038452 and batch: 950, loss is 8.813545455932617 and perplexity is 6724.71924694639
At time: 21.963173389434814 and batch: 1000, loss is 8.820387725830079 and perplexity is 6770.88936509603
At time: 23.039843797683716 and batch: 1050, loss is 8.906957626342773 and perplexity is 7383.164548848544
At time: 24.116102695465088 and batch: 1100, loss is 8.770262393951416 and perplexity is 6439.862023531517
At time: 25.193193674087524 and batch: 1150, loss is 8.807186851501465 and perplexity is 6682.095076079782
At time: 26.270108222961426 and batch: 1200, loss is 8.709711856842041 and perplexity is 6061.495657878782
At time: 27.34679913520813 and batch: 1250, loss is 8.740666732788085 and perplexity is 6252.062778189667
At time: 28.423164129257202 and batch: 1300, loss is 8.704578647613525 and perplexity is 6030.4604556700215
At time: 29.500150680541992 and batch: 1350, loss is 8.752508125305177 and perplexity is 6326.5359705305755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.86780029296875 and perplexity of 960.8326890886934
Finished 1 epochs...
Completing Train Step...
At time: 32.68456768989563 and batch: 50, loss is 6.332171659469605 and perplexity is 562.3765590790237
At time: 33.7548406124115 and batch: 100, loss is 5.975179967880249 and perplexity is 393.53891908348555
At time: 34.851908922195435 and batch: 150, loss is 5.822368860244751 and perplexity is 337.77123953765073
At time: 35.92349028587341 and batch: 200, loss is 5.769707746505738 and perplexity is 320.44406806251504
At time: 36.99745726585388 and batch: 250, loss is 5.793532962799072 and perplexity is 328.17039249131295
At time: 38.075693130493164 and batch: 300, loss is 5.76899320602417 and perplexity is 320.21517958858504
At time: 39.147130489349365 and batch: 350, loss is 5.7634576892852785 and perplexity is 318.4475200700602
At time: 40.21824526786804 and batch: 400, loss is 5.807353439331055 and perplexity is 332.7373497695482
At time: 41.2893123626709 and batch: 450, loss is 5.777463855743409 and perplexity is 322.93913074032105
At time: 42.360504388809204 and batch: 500, loss is 5.793692541122437 and perplexity is 328.22276555101587
At time: 43.433499813079834 and batch: 550, loss is 5.768213367462158 and perplexity is 319.96556078723415
At time: 44.50739359855652 and batch: 600, loss is 5.713935012817383 and perplexity is 303.06127500924674
At time: 45.593947649002075 and batch: 650, loss is 5.744285516738891 and perplexity is 312.4003432569864
At time: 46.67698574066162 and batch: 700, loss is 5.747578811645508 and perplexity is 313.4308656920007
At time: 47.759692907333374 and batch: 750, loss is 5.703435220718384 and perplexity is 299.8958419043559
At time: 48.8408899307251 and batch: 800, loss is 5.679585542678833 and perplexity is 292.828040043787
At time: 49.912556171417236 and batch: 850, loss is 5.6961930465698245 and perplexity is 297.73178967096476
At time: 50.9844651222229 and batch: 900, loss is 5.770435991287232 and perplexity is 320.6775147757005
At time: 52.06290936470032 and batch: 950, loss is 5.71121916770935 and perplexity is 302.2393241788626
At time: 53.1343252658844 and batch: 1000, loss is 5.7416889858245845 and perplexity is 311.5902382945111
At time: 54.20597195625305 and batch: 1050, loss is 5.713523044586181 and perplexity is 302.9364491057542
At time: 55.277297258377075 and batch: 1100, loss is 5.688225498199463 and perplexity is 295.3690224657499
At time: 56.34888219833374 and batch: 1150, loss is 5.708109064102173 and perplexity is 301.3007887941634
At time: 57.41867542266846 and batch: 1200, loss is 5.721439685821533 and perplexity is 305.3442063905958
At time: 58.48929047584534 and batch: 1250, loss is 5.71336932182312 and perplexity is 302.88988445688074
At time: 59.560706615448 and batch: 1300, loss is 5.681603469848633 and perplexity is 293.4195423053951
At time: 60.632577657699585 and batch: 1350, loss is 5.665271120071411 and perplexity is 288.6662337181101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4812325032552085 and perplexity of 240.1425014679926
Finished 2 epochs...
Completing Train Step...
At time: 63.83367657661438 and batch: 50, loss is 5.760057640075684 and perplexity is 317.36662142673316
At time: 64.93050241470337 and batch: 100, loss is 5.759218072891235 and perplexity is 317.10028264623855
At time: 66.00893640518188 and batch: 150, loss is 5.688780269622803 and perplexity is 295.5329302202189
At time: 67.08096766471863 and batch: 200, loss is 5.7162458610534665 and perplexity is 303.7624134222519
At time: 68.15486216545105 and batch: 250, loss is 5.746178407669067 and perplexity is 312.99224305747003
At time: 69.22787928581238 and batch: 300, loss is 5.745200567245483 and perplexity is 312.68633617837133
At time: 70.30265998840332 and batch: 350, loss is 5.752918376922607 and perplexity is 315.1089263294527
At time: 71.3745048046112 and batch: 400, loss is 5.778712902069092 and perplexity is 323.34274869127665
At time: 72.44562196731567 and batch: 450, loss is 5.732581653594971 and perplexity is 308.76536552763156
At time: 73.51730751991272 and batch: 500, loss is 5.7684434795379635 and perplexity is 320.03919719860204
At time: 74.58876061439514 and batch: 550, loss is 5.767749891281128 and perplexity is 319.81729873167916
At time: 75.66075730323792 and batch: 600, loss is 5.705134935379029 and perplexity is 300.4060127130838
At time: 76.73222780227661 and batch: 650, loss is 5.730639533996582 and perplexity is 308.1662881881591
At time: 77.80408453941345 and batch: 700, loss is 5.766116847991944 and perplexity is 319.2954494554231
At time: 78.87589263916016 and batch: 750, loss is 5.6900942993164065 and perplexity is 295.9215245222772
At time: 79.94773817062378 and batch: 800, loss is 5.665623035430908 and perplexity is 288.7678376764718
At time: 81.01941251754761 and batch: 850, loss is 5.638635339736939 and perplexity is 281.0788794523433
At time: 82.09079456329346 and batch: 900, loss is 5.725909471511841 and perplexity is 306.71208433817674
At time: 83.16202712059021 and batch: 950, loss is 5.678090019226074 and perplexity is 292.39043614728297
At time: 84.2335159778595 and batch: 1000, loss is 5.715914783477783 and perplexity is 303.66186114505274
At time: 85.33417439460754 and batch: 1050, loss is 5.664632034301758 and perplexity is 288.48181017346997
At time: 86.40850687026978 and batch: 1100, loss is 5.683802137374878 and perplexity is 294.06538406010014
At time: 87.4793791770935 and batch: 1150, loss is 5.698926076889038 and perplexity is 298.54661263987856
At time: 88.55021667480469 and batch: 1200, loss is 5.6903266429901125 and perplexity is 295.99028800448406
At time: 89.6211678981781 and batch: 1250, loss is 5.712370529174804 and perplexity is 302.5875112962179
At time: 90.69819474220276 and batch: 1300, loss is 5.646656446456909 and perplexity is 283.34250941343845
At time: 91.78079748153687 and batch: 1350, loss is 5.626706228256226 and perplexity is 277.74577815889575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.480234375 and perplexity of 239.9029280343974
Finished 3 epochs...
Completing Train Step...
At time: 94.94950079917908 and batch: 50, loss is 5.695840606689453 and perplexity is 297.626875603667
At time: 96.02852153778076 and batch: 100, loss is 5.733162202835083 and perplexity is 308.9446710687734
At time: 97.10520243644714 and batch: 150, loss is 5.667676048278809 and perplexity is 289.3612907322125
At time: 98.176518201828 and batch: 200, loss is 5.68034252166748 and perplexity is 293.04978863631084
At time: 99.25507259368896 and batch: 250, loss is 5.684392337799072 and perplexity is 294.2389928014502
At time: 100.32673358917236 and batch: 300, loss is 5.696711053848267 and perplexity is 297.8860568573511
At time: 101.39781093597412 and batch: 350, loss is 5.712961177825928 and perplexity is 302.76628699322663
At time: 102.46914434432983 and batch: 400, loss is 5.765484542846679 and perplexity is 319.09362111514645
At time: 103.54025554656982 and batch: 450, loss is 5.750333156585693 and perplexity is 314.295352411799
At time: 104.61622881889343 and batch: 500, loss is 5.711350622177124 and perplexity is 302.279057499867
At time: 105.69091176986694 and batch: 550, loss is 5.701606254577637 and perplexity is 299.3478438514639
At time: 106.76443934440613 and batch: 600, loss is 5.680869512557983 and perplexity is 293.20426390534067
At time: 107.8356728553772 and batch: 650, loss is 5.669720878601074 and perplexity is 289.9535908438222
At time: 108.9065294265747 and batch: 700, loss is 5.714308404922486 and perplexity is 303.17445682598094
At time: 109.97817969322205 and batch: 750, loss is 5.663710613250732 and perplexity is 288.21611938607833
At time: 111.04926443099976 and batch: 800, loss is 5.618401527404785 and perplexity is 275.44873389314495
At time: 112.1658947467804 and batch: 850, loss is 5.61265926361084 and perplexity is 273.87156718878936
At time: 113.23689579963684 and batch: 900, loss is 5.666100339889526 and perplexity is 288.90570075161327
At time: 114.30803537368774 and batch: 950, loss is 5.683085289001465 and perplexity is 293.85465930573207
At time: 115.37844324111938 and batch: 1000, loss is 5.6845442581176755 and perplexity is 294.28369707864016
At time: 116.449298620224 and batch: 1050, loss is 5.6665407371521 and perplexity is 289.0329620520734
At time: 117.5199978351593 and batch: 1100, loss is 5.639740829467773 and perplexity is 281.3897810847503
At time: 118.59075903892517 and batch: 1150, loss is 5.674425315856934 and perplexity is 291.320872943791
At time: 119.66143703460693 and batch: 1200, loss is 5.644601497650147 and perplexity is 282.76085290367524
At time: 120.73183512687683 and batch: 1250, loss is 5.659065389633179 and perplexity is 286.8803958305142
At time: 121.8030436038971 and batch: 1300, loss is 5.663320188522339 and perplexity is 288.10361464969316
At time: 122.87349557876587 and batch: 1350, loss is 5.639207010269165 and perplexity is 281.2396099030111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.475928141276042 and perplexity of 238.8720711036462
Finished 4 epochs...
Completing Train Step...
At time: 126.07987022399902 and batch: 50, loss is 5.703258543014527 and perplexity is 299.8428616759623
At time: 127.15169882774353 and batch: 100, loss is 5.733682641983032 and perplexity is 309.1054998173061
At time: 128.22295808792114 and batch: 150, loss is 5.646958198547363 and perplexity is 283.42802150904646
At time: 129.2939329147339 and batch: 200, loss is 5.6744803619384765 and perplexity is 291.3369094576878
At time: 130.36519074440002 and batch: 250, loss is 5.725193023681641 and perplexity is 306.4924198293329
At time: 131.44055843353271 and batch: 300, loss is 5.701483116149903 and perplexity is 299.3109848980497
At time: 132.5172402858734 and batch: 350, loss is 5.692873096466064 and perplexity is 296.7449739807761
At time: 133.58819961547852 and batch: 400, loss is 5.732964649200439 and perplexity is 308.8836439543625
At time: 134.6597020626068 and batch: 450, loss is 5.725384454727173 and perplexity is 306.55109760990393
At time: 135.73086094856262 and batch: 500, loss is 5.740533437728882 and perplexity is 311.2303887397861
At time: 136.8015739917755 and batch: 550, loss is 5.7014314079284665 and perplexity is 299.2955084594973
At time: 137.87287497520447 and batch: 600, loss is 5.65035400390625 and perplexity is 284.39212392896593
At time: 138.94396328926086 and batch: 650, loss is 5.7133950424194335 and perplexity is 302.89767506551533
At time: 140.0457465648651 and batch: 700, loss is 5.732691240310669 and perplexity is 308.79920396404884
At time: 141.1182291507721 and batch: 750, loss is 5.7083242225646975 and perplexity is 301.36562318322143
At time: 142.1897644996643 and batch: 800, loss is 5.6549357986450195 and perplexity is 285.6981399300041
At time: 143.26443815231323 and batch: 850, loss is 5.654562921524048 and perplexity is 285.5916294890074
At time: 144.3357982635498 and batch: 900, loss is 5.715154981613159 and perplexity is 303.4312259263696
At time: 145.40659093856812 and batch: 950, loss is 5.668025722503662 and perplexity is 289.4624906097152
At time: 146.4776268005371 and batch: 1000, loss is 5.7189365673065184 and perplexity is 304.5808494391606
At time: 147.54827618598938 and batch: 1050, loss is 5.677730360031128 and perplexity is 292.28529414718525
At time: 148.6191794872284 and batch: 1100, loss is 5.693573341369629 and perplexity is 296.9528409068487
At time: 149.68989372253418 and batch: 1150, loss is 5.682279977798462 and perplexity is 293.61811011717845
At time: 150.76026582717896 and batch: 1200, loss is 5.664092111587524 and perplexity is 288.3260943325566
At time: 151.83087372779846 and batch: 1250, loss is 5.690145072937011 and perplexity is 295.9365499109355
At time: 152.9051694869995 and batch: 1300, loss is 5.644430990219116 and perplexity is 282.71264418713974
At time: 153.9766881465912 and batch: 1350, loss is 5.624423379898071 and perplexity is 277.1124498365455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.5815828450520835 and perplexity of 265.4915052961563
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 157.13482642173767 and batch: 50, loss is 5.669610538482666 and perplexity is 289.9215990952947
At time: 158.23390102386475 and batch: 100, loss is 5.647390098571777 and perplexity is 283.5504605172579
At time: 159.3122296333313 and batch: 150, loss is 5.591794595718384 and perplexity is 268.2165282996221
At time: 160.39144897460938 and batch: 200, loss is 5.5691870498657225 and perplexity is 262.22084010033086
At time: 161.46195888519287 and batch: 250, loss is 5.597657375335693 and perplexity is 269.7936413103702
At time: 162.53445601463318 and batch: 300, loss is 5.568344135284423 and perplexity is 261.9999034591293
At time: 163.60656023025513 and batch: 350, loss is 5.566344814300537 and perplexity is 261.47660484962717
At time: 164.6787667274475 and batch: 400, loss is 5.594891548156738 and perplexity is 269.0484697074953
At time: 165.7511866092682 and batch: 450, loss is 5.575893449783325 and perplexity is 263.9853079210059
At time: 166.87403750419617 and batch: 500, loss is 5.58592038154602 and perplexity is 266.6455855123096
At time: 167.94507360458374 and batch: 550, loss is 5.5661375617980955 and perplexity is 261.42241878423494
At time: 169.02134132385254 and batch: 600, loss is 5.511366834640503 and perplexity is 247.48917276319344
At time: 170.09627056121826 and batch: 650, loss is 5.526990652084351 and perplexity is 251.38626285568054
At time: 171.16817426681519 and batch: 700, loss is 5.516394681930542 and perplexity is 248.73664394916906
At time: 172.246568441391 and batch: 750, loss is 5.4765771293640135 and perplexity is 239.02714654795662
At time: 173.3198618888855 and batch: 800, loss is 5.466392335891723 and perplexity is 236.6050595907014
At time: 174.3921947479248 and batch: 850, loss is 5.440873975753784 and perplexity is 230.64367237702425
At time: 175.46431684494019 and batch: 900, loss is 5.478077154159546 and perplexity is 239.38596224352403
At time: 176.535959482193 and batch: 950, loss is 5.443978385925293 and perplexity is 231.36079748885854
At time: 177.61652827262878 and batch: 1000, loss is 5.46101806640625 and perplexity is 235.3368910309816
At time: 178.6886749267578 and batch: 1050, loss is 5.4006665992736815 and perplexity is 221.55405476282823
At time: 179.75979685783386 and batch: 1100, loss is 5.398974628448486 and perplexity is 221.17950871581098
At time: 180.83199334144592 and batch: 1150, loss is 5.424254446029663 and perplexity is 226.84216018125494
At time: 181.91039061546326 and batch: 1200, loss is 5.356800594329834 and perplexity is 212.0454406366951
At time: 182.98301482200623 and batch: 1250, loss is 5.378916130065918 and perplexity is 216.78717893561202
At time: 184.05455350875854 and batch: 1300, loss is 5.358091087341308 and perplexity is 212.31926043922152
At time: 185.12603068351746 and batch: 1350, loss is 5.3178919506073 and perplexity is 203.95348448364507
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.300115152994792 and perplexity of 200.35988068673262
Finished 6 epochs...
Completing Train Step...
At time: 188.28914427757263 and batch: 50, loss is 5.484749584197998 and perplexity is 240.9885890906211
At time: 189.38779878616333 and batch: 100, loss is 5.493578519821167 and perplexity is 243.12568207561264
At time: 190.45942735671997 and batch: 150, loss is 5.456393537521362 and perplexity is 234.25108139485909
At time: 191.53196048736572 and batch: 200, loss is 5.4485897445678715 and perplexity is 232.43014878814475
At time: 192.61035585403442 and batch: 250, loss is 5.476924352645874 and perplexity is 239.11015674893787
At time: 193.70975279808044 and batch: 300, loss is 5.4536039257049564 and perplexity is 233.59852242647963
At time: 194.78188514709473 and batch: 350, loss is 5.454194221496582 and perplexity is 233.7364553578072
At time: 195.85267448425293 and batch: 400, loss is 5.487706146240234 and perplexity is 241.7021411163772
At time: 196.92452335357666 and batch: 450, loss is 5.4631428623199465 and perplexity is 235.83746551636565
At time: 197.9973385334015 and batch: 500, loss is 5.482737827301025 and perplexity is 240.50426596796208
At time: 199.06869530677795 and batch: 550, loss is 5.4715329360961915 and perplexity is 237.8244832077095
At time: 200.14069199562073 and batch: 600, loss is 5.41929500579834 and perplexity is 225.7199351500665
At time: 201.21287202835083 and batch: 650, loss is 5.436288166046142 and perplexity is 229.58840586027307
At time: 202.28530645370483 and batch: 700, loss is 5.435231275558472 and perplexity is 229.34588424001174
At time: 203.357159614563 and batch: 750, loss is 5.39035101890564 and perplexity is 219.28034359253724
At time: 204.4294581413269 and batch: 800, loss is 5.382995138168335 and perplexity is 217.67326153546662
At time: 205.5011341571808 and batch: 850, loss is 5.367640953063965 and perplexity is 214.35659351169028
At time: 206.5749762058258 and batch: 900, loss is 5.404750680923462 and perplexity is 222.4607498604396
At time: 207.64661836624146 and batch: 950, loss is 5.374451274871826 and perplexity is 215.82141318022573
At time: 208.71750664710999 and batch: 1000, loss is 5.400354337692261 and perplexity is 221.48488274376191
At time: 209.79050874710083 and batch: 1050, loss is 5.3454552745819095 and perplexity is 209.653312698513
At time: 210.86261677742004 and batch: 1100, loss is 5.341683235168457 and perplexity is 208.86398176944232
At time: 211.9356348514557 and batch: 1150, loss is 5.370950508117676 and perplexity is 215.06719369564868
At time: 213.00794911384583 and batch: 1200, loss is 5.31557466506958 and perplexity is 203.48141319691072
At time: 214.08027935028076 and batch: 1250, loss is 5.3395783233642575 and perplexity is 208.4248038862527
At time: 215.15151143074036 and batch: 1300, loss is 5.318084726333618 and perplexity is 203.99280555470375
At time: 216.22846913337708 and batch: 1350, loss is 5.297775611877442 and perplexity is 199.8916784103939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.293566080729167 and perplexity of 199.05199673686428
Finished 7 epochs...
Completing Train Step...
At time: 219.40053057670593 and batch: 50, loss is 5.428629417419433 and perplexity is 227.83676223338182
At time: 220.47245359420776 and batch: 100, loss is 5.426119737625122 and perplexity is 227.2656818290247
At time: 221.58990597724915 and batch: 150, loss is 5.384921989440918 and perplexity is 218.09308987996016
At time: 222.66190385818481 and batch: 200, loss is 5.379706745147705 and perplexity is 216.958641920496
At time: 223.73344016075134 and batch: 250, loss is 5.410051794052124 and perplexity is 223.64317076661976
At time: 224.80595088005066 and batch: 300, loss is 5.397618188858032 and perplexity is 220.87969545884698
At time: 225.87861466407776 and batch: 350, loss is 5.396421194076538 and perplexity is 220.61546179075512
At time: 226.95131826400757 and batch: 400, loss is 5.431760950088501 and perplexity is 228.5513588048106
At time: 228.02798652648926 and batch: 450, loss is 5.406329917907715 and perplexity is 222.8123456576341
At time: 229.10023379325867 and batch: 500, loss is 5.426579837799072 and perplexity is 227.37027086763956
At time: 230.1715705394745 and batch: 550, loss is 5.411516580581665 and perplexity is 223.97100031211784
At time: 231.24338150024414 and batch: 600, loss is 5.360795936584473 and perplexity is 212.89432941696398
At time: 232.3158152103424 and batch: 650, loss is 5.384821033477783 and perplexity is 218.07107319339482
At time: 233.38806748390198 and batch: 700, loss is 5.385755662918091 and perplexity is 218.27498411421223
At time: 234.45995235443115 and batch: 750, loss is 5.345073862075806 and perplexity is 209.57336355087526
At time: 235.53128385543823 and batch: 800, loss is 5.338020448684692 and perplexity is 208.10035695113618
At time: 236.6037356853485 and batch: 850, loss is 5.322409343719483 and perplexity is 204.8769067099158
At time: 237.6756556034088 and batch: 900, loss is 5.3605284500122075 and perplexity is 212.83739065804977
At time: 238.74736046791077 and batch: 950, loss is 5.334997148513794 and perplexity is 207.4721572031013
At time: 239.82201743125916 and batch: 1000, loss is 5.354618673324585 and perplexity is 211.58327861956334
At time: 240.89784002304077 and batch: 1050, loss is 5.3053358364105225 and perplexity is 201.40863140874166
At time: 241.9702627658844 and batch: 1100, loss is 5.3011701297760006 and perplexity is 200.57136724583262
At time: 243.04248881340027 and batch: 1150, loss is 5.330941047668457 and perplexity is 206.63233356696085
At time: 244.114098072052 and batch: 1200, loss is 5.285517053604126 and perplexity is 197.4562525253166
At time: 245.18552231788635 and batch: 1250, loss is 5.309298467636109 and perplexity is 202.20832293554614
At time: 246.25871467590332 and batch: 1300, loss is 5.284075918197632 and perplexity is 197.17189627571273
At time: 247.3330397605896 and batch: 1350, loss is 5.25875828742981 and perplexity is 192.24263293737724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.28057373046875 and perplexity of 196.4825710578211
Finished 8 epochs...
Completing Train Step...
At time: 250.51877403259277 and batch: 50, loss is 5.376448364257812 and perplexity is 216.25285850780182
At time: 251.59100198745728 and batch: 100, loss is 5.386127319335937 and perplexity is 218.3561224897787
At time: 252.67126083374023 and batch: 150, loss is 5.3444991874694825 and perplexity is 209.45296165994907
At time: 253.74372124671936 and batch: 200, loss is 5.337477350234986 and perplexity is 207.98736865455422
At time: 254.8162453174591 and batch: 250, loss is 5.364842472076416 and perplexity is 213.7575592441407
At time: 255.89039635658264 and batch: 300, loss is 5.3501721858978275 and perplexity is 210.6445647677674
At time: 256.967737197876 and batch: 350, loss is 5.352547760009766 and perplexity is 211.1455613843381
At time: 258.0460252761841 and batch: 400, loss is 5.386670608520507 and perplexity is 218.4747852406879
At time: 259.1230068206787 and batch: 450, loss is 5.362761077880859 and perplexity is 213.3131082004392
At time: 260.2042419910431 and batch: 500, loss is 5.390450801849365 and perplexity is 219.30222512240562
At time: 261.27623462677 and batch: 550, loss is 5.372493276596069 and perplexity is 215.3992486589228
At time: 262.34886360168457 and batch: 600, loss is 5.320084075927735 and perplexity is 204.40106647985132
At time: 263.42116928100586 and batch: 650, loss is 5.342865810394287 and perplexity is 209.11112524392405
At time: 264.49333572387695 and batch: 700, loss is 5.346177930831909 and perplexity is 209.80487473229735
At time: 265.5640239715576 and batch: 750, loss is 5.304074745178223 and perplexity is 201.1547968374793
At time: 266.6350634098053 and batch: 800, loss is 5.300127439498901 and perplexity is 200.36234242435305
At time: 267.71255254745483 and batch: 850, loss is 5.291430225372315 and perplexity is 198.62730416574294
At time: 268.78602623939514 and batch: 900, loss is 5.3270354652404786 and perplexity is 205.8268878470816
At time: 269.8573567867279 and batch: 950, loss is 5.301674337387085 and perplexity is 200.6725223552085
At time: 270.9292724132538 and batch: 1000, loss is 5.3156717586517335 and perplexity is 203.50117089537707
At time: 272.0015070438385 and batch: 1050, loss is 5.272789516448975 and perplexity is 194.95904608879306
At time: 273.0740284919739 and batch: 1100, loss is 5.27091155052185 and perplexity is 194.59326321444323
At time: 274.14594054222107 and batch: 1150, loss is 5.298032293319702 and perplexity is 199.94299348023543
At time: 275.243536233902 and batch: 1200, loss is 5.255830965042114 and perplexity is 191.6806996553258
At time: 276.3227951526642 and batch: 1250, loss is 5.274794092178345 and perplexity is 195.3502482269615
At time: 277.39865040779114 and batch: 1300, loss is 5.251433086395264 and perplexity is 190.83956216532798
At time: 278.4725408554077 and batch: 1350, loss is 5.229487199783325 and perplexity is 186.69704068574922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.283470865885417 and perplexity of 197.05263304785154
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 281.6767747402191 and batch: 50, loss is 5.3305698680877684 and perplexity is 206.55565009658042
At time: 282.7903034687042 and batch: 100, loss is 5.340824747085572 and perplexity is 208.68475147469312
At time: 283.87465500831604 and batch: 150, loss is 5.301557779312134 and perplexity is 200.64913371540115
At time: 284.9594123363495 and batch: 200, loss is 5.29126651763916 and perplexity is 198.59479000151805
At time: 286.0366265773773 and batch: 250, loss is 5.30069429397583 and perplexity is 200.47595091186213
At time: 287.1105737686157 and batch: 300, loss is 5.290386085510254 and perplexity is 198.42001771662444
At time: 288.1837809085846 and batch: 350, loss is 5.288624668121338 and perplexity is 198.07082487456503
At time: 289.2575900554657 and batch: 400, loss is 5.313979024887085 and perplexity is 203.15698897861623
At time: 290.33160305023193 and batch: 450, loss is 5.285138216018677 and perplexity is 197.38146284284383
At time: 291.40855860710144 and batch: 500, loss is 5.312264289855957 and perplexity is 202.80892707504992
At time: 292.48599219322205 and batch: 550, loss is 5.285801343917846 and perplexity is 197.51239540535343
At time: 293.5667898654938 and batch: 600, loss is 5.238405952453613 and perplexity is 188.36959286872724
At time: 294.63925647735596 and batch: 650, loss is 5.245262460708618 and perplexity is 189.6655884622233
At time: 295.7117269039154 and batch: 700, loss is 5.243223552703857 and perplexity is 189.2792717416382
At time: 296.78410387039185 and batch: 750, loss is 5.20657320022583 and perplexity is 182.46770532232335
At time: 297.856511592865 and batch: 800, loss is 5.200401983261108 and perplexity is 181.3451249299912
At time: 298.93162727355957 and batch: 850, loss is 5.174448804855347 and perplexity is 176.69919169294607
At time: 300.0068166255951 and batch: 900, loss is 5.205768117904663 and perplexity is 182.3208629166282
At time: 301.07781171798706 and batch: 950, loss is 5.175259790420532 and perplexity is 176.84255030981623
At time: 302.14974308013916 and batch: 1000, loss is 5.185594549179077 and perplexity is 178.67965205590986
At time: 303.24869990348816 and batch: 1050, loss is 5.139761619567871 and perplexity is 170.6750778727952
At time: 304.3206889629364 and batch: 1100, loss is 5.134370813369751 and perplexity is 169.7574771311991
At time: 305.39361333847046 and batch: 1150, loss is 5.154315671920776 and perplexity is 173.1772561406932
At time: 306.4656763076782 and batch: 1200, loss is 5.102825822830201 and perplexity is 164.48605964748782
At time: 307.5379590988159 and batch: 1250, loss is 5.115283632278443 and perplexity is 166.54801267709124
At time: 308.6102156639099 and batch: 1300, loss is 5.091121168136596 and perplexity is 162.57203049417302
At time: 309.68274545669556 and batch: 1350, loss is 5.088634881973267 and perplexity is 162.168331967201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.185719807942708 and perplexity of 178.7020346499911
Finished 10 epochs...
Completing Train Step...
At time: 312.8402862548828 and batch: 50, loss is 5.271823348999024 and perplexity is 194.77077397023064
At time: 313.9397704601288 and batch: 100, loss is 5.284485034942627 and perplexity is 197.25257910334398
At time: 315.01234459877014 and batch: 150, loss is 5.247425374984741 and perplexity is 190.07626283783102
At time: 316.084431886673 and batch: 200, loss is 5.243247861862183 and perplexity is 189.28387301734904
At time: 317.1561427116394 and batch: 250, loss is 5.255908641815186 and perplexity is 191.69558937182018
At time: 318.228000164032 and batch: 300, loss is 5.247024965286255 and perplexity is 190.00016969397188
At time: 319.2998352050781 and batch: 350, loss is 5.248177146911621 and perplexity is 190.21921056150921
At time: 320.371878862381 and batch: 400, loss is 5.2748587036132815 and perplexity is 195.36287049458167
At time: 321.4444332122803 and batch: 450, loss is 5.248790197372436 and perplexity is 190.335860288631
At time: 322.5168242454529 and batch: 500, loss is 5.2775078392028805 and perplexity is 195.88109935387845
At time: 323.58953070640564 and batch: 550, loss is 5.255563116073608 and perplexity is 191.62936505290764
At time: 324.6617524623871 and batch: 600, loss is 5.210171775817871 and perplexity is 183.12551202673836
At time: 325.73430705070496 and batch: 650, loss is 5.2178964424133305 and perplexity is 184.54557324067562
At time: 326.80622959136963 and batch: 700, loss is 5.220442314147949 and perplexity is 185.0160011698336
At time: 327.8835301399231 and batch: 750, loss is 5.185365819931031 and perplexity is 178.63878746709537
At time: 328.9563081264496 and batch: 800, loss is 5.1813381385803225 and perplexity is 177.9207343695368
At time: 330.05502247810364 and batch: 850, loss is 5.158696508407592 and perplexity is 173.93758159783707
At time: 331.1272506713867 and batch: 900, loss is 5.191616516113282 and perplexity is 179.75890135269808
At time: 332.1996703147888 and batch: 950, loss is 5.164248123168945 and perplexity is 174.90590142571344
At time: 333.278297662735 and batch: 1000, loss is 5.178655662536621 and perplexity is 177.44410582005105
At time: 334.3495433330536 and batch: 1050, loss is 5.13593747138977 and perplexity is 170.0236374808891
At time: 335.4217975139618 and batch: 1100, loss is 5.133027667999268 and perplexity is 169.52962121774817
At time: 336.4965772628784 and batch: 1150, loss is 5.155292177200318 and perplexity is 173.34644724016752
At time: 337.5684700012207 and batch: 1200, loss is 5.106294651031494 and perplexity is 165.0576242865567
At time: 338.64147448539734 and batch: 1250, loss is 5.124500455856324 and perplexity is 168.09015222422542
At time: 339.71681118011475 and batch: 1300, loss is 5.1018759059906005 and perplexity is 164.32988575739677
At time: 340.7892668247223 and batch: 1350, loss is 5.094362001419068 and perplexity is 163.09975401147696
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1822823079427085 and perplexity of 178.08880100506045
Finished 11 epochs...
Completing Train Step...
At time: 343.9822943210602 and batch: 50, loss is 5.2558098316192625 and perplexity is 191.67664882885154
At time: 345.0546488761902 and batch: 100, loss is 5.265343284606933 and perplexity is 193.5127273270754
At time: 346.1270966529846 and batch: 150, loss is 5.229223575592041 and perplexity is 186.64782931632206
At time: 347.1993639469147 and batch: 200, loss is 5.224832401275635 and perplexity is 185.8300230410772
At time: 348.27120900154114 and batch: 250, loss is 5.238548622131348 and perplexity is 188.39646941502536
At time: 349.342805147171 and batch: 300, loss is 5.23006311416626 and perplexity is 186.80459316426848
At time: 350.41646814346313 and batch: 350, loss is 5.232219305038452 and perplexity is 187.20781407733912
At time: 351.4967257976532 and batch: 400, loss is 5.259558334350586 and perplexity is 192.39649760517034
At time: 352.56929206848145 and batch: 450, loss is 5.2340452003479 and perplexity is 187.54994820244886
At time: 353.641482591629 and batch: 500, loss is 5.263822774887085 and perplexity is 193.21871292678256
At time: 354.72058176994324 and batch: 550, loss is 5.242757244110107 and perplexity is 189.19102976620104
At time: 355.79257917404175 and batch: 600, loss is 5.1985093688964845 and perplexity is 181.00223312492494
At time: 356.9008774757385 and batch: 650, loss is 5.2066222667694095 and perplexity is 182.47665860158978
At time: 357.98110365867615 and batch: 700, loss is 5.210895128250122 and perplexity is 183.25802423200517
At time: 359.05432963371277 and batch: 750, loss is 5.176994161605835 and perplexity is 177.14952706227612
At time: 360.13179564476013 and batch: 800, loss is 5.173140544891357 and perplexity is 176.46817436309635
At time: 361.2103145122528 and batch: 850, loss is 5.151439847946167 and perplexity is 172.6799442690742
At time: 362.28299856185913 and batch: 900, loss is 5.185791015625 and perplexity is 178.71476006076753
At time: 363.3553433418274 and batch: 950, loss is 5.159608421325683 and perplexity is 174.0962698693831
At time: 364.43856620788574 and batch: 1000, loss is 5.175806159973145 and perplexity is 176.93919809521122
At time: 365.5107696056366 and batch: 1050, loss is 5.1343320369720455 and perplexity is 169.7508946753752
At time: 366.5828106403351 and batch: 1100, loss is 5.1318739223480225 and perplexity is 169.3341399440299
At time: 367.65597558021545 and batch: 1150, loss is 5.154785966873169 and perplexity is 173.25871968457056
At time: 368.72752380371094 and batch: 1200, loss is 5.107474155426026 and perplexity is 165.25242534151946
At time: 369.7994849681854 and batch: 1250, loss is 5.126445350646972 and perplexity is 168.4173880020749
At time: 370.8765802383423 and batch: 1300, loss is 5.103636903762817 and perplexity is 164.61952527254425
At time: 371.9518473148346 and batch: 1350, loss is 5.0937110042572025 and perplexity is 162.9936110876342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.181595865885416 and perplexity of 177.9665953104807
Finished 12 epochs...
Completing Train Step...
At time: 375.16108894348145 and batch: 50, loss is 5.244313011169433 and perplexity is 189.48559601705193
At time: 376.23702692985535 and batch: 100, loss is 5.252516918182373 and perplexity is 191.0465122783376
At time: 377.30922198295593 and batch: 150, loss is 5.217181501388549 and perplexity is 184.4136811925601
At time: 378.3810908794403 and batch: 200, loss is 5.212391843795777 and perplexity is 183.5325147315962
At time: 379.4606192111969 and batch: 250, loss is 5.22702467918396 and perplexity is 186.2378609790025
At time: 380.5318465232849 and batch: 300, loss is 5.218648328781128 and perplexity is 184.68438271937052
At time: 381.60309743881226 and batch: 350, loss is 5.221764240264893 and perplexity is 185.26074038177066
At time: 382.67498230934143 and batch: 400, loss is 5.248931770324707 and perplexity is 190.36280860582644
At time: 383.74643182754517 and batch: 450, loss is 5.223828859329224 and perplexity is 185.643628361136
At time: 384.85116314888 and batch: 500, loss is 5.254776926040649 and perplexity is 191.47876716311777
At time: 385.9311993122101 and batch: 550, loss is 5.234073104858399 and perplexity is 187.55518176496716
At time: 387.00324153900146 and batch: 600, loss is 5.190514192581177 and perplexity is 179.56085805957673
At time: 388.07552194595337 and batch: 650, loss is 5.198525381088257 and perplexity is 181.00513139059672
At time: 389.1483290195465 and batch: 700, loss is 5.20379490852356 and perplexity is 181.96146038438718
At time: 390.22029995918274 and batch: 750, loss is 5.170594749450683 and perplexity is 176.0194938561009
At time: 391.2927441596985 and batch: 800, loss is 5.167429504394531 and perplexity is 175.46322984376755
At time: 392.3646717071533 and batch: 850, loss is 5.146247272491455 and perplexity is 171.78561457562031
At time: 393.443785905838 and batch: 900, loss is 5.180876083374024 and perplexity is 177.8385441575828
At time: 394.5161545276642 and batch: 950, loss is 5.155171585083008 and perplexity is 173.32554428545782
At time: 395.5951671600342 and batch: 1000, loss is 5.172440986633301 and perplexity is 176.34476776452195
At time: 396.67274260520935 and batch: 1050, loss is 5.131561498641968 and perplexity is 169.28124420783828
At time: 397.7446162700653 and batch: 1100, loss is 5.129551877975464 and perplexity is 168.94139471967978
At time: 398.81855511665344 and batch: 1150, loss is 5.152247228622437 and perplexity is 172.81941901628764
At time: 399.897488117218 and batch: 1200, loss is 5.10656325340271 and perplexity is 165.10196511058604
At time: 400.9686155319214 and batch: 1250, loss is 5.125607509613037 and perplexity is 168.27634009968972
At time: 402.0402510166168 and batch: 1300, loss is 5.102113704681397 and perplexity is 164.36896783573798
At time: 403.1114618778229 and batch: 1350, loss is 5.090873613357544 and perplexity is 162.53178999215368
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.181116536458333 and perplexity of 177.8813111255532
Finished 13 epochs...
Completing Train Step...
At time: 406.29043555259705 and batch: 50, loss is 5.234646539688111 and perplexity is 187.6627632812304
At time: 407.39184951782227 and batch: 100, loss is 5.242491235733032 and perplexity is 189.14071006044418
At time: 408.4685552120209 and batch: 150, loss is 5.207538394927979 and perplexity is 182.64390720569665
At time: 409.5405476093292 and batch: 200, loss is 5.2027643775939945 and perplexity is 181.77404005927974
At time: 410.6130061149597 and batch: 250, loss is 5.217579355239868 and perplexity is 184.48706548300177
At time: 411.7115116119385 and batch: 300, loss is 5.209733896255493 and perplexity is 183.0453426612161
At time: 412.7835142612457 and batch: 350, loss is 5.213453969955444 and perplexity is 183.72755297591755
At time: 413.85649156570435 and batch: 400, loss is 5.240908107757568 and perplexity is 188.8415130071506
At time: 414.9286415576935 and batch: 450, loss is 5.2156579875946045 and perplexity is 184.13293831759492
At time: 416.00126099586487 and batch: 500, loss is 5.247296009063721 and perplexity is 190.05167503747097
At time: 417.075053691864 and batch: 550, loss is 5.226734352111817 and perplexity is 186.18379893431955
At time: 418.15351843833923 and batch: 600, loss is 5.183815870285034 and perplexity is 178.362120806783
At time: 419.2258017063141 and batch: 650, loss is 5.191361465454102 and perplexity is 179.7130595726512
At time: 420.29825830459595 and batch: 700, loss is 5.197871046066284 and perplexity is 180.8867321345854
At time: 421.3702428340912 and batch: 750, loss is 5.165071105957031 and perplexity is 175.04990522031582
At time: 422.44948554039 and batch: 800, loss is 5.162565793991089 and perplexity is 174.61189949771773
At time: 423.52167868614197 and batch: 850, loss is 5.141549787521362 and perplexity is 170.98054661081522
At time: 424.59435772895813 and batch: 900, loss is 5.176873321533203 and perplexity is 177.12812159390444
At time: 425.66711831092834 and batch: 950, loss is 5.151330919265747 and perplexity is 172.66113549503598
At time: 426.7393660545349 and batch: 1000, loss is 5.1695098781585695 and perplexity is 175.82863890561123
At time: 427.81977105140686 and batch: 1050, loss is 5.128522052764892 and perplexity is 168.76750416609443
At time: 428.89228320121765 and batch: 1100, loss is 5.1262315654754635 and perplexity is 168.3813867103041
At time: 429.96471881866455 and batch: 1150, loss is 5.14936782836914 and perplexity is 172.32251846849377
At time: 431.04609966278076 and batch: 1200, loss is 5.104792308807373 and perplexity is 164.8098374251155
At time: 432.1208612918854 and batch: 1250, loss is 5.123877754211426 and perplexity is 167.98551479227595
At time: 433.1911828517914 and batch: 1300, loss is 5.099672298431397 and perplexity is 163.96816586965073
At time: 434.2622239589691 and batch: 1350, loss is 5.087198638916016 and perplexity is 161.9355860062014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180863444010416 and perplexity of 177.8362964057649
Finished 14 epochs...
Completing Train Step...
At time: 437.4033181667328 and batch: 50, loss is 5.225903425216675 and perplexity is 186.02915806487167
At time: 438.4986171722412 and batch: 100, loss is 5.233040771484375 and perplexity is 187.36166219690074
At time: 439.5689697265625 and batch: 150, loss is 5.199202957153321 and perplexity is 181.1278176952386
At time: 440.6395688056946 and batch: 200, loss is 5.1941282081604 and perplexity is 180.21096784387098
At time: 441.7102737426758 and batch: 250, loss is 5.209592256546021 and perplexity is 183.0194180080848
At time: 442.78118991851807 and batch: 300, loss is 5.2019866180419925 and perplexity is 181.63271852752715
At time: 443.8515386581421 and batch: 350, loss is 5.206471223831176 and perplexity is 182.44909887231927
At time: 444.9226608276367 and batch: 400, loss is 5.233652372360229 and perplexity is 187.47628780258924
At time: 445.99373030662537 and batch: 450, loss is 5.208316984176636 and perplexity is 182.78616716202953
At time: 447.06705713272095 and batch: 500, loss is 5.240621175765991 and perplexity is 188.78733610864538
At time: 448.14213514328003 and batch: 550, loss is 5.2202200508117675 and perplexity is 184.974883465815
At time: 449.2141344547272 and batch: 600, loss is 5.177667818069458 and perplexity is 177.26890519161898
At time: 450.2851514816284 and batch: 650, loss is 5.185198602676391 and perplexity is 178.60891847685787
At time: 451.3583996295929 and batch: 700, loss is 5.192478723526001 and perplexity is 179.91395764568355
At time: 452.4295446872711 and batch: 750, loss is 5.15975869178772 and perplexity is 174.12243336204602
At time: 453.5004515647888 and batch: 800, loss is 5.1578445148468015 and perplexity is 173.78945101045005
At time: 454.5737659931183 and batch: 850, loss is 5.136595773696899 and perplexity is 170.13560128268037
At time: 455.64935064315796 and batch: 900, loss is 5.172319412231445 and perplexity is 176.32333005802514
At time: 456.7294809818268 and batch: 950, loss is 5.146622066497803 and perplexity is 171.85001086125712
At time: 457.80648851394653 and batch: 1000, loss is 5.165520057678223 and perplexity is 175.1285118205229
At time: 458.87878251075745 and batch: 1050, loss is 5.1258823108673095 and perplexity is 168.32258900335086
At time: 459.9514923095703 and batch: 1100, loss is 5.12264500617981 and perplexity is 167.7785585682234
At time: 461.02347803115845 and batch: 1150, loss is 5.14585394859314 and perplexity is 171.71806047421313
At time: 462.09537863731384 and batch: 1200, loss is 5.102504596710205 and perplexity is 164.43323091419273
At time: 463.16722321510315 and batch: 1250, loss is 5.121476545333862 and perplexity is 167.58263038124613
At time: 464.23888301849365 and batch: 1300, loss is 5.096467714309693 and perplexity is 163.44355711423333
At time: 465.31050276756287 and batch: 1350, loss is 5.083218955993653 and perplexity is 161.2924143784936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180521240234375 and perplexity of 177.77545056504965
Finished 15 epochs...
Completing Train Step...
At time: 468.4996078014374 and batch: 50, loss is 5.2180038166046145 and perplexity is 184.56538973622847
At time: 469.57798433303833 and batch: 100, loss is 5.22480619430542 and perplexity is 185.82515306301224
At time: 470.6531276702881 and batch: 150, loss is 5.192094259262085 and perplexity is 179.84480045347533
At time: 471.73197531700134 and batch: 200, loss is 5.1866232204437255 and perplexity is 178.86354924821967
At time: 472.80450463294983 and batch: 250, loss is 5.202220544815064 and perplexity is 181.67521225327275
At time: 473.8790559768677 and batch: 300, loss is 5.195404262542724 and perplexity is 180.4410736216504
At time: 474.95371413230896 and batch: 350, loss is 5.200152378082276 and perplexity is 181.2998658963322
At time: 476.027024269104 and batch: 400, loss is 5.226932458877563 and perplexity is 186.22068685831385
At time: 477.1036968231201 and batch: 450, loss is 5.201924991607666 and perplexity is 181.62152549562418
At time: 478.1763105392456 and batch: 500, loss is 5.234714317321777 and perplexity is 187.67548305030596
At time: 479.249463558197 and batch: 550, loss is 5.214491863250732 and perplexity is 183.91834156328187
At time: 480.3229081630707 and batch: 600, loss is 5.172169027328491 and perplexity is 176.29681568487644
At time: 481.3959150314331 and batch: 650, loss is 5.179413461685181 and perplexity is 177.57862377471685
At time: 482.46737718582153 and batch: 700, loss is 5.187165966033936 and perplexity is 178.9606529997563
At time: 483.5386772155762 and batch: 750, loss is 5.154760189056397 and perplexity is 173.25425351060477
At time: 484.6103472709656 and batch: 800, loss is 5.153224773406983 and perplexity is 172.98844033751118
At time: 485.68309354782104 and batch: 850, loss is 5.131911373138427 and perplexity is 169.3404817601656
At time: 486.75620460510254 and batch: 900, loss is 5.168034439086914 and perplexity is 175.5694057502444
At time: 487.82882022857666 and batch: 950, loss is 5.142444429397583 and perplexity is 171.1335814132965
At time: 488.9008688926697 and batch: 1000, loss is 5.162024345397949 and perplexity is 174.517381720957
At time: 489.97719264030457 and batch: 1050, loss is 5.122399578094482 and perplexity is 167.73738605048771
At time: 491.05351662635803 and batch: 1100, loss is 5.119172658920288 and perplexity is 167.1969834499036
At time: 492.12531304359436 and batch: 1150, loss is 5.142344379425049 and perplexity is 171.11646035967132
At time: 493.2235417366028 and batch: 1200, loss is 5.10009241104126 and perplexity is 164.0370654355235
At time: 494.29529190063477 and batch: 1250, loss is 5.118769750595093 and perplexity is 167.12963196247279
At time: 495.3679337501526 and batch: 1300, loss is 5.093217754364014 and perplexity is 162.9132343309178
At time: 496.4395275115967 and batch: 1350, loss is 5.07941424369812 and perplexity is 160.6799090884127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180289713541667 and perplexity of 177.73429556735965
Finished 16 epochs...
Completing Train Step...
At time: 499.62414813041687 and batch: 50, loss is 5.210753087997436 and perplexity is 183.23199606450405
At time: 500.69803833961487 and batch: 100, loss is 5.217705717086792 and perplexity is 184.51037908227346
At time: 501.7723214626312 and batch: 150, loss is 5.185292587280274 and perplexity is 178.62570575417126
At time: 502.8454818725586 and batch: 200, loss is 5.179939632415771 and perplexity is 177.67208503505918
At time: 503.9203271865845 and batch: 250, loss is 5.195777511596679 and perplexity is 180.50843565229934
At time: 504.9955098628998 and batch: 300, loss is 5.189028263092041 and perplexity is 179.29424142131114
At time: 506.06981110572815 and batch: 350, loss is 5.194030475616455 and perplexity is 180.19335622816484
At time: 507.14654326438904 and batch: 400, loss is 5.2210352420806885 and perplexity is 185.12573485379932
At time: 508.2271864414215 and batch: 450, loss is 5.195961933135987 and perplexity is 180.5417283657127
At time: 509.3013370037079 and batch: 500, loss is 5.229147596359253 and perplexity is 186.6336484961798
At time: 510.37555146217346 and batch: 550, loss is 5.208933258056641 and perplexity is 182.89884822010782
At time: 511.4501781463623 and batch: 600, loss is 5.166981229782104 and perplexity is 175.38459175945945
At time: 512.5239486694336 and batch: 650, loss is 5.1738967609405515 and perplexity is 176.60167289922768
At time: 513.5964493751526 and batch: 700, loss is 5.182402591705323 and perplexity is 178.11022348448716
At time: 514.6691842079163 and batch: 750, loss is 5.1500539970397945 and perplexity is 172.44080135828082
At time: 515.7455973625183 and batch: 800, loss is 5.148906564712524 and perplexity is 172.2430506827174
At time: 516.8202383518219 and batch: 850, loss is 5.12753023147583 and perplexity is 168.60019994421995
At time: 517.8918290138245 and batch: 900, loss is 5.163642015457153 and perplexity is 174.79992173082104
At time: 518.964926481247 and batch: 950, loss is 5.138423748016358 and perplexity is 170.4468892191472
At time: 520.1036217212677 and batch: 1000, loss is 5.158470640182495 and perplexity is 173.8982990615092
At time: 521.1751067638397 and batch: 1050, loss is 5.118981533050537 and perplexity is 167.16503083460492
At time: 522.2473180294037 and batch: 1100, loss is 5.115584421157837 and perplexity is 166.59811600207343
At time: 523.319094657898 and batch: 1150, loss is 5.138805198669433 and perplexity is 170.5119186983347
At time: 524.3910491466522 and batch: 1200, loss is 5.097287883758545 and perplexity is 163.57766351385857
At time: 525.4622919559479 and batch: 1250, loss is 5.115524129867554 and perplexity is 166.58807188949024
At time: 526.5340051651001 and batch: 1300, loss is 5.089488468170166 and perplexity is 162.3068157124407
At time: 527.6065049171448 and batch: 1350, loss is 5.075390148162842 and perplexity is 160.03461701290723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180001627604167 and perplexity of 177.68310019088332
Finished 17 epochs...
Completing Train Step...
At time: 530.7610461711884 and batch: 50, loss is 5.203974695205688 and perplexity is 181.99417757259417
At time: 531.8585176467896 and batch: 100, loss is 5.210739088058472 and perplexity is 183.22943084569928
At time: 532.9305469989777 and batch: 150, loss is 5.17908429145813 and perplexity is 177.52017979834574
At time: 534.0020005702972 and batch: 200, loss is 5.173707962036133 and perplexity is 176.56833384415336
At time: 535.0736312866211 and batch: 250, loss is 5.189601345062256 and perplexity is 179.39702116622945
At time: 536.1454017162323 and batch: 300, loss is 5.182903118133545 and perplexity is 178.19939467288435
At time: 537.2171838283539 and batch: 350, loss is 5.188207511901855 and perplexity is 179.14714583196854
At time: 538.289395570755 and batch: 400, loss is 5.214911966323853 and perplexity is 183.99562245560946
At time: 539.3613088130951 and batch: 450, loss is 5.190125179290772 and perplexity is 179.49102008418598
At time: 540.4335315227509 and batch: 500, loss is 5.2237293148040775 and perplexity is 185.62514947405563
At time: 541.5058937072754 and batch: 550, loss is 5.203682813644409 and perplexity is 181.94106457962934
At time: 542.5778081417084 and batch: 600, loss is 5.161770429611206 and perplexity is 174.4730746280502
At time: 543.650509595871 and batch: 650, loss is 5.168586006164551 and perplexity is 175.66627076561753
At time: 544.7227001190186 and batch: 700, loss is 5.177205381393432 and perplexity is 177.18694849969006
At time: 545.7968373298645 and batch: 750, loss is 5.145591297149658 and perplexity is 171.67296440029142
At time: 546.8977043628693 and batch: 800, loss is 5.144181632995606 and perplexity is 171.4311336662612
At time: 547.9712021350861 and batch: 850, loss is 5.123231697082519 and perplexity is 167.87702160306418
At time: 549.0452644824982 and batch: 900, loss is 5.159318056106567 and perplexity is 174.04572570632382
At time: 550.119359254837 and batch: 950, loss is 5.134249572753906 and perplexity is 169.73689687773398
At time: 551.1925964355469 and batch: 1000, loss is 5.15474531173706 and perplexity is 173.25167597092238
At time: 552.2717752456665 and batch: 1050, loss is 5.115601959228516 and perplexity is 166.6010378372285
At time: 553.3468995094299 and batch: 1100, loss is 5.112005519866943 and perplexity is 166.0029434568223
At time: 554.4205622673035 and batch: 1150, loss is 5.135338668823242 and perplexity is 169.9218573665332
At time: 555.4948127269745 and batch: 1200, loss is 5.094586544036865 and perplexity is 163.13638096920735
At time: 556.5687830448151 and batch: 1250, loss is 5.112627906799316 and perplexity is 166.1062936781427
At time: 557.6446475982666 and batch: 1300, loss is 5.086044225692749 and perplexity is 161.74875328622846
At time: 558.7230446338654 and batch: 1350, loss is 5.071533412933349 and perplexity is 159.41859454888538
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.179978841145833 and perplexity of 177.67905146845243
Finished 18 epochs...
Completing Train Step...
At time: 561.8719277381897 and batch: 50, loss is 5.197765340805054 and perplexity is 180.8676124658546
At time: 562.9698143005371 and batch: 100, loss is 5.204269313812256 and perplexity is 182.04780434292837
At time: 564.0417582988739 and batch: 150, loss is 5.173451566696167 and perplexity is 176.5230683493492
At time: 565.1143276691437 and batch: 200, loss is 5.168023242950439 and perplexity is 175.5674400622209
At time: 566.1852645874023 and batch: 250, loss is 5.183726720809936 and perplexity is 178.34622062609262
At time: 567.2568094730377 and batch: 300, loss is 5.177294664382934 and perplexity is 177.20276898639253
At time: 568.3284683227539 and batch: 350, loss is 5.183100090026856 and perplexity is 178.23449840215036
At time: 569.4006118774414 and batch: 400, loss is 5.209236192703247 and perplexity is 182.9542630111643
At time: 570.4726114273071 and batch: 450, loss is 5.18460865020752 and perplexity is 178.50357878020228
At time: 571.5515213012695 and batch: 500, loss is 5.218707704544068 and perplexity is 184.6953488210547
At time: 572.6235342025757 and batch: 550, loss is 5.198854198455811 and perplexity is 181.06465880770224
At time: 573.6948671340942 and batch: 600, loss is 5.156860065460205 and perplexity is 173.61844827758412
At time: 574.8119337558746 and batch: 650, loss is 5.163451900482178 and perplexity is 174.76669280683362
At time: 575.8876864910126 and batch: 700, loss is 5.172582578659058 and perplexity is 176.36973854521128
At time: 576.9617156982422 and batch: 750, loss is 5.141100673675537 and perplexity is 170.9037741210501
At time: 578.0350298881531 and batch: 800, loss is 5.140063667297364 and perplexity is 170.7266376789169
At time: 579.1085071563721 and batch: 850, loss is 5.119248628616333 and perplexity is 167.20968583640803
At time: 580.1904542446136 and batch: 900, loss is 5.155372695922852 and perplexity is 173.3604054365956
At time: 581.2623240947723 and batch: 950, loss is 5.130210046768188 and perplexity is 169.0526232730497
At time: 582.3343200683594 and batch: 1000, loss is 5.1510050582885745 and perplexity is 172.60488113475205
At time: 583.4068529605865 and batch: 1050, loss is 5.112261018753052 and perplexity is 166.04536244273731
At time: 584.4783143997192 and batch: 1100, loss is 5.1083340740203855 and perplexity is 165.3945900911291
At time: 585.5505890846252 and batch: 1150, loss is 5.131520929336548 and perplexity is 169.2743767246456
At time: 586.6309049129486 and batch: 1200, loss is 5.091801567077637 and perplexity is 162.68268197086903
At time: 587.7041783332825 and batch: 1250, loss is 5.109562454223632 and perplexity is 165.59788236586144
At time: 588.7790057659149 and batch: 1300, loss is 5.082736310958862 and perplexity is 161.21458617875228
At time: 589.8508458137512 and batch: 1350, loss is 5.067642946243286 and perplexity is 158.79958671246158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1802445475260415 and perplexity of 177.72626819867241
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 593.0274257659912 and batch: 50, loss is 5.195648097991944 and perplexity is 180.4850769164581
At time: 594.1049563884735 and batch: 100, loss is 5.204481840133667 and perplexity is 182.08649840471395
At time: 595.1774487495422 and batch: 150, loss is 5.175367841720581 and perplexity is 176.8616594096441
At time: 596.2488203048706 and batch: 200, loss is 5.1702311325073245 and perplexity is 175.9555018207726
At time: 597.3207170963287 and batch: 250, loss is 5.1839714527130125 and perplexity is 178.38987297741653
At time: 598.3925802707672 and batch: 300, loss is 5.177245769500733 and perplexity is 177.19410488969385
At time: 599.4643535614014 and batch: 350, loss is 5.181835689544678 and perplexity is 178.00928102891234
At time: 600.5366995334625 and batch: 400, loss is 5.20673529624939 and perplexity is 182.49728500909413
At time: 601.6347470283508 and batch: 450, loss is 5.177770328521729 and perplexity is 177.28707803870117
At time: 602.7066380977631 and batch: 500, loss is 5.208547563552856 and perplexity is 182.82831874189117
At time: 603.7787871360779 and batch: 550, loss is 5.185718946456909 and perplexity is 178.7018807007923
At time: 604.8504884243011 and batch: 600, loss is 5.145468921661377 and perplexity is 171.6519571228623
At time: 605.9227356910706 and batch: 650, loss is 5.150235977172851 and perplexity is 172.47218501377074
At time: 606.9944367408752 and batch: 700, loss is 5.154156913757324 and perplexity is 173.14976501983435
At time: 608.0661911964417 and batch: 750, loss is 5.121439743041992 and perplexity is 167.5764630698568
At time: 609.137702703476 and batch: 800, loss is 5.12042688369751 and perplexity is 167.40681761131827
At time: 610.2097158432007 and batch: 850, loss is 5.089990215301514 and perplexity is 162.38827312542537
At time: 611.2822723388672 and batch: 900, loss is 5.119725437164306 and perplexity is 167.28943185419942
At time: 612.3624618053436 and batch: 950, loss is 5.094724931716919 and perplexity is 163.1589585966988
At time: 613.4352567195892 and batch: 1000, loss is 5.1179634380340575 and perplexity is 166.99492755512608
At time: 614.5076785087585 and batch: 1050, loss is 5.073665561676026 and perplexity is 159.75886132559606
At time: 615.582004070282 and batch: 1100, loss is 5.066662302017212 and perplexity is 158.6439371455472
At time: 616.6571748256683 and batch: 1150, loss is 5.085668230056763 and perplexity is 161.6879478928643
At time: 617.7318298816681 and batch: 1200, loss is 5.044141798019409 and perplexity is 155.1111253865009
At time: 618.8055782318115 and batch: 1250, loss is 5.058624982833862 and perplexity is 157.37397556594843
At time: 619.8801276683807 and batch: 1300, loss is 5.037623071670533 and perplexity is 154.10328688703513
At time: 620.9598543643951 and batch: 1350, loss is 5.0312275791168215 and perplexity is 153.12086534667782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.163916015625 and perplexity of 174.8478235009618
Finished 20 epochs...
Completing Train Step...
At time: 624.1704049110413 and batch: 50, loss is 5.184295949935913 and perplexity is 178.44776938889555
At time: 625.2447793483734 and batch: 100, loss is 5.191240930557251 and perplexity is 179.6913991829956
At time: 626.3191206455231 and batch: 150, loss is 5.1616884708404545 and perplexity is 174.4587756152972
At time: 627.3934562206268 and batch: 200, loss is 5.157933015823364 and perplexity is 173.804832227197
At time: 628.4948883056641 and batch: 250, loss is 5.1717130565643314 and perplexity is 176.21644781520163
At time: 629.5694682598114 and batch: 300, loss is 5.165375423431397 and perplexity is 175.10318407179201
At time: 630.643009185791 and batch: 350, loss is 5.170405750274658 and perplexity is 175.98622946036843
At time: 631.7178380489349 and batch: 400, loss is 5.196091604232788 and perplexity is 180.56514092758178
At time: 632.7974123954773 and batch: 450, loss is 5.166922903060913 and perplexity is 175.37436244959858
At time: 633.8726096153259 and batch: 500, loss is 5.199360466003418 and perplexity is 181.15634917644576
At time: 634.9462549686432 and batch: 550, loss is 5.178147468566895 and perplexity is 177.35395270508474
At time: 636.0272078514099 and batch: 600, loss is 5.138062076568604 and perplexity is 170.38525459237232
At time: 637.1075577735901 and batch: 650, loss is 5.14324912071228 and perplexity is 171.27134654168012
At time: 638.1846103668213 and batch: 700, loss is 5.148513488769531 and perplexity is 172.17535938792764
At time: 639.2603206634521 and batch: 750, loss is 5.117253704071045 and perplexity is 166.87644763297513
At time: 640.3343992233276 and batch: 800, loss is 5.116493263244629 and perplexity is 166.74959620684228
At time: 641.4083051681519 and batch: 850, loss is 5.086801013946533 and perplexity is 161.87120917352374
At time: 642.4820747375488 and batch: 900, loss is 5.117961463928222 and perplexity is 166.99459788979053
At time: 643.5584733486176 and batch: 950, loss is 5.093941764831543 and perplexity is 163.03122792701745
At time: 644.6363303661346 and batch: 1000, loss is 5.118097124099731 and perplexity is 167.01725394230854
At time: 645.720942735672 and batch: 1050, loss is 5.0750602436065675 and perplexity is 159.9818295714806
At time: 646.7969756126404 and batch: 1100, loss is 5.069354972839355 and perplexity is 159.07168868480323
At time: 647.8717014789581 and batch: 1150, loss is 5.089085178375244 and perplexity is 162.24137222724949
At time: 648.946986913681 and batch: 1200, loss is 5.049244060516357 and perplexity is 155.90456551301338
At time: 650.0214393138885 and batch: 1250, loss is 5.064419183731079 and perplexity is 158.28847884570112
At time: 651.0961184501648 and batch: 1300, loss is 5.043615627288818 and perplexity is 155.0295319202628
At time: 652.1704494953156 and batch: 1350, loss is 5.034761028289795 and perplexity is 153.6628671456868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.162270914713542 and perplexity of 174.56041765777965
Finished 21 epochs...
Completing Train Step...
At time: 655.3725397586823 and batch: 50, loss is 5.180437355041504 and perplexity is 177.7605384625523
At time: 656.4733512401581 and batch: 100, loss is 5.186285943984985 and perplexity is 178.803232955936
At time: 657.5473175048828 and batch: 150, loss is 5.155942430496216 and perplexity is 173.45920299474517
At time: 658.8321781158447 and batch: 200, loss is 5.152606000900269 and perplexity is 172.88143295667788
At time: 659.9060995578766 and batch: 250, loss is 5.16637113571167 and perplexity is 175.2776232937128
At time: 660.9805390834808 and batch: 300, loss is 5.160266971588134 and perplexity is 174.21095877365642
At time: 662.05544257164 and batch: 350, loss is 5.1654918670654295 and perplexity is 175.12357491004465
At time: 663.129465341568 and batch: 400, loss is 5.1912362670898435 and perplexity is 179.690561199966
At time: 664.2034394741058 and batch: 450, loss is 5.162215652465821 and perplexity is 174.5507713232783
At time: 665.2774007320404 and batch: 500, loss is 5.194976596832276 and perplexity is 180.3639216605059
At time: 666.3563425540924 and batch: 550, loss is 5.174591064453125 and perplexity is 176.72433063696968
At time: 667.4296388626099 and batch: 600, loss is 5.134922580718994 and perplexity is 169.8511696102184
At time: 668.5034236907959 and batch: 650, loss is 5.140061836242676 and perplexity is 170.72632506939289
At time: 669.5775580406189 and batch: 700, loss is 5.146171073913575 and perplexity is 171.77252525478949
At time: 670.6515061855316 and batch: 750, loss is 5.115679607391358 and perplexity is 166.61397460399567
At time: 671.725298166275 and batch: 800, loss is 5.114918212890625 and perplexity is 166.487163922591
At time: 672.7993624210358 and batch: 850, loss is 5.085732297897339 and perplexity is 161.6983072223793
At time: 673.8733444213867 and batch: 900, loss is 5.1173396396636965 and perplexity is 166.89078887560484
At time: 674.9514276981354 and batch: 950, loss is 5.094133892059326 and perplexity is 163.06255367404927
At time: 676.0274512767792 and batch: 1000, loss is 5.1186549949646 and perplexity is 167.11045399659366
At time: 677.101156949997 and batch: 1050, loss is 5.076234245300293 and perplexity is 160.16975880339623
At time: 678.1755139827728 and batch: 1100, loss is 5.0710544013977055 and perplexity is 159.34224948964214
At time: 679.2582402229309 and batch: 1150, loss is 5.091110525131225 and perplexity is 162.5703002483868
At time: 680.3324477672577 and batch: 1200, loss is 5.051896209716797 and perplexity is 156.3185964750386
At time: 681.4100730419159 and batch: 1250, loss is 5.067363481521607 and perplexity is 158.75521403074663
At time: 682.4838123321533 and batch: 1300, loss is 5.046552352905273 and perplexity is 155.48548028789713
At time: 683.5660390853882 and batch: 1350, loss is 5.036226835250854 and perplexity is 153.88827240594642
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161703694661458 and perplexity of 174.46143156468654
Finished 22 epochs...
Completing Train Step...
At time: 686.7708704471588 and batch: 50, loss is 5.177653779983521 and perplexity is 177.2664166929608
At time: 687.8439078330994 and batch: 100, loss is 5.182794694900513 and perplexity is 178.18007476577176
At time: 688.917397737503 and batch: 150, loss is 5.152081556320191 and perplexity is 172.7907899968497
At time: 689.9911670684814 and batch: 200, loss is 5.148971338272094 and perplexity is 172.25420783956184
At time: 691.0649077892303 and batch: 250, loss is 5.16270770072937 and perplexity is 174.6366798610492
At time: 692.1385977268219 and batch: 300, loss is 5.156884431838989 and perplexity is 173.62267878199958
At time: 693.211587190628 and batch: 350, loss is 5.162369146347046 and perplexity is 174.57756585498524
At time: 694.2901265621185 and batch: 400, loss is 5.188074865341187 and perplexity is 179.1233841552075
At time: 695.3647310733795 and batch: 450, loss is 5.159146318435669 and perplexity is 174.01583806525156
At time: 696.4408221244812 and batch: 500, loss is 5.1919499778747555 and perplexity is 179.81885406799722
At time: 697.5144462585449 and batch: 550, loss is 5.172206602096558 and perplexity is 176.30344012129174
At time: 698.5888633728027 and batch: 600, loss is 5.1329115295410155 and perplexity is 169.50993345218734
At time: 699.6692352294922 and batch: 650, loss is 5.13801007270813 and perplexity is 170.37639413175677
At time: 700.7435417175293 and batch: 700, loss is 5.144733066558838 and perplexity is 171.52569261624095
At time: 701.8170864582062 and batch: 750, loss is 5.114666576385498 and perplexity is 166.44527494513196
At time: 702.8908090591431 and batch: 800, loss is 5.11390832901001 and perplexity is 166.31911608809796
At time: 704.0119092464447 and batch: 850, loss is 5.0850290679931645 and perplexity is 161.58463611043322
At time: 705.0875816345215 and batch: 900, loss is 5.116886825561523 and perplexity is 166.8152354799916
At time: 706.1615467071533 and batch: 950, loss is 5.09419997215271 and perplexity is 163.07332921884404
At time: 707.2352058887482 and batch: 1000, loss is 5.118983325958252 and perplexity is 167.165330546347
At time: 708.3101551532745 and batch: 1050, loss is 5.076916027069092 and perplexity is 160.27899685888715
At time: 709.3842158317566 and batch: 1100, loss is 5.072062168121338 and perplexity is 159.50291024703193
At time: 710.4649429321289 and batch: 1150, loss is 5.092271490097046 and perplexity is 162.75914827321705
At time: 711.5411236286163 and batch: 1200, loss is 5.0534327030181885 and perplexity is 156.558963565329
At time: 712.6158661842346 and batch: 1250, loss is 5.068979368209839 and perplexity is 159.011951841528
At time: 713.6898200511932 and batch: 1300, loss is 5.048347702026367 and perplexity is 155.76488174480593
At time: 714.7647812366486 and batch: 1350, loss is 5.036914615631104 and perplexity is 153.99415014660033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161343587239584 and perplexity of 174.39861801884
Finished 23 epochs...
Completing Train Step...
At time: 717.9758758544922 and batch: 50, loss is 5.175310306549072 and perplexity is 176.8514839364632
At time: 719.0497174263 and batch: 100, loss is 5.180054693222046 and perplexity is 177.69252930456034
At time: 720.1230766773224 and batch: 150, loss is 5.148992938995361 and perplexity is 172.2579286952234
At time: 721.1960558891296 and batch: 200, loss is 5.146168375015259 and perplexity is 171.77206165883604
At time: 722.2695002555847 and batch: 250, loss is 5.159999561309815 and perplexity is 174.16437920089024
At time: 723.3426492214203 and batch: 300, loss is 5.154342861175537 and perplexity is 173.18196476524085
At time: 724.4160532951355 and batch: 350, loss is 5.160121450424194 and perplexity is 174.18560923665632
At time: 725.4901916980743 and batch: 400, loss is 5.185843448638916 and perplexity is 178.72413085993634
At time: 726.5709385871887 and batch: 450, loss is 5.1567737483978275 and perplexity is 173.6034626899195
At time: 727.6428225040436 and batch: 500, loss is 5.1897704124450685 and perplexity is 179.4273539151494
At time: 728.7153413295746 and batch: 550, loss is 5.170519046783447 and perplexity is 176.0061692152922
At time: 729.7900187969208 and batch: 600, loss is 5.131512031555176 and perplexity is 169.27287056495035
At time: 730.9058668613434 and batch: 650, loss is 5.136592988967895 and perplexity is 170.13512750179657
At time: 731.9810407161713 and batch: 700, loss is 5.143605976104737 and perplexity is 171.33247655190496
At time: 733.0564115047455 and batch: 750, loss is 5.113917121887207 and perplexity is 166.3205785180907
At time: 734.1312713623047 and batch: 800, loss is 5.113152389526367 and perplexity is 166.19343641046262
At time: 735.2057881355286 and batch: 850, loss is 5.084599103927612 and perplexity is 161.5151754572229
At time: 736.2803988456726 and batch: 900, loss is 5.116548414230347 and perplexity is 166.7587928650412
At time: 737.3545124530792 and batch: 950, loss is 5.094265584945679 and perplexity is 163.08402926645894
At time: 738.42928647995 and batch: 1000, loss is 5.119231510162353 and perplexity is 167.20682348959565
At time: 739.503636598587 and batch: 1050, loss is 5.077348461151123 and perplexity is 160.34832194794808
At time: 740.5788338184357 and batch: 1100, loss is 5.072688322067261 and perplexity is 159.602814898251
At time: 741.6531949043274 and batch: 1150, loss is 5.092952985763549 and perplexity is 162.8701057316682
At time: 742.7278394699097 and batch: 1200, loss is 5.054497318267822 and perplexity is 156.72572737930633
At time: 743.8020799160004 and batch: 1250, loss is 5.070145998001099 and perplexity is 159.19756817343156
At time: 744.8772146701813 and batch: 1300, loss is 5.0497167205810545 and perplexity is 155.97827279290698
At time: 745.9513998031616 and batch: 1350, loss is 5.0371435546875 and perplexity is 154.02940945798815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161300862630208 and perplexity of 174.39116706518018
Finished 24 epochs...
Completing Train Step...
At time: 749.2154183387756 and batch: 50, loss is 5.173388481140137 and perplexity is 176.5119326446849
At time: 750.3011050224304 and batch: 100, loss is 5.1777734375 and perplexity is 177.28762922123138
At time: 751.3785228729248 and batch: 150, loss is 5.146620349884033 and perplexity is 171.8497158614154
At time: 752.4514856338501 and batch: 200, loss is 5.143707056045532 and perplexity is 171.3497957037858
At time: 753.5252568721771 and batch: 250, loss is 5.157775287628174 and perplexity is 173.7774204665551
At time: 754.6041960716248 and batch: 300, loss is 5.152357196807861 and perplexity is 172.83842469919404
At time: 755.6785643100739 and batch: 350, loss is 5.158345460891724 and perplexity is 173.87653195819004
At time: 756.7605319023132 and batch: 400, loss is 5.183945741653442 and perplexity is 178.38528644372823
At time: 757.834878206253 and batch: 450, loss is 5.154806537628174 and perplexity is 173.2622837839037
At time: 758.9628672599792 and batch: 500, loss is 5.187932844161987 and perplexity is 179.0979466473428
At time: 760.0371241569519 and batch: 550, loss is 5.168848533630371 and perplexity is 175.71239404055996
At time: 761.1180884838104 and batch: 600, loss is 5.130143556594849 and perplexity is 169.0413833085025
At time: 762.1918435096741 and batch: 650, loss is 5.135240793228149 and perplexity is 169.90522697749208
At time: 763.2663054466248 and batch: 700, loss is 5.142693309783936 and perplexity is 171.1761785057272
At time: 764.3403179645538 and batch: 750, loss is 5.113117628097534 and perplexity is 166.18765938955963
At time: 765.4140872955322 and batch: 800, loss is 5.112424459457397 and perplexity is 166.07250323162268
At time: 766.4876811504364 and batch: 850, loss is 5.084093399047852 and perplexity is 161.43351709409546
At time: 767.561283826828 and batch: 900, loss is 5.115878648757935 and perplexity is 166.64714097782237
At time: 768.6348421573639 and batch: 950, loss is 5.094050350189209 and perplexity is 163.04893169238014
At time: 769.7088227272034 and batch: 1000, loss is 5.119232149124145 and perplexity is 167.20693032840134
At time: 770.7823357582092 and batch: 1050, loss is 5.077550840377808 and perplexity is 160.3807764012869
At time: 771.8556921482086 and batch: 1100, loss is 5.072853384017944 and perplexity is 159.62916142455725
At time: 772.9292151927948 and batch: 1150, loss is 5.093229236602784 and perplexity is 162.91510495031253
At time: 774.002809047699 and batch: 1200, loss is 5.054965839385987 and perplexity is 156.79917389662188
At time: 775.0757386684418 and batch: 1250, loss is 5.070534563064575 and perplexity is 159.2594388062188
At time: 776.148843050003 and batch: 1300, loss is 5.050124683380127 and perplexity is 156.04191910745166
At time: 777.2230036258698 and batch: 1350, loss is 5.037054834365844 and perplexity is 154.0157445254242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161131184895833 and perplexity of 174.36157927732296
Finished 25 epochs...
Completing Train Step...
At time: 780.4161024093628 and batch: 50, loss is 5.171414203643799 and perplexity is 176.1637928835582
At time: 781.5171387195587 and batch: 100, loss is 5.175726194381713 and perplexity is 176.92504961329158
At time: 782.5905480384827 and batch: 150, loss is 5.144307537078857 and perplexity is 171.45271890479253
At time: 783.6646029949188 and batch: 200, loss is 5.141701173782349 and perplexity is 171.00643267581594
At time: 784.7376682758331 and batch: 250, loss is 5.155800495147705 and perplexity is 173.43458474945666
At time: 785.8393087387085 and batch: 300, loss is 5.150602540969849 and perplexity is 172.53541866166077
At time: 786.9128746986389 and batch: 350, loss is 5.156785297393799 and perplexity is 173.60546764718825
At time: 787.9863197803497 and batch: 400, loss is 5.182276868820191 and perplexity is 178.08783236088703
At time: 789.0600917339325 and batch: 450, loss is 5.153049373626709 and perplexity is 172.95810086393243
At time: 790.1339485645294 and batch: 500, loss is 5.186305541992187 and perplexity is 178.80673717732097
At time: 791.2079870700836 and batch: 550, loss is 5.167433290481568 and perplexity is 175.46389416408508
At time: 792.2852895259857 and batch: 600, loss is 5.12906771659851 and perplexity is 168.85961961915788
At time: 793.3594505786896 and batch: 650, loss is 5.134065856933594 and perplexity is 169.7057163887491
At time: 794.4343235492706 and batch: 700, loss is 5.1417851161956785 and perplexity is 171.02078797097028
At time: 795.5081491470337 and batch: 750, loss is 5.112516050338745 and perplexity is 166.0877146551645
At time: 796.5822176933289 and batch: 800, loss is 5.111795263290405 and perplexity is 165.96804391529346
At time: 797.656331539154 and batch: 850, loss is 5.083540773391723 and perplexity is 161.3443294367538
At time: 798.7300972938538 and batch: 900, loss is 5.115377063751221 and perplexity is 166.563574230162
At time: 799.8040397167206 and batch: 950, loss is 5.093856840133667 and perplexity is 163.01738313713204
At time: 800.8768179416656 and batch: 1000, loss is 5.119076700210571 and perplexity is 167.18094021285964
At time: 801.9508910179138 and batch: 1050, loss is 5.077591218948364 and perplexity is 160.3872524785292
At time: 803.0292904376984 and batch: 1100, loss is 5.073010320663452 and perplexity is 159.65421505554153
At time: 804.1022734642029 and batch: 1150, loss is 5.093341817855835 and perplexity is 162.9334471694445
At time: 805.1758370399475 and batch: 1200, loss is 5.0552591037750245 and perplexity is 156.8451642538937
At time: 806.2547068595886 and batch: 1250, loss is 5.070765380859375 and perplexity is 159.29620296143256
At time: 807.3283762931824 and batch: 1300, loss is 5.050548753738403 and perplexity is 156.1081058929287
At time: 808.4026398658752 and batch: 1350, loss is 5.036870346069336 and perplexity is 153.98733304395478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1610546875 and perplexity of 174.34824158073096
Finished 26 epochs...
Completing Train Step...
At time: 811.6147880554199 and batch: 50, loss is 5.169762601852417 and perplexity is 175.87308058421573
At time: 812.7243950366974 and batch: 100, loss is 5.173966360092163 and perplexity is 176.61396465357754
At time: 813.8024849891663 and batch: 150, loss is 5.142417860031128 and perplexity is 171.12903456286298
At time: 814.8793606758118 and batch: 200, loss is 5.139826898574829 and perplexity is 170.68621973605218
At time: 815.9527068138123 and batch: 250, loss is 5.1541163349151615 and perplexity is 173.142738945405
At time: 817.0334928035736 and batch: 300, loss is 5.149057559967041 and perplexity is 172.2690605296263
At time: 818.1076056957245 and batch: 350, loss is 5.155391998291016 and perplexity is 173.3637517352621
At time: 819.1849873065948 and batch: 400, loss is 5.180845289230347 and perplexity is 177.83306785622216
At time: 820.258793592453 and batch: 450, loss is 5.1514868068695066 and perplexity is 172.68805332373412
At time: 821.3331537246704 and batch: 500, loss is 5.184884910583496 and perplexity is 178.5528990582948
At time: 822.4076220989227 and batch: 550, loss is 5.166195049285888 and perplexity is 175.2467620007146
At time: 823.4822347164154 and batch: 600, loss is 5.128131484985351 and perplexity is 168.7016018872247
At time: 824.5570809841156 and batch: 650, loss is 5.133016328811646 and perplexity is 169.52769890046451
At time: 825.6318466663361 and batch: 700, loss is 5.140977029800415 and perplexity is 170.88264422246291
At time: 826.706778049469 and batch: 750, loss is 5.111944551467896 and perplexity is 165.99282283164482
At time: 827.7812888622284 and batch: 800, loss is 5.111123580932617 and perplexity is 165.8566035386961
At time: 828.8565120697021 and batch: 850, loss is 5.083001699447632 and perplexity is 161.25737635190444
At time: 829.9311578273773 and batch: 900, loss is 5.11480375289917 and perplexity is 166.468108893771
At time: 831.0063784122467 and batch: 950, loss is 5.093571681976318 and perplexity is 162.9709040278043
At time: 832.0808773040771 and batch: 1000, loss is 5.118866748809815 and perplexity is 167.14584402465806
At time: 833.1557476520538 and batch: 1050, loss is 5.077476692199707 and perplexity is 160.36888489978642
At time: 834.2302312850952 and batch: 1100, loss is 5.073020620346069 and perplexity is 159.65585945175343
At time: 835.3045794963837 and batch: 1150, loss is 5.093283157348633 and perplexity is 162.92388969111937
At time: 836.3786056041718 and batch: 1200, loss is 5.055365695953369 and perplexity is 156.86188361267492
At time: 837.4542589187622 and batch: 1250, loss is 5.070794105529785 and perplexity is 159.30077875807905
At time: 838.5285999774933 and batch: 1300, loss is 5.050795869827271 and perplexity is 156.14668748436708
At time: 839.6035666465759 and batch: 1350, loss is 5.03661075592041 and perplexity is 153.947364637164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161063639322917 and perplexity of 174.34980232230114
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 842.8635075092316 and batch: 50, loss is 5.169580078125 and perplexity is 175.84098250341486
At time: 843.9403576850891 and batch: 100, loss is 5.1740639209747314 and perplexity is 176.63119610838731
At time: 845.0161435604095 and batch: 150, loss is 5.142574834823608 and perplexity is 171.15589961606372
At time: 846.0964984893799 and batch: 200, loss is 5.140955171585083 and perplexity is 170.87890907365102
At time: 847.1743805408478 and batch: 250, loss is 5.154179601669312 and perplexity is 173.15369347102776
At time: 848.2496953010559 and batch: 300, loss is 5.148944387435913 and perplexity is 172.24956550718247
At time: 849.3238432407379 and batch: 350, loss is 5.155129985809326 and perplexity is 173.31833421867285
At time: 850.3972263336182 and batch: 400, loss is 5.180121746063232 and perplexity is 177.7044444929769
At time: 851.4717581272125 and batch: 450, loss is 5.14983172416687 and perplexity is 172.4024767053767
At time: 852.5455174446106 and batch: 500, loss is 5.18228910446167 and perplexity is 178.09001139308657
At time: 853.6181683540344 and batch: 550, loss is 5.161907129287719 and perplexity is 174.49692667115832
At time: 854.694798707962 and batch: 600, loss is 5.123717012405396 and perplexity is 167.9585146673239
At time: 855.7691152095795 and batch: 650, loss is 5.129415235519409 and perplexity is 168.91831172967008
At time: 856.8427290916443 and batch: 700, loss is 5.135988111495972 and perplexity is 170.03224771395767
At time: 857.9167945384979 and batch: 750, loss is 5.107167177200317 and perplexity is 165.20170423073068
At time: 858.9900076389313 and batch: 800, loss is 5.106345844268799 and perplexity is 165.06607433697673
At time: 860.0649693012238 and batch: 850, loss is 5.076150617599487 and perplexity is 160.15636473479424
At time: 861.1386940479279 and batch: 900, loss is 5.105418395996094 and perplexity is 164.91305506115063
At time: 862.2134544849396 and batch: 950, loss is 5.083547096252442 and perplexity is 161.34534959770173
At time: 863.2874870300293 and batch: 1000, loss is 5.108983325958252 and perplexity is 165.50200771603562
At time: 864.3705599308014 and batch: 1050, loss is 5.066619997024536 and perplexity is 158.63722585690965
At time: 865.4439284801483 and batch: 1100, loss is 5.061583585739136 and perplexity is 157.84027212030523
At time: 866.5173976421356 and batch: 1150, loss is 5.081924552917481 and perplexity is 161.08377204393
At time: 867.6437077522278 and batch: 1200, loss is 5.042124805450439 and perplexity is 154.79858270332514
At time: 868.7168200016022 and batch: 1250, loss is 5.057455053329468 and perplexity is 157.18996676835894
At time: 869.7905964851379 and batch: 1300, loss is 5.039328575134277 and perplexity is 154.3663348274206
At time: 870.8640139102936 and batch: 1350, loss is 5.027512378692627 and perplexity is 152.55304607710488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157101236979167 and perplexity of 173.66032515202673
Finished 28 epochs...
Completing Train Step...
At time: 874.101514339447 and batch: 50, loss is 5.167331981658935 and perplexity is 175.44611902395732
At time: 875.1754384040833 and batch: 100, loss is 5.172063207626342 and perplexity is 176.27816099538518
At time: 876.2668528556824 and batch: 150, loss is 5.140503091812134 and perplexity is 170.8016756343884
At time: 877.3611857891083 and batch: 200, loss is 5.138919515609741 and perplexity is 170.53141221336458
At time: 878.453243970871 and batch: 250, loss is 5.152386951446533 and perplexity is 172.84356752058062
At time: 879.5314400196075 and batch: 300, loss is 5.147238731384277 and perplexity is 171.9560174105946
At time: 880.6052136421204 and batch: 350, loss is 5.153428430557251 and perplexity is 173.02367425799784
At time: 881.6793160438538 and batch: 400, loss is 5.178538599014282 and perplexity is 177.42333480379335
At time: 882.7533669471741 and batch: 450, loss is 5.148567008972168 and perplexity is 172.18457449464614
At time: 883.8270258903503 and batch: 500, loss is 5.1809698009490965 and perplexity is 177.85521153569664
At time: 884.9005522727966 and batch: 550, loss is 5.16093186378479 and perplexity is 174.3268287969854
At time: 885.9739375114441 and batch: 600, loss is 5.122887897491455 and perplexity is 167.81931547192846
At time: 887.0467903614044 and batch: 650, loss is 5.1286263751983645 and perplexity is 168.78511132121474
At time: 888.121125459671 and batch: 700, loss is 5.135255765914917 and perplexity is 169.9077709342807
At time: 889.20481133461 and batch: 750, loss is 5.106588125228882 and perplexity is 165.10607154903002
At time: 890.2795965671539 and batch: 800, loss is 5.105959901809692 and perplexity is 165.00238062217707
At time: 891.3543450832367 and batch: 850, loss is 5.075810995101929 and perplexity is 160.1019812656506
At time: 892.4422616958618 and batch: 900, loss is 5.105389986038208 and perplexity is 164.90836995475368
At time: 893.517810344696 and batch: 950, loss is 5.083407640457153 and perplexity is 161.3228506225002
At time: 894.6433384418488 and batch: 1000, loss is 5.109052324295044 and perplexity is 165.51342747327146
At time: 895.7205018997192 and batch: 1050, loss is 5.0668465042114255 and perplexity is 158.67316239846326
At time: 896.7971303462982 and batch: 1100, loss is 5.061978769302368 and perplexity is 157.90266032804848
At time: 897.8736984729767 and batch: 1150, loss is 5.082546520233154 and perplexity is 161.18399204877963
At time: 898.9507381916046 and batch: 1200, loss is 5.04308669090271 and perplexity is 154.94755284267865
At time: 900.0268337726593 and batch: 1250, loss is 5.058511791229248 and perplexity is 157.35616316125586
At time: 901.1033372879028 and batch: 1300, loss is 5.040224142074585 and perplexity is 154.50464213607114
At time: 902.1793191432953 and batch: 1350, loss is 5.027994155883789 and perplexity is 152.6265603624781
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156822916666667 and perplexity of 173.61199868149274
Finished 29 epochs...
Completing Train Step...
At time: 905.3965637683868 and batch: 50, loss is 5.166352834701538 and perplexity is 175.27441556550536
At time: 906.5346999168396 and batch: 100, loss is 5.171015138626099 and perplexity is 176.0935061018636
At time: 907.6085467338562 and batch: 150, loss is 5.139395742416382 and perplexity is 170.61264318388254
At time: 908.6820559501648 and batch: 200, loss is 5.13776894569397 and perplexity is 170.3353167331907
At time: 909.7709808349609 and batch: 250, loss is 5.151374769210816 and perplexity is 172.6687068423433
At time: 910.848482131958 and batch: 300, loss is 5.146220760345459 and perplexity is 171.78106023069967
At time: 911.9235293865204 and batch: 350, loss is 5.152474956512451 and perplexity is 172.8587792994808
At time: 912.9965724945068 and batch: 400, loss is 5.177629594802856 and perplexity is 177.26212952449055
At time: 914.0725305080414 and batch: 450, loss is 5.14782395362854 and perplexity is 172.05667934894797
At time: 915.1453559398651 and batch: 500, loss is 5.180147266387939 and perplexity is 177.708979625971
At time: 916.2172594070435 and batch: 550, loss is 5.160369081497192 and perplexity is 174.22874834704407
At time: 917.2907104492188 and batch: 600, loss is 5.1224178981781 and perplexity is 167.7404590415747
At time: 918.3637745380402 and batch: 650, loss is 5.128266086578369 and perplexity is 168.72431091988514
At time: 919.4374194145203 and batch: 700, loss is 5.134920883178711 and perplexity is 169.8508812812605
At time: 920.5117967128754 and batch: 750, loss is 5.106379203796386 and perplexity is 165.0715809550859
At time: 921.6614246368408 and batch: 800, loss is 5.105878429412842 and perplexity is 164.9889380303493
At time: 922.7435050010681 and batch: 850, loss is 5.075721597671508 and perplexity is 160.08766919966078
At time: 923.8249859809875 and batch: 900, loss is 5.105488958358765 and perplexity is 164.92469212651565
At time: 924.9046847820282 and batch: 950, loss is 5.08340817451477 and perplexity is 161.32293677822034
At time: 926.0064032077789 and batch: 1000, loss is 5.109191436767578 and perplexity is 165.5364540570101
At time: 927.0876915454865 and batch: 1050, loss is 5.067073698043823 and perplexity is 158.7092160577567
At time: 928.1609826087952 and batch: 1100, loss is 5.062355308532715 and perplexity is 157.9621280695043
At time: 929.2351624965668 and batch: 1150, loss is 5.083052129745483 and perplexity is 161.26550881448415
At time: 930.3092103004456 and batch: 1200, loss is 5.043795118331909 and perplexity is 155.05736083010234
At time: 931.3830432891846 and batch: 1250, loss is 5.059188070297242 and perplexity is 157.46261583242108
At time: 932.4565687179565 and batch: 1300, loss is 5.0408225440979 and perplexity is 154.5971256949516
At time: 933.5320253372192 and batch: 1350, loss is 5.028234643936157 and perplexity is 152.66326964061378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156670328776042 and perplexity of 173.5855096138336
Finished 30 epochs...
Completing Train Step...
At time: 936.7715268135071 and batch: 50, loss is 5.165595703125 and perplexity is 175.14175999611868
At time: 937.9037275314331 and batch: 100, loss is 5.170163240432739 and perplexity is 175.94355624222894
At time: 938.9770202636719 and batch: 150, loss is 5.138530378341675 and perplexity is 170.46506499542116
At time: 940.0518152713776 and batch: 200, loss is 5.13690001487732 and perplexity is 170.18737141374973
At time: 941.1398115158081 and batch: 250, loss is 5.150602130889893 and perplexity is 172.53534790835843
At time: 942.2211265563965 and batch: 300, loss is 5.145449285507202 and perplexity is 171.6485865716603
At time: 943.2970712184906 and batch: 350, loss is 5.151779441833496 and perplexity is 172.73859528081118
At time: 944.375569820404 and batch: 400, loss is 5.177005462646484 and perplexity is 177.15152904759464
At time: 945.4494400024414 and batch: 450, loss is 5.147269077301026 and perplexity is 171.9612356527591
At time: 946.5267572402954 and batch: 500, loss is 5.179548511505127 and perplexity is 177.60260735533652
At time: 947.6017420291901 and batch: 550, loss is 5.1599749565124515 and perplexity is 174.1600939743509
At time: 948.6788697242737 and batch: 600, loss is 5.122075328826904 and perplexity is 167.68300614271448
At time: 949.8038070201874 and batch: 650, loss is 5.128006429672241 and perplexity is 168.68050617467145
At time: 950.8807027339935 and batch: 700, loss is 5.134693546295166 and perplexity is 169.8122723000317
At time: 951.9567315578461 and batch: 750, loss is 5.106238307952881 and perplexity is 165.04832469384223
At time: 953.0327656269073 and batch: 800, loss is 5.105858106613159 and perplexity is 164.9855850272831
At time: 954.1091561317444 and batch: 850, loss is 5.075741634368897 and perplexity is 160.0908768599795
At time: 955.1904263496399 and batch: 900, loss is 5.105593929290771 and perplexity is 164.94200533383486
At time: 956.2836937904358 and batch: 950, loss is 5.083410053253174 and perplexity is 161.32323986210181
At time: 957.3810362815857 and batch: 1000, loss is 5.109290733337402 and perplexity is 165.55289207518476
At time: 958.4620764255524 and batch: 1050, loss is 5.06723349571228 and perplexity is 158.73457944689656
At time: 959.5470237731934 and batch: 1100, loss is 5.062650442123413 and perplexity is 158.00875487978627
At time: 960.6320176124573 and batch: 1150, loss is 5.083422870635986 and perplexity is 161.32530761707517
At time: 961.7168073654175 and batch: 1200, loss is 5.044323444366455 and perplexity is 155.1393033149449
At time: 962.7878978252411 and batch: 1250, loss is 5.0596621704101565 and perplexity is 157.53728657567237
At time: 963.8585138320923 and batch: 1300, loss is 5.041244869232178 and perplexity is 154.66242973561782
At time: 964.9291656017303 and batch: 1350, loss is 5.028353271484375 and perplexity is 152.68138078421316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156575520833333 and perplexity of 173.56905310889906
Finished 31 epochs...
Completing Train Step...
At time: 968.1283278465271 and batch: 50, loss is 5.164931335449219 and perplexity is 175.02544011596058
At time: 969.1978769302368 and batch: 100, loss is 5.169412851333618 and perplexity is 175.81157963865934
At time: 970.270349740982 and batch: 150, loss is 5.137797012329101 and perplexity is 170.34009753946572
At time: 971.3400866985321 and batch: 200, loss is 5.136172695159912 and perplexity is 170.06363578600224
At time: 972.4247345924377 and batch: 250, loss is 5.149949932098389 and perplexity is 172.42285725008404
At time: 973.5150711536407 and batch: 300, loss is 5.144802627563476 and perplexity is 171.53762453073375
At time: 974.5854713916779 and batch: 350, loss is 5.151193628311157 and perplexity is 172.63743231007697
At time: 975.6560008525848 and batch: 400, loss is 5.176488847732544 and perplexity is 177.06003356166255
At time: 976.771623134613 and batch: 450, loss is 5.146795072555542 and perplexity is 171.87974452613662
At time: 977.8428385257721 and batch: 500, loss is 5.17905026435852 and perplexity is 177.5141394042741
At time: 978.9309346675873 and batch: 550, loss is 5.159641323089599 and perplexity is 174.1019980379859
At time: 980.0116348266602 and batch: 600, loss is 5.121797065734864 and perplexity is 167.63635264221725
At time: 981.0822327136993 and batch: 650, loss is 5.127781944274902 and perplexity is 168.6426441141184
At time: 982.1523463726044 and batch: 700, loss is 5.134509840011597 and perplexity is 169.78107958381972
At time: 983.222163438797 and batch: 750, loss is 5.106124172210693 and perplexity is 165.0294878558051
At time: 984.2916724681854 and batch: 800, loss is 5.10586109161377 and perplexity is 164.98607751009027
At time: 985.3616065979004 and batch: 850, loss is 5.075769233703613 and perplexity is 160.095295322648
At time: 986.4312105178833 and batch: 900, loss is 5.105674839019775 and perplexity is 164.9553512866892
At time: 987.5011937618256 and batch: 950, loss is 5.083412818908691 and perplexity is 161.32368602722713
At time: 988.5710778236389 and batch: 1000, loss is 5.109359817504883 and perplexity is 165.56432955397761
At time: 989.6414408683777 and batch: 1050, loss is 5.067359399795532 and perplexity is 158.75456603677253
At time: 990.7146949768066 and batch: 1100, loss is 5.062869710922241 and perplexity is 158.04340506838685
At time: 991.7988703250885 and batch: 1150, loss is 5.083733587265015 and perplexity is 161.37544186120329
At time: 992.8726592063904 and batch: 1200, loss is 5.044746770858764 and perplexity is 155.20499179489244
At time: 993.9431550502777 and batch: 1250, loss is 5.060036106109619 and perplexity is 157.596206406547
At time: 995.0195446014404 and batch: 1300, loss is 5.0415695285797115 and perplexity is 154.71265049102152
At time: 996.096818447113 and batch: 1350, loss is 5.0284194660186765 and perplexity is 152.69148779162137
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156513671875 and perplexity of 173.55831837573493
Finished 32 epochs...
Completing Train Step...
At time: 999.3366587162018 and batch: 50, loss is 5.164334239959717 and perplexity is 174.92096440920992
At time: 1000.4079535007477 and batch: 100, loss is 5.168735189437866 and perplexity is 175.69247918978206
At time: 1001.4796905517578 and batch: 150, loss is 5.137170772552491 and perplexity is 170.2334571895344
At time: 1002.5514733791351 and batch: 200, loss is 5.135545902252197 and perplexity is 169.95707450464778
At time: 1003.6659514904022 and batch: 250, loss is 5.1493826007843015 and perplexity is 172.3250641070808
At time: 1004.7390191555023 and batch: 300, loss is 5.14425030708313 and perplexity is 171.442906947194
At time: 1005.8119094371796 and batch: 350, loss is 5.150709991455078 and perplexity is 172.55395867216396
At time: 1006.8871638774872 and batch: 400, loss is 5.176045379638672 and perplexity is 176.9815304941675
At time: 1007.9597365856171 and batch: 450, loss is 5.146383113861084 and perplexity is 171.8089517538281
At time: 1009.0334670543671 and batch: 500, loss is 5.178614654541016 and perplexity is 177.43682934213726
At time: 1010.1080079078674 and batch: 550, loss is 5.15934232711792 and perplexity is 174.04995002337233
At time: 1011.2019288539886 and batch: 600, loss is 5.121566257476807 and perplexity is 167.59766525253312
At time: 1012.2754852771759 and batch: 650, loss is 5.127605028152466 and perplexity is 168.61281115048828
At time: 1013.3547260761261 and batch: 700, loss is 5.134361877441406 and perplexity is 169.75596019732507
At time: 1014.4274008274078 and batch: 750, loss is 5.106035699844361 and perplexity is 165.01488795235338
At time: 1015.5015323162079 and batch: 800, loss is 5.105882568359375 and perplexity is 164.98962091215554
At time: 1016.5743787288666 and batch: 850, loss is 5.075794658660889 and perplexity is 160.09936579043713
At time: 1017.6474890708923 and batch: 900, loss is 5.105734996795654 and perplexity is 164.96527493223118
At time: 1018.7200071811676 and batch: 950, loss is 5.083394451141357 and perplexity is 161.32072289850987
At time: 1019.7927496433258 and batch: 1000, loss is 5.109406747817993 and perplexity is 165.57209972213028
At time: 1020.8650975227356 and batch: 1050, loss is 5.067452392578125 and perplexity is 158.7693297520664
At time: 1021.9410884380341 and batch: 1100, loss is 5.063041524887085 and perplexity is 158.0705614652864
At time: 1023.0148460865021 and batch: 1150, loss is 5.083976745605469 and perplexity is 161.41468641696343
At time: 1024.0891127586365 and batch: 1200, loss is 5.045094585418701 and perplexity is 155.25898373986152
At time: 1025.161512374878 and batch: 1250, loss is 5.060321025848388 and perplexity is 157.64111507388648
At time: 1026.2341058254242 and batch: 1300, loss is 5.0418175601959225 and perplexity is 154.75102887910114
At time: 1027.30690407753 and batch: 1350, loss is 5.028412818908691 and perplexity is 152.6904728378815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1564644368489585 and perplexity of 173.54977343776676
Finished 33 epochs...
Completing Train Step...
At time: 1030.5031218528748 and batch: 50, loss is 5.163772411346436 and perplexity is 174.82271640819548
At time: 1031.601851940155 and batch: 100, loss is 5.16809461593628 and perplexity is 175.5799712818245
At time: 1032.6764044761658 and batch: 150, loss is 5.136607694625854 and perplexity is 170.1376294691849
At time: 1033.7491352558136 and batch: 200, loss is 5.134980602264404 and perplexity is 169.86102492347635
At time: 1034.8269391059875 and batch: 250, loss is 5.148868055343628 and perplexity is 172.23641783925297
At time: 1035.9045240879059 and batch: 300, loss is 5.1437485408782955 and perplexity is 171.35690426885245
At time: 1036.978264093399 and batch: 350, loss is 5.150270576477051 and perplexity is 172.4781525346014
At time: 1038.0516624450684 and batch: 400, loss is 5.175646963119507 and perplexity is 176.91103217361186
At time: 1039.1246480941772 and batch: 450, loss is 5.146008567810059 and perplexity is 171.7446134390009
At time: 1040.1975083351135 and batch: 500, loss is 5.178206462860107 and perplexity is 177.3644158848039
At time: 1041.2770154476166 and batch: 550, loss is 5.159063720703125 and perplexity is 174.00146534518595
At time: 1042.3508050441742 and batch: 600, loss is 5.121352415084839 and perplexity is 167.56182959863492
At time: 1043.42378282547 and batch: 650, loss is 5.127435102462768 and perplexity is 168.5841619364493
At time: 1044.4971642494202 and batch: 700, loss is 5.134216947555542 and perplexity is 169.7313592681369
At time: 1045.5698926448822 and batch: 750, loss is 5.105945491790772 and perplexity is 165.00000295188158
At time: 1046.6428549289703 and batch: 800, loss is 5.105880270004272 and perplexity is 164.9892417078542
At time: 1047.716138601303 and batch: 850, loss is 5.075835580825806 and perplexity is 160.10591753714203
At time: 1048.788852930069 and batch: 900, loss is 5.105756769180298 and perplexity is 164.96886665874993
At time: 1049.8636741638184 and batch: 950, loss is 5.083370628356934 and perplexity is 161.31687983548164
At time: 1050.937701702118 and batch: 1000, loss is 5.109425687789917 and perplexity is 165.57523568274783
At time: 1052.0118253231049 and batch: 1050, loss is 5.0675148677825925 and perplexity is 158.77924920826263
At time: 1053.0844614505768 and batch: 1100, loss is 5.0631665515899655 and perplexity is 158.09032574191428
At time: 1054.1578693389893 and batch: 1150, loss is 5.08416428565979 and perplexity is 161.44496097477975
At time: 1055.229813337326 and batch: 1200, loss is 5.045384359359741 and perplexity is 155.30398026655735
At time: 1056.3045382499695 and batch: 1250, loss is 5.060553035736084 and perplexity is 157.67769361441842
At time: 1057.3844680786133 and batch: 1300, loss is 5.042017154693603 and perplexity is 154.78191941566385
At time: 1058.4571886062622 and batch: 1350, loss is 5.028378953933716 and perplexity is 152.68530206639437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156431477864583 and perplexity of 173.54405350775772
Finished 34 epochs...
Completing Train Step...
At time: 1061.6535186767578 and batch: 50, loss is 5.163212852478027 and perplexity is 174.72492017075774
At time: 1062.752726316452 and batch: 100, loss is 5.167515611648559 and perplexity is 175.4783391511735
At time: 1063.8258080482483 and batch: 150, loss is 5.136087770462036 and perplexity is 170.04919379636294
At time: 1064.899361371994 and batch: 200, loss is 5.1344601440429685 and perplexity is 169.77264235826485
At time: 1065.9735615253448 and batch: 250, loss is 5.148385171890259 and perplexity is 172.1532678005155
At time: 1067.0474948883057 and batch: 300, loss is 5.143288478851319 and perplexity is 171.27808759580742
At time: 1068.1206464767456 and batch: 350, loss is 5.149860410690308 and perplexity is 172.40742240400252
At time: 1069.1984539031982 and batch: 400, loss is 5.175284976959229 and perplexity is 176.84700441764434
At time: 1070.273621559143 and batch: 450, loss is 5.145662050247193 and perplexity is 171.68511122399332
At time: 1071.3511686325073 and batch: 500, loss is 5.177846813201905 and perplexity is 177.30063830273392
At time: 1072.4260067939758 and batch: 550, loss is 5.158807182312012 and perplexity is 173.9568330144129
At time: 1073.4986877441406 and batch: 600, loss is 5.1211568641662595 and perplexity is 167.5290659325249
At time: 1074.5701467990875 and batch: 650, loss is 5.127283716201783 and perplexity is 168.55864254220393
At time: 1075.640822172165 and batch: 700, loss is 5.134101905822754 and perplexity is 169.71183420157854
At time: 1076.719521522522 and batch: 750, loss is 5.105864458084106 and perplexity is 164.986632931761
At time: 1077.7945365905762 and batch: 800, loss is 5.105896368026733 and perplexity is 164.99189772975132
At time: 1078.8697860240936 and batch: 850, loss is 5.075861759185791 and perplexity is 160.11010890234843
At time: 1079.9452316761017 and batch: 900, loss is 5.105780916213989 and perplexity is 164.97285021562655
At time: 1081.0242874622345 and batch: 950, loss is 5.083356533050537 and perplexity is 161.31460604065836
At time: 1082.0949954986572 and batch: 1000, loss is 5.109434127807617 and perplexity is 165.57663314656494
At time: 1083.1661972999573 and batch: 1050, loss is 5.067542190551758 and perplexity is 158.78358755630458
At time: 1084.238787651062 and batch: 1100, loss is 5.063265733718872 and perplexity is 158.10600625458133
At time: 1085.3598170280457 and batch: 1150, loss is 5.084325218200684 and perplexity is 161.4709448133304
At time: 1086.4341259002686 and batch: 1200, loss is 5.045633211135864 and perplexity is 155.34263274705532
At time: 1087.5066695213318 and batch: 1250, loss is 5.060728874206543 and perplexity is 157.7054218566635
At time: 1088.5861558914185 and batch: 1300, loss is 5.042180948257446 and perplexity is 154.80727377424708
At time: 1089.6595795154572 and batch: 1350, loss is 5.028328647613526 and perplexity is 152.67762122389934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15641357421875 and perplexity of 173.540946464301
Finished 35 epochs...
Completing Train Step...
At time: 1092.9022204875946 and batch: 50, loss is 5.162687702178955 and perplexity is 174.63318741552476
At time: 1093.9749903678894 and batch: 100, loss is 5.166969785690307 and perplexity is 175.3825846535764
At time: 1095.047529220581 and batch: 150, loss is 5.135599145889282 and perplexity is 169.96612387835137
At time: 1096.1209859848022 and batch: 200, loss is 5.133990707397461 and perplexity is 169.69296356207394
At time: 1097.1953523159027 and batch: 250, loss is 5.147943105697632 and perplexity is 172.07718147970476
At time: 1098.2690560817719 and batch: 300, loss is 5.14285984992981 and perplexity is 171.20468858543617
At time: 1099.3420660495758 and batch: 350, loss is 5.149492244720459 and perplexity is 172.34395954127413
At time: 1100.4158771038055 and batch: 400, loss is 5.174935455322266 and perplexity is 176.78520336420016
At time: 1101.489666223526 and batch: 450, loss is 5.1453378391265865 and perplexity is 171.62945802387264
At time: 1102.5621495246887 and batch: 500, loss is 5.177516622543335 and perplexity is 177.24210495232248
At time: 1103.6345171928406 and batch: 550, loss is 5.158566703796387 and perplexity is 173.9150051629781
At time: 1104.7071726322174 and batch: 600, loss is 5.120977230072022 and perplexity is 167.49897470329387
At time: 1105.7917652130127 and batch: 650, loss is 5.127149486541748 and perplexity is 168.53601849136294
At time: 1106.8644993305206 and batch: 700, loss is 5.133991632461548 and perplexity is 169.6931205390129
At time: 1107.9384191036224 and batch: 750, loss is 5.105784111022949 and perplexity is 164.97337727320846
At time: 1109.0135717391968 and batch: 800, loss is 5.105908546447754 and perplexity is 164.99390708278227
At time: 1110.090059041977 and batch: 850, loss is 5.0758702754974365 and perplexity is 160.11147245573963
At time: 1111.1613309383392 and batch: 900, loss is 5.105788888931275 and perplexity is 164.9741655027643
At time: 1112.2895052433014 and batch: 950, loss is 5.083324899673462 and perplexity is 161.30950319560827
At time: 1113.364578962326 and batch: 1000, loss is 5.109411563873291 and perplexity is 165.57289712843846
At time: 1114.4365355968475 and batch: 1050, loss is 5.067547855377197 and perplexity is 158.78448704015835
At time: 1115.510015964508 and batch: 1100, loss is 5.063333435058594 and perplexity is 158.11671060536818
At time: 1116.5909569263458 and batch: 1150, loss is 5.084451580047608 and perplexity is 161.49134986932467
At time: 1117.6636369228363 and batch: 1200, loss is 5.045840692520142 and perplexity is 155.37486679540189
At time: 1118.7362034320831 and batch: 1250, loss is 5.060867033004761 and perplexity is 157.72721175341795
At time: 1119.8195753097534 and batch: 1300, loss is 5.042304973602295 and perplexity is 154.82647499045623
At time: 1120.892916917801 and batch: 1350, loss is 5.028244867324829 and perplexity is 152.66483038453325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15639892578125 and perplexity of 173.53840437921195
Finished 36 epochs...
Completing Train Step...
At time: 1124.1337769031525 and batch: 50, loss is 5.16217755317688 and perplexity is 174.54412118969034
At time: 1125.2109122276306 and batch: 100, loss is 5.166441497802734 and perplexity is 175.28995662769893
At time: 1126.2849638462067 and batch: 150, loss is 5.135131797790527 and perplexity is 169.88670909212425
At time: 1127.3587601184845 and batch: 200, loss is 5.133528518676758 and perplexity is 169.61455151031157
At time: 1128.4325683116913 and batch: 250, loss is 5.147498188018798 and perplexity is 172.0006383285039
At time: 1129.5069200992584 and batch: 300, loss is 5.142454872131347 and perplexity is 171.13536852505658
At time: 1130.5820944309235 and batch: 350, loss is 5.149160223007202 and perplexity is 172.28674710296917
At time: 1131.6654026508331 and batch: 400, loss is 5.174594879150391 and perplexity is 176.72500478807638
At time: 1132.7370133399963 and batch: 450, loss is 5.144995365142822 and perplexity is 171.57068946357782
At time: 1133.808441877365 and batch: 500, loss is 5.177164134979248 and perplexity is 177.1796403241432
At time: 1134.8869807720184 and batch: 550, loss is 5.158323707580567 and perplexity is 173.87274960902695
At time: 1135.963706254959 and batch: 600, loss is 5.120784549713135 and perplexity is 167.46670404979528
At time: 1137.0379247665405 and batch: 650, loss is 5.126986799240112 and perplexity is 168.50860205149982
At time: 1138.1089189052582 and batch: 700, loss is 5.133855514526367 and perplexity is 169.67002383380427
At time: 1139.1799521446228 and batch: 750, loss is 5.105742559432984 and perplexity is 164.96652250949495
At time: 1140.297179222107 and batch: 800, loss is 5.105899391174316 and perplexity is 164.9923965253621
At time: 1141.368152141571 and batch: 850, loss is 5.0758647441864015 and perplexity is 160.11058683183452
At time: 1142.4389605522156 and batch: 900, loss is 5.105763387680054 and perplexity is 164.9699585087669
At time: 1143.5117416381836 and batch: 950, loss is 5.083277711868286 and perplexity is 161.30189153378865
At time: 1144.593911409378 and batch: 1000, loss is 5.10935188293457 and perplexity is 165.56301587737522
At time: 1145.6672224998474 and batch: 1050, loss is 5.06753607749939 and perplexity is 158.78261690688544
At time: 1146.7408516407013 and batch: 1100, loss is 5.063372774124145 and perplexity is 158.12293089136082
At time: 1147.8151383399963 and batch: 1150, loss is 5.084538402557373 and perplexity is 161.50537156231624
At time: 1148.8871538639069 and batch: 1200, loss is 5.046026620864868 and perplexity is 155.40375807296775
At time: 1149.9579997062683 and batch: 1250, loss is 5.0609641456604 and perplexity is 157.7425298055943
At time: 1151.032496213913 and batch: 1300, loss is 5.042407875061035 and perplexity is 154.84240768031873
At time: 1152.1074759960175 and batch: 1350, loss is 5.028166370391846 and perplexity is 152.65284713390403
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156390380859375 and perplexity of 173.53692151343972
Finished 37 epochs...
Completing Train Step...
At time: 1155.2482464313507 and batch: 50, loss is 5.161696157455444 and perplexity is 174.46011661789083
At time: 1156.3454294204712 and batch: 100, loss is 5.165936803817749 and perplexity is 175.20151116178528
At time: 1157.4156894683838 and batch: 150, loss is 5.134702568054199 and perplexity is 169.813804312344
At time: 1158.487226486206 and batch: 200, loss is 5.1331103515625 and perplexity is 169.5436391104206
At time: 1159.5581092834473 and batch: 250, loss is 5.147091827392578 and perplexity is 171.93075824062217
At time: 1160.6309916973114 and batch: 300, loss is 5.142080593109131 and perplexity is 171.07132813189378
At time: 1161.7021658420563 and batch: 350, loss is 5.148831453323364 and perplexity is 172.23011375376893
At time: 1162.7740125656128 and batch: 400, loss is 5.174288654327393 and perplexity is 176.67089548999385
At time: 1163.847032546997 and batch: 450, loss is 5.144695739746094 and perplexity is 171.51929022832303
At time: 1164.9206218719482 and batch: 500, loss is 5.176836223602295 and perplexity is 177.12155062897295
At time: 1165.9940078258514 and batch: 550, loss is 5.158086605072022 and perplexity is 173.83152883089508
At time: 1167.1134991645813 and batch: 600, loss is 5.120617799758911 and perplexity is 167.43878131268318
At time: 1168.1860942840576 and batch: 650, loss is 5.126858940124512 and perplexity is 168.4870580679972
At time: 1169.258269071579 and batch: 700, loss is 5.133720197677612 and perplexity is 169.64706617416508
At time: 1170.331125497818 and batch: 750, loss is 5.105665969848633 and perplexity is 164.95388827593564
At time: 1171.4039764404297 and batch: 800, loss is 5.105906019210815 and perplexity is 164.9934901046125
At time: 1172.4768147468567 and batch: 850, loss is 5.075879211425781 and perplexity is 160.1129032067772
At time: 1173.5494828224182 and batch: 900, loss is 5.105768013000488 and perplexity is 164.97072154945167
At time: 1174.6218218803406 and batch: 950, loss is 5.083230924606323 and perplexity is 161.29434483648043
At time: 1175.7026770114899 and batch: 1000, loss is 5.109302949905396 and perplexity is 165.5549145757013
At time: 1176.7812278270721 and batch: 1050, loss is 5.0675507831573485 and perplexity is 158.78495192690846
At time: 1177.8549711704254 and batch: 1100, loss is 5.0634052944183345 and perplexity is 158.12807317920536
At time: 1178.9271593093872 and batch: 1150, loss is 5.084629001617432 and perplexity is 161.5200044600276
At time: 1180.0008628368378 and batch: 1200, loss is 5.046182870864868 and perplexity is 155.42804180728396
At time: 1181.077888250351 and batch: 1250, loss is 5.061077318191528 and perplexity is 157.7603829371819
At time: 1182.1518442630768 and batch: 1300, loss is 5.042507629394532 and perplexity is 154.85785465193226
At time: 1183.2252655029297 and batch: 1350, loss is 5.0280842781066895 and perplexity is 152.64031602720783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156371663411458 and perplexity of 173.53367337554815
Finished 38 epochs...
Completing Train Step...
At time: 1186.3928089141846 and batch: 50, loss is 5.161256589889526 and perplexity is 174.38344646117096
At time: 1187.492346048355 and batch: 100, loss is 5.165462455749512 and perplexity is 175.11842437100077
At time: 1188.565165758133 and batch: 150, loss is 5.13429783821106 and perplexity is 169.74508950436646
At time: 1189.639441728592 and batch: 200, loss is 5.132708902359009 and perplexity is 169.47558961166513
At time: 1190.7110278606415 and batch: 250, loss is 5.146716117858887 and perplexity is 171.86617434876803
At time: 1191.7855112552643 and batch: 300, loss is 5.1417257022857665 and perplexity is 171.0106272591275
At time: 1192.8583974838257 and batch: 350, loss is 5.1485191917419435 and perplexity is 172.17634130205226
At time: 1193.930834531784 and batch: 400, loss is 5.174001436233521 and perplexity is 176.62015969861596
At time: 1195.0505492687225 and batch: 450, loss is 5.144428625106811 and perplexity is 171.47348103340926
At time: 1196.1233303546906 and batch: 500, loss is 5.176530475616455 and perplexity is 177.06740434959912
At time: 1197.1968657970428 and batch: 550, loss is 5.157872457504272 and perplexity is 173.79430721739897
At time: 1198.270043373108 and batch: 600, loss is 5.120460329055786 and perplexity is 167.41241668594208
At time: 1199.3426172733307 and batch: 650, loss is 5.12673921585083 and perplexity is 168.46688728483554
At time: 1200.4151663780212 and batch: 700, loss is 5.133612689971923 and perplexity is 169.6288287876512
At time: 1201.488895893097 and batch: 750, loss is 5.105587482452393 and perplexity is 164.94094198281226
At time: 1202.5613567829132 and batch: 800, loss is 5.105898990631103 and perplexity is 164.99233043879076
At time: 1203.633777141571 and batch: 850, loss is 5.075881366729736 and perplexity is 160.1132482991226
At time: 1204.7060096263885 and batch: 900, loss is 5.105765333175659 and perplexity is 164.97027945740842
At time: 1205.7794606685638 and batch: 950, loss is 5.083178815841674 and perplexity is 161.28594020640548
At time: 1206.8512208461761 and batch: 1000, loss is 5.109249534606934 and perplexity is 165.5460716467034
At time: 1207.9234051704407 and batch: 1050, loss is 5.067542018890381 and perplexity is 158.78356029929768
At time: 1208.9956903457642 and batch: 1100, loss is 5.063427534103393 and perplexity is 158.1315899368575
At time: 1210.0684852600098 and batch: 1150, loss is 5.084707612991333 and perplexity is 161.53270226858024
At time: 1211.1416082382202 and batch: 1200, loss is 5.046327648162841 and perplexity is 155.4505458882068
At time: 1212.2140531539917 and batch: 1250, loss is 5.061179084777832 and perplexity is 157.7764384897529
At time: 1213.286311864853 and batch: 1300, loss is 5.042596397399902 and perplexity is 154.87160168494495
At time: 1214.3596410751343 and batch: 1350, loss is 5.028008222579956 and perplexity is 152.62870732903005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156358642578125 and perplexity of 173.53141383722
Finished 39 epochs...
Completing Train Step...
At time: 1217.5513188838959 and batch: 50, loss is 5.160834636688232 and perplexity is 174.30988032950785
At time: 1218.624137878418 and batch: 100, loss is 5.165016374588013 and perplexity is 175.0403247615348
At time: 1219.6973514556885 and batch: 150, loss is 5.133911962509155 and perplexity is 169.6796016347106
At time: 1220.7700250148773 and batch: 200, loss is 5.132325658798218 and perplexity is 169.4106516275621
At time: 1221.8693459033966 and batch: 250, loss is 5.146358022689819 and perplexity is 171.80464092007693
At time: 1222.9426963329315 and batch: 300, loss is 5.141388483047486 and perplexity is 170.95296890796425
At time: 1224.0154643058777 and batch: 350, loss is 5.14822832107544 and perplexity is 172.12626753774916
At time: 1225.0893204212189 and batch: 400, loss is 5.173729429244995 and perplexity is 176.57212431413967
At time: 1226.1622354984283 and batch: 450, loss is 5.144175500869751 and perplexity is 171.43008243219722
At time: 1227.2351109981537 and batch: 500, loss is 5.176219053268433 and perplexity is 177.01227018822894
At time: 1228.3093283176422 and batch: 550, loss is 5.157667369842529 and perplexity is 173.75866780403442
At time: 1229.3828003406525 and batch: 600, loss is 5.120311574935913 and perplexity is 167.38751525138363
At time: 1230.4619693756104 and batch: 650, loss is 5.12662368774414 and perplexity is 168.44742574850642
At time: 1231.5353429317474 and batch: 700, loss is 5.133506259918213 and perplexity is 169.61077614298148
At time: 1232.6084299087524 and batch: 750, loss is 5.1055066204071045 and perplexity is 164.92760506012448
At time: 1233.6814181804657 and batch: 800, loss is 5.105885801315307 and perplexity is 164.9901543171915
At time: 1234.754587173462 and batch: 850, loss is 5.075870952606201 and perplexity is 160.11158086865763
At time: 1235.8284888267517 and batch: 900, loss is 5.105750360488892 and perplexity is 164.96780942757965
At time: 1236.909203529358 and batch: 950, loss is 5.083117742538452 and perplexity is 161.27609024206168
At time: 1237.9810416698456 and batch: 1000, loss is 5.109189481735229 and perplexity is 165.53613042820393
At time: 1239.0533068180084 and batch: 1050, loss is 5.067524013519287 and perplexity is 158.7807013681089
At time: 1240.1255941390991 and batch: 1100, loss is 5.063435850143432 and perplexity is 158.13290497095875
At time: 1241.1984527111053 and batch: 1150, loss is 5.0847717380523685 and perplexity is 161.54306089509265
At time: 1242.2715260982513 and batch: 1200, loss is 5.046459922790527 and perplexity is 155.47110941127391
At time: 1243.3499693870544 and batch: 1250, loss is 5.061269826889038 and perplexity is 157.79075610647567
At time: 1244.4232022762299 and batch: 1300, loss is 5.042670736312866 and perplexity is 154.88311509940527
At time: 1245.4958233833313 and batch: 1350, loss is 5.027939157485962 and perplexity is 152.6181663770223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156349690755208 and perplexity of 173.52986042168578
Finished 40 epochs...
Completing Train Step...
At time: 1248.711965560913 and batch: 50, loss is 5.1604075050354 and perplexity is 174.2354429606277
At time: 1249.78497672081 and batch: 100, loss is 5.1645856285095215 and perplexity is 174.9649430644167
At time: 1250.858090877533 and batch: 150, loss is 5.13353928565979 and perplexity is 169.61637775714127
At time: 1251.930834054947 and batch: 200, loss is 5.131956291198731 and perplexity is 169.34808837697307
At time: 1253.0030150413513 and batch: 250, loss is 5.146011657714844 and perplexity is 171.74514411432367
At time: 1254.0778288841248 and batch: 300, loss is 5.14106517791748 and perplexity is 170.89770786969657
At time: 1255.1611318588257 and batch: 350, loss is 5.147958745956421 and perplexity is 172.07987283240155
At time: 1256.2354366779327 and batch: 400, loss is 5.173468704223633 and perplexity is 176.52609354420343
At time: 1257.3085327148438 and batch: 450, loss is 5.1439272403717045 and perplexity is 171.38752839701402
At time: 1258.3814165592194 and batch: 500, loss is 5.175910816192627 and perplexity is 176.9577168517968
At time: 1259.4536781311035 and batch: 550, loss is 5.157471475601196 and perplexity is 173.72463281536787
At time: 1260.5260593891144 and batch: 600, loss is 5.120166311264038 and perplexity is 167.36320169227332
At time: 1261.5977334976196 and batch: 650, loss is 5.126507368087768 and perplexity is 168.42783314135139
At time: 1262.6710293293 and batch: 700, loss is 5.133401098251343 and perplexity is 169.5929405288711
At time: 1263.7440114021301 and batch: 750, loss is 5.105423393249512 and perplexity is 164.9138791755379
At time: 1264.81711602211 and batch: 800, loss is 5.105870790481568 and perplexity is 164.98767769600448
At time: 1265.8898239135742 and batch: 850, loss is 5.07584436416626 and perplexity is 160.10732380810035
At time: 1266.9645202159882 and batch: 900, loss is 5.105725469589234 and perplexity is 164.96370328149146
At time: 1268.037466287613 and batch: 950, loss is 5.083046932220459 and perplexity is 161.2646706351447
At time: 1269.1175825595856 and batch: 1000, loss is 5.1091275310516355 and perplexity is 165.5258756694124
At time: 1270.1907329559326 and batch: 1050, loss is 5.06748685836792 and perplexity is 158.77480195671285
At time: 1271.2639439105988 and batch: 1100, loss is 5.063427600860596 and perplexity is 158.13160049328042
At time: 1272.3361158370972 and batch: 1150, loss is 5.084806966781616 and perplexity is 161.54875195209053
At time: 1273.4207344055176 and batch: 1200, loss is 5.046578893661499 and perplexity is 155.48960704488948
At time: 1274.4985301494598 and batch: 1250, loss is 5.061340484619141 and perplexity is 157.8019056370289
At time: 1275.574172258377 and batch: 1300, loss is 5.042697887420655 and perplexity is 154.88732040464708
At time: 1276.6490852832794 and batch: 1350, loss is 5.027850513458252 and perplexity is 152.60463828765393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156339111328125 and perplexity of 173.52802458489182
Finished 41 epochs...
Completing Train Step...
At time: 1279.8150553703308 and batch: 50, loss is 5.160012044906616 and perplexity is 174.16655341234832
At time: 1280.9147248268127 and batch: 100, loss is 5.164141445159912 and perplexity is 174.88724380757776
At time: 1281.9875593185425 and batch: 150, loss is 5.133160352706909 and perplexity is 169.55211669834614
At time: 1283.061086177826 and batch: 200, loss is 5.131596488952637 and perplexity is 169.28716751479203
At time: 1284.133422613144 and batch: 250, loss is 5.145676250457764 and perplexity is 171.68754920603448
At time: 1285.208019733429 and batch: 300, loss is 5.140768117904663 and perplexity is 170.84694853406415
At time: 1286.2903130054474 and batch: 350, loss is 5.147706565856933 and perplexity is 172.03648318418365
At time: 1287.3632881641388 and batch: 400, loss is 5.173204336166382 and perplexity is 176.47943185200128
At time: 1288.4367368221283 and batch: 450, loss is 5.143663120269776 and perplexity is 171.3422674829662
At time: 1289.509616136551 and batch: 500, loss is 5.175626573562622 and perplexity is 176.90742507283142
At time: 1290.5818221569061 and batch: 550, loss is 5.157253541946411 and perplexity is 173.68677649644508
At time: 1291.6642231941223 and batch: 600, loss is 5.120021028518677 and perplexity is 167.33888847304743
At time: 1292.743361711502 and batch: 650, loss is 5.126353874206543 and perplexity is 168.40198248354574
At time: 1293.8167281150818 and batch: 700, loss is 5.133305587768555 and perplexity is 169.57674339875385
At time: 1294.8894703388214 and batch: 750, loss is 5.105329885482788 and perplexity is 164.89845916795082
At time: 1295.964213848114 and batch: 800, loss is 5.105867938995361 and perplexity is 164.9872072365881
At time: 1297.0364480018616 and batch: 850, loss is 5.0757973194122314 and perplexity is 160.09979177560635
At time: 1298.1098194122314 and batch: 900, loss is 5.1056805515289305 and perplexity is 164.95629359833515
At time: 1299.1823418140411 and batch: 950, loss is 5.082963256835938 and perplexity is 161.2511773163569
At time: 1300.25501871109 and batch: 1000, loss is 5.10906759262085 and perplexity is 165.5159546054998
At time: 1301.329513311386 and batch: 1050, loss is 5.067409725189209 and perplexity is 158.7625556238441
At time: 1302.4078645706177 and batch: 1100, loss is 5.063408765792847 and perplexity is 158.12862210192105
At time: 1303.5072128772736 and batch: 1150, loss is 5.084825525283813 and perplexity is 161.5517500827789
At time: 1304.5898489952087 and batch: 1200, loss is 5.046686038970948 and perplexity is 155.5062679195037
At time: 1305.6644473075867 and batch: 1250, loss is 5.061406364440918 and perplexity is 157.81230194089798
At time: 1306.7364010810852 and batch: 1300, loss is 5.042731914520264 and perplexity is 154.89259086059533
At time: 1307.8106815814972 and batch: 1350, loss is 5.027765474319458 and perplexity is 152.59166147241442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156337076822917 and perplexity of 173.52767154158107
Finished 42 epochs...
Completing Train Step...
At time: 1311.0574884414673 and batch: 50, loss is 5.159622726440429 and perplexity is 174.09876035431373
At time: 1312.1590440273285 and batch: 100, loss is 5.163723726272583 and perplexity is 174.81420535851817
At time: 1313.2397737503052 and batch: 150, loss is 5.132789764404297 and perplexity is 169.48929430855497
At time: 1314.3161146640778 and batch: 200, loss is 5.131228895187378 and perplexity is 169.2249500435531
At time: 1315.3899974822998 and batch: 250, loss is 5.145344715118409 and perplexity is 171.63063815067972
At time: 1316.4672558307648 and batch: 300, loss is 5.14046459197998 and perplexity is 170.79509992512763
At time: 1317.5420596599579 and batch: 350, loss is 5.147463703155518 and perplexity is 171.99470701227787
At time: 1318.6171507835388 and batch: 400, loss is 5.172959976196289 and perplexity is 176.43631261183452
At time: 1319.7031333446503 and batch: 450, loss is 5.1434345626831055 and perplexity is 171.30311038281232
At time: 1320.7779123783112 and batch: 500, loss is 5.175344581604004 and perplexity is 176.85754563467188
At time: 1321.8515524864197 and batch: 550, loss is 5.157053003311157 and perplexity is 173.65194907956283
At time: 1322.9261920452118 and batch: 600, loss is 5.119889259338379 and perplexity is 167.3168398175799
At time: 1323.9998452663422 and batch: 650, loss is 5.126229333877563 and perplexity is 168.38101095117435
At time: 1325.0742824077606 and batch: 700, loss is 5.133196239471435 and perplexity is 169.558201484414
At time: 1326.1494481563568 and batch: 750, loss is 5.105239191055298 and perplexity is 164.88350447476654
At time: 1327.223736524582 and batch: 800, loss is 5.105851020812988 and perplexity is 164.9844159765384
At time: 1328.2984681129456 and batch: 850, loss is 5.075764837265015 and perplexity is 160.0945914750595
At time: 1329.3723366260529 and batch: 900, loss is 5.105632848739624 and perplexity is 164.94842491069755
At time: 1330.478565454483 and batch: 950, loss is 5.082875843048096 and perplexity is 161.2370823562096
At time: 1331.552984714508 and batch: 1000, loss is 5.109005069732666 and perplexity is 165.50560639348072
At time: 1332.6274321079254 and batch: 1050, loss is 5.067369585037231 and perplexity is 158.75618299863297
At time: 1333.7019085884094 and batch: 1100, loss is 5.0633978748321535 and perplexity is 158.12689993869125
At time: 1334.7770297527313 and batch: 1150, loss is 5.084855041503906 and perplexity is 161.55651855016396
At time: 1335.8516924381256 and batch: 1200, loss is 5.046762371063233 and perplexity is 155.5181384913445
At time: 1336.9255282878876 and batch: 1250, loss is 5.061468467712403 and perplexity is 157.82210290546183
At time: 1338.0099630355835 and batch: 1300, loss is 5.0427711391448975 and perplexity is 154.89866658348856
At time: 1339.0833163261414 and batch: 1350, loss is 5.02766019821167 and perplexity is 152.57559806177522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1563321940104165 and perplexity of 173.526824240566
Finished 43 epochs...
Completing Train Step...
At time: 1342.2810180187225 and batch: 50, loss is 5.159219541549683 and perplexity is 174.0285805133176
At time: 1343.3536393642426 and batch: 100, loss is 5.163295297622681 and perplexity is 174.7393259859124
At time: 1344.426460981369 and batch: 150, loss is 5.132442169189453 and perplexity is 169.43039087875425
At time: 1345.499502658844 and batch: 200, loss is 5.130885286331177 and perplexity is 169.16681284082884
At time: 1346.5721607208252 and batch: 250, loss is 5.1450133228302 and perplexity is 171.57377050404654
At time: 1347.6462240219116 and batch: 300, loss is 5.14016393661499 and perplexity is 170.74375718064368
At time: 1348.720549106598 and batch: 350, loss is 5.1472354221344 and perplexity is 171.9554483661066
At time: 1349.7933139801025 and batch: 400, loss is 5.172728528976441 and perplexity is 176.39548164308965
At time: 1350.8969831466675 and batch: 450, loss is 5.1432131481170655 and perplexity is 171.2651855776727
At time: 1351.9794132709503 and batch: 500, loss is 5.175060148239136 and perplexity is 176.807248601281
At time: 1353.054144859314 and batch: 550, loss is 5.157007427215576 and perplexity is 173.6440348820842
At time: 1354.1289732456207 and batch: 600, loss is 5.119751996994019 and perplexity is 167.29387509202772
At time: 1355.2028152942657 and batch: 650, loss is 5.1261152744293215 and perplexity is 168.36180660121045
At time: 1356.2802793979645 and batch: 700, loss is 5.133080224990845 and perplexity is 169.53853141876726
At time: 1357.3815908432007 and batch: 750, loss is 5.105141525268555 and perplexity is 164.8674017839348
At time: 1358.4560134410858 and batch: 800, loss is 5.10583158493042 and perplexity is 164.98120938996541
At time: 1359.5356059074402 and batch: 850, loss is 5.075726346969605 and perplexity is 160.08842950552878
At time: 1360.6164762973785 and batch: 900, loss is 5.105575542449952 and perplexity is 164.9389725993196
At time: 1361.6932022571564 and batch: 950, loss is 5.082776260375977 and perplexity is 161.22102673614793
At time: 1362.7684938907623 and batch: 1000, loss is 5.108927412033081 and perplexity is 165.49275410786578
At time: 1363.8428416252136 and batch: 1050, loss is 5.067313842773437 and perplexity is 158.74733381624034
At time: 1364.9158523082733 and batch: 1100, loss is 5.063374338150024 and perplexity is 158.12317819991014
At time: 1365.9880392551422 and batch: 1150, loss is 5.084887571334839 and perplexity is 161.56177404187818
At time: 1367.0613026618958 and batch: 1200, loss is 5.046827974319458 and perplexity is 155.52834132229748
At time: 1368.1376683712006 and batch: 1250, loss is 5.061505270004273 and perplexity is 157.8279112274356
At time: 1369.2131180763245 and batch: 1300, loss is 5.042783136367798 and perplexity is 154.90052494846614
At time: 1370.2843635082245 and batch: 1350, loss is 5.0275537872314455 and perplexity is 152.55936320662585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1563321940104165 and perplexity of 173.526824240566
Finished 44 epochs...
Completing Train Step...
At time: 1373.493473291397 and batch: 50, loss is 5.158845205307006 and perplexity is 173.9634474999543
At time: 1374.5646586418152 and batch: 100, loss is 5.162903985977173 and perplexity is 174.67096182944348
At time: 1375.6370840072632 and batch: 150, loss is 5.132107601165772 and perplexity is 169.373714369329
At time: 1376.7092785835266 and batch: 200, loss is 5.130546150207519 and perplexity is 169.10945199078844
At time: 1377.7833647727966 and batch: 250, loss is 5.14478515625 and perplexity is 171.53462756930315
At time: 1378.8542160987854 and batch: 300, loss is 5.139812850952149 and perplexity is 170.68382201728178
At time: 1379.9277606010437 and batch: 350, loss is 5.147016382217407 and perplexity is 171.9177873837498
At time: 1381.001302242279 and batch: 400, loss is 5.172480735778809 and perplexity is 176.35177745766904
At time: 1382.0737080574036 and batch: 450, loss is 5.143002595901489 and perplexity is 171.22912910941605
At time: 1383.1464591026306 and batch: 500, loss is 5.17491602897644 and perplexity is 176.78176910706043
At time: 1384.2184052467346 and batch: 550, loss is 5.1568356800079345 and perplexity is 173.61421456482103
At time: 1385.3174979686737 and batch: 600, loss is 5.119609870910645 and perplexity is 167.27009995836173
At time: 1386.3903160095215 and batch: 650, loss is 5.1260151863098145 and perplexity is 168.34495642785606
At time: 1387.462562084198 and batch: 700, loss is 5.13297360420227 and perplexity is 169.5204560504757
At time: 1388.5341708660126 and batch: 750, loss is 5.105043611526489 and perplexity is 164.85125978995595
At time: 1389.606496334076 and batch: 800, loss is 5.105805883407593 and perplexity is 164.9769691761364
At time: 1390.6791079044342 and batch: 850, loss is 5.075696849822998 and perplexity is 160.08370742329802
At time: 1391.7594289779663 and batch: 900, loss is 5.10553240776062 and perplexity is 164.93185816141852
At time: 1392.8313603401184 and batch: 950, loss is 5.082688694000244 and perplexity is 161.20690981323764
At time: 1393.9036247730255 and batch: 1000, loss is 5.108859262466431 and perplexity is 165.48147623268505
At time: 1394.9841964244843 and batch: 1050, loss is 5.067268657684326 and perplexity is 158.74016096586985
At time: 1396.0571250915527 and batch: 1100, loss is 5.06335108757019 and perplexity is 158.11950178707136
At time: 1397.129008769989 and batch: 1150, loss is 5.0849076271057125 and perplexity is 161.5650143202933
At time: 1398.2020945549011 and batch: 1200, loss is 5.046903638839722 and perplexity is 155.54010974485143
At time: 1399.275015592575 and batch: 1250, loss is 5.061540756225586 and perplexity is 157.83351204299817
At time: 1400.348001241684 and batch: 1300, loss is 5.042812185287476 and perplexity is 154.90502470672965
At time: 1401.4200639724731 and batch: 1350, loss is 5.027453927993775 and perplexity is 152.54412950554203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156324462890625 and perplexity of 173.5254826890866
Finished 45 epochs...
Completing Train Step...
At time: 1404.586211681366 and batch: 50, loss is 5.1584872627258305 and perplexity is 173.9011897175463
At time: 1405.6845104694366 and batch: 100, loss is 5.162533092498779 and perplexity is 174.60618952139203
At time: 1406.756861448288 and batch: 150, loss is 5.131787605285645 and perplexity is 169.319524149315
At time: 1407.829694032669 and batch: 200, loss is 5.130206022262573 and perplexity is 169.05194292118716
At time: 1408.909541130066 and batch: 250, loss is 5.144485702514649 and perplexity is 171.4832685745406
At time: 1409.9809656143188 and batch: 300, loss is 5.139521379470825 and perplexity is 170.63407980041134
At time: 1411.0556914806366 and batch: 350, loss is 5.146771354675293 and perplexity is 171.87566795128274
At time: 1412.1583256721497 and batch: 400, loss is 5.172237405776977 and perplexity is 176.30887099976323
At time: 1413.232842206955 and batch: 450, loss is 5.14279598236084 and perplexity is 171.19375450735026
At time: 1414.3034245967865 and batch: 500, loss is 5.174641561508179 and perplexity is 176.73325492054636
At time: 1415.377958059311 and batch: 550, loss is 5.156652307510376 and perplexity is 173.5823814114362
At time: 1416.4550020694733 and batch: 600, loss is 5.119452476501465 and perplexity is 167.24377465158776
At time: 1417.5274708271027 and batch: 650, loss is 5.125907478332519 and perplexity is 168.32682530956194
At time: 1418.600121974945 and batch: 700, loss is 5.132872018814087 and perplexity is 169.5032361238041
At time: 1419.6714932918549 and batch: 750, loss is 5.104943075180054 and perplexity is 164.8346870796852
At time: 1420.7507772445679 and batch: 800, loss is 5.105773906707764 and perplexity is 164.9716938414588
At time: 1421.8213589191437 and batch: 850, loss is 5.075655117034912 and perplexity is 160.077026823261
At time: 1422.891636133194 and batch: 900, loss is 5.105475425720215 and perplexity is 164.92246027537055
At time: 1423.962295293808 and batch: 950, loss is 5.082591781616211 and perplexity is 161.19128762428903
At time: 1425.0326862335205 and batch: 1000, loss is 5.108788003921509 and perplexity is 165.46968468360654
At time: 1426.1118123531342 and batch: 1050, loss is 5.067207622528076 and perplexity is 158.7304725310127
At time: 1427.1826202869415 and batch: 1100, loss is 5.06330304145813 and perplexity is 158.11190494227043
At time: 1428.2538802623749 and batch: 1150, loss is 5.0849157905578615 and perplexity is 161.56633325394017
At time: 1429.325252532959 and batch: 1200, loss is 5.046936321258545 and perplexity is 155.5451932549321
At time: 1430.3962469100952 and batch: 1250, loss is 5.061523084640503 and perplexity is 157.8307228993055
At time: 1431.4669449329376 and batch: 1300, loss is 5.042818031311035 and perplexity is 154.90593028780057
At time: 1432.537994146347 and batch: 1350, loss is 5.027339200973511 and perplexity is 152.52662957598176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1563033040364585 and perplexity of 173.52181112754735
Finished 46 epochs...
Completing Train Step...
At time: 1435.7243010997772 and batch: 50, loss is 5.158125505447388 and perplexity is 173.83829107414314
At time: 1436.8244121074677 and batch: 100, loss is 5.162135896682739 and perplexity is 174.53685044496652
At time: 1437.9015629291534 and batch: 150, loss is 5.1314522075653075 and perplexity is 169.2627442893568
At time: 1439.0010287761688 and batch: 200, loss is 5.129831466674805 and perplexity is 168.98863542817065
At time: 1440.0737438201904 and batch: 250, loss is 5.144153432846069 and perplexity is 171.42629935082113
At time: 1441.147227048874 and batch: 300, loss is 5.139225969314575 and perplexity is 170.58368020487868
At time: 1442.2222077846527 and batch: 350, loss is 5.146540937423706 and perplexity is 171.83606939452918
At time: 1443.2943136692047 and batch: 400, loss is 5.171984939575196 and perplexity is 176.26436458718035
At time: 1444.3685252666473 and batch: 450, loss is 5.142539920806885 and perplexity is 171.1499239804396
At time: 1445.4416692256927 and batch: 500, loss is 5.1743013954162596 and perplexity is 176.67314648391346
At time: 1446.5151643753052 and batch: 550, loss is 5.156492404937744 and perplexity is 173.5546273611161
At time: 1447.588287115097 and batch: 600, loss is 5.119272212982178 and perplexity is 167.2136294173149
At time: 1448.6619038581848 and batch: 650, loss is 5.125781021118164 and perplexity is 168.3055405139684
At time: 1449.7350859642029 and batch: 700, loss is 5.132757444381713 and perplexity is 169.4838164992572
At time: 1450.8083927631378 and batch: 750, loss is 5.10482590675354 and perplexity is 164.81537479018255
At time: 1451.8836042881012 and batch: 800, loss is 5.105726757049561 and perplexity is 164.96391566585152
At time: 1452.9621114730835 and batch: 850, loss is 5.075589904785156 and perplexity is 160.06658818057505
At time: 1454.034556388855 and batch: 900, loss is 5.105367708206177 and perplexity is 164.9046961947091
At time: 1455.1068365573883 and batch: 950, loss is 5.082455015182495 and perplexity is 161.16924357421198
At time: 1456.1786708831787 and batch: 1000, loss is 5.108703775405884 and perplexity is 165.45574800462578
At time: 1457.2517757415771 and batch: 1050, loss is 5.067133302688599 and perplexity is 158.7186761461322
At time: 1458.3245787620544 and batch: 1100, loss is 5.063244848251343 and perplexity is 158.1027041712045
At time: 1459.397578239441 and batch: 1150, loss is 5.084923944473267 and perplexity is 161.5676506575248
At time: 1460.4704718589783 and batch: 1200, loss is 5.046981954574585 and perplexity is 155.55229145985058
At time: 1461.5421929359436 and batch: 1250, loss is 5.061533555984497 and perplexity is 157.8323756077509
At time: 1462.6143567562103 and batch: 1300, loss is 5.042836332321167 and perplexity is 154.90876524874156
At time: 1463.6872954368591 and batch: 1350, loss is 5.02724365234375 and perplexity is 152.51205656175054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156296793619791 and perplexity of 173.52068143193347
Finished 47 epochs...
Completing Train Step...
At time: 1466.878021478653 and batch: 50, loss is 5.157783765792846 and perplexity is 173.7788937863877
At time: 1467.949645280838 and batch: 100, loss is 5.161780300140381 and perplexity is 174.47479677812288
At time: 1469.0221021175385 and batch: 150, loss is 5.131148223876953 and perplexity is 169.21129899570792
At time: 1470.0945920944214 and batch: 200, loss is 5.129506397247314 and perplexity is 168.93371131675798
At time: 1471.1710729599 and batch: 250, loss is 5.143864269256592 and perplexity is 171.37673627303408
At time: 1472.2468585968018 and batch: 300, loss is 5.13895435333252 and perplexity is 170.53735324291367
At time: 1473.3214962482452 and batch: 350, loss is 5.146328802108765 and perplexity is 171.79962076198774
At time: 1474.3935482501984 and batch: 400, loss is 5.171772603988647 and perplexity is 176.2269413632199
At time: 1475.4749882221222 and batch: 450, loss is 5.142317705154419 and perplexity is 171.1118960137739
At time: 1476.5564110279083 and batch: 500, loss is 5.174028959274292 and perplexity is 176.62502088936938
At time: 1477.640135526657 and batch: 550, loss is 5.1563294315338135 and perplexity is 173.52634487743612
At time: 1478.720939397812 and batch: 600, loss is 5.119122381210327 and perplexity is 167.18857737978414
At time: 1479.7965648174286 and batch: 650, loss is 5.12567174911499 and perplexity is 168.28715043518983
At time: 1480.8681252002716 and batch: 700, loss is 5.132649641036988 and perplexity is 169.46554656175957
At time: 1481.9405558109283 and batch: 750, loss is 5.104736375808716 and perplexity is 164.80061937449906
At time: 1483.0132024288177 and batch: 800, loss is 5.105680952072143 and perplexity is 164.9563596704722
At time: 1484.086215019226 and batch: 850, loss is 5.0755447673797605 and perplexity is 160.05936335315025
At time: 1485.1592330932617 and batch: 900, loss is 5.105306873321533 and perplexity is 164.89466454167922
At time: 1486.2314817905426 and batch: 950, loss is 5.082353582382202 and perplexity is 161.15289655559118
At time: 1487.3141572475433 and batch: 1000, loss is 5.108629932403565 and perplexity is 165.44353070652872
At time: 1488.3942697048187 and batch: 1050, loss is 5.067080278396606 and perplexity is 158.71026042382437
At time: 1489.4701557159424 and batch: 1100, loss is 5.063210353851319 and perplexity is 158.09725060734112
At time: 1490.5430326461792 and batch: 1150, loss is 5.084931144714355 and perplexity is 161.56881398774982
At time: 1491.6257770061493 and batch: 1200, loss is 5.047032709121704 and perplexity is 155.56018664631355
At time: 1492.6979517936707 and batch: 1250, loss is 5.061552152633667 and perplexity is 157.83531078835992
At time: 1493.7695095539093 and batch: 1300, loss is 5.0428492546081545 and perplexity is 154.91076703719673
At time: 1494.842500925064 and batch: 1350, loss is 5.02713547706604 and perplexity is 152.49555941998543
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1562939453125 and perplexity of 173.52018719241522
Finished 48 epochs...
Completing Train Step...
At time: 1498.0549747943878 and batch: 50, loss is 5.157453413009644 and perplexity is 173.72149492662206
At time: 1499.1262679100037 and batch: 100, loss is 5.161434841156006 and perplexity is 174.4145333019078
At time: 1500.1982662677765 and batch: 150, loss is 5.130852937698364 and perplexity is 169.16134061422622
At time: 1501.2711896896362 and batch: 200, loss is 5.129193572998047 and perplexity is 168.8808730203205
At time: 1502.344343662262 and batch: 250, loss is 5.143588600158691 and perplexity is 171.32949951390103
At time: 1503.4181768894196 and batch: 300, loss is 5.138680114746093 and perplexity is 170.4905917324258
At time: 1504.504930973053 and batch: 350, loss is 5.146119270324707 and perplexity is 171.76362705199386
At time: 1505.58291554451 and batch: 400, loss is 5.171573038101196 and perplexity is 176.1917759862955
At time: 1506.6568403244019 and batch: 450, loss is 5.142109069824219 and perplexity is 171.07619975072828
At time: 1507.7321646213531 and batch: 500, loss is 5.173770084381103 and perplexity is 176.57930302381132
At time: 1508.8158423900604 and batch: 550, loss is 5.156164598464966 and perplexity is 173.49774435470482
At time: 1509.889327764511 and batch: 600, loss is 5.118977880477905 and perplexity is 167.16442025330338
At time: 1510.9615635871887 and batch: 650, loss is 5.125563735961914 and perplexity is 168.26897419110355
At time: 1512.042496919632 and batch: 700, loss is 5.132537488937378 and perplexity is 169.44654171063803
At time: 1513.1197102069855 and batch: 750, loss is 5.104651002883911 and perplexity is 164.78655046417404
At time: 1514.1931018829346 and batch: 800, loss is 5.1056358528137205 and perplexity is 164.94892042873232
At time: 1515.2731666564941 and batch: 850, loss is 5.075499887466431 and perplexity is 160.05218006398925
At time: 1516.3456525802612 and batch: 900, loss is 5.105247201919556 and perplexity is 164.8848253394299
At time: 1517.422899723053 and batch: 950, loss is 5.08225459098816 and perplexity is 161.13694459527355
At time: 1518.495489358902 and batch: 1000, loss is 5.108558473587036 and perplexity is 165.43170873001932
At time: 1519.5684823989868 and batch: 1050, loss is 5.067022218704223 and perplexity is 158.70104602242142
At time: 1520.685985326767 and batch: 1100, loss is 5.063172092437744 and perplexity is 158.0912016987713
At time: 1521.7609701156616 and batch: 1150, loss is 5.084936828613281 and perplexity is 161.56973233116796
At time: 1522.8434596061707 and batch: 1200, loss is 5.047075815200806 and perplexity is 155.5668923805521
At time: 1523.9234726428986 and batch: 1250, loss is 5.061566944122315 and perplexity is 157.8376454248339
At time: 1525.0092418193817 and batch: 1300, loss is 5.042854890823365 and perplexity is 154.91164015007865
At time: 1526.0854935646057 and batch: 1350, loss is 5.027027645111084 and perplexity is 152.47911641224778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156297607421875 and perplexity of 173.520822643483
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1529.254774570465 and batch: 50, loss is 5.15744306564331 and perplexity is 173.719697375974
At time: 1530.3540604114532 and batch: 100, loss is 5.161450271606445 and perplexity is 174.41722461748384
At time: 1531.425973892212 and batch: 150, loss is 5.130947151184082 and perplexity is 169.17727864455108
At time: 1532.4988222122192 and batch: 200, loss is 5.129480028152466 and perplexity is 168.929256746433
At time: 1533.5720026493073 and batch: 250, loss is 5.143615779876709 and perplexity is 171.3341562646702
At time: 1534.6454067230225 and batch: 300, loss is 5.1387167739868165 and perplexity is 170.49684190263167
At time: 1535.7221636772156 and batch: 350, loss is 5.146174659729004 and perplexity is 171.77314120046523
At time: 1536.799741268158 and batch: 400, loss is 5.172115221023559 and perplexity is 176.28733005984873
At time: 1537.8716304302216 and batch: 450, loss is 5.1422607040405275 and perplexity is 171.10214272307795
At time: 1538.9543464183807 and batch: 500, loss is 5.173788423538208 and perplexity is 176.5825413690851
At time: 1540.0293145179749 and batch: 550, loss is 5.1554614925384525 and perplexity is 173.37579993735724
At time: 1541.1024746894836 and batch: 600, loss is 5.117798128128052 and perplexity is 166.96732392098846
At time: 1542.179009437561 and batch: 650, loss is 5.124634141921997 and perplexity is 168.11262503747227
At time: 1543.2547307014465 and batch: 700, loss is 5.131215867996215 and perplexity is 169.2227455321388
At time: 1544.336473941803 and batch: 750, loss is 5.103532629013062 and perplexity is 164.60236050768287
At time: 1545.409191608429 and batch: 800, loss is 5.104304065704346 and perplexity is 164.72938979927898
At time: 1546.482385635376 and batch: 850, loss is 5.073531188964844 and perplexity is 159.7373955365048
At time: 1547.6030521392822 and batch: 900, loss is 5.102909536361694 and perplexity is 164.49982993279392
At time: 1548.676594734192 and batch: 950, loss is 5.080146474838257 and perplexity is 160.79760700722343
At time: 1549.7504947185516 and batch: 1000, loss is 5.106384410858154 and perplexity is 165.07244049524184
At time: 1550.8244862556458 and batch: 1050, loss is 5.064479265213013 and perplexity is 158.29798933778255
At time: 1551.898759841919 and batch: 1100, loss is 5.060661067962647 and perplexity is 157.6947288068972
At time: 1552.971833705902 and batch: 1150, loss is 5.082462930679322 and perplexity is 161.17051931389713
At time: 1554.0448274612427 and batch: 1200, loss is 5.044116544723511 and perplexity is 155.10720836881333
At time: 1555.1174082756042 and batch: 1250, loss is 5.058875207901001 and perplexity is 157.41335940675688
At time: 1556.1898357868195 and batch: 1300, loss is 5.039861221313476 and perplexity is 154.44857936753888
At time: 1557.2740414142609 and batch: 1350, loss is 5.024805459976196 and perplexity is 152.1406557867406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.156883951822917 and perplexity of 173.62259544034328
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc203461c50>
SETTINGS FOR THIS RUN
{'dropout': 0.0, 'data': 'wikitext', 'wordvec_source': '', 'lr': 0.10894124076359464, 'wordvec_dim': 200, 'anneal': 5.833171865336385, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5571873188018799 and batch: 50, loss is 9.809597034454345 and perplexity is 18207.64854398706
At time: 2.6218340396881104 and batch: 100, loss is 9.526416988372803 and perplexity is 13717.353490196117
At time: 3.686981201171875 and batch: 150, loss is 9.116253013610839 and perplexity is 9102.0324489996
At time: 4.751857042312622 and batch: 200, loss is 8.552604560852052 and perplexity is 5180.229093666213
At time: 5.818077325820923 and batch: 250, loss is 7.920509700775146 and perplexity is 2753.1739830738074
At time: 6.884496450424194 and batch: 300, loss is 7.460389976501465 and perplexity is 1737.8256363821476
At time: 7.977957725524902 and batch: 350, loss is 7.198573560714721 and perplexity is 1337.5215097738078
At time: 9.044708967208862 and batch: 400, loss is 7.048616809844971 and perplexity is 1151.2652222452525
At time: 10.111056327819824 and batch: 450, loss is 6.894032278060913 and perplexity is 986.3707302085869
At time: 11.176766157150269 and batch: 500, loss is 6.770205945968628 and perplexity is 871.4913556418248
At time: 12.258259773254395 and batch: 550, loss is 6.65553394317627 and perplexity is 777.0727250155156
At time: 13.327842235565186 and batch: 600, loss is 6.555674028396607 and perplexity is 703.2229823759828
At time: 14.403700351715088 and batch: 650, loss is 6.53766134262085 and perplexity is 690.6694486151567
At time: 15.476452112197876 and batch: 700, loss is 6.508648118972778 and perplexity is 670.9188018360545
At time: 16.55190896987915 and batch: 750, loss is 6.454535245895386 and perplexity is 635.5782699910467
At time: 17.620492696762085 and batch: 800, loss is 6.3925104904174805 and perplexity is 597.3543512053873
At time: 18.68915843963623 and batch: 850, loss is 6.355272750854493 and perplexity is 575.5192926329343
At time: 19.757402896881104 and batch: 900, loss is 6.3767415714263915 and perplexity is 588.008598697197
At time: 20.825201749801636 and batch: 950, loss is 6.339001445770264 and perplexity is 566.2306170127243
At time: 21.893935918807983 and batch: 1000, loss is 6.334804782867431 and perplexity is 563.8593172410233
At time: 22.96206521987915 and batch: 1050, loss is 6.310148620605469 and perplexity is 550.1267029003874
At time: 24.03136420249939 and batch: 1100, loss is 6.292240514755249 and perplexity is 540.3626643346386
At time: 25.11452317237854 and batch: 1150, loss is 6.268685350418091 and perplexity is 527.7830717984081
At time: 26.183785676956177 and batch: 1200, loss is 6.219848718643188 and perplexity is 502.62718814538067
At time: 27.252501726150513 and batch: 1250, loss is 6.217839317321777 and perplexity is 501.6182224573289
At time: 28.32203459739685 and batch: 1300, loss is 6.166301689147949 and perplexity is 476.42089139212334
At time: 29.390949487686157 and batch: 1350, loss is 6.157347497940063 and perplexity is 472.1739698843847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.778951009114583 and perplexity of 323.419748044529
Finished 1 epochs...
Completing Train Step...
At time: 32.57216262817383 and batch: 50, loss is 6.206911458969116 and perplexity is 496.1664519165484
At time: 33.63976287841797 and batch: 100, loss is 6.209040040969849 and perplexity is 497.2237077241166
At time: 34.70815896987915 and batch: 150, loss is 6.153741540908814 and perplexity is 470.47439697277065
At time: 35.77585482597351 and batch: 200, loss is 6.1469512462615965 and perplexity is 467.2905590256229
At time: 36.84552836418152 and batch: 250, loss is 6.157731018066406 and perplexity is 472.35509283489904
At time: 37.91881799697876 and batch: 300, loss is 6.170080118179321 and perplexity is 478.22441902421815
At time: 38.98821425437927 and batch: 350, loss is 6.169503116607666 and perplexity is 477.94856237535095
At time: 40.06157374382019 and batch: 400, loss is 6.205170269012451 and perplexity is 495.30328356174783
At time: 41.15545701980591 and batch: 450, loss is 6.1677868461608885 and perplexity is 477.1289768990118
At time: 42.2240731716156 and batch: 500, loss is 6.1531847476959225 and perplexity is 470.21251293608987
At time: 43.29339098930359 and batch: 550, loss is 6.112224645614624 and perplexity is 451.3416744162199
At time: 44.36366605758667 and batch: 600, loss is 6.0608146858215335 and perplexity is 428.7245704517728
At time: 45.43419814109802 and batch: 650, loss is 6.083650188446045 and perplexity is 438.62734864256475
At time: 46.504294633865356 and batch: 700, loss is 6.087209224700928 and perplexity is 440.1912205664415
At time: 47.57466411590576 and batch: 750, loss is 6.063406620025635 and perplexity is 429.8372376872787
At time: 48.64298415184021 and batch: 800, loss is 6.029066114425659 and perplexity is 415.32698033791456
At time: 49.71201968193054 and batch: 850, loss is 6.013877716064453 and perplexity is 409.06649245321626
At time: 50.77987504005432 and batch: 900, loss is 6.047941484451294 and perplexity is 423.2408847483103
At time: 51.848206758499146 and batch: 950, loss is 6.026854343414307 and perplexity is 414.40938728948976
At time: 52.916339635849 and batch: 1000, loss is 6.039257230758667 and perplexity is 419.5812670558224
At time: 53.98468852043152 and batch: 1050, loss is 6.025639438629151 and perplexity is 413.9062250508525
At time: 55.05897259712219 and batch: 1100, loss is 6.013484210968017 and perplexity is 408.9055543707094
At time: 56.12690734863281 and batch: 1150, loss is 6.007242794036865 and perplexity is 406.3613522925525
At time: 57.194602489471436 and batch: 1200, loss is 5.972219104766846 and perplexity is 392.37542753388817
At time: 58.26237630844116 and batch: 1250, loss is 5.982939100265503 and perplexity is 396.6043166892032
At time: 59.3304283618927 and batch: 1300, loss is 5.941969890594482 and perplexity is 380.68409742948546
At time: 60.39906644821167 and batch: 1350, loss is 5.936570024490356 and perplexity is 378.6339943978324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.58033935546875 and perplexity of 265.16157455009335
Finished 2 epochs...
Completing Train Step...
At time: 63.566537618637085 and batch: 50, loss is 5.998123054504394 and perplexity is 402.6722898161675
At time: 64.63514852523804 and batch: 100, loss is 6.008055019378662 and perplexity is 406.691543357434
At time: 65.70378088951111 and batch: 150, loss is 5.959224271774292 and perplexity is 387.30956071671744
At time: 66.77415728569031 and batch: 200, loss is 5.958761339187622 and perplexity is 387.13030399502316
At time: 67.86980891227722 and batch: 250, loss is 5.978787031173706 and perplexity is 394.96100210290626
At time: 68.93771958351135 and batch: 300, loss is 5.991910667419433 and perplexity is 400.17848793516686
At time: 70.00577211380005 and batch: 350, loss is 5.997633628845215 and perplexity is 402.47525988497574
At time: 71.07429790496826 and batch: 400, loss is 6.039995365142822 and perplexity is 419.89108874693807
At time: 72.14190793037415 and batch: 450, loss is 6.007223911285401 and perplexity is 406.35367914457765
At time: 73.2161111831665 and batch: 500, loss is 6.001105995178222 and perplexity is 403.8752306262449
At time: 74.28451323509216 and batch: 550, loss is 5.966284065246582 and perplexity is 390.05356086549597
At time: 75.35267329216003 and batch: 600, loss is 5.918488969802857 and perplexity is 371.8494134641842
At time: 76.42979788780212 and batch: 650, loss is 5.947103853225708 and perplexity is 382.64354091095055
At time: 77.49851679801941 and batch: 700, loss is 5.950370578765869 and perplexity is 383.89557625331315
At time: 78.56763339042664 and batch: 750, loss is 5.928900804519653 and perplexity is 375.7412736407098
At time: 79.63564872741699 and batch: 800, loss is 5.898646860122681 and perplexity is 364.5438551496859
At time: 80.70503354072571 and batch: 850, loss is 5.887423629760742 and perplexity is 360.475368970875
At time: 81.77296042442322 and batch: 900, loss is 5.919081220626831 and perplexity is 372.0697068137224
At time: 82.84122014045715 and batch: 950, loss is 5.898719577789307 and perplexity is 364.5703648920669
At time: 83.90934610366821 and batch: 1000, loss is 5.916584606170654 and perplexity is 371.14195081140787
At time: 84.97737717628479 and batch: 1050, loss is 5.902789363861084 and perplexity is 366.0571116037156
At time: 86.04568028450012 and batch: 1100, loss is 5.8906485462188725 and perplexity is 361.63974842511544
At time: 87.11403298377991 and batch: 1150, loss is 5.889970779418945 and perplexity is 361.3947240541705
At time: 88.18206810951233 and batch: 1200, loss is 5.860033550262451 and perplexity is 350.73591110438656
At time: 89.25042462348938 and batch: 1250, loss is 5.873745126724243 and perplexity is 355.5781750386272
At time: 90.31916642189026 and batch: 1300, loss is 5.835286617279053 and perplexity is 342.16278976516725
At time: 91.38790464401245 and batch: 1350, loss is 5.829510793685913 and perplexity is 340.1922141780511
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.482286783854167 and perplexity of 240.3958125552949
Finished 3 epochs...
Completing Train Step...
At time: 94.53686285018921 and batch: 50, loss is 5.895010643005371 and perplexity is 363.22070163820666
At time: 95.60546660423279 and batch: 100, loss is 5.905649662017822 and perplexity is 367.1056429265389
At time: 96.67441368103027 and batch: 150, loss is 5.858291416168213 and perplexity is 350.1254140538475
At time: 97.74322962760925 and batch: 200, loss is 5.858201894760132 and perplexity is 350.09407173670155
At time: 98.81221270561218 and batch: 250, loss is 5.8837503147125245 and perplexity is 359.1536583893865
At time: 99.88090205192566 and batch: 300, loss is 5.892551546096802 and perplexity is 362.32860406043216
At time: 100.94976449012756 and batch: 350, loss is 5.901820106506348 and perplexity is 365.7024799484738
At time: 102.01861453056335 and batch: 400, loss is 5.947096519470215 and perplexity is 382.6407347070703
At time: 103.08714604377747 and batch: 450, loss is 5.9137732124328615 and perplexity is 370.09999002238214
At time: 104.15525197982788 and batch: 500, loss is 5.9135474109649655 and perplexity is 370.0164303356718
At time: 105.22387886047363 and batch: 550, loss is 5.881587686538697 and perplexity is 358.37778183766073
At time: 106.30605578422546 and batch: 600, loss is 5.834060754776001 and perplexity is 341.7436022168972
At time: 107.37942743301392 and batch: 650, loss is 5.865537910461426 and perplexity is 352.67181095103433
At time: 108.44817876815796 and batch: 700, loss is 5.869191370010376 and perplexity is 353.9626397059127
At time: 109.5182991027832 and batch: 750, loss is 5.847933807373047 and perplexity is 346.51766804991234
At time: 110.58737540245056 and batch: 800, loss is 5.818228244781494 and perplexity is 336.37555022061696
At time: 111.65651488304138 and batch: 850, loss is 5.808378915786744 and perplexity is 333.0787391011088
At time: 112.72608995437622 and batch: 900, loss is 5.839945402145386 and perplexity is 343.76057156288647
At time: 113.7964882850647 and batch: 950, loss is 5.819317979812622 and perplexity is 336.74231024063357
At time: 114.86572074890137 and batch: 1000, loss is 5.840152473449707 and perplexity is 343.8317618832961
At time: 115.93898725509644 and batch: 1050, loss is 5.825632438659668 and perplexity is 338.8753832139059
At time: 117.01015281677246 and batch: 1100, loss is 5.811850671768188 and perplexity is 334.23711684480304
At time: 118.0805881023407 and batch: 1150, loss is 5.814552869796753 and perplexity is 335.1415131015896
At time: 119.15096020698547 and batch: 1200, loss is 5.787695255279541 and perplexity is 326.2602106894399
At time: 120.23284554481506 and batch: 1250, loss is 5.802584867477417 and perplexity is 331.15444490608087
At time: 121.30332899093628 and batch: 1300, loss is 5.7659721851348875 and perplexity is 319.24926260430135
At time: 122.37578439712524 and batch: 1350, loss is 5.758580865859986 and perplexity is 316.8982884794116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.419136555989583 and perplexity of 225.68417270286076
Finished 4 epochs...
Completing Train Step...
At time: 125.56153392791748 and batch: 50, loss is 5.82711236000061 and perplexity is 339.37726340544697
At time: 126.65721392631531 and batch: 100, loss is 5.837107763290406 and perplexity is 342.7864859134801
At time: 127.72690558433533 and batch: 150, loss is 5.78974326133728 and perplexity is 326.929078265968
At time: 128.79675030708313 and batch: 200, loss is 5.789857339859009 and perplexity is 326.96637597932016
At time: 129.86614751815796 and batch: 250, loss is 5.818908090591431 and perplexity is 336.60431148138093
At time: 130.94395565986633 and batch: 300, loss is 5.82428918838501 and perplexity is 338.42049434552473
At time: 132.01383137702942 and batch: 350, loss is 5.835019159317016 and perplexity is 342.0712878397367
At time: 133.09211611747742 and batch: 400, loss is 5.882282724380493 and perplexity is 358.6269545398948
At time: 134.1665337085724 and batch: 450, loss is 5.847487192153931 and perplexity is 346.36294253962444
At time: 135.23647618293762 and batch: 500, loss is 5.851979570388794 and perplexity is 347.9224361789563
At time: 136.30643701553345 and batch: 550, loss is 5.821655225753784 and perplexity is 337.53028031969075
At time: 137.38926887512207 and batch: 600, loss is 5.774001121520996 and perplexity is 321.8228122331365
At time: 138.46206665039062 and batch: 650, loss is 5.808055686950683 and perplexity is 332.971095845592
At time: 139.5336513519287 and batch: 700, loss is 5.811024589538574 and perplexity is 333.961123514388
At time: 140.6069848537445 and batch: 750, loss is 5.789617881774903 and perplexity is 326.8880906107672
At time: 141.67902040481567 and batch: 800, loss is 5.760304298400879 and perplexity is 317.4449122011858
At time: 142.75944256782532 and batch: 850, loss is 5.75108639717102 and perplexity is 314.5321816104999
At time: 143.83024144172668 and batch: 900, loss is 5.780961036682129 and perplexity is 324.0704844339355
At time: 144.90051412582397 and batch: 950, loss is 5.760739583969116 and perplexity is 317.58312146824466
At time: 145.97262382507324 and batch: 1000, loss is 5.783221607208252 and perplexity is 324.80389727283426
At time: 147.04449200630188 and batch: 1050, loss is 5.76771876335144 and perplexity is 319.80734363623276
At time: 148.14298129081726 and batch: 1100, loss is 5.753060388565063 and perplexity is 315.1536786432329
At time: 149.23138666152954 and batch: 1150, loss is 5.757751216888428 and perplexity is 316.6354831734366
At time: 150.30345463752747 and batch: 1200, loss is 5.732952251434326 and perplexity is 308.8798145109269
At time: 151.3757152557373 and batch: 1250, loss is 5.7488219261169435 and perplexity is 313.82073841494196
At time: 152.4481382369995 and batch: 1300, loss is 5.713853721618652 and perplexity is 303.03663979623894
At time: 153.51887035369873 and batch: 1350, loss is 5.705184259414673 and perplexity is 300.4208303153916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3712646484375 and perplexity of 215.13476558563187
Finished 5 epochs...
Completing Train Step...
At time: 156.73117518424988 and batch: 50, loss is 5.7760193729400635 and perplexity is 322.4729874684613
At time: 157.83580827713013 and batch: 100, loss is 5.78493522644043 and perplexity is 325.36096464224767
At time: 158.9121024608612 and batch: 150, loss is 5.737229537963867 and perplexity is 310.2038115195037
At time: 159.98524260520935 and batch: 200, loss is 5.737970714569092 and perplexity is 310.4338125526167
At time: 161.0627956390381 and batch: 250, loss is 5.76879698753357 and perplexity is 320.1523536133894
At time: 162.1685974597931 and batch: 300, loss is 5.772263927459717 and perplexity is 321.26422887925986
At time: 163.2410683631897 and batch: 350, loss is 5.783222093582153 and perplexity is 324.8040552490113
At time: 164.31481051445007 and batch: 400, loss is 5.832073307037353 and perplexity is 341.0650791553803
At time: 165.38875579833984 and batch: 450, loss is 5.795886726379394 and perplexity is 328.9437377882556
At time: 166.4659764766693 and batch: 500, loss is 5.803808879852295 and perplexity is 331.56003021472253
At time: 167.5431821346283 and batch: 550, loss is 5.7745757579803465 and perplexity is 322.00779649875784
At time: 168.62468600273132 and batch: 600, loss is 5.726622695922852 and perplexity is 306.9309169129694
At time: 169.7002010345459 and batch: 650, loss is 5.762514257431031 and perplexity is 318.1472282104461
At time: 170.77048754692078 and batch: 700, loss is 5.765034713745117 and perplexity is 318.95011579709995
At time: 171.84312629699707 and batch: 750, loss is 5.743549499511719 and perplexity is 312.1704958187878
At time: 172.91596913337708 and batch: 800, loss is 5.713995714187622 and perplexity is 303.0796718022557
At time: 173.98962688446045 and batch: 850, loss is 5.704715814590454 and perplexity is 300.280132689453
At time: 175.06196665763855 and batch: 900, loss is 5.7341992378234865 and perplexity is 309.2652236855642
At time: 176.1812629699707 and batch: 950, loss is 5.713899974822998 and perplexity is 303.0506565360207
At time: 177.25354194641113 and batch: 1000, loss is 5.737146644592285 and perplexity is 310.17809874541325
At time: 178.53854727745056 and batch: 1050, loss is 5.721046323776245 and perplexity is 305.2241191894752
At time: 179.61084961891174 and batch: 1100, loss is 5.706024198532105 and perplexity is 300.67327152524695
At time: 180.68409895896912 and batch: 1150, loss is 5.712098503112793 and perplexity is 302.50521080155346
At time: 181.75827932357788 and batch: 1200, loss is 5.688572664260864 and perplexity is 295.4715823675676
At time: 182.83275437355042 and batch: 1250, loss is 5.705588846206665 and perplexity is 300.5424012067067
At time: 183.907488822937 and batch: 1300, loss is 5.67188307762146 and perplexity is 290.5812064843495
At time: 184.98792672157288 and batch: 1350, loss is 5.662032098770141 and perplexity is 287.7327502406916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3335498046875 and perplexity of 207.17209085921243
Finished 6 epochs...
Completing Train Step...
At time: 188.23050141334534 and batch: 50, loss is 5.735026206970215 and perplexity is 309.52108226270144
At time: 189.3054609298706 and batch: 100, loss is 5.742662143707276 and perplexity is 311.8936123825774
At time: 190.38012528419495 and batch: 150, loss is 5.694587507247925 and perplexity is 297.25415311001115
At time: 191.45397281646729 and batch: 200, loss is 5.695720243453979 and perplexity is 297.5910544257751
At time: 192.52904391288757 and batch: 250, loss is 5.727500534057617 and perplexity is 307.2004708716363
At time: 193.60641384124756 and batch: 300, loss is 5.729854574203491 and perplexity is 307.92448495766814
At time: 194.68476057052612 and batch: 350, loss is 5.740758695602417 and perplexity is 311.3005037320138
At time: 195.7646038532257 and batch: 400, loss is 5.789817743301391 and perplexity is 326.9534294926945
At time: 196.83812808990479 and batch: 450, loss is 5.75334602355957 and perplexity is 315.24371042000183
At time: 197.91069555282593 and batch: 500, loss is 5.763987722396851 and perplexity is 318.61635253944246
At time: 198.98396182060242 and batch: 550, loss is 5.7352536678314205 and perplexity is 309.59149420231086
At time: 200.05746817588806 and batch: 600, loss is 5.687215900421142 and perplexity is 295.07096903923906
At time: 201.13140845298767 and batch: 650, loss is 5.723896427154541 and perplexity is 306.0952803426774
At time: 202.20478987693787 and batch: 700, loss is 5.726621809005738 and perplexity is 306.93064469080707
At time: 203.27997159957886 and batch: 750, loss is 5.7054137134552 and perplexity is 300.4897709978225
At time: 204.3539743423462 and batch: 800, loss is 5.67563868522644 and perplexity is 291.6745673052768
At time: 205.4272768497467 and batch: 850, loss is 5.667103290557861 and perplexity is 289.1956042724314
At time: 206.49998784065247 and batch: 900, loss is 5.695039482116699 and perplexity is 297.3885348831601
At time: 207.57284545898438 and batch: 950, loss is 5.674925317764282 and perplexity is 291.46657035737036
At time: 208.64620923995972 and batch: 1000, loss is 5.69936161994934 and perplexity is 298.67667086611345
At time: 209.71948838233948 and batch: 1050, loss is 5.681734218597412 and perplexity is 293.45790905156616
At time: 210.79241800308228 and batch: 1100, loss is 5.666552171707154 and perplexity is 289.03626703428586
At time: 211.86595797538757 and batch: 1150, loss is 5.673533191680908 and perplexity is 291.06109444462635
At time: 212.94015741348267 and batch: 1200, loss is 5.650929298400879 and perplexity is 284.55578022294696
At time: 214.01269125938416 and batch: 1250, loss is 5.669083881378174 and perplexity is 289.7689500257722
At time: 215.08680200576782 and batch: 1300, loss is 5.636120204925537 and perplexity is 280.3728164718806
At time: 216.16053867340088 and batch: 1350, loss is 5.625640726089477 and perplexity is 277.44999703615895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.302296142578125 and perplexity of 200.79734037353242
Finished 7 epochs...
Completing Train Step...
At time: 219.34637475013733 and batch: 50, loss is 5.700247354507447 and perplexity is 298.9413363095614
At time: 220.4461772441864 and batch: 100, loss is 5.706728296279907 and perplexity is 300.8850494459817
At time: 221.51942348480225 and batch: 150, loss is 5.658143844604492 and perplexity is 286.6161444064031
At time: 222.59259057044983 and batch: 200, loss is 5.6591205978393555 and perplexity is 286.8962344197612
At time: 223.7026665210724 and batch: 250, loss is 5.692059688568115 and perplexity is 296.50369741669783
At time: 224.77511763572693 and batch: 300, loss is 5.693827924728393 and perplexity is 297.0284497824536
At time: 225.84799098968506 and batch: 350, loss is 5.7044648265838624 and perplexity is 300.2047754348094
At time: 226.92091298103333 and batch: 400, loss is 5.754260606765747 and perplexity is 315.5321589083703
At time: 227.994647026062 and batch: 450, loss is 5.717070798873902 and perplexity is 304.01310191250235
At time: 229.06710624694824 and batch: 500, loss is 5.72990200996399 and perplexity is 307.93909193623193
At time: 230.13934183120728 and batch: 550, loss is 5.70154803276062 and perplexity is 299.3304157834265
At time: 231.2123339176178 and batch: 600, loss is 5.653439359664917 and perplexity is 285.27092982352013
At time: 232.28615069389343 and batch: 650, loss is 5.690794897079468 and perplexity is 296.12891912201246
At time: 233.3583722114563 and batch: 700, loss is 5.693695344924927 and perplexity is 296.98907241933676
At time: 234.434814453125 and batch: 750, loss is 5.672327337265014 and perplexity is 290.71032866732963
At time: 235.50798726081848 and batch: 800, loss is 5.641924562454224 and perplexity is 282.0049326506828
At time: 236.58498764038086 and batch: 850, loss is 5.633889226913452 and perplexity is 279.74800810915804
At time: 237.6676733493805 and batch: 900, loss is 5.661071863174438 and perplexity is 287.4565916217483
At time: 238.74109268188477 and batch: 950, loss is 5.641123628616333 and perplexity is 281.7791557859056
At time: 239.81445789337158 and batch: 1000, loss is 5.666691045761109 and perplexity is 289.07640945973515
At time: 240.8876655101776 and batch: 1050, loss is 5.647576732635498 and perplexity is 283.603385630635
At time: 241.96110033988953 and batch: 1100, loss is 5.6325405406951905 and perplexity is 279.3709701361452
At time: 243.03385162353516 and batch: 1150, loss is 5.639720163345337 and perplexity is 281.38396590917085
At time: 244.1071002483368 and batch: 1200, loss is 5.617811765670776 and perplexity is 275.28633266393604
At time: 245.1855809688568 and batch: 1250, loss is 5.637213478088379 and perplexity is 280.67950816607123
At time: 246.26050639152527 and batch: 1300, loss is 5.6049649524688725 and perplexity is 271.7724003157345
At time: 247.33594584465027 and batch: 1350, loss is 5.593673162460327 and perplexity is 268.72086451562876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.275662434895834 and perplexity of 195.51995286259785
Finished 8 epochs...
Completing Train Step...
At time: 250.53275680541992 and batch: 50, loss is 5.670013065338135 and perplexity is 290.03832381575234
At time: 251.63261795043945 and batch: 100, loss is 5.675422086715698 and perplexity is 291.6113978698269
At time: 252.70521807670593 and batch: 150, loss is 5.626143350601196 and perplexity is 277.58948525760866
At time: 253.77991938591003 and batch: 200, loss is 5.627957677841186 and perplexity is 278.0935805809036
At time: 254.85222125053406 and batch: 250, loss is 5.661389017105103 and perplexity is 287.54777406834796
At time: 255.92971563339233 and batch: 300, loss is 5.66171856880188 and perplexity is 287.6425515413774
At time: 257.0041010379791 and batch: 350, loss is 5.672626914978028 and perplexity is 290.7974320492057
At time: 258.0768144130707 and batch: 400, loss is 5.723217897415161 and perplexity is 305.8876560394791
At time: 259.1534688472748 and batch: 450, loss is 5.685607767105102 and perplexity is 294.5968369193391
At time: 260.22761631011963 and batch: 500, loss is 5.699997587203979 and perplexity is 298.86667986185444
At time: 261.29948687553406 and batch: 550, loss is 5.6719089603424075 and perplexity is 290.5887276139628
At time: 262.37162709236145 and batch: 600, loss is 5.623577365875244 and perplexity is 276.8781079603178
At time: 263.444459438324 and batch: 650, loss is 5.661907882690429 and perplexity is 287.69701142616566
At time: 264.5158133506775 and batch: 700, loss is 5.664733724594116 and perplexity is 288.5111474647201
At time: 265.5878393650055 and batch: 750, loss is 5.643370571136475 and perplexity is 282.41300920174587
At time: 266.65697407722473 and batch: 800, loss is 5.612656011581421 and perplexity is 273.87067655184404
At time: 267.72611141204834 and batch: 850, loss is 5.603179540634155 and perplexity is 271.2876075620021
At time: 268.79687690734863 and batch: 900, loss is 5.630862846374511 and perplexity is 278.90266399330676
At time: 269.8671495914459 and batch: 950, loss is 5.611243000030518 and perplexity is 273.4839673990146
At time: 270.93735241889954 and batch: 1000, loss is 5.637761764526367 and perplexity is 280.8334431301902
At time: 272.00796461105347 and batch: 1050, loss is 5.617247257232666 and perplexity is 275.1309750607155
At time: 273.0913724899292 and batch: 1100, loss is 5.601816530227661 and perplexity is 270.91809161399067
At time: 274.1819303035736 and batch: 1150, loss is 5.6095827293396 and perplexity is 273.03028670410066
At time: 275.26861095428467 and batch: 1200, loss is 5.588388967514038 and perplexity is 267.3046361900835
At time: 276.3381118774414 and batch: 1250, loss is 5.608719682693481 and perplexity is 272.79475048486375
At time: 277.40755891799927 and batch: 1300, loss is 5.577259092330933 and perplexity is 264.3460637651444
At time: 278.4768035411835 and batch: 1350, loss is 5.565662708282471 and perplexity is 261.29831089847704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.252383626302083 and perplexity of 191.02104902655327
Finished 9 epochs...
Completing Train Step...
At time: 281.6077380180359 and batch: 50, loss is 5.643229932785034 and perplexity is 282.37329389451935
At time: 282.70318841934204 and batch: 100, loss is 5.64759407043457 and perplexity is 283.6083027317769
At time: 283.77206540107727 and batch: 150, loss is 5.597581014633179 and perplexity is 269.77304046494345
At time: 284.8414797782898 and batch: 200, loss is 5.599527330398559 and perplexity is 270.29861528804423
At time: 285.92119812965393 and batch: 250, loss is 5.633511533737183 and perplexity is 279.64236914623376
At time: 286.9919784069061 and batch: 300, loss is 5.6329961776733395 and perplexity is 279.49829088457847
At time: 288.0800983905792 and batch: 350, loss is 5.644393882751465 and perplexity is 282.70215363148105
At time: 289.15109038352966 and batch: 400, loss is 5.694158658981324 and perplexity is 297.12670351193276
At time: 290.23861598968506 and batch: 450, loss is 5.657310199737549 and perplexity is 286.37730789508345
At time: 291.31445574760437 and batch: 500, loss is 5.673098430633545 and perplexity is 290.93457992214485
At time: 292.39645195007324 and batch: 550, loss is 5.645288906097412 and perplexity is 282.95529192437334
At time: 293.472953081131 and batch: 600, loss is 5.597178564071656 and perplexity is 269.6644919974854
At time: 294.54969692230225 and batch: 650, loss is 5.635683574676514 and perplexity is 280.25042394129014
At time: 295.61945700645447 and batch: 700, loss is 5.638325300216675 and perplexity is 280.9917473992894
At time: 296.690509557724 and batch: 750, loss is 5.616797952651978 and perplexity is 275.0073852201513
At time: 297.76023626327515 and batch: 800, loss is 5.585993852615356 and perplexity is 266.66517696830465
At time: 298.829941034317 and batch: 850, loss is 5.57633641242981 and perplexity is 264.1022694545185
At time: 299.89965987205505 and batch: 900, loss is 5.603586540222168 and perplexity is 271.3980439787765
At time: 300.96948528289795 and batch: 950, loss is 5.584125738143921 and perplexity is 266.167480913524
At time: 302.044579744339 and batch: 1000, loss is 5.611662197113037 and perplexity is 273.5986351127704
At time: 303.11923837661743 and batch: 1050, loss is 5.589704713821411 and perplexity is 267.6565727569411
At time: 304.18885016441345 and batch: 1100, loss is 5.57403561592102 and perplexity is 263.4953223736043
At time: 305.31279277801514 and batch: 1150, loss is 5.58226634979248 and perplexity is 265.6730320286852
At time: 306.38748574256897 and batch: 1200, loss is 5.56121561050415 and perplexity is 260.1388717410727
At time: 307.46141242980957 and batch: 1250, loss is 5.582891311645508 and perplexity is 265.83911943282146
At time: 308.5452547073364 and batch: 1300, loss is 5.552783555984497 and perplexity is 257.9545885312066
At time: 309.61596155166626 and batch: 1350, loss is 5.540126180648803 and perplexity is 254.71013692128258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.231894124348958 and perplexity of 187.1469476081154
Finished 10 epochs...
Completing Train Step...
At time: 312.8399040699005 and batch: 50, loss is 5.618882284164429 and perplexity is 275.58118957082945
At time: 313.9110300540924 and batch: 100, loss is 5.622596397399902 and perplexity is 276.60663244112953
At time: 314.99026107788086 and batch: 150, loss is 5.571675205230713 and perplexity is 262.87409865780864
At time: 316.0605516433716 and batch: 200, loss is 5.574129571914673 and perplexity is 263.5200805015098
At time: 317.13106632232666 and batch: 250, loss is 5.608660383224487 and perplexity is 272.7785743806376
At time: 318.20320558547974 and batch: 300, loss is 5.60734673500061 and perplexity is 272.4204745509903
At time: 319.2758791446686 and batch: 350, loss is 5.618484029769897 and perplexity is 275.47146000262427
At time: 320.3492398262024 and batch: 400, loss is 5.668266801834107 and perplexity is 289.53228244548666
At time: 321.4394781589508 and batch: 450, loss is 5.63131724357605 and perplexity is 279.0294253811559
At time: 322.5216863155365 and batch: 500, loss is 5.648530883789062 and perplexity is 283.8741152661468
At time: 323.60518074035645 and batch: 550, loss is 5.621058959960937 and perplexity is 276.1816937905466
At time: 324.69406485557556 and batch: 600, loss is 5.572651329040528 and perplexity is 263.1308216007965
At time: 325.7746069431305 and batch: 650, loss is 5.612056512832641 and perplexity is 273.70654062848
At time: 326.8555362224579 and batch: 700, loss is 5.6143091201782225 and perplexity is 274.3237889404687
At time: 327.93380904197693 and batch: 750, loss is 5.592660083770752 and perplexity is 268.44876698572006
At time: 329.01834893226624 and batch: 800, loss is 5.56175910949707 and perplexity is 260.28029538420594
At time: 330.0991072654724 and batch: 850, loss is 5.551231031417847 and perplexity is 257.55441841278
At time: 331.1823396682739 and batch: 900, loss is 5.5787199592590335 and perplexity is 264.73252039940144
At time: 332.3141872882843 and batch: 950, loss is 5.5593243598937985 and perplexity is 259.6473488840756
At time: 333.3880431652069 and batch: 1000, loss is 5.587704334259033 and perplexity is 267.1216931785114
At time: 334.4617693424225 and batch: 1050, loss is 5.564568738937378 and perplexity is 261.0126148562785
At time: 335.5427505970001 and batch: 1100, loss is 5.54822995185852 and perplexity is 256.7826357820594
At time: 336.617182970047 and batch: 1150, loss is 5.557493906021119 and perplexity is 259.17251110568594
At time: 337.6909832954407 and batch: 1200, loss is 5.536507701873779 and perplexity is 253.79013919699233
At time: 338.76271295547485 and batch: 1250, loss is 5.559249601364136 and perplexity is 259.6279387555876
At time: 339.8376648426056 and batch: 1300, loss is 5.52939549446106 and perplexity is 251.9915346934969
At time: 340.91168332099915 and batch: 1350, loss is 5.5168899726867675 and perplexity is 248.859871423847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.213246256510416 and perplexity of 183.6893942561191
Finished 11 epochs...
Completing Train Step...
At time: 344.0883421897888 and batch: 50, loss is 5.59658519744873 and perplexity is 269.5045295514276
At time: 345.1656138896942 and batch: 100, loss is 5.600312194824219 and perplexity is 270.5108463308918
At time: 346.2375168800354 and batch: 150, loss is 5.547972106933594 and perplexity is 256.7164342178493
At time: 347.3096966743469 and batch: 200, loss is 5.550763893127441 and perplexity is 257.4341329792296
At time: 348.38667726516724 and batch: 250, loss is 5.5856102848052975 and perplexity is 266.5629124043072
At time: 349.4586384296417 and batch: 300, loss is 5.58328839302063 and perplexity is 265.9447001566093
At time: 350.53748416900635 and batch: 350, loss is 5.594681205749512 and perplexity is 268.99188335617987
At time: 351.61167645454407 and batch: 400, loss is 5.64445237159729 and perplexity is 282.718689037723
At time: 352.68649911880493 and batch: 450, loss is 5.607566213607788 and perplexity is 272.48027157915556
At time: 353.76016664505005 and batch: 500, loss is 5.625970773696899 and perplexity is 277.54158385703414
At time: 354.83341670036316 and batch: 550, loss is 5.598804216384888 and perplexity is 270.10322922316817
At time: 355.91097807884216 and batch: 600, loss is 5.550191040039063 and perplexity is 257.2867032729114
At time: 356.9850835800171 and batch: 650, loss is 5.589664697647095 and perplexity is 267.6458623791643
At time: 358.06122279167175 and batch: 700, loss is 5.5920861625671385 and perplexity is 268.2947427493785
At time: 359.1365282535553 and batch: 750, loss is 5.570399332046509 and perplexity is 262.53891851365677
At time: 360.2418715953827 and batch: 800, loss is 5.539657115936279 and perplexity is 254.59068940062917
At time: 361.31448459625244 and batch: 850, loss is 5.528696689605713 and perplexity is 251.815503298507
At time: 362.3920636177063 and batch: 900, loss is 5.555858211517334 and perplexity is 258.7489305723542
At time: 363.46423840522766 and batch: 950, loss is 5.536480569839478 and perplexity is 253.78325344764298
At time: 364.5437047481537 and batch: 1000, loss is 5.565700531005859 and perplexity is 261.3081940991157
At time: 365.61523389816284 and batch: 1050, loss is 5.5413353061676025 and perplexity is 255.01829971393508
At time: 366.6867558956146 and batch: 1100, loss is 5.524685039520263 and perplexity is 250.80733118213112
At time: 367.7594177722931 and batch: 1150, loss is 5.534457130432129 and perplexity is 253.27025759473426
At time: 368.83232522010803 and batch: 1200, loss is 5.513690328598022 and perplexity is 248.06488092887957
At time: 369.90721821784973 and batch: 1250, loss is 5.537360143661499 and perplexity is 254.00657275235253
At time: 370.98213505744934 and batch: 1300, loss is 5.508472604751587 and perplexity is 246.77391775768828
At time: 372.0584192276001 and batch: 1350, loss is 5.495348920822144 and perplexity is 243.5564932682809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1961474609375 and perplexity of 180.57522698302404
Finished 12 epochs...
Completing Train Step...
At time: 375.23334217071533 and batch: 50, loss is 5.575833339691162 and perplexity is 263.9694402167264
At time: 376.33476877212524 and batch: 100, loss is 5.579460010528565 and perplexity is 264.9285085489038
At time: 377.4060969352722 and batch: 150, loss is 5.526261444091797 and perplexity is 251.20301680395076
At time: 378.481365442276 and batch: 200, loss is 5.529394407272338 and perplexity is 251.99126073129145
At time: 379.5654830932617 and batch: 250, loss is 5.564348907470703 and perplexity is 260.95524237670304
At time: 380.645459651947 and batch: 300, loss is 5.561100902557373 and perplexity is 260.1090334565954
At time: 381.73023772239685 and batch: 350, loss is 5.572706260681152 and perplexity is 263.14527620552985
At time: 382.8243293762207 and batch: 400, loss is 5.622558946609497 and perplexity is 276.5962734980899
At time: 383.91728138923645 and batch: 450, loss is 5.58575101852417 and perplexity is 266.600429434177
At time: 385.0108609199524 and batch: 500, loss is 5.6050287532806395 and perplexity is 271.789740168633
At time: 386.0895092487335 and batch: 550, loss is 5.5781263256072995 and perplexity is 264.575412903346
At time: 387.2121653556824 and batch: 600, loss is 5.529733619689941 and perplexity is 252.07675379539364
At time: 388.28877997398376 and batch: 650, loss is 5.569200496673584 and perplexity is 262.2243661572921
At time: 389.3644597530365 and batch: 700, loss is 5.57156268119812 and perplexity is 262.844520668312
At time: 390.4411084651947 and batch: 750, loss is 5.5497688293457035 and perplexity is 257.1780970045077
At time: 391.5189108848572 and batch: 800, loss is 5.519183092117309 and perplexity is 249.43119163287503
At time: 392.5957500934601 and batch: 850, loss is 5.507458190917969 and perplexity is 246.52371380836829
At time: 393.67097663879395 and batch: 900, loss is 5.534669895172119 and perplexity is 253.32415030826985
At time: 394.7554008960724 and batch: 950, loss is 5.515122117996216 and perplexity is 248.42031198594736
At time: 395.833783864975 and batch: 1000, loss is 5.545254888534546 and perplexity is 256.0198264457861
At time: 396.91068959236145 and batch: 1050, loss is 5.519751453399659 and perplexity is 249.57299895988913
At time: 397.98665046691895 and batch: 1100, loss is 5.502971391677857 and perplexity is 245.42008911924705
At time: 399.0617582798004 and batch: 1150, loss is 5.513193616867065 and perplexity is 247.94169478901688
At time: 400.13752460479736 and batch: 1200, loss is 5.492565689086914 and perplexity is 242.87956157276474
At time: 401.214298248291 and batch: 1250, loss is 5.517110586166382 and perplexity is 248.9147793225068
At time: 402.2893624305725 and batch: 1300, loss is 5.488513851165772 and perplexity is 241.89744398919828
At time: 403.36505246162415 and batch: 1350, loss is 5.47552755355835 and perplexity is 238.7764010492661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.180616455078125 and perplexity of 177.79237823266757
Finished 13 epochs...
Completing Train Step...
At time: 406.5932867527008 and batch: 50, loss is 5.556666097640991 and perplexity is 258.95805470574317
At time: 407.6950044631958 and batch: 100, loss is 5.560138731002808 and perplexity is 259.8588843060149
At time: 408.77163553237915 and batch: 150, loss is 5.505983591079712 and perplexity is 246.16045787425406
At time: 409.8480107784271 and batch: 200, loss is 5.508720169067383 and perplexity is 246.83501773656937
At time: 410.92479968070984 and batch: 250, loss is 5.544688730239868 and perplexity is 255.8749197213845
At time: 412.0001356601715 and batch: 300, loss is 5.540953931808471 and perplexity is 254.9210608167046
At time: 413.07639932632446 and batch: 350, loss is 5.552257423400879 and perplexity is 257.81890591373934
At time: 414.1836323738098 and batch: 400, loss is 5.6021190357208255 and perplexity is 271.000058221951
At time: 415.26013445854187 and batch: 450, loss is 5.565509080886841 and perplexity is 261.2581714028333
At time: 416.33599519729614 and batch: 500, loss is 5.585484972000122 and perplexity is 266.5295107508693
At time: 417.41843032836914 and batch: 550, loss is 5.558768444061279 and perplexity is 259.50304692554727
At time: 418.4955062866211 and batch: 600, loss is 5.5102454280853275 and perplexity is 247.21179233970275
At time: 419.57298040390015 and batch: 650, loss is 5.550024614334107 and perplexity is 257.24388771484695
At time: 420.64814376831055 and batch: 700, loss is 5.552402505874634 and perplexity is 257.8563136319266
At time: 421.7236154079437 and batch: 750, loss is 5.53078372001648 and perplexity is 252.341598709395
At time: 422.80042123794556 and batch: 800, loss is 5.499897365570068 and perplexity is 244.66681973597062
At time: 423.87781500816345 and batch: 850, loss is 5.487691049575806 and perplexity is 241.69849224780398
At time: 424.95479583740234 and batch: 900, loss is 5.514863662719726 and perplexity is 248.35611474194292
At time: 426.030469417572 and batch: 950, loss is 5.495304584503174 and perplexity is 243.54569510928522
At time: 427.1076009273529 and batch: 1000, loss is 5.52621000289917 and perplexity is 251.19009495353532
At time: 428.1852924823761 and batch: 1050, loss is 5.499577140808105 and perplexity is 244.5884839050662
At time: 429.26242113113403 and batch: 1100, loss is 5.482697515487671 and perplexity is 240.4945710002937
At time: 430.3378109931946 and batch: 1150, loss is 5.493278703689575 and perplexity is 243.05280000027903
At time: 431.41341948509216 and batch: 1200, loss is 5.472885456085205 and perplexity is 238.14636320061877
At time: 432.4920084476471 and batch: 1250, loss is 5.498241157531738 and perplexity is 244.2619359608432
At time: 433.56837272644043 and batch: 1300, loss is 5.469746026992798 and perplexity is 237.39989193963507
At time: 434.6452717781067 and batch: 1350, loss is 5.456886301040649 and perplexity is 234.36654022673795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.165735270182291 and perplexity of 175.16620572203956
Finished 14 epochs...
Completing Train Step...
At time: 437.84936356544495 and batch: 50, loss is 5.538545579910278 and perplexity is 254.30785989418865
At time: 438.92626452445984 and batch: 100, loss is 5.542103490829468 and perplexity is 255.21427612366904
At time: 440.0022909641266 and batch: 150, loss is 5.486882190704346 and perplexity is 241.50307132275998
At time: 441.0886797904968 and batch: 200, loss is 5.490648183822632 and perplexity is 242.414284962599
At time: 442.1918821334839 and batch: 250, loss is 5.526005802154541 and perplexity is 251.1388069858012
At time: 443.2689938545227 and batch: 300, loss is 5.521676177978516 and perplexity is 250.05382082159767
At time: 444.3431408405304 and batch: 350, loss is 5.533023414611816 and perplexity is 252.90740019895608
At time: 445.41739892959595 and batch: 400, loss is 5.5829990863800045 and perplexity is 265.86777171730563
At time: 446.4914710521698 and batch: 450, loss is 5.546528882980347 and perplexity is 256.3462021389591
At time: 447.56522727012634 and batch: 500, loss is 5.567136316299439 and perplexity is 261.68364603097723
At time: 448.63896894454956 and batch: 550, loss is 5.540529975891113 and perplexity is 254.81300843085472
At time: 449.71349024772644 and batch: 600, loss is 5.492273807525635 and perplexity is 242.80867985216702
At time: 450.78765177726746 and batch: 650, loss is 5.532015352249146 and perplexity is 252.6525822253576
At time: 451.86037158966064 and batch: 700, loss is 5.534429330825805 and perplexity is 253.26321687914466
At time: 452.9343605041504 and batch: 750, loss is 5.512562856674195 and perplexity is 247.78535235026803
At time: 454.03152441978455 and batch: 800, loss is 5.481772165298462 and perplexity is 240.27213223626345
At time: 455.1102957725525 and batch: 850, loss is 5.469030084609986 and perplexity is 237.22998812324937
At time: 456.19221568107605 and batch: 900, loss is 5.496287145614624 and perplexity is 243.7851112393886
At time: 457.26429629325867 and batch: 950, loss is 5.47685583114624 and perplexity is 239.09377312374156
At time: 458.3363893032074 and batch: 1000, loss is 5.5082394409179685 and perplexity is 246.71638571244364
At time: 459.4120669364929 and batch: 1050, loss is 5.4805591011047365 and perplexity is 239.98084342762925
At time: 460.5059196949005 and batch: 1100, loss is 5.463583374023438 and perplexity is 235.94137756560391
At time: 461.5811402797699 and batch: 1150, loss is 5.474569807052612 and perplexity is 238.54782326276913
At time: 462.65617990493774 and batch: 1200, loss is 5.45434310913086 and perplexity is 233.77125841649806
At time: 463.74512100219727 and batch: 1250, loss is 5.480437717437744 and perplexity is 239.95171544071277
At time: 464.8201630115509 and batch: 1300, loss is 5.4522232246398925 and perplexity is 233.27621525389839
At time: 465.9023995399475 and batch: 1350, loss is 5.439451141357422 and perplexity is 230.31573798015677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15196044921875 and perplexity of 172.7698650722216
Finished 15 epochs...
Completing Train Step...
At time: 469.15131092071533 and batch: 50, loss is 5.521531000137329 and perplexity is 250.0175211827256
At time: 470.2244818210602 and batch: 100, loss is 5.525084791183471 and perplexity is 250.90761187226684
At time: 471.29737401008606 and batch: 150, loss is 5.468937997817993 and perplexity is 237.20814338050022
At time: 472.36886405944824 and batch: 200, loss is 5.4728927898406985 and perplexity is 238.1481097142224
At time: 473.4418680667877 and batch: 250, loss is 5.508701601028442 and perplexity is 246.8304345368989
At time: 474.5287914276123 and batch: 300, loss is 5.503828058242798 and perplexity is 245.63042238383468
At time: 475.6090233325958 and batch: 350, loss is 5.514917268753051 and perplexity is 248.36942848495156
At time: 476.6971890926361 and batch: 400, loss is 5.564913654327393 and perplexity is 261.10265765181066
At time: 477.7768063545227 and batch: 450, loss is 5.528614206314087 and perplexity is 251.79473358350145
At time: 478.85476875305176 and batch: 500, loss is 5.54974856376648 and perplexity is 257.1728851942187
At time: 479.9294481277466 and batch: 550, loss is 5.523238725662232 and perplexity is 250.44484725929465
At time: 481.0033049583435 and batch: 600, loss is 5.475262651443481 and perplexity is 238.71315705275146
At time: 482.0754656791687 and batch: 650, loss is 5.514856481552124 and perplexity is 248.35433126146174
At time: 483.1478536128998 and batch: 700, loss is 5.517401390075683 and perplexity is 248.98717523941434
At time: 484.21967339515686 and batch: 750, loss is 5.495420770645142 and perplexity is 243.57399338789492
At time: 485.29220056533813 and batch: 800, loss is 5.464664001464843 and perplexity is 236.19648010334086
At time: 486.364315032959 and batch: 850, loss is 5.45182246208191 and perplexity is 233.18274561197407
At time: 487.43714118003845 and batch: 900, loss is 5.478911008834839 and perplexity is 239.5856585946372
At time: 488.50933814048767 and batch: 950, loss is 5.459700803756714 and perplexity is 235.02709462078465
At time: 489.5821967124939 and batch: 1000, loss is 5.491231422424317 and perplexity is 242.55571156990828
At time: 490.6549482345581 and batch: 1050, loss is 5.462604455947876 and perplexity is 235.71052329847464
At time: 491.72759222984314 and batch: 1100, loss is 5.44554123878479 and perplexity is 231.7226630704639
At time: 492.8036551475525 and batch: 1150, loss is 5.456932611465454 and perplexity is 234.3773940920976
At time: 493.8778040409088 and batch: 1200, loss is 5.436813526153564 and perplexity is 229.70905413896
At time: 494.9499251842499 and batch: 1250, loss is 5.463666830062866 and perplexity is 235.961069120191
At time: 496.0229480266571 and batch: 1300, loss is 5.435622835159302 and perplexity is 229.43570440672352
At time: 497.09516191482544 and batch: 1350, loss is 5.422856979370117 and perplexity is 226.52537722378696
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.13912109375 and perplexity of 170.56579108319218
Finished 16 epochs...
Completing Train Step...
At time: 500.2283847332001 and batch: 50, loss is 5.505292425155639 and perplexity is 245.9903789370709
At time: 501.32492780685425 and batch: 100, loss is 5.509023914337158 and perplexity is 246.91000409342087
At time: 502.3977746963501 and batch: 150, loss is 5.451922674179077 and perplexity is 233.20611451483887
At time: 503.4702365398407 and batch: 200, loss is 5.4561161708831785 and perplexity is 234.18611696982032
At time: 504.5421493053436 and batch: 250, loss is 5.4922734642028805 and perplexity is 242.80859649043663
At time: 505.6145005226135 and batch: 300, loss is 5.486749544143676 and perplexity is 241.47103889550047
At time: 506.6860227584839 and batch: 350, loss is 5.497999238967895 and perplexity is 244.20285161118278
At time: 507.7584493160248 and batch: 400, loss is 5.547850704193115 and perplexity is 256.68527003095636
At time: 508.8302574157715 and batch: 450, loss is 5.511606225967407 and perplexity is 247.5484266168019
At time: 509.9023280143738 and batch: 500, loss is 5.533277368545532 and perplexity is 252.97163518412083
At time: 510.9741427898407 and batch: 550, loss is 5.506813669204712 and perplexity is 246.36487511497805
At time: 512.0466396808624 and batch: 600, loss is 5.459250497817993 and perplexity is 234.92128434960122
At time: 513.119505405426 and batch: 650, loss is 5.498601970672607 and perplexity is 244.3500847788216
At time: 514.1921977996826 and batch: 700, loss is 5.501287384033203 and perplexity is 245.00714760893646
At time: 515.2645137310028 and batch: 750, loss is 5.4793205833435055 and perplexity is 239.68380687118372
At time: 516.3372066020966 and batch: 800, loss is 5.448436546325683 and perplexity is 232.3945436253127
At time: 517.4091591835022 and batch: 850, loss is 5.434285306930542 and perplexity is 229.1290328120707
At time: 518.4815144538879 and batch: 900, loss is 5.462240591049194 and perplexity is 235.62477211466543
At time: 519.5537405014038 and batch: 950, loss is 5.443073673248291 and perplexity is 231.1515770988493
At time: 520.6258466243744 and batch: 1000, loss is 5.474941101074219 and perplexity is 238.63641108846116
At time: 521.6978833675385 and batch: 1050, loss is 5.445502738952637 and perplexity is 231.7137419585615
At time: 522.7728941440582 and batch: 1100, loss is 5.428375835418701 and perplexity is 227.7789942561436
At time: 523.8704152107239 and batch: 1150, loss is 5.440233221054077 and perplexity is 230.49593369717246
At time: 524.9420082569122 and batch: 1200, loss is 5.4201163387298585 and perplexity is 225.9054025209091
At time: 526.013498544693 and batch: 1250, loss is 5.447772827148437 and perplexity is 232.24035008628616
At time: 527.0849390029907 and batch: 1300, loss is 5.419897480010986 and perplexity is 225.8559665638695
At time: 528.1587524414062 and batch: 1350, loss is 5.407205591201782 and perplexity is 223.00754192992324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.127213134765625 and perplexity of 168.54674585098417
Finished 17 epochs...
Completing Train Step...
At time: 531.2756502628326 and batch: 50, loss is 5.489916839599609 and perplexity is 242.23706148929435
At time: 532.3711597919464 and batch: 100, loss is 5.493907136917114 and perplexity is 243.2055904601181
At time: 533.4429807662964 and batch: 150, loss is 5.435776815414429 and perplexity is 229.4710356951139
At time: 534.5154869556427 and batch: 200, loss is 5.440331382751465 and perplexity is 230.5185606797984
At time: 535.5881307125092 and batch: 250, loss is 5.476782741546631 and perplexity is 239.07629849420954
At time: 536.6603245735168 and batch: 300, loss is 5.470444707870484 and perplexity is 237.5658166619635
At time: 537.7321882247925 and batch: 350, loss is 5.481659832000733 and perplexity is 240.24514319120942
At time: 538.8040702342987 and batch: 400, loss is 5.531566200256347 and perplexity is 252.53912829550208
At time: 539.8765540122986 and batch: 450, loss is 5.495406303405762 and perplexity is 243.5704695701159
At time: 540.9483251571655 and batch: 500, loss is 5.517595291137695 and perplexity is 249.035458798086
At time: 542.0196268558502 and batch: 550, loss is 5.491161956787109 and perplexity is 242.5388628680554
At time: 543.0915644168854 and batch: 600, loss is 5.443952941894532 and perplexity is 231.35491081250095
At time: 544.1641049385071 and batch: 650, loss is 5.483067092895507 and perplexity is 240.58346878673757
At time: 545.2366790771484 and batch: 700, loss is 5.485972690582275 and perplexity is 241.28352410415644
At time: 546.3091628551483 and batch: 750, loss is 5.463866720199585 and perplexity is 236.0082401249099
At time: 547.3815715312958 and batch: 800, loss is 5.4328912734985355 and perplexity is 228.80984181324018
At time: 548.4545209407806 and batch: 850, loss is 5.417642011642456 and perplexity is 225.34712962396242
At time: 549.5264701843262 and batch: 900, loss is 5.446451663970947 and perplexity is 231.93372528272505
At time: 550.6233997344971 and batch: 950, loss is 5.427542562484741 and perplexity is 227.58927124180946
At time: 551.6952934265137 and batch: 1000, loss is 5.459352207183838 and perplexity is 234.9451792596034
At time: 552.769476890564 and batch: 1050, loss is 5.429268283843994 and perplexity is 227.9823659967789
At time: 553.8578090667725 and batch: 1100, loss is 5.411978559494019 and perplexity is 224.07449409537278
At time: 554.9321196079254 and batch: 1150, loss is 5.424212465286255 and perplexity is 226.83263737862268
At time: 556.0045742988586 and batch: 1200, loss is 5.404205694198608 and perplexity is 222.33954473555667
At time: 557.0781788825989 and batch: 1250, loss is 5.432512874603272 and perplexity is 228.72327680095793
At time: 558.1496803760529 and batch: 1300, loss is 5.404922561645508 and perplexity is 222.4989898610179
At time: 559.2222163677216 and batch: 1350, loss is 5.391998987197876 and perplexity is 219.64200857024557
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.115956624348958 and perplexity of 166.660135893769
Finished 18 epochs...
Completing Train Step...
At time: 562.3733270168304 and batch: 50, loss is 5.475208339691162 and perplexity is 238.70019247495787
At time: 563.4457066059113 and batch: 100, loss is 5.479035606384278 and perplexity is 239.6155122403857
At time: 564.5176339149475 and batch: 150, loss is 5.420385875701904 and perplexity is 225.9663005858447
At time: 565.5894341468811 and batch: 200, loss is 5.425091028213501 and perplexity is 227.03201169312942
At time: 566.6613721847534 and batch: 250, loss is 5.4623442649841305 and perplexity is 235.64920152828392
At time: 567.7340230941772 and batch: 300, loss is 5.455150012969971 and perplexity is 233.95996546637082
At time: 568.8062734603882 and batch: 350, loss is 5.4659398078918455 and perplexity is 236.49801339885016
At time: 569.8786914348602 and batch: 400, loss is 5.516277141571045 and perplexity is 248.7074090727918
At time: 570.9503538608551 and batch: 450, loss is 5.479882764816284 and perplexity is 239.81859054962533
At time: 572.0234754085541 and batch: 500, loss is 5.5026480579376225 and perplexity is 245.34074935120665
At time: 573.0953524112701 and batch: 550, loss is 5.476266498565674 and perplexity is 238.95290888544872
At time: 574.1685657501221 and batch: 600, loss is 5.429306201934814 and perplexity is 227.99101081673464
At time: 575.2426130771637 and batch: 650, loss is 5.468258113861084 and perplexity is 237.0469241807515
At time: 576.3167219161987 and batch: 700, loss is 5.4713232135772705 and perplexity is 237.7746112878452
At time: 577.4165754318237 and batch: 750, loss is 5.4490855693817135 and perplexity is 232.54542199869638
At time: 578.4904017448425 and batch: 800, loss is 5.418183631896973 and perplexity is 225.46921525270423
At time: 579.56471824646 and batch: 850, loss is 5.4018815326690675 and perplexity is 221.8233917629709
At time: 580.6381311416626 and batch: 900, loss is 5.431322755813599 and perplexity is 228.45123084721234
At time: 581.7125458717346 and batch: 950, loss is 5.412916059494019 and perplexity is 224.28466243460304
At time: 582.7861039638519 and batch: 1000, loss is 5.444412641525268 and perplexity is 231.46128902871058
At time: 583.8589856624603 and batch: 1050, loss is 5.413768119812012 and perplexity is 224.47584793462022
At time: 584.9329216480255 and batch: 1100, loss is 5.396385746002197 and perplexity is 220.60764153607215
At time: 586.0064990520477 and batch: 1150, loss is 5.408702564239502 and perplexity is 223.34162820408432
At time: 587.0799601078033 and batch: 1200, loss is 5.38899299621582 and perplexity is 218.9827580202214
At time: 588.1674997806549 and batch: 1250, loss is 5.418047323226928 and perplexity is 225.438483938357
At time: 589.2408535480499 and batch: 1300, loss is 5.3906196594238285 and perplexity is 219.33925909085923
At time: 590.3150429725647 and batch: 1350, loss is 5.377647886276245 and perplexity is 216.51241421340097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.104520263671875 and perplexity of 164.76500780867784
Finished 19 epochs...
Completing Train Step...
At time: 593.4740853309631 and batch: 50, loss is 5.461029605865479 and perplexity is 235.33960670710923
At time: 594.5452046394348 and batch: 100, loss is 5.464835443496704 and perplexity is 236.23697757919373
At time: 595.6170046329498 and batch: 150, loss is 5.405640811920166 and perplexity is 222.6588572271137
At time: 596.6885917186737 and batch: 200, loss is 5.410371208190918 and perplexity is 223.71461696726334
At time: 597.7604191303253 and batch: 250, loss is 5.447821998596192 and perplexity is 232.25176996129048
At time: 598.8318793773651 and batch: 300, loss is 5.4402821826934815 and perplexity is 230.50721943224406
At time: 599.9037566184998 and batch: 350, loss is 5.45090069770813 and perplexity is 232.9679050958674
At time: 600.9753472805023 and batch: 400, loss is 5.5010097694396975 and perplexity is 244.93913948970703
At time: 602.0473301410675 and batch: 450, loss is 5.464942560195923 and perplexity is 236.26228385980392
At time: 603.1338193416595 and batch: 500, loss is 5.488328418731689 and perplexity is 241.8525925159485
At time: 604.2073979377747 and batch: 550, loss is 5.461968221664429 and perplexity is 235.56060387957717
At time: 605.303453207016 and batch: 600, loss is 5.415217590332031 and perplexity is 224.8014549805575
At time: 606.3742392063141 and batch: 650, loss is 5.454013252258301 and perplexity is 233.6941600767104
At time: 607.4463722705841 and batch: 700, loss is 5.457315874099732 and perplexity is 234.46723940564837
At time: 608.5258107185364 and batch: 750, loss is 5.434907474517822 and perplexity is 229.27163382585556
At time: 609.5990023612976 and batch: 800, loss is 5.4040334510803225 and perplexity is 222.3012515770144
At time: 610.6726176738739 and batch: 850, loss is 5.386704063415527 and perplexity is 218.48209441395568
At time: 611.7450008392334 and batch: 900, loss is 5.416844177246094 and perplexity is 225.16741163495672
At time: 612.8161864280701 and batch: 950, loss is 5.398319234848023 and perplexity is 221.03459657367745
At time: 613.8909521102905 and batch: 1000, loss is 5.4300927066802975 and perplexity is 228.17039736360755
At time: 614.9693651199341 and batch: 1050, loss is 5.398879728317261 and perplexity is 221.15851974735318
At time: 616.0467956066132 and batch: 1100, loss is 5.3814795780181885 and perplexity is 217.3436144776012
At time: 617.1232345104218 and batch: 1150, loss is 5.393956537246704 and perplexity is 220.07238990391207
At time: 618.1987278461456 and batch: 1200, loss is 5.374444942474366 and perplexity is 215.8200465175841
At time: 619.2729177474976 and batch: 1250, loss is 5.4040165042877195 and perplexity is 222.29748431573012
At time: 620.349360704422 and batch: 1300, loss is 5.376935939788819 and perplexity is 216.35832381918368
At time: 621.4253265857697 and batch: 1350, loss is 5.363641729354859 and perplexity is 213.5010454450589
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09419921875 and perplexity of 163.07320635900214
Finished 20 epochs...
Completing Train Step...
At time: 624.593902349472 and batch: 50, loss is 5.447333745956421 and perplexity is 232.13840010033448
At time: 625.6928675174713 and batch: 100, loss is 5.451160316467285 and perplexity is 233.0283957862305
At time: 626.7674403190613 and batch: 150, loss is 5.391474876403809 and perplexity is 219.52692198441858
At time: 627.8427991867065 and batch: 200, loss is 5.396471490859986 and perplexity is 220.62655831791946
At time: 628.9176580905914 and batch: 250, loss is 5.433922758102417 and perplexity is 229.04597740646497
At time: 629.9932882785797 and batch: 300, loss is 5.4259890365600585 and perplexity is 227.23597990343623
At time: 631.0678017139435 and batch: 350, loss is 5.436426267623902 and perplexity is 229.62011457081869
At time: 632.1672677993774 and batch: 400, loss is 5.486657209396363 and perplexity is 241.44874375746426
At time: 633.2418429851532 and batch: 450, loss is 5.450569543838501 and perplexity is 232.89076964515192
At time: 634.3174924850464 and batch: 500, loss is 5.474594020843506 and perplexity is 238.55359947981162
At time: 635.392181634903 and batch: 550, loss is 5.448285179138184 and perplexity is 232.35936937903438
At time: 636.467666387558 and batch: 600, loss is 5.401688871383667 and perplexity is 221.78065909977897
At time: 637.5418701171875 and batch: 650, loss is 5.440372323989868 and perplexity is 230.52799858834604
At time: 638.6168444156647 and batch: 700, loss is 5.443884868621826 and perplexity is 231.3391622625991
At time: 639.6915168762207 and batch: 750, loss is 5.421211948394776 and perplexity is 226.1530422967625
At time: 640.7714240550995 and batch: 800, loss is 5.39047233581543 and perplexity is 219.30694761992612
At time: 641.8515219688416 and batch: 850, loss is 5.372229652404785 and perplexity is 215.34247169041197
At time: 642.9283437728882 and batch: 900, loss is 5.40293890953064 and perplexity is 222.0580667328534
At time: 644.0017421245575 and batch: 950, loss is 5.384517698287964 and perplexity is 218.00493459460307
At time: 645.0765902996063 and batch: 1000, loss is 5.4163071727752685 and perplexity is 225.04652818860518
At time: 646.1505591869354 and batch: 1050, loss is 5.384588117599487 and perplexity is 218.02028689254868
At time: 647.2292726039886 and batch: 1100, loss is 5.367146482467652 and perplexity is 214.25062667997312
At time: 648.3114910125732 and batch: 1150, loss is 5.379606533050537 and perplexity is 216.93690112935374
At time: 649.3860671520233 and batch: 1200, loss is 5.360323667526245 and perplexity is 212.79380975054067
At time: 650.4639418125153 and batch: 1250, loss is 5.390082454681396 and perplexity is 219.22146064444902
At time: 651.5428414344788 and batch: 1300, loss is 5.363717546463013 and perplexity is 213.51723309055495
At time: 652.6199240684509 and batch: 1350, loss is 5.3502059650421145 and perplexity is 210.65168028109127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.084215087890625 and perplexity of 161.45316294729176
Finished 21 epochs...
Completing Train Step...
At time: 655.7746734619141 and batch: 50, loss is 5.434142894744873 and perplexity is 229.0964043691068
At time: 656.8746802806854 and batch: 100, loss is 5.4380216217041015 and perplexity is 229.98673232229982
At time: 657.9481899738312 and batch: 150, loss is 5.377764158248901 and perplexity is 216.5375900024971
At time: 659.0476005077362 and batch: 200, loss is 5.383043746948243 and perplexity is 217.68384262429325
At time: 660.1205773353577 and batch: 250, loss is 5.420637617111206 and perplexity is 226.02319282157418
At time: 661.194221496582 and batch: 300, loss is 5.412261590957642 and perplexity is 224.13792320319044
At time: 662.2677655220032 and batch: 350, loss is 5.422399950027466 and perplexity is 226.4218721337739
At time: 663.3427886962891 and batch: 400, loss is 5.472699232101441 and perplexity is 238.10201876527142
At time: 664.4181816577911 and batch: 450, loss is 5.436726779937744 and perplexity is 229.6891286120183
At time: 665.4941861629486 and batch: 500, loss is 5.4613645648956295 and perplexity is 235.418449037266
At time: 666.5707297325134 and batch: 550, loss is 5.435104484558106 and perplexity is 229.3168070893185
At time: 667.6459636688232 and batch: 600, loss is 5.38866660118103 and perplexity is 218.91129479855377
At time: 668.7202408313751 and batch: 650, loss is 5.427292919158935 and perplexity is 227.53246219051417
At time: 669.796329498291 and batch: 700, loss is 5.430978174209595 and perplexity is 228.3725243168403
At time: 670.8711786270142 and batch: 750, loss is 5.408012466430664 and perplexity is 223.18755380515555
At time: 671.9602146148682 and batch: 800, loss is 5.377012414932251 and perplexity is 216.37487048572677
At time: 673.040892124176 and batch: 850, loss is 5.358142013549805 and perplexity is 212.3300733294739
At time: 674.1254830360413 and batch: 900, loss is 5.389561891555786 and perplexity is 219.10737173351157
At time: 675.201502084732 and batch: 950, loss is 5.371246223449707 and perplexity is 215.13080176671883
At time: 676.2759673595428 and batch: 1000, loss is 5.403139810562134 and perplexity is 222.1026829090795
At time: 677.3503255844116 and batch: 1050, loss is 5.370876312255859 and perplexity is 215.0512371918246
At time: 678.4244253635406 and batch: 1100, loss is 5.35332540512085 and perplexity is 211.3098215576583
At time: 679.4986972808838 and batch: 1150, loss is 5.365839204788208 and perplexity is 213.97072461263224
At time: 680.5714809894562 and batch: 1200, loss is 5.346822328567505 and perplexity is 209.94011608842374
At time: 681.6458559036255 and batch: 1250, loss is 5.37717267036438 and perplexity is 216.40954851269518
At time: 682.7350199222565 and batch: 1300, loss is 5.351025657653809 and perplexity is 210.82442069440694
At time: 683.8165209293365 and batch: 1350, loss is 5.337197122573852 and perplexity is 207.92909300629648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.074312337239584 and perplexity of 159.86222287542245
Finished 22 epochs...
Completing Train Step...
At time: 687.0423142910004 and batch: 50, loss is 5.421380910873413 and perplexity is 226.19125690366684
At time: 688.1242325305939 and batch: 100, loss is 5.4250623226165775 and perplexity is 227.0254946972506
At time: 689.198762178421 and batch: 150, loss is 5.36450234413147 and perplexity is 213.68486668788407
At time: 690.2711963653564 and batch: 200, loss is 5.370163373947143 and perplexity is 214.89797356674035
At time: 691.3469383716583 and batch: 250, loss is 5.407777996063232 and perplexity is 223.13522907194803
At time: 692.4298074245453 and batch: 300, loss is 5.398972778320313 and perplexity is 221.1790995057491
At time: 693.5067625045776 and batch: 350, loss is 5.408907375335693 and perplexity is 223.38737573242273
At time: 694.582480430603 and batch: 400, loss is 5.459243946075439 and perplexity is 234.91974521086777
At time: 695.6650459766388 and batch: 450, loss is 5.423327674865723 and perplexity is 226.63202679625428
At time: 696.7388203144073 and batch: 500, loss is 5.44862398147583 and perplexity is 232.43810661398047
At time: 697.8130390644073 and batch: 550, loss is 5.422432870864868 and perplexity is 226.4293262541079
At time: 698.8971507549286 and batch: 600, loss is 5.376126232147217 and perplexity is 216.18320773704568
At time: 699.9860351085663 and batch: 650, loss is 5.414552001953125 and perplexity is 224.6518795279247
At time: 701.0597767829895 and batch: 700, loss is 5.418484439849854 and perplexity is 225.53704838764375
At time: 702.1340794563293 and batch: 750, loss is 5.395269289016723 and perplexity is 220.3614800335643
At time: 703.2074489593506 and batch: 800, loss is 5.364077777862549 and perplexity is 213.59416255762903
At time: 704.2810411453247 and batch: 850, loss is 5.344655961990356 and perplexity is 209.48580112178706
At time: 705.3757815361023 and batch: 900, loss is 5.376642513275146 and perplexity is 216.29484786374098
At time: 706.4567739963531 and batch: 950, loss is 5.358388805389405 and perplexity is 212.38248112551545
At time: 707.5359704494476 and batch: 1000, loss is 5.390399961471558 and perplexity is 219.29107599784166
At time: 708.6139388084412 and batch: 1050, loss is 5.357677335739136 and perplexity is 212.23143117604485
At time: 709.6921508312225 and batch: 1100, loss is 5.3400055694580075 and perplexity is 208.5138715951142
At time: 710.7684836387634 and batch: 1150, loss is 5.352301397323608 and perplexity is 211.09354940383395
At time: 711.8432636260986 and batch: 1200, loss is 5.333737010955811 and perplexity is 207.2108784037627
At time: 712.9183721542358 and batch: 1250, loss is 5.364604835510254 and perplexity is 213.706768666859
At time: 713.992927312851 and batch: 1300, loss is 5.33868935585022 and perplexity is 208.23960333731043
At time: 715.0671632289886 and batch: 1350, loss is 5.324549627304077 and perplexity is 205.31587097664897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065266927083333 and perplexity of 158.422723745952
Finished 23 epochs...
Completing Train Step...
At time: 718.2373778820038 and batch: 50, loss is 5.409010505676269 and perplexity is 223.4104149365624
At time: 719.311429977417 and batch: 100, loss is 5.412603025436401 and perplexity is 224.21446468437628
At time: 720.3855700492859 and batch: 150, loss is 5.351789388656616 and perplexity is 210.9854953416618
At time: 721.4594724178314 and batch: 200, loss is 5.357709836959839 and perplexity is 212.23832906872403
At time: 722.5347783565521 and batch: 250, loss is 5.3953719806671145 and perplexity is 220.38411047959065
At time: 723.6068766117096 and batch: 300, loss is 5.386152744293213 and perplexity is 218.36167425544025
At time: 724.6805698871613 and batch: 350, loss is 5.395869636535645 and perplexity is 220.49381322034392
At time: 725.7552235126495 and batch: 400, loss is 5.4462164115905765 and perplexity is 231.879168739294
At time: 726.8297717571259 and batch: 450, loss is 5.410403242111206 and perplexity is 223.7217835382566
At time: 727.9042088985443 and batch: 500, loss is 5.436345510482788 and perplexity is 229.60157185556213
At time: 728.9778547286987 and batch: 550, loss is 5.410214481353759 and perplexity is 223.6795576303611
At time: 730.051287651062 and batch: 600, loss is 5.363945255279541 and perplexity is 213.5658583830041
At time: 731.1254711151123 and batch: 650, loss is 5.402288732528686 and perplexity is 221.9137366099131
At time: 732.1997172832489 and batch: 700, loss is 5.406449632644653 and perplexity is 222.83902117567564
At time: 733.2754709720612 and batch: 750, loss is 5.382842721939087 and perplexity is 217.64008712595881
At time: 734.3489458560944 and batch: 800, loss is 5.351691570281982 and perplexity is 210.96485809280364
At time: 735.4222891330719 and batch: 850, loss is 5.33144642829895 and perplexity is 206.73678793836396
At time: 736.4964919090271 and batch: 900, loss is 5.36417709350586 and perplexity is 213.61537685272918
At time: 737.5715668201447 and batch: 950, loss is 5.345899677276611 and perplexity is 209.7465039013064
At time: 738.6461443901062 and batch: 1000, loss is 5.3780996608734135 and perplexity is 216.61025112056487
At time: 739.720401763916 and batch: 1050, loss is 5.344955158233643 and perplexity is 209.54848786385583
At time: 740.8221197128296 and batch: 1100, loss is 5.3270649814605715 and perplexity is 205.83296316846418
At time: 741.8951315879822 and batch: 1150, loss is 5.339471759796143 and perplexity is 208.40259457883957
At time: 742.9698331356049 and batch: 1200, loss is 5.321089124679565 and perplexity is 204.6066027862924
At time: 744.0434904098511 and batch: 1250, loss is 5.3525308322906495 and perplexity is 211.1419872018338
At time: 745.1179811954498 and batch: 1300, loss is 5.326774578094483 and perplexity is 205.77319726163833
At time: 746.1921558380127 and batch: 1350, loss is 5.312249727249146 and perplexity is 202.80597366989184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.056493733723959 and perplexity of 157.03892958065157
Finished 24 epochs...
Completing Train Step...
At time: 749.3469030857086 and batch: 50, loss is 5.397061986923218 and perplexity is 220.75687590427484
At time: 750.4464144706726 and batch: 100, loss is 5.400487108230591 and perplexity is 221.51429136313163
At time: 751.5207374095917 and batch: 150, loss is 5.339459524154663 and perplexity is 208.40004465500888
At time: 752.595995426178 and batch: 200, loss is 5.3456455326080325 and perplexity is 209.69320471872535
At time: 753.6684494018555 and batch: 250, loss is 5.383316526412964 and perplexity is 217.7432304058781
At time: 754.742753982544 and batch: 300, loss is 5.3737326335906985 and perplexity is 215.66637071999182
At time: 755.8166801929474 and batch: 350, loss is 5.38320629119873 and perplexity is 217.71922875716425
At time: 756.8920137882233 and batch: 400, loss is 5.433532247543335 and perplexity is 228.95654999608286
At time: 757.966160774231 and batch: 450, loss is 5.398021278381347 and perplexity is 220.96874769680582
At time: 759.040280342102 and batch: 500, loss is 5.424504413604736 and perplexity is 226.898870453529
At time: 760.1124358177185 and batch: 550, loss is 5.398395252227783 and perplexity is 221.05139968320154
At time: 761.1957614421844 and batch: 600, loss is 5.35212347984314 and perplexity is 211.05599551222684
At time: 762.2698090076447 and batch: 650, loss is 5.390328102111816 and perplexity is 219.2753184476939
At time: 763.3528439998627 and batch: 700, loss is 5.3947239685058594 and perplexity is 220.2413451576807
At time: 764.4241020679474 and batch: 750, loss is 5.3706914329528805 and perplexity is 215.01148234402538
At time: 765.4955792427063 and batch: 800, loss is 5.339656705856323 and perplexity is 208.4411413820681
At time: 766.5665338039398 and batch: 850, loss is 5.318540983200073 and perplexity is 204.0858999087997
At time: 767.6731808185577 and batch: 900, loss is 5.352159156799316 and perplexity is 211.06352548205183
At time: 768.7495512962341 and batch: 950, loss is 5.333855409622192 and perplexity is 207.2354133478491
At time: 769.8209111690521 and batch: 1000, loss is 5.366202049255371 and perplexity is 214.04837679317285
At time: 770.8928062915802 and batch: 1050, loss is 5.332654113769531 and perplexity is 206.986611777338
At time: 771.9645113945007 and batch: 1100, loss is 5.314536190032959 and perplexity is 203.27021251118973
At time: 773.0365371704102 and batch: 1150, loss is 5.327067852020264 and perplexity is 205.8335540251196
At time: 774.1187162399292 and batch: 1200, loss is 5.308717193603516 and perplexity is 202.09081864265522
At time: 775.2059733867645 and batch: 1250, loss is 5.340792274475097 and perplexity is 208.67797504607128
At time: 776.2875154018402 and batch: 1300, loss is 5.315277853012085 and perplexity is 203.42102642220257
At time: 777.3654415607452 and batch: 1350, loss is 5.300419301986694 and perplexity is 200.42082921070735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.048681640625 and perplexity of 155.8169063371583
Finished 25 epochs...
Completing Train Step...
At time: 780.5436508655548 and batch: 50, loss is 5.385520324707032 and perplexity is 218.22362171393658
At time: 781.6392450332642 and batch: 100, loss is 5.388796367645264 and perplexity is 218.93970398650066
At time: 782.7092685699463 and batch: 150, loss is 5.327638425827026 and perplexity is 205.95103077098918
At time: 783.7794795036316 and batch: 200, loss is 5.333988265991211 and perplexity is 207.2629477214166
At time: 784.84943318367 and batch: 250, loss is 5.371533880233764 and perplexity is 215.19269450281269
At time: 785.9196631908417 and batch: 300, loss is 5.3616657543182376 and perplexity is 213.079589239568
At time: 786.9892601966858 and batch: 350, loss is 5.370980806350708 and perplexity is 215.07370995031596
At time: 788.0688121318817 and batch: 400, loss is 5.421244916915893 and perplexity is 226.16049835102012
At time: 789.1395921707153 and batch: 450, loss is 5.385794897079467 and perplexity is 218.2835481181631
At time: 790.2107241153717 and batch: 500, loss is 5.4130461883544925 and perplexity is 224.31385024119422
At time: 791.2815380096436 and batch: 550, loss is 5.3869319248199465 and perplexity is 218.53188372314492
At time: 792.363942861557 and batch: 600, loss is 5.340646896362305 and perplexity is 208.64764004095406
At time: 793.4547531604767 and batch: 650, loss is 5.37873387336731 and perplexity is 216.74767162042428
At time: 794.5448224544525 and batch: 700, loss is 5.383441295623779 and perplexity is 217.77039975180995
At time: 795.6527836322784 and batch: 750, loss is 5.358908309936523 and perplexity is 212.49284345457224
At time: 796.7260768413544 and batch: 800, loss is 5.327814693450928 and perplexity is 205.98733646948884
At time: 797.7967994213104 and batch: 850, loss is 5.306415710449219 and perplexity is 201.62624483736826
At time: 798.8798303604126 and batch: 900, loss is 5.34053713798523 and perplexity is 208.62474047133543
At time: 799.9513306617737 and batch: 950, loss is 5.322116918563843 and perplexity is 204.81700430749575
At time: 801.0224320888519 and batch: 1000, loss is 5.354685316085815 and perplexity is 211.5973795833391
At time: 802.0932557582855 and batch: 1050, loss is 5.320757246017456 and perplexity is 204.5387094874927
At time: 803.1640503406525 and batch: 1100, loss is 5.302393455505371 and perplexity is 200.816881501294
At time: 804.234992980957 and batch: 1150, loss is 5.314872436523437 and perplexity is 203.33857289909164
At time: 805.3166906833649 and batch: 1200, loss is 5.296671953201294 and perplexity is 199.6711879207284
At time: 806.3930907249451 and batch: 1250, loss is 5.329506235122681 and perplexity is 206.33606749636007
At time: 807.4713590145111 and batch: 1300, loss is 5.304080181121826 and perplexity is 201.15589030658236
At time: 808.5468156337738 and batch: 1350, loss is 5.28887469291687 and perplexity is 198.12035368351235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.039484049479166 and perplexity of 154.39033669799002
Finished 26 epochs...
Completing Train Step...
At time: 811.71817278862 and batch: 50, loss is 5.374523029327393 and perplexity is 215.83689988384145
At time: 812.791181564331 and batch: 100, loss is 5.377624616622925 and perplexity is 216.50737610320058
At time: 813.8655614852905 and batch: 150, loss is 5.316044702529907 and perplexity is 203.57707956522066
At time: 814.9407651424408 and batch: 200, loss is 5.322634887695313 and perplexity is 204.92312067345557
At time: 816.0165212154388 and batch: 250, loss is 5.360106954574585 and perplexity is 212.74769957245144
At time: 817.0912084579468 and batch: 300, loss is 5.349891538619995 and perplexity is 210.585456238787
At time: 818.1662774085999 and batch: 350, loss is 5.3590475273132325 and perplexity is 212.52242821011575
At time: 819.2412388324738 and batch: 400, loss is 5.409207935333252 and perplexity is 223.4545271325343
At time: 820.3172874450684 and batch: 450, loss is 5.3739414882659915 and perplexity is 215.71141835386086
At time: 821.4028763771057 and batch: 500, loss is 5.401878423690796 and perplexity is 221.8227021199379
At time: 822.5076751708984 and batch: 550, loss is 5.3757958984375 and perplexity is 216.1118069297513
At time: 823.5862412452698 and batch: 600, loss is 5.329470357894897 and perplexity is 206.32866486306037
At time: 824.6616740226746 and batch: 650, loss is 5.367448682785034 and perplexity is 214.31538307156347
At time: 825.7367897033691 and batch: 700, loss is 5.3723248100280765 and perplexity is 215.36296414320276
At time: 826.8112077713013 and batch: 750, loss is 5.347350902557373 and perplexity is 210.05111430601903
At time: 827.886492729187 and batch: 800, loss is 5.316351661682129 and perplexity is 203.63957900487256
At time: 828.9609973430634 and batch: 850, loss is 5.2946068286895756 and perplexity is 199.2592675361054
At time: 830.0371823310852 and batch: 900, loss is 5.32925482749939 and perplexity is 206.28419955630253
At time: 831.112785577774 and batch: 950, loss is 5.310647296905517 and perplexity is 202.48125146565545
At time: 832.1866357326508 and batch: 1000, loss is 5.343462896347046 and perplexity is 209.2360198420673
At time: 833.2608880996704 and batch: 1050, loss is 5.309186887741089 and perplexity is 202.1857618108083
At time: 834.3485317230225 and batch: 1100, loss is 5.2905277919769285 and perplexity is 198.44813710855536
At time: 835.4336018562317 and batch: 1150, loss is 5.303070468902588 and perplexity is 200.95288325276695
At time: 836.5183970928192 and batch: 1200, loss is 5.284917106628418 and perplexity is 197.33782477251768
At time: 837.595461845398 and batch: 1250, loss is 5.318518381118775 and perplexity is 204.0812871948268
At time: 838.6684296131134 and batch: 1300, loss is 5.293206129074097 and perplexity is 198.98036053475212
At time: 839.7428321838379 and batch: 1350, loss is 5.277657127380371 and perplexity is 195.9103442691115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.031851399739583 and perplexity of 153.21641510011094
Finished 27 epochs...
Completing Train Step...
At time: 842.9534797668457 and batch: 50, loss is 5.363810424804687 and perplexity is 213.5370651380529
At time: 844.0293700695038 and batch: 100, loss is 5.366394653320312 and perplexity is 214.0896073510964
At time: 845.1055099964142 and batch: 150, loss is 5.304608612060547 and perplexity is 201.26221539278475
At time: 846.1812973022461 and batch: 200, loss is 5.311740055084228 and perplexity is 202.70263544677823
At time: 847.2611885070801 and batch: 250, loss is 5.348964433670044 and perplexity is 210.39031189354216
At time: 848.3406231403351 and batch: 300, loss is 5.33848611831665 and perplexity is 208.19728553436522
At time: 849.4426136016846 and batch: 350, loss is 5.347524900436401 and perplexity is 210.08766593425634
At time: 850.5191547870636 and batch: 400, loss is 5.397437696456909 and perplexity is 220.83983194989278
At time: 851.5948383808136 and batch: 450, loss is 5.36242678642273 and perplexity is 213.24181136808576
At time: 852.6712543964386 and batch: 500, loss is 5.391045732498169 and perplexity is 219.43273355536576
At time: 853.7500505447388 and batch: 550, loss is 5.36500322341919 and perplexity is 213.7919238208192
At time: 854.8261618614197 and batch: 600, loss is 5.318599109649658 and perplexity is 204.09776304234936
At time: 855.9014501571655 and batch: 650, loss is 5.356434469223022 and perplexity is 211.9678196874493
At time: 856.9760904312134 and batch: 700, loss is 5.361585645675659 and perplexity is 213.06252040660257
At time: 858.0506777763367 and batch: 750, loss is 5.336113967895508 and perplexity is 207.703995566123
At time: 859.1249945163727 and batch: 800, loss is 5.305208740234375 and perplexity is 201.38303476849842
At time: 860.1997232437134 and batch: 850, loss is 5.2827927780151365 and perplexity is 196.91905934004862
At time: 861.2727227210999 and batch: 900, loss is 5.318226871490478 and perplexity is 204.0218042050077
At time: 862.3462572097778 and batch: 950, loss is 5.299658241271973 and perplexity is 200.26835481967737
At time: 863.4202833175659 and batch: 1000, loss is 5.332512006759644 and perplexity is 206.95719961873803
At time: 864.4964923858643 and batch: 1050, loss is 5.297918453216552 and perplexity is 199.92023324477196
At time: 865.5727016925812 and batch: 1100, loss is 5.2788847541809085 and perplexity is 196.15099674372928
At time: 866.6484005451202 and batch: 1150, loss is 5.291438903808594 and perplexity is 198.62902794762525
At time: 867.7255165576935 and batch: 1200, loss is 5.273417100906372 and perplexity is 195.08143775748485
At time: 868.8012733459473 and batch: 1250, loss is 5.307767419815064 and perplexity is 201.89896920142868
At time: 869.8779845237732 and batch: 1300, loss is 5.282622890472412 and perplexity is 196.88560808649785
At time: 870.9533338546753 and batch: 1350, loss is 5.2667334938049315 and perplexity is 193.78193758646648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.023095703125 and perplexity of 151.88075450547524
Finished 28 epochs...
Completing Train Step...
At time: 874.1220035552979 and batch: 50, loss is 5.353120651245117 and perplexity is 211.26655948190398
At time: 875.2231597900391 and batch: 100, loss is 5.355582666397095 and perplexity is 211.78734177634362
At time: 876.2993810176849 and batch: 150, loss is 5.293544721603394 and perplexity is 199.0477452056353
At time: 877.4038324356079 and batch: 200, loss is 5.301028556823731 and perplexity is 200.54297377515198
At time: 878.4786520004272 and batch: 250, loss is 5.338160781860352 and perplexity is 208.1295623842807
At time: 879.5536851882935 and batch: 300, loss is 5.327416315078735 and perplexity is 205.90529191316725
At time: 880.6294100284576 and batch: 350, loss is 5.336270971298218 and perplexity is 207.73660836027614
At time: 881.7057778835297 and batch: 400, loss is 5.385966911315918 and perplexity is 218.32109922559226
At time: 882.7821233272552 and batch: 450, loss is 5.351242485046387 and perplexity is 210.87013816005827
At time: 883.8576745986938 and batch: 500, loss is 5.380480499267578 and perplexity is 217.1265795263526
At time: 884.9330701828003 and batch: 550, loss is 5.35448522567749 and perplexity is 211.55504521274977
At time: 886.0095615386963 and batch: 600, loss is 5.308021631240845 and perplexity is 201.95030075050977
At time: 887.0862574577332 and batch: 650, loss is 5.346223392486572 and perplexity is 209.8144130258707
At time: 888.161600112915 and batch: 700, loss is 5.351108045578003 and perplexity is 210.84179079633086
At time: 889.2361218929291 and batch: 750, loss is 5.325184192657471 and perplexity is 205.44619866121582
At time: 890.3110065460205 and batch: 800, loss is 5.294320678710937 and perplexity is 199.20225765803315
At time: 891.3854835033417 and batch: 850, loss is 5.271463556289673 and perplexity is 194.70070947086532
At time: 892.4603688716888 and batch: 900, loss is 5.307495231628418 and perplexity is 201.8440221654224
At time: 893.5333211421967 and batch: 950, loss is 5.28880597114563 and perplexity is 198.10673896970735
At time: 894.6076281070709 and batch: 1000, loss is 5.321903047561645 and perplexity is 204.7732045734308
At time: 895.6827566623688 and batch: 1050, loss is 5.286968564987182 and perplexity is 197.74307063302908
At time: 896.7587814331055 and batch: 1100, loss is 5.267542381286621 and perplexity is 193.93874878271433
At time: 897.8351452350616 and batch: 1150, loss is 5.280091323852539 and perplexity is 196.38780942422994
At time: 898.9102203845978 and batch: 1200, loss is 5.262202625274658 and perplexity is 192.90592315545368
At time: 899.9854953289032 and batch: 1250, loss is 5.29736743927002 and perplexity is 199.81010475201415
At time: 901.060150384903 and batch: 1300, loss is 5.27216591835022 and perplexity is 194.8375078977481
At time: 902.1335217952728 and batch: 1350, loss is 5.255987234115601 and perplexity is 191.7106557612117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.015751546223958 and perplexity of 150.76940437420973
Finished 29 epochs...
Completing Train Step...
At time: 905.2922801971436 and batch: 50, loss is 5.342609958648682 and perplexity is 209.0576306411404
At time: 906.3900516033173 and batch: 100, loss is 5.345015439987183 and perplexity is 209.5611201949016
At time: 907.4632132053375 and batch: 150, loss is 5.282595090866089 and perplexity is 196.88013482017993
At time: 908.5362377166748 and batch: 200, loss is 5.290673141479492 and perplexity is 198.47698354292544
At time: 909.6099555492401 and batch: 250, loss is 5.32748345375061 and perplexity is 205.91911658507829
At time: 910.6833913326263 and batch: 300, loss is 5.316665687561035 and perplexity is 203.7035371443796
At time: 911.75559258461 and batch: 350, loss is 5.325266609191894 and perplexity is 205.4631315226843
At time: 912.831182718277 and batch: 400, loss is 5.374780883789063 and perplexity is 215.89256156746782
At time: 913.9072225093842 and batch: 450, loss is 5.34031400680542 and perplexity is 208.57819497992477
At time: 914.9832067489624 and batch: 500, loss is 5.370191421508789 and perplexity is 214.90400101542872
At time: 916.0582005977631 and batch: 550, loss is 5.34420090675354 and perplexity is 209.39049519732254
At time: 917.1332528591156 and batch: 600, loss is 5.297715463638306 and perplexity is 199.87965563949746
At time: 918.2087032794952 and batch: 650, loss is 5.335793981552124 and perplexity is 207.63754375647835
At time: 919.2850861549377 and batch: 700, loss is 5.340864400863648 and perplexity is 208.69302677758841
At time: 920.360499382019 and batch: 750, loss is 5.314532508850098 and perplexity is 203.2694642377446
At time: 921.4355030059814 and batch: 800, loss is 5.283681116104126 and perplexity is 197.0940677627233
At time: 922.5110816955566 and batch: 850, loss is 5.260416336059571 and perplexity is 192.56164496714638
At time: 923.5860197544098 and batch: 900, loss is 5.2970183563232425 and perplexity is 199.7403666247551
At time: 924.6614542007446 and batch: 950, loss is 5.278360891342163 and perplexity is 196.04826743613503
At time: 925.7477602958679 and batch: 1000, loss is 5.311477422714233 and perplexity is 202.64940616339902
At time: 926.8225162029266 and batch: 1050, loss is 5.27637508392334 and perplexity is 195.65933962788566
At time: 927.8985390663147 and batch: 1100, loss is 5.256472787857056 and perplexity is 191.80376419013703
At time: 928.9714298248291 and batch: 1150, loss is 5.26906346321106 and perplexity is 194.23396997882776
At time: 930.0427753925323 and batch: 1200, loss is 5.251229219436645 and perplexity is 190.80066024974755
At time: 931.1406803131104 and batch: 1250, loss is 5.287146158218384 and perplexity is 197.7781915824197
At time: 932.211864233017 and batch: 1300, loss is 5.262034254074097 and perplexity is 192.87344608775476
At time: 933.2837843894958 and batch: 1350, loss is 5.245484685897827 and perplexity is 189.7077416170786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.008330891927083 and perplexity of 149.65473763907718
Finished 30 epochs...
Completing Train Step...
At time: 936.4302833080292 and batch: 50, loss is 5.332194471359253 and perplexity is 206.89149381400497
At time: 937.5094957351685 and batch: 100, loss is 5.334703989028931 and perplexity is 207.41134368683737
At time: 938.5874803066254 and batch: 150, loss is 5.2720847415924075 and perplexity is 194.82169226249636
At time: 939.671924829483 and batch: 200, loss is 5.280433721542359 and perplexity is 196.4550636696776
At time: 940.7515778541565 and batch: 250, loss is 5.3173669338226315 and perplexity is 203.84643358521777
At time: 941.8303246498108 and batch: 300, loss is 5.306217374801636 and perplexity is 201.5862591309553
At time: 942.9046764373779 and batch: 350, loss is 5.3145443630218505 and perplexity is 203.27187384316764
At time: 943.9797689914703 and batch: 400, loss is 5.363869791030884 and perplexity is 213.54974240406017
At time: 945.0541503429413 and batch: 450, loss is 5.329707469940185 and perplexity is 206.37759367536373
At time: 946.1289203166962 and batch: 500, loss is 5.360232095718384 and perplexity is 212.77432472883314
At time: 947.2031602859497 and batch: 550, loss is 5.334118747711182 and perplexity is 207.2899935117738
At time: 948.2772071361542 and batch: 600, loss is 5.287691345214844 and perplexity is 197.88604707868933
At time: 949.3516054153442 and batch: 650, loss is 5.325650148391723 and perplexity is 205.54194980172653
At time: 950.436993598938 and batch: 700, loss is 5.330871410369873 and perplexity is 206.61794475045622
At time: 951.5116972923279 and batch: 750, loss is 5.304177541732788 and perplexity is 201.17547592037937
At time: 952.5915479660034 and batch: 800, loss is 5.273299961090088 and perplexity is 195.05858729208126
At time: 953.6650443077087 and batch: 850, loss is 5.249727745056152 and perplexity is 190.51439291191892
At time: 954.7507877349854 and batch: 900, loss is 5.286765089035034 and perplexity is 197.70283876669885
At time: 955.8299331665039 and batch: 950, loss is 5.267836980819702 and perplexity is 193.99589146424245
At time: 956.9064526557922 and batch: 1000, loss is 5.30140025138855 and perplexity is 200.61752836342617
At time: 957.9798610210419 and batch: 1050, loss is 5.2658420753479005 and perplexity is 193.60927375995718
At time: 959.0784382820129 and batch: 1100, loss is 5.24567343711853 and perplexity is 189.74355256445935
At time: 960.1497151851654 and batch: 1150, loss is 5.2583456802368165 and perplexity is 192.1633286061211
At time: 961.2209622859955 and batch: 1200, loss is 5.2405181312561036 and perplexity is 188.76788361237678
At time: 962.2914569377899 and batch: 1250, loss is 5.2770883655548095 and perplexity is 195.79894962557202
At time: 963.3631258010864 and batch: 1300, loss is 5.252102928161621 and perplexity is 190.96743729801068
At time: 964.4347648620605 and batch: 1350, loss is 5.235199317932129 and perplexity is 187.7665278507407
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.001285400390625 and perplexity of 148.6040520959414
Finished 31 epochs...
Completing Train Step...
At time: 967.576474905014 and batch: 50, loss is 5.322278184890747 and perplexity is 204.8500370569314
At time: 968.6600518226624 and batch: 100, loss is 5.324587306976318 and perplexity is 205.32360735712444
At time: 969.73393201828 and batch: 150, loss is 5.261844043731689 and perplexity is 192.83676305239007
At time: 970.8073875904083 and batch: 200, loss is 5.270679149627686 and perplexity is 194.5480448206749
At time: 971.8808927536011 and batch: 250, loss is 5.307248935699463 and perplexity is 201.7943149260758
At time: 972.954389333725 and batch: 300, loss is 5.295958671569824 and perplexity is 199.52881691139996
At time: 974.0407681465149 and batch: 350, loss is 5.304050397872925 and perplexity is 201.14989931984945
At time: 975.1174943447113 and batch: 400, loss is 5.353243751525879 and perplexity is 211.29256805549028
At time: 976.1917564868927 and batch: 450, loss is 5.319308481216431 and perplexity is 204.24259555625372
At time: 977.2654855251312 and batch: 500, loss is 5.35047607421875 and perplexity is 210.70858691816528
At time: 978.3387658596039 and batch: 550, loss is 5.324309482574463 and perplexity is 205.26657137208468
At time: 979.4131882190704 and batch: 600, loss is 5.277946367263794 and perplexity is 195.96701754994072
At time: 980.4871053695679 and batch: 650, loss is 5.315423450469971 and perplexity is 203.4506461627573
At time: 981.5609481334686 and batch: 700, loss is 5.3210834121704105 and perplexity is 204.60543397253932
At time: 982.6348383426666 and batch: 750, loss is 5.294146032333374 and perplexity is 199.16747074312346
At time: 983.7085099220276 and batch: 800, loss is 5.263219776153565 and perplexity is 193.10223740841954
At time: 984.7810063362122 and batch: 850, loss is 5.239205102920533 and perplexity is 188.52018868316472
At time: 985.8917877674103 and batch: 900, loss is 5.2767775344848635 and perplexity is 195.7380986862368
At time: 986.9716260433197 and batch: 950, loss is 5.257881050109863 and perplexity is 192.07406447336362
At time: 988.0546712875366 and batch: 1000, loss is 5.291530933380127 and perplexity is 198.64730853312565
At time: 989.1332008838654 and batch: 1050, loss is 5.255694484710693 and perplexity is 191.65454079503536
At time: 990.2081818580627 and batch: 1100, loss is 5.2351009559631345 and perplexity is 187.74805967364802
At time: 991.2824189662933 and batch: 1150, loss is 5.247924175262451 and perplexity is 190.1710965801029
At time: 992.3566858768463 and batch: 1200, loss is 5.230066280364991 and perplexity is 186.8051846256706
At time: 993.429452419281 and batch: 1250, loss is 5.267288007736206 and perplexity is 193.88942216858248
At time: 994.5039129257202 and batch: 1300, loss is 5.242375535964966 and perplexity is 189.11882779006942
At time: 995.5781447887421 and batch: 1350, loss is 5.225125503540039 and perplexity is 185.88449822463465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9944840494791665 and perplexity of 147.59677310264289
Finished 32 epochs...
Completing Train Step...
At time: 998.7294540405273 and batch: 50, loss is 5.312473964691162 and perplexity is 202.851455461823
At time: 999.8281455039978 and batch: 100, loss is 5.314819507598877 and perplexity is 203.32781069192495
At time: 1000.9010324478149 and batch: 150, loss is 5.251860609054566 and perplexity is 190.9211678453406
At time: 1001.9740691184998 and batch: 200, loss is 5.26104437828064 and perplexity is 192.68261979501764
At time: 1003.0478191375732 and batch: 250, loss is 5.2977259159088135 and perplexity is 199.88174484664566
At time: 1004.1217770576477 and batch: 300, loss is 5.285971326828003 and perplexity is 197.5459719907584
At time: 1005.1952786445618 and batch: 350, loss is 5.293829317092896 and perplexity is 199.1044013577766
At time: 1006.2696666717529 and batch: 400, loss is 5.342889575958252 and perplexity is 209.11609494680044
At time: 1007.343966960907 and batch: 450, loss is 5.30918981552124 and perplexity is 202.18635376713505
At time: 1008.417736530304 and batch: 500, loss is 5.340908060073852 and perplexity is 208.70213834921324
At time: 1009.490879535675 and batch: 550, loss is 5.314691781997681 and perplexity is 203.30184218352144
At time: 1010.5636179447174 and batch: 600, loss is 5.268499031066894 and perplexity is 194.1243690167456
At time: 1011.6369466781616 and batch: 650, loss is 5.305757398605347 and perplexity is 201.49355557260563
At time: 1012.7364206314087 and batch: 700, loss is 5.311477422714233 and perplexity is 202.64940616339902
At time: 1013.8098452091217 and batch: 750, loss is 5.28432297706604 and perplexity is 197.22061535928145
At time: 1014.8830404281616 and batch: 800, loss is 5.253278264999389 and perplexity is 191.192020316375
At time: 1015.9564545154572 and batch: 850, loss is 5.229002323150635 and perplexity is 186.60653759651802
At time: 1017.0302591323853 and batch: 900, loss is 5.267049169540405 and perplexity is 193.84311949845
At time: 1018.1028907299042 and batch: 950, loss is 5.2479804992675785 and perplexity is 190.18180807957623
At time: 1019.1752433776855 and batch: 1000, loss is 5.281910629272461 and perplexity is 196.74542403678518
At time: 1020.2489032745361 and batch: 1050, loss is 5.245744857788086 and perplexity is 189.7571046599716
At time: 1021.3226535320282 and batch: 1100, loss is 5.224826679229737 and perplexity is 185.82895971619826
At time: 1022.3967940807343 and batch: 1150, loss is 5.237738094329834 and perplexity is 188.24383070617236
At time: 1023.4704411029816 and batch: 1200, loss is 5.219834499359131 and perplexity is 184.90357987727774
At time: 1024.5448281764984 and batch: 1250, loss is 5.257713060379029 and perplexity is 192.04180071303855
At time: 1025.6187589168549 and batch: 1300, loss is 5.2329222679138185 and perplexity is 187.339460486462
At time: 1026.6913487911224 and batch: 1350, loss is 5.215297517776489 and perplexity is 184.06657591235114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.987684326171875 and perplexity of 146.5965603234061
Finished 33 epochs...
Completing Train Step...
At time: 1029.8441455364227 and batch: 50, loss is 5.302969350814819 and perplexity is 200.9325643088045
At time: 1030.9435062408447 and batch: 100, loss is 5.305311574935913 and perplexity is 201.40374499762055
At time: 1032.0173709392548 and batch: 150, loss is 5.242209491729736 and perplexity is 189.08742830586527
At time: 1033.0929684638977 and batch: 200, loss is 5.251733865737915 and perplexity is 190.8969713967105
At time: 1034.166251897812 and batch: 250, loss is 5.287782468795776 and perplexity is 197.90407998551476
At time: 1035.2390396595001 and batch: 300, loss is 5.276269702911377 and perplexity is 195.63872193505145
At time: 1036.3114399909973 and batch: 350, loss is 5.283901376724243 and perplexity is 197.137484605645
At time: 1037.3841106891632 and batch: 400, loss is 5.332818412780762 and perplexity is 207.02062226685942
At time: 1038.4565796852112 and batch: 450, loss is 5.299136924743652 and perplexity is 200.1639788250397
At time: 1039.5283846855164 and batch: 500, loss is 5.331585178375244 and perplexity is 206.76547467356053
At time: 1040.6252238750458 and batch: 550, loss is 5.30532320022583 and perplexity is 201.40608638815624
At time: 1041.6991920471191 and batch: 600, loss is 5.259204521179199 and perplexity is 192.32843723122733
At time: 1042.773252248764 and batch: 650, loss is 5.2964754390716555 and perplexity is 199.6319535661991
At time: 1043.8460590839386 and batch: 700, loss is 5.3021996974945065 and perplexity is 200.77797539109332
At time: 1044.9194822311401 and batch: 750, loss is 5.274710750579834 and perplexity is 195.33396810341986
At time: 1045.992384672165 and batch: 800, loss is 5.243624353408814 and perplexity is 189.3551502122424
At time: 1047.0641713142395 and batch: 850, loss is 5.219112358093262 and perplexity is 184.7701015729379
At time: 1048.1359934806824 and batch: 900, loss is 5.257657251358032 and perplexity is 192.03108334721597
At time: 1049.20822930336 and batch: 950, loss is 5.238237361907959 and perplexity is 188.3378382131235
At time: 1050.279806137085 and batch: 1000, loss is 5.272488384246826 and perplexity is 194.90034648053035
At time: 1051.3517541885376 and batch: 1050, loss is 5.236045408248901 and perplexity is 187.92546251882956
At time: 1052.4238493442535 and batch: 1100, loss is 5.2147277736663815 and perplexity is 183.96173493395844
At time: 1053.4956710338593 and batch: 1150, loss is 5.227865991592407 and perplexity is 186.394611131045
At time: 1054.567992925644 and batch: 1200, loss is 5.20983588218689 and perplexity is 183.06401166294685
At time: 1055.6401255130768 and batch: 1250, loss is 5.2483556270599365 and perplexity is 190.253163944335
At time: 1056.7125763893127 and batch: 1300, loss is 5.22363356590271 and perplexity is 185.6073769207921
At time: 1057.785479068756 and batch: 1350, loss is 5.205650243759155 and perplexity is 182.29937326726562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.981872151692708 and perplexity of 145.74698686299823
Finished 34 epochs...
Completing Train Step...
At time: 1060.9318869113922 and batch: 50, loss is 5.293643999099731 and perplexity is 199.0675071483728
At time: 1062.0046136379242 and batch: 100, loss is 5.296057195663452 and perplexity is 199.54847627568333
At time: 1063.0776236057281 and batch: 150, loss is 5.232767124176025 and perplexity is 187.3103981968003
At time: 1064.1517865657806 and batch: 200, loss is 5.242740106582642 and perplexity is 189.18778752751425
At time: 1065.2272746562958 and batch: 250, loss is 5.2783296680450436 and perplexity is 196.04214625839333
At time: 1066.3020734786987 and batch: 300, loss is 5.266689186096191 and perplexity is 193.77335174302772
At time: 1067.4023807048798 and batch: 350, loss is 5.274197063446045 and perplexity is 195.2336533246247
At time: 1068.4776921272278 and batch: 400, loss is 5.322850790023804 and perplexity is 204.96736882883857
At time: 1069.5513217449188 and batch: 450, loss is 5.289522495269775 and perplexity is 198.24873809415882
At time: 1070.6233382225037 and batch: 500, loss is 5.322415904998779 and perplexity is 204.8782509689322
At time: 1071.6960008144379 and batch: 550, loss is 5.296202993392944 and perplexity is 199.5775721114498
At time: 1072.7682485580444 and batch: 600, loss is 5.250146141052246 and perplexity is 190.59412004870597
At time: 1073.8407938480377 and batch: 650, loss is 5.287392406463623 and perplexity is 197.8269001119923
At time: 1074.9131474494934 and batch: 700, loss is 5.293075027465821 and perplexity is 198.9542755993965
At time: 1075.9867651462555 and batch: 750, loss is 5.265361738204956 and perplexity is 193.51629836610698
At time: 1077.0612676143646 and batch: 800, loss is 5.234179391860962 and perplexity is 187.5751175024882
At time: 1078.135333776474 and batch: 850, loss is 5.209298467636108 and perplexity is 182.96565683038096
At time: 1079.2086477279663 and batch: 900, loss is 5.2483838939666745 and perplexity is 190.2585418887854
At time: 1080.2813160419464 and batch: 950, loss is 5.228869562149048 and perplexity is 186.5817651701265
At time: 1081.3537728786469 and batch: 1000, loss is 5.263196830749512 and perplexity is 193.0978066503916
At time: 1082.4263129234314 and batch: 1050, loss is 5.22658413887024 and perplexity is 186.15583376277465
At time: 1083.499130487442 and batch: 1100, loss is 5.204846143722534 and perplexity is 182.15284525403092
At time: 1084.5711953639984 and batch: 1150, loss is 5.218250379562378 and perplexity is 184.61090233525258
At time: 1085.6441340446472 and batch: 1200, loss is 5.2000869941711425 and perplexity is 181.28801218953703
At time: 1086.7172226905823 and batch: 1250, loss is 5.239190731048584 and perplexity is 188.51747931462265
At time: 1087.7909572124481 and batch: 1300, loss is 5.21457010269165 and perplexity is 183.93273179443483
At time: 1088.863124847412 and batch: 1350, loss is 5.196267337799072 and perplexity is 180.59687507203904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.975572102864583 and perplexity of 144.83166005847866
Finished 35 epochs...
Completing Train Step...
At time: 1092.005402803421 and batch: 50, loss is 5.284751100540161 and perplexity is 197.30506821113158
At time: 1093.0919318199158 and batch: 100, loss is 5.286931581497193 and perplexity is 197.73575753938852
At time: 1094.1933386325836 and batch: 150, loss is 5.223538112640381 and perplexity is 185.58966093669036
At time: 1095.2666347026825 and batch: 200, loss is 5.233650484085083 and perplexity is 187.47593379610873
At time: 1096.3415446281433 and batch: 250, loss is 5.26916576385498 and perplexity is 194.2538412554327
At time: 1097.4161939620972 and batch: 300, loss is 5.257353954315185 and perplexity is 191.97284971899208
At time: 1098.4907717704773 and batch: 350, loss is 5.264775514602661 and perplexity is 193.40288778980215
At time: 1099.565714597702 and batch: 400, loss is 5.313182611465454 and perplexity is 202.99525643742726
At time: 1100.6404628753662 and batch: 450, loss is 5.279858827590942 and perplexity is 196.34215530012787
At time: 1101.715176820755 and batch: 500, loss is 5.313530044555664 and perplexity is 203.06579595984195
At time: 1102.8035006523132 and batch: 550, loss is 5.287297582626342 and perplexity is 197.8081422955644
At time: 1103.8845400810242 and batch: 600, loss is 5.24117769241333 and perplexity is 188.89242864415698
At time: 1104.9622764587402 and batch: 650, loss is 5.278497180938721 and perplexity is 196.07498859627646
At time: 1106.0344655513763 and batch: 700, loss is 5.284187803268432 and perplexity is 197.1939581014588
At time: 1107.1065905094147 and batch: 750, loss is 5.256212959289551 and perplexity is 191.7539345667056
At time: 1108.1785600185394 and batch: 800, loss is 5.2249890804290775 and perplexity is 185.85914101280147
At time: 1109.25044131279 and batch: 850, loss is 5.199760484695434 and perplexity is 181.22882959808908
At time: 1110.3222982883453 and batch: 900, loss is 5.23927508354187 and perplexity is 188.533381904733
At time: 1111.3942804336548 and batch: 950, loss is 5.219472894668579 and perplexity is 184.83672996284406
At time: 1112.4655618667603 and batch: 1000, loss is 5.254198904037476 and perplexity is 191.36812020382615
At time: 1113.537770986557 and batch: 1050, loss is 5.217268552780151 and perplexity is 184.42973535889695
At time: 1114.6092083454132 and batch: 1100, loss is 5.195233879089355 and perplexity is 180.41033206739752
At time: 1115.680630683899 and batch: 1150, loss is 5.2088739204406735 and perplexity is 182.88799576047398
At time: 1116.7595417499542 and batch: 1200, loss is 5.190569581985474 and perplexity is 179.5708041039899
At time: 1117.8310735225677 and batch: 1250, loss is 5.230202655792237 and perplexity is 186.8306619997401
At time: 1118.9035999774933 and batch: 1300, loss is 5.2057451820373535 and perplexity is 182.31668127746354
At time: 1119.9780766963959 and batch: 1350, loss is 5.18715579032898 and perplexity is 178.95883195821784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9697216796875 and perplexity of 143.9868073404201
Finished 36 epochs...
Completing Train Step...
At time: 1123.131915807724 and batch: 50, loss is 5.275742864608764 and perplexity is 195.53567910869904
At time: 1124.248958826065 and batch: 100, loss is 5.278279628753662 and perplexity is 196.0323366937475
At time: 1125.3262872695923 and batch: 150, loss is 5.214553871154785 and perplexity is 183.92974630774765
At time: 1126.4025127887726 and batch: 200, loss is 5.224857664108276 and perplexity is 185.8347176931488
At time: 1127.47709274292 and batch: 250, loss is 5.260171175003052 and perplexity is 192.51444213720546
At time: 1128.5508348941803 and batch: 300, loss is 5.248196849822998 and perplexity is 190.22295847067937
At time: 1129.6233134269714 and batch: 350, loss is 5.255575284957886 and perplexity is 191.6316969826637
At time: 1130.6955199241638 and batch: 400, loss is 5.303645963668823 and perplexity is 201.0685638689407
At time: 1131.7685997486115 and batch: 450, loss is 5.270549907684326 and perplexity is 194.5229026780301
At time: 1132.842451095581 and batch: 500, loss is 5.304705352783203 and perplexity is 201.28168658675864
At time: 1133.9156987667084 and batch: 550, loss is 5.278525905609131 and perplexity is 196.08062086659174
At time: 1134.9883863925934 and batch: 600, loss is 5.232493028640747 and perplexity is 187.25906428846244
At time: 1136.060996055603 and batch: 650, loss is 5.269527406692505 and perplexity is 194.3241044701127
At time: 1137.1442267894745 and batch: 700, loss is 5.2754414272308345 and perplexity is 195.4767462290294
At time: 1138.220622062683 and batch: 750, loss is 5.247204885482788 and perplexity is 190.0343576373031
At time: 1139.29838180542 and batch: 800, loss is 5.216042699813843 and perplexity is 184.20379013683646
At time: 1140.383294582367 and batch: 850, loss is 5.190395126342773 and perplexity is 179.53947969638892
At time: 1141.4587745666504 and batch: 900, loss is 5.230396862030029 and perplexity is 186.86694920319798
At time: 1142.5355207920074 and batch: 950, loss is 5.210594005584717 and perplexity is 183.20284939490546
At time: 1143.610461473465 and batch: 1000, loss is 5.245290956497192 and perplexity is 189.67099320973782
At time: 1144.6844823360443 and batch: 1050, loss is 5.208167772293091 and perplexity is 182.75889532843277
At time: 1145.7575895786285 and batch: 1100, loss is 5.18579249382019 and perplexity is 178.7150242362615
At time: 1146.8299496173859 and batch: 1150, loss is 5.199792442321777 and perplexity is 181.23462133385246
At time: 1147.9024639129639 and batch: 1200, loss is 5.181265649795532 and perplexity is 177.90783757915526
At time: 1149.0008482933044 and batch: 1250, loss is 5.221395750045776 and perplexity is 185.19248618722753
At time: 1150.0739278793335 and batch: 1300, loss is 5.197104616165161 and perplexity is 180.74814824856188
At time: 1151.1463329792023 and batch: 1350, loss is 5.178306589126587 and perplexity is 177.38217561066548
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.963718668619792 and perplexity of 143.1250421233092
Finished 37 epochs...
Completing Train Step...
At time: 1154.3046810626984 and batch: 50, loss is 5.266959838867187 and perplexity is 193.82580413549462
At time: 1155.4122037887573 and batch: 100, loss is 5.269408159255981 and perplexity is 194.30093320038463
At time: 1156.4851760864258 and batch: 150, loss is 5.205776748657226 and perplexity is 182.3224364896737
At time: 1157.5677254199982 and batch: 200, loss is 5.216158227920532 and perplexity is 184.22507208126362
At time: 1158.6422848701477 and batch: 250, loss is 5.251412982940674 and perplexity is 190.83572566941956
At time: 1159.7289385795593 and batch: 300, loss is 5.2392158031463625 and perplexity is 188.52220590254942
At time: 1160.8042652606964 and batch: 350, loss is 5.246567668914795 and perplexity is 189.91330316918118
At time: 1161.8849003314972 and batch: 400, loss is 5.294297981262207 and perplexity is 199.19773632631453
At time: 1162.9578957557678 and batch: 450, loss is 5.261227369308472 and perplexity is 192.71788221191386
At time: 1164.0310082435608 and batch: 500, loss is 5.296143922805786 and perplexity is 199.56578329527125
At time: 1165.1061778068542 and batch: 550, loss is 5.269979925155639 and perplexity is 194.41205961437998
At time: 1166.179601430893 and batch: 600, loss is 5.2240441703796385 and perplexity is 185.68360378918248
At time: 1167.2521510124207 and batch: 650, loss is 5.261057453155518 and perplexity is 192.68513911263247
At time: 1168.324934720993 and batch: 700, loss is 5.266953210830689 and perplexity is 193.82451945524795
At time: 1169.4001331329346 and batch: 750, loss is 5.238575096130371 and perplexity is 188.4014570889942
At time: 1170.4862833023071 and batch: 800, loss is 5.207271957397461 and perplexity is 182.5952504963713
At time: 1171.5647025108337 and batch: 850, loss is 5.181253070831299 and perplexity is 177.90559969690474
At time: 1172.6516253948212 and batch: 900, loss is 5.221691465377807 and perplexity is 185.24725854288363
At time: 1173.728872537613 and batch: 950, loss is 5.201760969161987 and perplexity is 181.59173793180577
At time: 1174.8101861476898 and batch: 1000, loss is 5.236632833480835 and perplexity is 188.03588710715528
At time: 1175.9142644405365 and batch: 1050, loss is 5.1991967105865475 and perplexity is 181.12668627176464
At time: 1176.9891591072083 and batch: 1100, loss is 5.176558427810669 and perplexity is 177.07235384124863
At time: 1178.0645565986633 and batch: 1150, loss is 5.190708436965942 and perplexity is 179.5957401356925
At time: 1179.1389782428741 and batch: 1200, loss is 5.172173891067505 and perplexity is 176.2976731486622
At time: 1180.214522600174 and batch: 1250, loss is 5.212812900543213 and perplexity is 183.60980860670978
At time: 1181.2889487743378 and batch: 1300, loss is 5.188671751022339 and perplexity is 179.23033225308816
At time: 1182.3643279075623 and batch: 1350, loss is 5.169663209915161 and perplexity is 175.85560108670012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.958157958984375 and perplexity of 142.33137404648153
Finished 38 epochs...
Completing Train Step...
At time: 1185.575662612915 and batch: 50, loss is 5.258453197479248 and perplexity is 192.1839905880491
At time: 1186.6500520706177 and batch: 100, loss is 5.261159839630127 and perplexity is 192.70486847472856
At time: 1187.7264983654022 and batch: 150, loss is 5.197367506027222 and perplexity is 180.79567135071986
At time: 1188.8012223243713 and batch: 200, loss is 5.207775220870972 and perplexity is 182.68716714358823
At time: 1189.8772151470184 and batch: 250, loss is 5.242820043563842 and perplexity is 189.2029112325928
At time: 1190.9514820575714 and batch: 300, loss is 5.230457286834717 and perplexity is 186.87824094325333
At time: 1192.027063369751 and batch: 350, loss is 5.237753524780273 and perplexity is 188.246735415683
At time: 1193.1028187274933 and batch: 400, loss is 5.285164909362793 and perplexity is 197.3867316844749
At time: 1194.1779565811157 and batch: 450, loss is 5.252324848175049 and perplexity is 191.00982149703722
At time: 1195.2513809204102 and batch: 500, loss is 5.287748517990113 and perplexity is 197.8973610966116
At time: 1196.3259916305542 and batch: 550, loss is 5.261566019058227 and perplexity is 192.78315712654125
At time: 1197.4006729125977 and batch: 600, loss is 5.215611371994019 and perplexity is 184.12435505014625
At time: 1198.4754900932312 and batch: 650, loss is 5.252562427520752 and perplexity is 191.0552068765523
At time: 1199.5482409000397 and batch: 700, loss is 5.258568153381348 and perplexity is 192.20608454194715
At time: 1200.6231417655945 and batch: 750, loss is 5.229923219680786 and perplexity is 186.77846205966492
At time: 1201.6974804401398 and batch: 800, loss is 5.198731622695923 and perplexity is 181.04246602973615
At time: 1202.7965705394745 and batch: 850, loss is 5.172450885772705 and perplexity is 176.34651343460155
At time: 1203.8699944019318 and batch: 900, loss is 5.2131865692138675 and perplexity is 183.67843065996823
At time: 1204.9447689056396 and batch: 950, loss is 5.193057136535645 and perplexity is 180.01805232135737
At time: 1206.0189099311829 and batch: 1000, loss is 5.228126964569092 and perplexity is 186.44326143548116
At time: 1207.0930652618408 and batch: 1050, loss is 5.190442581176757 and perplexity is 179.5479999147527
At time: 1208.167646408081 and batch: 1100, loss is 5.167489767074585 and perplexity is 175.4738040468606
At time: 1209.2423374652863 and batch: 1150, loss is 5.1819674682617185 and perplexity is 178.03274040927724
At time: 1210.3165035247803 and batch: 1200, loss is 5.163311567306518 and perplexity is 174.74216896262726
At time: 1211.3901875019073 and batch: 1250, loss is 5.204332752227783 and perplexity is 182.05935353351333
At time: 1212.4636199474335 and batch: 1300, loss is 5.180383749008179 and perplexity is 177.75100968060596
At time: 1213.542249917984 and batch: 1350, loss is 5.161189603805542 and perplexity is 174.37176558821312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.952807210286458 and perplexity of 141.57182851294743
Finished 39 epochs...
Completing Train Step...
At time: 1216.8492197990417 and batch: 50, loss is 5.250141716003418 and perplexity is 190.5932766622843
At time: 1217.9239752292633 and batch: 100, loss is 5.252831974029541 and perplexity is 191.10671208176404
At time: 1218.9982016086578 and batch: 150, loss is 5.188815565109253 and perplexity is 179.2561099532222
At time: 1220.072772026062 and batch: 200, loss is 5.199556684494018 and perplexity is 181.19189888948532
At time: 1221.1515185832977 and batch: 250, loss is 5.234418077468872 and perplexity is 187.61989432701736
At time: 1222.2252433300018 and batch: 300, loss is 5.221828603744507 and perplexity is 185.27266479140172
At time: 1223.2995028495789 and batch: 350, loss is 5.229095573425293 and perplexity is 186.62393951875634
At time: 1224.3726234436035 and batch: 400, loss is 5.276239938735962 and perplexity is 195.6328989964717
At time: 1225.445154428482 and batch: 450, loss is 5.243490133285523 and perplexity is 189.3297366461792
At time: 1226.5205256938934 and batch: 500, loss is 5.279586191177368 and perplexity is 196.2886325755268
At time: 1227.5940959453583 and batch: 550, loss is 5.253380994796753 and perplexity is 191.21166244277825
At time: 1228.6670215129852 and batch: 600, loss is 5.207360916137695 and perplexity is 182.61149466234767
At time: 1229.741038799286 and batch: 650, loss is 5.244469766616821 and perplexity is 189.5153012445964
At time: 1230.8417925834656 and batch: 700, loss is 5.250336980819702 and perplexity is 190.63049645717672
At time: 1231.9157655239105 and batch: 750, loss is 5.2215752696990965 and perplexity is 185.22573486245147
At time: 1232.9889216423035 and batch: 800, loss is 5.19037015914917 and perplexity is 179.53499715539837
At time: 1234.0628802776337 and batch: 850, loss is 5.163750953674317 and perplexity is 174.81896515991448
At time: 1235.137449979782 and batch: 900, loss is 5.204935808181762 and perplexity is 182.16917862264788
At time: 1236.2111654281616 and batch: 950, loss is 5.18456166267395 and perplexity is 178.49519153435156
At time: 1237.2848081588745 and batch: 1000, loss is 5.219789056777954 and perplexity is 184.89517757225204
At time: 1238.358990907669 and batch: 1050, loss is 5.181855916976929 and perplexity is 178.0128817360008
At time: 1239.434012889862 and batch: 1100, loss is 5.1586540412902835 and perplexity is 173.9301951269971
At time: 1240.5074090957642 and batch: 1150, loss is 5.173343830108642 and perplexity is 176.50405138077582
At time: 1241.5801177024841 and batch: 1200, loss is 5.154614200592041 and perplexity is 173.2289622343539
At time: 1242.6545038223267 and batch: 1250, loss is 5.196086702346801 and perplexity is 180.5642558200171
At time: 1243.7289996147156 and batch: 1300, loss is 5.172266330718994 and perplexity is 176.31397079738923
At time: 1244.802523136139 and batch: 1350, loss is 5.152904214859009 and perplexity is 172.93299630126504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9480322265625 and perplexity of 140.8974367223093
Finished 40 epochs...
Completing Train Step...
At time: 1247.9524600505829 and batch: 50, loss is 5.241922178268433 and perplexity is 189.0331087460938
At time: 1249.0519363880157 and batch: 100, loss is 5.244623355865478 and perplexity is 189.54441099273853
At time: 1250.1247215270996 and batch: 150, loss is 5.180562448501587 and perplexity is 177.78277653426446
At time: 1251.1994156837463 and batch: 200, loss is 5.19156400680542 and perplexity is 179.74946258501978
At time: 1252.282366514206 and batch: 250, loss is 5.2261551666259765 and perplexity is 186.07599520247024
At time: 1253.3581182956696 and batch: 300, loss is 5.213398885726929 and perplexity is 183.71743276413943
At time: 1254.4334630966187 and batch: 350, loss is 5.220695505142212 and perplexity is 185.06285148591311
At time: 1255.505922794342 and batch: 400, loss is 5.26747986793518 and perplexity is 193.92662540049437
At time: 1256.5773162841797 and batch: 450, loss is 5.23491322517395 and perplexity is 187.71281689041894
At time: 1257.674572467804 and batch: 500, loss is 5.271472997665406 and perplexity is 194.70254772209668
At time: 1258.7489562034607 and batch: 550, loss is 5.245338802337646 and perplexity is 189.68006839492088
At time: 1259.8241505622864 and batch: 600, loss is 5.199271230697632 and perplexity is 181.1401843554791
At time: 1260.8994009494781 and batch: 650, loss is 5.236075429916382 and perplexity is 187.931104439266
At time: 1261.973152399063 and batch: 700, loss is 5.2422509860992434 and perplexity is 189.0952745322706
At time: 1263.0454902648926 and batch: 750, loss is 5.21327621459961 and perplexity is 183.69489732180637
At time: 1264.1195755004883 and batch: 800, loss is 5.18211971282959 and perplexity is 178.05984699027036
At time: 1265.1926856040955 and batch: 850, loss is 5.155081071853638 and perplexity is 173.30985674068805
At time: 1266.2813713550568 and batch: 900, loss is 5.196835346221924 and perplexity is 180.69948475704462
At time: 1267.354650735855 and batch: 950, loss is 5.176301536560058 and perplexity is 177.02687134509958
At time: 1268.4344952106476 and batch: 1000, loss is 5.2115559482574465 and perplexity is 183.379164822575
At time: 1269.5084075927734 and batch: 1050, loss is 5.173406171798706 and perplexity is 176.51505528463937
At time: 1270.5824472904205 and batch: 1100, loss is 5.1499559020996095 and perplexity is 172.42388661782493
At time: 1271.6644275188446 and batch: 1150, loss is 5.1648109340667725 and perplexity is 175.00436807958394
At time: 1272.7398371696472 and batch: 1200, loss is 5.146107740402222 and perplexity is 171.7616466421052
At time: 1273.818188905716 and batch: 1250, loss is 5.18798321723938 and perplexity is 179.10696858929978
At time: 1274.8914275169373 and batch: 1300, loss is 5.164341678619385 and perplexity is 174.92226559157245
At time: 1275.9643785953522 and batch: 1350, loss is 5.144795227050781 and perplexity is 171.53635506906306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.943120524088542 and perplexity of 140.20708721735102
Finished 41 epochs...
Completing Train Step...
At time: 1279.1234498023987 and batch: 50, loss is 5.233856811523437 and perplexity is 187.5146192160765
At time: 1280.2221364974976 and batch: 100, loss is 5.236526374816894 and perplexity is 188.0158701233506
At time: 1281.3075666427612 and batch: 150, loss is 5.172467660903931 and perplexity is 176.3494716953181
At time: 1282.385554075241 and batch: 200, loss is 5.183725385665894 and perplexity is 178.34598250835762
At time: 1283.4626717567444 and batch: 250, loss is 5.218050212860107 and perplexity is 184.5739530778577
At time: 1284.5706429481506 and batch: 300, loss is 5.205091276168823 and perplexity is 182.19750229980838
At time: 1285.6506292819977 and batch: 350, loss is 5.21243987083435 and perplexity is 183.54132946643185
At time: 1286.7241508960724 and batch: 400, loss is 5.258859891891479 and perplexity is 192.2621666389455
At time: 1287.799434185028 and batch: 450, loss is 5.22647271156311 and perplexity is 186.13509207512865
At time: 1288.8999893665314 and batch: 500, loss is 5.263572540283203 and perplexity is 193.17036896760865
At time: 1289.9798743724823 and batch: 550, loss is 5.2374168968200685 and perplexity is 188.183376965836
At time: 1291.0601081848145 and batch: 600, loss is 5.191375827789306 and perplexity is 179.71564069038885
At time: 1292.1368548870087 and batch: 650, loss is 5.228250246047974 and perplexity is 186.46624785334924
At time: 1293.2122025489807 and batch: 700, loss is 5.234300718307495 and perplexity is 187.59787670557165
At time: 1294.30179977417 and batch: 750, loss is 5.205279226303101 and perplexity is 182.23174956311868
At time: 1295.3912374973297 and batch: 800, loss is 5.174151620864868 and perplexity is 176.64668732415976
At time: 1296.482925415039 and batch: 850, loss is 5.146719713211059 and perplexity is 171.86679226930215
At time: 1297.5661883354187 and batch: 900, loss is 5.188924350738525 and perplexity is 179.27561150266936
At time: 1298.647055864334 and batch: 950, loss is 5.168199558258056 and perplexity is 175.59839801852362
At time: 1299.7266268730164 and batch: 1000, loss is 5.203514089584351 and perplexity is 181.91036933410814
At time: 1300.804006576538 and batch: 1050, loss is 5.1651216411590575 and perplexity is 175.05875162616644
At time: 1301.884529352188 and batch: 1100, loss is 5.141440916061401 and perplexity is 170.96193272235976
At time: 1302.9893708229065 and batch: 1150, loss is 5.156414470672607 and perplexity is 173.54110203582167
At time: 1304.067144870758 and batch: 1200, loss is 5.137739353179931 and perplexity is 170.33027615752107
At time: 1305.1415774822235 and batch: 1250, loss is 5.180057754516602 and perplexity is 177.6930732745655
At time: 1306.2180979251862 and batch: 1300, loss is 5.156581773757934 and perplexity is 173.57013842649445
At time: 1307.2949962615967 and batch: 1350, loss is 5.136825141906738 and perplexity is 170.1746294567165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9382621256510415 and perplexity of 139.5275573738893
Finished 42 epochs...
Completing Train Step...
At time: 1310.499347448349 and batch: 50, loss is 5.225936937332153 and perplexity is 186.03539239996132
At time: 1311.572479724884 and batch: 100, loss is 5.228800745010376 and perplexity is 186.5689255887158
At time: 1312.6729493141174 and batch: 150, loss is 5.164564943313598 and perplexity is 174.96132391772122
At time: 1313.7476012706757 and batch: 200, loss is 5.175991220474243 and perplexity is 176.97194558191435
At time: 1314.8226609230042 and batch: 250, loss is 5.2101085662841795 and perplexity is 183.11393711434235
At time: 1315.897394657135 and batch: 300, loss is 5.1970751762390135 and perplexity is 180.7428271147534
At time: 1316.972115278244 and batch: 350, loss is 5.204315681457519 and perplexity is 182.05624566664167
At time: 1318.0467031002045 and batch: 400, loss is 5.250485982894897 and perplexity is 190.65890291300227
At time: 1319.1219062805176 and batch: 450, loss is 5.218241453170776 and perplexity is 184.6092544333993
At time: 1320.1968221664429 and batch: 500, loss is 5.255843658447265 and perplexity is 191.68313275154824
At time: 1321.2720928192139 and batch: 550, loss is 5.229684600830078 and perplexity is 186.7338985147736
At time: 1322.3474850654602 and batch: 600, loss is 5.183652286529541 and perplexity is 178.33294604754707
At time: 1323.4219505786896 and batch: 650, loss is 5.220182933807373 and perplexity is 184.9680178796683
At time: 1324.496498823166 and batch: 700, loss is 5.2264893436431885 and perplexity is 186.13818791463052
At time: 1325.571969985962 and batch: 750, loss is 5.197306346893311 and perplexity is 180.78461438216593
At time: 1326.6472718715668 and batch: 800, loss is 5.166227264404297 and perplexity is 175.25240768684088
At time: 1327.723257303238 and batch: 850, loss is 5.138562602996826 and perplexity is 170.47055826186482
At time: 1328.7981560230255 and batch: 900, loss is 5.181169147491455 and perplexity is 177.8906698912896
At time: 1329.8720376491547 and batch: 950, loss is 5.160280590057373 and perplexity is 174.21333127639437
At time: 1330.9472692012787 and batch: 1000, loss is 5.195557260513306 and perplexity is 180.4686828517483
At time: 1332.0227510929108 and batch: 1050, loss is 5.156970043182373 and perplexity is 173.6375434890566
At time: 1333.0987951755524 and batch: 1100, loss is 5.13309461593628 and perplexity is 169.54097125607768
At time: 1334.173658132553 and batch: 1150, loss is 5.148192958831787 and perplexity is 172.1201808743572
At time: 1335.249913930893 and batch: 1200, loss is 5.12955472946167 and perplexity is 168.94187645442332
At time: 1336.3238999843597 and batch: 1250, loss is 5.172303819656372 and perplexity is 176.3205807446986
At time: 1337.3987817764282 and batch: 1300, loss is 5.148979005813598 and perplexity is 172.25552861091322
At time: 1338.473483324051 and batch: 1350, loss is 5.129008111953735 and perplexity is 168.84955510146256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.933543294270834 and perplexity of 138.87070137297516
Finished 43 epochs...
Completing Train Step...
At time: 1341.6545050144196 and batch: 50, loss is 5.218123970031738 and perplexity is 184.58756723265805
At time: 1342.7268950939178 and batch: 100, loss is 5.221001396179199 and perplexity is 185.11946921244805
At time: 1343.8004200458527 and batch: 150, loss is 5.15687292098999 and perplexity is 173.6206802490637
At time: 1344.874730348587 and batch: 200, loss is 5.168472051620483 and perplexity is 175.64625393635038
At time: 1345.9494853019714 and batch: 250, loss is 5.202366809844971 and perplexity is 181.70178692705176
At time: 1347.0236504077911 and batch: 300, loss is 5.189145641326904 and perplexity is 179.31528789806532
At time: 1348.0977878570557 and batch: 350, loss is 5.19638614654541 and perplexity is 180.61833283501863
At time: 1349.1710753440857 and batch: 400, loss is 5.242271633148193 and perplexity is 189.09917883196601
At time: 1350.2451930046082 and batch: 450, loss is 5.210186471939087 and perplexity is 183.1282032812363
At time: 1351.3196547031403 and batch: 500, loss is 5.2482649612426755 and perplexity is 190.235915267684
At time: 1352.393753528595 and batch: 550, loss is 5.222074060440064 and perplexity is 185.31814678918047
At time: 1353.4687712192535 and batch: 600, loss is 5.176044940948486 and perplexity is 176.9814528541241
At time: 1354.5429060459137 and batch: 650, loss is 5.21263072013855 and perplexity is 183.57636154426984
At time: 1355.6157414913177 and batch: 700, loss is 5.21879955291748 and perplexity is 184.71231356750107
At time: 1356.6901242733002 and batch: 750, loss is 5.189631996154785 and perplexity is 179.40251996519632
At time: 1357.7648429870605 and batch: 800, loss is 5.158501920700073 and perplexity is 173.90373877538786
At time: 1358.8388986587524 and batch: 850, loss is 5.130496129989624 and perplexity is 169.10099331070606
At time: 1359.9133143424988 and batch: 900, loss is 5.173496465682984 and perplexity is 176.53099423419857
At time: 1360.9865839481354 and batch: 950, loss is 5.152540245056152 and perplexity is 172.87006536586864
At time: 1362.0597586631775 and batch: 1000, loss is 5.187725820541382 and perplexity is 179.06087297967974
At time: 1363.1342391967773 and batch: 1050, loss is 5.148971443176269 and perplexity is 172.25422590974838
At time: 1364.2083485126495 and batch: 1100, loss is 5.124911003112793 and perplexity is 168.15917534271702
At time: 1365.2823317050934 and batch: 1150, loss is 5.140172834396362 and perplexity is 170.74527642802468
At time: 1366.3822140693665 and batch: 1200, loss is 5.121562900543213 and perplexity is 167.59710263924478
At time: 1367.4551782608032 and batch: 1250, loss is 5.164669914245605 and perplexity is 174.97969073493218
At time: 1368.5300514698029 and batch: 1300, loss is 5.141501741409302 and perplexity is 170.97233185765768
At time: 1369.6040608882904 and batch: 1350, loss is 5.121420955657959 and perplexity is 167.57331477606434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.929132080078125 and perplexity of 138.25946210895097
Finished 44 epochs...
Completing Train Step...
At time: 1372.761485338211 and batch: 50, loss is 5.210567684173584 and perplexity is 183.19802730084817
At time: 1373.859209537506 and batch: 100, loss is 5.2137158012390135 and perplexity is 183.77566489526816
At time: 1374.9338216781616 and batch: 150, loss is 5.149377136230469 and perplexity is 172.32412243006422
At time: 1376.0083849430084 and batch: 200, loss is 5.160970935821533 and perplexity is 174.33364023431295
At time: 1377.0821738243103 and batch: 250, loss is 5.194762077331543 and perplexity is 180.32523423183338
At time: 1378.1564915180206 and batch: 300, loss is 5.181587371826172 and perplexity is 177.96508365809663
At time: 1379.2301399707794 and batch: 350, loss is 5.188569612503052 and perplexity is 179.212026867199
At time: 1380.3029792308807 and batch: 400, loss is 5.234172668457031 and perplexity is 187.57385636344551
At time: 1381.3776936531067 and batch: 450, loss is 5.202132844924927 and perplexity is 181.65928005575378
At time: 1382.4520263671875 and batch: 500, loss is 5.240718898773193 and perplexity is 188.80578587632027
At time: 1383.5260453224182 and batch: 550, loss is 5.214703750610352 and perplexity is 183.95731566397518
At time: 1384.6010038852692 and batch: 600, loss is 5.168579845428467 and perplexity is 175.66518853541817
At time: 1385.6741602420807 and batch: 650, loss is 5.204968585968017 and perplexity is 182.17514982290783
At time: 1386.7494106292725 and batch: 700, loss is 5.211272478103638 and perplexity is 183.3271896695678
At time: 1387.8240478038788 and batch: 750, loss is 5.18199125289917 and perplexity is 178.03697490382015
At time: 1388.898773431778 and batch: 800, loss is 5.150904445648194 and perplexity is 172.58751577552044
At time: 1389.9729540348053 and batch: 850, loss is 5.122567911148071 and perplexity is 167.76562417352065
At time: 1391.0477042198181 and batch: 900, loss is 5.166032171249389 and perplexity is 175.2182204766739
At time: 1392.121149778366 and batch: 950, loss is 5.144914569854737 and perplexity is 171.5568279202768
At time: 1393.1984660625458 and batch: 1000, loss is 5.180012245178222 and perplexity is 177.6849867643734
At time: 1394.2994389533997 and batch: 1050, loss is 5.141096773147583 and perplexity is 170.90310750740178
At time: 1395.3743052482605 and batch: 1100, loss is 5.11686803817749 and perplexity is 166.81210148753988
At time: 1396.4488105773926 and batch: 1150, loss is 5.132299575805664 and perplexity is 169.40623294842368
At time: 1397.5249962806702 and batch: 1200, loss is 5.113760499954224 and perplexity is 166.29453110743952
At time: 1398.597424507141 and batch: 1250, loss is 5.15714391708374 and perplexity is 173.66773715103577
At time: 1399.6821501255035 and batch: 1300, loss is 5.1341648769378665 and perplexity is 169.72252148151745
At time: 1400.758603811264 and batch: 1350, loss is 5.1139086151123045 and perplexity is 166.31916367238554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.924636637369792 and perplexity of 137.63931957015402
Finished 45 epochs...
Completing Train Step...
At time: 1403.9179148674011 and batch: 50, loss is 5.203013324737549 and perplexity is 181.81929782048636
At time: 1405.0146508216858 and batch: 100, loss is 5.206166801452636 and perplexity is 182.39356573687152
At time: 1406.087690114975 and batch: 150, loss is 5.141826467514038 and perplexity is 171.0278600522387
At time: 1407.16148519516 and batch: 200, loss is 5.153659038543701 and perplexity is 173.06357950018355
At time: 1408.2352600097656 and batch: 250, loss is 5.187240190505982 and perplexity is 178.97393675272588
At time: 1409.3089935779572 and batch: 300, loss is 5.173882293701172 and perplexity is 176.59911797903231
At time: 1410.38258934021 and batch: 350, loss is 5.180847158432007 and perplexity is 177.8334002623985
At time: 1411.4552166461945 and batch: 400, loss is 5.22623501777649 and perplexity is 186.0908541780153
At time: 1412.5383446216583 and batch: 450, loss is 5.194198980331421 and perplexity is 180.223722216629
At time: 1413.614219903946 and batch: 500, loss is 5.233456792831421 and perplexity is 187.4396248639352
At time: 1414.6900732517242 and batch: 550, loss is 5.207320890426636 and perplexity is 182.6041856537013
At time: 1415.7688345909119 and batch: 600, loss is 5.16128981590271 and perplexity is 174.38924062412
At time: 1416.8462824821472 and batch: 650, loss is 5.197497415542602 and perplexity is 180.81915995443146
At time: 1417.9230625629425 and batch: 700, loss is 5.203846492767334 and perplexity is 181.97084697081507
At time: 1419.0001153945923 and batch: 750, loss is 5.174476823806763 and perplexity is 176.70414268837388
At time: 1420.0772454738617 and batch: 800, loss is 5.143477926254272 and perplexity is 171.31053885849195
At time: 1421.1814064979553 and batch: 850, loss is 5.114766960144043 and perplexity is 166.46198418607713
At time: 1422.2579951286316 and batch: 900, loss is 5.158718576431275 and perplexity is 173.9414200988609
At time: 1423.333609342575 and batch: 950, loss is 5.137430839538574 and perplexity is 170.27773504903138
At time: 1424.407133102417 and batch: 1000, loss is 5.172416667938233 and perplexity is 176.3404793420324
At time: 1425.4798438549042 and batch: 1050, loss is 5.133473873138428 and perplexity is 169.60528308507705
At time: 1426.5543608665466 and batch: 1100, loss is 5.109052228927612 and perplexity is 165.51341168868163
At time: 1427.6293768882751 and batch: 1150, loss is 5.124539575576782 and perplexity is 168.09672799261253
At time: 1428.7030074596405 and batch: 1200, loss is 5.106046915054321 and perplexity is 165.0167386393463
At time: 1429.777146577835 and batch: 1250, loss is 5.14976203918457 and perplexity is 172.39046326042222
At time: 1430.8511106967926 and batch: 1300, loss is 5.126996564865112 and perplexity is 168.5102476513519
At time: 1431.925138950348 and batch: 1350, loss is 5.106479864120484 and perplexity is 165.08819795024613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.920311279296875 and perplexity of 137.04526590168095
Finished 46 epochs...
Completing Train Step...
At time: 1435.104971408844 and batch: 50, loss is 5.195594940185547 and perplexity is 180.47548298068043
At time: 1436.1791665554047 and batch: 100, loss is 5.198894138336182 and perplexity is 181.071890652933
At time: 1437.2525250911713 and batch: 150, loss is 5.134520816802978 and perplexity is 169.78294324553937
At time: 1438.3260462284088 and batch: 200, loss is 5.1464939880371094 and perplexity is 171.82800198585744
At time: 1439.400322675705 and batch: 250, loss is 5.179844055175781 and perplexity is 177.65510443904043
At time: 1440.4736042022705 and batch: 300, loss is 5.166231546401978 and perplexity is 175.25315811885085
At time: 1441.5474262237549 and batch: 350, loss is 5.1733920288085935 and perplexity is 176.51255885161137
At time: 1442.6209619045258 and batch: 400, loss is 5.21842866897583 and perplexity is 184.64381943904505
At time: 1443.6935696601868 and batch: 450, loss is 5.186495170593262 and perplexity is 178.84064726381422
At time: 1444.7674260139465 and batch: 500, loss is 5.22618634223938 and perplexity is 186.08179632618672
At time: 1445.8416752815247 and batch: 550, loss is 5.200095109939575 and perplexity is 181.28948348703386
At time: 1446.9156255722046 and batch: 600, loss is 5.154122228622437 and perplexity is 173.1437594010323
At time: 1448.0177240371704 and batch: 650, loss is 5.190350093841553 and perplexity is 179.53139476659405
At time: 1449.0911819934845 and batch: 700, loss is 5.196586875915528 and perplexity is 180.654591878206
At time: 1450.1650114059448 and batch: 750, loss is 5.167103176116943 and perplexity is 175.4059805717289
At time: 1451.2391347885132 and batch: 800, loss is 5.1361310672760006 and perplexity is 170.05655654406215
At time: 1452.3143906593323 and batch: 850, loss is 5.107056932449341 and perplexity is 165.18349261387297
At time: 1453.3902678489685 and batch: 900, loss is 5.151526641845703 and perplexity is 172.69493248524245
At time: 1454.4650404453278 and batch: 950, loss is 5.130069332122803 and perplexity is 169.0288367667085
At time: 1455.5401768684387 and batch: 1000, loss is 5.164943838119507 and perplexity is 175.02762841501018
At time: 1456.6230008602142 and batch: 1050, loss is 5.125850706100464 and perplexity is 168.3172692912352
At time: 1457.7112925052643 and batch: 1100, loss is 5.101393127441407 and perplexity is 164.2505699610847
At time: 1458.792366027832 and batch: 1150, loss is 5.116923131942749 and perplexity is 166.82129204747056
At time: 1459.871090888977 and batch: 1200, loss is 5.098484840393066 and perplexity is 163.7735761095111
At time: 1460.948985338211 and batch: 1250, loss is 5.142508678436279 and perplexity is 171.14457693461304
At time: 1462.027132987976 and batch: 1300, loss is 5.119914226531982 and perplexity is 167.32101730166252
At time: 1463.104992866516 and batch: 1350, loss is 5.09928783416748 and perplexity is 163.90513808619545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.915743815104166 and perplexity of 136.4207438835894
Finished 47 epochs...
Completing Train Step...
At time: 1466.2775847911835 and batch: 50, loss is 5.188305139541626 and perplexity is 179.16463639875525
At time: 1467.3511531352997 and batch: 100, loss is 5.191691570281982 and perplexity is 179.77239351392075
At time: 1468.424829006195 and batch: 150, loss is 5.127308740615844 and perplexity is 168.56286067624654
At time: 1469.5084397792816 and batch: 200, loss is 5.139436569213867 and perplexity is 170.61960889390704
At time: 1470.5839154720306 and batch: 250, loss is 5.172631664276123 and perplexity is 176.3783959751353
At time: 1471.6686372756958 and batch: 300, loss is 5.159020538330078 and perplexity is 173.9939517112281
At time: 1472.7413494586945 and batch: 350, loss is 5.165946292877197 and perplexity is 175.20317366722796
At time: 1473.8145835399628 and batch: 400, loss is 5.210760974884034 and perplexity is 183.23344120017677
At time: 1474.8869223594666 and batch: 450, loss is 5.179016170501709 and perplexity is 177.50808736579248
At time: 1475.9839115142822 and batch: 500, loss is 5.219084339141846 and perplexity is 184.7649245809661
At time: 1477.0566053390503 and batch: 550, loss is 5.193105401992798 and perplexity is 180.02674118463287
At time: 1478.1387958526611 and batch: 600, loss is 5.147063074111938 and perplexity is 171.9258147383511
At time: 1479.2110137939453 and batch: 650, loss is 5.18314416885376 and perplexity is 178.24235494290605
At time: 1480.2831773757935 and batch: 700, loss is 5.189465675354004 and perplexity is 179.37268407564693
At time: 1481.3555376529694 and batch: 750, loss is 5.15985065460205 and perplexity is 174.13844688736924
At time: 1482.4287555217743 and batch: 800, loss is 5.129005327224731 and perplexity is 168.84908490186388
At time: 1483.5013139247894 and batch: 850, loss is 5.099476451873779 and perplexity is 163.9360564131722
At time: 1484.5744018554688 and batch: 900, loss is 5.1444604778289795 and perplexity is 171.47894301754894
At time: 1485.6470894813538 and batch: 950, loss is 5.122838373184204 and perplexity is 167.81100454238464
At time: 1486.7194211483002 and batch: 1000, loss is 5.157594861984253 and perplexity is 173.74606939192256
At time: 1487.7933688163757 and batch: 1050, loss is 5.118362331390381 and perplexity is 167.0615540098092
At time: 1488.8666260242462 and batch: 1100, loss is 5.093884449005127 and perplexity is 163.0218839252394
At time: 1489.9461629390717 and batch: 1150, loss is 5.109385004043579 and perplexity is 165.56849959888496
At time: 1491.0189867019653 and batch: 1200, loss is 5.0910488986969 and perplexity is 162.56028192915508
At time: 1492.0914993286133 and batch: 1250, loss is 5.13535472869873 and perplexity is 169.92458631231844
At time: 1493.163745880127 and batch: 1300, loss is 5.112952709197998 and perplexity is 166.16025416353864
At time: 1494.2357211112976 and batch: 1350, loss is 5.0921375274658205 and perplexity is 162.73734608982988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9113134765625 and perplexity of 135.81769065544754
Finished 48 epochs...
Completing Train Step...
At time: 1497.36097073555 and batch: 50, loss is 5.181170082092285 and perplexity is 177.89083614813498
At time: 1498.4588696956635 and batch: 100, loss is 5.184613523483276 and perplexity is 178.50444867948477
At time: 1499.5314528942108 and batch: 150, loss is 5.120269441604615 and perplexity is 167.38046280632085
At time: 1500.6047630310059 and batch: 200, loss is 5.132500133514404 and perplexity is 169.44021208162474
At time: 1501.6772437095642 and batch: 250, loss is 5.165418634414673 and perplexity is 175.11075061602824
At time: 1502.774470090866 and batch: 300, loss is 5.151842298507691 and perplexity is 172.7494533956645
At time: 1503.847708940506 and batch: 350, loss is 5.158681745529175 and perplexity is 173.93501379742182
At time: 1504.9205913543701 and batch: 400, loss is 5.203151235580444 and perplexity is 181.84437440222985
At time: 1505.9939036369324 and batch: 450, loss is 5.1714826107025145 and perplexity is 176.1758441426724
At time: 1507.066740989685 and batch: 500, loss is 5.212194728851318 and perplexity is 183.49634129542812
At time: 1508.1416687965393 and batch: 550, loss is 5.186121034622192 and perplexity is 178.773749059876
At time: 1509.2152993679047 and batch: 600, loss is 5.14011775970459 and perplexity is 170.73587294350318
At time: 1510.2886338233948 and batch: 650, loss is 5.176042137145996 and perplexity is 176.98095663378143
At time: 1511.361745595932 and batch: 700, loss is 5.182415628433228 and perplexity is 178.11254547414342
At time: 1512.4350214004517 and batch: 750, loss is 5.152729501724243 and perplexity is 172.90278527458523
At time: 1513.5101065635681 and batch: 800, loss is 5.121875677108765 and perplexity is 167.64953128420302
At time: 1514.583326101303 and batch: 850, loss is 5.092081708908081 and perplexity is 162.72826257939738
At time: 1515.656132698059 and batch: 900, loss is 5.137532911300659 and perplexity is 170.2951164845535
At time: 1516.7290244102478 and batch: 950, loss is 5.115645713806153 and perplexity is 166.60832755475099
At time: 1517.802857875824 and batch: 1000, loss is 5.1503759860992435 and perplexity is 172.49633434974888
At time: 1518.876103401184 and batch: 1050, loss is 5.110995235443116 and perplexity is 165.8353179577113
At time: 1519.9494860172272 and batch: 1100, loss is 5.086508321762085 and perplexity is 161.82383766868426
At time: 1521.0223500728607 and batch: 1150, loss is 5.102070474624634 and perplexity is 164.36186230951566
At time: 1522.0953748226166 and batch: 1200, loss is 5.0837539863586425 and perplexity is 161.37873380752725
At time: 1523.1688313484192 and batch: 1250, loss is 5.128303098678589 and perplexity is 168.7305558765591
At time: 1524.2420091629028 and batch: 1300, loss is 5.10616171836853 and perplexity is 165.03568419532755
At time: 1525.3156490325928 and batch: 1350, loss is 5.085228662490845 and perplexity is 161.61689073352616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.907040201822917 and perplexity of 135.23854265934443
Finished 49 epochs...
Completing Train Step...
At time: 1528.4481959342957 and batch: 50, loss is 5.1741187953948975 and perplexity is 176.64088890879796
At time: 1529.5467913150787 and batch: 100, loss is 5.177710943222046 and perplexity is 177.27655010504725
At time: 1530.6201775074005 and batch: 150, loss is 5.113451375961303 and perplexity is 166.24313342252083
At time: 1531.6933073997498 and batch: 200, loss is 5.125670356750488 and perplexity is 168.28691611829856
At time: 1532.7662041187286 and batch: 250, loss is 5.158564329147339 and perplexity is 173.914592176367
At time: 1533.8393905162811 and batch: 300, loss is 5.1447252178192135 and perplexity is 171.5243463610239
At time: 1534.911996126175 and batch: 350, loss is 5.15150221824646 and perplexity is 172.69071470492693
At time: 1535.9845910072327 and batch: 400, loss is 5.1957900333404545 and perplexity is 180.51069594683125
At time: 1537.0571763515472 and batch: 450, loss is 5.1640472412109375 and perplexity is 174.87076951456967
At time: 1538.1302754878998 and batch: 500, loss is 5.205244779586792 and perplexity is 182.22547238585375
At time: 1539.2025673389435 and batch: 550, loss is 5.179359254837036 and perplexity is 177.56899805811628
At time: 1540.275114774704 and batch: 600, loss is 5.133269386291504 and perplexity is 169.57060458128717
At time: 1541.3481640815735 and batch: 650, loss is 5.169274349212646 and perplexity is 175.78723104819255
At time: 1542.4213852882385 and batch: 700, loss is 5.175523147583008 and perplexity is 176.88912919524319
At time: 1543.4950540065765 and batch: 750, loss is 5.145753688812256 and perplexity is 171.70084492212436
At time: 1544.5677468776703 and batch: 800, loss is 5.114905061721802 and perplexity is 166.48497443618854
At time: 1545.640972852707 and batch: 850, loss is 5.084749164581299 and perplexity is 161.53941434863887
At time: 1546.7131526470184 and batch: 900, loss is 5.130685987472535 and perplexity is 169.13310144754223
At time: 1547.7877180576324 and batch: 950, loss is 5.108655557632447 and perplexity is 165.44777028919
At time: 1548.86124253273 and batch: 1000, loss is 5.14327000617981 and perplexity is 171.27492366118184
At time: 1549.9347970485687 and batch: 1050, loss is 5.103715143203735 and perplexity is 164.6324055160307
At time: 1551.0074906349182 and batch: 1100, loss is 5.079294452667236 and perplexity is 160.6606622292842
At time: 1552.0803813934326 and batch: 1150, loss is 5.094836874008179 and perplexity is 163.1772240066805
At time: 1553.1528551578522 and batch: 1200, loss is 5.076636953353882 and perplexity is 160.2342734446186
At time: 1554.2251620292664 and batch: 1250, loss is 5.121370916366577 and perplexity is 167.56492973593097
At time: 1555.2979891300201 and batch: 1300, loss is 5.0994589900970455 and perplexity is 163.93319382334948
At time: 1556.3707528114319 and batch: 1350, loss is 5.078342809677124 and perplexity is 160.5078433623217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.902738444010416 and perplexity of 134.65802871231827
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc203461c50>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'dropout': 0.6035230574493423, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.993531646404836, 'wordvec_dim': 200, 'anneal': 4.377480264653539, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -173.42602495371904}, {'params': {'dropout': 0.7510165480743217, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.89367160872679, 'wordvec_dim': 200, 'anneal': 4.723259686697794, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -172.88695462763891}, {'params': {'dropout': 0.7815882339172517, 'data': 'wikitext', 'wordvec_source': '', 'lr': 21.625570823395684, 'wordvec_dim': 200, 'anneal': 2.8742957455685825, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -177.14737530525215}, {'params': {'dropout': 0.07444705983629185, 'data': 'wikitext', 'wordvec_source': '', 'lr': 3.543538552399709, 'wordvec_dim': 200, 'anneal': 5.777949298810614, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -94.6403023793914}, {'params': {'dropout': 0.9946054317887449, 'data': 'wikitext', 'wordvec_source': '', 'lr': 23.746236205741887, 'wordvec_dim': 200, 'anneal': 5.251549236760035, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -173.52018719241522}, {'params': {'dropout': 0.0, 'data': 'wikitext', 'wordvec_source': '', 'lr': 0.10894124076359464, 'wordvec_dim': 200, 'anneal': 5.833171865336385, 'batch_size': 80, 'num_layers': 1, 'tune_wordvecs': True, 'seq_len': 20}, 'best_accuracy': -134.65802871231827}]
