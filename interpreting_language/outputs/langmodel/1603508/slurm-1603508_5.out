Building Bayesian Optimizer for 
 data:ptb 
 choices:[{'domain': [0, 30], 'name': 'lr', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [2, 8], 'name': 'anneal', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.558669725775248, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 14.800885502949932, 'anneal': 2.9089546393359518, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.016098976135254 and batch: 50, loss is 6.546887979507447 and perplexity is 697.0714940830717
At time: 1.413517951965332 and batch: 100, loss is 5.979486541748047 and perplexity is 395.23737815304474
At time: 1.7986040115356445 and batch: 150, loss is 5.8359542560577395 and perplexity is 342.39130718729615
At time: 2.183474063873291 and batch: 200, loss is 5.767486457824707 and perplexity is 319.7330592514868
At time: 2.5766420364379883 and batch: 250, loss is 5.717528057098389 and perplexity is 304.1521461908509
At time: 2.9694159030914307 and batch: 300, loss is 5.763927440643311 and perplexity is 318.59714636590155
At time: 3.34843111038208 and batch: 350, loss is 5.7974726009368895 and perplexity is 329.46581515805167
At time: 3.7283036708831787 and batch: 400, loss is 5.671364593505859 and perplexity is 290.43058379560534
At time: 4.107388019561768 and batch: 450, loss is 5.707293996810913 and perplexity is 301.0553084314837
At time: 4.486562252044678 and batch: 500, loss is 5.684542713165283 and perplexity is 294.28324242468943
At time: 4.8659141063690186 and batch: 550, loss is 5.738569936752319 and perplexity is 310.6198871239598
At time: 5.245266914367676 and batch: 600, loss is 5.557324705123901 and perplexity is 259.1286625939811
At time: 5.624636888504028 and batch: 650, loss is 5.730472717285156 and perplexity is 308.11488518895015
At time: 6.003993511199951 and batch: 700, loss is 5.718446865081787 and perplexity is 304.43173203412204
At time: 6.382684230804443 and batch: 750, loss is 5.6517476558685305 and perplexity is 284.7887438814292
At time: 6.761462211608887 and batch: 800, loss is 5.5873510360717775 and perplexity is 267.0273362375843
At time: 7.141540050506592 and batch: 850, loss is 5.536592254638672 and perplexity is 253.81159876218393
At time: 7.522539138793945 and batch: 900, loss is 5.514927835464477 and perplexity is 248.3720529468953
At time: 7.90304970741272 and batch: 950, loss is 5.536014175415039 and perplexity is 253.66491795087197
At time: 8.283848524093628 and batch: 1000, loss is 5.587045125961303 and perplexity is 266.9456623687243
At time: 8.665553331375122 and batch: 1050, loss is 5.478440990447998 and perplexity is 239.47307539003518
At time: 9.046852350234985 and batch: 1100, loss is 5.571296577453613 and perplexity is 262.7745860624819
At time: 9.427509546279907 and batch: 1150, loss is 5.558828563690185 and perplexity is 259.51864862140786
At time: 9.808534145355225 and batch: 1200, loss is 5.5179362487792964 and perplexity is 249.12038381788736
At time: 10.189509153366089 and batch: 1250, loss is 5.537705078125 and perplexity is 254.09420348581162
At time: 10.570880651473999 and batch: 1300, loss is 5.593527431488037 and perplexity is 268.68170641611164
At time: 10.95184326171875 and batch: 1350, loss is 5.528852882385254 and perplexity is 251.85483813372744
At time: 11.333148002624512 and batch: 1400, loss is 5.417594757080078 and perplexity is 225.33648119556435
At time: 11.713403940200806 and batch: 1450, loss is 5.489142570495606 and perplexity is 242.04957740767074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.306567591479701 and perplexity of 201.65687036486585
Finished 1 epochs...
Completing Train Step...
At time: 12.9321608543396 and batch: 50, loss is 5.2942328453063965 and perplexity is 199.18476181392188
At time: 13.327461242675781 and batch: 100, loss is 5.264491128921509 and perplexity is 193.34789459783
At time: 13.701827764511108 and batch: 150, loss is 5.122076072692871 and perplexity is 167.6831308764424
At time: 14.088838338851929 and batch: 200, loss is 5.148889446258545 and perplexity is 172.24010217321816
At time: 14.463828325271606 and batch: 250, loss is 5.1536765384674075 and perplexity is 173.06660812612145
At time: 14.838191509246826 and batch: 300, loss is 5.157812595367432 and perplexity is 173.78390383018584
At time: 15.21301007270813 and batch: 350, loss is 5.1844980430603025 and perplexity is 178.4838361004462
At time: 15.587863683700562 and batch: 400, loss is 5.071027307510376 and perplexity is 159.33793234717203
At time: 15.962708950042725 and batch: 450, loss is 5.104436388015747 and perplexity is 164.751188615096
At time: 16.33606195449829 and batch: 500, loss is 5.070868263244629 and perplexity is 159.31259257784205
At time: 16.70836901664734 and batch: 550, loss is 5.123150863647461 and perplexity is 167.8634520751838
At time: 17.081392526626587 and batch: 600, loss is 5.0062770080566406 and perplexity is 149.34767962599724
At time: 17.46692156791687 and batch: 650, loss is 5.1249581241607665 and perplexity is 168.16709936597823
At time: 17.85441541671753 and batch: 700, loss is 5.13999415397644 and perplexity is 170.71477031583643
At time: 18.231969118118286 and batch: 750, loss is 5.098202753067016 and perplexity is 163.72738417473474
At time: 18.60987162590027 and batch: 800, loss is 5.01400990486145 and perplexity is 150.50704667617802
At time: 18.988625288009644 and batch: 850, loss is 4.968061075210572 and perplexity is 143.747900623215
At time: 19.367588758468628 and batch: 900, loss is 4.92298318862915 and perplexity is 137.4119280524625
At time: 19.746417760849 and batch: 950, loss is 4.995515651702881 and perplexity is 147.74911282547708
At time: 20.125088214874268 and batch: 1000, loss is 5.0344778919219975 and perplexity is 153.6193657583208
At time: 20.501997709274292 and batch: 1050, loss is 4.935047330856324 and perplexity is 139.07972513878508
At time: 20.8787784576416 and batch: 1100, loss is 5.057076320648194 and perplexity is 157.13044506289438
At time: 21.255162000656128 and batch: 1150, loss is 5.042381677627564 and perplexity is 154.8383512597791
At time: 21.631176233291626 and batch: 1200, loss is 4.9773409461975096 and perplexity is 145.08807128355764
At time: 22.008095264434814 and batch: 1250, loss is 4.948890619277954 and perplexity is 141.01843397977046
At time: 22.38497281074524 and batch: 1300, loss is 5.045467081069947 and perplexity is 155.3168278087847
At time: 22.762165307998657 and batch: 1350, loss is 5.014180831909179 and perplexity is 150.5327746000652
At time: 23.138981819152832 and batch: 1400, loss is 4.855775918960571 and perplexity is 128.48034288301466
At time: 23.515486478805542 and batch: 1450, loss is 4.952663745880127 and perplexity is 141.5515194514651
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.109273274739583 and perplexity of 165.55000177905458
Finished 2 epochs...
Completing Train Step...
At time: 24.77519178390503 and batch: 50, loss is 4.999626893997192 and perplexity is 148.35779559089124
At time: 25.153542518615723 and batch: 100, loss is 5.021121969223023 and perplexity is 151.58127795198388
At time: 25.532018423080444 and batch: 150, loss is 4.909281187057495 and perplexity is 135.5419500753832
At time: 25.925297021865845 and batch: 200, loss is 4.980392246246338 and perplexity is 145.53145462634987
At time: 26.31501269340515 and batch: 250, loss is 5.00315993309021 and perplexity is 148.88287650197321
At time: 26.696533679962158 and batch: 300, loss is 5.010609750747681 and perplexity is 149.996168546648
At time: 27.07594132423401 and batch: 350, loss is 5.041255912780762 and perplexity is 154.6641377671061
At time: 27.48737668991089 and batch: 400, loss is 4.9047958946228025 and perplexity is 134.935366162175
At time: 27.8654522895813 and batch: 450, loss is 4.973619966506958 and perplexity is 144.54920469453526
At time: 28.243661403656006 and batch: 500, loss is 4.946346206665039 and perplexity is 140.66008098996488
At time: 28.621750831604004 and batch: 550, loss is 5.0043372058868405 and perplexity is 149.05825547655522
At time: 29.0001699924469 and batch: 600, loss is 4.904289712905884 and perplexity is 134.86708163050673
At time: 29.378756999969482 and batch: 650, loss is 5.0140101337432865 and perplexity is 150.50708112451116
At time: 29.75852060317993 and batch: 700, loss is 5.03101432800293 and perplexity is 153.08821563300017
At time: 30.145614624023438 and batch: 750, loss is 4.998331336975098 and perplexity is 148.16571406018593
At time: 30.52543592453003 and batch: 800, loss is 4.923001756668091 and perplexity is 137.4144795461816
At time: 30.904391288757324 and batch: 850, loss is 4.881921510696412 and perplexity is 131.88383677377158
At time: 31.283611297607422 and batch: 900, loss is 4.8312324523925785 and perplexity is 125.36537233577891
At time: 31.66264581680298 and batch: 950, loss is 4.929657888412476 and perplexity is 138.33217920238226
At time: 32.04245662689209 and batch: 1000, loss is 4.963095684051513 and perplexity is 143.03590519907925
At time: 32.42234969139099 and batch: 1050, loss is 4.860027303695679 and perplexity is 129.02772499302145
At time: 32.81539797782898 and batch: 1100, loss is 5.002719297409057 and perplexity is 148.81728784568617
At time: 33.194724559783936 and batch: 1150, loss is 4.947001619338989 and perplexity is 140.75230160774416
At time: 33.57443618774414 and batch: 1200, loss is 4.9110884094238285 and perplexity is 135.78712599610992
At time: 33.953782081604004 and batch: 1250, loss is 4.876881713867188 and perplexity is 131.2208411163946
At time: 34.33378267288208 and batch: 1300, loss is 4.981292219161987 and perplexity is 145.66248794826475
At time: 34.71344447135925 and batch: 1350, loss is 4.943252725601196 and perplexity is 140.22562403163644
At time: 35.093538761138916 and batch: 1400, loss is 4.8018659973144535 and perplexity is 121.73736730950077
At time: 35.47278332710266 and batch: 1450, loss is 4.895157384872436 and perplexity is 133.6410380372132
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.108248197115385 and perplexity of 165.38038712549033
Finished 3 epochs...
Completing Train Step...
At time: 36.70036315917969 and batch: 50, loss is 4.933456192016601 and perplexity is 138.85860594861575
At time: 37.09222340583801 and batch: 100, loss is 4.969961156845093 and perplexity is 144.02129302087448
At time: 37.47094440460205 and batch: 150, loss is 4.853649082183838 and perplexity is 128.20737654500252
At time: 37.85087013244629 and batch: 200, loss is 4.923928442001343 and perplexity is 137.54187854923038
At time: 38.230957984924316 and batch: 250, loss is 4.951339607238769 and perplexity is 141.36420965425498
At time: 38.6106743812561 and batch: 300, loss is 4.960997400283813 and perplexity is 142.73608993974977
At time: 38.98985147476196 and batch: 350, loss is 4.994901008605957 and perplexity is 147.65832775626845
At time: 39.394168853759766 and batch: 400, loss is 4.852873983383179 and perplexity is 128.10804166335382
At time: 39.79384183883667 and batch: 450, loss is 4.9104547023773195 and perplexity is 135.7011039967933
At time: 40.18045616149902 and batch: 500, loss is 4.893944416046143 and perplexity is 133.47903389700943
At time: 40.5803062915802 and batch: 550, loss is 4.9448006725311275 and perplexity is 140.44285394266475
At time: 40.978466510772705 and batch: 600, loss is 4.864110088348388 and perplexity is 129.55559426341492
At time: 41.36349534988403 and batch: 650, loss is 4.955424976348877 and perplexity is 141.94291593914593
At time: 41.74237084388733 and batch: 700, loss is 4.989977416992187 and perplexity is 146.93310526676294
At time: 42.11965274810791 and batch: 750, loss is 4.9618223190307615 and perplexity is 142.85388419487205
At time: 42.51897478103638 and batch: 800, loss is 4.8720078277587895 and perplexity is 130.58284171292001
At time: 42.89702343940735 and batch: 850, loss is 4.852430295944214 and perplexity is 128.0512143421539
At time: 43.276268005371094 and batch: 900, loss is 4.800450658798217 and perplexity is 121.56518959829756
At time: 43.65498971939087 and batch: 950, loss is 4.87389570236206 and perplexity is 130.82959859314818
At time: 44.03325080871582 and batch: 1000, loss is 4.9287667655944825 and perplexity is 138.20896314950426
At time: 44.41160869598389 and batch: 1050, loss is 4.821203718185425 and perplexity is 124.11439965883157
At time: 44.7899374961853 and batch: 1100, loss is 4.958740644454956 and perplexity is 142.4143326371817
At time: 45.16807198524475 and batch: 1150, loss is 4.910001335144043 and perplexity is 135.63959550674218
At time: 45.545459270477295 and batch: 1200, loss is 4.887168045043945 and perplexity is 132.57758815716412
At time: 45.922486305236816 and batch: 1250, loss is 4.854031305313111 and perplexity is 128.25638973605228
At time: 46.300135374069214 and batch: 1300, loss is 4.912587070465088 and perplexity is 135.9907774358678
At time: 46.67818307876587 and batch: 1350, loss is 4.903142137527466 and perplexity is 134.71240025951025
At time: 47.05617117881775 and batch: 1400, loss is 4.777558898925781 and perplexity is 118.81395886928334
At time: 47.43516755104065 and batch: 1450, loss is 4.8548128795623775 and perplexity is 128.35667081102204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.094171507745727 and perplexity of 163.0686874992952
Finished 4 epochs...
Completing Train Step...
At time: 48.670167684555054 and batch: 50, loss is 4.919081802368164 and perplexity is 136.87687544636745
At time: 49.06191062927246 and batch: 100, loss is 4.9698454284667966 and perplexity is 144.00462663459854
At time: 49.44071912765503 and batch: 150, loss is 4.8291671848297115 and perplexity is 125.10672647717227
At time: 49.820399045944214 and batch: 200, loss is 4.892281446456909 and perplexity is 133.2572467865605
At time: 50.19885230064392 and batch: 250, loss is 4.9148708152771 and perplexity is 136.30170056772832
At time: 50.57649755477905 and batch: 300, loss is 4.932422389984131 and perplexity is 138.71512781633095
At time: 50.9532585144043 and batch: 350, loss is 4.960033750534057 and perplexity is 142.59860859496897
At time: 51.33036780357361 and batch: 400, loss is 4.830195894241333 and perplexity is 125.23549116352352
At time: 51.708109855651855 and batch: 450, loss is 4.881384506225586 and perplexity is 131.81303357631265
At time: 52.08552289009094 and batch: 500, loss is 4.871937646865844 and perplexity is 130.57367761406138
At time: 52.47535252571106 and batch: 550, loss is 4.932371196746826 and perplexity is 138.70802672164038
At time: 52.85247993469238 and batch: 600, loss is 4.83747465133667 and perplexity is 126.1503754544462
At time: 53.22952604293823 and batch: 650, loss is 4.947634372711182 and perplexity is 140.84139128415447
At time: 53.60653209686279 and batch: 700, loss is 4.9724413108825685 and perplexity is 144.37893132796395
At time: 53.9848837852478 and batch: 750, loss is 4.9445520114898684 and perplexity is 140.4079356179594
At time: 54.362337827682495 and batch: 800, loss is 4.858324031829834 and perplexity is 128.80814275633637
At time: 54.73981738090515 and batch: 850, loss is 4.846066179275513 and perplexity is 127.23886914611035
At time: 55.11636757850647 and batch: 900, loss is 4.778623437881469 and perplexity is 118.94050830342955
At time: 55.49385952949524 and batch: 950, loss is 4.854118804931641 and perplexity is 128.26761261221978
At time: 55.871079444885254 and batch: 1000, loss is 4.887828664779663 and perplexity is 132.66520046443793
At time: 56.24895668029785 and batch: 1050, loss is 4.807614269256592 and perplexity is 122.43916192303159
At time: 56.626330614089966 and batch: 1100, loss is 4.940188636779785 and perplexity is 139.79661785672684
At time: 57.00397181510925 and batch: 1150, loss is 4.896252336502076 and perplexity is 133.78744865124108
At time: 57.38149929046631 and batch: 1200, loss is 4.8631088829040525 and perplexity is 129.42594740949218
At time: 57.758843660354614 and batch: 1250, loss is 4.866255474090576 and perplexity is 129.8338393529696
At time: 58.13608694076538 and batch: 1300, loss is 4.92924054145813 and perplexity is 138.27445873427274
At time: 58.51417398452759 and batch: 1350, loss is 4.883993816375733 and perplexity is 132.15742377777076
At time: 58.90218639373779 and batch: 1400, loss is 4.764596843719483 and perplexity is 117.28382404489852
At time: 59.279712200164795 and batch: 1450, loss is 4.849581756591797 and perplexity is 127.68697444111362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1287210578592415 and perplexity of 168.80109310125783
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 60.51643991470337 and batch: 50, loss is 4.879071626663208 and perplexity is 131.50851819434888
At time: 60.896390438079834 and batch: 100, loss is 4.8427225112915036 and perplexity is 126.81413509356611
At time: 61.277310371398926 and batch: 150, loss is 4.732422418594361 and perplexity is 113.57034430964673
At time: 61.6588921546936 and batch: 200, loss is 4.788711242675781 and perplexity is 120.14642925433103
At time: 62.05396890640259 and batch: 250, loss is 4.792821931838989 and perplexity is 120.64133037450735
At time: 62.43457365036011 and batch: 300, loss is 4.801411542892456 and perplexity is 121.68205579383805
At time: 62.81541728973389 and batch: 350, loss is 4.829942798614502 and perplexity is 125.20379861917729
At time: 63.1955292224884 and batch: 400, loss is 4.699630556106567 and perplexity is 109.9065606430152
At time: 63.57619500160217 and batch: 450, loss is 4.738642530441284 and perplexity is 114.2789661225119
At time: 63.95625615119934 and batch: 500, loss is 4.718310565948486 and perplexity is 111.97891178675381
At time: 64.33707880973816 and batch: 550, loss is 4.787235050201416 and perplexity is 119.96920084345103
At time: 64.71643280982971 and batch: 600, loss is 4.679366044998169 and perplexity is 107.70177284660967
At time: 65.09678363800049 and batch: 650, loss is 4.759972105026245 and perplexity is 116.74266931987225
At time: 65.47656512260437 and batch: 700, loss is 4.804048223495483 and perplexity is 122.00331585405186
At time: 65.85702276229858 and batch: 750, loss is 4.74747899055481 and perplexity is 115.29326244302281
At time: 66.23719811439514 and batch: 800, loss is 4.688366041183472 and perplexity is 108.67546342472696
At time: 66.61786699295044 and batch: 850, loss is 4.640451231002808 and perplexity is 103.59108054596398
At time: 66.9984040260315 and batch: 900, loss is 4.584338979721069 and perplexity is 97.93842645442996
At time: 67.37865662574768 and batch: 950, loss is 4.655929412841797 and perplexity is 105.20695526893
At time: 67.75915312767029 and batch: 1000, loss is 4.678671398162842 and perplexity is 107.62698412982274
At time: 68.13902139663696 and batch: 1050, loss is 4.586767530441284 and perplexity is 98.17656393796936
At time: 68.51953268051147 and batch: 1100, loss is 4.739929971694946 and perplexity is 114.42618832755882
At time: 68.90015578269958 and batch: 1150, loss is 4.672464027404785 and perplexity is 106.9609727640264
At time: 69.28112888336182 and batch: 1200, loss is 4.616976661682129 and perplexity is 101.18764472294606
At time: 69.66165232658386 and batch: 1250, loss is 4.593260564804077 and perplexity is 98.81610176490177
At time: 70.04219317436218 and batch: 1300, loss is 4.669760417938233 and perplexity is 106.67218262929036
At time: 70.42308926582336 and batch: 1350, loss is 4.634387311935424 and perplexity is 102.96481335326008
At time: 70.8197660446167 and batch: 1400, loss is 4.509493598937988 and perplexity is 90.87578726119624
At time: 71.20569849014282 and batch: 1450, loss is 4.579752693176269 and perplexity is 97.49028121373142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.965316902877938 and perplexity of 143.3539723621739
Finished 6 epochs...
Completing Train Step...
At time: 72.46355271339417 and batch: 50, loss is 4.730496883392334 and perplexity is 113.35187102027942
At time: 72.8424642086029 and batch: 100, loss is 4.738943090438843 and perplexity is 114.31331897057807
At time: 73.2216305732727 and batch: 150, loss is 4.634292888641357 and perplexity is 102.95509153540051
At time: 73.60083532333374 and batch: 200, loss is 4.705980052947998 and perplexity is 110.6066322017341
At time: 73.98045587539673 and batch: 250, loss is 4.713933734893799 and perplexity is 111.4898700154812
At time: 74.35936665534973 and batch: 300, loss is 4.72308985710144 and perplexity is 112.51537253910166
At time: 74.73888492584229 and batch: 350, loss is 4.749644889831543 and perplexity is 115.54324665935151
At time: 75.11856365203857 and batch: 400, loss is 4.6208336067199705 and perplexity is 101.57867351067631
At time: 75.49761080741882 and batch: 450, loss is 4.657204046249389 and perplexity is 105.34114106951148
At time: 75.8760974407196 and batch: 500, loss is 4.641700191497803 and perplexity is 103.72054254283057
At time: 76.2529947757721 and batch: 550, loss is 4.710292825698852 and perplexity is 111.08468359368605
At time: 76.63238096237183 and batch: 600, loss is 4.609508466720581 and perplexity is 100.43477046953507
At time: 77.02428245544434 and batch: 650, loss is 4.6880392074584964 and perplexity is 108.63995042194203
At time: 77.41460466384888 and batch: 700, loss is 4.736811180114746 and perplexity is 114.0698728205692
At time: 77.7939338684082 and batch: 750, loss is 4.683665208816528 and perplexity is 108.16579715515819
At time: 78.17314648628235 and batch: 800, loss is 4.619796991348267 and perplexity is 101.47343005419454
At time: 78.55216765403748 and batch: 850, loss is 4.581345453262329 and perplexity is 97.64568356890852
At time: 78.93177199363708 and batch: 900, loss is 4.53219235420227 and perplexity is 92.96214378445121
At time: 79.31065154075623 and batch: 950, loss is 4.6032756996154784 and perplexity is 99.81073070339882
At time: 79.68948411941528 and batch: 1000, loss is 4.632155666351318 and perplexity is 102.7352885864455
At time: 80.06902027130127 and batch: 1050, loss is 4.538507404327393 and perplexity is 93.55106194888978
At time: 80.44846272468567 and batch: 1100, loss is 4.691327915191651 and perplexity is 108.99782361464132
At time: 80.82708263397217 and batch: 1150, loss is 4.632308254241943 and perplexity is 102.75096594348067
At time: 81.21924638748169 and batch: 1200, loss is 4.573299617767334 and perplexity is 96.86319457221687
At time: 81.59821057319641 and batch: 1250, loss is 4.5486988353729245 and perplexity is 94.5093560456407
At time: 81.97765731811523 and batch: 1300, loss is 4.6237150573730466 and perplexity is 101.87178954268725
At time: 82.35762095451355 and batch: 1350, loss is 4.591091575622559 and perplexity is 98.6020029821216
At time: 82.74737405776978 and batch: 1400, loss is 4.468506860733032 and perplexity is 87.22638459099967
At time: 83.13776516914368 and batch: 1450, loss is 4.5339282035827635 and perplexity is 93.12365220073654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.953808906750801 and perplexity of 141.71371156303047
Finished 7 epochs...
Completing Train Step...
At time: 84.37643909454346 and batch: 50, loss is 4.6678188610076905 and perplexity is 106.46527344179172
At time: 84.76900053024292 and batch: 100, loss is 4.685295553207397 and perplexity is 108.34228848756774
At time: 85.1475031375885 and batch: 150, loss is 4.580535078048706 and perplexity is 97.56658598091812
At time: 85.52611947059631 and batch: 200, loss is 4.657849521636963 and perplexity is 105.4091581326793
At time: 85.90547847747803 and batch: 250, loss is 4.665292234420776 and perplexity is 106.19661499404177
At time: 86.28465914726257 and batch: 300, loss is 4.675498285293579 and perplexity is 107.28601281772292
At time: 86.66446900367737 and batch: 350, loss is 4.694206304550171 and perplexity is 109.3120137540872
At time: 87.04397940635681 and batch: 400, loss is 4.570308179855346 and perplexity is 96.57386730772988
At time: 87.42264080047607 and batch: 450, loss is 4.599905500411987 and perplexity is 99.47491485928394
At time: 87.79917240142822 and batch: 500, loss is 4.598078365325928 and perplexity is 99.29332669573238
At time: 88.17675280570984 and batch: 550, loss is 4.665689144134522 and perplexity is 106.23877382817172
At time: 88.55610537528992 and batch: 600, loss is 4.557808246612549 and perplexity is 95.3742138278713
At time: 88.93500018119812 and batch: 650, loss is 4.642006893157959 and perplexity is 103.75235868420302
At time: 89.31390452384949 and batch: 700, loss is 4.693690195083618 and perplexity is 109.25561134514129
At time: 89.69514203071594 and batch: 750, loss is 4.643464155197144 and perplexity is 103.90366327643272
At time: 90.08280634880066 and batch: 800, loss is 4.582526683807373 and perplexity is 97.76109378254725
At time: 90.46251821517944 and batch: 850, loss is 4.544939537048339 and perplexity is 94.15473416415901
At time: 90.85459160804749 and batch: 900, loss is 4.491301784515381 and perplexity is 89.2375383441842
At time: 91.23436141014099 and batch: 950, loss is 4.566118631362915 and perplexity is 96.17011277271305
At time: 91.61367869377136 and batch: 1000, loss is 4.598866081237793 and perplexity is 99.37157244277664
At time: 91.99345803260803 and batch: 1050, loss is 4.5078467178344725 and perplexity is 90.72624881420836
At time: 92.37239480018616 and batch: 1100, loss is 4.658485527038574 and perplexity is 105.47622025030498
At time: 92.75175476074219 and batch: 1150, loss is 4.595828218460083 and perplexity is 99.07015330848114
At time: 93.13164019584656 and batch: 1200, loss is 4.542200345993042 and perplexity is 93.89717926559956
At time: 93.51084208488464 and batch: 1250, loss is 4.523413429260254 and perplexity is 92.14960791589256
At time: 93.89047074317932 and batch: 1300, loss is 4.589020795822144 and perplexity is 98.39803120926739
At time: 94.26937246322632 and batch: 1350, loss is 4.562146415710449 and perplexity is 95.78886205179528
At time: 94.64847683906555 and batch: 1400, loss is 4.441569118499756 and perplexity is 84.90806802131691
At time: 95.02830481529236 and batch: 1450, loss is 4.510633335113526 and perplexity is 90.97942072960645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.955043694911859 and perplexity of 141.8888060563845
Annealing...
Finished 8 epochs...
Completing Train Step...
At time: 96.25919127464294 and batch: 50, loss is 4.628981103897095 and perplexity is 102.40966612446061
At time: 96.6515645980835 and batch: 100, loss is 4.612388429641723 and perplexity is 100.72443579697052
At time: 97.03096199035645 and batch: 150, loss is 4.493183422088623 and perplexity is 89.40560912383452
At time: 97.41139554977417 and batch: 200, loss is 4.559823656082154 and perplexity is 95.56662575085252
At time: 97.79017901420593 and batch: 250, loss is 4.571312656402588 and perplexity is 96.67092222905256
At time: 98.1694450378418 and batch: 300, loss is 4.584693069458008 and perplexity is 97.97311158655164
At time: 98.54943561553955 and batch: 350, loss is 4.593034582138062 and perplexity is 98.79377356176813
At time: 98.92774963378906 and batch: 400, loss is 4.45871750831604 and perplexity is 86.37666068142556
At time: 99.30559396743774 and batch: 450, loss is 4.497518281936646 and perplexity is 89.7940111349496
At time: 99.68539237976074 and batch: 500, loss is 4.491899938583374 and perplexity is 89.29093210801902
At time: 100.06494116783142 and batch: 550, loss is 4.550225601196289 and perplexity is 94.65375990782957
At time: 100.44337630271912 and batch: 600, loss is 4.447975997924805 and perplexity is 85.45381016057962
At time: 100.83577418327332 and batch: 650, loss is 4.53031886100769 and perplexity is 92.78814288636161
At time: 101.21456575393677 and batch: 700, loss is 4.578429336547852 and perplexity is 97.36135213227404
At time: 101.59395384788513 and batch: 750, loss is 4.519912548065186 and perplexity is 91.82756712859056
At time: 101.97286558151245 and batch: 800, loss is 4.465117721557617 and perplexity is 86.93126262105483
At time: 102.35187888145447 and batch: 850, loss is 4.416362171173096 and perplexity is 82.7945444696748
At time: 102.73110675811768 and batch: 900, loss is 4.357373256683349 and perplexity is 78.05184276054837
At time: 103.1107988357544 and batch: 950, loss is 4.438717412948608 and perplexity is 84.66628013019503
At time: 103.49038410186768 and batch: 1000, loss is 4.466172456741333 and perplexity is 87.02300045336118
At time: 103.87000179290771 and batch: 1050, loss is 4.378346500396728 and perplexity is 79.70613032941743
At time: 104.24915862083435 and batch: 1100, loss is 4.519943752288818 and perplexity is 91.83043258123776
At time: 104.6283552646637 and batch: 1150, loss is 4.451107606887818 and perplexity is 85.7218375378258
At time: 105.00649571418762 and batch: 1200, loss is 4.396927051544189 and perplexity is 81.20095852103378
At time: 105.39664483070374 and batch: 1250, loss is 4.39011426448822 and perplexity is 80.64963384313744
At time: 105.78571629524231 and batch: 1300, loss is 4.449275712966919 and perplexity is 85.56494797114837
At time: 106.1657326221466 and batch: 1350, loss is 4.408157625198364 and perplexity is 82.11803185745678
At time: 106.54460525512695 and batch: 1400, loss is 4.280195684432983 and perplexity is 72.25457772008669
At time: 106.9238908290863 and batch: 1450, loss is 4.353927974700928 and perplexity is 77.78339485789073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.868297087840545 and perplexity of 130.0991806746832
Finished 9 epochs...
Completing Train Step...
At time: 108.16914558410645 and batch: 50, loss is 4.554624433517456 and perplexity is 95.071043032621
At time: 108.5495445728302 and batch: 100, loss is 4.55929407119751 and perplexity is 95.51602850932814
At time: 108.94532442092896 and batch: 150, loss is 4.4493755435943605 and perplexity is 85.57349039998222
At time: 109.34652638435364 and batch: 200, loss is 4.520790491104126 and perplexity is 91.9082219019017
At time: 109.73869109153748 and batch: 250, loss is 4.535118894577026 and perplexity is 93.2345997337711
At time: 110.1459333896637 and batch: 300, loss is 4.5496159934997555 and perplexity is 94.59607583139875
At time: 110.5776047706604 and batch: 350, loss is 4.558797197341919 and perplexity is 95.46858088069126
At time: 110.96814465522766 and batch: 400, loss is 4.428323488235474 and perplexity is 83.790822789185
At time: 111.35116791725159 and batch: 450, loss is 4.472589921951294 and perplexity is 87.58326334222153
At time: 111.7314076423645 and batch: 500, loss is 4.465780572891235 and perplexity is 86.98890422621321
At time: 112.11344361305237 and batch: 550, loss is 4.523467636108398 and perplexity is 92.15460319108327
At time: 112.49441862106323 and batch: 600, loss is 4.419355955123901 and perplexity is 83.04278485174876
At time: 112.87513494491577 and batch: 650, loss is 4.507487373352051 and perplexity is 90.69365269425485
At time: 113.25562262535095 and batch: 700, loss is 4.556159076690673 and perplexity is 95.21705516938965
At time: 113.63606429100037 and batch: 750, loss is 4.501249103546143 and perplexity is 90.12964227274122
At time: 114.01707673072815 and batch: 800, loss is 4.445857419967651 and perplexity is 85.2729612409291
At time: 114.39743041992188 and batch: 850, loss is 4.400004453659058 and perplexity is 81.45123142017492
At time: 114.77798223495483 and batch: 900, loss is 4.342740564346314 and perplexity is 76.918049612419
At time: 115.15876936912537 and batch: 950, loss is 4.425909376144409 and perplexity is 83.58878631823431
At time: 115.53917670249939 and batch: 1000, loss is 4.455108804702759 and perplexity is 86.0655146684564
At time: 115.91948127746582 and batch: 1050, loss is 4.369952058792114 and perplexity is 79.03984234321895
At time: 116.29983353614807 and batch: 1100, loss is 4.50829195022583 and perplexity is 90.7666520726791
At time: 116.68020534515381 and batch: 1150, loss is 4.441026649475098 and perplexity is 84.86202051527381
At time: 117.0606038570404 and batch: 1200, loss is 4.3888679790496825 and perplexity is 80.54918398645397
At time: 117.44094181060791 and batch: 1250, loss is 4.381429514884949 and perplexity is 79.95224467612876
At time: 117.82140851020813 and batch: 1300, loss is 4.442061710357666 and perplexity is 84.9499033473196
At time: 118.20850872993469 and batch: 1350, loss is 4.402538557052612 and perplexity is 81.65789901005027
At time: 118.60916662216187 and batch: 1400, loss is 4.279013729095459 and perplexity is 72.1692264868991
At time: 118.99904894828796 and batch: 1450, loss is 4.353259811401367 and perplexity is 77.73144020715978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8655374641092415 and perplexity of 129.7406508195512
Finished 10 epochs...
Completing Train Step...
At time: 120.24808263778687 and batch: 50, loss is 4.534080362319946 and perplexity is 93.1378228561244
At time: 120.62704849243164 and batch: 100, loss is 4.5368023872375485 and perplexity is 93.39169169260767
At time: 121.00616645812988 and batch: 150, loss is 4.430702085494995 and perplexity is 83.99036463140452
At time: 121.38523364067078 and batch: 200, loss is 4.499582147598266 and perplexity is 89.97952528344015
At time: 121.76357293128967 and batch: 250, loss is 4.5169474887847905 and perplexity is 91.55569620436441
At time: 122.1404480934143 and batch: 300, loss is 4.532474431991577 and perplexity is 92.98837003920725
At time: 122.51958560943604 and batch: 350, loss is 4.540247211456299 and perplexity is 93.71396442173577
At time: 122.89814138412476 and batch: 400, loss is 4.409874353408814 and perplexity is 82.25912727592316
At time: 123.27725958824158 and batch: 450, loss is 4.457884721755981 and perplexity is 86.30475730354628
At time: 123.66767072677612 and batch: 500, loss is 4.449414281845093 and perplexity is 85.57680543151824
At time: 124.05076813697815 and batch: 550, loss is 4.507686824798584 and perplexity is 90.71174347853264
At time: 124.44103980064392 and batch: 600, loss is 4.403129253387451 and perplexity is 81.70614828063691
At time: 124.83047366142273 and batch: 650, loss is 4.494014015197754 and perplexity is 89.47989965502111
At time: 125.22864508628845 and batch: 700, loss is 4.542244529724121 and perplexity is 93.90132808497181
At time: 125.63110589981079 and batch: 750, loss is 4.488542270660401 and perplexity is 88.99162557663412
At time: 126.0176796913147 and batch: 800, loss is 4.432213478088379 and perplexity is 84.11740302468444
At time: 126.40126705169678 and batch: 850, loss is 4.389430856704712 and perplexity is 80.59453608489476
At time: 126.8032295703888 and batch: 900, loss is 4.3322024297714234 and perplexity is 76.11173285355179
At time: 127.19125199317932 and batch: 950, loss is 4.415174942016602 and perplexity is 82.69630669939333
At time: 127.57050633430481 and batch: 1000, loss is 4.446115627288818 and perplexity is 85.29498218668147
At time: 127.94917345046997 and batch: 1050, loss is 4.3631328678131105 and perplexity is 78.50268812346718
At time: 128.3277871608734 and batch: 1100, loss is 4.4988049793243405 and perplexity is 89.9096232174393
At time: 128.70692372322083 and batch: 1150, loss is 4.430346832275391 and perplexity is 83.96053208332161
At time: 129.08619594573975 and batch: 1200, loss is 4.380799336433411 and perplexity is 79.9018763665603
At time: 129.46523571014404 and batch: 1250, loss is 4.373869433403015 and perplexity is 79.35007827330645
At time: 129.84356331825256 and batch: 1300, loss is 4.434409265518188 and perplexity is 84.30230989467091
At time: 130.22284770011902 and batch: 1350, loss is 4.393342504501343 and perplexity is 80.91041091717125
At time: 130.60141372680664 and batch: 1400, loss is 4.273547234535218 and perplexity is 71.7757901414528
At time: 130.98001766204834 and batch: 1450, loss is 4.348186140060425 and perplexity is 77.3380552236296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.864299024272169 and perplexity of 129.58007428180267
Finished 11 epochs...
Completing Train Step...
At time: 132.21026968955994 and batch: 50, loss is 4.517645397186279 and perplexity is 91.61961599643507
At time: 132.6031210422516 and batch: 100, loss is 4.52089825630188 and perplexity is 91.91812694330996
At time: 132.9822211265564 and batch: 150, loss is 4.4140482521057125 and perplexity is 82.6031860738528
At time: 133.35997009277344 and batch: 200, loss is 4.481827802658081 and perplexity is 88.39609572470101
At time: 133.7381236553192 and batch: 250, loss is 4.500567741394043 and perplexity is 90.0682522625041
At time: 134.11759305000305 and batch: 300, loss is 4.51602725982666 and perplexity is 91.47148275520546
At time: 134.49671030044556 and batch: 350, loss is 4.523354558944702 and perplexity is 92.14418319907558
At time: 134.876638174057 and batch: 400, loss is 4.393169412612915 and perplexity is 80.8964071933526
At time: 135.25646805763245 and batch: 450, loss is 4.4442699527740475 and perplexity is 85.13770060177664
At time: 135.63510370254517 and batch: 500, loss is 4.434322566986084 and perplexity is 84.29500132497573
At time: 136.01455235481262 and batch: 550, loss is 4.490950231552124 and perplexity is 89.20617213691017
At time: 136.39341187477112 and batch: 600, loss is 4.387847499847412 and perplexity is 80.46702714623902
At time: 136.79200387001038 and batch: 650, loss is 4.481413497924804 and perplexity is 88.3594803893162
At time: 137.18522572517395 and batch: 700, loss is 4.529842300415039 and perplexity is 92.74393424888059
At time: 137.56981420516968 and batch: 750, loss is 4.476187133789063 and perplexity is 87.8988862347644
At time: 137.94945096969604 and batch: 800, loss is 4.420232992172242 and perplexity is 83.11564839800536
At time: 138.3284890651703 and batch: 850, loss is 4.378903532028199 and perplexity is 79.75054153330736
At time: 138.7077877521515 and batch: 900, loss is 4.322340569496155 and perplexity is 75.36481861427323
At time: 139.10654282569885 and batch: 950, loss is 4.405541257858276 and perplexity is 81.90346174039696
At time: 139.49211835861206 and batch: 1000, loss is 4.436795320510864 and perplexity is 84.5037000104877
At time: 139.88459634780884 and batch: 1050, loss is 4.355128746032715 and perplexity is 77.87685102704039
At time: 140.26376008987427 and batch: 1100, loss is 4.488901100158691 and perplexity is 89.02356412689615
At time: 140.64250087738037 and batch: 1150, loss is 4.420296649932862 and perplexity is 83.12093952246364
At time: 141.0212140083313 and batch: 1200, loss is 4.371898670196533 and perplexity is 79.19385205162276
At time: 141.40064215660095 and batch: 1250, loss is 4.364232268333435 and perplexity is 78.58904147940139
At time: 141.77943015098572 and batch: 1300, loss is 4.425474996566773 and perplexity is 83.55248494139744
At time: 142.15839910507202 and batch: 1350, loss is 4.383635683059692 and perplexity is 80.12882748790067
At time: 142.53669214248657 and batch: 1400, loss is 4.265847516059876 and perplexity is 71.22525895148696
At time: 142.9162917137146 and batch: 1450, loss is 4.3413387966156005 and perplexity is 76.81030390743203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.863724146133814 and perplexity of 129.50560293795635
Finished 12 epochs...
Completing Train Step...
At time: 144.15220856666565 and batch: 50, loss is 4.504271030426025 and perplexity is 90.4024194100969
At time: 144.54705905914307 and batch: 100, loss is 4.506665925979615 and perplexity is 90.61918322211613
At time: 144.92681217193604 and batch: 150, loss is 4.401633453369141 and perplexity is 81.58402358237592
At time: 145.3071219921112 and batch: 200, loss is 4.466262531280518 and perplexity is 87.03083936306328
At time: 145.69921565055847 and batch: 250, loss is 4.487403535842896 and perplexity is 88.890345390705
At time: 146.0914170742035 and batch: 300, loss is 4.503055782318115 and perplexity is 90.2926247683359
At time: 146.47284841537476 and batch: 350, loss is 4.508426399230957 and perplexity is 90.77885637915898
At time: 146.85342597961426 and batch: 400, loss is 4.379781703948975 and perplexity is 79.8206069797997
At time: 147.2518961429596 and batch: 450, loss is 4.4326891040802 and perplexity is 84.15742096395914
At time: 147.6518497467041 and batch: 500, loss is 4.4220371913909915 and perplexity is 83.26574094362341
At time: 148.03653120994568 and batch: 550, loss is 4.477596712112427 and perplexity is 88.02287396412723
At time: 148.41982436180115 and batch: 600, loss is 4.37603102684021 and perplexity is 79.5217863964604
At time: 148.818421125412 and batch: 650, loss is 4.4702731800079345 and perplexity is 87.3805903836227
At time: 149.20526456832886 and batch: 700, loss is 4.51837158203125 and perplexity is 91.68617293646943
At time: 149.59739136695862 and batch: 750, loss is 4.465868940353394 and perplexity is 86.99659155456546
At time: 149.97961354255676 and batch: 800, loss is 4.409349365234375 and perplexity is 82.21595354070547
At time: 150.35839867591858 and batch: 850, loss is 4.369819951057434 and perplexity is 79.02940125838677
At time: 150.7377336025238 and batch: 900, loss is 4.313476705551148 and perplexity is 74.69974702233287
At time: 151.1168978214264 and batch: 950, loss is 4.396492986679077 and perplexity is 81.16571968644968
At time: 151.4957537651062 and batch: 1000, loss is 4.42912989616394 and perplexity is 83.85841962466378
At time: 151.8750765323639 and batch: 1050, loss is 4.348093786239624 and perplexity is 77.33091308854321
At time: 152.25537490844727 and batch: 1100, loss is 4.479361724853516 and perplexity is 88.17837264639051
At time: 152.6349859237671 and batch: 1150, loss is 4.410638046264649 and perplexity is 82.3219719777215
At time: 153.0142514705658 and batch: 1200, loss is 4.362891936302185 and perplexity is 78.48377663048468
At time: 153.39366102218628 and batch: 1250, loss is 4.356578459739685 and perplexity is 77.98983204070461
At time: 153.77288365364075 and batch: 1300, loss is 4.41806058883667 and perplexity is 82.93528366958961
At time: 154.1518828868866 and batch: 1350, loss is 4.373898391723633 and perplexity is 79.35237615158533
At time: 154.54111981391907 and batch: 1400, loss is 4.259238262176513 and perplexity is 70.75606534993584
At time: 154.93282628059387 and batch: 1450, loss is 4.334960031509399 and perplexity is 76.32190835732871
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.864311022636218 and perplexity of 129.58162904003464
Annealing...
Finished 13 epochs...
Completing Train Step...
At time: 156.2494659423828 and batch: 50, loss is 4.493203964233398 and perplexity is 89.40744572566469
At time: 156.63298988342285 and batch: 100, loss is 4.489234580993652 and perplexity is 89.05325673007424
At time: 157.01776123046875 and batch: 150, loss is 4.378467903137207 and perplexity is 79.71580745947558
At time: 157.40155053138733 and batch: 200, loss is 4.437562170028687 and perplexity is 84.56852648499353
At time: 157.78499603271484 and batch: 250, loss is 4.462848100662232 and perplexity is 86.73418534090268
At time: 158.16947221755981 and batch: 300, loss is 4.470316591262818 and perplexity is 87.38438376704087
At time: 158.55267190933228 and batch: 350, loss is 4.473977155685425 and perplexity is 87.70484611203703
At time: 158.93605971336365 and batch: 400, loss is 4.345060224533081 and perplexity is 77.0966804510726
At time: 159.34142065048218 and batch: 450, loss is 4.399291706085205 and perplexity is 81.39319793666196
At time: 159.72536754608154 and batch: 500, loss is 4.380212211608887 and perplexity is 79.85497776043465
At time: 160.10900712013245 and batch: 550, loss is 4.436784934997559 and perplexity is 84.50282240074411
At time: 160.49277305603027 and batch: 600, loss is 4.336110420227051 and perplexity is 76.40975874096934
At time: 160.8786449432373 and batch: 650, loss is 4.431859521865845 and perplexity is 84.08763441516356
At time: 161.26219487190247 and batch: 700, loss is 4.4744790744781495 and perplexity is 87.74887787177313
At time: 161.64610981941223 and batch: 750, loss is 4.418453893661499 and perplexity is 82.96790893222148
At time: 162.03616285324097 and batch: 800, loss is 4.365467190742493 and perplexity is 78.68615279796091
At time: 162.41421461105347 and batch: 850, loss is 4.319894762039184 and perplexity is 75.18071601044859
At time: 162.79677033424377 and batch: 900, loss is 4.261810212135315 and perplexity is 70.93828063314763
At time: 163.18244004249573 and batch: 950, loss is 4.345641679763794 and perplexity is 77.14152175453334
At time: 163.56783747673035 and batch: 1000, loss is 4.380589876174927 and perplexity is 79.88514185155233
At time: 163.9516956806183 and batch: 1050, loss is 4.294313597679138 and perplexity is 73.28189631405158
At time: 164.35480189323425 and batch: 1100, loss is 4.423761291503906 and perplexity is 83.40942324272875
At time: 164.7552351951599 and batch: 1150, loss is 4.35070122718811 and perplexity is 77.53281198324855
At time: 165.13887238502502 and batch: 1200, loss is 4.307939219474792 and perplexity is 74.28724138946895
At time: 165.52297925949097 and batch: 1250, loss is 4.297630543708801 and perplexity is 73.52537198367529
At time: 165.9083616733551 and batch: 1300, loss is 4.357965955734253 and perplexity is 78.09811772588317
At time: 166.29059505462646 and batch: 1350, loss is 4.305839757919312 and perplexity is 74.13144178697397
At time: 166.67513012886047 and batch: 1400, loss is 4.19073646068573 and perplexity is 66.07143205924444
At time: 167.05891752243042 and batch: 1450, loss is 4.266969218254089 and perplexity is 71.30519730586839
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.833304641593216 and perplexity of 125.62542244993219
Finished 14 epochs...
Completing Train Step...
At time: 168.48056817054749 and batch: 50, loss is 4.467819828987121 and perplexity is 87.16647787696819
At time: 168.86827898025513 and batch: 100, loss is 4.469055252075195 and perplexity is 87.27423190344443
At time: 169.26265501976013 and batch: 150, loss is 4.359574213027954 and perplexity is 78.22382064756634
At time: 169.64116096496582 and batch: 200, loss is 4.421510763168335 and perplexity is 83.22191904316492
At time: 170.02153420448303 and batch: 250, loss is 4.446029300689697 and perplexity is 85.28761927875921
At time: 170.40043711662292 and batch: 300, loss is 4.456372652053833 and perplexity is 86.17435710681477
At time: 170.7791883945465 and batch: 350, loss is 4.462451591491699 and perplexity is 86.69980125826886
At time: 171.1572847366333 and batch: 400, loss is 4.335036358833313 and perplexity is 76.32773402667566
At time: 171.53626155853271 and batch: 450, loss is 4.387066707611084 and perplexity is 80.40422363759944
At time: 171.9145631790161 and batch: 500, loss is 4.36990177154541 and perplexity is 79.0358677471042
At time: 172.29308080673218 and batch: 550, loss is 4.425783491134643 and perplexity is 83.5782644053418
At time: 172.67097187042236 and batch: 600, loss is 4.326354017257691 and perplexity is 75.66789916899717
At time: 173.04939723014832 and batch: 650, loss is 4.423034324645996 and perplexity is 83.3488093911939
At time: 173.42792081832886 and batch: 700, loss is 4.466199045181274 and perplexity is 87.02531428994276
At time: 173.80794048309326 and batch: 750, loss is 4.410560417175293 and perplexity is 82.31558164604392
At time: 174.18665671348572 and batch: 800, loss is 4.359037709236145 and perplexity is 78.18186452699443
At time: 174.56527304649353 and batch: 850, loss is 4.31489408493042 and perplexity is 74.8056999734252
At time: 174.94428730010986 and batch: 900, loss is 4.257901782989502 and perplexity is 70.66156450451365
At time: 175.32413983345032 and batch: 950, loss is 4.341702651977539 and perplexity is 76.83825683346352
At time: 175.70376777648926 and batch: 1000, loss is 4.378009567260742 and perplexity is 79.67927921673704
At time: 176.08276748657227 and batch: 1050, loss is 4.291608672142029 and perplexity is 73.08394208772127
At time: 176.46217608451843 and batch: 1100, loss is 4.422542762756348 and perplexity is 83.3078483612151
At time: 176.84085083007812 and batch: 1150, loss is 4.349945812225342 and perplexity is 77.47426465351955
At time: 177.22084164619446 and batch: 1200, loss is 4.307645001411438 and perplexity is 74.26538795617047
At time: 177.5995626449585 and batch: 1250, loss is 4.29892068862915 and perplexity is 73.62029158571204
At time: 177.9788043498993 and batch: 1300, loss is 4.35954140663147 and perplexity is 78.2212544479858
At time: 178.37024331092834 and batch: 1350, loss is 4.306392335891724 and perplexity is 74.17241650859027
At time: 178.74987196922302 and batch: 1400, loss is 4.192040767669678 and perplexity is 66.15766571487322
At time: 179.12785172462463 and batch: 1450, loss is 4.267685036659241 and perplexity is 71.35625715109117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.831968649839744 and perplexity of 125.45769998437498
Finished 15 epochs...
Completing Train Step...
At time: 180.38780808448792 and batch: 50, loss is 4.460052480697632 and perplexity is 86.49204814024829
At time: 180.78129196166992 and batch: 100, loss is 4.460973949432373 and perplexity is 86.57178459009394
At time: 181.16118836402893 and batch: 150, loss is 4.352050790786743 and perplexity is 77.63751808187845
At time: 181.54050850868225 and batch: 200, loss is 4.413753385543823 and perplexity is 82.57883274704143
At time: 181.9195680618286 and batch: 250, loss is 4.438109650611877 and perplexity is 84.6148387875795
At time: 182.29924154281616 and batch: 300, loss is 4.448854207992554 and perplexity is 85.52888951988935
At time: 182.67888379096985 and batch: 350, loss is 4.45618634223938 and perplexity is 86.15830347385268
At time: 183.0597264766693 and batch: 400, loss is 4.330258932113647 and perplexity is 75.9639535299221
At time: 183.43843722343445 and batch: 450, loss is 4.379525194168091 and perplexity is 79.80013483915765
At time: 183.81810975074768 and batch: 500, loss is 4.363726100921631 and perplexity is 78.54927233345153
At time: 184.19728231430054 and batch: 550, loss is 4.4194419479370115 and perplexity is 83.04992624147637
At time: 184.57646894454956 and batch: 600, loss is 4.320988569259644 and perplexity is 75.26299421050155
At time: 184.95592880249023 and batch: 650, loss is 4.417735195159912 and perplexity is 82.90830144286444
At time: 185.33650851249695 and batch: 700, loss is 4.46032883644104 and perplexity is 86.51595401762204
At time: 185.7154631614685 and batch: 750, loss is 4.4058127784729 and perplexity is 81.92570323804446
At time: 186.09476613998413 and batch: 800, loss is 4.354709749221802 and perplexity is 77.84422770982627
At time: 186.47433590888977 and batch: 850, loss is 4.31088198184967 and perplexity is 74.50617306231517
At time: 186.8537871837616 and batch: 900, loss is 4.254760575294495 and perplexity is 70.43995010500518
At time: 187.23287057876587 and batch: 950, loss is 4.339056363105774 and perplexity is 76.63518941550758
At time: 187.61216711997986 and batch: 1000, loss is 4.3755974864959715 and perplexity is 79.48731796607906
At time: 187.99143171310425 and batch: 1050, loss is 4.289036016464234 and perplexity is 72.89616391701051
At time: 188.3707399368286 and batch: 1100, loss is 4.421276874542237 and perplexity is 83.20245665896249
At time: 188.77254486083984 and batch: 1150, loss is 4.348873081207276 and perplexity is 77.39120016761466
At time: 189.15263652801514 and batch: 1200, loss is 4.306451888084411 and perplexity is 74.17683377015778
At time: 189.53245449066162 and batch: 1250, loss is 4.298509421348572 and perplexity is 73.59002019383942
At time: 189.9285774230957 and batch: 1300, loss is 4.359660539627075 and perplexity is 78.2305737354545
At time: 190.31559801101685 and batch: 1350, loss is 4.30551362991333 and perplexity is 74.10726938954554
At time: 190.6952633857727 and batch: 1400, loss is 4.190870070457459 and perplexity is 66.08026043796539
At time: 191.07379579544067 and batch: 1450, loss is 4.266468834877014 and perplexity is 71.26952629577202
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.831592005542201 and perplexity of 125.41045595474874
Finished 16 epochs...
Completing Train Step...
At time: 192.313374042511 and batch: 50, loss is 4.454574918746948 and perplexity is 86.01957776252088
At time: 192.7083957195282 and batch: 100, loss is 4.45485403060913 and perplexity is 86.04359019797624
At time: 193.0885820388794 and batch: 150, loss is 4.346315746307373 and perplexity is 77.19353780263818
At time: 193.46981525421143 and batch: 200, loss is 4.40770393371582 and perplexity is 82.0807840559838
At time: 193.8656768798828 and batch: 250, loss is 4.43230263710022 and perplexity is 84.12490318356517
At time: 194.25852274894714 and batch: 300, loss is 4.443154888153076 and perplexity is 85.04281947305071
At time: 194.64079761505127 and batch: 350, loss is 4.450555925369263 and perplexity is 85.67455942674876
At time: 195.02128982543945 and batch: 400, loss is 4.326048579216003 and perplexity is 75.64479084331691
At time: 195.40204882621765 and batch: 450, loss is 4.373693075180054 and perplexity is 79.33608546841971
At time: 195.7826042175293 and batch: 500, loss is 4.358518581390381 and perplexity is 78.14128867702276
At time: 196.1632571220398 and batch: 550, loss is 4.413914537429809 and perplexity is 82.59214155402199
At time: 196.54354739189148 and batch: 600, loss is 4.316048307418823 and perplexity is 74.89209224295425
At time: 196.92439794540405 and batch: 650, loss is 4.413328971862793 and perplexity is 82.54379259694558
At time: 197.30540990829468 and batch: 700, loss is 4.456108264923095 and perplexity is 86.1515767273484
At time: 197.71184921264648 and batch: 750, loss is 4.401651887893677 and perplexity is 81.58552755892292
At time: 198.10756134986877 and batch: 800, loss is 4.351250495910644 and perplexity is 77.57541002965738
At time: 198.5183002948761 and batch: 850, loss is 4.307827758789062 and perplexity is 74.27896174403874
At time: 198.9028673171997 and batch: 900, loss is 4.252454099655151 and perplexity is 70.27766929635952
At time: 199.28739428520203 and batch: 950, loss is 4.33643521785736 and perplexity is 76.43458048034377
At time: 199.67261242866516 and batch: 1000, loss is 4.373523569107055 and perplexity is 79.32263865981496
At time: 200.0564727783203 and batch: 1050, loss is 4.286652870178223 and perplexity is 72.72264853310035
At time: 200.43554782867432 and batch: 1100, loss is 4.4190602874755855 and perplexity is 83.01823541625784
At time: 200.81458950042725 and batch: 1150, loss is 4.347133455276489 and perplexity is 77.25668546554373
At time: 201.1932635307312 and batch: 1200, loss is 4.304631471633911 and perplexity is 74.04192387506941
At time: 201.57247638702393 and batch: 1250, loss is 4.297799205780029 and perplexity is 73.53777397104487
At time: 201.9545795917511 and batch: 1300, loss is 4.358714780807495 and perplexity is 78.15662145640572
At time: 202.33472061157227 and batch: 1350, loss is 4.303475980758667 and perplexity is 73.95641851749008
At time: 202.71542525291443 and batch: 1400, loss is 4.189208717346191 and perplexity is 65.97056893508311
At time: 203.09519219398499 and batch: 1450, loss is 4.2638896942138675 and perplexity is 71.08594900005599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.831357254941239 and perplexity of 125.38101923012607
Finished 17 epochs...
Completing Train Step...
At time: 204.35668873786926 and batch: 50, loss is 4.449818820953369 and perplexity is 85.61143159942392
At time: 204.736478805542 and batch: 100, loss is 4.449840803146362 and perplexity is 85.61331354712034
At time: 205.11585402488708 and batch: 150, loss is 4.341605110168457 and perplexity is 76.83076225640849
At time: 205.49585509300232 and batch: 200, loss is 4.402778539657593 and perplexity is 81.67749783696668
At time: 205.87517476081848 and batch: 250, loss is 4.426928286552429 and perplexity is 83.67399920738539
At time: 206.25526571273804 and batch: 300, loss is 4.438159627914429 and perplexity is 84.61906771465225
At time: 206.63352847099304 and batch: 350, loss is 4.445862360000611 and perplexity is 85.2733824932087
At time: 207.01256895065308 and batch: 400, loss is 4.322830300331116 and perplexity is 75.4017361289047
At time: 207.39207768440247 and batch: 450, loss is 4.368839817047119 and perplexity is 78.95197980229771
At time: 207.77239561080933 and batch: 500, loss is 4.353832883834839 and perplexity is 77.77599871916455
At time: 208.17439079284668 and batch: 550, loss is 4.409680233001709 and perplexity is 82.24316065042237
At time: 208.5532329082489 and batch: 600, loss is 4.311887426376343 and perplexity is 74.58112255869047
At time: 208.93255591392517 and batch: 650, loss is 4.409278650283813 and perplexity is 82.21013984917532
At time: 209.31139469146729 and batch: 700, loss is 4.4520130443573 and perplexity is 85.79948845020327
At time: 209.69098019599915 and batch: 750, loss is 4.397644691467285 and perplexity is 81.25925248519827
At time: 210.08891463279724 and batch: 800, loss is 4.347364926338196 and perplexity is 77.2745702223744
At time: 210.47938537597656 and batch: 850, loss is 4.304871411323547 and perplexity is 74.05969160281035
At time: 210.85939240455627 and batch: 900, loss is 4.2496133089065555 and perplexity is 70.07830844888682
At time: 211.23922443389893 and batch: 950, loss is 4.3336086225509645 and perplexity is 76.21883590885172
At time: 211.61836791038513 and batch: 1000, loss is 4.371177473068237 and perplexity is 79.13675826335721
At time: 211.99849891662598 and batch: 1050, loss is 4.284304246902466 and perplexity is 72.55205084135416
At time: 212.3782832622528 and batch: 1100, loss is 4.416685419082642 and perplexity is 82.82131195913088
At time: 212.75755262374878 and batch: 1150, loss is 4.345120553970337 and perplexity is 77.10133179072344
At time: 213.13698744773865 and batch: 1200, loss is 4.302509894371033 and perplexity is 73.88500472978062
At time: 213.51620984077454 and batch: 1250, loss is 4.296599721908569 and perplexity is 73.44961947773943
At time: 213.89405941963196 and batch: 1300, loss is 4.357333393096924 and perplexity is 78.0487313961843
At time: 214.27694082260132 and batch: 1350, loss is 4.301661596298218 and perplexity is 73.82235479932302
At time: 214.66776823997498 and batch: 1400, loss is 4.187048225402832 and perplexity is 65.82819390783034
At time: 215.04639172554016 and batch: 1450, loss is 4.261281924247742 and perplexity is 70.9008146959956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.831405248397436 and perplexity of 125.38703684298227
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 216.30340433120728 and batch: 50, loss is 4.44690927028656 and perplexity is 85.36270282148567
At time: 216.68267703056335 and batch: 100, loss is 4.445882768630981 and perplexity is 85.27512282391127
At time: 217.0630223751068 and batch: 150, loss is 4.335008935928345 and perplexity is 76.32564092717858
At time: 217.4421033859253 and batch: 200, loss is 4.393838796615601 and perplexity is 80.95057608207372
At time: 217.84343600273132 and batch: 250, loss is 4.420200147628784 and perplexity is 83.11291854731016
At time: 218.22281670570374 and batch: 300, loss is 4.429056558609009 and perplexity is 83.85226987871454
At time: 218.60240721702576 and batch: 350, loss is 4.435418319702149 and perplexity is 84.38741842552584
At time: 218.9819450378418 and batch: 400, loss is 4.312778472900391 and perplexity is 74.64760742486155
At time: 219.36077570915222 and batch: 450, loss is 4.358543834686279 and perplexity is 78.14326202702426
At time: 219.73999452590942 and batch: 500, loss is 4.338745050430298 and perplexity is 76.61133562284165
At time: 220.11965990066528 and batch: 550, loss is 4.394701681137085 and perplexity is 81.02045722652318
At time: 220.49896597862244 and batch: 600, loss is 4.297301692962646 and perplexity is 73.50119708542167
At time: 220.879408121109 and batch: 650, loss is 4.395329723358154 and perplexity is 81.07135747651171
At time: 221.25788140296936 and batch: 700, loss is 4.435477275848388 and perplexity is 84.39239372916823
At time: 221.6376473903656 and batch: 750, loss is 4.38144401550293 and perplexity is 79.95340404149127
At time: 222.01880884170532 and batch: 800, loss is 4.330706615447998 and perplexity is 75.99796893942666
At time: 222.39885878562927 and batch: 850, loss is 4.285819616317749 and perplexity is 72.6620773445592
At time: 222.78103041648865 and batch: 900, loss is 4.229509654045105 and perplexity is 68.68354521682498
At time: 223.16217398643494 and batch: 950, loss is 4.3114615106582646 and perplexity is 74.5493640500249
At time: 223.54378843307495 and batch: 1000, loss is 4.351686296463012 and perplexity is 77.60922480391193
At time: 223.92483973503113 and batch: 1050, loss is 4.261985669136047 and perplexity is 70.95072834309158
At time: 224.30577063560486 and batch: 1100, loss is 4.397664594650268 and perplexity is 81.26086981906458
At time: 224.6871783733368 and batch: 1150, loss is 4.320025935173034 and perplexity is 75.19057834739546
At time: 225.06842613220215 and batch: 1200, loss is 4.280288300514221 and perplexity is 72.26126996582663
At time: 225.44838547706604 and batch: 1250, loss is 4.273356566429138 and perplexity is 71.7621060920815
At time: 225.82966661453247 and batch: 1300, loss is 4.330914287567139 and perplexity is 76.01375323760935
At time: 226.21042490005493 and batch: 1350, loss is 4.273316688537598 and perplexity is 71.75924442765702
At time: 226.60834312438965 and batch: 1400, loss is 4.158002200126648 and perplexity is 63.9436482963658
At time: 226.9967315196991 and batch: 1450, loss is 4.232803678512573 and perplexity is 68.91016353350962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.821778908754006 and perplexity of 124.18580962614158
Finished 19 epochs...
Completing Train Step...
At time: 228.28060603141785 and batch: 50, loss is 4.4375182628631595 and perplexity is 84.56481340221882
At time: 228.67716193199158 and batch: 100, loss is 4.43908052444458 and perplexity is 84.69702901212987
At time: 229.0591070652008 and batch: 150, loss is 4.3274658203125 and perplexity is 75.7520737545542
At time: 229.44118285179138 and batch: 200, loss is 4.386912021636963 and perplexity is 80.3917871938391
At time: 229.82389378547668 and batch: 250, loss is 4.412685599327087 and perplexity is 82.49070326773516
At time: 230.20641565322876 and batch: 300, loss is 4.423868589401245 and perplexity is 83.41837337861772
At time: 230.5997588634491 and batch: 350, loss is 4.43080265045166 and perplexity is 83.99881154350852
At time: 230.99279761314392 and batch: 400, loss is 4.309381198883057 and perplexity is 74.39443933188737
At time: 231.39153003692627 and batch: 450, loss is 4.353583345413208 and perplexity is 77.75659304053531
At time: 231.7781331539154 and batch: 500, loss is 4.334089183807373 and perplexity is 76.25547253076357
At time: 232.1601688861847 and batch: 550, loss is 4.390402326583862 and perplexity is 80.67286929214043
At time: 232.54178738594055 and batch: 600, loss is 4.29380319595337 and perplexity is 73.24450265141206
At time: 232.92329216003418 and batch: 650, loss is 4.391473436355591 and perplexity is 80.75932508430886
At time: 233.3057723045349 and batch: 700, loss is 4.43218111038208 and perplexity is 84.11468038135186
At time: 233.6876540184021 and batch: 750, loss is 4.378464813232422 and perplexity is 79.71556114560119
At time: 234.06920075416565 and batch: 800, loss is 4.327921314239502 and perplexity is 75.78658622362055
At time: 234.4521508216858 and batch: 850, loss is 4.28396399974823 and perplexity is 72.5273694116526
At time: 234.84591722488403 and batch: 900, loss is 4.227253808975219 and perplexity is 68.52878040831153
At time: 235.23959589004517 and batch: 950, loss is 4.309642119407654 and perplexity is 74.41385290061406
At time: 235.6267454624176 and batch: 1000, loss is 4.349595546722412 and perplexity is 77.44713284319255
At time: 236.00848722457886 and batch: 1050, loss is 4.261450190544128 and perplexity is 70.91274591727831
At time: 236.39077305793762 and batch: 1100, loss is 4.397097387313843 and perplexity is 81.2147911268604
At time: 236.79559636116028 and batch: 1150, loss is 4.3202190113067624 and perplexity is 75.20509725513773
At time: 237.19890117645264 and batch: 1200, loss is 4.28081579208374 and perplexity is 72.29939723155792
At time: 237.60810208320618 and batch: 1250, loss is 4.274223532676697 and perplexity is 71.8243483930055
At time: 237.99456977844238 and batch: 1300, loss is 4.330521755218506 and perplexity is 75.98392123591844
At time: 238.38584637641907 and batch: 1350, loss is 4.273835563659668 and perplexity is 71.79648817596073
At time: 238.7767014503479 and batch: 1400, loss is 4.15941367149353 and perplexity is 64.03396665092102
At time: 239.16487956047058 and batch: 1450, loss is 4.2344195890426635 and perplexity is 69.02160620884035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.821175338875534 and perplexity of 124.11087742780127
Finished 20 epochs...
Completing Train Step...
At time: 240.42477583885193 and batch: 50, loss is 4.434521307945252 and perplexity is 84.31175585924308
At time: 240.84117007255554 and batch: 100, loss is 4.436186065673828 and perplexity is 84.45223140285003
At time: 241.22819566726685 and batch: 150, loss is 4.323917493820191 and perplexity is 75.48375698367963
At time: 241.6087954044342 and batch: 200, loss is 4.383475866317749 and perplexity is 80.11602258300215
At time: 241.98946022987366 and batch: 250, loss is 4.409056520462036 and perplexity is 82.19188055350446
At time: 242.37157130241394 and batch: 300, loss is 4.4212191295623775 and perplexity is 83.1976522734944
At time: 242.7537965774536 and batch: 350, loss is 4.428885450363159 and perplexity is 83.8379232913498
At time: 243.13639903068542 and batch: 400, loss is 4.308141360282898 and perplexity is 74.30225939029962
At time: 243.5207839012146 and batch: 450, loss is 4.35159631729126 and perplexity is 77.6022419043062
At time: 243.9025056362152 and batch: 500, loss is 4.331501941680909 and perplexity is 76.05843616016824
At time: 244.28496050834656 and batch: 550, loss is 4.387979164123535 and perplexity is 80.47762247661791
At time: 244.6804928779602 and batch: 600, loss is 4.29175295829773 and perplexity is 73.09448784955397
At time: 245.07253003120422 and batch: 650, loss is 4.3890305519104 and perplexity is 80.56228016223564
At time: 245.45550727844238 and batch: 700, loss is 4.430382633209229 and perplexity is 83.96353800258275
At time: 245.83837890625 and batch: 750, loss is 4.376780223846436 and perplexity is 79.58138620396925
At time: 246.23770475387573 and batch: 800, loss is 4.326029167175293 and perplexity is 75.64332243780999
At time: 246.62777376174927 and batch: 850, loss is 4.283021736145019 and perplexity is 72.45906169820947
At time: 247.018714427948 and batch: 900, loss is 4.225795526504516 and perplexity is 68.42891891992944
At time: 247.4301950931549 and batch: 950, loss is 4.3080813550949095 and perplexity is 74.29780100302148
At time: 247.8303186893463 and batch: 1000, loss is 4.348126907348632 and perplexity is 77.33347441656211
At time: 248.2212791442871 and batch: 1050, loss is 4.260883555412293 and perplexity is 70.87257564616493
At time: 248.60290622711182 and batch: 1100, loss is 4.396580944061279 and perplexity is 81.17285912465636
At time: 248.98443865776062 and batch: 1150, loss is 4.3200502109527585 and perplexity is 75.19240367946834
At time: 249.36687445640564 and batch: 1200, loss is 4.2808478307724 and perplexity is 72.30171364654333
At time: 249.75046062469482 and batch: 1250, loss is 4.274179196357727 and perplexity is 71.82116403637718
At time: 250.14030003547668 and batch: 1300, loss is 4.33010043144226 and perplexity is 75.95191414643679
At time: 250.53935527801514 and batch: 1350, loss is 4.273769464492798 and perplexity is 71.79174264474763
At time: 250.9276168346405 and batch: 1400, loss is 4.159444975852966 and perplexity is 64.03597122460496
At time: 251.30948400497437 and batch: 1450, loss is 4.23472291469574 and perplexity is 69.04254540815765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.820963019998665 and perplexity of 124.08452914291665
Finished 21 epochs...
Completing Train Step...
At time: 252.5931532382965 and batch: 50, loss is 4.432234320640564 and perplexity is 84.11915626431762
At time: 252.97543263435364 and batch: 100, loss is 4.434283990859985 and perplexity is 84.29174961309475
At time: 253.35856676101685 and batch: 150, loss is 4.321507377624512 and perplexity is 75.30205141218838
At time: 253.7415587902069 and batch: 200, loss is 4.380989484786987 and perplexity is 79.91707102137259
At time: 254.1246576309204 and batch: 250, loss is 4.406687455177307 and perplexity is 81.99739309031021
At time: 254.5263204574585 and batch: 300, loss is 4.418905553817749 and perplexity is 83.0053906948057
At time: 254.91899132728577 and batch: 350, loss is 4.4265514087677005 and perplexity is 83.64247027757453
At time: 255.30246543884277 and batch: 400, loss is 4.307235927581787 and perplexity is 74.23501414249841
At time: 255.6842498779297 and batch: 450, loss is 4.349497022628785 and perplexity is 77.43950281050232
At time: 256.06505012512207 and batch: 500, loss is 4.329023857116699 and perplexity is 75.87019026449926
At time: 256.44850635528564 and batch: 550, loss is 4.386077852249145 and perplexity is 80.32475478800748
At time: 256.84537982940674 and batch: 600, loss is 4.289749841690064 and perplexity is 72.94821761409145
At time: 257.2602834701538 and batch: 650, loss is 4.387070894241333 and perplexity is 80.4045602610589
At time: 257.65094900131226 and batch: 700, loss is 4.428850984573364 and perplexity is 83.83503380090332
At time: 258.03604674339294 and batch: 750, loss is 4.375296659469605 and perplexity is 79.46340962889875
At time: 258.4194858074188 and batch: 800, loss is 4.324495482444763 and perplexity is 75.52739834744713
At time: 258.80251908302307 and batch: 850, loss is 4.2819429063797 and perplexity is 72.38093285711966
At time: 259.1858551502228 and batch: 900, loss is 4.224498739242554 and perplexity is 68.3402386816534
At time: 259.56911182403564 and batch: 950, loss is 4.306761426925659 and perplexity is 74.1997979352976
At time: 259.9505310058594 and batch: 1000, loss is 4.346835956573487 and perplexity is 77.23370512030041
At time: 260.33138847351074 and batch: 1050, loss is 4.260308179855347 and perplexity is 70.8318090276629
At time: 260.71443939208984 and batch: 1100, loss is 4.396003952026367 and perplexity is 81.12603654091838
At time: 261.09786438941956 and batch: 1150, loss is 4.319664931297302 and perplexity is 75.16343915616483
At time: 261.4808392524719 and batch: 1200, loss is 4.28080111503601 and perplexity is 72.29833609764107
At time: 261.8632581233978 and batch: 1250, loss is 4.273943705558777 and perplexity is 71.80425280437466
At time: 262.24642872810364 and batch: 1300, loss is 4.329501724243164 and perplexity is 75.90645479842951
At time: 262.62954568862915 and batch: 1350, loss is 4.273290147781372 and perplexity is 71.75733990831753
At time: 263.0121557712555 and batch: 1400, loss is 4.1590937852859495 and perplexity is 64.01348634403121
At time: 263.39474654197693 and batch: 1450, loss is 4.234385318756104 and perplexity is 69.0192408591476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.820799216245994 and perplexity of 124.06420529600123
Finished 22 epochs...
Completing Train Step...
At time: 264.66557455062866 and batch: 50, loss is 4.43034749507904 and perplexity is 83.9605877326871
At time: 265.0479545593262 and batch: 100, loss is 4.4325346183776855 and perplexity is 84.14442084985143
At time: 265.43084192276 and batch: 150, loss is 4.318937187194824 and perplexity is 75.10875930547968
At time: 265.812846660614 and batch: 200, loss is 4.378564043045044 and perplexity is 79.72347169827155
At time: 266.19664311408997 and batch: 250, loss is 4.404514665603638 and perplexity is 81.8194234248687
At time: 266.5906093120575 and batch: 300, loss is 4.4170627021789555 and perplexity is 82.8525649353867
At time: 266.9787256717682 and batch: 350, loss is 4.425145959854126 and perplexity is 83.52499762883431
At time: 267.38443970680237 and batch: 400, loss is 4.306337742805481 and perplexity is 74.1683673179889
At time: 267.77581119537354 and batch: 450, loss is 4.34788685798645 and perplexity is 77.3149127932951
At time: 268.15864419937134 and batch: 500, loss is 4.326833066940307 and perplexity is 75.70415653592501
At time: 268.5415081977844 and batch: 550, loss is 4.384322595596314 and perplexity is 80.18388789272302
At time: 268.94222378730774 and batch: 600, loss is 4.287912130355835 and perplexity is 72.81428295208693
At time: 269.34838366508484 and batch: 650, loss is 4.3853678703308105 and perplexity is 80.26774590454627
At time: 269.74199962615967 and batch: 700, loss is 4.427451333999634 and perplexity is 83.71777612677316
At time: 270.12696266174316 and batch: 750, loss is 4.373954916000367 and perplexity is 79.35686161402198
At time: 270.5088231563568 and batch: 800, loss is 4.323011856079102 and perplexity is 75.4154269902967
At time: 270.88941764831543 and batch: 850, loss is 4.281067938804626 and perplexity is 72.31762958600947
At time: 271.2696123123169 and batch: 900, loss is 4.223157567977905 and perplexity is 68.2486441530188
At time: 271.64853596687317 and batch: 950, loss is 4.305555911064148 and perplexity is 74.11040279642086
At time: 272.0286386013031 and batch: 1000, loss is 4.345386533737183 and perplexity is 77.12184191249443
At time: 272.4083993434906 and batch: 1050, loss is 4.259660954475403 and perplexity is 70.78597971569961
At time: 272.78916239738464 and batch: 1100, loss is 4.395523185729981 and perplexity is 81.08704325087093
At time: 273.1717538833618 and batch: 1150, loss is 4.319037590026856 and perplexity is 75.1163008162125
At time: 273.5676658153534 and batch: 1200, loss is 4.280639104843139 and perplexity is 72.28662397903256
At time: 273.9516031742096 and batch: 1250, loss is 4.27350040435791 and perplexity is 71.77242894717736
At time: 274.3319876194 and batch: 1300, loss is 4.329022397994995 and perplexity is 75.87007956073876
At time: 274.7118561267853 and batch: 1350, loss is 4.272751331329346 and perplexity is 71.71868628755985
At time: 275.0925233364105 and batch: 1400, loss is 4.158687744140625 and perplexity is 63.98749951093865
At time: 275.4727141857147 and batch: 1450, loss is 4.234007477760315 and perplexity is 68.99316748655751
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.820710532685631 and perplexity of 124.05320332841603
Finished 23 epochs...
Completing Train Step...
At time: 276.7107689380646 and batch: 50, loss is 4.428583011627198 and perplexity is 83.8125712897108
At time: 277.10652112960815 and batch: 100, loss is 4.430954484939575 and perplexity is 84.0115664283359
At time: 277.50214290618896 and batch: 150, loss is 4.317115154266357 and perplexity is 74.97203327030324
At time: 277.9060618877411 and batch: 200, loss is 4.376410636901856 and perplexity is 79.55197939711735
At time: 278.3114650249481 and batch: 250, loss is 4.402648138999939 and perplexity is 81.66684773193865
At time: 278.71824645996094 and batch: 300, loss is 4.415330286026001 and perplexity is 82.70915407309394
At time: 279.11022877693176 and batch: 350, loss is 4.423840169906616 and perplexity is 83.41600270429038
At time: 279.4928410053253 and batch: 400, loss is 4.305572962760925 and perplexity is 74.11166651531161
At time: 279.87495517730713 and batch: 450, loss is 4.346555976867676 and perplexity is 77.21208427710206
At time: 280.2581744194031 and batch: 500, loss is 4.32507643699646 and perplexity is 75.57128908132124
At time: 280.6401858329773 and batch: 550, loss is 4.382768249511718 and perplexity is 80.05935119216909
At time: 281.02188634872437 and batch: 600, loss is 4.286400833129883 and perplexity is 72.7043220409911
At time: 281.4040710926056 and batch: 650, loss is 4.383862810134888 and perplexity is 80.14702898107454
At time: 281.78587651252747 and batch: 700, loss is 4.426074876785278 and perplexity is 83.60262146077037
At time: 282.1674835681915 and batch: 750, loss is 4.372765216827393 and perplexity is 79.26250695934631
At time: 282.54953622817993 and batch: 800, loss is 4.321779136657715 and perplexity is 75.32251820577042
At time: 282.93079233169556 and batch: 850, loss is 4.279913125038147 and perplexity is 72.23416439445622
At time: 283.3108808994293 and batch: 900, loss is 4.2222138786315915 and perplexity is 68.18426901447488
At time: 283.6926407814026 and batch: 950, loss is 4.304324016571045 and perplexity is 74.01916280989136
At time: 284.0743365287781 and batch: 1000, loss is 4.3442502689361575 and perplexity is 77.034260845204
At time: 284.45619344711304 and batch: 1050, loss is 4.258856644630432 and perplexity is 70.72906874542328
At time: 284.8381655216217 and batch: 1100, loss is 4.395047998428344 and perplexity is 81.04852087098864
At time: 285.2206230163574 and batch: 1150, loss is 4.3183322477340695 and perplexity is 75.06333679344765
At time: 285.6023232936859 and batch: 1200, loss is 4.280165152549744 and perplexity is 72.25237168543359
At time: 285.9841115474701 and batch: 1250, loss is 4.2729562520980835 and perplexity is 71.73338444181385
At time: 286.3657383918762 and batch: 1300, loss is 4.32830249786377 and perplexity is 75.81548033585949
At time: 286.74844098091125 and batch: 1350, loss is 4.272298822402954 and perplexity is 71.68624028343253
At time: 287.1309115886688 and batch: 1400, loss is 4.158190650939941 and perplexity is 63.955699664401564
At time: 287.5328314304352 and batch: 1450, loss is 4.233322200775146 and perplexity is 68.94590425279783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.820777827857906 and perplexity of 124.06155179100782
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 288.82439398765564 and batch: 50, loss is 4.427296729087829 and perplexity is 83.7048339478666
At time: 289.2179763317108 and batch: 100, loss is 4.429783811569214 and perplexity is 83.91327387018171
At time: 289.5987436771393 and batch: 150, loss is 4.314967679977417 and perplexity is 74.81120550501784
At time: 289.99412083625793 and batch: 200, loss is 4.374301080703735 and perplexity is 79.384336913698
At time: 290.3837013244629 and batch: 250, loss is 4.400643000602722 and perplexity is 81.5032584641431
At time: 290.7641804218292 and batch: 300, loss is 4.4130120277404785 and perplexity is 82.51763497252007
At time: 291.14483070373535 and batch: 350, loss is 4.419999294281006 and perplexity is 83.09622671573752
At time: 291.5253863334656 and batch: 400, loss is 4.301984887123108 and perplexity is 73.84622474756117
At time: 291.9154739379883 and batch: 450, loss is 4.34342134475708 and perplexity is 76.97043174217029
At time: 292.3021640777588 and batch: 500, loss is 4.319249420166016 and perplexity is 75.13221439809622
At time: 292.68340945243835 and batch: 550, loss is 4.377336187362671 and perplexity is 79.62564285267112
At time: 293.0639445781708 and batch: 600, loss is 4.281517734527588 and perplexity is 72.35016506310268
At time: 293.4447817802429 and batch: 650, loss is 4.3795199203491215 and perplexity is 79.79971398880255
At time: 293.82514691352844 and batch: 700, loss is 4.420527114868164 and perplexity is 83.1400981920289
At time: 294.2075607776642 and batch: 750, loss is 4.367071342468262 and perplexity is 78.81247862157032
At time: 294.5873396396637 and batch: 800, loss is 4.3149499368667605 and perplexity is 74.80987813329612
At time: 294.9731969833374 and batch: 850, loss is 4.273457107543945 and perplexity is 71.76932149694524
At time: 295.36672163009644 and batch: 900, loss is 4.214972062110901 and perplexity is 67.69227466525138
At time: 295.7531638145447 and batch: 950, loss is 4.295038371086121 and perplexity is 73.33502833572562
At time: 296.1332573890686 and batch: 1000, loss is 4.335805282592774 and perplexity is 76.38644680480682
At time: 296.52598690986633 and batch: 1050, loss is 4.2508776760101314 and perplexity is 70.16696919481784
At time: 296.9063789844513 and batch: 1100, loss is 4.387731409072876 and perplexity is 80.45768620894177
At time: 297.2876307964325 and batch: 1150, loss is 4.307957301139831 and perplexity is 74.28858463862848
At time: 297.668377161026 and batch: 1200, loss is 4.272392292022705 and perplexity is 71.69294108220886
At time: 298.0800714492798 and batch: 1250, loss is 4.263260917663574 and perplexity is 71.04126587159325
At time: 298.4811284542084 and batch: 1300, loss is 4.316684856414795 and perplexity is 74.93977990523425
At time: 298.87426018714905 and batch: 1350, loss is 4.261898736953736 and perplexity is 70.94456070952695
At time: 299.2562654018402 and batch: 1400, loss is 4.1460595703125 and perplexity is 63.18453490336251
At time: 299.63738441467285 and batch: 1450, loss is 4.221719479560852 and perplexity is 68.1505671070174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816921657986111 and perplexity of 123.58407058873688
Finished 25 epochs...
Completing Train Step...
At time: 300.88989877700806 and batch: 50, loss is 4.423818812370301 and perplexity is 83.41422116300807
At time: 301.3012127876282 and batch: 100, loss is 4.42729001045227 and perplexity is 83.704271567482
At time: 301.6813933849335 and batch: 150, loss is 4.312410831451416 and perplexity is 74.62016891438131
At time: 302.0633907318115 and batch: 200, loss is 4.37234977722168 and perplexity is 79.22958501372085
At time: 302.4445004463196 and batch: 250, loss is 4.398467154502868 and perplexity is 81.32611270792843
At time: 302.8254461288452 and batch: 300, loss is 4.411291761398315 and perplexity is 82.37580469034901
At time: 303.20640110969543 and batch: 350, loss is 4.418317775726319 and perplexity is 82.95661628035506
At time: 303.5854845046997 and batch: 400, loss is 4.300274171829224 and perplexity is 73.72000287711481
At time: 303.9647614955902 and batch: 450, loss is 4.341363134384156 and perplexity is 76.81217332157978
At time: 304.3433814048767 and batch: 500, loss is 4.317474203109741 and perplexity is 74.99895672526353
At time: 304.722617149353 and batch: 550, loss is 4.376089191436767 and perplexity is 79.52641188360212
At time: 305.10152530670166 and batch: 600, loss is 4.28050576210022 and perplexity is 72.27698572492471
At time: 305.48043966293335 and batch: 650, loss is 4.378718824386596 and perplexity is 79.73581235920163
At time: 305.85888028144836 and batch: 700, loss is 4.419400587081909 and perplexity is 83.04649129654743
At time: 306.2478995323181 and batch: 750, loss is 4.365957098007202 and perplexity is 78.72471116008833
At time: 306.62514543533325 and batch: 800, loss is 4.31416425704956 and perplexity is 74.75112460567235
At time: 307.0042426586151 and batch: 850, loss is 4.272741732597351 and perplexity is 71.71799788241505
At time: 307.3837742805481 and batch: 900, loss is 4.21440104007721 and perplexity is 67.65363191888666
At time: 307.76315784454346 and batch: 950, loss is 4.294607372283935 and perplexity is 73.30342783673247
At time: 308.1420097351074 and batch: 1000, loss is 4.335498609542847 and perplexity is 76.36302473183495
At time: 308.51875925064087 and batch: 1050, loss is 4.251117343902588 and perplexity is 70.1837879798257
At time: 308.89487290382385 and batch: 1100, loss is 4.3878386688232425 and perplexity is 80.4663165431151
At time: 309.2764699459076 and batch: 1150, loss is 4.307916483879089 and perplexity is 74.2855524439825
At time: 309.6602735519409 and batch: 1200, loss is 4.272700753211975 and perplexity is 71.715058983159
At time: 310.0428202152252 and batch: 1250, loss is 4.263467435836792 and perplexity is 71.05593869909474
At time: 310.4244329929352 and batch: 1300, loss is 4.3167103576660155 and perplexity is 74.94169098775545
At time: 310.80776047706604 and batch: 1350, loss is 4.2625203037261965 and perplexity is 70.9886711985378
At time: 311.194504737854 and batch: 1400, loss is 4.14650442123413 and perplexity is 63.21264885474205
At time: 311.58694219589233 and batch: 1450, loss is 4.22241289138794 and perplexity is 68.19783990413633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816634740584936 and perplexity of 123.54861725470943
Finished 26 epochs...
Completing Train Step...
At time: 312.91868567466736 and batch: 50, loss is 4.422187662124633 and perplexity is 83.27827094342594
At time: 313.30389046669006 and batch: 100, loss is 4.4259242248535156 and perplexity is 83.590027513022
At time: 313.68751978874207 and batch: 150, loss is 4.311075048446655 and perplexity is 74.5205591042901
At time: 314.07017850875854 and batch: 200, loss is 4.371473169326782 and perplexity is 79.16016216674183
At time: 314.4571852684021 and batch: 250, loss is 4.397288031578064 and perplexity is 81.23027573693784
At time: 314.8434569835663 and batch: 300, loss is 4.410271377563476 and perplexity is 82.29179262042949
At time: 315.2291820049286 and batch: 350, loss is 4.417278642654419 and perplexity is 82.8704580895108
At time: 315.61396503448486 and batch: 400, loss is 4.29942834854126 and perplexity is 73.6576751447322
At time: 316.00042963027954 and batch: 450, loss is 4.340116662979126 and perplexity is 76.71648879038094
At time: 316.45773792266846 and batch: 500, loss is 4.316415300369263 and perplexity is 74.91958215684487
At time: 316.8426716327667 and batch: 550, loss is 4.37535325050354 and perplexity is 79.46790667265466
At time: 317.22628235816956 and batch: 600, loss is 4.279840145111084 and perplexity is 72.2288929427647
At time: 317.6122577190399 and batch: 650, loss is 4.378247156143188 and perplexity is 79.69821237670536
At time: 317.9961874485016 and batch: 700, loss is 4.418746175765992 and perplexity is 82.99216251152048
At time: 318.38216257095337 and batch: 750, loss is 4.36517147064209 and perplexity is 78.66288716118295
At time: 318.7688798904419 and batch: 800, loss is 4.313582792282104 and perplexity is 74.70767209466281
At time: 319.1534776687622 and batch: 850, loss is 4.272169928550721 and perplexity is 71.67700096322885
At time: 319.5388524532318 and batch: 900, loss is 4.214028644561767 and perplexity is 67.62844270022381
At time: 319.92491126060486 and batch: 950, loss is 4.294255590438842 and perplexity is 73.27764555677132
At time: 320.3100051879883 and batch: 1000, loss is 4.335355377197265 and perplexity is 76.35208785996252
At time: 320.69415950775146 and batch: 1050, loss is 4.251195473670959 and perplexity is 70.18927163713963
At time: 321.0781261920929 and batch: 1100, loss is 4.387913675308227 and perplexity is 80.47235226503498
At time: 321.4607563018799 and batch: 1150, loss is 4.307789030075074 and perplexity is 74.27608507107927
At time: 321.8441083431244 and batch: 1200, loss is 4.2729294919967655 and perplexity is 71.73146487486233
At time: 322.2282292842865 and batch: 1250, loss is 4.263492727279663 and perplexity is 71.05773582903494
At time: 322.6116223335266 and batch: 1300, loss is 4.316710472106934 and perplexity is 74.94169956415185
At time: 322.9934630393982 and batch: 1350, loss is 4.262793502807617 and perplexity is 71.00806788775871
At time: 323.37660217285156 and batch: 1400, loss is 4.146602149009705 and perplexity is 63.21882678817571
At time: 323.7587926387787 and batch: 1450, loss is 4.222663550376892 and perplexity is 68.21493644834717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816560663728633 and perplexity of 123.53946550051336
Finished 27 epochs...
Completing Train Step...
At time: 325.0247826576233 and batch: 50, loss is 4.420958795547485 and perplexity is 83.17599591371429
At time: 325.4193983078003 and batch: 100, loss is 4.4249493026733395 and perplexity is 83.50857345329443
At time: 325.7997512817383 and batch: 150, loss is 4.310082187652588 and perplexity is 74.44660728081155
At time: 326.19526529312134 and batch: 200, loss is 4.370768690109253 and perplexity is 79.10441511626398
At time: 326.575168132782 and batch: 250, loss is 4.396324548721314 and perplexity is 81.15204944971096
At time: 326.955237865448 and batch: 300, loss is 4.409471635818481 and perplexity is 82.226006747961
At time: 327.3358380794525 and batch: 350, loss is 4.416448020935059 and perplexity is 82.80165266672354
At time: 327.76050662994385 and batch: 400, loss is 4.2988115453720095 and perplexity is 73.61225686577247
At time: 328.14036226272583 and batch: 450, loss is 4.3391822338104244 and perplexity is 76.6448361479081
At time: 328.52045488357544 and batch: 500, loss is 4.315529136657715 and perplexity is 74.85322054981988
At time: 328.900413274765 and batch: 550, loss is 4.374767799377441 and perplexity is 79.4213957134796
At time: 329.28070425987244 and batch: 600, loss is 4.279355545043945 and perplexity is 72.19389929604185
At time: 329.66221141815186 and batch: 650, loss is 4.377839574813843 and perplexity is 79.66573549229385
At time: 330.0451066493988 and batch: 700, loss is 4.418225908279419 and perplexity is 82.94899561786474
At time: 330.4245390892029 and batch: 750, loss is 4.3646590042114255 and perplexity is 78.62258539970564
At time: 330.8063895702362 and batch: 800, loss is 4.313103876113892 and perplexity is 74.67190194874145
At time: 331.1879334449768 and batch: 850, loss is 4.271742973327637 and perplexity is 71.64640462539053
At time: 331.57033491134644 and batch: 900, loss is 4.213715753555298 and perplexity is 67.60728567881485
At time: 331.9534752368927 and batch: 950, loss is 4.293921222686768 and perplexity is 73.25314797097876
At time: 332.3360195159912 and batch: 1000, loss is 4.3351883220672605 and perplexity is 76.33933391733437
At time: 332.718389749527 and batch: 1050, loss is 4.251194982528687 and perplexity is 70.18923716422971
At time: 333.1004614830017 and batch: 1100, loss is 4.387894973754883 and perplexity is 80.47084732111881
At time: 333.4839434623718 and batch: 1150, loss is 4.307606472969055 and perplexity is 74.26252668157011
At time: 333.8661434650421 and batch: 1200, loss is 4.273096327781677 and perplexity is 71.74343324845633
At time: 334.2501587867737 and batch: 1250, loss is 4.263388938903809 and perplexity is 71.05036124474603
At time: 334.63172602653503 and batch: 1300, loss is 4.316628885269165 and perplexity is 74.93558555728207
At time: 335.01310896873474 and batch: 1350, loss is 4.2629609870910645 and perplexity is 71.01996161910661
At time: 335.3960506916046 and batch: 1400, loss is 4.146586422920227 and perplexity is 63.217832611066235
At time: 335.77771830558777 and batch: 1450, loss is 4.22270896434784 and perplexity is 68.2180344298345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816512148604434 and perplexity of 123.53347211338728
Finished 28 epochs...
Completing Train Step...
At time: 337.04685044288635 and batch: 50, loss is 4.419903888702392 and perplexity is 83.08829925031534
At time: 337.4438326358795 and batch: 100, loss is 4.424117126464844 and perplexity is 83.43910851280538
At time: 337.82522082328796 and batch: 150, loss is 4.309222536087036 and perplexity is 74.3826366384835
At time: 338.2071888446808 and batch: 200, loss is 4.3701599502563475 and perplexity is 79.05627575990083
At time: 338.59083700180054 and batch: 250, loss is 4.395556244850159 and perplexity is 81.08972396148938
At time: 338.97368454933167 and batch: 300, loss is 4.408795766830444 and perplexity is 82.17045151613387
At time: 339.3577575683594 and batch: 350, loss is 4.415729446411133 and perplexity is 82.7421748807484
At time: 339.73997712135315 and batch: 400, loss is 4.298273000717163 and perplexity is 73.57262405128432
At time: 340.1228988170624 and batch: 450, loss is 4.338328561782837 and perplexity is 76.57943451497371
At time: 340.5043692588806 and batch: 500, loss is 4.314740467071533 and perplexity is 74.79420936456673
At time: 340.8865325450897 and batch: 550, loss is 4.374239702224731 and perplexity is 79.37946457337142
At time: 341.26677799224854 and batch: 600, loss is 4.278921756744385 and perplexity is 72.1625892186912
At time: 341.64786195755005 and batch: 650, loss is 4.3774285316467285 and perplexity is 79.63299616516595
At time: 342.02989077568054 and batch: 700, loss is 4.417759742736816 and perplexity is 82.91033666574994
At time: 342.4134769439697 and batch: 750, loss is 4.364184737205505 and perplexity is 78.58530614239007
At time: 342.7958812713623 and batch: 800, loss is 4.312654337882996 and perplexity is 74.63834161793281
At time: 343.177223443985 and batch: 850, loss is 4.271330757141113 and perplexity is 71.61687690401818
At time: 343.5822560787201 and batch: 900, loss is 4.213412957191467 and perplexity is 67.58681753753861
At time: 343.9734220504761 and batch: 950, loss is 4.293592796325684 and perplexity is 73.22909365640443
At time: 344.35549664497375 and batch: 1000, loss is 4.335004539489746 and perplexity is 76.32530536692235
At time: 344.73808455467224 and batch: 1050, loss is 4.2511526966094975 and perplexity is 70.1862692105708
At time: 345.1211519241333 and batch: 1100, loss is 4.387858619689942 and perplexity is 80.46792193188462
At time: 345.52593755722046 and batch: 1150, loss is 4.307385587692261 and perplexity is 74.24612499432095
At time: 345.90752935409546 and batch: 1200, loss is 4.27320255279541 and perplexity is 71.75105460042032
At time: 346.289754152298 and batch: 1250, loss is 4.263233852386475 and perplexity is 71.03934314606661
At time: 346.6730933189392 and batch: 1300, loss is 4.316511898040772 and perplexity is 74.92681956358432
At time: 347.0548002719879 and batch: 1350, loss is 4.263033332824707 and perplexity is 71.02509979619359
At time: 347.43671107292175 and batch: 1400, loss is 4.146466417312622 and perplexity is 63.210246571845005
At time: 347.8190848827362 and batch: 1450, loss is 4.22265962600708 and perplexity is 68.21466874823511
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816489195212339 and perplexity of 123.53063663370712
Finished 29 epochs...
Completing Train Step...
At time: 349.09417152404785 and batch: 50, loss is 4.419002289772034 and perplexity is 83.01342068887368
At time: 349.47681498527527 and batch: 100, loss is 4.423372764587402 and perplexity is 83.37702273135181
At time: 349.8573899269104 and batch: 150, loss is 4.308474073410034 and perplexity is 74.32698484038747
At time: 350.2368640899658 and batch: 200, loss is 4.369594602584839 and perplexity is 79.01159411000529
At time: 350.6178936958313 and batch: 250, loss is 4.394865412712097 and perplexity is 81.03372391965169
At time: 350.9981338977814 and batch: 300, loss is 4.408185377120971 and perplexity is 82.12031082234421
At time: 351.3789789676666 and batch: 350, loss is 4.4150803279876705 and perplexity is 82.68848283876807
At time: 351.7597975730896 and batch: 400, loss is 4.297803606986999 and perplexity is 73.5380976267205
At time: 352.14073061943054 and batch: 450, loss is 4.3375563621521 and perplexity is 76.5203227299058
At time: 352.5207431316376 and batch: 500, loss is 4.314015998840332 and perplexity is 74.7400429592933
At time: 352.90046548843384 and batch: 550, loss is 4.373749513626098 and perplexity is 79.34056320015573
At time: 353.2811858654022 and batch: 600, loss is 4.278549842834472 and perplexity is 72.1357559381299
At time: 353.66300988197327 and batch: 650, loss is 4.377055864334107 and perplexity is 79.60332507955432
At time: 354.0445144176483 and batch: 700, loss is 4.417310581207276 and perplexity is 82.87310489428408
At time: 354.42671036720276 and batch: 750, loss is 4.363718843460083 and perplexity is 78.54870226719655
At time: 354.80810928344727 and batch: 800, loss is 4.312211561203003 and perplexity is 74.6053008162191
At time: 355.2035393714905 and batch: 850, loss is 4.270942249298096 and perplexity is 71.58905858981508
At time: 355.5839877128601 and batch: 900, loss is 4.2131021165847775 and perplexity is 67.5658120750155
At time: 355.9642639160156 and batch: 950, loss is 4.293242001533509 and perplexity is 73.20340977686303
At time: 356.34376192092896 and batch: 1000, loss is 4.334796962738037 and perplexity is 76.3094636522038
At time: 356.72390961647034 and batch: 1050, loss is 4.251102256774902 and perplexity is 70.1827291160426
At time: 357.1037395000458 and batch: 1100, loss is 4.387809114456177 and perplexity is 80.4639384472013
At time: 357.4837861061096 and batch: 1150, loss is 4.307134351730347 and perplexity is 74.22747404068282
At time: 357.8639280796051 and batch: 1200, loss is 4.273261404037475 and perplexity is 71.75527736335926
At time: 358.2442739009857 and batch: 1250, loss is 4.263055214881897 and perplexity is 71.0266539884936
At time: 358.625412940979 and batch: 1300, loss is 4.316357841491699 and perplexity is 74.91527748541859
At time: 359.0331208705902 and batch: 1350, loss is 4.263063545227051 and perplexity is 71.0272456675009
At time: 359.4204707145691 and batch: 1400, loss is 4.146339936256409 and perplexity is 63.202252178675394
At time: 359.79925894737244 and batch: 1450, loss is 4.222561211585998 and perplexity is 68.20795577143325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816466763488248 and perplexity of 123.52786565962828
Finished 30 epochs...
Completing Train Step...
At time: 361.06215238571167 and batch: 50, loss is 4.418157939910889 and perplexity is 82.94335790155668
At time: 361.4466288089752 and batch: 100, loss is 4.422660064697266 and perplexity is 83.31762110669136
At time: 361.8302700519562 and batch: 150, loss is 4.307783946990967 and perplexity is 74.2757075204513
At time: 362.2136311531067 and batch: 200, loss is 4.369044008255005 and perplexity is 78.96810274844444
At time: 362.59715247154236 and batch: 250, loss is 4.394220218658448 and perplexity is 80.98145830537852
At time: 362.9806020259857 and batch: 300, loss is 4.407613468170166 and perplexity is 82.07335890893154
At time: 363.3637857437134 and batch: 350, loss is 4.414443788528442 and perplexity is 82.635865105026
At time: 363.7458689212799 and batch: 400, loss is 4.2973604488372805 and perplexity is 73.50551583941791
At time: 364.12761926651 and batch: 450, loss is 4.336841831207275 and perplexity is 76.46566612065209
At time: 364.5105118751526 and batch: 500, loss is 4.313330364227295 and perplexity is 74.68881616229993
At time: 364.89421463012695 and batch: 550, loss is 4.373287448883056 and perplexity is 79.30391119166042
At time: 365.30210733413696 and batch: 600, loss is 4.278215818405151 and perplexity is 72.11166485714779
At time: 365.685528755188 and batch: 650, loss is 4.376690673828125 and perplexity is 79.5742600084577
At time: 366.06901359558105 and batch: 700, loss is 4.41685320854187 and perplexity is 82.835209668189
At time: 366.4527542591095 and batch: 750, loss is 4.3632622241973875 and perplexity is 78.51284360418282
At time: 366.8369085788727 and batch: 800, loss is 4.3117801952362065 and perplexity is 74.57312556865669
At time: 367.2201817035675 and batch: 850, loss is 4.270554265975952 and perplexity is 71.56128861652587
At time: 367.6145770549774 and batch: 900, loss is 4.21278395652771 and perplexity is 67.5443187517297
At time: 368.0145251750946 and batch: 950, loss is 4.292882175445556 and perplexity is 73.17707401872882
At time: 368.39987301826477 and batch: 1000, loss is 4.334568138122559 and perplexity is 76.29200416618252
At time: 368.7828960418701 and batch: 1050, loss is 4.2510292339324955 and perplexity is 70.17760436078906
At time: 369.1658170223236 and batch: 1100, loss is 4.387719917297363 and perplexity is 80.45676161258623
At time: 369.5485680103302 and batch: 1150, loss is 4.306868510246277 and perplexity is 74.20774392148338
At time: 369.93261098861694 and batch: 1200, loss is 4.273301343917847 and perplexity is 71.75814331778575
At time: 370.31555438041687 and batch: 1250, loss is 4.262856793403626 and perplexity is 71.01256217291822
At time: 370.69908809661865 and batch: 1300, loss is 4.316156339645386 and perplexity is 74.90018343947833
At time: 371.0828528404236 and batch: 1350, loss is 4.263080692291259 and perplexity is 71.02846358668477
At time: 371.46616768836975 and batch: 1400, loss is 4.146192059516907 and perplexity is 63.192906726698574
At time: 371.8490147590637 and batch: 1450, loss is 4.222417964935302 and perplexity is 68.19818590998486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816451635116186 and perplexity of 123.52599689825227
Finished 31 epochs...
Completing Train Step...
At time: 373.10200691223145 and batch: 50, loss is 4.4173685789108275 and perplexity is 82.87791148343837
At time: 373.4972462654114 and batch: 100, loss is 4.4220489978790285 and perplexity is 83.26672402540112
At time: 373.878408908844 and batch: 150, loss is 4.307136459350586 and perplexity is 74.22763048417428
At time: 374.2605333328247 and batch: 200, loss is 4.368585481643676 and perplexity is 78.93190207200914
At time: 374.64236640930176 and batch: 250, loss is 4.393675966262817 and perplexity is 80.93739594430463
At time: 375.03555846214294 and batch: 300, loss is 4.407076463699341 and perplexity is 82.02929698004706
At time: 375.4175992012024 and batch: 350, loss is 4.413862953186035 and perplexity is 82.58788121074248
At time: 375.7978148460388 and batch: 400, loss is 4.296921429634094 and perplexity is 73.4732525890357
At time: 376.17812848091125 and batch: 450, loss is 4.33614294052124 and perplexity is 76.41224364920727
At time: 376.56020307540894 and batch: 500, loss is 4.3126508903503415 and perplexity is 74.6380843002564
At time: 376.9423108100891 and batch: 550, loss is 4.372841558456421 and perplexity is 79.26855821922702
At time: 377.32392978668213 and batch: 600, loss is 4.277912988662719 and perplexity is 72.0898306064499
At time: 377.7051649093628 and batch: 650, loss is 4.376303110122681 and perplexity is 79.54342588886963
At time: 378.08663535118103 and batch: 700, loss is 4.41637954711914 and perplexity is 82.7959831157112
At time: 378.46877694129944 and batch: 750, loss is 4.362810106277466 and perplexity is 78.47735456386542
At time: 378.8502025604248 and batch: 800, loss is 4.311369805335999 and perplexity is 74.54252779003549
At time: 379.2320923805237 and batch: 850, loss is 4.2701245260238645 and perplexity is 71.53054247867956
At time: 379.6144778728485 and batch: 900, loss is 4.212420043945312 and perplexity is 67.51974299625098
At time: 379.99705815315247 and batch: 950, loss is 4.2925165224075315 and perplexity is 73.15032149066974
At time: 380.3788592815399 and batch: 1000, loss is 4.334306488037109 and perplexity is 76.27204496805014
At time: 380.7612509727478 and batch: 1050, loss is 4.250883340835571 and perplexity is 70.1673666795758
At time: 381.1428573131561 and batch: 1100, loss is 4.38759690284729 and perplexity is 80.446864877035
At time: 381.52513217926025 and batch: 1150, loss is 4.306581029891968 and perplexity is 74.18641371912231
At time: 381.9074411392212 and batch: 1200, loss is 4.273303241729736 and perplexity is 71.7582795013725
At time: 382.2889988422394 and batch: 1250, loss is 4.262628679275513 and perplexity is 70.9963650516794
At time: 382.671391248703 and batch: 1300, loss is 4.315906991958618 and perplexity is 74.88150958023778
At time: 383.0534899234772 and batch: 1350, loss is 4.263010158538818 and perplexity is 71.02345385929736
At time: 383.4355671405792 and batch: 1400, loss is 4.14594190120697 and perplexity is 63.177100473067085
At time: 383.81763982772827 and batch: 1450, loss is 4.2221865606307984 and perplexity is 68.18240638200169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816349909855769 and perplexity of 123.51343182315314
Finished 32 epochs...
Completing Train Step...
At time: 385.0812785625458 and batch: 50, loss is 4.416502571105957 and perplexity is 82.80616963422668
At time: 385.47643995285034 and batch: 100, loss is 4.421407270431518 and perplexity is 83.21330662466904
At time: 385.8586084842682 and batch: 150, loss is 4.306467094421387 and perplexity is 74.17796173666396
At time: 386.2388710975647 and batch: 200, loss is 4.367930374145508 and perplexity is 78.88021012485683
At time: 386.61936044692993 and batch: 250, loss is 4.393225059509278 and perplexity is 80.90090895259311
At time: 387.001300573349 and batch: 300, loss is 4.406526174545288 and perplexity is 81.98416956530657
At time: 387.38351345062256 and batch: 350, loss is 4.413296222686768 and perplexity is 82.541089400016
At time: 387.764456987381 and batch: 400, loss is 4.296389222145081 and perplexity is 73.43415997737873
At time: 388.14637064933777 and batch: 450, loss is 4.335464363098144 and perplexity is 76.36040961451066
At time: 388.52845644950867 and batch: 500, loss is 4.31189902305603 and perplexity is 74.58198745709448
At time: 388.91040992736816 and batch: 550, loss is 4.3723697853088375 and perplexity is 79.23117026202212
At time: 389.2924163341522 and batch: 600, loss is 4.2775272941589355 and perplexity is 72.0620313163676
At time: 389.6741819381714 and batch: 650, loss is 4.375831203460693 and perplexity is 79.50589767187962
At time: 390.0784034729004 and batch: 700, loss is 4.415813751220703 and perplexity is 82.74915073809021
At time: 390.4671564102173 and batch: 750, loss is 4.362367539405823 and perplexity is 78.44263077092828
At time: 390.84953451156616 and batch: 800, loss is 4.310942039489746 and perplexity is 74.510647861612
At time: 391.23273825645447 and batch: 850, loss is 4.26970853805542 and perplexity is 71.5007928218108
At time: 391.6155228614807 and batch: 900, loss is 4.212073340415954 and perplexity is 67.49633772063312
At time: 392.0198493003845 and batch: 950, loss is 4.292134523391724 and perplexity is 73.122383476341
At time: 392.41339921951294 and batch: 1000, loss is 4.333988370895386 and perplexity is 76.24778538201122
At time: 392.7958333492279 and batch: 1050, loss is 4.250707969665528 and perplexity is 70.1550624253196
At time: 393.1777722835541 and batch: 1100, loss is 4.387440452575683 and perplexity is 80.43427992766016
At time: 393.5591130256653 and batch: 1150, loss is 4.306286654472351 and perplexity is 74.16457827652037
At time: 393.94083309173584 and batch: 1200, loss is 4.273259391784668 and perplexity is 71.75513297374623
At time: 394.33619379997253 and batch: 1250, loss is 4.2624308252334595 and perplexity is 70.98231952341095
At time: 394.7163898944855 and batch: 1300, loss is 4.315669260025024 and perplexity is 74.86370997002653
At time: 395.0968894958496 and batch: 1350, loss is 4.262932276725769 and perplexity is 71.0179226393353
At time: 395.4780693054199 and batch: 1400, loss is 4.145758013725281 and perplexity is 63.1654840632496
At time: 395.85973715782166 and batch: 1450, loss is 4.221950879096985 and perplexity is 68.16633894136038
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816303481403579 and perplexity of 123.50769741880966
Finished 33 epochs...
Completing Train Step...
At time: 397.12115955352783 and batch: 50, loss is 4.415785317420959 and perplexity is 82.74679789875937
At time: 397.5023949146271 and batch: 100, loss is 4.420821542739868 and perplexity is 83.1645805581615
At time: 397.88411927223206 and batch: 150, loss is 4.305914974212646 and perplexity is 74.13701788894893
At time: 398.26690578460693 and batch: 200, loss is 4.367498188018799 and perplexity is 78.84612655812187
At time: 398.64946389198303 and batch: 250, loss is 4.392734384536743 and perplexity is 80.8612226386515
At time: 399.0325434207916 and batch: 300, loss is 4.40599404335022 and perplexity is 81.94055483658717
At time: 399.4157974720001 and batch: 350, loss is 4.412725858688354 and perplexity is 82.49402435761121
At time: 399.79913234710693 and batch: 400, loss is 4.295859031677246 and perplexity is 73.39523620516356
At time: 400.1835160255432 and batch: 450, loss is 4.334839611053467 and perplexity is 76.31271819167978
At time: 400.56680154800415 and batch: 500, loss is 4.311231460571289 and perplexity is 74.53221593487955
At time: 400.94985365867615 and batch: 550, loss is 4.371909532546997 and perplexity is 79.19471228767046
At time: 401.33283972740173 and batch: 600, loss is 4.277283935546875 and perplexity is 72.04449653415087
At time: 401.71572947502136 and batch: 650, loss is 4.375542268753052 and perplexity is 79.4829289769664
At time: 402.0988538265228 and batch: 700, loss is 4.415312938690185 and perplexity is 82.70771930206796
At time: 402.4824318885803 and batch: 750, loss is 4.361961312294007 and perplexity is 78.41077171903035
At time: 402.8652787208557 and batch: 800, loss is 4.310487308502197 and perplexity is 74.47677326362539
At time: 403.2484242916107 and batch: 850, loss is 4.269323453903199 and perplexity is 71.4732643003627
At time: 403.6312267780304 and batch: 900, loss is 4.2117278146743775 and perplexity is 67.47302002715215
At time: 404.039270401001 and batch: 950, loss is 4.2918096542358395 and perplexity is 73.098632127594
At time: 404.42214727401733 and batch: 1000, loss is 4.333664875030518 and perplexity is 76.22312352795375
At time: 404.8041913509369 and batch: 1050, loss is 4.250502367019653 and perplexity is 70.14063984157494
At time: 405.1884684562683 and batch: 1100, loss is 4.38732424736023 and perplexity is 80.42493358788852
At time: 405.57107520103455 and batch: 1150, loss is 4.305816264152527 and perplexity is 74.1297001806277
At time: 405.9538028240204 and batch: 1200, loss is 4.273189849853516 and perplexity is 71.75014315673192
At time: 406.33686447143555 and batch: 1250, loss is 4.262221808433533 and perplexity is 70.96748457656336
At time: 406.72016620635986 and batch: 1300, loss is 4.315363931655884 and perplexity is 74.84085544479858
At time: 407.10339188575745 and batch: 1350, loss is 4.262821507453919 and perplexity is 71.01005647142911
At time: 407.4851498603821 and batch: 1400, loss is 4.145581040382385 and perplexity is 63.15430644547866
At time: 407.86733746528625 and batch: 1450, loss is 4.22174635887146 and perplexity is 68.15239897189832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816276354667468 and perplexity of 123.50434710353589
Finished 34 epochs...
Completing Train Step...
At time: 409.12626004219055 and batch: 50, loss is 4.415144286155701 and perplexity is 82.69377161177594
At time: 409.5058078765869 and batch: 100, loss is 4.420279493331909 and perplexity is 83.11951346190669
At time: 409.8861839771271 and batch: 150, loss is 4.305358543395996 and perplexity is 74.09577724238835
At time: 410.26702094078064 and batch: 200, loss is 4.3669805908203125 and perplexity is 78.80532658379096
At time: 410.6501739025116 and batch: 250, loss is 4.392198820114135 and perplexity is 80.81792783924968
At time: 411.0314316749573 and batch: 300, loss is 4.405431394577026 and perplexity is 81.89446405161128
At time: 411.413369178772 and batch: 350, loss is 4.41221139907837 and perplexity is 82.45159542893498
At time: 411.7954604625702 and batch: 400, loss is 4.29536735534668 and perplexity is 73.35915837477961
At time: 412.17643117904663 and batch: 450, loss is 4.334183197021485 and perplexity is 76.26264188983173
At time: 412.5577223300934 and batch: 500, loss is 4.310567045211792 and perplexity is 74.48271203323252
At time: 412.939847946167 and batch: 550, loss is 4.371457462310791 and perplexity is 79.1589188065736
At time: 413.3220512866974 and batch: 600, loss is 4.2769327735900875 and perplexity is 72.01920168932568
At time: 413.70445823669434 and batch: 650, loss is 4.375247192382813 and perplexity is 79.45947890273943
At time: 414.09980821609497 and batch: 700, loss is 4.414794759750366 and perplexity is 82.66487300574809
At time: 414.48216223716736 and batch: 750, loss is 4.36158133983612 and perplexity is 78.38098344509575
At time: 414.8643682003021 and batch: 800, loss is 4.310069489479065 and perplexity is 74.44566195087606
At time: 415.24653577804565 and batch: 850, loss is 4.268902940750122 and perplexity is 71.44321517110092
At time: 415.62876629829407 and batch: 900, loss is 4.211453504562378 and perplexity is 67.45451403377817
At time: 416.01113772392273 and batch: 950, loss is 4.291479835510254 and perplexity is 73.07452680531547
At time: 416.3933651447296 and batch: 1000, loss is 4.333393001556397 and perplexity is 76.20240329931974
At time: 416.77500772476196 and batch: 1050, loss is 4.2502960157394405 and perplexity is 70.12616772397006
At time: 417.1574881076813 and batch: 1100, loss is 4.3871846199035645 and perplexity is 80.41370484289797
At time: 417.53857159614563 and batch: 1150, loss is 4.305510449409485 and perplexity is 74.1070336914651
At time: 417.92053484916687 and batch: 1200, loss is 4.27299816608429 and perplexity is 71.73639113691073
At time: 418.3073980808258 and batch: 1250, loss is 4.261976108551026 and perplexity is 70.95005001586354
At time: 418.68847131729126 and batch: 1300, loss is 4.3151445388793945 and perplexity is 74.82443770276058
At time: 419.06767320632935 and batch: 1350, loss is 4.26275595664978 and perplexity is 71.00540185768399
At time: 419.44771575927734 and batch: 1400, loss is 4.145385665893555 and perplexity is 63.14196891039846
At time: 419.8273596763611 and batch: 1450, loss is 4.2214980936050415 and perplexity is 68.13548119854515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.816313393095619 and perplexity of 123.50892159513792
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 421.071076631546 and batch: 50, loss is 4.414365634918213 and perplexity is 82.62940706619648
At time: 421.4648849964142 and batch: 100, loss is 4.420240640640259 and perplexity is 83.11628410781496
At time: 421.84614753723145 and batch: 150, loss is 4.305054979324341 and perplexity is 74.07328784021617
At time: 422.22701930999756 and batch: 200, loss is 4.3664144515991214 and perplexity is 78.76072442428033
At time: 422.60853338241577 and batch: 250, loss is 4.392321815490723 and perplexity is 80.8278686820456
At time: 422.98900413513184 and batch: 300, loss is 4.404590339660644 and perplexity is 81.82561526685913
At time: 423.3693587779999 and batch: 350, loss is 4.410825147628784 and perplexity is 82.33737597198608
At time: 423.7634036540985 and batch: 400, loss is 4.293886327743531 and perplexity is 73.25059185113646
At time: 424.14423394203186 and batch: 450, loss is 4.332742519378662 and perplexity is 76.15285111222752
At time: 424.5254967212677 and batch: 500, loss is 4.308522291183472 and perplexity is 74.33056880850762
At time: 424.9065957069397 and batch: 550, loss is 4.3693162631988525 and perplexity is 78.98960513175619
At time: 425.28876280784607 and batch: 600, loss is 4.274764156341552 and perplexity is 71.86318883354424
At time: 425.6699924468994 and batch: 650, loss is 4.373781929016113 and perplexity is 79.34313509714016
At time: 426.0508131980896 and batch: 700, loss is 4.4124658584594725 and perplexity is 82.47257868045816
At time: 426.43161725997925 and batch: 750, loss is 4.359688844680786 and perplexity is 78.23278808738442
At time: 426.8208637237549 and batch: 800, loss is 4.307281894683838 and perplexity is 74.2384265893988
At time: 427.2183117866516 and batch: 850, loss is 4.266063494682312 and perplexity is 71.24064374613155
At time: 427.6069173812866 and batch: 900, loss is 4.20887818813324 and perplexity is 67.28102081142796
At time: 427.9880726337433 and batch: 950, loss is 4.287832131385803 and perplexity is 72.80845811744067
At time: 428.36911368370056 and batch: 1000, loss is 4.3310126686096195 and perplexity is 76.02123191776987
At time: 428.75044560432434 and batch: 1050, loss is 4.246792802810669 and perplexity is 69.88093063622841
At time: 429.1316194534302 and batch: 1100, loss is 4.3844358253479 and perplexity is 80.19296760846763
At time: 429.5125324726105 and batch: 1150, loss is 4.301568508148193 and perplexity is 73.81548313272461
At time: 429.89409041404724 and batch: 1200, loss is 4.269911675453186 and perplexity is 71.51531878213578
At time: 430.2750849723816 and batch: 1250, loss is 4.258692383766174 and perplexity is 70.71745168160358
At time: 430.6557641029358 and batch: 1300, loss is 4.310798645019531 and perplexity is 74.4999642127429
At time: 431.0530788898468 and batch: 1350, loss is 4.258754858970642 and perplexity is 70.72186990687014
At time: 431.43774580955505 and batch: 1400, loss is 4.140778985023498 and perplexity is 62.851762966423635
At time: 431.8182327747345 and batch: 1450, loss is 4.216758866310119 and perplexity is 67.81333562978882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815540281116453 and perplexity of 123.41347226958152
Finished 36 epochs...
Completing Train Step...
At time: 433.0750069618225 and batch: 50, loss is 4.413454575538635 and perplexity is 82.55416105185812
At time: 433.46791911125183 and batch: 100, loss is 4.419504270553589 and perplexity is 83.05510229147714
At time: 433.8476791381836 and batch: 150, loss is 4.304398603439331 and perplexity is 74.02468387333536
At time: 434.2288806438446 and batch: 200, loss is 4.3660668277740475 and perplexity is 78.73335007825347
At time: 434.6098721027374 and batch: 250, loss is 4.391931629180908 and perplexity is 80.79633690626801
At time: 434.99119234085083 and batch: 300, loss is 4.404101943969726 and perplexity is 81.78566174631389
At time: 435.37344217300415 and batch: 350, loss is 4.41033444404602 and perplexity is 82.29698263798865
At time: 435.7558469772339 and batch: 400, loss is 4.293353071212769 and perplexity is 73.21154090766038
At time: 436.1379930973053 and batch: 450, loss is 4.332203664779663 and perplexity is 76.11182685222704
At time: 436.52062702178955 and batch: 500, loss is 4.30795576095581 and perplexity is 74.28847022062558
At time: 436.9028899669647 and batch: 550, loss is 4.368897695541381 and perplexity is 78.95654955625164
At time: 437.2843768596649 and batch: 600, loss is 4.2744275665283205 and perplexity is 71.83900448656726
At time: 437.6658625602722 and batch: 650, loss is 4.373537960052491 and perplexity is 79.32378019579357
At time: 438.04781007766724 and batch: 700, loss is 4.411984281539917 and perplexity is 82.43287135190332
At time: 438.4301986694336 and batch: 750, loss is 4.359341077804565 and perplexity is 78.20558604531197
At time: 438.8124234676361 and batch: 800, loss is 4.307063074111938 and perplexity is 74.22218347166455
At time: 439.19487619400024 and batch: 850, loss is 4.265862274169922 and perplexity is 71.22631010945317
At time: 439.577623128891 and batch: 900, loss is 4.208762378692627 and perplexity is 67.27322948520717
At time: 439.95986700057983 and batch: 950, loss is 4.287765278816223 and perplexity is 72.80359084762487
At time: 440.3418469429016 and batch: 1000, loss is 4.3309770107269285 and perplexity is 76.01852120992946
At time: 440.72453904151917 and batch: 1050, loss is 4.246862049102783 and perplexity is 69.8857697991096
At time: 441.10661244392395 and batch: 1100, loss is 4.384423666000366 and perplexity is 80.19199252023292
At time: 441.4888234138489 and batch: 1150, loss is 4.301535558700562 and perplexity is 73.81305099339777
At time: 441.86987924575806 and batch: 1200, loss is 4.269981517791748 and perplexity is 71.5203137536707
At time: 442.2507474422455 and batch: 1250, loss is 4.258932723999023 and perplexity is 70.73444997301203
At time: 442.63256335258484 and batch: 1300, loss is 4.310788831710815 and perplexity is 74.49923312518196
At time: 443.0145092010498 and batch: 1350, loss is 4.258914971351624 and perplexity is 70.73319426040884
At time: 443.39501547813416 and batch: 1400, loss is 4.140955557823181 and perplexity is 62.86286185802797
At time: 443.77564787864685 and batch: 1450, loss is 4.21696774482727 and perplexity is 67.82750185823714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815442729200053 and perplexity of 123.40143363605748
Finished 37 epochs...
Completing Train Step...
At time: 445.038756608963 and batch: 50, loss is 4.412958469390869 and perplexity is 82.51321558252593
At time: 445.42137241363525 and batch: 100, loss is 4.4191556072235105 and perplexity is 83.02614907068866
At time: 445.8045792579651 and batch: 150, loss is 4.304051961898804 and perplexity is 73.99902828978283
At time: 446.1868131160736 and batch: 200, loss is 4.365853404998779 and perplexity is 78.71654838116976
At time: 446.5699827671051 and batch: 250, loss is 4.391700263023377 and perplexity is 80.77764553061466
At time: 446.95244336128235 and batch: 300, loss is 4.403752069473267 and perplexity is 81.75705203428896
At time: 447.3366358280182 and batch: 350, loss is 4.41000111579895 and perplexity is 82.26955530043391
At time: 447.7194392681122 and batch: 400, loss is 4.293040113449097 and perplexity is 73.18863237243188
At time: 448.10111379623413 and batch: 450, loss is 4.331846122741699 and perplexity is 76.08461853888889
At time: 448.4835867881775 and batch: 500, loss is 4.307628316879272 and perplexity is 74.26414888325303
At time: 448.8677730560303 and batch: 550, loss is 4.368665590286255 and perplexity is 78.93822545281557
At time: 449.25100564956665 and batch: 600, loss is 4.274192476272583 and perplexity is 71.82211782165356
At time: 449.63438987731934 and batch: 650, loss is 4.373405637741089 and perplexity is 79.31328458426607
At time: 450.01938009262085 and batch: 700, loss is 4.41167652130127 and perplexity is 82.40750569521414
At time: 450.4031927585602 and batch: 750, loss is 4.359120960235596 and perplexity is 78.18837351629138
At time: 450.78687500953674 and batch: 800, loss is 4.306887812614441 and perplexity is 74.2091763205015
At time: 451.1698715686798 and batch: 850, loss is 4.265688595771789 and perplexity is 71.2139407121881
At time: 451.5535321235657 and batch: 900, loss is 4.208692231178284 and perplexity is 67.2685106008879
At time: 451.93813157081604 and batch: 950, loss is 4.28769455909729 and perplexity is 72.79844238019409
At time: 452.3218891620636 and batch: 1000, loss is 4.330988092422485 and perplexity is 76.01936362870589
At time: 452.70527482032776 and batch: 1050, loss is 4.246874847412109 and perplexity is 69.88666422453252
At time: 453.1018750667572 and batch: 1100, loss is 4.384407806396484 and perplexity is 80.19072071708223
At time: 453.4842994213104 and batch: 1150, loss is 4.301466526985169 and perplexity is 73.8079557277388
At time: 453.86775064468384 and batch: 1200, loss is 4.270030736923218 and perplexity is 71.52383400802734
At time: 454.25126338005066 and batch: 1250, loss is 4.259079885482788 and perplexity is 70.74486012559134
At time: 454.63501596450806 and batch: 1300, loss is 4.310755186080932 and perplexity is 74.4967265937248
At time: 455.01749658584595 and batch: 1350, loss is 4.259002890586853 and perplexity is 70.73941334213796
At time: 455.4008848667145 and batch: 1400, loss is 4.141012306213379 and perplexity is 62.86642932546469
At time: 455.78383708000183 and batch: 1450, loss is 4.217049036026001 and perplexity is 67.83301586128702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8154072557759084 and perplexity of 123.39705624230307
Finished 38 epochs...
Completing Train Step...
At time: 457.04450964927673 and batch: 50, loss is 4.412534441947937 and perplexity is 82.47823513157407
At time: 457.4263713359833 and batch: 100, loss is 4.418857898712158 and perplexity is 83.00143515839906
At time: 457.8078520298004 and batch: 150, loss is 4.303785495758056 and perplexity is 73.97931268118313
At time: 458.18954825401306 and batch: 200, loss is 4.365687255859375 and perplexity is 78.70347078084548
At time: 458.5705626010895 and batch: 250, loss is 4.391528315544129 and perplexity is 80.76375721215099
At time: 458.9524886608124 and batch: 300, loss is 4.403445453643799 and perplexity is 81.73198787069559
At time: 459.33449244499207 and batch: 350, loss is 4.409693822860718 and perplexity is 82.2442783309746
At time: 459.7169177532196 and batch: 400, loss is 4.292784934043884 and perplexity is 73.16995852344694
At time: 460.09893012046814 and batch: 450, loss is 4.331559400558472 and perplexity is 76.06280651809597
At time: 460.48123359680176 and batch: 500, loss is 4.307358055114746 and perplexity is 74.24408083526998
At time: 460.8627576828003 and batch: 550, loss is 4.3684587574005125 and perplexity is 78.92190012021584
At time: 461.24415016174316 and batch: 600, loss is 4.273992319107055 and perplexity is 71.80774354873301
At time: 461.6264052391052 and batch: 650, loss is 4.373269395828247 and perplexity is 79.30247952672809
At time: 462.0091381072998 and batch: 700, loss is 4.411416912078858 and perplexity is 82.38611472350662
At time: 462.39009141921997 and batch: 750, loss is 4.35894193649292 and perplexity is 78.17437719390517
At time: 462.7964057922363 and batch: 800, loss is 4.306731400489807 and perplexity is 74.19757001327308
At time: 463.1789758205414 and batch: 850, loss is 4.265520267486572 and perplexity is 71.20195440051042
At time: 463.561172246933 and batch: 900, loss is 4.208626651763916 and perplexity is 67.26409931600365
At time: 463.94297337532043 and batch: 950, loss is 4.287610878944397 and perplexity is 72.79235085027895
At time: 464.3241198062897 and batch: 1000, loss is 4.330993804931641 and perplexity is 76.01979789125697
At time: 464.70557475090027 and batch: 1050, loss is 4.246856832504273 and perplexity is 69.88540523405784
At time: 465.0874412059784 and batch: 1100, loss is 4.384370174407959 and perplexity is 80.18770303758136
At time: 465.46990036964417 and batch: 1150, loss is 4.3013773441314695 and perplexity is 73.80137361713136
At time: 465.85179018974304 and batch: 1200, loss is 4.270033364295959 and perplexity is 71.52402192804605
At time: 466.23327803611755 and batch: 1250, loss is 4.259179353713989 and perplexity is 70.75189734167851
At time: 466.61450481414795 and batch: 1300, loss is 4.310722494125367 and perplexity is 74.49429118985849
At time: 466.9951992034912 and batch: 1350, loss is 4.259048871994018 and perplexity is 70.74266611468845
At time: 467.37730884552 and batch: 1400, loss is 4.141026768684387 and perplexity is 62.86733853595091
At time: 467.7593638896942 and batch: 1450, loss is 4.217073016166687 and perplexity is 67.83464252605425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.81538586738782 and perplexity of 123.39441700639982
Finished 39 epochs...
Completing Train Step...
At time: 469.0109920501709 and batch: 50, loss is 4.412152180671692 and perplexity is 82.44671292139422
At time: 469.40813994407654 and batch: 100, loss is 4.418606567382812 and perplexity is 82.98057691863745
At time: 469.81131410598755 and batch: 150, loss is 4.303486242294311 and perplexity is 73.95717742780862
At time: 470.20653533935547 and batch: 200, loss is 4.365536317825318 and perplexity is 78.69159233016988
At time: 470.58889293670654 and batch: 250, loss is 4.391357851028443 and perplexity is 80.74999103074889
At time: 470.9708218574524 and batch: 300, loss is 4.403121433258057 and perplexity is 81.70550933048335
At time: 471.3523328304291 and batch: 350, loss is 4.40931881904602 and perplexity is 82.21344219505907
At time: 471.73375034332275 and batch: 400, loss is 4.292555160522461 and perplexity is 73.15314793580255
At time: 472.1151690483093 and batch: 450, loss is 4.331334238052368 and perplexity is 76.04568195393628
At time: 472.5100793838501 and batch: 500, loss is 4.307121839523315 and perplexity is 74.22654529697054
At time: 472.89128732681274 and batch: 550, loss is 4.368249998092652 and perplexity is 78.90542615857792
At time: 473.28194189071655 and batch: 600, loss is 4.273813781738281 and perplexity is 71.79492432753126
At time: 473.67411947250366 and batch: 650, loss is 4.373126726150513 and perplexity is 79.29116627457871
At time: 474.0564410686493 and batch: 700, loss is 4.4111842918396 and perplexity is 82.36695227466124
At time: 474.4382824897766 and batch: 750, loss is 4.35877721786499 and perplexity is 78.16150147821871
At time: 474.82107639312744 and batch: 800, loss is 4.306597213745118 and perplexity is 74.18761435086307
At time: 475.20417189598083 and batch: 850, loss is 4.265353465080262 and perplexity is 71.19007873365484
At time: 475.5860285758972 and batch: 900, loss is 4.2085678672790525 and perplexity is 67.26014534679268
At time: 475.96899485588074 and batch: 950, loss is 4.287532019615173 and perplexity is 72.78661072065262
At time: 476.35065031051636 and batch: 1000, loss is 4.330973672866821 and perplexity is 76.01826747116355
At time: 476.7307815551758 and batch: 1050, loss is 4.246834688186645 and perplexity is 69.88385768658156
At time: 477.11046266555786 and batch: 1100, loss is 4.384325542449951 and perplexity is 80.18412418325289
At time: 477.4916846752167 and batch: 1150, loss is 4.301284437179565 and perplexity is 73.7945172749681
At time: 477.8717842102051 and batch: 1200, loss is 4.270034093856811 and perplexity is 71.52407410919145
At time: 478.25919461250305 and batch: 1250, loss is 4.259245834350586 and perplexity is 70.75660112920787
At time: 478.6412024497986 and batch: 1300, loss is 4.310680570602417 and perplexity is 74.49116819219618
At time: 479.0229563713074 and batch: 1350, loss is 4.259080185890197 and perplexity is 70.74488137787468
At time: 479.4035475254059 and batch: 1400, loss is 4.1410182857513425 and perplexity is 62.86680523878936
At time: 479.78505182266235 and batch: 1450, loss is 4.2170721054077145 and perplexity is 67.83458074507308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8153749123597755 and perplexity of 123.39306522450536
Finished 40 epochs...
Completing Train Step...
At time: 481.03173089027405 and batch: 50, loss is 4.411821746826172 and perplexity is 82.41947423753253
At time: 481.42841935157776 and batch: 100, loss is 4.418416905403137 and perplexity is 82.96484015052494
At time: 481.82544684410095 and batch: 150, loss is 4.30327220916748 and perplexity is 73.94134983574709
At time: 482.22305178642273 and batch: 200, loss is 4.365397357940674 and perplexity is 78.68065811530349
At time: 482.60547637939453 and batch: 250, loss is 4.391222925186157 and perplexity is 80.73909650518756
At time: 482.9878616333008 and batch: 300, loss is 4.40288405418396 and perplexity is 81.68611645415244
At time: 483.3698630332947 and batch: 350, loss is 4.409015378952026 and perplexity is 82.18849912498699
At time: 483.7518312931061 and batch: 400, loss is 4.292364282608032 and perplexity is 73.13918594805058
At time: 484.13453340530396 and batch: 450, loss is 4.331094913482666 and perplexity is 76.02748453145695
At time: 484.5176672935486 and batch: 500, loss is 4.306894130706787 and perplexity is 74.20964518241158
At time: 484.900456905365 and batch: 550, loss is 4.368080778121948 and perplexity is 78.89207491435546
At time: 485.2831768989563 and batch: 600, loss is 4.273655767440796 and perplexity is 71.78358059925989
At time: 485.66617584228516 and batch: 650, loss is 4.373014163970947 and perplexity is 79.28224159038291
At time: 486.0482232570648 and batch: 700, loss is 4.41095495223999 and perplexity is 82.34806443675288
At time: 486.42974376678467 and batch: 750, loss is 4.35862440109253 and perplexity is 78.14955800243712
At time: 486.81148862838745 and batch: 800, loss is 4.306447811126709 and perplexity is 74.1765313549605
At time: 487.19419503211975 and batch: 850, loss is 4.265202040672302 and perplexity is 71.17929963426
At time: 487.5765697956085 and batch: 900, loss is 4.208485970497131 and perplexity is 67.25463718289075
At time: 487.9702138900757 and batch: 950, loss is 4.287423434257508 and perplexity is 72.77870758958419
At time: 488.36155343055725 and batch: 1000, loss is 4.330974044799805 and perplexity is 76.01829574486987
At time: 488.74446415901184 and batch: 1050, loss is 4.246800270080566 and perplexity is 69.88145245794645
At time: 489.12643694877625 and batch: 1100, loss is 4.384277362823486 and perplexity is 80.18026103516456
At time: 489.5081171989441 and batch: 1150, loss is 4.301181683540344 and perplexity is 73.78693500932289
At time: 489.890576839447 and batch: 1200, loss is 4.270048108100891 and perplexity is 71.52507647204726
At time: 490.27339720726013 and batch: 1250, loss is 4.259280395507813 and perplexity is 70.75904660148326
At time: 490.65589928627014 and batch: 1300, loss is 4.310624980926514 and perplexity is 74.48702736739334
At time: 491.03874373435974 and batch: 1350, loss is 4.25910059928894 and perplexity is 70.7463255360873
At time: 491.42009377479553 and batch: 1400, loss is 4.140983934402466 and perplexity is 62.86464571632132
At time: 491.80036306381226 and batch: 1450, loss is 4.2170520734786985 and perplexity is 67.83322190117694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815370217347756 and perplexity of 123.39248589394104
Finished 41 epochs...
Completing Train Step...
At time: 493.074471950531 and batch: 50, loss is 4.411512274742126 and perplexity is 82.39397165744609
At time: 493.45478439331055 and batch: 100, loss is 4.418248043060303 and perplexity is 82.95083169602778
At time: 493.8350667953491 and batch: 150, loss is 4.303081588745117 and perplexity is 73.92725644769777
At time: 494.21539330482483 and batch: 200, loss is 4.3652587985992435 and perplexity is 78.66975693037963
At time: 494.5962851047516 and batch: 250, loss is 4.391095385551453 and perplexity is 80.72879972695058
At time: 494.98770093917847 and batch: 300, loss is 4.4026649284362795 and perplexity is 81.66821888379019
At time: 495.37875032424927 and batch: 350, loss is 4.408712491989136 and perplexity is 82.16360906972943
At time: 495.7597734928131 and batch: 400, loss is 4.292187595367432 and perplexity is 73.12626432868194
At time: 496.14048433303833 and batch: 450, loss is 4.330862197875977 and perplexity is 76.00979380780275
At time: 496.520795583725 and batch: 500, loss is 4.306673564910889 and perplexity is 74.1932788779484
At time: 496.91100239753723 and batch: 550, loss is 4.367913494110107 and perplexity is 78.87887863535535
At time: 497.30244398117065 and batch: 600, loss is 4.2735097694396975 and perplexity is 71.77310110499194
At time: 497.7023696899414 and batch: 650, loss is 4.37290472984314 and perplexity is 79.27356588214178
At time: 498.09609508514404 and batch: 700, loss is 4.410736494064331 and perplexity is 82.33007679367232
At time: 498.47688698768616 and batch: 750, loss is 4.35847731590271 and perplexity is 78.13806420516839
At time: 498.85812878608704 and batch: 800, loss is 4.306300234794617 and perplexity is 74.16558546223301
At time: 499.238970041275 and batch: 850, loss is 4.265059843063354 and perplexity is 71.16917882763971
At time: 499.6198523044586 and batch: 900, loss is 4.208421950340271 and perplexity is 67.25033166829004
At time: 500.0008924007416 and batch: 950, loss is 4.287331519126892 and perplexity is 72.7720184325921
At time: 500.3813474178314 and batch: 1000, loss is 4.330942010879516 and perplexity is 76.01586061984699
At time: 500.76097774505615 and batch: 1050, loss is 4.246779427528382 and perplexity is 69.87999596530543
At time: 501.1411712169647 and batch: 1100, loss is 4.384232597351074 and perplexity is 80.17667180823855
At time: 501.52151107788086 and batch: 1150, loss is 4.301074695587158 and perplexity is 73.77904111845754
At time: 501.91545581817627 and batch: 1200, loss is 4.270050816535949 and perplexity is 71.52527019333428
At time: 502.2960226535797 and batch: 1250, loss is 4.2593045854568485 and perplexity is 70.760758279917
At time: 502.6768465042114 and batch: 1300, loss is 4.310568971633911 and perplexity is 74.48285551851464
At time: 503.0574793815613 and batch: 1350, loss is 4.259115433692932 and perplexity is 70.74737502344546
At time: 503.4382736682892 and batch: 1400, loss is 4.140941734313965 and perplexity is 62.86199287868389
At time: 503.81896328926086 and batch: 1450, loss is 4.217018270492554 and perplexity is 67.830928974471
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815365522335737 and perplexity of 123.39190656609667
Finished 42 epochs...
Completing Train Step...
At time: 505.0784146785736 and batch: 50, loss is 4.411219682693481 and perplexity is 82.36986736301728
At time: 505.45843172073364 and batch: 100, loss is 4.418093347549439 and perplexity is 82.93800056722655
At time: 505.8392608165741 and batch: 150, loss is 4.30290096282959 and perplexity is 73.91390447521188
At time: 506.21954560279846 and batch: 200, loss is 4.365122528076172 and perplexity is 78.65903729185476
At time: 506.6011257171631 and batch: 250, loss is 4.390971884727478 and perplexity is 80.7188302692966
At time: 506.9824023246765 and batch: 300, loss is 4.402450008392334 and perplexity is 81.65066863261666
At time: 507.3638324737549 and batch: 350, loss is 4.408448858261108 and perplexity is 82.14195082620934
At time: 507.74487805366516 and batch: 400, loss is 4.292018990516663 and perplexity is 73.11393592514104
At time: 508.13782024383545 and batch: 450, loss is 4.330643739700317 and perplexity is 75.9931906605279
At time: 508.53288745880127 and batch: 500, loss is 4.30646203994751 and perplexity is 74.17758680704166
At time: 508.91638922691345 and batch: 550, loss is 4.3677496814727785 and perplexity is 78.86595833649957
At time: 509.2967267036438 and batch: 600, loss is 4.273375854492188 and perplexity is 71.76349025745729
At time: 509.6785464286804 and batch: 650, loss is 4.372799234390259 and perplexity is 79.26520332252132
At time: 510.07048201560974 and batch: 700, loss is 4.410526628494263 and perplexity is 82.31280035810018
At time: 510.4511685371399 and batch: 750, loss is 4.358335680961609 and perplexity is 78.12699790875259
At time: 510.8331289291382 and batch: 800, loss is 4.30615704536438 and perplexity is 74.15496649458757
At time: 511.21522283554077 and batch: 850, loss is 4.264916582107544 and perplexity is 71.15898379334924
At time: 511.6111328601837 and batch: 900, loss is 4.208344206809998 and perplexity is 67.24510359332126
At time: 511.99316120147705 and batch: 950, loss is 4.287207026481628 and perplexity is 72.76295941541846
At time: 512.3744201660156 and batch: 1000, loss is 4.330945854187012 and perplexity is 76.0161527727353
At time: 512.7572965621948 and batch: 1050, loss is 4.246746044158936 and perplexity is 69.87766317452167
At time: 513.1398818492889 and batch: 1100, loss is 4.384184141159057 and perplexity is 80.17278684616011
At time: 513.5224487781525 and batch: 1150, loss is 4.300960130691529 and perplexity is 73.77058911447286
At time: 513.9048893451691 and batch: 1200, loss is 4.270046939849854 and perplexity is 71.5249929128513
At time: 514.2868103981018 and batch: 1250, loss is 4.2593155145645145 and perplexity is 70.7615316360888
At time: 514.6692223548889 and batch: 1300, loss is 4.3105048561096195 and perplexity is 74.47808016427115
At time: 515.0520105361938 and batch: 1350, loss is 4.259128360748291 and perplexity is 70.7482895845902
At time: 515.4341123104095 and batch: 1400, loss is 4.140893106460571 and perplexity is 62.85893610923282
At time: 515.815970659256 and batch: 1450, loss is 4.216966738700867 and perplexity is 67.82743361523097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8153623923277245 and perplexity of 123.39152034904484
Finished 43 epochs...
Completing Train Step...
At time: 517.0624577999115 and batch: 50, loss is 4.410937347412109 and perplexity is 82.34661472601314
At time: 517.4753670692444 and batch: 100, loss is 4.417945814132691 and perplexity is 82.925765343199
At time: 517.866185426712 and batch: 150, loss is 4.302726449966431 and perplexity is 73.90100667356356
At time: 518.2475326061249 and batch: 200, loss is 4.364991970062256 and perplexity is 78.64876839452744
At time: 518.6365113258362 and batch: 250, loss is 4.390843358039856 and perplexity is 80.70845641208636
At time: 519.0314457416534 and batch: 300, loss is 4.402233409881592 and perplexity is 81.63298513456853
At time: 519.4125618934631 and batch: 350, loss is 4.408189077377319 and perplexity is 82.1206146891078
At time: 519.7937717437744 and batch: 400, loss is 4.291849851608276 and perplexity is 73.10157055959249
At time: 520.1748714447021 and batch: 450, loss is 4.330437803268433 and perplexity is 75.9775425053137
At time: 520.5550482273102 and batch: 500, loss is 4.306253843307495 and perplexity is 74.16214489023739
At time: 520.9396996498108 and batch: 550, loss is 4.36758095741272 and perplexity is 78.852652874316
At time: 521.3623087406158 and batch: 600, loss is 4.273246822357177 and perplexity is 71.75423105847352
At time: 521.7438666820526 and batch: 650, loss is 4.372695960998535 and perplexity is 79.25701775881127
At time: 522.1244242191315 and batch: 700, loss is 4.410320320129395 and perplexity is 82.2958202904758
At time: 522.5048713684082 and batch: 750, loss is 4.358194961547851 and perplexity is 78.1160046969055
At time: 522.8862030506134 and batch: 800, loss is 4.306015710830689 and perplexity is 74.14448657758174
At time: 523.2670526504517 and batch: 850, loss is 4.264775366783142 and perplexity is 71.14893576385332
At time: 523.6464943885803 and batch: 900, loss is 4.208275356292725 and perplexity is 67.24047389253525
At time: 524.0268342494965 and batch: 950, loss is 4.287093276977539 and perplexity is 72.7546831355892
At time: 524.4067196846008 and batch: 1000, loss is 4.3309256458282475 and perplexity is 76.01461662656975
At time: 524.7878260612488 and batch: 1050, loss is 4.246728239059448 and perplexity is 69.87641900685315
At time: 525.168496131897 and batch: 1100, loss is 4.384141359329224 and perplexity is 80.16935698100447
At time: 525.549729347229 and batch: 1150, loss is 4.300844979286194 and perplexity is 73.76209481653852
At time: 525.9305181503296 and batch: 1200, loss is 4.270032444000244 and perplexity is 71.52395610482543
At time: 526.3116981983185 and batch: 1250, loss is 4.259321970939636 and perplexity is 70.76198850055607
At time: 526.6930232048035 and batch: 1300, loss is 4.310438938140869 and perplexity is 74.47317088231704
At time: 527.0744206905365 and batch: 1350, loss is 4.259139099121094 and perplexity is 70.749049310178
At time: 527.4711983203888 and batch: 1400, loss is 4.1408437156677245 and perplexity is 62.85583153321025
At time: 527.8653030395508 and batch: 1450, loss is 4.216901998519898 and perplexity is 67.82304259704324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815360305655716 and perplexity of 123.39126287168187
Finished 44 epochs...
Completing Train Step...
At time: 529.1182553768158 and batch: 50, loss is 4.41066641330719 and perplexity is 82.32430724172482
At time: 529.513608455658 and batch: 100, loss is 4.417807383537292 and perplexity is 82.91428667464648
At time: 529.896087884903 and batch: 150, loss is 4.3025605010986325 and perplexity is 73.88874390270152
At time: 530.2785503864288 and batch: 200, loss is 4.364863786697388 and perplexity is 78.63868757686225
At time: 530.6602733135223 and batch: 250, loss is 4.390714416503906 and perplexity is 80.69805041064977
At time: 531.0754239559174 and batch: 300, loss is 4.402021007537842 and perplexity is 81.61564793849438
At time: 531.470358133316 and batch: 350, loss is 4.407934207916259 and perplexity is 82.09968731928711
At time: 531.868079662323 and batch: 400, loss is 4.291684083938598 and perplexity is 73.08945368691165
At time: 532.2547054290771 and batch: 450, loss is 4.3302430820465085 and perplexity is 75.96274950570047
At time: 532.6364943981171 and batch: 500, loss is 4.306052007675171 and perplexity is 74.14717783732208
At time: 533.0190751552582 and batch: 550, loss is 4.367419033050537 and perplexity is 78.83988574247564
At time: 533.4005999565125 and batch: 600, loss is 4.273124761581421 and perplexity is 71.74547321587214
At time: 533.7825384140015 and batch: 650, loss is 4.372592096328735 and perplexity is 79.2487861823248
At time: 534.164822101593 and batch: 700, loss is 4.41012716293335 and perplexity is 82.27992579569971
At time: 534.5473701953888 and batch: 750, loss is 4.358061184883118 and perplexity is 78.10555529729335
At time: 534.9285364151001 and batch: 800, loss is 4.305876145362854 and perplexity is 74.13413928970398
At time: 535.3092095851898 and batch: 850, loss is 4.264637842178344 and perplexity is 71.1391517073703
At time: 535.6908543109894 and batch: 900, loss is 4.208195476531983 and perplexity is 67.23510295408603
At time: 536.0742468833923 and batch: 950, loss is 4.28695855140686 and perplexity is 72.74488187963891
At time: 536.456102848053 and batch: 1000, loss is 4.3309324264526365 and perplexity is 76.01513205488064
At time: 536.8391783237457 and batch: 1050, loss is 4.246695513725281 and perplexity is 69.87413231510735
At time: 537.2208330631256 and batch: 1100, loss is 4.384096794128418 and perplexity is 80.16578429712139
At time: 537.6037771701813 and batch: 1150, loss is 4.300731310844421 and perplexity is 73.75371087066289
At time: 537.9864506721497 and batch: 1200, loss is 4.270014400482178 and perplexity is 71.52266557267419
At time: 538.3698306083679 and batch: 1250, loss is 4.2593135643005375 and perplexity is 70.76139363255727
At time: 538.7635843753815 and batch: 1300, loss is 4.310368089675904 and perplexity is 74.4678947593837
At time: 539.151175737381 and batch: 1350, loss is 4.259144067764282 and perplexity is 70.74940083783325
At time: 539.534191608429 and batch: 1400, loss is 4.140784492492676 and perplexity is 62.85210912152415
At time: 539.9167680740356 and batch: 1450, loss is 4.216827487945556 and perplexity is 67.81798925145192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815369174011752 and perplexity of 123.392357154185
Annealing...
Finished 45 epochs...
Completing Train Step...
At time: 541.1919765472412 and batch: 50, loss is 4.410354051589966 and perplexity is 82.2985962955122
At time: 541.5726945400238 and batch: 100, loss is 4.41798933506012 and perplexity is 82.92937442794928
At time: 541.9598562717438 and batch: 150, loss is 4.302938203811646 and perplexity is 73.91665715285805
At time: 542.3579363822937 and batch: 200, loss is 4.364474277496338 and perplexity is 78.60806304914745
At time: 542.7457749843597 and batch: 250, loss is 4.390648212432861 and perplexity is 80.69270804803223
At time: 543.1262676715851 and batch: 300, loss is 4.401717920303344 and perplexity is 81.59091502577336
At time: 543.521861076355 and batch: 350, loss is 4.40764965057373 and perplexity is 82.07632857404991
At time: 543.9170207977295 and batch: 400, loss is 4.290803489685058 and perplexity is 73.02511986415516
At time: 544.3044652938843 and batch: 450, loss is 4.329815397262573 and perplexity is 75.93026833993628
At time: 544.7048256397247 and batch: 500, loss is 4.3054384517669675 and perplexity is 74.10169835181362
At time: 545.0907778739929 and batch: 550, loss is 4.366595067977905 and perplexity is 78.77495118587063
At time: 545.4715712070465 and batch: 600, loss is 4.272204761505127 and perplexity is 71.67949772841997
At time: 545.8708951473236 and batch: 650, loss is 4.371892528533936 and perplexity is 79.19336567119728
At time: 546.2508747577667 and batch: 700, loss is 4.40933406829834 and perplexity is 82.21469589814215
At time: 546.6312334537506 and batch: 750, loss is 4.357333240509033 and perplexity is 78.0487194868939
At time: 547.0108153820038 and batch: 800, loss is 4.304820294380188 and perplexity is 74.05590599450468
At time: 547.3908724784851 and batch: 850, loss is 4.263634085655212 and perplexity is 71.06778114511998
At time: 547.7742321491241 and batch: 900, loss is 4.207402839660644 and perplexity is 67.18183104786404
At time: 548.1632134914398 and batch: 950, loss is 4.28553421497345 and perplexity is 72.64134244902978
At time: 548.556179523468 and batch: 1000, loss is 4.329992122650147 and perplexity is 75.94368833182894
At time: 548.9434549808502 and batch: 1050, loss is 4.245378131866455 and perplexity is 69.78214200727965
At time: 549.3246073722839 and batch: 1100, loss is 4.3831402206420895 and perplexity is 80.08913649882248
At time: 549.7041652202606 and batch: 1150, loss is 4.299235496520996 and perplexity is 73.6434714829191
At time: 550.084175825119 and batch: 1200, loss is 4.2687456417083744 and perplexity is 71.43197810562813
At time: 550.4651126861572 and batch: 1250, loss is 4.258129706382752 and perplexity is 70.67767176360869
At time: 550.8675830364227 and batch: 1300, loss is 4.308949565887451 and perplexity is 74.36233516628913
At time: 551.2627601623535 and batch: 1350, loss is 4.257372484207154 and perplexity is 70.6241733208895
At time: 551.6578760147095 and batch: 1400, loss is 4.138973617553711 and perplexity is 62.7383948045333
At time: 552.0592048168182 and batch: 1450, loss is 4.21501916885376 and perplexity is 67.69546350293489
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815188676883013 and perplexity of 123.37008719790235
Finished 46 epochs...
Completing Train Step...
At time: 553.3761427402496 and batch: 50, loss is 4.410034222602844 and perplexity is 82.27227902755438
At time: 553.7642781734467 and batch: 100, loss is 4.417747287750244 and perplexity is 82.90930402505087
At time: 554.1447055339813 and batch: 150, loss is 4.302735862731933 and perplexity is 73.90170228968358
At time: 554.5254044532776 and batch: 200, loss is 4.364276857376098 and perplexity is 78.59254576765065
At time: 554.9055912494659 and batch: 250, loss is 4.390557017326355 and perplexity is 80.68534960345967
At time: 555.285050868988 and batch: 300, loss is 4.40154504776001 and perplexity is 81.57681141587844
At time: 555.6794090270996 and batch: 350, loss is 4.407464628219604 and perplexity is 82.06114402330313
At time: 556.0736291408539 and batch: 400, loss is 4.290649056434631 and perplexity is 73.0138432282979
At time: 556.4579050540924 and batch: 450, loss is 4.3296949005126955 and perplexity is 75.92111954059534
At time: 556.8391759395599 and batch: 500, loss is 4.305312328338623 and perplexity is 74.09235298091882
At time: 557.2193932533264 and batch: 550, loss is 4.366456460952759 and perplexity is 78.76403318090429
At time: 557.6167349815369 and batch: 600, loss is 4.272131633758545 and perplexity is 71.67425615992937
At time: 557.9960653781891 and batch: 650, loss is 4.37179799079895 and perplexity is 79.18587926366045
At time: 558.396776676178 and batch: 700, loss is 4.409187927246093 and perplexity is 82.20268183386887
At time: 558.7767105102539 and batch: 750, loss is 4.357204403877258 and perplexity is 78.03866460049365
At time: 559.159345626831 and batch: 800, loss is 4.304770731925965 and perplexity is 74.0522356930092
At time: 559.5615963935852 and batch: 850, loss is 4.263593935966492 and perplexity is 71.06492785310873
At time: 559.957436800003 and batch: 900, loss is 4.207354331016541 and perplexity is 67.17857222737264
At time: 560.3409678936005 and batch: 950, loss is 4.285482678413391 and perplexity is 72.63759886058858
At time: 560.7355647087097 and batch: 1000, loss is 4.3299651527404786 and perplexity is 75.94164016503431
At time: 561.1295142173767 and batch: 1050, loss is 4.245435438156128 and perplexity is 69.78614107750835
At time: 561.5160050392151 and batch: 1100, loss is 4.38313045501709 and perplexity is 80.08835438216785
At time: 561.896870136261 and batch: 1150, loss is 4.299235553741455 and perplexity is 73.64347569683243
At time: 562.2782831192017 and batch: 1200, loss is 4.268764128684998 and perplexity is 71.4332986791442
At time: 562.6593911647797 and batch: 1250, loss is 4.258229627609253 and perplexity is 70.68473431610111
At time: 563.0504496097565 and batch: 1300, loss is 4.308990068435669 and perplexity is 74.36534709134975
At time: 563.4407074451447 and batch: 1350, loss is 4.257410011291504 and perplexity is 70.62682368992888
At time: 563.8395662307739 and batch: 1400, loss is 4.139061808586121 and perplexity is 62.74392801232889
At time: 564.225879907608 and batch: 1450, loss is 4.215069479942322 and perplexity is 67.69886942107142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815155811798879 and perplexity of 123.36603269623309
Finished 47 epochs...
Completing Train Step...
At time: 565.5251469612122 and batch: 50, loss is 4.409877161979676 and perplexity is 82.25935830683561
At time: 565.9210934638977 and batch: 100, loss is 4.417634716033936 and perplexity is 82.89997130770867
At time: 566.3135178089142 and batch: 150, loss is 4.302671213150024 and perplexity is 73.89692472996346
At time: 566.6948537826538 and batch: 200, loss is 4.3641468334198 and perplexity is 78.58232751823736
At time: 567.0986630916595 and batch: 250, loss is 4.390451955795288 and perplexity is 80.6768731223795
At time: 567.4885637760162 and batch: 300, loss is 4.401415166854858 and perplexity is 81.5662168338042
At time: 567.8829824924469 and batch: 350, loss is 4.407346248626709 and perplexity is 82.05143023344971
At time: 568.2850451469421 and batch: 400, loss is 4.290537495613098 and perplexity is 73.0056981983056
At time: 568.6778445243835 and batch: 450, loss is 4.329593820571899 and perplexity is 75.91344582616283
At time: 569.0601491928101 and batch: 500, loss is 4.305222969055176 and perplexity is 74.0857324371555
At time: 569.449634552002 and batch: 550, loss is 4.366377468109131 and perplexity is 78.75781163167989
At time: 569.8382792472839 and batch: 600, loss is 4.272061176300049 and perplexity is 71.66920635190115
At time: 570.2213492393494 and batch: 650, loss is 4.371739721298217 and perplexity is 79.18126527643933
At time: 570.6166179180145 and batch: 700, loss is 4.409088954925537 and perplexity is 82.19454644628757
At time: 570.9988167285919 and batch: 750, loss is 4.357111525535584 and perplexity is 78.03141683532448
At time: 571.3815348148346 and batch: 800, loss is 4.304727439880371 and perplexity is 74.04902988963865
At time: 571.7637252807617 and batch: 850, loss is 4.2635540103912355 and perplexity is 71.06209060162345
At time: 572.145913362503 and batch: 900, loss is 4.207324576377869 and perplexity is 67.1765733829671
At time: 572.5282471179962 and batch: 950, loss is 4.285432896614075 and perplexity is 72.63398292022401
At time: 572.9108612537384 and batch: 1000, loss is 4.329957942962647 and perplexity is 75.9410926446543
At time: 573.2934753894806 and batch: 1050, loss is 4.245465764999389 and perplexity is 69.78825750296272
At time: 573.6768112182617 and batch: 1100, loss is 4.38312798500061 and perplexity is 80.08815656285697
At time: 574.0604844093323 and batch: 1150, loss is 4.2992168807983395 and perplexity is 73.6421005692388
At time: 574.4424817562103 and batch: 1200, loss is 4.268783950805664 and perplexity is 71.43471465264398
At time: 574.8253366947174 and batch: 1250, loss is 4.258296036720276 and perplexity is 70.68942858233929
At time: 575.20720911026 and batch: 1300, loss is 4.309008951187134 and perplexity is 74.36675132697434
At time: 575.5898826122284 and batch: 1350, loss is 4.2574263048172 and perplexity is 70.6279744592705
At time: 575.9868795871735 and batch: 1400, loss is 4.139104099273681 and perplexity is 62.74658155229441
At time: 576.385493516922 and batch: 1450, loss is 4.215093121528626 and perplexity is 67.70046994865494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8151427700988245 and perplexity of 123.36442380392916
Finished 48 epochs...
Completing Train Step...
At time: 577.6647181510925 and batch: 50, loss is 4.4097394323348995 and perplexity is 82.24802953480827
At time: 578.0796263217926 and batch: 100, loss is 4.417552752494812 and perplexity is 82.89317681112132
At time: 578.4803574085236 and batch: 150, loss is 4.302612209320069 and perplexity is 73.89256465701425
At time: 578.8717451095581 and batch: 200, loss is 4.364037361145019 and perplexity is 78.57372540294156
At time: 579.2523813247681 and batch: 250, loss is 4.3903669309616085 and perplexity is 80.67001387626776
At time: 579.6408243179321 and batch: 300, loss is 4.401306657791138 and perplexity is 81.55736664015618
At time: 580.0240180492401 and batch: 350, loss is 4.407247238159179 and perplexity is 82.04330668514561
At time: 580.4042222499847 and batch: 400, loss is 4.290434718132019 and perplexity is 72.99819524211446
At time: 580.797755241394 and batch: 450, loss is 4.329504146575927 and perplexity is 75.90663866934464
At time: 581.1784698963165 and batch: 500, loss is 4.305146160125733 and perplexity is 74.08004220989291
At time: 581.5598719120026 and batch: 550, loss is 4.366309394836426 and perplexity is 78.75245051216758
At time: 581.9407904148102 and batch: 600, loss is 4.271995592117309 and perplexity is 71.66450613970643
At time: 582.3218207359314 and batch: 650, loss is 4.371688823699952 and perplexity is 79.1772352427695
At time: 582.7023108005524 and batch: 700, loss is 4.409004230499267 and perplexity is 82.18758285549465
At time: 583.083484172821 and batch: 750, loss is 4.357031207084656 and perplexity is 78.02514972448627
At time: 583.4763042926788 and batch: 800, loss is 4.304684247970581 and perplexity is 74.04583163968937
At time: 583.8710005283356 and batch: 850, loss is 4.263513827323914 and perplexity is 71.05923516622326
At time: 584.2668631076813 and batch: 900, loss is 4.207300539016724 and perplexity is 67.17495865481919
At time: 584.6501591205597 and batch: 950, loss is 4.2853839635849 and perplexity is 72.63042880637622
At time: 585.0308158397675 and batch: 1000, loss is 4.329952516555786 and perplexity is 75.94068055850624
At time: 585.4248282909393 and batch: 1050, loss is 4.2454836511611935 and perplexity is 69.78950575819167
At time: 585.8258860111237 and batch: 1100, loss is 4.383121738433838 and perplexity is 80.08765628840183
At time: 586.2180666923523 and batch: 1150, loss is 4.2991925573349 and perplexity is 73.64030936008227
At time: 586.6060843467712 and batch: 1200, loss is 4.2687979459762575 and perplexity is 71.43571440065762
At time: 587.0008201599121 and batch: 1250, loss is 4.258344445228577 and perplexity is 70.69285063495714
At time: 587.3927643299103 and batch: 1300, loss is 4.309018716812134 and perplexity is 74.36747756832636
At time: 587.7917339801788 and batch: 1350, loss is 4.257434115409851 and perplexity is 70.62852610776316
At time: 588.1893875598907 and batch: 1400, loss is 4.139128193855286 and perplexity is 62.7480934231379
At time: 588.5773627758026 and batch: 1450, loss is 4.215103297233582 and perplexity is 67.70115885216755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815136510082799 and perplexity of 123.36365154307636
Finished 49 epochs...
Completing Train Step...
At time: 589.8496940135956 and batch: 50, loss is 4.409611639976501 and perplexity is 82.23751953670342
At time: 590.2440960407257 and batch: 100, loss is 4.417487235069275 and perplexity is 82.88774604148902
At time: 590.6410808563232 and batch: 150, loss is 4.302558126449585 and perplexity is 73.88856844307455
At time: 591.0212171077728 and batch: 200, loss is 4.363935632705688 and perplexity is 78.5657326270371
At time: 591.401782989502 and batch: 250, loss is 4.3902921915054325 and perplexity is 80.66398486860612
At time: 591.7824029922485 and batch: 300, loss is 4.4012078762054445 and perplexity is 81.54931067205169
At time: 592.1789898872375 and batch: 350, loss is 4.407157897949219 and perplexity is 82.03597724631217
At time: 592.5698413848877 and batch: 400, loss is 4.290337915420532 and perplexity is 72.99112916089481
At time: 592.9534213542938 and batch: 450, loss is 4.329420204162598 and perplexity is 75.90026715033108
At time: 593.3345892429352 and batch: 500, loss is 4.30507607460022 and perplexity is 74.07485045314023
At time: 593.7157309055328 and batch: 550, loss is 4.366246566772461 and perplexity is 78.74750280359854
At time: 594.0954184532166 and batch: 600, loss is 4.271931943893432 and perplexity is 71.65994496633245
At time: 594.487279176712 and batch: 650, loss is 4.371641235351563 and perplexity is 79.17346741856726
At time: 594.8827018737793 and batch: 700, loss is 4.408924894332886 and perplexity is 82.18106266639357
At time: 595.2688875198364 and batch: 750, loss is 4.3569563341140745 and perplexity is 78.01930796844385
At time: 595.6715085506439 and batch: 800, loss is 4.304640426635742 and perplexity is 74.04258692360206
At time: 596.0714445114136 and batch: 850, loss is 4.26347288608551 and perplexity is 71.05632597268892
At time: 596.4514241218567 and batch: 900, loss is 4.207281727790832 and perplexity is 67.17369502338293
At time: 596.832113981247 and batch: 950, loss is 4.285336813926697 and perplexity is 72.62700438721355
At time: 597.2118408679962 and batch: 1000, loss is 4.329943923950196 and perplexity is 75.94002803299337
At time: 597.5927710533142 and batch: 1050, loss is 4.245494823455811 and perplexity is 69.79028547146679
At time: 597.9735386371613 and batch: 1100, loss is 4.383111791610718 and perplexity is 80.08685967461254
At time: 598.3536517620087 and batch: 1150, loss is 4.299165658950805 and perplexity is 73.63832858139627
At time: 598.7444899082184 and batch: 1200, loss is 4.268806266784668 and perplexity is 71.43630880602376
At time: 599.1345698833466 and batch: 1250, loss is 4.258382105827332 and perplexity is 70.69551302017295
At time: 599.5152385234833 and batch: 1300, loss is 4.309023675918579 and perplexity is 74.3678463654781
At time: 599.8962707519531 and batch: 1350, loss is 4.2574371194839475 and perplexity is 70.62873828140759
At time: 600.2767162322998 and batch: 1400, loss is 4.139143691062928 and perplexity is 62.74906585090574
At time: 600.6571974754333 and batch: 1450, loss is 4.215106248855591 and perplexity is 67.70135868069296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815132336738782 and perplexity of 123.36313670519357
Finished Training.
Improved accuracyfrom -10000000 to -123.36313670519357
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7fb370c898>
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.19290165492183386, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 22.074200923057358, 'anneal': 3.0942517694212013, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.614060640335083 and batch: 50, loss is 6.364475317001343 and perplexity is 580.8399914841923
At time: 1.0073418617248535 and batch: 100, loss is 5.665598278045654 and perplexity is 288.7606886283617
At time: 1.3873717784881592 and batch: 150, loss is 5.49148868560791 and perplexity is 242.61812025184946
At time: 1.7778027057647705 and batch: 200, loss is 5.464616422653198 and perplexity is 236.18524242284263
At time: 2.157775402069092 and batch: 250, loss is 5.436013145446777 and perplexity is 229.5252730011024
At time: 2.5355074405670166 and batch: 300, loss is 5.465317134857178 and perplexity is 236.35079830134646
At time: 2.9147510528564453 and batch: 350, loss is 5.473187475204468 and perplexity is 238.2182988179074
At time: 3.2964565753936768 and batch: 400, loss is 5.365684356689453 and perplexity is 213.93759421789227
At time: 3.678377389907837 and batch: 450, loss is 5.375706644058227 and perplexity is 216.0925188653553
At time: 4.060565710067749 and batch: 500, loss is 5.354620590209961 and perplexity is 211.5836842008446
At time: 4.4591710567474365 and batch: 550, loss is 5.415777235031128 and perplexity is 224.92729913390872
At time: 4.865645170211792 and batch: 600, loss is 5.248964786529541 and perplexity is 190.3690937670637
At time: 5.266580581665039 and batch: 650, loss is 5.401933126449585 and perplexity is 221.83483676560206
At time: 5.674423694610596 and batch: 700, loss is 5.4022508811950685 and perplexity is 221.9053370380028
At time: 6.0568318367004395 and batch: 750, loss is 5.356725282669068 and perplexity is 212.02947174373227
At time: 6.437811613082886 and batch: 800, loss is 5.270455551147461 and perplexity is 194.50454903649918
At time: 6.819297790527344 and batch: 850, loss is 5.223426885604859 and perplexity is 185.56901949684516
At time: 7.229562759399414 and batch: 900, loss is 5.202083339691162 and perplexity is 181.6502871932278
At time: 7.628619909286499 and batch: 950, loss is 5.239481267929077 and perplexity is 188.57225855229012
At time: 8.014009952545166 and batch: 1000, loss is 5.298684301376343 and perplexity is 200.07340043142509
At time: 8.394705057144165 and batch: 1050, loss is 5.192155456542968 and perplexity is 179.85580680302007
At time: 8.77549409866333 and batch: 1100, loss is 5.294082984924317 and perplexity is 199.15491414595928
At time: 9.157208442687988 and batch: 1150, loss is 5.274581327438354 and perplexity is 195.3086890035158
At time: 9.566779851913452 and batch: 1200, loss is 5.208719291687012 and perplexity is 182.85971820394784
At time: 9.981426000595093 and batch: 1250, loss is 5.2230611038208 and perplexity is 185.50115414253952
At time: 10.365008115768433 and batch: 1300, loss is 5.303924331665039 and perplexity is 201.12454271316471
At time: 10.745960712432861 and batch: 1350, loss is 5.252443771362305 and perplexity is 191.03253834456004
At time: 11.12978744506836 and batch: 1400, loss is 5.11473331451416 and perplexity is 166.4563835619864
At time: 11.514647960662842 and batch: 1450, loss is 5.200091371536255 and perplexity is 181.2888057550937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.18138187767094 and perplexity of 177.92851663085347
Finished 1 epochs...
Completing Train Step...
At time: 12.82030701637268 and batch: 50, loss is 5.1924371242523195 and perplexity is 179.90647351138864
At time: 13.218153953552246 and batch: 100, loss is 5.207462253570557 and perplexity is 182.63000098010338
At time: 13.613713502883911 and batch: 150, loss is 5.092184438705444 and perplexity is 162.74498047953594
At time: 13.998081684112549 and batch: 200, loss is 5.171927452087402 and perplexity is 176.25423188292743
At time: 14.376723051071167 and batch: 250, loss is 5.20026180267334 and perplexity is 181.31970564547623
At time: 14.756417274475098 and batch: 300, loss is 5.200287466049194 and perplexity is 181.32435898094195
At time: 15.135844230651855 and batch: 350, loss is 5.217867031097412 and perplexity is 184.54014559233718
At time: 15.515591859817505 and batch: 400, loss is 5.120558767318726 and perplexity is 167.4288972845827
At time: 15.897045135498047 and batch: 450, loss is 5.1424009895324705 and perplexity is 171.12614755506783
At time: 16.28178858757019 and batch: 500, loss is 5.135246343612671 and perplexity is 169.9061700194512
At time: 16.661738395690918 and batch: 550, loss is 5.196651220321655 and perplexity is 180.66621636461596
At time: 17.0420081615448 and batch: 600, loss is 5.065071868896484 and perplexity is 158.39182511031638
At time: 17.433650732040405 and batch: 650, loss is 5.214941120147705 and perplexity is 184.00098670976996
At time: 17.82909369468689 and batch: 700, loss is 5.210817613601685 and perplexity is 183.24381960122403
At time: 18.21199607849121 and batch: 750, loss is 5.180790891647339 and perplexity is 177.82339443025978
At time: 18.605304718017578 and batch: 800, loss is 5.122193775177002 and perplexity is 167.70286875906947
At time: 19.000099182128906 and batch: 850, loss is 5.090324029922486 and perplexity is 162.4424897539172
At time: 19.385996341705322 and batch: 900, loss is 5.044934682846069 and perplexity is 155.234159413727
At time: 19.80359196662903 and batch: 950, loss is 5.131904363632202 and perplexity is 169.33929477116465
At time: 20.206371068954468 and batch: 1000, loss is 5.169921007156372 and perplexity is 175.90094201964442
At time: 20.601261615753174 and batch: 1050, loss is 5.048064918518066 and perplexity is 155.72084023247618
At time: 20.982789754867554 and batch: 1100, loss is 5.167765550613403 and perplexity is 175.52220350709095
At time: 21.364057302474976 and batch: 1150, loss is 5.147974224090576 and perplexity is 172.0825363283715
At time: 21.74501633644104 and batch: 1200, loss is 5.0998760604858395 and perplexity is 164.0015797641178
At time: 22.125555992126465 and batch: 1250, loss is 5.075143766403198 and perplexity is 159.9951922593333
At time: 22.511849880218506 and batch: 1300, loss is 5.190986013412475 and perplexity is 179.6455986024997
At time: 22.907078742980957 and batch: 1350, loss is 5.149814214706421 and perplexity is 172.39945805745697
At time: 23.30966305732727 and batch: 1400, loss is 5.008571710586548 and perplexity is 149.6907816322368
At time: 23.69268798828125 and batch: 1450, loss is 5.112587604522705 and perplexity is 166.09959935124724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.2999043260884084 and perplexity of 200.31764388540762
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 24.943675756454468 and batch: 50, loss is 5.142442855834961 and perplexity is 171.13331212410137
At time: 25.338082313537598 and batch: 100, loss is 5.105341958999634 and perplexity is 164.9004500842941
At time: 25.73041033744812 and batch: 150, loss is 4.981875629425049 and perplexity is 145.74749373288932
At time: 26.11724066734314 and batch: 200, loss is 5.034959278106689 and perplexity is 153.6933338008665
At time: 26.49800181388855 and batch: 250, loss is 5.041719541549683 and perplexity is 154.7358611361192
At time: 26.897652864456177 and batch: 300, loss is 5.050261354446411 and perplexity is 156.06324698033941
At time: 27.305410385131836 and batch: 350, loss is 5.064775800704956 and perplexity is 158.34493727044452
At time: 27.703254222869873 and batch: 400, loss is 4.939096660614013 and perplexity is 139.64404659922081
At time: 28.098920583724976 and batch: 450, loss is 4.987573528289795 and perplexity is 146.58031863479104
At time: 28.48732042312622 and batch: 500, loss is 4.9680479049682615 and perplexity is 143.74600744099908
At time: 28.86640977859497 and batch: 550, loss is 5.02231122970581 and perplexity is 151.7616548120589
At time: 29.24588942527771 and batch: 600, loss is 4.888609313964844 and perplexity is 132.76880587956225
At time: 29.638824701309204 and batch: 650, loss is 5.005442800521851 and perplexity is 149.22314461759308
At time: 30.02931785583496 and batch: 700, loss is 5.039216108322144 and perplexity is 154.34897471407842
At time: 30.412055730819702 and batch: 750, loss is 4.995089149475097 and perplexity is 147.68611093588208
At time: 30.790518522262573 and batch: 800, loss is 4.91527135848999 and perplexity is 136.35630622402863
At time: 31.19161891937256 and batch: 850, loss is 4.858579549789429 and perplexity is 128.84105975541576
At time: 31.584200620651245 and batch: 900, loss is 4.808036022186279 and perplexity is 122.49081188927771
At time: 31.986278772354126 and batch: 950, loss is 4.882105102539063 and perplexity is 131.90805179315277
At time: 32.37704801559448 and batch: 1000, loss is 4.938055219650269 and perplexity is 139.4986912713834
At time: 32.77370238304138 and batch: 1050, loss is 4.812817878723145 and perplexity is 123.07794806049064
At time: 33.15217328071594 and batch: 1100, loss is 4.957327098846435 and perplexity is 142.2131656955117
At time: 33.53055477142334 and batch: 1150, loss is 4.911590662002563 and perplexity is 135.855342559839
At time: 33.92382526397705 and batch: 1200, loss is 4.836673841476441 and perplexity is 126.04939342900809
At time: 34.32263422012329 and batch: 1250, loss is 4.822430696487427 and perplexity is 124.26677879801078
At time: 34.726035356521606 and batch: 1300, loss is 4.892816123962402 and perplexity is 133.3285154900496
At time: 35.123733043670654 and batch: 1350, loss is 4.856353788375855 and perplexity is 128.55460919968175
At time: 35.51344037055969 and batch: 1400, loss is 4.71681170463562 and perplexity is 111.81119665028348
At time: 35.890340089797974 and batch: 1450, loss is 4.807170372009278 and perplexity is 122.38482357730378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.052533532819178 and perplexity of 156.41825368145058
Finished 3 epochs...
Completing Train Step...
At time: 37.158647775650024 and batch: 50, loss is 4.9230032062530515 and perplexity is 137.41467874028888
At time: 37.552358627319336 and batch: 100, loss is 4.932962427139282 and perplexity is 138.79005937042385
At time: 37.93364405632019 and batch: 150, loss is 4.819341478347778 and perplexity is 123.88348395630491
At time: 38.31267237663269 and batch: 200, loss is 4.894358158111572 and perplexity is 133.53427121439842
At time: 38.69250726699829 and batch: 250, loss is 4.913462924957275 and perplexity is 136.10993774510953
At time: 39.07206153869629 and batch: 300, loss is 4.927423515319824 and perplexity is 138.02343855267176
At time: 39.46597719192505 and batch: 350, loss is 4.944523105621338 and perplexity is 140.40387706329005
At time: 39.8451828956604 and batch: 400, loss is 4.811115016937256 and perplexity is 122.86854167172338
At time: 40.246832609176636 and batch: 450, loss is 4.855377521514892 and perplexity is 128.42916683746995
At time: 40.64233064651489 and batch: 500, loss is 4.8531356525421145 and perplexity is 128.14156797307808
At time: 41.039597272872925 and batch: 550, loss is 4.901878671646118 and perplexity is 134.5423032165209
At time: 41.43358874320984 and batch: 600, loss is 4.78715446472168 and perplexity is 119.95953345737819
At time: 41.812626123428345 and batch: 650, loss is 4.8758283042907715 and perplexity is 131.08268460620835
At time: 42.214542627334595 and batch: 700, loss is 4.915969371795654 and perplexity is 136.4515179657497
At time: 42.606138467788696 and batch: 750, loss is 4.87992226600647 and perplexity is 131.62043210633905
At time: 42.989816188812256 and batch: 800, loss is 4.8132211780548095 and perplexity is 123.12759532536755
At time: 43.369067907333374 and batch: 850, loss is 4.7627378273010255 and perplexity is 117.0659940279026
At time: 43.7480685710907 and batch: 900, loss is 4.713736953735352 and perplexity is 111.46793306816417
At time: 44.127358198165894 and batch: 950, loss is 4.797958288192749 and perplexity is 121.26258135568696
At time: 44.5073504447937 and batch: 1000, loss is 4.833517847061157 and perplexity is 125.65220933236434
At time: 44.88636136054993 and batch: 1050, loss is 4.721544218063355 and perplexity is 112.34159871731731
At time: 45.28526473045349 and batch: 1100, loss is 4.867154541015625 and perplexity is 129.9506211531445
At time: 45.68728041648865 and batch: 1150, loss is 4.820079002380371 and perplexity is 123.97488470394502
At time: 46.08727836608887 and batch: 1200, loss is 4.770912256240845 and perplexity is 118.02686360686047
At time: 46.500574827194214 and batch: 1250, loss is 4.74878228187561 and perplexity is 115.44362111060194
At time: 46.892683029174805 and batch: 1300, loss is 4.810421085357666 and perplexity is 122.78330888679994
At time: 47.27074575424194 and batch: 1350, loss is 4.783371572494507 and perplexity is 119.50659671626289
At time: 47.64937162399292 and batch: 1400, loss is 4.646313610076905 and perplexity is 104.20015429506013
At time: 48.029146671295166 and batch: 1450, loss is 4.745418691635132 and perplexity is 115.05596839124405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.041645278278579 and perplexity of 154.72437037159028
Finished 4 epochs...
Completing Train Step...
At time: 49.374748945236206 and batch: 50, loss is 4.832733249664306 and perplexity is 125.55366160121575
At time: 49.75494408607483 and batch: 100, loss is 4.847697305679321 and perplexity is 127.44658118140507
At time: 50.158443212509155 and batch: 150, loss is 4.740675411224365 and perplexity is 114.51151793161758
At time: 50.55581569671631 and batch: 200, loss is 4.813269166946411 and perplexity is 123.13350422397242
At time: 50.944074630737305 and batch: 250, loss is 4.843302774429321 and perplexity is 126.88774201514144
At time: 51.32496690750122 and batch: 300, loss is 4.851215181350708 and perplexity is 127.89571193864379
At time: 51.721991777420044 and batch: 350, loss is 4.862013368606568 and perplexity is 129.28423707066352
At time: 52.117483615875244 and batch: 400, loss is 4.741535730361939 and perplexity is 114.61007677191597
At time: 52.50144338607788 and batch: 450, loss is 4.782828102111816 and perplexity is 119.4416660659523
At time: 52.88272285461426 and batch: 500, loss is 4.779125900268554 and perplexity is 119.00028645203075
At time: 53.27502989768982 and batch: 550, loss is 4.823760643005371 and perplexity is 124.43215691541887
At time: 53.65667390823364 and batch: 600, loss is 4.723928318023682 and perplexity is 112.60975184327718
At time: 54.03758478164673 and batch: 650, loss is 4.814507265090942 and perplexity is 123.28605000091709
At time: 54.41906189918518 and batch: 700, loss is 4.857302417755127 and perplexity is 128.6766177401028
At time: 54.81648540496826 and batch: 750, loss is 4.816261968612671 and perplexity is 123.50257037601085
At time: 55.20327162742615 and batch: 800, loss is 4.757858715057373 and perplexity is 116.49620706075896
At time: 55.60595703125 and batch: 850, loss is 4.7089956188201905 and perplexity is 110.94067720124961
At time: 55.99578022956848 and batch: 900, loss is 4.65019962310791 and perplexity is 104.60586524093816
At time: 56.38781189918518 and batch: 950, loss is 4.722016115188598 and perplexity is 112.39462490526608
At time: 56.78316307067871 and batch: 1000, loss is 4.782688446044922 and perplexity is 119.42498647737625
At time: 57.16694498062134 and batch: 1050, loss is 4.675535326004028 and perplexity is 107.28998684145881
At time: 57.5483934879303 and batch: 1100, loss is 4.821577634811401 and perplexity is 124.16081677391185
At time: 57.92900466918945 and batch: 1150, loss is 4.765739936828613 and perplexity is 117.4179670303312
At time: 58.30857253074646 and batch: 1200, loss is 4.726854600906372 and perplexity is 112.93976244922013
At time: 58.68710923194885 and batch: 1250, loss is 4.69360107421875 and perplexity is 109.24587482443661
At time: 59.066590785980225 and batch: 1300, loss is 4.7597697067260745 and perplexity is 116.71904319306915
At time: 59.44592475891113 and batch: 1350, loss is 4.734663200378418 and perplexity is 113.82511600566978
At time: 59.82505965232849 and batch: 1400, loss is 4.598424043655395 and perplexity is 99.3276561801694
At time: 60.2047016620636 and batch: 1450, loss is 4.6898769187927245 and perplexity is 108.8397828511032
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.026827298677885 and perplexity of 152.44857082508915
Finished 5 epochs...
Completing Train Step...
At time: 61.431835889816284 and batch: 50, loss is 4.772190828323364 and perplexity is 118.17786597278938
At time: 61.82310438156128 and batch: 100, loss is 4.797901468276978 and perplexity is 121.25569142177268
At time: 62.19869375228882 and batch: 150, loss is 4.683779573440551 and perplexity is 108.17816820327367
At time: 62.576725482940674 and batch: 200, loss is 4.760097541809082 and perplexity is 116.7573140632071
At time: 62.95555067062378 and batch: 250, loss is 4.793897972106934 and perplexity is 120.77121517207254
At time: 63.340447425842285 and batch: 300, loss is 4.792852201461792 and perplexity is 120.6449821973416
At time: 63.72931981086731 and batch: 350, loss is 4.812161045074463 and perplexity is 122.99713286676858
At time: 64.10897254943848 and batch: 400, loss is 4.699922323226929 and perplexity is 109.9386324422436
At time: 64.48875379562378 and batch: 450, loss is 4.744032039642334 and perplexity is 114.8965363673042
At time: 64.88165473937988 and batch: 500, loss is 4.752877149581909 and perplexity is 115.91731666499201
At time: 65.26535701751709 and batch: 550, loss is 4.79508225440979 and perplexity is 120.91432711063683
At time: 65.64508938789368 and batch: 600, loss is 4.684298439025879 and perplexity is 108.23431269630113
At time: 66.02497148513794 and batch: 650, loss is 4.774854974746704 and perplexity is 118.49312887854067
At time: 66.40469527244568 and batch: 700, loss is 4.81623254776001 and perplexity is 123.49893687853515
At time: 66.78620457649231 and batch: 750, loss is 4.772785711288452 and perplexity is 118.24818888698505
At time: 67.16741728782654 and batch: 800, loss is 4.711216058731079 and perplexity is 111.18728799955458
At time: 67.54712414741516 and batch: 850, loss is 4.672350034713745 and perplexity is 106.9487806898217
At time: 67.92680978775024 and batch: 900, loss is 4.6356711673736575 and perplexity is 103.09709018282464
At time: 68.30806756019592 and batch: 950, loss is 4.688344974517822 and perplexity is 108.67317401918977
At time: 68.70171427726746 and batch: 1000, loss is 4.730554857254028 and perplexity is 113.35844265646247
At time: 69.10997104644775 and batch: 1050, loss is 4.629553985595703 and perplexity is 102.46835155624382
At time: 69.49011707305908 and batch: 1100, loss is 4.7796813583374025 and perplexity is 119.06640448253256
At time: 69.86872625350952 and batch: 1150, loss is 4.71505521774292 and perplexity is 111.61497413050176
At time: 70.24760627746582 and batch: 1200, loss is 4.674048509597778 and perplexity is 107.13058485890282
At time: 70.6434919834137 and batch: 1250, loss is 4.654068470001221 and perplexity is 105.01135319733012
At time: 71.03368520736694 and batch: 1300, loss is 4.721874179840088 and perplexity is 112.37867326708695
At time: 71.41307997703552 and batch: 1350, loss is 4.695892210006714 and perplexity is 109.49645890940077
At time: 71.81149911880493 and batch: 1400, loss is 4.562157669067383 and perplexity is 95.78994000411546
At time: 72.21998953819275 and batch: 1450, loss is 4.659352531433106 and perplexity is 105.56770825129907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.030484713040865 and perplexity of 153.0071592897059
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 73.49874591827393 and batch: 50, loss is 4.736730089187622 and perplexity is 114.06062316386203
At time: 73.90812993049622 and batch: 100, loss is 4.705718259811402 and perplexity is 110.57767993447942
At time: 74.30731177330017 and batch: 150, loss is 4.588088932037354 and perplexity is 98.30638035717604
At time: 74.71092319488525 and batch: 200, loss is 4.648837099075317 and perplexity is 104.46343429042868
At time: 75.10782051086426 and batch: 250, loss is 4.685057630538941 and perplexity is 108.3165144674175
At time: 75.50963044166565 and batch: 300, loss is 4.684824724197387 and perplexity is 108.29128980190939
At time: 75.89634728431702 and batch: 350, loss is 4.691791820526123 and perplexity is 109.04840001688638
At time: 76.27529573440552 and batch: 400, loss is 4.5533334827423095 and perplexity is 94.94839018235407
At time: 76.66056036949158 and batch: 450, loss is 4.605656480789184 and perplexity is 100.04864130615786
At time: 77.04006576538086 and batch: 500, loss is 4.608077850341797 and perplexity is 100.29118957098295
At time: 77.41938662528992 and batch: 550, loss is 4.6532744121551515 and perplexity is 104.92800120592845
At time: 77.80723214149475 and batch: 600, loss is 4.554104900360107 and perplexity is 95.02166330177623
At time: 78.2100145816803 and batch: 650, loss is 4.636712417602539 and perplexity is 103.20449596001549
At time: 78.61547780036926 and batch: 700, loss is 4.677655363082886 and perplexity is 107.51768687272322
At time: 79.0250301361084 and batch: 750, loss is 4.626873245239258 and perplexity is 102.19402836986906
At time: 79.4083023071289 and batch: 800, loss is 4.5652408695220945 and perplexity is 96.08573535455018
At time: 79.79542636871338 and batch: 850, loss is 4.517529697418213 and perplexity is 91.60901624132036
At time: 80.20135402679443 and batch: 900, loss is 4.4734063243865965 and perplexity is 87.65479572733945
At time: 80.59367775917053 and batch: 950, loss is 4.546001319885254 and perplexity is 94.25475913791173
At time: 80.98790907859802 and batch: 1000, loss is 4.587570104598999 and perplexity is 98.25538953854313
At time: 81.3667721748352 and batch: 1050, loss is 4.486320104598999 and perplexity is 88.79409096516937
At time: 81.75542521476746 and batch: 1100, loss is 4.6226274776458744 and perplexity is 101.7610560762614
At time: 82.14803814888 and batch: 1150, loss is 4.558851938247681 and perplexity is 95.47380706032209
At time: 82.5277488231659 and batch: 1200, loss is 4.512633275985718 and perplexity is 91.16155626109055
At time: 82.92577600479126 and batch: 1250, loss is 4.4869229602813725 and perplexity is 88.84763712615093
At time: 83.31427907943726 and batch: 1300, loss is 4.551105566024781 and perplexity is 94.7370885451909
At time: 83.71575665473938 and batch: 1350, loss is 4.517181825637818 and perplexity is 91.57715359211981
At time: 84.11023998260498 and batch: 1400, loss is 4.387570209503174 and perplexity is 80.44471750984815
At time: 84.51059651374817 and batch: 1450, loss is 4.478522930145264 and perplexity is 88.10444010547926
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.92576664329594 and perplexity of 137.79494072679435
Finished 7 epochs...
Completing Train Step...
At time: 85.80200123786926 and batch: 50, loss is 4.651663036346435 and perplexity is 104.75905891444441
At time: 86.18811774253845 and batch: 100, loss is 4.642709646224976 and perplexity is 103.8252965981482
At time: 86.56767177581787 and batch: 150, loss is 4.540040502548218 and perplexity is 93.69459491247223
At time: 86.94711780548096 and batch: 200, loss is 4.603568382263184 and perplexity is 99.83994784779752
At time: 87.32659721374512 and batch: 250, loss is 4.642038078308105 and perplexity is 103.75559426753748
At time: 87.70625138282776 and batch: 300, loss is 4.647236022949219 and perplexity is 104.29631420142864
At time: 88.08594632148743 and batch: 350, loss is 4.654625291824341 and perplexity is 105.0698420929013
At time: 88.47911882400513 and batch: 400, loss is 4.520165853500366 and perplexity is 91.85083049668799
At time: 88.90931248664856 and batch: 450, loss is 4.571444902420044 and perplexity is 96.68370741889774
At time: 89.30562567710876 and batch: 500, loss is 4.580318288803101 and perplexity is 97.54543688687788
At time: 89.69273853302002 and batch: 550, loss is 4.623481512069702 and perplexity is 101.84800064269733
At time: 90.0888729095459 and batch: 600, loss is 4.523783397674561 and perplexity is 92.18370666755382
At time: 90.47105050086975 and batch: 650, loss is 4.607728567123413 and perplexity is 100.25616565850257
At time: 90.84938454627991 and batch: 700, loss is 4.650569744110108 and perplexity is 104.64458923445649
At time: 91.25129532814026 and batch: 750, loss is 4.603040285110474 and perplexity is 99.78723657517392
At time: 91.64488410949707 and batch: 800, loss is 4.544321575164795 and perplexity is 94.09656810134618
At time: 92.02742385864258 and batch: 850, loss is 4.49844220161438 and perplexity is 89.87701192590757
At time: 92.41800618171692 and batch: 900, loss is 4.450869092941284 and perplexity is 85.70139412216732
At time: 92.81171417236328 and batch: 950, loss is 4.52597544670105 and perplexity is 92.38599950892286
At time: 93.19617295265198 and batch: 1000, loss is 4.571960334777832 and perplexity is 96.73355417538438
At time: 93.57438540458679 and batch: 1050, loss is 4.476647682189942 and perplexity is 87.93937724957922
At time: 93.9658272266388 and batch: 1100, loss is 4.606019792556762 and perplexity is 100.08499675865656
At time: 94.35916900634766 and batch: 1150, loss is 4.542754306793213 and perplexity is 93.94920903205431
At time: 94.7430784702301 and batch: 1200, loss is 4.501258354187012 and perplexity is 90.13047603354998
At time: 95.1227240562439 and batch: 1250, loss is 4.474741930961609 and perplexity is 87.77194626494355
At time: 95.52071475982666 and batch: 1300, loss is 4.538288965225219 and perplexity is 93.53062897067224
At time: 95.90666675567627 and batch: 1350, loss is 4.505274715423584 and perplexity is 90.49320051239611
At time: 96.30111169815063 and batch: 1400, loss is 4.382642984390259 and perplexity is 80.04932317591148
At time: 96.68013262748718 and batch: 1450, loss is 4.472263689041138 and perplexity is 87.55469545948554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9231546516092415 and perplexity of 137.43549113118664
Finished 8 epochs...
Completing Train Step...
At time: 97.9343273639679 and batch: 50, loss is 4.625096445083618 and perplexity is 102.01261122309143
At time: 98.31414151191711 and batch: 100, loss is 4.6172254848480225 and perplexity is 101.21282568572887
At time: 98.7077043056488 and batch: 150, loss is 4.514258394241333 and perplexity is 91.30982501487837
At time: 99.08810043334961 and batch: 200, loss is 4.575016508102417 and perplexity is 97.0296408989617
At time: 99.46783542633057 and batch: 250, loss is 4.616426191329956 and perplexity is 101.13195925252629
At time: 99.84780073165894 and batch: 300, loss is 4.621587553024292 and perplexity is 101.65528725386268
At time: 100.22805595397949 and batch: 350, loss is 4.628323411941528 and perplexity is 102.34233425511975
At time: 100.60819387435913 and batch: 400, loss is 4.493421421051026 and perplexity is 89.42689009836347
At time: 100.98813009262085 and batch: 450, loss is 4.5474921989440915 and perplexity is 94.39538638756913
At time: 101.36874413490295 and batch: 500, loss is 4.557734527587891 and perplexity is 95.36718319299935
At time: 101.74960517883301 and batch: 550, loss is 4.59883786201477 and perplexity is 99.36876829377744
At time: 102.13025403022766 and batch: 600, loss is 4.502868757247925 and perplexity is 90.27573936289726
At time: 102.51152205467224 and batch: 650, loss is 4.589027967453003 and perplexity is 98.3987368861549
At time: 102.89198875427246 and batch: 700, loss is 4.631376075744629 and perplexity is 102.65522833165407
At time: 103.27234387397766 and batch: 750, loss is 4.582984552383423 and perplexity is 97.80586576441017
At time: 103.6537253856659 and batch: 800, loss is 4.52631404876709 and perplexity is 92.41728689591775
At time: 104.0336925983429 and batch: 850, loss is 4.4827922916412355 and perplexity is 88.48139391315054
At time: 104.41274046897888 and batch: 900, loss is 4.433880939483642 and perplexity is 84.25778255309383
At time: 104.79274487495422 and batch: 950, loss is 4.50946834564209 and perplexity is 90.87349237702738
At time: 105.17358446121216 and batch: 1000, loss is 4.558488664627075 and perplexity is 95.43913024372593
At time: 105.5543909072876 and batch: 1050, loss is 4.464533529281616 and perplexity is 86.88049287997777
At time: 105.935142993927 and batch: 1100, loss is 4.589559926986694 and perplexity is 98.45109495729753
At time: 106.31523609161377 and batch: 1150, loss is 4.524041976928711 and perplexity is 92.20754654378457
At time: 106.69498467445374 and batch: 1200, loss is 4.488192005157471 and perplexity is 88.96046033851749
At time: 107.07485175132751 and batch: 1250, loss is 4.459996938705444 and perplexity is 86.48724433299392
At time: 107.45587348937988 and batch: 1300, loss is 4.5241513919830325 and perplexity is 92.2176359894571
At time: 107.83843636512756 and batch: 1350, loss is 4.49068250656128 and perplexity is 89.18229261200699
At time: 108.21813678741455 and batch: 1400, loss is 4.372973136901855 and perplexity is 79.27898893910323
At time: 108.59796404838562 and batch: 1450, loss is 4.459153709411621 and perplexity is 86.41434649414626
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.922611073551015 and perplexity of 137.36080451462814
Finished 9 epochs...
Completing Train Step...
At time: 109.82896304130554 and batch: 50, loss is 4.60214373588562 and perplexity is 99.69781249810553
At time: 110.22020483016968 and batch: 100, loss is 4.5964357280731205 and perplexity is 99.13035766449204
At time: 110.5993001461029 and batch: 150, loss is 4.49525110244751 and perplexity is 89.59066259557868
At time: 110.99577474594116 and batch: 200, loss is 4.551835412979126 and perplexity is 94.80625735898282
At time: 111.38073420524597 and batch: 250, loss is 4.595330114364624 and perplexity is 99.02081834737358
At time: 111.75878429412842 and batch: 300, loss is 4.601013841629029 and perplexity is 99.58522812856317
At time: 112.13755583763123 and batch: 350, loss is 4.608754072189331 and perplexity is 100.35903160003197
At time: 112.51649212837219 and batch: 400, loss is 4.474810934066772 and perplexity is 87.77800301074677
At time: 112.89523458480835 and batch: 450, loss is 4.528013124465942 and perplexity is 92.57444433562219
At time: 113.27422380447388 and batch: 500, loss is 4.539442663192749 and perplexity is 93.63859733668401
At time: 113.66866040229797 and batch: 550, loss is 4.579233226776123 and perplexity is 97.43965143967179
At time: 114.06280827522278 and batch: 600, loss is 4.484131021499634 and perplexity is 88.59992592056079
At time: 114.44182348251343 and batch: 650, loss is 4.573316869735717 and perplexity is 96.86486566740197
At time: 114.8209810256958 and batch: 700, loss is 4.614381484985351 and perplexity is 100.92538535724825
At time: 115.19981932640076 and batch: 750, loss is 4.565798263549805 and perplexity is 96.13930789870604
At time: 115.5782380104065 and batch: 800, loss is 4.511533432006836 and perplexity is 91.06134788921995
At time: 115.95670127868652 and batch: 850, loss is 4.468554201126099 and perplexity is 87.23051402007565
At time: 116.33531069755554 and batch: 900, loss is 4.419997930526733 and perplexity is 83.0961133929806
At time: 116.71358847618103 and batch: 950, loss is 4.4960874080657955 and perplexity is 89.66561910896118
At time: 117.09284448623657 and batch: 1000, loss is 4.5466557884216305 and perplexity is 94.31646610260212
At time: 117.47143054008484 and batch: 1050, loss is 4.454841470718383 and perplexity is 86.04250950667057
At time: 117.85252714157104 and batch: 1100, loss is 4.576250076293945 and perplexity is 97.1494074325159
At time: 118.24414587020874 and batch: 1150, loss is 4.507587947845459 and perplexity is 90.7027746211388
At time: 118.62314534187317 and batch: 1200, loss is 4.477138166427612 and perplexity is 87.98252070771885
At time: 119.00206089019775 and batch: 1250, loss is 4.450002207756042 and perplexity is 85.62713304581224
At time: 119.3801498413086 and batch: 1300, loss is 4.512609338760376 and perplexity is 91.15937413249293
At time: 119.7580394744873 and batch: 1350, loss is 4.478185653686523 and perplexity is 88.07472956253618
At time: 120.13716959953308 and batch: 1400, loss is 4.363648252487183 and perplexity is 78.54315763358632
At time: 120.5160071849823 and batch: 1450, loss is 4.447663326263427 and perplexity is 85.42709535248505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.922589685162928 and perplexity of 137.35786661985173
Finished 10 epochs...
Completing Train Step...
At time: 121.75234460830688 and batch: 50, loss is 4.587416257858276 and perplexity is 98.24027442983908
At time: 122.15420532226562 and batch: 100, loss is 4.580760831832886 and perplexity is 97.58861449332923
At time: 122.53363513946533 and batch: 150, loss is 4.4788290309906005 and perplexity is 88.13141307708756
At time: 122.91467809677124 and batch: 200, loss is 4.5336713790893555 and perplexity is 93.09973883683601
At time: 123.31500029563904 and batch: 250, loss is 4.576593751907349 and perplexity is 97.18280105266481
At time: 123.7019591331482 and batch: 300, loss is 4.583989877700805 and perplexity is 97.90424191918557
At time: 124.08159708976746 and batch: 350, loss is 4.591193885803222 and perplexity is 98.61209148693005
At time: 124.47354316711426 and batch: 400, loss is 4.456987009048462 and perplexity is 86.22731519178028
At time: 124.86724400520325 and batch: 450, loss is 4.513243017196655 and perplexity is 91.21715816846059
At time: 125.24586939811707 and batch: 500, loss is 4.524528856277466 and perplexity is 92.25245142473865
At time: 125.6250159740448 and batch: 550, loss is 4.562911701202393 and perplexity is 95.86219593531277
At time: 126.0253415107727 and batch: 600, loss is 4.46650912284851 and perplexity is 87.05230308048263
At time: 126.41297173500061 and batch: 650, loss is 4.558010501861572 and perplexity is 95.39350571411634
At time: 126.79163074493408 and batch: 700, loss is 4.598481578826904 and perplexity is 99.33337117830841
At time: 127.17056202888489 and batch: 750, loss is 4.55078465461731 and perplexity is 94.70669121045279
At time: 127.54931688308716 and batch: 800, loss is 4.497833318710327 and perplexity is 89.82230400692703
At time: 127.942134141922 and batch: 850, loss is 4.455826349258423 and perplexity is 86.12729267152146
At time: 128.32103061676025 and batch: 900, loss is 4.405408735275269 and perplexity is 81.89260840126201
At time: 128.69973516464233 and batch: 950, loss is 4.483605108261108 and perplexity is 88.55334229713263
At time: 129.07882475852966 and batch: 1000, loss is 4.5352876758575436 and perplexity is 93.25033731697003
At time: 129.4726333618164 and batch: 1050, loss is 4.444341735839844 and perplexity is 85.14381226629509
At time: 129.86525297164917 and batch: 1100, loss is 4.564940662384033 and perplexity is 96.05689406032866
At time: 130.26645493507385 and batch: 1150, loss is 4.494764919281006 and perplexity is 89.54711571028785
At time: 130.65797662734985 and batch: 1200, loss is 4.4632354164123536 and perplexity is 86.76778536344814
At time: 131.03675079345703 and batch: 1250, loss is 4.437242569923401 and perplexity is 84.54150269365839
At time: 131.43087434768677 and batch: 1300, loss is 4.499914522171021 and perplexity is 90.00943716041117
At time: 131.82420778274536 and batch: 1350, loss is 4.464105434417725 and perplexity is 86.84330774715359
At time: 132.20376658439636 and batch: 1400, loss is 4.351461925506592 and perplexity is 77.59181350128398
At time: 132.60039258003235 and batch: 1450, loss is 4.4341112327575685 and perplexity is 84.27718878816869
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.922530736678686 and perplexity of 137.3497698204652
Finished 11 epochs...
Completing Train Step...
At time: 133.88143491744995 and batch: 50, loss is 4.571704015731812 and perplexity is 96.70876270045935
At time: 134.27412247657776 and batch: 100, loss is 4.564747905731201 and perplexity is 96.03838023933655
At time: 134.65504789352417 and batch: 150, loss is 4.464259977340698 and perplexity is 86.85672980288867
At time: 135.03600597381592 and batch: 200, loss is 4.516010437011719 and perplexity is 91.46994396032215
At time: 135.41735291481018 and batch: 250, loss is 4.560513620376587 and perplexity is 95.63258606287343
At time: 135.79698395729065 and batch: 300, loss is 4.567951259613037 and perplexity is 96.34651843182296
At time: 136.1770281791687 and batch: 350, loss is 4.574328908920288 and perplexity is 96.96294632943078
At time: 136.5581774711609 and batch: 400, loss is 4.441326398849487 and perplexity is 84.88746166562663
At time: 136.9396493434906 and batch: 450, loss is 4.499133491516114 and perplexity is 89.93916447689023
At time: 137.3201253414154 and batch: 500, loss is 4.510391807556152 and perplexity is 90.95744934580048
At time: 137.71382665634155 and batch: 550, loss is 4.54731011390686 and perplexity is 94.378199964867
At time: 138.09580945968628 and batch: 600, loss is 4.451576309204102 and perplexity is 85.76202497887354
At time: 138.47679257392883 and batch: 650, loss is 4.544212293624878 and perplexity is 94.08628564533473
At time: 138.86926794052124 and batch: 700, loss is 4.583807640075683 and perplexity is 97.88640170827705
At time: 139.26435327529907 and batch: 750, loss is 4.536706209182739 and perplexity is 93.38270989329824
At time: 139.6664981842041 and batch: 800, loss is 4.485597310066223 and perplexity is 88.72993427052411
At time: 140.06074333190918 and batch: 850, loss is 4.443970937728881 and perplexity is 85.11224695408733
At time: 140.4417221546173 and batch: 900, loss is 4.393077373504639 and perplexity is 80.88896190280599
At time: 140.82310962677002 and batch: 950, loss is 4.471339626312256 and perplexity is 87.47382679828512
At time: 141.204265832901 and batch: 1000, loss is 4.523582153320312 and perplexity is 92.1651570835954
At time: 141.60024762153625 and batch: 1050, loss is 4.434559946060181 and perplexity is 84.31501356949131
At time: 141.99444198608398 and batch: 1100, loss is 4.552368087768555 and perplexity is 94.85677171482554
At time: 142.38279581069946 and batch: 1150, loss is 4.482480421066284 and perplexity is 88.45380347250526
At time: 142.79426789283752 and batch: 1200, loss is 4.45246639251709 and perplexity is 85.83839430868643
At time: 143.18849658966064 and batch: 1250, loss is 4.426546750068664 and perplexity is 83.64208061338653
At time: 143.57550859451294 and batch: 1300, loss is 4.487990379333496 and perplexity is 88.94252542053265
At time: 143.95639204978943 and batch: 1350, loss is 4.452330160140991 and perplexity is 85.82670113678161
At time: 144.3376750946045 and batch: 1400, loss is 4.34249674320221 and perplexity is 76.8992976517154
At time: 144.71807146072388 and batch: 1450, loss is 4.422686061859131 and perplexity is 83.31978715652893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.923050318008814 and perplexity of 137.4211527395714
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 145.97333931922913 and batch: 50, loss is 4.555928268432617 and perplexity is 95.19508082277665
At time: 146.35274839401245 and batch: 100, loss is 4.539973411560059 and perplexity is 93.68830906037878
At time: 146.73245453834534 and batch: 150, loss is 4.433969039916992 and perplexity is 84.26520602725067
At time: 147.11188507080078 and batch: 200, loss is 4.478261575698853 and perplexity is 88.08141662708442
At time: 147.51409125328064 and batch: 250, loss is 4.522866506576538 and perplexity is 92.09922298461468
At time: 147.89388179779053 and batch: 300, loss is 4.522794361114502 and perplexity is 92.09257868330032
At time: 148.2774248123169 and batch: 350, loss is 4.529720077514648 and perplexity is 92.73259950893954
At time: 148.65706539154053 and batch: 400, loss is 4.392663202285767 and perplexity is 80.85546695966092
At time: 149.0408215522766 and batch: 450, loss is 4.457149591445923 and perplexity is 86.24133537509736
At time: 149.436749458313 and batch: 500, loss is 4.453887948989868 and perplexity is 85.96050520693399
At time: 149.81977343559265 and batch: 550, loss is 4.4916898632049564 and perplexity is 89.27217625180796
At time: 150.22510170936584 and batch: 600, loss is 4.400268487930298 and perplexity is 81.47274017610391
At time: 150.61632537841797 and batch: 650, loss is 4.491481952667236 and perplexity is 89.25361755498116
At time: 150.99655079841614 and batch: 700, loss is 4.527411985397339 and perplexity is 92.51881094375582
At time: 151.37575888633728 and batch: 750, loss is 4.475154151916504 and perplexity is 87.80813515884363
At time: 151.75543022155762 and batch: 800, loss is 4.428032655715942 and perplexity is 83.76645723639885
At time: 152.13545274734497 and batch: 850, loss is 4.379170722961426 and perplexity is 79.77185300191385
At time: 152.53234672546387 and batch: 900, loss is 4.3309285879135135 and perplexity is 76.01484026838232
At time: 152.92503428459167 and batch: 950, loss is 4.407354774475098 and perplexity is 82.05212979448615
At time: 153.30323433876038 and batch: 1000, loss is 4.459348945617676 and perplexity is 86.43121935034715
At time: 153.68604636192322 and batch: 1050, loss is 4.368382034301757 and perplexity is 78.9158452197573
At time: 154.0786955356598 and batch: 1100, loss is 4.478833198547363 and perplexity is 88.13178037051951
At time: 154.47836065292358 and batch: 1150, loss is 4.408649635314942 and perplexity is 82.15844470083272
At time: 154.87009453773499 and batch: 1200, loss is 4.3797140789031985 and perplexity is 79.81520929011035
At time: 155.2497375011444 and batch: 1250, loss is 4.349752097129822 and perplexity is 77.45925817247974
At time: 155.62983417510986 and batch: 1300, loss is 4.412236118316651 and perplexity is 82.4536335947599
At time: 156.01930570602417 and batch: 1350, loss is 4.366495857238769 and perplexity is 78.76713625240716
At time: 156.4199936389923 and batch: 1400, loss is 4.2550573873519895 and perplexity is 70.46086063462081
At time: 156.82052564620972 and batch: 1450, loss is 4.338201131820679 and perplexity is 76.56967662226852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.881990351228633 and perplexity of 131.89291603979362
Finished 13 epochs...
Completing Train Step...
At time: 158.11987137794495 and batch: 50, loss is 4.5236976432800295 and perplexity is 92.17580184854422
At time: 158.51300811767578 and batch: 100, loss is 4.515077562332153 and perplexity is 91.38465375438238
At time: 158.89202761650085 and batch: 150, loss is 4.410600633621216 and perplexity is 82.31889215274975
At time: 159.27164816856384 and batch: 200, loss is 4.458710927963256 and perplexity is 86.3760922943961
At time: 159.66440224647522 and batch: 250, loss is 4.502896661758423 and perplexity is 90.27825849836147
At time: 160.05750679969788 and batch: 300, loss is 4.50594729423523 and perplexity is 90.55408479410251
At time: 160.45287084579468 and batch: 350, loss is 4.5154985904693605 and perplexity is 91.42313736569506
At time: 160.85848999023438 and batch: 400, loss is 4.38144380569458 and perplexity is 79.9533872666013
At time: 161.25062251091003 and batch: 450, loss is 4.443709487915039 and perplexity is 85.08999728167859
At time: 161.64740538597107 and batch: 500, loss is 4.4413912487030025 and perplexity is 84.89296678358208
At time: 162.04466772079468 and batch: 550, loss is 4.479926013946534 and perplexity is 88.22814478193082
At time: 162.4378056526184 and batch: 600, loss is 4.390253305435181 and perplexity is 80.66084822421001
At time: 162.81744575500488 and batch: 650, loss is 4.481349086761474 and perplexity is 88.35378923568196
At time: 163.21509790420532 and batch: 700, loss is 4.5179994010925295 and perplexity is 91.65205543989303
At time: 163.61515474319458 and batch: 750, loss is 4.466787061691284 and perplexity is 87.07650165956836
At time: 164.01612997055054 and batch: 800, loss is 4.420861296653747 and perplexity is 83.16788674145123
At time: 164.4053180217743 and batch: 850, loss is 4.373853583335876 and perplexity is 79.34882057920565
At time: 164.80546951293945 and batch: 900, loss is 4.325489706993103 and perplexity is 75.60252688208455
At time: 165.19396662712097 and batch: 950, loss is 4.40199234008789 and perplexity is 81.6133082595283
At time: 165.57186889648438 and batch: 1000, loss is 4.455180797576904 and perplexity is 86.07171099526524
At time: 165.9520697593689 and batch: 1050, loss is 4.365132913589478 and perplexity is 78.65985421057526
At time: 166.33098101615906 and batch: 1100, loss is 4.477110290527344 and perplexity is 87.98006814993005
At time: 166.71102285385132 and batch: 1150, loss is 4.407802963256836 and perplexity is 82.08891288084537
At time: 167.1111352443695 and batch: 1200, loss is 4.378806800842285 and perplexity is 79.74282754194537
At time: 167.52008533477783 and batch: 1250, loss is 4.351440205574035 and perplexity is 77.59012823062984
At time: 167.90210962295532 and batch: 1300, loss is 4.414385509490967 and perplexity is 82.63104930667816
At time: 168.2811243534088 and batch: 1350, loss is 4.368349514007568 and perplexity is 78.91327889498362
At time: 168.66100478172302 and batch: 1400, loss is 4.256753087043762 and perplexity is 70.58044245305355
At time: 169.04040384292603 and batch: 1450, loss is 4.340363025665283 and perplexity is 76.73539119896037
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.881331484541934 and perplexity of 131.80604481262486
Finished 14 epochs...
Completing Train Step...
At time: 170.28847098350525 and batch: 50, loss is 4.5158364200592045 and perplexity is 91.45402802428902
At time: 170.70061135292053 and batch: 100, loss is 4.507137746810913 and perplexity is 90.66194932865216
At time: 171.0951268672943 and batch: 150, loss is 4.4032236766815185 and perplexity is 81.71386360855071
At time: 171.48601841926575 and batch: 200, loss is 4.450092344284058 and perplexity is 85.63485152614221
At time: 171.87223291397095 and batch: 250, loss is 4.493787612915039 and perplexity is 89.45964349458909
At time: 172.25172805786133 and batch: 300, loss is 4.497559251785279 and perplexity is 89.79769005735587
At time: 172.6299455165863 and batch: 350, loss is 4.508799734115601 and perplexity is 90.81275362015099
At time: 173.00842022895813 and batch: 400, loss is 4.375310068130493 and perplexity is 79.46447513395498
At time: 173.38720965385437 and batch: 450, loss is 4.436347999572754 and perplexity is 84.46590818929185
At time: 173.76669931411743 and batch: 500, loss is 4.4343465805053714 and perplexity is 84.29702556892042
At time: 174.1460211277008 and batch: 550, loss is 4.473419847488404 and perplexity is 87.65598110008091
At time: 174.54150485992432 and batch: 600, loss is 4.385139408111573 and perplexity is 80.24940985181111
At time: 174.93421602249146 and batch: 650, loss is 4.475303764343262 and perplexity is 87.82127332982613
At time: 175.33014822006226 and batch: 700, loss is 4.512043924331665 and perplexity is 91.10784587582884
At time: 175.72163343429565 and batch: 750, loss is 4.461565065383911 and perplexity is 86.62297368077175
At time: 176.10065913200378 and batch: 800, loss is 4.416116118431091 and perplexity is 82.77417515105117
At time: 176.47997999191284 and batch: 850, loss is 4.37036180973053 and perplexity is 79.07223562892771
At time: 176.86965346336365 and batch: 900, loss is 4.321925039291382 and perplexity is 75.33350876130709
At time: 177.28099465370178 and batch: 950, loss is 4.398184280395508 and perplexity is 81.30311090985103
At time: 177.66234230995178 and batch: 1000, loss is 4.451980924606323 and perplexity is 85.79673263625854
At time: 178.0418348312378 and batch: 1050, loss is 4.3627493190765385 and perplexity is 78.47258429013259
At time: 178.42094492912292 and batch: 1100, loss is 4.4751881408691405 and perplexity is 87.81111971611134
At time: 178.800057888031 and batch: 1150, loss is 4.40579553604126 and perplexity is 81.92429065188502
At time: 179.19764351844788 and batch: 1200, loss is 4.37758243560791 and perplexity is 79.64525294187557
At time: 179.59113430976868 and batch: 1250, loss is 4.351336688995361 and perplexity is 77.58209678171775
At time: 179.98846292495728 and batch: 1300, loss is 4.41430983543396 and perplexity is 82.62479651653234
At time: 180.3780574798584 and batch: 1350, loss is 4.366459722518921 and perplexity is 78.76429007542863
At time: 180.75927710533142 and batch: 1400, loss is 4.255537400245666 and perplexity is 70.49469087505123
At time: 181.13854265213013 and batch: 1450, loss is 4.338786458969116 and perplexity is 76.61450805198909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8810972556089745 and perplexity of 131.77517563875872
Finished 15 epochs...
Completing Train Step...
At time: 182.40798544883728 and batch: 50, loss is 4.510015926361084 and perplexity is 90.92326657577273
At time: 182.80325508117676 and batch: 100, loss is 4.501392822265625 and perplexity is 90.14259652037774
At time: 183.1867516040802 and batch: 150, loss is 4.3972037982940675 and perplexity is 81.22343373221887
At time: 183.5674467086792 and batch: 200, loss is 4.443705987930298 and perplexity is 85.08969946850765
At time: 183.9628026485443 and batch: 250, loss is 4.486340932846069 and perplexity is 88.79594040969465
At time: 184.35292410850525 and batch: 300, loss is 4.49068320274353 and perplexity is 89.18235469915778
At time: 184.7328805923462 and batch: 350, loss is 4.502793636322021 and perplexity is 90.26895802048323
At time: 185.11378121376038 and batch: 400, loss is 4.371224784851075 and perplexity is 79.14050245305005
At time: 185.4944043159485 and batch: 450, loss is 4.430368919372558 and perplexity is 83.96238654823173
At time: 185.87577843666077 and batch: 500, loss is 4.428240842819214 and perplexity is 83.7838981479057
At time: 186.2577178478241 and batch: 550, loss is 4.4680855846405025 and perplexity is 87.1896459396348
At time: 186.65453672409058 and batch: 600, loss is 4.380388793945312 and perplexity is 79.86907998404791
At time: 187.0625445842743 and batch: 650, loss is 4.470256586074829 and perplexity is 87.37914040798157
At time: 187.44565963745117 and batch: 700, loss is 4.507078075408936 and perplexity is 90.65653956443546
At time: 187.99776411056519 and batch: 750, loss is 4.456772413253784 and perplexity is 86.20881315785407
At time: 188.3787488937378 and batch: 800, loss is 4.4124929285049435 and perplexity is 82.47481124713084
At time: 188.7596845626831 and batch: 850, loss is 4.366924924850464 and perplexity is 78.8009399309522
At time: 189.1400284767151 and batch: 900, loss is 4.318752689361572 and perplexity is 75.09490318038141
At time: 189.52072310447693 and batch: 950, loss is 4.3952099609375 and perplexity is 81.06164875587613
At time: 189.90180563926697 and batch: 1000, loss is 4.449059600830078 and perplexity is 85.54645834539186
At time: 190.2959885597229 and batch: 1050, loss is 4.360525660514831 and perplexity is 78.29828192251469
At time: 190.69866347312927 and batch: 1100, loss is 4.4726916027069095 and perplexity is 87.5921693273934
At time: 191.09800553321838 and batch: 1150, loss is 4.403077659606933 and perplexity is 81.7019328603012
At time: 191.48745131492615 and batch: 1200, loss is 4.375048313140869 and perplexity is 79.44367763313439
At time: 191.86871695518494 and batch: 1250, loss is 4.349809575080871 and perplexity is 77.46371049988339
At time: 192.24974918365479 and batch: 1300, loss is 4.413150949478149 and perplexity is 82.52909926206002
At time: 192.6305012702942 and batch: 1350, loss is 4.364105844497681 and perplexity is 78.57910657934667
At time: 193.01145815849304 and batch: 1400, loss is 4.253401594161987 and perplexity is 70.34428855767923
At time: 193.39221215248108 and batch: 1450, loss is 4.335982837677002 and perplexity is 76.40001081094664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.881107167301015 and perplexity of 131.77648176019116
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 194.6459596157074 and batch: 50, loss is 4.507358808517456 and perplexity is 90.68199342929917
At time: 195.02266597747803 and batch: 100, loss is 4.494647979736328 and perplexity is 89.53664472359762
At time: 195.40147042274475 and batch: 150, loss is 4.386773433685303 and perplexity is 80.38064663271318
At time: 195.79561853408813 and batch: 200, loss is 4.433415794372559 and perplexity is 84.21859957106128
At time: 196.1744430065155 and batch: 250, loss is 4.476843481063843 and perplexity is 87.95659736640097
At time: 196.55317616462708 and batch: 300, loss is 4.479465169906616 and perplexity is 88.18749473464054
At time: 196.9455804824829 and batch: 350, loss is 4.49027723312378 and perplexity is 89.14615672066905
At time: 197.33892130851746 and batch: 400, loss is 4.357834825515747 and perplexity is 78.08787737406534
At time: 197.73145937919617 and batch: 450, loss is 4.417435369491577 and perplexity is 82.8834471321402
At time: 198.10971355438232 and batch: 500, loss is 4.410127305984497 and perplexity is 82.27993756593838
At time: 198.5046844482422 and batch: 550, loss is 4.450660123825073 and perplexity is 85.68348704865738
At time: 198.89884114265442 and batch: 600, loss is 4.363535985946656 and perplexity is 78.53434035994839
At time: 199.2774212360382 and batch: 650, loss is 4.452695627212524 and perplexity is 85.85807370237605
At time: 199.65596222877502 and batch: 700, loss is 4.485698795318603 and perplexity is 88.7389395072389
At time: 200.03499937057495 and batch: 750, loss is 4.436572532653809 and perplexity is 84.48487570923986
At time: 200.43080830574036 and batch: 800, loss is 4.391412162780762 and perplexity is 80.75437682336052
At time: 200.82452249526978 and batch: 850, loss is 4.343505277633667 and perplexity is 76.97689236304399
At time: 201.20369410514832 and batch: 900, loss is 4.294754228591919 and perplexity is 73.31419369800508
At time: 201.58236455917358 and batch: 950, loss is 4.370352244377136 and perplexity is 79.07147927866767
At time: 201.96174788475037 and batch: 1000, loss is 4.425146570205689 and perplexity is 83.52504860846273
At time: 202.33998274803162 and batch: 1050, loss is 4.332876057624817 and perplexity is 76.16302110943138
At time: 202.7240936756134 and batch: 1100, loss is 4.447900304794311 and perplexity is 85.44734213897148
At time: 203.10427379608154 and batch: 1150, loss is 4.374013519287109 and perplexity is 79.36151232321022
At time: 203.48263573646545 and batch: 1200, loss is 4.349100275039673 and perplexity is 77.40878496847806
At time: 203.86198663711548 and batch: 1250, loss is 4.321110515594483 and perplexity is 75.27217281643183
At time: 204.24104404449463 and batch: 1300, loss is 4.381263065338135 and perplexity is 79.93893776873072
At time: 204.63512992858887 and batch: 1350, loss is 4.330891819000244 and perplexity is 76.0120453366969
At time: 205.02868390083313 and batch: 1400, loss is 4.219368209838867 and perplexity is 67.99051497864123
At time: 205.4073634147644 and batch: 1450, loss is 4.302284116744995 and perplexity is 73.8683250318351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.868649213741987 and perplexity of 130.1450000325731
Finished 17 epochs...
Completing Train Step...
At time: 206.66407585144043 and batch: 50, loss is 4.495175886154175 and perplexity is 89.58392417144361
At time: 207.0665044784546 and batch: 100, loss is 4.48656494140625 and perplexity is 88.81583368850495
At time: 207.44525265693665 and batch: 150, loss is 4.37757758140564 and perplexity is 79.64486632864626
At time: 207.82367992401123 and batch: 200, loss is 4.425003318786621 and perplexity is 83.51308438368845
At time: 208.20276641845703 and batch: 250, loss is 4.468591532707214 and perplexity is 87.23377053387055
At time: 208.58225297927856 and batch: 300, loss is 4.472966527938842 and perplexity is 87.61625393544277
At time: 208.9613847732544 and batch: 350, loss is 4.485067195892334 and perplexity is 88.68290974000543
At time: 209.33916425704956 and batch: 400, loss is 4.353910160064697 and perplexity is 77.78200918734923
At time: 209.71613955497742 and batch: 450, loss is 4.4117305469512935 and perplexity is 82.41195793454266
At time: 210.10570859909058 and batch: 500, loss is 4.404676656723023 and perplexity is 81.83267851843148
At time: 210.49128246307373 and batch: 550, loss is 4.445973291397094 and perplexity is 85.2828425133085
At time: 210.86996841430664 and batch: 600, loss is 4.358763771057129 and perplexity is 78.16045046259262
At time: 211.26125502586365 and batch: 650, loss is 4.448166065216064 and perplexity is 85.47005367843647
At time: 211.65499353408813 and batch: 700, loss is 4.482219076156616 and perplexity is 88.43068954171258
At time: 212.03604865074158 and batch: 750, loss is 4.43277081489563 and perplexity is 84.16429781640333
At time: 212.41529178619385 and batch: 800, loss is 4.388049635887146 and perplexity is 80.48329407644655
At time: 212.79402685165405 and batch: 850, loss is 4.3413968706130985 and perplexity is 76.81476471835629
At time: 213.17315006256104 and batch: 900, loss is 4.292115221023559 and perplexity is 73.12097205479603
At time: 213.55206155776978 and batch: 950, loss is 4.368439569473266 and perplexity is 78.92038578706669
At time: 213.9317398071289 and batch: 1000, loss is 4.42252366065979 and perplexity is 83.30625702185068
At time: 214.3331778049469 and batch: 1050, loss is 4.332413229942322 and perplexity is 76.1277789110411
At time: 214.711993932724 and batch: 1100, loss is 4.447336912155151 and perplexity is 85.39921529380275
At time: 215.09056210517883 and batch: 1150, loss is 4.374319696426392 and perplexity is 79.38581472425247
At time: 215.46967482566833 and batch: 1200, loss is 4.349605941772461 and perplexity is 77.44793791419899
At time: 215.84851574897766 and batch: 1250, loss is 4.321965537071228 and perplexity is 75.33655966293689
At time: 216.2269811630249 and batch: 1300, loss is 4.381659269332886 and perplexity is 79.9706161703511
At time: 216.62273573875427 and batch: 1350, loss is 4.332421226501465 and perplexity is 76.12838767376158
At time: 217.0246696472168 and batch: 1400, loss is 4.221038331985474 and perplexity is 68.10416231952024
At time: 217.42532896995544 and batch: 1450, loss is 4.3045320796966555 and perplexity is 74.03456507052631
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8676940396300745 and perplexity of 130.02074824823785
Finished 18 epochs...
Completing Train Step...
At time: 218.685378074646 and batch: 50, loss is 4.4922640419006346 and perplexity is 89.32344915202341
At time: 219.07855105400085 and batch: 100, loss is 4.483489837646484 and perplexity is 88.54313528723446
At time: 219.45851588249207 and batch: 150, loss is 4.373591718673706 and perplexity is 79.32804464747096
At time: 219.8479790687561 and batch: 200, loss is 4.421154899597168 and perplexity is 83.19230866279514
At time: 220.24270796775818 and batch: 250, loss is 4.464805345535279 and perplexity is 86.90411161990204
At time: 220.62290287017822 and batch: 300, loss is 4.469703178405762 and perplexity is 87.3307974994653
At time: 221.0203468799591 and batch: 350, loss is 4.482578201293945 and perplexity is 88.4624529284123
At time: 221.41655802726746 and batch: 400, loss is 4.352314462661743 and perplexity is 77.65799161086976
At time: 221.81325793266296 and batch: 450, loss is 4.408892183303833 and perplexity is 82.17837448323198
At time: 222.2117054462433 and batch: 500, loss is 4.401392631530761 and perplexity is 81.56437873338369
At time: 222.6069941520691 and batch: 550, loss is 4.443666915893555 and perplexity is 85.08637490559272
At time: 223.00284957885742 and batch: 600, loss is 4.356204652786255 and perplexity is 77.9606843473356
At time: 223.39356207847595 and batch: 650, loss is 4.445331745147705 and perplexity is 85.22814717222822
At time: 223.7733974456787 and batch: 700, loss is 4.479790496826172 and perplexity is 88.2161891679286
At time: 224.16680264472961 and batch: 750, loss is 4.43053505897522 and perplexity is 83.97633718461591
At time: 224.54595303535461 and batch: 800, loss is 4.385918488502503 and perplexity is 80.31195495407815
At time: 224.93114233016968 and batch: 850, loss is 4.340427432060242 and perplexity is 76.7403336080329
At time: 225.31743121147156 and batch: 900, loss is 4.290468716621399 and perplexity is 73.00067711266986
At time: 225.69802737236023 and batch: 950, loss is 4.366801347732544 and perplexity is 78.79120253957792
At time: 226.08566236495972 and batch: 1000, loss is 4.4207979106903075 and perplexity is 83.16261523189449
At time: 226.4845039844513 and batch: 1050, loss is 4.331646203994751 and perplexity is 76.06940931764345
At time: 226.87349796295166 and batch: 1100, loss is 4.446837244033813 and perplexity is 85.35655468729328
At time: 227.25385999679565 and batch: 1150, loss is 4.374212980270386 and perplexity is 79.37734342728385
At time: 227.6341998577118 and batch: 1200, loss is 4.34938603401184 and perplexity is 77.43090838413912
At time: 228.02781057357788 and batch: 1250, loss is 4.322235202789306 and perplexity is 75.35687808986441
At time: 228.4227113723755 and batch: 1300, loss is 4.38145673751831 and perplexity is 79.95442121639748
At time: 228.80575108528137 and batch: 1350, loss is 4.332947616577148 and perplexity is 76.16847145043641
At time: 229.1859483718872 and batch: 1400, loss is 4.221101622581482 and perplexity is 68.10847280894939
At time: 229.56604170799255 and batch: 1450, loss is 4.30522458076477 and perplexity is 74.0858518419375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867362258780716 and perplexity of 129.97761700940498
Finished 19 epochs...
Completing Train Step...
At time: 230.81643199920654 and batch: 50, loss is 4.490080943107605 and perplexity is 89.12865993740257
At time: 231.19604992866516 and batch: 100, loss is 4.480861406326294 and perplexity is 88.3107113262783
At time: 231.58260226249695 and batch: 150, loss is 4.370677509307861 and perplexity is 79.09720264112467
At time: 231.9604296684265 and batch: 200, loss is 4.41818305015564 and perplexity is 82.94544065572319
At time: 232.33971524238586 and batch: 250, loss is 4.4621713256835935 and perplexity is 86.67550567317657
At time: 232.71851587295532 and batch: 300, loss is 4.467344055175781 and perplexity is 87.1250162135365
At time: 233.09707045555115 and batch: 350, loss is 4.480455017089843 and perplexity is 88.27483009509885
At time: 233.47570037841797 and batch: 400, loss is 4.351216764450073 and perplexity is 77.57279334190525
At time: 233.86803460121155 and batch: 450, loss is 4.407293453216552 and perplexity is 82.04709840888783
At time: 234.2470259666443 and batch: 500, loss is 4.3989958000183105 and perplexity is 81.36911675864758
At time: 234.62644028663635 and batch: 550, loss is 4.441786775588989 and perplexity is 84.926550875644
At time: 235.00507616996765 and batch: 600, loss is 4.354171285629272 and perplexity is 77.8023227104867
At time: 235.3844277858734 and batch: 650, loss is 4.443187446594238 and perplexity is 85.04558837976015
At time: 235.76323294639587 and batch: 700, loss is 4.477870025634766 and perplexity is 88.04693509382301
At time: 236.14299821853638 and batch: 750, loss is 4.428916625976562 and perplexity is 83.84053703077707
At time: 236.5219669342041 and batch: 800, loss is 4.384660701751709 and perplexity is 80.21100314244123
At time: 236.90098404884338 and batch: 850, loss is 4.3393648958206175 and perplexity is 76.65883752647083
At time: 237.2803189754486 and batch: 900, loss is 4.2888604927062985 and perplexity is 72.88337003122903
At time: 237.65963196754456 and batch: 950, loss is 4.36553156375885 and perplexity is 78.69121822599877
At time: 238.04846715927124 and batch: 1000, loss is 4.419570469856263 and perplexity is 83.06060066332448
At time: 238.42683005332947 and batch: 1050, loss is 4.33089771270752 and perplexity is 76.01249333076173
At time: 238.80512499809265 and batch: 1100, loss is 4.4464135837554934 and perplexity is 85.32040016473637
At time: 239.183363199234 and batch: 1150, loss is 4.374533338546753 and perplexity is 79.40277668986738
At time: 239.56314039230347 and batch: 1200, loss is 4.349012260437012 and perplexity is 77.40197216484407
At time: 239.9416744709015 and batch: 1250, loss is 4.322251915931702 and perplexity is 75.35813755062314
At time: 240.32077360153198 and batch: 1300, loss is 4.381478099822998 and perplexity is 79.9561292453483
At time: 240.69924569129944 and batch: 1350, loss is 4.333166055679321 and perplexity is 76.18511144029996
At time: 241.07796430587769 and batch: 1400, loss is 4.220959243774414 and perplexity is 68.09877629614492
At time: 241.4565851688385 and batch: 1450, loss is 4.305223407745362 and perplexity is 74.08576493784633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867535974225428 and perplexity of 130.0001980902308
Annealing...
Finished 20 epochs...
Completing Train Step...
At time: 242.70537853240967 and batch: 50, loss is 4.488895864486694 and perplexity is 89.02309802993452
At time: 243.08267760276794 and batch: 100, loss is 4.478538656234742 and perplexity is 88.10582565468235
At time: 243.47400403022766 and batch: 150, loss is 4.367591209411621 and perplexity is 78.85346127577048
At time: 243.85209202766418 and batch: 200, loss is 4.415314722061157 and perplexity is 82.70786680074524
At time: 244.23082280158997 and batch: 250, loss is 4.459295568466186 and perplexity is 86.4266060211827
At time: 244.6092791557312 and batch: 300, loss is 4.464859380722046 and perplexity is 86.90880762667788
At time: 244.98779010772705 and batch: 350, loss is 4.4761760044097905 and perplexity is 87.89790798016557
At time: 245.3748300075531 and batch: 400, loss is 4.347608518600464 and perplexity is 77.29339600256475
At time: 245.763934135437 and batch: 450, loss is 4.4032204055786135 and perplexity is 81.71359631453126
At time: 246.14278841018677 and batch: 500, loss is 4.392063903808594 and perplexity is 80.80702491851149
At time: 246.52220797538757 and batch: 550, loss is 4.434813814163208 and perplexity is 84.33642117928261
At time: 246.9009828567505 and batch: 600, loss is 4.348346853256226 and perplexity is 77.35048546846707
At time: 247.28018021583557 and batch: 650, loss is 4.4374652862548825 and perplexity is 84.56033356388954
At time: 247.65872406959534 and batch: 700, loss is 4.4713090229034425 and perplexity is 87.47114984196534
At time: 248.0559220314026 and batch: 750, loss is 4.4221116638183595 and perplexity is 83.27194217637565
At time: 248.43801712989807 and batch: 800, loss is 4.376615142822265 and perplexity is 79.56824991153591
At time: 248.81685638427734 and batch: 850, loss is 4.331797256469726 and perplexity is 76.08090065806664
At time: 249.21767282485962 and batch: 900, loss is 4.2798226976394655 and perplexity is 72.22763274219874
At time: 249.61076712608337 and batch: 950, loss is 4.354996519088745 and perplexity is 77.86655428979113
At time: 249.99009442329407 and batch: 1000, loss is 4.409200987815857 and perplexity is 82.20375545474074
At time: 250.37119007110596 and batch: 1050, loss is 4.32151083946228 and perplexity is 75.30231209612522
At time: 250.76455116271973 and batch: 1100, loss is 4.438080348968506 and perplexity is 84.61235947007366
At time: 251.14374351501465 and batch: 1150, loss is 4.362337560653686 and perplexity is 78.44027919399228
At time: 251.52245712280273 and batch: 1200, loss is 4.3400388431549075 and perplexity is 76.71051895899726
At time: 251.9010398387909 and batch: 1250, loss is 4.31092029094696 and perplexity is 74.50902738122056
At time: 252.2790491580963 and batch: 1300, loss is 4.368227958679199 and perplexity is 78.90368714843062
At time: 252.65760493278503 and batch: 1350, loss is 4.321537876129151 and perplexity is 75.3043480471745
At time: 253.03623819351196 and batch: 1400, loss is 4.206637363433838 and perplexity is 67.13042463102875
At time: 253.4150354862213 and batch: 1450, loss is 4.291609516143799 and perplexity is 73.08400377072377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.863349066840278 and perplexity of 129.4570371764725
Finished 21 epochs...
Completing Train Step...
At time: 254.64335250854492 and batch: 50, loss is 4.484201669692993 and perplexity is 88.60618556637259
At time: 255.0349612236023 and batch: 100, loss is 4.475752563476562 and perplexity is 87.86069628701469
At time: 255.42673206329346 and batch: 150, loss is 4.364779262542725 and perplexity is 78.63204098917356
At time: 255.81951570510864 and batch: 200, loss is 4.413093194961548 and perplexity is 82.52433297146533
At time: 256.2018287181854 and batch: 250, loss is 4.456687197685242 and perplexity is 86.20146713782957
At time: 256.580929517746 and batch: 300, loss is 4.462866458892822 and perplexity is 86.73577764169315
At time: 256.97430300712585 and batch: 350, loss is 4.474380226135254 and perplexity is 87.74020446928732
At time: 257.3685941696167 and batch: 400, loss is 4.345714502334594 and perplexity is 77.14713960301356
At time: 257.74819827079773 and batch: 450, loss is 4.400829725265503 and perplexity is 81.51847855353415
At time: 258.127192735672 and batch: 500, loss is 4.389734697341919 and perplexity is 80.6190277006799
At time: 258.50562858581543 and batch: 550, loss is 4.433352146148682 and perplexity is 84.21323937736636
At time: 258.8901982307434 and batch: 600, loss is 4.347019395828247 and perplexity is 77.24787411314509
At time: 259.2868597507477 and batch: 650, loss is 4.436470212936402 and perplexity is 84.47623168286682
At time: 259.6741433143616 and batch: 700, loss is 4.470272006988526 and perplexity is 87.38048788455436
At time: 260.05249190330505 and batch: 750, loss is 4.420585718154907 and perplexity is 83.14497061781181
At time: 260.4319829940796 and batch: 800, loss is 4.375631384849548 and perplexity is 79.49001250095822
At time: 260.8253653049469 and batch: 850, loss is 4.331001400947571 and perplexity is 76.0203753410459
At time: 261.2180564403534 and batch: 900, loss is 4.279099516868591 and perplexity is 72.17541798970193
At time: 261.5965187549591 and batch: 950, loss is 4.354371075630188 and perplexity is 77.81786838949618
At time: 261.9745750427246 and batch: 1000, loss is 4.408635663986206 and perplexity is 82.15729684621193
At time: 262.3530914783478 and batch: 1050, loss is 4.321678156852722 and perplexity is 75.31491253658642
At time: 262.7387807369232 and batch: 1100, loss is 4.438247184753418 and perplexity is 84.62647701710242
At time: 263.1545522212982 and batch: 1150, loss is 4.362367000579834 and perplexity is 78.44258850401154
At time: 263.54659485816956 and batch: 1200, loss is 4.3405865287780765 and perplexity is 76.75254371450364
At time: 263.93171072006226 and batch: 1250, loss is 4.311332473754883 and perplexity is 74.53974505155503
At time: 264.3187847137451 and batch: 1300, loss is 4.368440256118775 and perplexity is 78.92043997741374
At time: 264.7152826786041 and batch: 1350, loss is 4.322164936065674 and perplexity is 75.3515831949675
At time: 265.11413073539734 and batch: 1400, loss is 4.207158136367798 and perplexity is 67.1653934438371
At time: 265.49847769737244 and batch: 1450, loss is 4.292383842468261 and perplexity is 73.1406165542962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.862921820746528 and perplexity of 129.4017389768415
Finished 22 epochs...
Completing Train Step...
At time: 266.7355206012726 and batch: 50, loss is 4.482324380874633 and perplexity is 88.44000220086373
At time: 267.12800765037537 and batch: 100, loss is 4.4741235446929934 and perplexity is 87.71768607721026
At time: 267.5202748775482 and batch: 150, loss is 4.363335485458374 and perplexity is 78.51859576481161
At time: 267.91566014289856 and batch: 200, loss is 4.411957025527954 and perplexity is 82.43062459119461
At time: 268.3007547855377 and batch: 250, loss is 4.455199699401856 and perplexity is 86.07333792305563
At time: 268.68079924583435 and batch: 300, loss is 4.461623678207397 and perplexity is 86.62805104663589
At time: 269.061644077301 and batch: 350, loss is 4.473158893585205 and perplexity is 87.63310991396654
At time: 269.4420516490936 and batch: 400, loss is 4.344720010757446 and perplexity is 77.07045555961504
At time: 269.82311272621155 and batch: 450, loss is 4.399311590194702 and perplexity is 81.39481638401266
At time: 270.20898962020874 and batch: 500, loss is 4.388181066513061 and perplexity is 80.49387274132778
At time: 270.61114859580994 and batch: 550, loss is 4.432381954193115 and perplexity is 84.13157599095614
At time: 271.0124750137329 and batch: 600, loss is 4.346271505355835 and perplexity is 77.19012276261608
At time: 271.4146921634674 and batch: 650, loss is 4.43597454071045 and perplexity is 84.43436953687716
At time: 271.8049750328064 and batch: 700, loss is 4.46955735206604 and perplexity is 87.31806329743456
At time: 272.2011444568634 and batch: 750, loss is 4.419665098190308 and perplexity is 83.06846092148574
At time: 272.595121383667 and batch: 800, loss is 4.374952812194824 and perplexity is 79.43609104903183
At time: 272.9910490512848 and batch: 850, loss is 4.330518088340759 and perplexity is 75.98364261267942
At time: 273.3714118003845 and batch: 900, loss is 4.27857246875763 and perplexity is 72.1373880946651
At time: 273.75221848487854 and batch: 950, loss is 4.3538088750839234 and perplexity is 77.77413143699975
At time: 274.1551899909973 and batch: 1000, loss is 4.408233284950256 and perplexity is 82.12424512241705
At time: 274.5558636188507 and batch: 1050, loss is 4.321699414253235 and perplexity is 75.31651355286346
At time: 274.9507522583008 and batch: 1100, loss is 4.438361148834229 and perplexity is 84.63612194534515
At time: 275.33728432655334 and batch: 1150, loss is 4.3622697162628175 and perplexity is 78.43495764155158
At time: 275.7172646522522 and batch: 1200, loss is 4.341131143569946 and perplexity is 76.79435566979538
At time: 276.09787607192993 and batch: 1250, loss is 4.311531372070313 and perplexity is 74.55457235579242
At time: 276.4784872531891 and batch: 1300, loss is 4.368576145172119 and perplexity is 78.93116512999067
At time: 276.8630259037018 and batch: 1350, loss is 4.322453155517578 and perplexity is 75.37330411702182
At time: 277.26218461990356 and batch: 1400, loss is 4.207375183105468 and perplexity is 67.1799730555398
At time: 277.6507873535156 and batch: 1450, loss is 4.292742948532105 and perplexity is 73.16688650978195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.862805488782051 and perplexity of 129.38668629391069
Finished 23 epochs...
Completing Train Step...
At time: 278.90163469314575 and batch: 50, loss is 4.480929541587829 and perplexity is 88.31672860468294
At time: 279.2797999382019 and batch: 100, loss is 4.4728688049316405 and perplexity is 87.60769222997305
At time: 279.6587929725647 and batch: 150, loss is 4.36221643447876 and perplexity is 78.43077859841037
At time: 280.0374536514282 and batch: 200, loss is 4.411067533493042 and perplexity is 82.35733580691497
At time: 280.4165880680084 and batch: 250, loss is 4.454062819480896 and perplexity is 85.97553847708791
At time: 280.79474568367004 and batch: 300, loss is 4.460707521438598 and perplexity is 86.54872251553567
At time: 281.172963142395 and batch: 350, loss is 4.4721641349792485 and perplexity is 87.54597946777845
At time: 281.55167031288147 and batch: 400, loss is 4.344121036529541 and perplexity is 77.02430616553048
At time: 281.93028569221497 and batch: 450, loss is 4.398130435943603 and perplexity is 81.2987333062618
At time: 282.3091471195221 and batch: 500, loss is 4.387004070281982 and perplexity is 80.39918748950933
At time: 282.70035696029663 and batch: 550, loss is 4.431637620925903 and perplexity is 84.06897736013492
At time: 283.077716588974 and batch: 600, loss is 4.345808372497559 and perplexity is 77.15438175748612
At time: 283.45642614364624 and batch: 650, loss is 4.435577001571655 and perplexity is 84.4008102413355
At time: 283.83555722236633 and batch: 700, loss is 4.46906644821167 and perplexity is 87.27520904312564
At time: 284.214079618454 and batch: 750, loss is 4.41901798248291 and perplexity is 83.01472340470497
At time: 284.59209990501404 and batch: 800, loss is 4.374316544532776 and perplexity is 79.38556450900414
At time: 284.971097946167 and batch: 850, loss is 4.330170412063598 and perplexity is 75.95722949456406
At time: 285.3500506877899 and batch: 900, loss is 4.27812310218811 and perplexity is 72.10497924631478
At time: 285.7284080982208 and batch: 950, loss is 4.353364305496216 and perplexity is 77.73956310803572
At time: 286.10604310035706 and batch: 1000, loss is 4.407899103164673 and perplexity is 82.09680528074536
At time: 286.4842450618744 and batch: 1050, loss is 4.321675343513489 and perplexity is 75.31470065048616
At time: 286.86286878585815 and batch: 1100, loss is 4.438426036834716 and perplexity is 84.64161399224925
At time: 287.24151492118835 and batch: 1150, loss is 4.3621324443817135 and perplexity is 78.42419146633529
At time: 287.6201410293579 and batch: 1200, loss is 4.341225080490112 and perplexity is 76.801569833886
At time: 287.9973027706146 and batch: 1250, loss is 4.311686406135559 and perplexity is 74.56613175025423
At time: 288.37587881088257 and batch: 1300, loss is 4.3686313056945805 and perplexity is 78.93551913438122
At time: 288.75497102737427 and batch: 1350, loss is 4.322678136825561 and perplexity is 75.39026360928194
At time: 289.13368487358093 and batch: 1400, loss is 4.207386755943299 and perplexity is 67.18075052297216
At time: 289.513836145401 and batch: 1450, loss is 4.29292010307312 and perplexity is 73.17984950417187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.862733498597756 and perplexity of 129.37737205778993
Finished 24 epochs...
Completing Train Step...
At time: 290.77412366867065 and batch: 50, loss is 4.479717669486999 and perplexity is 88.20976485153533
At time: 291.1692192554474 and batch: 100, loss is 4.471856250762939 and perplexity is 87.51902959143266
At time: 291.566490650177 and batch: 150, loss is 4.361218643188477 and perplexity is 78.3525600800024
At time: 291.9609794616699 and batch: 200, loss is 4.410291986465454 and perplexity is 82.29348858139308
At time: 292.3553614616394 and batch: 250, loss is 4.453111848831177 and perplexity is 85.89381712686384
At time: 292.74966049194336 and batch: 300, loss is 4.459970207214355 and perplexity is 86.48493243089314
At time: 293.1560845375061 and batch: 350, loss is 4.471215782165527 and perplexity is 87.46299434762582
At time: 293.5431137084961 and batch: 400, loss is 4.343624963760376 and perplexity is 76.98610598049711
At time: 293.9540150165558 and batch: 450, loss is 4.3971294498443605 and perplexity is 81.21739512032448
At time: 294.3434410095215 and batch: 500, loss is 4.385958709716797 and perplexity is 80.3151852633918
At time: 294.72287702560425 and batch: 550, loss is 4.43096926689148 and perplexity is 84.01280829244882
At time: 295.1197724342346 and batch: 600, loss is 4.3454393291473385 and perplexity is 77.12591369925505
At time: 295.4994969367981 and batch: 650, loss is 4.435227336883545 and perplexity is 84.37130341739409
At time: 295.88296604156494 and batch: 700, loss is 4.468577356338501 and perplexity is 87.2325338845408
At time: 296.26271176338196 and batch: 750, loss is 4.418384113311768 and perplexity is 82.96211960451271
At time: 296.6588020324707 and batch: 800, loss is 4.373737850189209 and perplexity is 79.33963782190065
At time: 297.0616981983185 and batch: 850, loss is 4.329890332221985 and perplexity is 75.93595838470142
At time: 297.44145917892456 and batch: 900, loss is 4.277667217254638 and perplexity is 72.07211516433718
At time: 297.842041015625 and batch: 950, loss is 4.352922449111938 and perplexity is 77.70522097346992
At time: 298.2339656352997 and batch: 1000, loss is 4.407512211799622 and perplexity is 82.06504887921886
At time: 298.6123924255371 and batch: 1050, loss is 4.3215875148773195 and perplexity is 75.30808615351991
At time: 299.01166892051697 and batch: 1100, loss is 4.438405733108521 and perplexity is 84.63989546954026
At time: 299.39810609817505 and batch: 1150, loss is 4.361919937133789 and perplexity is 78.4075275279026
At time: 299.7918062210083 and batch: 1200, loss is 4.341296882629394 and perplexity is 76.8070845488821
At time: 300.18510484695435 and batch: 1250, loss is 4.3116659879684445 and perplexity is 74.56460926205834
At time: 300.5646719932556 and batch: 1300, loss is 4.368566465377808 and perplexity is 78.93040109624533
At time: 300.9583694934845 and batch: 1350, loss is 4.322815322875977 and perplexity is 75.40060681124157
At time: 301.3521201610565 and batch: 1400, loss is 4.207278985977172 and perplexity is 67.17351084588084
At time: 301.7455642223358 and batch: 1450, loss is 4.29291841506958 and perplexity is 73.17972597643107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.862653161725428 and perplexity of 129.36697870185913
Finished 25 epochs...
Completing Train Step...
At time: 302.9927854537964 and batch: 50, loss is 4.47865460395813 and perplexity is 88.11604191684903
At time: 303.412442445755 and batch: 100, loss is 4.470913105010986 and perplexity is 87.43652530335864
At time: 303.80436992645264 and batch: 150, loss is 4.3602947330474855 and perplexity is 78.28020278613774
At time: 304.1840465068817 and batch: 200, loss is 4.40955849647522 and perplexity is 82.23314926310539
At time: 304.56413888931274 and batch: 250, loss is 4.452287302017212 and perplexity is 85.82302284422369
At time: 304.96107625961304 and batch: 300, loss is 4.459320240020752 and perplexity is 86.42873832621261
At time: 305.3430697917938 and batch: 350, loss is 4.4703663730621335 and perplexity is 87.38873402717788
At time: 305.72406697273254 and batch: 400, loss is 4.3431215000152585 and perplexity is 76.94735602267615
At time: 306.10495686531067 and batch: 450, loss is 4.396240186691284 and perplexity is 81.14520358684786
At time: 306.4856822490692 and batch: 500, loss is 4.384972190856933 and perplexity is 80.23599188769808
At time: 306.87236857414246 and batch: 550, loss is 4.4303527927398685 and perplexity is 83.96103252858204
At time: 307.26691699028015 and batch: 600, loss is 4.3450609302520755 and perplexity is 77.0967348596836
At time: 307.66701340675354 and batch: 650, loss is 4.434854021072388 and perplexity is 84.33981215427937
At time: 308.0647089481354 and batch: 700, loss is 4.4681581783294675 and perplexity is 87.19597558741657
At time: 308.45076537132263 and batch: 750, loss is 4.417795400619507 and perplexity is 82.91329312551886
At time: 308.83871245384216 and batch: 800, loss is 4.373173060417176 and perplexity is 79.29484025773586
At time: 309.21894097328186 and batch: 850, loss is 4.329561061859131 and perplexity is 75.91095904012795
At time: 309.598735332489 and batch: 900, loss is 4.277253136634827 and perplexity is 72.04227767620793
At time: 309.9806640148163 and batch: 950, loss is 4.352512893676757 and perplexity is 77.67340289395676
At time: 310.3602912425995 and batch: 1000, loss is 4.407127680778504 and perplexity is 82.03349838863518
At time: 310.7405540943146 and batch: 1050, loss is 4.321469106674194 and perplexity is 75.29916958626545
At time: 311.1341698169708 and batch: 1100, loss is 4.43837532043457 and perplexity is 84.63732138313875
At time: 311.5298738479614 and batch: 1150, loss is 4.361771898269653 and perplexity is 78.39592102571561
At time: 311.91233468055725 and batch: 1200, loss is 4.3414883708953855 and perplexity is 76.82179361257982
At time: 312.3062014579773 and batch: 1250, loss is 4.311644892692566 and perplexity is 74.56303631764612
At time: 312.68604612350464 and batch: 1300, loss is 4.368565158843994 and perplexity is 78.93029797107475
At time: 313.06762433052063 and batch: 1350, loss is 4.322917957305908 and perplexity is 75.40834590668013
At time: 313.4486651420593 and batch: 1400, loss is 4.207150893211365 and perplexity is 67.16490695614736
At time: 313.82945227622986 and batch: 1450, loss is 4.292824983596802 and perplexity is 73.17288900625466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.862749670305822 and perplexity of 129.37946432779893
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 315.1076035499573 and batch: 50, loss is 4.477673201560974 and perplexity is 88.02960704271776
At time: 315.5010323524475 and batch: 100, loss is 4.47027626991272 and perplexity is 87.38086038174421
At time: 315.88042640686035 and batch: 150, loss is 4.359482927322388 and perplexity is 78.2166802568192
At time: 316.2603943347931 and batch: 200, loss is 4.408667936325073 and perplexity is 82.15994829712018
At time: 316.6401243209839 and batch: 250, loss is 4.452081465721131 and perplexity is 85.80535916905801
At time: 317.0194044113159 and batch: 300, loss is 4.4586035251617435 and perplexity is 86.36681575827185
At time: 317.3984487056732 and batch: 350, loss is 4.469204330444336 and perplexity is 87.28724357345979
At time: 317.79792833328247 and batch: 400, loss is 4.341563510894775 and perplexity is 76.82756621897909
At time: 318.184778213501 and batch: 450, loss is 4.394479885101318 and perplexity is 81.00248920298617
At time: 318.5637059211731 and batch: 500, loss is 4.382311792373657 and perplexity is 80.02281586888778
At time: 318.9427721500397 and batch: 550, loss is 4.427907390594482 and perplexity is 83.75596487813588
At time: 319.3212308883667 and batch: 600, loss is 4.343012886047363 and perplexity is 76.93899891887679
At time: 319.70073986053467 and batch: 650, loss is 4.433020534515381 and perplexity is 84.18531791730726
At time: 320.08243799209595 and batch: 700, loss is 4.465463361740112 and perplexity is 86.96131475184448
At time: 320.4717035293579 and batch: 750, loss is 4.415709018707275 and perplexity is 82.74048466536709
At time: 320.85288429260254 and batch: 800, loss is 4.3701156759262085 and perplexity is 79.05277567373084
At time: 321.2479374408722 and batch: 850, loss is 4.326528496742249 and perplexity is 75.68110281689111
At time: 321.6414096355438 and batch: 900, loss is 4.27405038356781 and perplexity is 71.8119131476918
At time: 322.0330424308777 and batch: 950, loss is 4.348749380111695 and perplexity is 77.38162738345974
At time: 322.41212129592896 and batch: 1000, loss is 4.404280138015747 and perplexity is 81.80023676283899
At time: 322.7976338863373 and batch: 1050, loss is 4.317426962852478 and perplexity is 74.99541383893744
At time: 323.18646478652954 and batch: 1100, loss is 4.435464944839477 and perplexity is 84.39135309222522
At time: 323.56574010849 and batch: 1150, loss is 4.35760757446289 and perplexity is 78.07013383791175
At time: 323.94488620758057 and batch: 1200, loss is 4.337980003356933 and perplexity is 76.55274675921385
At time: 324.3238275051117 and batch: 1250, loss is 4.307922015190124 and perplexity is 74.28596334161487
At time: 324.70420002937317 and batch: 1300, loss is 4.363779954910278 and perplexity is 78.5535026389804
At time: 325.10356640815735 and batch: 1350, loss is 4.31892388343811 and perplexity is 75.1077600834655
At time: 325.4903004169464 and batch: 1400, loss is 4.201931462287903 and perplexity is 66.81525764280347
At time: 325.8698742389679 and batch: 1450, loss is 4.287631454467774 and perplexity is 72.79384860640403
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861904046474359 and perplexity of 129.270104214737
Finished 27 epochs...
Completing Train Step...
At time: 327.13583970069885 and batch: 50, loss is 4.47657274723053 and perplexity is 87.93278776280887
At time: 327.5234351158142 and batch: 100, loss is 4.4695072269439695 and perplexity is 87.3136865785455
At time: 327.90230345726013 and batch: 150, loss is 4.358868999481201 and perplexity is 78.16867559637092
At time: 328.2808530330658 and batch: 200, loss is 4.408401145935058 and perplexity is 82.13803173616432
At time: 328.6605849266052 and batch: 250, loss is 4.451629118919373 and perplexity is 85.76655416658524
At time: 329.039347410202 and batch: 300, loss is 4.45809778213501 and perplexity is 86.32314738687883
At time: 329.4182777404785 and batch: 350, loss is 4.468782014846802 and perplexity is 87.25038859179752
At time: 329.81966733932495 and batch: 400, loss is 4.341044883728028 and perplexity is 76.78773168651107
At time: 330.2078022956848 and batch: 450, loss is 4.393857641220093 and perplexity is 80.95210157803703
At time: 330.58635544776917 and batch: 500, loss is 4.381698141098022 and perplexity is 79.97372482977984
At time: 330.97954630851746 and batch: 550, loss is 4.42741364479065 and perplexity is 83.71462092947186
At time: 331.3811938762665 and batch: 600, loss is 4.342609376907348 and perplexity is 76.90795959233655
At time: 331.78524017333984 and batch: 650, loss is 4.432742528915405 and perplexity is 84.16191718040913
At time: 332.1634349822998 and batch: 700, loss is 4.464996738433838 and perplexity is 86.92074604152597
At time: 332.5424358844757 and batch: 750, loss is 4.415305652618408 and perplexity is 82.70711668988395
At time: 332.9399597644806 and batch: 800, loss is 4.369826593399048 and perplexity is 79.02992620041087
At time: 333.3287217617035 and batch: 850, loss is 4.326307516098023 and perplexity is 75.66438060574546
At time: 333.7184190750122 and batch: 900, loss is 4.2738967752456665 and perplexity is 71.80088308737946
At time: 334.1125512123108 and batch: 950, loss is 4.348715596199035 and perplexity is 77.37901317347816
At time: 334.49531841278076 and batch: 1000, loss is 4.404195990562439 and perplexity is 81.79335377083257
At time: 334.8739833831787 and batch: 1050, loss is 4.317498698234558 and perplexity is 75.00079385656991
At time: 335.25247979164124 and batch: 1100, loss is 4.435488901138306 and perplexity is 84.39337482091489
At time: 335.6310212612152 and batch: 1150, loss is 4.357550573348999 and perplexity is 78.06568388014884
At time: 336.00924706459045 and batch: 1200, loss is 4.3381281661987305 and perplexity is 76.56408987201424
At time: 336.38805413246155 and batch: 1250, loss is 4.308213486671447 and perplexity is 74.30761873720337
At time: 336.7829484939575 and batch: 1300, loss is 4.363780651092529 and perplexity is 78.55355732655377
At time: 337.1758098602295 and batch: 1350, loss is 4.3191606807708744 and perplexity is 75.12554750664724
At time: 337.55496549606323 and batch: 1400, loss is 4.2021723651885985 and perplexity is 66.83135557112129
At time: 337.9333610534668 and batch: 1450, loss is 4.287866106033325 and perplexity is 72.81093180116285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861801277877938 and perplexity of 129.25681999018
Finished 28 epochs...
Completing Train Step...
At time: 339.2328407764435 and batch: 50, loss is 4.476005725860595 and perplexity is 87.88294212613555
At time: 339.6298542022705 and batch: 100, loss is 4.469067754745484 and perplexity is 87.27532307121183
At time: 340.02204513549805 and batch: 150, loss is 4.358436489105225 and perplexity is 78.13487414336566
At time: 340.4010365009308 and batch: 200, loss is 4.408166599273682 and perplexity is 82.11876879416626
At time: 340.7988033294678 and batch: 250, loss is 4.45131600856781 and perplexity is 85.73970397441373
At time: 341.1891715526581 and batch: 300, loss is 4.457783765792847 and perplexity is 86.29604476344848
At time: 341.58314776420593 and batch: 350, loss is 4.4684976291656495 and perplexity is 87.22557935846957
At time: 341.990620136261 and batch: 400, loss is 4.340733337402344 and perplexity is 76.7638124770109
At time: 342.37040662765503 and batch: 450, loss is 4.393373165130615 and perplexity is 80.91289171931598
At time: 342.7489471435547 and batch: 500, loss is 4.381225748062134 and perplexity is 79.93595472098674
At time: 343.1267509460449 and batch: 550, loss is 4.42707106590271 and perplexity is 83.68594697955488
At time: 343.5060932636261 and batch: 600, loss is 4.342311105728149 and perplexity is 76.88502358528413
At time: 343.88483905792236 and batch: 650, loss is 4.432508134841919 and perplexity is 84.14219243758058
At time: 344.2624204158783 and batch: 700, loss is 4.464712867736816 and perplexity is 86.89607529057884
At time: 344.65746212005615 and batch: 750, loss is 4.415045099258423 and perplexity is 82.68556987990448
At time: 345.0501296520233 and batch: 800, loss is 4.369580535888672 and perplexity is 79.01048268573433
At time: 345.4278621673584 and batch: 850, loss is 4.326160292625428 and perplexity is 75.65324185284398
At time: 345.80662393569946 and batch: 900, loss is 4.2737515354156494 and perplexity is 71.79045549659386
At time: 346.18516516685486 and batch: 950, loss is 4.348672332763672 and perplexity is 77.37566556395834
At time: 346.5638544559479 and batch: 1000, loss is 4.404136247634888 and perplexity is 81.78846734239032
At time: 346.956951379776 and batch: 1050, loss is 4.3175230884552 and perplexity is 75.00262316478894
At time: 347.35067200660706 and batch: 1100, loss is 4.435491409301758 and perplexity is 84.39358649355866
At time: 347.7330024242401 and batch: 1150, loss is 4.357500619888306 and perplexity is 78.06178432647656
At time: 348.11146211624146 and batch: 1200, loss is 4.33824517250061 and perplexity is 76.57304887714673
At time: 348.4902012348175 and batch: 1250, loss is 4.308434648513794 and perplexity is 74.32405456448559
At time: 348.8692409992218 and batch: 1300, loss is 4.363764543533325 and perplexity is 78.55229203066884
At time: 349.24792766571045 and batch: 1350, loss is 4.319343748092652 and perplexity is 75.13930179836859
At time: 349.62723207473755 and batch: 1400, loss is 4.202333059310913 and perplexity is 66.84209584007381
At time: 350.00687432289124 and batch: 1450, loss is 4.287980842590332 and perplexity is 72.81928635606741
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861763717781784 and perplexity of 129.25196518276667
Finished 29 epochs...
Completing Train Step...
At time: 351.27403020858765 and batch: 50, loss is 4.475543384552002 and perplexity is 87.84231960312873
At time: 351.68419766426086 and batch: 100, loss is 4.468731555938721 and perplexity is 87.24598614353181
At time: 352.07835054397583 and batch: 150, loss is 4.358079299926758 and perplexity is 78.10697019565154
At time: 352.4612274169922 and batch: 200, loss is 4.407959117889404 and perplexity is 82.10173244576534
At time: 352.8419830799103 and batch: 250, loss is 4.451065421104431 and perplexity is 85.71822137123188
At time: 353.222373008728 and batch: 300, loss is 4.45750247001648 and perplexity is 86.27177346440634
At time: 353.6032898426056 and batch: 350, loss is 4.46825798034668 and perplexity is 87.20467835594268
At time: 353.9840009212494 and batch: 400, loss is 4.340478982925415 and perplexity is 76.74428974059421
At time: 354.39149737358093 and batch: 450, loss is 4.392976560592651 and perplexity is 80.88080766204222
At time: 354.7854645252228 and batch: 500, loss is 4.380837278366089 and perplexity is 79.90490805568798
At time: 355.1954770088196 and batch: 550, loss is 4.426784353256226 and perplexity is 83.66195659955986
At time: 355.59067034721375 and batch: 600, loss is 4.342071733474731 and perplexity is 76.86662164647908
At time: 355.97917127609253 and batch: 650, loss is 4.432341814041138 and perplexity is 84.12819900448659
At time: 356.35851287841797 and batch: 700, loss is 4.464481229782105 and perplexity is 86.87594919250014
At time: 356.7382230758667 and batch: 750, loss is 4.41483247756958 and perplexity is 82.66799100328511
At time: 357.1407148838043 and batch: 800, loss is 4.369343886375427 and perplexity is 78.9917871057027
At time: 357.5321578979492 and batch: 850, loss is 4.326014542579651 and perplexity is 75.64221619289553
At time: 357.92558097839355 and batch: 900, loss is 4.273617830276489 and perplexity is 71.780857385424
At time: 358.32074451446533 and batch: 950, loss is 4.348612189292908 and perplexity is 77.37101206281885
At time: 358.70675015449524 and batch: 1000, loss is 4.404080781936646 and perplexity is 81.78393101374748
At time: 359.1002674102783 and batch: 1050, loss is 4.31752760887146 and perplexity is 75.00296220863254
At time: 359.5018970966339 and batch: 1100, loss is 4.4354773616790775 and perplexity is 84.39240097262586
At time: 359.8925271034241 and batch: 1150, loss is 4.357439002990723 and perplexity is 78.05697454968981
At time: 360.2749993801117 and batch: 1200, loss is 4.3383498382568355 and perplexity is 76.58106387265443
At time: 360.65606212615967 and batch: 1250, loss is 4.308612389564514 and perplexity is 74.33726617412557
At time: 361.03644466400146 and batch: 1300, loss is 4.363739862442016 and perplexity is 78.55035329830186
At time: 361.4171118736267 and batch: 1350, loss is 4.319491510391235 and perplexity is 75.15040537464105
At time: 361.79831171035767 and batch: 1400, loss is 4.202433547973633 and perplexity is 66.84881305039427
At time: 362.1789846420288 and batch: 1450, loss is 4.2880367660522465 and perplexity is 72.82335877652547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.86175537109375 and perplexity of 129.25088636143778
Finished 30 epochs...
Completing Train Step...
At time: 363.42784214019775 and batch: 50, loss is 4.475134735107422 and perplexity is 87.80643022159965
At time: 363.8196473121643 and batch: 100, loss is 4.468441696166992 and perplexity is 87.22070070669649
At time: 364.19812059402466 and batch: 150, loss is 4.357771015167236 and perplexity is 78.08289471836981
At time: 364.57692766189575 and batch: 200, loss is 4.407769451141357 and perplexity is 82.08616195381231
At time: 364.97522735595703 and batch: 250, loss is 4.450841789245605 and perplexity is 85.69905418932753
At time: 365.3630886077881 and batch: 300, loss is 4.457247619628906 and perplexity is 86.24978987088491
At time: 365.74169421195984 and batch: 350, loss is 4.468038396835327 and perplexity is 87.18553174867948
At time: 366.12630343437195 and batch: 400, loss is 4.340261297225952 and perplexity is 76.7275854244136
At time: 366.52168798446655 and batch: 450, loss is 4.392628107070923 and perplexity is 80.8526293694699
At time: 366.9050784111023 and batch: 500, loss is 4.380500364303589 and perplexity is 79.8779915030384
At time: 367.2836346626282 and batch: 550, loss is 4.426532039642334 and perplexity is 83.64085021177142
At time: 367.6620924472809 and batch: 600, loss is 4.341855764389038 and perplexity is 76.85002262498402
At time: 368.0590875148773 and batch: 650, loss is 4.432203893661499 and perplexity is 84.11659681144938
At time: 368.4489588737488 and batch: 700, loss is 4.464267072677612 and perplexity is 86.85734608283617
At time: 368.8272371292114 and batch: 750, loss is 4.414646825790405 and perplexity is 82.65264496822797
At time: 369.2062203884125 and batch: 800, loss is 4.369121279716492 and perplexity is 78.97420496491516
At time: 369.5849938392639 and batch: 850, loss is 4.325872702598572 and perplexity is 75.63148786325293
At time: 369.96396923065186 and batch: 900, loss is 4.273481588363648 and perplexity is 71.77107849027124
At time: 370.34293127059937 and batch: 950, loss is 4.348534059524536 and perplexity is 77.36496731970799
At time: 370.74989461898804 and batch: 1000, loss is 4.404022970199585 and perplexity is 81.7792030792983
At time: 371.15713930130005 and batch: 1050, loss is 4.317517380714417 and perplexity is 75.00219507047959
At time: 371.538330078125 and batch: 1100, loss is 4.435453090667725 and perplexity is 84.3903527085606
At time: 371.91699838638306 and batch: 1150, loss is 4.357370738983154 and perplexity is 78.05164624965602
At time: 372.2951319217682 and batch: 1200, loss is 4.338441314697266 and perplexity is 76.58806955620449
At time: 372.6737334728241 and batch: 1250, loss is 4.308750948905945 and perplexity is 74.3475670103925
At time: 373.05255246162415 and batch: 1300, loss is 4.36371018409729 and perplexity is 78.54802208843167
At time: 373.4316523075104 and batch: 1350, loss is 4.319615173339844 and perplexity is 75.15969927000219
At time: 373.80967688560486 and batch: 1400, loss is 4.20250675201416 and perplexity is 66.85370683273413
At time: 374.18811106681824 and batch: 1450, loss is 4.288065204620361 and perplexity is 72.82542979802267
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861760587773771 and perplexity of 129.2515606237131
Annealing...
Finished 31 epochs...
Completing Train Step...
At time: 375.438848733902 and batch: 50, loss is 4.474727072715759 and perplexity is 87.77064213747579
At time: 375.8171980381012 and batch: 100, loss is 4.468390054702759 and perplexity is 87.21619661830044
At time: 376.1963541507721 and batch: 150, loss is 4.358058176040649 and perplexity is 78.1053202903351
At time: 376.57499623298645 and batch: 200, loss is 4.407214889526367 and perplexity is 82.04065273926894
At time: 376.95475339889526 and batch: 250, loss is 4.450780968666077 and perplexity is 85.69384208169002
At time: 377.33371901512146 and batch: 300, loss is 4.456917333602905 and perplexity is 86.22130747447271
At time: 377.71165919303894 and batch: 350, loss is 4.467760267257691 and perplexity is 87.1612862454103
At time: 378.08857464790344 and batch: 400, loss is 4.33936203956604 and perplexity is 76.65861856962792
At time: 378.4675931930542 and batch: 450, loss is 4.392054767608642 and perplexity is 80.80628665274685
At time: 378.84644532203674 and batch: 500, loss is 4.379774379730224 and perplexity is 79.82002235835432
At time: 379.2253520488739 and batch: 550, loss is 4.425493688583374 and perplexity is 83.5540467204294
At time: 379.60414814949036 and batch: 600, loss is 4.340962476730347 and perplexity is 76.78140410080631
At time: 379.9832513332367 and batch: 650, loss is 4.431443033218383 and perplexity is 84.05262016206335
At time: 380.363000869751 and batch: 700, loss is 4.463296861648559 and perplexity is 86.77311699431483
At time: 380.75511622428894 and batch: 750, loss is 4.4139692497253415 and perplexity is 82.59666048329872
At time: 381.13422107696533 and batch: 800, loss is 4.367999320030212 and perplexity is 78.88564877821379
At time: 381.5131196975708 and batch: 850, loss is 4.324784998893738 and perplexity is 75.54926793726722
At time: 381.90784645080566 and batch: 900, loss is 4.27257529258728 and perplexity is 71.70606213144609
At time: 382.3014645576477 and batch: 950, loss is 4.347058057785034 and perplexity is 77.2508607248497
At time: 382.6865074634552 and batch: 1000, loss is 4.403071818351745 and perplexity is 81.70145561985586
At time: 383.06818985939026 and batch: 1050, loss is 4.316070604324341 and perplexity is 74.89376212347551
At time: 383.4473252296448 and batch: 1100, loss is 4.434376497268676 and perplexity is 84.2995475008055
At time: 383.8363642692566 and batch: 1150, loss is 4.355903978347778 and perplexity is 77.93724708601546
At time: 384.22972440719604 and batch: 1200, loss is 4.337267913818359 and perplexity is 76.49825375334987
At time: 384.6304862499237 and batch: 1250, loss is 4.3076161813735965 and perplexity is 74.26324765572117
At time: 385.0290093421936 and batch: 1300, loss is 4.362199554443359 and perplexity is 78.42945469526492
At time: 385.4314992427826 and batch: 1350, loss is 4.317929105758667 and perplexity is 75.03308171052915
At time: 385.82555651664734 and batch: 1400, loss is 4.200662651062012 and perplexity is 66.73053545344399
At time: 386.20696783065796 and batch: 1450, loss is 4.286213798522949 and perplexity is 72.69072508828577
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861549312232906 and perplexity of 129.22425581485538
Finished 32 epochs...
Completing Train Step...
At time: 387.4561824798584 and batch: 50, loss is 4.474397854804993 and perplexity is 87.74175122600835
At time: 387.8339822292328 and batch: 100, loss is 4.468080396652222 and perplexity is 87.18919360194683
At time: 388.2136549949646 and batch: 150, loss is 4.357885694503784 and perplexity is 78.09184972639923
At time: 388.59331798553467 and batch: 200, loss is 4.40701844215393 and perplexity is 82.02453765154046
At time: 388.98913860321045 and batch: 250, loss is 4.450639524459839 and perplexity is 85.68172204139222
At time: 389.3707263469696 and batch: 300, loss is 4.456691188812256 and perplexity is 86.20181117952025
At time: 389.76417994499207 and batch: 350, loss is 4.467618865966797 and perplexity is 87.14896239834368
At time: 390.16327929496765 and batch: 400, loss is 4.339244699478149 and perplexity is 76.64962396831136
At time: 390.55604887008667 and batch: 450, loss is 4.391902675628662 and perplexity is 80.79399759917193
At time: 390.94950318336487 and batch: 500, loss is 4.379630880355835 and perplexity is 79.8085690568726
At time: 391.3293704986572 and batch: 550, loss is 4.425364475250245 and perplexity is 83.54325112103892
At time: 391.7097430229187 and batch: 600, loss is 4.3408557891845705 and perplexity is 76.77321291819788
At time: 392.0898039340973 and batch: 650, loss is 4.431346673965454 and perplexity is 84.04452130458394
At time: 392.47017788887024 and batch: 700, loss is 4.4631604480743405 and perplexity is 86.76128077060868
At time: 392.8501491546631 and batch: 750, loss is 4.413794412612915 and perplexity is 82.58222078401816
At time: 393.22974395751953 and batch: 800, loss is 4.367908143997193 and perplexity is 78.87845662557699
At time: 393.6096305847168 and batch: 850, loss is 4.324768052101136 and perplexity is 75.54798763034081
At time: 393.98896837234497 and batch: 900, loss is 4.272538080215454 and perplexity is 71.70339382844708
At time: 394.3689475059509 and batch: 950, loss is 4.347017250061035 and perplexity is 77.24770835736746
At time: 394.7490358352661 and batch: 1000, loss is 4.4030023956298825 and perplexity is 81.6957838793027
At time: 395.13889837265015 and batch: 1050, loss is 4.316124095916748 and perplexity is 74.89776841722342
At time: 395.53447437286377 and batch: 1100, loss is 4.4343963050842286 and perplexity is 84.30121730723108
At time: 395.92103576660156 and batch: 1150, loss is 4.3559095001220705 and perplexity is 77.93767743909096
At time: 396.300662279129 and batch: 1200, loss is 4.337298064231873 and perplexity is 76.50056024210421
At time: 396.6922450065613 and batch: 1250, loss is 4.307747774124145 and perplexity is 74.27302080376849
At time: 397.08952736854553 and batch: 1300, loss is 4.362246990203857 and perplexity is 78.43317514433433
At time: 397.49281668663025 and batch: 1350, loss is 4.317975196838379 and perplexity is 75.0365401459802
At time: 397.87241291999817 and batch: 1400, loss is 4.200787119865417 and perplexity is 66.73884184027477
At time: 398.25114703178406 and batch: 1450, loss is 4.2862789344787595 and perplexity is 72.6954600223485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861515403812767 and perplexity of 129.219874098786
Finished 33 epochs...
Completing Train Step...
At time: 399.4850926399231 and batch: 50, loss is 4.474209089279174 and perplexity is 87.72519017132922
At time: 399.8756983280182 and batch: 100, loss is 4.4679281044006345 and perplexity is 87.1759163743742
At time: 400.25204586982727 and batch: 150, loss is 4.357809038162231 and perplexity is 78.08586372032971
At time: 400.64349126815796 and batch: 200, loss is 4.406888236999512 and perplexity is 82.01385832921594
At time: 401.0300750732422 and batch: 250, loss is 4.45050467967987 and perplexity is 85.67016908738148
At time: 401.41638255119324 and batch: 300, loss is 4.456544523239136 and perplexity is 86.18916926856883
At time: 401.813481092453 and batch: 350, loss is 4.467527561187744 and perplexity is 87.14100564483755
At time: 402.20399594306946 and batch: 400, loss is 4.3391412734985355 and perplexity is 76.64169681580925
At time: 402.58285999298096 and batch: 450, loss is 4.39177604675293 and perplexity is 80.78376739382337
At time: 402.96178913116455 and batch: 500, loss is 4.379506483078003 and perplexity is 79.79864170561477
At time: 403.3401024341583 and batch: 550, loss is 4.425269832611084 and perplexity is 83.535344741415
At time: 403.7401430606842 and batch: 600, loss is 4.3407625961303715 and perplexity is 76.76605852138059
At time: 404.1335778236389 and batch: 650, loss is 4.431278171539307 and perplexity is 84.03876424815866
At time: 404.51843643188477 and batch: 700, loss is 4.463062715530396 and perplexity is 86.75280178426625
At time: 404.8980624675751 and batch: 750, loss is 4.413683738708496 and perplexity is 82.57308159295273
At time: 405.2934079170227 and batch: 800, loss is 4.367834753990174 and perplexity is 78.87266794750974
At time: 405.6848850250244 and batch: 850, loss is 4.324734153747559 and perplexity is 75.54542672134967
At time: 406.07245206832886 and batch: 900, loss is 4.272520384788513 and perplexity is 71.7021250175063
At time: 406.46776700019836 and batch: 950, loss is 4.346974377632141 and perplexity is 77.24439663147504
At time: 406.87412095069885 and batch: 1000, loss is 4.4029596900939945 and perplexity is 81.69229509156814
At time: 407.27524995803833 and batch: 1050, loss is 4.3161580801010135 and perplexity is 74.90031380003754
At time: 407.663245677948 and batch: 1100, loss is 4.434407691955567 and perplexity is 84.30217723981153
At time: 408.04101848602295 and batch: 1150, loss is 4.355902738571167 and perplexity is 77.93715046129928
At time: 408.43948554992676 and batch: 1200, loss is 4.337338995933533 and perplexity is 76.50369160429842
At time: 408.8312466144562 and batch: 1250, loss is 4.307847056388855 and perplexity is 74.28039516354625
At time: 409.20951986312866 and batch: 1300, loss is 4.362278814315796 and perplexity is 78.43567125019779
At time: 409.5885536670685 and batch: 1350, loss is 4.318006639480591 and perplexity is 75.03889953015725
At time: 409.9673366546631 and batch: 1400, loss is 4.200856008529663 and perplexity is 66.74343954830564
At time: 410.34669375419617 and batch: 1450, loss is 4.286322860717774 and perplexity is 72.69865333063518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.86149662376469 and perplexity of 129.2174473661251
Finished 34 epochs...
Completing Train Step...
At time: 411.58245944976807 and batch: 50, loss is 4.474038786888123 and perplexity is 87.71025163375802
At time: 411.98394417762756 and batch: 100, loss is 4.467811145782471 and perplexity is 87.16572099588821
At time: 412.3620693683624 and batch: 150, loss is 4.357735290527343 and perplexity is 78.08010528490028
At time: 412.74074387550354 and batch: 200, loss is 4.406773681640625 and perplexity is 82.00446374035187
At time: 413.1190550327301 and batch: 250, loss is 4.450395913124084 and perplexity is 85.66085154488394
At time: 413.4973418712616 and batch: 300, loss is 4.456418857574463 and perplexity is 86.17833892984024
At time: 413.8759970664978 and batch: 350, loss is 4.467449016571045 and perplexity is 87.13416145674103
At time: 414.2547414302826 and batch: 400, loss is 4.339044189453125 and perplexity is 76.63425649100948
At time: 414.63322353363037 and batch: 450, loss is 4.391668243408203 and perplexity is 80.77505910289858
At time: 415.0108411312103 and batch: 500, loss is 4.379392910003662 and perplexity is 79.78957924318365
At time: 415.389443397522 and batch: 550, loss is 4.425182552337646 and perplexity is 83.52805407185468
At time: 415.76864409446716 and batch: 600, loss is 4.340676393508911 and perplexity is 76.7594413711088
At time: 416.1472518444061 and batch: 650, loss is 4.431217699050904 and perplexity is 84.03368236862072
At time: 416.52537631988525 and batch: 700, loss is 4.46297776222229 and perplexity is 86.74543215980869
At time: 416.90416741371155 and batch: 750, loss is 4.413592529296875 and perplexity is 82.56555049422369
At time: 417.2827208042145 and batch: 800, loss is 4.367766523361206 and perplexity is 78.86728659935582
At time: 417.661244392395 and batch: 850, loss is 4.324695205688476 and perplexity is 75.54248443090492
At time: 418.0403938293457 and batch: 900, loss is 4.27250159740448 and perplexity is 71.7007779348017
At time: 418.4197790622711 and batch: 950, loss is 4.346926345825195 and perplexity is 77.24068653263046
At time: 418.79858922958374 and batch: 1000, loss is 4.40292275428772 and perplexity is 81.68927777650632
At time: 419.1775414943695 and batch: 1050, loss is 4.316183671951294 and perplexity is 74.9022306621822
At time: 419.5560302734375 and batch: 1100, loss is 4.434410953521729 and perplexity is 84.30245219738859
At time: 419.9477701187134 and batch: 1150, loss is 4.355889883041382 and perplexity is 77.93614854438022
At time: 420.32637310028076 and batch: 1200, loss is 4.33737009525299 and perplexity is 76.50607085403963
At time: 420.72428035736084 and batch: 1250, loss is 4.3079329681396485 and perplexity is 74.28677699647766
At time: 421.11538434028625 and batch: 1300, loss is 4.36230393409729 and perplexity is 78.43764156186772
At time: 421.49475026130676 and batch: 1350, loss is 4.318033227920532 and perplexity is 75.04089472395509
At time: 421.8758728504181 and batch: 1400, loss is 4.200908851623535 and perplexity is 66.74696657133563
At time: 422.27427911758423 and batch: 1450, loss is 4.286357555389404 and perplexity is 72.70117563029541
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861487233740652 and perplexity of 129.21623401688487
Finished 35 epochs...
Completing Train Step...
At time: 423.54638719558716 and batch: 50, loss is 4.473879957199097 and perplexity is 87.69632174803566
At time: 423.9321548938751 and batch: 100, loss is 4.467714366912841 and perplexity is 87.15728560413022
At time: 424.31072521209717 and batch: 150, loss is 4.357666091918945 and perplexity is 78.07470243720792
At time: 424.6898503303528 and batch: 200, loss is 4.406666040420532 and perplexity is 81.99563715488253
At time: 425.0687770843506 and batch: 250, loss is 4.450299973487854 and perplexity is 85.65263366816392
At time: 425.448086977005 and batch: 300, loss is 4.456302690505981 and perplexity is 86.1683284262968
At time: 425.8271186351776 and batch: 350, loss is 4.46737738609314 and perplexity is 87.12792021864809
At time: 426.20597434043884 and batch: 400, loss is 4.338954591751099 and perplexity is 76.62739054532251
At time: 426.5850510597229 and batch: 450, loss is 4.391570072174073 and perplexity is 80.76712970488526
At time: 426.9639525413513 and batch: 500, loss is 4.3792854690551755 and perplexity is 79.78100703562173
At time: 427.34305691719055 and batch: 550, loss is 4.425098886489868 and perplexity is 83.52106591873648
At time: 427.7220332622528 and batch: 600, loss is 4.340593852996826 and perplexity is 76.75310586898208
At time: 428.1005244255066 and batch: 650, loss is 4.43116003036499 and perplexity is 84.0288363963178
At time: 428.4797217845917 and batch: 700, loss is 4.462897758483887 and perplexity is 86.73849247855044
At time: 428.85887265205383 and batch: 750, loss is 4.41350923538208 and perplexity is 82.55867357270267
At time: 429.23710346221924 and batch: 800, loss is 4.367702169418335 and perplexity is 78.86221134180775
At time: 429.6279413700104 and batch: 850, loss is 4.32465313911438 and perplexity is 75.53930668422512
At time: 430.027991771698 and batch: 900, loss is 4.2724799633026125 and perplexity is 71.699226769647
At time: 430.4187641143799 and batch: 950, loss is 4.346874675750732 and perplexity is 77.23669560371248
At time: 430.7973806858063 and batch: 1000, loss is 4.402887392044067 and perplexity is 81.68638911143694
At time: 431.1777503490448 and batch: 1050, loss is 4.3162040567398074 and perplexity is 74.90375754387595
At time: 431.5568130016327 and batch: 1100, loss is 4.434408645629883 and perplexity is 84.30225763667111
At time: 431.93642950057983 and batch: 1150, loss is 4.355873184204102 and perplexity is 77.93484711218368
At time: 432.3354284763336 and batch: 1200, loss is 4.3373923587799075 and perplexity is 76.50777416796824
At time: 432.7360792160034 and batch: 1250, loss is 4.3080115270614625 and perplexity is 74.29261311482011
At time: 433.12442564964294 and batch: 1300, loss is 4.362324829101563 and perplexity is 78.4392805338464
At time: 433.5030472278595 and batch: 1350, loss is 4.3180576610565184 and perplexity is 75.0427282307395
At time: 433.9013862609863 and batch: 1400, loss is 4.200955195426941 and perplexity is 66.75005995131127
At time: 434.28783679008484 and batch: 1450, loss is 4.28638557434082 and perplexity is 72.70321266954099
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861479930388621 and perplexity of 129.21529030868587
Finished 36 epochs...
Completing Train Step...
At time: 435.54631304740906 and batch: 50, loss is 4.473729567527771 and perplexity is 87.68313411869795
At time: 435.9437048435211 and batch: 100, loss is 4.467629528045654 and perplexity is 87.14989159240666
At time: 436.3378405570984 and batch: 150, loss is 4.357600603103638 and perplexity is 78.06958958485897
At time: 436.7179174423218 and batch: 200, loss is 4.40656343460083 and perplexity is 81.98722435692865
At time: 437.10845971107483 and batch: 250, loss is 4.450212144851685 and perplexity is 85.64511124451148
At time: 437.5101263523102 and batch: 300, loss is 4.456192169189453 and perplexity is 86.15880551544812
At time: 437.90452456474304 and batch: 350, loss is 4.467309503555298 and perplexity is 87.12200595504667
At time: 438.28696060180664 and batch: 400, loss is 4.338870944976807 and perplexity is 76.62098117934612
At time: 438.68279910087585 and batch: 450, loss is 4.39147759437561 and perplexity is 80.7596608838974
At time: 439.0766236782074 and batch: 500, loss is 4.379181880950927 and perplexity is 79.77274310037798
At time: 439.4796109199524 and batch: 550, loss is 4.425017461776734 and perplexity is 83.5142655167675
At time: 439.88842129707336 and batch: 600, loss is 4.340513763427734 and perplexity is 76.7469589919602
At time: 440.2709581851959 and batch: 650, loss is 4.431104335784912 and perplexity is 84.02415657588183
At time: 440.65215516090393 and batch: 700, loss is 4.46282054901123 and perplexity is 86.73179570381764
At time: 441.05052042007446 and batch: 750, loss is 4.413430624008178 and perplexity is 82.55218377703481
At time: 441.4425354003906 and batch: 800, loss is 4.367639498710632 and perplexity is 78.85726914607905
At time: 441.83137559890747 and batch: 850, loss is 4.32460883140564 and perplexity is 75.5359597847734
At time: 442.2357680797577 and batch: 900, loss is 4.272456507682801 and perplexity is 71.69754503956618
At time: 442.6242334842682 and batch: 950, loss is 4.346820855140686 and perplexity is 77.23253878949929
At time: 443.0171146392822 and batch: 1000, loss is 4.402853236198426 and perplexity is 81.68359909138744
At time: 443.41351103782654 and batch: 1050, loss is 4.31621949672699 and perplexity is 74.90491406586064
At time: 443.80857968330383 and batch: 1100, loss is 4.434402370452881 and perplexity is 84.30172862674259
At time: 444.18955636024475 and batch: 1150, loss is 4.35585389137268 and perplexity is 77.9333435428206
At time: 444.57097721099854 and batch: 1200, loss is 4.337411012649536 and perplexity is 76.5092013473243
At time: 444.9768614768982 and batch: 1250, loss is 4.308084392547608 and perplexity is 74.29802667942035
At time: 445.38759779930115 and batch: 1300, loss is 4.362342758178711 and perplexity is 78.44068689036584
At time: 445.7719795703888 and batch: 1350, loss is 4.318079977035523 and perplexity is 75.044402901373
At time: 446.16776847839355 and batch: 1400, loss is 4.2009951877594 and perplexity is 66.75272949528079
At time: 446.56064915657043 and batch: 1450, loss is 4.2864087867736815 and perplexity is 72.7049003075709
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861473148704594 and perplexity of 129.21441401438682
Finished 37 epochs...
Completing Train Step...
At time: 447.8413989543915 and batch: 50, loss is 4.473585729598999 and perplexity is 87.67052286530809
At time: 448.23609232902527 and batch: 100, loss is 4.467552165985108 and perplexity is 87.14314975800116
At time: 448.61824226379395 and batch: 150, loss is 4.357537870407104 and perplexity is 78.06469222260102
At time: 449.00994181632996 and batch: 200, loss is 4.4064649486541745 and perplexity is 81.97915016512792
At time: 449.3927426338196 and batch: 250, loss is 4.45013011932373 and perplexity is 85.6380864471552
At time: 449.7861511707306 and batch: 300, loss is 4.4560853099823 and perplexity is 86.14959914570294
At time: 450.1672410964966 and batch: 350, loss is 4.467244415283203 and perplexity is 87.11633551875907
At time: 450.54724884033203 and batch: 400, loss is 4.338791341781616 and perplexity is 76.61488214718001
At time: 450.9450898170471 and batch: 450, loss is 4.391389093399048 and perplexity is 80.7525138913049
At time: 451.34843254089355 and batch: 500, loss is 4.379081163406372 and perplexity is 79.7647089901652
At time: 451.7492094039917 and batch: 550, loss is 4.42493763923645 and perplexity is 83.5075994619983
At time: 452.13104796409607 and batch: 600, loss is 4.340435352325439 and perplexity is 76.7409414142334
At time: 452.51106452941895 and batch: 650, loss is 4.4310495567321775 and perplexity is 84.01955393824298
At time: 452.89799642562866 and batch: 700, loss is 4.462745227813721 and perplexity is 86.72526320712393
At time: 453.3001823425293 and batch: 750, loss is 4.413355283737182 and perplexity is 82.5459645074214
At time: 453.69126439094543 and batch: 800, loss is 4.367577714920044 and perplexity is 78.85239719558108
At time: 454.0809051990509 and batch: 850, loss is 4.324562783241272 and perplexity is 75.5324815725648
At time: 454.4657943248749 and batch: 900, loss is 4.272431483268738 and perplexity is 71.6957508729609
At time: 454.84576964378357 and batch: 950, loss is 4.346765432357788 and perplexity is 77.2282584658841
At time: 455.2252449989319 and batch: 1000, loss is 4.402819671630859 and perplexity is 81.68085746271774
At time: 455.60519194602966 and batch: 1050, loss is 4.316230273246765 and perplexity is 74.90572128449783
At time: 455.99062728881836 and batch: 1100, loss is 4.434393005371094 and perplexity is 84.300939137856
At time: 456.3847894668579 and batch: 1150, loss is 4.355832786560058 and perplexity is 77.93169879156426
At time: 456.77866101264954 and batch: 1200, loss is 4.337428126335144 and perplexity is 76.51051071294629
At time: 457.1755270957947 and batch: 1250, loss is 4.308152737617493 and perplexity is 74.30310475677489
At time: 457.56712436676025 and batch: 1300, loss is 4.362358436584473 and perplexity is 78.44191672492406
At time: 457.9632167816162 and batch: 1350, loss is 4.318100090026856 and perplexity is 75.04591228397719
At time: 458.3535645008087 and batch: 1400, loss is 4.201029577255249 and perplexity is 66.75502512746728
At time: 458.7440061569214 and batch: 1450, loss is 4.2864278793334964 and perplexity is 72.70628844348035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861467932024572 and perplexity of 129.213739945893
Finished 38 epochs...
Completing Train Step...
At time: 459.99940299987793 and batch: 50, loss is 4.473446912765503 and perplexity is 87.65835356560439
At time: 460.4201545715332 and batch: 100, loss is 4.467479801177978 and perplexity is 87.1368438889405
At time: 460.8246681690216 and batch: 150, loss is 4.357477645874024 and perplexity is 78.0599909545291
At time: 461.21711349487305 and batch: 200, loss is 4.406369667053223 and perplexity is 81.97133943257101
At time: 461.6045928001404 and batch: 250, loss is 4.450052671432495 and perplexity is 85.63145421477996
At time: 461.9944784641266 and batch: 300, loss is 4.455982007980347 and perplexity is 86.14070017929212
At time: 462.37949895858765 and batch: 350, loss is 4.467181196212769 and perplexity is 87.11082827909104
At time: 462.7785270214081 and batch: 400, loss is 4.338714866638184 and perplexity is 76.60902323711211
At time: 463.19312477111816 and batch: 450, loss is 4.39130352973938 and perplexity is 80.74560470628079
At time: 463.5857608318329 and batch: 500, loss is 4.378982381820679 and perplexity is 79.75683009488007
At time: 463.9719898700714 and batch: 550, loss is 4.4248593807220455 and perplexity is 83.50106453703299
At time: 464.36445808410645 and batch: 600, loss is 4.340358304977417 and perplexity is 76.73502895598523
At time: 464.76308250427246 and batch: 650, loss is 4.430995712280273 and perplexity is 84.01503007320554
At time: 465.15515637397766 and batch: 700, loss is 4.4626709079742435 and perplexity is 86.71881803898864
At time: 465.53614020347595 and batch: 750, loss is 4.4132825756073 and perplexity is 82.53996296289594
At time: 465.9161171913147 and batch: 800, loss is 4.367516574859619 and perplexity is 78.84757630262821
At time: 466.2961413860321 and batch: 850, loss is 4.3245158290863035 and perplexity is 75.52893509198154
At time: 466.69690585136414 and batch: 900, loss is 4.272405643463134 and perplexity is 71.69389829263099
At time: 467.09651136398315 and batch: 950, loss is 4.346709170341492 and perplexity is 77.22391357057518
At time: 467.4963393211365 and batch: 1000, loss is 4.402786412239075 and perplexity is 81.67814085225473
At time: 467.88913130760193 and batch: 1050, loss is 4.316237540245056 and perplexity is 74.90626562622427
At time: 468.2699956893921 and batch: 1100, loss is 4.434381704330445 and perplexity is 84.29998645489921
At time: 468.64862728118896 and batch: 1150, loss is 4.355810270309449 and perplexity is 77.92994408165865
At time: 469.03205370903015 and batch: 1200, loss is 4.337444829940796 and perplexity is 76.51178872501912
At time: 469.44364619255066 and batch: 1250, loss is 4.308217673301697 and perplexity is 74.30792983637897
At time: 469.84561824798584 and batch: 1300, loss is 4.362372512817383 and perplexity is 78.44302089938508
At time: 470.2387101650238 and batch: 1350, loss is 4.318118114471435 and perplexity is 75.04726495705462
At time: 470.63377809524536 and batch: 1400, loss is 4.201059188842773 and perplexity is 66.75700187900375
At time: 471.0411858558655 and batch: 1450, loss is 4.286443614959717 and perplexity is 72.70743253146064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861462715344551 and perplexity of 129.21306588091554
Finished 39 epochs...
Completing Train Step...
At time: 472.31050872802734 and batch: 50, loss is 4.4733126354217525 and perplexity is 87.64658382495247
At time: 472.6902241706848 and batch: 100, loss is 4.467411012649536 and perplexity is 87.13085007983129
At time: 473.07132720947266 and batch: 150, loss is 4.357419691085815 and perplexity is 78.05546713537554
At time: 473.4513533115387 and batch: 200, loss is 4.406276750564575 and perplexity is 81.96372329737892
At time: 473.83139204978943 and batch: 250, loss is 4.449979095458985 and perplexity is 85.62515402894701
At time: 474.2107033729553 and batch: 300, loss is 4.455881595611572 and perplexity is 86.1320510217877
At time: 474.59033489227295 and batch: 350, loss is 4.467119426727295 and perplexity is 87.10544765422993
At time: 474.9704146385193 and batch: 400, loss is 4.338640985488891 and perplexity is 76.6033634835063
At time: 475.35054779052734 and batch: 450, loss is 4.391220149993896 and perplexity is 80.7388724389827
At time: 475.7309937477112 and batch: 500, loss is 4.3788853931427 and perplexity is 79.74909496048569
At time: 476.11197090148926 and batch: 550, loss is 4.42478271484375 and perplexity is 83.49466309997068
At time: 476.50325775146484 and batch: 600, loss is 4.34028244972229 and perplexity is 76.72920842154845
At time: 476.90707874298096 and batch: 650, loss is 4.430942945480346 and perplexity is 84.01059698588377
At time: 477.30187010765076 and batch: 700, loss is 4.462597370147705 and perplexity is 86.71244116006386
At time: 477.6997563838959 and batch: 750, loss is 4.4132117176055905 and perplexity is 82.53411455326496
At time: 478.0955853462219 and batch: 800, loss is 4.3674560022354125 and perplexity is 78.84280044266391
At time: 478.49464106559753 and batch: 850, loss is 4.324468574523926 and perplexity is 75.52536608953339
At time: 478.8810226917267 and batch: 900, loss is 4.272378873825073 and perplexity is 71.6919790986107
At time: 479.2737123966217 and batch: 950, loss is 4.34665198802948 and perplexity is 77.21949785490624
At time: 479.6536042690277 and batch: 1000, loss is 4.402753210067749 and perplexity is 81.67542900564841
At time: 480.03336238861084 and batch: 1050, loss is 4.316241774559021 and perplexity is 74.9065828035424
At time: 480.4137394428253 and batch: 1100, loss is 4.434367809295654 and perplexity is 84.29881511179255
At time: 480.79729080200195 and batch: 1150, loss is 4.355786762237549 and perplexity is 77.92811212046306
At time: 481.19696259498596 and batch: 1200, loss is 4.337461519241333 and perplexity is 76.51306566391136
At time: 481.5771691799164 and batch: 1250, loss is 4.308279738426209 and perplexity is 74.31254191041948
At time: 481.9780089855194 and batch: 1300, loss is 4.362385301589966 and perplexity is 78.4440240957549
At time: 482.3680188655853 and batch: 1350, loss is 4.318134021759033 and perplexity is 75.04845876497686
At time: 482.74824023246765 and batch: 1400, loss is 4.2010845279693605 and perplexity is 66.75869346455652
At time: 483.12863993644714 and batch: 1450, loss is 4.286456651687622 and perplexity is 72.7083804046538
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861458542000534 and perplexity of 129.21252663146535
Finished 40 epochs...
Completing Train Step...
At time: 484.37949323654175 and batch: 50, loss is 4.473182148933411 and perplexity is 87.63514787614865
At time: 484.75900292396545 and batch: 100, loss is 4.467345094680786 and perplexity is 87.12510678047396
At time: 485.13745284080505 and batch: 150, loss is 4.357363862991333 and perplexity is 78.05110956901987
At time: 485.5187108516693 and batch: 200, loss is 4.406186428070068 and perplexity is 81.95632046375786
At time: 485.9190528392792 and batch: 250, loss is 4.449909148216247 and perplexity is 85.61916499497437
At time: 486.3066596984863 and batch: 300, loss is 4.455784072875977 and perplexity is 86.12365159812366
At time: 486.7038724422455 and batch: 350, loss is 4.467058906555176 and perplexity is 87.10017617706235
At time: 487.09335255622864 and batch: 400, loss is 4.338569183349609 and perplexity is 76.59786339559336
At time: 487.4719569683075 and batch: 450, loss is 4.391139125823974 and perplexity is 80.73233090387771
At time: 487.8512234687805 and batch: 500, loss is 4.3787898921966555 and perplexity is 79.74147921013224
At time: 488.2300148010254 and batch: 550, loss is 4.424707412719727 and perplexity is 83.48837601121316
At time: 488.6098771095276 and batch: 600, loss is 4.340207557678223 and perplexity is 76.72346222946486
At time: 488.98749351501465 and batch: 650, loss is 4.430891075134277 and perplexity is 84.00623944015932
At time: 489.37743735313416 and batch: 700, loss is 4.462524299621582 and perplexity is 86.70610526785318
At time: 489.7544174194336 and batch: 750, loss is 4.4131427669525145 and perplexity is 82.52842396835248
At time: 490.13152837753296 and batch: 800, loss is 4.3673951530456545 and perplexity is 78.83800306809837
At time: 490.5089943408966 and batch: 850, loss is 4.324421401023865 and perplexity is 75.52180337770503
At time: 490.8856511116028 and batch: 900, loss is 4.272351016998291 and perplexity is 71.68998201538362
At time: 491.2620677947998 and batch: 950, loss is 4.3465937852859495 and perplexity is 77.2150035990673
At time: 491.639146566391 and batch: 1000, loss is 4.402719674110412 and perplexity is 81.67268998787388
At time: 492.03979110717773 and batch: 1050, loss is 4.3162434911727905 and perplexity is 74.90671138932422
At time: 492.4257972240448 and batch: 1100, loss is 4.434351749420166 and perplexity is 84.29746129418916
At time: 492.8033995628357 and batch: 1150, loss is 4.35576265335083 and perplexity is 77.92623338308293
At time: 493.18099093437195 and batch: 1200, loss is 4.337478909492493 and perplexity is 76.51439625690992
At time: 493.5591404438019 and batch: 1250, loss is 4.308339543342591 and perplexity is 74.31698629867137
At time: 493.93625569343567 and batch: 1300, loss is 4.362397317886352 and perplexity is 78.44496670806151
At time: 494.31343722343445 and batch: 1350, loss is 4.318147964477539 and perplexity is 75.04950515180646
At time: 494.6931297779083 and batch: 1400, loss is 4.201105923652649 and perplexity is 66.76012182769895
At time: 495.0714876651764 and batch: 1450, loss is 4.2864670562744145 and perplexity is 72.7091369092438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861453325320513 and perplexity of 129.21185257281735
Finished 41 epochs...
Completing Train Step...
At time: 496.3174111843109 and batch: 50, loss is 4.4730548000335695 and perplexity is 87.62398834707113
At time: 496.72955346107483 and batch: 100, loss is 4.467281188964844 and perplexity is 87.1195391660517
At time: 497.1217439174652 and batch: 150, loss is 4.357309846878052 and perplexity is 78.04689366530809
At time: 497.51426887512207 and batch: 200, loss is 4.406099691390991 and perplexity is 81.94921215297153
At time: 497.90809655189514 and batch: 250, loss is 4.449841990470886 and perplexity is 85.61341519796746
At time: 498.3049430847168 and batch: 300, loss is 4.455689096450806 and perplexity is 86.11547227000003
At time: 498.6984374523163 and batch: 350, loss is 4.466999053955078 and perplexity is 87.09496316105705
At time: 499.09276247024536 and batch: 400, loss is 4.338499507904053 and perplexity is 76.59252659125688
At time: 499.4707622528076 and batch: 450, loss is 4.3910595703125 and perplexity is 80.725908457474
At time: 499.84969878196716 and batch: 500, loss is 4.378695726394653 and perplexity is 79.73397064332023
At time: 500.2280282974243 and batch: 550, loss is 4.424633312225342 and perplexity is 83.48218971048215
At time: 500.60636138916016 and batch: 600, loss is 4.340134010314942 and perplexity is 76.71781962861782
At time: 500.9847159385681 and batch: 650, loss is 4.430839748382568 and perplexity is 84.00192778341817
At time: 501.36301732063293 and batch: 700, loss is 4.462451286315918 and perplexity is 86.69977479959337
At time: 501.74066138267517 and batch: 750, loss is 4.413075342178344 and perplexity is 82.52285969559082
At time: 502.1194031238556 and batch: 800, loss is 4.367334189414978 and perplexity is 78.83319696369637
At time: 502.5063772201538 and batch: 850, loss is 4.324374814033508 and perplexity is 75.51828512613234
At time: 502.90335273742676 and batch: 900, loss is 4.272322068214416 and perplexity is 71.68790670762722
At time: 503.2967255115509 and batch: 950, loss is 4.346534404754639 and perplexity is 77.21041866725763
At time: 503.68642830848694 and batch: 1000, loss is 4.402685837745667 and perplexity is 81.66992652769868
At time: 504.0649938583374 and batch: 1050, loss is 4.3162429141998295 and perplexity is 74.90666817018962
At time: 504.4434976577759 and batch: 1100, loss is 4.434333162307739 and perplexity is 84.29589446236025
At time: 504.8360798358917 and batch: 1150, loss is 4.355737619400024 and perplexity is 77.92428260600788
At time: 505.2299110889435 and batch: 1200, loss is 4.3374970293045045 and perplexity is 76.51578269594725
At time: 505.6121401786804 and batch: 1250, loss is 4.308397765159607 and perplexity is 74.32131329461042
At time: 505.9897999763489 and batch: 1300, loss is 4.362408618927002 and perplexity is 78.44585322282833
At time: 506.3796582221985 and batch: 1350, loss is 4.318159990310669 and perplexity is 75.05040769005872
At time: 506.77354621887207 and batch: 1400, loss is 4.2011233949661255 and perplexity is 66.76128822490438
At time: 507.15636563301086 and batch: 1450, loss is 4.286475419998169 and perplexity is 72.7097450309224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861449151976496 and perplexity of 129.2113133284307
Finished 42 epochs...
Completing Train Step...
At time: 508.403781414032 and batch: 50, loss is 4.472930169105529 and perplexity is 87.61306836858253
At time: 508.7961618900299 and batch: 100, loss is 4.467218961715698 and perplexity is 87.11411812545255
At time: 509.17477917671204 and batch: 150, loss is 4.357256784439087 and perplexity is 78.04275241664988
At time: 509.5525629520416 and batch: 200, loss is 4.406016540527344 and perplexity is 81.9423982884991
At time: 509.93106865882874 and batch: 250, loss is 4.449777646064758 and perplexity is 85.60790663083462
At time: 510.3122658729553 and batch: 300, loss is 4.455596046447754 and perplexity is 86.10745959783785
At time: 510.69108033180237 and batch: 350, loss is 4.466939907073975 and perplexity is 87.08981191796776
At time: 511.069363117218 and batch: 400, loss is 4.338430795669556 and perplexity is 76.58726392841578
At time: 511.44885420799255 and batch: 450, loss is 4.390981645584106 and perplexity is 80.71961815807126
At time: 511.82780599594116 and batch: 500, loss is 4.378602790832519 and perplexity is 79.72656086625855
At time: 512.2156882286072 and batch: 550, loss is 4.424560012817383 and perplexity is 83.4760707396625
At time: 512.6098935604095 and batch: 600, loss is 4.340061435699463 and perplexity is 76.71225206439223
At time: 512.9916729927063 and batch: 650, loss is 4.430788717269897 and perplexity is 83.99764118095287
At time: 513.3699901103973 and batch: 700, loss is 4.462377729415894 and perplexity is 86.69339766747022
At time: 513.7488782405853 and batch: 750, loss is 4.413009061813354 and perplexity is 82.51739023159121
At time: 514.1269392967224 and batch: 800, loss is 4.367272558212281 and perplexity is 78.82833852867212
At time: 514.5051443576813 and batch: 850, loss is 4.324327931404114 and perplexity is 75.5147447133509
At time: 514.88822889328 and batch: 900, loss is 4.272291307449341 and perplexity is 71.6857015666863
At time: 515.2717859745026 and batch: 950, loss is 4.346474027633667 and perplexity is 77.20575706519791
At time: 515.650758266449 and batch: 1000, loss is 4.402651224136353 and perplexity is 81.66709968569305
At time: 516.0301208496094 and batch: 1050, loss is 4.316239991188049 and perplexity is 74.90644921743615
At time: 516.4287118911743 and batch: 1100, loss is 4.434311895370484 and perplexity is 84.29410176592447
At time: 516.8184549808502 and batch: 1150, loss is 4.3557118225097655 and perplexity is 77.9222724277693
At time: 517.1968533992767 and batch: 1200, loss is 4.3375164270401 and perplexity is 76.51726694326435
At time: 517.5757505893707 and batch: 1250, loss is 4.308454365730285 and perplexity is 74.32552004240749
At time: 517.9547107219696 and batch: 1300, loss is 4.36241907119751 and perplexity is 78.44667316439156
At time: 518.3333568572998 and batch: 1350, loss is 4.318170156478882 and perplexity is 75.05117066900603
At time: 518.7266979217529 and batch: 1400, loss is 4.201136674880981 and perplexity is 66.76217481501457
At time: 519.1204726696014 and batch: 1450, loss is 4.286481313705444 and perplexity is 72.71017356213848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861443413628472 and perplexity of 129.21057187107363
Finished 43 epochs...
Completing Train Step...
At time: 520.3708465099335 and batch: 50, loss is 4.4728077793121335 and perplexity is 87.60234607940887
At time: 520.750962972641 and batch: 100, loss is 4.467157936096191 and perplexity is 87.10880209463481
At time: 521.1481726169586 and batch: 150, loss is 4.357204818725586 and perplexity is 78.0386969747099
At time: 521.5427873134613 and batch: 200, loss is 4.405935907363892 and perplexity is 81.93579128007984
At time: 521.9237990379333 and batch: 250, loss is 4.4497158908843994 and perplexity is 85.60262006235867
At time: 522.304783821106 and batch: 300, loss is 4.455505027770996 and perplexity is 86.09962256746972
At time: 522.685432434082 and batch: 350, loss is 4.466881198883057 and perplexity is 87.08469918274382
At time: 523.0769467353821 and batch: 400, loss is 4.338363151550293 and perplexity is 76.58208342561787
At time: 523.4715745449066 and batch: 450, loss is 4.390905036926269 and perplexity is 80.71343457332415
At time: 523.8687760829926 and batch: 500, loss is 4.378511056900025 and perplexity is 79.71924757074983
At time: 524.2623443603516 and batch: 550, loss is 4.424486932754516 and perplexity is 83.46997052606967
At time: 524.6426351070404 and batch: 600, loss is 4.339989929199219 and perplexity is 76.70676683583838
At time: 525.0236759185791 and batch: 650, loss is 4.430737199783326 and perplexity is 83.99331394506638
At time: 525.4157938957214 and batch: 700, loss is 4.462302894592285 and perplexity is 86.68691022509404
At time: 525.8101353645325 and batch: 750, loss is 4.4129434299469 and perplexity is 82.51197463897502
At time: 526.1930406093597 and batch: 800, loss is 4.367210493087769 and perplexity is 78.82344618984966
At time: 526.5736374855042 and batch: 850, loss is 4.3242808532714845 and perplexity is 75.51118970386605
At time: 526.9686970710754 and batch: 900, loss is 4.272258715629578 and perplexity is 71.68336523729408
At time: 527.363653421402 and batch: 950, loss is 4.346413178443909 and perplexity is 77.20105930036489
At time: 527.7640845775604 and batch: 1000, loss is 4.402615799903869 and perplexity is 81.66420674260799
At time: 528.1520175933838 and batch: 1050, loss is 4.3162339353561405 and perplexity is 74.90599559794433
At time: 528.546560049057 and batch: 1100, loss is 4.4342879295349125 and perplexity is 84.29208161154936
At time: 528.942314863205 and batch: 1150, loss is 4.355684957504272 and perplexity is 77.9201790736116
At time: 529.3371877670288 and batch: 1200, loss is 4.337537240982056 and perplexity is 76.51885958579165
At time: 529.7254717350006 and batch: 1250, loss is 4.308509011268615 and perplexity is 74.3295817114369
At time: 530.1249260902405 and batch: 1300, loss is 4.362427921295166 and perplexity is 78.44736742818196
At time: 530.5215363502502 and batch: 1350, loss is 4.318179035186768 and perplexity is 75.05183702938513
At time: 530.9053308963776 and batch: 1400, loss is 4.201145892143249 and perplexity is 66.76279018232543
At time: 531.2965755462646 and batch: 1450, loss is 4.286485071182251 and perplexity is 72.71044676944256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861438718616453 and perplexity of 129.2099652273098
Finished 44 epochs...
Completing Train Step...
At time: 532.5695757865906 and batch: 50, loss is 4.472686858177185 and perplexity is 87.59175374472827
At time: 532.9480886459351 and batch: 100, loss is 4.467097578048706 and perplexity is 87.10354453609118
At time: 533.3273801803589 and batch: 150, loss is 4.357153835296631 and perplexity is 78.0347183957686
At time: 533.7063467502594 and batch: 200, loss is 4.40585765838623 and perplexity is 81.92938013901414
At time: 534.0849416255951 and batch: 250, loss is 4.449656848907471 and perplexity is 85.5975660636404
At time: 534.4638528823853 and batch: 300, loss is 4.455415840148926 and perplexity is 86.09194388929842
At time: 534.8424682617188 and batch: 350, loss is 4.466823101043701 and perplexity is 87.0796398968486
At time: 535.2209651470184 and batch: 400, loss is 4.338295421600342 and perplexity is 76.57689670059055
At time: 535.5982627868652 and batch: 450, loss is 4.390829734802246 and perplexity is 80.70735690909693
At time: 535.9766583442688 and batch: 500, loss is 4.378420581817627 and perplexity is 79.71203529152788
At time: 536.3542609214783 and batch: 550, loss is 4.424413681030273 and perplexity is 83.4638564307429
At time: 536.7329721450806 and batch: 600, loss is 4.339919385910034 and perplexity is 76.70135587905861
At time: 537.1103436946869 and batch: 650, loss is 4.430684900283813 and perplexity is 83.9889212516535
At time: 537.4877796173096 and batch: 700, loss is 4.46222635269165 and perplexity is 86.68027529815346
At time: 537.8652718067169 and batch: 750, loss is 4.412878036499023 and perplexity is 82.50657907288156
At time: 538.256049156189 and batch: 800, loss is 4.36714852809906 and perplexity is 78.81856204722098
At time: 538.6337413787842 and batch: 850, loss is 4.3242333889007565 and perplexity is 75.5076056978208
At time: 539.0111689567566 and batch: 900, loss is 4.27222496509552 and perplexity is 71.68094592626105
At time: 539.3901386260986 and batch: 950, loss is 4.346354079246521 and perplexity is 77.19649691454077
At time: 539.768739938736 and batch: 1000, loss is 4.4025797843933105 and perplexity is 81.66126561747114
At time: 540.1469700336456 and batch: 1050, loss is 4.31622483253479 and perplexity is 74.90531374515169
At time: 540.5251376628876 and batch: 1100, loss is 4.4342623138427735 and perplexity is 84.28992243919151
At time: 540.9028520584106 and batch: 1150, loss is 4.355657348632812 and perplexity is 77.91802781510046
At time: 541.2809357643127 and batch: 1200, loss is 4.3375581979751585 and perplexity is 76.5204632078077
At time: 541.6580743789673 and batch: 1250, loss is 4.308561058044433 and perplexity is 74.33345042718909
At time: 542.0369520187378 and batch: 1300, loss is 4.362435035705566 and perplexity is 78.44792553693398
At time: 542.4173049926758 and batch: 1350, loss is 4.3181871318817135 and perplexity is 75.05244470367474
At time: 542.7952241897583 and batch: 1400, loss is 4.201152400970459 and perplexity is 66.76322473120496
At time: 543.1743016242981 and batch: 1450, loss is 4.286486139297486 and perplexity is 72.71052443261993
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861433501936432 and perplexity of 129.20929118202378
Finished 45 epochs...
Completing Train Step...
At time: 544.4021747112274 and batch: 50, loss is 4.472567472457886 and perplexity is 87.58129716439839
At time: 544.7924468517303 and batch: 100, loss is 4.4670380687713624 and perplexity is 87.09836122133099
At time: 545.1706643104553 and batch: 150, loss is 4.357104005813599 and perplexity is 78.03083006296998
At time: 545.54922914505 and batch: 200, loss is 4.40578125 and perplexity is 81.9231202864486
At time: 545.928023815155 and batch: 250, loss is 4.449600238800048 and perplexity is 85.59272051338532
At time: 546.3060953617096 and batch: 300, loss is 4.455329122543335 and perplexity is 86.08447852575762
At time: 546.6831912994385 and batch: 350, loss is 4.466765060424804 and perplexity is 87.07458588732601
At time: 547.0612559318542 and batch: 400, loss is 4.338227233886719 and perplexity is 76.57167527510875
At time: 547.4392518997192 and batch: 450, loss is 4.390755758285523 and perplexity is 80.70138668078995
At time: 547.8301131725311 and batch: 500, loss is 4.378331279754638 and perplexity is 79.70491716016795
At time: 548.2083370685577 and batch: 550, loss is 4.42434024810791 and perplexity is 83.45772766088297
At time: 548.5860431194305 and batch: 600, loss is 4.339850482940673 and perplexity is 76.69607110995481
At time: 548.9639554023743 and batch: 650, loss is 4.430632705688477 and perplexity is 83.98453759829852
At time: 549.3424551486969 and batch: 700, loss is 4.46214937210083 and perplexity is 86.67360285617613
At time: 549.7209575176239 and batch: 750, loss is 4.412812747955322 and perplexity is 82.50119251433033
At time: 550.0997829437256 and batch: 800, loss is 4.367087612152099 and perplexity is 78.81376088611094
At time: 550.4783051013947 and batch: 850, loss is 4.324186282157898 and perplexity is 75.50404886423141
At time: 550.8566517829895 and batch: 900, loss is 4.2721910429000856 and perplexity is 71.6785143924461
At time: 551.2352650165558 and batch: 950, loss is 4.346298007965088 and perplexity is 77.19216852938682
At time: 551.6138489246368 and batch: 1000, loss is 4.402543268203735 and perplexity is 81.65828371365913
At time: 551.9928147792816 and batch: 1050, loss is 4.3162144184112545 and perplexity is 74.90453367602278
At time: 552.3719425201416 and batch: 1100, loss is 4.434237461090088 and perplexity is 84.28782762862629
At time: 552.7526807785034 and batch: 1150, loss is 4.355628871917725 and perplexity is 77.91580899721467
At time: 553.1300117969513 and batch: 1200, loss is 4.337578654289246 and perplexity is 76.52202855044767
At time: 553.508496761322 and batch: 1250, loss is 4.3086098861694335 and perplexity is 74.33708007881206
At time: 553.8867540359497 and batch: 1300, loss is 4.362440452575684 and perplexity is 78.44835048030855
At time: 554.2653601169586 and batch: 1350, loss is 4.318195142745972 and perplexity is 75.05304594102971
At time: 554.6436805725098 and batch: 1400, loss is 4.2011584424972535 and perplexity is 66.76362808423448
At time: 555.0221703052521 and batch: 1450, loss is 4.286485214233398 and perplexity is 72.7104571707561
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861429328592415 and perplexity of 129.2087519483267
Finished 46 epochs...
Completing Train Step...
At time: 556.2508127689362 and batch: 50, loss is 4.472450132369995 and perplexity is 87.5710209702081
At time: 556.6423709392548 and batch: 100, loss is 4.466979284286499 and perplexity is 87.09324133952039
At time: 557.0218489170074 and batch: 150, loss is 4.357054615020752 and perplexity is 78.02697615358129
At time: 557.4150924682617 and batch: 200, loss is 4.405706758499146 and perplexity is 81.91701793755313
At time: 557.7946608066559 and batch: 250, loss is 4.449544954299927 and perplexity is 85.58798869341702
At time: 558.173712015152 and batch: 300, loss is 4.455244512557983 and perplexity is 86.07719522741472
At time: 558.5535795688629 and batch: 350, loss is 4.466707439422607 and perplexity is 87.06956870697014
At time: 558.9333298206329 and batch: 400, loss is 4.338159160614014 and perplexity is 76.56646296798769
At time: 559.3129584789276 and batch: 450, loss is 4.390682401657105 and perplexity is 80.69546691628403
At time: 559.6926968097687 and batch: 500, loss is 4.378243179321289 and perplexity is 79.69789543173925
At time: 560.0717358589172 and batch: 550, loss is 4.424267377853393 and perplexity is 83.45164629660489
At time: 560.4510810375214 and batch: 600, loss is 4.339783201217651 and perplexity is 76.69091103973265
At time: 560.8305048942566 and batch: 650, loss is 4.430580940246582 and perplexity is 83.98019021412051
At time: 561.2108292579651 and batch: 700, loss is 4.462074537277221 and perplexity is 86.66711689508573
At time: 561.5905530452728 and batch: 750, loss is 4.412748651504517 and perplexity is 82.4959046501714
At time: 561.9704122543335 and batch: 800, loss is 4.367027797698975 and perplexity is 78.80904682509073
At time: 562.3500893115997 and batch: 850, loss is 4.324139661788941 and perplexity is 75.50052891966679
At time: 562.7445044517517 and batch: 900, loss is 4.272158031463623 and perplexity is 71.67614822077807
At time: 563.1390132904053 and batch: 950, loss is 4.346244807243347 and perplexity is 77.18806195954552
At time: 563.5212187767029 and batch: 1000, loss is 4.40250702381134 and perplexity is 81.65532411241671
At time: 563.9007849693298 and batch: 1050, loss is 4.316204042434692 and perplexity is 74.90375647236907
At time: 564.3000888824463 and batch: 1100, loss is 4.434215097427368 and perplexity is 84.28594266515523
At time: 564.6900544166565 and batch: 1150, loss is 4.355599365234375 and perplexity is 77.91350999402879
At time: 565.0702698230743 and batch: 1200, loss is 4.3375972604751585 and perplexity is 76.52345234678299
At time: 565.449699640274 and batch: 1250, loss is 4.308655557632446 and perplexity is 74.34047523954573
At time: 565.8287446498871 and batch: 1300, loss is 4.362444925308227 and perplexity is 78.44870135958341
At time: 566.209050655365 and batch: 1350, loss is 4.318202695846558 and perplexity is 75.05361282637585
At time: 566.5882594585419 and batch: 1400, loss is 4.201165299415589 and perplexity is 66.76408587854957
At time: 566.9670338630676 and batch: 1450, loss is 4.286483278274536 and perplexity is 72.71031640643847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861427241920406 and perplexity of 129.20848233232203
Finished 47 epochs...
Completing Train Step...
At time: 568.1980223655701 and batch: 50, loss is 4.472334852218628 and perplexity is 87.56092635152105
At time: 568.5766689777374 and batch: 100, loss is 4.4669215202331545 and perplexity is 87.08821062618033
At time: 568.955463886261 and batch: 150, loss is 4.357005929946899 and perplexity is 78.0231774969544
At time: 569.3334155082703 and batch: 200, loss is 4.405633420944214 and perplexity is 81.911010564036
At time: 569.7122266292572 and batch: 250, loss is 4.449489870071411 and perplexity is 85.5832742749359
At time: 570.0908615589142 and batch: 300, loss is 4.4551615810394285 and perplexity is 86.07005701089724
At time: 570.4804122447968 and batch: 350, loss is 4.466649732589722 and perplexity is 87.06454434289083
At time: 570.8593242168427 and batch: 400, loss is 4.338091773986816 and perplexity is 76.56130358613046
At time: 571.2455179691315 and batch: 450, loss is 4.390609588623047 and perplexity is 80.68959144841104
At time: 571.6453056335449 and batch: 500, loss is 4.378156366348267 and perplexity is 79.69097692080584
At time: 572.0327937602997 and batch: 550, loss is 4.424195461273193 and perplexity is 83.44564495539171
At time: 572.4111089706421 and batch: 600, loss is 4.339717302322388 and perplexity is 76.68585735993618
At time: 572.8025734424591 and batch: 650, loss is 4.430530090332031 and perplexity is 83.97591993719668
At time: 573.1949779987335 and batch: 700, loss is 4.462001934051513 and perplexity is 86.6608248112519
At time: 573.5849721431732 and batch: 750, loss is 4.4126854991912845 and perplexity is 82.49069500746279
At time: 573.9768459796906 and batch: 800, loss is 4.366968412399292 and perplexity is 78.80436686518907
At time: 574.3794083595276 and batch: 850, loss is 4.324093790054321 and perplexity is 75.49706565887404
At time: 574.7706117630005 and batch: 900, loss is 4.272125978469848 and perplexity is 71.6738508224648
At time: 575.1513636112213 and batch: 950, loss is 4.346193828582764 and perplexity is 77.18412711583116
At time: 575.5294592380524 and batch: 1000, loss is 4.402470993995666 and perplexity is 81.65238213913983
At time: 575.9074468612671 and batch: 1050, loss is 4.316193933486939 and perplexity is 74.90299927803558
At time: 576.285165309906 and batch: 1100, loss is 4.434195384979248 and perplexity is 84.28428119925903
At time: 576.6637785434723 and batch: 1150, loss is 4.355568590164185 and perplexity is 77.91111223718572
At time: 577.063460111618 and batch: 1200, loss is 4.3376134538650515 and perplexity is 76.52469153091606
At time: 577.4548032283783 and batch: 1250, loss is 4.308698062896728 and perplexity is 74.343635168249
At time: 577.8484072685242 and batch: 1300, loss is 4.362448749542236 and perplexity is 78.44900136634872
At time: 578.2275786399841 and batch: 1350, loss is 4.318210039138794 and perplexity is 75.05416396901184
At time: 578.607232093811 and batch: 1400, loss is 4.201172533035279 and perplexity is 66.76456882630248
At time: 578.9866840839386 and batch: 1450, loss is 4.2864805030822755 and perplexity is 72.71011462161108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.861426198584402 and perplexity of 129.2083475245307
Finished 48 epochs...
Completing Train Step...
At time: 580.2391173839569 and batch: 50, loss is 4.472221817970276 and perplexity is 87.55102952737644
At time: 580.6305134296417 and batch: 100, loss is 4.466864061355591 and perplexity is 87.08320677910784
At time: 581.0246410369873 and batch: 150, loss is 4.356957502365113 and perplexity is 78.01939911463462
At time: 581.4056460857391 and batch: 200, loss is 4.405560865402221 and perplexity is 81.90506768186651
At time: 581.7847421169281 and batch: 250, loss is 4.449434814453125 and perplexity is 85.57856256455996
At time: 582.163370847702 and batch: 300, loss is 4.45507963180542 and perplexity is 86.06300392465559
At time: 582.5409610271454 and batch: 350, loss is 4.466591997146606 and perplexity is 87.05951777795043
At time: 582.9220221042633 and batch: 400, loss is 4.338025588989257 and perplexity is 76.55623654412244
At time: 583.3009355068207 and batch: 450, loss is 4.390536870956421 and perplexity is 80.68372410293233
At time: 583.6945352554321 and batch: 500, loss is 4.3780706596374515 and perplexity is 79.68414716197455
At time: 584.08824467659 and batch: 550, loss is 4.4241240692138675 and perplexity is 83.43968781160551
At time: 584.467776298523 and batch: 600, loss is 4.339652662277222 and perplexity is 76.68090054285899
At time: 584.8459575176239 and batch: 650, loss is 4.430480308532715 and perplexity is 83.971739568857
At time: 585.2453813552856 and batch: 700, loss is 4.461931858062744 and perplexity is 86.65475218104098
At time: 585.6341269016266 and batch: 750, loss is 4.412623510360718 and perplexity is 82.48558166423338
At time: 586.0128273963928 and batch: 800, loss is 4.366909055709839 and perplexity is 78.79968943767723
At time: 586.3911421298981 and batch: 850, loss is 4.324048275947571 and perplexity is 75.4936295555645
At time: 586.801709651947 and batch: 900, loss is 4.272094402313233 and perplexity is 71.67158767345694
At time: 587.1901304721832 and batch: 950, loss is 4.346143660545349 and perplexity is 77.18025503678228
At time: 587.5839111804962 and batch: 1000, loss is 4.402435202598571 and perplexity is 81.64945973860564
At time: 587.9757876396179 and batch: 1050, loss is 4.316183905601502 and perplexity is 74.902248163106
At time: 588.3717494010925 and batch: 1100, loss is 4.43417724609375 and perplexity is 84.28275239019852
At time: 588.7633295059204 and batch: 1150, loss is 4.355536994934082 and perplexity is 77.90865065655429
At time: 589.1420555114746 and batch: 1200, loss is 4.337627339363098 and perplexity is 76.52575412174811
At time: 589.5210514068604 and batch: 1250, loss is 4.3087378072738645 and perplexity is 74.34658996844075
At time: 589.8994617462158 and batch: 1300, loss is 4.362451524734497 and perplexity is 78.44921907771229
At time: 590.2781090736389 and batch: 1350, loss is 4.318216705322266 and perplexity is 75.05466429550681
At time: 590.6734623908997 and batch: 1400, loss is 4.201179332733155 and perplexity is 66.76502280674278
At time: 591.0657472610474 and batch: 1450, loss is 4.286476831436158 and perplexity is 72.70984765629112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8614277635884084 and perplexity of 129.20854973627047
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 592.3340947628021 and batch: 50, loss is 4.472095351219178 and perplexity is 87.53995793322585
At time: 592.7370584011078 and batch: 100, loss is 4.4668577289581295 and perplexity is 87.08265533537627
At time: 593.1153318881989 and batch: 150, loss is 4.357206220626831 and perplexity is 78.03880637733302
At time: 593.5115666389465 and batch: 200, loss is 4.405407867431641 and perplexity is 81.89253733131446
At time: 593.9050874710083 and batch: 250, loss is 4.449319767951965 and perplexity is 85.56871761668691
At time: 594.2856993675232 and batch: 300, loss is 4.454981832504273 and perplexity is 86.05458743458726
At time: 594.6763143539429 and batch: 350, loss is 4.466686677932739 and perplexity is 87.06776103176674
At time: 595.0634560585022 and batch: 400, loss is 4.33755669593811 and perplexity is 76.5203482713233
At time: 595.4421045780182 and batch: 450, loss is 4.390355577468872 and perplexity is 80.66909799505042
At time: 595.830769777298 and batch: 500, loss is 4.377845163345337 and perplexity is 79.66618070800973
At time: 596.2245509624481 and batch: 550, loss is 4.4237987995147705 and perplexity is 83.41255182295497
At time: 596.6208562850952 and batch: 600, loss is 4.3393620681762695 and perplexity is 76.65862076284864
At time: 596.9988625049591 and batch: 650, loss is 4.430144519805908 and perplexity is 83.94354753888722
At time: 597.3770020008087 and batch: 700, loss is 4.461579675674439 and perplexity is 86.62423927682894
At time: 597.7554104328156 and batch: 750, loss is 4.412364645004272 and perplexity is 82.46423176822768
At time: 598.1343803405762 and batch: 800, loss is 4.366525459289551 and perplexity is 78.76946795568583
At time: 598.5122272968292 and batch: 850, loss is 4.323666787147522 and perplexity is 75.46483507414928
At time: 598.8985605239868 and batch: 900, loss is 4.271801586151123 and perplexity is 71.65060414652996
At time: 599.294438123703 and batch: 950, loss is 4.345632309913635 and perplexity is 77.14079895341975
At time: 599.6781222820282 and batch: 1000, loss is 4.402054824829102 and perplexity is 81.6184080053008
At time: 600.0728487968445 and batch: 1050, loss is 4.315840563774109 and perplexity is 74.87653550271433
At time: 600.4668245315552 and batch: 1100, loss is 4.43381893157959 and perplexity is 84.25255806657901
At time: 600.8468337059021 and batch: 1150, loss is 4.355024681091309 and perplexity is 77.86874719877086
At time: 601.2261593341827 and batch: 1200, loss is 4.337141528129577 and perplexity is 76.48858607979929
At time: 601.6056895256042 and batch: 1250, loss is 4.308146376609802 and perplexity is 74.30263211565729
At time: 601.9845721721649 and batch: 1300, loss is 4.361942567825317 and perplexity is 78.4093019645499
At time: 602.3636984825134 and batch: 1350, loss is 4.317589063644409 and perplexity is 75.00757164027989
At time: 602.7413592338562 and batch: 1400, loss is 4.200495491027832 and perplexity is 66.71938170711303
At time: 603.1205825805664 and batch: 1450, loss is 4.285842199325561 and perplexity is 72.6637182913482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8614074185363245 and perplexity of 129.20592100833727
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7fb370c898>
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.9222754832816875, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 26.928206893112907, 'anneal': 3.519315938726637, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6667542457580566 and batch: 50, loss is 8.263784732818603 and perplexity is 3880.753958025709
At time: 1.0682754516601562 and batch: 100, loss is 7.627002630233765 and perplexity is 2052.887525811126
At time: 1.458402395248413 and batch: 150, loss is 7.453923597335815 and perplexity is 1726.6244514784175
At time: 1.8663790225982666 and batch: 200, loss is 7.235378131866455 and perplexity is 1387.6655195380447
At time: 2.2652382850646973 and batch: 250, loss is 7.120124969482422 and perplexity is 1236.6049616917996
At time: 2.649935245513916 and batch: 300, loss is 7.146860256195068 and perplexity is 1270.1118623890525
At time: 3.0357978343963623 and batch: 350, loss is 7.11163212776184 and perplexity is 1226.147142640939
At time: 3.4373180866241455 and batch: 400, loss is 6.969210042953491 and perplexity is 1063.3823922444271
At time: 3.8309829235076904 and batch: 450, loss is 7.01637601852417 and perplexity is 1114.7394935492484
At time: 4.239784240722656 and batch: 500, loss is 6.942307109832764 and perplexity is 1035.1556799851228
At time: 4.6212475299835205 and batch: 550, loss is 6.9733705234527585 and perplexity is 1067.8157900882359
At time: 5.0241379737854 and batch: 600, loss is 6.791911983489991 and perplexity is 890.6147757130559
At time: 5.414089918136597 and batch: 650, loss is 6.953881759643554 and perplexity is 1047.206853996553
At time: 5.810911655426025 and batch: 700, loss is 6.874476146697998 and perplexity is 967.2685260301969
At time: 6.2108941078186035 and batch: 750, loss is 6.8082637596130375 and perplexity is 905.2976273309855
At time: 6.594606637954712 and batch: 800, loss is 6.7949015903472905 and perplexity is 893.281347768696
At time: 6.978846311569214 and batch: 850, loss is 6.7321838283538815 and perplexity is 838.9774495659785
At time: 7.386046886444092 and batch: 900, loss is 6.653107395172119 and perplexity is 775.1894066508617
At time: 7.784910678863525 and batch: 950, loss is 6.681819353103638 and perplexity is 797.7692163897918
At time: 8.169081926345825 and batch: 1000, loss is 6.76684907913208 and perplexity is 868.5707799461363
At time: 8.568226099014282 and batch: 1050, loss is 6.58662859916687 and perplexity is 725.3313603271844
At time: 8.964168548583984 and batch: 1100, loss is 6.678919191360474 and perplexity is 795.458908381316
At time: 9.356242656707764 and batch: 1150, loss is 6.7048258876800535 and perplexity is 816.335879804236
At time: 9.754962682723999 and batch: 1200, loss is 6.634351806640625 and perplexity is 760.785769680592
At time: 10.150490760803223 and batch: 1250, loss is 6.659437961578369 and perplexity is 780.1123607700258
At time: 10.551696538925171 and batch: 1300, loss is 6.7229670143127445 and perplexity is 831.2802766237227
At time: 10.941223859786987 and batch: 1350, loss is 6.6648972129821775 and perplexity is 784.3828364646745
At time: 11.330490827560425 and batch: 1400, loss is 6.563554944992066 and perplexity is 708.7869197137009
At time: 11.73367977142334 and batch: 1450, loss is 6.606160306930542 and perplexity is 739.6375781206522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.036914792835203 and perplexity of 418.5995742100515
Finished 1 epochs...
Completing Train Step...
At time: 12.97194504737854 and batch: 50, loss is 6.079952459335328 and perplexity is 437.0084185538535
At time: 13.368547916412354 and batch: 100, loss is 5.927998332977295 and perplexity is 375.40233080009824
At time: 13.745299577713013 and batch: 150, loss is 5.715946941375733 and perplexity is 303.67162642920937
At time: 14.137610673904419 and batch: 200, loss is 5.634560756683349 and perplexity is 279.93593031528866
At time: 14.533406972885132 and batch: 250, loss is 5.590793657302856 and perplexity is 267.9481943880308
At time: 14.915497541427612 and batch: 300, loss is 5.572079210281372 and perplexity is 262.9803225774091
At time: 15.292269229888916 and batch: 350, loss is 5.605533075332642 and perplexity is 271.92684429751984
At time: 15.669564247131348 and batch: 400, loss is 5.499117736816406 and perplexity is 244.47614478573232
At time: 16.046051263809204 and batch: 450, loss is 5.528570375442505 and perplexity is 251.78369744273232
At time: 16.437782049179077 and batch: 500, loss is 5.477728290557861 and perplexity is 239.30246376018056
At time: 16.830329179763794 and batch: 550, loss is 5.514115648269653 and perplexity is 248.17041024283523
At time: 17.206162214279175 and batch: 600, loss is 5.34747875213623 and perplexity is 210.07797096929147
At time: 17.584075689315796 and batch: 650, loss is 5.514081945419312 and perplexity is 248.1620463335842
At time: 17.961814403533936 and batch: 700, loss is 5.507026147842407 and perplexity is 246.41722794975095
At time: 18.340829372406006 and batch: 750, loss is 5.461040029525757 and perplexity is 235.3420598200047
At time: 18.719533681869507 and batch: 800, loss is 5.396424331665039 and perplexity is 220.6161539923771
At time: 19.0985586643219 and batch: 850, loss is 5.361419525146484 and perplexity is 213.0271292876423
At time: 19.477514505386353 and batch: 900, loss is 5.346715784072876 and perplexity is 209.917749316402
At time: 19.856568098068237 and batch: 950, loss is 5.3834892272949215 and perplexity is 217.78083810115717
At time: 20.23530101776123 and batch: 1000, loss is 5.428305406570434 and perplexity is 227.76295260882267
At time: 20.626402139663696 and batch: 1050, loss is 5.3096142578125 and perplexity is 202.2721884210295
At time: 21.01558542251587 and batch: 1100, loss is 5.409268064498901 and perplexity is 223.4679636707712
At time: 21.39448571205139 and batch: 1150, loss is 5.418227338790894 and perplexity is 225.47907002713694
At time: 21.7750301361084 and batch: 1200, loss is 5.385577716827393 and perplexity is 218.23614638970503
At time: 22.155017375946045 and batch: 1250, loss is 5.376007804870605 and perplexity is 216.1576072644312
At time: 22.53491497039795 and batch: 1300, loss is 5.456801176071167 and perplexity is 234.34659063126992
At time: 22.915168523788452 and batch: 1350, loss is 5.414295492172241 and perplexity is 224.59426151363974
At time: 23.295490026474 and batch: 1400, loss is 5.256683197021484 and perplexity is 191.84412570596206
At time: 23.676310777664185 and batch: 1450, loss is 5.354959335327148 and perplexity is 211.65536928154427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.5144267285990916 and perplexity of 248.24762318490144
Finished 2 epochs...
Completing Train Step...
At time: 24.92992663383484 and batch: 50, loss is 5.428474359512329 and perplexity is 227.80143708066137
At time: 25.30828595161438 and batch: 100, loss is 5.455468578338623 and perplexity is 234.0345088818644
At time: 25.68746256828308 and batch: 150, loss is 5.322864723205567 and perplexity is 204.97022469633959
At time: 26.06651020050049 and batch: 200, loss is 5.351729097366333 and perplexity is 210.97277513737927
At time: 26.4452486038208 and batch: 250, loss is 5.34907748222351 and perplexity is 210.41409755840715
At time: 26.824923753738403 and batch: 300, loss is 5.3663014793396 and perplexity is 214.06966069941927
At time: 27.204769611358643 and batch: 350, loss is 5.42978138923645 and perplexity is 228.0993749945635
At time: 27.584295511245728 and batch: 400, loss is 5.332046546936035 and perplexity is 206.8608917725643
At time: 27.963679790496826 and batch: 450, loss is 5.326930418014526 and perplexity is 205.80526743908865
At time: 28.34688377380371 and batch: 500, loss is 5.33654221534729 and perplexity is 207.79296332169676
At time: 28.72620677947998 and batch: 550, loss is 5.3765290832519534 and perplexity is 216.2703149255435
At time: 29.11478590965271 and batch: 600, loss is 5.262724590301514 and perplexity is 193.0066395837541
At time: 29.508662939071655 and batch: 650, loss is 5.38830262184143 and perplexity is 218.8316301090721
At time: 29.893377780914307 and batch: 700, loss is 5.372859725952148 and perplexity is 215.47819603911864
At time: 30.2728328704834 and batch: 750, loss is 5.342009038925171 and perplexity is 208.93204152580512
At time: 30.652122259140015 and batch: 800, loss is 5.252374649047852 and perplexity is 191.01933418972985
At time: 31.044316053390503 and batch: 850, loss is 5.228991432189941 and perplexity is 186.60450528311887
At time: 31.435603141784668 and batch: 900, loss is 5.235598640441895 and perplexity is 187.8415222243662
At time: 31.81402087211609 and batch: 950, loss is 5.287711029052734 and perplexity is 197.88994227389685
At time: 32.210646629333496 and batch: 1000, loss is 5.368354606628418 and perplexity is 214.50962445775897
At time: 32.60110688209534 and batch: 1050, loss is 5.229779987335205 and perplexity is 186.75171125827592
At time: 32.98005437850952 and batch: 1100, loss is 5.3360950469970705 and perplexity is 207.70006565709667
At time: 33.360146284103394 and batch: 1150, loss is 5.3323486328125 and perplexity is 206.9233909659482
At time: 33.76036286354065 and batch: 1200, loss is 5.277948579788208 and perplexity is 195.9674511322311
At time: 34.15547060966492 and batch: 1250, loss is 5.298193435668946 and perplexity is 199.97521536000465
At time: 34.5541718006134 and batch: 1300, loss is 5.346819744110108 and perplexity is 209.93957350783884
At time: 34.94513988494873 and batch: 1350, loss is 5.31601240158081 and perplexity is 203.57050393853643
At time: 35.32367420196533 and batch: 1400, loss is 5.182969045639038 and perplexity is 178.21114330173015
At time: 35.70266246795654 and batch: 1450, loss is 5.257133197784424 and perplexity is 191.9304751360928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4370138054220085 and perplexity of 229.7550647076057
Finished 3 epochs...
Completing Train Step...
At time: 36.9595148563385 and batch: 50, loss is 5.344284782409668 and perplexity is 209.408058699059
At time: 37.33953499794006 and batch: 100, loss is 5.370542421340942 and perplexity is 214.97944552344444
At time: 37.74217224121094 and batch: 150, loss is 5.2456184673309325 and perplexity is 189.73312268834357
At time: 38.132405519485474 and batch: 200, loss is 5.323694295883179 and perplexity is 205.14033294329312
At time: 38.513490438461304 and batch: 250, loss is 5.3610118389129635 and perplexity is 212.94029876067322
At time: 38.91335153579712 and batch: 300, loss is 5.335954761505127 and perplexity is 207.67093039488427
At time: 39.31507587432861 and batch: 350, loss is 5.3973961925506595 and perplexity is 220.83066642441523
At time: 39.716630935668945 and batch: 400, loss is 5.283284015655518 and perplexity is 197.0158171577002
At time: 40.10850930213928 and batch: 450, loss is 5.279885425567627 and perplexity is 196.34737767364865
At time: 40.489299058914185 and batch: 500, loss is 5.291241817474365 and perplexity is 198.5898847380582
At time: 40.870452642440796 and batch: 550, loss is 5.317551107406616 and perplexity is 203.8839801709121
At time: 41.25116848945618 and batch: 600, loss is 5.214316883087158 and perplexity is 183.88616231723788
At time: 41.6324622631073 and batch: 650, loss is 5.363535861968995 and perplexity is 213.47844384390572
At time: 42.01951241493225 and batch: 700, loss is 5.3799625015258785 and perplexity is 217.01413757334814
At time: 42.41575002670288 and batch: 750, loss is 5.367037878036499 and perplexity is 214.22735937602755
At time: 42.80438446998596 and batch: 800, loss is 5.276443891525268 and perplexity is 195.67280294102414
At time: 43.18485069274902 and batch: 850, loss is 5.207926301956177 and perplexity is 182.71476980412075
At time: 43.580896615982056 and batch: 900, loss is 5.216283626556397 and perplexity is 184.24817510250807
At time: 43.96319246292114 and batch: 950, loss is 5.2623139762878415 and perplexity is 192.9274046214154
At time: 44.366475105285645 and batch: 1000, loss is 5.271390790939331 and perplexity is 194.6865425209667
At time: 44.75788736343384 and batch: 1050, loss is 5.1715598392486575 and perplexity is 176.1894504723728
At time: 45.13877320289612 and batch: 1100, loss is 5.298457202911377 and perplexity is 200.02796922817998
At time: 45.519821882247925 and batch: 1150, loss is 5.296585931777954 and perplexity is 199.65401265967427
At time: 45.91892433166504 and batch: 1200, loss is 5.211953468322754 and perplexity is 183.45207621106118
At time: 46.311835527420044 and batch: 1250, loss is 5.246052894592285 and perplexity is 189.81556583569974
At time: 46.69174909591675 and batch: 1300, loss is 5.339829349517823 and perplexity is 208.47713053048318
At time: 47.07227563858032 and batch: 1350, loss is 5.289394235610962 and perplexity is 198.22331240923032
At time: 47.45288014411926 and batch: 1400, loss is 5.182620420455932 and perplexity is 178.1490252378549
At time: 47.83401155471802 and batch: 1450, loss is 5.272797126770019 and perplexity is 194.96052979537004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.490626147669604 and perplexity of 242.40894314317626
Annealing...
Finished 4 epochs...
Completing Train Step...
At time: 49.106526374816895 and batch: 50, loss is 5.27961986541748 and perplexity is 196.29524255736382
At time: 49.49995565414429 and batch: 100, loss is 5.230251331329345 and perplexity is 186.83975630389457
At time: 49.88159227371216 and batch: 150, loss is 5.141680173873901 and perplexity is 171.0028415940921
At time: 50.26096820831299 and batch: 200, loss is 5.169846706390381 and perplexity is 175.88787293044146
At time: 50.64024543762207 and batch: 250, loss is 5.195728931427002 and perplexity is 180.49966673486665
At time: 51.019771099090576 and batch: 300, loss is 5.199292440414428 and perplexity is 181.1440263282331
At time: 51.39957404136658 and batch: 350, loss is 5.234499568939209 and perplexity is 187.63518437106617
At time: 51.79554605484009 and batch: 400, loss is 5.130636577606201 and perplexity is 169.124744810059
At time: 52.189098834991455 and batch: 450, loss is 5.1488712120056155 and perplexity is 172.2369615322642
At time: 52.586376428604126 and batch: 500, loss is 5.12558141708374 and perplexity is 168.27194940163824
At time: 52.97837018966675 and batch: 550, loss is 5.183792400360107 and perplexity is 178.3579347103217
At time: 53.37349510192871 and batch: 600, loss is 5.057422304153443 and perplexity is 157.18481901076072
At time: 53.753538370132446 and batch: 650, loss is 5.179876852035522 and perplexity is 177.66093106412995
At time: 54.15380644798279 and batch: 700, loss is 5.166820259094238 and perplexity is 175.35636225320528
At time: 54.54199194908142 and batch: 750, loss is 5.145439949035644 and perplexity is 171.64698398699514
At time: 54.921470165252686 and batch: 800, loss is 5.088816738128662 and perplexity is 162.19782595833001
At time: 55.300769567489624 and batch: 850, loss is 5.047020435333252 and perplexity is 155.55827734520824
At time: 55.68084359169006 and batch: 900, loss is 4.992296085357666 and perplexity is 147.27418968780296
At time: 56.06079626083374 and batch: 950, loss is 5.062266235351562 and perplexity is 157.94805850687513
At time: 56.44104027748108 and batch: 1000, loss is 5.102709331512451 and perplexity is 164.46689956566132
At time: 56.8210072517395 and batch: 1050, loss is 4.998330621719361 and perplexity is 148.1656080838468
At time: 57.22493267059326 and batch: 1100, loss is 5.1091304111480715 and perplexity is 165.52635240058348
At time: 57.617379903793335 and batch: 1150, loss is 5.0792700386047365 and perplexity is 160.65673989771554
At time: 57.998621463775635 and batch: 1200, loss is 5.050591125488281 and perplexity is 156.11472060668297
At time: 58.38947129249573 and batch: 1250, loss is 5.00711763381958 and perplexity is 149.4732779163092
At time: 58.783143520355225 and batch: 1300, loss is 5.085239372253418 and perplexity is 161.61862162132235
At time: 59.164655685424805 and batch: 1350, loss is 5.023073053359985 and perplexity is 151.87731448103347
At time: 59.54468321800232 and batch: 1400, loss is 4.912959775924683 and perplexity is 136.04147138744207
At time: 59.9245126247406 and batch: 1450, loss is 5.0023840713500975 and perplexity is 148.76740877362607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.260441185062767 and perplexity of 192.56642999152896
Finished 5 epochs...
Completing Train Step...
At time: 61.167739152908325 and batch: 50, loss is 5.113318462371826 and perplexity is 166.22103891929402
At time: 61.56478476524353 and batch: 100, loss is 5.122226772308349 and perplexity is 167.70840256395658
At time: 61.94395470619202 and batch: 150, loss is 5.036898498535156 and perplexity is 153.99166822810778
At time: 62.32347583770752 and batch: 200, loss is 5.082130546569824 and perplexity is 161.11695769636614
At time: 62.70315098762512 and batch: 250, loss is 5.095616197586059 and perplexity is 163.30444143005204
At time: 63.096009254455566 and batch: 300, loss is 5.123569688796997 and perplexity is 167.9337722354987
At time: 63.47634768486023 and batch: 350, loss is 5.140376386642456 and perplexity is 170.78003555008007
At time: 63.854968547821045 and batch: 400, loss is 5.047668199539185 and perplexity is 155.65907507226436
At time: 64.25562787055969 and batch: 450, loss is 5.0727807140350345 and perplexity is 159.6175615976094
At time: 64.6486132144928 and batch: 500, loss is 5.064707107543946 and perplexity is 158.33406042976003
At time: 65.04918885231018 and batch: 550, loss is 5.1196195507049564 and perplexity is 167.27171910636034
At time: 65.4387595653534 and batch: 600, loss is 4.978318042755127 and perplexity is 145.22990562019692
At time: 65.81840920448303 and batch: 650, loss is 5.10721529006958 and perplexity is 165.20965274993986
At time: 66.20826578140259 and batch: 700, loss is 5.106016578674317 and perplexity is 165.0117327047872
At time: 66.60158681869507 and batch: 750, loss is 5.078239059448242 and perplexity is 160.49119150066767
At time: 66.98504614830017 and batch: 800, loss is 5.011657991409302 and perplexity is 150.15348306693954
At time: 67.36476993560791 and batch: 850, loss is 4.980426359176636 and perplexity is 145.53641921539548
At time: 67.74440455436707 and batch: 900, loss is 4.92232120513916 and perplexity is 137.32099372659607
At time: 68.12431955337524 and batch: 950, loss is 4.9991910362243654 and perplexity is 148.29314678238987
At time: 68.50456404685974 and batch: 1000, loss is 5.0370377159118656 and perplexity is 154.0131080365559
At time: 68.88414120674133 and batch: 1050, loss is 4.951863136291504 and perplexity is 141.43823730114693
At time: 69.26321339607239 and batch: 1100, loss is 5.070285511016846 and perplexity is 159.21977985564038
At time: 69.64338064193726 and batch: 1150, loss is 5.032215366363525 and perplexity is 153.27219091109848
At time: 70.02247285842896 and batch: 1200, loss is 4.979145898818969 and perplexity is 145.35018485829474
At time: 70.41627740859985 and batch: 1250, loss is 4.953178548812867 and perplexity is 141.62440934916927
At time: 70.81031370162964 and batch: 1300, loss is 5.033951263427735 and perplexity is 153.53848672151383
At time: 71.1925790309906 and batch: 1350, loss is 4.981720666885376 and perplexity is 145.72491008096483
At time: 71.57204365730286 and batch: 1400, loss is 4.859854860305786 and perplexity is 129.00547693305407
At time: 71.95183086395264 and batch: 1450, loss is 4.961340761184692 and perplexity is 142.78510834720012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.2324766501402245 and perplexity of 187.25599729089654
Finished 6 epochs...
Completing Train Step...
At time: 73.19927740097046 and batch: 50, loss is 5.0480801486969 and perplexity is 155.7232119067815
At time: 73.5914876461029 and batch: 100, loss is 5.060436859130859 and perplexity is 157.6593762193016
At time: 73.96982836723328 and batch: 150, loss is 4.9788634395599365 and perplexity is 145.30913515048732
At time: 74.34878635406494 and batch: 200, loss is 5.018151025772095 and perplexity is 151.13160685142682
At time: 74.72788739204407 and batch: 250, loss is 5.0447319221496585 and perplexity is 155.20268721822754
At time: 75.10766744613647 and batch: 300, loss is 5.05656907081604 and perplexity is 157.05076088261205
At time: 75.48651003837585 and batch: 350, loss is 5.065190773010254 and perplexity is 158.41065966964064
At time: 75.86484384536743 and batch: 400, loss is 4.984275760650635 and perplexity is 146.09772697839267
At time: 76.24450182914734 and batch: 450, loss is 4.99942792892456 and perplexity is 148.32828050764874
At time: 76.62356400489807 and batch: 500, loss is 4.988637371063232 and perplexity is 146.7363400238975
At time: 77.00281929969788 and batch: 550, loss is 5.044722909927368 and perplexity is 155.20128850341308
At time: 77.38158345222473 and batch: 600, loss is 4.920948963165284 and perplexity is 137.13268532700448
At time: 77.75991344451904 and batch: 650, loss is 5.05099555015564 and perplexity is 156.1778700193635
At time: 78.1394944190979 and batch: 700, loss is 5.048814258575439 and perplexity is 155.83757182619757
At time: 78.53767108917236 and batch: 750, loss is 5.007113771438599 and perplexity is 149.4727005946783
At time: 78.92426562309265 and batch: 800, loss is 4.950126104354858 and perplexity is 141.19276782177536
At time: 79.3040452003479 and batch: 850, loss is 4.9205296611785885 and perplexity is 137.075197372855
At time: 79.68381643295288 and batch: 900, loss is 4.870967664718628 and perplexity is 130.4470848841489
At time: 80.06375360488892 and batch: 950, loss is 4.953508176803589 and perplexity is 141.6711004135784
At time: 80.44333219528198 and batch: 1000, loss is 4.977655067443847 and perplexity is 145.13365368816403
At time: 80.82280445098877 and batch: 1050, loss is 4.897475881576538 and perplexity is 133.95124381000878
At time: 81.20202541351318 and batch: 1100, loss is 5.016414842605591 and perplexity is 150.8694423483374
At time: 81.58117246627808 and batch: 1150, loss is 4.980688495635986 and perplexity is 145.57457461777776
At time: 81.97914290428162 and batch: 1200, loss is 4.92987359046936 and perplexity is 138.36202095631768
At time: 82.37878966331482 and batch: 1250, loss is 4.917715215682984 and perplexity is 136.6899490855026
At time: 82.75870323181152 and batch: 1300, loss is 4.985617818832398 and perplexity is 146.29393025687975
At time: 83.13823390007019 and batch: 1350, loss is 4.935942344665527 and perplexity is 139.20425913487446
At time: 83.51753544807434 and batch: 1400, loss is 4.829973487854004 and perplexity is 125.20764108750066
At time: 83.89791750907898 and batch: 1450, loss is 4.912682161331177 and perplexity is 136.00370953152662
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.219576843783387 and perplexity of 184.85594457596144
Finished 7 epochs...
Completing Train Step...
At time: 85.17484474182129 and batch: 50, loss is 4.990212526321411 and perplexity is 146.96765467186756
At time: 85.56550168991089 and batch: 100, loss is 4.996883325576782 and perplexity is 147.9513236747081
At time: 85.94769144058228 and batch: 150, loss is 4.918756809234619 and perplexity is 136.8323986294278
At time: 86.32909178733826 and batch: 200, loss is 4.96181694984436 and perplexity is 142.85311718779877
At time: 86.71085476875305 and batch: 250, loss is 4.982728624343872 and perplexity is 145.8718686425165
At time: 87.09183502197266 and batch: 300, loss is 4.9987397956848145 and perplexity is 148.22624599813224
At time: 87.4730076789856 and batch: 350, loss is 5.0360408115386965 and perplexity is 153.8596482007289
At time: 87.85426187515259 and batch: 400, loss is 4.925042781829834 and perplexity is 137.69523237084994
At time: 88.23648929595947 and batch: 450, loss is 4.955648612976074 and perplexity is 141.97466312390546
At time: 88.63922810554504 and batch: 500, loss is 4.956316070556641 and perplexity is 142.06945682092245
At time: 89.0292501449585 and batch: 550, loss is 5.012522554397583 and perplexity is 150.28335634468553
At time: 89.41006541252136 and batch: 600, loss is 4.880992231369018 and perplexity is 131.7613367778128
At time: 89.79126071929932 and batch: 650, loss is 5.021990270614624 and perplexity is 151.71295334526084
At time: 90.1704933643341 and batch: 700, loss is 5.031457576751709 and perplexity is 153.1560868338336
At time: 90.55085349082947 and batch: 750, loss is 5.007300491333008 and perplexity is 149.50061272734453
At time: 90.93521070480347 and batch: 800, loss is 4.92973554611206 and perplexity is 138.34292217832967
At time: 91.3292670249939 and batch: 850, loss is 4.907710676193237 and perplexity is 135.3292470401604
At time: 91.70985221862793 and batch: 900, loss is 4.847862930297851 and perplexity is 127.46769122091908
At time: 92.10396909713745 and batch: 950, loss is 4.910782146453857 and perplexity is 135.7455457951814
At time: 92.48492527008057 and batch: 1000, loss is 4.96345477104187 and perplexity is 143.08727675466676
At time: 92.86506295204163 and batch: 1050, loss is 4.869118795394898 and perplexity is 130.20612808798984
At time: 93.24686002731323 and batch: 1100, loss is 5.004418859481811 and perplexity is 149.07042711589725
At time: 93.62876486778259 and batch: 1150, loss is 4.967205772399902 and perplexity is 143.62500520367493
At time: 94.0093240737915 and batch: 1200, loss is 4.916392431259156 and perplexity is 136.50925728445566
At time: 94.39011025428772 and batch: 1250, loss is 4.8936776924133305 and perplexity is 133.44343663171114
At time: 94.77168989181519 and batch: 1300, loss is 4.968129987716675 and perplexity is 143.75780699262648
At time: 95.15257787704468 and batch: 1350, loss is 4.920046482086182 and perplexity is 137.0089815017474
At time: 95.53448867797852 and batch: 1400, loss is 4.798703260421753 and perplexity is 121.3529522689451
At time: 95.91615653038025 and batch: 1450, loss is 4.879150552749634 and perplexity is 131.51889805663714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.201741014790331 and perplexity of 181.58811441892993
Finished 8 epochs...
Completing Train Step...
At time: 97.17020988464355 and batch: 50, loss is 4.961871862411499 and perplexity is 142.8609618345702
At time: 97.54983305931091 and batch: 100, loss is 4.960158452987671 and perplexity is 142.61639210014303
At time: 97.92979598045349 and batch: 150, loss is 4.883753118515014 and perplexity is 132.12561759658286
At time: 98.31154322624207 and batch: 200, loss is 4.9315944480896 and perplexity is 138.60032728125066
At time: 98.70465755462646 and batch: 250, loss is 4.962005662918091 and perplexity is 142.88007798248245
At time: 99.08754062652588 and batch: 300, loss is 4.9760300731658935 and perplexity is 144.898003848058
At time: 99.48427367210388 and batch: 350, loss is 4.9968188190460205 and perplexity is 147.94178015590924
At time: 99.86812782287598 and batch: 400, loss is 4.907532148361206 and perplexity is 135.30508915956705
At time: 100.26982975006104 and batch: 450, loss is 4.934381322860718 and perplexity is 138.98712776853324
At time: 100.65947151184082 and batch: 500, loss is 4.938704805374146 and perplexity is 139.58933706765293
At time: 101.03879189491272 and batch: 550, loss is 4.987650060653687 and perplexity is 146.59153720236242
At time: 101.4181797504425 and batch: 600, loss is 4.870198221206665 and perplexity is 130.3467518262906
At time: 101.81833529472351 and batch: 650, loss is 4.980901823043824 and perplexity is 145.60563297710982
At time: 102.22058272361755 and batch: 700, loss is 4.994709825515747 and perplexity is 147.63010067922855
At time: 102.61367630958557 and batch: 750, loss is 4.973587532043457 and perplexity is 144.54451639466305
At time: 102.9978723526001 and batch: 800, loss is 4.897364530563355 and perplexity is 133.9363290336965
At time: 103.37652039527893 and batch: 850, loss is 4.871845283508301 and perplexity is 130.56161794773433
At time: 103.75553154945374 and batch: 900, loss is 4.815792274475098 and perplexity is 123.44457556370791
At time: 104.13458395004272 and batch: 950, loss is 4.883128147125245 and perplexity is 132.04306866377686
At time: 104.51340508460999 and batch: 1000, loss is 4.928310432434082 and perplexity is 138.1459082046799
At time: 104.89187169075012 and batch: 1050, loss is 4.819725885391235 and perplexity is 123.93111479433401
At time: 105.27079606056213 and batch: 1100, loss is 4.956029806137085 and perplexity is 142.0287932108791
At time: 105.65026450157166 and batch: 1150, loss is 4.933838567733765 and perplexity is 138.9117122602846
At time: 106.02981090545654 and batch: 1200, loss is 4.870174102783203 and perplexity is 130.34360810604412
At time: 106.40878677368164 and batch: 1250, loss is 4.865554132461548 and perplexity is 129.7428134004508
At time: 106.78784155845642 and batch: 1300, loss is 4.934901485443115 and perplexity is 139.05944247790578
At time: 107.16646385192871 and batch: 1350, loss is 4.897692613601684 and perplexity is 133.9802784806084
At time: 107.54569435119629 and batch: 1400, loss is 4.794265375137329 and perplexity is 120.81559503466009
At time: 107.92518615722656 and batch: 1450, loss is 4.852767362594604 and perplexity is 128.09438341106863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.2121274247128735 and perplexity of 183.48399164786534
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 109.19121432304382 and batch: 50, loss is 4.949030275344849 and perplexity is 141.03812943488265
At time: 109.59814047813416 and batch: 100, loss is 4.906326675415039 and perplexity is 135.14208080592655
At time: 109.97756457328796 and batch: 150, loss is 4.808004512786865 and perplexity is 122.48695233816773
At time: 110.35707235336304 and batch: 200, loss is 4.833991317749024 and perplexity is 125.71171605658209
At time: 110.73712587356567 and batch: 250, loss is 4.856880016326905 and perplexity is 128.62227603080635
At time: 111.11740255355835 and batch: 300, loss is 4.877363634109497 and perplexity is 131.28409433622082
At time: 111.49620175361633 and batch: 350, loss is 4.89348108291626 and perplexity is 133.41720296372625
At time: 111.88872623443604 and batch: 400, loss is 4.76912859916687 and perplexity is 117.81653179234655
At time: 112.268625497818 and batch: 450, loss is 4.804255361557007 and perplexity is 122.02859000192596
At time: 112.6479263305664 and batch: 500, loss is 4.805864543914795 and perplexity is 122.22511433544017
At time: 113.05131483078003 and batch: 550, loss is 4.849684181213379 and perplexity is 127.70005340094407
At time: 113.44288420677185 and batch: 600, loss is 4.739906320571899 and perplexity is 114.42348205170228
At time: 113.82213687896729 and batch: 650, loss is 4.8531531143188475 and perplexity is 128.1438055720644
At time: 114.20080471038818 and batch: 700, loss is 4.8715636253356935 and perplexity is 130.5248493793375
At time: 114.57885503768921 and batch: 750, loss is 4.827867031097412 and perplexity is 124.94417419418411
At time: 114.95775556564331 and batch: 800, loss is 4.767727918624878 and perplexity is 117.65162398727806
At time: 115.33685898780823 and batch: 850, loss is 4.735085697174072 and perplexity is 113.8732169129712
At time: 115.71609711647034 and batch: 900, loss is 4.6839802455902095 and perplexity is 108.199878727109
At time: 116.0949649810791 and batch: 950, loss is 4.7540476036071775 and perplexity is 116.05307198706411
At time: 116.47433710098267 and batch: 1000, loss is 4.793954572677612 and perplexity is 120.77805108522927
At time: 116.85418033599854 and batch: 1050, loss is 4.689810619354248 and perplexity is 108.83256707381994
At time: 117.23580884933472 and batch: 1100, loss is 4.825932922363282 and perplexity is 124.70275211912725
At time: 117.61439204216003 and batch: 1150, loss is 4.7923711490631105 and perplexity is 120.58695959634129
At time: 117.99385786056519 and batch: 1200, loss is 4.713738861083985 and perplexity is 111.46814567657667
At time: 118.37366151809692 and batch: 1250, loss is 4.703142356872559 and perplexity is 110.29320910568289
At time: 118.75319004058838 and batch: 1300, loss is 4.768584566116333 and perplexity is 117.75245313718544
At time: 119.13283348083496 and batch: 1350, loss is 4.709365062713623 and perplexity is 110.98167112898673
At time: 119.51230120658875 and batch: 1400, loss is 4.618384513854981 and perplexity is 101.3302022948824
At time: 119.89168500900269 and batch: 1450, loss is 4.68976089477539 and perplexity is 108.82715555480003
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.104977860409989 and perplexity of 164.8404209919038
Finished 10 epochs...
Completing Train Step...
At time: 121.13751149177551 and batch: 50, loss is 4.862096738815308 and perplexity is 129.29501597380838
At time: 121.53118872642517 and batch: 100, loss is 4.850791826248169 and perplexity is 127.84157809612947
At time: 121.91203808784485 and batch: 150, loss is 4.756506881713867 and perplexity is 116.33883000140703
At time: 122.29255700111389 and batch: 200, loss is 4.788614616394043 and perplexity is 120.13482051247193
At time: 122.67192196846008 and batch: 250, loss is 4.820308828353882 and perplexity is 124.0033806269392
At time: 123.0534508228302 and batch: 300, loss is 4.845189485549927 and perplexity is 127.12736851097442
At time: 123.43445038795471 and batch: 350, loss is 4.8538981056213375 and perplexity is 128.2393071621935
At time: 123.81519484519958 and batch: 400, loss is 4.731980266571045 and perplexity is 113.52014005189658
At time: 124.1970751285553 and batch: 450, loss is 4.7761709594726565 and perplexity is 118.64916667543477
At time: 124.57715272903442 and batch: 500, loss is 4.781440420150757 and perplexity is 119.27603396946921
At time: 124.95884227752686 and batch: 550, loss is 4.825345306396485 and perplexity is 124.62949631612616
At time: 125.3401951789856 and batch: 600, loss is 4.71760066986084 and perplexity is 111.89944660472564
At time: 125.72044801712036 and batch: 650, loss is 4.8297747707366945 and perplexity is 125.18276265796538
At time: 126.10413861274719 and batch: 700, loss is 4.852631244659424 and perplexity is 128.07694865470899
At time: 126.50281929969788 and batch: 750, loss is 4.8094798183441165 and perplexity is 122.66779138326706
At time: 126.89029669761658 and batch: 800, loss is 4.748610334396362 and perplexity is 115.42377257745825
At time: 127.27193117141724 and batch: 850, loss is 4.7217641448974605 and perplexity is 112.36630836651948
At time: 127.65285348892212 and batch: 900, loss is 4.667207689285278 and perplexity is 106.40022475722829
At time: 128.03410577774048 and batch: 950, loss is 4.742605743408203 and perplexity is 114.73277668284109
At time: 128.4147870540619 and batch: 1000, loss is 4.781060571670532 and perplexity is 119.2307357530127
At time: 128.79569101333618 and batch: 1050, loss is 4.679981985092163 and perplexity is 107.76813112096312
At time: 129.1916801929474 and batch: 1100, loss is 4.811868219375611 and perplexity is 122.96112141817616
At time: 129.58283591270447 and batch: 1150, loss is 4.780038118362427 and perplexity is 119.10889019412643
At time: 129.963525056839 and batch: 1200, loss is 4.709947023391724 and perplexity is 111.04627689475798
At time: 130.34463739395142 and batch: 1250, loss is 4.699613180160522 and perplexity is 109.9046509291391
At time: 130.72563672065735 and batch: 1300, loss is 4.761167860031128 and perplexity is 116.88234844535843
At time: 131.10685539245605 and batch: 1350, loss is 4.709215955734253 and perplexity is 110.96512422089968
At time: 131.48834872245789 and batch: 1400, loss is 4.614972620010376 and perplexity is 100.9850635246367
At time: 131.86923551559448 and batch: 1450, loss is 4.692073068618774 and perplexity is 109.0790739846931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.104102501502404 and perplexity of 164.69618959738622
Finished 11 epochs...
Completing Train Step...
At time: 133.1270124912262 and batch: 50, loss is 4.840323858261108 and perplexity is 126.5103165074823
At time: 133.51556611061096 and batch: 100, loss is 4.8294469928741455 and perplexity is 125.141737243572
At time: 133.89680075645447 and batch: 150, loss is 4.7421830463409425 and perplexity is 114.68428972298844
At time: 134.27881264686584 and batch: 200, loss is 4.771049003601075 and perplexity is 118.04300457248702
At time: 134.65890955924988 and batch: 250, loss is 4.804863786697387 and perplexity is 122.10285785485168
At time: 135.0388252735138 and batch: 300, loss is 4.830771646499634 and perplexity is 125.30761654156254
At time: 135.41922116279602 and batch: 350, loss is 4.837783842086792 and perplexity is 126.18938601420247
At time: 135.79889917373657 and batch: 400, loss is 4.715853490829468 and perplexity is 111.70410893262931
At time: 136.1784679889679 and batch: 450, loss is 4.760821046829224 and perplexity is 116.84181913230474
At time: 136.56863713264465 and batch: 500, loss is 4.769184789657593 and perplexity is 117.82315214708194
At time: 136.9596402645111 and batch: 550, loss is 4.809719495773315 and perplexity is 122.69719560777497
At time: 137.339049577713 and batch: 600, loss is 4.702582235336304 and perplexity is 110.23144880221287
At time: 137.71919298171997 and batch: 650, loss is 4.814346256256104 and perplexity is 123.2662014555931
At time: 138.10606956481934 and batch: 700, loss is 4.837963438034057 and perplexity is 126.21205115174098
At time: 138.49753069877625 and batch: 750, loss is 4.796305952072143 and perplexity is 121.06238025773713
At time: 138.87675309181213 and batch: 800, loss is 4.734469270706176 and perplexity is 113.80304407849991
At time: 139.2565348148346 and batch: 850, loss is 4.709438781738282 and perplexity is 110.98985289110944
At time: 139.6507453918457 and batch: 900, loss is 4.6557965755462645 and perplexity is 105.19298078970746
At time: 140.0474202632904 and batch: 950, loss is 4.7343221855163575 and perplexity is 113.78630656710985
At time: 140.44550395011902 and batch: 1000, loss is 4.774580583572388 and perplexity is 118.46061987005578
At time: 140.8430106639862 and batch: 1050, loss is 4.674412002563477 and perplexity is 107.1695331511965
At time: 141.24385404586792 and batch: 1100, loss is 4.803741474151611 and perplexity is 121.96589715633728
At time: 141.63253903388977 and batch: 1150, loss is 4.769982280731202 and perplexity is 117.91715253643744
At time: 142.0266695022583 and batch: 1200, loss is 4.703154134750366 and perplexity is 110.29450813327259
At time: 142.41089010238647 and batch: 1250, loss is 4.693277778625489 and perplexity is 109.21056182310028
At time: 142.79144954681396 and batch: 1300, loss is 4.754351329803467 and perplexity is 116.0883256986533
At time: 143.17065691947937 and batch: 1350, loss is 4.704003114700317 and perplexity is 110.38818571883675
At time: 143.55962920188904 and batch: 1400, loss is 4.608208265304565 and perplexity is 100.30426989565335
At time: 143.94733452796936 and batch: 1450, loss is 4.683509454727173 and perplexity is 108.14895120187006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.103520841680021 and perplexity of 164.60042029627533
Finished 12 epochs...
Completing Train Step...
At time: 145.197039604187 and batch: 50, loss is 4.82507025718689 and perplexity is 124.59522178547957
At time: 145.57606101036072 and batch: 100, loss is 4.812872619628906 and perplexity is 123.08468564325571
At time: 145.95547914505005 and batch: 150, loss is 4.7275059795379635 and perplexity is 113.01335296217837
At time: 146.334858417511 and batch: 200, loss is 4.753923225402832 and perplexity is 116.03863841199126
At time: 146.71462035179138 and batch: 250, loss is 4.791382856369019 and perplexity is 120.46784325576938
At time: 147.09413123130798 and batch: 300, loss is 4.815709657669068 and perplexity is 123.43437738842923
At time: 147.4736409187317 and batch: 350, loss is 4.822699155807495 and perplexity is 124.30014385133335
At time: 147.85322618484497 and batch: 400, loss is 4.700993156433105 and perplexity is 110.05642143543143
At time: 148.24606919288635 and batch: 450, loss is 4.74775387763977 and perplexity is 115.32495942819767
At time: 148.63870358467102 and batch: 500, loss is 4.756703910827636 and perplexity is 116.3617543962916
At time: 149.0203640460968 and batch: 550, loss is 4.796495094299316 and perplexity is 121.08528043159261
At time: 149.39987659454346 and batch: 600, loss is 4.690482521057129 and perplexity is 108.90571643280322
At time: 149.7792477607727 and batch: 650, loss is 4.801830930709839 and perplexity is 121.73309846822181
At time: 150.15911722183228 and batch: 700, loss is 4.8258029747009275 and perplexity is 124.6865483408446
At time: 150.53927421569824 and batch: 750, loss is 4.783875341415405 and perplexity is 119.5668155924565
At time: 150.93161010742188 and batch: 800, loss is 4.722797880172729 and perplexity is 112.48252544172557
At time: 151.32570433616638 and batch: 850, loss is 4.698959035873413 and perplexity is 109.83278093884164
At time: 151.71909618377686 and batch: 900, loss is 4.645545625686646 and perplexity is 104.12016092386084
At time: 152.09983825683594 and batch: 950, loss is 4.725829181671142 and perplexity is 112.82401120130301
At time: 152.4792730808258 and batch: 1000, loss is 4.76539174079895 and perplexity is 117.37708967747918
At time: 152.85837364196777 and batch: 1050, loss is 4.667121753692627 and perplexity is 106.39108158372325
At time: 153.24908900260925 and batch: 1100, loss is 4.7938496780395505 and perplexity is 120.76538277970516
At time: 153.6427104473114 and batch: 1150, loss is 4.759369945526123 and perplexity is 116.67239277344021
At time: 154.03596949577332 and batch: 1200, loss is 4.695175638198853 and perplexity is 109.41802493902779
At time: 154.42920684814453 and batch: 1250, loss is 4.686300506591797 and perplexity is 108.45122216452266
At time: 154.81487655639648 and batch: 1300, loss is 4.744598293304444 and perplexity is 114.96161537566041
At time: 155.19369769096375 and batch: 1350, loss is 4.6960103225708005 and perplexity is 109.50939258072046
At time: 155.5731337070465 and batch: 1400, loss is 4.60058367729187 and perplexity is 99.54239932728633
At time: 155.95287919044495 and batch: 1450, loss is 4.6760569667816165 and perplexity is 107.34596827345167
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.103361211271367 and perplexity of 164.57414716097026
Finished 13 epochs...
Completing Train Step...
At time: 157.19133257865906 and batch: 50, loss is 4.810875062942505 and perplexity is 122.83906241129459
At time: 157.59087491035461 and batch: 100, loss is 4.799137535095215 and perplexity is 121.40566422757124
At time: 157.98888278007507 and batch: 150, loss is 4.714866600036621 and perplexity is 111.59392355541064
At time: 158.37764501571655 and batch: 200, loss is 4.740136413574219 and perplexity is 114.44981312340494
At time: 158.7571783065796 and batch: 250, loss is 4.779587440490722 and perplexity is 119.05522254731147
At time: 159.13714218139648 and batch: 300, loss is 4.802159299850464 and perplexity is 121.77307842488425
At time: 159.5170283317566 and batch: 350, loss is 4.808802251815796 and perplexity is 122.58470394553486
At time: 159.89652252197266 and batch: 400, loss is 4.6882797050476075 and perplexity is 108.6660812101695
At time: 160.27559447288513 and batch: 450, loss is 4.737378444671631 and perplexity is 114.13459897311914
At time: 160.6681776046753 and batch: 500, loss is 4.746055994033814 and perplexity is 115.12931720608765
At time: 161.04728722572327 and batch: 550, loss is 4.785181503295899 and perplexity is 119.72309124758921
At time: 161.4332981109619 and batch: 600, loss is 4.679381322860718 and perplexity is 107.70341831206109
At time: 161.81420302391052 and batch: 650, loss is 4.79127345085144 and perplexity is 120.45466412997406
At time: 162.1938853263855 and batch: 700, loss is 4.816058616638184 and perplexity is 123.47745843783834
At time: 162.57319521903992 and batch: 750, loss is 4.774295377731323 and perplexity is 118.42683902680855
At time: 162.9521622657776 and batch: 800, loss is 4.7137650299072265 and perplexity is 111.4710627049454
At time: 163.33088898658752 and batch: 850, loss is 4.690012722015381 and perplexity is 108.85456464805273
At time: 163.71212720870972 and batch: 900, loss is 4.636491270065307 and perplexity is 103.18167506338821
At time: 164.09175610542297 and batch: 950, loss is 4.7168395042419435 and perplexity is 111.81430500073819
At time: 164.47153282165527 and batch: 1000, loss is 4.75684175491333 and perplexity is 116.37779528148121
At time: 164.85100531578064 and batch: 1050, loss is 4.659546413421631 and perplexity is 105.58817791278409
At time: 165.23053622245789 and batch: 1100, loss is 4.7842057418823245 and perplexity is 119.60632705109904
At time: 165.6100378036499 and batch: 1150, loss is 4.749231243133545 and perplexity is 115.49546246046437
At time: 165.99038219451904 and batch: 1200, loss is 4.688160037994384 and perplexity is 108.65307823847493
At time: 166.37039065361023 and batch: 1250, loss is 4.680994091033935 and perplexity is 107.87725910202782
At time: 166.74991607666016 and batch: 1300, loss is 4.737805948257447 and perplexity is 114.18340235451281
At time: 167.1295018196106 and batch: 1350, loss is 4.689062948226929 and perplexity is 108.75122651748869
At time: 167.50838470458984 and batch: 1400, loss is 4.594064168930053 and perplexity is 98.89554270725235
At time: 167.8875014781952 and batch: 1450, loss is 4.667952089309693 and perplexity is 106.47945857430415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.103732117220887 and perplexity of 164.63520001302254
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 169.13078022003174 and batch: 50, loss is 4.799661941528321 and perplexity is 121.46934683523276
At time: 169.52529501914978 and batch: 100, loss is 4.778886022567749 and perplexity is 118.97174436036403
At time: 169.9065420627594 and batch: 150, loss is 4.688711957931519 and perplexity is 108.71306259034293
At time: 170.3029534816742 and batch: 200, loss is 4.704929904937744 and perplexity is 110.49053983475963
At time: 170.68318557739258 and batch: 250, loss is 4.748995151519775 and perplexity is 115.46819816891089
At time: 171.0635004043579 and batch: 300, loss is 4.760024375915528 and perplexity is 116.74877172250245
At time: 171.44487738609314 and batch: 350, loss is 4.765251111984253 and perplexity is 117.36058423708268
At time: 171.82580041885376 and batch: 400, loss is 4.644473361968994 and perplexity is 104.00857648768847
At time: 172.2066478729248 and batch: 450, loss is 4.701014652252197 and perplexity is 110.05878721378359
At time: 172.58806777000427 and batch: 500, loss is 4.69282304763794 and perplexity is 109.16091168605516
At time: 172.96988201141357 and batch: 550, loss is 4.736018257141113 and perplexity is 113.97946004772989
At time: 173.35076665878296 and batch: 600, loss is 4.63210298538208 and perplexity is 102.72987653442509
At time: 173.73417043685913 and batch: 650, loss is 4.74571102142334 and perplexity is 115.08960759474691
At time: 174.11522698402405 and batch: 700, loss is 4.763405160903931 and perplexity is 117.14414217201605
At time: 174.49616408348083 and batch: 750, loss is 4.71791030883789 and perplexity is 111.93410039971079
At time: 174.87770056724548 and batch: 800, loss is 4.659074411392212 and perplexity is 105.5383518384558
At time: 175.2591962814331 and batch: 850, loss is 4.630547590255738 and perplexity is 102.57021518556411
At time: 175.64031505584717 and batch: 900, loss is 4.576315727233887 and perplexity is 97.15578559179237
At time: 176.02181792259216 and batch: 950, loss is 4.655533685684204 and perplexity is 105.16533025617962
At time: 176.42105078697205 and batch: 1000, loss is 4.698850784301758 and perplexity is 109.82089201119493
At time: 176.82332634925842 and batch: 1050, loss is 4.596896991729737 and perplexity is 99.17609344306534
At time: 177.21406841278076 and batch: 1100, loss is 4.717384366989136 and perplexity is 111.87524505061016
At time: 177.5950002670288 and batch: 1150, loss is 4.678746242523193 and perplexity is 107.63503970405985
At time: 177.97465753555298 and batch: 1200, loss is 4.619681921005249 and perplexity is 101.46175414357941
At time: 178.3566653728485 and batch: 1250, loss is 4.609412279129028 and perplexity is 100.42511035545442
At time: 178.73707604408264 and batch: 1300, loss is 4.665781030654907 and perplexity is 106.24853618793657
At time: 179.11724472045898 and batch: 1350, loss is 4.607791252136231 and perplexity is 100.26245041450989
At time: 179.49855971336365 and batch: 1400, loss is 4.510755224227905 and perplexity is 90.99051080649203
At time: 179.89037537574768 and batch: 1450, loss is 4.587902326583862 and perplexity is 98.28803756197436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.05586438301282 and perplexity of 156.9401281122919
Finished 15 epochs...
Completing Train Step...
At time: 181.18066549301147 and batch: 50, loss is 4.766714191436767 and perplexity is 117.53241776881751
At time: 181.55999875068665 and batch: 100, loss is 4.754402103424073 and perplexity is 116.09422007289717
At time: 181.93953895568848 and batch: 150, loss is 4.665885801315308 and perplexity is 106.25966850039926
At time: 182.33084511756897 and batch: 200, loss is 4.687039194107055 and perplexity is 108.53136332434305
At time: 182.7214982509613 and batch: 250, loss is 4.730795755386352 and perplexity is 113.38575378304917
At time: 183.10060381889343 and batch: 300, loss is 4.744914836883545 and perplexity is 114.99801149702607
At time: 183.4799189567566 and batch: 350, loss is 4.753141164779663 and perplexity is 115.94792463858171
At time: 183.861652135849 and batch: 400, loss is 4.63382511138916 and perplexity is 102.90694274791409
At time: 184.24086570739746 and batch: 450, loss is 4.688303098678589 and perplexity is 108.66862333410819
At time: 184.61936116218567 and batch: 500, loss is 4.680790510177612 and perplexity is 107.85529959258577
At time: 185.00566816329956 and batch: 550, loss is 4.725874662399292 and perplexity is 112.82914263617505
At time: 185.4009952545166 and batch: 600, loss is 4.6223678874969485 and perplexity is 101.73464333695148
At time: 185.78713846206665 and batch: 650, loss is 4.736629390716553 and perplexity is 114.04913801177857
At time: 186.1667196750641 and batch: 700, loss is 4.755449008941651 and perplexity is 116.21582339493824
At time: 186.54669666290283 and batch: 750, loss is 4.711169843673706 and perplexity is 111.18214959139736
At time: 186.92976355552673 and batch: 800, loss is 4.653403625488282 and perplexity is 104.94156017868413
At time: 187.32814693450928 and batch: 850, loss is 4.626622543334961 and perplexity is 102.16841134360179
At time: 187.7150375843048 and batch: 900, loss is 4.5732769203186034 and perplexity is 96.86099604977474
At time: 188.11683082580566 and batch: 950, loss is 4.652885236740112 and perplexity is 104.88717375254578
At time: 188.50836205482483 and batch: 1000, loss is 4.696141395568848 and perplexity is 109.5237472458543
At time: 188.89782977104187 and batch: 1050, loss is 4.595593814849853 and perplexity is 99.04693362837438
At time: 189.2776927947998 and batch: 1100, loss is 4.716893301010132 and perplexity is 111.82032041078784
At time: 189.65728735923767 and batch: 1150, loss is 4.678980588912964 and perplexity is 107.66026654282119
At time: 190.05292057991028 and batch: 1200, loss is 4.620638294219971 and perplexity is 101.55883586333958
At time: 190.43188381195068 and batch: 1250, loss is 4.612838945388794 and perplexity is 100.76982396468634
At time: 190.81195068359375 and batch: 1300, loss is 4.6705668258666995 and perplexity is 106.75823861656123
At time: 191.19092178344727 and batch: 1350, loss is 4.611668300628662 and perplexity is 100.65192731929166
At time: 191.5703239440918 and batch: 1400, loss is 4.514332609176636 and perplexity is 91.31660181910132
At time: 191.94985628128052 and batch: 1450, loss is 4.591656589508057 and perplexity is 98.65773022479485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.054798093616453 and perplexity of 156.77287370446902
Finished 16 epochs...
Completing Train Step...
At time: 193.19648504257202 and batch: 50, loss is 4.759827299118042 and perplexity is 116.72576551553026
At time: 193.5778579711914 and batch: 100, loss is 4.747549791336059 and perplexity is 115.30142558505158
At time: 193.9567666053772 and batch: 150, loss is 4.659060955047607 and perplexity is 105.53693168757947
At time: 194.34910368919373 and batch: 200, loss is 4.680113859176636 and perplexity is 107.78234388171686
At time: 194.75024271011353 and batch: 250, loss is 4.723767337799072 and perplexity is 112.59162535917405
At time: 195.14425492286682 and batch: 300, loss is 4.7386730194091795 and perplexity is 114.28245042335722
At time: 195.52988147735596 and batch: 350, loss is 4.74803017616272 and perplexity is 115.35682794655648
At time: 195.90978479385376 and batch: 400, loss is 4.629783296585083 and perplexity is 102.49185136959908
At time: 196.28915214538574 and batch: 450, loss is 4.681929740905762 and perplexity is 107.97824168048092
At time: 196.68933582305908 and batch: 500, loss is 4.674888458251953 and perplexity is 107.22060685110897
At time: 197.07893633842468 and batch: 550, loss is 4.721157970428467 and perplexity is 112.29821541940073
At time: 197.45907711982727 and batch: 600, loss is 4.617749271392822 and perplexity is 101.26585348839659
At time: 197.85532140731812 and batch: 650, loss is 4.73231071472168 and perplexity is 113.55765877089077
At time: 198.23985838890076 and batch: 700, loss is 4.751035356521607 and perplexity is 115.70401744239967
At time: 198.61962056159973 and batch: 750, loss is 4.707507228851318 and perplexity is 110.77567703292152
At time: 198.9996736049652 and batch: 800, loss is 4.650183143615723 and perplexity is 104.60414140360325
At time: 199.37921571731567 and batch: 850, loss is 4.624423055648804 and perplexity is 101.94394013226444
At time: 199.79131245613098 and batch: 900, loss is 4.571647148132325 and perplexity is 96.70326326164663
At time: 200.1917543411255 and batch: 950, loss is 4.65116509437561 and perplexity is 104.706907967337
At time: 200.5920512676239 and batch: 1000, loss is 4.69460247039795 and perplexity is 109.35532801993838
At time: 200.97781944274902 and batch: 1050, loss is 4.59477876663208 and perplexity is 98.96623849132567
At time: 201.3567671775818 and batch: 1100, loss is 4.7162983608245845 and perplexity is 111.75381379430573
At time: 201.73585772514343 and batch: 1150, loss is 4.678407468795776 and perplexity is 107.5985819562709
At time: 202.11606550216675 and batch: 1200, loss is 4.620670423507691 and perplexity is 101.56209892881726
At time: 202.50261569023132 and batch: 1250, loss is 4.6140823078155515 and perplexity is 100.89519530240888
At time: 202.8985571861267 and batch: 1300, loss is 4.672545156478882 and perplexity is 106.96965076072541
At time: 203.28416872024536 and batch: 1350, loss is 4.612638988494873 and perplexity is 100.74967635807896
At time: 203.67767119407654 and batch: 1400, loss is 4.515043630599975 and perplexity is 91.38155296739386
At time: 204.0713334083557 and batch: 1450, loss is 4.591766214370727 and perplexity is 98.66854615775884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.054402147602831 and perplexity of 156.710812397356
Finished 17 epochs...
Completing Train Step...
At time: 205.33381152153015 and batch: 50, loss is 4.755159358978272 and perplexity is 116.18216636056258
At time: 205.73695492744446 and batch: 100, loss is 4.742804918289185 and perplexity is 114.75563084589368
At time: 206.11784648895264 and batch: 150, loss is 4.6543018245697025 and perplexity is 105.03586093572632
At time: 206.49952936172485 and batch: 200, loss is 4.674922180175781 and perplexity is 107.22422259721066
At time: 206.88031101226807 and batch: 250, loss is 4.718489685058594 and perplexity is 111.99897114623757
At time: 207.2621214389801 and batch: 300, loss is 4.73383394241333 and perplexity is 113.73076474776796
At time: 207.64227509498596 and batch: 350, loss is 4.744033203125 and perplexity is 114.89667004751048
At time: 208.03515529632568 and batch: 400, loss is 4.626820077896118 and perplexity is 102.18859512933267
At time: 208.43023419380188 and batch: 450, loss is 4.677434701919555 and perplexity is 107.49396451225734
At time: 208.81547617912292 and batch: 500, loss is 4.670341672897339 and perplexity is 106.73420438792355
At time: 209.19708251953125 and batch: 550, loss is 4.71737566947937 and perplexity is 111.87427201880529
At time: 209.59126734733582 and batch: 600, loss is 4.614319801330566 and perplexity is 100.91916010261903
At time: 209.97268199920654 and batch: 650, loss is 4.728946151733399 and perplexity is 113.17622890737952
At time: 210.35423278808594 and batch: 700, loss is 4.7476686668395995 and perplexity is 115.31513291479364
At time: 210.73487639427185 and batch: 750, loss is 4.704676513671875 and perplexity is 110.46254604384517
At time: 211.11623525619507 and batch: 800, loss is 4.6479039478302 and perplexity is 104.36599957438497
At time: 211.51253128051758 and batch: 850, loss is 4.622476043701172 and perplexity is 101.74564716486827
At time: 211.90621042251587 and batch: 900, loss is 4.570323047637939 and perplexity is 96.57530315766707
At time: 212.3018114566803 and batch: 950, loss is 4.649339742660523 and perplexity is 104.51595536414791
At time: 212.69538712501526 and batch: 1000, loss is 4.692893896102905 and perplexity is 109.16864584305573
At time: 213.07945728302002 and batch: 1050, loss is 4.59362156867981 and perplexity is 98.85178120044344
At time: 213.46019101142883 and batch: 1100, loss is 4.715021686553955 and perplexity is 111.6112316104588
At time: 213.84174489974976 and batch: 1150, loss is 4.677513809204101 and perplexity is 107.50246840425045
At time: 214.22247862815857 and batch: 1200, loss is 4.620061950683594 and perplexity is 101.50031994898208
At time: 214.60370349884033 and batch: 1250, loss is 4.614545183181763 and perplexity is 100.94190801313094
At time: 214.99546813964844 and batch: 1300, loss is 4.673398103713989 and perplexity is 107.06092915087352
At time: 215.38853073120117 and batch: 1350, loss is 4.612366313934326 and perplexity is 100.72220822945293
At time: 215.76998257637024 and batch: 1400, loss is 4.51448281288147 and perplexity is 91.33031894116289
At time: 216.15123891830444 and batch: 1450, loss is 4.591037998199463 and perplexity is 98.59672028240767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.054226345486111 and perplexity of 156.683264726364
Finished 18 epochs...
Completing Train Step...
At time: 217.40133690834045 and batch: 50, loss is 4.751611013412475 and perplexity is 115.7706424320689
At time: 217.8167781829834 and batch: 100, loss is 4.73901439666748 and perplexity is 114.32147051286128
At time: 218.20846819877625 and batch: 150, loss is 4.650330581665039 and perplexity is 104.61956517115934
At time: 218.58818078041077 and batch: 200, loss is 4.670724859237671 and perplexity is 106.77511131407832
At time: 218.96779894828796 and batch: 250, loss is 4.714151859283447 and perplexity is 111.51419132776955
At time: 219.36104011535645 and batch: 300, loss is 4.7295623397827145 and perplexity is 113.24598823732434
At time: 219.74088144302368 and batch: 350, loss is 4.740552740097046 and perplexity is 114.49747153618307
At time: 220.13733553886414 and batch: 400, loss is 4.624373140335083 and perplexity is 101.93885169550735
At time: 220.52886486053467 and batch: 450, loss is 4.673559579849243 and perplexity is 107.07821833180702
At time: 220.9087896347046 and batch: 500, loss is 4.6662548828125 and perplexity is 106.29889421623822
At time: 221.28918051719666 and batch: 550, loss is 4.713949975967407 and perplexity is 111.4916807453707
At time: 221.67502617835999 and batch: 600, loss is 4.611186513900757 and perplexity is 100.60344623628005
At time: 222.05854654312134 and batch: 650, loss is 4.72576343536377 and perplexity is 112.81659368302346
At time: 222.4381721019745 and batch: 700, loss is 4.74490364074707 and perplexity is 114.99672397080269
At time: 222.81765818595886 and batch: 750, loss is 4.701839647293091 and perplexity is 110.14962263167439
At time: 223.19766783714294 and batch: 800, loss is 4.645380487442017 and perplexity is 104.10296812288894
At time: 223.5777726173401 and batch: 850, loss is 4.62050931930542 and perplexity is 101.54573816581758
At time: 223.95674991607666 and batch: 900, loss is 4.5685937786102295 and perplexity is 96.4084427918873
At time: 224.33631038665771 and batch: 950, loss is 4.648042211532593 and perplexity is 104.38043060151061
At time: 224.71625924110413 and batch: 1000, loss is 4.691500473022461 and perplexity is 109.01663366551139
At time: 225.0962314605713 and batch: 1050, loss is 4.592615699768066 and perplexity is 98.752399257846
At time: 225.47584581375122 and batch: 1100, loss is 4.7138994026184085 and perplexity is 111.48604238026665
At time: 225.85685563087463 and batch: 1150, loss is 4.676217746734619 and perplexity is 107.36322874071709
At time: 226.23623085021973 and batch: 1200, loss is 4.619145956039429 and perplexity is 101.40738876825746
At time: 226.61574530601501 and batch: 1250, loss is 4.614482784271241 and perplexity is 100.93560954455573
At time: 226.995290517807 and batch: 1300, loss is 4.673422002792359 and perplexity is 107.06348783898464
At time: 227.37479329109192 and batch: 1350, loss is 4.611443567276001 and perplexity is 100.62931001573978
At time: 227.75353813171387 and batch: 1400, loss is 4.513551769256591 and perplexity is 91.24532600216124
At time: 228.13411712646484 and batch: 1450, loss is 4.589723472595215 and perplexity is 98.46719751824752
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.054333809094551 and perplexity of 156.70010338012875
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 229.39478707313538 and batch: 50, loss is 4.750251340866089 and perplexity is 115.61333923253142
At time: 229.77440667152405 and batch: 100, loss is 4.735034608840943 and perplexity is 113.86739946873408
At time: 230.15362763404846 and batch: 150, loss is 4.644028739929199 and perplexity is 103.96234226139404
At time: 230.5326805114746 and batch: 200, loss is 4.662898406982422 and perplexity is 105.94270265562184
At time: 230.9126079082489 and batch: 250, loss is 4.708485403060913 and perplexity is 110.88408795698636
At time: 231.29169869422913 and batch: 300, loss is 4.721436786651611 and perplexity is 112.32953034904212
At time: 231.672913312912 and batch: 350, loss is 4.730072259902954 and perplexity is 113.30374937079347
At time: 232.052166223526 and batch: 400, loss is 4.61381043434143 and perplexity is 100.86776830364553
At time: 232.43205285072327 and batch: 450, loss is 4.663584985733032 and perplexity is 106.01546563994852
At time: 232.81127834320068 and batch: 500, loss is 4.65171033859253 and perplexity is 104.76401437043096
At time: 233.1907196044922 and batch: 550, loss is 4.699838533401489 and perplexity is 109.9294210893364
At time: 233.5698127746582 and batch: 600, loss is 4.597445154190064 and perplexity is 99.23047295749528
At time: 233.94884943962097 and batch: 650, loss is 4.712195301055909 and perplexity is 111.29622062496068
At time: 234.33480882644653 and batch: 700, loss is 4.72947642326355 and perplexity is 113.23625895416467
At time: 234.71516132354736 and batch: 750, loss is 4.685642051696777 and perplexity is 108.37983543146866
At time: 235.09294414520264 and batch: 800, loss is 4.628261442184448 and perplexity is 102.33599232203305
At time: 235.47181153297424 and batch: 850, loss is 4.601373739242554 and perplexity is 99.62107506473546
At time: 235.85069704055786 and batch: 900, loss is 4.547939252853394 and perplexity is 94.4375956482783
At time: 236.22931122779846 and batch: 950, loss is 4.626642932891846 and perplexity is 102.17049453347428
At time: 236.60775756835938 and batch: 1000, loss is 4.671286497116089 and perplexity is 106.83509710463385
At time: 236.98752236366272 and batch: 1050, loss is 4.568038520812988 and perplexity is 96.3549261114592
At time: 237.36663222312927 and batch: 1100, loss is 4.6941627025604244 and perplexity is 109.30724763669116
At time: 237.74594283103943 and batch: 1150, loss is 4.651745624542237 and perplexity is 104.76771113339466
At time: 238.12564754486084 and batch: 1200, loss is 4.596835994720459 and perplexity is 99.17004418246879
At time: 238.50498819351196 and batch: 1250, loss is 4.591092491149903 and perplexity is 98.6020932549928
At time: 238.88354301452637 and batch: 1300, loss is 4.64611442565918 and perplexity is 104.17940131490377
At time: 239.26226019859314 and batch: 1350, loss is 4.583419876098633 and perplexity is 97.8484522460442
At time: 239.6409249305725 and batch: 1400, loss is 4.483562622070313 and perplexity is 88.54958008285783
At time: 240.02026462554932 and batch: 1450, loss is 4.560802898406982 and perplexity is 95.66025447074965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.04304439186031 and perplexity of 154.94099884818596
Finished 20 epochs...
Completing Train Step...
At time: 241.27150106430054 and batch: 50, loss is 4.740264415740967 and perplexity is 114.46446388511323
At time: 241.65110540390015 and batch: 100, loss is 4.727873468399048 and perplexity is 113.05489174259789
At time: 242.03066873550415 and batch: 150, loss is 4.636248273849487 and perplexity is 103.15660535285157
At time: 242.4098641872406 and batch: 200, loss is 4.656840715408325 and perplexity is 105.3028743362912
At time: 242.78903126716614 and batch: 250, loss is 4.701896991729736 and perplexity is 110.15593928084152
At time: 243.16875433921814 and batch: 300, loss is 4.716952724456787 and perplexity is 111.82696535706356
At time: 243.5485336780548 and batch: 350, loss is 4.72633487701416 and perplexity is 112.88108020689715
At time: 243.92807698249817 and batch: 400, loss is 4.610790452957153 and perplexity is 100.56360902993548
At time: 244.3074595928192 and batch: 450, loss is 4.659765062332153 and perplexity is 105.61126717697798
At time: 244.6874816417694 and batch: 500, loss is 4.647240734100341 and perplexity is 104.2968055582838
At time: 245.06695818901062 and batch: 550, loss is 4.696500492095947 and perplexity is 109.56308390553146
At time: 245.44692587852478 and batch: 600, loss is 4.594327936172485 and perplexity is 98.92163155238114
At time: 245.82592368125916 and batch: 650, loss is 4.709154663085937 and perplexity is 110.95832308299748
At time: 246.20513439178467 and batch: 700, loss is 4.727120151519776 and perplexity is 112.96975765486253
At time: 246.582946062088 and batch: 750, loss is 4.683036413192749 and perplexity is 108.09780435429253
At time: 246.96228551864624 and batch: 800, loss is 4.625967140197754 and perplexity is 102.10147178487829
At time: 247.34154677391052 and batch: 850, loss is 4.600025224685669 and perplexity is 99.48682513417529
At time: 247.72086906433105 and batch: 900, loss is 4.546378984451294 and perplexity is 94.29036254326789
At time: 248.100257396698 and batch: 950, loss is 4.625359888076782 and perplexity is 102.03948927099378
At time: 248.4991717338562 and batch: 1000, loss is 4.66988712310791 and perplexity is 106.6856994025947
At time: 248.8788924217224 and batch: 1050, loss is 4.568110237121582 and perplexity is 96.3618365788684
At time: 249.25867557525635 and batch: 1100, loss is 4.694601335525513 and perplexity is 109.3552039156612
At time: 249.63818907737732 and batch: 1150, loss is 4.652554588317871 and perplexity is 104.85249870697163
At time: 250.0174376964569 and batch: 1200, loss is 4.59822268486023 and perplexity is 99.30765769649719
At time: 250.3960554599762 and batch: 1250, loss is 4.592247085571289 and perplexity is 98.71600442975102
At time: 250.7754843235016 and batch: 1300, loss is 4.646722717285156 and perplexity is 104.242792050395
At time: 251.15423941612244 and batch: 1350, loss is 4.585118980407715 and perplexity is 98.01484829498283
At time: 251.53430914878845 and batch: 1400, loss is 4.485673570632935 and perplexity is 88.73670112361467
At time: 251.91338229179382 and batch: 1450, loss is 4.563346357345581 and perplexity is 95.90387208441652
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042594714042468 and perplexity of 154.87134098090237
Finished 21 epochs...
Completing Train Step...
At time: 253.14182662963867 and batch: 50, loss is 4.737690505981445 and perplexity is 114.1702215234906
At time: 253.53569769859314 and batch: 100, loss is 4.725635719299317 and perplexity is 112.802186111732
At time: 253.93094611167908 and batch: 150, loss is 4.6333043670654295 and perplexity is 102.85336849206114
At time: 254.3242893218994 and batch: 200, loss is 4.65424524307251 and perplexity is 105.02991801758687
At time: 254.70847916603088 and batch: 250, loss is 4.6992755794525145 and perplexity is 109.86755330361673
At time: 255.08788681030273 and batch: 300, loss is 4.7146924877166745 and perplexity is 111.57449536988078
At time: 255.4672336578369 and batch: 350, loss is 4.724793634414673 and perplexity is 112.7072370790359
At time: 255.8465757369995 and batch: 400, loss is 4.610008621215821 and perplexity is 100.4850159356642
At time: 256.2273349761963 and batch: 450, loss is 4.65820878982544 and perplexity is 105.44703509355668
At time: 256.6068105697632 and batch: 500, loss is 4.644939937591553 and perplexity is 104.0571156767353
At time: 256.98621249198914 and batch: 550, loss is 4.6949271392822265 and perplexity is 109.3908380564664
At time: 257.3671441078186 and batch: 600, loss is 4.59283405303955 and perplexity is 98.77396452162813
At time: 257.7469530105591 and batch: 650, loss is 4.707390985488892 and perplexity is 110.7628008441484
At time: 258.1447548866272 and batch: 700, loss is 4.725667228698731 and perplexity is 112.80574049686696
At time: 258.52660155296326 and batch: 750, loss is 4.681748075485229 and perplexity is 107.95862754945631
At time: 258.9081745147705 and batch: 800, loss is 4.624675369262695 and perplexity is 101.96966522147214
At time: 259.306352853775 and batch: 850, loss is 4.599453754425049 and perplexity is 99.42998761431062
At time: 259.69996404647827 and batch: 900, loss is 4.545362234115601 and perplexity is 94.19454150678973
At time: 260.09936141967773 and batch: 950, loss is 4.624338159561157 and perplexity is 101.93528585795012
At time: 260.4932870864868 and batch: 1000, loss is 4.6690233612060545 and perplexity is 106.5935881468016
At time: 260.89081025123596 and batch: 1050, loss is 4.56806056022644 and perplexity is 96.35704974091566
At time: 261.2718231678009 and batch: 1100, loss is 4.694854040145874 and perplexity is 109.3828419729365
At time: 261.656094789505 and batch: 1150, loss is 4.6531069946289065 and perplexity is 104.91043588994464
At time: 262.0508975982666 and batch: 1200, loss is 4.59901195526123 and perplexity is 99.3860692311909
At time: 262.44329357147217 and batch: 1250, loss is 4.592752561569214 and perplexity is 98.76591561399144
At time: 262.84486055374146 and batch: 1300, loss is 4.646884632110596 and perplexity is 104.25967187038286
At time: 263.24006748199463 and batch: 1350, loss is 4.585874748229981 and perplexity is 98.0889527627873
At time: 263.62297010421753 and batch: 1400, loss is 4.486688203811646 and perplexity is 88.82678201654736
At time: 264.0049629211426 and batch: 1450, loss is 4.564347248077393 and perplexity is 95.99990943456017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042526375534188 and perplexity of 154.86075766611256
Finished 22 epochs...
Completing Train Step...
At time: 265.24651622772217 and batch: 50, loss is 4.736012182235718 and perplexity is 113.97876763539622
At time: 265.65817642211914 and batch: 100, loss is 4.724012718200684 and perplexity is 112.61925652735776
At time: 266.0521502494812 and batch: 150, loss is 4.63130145072937 and perplexity is 102.64756796950431
At time: 266.4315547943115 and batch: 200, loss is 4.652265548706055 and perplexity is 104.82219656091861
At time: 266.81007194519043 and batch: 250, loss is 4.697492914199829 and perplexity is 109.6718707040518
At time: 267.190190076828 and batch: 300, loss is 4.713156824111938 and perplexity is 111.40328597179156
At time: 267.569787979126 and batch: 350, loss is 4.723803443908691 and perplexity is 112.59569067813248
At time: 267.9495794773102 and batch: 400, loss is 4.6096052551269535 and perplexity is 100.44449186136461
At time: 268.34191060066223 and batch: 450, loss is 4.657058868408203 and perplexity is 105.32584898012605
At time: 268.7205481529236 and batch: 500, loss is 4.643179883956909 and perplexity is 103.87413065104514
At time: 269.09963726997375 and batch: 550, loss is 4.693834104537964 and perplexity is 109.27133539194658
At time: 269.47883129119873 and batch: 600, loss is 4.59186014175415 and perplexity is 98.67781427138361
At time: 269.8586061000824 and batch: 650, loss is 4.706128959655762 and perplexity is 110.62310349750483
At time: 270.2378282546997 and batch: 700, loss is 4.724652051925659 and perplexity is 112.69128083746926
At time: 270.61760568618774 and batch: 750, loss is 4.680934972763062 and perplexity is 107.87088177351333
At time: 270.9969928264618 and batch: 800, loss is 4.623678159713745 and perplexity is 101.86803078144948
At time: 271.37638092041016 and batch: 850, loss is 4.598969602584839 and perplexity is 99.38186005429857
At time: 271.75504875183105 and batch: 900, loss is 4.54465760231018 and perplexity is 94.12819241553228
At time: 272.13376212120056 and batch: 950, loss is 4.6235306930541995 and perplexity is 101.85300975081346
At time: 272.51280760765076 and batch: 1000, loss is 4.6681124877929685 and perplexity is 106.4965390877671
At time: 272.89219307899475 and batch: 1050, loss is 4.567789735794068 and perplexity is 96.33095743099146
At time: 273.27151823043823 and batch: 1100, loss is 4.6950811004638675 and perplexity is 109.4076812957235
At time: 273.65074467658997 and batch: 1150, loss is 4.653449935913086 and perplexity is 104.9464201794491
At time: 274.02961826324463 and batch: 1200, loss is 4.599386501312256 and perplexity is 99.42330086299349
At time: 274.40984439849854 and batch: 1250, loss is 4.593252191543579 and perplexity is 98.81527435540433
At time: 274.789888381958 and batch: 1300, loss is 4.646862030029297 and perplexity is 104.25731541143358
At time: 275.16815543174744 and batch: 1350, loss is 4.586224622726441 and perplexity is 98.12327759008417
At time: 275.54774737358093 and batch: 1400, loss is 4.4871178817749025 and perplexity is 88.86495712824166
At time: 275.92758321762085 and batch: 1450, loss is 4.56473750114441 and perplexity is 96.03738100487237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042503422142094 and perplexity of 154.8572031272163
Finished 23 epochs...
Completing Train Step...
At time: 277.1822154521942 and batch: 50, loss is 4.734734268188476 and perplexity is 113.83320559484521
At time: 277.56156182289124 and batch: 100, loss is 4.722748203277588 and perplexity is 112.4769377978935
At time: 277.9548056125641 and batch: 150, loss is 4.629700622558594 and perplexity is 102.48337830581994
At time: 278.33474135398865 and batch: 200, loss is 4.650641345977784 and perplexity is 104.65208225074163
At time: 278.7141053676605 and batch: 250, loss is 4.695968427658081 and perplexity is 109.50480479037954
At time: 279.0937674045563 and batch: 300, loss is 4.711994791030884 and perplexity is 111.27390685412017
At time: 279.48875641822815 and batch: 350, loss is 4.722947063446045 and perplexity is 112.49930720480987
At time: 279.8795940876007 and batch: 400, loss is 4.609414100646973 and perplexity is 100.42529328176161
At time: 280.2730996608734 and batch: 450, loss is 4.6559046936035156 and perplexity is 105.20435466527648
At time: 280.66534066200256 and batch: 500, loss is 4.641455326080322 and perplexity is 103.69514807811953
At time: 281.0457835197449 and batch: 550, loss is 4.69283992767334 and perplexity is 109.16275434166077
At time: 281.43804597854614 and batch: 600, loss is 4.590943641662598 and perplexity is 98.58741747623279
At time: 281.8262722492218 and batch: 650, loss is 4.704928131103515 and perplexity is 110.49034384303194
At time: 282.2063627243042 and batch: 700, loss is 4.723694391250611 and perplexity is 112.58341248827239
At time: 282.58915281295776 and batch: 750, loss is 4.680176963806153 and perplexity is 107.78914566120557
At time: 282.9716160297394 and batch: 800, loss is 4.622816400527954 and perplexity is 101.78028288439361
At time: 283.3512659072876 and batch: 850, loss is 4.598542242050171 and perplexity is 99.33939724356048
At time: 283.7303442955017 and batch: 900, loss is 4.5440283870697025 and perplexity is 94.06898415163023
At time: 284.12336230278015 and batch: 950, loss is 4.6227663803100585 and perplexity is 101.77519193979239
At time: 284.5165493488312 and batch: 1000, loss is 4.667392816543579 and perplexity is 106.41992416251237
At time: 284.8989477157593 and batch: 1050, loss is 4.567632150650025 and perplexity is 96.31577829922313
At time: 285.2789258956909 and batch: 1100, loss is 4.695023193359375 and perplexity is 109.40134599712157
At time: 285.6585645675659 and batch: 1150, loss is 4.6535491943359375 and perplexity is 104.95683751259551
At time: 286.03859281539917 and batch: 1200, loss is 4.599642000198364 and perplexity is 99.44870665105428
At time: 286.4184572696686 and batch: 1250, loss is 4.593539228439331 and perplexity is 98.84364205610183
At time: 286.7974817752838 and batch: 1300, loss is 4.646694231033325 and perplexity is 104.23982260626343
At time: 287.17757201194763 and batch: 1350, loss is 4.586507577896118 and perplexity is 98.15104600716725
At time: 287.5575575828552 and batch: 1400, loss is 4.48700421333313 and perplexity is 88.85485656110542
At time: 287.9375240802765 and batch: 1450, loss is 4.564857215881347 and perplexity is 96.04887878288856
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042504465478098 and perplexity of 154.85736469539611
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 289.213552236557 and batch: 50, loss is 4.7338488674163814 and perplexity is 113.732462192446
At time: 289.6080801486969 and batch: 100, loss is 4.721235504150391 and perplexity is 112.30692265555544
At time: 289.98956871032715 and batch: 150, loss is 4.627570705413818 and perplexity is 102.26532949669276
At time: 290.37047839164734 and batch: 200, loss is 4.649372415542603 and perplexity is 104.51937025741988
At time: 290.7663230895996 and batch: 250, loss is 4.694632377624512 and perplexity is 109.35859858341573
At time: 291.14833331108093 and batch: 300, loss is 4.710841035842895 and perplexity is 111.14559803951289
At time: 291.5282504558563 and batch: 350, loss is 4.719645204544068 and perplexity is 112.12846294048742
At time: 291.90878105163574 and batch: 400, loss is 4.605832481384278 and perplexity is 100.0662514762208
At time: 292.30788350105286 and batch: 450, loss is 4.652843732833862 and perplexity is 104.8828206154562
At time: 292.69684052467346 and batch: 500, loss is 4.63623592376709 and perplexity is 103.15533136814253
At time: 293.0777463912964 and batch: 550, loss is 4.689075336456299 and perplexity is 108.75257376097207
At time: 293.4591553211212 and batch: 600, loss is 4.586876497268677 and perplexity is 98.18726250955017
At time: 293.84051966667175 and batch: 650, loss is 4.7012613582611085 and perplexity is 110.08594272749922
At time: 294.221887588501 and batch: 700, loss is 4.719088869094849 and perplexity is 112.06609925086134
At time: 294.6026861667633 and batch: 750, loss is 4.675583801269531 and perplexity is 107.29518787811656
At time: 294.98363161087036 and batch: 800, loss is 4.617087326049805 and perplexity is 101.19884320929121
At time: 295.3635804653168 and batch: 850, loss is 4.592834367752075 and perplexity is 98.77399560703675
At time: 295.75651383399963 and batch: 900, loss is 4.537815647125244 and perplexity is 93.48636970626012
At time: 296.15124106407166 and batch: 950, loss is 4.615053987503051 and perplexity is 100.99328076035675
At time: 296.53382658958435 and batch: 1000, loss is 4.660029315948487 and perplexity is 105.63917902399592
At time: 296.91455006599426 and batch: 1050, loss is 4.560668859481812 and perplexity is 95.64743313235724
At time: 297.3092267513275 and batch: 1100, loss is 4.689414834976196 and perplexity is 108.78950136687797
At time: 297.6901767253876 and batch: 1150, loss is 4.644404163360596 and perplexity is 104.00137948794811
At time: 298.07138562202454 and batch: 1200, loss is 4.592856550216675 and perplexity is 98.77618668199936
At time: 298.47127199172974 and batch: 1250, loss is 4.585516653060913 and perplexity is 98.05383387099208
At time: 298.86424350738525 and batch: 1300, loss is 4.636450643539429 and perplexity is 103.17748323554633
At time: 299.2453889846802 and batch: 1350, loss is 4.577882585525512 and perplexity is 97.30813426324725
At time: 299.6271724700928 and batch: 1400, loss is 4.476228790283203 and perplexity is 87.90254787046871
At time: 300.0235891342163 and batch: 1450, loss is 4.5545402526855465 and perplexity is 95.06304020997486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0390035515157585 and perplexity of 154.31617027547122
Finished 25 epochs...
Completing Train Step...
At time: 301.27775835990906 and batch: 50, loss is 4.730904588699341 and perplexity is 113.39809460181299
At time: 301.67214345932007 and batch: 100, loss is 4.719738073348999 and perplexity is 112.1388766603869
At time: 302.0525395870209 and batch: 150, loss is 4.625855903625489 and perplexity is 102.09011499879037
At time: 302.4518573284149 and batch: 200, loss is 4.648296127319336 and perplexity is 104.40693780582379
At time: 302.8415729999542 and batch: 250, loss is 4.6932092380523684 and perplexity is 109.20307672512153
At time: 303.22156381607056 and batch: 300, loss is 4.7097628211975096 and perplexity is 111.02582381070397
At time: 303.6011176109314 and batch: 350, loss is 4.718556509017945 and perplexity is 112.00645561100079
At time: 303.98135805130005 and batch: 400, loss is 4.604489336013794 and perplexity is 99.93193817514529
At time: 304.3615801334381 and batch: 450, loss is 4.651190586090088 and perplexity is 104.70957715995979
At time: 304.7415053844452 and batch: 500, loss is 4.634855213165284 and perplexity is 103.01300198894207
At time: 305.12625646591187 and batch: 550, loss is 4.688311796188355 and perplexity is 108.66956848463109
At time: 305.5064206123352 and batch: 600, loss is 4.5863007640838624 and perplexity is 98.13074911407692
At time: 305.8863377571106 and batch: 650, loss is 4.700980520248413 and perplexity is 110.05503075095008
At time: 306.26611399650574 and batch: 700, loss is 4.718331880569458 and perplexity is 111.98129860025236
At time: 306.6562252044678 and batch: 750, loss is 4.67480170249939 and perplexity is 107.21130525016085
At time: 307.04856610298157 and batch: 800, loss is 4.616494054794312 and perplexity is 101.13882265052258
At time: 307.42828154563904 and batch: 850, loss is 4.5924293899536135 and perplexity is 98.73400243047148
At time: 307.80876326560974 and batch: 900, loss is 4.537488107681274 and perplexity is 93.45575424686675
At time: 308.1884744167328 and batch: 950, loss is 4.615018463134765 and perplexity is 100.98969310158162
At time: 308.56706523895264 and batch: 1000, loss is 4.659894790649414 and perplexity is 105.62496883768013
At time: 308.9581775665283 and batch: 1050, loss is 4.561166944503785 and perplexity is 95.69508555268386
At time: 309.34605622291565 and batch: 1100, loss is 4.689714450836181 and perplexity is 108.82210131037355
At time: 309.7424132823944 and batch: 1150, loss is 4.644383411407471 and perplexity is 103.99922127858967
At time: 310.12979912757874 and batch: 1200, loss is 4.593304376602173 and perplexity is 98.82043117083978
At time: 310.5090718269348 and batch: 1250, loss is 4.585879697799682 and perplexity is 98.08943826209747
At time: 310.8889458179474 and batch: 1300, loss is 4.636739015579224 and perplexity is 103.20724102729919
At time: 311.2689266204834 and batch: 1350, loss is 4.578551578521728 and perplexity is 97.37325450360785
At time: 311.65105271339417 and batch: 1400, loss is 4.476805725097656 and perplexity is 87.95327654277578
At time: 312.0317678451538 and batch: 1450, loss is 4.555311832427979 and perplexity is 95.13641723052586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038821489383013 and perplexity of 154.28807770176823
Finished 26 epochs...
Completing Train Step...
At time: 313.2833375930786 and batch: 50, loss is 4.729640045166016 and perplexity is 113.25478840215331
At time: 313.7018930912018 and batch: 100, loss is 4.718686666488647 and perplexity is 112.02103503675549
At time: 314.0886175632477 and batch: 150, loss is 4.6249652671813966 and perplexity is 101.99923030041091
At time: 314.46861147880554 and batch: 200, loss is 4.647856512069702 and perplexity is 104.36104901124278
At time: 314.8483979701996 and batch: 250, loss is 4.692430477142334 and perplexity is 109.11806674323431
At time: 315.23021697998047 and batch: 300, loss is 4.709122533798218 and perplexity is 110.95475812838033
At time: 315.60804319381714 and batch: 350, loss is 4.717769260406494 and perplexity is 111.91831338382278
At time: 315.9868817329407 and batch: 400, loss is 4.60388487815857 and perplexity is 99.87155178248088
At time: 316.366929769516 and batch: 450, loss is 4.65012222290039 and perplexity is 104.59776903858865
At time: 316.7459542751312 and batch: 500, loss is 4.6340625 and perplexity is 102.93137458390385
At time: 317.1442937850952 and batch: 550, loss is 4.68787483215332 and perplexity is 108.6220941645412
At time: 317.52404737472534 and batch: 600, loss is 4.58600263595581 and perplexity is 98.10149793805503
At time: 317.90383076667786 and batch: 650, loss is 4.7008028411865235 and perplexity is 110.03547801343753
At time: 318.2831094264984 and batch: 700, loss is 4.717858257293702 and perplexity is 111.92827420857004
At time: 318.6630480289459 and batch: 750, loss is 4.674324388504028 and perplexity is 107.16014400466456
At time: 319.0428524017334 and batch: 800, loss is 4.616066598892212 and perplexity is 101.09559950250224
At time: 319.4226140975952 and batch: 850, loss is 4.592177124023437 and perplexity is 98.70909834686631
At time: 319.80235266685486 and batch: 900, loss is 4.537291078567505 and perplexity is 93.43734255630996
At time: 320.1819558143616 and batch: 950, loss is 4.614986410140991 and perplexity is 100.98645613145499
At time: 320.5621078014374 and batch: 1000, loss is 4.659884099960327 and perplexity is 105.62383964001444
At time: 320.94177746772766 and batch: 1050, loss is 4.561491613388061 and perplexity is 95.72615981349087
At time: 321.321236371994 and batch: 1100, loss is 4.689973173141479 and perplexity is 108.85025965773113
At time: 321.7021975517273 and batch: 1150, loss is 4.644433164596558 and perplexity is 104.00439570023175
At time: 322.090304851532 and batch: 1200, loss is 4.593655643463134 and perplexity is 98.85514961085771
At time: 322.4842755794525 and batch: 1250, loss is 4.586061973571777 and perplexity is 98.1073192197742
At time: 322.86387395858765 and batch: 1300, loss is 4.636966905593872 and perplexity is 103.23076360714747
At time: 323.24384331703186 and batch: 1350, loss is 4.579198036193848 and perplexity is 97.43622254193379
At time: 323.6231544017792 and batch: 1400, loss is 4.477089986801148 and perplexity is 87.97828184484999
At time: 324.02371287345886 and batch: 1450, loss is 4.555726804733276 and perplexity is 95.1759044013763
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038750542534722 and perplexity of 154.2771318372184
Finished 27 epochs...
Completing Train Step...
At time: 325.2957227230072 and batch: 50, loss is 4.728692560195923 and perplexity is 113.14753201228386
At time: 325.6893801689148 and batch: 100, loss is 4.71788667678833 and perplexity is 111.93145519875858
At time: 326.082955121994 and batch: 150, loss is 4.624262104034424 and perplexity is 101.92753341090344
At time: 326.4635908603668 and batch: 200, loss is 4.647551507949829 and perplexity is 104.329223315071
At time: 326.86088824272156 and batch: 250, loss is 4.691880836486816 and perplexity is 109.05810749702985
At time: 327.2404742240906 and batch: 300, loss is 4.708647699356079 and perplexity is 110.9020854940819
At time: 327.6205143928528 and batch: 350, loss is 4.717132606506348 and perplexity is 111.84708283012003
At time: 327.9995114803314 and batch: 400, loss is 4.6034257698059085 and perplexity is 99.82571044274049
At time: 328.37880277633667 and batch: 450, loss is 4.649335031509399 and perplexity is 104.51546297484724
At time: 328.7583518028259 and batch: 500, loss is 4.633454885482788 and perplexity is 102.86885098347737
At time: 329.13783383369446 and batch: 550, loss is 4.68760124206543 and perplexity is 108.59238030114646
At time: 329.51622581481934 and batch: 600, loss is 4.5857995414733885 and perplexity is 98.08157608818387
At time: 329.895405292511 and batch: 650, loss is 4.700669555664063 and perplexity is 110.02081285460969
At time: 330.27351331710815 and batch: 700, loss is 4.71758397102356 and perplexity is 111.89757802967662
At time: 330.65304684638977 and batch: 750, loss is 4.674037199020386 and perplexity is 107.12937315698426
At time: 331.03314876556396 and batch: 800, loss is 4.615699882507324 and perplexity is 101.05853288660768
At time: 331.41225481033325 and batch: 850, loss is 4.5919898319244385 and perplexity is 98.69061264381375
At time: 331.7918646335602 and batch: 900, loss is 4.537152528762817 and perplexity is 93.42439772752068
At time: 332.1715877056122 and batch: 950, loss is 4.614920740127563 and perplexity is 100.97982456727462
At time: 332.55152344703674 and batch: 1000, loss is 4.659857606887817 and perplexity is 105.62104137703952
At time: 332.93121576309204 and batch: 1050, loss is 4.561770000457764 and perplexity is 95.75281244831751
At time: 333.31124544143677 and batch: 1100, loss is 4.6901976680755615 and perplexity is 108.87469873271947
At time: 333.69082474708557 and batch: 1150, loss is 4.644418334960937 and perplexity is 104.00285336437672
At time: 334.07104301452637 and batch: 1200, loss is 4.59386420249939 and perplexity is 98.87576889568378
At time: 334.45051193237305 and batch: 1250, loss is 4.586175765991211 and perplexity is 98.11848372419833
At time: 334.83010268211365 and batch: 1300, loss is 4.637110328674316 and perplexity is 103.24557034304904
At time: 335.209529876709 and batch: 1350, loss is 4.579495096206665 and perplexity is 97.46517124698946
At time: 335.58977150917053 and batch: 1400, loss is 4.477214069366455 and perplexity is 87.98919909305869
At time: 335.96921849250793 and batch: 1450, loss is 4.555931053161621 and perplexity is 95.19534591564835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038727589142629 and perplexity of 154.27359069436102
Finished 28 epochs...
Completing Train Step...
At time: 337.2318787574768 and batch: 50, loss is 4.7278775882720945 and perplexity is 113.05535751535858
At time: 337.6135399341583 and batch: 100, loss is 4.717219219207764 and perplexity is 111.85677062764658
At time: 337.9948887825012 and batch: 150, loss is 4.623670301437378 and perplexity is 101.86723027745589
At time: 338.37612080574036 and batch: 200, loss is 4.6473369121551515 and perplexity is 104.30683710456486
At time: 338.75734639167786 and batch: 250, loss is 4.691441478729248 and perplexity is 109.01020249596293
At time: 339.1388189792633 and batch: 300, loss is 4.708239459991455 and perplexity is 110.85682013734328
At time: 339.53341364860535 and batch: 350, loss is 4.716562271118164 and perplexity is 111.78331066820593
At time: 339.9281346797943 and batch: 400, loss is 4.603036842346191 and perplexity is 99.78689303183135
At time: 340.31200766563416 and batch: 450, loss is 4.6486717796325685 and perplexity is 104.4461658811254
At time: 340.69280338287354 and batch: 500, loss is 4.632948360443115 and perplexity is 102.81675852883197
At time: 341.0735032558441 and batch: 550, loss is 4.6873651790618895 and perplexity is 108.56674868314838
At time: 341.45488357543945 and batch: 600, loss is 4.5856281280517575 and perplexity is 98.06476503048924
At time: 341.83618211746216 and batch: 650, loss is 4.700537967681885 and perplexity is 110.0063363903338
At time: 342.22690653800964 and batch: 700, loss is 4.7173524093627925 and perplexity is 111.87166984045967
At time: 342.60778164863586 and batch: 750, loss is 4.673812026977539 and perplexity is 107.10525333283853
At time: 342.989385843277 and batch: 800, loss is 4.61535873413086 and perplexity is 101.02406281222478
At time: 343.37085700035095 and batch: 850, loss is 4.59183705329895 and perplexity is 98.67553597939077
At time: 343.7580842971802 and batch: 900, loss is 4.536997547149658 and perplexity is 93.40991978558885
At time: 344.1401414871216 and batch: 950, loss is 4.614827222824097 and perplexity is 100.97038164792164
At time: 344.5216717720032 and batch: 1000, loss is 4.659802265167237 and perplexity is 105.61519628862034
At time: 344.90209102630615 and batch: 1050, loss is 4.562003574371338 and perplexity is 95.77518041964241
At time: 345.28187131881714 and batch: 1100, loss is 4.690388736724853 and perplexity is 108.8955032618317
At time: 345.66255617141724 and batch: 1150, loss is 4.644391736984253 and perplexity is 104.00008713569605
At time: 346.05777525901794 and batch: 1200, loss is 4.594010066986084 and perplexity is 98.89019241087401
At time: 346.43890595436096 and batch: 1250, loss is 4.586279735565186 and perplexity is 98.12868559148292
At time: 346.8204905986786 and batch: 1300, loss is 4.637204513549805 and perplexity is 103.2552949721859
At time: 347.2018699645996 and batch: 1350, loss is 4.579745769500732 and perplexity is 97.48960622499301
At time: 347.58230233192444 and batch: 1400, loss is 4.47726749420166 and perplexity is 87.9939000270923
At time: 347.96263575553894 and batch: 1450, loss is 4.556069173812866 and perplexity is 95.20849526689929
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038693159054487 and perplexity of 154.26827913247482
Finished 29 epochs...
Completing Train Step...
At time: 349.2014100551605 and batch: 50, loss is 4.727146682739257 and perplexity is 112.97275492005805
At time: 349.59357619285583 and batch: 100, loss is 4.71663722038269 and perplexity is 111.79168905910002
At time: 349.97322845458984 and batch: 150, loss is 4.623128490447998 and perplexity is 101.81205244196254
At time: 350.35298323631287 and batch: 200, loss is 4.647147998809815 and perplexity is 104.2871340121731
At time: 350.73300862312317 and batch: 250, loss is 4.691064310073853 and perplexity is 108.96909501717667
At time: 351.1123433113098 and batch: 300, loss is 4.7078588008880615 and perplexity is 110.8146295102173
At time: 351.4915792942047 and batch: 350, loss is 4.716018085479736 and perplexity is 111.72249634456593
At time: 351.8706841468811 and batch: 400, loss is 4.602646217346192 and perplexity is 99.7479213888854
At time: 352.2496409416199 and batch: 450, loss is 4.648070526123047 and perplexity is 104.38338613249668
At time: 352.6286189556122 and batch: 500, loss is 4.632473831176758 and perplexity is 102.76798054204448
At time: 353.0080614089966 and batch: 550, loss is 4.687118148803711 and perplexity is 108.5399327235046
At time: 353.3991551399231 and batch: 600, loss is 4.585480108261108 and perplexity is 98.0502505787389
At time: 353.7910952568054 and batch: 650, loss is 4.700393753051758 and perplexity is 109.99047301111284
At time: 354.17295575141907 and batch: 700, loss is 4.717137002944947 and perplexity is 111.8475745600331
At time: 354.5522270202637 and batch: 750, loss is 4.673598432540894 and perplexity is 107.08237868962638
At time: 354.93188285827637 and batch: 800, loss is 4.615033693313599 and perplexity is 100.99123120438068
At time: 355.31165742874146 and batch: 850, loss is 4.591687841415405 and perplexity is 98.66081351521811
At time: 355.7252426147461 and batch: 900, loss is 4.53684178352356 and perplexity is 93.39537105088071
At time: 356.11054134368896 and batch: 950, loss is 4.614727287292481 and perplexity is 100.96029162333853
At time: 356.4899160861969 and batch: 1000, loss is 4.659695739746094 and perplexity is 105.60394618457829
At time: 356.8697741031647 and batch: 1050, loss is 4.562180004119873 and perplexity is 95.7920795013463
At time: 357.24925088882446 and batch: 1100, loss is 4.690575523376465 and perplexity is 108.91584538802122
At time: 357.629088640213 and batch: 1150, loss is 4.644331302642822 and perplexity is 103.99380214883769
At time: 358.00814604759216 and batch: 1200, loss is 4.594113626480103 and perplexity is 98.90043395945911
At time: 358.38808035850525 and batch: 1250, loss is 4.58632040977478 and perplexity is 98.13267697938059
At time: 358.7725315093994 and batch: 1300, loss is 4.637227373123169 and perplexity is 103.25765537115528
At time: 359.16903376579285 and batch: 1350, loss is 4.57994701385498 and perplexity is 97.50922743210597
At time: 359.55327558517456 and batch: 1400, loss is 4.477255010604859 and perplexity is 87.99280155357981
At time: 359.9325952529907 and batch: 1450, loss is 4.556090402603149 and perplexity is 95.21051644953204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038662380642361 and perplexity of 154.26353107287088
Finished 30 epochs...
Completing Train Step...
At time: 361.17151165008545 and batch: 50, loss is 4.726419296264648 and perplexity is 112.8906099453235
At time: 361.5643038749695 and batch: 100, loss is 4.7161171340942385 and perplexity is 111.73356285108962
At time: 361.94410514831543 and batch: 150, loss is 4.62261396408081 and perplexity is 101.75968093090067
At time: 362.34100341796875 and batch: 200, loss is 4.646996898651123 and perplexity is 104.27137740011761
At time: 362.73391938209534 and batch: 250, loss is 4.690722093582154 and perplexity is 108.93181037584972
At time: 363.114928483963 and batch: 300, loss is 4.707504482269287 and perplexity is 110.77537277885533
At time: 363.4939486980438 and batch: 350, loss is 4.715538988113403 and perplexity is 111.6689832108314
At time: 363.87338066101074 and batch: 400, loss is 4.6022838306427 and perplexity is 99.7117806173362
At time: 364.26708722114563 and batch: 450, loss is 4.647465753555298 and perplexity is 104.32027700929171
At time: 364.6671073436737 and batch: 500, loss is 4.632010450363159 and perplexity is 102.72037086316682
At time: 365.0578017234802 and batch: 550, loss is 4.68689284324646 and perplexity is 108.51548082815575
At time: 365.4370355606079 and batch: 600, loss is 4.5853464221954345 and perplexity is 98.03714350263697
At time: 365.8301646709442 and batch: 650, loss is 4.700240106582641 and perplexity is 109.97357466151735
At time: 366.2289836406708 and batch: 700, loss is 4.716912679672241 and perplexity is 111.8224873599902
At time: 366.6187491416931 and batch: 750, loss is 4.673356504440307 and perplexity is 107.05647558661431
At time: 366.99823546409607 and batch: 800, loss is 4.614686460494995 and perplexity is 100.95616982209887
At time: 367.3781123161316 and batch: 850, loss is 4.59151707649231 and perplexity is 98.64396714741095
At time: 367.7693819999695 and batch: 900, loss is 4.5367162322998045 and perplexity is 93.38364588382214
At time: 368.1623914241791 and batch: 950, loss is 4.6146093845367435 and perplexity is 100.94838882843607
At time: 368.54403424263 and batch: 1000, loss is 4.6595575141906735 and perplexity is 105.58935002926643
At time: 368.92393946647644 and batch: 1050, loss is 4.562328634262085 and perplexity is 95.80631814986528
At time: 369.30280089378357 and batch: 1100, loss is 4.690700445175171 and perplexity is 108.92945220121081
At time: 369.6827871799469 and batch: 1150, loss is 4.644254179000854 and perplexity is 103.98578207734643
At time: 370.0628101825714 and batch: 1200, loss is 4.5942075729370115 and perplexity is 98.90972574127451
At time: 370.4414999485016 and batch: 1250, loss is 4.586323041915893 and perplexity is 98.13293527877414
At time: 370.82189679145813 and batch: 1300, loss is 4.6372470283508305 and perplexity is 103.25968494382518
At time: 371.20137071609497 and batch: 1350, loss is 4.580153760910034 and perplexity is 97.52938926184576
At time: 371.5801498889923 and batch: 1400, loss is 4.477212152481079 and perplexity is 87.98903042801138
At time: 371.96066308021545 and batch: 1450, loss is 4.556101655960083 and perplexity is 95.21158789348611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038638383914263 and perplexity of 154.25982929727573
Finished 31 epochs...
Completing Train Step...
At time: 373.22015833854675 and batch: 50, loss is 4.725756530761719 and perplexity is 112.8158147320285
At time: 373.6018068790436 and batch: 100, loss is 4.715612850189209 and perplexity is 111.67723161835298
At time: 373.98300790786743 and batch: 150, loss is 4.622161388397217 and perplexity is 101.71363739361972
At time: 374.3622636795044 and batch: 200, loss is 4.6468400955200195 and perplexity is 104.25502860346155
At time: 374.7428777217865 and batch: 250, loss is 4.690422878265381 and perplexity is 108.8992211855371
At time: 375.12393283843994 and batch: 300, loss is 4.707198686599732 and perplexity is 110.74150332839578
At time: 375.5196695327759 and batch: 350, loss is 4.715141000747681 and perplexity is 111.62454920904263
At time: 375.90223598480225 and batch: 400, loss is 4.601973915100098 and perplexity is 99.68088317478848
At time: 376.2837562561035 and batch: 450, loss is 4.646949825286865 and perplexity is 104.2664691111133
At time: 376.66487741470337 and batch: 500, loss is 4.631557216644287 and perplexity is 102.67382507633342
At time: 377.0468440055847 and batch: 550, loss is 4.6867074775695805 and perplexity is 108.49536764680451
At time: 377.4275505542755 and batch: 600, loss is 4.585228967666626 and perplexity is 98.0256292723536
At time: 377.80877113342285 and batch: 650, loss is 4.700115642547607 and perplexity is 109.95988775844913
At time: 378.1901788711548 and batch: 700, loss is 4.716771793365479 and perplexity is 111.80673421246053
At time: 378.5713574886322 and batch: 750, loss is 4.673118591308594 and perplexity is 107.03100847483756
At time: 378.9521403312683 and batch: 800, loss is 4.614406261444092 and perplexity is 100.92788596187236
At time: 379.3335225582123 and batch: 850, loss is 4.5913910484313964 and perplexity is 98.63153602286226
At time: 379.71476674079895 and batch: 900, loss is 4.536598520278931 and perplexity is 93.3726541530907
At time: 380.0960302352905 and batch: 950, loss is 4.614501142501831 and perplexity is 100.93746256075957
At time: 380.47682547569275 and batch: 1000, loss is 4.65949107170105 and perplexity is 105.58233464303515
At time: 380.8572413921356 and batch: 1050, loss is 4.562445650100708 and perplexity is 95.81752966247848
At time: 381.23733711242676 and batch: 1100, loss is 4.690830278396606 and perplexity is 108.94359578103267
At time: 381.6179118156433 and batch: 1150, loss is 4.644217262268066 and perplexity is 103.9819433328731
At time: 381.999187707901 and batch: 1200, loss is 4.594280509948731 and perplexity is 98.9169401841968
At time: 382.3793852329254 and batch: 1250, loss is 4.5862958621978756 and perplexity is 98.13026808951193
At time: 382.76007056236267 and batch: 1300, loss is 4.637263555526733 and perplexity is 103.26139154890453
At time: 383.1406395435333 and batch: 1350, loss is 4.580327672958374 and perplexity is 97.54635227269888
At time: 383.52164936065674 and batch: 1400, loss is 4.477157869338989 and perplexity is 87.98425423660481
At time: 383.9041929244995 and batch: 1450, loss is 4.556085195541382 and perplexity is 95.2100206837827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038631602230235 and perplexity of 154.25878315940255
Finished 32 epochs...
Completing Train Step...
At time: 385.165828704834 and batch: 50, loss is 4.725164766311646 and perplexity is 112.74907409278055
At time: 385.5448794364929 and batch: 100, loss is 4.715144100189209 and perplexity is 111.62489518334219
At time: 385.9247422218323 and batch: 150, loss is 4.621741905212402 and perplexity is 101.67097918089374
At time: 386.3215115070343 and batch: 200, loss is 4.646690721511841 and perplexity is 104.23945677500845
At time: 386.71311473846436 and batch: 250, loss is 4.690146398544312 and perplexity is 108.86911692104015
At time: 387.09219551086426 and batch: 300, loss is 4.706903791427612 and perplexity is 110.70885100845332
At time: 387.4710018634796 and batch: 350, loss is 4.714767065048218 and perplexity is 111.58281660829776
At time: 387.8506407737732 and batch: 400, loss is 4.6016945552825925 and perplexity is 99.65304023073695
At time: 388.23026156425476 and batch: 450, loss is 4.646475887298584 and perplexity is 104.21706497866991
At time: 388.6102068424225 and batch: 500, loss is 4.631099529266358 and perplexity is 102.62684331485197
At time: 388.9973931312561 and batch: 550, loss is 4.68648398399353 and perplexity is 108.47112233854047
At time: 389.3918924331665 and batch: 600, loss is 4.58508828163147 and perplexity is 98.01183940527122
At time: 389.7757451534271 and batch: 650, loss is 4.699875345230103 and perplexity is 109.93346786682933
At time: 390.1556830406189 and batch: 700, loss is 4.716449604034424 and perplexity is 111.77071707803701
At time: 390.5350501537323 and batch: 750, loss is 4.672889223098755 and perplexity is 107.00646177924989
At time: 390.91499185562134 and batch: 800, loss is 4.614209127426148 and perplexity is 100.90799160318194
At time: 391.29451990127563 and batch: 850, loss is 4.5911796760559085 and perplexity is 98.61069024398361
At time: 391.67387437820435 and batch: 900, loss is 4.536398010253906 and perplexity is 93.35393387673413
At time: 392.05393719673157 and batch: 950, loss is 4.61430811882019 and perplexity is 100.91798112037075
At time: 392.4332444667816 and batch: 1000, loss is 4.659406757354736 and perplexity is 105.57343291278451
At time: 392.81217980384827 and batch: 1050, loss is 4.562458076477051 and perplexity is 95.81872033456017
At time: 393.1922528743744 and batch: 1100, loss is 4.69096248626709 and perplexity is 108.95799993398388
At time: 393.5779142379761 and batch: 1150, loss is 4.644137325286866 and perplexity is 103.97363166243305
At time: 393.95758080482483 and batch: 1200, loss is 4.5943238639831545 and perplexity is 98.92122872558876
At time: 394.3375380039215 and batch: 1250, loss is 4.586237516403198 and perplexity is 98.12454276806417
At time: 394.71756625175476 and batch: 1300, loss is 4.63723482131958 and perplexity is 103.25842445731755
At time: 395.0982871055603 and batch: 1350, loss is 4.580523357391358 and perplexity is 97.56544244309667
At time: 395.4780502319336 and batch: 1400, loss is 4.477088537216186 and perplexity is 87.97815431294813
At time: 395.8577654361725 and batch: 1450, loss is 4.55602237701416 and perplexity is 95.20403991836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038621690538195 and perplexity of 154.25725420142663
Finished 33 epochs...
Completing Train Step...
At time: 397.14198660850525 and batch: 50, loss is 4.7246152210235595 and perplexity is 112.68713039237004
At time: 397.5440490245819 and batch: 100, loss is 4.714669065475464 and perplexity is 111.57188207574201
At time: 397.92316198349 and batch: 150, loss is 4.621327896118164 and perplexity is 101.62889518307276
At time: 398.30249524116516 and batch: 200, loss is 4.646536674499512 and perplexity is 104.22340023488819
At time: 398.68225741386414 and batch: 250, loss is 4.689884910583496 and perplexity is 108.84065267935108
At time: 399.0632703304291 and batch: 300, loss is 4.706626186370849 and perplexity is 110.67812193705515
At time: 399.4573163986206 and batch: 350, loss is 4.714385137557984 and perplexity is 111.54020820037641
At time: 399.84892439842224 and batch: 400, loss is 4.601434154510498 and perplexity is 99.62709388049073
At time: 400.2483160495758 and batch: 450, loss is 4.646039981842041 and perplexity is 104.17164609127042
At time: 400.63603496551514 and batch: 500, loss is 4.630702714920044 and perplexity is 102.58612758993394
At time: 401.0155255794525 and batch: 550, loss is 4.686317720413208 and perplexity is 108.45308904056078
At time: 401.3953957557678 and batch: 600, loss is 4.584972696304321 and perplexity is 98.00051132944141
At time: 401.77911043167114 and batch: 650, loss is 4.699750719070434 and perplexity is 109.91976813460029
At time: 402.16191267967224 and batch: 700, loss is 4.716288299560547 and perplexity is 111.75268941533425
At time: 402.5552418231964 and batch: 750, loss is 4.6727265453338624 and perplexity is 106.98905562305426
At time: 402.9342978000641 and batch: 800, loss is 4.613938808441162 and perplexity is 100.88071794377488
At time: 403.31387186050415 and batch: 850, loss is 4.591065006256104 and perplexity is 98.59938322417395
At time: 403.6918296813965 and batch: 900, loss is 4.536244306564331 and perplexity is 93.33958613533957
At time: 404.06977677345276 and batch: 950, loss is 4.614173069000244 and perplexity is 100.90435308544362
At time: 404.4493820667267 and batch: 1000, loss is 4.659304943084717 and perplexity is 105.56268457795528
At time: 404.84180545806885 and batch: 1050, loss is 4.562525043487549 and perplexity is 95.82513724266889
At time: 405.2204644680023 and batch: 1100, loss is 4.6910292911529545 and perplexity is 108.96527910387289
At time: 405.59989190101624 and batch: 1150, loss is 4.644020042419434 and perplexity is 103.96143805183914
At time: 405.98017024993896 and batch: 1200, loss is 4.594351854324341 and perplexity is 98.92399760328207
At time: 406.36200618743896 and batch: 1250, loss is 4.586220216751099 and perplexity is 98.12284526229506
At time: 406.742311000824 and batch: 1300, loss is 4.637257490158081 and perplexity is 103.26076523239671
At time: 407.14478278160095 and batch: 1350, loss is 4.580648384094238 and perplexity is 97.57764149126791
At time: 407.5328049659729 and batch: 1400, loss is 4.476982355117798 and perplexity is 87.9688131038542
At time: 407.912739276886 and batch: 1450, loss is 4.556010313034058 and perplexity is 95.20289138564473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0386169955261755 and perplexity of 154.2565299634643
Finished 34 epochs...
Completing Train Step...
At time: 409.25985407829285 and batch: 50, loss is 4.724078979492187 and perplexity is 112.62671907197961
At time: 409.6664514541626 and batch: 100, loss is 4.714202709197998 and perplexity is 111.51986195904414
At time: 410.0457923412323 and batch: 150, loss is 4.620937089920044 and perplexity is 101.58918574078068
At time: 410.425288438797 and batch: 200, loss is 4.6463861083984375 and perplexity is 104.20770890519495
At time: 410.80479526519775 and batch: 250, loss is 4.689695596694946 and perplexity is 108.82004958244781
At time: 411.18527579307556 and batch: 300, loss is 4.706401824951172 and perplexity is 110.65329282194203
At time: 411.564551115036 and batch: 350, loss is 4.714040155410767 and perplexity is 111.50173545643688
At time: 411.9437611103058 and batch: 400, loss is 4.6011427307128905 and perplexity is 99.59806440459298
At time: 412.3238203525543 and batch: 450, loss is 4.645585813522339 and perplexity is 104.12434537186178
At time: 412.70335125923157 and batch: 500, loss is 4.63031681060791 and perplexity is 102.54654679862206
At time: 413.10432863235474 and batch: 550, loss is 4.68614953994751 and perplexity is 108.43485088323345
At time: 413.5038740634918 and batch: 600, loss is 4.584803771972656 and perplexity is 97.98395805672689
At time: 413.90058994293213 and batch: 650, loss is 4.699590606689453 and perplexity is 109.90217002768236
At time: 414.28898572921753 and batch: 700, loss is 4.716141881942749 and perplexity is 111.73632805059287
At time: 414.6816418170929 and batch: 750, loss is 4.6725767993927 and perplexity is 106.97303564571911
At time: 415.0603721141815 and batch: 800, loss is 4.61364369392395 and perplexity is 100.85095097195169
At time: 415.43893361091614 and batch: 850, loss is 4.59093297958374 and perplexity is 98.58636633501693
At time: 415.81844758987427 and batch: 900, loss is 4.536084289550781 and perplexity is 93.32465140845727
At time: 416.19779229164124 and batch: 950, loss is 4.614038257598877 and perplexity is 100.89075094508257
At time: 416.5774121284485 and batch: 1000, loss is 4.659189939498901 and perplexity is 105.55054518875055
At time: 416.9565954208374 and batch: 1050, loss is 4.562593030929565 and perplexity is 95.83165237010182
At time: 417.33654594421387 and batch: 1100, loss is 4.691118183135987 and perplexity is 108.97496567413694
At time: 417.715469121933 and batch: 1150, loss is 4.643927173614502 and perplexity is 103.95178372562812
At time: 418.09417819976807 and batch: 1200, loss is 4.594394731521606 and perplexity is 98.92823927797653
At time: 418.4725260734558 and batch: 1250, loss is 4.586213245391845 and perplexity is 98.12216121507413
At time: 418.8683068752289 and batch: 1300, loss is 4.637242450714111 and perplexity is 103.25921225958163
At time: 419.2524793148041 and batch: 1350, loss is 4.580769033432007 and perplexity is 97.58941487930628
At time: 419.6311979293823 and batch: 1400, loss is 4.476902933120727 and perplexity is 87.96182672247743
At time: 420.01009368896484 and batch: 1450, loss is 4.555950632095337 and perplexity is 95.19720975726206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038602388822115 and perplexity of 154.2542768004374
Finished 35 epochs...
Completing Train Step...
At time: 421.2713289260864 and batch: 50, loss is 4.723620357513428 and perplexity is 112.57507782602802
At time: 421.65192556381226 and batch: 100, loss is 4.713757915496826 and perplexity is 111.47026965687859
At time: 422.03288078308105 and batch: 150, loss is 4.620560817718506 and perplexity is 101.55096774484511
At time: 422.4140384197235 and batch: 200, loss is 4.646247463226318 and perplexity is 104.19326201097687
At time: 422.79485535621643 and batch: 250, loss is 4.689497604370117 and perplexity is 108.79850618062741
At time: 423.17615938186646 and batch: 300, loss is 4.706188888549804 and perplexity is 110.62973321640689
At time: 423.55669617652893 and batch: 350, loss is 4.7136925601959225 and perplexity is 111.4629847219205
At time: 423.9374580383301 and batch: 400, loss is 4.600910758972168 and perplexity is 99.57496314774339
At time: 424.33156085014343 and batch: 450, loss is 4.645156955718994 and perplexity is 104.07970040768573
At time: 424.71192598342896 and batch: 500, loss is 4.629943294525146 and perplexity is 102.50825116662334
At time: 425.09347891807556 and batch: 550, loss is 4.685996341705322 and perplexity is 108.41824012708803
At time: 425.4743843078613 and batch: 600, loss is 4.584683256149292 and perplexity is 97.97215015087922
At time: 425.8659510612488 and batch: 650, loss is 4.699453201293945 and perplexity is 109.88706991398483
At time: 426.26116919517517 and batch: 700, loss is 4.715932693481445 and perplexity is 111.71295654466608
At time: 426.64514780044556 and batch: 750, loss is 4.67237922668457 and perplexity is 106.95190278107711
At time: 427.0260760784149 and batch: 800, loss is 4.613381843566895 and perplexity is 100.82454657158205
At time: 427.4074854850769 and batch: 850, loss is 4.5907785606384275 and perplexity is 98.57114390765113
At time: 427.7882936000824 and batch: 900, loss is 4.5359491443634035 and perplexity is 93.31203988316837
At time: 428.16947650909424 and batch: 950, loss is 4.6138960552215575 and perplexity is 100.87640506048224
At time: 428.55512523651123 and batch: 1000, loss is 4.659073657989502 and perplexity is 105.53827232560546
At time: 428.94801473617554 and batch: 1050, loss is 4.562665510177612 and perplexity is 95.83859842792418
At time: 429.3288221359253 and batch: 1100, loss is 4.6911803817749025 and perplexity is 108.98174397947625
At time: 429.70987462997437 and batch: 1150, loss is 4.643844575881958 and perplexity is 103.94319789858825
At time: 430.09094619750977 and batch: 1200, loss is 4.594432945251465 and perplexity is 98.93201976722052
At time: 430.4723391532898 and batch: 1250, loss is 4.586198825836181 and perplexity is 98.1207463473095
At time: 430.85302090644836 and batch: 1300, loss is 4.637236595153809 and perplexity is 103.25860762080772
At time: 431.234402179718 and batch: 1350, loss is 4.580914945602417 and perplexity is 97.60365540154787
At time: 431.6158194541931 and batch: 1400, loss is 4.47682858467102 and perplexity is 87.95528714013413
At time: 431.99646258354187 and batch: 1450, loss is 4.555880470275879 and perplexity is 95.19053078212539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0386091705061435 and perplexity of 154.25532290774987
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 433.24908804893494 and batch: 50, loss is 4.723037433624268 and perplexity is 112.50947424664363
At time: 433.64518666267395 and batch: 100, loss is 4.713756694793701 and perplexity is 111.47013358485509
At time: 434.04339575767517 and batch: 150, loss is 4.620433807373047 and perplexity is 101.53807054040671
At time: 434.42224860191345 and batch: 200, loss is 4.645741300582886 and perplexity is 104.14053661898711
At time: 434.8018493652344 and batch: 250, loss is 4.690026931762695 and perplexity is 108.85611145490019
At time: 435.1812365055084 and batch: 300, loss is 4.705680742263794 and perplexity is 110.57353140892981
At time: 435.5603325366974 and batch: 350, loss is 4.71302734375 and perplexity is 111.38886236780974
At time: 435.94015097618103 and batch: 400, loss is 4.599516916275024 and perplexity is 99.43626799460947
At time: 436.32044506073 and batch: 450, loss is 4.6441074657440184 and perplexity is 103.97052710367403
At time: 436.700071811676 and batch: 500, loss is 4.628506841659546 and perplexity is 102.36110860246748
At time: 437.07944774627686 and batch: 550, loss is 4.684516067504883 and perplexity is 108.25787012844036
At time: 437.45880246162415 and batch: 600, loss is 4.583014335632324 and perplexity is 97.80877878423358
At time: 437.83698439598083 and batch: 650, loss is 4.698337879180908 and perplexity is 109.76457875621904
At time: 438.21636033058167 and batch: 700, loss is 4.714251832962036 and perplexity is 111.5253403689875
At time: 438.59606742858887 and batch: 750, loss is 4.671127767562866 and perplexity is 106.81814056318962
At time: 438.9907217025757 and batch: 800, loss is 4.611251220703125 and perplexity is 100.60995617420964
At time: 439.3742792606354 and batch: 850, loss is 4.5885584259033205 and perplexity is 98.35254543600179
At time: 439.75339794158936 and batch: 900, loss is 4.534167108535766 and perplexity is 93.14590256024371
At time: 440.13312125205994 and batch: 950, loss is 4.611350002288819 and perplexity is 100.61989507609924
At time: 440.5226216316223 and batch: 1000, loss is 4.657513914108276 and perplexity is 105.37378796119735
At time: 440.909015417099 and batch: 1050, loss is 4.559878616333008 and perplexity is 95.5718782609154
At time: 441.28781819343567 and batch: 1100, loss is 4.6894078540802 and perplexity is 108.78874192133433
At time: 441.66729259490967 and batch: 1150, loss is 4.641028776168823 and perplexity is 103.65092635394065
At time: 442.0468611717224 and batch: 1200, loss is 4.592085094451904 and perplexity is 98.7000146088317
At time: 442.4260218143463 and batch: 1250, loss is 4.584227294921875 and perplexity is 97.92748883173242
At time: 442.8099105358124 and batch: 1300, loss is 4.634094400405884 and perplexity is 102.93465818890516
At time: 443.18956780433655 and batch: 1350, loss is 4.578043966293335 and perplexity is 97.32383919187271
At time: 443.5691351890564 and batch: 1400, loss is 4.473321580886841 and perplexity is 87.64736786791502
At time: 443.94805097579956 and batch: 1450, loss is 4.552338304519654 and perplexity is 94.85394661405417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038134974292201 and perplexity of 154.18219295798954
Finished 37 epochs...
Completing Train Step...
At time: 445.1898498535156 and batch: 50, loss is 4.722452936172485 and perplexity is 112.44373196061605
At time: 445.5822744369507 and batch: 100, loss is 4.7134067153930665 and perplexity is 111.43112816026013
At time: 445.96154499053955 and batch: 150, loss is 4.620242414474487 and perplexity is 101.51863873438595
At time: 446.3652882575989 and batch: 200, loss is 4.64555513381958 and perplexity is 104.12115091689853
At time: 446.7558124065399 and batch: 250, loss is 4.689767580032349 and perplexity is 108.82788309473088
At time: 447.1355211734772 and batch: 300, loss is 4.7053162956237795 and perplexity is 110.53324059930439
At time: 447.5147726535797 and batch: 350, loss is 4.712711753845215 and perplexity is 111.35371471375507
At time: 447.8990755081177 and batch: 400, loss is 4.599283266067505 and perplexity is 99.4130374039794
At time: 448.3013758659363 and batch: 450, loss is 4.643804683685302 and perplexity is 103.93905145880254
At time: 448.69650506973267 and batch: 500, loss is 4.628136320114136 and perplexity is 102.32318863183504
At time: 449.07465171813965 and batch: 550, loss is 4.684277849197388 and perplexity is 108.23208419330818
At time: 449.4537925720215 and batch: 600, loss is 4.582842950820923 and perplexity is 97.79201728150278
At time: 449.8334047794342 and batch: 650, loss is 4.698200025558472 and perplexity is 109.74944835433661
At time: 450.21347212791443 and batch: 700, loss is 4.713925886154175 and perplexity is 111.48899496395471
At time: 450.59298825263977 and batch: 750, loss is 4.670881099700928 and perplexity is 106.79179521025023
At time: 450.97954535484314 and batch: 800, loss is 4.61115138053894 and perplexity is 100.59991176109283
At time: 451.3806667327881 and batch: 850, loss is 4.588497247695923 and perplexity is 98.34652858763087
At time: 451.77368235588074 and batch: 900, loss is 4.53411075592041 and perplexity is 93.14065369291981
At time: 452.15856552124023 and batch: 950, loss is 4.611297855377197 and perplexity is 100.6146481961288
At time: 452.5508108139038 and batch: 1000, loss is 4.657467832565308 and perplexity is 105.36893228633906
At time: 452.94360733032227 and batch: 1050, loss is 4.559950523376465 and perplexity is 95.57875079920773
At time: 453.32249331474304 and batch: 1100, loss is 4.68940432548523 and perplexity is 108.78835805060396
At time: 453.7250270843506 and batch: 1150, loss is 4.641004028320313 and perplexity is 103.64836124825787
At time: 454.1174466609955 and batch: 1200, loss is 4.592211055755615 and perplexity is 98.71244777438055
At time: 454.50100445747375 and batch: 1250, loss is 4.584482126235962 and perplexity is 97.95244700232328
At time: 454.88080644607544 and batch: 1300, loss is 4.634098711013794 and perplexity is 102.93510190081336
At time: 455.26066637039185 and batch: 1350, loss is 4.578192434310913 and perplexity is 97.33828974203631
At time: 455.63995885849 and batch: 1400, loss is 4.473514528274536 and perplexity is 87.66428083018694
At time: 456.0195896625519 and batch: 1450, loss is 4.552484254837037 and perplexity is 94.8677915879821
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.03807863414797 and perplexity of 154.17350655569933
Finished 38 epochs...
Completing Train Step...
At time: 457.2562208175659 and batch: 50, loss is 4.722186918258667 and perplexity is 112.41382389183539
At time: 457.66993379592896 and batch: 100, loss is 4.713260326385498 and perplexity is 111.41481706190841
At time: 458.0602481365204 and batch: 150, loss is 4.620102281570435 and perplexity is 101.50441362945058
At time: 458.4418306350708 and batch: 200, loss is 4.645413036346436 and perplexity is 104.10635661559365
At time: 458.8391544818878 and batch: 250, loss is 4.689642753601074 and perplexity is 108.81429934628402
At time: 459.2407820224762 and batch: 300, loss is 4.705091571807861 and perplexity is 110.50840393849019
At time: 459.6326172351837 and batch: 350, loss is 4.712538404464722 and perplexity is 111.3344132892871
At time: 460.01290559768677 and batch: 400, loss is 4.599102306365967 and perplexity is 99.39504927801383
At time: 460.3928699493408 and batch: 450, loss is 4.643614377975464 and perplexity is 103.91927314585735
At time: 460.77363300323486 and batch: 500, loss is 4.627913331985473 and perplexity is 102.30037431923822
At time: 461.1824469566345 and batch: 550, loss is 4.684124183654785 and perplexity is 108.21545392914564
At time: 461.5732686519623 and batch: 600, loss is 4.582714462280274 and perplexity is 97.7794529351197
At time: 461.9542031288147 and batch: 650, loss is 4.698120403289795 and perplexity is 109.74071020215295
At time: 462.3342661857605 and batch: 700, loss is 4.713748350143432 and perplexity is 111.46920340945594
At time: 462.715060710907 and batch: 750, loss is 4.670777950286865 and perplexity is 106.78078026724982
At time: 463.0961501598358 and batch: 800, loss is 4.611064796447754 and perplexity is 100.59120178623762
At time: 463.4917905330658 and batch: 850, loss is 4.588433399200439 and perplexity is 98.34024951020147
At time: 463.87252283096313 and batch: 900, loss is 4.5341056442260745 and perplexity is 93.14017758758479
At time: 464.2534954547882 and batch: 950, loss is 4.61126296043396 and perplexity is 100.61113731494753
At time: 464.63429069519043 and batch: 1000, loss is 4.6574530506134035 and perplexity is 105.36737473936161
At time: 465.0140233039856 and batch: 1050, loss is 4.560008935928344 and perplexity is 95.58433396100918
At time: 465.3943634033203 and batch: 1100, loss is 4.6894142627716064 and perplexity is 108.7894391170438
At time: 465.77484130859375 and batch: 1150, loss is 4.640981063842774 and perplexity is 103.64598104512419
At time: 466.1571764945984 and batch: 1200, loss is 4.592296886444092 and perplexity is 98.72092069534735
At time: 466.5571928024292 and batch: 1250, loss is 4.584672203063965 and perplexity is 97.97106726232857
At time: 466.9496765136719 and batch: 1300, loss is 4.634106388092041 and perplexity is 102.93589214467838
At time: 467.33067321777344 and batch: 1350, loss is 4.578299913406372 and perplexity is 97.34875213560555
At time: 467.71115922927856 and batch: 1400, loss is 4.473613414764404 and perplexity is 87.67295007183345
At time: 468.11134600639343 and batch: 1450, loss is 4.552551364898681 and perplexity is 94.87415838495934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038056724091881 and perplexity of 154.17012864252845
Finished 39 epochs...
Completing Train Step...
At time: 469.38269543647766 and batch: 50, loss is 4.721970529556274 and perplexity is 112.389501441999
At time: 469.78228402137756 and batch: 100, loss is 4.713154354095459 and perplexity is 111.4030108041792
At time: 470.17261385917664 and batch: 150, loss is 4.619985523223877 and perplexity is 101.49256283380005
At time: 470.5523669719696 and batch: 200, loss is 4.645296745300293 and perplexity is 104.09425068239216
At time: 470.93163776397705 and batch: 250, loss is 4.689551076889038 and perplexity is 108.80432406635487
At time: 471.311274766922 and batch: 300, loss is 4.704904594421387 and perplexity is 110.48774329753485
At time: 471.69202613830566 and batch: 350, loss is 4.7124134540557865 and perplexity is 111.32050287789194
At time: 472.0710253715515 and batch: 400, loss is 4.598950023651123 and perplexity is 99.37991428249612
At time: 472.4508731365204 and batch: 450, loss is 4.643457498550415 and perplexity is 103.90297162875447
At time: 472.8304486274719 and batch: 500, loss is 4.627738246917724 and perplexity is 102.28246461917608
At time: 473.2232789993286 and batch: 550, loss is 4.6839921760559085 and perplexity is 108.20116960975118
At time: 473.603084564209 and batch: 600, loss is 4.582599315643311 and perplexity is 97.76819460814183
At time: 473.9829592704773 and batch: 650, loss is 4.698060884475708 and perplexity is 109.73417875959844
At time: 474.36326909065247 and batch: 700, loss is 4.713622188568115 and perplexity is 111.45514116623045
At time: 474.75184655189514 and batch: 750, loss is 4.670706090927124 and perplexity is 106.77310734443606
At time: 475.147567987442 and batch: 800, loss is 4.610972557067871 and perplexity is 100.58192374407022
At time: 475.533899307251 and batch: 850, loss is 4.588367586135864 and perplexity is 98.33377764997896
At time: 475.9133110046387 and batch: 900, loss is 4.534101371765137 and perplexity is 93.13977965066438
At time: 476.29287219047546 and batch: 950, loss is 4.611214246749878 and perplexity is 100.60623629516355
At time: 476.68849897384644 and batch: 1000, loss is 4.657443809509277 and perplexity is 105.3664010329792
At time: 477.0784025192261 and batch: 1050, loss is 4.5600599098205565 and perplexity is 95.58920639072797
At time: 477.45803451538086 and batch: 1100, loss is 4.689413738250733 and perplexity is 108.7893820547271
At time: 477.8466763496399 and batch: 1150, loss is 4.640950021743774 and perplexity is 103.64276370625639
At time: 478.23327350616455 and batch: 1200, loss is 4.5923623275756835 and perplexity is 98.72738131550229
At time: 478.6124544143677 and batch: 1250, loss is 4.584829950332642 and perplexity is 97.98652314962852
At time: 478.99280047416687 and batch: 1300, loss is 4.634113721847534 and perplexity is 102.93664705411095
At time: 479.37196254730225 and batch: 1350, loss is 4.5784008502960205 and perplexity is 97.35857871178094
At time: 479.75438165664673 and batch: 1400, loss is 4.473676509857178 and perplexity is 87.67848197926824
At time: 480.1336166858673 and batch: 1450, loss is 4.552588615417481 and perplexity is 94.87769256240439
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038045769063835 and perplexity of 154.16843971369653
Finished 40 epochs...
Completing Train Step...
At time: 481.4365870952606 and batch: 50, loss is 4.721778440475464 and perplexity is 112.36791471932749
At time: 481.81779646873474 and batch: 100, loss is 4.7130641746521 and perplexity is 111.39296499564588
At time: 482.1973125934601 and batch: 150, loss is 4.619884071350097 and perplexity is 101.48226674541338
At time: 482.57676100730896 and batch: 200, loss is 4.64519492149353 and perplexity is 104.08365194913645
At time: 482.9678761959076 and batch: 250, loss is 4.689481592178344 and perplexity is 108.79676409202925
At time: 483.36937260627747 and batch: 300, loss is 4.704736680984497 and perplexity is 110.46919247833304
At time: 483.7595660686493 and batch: 350, loss is 4.7123118591308595 and perplexity is 111.30919385423866
At time: 484.1388084888458 and batch: 400, loss is 4.598816595077515 and perplexity is 99.36665504688818
At time: 484.53329825401306 and batch: 450, loss is 4.643316488265992 and perplexity is 103.8883212741223
At time: 484.92457842826843 and batch: 500, loss is 4.627585573196411 and perplexity is 102.26684996668145
At time: 485.30384612083435 and batch: 550, loss is 4.683876113891602 and perplexity is 108.18861227655547
At time: 485.6821548938751 and batch: 600, loss is 4.582492179870606 and perplexity is 97.75772069814175
At time: 486.06157660484314 and batch: 650, loss is 4.698008193969726 and perplexity is 109.72839696252038
At time: 486.44120717048645 and batch: 700, loss is 4.713524255752564 and perplexity is 111.44422658490494
At time: 486.82050371170044 and batch: 750, loss is 4.670641040802002 and perplexity is 106.76616196634494
At time: 487.19963669776917 and batch: 800, loss is 4.610880250930786 and perplexity is 100.5726398437159
At time: 487.57819867134094 and batch: 850, loss is 4.588303718566895 and perplexity is 98.3274975112036
At time: 487.9571604728699 and batch: 900, loss is 4.53409218788147 and perplexity is 93.13892426969117
At time: 488.3360550403595 and batch: 950, loss is 4.611162853240967 and perplexity is 100.60106592052502
At time: 488.73444151878357 and batch: 1000, loss is 4.65743839263916 and perplexity is 105.36583027841597
At time: 489.13314604759216 and batch: 1050, loss is 4.560099458694458 and perplexity is 95.59298691095499
At time: 489.52678775787354 and batch: 1100, loss is 4.6894082260131835 and perplexity is 108.78878238346316
At time: 489.91140484809875 and batch: 1150, loss is 4.640920257568359 and perplexity is 103.63967891076537
At time: 490.30916714668274 and batch: 1200, loss is 4.592418003082275 and perplexity is 98.73287816549004
At time: 490.6964225769043 and batch: 1250, loss is 4.584966735839844 and perplexity is 97.99992720261568
At time: 491.0897822380066 and batch: 1300, loss is 4.6341180419921875 and perplexity is 102.93709175627697
At time: 491.479444026947 and batch: 1350, loss is 4.578482542037964 and perplexity is 97.36653242854112
At time: 491.86262798309326 and batch: 1400, loss is 4.4737202835083005 and perplexity is 87.68232007055238
At time: 492.2612020969391 and batch: 1450, loss is 4.552610521316528 and perplexity is 94.8797709663241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0380348140357905 and perplexity of 154.1667508033669
Finished 41 epochs...
Completing Train Step...
At time: 493.5285048484802 and batch: 50, loss is 4.721603612899781 and perplexity is 112.34827142635724
At time: 493.94259119033813 and batch: 100, loss is 4.712981510162353 and perplexity is 111.38375713362
At time: 494.33277440071106 and batch: 150, loss is 4.619791803359985 and perplexity is 101.47290361259411
At time: 494.71222829818726 and batch: 200, loss is 4.645104455947876 and perplexity is 104.07423639066738
At time: 495.09105801582336 and batch: 250, loss is 4.689426259994507 and perplexity is 108.79074429602335
At time: 495.4709572792053 and batch: 300, loss is 4.7045807361602785 and perplexity is 110.4519667226991
At time: 495.8498296737671 and batch: 350, loss is 4.7122213172912595 and perplexity is 111.29911617129557
At time: 496.2292790412903 and batch: 400, loss is 4.598698472976684 and perplexity is 99.35491834203732
At time: 496.6205995082855 and batch: 450, loss is 4.643186321258545 and perplexity is 103.8747993223085
At time: 497.0213840007782 and batch: 500, loss is 4.627447576522827 and perplexity is 102.25273845526134
At time: 497.40988183021545 and batch: 550, loss is 4.6837741661071775 and perplexity is 108.17758324943594
At time: 497.7900846004486 and batch: 600, loss is 4.582394857406616 and perplexity is 97.7482071388384
At time: 498.16984128952026 and batch: 650, loss is 4.697960357666016 and perplexity is 109.72314808714205
At time: 498.5489058494568 and batch: 700, loss is 4.7134420204162595 and perplexity is 111.43506230827143
At time: 498.9278197288513 and batch: 750, loss is 4.670578441619873 and perplexity is 106.75947870111249
At time: 499.30675888061523 and batch: 800, loss is 4.610792264938355 and perplexity is 100.56379124946969
At time: 499.6858286857605 and batch: 850, loss is 4.588238773345947 and perplexity is 98.32111181751488
At time: 500.06524300575256 and batch: 900, loss is 4.534080772399903 and perplexity is 93.13786105008658
At time: 500.44709181785583 and batch: 950, loss is 4.61111102104187 and perplexity is 100.59585168118075
At time: 500.8444359302521 and batch: 1000, loss is 4.657432374954223 and perplexity is 105.365196221954
At time: 501.2329797744751 and batch: 1050, loss is 4.560130701065064 and perplexity is 95.59597350913337
At time: 501.61251640319824 and batch: 1100, loss is 4.689398651123047 and perplexity is 108.78774074781052
At time: 502.00581192970276 and batch: 1150, loss is 4.640891017913819 and perplexity is 103.63664856666067
At time: 502.38490891456604 and batch: 1200, loss is 4.592467880249023 and perplexity is 98.73780280453029
At time: 502.777795791626 and batch: 1250, loss is 4.5850864601135255 and perplexity is 98.01166087510957
At time: 503.156418800354 and batch: 1300, loss is 4.634118595123291 and perplexity is 102.93714869399987
At time: 503.53602361679077 and batch: 1350, loss is 4.57855107307434 and perplexity is 97.37320528656315
At time: 503.915408372879 and batch: 1400, loss is 4.473750963211059 and perplexity is 87.685010179335
At time: 504.29527139663696 and batch: 1450, loss is 4.552622003555298 and perplexity is 94.88086040476333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038028032351763 and perplexity of 154.16570529672055
Finished 42 epochs...
Completing Train Step...
At time: 505.5278537273407 and batch: 50, loss is 4.72144211769104 and perplexity is 112.3301291837936
At time: 505.9214527606964 and batch: 100, loss is 4.712903785705566 and perplexity is 111.37510022803288
At time: 506.30105447769165 and batch: 150, loss is 4.619707250595093 and perplexity is 101.46432416074535
At time: 506.68218064308167 and batch: 200, loss is 4.6450214767456055 and perplexity is 104.06560075184896
At time: 507.06318402290344 and batch: 250, loss is 4.68938006401062 and perplexity is 108.78571871663448
At time: 507.45240807533264 and batch: 300, loss is 4.704432287216187 and perplexity is 110.43557146182592
At time: 507.8430950641632 and batch: 350, loss is 4.712136716842651 and perplexity is 111.28970061442355
At time: 508.2237801551819 and batch: 400, loss is 4.598590393066406 and perplexity is 99.34418065165195
At time: 508.60487627983093 and batch: 450, loss is 4.643063106536865 and perplexity is 103.86200120629479
At time: 508.9870388507843 and batch: 500, loss is 4.627319183349609 and perplexity is 102.23961074447313
At time: 509.367880821228 and batch: 550, loss is 4.683680582046509 and perplexity is 108.1674600256157
At time: 509.7491600513458 and batch: 600, loss is 4.5823038291931155 and perplexity is 97.73930969913485
At time: 510.12946009635925 and batch: 650, loss is 4.69791618347168 and perplexity is 109.71830126252834
At time: 510.51045966148376 and batch: 700, loss is 4.71336763381958 and perplexity is 111.42677334153336
At time: 510.89496994018555 and batch: 750, loss is 4.670518655776977 and perplexity is 106.75309618648512
At time: 511.2931499481201 and batch: 800, loss is 4.610705118179322 and perplexity is 100.55502782284388
At time: 511.68144488334656 and batch: 850, loss is 4.588171854019165 and perplexity is 98.31453245504929
At time: 512.0786299705505 and batch: 900, loss is 4.534066915512085 and perplexity is 93.13657045813626
At time: 512.4850854873657 and batch: 950, loss is 4.611057243347168 and perplexity is 100.59044201364179
At time: 512.8660509586334 and batch: 1000, loss is 4.657423686981201 and perplexity is 105.36428081594829
At time: 513.2469091415405 and batch: 1050, loss is 4.560157899856567 and perplexity is 95.59857363944546
At time: 513.6282622814178 and batch: 1100, loss is 4.689386949539185 and perplexity is 108.78646776638698
At time: 514.0091001987457 and batch: 1150, loss is 4.640860595703125 and perplexity is 103.63349575866033
At time: 514.4085178375244 and batch: 1200, loss is 4.592514219284058 and perplexity is 98.74237832504551
At time: 514.8000333309174 and batch: 1250, loss is 4.585194787979126 and perplexity is 98.02227884423671
At time: 515.1942467689514 and batch: 1300, loss is 4.634116868972779 and perplexity is 102.93697100914127
At time: 515.58269739151 and batch: 1350, loss is 4.57861252784729 and perplexity is 97.37918951866334
At time: 515.9642505645752 and batch: 1400, loss is 4.473772354125977 and perplexity is 87.6868858619885
At time: 516.3445489406586 and batch: 1450, loss is 4.55262565612793 and perplexity is 94.88120696463025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038027510683761 and perplexity of 154.16562487342605
Finished 43 epochs...
Completing Train Step...
At time: 517.5993776321411 and batch: 50, loss is 4.721289987564087 and perplexity is 112.31304168677477
At time: 517.9934384822845 and batch: 100, loss is 4.712831983566284 and perplexity is 111.36710354466665
At time: 518.3776607513428 and batch: 150, loss is 4.619628000259399 and perplexity is 101.45628339761546
At time: 518.7563745975494 and batch: 200, loss is 4.644943809509277 and perplexity is 104.05751857810581
At time: 519.1356225013733 and batch: 250, loss is 4.689339570999145 and perplexity is 108.78131374446411
At time: 519.5164966583252 and batch: 300, loss is 4.704292573928833 and perplexity is 110.42014322288631
At time: 519.916955947876 and batch: 350, loss is 4.712055711746216 and perplexity is 111.280685946615
At time: 520.3045401573181 and batch: 400, loss is 4.598488464355468 and perplexity is 99.33405514342778
At time: 520.6830499172211 and batch: 450, loss is 4.642945337295532 and perplexity is 103.849770177443
At time: 521.0612609386444 and batch: 500, loss is 4.627198266983032 and perplexity is 102.2272490496023
At time: 521.4580829143524 and batch: 550, loss is 4.683591279983521 and perplexity is 108.1578008795845
At time: 521.8515784740448 and batch: 600, loss is 4.582217111587524 and perplexity is 97.73083434771199
At time: 522.261302947998 and batch: 650, loss is 4.697875051498413 and perplexity is 109.71378842510555
At time: 522.6505601406097 and batch: 700, loss is 4.713297672271729 and perplexity is 111.41897802468775
At time: 523.0300662517548 and batch: 750, loss is 4.670461025238037 and perplexity is 106.74694412529337
At time: 523.409196138382 and batch: 800, loss is 4.61061876296997 and perplexity is 100.54634474728472
At time: 523.8015749454498 and batch: 850, loss is 4.588100357055664 and perplexity is 98.30750351578766
At time: 524.2045369148254 and batch: 900, loss is 4.534052238464356 and perplexity is 93.1352034982778
At time: 524.59650182724 and batch: 950, loss is 4.611000337600708 and perplexity is 100.5847180023184
At time: 524.9761502742767 and batch: 1000, loss is 4.657411861419678 and perplexity is 105.36303483153034
At time: 525.3555719852448 and batch: 1050, loss is 4.560182800292969 and perplexity is 95.60095411528577
At time: 525.7472014427185 and batch: 1100, loss is 4.689375371932983 and perplexity is 108.78520828679399
At time: 526.1461255550385 and batch: 1150, loss is 4.640828857421875 and perplexity is 103.63020666182041
At time: 526.534018278122 and batch: 1200, loss is 4.592556753158569 and perplexity is 98.74657831029432
At time: 526.9128663539886 and batch: 1250, loss is 4.5852985668182376 and perplexity is 98.0324520104128
At time: 527.3025939464569 and batch: 1300, loss is 4.634113540649414 and perplexity is 102.93662840218575
At time: 527.6947660446167 and batch: 1350, loss is 4.578668584823609 and perplexity is 97.3846484545884
At time: 528.0731649398804 and batch: 1400, loss is 4.4737865924835205 and perplexity is 87.68813438810976
At time: 528.4525909423828 and batch: 1450, loss is 4.552621746063233 and perplexity is 94.8808359736978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038029075687767 and perplexity of 154.1658661434354
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 529.701159954071 and batch: 50, loss is 4.721097202301025 and perplexity is 112.29139147447589
At time: 530.0802736282349 and batch: 100, loss is 4.712940101623535 and perplexity is 111.37914499048071
At time: 530.4604113101959 and batch: 150, loss is 4.620016489028931 and perplexity is 101.49570568137528
At time: 530.839987039566 and batch: 200, loss is 4.644656410217285 and perplexity is 104.02761681801822
At time: 531.2193095684052 and batch: 250, loss is 4.689213418960572 and perplexity is 108.76759162553137
At time: 531.5988659858704 and batch: 300, loss is 4.704104957580566 and perplexity is 110.39942854210686
At time: 531.9785132408142 and batch: 350, loss is 4.712124938964844 and perplexity is 111.28838986564743
At time: 532.3701913356781 and batch: 400, loss is 4.597698163986206 and perplexity is 99.25558241556485
At time: 532.7489469051361 and batch: 450, loss is 4.642690782546997 and perplexity is 103.82333808965952
At time: 533.12806224823 and batch: 500, loss is 4.626830406188965 and perplexity is 102.18965056851918
At time: 533.5071692466736 and batch: 550, loss is 4.6829986667633055 and perplexity is 108.093724125155
At time: 533.8858213424683 and batch: 600, loss is 4.581699476242066 and perplexity is 97.6802585045638
At time: 534.2637836933136 and batch: 650, loss is 4.69738842010498 and perplexity is 109.66041123992578
At time: 534.6424427032471 and batch: 700, loss is 4.712891426086426 and perplexity is 111.37372368271912
At time: 535.0211474895477 and batch: 750, loss is 4.670046854019165 and perplexity is 106.70274176763816
At time: 535.3990406990051 and batch: 800, loss is 4.60991587638855 and perplexity is 100.47569690237071
At time: 535.7765798568726 and batch: 850, loss is 4.587476863861084 and perplexity is 98.24622856061318
At time: 536.1565871238708 and batch: 900, loss is 4.533592920303345 and perplexity is 93.09243463089231
At time: 536.5351791381836 and batch: 950, loss is 4.610081872940063 and perplexity is 100.49237690594065
At time: 536.9138422012329 and batch: 1000, loss is 4.65682505607605 and perplexity is 105.30122537650325
At time: 537.2924664020538 and batch: 1050, loss is 4.559417371749878 and perplexity is 95.52780641449954
At time: 537.6713190078735 and batch: 1100, loss is 4.6888499927520755 and perplexity is 108.72806981416566
At time: 538.0551156997681 and batch: 1150, loss is 4.639937229156494 and perplexity is 103.53784822123036
At time: 538.4576542377472 and batch: 1200, loss is 4.59169713973999 and perplexity is 98.66173089975105
At time: 538.8576159477234 and batch: 1250, loss is 4.584594841003418 and perplexity is 97.96348831185657
At time: 539.2450480461121 and batch: 1300, loss is 4.6333409023284915 and perplexity is 102.8571263355823
At time: 539.6250476837158 and batch: 1350, loss is 4.577543020248413 and perplexity is 97.27509740907387
At time: 540.0045793056488 and batch: 1400, loss is 4.472585525512695 and perplexity is 87.5828782886284
At time: 540.3839728832245 and batch: 1450, loss is 4.551505393981934 and perplexity is 94.77497465522885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0379576071714745 and perplexity of 154.15484853143005
Finished 45 epochs...
Completing Train Step...
At time: 541.6655316352844 and batch: 50, loss is 4.720940656661988 and perplexity is 112.27381412270388
At time: 542.0590119361877 and batch: 100, loss is 4.712833852767944 and perplexity is 111.36731171243603
At time: 542.4522821903229 and batch: 150, loss is 4.619955453872681 and perplexity is 101.48951106416696
At time: 542.8391637802124 and batch: 200, loss is 4.644533004760742 and perplexity is 104.01478003455253
At time: 543.2307026386261 and batch: 250, loss is 4.689159460067749 and perplexity is 108.76172280505125
At time: 543.6245813369751 and batch: 300, loss is 4.703979959487915 and perplexity is 110.38562968654264
At time: 544.0213425159454 and batch: 350, loss is 4.712035970687866 and perplexity is 111.27848916978394
At time: 544.415689945221 and batch: 400, loss is 4.597643346786499 and perplexity is 99.25014165160658
At time: 544.8019983768463 and batch: 450, loss is 4.642624464035034 and perplexity is 103.81645290868039
At time: 545.1858050823212 and batch: 500, loss is 4.626767053604126 and perplexity is 102.18317679507913
At time: 545.5849249362946 and batch: 550, loss is 4.682952785491944 and perplexity is 108.08876476143774
At time: 545.9727509021759 and batch: 600, loss is 4.581691370010376 and perplexity is 97.6794666889662
At time: 546.3528633117676 and batch: 650, loss is 4.697341756820679 and perplexity is 109.6552942443683
At time: 546.7341418266296 and batch: 700, loss is 4.712809190750122 and perplexity is 111.36456520367719
At time: 547.11496925354 and batch: 750, loss is 4.6699741840362545 and perplexity is 106.69498796295527
At time: 547.4958543777466 and batch: 800, loss is 4.609875841140747 and perplexity is 100.47167441346825
At time: 547.8766844272614 and batch: 850, loss is 4.5874663257598876 and perplexity is 98.24519323736965
At time: 548.2599077224731 and batch: 900, loss is 4.533592605590821 and perplexity is 93.0924053335418
At time: 548.6597907543182 and batch: 950, loss is 4.610064353942871 and perplexity is 100.490616395693
At time: 549.0474889278412 and batch: 1000, loss is 4.656785039901734 and perplexity is 105.29701170862086
At time: 549.4284760951996 and batch: 1050, loss is 4.559451770782471 and perplexity is 95.53109253514529
At time: 549.8082001209259 and batch: 1100, loss is 4.688849534988403 and perplexity is 108.72802004241655
At time: 550.1868150234222 and batch: 1150, loss is 4.639949522018433 and perplexity is 103.53912100552698
At time: 550.5667974948883 and batch: 1200, loss is 4.591725006103515 and perplexity is 98.66448028171779
At time: 550.9477779865265 and batch: 1250, loss is 4.584674320220947 and perplexity is 97.97127468267725
At time: 551.3278901576996 and batch: 1300, loss is 4.633367347717285 and perplexity is 102.85984646824573
At time: 551.7270965576172 and batch: 1350, loss is 4.5775918292999265 and perplexity is 97.27984543018653
At time: 552.1275868415833 and batch: 1400, loss is 4.472657957077026 and perplexity is 87.58922228326142
At time: 552.5250232219696 and batch: 1450, loss is 4.551537771224975 and perplexity is 94.77804325729366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0379377837873935 and perplexity of 154.15179269094833
Finished 46 epochs...
Completing Train Step...
At time: 553.8088314533234 and batch: 50, loss is 4.720860033035279 and perplexity is 112.26476256551445
At time: 554.2006435394287 and batch: 100, loss is 4.712785434722901 and perplexity is 111.36191965545865
At time: 554.5954053401947 and batch: 150, loss is 4.619956178665161 and perplexity is 101.48958462302807
At time: 554.9890892505646 and batch: 200, loss is 4.644453182220459 and perplexity is 104.00647764194659
At time: 555.3721816539764 and batch: 250, loss is 4.689096603393555 and perplexity is 108.75488661972825
At time: 555.7522320747375 and batch: 300, loss is 4.703891878128052 and perplexity is 110.37590719836173
At time: 556.1313621997833 and batch: 350, loss is 4.71198504447937 and perplexity is 111.27282232254005
At time: 556.5111162662506 and batch: 400, loss is 4.597594337463379 and perplexity is 99.24527758853789
At time: 556.8908541202545 and batch: 450, loss is 4.642567863464356 and perplexity is 103.8105770044913
At time: 557.269960641861 and batch: 500, loss is 4.626715726852417 and perplexity is 102.1779321991302
At time: 557.670952796936 and batch: 550, loss is 4.682927103042602 and perplexity is 108.08598881285911
At time: 558.0758292675018 and batch: 600, loss is 4.581672048568725 and perplexity is 97.6775793990827
At time: 558.4718570709229 and batch: 650, loss is 4.697308998107911 and perplexity is 109.65170213691738
At time: 558.8726961612701 and batch: 700, loss is 4.7127597045898435 and perplexity is 111.35905433531111
At time: 559.2645182609558 and batch: 750, loss is 4.6699288463592525 and perplexity is 106.69015076970766
At time: 559.6442277431488 and batch: 800, loss is 4.609851980209351 and perplexity is 100.46927709433906
At time: 560.0460605621338 and batch: 850, loss is 4.587454195022583 and perplexity is 98.24400145796767
At time: 560.4397480487823 and batch: 900, loss is 4.53359902381897 and perplexity is 93.09300282375558
At time: 560.8431959152222 and batch: 950, loss is 4.610045156478882 and perplexity is 100.4886872492209
At time: 561.230700969696 and batch: 1000, loss is 4.65676058769226 and perplexity is 105.2944369955125
At time: 561.6209027767181 and batch: 1050, loss is 4.559479780197144 and perplexity is 95.53376834260399
At time: 562.0222053527832 and batch: 1100, loss is 4.688852472305298 and perplexity is 108.72833941153577
At time: 562.4148945808411 and batch: 1150, loss is 4.639954242706299 and perplexity is 103.53960978255289
At time: 562.8148808479309 and batch: 1200, loss is 4.591746015548706 and perplexity is 98.66655318948378
At time: 563.1941158771515 and batch: 1250, loss is 4.584740791320801 and perplexity is 97.97778715750276
At time: 563.5727958679199 and batch: 1300, loss is 4.633389339447022 and perplexity is 102.8621085590636
At time: 563.9526071548462 and batch: 1350, loss is 4.577621765136719 and perplexity is 97.28275762735184
At time: 564.3322854042053 and batch: 1400, loss is 4.472701177597046 and perplexity is 87.59300801680673
At time: 564.7111597061157 and batch: 1450, loss is 4.551557626724243 and perplexity is 94.77992514134498
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037926307091346 and perplexity of 154.1500235478304
Finished 47 epochs...
Completing Train Step...
At time: 565.9610443115234 and batch: 50, loss is 4.720795421600342 and perplexity is 112.25750921243957
At time: 566.3405802249908 and batch: 100, loss is 4.712749910354614 and perplexity is 111.35796366387922
At time: 566.7297966480255 and batch: 150, loss is 4.619951238632202 and perplexity is 101.48908326237343
At time: 567.1239385604858 and batch: 200, loss is 4.644391431808471 and perplexity is 104.00005539739301
At time: 567.5216970443726 and batch: 250, loss is 4.689046258926392 and perplexity is 108.74941155073087
At time: 567.912011384964 and batch: 300, loss is 4.703819522857666 and perplexity is 110.36792120867001
At time: 568.2917869091034 and batch: 350, loss is 4.711946697235107 and perplexity is 111.26855539825557
At time: 568.6715078353882 and batch: 400, loss is 4.597544775009156 and perplexity is 99.24035887090338
At time: 569.0690653324127 and batch: 450, loss is 4.6425190353393555 and perplexity is 103.80550825241082
At time: 569.4579563140869 and batch: 500, loss is 4.626671953201294 and perplexity is 102.1734595958654
At time: 569.8378632068634 and batch: 550, loss is 4.682902421951294 and perplexity is 108.08332116562042
At time: 570.2174046039581 and batch: 600, loss is 4.58165093421936 and perplexity is 97.6755170223191
At time: 570.6158242225647 and batch: 650, loss is 4.69728123664856 and perplexity is 109.64865808789956
At time: 571.0063009262085 and batch: 700, loss is 4.712727537155152 and perplexity is 111.35547225781686
At time: 571.3971917629242 and batch: 750, loss is 4.669894971847534 and perplexity is 106.68653675415702
At time: 571.7892825603485 and batch: 800, loss is 4.609829206466674 and perplexity is 100.46698905892929
At time: 572.1822032928467 and batch: 850, loss is 4.587441387176514 and perplexity is 98.24274317197776
At time: 572.5648953914642 and batch: 900, loss is 4.533606243133545 and perplexity is 93.09367489385369
At time: 572.9428100585938 and batch: 950, loss is 4.610023860931396 and perplexity is 100.48654731039551
At time: 573.3268373012543 and batch: 1000, loss is 4.656741695404053 and perplexity is 105.29244776145276
At time: 573.7198848724365 and batch: 1050, loss is 4.559505453109741 and perplexity is 95.53622100417212
At time: 574.1037781238556 and batch: 1100, loss is 4.688856163024902 and perplexity is 108.72874069809014
At time: 574.4832825660706 and batch: 1150, loss is 4.639954595565796 and perplexity is 103.53964631749399
At time: 574.8626968860626 and batch: 1200, loss is 4.591762952804565 and perplexity is 98.66822434429224
At time: 575.2568249702454 and batch: 1250, loss is 4.584797382354736 and perplexity is 97.98333197867281
At time: 575.6499629020691 and batch: 1300, loss is 4.633408155441284 and perplexity is 102.86404403011689
At time: 576.0298447608948 and batch: 1350, loss is 4.57764199256897 and perplexity is 97.28472542764264
At time: 576.4092102050781 and batch: 1400, loss is 4.472728872299195 and perplexity is 87.59543391266612
At time: 576.7921969890594 and batch: 1450, loss is 4.5515708732604985 and perplexity is 94.78118065537524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037919003739316 and perplexity of 154.1488977400541
Finished 48 epochs...
Completing Train Step...
At time: 578.0510170459747 and batch: 50, loss is 4.7207379817962645 and perplexity is 112.25106134828798
At time: 578.4306592941284 and batch: 100, loss is 4.712721815109253 and perplexity is 111.35483507851654
At time: 578.821694612503 and batch: 150, loss is 4.619943294525147 and perplexity is 101.48827702543342
At time: 579.2147195339203 and batch: 200, loss is 4.644337720870972 and perplexity is 103.99446960692799
At time: 579.5960295200348 and batch: 250, loss is 4.6890047168731686 and perplexity is 108.74489397072367
At time: 579.9755706787109 and batch: 300, loss is 4.703755502700806 and perplexity is 110.36085566321297
At time: 580.354855298996 and batch: 350, loss is 4.7119144821167 and perplexity is 111.26497092630578
At time: 580.7344124317169 and batch: 400, loss is 4.597496480941772 and perplexity is 99.23556626605304
At time: 581.127473115921 and batch: 450, loss is 4.642474870681763 and perplexity is 103.80092381891835
At time: 581.5340809822083 and batch: 500, loss is 4.626632766723633 and perplexity is 102.16945585632014
At time: 581.9257936477661 and batch: 550, loss is 4.682878456115723 and perplexity is 108.08073088955656
At time: 582.3126697540283 and batch: 600, loss is 4.581629858016968 and perplexity is 97.67345841504746
At time: 582.6918840408325 and batch: 650, loss is 4.697256803512573 and perplexity is 109.64597906005443
At time: 583.0708405971527 and batch: 700, loss is 4.712704181671143 and perplexity is 111.352871527236
At time: 583.4498889446259 and batch: 750, loss is 4.669866638183594 and perplexity is 106.68351397650105
At time: 583.8287861347198 and batch: 800, loss is 4.609806842803955 and perplexity is 100.46474227419483
At time: 584.2065916061401 and batch: 850, loss is 4.587427396774292 and perplexity is 98.24136872609989
At time: 584.5846943855286 and batch: 900, loss is 4.5336133480072025 and perplexity is 93.09433631500175
At time: 584.9631271362305 and batch: 950, loss is 4.610000953674317 and perplexity is 100.4842454655878
At time: 585.341635465622 and batch: 1000, loss is 4.656724863052368 and perplexity is 105.29067545685835
At time: 585.7194650173187 and batch: 1050, loss is 4.559528942108154 and perplexity is 95.53846508067112
At time: 586.097815990448 and batch: 1100, loss is 4.688859214782715 and perplexity is 108.72907251238033
At time: 586.4758567810059 and batch: 1150, loss is 4.639951725006103 and perplexity is 103.53934910118522
At time: 586.8668966293335 and batch: 1200, loss is 4.591776504516601 and perplexity is 98.66956147671586
At time: 587.2592942714691 and batch: 1250, loss is 4.584847888946533 and perplexity is 97.98828090779968
At time: 587.6399590969086 and batch: 1300, loss is 4.633424406051636 and perplexity is 102.86571564719797
At time: 588.0180749893188 and batch: 1350, loss is 4.577656955718994 and perplexity is 97.28618112447514
At time: 588.3972630500793 and batch: 1400, loss is 4.4727481079101565 and perplexity is 87.59711888056054
At time: 588.7754561901093 and batch: 1450, loss is 4.551580877304077 and perplexity is 94.78212885517983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037915873731303 and perplexity of 154.14841525352412
Finished 49 epochs...
Completing Train Step...
At time: 589.999029636383 and batch: 50, loss is 4.720684814453125 and perplexity is 112.24509341624243
At time: 590.3918647766113 and batch: 100, loss is 4.712697801589965 and perplexity is 111.35216108914268
At time: 590.7729170322418 and batch: 150, loss is 4.619933910369873 and perplexity is 101.48732464815204
At time: 591.1683096885681 and batch: 200, loss is 4.644287700653076 and perplexity is 103.98926791099439
At time: 591.5487968921661 and batch: 250, loss is 4.688968896865845 and perplexity is 108.74099879758819
At time: 591.9394507408142 and batch: 300, loss is 4.703696460723877 and perplexity is 110.35433993247176
At time: 592.3201565742493 and batch: 350, loss is 4.711886157989502 and perplexity is 111.26181948774773
At time: 592.701201915741 and batch: 400, loss is 4.597450151443481 and perplexity is 99.23096883855438
At time: 593.0818033218384 and batch: 450, loss is 4.642433671951294 and perplexity is 103.7966474407268
At time: 593.4630026817322 and batch: 500, loss is 4.6265960311889645 and perplexity is 102.16570267567045
At time: 593.8426637649536 and batch: 550, loss is 4.682855415344238 and perplexity is 108.07824065482284
At time: 594.2223415374756 and batch: 600, loss is 4.5816092205047605 and perplexity is 97.67144269865682
At time: 594.6034724712372 and batch: 650, loss is 4.6972346591949465 and perplexity is 109.64355105155103
At time: 594.9844765663147 and batch: 700, loss is 4.712685537338257 and perplexity is 111.35079544658512
At time: 595.3645000457764 and batch: 750, loss is 4.669841146469116 and perplexity is 106.6807944654859
At time: 595.7454607486725 and batch: 800, loss is 4.60978443145752 and perplexity is 100.46249074928112
At time: 596.1253683567047 and batch: 850, loss is 4.587412586212158 and perplexity is 98.23991372697904
At time: 596.5061767101288 and batch: 900, loss is 4.533620185852051 and perplexity is 93.09497288180613
At time: 596.8872120380402 and batch: 950, loss is 4.609976825714111 and perplexity is 100.48182101496054
At time: 597.2675924301147 and batch: 1000, loss is 4.6567092132568355 and perplexity is 105.28902769220961
At time: 597.6485199928284 and batch: 1050, loss is 4.5595503997802735 and perplexity is 95.5405151357242
At time: 598.0290122032166 and batch: 1100, loss is 4.688861408233643 and perplexity is 108.72931100452685
At time: 598.4102509021759 and batch: 1150, loss is 4.639947118759156 and perplexity is 103.5388721744729
At time: 598.7907581329346 and batch: 1200, loss is 4.591787948608398 and perplexity is 98.67069066669622
At time: 599.1718678474426 and batch: 1250, loss is 4.584894781112671 and perplexity is 97.99287589828123
At time: 599.552342414856 and batch: 1300, loss is 4.6334388637542725 and perplexity is 102.86720285987714
At time: 599.9338715076447 and batch: 1350, loss is 4.577669095993042 and perplexity is 97.28736221254445
At time: 600.3150207996368 and batch: 1400, loss is 4.472761716842651 and perplexity is 87.59831099194977
At time: 600.696302652359 and batch: 1450, loss is 4.55158839225769 and perplexity is 94.78284114115795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037913265391293 and perplexity of 154.1480131825694
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7fb370c898>
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.42622398020897856, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 0.19597144310909975, 'anneal': 6.0823246452134585, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6517791748046875 and batch: 50, loss is 8.948496017456055 and perplexity is 7696.308039415118
At time: 1.0445647239685059 and batch: 100, loss is 8.370928878784179 and perplexity is 4319.64662785237
At time: 1.425520658493042 and batch: 150, loss is 7.809954500198364 and perplexity is 2465.018274891421
At time: 1.8077447414398193 and batch: 200, loss is 6.967114095687866 and perplexity is 1061.1559329128315
At time: 2.1884829998016357 and batch: 250, loss is 6.581856412887573 and perplexity is 721.8781901007451
At time: 2.5704805850982666 and batch: 300, loss is 6.504690933227539 and perplexity is 668.2690976607244
At time: 2.9524013996124268 and batch: 350, loss is 6.399634313583374 and perplexity is 601.6249915532456
At time: 3.334542989730835 and batch: 400, loss is 6.21674898147583 and perplexity is 501.0715881900262
At time: 3.716994285583496 and batch: 450, loss is 6.214566030502319 and perplexity is 499.9789664824851
At time: 4.098852157592773 and batch: 500, loss is 6.138977975845337 and perplexity is 463.57953917797636
At time: 4.4990808963775635 and batch: 550, loss is 6.1706227207183835 and perplexity is 478.48397521977955
At time: 4.880449533462524 and batch: 600, loss is 5.946531581878662 and perplexity is 382.4246276212309
At time: 5.261052131652832 and batch: 650, loss is 6.140896644592285 and perplexity is 464.46984858281303
At time: 5.642419815063477 and batch: 700, loss is 6.070450620651245 and perplexity is 432.8757003614349
At time: 6.0420167446136475 and batch: 750, loss is 6.011554613113403 and perplexity is 408.1172918496718
At time: 6.424405574798584 and batch: 800, loss is 5.965448808670044 and perplexity is 389.72790208683233
At time: 6.806214332580566 and batch: 850, loss is 5.891916561126709 and perplexity is 362.09860387367803
At time: 7.187973976135254 and batch: 900, loss is 5.841288528442383 and perplexity is 344.22259563530696
At time: 7.56976318359375 and batch: 950, loss is 5.8594480323791505 and perplexity is 350.530609065992
At time: 7.9520018100738525 and batch: 1000, loss is 5.931529378890991 and perplexity is 376.73023673494873
At time: 8.333338022232056 and batch: 1050, loss is 5.747840871810913 and perplexity is 313.5130141999627
At time: 8.732271671295166 and batch: 1100, loss is 5.853336420059204 and perplexity is 348.3948350364555
At time: 9.127729654312134 and batch: 1150, loss is 5.859524869918824 and perplexity is 350.5575440103669
At time: 9.530570268630981 and batch: 1200, loss is 5.806023769378662 and perplexity is 332.29521292670034
At time: 9.924437999725342 and batch: 1250, loss is 5.840145664215088 and perplexity is 343.829420660131
At time: 10.30630111694336 and batch: 1300, loss is 5.886430759429931 and perplexity is 360.1176412900232
At time: 10.688783407211304 and batch: 1350, loss is 5.806422700881958 and perplexity is 332.4278024008321
At time: 11.071534395217896 and batch: 1400, loss is 5.711499042510987 and perplexity is 302.323925188057
At time: 11.455005407333374 and batch: 1450, loss is 5.74883204460144 and perplexity is 313.82391382128344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.702708187266293 and perplexity of 299.6778868350621
Finished 1 epochs...
Completing Train Step...
At time: 12.718156099319458 and batch: 50, loss is 5.7101093101501466 and perplexity is 301.9040676581396
At time: 13.094251155853271 and batch: 100, loss is 5.697755365371704 and perplexity is 298.19730519102245
At time: 13.494925022125244 and batch: 150, loss is 5.650831594467163 and perplexity is 284.52797936200636
At time: 13.870496988296509 and batch: 200, loss is 5.5874685955047605 and perplexity is 267.05872966508394
At time: 14.246532201766968 and batch: 250, loss is 5.575011253356934 and perplexity is 263.75252372153005
At time: 14.626798152923584 and batch: 300, loss is 5.638556985855103 and perplexity is 281.05685669383166
At time: 15.003045558929443 and batch: 350, loss is 5.6517196559906 and perplexity is 284.7807699429998
At time: 15.37824010848999 and batch: 400, loss is 5.526506500244141 and perplexity is 251.26458319200884
At time: 15.75286865234375 and batch: 450, loss is 5.585292339324951 and perplexity is 266.4781734029854
At time: 16.12814712524414 and batch: 500, loss is 5.55244218826294 and perplexity is 257.8665461893161
At time: 16.50312566757202 and batch: 550, loss is 5.617628974914551 and perplexity is 275.2360174657265
At time: 16.88001298904419 and batch: 600, loss is 5.423793487548828 and perplexity is 226.73761946002546
At time: 17.256155252456665 and batch: 650, loss is 5.62011534690857 and perplexity is 275.92120805765785
At time: 17.65342426300049 and batch: 700, loss is 5.604672117233276 and perplexity is 271.69282743230013
At time: 18.029077768325806 and batch: 750, loss is 5.53073353767395 and perplexity is 252.32893593458064
At time: 18.405333757400513 and batch: 800, loss is 5.478200531005859 and perplexity is 239.41549875062023
At time: 18.78182077407837 and batch: 850, loss is 5.41691858291626 and perplexity is 225.18416599042087
At time: 19.180834531784058 and batch: 900, loss is 5.3859916687011715 and perplexity is 218.32650435206295
At time: 19.56691265106201 and batch: 950, loss is 5.410004434585571 and perplexity is 223.63257939615687
At time: 19.942524671554565 and batch: 1000, loss is 5.483198518753052 and perplexity is 240.61508975329468
At time: 20.318718671798706 and batch: 1050, loss is 5.343377523422241 and perplexity is 209.21815751356925
At time: 20.710651874542236 and batch: 1100, loss is 5.448774089813233 and perplexity is 232.4730001305517
At time: 21.10329842567444 and batch: 1150, loss is 5.432859649658203 and perplexity is 228.80260608174765
At time: 21.479358911514282 and batch: 1200, loss is 5.38941143989563 and perplexity is 219.07440914538205
At time: 21.85504126548767 and batch: 1250, loss is 5.4142039775848385 and perplexity is 224.57370880291518
At time: 22.23056411743164 and batch: 1300, loss is 5.479769287109375 and perplexity is 239.79137802993188
At time: 22.60651445388794 and batch: 1350, loss is 5.401899967193604 and perplexity is 221.8274810094206
At time: 22.982108116149902 and batch: 1400, loss is 5.2885691356658935 and perplexity is 198.05982582071286
At time: 23.35784888267517 and batch: 1450, loss is 5.348982162475586 and perplexity is 210.39404189553377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.422437879774305 and perplexity of 226.43046042093758
Finished 2 epochs...
Completing Train Step...
At time: 24.590425491333008 and batch: 50, loss is 5.445230293273926 and perplexity is 231.65062114975305
At time: 24.98101568222046 and batch: 100, loss is 5.431492443084717 and perplexity is 228.48999940233045
At time: 25.377562522888184 and batch: 150, loss is 5.379805917739868 and perplexity is 216.9801593383589
At time: 25.76913332939148 and batch: 200, loss is 5.3577287483215335 and perplexity is 212.24234282248312
At time: 26.14600443840027 and batch: 250, loss is 5.3614945983886715 and perplexity is 213.04312252523638
At time: 26.5232412815094 and batch: 300, loss is 5.418019380569458 and perplexity is 225.43218467602912
At time: 26.900343894958496 and batch: 350, loss is 5.44521206855774 and perplexity is 231.6463994213983
At time: 27.277024269104004 and batch: 400, loss is 5.320837459564209 and perplexity is 204.55511692086944
At time: 27.666601419448853 and batch: 450, loss is 5.385824117660523 and perplexity is 218.2899265834647
At time: 28.06464123725891 and batch: 500, loss is 5.359053297042847 and perplexity is 212.52365441060087
At time: 28.451998233795166 and batch: 550, loss is 5.427964191436768 and perplexity is 227.68524969996218
At time: 28.82949423789978 and batch: 600, loss is 5.2460707092285155 and perplexity is 189.81894736107617
At time: 29.20676565170288 and batch: 650, loss is 5.434193782806396 and perplexity is 229.10806293766547
At time: 29.58471417427063 and batch: 700, loss is 5.43560378074646 and perplexity is 229.43133268574144
At time: 29.961342811584473 and batch: 750, loss is 5.366068668365479 and perplexity is 214.01982873412132
At time: 30.336785554885864 and batch: 800, loss is 5.30505672454834 and perplexity is 201.35242371505146
At time: 30.71429419517517 and batch: 850, loss is 5.2461927700042725 and perplexity is 189.84211822314236
At time: 31.094149112701416 and batch: 900, loss is 5.221653099060059 and perplexity is 185.24015142403817
At time: 31.479174852371216 and batch: 950, loss is 5.2481692504882815 and perplexity is 190.21770851602577
At time: 31.856411457061768 and batch: 1000, loss is 5.31924464225769 and perplexity is 204.22955733780051
At time: 32.23369264602661 and batch: 1050, loss is 5.201972141265869 and perplexity is 181.63008909035722
At time: 32.61095595359802 and batch: 1100, loss is 5.30596378326416 and perplexity is 201.53514504289234
At time: 32.98875617980957 and batch: 1150, loss is 5.284687700271607 and perplexity is 197.29255941335464
At time: 33.36594080924988 and batch: 1200, loss is 5.239476232528687 and perplexity is 188.57130901785652
At time: 33.74305725097656 and batch: 1250, loss is 5.2657081985473635 and perplexity is 193.58335570478377
At time: 34.12041640281677 and batch: 1300, loss is 5.338850755691528 and perplexity is 208.27321588870035
At time: 34.497652530670166 and batch: 1350, loss is 5.257269802093506 and perplexity is 191.95669545690424
At time: 34.88244080543518 and batch: 1400, loss is 5.142668285369873 and perplexity is 171.1718949757552
At time: 35.259026765823364 and batch: 1450, loss is 5.212538957595825 and perplexity is 183.55951688341673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.298601721087072 and perplexity of 200.056878994324
Finished 3 epochs...
Completing Train Step...
At time: 36.502278566360474 and batch: 50, loss is 5.31865309715271 and perplexity is 204.1087820683967
At time: 36.88862204551697 and batch: 100, loss is 5.299414567947387 and perplexity is 200.2195607090022
At time: 37.29579567909241 and batch: 150, loss is 5.2410331726074215 and perplexity is 188.86513191953796
At time: 37.679303884506226 and batch: 200, loss is 5.238525218963623 and perplexity is 188.39206039244567
At time: 38.055296659469604 and batch: 250, loss is 5.246508226394654 and perplexity is 189.9020145793468
At time: 38.4307816028595 and batch: 300, loss is 5.297983675003052 and perplexity is 199.93327282476935
At time: 38.80635666847229 and batch: 350, loss is 5.329133787155151 and perplexity is 206.25923235682703
At time: 39.18233346939087 and batch: 400, loss is 5.20373085975647 and perplexity is 181.9498063504089
At time: 39.56696271896362 and batch: 450, loss is 5.269576749801636 and perplexity is 194.33369326217482
At time: 39.96149921417236 and batch: 500, loss is 5.245144586563111 and perplexity is 189.643233110636
At time: 40.34538245201111 and batch: 550, loss is 5.314459648132324 and perplexity is 203.25465441821234
At time: 40.72093152999878 and batch: 600, loss is 5.139033107757569 and perplexity is 170.55078434299003
At time: 41.1170117855072 and batch: 650, loss is 5.3194060897827145 and perplexity is 204.26253235616545
At time: 41.51625657081604 and batch: 700, loss is 5.330632209777832 and perplexity is 206.5685275262958
At time: 41.90823984146118 and batch: 750, loss is 5.263811674118042 and perplexity is 193.2165680623803
At time: 42.289875984191895 and batch: 800, loss is 5.1956058120727535 and perplexity is 180.4774451004409
At time: 42.66585421562195 and batch: 850, loss is 5.1394316101074216 and perplexity is 170.61876277520284
At time: 43.042083740234375 and batch: 900, loss is 5.115293731689453 and perplexity is 166.54969472241808
At time: 43.43512797355652 and batch: 950, loss is 5.14465516090393 and perplexity is 171.51233031533036
At time: 43.82351875305176 and batch: 1000, loss is 5.211965856552124 and perplexity is 183.45434887153667
At time: 44.19875407218933 and batch: 1050, loss is 5.108926792144775 and perplexity is 165.49265152087455
At time: 44.587515354156494 and batch: 1100, loss is 5.212627725601196 and perplexity is 183.5758118188211
At time: 44.98626470565796 and batch: 1150, loss is 5.185221118927002 and perplexity is 178.61294012530365
At time: 45.375322103500366 and batch: 1200, loss is 5.139016160964966 and perplexity is 170.5478940787099
At time: 45.766071796417236 and batch: 1250, loss is 5.163646984100342 and perplexity is 174.8007902514192
At time: 46.14951848983765 and batch: 1300, loss is 5.243429317474365 and perplexity is 189.31822275478567
At time: 46.52546453475952 and batch: 1350, loss is 5.159747791290283 and perplexity is 174.12053535125222
At time: 46.901867628097534 and batch: 1400, loss is 5.043187856674194 and perplexity is 154.96322902433474
At time: 47.2778000831604 and batch: 1450, loss is 5.118144483566284 and perplexity is 167.02516397766644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.215857350928152 and perplexity of 184.16965133348683
Finished 4 epochs...
Completing Train Step...
At time: 48.571808099746704 and batch: 50, loss is 5.228906059265137 and perplexity is 186.58857499073872
At time: 48.962968826293945 and batch: 100, loss is 5.2066458892822265 and perplexity is 182.48096920970988
At time: 49.34047484397888 and batch: 150, loss is 5.14392424583435 and perplexity is 171.38701517142667
At time: 49.71502709388733 and batch: 200, loss is 5.154107208251953 and perplexity is 173.14115873715073
At time: 50.09065794944763 and batch: 250, loss is 5.163503150939942 and perplexity is 174.7756499093677
At time: 50.467280864715576 and batch: 300, loss is 5.212578067779541 and perplexity is 183.56669607023352
At time: 50.843441009521484 and batch: 350, loss is 5.2461640167236325 and perplexity is 189.83665971791515
At time: 51.21995425224304 and batch: 400, loss is 5.118225383758545 and perplexity is 167.03867689213592
At time: 51.595855951309204 and batch: 450, loss is 5.185046873092651 and perplexity is 178.5818202758565
At time: 51.97205638885498 and batch: 500, loss is 5.160399885177612 and perplexity is 174.23411531638888
At time: 52.347965240478516 and batch: 550, loss is 5.23041000366211 and perplexity is 186.86940495602863
At time: 52.72389101982117 and batch: 600, loss is 5.0610072135925295 and perplexity is 157.74932359645805
At time: 53.10014367103577 and batch: 650, loss is 5.235290374755859 and perplexity is 187.78362605281177
At time: 53.47581243515015 and batch: 700, loss is 5.253093290328979 and perplexity is 191.15665790610785
At time: 53.85148763656616 and batch: 750, loss is 5.187593851089478 and perplexity is 179.0372439736029
At time: 54.227641582489014 and batch: 800, loss is 5.114498348236084 and perplexity is 166.41727651967685
At time: 54.60270142555237 and batch: 850, loss is 5.060278739929199 and perplexity is 157.63444921537052
At time: 54.979048013687134 and batch: 900, loss is 5.035551204681396 and perplexity is 153.78433590012187
At time: 55.35496163368225 and batch: 950, loss is 5.068623008728028 and perplexity is 158.95529652019795
At time: 55.73102378845215 and batch: 1000, loss is 5.133408088684082 and perplexity is 169.59412606105846
At time: 56.1070282459259 and batch: 1050, loss is 5.038789644241333 and perplexity is 154.28316445430622
At time: 56.49574160575867 and batch: 1100, loss is 5.143688402175903 and perplexity is 171.3465993968477
At time: 56.871257305145264 and batch: 1150, loss is 5.110596075057983 and perplexity is 165.7691362777579
At time: 57.246450662612915 and batch: 1200, loss is 5.063771905899048 and perplexity is 158.18605537407575
At time: 57.62166976928711 and batch: 1250, loss is 5.085205869674683 and perplexity is 161.6132070714276
At time: 57.9981153011322 and batch: 1300, loss is 5.170864744186401 and perplexity is 176.0670246090636
At time: 58.374348878860474 and batch: 1350, loss is 5.086836986541748 and perplexity is 161.8770322057424
At time: 58.7505407333374 and batch: 1400, loss is 4.967729988098145 and perplexity is 143.7003154237381
At time: 59.12608528137207 and batch: 1450, loss is 5.046767845153808 and perplexity is 155.51898981405083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.154248881543803 and perplexity of 173.16568995273173
Finished 5 epochs...
Completing Train Step...
At time: 60.35497045516968 and batch: 50, loss is 5.158779840469361 and perplexity is 173.9520767790789
At time: 60.743027210235596 and batch: 100, loss is 5.135851907730102 and perplexity is 170.0090902586019
At time: 61.11851954460144 and batch: 150, loss is 5.069514064788819 and perplexity is 159.09699772303924
At time: 61.49497175216675 and batch: 200, loss is 5.088788480758667 and perplexity is 162.19324273910468
At time: 61.871108293533325 and batch: 250, loss is 5.098957500457764 and perplexity is 163.851003635599
At time: 62.247604846954346 and batch: 300, loss is 5.146502885818482 and perplexity is 171.8295308806546
At time: 62.62371897697449 and batch: 350, loss is 5.181914234161377 and perplexity is 178.02326324876657
At time: 62.999348402023315 and batch: 400, loss is 5.050968618392944 and perplexity is 156.1736639306688
At time: 63.39662551879883 and batch: 450, loss is 5.119063301086426 and perplexity is 167.1787001496945
At time: 63.78353929519653 and batch: 500, loss is 5.093861494064331 and perplexity is 163.0181418104956
At time: 64.16001462936401 and batch: 550, loss is 5.164386882781982 and perplexity is 174.9301729848303
At time: 64.53662967681885 and batch: 600, loss is 5.000374956130981 and perplexity is 148.46881796066336
At time: 64.9125108718872 and batch: 650, loss is 5.169544439315796 and perplexity is 175.83471585185796
At time: 65.28850889205933 and batch: 700, loss is 5.191954212188721 and perplexity is 179.81961547909427
At time: 65.66526508331299 and batch: 750, loss is 5.126992053985596 and perplexity is 168.50948752364192
At time: 66.05640625953674 and batch: 800, loss is 5.05067997932434 and perplexity is 156.12859261475566
At time: 66.44753384590149 and batch: 850, loss is 4.997588148117066 and perplexity is 148.05563986037987
At time: 66.82954144477844 and batch: 900, loss is 4.97228346824646 and perplexity is 144.3561439752999
At time: 67.20609331130981 and batch: 950, loss is 5.0090577507019045 and perplexity is 149.76355504097452
At time: 67.58180093765259 and batch: 1000, loss is 5.072036056518555 and perplexity is 159.49874542477215
At time: 67.9581184387207 and batch: 1050, loss is 4.983084020614624 and perplexity is 145.92372017401425
At time: 68.33340311050415 and batch: 1100, loss is 5.089077320098877 and perplexity is 162.24009729471769
At time: 68.70951247215271 and batch: 1150, loss is 5.051758165359497 and perplexity is 156.29701906420834
At time: 69.0855028629303 and batch: 1200, loss is 5.0038160228729245 and perplexity is 148.9805890866765
At time: 69.46141767501831 and batch: 1250, loss is 5.021512660980225 and perplexity is 151.64051107801947
At time: 69.8370132446289 and batch: 1300, loss is 5.112550458908081 and perplexity is 166.09342959413092
At time: 70.21852016448975 and batch: 1350, loss is 5.029397821426391 and perplexity is 152.84094743481776
At time: 70.5938229560852 and batch: 1400, loss is 4.90685393333435 and perplexity is 135.21335432637648
At time: 70.969393491745 and batch: 1450, loss is 4.989494667053223 and perplexity is 146.86219043760553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.105801574185363 and perplexity of 164.9762582552452
Finished 6 epochs...
Completing Train Step...
At time: 72.19326615333557 and batch: 50, loss is 5.101127471923828 and perplexity is 164.20694168621165
At time: 72.5834858417511 and batch: 100, loss is 5.07911319732666 and perplexity is 160.63154426520768
At time: 72.96076774597168 and batch: 150, loss is 5.009192943572998 and perplexity is 149.78380337465003
At time: 73.33862924575806 and batch: 200, loss is 5.035446319580078 and perplexity is 153.76820706032217
At time: 73.7152955532074 and batch: 250, loss is 5.046496849060059 and perplexity is 155.476850485362
At time: 74.09246873855591 and batch: 300, loss is 5.0924663162231445 and perplexity is 162.79086109670519
At time: 74.47107410430908 and batch: 350, loss is 5.129319839477539 and perplexity is 168.9021983599197
At time: 74.8496482372284 and batch: 400, loss is 4.995749521255493 and perplexity is 147.78367088527384
At time: 75.22802233695984 and batch: 450, loss is 5.064860105514526 and perplexity is 158.35828707294596
At time: 75.6067111492157 and batch: 500, loss is 5.0395689296722415 and perplexity is 154.40344193575754
At time: 75.99878525733948 and batch: 550, loss is 5.11002067565918 and perplexity is 165.6737802529341
At time: 76.377769947052 and batch: 600, loss is 4.950825681686402 and perplexity is 141.291577640046
At time: 76.75502753257751 and batch: 650, loss is 5.115608797073365 and perplexity is 166.60217703317164
At time: 77.13073968887329 and batch: 700, loss is 5.141263132095337 and perplexity is 170.931541133563
At time: 77.50725817680359 and batch: 750, loss is 5.076389226913452 and perplexity is 160.19458409467703
At time: 77.88466572761536 and batch: 800, loss is 4.9979902935028075 and perplexity is 148.11519172623426
At time: 78.26137399673462 and batch: 850, loss is 4.945710725784302 and perplexity is 140.57072259359623
At time: 78.63770198822021 and batch: 900, loss is 4.919533472061158 and perplexity is 136.938712546599
At time: 79.01430153846741 and batch: 950, loss is 4.9599509525299075 and perplexity is 142.58680220356234
At time: 79.38998246192932 and batch: 1000, loss is 5.0215136909484865 and perplexity is 151.6406672630135
At time: 79.76645565032959 and batch: 1050, loss is 4.936618661880493 and perplexity is 139.29843721526265
At time: 80.14336109161377 and batch: 1100, loss is 5.043592700958252 and perplexity is 155.02597770270916
At time: 80.52015018463135 and batch: 1150, loss is 5.003354272842407 and perplexity is 148.9118131749809
At time: 80.89712262153625 and batch: 1200, loss is 4.9538454246520995 and perplexity is 141.71888674485479
At time: 81.27412724494934 and batch: 1250, loss is 4.967605619430542 and perplexity is 143.6824447182757
At time: 81.65138530731201 and batch: 1300, loss is 5.063519468307495 and perplexity is 158.1461283069982
At time: 82.02834510803223 and batch: 1350, loss is 4.982016115188599 and perplexity is 145.76797061915374
At time: 82.4073395729065 and batch: 1400, loss is 4.8555104637146 and perplexity is 128.4462416283709
At time: 82.78581833839417 and batch: 1450, loss is 4.941331787109375 and perplexity is 139.9565177839195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.065863715277778 and perplexity of 158.51729677444192
Finished 7 epochs...
Completing Train Step...
At time: 84.01580595970154 and batch: 50, loss is 5.05184573173523 and perplexity is 156.31070602695576
At time: 84.39006567001343 and batch: 100, loss is 5.031611814498901 and perplexity is 153.17971110546597
At time: 84.76484203338623 and batch: 150, loss is 4.958329477310181 and perplexity is 142.35578857917758
At time: 85.14203381538391 and batch: 200, loss is 4.990241537094116 and perplexity is 146.97191837893865
At time: 85.5420434474945 and batch: 250, loss is 5.002289581298828 and perplexity is 148.7533523976481
At time: 85.92214274406433 and batch: 300, loss is 5.04660855293274 and perplexity is 155.49421882171058
At time: 86.30223870277405 and batch: 350, loss is 5.084487066268921 and perplexity is 161.49708068878832
At time: 86.68249464035034 and batch: 400, loss is 4.948680095672607 and perplexity is 140.98874939539118
At time: 87.0628252029419 and batch: 450, loss is 5.018710031509399 and perplexity is 151.21611390450786
At time: 87.44285726547241 and batch: 500, loss is 4.993496503829956 and perplexity is 147.45108649945345
At time: 87.82268762588501 and batch: 550, loss is 5.06355839729309 and perplexity is 158.15228489518307
At time: 88.20183277130127 and batch: 600, loss is 4.908843250274658 and perplexity is 135.48260426563272
At time: 88.58238101005554 and batch: 650, loss is 5.069545545578003 and perplexity is 159.10200630092098
At time: 88.96325945854187 and batch: 700, loss is 5.097682132720947 and perplexity is 163.64216655226352
At time: 89.34416651725769 and batch: 750, loss is 5.032701053619385 and perplexity is 153.34665134167906
At time: 89.7246720790863 and batch: 800, loss is 4.952899627685547 and perplexity is 141.58491281772217
At time: 90.11765503883362 and batch: 850, loss is 4.901452436447143 and perplexity is 134.48496877098628
At time: 90.50941896438599 and batch: 900, loss is 4.874151153564453 and perplexity is 130.86302344044435
At time: 90.88404870033264 and batch: 950, loss is 4.917980756759643 and perplexity is 136.7262507013231
At time: 91.25913429260254 and batch: 1000, loss is 4.97833818435669 and perplexity is 145.23283081254982
At time: 91.634840965271 and batch: 1050, loss is 4.896489915847778 and perplexity is 133.81923756179958
At time: 92.01030278205872 and batch: 1100, loss is 5.004406175613403 and perplexity is 149.0685363382074
At time: 92.38505482673645 and batch: 1150, loss is 4.9620885181427 and perplexity is 142.89191683388444
At time: 92.76012659072876 and batch: 1200, loss is 4.910876836776733 and perplexity is 135.7584001933257
At time: 93.13531064987183 and batch: 1250, loss is 4.920544996261596 and perplexity is 137.07729944850274
At time: 93.51077818870544 and batch: 1300, loss is 5.020914583206177 and perplexity is 151.5498453739723
At time: 93.88574314117432 and batch: 1350, loss is 4.941544303894043 and perplexity is 139.9862640537511
At time: 94.26051759719849 and batch: 1400, loss is 4.8109407806396485 and perplexity is 122.84713537686099
At time: 94.63541865348816 and batch: 1450, loss is 4.899689130783081 and perplexity is 134.24803961447222
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.031620905949519 and perplexity of 153.18110373757568
Finished 8 epochs...
Completing Train Step...
At time: 95.8885486125946 and batch: 50, loss is 5.00859824180603 and perplexity is 149.69475316390336
At time: 96.2632577419281 and batch: 100, loss is 4.9906659507751465 and perplexity is 147.03430851050217
At time: 96.63953351974487 and batch: 150, loss is 4.914200439453125 and perplexity is 136.21035782330563
At time: 97.01481866836548 and batch: 200, loss is 4.9509484004974365 and perplexity is 141.30891783842574
At time: 97.38995027542114 and batch: 250, loss is 4.964156789779663 and perplexity is 143.18776197121394
At time: 97.76481056213379 and batch: 300, loss is 5.0067899131774904 and perplexity is 149.4243004635947
At time: 98.13975644111633 and batch: 350, loss is 5.04516297340393 and perplexity is 155.26960195202318
At time: 98.51526808738708 and batch: 400, loss is 4.907306957244873 and perplexity is 135.274623085967
At time: 98.89033341407776 and batch: 450, loss is 4.9784140872955325 and perplexity is 145.2438548295973
At time: 99.26563000679016 and batch: 500, loss is 4.953302125930787 and perplexity is 141.641911966943
At time: 99.64082789421082 and batch: 550, loss is 5.022865476608277 and perplexity is 151.845791553262
At time: 100.01633906364441 and batch: 600, loss is 4.87215142250061 and perplexity is 130.6015940686996
At time: 100.39185285568237 and batch: 650, loss is 5.029034013748169 and perplexity is 152.78535283807798
At time: 100.76780414581299 and batch: 700, loss is 5.059269275665283 and perplexity is 157.47540316128539
At time: 101.14308214187622 and batch: 750, loss is 4.994238958358765 and perplexity is 147.56060287683718
At time: 101.51883721351624 and batch: 800, loss is 4.913490972518921 and perplexity is 136.11375535051604
At time: 101.89435029029846 and batch: 850, loss is 4.862820692062378 and perplexity is 129.38865341092628
At time: 102.26946091651917 and batch: 900, loss is 4.834114503860474 and perplexity is 125.72720294791219
At time: 102.64311003684998 and batch: 950, loss is 4.881215200424195 and perplexity is 131.79071875409696
At time: 103.01704239845276 and batch: 1000, loss is 4.9405081176757815 and perplexity is 139.84128734060036
At time: 103.39277648925781 and batch: 1050, loss is 4.861070041656494 and perplexity is 129.16233727033804
At time: 103.76829218864441 and batch: 1100, loss is 4.969920558929443 and perplexity is 144.0154461752543
At time: 104.14295196533203 and batch: 1150, loss is 4.925969982147217 and perplexity is 137.82296264062882
At time: 104.53682041168213 and batch: 1200, loss is 4.873235921859742 and perplexity is 130.74330824434537
At time: 104.93074679374695 and batch: 1250, loss is 4.878653116226197 and perplexity is 131.45349202224543
At time: 105.3178026676178 and batch: 1300, loss is 4.983129158020019 and perplexity is 145.93030694078223
At time: 105.69285917282104 and batch: 1350, loss is 4.906082830429077 and perplexity is 135.1091311046025
At time: 106.0681004524231 and batch: 1400, loss is 4.771482372283936 and perplexity is 118.09417180023583
At time: 106.44331526756287 and batch: 1450, loss is 4.862959146499634 and perplexity is 129.40656908434516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.001750717815171 and perplexity of 148.67321624113285
Finished 9 epochs...
Completing Train Step...
At time: 107.66440296173096 and batch: 50, loss is 4.970090131759644 and perplexity is 144.03986935275
At time: 108.05362343788147 and batch: 100, loss is 4.954632663726807 and perplexity is 141.83049731646176
At time: 108.4300286769867 and batch: 150, loss is 4.875098791122436 and perplexity is 130.9870929335788
At time: 108.80652046203613 and batch: 200, loss is 4.916169443130493 and perplexity is 136.4788207342495
At time: 109.18360829353333 and batch: 250, loss is 4.930609436035156 and perplexity is 138.46387150445432
At time: 109.56041550636292 and batch: 300, loss is 4.971617851257324 and perplexity is 144.26009004449426
At time: 109.93722105026245 and batch: 350, loss is 5.010094518661499 and perplexity is 149.91890561368876
At time: 110.31460309028625 and batch: 400, loss is 4.870245943069458 and perplexity is 130.35297236452342
At time: 110.69145774841309 and batch: 450, loss is 4.942510900497436 and perplexity is 140.12163971739528
At time: 111.06828260421753 and batch: 500, loss is 4.91744517326355 and perplexity is 136.653041984405
At time: 111.44476199150085 and batch: 550, loss is 4.986604461669922 and perplexity is 146.43834134470873
At time: 111.82130026817322 and batch: 600, loss is 4.839399957656861 and perplexity is 126.39348752711065
At time: 112.19829893112183 and batch: 650, loss is 4.992749891281128 and perplexity is 147.3410387545603
At time: 112.57514500617981 and batch: 700, loss is 5.0247844886779784 and perplexity is 152.1374652331322
At time: 112.95939111709595 and batch: 750, loss is 4.959890880584717 and perplexity is 142.57823699426243
At time: 113.354905128479 and batch: 800, loss is 4.87848650932312 and perplexity is 131.43159278737355
At time: 113.74854636192322 and batch: 850, loss is 4.8285573387145995 and perplexity is 125.03045388569147
At time: 114.14411163330078 and batch: 900, loss is 4.7981562900543215 and perplexity is 121.28659394972517
At time: 114.5407989025116 and batch: 950, loss is 4.8484193801879885 and perplexity is 127.53864034167952
At time: 114.93047523498535 and batch: 1000, loss is 4.906758584976196 and perplexity is 135.2004625696547
At time: 115.3078362941742 and batch: 1050, loss is 4.8292822265625 and perplexity is 125.12111979967025
At time: 115.68503665924072 and batch: 1100, loss is 4.9390636157989505 and perplexity is 139.6394321637683
At time: 116.08001589775085 and batch: 1150, loss is 4.8937015628814695 and perplexity is 133.4466220270319
At time: 116.470947265625 and batch: 1200, loss is 4.839727411270141 and perplexity is 126.43488230836202
At time: 116.84740281105042 and batch: 1250, loss is 4.8409848976135255 and perplexity is 126.59397245206996
At time: 117.24562287330627 and batch: 1300, loss is 4.949035243988037 and perplexity is 141.0388302047647
At time: 117.63742399215698 and batch: 1350, loss is 4.874429664611816 and perplexity is 130.899475314053
At time: 118.01538467407227 and batch: 1400, loss is 4.736009407043457 and perplexity is 113.9784513228413
At time: 118.39258623123169 and batch: 1450, loss is 4.830020303726196 and perplexity is 125.21350292963587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.975377270299146 and perplexity of 144.80344488329962
Finished 10 epochs...
Completing Train Step...
At time: 119.63361692428589 and batch: 50, loss is 4.935352640151978 and perplexity is 139.12219395443915
At time: 120.02328372001648 and batch: 100, loss is 4.9224005126953125 and perplexity is 137.33188475088153
At time: 120.39925122261047 and batch: 150, loss is 4.83980546951294 and perplexity is 126.44475197830296
At time: 120.77595329284668 and batch: 200, loss is 4.884998302459717 and perplexity is 132.29024076609144
At time: 121.15978622436523 and batch: 250, loss is 4.900504083633423 and perplexity is 134.35749002941506
At time: 121.53823113441467 and batch: 300, loss is 4.940080642700195 and perplexity is 139.78152146482677
At time: 121.91396737098694 and batch: 350, loss is 4.978419303894043 and perplexity is 145.2446125104503
At time: 122.29008626937866 and batch: 400, loss is 4.836687622070312 and perplexity is 126.05113047647541
At time: 122.66606116294861 and batch: 450, loss is 4.910059223175049 and perplexity is 135.6474476431227
At time: 123.0626769065857 and batch: 500, loss is 4.884886817932129 and perplexity is 132.275493273169
At time: 123.45451593399048 and batch: 550, loss is 4.953837814331055 and perplexity is 141.71780822273254
At time: 123.83073139190674 and batch: 600, loss is 4.80977144241333 and perplexity is 122.7035694803753
At time: 124.2194893360138 and batch: 650, loss is 4.959845676422119 and perplexity is 142.57179201012556
At time: 124.59452104568481 and batch: 700, loss is 4.9933836555480955 and perplexity is 147.43444783652347
At time: 124.98668813705444 and batch: 750, loss is 4.9288187503814695 and perplexity is 138.21614809976572
At time: 125.38138437271118 and batch: 800, loss is 4.846916580200196 and perplexity is 127.34711921954533
At time: 125.77945327758789 and batch: 850, loss is 4.797731714248657 and perplexity is 121.2351095266763
At time: 126.1775450706482 and batch: 900, loss is 4.765373220443726 and perplexity is 117.37491583221338
At time: 126.57453227043152 and batch: 950, loss is 4.818779983520508 and perplexity is 123.81394354599664
At time: 126.96371698379517 and batch: 1000, loss is 4.876224708557129 and perplexity is 131.13465664191966
At time: 127.34028601646423 and batch: 1050, loss is 4.800412521362305 and perplexity is 121.56055350207505
At time: 127.71534538269043 and batch: 1100, loss is 4.911094055175782 and perplexity is 135.7878926187058
At time: 128.09081029891968 and batch: 1150, loss is 4.8644039344787595 and perplexity is 129.59366926727947
At time: 128.46730136871338 and batch: 1200, loss is 4.809503097534179 and perplexity is 122.6706470233356
At time: 128.84350061416626 and batch: 1250, loss is 4.806731204986573 and perplexity is 122.33108799901966
At time: 129.21929669380188 and batch: 1300, loss is 4.917819957733155 and perplexity is 136.70426702083944
At time: 129.6067271232605 and batch: 1350, loss is 4.845782260894776 and perplexity is 127.2027488202704
At time: 129.99868631362915 and batch: 1400, loss is 4.703737573623657 and perplexity is 110.35887701265538
At time: 130.37954473495483 and batch: 1450, loss is 4.80009017944336 and perplexity is 121.5213757546455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.951827090010684 and perplexity of 141.43313907061318
Finished 11 epochs...
Completing Train Step...
At time: 131.6212809085846 and batch: 50, loss is 4.9036344718933105 and perplexity is 134.77874013302318
At time: 131.99749541282654 and batch: 100, loss is 4.8931404399871825 and perplexity is 133.37176307674687
At time: 132.37236618995667 and batch: 150, loss is 4.807501258850098 and perplexity is 122.42532580539923
At time: 132.75425720214844 and batch: 200, loss is 4.856764030456543 and perplexity is 128.60735852929946
At time: 133.14699959754944 and batch: 250, loss is 4.873063850402832 and perplexity is 130.7208129882658
At time: 133.54648661613464 and batch: 300, loss is 4.911398134231567 and perplexity is 135.82918915126754
At time: 133.95163583755493 and batch: 350, loss is 4.949541091918945 and perplexity is 141.11019245290257
At time: 134.32916116714478 and batch: 400, loss is 4.805984907150268 and perplexity is 122.2398266310497
At time: 134.70750665664673 and batch: 450, loss is 4.880367937088013 and perplexity is 131.67910460001477
At time: 135.0847270488739 and batch: 500, loss is 4.854939022064209 and perplexity is 128.37286306384908
At time: 135.46306467056274 and batch: 550, loss is 4.923899250030518 and perplexity is 137.53786348932852
At time: 135.84083533287048 and batch: 600, loss is 4.782635374069214 and perplexity is 119.41864852558024
At time: 136.21854209899902 and batch: 650, loss is 4.929718389511108 and perplexity is 138.3405487043797
At time: 136.60450267791748 and batch: 700, loss is 4.964480276107788 and perplexity is 143.2340887472018
At time: 136.99327611923218 and batch: 750, loss is 4.900398464202881 and perplexity is 134.34330001721278
At time: 137.37086725234985 and batch: 800, loss is 4.81807463645935 and perplexity is 123.72664253716061
At time: 137.74862551689148 and batch: 850, loss is 4.7696149539947506 and perplexity is 117.87384636786837
At time: 138.14037537574768 and batch: 900, loss is 4.735112571716309 and perplexity is 113.8762772446711
At time: 138.52365446090698 and batch: 950, loss is 4.7917375564575195 and perplexity is 120.51058078948911
At time: 138.90113186836243 and batch: 1000, loss is 4.848265304565429 and perplexity is 127.51899126002965
At time: 139.27849912643433 and batch: 1050, loss is 4.773898763656616 and perplexity is 118.37987858882838
At time: 139.6568202972412 and batch: 1100, loss is 4.885443344116211 and perplexity is 132.34912853676343
At time: 140.03428959846497 and batch: 1150, loss is 4.8374920749664305 and perplexity is 126.1525734710309
At time: 140.41228008270264 and batch: 1200, loss is 4.781861743927002 and perplexity is 119.32629838657023
At time: 140.79003024101257 and batch: 1250, loss is 4.7752679824829105 and perplexity is 118.54207756485208
At time: 141.16737532615662 and batch: 1300, loss is 4.888959369659424 and perplexity is 132.81529049174986
At time: 141.545086145401 and batch: 1350, loss is 4.81953218460083 and perplexity is 123.90711156423998
At time: 141.92282891273499 and batch: 1400, loss is 4.674093856811523 and perplexity is 107.13544304258475
At time: 142.29967188835144 and batch: 1450, loss is 4.772669286727905 and perplexity is 118.23442269493539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.930552425547543 and perplexity of 138.45597783663607
Finished 12 epochs...
Completing Train Step...
At time: 143.57665634155273 and batch: 50, loss is 4.874399147033691 and perplexity is 130.89548064004276
At time: 143.96954870224 and batch: 100, loss is 4.866263570785523 and perplexity is 129.83489058221627
At time: 144.34927320480347 and batch: 150, loss is 4.7776580429077145 and perplexity is 118.82573914223686
At time: 144.7404820919037 and batch: 200, loss is 4.830913887023926 and perplexity is 125.32544163033216
At time: 145.11941981315613 and batch: 250, loss is 4.847756967544556 and perplexity is 127.45418510898615
At time: 145.50309801101685 and batch: 300, loss is 4.885008850097656 and perplexity is 132.29163612301275
At time: 145.90368843078613 and batch: 350, loss is 4.922999305725098 and perplexity is 137.4141427515385
At time: 146.28193640708923 and batch: 400, loss is 4.77764178276062 and perplexity is 118.82380703394801
At time: 146.65811467170715 and batch: 450, loss is 4.852955236434936 and perplexity is 128.11845125559344
At time: 147.03406643867493 and batch: 500, loss is 4.827155208587646 and perplexity is 124.85526776508134
At time: 147.41130805015564 and batch: 550, loss is 4.89632435798645 and perplexity is 133.79708456887602
At time: 147.80797576904297 and batch: 600, loss is 4.7575230884552 and perplexity is 116.45711439525338
At time: 148.19640445709229 and batch: 650, loss is 4.9019058799743656 and perplexity is 134.5459639374708
At time: 148.5895483493805 and batch: 700, loss is 4.937692928314209 and perplexity is 139.44816125798977
At time: 148.98757576942444 and batch: 750, loss is 4.874161701202393 and perplexity is 130.86440374351477
At time: 149.3679313659668 and batch: 800, loss is 4.791505136489868 and perplexity is 120.48257497888123
At time: 149.77357578277588 and batch: 850, loss is 4.74372410774231 and perplexity is 114.86116150535817
At time: 150.16567945480347 and batch: 900, loss is 4.706953496932983 and perplexity is 110.71435398460474
At time: 150.5633647441864 and batch: 950, loss is 4.766892194747925 and perplexity is 117.55334079047704
At time: 150.95666885375977 and batch: 1000, loss is 4.822433042526245 and perplexity is 124.26707033303964
At time: 151.35238552093506 and batch: 1050, loss is 4.749340333938599 and perplexity is 115.50806264071359
At time: 151.7447476387024 and batch: 1100, loss is 4.861722536087036 and perplexity is 129.24664247739074
At time: 152.12192702293396 and batch: 1150, loss is 4.812607126235962 and perplexity is 123.05201180998019
At time: 152.49806714057922 and batch: 1200, loss is 4.756332902908325 and perplexity is 116.31859127133137
At time: 152.88147830963135 and batch: 1250, loss is 4.746111755371094 and perplexity is 115.13573714976584
At time: 153.2730576992035 and batch: 1300, loss is 4.862087078094483 and perplexity is 129.2937668967885
At time: 153.65500497817993 and batch: 1350, loss is 4.795274124145508 and perplexity is 120.9375291364362
At time: 154.03375244140625 and batch: 1400, loss is 4.64664249420166 and perplexity is 104.2344297076154
At time: 154.43814778327942 and batch: 1450, loss is 4.747356901168823 and perplexity is 115.27918721863797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.911141680856036 and perplexity of 135.79435976346198
Finished 13 epochs...
Completing Train Step...
At time: 155.70628333091736 and batch: 50, loss is 4.8472849559783935 and perplexity is 127.39403945529767
At time: 156.09774446487427 and batch: 100, loss is 4.8413518619537355 and perplexity is 126.64043645043924
At time: 156.4751889705658 and batch: 150, loss is 4.74989764213562 and perplexity is 115.57245417214284
At time: 156.87084245681763 and batch: 200, loss is 4.807030401229858 and perplexity is 122.36769447697328
At time: 157.26346564292908 and batch: 250, loss is 4.8242598724365235 and perplexity is 124.49429261902834
At time: 157.64326691627502 and batch: 300, loss is 4.860539846420288 and perplexity is 129.09387416542987
At time: 158.02257871627808 and batch: 350, loss is 4.898442659378052 and perplexity is 134.08080751857662
At time: 158.4235541820526 and batch: 400, loss is 4.751291818618775 and perplexity is 115.73369494277803
At time: 158.833256483078 and batch: 450, loss is 4.827480192184448 and perplexity is 124.89585027304686
At time: 159.22673392295837 and batch: 500, loss is 4.801242694854737 and perplexity is 121.66151175195097
At time: 159.60904121398926 and batch: 550, loss is 4.870731496810913 and perplexity is 130.41628110661935
At time: 159.99435448646545 and batch: 600, loss is 4.734120979309082 and perplexity is 113.76341435902997
At time: 160.3737666606903 and batch: 650, loss is 4.876053380966186 and perplexity is 131.11219158160537
At time: 160.75263166427612 and batch: 700, loss is 4.912724351882934 and perplexity is 136.0094477241207
At time: 161.13112545013428 and batch: 750, loss is 4.849742650985718 and perplexity is 127.70752021228328
At time: 161.50966429710388 and batch: 800, loss is 4.766862878799438 and perplexity is 117.54989465330765
At time: 161.88562417030334 and batch: 850, loss is 4.71972578048706 and perplexity is 112.13749816113098
At time: 162.2934262752533 and batch: 900, loss is 4.680593318939209 and perplexity is 107.83403356929644
At time: 162.6938133239746 and batch: 950, loss is 4.743889417648315 and perplexity is 114.88015076268326
At time: 163.08987712860107 and batch: 1000, loss is 4.798394336700439 and perplexity is 121.31546925333217
At time: 163.5048635005951 and batch: 1050, loss is 4.726442546844482 and perplexity is 112.8932347479765
At time: 163.8953411579132 and batch: 1100, loss is 4.839653730392456 and perplexity is 126.42556681845444
At time: 164.2749445438385 and batch: 1150, loss is 4.7894820213317875 and perplexity is 120.23907125624797
At time: 164.65434002876282 and batch: 1200, loss is 4.732621269226074 and perplexity is 113.59293008988054
At time: 165.04304027557373 and batch: 1250, loss is 4.718892192840576 and perplexity is 112.04406067753277
At time: 165.42403388023376 and batch: 1300, loss is 4.836960830688477 and perplexity is 126.08557343649348
At time: 165.8055067062378 and batch: 1350, loss is 4.772706785202026 and perplexity is 118.23885638850292
At time: 166.19852828979492 and batch: 1400, loss is 4.621030559539795 and perplexity is 101.598681687127
At time: 166.5875265598297 and batch: 1450, loss is 4.723812055587769 and perplexity is 112.59666032026122
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.89319577991453 and perplexity of 133.3791440646555
Finished 14 epochs...
Completing Train Step...
At time: 167.8796670436859 and batch: 50, loss is 4.822012310028076 and perplexity is 124.21479813517557
At time: 168.27003979682922 and batch: 100, loss is 4.818109436035156 and perplexity is 123.73094824675479
At time: 168.6473331451416 and batch: 150, loss is 4.72395544052124 and perplexity is 112.61280614241649
At time: 169.03693294525146 and batch: 200, loss is 4.784803619384766 and perplexity is 119.67785836454327
At time: 169.42872524261475 and batch: 250, loss is 4.802339696884156 and perplexity is 121.79504790857084
At time: 169.8155267238617 and batch: 300, loss is 4.837721824645996 and perplexity is 126.18156031409369
At time: 170.20488119125366 and batch: 350, loss is 4.875578651428222 and perplexity is 131.04996352339174
At time: 170.60140705108643 and batch: 400, loss is 4.726629266738891 and perplexity is 112.91431612894354
At time: 170.9941110610962 and batch: 450, loss is 4.803667640686035 and perplexity is 121.9568923239012
At time: 171.36988258361816 and batch: 500, loss is 4.776940031051636 and perplexity is 118.74045147516759
At time: 171.74625873565674 and batch: 550, loss is 4.846793613433838 and perplexity is 127.33146071884725
At time: 172.1218843460083 and batch: 600, loss is 4.712207899093628 and perplexity is 111.29762274777815
At time: 172.49762320518494 and batch: 650, loss is 4.8518954944610595 and perplexity is 127.98275067167205
At time: 172.87323546409607 and batch: 700, loss is 4.889328947067261 and perplexity is 132.86438509410007
At time: 173.2610719203949 and batch: 750, loss is 4.82686146736145 and perplexity is 124.81859801160383
At time: 173.63649988174438 and batch: 800, loss is 4.743843288421631 and perplexity is 114.87485155239233
At time: 174.01230382919312 and batch: 850, loss is 4.697362871170044 and perplexity is 109.6576095690039
At time: 174.38825583457947 and batch: 900, loss is 4.655848169326783 and perplexity is 105.19840823328033
At time: 174.76427674293518 and batch: 950, loss is 4.72246057510376 and perplexity is 112.44459091383754
At time: 175.14000725746155 and batch: 1000, loss is 4.775920276641846 and perplexity is 118.61942709421616
At time: 175.51669001579285 and batch: 1050, loss is 4.704968748092651 and perplexity is 110.49483171926879
At time: 175.8926284313202 and batch: 1100, loss is 4.819011659622192 and perplexity is 123.84263160081157
At time: 176.26882123947144 and batch: 1150, loss is 4.7678858757019045 and perplexity is 117.67020936171755
At time: 176.64275217056274 and batch: 1200, loss is 4.710469455718994 and perplexity is 111.10430621650775
At time: 177.01833820343018 and batch: 1250, loss is 4.693365688323975 and perplexity is 109.2201629126699
At time: 177.39472150802612 and batch: 1300, loss is 4.813360137939453 and perplexity is 123.14470631065313
At time: 177.77059960365295 and batch: 1350, loss is 4.7515715312957765 and perplexity is 115.76607165228673
At time: 178.14704036712646 and batch: 1400, loss is 4.596998853683472 and perplexity is 99.18619622824325
At time: 178.52254104614258 and batch: 1450, loss is 4.7017792797088624 and perplexity is 110.14297336575453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.876490405482104 and perplexity of 131.16950334607316
Finished 15 epochs...
Completing Train Step...
At time: 179.7697868347168 and batch: 50, loss is 4.798314218521118 and perplexity is 121.30575006815901
At time: 180.14551401138306 and batch: 100, loss is 4.796313409805298 and perplexity is 121.06328311203077
At time: 180.52240753173828 and batch: 150, loss is 4.699647245407104 and perplexity is 109.90839492194314
At time: 180.89882612228394 and batch: 200, loss is 4.763992414474488 and perplexity is 117.21295569129121
At time: 181.29682636260986 and batch: 250, loss is 4.781813898086548 and perplexity is 119.32058925611581
At time: 181.68534398078918 and batch: 300, loss is 4.816323595046997 and perplexity is 123.51018163357818
At time: 182.06024360656738 and batch: 350, loss is 4.854166774749756 and perplexity is 128.2737657338477
At time: 182.45625734329224 and batch: 400, loss is 4.703456430435181 and perplexity is 110.32785472715183
At time: 182.8566288948059 and batch: 450, loss is 4.781290168762207 and perplexity is 119.25811392603401
At time: 183.2324299812317 and batch: 500, loss is 4.754060134887696 and perplexity is 116.05452628977629
At time: 183.60864281654358 and batch: 550, loss is 4.824278802871704 and perplexity is 124.4966493724722
At time: 183.98469710350037 and batch: 600, loss is 4.691612739562988 and perplexity is 109.02887327286926
At time: 184.36027097702026 and batch: 650, loss is 4.82920991897583 and perplexity is 125.112072920539
At time: 184.73578572273254 and batch: 700, loss is 4.867305679321289 and perplexity is 129.9702631541375
At time: 185.1116120815277 and batch: 750, loss is 4.805307846069336 and perplexity is 122.15709081365952
At time: 185.4874815940857 and batch: 800, loss is 4.722232999801636 and perplexity is 112.41900421364907
At time: 185.8656144142151 and batch: 850, loss is 4.676431312561035 and perplexity is 107.38616030600193
At time: 186.24705290794373 and batch: 900, loss is 4.632666187286377 and perplexity is 102.78775049234939
At time: 186.62233471870422 and batch: 950, loss is 4.702430896759033 and perplexity is 110.2147677938525
At time: 186.99833297729492 and batch: 1000, loss is 4.754815721511841 and perplexity is 116.14224867426911
At time: 187.39516067504883 and batch: 1050, loss is 4.684741249084473 and perplexity is 108.282250551547
At time: 187.78414607048035 and batch: 1100, loss is 4.799599094390869 and perplexity is 121.46171307437858
At time: 188.1595368385315 and batch: 1150, loss is 4.747627000808716 and perplexity is 115.3103282909998
At time: 188.5578203201294 and batch: 1200, loss is 4.689667482376098 and perplexity is 108.81699022388288
At time: 188.94128036499023 and batch: 1250, loss is 4.66934663772583 and perplexity is 106.62805292153416
At time: 189.31753635406494 and batch: 1300, loss is 4.791081256866455 and perplexity is 120.4315156926314
At time: 189.69355607032776 and batch: 1350, loss is 4.731677770614624 and perplexity is 113.48580586179713
At time: 190.06949377059937 and batch: 1400, loss is 4.574376850128174 and perplexity is 96.96759496162764
At time: 190.4567060470581 and batch: 1450, loss is 4.681084613800049 and perplexity is 107.88702489192903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8609619140625 and perplexity of 129.1483720126028
Finished 16 epochs...
Completing Train Step...
At time: 191.720383644104 and batch: 50, loss is 4.776033325195312 and perplexity is 118.63283760686747
At time: 192.09756088256836 and batch: 100, loss is 4.775776176452637 and perplexity is 118.60233524382708
At time: 192.48786520957947 and batch: 150, loss is 4.676794719696045 and perplexity is 107.42519229468051
At time: 192.8649513721466 and batch: 200, loss is 4.744422922134399 and perplexity is 114.9414561903834
At time: 193.25102400779724 and batch: 250, loss is 4.762517995834351 and perplexity is 117.04026206718869
At time: 193.62849736213684 and batch: 300, loss is 4.796176853179932 and perplexity is 121.04675224735853
At time: 194.00524878501892 and batch: 350, loss is 4.833993673324585 and perplexity is 125.71201218037696
At time: 194.38337182998657 and batch: 400, loss is 4.681559743881226 and perplexity is 107.93829744242483
At time: 194.76076292991638 and batch: 450, loss is 4.760188817977905 and perplexity is 116.76797170990406
At time: 195.1375608444214 and batch: 500, loss is 4.732401876449585 and perplexity is 113.56801135515374
At time: 195.514226436615 and batch: 550, loss is 4.803026838302612 and perplexity is 121.87876709071642
At time: 195.89127254486084 and batch: 600, loss is 4.672201356887817 and perplexity is 106.93288095962103
At time: 196.26864957809448 and batch: 650, loss is 4.8078775978088375 and perplexity is 122.47140789573523
At time: 196.64686012268066 and batch: 700, loss is 4.846504192352295 and perplexity is 127.29461364218922
At time: 197.02399134635925 and batch: 750, loss is 4.784909296035766 and perplexity is 119.6905061880922
At time: 197.4007339477539 and batch: 800, loss is 4.701866779327393 and perplexity is 110.15261125555752
At time: 197.77771067619324 and batch: 850, loss is 4.656769590377808 and perplexity is 105.29538493248563
At time: 198.15506744384766 and batch: 900, loss is 4.610784635543824 and perplexity is 100.56302401155747
At time: 198.53170919418335 and batch: 950, loss is 4.683597736358642 and perplexity is 108.15849918917358
At time: 198.90932393074036 and batch: 1000, loss is 4.734909420013428 and perplexity is 113.85314543474391
At time: 199.28731155395508 and batch: 1050, loss is 4.665559453964233 and perplexity is 106.22499659690776
At time: 199.6650960445404 and batch: 1100, loss is 4.781260061264038 and perplexity is 119.25452341663822
At time: 200.04253935813904 and batch: 1150, loss is 4.728568534851075 and perplexity is 113.13349972080516
At time: 200.42041277885437 and batch: 1200, loss is 4.670063505172729 and perplexity is 106.70451850616942
At time: 200.79787278175354 and batch: 1250, loss is 4.646641435623169 and perplexity is 104.23431936734853
At time: 201.17525267601013 and batch: 1300, loss is 4.769955739974976 and perplexity is 117.9140229675679
At time: 201.55284762382507 and batch: 1350, loss is 4.712874574661255 and perplexity is 111.37184689256182
At time: 201.93022966384888 and batch: 1400, loss is 4.553016834259033 and perplexity is 94.91832967817096
At time: 202.3072214126587 and batch: 1450, loss is 4.661586303710937 and perplexity is 105.80378604527695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.84651118873531 and perplexity of 127.2955042471774
Finished 17 epochs...
Completing Train Step...
At time: 203.53874588012695 and batch: 50, loss is 4.754956493377685 and perplexity is 116.15859938615142
At time: 203.93048071861267 and batch: 100, loss is 4.756357736587525 and perplexity is 116.32147992577971
At time: 204.32099294662476 and batch: 150, loss is 4.655227003097534 and perplexity is 105.13308282578409
At time: 204.69830226898193 and batch: 200, loss is 4.725948638916016 and perplexity is 112.83748965186999
At time: 205.07384300231934 and batch: 250, loss is 4.7443152523040775 and perplexity is 114.92908112952075
At time: 205.4498474597931 and batch: 300, loss is 4.777155838012695 and perplexity is 118.76607925638261
At time: 205.82563471794128 and batch: 350, loss is 4.81489275932312 and perplexity is 123.33358522378894
At time: 206.20070028305054 and batch: 400, loss is 4.660736150741577 and perplexity is 105.71387486694404
At time: 206.5753312110901 and batch: 450, loss is 4.740236911773682 and perplexity is 114.46131570153722
At time: 206.95050048828125 and batch: 500, loss is 4.7118307304382325 and perplexity is 111.2556526884506
At time: 207.3260748386383 and batch: 550, loss is 4.7828868389129635 and perplexity is 119.44868189338234
At time: 207.70233917236328 and batch: 600, loss is 4.653852396011352 and perplexity is 104.98866542647015
At time: 208.09623956680298 and batch: 650, loss is 4.787764530181885 and perplexity is 120.03273895316464
At time: 208.482971906662 and batch: 700, loss is 4.826776742935181 and perplexity is 124.8080232754751
At time: 208.88036274909973 and batch: 750, loss is 4.765524263381958 and perplexity is 117.39264582333671
At time: 209.264422416687 and batch: 800, loss is 4.682609758377075 and perplexity is 108.05169374285771
At time: 209.6433551311493 and batch: 850, loss is 4.6381572818756105 and perplexity is 103.35372022749435
At time: 210.03200936317444 and batch: 900, loss is 4.590053434371948 and perplexity is 98.49969329057717
At time: 210.40787887573242 and batch: 950, loss is 4.665774574279785 and perplexity is 106.24785020974528
At time: 210.79596257209778 and batch: 1000, loss is 4.716063680648804 and perplexity is 111.72759046680825
At time: 211.18691778182983 and batch: 1050, loss is 4.647293930053711 and perplexity is 104.3023538738615
At time: 211.56700468063354 and batch: 1100, loss is 4.763897171020508 and perplexity is 117.20179245616099
At time: 211.9645779132843 and batch: 1150, loss is 4.710590877532959 and perplexity is 111.11779752196071
At time: 212.35981607437134 and batch: 1200, loss is 4.65151909828186 and perplexity is 104.74398118341331
At time: 212.74439358711243 and batch: 1250, loss is 4.625141820907593 and perplexity is 102.01724023440329
At time: 213.12080550193787 and batch: 1300, loss is 4.749867744445801 and perplexity is 115.56899887440935
At time: 213.497252702713 and batch: 1350, loss is 4.695049352645874 and perplexity is 109.4042078957074
At time: 213.8737359046936 and batch: 1400, loss is 4.532767324447632 and perplexity is 93.01560962023173
At time: 214.2570676803589 and batch: 1450, loss is 4.643154916763305 and perplexity is 103.87153723788997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.83299059745593 and perplexity of 125.58597671669251
Finished 18 epochs...
Completing Train Step...
At time: 215.48602437973022 and batch: 50, loss is 4.734934282302857 and perplexity is 113.85597611978662
At time: 215.87411069869995 and batch: 100, loss is 4.737939004898071 and perplexity is 114.19859622524547
At time: 216.24947929382324 and batch: 150, loss is 4.634862909317016 and perplexity is 103.01379479568661
At time: 216.6500072479248 and batch: 200, loss is 4.708443260192871 and perplexity is 110.87941508196445
At time: 217.03749442100525 and batch: 250, loss is 4.727078046798706 and perplexity is 112.96500119486258
At time: 217.41378355026245 and batch: 300, loss is 4.759132528305054 and perplexity is 116.64469602614498
At time: 217.7885296344757 and batch: 350, loss is 4.7967362976074215 and perplexity is 121.11449012439122
At time: 218.16429686546326 and batch: 400, loss is 4.640919380187988 and perplexity is 103.63958797938533
At time: 218.5405604839325 and batch: 450, loss is 4.721319103240967 and perplexity is 112.31631180461156
At time: 218.9333086013794 and batch: 500, loss is 4.692236976623535 and perplexity is 109.0969543834013
At time: 219.32376909255981 and batch: 550, loss is 4.763715858459473 and perplexity is 117.18054422535663
At time: 219.700035572052 and batch: 600, loss is 4.6364383792877195 and perplexity is 103.17621784868072
At time: 220.0767741203308 and batch: 650, loss is 4.768718919754028 and perplexity is 117.76827467042843
At time: 220.4534878730774 and batch: 700, loss is 4.807986459732056 and perplexity is 122.48474109446364
At time: 220.82851314544678 and batch: 750, loss is 4.747049503326416 and perplexity is 115.24375609121756
At time: 221.2042591571808 and batch: 800, loss is 4.6643369674682615 and perplexity is 106.09521731590527
At time: 221.61233520507812 and batch: 850, loss is 4.620479440689087 and perplexity is 101.54270416499276
At time: 221.99814915657043 and batch: 900, loss is 4.570377855300904 and perplexity is 96.58059636938619
At time: 222.38092756271362 and batch: 950, loss is 4.648828344345093 and perplexity is 104.46251974524645
At time: 222.77565264701843 and batch: 1000, loss is 4.698163146972656 and perplexity is 109.74540102451765
At time: 223.15887594223022 and batch: 1050, loss is 4.629861736297608 and perplexity is 102.49989111627019
At time: 223.53530621528625 and batch: 1100, loss is 4.747409162521362 and perplexity is 115.28521202231242
At time: 223.9121377468109 and batch: 1150, loss is 4.693565130233765 and perplexity is 109.24194816292253
At time: 224.28843331336975 and batch: 1200, loss is 4.6339170932769775 and perplexity is 102.91640875812165
At time: 224.66482663154602 and batch: 1250, loss is 4.60472957611084 and perplexity is 99.95594871770255
At time: 225.04283785820007 and batch: 1300, loss is 4.730719022750854 and perplexity is 113.37705372912677
At time: 225.4401605129242 and batch: 1350, loss is 4.678098945617676 and perplexity is 107.56539042024905
At time: 225.82286858558655 and batch: 1400, loss is 4.513514490127563 and perplexity is 91.24192451928253
At time: 226.1990373134613 and batch: 1450, loss is 4.625677661895752 and perplexity is 102.07191990171494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.820272331563835 and perplexity of 123.99885498417756
Finished 19 epochs...
Completing Train Step...
At time: 227.44479322433472 and batch: 50, loss is 4.715853757858277 and perplexity is 111.70413876084845
At time: 227.82199501991272 and batch: 100, loss is 4.720409574508667 and perplexity is 112.21420333425216
At time: 228.2014811038971 and batch: 150, loss is 4.6155808067321775 and perplexity is 101.04649997989708
At time: 228.57975125312805 and batch: 200, loss is 4.691806764602661 and perplexity is 109.05002965669927
At time: 228.95836281776428 and batch: 250, loss is 4.710683069229126 and perplexity is 111.12804213241535
At time: 229.33598923683167 and batch: 300, loss is 4.742000675201416 and perplexity is 114.66337652542563
At time: 229.7154402732849 and batch: 350, loss is 4.779421911239624 and perplexity is 119.03551705644648
At time: 230.09378957748413 and batch: 400, loss is 4.62203595161438 and perplexity is 101.70087956234178
At time: 230.4725215435028 and batch: 450, loss is 4.703338117599487 and perplexity is 110.31480229795322
At time: 230.85080575942993 and batch: 500, loss is 4.673500127792359 and perplexity is 107.0718525007124
At time: 231.24927878379822 and batch: 550, loss is 4.745412673950195 and perplexity is 115.05527602275937
At time: 231.62752318382263 and batch: 600, loss is 4.619844398498535 and perplexity is 101.4782407343708
At time: 232.00630497932434 and batch: 650, loss is 4.750600519180298 and perplexity is 115.653715952352
At time: 232.3845887184143 and batch: 700, loss is 4.790018815994262 and perplexity is 120.30363227437395
At time: 232.76344108581543 and batch: 750, loss is 4.729400033950806 and perplexity is 113.22760924454236
At time: 233.14240336418152 and batch: 800, loss is 4.64693356513977 and perplexity is 104.26477373677209
At time: 233.52102971076965 and batch: 850, loss is 4.603660793304443 and perplexity is 99.84917458765716
At time: 233.89974212646484 and batch: 900, loss is 4.551629238128662 and perplexity is 94.78671270792574
At time: 234.27902340888977 and batch: 950, loss is 4.632666263580322 and perplexity is 102.78775833443271
At time: 234.6568660736084 and batch: 1000, loss is 4.681115884780883 and perplexity is 107.8903986777672
At time: 235.03579998016357 and batch: 1050, loss is 4.613180532455444 and perplexity is 100.80425151292913
At time: 235.41450810432434 and batch: 1100, loss is 4.7316961765289305 and perplexity is 113.48789469103818
At time: 235.79285645484924 and batch: 1150, loss is 4.677375707626343 and perplexity is 107.48762316884971
At time: 236.17265439033508 and batch: 1200, loss is 4.617150030136108 and perplexity is 101.20518898924072
At time: 236.55155992507935 and batch: 1250, loss is 4.585275526046753 and perplexity is 98.03019329310935
At time: 236.93025016784668 and batch: 1300, loss is 4.712407999038696 and perplexity is 111.31989562430252
At time: 237.30915021896362 and batch: 1350, loss is 4.661929054260254 and perplexity is 105.84005656657922
At time: 237.6875138282776 and batch: 1400, loss is 4.495165271759033 and perplexity is 89.58297329732062
At time: 238.06423091888428 and batch: 1450, loss is 4.609055643081665 and perplexity is 100.38930152678034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.808308919270833 and perplexity of 122.5242438362599
Finished 20 epochs...
Completing Train Step...
At time: 239.30733633041382 and batch: 50, loss is 4.697616062164307 and perplexity is 109.68537740333362
At time: 239.68388533592224 and batch: 100, loss is 4.7036786556243895 and perplexity is 110.35237507996266
At time: 240.07364654541016 and batch: 150, loss is 4.597258358001709 and perplexity is 99.21193881448572
At time: 240.46579098701477 and batch: 200, loss is 4.675951881408691 and perplexity is 107.33468837503018
At time: 240.8604543209076 and batch: 250, loss is 4.6950244140625 and perplexity is 109.40147954376803
At time: 241.23817133903503 and batch: 300, loss is 4.725677700042724 and perplexity is 112.8069217307647
At time: 241.61580967903137 and batch: 350, loss is 4.762869033813477 and perplexity is 117.08135485640398
At time: 242.00111269950867 and batch: 400, loss is 4.6039426898956295 and perplexity is 99.87732569727069
At time: 242.3980143070221 and batch: 450, loss is 4.686204433441162 and perplexity is 108.4408034144082
At time: 242.78505969047546 and batch: 500, loss is 4.655537242889404 and perplexity is 105.1657043515047
At time: 243.16259384155273 and batch: 550, loss is 4.7278960418701175 and perplexity is 113.05744381273031
At time: 243.53955101966858 and batch: 600, loss is 4.603983907699585 and perplexity is 99.88144250614323
At time: 243.9166669845581 and batch: 650, loss is 4.733296375274659 and perplexity is 113.66964325590821
At time: 244.29463291168213 and batch: 700, loss is 4.77281002998352 and perplexity is 118.25106456359919
At time: 244.67204117774963 and batch: 750, loss is 4.712499942779541 and perplexity is 111.3301312624809
At time: 245.04935836791992 and batch: 800, loss is 4.630315084457397 and perplexity is 102.54636978800045
At time: 245.42673420906067 and batch: 850, loss is 4.587610025405883 and perplexity is 98.25931205126864
At time: 245.80454778671265 and batch: 900, loss is 4.533716554641724 and perplexity is 93.10394476396513
At time: 246.1882679462433 and batch: 950, loss is 4.617220497131347 and perplexity is 101.2123208660894
At time: 246.56607818603516 and batch: 1000, loss is 4.664848918914795 and perplexity is 106.14954682172836
At time: 246.94353580474854 and batch: 1050, loss is 4.5971878719329835 and perplexity is 99.20494600139888
At time: 247.3200786113739 and batch: 1100, loss is 4.7166684627532955 and perplexity is 111.79518175103989
At time: 247.69628143310547 and batch: 1150, loss is 4.661929349899292 and perplexity is 105.84008785703642
At time: 248.07416319847107 and batch: 1200, loss is 4.601123809814453 and perplexity is 99.59617993755978
At time: 248.45213747024536 and batch: 1250, loss is 4.566711683273315 and perplexity is 96.22716355718252
At time: 248.82954335212708 and batch: 1300, loss is 4.69484652519226 and perplexity is 109.38201996904166
At time: 249.20700478553772 and batch: 1350, loss is 4.646461248397827 and perplexity is 104.21553936656524
At time: 249.58314514160156 and batch: 1400, loss is 4.4776645755767825 and perplexity is 88.02884770399402
At time: 249.95875573158264 and batch: 1450, loss is 4.593197059631348 and perplexity is 98.8098266305446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7970560187967415 and perplexity of 121.1532191841383
Finished 21 epochs...
Completing Train Step...
At time: 251.20452499389648 and batch: 50, loss is 4.680150051116943 and perplexity is 107.78624480446332
At time: 251.60061860084534 and batch: 100, loss is 4.687670679092407 and perplexity is 108.59992089498212
At time: 251.9786081314087 and batch: 150, loss is 4.579790544509888 and perplexity is 97.49397142072941
At time: 252.35736322402954 and batch: 200, loss is 4.660802659988403 and perplexity is 105.72090605095723
At time: 252.73513388633728 and batch: 250, loss is 4.6800158596038814 and perplexity is 107.77178177561537
At time: 253.1113245487213 and batch: 300, loss is 4.710094738006592 and perplexity is 111.06268126433474
At time: 253.50134229660034 and batch: 350, loss is 4.747016277313232 and perplexity is 115.23992706427036
At time: 253.87750124931335 and batch: 400, loss is 4.586555233001709 and perplexity is 98.15572351708136
At time: 254.26515865325928 and batch: 450, loss is 4.669841623306274 and perplexity is 106.6808453348649
At time: 254.6639461517334 and batch: 500, loss is 4.638305263519287 and perplexity is 103.36901581259872
At time: 255.0487983226776 and batch: 550, loss is 4.711109275817871 and perplexity is 111.17541573091931
At time: 255.42377853393555 and batch: 600, loss is 4.5887895107269285 and perplexity is 98.37527584284014
At time: 255.8126621246338 and batch: 650, loss is 4.7167229652404785 and perplexity is 111.80127503254839
At time: 256.20510172843933 and batch: 700, loss is 4.75632791519165 and perplexity is 116.31801110860088
At time: 256.5828709602356 and batch: 750, loss is 4.696277046203614 and perplexity is 109.53860521941412
At time: 256.9803104400635 and batch: 800, loss is 4.614415073394776 and perplexity is 100.92877533734465
At time: 257.3646459579468 and batch: 850, loss is 4.572240562438965 and perplexity is 96.76066539150293
At time: 257.74047660827637 and batch: 900, loss is 4.5165721035003665 and perplexity is 91.52133399324181
At time: 258.11652421951294 and batch: 950, loss is 4.602434978485108 and perplexity is 99.72685297688774
At time: 258.5012140274048 and batch: 1000, loss is 4.649294090270996 and perplexity is 104.51118406995322
At time: 258.8860213756561 and batch: 1050, loss is 4.581836557388305 and perplexity is 97.69364954417314
At time: 259.26158690452576 and batch: 1100, loss is 4.702253913879394 and perplexity is 110.19526339289307
At time: 259.63800621032715 and batch: 1150, loss is 4.6471484279632564 and perplexity is 104.28717876736518
At time: 260.01433277130127 and batch: 1200, loss is 4.5857623672485355 and perplexity is 98.07793004939018
At time: 260.4133267402649 and batch: 1250, loss is 4.549005184173584 and perplexity is 94.53831330880134
At time: 260.7894551753998 and batch: 1300, loss is 4.677976293563843 and perplexity is 107.55219811324092
At time: 261.16522884368896 and batch: 1350, loss is 4.631622333526611 and perplexity is 102.68051109340256
At time: 261.55411171913147 and batch: 1400, loss is 4.460962209701538 and perplexity is 86.57076826661067
At time: 261.946177482605 and batch: 1450, loss is 4.578019962310791 and perplexity is 97.32150306017398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.786427554921207 and perplexity of 119.87236538235021
Finished 22 epochs...
Completing Train Step...
At time: 263.1727511882782 and batch: 50, loss is 4.663397188186646 and perplexity is 105.99555806497767
At time: 263.56174397468567 and batch: 100, loss is 4.672322788238525 and perplexity is 106.94586675221628
At time: 263.9370412826538 and batch: 150, loss is 4.563084859848022 and perplexity is 95.87879674057297
At time: 264.3123471736908 and batch: 200, loss is 4.646290731430054 and perplexity is 104.19777036379888
At time: 264.68761682510376 and batch: 250, loss is 4.665592565536499 and perplexity is 106.2285139317909
At time: 265.077246427536 and batch: 300, loss is 4.695191984176636 and perplexity is 109.41981349825032
At time: 265.4670898914337 and batch: 350, loss is 4.7318124675750735 and perplexity is 113.50109308444898
At time: 265.8437592983246 and batch: 400, loss is 4.569819526672363 and perplexity is 96.5266877082465
At time: 266.2202606201172 and batch: 450, loss is 4.654175710678101 and perplexity is 105.0226152897935
At time: 266.59631299972534 and batch: 500, loss is 4.621756706237793 and perplexity is 101.67248402677474
At time: 266.9721522331238 and batch: 550, loss is 4.6949959659576415 and perplexity is 109.3983673232749
At time: 267.3700394630432 and batch: 600, loss is 4.574195747375488 and perplexity is 96.9500354533444
At time: 267.75681233406067 and batch: 650, loss is 4.7008206748962404 and perplexity is 110.03744037170901
At time: 268.147097826004 and batch: 700, loss is 4.740511026382446 and perplexity is 114.49269552094637
At time: 268.5398235321045 and batch: 750, loss is 4.680675973892212 and perplexity is 107.84294695463586
At time: 268.9293866157532 and batch: 800, loss is 4.599175162315369 and perplexity is 99.40229106249521
At time: 269.3224949836731 and batch: 850, loss is 4.5574782180786135 and perplexity is 95.34274280935918
At time: 269.7184262275696 and batch: 900, loss is 4.500137214660644 and perplexity is 90.02948381809927
At time: 270.14472126960754 and batch: 950, loss is 4.588256950378418 and perplexity is 98.32289901979996
At time: 270.5358452796936 and batch: 1000, loss is 4.634382085800171 and perplexity is 102.96427524662526
At time: 270.9122476577759 and batch: 1050, loss is 4.567083778381348 and perplexity is 96.26297587638324
At time: 271.28800654411316 and batch: 1100, loss is 4.68840030670166 and perplexity is 108.6791873095956
At time: 271.6636049747467 and batch: 1150, loss is 4.632966594696045 and perplexity is 102.81863333270518
At time: 272.03970766067505 and batch: 1200, loss is 4.571007976531982 and perplexity is 96.64147303149313
At time: 272.41516876220703 and batch: 1250, loss is 4.532101068496704 and perplexity is 92.95365805688361
At time: 272.81469559669495 and batch: 1300, loss is 4.661754903793335 and perplexity is 105.82162607619523
At time: 273.2094655036926 and batch: 1350, loss is 4.6173544597625735 and perplexity is 101.22588044312317
At time: 273.59262323379517 and batch: 1400, loss is 4.444986505508423 and perplexity is 85.19872811604618
At time: 273.98653650283813 and batch: 1450, loss is 4.563450136184692 and perplexity is 95.91382539339024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7763285840678416 and perplexity of 118.66787017632818
Finished 23 epochs...
Completing Train Step...
At time: 275.2907555103302 and batch: 50, loss is 4.647299566268921 and perplexity is 104.30294174603155
At time: 275.6809871196747 and batch: 100, loss is 4.657583017349243 and perplexity is 105.38106988305772
At time: 276.0588698387146 and batch: 150, loss is 4.547061414718628 and perplexity is 94.35473110161345
At time: 276.4591829776764 and batch: 200, loss is 4.632350788116455 and perplexity is 102.75533643311839
At time: 276.845383644104 and batch: 250, loss is 4.651720886230469 and perplexity is 104.76511938915124
At time: 277.2227072715759 and batch: 300, loss is 4.680918102264404 and perplexity is 107.86906195329786
At time: 277.60040378570557 and batch: 350, loss is 4.71720368385315 and perplexity is 111.85503290654697
At time: 277.9781382083893 and batch: 400, loss is 4.553701124191284 and perplexity is 94.98330356350829
At time: 278.35630202293396 and batch: 450, loss is 4.639127931594849 and perplexity is 103.45408919068804
At time: 278.73336458206177 and batch: 500, loss is 4.605832023620605 and perplexity is 100.06620566953653
At time: 279.1092903614044 and batch: 550, loss is 4.679501008987427 and perplexity is 107.71630968847624
At time: 279.48574805259705 and batch: 600, loss is 4.560156221389771 and perplexity is 95.59841318054846
At time: 279.87775802612305 and batch: 650, loss is 4.685538473129273 and perplexity is 108.36861018472584
At time: 280.25530195236206 and batch: 700, loss is 4.725305519104004 and perplexity is 112.7649449567029
At time: 280.6335754394531 and batch: 750, loss is 4.665658826828003 and perplexity is 106.23555300352501
At time: 281.02224254608154 and batch: 800, loss is 4.584539966583252 and perplexity is 97.95811276972924
At time: 281.40002274513245 and batch: 850, loss is 4.543259649276734 and perplexity is 93.9966975566453
At time: 281.7773904800415 and batch: 900, loss is 4.484351758956909 and perplexity is 88.61948540159892
At time: 282.15444588661194 and batch: 950, loss is 4.574646673202515 and perplexity is 96.99376258636731
At time: 282.5321362018585 and batch: 1000, loss is 4.620053424835205 and perplexity is 101.49945457633177
At time: 282.90893173217773 and batch: 1050, loss is 4.552887058258056 and perplexity is 94.90601235618963
At time: 283.2859389781952 and batch: 1100, loss is 4.675061330795288 and perplexity is 107.23914395234503
At time: 283.6624240875244 and batch: 1150, loss is 4.619328556060791 and perplexity is 101.42590745031723
At time: 284.0389711856842 and batch: 1200, loss is 4.556810302734375 and perplexity is 95.27908319045974
At time: 284.4155533313751 and batch: 1250, loss is 4.5159150505065915 and perplexity is 91.4612193781539
At time: 284.79208731651306 and batch: 1300, loss is 4.64614725112915 and perplexity is 104.18282110884105
At time: 285.1680624485016 and batch: 1350, loss is 4.603613615036011 and perplexity is 99.84446398761557
At time: 285.54572200775146 and batch: 1400, loss is 4.42967396736145 and perplexity is 83.90405698931228
At time: 285.92311906814575 and batch: 1450, loss is 4.549423999786377 and perplexity is 94.57791572289798
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.766779451288729 and perplexity of 117.5400881672836
Finished 24 epochs...
Completing Train Step...
At time: 287.1765718460083 and batch: 50, loss is 4.631818313598632 and perplexity is 102.70063639937688
At time: 287.55209136009216 and batch: 100, loss is 4.643407897949219 and perplexity is 103.89781810670559
At time: 287.9279942512512 and batch: 150, loss is 4.5316495609283445 and perplexity is 92.9116982500622
At time: 288.3042149543762 and batch: 200, loss is 4.61892336845398 and perplexity is 101.38481925438487
At time: 288.6806290149689 and batch: 250, loss is 4.638369607925415 and perplexity is 103.3756672445221
At time: 289.0565023422241 and batch: 300, loss is 4.667234649658203 and perplexity is 106.40309338563655
At time: 289.43265414237976 and batch: 350, loss is 4.703136796951294 and perplexity is 110.29259588582896
At time: 289.8224985599518 and batch: 400, loss is 4.538161649703979 and perplexity is 93.51872182789104
At time: 290.1985852718353 and batch: 450, loss is 4.624631872177124 and perplexity is 101.96522993468011
At time: 290.5747151374817 and batch: 500, loss is 4.59048433303833 and perplexity is 98.542145822768
At time: 290.9505259990692 and batch: 550, loss is 4.664583320617676 and perplexity is 106.12135742654594
At time: 291.3264727592468 and batch: 600, loss is 4.54663405418396 and perplexity is 94.31441622838788
At time: 291.70259165763855 and batch: 650, loss is 4.670827140808106 and perplexity is 106.78603299868085
At time: 292.0789692401886 and batch: 700, loss is 4.710660743713379 and perplexity is 111.12556116925525
At time: 292.4552581310272 and batch: 750, loss is 4.651193265914917 and perplexity is 104.70985776366045
At time: 292.8313744068146 and batch: 800, loss is 4.5704475688934325 and perplexity is 96.58732958442326
At time: 293.2067174911499 and batch: 850, loss is 4.529545526504517 and perplexity is 92.71641435263196
At time: 293.5810697078705 and batch: 900, loss is 4.469155006408691 and perplexity is 87.28293832052351
At time: 293.95657444000244 and batch: 950, loss is 4.56156735420227 and perplexity is 95.7334104653579
At time: 294.34825801849365 and batch: 1000, loss is 4.606267080307007 and perplexity is 100.10974961275093
At time: 294.733571767807 and batch: 1050, loss is 4.539203443527222 and perplexity is 93.61619982181851
At time: 295.12103033065796 and batch: 1100, loss is 4.662196226119995 and perplexity is 105.8683378291378
At time: 295.5122261047363 and batch: 1150, loss is 4.606190948486328 and perplexity is 100.10212836535861
At time: 295.89572620391846 and batch: 1200, loss is 4.543127164840699 and perplexity is 93.98424528206485
At time: 296.2708508968353 and batch: 1250, loss is 4.500369443893432 and perplexity is 90.05039372390635
At time: 296.64734625816345 and batch: 1300, loss is 4.631122245788574 and perplexity is 102.62917466629811
At time: 297.023152589798 and batch: 1350, loss is 4.590357866287231 and perplexity is 98.52968430573988
At time: 297.40711402893066 and batch: 1400, loss is 4.41497875213623 and perplexity is 82.68008411228054
At time: 297.8034579753876 and batch: 1450, loss is 4.535899686813354 and perplexity is 93.30742501240671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.757778591579861 and perplexity of 116.4868733534618
Finished 25 epochs...
Completing Train Step...
At time: 299.0413796901703 and batch: 50, loss is 4.616916246414185 and perplexity is 101.18153162894147
At time: 299.45148038864136 and batch: 100, loss is 4.629765214920044 and perplexity is 102.48999816302796
At time: 299.84132647514343 and batch: 150, loss is 4.516798868179321 and perplexity is 91.54209015245522
At time: 300.2344002723694 and batch: 200, loss is 4.60596586227417 and perplexity is 100.07959929204284
At time: 300.62631273269653 and batch: 250, loss is 4.625496788024902 and perplexity is 102.05345942801624
At time: 301.00370478630066 and batch: 300, loss is 4.65409553527832 and perplexity is 105.0141953971653
At time: 301.37976241111755 and batch: 350, loss is 4.689556303024292 and perplexity is 108.80489269395456
At time: 301.7652654647827 and batch: 400, loss is 4.523164377212525 and perplexity is 92.12666072498475
At time: 302.15626430511475 and batch: 450, loss is 4.610644588470459 and perplexity is 100.5489414404904
At time: 302.53245735168457 and batch: 500, loss is 4.575679502487183 and perplexity is 97.09399233599706
At time: 302.9080271720886 and batch: 550, loss is 4.650193881988526 and perplexity is 104.60526468790144
At time: 303.2833161354065 and batch: 600, loss is 4.533581209182739 and perplexity is 93.09134442054668
At time: 303.6663043498993 and batch: 650, loss is 4.6566383743286135 and perplexity is 105.28156939450638
At time: 304.05895590782166 and batch: 700, loss is 4.696522922515869 and perplexity is 109.56554147907345
At time: 304.4372971057892 and batch: 750, loss is 4.637245550155639 and perplexity is 103.25953230596828
At time: 304.8333604335785 and batch: 800, loss is 4.556840462684631 and perplexity is 95.28195684620368
At time: 305.21574997901917 and batch: 850, loss is 4.516306872367859 and perplexity is 91.49706290504457
At time: 305.5917258262634 and batch: 900, loss is 4.454494042396545 and perplexity is 86.01262109432705
At time: 305.9759147167206 and batch: 950, loss is 4.548977298736572 and perplexity is 94.5356771033764
At time: 306.37198424339294 and batch: 1000, loss is 4.5929861259460445 and perplexity is 98.78898650768848
At time: 306.74809765815735 and batch: 1050, loss is 4.525996208190918 and perplexity is 92.38791759982674
At time: 307.12265944480896 and batch: 1100, loss is 4.649762287139892 and perplexity is 104.56012733574721
At time: 307.4974670410156 and batch: 1150, loss is 4.593519554138184 and perplexity is 98.84169739565151
At time: 307.87345576286316 and batch: 1200, loss is 4.529916667938233 and perplexity is 92.75083164202977
At time: 308.2488474845886 and batch: 1250, loss is 4.485401873588562 and perplexity is 88.71259489913523
At time: 308.6240494251251 and batch: 1300, loss is 4.616644296646118 and perplexity is 101.15401907606811
At time: 309.00106263160706 and batch: 1350, loss is 4.577553844451904 and perplexity is 97.27615034022136
At time: 309.3771507740021 and batch: 1400, loss is 4.400855970382691 and perplexity is 81.52061804363223
At time: 309.7533242702484 and batch: 1450, loss is 4.522845516204834 and perplexity is 92.09728980797972
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.749268621461004 and perplexity of 115.49977956836287
Finished 26 epochs...
Completing Train Step...
At time: 310.98151683807373 and batch: 50, loss is 4.602551555633545 and perplexity is 99.73847952671221
At time: 311.37026739120483 and batch: 100, loss is 4.616618509292603 and perplexity is 101.15141061525146
At time: 311.7462434768677 and batch: 150, loss is 4.502467651367187 and perplexity is 90.239536494028
At time: 312.1225516796112 and batch: 200, loss is 4.593437013626098 and perplexity is 98.83353928802487
At time: 312.49864625930786 and batch: 250, loss is 4.6130625438690185 and perplexity is 100.79235846342328
At time: 312.8753430843353 and batch: 300, loss is 4.641456356048584 and perplexity is 103.69525488088595
At time: 313.2516348361969 and batch: 350, loss is 4.6764324760437015 and perplexity is 107.38628524801076
At time: 313.6396973133087 and batch: 400, loss is 4.508663091659546 and perplexity is 90.80034559020636
At time: 314.0160346031189 and batch: 450, loss is 4.597138814926147 and perplexity is 99.20007942305554
At time: 314.39282512664795 and batch: 500, loss is 4.561365976333618 and perplexity is 95.71413381620997
At time: 314.78226017951965 and batch: 550, loss is 4.636286325454712 and perplexity is 103.16053070195726
At time: 315.1742687225342 and batch: 600, loss is 4.520950689315796 and perplexity is 91.9229466140929
At time: 315.55353903770447 and batch: 650, loss is 4.642924137115479 and perplexity is 103.84756856695411
At time: 315.92882776260376 and batch: 700, loss is 4.682852544784546 and perplexity is 108.0779304102269
At time: 316.3043713569641 and batch: 750, loss is 4.623779430389404 and perplexity is 101.87834754813888
At time: 316.6803414821625 and batch: 800, loss is 4.543675508499145 and perplexity is 94.03579507916967
At time: 317.05611181259155 and batch: 850, loss is 4.503501543998718 and perplexity is 90.33288273256098
At time: 317.4323778152466 and batch: 900, loss is 4.440330605506897 and perplexity is 84.80297336985349
At time: 317.8088459968567 and batch: 950, loss is 4.536837730407715 and perplexity is 93.39499250938961
At time: 318.1840319633484 and batch: 1000, loss is 4.580173540115356 and perplexity is 97.53131833473866
At time: 318.5807011127472 and batch: 1050, loss is 4.513234577178955 and perplexity is 91.21638829727999
At time: 318.968239068985 and batch: 1100, loss is 4.6377193641662595 and perplexity is 103.30846971180365
At time: 319.3614318370819 and batch: 1150, loss is 4.58127947807312 and perplexity is 97.63924158896741
At time: 319.7456603050232 and batch: 1200, loss is 4.517137279510498 and perplexity is 91.57307427543591
At time: 320.1219871044159 and batch: 1250, loss is 4.470964593887329 and perplexity is 87.44102742770151
At time: 320.4973771572113 and batch: 1300, loss is 4.602676448822021 and perplexity is 99.75093696134228
At time: 320.8740451335907 and batch: 1350, loss is 4.565167169570923 and perplexity is 96.0786541014935
At time: 321.26856994628906 and batch: 1400, loss is 4.387260150909424 and perplexity is 80.41977880029282
At time: 321.65971302986145 and batch: 1450, loss is 4.510227241516113 and perplexity is 90.94248207013605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.741183810763889 and perplexity of 114.56975033601373
Finished 27 epochs...
Completing Train Step...
At time: 322.9047255516052 and batch: 50, loss is 4.588681783676147 and perplexity is 98.36467873531163
At time: 323.2815246582031 and batch: 100, loss is 4.603928451538086 and perplexity is 99.87590361832096
At time: 323.68291306495667 and batch: 150, loss is 4.488618650436401 and perplexity is 88.99842299665102
At time: 324.0599477291107 and batch: 200, loss is 4.5812952423095705 and perplexity is 97.64078080919094
At time: 324.43754959106445 and batch: 250, loss is 4.601034450531006 and perplexity is 99.58728049191643
At time: 324.8153131008148 and batch: 300, loss is 4.629269304275513 and perplexity is 102.43918488244564
At time: 325.193359375 and batch: 350, loss is 4.6637391757965085 and perplexity is 106.03181343162613
At time: 325.5714068412781 and batch: 400, loss is 4.494622716903686 and perplexity is 89.53438280289804
At time: 325.9489965438843 and batch: 450, loss is 4.584080400466919 and perplexity is 97.91310488312234
At time: 326.35063219070435 and batch: 500, loss is 4.54750542640686 and perplexity is 94.39663500728612
At time: 326.7440662384033 and batch: 550, loss is 4.622821731567383 and perplexity is 101.78082548054103
At time: 327.1243534088135 and batch: 600, loss is 4.508714466094971 and perplexity is 90.80501052652566
At time: 327.50185441970825 and batch: 650, loss is 4.629637632369995 and perplexity is 102.4769230618029
At time: 327.87927198410034 and batch: 700, loss is 4.669616985321045 and perplexity is 106.65688345618115
At time: 328.28903365135193 and batch: 750, loss is 4.61076265335083 and perplexity is 100.5608134400523
At time: 328.67995595932007 and batch: 800, loss is 4.5309249305725094 and perplexity is 92.84439600066946
At time: 329.0569198131561 and batch: 850, loss is 4.491080031394959 and perplexity is 89.21775183553872
At time: 329.4339096546173 and batch: 900, loss is 4.426636738777161 and perplexity is 83.64960779487247
At time: 329.80926609039307 and batch: 950, loss is 4.525119924545288 and perplexity is 92.3069950393166
At time: 330.18690490722656 and batch: 1000, loss is 4.567795524597168 and perplexity is 96.3315150735505
At time: 330.5856294631958 and batch: 1050, loss is 4.500889854431152 and perplexity is 90.09726909388644
At time: 330.97011256217957 and batch: 1100, loss is 4.626037616729736 and perplexity is 102.10866779609191
At time: 331.3462977409363 and batch: 1150, loss is 4.569432363510132 and perplexity is 96.48932336410923
At time: 331.72237277030945 and batch: 1200, loss is 4.504760284423828 and perplexity is 90.44665997675885
At time: 332.0982675552368 and batch: 1250, loss is 4.457018194198608 and perplexity is 86.23000424548026
At time: 332.4736907482147 and batch: 1300, loss is 4.589189996719361 and perplexity is 98.41468165302764
At time: 332.84906029701233 and batch: 1350, loss is 4.5531659507751465 and perplexity is 94.9324846241498
At time: 333.22439098358154 and batch: 1400, loss is 4.374150705337525 and perplexity is 79.37240036246733
At time: 333.6002779006958 and batch: 1450, loss is 4.498014106750488 and perplexity is 89.83854427320986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.733486599392361 and perplexity of 113.69126802021673
Finished 28 epochs...
Completing Train Step...
At time: 334.8510637283325 and batch: 50, loss is 4.575265121459961 and perplexity is 97.05376676264864
At time: 335.2267396450043 and batch: 100, loss is 4.591662044525147 and perplexity is 98.65826840586713
At time: 335.601767539978 and batch: 150, loss is 4.475221853256226 and perplexity is 87.81408008846995
At time: 335.99423456192017 and batch: 200, loss is 4.569512062072754 and perplexity is 96.49701373094118
At time: 336.3861463069916 and batch: 250, loss is 4.589383687973022 and perplexity is 98.43374556229239
At time: 336.7628309726715 and batch: 300, loss is 4.6174954986572265 and perplexity is 101.24015823624956
At time: 337.1386880874634 and batch: 350, loss is 4.651449432373047 and perplexity is 104.73668435294456
At time: 337.5131576061249 and batch: 400, loss is 4.481020441055298 and perplexity is 88.32475691316064
At time: 337.9077365398407 and batch: 450, loss is 4.571430168151855 and perplexity is 96.68228286571807
At time: 338.31326174736023 and batch: 500, loss is 4.534079484939575 and perplexity is 93.13774113886268
At time: 338.6890528202057 and batch: 550, loss is 4.6097682857513425 and perplexity is 100.46086872451804
At time: 339.06498193740845 and batch: 600, loss is 4.49685489654541 and perplexity is 89.734462853656
At time: 339.4409890174866 and batch: 650, loss is 4.616746397018432 and perplexity is 101.16434746633412
At time: 339.8163595199585 and batch: 700, loss is 4.656784839630127 and perplexity is 105.29699062062129
At time: 340.1919198036194 and batch: 750, loss is 4.5981717205047605 and perplexity is 99.30259667469649
At time: 340.5676290988922 and batch: 800, loss is 4.518568978309632 and perplexity is 91.70427323219289
At time: 340.942822933197 and batch: 850, loss is 4.479011974334717 and perplexity is 88.14753760741036
At time: 341.3184118270874 and batch: 900, loss is 4.413385992050171 and perplexity is 82.54849939365627
At time: 341.6940803527832 and batch: 950, loss is 4.513795223236084 and perplexity is 91.26754274415394
At time: 342.0703535079956 and batch: 1000, loss is 4.555820302963257 and perplexity is 95.18480359599761
At time: 342.4459991455078 and batch: 1050, loss is 4.488930892944336 and perplexity is 89.02621642636902
At time: 342.82258129119873 and batch: 1100, loss is 4.614698467254638 and perplexity is 100.95738198584151
At time: 343.1990735530853 and batch: 1150, loss is 4.5579441547393795 and perplexity is 95.38717683948998
At time: 343.57473731040955 and batch: 1200, loss is 4.492769622802735 and perplexity is 89.36862080002346
At time: 343.95081090927124 and batch: 1250, loss is 4.443524575233459 and perplexity is 85.0742645167443
At time: 344.34214448928833 and batch: 1300, loss is 4.576148738861084 and perplexity is 97.13956305977287
At time: 344.7361550331116 and batch: 1350, loss is 4.541526184082032 and perplexity is 93.83389869685871
At time: 345.1288814544678 and batch: 1400, loss is 4.3614916467666625 and perplexity is 78.3739535293755
At time: 345.5098252296448 and batch: 1450, loss is 4.486180601119995 and perplexity is 88.78170474454525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.726144122262286 and perplexity of 112.85954965804353
Finished 29 epochs...
Completing Train Step...
At time: 346.736615896225 and batch: 50, loss is 4.562266912460327 and perplexity is 95.80040499377651
At time: 347.1250627040863 and batch: 100, loss is 4.579792518615722 and perplexity is 97.49416388433717
At time: 347.5012221336365 and batch: 150, loss is 4.462246532440186 and perplexity is 86.68202450196114
At time: 347.8922996520996 and batch: 200, loss is 4.558068265914917 and perplexity is 95.39901618882134
At time: 348.26786828041077 and batch: 250, loss is 4.578086891174316 and perplexity is 97.32801689574974
At time: 348.6433856487274 and batch: 300, loss is 4.6061074161529545 and perplexity is 100.09376695022968
At time: 349.01927876472473 and batch: 350, loss is 4.639538497924804 and perplexity is 103.49657267695373
At time: 349.39450430870056 and batch: 400, loss is 4.4678340339660645 and perplexity is 87.16771608374532
At time: 349.7697148323059 and batch: 450, loss is 4.559159936904908 and perplexity is 95.50321739363606
At time: 350.1453046798706 and batch: 500, loss is 4.521071834564209 and perplexity is 91.93408331686103
At time: 350.5345606803894 and batch: 550, loss is 4.597091302871704 and perplexity is 99.1953663354464
At time: 350.9263377189636 and batch: 600, loss is 4.485355587005615 and perplexity is 88.70848879128258
At time: 351.30414724349976 and batch: 650, loss is 4.604228858947754 and perplexity is 99.90591158689757
At time: 351.6798243522644 and batch: 700, loss is 4.644334878921509 and perplexity is 103.99417406032087
At time: 352.0533275604248 and batch: 750, loss is 4.585986185073852 and perplexity is 98.09988409516716
At time: 352.42771792411804 and batch: 800, loss is 4.506597228050232 and perplexity is 90.61295808569588
At time: 352.803258895874 and batch: 850, loss is 4.467290477752686 and perplexity is 87.12034840472633
At time: 353.1782796382904 and batch: 900, loss is 4.400544481277466 and perplexity is 81.4952292136377
At time: 353.55326223373413 and batch: 950, loss is 4.5028379440307615 and perplexity is 90.27295771979158
At time: 353.9283106327057 and batch: 1000, loss is 4.544220771789551 and perplexity is 94.0870833277393
At time: 354.30351305007935 and batch: 1050, loss is 4.477331056594848 and perplexity is 87.99949330772323
At time: 354.6792778968811 and batch: 1100, loss is 4.603684024810791 and perplexity is 99.85149426133509
At time: 355.05451560020447 and batch: 1150, loss is 4.5467871475219725 and perplexity is 94.3288562424978
At time: 355.43005657196045 and batch: 1200, loss is 4.481149196624756 and perplexity is 88.3361299496894
At time: 355.805540561676 and batch: 1250, loss is 4.430449872016907 and perplexity is 83.96918380057272
At time: 356.1811091899872 and batch: 1300, loss is 4.563506784439087 and perplexity is 95.91925889806893
At time: 356.5566301345825 and batch: 1350, loss is 4.530225553512573 and perplexity is 92.77948546107993
At time: 356.9318492412567 and batch: 1400, loss is 4.349254989624024 and perplexity is 77.42076216296901
At time: 357.3233768939972 and batch: 1450, loss is 4.474703578948975 and perplexity is 87.7685800987015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.719120384281517 and perplexity of 112.06963109055143
Finished 30 epochs...
Completing Train Step...
At time: 358.5560345649719 and batch: 50, loss is 4.549657578468323 and perplexity is 94.60000968803287
At time: 358.94594979286194 and batch: 100, loss is 4.568292064666748 and perplexity is 96.37935940807948
At time: 359.3231055736542 and batch: 150, loss is 4.44966197013855 and perplexity is 85.59800442967851
At time: 359.7145736217499 and batch: 200, loss is 4.546941528320312 and perplexity is 94.34341993077898
At time: 360.11629128456116 and batch: 250, loss is 4.567124691009521 and perplexity is 96.26691432828778
At time: 360.510422706604 and batch: 300, loss is 4.595081176757812 and perplexity is 98.99617140973176
At time: 360.89431262016296 and batch: 350, loss is 4.627981557846069 and perplexity is 102.30735408841309
At time: 361.2719280719757 and batch: 400, loss is 4.45504677772522 and perplexity is 86.06017645026965
At time: 361.6641492843628 and batch: 450, loss is 4.547247562408447 and perplexity is 94.37229665167415
At time: 362.0575621128082 and batch: 500, loss is 4.508459177017212 and perplexity is 90.78183195787602
At time: 362.438259601593 and batch: 550, loss is 4.584763689041138 and perplexity is 97.98003065115765
At time: 362.81509828567505 and batch: 600, loss is 4.4741919898986815 and perplexity is 87.72369013774852
At time: 363.196320772171 and batch: 650, loss is 4.592065629959106 and perplexity is 98.69809348180512
At time: 363.57633900642395 and batch: 700, loss is 4.632246570587158 and perplexity is 102.74462808384177
At time: 363.97242856025696 and batch: 750, loss is 4.574177837371826 and perplexity is 96.94829909340352
At time: 364.3552625179291 and batch: 800, loss is 4.4949795484542845 and perplexity is 89.56633719637428
At time: 364.732284784317 and batch: 850, loss is 4.4558983278274535 and perplexity is 86.13349221391684
At time: 365.1098721027374 and batch: 900, loss is 4.38808464050293 and perplexity is 80.48611141254231
At time: 365.48752617836 and batch: 950, loss is 4.492214756011963 and perplexity is 89.3190468749387
At time: 365.8692457675934 and batch: 1000, loss is 4.532970771789551 and perplexity is 93.03453532389271
At time: 366.2578902244568 and batch: 1050, loss is 4.4660618019104 and perplexity is 87.01337147071528
At time: 366.6330428123474 and batch: 1100, loss is 4.592975349426269 and perplexity is 98.78792191195812
At time: 367.02937865257263 and batch: 1150, loss is 4.535941457748413 and perplexity is 93.31132263220042
At time: 367.4066376686096 and batch: 1200, loss is 4.4698839855194095 and perplexity is 87.34658895645455
At time: 367.7838168144226 and batch: 1250, loss is 4.417759995460511 and perplexity is 82.91035761915917
At time: 368.1611285209656 and batch: 1300, loss is 4.551217565536499 and perplexity is 94.74769964705759
At time: 368.53804659843445 and batch: 1350, loss is 4.519244384765625 and perplexity is 91.76623181163306
At time: 368.91466522216797 and batch: 1400, loss is 4.3374186038970945 and perplexity is 76.50978214981673
At time: 369.2909758090973 and batch: 1450, loss is 4.463562068939209 and perplexity is 86.79613290943342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.712387215377938 and perplexity of 111.317582013399
Finished 31 epochs...
Completing Train Step...
At time: 370.5609269142151 and batch: 50, loss is 4.537416877746582 and perplexity is 93.44909763667293
At time: 370.9443175792694 and batch: 100, loss is 4.557134046554565 and perplexity is 95.30993419847819
At time: 371.32073736190796 and batch: 150, loss is 4.437448720932007 and perplexity is 84.55893280626367
At time: 371.7042279243469 and batch: 200, loss is 4.536115274429322 and perplexity is 93.3275431062452
At time: 372.0997498035431 and batch: 250, loss is 4.5564843273162845 and perplexity is 95.24802961310787
At time: 372.48636960983276 and batch: 300, loss is 4.58439299583435 and perplexity is 97.9437168504499
At time: 372.8631446361542 and batch: 350, loss is 4.616753091812134 and perplexity is 101.16502474303748
At time: 373.25112080574036 and batch: 400, loss is 4.442647962570191 and perplexity is 84.99972001725043
At time: 373.64006543159485 and batch: 450, loss is 4.535671072006226 and perplexity is 93.28609599159171
At time: 374.01642179489136 and batch: 500, loss is 4.4962125015258785 and perplexity is 89.67683639309581
At time: 374.40987730026245 and batch: 550, loss is 4.572762670516968 and perplexity is 96.81119810715843
At time: 374.8014805316925 and batch: 600, loss is 4.4633377838134765 and perplexity is 86.77666801077599
At time: 375.1789150238037 and batch: 650, loss is 4.580242805480957 and perplexity is 97.53807411112857
At time: 375.55460596084595 and batch: 700, loss is 4.620495491027832 and perplexity is 101.54433397287116
At time: 375.9305410385132 and batch: 750, loss is 4.562714796066285 and perplexity is 95.84332203481945
At time: 376.30686831474304 and batch: 800, loss is 4.483657956123352 and perplexity is 88.55802227562991
At time: 376.6963119506836 and batch: 850, loss is 4.444823899269104 and perplexity is 85.18487539757224
At time: 377.0871548652649 and batch: 900, loss is 4.375980525016785 and perplexity is 79.51777050265116
At time: 377.47405219078064 and batch: 950, loss is 4.481894192695617 and perplexity is 88.40196453962749
At time: 377.8506305217743 and batch: 1000, loss is 4.52204273223877 and perplexity is 92.02338524907046
At time: 378.22648096084595 and batch: 1050, loss is 4.455098371505738 and perplexity is 86.06461673466933
At time: 378.6030375957489 and batch: 1100, loss is 4.582557077407837 and perplexity is 97.76406513932749
At time: 378.9789938926697 and batch: 1150, loss is 4.525391092300415 and perplexity is 92.33202911400743
At time: 379.35515451431274 and batch: 1200, loss is 4.458959760665894 and perplexity is 86.39758816521189
At time: 379.73172664642334 and batch: 1250, loss is 4.405422277450562 and perplexity is 81.89371741282939
At time: 380.1074845790863 and batch: 1300, loss is 4.539238290786743 and perplexity is 93.61946214667033
At time: 380.48201847076416 and batch: 1350, loss is 4.508563814163208 and perplexity is 90.79133160667976
At time: 380.85808515548706 and batch: 1400, loss is 4.325965399742127 and perplexity is 75.63849901109234
At time: 381.2470932006836 and batch: 1450, loss is 4.452738733291626 and perplexity is 85.86177478706163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.705911228799413 and perplexity of 110.59902005639762
Finished 32 epochs...
Completing Train Step...
At time: 382.528361082077 and batch: 50, loss is 4.525533771514892 and perplexity is 92.34520391525528
At time: 382.92635846138 and batch: 100, loss is 4.546295042037964 and perplexity is 94.28244791487343
At time: 383.31680631637573 and batch: 150, loss is 4.425589399337769 and perplexity is 83.56204412398641
At time: 383.6972417831421 and batch: 200, loss is 4.525581035614014 and perplexity is 92.3495686312729
At time: 384.0918765068054 and batch: 250, loss is 4.546153388023376 and perplexity is 94.26909337350567
At time: 384.48152136802673 and batch: 300, loss is 4.574018592834473 and perplexity is 96.93286183554933
At time: 384.85530185699463 and batch: 350, loss is 4.60583158493042 and perplexity is 100.06616177148383
At time: 385.23135590553284 and batch: 400, loss is 4.430615243911743 and perplexity is 83.98307109185782
At time: 385.6077823638916 and batch: 450, loss is 4.524404935836792 and perplexity is 92.2410201686026
At time: 385.9817042350769 and batch: 500, loss is 4.484308319091797 and perplexity is 88.615635866719
At time: 386.355676651001 and batch: 550, loss is 4.561071557998657 and perplexity is 95.68595796824624
At time: 386.74187111854553 and batch: 600, loss is 4.452774658203125 and perplexity is 85.86485941912923
At time: 387.1154844760895 and batch: 650, loss is 4.568760900497437 and perplexity is 96.42455609919506
At time: 387.4898011684418 and batch: 700, loss is 4.609055261611939 and perplexity is 100.38926323130829
At time: 387.8805990219116 and batch: 750, loss is 4.551566686630249 and perplexity is 94.78078384244787
At time: 388.2716290950775 and batch: 800, loss is 4.4726232814788816 and perplexity is 87.58618512724561
At time: 388.6458079814911 and batch: 850, loss is 4.4340462970733645 and perplexity is 84.27171636893151
At time: 389.0204288959503 and batch: 900, loss is 4.36421434879303 and perplexity is 78.58763321251497
At time: 389.39372539520264 and batch: 950, loss is 4.471852650642395 and perplexity is 87.5187145129434
At time: 389.7680847644806 and batch: 1000, loss is 4.511409425735474 and perplexity is 91.05005641112456
At time: 390.14207887649536 and batch: 1050, loss is 4.444422693252563 and perplexity is 85.1507055680734
At time: 390.5293378829956 and batch: 1100, loss is 4.5724215316772465 and perplexity is 96.77817767995944
At time: 390.9173104763031 and batch: 1150, loss is 4.515116548538208 and perplexity is 91.38821656477366
At time: 391.290988445282 and batch: 1200, loss is 4.4483580493927 and perplexity is 85.48646415154415
At time: 391.6635060310364 and batch: 1250, loss is 4.393417339324952 and perplexity is 80.91646606006532
At time: 392.03698658943176 and batch: 1300, loss is 4.527552757263184 and perplexity is 92.53183590615076
At time: 392.4491696357727 and batch: 1350, loss is 4.498169078826904 and perplexity is 89.85246781781052
At time: 392.8257200717926 and batch: 1400, loss is 4.314876074790955 and perplexity is 74.804352724468
At time: 393.2002649307251 and batch: 1450, loss is 4.442218923568726 and perplexity is 84.96325964426974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.699673644497863 and perplexity of 109.91129644193441
Finished 33 epochs...
Completing Train Step...
At time: 394.4130895137787 and batch: 50, loss is 4.513996543884278 and perplexity is 91.28591863467929
At time: 394.8086426258087 and batch: 100, loss is 4.535752067565918 and perplexity is 93.29365205714778
At time: 395.1901104450226 and batch: 150, loss is 4.414061908721924 and perplexity is 82.60431416156574
At time: 395.5642330646515 and batch: 200, loss is 4.51532621383667 and perplexity is 91.40737951130791
At time: 395.9386074542999 and batch: 250, loss is 4.536110849380493 and perplexity is 93.32713012822362
At time: 396.3268823623657 and batch: 300, loss is 4.56393144607544 and perplexity is 95.96000077765467
At time: 396.7069149017334 and batch: 350, loss is 4.595198774337769 and perplexity is 99.00781380445981
At time: 397.0880353450775 and batch: 400, loss is 4.4189129734039305 and perplexity is 83.00600656274027
At time: 397.46306467056274 and batch: 450, loss is 4.513424453735351 and perplexity is 91.23370979539793
At time: 397.839599609375 and batch: 500, loss is 4.472735261917114 and perplexity is 87.59599361580844
At time: 398.2162821292877 and batch: 550, loss is 4.5496870708465575 and perplexity is 94.60279970844157
At time: 398.6137878894806 and batch: 600, loss is 4.442488527297973 and perplexity is 84.98616914402336
At time: 399.0074317455292 and batch: 650, loss is 4.557604236602783 and perplexity is 95.35475851818333
At time: 399.38753867149353 and batch: 700, loss is 4.597906084060669 and perplexity is 99.27622178924722
At time: 399.763845205307 and batch: 750, loss is 4.540714540481567 and perplexity is 93.75776991237443
At time: 400.1403965950012 and batch: 800, loss is 4.46187792301178 and perplexity is 86.65007857860243
At time: 400.517529964447 and batch: 850, loss is 4.423547530174256 and perplexity is 83.3915954390264
At time: 400.8947563171387 and batch: 900, loss is 4.3527733516693115 and perplexity is 77.69363618739648
At time: 401.27170038223267 and batch: 950, loss is 4.462067685127258 and perplexity is 86.6665230410385
At time: 401.6480770111084 and batch: 1000, loss is 4.501052904129028 and perplexity is 90.11196062408386
At time: 402.0245804786682 and batch: 1050, loss is 4.434023780822754 and perplexity is 84.26981890720829
At time: 402.4012920856476 and batch: 1100, loss is 4.56255955696106 and perplexity is 95.82844455807795
At time: 402.77722454071045 and batch: 1150, loss is 4.505104846954346 and perplexity is 90.47782987647875
At time: 403.15208673477173 and batch: 1200, loss is 4.438058996200562 and perplexity is 84.61055278128566
At time: 403.52851700782776 and batch: 1250, loss is 4.381738619804382 and perplexity is 79.97696212822413
At time: 403.90409564971924 and batch: 1300, loss is 4.516156530380249 and perplexity is 91.48330808873604
At time: 404.2795023918152 and batch: 1350, loss is 4.488054323196411 and perplexity is 88.9482129310242
At time: 404.6541209220886 and batch: 1400, loss is 4.304119186401367 and perplexity is 74.0040030048593
At time: 405.0302245616913 and batch: 1450, loss is 4.431986255645752 and perplexity is 84.09829183422967
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.693666115785256 and perplexity of 109.25298057835168
Finished 34 epochs...
Completing Train Step...
At time: 406.2472679615021 and batch: 50, loss is 4.502787437438965 and perplexity is 90.26839845550315
At time: 406.6373188495636 and batch: 100, loss is 4.525484838485718 and perplexity is 92.34068529525376
At time: 407.01326990127563 and batch: 150, loss is 4.402850456237793 and perplexity is 81.6833720145133
At time: 407.3899972438812 and batch: 200, loss is 4.505332679748535 and perplexity is 90.49844604170174
At time: 407.76641178131104 and batch: 250, loss is 4.526337895393372 and perplexity is 92.41949076269762
At time: 408.1431496143341 and batch: 300, loss is 4.554112796783447 and perplexity is 95.02241363601861
At time: 408.5202827453613 and batch: 350, loss is 4.584836101531982 and perplexity is 97.98712588611883
At time: 408.8970584869385 and batch: 400, loss is 4.407521028518676 and perplexity is 82.06577242688867
At time: 409.27402234077454 and batch: 450, loss is 4.502714538574219 and perplexity is 90.26181823158169
At time: 409.6504328250885 and batch: 500, loss is 4.461471138000488 and perplexity is 86.61483779360688
At time: 410.03114008903503 and batch: 550, loss is 4.53860918045044 and perplexity is 93.56058369781697
At time: 410.4302761554718 and batch: 600, loss is 4.432468032836914 and perplexity is 84.13881823461486
At time: 410.83020639419556 and batch: 650, loss is 4.546738615036011 and perplexity is 94.32427833969584
At time: 411.21976017951965 and batch: 700, loss is 4.5870490074157715 and perplexity is 98.20420226974673
At time: 411.59720754623413 and batch: 750, loss is 4.530150470733642 and perplexity is 92.7725195809958
At time: 411.97379422187805 and batch: 800, loss is 4.45140202999115 and perplexity is 85.74707974301887
At time: 412.3520381450653 and batch: 850, loss is 4.413313679695129 and perplexity is 82.54253033308098
At time: 412.7322175502777 and batch: 900, loss is 4.341642179489136 and perplexity is 76.83361037336113
At time: 413.1155164241791 and batch: 950, loss is 4.452520890235901 and perplexity is 85.84307243283502
At time: 413.50379967689514 and batch: 1000, loss is 4.4909576797485355 and perplexity is 89.20683656447576
At time: 413.93964433670044 and batch: 1050, loss is 4.423892135620117 and perplexity is 83.42033758902004
At time: 414.3466331958771 and batch: 1100, loss is 4.552958574295044 and perplexity is 94.9127999007859
At time: 414.74249482154846 and batch: 1150, loss is 4.495345458984375 and perplexity is 89.59911645906905
At time: 415.1520125865936 and batch: 1200, loss is 4.428041305541992 and perplexity is 83.76718180481647
At time: 415.5460660457611 and batch: 1250, loss is 4.370374927520752 and perplexity is 79.07327288873034
At time: 415.94014859199524 and batch: 1300, loss is 4.5050490188598635 and perplexity is 90.47277881264078
At time: 416.3581426143646 and batch: 1350, loss is 4.4782074928283695 and perplexity is 88.07665306005184
At time: 416.76379585266113 and batch: 1400, loss is 4.29367338180542 and perplexity is 73.23499509582936
At time: 417.1718645095825 and batch: 1450, loss is 4.422023859024048 and perplexity is 83.2646308216116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.687882904313568 and perplexity of 108.62297098303064
Finished 35 epochs...
Completing Train Step...
At time: 418.4733872413635 and batch: 50, loss is 4.491880159378052 and perplexity is 89.28916602180546
At time: 418.86672353744507 and batch: 100, loss is 4.51547529220581 and perplexity is 91.42100739015856
At time: 419.24644780158997 and batch: 150, loss is 4.391944503784179 and perplexity is 80.79737713374772
At time: 419.6399829387665 and batch: 200, loss is 4.495585536956787 and perplexity is 89.62062981561658
At time: 420.0393681526184 and batch: 250, loss is 4.516822676658631 and perplexity is 91.54426965635983
At time: 420.4341368675232 and batch: 300, loss is 4.544550495147705 and perplexity is 94.11811115183114
At time: 420.8258264064789 and batch: 350, loss is 4.574721651077271 and perplexity is 97.00103524519147
At time: 421.2244975566864 and batch: 400, loss is 4.39642894744873 and perplexity is 81.16052206265809
At time: 421.6114161014557 and batch: 450, loss is 4.492265310287475 and perplexity is 89.32356244878275
At time: 422.00594425201416 and batch: 500, loss is 4.450493297576904 and perplexity is 85.66919398624519
At time: 422.3916347026825 and batch: 550, loss is 4.527829179763794 and perplexity is 92.55741732309471
At time: 422.7722382545471 and batch: 600, loss is 4.4227054405212405 and perplexity is 83.32140179817604
At time: 423.14844512939453 and batch: 650, loss is 4.536152067184449 and perplexity is 93.33097694685516
At time: 423.5238127708435 and batch: 700, loss is 4.576471929550171 and perplexity is 97.17096273586388
At time: 423.91206073760986 and batch: 750, loss is 4.519868497848511 and perplexity is 91.82352219345258
At time: 424.3014497756958 and batch: 800, loss is 4.44117163181305 and perplexity is 84.87432490134923
At time: 424.6832785606384 and batch: 850, loss is 4.403331475257874 and perplexity is 81.72267272151258
At time: 425.0600690841675 and batch: 900, loss is 4.330801901817321 and perplexity is 76.00521085498532
At time: 425.4862916469574 and batch: 950, loss is 4.443196568489075 and perplexity is 85.04636416021198
At time: 425.8825511932373 and batch: 1000, loss is 4.481112608909607 and perplexity is 88.33289799165476
At time: 426.27604150772095 and batch: 1050, loss is 4.414014854431152 and perplexity is 82.60042736559414
At time: 426.6821184158325 and batch: 1100, loss is 4.54360411643982 and perplexity is 94.029081909745
At time: 427.0865445137024 and batch: 1150, loss is 4.4858292388916015 and perplexity is 88.75051568657497
At time: 427.47987818717957 and batch: 1200, loss is 4.418284997940064 and perplexity is 82.9538971906813
At time: 427.87255334854126 and batch: 1250, loss is 4.359313950538636 and perplexity is 78.20346457035718
At time: 428.2612328529358 and batch: 1300, loss is 4.494222526550293 and perplexity is 89.4985591752165
At time: 428.6452603340149 and batch: 1350, loss is 4.468613910675049 and perplexity is 87.23572267022396
At time: 429.0360674858093 and batch: 1400, loss is 4.283517327308655 and perplexity is 72.49498066873943
At time: 429.4324655532837 and batch: 1450, loss is 4.412314624786377 and perplexity is 82.46010699254798
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682308360042735 and perplexity of 108.01913204960753
Finished 36 epochs...
Completing Train Step...
At time: 430.7647445201874 and batch: 50, loss is 4.481246790885925 and perplexity is 88.344751469725
At time: 431.13782262802124 and batch: 100, loss is 4.505711030960083 and perplexity is 90.5326927166318
At time: 431.5350344181061 and batch: 150, loss is 4.381328811645508 and perplexity is 79.94419363147927
At time: 431.9293055534363 and batch: 200, loss is 4.486071701049805 and perplexity is 88.772036937089
At time: 432.31301856040955 and batch: 250, loss is 4.507554750442505 and perplexity is 90.69976357456042
At time: 432.7054877281189 and batch: 300, loss is 4.535231971740723 and perplexity is 93.2451430339594
At time: 433.1029555797577 and batch: 350, loss is 4.564835939407349 and perplexity is 96.04683522315649
At time: 433.5051896572113 and batch: 400, loss is 4.385628690719605 and perplexity is 80.28868409967613
At time: 433.9065294265747 and batch: 450, loss is 4.482065048217773 and perplexity is 88.41706979380982
At time: 434.2873215675354 and batch: 500, loss is 4.4398034477233885 and perplexity is 84.7582806034817
At time: 434.66287660598755 and batch: 550, loss is 4.517329607009888 and perplexity is 91.59068798956923
At time: 435.03735542297363 and batch: 600, loss is 4.413188762664795 and perplexity is 82.53222000929645
At time: 435.41298389434814 and batch: 650, loss is 4.525836009979248 and perplexity is 92.37311840608113
At time: 435.82713413238525 and batch: 700, loss is 4.566157169342041 and perplexity is 96.17381904592732
At time: 436.21008253097534 and batch: 750, loss is 4.509856071472168 and perplexity is 90.9087332087402
At time: 436.60845375061035 and batch: 800, loss is 4.431173162460327 and perplexity is 84.02993987825394
At time: 436.9946331977844 and batch: 850, loss is 4.3935881614685055 and perplexity is 80.93028956489326
At time: 437.4038851261139 and batch: 900, loss is 4.320236644744873 and perplexity is 75.20642339125791
At time: 437.8010959625244 and batch: 950, loss is 4.434083061218262 and perplexity is 84.27481460347445
At time: 438.19441199302673 and batch: 1000, loss is 4.471507544517517 and perplexity is 87.48851647958638
At time: 438.5851366519928 and batch: 1050, loss is 4.404377841949463 and perplexity is 81.80822935819727
At time: 438.98239850997925 and batch: 1100, loss is 4.534484758377075 and perplexity is 93.17549504118514
At time: 439.3776021003723 and batch: 1150, loss is 4.476545619964599 and perplexity is 87.9304024190453
At time: 439.76932311058044 and batch: 1200, loss is 4.408771619796753 and perplexity is 82.16846736742846
At time: 440.1522693634033 and batch: 1250, loss is 4.34853964805603 and perplexity is 77.36539967747248
At time: 440.5459907054901 and batch: 1300, loss is 4.4836638641357425 and perplexity is 88.55854547906833
At time: 440.93980288505554 and batch: 1350, loss is 4.459260473251343 and perplexity is 86.42357291410028
At time: 441.32794308662415 and batch: 1400, loss is 4.2736266279220585 and perplexity is 71.78148889074382
At time: 441.72298765182495 and batch: 1450, loss is 4.402843732833862 and perplexity is 81.68282282605497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.67693361461672 and perplexity of 107.44011414450337
Finished 37 epochs...
Completing Train Step...
At time: 443.04179763793945 and batch: 50, loss is 4.470865879058838 and perplexity is 87.43239612770157
At time: 443.4482686519623 and batch: 100, loss is 4.496181402206421 and perplexity is 89.67404754787871
At time: 443.8610351085663 and batch: 150, loss is 4.3709854412078855 and perplexity is 79.12156294348515
At time: 444.2708029747009 and batch: 200, loss is 4.476778917312622 and perplexity is 87.950918741849
At time: 444.6630253791809 and batch: 250, loss is 4.498521614074707 and perplexity is 89.88414956395637
At time: 445.0745015144348 and batch: 300, loss is 4.526141729354858 and perplexity is 92.40136297539951
At time: 445.45564341545105 and batch: 350, loss is 4.555164222717285 and perplexity is 95.122375207897
At time: 445.8660800457001 and batch: 400, loss is 4.375104851722718 and perplexity is 79.44816939298224
At time: 446.2736282348633 and batch: 450, loss is 4.47210186958313 and perplexity is 87.5405285523918
At time: 446.67415618896484 and batch: 500, loss is 4.429390001296997 and perplexity is 83.88023446701143
At time: 447.07103514671326 and batch: 550, loss is 4.507101316452026 and perplexity is 90.65864654146196
At time: 447.46028780937195 and batch: 600, loss is 4.403906917572021 and perplexity is 81.7697129385894
At time: 447.8594069480896 and batch: 650, loss is 4.515775671005249 and perplexity is 91.44847244735588
At time: 448.2689309120178 and batch: 700, loss is 4.556090316772461 and perplexity is 95.21050827754821
At time: 448.650386095047 and batch: 750, loss is 4.500097780227661 and perplexity is 90.02593362645351
At time: 449.06561160087585 and batch: 800, loss is 4.421397824287414 and perplexity is 83.21252058349582
At time: 449.4875886440277 and batch: 850, loss is 4.384072623252869 and perplexity is 80.16384664334335
At time: 449.88581824302673 and batch: 900, loss is 4.309933271408081 and perplexity is 74.43552179706377
At time: 450.2855315208435 and batch: 950, loss is 4.425171451568604 and perplexity is 83.5271268513643
At time: 450.68650460243225 and batch: 1000, loss is 4.462133731842041 and perplexity is 86.67224726919814
At time: 451.0770492553711 and batch: 1050, loss is 4.394966049194336 and perplexity is 81.04187927892615
At time: 451.45692801475525 and batch: 1100, loss is 4.525590353012085 and perplexity is 92.35042909297414
At time: 451.85279154777527 and batch: 1150, loss is 4.4674818897247315 and perplexity is 87.13702587850295
At time: 452.2519884109497 and batch: 1200, loss is 4.399486627578735 and perplexity is 81.40906476670982
At time: 452.6481702327728 and batch: 1250, loss is 4.338035111427307 and perplexity is 76.5569655496132
At time: 453.0281524658203 and batch: 1300, loss is 4.47336256980896 and perplexity is 87.65096051267929
At time: 453.42160749435425 and batch: 1350, loss is 4.450134763717651 and perplexity is 85.63848418508692
At time: 453.8224940299988 and batch: 1400, loss is 4.263977541923523 and perplexity is 71.0921940121653
At time: 454.22683691978455 and batch: 1450, loss is 4.393595552444458 and perplexity is 80.93088772092771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.671748756343483 and perplexity of 106.88449403029273
Finished 38 epochs...
Completing Train Step...
At time: 455.50083780288696 and batch: 50, loss is 4.460724148750305 and perplexity is 86.5501616000868
At time: 455.91219115257263 and batch: 100, loss is 4.486875128746033 and perplexity is 88.84338750888955
At time: 456.3130099773407 and batch: 150, loss is 4.36089783668518 and perplexity is 78.32742810064556
At time: 456.7048463821411 and batch: 200, loss is 4.467696104049683 and perplexity is 87.15569387708474
At time: 457.1007311344147 and batch: 250, loss is 4.489709057807922 and perplexity is 89.09552046141533
At time: 457.5016944408417 and batch: 300, loss is 4.517262439727784 and perplexity is 91.58453629858941
At time: 457.9008538722992 and batch: 350, loss is 4.5456956768035885 and perplexity is 94.2259552249498
At time: 458.2968416213989 and batch: 400, loss is 4.364833159446716 and perplexity is 78.63627912694763
At time: 458.6870560646057 and batch: 450, loss is 4.462362480163574 and perplexity is 86.69207566805453
At time: 459.0784158706665 and batch: 500, loss is 4.419240474700928 and perplexity is 83.03319558952587
At time: 459.45500659942627 and batch: 550, loss is 4.497130918502807 and perplexity is 89.75923495440344
At time: 459.84257650375366 and batch: 600, loss is 4.394847478866577 and perplexity is 81.03227068639609
At time: 460.22277331352234 and batch: 650, loss is 4.505957250595093 and perplexity is 90.55498638764605
At time: 460.6149079799652 and batch: 700, loss is 4.546263122558594 and perplexity is 94.27943851625174
At time: 460.9900059700012 and batch: 750, loss is 4.490576691627503 and perplexity is 89.17285629288072
At time: 461.3785750865936 and batch: 800, loss is 4.411841640472412 and perplexity is 82.42111387770542
At time: 461.7800621986389 and batch: 850, loss is 4.374774436950684 and perplexity is 79.42192288056027
At time: 462.1764626502991 and batch: 900, loss is 4.299880790710449 and perplexity is 73.69100852319654
At time: 462.5815632343292 and batch: 950, loss is 4.416455173492432 and perplexity is 82.80224491241286
At time: 462.98490715026855 and batch: 1000, loss is 4.452979736328125 and perplexity is 85.88247022923655
At time: 463.38641452789307 and batch: 1050, loss is 4.385768194198608 and perplexity is 80.29988543172685
At time: 463.78213763237 and batch: 1100, loss is 4.516907987594604 and perplexity is 91.55207971682425
At time: 464.18472838401794 and batch: 1150, loss is 4.4586201095581055 and perplexity is 86.36824811165424
At time: 464.5783863067627 and batch: 1200, loss is 4.390419025421142 and perplexity is 80.67421644650558
At time: 464.95954513549805 and batch: 1250, loss is 4.327784624099731 and perplexity is 75.7762276525303
At time: 465.34916853904724 and batch: 1300, loss is 4.463309936523437 and perplexity is 86.77425154937937
At time: 465.736784696579 and batch: 1350, loss is 4.441221475601196 and perplexity is 84.87855546465147
At time: 466.12583351135254 and batch: 1400, loss is 4.254551033973694 and perplexity is 70.4251915711384
At time: 466.53287053108215 and batch: 1450, loss is 4.384555225372314 and perplexity is 80.20254322241082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.666742308526977 and perplexity of 106.3507196602006
Finished 39 epochs...
Completing Train Step...
At time: 467.822625875473 and batch: 50, loss is 4.450817141532898 and perplexity is 85.69694192969187
At time: 468.2088260650635 and batch: 100, loss is 4.477780923843384 and perplexity is 88.03909030367812
At time: 468.594518661499 and batch: 150, loss is 4.351050949096679 and perplexity is 77.55993164812614
At time: 468.98602414131165 and batch: 200, loss is 4.458811569213867 and perplexity is 86.38478572979925
At time: 469.3808763027191 and batch: 250, loss is 4.481102695465088 and perplexity is 88.33202231271186
At time: 469.7765426635742 and batch: 300, loss is 4.508577213287354 and perplexity is 90.79254813915358
At time: 470.1686029434204 and batch: 350, loss is 4.536423044204712 and perplexity is 93.35627092377496
At time: 470.5644278526306 and batch: 400, loss is 4.3547890090942385 and perplexity is 77.85039787790464
At time: 470.9599905014038 and batch: 450, loss is 4.452832498550415 and perplexity is 85.86982601605155
At time: 471.36086869239807 and batch: 500, loss is 4.40934796333313 and perplexity is 82.21583828213865
At time: 471.76285338401794 and batch: 550, loss is 4.487399616241455 and perplexity is 88.88999697666195
At time: 472.1738712787628 and batch: 600, loss is 4.385997447967529 and perplexity is 80.31829659343951
At time: 472.5803384780884 and batch: 650, loss is 4.4963698387146 and perplexity is 89.69094700446016
At time: 472.9745910167694 and batch: 700, loss is 4.536665630340576 and perplexity is 93.37892060793567
At time: 473.36546874046326 and batch: 750, loss is 4.4812760925292965 and perplexity is 88.34734015405245
At time: 473.7630159854889 and batch: 800, loss is 4.402499127388 and perplexity is 81.65467932995529
At time: 474.1585133075714 and batch: 850, loss is 4.365683670043945 and perplexity is 78.70318856523159
At time: 474.56453227996826 and batch: 900, loss is 4.290068302154541 and perplexity is 72.97145243684547
At time: 474.9556646347046 and batch: 950, loss is 4.407925157546997 and perplexity is 82.09894429016293
At time: 475.3541076183319 and batch: 1000, loss is 4.444030432701111 and perplexity is 85.11731085549312
At time: 475.7498686313629 and batch: 1050, loss is 4.376779222488404 and perplexity is 79.58130651454886
At time: 476.1688508987427 and batch: 1100, loss is 4.508423709869385 and perplexity is 90.7786122423194
At time: 476.55875754356384 and batch: 1150, loss is 4.449945163726807 and perplexity is 85.62224866844505
At time: 476.96293807029724 and batch: 1200, loss is 4.381559638977051 and perplexity is 79.96264906629501
At time: 477.36403226852417 and batch: 1250, loss is 4.317774515151978 and perplexity is 75.02148319743945
At time: 477.7508590221405 and batch: 1300, loss is 4.453492221832275 and perplexity is 85.92649503036228
At time: 478.12887167930603 and batch: 1350, loss is 4.4325043487548825 and perplexity is 84.1418738685196
At time: 478.52108907699585 and batch: 1400, loss is 4.245334191322327 and perplexity is 69.77907580935509
At time: 478.9099566936493 and batch: 1450, loss is 4.375711030960083 and perplexity is 79.49634382340957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.661907489483173 and perplexity of 105.83777417396291
Finished 40 epochs...
Completing Train Step...
At time: 480.23582792282104 and batch: 50, loss is 4.441150994300842 and perplexity is 84.87257332450712
At time: 480.63796496391296 and batch: 100, loss is 4.468887672424317 and perplexity is 87.25960774352139
At time: 481.03095746040344 and batch: 150, loss is 4.341433544158935 and perplexity is 76.81758183980772
At time: 481.4092116355896 and batch: 200, loss is 4.450113649368286 and perplexity is 85.63667600330211
At time: 481.8027603626251 and batch: 250, loss is 4.47268985748291 and perplexity is 87.59201645957076
At time: 482.19943737983704 and batch: 300, loss is 4.50007155418396 and perplexity is 90.02357263334387
At time: 482.5980935096741 and batch: 350, loss is 4.527337617874146 and perplexity is 92.5119308047698
At time: 482.9898614883423 and batch: 400, loss is 4.344957818984986 and perplexity is 77.0887857274933
At time: 483.3850066661835 and batch: 450, loss is 4.4434998512268065 and perplexity is 85.07216116606415
At time: 483.7772719860077 and batch: 500, loss is 4.399704704284668 and perplexity is 81.42682012333167
At time: 484.1737153530121 and batch: 550, loss is 4.477897663116455 and perplexity is 88.04936852300621
At time: 484.56413674354553 and batch: 600, loss is 4.377343845367432 and perplexity is 79.626252628558
At time: 484.9623441696167 and batch: 650, loss is 4.487004566192627 and perplexity is 88.85488791439096
At time: 485.3612005710602 and batch: 700, loss is 4.527282123565674 and perplexity is 92.50679706159247
At time: 485.7574796676636 and batch: 750, loss is 4.4721844148635865 and perplexity is 87.54775490811913
At time: 486.1822762489319 and batch: 800, loss is 4.3933627223968506 and perplexity is 80.91204677194139
At time: 486.57561016082764 and batch: 850, loss is 4.356785244941712 and perplexity is 78.00596085142138
At time: 486.970566034317 and batch: 900, loss is 4.280485582351685 and perplexity is 72.2755272082442
At time: 487.37865257263184 and batch: 950, loss is 4.399570932388306 and perplexity is 81.41592823171979
At time: 487.77043056488037 and batch: 1000, loss is 4.435270156860351 and perplexity is 84.37491627200015
At time: 488.1553258895874 and batch: 1050, loss is 4.367990627288818 and perplexity is 78.8849630486497
At time: 488.5443227291107 and batch: 1100, loss is 4.500122728347779 and perplexity is 90.028179632276
At time: 488.9276957511902 and batch: 1150, loss is 4.441451530456543 and perplexity is 84.89808443473203
At time: 489.31932759284973 and batch: 1200, loss is 4.372898712158203 and perplexity is 79.27308884023381
At time: 489.71416187286377 and batch: 1250, loss is 4.307991614341736 and perplexity is 74.29113376156644
At time: 490.1155483722687 and batch: 1300, loss is 4.443892793655396 and perplexity is 85.10559619626885
At time: 490.50804257392883 and batch: 1350, loss is 4.423969488143921 and perplexity is 83.42679061224473
At time: 490.88851833343506 and batch: 1400, loss is 4.236317539215088 and perplexity is 69.15273017225856
At time: 491.2843236923218 and batch: 1450, loss is 4.367055144309997 and perplexity is 78.81120201490776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.657230735844017 and perplexity of 105.34395261938364
Finished 41 epochs...
Completing Train Step...
At time: 492.6219837665558 and batch: 50, loss is 4.431718144416809 and perplexity is 84.07574716022918
At time: 493.0289103984833 and batch: 100, loss is 4.460187134742736 and perplexity is 86.50369542855937
At time: 493.42687916755676 and batch: 150, loss is 4.332036752700805 and perplexity is 76.09912392914661
At time: 493.8324146270752 and batch: 200, loss is 4.441592330932617 and perplexity is 84.91003896702037
At time: 494.23655581474304 and batch: 250, loss is 4.464461054801941 and perplexity is 86.8741964896289
At time: 494.61419892311096 and batch: 300, loss is 4.491735401153565 and perplexity is 89.27624161614575
At time: 495.0072023868561 and batch: 350, loss is 4.518431367874146 and perplexity is 91.69165463546271
At time: 495.40417861938477 and batch: 400, loss is 4.33533205986023 and perplexity is 76.35030755335262
At time: 495.79413652420044 and batch: 450, loss is 4.434357242584229 and perplexity is 84.29792435524591
At time: 496.2143967151642 and batch: 500, loss is 4.390302667617798 and perplexity is 80.66482991800183
At time: 496.6045083999634 and batch: 550, loss is 4.468614120483398 and perplexity is 87.23574097300886
At time: 496.98721385002136 and batch: 600, loss is 4.368873109817505 and perplexity is 78.95460837618879
At time: 497.3787190914154 and batch: 650, loss is 4.477854385375976 and perplexity is 88.0455580277414
At time: 497.7803816795349 and batch: 700, loss is 4.518096189498902 and perplexity is 91.66092672559168
At time: 498.17177987098694 and batch: 750, loss is 4.4632904863357545 and perplexity is 86.77256379031438
At time: 498.55382895469666 and batch: 800, loss is 4.384425802230835 and perplexity is 80.19216382899369
At time: 498.9462265968323 and batch: 850, loss is 4.3480649137496945 and perplexity is 77.32868038476583
At time: 499.33120489120483 and batch: 900, loss is 4.271121859550476 and perplexity is 71.6019178734911
At time: 499.7138500213623 and batch: 950, loss is 4.391379938125611 and perplexity is 80.75177458334379
At time: 500.0951509475708 and batch: 1000, loss is 4.4266876077651975 and perplexity is 83.65386307400063
At time: 500.49132561683655 and batch: 1050, loss is 4.3593895149230955 and perplexity is 78.20937419029566
At time: 500.8855354785919 and batch: 1100, loss is 4.491991233825684 and perplexity is 89.29908431742521
At time: 501.2878403663635 and batch: 1150, loss is 4.433129959106445 and perplexity is 84.19453036531893
At time: 501.68750286102295 and batch: 1200, loss is 4.3644281673431395 and perplexity is 78.60443850288243
At time: 502.07986521720886 and batch: 1250, loss is 4.2984207725524906 and perplexity is 73.58349681629467
At time: 502.48223066329956 and batch: 1300, loss is 4.434497385025025 and perplexity is 84.30973889995933
At time: 502.88776111602783 and batch: 1350, loss is 4.415607347488403 and perplexity is 82.7320727670723
At time: 503.2930052280426 and batch: 1400, loss is 4.227494025230408 and perplexity is 68.54524411265939
At time: 503.6873815059662 and batch: 1450, loss is 4.358582139015198 and perplexity is 78.14625530956319
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.652708917601496 and perplexity of 104.8686817667112
Finished 42 epochs...
Completing Train Step...
At time: 505.00885128974915 and batch: 50, loss is 4.422440605163574 and perplexity is 83.29933826666016
At time: 505.4146535396576 and batch: 100, loss is 4.451676874160767 and perplexity is 85.7706500668826
At time: 505.79800033569336 and batch: 150, loss is 4.322840385437011 and perplexity is 75.40249656723279
At time: 506.2282838821411 and batch: 200, loss is 4.4332445621490475 and perplexity is 84.20417986758987
At time: 506.62100768089294 and batch: 250, loss is 4.45640754699707 and perplexity is 86.17736420858053
At time: 507.01030826568604 and batch: 300, loss is 4.483559675216675 and perplexity is 88.54931914059014
At time: 507.3965651988983 and batch: 350, loss is 4.509703855514527 and perplexity is 90.89489650196741
At time: 507.78441882133484 and batch: 400, loss is 4.325896048545838 and perplexity is 75.63325357259124
At time: 508.1834590435028 and batch: 450, loss is 4.425398578643799 and perplexity is 83.5461002779934
At time: 508.5630359649658 and batch: 500, loss is 4.381127462387085 and perplexity is 79.92809854779732
At time: 508.9582371711731 and batch: 550, loss is 4.459535093307495 and perplexity is 86.44730981971283
At time: 509.34912395477295 and batch: 600, loss is 4.360580348968506 and perplexity is 78.30256405156888
At time: 509.7488386631012 and batch: 650, loss is 4.468910555839539 and perplexity is 87.26160456420446
At time: 510.12560987472534 and batch: 700, loss is 4.509101505279541 and perplexity is 90.84016242589715
At time: 510.5265393257141 and batch: 750, loss is 4.454581665992737 and perplexity is 86.02015815971274
At time: 510.92612051963806 and batch: 800, loss is 4.3756730222702025 and perplexity is 79.49332232895242
At time: 511.3182489871979 and batch: 850, loss is 4.339521059989929 and perplexity is 76.67080982495123
At time: 511.7094843387604 and batch: 900, loss is 4.261963934898376 and perplexity is 70.94918629985648
At time: 512.1087634563446 and batch: 950, loss is 4.383345351219178 and perplexity is 80.1055669147437
At time: 512.5007817745209 and batch: 1000, loss is 4.41827757358551 and perplexity is 82.95328131382323
At time: 512.8759279251099 and batch: 1050, loss is 4.35096830368042 and perplexity is 77.55352194016021
At time: 513.2717821598053 and batch: 1100, loss is 4.484020643234253 and perplexity is 88.59014695412739
At time: 513.6633152961731 and batch: 1150, loss is 4.424970359802246 and perplexity is 83.51033192260451
At time: 514.0704843997955 and batch: 1200, loss is 4.356146903038025 and perplexity is 77.9561822674409
At time: 514.453937292099 and batch: 1250, loss is 4.289051094055176 and perplexity is 72.89726302383723
At time: 514.8623101711273 and batch: 1300, loss is 4.425293884277344 and perplexity is 83.53735392980967
At time: 515.2480187416077 and batch: 1350, loss is 4.407409191131592 and perplexity is 82.05659491853521
At time: 515.6226613521576 and batch: 1400, loss is 4.218854565620422 and perplexity is 67.95560101115971
At time: 516.010409116745 and batch: 1450, loss is 4.350283231735229 and perplexity is 77.50041039272101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6483253413795405 and perplexity of 104.40998800094471
Finished 43 epochs...
Completing Train Step...
At time: 517.2976701259613 and batch: 50, loss is 4.41333749294281 and perplexity is 82.54449596220395
At time: 517.6868658065796 and batch: 100, loss is 4.443337569236755 and perplexity is 85.05835660659814
At time: 518.0988230705261 and batch: 150, loss is 4.313842792510986 and perplexity is 74.72709863184926
At time: 518.4939925670624 and batch: 200, loss is 4.425058526992798 and perplexity is 83.51769511854356
At time: 518.8962244987488 and batch: 250, loss is 4.44852219581604 and perplexity is 85.50049760061734
At time: 519.285881280899 and batch: 300, loss is 4.47553822517395 and perplexity is 87.8418663925621
At time: 519.6867847442627 and batch: 350, loss is 4.501140871047974 and perplexity is 90.11988784428156
At time: 520.0726447105408 and batch: 400, loss is 4.316651487350464 and perplexity is 74.93727927661973
At time: 520.4837262630463 and batch: 450, loss is 4.416617364883423 and perplexity is 82.81567581285111
At time: 520.8735706806183 and batch: 500, loss is 4.372170352935791 and perplexity is 79.21537057725422
At time: 521.2700288295746 and batch: 550, loss is 4.450649356842041 and perplexity is 85.68256450097272
At time: 521.6747887134552 and batch: 600, loss is 4.352453536987305 and perplexity is 77.66879259472988
At time: 522.0884997844696 and batch: 650, loss is 4.460154943466186 and perplexity is 86.50091080899769
At time: 522.4790005683899 and batch: 700, loss is 4.500282335281372 and perplexity is 90.0425499007308
At time: 522.878671169281 and batch: 750, loss is 4.446048445701599 and perplexity is 85.2892521268758
At time: 523.2797338962555 and batch: 800, loss is 4.367083139419556 and perplexity is 78.8134083740261
At time: 523.6765079498291 and batch: 850, loss is 4.33114872455597 and perplexity is 76.03157576207595
At time: 524.0536971092224 and batch: 900, loss is 4.252998185157776 and perplexity is 70.31591676138403
At time: 524.4482591152191 and batch: 950, loss is 4.375462694168091 and perplexity is 79.47660440752239
At time: 524.8445837497711 and batch: 1000, loss is 4.410029873847962 and perplexity is 82.27192124635722
At time: 525.237218618393 and batch: 1050, loss is 4.342721309661865 and perplexity is 76.91656859390362
At time: 525.6214032173157 and batch: 1100, loss is 4.476199350357056 and perplexity is 87.89996006404382
At time: 526.006582736969 and batch: 1150, loss is 4.416961765289306 and perplexity is 82.84420247723003
At time: 526.4328393936157 and batch: 1200, loss is 4.348048191070557 and perplexity is 77.32738725286798
At time: 526.8235516548157 and batch: 1250, loss is 4.279867949485779 and perplexity is 72.23090124988764
At time: 527.2288780212402 and batch: 1300, loss is 4.416282720565796 and perplexity is 82.7879666541448
At time: 527.627279996872 and batch: 1350, loss is 4.399365615844727 and perplexity is 81.399213910665
At time: 528.0281112194061 and batch: 1400, loss is 4.21038863658905 and perplexity is 67.38272211336957
At time: 528.4189851284027 and batch: 1450, loss is 4.3421500778198245 and perplexity is 76.87264394751503
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.644074268830129 and perplexity of 103.96707566032765
Finished 44 epochs...
Completing Train Step...
At time: 529.744861125946 and batch: 50, loss is 4.4043807744979855 and perplexity is 81.80846926515115
At time: 530.163987159729 and batch: 100, loss is 4.4351615858078 and perplexity is 84.36575609580558
At time: 530.5395312309265 and batch: 150, loss is 4.305033187866211 and perplexity is 74.07167369285305
At time: 530.922726392746 and batch: 200, loss is 4.417033805847168 and perplexity is 82.85017083477139
At time: 531.3099715709686 and batch: 250, loss is 4.440801501274109 and perplexity is 84.84291613476168
At time: 531.7151143550873 and batch: 300, loss is 4.467668619155884 and perplexity is 87.15329844501379
At time: 532.108895778656 and batch: 350, loss is 4.4927420330047605 and perplexity is 89.3661551718436
At time: 532.5147314071655 and batch: 400, loss is 4.307586631774902 and perplexity is 74.26105323897744
At time: 532.9114670753479 and batch: 450, loss is 4.408005657196045 and perplexity is 82.10555349238116
At time: 533.3040676116943 and batch: 500, loss is 4.363422164916992 and perplexity is 78.52540200916046
At time: 533.6950297355652 and batch: 550, loss is 4.441955137252807 and perplexity is 84.94085045476847
At time: 534.1045024394989 and batch: 600, loss is 4.344484748840332 and perplexity is 77.05232594917432
At time: 534.4996302127838 and batch: 650, loss is 4.4515701150894165 and perplexity is 85.7614937607004
At time: 534.8913311958313 and batch: 700, loss is 4.49162787437439 and perplexity is 89.26664254551577
At time: 535.2996850013733 and batch: 750, loss is 4.437678933143616 and perplexity is 84.57840154608108
At time: 535.696811914444 and batch: 800, loss is 4.358650455474853 and perplexity is 78.15159416742513
At time: 536.0810029506683 and batch: 850, loss is 4.322938976287841 and perplexity is 75.40993092999811
At time: 536.4688351154327 and batch: 900, loss is 4.24421464920044 and perplexity is 69.70099890810498
At time: 536.8624231815338 and batch: 950, loss is 4.367728314399719 and perplexity is 78.86427321980896
At time: 537.2622876167297 and batch: 1000, loss is 4.401938338279724 and perplexity is 81.60890111230987
At time: 537.6666207313538 and batch: 1050, loss is 4.3346451473236085 and perplexity is 76.29787957869736
At time: 538.0580286979675 and batch: 1100, loss is 4.468517370223999 and perplexity is 87.22730130071771
At time: 538.4663033485413 and batch: 1150, loss is 4.409096832275391 and perplexity is 82.19519392403618
At time: 538.872935295105 and batch: 1200, loss is 4.340124578475952 and perplexity is 76.71709604190781
At time: 539.2653667926788 and batch: 1250, loss is 4.270865521430969 and perplexity is 71.58356592476282
At time: 539.6585834026337 and batch: 1300, loss is 4.407459487915039 and perplexity is 82.06072220511402
At time: 540.0597088336945 and batch: 1350, loss is 4.391466178894043 and perplexity is 80.75873897873922
At time: 540.4584159851074 and batch: 1400, loss is 4.202087392807007 and perplexity is 66.825676992938
At time: 540.8537974357605 and batch: 1450, loss is 4.33417432308197 and perplexity is 76.26196514276307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.639949439937233 and perplexity of 103.53911250691208
Finished 45 epochs...
Completing Train Step...
At time: 542.1148717403412 and batch: 50, loss is 4.395574712753296 and perplexity is 81.0912215324854
At time: 542.5341558456421 and batch: 100, loss is 4.427137351036071 and perplexity is 83.69149429756125
At time: 542.9122774600983 and batch: 150, loss is 4.2964070034027095 and perplexity is 73.43546574070507
At time: 543.300863981247 and batch: 200, loss is 4.409161024093628 and perplexity is 82.20047035233445
At time: 543.694643497467 and batch: 250, loss is 4.433237905502319 and perplexity is 84.20361935197705
At time: 544.0997564792633 and batch: 300, loss is 4.45994927406311 and perplexity is 86.4831220476707
At time: 544.4890177249908 and batch: 350, loss is 4.484499216079712 and perplexity is 88.63255393944132
At time: 544.8766956329346 and batch: 400, loss is 4.298698539733887 and perplexity is 73.60393873571834
At time: 545.2697532176971 and batch: 450, loss is 4.399554052352905 and perplexity is 81.41455393956815
At time: 545.6451177597046 and batch: 500, loss is 4.3548775482177735 and perplexity is 77.8572909890501
At time: 546.0552928447723 and batch: 550, loss is 4.433445768356323 and perplexity is 84.22112397583051
At time: 546.4743061065674 and batch: 600, loss is 4.336658182144165 and perplexity is 76.45162456210797
At time: 546.8613669872284 and batch: 650, loss is 4.4431432294845585 and perplexity is 85.04182799278834
At time: 547.2521362304688 and batch: 700, loss is 4.483128509521484 and perplexity is 88.51114794149137
At time: 547.6387968063354 and batch: 750, loss is 4.429465045928955 and perplexity is 83.88652946453553
At time: 548.0160717964172 and batch: 800, loss is 4.350381345748901 and perplexity is 77.50801464208146
At time: 548.3918154239655 and batch: 850, loss is 4.314882063865662 and perplexity is 74.80480073466649
At time: 548.7833666801453 and batch: 900, loss is 4.235614280700684 and perplexity is 69.10411502248326
At time: 549.1771183013916 and batch: 950, loss is 4.360133275985718 and perplexity is 78.26756491486556
At time: 549.5649344921112 and batch: 1000, loss is 4.393999171257019 and perplexity is 80.9635595427666
At time: 549.9546570777893 and batch: 1050, loss is 4.326734662055969 and perplexity is 75.69670724368657
At time: 550.3573014736176 and batch: 1100, loss is 4.4609651947021485 and perplexity is 86.57102668079246
At time: 550.7446827888489 and batch: 1150, loss is 4.401368541717529 and perplexity is 81.5624138864001
At time: 551.1258416175842 and batch: 1200, loss is 4.332365088462829 and perplexity is 76.12411409534938
At time: 551.5269093513489 and batch: 1250, loss is 4.262039966583252 and perplexity is 70.95458089110878
At time: 551.9195940494537 and batch: 1300, loss is 4.3988192653656 and perplexity is 81.3547535577179
At time: 552.3202109336853 and batch: 1350, loss is 4.383700561523438 and perplexity is 80.13402629177317
At time: 552.7178392410278 and batch: 1400, loss is 4.19394275188446 and perplexity is 66.28361629078408
At time: 553.1089313030243 and batch: 1450, loss is 4.326349291801453 and perplexity is 75.66754160449587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.635950854700854 and perplexity of 103.12592916518061
Finished 46 epochs...
Completing Train Step...
At time: 554.4023585319519 and batch: 50, loss is 4.386910052299499 and perplexity is 80.3916288754367
At time: 554.8072776794434 and batch: 100, loss is 4.419255495071411 and perplexity is 83.03444278825272
At time: 555.2046403884888 and batch: 150, loss is 4.287959814071655 and perplexity is 72.81775509044444
At time: 555.6095831394196 and batch: 200, loss is 4.4014341926574705 and perplexity is 81.56776871130835
At time: 555.9960358142853 and batch: 250, loss is 4.425822362899781 and perplexity is 83.58151330315114
At time: 556.409661769867 and batch: 300, loss is 4.452376117706299 and perplexity is 85.83064561364286
At time: 556.7919881343842 and batch: 350, loss is 4.4764053249359135 and perplexity is 87.91806708602873
At time: 557.1818823814392 and batch: 400, loss is 4.2899766492843625 and perplexity is 72.96476470026833
At time: 557.5717582702637 and batch: 450, loss is 4.391254062652588 and perplexity is 80.74161055523503
At time: 557.9661571979523 and batch: 500, loss is 4.34652726650238 and perplexity is 77.2098675217793
At time: 558.3693327903748 and batch: 550, loss is 4.425114240646362 and perplexity is 83.52234832409823
At time: 558.7649576663971 and batch: 600, loss is 4.328965578079224 and perplexity is 75.86576875167961
At time: 559.1609177589417 and batch: 650, loss is 4.434865164756775 and perplexity is 84.34075201576401
At time: 559.5509831905365 and batch: 700, loss is 4.474779319763184 and perplexity is 87.77522801417624
At time: 559.9406626224518 and batch: 750, loss is 4.42139856338501 and perplexity is 83.21258208569243
At time: 560.3253705501556 and batch: 800, loss is 4.34227376461029 and perplexity is 76.88215266615883
At time: 560.7241027355194 and batch: 850, loss is 4.306971035003662 and perplexity is 74.21535244244926
At time: 561.1187887191772 and batch: 900, loss is 4.227194361686706 and perplexity is 68.52470667921841
At time: 561.5115756988525 and batch: 950, loss is 4.35267409324646 and perplexity is 77.68592482231821
At time: 561.9067378044128 and batch: 1000, loss is 4.386208472251892 and perplexity is 80.33524749296215
At time: 562.2970454692841 and batch: 1050, loss is 4.31898072719574 and perplexity is 75.11202961212268
At time: 562.7026724815369 and batch: 1100, loss is 4.4535408782958985 and perplexity is 85.93067601145707
At time: 563.103812456131 and batch: 1150, loss is 4.393773832321167 and perplexity is 80.94531735583112
At time: 563.5032727718353 and batch: 1200, loss is 4.324759488105774 and perplexity is 75.54734064049558
At time: 563.8927574157715 and batch: 1250, loss is 4.2533847618103025 and perplexity is 70.3431045078404
At time: 564.2935264110565 and batch: 1300, loss is 4.390353507995606 and perplexity is 80.66893105268143
At time: 564.688257932663 and batch: 1350, loss is 4.376062135696412 and perplexity is 79.52426026675771
At time: 565.0895354747772 and batch: 1400, loss is 4.1859503173828125 and perplexity is 65.75596026599874
At time: 565.4813852310181 and batch: 1450, loss is 4.318671617507935 and perplexity is 75.08881534416126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.63207277477297 and perplexity of 102.72677304916057
Finished 47 epochs...
Completing Train Step...
At time: 566.7980153560638 and batch: 50, loss is 4.378386182785034 and perplexity is 79.70929332178866
At time: 567.1735353469849 and batch: 100, loss is 4.411506280899048 and perplexity is 82.39347780238946
At time: 567.5745720863342 and batch: 150, loss is 4.279691557884217 and perplexity is 72.21816144916383
At time: 567.9733481407166 and batch: 200, loss is 4.393847455978394 and perplexity is 80.95127706551536
At time: 568.3690347671509 and batch: 250, loss is 4.4185436773300175 and perplexity is 82.97535842987133
At time: 568.7763102054596 and batch: 300, loss is 4.444939403533936 and perplexity is 85.19471518223743
At time: 569.1892879009247 and batch: 350, loss is 4.468448095321655 and perplexity is 87.22125884723594
At time: 569.5940616130829 and batch: 400, loss is 4.28141604423523 and perplexity is 72.34280812773603
At time: 569.9992783069611 and batch: 450, loss is 4.3830952644348145 and perplexity is 80.08553607593285
At time: 570.3904736042023 and batch: 500, loss is 4.338362421989441 and perplexity is 76.58202755434817
At time: 570.7835252285004 and batch: 550, loss is 4.416949110031128 and perplexity is 82.84315406909305
At time: 571.1805353164673 and batch: 600, loss is 4.321400547027588 and perplexity is 75.29400727877389
At time: 571.5716547966003 and batch: 650, loss is 4.426723499298095 and perplexity is 83.65686559326136
At time: 571.9467353820801 and batch: 700, loss is 4.466572790145874 and perplexity is 87.05784564178715
At time: 572.3479657173157 and batch: 750, loss is 4.413473057746887 and perplexity is 82.55568684915474
At time: 572.7436385154724 and batch: 800, loss is 4.334323887825012 and perplexity is 76.27337209700136
At time: 573.1377139091492 and batch: 850, loss is 4.299198255538941 and perplexity is 73.64072897878619
At time: 573.530722618103 and batch: 900, loss is 4.21895058631897 and perplexity is 67.96212646872353
At time: 573.929473400116 and batch: 950, loss is 4.345344738960266 and perplexity is 77.11861868967371
At time: 574.3413724899292 and batch: 1000, loss is 4.378561501502991 and perplexity is 79.72326907797309
At time: 574.7286434173584 and batch: 1050, loss is 4.311376280784607 and perplexity is 74.54301048790619
At time: 575.1217973232269 and batch: 1100, loss is 4.446237936019897 and perplexity is 85.30541514572812
At time: 575.5110921859741 and batch: 1150, loss is 4.386308541297913 and perplexity is 80.34328696678517
At time: 575.904876947403 and batch: 1200, loss is 4.317296895980835 and perplexity is 74.98566005440772
At time: 576.3010070323944 and batch: 1250, loss is 4.244892606735229 and perplexity is 69.74826924732787
At time: 576.7000241279602 and batch: 1300, loss is 4.382052068710327 and perplexity is 80.00203474879146
At time: 577.0881471633911 and batch: 1350, loss is 4.368547506332398 and perplexity is 78.92890466537222
At time: 577.4695336818695 and batch: 1400, loss is 4.1781082487106325 and perplexity is 65.24231416633074
At time: 577.8608295917511 and batch: 1450, loss is 4.311137418746949 and perplexity is 74.52520711888698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.628317286825587 and perplexity of 102.34170739837658
Finished 48 epochs...
Completing Train Step...
At time: 579.1733663082123 and batch: 50, loss is 4.370004210472107 and perplexity is 79.04396451127161
At time: 579.5480201244354 and batch: 100, loss is 4.40389997959137 and perplexity is 81.76914562387118
At time: 579.9442429542542 and batch: 150, loss is 4.271576285362244 and perplexity is 71.63446302726378
At time: 580.3549919128418 and batch: 200, loss is 4.386395874023438 and perplexity is 80.35030387141187
At time: 580.7557201385498 and batch: 250, loss is 4.411392350196838 and perplexity is 82.3840911903277
At time: 581.1516137123108 and batch: 300, loss is 4.437632722854614 and perplexity is 84.57449324400493
At time: 581.5464961528778 and batch: 350, loss is 4.460629243850708 and perplexity is 86.5419479554537
At time: 581.9467375278473 and batch: 400, loss is 4.27300721168518 and perplexity is 71.73704003860912
At time: 582.3558433055878 and batch: 450, loss is 4.375074195861816 and perplexity is 79.44573387828405
At time: 582.7528474330902 and batch: 500, loss is 4.330369515419006 and perplexity is 75.97235433947765
At time: 583.1518561840057 and batch: 550, loss is 4.408936910629272 and perplexity is 82.18205018433306
At time: 583.5518646240234 and batch: 600, loss is 4.313958673477173 and perplexity is 74.73575858199109
At time: 583.9527673721313 and batch: 650, loss is 4.418708643913269 and perplexity is 82.98904772035227
At time: 584.3448379039764 and batch: 700, loss is 4.458506031036377 and perplexity is 86.35839591155826
At time: 584.7563138008118 and batch: 750, loss is 4.40567873954773 and perplexity is 81.91472274076204
At time: 585.1504111289978 and batch: 800, loss is 4.326525130271912 and perplexity is 75.68084803913226
At time: 585.5436546802521 and batch: 850, loss is 4.291561284065247 and perplexity is 73.08047886232049
At time: 585.9350507259369 and batch: 900, loss is 4.210874376296997 and perplexity is 67.41546052765976
At time: 586.3384890556335 and batch: 950, loss is 4.338138203620911 and perplexity is 76.56485838196508
At time: 586.7624340057373 and batch: 1000, loss is 4.371054039001465 and perplexity is 79.12699069429138
At time: 587.1779158115387 and batch: 1050, loss is 4.303906497955322 and perplexity is 73.98826488217682
At time: 587.5687851905823 and batch: 1100, loss is 4.439054002761841 and perplexity is 84.69478273418515
At time: 587.963431596756 and batch: 1150, loss is 4.378969383239746 and perplexity is 79.75579337600712
At time: 588.3613345623016 and batch: 1200, loss is 4.309969387054443 and perplexity is 74.438210132591
At time: 588.7557499408722 and batch: 1250, loss is 4.236557302474975 and perplexity is 69.16931244410507
At time: 589.1483640670776 and batch: 1300, loss is 4.373904867172241 and perplexity is 79.35288999548274
At time: 589.5489563941956 and batch: 1350, loss is 4.361152229309082 and perplexity is 78.34735655532201
At time: 589.9434885978699 and batch: 1400, loss is 4.170414190292359 and perplexity is 64.74226217128236
At time: 590.3398933410645 and batch: 1450, loss is 4.303739132881165 and perplexity is 73.97588286692543
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.624678130842682 and perplexity of 101.96994681924772
Finished 49 epochs...
Completing Train Step...
At time: 591.5789303779602 and batch: 50, loss is 4.361755080223084 and perplexity is 78.39460257055188
At time: 591.9952259063721 and batch: 100, loss is 4.39643798828125 and perplexity is 81.16125582466219
At time: 592.385246515274 and batch: 150, loss is 4.263596081733704 and perplexity is 71.06508034206443
At time: 592.784651517868 and batch: 200, loss is 4.379075326919556 and perplexity is 79.76424344585133
At time: 593.1835300922394 and batch: 250, loss is 4.404362092018127 and perplexity is 81.8069408943488
At time: 593.5824027061462 and batch: 300, loss is 4.430451974868775 and perplexity is 83.96936037551336
At time: 593.9812953472137 and batch: 350, loss is 4.452947874069213 and perplexity is 85.87973386332779
At time: 594.3752961158752 and batch: 400, loss is 4.264744963645935 and perplexity is 71.14677264588012
At time: 594.7792019844055 and batch: 450, loss is 4.367191925048828 and perplexity is 78.82198260661931
At time: 595.1750445365906 and batch: 500, loss is 4.322536182403565 and perplexity is 75.37956238754795
At time: 595.5749757289886 and batch: 550, loss is 4.401067771911621 and perplexity is 81.53788606380522
At time: 595.970948934555 and batch: 600, loss is 4.306633501052857 and perplexity is 74.1903064685
At time: 596.3538312911987 and batch: 650, loss is 4.410817284584045 and perplexity is 82.33672855206048
At time: 596.7554121017456 and batch: 700, loss is 4.4505799293518065 and perplexity is 85.67661598206035
At time: 597.1490111351013 and batch: 750, loss is 4.398007645606994 and perplexity is 81.28875122029764
At time: 597.550950050354 and batch: 800, loss is 4.318869705200195 and perplexity is 75.10369098759968
At time: 597.9541547298431 and batch: 850, loss is 4.28405960559845 and perplexity is 72.53430378394741
At time: 598.3435430526733 and batch: 900, loss is 4.202963676452637 and perplexity is 66.88426090510835
At time: 598.737601518631 and batch: 950, loss is 4.331048254966736 and perplexity is 76.02393728461409
At time: 599.1350018978119 and batch: 1000, loss is 4.363678193092346 and perplexity is 78.54550929846225
At time: 599.5115315914154 and batch: 1050, loss is 4.296555738449097 and perplexity is 73.44638898042265
At time: 599.8869109153748 and batch: 1100, loss is 4.43198956489563 and perplexity is 84.09857013695212
At time: 600.269232749939 and batch: 1150, loss is 4.3717529296875 and perplexity is 79.18231114032207
At time: 600.6626818180084 and batch: 1200, loss is 4.302769832611084 and perplexity is 73.9042127642194
At time: 601.0588822364807 and batch: 1250, loss is 4.2283690690994264 and perplexity is 68.60525045853416
At time: 601.4561314582825 and batch: 1300, loss is 4.3659044456481935 and perplexity is 78.72056622745468
At time: 601.8554759025574 and batch: 1350, loss is 4.35387354850769 and perplexity is 77.77916151901482
At time: 602.2529566287994 and batch: 1400, loss is 4.162863345146179 and perplexity is 64.25524438710121
At time: 602.6441037654877 and batch: 1450, loss is 4.296470203399658 and perplexity is 73.44010700857832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.621153220152244 and perplexity of 101.61114460798582
Finished Training.
Improved accuracyfrom -123.36313670519357 to -101.61114460798582
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7fb370c6a0>
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.1615776763065303, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 16.188439477776065, 'anneal': 6.163990410661358, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6276812553405762 and batch: 50, loss is 6.249345655441284 and perplexity is 517.6739766689379
At time: 1.0406036376953125 and batch: 100, loss is 5.586455163955688 and perplexity is 266.78822101713723
At time: 1.4180657863616943 and batch: 150, loss is 5.40104564666748 and perplexity is 221.63805016798565
At time: 1.8223984241485596 and batch: 200, loss is 5.361344795227051 and perplexity is 213.01121038225028
At time: 2.219989061355591 and batch: 250, loss is 5.324996147155762 and perplexity is 205.40756905988962
At time: 2.627284288406372 and batch: 300, loss is 5.34811806678772 and perplexity is 210.2123198351105
At time: 3.0200424194335938 and batch: 350, loss is 5.357149238586426 and perplexity is 212.1193819505678
At time: 3.426485776901245 and batch: 400, loss is 5.237737436294555 and perplexity is 188.24370683513152
At time: 3.827996253967285 and batch: 450, loss is 5.249577360153198 and perplexity is 190.48574457762206
At time: 4.240481376647949 and batch: 500, loss is 5.235032520294189 and perplexity is 187.73521144923453
At time: 4.636437892913818 and batch: 550, loss is 5.276011352539062 and perplexity is 195.58818512678303
At time: 5.040333986282349 and batch: 600, loss is 5.126396026611328 and perplexity is 168.4090811816906
At time: 5.434240818023682 and batch: 650, loss is 5.257912635803223 and perplexity is 192.08013136167932
At time: 5.847125768661499 and batch: 700, loss is 5.272867107391358 and perplexity is 194.97417373178166
At time: 6.251800298690796 and batch: 750, loss is 5.223322095870972 and perplexity is 185.54957478749523
At time: 6.658711910247803 and batch: 800, loss is 5.127624244689941 and perplexity is 168.616051336025
At time: 7.066301345825195 and batch: 850, loss is 5.074541673660279 and perplexity is 159.8988893097347
At time: 7.4698474407196045 and batch: 900, loss is 5.061590843200683 and perplexity is 157.84141764416756
At time: 7.866410970687866 and batch: 950, loss is 5.107276248931885 and perplexity is 165.2197240493776
At time: 8.269549131393433 and batch: 1000, loss is 5.149179067611694 and perplexity is 172.2899938091689
At time: 8.66382122039795 and batch: 1050, loss is 5.053119983673096 and perplexity is 156.5100122031923
At time: 9.05970811843872 and batch: 1100, loss is 5.1574986743927 and perplexity is 173.72935797969407
At time: 9.442181587219238 and batch: 1150, loss is 5.1213703441619876 and perplexity is 167.56483385453657
At time: 9.848721027374268 and batch: 1200, loss is 5.057836542129516 and perplexity is 157.2499444198348
At time: 10.260992765426636 and batch: 1250, loss is 5.0509863948822025 and perplexity is 156.17644017480396
At time: 10.679880619049072 and batch: 1300, loss is 5.151890954971313 and perplexity is 172.75785897765076
At time: 11.058290004730225 and batch: 1350, loss is 5.102255163192749 and perplexity is 164.39222086987144
At time: 11.45771312713623 and batch: 1400, loss is 4.9428005027771 and perplexity is 140.16222514021953
At time: 11.861612558364868 and batch: 1450, loss is 5.042731599807739 and perplexity is 154.8925421139647
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.058133117154113 and perplexity of 157.29658774224927
Finished 1 epochs...
Completing Train Step...
At time: 13.237109661102295 and batch: 50, loss is 5.02137791633606 and perplexity is 151.62007970785302
At time: 13.641361951828003 and batch: 100, loss is 5.025379447937012 and perplexity is 152.22800775860463
At time: 14.041254997253418 and batch: 150, loss is 4.905321159362793 and perplexity is 135.00626156999667
At time: 14.438957214355469 and batch: 200, loss is 4.98793815612793 and perplexity is 146.63377564485268
At time: 14.824331283569336 and batch: 250, loss is 5.01116265296936 and perplexity is 150.07912469268626
At time: 15.234279155731201 and batch: 300, loss is 5.020140571594238 and perplexity is 151.4325894184548
At time: 15.643299579620361 and batch: 350, loss is 5.061656808853149 and perplexity is 157.851830099697
At time: 16.047610998153687 and batch: 400, loss is 4.9294239521026615 and perplexity is 138.299822067753
At time: 16.424947261810303 and batch: 450, loss is 4.953443737030029 and perplexity is 141.66197145408495
At time: 16.80793571472168 and batch: 500, loss is 4.947968406677246 and perplexity is 140.88844495099508
At time: 17.200742483139038 and batch: 550, loss is 5.01811113357544 and perplexity is 151.12557799989833
At time: 17.60996651649475 and batch: 600, loss is 4.899881629943848 and perplexity is 134.27388473693503
At time: 18.003786087036133 and batch: 650, loss is 5.008920087814331 and perplexity is 149.742939576559
At time: 18.398836135864258 and batch: 700, loss is 5.023052730560303 and perplexity is 151.87422794015868
At time: 18.817272186279297 and batch: 750, loss is 5.002841682434082 and perplexity is 148.8355019677284
At time: 19.219447135925293 and batch: 800, loss is 4.919132328033447 and perplexity is 136.88379141627672
At time: 19.613018035888672 and batch: 850, loss is 4.88866888999939 and perplexity is 132.77671595415103
At time: 20.002258777618408 and batch: 900, loss is 4.8364654064178465 and perplexity is 126.0231230542316
At time: 20.39069104194641 and batch: 950, loss is 4.921853218078613 and perplexity is 137.25674431351024
At time: 20.79006004333496 and batch: 1000, loss is 4.961481561660767 and perplexity is 142.80521397383947
At time: 21.184935331344604 and batch: 1050, loss is 4.872943029403687 and perplexity is 130.7050201231056
At time: 21.57627534866333 and batch: 1100, loss is 5.004811639785767 and perplexity is 149.12899054409823
At time: 21.980857849121094 and batch: 1150, loss is 4.964109230041504 and perplexity is 143.18095216068465
At time: 22.37239408493042 and batch: 1200, loss is 4.9126337623596195 and perplexity is 135.99712725114637
At time: 22.77205467224121 and batch: 1250, loss is 4.891612253189087 and perplexity is 133.16810176507326
At time: 23.180156469345093 and batch: 1300, loss is 4.981324462890625 and perplexity is 145.66718472571932
At time: 23.574803352355957 and batch: 1350, loss is 4.949315547943115 and perplexity is 141.07836948794053
At time: 23.971689462661743 and batch: 1400, loss is 4.79524001121521 and perplexity is 120.93340367330053
At time: 24.378527641296387 and batch: 1450, loss is 4.9042910289764405 and perplexity is 134.8672591252187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.083216479700854 and perplexity of 161.29201497174395
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 25.705700874328613 and batch: 50, loss is 4.93792158126831 and perplexity is 139.48005013760974
At time: 26.09003710746765 and batch: 100, loss is 4.883288135528565 and perplexity is 132.0641957134983
At time: 26.4843852519989 and batch: 150, loss is 4.747387294769287 and perplexity is 115.28269102144243
At time: 26.8794903755188 and batch: 200, loss is 4.811418647766113 and perplexity is 122.90585401317358
At time: 27.26231861114502 and batch: 250, loss is 4.831062593460083 and perplexity is 125.3440797158841
At time: 27.644078493118286 and batch: 300, loss is 4.818684844970703 and perplexity is 123.8021646272856
At time: 28.03289556503296 and batch: 350, loss is 4.82187560081482 and perplexity is 124.19781798854538
At time: 28.427210330963135 and batch: 400, loss is 4.6692068481445315 and perplexity is 106.61314847242917
At time: 28.8189640045166 and batch: 450, loss is 4.721637191772461 and perplexity is 112.35204401799868
At time: 29.209535837173462 and batch: 500, loss is 4.685564956665039 and perplexity is 108.3714802066936
At time: 29.597033262252808 and batch: 550, loss is 4.7492028427124025 and perplexity is 115.49218238726834
At time: 29.981630086898804 and batch: 600, loss is 4.651255950927735 and perplexity is 104.71642170816483
At time: 30.362789392471313 and batch: 650, loss is 4.739071712493897 and perplexity is 114.32802313020342
At time: 30.746866703033447 and batch: 700, loss is 4.761553630828858 and perplexity is 116.92744694044069
At time: 31.141063928604126 and batch: 750, loss is 4.708810329437256 and perplexity is 110.92012297592731
At time: 31.556095361709595 and batch: 800, loss is 4.629788255691528 and perplexity is 102.49235963886
At time: 31.947431564331055 and batch: 850, loss is 4.571289863586426 and perplexity is 96.66871885160464
At time: 32.33857250213623 and batch: 900, loss is 4.4967096900939945 and perplexity is 89.72143377671122
At time: 32.73777461051941 and batch: 950, loss is 4.594898500442505 and perplexity is 98.97808880559111
At time: 33.14323425292969 and batch: 1000, loss is 4.615842399597168 and perplexity is 101.07293648097331
At time: 33.53399181365967 and batch: 1050, loss is 4.511197986602784 and perplexity is 91.03080690128712
At time: 33.929349184036255 and batch: 1100, loss is 4.628605709075928 and perplexity is 102.3712292811074
At time: 34.32481050491333 and batch: 1150, loss is 4.566005229949951 and perplexity is 96.15920756438442
At time: 34.701823234558105 and batch: 1200, loss is 4.487795248031616 and perplexity is 88.9251716429425
At time: 35.101134300231934 and batch: 1250, loss is 4.44366457939148 and perplexity is 85.08617610133342
At time: 35.512587785720825 and batch: 1300, loss is 4.527975244522095 and perplexity is 92.5709376872853
At time: 35.915502309799194 and batch: 1350, loss is 4.464453296661377 and perplexity is 86.87352251001559
At time: 36.30706858634949 and batch: 1400, loss is 4.302740144729614 and perplexity is 73.90201873727892
At time: 36.70077323913574 and batch: 1450, loss is 4.378760690689087 and perplexity is 79.73915067272213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.818501790364583 and perplexity of 123.77950414491903
Finished 3 epochs...
Completing Train Step...
At time: 38.03181338310242 and batch: 50, loss is 4.675483112335205 and perplexity is 107.28438498386586
At time: 38.42476773262024 and batch: 100, loss is 4.6673472881317135 and perplexity is 106.41507914266829
At time: 38.81356453895569 and batch: 150, loss is 4.537406158447266 and perplexity is 93.44809593319329
At time: 39.209614753723145 and batch: 200, loss is 4.628344030380249 and perplexity is 102.34444441602116
At time: 39.60502505302429 and batch: 250, loss is 4.663352279663086 and perplexity is 105.99079806784414
At time: 39.99958634376526 and batch: 300, loss is 4.659981193542481 and perplexity is 105.63409553484864
At time: 40.40500330924988 and batch: 350, loss is 4.660643577575684 and perplexity is 105.70408905182762
At time: 40.79293942451477 and batch: 400, loss is 4.507383728027344 and perplexity is 90.68425320828732
At time: 41.1837260723114 and batch: 450, loss is 4.567124090194702 and perplexity is 96.26685648971642
At time: 41.56369638442993 and batch: 500, loss is 4.542851152420044 and perplexity is 93.95830804268596
At time: 41.9432156085968 and batch: 550, loss is 4.603303985595703 and perplexity is 99.8135539876832
At time: 42.35109567642212 and batch: 600, loss is 4.514143285751342 and perplexity is 91.29931508370238
At time: 42.74288082122803 and batch: 650, loss is 4.59755651473999 and perplexity is 99.2415239328432
At time: 43.14333963394165 and batch: 700, loss is 4.629073724746704 and perplexity is 102.41915183402574
At time: 43.53563404083252 and batch: 750, loss is 4.586758403778076 and perplexity is 98.17566791762428
At time: 43.93844819068909 and batch: 800, loss is 4.503537817001343 and perplexity is 90.33615943688102
At time: 44.335299253463745 and batch: 850, loss is 4.456168355941773 and perplexity is 86.15675381890141
At time: 44.744385957717896 and batch: 900, loss is 4.380830445289612 and perplexity is 79.90436206120576
At time: 45.14103150367737 and batch: 950, loss is 4.49043119430542 and perplexity is 89.15988282491294
At time: 45.56942367553711 and batch: 1000, loss is 4.512014207839965 and perplexity is 91.10513851051003
At time: 45.96115183830261 and batch: 1050, loss is 4.410030174255371 and perplexity is 82.27194596145564
At time: 46.357396841049194 and batch: 1100, loss is 4.53606406211853 and perplexity is 93.32276370948529
At time: 46.75075626373291 and batch: 1150, loss is 4.476254987716675 and perplexity is 87.90485072178278
At time: 47.150147438049316 and batch: 1200, loss is 4.409945721626282 and perplexity is 82.26499817270256
At time: 47.54298734664917 and batch: 1250, loss is 4.36475905418396 and perplexity is 78.6304519807345
At time: 47.95152235031128 and batch: 1300, loss is 4.449193811416626 and perplexity is 85.5579403562299
At time: 48.35367226600647 and batch: 1350, loss is 4.402434844970703 and perplexity is 81.6494305384886
At time: 48.748411655426025 and batch: 1400, loss is 4.249684166908264 and perplexity is 70.08327423371736
At time: 49.146044969558716 and batch: 1450, loss is 4.334410028457642 and perplexity is 76.27994261651688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.788464668469551 and perplexity of 120.11680789598782
Finished 4 epochs...
Completing Train Step...
At time: 50.463751792907715 and batch: 50, loss is 4.576066293716431 and perplexity is 97.13155470457437
At time: 50.840272188186646 and batch: 100, loss is 4.574145774841309 and perplexity is 96.94519073543646
At time: 51.24168157577515 and batch: 150, loss is 4.4471405982971195 and perplexity is 85.38245188987362
At time: 51.6360809803009 and batch: 200, loss is 4.5390074348449705 and perplexity is 93.59785203207586
At time: 52.032325983047485 and batch: 250, loss is 4.570974082946777 and perplexity is 96.63819756100163
At time: 52.423609256744385 and batch: 300, loss is 4.574212274551392 and perplexity is 96.95163777687507
At time: 52.82141137123108 and batch: 350, loss is 4.5734381580352785 and perplexity is 96.87661495475713
At time: 53.2162766456604 and batch: 400, loss is 4.419768052101135 and perplexity is 83.07701358466154
At time: 53.61954927444458 and batch: 450, loss is 4.477745943069458 and perplexity is 88.03601068202761
At time: 53.99890875816345 and batch: 500, loss is 4.46098991394043 and perplexity is 86.57316667707866
At time: 54.39676356315613 and batch: 550, loss is 4.518170280456543 and perplexity is 91.66771822302222
At time: 54.791327476501465 and batch: 600, loss is 4.435876827239991 and perplexity is 84.42611956467697
At time: 55.195027589797974 and batch: 650, loss is 4.517476539611817 and perplexity is 91.6041466364008
At time: 55.60140681266785 and batch: 700, loss is 4.550226602554321 and perplexity is 94.65385469017977
At time: 56.00863432884216 and batch: 750, loss is 4.510973072052002 and perplexity is 91.01033505054046
At time: 56.41043305397034 and batch: 800, loss is 4.429863014221191 and perplexity is 83.91992028721178
At time: 56.801690340042114 and batch: 850, loss is 4.388378028869629 and perplexity is 80.50972856564117
At time: 57.196789503097534 and batch: 900, loss is 4.311342129707336 and perplexity is 74.54046480726412
At time: 57.58187675476074 and batch: 950, loss is 4.425077133178711 and perplexity is 83.51924907876254
At time: 57.97952890396118 and batch: 1000, loss is 4.4483889293670655 and perplexity is 85.48910401212493
At time: 58.37276840209961 and batch: 1050, loss is 4.351654891967773 and perplexity is 77.60678756365142
At time: 58.76998257637024 and batch: 1100, loss is 4.475136861801148 and perplexity is 87.80661695918248
At time: 59.16620874404907 and batch: 1150, loss is 4.418075294494629 and perplexity is 82.93650329647167
At time: 59.557456493377686 and batch: 1200, loss is 4.354494495391846 and perplexity is 77.82747324496782
At time: 59.93649411201477 and batch: 1250, loss is 4.311618013381958 and perplexity is 74.56103214156859
At time: 60.342235803604126 and batch: 1300, loss is 4.3921942710876465 and perplexity is 80.81756019719137
At time: 60.73834705352783 and batch: 1350, loss is 4.3533671188354495 and perplexity is 77.73978181610626
At time: 61.12944841384888 and batch: 1400, loss is 4.207074623107911 and perplexity is 67.15978447709381
At time: 61.52816438674927 and batch: 1450, loss is 4.2917663097381595 and perplexity is 73.09546377276922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.770324185363248 and perplexity of 117.9574758500584
Finished 5 epochs...
Completing Train Step...
At time: 62.83039832115173 and batch: 50, loss is 4.504737038612365 and perplexity is 90.44455749519067
At time: 63.24120235443115 and batch: 100, loss is 4.5119943523406985 and perplexity is 91.10332959045768
At time: 63.63597249984741 and batch: 150, loss is 4.382397155761719 and perplexity is 80.02964717914035
At time: 64.03547859191895 and batch: 200, loss is 4.472941341400147 and perplexity is 87.61404721306263
At time: 64.44512414932251 and batch: 250, loss is 4.507160873413086 and perplexity is 90.66404605573149
At time: 64.8506600856781 and batch: 300, loss is 4.513502082824707 and perplexity is 91.24079246011475
At time: 65.24415612220764 and batch: 350, loss is 4.508752117156982 and perplexity is 90.80842949597144
At time: 65.65763068199158 and batch: 400, loss is 4.357028789520264 and perplexity is 78.02496109389061
At time: 66.05802512168884 and batch: 450, loss is 4.413344373703003 and perplexity is 82.54506393303994
At time: 66.45673847198486 and batch: 500, loss is 4.400870742797852 and perplexity is 81.52182230894111
At time: 66.85009860992432 and batch: 550, loss is 4.45475396156311 and perplexity is 86.03498032878686
At time: 67.24266862869263 and batch: 600, loss is 4.37860221862793 and perplexity is 79.72651524636757
At time: 67.63454675674438 and batch: 650, loss is 4.459971485137939 and perplexity is 86.48504295209857
At time: 68.02576065063477 and batch: 700, loss is 4.4940696048736575 and perplexity is 89.48487395190129
At time: 68.42159676551819 and batch: 750, loss is 4.457092742919922 and perplexity is 86.23643282165376
At time: 68.83538150787354 and batch: 800, loss is 4.376780786514282 and perplexity is 79.58143098186903
At time: 69.21756625175476 and batch: 850, loss is 4.337602787017822 and perplexity is 76.52387525807575
At time: 69.59597849845886 and batch: 900, loss is 4.254539442062378 and perplexity is 70.42437521329487
At time: 70.00266718864441 and batch: 950, loss is 4.3779241704940794 and perplexity is 79.67247515444852
At time: 70.39243125915527 and batch: 1000, loss is 4.3966310024261475 and perplexity is 81.17692260696062
At time: 70.7772319316864 and batch: 1050, loss is 4.304289555549621 and perplexity is 74.01661207788665
At time: 71.1790885925293 and batch: 1100, loss is 4.428808927536011 and perplexity is 83.83150802189768
At time: 71.57750463485718 and batch: 1150, loss is 4.369551134109497 and perplexity is 79.00815967112045
At time: 71.97221803665161 and batch: 1200, loss is 4.309989123344422 and perplexity is 74.43967928118936
At time: 72.37358570098877 and batch: 1250, loss is 4.265875773429871 and perplexity is 71.22727161841836
At time: 72.75989747047424 and batch: 1300, loss is 4.347020359039306 and perplexity is 77.24794851918757
At time: 73.16480016708374 and batch: 1350, loss is 4.3112131690979005 and perplexity is 74.53085264330353
At time: 73.58313751220703 and batch: 1400, loss is 4.1694250631332395 and perplexity is 64.67825550201192
At time: 73.97698783874512 and batch: 1450, loss is 4.2533087682724 and perplexity is 70.337759089573
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.761945153912928 and perplexity of 116.97323569817213
Finished 6 epochs...
Completing Train Step...
At time: 75.26415991783142 and batch: 50, loss is 4.4494764566421505 and perplexity is 85.58212631743956
At time: 75.69527173042297 and batch: 100, loss is 4.460003585815429 and perplexity is 86.48781922513
At time: 76.08673548698425 and batch: 150, loss is 4.330537042617798 and perplexity is 75.98508284134111
At time: 76.49092817306519 and batch: 200, loss is 4.418589534759522 and perplexity is 82.97916355376707
At time: 76.88433074951172 and batch: 250, loss is 4.4543537902832036 and perplexity is 86.00055848836726
At time: 77.26436924934387 and batch: 300, loss is 4.460741567611694 and perplexity is 86.55166921848536
At time: 77.65433979034424 and batch: 350, loss is 4.455682363510132 and perplexity is 86.11489246158601
At time: 78.05890607833862 and batch: 400, loss is 4.304552655220032 and perplexity is 74.03608838612206
At time: 78.46714687347412 and batch: 450, loss is 4.361581220626831 and perplexity is 78.38097410135495
At time: 78.86968064308167 and batch: 500, loss is 4.352904720306396 and perplexity is 77.70384336492941
At time: 79.26118540763855 and batch: 550, loss is 4.403117837905884 and perplexity is 81.70521557093096
At time: 79.64877152442932 and batch: 600, loss is 4.327553243637085 and perplexity is 75.75869654217486
At time: 80.03106760978699 and batch: 650, loss is 4.408694767951966 and perplexity is 82.16215281177364
At time: 80.40773057937622 and batch: 700, loss is 4.447918672561645 and perplexity is 85.44891163028515
At time: 80.79547595977783 and batch: 750, loss is 4.409726896286011 and perplexity is 82.24699847595173
At time: 81.19294595718384 and batch: 800, loss is 4.3318802881240845 and perplexity is 76.0872180433812
At time: 81.58571243286133 and batch: 850, loss is 4.292603940963745 and perplexity is 73.15671646567667
At time: 81.97657346725464 and batch: 900, loss is 4.210168943405152 and perplexity is 67.36792021460641
At time: 82.37090539932251 and batch: 950, loss is 4.332444324493408 and perplexity is 76.13014610695478
At time: 82.77792739868164 and batch: 1000, loss is 4.355619764328003 and perplexity is 77.91509937522491
At time: 83.18577218055725 and batch: 1050, loss is 4.264476804733277 and perplexity is 71.12769656251345
At time: 83.57687592506409 and batch: 1100, loss is 4.388708839416504 and perplexity is 80.53636643877847
At time: 83.9710054397583 and batch: 1150, loss is 4.327728743553162 and perplexity is 75.77199335382066
At time: 84.36292695999146 and batch: 1200, loss is 4.268829960823059 and perplexity is 71.43800144071972
At time: 84.73877954483032 and batch: 1250, loss is 4.229177680015564 and perplexity is 68.66074784783275
At time: 85.12425899505615 and batch: 1300, loss is 4.307988662719726 and perplexity is 74.29091448254451
At time: 85.53252840042114 and batch: 1350, loss is 4.27502986907959 and perplexity is 71.88228633532567
At time: 85.94255590438843 and batch: 1400, loss is 4.136183471679687 and perplexity is 62.56358951066493
At time: 86.33656620979309 and batch: 1450, loss is 4.2189494371414185 and perplexity is 67.96204836821832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7575866177550745 and perplexity of 116.46451306921007
Finished 7 epochs...
Completing Train Step...
At time: 87.63668203353882 and batch: 50, loss is 4.401840705871582 and perplexity is 81.60093382770737
At time: 88.03394412994385 and batch: 100, loss is 4.4165911293029785 and perplexity is 82.81350312402729
At time: 88.44722366333008 and batch: 150, loss is 4.286805863380432 and perplexity is 72.73377545512258
At time: 88.85108351707458 and batch: 200, loss is 4.376490135192871 and perplexity is 79.55830389491634
At time: 89.24763560295105 and batch: 250, loss is 4.410375232696533 and perplexity is 82.30033948931201
At time: 89.64918160438538 and batch: 300, loss is 4.419979257583618 and perplexity is 83.09456175846896
At time: 90.04038000106812 and batch: 350, loss is 4.410656719207764 and perplexity is 82.32350918557344
At time: 90.43438291549683 and batch: 400, loss is 4.262346639633178 and perplexity is 70.97634408575895
At time: 90.82856702804565 and batch: 450, loss is 4.317313919067383 and perplexity is 74.98693655265357
At time: 91.21949648857117 and batch: 500, loss is 4.3135503482818605 and perplexity is 74.70524831824987
At time: 91.61928749084473 and batch: 550, loss is 4.359305143356323 and perplexity is 78.20277582122024
At time: 92.01694822311401 and batch: 600, loss is 4.287738695144653 and perplexity is 72.80165548660129
At time: 92.42155885696411 and batch: 650, loss is 4.369529762268066 and perplexity is 79.0064711393038
At time: 92.80265855789185 and batch: 700, loss is 4.410069885253907 and perplexity is 82.27521312745203
At time: 93.19758129119873 and batch: 750, loss is 4.36960696220398 and perplexity is 79.01257066925112
At time: 93.59128546714783 and batch: 800, loss is 4.294768533706665 and perplexity is 73.31524247345986
At time: 93.9788453578949 and batch: 850, loss is 4.259462943077088 and perplexity is 70.77196467248993
At time: 94.37042880058289 and batch: 900, loss is 4.173001661300659 and perplexity is 64.90999780963037
At time: 94.75451970100403 and batch: 950, loss is 4.298544006347656 and perplexity is 73.59256534863226
At time: 95.146901845932 and batch: 1000, loss is 4.319248008728027 and perplexity is 75.13210835370948
At time: 95.54618668556213 and batch: 1050, loss is 4.23274836063385 and perplexity is 68.90635167487342
At time: 95.93461680412292 and batch: 1100, loss is 4.35422303199768 and perplexity is 77.8063488023076
At time: 96.33557176589966 and batch: 1150, loss is 4.292971134185791 and perplexity is 73.18358404860531
At time: 96.73020458221436 and batch: 1200, loss is 4.236677093505859 and perplexity is 69.17759880365416
At time: 97.1357147693634 and batch: 1250, loss is 4.196504998207092 and perplexity is 66.45366900831645
At time: 97.52995944023132 and batch: 1300, loss is 4.273165454864502 and perplexity is 71.74839283412751
At time: 97.92733573913574 and batch: 1350, loss is 4.241371064186096 and perplexity is 69.50307972550013
At time: 98.3242518901825 and batch: 1400, loss is 4.107163934707642 and perplexity is 60.77411357303352
At time: 98.71690058708191 and batch: 1450, loss is 4.190931506156922 and perplexity is 66.08432024969349
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.755847376635951 and perplexity of 116.26212924731075
Finished 8 epochs...
Completing Train Step...
At time: 99.98943495750427 and batch: 50, loss is 4.361694445610047 and perplexity is 78.38984928826898
At time: 100.38695335388184 and batch: 100, loss is 4.378334984779358 and perplexity is 79.70521246940339
At time: 100.7802402973175 and batch: 150, loss is 4.2486576032638546 and perplexity is 70.01136620770536
At time: 101.1801507472992 and batch: 200, loss is 4.336211080551148 and perplexity is 76.41745055917231
At time: 101.56971406936646 and batch: 250, loss is 4.369661531448364 and perplexity is 79.01688244317347
At time: 101.97075033187866 and batch: 300, loss is 4.380860671997071 and perplexity is 79.90677734348529
At time: 102.37173891067505 and batch: 350, loss is 4.37141939163208 and perplexity is 79.15590523017342
At time: 102.77679133415222 and batch: 400, loss is 4.224095954895019 and perplexity is 68.31271784605862
At time: 103.17447686195374 and batch: 450, loss is 4.276776738166809 and perplexity is 72.00796501938801
At time: 103.57315468788147 and batch: 500, loss is 4.2754165554046635 and perplexity is 71.91008760730602
At time: 103.97640585899353 and batch: 550, loss is 4.31875060081482 and perplexity is 75.09474634132903
At time: 104.36973118782043 and batch: 600, loss is 4.251021804809571 and perplexity is 70.1770830046763
At time: 104.76934242248535 and batch: 650, loss is 4.331989660263061 and perplexity is 76.0955403202717
At time: 105.16234588623047 and batch: 700, loss is 4.376164426803589 and perplexity is 79.53239530745194
At time: 105.55918884277344 and batch: 750, loss is 4.33623360157013 and perplexity is 76.41917157740639
At time: 105.97471237182617 and batch: 800, loss is 4.261493453979492 and perplexity is 70.91581391264333
At time: 106.3733172416687 and batch: 850, loss is 4.226990418434143 and perplexity is 68.51073295262938
At time: 106.76550674438477 and batch: 900, loss is 4.139956073760986 and perplexity is 62.80006281804456
At time: 107.16532135009766 and batch: 950, loss is 4.2678373384475705 and perplexity is 71.36712566428977
At time: 107.56393766403198 and batch: 1000, loss is 4.287745532989502 and perplexity is 72.80215329472819
At time: 107.960533618927 and batch: 1050, loss is 4.2015561723709105 and perplexity is 66.790187254935
At time: 108.34967565536499 and batch: 1100, loss is 4.324516267776489 and perplexity is 75.52896822579135
At time: 108.7514545917511 and batch: 1150, loss is 4.259580702781677 and perplexity is 70.78029924887197
At time: 109.15037155151367 and batch: 1200, loss is 4.206917071342469 and perplexity is 67.14920416797781
At time: 109.54849457740784 and batch: 1250, loss is 4.167678637504578 and perplexity is 64.56539831601162
At time: 109.94509077072144 and batch: 1300, loss is 4.2444514513015745 and perplexity is 69.71750620550185
At time: 110.34546518325806 and batch: 1350, loss is 4.215600476264954 and perplexity is 67.73482681755813
At time: 110.73520255088806 and batch: 1400, loss is 4.0820044946670535 and perplexity is 59.26414553142555
At time: 111.11659240722656 and batch: 1450, loss is 4.165043997764587 and perplexity is 64.39551563987239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.755878155048077 and perplexity of 116.26570766610807
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 112.39105486869812 and batch: 50, loss is 4.335093340873718 and perplexity is 76.33208346061865
At time: 112.80606961250305 and batch: 100, loss is 4.3461452293396 and perplexity is 77.18037611681765
At time: 113.1974823474884 and batch: 150, loss is 4.213078756332397 and perplexity is 67.56423373902837
At time: 113.59657573699951 and batch: 200, loss is 4.292312154769897 and perplexity is 73.13537345977342
At time: 113.98525285720825 and batch: 250, loss is 4.321233325004577 and perplexity is 75.28141751522834
At time: 114.38545966148376 and batch: 300, loss is 4.32909264087677 and perplexity is 75.87540908094579
At time: 114.78500580787659 and batch: 350, loss is 4.310682888031006 and perplexity is 74.49134082035899
At time: 115.18670463562012 and batch: 400, loss is 4.163162593841553 and perplexity is 64.27447556246354
At time: 115.57904195785522 and batch: 450, loss is 4.219513363838196 and perplexity is 68.00038479011077
At time: 115.97921824455261 and batch: 500, loss is 4.202830109596253 and perplexity is 66.87532798122226
At time: 116.38114023208618 and batch: 550, loss is 4.247553653717041 and perplexity is 69.93411983760127
At time: 116.77236676216125 and batch: 600, loss is 4.176220335960388 and perplexity is 65.11925856522954
At time: 117.16380524635315 and batch: 650, loss is 4.252617435455322 and perplexity is 70.2891490932136
At time: 117.5636944770813 and batch: 700, loss is 4.296810045242309 and perplexity is 73.46506927123903
At time: 117.96252369880676 and batch: 750, loss is 4.249838109016419 and perplexity is 70.09406383116463
At time: 118.34846591949463 and batch: 800, loss is 4.171493253707886 and perplexity is 64.8121608836191
At time: 118.74343037605286 and batch: 850, loss is 4.125631995201111 and perplexity is 61.90692176707696
At time: 119.1347234249115 and batch: 900, loss is 4.036146230697632 and perplexity is 56.60776862774117
At time: 119.53934812545776 and batch: 950, loss is 4.160952711105347 and perplexity is 64.1325933378199
At time: 119.93791341781616 and batch: 1000, loss is 4.185609278678894 and perplexity is 65.73353876205232
At time: 120.33280324935913 and batch: 1050, loss is 4.089402384757996 and perplexity is 59.70420090005363
At time: 120.70828199386597 and batch: 1100, loss is 4.208496913909912 and perplexity is 67.25537318217407
At time: 121.0932126045227 and batch: 1150, loss is 4.132222375869751 and perplexity is 62.31625931109817
At time: 121.4870810508728 and batch: 1200, loss is 4.079700536727906 and perplexity is 59.1277606057179
At time: 121.88075256347656 and batch: 1250, loss is 4.0375461435318 and perplexity is 56.68707006415508
At time: 122.27439165115356 and batch: 1300, loss is 4.102397022247314 and perplexity is 60.485098096799916
At time: 122.66655087471008 and batch: 1350, loss is 4.0669080257415775 and perplexity is 58.37618559384265
At time: 123.06318473815918 and batch: 1400, loss is 3.9296499729156493 and perplexity is 50.88916196640592
At time: 123.43947243690491 and batch: 1450, loss is 4.007434134483337 and perplexity is 55.00555248905274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.70341296073718 and perplexity of 110.32305891286278
Finished 10 epochs...
Completing Train Step...
At time: 124.78059101104736 and batch: 50, loss is 4.2836009836196896 and perplexity is 72.50104558507145
At time: 125.19507837295532 and batch: 100, loss is 4.30130711555481 and perplexity is 73.79619083369856
At time: 125.58597302436829 and batch: 150, loss is 4.168292560577393 and perplexity is 64.60504867363265
At time: 125.99302124977112 and batch: 200, loss is 4.25478991985321 and perplexity is 70.44201716458528
At time: 126.39208722114563 and batch: 250, loss is 4.284418601989746 and perplexity is 72.56034801186321
At time: 126.7981584072113 and batch: 300, loss is 4.295267014503479 and perplexity is 73.3517978242599
At time: 127.17773485183716 and batch: 350, loss is 4.277639675140381 and perplexity is 72.07013017324208
At time: 127.56535744667053 and batch: 400, loss is 4.133303761482239 and perplexity is 62.38368366663478
At time: 127.96163845062256 and batch: 450, loss is 4.190049443244934 and perplexity is 66.02605542213675
At time: 128.35695385932922 and batch: 500, loss is 4.174986624717713 and perplexity is 65.03896974061932
At time: 128.74896144866943 and batch: 550, loss is 4.219652886390686 and perplexity is 68.00987303926398
At time: 129.14182472229004 and batch: 600, loss is 4.1514792203903195 and perplexity is 63.52790259878051
At time: 129.52877569198608 and batch: 650, loss is 4.228249087333679 and perplexity is 68.59701957323254
At time: 129.9042353630066 and batch: 700, loss is 4.274000949859619 and perplexity is 71.80836330627426
At time: 130.30068564414978 and batch: 750, loss is 4.2275128698349 and perplexity is 68.54653583284544
At time: 130.70153665542603 and batch: 800, loss is 4.150870709419251 and perplexity is 63.48925693242864
At time: 131.1049826145172 and batch: 850, loss is 4.107839460372925 and perplexity is 60.81518191633515
At time: 131.49709367752075 and batch: 900, loss is 4.019004955291748 and perplexity is 55.645708302276496
At time: 131.87941575050354 and batch: 950, loss is 4.145682616233826 and perplexity is 63.16072172374113
At time: 132.26793670654297 and batch: 1000, loss is 4.1708224010467525 and perplexity is 64.76869605389496
At time: 132.67734932899475 and batch: 1050, loss is 4.075975341796875 and perplexity is 58.90790792291872
At time: 133.0543897151947 and batch: 1100, loss is 4.197228140830994 and perplexity is 66.50174186856326
At time: 133.45120787620544 and batch: 1150, loss is 4.122565016746521 and perplexity is 61.71734543369421
At time: 133.85225582122803 and batch: 1200, loss is 4.071714286804199 and perplexity is 58.65743211233938
At time: 134.25242590904236 and batch: 1250, loss is 4.031778192520141 and perplexity is 56.361042979047724
At time: 134.6521668434143 and batch: 1300, loss is 4.098316059112549 and perplexity is 60.238763624091646
At time: 135.0560965538025 and batch: 1350, loss is 4.0640312194824215 and perplexity is 58.20848994733766
At time: 135.45253443717957 and batch: 1400, loss is 3.929569892883301 and perplexity is 50.88508692383642
At time: 135.84679317474365 and batch: 1450, loss is 4.01069130897522 and perplexity is 55.185007270644796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6986918653178416 and perplexity of 109.80344077332693
Finished 11 epochs...
Completing Train Step...
At time: 137.13858032226562 and batch: 50, loss is 4.266005940437317 and perplexity is 71.23654366265754
At time: 137.540757894516 and batch: 100, loss is 4.2845040130615235 and perplexity is 72.56654573362874
At time: 137.91779112815857 and batch: 150, loss is 4.1508726167678835 and perplexity is 63.48937802869153
At time: 138.30765223503113 and batch: 200, loss is 4.238382821083069 and perplexity is 69.29569763524152
At time: 138.7072787284851 and batch: 250, loss is 4.267465057373047 and perplexity is 71.34056197894729
At time: 139.10316944122314 and batch: 300, loss is 4.2783304214477536 and perplexity is 72.11992954691779
At time: 139.50415706634521 and batch: 350, loss is 4.261457176208496 and perplexity is 70.91324129165096
At time: 139.89902472496033 and batch: 400, loss is 4.118948373794556 and perplexity is 61.4945389798738
At time: 140.29165482521057 and batch: 450, loss is 4.174647312164307 and perplexity is 65.01690494536845
At time: 140.7091088294983 and batch: 500, loss is 4.160640091896057 and perplexity is 64.11254739073823
At time: 141.10116362571716 and batch: 550, loss is 4.205063314437866 and perplexity is 67.02484117210756
At time: 141.51240181922913 and batch: 600, loss is 4.138387088775635 and perplexity is 62.701607719886624
At time: 141.91065430641174 and batch: 650, loss is 4.214599437713623 and perplexity is 67.66705557112057
At time: 142.29836654663086 and batch: 700, loss is 4.2608954000473025 and perplexity is 70.87341511092721
At time: 142.68155646324158 and batch: 750, loss is 4.215407133102417 and perplexity is 67.72173201786312
At time: 143.0783975124359 and batch: 800, loss is 4.1395263624191285 and perplexity is 62.773082716025336
At time: 143.47537660598755 and batch: 850, loss is 4.097271904945374 and perplexity is 60.17589789449649
At time: 143.87326788902283 and batch: 900, loss is 4.009133992195129 and perplexity is 55.099133616409446
At time: 144.2594497203827 and batch: 950, loss is 4.136222848892212 and perplexity is 62.56605313893047
At time: 144.64669394493103 and batch: 1000, loss is 4.162073431015014 and perplexity is 64.20450830277152
At time: 145.0415234565735 and batch: 1050, loss is 4.067436490058899 and perplexity is 58.40704347783748
At time: 145.43271279335022 and batch: 1100, loss is 4.189950089454651 and perplexity is 66.01949580913973
At time: 145.828045129776 and batch: 1150, loss is 4.115671405792236 and perplexity is 61.293353163097855
At time: 146.24350237846375 and batch: 1200, loss is 4.066377348899842 and perplexity is 58.34521492247497
At time: 146.65237665176392 and batch: 1250, loss is 4.026518683433533 and perplexity is 56.06538973836207
At time: 147.0437376499176 and batch: 1300, loss is 4.094605841636658 and perplexity is 60.01567881305978
At time: 147.4387526512146 and batch: 1350, loss is 4.060104513168335 and perplexity is 57.98037047453001
At time: 147.82757019996643 and batch: 1400, loss is 3.927182559967041 and perplexity is 50.7637521717277
At time: 148.21035528182983 and batch: 1450, loss is 4.009698338508606 and perplexity is 55.13023738516476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.696720481937767 and perplexity of 109.58718932240531
Finished 12 epochs...
Completing Train Step...
At time: 149.51654291152954 and batch: 50, loss is 4.25364688873291 and perplexity is 70.36154574621865
At time: 149.91253352165222 and batch: 100, loss is 4.27171905040741 and perplexity is 71.6446906546698
At time: 150.29295682907104 and batch: 150, loss is 4.138228135108948 and perplexity is 62.69164186150824
At time: 150.69398999214172 and batch: 200, loss is 4.2260107326507566 and perplexity is 68.44364682857298
At time: 151.10130906105042 and batch: 250, loss is 4.2546085309982296 and perplexity is 70.42924092651789
At time: 151.502051115036 and batch: 300, loss is 4.2660227346420285 and perplexity is 71.23774003380076
At time: 151.8940727710724 and batch: 350, loss is 4.250351982116699 and perplexity is 70.13009254135649
At time: 152.29640913009644 and batch: 400, loss is 4.108163914680481 and perplexity is 60.83491686544421
At time: 152.69191241264343 and batch: 450, loss is 4.163003950119019 and perplexity is 64.26427962917818
At time: 153.09193325042725 and batch: 500, loss is 4.149678893089295 and perplexity is 63.41363447223262
At time: 153.48588490486145 and batch: 550, loss is 4.194188528060913 and perplexity is 66.2999092266832
At time: 153.89362502098083 and batch: 600, loss is 4.1282321643829345 and perplexity is 62.068099691324264
At time: 154.28873872756958 and batch: 650, loss is 4.204210748672486 and perplexity is 66.96772243929206
At time: 154.68437719345093 and batch: 700, loss is 4.250886106491089 and perplexity is 70.167560738609
At time: 155.0775396823883 and batch: 750, loss is 4.20608314037323 and perplexity is 67.09322970972343
At time: 155.4793677330017 and batch: 800, loss is 4.130722184181213 and perplexity is 62.22284306547653
At time: 155.89394450187683 and batch: 850, loss is 4.0892688226699825 and perplexity is 59.69622721482112
At time: 156.30979824066162 and batch: 900, loss is 4.001312766075134 and perplexity is 54.66987169885749
At time: 156.70276069641113 and batch: 950, loss is 4.129171080589295 and perplexity is 62.12640380307691
At time: 157.09993147850037 and batch: 1000, loss is 4.155065493583679 and perplexity is 63.75614002916988
At time: 157.49295687675476 and batch: 1050, loss is 4.0606198453903195 and perplexity is 58.01025732784596
At time: 157.8729944229126 and batch: 1100, loss is 4.1838208150863645 and perplexity is 65.61608178623892
At time: 158.2710063457489 and batch: 1150, loss is 4.109508905410767 and perplexity is 60.91679431456796
At time: 158.65836763381958 and batch: 1200, loss is 4.0607610702514645 and perplexity is 58.018450396900974
At time: 159.0427963733673 and batch: 1250, loss is 4.021382975578308 and perplexity is 55.778192387968126
At time: 159.43563723564148 and batch: 1300, loss is 4.0903174018859865 and perplexity is 59.75885626797568
At time: 159.828040599823 and batch: 1350, loss is 4.056056804656983 and perplexity is 57.74615716884239
At time: 160.21619749069214 and batch: 1400, loss is 3.924080309867859 and perplexity is 50.60651433816464
At time: 160.6206464767456 and batch: 1450, loss is 4.006813735961914 and perplexity is 54.971437709092186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.695360493456197 and perplexity of 109.43825330578834
Finished 13 epochs...
Completing Train Step...
At time: 161.8710868358612 and batch: 50, loss is 4.242549481391907 and perplexity is 69.58503162778769
At time: 162.28603959083557 and batch: 100, loss is 4.260962867736817 and perplexity is 70.87819693780033
At time: 162.67748141288757 and batch: 150, loss is 4.12750638961792 and perplexity is 62.02306857405682
At time: 163.0768096446991 and batch: 200, loss is 4.2157170820236205 and perplexity is 67.74272554893717
At time: 163.47968101501465 and batch: 250, loss is 4.244202404022217 and perplexity is 69.70014541217668
At time: 163.88366174697876 and batch: 300, loss is 4.256149339675903 and perplexity is 70.53784255778152
At time: 164.27373099327087 and batch: 350, loss is 4.240793209075928 and perplexity is 69.46292861758701
At time: 164.67106342315674 and batch: 400, loss is 4.09904191493988 and perplexity is 60.28250415443837
At time: 165.07813382148743 and batch: 450, loss is 4.15337721824646 and perplexity is 63.648592920472815
At time: 165.4806637763977 and batch: 500, loss is 4.140212726593018 and perplexity is 62.816182700536814
At time: 165.87137484550476 and batch: 550, loss is 4.185177216529846 and perplexity is 65.70514392263966
At time: 166.2813651561737 and batch: 600, loss is 4.118848824501038 and perplexity is 61.488417546660386
At time: 166.69391989707947 and batch: 650, loss is 4.195356216430664 and perplexity is 66.37737207703579
At time: 167.0999104976654 and batch: 700, loss is 4.242463526725769 and perplexity is 69.57905072667275
At time: 167.49045324325562 and batch: 750, loss is 4.1976735353469845 and perplexity is 66.53136797685866
At time: 167.88830995559692 and batch: 800, loss is 4.12304678440094 and perplexity is 61.74708601789127
At time: 168.27934217453003 and batch: 850, loss is 4.081509127616882 and perplexity is 59.23479529664251
At time: 168.6709430217743 and batch: 900, loss is 3.9939186429977416 and perplexity is 54.267126746703156
At time: 169.0799114704132 and batch: 950, loss is 4.122523326873779 and perplexity is 61.714772499050106
At time: 169.48581504821777 and batch: 1000, loss is 4.1486815023422245 and perplexity is 63.35041783105901
At time: 169.8806116580963 and batch: 1050, loss is 4.054349298477173 and perplexity is 57.647639382417246
At time: 170.27459168434143 and batch: 1100, loss is 4.178043856620788 and perplexity is 65.23811321263084
At time: 170.65897822380066 and batch: 1150, loss is 4.104062609672546 and perplexity is 60.58592526052248
At time: 171.04924368858337 and batch: 1200, loss is 4.05573830127716 and perplexity is 57.727767751313635
At time: 171.4402084350586 and batch: 1250, loss is 4.016123809814453 and perplexity is 55.48561565731459
At time: 171.82531547546387 and batch: 1300, loss is 4.085609664916992 and perplexity is 59.47818846456008
At time: 172.2187738418579 and batch: 1350, loss is 4.051455321311951 and perplexity is 57.48104960019565
At time: 172.61642932891846 and batch: 1400, loss is 3.920452284812927 and perplexity is 50.423245289577245
At time: 173.01616382598877 and batch: 1450, loss is 4.003230295181274 and perplexity is 54.774803341656515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.694304637419871 and perplexity of 109.32276324659792
Finished 14 epochs...
Completing Train Step...
At time: 174.28761911392212 and batch: 50, loss is 4.234144473075867 and perplexity is 69.00261987475994
At time: 174.69326972961426 and batch: 100, loss is 4.2518510389328 and perplexity is 70.23530037114993
At time: 175.08410358428955 and batch: 150, loss is 4.118828568458557 and perplexity is 61.48717204727698
At time: 175.48096346855164 and batch: 200, loss is 4.2062200880050655 and perplexity is 67.10241859782826
At time: 175.88526940345764 and batch: 250, loss is 4.2351295757293705 and perplexity is 69.07062803070495
At time: 176.28712725639343 and batch: 300, loss is 4.247482514381408 and perplexity is 69.92914494773522
At time: 176.67820024490356 and batch: 350, loss is 4.2320090675354 and perplexity is 68.85542851053216
At time: 177.08001255989075 and batch: 400, loss is 4.0901546287536625 and perplexity is 59.74912992337211
At time: 177.46624422073364 and batch: 450, loss is 4.14497477054596 and perplexity is 63.11602949869196
At time: 177.8554482460022 and batch: 500, loss is 4.132063574790955 and perplexity is 62.306364207590384
At time: 178.23286724090576 and batch: 550, loss is 4.176920299530029 and perplexity is 65.16485563018773
At time: 178.61036133766174 and batch: 600, loss is 4.111513381004333 and perplexity is 61.03902300329608
At time: 178.99739146232605 and batch: 650, loss is 4.187762603759766 and perplexity is 65.87523694609767
At time: 179.38903260231018 and batch: 700, loss is 4.235074172019958 and perplexity is 69.06680136770726
At time: 179.77585244178772 and batch: 750, loss is 4.1904061460495 and perplexity is 66.04961130225472
At time: 180.16560244560242 and batch: 800, loss is 4.116381406784058 and perplexity is 61.33688695732547
At time: 180.57022285461426 and batch: 850, loss is 4.075127744674683 and perplexity is 58.857998904047264
At time: 180.9618067741394 and batch: 900, loss is 3.9884215879440306 and perplexity is 53.969635774617494
At time: 181.35042095184326 and batch: 950, loss is 4.117180137634278 and perplexity is 61.38589819198166
At time: 181.74373197555542 and batch: 1000, loss is 4.142255053520203 and perplexity is 62.94460497742768
At time: 182.1394715309143 and batch: 1050, loss is 4.048609170913696 and perplexity is 57.31768248195885
At time: 182.52528929710388 and batch: 1100, loss is 4.172917413711548 and perplexity is 64.90452952915365
At time: 182.92663478851318 and batch: 1150, loss is 4.09924774646759 and perplexity is 60.29491347143319
At time: 183.3215401172638 and batch: 1200, loss is 4.05097945690155 and perplexity is 57.45370292159002
At time: 183.70110321044922 and batch: 1250, loss is 4.0115948677062985 and perplexity is 55.234892699602305
At time: 184.0952868461609 and batch: 1300, loss is 4.0815332412719725 and perplexity is 59.23622368128736
At time: 184.49161434173584 and batch: 1350, loss is 4.047546343803406 and perplexity is 57.25679605672114
At time: 184.89118552207947 and batch: 1400, loss is 3.9169353818893433 and perplexity is 50.246223098192736
At time: 185.28962779045105 and batch: 1450, loss is 3.9999104070663454 and perplexity is 54.593258643830886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.693846091245994 and perplexity of 109.27264520339008
Finished 15 epochs...
Completing Train Step...
At time: 186.60892486572266 and batch: 50, loss is 4.226104936599731 and perplexity is 68.45009479409362
At time: 186.9876868724823 and batch: 100, loss is 4.2435698890686036 and perplexity is 69.65607296764391
At time: 187.3893644809723 and batch: 150, loss is 4.111128931045532 and perplexity is 61.015561063677026
At time: 187.78339004516602 and batch: 200, loss is 4.197846364974976 and perplexity is 66.54286756214175
At time: 188.17656540870667 and batch: 250, loss is 4.227227454185486 and perplexity is 68.52697437051214
At time: 188.56541466712952 and batch: 300, loss is 4.2396449279785156 and perplexity is 69.38321142731513
At time: 188.97615599632263 and batch: 350, loss is 4.224023189544678 and perplexity is 68.30774722805833
At time: 189.37356686592102 and batch: 400, loss is 4.082262797355652 and perplexity is 59.279455596784196
At time: 189.7663712501526 and batch: 450, loss is 4.137660608291626 and perplexity is 62.65607276769192
At time: 190.1510410308838 and batch: 500, loss is 4.124864916801453 and perplexity is 61.859452513247355
At time: 190.55092310905457 and batch: 550, loss is 4.169786391258239 and perplexity is 64.70162979744158
At time: 190.95845079421997 and batch: 600, loss is 4.104242649078369 and perplexity is 60.59683409648832
At time: 191.36870336532593 and batch: 650, loss is 4.180333437919617 and perplexity is 65.38765230223893
At time: 191.7684199810028 and batch: 700, loss is 4.227978410720826 and perplexity is 68.57845447700466
At time: 192.16137170791626 and batch: 750, loss is 4.1836701059341435 and perplexity is 65.6061935873206
At time: 192.5476267337799 and batch: 800, loss is 4.110324325561524 and perplexity is 60.966487353770894
At time: 192.94263815879822 and batch: 850, loss is 4.06929340839386 and perplexity is 58.5156013481186
At time: 193.34093832969666 and batch: 900, loss is 3.9820401430130006 and perplexity is 53.626328080583846
At time: 193.7425467967987 and batch: 950, loss is 4.1107807445526126 and perplexity is 60.99431996760271
At time: 194.1239402294159 and batch: 1000, loss is 4.136359362602234 and perplexity is 62.57459484598272
At time: 194.52131915092468 and batch: 1050, loss is 4.0428816604614255 and perplexity is 56.990333199535385
At time: 194.9279670715332 and batch: 1100, loss is 4.167955145835877 and perplexity is 64.58325365502088
At time: 195.32871007919312 and batch: 1150, loss is 4.094497833251953 and perplexity is 60.00919696658742
At time: 195.72116947174072 and batch: 1200, loss is 4.046806120872498 and perplexity is 57.21442894581766
At time: 196.12173557281494 and batch: 1250, loss is 4.0068483781814574 and perplexity is 54.97334207469147
At time: 196.51956510543823 and batch: 1300, loss is 4.07678373336792 and perplexity is 58.95554783240777
At time: 196.92164731025696 and batch: 1350, loss is 4.043359980583191 and perplexity is 57.01759934310356
At time: 197.31457233428955 and batch: 1400, loss is 3.9127048015594483 and perplexity is 50.03410143035577
At time: 197.7205936908722 and batch: 1450, loss is 3.9954694509506226 and perplexity is 54.35134992855229
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6931987012553416 and perplexity of 109.20192608052943
Finished 16 epochs...
Completing Train Step...
At time: 199.04188299179077 and batch: 50, loss is 4.218388133049011 and perplexity is 67.92391169647709
At time: 199.43432331085205 and batch: 100, loss is 4.2355523729324345 and perplexity is 69.09983707336586
At time: 199.82577276229858 and batch: 150, loss is 4.103555474281311 and perplexity is 60.55520778323043
At time: 200.2064528465271 and batch: 200, loss is 4.189988303184509 and perplexity is 66.02201870852231
At time: 200.60288763046265 and batch: 250, loss is 4.219498143196106 and perplexity is 67.99934978846863
At time: 200.99803924560547 and batch: 300, loss is 4.231870365142822 and perplexity is 68.84587876015772
At time: 201.40014386177063 and batch: 350, loss is 4.216362614631652 and perplexity is 67.78646980488872
At time: 201.7995593547821 and batch: 400, loss is 4.075098557472229 and perplexity is 58.85628102878732
At time: 202.18726706504822 and batch: 450, loss is 4.130471420288086 and perplexity is 62.2072417793094
At time: 202.5857493877411 and batch: 500, loss is 4.11713870048523 and perplexity is 61.38335458806905
At time: 202.97571682929993 and batch: 550, loss is 4.162837028503418 and perplexity is 64.25355342703946
At time: 203.36769366264343 and batch: 600, loss is 4.0969362592697145 and perplexity is 60.15570350385881
At time: 203.7588438987732 and batch: 650, loss is 4.173255443572998 and perplexity is 64.92647290682741
At time: 204.1627848148346 and batch: 700, loss is 4.221013150215149 and perplexity is 68.10244735773952
At time: 204.5586438179016 and batch: 750, loss is 4.177056221961975 and perplexity is 65.17371359782702
At time: 204.95197868347168 and batch: 800, loss is 4.10396514415741 and perplexity is 60.58002050986643
At time: 205.35485792160034 and batch: 850, loss is 4.0633134841918945 and perplexity is 58.16672664918348
At time: 205.74925756454468 and batch: 900, loss is 3.9761706447601317 and perplexity is 53.312490377533585
At time: 206.13986778259277 and batch: 950, loss is 4.1047971820831295 and perplexity is 60.630446359672135
At time: 206.5445954799652 and batch: 1000, loss is 4.131009979248047 and perplexity is 62.240753069836984
At time: 206.9311990737915 and batch: 1050, loss is 4.037015037536621 and perplexity is 56.65697121494204
At time: 207.32518982887268 and batch: 1100, loss is 4.163074169158936 and perplexity is 64.26879236363278
At time: 207.72835159301758 and batch: 1150, loss is 4.089358582496643 and perplexity is 59.70158577831646
At time: 208.11845517158508 and batch: 1200, loss is 4.041428923606873 and perplexity is 56.90760135049632
At time: 208.51493382453918 and batch: 1250, loss is 4.002515377998352 and perplexity is 54.73565788810238
At time: 208.91661429405212 and batch: 1300, loss is 4.071869263648987 and perplexity is 58.66652336053977
At time: 209.32059836387634 and batch: 1350, loss is 4.038767037391662 and perplexity is 56.756321225486786
At time: 209.71764135360718 and batch: 1400, loss is 3.9086982297897337 and perplexity is 49.83403726538899
At time: 210.11065006256104 and batch: 1450, loss is 3.9914701890945437 and perplexity is 54.134418719446415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6929383889222755 and perplexity of 109.17350317195343
Finished 17 epochs...
Completing Train Step...
At time: 211.38693237304688 and batch: 50, loss is 4.209442892074585 and perplexity is 67.31902539871807
At time: 211.79602074623108 and batch: 100, loss is 4.2278817987442014 and perplexity is 68.57182929700483
At time: 212.19098353385925 and batch: 150, loss is 4.096124320030213 and perplexity is 60.10688055102198
At time: 212.5838804244995 and batch: 200, loss is 4.182377924919129 and perplexity is 65.52147325828841
At time: 212.97625708580017 and batch: 250, loss is 4.211844367980957 and perplexity is 67.48088468905848
At time: 213.38171792030334 and batch: 300, loss is 4.224239120483398 and perplexity is 68.32249857661813
At time: 213.7748727798462 and batch: 350, loss is 4.209375867843628 and perplexity is 67.31451354401541
At time: 214.1746368408203 and batch: 400, loss is 4.068092498779297 and perplexity is 58.445371578101074
At time: 214.5519380569458 and batch: 450, loss is 4.124326810836792 and perplexity is 61.826174527223706
At time: 214.9522361755371 and batch: 500, loss is 4.111418938636779 and perplexity is 61.03325860565643
At time: 215.3552474975586 and batch: 550, loss is 4.156068668365479 and perplexity is 63.82013067256542
At time: 215.7508020401001 and batch: 600, loss is 4.0906096458435055 and perplexity is 59.77632298477515
At time: 216.13699769973755 and batch: 650, loss is 4.166768789291382 and perplexity is 64.50668032000209
At time: 216.54692673683167 and batch: 700, loss is 4.21512725353241 and perplexity is 67.70278074078718
At time: 216.93947529792786 and batch: 750, loss is 4.170735220909119 and perplexity is 64.76304975618473
At time: 217.33516693115234 and batch: 800, loss is 4.098132925033569 and perplexity is 60.227732863681375
At time: 217.71277928352356 and batch: 850, loss is 4.057999119758606 and perplexity is 57.8584273987579
At time: 218.11694312095642 and batch: 900, loss is 3.9706963443756105 and perplexity is 53.021439168682996
At time: 218.51618599891663 and batch: 950, loss is 4.098919849395752 and perplexity is 60.275146186853675
At time: 218.89447164535522 and batch: 1000, loss is 4.124874348640442 and perplexity is 61.8600359643949
At time: 219.27415251731873 and batch: 1050, loss is 4.0309040021896365 and perplexity is 56.31179422978484
At time: 219.66920709609985 and batch: 1100, loss is 4.158131303787232 and perplexity is 63.951904188353396
At time: 220.0632288455963 and batch: 1150, loss is 4.0843748331069945 and perplexity is 59.40478823324001
At time: 220.45535254478455 and batch: 1200, loss is 4.036305480003357 and perplexity is 56.61678409342802
At time: 220.84197735786438 and batch: 1250, loss is 3.997705326080322 and perplexity is 54.47300871636972
At time: 221.22776770591736 and batch: 1300, loss is 4.067089838981628 and perplexity is 58.38680012218893
At time: 221.6059651374817 and batch: 1350, loss is 4.033594493865967 and perplexity is 56.46350463972079
At time: 222.00135231018066 and batch: 1400, loss is 3.904664363861084 and perplexity is 49.633418347326604
At time: 222.40209531784058 and batch: 1450, loss is 3.987190146446228 and perplexity is 53.903216229788704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6910869891826925 and perplexity of 108.97156636716664
Finished 18 epochs...
Completing Train Step...
At time: 223.67866683006287 and batch: 50, loss is 4.202634749412536 and perplexity is 66.8622644809472
At time: 224.09551858901978 and batch: 100, loss is 4.220641040802002 and perplexity is 68.07711051035145
At time: 224.47345662117004 and batch: 150, loss is 4.089038982391357 and perplexity is 59.68250819397736
At time: 224.85161519050598 and batch: 200, loss is 4.175249028205871 and perplexity is 65.0560384324897
At time: 225.2474946975708 and batch: 250, loss is 4.204483790397644 and perplexity is 66.98600991826561
At time: 225.6477530002594 and batch: 300, loss is 4.2173117685318 and perplexity is 67.85084014092642
At time: 226.05478405952454 and batch: 350, loss is 4.202512378692627 and perplexity is 66.8540829981051
At time: 226.45324635505676 and batch: 400, loss is 4.0614234066009525 and perplexity is 58.056890854390666
At time: 226.87773990631104 and batch: 450, loss is 4.118327631950378 and perplexity is 61.45637859144085
At time: 227.2746183872223 and batch: 500, loss is 4.1048583936691285 and perplexity is 60.6341577590428
At time: 227.68335008621216 and batch: 550, loss is 4.15045476436615 and perplexity is 63.46285438146843
At time: 228.07286930084229 and batch: 600, loss is 4.084759292602539 and perplexity is 59.42763135900401
At time: 228.47059535980225 and batch: 650, loss is 4.160808482170105 and perplexity is 64.12334422917905
At time: 228.86995935440063 and batch: 700, loss is 4.209162659645081 and perplexity is 67.30016306772059
At time: 229.26807951927185 and batch: 750, loss is 4.1647534894943234 and perplexity is 64.37681092707953
At time: 229.6531913280487 and batch: 800, loss is 4.0926442718505855 and perplexity is 59.89806925819522
At time: 230.03553557395935 and batch: 850, loss is 4.0528275537490845 and perplexity is 57.55998110477715
At time: 230.42597436904907 and batch: 900, loss is 3.9644209241867063 and perplexity is 52.68974919437974
At time: 230.81798934936523 and batch: 950, loss is 4.092982482910156 and perplexity is 59.91833087382339
At time: 231.2098581790924 and batch: 1000, loss is 4.119103746414185 and perplexity is 61.50409428978552
At time: 231.59320044517517 and batch: 1050, loss is 4.024535307884216 and perplexity is 55.95430121673734
At time: 231.97220730781555 and batch: 1100, loss is 4.1537125873565675 and perplexity is 63.66994227219659
At time: 232.36861515045166 and batch: 1150, loss is 4.0797775363922115 and perplexity is 59.132313598722924
At time: 232.75234818458557 and batch: 1200, loss is 4.031739974021912 and perplexity is 56.358888985787885
At time: 233.13800072669983 and batch: 1250, loss is 3.993704023361206 and perplexity is 54.25548120541057
At time: 233.52940130233765 and batch: 1300, loss is 4.062469592094422 and perplexity is 58.11766091423322
At time: 233.92303776741028 and batch: 1350, loss is 4.028791618347168 and perplexity is 56.1929676533688
At time: 234.31709218025208 and batch: 1400, loss is 3.9006046295166015 and perplexity is 49.43232831646795
At time: 234.71572065353394 and batch: 1450, loss is 3.9829001426696777 and perplexity is 53.672466541008404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.691132895966881 and perplexity of 108.9765690161734
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 235.99688386917114 and batch: 50, loss is 4.197846765518189 and perplexity is 66.54289421544105
At time: 236.39728665351868 and batch: 100, loss is 4.217593111991882 and perplexity is 67.86993221665058
At time: 236.81794691085815 and batch: 150, loss is 4.0835063123703 and perplexity is 59.353216341670986
At time: 237.21505880355835 and batch: 200, loss is 4.170726146697998 and perplexity is 64.76246208526472
At time: 237.60052943229675 and batch: 250, loss is 4.198706026077271 and perplexity is 66.60009647222962
At time: 237.9838764667511 and batch: 300, loss is 4.210464305877686 and perplexity is 67.38782110893449
At time: 238.36358404159546 and batch: 350, loss is 4.193581495285034 and perplexity is 66.2596752216602
At time: 238.7461838722229 and batch: 400, loss is 4.051837453842163 and perplexity is 57.503019176496146
At time: 239.13885927200317 and batch: 450, loss is 4.109532132148742 and perplexity is 60.91820922941968
At time: 239.5531132221222 and batch: 500, loss is 4.090328211784363 and perplexity is 59.75950225863057
At time: 239.94700503349304 and batch: 550, loss is 4.134966721534729 and perplexity is 62.48751154738116
At time: 240.32882237434387 and batch: 600, loss is 4.070205659866333 and perplexity is 58.56900664743884
At time: 240.7171733379364 and batch: 650, loss is 4.146241154670715 and perplexity is 63.19600926833316
At time: 241.1146204471588 and batch: 700, loss is 4.193047122955322 and perplexity is 66.22427734331173
At time: 241.51940417289734 and batch: 750, loss is 4.148732733726502 and perplexity is 63.35366344379694
At time: 241.9112033843994 and batch: 800, loss is 4.073126602172851 and perplexity is 58.740333432822
At time: 242.30361151695251 and batch: 850, loss is 4.032302346229553 and perplexity is 56.39059257237946
At time: 242.70226335525513 and batch: 900, loss is 3.944632062911987 and perplexity is 51.65732796822585
At time: 243.0911877155304 and batch: 950, loss is 4.069250679016113 and perplexity is 58.51310106630262
At time: 243.48441314697266 and batch: 1000, loss is 4.096309218406677 and perplexity is 60.117995243162824
At time: 243.88054943084717 and batch: 1050, loss is 4.001952023506164 and perplexity is 54.70483099339834
At time: 244.25848364830017 and batch: 1100, loss is 4.13033748626709 and perplexity is 62.19891067120465
At time: 244.65550184249878 and batch: 1150, loss is 4.051513619422913 and perplexity is 57.48440073448489
At time: 245.05320596694946 and batch: 1200, loss is 4.005561590194702 and perplexity is 54.90264853207333
At time: 245.45065450668335 and batch: 1250, loss is 3.963481936454773 and perplexity is 52.64029738724116
At time: 245.86159586906433 and batch: 1300, loss is 4.030866956710815 and perplexity is 56.309708171044065
At time: 246.26312804222107 and batch: 1350, loss is 3.99606969833374 and perplexity is 54.38398397738718
At time: 246.65646362304688 and batch: 1400, loss is 3.8652647829055784 and perplexity is 47.715905116154545
At time: 247.0452790260315 and batch: 1450, loss is 3.9463748598098753 and perplexity is 51.74743469521714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.684595874232104 and perplexity of 108.26651017951379
Finished 20 epochs...
Completing Train Step...
At time: 248.32065844535828 and batch: 50, loss is 4.190254411697388 and perplexity is 66.0395900675785
At time: 248.7009036540985 and batch: 100, loss is 4.2099371337890625 and perplexity is 67.352305492776
At time: 249.11082339286804 and batch: 150, loss is 4.077109713554382 and perplexity is 58.97476930562264
At time: 249.50388741493225 and batch: 200, loss is 4.163813948631287 and perplexity is 64.3163546875825
At time: 249.90224194526672 and batch: 250, loss is 4.1916998815536495 and perplexity is 66.13511732859645
At time: 250.29673719406128 and batch: 300, loss is 4.204875645637512 and perplexity is 67.01226388079037
At time: 250.69112277030945 and batch: 350, loss is 4.188473162651062 and perplexity is 65.92206181536939
At time: 251.08228611946106 and batch: 400, loss is 4.046135339736939 and perplexity is 57.176063455061275
At time: 251.45995116233826 and batch: 450, loss is 4.104194502830506 and perplexity is 60.593916656526645
At time: 251.83906292915344 and batch: 500, loss is 4.085908756256104 and perplexity is 59.495980536190494
At time: 252.23362803459167 and batch: 550, loss is 4.130633420944214 and perplexity is 62.21732020962768
At time: 252.63966584205627 and batch: 600, loss is 4.066173567771911 and perplexity is 58.333326480129976
At time: 253.04737329483032 and batch: 650, loss is 4.142762198448181 and perplexity is 62.97653511050371
At time: 253.4379699230194 and batch: 700, loss is 4.189237904548645 and perplexity is 65.97249445953481
At time: 253.8334503173828 and batch: 750, loss is 4.1448973321914675 and perplexity is 63.11114208646451
At time: 254.22425985336304 and batch: 800, loss is 4.0700147914886475 and perplexity is 58.557828742945595
At time: 254.60433340072632 and batch: 850, loss is 4.029206132888794 and perplexity is 56.21626528386793
At time: 255.0008008480072 and batch: 900, loss is 3.942297077178955 and perplexity is 51.5368495568383
At time: 255.39367055892944 and batch: 950, loss is 4.066880168914795 and perplexity is 58.37455944120219
At time: 255.7953119277954 and batch: 1000, loss is 4.093868060111999 and perplexity is 59.971416683939964
At time: 256.1862916946411 and batch: 1050, loss is 4.001099538803101 and perplexity is 54.65821583397101
At time: 256.59133887290955 and batch: 1100, loss is 4.129346852302551 and perplexity is 62.13732482728729
At time: 256.9825630187988 and batch: 1150, loss is 4.050456166267395 and perplexity is 57.423645801944105
At time: 257.3759787082672 and batch: 1200, loss is 4.004671130180359 and perplexity is 54.85378167909224
At time: 257.77377104759216 and batch: 1250, loss is 3.9635584354400635 and perplexity is 52.6443244706086
At time: 258.17157912254333 and batch: 1300, loss is 4.030962285995483 and perplexity is 56.3150763911141
At time: 258.5588116645813 and batch: 1350, loss is 3.9966934537887573 and perplexity is 54.41791686587061
At time: 258.96165204048157 and batch: 1400, loss is 3.866235384941101 and perplexity is 47.76224075388161
At time: 259.3533797264099 and batch: 1450, loss is 3.948109359741211 and perplexity is 51.83726850298749
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.683683998564369 and perplexity of 108.16782958230611
Finished 21 epochs...
Completing Train Step...
At time: 260.70894956588745 and batch: 50, loss is 4.187396392822266 and perplexity is 65.85111713055728
At time: 261.12317514419556 and batch: 100, loss is 4.20648717880249 and perplexity is 67.12034342999297
At time: 261.5149459838867 and batch: 150, loss is 4.074112639427185 and perplexity is 58.798282155023074
At time: 261.9085087776184 and batch: 200, loss is 4.160711445808411 and perplexity is 64.1171222350401
At time: 262.31339144706726 and batch: 250, loss is 4.1885843849182125 and perplexity is 65.92939422429576
At time: 262.72150325775146 and batch: 300, loss is 4.201972298622131 and perplexity is 66.81798618870764
At time: 263.1170861721039 and batch: 350, loss is 4.185543651580811 and perplexity is 65.72922500220795
At time: 263.5136790275574 and batch: 400, loss is 4.0435730791091915 and perplexity is 57.0297510041842
At time: 263.90442538261414 and batch: 450, loss is 4.1015157127380375 and perplexity is 60.43181548736162
At time: 264.30790853500366 and batch: 500, loss is 4.083508701324463 and perplexity is 59.35335813395359
At time: 264.6879789829254 and batch: 550, loss is 4.128014750480652 and perplexity is 62.05460669039927
At time: 265.0893852710724 and batch: 600, loss is 4.063910217285156 and perplexity is 58.20144701826806
At time: 265.4981164932251 and batch: 650, loss is 4.140762128829956 and perplexity is 62.850703533871624
At time: 265.8908922672272 and batch: 700, loss is 4.187218489646912 and perplexity is 65.83940304973615
At time: 266.29247856140137 and batch: 750, loss is 4.142880730628967 and perplexity is 62.98400029897251
At time: 266.7324204444885 and batch: 800, loss is 4.067983193397522 and perplexity is 58.438983533577925
At time: 267.1307883262634 and batch: 850, loss is 4.027682089805603 and perplexity is 56.130654527410606
At time: 267.520384311676 and batch: 900, loss is 3.9410105657577517 and perplexity is 51.47058944260643
At time: 267.913281917572 and batch: 950, loss is 4.065800757408142 and perplexity is 58.311583264764884
At time: 268.3235077857971 and batch: 1000, loss is 4.092659149169922 and perplexity is 59.89896038752801
At time: 268.7175352573395 and batch: 1050, loss is 4.000839004516601 and perplexity is 54.64397734959461
At time: 269.1117537021637 and batch: 1100, loss is 4.128861646652222 and perplexity is 62.107182759326946
At time: 269.50754141807556 and batch: 1150, loss is 4.049738111495972 and perplexity is 57.38242727943293
At time: 269.91224670410156 and batch: 1200, loss is 4.004352116584778 and perplexity is 54.836285367896544
At time: 270.30250310897827 and batch: 1250, loss is 3.9635820102691652 and perplexity is 52.64556556619042
At time: 270.694851398468 and batch: 1300, loss is 4.031004238128662 and perplexity is 56.31743897825628
At time: 271.093875169754 and batch: 1350, loss is 3.9970568084716795 and perplexity is 54.437693463540796
At time: 271.50619435310364 and batch: 1400, loss is 3.8666333627700804 and perplexity is 47.78125284970942
At time: 271.90624165534973 and batch: 1450, loss is 3.9488434982299805 and perplexity is 51.87533820945676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6832864875467415 and perplexity of 108.12484022323228
Finished 22 epochs...
Completing Train Step...
At time: 273.13727951049805 and batch: 50, loss is 4.185323028564453 and perplexity is 65.71472522187659
At time: 273.5508852005005 and batch: 100, loss is 4.204013938903809 and perplexity is 66.95454383421162
At time: 273.94894003868103 and batch: 150, loss is 4.0718448448181155 and perplexity is 58.66509081011871
At time: 274.34960436820984 and batch: 200, loss is 4.15837550163269 and perplexity is 63.967523012533164
At time: 274.75070548057556 and batch: 250, loss is 4.186218371391297 and perplexity is 65.77358877732077
At time: 275.1510512828827 and batch: 300, loss is 4.199755649566651 and perplexity is 66.67003819769954
At time: 275.5435404777527 and batch: 350, loss is 4.18338182926178 and perplexity is 65.58728357793507
At time: 275.93989300727844 and batch: 400, loss is 4.041735439300537 and perplexity is 56.92504709696002
At time: 276.3296880722046 and batch: 450, loss is 4.099575805664062 and perplexity is 60.31469701720763
At time: 276.7129476070404 and batch: 500, loss is 4.081698136329651 and perplexity is 59.24599224717993
At time: 277.1175000667572 and batch: 550, loss is 4.126038513183594 and perplexity is 61.9320931599807
At time: 277.50543189048767 and batch: 600, loss is 4.062148299217224 and perplexity is 58.09899112313814
At time: 277.913565158844 and batch: 650, loss is 4.1392343759536745 and perplexity is 62.75475650111099
At time: 278.30658769607544 and batch: 700, loss is 4.18569655418396 and perplexity is 65.7392759402015
At time: 278.7026216983795 and batch: 750, loss is 4.141314539909363 and perplexity is 62.88543255031583
At time: 279.11279797554016 and batch: 800, loss is 4.066352410316467 and perplexity is 58.34375989361139
At time: 279.51169443130493 and batch: 850, loss is 4.026481366157531 and perplexity is 56.06329756977632
At time: 279.9127838611603 and batch: 900, loss is 3.939948024749756 and perplexity is 51.4159288753077
At time: 280.3054106235504 and batch: 950, loss is 4.064889521598816 and perplexity is 58.25847186417567
At time: 280.7084138393402 and batch: 1000, loss is 4.0916626930236815 and perplexity is 59.83930342800467
At time: 281.11140036582947 and batch: 1050, loss is 4.000611882209778 and perplexity is 54.63156789269056
At time: 281.51380825042725 and batch: 1100, loss is 4.128446245193482 and perplexity is 62.08138870282574
At time: 281.9158763885498 and batch: 1150, loss is 4.049127826690674 and perplexity is 57.34741833977169
At time: 282.3232204914093 and batch: 1200, loss is 4.004018440246582 and perplexity is 54.8179908493884
At time: 282.7247242927551 and batch: 1250, loss is 3.9634486722946165 and perplexity is 52.63854638108121
At time: 283.11869740486145 and batch: 1300, loss is 4.030894250869751 and perplexity is 56.31124511814325
At time: 283.51430559158325 and batch: 1350, loss is 3.997155337333679 and perplexity is 54.44305741177515
At time: 283.9040620326996 and batch: 1400, loss is 3.8667295742034913 and perplexity is 47.78585017369027
At time: 284.30294156074524 and batch: 1450, loss is 3.949089002609253 and perplexity is 51.888075395616944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6830705169938565 and perplexity of 108.10149096317572
Finished 23 epochs...
Completing Train Step...
At time: 285.66559648513794 and batch: 50, loss is 4.183627815246582 and perplexity is 65.60341911495308
At time: 286.0712718963623 and batch: 100, loss is 4.201986322402954 and perplexity is 66.81892323607143
At time: 286.4733393192291 and batch: 150, loss is 4.069907941818237 and perplexity is 58.5515721925056
At time: 286.882803440094 and batch: 200, loss is 4.156396503448486 and perplexity is 63.84105658033795
At time: 287.2967083454132 and batch: 250, loss is 4.184186282157898 and perplexity is 65.64006668607345
At time: 287.6916751861572 and batch: 300, loss is 4.197897777557373 and perplexity is 66.54628879074961
At time: 288.0799653530121 and batch: 350, loss is 4.181584787368775 and perplexity is 65.46952632074932
At time: 288.4820032119751 and batch: 400, loss is 4.040154175758362 and perplexity is 56.83510472538646
At time: 288.8865783214569 and batch: 450, loss is 4.097951779365539 and perplexity is 60.21682385886716
At time: 289.277724981308 and batch: 500, loss is 4.080163993835449 and perplexity is 59.15517013770436
At time: 289.6730935573578 and batch: 550, loss is 4.124372501373291 and perplexity is 61.828999462843406
At time: 290.06281304359436 and batch: 600, loss is 4.060638518333435 and perplexity is 58.01134056019469
At time: 290.4477698802948 and batch: 650, loss is 4.137930994033813 and perplexity is 62.67301636698034
At time: 290.83975315093994 and batch: 700, loss is 4.1844133853912355 and perplexity is 65.65497545030453
At time: 291.2468349933624 and batch: 750, loss is 4.139972219467163 and perplexity is 62.80107677759221
At time: 291.6455888748169 and batch: 800, loss is 4.0649368906021115 and perplexity is 58.261231575283276
At time: 292.0461046695709 and batch: 850, loss is 4.025452527999878 and perplexity is 56.0056471715427
At time: 292.4528748989105 and batch: 900, loss is 3.9390113067626955 and perplexity is 51.367789200078604
At time: 292.8524444103241 and batch: 950, loss is 4.064035673141479 and perplexity is 58.20874918868343
At time: 293.2515480518341 and batch: 1000, loss is 4.090776233673096 and perplexity is 59.786281822169606
At time: 293.6666395664215 and batch: 1050, loss is 4.0003453063964844 and perplexity is 54.61700637900796
At time: 294.06396555900574 and batch: 1100, loss is 4.128017015457154 and perplexity is 62.0547472427844
At time: 294.45751762390137 and batch: 1150, loss is 4.048534784317017 and perplexity is 57.313418973205366
At time: 294.8503267765045 and batch: 1200, loss is 4.0036295223236085 and perplexity is 54.79667529551484
At time: 295.24195075035095 and batch: 1250, loss is 3.9632061958312987 and perplexity is 52.62578431983281
At time: 295.6382930278778 and batch: 1300, loss is 4.030668940544128 and perplexity is 56.298559042375075
At time: 296.03990411758423 and batch: 1350, loss is 3.9970691108703615 and perplexity is 54.438363181868674
At time: 296.432564496994 and batch: 1400, loss is 3.8666598129272463 and perplexity is 47.78251668807116
At time: 296.82737469673157 and batch: 1450, loss is 3.9490565252304077 and perplexity is 51.886390234299725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682956271701389 and perplexity of 108.08914158216726
Finished 24 epochs...
Completing Train Step...
At time: 298.19045901298523 and batch: 50, loss is 4.182153429985046 and perplexity is 65.50676567041957
At time: 298.58925223350525 and batch: 100, loss is 4.200228757858277 and perplexity is 66.70158780817655
At time: 298.9889235496521 and batch: 150, loss is 4.068192410469055 and perplexity is 58.45121124565465
At time: 299.38310527801514 and batch: 200, loss is 4.15463611125946 and perplexity is 63.728770146073444
At time: 299.7624714374542 and batch: 250, loss is 4.182354249954224 and perplexity is 65.51992205807088
At time: 300.155579328537 and batch: 300, loss is 4.19621090888977 and perplexity is 66.43412856762254
At time: 300.55277705192566 and batch: 350, loss is 4.179978528022766 and perplexity is 65.36444969496605
At time: 300.95424485206604 and batch: 400, loss is 4.03862578868866 and perplexity is 56.74830503487809
At time: 301.3343753814697 and batch: 450, loss is 4.096566390991211 and perplexity is 60.13345793158104
At time: 301.71881580352783 and batch: 500, loss is 4.07882143497467 and perplexity is 59.075804128565686
At time: 302.1049497127533 and batch: 550, loss is 4.122885241508484 and perplexity is 61.73711202065105
At time: 302.5010688304901 and batch: 600, loss is 4.0593155574798585 and perplexity is 57.934644571651575
At time: 302.9082908630371 and batch: 650, loss is 4.136731834411621 and perplexity is 62.59790645973661
At time: 303.3029911518097 and batch: 700, loss is 4.183246989250183 and perplexity is 65.57844038407836
At time: 303.69116711616516 and batch: 750, loss is 4.138751983642578 and perplexity is 62.724491389505594
At time: 304.0827741622925 and batch: 800, loss is 4.0636572885513305 and perplexity is 58.18672806146894
At time: 304.4818711280823 and batch: 850, loss is 4.024516201019287 and perplexity is 55.95323211567539
At time: 304.8849799633026 and batch: 900, loss is 3.9381305885314943 and perplexity is 51.32256856787421
At time: 305.2766418457031 and batch: 950, loss is 4.063200736045838 and perplexity is 58.16016882828961
At time: 305.6691279411316 and batch: 1000, loss is 4.089932680130005 and perplexity is 59.735870157768666
At time: 306.0653166770935 and batch: 1050, loss is 4.000046348571777 and perplexity is 54.60068063806445
At time: 306.4640235900879 and batch: 1100, loss is 4.1275753402709965 and perplexity is 62.02734525257903
At time: 306.8612217903137 and batch: 1150, loss is 4.047927675247192 and perplexity is 57.27863403691765
At time: 307.28939723968506 and batch: 1200, loss is 4.003190908432007 and perplexity is 54.772645982697085
At time: 307.6838140487671 and batch: 1250, loss is 3.962884111404419 and perplexity is 52.60883710361477
At time: 308.0703091621399 and batch: 1300, loss is 4.030358538627625 and perplexity is 56.28108657363612
At time: 308.47786712646484 and batch: 1350, loss is 3.996858081817627 and perplexity is 54.42687631772764
At time: 308.87720108032227 and batch: 1400, loss is 3.866456775665283 and perplexity is 47.77281604154278
At time: 309.2807545661926 and batch: 1450, loss is 3.948858003616333 and perplexity is 51.87609068673713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6828837598490916 and perplexity of 108.08130412245565
Finished 25 epochs...
Completing Train Step...
At time: 310.5613968372345 and batch: 50, loss is 4.180825848579406 and perplexity is 65.41985780776753
At time: 310.9660310745239 and batch: 100, loss is 4.198631310462952 and perplexity is 66.59512059099835
At time: 311.3541226387024 and batch: 150, loss is 4.06663583278656 and perplexity is 58.36029816970378
At time: 311.74909567832947 and batch: 200, loss is 4.153031044006347 and perplexity is 63.62656323045994
At time: 312.1428334712982 and batch: 250, loss is 4.180670409202576 and perplexity is 65.40968977611428
At time: 312.5426151752472 and batch: 300, loss is 4.194653115272522 and perplexity is 66.33071847287749
At time: 312.9375514984131 and batch: 350, loss is 4.178507852554321 and perplexity is 65.26839045558846
At time: 313.3289270401001 and batch: 400, loss is 4.037266497611999 and perplexity is 56.671219972616214
At time: 313.7326111793518 and batch: 450, loss is 4.095319948196411 and perplexity is 60.05855170907446
At time: 314.1213402748108 and batch: 500, loss is 4.077597985267639 and perplexity is 59.0035720484805
At time: 314.5123014450073 and batch: 550, loss is 4.121518921852112 and perplexity is 61.65281699106125
At time: 314.8935558795929 and batch: 600, loss is 4.058072519302368 and perplexity is 57.86267433679151
At time: 315.2971839904785 and batch: 650, loss is 4.135607233047486 and perplexity is 62.527548338574825
At time: 315.699871301651 and batch: 700, loss is 4.18214054107666 and perplexity is 65.50592136515928
At time: 316.09146428108215 and batch: 750, loss is 4.137595424652099 and perplexity is 62.65198874993747
At time: 316.48966908454895 and batch: 800, loss is 4.062450566291809 and perplexity is 58.11655518960705
At time: 316.88845586776733 and batch: 850, loss is 4.023642988204956 and perplexity is 55.904394362367995
At time: 317.3166286945343 and batch: 900, loss is 3.9372695112228393 and perplexity is 51.2783948898638
At time: 317.7079782485962 and batch: 950, loss is 4.062339849472046 and perplexity is 58.110121065630324
At time: 318.1086337566376 and batch: 1000, loss is 4.089097099304199 and perplexity is 59.685976857897316
At time: 318.49360394477844 and batch: 1050, loss is 3.999720892906189 and perplexity is 54.582913428582145
At time: 318.87916898727417 and batch: 1100, loss is 4.127106451988221 and perplexity is 61.998268174661696
At time: 319.26948833465576 and batch: 1150, loss is 4.047304682731628 and perplexity is 57.2429609897854
At time: 319.66399669647217 and batch: 1200, loss is 4.002716197967529 and perplexity is 54.74665100501408
At time: 320.0554826259613 and batch: 1250, loss is 3.9625058650970457 and perplexity is 52.588941768150924
At time: 320.4429335594177 and batch: 1300, loss is 4.029976887702942 and perplexity is 56.259610943260896
At time: 320.8399655818939 and batch: 1350, loss is 3.996566905975342 and perplexity is 54.41103083319599
At time: 321.241623878479 and batch: 1400, loss is 3.8661438751220705 and perplexity is 47.75787023984927
At time: 321.64301800727844 and batch: 1450, loss is 3.94854681968689 and perplexity is 51.85995019245454
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682820638020833 and perplexity of 108.07448204825204
Finished 26 epochs...
Completing Train Step...
At time: 322.9885551929474 and batch: 50, loss is 4.179606170654297 and perplexity is 65.34011529131459
At time: 323.38940358161926 and batch: 100, loss is 4.1971249628067016 and perplexity is 66.49488070419204
At time: 323.7778649330139 and batch: 150, loss is 4.065196766853332 and perplexity is 58.27637425326253
At time: 324.1706585884094 and batch: 200, loss is 4.151526584625244 and perplexity is 63.53091162054289
At time: 324.5627965927124 and batch: 250, loss is 4.1791298389434814 and perplexity is 65.30899913380763
At time: 324.9532678127289 and batch: 300, loss is 4.193194146156311 and perplexity is 66.23401456433108
At time: 325.3509771823883 and batch: 350, loss is 4.177167448997498 and perplexity is 65.18096307994622
At time: 325.74808263778687 and batch: 400, loss is 4.036056723594665 and perplexity is 56.6027020571163
At time: 326.1546974182129 and batch: 450, loss is 4.09411970615387 and perplexity is 59.9865101526
At time: 326.5514225959778 and batch: 500, loss is 4.076437244415283 and perplexity is 58.93512392492067
At time: 326.9546458721161 and batch: 550, loss is 4.120225305557251 and perplexity is 61.57311346638162
At time: 327.34981989860535 and batch: 600, loss is 4.056873731613159 and perplexity is 57.7933508355138
At time: 327.77158880233765 and batch: 650, loss is 4.134534869194031 and perplexity is 62.460531995265676
At time: 328.1841232776642 and batch: 700, loss is 4.181063385009765 and perplexity is 65.43539925302242
At time: 328.5863461494446 and batch: 750, loss is 4.136478128433228 and perplexity is 62.5820270110736
At time: 328.9777376651764 and batch: 800, loss is 4.061289381980896 and perplexity is 58.04911032305528
At time: 329.38306164741516 and batch: 850, loss is 4.022800097465515 and perplexity is 55.857292919539546
At time: 329.7890393733978 and batch: 900, loss is 3.93642737865448 and perplexity is 51.23522986136302
At time: 330.1818721294403 and batch: 950, loss is 4.061486592292786 and perplexity is 58.06055933510152
At time: 330.5808103084564 and batch: 1000, loss is 4.088301076889038 and perplexity is 59.63848438749093
At time: 330.9814715385437 and batch: 1050, loss is 3.999397664070129 and perplexity is 54.56527350802495
At time: 331.37600231170654 and batch: 1100, loss is 4.126629896163941 and perplexity is 61.96872957782201
At time: 331.79178833961487 and batch: 1150, loss is 4.046661615371704 and perplexity is 57.206161743452704
At time: 332.1855010986328 and batch: 1200, loss is 4.002191271781921 and perplexity is 54.71792059565903
At time: 332.5890610218048 and batch: 1250, loss is 3.9620804977416992 and perplexity is 52.56657690604887
At time: 332.98728370666504 and batch: 1300, loss is 4.0295472860336305 and perplexity is 56.23544691131073
At time: 333.383100271225 and batch: 1350, loss is 3.9962042236328124 and perplexity is 54.391300491213556
At time: 333.7773132324219 and batch: 1400, loss is 3.8657602977752688 and perplexity is 47.73955491559007
At time: 334.1872639656067 and batch: 1450, loss is 3.9481582975387575 and perplexity is 51.839805366812605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682760646200587 and perplexity of 108.067998657829
Finished 27 epochs...
Completing Train Step...
At time: 335.56128883361816 and batch: 50, loss is 4.178475222587585 and perplexity is 65.26626078492474
At time: 335.93618655204773 and batch: 100, loss is 4.195708351135254 and perplexity is 66.4007499691856
At time: 336.3233664035797 and batch: 150, loss is 4.06385630607605 and perplexity is 58.198309392464964
At time: 336.72591066360474 and batch: 200, loss is 4.150113544464111 and perplexity is 63.441203286615604
At time: 337.1170823574066 and batch: 250, loss is 4.177698540687561 and perplexity is 65.21558934183437
At time: 337.51899886131287 and batch: 300, loss is 4.191821413040161 and perplexity is 66.14315531614041
At time: 337.94246530532837 and batch: 350, loss is 4.175916023254395 and perplexity is 65.09944496236173
At time: 338.33757042884827 and batch: 400, loss is 4.034926381111145 and perplexity is 56.538757764582634
At time: 338.72843980789185 and batch: 450, loss is 4.092973322868347 and perplexity is 59.91778202192119
At time: 339.11976766586304 and batch: 500, loss is 4.075331101417541 and perplexity is 58.86996929208386
At time: 339.51599502563477 and batch: 550, loss is 4.1190278482437135 and perplexity is 61.49942641869612
At time: 339.9099621772766 and batch: 600, loss is 4.05572979927063 and perplexity is 57.7272769515416
At time: 340.30854749679565 and batch: 650, loss is 4.133504815101624 and perplexity is 62.396227392965066
At time: 340.701740026474 and batch: 700, loss is 4.180032434463501 and perplexity is 65.36797335477286
At time: 341.104022026062 and batch: 750, loss is 4.135422863960266 and perplexity is 62.516021254213236
At time: 341.4999735355377 and batch: 800, loss is 4.060180282592773 and perplexity is 57.984763780266576
At time: 341.89292073249817 and batch: 850, loss is 4.021997156143189 and perplexity is 55.81246079209369
At time: 342.2830729484558 and batch: 900, loss is 3.9356110429763795 and perplexity is 51.193421782286556
At time: 342.68753600120544 and batch: 950, loss is 4.060665407180786 and perplexity is 58.01290043924724
At time: 343.08447456359863 and batch: 1000, loss is 4.087493305206299 and perplexity is 59.59032956027254
At time: 343.48439836502075 and batch: 1050, loss is 3.999062008857727 and perplexity is 54.54696146299444
At time: 343.88260650634766 and batch: 1100, loss is 4.126114549636841 and perplexity is 61.936802435722825
At time: 344.27932024002075 and batch: 1150, loss is 4.045973196029663 and perplexity is 57.166793467720595
At time: 344.6859004497528 and batch: 1200, loss is 4.001643304824829 and perplexity is 54.68794519672594
At time: 345.0773186683655 and batch: 1250, loss is 3.9616402339935304 and perplexity is 52.543438841671026
At time: 345.47734117507935 and batch: 1300, loss is 4.029113903045654 and perplexity is 56.211080705629
At time: 345.8789904117584 and batch: 1350, loss is 3.9957813358306886 and perplexity is 54.368303936518124
At time: 346.26687026023865 and batch: 1400, loss is 3.8653188228607176 and perplexity is 47.71848375120048
At time: 346.6636219024658 and batch: 1450, loss is 3.947710590362549 and perplexity is 51.816601508591134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682682917668269 and perplexity of 108.05959901735285
Finished 28 epochs...
Completing Train Step...
At time: 347.9195146560669 and batch: 50, loss is 4.177359657287598 and perplexity is 65.19349260550766
At time: 348.2976725101471 and batch: 100, loss is 4.194387426376343 and perplexity is 66.31309747845862
At time: 348.6948606967926 and batch: 150, loss is 4.062585625648499 and perplexity is 58.12440490424074
At time: 349.090039730072 and batch: 200, loss is 4.148785052299499 and perplexity is 63.356978103770864
At time: 349.468537569046 and batch: 250, loss is 4.176336178779602 and perplexity is 65.12680260067958
At time: 349.8590672016144 and batch: 300, loss is 4.190520811080932 and perplexity is 66.05718531723983
At time: 350.2440629005432 and batch: 350, loss is 4.174722023010254 and perplexity is 65.02176259479508
At time: 350.6353271007538 and batch: 400, loss is 4.033859167098999 and perplexity is 56.478450995905085
At time: 351.01484990119934 and batch: 450, loss is 4.091870617866516 and perplexity is 59.85174679936347
At time: 351.40853548049927 and batch: 500, loss is 4.074248604774475 and perplexity is 58.80627722739038
At time: 351.8066735267639 and batch: 550, loss is 4.11790322303772 and perplexity is 61.43030149069536
At time: 352.2065336704254 and batch: 600, loss is 4.054626560211181 and perplexity is 57.66362508288301
At time: 352.59387850761414 and batch: 650, loss is 4.13249255657196 and perplexity is 62.3330982364718
At time: 352.9910671710968 and batch: 700, loss is 4.179041399955749 and perplexity is 65.30322352743258
At time: 353.38545632362366 and batch: 750, loss is 4.1344193983078 and perplexity is 62.45332003867527
At time: 353.77733278274536 and batch: 800, loss is 4.0591159915924075 and perplexity is 57.92308394648506
At time: 354.1744270324707 and batch: 850, loss is 4.021219158172608 and perplexity is 55.76905569759138
At time: 354.5729396343231 and batch: 900, loss is 3.9348272371292112 and perplexity is 51.15331180022975
At time: 354.98529052734375 and batch: 950, loss is 4.059867157936096 and perplexity is 57.96661016333623
At time: 355.3770020008087 and batch: 1000, loss is 4.086679873466491 and perplexity is 59.54187660408052
At time: 355.77673077583313 and batch: 1050, loss is 3.9987135457992555 and perplexity is 54.52795717331148
At time: 356.1686203479767 and batch: 1100, loss is 4.125575346946716 and perplexity is 61.90341494735244
At time: 356.55922293663025 and batch: 1150, loss is 4.045308656692505 and perplexity is 57.12881650467265
At time: 356.95090341567993 and batch: 1200, loss is 4.0010892057418825 and perplexity is 54.6576510501987
At time: 357.34998297691345 and batch: 1250, loss is 3.96120445728302 and perplexity is 52.52054662304383
At time: 357.7394607067108 and batch: 1300, loss is 4.0286425733566285 and perplexity is 56.18459299715228
At time: 358.1401915550232 and batch: 1350, loss is 3.995326280593872 and perplexity is 54.34356898340678
At time: 358.5419988632202 and batch: 1400, loss is 3.8648538398742676 and perplexity is 47.696300625904584
At time: 358.93369364738464 and batch: 1450, loss is 3.947231345176697 and perplexity is 51.791774601334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682628142528045 and perplexity of 108.0536801997676
Finished 29 epochs...
Completing Train Step...
At time: 360.25411081314087 and batch: 50, loss is 4.176341781616211 and perplexity is 65.12716749653563
At time: 360.67217779159546 and batch: 100, loss is 4.193124098777771 and perplexity is 66.22937520772993
At time: 361.0836269855499 and batch: 150, loss is 4.0613663244247435 and perplexity is 58.05357693530053
At time: 361.4846439361572 and batch: 200, loss is 4.147505707740784 and perplexity is 63.275974525369165
At time: 361.8957166671753 and batch: 250, loss is 4.175044136047363 and perplexity is 65.04271032581019
At time: 362.2882082462311 and batch: 300, loss is 4.1892547607421875 and perplexity is 65.97360651404237
At time: 362.6785488128662 and batch: 350, loss is 4.173559718132019 and perplexity is 64.94623138658882
At time: 363.08134746551514 and batch: 400, loss is 4.0328502321243285 and perplexity is 56.42149664782835
At time: 363.4743790626526 and batch: 450, loss is 4.090786361694336 and perplexity is 59.78688734196813
At time: 363.85656452178955 and batch: 500, loss is 4.073200097084046 and perplexity is 58.744650707058064
At time: 364.2388002872467 and batch: 550, loss is 4.116836013793946 and perplexity is 61.36477747523312
At time: 364.6291320323944 and batch: 600, loss is 4.053553314208984 and perplexity is 57.601771026037476
At time: 365.02117800712585 and batch: 650, loss is 4.13149474143982 and perplexity is 62.27093234800824
At time: 365.43472623825073 and batch: 700, loss is 4.178074836730957 and perplexity is 65.2401343278724
At time: 365.8468749523163 and batch: 750, loss is 4.1334654903411865 and perplexity is 62.393773724515924
At time: 366.25231671333313 and batch: 800, loss is 4.058088817596436 and perplexity is 57.86361740735856
At time: 366.64690113067627 and batch: 850, loss is 4.020458226203918 and perplexity is 55.72663538178151
At time: 367.0488636493683 and batch: 900, loss is 3.934082851409912 and perplexity is 51.11524817419824
At time: 367.44900608062744 and batch: 950, loss is 4.0590914487838745 and perplexity is 57.92166236877094
At time: 367.8520052433014 and batch: 1000, loss is 4.085871696472168 and perplexity is 59.49377566886298
At time: 368.25969886779785 and batch: 1050, loss is 3.9983495759963987 and perplexity is 54.508114254819546
At time: 368.6666407585144 and batch: 1100, loss is 4.125029444694519 and perplexity is 61.86963095593148
At time: 369.0601773262024 and batch: 1150, loss is 4.044649133682251 and perplexity is 57.09115115758604
At time: 369.4595184326172 and batch: 1200, loss is 4.000519766807556 and perplexity is 54.626535715614146
At time: 369.8518590927124 and batch: 1250, loss is 3.9607484197616576 and perplexity is 52.49660074366601
At time: 370.26274275779724 and batch: 1300, loss is 4.02814359664917 and perplexity is 56.15656518712238
At time: 370.67105054855347 and batch: 1350, loss is 3.9948457431793214 and perplexity is 54.317461138670545
At time: 371.0758693218231 and batch: 1400, loss is 3.8643538904190065 and perplexity is 47.672460846227686
At time: 371.4688551425934 and batch: 1450, loss is 3.946717562675476 and perplexity is 51.76517172846714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682578062399839 and perplexity of 108.04826899310822
Finished 30 epochs...
Completing Train Step...
At time: 372.77441477775574 and batch: 50, loss is 4.175361642837524 and perplexity is 65.0633651068322
At time: 373.190523147583 and batch: 100, loss is 4.191906809806824 and perplexity is 66.14880396892617
At time: 373.58083295822144 and batch: 150, loss is 4.0601944780349735 and perplexity is 57.98558690547162
At time: 373.9634337425232 and batch: 200, loss is 4.146270356178284 and perplexity is 63.19785471402087
At time: 374.3413317203522 and batch: 250, loss is 4.173813872337341 and perplexity is 64.96273984217339
At time: 374.7175679206848 and batch: 300, loss is 4.188033103942871 and perplexity is 65.89305862002804
At time: 375.09795093536377 and batch: 350, loss is 4.17243079662323 and perplexity is 64.87295355930189
At time: 375.48585963249207 and batch: 400, loss is 4.031880550384521 and perplexity is 56.36681227030242
At time: 375.8690621852875 and batch: 450, loss is 4.08972713470459 and perplexity is 59.72359298472614
At time: 376.2702078819275 and batch: 500, loss is 4.072180800437927 and perplexity is 58.6848029880862
At time: 376.6708986759186 and batch: 550, loss is 4.115803232192993 and perplexity is 61.301433777843165
At time: 377.07824087142944 and batch: 600, loss is 4.052513570785522 and perplexity is 57.54191108831439
At time: 377.4686019420624 and batch: 650, loss is 4.130508470535278 and perplexity is 62.20954661569157
At time: 377.86214232444763 and batch: 700, loss is 4.177133755683899 and perplexity is 65.17876695431409
At time: 378.27302718162537 and batch: 750, loss is 4.1325503969192505 and perplexity is 62.33670370879136
At time: 378.67752718925476 and batch: 800, loss is 4.057094283103943 and perplexity is 57.80609865092116
At time: 379.07197189331055 and batch: 850, loss is 4.019706678390503 and perplexity is 55.684769884743275
At time: 379.4656310081482 and batch: 900, loss is 3.933354630470276 and perplexity is 51.078038530208424
At time: 379.8634150028229 and batch: 950, loss is 4.058332901000977 and perplexity is 57.87774267989661
At time: 380.25579619407654 and batch: 1000, loss is 4.0850481605529785 and perplexity is 59.44480057677316
At time: 380.6459894180298 and batch: 1050, loss is 3.9979610729217527 and perplexity is 54.486941797887006
At time: 381.0465290546417 and batch: 1100, loss is 4.124476299285889 and perplexity is 61.83541751701025
At time: 381.4333462715149 and batch: 1150, loss is 4.043980598449707 and perplexity is 57.052996466869295
At time: 381.8179397583008 and batch: 1200, loss is 3.9999312925338746 and perplexity is 54.594398861468555
At time: 382.2100830078125 and batch: 1250, loss is 3.960278797149658 and perplexity is 52.47195294093942
At time: 382.6068081855774 and batch: 1300, loss is 4.027629714012146 and perplexity is 56.1277147168306
At time: 383.0023431777954 and batch: 1350, loss is 3.994347014427185 and perplexity is 54.29037821313583
At time: 383.4020576477051 and batch: 1400, loss is 3.863830943107605 and perplexity is 47.64753717845078
At time: 383.8041408061981 and batch: 1450, loss is 3.946170983314514 and perplexity is 51.73688568497171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6825258955996265 and perplexity of 108.04263260766369
Finished 31 epochs...
Completing Train Step...
At time: 385.1064176559448 and batch: 50, loss is 4.17441089630127 and perplexity is 65.00153573450798
At time: 385.4973645210266 and batch: 100, loss is 4.190730304718017 and perplexity is 66.07102532689389
At time: 385.8960814476013 and batch: 150, loss is 4.059073166847229 and perplexity is 57.92060345828861
At time: 386.2871515750885 and batch: 200, loss is 4.145071020126343 and perplexity is 63.12210468240891
At time: 386.6809322834015 and batch: 250, loss is 4.172622203826904 and perplexity is 64.88537189837864
At time: 387.0593204498291 and batch: 300, loss is 4.1868514776229855 and perplexity is 65.81524363083854
At time: 387.4580144882202 and batch: 350, loss is 4.171328339576721 and perplexity is 64.80147332370714
At time: 387.8380422592163 and batch: 400, loss is 4.030947861671447 and perplexity is 56.3142640900626
At time: 388.2577049732208 and batch: 450, loss is 4.088688821792602 and perplexity is 59.66161338965506
At time: 388.6497082710266 and batch: 500, loss is 4.071195993423462 and perplexity is 58.627038230698744
At time: 389.0429427623749 and batch: 550, loss is 4.114783849716186 and perplexity is 61.238976010032445
At time: 389.4473030567169 and batch: 600, loss is 4.051498622894287 and perplexity is 57.4835386744877
At time: 389.83884716033936 and batch: 650, loss is 4.129538650512695 and perplexity is 62.1492437979544
At time: 390.22191071510315 and batch: 700, loss is 4.17622088432312 and perplexity is 65.11929427421389
At time: 390.62326979637146 and batch: 750, loss is 4.131661548614502 and perplexity is 62.281320452679125
At time: 391.04168796539307 and batch: 800, loss is 4.05611752986908 and perplexity is 57.74966392295737
At time: 391.4423544406891 and batch: 850, loss is 4.018956284523011 and perplexity is 55.64300004878343
At time: 391.8430941104889 and batch: 900, loss is 3.932629780769348 and perplexity is 51.04102804439608
At time: 392.24376606941223 and batch: 950, loss is 4.057561092376709 and perplexity is 57.833089373063366
At time: 392.65970158576965 and batch: 1000, loss is 4.0841873931884765 and perplexity is 59.39365444806449
At time: 393.05396246910095 and batch: 1050, loss is 3.9975420141220095 and perplexity is 54.46411334902077
At time: 393.4505558013916 and batch: 1100, loss is 4.123922376632691 and perplexity is 61.80117496321628
At time: 393.85603523254395 and batch: 1150, loss is 4.04330267906189 and perplexity is 57.0143322415261
At time: 394.25709295272827 and batch: 1200, loss is 3.9993068408966064 and perplexity is 54.560317941764346
At time: 394.63806319236755 and batch: 1250, loss is 3.95979389667511 and perplexity is 52.446515433885935
At time: 395.0324604511261 and batch: 1300, loss is 4.027117538452148 and perplexity is 56.09897483367523
At time: 395.42609572410583 and batch: 1350, loss is 3.9938392448425293 and perplexity is 54.26281820799807
At time: 395.821005821228 and batch: 1400, loss is 3.8632886457443236 and perplexity is 47.6217050496528
At time: 396.21435832977295 and batch: 1450, loss is 3.945589056015015 and perplexity is 51.706787337175044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.68245860042735 and perplexity of 108.03536210472677
Finished 32 epochs...
Completing Train Step...
At time: 397.4982964992523 and batch: 50, loss is 4.173480253219605 and perplexity is 64.94107064505172
At time: 397.8897888660431 and batch: 100, loss is 4.189561586380005 and perplexity is 65.99385201370053
At time: 398.3009886741638 and batch: 150, loss is 4.057978496551514 and perplexity is 57.85723418473161
At time: 398.69736766815186 and batch: 200, loss is 4.143918852806092 and perplexity is 63.04941933708888
At time: 399.09569931030273 and batch: 250, loss is 4.171446986198426 and perplexity is 64.80916225572234
At time: 399.48704957962036 and batch: 300, loss is 4.185706009864807 and perplexity is 65.7398975527528
At time: 399.8846333026886 and batch: 350, loss is 4.17019633769989 and perplexity is 64.72815943784035
At time: 400.28231143951416 and batch: 400, loss is 4.030041828155517 and perplexity is 56.26326458649061
At time: 400.67322993278503 and batch: 450, loss is 4.087627773284912 and perplexity is 59.59834309616275
At time: 401.05782103538513 and batch: 500, loss is 4.070206823348999 and perplexity is 58.56907479150252
At time: 401.45171999931335 and batch: 550, loss is 4.113666653633118 and perplexity is 61.17059826868731
At time: 401.84618282318115 and batch: 600, loss is 4.0505216026306154 and perplexity is 57.42740351943259
At time: 402.2390911579132 and batch: 650, loss is 4.128558382987976 and perplexity is 62.088350763181786
At time: 402.635201215744 and batch: 700, loss is 4.175364952087403 and perplexity is 65.06358041812153
At time: 403.0271918773651 and batch: 750, loss is 4.130777587890625 and perplexity is 62.22629053729302
At time: 403.4384195804596 and batch: 800, loss is 4.05514582157135 and perplexity is 57.693575350611226
At time: 403.8334150314331 and batch: 850, loss is 4.018158483505249 and perplexity is 55.598625710013145
At time: 404.23184156417847 and batch: 900, loss is 3.931872372627258 and perplexity is 51.002383790758195
At time: 404.6271810531616 and batch: 950, loss is 4.056775102615356 and perplexity is 57.787651016329576
At time: 405.028600692749 and batch: 1000, loss is 4.083312382698059 and perplexity is 59.341707107906444
At time: 405.41933274269104 and batch: 1050, loss is 3.9970385122299192 and perplexity is 54.436697467451836
At time: 405.82357454299927 and batch: 1100, loss is 4.123406281471253 and perplexity is 61.7692879049326
At time: 406.2295205593109 and batch: 1150, loss is 4.042630152702332 and perplexity is 56.976001490885864
At time: 406.6310224533081 and batch: 1200, loss is 3.998669538497925 and perplexity is 54.52555759786902
At time: 407.02127289772034 and batch: 1250, loss is 3.9592594051361085 and perplexity is 52.41849070529375
At time: 407.4117166996002 and batch: 1300, loss is 4.026598653793335 and perplexity is 56.06987348703298
At time: 407.8164904117584 and batch: 1350, loss is 3.993339138031006 and perplexity is 54.23568778761927
At time: 408.21021461486816 and batch: 1400, loss is 3.8627012157440186 and perplexity is 47.59373884633857
At time: 408.60452675819397 and batch: 1450, loss is 3.944978423118591 and perplexity is 51.67522310991713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682384001903045 and perplexity of 108.02730312673863
Finished 33 epochs...
Completing Train Step...
At time: 410.02239179611206 and batch: 50, loss is 4.1725850009918215 and perplexity is 64.88295802349039
At time: 410.4362623691559 and batch: 100, loss is 4.188409204483032 and perplexity is 65.91784569589204
At time: 410.8155598640442 and batch: 150, loss is 4.056952500343323 and perplexity is 57.797903323665544
At time: 411.21871972084045 and batch: 200, loss is 4.142818684577942 and perplexity is 62.98009251170884
At time: 411.61913990974426 and batch: 250, loss is 4.17030179977417 and perplexity is 64.73498616377299
At time: 412.02218556404114 and batch: 300, loss is 4.18459493637085 and perplexity is 65.66689625749846
At time: 412.4206268787384 and batch: 350, loss is 4.169089441299438 and perplexity is 64.6565517096303
At time: 412.8224720954895 and batch: 400, loss is 4.029165277481079 and perplexity is 56.21396859234601
At time: 413.2273235321045 and batch: 450, loss is 4.086619982719421 and perplexity is 59.538310703392035
At time: 413.63432359695435 and batch: 500, loss is 4.069250745773315 and perplexity is 58.51310497247368
At time: 414.02635979652405 and batch: 550, loss is 4.112638592720032 and perplexity is 61.10774348238767
At time: 414.42247700691223 and batch: 600, loss is 4.049611048698425 and perplexity is 57.375136570891506
At time: 414.8206133842468 and batch: 650, loss is 4.1276172924041745 and perplexity is 62.029947486612
At time: 415.21461820602417 and batch: 700, loss is 4.174504981040955 and perplexity is 65.00765167478052
At time: 415.59720063209534 and batch: 750, loss is 4.12990909576416 and perplexity is 62.17227095508862
At time: 415.9942436218262 and batch: 800, loss is 4.054212131500244 and perplexity is 57.6397325722851
At time: 416.4001135826111 and batch: 850, loss is 4.0174164199829105 and perplexity is 55.55738330211738
At time: 416.8009443283081 and batch: 900, loss is 3.9311893129348756 and perplexity is 50.96755801357168
At time: 417.2068021297455 and batch: 950, loss is 4.05608570098877 and perplexity is 57.747825845068554
At time: 417.6003985404968 and batch: 1000, loss is 4.082521395683289 and perplexity is 59.29478714713595
At time: 417.9975061416626 and batch: 1050, loss is 3.996616258621216 and perplexity is 54.41371622779746
At time: 418.3894667625427 and batch: 1100, loss is 4.122862696647644 and perplexity is 61.73572018174137
At time: 418.8047225475311 and batch: 1150, loss is 4.041950097084046 and perplexity is 56.937267812984935
At time: 419.20731234550476 and batch: 1200, loss is 3.9980546045303345 and perplexity is 54.49203828753778
At time: 419.74638271331787 and batch: 1250, loss is 3.958784747123718 and perplexity is 52.393615752697876
At time: 420.13057947158813 and batch: 1300, loss is 4.026078128814698 and perplexity is 56.04069531197723
At time: 420.53111004829407 and batch: 1350, loss is 3.9928260755538942 and perplexity is 54.20786862838872
At time: 420.9154052734375 and batch: 1400, loss is 3.8621485328674314 and perplexity is 47.56744186945924
At time: 421.3166558742523 and batch: 1450, loss is 3.9444075536727907 and perplexity is 51.64573172260564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.68233653011485 and perplexity of 108.02217499920702
Finished 34 epochs...
Completing Train Step...
At time: 422.63910126686096 and batch: 50, loss is 4.171735563278198 and perplexity is 64.8278673933158
At time: 423.0217182636261 and batch: 100, loss is 4.187350759506225 and perplexity is 65.84811219428077
At time: 423.4298176765442 and batch: 150, loss is 4.05598180770874 and perplexity is 57.741826545675764
At time: 423.84136486053467 and batch: 200, loss is 4.141733694076538 and perplexity is 62.911796766373406
At time: 424.21835255622864 and batch: 250, loss is 4.169181561470031 and perplexity is 64.662508156554
At time: 424.60122632980347 and batch: 300, loss is 4.183504467010498 and perplexity is 65.59532754797469
At time: 424.98532032966614 and batch: 350, loss is 4.16805811882019 and perplexity is 64.58990432780037
At time: 425.37700629234314 and batch: 400, loss is 4.028315024375916 and perplexity is 56.16619280463096
At time: 425.770530462265 and batch: 450, loss is 4.0856676197052 and perplexity is 59.481635610263844
At time: 426.16676139831543 and batch: 500, loss is 4.068350610733032 and perplexity is 58.46045897418073
At time: 426.562762260437 and batch: 550, loss is 4.111689939498901 and perplexity is 61.049800912745155
At time: 426.9554603099823 and batch: 600, loss is 4.048660717010498 and perplexity is 57.32063706091636
At time: 427.3515486717224 and batch: 650, loss is 4.126689291000366 and perplexity is 61.97241030968591
At time: 427.7449655532837 and batch: 700, loss is 4.173656330108643 and perplexity is 64.9525062734871
At time: 428.1319274902344 and batch: 750, loss is 4.129053115844727 and perplexity is 62.11907550996995
At time: 428.50826954841614 and batch: 800, loss is 4.053270149230957 and perplexity is 57.58546253091686
At time: 428.90231823921204 and batch: 850, loss is 4.016700358390808 and perplexity is 55.51761503374104
At time: 429.31066131591797 and batch: 900, loss is 3.930517244338989 and perplexity is 50.93331582625998
At time: 429.7059283256531 and batch: 950, loss is 4.05541793346405 and perplexity is 57.70927659474727
At time: 430.08490800857544 and batch: 1000, loss is 4.081740069389343 and perplexity is 59.248476664998606
At time: 430.48712682724 and batch: 1050, loss is 3.996184062957764 and perplexity is 54.390203936932565
At time: 430.8781886100769 and batch: 1100, loss is 4.122317252159118 and perplexity is 61.70205595524109
At time: 431.25913882255554 and batch: 1150, loss is 4.041279292106628 and perplexity is 56.899086817767966
At time: 431.6412591934204 and batch: 1200, loss is 3.9974374341964722 and perplexity is 54.45841779392783
At time: 432.04246282577515 and batch: 1250, loss is 3.958302183151245 and perplexity is 52.3683385807648
At time: 432.44487380981445 and batch: 1300, loss is 4.025558381080628 and perplexity is 56.01157585561438
At time: 432.83574295043945 and batch: 1350, loss is 3.992318005561829 and perplexity is 54.180334232297305
At time: 433.2200334072113 and batch: 1400, loss is 3.861587347984314 and perplexity is 47.540755228923516
At time: 433.6009199619293 and batch: 1450, loss is 3.943841075897217 and perplexity is 51.61648384829905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682288536658654 and perplexity of 108.01699076608864
Finished 35 epochs...
Completing Train Step...
At time: 434.9978847503662 and batch: 50, loss is 4.170906047821045 and perplexity is 64.77411397298759
At time: 435.40710949897766 and batch: 100, loss is 4.186329956054688 and perplexity is 65.78092851057771
At time: 435.8050343990326 and batch: 150, loss is 4.055047478675842 and perplexity is 57.687901876336554
At time: 436.1968936920166 and batch: 200, loss is 4.140672464370727 and perplexity is 62.845068312170426
At time: 436.5878562927246 and batch: 250, loss is 4.168077864646912 and perplexity is 64.59117972145097
At time: 436.97375106811523 and batch: 300, loss is 4.182430663108826 and perplexity is 65.52492883329393
At time: 437.36146092414856 and batch: 350, loss is 4.167042603492737 and perplexity is 64.52434558354562
At time: 437.76406145095825 and batch: 400, loss is 4.027480978965759 and perplexity is 56.11936717937964
At time: 438.1605863571167 and batch: 450, loss is 4.084729151725769 and perplexity is 59.425840185084425
At time: 438.5714030265808 and batch: 500, loss is 4.0674755859375 and perplexity is 58.40932699715655
At time: 438.964586019516 and batch: 550, loss is 4.110760779380798 and perplexity is 60.99310221768119
At time: 439.3576571941376 and batch: 600, loss is 4.047718758583069 and perplexity is 57.266668825678664
At time: 439.75070309638977 and batch: 650, loss is 4.125769248008728 and perplexity is 61.915419249038706
At time: 440.1567211151123 and batch: 700, loss is 4.172813291549683 and perplexity is 64.89777188104082
At time: 440.55492544174194 and batch: 750, loss is 4.128209457397461 and perplexity is 62.06669032788748
At time: 440.9476363658905 and batch: 800, loss is 4.0523292922973635 and perplexity is 57.53130832889352
At time: 441.3418183326721 and batch: 850, loss is 4.015995020866394 and perplexity is 55.478470183380594
At time: 441.7372901439667 and batch: 900, loss is 3.9298512744903564 and perplexity is 50.89940706598803
At time: 442.1402988433838 and batch: 950, loss is 4.0547659301757815 and perplexity is 57.6716622203243
At time: 442.531316280365 and batch: 1000, loss is 4.08096107006073 and perplexity is 59.20234011395949
At time: 442.92189717292786 and batch: 1050, loss is 3.9957400798797607 and perplexity is 54.36606096670713
At time: 443.3070306777954 and batch: 1100, loss is 4.121765913963318 and perplexity is 61.66804663121475
At time: 443.6963288784027 and batch: 1150, loss is 4.040620698928833 and perplexity is 56.861625804504925
At time: 444.0881154537201 and batch: 1200, loss is 3.996816396713257 and perplexity is 54.42460757499452
At time: 444.4888117313385 and batch: 1250, loss is 3.957812581062317 and perplexity is 52.34270520839034
At time: 444.8839945793152 and batch: 1300, loss is 4.025032210350036 and perplexity is 55.98211195602542
At time: 445.28087520599365 and batch: 1350, loss is 3.9918115854263307 and perplexity is 54.152903166502334
At time: 445.677946805954 and batch: 1400, loss is 3.861013870239258 and perplexity is 47.51349947984631
At time: 446.0760498046875 and batch: 1450, loss is 3.943276634216309 and perplexity is 51.58735757420799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.68223636985844 and perplexity of 108.01135601228647
Finished 36 epochs...
Completing Train Step...
At time: 447.4046745300293 and batch: 50, loss is 4.170092492103577 and perplexity is 64.72143805252445
At time: 447.80076599121094 and batch: 100, loss is 4.185342936515808 and perplexity is 65.71603348045194
At time: 448.19044041633606 and batch: 150, loss is 4.054138360023498 and perplexity is 57.6354805609345
At time: 448.58838081359863 and batch: 200, loss is 4.139633059501648 and perplexity is 62.77978077813738
At time: 448.9669008255005 and batch: 250, loss is 4.166988034248352 and perplexity is 64.5208246348313
At time: 449.36719965934753 and batch: 300, loss is 4.181372699737548 and perplexity is 65.45564251633809
At time: 449.77414870262146 and batch: 350, loss is 4.166041111946106 and perplexity is 64.45975734457787
At time: 450.18093729019165 and batch: 400, loss is 4.026653995513916 and perplexity is 56.072976576168884
At time: 450.57694458961487 and batch: 450, loss is 4.0838003253936765 and perplexity is 59.37066952586071
At time: 450.9790358543396 and batch: 500, loss is 4.066621174812317 and perplexity is 58.35944273222589
At time: 451.3656687736511 and batch: 550, loss is 4.1098509740829465 and perplexity is 60.937635605885795
At time: 451.75143671035767 and batch: 600, loss is 4.046783814430237 and perplexity is 57.21315270969606
At time: 452.1462481021881 and batch: 650, loss is 4.124860873222351 and perplexity is 61.85920238016364
At time: 452.55118060112 and batch: 700, loss is 4.171973762512207 and perplexity is 64.84331118094745
At time: 452.9458484649658 and batch: 750, loss is 4.127370223999024 and perplexity is 62.014623739499726
At time: 453.3507385253906 and batch: 800, loss is 4.051389870643615 and perplexity is 57.47728755019836
At time: 453.74665784835815 and batch: 850, loss is 4.015296902656555 and perplexity is 55.43975316919033
At time: 454.15194368362427 and batch: 900, loss is 3.9291916847229005 and perplexity is 50.86584540759773
At time: 454.541996717453 and batch: 950, loss is 4.054121441841126 and perplexity is 57.634505481611555
At time: 454.93679213523865 and batch: 1000, loss is 4.080183954238891 and perplexity is 59.1563509105503
At time: 455.3231906890869 and batch: 1050, loss is 3.995278949737549 and perplexity is 54.34099691662069
At time: 455.7131962776184 and batch: 1100, loss is 4.121201691627502 and perplexity is 61.63326195596742
At time: 456.1117146015167 and batch: 1150, loss is 4.039974484443665 and perplexity is 56.8248928682159
At time: 456.50363516807556 and batch: 1200, loss is 3.9961896324157715 and perplexity is 54.39050686173298
At time: 456.9000971317291 and batch: 1250, loss is 3.957316074371338 and perplexity is 52.3167231556957
At time: 457.3122820854187 and batch: 1300, loss is 4.024501566886902 and perplexity is 55.95241329466062
At time: 457.71807956695557 and batch: 1350, loss is 3.9913055086135865 and perplexity is 54.1255045713486
At time: 458.11086082458496 and batch: 1400, loss is 3.860423092842102 and perplexity is 47.48543786819295
At time: 458.5119433403015 and batch: 1450, loss is 3.9427121543884276 and perplexity is 51.55824576877013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682176378038195 and perplexity of 108.00487640879562
Finished 37 epochs...
Completing Train Step...
At time: 459.84522008895874 and batch: 50, loss is 4.169287858009338 and perplexity is 64.66938192271623
At time: 460.2296030521393 and batch: 100, loss is 4.184392828941345 and perplexity is 65.65362583096335
At time: 460.6321120262146 and batch: 150, loss is 4.053249449729919 and perplexity is 57.58427055291216
At time: 461.03812551498413 and batch: 200, loss is 4.1386172533035275 and perplexity is 62.716041066784115
At time: 461.43535804748535 and batch: 250, loss is 4.1659106397628785 and perplexity is 64.45134768793189
At time: 461.830774307251 and batch: 300, loss is 4.180326628684997 and perplexity is 65.38720706388905
At time: 462.23092794418335 and batch: 350, loss is 4.1650518131256105 and perplexity is 64.39601891604202
At time: 462.6240849494934 and batch: 400, loss is 4.025808253288269 and perplexity is 56.025573340445284
At time: 463.0183048248291 and batch: 450, loss is 4.082876996994019 and perplexity is 59.31587620059022
At time: 463.4129960536957 and batch: 500, loss is 4.065774631500244 and perplexity is 58.31005984161165
At time: 463.810822725296 and batch: 550, loss is 4.108959927558899 and perplexity is 60.88336152145358
At time: 464.2127757072449 and batch: 600, loss is 4.0458571195602415 and perplexity is 57.16015813327728
At time: 464.6036412715912 and batch: 650, loss is 4.123979206085205 and perplexity is 61.80468718995221
At time: 465.0205624103546 and batch: 700, loss is 4.171157479286194 and perplexity is 64.79040227097703
At time: 465.4162256717682 and batch: 750, loss is 4.126527175903321 and perplexity is 61.96236446068833
At time: 465.80258226394653 and batch: 800, loss is 4.05045744895935 and perplexity is 57.42371945883986
At time: 466.19335889816284 and batch: 850, loss is 4.0146179246902465 and perplexity is 55.402123574609305
At time: 466.62418818473816 and batch: 900, loss is 3.928538737297058 and perplexity is 50.83264352549688
At time: 467.02554535865784 and batch: 950, loss is 4.053473143577576 and perplexity is 57.59715324079194
At time: 467.4234628677368 and batch: 1000, loss is 4.079408445358276 and perplexity is 59.11049241920637
At time: 467.8136966228485 and batch: 1050, loss is 3.9947967290878297 and perplexity is 54.31479888290525
At time: 468.22288036346436 and batch: 1100, loss is 4.120627837181091 and perplexity is 61.59790358079792
At time: 468.6222474575043 and batch: 1150, loss is 4.0393332529068 and perplexity is 56.78846663490274
At time: 469.0179805755615 and batch: 1200, loss is 3.995564332008362 and perplexity is 54.356507086777526
At time: 469.4072017669678 and batch: 1250, loss is 3.9568182706832884 and perplexity is 52.29068617915127
At time: 469.8075451850891 and batch: 1300, loss is 4.023984766006469 and perplexity is 55.92350450889402
At time: 470.2046654224396 and batch: 1350, loss is 3.9907970237731933 and perplexity is 54.09798956886911
At time: 470.6001832485199 and batch: 1400, loss is 3.8598262739181517 and perplexity is 47.457106115565175
At time: 470.9758644104004 and batch: 1450, loss is 3.9421447849273683 and perplexity is 51.52900149159453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682112212873932 and perplexity of 107.99794648049205
Finished 38 epochs...
Completing Train Step...
At time: 472.24129605293274 and batch: 50, loss is 4.168490352630616 and perplexity is 64.61782830267126
At time: 472.64747524261475 and batch: 100, loss is 4.1834811592102055 and perplexity is 65.5937986829974
At time: 473.0449905395508 and batch: 150, loss is 4.052383728027344 and perplexity is 57.534440172900474
At time: 473.44070506095886 and batch: 200, loss is 4.137619395256042 and perplexity is 62.65349057394576
At time: 473.83727383613586 and batch: 250, loss is 4.164850869178772 and perplexity is 64.38308022585963
At time: 474.21577310562134 and batch: 300, loss is 4.179295949935913 and perplexity is 65.31984857754942
At time: 474.5985882282257 and batch: 350, loss is 4.164076037406922 and perplexity is 64.333213491391
At time: 474.9887981414795 and batch: 400, loss is 4.024983139038086 and perplexity is 55.97936490774715
At time: 475.3746302127838 and batch: 450, loss is 4.081960468292237 and perplexity is 59.26153640337682
At time: 475.7681133747101 and batch: 500, loss is 4.064957346916199 and perplexity is 58.26242339752559
At time: 476.16430926322937 and batch: 550, loss is 4.108083171844482 and perplexity is 60.83000508002716
At time: 476.5744948387146 and batch: 600, loss is 4.04494794845581 and perplexity is 57.10821338608746
At time: 476.9538252353668 and batch: 650, loss is 4.123122248649597 and perplexity is 61.75174589116909
At time: 477.3639249801636 and batch: 700, loss is 4.1703675794601445 and perplexity is 64.73924455089056
At time: 477.7629849910736 and batch: 750, loss is 4.125697860717773 and perplexity is 61.91099943275141
At time: 478.1568052768707 and batch: 800, loss is 4.049549202919007 and perplexity is 57.37158827057586
At time: 478.5345525741577 and batch: 850, loss is 4.013950462341309 and perplexity is 55.36515708131568
At time: 478.9185471534729 and batch: 900, loss is 3.927889552116394 and perplexity is 50.7996544357988
At time: 479.3095529079437 and batch: 950, loss is 4.052825627326965 and perplexity is 57.559870220063154
At time: 479.7127010822296 and batch: 1000, loss is 4.078639798164367 and perplexity is 59.065074762391134
At time: 480.1032466888428 and batch: 1050, loss is 3.9943203592300414 and perplexity is 54.28893111168802
At time: 480.49794483184814 and batch: 1100, loss is 4.120056567192077 and perplexity is 61.56272459640176
At time: 480.89185881614685 and batch: 1150, loss is 4.0386925888061525 and perplexity is 56.752095954937474
At time: 481.2930679321289 and batch: 1200, loss is 3.9949361896514892 and perplexity is 54.32237418358809
At time: 481.6707446575165 and batch: 1250, loss is 3.9563171672821045 and perplexity is 52.26448970257659
At time: 482.0621919631958 and batch: 1300, loss is 4.023465704917908 and perplexity is 55.89448432604287
At time: 482.4481039047241 and batch: 1350, loss is 3.990293412208557 and perplexity is 54.070752054837854
At time: 482.83964681625366 and batch: 1400, loss is 3.8592447662353515 and perplexity is 47.42951746603877
At time: 483.2413935661316 and batch: 1450, loss is 3.9415737438201903 and perplexity is 51.49958471342515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682058481069712 and perplexity of 107.99214371187358
Finished 39 epochs...
Completing Train Step...
At time: 484.544718503952 and batch: 50, loss is 4.167708683013916 and perplexity is 64.5673382454326
At time: 484.94762325286865 and batch: 100, loss is 4.182589440345764 and perplexity is 65.53533352643704
At time: 485.3431477546692 and batch: 150, loss is 4.051543340682984 and perplexity is 57.486109268698904
At time: 485.73814845085144 and batch: 200, loss is 4.136633553504944 and perplexity is 62.59175458304463
At time: 486.13126969337463 and batch: 250, loss is 4.163809103965759 and perplexity is 64.31604309711088
At time: 486.54155564308167 and batch: 300, loss is 4.178284530639648 and perplexity is 65.25381622109785
At time: 486.93532395362854 and batch: 350, loss is 4.163121080398559 and perplexity is 64.2718073630698
At time: 487.3332459926605 and batch: 400, loss is 4.024204254150391 and perplexity is 55.93578040225749
At time: 487.73414850234985 and batch: 450, loss is 4.08105329990387 and perplexity is 59.20780058830717
At time: 488.11754870414734 and batch: 500, loss is 4.064166054725647 and perplexity is 58.21633903239227
At time: 488.51372599601746 and batch: 550, loss is 4.107220773696899 and perplexity is 60.77756801039446
At time: 488.9107220172882 and batch: 600, loss is 4.04404773235321 and perplexity is 57.05682678579935
At time: 489.2892074584961 and batch: 650, loss is 4.122271165847779 and perplexity is 61.69921240060502
At time: 489.6801173686981 and batch: 700, loss is 4.169573407173157 and perplexity is 64.68785084741647
At time: 490.07667899131775 and batch: 750, loss is 4.1248886060714725 and perplexity is 61.86091793587852
At time: 490.47200775146484 and batch: 800, loss is 4.048661689758301 and perplexity is 57.32069281946726
At time: 490.85091638565063 and batch: 850, loss is 4.0132821798324585 and perplexity is 55.32816987556636
At time: 491.23825883865356 and batch: 900, loss is 3.9272374534606933 and perplexity is 50.76653884791981
At time: 491.62653851509094 and batch: 950, loss is 4.052179923057556 and perplexity is 57.522715562866765
At time: 492.0072672367096 and batch: 1000, loss is 4.077877006530762 and perplexity is 59.02003759669442
At time: 492.39136600494385 and batch: 1050, loss is 3.9938489389419556 and perplexity is 54.263344239702626
At time: 492.7817301750183 and batch: 1100, loss is 4.119482975006104 and perplexity is 61.52742282400432
At time: 493.1832637786865 and batch: 1150, loss is 4.03805037021637 and perplexity is 56.715660404952146
At time: 493.58113074302673 and batch: 1200, loss is 3.9943037319183348 and perplexity is 54.288028440212734
At time: 493.981214761734 and batch: 1250, loss is 3.955805735588074 and perplexity is 52.23776682011735
At time: 494.3728721141815 and batch: 1300, loss is 4.022939515113831 and perplexity is 55.865080954841844
At time: 494.7502210140228 and batch: 1350, loss is 3.98979389667511 and perplexity is 54.04374961891085
At time: 495.14653062820435 and batch: 1400, loss is 3.8586754751205445 and perplexity is 47.402523947479935
At time: 495.5587725639343 and batch: 1450, loss is 3.940993895530701 and perplexity is 51.4697314233457
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.682011530949519 and perplexity of 107.98707358676889
Finished 40 epochs...
Completing Train Step...
At time: 496.828617811203 and batch: 50, loss is 4.166935811042785 and perplexity is 64.51745523852419
At time: 497.2308826446533 and batch: 100, loss is 4.181708898544311 and perplexity is 65.47765232487636
At time: 497.65218782424927 and batch: 150, loss is 4.050722393989563 and perplexity is 57.43893560355876
At time: 498.05235743522644 and batch: 200, loss is 4.135656208992004 and perplexity is 62.530610759305
At time: 498.44441175460815 and batch: 250, loss is 4.162776489257812 and perplexity is 64.24966368312975
At time: 498.85087394714355 and batch: 300, loss is 4.177288846969605 and perplexity is 65.1888763970047
At time: 499.25801062583923 and batch: 350, loss is 4.162186660766602 and perplexity is 64.21177857489522
At time: 499.6499047279358 and batch: 400, loss is 4.023445687294006 and perplexity is 55.89336546247599
At time: 500.0453667640686 and batch: 450, loss is 4.080150895118713 and perplexity is 59.15439528596204
At time: 500.45016384124756 and batch: 500, loss is 4.063390407562256 and perplexity is 58.17120120193686
At time: 500.8505165576935 and batch: 550, loss is 4.106376333236694 and perplexity is 60.72626663642004
At time: 501.23427176475525 and batch: 600, loss is 4.043150310516357 and perplexity is 57.00564571244164
At time: 501.63686776161194 and batch: 650, loss is 4.121424527168274 and perplexity is 61.64699756755928
At time: 502.04203748703003 and batch: 700, loss is 4.168772230148315 and perplexity is 64.63604518305624
At time: 502.4357886314392 and batch: 750, loss is 4.1240882396698 and perplexity is 61.81142634393167
At time: 502.8139178752899 and batch: 800, loss is 4.047787404060363 and perplexity is 57.270600058422396
At time: 503.21239709854126 and batch: 850, loss is 4.012616739273072 and perplexity is 55.29136451450269
At time: 503.6160032749176 and batch: 900, loss is 3.926580801010132 and perplexity is 50.7332138184574
At time: 504.0137679576874 and batch: 950, loss is 4.051536331176758 and perplexity is 57.48570632087031
At time: 504.4143738746643 and batch: 1000, loss is 4.077116918563843 and perplexity is 58.97519422092421
At time: 504.8115417957306 and batch: 1050, loss is 3.993371458053589 and perplexity is 54.237440714600545
At time: 505.2085175514221 and batch: 1100, loss is 4.118907451629639 and perplexity is 61.492022541697565
At time: 505.60136103630066 and batch: 1150, loss is 4.037397594451904 and perplexity is 56.67864987747605
At time: 505.99687218666077 and batch: 1200, loss is 3.9936685943603516 and perplexity is 54.253559021971306
At time: 506.4028444290161 and batch: 1250, loss is 3.9552852630615236 and perplexity is 52.210585571799236
At time: 506.8031129837036 and batch: 1300, loss is 4.022416586875916 and perplexity is 55.8358751634292
At time: 507.19863629341125 and batch: 1350, loss is 3.9893013429641724 and perplexity is 54.01713672416116
At time: 507.5781989097595 and batch: 1400, loss is 3.858118996620178 and perplexity is 47.37615280020883
At time: 507.9643795490265 and batch: 1450, loss is 3.9404078769683837 and perplexity is 51.43957804141783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681967710837339 and perplexity of 107.98234168476735
Finished 41 epochs...
Completing Train Step...
At time: 509.3268518447876 and batch: 50, loss is 4.166170358657837 and perplexity is 64.4680890946677
At time: 509.71957540512085 and batch: 100, loss is 4.180834264755249 and perplexity is 65.42040839511135
At time: 510.1050786972046 and batch: 150, loss is 4.049922122955322 and perplexity is 57.39298727516797
At time: 510.49123978614807 and batch: 200, loss is 4.134692764282226 and perplexity is 62.47039498511213
At time: 510.88242745399475 and batch: 250, loss is 4.161749811172485 and perplexity is 64.18373381160501
At time: 511.2836329936981 and batch: 300, loss is 4.176310291290283 and perplexity is 65.12511665309547
At time: 511.6774969100952 and batch: 350, loss is 4.161265735626221 and perplexity is 64.15267155444496
At time: 512.0725626945496 and batch: 400, loss is 4.022697377204895 and perplexity is 55.851555538531
At time: 512.463212966919 and batch: 450, loss is 4.079258937835693 and perplexity is 59.101655616526784
At time: 512.870436668396 and batch: 500, loss is 4.062626132965088 and perplexity is 58.12675941559889
At time: 513.2786529064178 and batch: 550, loss is 4.105550589561463 and perplexity is 60.676143003309186
At time: 513.6663534641266 and batch: 600, loss is 4.042259311676025 and perplexity is 56.95487636929113
At time: 514.0533027648926 and batch: 650, loss is 4.120589385032654 and perplexity is 61.59553505460373
At time: 514.4474651813507 and batch: 700, loss is 4.1679692029953 and perplexity is 64.58416151849455
At time: 514.8463506698608 and batch: 750, loss is 4.123289704322815 and perplexity is 61.76208743720077
At time: 515.24760389328 and batch: 800, loss is 4.04692437171936 and perplexity is 57.221195000531196
At time: 515.6416108608246 and batch: 850, loss is 4.0119585609436035 and perplexity is 55.25498491001947
At time: 516.043506860733 and batch: 900, loss is 3.9259313583374023 and perplexity is 50.70027620118376
At time: 516.4443807601929 and batch: 950, loss is 4.050892772674561 and perplexity is 57.44872280761638
At time: 516.8555293083191 and batch: 1000, loss is 4.076361684799195 and perplexity is 58.93067097781638
At time: 517.2480752468109 and batch: 1050, loss is 3.992889475822449 and perplexity is 54.211305530766644
At time: 517.661173582077 and batch: 1100, loss is 4.118338332176209 and perplexity is 61.45703619208875
At time: 518.0609149932861 and batch: 1150, loss is 4.036738452911377 and perplexity is 56.641302934693655
At time: 518.461220741272 and batch: 1200, loss is 3.993037919998169 and perplexity is 54.21935348065173
At time: 518.8497684001923 and batch: 1250, loss is 3.9547911739349364 and perplexity is 52.18479526105618
At time: 519.2491314411163 and batch: 1300, loss is 4.021897554397583 and perplexity is 55.80690205040702
At time: 519.6443848609924 and batch: 1350, loss is 3.988809461593628 and perplexity is 53.99057323449483
At time: 520.0393400192261 and batch: 1400, loss is 3.8575665378570556 and perplexity is 47.34998665795413
At time: 520.4530611038208 and batch: 1450, loss is 3.9398257875442506 and perplexity is 51.4096443199546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.68192128238515 and perplexity of 107.97732834816075
Finished 42 epochs...
Completing Train Step...
At time: 521.7633063793182 and batch: 50, loss is 4.165407876968384 and perplexity is 64.4189520925918
At time: 522.1685049533844 and batch: 100, loss is 4.179980006217956 and perplexity is 65.36454631645262
At time: 522.5638763904572 and batch: 150, loss is 4.049138369560242 and perplexity is 57.34802294931049
At time: 522.958203792572 and batch: 200, loss is 4.1337528944015505 and perplexity is 62.41170852556965
At time: 523.3474404811859 and batch: 250, loss is 4.160728087425232 and perplexity is 64.11818925649848
At time: 523.7246050834656 and batch: 300, loss is 4.175344433784485 and perplexity is 65.0622454375654
At time: 524.124507188797 and batch: 350, loss is 4.16034104347229 and perplexity is 64.09337750100283
At time: 524.5216429233551 and batch: 400, loss is 4.021952719688415 and perplexity is 55.80998073930668
At time: 524.9290571212769 and batch: 450, loss is 4.078383727073669 and perplexity is 59.04995184062874
At time: 525.319657087326 and batch: 500, loss is 4.061868839263916 and perplexity is 58.08275705028389
At time: 525.7063238620758 and batch: 550, loss is 4.104735312461853 and perplexity is 60.62669529295775
At time: 526.0932855606079 and batch: 600, loss is 4.041379585266113 and perplexity is 56.90479369313223
At time: 526.4918038845062 and batch: 650, loss is 4.1197705793380734 and perplexity is 61.545120922246284
At time: 526.9227690696716 and batch: 700, loss is 4.1671709537506105 and perplexity is 64.53262783144335
At time: 527.3199138641357 and batch: 750, loss is 4.1224924659729005 and perplexity is 61.71286795496141
At time: 527.7101683616638 and batch: 800, loss is 4.046062531471253 and perplexity is 57.17190071658509
At time: 528.1012551784515 and batch: 850, loss is 4.011300897598266 and perplexity is 55.21865767865061
At time: 528.4955942630768 and batch: 900, loss is 3.925293312072754 and perplexity is 50.66793739726057
At time: 528.8926050662994 and batch: 950, loss is 4.050248351097107 and perplexity is 57.41171353710897
At time: 529.2884664535522 and batch: 1000, loss is 4.075614666938781 and perplexity is 58.886665152684884
At time: 529.6810390949249 and batch: 1050, loss is 3.992411160469055 and perplexity is 54.185381631397554
At time: 530.0718333721161 and batch: 1100, loss is 4.117774271965027 and perplexity is 61.42238049814352
At time: 530.4570467472076 and batch: 1150, loss is 4.036081466674805 and perplexity is 56.60410259963621
At time: 530.8597319126129 and batch: 1200, loss is 3.9924166774749756 and perplexity is 54.18568057329345
At time: 531.2543866634369 and batch: 1250, loss is 3.954302749633789 and perplexity is 52.15931316244497
At time: 531.6458253860474 and batch: 1300, loss is 4.021378998756409 and perplexity is 55.7779705684722
At time: 532.0324368476868 and batch: 1350, loss is 3.988308424949646 and perplexity is 53.96352875457825
At time: 532.424122095108 and batch: 1400, loss is 3.8570134019851685 and perplexity is 47.323802924049076
At time: 532.8327701091766 and batch: 1450, loss is 3.9392433643341063 and perplexity is 51.37971086769223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681873810596955 and perplexity of 107.97220259296493
Finished 43 epochs...
Completing Train Step...
At time: 534.133252620697 and batch: 50, loss is 4.164641098976135 and perplexity is 64.36957599051688
At time: 534.5349533557892 and batch: 100, loss is 4.179134106636047 and perplexity is 65.30927785313244
At time: 534.9240386486053 and batch: 150, loss is 4.0483676528930665 and perplexity is 57.3038409003017
At time: 535.3045201301575 and batch: 200, loss is 4.132831888198853 and perplexity is 62.354253417213584
At time: 535.6872065067291 and batch: 250, loss is 4.159709482192993 and perplexity is 64.05291138527485
At time: 536.082300901413 and batch: 300, loss is 4.174390325546264 and perplexity is 65.00019861759422
At time: 536.4824011325836 and batch: 350, loss is 4.159411797523498 and perplexity is 64.03384665329894
At time: 536.8763916492462 and batch: 400, loss is 4.021214952468872 and perplexity is 55.768821149958725
At time: 537.2882912158966 and batch: 450, loss is 4.077529230117798 and perplexity is 58.99951538850288
At time: 537.68932056427 and batch: 500, loss is 4.06111545085907 and perplexity is 58.039014654176746
At time: 538.086300611496 and batch: 550, loss is 4.103923206329346 and perplexity is 60.577479968654906
At time: 538.4741747379303 and batch: 600, loss is 4.040511808395386 and perplexity is 56.855434448834544
At time: 538.867178440094 and batch: 650, loss is 4.118965268135071 and perplexity is 61.49557789833104
At time: 539.2671151161194 and batch: 700, loss is 4.16637321472168 and perplexity is 64.48116816400433
At time: 539.6704325675964 and batch: 750, loss is 4.1216960048675535 and perplexity is 61.66373562452823
At time: 540.0710997581482 and batch: 800, loss is 4.045196299552917 and perplexity is 57.122398034849354
At time: 540.4641587734222 and batch: 850, loss is 4.010637845993042 and perplexity is 55.18205699445056
At time: 540.8742938041687 and batch: 900, loss is 3.9246590328216553 and perplexity is 50.63580996583221
At time: 541.2802791595459 and batch: 950, loss is 4.049609541893005 and perplexity is 57.37505011778988
At time: 541.6816785335541 and batch: 1000, loss is 4.074873042106629 and perplexity is 58.84300952957298
At time: 542.0700604915619 and batch: 1050, loss is 3.9919332695007324 and perplexity is 54.15949311333797
At time: 542.4684989452362 and batch: 1100, loss is 4.1172124290466305 and perplexity is 61.3878804613378
At time: 542.861031293869 and batch: 1150, loss is 4.03542585849762 and perplexity is 56.56700464929825
At time: 543.245002746582 and batch: 1200, loss is 3.991810302734375 and perplexity is 54.15283370505361
At time: 543.6238913536072 and batch: 1250, loss is 3.9538176012039186 and perplexity is 52.134014290911196
At time: 544.0187544822693 and batch: 1300, loss is 4.0208615922927855 and perplexity is 55.74911815082966
At time: 544.4163165092468 and batch: 1350, loss is 3.987798948287964 and perplexity is 53.93604259846784
At time: 544.8108835220337 and batch: 1400, loss is 3.8564587020874024 and perplexity is 47.29755969463644
At time: 545.19593501091 and batch: 1450, loss is 3.9386532354354857 and perplexity is 51.349399160293366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6818258171407585 and perplexity of 107.9670207581374
Finished 44 epochs...
Completing Train Step...
At time: 546.5194439888 and batch: 50, loss is 4.163859944343567 and perplexity is 64.31931303216273
At time: 546.9101479053497 and batch: 100, loss is 4.178299293518067 and perplexity is 65.2547795623639
At time: 547.3113570213318 and batch: 150, loss is 4.047606520652771 and perplexity is 57.26024169398532
At time: 547.7043240070343 and batch: 200, loss is 4.13193293094635 and perplexity is 62.29822479632053
At time: 548.097067117691 and batch: 250, loss is 4.158692674636841 and perplexity is 63.9878150018406
At time: 548.4748749732971 and batch: 300, loss is 4.173449029922486 and perplexity is 64.93904300236274
At time: 548.8672499656677 and batch: 350, loss is 4.158498282432556 and perplexity is 63.975377478353
At time: 549.2559769153595 and batch: 400, loss is 4.020489492416382 and perplexity is 55.72837776984203
At time: 549.6369364261627 and batch: 450, loss is 4.076687564849854 and perplexity is 58.949878437353966
At time: 550.0349662303925 and batch: 500, loss is 4.060364928245544 and perplexity is 57.99547140335317
At time: 550.4379026889801 and batch: 550, loss is 4.103114252090454 and perplexity is 60.52849537527144
At time: 550.8326816558838 and batch: 600, loss is 4.039655804634094 and perplexity is 56.80678680734904
At time: 551.2264091968536 and batch: 650, loss is 4.11817087650299 and perplexity is 61.446745724341845
At time: 551.6269516944885 and batch: 700, loss is 4.165572919845581 and perplexity is 64.42958485919823
At time: 552.0154714584351 and batch: 750, loss is 4.12089807510376 and perplexity is 61.61455191970728
At time: 552.3976051807404 and batch: 800, loss is 4.044342484474182 and perplexity is 57.073646885268616
At time: 552.7894146442413 and batch: 850, loss is 4.009978175163269 and perplexity is 55.145667005151324
At time: 553.1804931163788 and batch: 900, loss is 3.9240305614471436 and perplexity is 50.603996806620536
At time: 553.5729384422302 and batch: 950, loss is 4.048975844383239 and perplexity is 57.33870320909662
At time: 553.9544308185577 and batch: 1000, loss is 4.074127125740051 and perplexity is 58.799133931503874
At time: 554.3494527339935 and batch: 1050, loss is 3.9914485597610474 and perplexity is 54.13324784071301
At time: 554.7449843883514 and batch: 1100, loss is 4.11665554523468 and perplexity is 61.35370406148409
At time: 555.1425454616547 and batch: 1150, loss is 4.034773478507995 and perplexity is 56.53011350222354
At time: 555.5301358699799 and batch: 1200, loss is 3.9912078189849853 and perplexity is 54.120217329167744
At time: 555.9161942005157 and batch: 1250, loss is 3.9533334589004516 and perplexity is 52.108780118101585
At time: 556.303927898407 and batch: 1300, loss is 4.020347661972046 and perplexity is 55.720474349746866
At time: 556.7112653255463 and batch: 1350, loss is 3.9872916316986085 and perplexity is 53.90868688888282
At time: 557.1095840930939 and batch: 1400, loss is 3.8559058713912964 and perplexity is 47.27141937803681
At time: 557.5060112476349 and batch: 1450, loss is 3.9380564880371094 and perplexity is 51.318765681069856
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681781997028579 and perplexity of 107.9622897348338
Finished 45 epochs...
Completing Train Step...
At time: 558.7892565727234 and batch: 50, loss is 4.163074750900268 and perplexity is 64.26882975145656
At time: 559.1817824840546 and batch: 100, loss is 4.177478179931641 and perplexity is 65.20121996855038
At time: 559.5834786891937 and batch: 150, loss is 4.046850843429565 and perplexity is 57.216987778599616
At time: 559.9782290458679 and batch: 200, loss is 4.131047368049622 and perplexity is 62.2430802205078
At time: 560.3756465911865 and batch: 250, loss is 4.157683906555175 and perplexity is 63.923298682923914
At time: 560.7685534954071 and batch: 300, loss is 4.172519564628601 and perplexity is 64.87871245759106
At time: 561.165333032608 and batch: 350, loss is 4.157601318359375 and perplexity is 63.91801959101442
At time: 561.5468344688416 and batch: 400, loss is 4.019780697822571 and perplexity is 55.688891792333735
At time: 561.9481346607208 and batch: 450, loss is 4.075854034423828 and perplexity is 58.9007623927684
At time: 562.3584578037262 and batch: 500, loss is 4.05962504863739 and perplexity is 57.95257760677597
At time: 562.7670402526855 and batch: 550, loss is 4.102309608459473 and perplexity is 60.479811096349074
At time: 563.1634278297424 and batch: 600, loss is 4.03881311416626 and perplexity is 56.758936433956606
At time: 563.541365146637 and batch: 650, loss is 4.117389235496521 and perplexity is 61.398735194113584
At time: 563.9443967342377 and batch: 700, loss is 4.16478497505188 and perplexity is 64.37883789877529
At time: 564.3440699577332 and batch: 750, loss is 4.120100831985473 and perplexity is 61.56544971799994
At time: 564.7402422428131 and batch: 800, loss is 4.043501186370849 and perplexity is 57.02565112659502
At time: 565.1319117546082 and batch: 850, loss is 4.009328570365906 and perplexity is 55.10985574815247
At time: 565.5420398712158 and batch: 900, loss is 3.923402714729309 and perplexity is 50.572235225061895
At time: 565.9398005008698 and batch: 950, loss is 4.04834623336792 and perplexity is 57.302613492385845
At time: 566.3251333236694 and batch: 1000, loss is 4.073383312225342 and perplexity is 58.755414602561984
At time: 566.7328190803528 and batch: 1050, loss is 3.990961184501648 and perplexity is 54.10687106322103
At time: 567.1368699073792 and batch: 1100, loss is 4.116104240417481 and perplexity is 61.31988879099918
At time: 567.5224661827087 and batch: 1150, loss is 4.0341340970993045 and perplexity is 56.49398075115462
At time: 567.9009437561035 and batch: 1200, loss is 3.990604224205017 and perplexity is 54.087560505232815
At time: 568.2914543151855 and batch: 1250, loss is 3.952848753929138 and perplexity is 52.083528853530375
At time: 568.7038605213165 and batch: 1300, loss is 4.019831628799438 and perplexity is 55.69172815422209
At time: 569.1117956638336 and batch: 1350, loss is 3.986792244911194 and perplexity is 53.88177232387206
At time: 569.4912042617798 and batch: 1400, loss is 3.8553566551208496 and perplexity is 47.24546427352255
At time: 569.892608165741 and batch: 1450, loss is 3.9374579906463625 and perplexity is 51.28806072304855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681738698584402 and perplexity of 107.9576152368585
Finished 46 epochs...
Completing Train Step...
At time: 571.1796617507935 and batch: 50, loss is 4.16230320930481 and perplexity is 64.21926279995313
At time: 571.5868101119995 and batch: 100, loss is 4.176674752235413 and perplexity is 65.14885654053064
At time: 571.9722907543182 and batch: 150, loss is 4.046097435951233 and perplexity is 57.173896306876394
At time: 572.3572397232056 and batch: 200, loss is 4.130170783996582 and perplexity is 62.18854283576752
At time: 572.7392451763153 and batch: 250, loss is 4.156690411567688 and perplexity is 63.85982274283397
At time: 573.1255795955658 and batch: 300, loss is 4.171601490974426 and perplexity is 64.81917635441258
At time: 573.5251252651215 and batch: 350, loss is 4.15671332359314 and perplexity is 63.8612859174801
At time: 573.923357963562 and batch: 400, loss is 4.0190821504592895 and perplexity is 55.65000404785514
At time: 574.3148498535156 and batch: 450, loss is 4.075026669502258 and perplexity is 58.852050122301605
At time: 574.6985323429108 and batch: 500, loss is 4.05890311717987 and perplexity is 57.910754916331676
At time: 575.0965015888214 and batch: 550, loss is 4.101509013175964 and perplexity is 60.43141062201878
At time: 575.5025551319122 and batch: 600, loss is 4.037981677055359 and perplexity is 56.71176456077056
At time: 575.8900833129883 and batch: 650, loss is 4.116616902351379 and perplexity is 61.351333223266245
At time: 576.2906179428101 and batch: 700, loss is 4.164015183448791 and perplexity is 64.3292986798279
At time: 576.6942749023438 and batch: 750, loss is 4.119309992790222 and perplexity is 61.51678059455146
At time: 577.1218938827515 and batch: 800, loss is 4.042673468589783 and perplexity is 56.9784695104057
At time: 577.5191426277161 and batch: 850, loss is 4.00868335723877 and perplexity is 55.07430961443839
At time: 577.9118914604187 and batch: 900, loss is 3.9227693033218385 and perplexity is 50.54021233727094
At time: 578.2925815582275 and batch: 950, loss is 4.047720432281494 and perplexity is 57.2667646728923
At time: 578.6725580692291 and batch: 1000, loss is 4.072646174430847 and perplexity is 58.712119724932954
At time: 579.0664930343628 and batch: 1050, loss is 3.9904733753204344 and perplexity is 54.08048367127893
At time: 579.4731421470642 and batch: 1100, loss is 4.115556931495666 and perplexity is 61.28633705119999
At time: 579.8693904876709 and batch: 1150, loss is 4.033506326675415 and perplexity is 56.458526630599756
At time: 580.2517428398132 and batch: 1200, loss is 3.9899988412857055 and perplexity is 54.054826729189884
At time: 580.6348583698273 and batch: 1250, loss is 3.9523603296279908 and perplexity is 52.058096203816476
At time: 581.0257480144501 and batch: 1300, loss is 4.019307045936585 and perplexity is 55.662520889514745
At time: 581.4159851074219 and batch: 1350, loss is 3.9862918138504027 and perplexity is 53.85481495710512
At time: 581.8116240501404 and batch: 1400, loss is 3.854809365272522 and perplexity is 47.21961438488216
At time: 582.2031996250153 and batch: 1450, loss is 3.9368573951721193 and perplexity is 51.25726659422844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681696443476229 and perplexity of 107.95305357252602
Finished 47 epochs...
Completing Train Step...
At time: 583.4344534873962 and batch: 50, loss is 4.161540608406067 and perplexity is 64.1703078013608
At time: 583.8486535549164 and batch: 100, loss is 4.175880656242371 and perplexity is 65.09714263022255
At time: 584.2293519973755 and batch: 150, loss is 4.045346760749817 and perplexity is 57.130993385844654
At time: 584.6181836128235 and batch: 200, loss is 4.12930389881134 and perplexity is 62.134655869572384
At time: 585.0109708309174 and batch: 250, loss is 4.155709838867187 and perplexity is 63.79723423529949
At time: 585.4031567573547 and batch: 300, loss is 4.1706907844543455 and perplexity is 64.7601719797928
At time: 585.7929437160492 and batch: 350, loss is 4.155835604667663 and perplexity is 63.805258250094
At time: 586.1794083118439 and batch: 400, loss is 4.018389887809754 and perplexity is 55.6114929600381
At time: 586.5722286701202 and batch: 450, loss is 4.074203953742981 and perplexity is 58.80365152507448
At time: 586.9609739780426 and batch: 500, loss is 4.058194699287415 and perplexity is 57.869744429379836
At time: 587.3608636856079 and batch: 550, loss is 4.100712924003601 and perplexity is 60.38332097471549
At time: 587.7532024383545 and batch: 600, loss is 4.037158184051513 and perplexity is 56.66508204342038
At time: 588.1378035545349 and batch: 650, loss is 4.115844802856445 and perplexity is 61.30398217208472
At time: 588.5311193466187 and batch: 700, loss is 4.163252925872802 and perplexity is 64.28028186864236
At time: 588.9331052303314 and batch: 750, loss is 4.118526306152344 and perplexity is 61.468589601379364
At time: 589.3256165981293 and batch: 800, loss is 4.041855554580689 and perplexity is 56.93188507560435
At time: 589.7222201824188 and batch: 850, loss is 4.008034176826477 and perplexity is 55.03856805403186
At time: 590.1244149208069 and batch: 900, loss is 3.9221216821670533 and perplexity is 50.507492022921475
At time: 590.5145361423492 and batch: 950, loss is 4.04710021018982 and perplexity is 57.23125757260568
At time: 590.9167141914368 and batch: 1000, loss is 4.0719118356704715 and perplexity is 58.669020966196406
At time: 591.3202912807465 and batch: 1050, loss is 3.9899860620498657 and perplexity is 54.05413595422463
At time: 591.7186737060547 and batch: 1100, loss is 4.115015501976013 and perplexity is 61.253163800468066
At time: 592.1214995384216 and batch: 1150, loss is 4.032884459495545 and perplexity is 56.42342784038833
At time: 592.5155248641968 and batch: 1200, loss is 3.9893916940689085 and perplexity is 54.02201745262515
At time: 592.9110798835754 and batch: 1250, loss is 3.9518649053573607 and perplexity is 52.032311747124524
At time: 593.306823015213 and batch: 1300, loss is 4.0187732696533205 and perplexity is 55.63281748418912
At time: 593.6859829425812 and batch: 1350, loss is 3.9857835817337035 and perplexity is 53.82745116467311
At time: 594.0703539848328 and batch: 1400, loss is 3.854259042739868 and perplexity is 47.19363551613701
At time: 594.4678792953491 and batch: 1450, loss is 3.936257925033569 and perplexity is 51.226548601701026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6816547100360575 and perplexity of 107.94854841423198
Finished 48 epochs...
Completing Train Step...
At time: 595.802797794342 and batch: 50, loss is 4.160791482925415 and perplexity is 64.1222541900251
At time: 596.1864020824432 and batch: 100, loss is 4.175090389251709 and perplexity is 65.045718829158
At time: 596.5856730937958 and batch: 150, loss is 4.044597945213318 and perplexity is 57.0882288237642
At time: 596.9821133613586 and batch: 200, loss is 4.128448495864868 and perplexity is 62.08152842778814
At time: 597.3787095546722 and batch: 250, loss is 4.15473813533783 and perplexity is 63.7352723467981
At time: 597.7703382968903 and batch: 300, loss is 4.169785938262939 and perplexity is 64.70160048791402
At time: 598.1670792102814 and batch: 350, loss is 4.154966964721679 and perplexity is 63.74985851870741
At time: 598.568484544754 and batch: 400, loss is 4.017703609466553 and perplexity is 55.57334108968514
At time: 598.9568169116974 and batch: 450, loss is 4.073386011123657 and perplexity is 58.75557317766542
At time: 599.3421967029572 and batch: 500, loss is 4.057495284080505 and perplexity is 57.82928360121459
At time: 599.7319569587708 and batch: 550, loss is 4.099920921325683 and perplexity is 60.33551615607299
At time: 600.1226959228516 and batch: 600, loss is 4.03633897781372 and perplexity is 56.61868066349029
At time: 600.5107042789459 and batch: 650, loss is 4.115067024230957 and perplexity is 61.25631978289044
At time: 600.9083559513092 and batch: 700, loss is 4.162496094703674 and perplexity is 64.23165095278158
At time: 601.3120520114899 and batch: 750, loss is 4.1177492570877074 and perplexity is 61.42084404404786
At time: 601.7020876407623 and batch: 800, loss is 4.041046438217163 and perplexity is 56.885839186536515
At time: 602.1027402877808 and batch: 850, loss is 4.007389674186706 and perplexity is 55.003106980237156
At time: 602.4948618412018 and batch: 900, loss is 3.9214670991897584 and perplexity is 50.47444149675345
At time: 602.8913521766663 and batch: 950, loss is 4.046483907699585 and perplexity is 57.19599667285068
At time: 603.2748477458954 and batch: 1000, loss is 4.071178154945374 and perplexity is 58.625992422889716
At time: 603.6685788631439 and batch: 1050, loss is 3.989490604400635 and perplexity is 54.02736105255619
At time: 604.0633051395416 and batch: 1100, loss is 4.114471592903137 and perplexity is 61.2198567077707
At time: 604.4622235298157 and batch: 1150, loss is 4.032266488075257 and perplexity is 56.38857054606341
At time: 604.8548810482025 and batch: 1200, loss is 3.9887862634658813 and perplexity is 53.9893207688073
At time: 605.243985414505 and batch: 1250, loss is 3.951369161605835 and perplexity is 52.00652344642107
At time: 605.6354734897614 and batch: 1300, loss is 4.018226194381714 and perplexity is 55.60239046914634
At time: 606.0419614315033 and batch: 1350, loss is 3.985279612541199 and perplexity is 53.800330622108056
At time: 606.4346344470978 and batch: 1400, loss is 3.853713421821594 and perplexity is 47.16789270493679
At time: 606.8303887844086 and batch: 1450, loss is 3.9356551456451414 and perplexity is 51.19567959859771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681617671607906 and perplexity of 107.94455024372095
Finished 49 epochs...
Completing Train Step...
At time: 608.2121744155884 and batch: 50, loss is 4.1600402116775514 and perplexity is 64.0740990751455
At time: 608.603268623352 and batch: 100, loss is 4.174303278923035 and perplexity is 64.99454081604516
At time: 609.0014145374298 and batch: 150, loss is 4.0438508129119874 and perplexity is 57.04559229353203
At time: 609.3975703716278 and batch: 200, loss is 4.1276103162765505 and perplexity is 62.0295147592912
At time: 609.7863092422485 and batch: 250, loss is 4.153779110908508 and perplexity is 63.67417796379347
At time: 610.1828317642212 and batch: 300, loss is 4.168893866539001 and perplexity is 64.64390775647836
At time: 610.5810883045197 and batch: 350, loss is 4.154096159934998 and perplexity is 63.69436900053454
At time: 610.9727318286896 and batch: 400, loss is 4.017019414901734 and perplexity is 55.535331116354094
At time: 611.3502750396729 and batch: 450, loss is 4.072573752403259 and perplexity is 58.70786782814582
At time: 611.7385070323944 and batch: 500, loss is 4.056798601150513 and perplexity is 57.78900895743337
At time: 612.1353282928467 and batch: 550, loss is 4.0991345357894895 and perplexity is 60.28808782976812
At time: 612.5314733982086 and batch: 600, loss is 4.0355197620391845 and perplexity is 56.57231674077873
At time: 612.9096131324768 and batch: 650, loss is 4.114286937713623 and perplexity is 61.20855318718729
At time: 613.3081159591675 and batch: 700, loss is 4.161746282577514 and perplexity is 64.18350733360424
At time: 613.704873085022 and batch: 750, loss is 4.1169797229766845 and perplexity is 61.37359679094618
At time: 614.0955486297607 and batch: 800, loss is 4.040246968269348 and perplexity is 56.84037884216157
At time: 614.4869167804718 and batch: 850, loss is 4.006759419441223 and perplexity is 54.96845193294767
At time: 614.8947720527649 and batch: 900, loss is 3.920823736190796 and perplexity is 50.44197855254944
At time: 615.2943568229675 and batch: 950, loss is 4.045852656364441 and perplexity is 57.15990301686886
At time: 615.6849784851074 and batch: 1000, loss is 4.070439200401307 and perplexity is 58.58268648191993
At time: 616.0931007862091 and batch: 1050, loss is 3.9889804220199583 and perplexity is 53.99980427496164
At time: 616.4892840385437 and batch: 1100, loss is 4.1139195442199705 and perplexity is 61.186069693388
At time: 616.898832321167 and batch: 1150, loss is 4.0316507577896115 and perplexity is 56.35386108234457
At time: 617.3074054718018 and batch: 1200, loss is 3.988163275718689 and perplexity is 53.95569655831217
At time: 617.6988935470581 and batch: 1250, loss is 3.950867495536804 and perplexity is 51.980440081356384
At time: 618.0847237110138 and batch: 1300, loss is 4.0176654624938966 and perplexity is 55.57122117539658
At time: 618.4755291938782 and batch: 1350, loss is 3.984777069091797 and perplexity is 53.773300410874924
At time: 618.8687117099762 and batch: 1400, loss is 3.8531669569015503 and perplexity is 47.14212414766871
At time: 619.2716672420502 and batch: 1450, loss is 3.93504638671875 and perplexity is 51.16452325596242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.681580111511752 and perplexity of 107.94049591217549
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7fb370c6a0>
SETTINGS FOR THIS RUN
{'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.20019797681469986, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 2.5878190891379167, 'anneal': 7.684145487285577, 'wordvec_dim': 200}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6262900829315186 and batch: 50, loss is 6.810872764587402 and perplexity is 907.662637163648
At time: 1.0475833415985107 and batch: 100, loss is 5.944442596435547 and perplexity is 381.6265819841141
At time: 1.4540963172912598 and batch: 150, loss is 5.744775981903076 and perplexity is 312.55360232367764
At time: 1.8649718761444092 and batch: 200, loss is 5.5961708736419675 and perplexity is 269.3928905377516
At time: 2.2810800075531006 and batch: 250, loss is 5.516225652694702 and perplexity is 248.69460373742945
At time: 2.6822009086608887 and batch: 300, loss is 5.535368356704712 and perplexity is 253.50114928883096
At time: 3.085703134536743 and batch: 350, loss is 5.528437023162842 and perplexity is 251.7501237513102
At time: 3.4929847717285156 and batch: 400, loss is 5.378798389434815 and perplexity is 216.76165577893477
At time: 3.897595167160034 and batch: 450, loss is 5.3869536590576175 and perplexity is 218.53663339865952
At time: 4.298762798309326 and batch: 500, loss is 5.340060729980468 and perplexity is 208.52537364643837
At time: 4.695980072021484 and batch: 550, loss is 5.387771091461182 and perplexity is 218.7153453566869
At time: 5.089721441268921 and batch: 600, loss is 5.194133605957031 and perplexity is 180.2119405886514
At time: 5.506402969360352 and batch: 650, loss is 5.34372052192688 and perplexity is 209.2899313371931
At time: 5.907331228256226 and batch: 700, loss is 5.3353504467010495 and perplexity is 207.545469689969
At time: 6.302538871765137 and batch: 750, loss is 5.262806949615478 and perplexity is 193.0225361327862
At time: 6.70870041847229 and batch: 800, loss is 5.161380290985107 and perplexity is 174.40501921880877
At time: 7.123717784881592 and batch: 850, loss is 5.09118911743164 and perplexity is 162.58307752435366
At time: 7.542954206466675 and batch: 900, loss is 5.0761404132843015 and perplexity is 160.15473045710783
At time: 7.934948444366455 and batch: 950, loss is 5.085480737686157 and perplexity is 161.6576354779775
At time: 8.319689750671387 and batch: 1000, loss is 5.134964551925659 and perplexity is 169.85829861836586
At time: 8.700653553009033 and batch: 1050, loss is 5.042137250900269 and perplexity is 154.80050925330826
At time: 9.101755857467651 and batch: 1100, loss is 5.133113689422608 and perplexity is 169.54420502431452
At time: 9.50181269645691 and batch: 1150, loss is 5.086149225234985 and perplexity is 161.76573772294418
At time: 9.922222375869751 and batch: 1200, loss is 5.024358940124512 and perplexity is 152.07273712832665
At time: 10.322133779525757 and batch: 1250, loss is 5.024081497192383 and perplexity is 152.03055147456723
At time: 10.724343299865723 and batch: 1300, loss is 5.106828994750977 and perplexity is 165.14584535953608
At time: 11.128818988800049 and batch: 1350, loss is 5.0288370418548585 and perplexity is 152.75526138154223
At time: 11.535130262374878 and batch: 1400, loss is 4.889515295028686 and perplexity is 132.88914640844695
At time: 11.951041221618652 and batch: 1450, loss is 4.960706176757813 and perplexity is 142.69452788456792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.958230043068911 and perplexity of 142.3416342430743
Finished 1 epochs...
Completing Train Step...
At time: 13.24684453010559 and batch: 50, loss is 4.931225414276123 and perplexity is 138.54918851047313
At time: 13.65972089767456 and batch: 100, loss is 4.891862688064575 and perplexity is 133.20145587840003
At time: 14.036932229995728 and batch: 150, loss is 4.766407375335693 and perplexity is 117.49636246210504
At time: 14.435935020446777 and batch: 200, loss is 4.828203859329224 and perplexity is 124.98626600791079
At time: 14.823456048965454 and batch: 250, loss is 4.82553653717041 and perplexity is 124.65333159010693
At time: 15.20902132987976 and batch: 300, loss is 4.852209749221802 and perplexity is 128.02297618056136
At time: 15.606937646865845 and batch: 350, loss is 4.876018877029419 and perplexity is 131.10766777288268
At time: 16.01415252685547 and batch: 400, loss is 4.715161256790161 and perplexity is 111.62681030355353
At time: 16.41242265701294 and batch: 450, loss is 4.771789703369141 and perplexity is 118.13047138792169
At time: 16.819108724594116 and batch: 500, loss is 4.734483804702759 and perplexity is 113.80469810357336
At time: 17.2144832611084 and batch: 550, loss is 4.797540187835693 and perplexity is 121.21189202447678
At time: 17.611984729766846 and batch: 600, loss is 4.657306928634643 and perplexity is 105.35197937489586
At time: 18.033538579940796 and batch: 650, loss is 4.7862194061279295 and perplexity is 119.8474166907586
At time: 18.438252687454224 and batch: 700, loss is 4.7979989433288575 and perplexity is 121.267511402652
At time: 18.83350658416748 and batch: 750, loss is 4.739157419204712 and perplexity is 114.33782222893822
At time: 19.229260444641113 and batch: 800, loss is 4.640691337585449 and perplexity is 103.61595643261853
At time: 19.61982274055481 and batch: 850, loss is 4.5942919731140135 and perplexity is 98.91807409193048
At time: 20.024726390838623 and batch: 900, loss is 4.548168687820435 and perplexity is 94.45926542073002
At time: 20.416357040405273 and batch: 950, loss is 4.620317897796631 and perplexity is 101.52630198771742
At time: 20.815327882766724 and batch: 1000, loss is 4.653857278823852 and perplexity is 104.98917806768962
At time: 21.210514783859253 and batch: 1050, loss is 4.587019567489624 and perplexity is 98.20131118784136
At time: 21.595022439956665 and batch: 1100, loss is 4.7001132392883305 and perplexity is 109.95962349664633
At time: 21.989092350006104 and batch: 1150, loss is 4.640924186706543 and perplexity is 103.64008612618512
At time: 22.397056818008423 and batch: 1200, loss is 4.571694202423096 and perplexity is 96.70781367217201
At time: 22.790305137634277 and batch: 1250, loss is 4.515078496932984 and perplexity is 91.3847391625956
At time: 23.17949080467224 and batch: 1300, loss is 4.636353759765625 and perplexity is 103.16748749581923
At time: 23.584321975708008 and batch: 1350, loss is 4.600146131515503 and perplexity is 99.49885449801401
At time: 23.977617502212524 and batch: 1400, loss is 4.4229394149780275 and perplexity is 83.34089915875373
At time: 24.364088535308838 and batch: 1450, loss is 4.531402387619019 and perplexity is 92.88873579610042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.698721600393964 and perplexity of 109.80670583554001
Finished 2 epochs...
Completing Train Step...
At time: 25.63103723526001 and batch: 50, loss is 4.567851867675781 and perplexity is 96.33694284058436
At time: 26.028504848480225 and batch: 100, loss is 4.566800718307495 and perplexity is 96.23573152739797
At time: 26.42021942138672 and batch: 150, loss is 4.418298788070679 and perplexity is 82.95504114364621
At time: 26.803999185562134 and batch: 200, loss is 4.540486936569214 and perplexity is 93.73643270543681
At time: 27.192347764968872 and batch: 250, loss is 4.5604074192047115 and perplexity is 95.62243030945008
At time: 27.574967861175537 and batch: 300, loss is 4.579450616836548 and perplexity is 97.46083615397579
At time: 27.980443239212036 and batch: 350, loss is 4.595105419158935 and perplexity is 98.99857134371867
At time: 28.36347508430481 and batch: 400, loss is 4.4142868709564205 and perplexity is 82.6228991030352
At time: 28.747442722320557 and batch: 450, loss is 4.49934419631958 and perplexity is 89.95811708749818
At time: 29.139639854431152 and batch: 500, loss is 4.462544965744018 and perplexity is 86.70789716535636
At time: 29.517414808273315 and batch: 550, loss is 4.526942930221558 and perplexity is 92.47542469269382
At time: 29.912843942642212 and batch: 600, loss is 4.421368379592895 and perplexity is 83.21007045231893
At time: 30.32019877433777 and batch: 650, loss is 4.526894702911377 and perplexity is 92.47096495924438
At time: 30.713249921798706 and batch: 700, loss is 4.543420829772949 and perplexity is 94.01184921204297
At time: 31.114874601364136 and batch: 750, loss is 4.499692616462707 and perplexity is 89.98946576846808
At time: 31.51962947845459 and batch: 800, loss is 4.40923128604889 and perplexity is 82.20624612101088
At time: 31.930196523666382 and batch: 850, loss is 4.367595868110657 and perplexity is 78.85382863117017
At time: 32.32157301902771 and batch: 900, loss is 4.304670653343201 and perplexity is 74.04482502104149
At time: 32.7188663482666 and batch: 950, loss is 4.411973080635071 and perplexity is 82.4319480343261
At time: 33.102224826812744 and batch: 1000, loss is 4.442334213256836 and perplexity is 84.97305559665024
At time: 33.48988676071167 and batch: 1050, loss is 4.375066165924072 and perplexity is 79.4450959365483
At time: 33.882272243499756 and batch: 1100, loss is 4.504747667312622 and perplexity is 90.44551880839089
At time: 34.27416276931763 and batch: 1150, loss is 4.440674505233765 and perplexity is 84.83214210450538
At time: 34.66511583328247 and batch: 1200, loss is 4.371223020553589 and perplexity is 79.14036282578371
At time: 35.057206869125366 and batch: 1250, loss is 4.286623253822326 and perplexity is 72.7204947851529
At time: 35.4529755115509 and batch: 1300, loss is 4.426534824371338 and perplexity is 83.64108312919721
At time: 35.8457145690918 and batch: 1350, loss is 4.4070251941680905 and perplexity is 82.0250914842499
At time: 36.25238537788391 and batch: 1400, loss is 4.225122423171997 and perplexity is 68.3828746845663
At time: 36.64286231994629 and batch: 1450, loss is 4.347670121192932 and perplexity is 77.29815762280172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.595494979467148 and perplexity of 99.03714477053413
Finished 3 epochs...
Completing Train Step...
At time: 37.988503217697144 and batch: 50, loss is 4.377135419845581 and perplexity is 79.60965821471066
At time: 38.37732768058777 and batch: 100, loss is 4.394484825134278 and perplexity is 81.00288935894102
At time: 38.7594780921936 and batch: 150, loss is 4.235544490814209 and perplexity is 69.09929242242718
At time: 39.15810227394104 and batch: 200, loss is 4.379364366531372 and perplexity is 79.78730180404268
At time: 39.549527406692505 and batch: 250, loss is 4.406444311141968 and perplexity is 81.97745833687333
At time: 39.92816495895386 and batch: 300, loss is 4.425638942718506 and perplexity is 83.5661841727088
At time: 40.321091175079346 and batch: 350, loss is 4.430565452575683 and perplexity is 83.9788895666445
At time: 40.72342801094055 and batch: 400, loss is 4.2384042549133305 and perplexity is 69.29718292338015
At time: 41.11814999580383 and batch: 450, loss is 4.334726567268372 and perplexity is 76.3040920007423
At time: 41.51740789413452 and batch: 500, loss is 4.304397897720337 and perplexity is 74.02463163272833
At time: 41.912867307662964 and batch: 550, loss is 4.363585610389709 and perplexity is 78.53823767954968
At time: 42.307039737701416 and batch: 600, loss is 4.272309489250183 and perplexity is 71.68700495368438
At time: 42.70601963996887 and batch: 650, loss is 4.3663787937164305 and perplexity is 78.75791603367908
At time: 43.0979528427124 and batch: 700, loss is 4.384285526275635 and perplexity is 80.1809155855605
At time: 43.478718996047974 and batch: 750, loss is 4.347651982307434 and perplexity is 77.29675553308763
At time: 43.872562885284424 and batch: 800, loss is 4.261289935112 and perplexity is 70.90138267507292
At time: 44.26649880409241 and batch: 850, loss is 4.221461873054505 and perplexity is 68.13301333859896
At time: 44.65816807746887 and batch: 900, loss is 4.148974909782409 and perplexity is 63.369008042109215
At time: 45.044926166534424 and batch: 950, loss is 4.277501912117004 and perplexity is 72.06020225807977
At time: 45.43548655509949 and batch: 1000, loss is 4.3043196439743046 and perplexity is 74.01883915464892
At time: 45.83094668388367 and batch: 1050, loss is 4.235089221000671 and perplexity is 69.06784076048984
At time: 46.22245955467224 and batch: 1100, loss is 4.373295392990112 and perplexity is 79.30454119292327
At time: 46.60800814628601 and batch: 1150, loss is 4.3069118928909305 and perplexity is 74.21096331950096
At time: 46.985902309417725 and batch: 1200, loss is 4.236365494728088 and perplexity is 69.15604650642692
At time: 47.383127212524414 and batch: 1250, loss is 4.138564863204956 and perplexity is 62.71275545327818
At time: 47.77678370475769 and batch: 1300, loss is 4.283518862724304 and perplexity is 72.49509197875273
At time: 48.16934680938721 and batch: 1350, loss is 4.273915076255799 and perplexity is 71.80219712809244
At time: 48.563008308410645 and batch: 1400, loss is 4.095699615478516 and perplexity is 60.08135830535425
At time: 48.94153118133545 and batch: 1450, loss is 4.217705039978028 and perplexity is 67.87752918663226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.542819552951389 and perplexity of 93.95533905698551
Finished 4 epochs...
Completing Train Step...
At time: 50.2439067363739 and batch: 50, loss is 4.243358678817749 and perplexity is 69.64136244456022
At time: 50.64951300621033 and batch: 100, loss is 4.273449883460999 and perplexity is 71.76880303128648
At time: 51.02985978126526 and batch: 150, loss is 4.109604864120484 and perplexity is 60.92264009202262
At time: 51.42992067337036 and batch: 200, loss is 4.261768093109131 and perplexity is 70.93529284476999
At time: 51.82494926452637 and batch: 250, loss is 4.295157079696655 and perplexity is 73.34373435177216
At time: 52.21889567375183 and batch: 300, loss is 4.314450278282165 and perplexity is 74.77250807238764
At time: 52.60211253166199 and batch: 350, loss is 4.308746633529663 and perplexity is 74.34724617335745
At time: 52.99359107017517 and batch: 400, loss is 4.1120300245285035 and perplexity is 61.07056656693971
At time: 53.393197536468506 and batch: 450, loss is 4.21016526222229 and perplexity is 67.36767222142954
At time: 53.78633260726929 and batch: 500, loss is 4.187030911445618 and perplexity is 65.8270541711642
At time: 54.184303998947144 and batch: 550, loss is 4.241230449676514 and perplexity is 69.49330727112057
At time: 54.581884145736694 and batch: 600, loss is 4.162545342445373 and perplexity is 64.23481429442967
At time: 54.97819662094116 and batch: 650, loss is 4.246403036117553 and perplexity is 69.85369868438116
At time: 55.37831377983093 and batch: 700, loss is 4.270293021202088 and perplexity is 71.54259604563835
At time: 55.784419536590576 and batch: 750, loss is 4.235568518638611 and perplexity is 69.10095274803875
At time: 56.18861746788025 and batch: 800, loss is 4.150101361274719 and perplexity is 63.440430375128955
At time: 56.5874183177948 and batch: 850, loss is 4.111447110176086 and perplexity is 61.034978030719564
At time: 56.98881459236145 and batch: 900, loss is 4.034976816177368 and perplexity is 56.541609372484565
At time: 57.3828911781311 and batch: 950, loss is 4.173036637306214 and perplexity is 64.91226814177767
At time: 57.81185722351074 and batch: 1000, loss is 4.20138798236847 and perplexity is 66.77895475780092
At time: 58.210949182510376 and batch: 1050, loss is 4.130641627311706 and perplexity is 62.217830789916704
At time: 58.61007523536682 and batch: 1100, loss is 4.276102995872497 and perplexity is 71.95946654739757
At time: 58.994497537612915 and batch: 1150, loss is 4.206291279792786 and perplexity is 67.10719590901923
At time: 59.3834228515625 and batch: 1200, loss is 4.133567337989807 and perplexity is 62.400128707272856
At time: 59.78779172897339 and batch: 1250, loss is 4.029238409996033 and perplexity is 56.21807981157479
At time: 60.18384027481079 and batch: 1300, loss is 4.175396475791931 and perplexity is 65.0656314955348
At time: 60.57985472679138 and batch: 1350, loss is 4.17476065158844 and perplexity is 65.02427434154755
At time: 60.96713995933533 and batch: 1400, loss is 3.996970295906067 and perplexity is 54.43298412272475
At time: 61.35071396827698 and batch: 1450, loss is 4.117660450935364 and perplexity is 61.41538973740617
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.511351495726496 and perplexity of 91.04478203331304
Finished 5 epochs...
Completing Train Step...
At time: 62.67577075958252 and batch: 50, loss is 4.140349917411804 and perplexity is 62.824801095243316
At time: 63.09903264045715 and batch: 100, loss is 4.178481874465942 and perplexity is 65.2666949295962
At time: 63.490381956100464 and batch: 150, loss is 4.011418871879577 and perplexity is 55.22517244438506
At time: 63.89073300361633 and batch: 200, loss is 4.168912258148193 and perplexity is 64.64509667289947
At time: 64.29858613014221 and batch: 250, loss is 4.206698966026306 and perplexity is 67.13456016659805
At time: 64.70151615142822 and batch: 300, loss is 4.2262642955780025 and perplexity is 68.46100380046353
At time: 65.09807252883911 and batch: 350, loss is 4.214086456298828 and perplexity is 67.63235253098699
At time: 65.47846746444702 and batch: 400, loss is 4.013038277626038 and perplexity is 55.3146768584117
At time: 65.866126537323 and batch: 450, loss is 4.11223081111908 and perplexity is 61.08282994890537
At time: 66.2867534160614 and batch: 500, loss is 4.0956824588775635 and perplexity is 60.08032752230752
At time: 66.67783737182617 and batch: 550, loss is 4.144263939857483 and perplexity is 63.07118062985407
At time: 67.08909749984741 and batch: 600, loss is 4.07290123462677 and perplexity is 58.72709675963456
At time: 67.48431468009949 and batch: 650, loss is 4.151408710479736 and perplexity is 63.523423409964195
At time: 67.90104675292969 and batch: 700, loss is 4.18019739151001 and perplexity is 65.37875715200092
At time: 68.2774863243103 and batch: 750, loss is 4.147699446678161 and perplexity is 63.28823473303668
At time: 68.67401003837585 and batch: 800, loss is 4.061250853538513 and perplexity is 58.04687382433749
At time: 69.0813090801239 and batch: 850, loss is 4.024283409118652 and perplexity is 55.94020817241761
At time: 69.47790360450745 and batch: 900, loss is 3.945289206504822 and perplexity is 51.69128540655765
At time: 69.86772894859314 and batch: 950, loss is 4.091225199699402 and perplexity is 59.81312985802389
At time: 70.26396179199219 and batch: 1000, loss is 4.116756043434143 and perplexity is 61.35987030811579
At time: 70.65356492996216 and batch: 1050, loss is 4.045819878578186 and perplexity is 57.1580294724909
At time: 71.04281234741211 and batch: 1100, loss is 4.195361523628235 and perplexity is 66.37772435579846
At time: 71.42135643959045 and batch: 1150, loss is 4.12298309803009 and perplexity is 61.74315369529125
At time: 71.82112979888916 and batch: 1200, loss is 4.050240073204041 and perplexity is 57.41123829105059
At time: 72.22471904754639 and batch: 1250, loss is 3.942271499633789 and perplexity is 51.535531387598866
At time: 72.61923003196716 and batch: 1300, loss is 4.087144527435303 and perplexity is 59.56954940199489
At time: 73.01434278488159 and batch: 1350, loss is 4.092837309837341 and perplexity is 59.909632976977946
At time: 73.39932656288147 and batch: 1400, loss is 3.9148327350616454 and perplexity is 50.14068403116719
At time: 73.79006218910217 and batch: 1450, loss is 4.036046404838562 and perplexity is 56.60211799065238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.495151617588141 and perplexity of 89.58175012444495
Finished 6 epochs...
Completing Train Step...
At time: 75.08848309516907 and batch: 50, loss is 4.055112290382385 and perplexity is 57.69164084886733
At time: 75.49849152565002 and batch: 100, loss is 4.100803294181824 and perplexity is 60.388778072769384
At time: 75.89169549942017 and batch: 150, loss is 3.9289981937408447 and perplexity is 50.8560042773324
At time: 76.28362798690796 and batch: 200, loss is 4.088629293441772 and perplexity is 59.6580619379092
At time: 76.68899178504944 and batch: 250, loss is 4.132216019630432 and perplexity is 62.31586321529937
At time: 77.08604621887207 and batch: 300, loss is 4.151162838935852 and perplexity is 63.50780672770511
At time: 77.49744510650635 and batch: 350, loss is 4.135239386558533 and perplexity is 62.50455202927079
At time: 77.90501928329468 and batch: 400, loss is 3.930894823074341 and perplexity is 50.952550794365884
At time: 78.30293488502502 and batch: 450, loss is 4.030487861633301 and perplexity is 56.28836548356963
At time: 78.7034101486206 and batch: 500, loss is 4.018018341064453 and perplexity is 55.59083452885156
At time: 79.11294746398926 and batch: 550, loss is 4.064669547080993 and perplexity is 58.24565789434337
At time: 79.51631879806519 and batch: 600, loss is 3.998077507019043 and perplexity is 54.49328630512067
At time: 79.92015838623047 and batch: 650, loss is 4.07054033279419 and perplexity is 58.58861138878033
At time: 80.32247567176819 and batch: 700, loss is 4.105746040344238 and perplexity is 60.688003361975404
At time: 80.71962237358093 and batch: 750, loss is 4.0709900331497195 and perplexity is 58.61496463323944
At time: 81.11922001838684 and batch: 800, loss is 3.986356019973755 and perplexity is 53.858272877005994
At time: 81.51360487937927 and batch: 850, loss is 3.9521351861953735 and perplexity is 52.04637698464375
At time: 81.90302681922913 and batch: 900, loss is 3.8711483001708986 and perplexity is 47.99746995130532
At time: 82.2959840297699 and batch: 950, loss is 4.021145176887512 and perplexity is 55.764929983796996
At time: 82.68907189369202 and batch: 1000, loss is 4.044597144126892 and perplexity is 57.08818309117734
At time: 83.09537029266357 and batch: 1050, loss is 3.9741187620162965 and perplexity is 53.20321155050745
At time: 83.4869794845581 and batch: 1100, loss is 4.126736068725586 and perplexity is 61.975309305870326
At time: 83.8808331489563 and batch: 1150, loss is 4.051702494621277 and perplexity is 57.49525913748569
At time: 84.26898145675659 and batch: 1200, loss is 3.9785572147369384 and perplexity is 53.43987631371994
At time: 84.66003680229187 and batch: 1250, loss is 3.869915556907654 and perplexity is 47.938337848409176
At time: 85.04910230636597 and batch: 1300, loss is 4.012003273963928 and perplexity is 55.25745558251799
At time: 85.4254961013794 and batch: 1350, loss is 4.020338258743286 and perplexity is 55.71995039984335
At time: 85.81918597221375 and batch: 1400, loss is 3.8445495557785034 and perplexity is 46.73762691469781
At time: 86.21747756004333 and batch: 1450, loss is 3.966023550033569 and perplexity is 52.774258848893744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.488107534555288 and perplexity of 88.95294611223237
Finished 7 epochs...
Completing Train Step...
At time: 87.50241351127625 and batch: 50, loss is 3.984758758544922 and perplexity is 53.77231580135152
At time: 87.89623785018921 and batch: 100, loss is 4.035527157783508 and perplexity is 56.57273513671631
At time: 88.30539274215698 and batch: 150, loss is 3.8607861852645873 and perplexity is 47.50268260138781
At time: 88.70516276359558 and batch: 200, loss is 4.018906855583191 and perplexity is 55.64024974225558
At time: 89.1085147857666 and batch: 250, loss is 4.068135604858399 and perplexity is 58.4478909832119
At time: 89.51091170310974 and batch: 300, loss is 4.084718565940857 and perplexity is 59.425211119251614
At time: 89.90635824203491 and batch: 350, loss is 4.065440974235535 and perplexity is 58.290607511925856
At time: 90.30451607704163 and batch: 400, loss is 3.860545735359192 and perplexity is 47.491261958951505
At time: 90.71841239929199 and batch: 450, loss is 3.959208540916443 and perplexity is 52.41582454747457
At time: 91.14901947975159 and batch: 500, loss is 3.9513291549682616 and perplexity is 52.004442881904566
At time: 91.5475583076477 and batch: 550, loss is 3.9970796155929564 and perplexity is 54.438935044776045
At time: 91.94119453430176 and batch: 600, loss is 3.931185412406921 and perplexity is 50.967359213574596
At time: 92.34238409996033 and batch: 650, loss is 4.001317129135132 and perplexity is 54.67011022730814
At time: 92.73726415634155 and batch: 700, loss is 4.041580801010132 and perplexity is 56.91624498558495
At time: 93.13283109664917 and batch: 750, loss is 4.005704445838928 and perplexity is 54.91049224554512
At time: 93.52578020095825 and batch: 800, loss is 3.9216824769973755 and perplexity is 50.485313742081864
At time: 93.92935466766357 and batch: 850, loss is 3.888661012649536 and perplexity is 48.84543929166285
At time: 94.32711505889893 and batch: 900, loss is 3.8063109493255616 and perplexity is 44.98418346022548
At time: 94.7211081981659 and batch: 950, loss is 3.958736472129822 and perplexity is 52.391086512267236
At time: 95.11263179779053 and batch: 1000, loss is 3.9808140325546266 and perplexity is 53.56061657189633
At time: 95.50326800346375 and batch: 1050, loss is 3.9123045778274537 and perplexity is 50.01408060222683
At time: 95.89414882659912 and batch: 1100, loss is 4.065580115318299 and perplexity is 58.29871869445631
At time: 96.29901003837585 and batch: 1150, loss is 3.990156440734863 and perplexity is 54.06334641143769
At time: 96.69303274154663 and batch: 1200, loss is 3.916723232269287 and perplexity is 50.2355645117007
At time: 97.08627939224243 and batch: 1250, loss is 3.80646812915802 and perplexity is 44.99125462235252
At time: 97.49562406539917 and batch: 1300, loss is 3.9456476259231565 and perplexity is 51.70981588764978
At time: 97.89912605285645 and batch: 1350, loss is 3.9582276439666746 and perplexity is 52.36443523298767
At time: 98.29262709617615 and batch: 1400, loss is 3.78374671459198 and perplexity is 43.98051586491216
At time: 98.69202542304993 and batch: 1450, loss is 3.905084662437439 and perplexity is 49.65428358690572
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4855977897970085 and perplexity of 88.72997683701541
Finished 8 epochs...
Completing Train Step...
At time: 100.06980752944946 and batch: 50, loss is 3.9237987327575685 and perplexity is 50.592266708092815
At time: 100.46803784370422 and batch: 100, loss is 3.9764780712127688 and perplexity is 53.328882566898805
At time: 100.86046409606934 and batch: 150, loss is 3.8021317291259766 and perplexity is 44.79657694956548
At time: 101.25508546829224 and batch: 200, loss is 3.958350977897644 and perplexity is 52.37089394290879
At time: 101.6549859046936 and batch: 250, loss is 4.010818996429443 and perplexity is 55.19205415362418
At time: 102.06574392318726 and batch: 300, loss is 4.025415053367615 and perplexity is 56.003548419835504
At time: 102.46615624427795 and batch: 350, loss is 4.004681067466736 and perplexity is 54.85432677953805
At time: 102.85515642166138 and batch: 400, loss is 3.799495830535889 and perplexity is 44.67865320134166
At time: 103.23233795166016 and batch: 450, loss is 3.89691792011261 and perplexity is 49.25042121215592
At time: 103.6135675907135 and batch: 500, loss is 3.8937323665618897 and perplexity is 49.093780983369726
At time: 104.00425696372986 and batch: 550, loss is 3.936844711303711 and perplexity is 51.25661645792711
At time: 104.39556002616882 and batch: 600, loss is 3.873258662223816 and perplexity is 48.09886894719038
At time: 104.78792262077332 and batch: 650, loss is 3.9401637935638427 and perplexity is 51.427024026257044
At time: 105.18182253837585 and batch: 700, loss is 3.98308002948761 and perplexity is 53.68212237867795
At time: 105.58040571212769 and batch: 750, loss is 3.948116855621338 and perplexity is 51.83765707039462
At time: 105.97521209716797 and batch: 800, loss is 3.8655926752090455 and perplexity is 47.73155335952418
At time: 106.3709602355957 and batch: 850, loss is 3.8312549066543578 and perplexity is 46.120378704566214
At time: 106.77330160140991 and batch: 900, loss is 3.7493249464035032 and perplexity is 42.49238767692438
At time: 107.17145442962646 and batch: 950, loss is 3.9047251749038696 and perplexity is 49.63643669902695
At time: 107.56340456008911 and batch: 1000, loss is 3.9241274881362913 and perplexity is 50.60890192220311
At time: 107.94652199745178 and batch: 1050, loss is 3.8561524820327757 and perplexity is 47.283078450659865
At time: 108.35974550247192 and batch: 1100, loss is 4.010893592834472 and perplexity is 55.19617143601553
At time: 108.74446272850037 and batch: 1150, loss is 3.936297278404236 and perplexity is 51.228564578723606
At time: 109.1232054233551 and batch: 1200, loss is 3.8610763502120973 and perplexity is 47.51646821474559
At time: 109.52082753181458 and batch: 1250, loss is 3.7509342861175536 and perplexity is 42.560827420585
At time: 109.92686009407043 and batch: 1300, loss is 3.8864812994003297 and perplexity is 48.73908619221378
At time: 110.3132438659668 and batch: 1350, loss is 3.9036291313171385 and perplexity is 49.582062804437356
At time: 110.70848059654236 and batch: 1400, loss is 3.729163589477539 and perplexity is 41.64426189431892
At time: 111.10028982162476 and batch: 1450, loss is 3.851240692138672 and perplexity is 47.05140333927565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.484827807825854 and perplexity of 88.66168265057028
Finished 9 epochs...
Completing Train Step...
At time: 112.35673832893372 and batch: 50, loss is 3.869129219055176 and perplexity is 47.90065693567968
At time: 112.78379893302917 and batch: 100, loss is 3.9251680183410644 and perplexity is 50.661589419996254
At time: 113.18559312820435 and batch: 150, loss is 3.7491881275177 and perplexity is 42.486574313485335
At time: 113.5967333316803 and batch: 200, loss is 3.903345251083374 and perplexity is 49.56798943452819
At time: 113.99323296546936 and batch: 250, loss is 3.9587300300598143 and perplexity is 52.39074900630727
At time: 114.40314865112305 and batch: 300, loss is 3.971761775016785 and perplexity is 53.07795993874603
At time: 114.81392908096313 and batch: 350, loss is 3.9507771158218383 and perplexity is 51.97574231629256
At time: 115.21453285217285 and batch: 400, loss is 3.743685145378113 and perplexity is 42.253413581933266
At time: 115.60611081123352 and batch: 450, loss is 3.8410504770278933 and perplexity is 46.57437406136788
At time: 116.0065324306488 and batch: 500, loss is 3.841489272117615 and perplexity is 46.59481515241007
At time: 116.41671657562256 and batch: 550, loss is 3.8823058652877807 and perplexity is 48.536003623104975
At time: 116.81775379180908 and batch: 600, loss is 3.8202106666564943 and perplexity is 45.613816618976244
At time: 117.19787287712097 and batch: 650, loss is 3.8855983304977415 and perplexity is 48.69607008850117
At time: 117.59317827224731 and batch: 700, loss is 3.9298115158081055 and perplexity is 50.89738341286489
At time: 117.98714971542358 and batch: 750, loss is 3.8967378187179564 and perplexity is 49.24155194131634
At time: 118.40687918663025 and batch: 800, loss is 3.8147967433929444 and perplexity is 45.367534194672764
At time: 118.7934250831604 and batch: 850, loss is 3.778874855041504 and perplexity is 43.76677006119991
At time: 119.18882322311401 and batch: 900, loss is 3.699043550491333 and perplexity is 40.40863705029774
At time: 119.5888729095459 and batch: 950, loss is 3.8563567066192626 and perplexity is 47.292735803905195
At time: 119.98210310935974 and batch: 1000, loss is 3.873377494812012 and perplexity is 48.10458499989661
At time: 120.39866709709167 and batch: 1050, loss is 3.8035189580917357 and perplexity is 44.85876318197558
At time: 120.80643129348755 and batch: 1100, loss is 3.9605858850479128 and perplexity is 52.48806891706934
At time: 121.21577167510986 and batch: 1150, loss is 3.88559720993042 and perplexity is 48.69601552130691
At time: 121.61402773857117 and batch: 1200, loss is 3.8111682510375977 and perplexity is 45.203216736270306
At time: 122.0171172618866 and batch: 1250, loss is 3.7006313467025755 and perplexity is 40.47284869512055
At time: 122.40881586074829 and batch: 1300, loss is 3.832811312675476 and perplexity is 46.19221662966616
At time: 122.81518578529358 and batch: 1350, loss is 3.8537058305740355 and perplexity is 47.16753464314552
At time: 123.20541214942932 and batch: 1400, loss is 3.6797834491729735 and perplexity is 39.63780954267463
At time: 123.60661792755127 and batch: 1450, loss is 3.8028019094467163 and perplexity is 44.82660879612581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.489152435563568 and perplexity of 89.04594171245152
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 125.00179028511047 and batch: 50, loss is 3.8431287145614625 and perplexity is 46.67126732237652
At time: 125.42031335830688 and batch: 100, loss is 3.9092191457748413 and perplexity is 49.860003374496465
At time: 125.83029627799988 and batch: 150, loss is 3.731897416114807 and perplexity is 41.75826584929578
At time: 126.23352098464966 and batch: 200, loss is 3.8816779232025147 and perplexity is 48.5055353909232
At time: 126.63093829154968 and batch: 250, loss is 3.938448066711426 and perplexity is 51.33886495026858
At time: 127.04300427436829 and batch: 300, loss is 3.940723571777344 and perplexity is 51.455819812767174
At time: 127.44369220733643 and batch: 350, loss is 3.9125421619415284 and perplexity is 50.02596456492244
At time: 127.85944175720215 and batch: 400, loss is 3.697890520095825 and perplexity is 40.36207151443581
At time: 128.2781584262848 and batch: 450, loss is 3.8059005880355836 and perplexity is 44.96572747974111
At time: 128.66893696784973 and batch: 500, loss is 3.7878029251098635 and perplexity is 44.159272387902
At time: 129.07690262794495 and batch: 550, loss is 3.828501706123352 and perplexity is 45.99357469196308
At time: 129.48208808898926 and batch: 600, loss is 3.7654719591140746 and perplexity is 43.18408217225276
At time: 129.90217542648315 and batch: 650, loss is 3.8181041860580445 and perplexity is 45.51783312841941
At time: 130.3170998096466 and batch: 700, loss is 3.864952077865601 and perplexity is 47.70098644483105
At time: 130.70929765701294 and batch: 750, loss is 3.8172941970825196 and perplexity is 45.48097911308361
At time: 131.12823748588562 and batch: 800, loss is 3.730138349533081 and perplexity is 41.68487484808284
At time: 131.54267001152039 and batch: 850, loss is 3.6798847198486326 and perplexity is 39.64182389369326
At time: 131.95691013336182 and batch: 900, loss is 3.5841038179397584 and perplexity is 36.021061820124174
At time: 132.3626344203949 and batch: 950, loss is 3.739621887207031 and perplexity is 42.08207538533774
At time: 132.76007604599 and batch: 1000, loss is 3.7552677679061888 and perplexity is 42.745664195264766
At time: 133.1641869544983 and batch: 1050, loss is 3.6747783041000366 and perplexity is 39.43991222107702
At time: 133.566490650177 and batch: 1100, loss is 3.8225849199295046 and perplexity is 45.72224403852172
At time: 133.95763230323792 and batch: 1150, loss is 3.7342896270751953 and perplexity is 41.8582800103377
At time: 134.36051082611084 and batch: 1200, loss is 3.6523533868789673 and perplexity is 38.565318451532534
At time: 134.7736783027649 and batch: 1250, loss is 3.5343462562561037 and perplexity is 34.272601889832686
At time: 135.1879677772522 and batch: 1300, loss is 3.6489474630355834 and perplexity is 38.43419134511953
At time: 135.580659866333 and batch: 1350, loss is 3.660337357521057 and perplexity is 38.874455249283784
At time: 135.98845553398132 and batch: 1400, loss is 3.4693902492523194 and perplexity is 32.11715301496112
At time: 136.38147377967834 and batch: 1450, loss is 3.580049295425415 and perplexity is 35.87530929210773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.441479805188301 and perplexity of 84.90048493923281
Finished 11 epochs...
Completing Train Step...
At time: 137.7327651977539 and batch: 50, loss is 3.786561894416809 and perplexity is 44.104503367532715
At time: 138.13702630996704 and batch: 100, loss is 3.8466307067871095 and perplexity is 46.83499625910209
At time: 138.54280066490173 and batch: 150, loss is 3.6693006229400633 and perplexity is 39.22446357515793
At time: 138.95719933509827 and batch: 200, loss is 3.8202171421051023 and perplexity is 45.6141119898579
At time: 139.37203335762024 and batch: 250, loss is 3.88229052066803 and perplexity is 48.5352588622992
At time: 139.76694560050964 and batch: 300, loss is 3.885048313140869 and perplexity is 48.66929376913625
At time: 140.15858125686646 and batch: 350, loss is 3.858282389640808 and perplexity is 47.383894365362316
At time: 140.57466793060303 and batch: 400, loss is 3.6472228574752807 and perplexity is 38.36796464889892
At time: 140.9911777973175 and batch: 450, loss is 3.75458655834198 and perplexity is 42.7165553557221
At time: 141.40053009986877 and batch: 500, loss is 3.7411526918411253 and perplexity is 42.14654415330482
At time: 141.8050901889801 and batch: 550, loss is 3.780686173439026 and perplexity is 43.846117457016724
At time: 142.21063375473022 and batch: 600, loss is 3.720199999809265 and perplexity is 41.27264780490329
At time: 142.62505984306335 and batch: 650, loss is 3.7736269283294677 and perplexity is 43.53768689109967
At time: 143.02830958366394 and batch: 700, loss is 3.8236193895339965 and perplexity is 45.76956678297899
At time: 143.425142288208 and batch: 750, loss is 3.778474597930908 and perplexity is 43.749255605651605
At time: 143.82603192329407 and batch: 800, loss is 3.6946484518051146 and perplexity is 40.231426816182164
At time: 144.22391629219055 and batch: 850, loss is 3.64718279838562 and perplexity is 38.36642769394767
At time: 144.6164722442627 and batch: 900, loss is 3.553492531776428 and perplexity is 34.935116675130146
At time: 145.00535821914673 and batch: 950, loss is 3.7126917839050293 and perplexity is 40.96392428597443
At time: 145.40088486671448 and batch: 1000, loss is 3.730248394012451 and perplexity is 41.689462290839856
At time: 145.80262517929077 and batch: 1050, loss is 3.652947268486023 and perplexity is 38.588228487082155
At time: 146.2067084312439 and batch: 1100, loss is 3.8039189863204954 and perplexity is 44.87671154324186
At time: 146.6170210838318 and batch: 1150, loss is 3.719049668312073 and perplexity is 41.22519787496765
At time: 147.01120257377625 and batch: 1200, loss is 3.6405204582214354 and perplexity is 38.111667094984135
At time: 147.41017842292786 and batch: 1250, loss is 3.525880227088928 and perplexity is 33.983673805103436
At time: 147.83603715896606 and batch: 1300, loss is 3.644696955680847 and perplexity is 38.271173232412
At time: 148.2555069923401 and batch: 1350, loss is 3.6610837411880492 and perplexity is 38.90348133869709
At time: 148.66396379470825 and batch: 1400, loss is 3.4750194120407105 and perplexity is 32.298455509458485
At time: 149.09387230873108 and batch: 1450, loss is 3.592408423423767 and perplexity is 36.321448096032675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.439729609041133 and perplexity of 84.75202239478347
Finished 12 epochs...
Completing Train Step...
At time: 150.5279734134674 and batch: 50, loss is 3.764402108192444 and perplexity is 43.13790634716984
At time: 150.9219892024994 and batch: 100, loss is 3.823815579414368 and perplexity is 45.77854718971445
At time: 151.33324003219604 and batch: 150, loss is 3.644790544509888 and perplexity is 38.27475515431217
At time: 151.73690247535706 and batch: 200, loss is 3.7952986192703246 and perplexity is 44.491520447366206
At time: 152.14389491081238 and batch: 250, loss is 3.858748116493225 and perplexity is 47.40596745695712
At time: 152.55009865760803 and batch: 300, loss is 3.861052541732788 and perplexity is 47.51533693336234
At time: 152.94874167442322 and batch: 350, loss is 3.833975248336792 and perplexity is 46.246012699385325
At time: 153.35352540016174 and batch: 400, loss is 3.6231023693084716 and perplexity is 37.45358261383187
At time: 153.75458145141602 and batch: 450, loss is 3.7296112155914307 and perplexity is 41.662907126171575
At time: 154.16292691230774 and batch: 500, loss is 3.7184906816482544 and perplexity is 41.202159978680534
At time: 154.5727982521057 and batch: 550, loss is 3.7577164459228514 and perplexity is 42.85046282016726
At time: 154.98195123672485 and batch: 600, loss is 3.698290271759033 and perplexity is 40.37820954504161
At time: 155.39468598365784 and batch: 650, loss is 3.7519825315475464 and perplexity is 42.60546500490984
At time: 155.80636930465698 and batch: 700, loss is 3.8035021734237673 and perplexity is 44.858010248848984
At time: 156.20779538154602 and batch: 750, loss is 3.7591292428970338 and perplexity is 42.91104460918927
At time: 156.6071057319641 and batch: 800, loss is 3.6766912078857423 and perplexity is 39.51542918378691
At time: 157.00523805618286 and batch: 850, loss is 3.6306465339660643 and perplexity is 37.73720711787467
At time: 157.4002661705017 and batch: 900, loss is 3.537968692779541 and perplexity is 34.39697734977098
At time: 157.79887437820435 and batch: 950, loss is 3.6986194753646853 and perplexity is 40.39150438544824
At time: 158.21978569030762 and batch: 1000, loss is 3.7171911573410035 and perplexity is 41.148651545562
At time: 158.63025379180908 and batch: 1050, loss is 3.6413806581497195 and perplexity is 38.14446485257802
At time: 159.03990077972412 and batch: 1100, loss is 3.7940115928649902 and perplexity is 44.434295518633256
At time: 159.44945192337036 and batch: 1150, loss is 3.710802102088928 and perplexity is 40.8865885960717
At time: 159.88318800926208 and batch: 1200, loss is 3.633376536369324 and perplexity is 37.84037053811904
At time: 160.2858338356018 and batch: 1250, loss is 3.5201172685623168 and perplexity is 33.78839054751359
At time: 160.67455387115479 and batch: 1300, loss is 3.6408908224105834 and perplexity is 38.12578490586926
At time: 161.0809509754181 and batch: 1350, loss is 3.6594251680374144 and perplexity is 38.83901054862241
At time: 161.47781109809875 and batch: 1400, loss is 3.4749971199035645 and perplexity is 32.29773551588379
At time: 161.8914315700531 and batch: 1450, loss is 3.5950583314895628 and perplexity is 36.417824231857374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.440411950787928 and perplexity of 84.80987197213503
Annealing...
Finished 13 epochs...
Completing Train Step...
At time: 163.21851682662964 and batch: 50, loss is 3.7545310115814208 and perplexity is 42.71418265534837
At time: 163.6316499710083 and batch: 100, loss is 3.8184194564819336 and perplexity is 45.5321858173346
At time: 164.04289722442627 and batch: 150, loss is 3.6409828901290893 and perplexity is 38.12929522149268
At time: 164.45338106155396 and batch: 200, loss is 3.7926349020004273 and perplexity is 44.373165318268555
At time: 164.87055468559265 and batch: 250, loss is 3.8560873317718505 and perplexity is 47.279998046107124
At time: 165.26715230941772 and batch: 300, loss is 3.8571761322021483 and perplexity is 47.331504563394944
At time: 165.66260409355164 and batch: 350, loss is 3.8282969427108764 and perplexity is 45.984157854801964
At time: 166.046692609787 and batch: 400, loss is 3.612810745239258 and perplexity is 37.07010112993814
At time: 166.45936465263367 and batch: 450, loss is 3.722948045730591 and perplexity is 41.38622291970708
At time: 166.8582525253296 and batch: 500, loss is 3.7109025287628175 and perplexity is 40.89069490635917
At time: 167.258864402771 and batch: 550, loss is 3.7508617544174196 and perplexity is 42.55774052336338
At time: 167.66728949546814 and batch: 600, loss is 3.691577272415161 and perplexity is 40.108058427511224
At time: 168.06602692604065 and batch: 650, loss is 3.7404121208190917 and perplexity is 42.11534319871344
At time: 168.46825003623962 and batch: 700, loss is 3.7912294101715087 and perplexity is 44.31084300400153
At time: 168.8803083896637 and batch: 750, loss is 3.747271294593811 and perplexity is 42.40521265228537
At time: 169.281635761261 and batch: 800, loss is 3.6630313777923584 and perplexity is 38.97932501697466
At time: 169.68828225135803 and batch: 850, loss is 3.6183118629455566 and perplexity is 37.27459006279116
At time: 170.12919521331787 and batch: 900, loss is 3.518122673034668 and perplexity is 33.721063542234084
At time: 170.51931047439575 and batch: 950, loss is 3.6779956102371214 and perplexity is 39.56700683422111
At time: 170.92736673355103 and batch: 1000, loss is 3.69462694644928 and perplexity is 40.2305616343358
At time: 171.3378984928131 and batch: 1050, loss is 3.617696647644043 and perplexity is 37.251665217207844
At time: 171.74360632896423 and batch: 1100, loss is 3.7676992177963258 and perplexity is 43.28037148500483
At time: 172.15609622001648 and batch: 1150, loss is 3.681385245323181 and perplexity is 39.70135211093716
At time: 172.55137825012207 and batch: 1200, loss is 3.6025244998931885 and perplexity is 36.69074340292007
At time: 172.9748432636261 and batch: 1250, loss is 3.4840973138809206 and perplexity is 32.59299258480398
At time: 173.3922083377838 and batch: 1300, loss is 3.6038876819610595 and perplexity is 36.74079367244819
At time: 173.79182505607605 and batch: 1350, loss is 3.6173537397384643 and perplexity is 37.2388935165926
At time: 174.1884846687317 and batch: 1400, loss is 3.4302908849716185 and perplexity is 30.88562560745278
At time: 174.58365058898926 and batch: 1450, loss is 3.550704011917114 and perplexity is 34.83783510732315
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.435489491519765 and perplexity of 84.39342464521337
Finished 14 epochs...
Completing Train Step...
At time: 175.94292664527893 and batch: 50, loss is 3.7489912557601928 and perplexity is 42.47821073023346
At time: 176.35526585578918 and batch: 100, loss is 3.809381194114685 and perplexity is 45.12250815176023
At time: 176.76135158538818 and batch: 150, loss is 3.6305047702789306 and perplexity is 37.73185773143484
At time: 177.1728048324585 and batch: 200, loss is 3.7824398136138915 and perplexity is 43.92307522849909
At time: 177.56703686714172 and batch: 250, loss is 3.847691740989685 and perplexity is 46.884716164606104
At time: 177.9836049079895 and batch: 300, loss is 3.848414444923401 and perplexity is 46.91861218032604
At time: 178.40379238128662 and batch: 350, loss is 3.818753843307495 and perplexity is 45.54741372627511
At time: 178.810387134552 and batch: 400, loss is 3.6041847562789915 and perplexity is 36.75171004007466
At time: 179.21762490272522 and batch: 450, loss is 3.714085507392883 and perplexity is 41.02105647339411
At time: 179.61836743354797 and batch: 500, loss is 3.7027567195892335 and perplexity is 40.55896006735559
At time: 180.03464436531067 and batch: 550, loss is 3.742446503639221 and perplexity is 42.20110914017964
At time: 180.43447828292847 and batch: 600, loss is 3.683467779159546 and perplexity is 39.78411767118499
At time: 180.85008573532104 and batch: 650, loss is 3.7331715202331544 and perplexity is 41.81150413614768
At time: 181.26699447631836 and batch: 700, loss is 3.784291262626648 and perplexity is 44.0044718904014
At time: 181.704407453537 and batch: 750, loss is 3.7408619356155395 and perplexity is 42.13429156454987
At time: 182.10773587226868 and batch: 800, loss is 3.6569197463989256 and perplexity is 38.74182424834388
At time: 182.4999885559082 and batch: 850, loss is 3.612317886352539 and perplexity is 37.05183530277204
At time: 182.89858627319336 and batch: 900, loss is 3.513179440498352 and perplexity is 33.55478380207835
At time: 183.29620122909546 and batch: 950, loss is 3.6735221195220946 and perplexity is 39.390399516648294
At time: 183.67733144760132 and batch: 1000, loss is 3.6910097122192385 and perplexity is 40.08530114868573
At time: 184.09854984283447 and batch: 1050, loss is 3.615038161277771 and perplexity is 37.15276369552974
At time: 184.51189517974854 and batch: 1100, loss is 3.766006031036377 and perplexity is 43.20715173788664
At time: 184.91801524162292 and batch: 1150, loss is 3.6799440956115723 and perplexity is 39.6441777271109
At time: 185.31670904159546 and batch: 1200, loss is 3.60221821308136 and perplexity is 36.67950723293275
At time: 185.7309069633484 and batch: 1250, loss is 3.4845130157470705 and perplexity is 32.60654436920077
At time: 186.12024927139282 and batch: 1300, loss is 3.605238699913025 and perplexity is 36.79046468993211
At time: 186.54273223876953 and batch: 1350, loss is 3.6201165437698366 and perplexity is 37.341919536541845
At time: 186.93278646469116 and batch: 1400, loss is 3.433847637176514 and perplexity is 30.995673715343372
At time: 187.33271741867065 and batch: 1450, loss is 3.5556115245819093 and perplexity is 35.00922242306805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434745071280716 and perplexity of 84.33062384985652
Finished 15 epochs...
Completing Train Step...
At time: 188.61363577842712 and batch: 50, loss is 3.7457953882217407 and perplexity is 42.34267269163864
At time: 189.00737166404724 and batch: 100, loss is 3.804986081123352 and perplexity is 44.92462480835051
At time: 189.39720702171326 and batch: 150, loss is 3.6254157876968383 and perplexity is 37.5403287218936
At time: 189.79662418365479 and batch: 200, loss is 3.7771631717681884 and perplexity is 43.691919291639415
At time: 190.18962597846985 and batch: 250, loss is 3.842793116569519 and perplexity is 46.65560716668705
At time: 190.58226919174194 and batch: 300, loss is 3.8433881521224977 and perplexity is 46.68337717294819
At time: 190.99862098693848 and batch: 350, loss is 3.813727340698242 and perplexity is 45.31904396376599
At time: 191.39150023460388 and batch: 400, loss is 3.599361138343811 and perplexity is 36.57486070209633
At time: 191.79325079917908 and batch: 450, loss is 3.709142279624939 and perplexity is 40.818780408188495
At time: 192.19525456428528 and batch: 500, loss is 3.6981188821792603 and perplexity is 40.37128973368442
At time: 192.60637640953064 and batch: 550, loss is 3.737596535682678 and perplexity is 41.99693064293068
At time: 192.99823307991028 and batch: 600, loss is 3.678911075592041 and perplexity is 39.60324564333192
At time: 193.39224123954773 and batch: 650, loss is 3.729022216796875 and perplexity is 41.63837494951704
At time: 193.81122183799744 and batch: 700, loss is 3.780368800163269 and perplexity is 43.832204079074124
At time: 194.2041265964508 and batch: 750, loss is 3.7371464729309083 and perplexity is 41.97803364149684
At time: 194.61940813064575 and batch: 800, loss is 3.6533947563171387 and perplexity is 38.605500113887636
At time: 195.03758144378662 and batch: 850, loss is 3.608943452835083 and perplexity is 36.927017061711254
At time: 195.4597098827362 and batch: 900, loss is 3.5103857040405275 and perplexity is 33.46117140430711
At time: 195.85022354125977 and batch: 950, loss is 3.6711126279830935 and perplexity is 39.29560293394001
At time: 196.26501488685608 and batch: 1000, loss is 3.6890594434738158 and perplexity is 40.00720022235745
At time: 196.65645575523376 and batch: 1050, loss is 3.6136526012420656 and perplexity is 37.10132195697548
At time: 197.03486943244934 and batch: 1100, loss is 3.765213141441345 and perplexity is 43.17290681485835
At time: 197.45076870918274 and batch: 1150, loss is 3.679429082870483 and perplexity is 39.62376572714263
At time: 197.85957288742065 and batch: 1200, loss is 3.6022592067718504 and perplexity is 36.681010892119666
At time: 198.25179362297058 and batch: 1250, loss is 3.4850428104400635 and perplexity is 32.623823720214475
At time: 198.65300965309143 and batch: 1300, loss is 3.6061972045898436 and perplexity is 36.825745428074875
At time: 199.05830025672913 and batch: 1350, loss is 3.6217753505706787 and perplexity is 37.403913970804616
At time: 199.45713543891907 and batch: 1400, loss is 3.435861096382141 and perplexity is 31.058145110618085
At time: 199.84803175926208 and batch: 1450, loss is 3.558294081687927 and perplexity is 35.103262739320805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4346454326923075 and perplexity of 84.32222168413344
Finished 16 epochs...
Completing Train Step...
At time: 201.18711805343628 and batch: 50, loss is 3.7427687740325926 and perplexity is 42.21471149992414
At time: 201.57795238494873 and batch: 100, loss is 3.8014166736602784 and perplexity is 44.764556361985555
At time: 201.9720253944397 and batch: 150, loss is 3.621487674713135 and perplexity is 37.39315531535448
At time: 202.3753252029419 and batch: 200, loss is 3.773152403831482 and perplexity is 43.51703209307563
At time: 202.76795554161072 and batch: 250, loss is 3.8389479303359986 and perplexity is 46.47655213887465
At time: 203.1728596687317 and batch: 300, loss is 3.839448571205139 and perplexity is 46.49982602577548
At time: 203.58981704711914 and batch: 350, loss is 3.8098963117599487 and perplexity is 45.14575753947859
At time: 203.98142266273499 and batch: 400, loss is 3.595607533454895 and perplexity is 36.43783046572726
At time: 204.37332606315613 and batch: 450, loss is 3.7052868175506593 and perplexity is 40.66170813606824
At time: 204.76829624176025 and batch: 500, loss is 3.694544496536255 and perplexity is 40.22724476476778
At time: 205.16930627822876 and batch: 550, loss is 3.7338770055770873 and perplexity is 41.841011946963704
At time: 205.57621955871582 and batch: 600, loss is 3.6754659700393675 and perplexity is 39.46704303276006
At time: 205.98707914352417 and batch: 650, loss is 3.725823130607605 and perplexity is 41.505383038986125
At time: 206.38548159599304 and batch: 700, loss is 3.7773548364639282 and perplexity is 43.700294292627106
At time: 206.78893160820007 and batch: 750, loss is 3.7342847299575808 and perplexity is 41.85807502591926
At time: 207.18064403533936 and batch: 800, loss is 3.650733246803284 and perplexity is 38.502887820417364
At time: 207.58761954307556 and batch: 850, loss is 3.6064331769943236 and perplexity is 36.8344363131345
At time: 208.00133419036865 and batch: 900, loss is 3.5082685804367064 and perplexity is 33.39040490566041
At time: 208.41935420036316 and batch: 950, loss is 3.6692854261398313 and perplexity is 39.22386749335005
At time: 208.81321096420288 and batch: 1000, loss is 3.687544860839844 and perplexity is 39.94665187597842
At time: 209.20525527000427 and batch: 1050, loss is 3.612548384666443 and perplexity is 37.06037667268425
At time: 209.64129042625427 and batch: 1100, loss is 3.764507489204407 and perplexity is 43.14245250292971
At time: 210.03211855888367 and batch: 1150, loss is 3.678970332145691 and perplexity is 39.60559246471369
At time: 210.43262720108032 and batch: 1200, loss is 3.602135863304138 and perplexity is 36.67648680805088
At time: 210.84161734580994 and batch: 1250, loss is 3.4852898502349854 and perplexity is 32.631884098511996
At time: 211.24351000785828 and batch: 1300, loss is 3.606723666191101 and perplexity is 36.8451378732214
At time: 211.64680409431458 and batch: 1350, loss is 3.6227662420272826 and perplexity is 37.44099555848195
At time: 212.0545403957367 and batch: 1400, loss is 3.43708016872406 and perplexity is 31.09603032402978
At time: 212.4691023826599 and batch: 1450, loss is 3.559948196411133 and perplexity is 35.16137561247983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434734116252671 and perplexity of 84.32970001056756
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 213.73050808906555 and batch: 50, loss is 3.7409752655029296 and perplexity is 42.13906690965769
At time: 214.15458989143372 and batch: 100, loss is 3.799936490058899 and perplexity is 44.698345613856
At time: 214.54245495796204 and batch: 150, loss is 3.6209374380111696 and perplexity is 37.37258588844347
At time: 214.94192743301392 and batch: 200, loss is 3.7724563789367678 and perplexity is 43.486753693876935
At time: 215.3380515575409 and batch: 250, loss is 3.838348722457886 and perplexity is 46.44871136472414
At time: 215.7283217906952 and batch: 300, loss is 3.839178318977356 and perplexity is 46.48726104213437
At time: 216.1490592956543 and batch: 350, loss is 3.8085890769958497 and perplexity is 45.086779992919695
At time: 216.56729531288147 and batch: 400, loss is 3.5931300687789918 and perplexity is 36.34766876021856
At time: 216.99123859405518 and batch: 450, loss is 3.7036727905273437 and perplexity is 40.5961319754061
At time: 217.38220739364624 and batch: 500, loss is 3.6922623538970947 and perplexity is 40.13554512985657
At time: 217.77684020996094 and batch: 550, loss is 3.7313850593566893 and perplexity is 41.736876199614315
At time: 218.17677974700928 and batch: 600, loss is 3.673228874206543 and perplexity is 39.37885015999247
At time: 218.57021594047546 and batch: 650, loss is 3.723483667373657 and perplexity is 41.408396214145725
At time: 219.01662468910217 and batch: 700, loss is 3.7739959859848025 and perplexity is 43.553757773101005
At time: 219.42396020889282 and batch: 750, loss is 3.731500449180603 and perplexity is 41.7416924882797
At time: 219.82876443862915 and batch: 800, loss is 3.6470248889923096 and perplexity is 38.3603697529425
At time: 220.22080755233765 and batch: 850, loss is 3.6037630939483645 and perplexity is 36.73621649511634
At time: 220.62150025367737 and batch: 900, loss is 3.505147032737732 and perplexity is 33.28633767397623
At time: 221.03048539161682 and batch: 950, loss is 3.665397891998291 and perplexity is 39.07167937921841
At time: 221.43200969696045 and batch: 1000, loss is 3.682882013320923 and perplexity is 39.76082031819635
At time: 221.8519365787506 and batch: 1050, loss is 3.6075272083282472 and perplexity is 36.87475639232189
At time: 222.25932145118713 and batch: 1100, loss is 3.7592507123947145 and perplexity is 42.9162573088085
At time: 222.67455053329468 and batch: 1150, loss is 3.6735908937454225 and perplexity is 39.39310865393997
At time: 223.07979130744934 and batch: 1200, loss is 3.5963085508346557 and perplexity is 36.46338297349409
At time: 223.47109270095825 and batch: 1250, loss is 3.479163131713867 and perplexity is 32.43256892727101
At time: 223.86625480651855 and batch: 1300, loss is 3.6000954151153564 and perplexity is 36.60172663504054
At time: 224.28791880607605 and batch: 1350, loss is 3.6154085779190064 and perplexity is 37.16652824662246
At time: 224.67815899848938 and batch: 1400, loss is 3.4293277406692506 and perplexity is 30.855892614003988
At time: 225.0875527858734 and batch: 1450, loss is 3.551812481880188 and perplexity is 34.876473211751005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434509799011752 and perplexity of 84.31078552643542
Finished 18 epochs...
Completing Train Step...
At time: 226.39802598953247 and batch: 50, loss is 3.7404036045074465 and perplexity is 42.11498453285297
At time: 226.81577134132385 and batch: 100, loss is 3.799142322540283 and perplexity is 44.66286173157196
At time: 227.21079349517822 and batch: 150, loss is 3.62003303527832 and perplexity is 37.33880129937247
At time: 227.64214301109314 and batch: 200, loss is 3.771523509025574 and perplexity is 43.44620512603046
At time: 228.03430008888245 and batch: 250, loss is 3.837512936592102 and perplexity is 46.40990640685818
At time: 228.4261155128479 and batch: 300, loss is 3.8384157037734985 and perplexity is 46.45182266471818
At time: 228.8239290714264 and batch: 350, loss is 3.8077602624893188 and perplexity is 45.04942689714087
At time: 229.22252988815308 and batch: 400, loss is 3.59239914894104 and perplexity is 36.32111123495179
At time: 229.63472700119019 and batch: 450, loss is 3.7028057622909545 and perplexity is 40.56094923711302
At time: 230.03534698486328 and batch: 500, loss is 3.691550192832947 and perplexity is 40.10697233275114
At time: 230.44128823280334 and batch: 550, loss is 3.7306339597702025 and perplexity is 41.705539419154185
At time: 230.83290195465088 and batch: 600, loss is 3.6724849128723145 and perplexity is 39.34956471305788
At time: 231.234299659729 and batch: 650, loss is 3.7228751134872438 and perplexity is 41.38320463969218
At time: 231.64075565338135 and batch: 700, loss is 3.7735172414779665 and perplexity is 43.532911641198794
At time: 232.07029604911804 and batch: 750, loss is 3.730961437225342 and perplexity is 41.71919927959448
At time: 232.46061849594116 and batch: 800, loss is 3.646649079322815 and perplexity is 38.345956263597934
At time: 232.8613314628601 and batch: 850, loss is 3.6033380126953123 and perplexity is 36.720603936714234
At time: 233.25723958015442 and batch: 900, loss is 3.504706859588623 and perplexity is 33.2716891460808
At time: 233.63664507865906 and batch: 950, loss is 3.6650821495056154 and perplexity is 39.059344737165986
At time: 234.03067755699158 and batch: 1000, loss is 3.682654609680176 and perplexity is 39.751779590883025
At time: 234.45976185798645 and batch: 1050, loss is 3.607491035461426 and perplexity is 36.873422550794416
At time: 234.8501217365265 and batch: 1100, loss is 3.7592603874206545 and perplexity is 42.91667252671983
At time: 235.2479612827301 and batch: 1150, loss is 3.6735544490814207 and perplexity is 39.391673011492
At time: 235.66292214393616 and batch: 1200, loss is 3.596418790817261 and perplexity is 36.46740291777404
At time: 236.05541348457336 and batch: 1250, loss is 3.479437885284424 and perplexity is 32.44148111565783
At time: 236.44815707206726 and batch: 1300, loss is 3.6003733396530153 and perplexity is 36.611900566720244
At time: 236.8424551486969 and batch: 1350, loss is 3.6156748294830323 and perplexity is 37.17642521038011
At time: 237.25666618347168 and batch: 1400, loss is 3.4297255659103394 and perplexity is 30.868170308948713
At time: 237.6547544002533 and batch: 1450, loss is 3.552235722541809 and perplexity is 34.89123747754657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4344341571514425 and perplexity of 84.30440834296809
Finished 19 epochs...
Completing Train Step...
At time: 239.00788354873657 and batch: 50, loss is 3.7399020624160766 and perplexity is 42.09386739144264
At time: 239.42781043052673 and batch: 100, loss is 3.7985261249542237 and perplexity is 44.63534906147745
At time: 239.81901216506958 and batch: 150, loss is 3.6193542861938477 and perplexity is 37.31346622122843
At time: 240.24670886993408 and batch: 200, loss is 3.770850887298584 and perplexity is 43.41699209027011
At time: 240.65104985237122 and batch: 250, loss is 3.8368055248260498 and perplexity is 46.377087102754174
At time: 241.05563378334045 and batch: 300, loss is 3.8377514410018922 and perplexity is 46.42097669429788
At time: 241.44783353805542 and batch: 350, loss is 3.8070946311950684 and perplexity is 45.01945056650876
At time: 241.8483850955963 and batch: 400, loss is 3.5917903137207032 and perplexity is 36.29900439358489
At time: 242.26912260055542 and batch: 450, loss is 3.702098512649536 and perplexity is 40.53227266225347
At time: 242.66035223007202 and batch: 500, loss is 3.6909264755249023 and perplexity is 40.08196471958524
At time: 243.08365607261658 and batch: 550, loss is 3.7299976539611817 and perplexity is 41.67901038333832
At time: 243.5108082294464 and batch: 600, loss is 3.6718851566314696 and perplexity is 39.325971641799775
At time: 243.90830636024475 and batch: 650, loss is 3.7223529052734374 and perplexity is 41.36159963196293
At time: 244.30900692939758 and batch: 700, loss is 3.773067984580994 and perplexity is 43.513358572902945
At time: 244.70765209197998 and batch: 750, loss is 3.730510029792786 and perplexity is 41.700371172852755
At time: 245.1184434890747 and batch: 800, loss is 3.6463060760498047 and perplexity is 38.33280573055968
At time: 245.50867676734924 and batch: 850, loss is 3.60298837184906 and perplexity is 36.707767157940765
At time: 245.89159870147705 and batch: 900, loss is 3.504378318786621 and perplexity is 33.26075983410556
At time: 246.29729890823364 and batch: 950, loss is 3.6648287200927734 and perplexity is 39.04944720457916
At time: 246.70125079154968 and batch: 1000, loss is 3.682484359741211 and perplexity is 39.74501242890474
At time: 247.0920214653015 and batch: 1050, loss is 3.6074534320831297 and perplexity is 36.87203601160661
At time: 247.50481915473938 and batch: 1100, loss is 3.759247965812683 and perplexity is 42.916139435949184
At time: 247.92874479293823 and batch: 1150, loss is 3.673535747528076 and perplexity is 39.390936332906385
At time: 248.30769634246826 and batch: 1200, loss is 3.596517996788025 and perplexity is 36.471020881340564
At time: 248.71888947486877 and batch: 1250, loss is 3.479648427963257 and perplexity is 32.448312151084245
At time: 249.1185166835785 and batch: 1300, loss is 3.600604386329651 and perplexity is 36.62036060196539
At time: 249.49934816360474 and batch: 1350, loss is 3.615915575027466 and perplexity is 37.18537634653732
At time: 249.91086339950562 and batch: 1400, loss is 3.4300482797622682 and perplexity is 30.878133502634945
At time: 250.3321189880371 and batch: 1450, loss is 3.55259934425354 and perplexity is 34.903926995994965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434398683727297 and perplexity of 84.30141782997576
Finished 20 epochs...
Completing Train Step...
At time: 251.63061380386353 and batch: 50, loss is 3.739430937767029 and perplexity is 42.07404060375172
At time: 252.0272924900055 and batch: 100, loss is 3.7979612064361574 and perplexity is 44.6101408471962
At time: 252.44854593276978 and batch: 150, loss is 3.6187398529052732 and perplexity is 37.290546627471755
At time: 252.83711409568787 and batch: 200, loss is 3.7702431011199953 and perplexity is 43.390611860143444
At time: 253.23256874084473 and batch: 250, loss is 3.8361748123168944 and perplexity is 46.347845716203764
At time: 253.63356971740723 and batch: 300, loss is 3.8371506261825563 and perplexity is 46.393094660380214
At time: 254.04570746421814 and batch: 350, loss is 3.8064969682693484 and perplexity is 44.99255214886304
At time: 254.44243907928467 and batch: 400, loss is 3.59123046875 and perplexity is 36.27868826600517
At time: 254.8379008769989 and batch: 450, loss is 3.7014712285995484 and perplexity is 40.50685538686185
At time: 255.25366139411926 and batch: 500, loss is 3.6903617000579834 and perplexity is 40.05933380054119
At time: 255.6292405128479 and batch: 550, loss is 3.729421467781067 and perplexity is 41.65500243074404
At time: 256.02184224128723 and batch: 600, loss is 3.67135329246521 and perplexity is 39.3050611279496
At time: 256.4315824508667 and batch: 650, loss is 3.721880512237549 and perplexity is 41.34206531464458
At time: 256.8317427635193 and batch: 700, loss is 3.772646565437317 and perplexity is 43.495025073909694
At time: 257.2226459980011 and batch: 750, loss is 3.7301026678085325 and perplexity is 41.68338748639665
At time: 257.6137065887451 and batch: 800, loss is 3.645976004600525 and perplexity is 38.3201552537127
At time: 258.01873660087585 and batch: 850, loss is 3.6026680850982666 and perplexity is 36.69601202907538
At time: 258.4335482120514 and batch: 900, loss is 3.504090166091919 and perplexity is 33.2511770372522
At time: 258.82991456985474 and batch: 950, loss is 3.6646015310287474 and perplexity is 39.04057660490779
At time: 259.23959040641785 and batch: 1000, loss is 3.6823306560516356 and perplexity is 39.7389039433126
At time: 259.6458284854889 and batch: 1050, loss is 3.607400026321411 and perplexity is 36.870066885019114
At time: 260.04070591926575 and batch: 1100, loss is 3.7592244386672973 and perplexity is 42.9151297535748
At time: 260.4495179653168 and batch: 1150, loss is 3.6735233449935913 and perplexity is 39.39044778848973
At time: 260.84995555877686 and batch: 1200, loss is 3.596597352027893 and perplexity is 36.47391516278752
At time: 261.25833797454834 and batch: 1250, loss is 3.479815335273743 and perplexity is 32.45372846359369
At time: 261.65053272247314 and batch: 1300, loss is 3.6008007669448854 and perplexity is 36.627552837095166
At time: 262.06098079681396 and batch: 1350, loss is 3.616132826805115 and perplexity is 37.19345581325863
At time: 262.4446942806244 and batch: 1400, loss is 3.430319380760193 and perplexity is 30.886505730249922
At time: 262.82077741622925 and batch: 1450, loss is 3.552917523384094 and perplexity is 34.915034464128034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4343809470152245 and perplexity of 84.29992261326058
Finished 21 epochs...
Completing Train Step...
At time: 264.1686432361603 and batch: 50, loss is 3.7389799404144286 and perplexity is 42.05506960108377
At time: 264.59503746032715 and batch: 100, loss is 3.797428832054138 and perplexity is 44.58639787166761
At time: 264.9766843318939 and batch: 150, loss is 3.6181660890579224 and perplexity is 37.2691567969115
At time: 265.37655210494995 and batch: 200, loss is 3.7696738386154176 and perplexity is 43.36591824100338
At time: 265.76603722572327 and batch: 250, loss is 3.8355949115753174 and perplexity is 46.3209763576359
At time: 266.16845989227295 and batch: 300, loss is 3.8365892696380617 and perplexity is 46.36705890142879
At time: 266.57111263275146 and batch: 350, loss is 3.8059422063827513 and perplexity is 44.96759891794082
At time: 266.98752546310425 and batch: 400, loss is 3.590702610015869 and perplexity is 36.25954329690526
At time: 267.39526653289795 and batch: 450, loss is 3.700894260406494 and perplexity is 40.48349096061653
At time: 267.780549287796 and batch: 500, loss is 3.689837441444397 and perplexity is 40.038337853875554
At time: 268.1990587711334 and batch: 550, loss is 3.7288877725601197 and perplexity is 41.632777286272436
At time: 268.609486579895 and batch: 600, loss is 3.6708634519577026 and perplexity is 39.28581263159057
At time: 269.02483916282654 and batch: 650, loss is 3.721440329551697 and perplexity is 41.32387125794386
At time: 269.41640400886536 and batch: 700, loss is 3.772246870994568 and perplexity is 43.47764382792554
At time: 269.8327052593231 and batch: 750, loss is 3.7297229766845703 and perplexity is 41.66756367842121
At time: 270.2445704936981 and batch: 800, loss is 3.6456561422348024 and perplexity is 38.30790003829397
At time: 270.6503348350525 and batch: 850, loss is 3.6023641538619997 and perplexity is 36.68486065948393
At time: 271.03275513648987 and batch: 900, loss is 3.503821792602539 and perplexity is 33.24225450018448
At time: 271.44546127319336 and batch: 950, loss is 3.664388127326965 and perplexity is 39.032246090253544
At time: 271.8343553543091 and batch: 1000, loss is 3.6821810531616213 and perplexity is 39.7329593331132
At time: 272.22582030296326 and batch: 1050, loss is 3.6073325872421265 and perplexity is 36.86758048549642
At time: 272.62828493118286 and batch: 1100, loss is 3.7591929721832273 and perplexity is 42.913779386573815
At time: 273.0752680301666 and batch: 1150, loss is 3.6735116386413575 and perplexity is 39.38998667273226
At time: 273.49323058128357 and batch: 1200, loss is 3.5966599416732787 and perplexity is 36.4761981236475
At time: 273.89701104164124 and batch: 1250, loss is 3.479951014518738 and perplexity is 32.45813205970045
At time: 274.30697083473206 and batch: 1300, loss is 3.6009689712524415 and perplexity is 36.633714267432644
At time: 274.7033064365387 and batch: 1350, loss is 3.616328320503235 and perplexity is 37.20072761025351
At time: 275.07920837402344 and batch: 1400, loss is 3.4305534601211547 and perplexity is 30.893736470024052
At time: 275.50338554382324 and batch: 1450, loss is 3.553200755119324 and perplexity is 34.924924910502945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4343772953392095 and perplexity of 84.29961477781717
Finished 22 epochs...
Completing Train Step...
At time: 276.85666012763977 and batch: 50, loss is 3.738543920516968 and perplexity is 42.03673675098276
At time: 277.26725220680237 and batch: 100, loss is 3.7969209814071654 and perplexity is 44.56376038937886
At time: 277.66472339630127 and batch: 150, loss is 3.6176221227645873 and perplexity is 37.24888914479253
At time: 278.0622937679291 and batch: 200, loss is 3.769133200645447 and perplexity is 43.34247931555709
At time: 278.46719002723694 and batch: 250, loss is 3.8350509786605835 and perplexity is 46.29578770504202
At time: 278.8875775337219 and batch: 300, loss is 3.836056571006775 and perplexity is 46.34236581018708
At time: 279.2930762767792 and batch: 350, loss is 3.8054187059402467 and perplexity is 44.94406452068007
At time: 279.69486451148987 and batch: 400, loss is 3.590199203491211 and perplexity is 36.24129459987043
At time: 280.08554792404175 and batch: 450, loss is 3.7003535509109495 and perplexity is 40.461607069588354
At time: 280.50129985809326 and batch: 500, loss is 3.6893431997299193 and perplexity is 40.01855412650421
At time: 280.9111030101776 and batch: 550, loss is 3.7283859968185427 and perplexity is 41.61189220882651
At time: 281.30909395217896 and batch: 600, loss is 3.670403161048889 and perplexity is 39.26773389025023
At time: 281.70324087142944 and batch: 650, loss is 3.721022663116455 and perplexity is 41.30661526781996
At time: 282.1067957878113 and batch: 700, loss is 3.7718646812438963 and perplexity is 43.46103029303476
At time: 282.51230478286743 and batch: 750, loss is 3.7293624591827395 and perplexity is 41.65254449995751
At time: 282.89034938812256 and batch: 800, loss is 3.6453450393676756 and perplexity is 38.29598419438116
At time: 283.3286175727844 and batch: 850, loss is 3.6020712184906007 and perplexity is 36.674115940032955
At time: 283.7342622280121 and batch: 900, loss is 3.503565707206726 and perplexity is 33.23374273419908
At time: 284.1570315361023 and batch: 950, loss is 3.664182710647583 and perplexity is 39.024229039319025
At time: 284.5483980178833 and batch: 1000, loss is 3.682031788825989 and perplexity is 39.72702906193563
At time: 284.9406795501709 and batch: 1050, loss is 3.6072545623779297 and perplexity is 36.86470400975555
At time: 285.35061717033386 and batch: 1100, loss is 3.7591547775268555 and perplexity is 42.91214034081812
At time: 285.7836046218872 and batch: 1150, loss is 3.6734980869293214 and perplexity is 39.38945287459272
At time: 286.17469787597656 and batch: 1200, loss is 3.5967081451416014 and perplexity is 36.477956445286544
At time: 286.5738101005554 and batch: 1250, loss is 3.4800625705718993 and perplexity is 32.46175316278025
At time: 286.9845550060272 and batch: 1300, loss is 3.601114230155945 and perplexity is 36.63903602710551
At time: 287.3850564956665 and batch: 1350, loss is 3.6165043020248415 and perplexity is 37.20727482698092
At time: 287.7843506336212 and batch: 1400, loss is 3.4307597637176515 and perplexity is 30.9001106164491
At time: 288.19308400154114 and batch: 1450, loss is 3.553455853462219 and perplexity is 34.93383533744261
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434381990351229 and perplexity of 84.30001056645088
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 289.5809226036072 and batch: 50, loss is 3.738261828422546 and perplexity is 42.024880192269386
At time: 289.97357201576233 and batch: 100, loss is 3.7966538715362548 and perplexity is 44.55185855871295
At time: 290.3905620574951 and batch: 150, loss is 3.6175390768051146 and perplexity is 37.24579590349658
At time: 290.80305433273315 and batch: 200, loss is 3.7690670537948607 and perplexity is 43.33961244187215
At time: 291.1928734779358 and batch: 250, loss is 3.8349209690093993 and perplexity is 46.28976919707173
At time: 291.58858251571655 and batch: 300, loss is 3.835901918411255 and perplexity is 46.335199397198465
At time: 291.9977197647095 and batch: 350, loss is 3.8053432941436767 and perplexity is 44.94067533582327
At time: 292.3889753818512 and batch: 400, loss is 3.5898014593124388 and perplexity is 36.226882702226355
At time: 292.79907488822937 and batch: 450, loss is 3.7000563764572143 and perplexity is 40.449584700069224
At time: 293.2019398212433 and batch: 500, loss is 3.6888924264907836 and perplexity is 40.00051889843956
At time: 293.62635469436646 and batch: 550, loss is 3.7279247760772707 and perplexity is 41.59270436631185
At time: 294.0064823627472 and batch: 600, loss is 3.6698989725112914 and perplexity is 39.247940539135
At time: 294.4170787334442 and batch: 650, loss is 3.720730905532837 and perplexity is 41.29456550745192
At time: 294.82658195495605 and batch: 700, loss is 3.7712754726409914 and perplexity is 43.435430222726445
At time: 295.22050285339355 and batch: 750, loss is 3.7288406133651733 and perplexity is 41.63081396430693
At time: 295.6111867427826 and batch: 800, loss is 3.644768385887146 and perplexity is 38.27390704784863
At time: 296.0513083934784 and batch: 850, loss is 3.601641640663147 and perplexity is 36.65836493636683
At time: 296.47703647613525 and batch: 900, loss is 3.5030513525009157 and perplexity is 33.216653197650594
At time: 296.87692642211914 and batch: 950, loss is 3.663581442832947 and perplexity is 39.000772079071005
At time: 297.2996504306793 and batch: 1000, loss is 3.681410217285156 and perplexity is 39.702343543971395
At time: 297.7080178260803 and batch: 1050, loss is 3.606498327255249 and perplexity is 36.83683616444596
At time: 298.0999960899353 and batch: 1100, loss is 3.758333477973938 and perplexity is 42.876911088006544
At time: 298.50053334236145 and batch: 1150, loss is 3.6727152824401856 and perplexity is 39.35863069950034
At time: 298.89485001564026 and batch: 1200, loss is 3.595750584602356 and perplexity is 36.443043312029296
At time: 299.31053256988525 and batch: 1250, loss is 3.4790751695632935 and perplexity is 32.429716214226765
At time: 299.7055778503418 and batch: 1300, loss is 3.6001652097702026 and perplexity is 36.60428132906877
At time: 300.114604473114 and batch: 1350, loss is 3.615466146469116 and perplexity is 37.16866793135491
At time: 300.5088081359863 and batch: 1400, loss is 3.42967668056488 and perplexity is 30.866661344662887
At time: 300.9268047809601 and batch: 1450, loss is 3.552364859580994 and perplexity is 34.89574351959011
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434375208667201 and perplexity of 84.29943887235422
Finished 24 epochs...
Completing Train Step...
At time: 302.3445770740509 and batch: 50, loss is 3.738195786476135 and perplexity is 42.02210487902835
At time: 302.7572774887085 and batch: 100, loss is 3.7965717411041258 and perplexity is 44.54819964557348
At time: 303.1869821548462 and batch: 150, loss is 3.617430176734924 and perplexity is 37.24174005455352
At time: 303.5844016075134 and batch: 200, loss is 3.7689645862579346 and perplexity is 43.33517176605034
At time: 303.99795603752136 and batch: 250, loss is 3.834830813407898 and perplexity is 46.28559610320313
At time: 304.4138903617859 and batch: 300, loss is 3.835824770927429 and perplexity is 46.33162489103626
At time: 304.82969522476196 and batch: 350, loss is 3.8052472686767578 and perplexity is 44.936360093680385
At time: 305.22218346595764 and batch: 400, loss is 3.589727840423584 and perplexity is 36.22421581754289
At time: 305.6300084590912 and batch: 450, loss is 3.69998016834259 and perplexity is 40.44650223093797
At time: 306.037499666214 and batch: 500, loss is 3.6888292741775515 and perplexity is 39.99799285290428
At time: 306.41294503211975 and batch: 550, loss is 3.727848868370056 and perplexity is 41.58954727931168
At time: 306.8145809173584 and batch: 600, loss is 3.669839382171631 and perplexity is 39.245601810710795
At time: 307.20812153816223 and batch: 650, loss is 3.7206595039367674 and perplexity is 41.29161711482692
At time: 307.59937381744385 and batch: 700, loss is 3.7712342071533205 and perplexity is 43.4336378754974
At time: 307.996342420578 and batch: 750, loss is 3.7287975025177 and perplexity is 41.62901926332175
At time: 308.4171450138092 and batch: 800, loss is 3.6447258043289184 and perplexity is 38.2722773199455
At time: 308.83390736579895 and batch: 850, loss is 3.6015985107421873 and perplexity is 36.656783898079894
At time: 309.22559213638306 and batch: 900, loss is 3.5030284309387207 and perplexity is 33.215891828794334
At time: 309.6371283531189 and batch: 950, loss is 3.663552846908569 and perplexity is 38.9996568318878
At time: 310.0410714149475 and batch: 1000, loss is 3.681386184692383 and perplexity is 39.70138940518212
At time: 310.47409892082214 and batch: 1050, loss is 3.6065007495880126 and perplexity is 36.83692539562919
At time: 310.86648964881897 and batch: 1100, loss is 3.7583399868011473 and perplexity is 42.87719016732032
At time: 311.2659902572632 and batch: 1150, loss is 3.6727150535583495 and perplexity is 39.358621691025704
At time: 311.6745414733887 and batch: 1200, loss is 3.5957670640945434 and perplexity is 36.44364387982535
At time: 312.05870604515076 and batch: 1250, loss is 3.479101815223694 and perplexity is 32.430580336944395
At time: 312.4508476257324 and batch: 1300, loss is 3.6001927757263186 and perplexity is 36.60529037498914
At time: 312.83108830451965 and batch: 1350, loss is 3.6154887819290162 and perplexity is 37.16950927076943
At time: 313.23244857788086 and batch: 1400, loss is 3.429704508781433 and perplexity is 30.86752032075088
At time: 313.6313409805298 and batch: 1450, loss is 3.5524038743972777 and perplexity is 34.89710499717135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4343689486511755 and perplexity of 84.29891115816768
Finished 25 epochs...
Completing Train Step...
At time: 314.97076964378357 and batch: 50, loss is 3.7381317949295045 and perplexity is 42.01941590558117
At time: 315.38417410850525 and batch: 100, loss is 3.796495585441589 and perplexity is 44.54480717709414
At time: 315.7994248867035 and batch: 150, loss is 3.6173352003097534 and perplexity is 37.23820313518063
At time: 316.20195841789246 and batch: 200, loss is 3.7688730907440187 and perplexity is 43.331206973622095
At time: 316.59521317481995 and batch: 250, loss is 3.8347444105148316 and perplexity is 46.281597066559165
At time: 316.99172043800354 and batch: 300, loss is 3.835747537612915 and perplexity is 46.32804668425927
At time: 317.37909293174744 and batch: 350, loss is 3.805159635543823 and perplexity is 44.93242235220353
At time: 317.80854392051697 and batch: 400, loss is 3.5896560382843017 and perplexity is 36.22161493472896
At time: 318.2116029262543 and batch: 450, loss is 3.6999041986465455 and perplexity is 40.44342963917083
At time: 318.6150314807892 and batch: 500, loss is 3.6887648630142214 and perplexity is 39.99541661862377
At time: 319.0064101219177 and batch: 550, loss is 3.7277768421173096 and perplexity is 41.58655184794387
At time: 319.399530172348 and batch: 600, loss is 3.6697793197631836 and perplexity is 39.243244696132784
At time: 319.81578063964844 and batch: 650, loss is 3.7205928421020507 and perplexity is 41.28886463161543
At time: 320.24453473091125 and batch: 700, loss is 3.7711904048919678 and perplexity is 43.431735425605794
At time: 320.64553570747375 and batch: 750, loss is 3.7287529039382936 and perplexity is 41.62716270960066
At time: 321.0373327732086 and batch: 800, loss is 3.644684615135193 and perplexity is 38.27070094816562
At time: 321.4554579257965 and batch: 850, loss is 3.6015569877624514 and perplexity is 36.65526183078551
At time: 321.86914682388306 and batch: 900, loss is 3.5030012845993044 and perplexity is 33.214990151159405
At time: 322.2862071990967 and batch: 950, loss is 3.663525424003601 and perplexity is 38.99858736266875
At time: 322.6715466976166 and batch: 1000, loss is 3.6813628578186037 and perplexity is 39.70046330668414
At time: 323.07185196876526 and batch: 1050, loss is 3.6065001249313355 and perplexity is 36.836902385204965
At time: 323.4816737174988 and batch: 1100, loss is 3.758344235420227 and perplexity is 42.87737233655553
At time: 323.8895380496979 and batch: 1150, loss is 3.672715702056885 and perplexity is 39.3586472150425
At time: 324.2777259349823 and batch: 1200, loss is 3.595781674385071 and perplexity is 36.444176335939986
At time: 324.71190547943115 and batch: 1250, loss is 3.479127597808838 and perplexity is 32.43141649192228
At time: 325.12401580810547 and batch: 1300, loss is 3.6002169847488403 and perplexity is 36.60617656401508
At time: 325.52442836761475 and batch: 1350, loss is 3.6155121660232545 and perplexity is 37.170378456239526
At time: 325.9279954433441 and batch: 1400, loss is 3.4297345733642577 and perplexity is 30.868448353822547
At time: 326.3247981071472 and batch: 1450, loss is 3.552440266609192 and perplexity is 34.89837500312061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434365296975161 and perplexity of 84.29860332641778
Finished 26 epochs...
Completing Train Step...
At time: 327.60919523239136 and batch: 50, loss is 3.738068962097168 and perplexity is 42.01677578961054
At time: 328.0540084838867 and batch: 100, loss is 3.7964231252670286 and perplexity is 44.541579569528245
At time: 328.47553753852844 and batch: 150, loss is 3.617248649597168 and perplexity is 37.234980281636034
At time: 328.86760663986206 and batch: 200, loss is 3.7687881851196288 and perplexity is 43.32752806662059
At time: 329.26633167266846 and batch: 250, loss is 3.83466091632843 and perplexity is 46.2777329835832
At time: 329.676522731781 and batch: 300, loss is 3.835670495033264 and perplexity is 46.32447758952042
At time: 330.0663650035858 and batch: 350, loss is 3.805077300071716 and perplexity is 44.928722972293436
At time: 330.47203278541565 and batch: 400, loss is 3.589585108757019 and perplexity is 36.219045843817504
At time: 330.8854835033417 and batch: 450, loss is 3.6998287868499755 and perplexity is 40.440379842479054
At time: 331.2837791442871 and batch: 500, loss is 3.688699598312378 and perplexity is 39.99280641486107
At time: 331.6791183948517 and batch: 550, loss is 3.727707552909851 and perplexity is 41.58367044855148
At time: 332.1016035079956 and batch: 600, loss is 3.669719014167786 and perplexity is 39.24087818025383
At time: 332.51219415664673 and batch: 650, loss is 3.720529432296753 and perplexity is 41.28624659575363
At time: 332.9229691028595 and batch: 700, loss is 3.771145029067993 and perplexity is 43.42976471953575
At time: 333.30500316619873 and batch: 750, loss is 3.728707537651062 and perplexity is 41.62527428261632
At time: 333.7024462223053 and batch: 800, loss is 3.644644169807434 and perplexity is 38.26915310842386
At time: 334.1032238006592 and batch: 850, loss is 3.6015163612365724 and perplexity is 36.65377268509175
At time: 334.51530742645264 and batch: 900, loss is 3.5029714727401733 and perplexity is 33.21399996531169
At time: 334.93714594841003 and batch: 950, loss is 3.6634984493255613 and perplexity is 38.99753540251884
At time: 335.35510182380676 and batch: 1000, loss is 3.6813401889801027 and perplexity is 39.69956335349351
At time: 335.7719898223877 and batch: 1050, loss is 3.606497435569763 and perplexity is 36.83680331758845
At time: 336.179648399353 and batch: 1100, loss is 3.758346972465515 and perplexity is 42.87748969402606
At time: 336.59777307510376 and batch: 1150, loss is 3.672716598510742 and perplexity is 39.35868249826943
At time: 337.0180706977844 and batch: 1200, loss is 3.5957946395874023 and perplexity is 36.444648845123055
At time: 337.4167923927307 and batch: 1250, loss is 3.4791521406173707 and perplexity is 32.43221245973528
At time: 337.8068015575409 and batch: 1300, loss is 3.6002390956878663 and perplexity is 36.60698596990139
At time: 338.208327293396 and batch: 1350, loss is 3.6155356884002687 and perplexity is 37.17125280217864
At time: 338.60551261901855 and batch: 1400, loss is 3.4297653818130494 and perplexity is 30.86939937748264
At time: 338.9957718849182 and batch: 1450, loss is 3.552475023269653 and perplexity is 34.899587975170554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.43436268863515 and perplexity of 84.29838344728464
Finished 27 epochs...
Completing Train Step...
At time: 340.34931325912476 and batch: 50, loss is 3.738007345199585 and perplexity is 42.01418692599964
At time: 340.7763297557831 and batch: 100, loss is 3.7963527727127073 and perplexity is 44.53844606585831
At time: 341.17750811576843 and batch: 150, loss is 3.617167468070984 and perplexity is 37.23195761180347
At time: 341.5804178714752 and batch: 200, loss is 3.7687076807022093 and perplexity is 43.32404014961361
At time: 341.99177718162537 and batch: 250, loss is 3.8345794582366945 and perplexity is 46.27396344129646
At time: 342.40321588516235 and batch: 300, loss is 3.8355942583084106 and perplexity is 46.32094609768484
At time: 342.7956247329712 and batch: 350, loss is 3.80499858379364 and perplexity is 44.925186489633546
At time: 343.1985080242157 and batch: 400, loss is 3.589515233039856 and perplexity is 36.21651510043399
At time: 343.59584045410156 and batch: 450, loss is 3.699754042625427 and perplexity is 40.43735727060859
At time: 343.98635244369507 and batch: 500, loss is 3.6886341381073 and perplexity is 39.99018856323499
At time: 344.41261315345764 and batch: 550, loss is 3.7276398801803587 and perplexity is 41.58085646328603
At time: 344.8316752910614 and batch: 600, loss is 3.66965874671936 and perplexity is 39.23851330391518
At time: 345.2411165237427 and batch: 650, loss is 3.720468258857727 and perplexity is 41.283721051313805
At time: 345.6312162876129 and batch: 700, loss is 3.7710986137390137 and perplexity is 43.427748959500235
At time: 346.0501811504364 and batch: 750, loss is 3.7286616516113282 and perplexity is 41.623364307447595
At time: 346.45847630500793 and batch: 800, loss is 3.6446041536331175 and perplexity is 38.26762175396181
At time: 346.8615560531616 and batch: 850, loss is 3.6014762926101684 and perplexity is 36.65230404819107
At time: 347.2816686630249 and batch: 900, loss is 3.5029401350021363 and perplexity is 33.212959129990416
At time: 347.7121727466583 and batch: 950, loss is 3.663471989631653 and perplexity is 38.99650355332018
At time: 348.10571360588074 and batch: 1000, loss is 3.681317925453186 and perplexity is 39.698679511034975
At time: 348.49983620643616 and batch: 1050, loss is 3.6064930629730223 and perplexity is 36.83664224545448
At time: 348.9079873561859 and batch: 1100, loss is 3.7583482027053834 and perplexity is 42.87754244365578
At time: 349.3261511325836 and batch: 1150, loss is 3.672717447280884 and perplexity is 39.358715904758135
At time: 349.73494362831116 and batch: 1200, loss is 3.595806350708008 and perplexity is 36.44507565530032
At time: 350.10927152633667 and batch: 1250, loss is 3.4791752910614013 and perplexity is 32.4329632885456
At time: 350.50365805625916 and batch: 1300, loss is 3.6002597761154176 and perplexity is 36.60774302585071
At time: 350.9093186855316 and batch: 1350, loss is 3.615558929443359 and perplexity is 37.172116710905776
At time: 351.3020374774933 and batch: 1400, loss is 3.429795951843262 and perplexity is 30.870343070378542
At time: 351.68525195121765 and batch: 1450, loss is 3.5525085878372193 and perplexity is 34.90075938440799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434358515291133 and perplexity of 84.29803164186453
Finished 28 epochs...
Completing Train Step...
At time: 353.01431131362915 and batch: 50, loss is 3.7379465389251707 and perplexity is 42.01163227749024
At time: 353.41406893730164 and batch: 100, loss is 3.796283874511719 and perplexity is 44.53537755275828
At time: 353.83558893203735 and batch: 150, loss is 3.6170897579193113 and perplexity is 37.22906442314691
At time: 354.24312806129456 and batch: 200, loss is 3.7686298513412475 and perplexity is 43.3206683984668
At time: 354.6473436355591 and batch: 250, loss is 3.834499759674072 and perplexity is 46.270275619882334
At time: 355.0543749332428 and batch: 300, loss is 3.8355187368392945 and perplexity is 46.31744800387695
At time: 355.45311307907104 and batch: 350, loss is 3.8049226713180544 and perplexity is 44.92177623695297
At time: 355.8689293861389 and batch: 400, loss is 3.589446158409119 and perplexity is 36.214013544424866
At time: 356.2667999267578 and batch: 450, loss is 3.6996799373626708 and perplexity is 40.43436076065283
At time: 356.685240983963 and batch: 500, loss is 3.6885688495635987 and perplexity is 39.98757774729047
At time: 357.1084244251251 and batch: 550, loss is 3.7275736808776854 and perplexity is 41.57810393069247
At time: 357.50147318840027 and batch: 600, loss is 3.6695983934402467 and perplexity is 39.236145202431814
At time: 357.90105056762695 and batch: 650, loss is 3.720408730506897 and perplexity is 41.28126357262905
At time: 358.3218846321106 and batch: 700, loss is 3.7710515832901 and perplexity is 43.425706580998735
At time: 358.7371075153351 and batch: 750, loss is 3.7286156606674195 and perplexity is 41.621450053653945
At time: 359.14044070243835 and batch: 800, loss is 3.6445642280578614 and perplexity is 38.26609392764948
At time: 359.53872656822205 and batch: 850, loss is 3.601436595916748 and perplexity is 36.65084910179259
At time: 359.9562044143677 and batch: 900, loss is 3.5029079008102415 and perplexity is 33.21188855434709
At time: 360.3782916069031 and batch: 950, loss is 3.663445544242859 and perplexity is 38.99547228925826
At time: 360.78258180618286 and batch: 1000, loss is 3.681296229362488 and perplexity is 39.69781821422712
At time: 361.180725812912 and batch: 1050, loss is 3.6064875745773315 and perplexity is 36.83644007194072
At time: 361.5690851211548 and batch: 1100, loss is 3.758348298072815 and perplexity is 42.877546532777075
At time: 361.9573907852173 and batch: 1150, loss is 3.6727181339263915 and perplexity is 39.35874293025287
At time: 362.33614444732666 and batch: 1200, loss is 3.5958169174194334 and perplexity is 36.4454607619323
At time: 362.73071098327637 and batch: 1250, loss is 3.4791974306106566 and perplexity is 32.433681347682544
At time: 363.13050079345703 and batch: 1300, loss is 3.6002794790267942 and perplexity is 36.60846431207294
At time: 363.53026580810547 and batch: 1350, loss is 3.615581684112549 and perplexity is 37.172962559748086
At time: 363.93799114227295 and batch: 1400, loss is 3.429826045036316 and perplexity is 30.871272071550436
At time: 364.3429799079895 and batch: 1450, loss is 3.552541036605835 and perplexity is 34.90189188944787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434357471955129 and perplexity of 84.29794369073892
Finished 29 epochs...
Completing Train Step...
At time: 365.65559339523315 and batch: 50, loss is 3.7378865337371825 and perplexity is 42.00911143723024
At time: 366.0699872970581 and batch: 100, loss is 3.7962160444259645 and perplexity is 44.53235681672932
At time: 366.48489212989807 and batch: 150, loss is 3.6170142984390257 and perplexity is 37.226255243284974
At time: 366.8679208755493 and batch: 200, loss is 3.7685541200637815 and perplexity is 43.31738779313209
At time: 367.2583255767822 and batch: 250, loss is 3.8344217681884767 and perplexity is 46.26666707306762
At time: 367.6729829311371 and batch: 300, loss is 3.8354440689086915 and perplexity is 46.313989704997304
At time: 368.08566784858704 and batch: 350, loss is 3.804848761558533 and perplexity is 44.918456201967025
At time: 368.4771947860718 and batch: 400, loss is 3.58937780380249 and perplexity is 36.21153823437498
At time: 368.89820432662964 and batch: 450, loss is 3.699606709480286 and perplexity is 40.43139994644714
At time: 369.31410217285156 and batch: 500, loss is 3.688503694534302 and perplexity is 39.98497244036619
At time: 369.7126770019531 and batch: 550, loss is 3.7275084924697874 and perplexity is 41.575393608635565
At time: 370.11518812179565 and batch: 600, loss is 3.669538378715515 and perplexity is 39.23379052663628
At time: 370.51281356811523 and batch: 650, loss is 3.7203504467010498 and perplexity is 41.27885761359275
At time: 370.93353033065796 and batch: 700, loss is 3.7710042238235473 and perplexity is 43.42365001139978
At time: 371.3354682922363 and batch: 750, loss is 3.7285695123672484 and perplexity is 41.619529338802515
At time: 371.7272367477417 and batch: 800, loss is 3.64452437877655 and perplexity is 38.264569081690084
At time: 372.11769580841064 and batch: 850, loss is 3.6013971757888794 and perplexity is 36.64940434911086
At time: 372.51139974594116 and batch: 900, loss is 3.5028752660751343 and perplexity is 33.21080471084728
At time: 372.90650486946106 and batch: 950, loss is 3.663419346809387 and perplexity is 38.99445072134854
At time: 373.2840995788574 and batch: 1000, loss is 3.681274914741516 and perplexity is 39.69697207929603
At time: 373.67409229278564 and batch: 1050, loss is 3.606481056213379 and perplexity is 36.83619995940018
At time: 374.0783348083496 and batch: 1100, loss is 3.7583476972579954 and perplexity is 42.877520771319425
At time: 374.48398303985596 and batch: 1150, loss is 3.6727184581756593 and perplexity is 39.358755692298516
At time: 374.8651793003082 and batch: 1200, loss is 3.595826473236084 and perplexity is 36.44580902973707
At time: 375.28221321105957 and batch: 1250, loss is 3.479218354225159 and perplexity is 32.4343599846277
At time: 375.6792049407959 and batch: 1300, loss is 3.6002985286712645 and perplexity is 36.60916169694514
At time: 376.069949388504 and batch: 1350, loss is 3.6156039953231813 and perplexity is 37.17379194279782
At time: 376.49417185783386 and batch: 1400, loss is 3.4298555564880373 and perplexity is 30.87218314104918
At time: 376.92261385917664 and batch: 1450, loss is 3.5525730514526366 and perplexity is 34.90300928605634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4343564286191235 and perplexity of 84.29785573970499
Finished 30 epochs...
Completing Train Step...
At time: 378.28696942329407 and batch: 50, loss is 3.7378270339965822 and perplexity is 42.00661198035613
At time: 378.71031522750854 and batch: 100, loss is 3.7961487436294554 and perplexity is 44.52935985449523
At time: 379.138783454895 and batch: 150, loss is 3.6169405031204223 and perplexity is 37.22350822127881
At time: 379.5629258155823 and batch: 200, loss is 3.7684797716140745 and perplexity is 43.31416733222394
At time: 379.94384598731995 and batch: 250, loss is 3.834344940185547 and perplexity is 46.26311263397616
At time: 380.35222840309143 and batch: 300, loss is 3.83537052154541 and perplexity is 46.31058355842955
At time: 380.73610973358154 and batch: 350, loss is 3.8047762155532836 and perplexity is 44.91519766560594
At time: 381.1401288509369 and batch: 400, loss is 3.5893102073669434 and perplexity is 36.209090546193096
At time: 381.5345392227173 and batch: 450, loss is 3.6995339298248293 and perplexity is 40.42845747016691
At time: 381.9247348308563 and batch: 500, loss is 3.6884390687942505 and perplexity is 39.98238846542784
At time: 382.3360433578491 and batch: 550, loss is 3.7274441432952883 and perplexity is 41.57271835245356
At time: 382.72785472869873 and batch: 600, loss is 3.669478578567505 and perplexity is 39.23144441030553
At time: 383.14628076553345 and batch: 650, loss is 3.720293016433716 and perplexity is 41.27648702583717
At time: 383.53470516204834 and batch: 700, loss is 3.7709567832946775 and perplexity is 43.42159001934173
At time: 383.91113901138306 and batch: 750, loss is 3.7285234832763674 and perplexity is 41.617613673792654
At time: 384.32853746414185 and batch: 800, loss is 3.6444846630096435 and perplexity is 38.263049405161404
At time: 384.7398121356964 and batch: 850, loss is 3.6013581132888794 and perplexity is 36.647972759714385
At time: 385.1474657058716 and batch: 900, loss is 3.502842411994934 and perplexity is 33.20971361832931
At time: 385.5253093242645 and batch: 950, loss is 3.663393244743347 and perplexity is 38.99343289890431
At time: 385.9419951438904 and batch: 1000, loss is 3.68125391960144 and perplexity is 39.69613864455571
At time: 386.38076734542847 and batch: 1050, loss is 3.606474075317383 and perplexity is 36.83594281061695
At time: 386.7672498226166 and batch: 1100, loss is 3.758346381187439 and perplexity is 42.877464341513935
At time: 387.16044902801514 and batch: 1150, loss is 3.6727183437347413 and perplexity is 39.35875118804664
At time: 387.5924918651581 and batch: 1200, loss is 3.595835223197937 and perplexity is 36.44612793057098
At time: 387.98140716552734 and batch: 1250, loss is 3.479238109588623 and perplexity is 32.43500074352712
At time: 388.3797369003296 and batch: 1300, loss is 3.6003169202804566 and perplexity is 36.6098350045315
At time: 388.8018128871918 and batch: 1350, loss is 3.6156259393692016 and perplexity is 37.17460769514938
At time: 389.19452595710754 and batch: 1400, loss is 3.42988440990448 and perplexity is 30.873073921856818
At time: 389.6042912006378 and batch: 1450, loss is 3.5526044034957884 and perplexity is 34.90410358386375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434354341947115 and perplexity of 84.29767983791255
Finished 31 epochs...
Completing Train Step...
At time: 390.9344334602356 and batch: 50, loss is 3.737768087387085 and perplexity is 42.00413590598224
At time: 391.35749530792236 and batch: 100, loss is 3.796082353591919 and perplexity is 44.52640364675548
At time: 391.75058245658875 and batch: 150, loss is 3.616867847442627 and perplexity is 37.220803820305306
At time: 392.1478593349457 and batch: 200, loss is 3.768406476974487 and perplexity is 43.310992752281564
At time: 392.54399037361145 and batch: 250, loss is 3.8342694997787476 and perplexity is 46.25962265758353
At time: 392.9535188674927 and batch: 300, loss is 3.8352976655960083 and perplexity is 46.3072096798021
At time: 393.34539127349854 and batch: 350, loss is 3.8047051334381106 and perplexity is 44.912005111820534
At time: 393.74198055267334 and batch: 400, loss is 3.589243211746216 and perplexity is 36.20666477695484
At time: 394.1524658203125 and batch: 450, loss is 3.699462027549744 and perplexity is 40.4255506766004
At time: 394.52976965904236 and batch: 500, loss is 3.688374848365784 and perplexity is 39.97982086175666
At time: 394.945378780365 and batch: 550, loss is 3.7273804187774657 and perplexity is 41.57006923542973
At time: 395.335168838501 and batch: 600, loss is 3.669419298171997 and perplexity is 39.22911882369606
At time: 395.7310092449188 and batch: 650, loss is 3.720236649513245 and perplexity is 41.27416046294686
At time: 396.1271481513977 and batch: 700, loss is 3.7709091997146604 and perplexity is 43.41952391379531
At time: 396.55371356010437 and batch: 750, loss is 3.7284775972366333 and perplexity is 41.61570405013085
At time: 396.949355840683 and batch: 800, loss is 3.644444808959961 and perplexity is 38.26152449807647
At time: 397.3414742946625 and batch: 850, loss is 3.60131929397583 and perplexity is 36.64655013819997
At time: 397.72518825531006 and batch: 900, loss is 3.5028095769882204 and perplexity is 33.20862319506182
At time: 398.12788248062134 and batch: 950, loss is 3.6633672666549684 and perplexity is 38.992419937215736
At time: 398.5199375152588 and batch: 1000, loss is 3.681233024597168 and perplexity is 39.695309202234775
At time: 398.9220643043518 and batch: 1050, loss is 3.6064662599563597 and perplexity is 36.835654925550216
At time: 399.3218448162079 and batch: 1100, loss is 3.7583444547653198 and perplexity is 42.87738174149778
At time: 399.73995661735535 and batch: 1150, loss is 3.6727180957794188 and perplexity is 39.358741428836005
At time: 400.1330397129059 and batch: 1200, loss is 3.595843553543091 and perplexity is 36.44643154066074
At time: 400.525603055954 and batch: 1250, loss is 3.4792569351196287 and perplexity is 32.43561135538681
At time: 400.927937746048 and batch: 1300, loss is 3.600334963798523 and perplexity is 36.61049558071035
At time: 401.3306984901428 and batch: 1350, loss is 3.6156473636627195 and perplexity is 37.175404143387695
At time: 401.73885130882263 and batch: 1400, loss is 3.4299124479293823 and perplexity is 30.8739395540075
At time: 402.13268089294434 and batch: 1450, loss is 3.552635250091553 and perplexity is 34.90518027324353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434353298611111 and perplexity of 84.29759188715398
Finished 32 epochs...
Completing Train Step...
At time: 403.50664710998535 and batch: 50, loss is 3.7377097606658936 and perplexity is 42.001686013906145
At time: 403.89880418777466 and batch: 100, loss is 3.7960161638259886 and perplexity is 44.52345655205521
At time: 404.3322870731354 and batch: 150, loss is 3.6167961311340333 and perplexity is 37.2181345773677
At time: 404.72053122520447 and batch: 200, loss is 3.7683343172073362 and perplexity is 43.30786755388763
At time: 405.1362500190735 and batch: 250, loss is 3.834195084571838 and perplexity is 46.25618036627291
At time: 405.5363972187042 and batch: 300, loss is 3.8352257919311525 and perplexity is 46.30388153053775
At time: 405.9320936203003 and batch: 350, loss is 3.804635076522827 and perplexity is 44.908858825494036
At time: 406.3111937046051 and batch: 400, loss is 3.5891766500473024 and perplexity is 36.2042548800396
At time: 406.7276146411896 and batch: 450, loss is 3.6993907737731933 and perplexity is 40.42267030606541
At time: 407.13135743141174 and batch: 500, loss is 3.688311004638672 and perplexity is 39.97726848246114
At time: 407.50827169418335 and batch: 550, loss is 3.727317047119141 and perplexity is 41.567434954675846
At time: 407.91189646720886 and batch: 600, loss is 3.6693601608276367 and perplexity is 39.22679898638243
At time: 408.32971835136414 and batch: 650, loss is 3.720180835723877 and perplexity is 41.27185685993545
At time: 408.7424418926239 and batch: 700, loss is 3.770861611366272 and perplexity is 43.41745769952869
At time: 409.15895342826843 and batch: 750, loss is 3.7284319257736205 and perplexity is 41.613803443444645
At time: 409.5810377597809 and batch: 800, loss is 3.6444051599502565 and perplexity is 38.26000749659434
At time: 410.0040910243988 and batch: 850, loss is 3.6012805271148682 and perplexity is 36.64512949402317
At time: 410.399662733078 and batch: 900, loss is 3.5027767419815063 and perplexity is 33.20753280759779
At time: 410.79261898994446 and batch: 950, loss is 3.6633413076400756 and perplexity is 38.99140774554368
At time: 411.21003675460815 and batch: 1000, loss is 3.681212477684021 and perplexity is 39.694493594543395
At time: 411.619446516037 and batch: 1050, loss is 3.6064580345153807 and perplexity is 36.83535193729081
At time: 412.0190238952637 and batch: 1100, loss is 3.758341898918152 and perplexity is 42.87727215360314
At time: 412.4141342639923 and batch: 1150, loss is 3.6727174806594847 and perplexity is 39.35871721849702
At time: 412.824688911438 and batch: 1200, loss is 3.5958510065078735 and perplexity is 36.44670317564371
At time: 413.2325050830841 and batch: 1250, loss is 3.479274797439575 and perplexity is 32.436190735829015
At time: 413.6103935241699 and batch: 1300, loss is 3.600352478027344 and perplexity is 36.61113679092234
At time: 414.0191955566406 and batch: 1350, loss is 3.6156684875488283 and perplexity is 37.17618944068511
At time: 414.43613934516907 and batch: 1400, loss is 3.429939880371094 and perplexity is 30.87478651317175
At time: 414.85928654670715 and batch: 1450, loss is 3.552665767669678 and perplexity is 34.906245511063645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434353820279113 and perplexity of 84.2976358625218
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 416.1461384296417 and batch: 50, loss is 3.737670383453369 and perplexity is 42.00003213715233
At time: 416.5548195838928 and batch: 100, loss is 3.795978808403015 and perplexity is 44.5217933905677
At time: 416.9303529262543 and batch: 150, loss is 3.6167809534072877 and perplexity is 37.217569694977925
At time: 417.35358214378357 and batch: 200, loss is 3.768322730064392 and perplexity is 43.30736574234296
At time: 417.75068831443787 and batch: 250, loss is 3.834175453186035 and perplexity is 46.25527230226366
At time: 418.1495792865753 and batch: 300, loss is 3.835201077461243 and perplexity is 46.30273716879216
At time: 418.54017210006714 and batch: 350, loss is 3.804630365371704 and perplexity is 44.90864725357172
At time: 418.9454209804535 and batch: 400, loss is 3.58912193775177 and perplexity is 36.20227411633363
At time: 419.3427963256836 and batch: 450, loss is 3.6993486499786377 and perplexity is 40.420967585668826
At time: 419.7356116771698 and batch: 500, loss is 3.6882458257675172 and perplexity is 39.97466289414518
At time: 420.13319969177246 and batch: 550, loss is 3.727253541946411 and perplexity is 41.56479529135614
At time: 420.5304284095764 and batch: 600, loss is 3.6692852354049683 and perplexity is 39.22386001199177
At time: 420.93030643463135 and batch: 650, loss is 3.7201480054855347 and perplexity is 41.27050191727958
At time: 421.3207643032074 and batch: 700, loss is 3.770777077674866 and perplexity is 43.413787616682896
At time: 421.73658537864685 and batch: 750, loss is 3.728355383872986 and perplexity is 41.610618365733956
At time: 422.17378640174866 and batch: 800, loss is 3.6443284511566163 and perplexity is 38.257072730137246
At time: 422.57344222068787 and batch: 850, loss is 3.6012232303619385 and perplexity is 36.6430299072428
At time: 422.97588443756104 and batch: 900, loss is 3.502689490318298 and perplexity is 33.204635521527635
At time: 423.3848237991333 and batch: 950, loss is 3.6632621335983275 and perplexity is 38.98832076040518
At time: 423.80366611480713 and batch: 1000, loss is 3.681125111579895 and perplexity is 39.691025792769146
At time: 424.19562244415283 and batch: 1050, loss is 3.606347680091858 and perplexity is 36.83128721754654
At time: 424.6114044189453 and batch: 1100, loss is 3.758227519989014 and perplexity is 42.87236817759095
At time: 425.03125834465027 and batch: 1150, loss is 3.6726104068756102 and perplexity is 39.354503157327756
At time: 425.4393825531006 and batch: 1200, loss is 3.5957236242294313 and perplexity is 36.4420608072355
At time: 425.8423230648041 and batch: 1250, loss is 3.4791437768936158 and perplexity is 32.431941206803856
At time: 426.2528820037842 and batch: 1300, loss is 3.6002255153656004 and perplexity is 36.606488838610346
At time: 426.6560025215149 and batch: 1350, loss is 3.6155322694778445 and perplexity is 37.17112571676615
At time: 427.0514187812805 and batch: 1400, loss is 3.4297974348068236 and perplexity is 30.8703888500064
At time: 427.4443998336792 and batch: 1450, loss is 3.5525212335586547 and perplexity is 34.90120073247963
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434354341947115 and perplexity of 84.29767983791255
Annealing...
Finished 34 epochs...
Completing Train Step...
At time: 428.7974615097046 and batch: 50, loss is 3.7376643085479735 and perplexity is 41.999776991705474
At time: 429.1857211589813 and batch: 100, loss is 3.7959732484817503 and perplexity is 44.521545853590034
At time: 429.59318566322327 and batch: 150, loss is 3.6167775869369505 and perplexity is 37.21744440334442
At time: 430.0108585357666 and batch: 200, loss is 3.7683206176757813 and perplexity is 43.30727426045343
At time: 430.41027665138245 and batch: 250, loss is 3.834172930717468 and perplexity is 46.25515562494038
At time: 430.8052399158478 and batch: 300, loss is 3.8351978635787964 and perplexity is 46.30258835747709
At time: 431.19981598854065 and batch: 350, loss is 3.8046292066574097 and perplexity is 44.90859521731036
At time: 431.60310983657837 and batch: 400, loss is 3.5891151285171508 and perplexity is 36.2020276073947
At time: 432.0098457336426 and batch: 450, loss is 3.699343194961548 and perplexity is 40.42074708920127
At time: 432.41173124313354 and batch: 500, loss is 3.688237581253052 and perplexity is 39.974333323817284
At time: 432.81325697898865 and batch: 550, loss is 3.7272451400756834 and perplexity is 41.56444607078634
At time: 433.2469165325165 and batch: 600, loss is 3.6692759466171263 and perplexity is 39.223495671569914
At time: 433.63808012008667 and batch: 650, loss is 3.7201436042785643 and perplexity is 41.270320277658584
At time: 434.046434879303 and batch: 700, loss is 3.770766191482544 and perplexity is 43.41331500841394
At time: 434.47002482414246 and batch: 750, loss is 3.728345527648926 and perplexity is 41.610208244177194
At time: 434.8508973121643 and batch: 800, loss is 3.644318313598633 and perplexity is 38.25668489881001
At time: 435.25606894493103 and batch: 850, loss is 3.601215991973877 and perplexity is 36.64276467173253
At time: 435.6582188606262 and batch: 900, loss is 3.502678270339966 and perplexity is 33.204262968326574
At time: 436.0855801105499 and batch: 950, loss is 3.663251738548279 and perplexity is 38.98791547696604
At time: 436.4754047393799 and batch: 1000, loss is 3.68111328125 and perplexity is 39.690556237617656
At time: 436.870792388916 and batch: 1050, loss is 3.6063330698013307 and perplexity is 36.8307491056708
At time: 437.2795317173004 and batch: 1100, loss is 3.758212242126465 and perplexity is 42.87171318444625
At time: 437.7205846309662 and batch: 1150, loss is 3.672596125602722 and perplexity is 39.35394112894203
At time: 438.1179211139679 and batch: 1200, loss is 3.595706596374512 and perplexity is 36.441440282394225
At time: 438.5115032196045 and batch: 1250, loss is 3.4791262197494506 and perplexity is 32.43137179953513
At time: 438.89996433258057 and batch: 1300, loss is 3.600208492279053 and perplexity is 36.60586568848663
At time: 439.29042077064514 and batch: 1350, loss is 3.6155140209198 and perplexity is 37.17044740351006
At time: 439.68658804893494 and batch: 1400, loss is 3.429778184890747 and perplexity is 30.869794603331396
At time: 440.07864785194397 and batch: 1450, loss is 3.5525017833709716 and perplexity is 34.900521904176706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434354341947115 and perplexity of 84.29767983791255
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 441.40974283218384 and batch: 50, loss is 3.7376638507843016 and perplexity is 41.99975776573774
At time: 441.8161165714264 and batch: 100, loss is 3.795972719192505 and perplexity is 44.52152228882086
At time: 442.1979100704193 and batch: 150, loss is 3.6167775344848634 and perplexity is 37.21744245121184
At time: 442.5837790966034 and batch: 200, loss is 3.768320708274841 and perplexity is 43.30727818405194
At time: 442.9833433628082 and batch: 250, loss is 3.8341728925704954 and perplexity is 46.255153860446256
At time: 443.391455411911 and batch: 300, loss is 3.8351975774765013 and perplexity is 46.302575110202184
At time: 443.7879385948181 and batch: 350, loss is 3.804629392623901 and perplexity is 44.908603568805034
At time: 444.20200514793396 and batch: 400, loss is 3.589114785194397 and perplexity is 36.20201517841702
At time: 444.61292338371277 and batch: 450, loss is 3.6993428373336794 and perplexity is 40.42073263361823
At time: 444.9960193634033 and batch: 500, loss is 3.688237009048462 and perplexity is 39.97431045032682
At time: 445.3950514793396 and batch: 550, loss is 3.727244472503662 and perplexity is 41.564418323534326
At time: 445.7919454574585 and batch: 600, loss is 3.669275245666504 and perplexity is 39.223468177845845
At time: 446.19046092033386 and batch: 650, loss is 3.720143365859985 and perplexity is 41.27031043804864
At time: 446.5768744945526 and batch: 700, loss is 3.7707654237747192 and perplexity is 43.4132816796851
At time: 446.9674701690674 and batch: 750, loss is 3.728344612121582 and perplexity is 41.61017014891121
At time: 447.3744258880615 and batch: 800, loss is 3.6443173933029174 and perplexity is 38.256649691363
At time: 447.8113203048706 and batch: 850, loss is 3.6012154626846313 and perplexity is 36.64274527711638
At time: 448.204384803772 and batch: 900, loss is 3.5026771306991575 and perplexity is 33.20422512741505
At time: 448.6006302833557 and batch: 950, loss is 3.6632508754730226 and perplexity is 38.98788182747542
At time: 448.98789834976196 and batch: 1000, loss is 3.681112265586853 and perplexity is 39.69051592540288
At time: 449.38028740882874 and batch: 1050, loss is 3.6063317680358886 and perplexity is 36.83070116070561
At time: 449.7879159450531 and batch: 1100, loss is 3.758210816383362 and perplexity is 42.87165206044043
At time: 450.18929648399353 and batch: 1150, loss is 3.6725948429107667 and perplexity is 39.35389064999071
At time: 450.58746457099915 and batch: 1200, loss is 3.595705122947693 and perplexity is 36.44138658863836
At time: 450.9941680431366 and batch: 1250, loss is 3.479124655723572 and perplexity is 32.43132107607002
At time: 451.40763115882874 and batch: 1300, loss is 3.600206995010376 and perplexity is 36.60581087971157
At time: 451.80358362197876 and batch: 1350, loss is 3.6155123710632324 and perplexity is 37.17038607765389
At time: 452.1972508430481 and batch: 1400, loss is 3.4297764348983764 and perplexity is 30.86974058147363
At time: 452.62565302848816 and batch: 1450, loss is 3.5524999952316283 and perplexity is 34.900459497236184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434354863615117 and perplexity of 84.29772381332626
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 453.97962522506714 and batch: 50, loss is 3.737663836479187 and perplexity is 41.99975716492641
At time: 454.3766348361969 and batch: 100, loss is 3.795972785949707 and perplexity is 44.52152526095322
At time: 454.7714068889618 and batch: 150, loss is 3.616777567863464 and perplexity is 37.21744369347801
At time: 455.18308877944946 and batch: 200, loss is 3.768320708274841 and perplexity is 43.30727818405194
At time: 455.5638225078583 and batch: 250, loss is 3.834172902107239 and perplexity is 46.255154301569796
At time: 455.9819378852844 and batch: 300, loss is 3.835197582244873 and perplexity is 46.30257533099008
At time: 456.3917076587677 and batch: 350, loss is 3.8046294116973876 and perplexity is 44.90860442536868
At time: 456.8065049648285 and batch: 400, loss is 3.589114775657654 and perplexity is 36.20201483316771
At time: 457.1963107585907 and batch: 450, loss is 3.6993428373336794 and perplexity is 40.42073263361823
At time: 457.6198787689209 and batch: 500, loss is 3.6882369232177736 and perplexity is 39.97430701930438
At time: 458.0264594554901 and batch: 550, loss is 3.727244486808777 and perplexity is 41.56441891811811
At time: 458.4499545097351 and batch: 600, loss is 3.6692752027511597 and perplexity is 39.22346649455724
At time: 458.83714962005615 and batch: 650, loss is 3.72014340877533 and perplexity is 41.27031220917827
At time: 459.23637199401855 and batch: 700, loss is 3.770765337944031 and perplexity is 43.413277953493406
At time: 459.6528494358063 and batch: 750, loss is 3.7283445692062376 and perplexity is 41.61016836319646
At time: 460.04981446266174 and batch: 800, loss is 3.644317417144775 and perplexity is 38.25665060347262
At time: 460.4357750415802 and batch: 850, loss is 3.601215581893921 and perplexity is 36.642749645272275
At time: 460.8278212547302 and batch: 900, loss is 3.502677092552185 and perplexity is 33.204223860774405
At time: 461.2291691303253 and batch: 950, loss is 3.66325080871582 and perplexity is 38.987879224753584
At time: 461.6301109790802 and batch: 1000, loss is 3.6811122512817382 and perplexity is 39.69051535762549
At time: 462.0280306339264 and batch: 1050, loss is 3.6063317680358886 and perplexity is 36.83070116070561
At time: 462.42843770980835 and batch: 1100, loss is 3.758210778236389 and perplexity is 42.87165042501672
At time: 462.82944655418396 and batch: 1150, loss is 3.672594828605652 and perplexity is 39.35389008702879
At time: 463.21962690353394 and batch: 1200, loss is 3.5957050704956055 and perplexity is 36.44138467721161
At time: 463.643593788147 and batch: 1250, loss is 3.4791245746612547 and perplexity is 32.43131844711209
At time: 464.0589563846588 and batch: 1300, loss is 3.6002069187164305 and perplexity is 36.605808086909946
At time: 464.44948148727417 and batch: 1350, loss is 3.6155123329162597 and perplexity is 37.17038465971621
At time: 464.85820055007935 and batch: 1400, loss is 3.4297763442993165 and perplexity is 30.869737784704284
At time: 465.2830605506897 and batch: 1450, loss is 3.552499966621399 and perplexity is 34.900458498726046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.434354863615117 and perplexity of 84.29772381332626
Annealing...
Model not improving. Stopping early with 84.29759188715398loss at 36 epochs.
Finished Training.
Improved accuracyfrom -101.61114460798582 to -84.29759188715398
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7faab2a668>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.558669725775248, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 14.800885502949932, 'anneal': 2.9089546393359518, 'wordvec_dim': 200}, 'best_accuracy': -123.36313670519357}, {'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.19290165492183386, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 22.074200923057358, 'anneal': 3.0942517694212013, 'wordvec_dim': 200}, 'best_accuracy': -129.20592100833727}, {'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.9222754832816875, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 26.928206893112907, 'anneal': 3.519315938726637, 'wordvec_dim': 200}, 'best_accuracy': -154.1480131825694}, {'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.42622398020897856, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 0.19597144310909975, 'anneal': 6.0823246452134585, 'wordvec_dim': 200}, 'best_accuracy': -101.61114460798582}, {'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.1615776763065303, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 16.188439477776065, 'anneal': 6.163990410661358, 'wordvec_dim': 200}, 'best_accuracy': -107.94049591217549}, {'params': {'seq_len': 35, 'batch_size': 20, 'num_layers': 1, 'data': 'ptb', 'dropout': 0.20019797681469986, 'tune_wordvecs': True, 'wordvec_source': '', 'lr': 2.5878190891379167, 'anneal': 7.684145487285577, 'wordvec_dim': 200}, 'best_accuracy': -84.29759188715398}]
