TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'domain': [0, 1], 'name': 'dropout'}, {'type': 'continuous', 'domain': [0, 1], 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.608182668685913 and batch: 50, loss is 7.632045631408691 and perplexity is 2063.2663883275764
At time: 2.566918134689331 and batch: 100, loss is 6.851718626022339 and perplexity is 945.5044797175904
At time: 3.5251495838165283 and batch: 150, loss is 6.625852832794189 and perplexity is 754.3472703955781
At time: 4.485491991043091 and batch: 200, loss is 6.5540532207489015 and perplexity is 702.0841163787833
At time: 5.45685601234436 and batch: 250, loss is 6.527341785430909 and perplexity is 683.5786953839131
At time: 6.419968605041504 and batch: 300, loss is 6.467342157363891 and perplexity is 643.7704106657645
At time: 7.3875110149383545 and batch: 350, loss is 6.445612678527832 and perplexity is 629.932504875427
At time: 8.364644050598145 and batch: 400, loss is 6.435809726715088 and perplexity is 623.7874758070434
At time: 9.334144830703735 and batch: 450, loss is 6.352484588623047 and perplexity is 573.9168864000874
At time: 10.293701171875 and batch: 500, loss is 6.344163675308227 and perplexity is 569.1611870588279
At time: 11.253666400909424 and batch: 550, loss is 6.31060037612915 and perplexity is 550.3752818213698
At time: 12.212722063064575 and batch: 600, loss is 6.36141432762146 and perplexity is 579.0647647999664
At time: 13.172760248184204 and batch: 650, loss is 6.444529218673706 and perplexity is 629.2503678963307
At time: 14.132171869277954 and batch: 700, loss is 6.345030193328857 and perplexity is 569.6545892241187
At time: 15.091321229934692 and batch: 750, loss is 6.283054933547974 and perplexity is 535.4218460836898
At time: 16.052388906478882 and batch: 800, loss is 6.295650224685669 and perplexity is 542.2082890115222
At time: 17.012477159500122 and batch: 850, loss is 6.343945035934448 and perplexity is 569.0367596161747
At time: 17.971797704696655 and batch: 900, loss is 6.333301334381104 and perplexity is 563.0122207465485
At time: 18.93181800842285 and batch: 950, loss is 6.345271577835083 and perplexity is 569.792111613077
At time: 19.891576051712036 and batch: 1000, loss is 6.332581577301025 and perplexity is 562.6071345138253
At time: 20.852445125579834 and batch: 1050, loss is 6.23958869934082 and perplexity is 512.6476152729493
At time: 21.813315629959106 and batch: 1100, loss is 6.317591772079468 and perplexity is 554.2366558065447
At time: 22.773420810699463 and batch: 1150, loss is 6.229001226425171 and perplexity is 507.24860390750933
At time: 23.733555793762207 and batch: 1200, loss is 6.32276237487793 and perplexity is 557.1098149913404
At time: 24.693625450134277 and batch: 1250, loss is 6.251608610153198 and perplexity is 518.8467759289935
At time: 25.654396295547485 and batch: 1300, loss is 6.262388162612915 and perplexity is 524.4699652502887
At time: 26.613784790039062 and batch: 1350, loss is 6.252873258590698 and perplexity is 519.5033497735104
At time: 27.57412600517273 and batch: 1400, loss is 6.2763403797149655 and perplexity is 531.8387701150064
At time: 28.5343599319458 and batch: 1450, loss is 6.280200176239013 and perplexity is 533.8955263280238
At time: 29.494628429412842 and batch: 1500, loss is 6.2607918548583985 and perplexity is 523.633417649101
At time: 30.454368352890015 and batch: 1550, loss is 6.232969856262207 and perplexity is 509.26568572990027
At time: 31.41416049003601 and batch: 1600, loss is 6.2243184566497805 and perplexity is 504.87882836360177
At time: 32.37386918067932 and batch: 1650, loss is 6.223972425460816 and perplexity is 504.70415476533935
At time: 33.33462119102478 and batch: 1700, loss is 6.24584958076477 and perplexity is 515.8673097498187
At time: 34.307405948638916 and batch: 1750, loss is 6.264361724853516 and perplexity is 525.5060614338939
At time: 35.27484893798828 and batch: 1800, loss is 6.2776518726348876 and perplexity is 532.5367304815501
At time: 36.23537540435791 and batch: 1850, loss is 6.221185646057129 and perplexity is 503.2996136040625
At time: 37.19544959068298 and batch: 1900, loss is 6.1930175876617435 and perplexity is 489.32044796436026
At time: 38.15660071372986 and batch: 1950, loss is 6.135441761016846 and perplexity is 461.9431174120698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.599171057412791 and perplexity of 270.2023323458506
finished 1 epochs...
Completing Train Step...
At time: 41.14740443229675 and batch: 50, loss is 5.849960117340088 and perplexity is 347.2205321241847
At time: 42.042399883270264 and batch: 100, loss is 5.7073766803741455 and perplexity is 301.08020178623633
At time: 42.93369722366333 and batch: 150, loss is 5.557877616882324 and perplexity is 259.27197749506973
At time: 43.82414770126343 and batch: 200, loss is 5.468055171966553 and perplexity is 236.99882230997295
At time: 44.73864126205444 and batch: 250, loss is 5.43532543182373 and perplexity is 229.36747960857784
At time: 45.62952780723572 and batch: 300, loss is 5.3978601169586184 and perplexity is 220.93313892850537
At time: 46.51960611343384 and batch: 350, loss is 5.3553125858306885 and perplexity is 211.7301498546799
At time: 47.4119086265564 and batch: 400, loss is 5.296025581359864 and perplexity is 199.5421677892935
At time: 48.30194926261902 and batch: 450, loss is 5.221372232437134 and perplexity is 185.18813095402652
At time: 49.19383978843689 and batch: 500, loss is 5.198268928527832 and perplexity is 180.9587181128579
At time: 50.086199045181274 and batch: 550, loss is 5.134315500259399 and perplexity is 169.74808757681865
At time: 50.97853446006775 and batch: 600, loss is 5.127217416763306 and perplexity is 168.54746756930422
At time: 51.87040567398071 and batch: 650, loss is 5.198648281097412 and perplexity is 181.02737828994586
At time: 52.76236319541931 and batch: 700, loss is 5.161072540283203 and perplexity is 174.35135420987416
At time: 53.65976285934448 and batch: 750, loss is 5.102483043670654 and perplexity is 164.42968691645538
At time: 54.55837345123291 and batch: 800, loss is 5.082962598800659 and perplexity is 161.2510712074284
At time: 55.455503940582275 and batch: 850, loss is 5.0720030879974365 and perplexity is 159.49348707369575
At time: 56.350666761398315 and batch: 900, loss is 5.085141696929932 and perplexity is 161.6028362411077
At time: 57.24689841270447 and batch: 950, loss is 5.133189353942871 and perplexity is 169.55703399059382
At time: 58.1429603099823 and batch: 1000, loss is 5.087084627151489 and perplexity is 161.91712449673574
At time: 59.0382239818573 and batch: 1050, loss is 4.980423173904419 and perplexity is 145.53595564302114
At time: 59.93247604370117 and batch: 1100, loss is 5.06084641456604 and perplexity is 157.7239596980941
At time: 60.82686233520508 and batch: 1150, loss is 4.955348386764526 and perplexity is 141.932045006518
At time: 61.722774267196655 and batch: 1200, loss is 5.038779706954956 and perplexity is 154.2816313059356
At time: 62.62045121192932 and batch: 1250, loss is 4.982908544540405 and perplexity is 145.89811629896215
At time: 63.51725888252258 and batch: 1300, loss is 5.014782266616821 and perplexity is 150.62333746644296
At time: 64.41443085670471 and batch: 1350, loss is 4.923425407409668 and perplexity is 137.47270762565833
At time: 65.31214666366577 and batch: 1400, loss is 4.935438575744629 and perplexity is 139.13415001634593
At time: 66.21018862724304 and batch: 1450, loss is 4.882593269348145 and perplexity is 131.97246064574176
At time: 67.10819220542908 and batch: 1500, loss is 4.851792802810669 and perplexity is 127.96960858658683
At time: 68.00485801696777 and batch: 1550, loss is 4.849901905059815 and perplexity is 127.727859774706
At time: 68.90107226371765 and batch: 1600, loss is 4.904757318496704 and perplexity is 134.9301609788733
At time: 69.79828977584839 and batch: 1650, loss is 4.864729299545288 and perplexity is 129.6358413803964
At time: 70.69678926467896 and batch: 1700, loss is 4.893366479873658 and perplexity is 133.4019138224389
At time: 71.59220123291016 and batch: 1750, loss is 4.898548412322998 and perplexity is 134.09498770861765
At time: 72.48961758613586 and batch: 1800, loss is 4.84521879196167 and perplexity is 127.13109421257298
At time: 73.3853440284729 and batch: 1850, loss is 4.844954404830933 and perplexity is 127.09748683022214
At time: 74.28146767616272 and batch: 1900, loss is 4.923853206634521 and perplexity is 137.5315309248029
At time: 75.17908263206482 and batch: 1950, loss is 4.841380939483643 and perplexity is 126.64411889505556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6492224404978195 and perplexity of 104.50369613557777
finished 2 epochs...
Completing Train Step...
At time: 78.11937928199768 and batch: 50, loss is 4.814574928283691 and perplexity is 123.29439221090868
At time: 79.03808307647705 and batch: 100, loss is 4.76059923171997 and perplexity is 116.81590472563823
At time: 79.93294501304626 and batch: 150, loss is 4.699907608032227 and perplexity is 109.9370146857648
At time: 80.82710361480713 and batch: 200, loss is 4.689513359069824 and perplexity is 108.80022028192344
At time: 81.7237286567688 and batch: 250, loss is 4.702441930770874 and perplexity is 110.21598391161471
At time: 82.62110233306885 and batch: 300, loss is 4.724442081451416 and perplexity is 112.66762147975896
At time: 83.51664638519287 and batch: 350, loss is 4.723846635818481 and perplexity is 112.60055400607446
At time: 84.41313195228577 and batch: 400, loss is 4.679863042831421 and perplexity is 107.75531369809339
At time: 85.30819320678711 and batch: 450, loss is 4.6748991870880126 and perplexity is 107.22175720959306
At time: 86.20511722564697 and batch: 500, loss is 4.67151198387146 and perplexity is 106.85918972022046
At time: 87.10156679153442 and batch: 550, loss is 4.633123254776001 and perplexity is 102.83474216979691
At time: 87.99815130233765 and batch: 600, loss is 4.613508205413819 and perplexity is 100.83728775248471
At time: 88.89483261108398 and batch: 650, loss is 4.685873117446899 and perplexity is 108.40488119293815
At time: 89.8146562576294 and batch: 700, loss is 4.691027021408081 and perplexity is 108.9650317807699
At time: 90.70937967300415 and batch: 750, loss is 4.655009002685547 and perplexity is 105.11016626841482
At time: 91.60449814796448 and batch: 800, loss is 4.628710422515869 and perplexity is 102.38194948594142
At time: 92.49895763397217 and batch: 850, loss is 4.625043201446533 and perplexity is 102.00717984523581
At time: 93.39402031898499 and batch: 900, loss is 4.618290796279907 and perplexity is 101.32070631901846
At time: 94.29007601737976 and batch: 950, loss is 4.685595874786377 and perplexity is 108.37483090106652
At time: 95.18769335746765 and batch: 1000, loss is 4.658432111740113 and perplexity is 105.47058635698909
At time: 96.082674741745 and batch: 1050, loss is 4.577208127975464 and perplexity is 97.24252618483123
At time: 96.97980666160583 and batch: 1100, loss is 4.639422521591187 and perplexity is 103.48457021992661
At time: 97.87764406204224 and batch: 1150, loss is 4.5708949089050295 and perplexity is 96.63054662719519
At time: 98.77494025230408 and batch: 1200, loss is 4.65889196395874 and perplexity is 105.5190983934542
At time: 99.67241764068604 and batch: 1250, loss is 4.629099063873291 and perplexity is 102.42174707875941
At time: 100.56777667999268 and batch: 1300, loss is 4.644008512496948 and perplexity is 103.9602393914272
At time: 101.46604108810425 and batch: 1350, loss is 4.534416255950927 and perplexity is 93.16911251232918
At time: 102.3639132976532 and batch: 1400, loss is 4.542789964675904 and perplexity is 93.95255912165709
At time: 103.2616195678711 and batch: 1450, loss is 4.49177698135376 and perplexity is 89.27995381732131
At time: 104.1587963104248 and batch: 1500, loss is 4.4811002635955814 and perplexity is 88.33180750102153
At time: 105.05611824989319 and batch: 1550, loss is 4.4957502079010006 and perplexity is 89.63538894451585
At time: 105.95445799827576 and batch: 1600, loss is 4.562758092880249 and perplexity is 95.84747183513923
At time: 106.85092854499817 and batch: 1650, loss is 4.526287851333618 and perplexity is 92.41486583190559
At time: 107.74668478965759 and batch: 1700, loss is 4.5493525123596195 and perplexity is 94.57115483273704
At time: 108.64391922950745 and batch: 1750, loss is 4.543315649032593 and perplexity is 94.00196149614833
At time: 109.5402672290802 and batch: 1800, loss is 4.5080696392059325 and perplexity is 90.74647588846125
At time: 110.43643879890442 and batch: 1850, loss is 4.527999315261841 and perplexity is 92.57316596505247
At time: 111.33427095413208 and batch: 1900, loss is 4.624115533828736 and perplexity is 101.91259496615832
At time: 112.2305257320404 and batch: 1950, loss is 4.551778392791748 and perplexity is 94.80085164254255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488558037336483 and perplexity of 88.99302868982979
finished 3 epochs...
Completing Train Step...
At time: 115.16997766494751 and batch: 50, loss is 4.520776443481445 and perplexity is 91.90693081894747
At time: 116.09020519256592 and batch: 100, loss is 4.477791013717652 and perplexity is 88.03997861151137
At time: 116.9860680103302 and batch: 150, loss is 4.431010093688965 and perplexity is 84.0162383363775
At time: 117.88044047355652 and batch: 200, loss is 4.429550476074219 and perplexity is 83.893696209057
At time: 118.77488923072815 and batch: 250, loss is 4.4338552856445315 and perplexity is 84.25562104522199
At time: 119.66895842552185 and batch: 300, loss is 4.466200885772705 and perplexity is 87.02547446813787
At time: 120.56402158737183 and batch: 350, loss is 4.459784088134765 and perplexity is 86.46883743271029
At time: 121.46038484573364 and batch: 400, loss is 4.423620805740357 and perplexity is 83.39770622927334
At time: 122.35640478134155 and batch: 450, loss is 4.436564836502075 and perplexity is 84.48422550331925
At time: 123.25208067893982 and batch: 500, loss is 4.437891111373902 and perplexity is 84.59634914561917
At time: 124.1460211277008 and batch: 550, loss is 4.405040302276611 and perplexity is 81.86244201946735
At time: 125.03956055641174 and batch: 600, loss is 4.389258327484131 and perplexity is 80.58063237183387
At time: 125.93291711807251 and batch: 650, loss is 4.455152711868286 and perplexity is 86.0692936442166
At time: 126.82616424560547 and batch: 700, loss is 4.469618320465088 and perplexity is 87.32338710225203
At time: 127.7200219631195 and batch: 750, loss is 4.432462854385376 and perplexity is 84.13838252695034
At time: 128.61319041252136 and batch: 800, loss is 4.411781845092773 and perplexity is 82.41618562325574
At time: 129.5065233707428 and batch: 850, loss is 4.408969535827636 and perplexity is 82.18473143376022
At time: 130.39995193481445 and batch: 900, loss is 4.39203556060791 and perplexity is 80.80473462124493
At time: 131.2938883304596 and batch: 950, loss is 4.47256742477417 and perplexity is 87.58129298819682
At time: 132.18767642974854 and batch: 1000, loss is 4.445957336425781 and perplexity is 85.28148183885749
At time: 133.0809416770935 and batch: 1050, loss is 4.375582904815674 and perplexity is 79.48615891587121
At time: 133.97613620758057 and batch: 1100, loss is 4.429008617401123 and perplexity is 83.84824999597234
At time: 134.89414525032043 and batch: 1150, loss is 4.3739009284973145 and perplexity is 79.35257745086007
At time: 135.7890751361847 and batch: 1200, loss is 4.463951873779297 and perplexity is 86.82997305724066
At time: 136.68424916267395 and batch: 1250, loss is 4.439905986785889 and perplexity is 84.76697208371444
At time: 137.58004117012024 and batch: 1300, loss is 4.447701501846313 and perplexity is 85.43035664389485
At time: 138.47639083862305 and batch: 1350, loss is 4.330963716506958 and perplexity is 76.01751060970427
At time: 139.37114930152893 and batch: 1400, loss is 4.3493173217773435 and perplexity is 77.42558811619075
At time: 140.2673852443695 and batch: 1450, loss is 4.289730458259583 and perplexity is 72.94680364109047
At time: 141.1618423461914 and batch: 1500, loss is 4.290399122238159 and perplexity is 72.99559685235093
At time: 142.05474948883057 and batch: 1550, loss is 4.301987342834472 and perplexity is 73.84640609279712
At time: 142.94857144355774 and batch: 1600, loss is 4.379649744033814 and perplexity is 79.8100745542188
At time: 143.84119176864624 and batch: 1650, loss is 4.338715019226075 and perplexity is 76.60903492672227
At time: 144.73566269874573 and batch: 1700, loss is 4.358925924301148 and perplexity is 78.17312546080737
At time: 145.63105583190918 and batch: 1750, loss is 4.356589288711548 and perplexity is 77.99067659497415
At time: 146.52543926239014 and batch: 1800, loss is 4.320783557891846 and perplexity is 75.2475660226449
At time: 147.42133021354675 and batch: 1850, loss is 4.347411069869995 and perplexity is 77.27813602623146
At time: 148.31574058532715 and batch: 1900, loss is 4.4438230991363525 and perplexity is 85.09966500936208
At time: 149.21255898475647 and batch: 1950, loss is 4.373666820526123 and perplexity is 79.33400255429471
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421983727743459 and perplexity of 83.26128937239777
finished 4 epochs...
Completing Train Step...
At time: 152.14327692985535 and batch: 50, loss is 4.347229971885681 and perplexity is 77.26414237871447
At time: 153.0747354030609 and batch: 100, loss is 4.309114656448364 and perplexity is 74.37461269933709
At time: 153.97241711616516 and batch: 150, loss is 4.270169229507446 and perplexity is 71.53374021458526
At time: 154.86792969703674 and batch: 200, loss is 4.270615396499633 and perplexity is 71.56566332928719
At time: 155.76320719718933 and batch: 250, loss is 4.266712331771851 and perplexity is 71.28688231710443
At time: 156.68338751792908 and batch: 300, loss is 4.3014726734161375 and perplexity is 73.8084093846378
At time: 157.57977676391602 and batch: 350, loss is 4.300400514602661 and perplexity is 73.72931745513851
At time: 158.4773552417755 and batch: 400, loss is 4.259916043281555 and perplexity is 70.80403872998585
At time: 159.3724205493927 and batch: 450, loss is 4.281372528076172 and perplexity is 72.33966011508609
At time: 160.26800298690796 and batch: 500, loss is 4.288769960403442 and perplexity is 72.8767720305708
At time: 161.16338896751404 and batch: 550, loss is 4.256784191131592 and perplexity is 70.58263782747706
At time: 162.07272338867188 and batch: 600, loss is 4.242738585472107 and perplexity is 69.59819168546043
At time: 162.97025084495544 and batch: 650, loss is 4.310421543121338 and perplexity is 74.4718754313222
At time: 163.8655562400818 and batch: 700, loss is 4.325797023773194 and perplexity is 75.62576437766592
At time: 164.76174592971802 and batch: 750, loss is 4.289646048545837 and perplexity is 72.94064648214213
At time: 165.6601538658142 and batch: 800, loss is 4.26780864238739 and perplexity is 71.36507773834063
At time: 166.55851793289185 and batch: 850, loss is 4.26602873802185 and perplexity is 71.23816770229556
At time: 167.45623922348022 and batch: 900, loss is 4.242279672622681 and perplexity is 69.5662595086027
At time: 168.35359144210815 and batch: 950, loss is 4.331311931610108 and perplexity is 76.04398566424179
At time: 169.25001335144043 and batch: 1000, loss is 4.307321901321411 and perplexity is 74.24139667863663
At time: 170.14944458007812 and batch: 1050, loss is 4.241978778839111 and perplexity is 69.54533060241712
At time: 171.04685926437378 and batch: 1100, loss is 4.282101435661316 and perplexity is 72.39240826397814
At time: 171.94399738311768 and batch: 1150, loss is 4.240094051361084 and perplexity is 69.41438004867926
At time: 172.839364528656 and batch: 1200, loss is 4.325402412414551 and perplexity is 75.5959274794131
At time: 173.7374210357666 and batch: 1250, loss is 4.307452445030212 and perplexity is 74.25108905853148
At time: 174.63497233390808 and batch: 1300, loss is 4.313153324127197 and perplexity is 74.67559441723441
At time: 175.53263354301453 and batch: 1350, loss is 4.19105293750763 and perplexity is 66.09234544520734
At time: 176.42889189720154 and batch: 1400, loss is 4.220283389091492 and perplexity is 68.05276696884492
At time: 177.350581407547 and batch: 1450, loss is 4.151831226348877 and perplexity is 63.55026873530566
At time: 178.24922466278076 and batch: 1500, loss is 4.160858197212219 and perplexity is 64.12653220318238
At time: 179.14753460884094 and batch: 1550, loss is 4.169000205993652 and perplexity is 64.65078231988785
At time: 180.04405736923218 and batch: 1600, loss is 4.2541086387634275 and perplexity is 70.3940426942702
At time: 180.94156074523926 and batch: 1650, loss is 4.208671255111694 and perplexity is 67.26709958692898
At time: 181.83719968795776 and batch: 1700, loss is 4.231646580696106 and perplexity is 68.83047384702493
At time: 182.73260807991028 and batch: 1750, loss is 4.228725457191468 and perplexity is 68.62970491022794
At time: 183.62850666046143 and batch: 1800, loss is 4.192445273399353 and perplexity is 66.18443228296695
At time: 184.52580618858337 and batch: 1850, loss is 4.223741455078125 and perplexity is 68.28850529201719
At time: 185.4237720966339 and batch: 1900, loss is 4.312626695632934 and perplexity is 74.63627847474473
At time: 186.3221538066864 and batch: 1950, loss is 4.245246238708496 and perplexity is 69.77293882713278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398012808866279 and perplexity of 81.2891709362807
finished 5 epochs...
Completing Train Step...
At time: 189.24769043922424 and batch: 50, loss is 4.2243378591537475 and perplexity is 68.32924498234262
At time: 190.14180827140808 and batch: 100, loss is 4.191809401512146 and perplexity is 66.14236084054879
At time: 191.03842639923096 and batch: 150, loss is 4.154313402175903 and perplexity is 63.708207611100256
At time: 191.93573021888733 and batch: 200, loss is 4.152615184783936 and perplexity is 63.600109038341316
At time: 192.8321578502655 and batch: 250, loss is 4.149494552612305 and perplexity is 63.40194584998257
At time: 193.72820901870728 and batch: 300, loss is 4.182936954498291 and perplexity is 65.55811194000933
At time: 194.6242926120758 and batch: 350, loss is 4.185138249397278 and perplexity is 65.70258363146998
At time: 195.5223081111908 and batch: 400, loss is 4.144452600479126 and perplexity is 63.08308080051097
At time: 196.42116451263428 and batch: 450, loss is 4.168691091537475 and perplexity is 64.63080091689902
At time: 197.31846070289612 and batch: 500, loss is 4.179760942459106 and perplexity is 65.35022888151381
At time: 198.21686005592346 and batch: 550, loss is 4.144980182647705 and perplexity is 63.116371089989734
At time: 199.11358547210693 and batch: 600, loss is 4.13683747291565 and perplexity is 62.60451955822312
At time: 200.01160049438477 and batch: 650, loss is 4.201610069274903 and perplexity is 66.79378713625547
At time: 200.90876126289368 and batch: 700, loss is 4.217629613876343 and perplexity is 67.8724096422898
At time: 201.8499972820282 and batch: 750, loss is 4.190528655052185 and perplexity is 66.0577034699347
At time: 202.74764132499695 and batch: 800, loss is 4.165638265609741 and perplexity is 64.43379519721772
At time: 203.64516472816467 and batch: 850, loss is 4.162158451080322 and perplexity is 64.20996720631537
At time: 204.54181385040283 and batch: 900, loss is 4.133764252662659 and perplexity is 62.4124174180772
At time: 205.43901872634888 and batch: 950, loss is 4.227626581192016 and perplexity is 68.5543307956401
At time: 206.33558440208435 and batch: 1000, loss is 4.206077399253846 and perplexity is 67.0928445205875
At time: 207.2327229976654 and batch: 1050, loss is 4.14427800655365 and perplexity is 63.07206783922892
At time: 208.12948989868164 and batch: 1100, loss is 4.175931401252747 and perplexity is 65.10044606921657
At time: 209.02604413032532 and batch: 1150, loss is 4.140098299980163 and perplexity is 62.808995268742535
At time: 209.92345261573792 and batch: 1200, loss is 4.222677788734436 and perplexity is 68.21590772391681
At time: 210.8197569847107 and batch: 1250, loss is 4.21012327671051 and perplexity is 67.36484381461037
At time: 211.71586084365845 and batch: 1300, loss is 4.211352486610412 and perplexity is 67.44770026108208
At time: 212.61309957504272 and batch: 1350, loss is 4.090809316635132 and perplexity is 59.78825976217925
At time: 213.5108494758606 and batch: 1400, loss is 4.1242483043670655 and perplexity is 61.821320963045444
At time: 214.40741848945618 and batch: 1450, loss is 4.0506216907501225 and perplexity is 57.4331516079119
At time: 215.30384063720703 and batch: 1500, loss is 4.064125852584839 and perplexity is 58.213998657977484
At time: 216.20116353034973 and batch: 1550, loss is 4.0693790102005005 and perplexity is 58.520610603708256
At time: 217.0980887413025 and batch: 1600, loss is 4.158626894950867 and perplexity is 63.98360604189718
At time: 217.9940333366394 and batch: 1650, loss is 4.11151195526123 and perplexity is 61.03893597739205
At time: 218.89036583900452 and batch: 1700, loss is 4.135368461608887 and perplexity is 62.512620328168154
At time: 219.78693962097168 and batch: 1750, loss is 4.132450857162476 and perplexity is 62.330499037276915
At time: 220.68410730361938 and batch: 1800, loss is 4.099720816612244 and perplexity is 60.32344394279605
At time: 221.57823991775513 and batch: 1850, loss is 4.13136821269989 and perplexity is 62.26305378384689
At time: 222.4751217365265 and batch: 1900, loss is 4.216018652915954 and perplexity is 67.76315786387096
At time: 223.36952948570251 and batch: 1950, loss is 4.150959267616272 and perplexity is 63.494879675519094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383798998455669 and perplexity of 80.14191482774395
finished 6 epochs...
Completing Train Step...
At time: 226.31797814369202 and batch: 50, loss is 4.134225182533264 and perplexity is 62.44119179653768
At time: 227.2331554889679 and batch: 100, loss is 4.107207646369934 and perplexity is 60.77677016862383
At time: 228.1305594444275 and batch: 150, loss is 4.067938189506531 and perplexity is 58.43635361111219
At time: 229.02722644805908 and batch: 200, loss is 4.065924038887024 and perplexity is 58.318772446123084
At time: 229.92387771606445 and batch: 250, loss is 4.060654649734497 and perplexity is 58.01227637194337
At time: 230.82006168365479 and batch: 300, loss is 4.0905243682861325 and perplexity is 59.77122562331063
At time: 231.71681261062622 and batch: 350, loss is 4.096902904510498 and perplexity is 60.15369705831536
At time: 232.6131308078766 and batch: 400, loss is 4.054887943267822 and perplexity is 57.678699347457005
At time: 233.51131081581116 and batch: 450, loss is 4.08504207611084 and perplexity is 59.44443888942395
At time: 234.40779948234558 and batch: 500, loss is 4.097027459144592 and perplexity is 60.1611899466692
At time: 235.30585980415344 and batch: 550, loss is 4.063813467025756 and perplexity is 58.19581628556343
At time: 236.20355987548828 and batch: 600, loss is 4.054728302955628 and perplexity is 57.669492236818776
At time: 237.1034243106842 and batch: 650, loss is 4.117805805206299 and perplexity is 61.42431737542508
At time: 238.00170063972473 and batch: 700, loss is 4.136263518333435 and perplexity is 62.568597717094136
At time: 238.89987349510193 and batch: 750, loss is 4.107123465538025 and perplexity is 60.77165414488884
At time: 239.79801654815674 and batch: 800, loss is 4.08278872013092 and perplexity is 59.310640212219006
At time: 240.69611358642578 and batch: 850, loss is 4.081812272071838 and perplexity is 59.25275471838917
At time: 241.59424471855164 and batch: 900, loss is 4.0536853170394895 and perplexity is 57.60937512472527
At time: 242.4925332069397 and batch: 950, loss is 4.149128832817078 and perplexity is 63.37876274284829
At time: 243.3905963897705 and batch: 1000, loss is 4.123192648887635 and perplexity is 61.75609338180944
At time: 244.2861397266388 and batch: 1050, loss is 4.067456293106079 and perplexity is 58.40820012672766
At time: 245.18525671958923 and batch: 1100, loss is 4.09721227645874 and perplexity is 60.17230980375049
At time: 246.1264169216156 and batch: 1150, loss is 4.0610850811004635 and perplexity is 58.037252050077
At time: 247.02459740638733 and batch: 1200, loss is 4.141274847984314 and perplexity is 62.88293655597611
At time: 247.92225861549377 and batch: 1250, loss is 4.134033088684082 and perplexity is 62.42919837962566
At time: 248.82019543647766 and batch: 1300, loss is 4.126202931404114 and perplexity is 61.94227676169305
At time: 249.7168161869049 and batch: 1350, loss is 4.015882539749145 and perplexity is 55.472230254014804
At time: 250.61470556259155 and batch: 1400, loss is 4.047251906394958 and perplexity is 57.239939995723425
At time: 251.51118755340576 and batch: 1450, loss is 3.972164101600647 and perplexity is 53.09931890939929
At time: 252.40767908096313 and batch: 1500, loss is 3.986035213470459 and perplexity is 53.84099756397531
At time: 253.30413675308228 and batch: 1550, loss is 3.992603135108948 and perplexity is 54.19578484906873
At time: 254.20104837417603 and batch: 1600, loss is 4.082780151367188 and perplexity is 59.31013199553361
At time: 255.09936594963074 and batch: 1650, loss is 4.039603605270385 and perplexity is 56.803821606614825
At time: 256.0110385417938 and batch: 1700, loss is 4.059757976531983 and perplexity is 57.960281632932116
At time: 256.921226978302 and batch: 1750, loss is 4.060694541931152 and perplexity is 58.014590655241435
At time: 257.8180170059204 and batch: 1800, loss is 4.026572427749634 and perplexity is 56.068403015363
At time: 258.71527791023254 and batch: 1850, loss is 4.05767258644104 and perplexity is 57.8395377787232
At time: 259.6122007369995 and batch: 1900, loss is 4.137182378768921 and perplexity is 62.62611594760647
At time: 260.5085859298706 and batch: 1950, loss is 4.073319525718689 and perplexity is 58.75166691944458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380451433048692 and perplexity of 79.8740830682986
finished 7 epochs...
Completing Train Step...
At time: 263.4589457511902 and batch: 50, loss is 4.0604332113265995 and perplexity is 57.999431648035156
At time: 264.3557949066162 and batch: 100, loss is 4.03902265548706 and perplexity is 56.7708310226246
At time: 265.2508134841919 and batch: 150, loss is 3.992073860168457 and perplexity is 54.1671079679146
At time: 266.1458411216736 and batch: 200, loss is 3.99392792224884 and perplexity is 54.26763030733497
At time: 267.04363894462585 and batch: 250, loss is 3.9874063682556153 and perplexity is 53.91487254086263
At time: 267.9398543834686 and batch: 300, loss is 4.017016906738281 and perplexity is 55.53519182484092
At time: 268.8595995903015 and batch: 350, loss is 4.019320740699768 and perplexity is 55.66328317977617
At time: 269.7553207874298 and batch: 400, loss is 3.983659615516663 and perplexity is 53.71324480500907
At time: 270.6503674983978 and batch: 450, loss is 4.012045650482178 and perplexity is 55.25979725070845
At time: 271.54642367362976 and batch: 500, loss is 4.032687559127807 and perplexity is 56.41231914038699
At time: 272.4431645870209 and batch: 550, loss is 3.997388982772827 and perplexity is 54.45577926997689
At time: 273.339962720871 and batch: 600, loss is 3.9925486993789674 and perplexity is 54.19283474225494
At time: 274.23323011398315 and batch: 650, loss is 4.055159673690796 and perplexity is 57.69437453444344
At time: 275.1270275115967 and batch: 700, loss is 4.068366374969482 and perplexity is 58.46138056594308
At time: 276.02122831344604 and batch: 750, loss is 4.04371928691864 and perplexity is 57.038089808736245
At time: 276.9150264263153 and batch: 800, loss is 4.0159128332138065 and perplexity is 55.4739107255152
At time: 277.8097200393677 and batch: 850, loss is 4.017714695930481 and perplexity is 55.57395720494176
At time: 278.7034032344818 and batch: 900, loss is 3.988846468925476 and perplexity is 53.99257131852683
At time: 279.5977153778076 and batch: 950, loss is 4.086356558799744 and perplexity is 59.52262895378023
At time: 280.49265480041504 and batch: 1000, loss is 4.065386848449707 and perplexity is 58.28745257237047
At time: 281.3862898349762 and batch: 1050, loss is 4.008530306816101 and perplexity is 55.06588111308301
At time: 282.28376626968384 and batch: 1100, loss is 4.032386884689331 and perplexity is 56.39535994773196
At time: 283.178120136261 and batch: 1150, loss is 3.9957187604904174 and perplexity is 54.364901927841366
At time: 284.073748588562 and batch: 1200, loss is 4.073604025840759 and perplexity is 58.76838415376986
At time: 284.96835064888 and batch: 1250, loss is 4.068013606071472 and perplexity is 58.440760846356376
At time: 285.8614938259125 and batch: 1300, loss is 4.060257434844971 and perplexity is 57.98923760796609
At time: 286.756139755249 and batch: 1350, loss is 3.9560025405883787 and perplexity is 52.24804848554071
At time: 287.6501874923706 and batch: 1400, loss is 3.98503387928009 and perplexity is 53.78711171564457
At time: 288.5447120666504 and batch: 1450, loss is 3.910487885475159 and perplexity is 49.923302887046844
At time: 289.4384717941284 and batch: 1500, loss is 3.922823357582092 and perplexity is 50.542944324899004
At time: 290.33444356918335 and batch: 1550, loss is 3.929334464073181 and perplexity is 50.87310851845529
At time: 291.2272799015045 and batch: 1600, loss is 4.023904809951782 and perplexity is 55.919033264863096
At time: 292.12051820755005 and batch: 1650, loss is 3.973901777267456 and perplexity is 53.191668517388
At time: 293.01455521583557 and batch: 1700, loss is 4.0005995607376095 and perplexity is 54.63089475549426
At time: 293.90773248672485 and batch: 1750, loss is 4.005232810974121 and perplexity is 54.88460064912814
At time: 294.8026843070984 and batch: 1800, loss is 3.967849373817444 and perplexity is 52.87070336442901
At time: 295.69579815864563 and batch: 1850, loss is 3.9983001375198364 and perplexity is 54.50541952330276
At time: 296.5896589756012 and batch: 1900, loss is 4.070066442489624 and perplexity is 58.56085339152758
At time: 297.4847993850708 and batch: 1950, loss is 4.011091442108154 and perplexity is 55.20709303882412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3816778138626455 and perplexity of 79.97209920157358
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 300.419953584671 and batch: 50, loss is 4.029815640449524 and perplexity is 56.250539966872594
At time: 301.3389654159546 and batch: 100, loss is 4.027235598564148 and perplexity is 56.10559827590162
At time: 302.2335228919983 and batch: 150, loss is 3.991153793334961 and perplexity is 54.11729352822791
At time: 303.1288170814514 and batch: 200, loss is 3.981525435447693 and perplexity is 53.59873330604992
At time: 304.0235960483551 and batch: 250, loss is 3.9690520048141478 and perplexity is 52.93432556045695
At time: 304.9179618358612 and batch: 300, loss is 3.987727861404419 and perplexity is 53.93220858956426
At time: 305.81227350234985 and batch: 350, loss is 3.9981461238861082 and perplexity is 54.49702559199062
At time: 306.70810627937317 and batch: 400, loss is 3.952730097770691 and perplexity is 52.077349188713136
At time: 307.6042275428772 and batch: 450, loss is 3.975488419532776 and perplexity is 53.276131655493785
At time: 308.49991178512573 and batch: 500, loss is 3.9881384229660033 and perplexity is 53.95435562739261
At time: 309.3955581188202 and batch: 550, loss is 3.945661163330078 and perplexity is 51.71051590920752
At time: 310.29087805747986 and batch: 600, loss is 3.9262764167785646 and perplexity is 50.717773778125945
At time: 311.1865463256836 and batch: 650, loss is 3.9809635877609253 and perplexity is 53.568627439975806
At time: 312.084260225296 and batch: 700, loss is 3.996785755157471 and perplexity is 54.42293994589488
At time: 312.98123574256897 and batch: 750, loss is 3.953352289199829 and perplexity is 52.10976135126984
At time: 313.9191663265228 and batch: 800, loss is 3.927117791175842 and perplexity is 50.760464371337406
At time: 314.8163387775421 and batch: 850, loss is 3.9330994510650634 and perplexity is 51.0650061295877
At time: 315.7134909629822 and batch: 900, loss is 3.8948538875579835 and perplexity is 49.14887157637412
At time: 316.60883617401123 and batch: 950, loss is 3.993399257659912 and perplexity is 54.23894851505842
At time: 317.5038170814514 and batch: 1000, loss is 3.967830443382263 and perplexity is 52.869702508479364
At time: 318.399126291275 and batch: 1050, loss is 3.9000490617752077 and perplexity is 49.404872936841144
At time: 319.29522466659546 and batch: 1100, loss is 3.9174122428894043 and perplexity is 50.27018927620228
At time: 320.1904208660126 and batch: 1150, loss is 3.8793295001983643 and perplexity is 48.391757527349874
At time: 321.0865321159363 and batch: 1200, loss is 3.9403077077865603 and perplexity is 51.434425639032355
At time: 321.98316073417664 and batch: 1250, loss is 3.9263264513015748 and perplexity is 50.720311481230915
At time: 322.880407333374 and batch: 1300, loss is 3.923979697227478 and perplexity is 50.60142293927044
At time: 323.7780201435089 and batch: 1350, loss is 3.8098437118530275 and perplexity is 45.143382939286546
At time: 324.67492747306824 and batch: 1400, loss is 3.829327578544617 and perplexity is 46.03157520648513
At time: 325.59583020210266 and batch: 1450, loss is 3.745515909194946 and perplexity is 42.330840456190735
At time: 326.4929177761078 and batch: 1500, loss is 3.756787428855896 and perplexity is 42.81067249468794
At time: 327.4238362312317 and batch: 1550, loss is 3.7622495222091676 and perplexity is 43.0451481654172
At time: 328.327623128891 and batch: 1600, loss is 3.8445179319381713 and perplexity is 46.736148914816894
At time: 329.2482488155365 and batch: 1650, loss is 3.7965766191482544 and perplexity is 44.548416954187225
At time: 330.14672112464905 and batch: 1700, loss is 3.802345414161682 and perplexity is 44.80615033051813
At time: 331.04352736473083 and batch: 1750, loss is 3.7972008895874025 and perplexity is 44.57623589637075
At time: 331.940753698349 and batch: 1800, loss is 3.7568383502960203 and perplexity is 42.812852531288904
At time: 332.8395733833313 and batch: 1850, loss is 3.7795315265655516 and perplexity is 43.795519891362915
At time: 333.73635959625244 and batch: 1900, loss is 3.8526926851272583 and perplexity is 47.119771269893796
At time: 334.63391947746277 and batch: 1950, loss is 3.7801817655563354 and perplexity is 43.82400670663322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30857671693314 and perplexity of 74.33461441552987
finished 9 epochs...
Completing Train Step...
At time: 337.57716488838196 and batch: 50, loss is 3.9435957956314085 and perplexity is 51.603824895979706
At time: 338.4974133968353 and batch: 100, loss is 3.9306916999816894 and perplexity is 50.942202205724286
At time: 339.3919713497162 and batch: 150, loss is 3.8925982761383056 and perplexity is 49.03813575582284
At time: 340.2882776260376 and batch: 200, loss is 3.884378881454468 and perplexity is 48.63672390459842
At time: 341.18818068504333 and batch: 250, loss is 3.873547854423523 and perplexity is 48.112780776403916
At time: 342.0844178199768 and batch: 300, loss is 3.892695527076721 and perplexity is 49.04290499244586
At time: 342.9796404838562 and batch: 350, loss is 3.90627215385437 and perplexity is 49.7132826459841
At time: 343.874906539917 and batch: 400, loss is 3.8620602321624755 and perplexity is 47.56324181624577
At time: 344.77099680900574 and batch: 450, loss is 3.8943114614486696 and perplexity is 49.122219174320634
At time: 345.6676564216614 and batch: 500, loss is 3.908011360168457 and perplexity is 49.799819531991915
At time: 346.5639522075653 and batch: 550, loss is 3.870051612854004 and perplexity is 47.94486058805029
At time: 347.45844888687134 and batch: 600, loss is 3.854568347930908 and perplexity is 47.20823501031948
At time: 348.3620467185974 and batch: 650, loss is 3.9089396619796752 and perplexity is 49.846070258657114
At time: 349.2733964920044 and batch: 700, loss is 3.927611241340637 and perplexity is 50.78551831177365
At time: 350.16829895973206 and batch: 750, loss is 3.886861939430237 and perplexity is 48.75764177071357
At time: 351.06394815444946 and batch: 800, loss is 3.861634888648987 and perplexity is 47.543015401750786
At time: 351.95917892456055 and batch: 850, loss is 3.869481234550476 and perplexity is 47.91752167730713
At time: 352.852872133255 and batch: 900, loss is 3.8304129600524903 and perplexity is 46.081564150622846
At time: 353.74689841270447 and batch: 950, loss is 3.933734474182129 and perplexity is 51.097443887226014
At time: 354.64199447631836 and batch: 1000, loss is 3.909418153762817 and perplexity is 49.86992690084625
At time: 355.5371308326721 and batch: 1050, loss is 3.8482769966125487 and perplexity is 46.91216373950813
At time: 356.4321491718292 and batch: 1100, loss is 3.8643386697769166 and perplexity is 47.67173524628567
At time: 357.3257887363434 and batch: 1150, loss is 3.8293016529083252 and perplexity is 46.03038182407806
At time: 358.22121810913086 and batch: 1200, loss is 3.8922678232192993 and perplexity is 49.02193363788573
At time: 359.1523323059082 and batch: 1250, loss is 3.8822016811370847 and perplexity is 48.53094720419326
At time: 360.04790139198303 and batch: 1300, loss is 3.8811535024642945 and perplexity is 48.480104751006024
At time: 360.94159626960754 and batch: 1350, loss is 3.7692945861816405 and perplexity is 43.349474729285504
At time: 361.8364312648773 and batch: 1400, loss is 3.7928876781463625 and perplexity is 44.38438321372911
At time: 362.7318365573883 and batch: 1450, loss is 3.712460746765137 and perplexity is 40.95446119127389
At time: 363.6264851093292 and batch: 1500, loss is 3.723990035057068 and perplexity is 41.42936939743342
At time: 364.52071928977966 and batch: 1550, loss is 3.732706904411316 and perplexity is 41.792082361972334
At time: 365.4159951210022 and batch: 1600, loss is 3.818997173309326 and perplexity is 45.558498127069456
At time: 366.31035113334656 and batch: 1650, loss is 3.7732591247558593 and perplexity is 43.52167651879105
At time: 367.20523047447205 and batch: 1700, loss is 3.7831975555419923 and perplexity is 43.956370197114616
At time: 368.10025787353516 and batch: 1750, loss is 3.782121334075928 and perplexity is 43.90908885509946
At time: 368.9942309856415 and batch: 1800, loss is 3.7445590114593506 and perplexity is 42.290353544818586
At time: 369.8897178173065 and batch: 1850, loss is 3.7711822032928466 and perplexity is 43.43137921738344
At time: 370.7832500934601 and batch: 1900, loss is 3.8482235717773436 and perplexity is 46.9096575318387
At time: 371.67735600471497 and batch: 1950, loss is 3.7759031867980957 and perplexity is 43.636902797273954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307952455032703 and perplexity of 74.28822462906126
finished 10 epochs...
Completing Train Step...
At time: 374.61055636405945 and batch: 50, loss is 3.9012526273727417 and perplexity is 49.46437073983064
At time: 375.52949237823486 and batch: 100, loss is 3.8870808458328248 and perplexity is 48.76831629899093
At time: 376.42156434059143 and batch: 150, loss is 3.849487156867981 and perplexity is 46.96896934056978
At time: 377.3144459724426 and batch: 200, loss is 3.842466325759888 and perplexity is 46.64036303400412
At time: 378.2069716453552 and batch: 250, loss is 3.8307713365554807 and perplexity is 46.09808166000232
At time: 379.0988507270813 and batch: 300, loss is 3.8514406204223635 and perplexity is 47.06081118600654
At time: 379.9911684989929 and batch: 350, loss is 3.8648866415023804 and perplexity is 47.6978651678797
At time: 380.90612602233887 and batch: 400, loss is 3.820029492378235 and perplexity is 45.605553317243114
At time: 381.79878091812134 and batch: 450, loss is 3.8547295570373534 and perplexity is 47.215846021168
At time: 382.7010726928711 and batch: 500, loss is 3.8697417974472046 and perplexity is 47.93000883233342
At time: 383.5961923599243 and batch: 550, loss is 3.833232626914978 and perplexity is 46.21168216855281
At time: 384.48701643943787 and batch: 600, loss is 3.8186351013183595 and perplexity is 45.54200565685809
At time: 385.3790512084961 and batch: 650, loss is 3.8731095218658447 and perplexity is 48.09169599955886
At time: 386.27176547050476 and batch: 700, loss is 3.8918220138549806 and perplexity is 49.000084071545466
At time: 387.1876165866852 and batch: 750, loss is 3.8526025724411013 and perplexity is 47.11552537204106
At time: 388.0870485305786 and batch: 800, loss is 3.8264869260787964 and perplexity is 45.90100104458028
At time: 388.9806008338928 and batch: 850, loss is 3.8361343812942503 and perplexity is 46.345971863285264
At time: 389.87341713905334 and batch: 900, loss is 3.7966629314422606 and perplexity is 44.55226219619233
At time: 390.76614236831665 and batch: 950, loss is 3.901612696647644 and perplexity is 49.48218454684626
At time: 391.65921354293823 and batch: 1000, loss is 3.877926940917969 and perplexity is 48.323932793958456
At time: 392.55394220352173 and batch: 1050, loss is 3.8194051218032836 and perplexity is 45.57708743925052
At time: 393.4482216835022 and batch: 1100, loss is 3.8351463794708254 and perplexity is 46.30020457138283
At time: 394.3421730995178 and batch: 1150, loss is 3.801492223739624 and perplexity is 44.76793845552768
At time: 395.2364158630371 and batch: 1200, loss is 3.864557662010193 and perplexity is 47.68217612924582
At time: 396.12955498695374 and batch: 1250, loss is 3.856204857826233 and perplexity is 47.28555500426599
At time: 397.0219941139221 and batch: 1300, loss is 3.8549377155303954 and perplexity is 47.22567542352477
At time: 397.91420578956604 and batch: 1350, loss is 3.7440854120254516 and perplexity is 42.27032959935927
At time: 398.807430267334 and batch: 1400, loss is 3.769575834274292 and perplexity is 43.361668401013645
At time: 399.70029187202454 and batch: 1450, loss is 3.690419092178345 and perplexity is 40.06163295662436
At time: 400.59353518486023 and batch: 1500, loss is 3.7018443965911865 and perplexity is 40.52197406946291
At time: 401.5053460597992 and batch: 1550, loss is 3.711533589363098 and perplexity is 40.916507556649336
At time: 402.4197323322296 and batch: 1600, loss is 3.7992374515533447 and perplexity is 44.66711066762433
At time: 403.3384883403778 and batch: 1650, loss is 3.75488094329834 and perplexity is 42.72913231814978
At time: 404.23233938217163 and batch: 1700, loss is 3.7665079641342163 and perplexity is 43.22884428105452
At time: 405.1256151199341 and batch: 1750, loss is 3.7671134233474732 and perplexity is 43.25502550813571
At time: 406.01998686790466 and batch: 1800, loss is 3.7298067951202394 and perplexity is 41.67105633479933
At time: 406.9134876728058 and batch: 1850, loss is 3.7579034185409546 and perplexity is 42.858475432433885
At time: 407.80824851989746 and batch: 1900, loss is 3.837173414230347 and perplexity is 46.39415188048443
At time: 408.7023844718933 and batch: 1950, loss is 3.764379258155823 and perplexity is 43.13692065569164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310591160973837 and perplexity of 74.48450826225101
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 411.66197872161865 and batch: 50, loss is 3.895094428062439 and perplexity is 49.16069529272086
At time: 412.5553786754608 and batch: 100, loss is 3.908945026397705 and perplexity is 49.846337654532334
At time: 413.4517402648926 and batch: 150, loss is 3.8804409456253053 and perplexity is 48.445572225465526
At time: 414.3472578525543 and batch: 200, loss is 3.872021322250366 and perplexity is 48.03939109871245
At time: 415.24366450309753 and batch: 250, loss is 3.860544538497925 and perplexity is 47.49120511853356
At time: 416.1391673088074 and batch: 300, loss is 3.8757223749160765 and perplexity is 48.21751683824162
At time: 417.0335428714752 and batch: 350, loss is 3.8879613494873047 and perplexity is 48.811275889977956
At time: 417.9280834197998 and batch: 400, loss is 3.8451521825790405 and perplexity is 46.76580074957146
At time: 418.82331371307373 and batch: 450, loss is 3.8845186471939086 and perplexity is 48.64352212734716
At time: 419.71880865097046 and batch: 500, loss is 3.8948391485214233 and perplexity is 49.14814717469757
At time: 420.61432242393494 and batch: 550, loss is 3.8617333793640136 and perplexity is 47.547698177933434
At time: 421.5097677707672 and batch: 600, loss is 3.834871082305908 and perplexity is 46.28746001068044
At time: 422.4043707847595 and batch: 650, loss is 3.8769156742095947 and perplexity is 48.27508911066417
At time: 423.2994213104248 and batch: 700, loss is 3.8965330076217652 and perplexity is 49.23146775779667
At time: 424.19590282440186 and batch: 750, loss is 3.8575624418258667 and perplexity is 47.349792711329194
At time: 425.0914297103882 and batch: 800, loss is 3.8257133102416994 and perplexity is 45.865505035141425
At time: 426.0090491771698 and batch: 850, loss is 3.8325823450088503 and perplexity is 46.1816413163568
At time: 426.9028594493866 and batch: 900, loss is 3.799766583442688 and perplexity is 44.69075171434766
At time: 427.7969648838043 and batch: 950, loss is 3.898339829444885 and perplexity is 49.32050065719706
At time: 428.69207787513733 and batch: 1000, loss is 3.8706785583496095 and perplexity is 47.974928827022
At time: 429.58706736564636 and batch: 1050, loss is 3.8109982633590698 and perplexity is 45.195533399450106
At time: 430.4828555583954 and batch: 1100, loss is 3.8256054973602294 and perplexity is 45.86056040943547
At time: 431.37834453582764 and batch: 1150, loss is 3.7969313049316407 and perplexity is 44.56422044682465
At time: 432.27529072761536 and batch: 1200, loss is 3.8478972482681275 and perplexity is 46.89435230514024
At time: 433.17094349861145 and batch: 1250, loss is 3.8336895179748534 and perplexity is 46.232800697063496
At time: 434.06681871414185 and batch: 1300, loss is 3.835563073158264 and perplexity is 46.31950159454949
At time: 434.9632246494293 and batch: 1350, loss is 3.7227481412887573 and perplexity is 41.3779504567933
At time: 435.8586232662201 and batch: 1400, loss is 3.7418057250976564 and perplexity is 42.17407623698949
At time: 436.75265526771545 and batch: 1450, loss is 3.658471817970276 and perplexity is 38.80200101962986
At time: 437.6470170021057 and batch: 1500, loss is 3.6669789695739747 and perplexity is 39.133503596892254
At time: 438.5589587688446 and batch: 1550, loss is 3.6695121002197264 and perplexity is 39.232759535183654
At time: 439.4548101425171 and batch: 1600, loss is 3.757649450302124 and perplexity is 42.84759212297531
At time: 440.35019040107727 and batch: 1650, loss is 3.7098265886306763 and perplexity is 40.846722626690514
At time: 441.24406909942627 and batch: 1700, loss is 3.7180248928070068 and perplexity is 41.182972941228044
At time: 442.13796186447144 and batch: 1750, loss is 3.7119410324096678 and perplexity is 40.93318209987588
At time: 443.0328722000122 and batch: 1800, loss is 3.6792737293243407 and perplexity is 39.61761051275497
At time: 443.9282031059265 and batch: 1850, loss is 3.7033293199539186 and perplexity is 40.582190793007676
At time: 444.82361459732056 and batch: 1900, loss is 3.7880520629882812 and perplexity is 44.17027550592702
At time: 445.7189111709595 and batch: 1950, loss is 3.7144981527328493 and perplexity is 41.037987114123105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.285347588117733 and perplexity of 72.62778688864861
finished 12 epochs...
Completing Train Step...
At time: 448.6759533882141 and batch: 50, loss is 3.8882769393920897 and perplexity is 48.826682666872266
At time: 449.5768811702728 and batch: 100, loss is 3.880556378364563 and perplexity is 48.45116475334662
At time: 450.4937033653259 and batch: 150, loss is 3.8460123777389525 and perplexity is 46.806045771830775
At time: 451.4051208496094 and batch: 200, loss is 3.83412654876709 and perplexity is 46.2530102703607
At time: 452.29879808425903 and batch: 250, loss is 3.8225969552993773 and perplexity is 45.72279432595159
At time: 453.19261479377747 and batch: 300, loss is 3.8370730829238893 and perplexity is 46.38949732811683
At time: 454.0867750644684 and batch: 350, loss is 3.8503877210617063 and perplexity is 47.011286964582524
At time: 454.97998428344727 and batch: 400, loss is 3.809313726425171 and perplexity is 45.11946394308418
At time: 455.87394857406616 and batch: 450, loss is 3.850410680770874 and perplexity is 47.01236634244988
At time: 456.76969504356384 and batch: 500, loss is 3.862867150306702 and perplexity is 47.60163694784638
At time: 457.6635365486145 and batch: 550, loss is 3.830906004905701 and perplexity is 46.10429003063392
At time: 458.5552740097046 and batch: 600, loss is 3.805324535369873 and perplexity is 44.93983231176714
At time: 459.44772386550903 and batch: 650, loss is 3.8486309671401977 and perplexity is 46.92877220213989
At time: 460.3416557312012 and batch: 700, loss is 3.8699668979644777 and perplexity is 47.9407991165182
At time: 461.23461723327637 and batch: 750, loss is 3.8324046182632445 and perplexity is 46.17343433286075
At time: 462.134703874588 and batch: 800, loss is 3.800913414955139 and perplexity is 44.742033877108334
At time: 463.0302722454071 and batch: 850, loss is 3.8096434020996095 and perplexity is 45.13434118498755
At time: 463.9252049922943 and batch: 900, loss is 3.7762439680099487 and perplexity is 43.651775967995356
At time: 464.8191075325012 and batch: 950, loss is 3.875824112892151 and perplexity is 48.22242264036504
At time: 465.7131004333496 and batch: 1000, loss is 3.849589257240295 and perplexity is 46.97376513464867
At time: 466.608083486557 and batch: 1050, loss is 3.7923473787307738 and perplexity is 44.360408834672185
At time: 467.5032522678375 and batch: 1100, loss is 3.806857442855835 and perplexity is 45.008773744054636
At time: 468.39633893966675 and batch: 1150, loss is 3.779544959068298 and perplexity is 43.79610817875522
At time: 469.29065132141113 and batch: 1200, loss is 3.832599787712097 and perplexity is 46.1824468560471
At time: 470.1848726272583 and batch: 1250, loss is 3.8200352430343627 and perplexity is 45.60581557985185
At time: 471.07927894592285 and batch: 1300, loss is 3.822852120399475 and perplexity is 45.734462675957055
At time: 471.97274470329285 and batch: 1350, loss is 3.710724654197693 and perplexity is 40.88342213862444
At time: 472.8673827648163 and batch: 1400, loss is 3.7321449851989748 and perplexity is 41.768605184725615
At time: 473.7617371082306 and batch: 1450, loss is 3.650216760635376 and perplexity is 38.483006746025524
At time: 474.6567599773407 and batch: 1500, loss is 3.660183048248291 and perplexity is 38.868457023167956
At time: 475.5528085231781 and batch: 1550, loss is 3.663982644081116 and perplexity is 39.016422376758236
At time: 476.4459352493286 and batch: 1600, loss is 3.7553775453567506 and perplexity is 42.750356962878016
At time: 477.3383729457855 and batch: 1650, loss is 3.7081638193130493 and perplexity is 40.77886038484348
At time: 478.2414791584015 and batch: 1700, loss is 3.718506712913513 and perplexity is 41.20282050673093
At time: 479.135085105896 and batch: 1750, loss is 3.7139296674728395 and perplexity is 41.01466425332766
At time: 480.0398585796356 and batch: 1800, loss is 3.6831181716918944 and perplexity is 39.77021127758438
At time: 480.94587898254395 and batch: 1850, loss is 3.708082127571106 and perplexity is 40.77552922477017
At time: 481.84022784233093 and batch: 1900, loss is 3.7936382246017457 and perplexity is 44.4177082596577
At time: 482.7335283756256 and batch: 1950, loss is 3.719904680252075 and perplexity is 41.26046098442127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283994878724564 and perplexity of 72.52960901715443
finished 13 epochs...
Completing Train Step...
At time: 485.67287731170654 and batch: 50, loss is 3.8755528259277345 and perplexity is 48.20934230005326
At time: 486.56635189056396 and batch: 100, loss is 3.8656619882583616 and perplexity is 47.734861893697094
At time: 487.46004700660706 and batch: 150, loss is 3.830246772766113 and perplexity is 46.07390661683464
At time: 488.35352396965027 and batch: 200, loss is 3.8178624010086057 and perplexity is 45.50682892726539
At time: 489.24852681159973 and batch: 250, loss is 3.8060822534561156 and perplexity is 44.97389693956495
At time: 490.14277601242065 and batch: 300, loss is 3.8207657527923584 and perplexity is 45.639143244764405
At time: 491.03688049316406 and batch: 350, loss is 3.8343539333343504 and perplexity is 46.263528686902994
At time: 491.9304175376892 and batch: 400, loss is 3.793558692932129 and perplexity is 44.41417578563291
At time: 492.8620641231537 and batch: 450, loss is 3.835072546005249 and perplexity is 46.29678619301934
At time: 493.75604224205017 and batch: 500, loss is 3.8479140281677244 and perplexity is 46.895139194265525
At time: 494.6500930786133 and batch: 550, loss is 3.816426019668579 and perplexity is 45.441510689529736
At time: 495.54484486579895 and batch: 600, loss is 3.79117299079895 and perplexity is 44.30834308456431
At time: 496.43888330459595 and batch: 650, loss is 3.8350514459609983 and perplexity is 46.295809339087874
At time: 497.33326506614685 and batch: 700, loss is 3.8567705297470094 and perplexity is 47.31231068174451
At time: 498.2283866405487 and batch: 750, loss is 3.8197801446914674 and perplexity is 45.59418309564784
At time: 499.12079524993896 and batch: 800, loss is 3.7883877038955687 and perplexity is 44.185103345548534
At time: 500.0140016078949 and batch: 850, loss is 3.797794418334961 and perplexity is 44.602701026964176
At time: 500.9090585708618 and batch: 900, loss is 3.764179520606995 and perplexity is 43.128305453314226
At time: 501.8036901950836 and batch: 950, loss is 3.864124870300293 and perplexity is 47.66154414370529
At time: 502.6990931034088 and batch: 1000, loss is 3.8384747743606566 and perplexity is 46.45456668220211
At time: 503.5942232608795 and batch: 1050, loss is 3.7823110961914064 and perplexity is 43.91742192731504
At time: 504.4886088371277 and batch: 1100, loss is 3.796873621940613 and perplexity is 44.561649923434906
At time: 505.38204169273376 and batch: 1150, loss is 3.770043787956238 and perplexity is 43.381964401820994
At time: 506.27674293518066 and batch: 1200, loss is 3.8239530754089355 and perplexity is 45.78484198933511
At time: 507.1716990470886 and batch: 1250, loss is 3.8123044919967652 and perplexity is 45.254607673326994
At time: 508.06606101989746 and batch: 1300, loss is 3.8153276014328004 and perplexity is 45.39162430859804
At time: 508.9598298072815 and batch: 1350, loss is 3.7033559608459474 and perplexity is 40.58327195317236
At time: 509.8550674915314 and batch: 1400, loss is 3.7260086965560912 and perplexity is 41.51308573941439
At time: 510.75078678131104 and batch: 1450, loss is 3.6445629930496217 and perplexity is 38.26604666873736
At time: 511.6466166973114 and batch: 1500, loss is 3.6548648071289063 and perplexity is 38.66229389531314
At time: 512.5415761470795 and batch: 1550, loss is 3.6588529348373413 and perplexity is 38.81679193504897
At time: 513.4366533756256 and batch: 1600, loss is 3.7518440961837767 and perplexity is 42.59956731009749
At time: 514.3326938152313 and batch: 1650, loss is 3.7047266292572023 and perplexity is 40.63893630203138
At time: 515.2271740436554 and batch: 1700, loss is 3.7159987115859985 and perplexity is 41.0996132542642
At time: 516.1225168704987 and batch: 1750, loss is 3.71214759349823 and perplexity is 40.941638175846805
At time: 517.0175814628601 and batch: 1800, loss is 3.6820870876312255 and perplexity is 39.729225979921274
At time: 517.9129064083099 and batch: 1850, loss is 3.7075134897232056 and perplexity is 40.75234930669876
At time: 518.8078632354736 and batch: 1900, loss is 3.793246693611145 and perplexity is 44.40032075443827
At time: 519.7018105983734 and batch: 1950, loss is 3.7196404838562014 and perplexity is 41.24956155919492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284048249000727 and perplexity of 72.53348004571568
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 522.6465737819672 and batch: 50, loss is 3.8764426040649416 and perplexity is 48.25225700829424
At time: 523.5645520687103 and batch: 100, loss is 3.88530526638031 and perplexity is 48.68180110866342
At time: 524.4597833156586 and batch: 150, loss is 3.8603785133361814 and perplexity is 47.48332103801834
At time: 525.354238986969 and batch: 200, loss is 3.8523147964477538 and perplexity is 47.10196860567455
At time: 526.2487313747406 and batch: 250, loss is 3.8424494457244873 and perplexity is 46.63957574966972
At time: 527.1434283256531 and batch: 300, loss is 3.8518663024902344 and perplexity is 47.080848393865345
At time: 528.0384004116058 and batch: 350, loss is 3.860103521347046 and perplexity is 47.47026530030926
At time: 528.9307425022125 and batch: 400, loss is 3.8189684343338013 and perplexity is 45.5571888413207
At time: 529.8227198123932 and batch: 450, loss is 3.86874635219574 and perplexity is 47.88232087195335
At time: 530.7164454460144 and batch: 500, loss is 3.8816045331954956 and perplexity is 48.50197569996486
At time: 531.6097149848938 and batch: 550, loss is 3.8562253665924073 and perplexity is 47.28652478260143
At time: 532.5039992332458 and batch: 600, loss is 3.8287780475616455 and perplexity is 46.00628637884775
At time: 533.3983428478241 and batch: 650, loss is 3.8588553428649903 and perplexity is 47.411050899382225
At time: 534.2916541099548 and batch: 700, loss is 3.8765811061859132 and perplexity is 48.25894051106053
At time: 535.1866998672485 and batch: 750, loss is 3.833357877731323 and perplexity is 46.21747058196329
At time: 536.0805549621582 and batch: 800, loss is 3.8010615253448488 and perplexity is 44.74866112795251
At time: 536.9749436378479 and batch: 850, loss is 3.8090609550476073 and perplexity is 45.10806047532419
At time: 537.8954756259918 and batch: 900, loss is 3.7752419185638426 and perplexity is 43.608056638188415
At time: 538.7894697189331 and batch: 950, loss is 3.8774806594848634 and perplexity is 48.30237153153128
At time: 539.6824884414673 and batch: 1000, loss is 3.8490744495391844 and perplexity is 46.94958890219645
At time: 540.5771152973175 and batch: 1050, loss is 3.793206787109375 and perplexity is 44.39854892831343
At time: 541.470766544342 and batch: 1100, loss is 3.8083241748809815 and perplexity is 45.07483799134754
At time: 542.3651299476624 and batch: 1150, loss is 3.782806787490845 and perplexity is 43.93919680762168
At time: 543.2587199211121 and batch: 1200, loss is 3.8329705286026 and perplexity is 46.19957175177351
At time: 544.1526622772217 and batch: 1250, loss is 3.817416477203369 and perplexity is 45.4865408727453
At time: 545.0470495223999 and batch: 1300, loss is 3.821024761199951 and perplexity is 45.650965697571365
At time: 545.9403491020203 and batch: 1350, loss is 3.708703570365906 and perplexity is 40.80087675881651
At time: 546.8348622322083 and batch: 1400, loss is 3.729540638923645 and perplexity is 41.65996680077676
At time: 547.7306079864502 and batch: 1450, loss is 3.644174361228943 and perplexity is 38.251178154726276
At time: 548.6463820934296 and batch: 1500, loss is 3.6565924739837645 and perplexity is 38.729147192492874
At time: 549.542188167572 and batch: 1550, loss is 3.6577964448928832 and perplexity is 38.77580404015533
At time: 550.4390280246735 and batch: 1600, loss is 3.7474792766571046 and perplexity is 42.414033093122136
At time: 551.3351171016693 and batch: 1650, loss is 3.698614854812622 and perplexity is 40.39131775483049
At time: 552.2318689823151 and batch: 1700, loss is 3.7054912185668947 and perplexity is 40.67002028000952
At time: 553.1284348964691 and batch: 1750, loss is 3.6964839458465577 and perplexity is 40.305339172475676
At time: 554.0247647762299 and batch: 1800, loss is 3.662938508987427 and perplexity is 38.97570522172893
At time: 554.9212880134583 and batch: 1850, loss is 3.6863123321533204 and perplexity is 39.89744681116673
At time: 555.8170809745789 and batch: 1900, loss is 3.7797910451889036 and perplexity is 43.806887119333986
At time: 556.7326934337616 and batch: 1950, loss is 3.714609169960022 and perplexity is 41.042543290563614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2692774573037795 and perplexity of 71.46997684886188
finished 15 epochs...
Completing Train Step...
At time: 559.6823906898499 and batch: 50, loss is 3.8783554601669312 and perplexity is 48.34464496681166
At time: 560.6024131774902 and batch: 100, loss is 3.8759500074386595 and perplexity is 48.22849396256005
At time: 561.4986612796783 and batch: 150, loss is 3.8433457612991333 and perplexity is 46.681398268096395
At time: 562.3950614929199 and batch: 200, loss is 3.8344839668273925 and perplexity is 46.26954488628384
At time: 563.2916746139526 and batch: 250, loss is 3.8229724550247193 and perplexity is 45.739966446524356
At time: 564.1883795261383 and batch: 300, loss is 3.8306370830535887 and perplexity is 46.09189324652635
At time: 565.0853807926178 and batch: 350, loss is 3.8400159645080567 and perplexity is 46.52621720202965
At time: 565.9820959568024 and batch: 400, loss is 3.7995246839523316 and perplexity is 44.67994235172669
At time: 566.879148721695 and batch: 450, loss is 3.8497053813934325 and perplexity is 46.979220240073225
At time: 567.7762475013733 and batch: 500, loss is 3.8649591493606565 and perplexity is 47.701323763313525
At time: 568.6727495193481 and batch: 550, loss is 3.8412429094314575 and perplexity is 46.58333734249821
At time: 569.5682458877563 and batch: 600, loss is 3.8143191289901734 and perplexity is 45.34587118061875
At time: 570.4657900333405 and batch: 650, loss is 3.8457322120666504 and perplexity is 46.79293416134665
At time: 571.3641633987427 and batch: 700, loss is 3.863603129386902 and perplexity is 47.63668365206188
At time: 572.2601685523987 and batch: 750, loss is 3.822406415939331 and perplexity is 45.71408316391717
At time: 573.1564497947693 and batch: 800, loss is 3.7909995985031126 and perplexity is 44.30066102525632
At time: 574.0534565448761 and batch: 850, loss is 3.7993329763412476 and perplexity is 44.67137768769694
At time: 574.9519362449646 and batch: 900, loss is 3.7666323041915892 and perplexity is 43.23421969221513
At time: 575.8483369350433 and batch: 950, loss is 3.8689313077926637 and perplexity is 47.891177794235745
At time: 576.7440252304077 and batch: 1000, loss is 3.8411613082885743 and perplexity is 46.57953624402085
At time: 577.6417515277863 and batch: 1050, loss is 3.785724639892578 and perplexity is 44.067592126757184
At time: 578.5397164821625 and batch: 1100, loss is 3.8011112070083617 and perplexity is 44.75088437110407
At time: 579.4364922046661 and batch: 1150, loss is 3.7764973974227907 and perplexity is 43.66284001386654
At time: 580.3331370353699 and batch: 1200, loss is 3.826937208175659 and perplexity is 45.92167409758226
At time: 581.2298407554626 and batch: 1250, loss is 3.812198963165283 and perplexity is 45.2498322594364
At time: 582.1514122486115 and batch: 1300, loss is 3.8163724327087403 and perplexity is 45.4390756823643
At time: 583.0540759563446 and batch: 1350, loss is 3.703825440406799 and perplexity is 40.602329443067816
At time: 583.9519436359406 and batch: 1400, loss is 3.725613398551941 and perplexity is 41.496678942476166
At time: 584.8497531414032 and batch: 1450, loss is 3.6413804864883423 and perplexity is 38.14445830464721
At time: 585.7467529773712 and batch: 1500, loss is 3.6549697351455688 and perplexity is 38.66635086597242
At time: 586.6438643932343 and batch: 1550, loss is 3.657342553138733 and perplexity is 38.758208016088155
At time: 587.5394198894501 and batch: 1600, loss is 3.7486407279968263 and perplexity is 42.46332354737226
At time: 588.4346926212311 and batch: 1650, loss is 3.70047390460968 and perplexity is 40.466477066710965
At time: 589.330353975296 and batch: 1700, loss is 3.708109908103943 and perplexity is 40.77666200643331
At time: 590.2257509231567 and batch: 1750, loss is 3.7003945302963257 and perplexity is 40.46326519535165
At time: 591.1503396034241 and batch: 1800, loss is 3.6676115942001344 and perplexity is 39.15826824751355
At time: 592.0581319332123 and batch: 1850, loss is 3.691168804168701 and perplexity is 40.091678904701645
At time: 592.9796161651611 and batch: 1900, loss is 3.7849577283859253 and perplexity is 44.03380913922142
At time: 593.8771638870239 and batch: 1950, loss is 3.7191924095153808 and perplexity is 41.23108282932167
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267853209029797 and perplexity of 71.36825831111372
finished 16 epochs...
Completing Train Step...
At time: 596.8059606552124 and batch: 50, loss is 3.8750495386123656 and perplexity is 48.18508525423512
At time: 597.7311110496521 and batch: 100, loss is 3.8711031579971316 and perplexity is 47.99530329008066
At time: 598.6273746490479 and batch: 150, loss is 3.8372966337203978 and perplexity is 46.39986889643715
At time: 599.5460131168365 and batch: 200, loss is 3.828054723739624 and perplexity is 45.97302096822953
At time: 600.4424374103546 and batch: 250, loss is 3.8159801149368286 and perplexity is 45.42125262181517
At time: 601.3384065628052 and batch: 300, loss is 3.823340835571289 and perplexity is 45.756819264298535
At time: 602.2558841705322 and batch: 350, loss is 3.8329774379730224 and perplexity is 46.19989096283088
At time: 603.1544075012207 and batch: 400, loss is 3.7923737144470215 and perplexity is 44.36157711319555
At time: 604.0505630970001 and batch: 450, loss is 3.8426474428176878 and perplexity is 46.64881116435872
At time: 604.9453692436218 and batch: 500, loss is 3.858055772781372 and perplexity is 47.373157592646194
At time: 605.864470243454 and batch: 550, loss is 3.83468213558197 and perplexity is 46.27871497295114
At time: 606.7606139183044 and batch: 600, loss is 3.8081512689590453 and perplexity is 45.067044958678686
At time: 607.6557958126068 and batch: 650, loss is 3.839904160499573 and perplexity is 46.521015675228064
At time: 608.5502486228943 and batch: 700, loss is 3.857848629951477 and perplexity is 47.363345598998535
At time: 609.445553779602 and batch: 750, loss is 3.817260947227478 and perplexity is 45.479466902261485
At time: 610.3408226966858 and batch: 800, loss is 3.786087818145752 and perplexity is 44.08359942446261
At time: 611.2355239391327 and batch: 850, loss is 3.7945305490493775 and perplexity is 44.457360955549454
At time: 612.1482591629028 and batch: 900, loss is 3.7622249841690065 and perplexity is 43.04409193480175
At time: 613.0467901229858 and batch: 950, loss is 3.8645204639434816 and perplexity is 47.680402477465634
At time: 613.9421832561493 and batch: 1000, loss is 3.83697322845459 and perplexity is 46.38486536074524
At time: 614.8367674350739 and batch: 1050, loss is 3.7819517040252686 and perplexity is 43.90164118582468
At time: 615.7313542366028 and batch: 1100, loss is 3.797396755218506 and perplexity is 44.5849677040494
At time: 616.6259150505066 and batch: 1150, loss is 3.773202381134033 and perplexity is 43.519207011302484
At time: 617.5207376480103 and batch: 1200, loss is 3.8238957214355467 and perplexity is 45.78221612202873
At time: 618.4162337779999 and batch: 1250, loss is 3.8096313190460207 and perplexity is 45.13379582761911
At time: 619.3114416599274 and batch: 1300, loss is 3.813984603881836 and perplexity is 45.330704385127795
At time: 620.207160949707 and batch: 1350, loss is 3.701473331451416 and perplexity is 40.50694056686792
At time: 621.1020550727844 and batch: 1400, loss is 3.7237468957901 and perplexity is 41.419297515411806
At time: 621.9958333969116 and batch: 1450, loss is 3.639968032836914 and perplexity is 38.090619056904984
At time: 622.888739824295 and batch: 1500, loss is 3.653985981941223 and perplexity is 38.628331423348094
At time: 623.7825510501862 and batch: 1550, loss is 3.656780023574829 and perplexity is 38.73641150939965
At time: 624.6752994060516 and batch: 1600, loss is 3.7488061666488646 and perplexity is 42.470349203522524
At time: 625.5686495304108 and batch: 1650, loss is 3.700831413269043 and perplexity is 40.480946769044046
At time: 626.4619290828705 and batch: 1700, loss is 3.708683228492737 and perplexity is 40.80004680099778
At time: 627.3785490989685 and batch: 1750, loss is 3.7014004468917845 and perplexity is 40.50398834392972
At time: 628.2867331504822 and batch: 1800, loss is 3.6690286016464233 and perplexity is 39.213795136920844
At time: 629.1803109645844 and batch: 1850, loss is 3.692664179801941 and perplexity is 40.15167587225291
At time: 630.0756900310516 and batch: 1900, loss is 3.7864429807662963 and perplexity is 44.09925905184978
At time: 630.970920085907 and batch: 1950, loss is 3.7202945232391356 and perplexity is 41.27654922151838
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267363508357558 and perplexity of 71.33331778294061
finished 17 epochs...
Completing Train Step...
At time: 633.9240746498108 and batch: 50, loss is 3.8713603973388673 and perplexity is 48.00765115841608
At time: 634.8178908824921 and batch: 100, loss is 3.866759433746338 and perplexity is 47.78727705863396
At time: 635.7114300727844 and batch: 150, loss is 3.8324453735351565 and perplexity is 46.17531618207947
At time: 636.6036751270294 and batch: 200, loss is 3.8230294942855836 and perplexity is 45.742575494810815
At time: 637.4968481063843 and batch: 250, loss is 3.810695652961731 and perplexity is 45.18185883026791
At time: 638.389641046524 and batch: 300, loss is 3.8180938529968262 and perplexity is 45.51736279229319
At time: 639.3030962944031 and batch: 350, loss is 3.827956314086914 and perplexity is 45.96849700180665
At time: 640.2083866596222 and batch: 400, loss is 3.787331190109253 and perplexity is 44.138445826210386
At time: 641.1129262447357 and batch: 450, loss is 3.837702374458313 and perplexity is 46.41869903330085
At time: 642.0211465358734 and batch: 500, loss is 3.853216013908386 and perplexity is 47.144436855902086
At time: 642.9360888004303 and batch: 550, loss is 3.830037727355957 and perplexity is 46.06427608477277
At time: 643.836507320404 and batch: 600, loss is 3.8037386322021485 and perplexity is 44.86861857331933
At time: 644.740220785141 and batch: 650, loss is 3.8356918048858644 and perplexity is 46.32546476782791
At time: 645.6395449638367 and batch: 700, loss is 3.853685474395752 and perplexity is 47.16657450217357
At time: 646.5447392463684 and batch: 750, loss is 3.813465299606323 and perplexity is 45.30717006779328
At time: 647.4509000778198 and batch: 800, loss is 3.7824672985076906 and perplexity is 43.924282466147396
At time: 648.3440737724304 and batch: 850, loss is 3.7909493589401246 and perplexity is 44.29843543531313
At time: 649.2376523017883 and batch: 900, loss is 3.7588322353363037 and perplexity is 42.89830159698068
At time: 650.1525747776031 and batch: 950, loss is 3.8611675786972044 and perplexity is 47.52080326789562
At time: 651.0450587272644 and batch: 1000, loss is 3.8337612628936766 and perplexity is 46.236117784587144
At time: 651.9387404918671 and batch: 1050, loss is 3.779052848815918 and perplexity is 43.774560967142826
At time: 652.8329746723175 and batch: 1100, loss is 3.7945165729522703 and perplexity is 44.45673961949755
At time: 653.7266430854797 and batch: 1150, loss is 3.770608959197998 and perplexity is 43.406489570319124
At time: 654.621395111084 and batch: 1200, loss is 3.8214763975143433 and perplexity is 45.67158798800455
At time: 655.5166490077972 and batch: 1250, loss is 3.8075550270080565 and perplexity is 45.04018210504317
At time: 656.4113698005676 and batch: 1300, loss is 3.8119574880599973 and perplexity is 45.23890687058519
At time: 657.3046288490295 and batch: 1350, loss is 3.6995127248764037 and perplexity is 40.42760019590059
At time: 658.1979463100433 and batch: 1400, loss is 3.7221071529388428 and perplexity is 41.351436171189064
At time: 659.0904619693756 and batch: 1450, loss is 3.6385878276824952 and perplexity is 38.03808245213402
At time: 659.9828851222992 and batch: 1500, loss is 3.6528557538986206 and perplexity is 38.5846972628553
At time: 660.8755810260773 and batch: 1550, loss is 3.655846633911133 and perplexity is 38.70027221193521
At time: 661.7681219577789 and batch: 1600, loss is 3.7483703660964967 and perplexity is 42.451844634323976
At time: 662.6626443862915 and batch: 1650, loss is 3.7004775047302245 and perplexity is 40.46662275116865
At time: 663.5562329292297 and batch: 1700, loss is 3.708452558517456 and perplexity is 40.79063654058473
At time: 664.447839975357 and batch: 1750, loss is 3.7013962030410767 and perplexity is 40.50381645141486
At time: 665.3401243686676 and batch: 1800, loss is 3.6693360424041748 and perplexity is 39.225852909242406
At time: 666.2329120635986 and batch: 1850, loss is 3.693045244216919 and perplexity is 40.16697916271407
At time: 667.1260101795197 and batch: 1900, loss is 3.786816482543945 and perplexity is 44.115733279883855
At time: 668.0192432403564 and batch: 1950, loss is 3.7203986167907717 and perplexity is 41.28084606775924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267206520257994 and perplexity of 71.32212017991444
finished 18 epochs...
Completing Train Step...
At time: 670.9569435119629 and batch: 50, loss is 3.8678131771087645 and perplexity is 47.837659124864956
At time: 671.8529462814331 and batch: 100, loss is 3.8628409004211424 and perplexity is 47.600387426724026
At time: 672.7713031768799 and batch: 150, loss is 3.8282120752334596 and perplexity is 45.980255460919196
At time: 673.6664199829102 and batch: 200, loss is 3.8187978792190553 and perplexity is 45.549419492320304
At time: 674.5603845119476 and batch: 250, loss is 3.806273112297058 and perplexity is 44.98248142459387
At time: 675.4550046920776 and batch: 300, loss is 3.8137748861312866 and perplexity is 45.32119872856062
At time: 676.3501982688904 and batch: 350, loss is 3.823788809776306 and perplexity is 45.7773217309778
At time: 677.2454402446747 and batch: 400, loss is 3.7831780195236204 and perplexity is 43.95551147304693
At time: 678.1397249698639 and batch: 450, loss is 3.8336540412902833 and perplexity is 46.23116053967022
At time: 679.0357794761658 and batch: 500, loss is 3.8492664432525636 and perplexity is 46.95860379348495
At time: 679.9317235946655 and batch: 550, loss is 3.8262187480926513 and perplexity is 45.88869305699753
At time: 680.8271191120148 and batch: 600, loss is 3.8000814056396486 and perplexity is 44.704823569936224
At time: 681.7218079566956 and batch: 650, loss is 3.8322027063369752 and perplexity is 46.16411230693791
At time: 682.6159288883209 and batch: 700, loss is 3.8502135610580446 and perplexity is 47.003100191597525
At time: 683.5118825435638 and batch: 750, loss is 3.810252084732056 and perplexity is 45.16182203730406
At time: 684.4078845977783 and batch: 800, loss is 3.7794007682800292 and perplexity is 43.78979363865401
At time: 685.3032667636871 and batch: 850, loss is 3.7878766536712645 and perplexity is 44.16252830755334
At time: 686.198529958725 and batch: 900, loss is 3.7558742237091063 and perplexity is 42.771595413639716
At time: 687.0946581363678 and batch: 950, loss is 3.8582718086242678 and perplexity is 47.38339299824479
At time: 687.9883348941803 and batch: 1000, loss is 3.83098228931427 and perplexity is 46.10780720328241
At time: 688.8836984634399 and batch: 1050, loss is 3.776518669128418 and perplexity is 43.663768806824635
At time: 689.7787885665894 and batch: 1100, loss is 3.7919886016845705 and perplexity is 44.3444961929381
At time: 690.6944863796234 and batch: 1150, loss is 3.768286361694336 and perplexity is 43.30579075267957
At time: 691.5904231071472 and batch: 1200, loss is 3.819267191886902 and perplexity is 45.5708014289155
At time: 692.5038647651672 and batch: 1250, loss is 3.8056373310089113 and perplexity is 44.95389149404419
At time: 693.4057803153992 and batch: 1300, loss is 3.8100466251373293 and perplexity is 45.152544060808445
At time: 694.3201041221619 and batch: 1350, loss is 3.69767804145813 and perplexity is 40.353496347518025
At time: 695.2222621440887 and batch: 1400, loss is 3.7205058670043947 and perplexity is 41.28527368474573
At time: 696.1175067424774 and batch: 1450, loss is 3.6371640968322754 and perplexity is 37.98396499415233
At time: 697.0131623744965 and batch: 1500, loss is 3.6516106510162354 and perplexity is 38.536685241233286
At time: 697.9081594944 and batch: 1550, loss is 3.6547011280059816 and perplexity is 38.655966202827805
At time: 698.8043253421783 and batch: 1600, loss is 3.7476252460479738 and perplexity is 42.42022469557827
At time: 699.6996538639069 and batch: 1650, loss is 3.699773597717285 and perplexity is 40.43814803457621
At time: 700.5947859287262 and batch: 1700, loss is 3.7078379821777343 and perplexity is 40.7655752823017
At time: 701.4943408966064 and batch: 1750, loss is 3.7009406805038454 and perplexity is 40.48537025182615
At time: 702.3874397277832 and batch: 1800, loss is 3.6691378927230835 and perplexity is 39.218081089015186
At time: 703.2808947563171 and batch: 1850, loss is 3.692917032241821 and perplexity is 40.16182960510645
At time: 704.1763327121735 and batch: 1900, loss is 3.786704773902893 and perplexity is 44.11080544651605
At time: 705.0718700885773 and batch: 1950, loss is 3.720084857940674 and perplexity is 41.26789586869199
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267200842569041 and perplexity of 71.32171523625018
finished 19 epochs...
Completing Train Step...
At time: 708.0327987670898 and batch: 50, loss is 3.8644511890411377 and perplexity is 47.67709953664706
At time: 708.9263010025024 and batch: 100, loss is 3.859254631996155 and perplexity is 47.42998539662135
At time: 709.8191947937012 and batch: 150, loss is 3.824614553451538 and perplexity is 45.81513767585612
At time: 710.7126648426056 and batch: 200, loss is 3.814906568527222 and perplexity is 45.37251696381917
At time: 711.607830286026 and batch: 250, loss is 3.802286133766174 and perplexity is 44.8034942829319
At time: 712.5020439624786 and batch: 300, loss is 3.809958176612854 and perplexity is 45.14855056152213
At time: 713.3953578472137 and batch: 350, loss is 3.8200797128677366 and perplexity is 45.60784370796649
At time: 714.3047487735748 and batch: 400, loss is 3.779519124031067 and perplexity is 43.79497671928554
At time: 715.2086985111237 and batch: 450, loss is 3.8301004123687745 and perplexity is 46.067163715014196
At time: 716.1006000041962 and batch: 500, loss is 3.845772833824158 and perplexity is 46.79483501117889
At time: 717.0114464759827 and batch: 550, loss is 3.822874174118042 and perplexity is 45.73547130204766
At time: 717.9402420520782 and batch: 600, loss is 3.796828260421753 and perplexity is 44.55962858515732
At time: 718.8337254524231 and batch: 650, loss is 3.8290803146362307 and perplexity is 46.020194666346804
At time: 719.7283306121826 and batch: 700, loss is 3.847108941078186 and perplexity is 46.85739971695954
At time: 720.6225130558014 and batch: 750, loss is 3.807334599494934 and perplexity is 45.03025510384347
At time: 721.5170633792877 and batch: 800, loss is 3.7766090059280395 and perplexity is 43.667713430127705
At time: 722.4104413986206 and batch: 850, loss is 3.7851086235046387 and perplexity is 44.04045412741442
At time: 723.3039786815643 and batch: 900, loss is 3.7531766414642336 and perplexity is 42.656371000805635
At time: 724.1973176002502 and batch: 950, loss is 3.8556425285339357 and perplexity is 47.25897242636614
At time: 725.0919325351715 and batch: 1000, loss is 3.8284280681610108 and perplexity is 45.990187943540136
At time: 725.9858453273773 and batch: 1050, loss is 3.7741953849792482 and perplexity is 43.56244321451066
At time: 726.8804476261139 and batch: 1100, loss is 3.7896717166900635 and perplexity is 44.241874022908576
At time: 727.7751815319061 and batch: 1150, loss is 3.7661430072784423 and perplexity is 43.213070496517446
At time: 728.669417142868 and batch: 1200, loss is 3.817200517654419 and perplexity is 45.476718680531405
At time: 729.5640275478363 and batch: 1250, loss is 3.8038126754760744 and perplexity is 44.87194091573207
At time: 730.4585547447205 and batch: 1300, loss is 3.808195791244507 and perplexity is 45.06905149118662
At time: 731.3553478717804 and batch: 1350, loss is 3.6958969259262084 and perplexity is 40.28168607858287
At time: 732.2479522228241 and batch: 1400, loss is 3.7189162492752077 and perplexity is 41.21969801567372
At time: 733.1433594226837 and batch: 1450, loss is 3.6357258224487303 and perplexity is 37.92937289893273
At time: 734.0380589962006 and batch: 1500, loss is 3.650306510925293 and perplexity is 38.486460762035
At time: 734.9308714866638 and batch: 1550, loss is 3.65345278263092 and perplexity is 38.60774031374557
At time: 735.8252599239349 and batch: 1600, loss is 3.746681709289551 and perplexity is 42.3802185308889
At time: 736.7172167301178 and batch: 1650, loss is 3.6988731670379638 and perplexity is 40.40175267367975
At time: 737.6106102466583 and batch: 1700, loss is 3.707033185958862 and perplexity is 40.732780499782926
At time: 738.5050551891327 and batch: 1750, loss is 3.700253086090088 and perplexity is 40.45754230566864
At time: 739.3994793891907 and batch: 1800, loss is 3.668683261871338 and perplexity is 39.20025539176886
At time: 740.2912704944611 and batch: 1850, loss is 3.6925061893463136 and perplexity is 40.145332791773924
At time: 741.1837430000305 and batch: 1900, loss is 3.786332550048828 and perplexity is 44.09438940791695
At time: 742.1075494289398 and batch: 1950, loss is 3.7195650148391723 and perplexity is 41.246448612798154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2672826012899705 and perplexity of 71.32754664684347
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -71.32171523625018
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
771.7453339099884


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4037106037139893 and batch: 50, loss is 7.531650609970093 and perplexity is 1866.1833035008644
At time: 2.3636624813079834 and batch: 100, loss is 6.710392932891846 and perplexity is 820.8931319997673
At time: 3.324425220489502 and batch: 150, loss is 6.445662775039673 and perplexity is 629.9640630870881
At time: 4.284193515777588 and batch: 200, loss is 6.281309738159179 and perplexity is 534.488245241743
At time: 5.244542837142944 and batch: 250, loss is 6.187659740447998 and perplexity is 486.7057545843204
At time: 6.204347848892212 and batch: 300, loss is 6.100158052444458 and perplexity is 445.9282445621443
At time: 7.164799928665161 and batch: 350, loss is 6.040179471969605 and perplexity is 419.96840067949057
At time: 8.125980615615845 and batch: 400, loss is 5.978747758865357 and perplexity is 394.9454913772187
At time: 9.087141275405884 and batch: 450, loss is 5.887201843261718 and perplexity is 360.395429265908
At time: 10.045118570327759 and batch: 500, loss is 5.85636414527893 and perplexity is 349.45127736641626
At time: 11.030308961868286 and batch: 550, loss is 5.793259792327881 and perplexity is 328.080758273833
At time: 11.989936828613281 and batch: 600, loss is 5.814797897338867 and perplexity is 335.22364206432326
At time: 12.949646949768066 and batch: 650, loss is 5.86980710029602 and perplexity is 354.1806523347675
At time: 13.909454584121704 and batch: 700, loss is 5.787820024490356 and perplexity is 326.3009204580581
At time: 14.870180606842041 and batch: 750, loss is 5.725424041748047 and perplexity is 306.5632332948101
At time: 15.828752279281616 and batch: 800, loss is 5.717136363983155 and perplexity is 304.0330352182011
At time: 16.78848361968994 and batch: 850, loss is 5.73879940032959 and perplexity is 310.69117125267354
At time: 17.748596668243408 and batch: 900, loss is 5.724787921905517 and perplexity is 306.3682843511407
At time: 18.70854377746582 and batch: 950, loss is 5.751908388137817 and perplexity is 314.7908305115173
At time: 19.66838264465332 and batch: 1000, loss is 5.71715482711792 and perplexity is 304.0386486729242
At time: 20.629786014556885 and batch: 1050, loss is 5.612391204833984 and perplexity is 273.7981633501844
At time: 21.58972954750061 and batch: 1100, loss is 5.692284812927246 and perplexity is 296.5704551356713
At time: 22.54917001724243 and batch: 1150, loss is 5.593974046707153 and perplexity is 268.80173055560374
At time: 23.510380744934082 and batch: 1200, loss is 5.67153865814209 and perplexity is 290.48114188958453
At time: 24.470542430877686 and batch: 1250, loss is 5.614752149581909 and perplexity is 274.44534937053413
At time: 25.43278431892395 and batch: 1300, loss is 5.620530080795288 and perplexity is 276.0356656657874
At time: 26.394801139831543 and batch: 1350, loss is 5.581085815429687 and perplexity is 265.35958094140153
At time: 27.3559889793396 and batch: 1400, loss is 5.601680164337158 and perplexity is 270.88115014600965
At time: 28.316284656524658 and batch: 1450, loss is 5.572391357421875 and perplexity is 263.06242394629714
At time: 29.276658535003662 and batch: 1500, loss is 5.532609577178955 and perplexity is 252.80275930335947
At time: 30.237346410751343 and batch: 1550, loss is 5.507771463394165 and perplexity is 246.60095500077207
At time: 31.197885751724243 and batch: 1600, loss is 5.537579927444458 and perplexity is 254.06240541314043
At time: 32.15877819061279 and batch: 1650, loss is 5.527973947525024 and perplexity is 251.6335713905456
At time: 33.12038779258728 and batch: 1700, loss is 5.553194198608399 and perplexity is 258.06053743236697
At time: 34.081329584121704 and batch: 1750, loss is 5.55521728515625 and perplexity is 258.58314469579244
At time: 35.04161357879639 and batch: 1800, loss is 5.541421871185303 and perplexity is 255.0403763330815
At time: 36.003867864608765 and batch: 1850, loss is 5.501354112625122 and perplexity is 245.02349713639083
At time: 36.96428561210632 and batch: 1900, loss is 5.527149629592896 and perplexity is 251.42623079434927
At time: 37.92495656013489 and batch: 1950, loss is 5.455602045059204 and perplexity is 234.06574678483156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.956788812681686 and perplexity of 142.1366349155505
finished 1 epochs...
Completing Train Step...
At time: 40.87035870552063 and batch: 50, loss is 5.19564905166626 and perplexity is 180.48524904052252
At time: 41.78541803359985 and batch: 100, loss is 5.119701614379883 and perplexity is 167.28544660159815
At time: 42.67457580566406 and batch: 150, loss is 5.038796968460083 and perplexity is 154.28429446209043
At time: 43.564202070236206 and batch: 200, loss is 4.995522546768188 and perplexity is 147.75013156877122
At time: 44.45411825180054 and batch: 250, loss is 5.001638689041138 and perplexity is 148.6565614959085
At time: 45.36688160896301 and batch: 300, loss is 5.003669033050537 and perplexity is 148.9586920657065
At time: 46.25669884681702 and batch: 350, loss is 4.99705732345581 and perplexity is 147.9770691309894
At time: 47.14677953720093 and batch: 400, loss is 4.947933368682861 and perplexity is 140.8835085889326
At time: 48.03602719306946 and batch: 450, loss is 4.914915809631347 and perplexity is 136.30783351270117
At time: 48.923606395721436 and batch: 500, loss is 4.896921691894531 and perplexity is 133.87702997896636
At time: 49.81178593635559 and batch: 550, loss is 4.855627689361572 and perplexity is 128.46129970472612
At time: 50.70062851905823 and batch: 600, loss is 4.84145809173584 and perplexity is 126.65389015098813
At time: 51.611074686050415 and batch: 650, loss is 4.910837526321411 and perplexity is 135.75306357369348
At time: 52.500937938690186 and batch: 700, loss is 4.899866781234741 and perplexity is 134.2718909578825
At time: 53.391849517822266 and batch: 750, loss is 4.861121816635132 and perplexity is 129.1690248207134
At time: 54.29428148269653 and batch: 800, loss is 4.838895492553711 and perplexity is 126.32974250330965
At time: 55.18446588516235 and batch: 850, loss is 4.82607346534729 and perplexity is 124.72027944766675
At time: 56.074963092803955 and batch: 900, loss is 4.822590627670288 and perplexity is 124.28665452026586
At time: 56.96567392349243 and batch: 950, loss is 4.877293577194214 and perplexity is 131.27489729970765
At time: 57.86092138290405 and batch: 1000, loss is 4.851196613311767 and perplexity is 127.89333718813153
At time: 58.75797510147095 and batch: 1050, loss is 4.760693426132202 and perplexity is 116.82690864936913
At time: 59.67944407463074 and batch: 1100, loss is 4.831886615753174 and perplexity is 125.44740859868159
At time: 60.574766874313354 and batch: 1150, loss is 4.755072536468506 and perplexity is 116.17207957117566
At time: 61.46965956687927 and batch: 1200, loss is 4.837680683135987 and perplexity is 126.17636912095452
At time: 62.36469841003418 and batch: 1250, loss is 4.795681705474854 and perplexity is 120.98683106191905
At time: 63.259666442871094 and batch: 1300, loss is 4.814814176559448 and perplexity is 123.32389371060638
At time: 64.15496611595154 and batch: 1350, loss is 4.712809610366821 and perplexity is 111.3646119341182
At time: 65.08409428596497 and batch: 1400, loss is 4.723835411071778 and perplexity is 112.59929010047057
At time: 65.99350357055664 and batch: 1450, loss is 4.663477115631103 and perplexity is 106.0040303576375
At time: 66.88818359375 and batch: 1500, loss is 4.65289348602295 and perplexity is 104.88803900007689
At time: 67.78295540809631 and batch: 1550, loss is 4.651405944824218 and perplexity is 104.73212971030546
At time: 68.67772150039673 and batch: 1600, loss is 4.718884449005127 and perplexity is 112.04319303012338
At time: 69.57209014892578 and batch: 1650, loss is 4.681014518737793 and perplexity is 107.87946280923806
At time: 70.46659302711487 and batch: 1700, loss is 4.708197593688965 and perplexity is 110.85217906933113
At time: 71.36063957214355 and batch: 1750, loss is 4.704327964782715 and perplexity is 110.42405115519288
At time: 72.25420045852661 and batch: 1800, loss is 4.660945949554443 and perplexity is 105.73605583908399
At time: 73.14808297157288 and batch: 1850, loss is 4.678515930175781 and perplexity is 107.6102528798672
At time: 74.04246830940247 and batch: 1900, loss is 4.753056497573852 and perplexity is 115.93810806735969
At time: 74.9358081817627 and batch: 1950, loss is 4.669027462005615 and perplexity is 106.59402526663727
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.545318461573401 and perplexity of 94.19041846248537
finished 2 epochs...
Completing Train Step...
At time: 77.87222957611084 and batch: 50, loss is 4.626423263549805 and perplexity is 102.14805327308281
At time: 78.7906768321991 and batch: 100, loss is 4.5826591205596925 and perplexity is 97.77404180168888
At time: 79.68737149238586 and batch: 150, loss is 4.532171859741211 and perplexity is 92.96023859493837
At time: 80.58323383331299 and batch: 200, loss is 4.528906383514404 and perplexity is 92.65717423979817
At time: 81.47861385345459 and batch: 250, loss is 4.522929048538208 and perplexity is 92.1049832308151
At time: 82.37498188018799 and batch: 300, loss is 4.542644882202149 and perplexity is 93.93892924071646
At time: 83.27006649971008 and batch: 350, loss is 4.5542521476745605 and perplexity is 95.03565601668187
At time: 84.16524648666382 and batch: 400, loss is 4.513785696029663 and perplexity is 91.26667322357673
At time: 85.06130337715149 and batch: 450, loss is 4.515600214004516 and perplexity is 91.43242858020423
At time: 85.95583820343018 and batch: 500, loss is 4.51207314491272 and perplexity is 91.11050813892028
At time: 86.8515772819519 and batch: 550, loss is 4.482144727706909 and perplexity is 88.42411510144137
At time: 87.74792790412903 and batch: 600, loss is 4.465954113006592 and perplexity is 87.0040016006495
At time: 88.64461851119995 and batch: 650, loss is 4.533134431838989 and perplexity is 93.04976260655818
At time: 89.56398844718933 and batch: 700, loss is 4.545493755340576 and perplexity is 94.20693090299116
At time: 90.46046614646912 and batch: 750, loss is 4.515050783157348 and perplexity is 91.3822065815318
At time: 91.3569724559784 and batch: 800, loss is 4.4924343490600585 and perplexity is 89.33866287038425
At time: 92.2524197101593 and batch: 850, loss is 4.486145009994507 and perplexity is 88.77854495998115
At time: 93.14864683151245 and batch: 900, loss is 4.47494288444519 and perplexity is 87.78958611564157
At time: 94.05732464790344 and batch: 950, loss is 4.538926820755005 and perplexity is 93.5903070305324
At time: 94.96161150932312 and batch: 1000, loss is 4.520041971206665 and perplexity is 91.83945250990786
At time: 95.85847759246826 and batch: 1050, loss is 4.451400814056396 and perplexity is 85.74697548022796
At time: 96.75509738922119 and batch: 1100, loss is 4.499020719528199 and perplexity is 89.92902243040088
At time: 97.6506655216217 and batch: 1150, loss is 4.450009803771973 and perplexity is 85.62778347334931
At time: 98.54593014717102 and batch: 1200, loss is 4.533112716674805 and perplexity is 93.04774203762446
At time: 99.44086837768555 and batch: 1250, loss is 4.501245412826538 and perplexity is 90.12930963011738
At time: 100.35704636573792 and batch: 1300, loss is 4.512950973510742 and perplexity is 91.19052266292552
At time: 101.25397753715515 and batch: 1350, loss is 4.392200174331665 and perplexity is 80.8180372843784
At time: 102.15125632286072 and batch: 1400, loss is 4.414949674606323 and perplexity is 82.6776800146148
At time: 103.04658770561218 and batch: 1450, loss is 4.353539991378784 and perplexity is 77.75322205159746
At time: 103.94266104698181 and batch: 1500, loss is 4.359368758201599 and perplexity is 78.20775083694501
At time: 104.83898878097534 and batch: 1550, loss is 4.365166530609131 and perplexity is 78.6624985648876
At time: 105.73399090766907 and batch: 1600, loss is 4.439352979660034 and perplexity is 84.72010830331159
At time: 106.62996482849121 and batch: 1650, loss is 4.400901746749878 and perplexity is 81.5243498467907
At time: 107.52483677864075 and batch: 1700, loss is 4.428112258911133 and perplexity is 83.77312557945189
At time: 108.42038154602051 and batch: 1750, loss is 4.422294244766236 and perplexity is 83.28714743456268
At time: 109.31455326080322 and batch: 1800, loss is 4.382871904373169 and perplexity is 80.06765016323166
At time: 110.21159029006958 and batch: 1850, loss is 4.418207445144653 and perplexity is 82.94746413351798
At time: 111.10697078704834 and batch: 1900, loss is 4.490433435440064 and perplexity is 89.16008264443911
At time: 112.00292658805847 and batch: 1950, loss is 4.417845096588135 and perplexity is 82.91741368431956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.432514705214389 and perplexity of 84.14274528494154
finished 3 epochs...
Completing Train Step...
At time: 114.96712970733643 and batch: 50, loss is 4.385702004432678 and perplexity is 80.2945705770024
At time: 115.91706490516663 and batch: 100, loss is 4.3507796478271485 and perplexity is 77.53889239432247
At time: 116.8131947517395 and batch: 150, loss is 4.313412475585937 and perplexity is 74.69494921426356
At time: 117.7089524269104 and batch: 200, loss is 4.31266845703125 and perplexity is 74.63939545518318
At time: 118.60523343086243 and batch: 250, loss is 4.299053459167481 and perplexity is 73.63006684037649
At time: 119.5009093284607 and batch: 300, loss is 4.31902681350708 and perplexity is 75.11549132827305
At time: 120.39668893814087 and batch: 350, loss is 4.336995658874511 and perplexity is 76.47742956044314
At time: 121.29182839393616 and batch: 400, loss is 4.293236722946167 and perplexity is 73.20302336729067
At time: 122.18691945075989 and batch: 450, loss is 4.315089960098266 and perplexity is 74.82035398759525
At time: 123.08249282836914 and batch: 500, loss is 4.313849220275879 and perplexity is 74.72757896161411
At time: 123.97660231590271 and batch: 550, loss is 4.2827832126617436 and perplexity is 72.44178057147752
At time: 124.87037754058838 and batch: 600, loss is 4.273989939689637 and perplexity is 71.8075726883405
At time: 125.76550579071045 and batch: 650, loss is 4.337569723129272 and perplexity is 76.5213451230211
At time: 126.66101884841919 and batch: 700, loss is 4.359418439865112 and perplexity is 78.21163642462662
At time: 127.55516839027405 and batch: 750, loss is 4.32733564376831 and perplexity is 75.74221325319458
At time: 128.44897747039795 and batch: 800, loss is 4.305771260261536 and perplexity is 74.12636413074976
At time: 129.34354209899902 and batch: 850, loss is 4.299900197982788 and perplexity is 73.69243867854557
At time: 130.23988485336304 and batch: 900, loss is 4.283810358047486 and perplexity is 72.51622703925413
At time: 131.135990858078 and batch: 950, loss is 4.35970778465271 and perplexity is 78.23426982822637
At time: 132.03080439567566 and batch: 1000, loss is 4.336910552978516 and perplexity is 76.47092115723265
At time: 132.92698526382446 and batch: 1050, loss is 4.276989097595215 and perplexity is 72.02325821344968
At time: 133.82227206230164 and batch: 1100, loss is 4.31988920211792 and perplexity is 75.18029801274898
At time: 134.73970794677734 and batch: 1150, loss is 4.280598192214966 and perplexity is 72.2836666037612
At time: 135.6346094608307 and batch: 1200, loss is 4.359807686805725 and perplexity is 78.24208599064099
At time: 136.52977204322815 and batch: 1250, loss is 4.33782543182373 and perplexity is 76.5409147982421
At time: 137.42501020431519 and batch: 1300, loss is 4.340807371139526 and perplexity is 76.76949579930515
At time: 138.32112407684326 and batch: 1350, loss is 4.218853535652161 and perplexity is 67.95553101908357
At time: 139.21650004386902 and batch: 1400, loss is 4.246728258132935 and perplexity is 69.87642033964012
At time: 140.1125431060791 and batch: 1450, loss is 4.179110884666443 and perplexity is 65.30776126067646
At time: 141.00800585746765 and batch: 1500, loss is 4.191181602478028 and perplexity is 66.10084976196968
At time: 141.90327978134155 and batch: 1550, loss is 4.202095232009888 and perplexity is 66.82620085503092
At time: 142.79965901374817 and batch: 1600, loss is 4.279050598144531 and perplexity is 72.17188734670336
At time: 143.69677734375 and batch: 1650, loss is 4.239090008735657 and perplexity is 69.34472002895933
At time: 144.59440398216248 and batch: 1700, loss is 4.264979310035706 and perplexity is 71.16344758897357
At time: 145.49159932136536 and batch: 1750, loss is 4.260692930221557 and perplexity is 70.85906683551516
At time: 146.38777470588684 and batch: 1800, loss is 4.220797600746155 and perplexity is 68.08776949333415
At time: 147.28412175178528 and batch: 1850, loss is 4.261982383728028 and perplexity is 70.95049524138263
At time: 148.18189096450806 and batch: 1900, loss is 4.331170501708985 and perplexity is 76.03323153136421
At time: 149.07898783683777 and batch: 1950, loss is 4.263622446060181 and perplexity is 71.06695394974176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388968250363372 and perplexity of 80.55726116389673
finished 4 epochs...
Completing Train Step...
At time: 152.03761386871338 and batch: 50, loss is 4.2349628782272335 and perplexity is 69.05911508915716
At time: 152.93144845962524 and batch: 100, loss is 4.20365355014801 and perplexity is 66.93041851697177
At time: 153.82635974884033 and batch: 150, loss is 4.177043318748474 and perplexity is 65.17287265291125
At time: 154.71986389160156 and batch: 200, loss is 4.1750508975982665 and perplexity is 65.04315011689377
At time: 155.6143729686737 and batch: 250, loss is 4.156274046897888 and perplexity is 63.833239303410714
At time: 156.50929307937622 and batch: 300, loss is 4.181759223937989 and perplexity is 65.48094759642389
At time: 157.44390559196472 and batch: 350, loss is 4.195122723579407 and perplexity is 66.36187524444077
At time: 158.33935952186584 and batch: 400, loss is 4.154153566360474 and perplexity is 63.69802557153617
At time: 159.23258638381958 and batch: 450, loss is 4.1867060947418215 and perplexity is 65.80567591660277
At time: 160.12644696235657 and batch: 500, loss is 4.187733879089356 and perplexity is 65.87334472880498
At time: 161.02110075950623 and batch: 550, loss is 4.15062783241272 and perplexity is 63.47383872419796
At time: 161.91415643692017 and batch: 600, loss is 4.149364595413208 and perplexity is 63.39370684605313
At time: 162.80848503112793 and batch: 650, loss is 4.209192447662353 and perplexity is 67.30216783599937
At time: 163.70265555381775 and batch: 700, loss is 4.233688349723816 and perplexity is 68.97115334533736
At time: 164.59651708602905 and batch: 750, loss is 4.204233288764954 and perplexity is 66.96923191496002
At time: 165.4920735359192 and batch: 800, loss is 4.181207804679871 and perplexity is 65.44485009422303
At time: 166.38770246505737 and batch: 850, loss is 4.177490110397339 and perplexity is 65.20199785410894
At time: 167.28172850608826 and batch: 900, loss is 4.159622740745545 and perplexity is 64.0473555839906
At time: 168.17458581924438 and batch: 950, loss is 4.240344414710998 and perplexity is 69.4317610410914
At time: 169.06800723075867 and batch: 1000, loss is 4.218149538040161 and perplexity is 67.90770732338291
At time: 169.96230030059814 and batch: 1050, loss is 4.164313654899598 and perplexity is 64.34850200461376
At time: 170.8569095134735 and batch: 1100, loss is 4.199021468162536 and perplexity is 66.62110825936647
At time: 171.74978256225586 and batch: 1150, loss is 4.163204584121704 and perplexity is 64.27717452236364
At time: 172.64516353607178 and batch: 1200, loss is 4.242663831710815 and perplexity is 69.59298915330966
At time: 173.53865385055542 and batch: 1250, loss is 4.221341519355774 and perplexity is 68.12481377187197
At time: 174.43969058990479 and batch: 1300, loss is 4.222451949119568 and perplexity is 68.20050360908374
At time: 175.34654688835144 and batch: 1350, loss is 4.102588467597961 and perplexity is 60.49667879611413
At time: 176.24101066589355 and batch: 1400, loss is 4.13266812324524 and perplexity is 62.34404281188761
At time: 177.13541078567505 and batch: 1450, loss is 4.058423142433167 and perplexity is 57.882965885959216
At time: 178.03241205215454 and batch: 1500, loss is 4.076391854286194 and perplexity is 58.932448912747866
At time: 178.92890405654907 and batch: 1550, loss is 4.084251289367676 and perplexity is 59.39744959689886
At time: 179.82416820526123 and batch: 1600, loss is 4.167663564682007 and perplexity is 64.56442514055288
At time: 180.7198622226715 and batch: 1650, loss is 4.125514507293701 and perplexity is 61.89964887963088
At time: 181.6130633354187 and batch: 1700, loss is 4.153636155128479 and perplexity is 63.66507602261796
At time: 182.50676155090332 and batch: 1750, loss is 4.147794308662415 and perplexity is 63.29423866533133
At time: 183.40357947349548 and batch: 1800, loss is 4.108628740310669 and perplexity is 60.863201067115305
At time: 184.29748344421387 and batch: 1850, loss is 4.151555433273315 and perplexity is 63.53274442789076
At time: 185.19190502166748 and batch: 1900, loss is 4.220685992240906 and perplexity is 68.0801707432057
At time: 186.08675956726074 and batch: 1950, loss is 4.154714984893799 and perplexity is 63.73379686402193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368709972292878 and perplexity of 78.9417289674064
finished 5 epochs...
Completing Train Step...
At time: 189.05682826042175 and batch: 50, loss is 4.13033314704895 and perplexity is 62.198640777148775
At time: 189.95132780075073 and batch: 100, loss is 4.098883008956909 and perplexity is 60.27292566491955
At time: 190.8454475402832 and batch: 150, loss is 4.075137405395508 and perplexity is 58.858567517489604
At time: 191.74148726463318 and batch: 200, loss is 4.069927921295166 and perplexity is 58.552742033977744
At time: 192.63596630096436 and batch: 250, loss is 4.054582271575928 and perplexity is 57.6610712961766
At time: 193.53061771392822 and batch: 300, loss is 4.078801832199097 and perplexity is 59.07464609018596
At time: 194.4259889125824 and batch: 350, loss is 4.093333401679993 and perplexity is 59.939361030506824
At time: 195.32252502441406 and batch: 400, loss is 4.052045192718506 and perplexity is 57.514966029956184
At time: 196.21751618385315 and batch: 450, loss is 4.088481564521789 and perplexity is 59.64924936780258
At time: 197.11195421218872 and batch: 500, loss is 4.09530613899231 and perplexity is 60.05772235400227
At time: 198.0065722465515 and batch: 550, loss is 4.057433428764344 and perplexity is 57.8257066632215
At time: 198.90408158302307 and batch: 600, loss is 4.058600821495056 and perplexity is 57.893251390769564
At time: 199.8109290599823 and batch: 650, loss is 4.116728920936584 and perplexity is 61.35820609775201
At time: 200.7047336101532 and batch: 700, loss is 4.137278542518616 and perplexity is 62.632138599320555
At time: 201.64349246025085 and batch: 750, loss is 4.114386239051819 and perplexity is 61.21463158021909
At time: 202.53758335113525 and batch: 800, loss is 4.087279748916626 and perplexity is 59.57760502934145
At time: 203.43284344673157 and batch: 850, loss is 4.085251603126526 and perplexity is 59.45689541024683
At time: 204.32636904716492 and batch: 900, loss is 4.065741028785705 and perplexity is 58.30810049823585
At time: 205.22199988365173 and batch: 950, loss is 4.148134689331055 and perplexity is 63.31578646762894
At time: 206.11769556999207 and batch: 1000, loss is 4.13011803150177 and perplexity is 62.1852623215126
At time: 207.01551461219788 and batch: 1050, loss is 4.077581038475037 and perplexity is 59.002572135654894
At time: 207.9108703136444 and batch: 1100, loss is 4.108606061935425 and perplexity is 60.86182080425405
At time: 208.80768609046936 and batch: 1150, loss is 4.074949975013733 and perplexity is 58.84753666749957
At time: 209.70389437675476 and batch: 1200, loss is 4.1548930406570435 and perplexity is 63.74514604423053
At time: 210.6012806892395 and batch: 1250, loss is 4.134360499382019 and perplexity is 62.4496417135393
At time: 211.49672198295593 and batch: 1300, loss is 4.1338119792938235 and perplexity is 62.41539622358701
At time: 212.39170575141907 and batch: 1350, loss is 4.012784419059753 and perplexity is 55.30063653605338
At time: 213.2876181602478 and batch: 1400, loss is 4.047390775680542 and perplexity is 57.24788941724996
At time: 214.21013760566711 and batch: 1450, loss is 3.9727805519104002 and perplexity is 53.13206209222438
At time: 215.1230869293213 and batch: 1500, loss is 3.98935284614563 and perplexity is 54.01991885019923
At time: 216.0329532623291 and batch: 1550, loss is 3.9970745706558226 and perplexity is 54.43866040446389
At time: 216.9283652305603 and batch: 1600, loss is 4.084547781944275 and perplexity is 59.41506311078232
At time: 217.82403993606567 and batch: 1650, loss is 4.039864401817322 and perplexity is 56.81863777906197
At time: 218.7184443473816 and batch: 1700, loss is 4.067073330879212 and perplexity is 58.3858362748684
At time: 219.61537718772888 and batch: 1750, loss is 4.0637735080718995 and perplexity is 58.193490888086345
At time: 220.5098123550415 and batch: 1800, loss is 4.028356461524964 and perplexity is 56.16852021975406
At time: 221.40586948394775 and batch: 1850, loss is 4.069658265113831 and perplexity is 58.53695505377821
At time: 222.30215311050415 and batch: 1900, loss is 4.136533479690552 and perplexity is 62.58549110082454
At time: 223.19738340377808 and batch: 1950, loss is 4.067960534095764 and perplexity is 58.43765936201809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361286393986192 and perplexity of 78.35786870828072
finished 6 epochs...
Completing Train Step...
At time: 226.15423798561096 and batch: 50, loss is 4.046481018066406 and perplexity is 57.195831397639786
At time: 227.0504059791565 and batch: 100, loss is 4.018982281684876 and perplexity is 55.644446627665744
At time: 227.9462330341339 and batch: 150, loss is 3.998960227966309 and perplexity is 54.54140990715853
At time: 228.84097576141357 and batch: 200, loss is 3.992228374481201 and perplexity is 54.175478208019896
At time: 229.73640131950378 and batch: 250, loss is 3.9737328147888182 and perplexity is 53.18268188045604
At time: 230.63196182250977 and batch: 300, loss is 4.000515151023865 and perplexity is 54.6262835719234
At time: 231.52837562561035 and batch: 350, loss is 4.012183012962342 and perplexity is 55.267388394869414
At time: 232.4242627620697 and batch: 400, loss is 3.9751520919799805 and perplexity is 53.258216437371296
At time: 233.3209056854248 and batch: 450, loss is 4.0118230676651 and perplexity is 55.24749873813479
At time: 234.2188732624054 and batch: 500, loss is 4.025817828178406 and perplexity is 56.02610978172305
At time: 235.13250494003296 and batch: 550, loss is 3.980623822212219 and perplexity is 53.55042975752808
At time: 236.02881717681885 and batch: 600, loss is 3.9879070949554443 and perplexity is 53.941875917153254
At time: 236.9240527153015 and batch: 650, loss is 4.044792623519897 and perplexity is 57.09934374535918
At time: 237.8208680152893 and batch: 700, loss is 4.061894397735596 and perplexity is 58.084241575756096
At time: 238.718120098114 and batch: 750, loss is 4.040755109786987 and perplexity is 56.86926913808739
At time: 239.6139748096466 and batch: 800, loss is 4.013450169563294 and perplexity is 55.33746522067077
At time: 240.50901126861572 and batch: 850, loss is 4.012819256782532 and perplexity is 55.30256311785717
At time: 241.40594673156738 and batch: 900, loss is 3.99098792552948 and perplexity is 54.10831795591162
At time: 242.3087944984436 and batch: 950, loss is 4.076493468284607 and perplexity is 58.93843757877915
At time: 243.23246788978577 and batch: 1000, loss is 4.055373158454895 and perplexity is 57.706692719206345
At time: 244.14204502105713 and batch: 1050, loss is 4.008156714439392 and perplexity is 55.0453127620112
At time: 245.03870677947998 and batch: 1100, loss is 4.03411868095398 and perplexity is 56.493109838450465
At time: 245.9361834526062 and batch: 1150, loss is 4.003812074661255 and perplexity is 54.8066794698002
At time: 246.90456223487854 and batch: 1200, loss is 4.082926316261291 and perplexity is 59.31880168828294
At time: 247.81170344352722 and batch: 1250, loss is 4.068237643241883 and perplexity is 58.453855215811025
At time: 248.70935559272766 and batch: 1300, loss is 4.066387042999268 and perplexity is 58.345780529531005
At time: 249.60596084594727 and batch: 1350, loss is 3.946335821151733 and perplexity is 51.74541458423581
At time: 250.50192761421204 and batch: 1400, loss is 3.9778355312347413 and perplexity is 53.40132354974502
At time: 251.39897894859314 and batch: 1450, loss is 3.90039701461792 and perplexity is 49.422066493923424
At time: 252.29541110992432 and batch: 1500, loss is 3.9226341247558594 and perplexity is 50.53338084558893
At time: 253.1921260356903 and batch: 1550, loss is 3.928919734954834 and perplexity is 50.85201433350056
At time: 254.08901691436768 and batch: 1600, loss is 4.018259272575379 and perplexity is 55.604229726206
At time: 254.98534679412842 and batch: 1650, loss is 3.972320070266724 and perplexity is 53.10760138522574
At time: 255.88117909431458 and batch: 1700, loss is 4.002206716537476 and perplexity is 54.71876570709333
At time: 256.7776668071747 and batch: 1750, loss is 3.9984839391708373 and perplexity is 54.51543863013563
At time: 257.6743075847626 and batch: 1800, loss is 3.9612859582901 and perplexity is 52.52482727492235
At time: 258.5704321861267 and batch: 1850, loss is 4.000892653465271 and perplexity is 54.64690902017034
At time: 259.4678838253021 and batch: 1900, loss is 4.070687217712402 and perplexity is 58.59721780423319
At time: 260.3628430366516 and batch: 1950, loss is 4.001483402252197 and perplexity is 54.67920115271323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361920875726744 and perplexity of 78.40760112069012
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 263.2962954044342 and batch: 50, loss is 4.012418460845947 and perplexity is 55.28040251651298
At time: 264.21531534194946 and batch: 100, loss is 4.002464246749878 and perplexity is 54.732859257127856
At time: 265.1119682788849 and batch: 150, loss is 3.9899003458023072 and perplexity is 54.04950283509525
At time: 266.0073277950287 and batch: 200, loss is 3.9773668336868284 and perplexity is 53.3763003449574
At time: 266.9031720161438 and batch: 250, loss is 3.9674882745742797 and perplexity is 52.85161524001961
At time: 267.79896068573 and batch: 300, loss is 3.9763455200195312 and perplexity is 53.32181422834925
At time: 268.6950421333313 and batch: 350, loss is 3.985427713394165 and perplexity is 53.808299087016714
At time: 269.61482286453247 and batch: 400, loss is 3.9437347269058227 and perplexity is 51.61099477918612
At time: 270.51006507873535 and batch: 450, loss is 3.9694631576538084 and perplexity is 52.956094133525305
At time: 271.4054822921753 and batch: 500, loss is 3.9799484825134277 and perplexity is 53.514277235416216
At time: 272.30216240882874 and batch: 550, loss is 3.9314353036880494 and perplexity is 50.980097103741755
At time: 273.1956090927124 and batch: 600, loss is 3.922865586280823 and perplexity is 50.54507873273418
At time: 274.1047351360321 and batch: 650, loss is 3.96664183139801 and perplexity is 52.806898278798066
At time: 275.0063467025757 and batch: 700, loss is 3.9854366540908814 and perplexity is 53.80878017285029
At time: 275.9015996456146 and batch: 750, loss is 3.960299015045166 and perplexity is 52.47301382412545
At time: 276.7974693775177 and batch: 800, loss is 3.9268796920776365 and perplexity is 50.74837978926723
At time: 277.69282150268555 and batch: 850, loss is 3.9255363941192627 and perplexity is 50.68025536025266
At time: 278.58975887298584 and batch: 900, loss is 3.8918139028549192 and perplexity is 48.99968663347237
At time: 279.48591804504395 and batch: 950, loss is 3.980657486915588 and perplexity is 53.55223254720617
At time: 280.37990856170654 and batch: 1000, loss is 3.9451372051239013 and perplexity is 51.683428856912606
At time: 281.27533078193665 and batch: 1050, loss is 3.8942725086212158 and perplexity is 49.12030576225964
At time: 282.20618748664856 and batch: 1100, loss is 3.9113009691238405 and perplexity is 49.96391121505904
At time: 283.11526012420654 and batch: 1150, loss is 3.8752242660522462 and perplexity is 48.19350524640244
At time: 284.0448796749115 and batch: 1200, loss is 3.9399606704711916 and perplexity is 51.41657907093271
At time: 284.9403910636902 and batch: 1250, loss is 3.9219312334060668 and perplexity is 50.49787384955884
At time: 285.83603405952454 and batch: 1300, loss is 3.913597831726074 and perplexity is 50.078803349403366
At time: 286.7321560382843 and batch: 1350, loss is 3.798466892242432 and perplexity is 44.6327052670111
At time: 287.62767481803894 and batch: 1400, loss is 3.8189073848724364 and perplexity is 45.55440768437557
At time: 288.52442479133606 and batch: 1450, loss is 3.7314430618286134 and perplexity is 41.73929711181305
At time: 289.4209244251251 and batch: 1500, loss is 3.751406183242798 and perplexity is 42.5809164923076
At time: 290.3169734477997 and batch: 1550, loss is 3.7527503681182863 and perplexity is 42.63819160178506
At time: 291.21247005462646 and batch: 1600, loss is 3.8367150831222534 and perplexity is 46.37289286964914
At time: 292.1098618507385 and batch: 1650, loss is 3.7876906394958496 and perplexity is 44.15431421525846
At time: 293.00703978538513 and batch: 1700, loss is 3.8033882904052736 and perplexity is 44.85290197411662
At time: 293.91825461387634 and batch: 1750, loss is 3.7858351945877073 and perplexity is 44.07246427528432
At time: 294.82327461242676 and batch: 1800, loss is 3.7500195932388305 and perplexity is 42.52191513393961
At time: 295.7197861671448 and batch: 1850, loss is 3.771820459365845 and perplexity is 43.459108407148165
At time: 296.61614513397217 and batch: 1900, loss is 3.8368796634674074 and perplexity is 46.38052556444196
At time: 297.51331615448 and batch: 1950, loss is 3.769111671447754 and perplexity is 43.34154619679609
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.279830577761628 and perplexity of 72.22820190701081
finished 8 epochs...
Completing Train Step...
At time: 300.47300696372986 and batch: 50, loss is 3.9227578163146974 and perplexity is 50.53963178482532
At time: 301.3910143375397 and batch: 100, loss is 3.9028022813797 and perplexity is 49.54108282339158
At time: 302.28638339042664 and batch: 150, loss is 3.8826389932632446 and perplexity is 48.55217501715138
At time: 303.1873924732208 and batch: 200, loss is 3.871285753250122 and perplexity is 48.004067804782316
At time: 304.0982894897461 and batch: 250, loss is 3.860881290435791 and perplexity is 47.50720056698679
At time: 304.99400997161865 and batch: 300, loss is 3.872952084541321 and perplexity is 48.08412516759028
At time: 305.8886516094208 and batch: 350, loss is 3.884709939956665 and perplexity is 48.65282817114613
At time: 306.7843339443207 and batch: 400, loss is 3.8479973602294923 and perplexity is 46.89904722573137
At time: 307.68159103393555 and batch: 450, loss is 3.8800497531890867 and perplexity is 48.42662439040915
At time: 308.57752084732056 and batch: 500, loss is 3.8935756206512453 and perplexity is 49.08608633703044
At time: 309.4939877986908 and batch: 550, loss is 3.847287168502808 and perplexity is 46.86575173489278
At time: 310.3875856399536 and batch: 600, loss is 3.8420297002792356 and perplexity is 46.62000310823124
At time: 311.28110694885254 and batch: 650, loss is 3.891329221725464 and perplexity is 48.9759431644824
At time: 312.1756446361542 and batch: 700, loss is 3.9117827558517457 and perplexity is 49.987988964060904
At time: 313.07074069976807 and batch: 750, loss is 3.8883156633377074 and perplexity is 48.8285734652859
At time: 313.9668536186218 and batch: 800, loss is 3.8568712425231935 and perplexity is 47.31707587585489
At time: 314.88389921188354 and batch: 850, loss is 3.8578680849075315 and perplexity is 47.364267059769226
At time: 315.7778310775757 and batch: 900, loss is 3.8247776794433594 and perplexity is 45.822611925235535
At time: 316.6714427471161 and batch: 950, loss is 3.917152509689331 and perplexity is 50.257134134573526
At time: 317.5669810771942 and batch: 1000, loss is 3.8850964307785034 and perplexity is 48.671635676920836
At time: 318.46301555633545 and batch: 1050, loss is 3.838172278404236 and perplexity is 46.44051648879395
At time: 319.3585102558136 and batch: 1100, loss is 3.856154179573059 and perplexity is 47.28315871565839
At time: 320.2524833679199 and batch: 1150, loss is 3.8227170658111573 and perplexity is 45.728286444002045
At time: 321.1494426727295 and batch: 1200, loss is 3.8891963577270507 and perplexity is 48.8715954578094
At time: 322.04615807533264 and batch: 1250, loss is 3.8758003330230713 and perplexity is 48.2212759311023
At time: 322.9414005279541 and batch: 1300, loss is 3.871428370475769 and perplexity is 48.01091449996913
At time: 323.8363718986511 and batch: 1350, loss is 3.7559912538528444 and perplexity is 42.77660127251136
At time: 324.7318916320801 and batch: 1400, loss is 3.780475420951843 and perplexity is 43.836877752388915
At time: 325.6267592906952 and batch: 1450, loss is 3.6955306243896486 and perplexity is 40.26693353718131
At time: 326.5209307670593 and batch: 1500, loss is 3.7165478229522706 and perplexity is 41.122187716431156
At time: 327.4181749820709 and batch: 1550, loss is 3.721846203804016 and perplexity is 41.34064695747557
At time: 328.3138873577118 and batch: 1600, loss is 3.809979033470154 and perplexity is 45.14949222821856
At time: 329.20811128616333 and batch: 1650, loss is 3.761632242202759 and perplexity is 43.018585455240185
At time: 330.1019444465637 and batch: 1700, loss is 3.782819962501526 and perplexity is 43.93977571082245
At time: 330.995707988739 and batch: 1750, loss is 3.7693805265426636 and perplexity is 43.35320035888259
At time: 331.8908541202545 and batch: 1800, loss is 3.7355811405181885 and perplexity is 41.91237546665685
At time: 332.78659296035767 and batch: 1850, loss is 3.761419930458069 and perplexity is 43.00945307379831
At time: 333.682003736496 and batch: 1900, loss is 3.8285107707977293 and perplexity is 45.99399161063073
At time: 334.57818269729614 and batch: 1950, loss is 3.7644368839263915 and perplexity is 43.13940652560878
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.279353651889535 and perplexity of 72.19376262197238
finished 9 epochs...
Completing Train Step...
At time: 337.50740146636963 and batch: 50, loss is 3.8787239456176756 and perplexity is 48.36246254766138
At time: 338.4480149745941 and batch: 100, loss is 3.8562188053131106 and perplexity is 47.28621452352321
At time: 339.3449242115021 and batch: 150, loss is 3.8352404499053954 and perplexity is 46.30456025661493
At time: 340.24045181274414 and batch: 200, loss is 3.8240362358093263 and perplexity is 45.788649633447186
At time: 341.1365180015564 and batch: 250, loss is 3.814634771347046 and perplexity is 45.36018651741712
At time: 342.03194308280945 and batch: 300, loss is 3.827958917617798 and perplexity is 45.96861668236407
At time: 342.92686653137207 and batch: 350, loss is 3.8399281024932863 and perplexity is 46.52212949442637
At time: 343.8227126598358 and batch: 400, loss is 3.80430401802063 and perplexity is 44.89399382668378
At time: 344.7188322544098 and batch: 450, loss is 3.838160557746887 and perplexity is 46.439972178602936
At time: 345.6148135662079 and batch: 500, loss is 3.8542922639846804 and perplexity is 47.19520337349902
At time: 346.5406084060669 and batch: 550, loss is 3.8063582944869996 and perplexity is 44.98631329407183
At time: 347.46558237075806 and batch: 600, loss is 3.8026869010925295 and perplexity is 44.821453658072045
At time: 348.3645157814026 and batch: 650, loss is 3.8532786893844606 and perplexity is 47.147391748524974
At time: 349.2600269317627 and batch: 700, loss is 3.8737211513519285 and perplexity is 48.121119296028574
At time: 350.15688729286194 and batch: 750, loss is 3.850513834953308 and perplexity is 47.01721611479708
At time: 351.053692817688 and batch: 800, loss is 3.819891037940979 and perplexity is 45.599239463123475
At time: 351.94989585876465 and batch: 850, loss is 3.8221036195755005 and perplexity is 45.70024320121022
At time: 352.84546542167664 and batch: 900, loss is 3.7893729543685915 and perplexity is 44.22865819221364
At time: 353.74382877349854 and batch: 950, loss is 3.883242406845093 and perplexity is 48.58148089987962
At time: 354.65127658843994 and batch: 1000, loss is 3.8522441244125365 and perplexity is 47.098639931313926
At time: 355.5477776527405 and batch: 1050, loss is 3.807140965461731 and perplexity is 45.02153655806238
At time: 356.4447009563446 and batch: 1100, loss is 3.825673666000366 and perplexity is 45.86368676803309
At time: 357.34225058555603 and batch: 1150, loss is 3.7925953388214113 and perplexity is 44.37140980951254
At time: 358.23923230171204 and batch: 1200, loss is 3.8594112539291383 and perplexity is 47.43741455438488
At time: 359.16060733795166 and batch: 1250, loss is 3.8484593629837036 and perplexity is 46.92071972071024
At time: 360.0564692020416 and batch: 1300, loss is 3.845241861343384 and perplexity is 46.769994836853684
At time: 360.95264530181885 and batch: 1350, loss is 3.729538011550903 and perplexity is 41.65985734465934
At time: 361.8493278026581 and batch: 1400, loss is 3.756412959098816 and perplexity is 42.794644193802704
At time: 362.74559688568115 and batch: 1450, loss is 3.6719636964797973 and perplexity is 39.32906041894231
At time: 363.6425940990448 and batch: 1500, loss is 3.6926376104354857 and perplexity is 40.150609081834894
At time: 364.540244102478 and batch: 1550, loss is 3.699130878448486 and perplexity is 40.412166008108784
At time: 365.4467658996582 and batch: 1600, loss is 3.7894956731796263 and perplexity is 44.23408621361401
At time: 366.3592324256897 and batch: 1650, loss is 3.741277508735657 and perplexity is 42.15180508238086
At time: 367.25640177726746 and batch: 1700, loss is 3.764954571723938 and perplexity is 43.16174505165276
At time: 368.1749551296234 and batch: 1750, loss is 3.7525686836242675 and perplexity is 42.63044560720287
At time: 369.0710959434509 and batch: 1800, loss is 3.719569721221924 and perplexity is 41.24664273482927
At time: 369.969722032547 and batch: 1850, loss is 3.7464148712158205 and perplexity is 42.36891138366763
At time: 370.8662369251251 and batch: 1900, loss is 3.814151153564453 and perplexity is 45.33825482830044
At time: 371.7628843784332 and batch: 1950, loss is 3.7514199590682984 and perplexity is 42.58150308362322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2823741824127906 and perplexity of 72.41215575107263
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 374.7213969230652 and batch: 50, loss is 3.868185863494873 and perplexity is 47.855490891786076
At time: 375.6157600879669 and batch: 100, loss is 3.869322171211243 and perplexity is 47.90990036245333
At time: 376.51242113113403 and batch: 150, loss is 3.8552318525314333 and perplexity is 47.239568285168
At time: 377.40717482566833 and batch: 200, loss is 3.8462200450897215 and perplexity is 46.81576686869846
At time: 378.3035433292389 and batch: 250, loss is 3.842050714492798 and perplexity is 46.620982801226525
At time: 379.1996042728424 and batch: 300, loss is 3.8495831155776976 and perplexity is 46.9734766385182
At time: 380.0947117805481 and batch: 350, loss is 3.862334589958191 and perplexity is 47.5762929526862
At time: 380.99025869369507 and batch: 400, loss is 3.8290177059173582 and perplexity is 46.01731349111077
At time: 381.91086864471436 and batch: 450, loss is 3.8631420278549196 and perplexity is 47.61472336760085
At time: 382.8062596321106 and batch: 500, loss is 3.877706985473633 and perplexity is 48.31330485072853
At time: 383.7013189792633 and batch: 550, loss is 3.828993582725525 and perplexity is 46.016203420019046
At time: 384.5954170227051 and batch: 600, loss is 3.818132610321045 and perplexity is 45.51912695766746
At time: 385.4905264377594 and batch: 650, loss is 3.8606628513336183 and perplexity is 47.49682427008395
At time: 386.3861770629883 and batch: 700, loss is 3.874614129066467 and perplexity is 48.16410957498236
At time: 387.28264236450195 and batch: 750, loss is 3.849286298751831 and perplexity is 46.95953618926473
At time: 388.17997336387634 and batch: 800, loss is 3.811760368347168 and perplexity is 45.229990269101975
At time: 389.07696199417114 and batch: 850, loss is 3.815632519721985 and perplexity is 45.40546715538685
At time: 389.9742558002472 and batch: 900, loss is 3.7780207204818725 and perplexity is 43.72940331071541
At time: 390.8719871044159 and batch: 950, loss is 3.8768057346343996 and perplexity is 48.26978205960765
At time: 391.76830649375916 and batch: 1000, loss is 3.839197759628296 and perplexity is 46.48816479353417
At time: 392.6840856075287 and batch: 1050, loss is 3.7933456659317017 and perplexity is 44.404715374686106
At time: 393.6207354068756 and batch: 1100, loss is 3.806819338798523 and perplexity is 45.007058759834486
At time: 394.5186324119568 and batch: 1150, loss is 3.7771818923950193 and perplexity is 43.692737239412224
At time: 395.41598296165466 and batch: 1200, loss is 3.8372312641143798 and perplexity is 46.396835854423564
At time: 396.3127381801605 and batch: 1250, loss is 3.8238379430770872 and perplexity is 45.779570977151366
At time: 397.21069836616516 and batch: 1300, loss is 3.816383948326111 and perplexity is 45.439598944386375
At time: 398.10829401016235 and batch: 1350, loss is 3.6978288555145262 and perplexity is 40.35958268093274
At time: 399.0058903694153 and batch: 1400, loss is 3.720483922958374 and perplexity is 41.28436772874023
At time: 399.92222905158997 and batch: 1450, loss is 3.626404128074646 and perplexity is 37.57744968561758
At time: 400.82609510421753 and batch: 1500, loss is 3.6534206008911134 and perplexity is 38.606497869484386
At time: 401.7228214740753 and batch: 1550, loss is 3.6596001482009886 and perplexity is 38.84580719966348
At time: 402.6187880039215 and batch: 1600, loss is 3.7500940799713134 and perplexity is 42.52508257042138
At time: 403.51240587234497 and batch: 1650, loss is 3.6976562452316286 and perplexity is 40.35261680315692
At time: 404.40648555755615 and batch: 1700, loss is 3.715854911804199 and perplexity is 41.09370356376248
At time: 405.30220460891724 and batch: 1750, loss is 3.6969746351242065 and perplexity is 40.32512142331187
At time: 406.1967248916626 and batch: 1800, loss is 3.6643744993209837 and perplexity is 39.031714162194916
At time: 407.09265327453613 and batch: 1850, loss is 3.6822865533828737 and perplexity is 39.73715139024144
At time: 407.989937543869 and batch: 1900, loss is 3.74725576877594 and perplexity is 42.40455428178782
At time: 408.8866853713989 and batch: 1950, loss is 3.692099003791809 and perplexity is 40.12898951977827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258540379723837 and perplexity of 70.70670316001426
finished 11 epochs...
Completing Train Step...
At time: 411.87694907188416 and batch: 50, loss is 3.857295079231262 and perplexity is 47.337134840091956
At time: 412.77321910858154 and batch: 100, loss is 3.8413500928878785 and perplexity is 46.58833057319729
At time: 413.6704123020172 and batch: 150, loss is 3.8213682079315188 and perplexity is 45.666647065236205
At time: 414.5724935531616 and batch: 200, loss is 3.809012475013733 and perplexity is 45.105873688032524
At time: 415.4702892303467 and batch: 250, loss is 3.8028837299346923 and perplexity is 44.83027668118384
At time: 416.36901688575745 and batch: 300, loss is 3.809235701560974 and perplexity is 45.115943640374724
At time: 417.26553082466125 and batch: 350, loss is 3.8218578100204468 and perplexity is 45.68901102530772
At time: 418.1628828048706 and batch: 400, loss is 3.7914694786071776 and perplexity is 44.32148191574703
At time: 419.06078481674194 and batch: 450, loss is 3.8266056299209597 and perplexity is 45.90644999316258
At time: 419.9573976993561 and batch: 500, loss is 3.841343812942505 and perplexity is 46.588038001944916
At time: 420.85464549064636 and batch: 550, loss is 3.793809895515442 and perplexity is 44.425334142771355
At time: 421.7517783641815 and batch: 600, loss is 3.785958113670349 and perplexity is 44.0778819551241
At time: 422.64762783050537 and batch: 650, loss is 3.8298406744003297 and perplexity is 46.055199877297554
At time: 423.5436267852783 and batch: 700, loss is 3.8466584491729736 and perplexity is 46.836295591663465
At time: 424.4404876232147 and batch: 750, loss is 3.8226897144317626 and perplexity is 45.727035729394906
At time: 425.33692264556885 and batch: 800, loss is 3.786959466934204 and perplexity is 44.122041592092046
At time: 426.25763416290283 and batch: 850, loss is 3.7920465517044066 and perplexity is 44.3470660318325
At time: 427.15563440322876 and batch: 900, loss is 3.7551039171218874 and perplexity is 42.73866085842768
At time: 428.06834959983826 and batch: 950, loss is 3.8546702575683596 and perplexity is 47.21304622958475
At time: 428.9646294116974 and batch: 1000, loss is 3.8188889741897585 and perplexity is 45.55356900435147
At time: 429.8616006374359 and batch: 1050, loss is 3.7745574855804445 and perplexity is 43.57822005761801
At time: 430.7577061653137 and batch: 1100, loss is 3.788982014656067 and perplexity is 44.21137083267249
At time: 431.65334010124207 and batch: 1150, loss is 3.7604447698593138 and perplexity is 42.96753239280692
At time: 432.55088925361633 and batch: 1200, loss is 3.821533513069153 and perplexity is 45.674196620587566
At time: 433.44719791412354 and batch: 1250, loss is 3.8106494522094727 and perplexity is 45.179771442621345
At time: 434.34376525878906 and batch: 1300, loss is 3.8040137672424317 and perplexity is 44.88096520091501
At time: 435.2416272163391 and batch: 1350, loss is 3.6866948127746584 and perplexity is 39.912709730112155
At time: 436.1386125087738 and batch: 1400, loss is 3.7114144563674927 and perplexity is 40.91163334088013
At time: 437.0338454246521 and batch: 1450, loss is 3.6199572896957397 and perplexity is 37.335973157226185
At time: 437.9306147098541 and batch: 1500, loss is 3.6473494815826415 and perplexity is 38.372823265776354
At time: 438.82753252983093 and batch: 1550, loss is 3.655608196258545 and perplexity is 38.691045709890936
At time: 439.756334066391 and batch: 1600, loss is 3.7476290035247803 and perplexity is 42.42038408888815
At time: 440.66111493110657 and batch: 1650, loss is 3.696171226501465 and perplexity is 40.29273688379835
At time: 441.5829164981842 and batch: 1700, loss is 3.716134533882141 and perplexity is 41.105195877220716
At time: 442.4795935153961 and batch: 1750, loss is 3.698412437438965 and perplexity is 40.383142677788726
At time: 443.37660789489746 and batch: 1800, loss is 3.6680574512481687 and perplexity is 39.17573113008587
At time: 444.27464294433594 and batch: 1850, loss is 3.6865136289596556 and perplexity is 39.90547884817532
At time: 445.17128920555115 and batch: 1900, loss is 3.75205246925354 and perplexity is 42.608444837595194
At time: 446.06796956062317 and batch: 1950, loss is 3.6971588468551637 and perplexity is 40.3325504679679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257468999818314 and perplexity of 70.63098998509221
finished 12 epochs...
Completing Train Step...
At time: 449.0340871810913 and batch: 50, loss is 3.8431580591201784 and perplexity is 46.672636890215394
At time: 449.93162751197815 and batch: 100, loss is 3.8262081146240234 and perplexity is 45.88820510361386
At time: 450.82852697372437 and batch: 150, loss is 3.805271277427673 and perplexity is 44.93743897250813
At time: 451.726389169693 and batch: 200, loss is 3.792234354019165 and perplexity is 44.35539529558905
At time: 452.62351846694946 and batch: 250, loss is 3.7857980585098265 and perplexity is 44.070827627208125
At time: 453.52139806747437 and batch: 300, loss is 3.7922630310058594 and perplexity is 44.35666729290819
At time: 454.44460940361023 and batch: 350, loss is 3.8043139696121218 and perplexity is 44.89444059559381
At time: 455.34205746650696 and batch: 400, loss is 3.774211115837097 and perplexity is 43.56312849450242
At time: 456.23863649368286 and batch: 450, loss is 3.8098213291168213 and perplexity is 45.1423725181628
At time: 457.1358742713928 and batch: 500, loss is 3.824680414199829 and perplexity is 45.81815519447344
At time: 458.03389048576355 and batch: 550, loss is 3.7774766445159913 and perplexity is 43.70561766455767
At time: 458.9325613975525 and batch: 600, loss is 3.7706906175613404 and perplexity is 43.410034217938964
At time: 459.85292172431946 and batch: 650, loss is 3.815202178955078 and perplexity is 45.38593153561773
At time: 460.75041699409485 and batch: 700, loss is 3.832897844314575 and perplexity is 46.19621389082703
At time: 461.6469235420227 and batch: 750, loss is 3.809084177017212 and perplexity is 45.109107985496046
At time: 462.5439176559448 and batch: 800, loss is 3.773926615715027 and perplexity is 43.55073654196757
At time: 463.4438452720642 and batch: 850, loss is 3.7795643329620363 and perplexity is 43.79695668812066
At time: 464.34195351600647 and batch: 900, loss is 3.743134870529175 and perplexity is 42.23016898720183
At time: 465.238543510437 and batch: 950, loss is 3.8429794311523438 and perplexity is 46.66430059650398
At time: 466.1352505683899 and batch: 1000, loss is 3.807793068885803 and perplexity is 45.050904830743754
At time: 467.0321955680847 and batch: 1050, loss is 3.764293975830078 and perplexity is 43.13324199563722
At time: 467.92859387397766 and batch: 1100, loss is 3.7790059995651246 and perplexity is 43.772510209796295
At time: 468.8242919445038 and batch: 1150, loss is 3.7507933044433592 and perplexity is 42.55482754682621
At time: 469.7212405204773 and batch: 1200, loss is 3.8120749759674073 and perplexity is 45.24422220732471
At time: 470.61710262298584 and batch: 1250, loss is 3.8022489738464356 and perplexity is 44.80182941961362
At time: 471.51240706443787 and batch: 1300, loss is 3.7965560436248778 and perplexity is 44.547500356622564
At time: 472.40807723999023 and batch: 1350, loss is 3.6794924402236937 and perplexity is 39.62627626359297
At time: 473.30515003204346 and batch: 1400, loss is 3.704964027404785 and perplexity is 40.648585055482
At time: 474.2105326652527 and batch: 1450, loss is 3.6144780111312866 and perplexity is 37.13195839709288
At time: 475.13074350357056 and batch: 1500, loss is 3.6418784475326538 and perplexity is 38.16345748897353
At time: 476.03787446022034 and batch: 1550, loss is 3.6510301446914672 and perplexity is 38.51432094365129
At time: 476.9345669746399 and batch: 1600, loss is 3.7436765813827515 and perplexity is 42.25305172544482
At time: 477.8318943977356 and batch: 1650, loss is 3.6925479221343993 and perplexity is 40.14700820339951
At time: 478.7274487018585 and batch: 1700, loss is 3.713453269004822 and perplexity is 40.995129583623935
At time: 479.6230435371399 and batch: 1750, loss is 3.6961862993240358 and perplexity is 40.29334421364937
At time: 480.5189878940582 and batch: 1800, loss is 3.666823596954346 and perplexity is 39.12742379425281
At time: 481.41588735580444 and batch: 1850, loss is 3.685478477478027 and perplexity is 39.86419200537549
At time: 482.31050658226013 and batch: 1900, loss is 3.7513829278945923 and perplexity is 42.57992626978168
At time: 483.2062678337097 and batch: 1950, loss is 3.6963805770874023 and perplexity is 40.30117307490396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257860760356104 and perplexity of 70.65866584051348
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 486.1553068161011 and batch: 50, loss is 3.8405127477645875 and perplexity is 46.54933638986257
At time: 487.1005976200104 and batch: 100, loss is 3.836854033470154 and perplexity is 46.37933684693261
At time: 487.9987726211548 and batch: 150, loss is 3.821877007484436 and perplexity is 45.689888146870814
At time: 488.89488697052 and batch: 200, loss is 3.8147807502746582 and perplexity is 45.36680863213406
At time: 489.7904222011566 and batch: 250, loss is 3.8082444047927857 and perplexity is 45.07124251095336
At time: 490.68835067749023 and batch: 300, loss is 3.8112027406692506 and perplexity is 45.20477580545077
At time: 491.590678691864 and batch: 350, loss is 3.8298030710220337 and perplexity is 46.05346807875501
At time: 492.489369392395 and batch: 400, loss is 3.7978709363937377 and perplexity is 44.606114069640995
At time: 493.38593196868896 and batch: 450, loss is 3.8340102529525755 and perplexity is 46.24763155162486
At time: 494.306391954422 and batch: 500, loss is 3.8420686531066894 and perplexity is 46.62181912453747
At time: 495.20412516593933 and batch: 550, loss is 3.79889271736145 and perplexity is 44.651715041175954
At time: 496.1018166542053 and batch: 600, loss is 3.789278645515442 and perplexity is 44.224487234865386
At time: 496.9995701313019 and batch: 650, loss is 3.827992043495178 and perplexity is 45.97013945834514
At time: 497.8981566429138 and batch: 700, loss is 3.846244330406189 and perplexity is 46.81690381821807
At time: 498.79570984840393 and batch: 750, loss is 3.8193644762039183 and perplexity is 45.575234968861864
At time: 499.69314193725586 and batch: 800, loss is 3.7810947704315185 and perplexity is 43.86403650932828
At time: 500.59152364730835 and batch: 850, loss is 3.786478114128113 and perplexity is 44.100808434291245
At time: 501.4901821613312 and batch: 900, loss is 3.748618721961975 and perplexity is 42.46238910827607
At time: 502.3889248371124 and batch: 950, loss is 3.84919105052948 and perplexity is 46.95506358992722
At time: 503.28789591789246 and batch: 1000, loss is 3.811106948852539 and perplexity is 45.20044576524684
At time: 504.185923576355 and batch: 1050, loss is 3.767581748962402 and perplexity is 43.275287688834354
At time: 505.0846393108368 and batch: 1100, loss is 3.7752315044403075 and perplexity is 43.60760250086419
At time: 505.98328924179077 and batch: 1150, loss is 3.753683953285217 and perplexity is 42.678016572117464
At time: 506.8813145160675 and batch: 1200, loss is 3.8124207925796507 and perplexity is 45.259871116642486
At time: 507.7796096801758 and batch: 1250, loss is 3.803114194869995 and perplexity is 44.84060967864984
At time: 508.67768907546997 and batch: 1300, loss is 3.795513381958008 and perplexity is 44.50107659199153
At time: 509.57546639442444 and batch: 1350, loss is 3.6724392986297607 and perplexity is 39.347769853404564
At time: 510.47443652153015 and batch: 1400, loss is 3.697149467468262 and perplexity is 40.332172175146404
At time: 511.37295174598694 and batch: 1450, loss is 3.6000134897232057 and perplexity is 36.598728147060406
At time: 512.2713670730591 and batch: 1500, loss is 3.627704839706421 and perplexity is 37.626358913021
At time: 513.1689507961273 and batch: 1550, loss is 3.6371636056900023 and perplexity is 37.983946338626005
At time: 514.0744857788086 and batch: 1600, loss is 3.7320188760757445 and perplexity is 41.76333811466699
At time: 514.970561504364 and batch: 1650, loss is 3.6800437641143797 and perplexity is 39.64812919986541
At time: 515.8667604923248 and batch: 1700, loss is 3.697401008605957 and perplexity is 40.34231865169568
At time: 516.7631957530975 and batch: 1750, loss is 3.6805381774902344 and perplexity is 39.66773661195343
At time: 517.6589357852936 and batch: 1800, loss is 3.6506704568862913 and perplexity is 38.50047030318579
At time: 518.5549945831299 and batch: 1850, loss is 3.665754189491272 and perplexity is 39.085603000956255
At time: 519.4591019153595 and batch: 1900, loss is 3.73144446849823 and perplexity is 41.73935582525542
At time: 520.370391368866 and batch: 1950, loss is 3.6810369729995727 and perplexity is 39.68752763626778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247676689680232 and perplexity of 69.94272477874316
finished 14 epochs...
Completing Train Step...
At time: 523.3431959152222 and batch: 50, loss is 3.8404548263549803 and perplexity is 46.546640264765024
At time: 524.2638216018677 and batch: 100, loss is 3.827251753807068 and perplexity is 45.93612083151605
At time: 525.1614816188812 and batch: 150, loss is 3.8070947790145873 and perplexity is 45.01945722126277
At time: 526.0596261024475 and batch: 200, loss is 3.7983316802978515 and perplexity is 44.62667080011526
At time: 526.976970911026 and batch: 250, loss is 3.7918423938751222 and perplexity is 44.338013155235565
At time: 527.8880703449249 and batch: 300, loss is 3.794273257255554 and perplexity is 44.44592391279227
At time: 528.7849645614624 and batch: 350, loss is 3.8107044982910154 and perplexity is 45.18225848045447
At time: 529.6823406219482 and batch: 400, loss is 3.7800294971466064 and perplexity is 43.81733420284271
At time: 530.5784521102905 and batch: 450, loss is 3.816524877548218 and perplexity is 45.44600316297863
At time: 531.4754347801208 and batch: 500, loss is 3.825896100997925 and perplexity is 45.873889591777846
At time: 532.3730411529541 and batch: 550, loss is 3.7828597259521484 and perplexity is 43.94152294266205
At time: 533.2698709964752 and batch: 600, loss is 3.77444363117218 and perplexity is 43.57325876759787
At time: 534.1676993370056 and batch: 650, loss is 3.8140155363082884 and perplexity is 45.33210659549399
At time: 535.0661821365356 and batch: 700, loss is 3.8335179805755617 and perplexity is 46.224870722832975
At time: 535.9618446826935 and batch: 750, loss is 3.807946844100952 and perplexity is 45.05783307600931
At time: 536.8746395111084 and batch: 800, loss is 3.771349883079529 and perplexity is 43.438662392389475
At time: 537.775876045227 and batch: 850, loss is 3.7774138498306273 and perplexity is 43.702873270215385
At time: 538.6730818748474 and batch: 900, loss is 3.7393293142318726 and perplexity is 42.06976510825642
At time: 539.6094744205475 and batch: 950, loss is 3.8407860946655275 and perplexity is 46.56206224591297
At time: 540.5068783760071 and batch: 1000, loss is 3.8031764793395997 and perplexity is 44.84340263921855
At time: 541.405811548233 and batch: 1050, loss is 3.760541138648987 and perplexity is 42.97167332142379
At time: 542.3031203746796 and batch: 1100, loss is 3.7687011194229125 and perplexity is 43.32375588941848
At time: 543.1997582912445 and batch: 1150, loss is 3.7471155977249144 and perplexity is 42.39861080740713
At time: 544.0963003635406 and batch: 1200, loss is 3.806977710723877 and perplexity is 45.01418717884062
At time: 544.9936225414276 and batch: 1250, loss is 3.7983893728256226 and perplexity is 44.62924549982948
At time: 545.8909704685211 and batch: 1300, loss is 3.7914406490325927 and perplexity is 44.320204164697024
At time: 546.7886345386505 and batch: 1350, loss is 3.669320864677429 and perplexity is 39.22525755448366
At time: 547.6856248378754 and batch: 1400, loss is 3.6947294330596923 and perplexity is 40.23468493952087
At time: 548.5827581882477 and batch: 1450, loss is 3.5989595317840575 and perplexity is 36.560174947261416
At time: 549.4803237915039 and batch: 1500, loss is 3.627895860671997 and perplexity is 37.633547022949664
At time: 550.3787252902985 and batch: 1550, loss is 3.638269553184509 and perplexity is 38.02597782693615
At time: 551.2751312255859 and batch: 1600, loss is 3.7337811183929444 and perplexity is 41.837000122490764
At time: 552.1724319458008 and batch: 1650, loss is 3.682700791358948 and perplexity is 39.7536154371896
At time: 553.0689594745636 and batch: 1700, loss is 3.700826849937439 and perplexity is 40.480762041481775
At time: 553.9673361778259 and batch: 1750, loss is 3.6844978857040407 and perplexity is 39.82512066626605
At time: 554.8641631603241 and batch: 1800, loss is 3.655084071159363 and perplexity is 38.6707720751453
At time: 555.7624151706696 and batch: 1850, loss is 3.670066223144531 and perplexity is 39.25450533101102
At time: 556.6592328548431 and batch: 1900, loss is 3.735719199180603 and perplexity is 41.918162232599784
At time: 557.5571641921997 and batch: 1950, loss is 3.6847915649414062 and perplexity is 39.836818194907885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246679971384448 and perplexity of 69.87304631596699
finished 15 epochs...
Completing Train Step...
At time: 560.5092062950134 and batch: 50, loss is 3.836878046989441 and perplexity is 46.3804505914049
At time: 561.4310419559479 and batch: 100, loss is 3.8221998691558836 and perplexity is 45.704642042131645
At time: 562.3283107280731 and batch: 150, loss is 3.8013581228256226 and perplexity is 44.761935436577
At time: 563.2245671749115 and batch: 200, loss is 3.792233443260193 and perplexity is 44.355354898533214
At time: 564.1212711334229 and batch: 250, loss is 3.7852669095993043 and perplexity is 44.04742567064017
At time: 565.0176920890808 and batch: 300, loss is 3.7876034688949587 and perplexity is 44.150465424909505
At time: 565.9138400554657 and batch: 350, loss is 3.8037009716033934 and perplexity is 44.866928826097194
At time: 566.8104794025421 and batch: 400, loss is 3.772950768470764 and perplexity is 43.508258405184755
At time: 567.7078938484192 and batch: 450, loss is 3.8093570613861085 and perplexity is 45.121419235657626
At time: 568.6056652069092 and batch: 500, loss is 3.8190015172958374 and perplexity is 45.55869603300065
At time: 569.5037021636963 and batch: 550, loss is 3.7760854816436766 and perplexity is 43.644858304833
At time: 570.4011473655701 and batch: 600, loss is 3.7680960655212403 and perplexity is 43.29755061048508
At time: 571.297313451767 and batch: 650, loss is 3.807820887565613 and perplexity is 45.052158104872525
At time: 572.194046497345 and batch: 700, loss is 3.827850422859192 and perplexity is 45.96362959893476
At time: 573.0922019481659 and batch: 750, loss is 3.8024890756607057 and perplexity is 44.812587711630925
At time: 573.9886922836304 and batch: 800, loss is 3.766415629386902 and perplexity is 43.224852940913664
At time: 574.8855879306793 and batch: 850, loss is 3.772605595588684 and perplexity is 43.49324312581946
At time: 575.7826669216156 and batch: 900, loss is 3.7347979307174684 and perplexity is 41.879562134958746
At time: 576.679797410965 and batch: 950, loss is 3.836576681137085 and perplexity is 46.36647521333641
At time: 577.576117515564 and batch: 1000, loss is 3.799319486618042 and perplexity is 44.67077508724118
At time: 578.4714531898499 and batch: 1050, loss is 3.7570802688598635 and perplexity is 42.823211007990686
At time: 579.3675887584686 and batch: 1100, loss is 3.7654900312423707 and perplexity is 43.18486260757817
At time: 580.2642984390259 and batch: 1150, loss is 3.744021692276001 and perplexity is 42.267636230359315
At time: 581.1619095802307 and batch: 1200, loss is 3.8041321516036986 and perplexity is 44.886278719825924
At time: 582.0578203201294 and batch: 1250, loss is 3.795890440940857 and perplexity is 44.517859286501015
At time: 582.9556357860565 and batch: 1300, loss is 3.7893454790115357 and perplexity is 44.22744301073157
At time: 583.8527145385742 and batch: 1350, loss is 3.667644290924072 and perplexity is 39.15954861553212
At time: 584.7499306201935 and batch: 1400, loss is 3.6932649850845336 and perplexity is 40.17580645938815
At time: 585.6465904712677 and batch: 1450, loss is 3.598147807121277 and perplexity is 36.530510193016305
At time: 586.5554752349854 and batch: 1500, loss is 3.6275108098983764 and perplexity is 37.61905898604831
At time: 587.4635891914368 and batch: 1550, loss is 3.638284239768982 and perplexity is 38.02653630277271
At time: 588.3599359989166 and batch: 1600, loss is 3.734024920463562 and perplexity is 41.847201313234244
At time: 589.25763630867 and batch: 1650, loss is 3.683227162361145 and perplexity is 39.774546095750836
At time: 590.1540775299072 and batch: 1700, loss is 3.7016351556777956 and perplexity is 40.51349610159601
At time: 591.0537595748901 and batch: 1750, loss is 3.6855364084243774 and perplexity is 39.866501442637144
At time: 591.9504451751709 and batch: 1800, loss is 3.656421575546265 and perplexity is 38.722529007286845
At time: 592.8461818695068 and batch: 1850, loss is 3.6713351583480835 and perplexity is 39.30434837183006
At time: 593.7404201030731 and batch: 1900, loss is 3.7369432258605957 and perplexity is 41.96950259612608
At time: 594.6410584449768 and batch: 1950, loss is 3.6857548713684083 and perplexity is 39.87521174731528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246441792332849 and perplexity of 69.85640600182892
finished 16 epochs...
Completing Train Step...
At time: 597.6330981254578 and batch: 50, loss is 3.833090109825134 and perplexity is 46.20509668337661
At time: 598.5306615829468 and batch: 100, loss is 3.8177839946746825 and perplexity is 45.5032610435149
At time: 599.4289920330048 and batch: 150, loss is 3.7966704177856445 and perplexity is 44.55259573097414
At time: 600.3270320892334 and batch: 200, loss is 3.787345724105835 and perplexity is 44.139087338893034
At time: 601.2249586582184 and batch: 250, loss is 3.780195074081421 and perplexity is 43.82458994340683
At time: 602.1229796409607 and batch: 300, loss is 3.782488532066345 and perplexity is 43.925215144877505
At time: 603.0220770835876 and batch: 350, loss is 3.798523049354553 and perplexity is 44.635211781223695
At time: 603.9206788539886 and batch: 400, loss is 3.767773299217224 and perplexity is 43.28357787518694
At time: 604.818615436554 and batch: 450, loss is 3.80420795917511 and perplexity is 44.88968156858459
At time: 605.716629743576 and batch: 500, loss is 3.8140470218658447 and perplexity is 45.33353392461536
At time: 606.6659827232361 and batch: 550, loss is 3.771235933303833 and perplexity is 43.4337128485584
At time: 607.5644927024841 and batch: 600, loss is 3.763544282913208 and perplexity is 43.10091742789516
At time: 608.4613461494446 and batch: 650, loss is 3.803370532989502 and perplexity is 44.8521055095593
At time: 609.3588619232178 and batch: 700, loss is 3.8237204217910765 and perplexity is 45.774191219221336
At time: 610.2555022239685 and batch: 750, loss is 3.798442912101746 and perplexity is 44.63163498129244
At time: 611.1519763469696 and batch: 800, loss is 3.7626721906661986 and perplexity is 43.06334583729498
At time: 612.0486931800842 and batch: 850, loss is 3.768957424163818 and perplexity is 43.33486139658305
At time: 612.9466030597687 and batch: 900, loss is 3.731405563354492 and perplexity is 41.73773198120565
At time: 613.8436107635498 and batch: 950, loss is 3.8333688402175903 and perplexity is 46.21797724312698
At time: 614.7399303913116 and batch: 1000, loss is 3.796346673965454 and perplexity is 44.53817443796099
At time: 615.636944770813 and batch: 1050, loss is 3.754375448226929 and perplexity is 42.70753841062402
At time: 616.5336172580719 and batch: 1100, loss is 3.7629086542129517 and perplexity is 43.07352995282531
At time: 617.4303925037384 and batch: 1150, loss is 3.741558337211609 and perplexity is 42.16364417185969
At time: 618.3268620967865 and batch: 1200, loss is 3.8017469310760497 and perplexity is 44.77934263019078
At time: 619.224287033081 and batch: 1250, loss is 3.7937377309799194 and perplexity is 44.42212832484209
At time: 620.1210281848907 and batch: 1300, loss is 3.7875068521499635 and perplexity is 44.14619995671128
At time: 621.0180623531342 and batch: 1350, loss is 3.66602135181427 and perplexity is 39.09604659645526
At time: 621.9135310649872 and batch: 1400, loss is 3.6917928743362425 and perplexity is 40.1167067342213
At time: 622.8086657524109 and batch: 1450, loss is 3.5971039962768554 and perplexity is 36.49239914414793
At time: 623.7047729492188 and batch: 1500, loss is 3.626639404296875 and perplexity is 37.586291806150186
At time: 624.6019332408905 and batch: 1550, loss is 3.637714638710022 and perplexity is 38.00488251502175
At time: 625.4991507530212 and batch: 1600, loss is 3.7335913467407225 and perplexity is 41.82906139914966
At time: 626.3949937820435 and batch: 1650, loss is 3.6829199457168578 and perplexity is 39.76232856998098
At time: 627.2914686203003 and batch: 1700, loss is 3.7014804029464723 and perplexity is 40.507227012510675
At time: 628.1879341602325 and batch: 1750, loss is 3.6855698251724243 and perplexity is 39.86783367373066
At time: 629.0843412876129 and batch: 1800, loss is 3.656689100265503 and perplexity is 38.732889626786836
At time: 629.9809005260468 and batch: 1850, loss is 3.671547169685364 and perplexity is 39.31268222269352
At time: 630.8777070045471 and batch: 1900, loss is 3.7372053337097166 and perplexity is 41.98050457396961
At time: 631.7739765644073 and batch: 1950, loss is 3.685826621055603 and perplexity is 39.87807288392657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246446902252907 and perplexity of 69.85676296339113
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 634.7566504478455 and batch: 50, loss is 3.83254150390625 and perplexity is 46.179755245720415
At time: 635.6539378166199 and batch: 100, loss is 3.821769800186157 and perplexity is 45.68499011996073
At time: 636.5516443252563 and batch: 150, loss is 3.8028273153305054 and perplexity is 44.827747670206534
At time: 637.4494729042053 and batch: 200, loss is 3.7950270986557006 and perplexity is 44.47944172227442
At time: 638.3462598323822 and batch: 250, loss is 3.7883480739593507 and perplexity is 44.183352327417765
At time: 639.2499721050262 and batch: 300, loss is 3.7891491651535034 and perplexity is 44.21876140295107
At time: 640.1649849414825 and batch: 350, loss is 3.808811626434326 and perplexity is 45.09681514710737
At time: 641.0626952648163 and batch: 400, loss is 3.779218235015869 and perplexity is 43.78180127414263
At time: 641.959778547287 and batch: 450, loss is 3.8169521379470823 and perplexity is 45.465424589124524
At time: 642.8578147888184 and batch: 500, loss is 3.8246133852005006 and perplexity is 45.815084152305275
At time: 643.754810333252 and batch: 550, loss is 3.7831246137619017 and perplexity is 43.95316405815828
At time: 644.6523857116699 and batch: 600, loss is 3.77320725440979 and perplexity is 43.51941909291573
At time: 645.5509376525879 and batch: 650, loss is 3.8109843015670775 and perplexity is 45.194902393218804
At time: 646.4483540058136 and batch: 700, loss is 3.8309623336791994 and perplexity is 46.106887101888596
At time: 647.3440639972687 and batch: 750, loss is 3.804586386680603 and perplexity is 44.906672273475245
At time: 648.2403724193573 and batch: 800, loss is 3.7673051881790163 and perplexity is 43.26332109619127
At time: 649.138391494751 and batch: 850, loss is 3.772471342086792 and perplexity is 43.48740439756481
At time: 650.0359115600586 and batch: 900, loss is 3.7336730051040647 and perplexity is 41.832477231307394
At time: 650.9573745727539 and batch: 950, loss is 3.8365207576751708 and perplexity is 46.3638823120284
At time: 651.8695442676544 and batch: 1000, loss is 3.7992237854003905 and perplexity is 44.666500244229006
At time: 652.7901744842529 and batch: 1050, loss is 3.7563494205474854 and perplexity is 42.79192517048824
At time: 653.7165982723236 and batch: 1100, loss is 3.7625191688537596 and perplexity is 43.05675671021821
At time: 654.6142463684082 and batch: 1150, loss is 3.743509168624878 and perplexity is 42.245978617607655
At time: 655.5124020576477 and batch: 1200, loss is 3.802434720993042 and perplexity is 44.81015200451533
At time: 656.4103729724884 and batch: 1250, loss is 3.7944586801528932 and perplexity is 44.45416596888843
At time: 657.3080728054047 and batch: 1300, loss is 3.786959071159363 and perplexity is 44.122024129701494
At time: 658.2059412002563 and batch: 1350, loss is 3.6638162517547608 and perplexity is 39.00993088355522
At time: 659.1034002304077 and batch: 1400, loss is 3.689563374519348 and perplexity is 40.02736617329194
At time: 660.0024371147156 and batch: 1450, loss is 3.591629662513733 and perplexity is 36.29317338310921
At time: 660.9008221626282 and batch: 1500, loss is 3.6191675424575807 and perplexity is 37.30649881571312
At time: 661.7980871200562 and batch: 1550, loss is 3.6291094970703126 and perplexity is 37.67924819210612
At time: 662.6962766647339 and batch: 1600, loss is 3.72543487071991 and perplexity is 41.48927129160368
At time: 663.593861579895 and batch: 1650, loss is 3.6733711194992065 and perplexity is 39.38445201446749
At time: 664.4908063411713 and batch: 1700, loss is 3.691600966453552 and perplexity is 40.10900876064596
At time: 665.3856358528137 and batch: 1750, loss is 3.6764302110671996 and perplexity is 39.50511712825197
At time: 666.2801244258881 and batch: 1800, loss is 3.6482534313201906 and perplexity is 38.40752605172055
At time: 667.1900155544281 and batch: 1850, loss is 3.6639694738388062 and perplexity is 39.01590852440527
At time: 668.1238753795624 and batch: 1900, loss is 3.729148368835449 and perplexity is 41.643628046737334
At time: 669.0323724746704 and batch: 1950, loss is 3.6796115684509276 and perplexity is 39.63099715282613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244142328306686 and perplexity of 69.69595825184301
finished 18 epochs...
Completing Train Step...
At time: 672.069995880127 and batch: 50, loss is 3.831755361557007 and perplexity is 46.14346565070678
At time: 672.9666302204132 and batch: 100, loss is 3.8178608798980713 and perplexity is 45.50675970640116
At time: 673.8865699768066 and batch: 150, loss is 3.7971188974380494 and perplexity is 44.57258114481205
At time: 674.7830100059509 and batch: 200, loss is 3.7882704305648804 and perplexity is 44.17992191514014
At time: 675.6796481609344 and batch: 250, loss is 3.782393145561218 and perplexity is 43.92102547194019
At time: 676.5759923458099 and batch: 300, loss is 3.7831538772583007 and perplexity is 43.954450300236296
At time: 677.4716720581055 and batch: 350, loss is 3.8002991676330566 and perplexity is 44.714559641466465
At time: 678.3684313297272 and batch: 400, loss is 3.7716324710845948 and perplexity is 43.450939371919546
At time: 679.2649304866791 and batch: 450, loss is 3.809936761856079 and perplexity is 45.147583726645415
At time: 680.1616549491882 and batch: 500, loss is 3.8184580326080324 and perplexity is 45.5339423065553
At time: 681.0579421520233 and batch: 550, loss is 3.7765488386154176 and perplexity is 43.665086140201545
At time: 681.9555041790009 and batch: 600, loss is 3.7676027631759643 and perplexity is 43.276197094527
At time: 682.8529267311096 and batch: 650, loss is 3.8049951934814454 and perplexity is 44.925034179484136
At time: 683.750776052475 and batch: 700, loss is 3.825472288131714 and perplexity is 45.854451766436895
At time: 684.6477825641632 and batch: 750, loss is 3.799889531135559 and perplexity is 44.69624667695318
At time: 685.5709664821625 and batch: 800, loss is 3.763453230857849 and perplexity is 43.09699317943365
At time: 686.4676148891449 and batch: 850, loss is 3.7689294910430906 and perplexity is 43.333650935574
At time: 687.3644540309906 and batch: 900, loss is 3.730458254814148 and perplexity is 41.69821219291715
At time: 688.2613627910614 and batch: 950, loss is 3.8332723808288574 and perplexity is 46.213519300302316
At time: 689.1578969955444 and batch: 1000, loss is 3.7958735609054566 and perplexity is 44.51710782980263
At time: 690.0551292896271 and batch: 1050, loss is 3.7534075498580934 and perplexity is 42.66622185219969
At time: 690.9524579048157 and batch: 1100, loss is 3.759711990356445 and perplexity is 42.93605819901105
At time: 691.8495953083038 and batch: 1150, loss is 3.7407510042190553 and perplexity is 42.1296178079847
At time: 692.7470128536224 and batch: 1200, loss is 3.8003073596954344 and perplexity is 44.71492594742864
At time: 693.6435465812683 and batch: 1250, loss is 3.792722043991089 and perplexity is 44.37703225271008
At time: 694.5741007328033 and batch: 1300, loss is 3.7855042791366578 and perplexity is 44.05788242870204
At time: 695.469776391983 and batch: 1350, loss is 3.6627859687805175 and perplexity is 38.969760313020295
At time: 696.3669595718384 and batch: 1400, loss is 3.6887131261825563 and perplexity is 39.99334743601374
At time: 697.2636818885803 and batch: 1450, loss is 3.591523914337158 and perplexity is 36.289335649122094
At time: 698.1598267555237 and batch: 1500, loss is 3.619677095413208 and perplexity is 37.32551329647979
At time: 699.0570709705353 and batch: 1550, loss is 3.6303956413269045 and perplexity is 37.72774031801121
At time: 699.9538400173187 and batch: 1600, loss is 3.7270882081985475 and perplexity is 41.55792379603213
At time: 700.850604057312 and batch: 1650, loss is 3.6756405353546144 and perplexity is 39.47393321094451
At time: 701.7454378604889 and batch: 1700, loss is 3.6942731094360353 and perplexity is 40.21632909071481
At time: 702.6409547328949 and batch: 1750, loss is 3.679447727203369 and perplexity is 39.62450449270792
At time: 703.5747647285461 and batch: 1800, loss is 3.6511875009536743 and perplexity is 38.52038189008786
At time: 704.4792809486389 and batch: 1850, loss is 3.6668881225585936 and perplexity is 39.12994859637211
At time: 705.3993308544159 and batch: 1900, loss is 3.7322195100784303 and perplexity is 41.77171810098545
At time: 706.3007707595825 and batch: 1950, loss is 3.682142052650452 and perplexity is 39.731409757606244
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243663131359011 and perplexity of 69.66256816223694
finished 19 epochs...
Completing Train Step...
At time: 709.2528388500214 and batch: 50, loss is 3.8312795209884642 and perplexity is 46.121513940948255
At time: 710.1729698181152 and batch: 100, loss is 3.8163174486160276 and perplexity is 45.4365773246998
At time: 711.0694334506989 and batch: 150, loss is 3.7948798751831054 and perplexity is 44.47289378642173
At time: 711.9674572944641 and batch: 200, loss is 3.7856047105789186 and perplexity is 44.0623074475791
At time: 712.8647360801697 and batch: 250, loss is 3.7796757984161378 and perplexity is 43.80183880787495
At time: 713.7627060413361 and batch: 300, loss is 3.780392174720764 and perplexity is 43.83322864942289
At time: 714.6623048782349 and batch: 350, loss is 3.7970911502838134 and perplexity is 44.57134439968648
At time: 715.5600636005402 and batch: 400, loss is 3.768640875816345 and perplexity is 43.32114598872936
At time: 716.4577903747559 and batch: 450, loss is 3.8069803524017334 and perplexity is 45.01430609197918
At time: 717.3547778129578 and batch: 500, loss is 3.8157351446151733 and perplexity is 45.41012712571423
At time: 718.2513856887817 and batch: 550, loss is 3.773746566772461 and perplexity is 43.54289598376851
At time: 719.1883063316345 and batch: 600, loss is 3.7651470518112182 and perplexity is 43.17005362769954
At time: 720.0845546722412 and batch: 650, loss is 3.8025234222412108 and perplexity is 44.81412689721513
At time: 721.1840059757233 and batch: 700, loss is 3.823083214759827 and perplexity is 45.74503287366469
At time: 722.0816679000854 and batch: 750, loss is 3.7976697635650636 and perplexity is 44.59714143405294
At time: 722.9785046577454 and batch: 800, loss is 3.7615686655044556 and perplexity is 43.01585056254991
At time: 723.8750970363617 and batch: 850, loss is 3.767113971710205 and perplexity is 43.25504922758616
At time: 724.7938225269318 and batch: 900, loss is 3.728825430870056 and perplexity is 41.6301819094753
At time: 725.700971364975 and batch: 950, loss is 3.831700782775879 and perplexity is 46.14094726532038
At time: 726.5976078510284 and batch: 1000, loss is 3.794340434074402 and perplexity is 44.44890974885983
At time: 727.5116338729858 and batch: 1050, loss is 3.752121114730835 and perplexity is 42.61136981501995
At time: 728.4166171550751 and batch: 1100, loss is 3.7585291767120363 and perplexity is 42.885302866503466
At time: 729.3139765262604 and batch: 1150, loss is 3.7396209144592287 and perplexity is 42.0820344501113
At time: 730.21178150177 and batch: 1200, loss is 3.799427561759949 and perplexity is 44.675603148489834
At time: 731.1090021133423 and batch: 1250, loss is 3.7920425653457643 and perplexity is 44.346889248874916
At time: 732.0052890777588 and batch: 1300, loss is 3.785004472732544 and perplexity is 44.0358675189672
At time: 732.9025981426239 and batch: 1350, loss is 3.662430291175842 and perplexity is 38.9559021066903
At time: 733.7999613285065 and batch: 1400, loss is 3.68841637134552 and perplexity is 39.98148097751439
At time: 734.6973841190338 and batch: 1450, loss is 3.5915555334091187 and perplexity is 36.290483102378
At time: 735.5943169593811 and batch: 1500, loss is 3.619990644454956 and perplexity is 37.337218510390066
At time: 736.4919557571411 and batch: 1550, loss is 3.6309930181503294 and perplexity is 37.75028472876119
At time: 737.3892693519592 and batch: 1600, loss is 3.7278623294830324 and perplexity is 41.590107124674304
At time: 738.2879757881165 and batch: 1650, loss is 3.6766078901290893 and perplexity is 39.51213698402538
At time: 739.1850872039795 and batch: 1700, loss is 3.6953929901123046 and perplexity is 40.261391808257734
At time: 740.0828442573547 and batch: 1750, loss is 3.6807233619689943 and perplexity is 39.675083141292106
At time: 740.9799723625183 and batch: 1800, loss is 3.652456364631653 and perplexity is 38.56929002584666
At time: 741.8782911300659 and batch: 1850, loss is 3.6681083965301515 and perplexity is 39.17772699959481
At time: 742.7755460739136 and batch: 1900, loss is 3.7334709215164184 and perplexity is 41.82402442834349
At time: 743.6732692718506 and batch: 1950, loss is 3.6830903768539427 and perplexity is 39.76910588636877
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24344482421875 and perplexity of 69.647361986067
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
1540.6887788772583


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5224888324737549 and batch: 50, loss is 7.571755666732788 and perplexity is 1942.5477559607643
At time: 2.4807589054107666 and batch: 100, loss is 6.778732786178589 and perplexity is 878.9541951791983
At time: 3.443593978881836 and batch: 150, loss is 6.525995941162109 and perplexity is 682.6593237187717
At time: 4.405191659927368 and batch: 200, loss is 6.39002631187439 and perplexity is 595.8722579977577
At time: 5.363976001739502 and batch: 250, loss is 6.330393362045288 and perplexity is 561.3773749790863
At time: 6.325981855392456 and batch: 300, loss is 6.251067657470703 and perplexity is 518.5661802750789
At time: 7.287275791168213 and batch: 350, loss is 6.199488687515259 and perplexity is 492.4971567579913
At time: 8.247811079025269 and batch: 400, loss is 6.149426746368408 and perplexity is 468.4487698384289
At time: 9.261173963546753 and batch: 450, loss is 6.062469549179077 and perplexity is 429.43463840456275
At time: 10.223965406417847 and batch: 500, loss is 6.047595767974854 and perplexity is 423.09458869088553
At time: 11.18767786026001 and batch: 550, loss is 5.997171068191529 and perplexity is 402.28913371631074
At time: 12.151775360107422 and batch: 600, loss is 6.0326377868652346 and perplexity is 416.813044554512
At time: 13.113100290298462 and batch: 650, loss is 6.092213401794433 and perplexity is 442.39953618202594
At time: 14.075509071350098 and batch: 700, loss is 6.006728763580322 and perplexity is 406.1525238577982
At time: 15.038846731185913 and batch: 750, loss is 5.940320329666138 and perplexity is 380.056653462126
At time: 16.00231409072876 and batch: 800, loss is 5.937731103897095 and perplexity is 379.07387384948834
At time: 16.966179370880127 and batch: 850, loss is 5.974351053237915 and perplexity is 393.2128440739745
At time: 17.931384086608887 and batch: 900, loss is 5.951603107452392 and perplexity is 384.3690302765709
At time: 18.89554524421692 and batch: 950, loss is 5.972025480270386 and perplexity is 392.2994613939987
At time: 19.85957908630371 and batch: 1000, loss is 5.947143278121948 and perplexity is 382.6586268902275
At time: 20.823756456375122 and batch: 1050, loss is 5.848406772613526 and perplexity is 346.6815976255515
At time: 21.78768801689148 and batch: 1100, loss is 5.92706748008728 and perplexity is 375.0530490457405
At time: 22.751659393310547 and batch: 1150, loss is 5.831082973480225 and perplexity is 340.72747815871816
At time: 23.7160165309906 and batch: 1200, loss is 5.906199111938476 and perplexity is 367.3074045167855
At time: 24.67961549758911 and batch: 1250, loss is 5.847155799865723 and perplexity is 346.2481795483811
At time: 25.641749382019043 and batch: 1300, loss is 5.856032781600952 and perplexity is 349.33550108895975
At time: 26.60407018661499 and batch: 1350, loss is 5.827254734039307 and perplexity is 339.42558535689375
At time: 27.567989110946655 and batch: 1400, loss is 5.844124698638916 and perplexity is 345.2002552512073
At time: 28.5316162109375 and batch: 1450, loss is 5.828537797927856 and perplexity is 339.8613695780294
At time: 29.495171785354614 and batch: 1500, loss is 5.801600160598755 and perplexity is 330.828515345159
At time: 30.459264039993286 and batch: 1550, loss is 5.767642526626587 and perplexity is 319.78296350111265
At time: 31.42211890220642 and batch: 1600, loss is 5.787642259597778 and perplexity is 326.24292076529196
At time: 32.38629364967346 and batch: 1650, loss is 5.786939334869385 and perplexity is 326.01367712877254
At time: 33.351317405700684 and batch: 1700, loss is 5.808579559326172 and perplexity is 333.1455759031924
At time: 34.31514286994934 and batch: 1750, loss is 5.807621412277221 and perplexity is 332.82652632538407
At time: 35.27864599227905 and batch: 1800, loss is 5.811628351211548 and perplexity is 334.1628173223977
At time: 36.242258071899414 and batch: 1850, loss is 5.7722290515899655 and perplexity is 321.2530247052365
At time: 37.206013202667236 and batch: 1900, loss is 5.767334222793579 and perplexity is 319.6843883840586
At time: 38.1697142124176 and batch: 1950, loss is 5.701286525726318 and perplexity is 299.25214900822084
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.142794444949128 and perplexity of 171.1934913122693
finished 1 epochs...
Completing Train Step...
At time: 41.13976430892944 and batch: 50, loss is 5.389228897094727 and perplexity is 219.03442233889325
At time: 42.06055283546448 and batch: 100, loss is 5.283664007186889 and perplexity is 197.09069572547617
At time: 42.95551681518555 and batch: 150, loss is 5.184009952545166 and perplexity is 178.39674108979378
At time: 43.84909987449646 and batch: 200, loss is 5.130195741653442 and perplexity is 169.05020497317273
At time: 44.742334604263306 and batch: 250, loss is 5.135548629760742 and perplexity is 169.957538064653
At time: 45.63608241081238 and batch: 300, loss is 5.126728963851929 and perplexity is 168.46516017134536
At time: 46.53020429611206 and batch: 350, loss is 5.109756126403808 and perplexity is 165.62995717467055
At time: 47.4242217540741 and batch: 400, loss is 5.059243144989014 and perplexity is 157.47128827626764
At time: 48.31880283355713 and batch: 450, loss is 5.012227592468261 and perplexity is 150.23903501282734
At time: 49.21292424201965 and batch: 500, loss is 5.0026191711425785 and perplexity is 148.80238807220846
At time: 50.105496406555176 and batch: 550, loss is 4.938852243423462 and perplexity is 139.60991936448505
At time: 50.99812078475952 and batch: 600, loss is 4.930979518890381 and perplexity is 138.5151240926333
At time: 51.89223766326904 and batch: 650, loss is 5.003431558609009 and perplexity is 148.92332238336144
At time: 52.786831855773926 and batch: 700, loss is 4.992223167419434 and perplexity is 147.2634511490569
At time: 53.68149781227112 and batch: 750, loss is 4.942453088760376 and perplexity is 140.1135392761561
At time: 54.57923197746277 and batch: 800, loss is 4.9166802978515625 and perplexity is 136.54855939579315
At time: 55.47900104522705 and batch: 850, loss is 4.903591604232788 and perplexity is 134.77296260758087
At time: 56.379018783569336 and batch: 900, loss is 4.912121639251709 and perplexity is 135.9274978106162
At time: 57.27764534950256 and batch: 950, loss is 4.962561292648315 and perplexity is 142.95948846103474
At time: 58.17784810066223 and batch: 1000, loss is 4.927806406021118 and perplexity is 138.07629656262873
At time: 59.078123331069946 and batch: 1050, loss is 4.841914625167846 and perplexity is 126.71172508692216
At time: 59.97800540924072 and batch: 1100, loss is 4.9121576690673825 and perplexity is 135.93239534153528
At time: 60.87829089164734 and batch: 1150, loss is 4.823738927841187 and perplexity is 124.42945488003934
At time: 61.77829170227051 and batch: 1200, loss is 4.9094361972808835 and perplexity is 135.56296209183952
At time: 62.67880868911743 and batch: 1250, loss is 4.86204384803772 and perplexity is 129.28817764071925
At time: 63.579108476638794 and batch: 1300, loss is 4.883085899353027 and perplexity is 132.03749025612754
At time: 64.4844651222229 and batch: 1350, loss is 4.79126012802124 and perplexity is 120.45305934362725
At time: 65.38935875892639 and batch: 1400, loss is 4.7961820793151855 and perplexity is 121.04738485571082
At time: 66.28831434249878 and batch: 1450, loss is 4.747236213684082 and perplexity is 115.2652753030035
At time: 67.18812990188599 and batch: 1500, loss is 4.723395547866821 and perplexity is 112.54977270708922
At time: 68.08616471290588 and batch: 1550, loss is 4.724527206420898 and perplexity is 112.6772127158201
At time: 68.98801898956299 and batch: 1600, loss is 4.7781687927246095 and perplexity is 118.8864448681457
At time: 69.92102527618408 and batch: 1650, loss is 4.742873363494873 and perplexity is 114.76348558745742
At time: 70.83573937416077 and batch: 1700, loss is 4.7718698596954345 and perplexity is 118.13994067203794
At time: 71.75378966331482 and batch: 1750, loss is 4.769379215240479 and perplexity is 117.8460622091945
At time: 72.65565180778503 and batch: 1800, loss is 4.719885225296021 and perplexity is 112.15537932859435
At time: 73.5968689918518 and batch: 1850, loss is 4.729606971740723 and perplexity is 113.25104274031133
At time: 74.52606129646301 and batch: 1900, loss is 4.815640563964844 and perplexity is 123.42584914469427
At time: 75.42746186256409 and batch: 1950, loss is 4.728112268447876 and perplexity is 113.08189248002661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.574001010628634 and perplexity of 96.93115755700252
finished 2 epochs...
Completing Train Step...
At time: 78.62002396583557 and batch: 50, loss is 4.682037391662598 and perplexity is 107.98986624560501
At time: 79.54408502578735 and batch: 100, loss is 4.629182634353637 and perplexity is 102.4303068710287
At time: 80.44389390945435 and batch: 150, loss is 4.58208270072937 and perplexity is 97.71769914517593
At time: 81.34410977363586 and batch: 200, loss is 4.576203165054321 and perplexity is 97.14485014027942
At time: 82.24339866638184 and batch: 250, loss is 4.57682954788208 and perplexity is 97.20571906784784
At time: 83.14294147491455 and batch: 300, loss is 4.593314580917358 and perplexity is 98.82143957081115
At time: 84.04332613945007 and batch: 350, loss is 4.600985765457153 and perplexity is 99.5824321958317
At time: 84.9433081150055 and batch: 400, loss is 4.558840398788452 and perplexity is 95.47270535057466
At time: 85.84286069869995 and batch: 450, loss is 4.55836184501648 and perplexity is 95.42702745784439
At time: 86.76680660247803 and batch: 500, loss is 4.559971532821655 and perplexity is 95.58075887682826
At time: 87.66513872146606 and batch: 550, loss is 4.514892120361328 and perplexity is 91.3677087752907
At time: 88.56225848197937 and batch: 600, loss is 4.50894513130188 and perplexity is 90.82595849895847
At time: 89.46138048171997 and batch: 650, loss is 4.573747959136963 and perplexity is 96.90663208622767
At time: 90.3612790107727 and batch: 700, loss is 4.590365781784057 and perplexity is 98.53046422022996
At time: 91.26137185096741 and batch: 750, loss is 4.55475305557251 and perplexity is 95.0832720519959
At time: 92.1616153717041 and batch: 800, loss is 4.526954612731934 and perplexity is 92.47650504411291
At time: 93.06094145774841 and batch: 850, loss is 4.518966178894043 and perplexity is 91.74070545808549
At time: 93.95869708061218 and batch: 900, loss is 4.514419145584107 and perplexity is 91.32450437168951
At time: 94.85782527923584 and batch: 950, loss is 4.584046039581299 and perplexity is 97.90974055992561
At time: 95.7590024471283 and batch: 1000, loss is 4.564667615890503 and perplexity is 96.0306696426317
At time: 96.65931749343872 and batch: 1050, loss is 4.490331001281739 and perplexity is 89.15095007416878
At time: 97.55930256843567 and batch: 1100, loss is 4.546723222732544 and perplexity is 94.32282648295303
At time: 98.45898008346558 and batch: 1150, loss is 4.490979995727539 and perplexity is 89.2088273245803
At time: 99.35898113250732 and batch: 1200, loss is 4.567925691604614 and perplexity is 96.34405507471992
At time: 100.25919437408447 and batch: 1250, loss is 4.540444431304931 and perplexity is 93.73244849826726
At time: 101.16136741638184 and batch: 1300, loss is 4.5449825954437255 and perplexity is 94.158788403214
At time: 102.06179928779602 and batch: 1350, loss is 4.4462645053863525 and perplexity is 85.3076816866739
At time: 102.96128606796265 and batch: 1400, loss is 4.4531151294708256 and perplexity is 85.89409891398812
At time: 103.86219358444214 and batch: 1450, loss is 4.402288274765015 and perplexity is 81.63746404164765
At time: 104.76077485084534 and batch: 1500, loss is 4.398962230682373 and perplexity is 81.36638529727908
At time: 105.66025900840759 and batch: 1550, loss is 4.407283601760864 and perplexity is 82.04629012951484
At time: 106.56035947799683 and batch: 1600, loss is 4.480234661102295 and perplexity is 88.25538035075009
At time: 107.46109747886658 and batch: 1650, loss is 4.43691125869751 and perplexity is 84.51349778418886
At time: 108.36101579666138 and batch: 1700, loss is 4.466271648406982 and perplexity is 87.03163283784916
At time: 109.26129102706909 and batch: 1750, loss is 4.462895107269287 and perplexity is 86.73826251649764
At time: 110.16103625297546 and batch: 1800, loss is 4.420762729644776 and perplexity is 83.15968953560629
At time: 111.06051898002625 and batch: 1850, loss is 4.445984373092651 and perplexity is 85.283787597042
At time: 111.96024918556213 and batch: 1900, loss is 4.536577339172363 and perplexity is 93.37067643789779
At time: 112.85833096504211 and batch: 1950, loss is 4.459575681686402 and perplexity is 86.45081864708759
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.44463628724564 and perplexity of 85.16889518981678
finished 3 epochs...
Completing Train Step...
At time: 115.82318043708801 and batch: 50, loss is 4.431081342697143 and perplexity is 84.02222462328584
At time: 116.74963617324829 and batch: 100, loss is 4.3810270881652835 and perplexity is 79.92007622972919
At time: 117.65039372444153 and batch: 150, loss is 4.344243707656861 and perplexity is 77.03375540356134
At time: 118.5507595539093 and batch: 200, loss is 4.3460249328613285 and perplexity is 77.17109214780474
At time: 119.4547073841095 and batch: 250, loss is 4.342600860595703 and perplexity is 76.90730462297364
At time: 120.3554174900055 and batch: 300, loss is 4.362110786437988 and perplexity is 78.42249297800274
At time: 121.25676035881042 and batch: 350, loss is 4.373464469909668 and perplexity is 79.31795089405847
At time: 122.15784406661987 and batch: 400, loss is 4.3296911334991455 and perplexity is 75.92083354524797
At time: 123.0591676235199 and batch: 450, loss is 4.348987379074097 and perplexity is 77.4000463222432
At time: 123.9605770111084 and batch: 500, loss is 4.353378458023071 and perplexity is 77.74066332707575
At time: 124.87776708602905 and batch: 550, loss is 4.310485858917236 and perplexity is 74.47666530329313
At time: 125.78135681152344 and batch: 600, loss is 4.307847146987915 and perplexity is 74.28040189328051
At time: 126.6834545135498 and batch: 650, loss is 4.368542461395264 and perplexity is 78.92850647501456
At time: 127.58455657958984 and batch: 700, loss is 4.384395532608032 and perplexity is 80.1897364791805
At time: 128.48557925224304 and batch: 750, loss is 4.354676685333252 and perplexity is 77.84165391950702
At time: 129.3869936466217 and batch: 800, loss is 4.327955980300903 and perplexity is 75.7892134916102
At time: 130.2890202999115 and batch: 850, loss is 4.320517873764038 and perplexity is 75.22757659425098
At time: 131.19038486480713 and batch: 900, loss is 4.309124221801758 and perplexity is 74.37532412219359
At time: 132.15533423423767 and batch: 950, loss is 4.390781526565552 and perplexity is 80.70346624351392
At time: 133.0572612285614 and batch: 1000, loss is 4.368963088989258 and perplexity is 78.96171296608429
At time: 133.95779991149902 and batch: 1050, loss is 4.304090948104858 and perplexity is 74.00191328738477
At time: 134.85949993133545 and batch: 1100, loss is 4.354449100494385 and perplexity is 77.82394035498845
At time: 135.75942420959473 and batch: 1150, loss is 4.3071619462966915 and perplexity is 74.22952234390074
At time: 136.66103553771973 and batch: 1200, loss is 4.380535888671875 and perplexity is 79.88082916862935
At time: 137.56376481056213 and batch: 1250, loss is 4.362585115432739 and perplexity is 78.45969986371762
At time: 138.46470856666565 and batch: 1300, loss is 4.364017305374145 and perplexity is 78.57214956211054
At time: 139.36485195159912 and batch: 1350, loss is 4.260115299224854 and perplexity is 70.81814826116965
At time: 140.26553869247437 and batch: 1400, loss is 4.276083450317383 and perplexity is 71.9580600734234
At time: 141.16622519493103 and batch: 1450, loss is 4.218335719108581 and perplexity is 67.92035162991505
At time: 142.08898186683655 and batch: 1500, loss is 4.2209180736541745 and perplexity is 68.09597271904887
At time: 142.98899292945862 and batch: 1550, loss is 4.232554349899292 and perplexity is 68.89298439970865
At time: 143.89091277122498 and batch: 1600, loss is 4.3102185153961186 and perplexity is 74.45675711063161
At time: 144.79155850410461 and batch: 1650, loss is 4.2614846467971805 and perplexity is 70.91518934689176
At time: 145.69241094589233 and batch: 1700, loss is 4.299026069641113 and perplexity is 73.62805017533718
At time: 146.59440970420837 and batch: 1750, loss is 4.293794069290161 and perplexity is 73.24383417655497
At time: 147.49365639686584 and batch: 1800, loss is 4.248324246406555 and perplexity is 69.98803132832823
At time: 148.3937861919403 and batch: 1850, loss is 4.283653306961059 and perplexity is 72.50483918127522
At time: 149.2948899269104 and batch: 1900, loss is 4.369972085952758 and perplexity is 79.04142530268992
At time: 150.1967089176178 and batch: 1950, loss is 4.297929477691651 and perplexity is 73.54735450145994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4013845044513085 and perplexity of 81.56371585589083
finished 4 epochs...
Completing Train Step...
At time: 153.15733528137207 and batch: 50, loss is 4.272920680046082 and perplexity is 71.73083278351635
At time: 154.05755472183228 and batch: 100, loss is 4.227094149589538 and perplexity is 68.51784001872123
At time: 154.9802541732788 and batch: 150, loss is 4.196994876861572 and perplexity is 66.48623121738989
At time: 155.9024133682251 and batch: 200, loss is 4.2000014162063595 and perplexity is 66.68642548259812
At time: 156.82328462600708 and batch: 250, loss is 4.195851683616638 and perplexity is 66.41026803555219
At time: 157.74783396720886 and batch: 300, loss is 4.215309410095215 and perplexity is 67.7151143699109
At time: 158.64833188056946 and batch: 350, loss is 4.230537943840027 and perplexity is 68.75420813020034
At time: 159.54842853546143 and batch: 400, loss is 4.18255989074707 and perplexity is 65.53339701224279
At time: 160.44933891296387 and batch: 450, loss is 4.213746600151062 and perplexity is 67.6093711655918
At time: 161.3493206501007 and batch: 500, loss is 4.221003108024597 and perplexity is 68.10176346342
At time: 162.24803256988525 and batch: 550, loss is 4.17707447052002 and perplexity is 65.17490293497438
At time: 163.1460108757019 and batch: 600, loss is 4.17612895488739 and perplexity is 65.11330816938992
At time: 164.046865940094 and batch: 650, loss is 4.232686157226563 and perplexity is 68.90206559832119
At time: 164.94657373428345 and batch: 700, loss is 4.250397906303406 and perplexity is 70.13331328277452
At time: 165.84709692001343 and batch: 750, loss is 4.22506203174591 and perplexity is 68.37874506994211
At time: 166.74622917175293 and batch: 800, loss is 4.196687927246094 and perplexity is 66.46582642606477
At time: 167.64527010917664 and batch: 850, loss is 4.185778937339783 and perplexity is 65.74469197230678
At time: 168.54533457756042 and batch: 900, loss is 4.174843068122864 and perplexity is 65.02963363773648
At time: 169.44566988945007 and batch: 950, loss is 4.264937400817871 and perplexity is 71.16046524704095
At time: 170.34544277191162 and batch: 1000, loss is 4.242243299484253 and perplexity is 69.56372921143335
At time: 171.24652791023254 and batch: 1050, loss is 4.178478651046753 and perplexity is 65.26648454801841
At time: 172.14643168449402 and batch: 1100, loss is 4.224345769882202 and perplexity is 68.32978551858318
At time: 173.04642391204834 and batch: 1150, loss is 4.18374611377716 and perplexity is 65.61118036209832
At time: 173.9459867477417 and batch: 1200, loss is 4.258328957557678 and perplexity is 70.69175577583005
At time: 174.84633684158325 and batch: 1250, loss is 4.243115429878235 and perplexity is 69.6244243171735
At time: 175.7466652393341 and batch: 1300, loss is 4.241077070236206 and perplexity is 69.48264924392822
At time: 176.64698195457458 and batch: 1350, loss is 4.13747950553894 and perplexity is 62.644726607882596
At time: 177.54699897766113 and batch: 1400, loss is 4.155569095611572 and perplexity is 63.78825583669331
At time: 178.44712829589844 and batch: 1450, loss is 4.09323661327362 and perplexity is 59.93355987602049
At time: 179.3472671508789 and batch: 1500, loss is 4.098923530578613 and perplexity is 60.27536807109715
At time: 180.24734473228455 and batch: 1550, loss is 4.11343361377716 and perplexity is 61.15634474216234
At time: 181.14775228500366 and batch: 1600, loss is 4.196273012161255 and perplexity is 66.43825447245958
At time: 182.04926872253418 and batch: 1650, loss is 4.1473462009429936 and perplexity is 63.26588238219967
At time: 182.94838309288025 and batch: 1700, loss is 4.179416742324829 and perplexity is 65.3277391946564
At time: 183.84783506393433 and batch: 1750, loss is 4.1805921030044555 and perplexity is 65.404567992524
At time: 184.75004768371582 and batch: 1800, loss is 4.132580623626709 and perplexity is 62.33858797057569
At time: 185.6504464149475 and batch: 1850, loss is 4.169092831611633 and perplexity is 64.65677091589761
At time: 186.55018258094788 and batch: 1900, loss is 4.254292588233948 and perplexity is 70.40699283220061
At time: 187.45002031326294 and batch: 1950, loss is 4.18312777519226 and perplexity is 65.57062297806957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377659145621366 and perplexity of 79.65136276463974
finished 5 epochs...
Completing Train Step...
At time: 190.45183086395264 and batch: 50, loss is 4.163187503814697 and perplexity is 64.27607665786522
At time: 191.35155320167542 and batch: 100, loss is 4.121150078773499 and perplexity is 61.630080969506956
At time: 192.2510027885437 and batch: 150, loss is 4.093664512634278 and perplexity is 59.9592108956094
At time: 193.15168142318726 and batch: 200, loss is 4.0981899976730345 and perplexity is 60.23117031745625
At time: 194.05294799804688 and batch: 250, loss is 4.094701781272888 and perplexity is 60.02143697166661
At time: 194.9542224407196 and batch: 300, loss is 4.1088191556930544 and perplexity is 60.87479146027925
At time: 195.85493230819702 and batch: 350, loss is 4.124250950813294 and perplexity is 61.821484570063625
At time: 196.7542188167572 and batch: 400, loss is 4.0719250345230105 and perplexity is 58.66979533506312
At time: 197.65356421470642 and batch: 450, loss is 4.117310853004455 and perplexity is 61.393922796845686
At time: 198.5535695552826 and batch: 500, loss is 4.126215209960938 and perplexity is 61.94303732812738
At time: 199.47570490837097 and batch: 550, loss is 4.081694655418396 and perplexity is 59.24578601749762
At time: 200.37500071525574 and batch: 600, loss is 4.081189789772034 and perplexity is 59.215882404734245
At time: 201.27257919311523 and batch: 650, loss is 4.134736194610595 and perplexity is 62.47310815379616
At time: 202.1703188419342 and batch: 700, loss is 4.150281090736389 and perplexity is 63.45183351423771
At time: 203.07128167152405 and batch: 750, loss is 4.13052610874176 and perplexity is 62.21064389019688
At time: 203.97067880630493 and batch: 800, loss is 4.097523021697998 and perplexity is 60.191010968055544
At time: 204.87076878547668 and batch: 850, loss is 4.093170547485352 and perplexity is 59.92960044893631
At time: 205.769948720932 and batch: 900, loss is 4.079813933372497 and perplexity is 59.13446587554317
At time: 206.6700096130371 and batch: 950, loss is 4.173120203018189 and perplexity is 64.91769280833576
At time: 207.56998205184937 and batch: 1000, loss is 4.144735832214355 and perplexity is 63.10095046145776
At time: 208.4693157672882 and batch: 1050, loss is 4.086223578453064 and perplexity is 59.51471414021564
At time: 209.3701503276825 and batch: 1100, loss is 4.127159314155579 and perplexity is 62.001545624115636
At time: 210.2996907234192 and batch: 1150, loss is 4.093415975570679 and perplexity is 59.944310661104666
At time: 211.22124481201172 and batch: 1200, loss is 4.164314875602722 and perplexity is 64.34858055507915
At time: 212.1171042919159 and batch: 1250, loss is 4.150820183753967 and perplexity is 63.48604917652145
At time: 213.01439142227173 and batch: 1300, loss is 4.150712904930114 and perplexity is 63.47923883314407
At time: 213.91230726242065 and batch: 1350, loss is 4.043272562026978 and perplexity is 57.01261516474824
At time: 214.80913758277893 and batch: 1400, loss is 4.06620924949646 and perplexity is 58.335407950952444
At time: 215.7059555053711 and batch: 1450, loss is 4.0027748966217045 and perplexity is 54.74986465406621
At time: 216.6032862663269 and batch: 1500, loss is 4.01060142993927 and perplexity is 55.180047518284645
At time: 217.5000319480896 and batch: 1550, loss is 4.027036738395691 and perplexity is 56.09444221646181
At time: 218.39766120910645 and batch: 1600, loss is 4.112866430282593 and perplexity is 61.12166770788688
At time: 219.29439067840576 and batch: 1650, loss is 4.06143488407135 and perplexity is 58.0575572044608
At time: 220.19161939620972 and batch: 1700, loss is 4.09385262966156 and perplexity is 59.97049130510658
At time: 221.08844113349915 and batch: 1750, loss is 4.095832719802856 and perplexity is 60.08935592620408
At time: 221.98497939109802 and batch: 1800, loss is 4.0457567119598385 and perplexity is 57.154419107086206
At time: 222.88206219673157 and batch: 1850, loss is 4.078599863052368 and perplexity is 59.06271603911349
At time: 223.8031256198883 and batch: 1900, loss is 4.167777938842773 and perplexity is 64.57181006480789
At time: 224.73404717445374 and batch: 1950, loss is 4.101880388259888 and perplexity is 60.45385751005961
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374391635628633 and perplexity of 79.39152588185863
finished 6 epochs...
Completing Train Step...
At time: 227.69586086273193 and batch: 50, loss is 4.075334348678589 and perplexity is 58.8701604585524
At time: 228.5977008342743 and batch: 100, loss is 4.038006634712219 and perplexity is 56.713179971193
At time: 229.49777936935425 and batch: 150, loss is 4.016144609451294 and perplexity is 55.486769749972446
At time: 230.39875602722168 and batch: 200, loss is 4.017873644828796 and perplexity is 55.58279132628284
At time: 231.29894185066223 and batch: 250, loss is 4.011402139663696 and perplexity is 55.224248412608205
At time: 232.19861435890198 and batch: 300, loss is 4.0280184555053715 and perplexity is 56.149538130019224
At time: 233.09871649742126 and batch: 350, loss is 4.039037947654724 and perplexity is 56.77169917832898
At time: 233.9992377758026 and batch: 400, loss is 3.989324622154236 and perplexity is 54.01839421399027
At time: 234.8991048336029 and batch: 450, loss is 4.035101871490479 and perplexity is 56.548680643289224
At time: 235.798983335495 and batch: 500, loss is 4.0517979431152344 and perplexity is 57.50074723529122
At time: 236.6974172592163 and batch: 550, loss is 4.008052639961242 and perplexity is 55.03958424791215
At time: 237.5972762107849 and batch: 600, loss is 4.006612501144409 and perplexity is 54.96037665482878
At time: 238.49730825424194 and batch: 650, loss is 4.05869375705719 and perplexity is 57.89863198265162
At time: 239.39803075790405 and batch: 700, loss is 4.074168920516968 and perplexity is 58.801591479545415
At time: 240.29890871047974 and batch: 750, loss is 4.055398125648498 and perplexity is 57.70813351136186
At time: 241.1982297897339 and batch: 800, loss is 4.019809880256653 and perplexity is 55.69051695346051
At time: 242.0979447364807 and batch: 850, loss is 4.017245182991028 and perplexity is 55.54787063740713
At time: 242.9991135597229 and batch: 900, loss is 4.005218663215637 and perplexity is 54.88382416054647
At time: 243.90031576156616 and batch: 950, loss is 4.103399114608765 and perplexity is 60.54574013096926
At time: 244.83109664916992 and batch: 1000, loss is 4.070607242584228 and perplexity is 58.592531671618175
At time: 245.7594611644745 and batch: 1050, loss is 4.016942195892334 and perplexity is 55.531042898666676
At time: 246.66028928756714 and batch: 1100, loss is 4.054464197158813 and perplexity is 57.65426340072015
At time: 247.5613067150116 and batch: 1150, loss is 4.021832132339478 and perplexity is 55.803251167443854
At time: 248.4626054763794 and batch: 1200, loss is 4.092462830543518 and perplexity is 59.88720226010916
At time: 249.36229610443115 and batch: 1250, loss is 4.080448307991028 and perplexity is 59.17199118106723
At time: 250.2633285522461 and batch: 1300, loss is 4.080074167251587 and perplexity is 59.14985666950199
At time: 251.16361570358276 and batch: 1350, loss is 3.9724953985214233 and perplexity is 53.11691346459935
At time: 252.06430411338806 and batch: 1400, loss is 3.9956911325454714 and perplexity is 54.36339995807217
At time: 252.96444463729858 and batch: 1450, loss is 3.9307122564315797 and perplexity is 50.94324940731457
At time: 253.86576080322266 and batch: 1500, loss is 3.944407653808594 and perplexity is 51.64573689419272
At time: 254.7658064365387 and batch: 1550, loss is 3.952339057922363 and perplexity is 52.05698885109618
At time: 255.66336917877197 and batch: 1600, loss is 4.045350217819214 and perplexity is 57.131190891994905
At time: 256.5617415904999 and batch: 1650, loss is 3.9955909490585326 and perplexity is 54.35795391590883
At time: 257.4637088775635 and batch: 1700, loss is 4.027866549491883 and perplexity is 56.1410093253274
At time: 258.36520314216614 and batch: 1750, loss is 4.025398635864258 and perplexity is 56.00262898893873
At time: 259.2671239376068 and batch: 1800, loss is 3.977001495361328 and perplexity is 53.356803498457445
At time: 260.16865611076355 and batch: 1850, loss is 4.011479935646057 and perplexity is 55.22854480438246
At time: 261.06976556777954 and batch: 1900, loss is 4.09912896156311 and perplexity is 60.28775177125523
At time: 261.9731590747833 and batch: 1950, loss is 4.034491934776306 and perplexity is 56.514200043387724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371321425327035 and perplexity of 79.14815099844844
finished 7 epochs...
Completing Train Step...
At time: 265.0788486003876 and batch: 50, loss is 4.008332791328431 and perplexity is 55.05500582277545
At time: 266.03331756591797 and batch: 100, loss is 3.972171049118042 and perplexity is 53.09968781912258
At time: 266.93363094329834 and batch: 150, loss is 3.950536861419678 and perplexity is 51.96325641535191
At time: 267.8585436344147 and batch: 200, loss is 3.9560664463043214 and perplexity is 52.25138754117702
At time: 268.7589547634125 and batch: 250, loss is 3.9484132862091066 and perplexity is 51.853025615289404
At time: 269.6597249507904 and batch: 300, loss is 3.9613217878341676 and perplexity is 52.526709249250786
At time: 270.5617444515228 and batch: 350, loss is 3.9725942850112914 and perplexity is 53.12216626943593
At time: 271.4635157585144 and batch: 400, loss is 3.922584390640259 and perplexity is 50.530867675079946
At time: 272.36295795440674 and batch: 450, loss is 3.97117075920105 and perplexity is 53.046599293186894
At time: 273.26333498954773 and batch: 500, loss is 3.990059218406677 and perplexity is 54.05809050253004
At time: 274.1632659435272 and batch: 550, loss is 3.953455367088318 and perplexity is 52.11513299228353
At time: 275.0632359981537 and batch: 600, loss is 3.947176661491394 and perplexity is 51.78894251366562
At time: 275.9631187915802 and batch: 650, loss is 3.9962844371795656 and perplexity is 54.395663585325764
At time: 276.86344933509827 and batch: 700, loss is 4.01283784866333 and perplexity is 55.30359130607645
At time: 277.76439118385315 and batch: 750, loss is 3.99843376159668 and perplexity is 54.51270324629907
At time: 278.66502475738525 and batch: 800, loss is 3.9583384466171263 and perplexity is 52.370237672657794
At time: 279.564781665802 and batch: 850, loss is 3.961132516860962 and perplexity is 52.51676840865787
At time: 280.46475768089294 and batch: 900, loss is 3.9435671854019163 and perplexity is 51.602348519826585
At time: 281.36573815345764 and batch: 950, loss is 4.043847155570984 and perplexity is 57.0453836587298
At time: 282.2664203643799 and batch: 1000, loss is 4.013842692375183 and perplexity is 55.359190701716535
At time: 283.1669714450836 and batch: 1050, loss is 3.958480997085571 and perplexity is 52.37770360669416
At time: 284.06619024276733 and batch: 1100, loss is 3.9930498886108396 and perplexity is 54.220002414976214
At time: 284.9663987159729 and batch: 1150, loss is 3.9623543882369994 and perplexity is 52.58097636368118
At time: 285.86524510383606 and batch: 1200, loss is 4.033626356124878 and perplexity is 56.46530372318594
At time: 286.76443004608154 and batch: 1250, loss is 4.019480872154236 and perplexity is 55.67219733597156
At time: 287.6640479564667 and batch: 1300, loss is 4.019669303894043 and perplexity is 55.68268873339956
At time: 288.56420397758484 and batch: 1350, loss is 3.9165952444076537 and perplexity is 50.22913538065505
At time: 289.46367168426514 and batch: 1400, loss is 3.936696729660034 and perplexity is 51.2490319807699
At time: 290.36245107650757 and batch: 1450, loss is 3.8747702693939208 and perplexity is 48.1716305219692
At time: 291.2622883319855 and batch: 1500, loss is 3.8897132444381715 and perplexity is 48.89686306573562
At time: 292.1622016429901 and batch: 1550, loss is 3.896081314086914 and perplexity is 49.2092352436187
At time: 293.06058263778687 and batch: 1600, loss is 3.9907288789749145 and perplexity is 54.09430319788758
At time: 293.96026277542114 and batch: 1650, loss is 3.9391834115982056 and perplexity is 51.37663060579192
At time: 294.8590757846832 and batch: 1700, loss is 3.9738280820846557 and perplexity is 53.18774869209106
At time: 295.7575078010559 and batch: 1750, loss is 3.972546281814575 and perplexity is 53.11961629684241
At time: 296.65669894218445 and batch: 1800, loss is 3.9229326677322387 and perplexity is 50.54846948370448
At time: 297.55583477020264 and batch: 1850, loss is 3.9534219121932983 and perplexity is 52.113389515144426
At time: 298.45484375953674 and batch: 1900, loss is 4.042443709373474 and perplexity is 56.965379685716044
At time: 299.37232995033264 and batch: 1950, loss is 3.9785172843933108 and perplexity is 53.43774248369789
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3760713799055235 and perplexity of 79.524995409047
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 302.324147939682 and batch: 50, loss is 3.9895069646835326 and perplexity is 54.02824496269771
At time: 303.2480437755585 and batch: 100, loss is 3.972107758522034 and perplexity is 53.096327214581116
At time: 304.15042901039124 and batch: 150, loss is 3.9496603441238403 and perplexity is 51.91772967775705
At time: 305.049373626709 and batch: 200, loss is 3.957023048400879 and perplexity is 52.30139524296968
At time: 305.94876503944397 and batch: 250, loss is 3.949095950126648 and perplexity is 51.88843589017561
At time: 306.84699511528015 and batch: 300, loss is 3.949976978302002 and perplexity is 51.93417120826348
At time: 307.7451629638672 and batch: 350, loss is 3.9578366708755492 and perplexity is 52.34396614957074
At time: 308.64397621154785 and batch: 400, loss is 3.901871509552002 and perplexity is 49.49499283214606
At time: 309.54088616371155 and batch: 450, loss is 3.938440775871277 and perplexity is 51.33849064817529
At time: 310.4386067390442 and batch: 500, loss is 3.9631262969970704 and perplexity is 52.62157974898769
At time: 311.3356635570526 and batch: 550, loss is 3.9197501277923585 and perplexity is 50.38785268093575
At time: 312.2744655609131 and batch: 600, loss is 3.9029671287536623 and perplexity is 49.54925021396622
At time: 313.1722707748413 and batch: 650, loss is 3.940939497947693 and perplexity is 51.466931670508785
At time: 314.0723397731781 and batch: 700, loss is 3.9554492330551145 and perplexity is 52.219147243090234
At time: 314.97304797172546 and batch: 750, loss is 3.9226024389266967 and perplexity is 50.53177967888372
At time: 315.87368392944336 and batch: 800, loss is 3.880391912460327 and perplexity is 48.443196843966845
At time: 316.7747004032135 and batch: 850, loss is 3.8802806520462036 and perplexity is 48.43780733364965
At time: 317.67607855796814 and batch: 900, loss is 3.8599516916275025 and perplexity is 47.4630584503629
At time: 318.57679772377014 and batch: 950, loss is 3.9546231269836425 and perplexity is 52.1760265021109
At time: 319.4780101776123 and batch: 1000, loss is 3.9182896709442137 and perplexity is 50.31431710726119
At time: 320.37854647636414 and batch: 1050, loss is 3.855815577507019 and perplexity is 47.267151250661655
At time: 321.27946376800537 and batch: 1100, loss is 3.8732569456100463 and perplexity is 48.098786380080504
At time: 322.1802532672882 and batch: 1150, loss is 3.8513347864151 and perplexity is 47.055830815324605
At time: 323.08090257644653 and batch: 1200, loss is 3.9028363466262816 and perplexity is 49.54277048133896
At time: 323.9823205471039 and batch: 1250, loss is 3.884020504951477 and perplexity is 48.61929676849312
At time: 324.8832986354828 and batch: 1300, loss is 3.8834213972091676 and perplexity is 48.590177295095444
At time: 325.7830460071564 and batch: 1350, loss is 3.776952791213989 and perplexity is 43.68272832827869
At time: 326.68343138694763 and batch: 1400, loss is 3.7895996046066283 and perplexity is 44.23868376422718
At time: 327.58350801467896 and batch: 1450, loss is 3.7181101179122926 and perplexity is 41.18648291399972
At time: 328.4836595058441 and batch: 1500, loss is 3.727186346054077 and perplexity is 41.562002401683266
At time: 329.38477873802185 and batch: 1550, loss is 3.7269036245346068 and perplexity is 41.550253590111225
At time: 330.2850034236908 and batch: 1600, loss is 3.8118958473205566 and perplexity is 45.236118396856874
At time: 331.18588066101074 and batch: 1650, loss is 3.7571276473999022 and perplexity is 42.82523995727196
At time: 332.0867533683777 and batch: 1700, loss is 3.7749195528030395 and perplexity is 43.59400115945737
At time: 332.9871504306793 and batch: 1750, loss is 3.763884439468384 and perplexity is 43.11558098130288
At time: 333.8873405456543 and batch: 1800, loss is 3.7202582120895387 and perplexity is 41.275050449775975
At time: 334.7875008583069 and batch: 1850, loss is 3.7330501222610475 and perplexity is 41.8064286124202
At time: 335.68846344947815 and batch: 1900, loss is 3.8175907564163207 and perplexity is 45.49446892211554
At time: 336.58865547180176 and batch: 1950, loss is 3.752002410888672 and perplexity is 42.606311981901136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.299870832576308 and perplexity of 73.69027470190241
finished 9 epochs...
Completing Train Step...
At time: 339.57080721855164 and batch: 50, loss is 3.9023481941223146 and perplexity is 49.51859195575907
At time: 340.49822092056274 and batch: 100, loss is 3.8726279401779173 and perplexity is 48.068541495264235
At time: 341.3993833065033 and batch: 150, loss is 3.845537266731262 and perplexity is 46.78381298619693
At time: 342.2997319698334 and batch: 200, loss is 3.8533697843551638 and perplexity is 47.15168683442243
At time: 343.1997344493866 and batch: 250, loss is 3.847647156715393 and perplexity is 46.88262589015755
At time: 344.10115122795105 and batch: 300, loss is 3.849125247001648 and perplexity is 46.95197388275136
At time: 345.0009653568268 and batch: 350, loss is 3.859274606704712 and perplexity is 47.43093280621859
At time: 345.90165090560913 and batch: 400, loss is 3.810294818878174 and perplexity is 45.16375203044398
At time: 346.8016211986542 and batch: 450, loss is 3.852498321533203 and perplexity is 47.11061379176772
At time: 347.7020630836487 and batch: 500, loss is 3.879067997932434 and perplexity is 48.37910462755721
At time: 348.60237646102905 and batch: 550, loss is 3.839390983581543 and perplexity is 46.497148288400034
At time: 349.50128698349 and batch: 600, loss is 3.8261321640014647 and perplexity is 45.884719998217776
At time: 350.40165638923645 and batch: 650, loss is 3.865646767616272 and perplexity is 47.734135343978295
At time: 351.3023929595947 and batch: 700, loss is 3.8797924852371217 and perplexity is 48.41416737439586
At time: 352.202335357666 and batch: 750, loss is 3.8499165296554567 and perplexity is 46.98914086810299
At time: 353.10270977020264 and batch: 800, loss is 3.810132689476013 and perplexity is 45.156430251881766
At time: 354.0263147354126 and batch: 850, loss is 3.813083653450012 and perplexity is 45.28988205964435
At time: 354.92668080329895 and batch: 900, loss is 3.793314824104309 and perplexity is 44.40334587323816
At time: 355.8282859325409 and batch: 950, loss is 3.8937767124176026 and perplexity is 49.095958137371134
At time: 356.7278416156769 and batch: 1000, loss is 3.858119306564331 and perplexity is 47.376167484172655
At time: 357.67853260040283 and batch: 1050, loss is 3.8012743616104125 and perplexity is 44.75818627948885
At time: 358.5769159793854 and batch: 1100, loss is 3.818310012817383 and perplexity is 45.52720288074415
At time: 359.47494769096375 and batch: 1150, loss is 3.7992150735855104 and perplexity is 44.66611111964252
At time: 360.3747453689575 and batch: 1200, loss is 3.8537269830703735 and perplexity is 47.16853236480145
At time: 361.2752435207367 and batch: 1250, loss is 3.8392471361160276 and perplexity is 46.49046027250365
At time: 362.1752622127533 and batch: 1300, loss is 3.841336531639099 and perplexity is 46.58769878154012
At time: 363.07462525367737 and batch: 1350, loss is 3.7362672233581544 and perplexity is 41.941140694783094
At time: 363.97205352783203 and batch: 1400, loss is 3.7518524742126464 and perplexity is 42.59992421199732
At time: 364.8786678314209 and batch: 1450, loss is 3.6816063928604126 and perplexity is 39.710132938074615
At time: 365.78004908561707 and batch: 1500, loss is 3.694191493988037 and perplexity is 40.21304695093771
At time: 366.6801915168762 and batch: 1550, loss is 3.6956009817123414 and perplexity is 40.26976671048411
At time: 367.5812397003174 and batch: 1600, loss is 3.7863708114624024 and perplexity is 44.09607655386248
At time: 368.48205041885376 and batch: 1650, loss is 3.7333905410766604 and perplexity is 41.8206627299767
At time: 369.3827061653137 and batch: 1700, loss is 3.756367049217224 and perplexity is 42.792679541853815
At time: 370.2827944755554 and batch: 1750, loss is 3.749248299598694 and perplexity is 42.48913089599275
At time: 371.1819975376129 and batch: 1800, loss is 3.7075488138198853 and perplexity is 40.753788872051125
At time: 372.08255434036255 and batch: 1850, loss is 3.7251521015167235 and perplexity is 41.47754106197178
At time: 372.98376512527466 and batch: 1900, loss is 3.812223434448242 and perplexity is 45.25093959443437
At time: 373.8848867416382 and batch: 1950, loss is 3.7483573961257934 and perplexity is 42.451294038713385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.300708859465843 and perplexity of 73.75205501676673
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 376.9164168834686 and batch: 50, loss is 3.8825749206542968 and perplexity is 48.54906425228641
At time: 377.8173899650574 and batch: 100, loss is 3.881735372543335 and perplexity is 48.508322082003545
At time: 378.71724557876587 and batch: 150, loss is 3.8592306900024416 and perplexity is 47.428849841802936
At time: 379.6175706386566 and batch: 200, loss is 3.872794580459595 and perplexity is 48.07655231800318
At time: 380.54603457450867 and batch: 250, loss is 3.8684743738174436 and perplexity is 47.869299686794214
At time: 381.4469928741455 and batch: 300, loss is 3.8673870611190795 and perplexity is 47.8172790758435
At time: 382.3496928215027 and batch: 350, loss is 3.8735193490982054 and perplexity is 48.111409325482875
At time: 383.2514054775238 and batch: 400, loss is 3.8293477392196653 and perplexity is 46.03250324346973
At time: 384.1512541770935 and batch: 450, loss is 3.8710180521011353 and perplexity is 47.99121878060093
At time: 385.0515823364258 and batch: 500, loss is 3.89406361579895 and perplexity is 49.110045954595805
At time: 385.9517412185669 and batch: 550, loss is 3.861998381614685 and perplexity is 47.560300094659226
At time: 386.8527464866638 and batch: 600, loss is 3.838006410598755 and perplexity is 46.43281414104198
At time: 387.7536668777466 and batch: 650, loss is 3.8721989250183104 and perplexity is 48.047923785233884
At time: 388.65312600135803 and batch: 700, loss is 3.8806749629974364 and perplexity is 48.45691065761242
At time: 389.55493903160095 and batch: 750, loss is 3.843805613517761 and perplexity is 46.70286974913436
At time: 390.4564027786255 and batch: 800, loss is 3.806553897857666 and perplexity is 44.99511362924556
At time: 391.3568913936615 and batch: 850, loss is 3.8052721500396727 and perplexity is 44.93747818547372
At time: 392.25722193717957 and batch: 900, loss is 3.7817923164367677 and perplexity is 43.894644366722716
At time: 393.1576008796692 and batch: 950, loss is 3.884035530090332 and perplexity is 48.62002728566614
At time: 394.0582284927368 and batch: 1000, loss is 3.844719567298889 and perplexity is 46.74557352519733
At time: 394.9594991207123 and batch: 1050, loss is 3.7872016763687135 and perplexity is 44.1327296611588
At time: 395.8614592552185 and batch: 1100, loss is 3.7990726232528687 and perplexity is 44.65974887041874
At time: 396.7646520137787 and batch: 1150, loss is 3.78350790977478 and perplexity is 43.970014359815586
At time: 397.66766595840454 and batch: 1200, loss is 3.828702564239502 and perplexity is 46.002813802574835
At time: 398.569509267807 and batch: 1250, loss is 3.810767889022827 and perplexity is 45.185122707666224
At time: 399.4711186885834 and batch: 1300, loss is 3.813994913101196 and perplexity is 45.331171711711924
At time: 400.37298822402954 and batch: 1350, loss is 3.705962347984314 and perplexity is 40.68918563729777
At time: 401.27435517311096 and batch: 1400, loss is 3.715922737121582 and perplexity is 41.09649085177241
At time: 402.17661142349243 and batch: 1450, loss is 3.6435312032699585 and perplexity is 38.22658451470097
At time: 403.07836866378784 and batch: 1500, loss is 3.659528708457947 and perplexity is 38.84303216430398
At time: 403.97927021980286 and batch: 1550, loss is 3.6616557359695436 and perplexity is 38.92574029240058
At time: 404.87861132621765 and batch: 1600, loss is 3.745978298187256 and perplexity is 42.35041829679307
At time: 405.77903842926025 and batch: 1650, loss is 3.691662673950195 and perplexity is 40.111483863534836
At time: 406.6814270019531 and batch: 1700, loss is 3.7071730852127076 and perplexity is 40.73847938400743
At time: 407.5819761753082 and batch: 1750, loss is 3.6945030450820924 and perplexity is 40.225577321534544
At time: 408.4834129810333 and batch: 1800, loss is 3.6500278997421263 and perplexity is 38.47573949726768
At time: 409.3843173980713 and batch: 1850, loss is 3.6654582977294923 and perplexity is 39.07403960386541
At time: 410.2853331565857 and batch: 1900, loss is 3.7528597211837766 and perplexity is 42.6428544736887
At time: 411.18567848205566 and batch: 1950, loss is 3.693243269920349 and perplexity is 40.17493404462699
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.274609942768896 and perplexity of 71.85210740892673
finished 11 epochs...
Completing Train Step...
At time: 414.20899724960327 and batch: 50, loss is 3.8695262765884397 and perplexity is 47.91968002874556
At time: 415.13816022872925 and batch: 100, loss is 3.85178671836853 and perplexity is 47.07710165498927
At time: 416.064382314682 and batch: 150, loss is 3.8187987184524537 and perplexity is 45.549457718930455
At time: 416.9650790691376 and batch: 200, loss is 3.8294718503952025 and perplexity is 46.03821674610763
At time: 417.8626959323883 and batch: 250, loss is 3.826410422325134 and perplexity is 45.897489580025336
At time: 418.7623221874237 and batch: 300, loss is 3.826463007926941 and perplexity is 45.89990319059635
At time: 419.66445994377136 and batch: 350, loss is 3.8321571016311644 and perplexity is 46.16200705418222
At time: 420.56538462638855 and batch: 400, loss is 3.788956036567688 and perplexity is 44.2102223206918
At time: 421.4763705730438 and batch: 450, loss is 3.8328787326812743 and perplexity is 46.1953310141639
At time: 422.3897442817688 and batch: 500, loss is 3.856147775650024 and perplexity is 47.28285591891866
At time: 423.28893089294434 and batch: 550, loss is 3.824554319381714 and perplexity is 45.812378126764635
At time: 424.18930292129517 and batch: 600, loss is 3.8037605142593383 and perplexity is 44.869600401739156
At time: 425.1362838745117 and batch: 650, loss is 3.838193016052246 and perplexity is 46.441479565864256
At time: 426.03802394866943 and batch: 700, loss is 3.850202045440674 and perplexity is 47.002558924997
At time: 426.93956208229065 and batch: 750, loss is 3.8149299240112304 and perplexity is 45.37357667328851
At time: 427.8410029411316 and batch: 800, loss is 3.7780994892120363 and perplexity is 43.7328479559484
At time: 428.7442066669464 and batch: 850, loss is 3.778060345649719 and perplexity is 43.73113612999283
At time: 429.6453130245209 and batch: 900, loss is 3.75573184967041 and perplexity is 42.76550628233658
At time: 430.5468578338623 and batch: 950, loss is 3.859677529335022 and perplexity is 47.45004765306652
At time: 431.4502332210541 and batch: 1000, loss is 3.8206814622879026 and perplexity is 45.635296460483346
At time: 432.35141825675964 and batch: 1050, loss is 3.7657066917419435 and perplexity is 43.194220075144905
At time: 433.25291109085083 and batch: 1100, loss is 3.778986110687256 and perplexity is 43.77163963234416
At time: 434.15343737602234 and batch: 1150, loss is 3.7648435163497926 and perplexity is 43.156951974060725
At time: 435.0534677505493 and batch: 1200, loss is 3.8118628549575804 and perplexity is 45.23462597503848
At time: 435.9533748626709 and batch: 1250, loss is 3.796431293487549 and perplexity is 44.5419433964584
At time: 436.8534848690033 and batch: 1300, loss is 3.800372672080994 and perplexity is 44.71784648128486
At time: 437.75497484207153 and batch: 1350, loss is 3.6932669496536255 and perplexity is 40.17588538761329
At time: 438.65515542030334 and batch: 1400, loss is 3.705525531768799 and perplexity is 40.671415822569465
At time: 439.55564069747925 and batch: 1450, loss is 3.634722967147827 and perplexity is 37.891354293027675
At time: 440.45627188682556 and batch: 1500, loss is 3.652491865158081 and perplexity is 38.57065928025103
At time: 441.3586313724518 and batch: 1550, loss is 3.6555674076080322 and perplexity is 38.689467586534484
At time: 442.25886583328247 and batch: 1600, loss is 3.7426027154922483 and perplexity is 42.20770196856379
At time: 443.1594166755676 and batch: 1650, loss is 3.689585204124451 and perplexity is 40.02823996442602
At time: 444.0606813430786 and batch: 1700, loss is 3.7076225090026855 and perplexity is 40.75679234064107
At time: 444.9601716995239 and batch: 1750, loss is 3.696647448539734 and perplexity is 40.311929742753065
At time: 445.8608319759369 and batch: 1800, loss is 3.6541349411010744 and perplexity is 38.634085895723416
At time: 446.76127004623413 and batch: 1850, loss is 3.6714264965057373 and perplexity is 39.3079385225545
At time: 447.6613953113556 and batch: 1900, loss is 3.7594025468826295 and perplexity is 42.92277397147476
At time: 448.56102442741394 and batch: 1950, loss is 3.699439387321472 and perplexity is 40.42463544326566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273300951580668 and perplexity of 71.75811516440378
finished 12 epochs...
Completing Train Step...
At time: 451.56311559677124 and batch: 50, loss is 3.8548724269866943 and perplexity is 47.22259222860081
At time: 452.46408200263977 and batch: 100, loss is 3.8349123668670653 and perplexity is 46.289371007601126
At time: 453.36418414115906 and batch: 150, loss is 3.800502395629883 and perplexity is 44.72364781530577
At time: 454.2655303478241 and batch: 200, loss is 3.810762906074524 and perplexity is 45.18489755309666
At time: 455.1692461967468 and batch: 250, loss is 3.807405080795288 and perplexity is 45.033429006627536
At time: 456.0724124908447 and batch: 300, loss is 3.8074640703201292 and perplexity is 45.036085585561004
At time: 456.97495889663696 and batch: 350, loss is 3.812840042114258 and perplexity is 45.278850274768125
At time: 457.87723183631897 and batch: 400, loss is 3.770107183456421 and perplexity is 43.38471471033085
At time: 458.7793185710907 and batch: 450, loss is 3.8146249532699583 and perplexity is 45.359741169795406
At time: 459.68130803108215 and batch: 500, loss is 3.8383341598510743 and perplexity is 46.44803495532879
At time: 460.5836386680603 and batch: 550, loss is 3.8069291305541992 and perplexity is 45.01200043510619
At time: 461.485680103302 and batch: 600, loss is 3.7872401237487794 and perplexity is 44.134426481608365
At time: 462.3879392147064 and batch: 650, loss is 3.8217509746551515 and perplexity is 45.68413008385808
At time: 463.29060077667236 and batch: 700, loss is 3.834555063247681 and perplexity is 46.272834602235754
At time: 464.1927411556244 and batch: 750, loss is 3.7998744535446165 and perplexity is 44.69557277030958
At time: 465.09562730789185 and batch: 800, loss is 3.7633402013778685 and perplexity is 43.09212222399182
At time: 465.9968903064728 and batch: 850, loss is 3.763772177696228 and perplexity is 43.11074102145069
At time: 466.8981935977936 and batch: 900, loss is 3.7418122577667234 and perplexity is 42.174351747172665
At time: 467.7985737323761 and batch: 950, loss is 3.8466258239746094 and perplexity is 46.83476757315523
At time: 468.6996958255768 and batch: 1000, loss is 3.808059267997742 and perplexity is 45.062898937941256
At time: 469.6017551422119 and batch: 1050, loss is 3.7539808130264283 and perplexity is 42.69068783777374
At time: 470.54606652259827 and batch: 1100, loss is 3.767960033416748 and perplexity is 43.29166115414283
At time: 471.44370794296265 and batch: 1150, loss is 3.754387865066528 and perplexity is 42.70806870657043
At time: 472.35735845565796 and batch: 1200, loss is 3.8017606639862063 and perplexity is 44.779957585102544
At time: 473.2822856903076 and batch: 1250, loss is 3.7874877500534057 and perplexity is 44.14535667979124
At time: 474.19196128845215 and batch: 1300, loss is 3.7918756103515623 and perplexity is 44.339485932265035
At time: 475.102694272995 and batch: 1350, loss is 3.68528223991394 and perplexity is 39.85636992096056
At time: 476.0282440185547 and batch: 1400, loss is 3.6983526754379272 and perplexity is 40.380729372486805
At time: 476.9293041229248 and batch: 1450, loss is 3.6283017444610595 and perplexity is 37.64882496993697
At time: 477.8291265964508 and batch: 1500, loss is 3.646373109817505 and perplexity is 38.335375409080974
At time: 478.72925329208374 and batch: 1550, loss is 3.649911503791809 and perplexity is 38.47126133762962
At time: 479.63202691078186 and batch: 1600, loss is 3.738286590576172 and perplexity is 42.02592083169299
At time: 480.53246450424194 and batch: 1650, loss is 3.685745511054993 and perplexity is 39.87483850458265
At time: 481.4324073791504 and batch: 1700, loss is 3.704867401123047 and perplexity is 40.64465752360463
At time: 482.3321444988251 and batch: 1750, loss is 3.694774932861328 and perplexity is 40.23651565135269
At time: 483.2329571247101 and batch: 1800, loss is 3.653198628425598 and perplexity is 38.597929241002355
At time: 484.13360261917114 and batch: 1850, loss is 3.6713213396072386 and perplexity is 39.30380523897855
At time: 485.0374710559845 and batch: 1900, loss is 3.7595177936553954 and perplexity is 42.92772096771033
At time: 485.9382014274597 and batch: 1950, loss is 3.699327173233032 and perplexity is 40.42009948415289
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2735595703125 and perplexity of 71.77667555707538
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 488.87969756126404 and batch: 50, loss is 3.8505125999450684 and perplexity is 47.017158048183624
At time: 489.8034999370575 and batch: 100, loss is 3.844282698631287 and perplexity is 46.72515630892082
At time: 490.70465445518494 and batch: 150, loss is 3.8155206489562987 and perplexity is 45.400387895125505
At time: 491.604220867157 and batch: 200, loss is 3.828965606689453 and perplexity is 46.0149160870596
At time: 492.5031077861786 and batch: 250, loss is 3.828975324630737 and perplexity is 46.01536325948513
At time: 493.4253327846527 and batch: 300, loss is 3.831005153656006 and perplexity is 46.108861439995174
At time: 494.32633352279663 and batch: 350, loss is 3.8363095331192016 and perplexity is 46.35409015578237
At time: 495.22594380378723 and batch: 400, loss is 3.7970204734802246 and perplexity is 44.56819435085166
At time: 496.12600779533386 and batch: 450, loss is 3.841815929412842 and perplexity is 46.61003817491967
At time: 497.0257294178009 and batch: 500, loss is 3.860868396759033 and perplexity is 47.50658802844796
At time: 497.926317691803 and batch: 550, loss is 3.8307576608657836 and perplexity is 46.09745124125262
At time: 498.82631850242615 and batch: 600, loss is 3.8087731170654298 and perplexity is 45.09507853065504
At time: 499.7271058559418 and batch: 650, loss is 3.8372905683517455 and perplexity is 46.39958746498037
At time: 500.6269865036011 and batch: 700, loss is 3.847461071014404 and perplexity is 46.8739025155274
At time: 501.5274341106415 and batch: 750, loss is 3.808228178024292 and perplexity is 45.070511156269184
At time: 502.4291455745697 and batch: 800, loss is 3.7729326391220095 and perplexity is 43.507469635944375
At time: 503.32920384407043 and batch: 850, loss is 3.772965121269226 and perplexity is 43.5088828749305
At time: 504.2289924621582 and batch: 900, loss is 3.74543728351593 and perplexity is 42.327512295957696
At time: 505.12931060791016 and batch: 950, loss is 3.853197956085205 and perplexity is 47.14358553768387
At time: 506.02993965148926 and batch: 1000, loss is 3.812043685913086 and perplexity is 45.24280653530246
At time: 506.93037605285645 and batch: 1050, loss is 3.758538312911987 and perplexity is 42.885694676995236
At time: 507.83141684532166 and batch: 1100, loss is 3.7677892446517944 and perplexity is 43.284268056148534
At time: 508.73112440109253 and batch: 1150, loss is 3.7551656103134157 and perplexity is 42.74129762415209
At time: 509.63103127479553 and batch: 1200, loss is 3.7994013357162477 and perplexity is 44.674431499533206
At time: 510.5310297012329 and batch: 1250, loss is 3.783629631996155 and perplexity is 43.975366813387
At time: 511.43271350860596 and batch: 1300, loss is 3.785481586456299 and perplexity is 44.05688264860268
At time: 512.3331916332245 and batch: 1350, loss is 3.6793485498428344 and perplexity is 39.620574833809656
At time: 513.2340297698975 and batch: 1400, loss is 3.690370111465454 and perplexity is 40.05967075733792
At time: 514.1343343257904 and batch: 1450, loss is 3.615015621185303 and perplexity is 37.15192627823836
At time: 515.0343148708344 and batch: 1500, loss is 3.6318112325668337 and perplexity is 37.781185195833295
At time: 515.9341187477112 and batch: 1550, loss is 3.639854521751404 and perplexity is 38.08629559477316
At time: 516.8344597816467 and batch: 1600, loss is 3.725521264076233 and perplexity is 41.49285584384048
At time: 517.7347626686096 and batch: 1650, loss is 3.6734890604019164 and perplexity is 39.38909732622156
At time: 518.634952545166 and batch: 1700, loss is 3.691804876327515 and perplexity is 40.117188217474784
At time: 519.5354619026184 and batch: 1750, loss is 3.680328855514526 and perplexity is 39.65943415192792
At time: 520.4350135326385 and batch: 1800, loss is 3.6348761510849 and perplexity is 37.89715908444835
At time: 521.3351919651031 and batch: 1850, loss is 3.6510479974746706 and perplexity is 38.51500853761104
At time: 522.2353279590607 and batch: 1900, loss is 3.7375305128097533 and perplexity is 41.99415797644632
At time: 523.13525223732 and batch: 1950, loss is 3.683137912750244 and perplexity is 39.77099639139526
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.262429596656977 and perplexity of 70.98223231625609
finished 14 epochs...
Completing Train Step...
At time: 526.0807523727417 and batch: 50, loss is 3.8488694715499876 and perplexity is 46.93996625611868
At time: 527.0026097297668 and batch: 100, loss is 3.8325034046173094 and perplexity is 46.177995863397925
At time: 527.904130935669 and batch: 150, loss is 3.799945368766785 and perplexity is 44.6987424791715
At time: 528.8025968074799 and batch: 200, loss is 3.810409731864929 and perplexity is 45.16894223028783
At time: 529.7015931606293 and batch: 250, loss is 3.8103892993927 and perplexity is 45.16801932655874
At time: 530.5993258953094 and batch: 300, loss is 3.8111179780960085 and perplexity is 45.20094429471732
At time: 531.4969255924225 and batch: 350, loss is 3.8156082153320314 and perplexity is 45.40436361661756
At time: 532.3949210643768 and batch: 400, loss is 3.7772212743759157 and perplexity is 43.69445797983836
At time: 533.2930862903595 and batch: 450, loss is 3.822393550872803 and perplexity is 45.71349505297904
At time: 534.1902668476105 and batch: 500, loss is 3.8435527753829954 and perplexity is 46.69106297532301
At time: 535.0871901512146 and batch: 550, loss is 3.8139675521850585 and perplexity is 45.32993142629205
At time: 535.9839663505554 and batch: 600, loss is 3.793252429962158 and perplexity is 44.400575450993735
At time: 536.8801267147064 and batch: 650, loss is 3.8221208000183107 and perplexity is 45.701028358369605
At time: 537.8008227348328 and batch: 700, loss is 3.835073585510254 and perplexity is 46.29683431878532
At time: 538.7015097141266 and batch: 750, loss is 3.7977469301223756 and perplexity is 44.600582974707585
At time: 539.6172006130219 and batch: 800, loss is 3.7625099182128907 and perplexity is 43.05635840946718
At time: 540.523282289505 and batch: 850, loss is 3.7629311895370483 and perplexity is 43.074500639720114
At time: 541.42218708992 and batch: 900, loss is 3.7363078594207764 and perplexity is 41.94284505223175
At time: 542.3215827941895 and batch: 950, loss is 3.8439434337615968 and perplexity is 46.70930679359833
At time: 543.2206237316132 and batch: 1000, loss is 3.803748869895935 and perplexity is 44.86907792684826
At time: 544.1190419197083 and batch: 1050, loss is 3.750879936218262 and perplexity is 42.55851430676024
At time: 545.0462229251862 and batch: 1100, loss is 3.7610181522369386 and perplexity is 42.992176283202035
At time: 545.9722163677216 and batch: 1150, loss is 3.7488773679733276 and perplexity is 42.47337325629322
At time: 546.8723993301392 and batch: 1200, loss is 3.793825707435608 and perplexity is 44.426036598161744
At time: 547.7725768089294 and batch: 1250, loss is 3.7791967964172364 and perplexity is 43.78086266373898
At time: 548.6730153560638 and batch: 1300, loss is 3.781509509086609 and perplexity is 43.88223239384452
At time: 549.5742859840393 and batch: 1350, loss is 3.6762180042266848 and perplexity is 39.49673476159124
At time: 550.4776475429535 and batch: 1400, loss is 3.6879619216918944 and perplexity is 39.96331553528482
At time: 551.3802826404572 and batch: 1450, loss is 3.6144546842575074 and perplexity is 37.131092234688644
At time: 552.2803027629852 and batch: 1500, loss is 3.632483220100403 and perplexity is 37.80658221357232
At time: 553.1810619831085 and batch: 1550, loss is 3.641220293045044 and perplexity is 38.138348301932886
At time: 554.081295967102 and batch: 1600, loss is 3.7276009130477905 and perplexity is 41.579236208108476
At time: 554.9818279743195 and batch: 1650, loss is 3.6759909915924074 and perplexity is 39.48776952143755
At time: 555.8828227519989 and batch: 1700, loss is 3.695142664909363 and perplexity is 40.25131462852127
At time: 556.7835850715637 and batch: 1750, loss is 3.684542098045349 and perplexity is 39.82688146701788
At time: 557.6855864524841 and batch: 1800, loss is 3.639178223609924 and perplexity is 38.060546611822645
At time: 558.587366104126 and batch: 1850, loss is 3.6558868980407713 and perplexity is 38.70183047608345
At time: 559.4876532554626 and batch: 1900, loss is 3.74231164932251 and perplexity is 42.19541852215291
At time: 560.3883819580078 and batch: 1950, loss is 3.687335796356201 and perplexity is 39.938301322763174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26134515806686 and perplexity of 70.90529816703946
finished 15 epochs...
Completing Train Step...
At time: 563.3435535430908 and batch: 50, loss is 3.8450790357589724 and perplexity is 46.76238010506485
At time: 564.2710046768188 and batch: 100, loss is 3.8271303844451903 and perplexity is 45.93054593216143
At time: 565.1722118854523 and batch: 150, loss is 3.793731565475464 and perplexity is 44.4218544408563
At time: 566.0734016895294 and batch: 200, loss is 3.8032279586791993 and perplexity is 44.84571120739309
At time: 566.9727363586426 and batch: 250, loss is 3.8029672956466674 and perplexity is 44.83402311170713
At time: 567.8738157749176 and batch: 300, loss is 3.803371410369873 and perplexity is 44.85214486193354
At time: 568.7742114067078 and batch: 350, loss is 3.807826828956604 and perplexity is 45.052425778153996
At time: 569.6738204956055 and batch: 400, loss is 3.7692870569229124 and perplexity is 43.34914834110327
At time: 570.5746309757233 and batch: 450, loss is 3.81468120098114 and perplexity is 45.36229262317203
At time: 571.4739434719086 and batch: 500, loss is 3.8361464023590086 and perplexity is 46.346528994562966
At time: 572.3732793331146 and batch: 550, loss is 3.8065852737426757 and perplexity is 44.99652541290465
At time: 573.2740302085876 and batch: 600, loss is 3.786336717605591 and perplexity is 44.094573174170655
At time: 574.1745479106903 and batch: 650, loss is 3.815349383354187 and perplexity is 45.392613036158494
At time: 575.0753836631775 and batch: 700, loss is 3.829109773635864 and perplexity is 46.02155039521372
At time: 575.9758048057556 and batch: 750, loss is 3.79236451625824 and perplexity is 44.361169068911245
At time: 576.8762640953064 and batch: 800, loss is 3.757196798324585 and perplexity is 42.82820146460908
At time: 577.7772963047028 and batch: 850, loss is 3.757718267440796 and perplexity is 42.850540873125304
At time: 578.6777424812317 and batch: 900, loss is 3.73152286529541 and perplexity is 41.74262818533807
At time: 579.5769634246826 and batch: 950, loss is 3.839098687171936 and perplexity is 46.48355932499773
At time: 580.4754073619843 and batch: 1000, loss is 3.7993737697601317 and perplexity is 44.67320002308848
At time: 581.3742272853851 and batch: 1050, loss is 3.7469406223297117 and perplexity is 42.39119274273339
At time: 582.2747721672058 and batch: 1100, loss is 3.7573654222488404 and perplexity is 42.8354239329322
At time: 583.199117898941 and batch: 1150, loss is 3.7454949712753294 and perplexity is 42.32995414573474
At time: 584.0996069908142 and batch: 1200, loss is 3.7907877159118653 and perplexity is 44.29127548075618
At time: 585.0013785362244 and batch: 1250, loss is 3.7767185306549074 and perplexity is 43.67249638643529
At time: 585.9026165008545 and batch: 1300, loss is 3.7794464874267577 and perplexity is 43.79179571642088
At time: 586.8039953708649 and batch: 1350, loss is 3.6743399906158447 and perplexity is 39.42262896375425
At time: 587.704521894455 and batch: 1400, loss is 3.686500825881958 and perplexity is 39.90496793849969
At time: 588.6049540042877 and batch: 1450, loss is 3.6136711263656616 and perplexity is 37.10200926991657
At time: 589.5074849128723 and batch: 1500, loss is 3.632131357192993 and perplexity is 37.79328181973027
At time: 590.408310174942 and batch: 1550, loss is 3.6411240100860596 and perplexity is 38.134676405680956
At time: 591.3087933063507 and batch: 1600, loss is 3.7279728841781616 and perplexity is 41.59470536046146
At time: 592.2093768119812 and batch: 1650, loss is 3.676465940475464 and perplexity is 39.50652864792661
At time: 593.109349489212 and batch: 1700, loss is 3.695885763168335 and perplexity is 40.28123642638412
At time: 594.0092718601227 and batch: 1750, loss is 3.685740509033203 and perplexity is 39.87463905027043
At time: 594.9093005657196 and batch: 1800, loss is 3.640528688430786 and perplexity is 38.1119807632738
At time: 595.8097941875458 and batch: 1850, loss is 3.657628893852234 and perplexity is 38.76930765808937
At time: 596.7106008529663 and batch: 1900, loss is 3.7439219427108763 and perplexity is 42.26342026230047
At time: 597.6107544898987 and batch: 1950, loss is 3.6886013078689577 and perplexity is 39.98887569736408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261080009992733 and perplexity of 70.8865002560101
finished 16 epochs...
Completing Train Step...
At time: 600.5716924667358 and batch: 50, loss is 3.841167516708374 and perplexity is 46.57982543023362
At time: 601.4710824489594 and batch: 100, loss is 3.822481894493103 and perplexity is 45.71753372702151
At time: 602.3701264858246 and batch: 150, loss is 3.7886645221710205 and perplexity is 44.19733628272948
At time: 603.2709362506866 and batch: 200, loss is 3.7978805541992187 and perplexity is 44.60654308463246
At time: 604.1713814735413 and batch: 250, loss is 3.7974619913101195 and perplexity is 44.58787634796038
At time: 605.074282169342 and batch: 300, loss is 3.797689075469971 and perplexity is 44.59800269812375
At time: 605.9992537498474 and batch: 350, loss is 3.8022461414337156 and perplexity is 44.80170252252181
At time: 606.8990478515625 and batch: 400, loss is 3.7636567115783692 and perplexity is 43.105763478921226
At time: 607.7989311218262 and batch: 450, loss is 3.809230742454529 and perplexity is 45.1157199061626
At time: 608.6980164051056 and batch: 500, loss is 3.830876979827881 and perplexity is 46.102951869448155
At time: 609.597056388855 and batch: 550, loss is 3.80126953125 and perplexity is 44.75797008183986
At time: 610.4947617053986 and batch: 600, loss is 3.7813880109786986 and perplexity is 43.87690110951481
At time: 611.3915755748749 and batch: 650, loss is 3.810498204231262 and perplexity is 45.1729386102737
At time: 612.2880470752716 and batch: 700, loss is 3.8247082662582397 and perplexity is 45.819431342179776
At time: 613.1868822574615 and batch: 750, loss is 3.788275246620178 and perplexity is 44.180134688599495
At time: 614.0866847038269 and batch: 800, loss is 3.75320077419281 and perplexity is 42.65740042785044
At time: 614.9858672618866 and batch: 850, loss is 3.753745102882385 and perplexity is 42.68062639543279
At time: 615.8847751617432 and batch: 900, loss is 3.7277947425842286 and perplexity is 41.587296273302265
At time: 616.7829604148865 and batch: 950, loss is 3.835395884513855 and perplexity is 46.311758147194475
At time: 617.6822052001953 and batch: 1000, loss is 3.795985746383667 and perplexity is 44.52210228298038
At time: 618.5809597969055 and batch: 1050, loss is 3.743871636390686 and perplexity is 42.26129419862608
At time: 619.4799253940582 and batch: 1100, loss is 3.7544639539718627 and perplexity is 42.71131844040005
At time: 620.3786795139313 and batch: 1150, loss is 3.7427710628509523 and perplexity is 42.21480812184145
At time: 621.2769446372986 and batch: 1200, loss is 3.7882612133026123 and perplexity is 44.17951469908957
At time: 622.176628112793 and batch: 1250, loss is 3.7745876121520996 and perplexity is 43.5795329397634
At time: 623.0742745399475 and batch: 1300, loss is 3.7775992441177366 and perplexity is 43.710976284352995
At time: 623.9721572399139 and batch: 1350, loss is 3.6725575590133666 and perplexity is 39.35242341092179
At time: 624.870099067688 and batch: 1400, loss is 3.6850145769119265 and perplexity is 39.845703272935346
At time: 625.7700848579407 and batch: 1450, loss is 3.612535538673401 and perplexity is 37.0599005984012
At time: 626.6690380573273 and batch: 1500, loss is 3.631223282814026 and perplexity is 37.758978286249835
At time: 627.5681858062744 and batch: 1550, loss is 3.640343041419983 and perplexity is 38.10490604468982
At time: 628.4669420719147 and batch: 1600, loss is 3.727540259361267 and perplexity is 41.576714350630375
At time: 629.3659677505493 and batch: 1650, loss is 3.6761093854904177 and perplexity is 39.49244490915815
At time: 630.2650990486145 and batch: 1700, loss is 3.695679154396057 and perplexity is 40.272914829267314
At time: 631.1645219326019 and batch: 1750, loss is 3.685822620391846 and perplexity is 39.87791334548481
At time: 632.0640416145325 and batch: 1800, loss is 3.6408135223388673 and perplexity is 38.122837893865395
At time: 632.9629073143005 and batch: 1850, loss is 3.6582209634780884 and perplexity is 38.79226858413184
At time: 633.8620433807373 and batch: 1900, loss is 3.744452939033508 and perplexity is 42.28586794233193
At time: 634.7621278762817 and batch: 1950, loss is 3.6889052772521973 and perplexity is 40.00103293886725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261079442223838 and perplexity of 70.8864600088716
finished 17 epochs...
Completing Train Step...
At time: 637.7454743385315 and batch: 50, loss is 3.8374225997924807 and perplexity is 46.405714073806486
At time: 638.6471045017242 and batch: 100, loss is 3.8182746315002443 and perplexity is 45.52559209683658
At time: 639.5494530200958 and batch: 150, loss is 3.7842091941833496 and perplexity is 44.00086066008123
At time: 640.4510533809662 and batch: 200, loss is 3.7933084058761595 and perplexity is 44.40306088334832
At time: 641.3527932167053 and batch: 250, loss is 3.792789673805237 and perplexity is 44.38003356464171
At time: 642.2544782161713 and batch: 300, loss is 3.7929191112518312 and perplexity is 44.385778374654834
At time: 643.1577696800232 and batch: 350, loss is 3.7976194524765017 and perplexity is 44.59489775976197
At time: 644.0605823993683 and batch: 400, loss is 3.7590188550949097 and perplexity is 42.906308014723955
At time: 644.9622943401337 and batch: 450, loss is 3.8047401762008666 and perplexity is 44.91357898013675
At time: 645.8635065555573 and batch: 500, loss is 3.8265492630004885 and perplexity is 45.90386246087301
At time: 646.7657492160797 and batch: 550, loss is 3.796865725517273 and perplexity is 44.56129804717166
At time: 647.6681101322174 and batch: 600, loss is 3.7772846269607543 and perplexity is 43.697226224381296
At time: 648.5705087184906 and batch: 650, loss is 3.806478762626648 and perplexity is 44.99173303799068
At time: 649.4727554321289 and batch: 700, loss is 3.8210104846954347 and perplexity is 45.65031396600565
At time: 650.3979432582855 and batch: 750, loss is 3.78478346824646 and perplexity is 44.02613647003924
At time: 651.2998580932617 and batch: 800, loss is 3.7497898006439208 and perplexity is 42.5121450353116
At time: 652.201397895813 and batch: 850, loss is 3.750335330963135 and perplexity is 42.535343026391615
At time: 653.1022760868073 and batch: 900, loss is 3.724553370475769 and perplexity is 41.4527146035628
At time: 654.0040712356567 and batch: 950, loss is 3.83221004486084 and perplexity is 46.16445108462082
At time: 654.9067413806915 and batch: 1000, loss is 3.793020696640015 and perplexity is 44.390287550210154
At time: 655.8321704864502 and batch: 1050, loss is 3.741165509223938 and perplexity is 42.14708436515752
At time: 656.7336328029633 and batch: 1100, loss is 3.7518668794631957 and perplexity is 42.60053787899898
At time: 657.6354694366455 and batch: 1150, loss is 3.7403010940551757 and perplexity is 42.11066752801397
At time: 658.5384206771851 and batch: 1200, loss is 3.7859352159500124 and perplexity is 44.0768726836651
At time: 659.4403758049011 and batch: 1250, loss is 3.7725722217559814 and perplexity is 43.49179161382107
At time: 660.3428814411163 and batch: 1300, loss is 3.7757952928543093 and perplexity is 43.63219489371824
At time: 661.2451226711273 and batch: 1350, loss is 3.670786390304565 and perplexity is 39.282785318570696
At time: 662.1465895175934 and batch: 1400, loss is 3.6834678554534914 and perplexity is 39.78412070647241
At time: 663.0486304759979 and batch: 1450, loss is 3.6112099933624267 and perplexity is 37.01080856498335
At time: 663.95210313797 and batch: 1500, loss is 3.6300341987609865 and perplexity is 37.71410637083723
At time: 664.855272769928 and batch: 1550, loss is 3.63923583984375 and perplexity is 38.06273958035045
At time: 665.7553272247314 and batch: 1600, loss is 3.7267123889923095 and perplexity is 41.54230846455274
At time: 666.6586048603058 and batch: 1650, loss is 3.6753475046157837 and perplexity is 39.46236782972001
At time: 667.5770444869995 and batch: 1700, loss is 3.695037431716919 and perplexity is 40.247079077047054
At time: 668.4795925617218 and batch: 1750, loss is 3.6853959226608275 and perplexity is 39.86090116013111
At time: 669.3857517242432 and batch: 1800, loss is 3.6406084966659544 and perplexity is 38.11502253457488
At time: 670.2908759117126 and batch: 1850, loss is 3.6582635545730593 and perplexity is 38.793920824512355
At time: 671.2035603523254 and batch: 1900, loss is 3.7444774961471556 and perplexity is 42.28690637394706
At time: 672.1399002075195 and batch: 1950, loss is 3.6887654495239257 and perplexity is 39.99544007633063
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261201228651889 and perplexity of 70.89509354334629
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 675.5249841213226 and batch: 50, loss is 3.836573534011841 and perplexity is 46.36632929246141
At time: 676.4378452301025 and batch: 100, loss is 3.821646361351013 and perplexity is 45.67935116603687
At time: 677.3470685482025 and batch: 150, loss is 3.7894792890548707 and perplexity is 44.2333614827641
At time: 678.2675890922546 and batch: 200, loss is 3.7999973821640016 and perplexity is 44.70106747308406
At time: 679.18989777565 and batch: 250, loss is 3.8006423997879026 and perplexity is 44.72990975029996
At time: 680.1315593719482 and batch: 300, loss is 3.801028447151184 and perplexity is 44.74718094755447
At time: 681.0668649673462 and batch: 350, loss is 3.807899627685547 and perplexity is 45.055705656870494
At time: 681.9919128417969 and batch: 400, loss is 3.771474781036377 and perplexity is 43.4440881313953
At time: 682.899729013443 and batch: 450, loss is 3.817295527458191 and perplexity is 45.48103961991199
At time: 683.8040437698364 and batch: 500, loss is 3.838580927848816 and perplexity is 46.45949825824373
At time: 684.7152183055878 and batch: 550, loss is 3.80910719871521 and perplexity is 45.11014648571103
At time: 685.6333961486816 and batch: 600, loss is 3.7885669708251952 and perplexity is 44.193024983383154
At time: 686.5656759738922 and batch: 650, loss is 3.814686403274536 and perplexity is 45.36252861174121
At time: 687.4883496761322 and batch: 700, loss is 3.8286526918411257 and perplexity is 46.000519589127876
At time: 688.39537358284 and batch: 750, loss is 3.790985403060913 and perplexity is 44.30003216224684
At time: 689.2923309803009 and batch: 800, loss is 3.7559179782867433 and perplexity is 42.773466907674816
At time: 690.192268371582 and batch: 850, loss is 3.7563926458358763 and perplexity is 42.79377490377187
At time: 691.0927312374115 and batch: 900, loss is 3.7255210161209105 and perplexity is 41.492845555467305
At time: 691.9971990585327 and batch: 950, loss is 3.833951177597046 and perplexity is 46.244899537046706
At time: 692.8994355201721 and batch: 1000, loss is 3.7939857053756714 and perplexity is 44.43314524117159
At time: 693.7999279499054 and batch: 1050, loss is 3.7441564655303954 and perplexity is 42.27333316113796
At time: 694.706592798233 and batch: 1100, loss is 3.751452956199646 and perplexity is 42.58290817425531
At time: 695.6104264259338 and batch: 1150, loss is 3.7421930027008057 and perplexity is 42.19041247527501
At time: 696.649307012558 and batch: 1200, loss is 3.786652464866638 and perplexity is 44.10849811314244
At time: 697.5521733760834 and batch: 1250, loss is 3.771521096229553 and perplexity is 43.44610029932608
At time: 698.4543724060059 and batch: 1300, loss is 3.774716753959656 and perplexity is 43.58516124283649
At time: 699.3552062511444 and batch: 1350, loss is 3.668313055038452 and perplexity is 39.18574587529873
At time: 700.2549469470978 and batch: 1400, loss is 3.681156735420227 and perplexity is 39.692280995278495
At time: 701.1552927494049 and batch: 1450, loss is 3.604816908836365 and perplexity is 36.774950072413354
At time: 702.0549819469452 and batch: 1500, loss is 3.6209068202972414 and perplexity is 37.37144164281716
At time: 702.9547839164734 and batch: 1550, loss is 3.6304179859161376 and perplexity is 37.728583338289745
At time: 703.8545894622803 and batch: 1600, loss is 3.718538341522217 and perplexity is 41.20412371522745
At time: 704.7837567329407 and batch: 1650, loss is 3.664806046485901 and perplexity is 39.04856182280209
At time: 705.716249704361 and batch: 1700, loss is 3.684800219535828 and perplexity is 39.83716296790434
At time: 706.6417210102081 and batch: 1750, loss is 3.6769740915298463 and perplexity is 39.52660903361652
At time: 707.5469839572906 and batch: 1800, loss is 3.6309245300292967 and perplexity is 37.74769937122581
At time: 708.4467780590057 and batch: 1850, loss is 3.6502004146575926 and perplexity is 38.482377708793344
At time: 709.3492667675018 and batch: 1900, loss is 3.735183973312378 and perplexity is 41.89573255083283
At time: 710.2504894733429 and batch: 1950, loss is 3.682311716079712 and perplexity is 39.73815129671521
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258846974927326 and perplexity of 70.72838481963417
finished 19 epochs...
Completing Train Step...
At time: 713.2274122238159 and batch: 50, loss is 3.8364916181564332 and perplexity is 46.362531310494894
At time: 714.1713809967041 and batch: 100, loss is 3.8185201597213747 and perplexity is 45.53677128682718
At time: 715.07776927948 and batch: 150, loss is 3.784953808784485 and perplexity is 44.033636544577945
At time: 715.9781210422516 and batch: 200, loss is 3.794667935371399 and perplexity is 44.46346920844351
At time: 716.8778643608093 and batch: 250, loss is 3.795022168159485 and perplexity is 44.479222417095976
At time: 717.7773258686066 and batch: 300, loss is 3.7942197799682615 and perplexity is 44.44354712890274
At time: 718.6776247024536 and batch: 350, loss is 3.7998238134384157 and perplexity is 44.693309439065935
At time: 719.5992860794067 and batch: 400, loss is 3.763574604988098 and perplexity is 43.102224356955546
At time: 720.4978716373444 and batch: 450, loss is 3.8094794178009033 and perplexity is 45.126940468517994
At time: 721.400039434433 and batch: 500, loss is 3.8315274286270142 and perplexity is 46.132949233945375
At time: 722.3001606464386 and batch: 550, loss is 3.8017476987838745 and perplexity is 44.779377007655704
At time: 723.200028181076 and batch: 600, loss is 3.782117986679077 and perplexity is 43.908941874199705
At time: 724.1000168323517 and batch: 650, loss is 3.808888373374939 and perplexity is 45.10027632251691
At time: 725.0011899471283 and batch: 700, loss is 3.823697600364685 and perplexity is 45.77314659880572
At time: 725.8999769687653 and batch: 750, loss is 3.7869167137145996 and perplexity is 44.12015527308185
At time: 726.7987062931061 and batch: 800, loss is 3.752197299003601 and perplexity is 42.61461625490315
At time: 727.698127746582 and batch: 850, loss is 3.7524225187301634 and perplexity is 42.624214987995074
At time: 728.5975344181061 and batch: 900, loss is 3.722487111091614 and perplexity is 41.36715097178534
At time: 729.4974851608276 and batch: 950, loss is 3.8307480239868164 and perplexity is 46.097007007834826
At time: 730.3968527317047 and batch: 1000, loss is 3.791146478652954 and perplexity is 44.3071683908755
At time: 731.2966148853302 and batch: 1050, loss is 3.740869255065918 and perplexity is 42.134599965534875
At time: 732.1950097084045 and batch: 1100, loss is 3.7488500261306763 and perplexity is 42.47221197188068
At time: 733.0945074558258 and batch: 1150, loss is 3.739259428977966 and perplexity is 42.06682515477093
At time: 733.9951322078705 and batch: 1200, loss is 3.784374032020569 and perplexity is 44.00811426460605
At time: 734.8940091133118 and batch: 1250, loss is 3.770001282691956 and perplexity is 43.38012047914751
At time: 735.7933051586151 and batch: 1300, loss is 3.7729155254364013 and perplexity is 43.50672506915858
At time: 736.6934623718262 and batch: 1350, loss is 3.6672622776031494 and perplexity is 39.14459200331411
At time: 737.593287229538 and batch: 1400, loss is 3.6804694080352784 and perplexity is 39.66500877712422
At time: 738.4907691478729 and batch: 1450, loss is 3.604945216178894 and perplexity is 36.779668871250585
At time: 739.3895215988159 and batch: 1500, loss is 3.6219135427474978 and perplexity is 37.409083256266975
At time: 740.2889869213104 and batch: 1550, loss is 3.6320314979553223 and perplexity is 37.789507999847196
At time: 741.1881194114685 and batch: 1600, loss is 3.720306386947632 and perplexity is 41.27703891737088
At time: 742.0873346328735 and batch: 1650, loss is 3.6673882579803467 and perplexity is 39.14952376442596
At time: 742.986170053482 and batch: 1700, loss is 3.687785573005676 and perplexity is 39.95626867846348
At time: 743.8860540390015 and batch: 1750, loss is 3.6799129676818847 and perplexity is 39.64294370514046
At time: 744.7856001853943 and batch: 1800, loss is 3.6337080574035645 and perplexity is 37.852917496571294
At time: 745.6832473278046 and batch: 1850, loss is 3.6530591583251955 and perplexity is 38.59254635932003
At time: 746.5810759067535 and batch: 1900, loss is 3.7380400848388673 and perplexity is 42.01556247784175
At time: 747.4803156852722 and batch: 1950, loss is 3.684931058883667 and perplexity is 39.8423755773266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25828488372093 and perplexity of 70.68864018758501
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
2314.323786497116


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.68864018758501}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.09000677972055571, 'batch_size': 32, 'rnn_dropout': 0.41910426663286526, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4300930500030518 and batch: 50, loss is 7.584774284362793 and perplexity is 1968.0023748866029
At time: 2.3932383060455322 and batch: 100, loss is 6.752358856201172 and perplexity is 856.0757422816636
At time: 3.357426643371582 and batch: 150, loss is 6.455707120895386 and perplexity is 636.3235248636817
At time: 4.322777271270752 and batch: 200, loss is 6.216863660812378 and perplexity is 501.12905404233277
At time: 5.286888837814331 and batch: 250, loss is 6.02901912689209 and perplexity is 415.3074656059617
At time: 6.251511812210083 and batch: 300, loss is 5.894862098693848 and perplexity is 363.1667512762597
At time: 7.215235471725464 and batch: 350, loss is 5.80082142829895 and perplexity is 330.57098877970463
At time: 8.180207014083862 and batch: 400, loss is 5.707462377548218 and perplexity is 301.10600461429755
At time: 9.144952535629272 and batch: 450, loss is 5.597720556259155 and perplexity is 269.81068766026874
At time: 10.134471416473389 and batch: 500, loss is 5.547185411453247 and perplexity is 256.5145559780805
At time: 11.099441766738892 and batch: 550, loss is 5.470823068618774 and perplexity is 237.65571924885643
At time: 12.06403660774231 and batch: 600, loss is 5.475230073928833 and perplexity is 238.70538049805188
At time: 13.029378652572632 and batch: 650, loss is 5.523577165603638 and perplexity is 250.52962214352078
At time: 13.994124174118042 and batch: 700, loss is 5.458607406616211 and perplexity is 234.77025710587543
At time: 14.959530353546143 and batch: 750, loss is 5.396563005447388 and perplexity is 220.64674979026694
At time: 15.923542737960815 and batch: 800, loss is 5.370241317749024 and perplexity is 214.91472418461146
At time: 16.889153242111206 and batch: 850, loss is 5.366343460083008 and perplexity is 214.07864769155546
At time: 17.854006052017212 and batch: 900, loss is 5.367240619659424 and perplexity is 214.27079658165832
At time: 18.818893909454346 and batch: 950, loss is 5.398467817306519 and perplexity is 221.0674408774323
At time: 19.784003496170044 and batch: 1000, loss is 5.360248165130615 and perplexity is 212.7777439146415
At time: 20.748878717422485 and batch: 1050, loss is 5.243106174468994 and perplexity is 189.25705577868573
At time: 21.71179175376892 and batch: 1100, loss is 5.331854906082153 and perplexity is 206.82125257299654
At time: 22.675084829330444 and batch: 1150, loss is 5.215994396209717 and perplexity is 184.19489264477133
At time: 23.63935136795044 and batch: 1200, loss is 5.29377142906189 and perplexity is 199.09287592961277
At time: 24.60508632659912 and batch: 1250, loss is 5.241997022628784 and perplexity is 189.04725733766762
At time: 25.570616006851196 and batch: 1300, loss is 5.2614436435699465 and perplexity is 192.75956663703388
At time: 26.53643798828125 and batch: 1350, loss is 5.186710109710694 and perplexity is 178.87909124610778
At time: 27.50194787979126 and batch: 1400, loss is 5.196687927246094 and perplexity is 180.67284818748485
At time: 28.467731714248657 and batch: 1450, loss is 5.14700291633606 and perplexity is 171.91547237481035
At time: 29.433262586593628 and batch: 1500, loss is 5.1141614818573 and perplexity is 166.3612255757379
At time: 30.39796018600464 and batch: 1550, loss is 5.09883635520935 and perplexity is 163.83115506736493
At time: 31.3623526096344 and batch: 1600, loss is 5.150272188186645 and perplexity is 172.47843051951867
At time: 32.326733112335205 and batch: 1650, loss is 5.11730507850647 and perplexity is 166.88502103648298
At time: 33.29156446456909 and batch: 1700, loss is 5.139015979766846 and perplexity is 170.547863175755
At time: 34.25655651092529 and batch: 1750, loss is 5.133534660339356 and perplexity is 169.6155932288576
At time: 35.227415800094604 and batch: 1800, loss is 5.1020283508300786 and perplexity is 164.3549389100159
At time: 36.1945104598999 and batch: 1850, loss is 5.087279062271119 and perplexity is 161.94860993304545
At time: 37.15868806838989 and batch: 1900, loss is 5.149386596679688 and perplexity is 172.32575270138517
At time: 38.123026609420776 and batch: 1950, loss is 5.07337495803833 and perplexity is 159.71244156454307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.767094385901163 and perplexity of 117.57711143904488
finished 1 epochs...
Completing Train Step...
At time: 41.09634017944336 and batch: 50, loss is 4.972871284484864 and perplexity is 144.44102380526903
At time: 42.01613140106201 and batch: 100, loss is 4.926057186126709 and perplexity is 137.83498187549137
At time: 42.90980529785156 and batch: 150, loss is 4.865063591003418 and perplexity is 129.67918477909774
At time: 43.82762050628662 and batch: 200, loss is 4.840188646316529 and perplexity is 126.49321195797373
At time: 44.72171497344971 and batch: 250, loss is 4.8447026443481445 and perplexity is 127.06549273317025
At time: 45.616416215896606 and batch: 300, loss is 4.851629791259765 and perplexity is 127.9487497623834
At time: 46.51076579093933 and batch: 350, loss is 4.84885350227356 and perplexity is 127.59401970204755
At time: 47.40369200706482 and batch: 400, loss is 4.8030611038208 and perplexity is 121.88294340137824
At time: 48.29728627204895 and batch: 450, loss is 4.777731666564941 and perplexity is 118.83448784977715
At time: 49.19209885597229 and batch: 500, loss is 4.765942049026489 and perplexity is 117.44170103210273
At time: 50.092432260513306 and batch: 550, loss is 4.726484127044678 and perplexity is 112.89792896887073
At time: 50.99123215675354 and batch: 600, loss is 4.7107012081146244 and perplexity is 111.13005788952898
At time: 51.89041566848755 and batch: 650, loss is 4.786096391677856 and perplexity is 119.83267463346328
At time: 52.790703773498535 and batch: 700, loss is 4.786276512145996 and perplexity is 119.8542608949221
At time: 53.68900394439697 and batch: 750, loss is 4.741980075836182 and perplexity is 114.66101455698123
At time: 54.58658790588379 and batch: 800, loss is 4.713055677413941 and perplexity is 111.39201846711448
At time: 55.4867742061615 and batch: 850, loss is 4.711001682281494 and perplexity is 111.16345461826336
At time: 56.38734793663025 and batch: 900, loss is 4.709005470275879 and perplexity is 110.9417701337986
At time: 57.28741717338562 and batch: 950, loss is 4.7658884239196775 and perplexity is 117.43540337719843
At time: 58.18758797645569 and batch: 1000, loss is 4.7388576412200925 and perplexity is 114.30355140410066
At time: 59.086082220077515 and batch: 1050, loss is 4.652280082702637 and perplexity is 104.82372005743639
At time: 59.985435962677 and batch: 1100, loss is 4.720160312652588 and perplexity is 112.18623609937785
At time: 60.88513255119324 and batch: 1150, loss is 4.6522088050842285 and perplexity is 104.81624873859005
At time: 61.78470015525818 and batch: 1200, loss is 4.726948986053467 and perplexity is 112.95042278839264
At time: 62.68367648124695 and batch: 1250, loss is 4.698717670440674 and perplexity is 109.80627430116311
At time: 63.583078384399414 and batch: 1300, loss is 4.710890264511108 and perplexity is 111.15106972396288
At time: 64.48316550254822 and batch: 1350, loss is 4.606063613891601 and perplexity is 100.08938271291036
At time: 65.38106942176819 and batch: 1400, loss is 4.614958744049073 and perplexity is 100.98366226952491
At time: 66.27959275245667 and batch: 1450, loss is 4.561934604644775 and perplexity is 95.76857505942493
At time: 67.17803192138672 and batch: 1500, loss is 4.555965566635132 and perplexity is 95.19863149439603
At time: 68.07800674438477 and batch: 1550, loss is 4.560295305252075 and perplexity is 95.61171030176985
At time: 68.9777421951294 and batch: 1600, loss is 4.622169246673584 and perplexity is 101.71443669063324
At time: 69.87700748443604 and batch: 1650, loss is 4.581793413162232 and perplexity is 97.68943471819462
At time: 70.77681636810303 and batch: 1700, loss is 4.6129240131378175 and perplexity is 100.77839659140237
At time: 71.67905974388123 and batch: 1750, loss is 4.6062944221496585 and perplexity is 100.11248683519288
At time: 72.5831208229065 and batch: 1800, loss is 4.564947891235351 and perplexity is 96.05758844384373
At time: 73.48209381103516 and batch: 1850, loss is 4.582440967559815 and perplexity is 97.75271442755955
At time: 74.3823504447937 and batch: 1900, loss is 4.671623916625976 and perplexity is 106.87115143311252
At time: 75.28165578842163 and batch: 1950, loss is 4.598272285461426 and perplexity is 99.31258353818365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508112281976744 and perplexity of 90.75034565214264
finished 2 epochs...
Completing Train Step...
At time: 78.25939202308655 and batch: 50, loss is 4.567904634475708 and perplexity is 96.34202636689231
At time: 79.18169808387756 and batch: 100, loss is 4.526791133880615 and perplexity is 92.4613883269598
At time: 80.08092832565308 and batch: 150, loss is 4.481824636459351 and perplexity is 88.39581584553801
At time: 80.9800636768341 and batch: 200, loss is 4.474620065689087 and perplexity is 87.76125056452263
At time: 81.87905669212341 and batch: 250, loss is 4.474971208572388 and perplexity is 87.79207271426053
At time: 82.77745366096497 and batch: 300, loss is 4.495370082855224 and perplexity is 89.6013227633047
At time: 83.67652726173401 and batch: 350, loss is 4.498596906661987 and perplexity is 89.89091742891438
At time: 84.57675099372864 and batch: 400, loss is 4.460198669433594 and perplexity is 86.50469322769882
At time: 85.47476649284363 and batch: 450, loss is 4.469589805603027 and perplexity is 87.32089712341498
At time: 86.37305235862732 and batch: 500, loss is 4.4638647365570066 and perplexity is 86.82240726421281
At time: 87.27240061759949 and batch: 550, loss is 4.4336662769317625 and perplexity is 84.23969750363614
At time: 88.19508171081543 and batch: 600, loss is 4.417933292388916 and perplexity is 82.92472697451419
At time: 89.09399962425232 and batch: 650, loss is 4.481331768035889 and perplexity is 88.35225907390203
At time: 89.99374842643738 and batch: 700, loss is 4.502180910110473 and perplexity is 90.21366480534597
At time: 90.89279389381409 and batch: 750, loss is 4.463900814056396 and perplexity is 86.82553965606199
At time: 91.7921040058136 and batch: 800, loss is 4.432610702514649 and perplexity is 84.15082314904566
At time: 92.69208335876465 and batch: 850, loss is 4.434111824035645 and perplexity is 84.27723861943747
At time: 93.59186220169067 and batch: 900, loss is 4.419058847427368 and perplexity is 83.01811586608197
At time: 94.4923529624939 and batch: 950, loss is 4.492302417755127 and perplexity is 89.32687708148528
At time: 95.3915867805481 and batch: 1000, loss is 4.473149471282959 and perplexity is 87.63228421220818
At time: 96.29176688194275 and batch: 1050, loss is 4.4012321090698245 and perplexity is 81.55128686938185
At time: 97.1918044090271 and batch: 1100, loss is 4.453852672576904 and perplexity is 85.95747288213879
At time: 98.0920684337616 and batch: 1150, loss is 4.408873891830444 and perplexity is 82.1768713334294
At time: 98.99145102500916 and batch: 1200, loss is 4.48084418296814 and perplexity is 88.30919033236655
At time: 99.89184927940369 and batch: 1250, loss is 4.458658437728882 and perplexity is 86.37155851205794
At time: 100.7909779548645 and batch: 1300, loss is 4.462645187377929 and perplexity is 86.71658760796116
At time: 101.68898105621338 and batch: 1350, loss is 4.351465139389038 and perplexity is 77.59206287265211
At time: 102.58736824989319 and batch: 1400, loss is 4.373211431503296 and perplexity is 79.29788294525551
At time: 103.48669910430908 and batch: 1450, loss is 4.313726897239685 and perplexity is 74.71843861631693
At time: 104.38695311546326 and batch: 1500, loss is 4.319636831283569 and perplexity is 75.161327092167
At time: 105.2860541343689 and batch: 1550, loss is 4.32601300239563 and perplexity is 75.64209969005253
At time: 106.18521189689636 and batch: 1600, loss is 4.400826892852783 and perplexity is 81.51824765988562
At time: 107.0846197605133 and batch: 1650, loss is 4.35389178276062 and perplexity is 77.78057977684902
At time: 107.98066258430481 and batch: 1700, loss is 4.383619117736816 and perplexity is 80.12750013899566
At time: 108.87743639945984 and batch: 1750, loss is 4.3793800258636475 and perplexity is 79.78855122969554
At time: 109.77583336830139 and batch: 1800, loss is 4.335912656784058 and perplexity is 76.39464917811128
At time: 110.67504572868347 and batch: 1850, loss is 4.366354837417602 and perplexity is 78.75602930810706
At time: 111.57419419288635 and batch: 1900, loss is 4.455137767791748 and perplexity is 86.06800742771549
At time: 112.47295665740967 and batch: 1950, loss is 4.385005979537964 and perplexity is 80.2387030018374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.42134896211846 and perplexity of 83.20845473858975
finished 3 epochs...
Completing Train Step...
At time: 115.44604110717773 and batch: 50, loss is 4.3617049741745 and perplexity is 78.39067462519449
At time: 116.3742322921753 and batch: 100, loss is 4.32264591217041 and perplexity is 75.38783422317863
At time: 117.27347874641418 and batch: 150, loss is 4.286667165756225 and perplexity is 72.72368815282596
At time: 118.17190885543823 and batch: 200, loss is 4.285207872390747 and perplexity is 72.61764035343586
At time: 119.07148313522339 and batch: 250, loss is 4.27823194026947 and perplexity is 72.11282744099591
At time: 119.97113585472107 and batch: 300, loss is 4.298335800170898 and perplexity is 73.57724451696444
At time: 120.87015533447266 and batch: 350, loss is 4.308028478622436 and perplexity is 74.29387250125548
At time: 121.76903176307678 and batch: 400, loss is 4.272559032440186 and perplexity is 71.70489618980747
At time: 122.66658759117126 and batch: 450, loss is 4.293708229064942 and perplexity is 73.23754717917582
At time: 123.56475496292114 and batch: 500, loss is 4.292517032623291 and perplexity is 73.15035881312609
At time: 124.46280217170715 and batch: 550, loss is 4.260415668487549 and perplexity is 70.83942305113484
At time: 125.36138439178467 and batch: 600, loss is 4.250710282325745 and perplexity is 70.1552246703291
At time: 126.26115155220032 and batch: 650, loss is 4.3103080749511715 and perplexity is 74.46342572328366
At time: 127.16052007675171 and batch: 700, loss is 4.335438232421875 and perplexity is 76.35841429143694
At time: 128.0594711303711 and batch: 750, loss is 4.300904359817505 and perplexity is 73.76647497896622
At time: 128.9580955505371 and batch: 800, loss is 4.270042786598205 and perplexity is 71.52469585217347
At time: 129.85789895057678 and batch: 850, loss is 4.275099487304687 and perplexity is 71.88729082671618
At time: 130.75760436058044 and batch: 900, loss is 4.254239602088928 and perplexity is 70.40326233590116
At time: 131.6678900718689 and batch: 950, loss is 4.331572742462158 and perplexity is 76.06382134750447
At time: 132.56587529182434 and batch: 1000, loss is 4.311138143539429 and perplexity is 74.52526113421628
At time: 133.48978567123413 and batch: 1050, loss is 4.246602277755738 and perplexity is 69.86761783633155
At time: 134.3893609046936 and batch: 1100, loss is 4.293413801193237 and perplexity is 73.21598717811935
At time: 135.2890465259552 and batch: 1150, loss is 4.256515040397644 and perplexity is 70.5636430150503
At time: 136.18787026405334 and batch: 1200, loss is 4.328356013298035 and perplexity is 75.81953774277969
At time: 137.08679604530334 and batch: 1250, loss is 4.31002631187439 and perplexity is 74.44244763490833
At time: 137.9866418838501 and batch: 1300, loss is 4.309636077880859 and perplexity is 74.41340332868594
At time: 138.88558721542358 and batch: 1350, loss is 4.197834763526917 and perplexity is 66.54209557299814
At time: 139.78486108779907 and batch: 1400, loss is 4.225861711502075 and perplexity is 68.43344803763928
At time: 140.68494844436646 and batch: 1450, loss is 4.161396455764771 and perplexity is 64.16105814869536
At time: 141.58364748954773 and batch: 1500, loss is 4.170257015228271 and perplexity is 64.73208710173097
At time: 142.48370265960693 and batch: 1550, loss is 4.180409870147705 and perplexity is 65.3926502171923
At time: 143.3830428123474 and batch: 1600, loss is 4.258220052719116 and perplexity is 70.68405752077581
At time: 144.28247117996216 and batch: 1650, loss is 4.210202760696411 and perplexity is 67.37019845370759
At time: 145.18174171447754 and batch: 1700, loss is 4.239420528411865 and perplexity is 69.36764361150894
At time: 146.08045625686646 and batch: 1750, loss is 4.239867210388184 and perplexity is 69.39863580896257
At time: 146.97963428497314 and batch: 1800, loss is 4.193489632606506 and perplexity is 66.25358870998186
At time: 147.87894988059998 and batch: 1850, loss is 4.227527303695679 and perplexity is 68.54752523114091
At time: 148.77862858772278 and batch: 1900, loss is 4.3190123653411865 and perplexity is 75.11440605503326
At time: 149.67776703834534 and batch: 1950, loss is 4.245058484077454 and perplexity is 69.75983986448047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386972826580669 and perplexity of 80.39667556055076
finished 4 epochs...
Completing Train Step...
At time: 152.65536308288574 and batch: 50, loss is 4.223693203926087 and perplexity is 68.28521037245835
At time: 153.55532813072205 and batch: 100, loss is 4.191024355888366 and perplexity is 66.09045644594907
At time: 154.45599722862244 and batch: 150, loss is 4.15538854598999 and perplexity is 63.77673993086816
At time: 155.35529589653015 and batch: 200, loss is 4.15527753829956 and perplexity is 63.769660615201786
At time: 156.27906107902527 and batch: 250, loss is 4.143032584190369 and perplexity is 62.99356536995591
At time: 157.17927622795105 and batch: 300, loss is 4.16987042427063 and perplexity is 64.70706709875323
At time: 158.07914423942566 and batch: 350, loss is 4.181746325492859 and perplexity is 65.48010299946128
At time: 158.97793126106262 and batch: 400, loss is 4.142005791664124 and perplexity is 62.928917243618876
At time: 159.87700128555298 and batch: 450, loss is 4.1744394826889035 and perplexity is 65.00339392016457
At time: 160.77750372886658 and batch: 500, loss is 4.178764457702637 and perplexity is 65.28514080962327
At time: 161.67598009109497 and batch: 550, loss is 4.143468289375305 and perplexity is 63.02101797319173
At time: 162.57538723945618 and batch: 600, loss is 4.132775521278381 and perplexity is 62.35073879902518
At time: 163.47611546516418 and batch: 650, loss is 4.192368235588074 and perplexity is 66.17933377555454
At time: 164.3775510787964 and batch: 700, loss is 4.215797152519226 and perplexity is 67.74814995971028
At time: 165.2780523300171 and batch: 750, loss is 4.186425752639771 and perplexity is 65.78723040073758
At time: 166.1781039237976 and batch: 800, loss is 4.155160508155823 and perplexity is 63.76219807933323
At time: 167.07788920402527 and batch: 850, loss is 4.161048555374146 and perplexity is 64.13874037390892
At time: 167.97790336608887 and batch: 900, loss is 4.139262166023254 and perplexity is 62.756500484393214
At time: 168.87851428985596 and batch: 950, loss is 4.21879771232605 and perplexity is 67.95173762119546
At time: 169.7769455909729 and batch: 1000, loss is 4.198598551750183 and perplexity is 66.59293905630341
At time: 170.67775130271912 and batch: 1050, loss is 4.139480338096619 and perplexity is 62.77019369390465
At time: 171.5775604248047 and batch: 1100, loss is 4.183776273727417 and perplexity is 65.6131592218753
At time: 172.47652053833008 and batch: 1150, loss is 4.150737161636353 and perplexity is 63.480778649068036
At time: 173.37616777420044 and batch: 1200, loss is 4.222210512161255 and perplexity is 68.1840394745422
At time: 174.27649569511414 and batch: 1250, loss is 4.202022809982299 and perplexity is 66.82136134131478
At time: 175.17753052711487 and batch: 1300, loss is 4.20073290348053 and perplexity is 66.73522359962348
At time: 176.07826399803162 and batch: 1350, loss is 4.093013958930969 and perplexity is 59.9202168941351
At time: 176.99979853630066 and batch: 1400, loss is 4.127336711883545 and perplexity is 62.01254553309032
At time: 177.90108466148376 and batch: 1450, loss is 4.056545271873474 and perplexity is 57.774371163742494
At time: 178.80117654800415 and batch: 1500, loss is 4.062411994934082 and perplexity is 58.114313598397835
At time: 179.70130276679993 and batch: 1550, loss is 4.074786043167114 and perplexity is 58.837890472825535
At time: 180.6018466949463 and batch: 1600, loss is 4.153737277984619 and perplexity is 63.671514342466914
At time: 181.50153398513794 and batch: 1650, loss is 4.109124336242676 and perplexity is 60.893372097675545
At time: 182.40221309661865 and batch: 1700, loss is 4.138606109619141 and perplexity is 62.715342182910554
At time: 183.3015615940094 and batch: 1750, loss is 4.136944313049316 and perplexity is 62.61120859078304
At time: 184.2023365497589 and batch: 1800, loss is 4.092779078483582 and perplexity is 59.906144459518
At time: 185.10310339927673 and batch: 1850, loss is 4.1312900733947755 and perplexity is 62.25818878216633
At time: 186.0034418106079 and batch: 1900, loss is 4.217025036811829 and perplexity is 67.83138794174589
At time: 186.90281772613525 and batch: 1950, loss is 4.145815424919128 and perplexity is 63.16911057319973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370401071947675 and perplexity of 79.0753402411597
finished 5 epochs...
Completing Train Step...
At time: 189.9019594192505 and batch: 50, loss is 4.127801098823547 and perplexity is 62.04135003705228
At time: 190.80119848251343 and batch: 100, loss is 4.0936809301376345 and perplexity is 59.96019528423613
At time: 191.70343899726868 and batch: 150, loss is 4.06589515209198 and perplexity is 58.317087828027944
At time: 192.60207319259644 and batch: 200, loss is 4.063864259719849 and perplexity is 58.19877228292838
At time: 193.50176095962524 and batch: 250, loss is 4.044025487899781 and perplexity is 57.055557601989285
At time: 194.40897870063782 and batch: 300, loss is 4.074810156822204 and perplexity is 58.83930928652897
At time: 195.30631732940674 and batch: 350, loss is 4.08302011013031 and perplexity is 59.32436568912931
At time: 196.20495319366455 and batch: 400, loss is 4.04649519443512 and perplexity is 57.196642232581894
At time: 197.10218167304993 and batch: 450, loss is 4.084611840248108 and perplexity is 59.418869260853775
At time: 197.99796342849731 and batch: 500, loss is 4.092565631866455 and perplexity is 59.89335906018667
At time: 198.92362523078918 and batch: 550, loss is 4.054708065986634 and perplexity is 57.668325192901236
At time: 199.84363317489624 and batch: 600, loss is 4.049652533531189 and perplexity is 57.37751681820868
At time: 200.76336526870728 and batch: 650, loss is 4.103795251846313 and perplexity is 60.56972930439882
At time: 201.65890383720398 and batch: 700, loss is 4.12581238746643 and perplexity is 61.91809030426203
At time: 202.55607151985168 and batch: 750, loss is 4.10059501171112 and perplexity is 60.376201458659224
At time: 203.45302414894104 and batch: 800, loss is 4.072877669334412 and perplexity is 58.72571285473619
At time: 204.35177636146545 and batch: 850, loss is 4.078248991966247 and perplexity is 59.04199627498325
At time: 205.24955368041992 and batch: 900, loss is 4.053376307487488 and perplexity is 57.59157602771402
At time: 206.14698886871338 and batch: 950, loss is 4.135095000267029 and perplexity is 62.49552788029853
At time: 207.04437518119812 and batch: 1000, loss is 4.112021560668945 and perplexity is 61.0700496764286
At time: 207.94071412086487 and batch: 1050, loss is 4.056294374465942 and perplexity is 57.75987754207782
At time: 208.83739495277405 and batch: 1100, loss is 4.099458417892456 and perplexity is 60.30761722487832
At time: 209.73480558395386 and batch: 1150, loss is 4.06188841342926 and perplexity is 58.08389398290128
At time: 210.63125848770142 and batch: 1200, loss is 4.135850434303284 and perplexity is 62.54275696615644
At time: 211.52771735191345 and batch: 1250, loss is 4.11841423034668 and perplexity is 61.46170084571541
At time: 212.4239809513092 and batch: 1300, loss is 4.115265498161316 and perplexity is 61.268478772018355
At time: 213.3207232952118 and batch: 1350, loss is 4.011415143013 and perplexity is 55.22496651746924
At time: 214.21790885925293 and batch: 1400, loss is 4.047921433448791 and perplexity is 57.278276516347105
At time: 215.11427450180054 and batch: 1450, loss is 3.974238176345825 and perplexity is 53.20956515569173
At time: 216.00904941558838 and batch: 1500, loss is 3.985964870452881 and perplexity is 53.837210358940524
At time: 216.90511846542358 and batch: 1550, loss is 3.9936315488815306 and perplexity is 54.251549210127045
At time: 217.82516741752625 and batch: 1600, loss is 4.076563172340393 and perplexity is 58.942545970104185
At time: 218.72117257118225 and batch: 1650, loss is 4.035227918624878 and perplexity is 56.55580889167658
At time: 219.61823678016663 and batch: 1700, loss is 4.063492403030396 and perplexity is 58.17713470342569
At time: 220.5153660774231 and batch: 1750, loss is 4.0570614528656 and perplexity is 57.80420089407684
At time: 221.4113585948944 and batch: 1800, loss is 4.015332312583923 and perplexity is 55.44171632158069
At time: 222.31979751586914 and batch: 1850, loss is 4.052486972808838 and perplexity is 57.5403806102588
At time: 223.2313735485077 and batch: 1900, loss is 4.139443197250366 and perplexity is 62.767862399084805
At time: 224.12773609161377 and batch: 1950, loss is 4.063933339118957 and perplexity is 58.20279275801094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366121230014535 and perplexity of 78.7376334654107
finished 6 epochs...
Completing Train Step...
At time: 227.12037062644958 and batch: 50, loss is 4.05153169631958 and perplexity is 57.48543988344923
At time: 228.01593732833862 and batch: 100, loss is 4.018819808959961 and perplexity is 55.635406657189975
At time: 228.91149187088013 and batch: 150, loss is 3.9928154039382933 and perplexity is 54.20729014593884
At time: 229.80973100662231 and batch: 200, loss is 3.9935297203063964 and perplexity is 54.24602513343136
At time: 230.7057123184204 and batch: 250, loss is 3.9727144479751586 and perplexity is 53.12854996991641
At time: 231.60152220726013 and batch: 300, loss is 3.9975412845611573 and perplexity is 54.464073614150315
At time: 232.4973509311676 and batch: 350, loss is 4.009310326576233 and perplexity is 55.10885034470651
At time: 233.39256739616394 and batch: 400, loss is 3.9713356590270994 and perplexity is 53.05534738944281
At time: 234.28690576553345 and batch: 450, loss is 4.0127925777435305 and perplexity is 55.301087718300096
At time: 235.18156266212463 and batch: 500, loss is 4.019545826911926 and perplexity is 55.67581362750603
At time: 236.07745456695557 and batch: 550, loss is 3.9863656091690065 and perplexity is 53.85878933697674
At time: 236.99993586540222 and batch: 600, loss is 3.9814725971221923 and perplexity is 53.595901313552595
At time: 237.89854073524475 and batch: 650, loss is 4.036438336372376 and perplexity is 56.624306493476524
At time: 238.796452999115 and batch: 700, loss is 4.056859016418457 and perplexity is 57.79250040136095
At time: 239.69504618644714 and batch: 750, loss is 4.032991185188293 and perplexity is 56.42944999116522
At time: 240.59400701522827 and batch: 800, loss is 4.005913848876953 and perplexity is 54.92199187342728
At time: 241.493182182312 and batch: 850, loss is 4.01245979309082 and perplexity is 55.28268742686638
At time: 242.39366698265076 and batch: 900, loss is 3.9824596452713013 and perplexity is 53.648829165616036
At time: 243.2925100326538 and batch: 950, loss is 4.068529877662659 and perplexity is 58.47093994058289
At time: 244.19232964515686 and batch: 1000, loss is 4.045699963569641 and perplexity is 57.151175777836926
At time: 245.09195804595947 and batch: 1050, loss is 3.9944595956802367 and perplexity is 54.296490636009366
At time: 246.03365969657898 and batch: 1100, loss is 4.031587200164795 and perplexity is 56.35027947860526
At time: 246.93303322792053 and batch: 1150, loss is 3.99472195148468 and perplexity is 54.31073750428121
At time: 247.83336901664734 and batch: 1200, loss is 4.070976114273071 and perplexity is 58.614148784454805
At time: 248.73161435127258 and batch: 1250, loss is 4.054069924354553 and perplexity is 57.63153637323044
At time: 249.63155221939087 and batch: 1300, loss is 4.053188247680664 and perplexity is 57.580746385393695
At time: 250.53075695037842 and batch: 1350, loss is 3.948276743888855 and perplexity is 51.84594596620668
At time: 251.4534125328064 and batch: 1400, loss is 3.9863299703598023 and perplexity is 53.856869908062876
At time: 252.35188245773315 and batch: 1450, loss is 3.9078319311141967 and perplexity is 49.79088479907026
At time: 253.24952721595764 and batch: 1500, loss is 3.919385747909546 and perplexity is 50.369495705740036
At time: 254.14510011672974 and batch: 1550, loss is 3.931897144317627 and perplexity is 51.00364722166612
At time: 255.04170632362366 and batch: 1600, loss is 4.015535573959351 and perplexity is 55.452986626466334
At time: 255.93730974197388 and batch: 1650, loss is 3.970023694038391 and perplexity is 52.985786272057084
At time: 256.83275055885315 and batch: 1700, loss is 4.000993213653564 and perplexity is 54.65240459994472
At time: 257.73050475120544 and batch: 1750, loss is 3.995964093208313 and perplexity is 54.37824105318448
At time: 258.63034224510193 and batch: 1800, loss is 3.9495467567443847 and perplexity is 51.911832813806676
At time: 259.52934408187866 and batch: 1850, loss is 3.989674572944641 and perplexity is 54.03730130182407
At time: 260.4279329776764 and batch: 1900, loss is 4.074515981674194 and perplexity is 58.82200276970918
At time: 261.3280382156372 and batch: 1950, loss is 4.002247796058655 and perplexity is 54.72101357395844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369828760901163 and perplexity of 79.03009749812868
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 264.290096282959 and batch: 50, loss is 4.023200302124024 and perplexity is 55.87965174213169
At time: 265.2121670246124 and batch: 100, loss is 4.007615284919739 and perplexity is 55.01551767146196
At time: 266.11372780799866 and batch: 150, loss is 3.9749481868743897 and perplexity is 53.24735792221601
At time: 267.01305961608887 and batch: 200, loss is 3.9803516721725463 and perplexity is 53.53585798888871
At time: 267.91265416145325 and batch: 250, loss is 3.96147057056427 and perplexity is 52.53452489785853
At time: 268.8533489704132 and batch: 300, loss is 3.974145917892456 and perplexity is 53.2046563499489
At time: 269.7511444091797 and batch: 350, loss is 3.9806780338287355 and perplexity is 53.55333289158146
At time: 270.6480143070221 and batch: 400, loss is 3.94221052646637 and perplexity is 51.53238919881112
At time: 271.54675102233887 and batch: 450, loss is 3.9746433877944947 and perplexity is 53.231130649668984
At time: 272.4451057910919 and batch: 500, loss is 3.976967329978943 and perplexity is 53.35498057400372
At time: 273.3447742462158 and batch: 550, loss is 3.940752820968628 and perplexity is 51.457324875894386
At time: 274.2441453933716 and batch: 600, loss is 3.9257067251205444 and perplexity is 50.688888514119384
At time: 275.1433084011078 and batch: 650, loss is 3.9618055057525634 and perplexity is 52.55212350587913
At time: 276.0425012111664 and batch: 700, loss is 3.9861837148666384 and perplexity is 53.84899362098337
At time: 276.94236731529236 and batch: 750, loss is 3.945478539466858 and perplexity is 51.70107319728158
At time: 277.84222316741943 and batch: 800, loss is 3.912300305366516 and perplexity is 50.01386691947761
At time: 278.7415566444397 and batch: 850, loss is 3.9160545921325682 and perplexity is 50.201986224123864
At time: 279.64095282554626 and batch: 900, loss is 3.8769293355941774 and perplexity is 48.27574861972717
At time: 280.5403287410736 and batch: 950, loss is 3.972607650756836 and perplexity is 53.122876291538034
At time: 281.4389464855194 and batch: 1000, loss is 3.941408467292786 and perplexity is 51.49107374425203
At time: 282.3370909690857 and batch: 1050, loss is 3.8833893966674804 and perplexity is 48.58862240798007
At time: 283.23614525794983 and batch: 1100, loss is 3.9094414615631106 and perplexity is 49.87108927268922
At time: 284.1346926689148 and batch: 1150, loss is 3.8696554851531983 and perplexity is 47.925872061849006
At time: 285.03421998023987 and batch: 1200, loss is 3.928049168586731 and perplexity is 50.80776354449062
At time: 285.9340672492981 and batch: 1250, loss is 3.9134657430648803 and perplexity is 50.07218894416834
At time: 286.83373737335205 and batch: 1300, loss is 3.9057034397125245 and perplexity is 49.68501803710897
At time: 287.73278403282166 and batch: 1350, loss is 3.7949634408950805 and perplexity is 44.47661035074109
At time: 288.63246870040894 and batch: 1400, loss is 3.8276844596862794 and perplexity is 45.95600196209886
At time: 289.5321886539459 and batch: 1450, loss is 3.736736783981323 and perplexity is 41.96083922740983
At time: 290.43200397491455 and batch: 1500, loss is 3.7477445936203004 and perplexity is 42.42528774853877
At time: 291.33125376701355 and batch: 1550, loss is 3.757318549156189 and perplexity is 42.83341615119327
At time: 292.22940826416016 and batch: 1600, loss is 3.8322954320907594 and perplexity is 46.16839310751651
At time: 293.12807536125183 and batch: 1650, loss is 3.7771874332427977 and perplexity is 43.692979334888996
At time: 294.0278036594391 and batch: 1700, loss is 3.798633642196655 and perplexity is 44.64014838912412
At time: 294.93001770973206 and batch: 1750, loss is 3.7793515300750733 and perplexity is 43.78763756090099
At time: 295.8296709060669 and batch: 1800, loss is 3.7337495613098146 and perplexity is 41.83567988963146
At time: 296.72998046875 and batch: 1850, loss is 3.758643054962158 and perplexity is 42.890186847834194
At time: 297.6299591064453 and batch: 1900, loss is 3.8406568479537966 and perplexity is 46.55604464136245
At time: 298.53046703338623 and batch: 1950, loss is 3.765047187805176 and perplexity is 43.16574270845963
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283408089571221 and perplexity of 72.48706191359722
finished 8 epochs...
Completing Train Step...
At time: 301.510267496109 and batch: 50, loss is 3.9316274166107177 and perplexity is 50.9898919800253
At time: 302.4349555969238 and batch: 100, loss is 3.907507076263428 and perplexity is 49.774712615567566
At time: 303.33605909347534 and batch: 150, loss is 3.86932430267334 and perplexity is 47.91000248069886
At time: 304.23663353919983 and batch: 200, loss is 3.873516354560852 and perplexity is 48.11126525428625
At time: 305.1373338699341 and batch: 250, loss is 3.8558455753326415 and perplexity is 47.2685691836899
At time: 306.0368506908417 and batch: 300, loss is 3.8691489601135256 and perplexity is 47.90160255467697
At time: 306.9356005191803 and batch: 350, loss is 3.8769136333465575 and perplexity is 48.27499058791972
At time: 307.83418011665344 and batch: 400, loss is 3.841983103752136 and perplexity is 46.617830828603765
At time: 308.73222398757935 and batch: 450, loss is 3.8843499565124513 and perplexity is 48.63531711052541
At time: 309.6314969062805 and batch: 500, loss is 3.8891948080062866 and perplexity is 48.871519720541826
At time: 310.5309467315674 and batch: 550, loss is 3.8582928562164307 and perplexity is 47.38439031507143
At time: 311.43655586242676 and batch: 600, loss is 3.8460218143463134 and perplexity is 46.80648746419087
At time: 312.336008310318 and batch: 650, loss is 3.8850132513046263 and perplexity is 48.66758736424308
At time: 313.2589817047119 and batch: 700, loss is 3.91050350189209 and perplexity is 49.9240825162468
At time: 314.15944027900696 and batch: 750, loss is 3.876394305229187 and perplexity is 48.2499265367382
At time: 315.0590732097626 and batch: 800, loss is 3.8434484004974365 and perplexity is 46.68618985528843
At time: 315.9584195613861 and batch: 850, loss is 3.8502768516540526 and perplexity is 47.00607513996501
At time: 316.85820055007935 and batch: 900, loss is 3.811558871269226 and perplexity is 45.220877476358794
At time: 317.75851607322693 and batch: 950, loss is 3.9095135593414305 and perplexity is 49.87468499704848
At time: 318.66010427474976 and batch: 1000, loss is 3.8804214143753053 and perplexity is 48.444626032123196
At time: 319.5604672431946 and batch: 1050, loss is 3.828171911239624 and perplexity is 45.97840874730825
At time: 320.45932483673096 and batch: 1100, loss is 3.853910837173462 and perplexity is 47.17720529026542
At time: 321.359512090683 and batch: 1150, loss is 3.8169595909118654 and perplexity is 45.465763442595566
At time: 322.2577419281006 and batch: 1200, loss is 3.876707649230957 and perplexity is 48.26504773074833
At time: 323.15565037727356 and batch: 1250, loss is 3.866598896980286 and perplexity is 47.7796060594717
At time: 324.05747842788696 and batch: 1300, loss is 3.86154100894928 and perplexity is 47.53855228724291
At time: 324.96726155281067 and batch: 1350, loss is 3.7520324754714967 and perplexity is 42.60759294215224
At time: 325.86611127853394 and batch: 1400, loss is 3.789710898399353 and perplexity is 44.24360752911561
At time: 326.7659890651703 and batch: 1450, loss is 3.6992267560958862 and perplexity is 40.416040817262804
At time: 327.6646912097931 and batch: 1500, loss is 3.714323630332947 and perplexity is 41.03082569105734
At time: 328.56440448760986 and batch: 1550, loss is 3.7259346866607665 and perplexity is 41.51001347397464
At time: 329.4844584465027 and batch: 1600, loss is 3.804770746231079 and perplexity is 44.91495201058981
At time: 330.3838641643524 and batch: 1650, loss is 3.7513316965103147 and perplexity is 42.57774489709429
At time: 331.28578996658325 and batch: 1700, loss is 3.7776276206970216 and perplexity is 43.71221666993602
At time: 332.1868841648102 and batch: 1750, loss is 3.7626507234573365 and perplexity is 43.0624213973782
At time: 333.0863149166107 and batch: 1800, loss is 3.720271596908569 and perplexity is 41.27560291255402
At time: 333.9856946468353 and batch: 1850, loss is 3.7487822771072388 and perplexity is 42.4693346184664
At time: 334.8860538005829 and batch: 1900, loss is 3.8340684175491333 and perplexity is 46.25032160468798
At time: 335.78585505485535 and batch: 1950, loss is 3.7608253955841064 and perplexity is 42.983890053842295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.282393202670785 and perplexity of 72.41353306205531
finished 9 epochs...
Completing Train Step...
At time: 338.76905822753906 and batch: 50, loss is 3.886709518432617 and perplexity is 48.750210648657195
At time: 339.69473361968994 and batch: 100, loss is 3.862282004356384 and perplexity is 47.57379119046846
At time: 340.59497833251953 and batch: 150, loss is 3.823481922149658 and perplexity is 45.76327539279142
At time: 341.49466490745544 and batch: 200, loss is 3.825696840286255 and perplexity is 45.86474963853776
At time: 342.39354610443115 and batch: 250, loss is 3.8087268543243407 and perplexity is 45.09299235696901
At time: 343.29305601119995 and batch: 300, loss is 3.823733615875244 and perplexity is 45.77479517173727
At time: 344.19279503822327 and batch: 350, loss is 3.831692724227905 and perplexity is 46.14057543778148
At time: 345.0921366214752 and batch: 400, loss is 3.7972369480133055 and perplexity is 44.57784327424943
At time: 345.990802526474 and batch: 450, loss is 3.842497763633728 and perplexity is 46.641829330901544
At time: 346.88970851898193 and batch: 500, loss is 3.8480710697174074 and perplexity is 46.90250425789256
At time: 347.7891674041748 and batch: 550, loss is 3.8177652072906496 and perplexity is 45.50240616430542
At time: 348.68897581100464 and batch: 600, loss is 3.807182297706604 and perplexity is 45.02339743769285
At time: 349.5889902114868 and batch: 650, loss is 3.8473899793624877 and perplexity is 46.87057029081389
At time: 350.48848509788513 and batch: 700, loss is 3.8726651287078857 and perplexity is 48.07032912689966
At time: 351.38772678375244 and batch: 750, loss is 3.840696620941162 and perplexity is 46.557896351161524
At time: 352.2868332862854 and batch: 800, loss is 3.807534375190735 and perplexity is 45.039251953034906
At time: 353.18721103668213 and batch: 850, loss is 3.8155288982391355 and perplexity is 45.40076241731092
At time: 354.0956678390503 and batch: 900, loss is 3.7767783880233763 and perplexity is 43.67511058538221
At time: 355.007196187973 and batch: 950, loss is 3.875837941169739 and perplexity is 48.22308947802186
At time: 355.90677428245544 and batch: 1000, loss is 3.848106555938721 and perplexity is 46.90416868007066
At time: 356.81990671157837 and batch: 1050, loss is 3.797991409301758 and perplexity is 44.6114882216318
At time: 357.7194697856903 and batch: 1100, loss is 3.823271460533142 and perplexity is 45.753644993325445
At time: 358.6432433128357 and batch: 1150, loss is 3.7870325899124144 and perplexity is 44.125268045140466
At time: 359.5425090789795 and batch: 1200, loss is 3.8470139503479004 and perplexity is 46.8529489097372
At time: 360.4448721408844 and batch: 1250, loss is 3.838623285293579 and perplexity is 46.46146620555324
At time: 361.34511947631836 and batch: 1300, loss is 3.834100379943848 and perplexity is 46.25179989934758
At time: 362.2459726333618 and batch: 1350, loss is 3.7251557302474976 and perplexity is 41.477691573074544
At time: 363.14601492881775 and batch: 1400, loss is 3.764849581718445 and perplexity is 43.1572137376782
At time: 364.0458040237427 and batch: 1450, loss is 3.674000244140625 and perplexity is 39.409237539493326
At time: 364.94524002075195 and batch: 1500, loss is 3.6912830018997194 and perplexity is 40.09625754489545
At time: 365.84489274024963 and batch: 1550, loss is 3.7034809732437135 and perplexity is 40.58834568244134
At time: 366.7450387477875 and batch: 1600, loss is 3.7837735414505005 and perplexity is 43.98169573981502
At time: 367.64505672454834 and batch: 1650, loss is 3.7312016534805297 and perplexity is 41.72922211319043
At time: 368.54298543930054 and batch: 1700, loss is 3.759439220428467 and perplexity is 42.924348130658295
At time: 369.4425251483917 and batch: 1750, loss is 3.7457255935668945 and perplexity is 42.33971750254226
At time: 370.34198117256165 and batch: 1800, loss is 3.7046267366409302 and perplexity is 40.63487697511343
At time: 371.2447636127472 and batch: 1850, loss is 3.734817690849304 and perplexity is 41.88038968880401
At time: 372.1453700065613 and batch: 1900, loss is 3.821158947944641 and perplexity is 45.65709186306619
At time: 373.0451090335846 and batch: 1950, loss is 3.748785490989685 and perplexity is 42.46947111013477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.28511593840843 and perplexity of 72.61096463143927
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 376.04616355895996 and batch: 50, loss is 3.876222863197327 and perplexity is 48.241655180344964
At time: 376.94525027275085 and batch: 100, loss is 3.876285319328308 and perplexity is 48.24466826157138
At time: 377.84184217453003 and batch: 150, loss is 3.840885348320007 and perplexity is 46.56668393010671
At time: 378.7410080432892 and batch: 200, loss is 3.8445250844955443 and perplexity is 46.7364831989989
At time: 379.6420691013336 and batch: 250, loss is 3.8343844175338746 and perplexity is 46.264939015038436
At time: 380.54074144363403 and batch: 300, loss is 3.8418689155578614 and perplexity is 46.61250792659251
At time: 381.464453458786 and batch: 350, loss is 3.85273756980896 and perplexity is 47.121886273294365
At time: 382.3627042770386 and batch: 400, loss is 3.81827880859375 and perplexity is 45.52578226188884
At time: 383.26072335243225 and batch: 450, loss is 3.8665388345718386 and perplexity is 47.77673638743768
At time: 384.1586060523987 and batch: 500, loss is 3.87119469165802 and perplexity is 47.9996966769646
At time: 385.05829095840454 and batch: 550, loss is 3.8403991746902464 and perplexity is 46.54404993882516
At time: 385.9563331604004 and batch: 600, loss is 3.8259692287445066 and perplexity is 45.87724436861277
At time: 386.8553795814514 and batch: 650, loss is 3.8613178062438966 and perplexity is 47.5279427378465
At time: 387.75480365753174 and batch: 700, loss is 3.883265805244446 and perplexity is 48.58261764206981
At time: 388.65421056747437 and batch: 750, loss is 3.8406232023239135 and perplexity is 46.55447826026671
At time: 389.55385756492615 and batch: 800, loss is 3.8023777341842653 and perplexity is 44.80759848971081
At time: 390.45405173301697 and batch: 850, loss is 3.808027982711792 and perplexity is 45.061489154315105
At time: 391.35214924812317 and batch: 900, loss is 3.7648067760467527 and perplexity is 43.155366403694266
At time: 392.2498474121094 and batch: 950, loss is 3.8705441761016846 and perplexity is 47.96848228140254
At time: 393.1495313644409 and batch: 1000, loss is 3.8367619037628176 and perplexity is 46.37506412902759
At time: 394.04847025871277 and batch: 1050, loss is 3.786433844566345 and perplexity is 44.09885615404186
At time: 394.946813583374 and batch: 1100, loss is 3.8043172359466553 and perplexity is 44.89458723609498
At time: 395.84767961502075 and batch: 1150, loss is 3.7747875308990477 and perplexity is 43.58824617632195
At time: 396.7471423149109 and batch: 1200, loss is 3.829160003662109 and perplexity is 46.023862116956344
At time: 397.64680194854736 and batch: 1250, loss is 3.8185253238677976 and perplexity is 45.537006445988936
At time: 398.5455811023712 and batch: 1300, loss is 3.815790901184082 and perplexity is 45.41265910918316
At time: 399.44554805755615 and batch: 1350, loss is 3.703359546661377 and perplexity is 40.58341747755602
At time: 400.3461253643036 and batch: 1400, loss is 3.7304539632797242 and perplexity is 41.69803324398809
At time: 401.245454788208 and batch: 1450, loss is 3.634616131782532 and perplexity is 37.887306372584625
At time: 402.1457643508911 and batch: 1500, loss is 3.649216480255127 and perplexity is 38.44453219528161
At time: 403.0458552837372 and batch: 1550, loss is 3.6594694566726687 and perplexity is 38.84073071348583
At time: 403.949964761734 and batch: 1600, loss is 3.738122944831848 and perplexity is 42.0190440312925
At time: 404.84809970855713 and batch: 1650, loss is 3.6838374519348145 and perplexity is 39.798827495119305
At time: 405.77999544143677 and batch: 1700, loss is 3.703273949623108 and perplexity is 40.57994380588723
At time: 406.6860280036926 and batch: 1750, loss is 3.688750133514404 and perplexity is 39.99482751048065
At time: 407.592467546463 and batch: 1800, loss is 3.6494415187835694 and perplexity is 38.45318466976705
At time: 408.5154592990875 and batch: 1850, loss is 3.6741843748092653 and perplexity is 39.416494656860515
At time: 409.4135890007019 and batch: 1900, loss is 3.7607859420776366 and perplexity is 42.98219422211143
At time: 410.31113266944885 and batch: 1950, loss is 3.693406548500061 and perplexity is 40.18149428635671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261202648074128 and perplexity of 70.89519417349008
finished 11 epochs...
Completing Train Step...
At time: 413.30600118637085 and batch: 50, loss is 3.8624046564102175 and perplexity is 47.57962657152003
At time: 414.2047667503357 and batch: 100, loss is 3.8469392681121826 and perplexity is 46.84944995741907
At time: 415.1031394004822 and batch: 150, loss is 3.80733359336853 and perplexity is 45.030209797737626
At time: 416.00121808052063 and batch: 200, loss is 3.8078721570968628 and perplexity is 45.05446796711262
At time: 416.89971446990967 and batch: 250, loss is 3.7969674253463745 and perplexity is 44.56583015402095
At time: 417.79760694503784 and batch: 300, loss is 3.8038952589035033 and perplexity is 44.875646747426316
At time: 418.6957037448883 and batch: 350, loss is 3.815717978477478 and perplexity is 45.40934761590984
At time: 419.59397649765015 and batch: 400, loss is 3.779846396446228 and perplexity is 43.80931195272367
At time: 420.49173760414124 and batch: 450, loss is 3.830338063240051 and perplexity is 46.07811291760055
At time: 421.3893585205078 and batch: 500, loss is 3.8347330474853516 and perplexity is 46.28107117039521
At time: 422.2875442504883 and batch: 550, loss is 3.805519948005676 and perplexity is 44.94861498094605
At time: 423.18516778945923 and batch: 600, loss is 3.7932780838012694 and perplexity is 44.40171451082337
At time: 424.0832600593567 and batch: 650, loss is 3.8300880336761476 and perplexity is 46.06659346728384
At time: 424.9823615550995 and batch: 700, loss is 3.8541770076751707 and perplexity is 47.18976414199053
At time: 425.9049286842346 and batch: 750, loss is 3.814791622161865 and perplexity is 45.367301857641586
At time: 426.80270433425903 and batch: 800, loss is 3.777566523551941 and perplexity is 43.7095460598765
At time: 427.7009584903717 and batch: 850, loss is 3.785416841506958 and perplexity is 44.05403028030669
At time: 428.59920024871826 and batch: 900, loss is 3.7415005588531494 and perplexity is 42.16120809608967
At time: 429.4989740848541 and batch: 950, loss is 3.8484995317459108 and perplexity is 46.92260450579778
At time: 430.39690613746643 and batch: 1000, loss is 3.8150008487701417 and perplexity is 45.37679489739954
At time: 431.2974212169647 and batch: 1050, loss is 3.766518292427063 and perplexity is 43.22929076352337
At time: 432.1998209953308 and batch: 1100, loss is 3.7850923633575437 and perplexity is 44.03973802897413
At time: 433.09812688827515 and batch: 1150, loss is 3.7567688751220705 and perplexity is 42.809878204234145
At time: 433.99584007263184 and batch: 1200, loss is 3.81339524269104 and perplexity is 45.30399609839867
At time: 434.8957233428955 and batch: 1250, loss is 3.8042295742034913 and perplexity is 44.89065187081224
At time: 435.794882774353 and batch: 1300, loss is 3.8028954219818116 and perplexity is 44.83080084195542
At time: 436.69415950775146 and batch: 1350, loss is 3.690715570449829 and perplexity is 40.073512121186255
At time: 437.59974670410156 and batch: 1400, loss is 3.719895429611206 and perplexity is 41.260079300480015
At time: 438.51211047172546 and batch: 1450, loss is 3.627045307159424 and perplexity is 37.60155128631073
At time: 439.44645595550537 and batch: 1500, loss is 3.6435292100906373 and perplexity is 38.22650832233912
At time: 440.3630528450012 and batch: 1550, loss is 3.655216026306152 and perplexity is 38.67587521923659
At time: 441.2812066078186 and batch: 1600, loss is 3.73529091835022 and perplexity is 41.90021333113023
At time: 442.21919655799866 and batch: 1650, loss is 3.6824586629867553 and perplexity is 39.74399112420167
At time: 443.15215277671814 and batch: 1700, loss is 3.7035425901412964 and perplexity is 40.59084668743161
At time: 444.05103731155396 and batch: 1750, loss is 3.6909199285507204 and perplexity is 40.081702304856066
At time: 444.95088052749634 and batch: 1800, loss is 3.652241516113281 and perplexity is 38.561004361143226
At time: 445.8504886627197 and batch: 1850, loss is 3.678798584938049 and perplexity is 39.59879089889255
At time: 446.7507755756378 and batch: 1900, loss is 3.7665560483932494 and perplexity is 43.23092295797605
At time: 447.6513948440552 and batch: 1950, loss is 3.6993941974639895 and perplexity is 40.42280870102661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260443824945495 and perplexity of 70.84141766645139
finished 12 epochs...
Completing Train Step...
At time: 450.66162037849426 and batch: 50, loss is 3.848505387306213 and perplexity is 46.92287926474244
At time: 451.56404089927673 and batch: 100, loss is 3.831337738037109 and perplexity is 46.12419907752854
At time: 452.46276021003723 and batch: 150, loss is 3.79187828540802 and perplexity is 44.33960454305185
At time: 453.3619465827942 and batch: 200, loss is 3.790985622406006 and perplexity is 44.30004187924257
At time: 454.261727809906 and batch: 250, loss is 3.779487524032593 and perplexity is 43.79359281995377
At time: 455.1606981754303 and batch: 300, loss is 3.7868087100982666 and perplexity is 44.115390394075895
At time: 456.0606610774994 and batch: 350, loss is 3.7987071466445923 and perplexity is 44.64342975918346
At time: 456.95898365974426 and batch: 400, loss is 3.762358293533325 and perplexity is 43.04983049782884
At time: 457.8575863838196 and batch: 450, loss is 3.813994493484497 and perplexity is 45.33115268999928
At time: 458.7554602622986 and batch: 500, loss is 3.8181993532180787 and perplexity is 45.52216513745839
At time: 459.6542332172394 and batch: 550, loss is 3.7894301080703734 and perplexity is 44.23118609599302
At time: 460.5563871860504 and batch: 600, loss is 3.778027505874634 and perplexity is 43.72970003289878
At time: 461.45590353012085 and batch: 650, loss is 3.8151069688796997 and perplexity is 45.381610543359365
At time: 462.3554742336273 and batch: 700, loss is 3.839837465286255 and perplexity is 46.517913049630124
At time: 463.2540764808655 and batch: 750, loss is 3.8016891956329344 and perplexity is 44.77675734963349
At time: 464.1534962654114 and batch: 800, loss is 3.76495596408844 and perplexity is 43.16180514857625
At time: 465.052695274353 and batch: 850, loss is 3.773137435913086 and perplexity is 43.51638073856513
At time: 465.9515166282654 and batch: 900, loss is 3.729614486694336 and perplexity is 41.663043410051024
At time: 466.8510618209839 and batch: 950, loss is 3.8367454862594603 and perplexity is 46.37430277250636
At time: 467.7507574558258 and batch: 1000, loss is 3.8034667348861695 and perplexity is 44.85642057473425
At time: 468.6500060558319 and batch: 1050, loss is 3.7559643507003786 and perplexity is 42.77545046256563
At time: 469.5489375591278 and batch: 1100, loss is 3.774579486846924 and perplexity is 43.579178844197415
At time: 470.4486172199249 and batch: 1150, loss is 3.7468097257614135 and perplexity is 42.38564424422492
At time: 471.3928453922272 and batch: 1200, loss is 3.804472713470459 and perplexity is 44.90156787800302
At time: 472.29174733161926 and batch: 1250, loss is 3.7956929111480715 and perplexity is 44.509066551423054
At time: 473.19066977500916 and batch: 1300, loss is 3.795084586143494 and perplexity is 44.48199880713697
At time: 474.0901834964752 and batch: 1350, loss is 3.682811894416809 and perplexity is 39.75803243079192
At time: 474.98906230926514 and batch: 1400, loss is 3.712666368484497 and perplexity is 40.96288318384213
At time: 475.88875818252563 and batch: 1450, loss is 3.6210002422332765 and perplexity is 37.37493311833551
At time: 476.78850769996643 and batch: 1500, loss is 3.638356466293335 and perplexity is 38.02928292651139
At time: 477.68797850608826 and batch: 1550, loss is 3.6504848432540893 and perplexity is 38.493324754227494
At time: 478.58818078041077 and batch: 1600, loss is 3.731053490638733 and perplexity is 41.723039851058246
At time: 479.48751878738403 and batch: 1650, loss is 3.6789168167114257 and perplexity is 39.60347301094585
At time: 480.3854281902313 and batch: 1700, loss is 3.700709500312805 and perplexity is 40.47601191796938
At time: 481.28426361083984 and batch: 1750, loss is 3.68885094165802 and perplexity is 39.99885951802239
At time: 482.1836977005005 and batch: 1800, loss is 3.6505957508087157 and perplexity is 38.49759419149747
At time: 483.0827980041504 and batch: 1850, loss is 3.6779402542114257 and perplexity is 39.56481662259536
At time: 483.98074865341187 and batch: 1900, loss is 3.766309223175049 and perplexity is 43.22025379274762
At time: 484.87899231910706 and batch: 1950, loss is 3.699317202568054 and perplexity is 40.41969647089171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260887820221657 and perplexity of 70.87287790483376
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 487.8347189426422 and batch: 50, loss is 3.8462285232543945 and perplexity is 46.81616378216181
At time: 488.7577483654022 and batch: 100, loss is 3.8434239721298216 and perplexity is 46.68504940180987
At time: 489.65797328948975 and batch: 150, loss is 3.8088064908981325 and perplexity is 45.09658355137565
At time: 490.5574972629547 and batch: 200, loss is 3.80818790435791 and perplexity is 45.068696038090195
At time: 491.458612203598 and batch: 250, loss is 3.800101628303528 and perplexity is 44.70572762969828
At time: 492.35850620269775 and batch: 300, loss is 3.8050430250167846 and perplexity is 44.927183064235926
At time: 493.2572114467621 and batch: 350, loss is 3.819356470108032 and perplexity is 45.57487009062129
At time: 494.18079686164856 and batch: 400, loss is 3.7831625366210937 and perplexity is 43.95483091941577
At time: 495.08004450798035 and batch: 450, loss is 3.8390690898895263 and perplexity is 46.48218355832455
At time: 495.9784052371979 and batch: 500, loss is 3.8429958820343018 and perplexity is 46.66506827171919
At time: 496.87741017341614 and batch: 550, loss is 3.816914134025574 and perplexity is 45.46369675752949
At time: 497.77678322792053 and batch: 600, loss is 3.7996017503738404 and perplexity is 44.68338580768266
At time: 498.67564034461975 and batch: 650, loss is 3.82979923248291 and perplexity is 46.0532913010553
At time: 499.57485342025757 and batch: 700, loss is 3.8562688207626343 and perplexity is 47.28857962394417
At time: 500.4736633300781 and batch: 750, loss is 3.816985077857971 and perplexity is 45.46692224082513
At time: 501.3730845451355 and batch: 800, loss is 3.7813908100128173 and perplexity is 43.87702392262992
At time: 502.272775888443 and batch: 850, loss is 3.7869717931747435 and perplexity is 44.12258545434168
At time: 503.1714997291565 and batch: 900, loss is 3.738243498802185 and perplexity is 42.02410989922935
At time: 504.07133626937866 and batch: 950, loss is 3.844710626602173 and perplexity is 46.74515558906993
At time: 504.9704837799072 and batch: 1000, loss is 3.8085569620132445 and perplexity is 45.08533205501487
At time: 505.86911630630493 and batch: 1050, loss is 3.7608316850662233 and perplexity is 42.984160401100276
At time: 506.7671220302582 and batch: 1100, loss is 3.7777051401138304 and perplexity is 43.71560534682212
At time: 507.666047334671 and batch: 1150, loss is 3.7524268102645872 and perplexity is 42.6243979116735
At time: 508.56580686569214 and batch: 1200, loss is 3.806903681755066 and perplexity is 45.010854948324216
At time: 509.4658193588257 and batch: 1250, loss is 3.796274952888489 and perplexity is 44.53498022667175
At time: 510.3658695220947 and batch: 1300, loss is 3.7959189414978027 and perplexity is 44.5191280883654
At time: 511.2654242515564 and batch: 1350, loss is 3.6860125160217283 and perplexity is 39.885486706009225
At time: 512.1641356945038 and batch: 1400, loss is 3.711347851753235 and perplexity is 40.90890852806637
At time: 513.0625114440918 and batch: 1450, loss is 3.6163805866241456 and perplexity is 37.202671998793136
At time: 513.9611594676971 and batch: 1500, loss is 3.630665159225464 and perplexity is 37.73790998969182
At time: 514.8598141670227 and batch: 1550, loss is 3.6397797155380247 and perplexity is 38.08344660978029
At time: 515.7597136497498 and batch: 1600, loss is 3.7174752855300905 and perplexity is 41.16034469850754
At time: 516.6591260433197 and batch: 1650, loss is 3.6640004539489746 and perplexity is 39.01711726027296
At time: 517.5585000514984 and batch: 1700, loss is 3.6833499002456667 and perplexity is 39.77942823900228
At time: 518.4567806720734 and batch: 1750, loss is 3.6713425064086915 and perplexity is 39.304637183625154
At time: 519.3554525375366 and batch: 1800, loss is 3.634559292793274 and perplexity is 37.885152957584246
At time: 520.254620552063 and batch: 1850, loss is 3.657521662712097 and perplexity is 38.765150603913696
At time: 521.1538515090942 and batch: 1900, loss is 3.745608687400818 and perplexity is 42.33476801781455
At time: 522.0531318187714 and batch: 1950, loss is 3.6833423948287964 and perplexity is 39.77912967893089
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.250484022983285 and perplexity of 70.13935319092802
finished 14 epochs...
Completing Train Step...
At time: 525.0308816432953 and batch: 50, loss is 3.8472113704681394 and perplexity is 46.86219953764451
At time: 525.9557726383209 and batch: 100, loss is 3.8351705932617186 and perplexity is 46.30132568842782
At time: 526.8553063869476 and batch: 150, loss is 3.7972498607635496 and perplexity is 44.57841890052251
At time: 527.7550621032715 and batch: 200, loss is 3.7938730096817017 and perplexity is 44.42813809918035
At time: 528.6530210971832 and batch: 250, loss is 3.7843219375610353 and perplexity is 44.00582174539263
At time: 529.5512320995331 and batch: 300, loss is 3.78823947429657 and perplexity is 44.17855429079178
At time: 530.4501404762268 and batch: 350, loss is 3.8018189668655396 and perplexity is 44.78256846167625
At time: 531.3507070541382 and batch: 400, loss is 3.7657048416137697 and perplexity is 43.194140160375326
At time: 532.2507283687592 and batch: 450, loss is 3.821851944923401 and perplexity is 45.68874305560997
At time: 533.1491749286652 and batch: 500, loss is 3.8267495822906494 and perplexity is 45.913058811089236
At time: 534.0477230548859 and batch: 550, loss is 3.8008323431015016 and perplexity is 44.73840670451919
At time: 534.9469871520996 and batch: 600, loss is 3.784779052734375 and perplexity is 44.025942072530796
At time: 535.8469591140747 and batch: 650, loss is 3.8154327630996705 and perplexity is 45.39639801847352
At time: 536.7479870319366 and batch: 700, loss is 3.842629532814026 and perplexity is 46.647975691461625
At time: 537.6475646495819 and batch: 750, loss is 3.804688267707825 and perplexity is 44.911247644443364
At time: 538.5464253425598 and batch: 800, loss is 3.769217095375061 and perplexity is 43.34611567367358
At time: 539.4675543308258 and batch: 850, loss is 3.775617685317993 and perplexity is 43.62444617521487
At time: 540.3667702674866 and batch: 900, loss is 3.727893714904785 and perplexity is 41.59141246821142
At time: 541.2657790184021 and batch: 950, loss is 3.835808210372925 and perplexity is 46.33085761999022
At time: 542.1659712791443 and batch: 1000, loss is 3.8000213956832884 and perplexity is 44.702140915918484
At time: 543.0655136108398 and batch: 1050, loss is 3.753016920089722 and perplexity is 42.649558410670316
At time: 543.9644544124603 and batch: 1100, loss is 3.7701192140579223 and perplexity is 43.38523665768444
At time: 544.8634569644928 and batch: 1150, loss is 3.745726537704468 and perplexity is 42.339757477079274
At time: 545.7634568214417 and batch: 1200, loss is 3.8010192918777466 and perplexity is 44.74677127675266
At time: 546.6628017425537 and batch: 1250, loss is 3.7909339570999148 and perplexity is 44.29775316314315
At time: 547.5633721351624 and batch: 1300, loss is 3.7912144231796265 and perplexity is 44.31017892273344
At time: 548.4629490375519 and batch: 1350, loss is 3.68176589012146 and perplexity is 39.71646710064143
At time: 549.3626954555511 and batch: 1400, loss is 3.7084271001815794 and perplexity is 40.789598092077696
At time: 550.2622473239899 and batch: 1450, loss is 3.6145806074142457 and perplexity is 37.135768193435545
At time: 551.1622366905212 and batch: 1500, loss is 3.630336308479309 and perplexity is 37.7255018901516
At time: 552.0720450878143 and batch: 1550, loss is 3.6407068586349487 and perplexity is 38.118771787628575
At time: 552.9714832305908 and batch: 1600, loss is 3.719431700706482 and perplexity is 41.240950244788
At time: 553.8713855743408 and batch: 1650, loss is 3.6663465213775637 and perplexity is 39.10876150799262
At time: 554.7690255641937 and batch: 1700, loss is 3.6863358879089354 and perplexity is 39.89838663674258
At time: 555.6694769859314 and batch: 1750, loss is 3.6752674198150634 and perplexity is 39.45920762040047
At time: 556.5701036453247 and batch: 1800, loss is 3.6388684797286985 and perplexity is 38.04875941599366
At time: 557.4687843322754 and batch: 1850, loss is 3.6624080467224123 and perplexity is 38.955035563577994
At time: 558.3680558204651 and batch: 1900, loss is 3.750577507019043 and perplexity is 42.545645315435955
At time: 559.2679536342621 and batch: 1950, loss is 3.687700505256653 and perplexity is 39.95286983319575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24954464934593 and perplexity of 70.07349706819488
finished 15 epochs...
Completing Train Step...
At time: 562.2307462692261 and batch: 50, loss is 3.843610544204712 and perplexity is 46.69376034092685
At time: 563.1566324234009 and batch: 100, loss is 3.8302570295333864 and perplexity is 46.07437918859571
At time: 564.0560569763184 and batch: 150, loss is 3.7919601917266847 and perplexity is 44.34323638556442
At time: 564.9578783512115 and batch: 200, loss is 3.788120093345642 and perplexity is 44.17328052776961
At time: 565.857745885849 and batch: 250, loss is 3.777840008735657 and perplexity is 43.72150160786893
At time: 566.758015871048 and batch: 300, loss is 3.7814692497253417 and perplexity is 43.88046575875939
At time: 567.6584765911102 and batch: 350, loss is 3.7950260496139525 and perplexity is 44.479395061507596
At time: 568.558191537857 and batch: 400, loss is 3.7586765480041504 and perplexity is 42.89162339472037
At time: 569.4578042030334 and batch: 450, loss is 3.814963364601135 and perplexity is 45.375094017828864
At time: 570.3567178249359 and batch: 500, loss is 3.8197700643539427 and perplexity is 45.59372349320955
At time: 571.2559263706207 and batch: 550, loss is 3.7938181495666505 and perplexity is 44.425700833267676
At time: 572.1561245918274 and batch: 600, loss is 3.778217258453369 and perplexity is 43.73799864356383
At time: 573.0554988384247 and batch: 650, loss is 3.809046688079834 and perplexity is 45.107416924669835
At time: 573.9537854194641 and batch: 700, loss is 3.8365689277648927 and perplexity is 46.366115718190485
At time: 574.8516156673431 and batch: 750, loss is 3.799130334854126 and perplexity is 44.66232633041176
At time: 575.7509727478027 and batch: 800, loss is 3.7638036680221556 and perplexity is 43.11209861411185
At time: 576.651201248169 and batch: 850, loss is 3.770444793701172 and perplexity is 43.3993643072705
At time: 577.5518846511841 and batch: 900, loss is 3.7229816484451295 and perplexity is 41.38761363250741
At time: 578.4511649608612 and batch: 950, loss is 3.831353440284729 and perplexity is 46.12492333680996
At time: 579.3510658740997 and batch: 1000, loss is 3.7957021474838255 and perplexity is 44.50947765400436
At time: 580.2524926662445 and batch: 1050, loss is 3.749092392921448 and perplexity is 42.48250707313821
At time: 581.152170419693 and batch: 1100, loss is 3.7664334106445314 and perplexity is 43.22562153999311
At time: 582.0524559020996 and batch: 1150, loss is 3.742357153892517 and perplexity is 42.197338650216004
At time: 582.9547665119171 and batch: 1200, loss is 3.798072624206543 and perplexity is 44.6151114865296
At time: 583.8969080448151 and batch: 1250, loss is 3.7883448028564453 and perplexity is 44.18320779936198
At time: 584.7971227169037 and batch: 1300, loss is 3.788887219429016 and perplexity is 44.207180004374585
At time: 585.6984827518463 and batch: 1350, loss is 3.6795743799209593 and perplexity is 39.629523361705076
At time: 586.5991544723511 and batch: 1400, loss is 3.7068112468719483 and perplexity is 40.723741306783566
At time: 587.499881029129 and batch: 1450, loss is 3.6134244108200075 and perplexity is 37.09285675653477
At time: 588.4003336429596 and batch: 1500, loss is 3.6297660064697266 and perplexity is 37.70399309444882
At time: 589.3005230426788 and batch: 1550, loss is 3.640580725669861 and perplexity is 38.113964057130524
At time: 590.2023811340332 and batch: 1600, loss is 3.719801206588745 and perplexity is 41.25619183424864
At time: 591.1038706302643 and batch: 1650, loss is 3.666736431121826 and perplexity is 39.12401336842189
At time: 592.0046575069427 and batch: 1700, loss is 3.68696711063385 and perplexity is 39.92357935534689
At time: 592.9036717414856 and batch: 1750, loss is 3.676333746910095 and perplexity is 39.50130648422512
At time: 593.8020679950714 and batch: 1800, loss is 3.6400303792953492 and perplexity is 38.092993946134975
At time: 594.7028839588165 and batch: 1850, loss is 3.66385320186615 and perplexity is 39.011372331477325
At time: 595.6028859615326 and batch: 1900, loss is 3.7519969511032105 and perplexity is 42.60607936121344
At time: 596.5045788288116 and batch: 1950, loss is 3.6888866567611696 and perplexity is 40.000288106926895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2493635310683135 and perplexity of 70.06080662636948
finished 16 epochs...
Completing Train Step...
At time: 599.4912838935852 and batch: 50, loss is 3.8397894287109375 and perplexity is 46.51567854206578
At time: 600.3896284103394 and batch: 100, loss is 3.8258998250961302 and perplexity is 45.874060430965855
At time: 601.2888648509979 and batch: 150, loss is 3.787482762336731 and perplexity is 44.14513649580873
At time: 602.1888072490692 and batch: 200, loss is 3.7833585262298586 and perplexity is 43.96344645378102
At time: 603.088788986206 and batch: 250, loss is 3.7728361320495605 and perplexity is 43.503271060019536
At time: 603.9885094165802 and batch: 300, loss is 3.7764327335357666 and perplexity is 43.66001669619707
At time: 604.8885228633881 and batch: 350, loss is 3.7899778699874878 and perplexity is 44.25542089212844
At time: 605.7879145145416 and batch: 400, loss is 3.753550944328308 and perplexity is 42.67234039115009
At time: 606.7115132808685 and batch: 450, loss is 3.810031032562256 and perplexity is 45.15184002186433
At time: 607.6107189655304 and batch: 500, loss is 3.814773664474487 and perplexity is 45.36648717313259
At time: 608.5088355541229 and batch: 550, loss is 3.78885516166687 and perplexity is 44.205762843828474
At time: 609.4068553447723 and batch: 600, loss is 3.773528199195862 and perplexity is 43.53338866517726
At time: 610.3053457736969 and batch: 650, loss is 3.804489312171936 and perplexity is 44.9023131919097
At time: 611.2076110839844 and batch: 700, loss is 3.832212519645691 and perplexity is 46.164565331846404
At time: 612.1060440540314 and batch: 750, loss is 3.795117931365967 and perplexity is 44.48348209401336
At time: 613.0040552616119 and batch: 800, loss is 3.7599144124984742 and perplexity is 42.944750287587894
At time: 613.9019184112549 and batch: 850, loss is 3.7666951417922974 and perplexity is 43.23693651220741
At time: 614.8001313209534 and batch: 900, loss is 3.7193503046035765 and perplexity is 41.23759352877162
At time: 615.6986167430878 and batch: 950, loss is 3.827953062057495 and perplexity is 45.968347511145126
At time: 616.5967562198639 and batch: 1000, loss is 3.7924131679534914 and perplexity is 44.363327367491806
At time: 617.4944081306458 and batch: 1050, loss is 3.7460648441314697 and perplexity is 42.35408371234356
At time: 618.3913271427155 and batch: 1100, loss is 3.7635773229599 and perplexity is 43.102341507745145
At time: 619.287929058075 and batch: 1150, loss is 3.739670600891113 and perplexity is 42.084125408195256
At time: 620.1853215694427 and batch: 1200, loss is 3.7956800746917723 and perplexity is 44.50849521640231
At time: 621.0839011669159 and batch: 1250, loss is 3.786209754943848 and perplexity is 44.08897516516863
At time: 621.9823729991913 and batch: 1300, loss is 3.7869100618362426 and perplexity is 44.11986179215198
At time: 622.8806903362274 and batch: 1350, loss is 3.6776326274871827 and perplexity is 39.552647299562935
At time: 623.7783722877502 and batch: 1400, loss is 3.7052406072616577 and perplexity is 40.65982919019763
At time: 624.6773610115051 and batch: 1450, loss is 3.6120979738235475 and perplexity is 37.043688035842706
At time: 625.5756521224976 and batch: 1500, loss is 3.6288157081604004 and perplexity is 37.66818007277842
At time: 626.4737360477448 and batch: 1550, loss is 3.639857850074768 and perplexity is 38.086422358491596
At time: 627.3717310428619 and batch: 1600, loss is 3.719395627975464 and perplexity is 41.23946259791481
At time: 628.2707448005676 and batch: 1650, loss is 3.666348910331726 and perplexity is 39.108854937142816
At time: 629.169527053833 and batch: 1700, loss is 3.686741075515747 and perplexity is 39.914556244180616
At time: 630.0671288967133 and batch: 1750, loss is 3.6763929605484007 and perplexity is 39.50364556955206
At time: 630.9652733802795 and batch: 1800, loss is 3.6401592254638673 and perplexity is 38.09790239866318
At time: 631.8648459911346 and batch: 1850, loss is 3.6641706609725953 and perplexity is 39.023758812875506
At time: 632.7648437023163 and batch: 1900, loss is 3.752315263748169 and perplexity is 42.61964357374187
At time: 633.6641869544983 and batch: 1950, loss is 3.6890934753417968 and perplexity is 40.0085617652815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249418888535611 and perplexity of 70.064685122532
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 636.6646857261658 and batch: 50, loss is 3.839502363204956 and perplexity is 46.50232741168521
At time: 637.5651752948761 and batch: 100, loss is 3.8310938835144044 and perplexity is 46.112952854254274
At time: 638.4644732475281 and batch: 150, loss is 3.7961203908920287 and perplexity is 44.52809734314541
At time: 639.3638665676117 and batch: 200, loss is 3.7914030361175537 and perplexity is 44.31853718397346
At time: 640.2639586925507 and batch: 250, loss is 3.781435570716858 and perplexity is 43.87898793306682
At time: 641.1634225845337 and batch: 300, loss is 3.7833301258087157 and perplexity is 43.96219789111678
At time: 642.0624210834503 and batch: 350, loss is 3.7976757717132568 and perplexity is 44.597409381092604
At time: 642.9609625339508 and batch: 400, loss is 3.761877427101135 and perplexity is 43.02913425589378
At time: 643.860780954361 and batch: 450, loss is 3.820712456703186 and perplexity is 45.636710921733496
At time: 644.7601413726807 and batch: 500, loss is 3.825321702957153 and perplexity is 45.847547285682516
At time: 645.6597516536713 and batch: 550, loss is 3.8010915613174436 and perplexity is 44.75000521769723
At time: 646.5590536594391 and batch: 600, loss is 3.7839900779724123 and perplexity is 43.991220414421036
At time: 647.4552381038666 and batch: 650, loss is 3.8127489376068113 and perplexity is 45.27472535531833
At time: 648.3540861606598 and batch: 700, loss is 3.8406002569198607 and perplexity is 46.55341006120774
At time: 649.2539618015289 and batch: 750, loss is 3.8032157707214354 and perplexity is 44.84516463308982
At time: 650.1534910202026 and batch: 800, loss is 3.7688097524642945 and perplexity is 43.328462536428894
At time: 651.0783681869507 and batch: 850, loss is 3.7744733047485353 and perplexity is 43.57455176120273
At time: 651.9779276847839 and batch: 900, loss is 3.7225927734375 and perplexity is 41.371522152930204
At time: 652.8773372173309 and batch: 950, loss is 3.8314497804641725 and perplexity is 46.12936723426054
At time: 653.7759582996368 and batch: 1000, loss is 3.794684910774231 and perplexity is 44.464224000151056
At time: 654.6754264831543 and batch: 1050, loss is 3.7488180875778196 and perplexity is 42.470855492555785
At time: 655.5747764110565 and batch: 1100, loss is 3.766280856132507 and perplexity is 43.21902777935889
At time: 656.4739091396332 and batch: 1150, loss is 3.7422894620895386 and perplexity is 42.194482332957605
At time: 657.3729958534241 and batch: 1200, loss is 3.7975047540664675 and perplexity is 44.589783089221186
At time: 658.272819519043 and batch: 1250, loss is 3.787782921791077 and perplexity is 44.15838906473376
At time: 659.1721377372742 and batch: 1300, loss is 3.7872601890563966 and perplexity is 44.13531206133691
At time: 660.0711104869843 and batch: 1350, loss is 3.675287199020386 and perplexity is 39.45998809988846
At time: 660.969810962677 and batch: 1400, loss is 3.704014048576355 and perplexity is 40.609988096323356
At time: 661.8689804077148 and batch: 1450, loss is 3.6087601661682127 and perplexity is 36.920249452061796
At time: 662.7670047283173 and batch: 1500, loss is 3.625428304672241 and perplexity is 37.54079861620565
At time: 663.6664516925812 and batch: 1550, loss is 3.636218910217285 and perplexity is 37.94808002052554
At time: 664.5671727657318 and batch: 1600, loss is 3.7153584384918212 and perplexity is 41.07330670030445
At time: 665.4667446613312 and batch: 1650, loss is 3.659209690093994 and perplexity is 38.830642500102236
At time: 666.3653807640076 and batch: 1700, loss is 3.677572937011719 and perplexity is 39.55028645370048
At time: 667.265040397644 and batch: 1750, loss is 3.6668680715560913 and perplexity is 39.12916400954079
At time: 668.1630289554596 and batch: 1800, loss is 3.6299883842468263 and perplexity is 37.712378556956644
At time: 669.0610585212708 and batch: 1850, loss is 3.654105095863342 and perplexity is 38.63293286945155
At time: 669.9619252681732 and batch: 1900, loss is 3.7416455078125 and perplexity is 42.1673197622573
At time: 670.8633813858032 and batch: 1950, loss is 3.6794951295852663 and perplexity is 39.62638283312092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246986282703489 and perplexity of 69.8944524992602
finished 18 epochs...
Completing Train Step...
At time: 673.8446297645569 and batch: 50, loss is 3.8375782918930055 and perplexity is 46.41293963937413
At time: 674.7439064979553 and batch: 100, loss is 3.827339277267456 and perplexity is 45.94014149571669
At time: 675.6445529460907 and batch: 150, loss is 3.7910486841201783 and perplexity is 44.30283560390899
At time: 676.5456397533417 and batch: 200, loss is 3.7859753942489625 and perplexity is 44.07864365300961
At time: 677.4460415840149 and batch: 250, loss is 3.7761901950836183 and perplexity is 43.64942874737107
At time: 678.3470373153687 and batch: 300, loss is 3.7780966997146606 and perplexity is 43.73272596345394
At time: 679.2476665973663 and batch: 350, loss is 3.7913557195663454 and perplexity is 44.31644023324995
At time: 680.1484270095825 and batch: 400, loss is 3.7557803535461427 and perplexity is 42.76758062544538
At time: 681.0480351448059 and batch: 450, loss is 3.814899425506592 and perplexity is 45.37219286815197
At time: 681.9490389823914 and batch: 500, loss is 3.820773358345032 and perplexity is 45.63949035699231
At time: 682.8498206138611 and batch: 550, loss is 3.7958180046081544 and perplexity is 44.51463469282481
At time: 683.7510912418365 and batch: 600, loss is 3.7786888885498047 and perplexity is 43.75863166527654
At time: 684.6898667812347 and batch: 650, loss is 3.8073299884796143 and perplexity is 45.03004746912604
At time: 685.5976057052612 and batch: 700, loss is 3.835855278968811 and perplexity is 46.333038399727315
At time: 686.5056903362274 and batch: 750, loss is 3.7988109970092774 and perplexity is 44.648066236390505
At time: 687.4175088405609 and batch: 800, loss is 3.7644075536727906 and perplexity is 43.13814125443064
At time: 688.3406114578247 and batch: 850, loss is 3.770290846824646 and perplexity is 43.39268362494048
At time: 689.2480480670929 and batch: 900, loss is 3.7191609001159667 and perplexity is 41.22978368313229
At time: 690.1487500667572 and batch: 950, loss is 3.8284692430496214 and perplexity is 45.992081623391655
At time: 691.049037694931 and batch: 1000, loss is 3.7919114685058593 and perplexity is 44.3410758928994
At time: 691.9532165527344 and batch: 1050, loss is 3.7460305213928224 and perplexity is 42.35263002914499
At time: 692.8538868427277 and batch: 1100, loss is 3.7634424924850465 and perplexity is 43.096530390339026
At time: 693.7553656101227 and batch: 1150, loss is 3.7397355604171754 and perplexity is 42.08685926183047
At time: 694.6562159061432 and batch: 1200, loss is 3.795307297706604 and perplexity is 44.491906565866834
At time: 695.5562200546265 and batch: 1250, loss is 3.7855102157592775 and perplexity is 44.058143984499814
At time: 696.4556996822357 and batch: 1300, loss is 3.785442852973938 and perplexity is 44.05517620516419
At time: 697.3560876846313 and batch: 1350, loss is 3.6741705465316774 and perplexity is 39.41594959839947
At time: 698.2574479579926 and batch: 1400, loss is 3.703286542892456 and perplexity is 40.580454843267525
At time: 699.1581256389618 and batch: 1450, loss is 3.6087849712371827 and perplexity is 36.921165272754294
At time: 700.0592477321625 and batch: 1500, loss is 3.6263332176208496 and perplexity is 37.574785146080835
At time: 700.9590215682983 and batch: 1550, loss is 3.6374604082107544 and perplexity is 37.99522174284885
At time: 701.8830034732819 and batch: 1600, loss is 3.7169238901138306 and perplexity is 41.13765532909112
At time: 702.7841191291809 and batch: 1650, loss is 3.6612698888778685 and perplexity is 38.91072380593757
At time: 703.6850407123566 and batch: 1700, loss is 3.679918384552002 and perplexity is 39.6431584463992
At time: 704.5860815048218 and batch: 1750, loss is 3.669574499130249 and perplexity is 39.235207693015845
At time: 705.4848577976227 and batch: 1800, loss is 3.6326588106155397 and perplexity is 37.813221273679694
At time: 706.3831536769867 and batch: 1850, loss is 3.656792960166931 and perplexity is 38.73691262979623
At time: 707.2825300693512 and batch: 1900, loss is 3.7441491222381593 and perplexity is 42.273022736838534
At time: 708.1827449798584 and batch: 1950, loss is 3.6813972187042237 and perplexity is 39.70182747319973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2463282385537795 and perplexity of 69.8484739932985
finished 19 epochs...
Completing Train Step...
At time: 711.1757340431213 and batch: 50, loss is 3.836467561721802 and perplexity is 46.36141600670624
At time: 712.1121582984924 and batch: 100, loss is 3.825507378578186 and perplexity is 45.85606084785364
At time: 713.0120465755463 and batch: 150, loss is 3.788833203315735 and perplexity is 44.204792168823
At time: 713.9117889404297 and batch: 200, loss is 3.7835284233093263 and perplexity is 43.970916349475615
At time: 714.8115367889404 and batch: 250, loss is 3.7735634088516234 and perplexity is 43.534921487791216
At time: 715.7109863758087 and batch: 300, loss is 3.775527892112732 and perplexity is 43.62052917222782
At time: 716.6104805469513 and batch: 350, loss is 3.7885716915130616 and perplexity is 44.19323360535239
At time: 717.5099601745605 and batch: 400, loss is 3.7529733324050905 and perplexity is 42.64769945568271
At time: 718.4087879657745 and batch: 450, loss is 3.8121272563934325 and perplexity is 45.24658765636969
At time: 719.3331604003906 and batch: 500, loss is 3.818144826889038 and perplexity is 45.51968304857367
At time: 720.2315127849579 and batch: 550, loss is 3.792938914299011 and perplexity is 44.38665735702134
At time: 721.130131483078 and batch: 600, loss is 3.775975909233093 and perplexity is 43.64007629449195
At time: 722.0284476280212 and batch: 650, loss is 3.804617142677307 and perplexity is 44.90805344417921
At time: 722.9270370006561 and batch: 700, loss is 3.8333856439590455 and perplexity is 46.21875388459238
At time: 723.8254401683807 and batch: 750, loss is 3.796442456245422 and perplexity is 44.54244061016287
At time: 724.7257120609283 and batch: 800, loss is 3.762056756019592 and perplexity is 43.036851315927365
At time: 725.6246399879456 and batch: 850, loss is 3.7680875062942505 and perplexity is 43.2971800185073
At time: 726.5232017040253 and batch: 900, loss is 3.717291259765625 and perplexity is 41.152770831523426
At time: 727.4229438304901 and batch: 950, loss is 3.826926898956299 and perplexity is 45.92120068341088
At time: 728.3224587440491 and batch: 1000, loss is 3.7904490089416503 and perplexity is 44.27627625734529
At time: 729.221474647522 and batch: 1050, loss is 3.7446773624420167 and perplexity is 42.29535894590914
At time: 730.1218686103821 and batch: 1100, loss is 3.7621273040771483 and perplexity is 43.039887589291375
At time: 731.0238919258118 and batch: 1150, loss is 3.738618507385254 and perplexity is 42.039872256462296
At time: 731.9392077922821 and batch: 1200, loss is 3.794372110366821 and perplexity is 44.45031774782273
At time: 732.8385601043701 and batch: 1250, loss is 3.7845883989334106 and perplexity is 44.01754915942944
At time: 733.7378575801849 and batch: 1300, loss is 3.7847466707229613 and perplexity is 44.02451644705454
At time: 734.6375422477722 and batch: 1350, loss is 3.673713412284851 and perplexity is 39.39793533574876
At time: 735.5365283489227 and batch: 1400, loss is 3.7030305290222167 and perplexity is 40.57006701373798
At time: 736.4356236457825 and batch: 1450, loss is 3.608834581375122 and perplexity is 36.92299698229167
At time: 737.3355138301849 and batch: 1500, loss is 3.6268078756332396 and perplexity is 37.59262455238789
At time: 738.2350871562958 and batch: 1550, loss is 3.6380942678451538 and perplexity is 38.019313014647445
At time: 739.1346383094788 and batch: 1600, loss is 3.717733817100525 and perplexity is 41.170987322729964
At time: 740.0343236923218 and batch: 1650, loss is 3.662207636833191 and perplexity is 38.94722937146126
At time: 740.9339487552643 and batch: 1700, loss is 3.680999965667725 and perplexity is 39.68605893393887
At time: 741.8358273506165 and batch: 1750, loss is 3.670818638801575 and perplexity is 39.28405214978217
At time: 742.7364342212677 and batch: 1800, loss is 3.6338866424560545 and perplexity is 37.85967806547963
At time: 743.6349542140961 and batch: 1850, loss is 3.6580631637573244 and perplexity is 38.786147657934386
At time: 744.5333895683289 and batch: 1900, loss is 3.7452739477157593 and perplexity is 42.32059926245589
At time: 745.4319293498993 and batch: 1950, loss is 3.682245259284973 and perplexity is 39.73551051430112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2460693359375 and perplexity of 69.83039238142784
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
3085.505666732788


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.68864018758501}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.09000677972055571, 'batch_size': 32, 'rnn_dropout': 0.41910426663286526, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.83039238142784}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6648606163334299, 'batch_size': 32, 'rnn_dropout': 0.9502082500073664, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.532111644744873 and batch: 50, loss is 7.622978830337525 and perplexity is 2044.6437140451756
At time: 2.4917831420898438 and batch: 100, loss is 6.835562219619751 and perplexity is 930.3512654499995
At time: 3.448519706726074 and batch: 150, loss is 6.62529333114624 and perplexity is 753.9253299038734
At time: 4.405971050262451 and batch: 200, loss is 6.535078039169312 and perplexity is 688.8875424378224
At time: 5.36390495300293 and batch: 250, loss is 6.497796201705933 and perplexity is 663.6774090679078
At time: 6.325173377990723 and batch: 300, loss is 6.4534009742736815 and perplexity is 634.8577603001207
At time: 7.286759853363037 and batch: 350, loss is 6.42377462387085 and perplexity is 616.3251245379134
At time: 8.248140096664429 and batch: 400, loss is 6.4077809619903565 and perplexity is 606.5462374445929
At time: 9.209519624710083 and batch: 450, loss is 6.330017957687378 and perplexity is 561.1666710181543
At time: 10.169364213943481 and batch: 500, loss is 6.3281717872619625 and perplexity is 560.1316174430261
At time: 11.161788702011108 and batch: 550, loss is 6.2871399974823 and perplexity is 537.6135521385708
At time: 12.122971296310425 and batch: 600, loss is 6.3505625152587895 and perplexity is 572.814835490072
At time: 13.08403754234314 and batch: 650, loss is 6.428222198486328 and perplexity is 619.0723813028103
At time: 14.045861005783081 and batch: 700, loss is 6.322287378311157 and perplexity is 556.8452525799969
At time: 15.007076025009155 and batch: 750, loss is 6.266970834732056 and perplexity is 526.8789547259131
At time: 15.967328071594238 and batch: 800, loss is 6.276070795059204 and perplexity is 531.6954138674349
At time: 16.92863440513611 and batch: 850, loss is 6.3284986877441405 and perplexity is 560.3147546710446
At time: 17.89033532142639 and batch: 900, loss is 6.313123760223388 and perplexity is 551.7658437764765
At time: 18.85166597366333 and batch: 950, loss is 6.332555112838745 and perplexity is 562.5922456155495
At time: 19.814996004104614 and batch: 1000, loss is 6.3145247840881344 and perplexity is 552.5394226660658
At time: 20.772757291793823 and batch: 1050, loss is 6.222209749221801 and perplexity is 503.8153083483715
At time: 21.730109930038452 and batch: 1100, loss is 6.303021850585938 and perplexity is 546.2200139792766
At time: 22.687586784362793 and batch: 1150, loss is 6.210941047668457 and perplexity is 498.16983233288886
At time: 23.64670968055725 and batch: 1200, loss is 6.305360298156739 and perplexity is 547.4988154664617
At time: 24.605109214782715 and batch: 1250, loss is 6.236177530288696 and perplexity is 510.9018668074587
At time: 25.563307523727417 and batch: 1300, loss is 6.246824178695679 and perplexity is 516.370318038128
At time: 26.521634578704834 and batch: 1350, loss is 6.2443484115600585 and perplexity is 515.0934865957672
At time: 27.48078203201294 and batch: 1400, loss is 6.260197534561157 and perplexity is 523.3223041403722
At time: 28.439298629760742 and batch: 1450, loss is 6.265221071243286 and perplexity is 525.9578472630475
At time: 29.39773988723755 and batch: 1500, loss is 6.2395859050750735 and perplexity is 512.6461828012791
At time: 30.3561270236969 and batch: 1550, loss is 6.214739961624145 and perplexity is 500.06593594814393
At time: 31.314737796783447 and batch: 1600, loss is 6.212513341903686 and perplexity is 498.9537179763827
At time: 32.27440881729126 and batch: 1650, loss is 6.205230951309204 and perplexity is 495.33334061453985
At time: 33.233699560165405 and batch: 1700, loss is 6.239398889541626 and perplexity is 512.5503189662252
At time: 34.19260835647583 and batch: 1750, loss is 6.253605108261109 and perplexity is 519.8836872867854
At time: 35.15930485725403 and batch: 1800, loss is 6.259266424179077 and perplexity is 522.8352600908862
At time: 36.132092237472534 and batch: 1850, loss is 6.210681228637696 and perplexity is 498.0404151431501
At time: 37.09844946861267 and batch: 1900, loss is 6.179338951110839 and perplexity is 482.6727805635885
At time: 38.0534725189209 and batch: 1950, loss is 6.1222737026214595 and perplexity is 455.9000982018115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.593371298146803 and perplexity of 268.6397595183002
finished 1 epochs...
Completing Train Step...
At time: 41.0395941734314 and batch: 50, loss is 5.853253593444824 and perplexity is 348.3659798668066
At time: 41.95626401901245 and batch: 100, loss is 5.717010860443115 and perplexity is 303.9948803903253
At time: 42.846155405044556 and batch: 150, loss is 5.567415180206299 and perplexity is 261.7566303307415
At time: 43.7462432384491 and batch: 200, loss is 5.474554967880249 and perplexity is 238.54428343676705
At time: 44.6468026638031 and batch: 250, loss is 5.4424621200561525 and perplexity is 231.01025883023016
At time: 45.56211280822754 and batch: 300, loss is 5.404431219100952 and perplexity is 222.38969349435482
At time: 46.45715093612671 and batch: 350, loss is 5.366524171829224 and perplexity is 214.11733771357282
At time: 47.355772972106934 and batch: 400, loss is 5.305398712158203 and perplexity is 201.42129552515948
At time: 48.24544715881348 and batch: 450, loss is 5.235006647109985 and perplexity is 187.7303542043636
At time: 49.135483503341675 and batch: 500, loss is 5.20869550704956 and perplexity is 182.85536900356814
At time: 50.02630162239075 and batch: 550, loss is 5.154510078430175 and perplexity is 173.21092619930008
At time: 50.917043685913086 and batch: 600, loss is 5.153552379608154 and perplexity is 173.0451217073739
At time: 51.830077171325684 and batch: 650, loss is 5.210264530181885 and perplexity is 183.14249850491385
At time: 52.72247934341431 and batch: 700, loss is 5.175025682449341 and perplexity is 176.8011549048292
At time: 53.6138391494751 and batch: 750, loss is 5.116691951751709 and perplexity is 166.78273072678394
At time: 54.50443172454834 and batch: 800, loss is 5.09583815574646 and perplexity is 163.34069220638608
At time: 55.39923143386841 and batch: 850, loss is 5.08439751625061 and perplexity is 161.48261926977528
At time: 56.29658031463623 and batch: 900, loss is 5.095236558914184 and perplexity is 163.24245651547602
At time: 57.192452907562256 and batch: 950, loss is 5.141827735900879 and perplexity is 171.02807698186342
At time: 58.08868193626404 and batch: 1000, loss is 5.100250453948974 and perplexity is 164.0629923790487
At time: 58.983893156051636 and batch: 1050, loss is 4.999589977264404 and perplexity is 148.3523188068875
At time: 59.88029074668884 and batch: 1100, loss is 5.073964548110962 and perplexity is 159.806634199358
At time: 60.776043176651 and batch: 1150, loss is 4.975478467941284 and perplexity is 144.81809939198365
At time: 61.69559669494629 and batch: 1200, loss is 5.059276037216186 and perplexity is 157.47646794283963
At time: 62.591615200042725 and batch: 1250, loss is 5.006347055435181 and perplexity is 149.35814140585194
At time: 63.487154722213745 and batch: 1300, loss is 5.024171447753906 and perplexity is 152.04422732310692
At time: 64.38309288024902 and batch: 1350, loss is 4.946087198257446 and perplexity is 140.62365356408424
At time: 65.27877736091614 and batch: 1400, loss is 4.94933780670166 and perplexity is 141.08150975225192
At time: 66.1847460269928 and batch: 1450, loss is 4.898523330688477 and perplexity is 134.09162442932325
At time: 67.09194779396057 and batch: 1500, loss is 4.865024242401123 and perplexity is 129.6740821848206
At time: 67.9875979423523 and batch: 1550, loss is 4.863918294906616 and perplexity is 129.53074873277143
At time: 68.88352465629578 and batch: 1600, loss is 4.918503923416138 and perplexity is 136.79780003123741
At time: 69.77934312820435 and batch: 1650, loss is 4.879302024841309 and perplexity is 131.53882100806803
At time: 70.6751492023468 and batch: 1700, loss is 4.903918237686157 and perplexity is 134.81699115598514
At time: 71.57121539115906 and batch: 1750, loss is 4.908663387298584 and perplexity is 135.45823815256978
At time: 72.46682047843933 and batch: 1800, loss is 4.865656023025513 and perplexity is 129.75603364237608
At time: 73.36239409446716 and batch: 1850, loss is 4.861191282272339 and perplexity is 129.17799794098812
At time: 74.27231073379517 and batch: 1900, loss is 4.93074200630188 and perplexity is 138.48222891362775
At time: 75.19608640670776 and batch: 1950, loss is 4.851771373748779 and perplexity is 127.96686634730627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.665529330941133 and perplexity of 106.2217968270751
finished 2 epochs...
Completing Train Step...
At time: 78.13718366622925 and batch: 50, loss is 4.827736892700195 and perplexity is 124.92791521759445
At time: 79.08722257614136 and batch: 100, loss is 4.773323364257813 and perplexity is 118.31178247096939
At time: 79.99633622169495 and batch: 150, loss is 4.720475482940674 and perplexity is 112.22159944017295
At time: 80.90583443641663 and batch: 200, loss is 4.707156162261963 and perplexity is 110.73679421942984
At time: 81.80294680595398 and batch: 250, loss is 4.716764507293701 and perplexity is 111.80591958353753
At time: 82.6999659538269 and batch: 300, loss is 4.742515020370483 and perplexity is 114.72236824896393
At time: 83.59583115577698 and batch: 350, loss is 4.743061447143555 and perplexity is 114.78507275259496
At time: 84.49304389953613 and batch: 400, loss is 4.693533153533935 and perplexity is 109.2384550217872
At time: 85.38944220542908 and batch: 450, loss is 4.685594205856323 and perplexity is 108.37465003120508
At time: 86.28561472892761 and batch: 500, loss is 4.682153673171997 and perplexity is 108.00242420036669
At time: 87.20623397827148 and batch: 550, loss is 4.652135105133056 and perplexity is 104.80852407083329
At time: 88.1022789478302 and batch: 600, loss is 4.629815645217896 and perplexity is 102.49516689449135
At time: 88.99842691421509 and batch: 650, loss is 4.698872985839844 and perplexity is 109.82333023097758
At time: 89.92242789268494 and batch: 700, loss is 4.708067722320557 and perplexity is 110.83778347995207
At time: 90.82052278518677 and batch: 750, loss is 4.667374849319458 and perplexity is 106.41801210906121
At time: 91.71604609489441 and batch: 800, loss is 4.65128002166748 and perplexity is 104.71894234023546
At time: 92.61141300201416 and batch: 850, loss is 4.642599868774414 and perplexity is 103.81389954736487
At time: 93.50709915161133 and batch: 900, loss is 4.625663433074951 and perplexity is 102.07046754899052
At time: 94.40117835998535 and batch: 950, loss is 4.692931232452392 and perplexity is 109.17272187786158
At time: 95.29540228843689 and batch: 1000, loss is 4.676909513473511 and perplexity is 107.43752474612982
At time: 96.19030785560608 and batch: 1050, loss is 4.588686828613281 and perplexity is 98.3651749801838
At time: 97.08499670028687 and batch: 1100, loss is 4.654637727737427 and perplexity is 105.07114874045018
At time: 97.97909331321716 and batch: 1150, loss is 4.594599800109863 and perplexity is 98.94852843260706
At time: 98.87367963790894 and batch: 1200, loss is 4.676886262893677 and perplexity is 107.43502679042312
At time: 99.76811337471008 and batch: 1250, loss is 4.644108123779297 and perplexity is 103.97059551997133
At time: 100.66541290283203 and batch: 1300, loss is 4.651950244903564 and perplexity is 104.78915093373729
At time: 101.56012010574341 and batch: 1350, loss is 4.5544414043426515 and perplexity is 95.05364385039448
At time: 102.45501661300659 and batch: 1400, loss is 4.563072814941406 and perplexity is 95.87764189637477
At time: 103.3498592376709 and batch: 1450, loss is 4.510771217346192 and perplexity is 90.99196604013115
At time: 104.24481058120728 and batch: 1500, loss is 4.491580705642701 and perplexity is 89.26243205050736
At time: 105.14183282852173 and batch: 1550, loss is 4.507518110275268 and perplexity is 90.69644038093624
At time: 106.03717756271362 and batch: 1600, loss is 4.5757657909393314 and perplexity is 97.1023707877853
At time: 106.93237233161926 and batch: 1650, loss is 4.528693351745606 and perplexity is 92.63743742043738
At time: 107.82761025428772 and batch: 1700, loss is 4.5596248817443845 and perplexity is 95.54763144595879
At time: 108.72177314758301 and batch: 1750, loss is 4.559600229263306 and perplexity is 95.5452759888165
At time: 109.61678457260132 and batch: 1800, loss is 4.518262987136841 and perplexity is 91.67621682680173
At time: 110.51219344139099 and batch: 1850, loss is 4.542502727508545 and perplexity is 93.9255763301247
At time: 111.40909194946289 and batch: 1900, loss is 4.625174694061279 and perplexity is 102.02059391794295
At time: 112.30414366722107 and batch: 1950, loss is 4.5545556926727295 and perplexity is 95.06450799342852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490787665788518 and perplexity of 89.19167144610823
finished 3 epochs...
Completing Train Step...
At time: 115.22787928581238 and batch: 50, loss is 4.5289257049560545 and perplexity is 92.65896452727912
At time: 116.14794373512268 and batch: 100, loss is 4.485576066970825 and perplexity is 88.7280493920862
At time: 117.04533672332764 and batch: 150, loss is 4.445438795089721 and perplexity is 85.23727132880269
At time: 117.95227146148682 and batch: 200, loss is 4.443135223388672 and perplexity is 85.04114714248453
At time: 118.84802079200745 and batch: 250, loss is 4.448185434341431 and perplexity is 85.47170917465398
At time: 119.74372506141663 and batch: 300, loss is 4.479788799285888 and perplexity is 88.21603941752093
At time: 120.63992810249329 and batch: 350, loss is 4.480596122741699 and perplexity is 88.28728705139464
At time: 121.53629040718079 and batch: 400, loss is 4.4374690341949465 and perplexity is 84.56065049154546
At time: 122.43189668655396 and batch: 450, loss is 4.440969791412353 and perplexity is 84.85719556235678
At time: 123.32722187042236 and batch: 500, loss is 4.446917905807495 and perplexity is 85.36343997607578
At time: 124.22322869300842 and batch: 550, loss is 4.416569061279297 and perplexity is 82.81167561384406
At time: 125.15193843841553 and batch: 600, loss is 4.398673343658447 and perplexity is 81.34288299930087
At time: 126.0602719783783 and batch: 650, loss is 4.467570848464966 and perplexity is 87.1447778233494
At time: 126.98023462295532 and batch: 700, loss is 4.480911312103271 and perplexity is 88.31511865091696
At time: 127.87631130218506 and batch: 750, loss is 4.444878168106079 and perplexity is 85.1894984071295
At time: 128.77182531356812 and batch: 800, loss is 4.426379795074463 and perplexity is 83.62811731595629
At time: 129.66941809654236 and batch: 850, loss is 4.419192714691162 and perplexity is 83.02923001799226
At time: 130.56601333618164 and batch: 900, loss is 4.4023252201080325 and perplexity is 81.64048022147632
At time: 131.46263337135315 and batch: 950, loss is 4.475350790023803 and perplexity is 87.82540328207664
At time: 132.3583481311798 and batch: 1000, loss is 4.463740434646606 and perplexity is 86.81161574384151
At time: 133.27013278007507 and batch: 1050, loss is 4.386428480148315 and perplexity is 80.3529238261669
At time: 134.16912651062012 and batch: 1100, loss is 4.442917098999024 and perplexity is 85.02259961707647
At time: 135.08908438682556 and batch: 1150, loss is 4.397685127258301 and perplexity is 81.26253833378237
At time: 135.99988842010498 and batch: 1200, loss is 4.479596214294434 and perplexity is 88.19905196813995
At time: 136.90227007865906 and batch: 1250, loss is 4.4510812568664555 and perplexity is 85.71957879533456
At time: 137.79865431785583 and batch: 1300, loss is 4.452501535415649 and perplexity is 85.84141097167694
At time: 138.69562792778015 and batch: 1350, loss is 4.351196336746216 and perplexity is 77.57120872404057
At time: 139.5924711227417 and batch: 1400, loss is 4.35793698310852 and perplexity is 78.09585505112588
At time: 140.51237034797668 and batch: 1450, loss is 4.302168431282044 and perplexity is 73.85978003473186
At time: 141.4088912010193 and batch: 1500, loss is 4.297089033126831 and perplexity is 73.48556799481604
At time: 142.30579376220703 and batch: 1550, loss is 4.3130918216705325 and perplexity is 74.67100182595415
At time: 143.2023503780365 and batch: 1600, loss is 4.390489120483398 and perplexity is 80.6798715089235
At time: 144.09994459152222 and batch: 1650, loss is 4.342170796394348 and perplexity is 76.87423665561674
At time: 144.99648118019104 and batch: 1700, loss is 4.372641468048096 and perplexity is 79.25269892774458
At time: 145.91972947120667 and batch: 1750, loss is 4.375352544784546 and perplexity is 79.46785059066328
At time: 146.83578300476074 and batch: 1800, loss is 4.330953712463379 and perplexity is 76.01675013101928
At time: 147.73286080360413 and batch: 1850, loss is 4.360797948837281 and perplexity is 78.31960453316724
At time: 148.62903714179993 and batch: 1900, loss is 4.446680498123169 and perplexity is 85.34317644491917
At time: 149.52586030960083 and batch: 1950, loss is 4.372687206268311 and perplexity is 79.25632388803974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4266096248183135 and perplexity of 83.64733975359707
finished 4 epochs...
Completing Train Step...
At time: 152.52702736854553 and batch: 50, loss is 4.355974979400635 and perplexity is 77.94278090906661
At time: 153.45389580726624 and batch: 100, loss is 4.316700887680054 and perplexity is 74.94098129435424
At time: 154.35593223571777 and batch: 150, loss is 4.281459121704102 and perplexity is 72.34592453992437
At time: 155.25568675994873 and batch: 200, loss is 4.283577852249145 and perplexity is 72.49936855591724
At time: 156.15631008148193 and batch: 250, loss is 4.2863482475280765 and perplexity is 72.70049894098354
At time: 157.05517768859863 and batch: 300, loss is 4.3113288307189945 and perplexity is 74.53947350108336
At time: 157.99004125595093 and batch: 350, loss is 4.313494110107422 and perplexity is 74.70104714959764
At time: 158.88912534713745 and batch: 400, loss is 4.2703461074829105 and perplexity is 71.5463940767936
At time: 159.81471014022827 and batch: 450, loss is 4.286600608825683 and perplexity is 72.71884804843783
At time: 160.73992800712585 and batch: 500, loss is 4.296388330459595 and perplexity is 73.43409449723333
At time: 161.64966344833374 and batch: 550, loss is 4.265503396987915 and perplexity is 71.20075319816682
At time: 162.54830312728882 and batch: 600, loss is 4.25607274055481 and perplexity is 70.53243962797026
At time: 163.44740104675293 and batch: 650, loss is 4.3196901512145995 and perplexity is 75.165334795788
At time: 164.34674501419067 and batch: 700, loss is 4.33400938987732 and perplexity is 76.24938804967779
At time: 165.24588918685913 and batch: 750, loss is 4.302530546188354 and perplexity is 73.88653060515706
At time: 166.14410758018494 and batch: 800, loss is 4.285591330528259 and perplexity is 72.64549151809291
At time: 167.0430393218994 and batch: 850, loss is 4.277228584289551 and perplexity is 72.04050889104596
At time: 167.94239807128906 and batch: 900, loss is 4.260241098403931 and perplexity is 70.82705768647213
At time: 168.84115052223206 and batch: 950, loss is 4.33660966873169 and perplexity is 76.4479157228761
At time: 169.7392988204956 and batch: 1000, loss is 4.322501583099365 and perplexity is 75.37695435225685
At time: 170.64113354682922 and batch: 1050, loss is 4.2507234477996825 and perplexity is 70.15614830319112
At time: 171.54100108146667 and batch: 1100, loss is 4.305923366546631 and perplexity is 74.1376400741745
At time: 172.44215536117554 and batch: 1150, loss is 4.261618576049805 and perplexity is 70.92468760123354
At time: 173.34078431129456 and batch: 1200, loss is 4.340857567787171 and perplexity is 76.77334946735544
At time: 174.24051547050476 and batch: 1250, loss is 4.316955461502075 and perplexity is 74.96006173497565
At time: 175.13863921165466 and batch: 1300, loss is 4.320905170440674 and perplexity is 75.2567176274057
At time: 176.0367419719696 and batch: 1350, loss is 4.2113570833206175 and perplexity is 67.44801029932678
At time: 176.93507862091064 and batch: 1400, loss is 4.227372879981995 and perplexity is 68.53694068500437
At time: 177.83308029174805 and batch: 1450, loss is 4.164277601242065 and perplexity is 64.3461820475815
At time: 178.73006534576416 and batch: 1500, loss is 4.166022143363953 and perplexity is 64.45853464597158
At time: 179.6282389163971 and batch: 1550, loss is 4.183571271896362 and perplexity is 65.59970978272047
At time: 180.52822971343994 and batch: 1600, loss is 4.262499737739563 and perplexity is 70.98721126148736
At time: 181.4272379875183 and batch: 1650, loss is 4.217199487686157 and perplexity is 67.84322221889921
At time: 182.32526516914368 and batch: 1700, loss is 4.249344730377198 and perplexity is 70.05948944716675
At time: 183.22352719306946 and batch: 1750, loss is 4.249121098518372 and perplexity is 70.04382366506258
At time: 184.12251543998718 and batch: 1800, loss is 4.207424812316894 and perplexity is 67.18330722736162
At time: 185.02231335639954 and batch: 1850, loss is 4.234304895401001 and perplexity is 69.01369032343041
At time: 185.92206358909607 and batch: 1900, loss is 4.321848707199097 and perplexity is 75.32775861642725
At time: 186.82196593284607 and batch: 1950, loss is 4.245203199386597 and perplexity is 69.7699359117809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.395719590297965 and perplexity of 81.10297068062853
finished 5 epochs...
Completing Train Step...
At time: 189.79372119903564 and batch: 50, loss is 4.233882098197937 and perplexity is 68.98451769567583
At time: 190.6935896873474 and batch: 100, loss is 4.197790956497192 and perplexity is 66.5391806252875
At time: 191.59408855438232 and batch: 150, loss is 4.167696599960327 and perplexity is 64.56655807953788
At time: 192.49298667907715 and batch: 200, loss is 4.1700403070449825 and perplexity is 64.71806064861315
At time: 193.3947353363037 and batch: 250, loss is 4.1665326642990115 and perplexity is 64.49145047874752
At time: 194.29400897026062 and batch: 300, loss is 4.193980846405029 and perplexity is 66.28614138146402
At time: 195.19170355796814 and batch: 350, loss is 4.19390896320343 and perplexity is 66.28137669265247
At time: 196.12938928604126 and batch: 400, loss is 4.151568746566772 and perplexity is 63.533590263591876
At time: 197.05286312103271 and batch: 450, loss is 4.173403038978576 and perplexity is 64.93605646315591
At time: 197.95078420639038 and batch: 500, loss is 4.186856498718262 and perplexity is 65.8155740962771
At time: 198.8503978252411 and batch: 550, loss is 4.15673876285553 and perplexity is 63.8629105221534
At time: 199.7547745704651 and batch: 600, loss is 4.152624745368957 and perplexity is 63.600717095497835
At time: 200.6564667224884 and batch: 650, loss is 4.210001392364502 and perplexity is 67.35663359503687
At time: 201.55546188354492 and batch: 700, loss is 4.228608846664429 and perplexity is 68.62170243076358
At time: 202.50230932235718 and batch: 750, loss is 4.201020088195801 and perplexity is 66.75439168807074
At time: 203.40417766571045 and batch: 800, loss is 4.181740508079529 and perplexity is 65.47972207574526
At time: 204.30608558654785 and batch: 850, loss is 4.175343689918518 and perplexity is 65.06219703999326
At time: 205.21150970458984 and batch: 900, loss is 4.155597538948059 and perplexity is 63.790070213321336
At time: 206.11376118659973 and batch: 950, loss is 4.236884083747864 and perplexity is 69.1919193736298
At time: 207.01589488983154 and batch: 1000, loss is 4.221224384307861 and perplexity is 68.11683443588583
At time: 207.91838121414185 and batch: 1050, loss is 4.1496345949172975 and perplexity is 63.41082542636406
At time: 208.84878206253052 and batch: 1100, loss is 4.202100882530212 and perplexity is 66.82657845890388
At time: 209.76227474212646 and batch: 1150, loss is 4.15886016368866 and perplexity is 63.99853315786506
At time: 210.6764850616455 and batch: 1200, loss is 4.237640552520752 and perplexity is 69.24428070233022
At time: 211.57905888557434 and batch: 1250, loss is 4.221605348587036 and perplexity is 68.14278946027102
At time: 212.49735188484192 and batch: 1300, loss is 4.2194699907302855 and perplexity is 67.99743546604445
At time: 213.41779780387878 and batch: 1350, loss is 4.113983364105224 and perplexity is 61.18997470594236
At time: 214.32720923423767 and batch: 1400, loss is 4.129047875404358 and perplexity is 62.11874997951194
At time: 215.24127626419067 and batch: 1450, loss is 4.0645711660385135 and perplexity is 58.239927907665454
At time: 216.14348816871643 and batch: 1500, loss is 4.0703342294692995 and perplexity is 58.57653732546743
At time: 217.04300594329834 and batch: 1550, loss is 4.088114156723022 and perplexity is 59.62733779388231
At time: 217.94285082817078 and batch: 1600, loss is 4.172558736801148 and perplexity is 64.88125394748756
At time: 218.84894824028015 and batch: 1650, loss is 4.127236108779908 and perplexity is 62.00630719234874
At time: 219.7494354248047 and batch: 1700, loss is 4.156826868057251 and perplexity is 63.86853742464349
At time: 220.6494336128235 and batch: 1750, loss is 4.15507550239563 and perplexity is 63.756778155579575
At time: 221.54931473731995 and batch: 1800, loss is 4.113038272857666 and perplexity is 61.13217191516771
At time: 222.44948196411133 and batch: 1850, loss is 4.1433448362350465 and perplexity is 63.013238310842375
At time: 223.3490767478943 and batch: 1900, loss is 4.229050860404969 and perplexity is 68.65204087064691
At time: 224.24905014038086 and batch: 1950, loss is 4.148341817855835 and perplexity is 63.32890233136311
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388475426962209 and perplexity of 80.5175704415233
finished 6 epochs...
Completing Train Step...
At time: 227.20730090141296 and batch: 50, loss is 4.1418644189834595 and perplexity is 62.920021442723275
At time: 228.10620713233948 and batch: 100, loss is 4.110454363822937 and perplexity is 60.974415845283296
At time: 229.00544786453247 and batch: 150, loss is 4.078823685646057 and perplexity is 59.07593708893733
At time: 229.90462493896484 and batch: 200, loss is 4.079295678138733 and perplexity is 59.103827069153965
At time: 230.80324578285217 and batch: 250, loss is 4.076952834129333 and perplexity is 58.965518103402204
At time: 231.70263481140137 and batch: 300, loss is 4.105061917304993 and perplexity is 60.64649949916281
At time: 232.59853172302246 and batch: 350, loss is 4.104125013351441 and perplexity is 60.58970616311785
At time: 233.498309135437 and batch: 400, loss is 4.061902112960816 and perplexity is 58.084689710490295
At time: 234.39604425430298 and batch: 450, loss is 4.0889084959030155 and perplexity is 59.6747209411444
At time: 235.29500555992126 and batch: 500, loss is 4.102988305091858 and perplexity is 60.52087247300032
At time: 236.19586038589478 and batch: 550, loss is 4.072952480316162 and perplexity is 58.73010634730751
At time: 237.0946545600891 and batch: 600, loss is 4.069888648986816 and perplexity is 58.550442577790605
At time: 237.99132561683655 and batch: 650, loss is 4.126346273422241 and perplexity is 61.95115632904381
At time: 238.88939952850342 and batch: 700, loss is 4.143179521560669 and perplexity is 63.002822158864674
At time: 239.78806161880493 and batch: 750, loss is 4.118781352043152 and perplexity is 61.48426891195787
At time: 240.68703985214233 and batch: 800, loss is 4.098702526092529 and perplexity is 60.262048416259006
At time: 241.586669921875 and batch: 850, loss is 4.096160969734192 and perplexity is 60.109083490769585
At time: 242.48566317558289 and batch: 900, loss is 4.075006346702576 and perplexity is 58.85085409602942
At time: 243.38514137268066 and batch: 950, loss is 4.16185158252716 and perplexity is 64.19026620954297
At time: 244.2851378917694 and batch: 1000, loss is 4.138901009559631 and perplexity is 62.73383966090665
At time: 245.18585729599 and batch: 1050, loss is 4.0695314645767215 and perplexity is 58.52953300700635
At time: 246.0857172012329 and batch: 1100, loss is 4.120964946746827 and perplexity is 61.61867232379852
At time: 246.98634457588196 and batch: 1150, loss is 4.081829829216003 and perplexity is 59.25379503667843
At time: 247.9103982448578 and batch: 1200, loss is 4.1591003179550174 and perplexity is 64.0139045243193
At time: 248.8091447353363 and batch: 1250, loss is 4.144117441177368 and perplexity is 63.06194146191798
At time: 249.70813655853271 and batch: 1300, loss is 4.143047266006469 and perplexity is 62.99449023668754
At time: 250.60744786262512 and batch: 1350, loss is 4.034375824928284 and perplexity is 56.507638569142834
At time: 251.50641083717346 and batch: 1400, loss is 4.0535537099838255 and perplexity is 57.601793823373775
At time: 252.40548300743103 and batch: 1450, loss is 3.9825848579406737 and perplexity is 53.655547099300996
At time: 253.3044035434723 and batch: 1500, loss is 3.9925568151474 and perplexity is 54.193274560537134
At time: 254.20388650894165 and batch: 1550, loss is 4.0100457239151 and perplexity is 55.14939215193951
At time: 255.10333609580994 and batch: 1600, loss is 4.097588338851929 and perplexity is 60.194942601984366
At time: 256.0033793449402 and batch: 1650, loss is 4.054842009544372 and perplexity is 57.67605001087965
At time: 256.90446496009827 and batch: 1700, loss is 4.082441177368164 and perplexity is 59.29003080999055
At time: 257.8035497665405 and batch: 1750, loss is 4.08400185585022 and perplexity is 59.3826357297323
At time: 258.7026035785675 and batch: 1800, loss is 4.04027289390564 and perplexity is 56.841852484252605
At time: 259.6179277896881 and batch: 1850, loss is 4.07467866897583 and perplexity is 58.83157314108442
At time: 260.5321435928345 and batch: 1900, loss is 4.152225403785706 and perplexity is 63.57532375508285
At time: 261.4456522464752 and batch: 1950, loss is 4.077557530403137 and perplexity is 59.00118511525001
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380568677325582 and perplexity of 79.883448396415
finished 7 epochs...
Completing Train Step...
At time: 264.4839437007904 and batch: 50, loss is 4.073561949729919 and perplexity is 58.76591146074534
At time: 265.45820474624634 and batch: 100, loss is 4.0404707717895505 and perplexity is 56.85310134265318
At time: 266.37274861335754 and batch: 150, loss is 4.013079724311829 and perplexity is 55.31696951595428
At time: 267.272620677948 and batch: 200, loss is 4.008305959701538 and perplexity is 55.053528627218505
At time: 268.17222571372986 and batch: 250, loss is 4.0020301723480225 and perplexity is 54.70910627963668
At time: 269.07032537460327 and batch: 300, loss is 4.034082531929016 and perplexity is 56.49106770452344
At time: 269.969265460968 and batch: 350, loss is 4.031447257995605 and perplexity is 56.342394250011445
At time: 270.8996195793152 and batch: 400, loss is 3.986552734375 and perplexity is 53.868868617040256
At time: 271.7968120574951 and batch: 450, loss is 4.0204257392883305 and perplexity is 55.724825024688485
At time: 272.6940453052521 and batch: 500, loss is 4.0357230854034425 and perplexity is 56.58382038398242
At time: 273.59192299842834 and batch: 550, loss is 4.005730924606323 and perplexity is 54.911946226946554
At time: 274.4903383255005 and batch: 600, loss is 4.002192983627319 and perplexity is 54.71801426435976
At time: 275.389755487442 and batch: 650, loss is 4.058689379692078 and perplexity is 57.898378539754646
At time: 276.28810262680054 and batch: 700, loss is 4.069490084648132 and perplexity is 58.52711110921947
At time: 277.18684434890747 and batch: 750, loss is 4.054234595298767 and perplexity is 57.64102739416776
At time: 278.084344625473 and batch: 800, loss is 4.0333024549484255 and perplexity is 56.44701750650467
At time: 278.9830369949341 and batch: 850, loss is 4.031234040260315 and perplexity is 56.33038233293099
At time: 279.88095331192017 and batch: 900, loss is 4.006776709556579 and perplexity is 54.969402352038955
At time: 280.77827048301697 and batch: 950, loss is 4.096238083839417 and perplexity is 60.113718927685355
At time: 281.67677664756775 and batch: 1000, loss is 4.075160083770752 and perplexity is 58.85990234930591
At time: 282.57623386383057 and batch: 1050, loss is 4.008160705566406 and perplexity is 55.0455324552844
At time: 283.47633504867554 and batch: 1100, loss is 4.0549300146102905 and perplexity is 57.68112601881669
At time: 284.375629901886 and batch: 1150, loss is 4.018714966773987 and perplexity is 55.62957402529678
At time: 285.2740750312805 and batch: 1200, loss is 4.093822774887085 and perplexity is 59.96870092633928
At time: 286.1703815460205 and batch: 1250, loss is 4.079651494026184 and perplexity is 59.124860891696514
At time: 287.06694412231445 and batch: 1300, loss is 4.078078136444092 and perplexity is 59.03190948559698
At time: 287.96564531326294 and batch: 1350, loss is 3.9727608346939087 and perplexity is 53.131014486181435
At time: 288.864869594574 and batch: 1400, loss is 3.989791917800903 and perplexity is 54.043642673234515
At time: 289.76359272003174 and batch: 1450, loss is 3.920093450546265 and perplexity is 50.4051549472425
At time: 290.66229224205017 and batch: 1500, loss is 3.9297042798995974 and perplexity is 50.89192567835171
At time: 291.5604865550995 and batch: 1550, loss is 3.9497540521621706 and perplexity is 51.922595014316734
At time: 292.45886063575745 and batch: 1600, loss is 4.037180209159851 and perplexity is 56.66633011173573
At time: 293.35680389404297 and batch: 1650, loss is 3.995341377258301 and perplexity is 54.34438939622432
At time: 294.2553927898407 and batch: 1700, loss is 4.02458236694336 and perplexity is 55.956934435465556
At time: 295.15496945381165 and batch: 1750, loss is 4.024197688102722 and perplexity is 55.935413126462784
At time: 296.05263805389404 and batch: 1800, loss is 3.980386791229248 and perplexity is 53.537738150735564
At time: 296.9502806663513 and batch: 1850, loss is 4.0131737232208256 and perplexity is 55.322169495130154
At time: 297.8483347892761 and batch: 1900, loss is 4.088711771965027 and perplexity is 59.66298264968181
At time: 298.7463335990906 and batch: 1950, loss is 4.018447909355164 and perplexity is 55.61471971841205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384371877271076 and perplexity of 80.18783958637958
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 301.6817772388458 and batch: 50, loss is 4.0437821006774906 and perplexity is 57.041672698080966
At time: 302.60260343551636 and batch: 100, loss is 4.030895576477051 and perplexity is 56.31131976479035
At time: 303.502925157547 and batch: 150, loss is 4.001711502075195 and perplexity is 54.69167489139254
At time: 304.40208745002747 and batch: 200, loss is 3.995966739654541 and perplexity is 54.37838496246582
At time: 305.3004150390625 and batch: 250, loss is 3.9868401956558226 and perplexity is 53.88435605692237
At time: 306.19922161102295 and batch: 300, loss is 4.0126468944549565 and perplexity is 55.29303186079573
At time: 307.09736919403076 and batch: 350, loss is 4.009633240699768 and perplexity is 55.12664864432109
At time: 307.9952747821808 and batch: 400, loss is 3.9645951318740846 and perplexity is 52.69892895330451
At time: 308.89340925216675 and batch: 450, loss is 3.986996192932129 and perplexity is 53.89276252537882
At time: 309.791170835495 and batch: 500, loss is 3.9981268548965456 and perplexity is 54.49597549949044
At time: 310.68988060951233 and batch: 550, loss is 3.957425718307495 and perplexity is 52.322459681631216
At time: 311.58926653862 and batch: 600, loss is 3.9405843162536622 and perplexity is 51.44865480452774
At time: 312.4878120422363 and batch: 650, loss is 3.9820146942138672 and perplexity is 53.62496337229743
At time: 313.386385679245 and batch: 700, loss is 3.9995038223266604 and perplexity is 54.571066369802324
At time: 314.28517866134644 and batch: 750, loss is 3.9677355766296385 and perplexity is 52.86468716938838
At time: 315.1854066848755 and batch: 800, loss is 3.943506484031677 and perplexity is 51.59921628163041
At time: 316.1083483695984 and batch: 850, loss is 3.9459128379821777 and perplexity is 51.72353177312167
At time: 317.0087103843689 and batch: 900, loss is 3.9107024574279787 and perplexity is 49.93401617698321
At time: 317.90673446655273 and batch: 950, loss is 4.006242656707764 and perplexity is 54.940053623698724
At time: 318.80641055107117 and batch: 1000, loss is 3.9680124282836915 and perplexity is 52.87932487161476
At time: 319.71085596084595 and batch: 1050, loss is 3.900737943649292 and perplexity is 49.43891878373579
At time: 320.60673356056213 and batch: 1100, loss is 3.9361755943298338 and perplexity is 51.222331257515556
At time: 321.5034489631653 and batch: 1150, loss is 3.901559281349182 and perplexity is 49.47954151178001
At time: 322.40025806427 and batch: 1200, loss is 3.9619384813308716 and perplexity is 52.55911211954082
At time: 323.2960286140442 and batch: 1250, loss is 3.9431764698028564 and perplexity is 51.582190615572024
At time: 324.21214723587036 and batch: 1300, loss is 3.943325481414795 and perplexity is 51.589877533648774
At time: 325.1083104610443 and batch: 1350, loss is 3.835038228034973 and perplexity is 46.29519740854899
At time: 326.0038249492645 and batch: 1400, loss is 3.8407796669006347 and perplexity is 46.56176295688581
At time: 326.90027809143066 and batch: 1450, loss is 3.756822419166565 and perplexity is 42.81217047962582
At time: 327.814329624176 and batch: 1500, loss is 3.7602289724349975 and perplexity is 42.95826111038274
At time: 328.71857500076294 and batch: 1550, loss is 3.7760057258605957 and perplexity is 43.64137751378989
At time: 329.6142599582672 and batch: 1600, loss is 3.85959445476532 and perplexity is 47.44610592450637
At time: 330.5160768032074 and batch: 1650, loss is 3.80759934425354 and perplexity is 45.04217820608067
At time: 331.4328782558441 and batch: 1700, loss is 3.826736216545105 and perplexity is 45.912445152929
At time: 332.3555209636688 and batch: 1750, loss is 3.8237047004699707 and perplexity is 45.77347159411956
At time: 333.28065371513367 and batch: 1800, loss is 3.778055305480957 and perplexity is 43.73091571824204
At time: 334.18033242225647 and batch: 1850, loss is 3.802540464401245 and perplexity is 44.81489063324535
At time: 335.0797154903412 and batch: 1900, loss is 3.869216480255127 and perplexity is 47.90483698685782
At time: 335.9784998893738 and batch: 1950, loss is 3.797905478477478 and perplexity is 44.60765488437985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.299582405977471 and perplexity of 73.66902353145154
finished 9 epochs...
Completing Train Step...
At time: 338.9133200645447 and batch: 50, loss is 3.9517784786224364 and perplexity is 52.027814958633826
At time: 339.83696269989014 and batch: 100, loss is 3.933139638900757 and perplexity is 51.06705836290086
At time: 340.73643016815186 and batch: 150, loss is 3.8995438480377196 and perplexity is 49.379919220345556
At time: 341.63611674308777 and batch: 200, loss is 3.896147813796997 and perplexity is 49.21250775230504
At time: 342.5358307361603 and batch: 250, loss is 3.888096809387207 and perplexity is 48.81788830837278
At time: 343.43744468688965 and batch: 300, loss is 3.9137687253952027 and perplexity is 50.08736223116184
At time: 344.3362238407135 and batch: 350, loss is 3.915081486701965 and perplexity is 50.15315815998238
At time: 345.2360951900482 and batch: 400, loss is 3.8699185466766357 and perplexity is 47.938481173178964
At time: 346.13533544540405 and batch: 450, loss is 3.9030465698242187 and perplexity is 49.5531866158024
At time: 347.03371477127075 and batch: 500, loss is 3.915863356590271 and perplexity is 50.192386737974616
At time: 347.93368554115295 and batch: 550, loss is 3.880081729888916 and perplexity is 48.428172938799634
At time: 348.83326411247253 and batch: 600, loss is 3.8690182161331177 and perplexity is 47.895340117887926
At time: 349.7346348762512 and batch: 650, loss is 3.912575011253357 and perplexity is 50.02760791042319
At time: 350.63490533828735 and batch: 700, loss is 3.9307918977737426 and perplexity is 50.94730675763577
At time: 351.5357930660248 and batch: 750, loss is 3.9033022832870485 and perplexity is 49.56585965301024
At time: 352.43573546409607 and batch: 800, loss is 3.880115857124329 and perplexity is 48.429825686659825
At time: 353.33512330055237 and batch: 850, loss is 3.885093779563904 and perplexity is 48.671506638140805
At time: 354.2353353500366 and batch: 900, loss is 3.8487245416641236 and perplexity is 46.9331637451222
At time: 355.1353974342346 and batch: 950, loss is 3.9483472967147826 and perplexity is 51.84960397324734
At time: 356.03530287742615 and batch: 1000, loss is 3.9101174306869506 and perplexity is 49.904811985682116
At time: 356.9340326786041 and batch: 1050, loss is 3.847641320228577 and perplexity is 46.882352261128155
At time: 357.83440470695496 and batch: 1100, loss is 3.8818154621124266 and perplexity is 48.512207248195025
At time: 358.7341260910034 and batch: 1150, loss is 3.851304669380188 and perplexity is 47.054413654565565
At time: 359.6344213485718 and batch: 1200, loss is 3.91394172668457 and perplexity is 50.09602815899558
At time: 360.55942273139954 and batch: 1250, loss is 3.900504512786865 and perplexity is 49.427379561144384
At time: 361.4591031074524 and batch: 1300, loss is 3.90168860912323 and perplexity is 49.48594100455181
At time: 362.35942482948303 and batch: 1350, loss is 3.7944744396209718 and perplexity is 44.454866548418345
At time: 363.2591383457184 and batch: 1400, loss is 3.8062206745147704 and perplexity is 44.980122704869736
At time: 364.15969371795654 and batch: 1450, loss is 3.7231736469268797 and perplexity is 41.39556075438137
At time: 365.0604362487793 and batch: 1500, loss is 3.730770621299744 and perplexity is 41.711239351433406
At time: 365.9599275588989 and batch: 1550, loss is 3.7484331846237184 and perplexity is 42.45451148044455
At time: 366.85982942581177 and batch: 1600, loss is 3.8368828296661377 and perplexity is 46.38067241463559
At time: 367.75902485847473 and batch: 1650, loss is 3.7857542419433594 and perplexity is 44.068896637165125
At time: 368.6593544483185 and batch: 1700, loss is 3.80945867061615 and perplexity is 45.12600422125902
At time: 369.559068441391 and batch: 1750, loss is 3.8085427188873293 and perplexity is 45.084689903526616
At time: 370.45942425727844 and batch: 1800, loss is 3.766735763549805 and perplexity is 43.23869290823148
At time: 371.35942578315735 and batch: 1850, loss is 3.794498028755188 and perplexity is 44.45591521260041
At time: 372.2596960067749 and batch: 1900, loss is 3.865163903236389 and perplexity is 47.7110917942186
At time: 373.15939021110535 and batch: 1950, loss is 3.7942231035232545 and perplexity is 44.44369483972117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298729049327761 and perplexity of 73.60618439625365
finished 10 epochs...
Completing Train Step...
At time: 376.11995029449463 and batch: 50, loss is 3.910282597541809 and perplexity is 49.91305528726144
At time: 377.04137992858887 and batch: 100, loss is 3.8902753973007203 and perplexity is 48.92435830481728
At time: 377.95016050338745 and batch: 150, loss is 3.8563916444778443 and perplexity is 47.294388139685026
At time: 378.8479187488556 and batch: 200, loss is 3.8527115201950073 and perplexity is 47.120658782336136
At time: 379.7509591579437 and batch: 250, loss is 3.8448889875411987 and perplexity is 46.753493842502955
At time: 380.6549162864685 and batch: 300, loss is 3.8711001539230345 and perplexity is 47.99515910884984
At time: 381.55426144599915 and batch: 350, loss is 3.8722962951660156 and perplexity is 48.05260244644705
At time: 382.45503330230713 and batch: 400, loss is 3.8276582193374633 and perplexity is 45.95479607639869
At time: 383.37970066070557 and batch: 450, loss is 3.8639906644821167 and perplexity is 47.65514811637958
At time: 384.2776744365692 and batch: 500, loss is 3.876920084953308 and perplexity is 48.27530204017957
At time: 385.1763331890106 and batch: 550, loss is 3.842613043785095 and perplexity is 46.64720651798237
At time: 386.0750548839569 and batch: 600, loss is 3.833935441970825 and perplexity is 46.244171850318295
At time: 386.97429633140564 and batch: 650, loss is 3.8770930051803587 and perplexity is 48.28365053816057
At time: 387.87349677085876 and batch: 700, loss is 3.8951671361923217 and perplexity is 49.1642698048858
At time: 388.7726185321808 and batch: 750, loss is 3.86960289478302 and perplexity is 47.92335168877042
At time: 389.6719958782196 and batch: 800, loss is 3.8471066427230833 and perplexity is 46.85729202213956
At time: 390.57189106941223 and batch: 850, loss is 3.8530854558944703 and perplexity is 47.13828217363928
At time: 391.47080993652344 and batch: 900, loss is 3.8158106565475465 and perplexity is 45.41355626163152
At time: 392.37010622024536 and batch: 950, loss is 3.91732328414917 and perplexity is 50.265717502397564
At time: 393.2696225643158 and batch: 1000, loss is 3.8793548059463503 and perplexity is 48.39298213246517
At time: 394.16697573661804 and batch: 1050, loss is 3.819009346961975 and perplexity is 45.55905274377672
At time: 395.06609892845154 and batch: 1100, loss is 3.8524416875839234 and perplexity is 47.107945807205674
At time: 395.96631145477295 and batch: 1150, loss is 3.8229598569869996 and perplexity is 45.73939021633146
At time: 396.8652808666229 and batch: 1200, loss is 3.8865428304672243 and perplexity is 48.7420852524534
At time: 397.7647337913513 and batch: 1250, loss is 3.875463104248047 and perplexity is 48.20501707092178
At time: 398.6642644405365 and batch: 1300, loss is 3.876529059410095 and perplexity is 48.25642885416492
At time: 399.56331419944763 and batch: 1350, loss is 3.769558529853821 and perplexity is 43.360918058963435
At time: 400.4629979133606 and batch: 1400, loss is 3.7836475133895875 and perplexity is 43.97615316125281
At time: 401.3634467124939 and batch: 1450, loss is 3.7008109855651856 and perplexity is 40.4801198446977
At time: 402.2623131275177 and batch: 1500, loss is 3.7103301954269408 and perplexity is 40.867298494448995
At time: 403.16201424598694 and batch: 1550, loss is 3.727810320854187 and perplexity is 41.58794413647673
At time: 404.0615077018738 and batch: 1600, loss is 3.81813533782959 and perplexity is 45.51925111164451
At time: 404.95972752571106 and batch: 1650, loss is 3.76751247882843 and perplexity is 43.272290107681094
At time: 405.85878229141235 and batch: 1700, loss is 3.7928392457962037 and perplexity is 44.38223362579494
At time: 406.7584629058838 and batch: 1750, loss is 3.792954139709473 and perplexity is 44.387333167243355
At time: 407.65781831741333 and batch: 1800, loss is 3.75249050617218 and perplexity is 42.6271129978531
At time: 408.5571537017822 and batch: 1850, loss is 3.7817665672302248 and perplexity is 43.893514129010214
At time: 409.45519185066223 and batch: 1900, loss is 3.854257640838623 and perplexity is 47.193569355367
At time: 410.3533079624176 and batch: 1950, loss is 3.782948079109192 and perplexity is 43.9454054864543
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.300926314952761 and perplexity of 73.76809454968067
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 413.2986640930176 and batch: 50, loss is 3.903443284034729 and perplexity is 49.572848969018544
At time: 414.19806385040283 and batch: 100, loss is 3.9068334531784057 and perplexity is 49.74119451065145
At time: 415.097531080246 and batch: 150, loss is 3.8827505826950075 and perplexity is 48.55759322907437
At time: 415.9968466758728 and batch: 200, loss is 3.87742796421051 and perplexity is 48.299826291873146
At time: 416.8967866897583 and batch: 250, loss is 3.875752091407776 and perplexity is 48.21894971497044
At time: 417.79508566856384 and batch: 300, loss is 3.893856325149536 and perplexity is 49.09986695631916
At time: 418.69425106048584 and batch: 350, loss is 3.8933350372314455 and perplexity is 49.07427845896168
At time: 419.59390473365784 and batch: 400, loss is 3.8579386329650878 and perplexity is 47.36760863467729
At time: 420.4930205345154 and batch: 450, loss is 3.8960269784927366 and perplexity is 49.20656150322302
At time: 421.3910553455353 and batch: 500, loss is 3.905235280990601 and perplexity is 49.6617630065134
At time: 422.2892017364502 and batch: 550, loss is 3.867924919128418 and perplexity is 47.84300490017937
At time: 423.18681383132935 and batch: 600, loss is 3.8430033540725708 and perplexity is 46.66541695619784
At time: 424.0860044956207 and batch: 650, loss is 3.878826017379761 and perplexity is 48.36739924137663
At time: 424.9970591068268 and batch: 700, loss is 3.897135157585144 and perplexity is 49.26112141138133
At time: 425.9114692211151 and batch: 750, loss is 3.8661922454833983 and perplexity is 47.760180361159264
At time: 426.8101327419281 and batch: 800, loss is 3.8428663301467894 and perplexity is 46.65902311563284
At time: 427.731716632843 and batch: 850, loss is 3.8475431489944456 and perplexity is 46.87774998865679
At time: 428.63113713264465 and batch: 900, loss is 3.803676428794861 and perplexity is 44.865827679166244
At time: 429.5301733016968 and batch: 950, loss is 3.9071571159362795 and perplexity is 49.757296488511415
At time: 430.4283256530762 and batch: 1000, loss is 3.873003978729248 and perplexity is 48.0866205189646
At time: 431.32831478118896 and batch: 1050, loss is 3.8119107055664063 and perplexity is 45.23679053121865
At time: 432.2271246910095 and batch: 1100, loss is 3.8368218660354616 and perplexity is 46.37784496663862
At time: 433.1256105899811 and batch: 1150, loss is 3.812321939468384 and perplexity is 45.255397258698096
At time: 434.0249648094177 and batch: 1200, loss is 3.8700218105316164 and perplexity is 47.943431741149794
At time: 434.92433977127075 and batch: 1250, loss is 3.8527388429641722 and perplexity is 47.12194626680768
At time: 435.82433104515076 and batch: 1300, loss is 3.854298725128174 and perplexity is 47.19550830946534
At time: 436.7239713668823 and batch: 1350, loss is 3.751233558654785 and perplexity is 42.573566613544045
At time: 437.62305760383606 and batch: 1400, loss is 3.759443678855896 and perplexity is 42.92453950617599
At time: 438.5214772224426 and batch: 1450, loss is 3.665704846382141 and perplexity is 39.08367444336283
At time: 439.42114067077637 and batch: 1500, loss is 3.6708542585372923 and perplexity is 39.285451462259076
At time: 440.32459926605225 and batch: 1550, loss is 3.6878405714035036 and perplexity is 39.9584662696554
At time: 441.22340059280396 and batch: 1600, loss is 3.7733808279037477 and perplexity is 43.526973566151895
At time: 442.12284994125366 and batch: 1650, loss is 3.7174186086654664 and perplexity is 41.15801192533093
At time: 443.0227634906769 and batch: 1700, loss is 3.7369822454452515 and perplexity is 41.97114026063588
At time: 443.9233396053314 and batch: 1750, loss is 3.7344798183441164 and perplexity is 41.866241846839614
At time: 444.8231432437897 and batch: 1800, loss is 3.6966838741302492 and perplexity is 40.3133981553425
At time: 445.72199416160583 and batch: 1850, loss is 3.7240793323516845 and perplexity is 41.43306909322223
At time: 446.62159538269043 and batch: 1900, loss is 3.800116400718689 and perplexity is 44.70638804614486
At time: 447.5194282531738 and batch: 1950, loss is 3.734007396697998 and perplexity is 41.846467999114154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2785031340843025 and perplexity of 72.1323866458158
finished 12 epochs...
Completing Train Step...
At time: 450.4696707725525 and batch: 50, loss is 3.8922276592254637 and perplexity is 49.01996476078454
At time: 451.3706738948822 and batch: 100, loss is 3.881935315132141 and perplexity is 48.51802193117344
At time: 452.2707784175873 and batch: 150, loss is 3.850341320037842 and perplexity is 47.00910564334234
At time: 453.1709551811218 and batch: 200, loss is 3.842025122642517 and perplexity is 46.61978969928165
At time: 454.06920862197876 and batch: 250, loss is 3.837564206123352 and perplexity is 46.41228588200179
At time: 454.96936416625977 and batch: 300, loss is 3.8553275060653687 and perplexity is 47.24408713293449
At time: 455.86929655075073 and batch: 350, loss is 3.856423029899597 and perplexity is 47.29587251729711
At time: 456.769394159317 and batch: 400, loss is 3.8204748106002806 and perplexity is 45.625866823813375
At time: 457.66901183128357 and batch: 450, loss is 3.861284656524658 and perplexity is 47.52636722600279
At time: 458.5690960884094 and batch: 500, loss is 3.8720392656326292 and perplexity is 48.04025309560417
At time: 459.467529296875 and batch: 550, loss is 3.835123300552368 and perplexity is 46.29913602506747
At time: 460.3670597076416 and batch: 600, loss is 3.8136887121200562 and perplexity is 45.317293387344286
At time: 461.26641941070557 and batch: 650, loss is 3.8513039112091065 and perplexity is 47.0543779792834
At time: 462.1666808128357 and batch: 700, loss is 3.8713701152801514 and perplexity is 48.00811769621812
At time: 463.06674814224243 and batch: 750, loss is 3.843004765510559 and perplexity is 46.66548282158655
At time: 463.9670000076294 and batch: 800, loss is 3.820225076675415 and perplexity is 45.61447391967262
At time: 464.86825037002563 and batch: 850, loss is 3.825665383338928 and perplexity is 45.863306896216464
At time: 465.76838064193726 and batch: 900, loss is 3.782331190109253 and perplexity is 43.91830440924951
At time: 466.66881680488586 and batch: 950, loss is 3.8866016912460326 and perplexity is 48.744954333989455
At time: 467.56905364990234 and batch: 1000, loss is 3.8527284049987793 and perplexity is 47.12145441213029
At time: 468.4694230556488 and batch: 1050, loss is 3.793268795013428 and perplexity is 44.401302074632994
At time: 469.3690812587738 and batch: 1100, loss is 3.8189475774765014 and perplexity is 45.55623867144286
At time: 470.27001762390137 and batch: 1150, loss is 3.795412931442261 and perplexity is 44.496606660403785
At time: 471.17004227638245 and batch: 1200, loss is 3.85452871799469 and perplexity is 47.20636418804759
At time: 472.07016611099243 and batch: 1250, loss is 3.8391184329986574 and perplexity is 46.48447719036752
At time: 472.9702744483948 and batch: 1300, loss is 3.8412461996078493 and perplexity is 46.58349061014713
At time: 473.87032890319824 and batch: 1350, loss is 3.7383368682861327 and perplexity is 42.028033851869864
At time: 474.77017641067505 and batch: 1400, loss is 3.7490792512893676 and perplexity is 42.481948787328804
At time: 475.67029213905334 and batch: 1450, loss is 3.6577821874618532 and perplexity is 38.775251200744634
At time: 476.57045578956604 and batch: 1500, loss is 3.6649364709854124 and perplexity is 39.053655044067675
At time: 477.4697480201721 and batch: 1550, loss is 3.683182601928711 and perplexity is 39.77277376426516
At time: 478.36971402168274 and batch: 1600, loss is 3.771436862945557 and perplexity is 43.44244084574709
At time: 479.26873302459717 and batch: 1650, loss is 3.71666702747345 and perplexity is 41.127089959306694
At time: 480.1695761680603 and batch: 1700, loss is 3.738006901741028 and perplexity is 42.014168294453064
At time: 481.0703134536743 and batch: 1750, loss is 3.736640567779541 and perplexity is 41.956802109056994
At time: 481.9702134132385 and batch: 1800, loss is 3.700050616264343 and perplexity is 40.44935170333085
At time: 482.87040543556213 and batch: 1850, loss is 3.7293127393722534 and perplexity is 41.65047359482164
At time: 483.7704610824585 and batch: 1900, loss is 3.8057719469070435 and perplexity is 44.9599434098551
At time: 484.6704912185669 and batch: 1950, loss is 3.7388264989852904 and perplexity is 42.04861710615435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.27738037109375 and perplexity of 72.05144451958448
finished 13 epochs...
Completing Train Step...
At time: 487.5958936214447 and batch: 50, loss is 3.8792616653442384 and perplexity is 48.38847499087356
At time: 488.51878929138184 and batch: 100, loss is 3.867704916000366 and perplexity is 47.83248044719466
At time: 489.41832852363586 and batch: 150, loss is 3.8352187871932983 and perplexity is 46.303557185121974
At time: 490.31687569618225 and batch: 200, loss is 3.8264934635162353 and perplexity is 45.901301120483865
At time: 491.2162218093872 and batch: 250, loss is 3.821656484603882 and perplexity is 45.67981359200023
At time: 492.1147928237915 and batch: 300, loss is 3.8392559576034544 and perplexity is 46.49087038932333
At time: 493.01301193237305 and batch: 350, loss is 3.839928874969482 and perplexity is 46.52216543167787
At time: 493.91097807884216 and batch: 400, loss is 3.8040451192855835 and perplexity is 44.8823723329308
At time: 494.81038451194763 and batch: 450, loss is 3.845928235054016 and perplexity is 46.80210755115682
At time: 495.7299163341522 and batch: 500, loss is 3.856774959564209 and perplexity is 47.31252026709634
At time: 496.62565064430237 and batch: 550, loss is 3.8199062395095824 and perplexity is 45.59993264835918
At time: 497.5235676765442 and batch: 600, loss is 3.7997906255722045 and perplexity is 44.69182618810484
At time: 498.4238579273224 and batch: 650, loss is 3.837937984466553 and perplexity is 46.42963703186293
At time: 499.3230981826782 and batch: 700, loss is 3.85828293800354 and perplexity is 47.38392034893121
At time: 500.2324891090393 and batch: 750, loss is 3.83085608959198 and perplexity is 46.101988777967506
At time: 501.13101267814636 and batch: 800, loss is 3.8083288717269896 and perplexity is 45.07504970141761
At time: 502.02824234962463 and batch: 850, loss is 3.8141709852218626 and perplexity is 45.33915396995345
At time: 502.9268321990967 and batch: 900, loss is 3.7710625314712525 and perplexity is 43.42618201610362
At time: 503.82673835754395 and batch: 950, loss is 3.875751461982727 and perplexity is 48.218919364765206
At time: 504.72609281539917 and batch: 1000, loss is 3.8421401500701906 and perplexity is 46.625152562201684
At time: 505.6250789165497 and batch: 1050, loss is 3.7836873626708982 and perplexity is 43.97790561426786
At time: 506.5247631072998 and batch: 1100, loss is 3.8091435194015504 and perplexity is 45.11178494694714
At time: 507.42412209510803 and batch: 1150, loss is 3.786052803993225 and perplexity is 44.08205590161117
At time: 508.3241763114929 and batch: 1200, loss is 3.845616993904114 and perplexity is 46.78754307603432
At time: 509.22401666641235 and batch: 1250, loss is 3.8309954404830933 and perplexity is 46.10841357882628
At time: 510.12368297576904 and batch: 1300, loss is 3.8332932662963866 and perplexity is 46.21448450133837
At time: 511.02352118492126 and batch: 1350, loss is 3.73036150932312 and perplexity is 41.69417827403842
At time: 511.92325472831726 and batch: 1400, loss is 3.742288575172424 and perplexity is 42.19444490996568
At time: 512.8235154151917 and batch: 1450, loss is 3.651966676712036 and perplexity is 38.55040773404522
At time: 513.722487449646 and batch: 1500, loss is 3.660079827308655 and perplexity is 38.864445191567896
At time: 514.6221828460693 and batch: 1550, loss is 3.678691935539246 and perplexity is 39.59456793684203
At time: 515.5254108905792 and batch: 1600, loss is 3.7680783557891844 and perplexity is 43.296783829254856
At time: 516.4243965148926 and batch: 1650, loss is 3.713904032707214 and perplexity is 41.01361286549842
At time: 517.3231265544891 and batch: 1700, loss is 3.7358154344558714 and perplexity is 41.922196432594035
At time: 518.2218859195709 and batch: 1750, loss is 3.7348763370513915 and perplexity is 41.88284588662384
At time: 519.1202623844147 and batch: 1800, loss is 3.698932271003723 and perplexity is 40.404140648055076
At time: 520.0183680057526 and batch: 1850, loss is 3.729032096862793 and perplexity is 41.638786341438546
At time: 520.9182517528534 and batch: 1900, loss is 3.8056762838363647 and perplexity is 44.955642609328144
At time: 521.8180334568024 and batch: 1950, loss is 3.737915678024292 and perplexity is 42.0103357806764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.277616846838662 and perplexity of 72.06848495334447
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 524.7449152469635 and batch: 50, loss is 3.8785147047042847 and perplexity is 48.3523442004471
At time: 525.6672620773315 and batch: 100, loss is 3.8823550224304197 and perplexity is 48.53838957300097
At time: 526.5650453567505 and batch: 150, loss is 3.8593806648254394 and perplexity is 47.435963508585075
At time: 527.462947845459 and batch: 200, loss is 3.8538650369644163 and perplexity is 47.17504461388102
At time: 528.3616344928741 and batch: 250, loss is 3.8527795457839966 and perplexity is 47.12386430193081
At time: 529.2603216171265 and batch: 300, loss is 3.863942070007324 and perplexity is 47.65283239575177
At time: 530.1580748558044 and batch: 350, loss is 3.8642807149887086 and perplexity is 47.66897252102331
At time: 531.0561316013336 and batch: 400, loss is 3.831257824897766 and perplexity is 46.12051329525374
At time: 531.9552021026611 and batch: 450, loss is 3.874434666633606 and perplexity is 48.15546670226013
At time: 532.8520607948303 and batch: 500, loss is 3.8861244916915894 and perplexity is 48.72169881270343
At time: 533.7499711513519 and batch: 550, loss is 3.8498944854736328 and perplexity is 46.98810504235495
At time: 534.6483364105225 and batch: 600, loss is 3.823664593696594 and perplexity is 45.771635804681715
At time: 535.5472493171692 and batch: 650, loss is 3.853541808128357 and perplexity is 47.15979874320469
At time: 536.4461989402771 and batch: 700, loss is 3.868642807006836 and perplexity is 47.87736314467234
At time: 537.3453121185303 and batch: 750, loss is 3.838718810081482 and perplexity is 46.465904639245025
At time: 538.2432782649994 and batch: 800, loss is 3.817710556983948 and perplexity is 45.49991951180165
At time: 539.1407079696655 and batch: 850, loss is 3.8202424907684325 and perplexity is 45.61526826128075
At time: 540.038978099823 and batch: 900, loss is 3.775358557701111 and perplexity is 43.613143340941185
At time: 540.9594039916992 and batch: 950, loss is 3.878421196937561 and perplexity is 48.34782309210772
At time: 541.8561704158783 and batch: 1000, loss is 3.8476572132110594 and perplexity is 46.88309736745234
At time: 542.7532570362091 and batch: 1050, loss is 3.7905573320388792 and perplexity is 44.28107266049918
At time: 543.6495845317841 and batch: 1100, loss is 3.813919472694397 and perplexity is 45.32775203866969
At time: 544.5466868877411 and batch: 1150, loss is 3.793923707008362 and perplexity is 44.43039054410646
At time: 545.4527859687805 and batch: 1200, loss is 3.8481752824783326 and perplexity is 46.90739235205205
At time: 546.350828409195 and batch: 1250, loss is 3.8327231121063234 and perplexity is 46.18814262953621
At time: 547.2485463619232 and batch: 1300, loss is 3.8311076068878176 and perplexity is 46.113585683867754
At time: 548.1460838317871 and batch: 1350, loss is 3.729481806755066 and perplexity is 41.65751592668276
At time: 549.0438697338104 and batch: 1400, loss is 3.7402533721923827 and perplexity is 42.10865797646623
At time: 549.9417176246643 and batch: 1450, loss is 3.6483595609664916 and perplexity is 38.41160244518499
At time: 550.8390529155731 and batch: 1500, loss is 3.656088643074036 and perplexity is 38.70963916581595
At time: 551.7353055477142 and batch: 1550, loss is 3.6737903118133546 and perplexity is 39.40096513489367
At time: 552.6291246414185 and batch: 1600, loss is 3.7579829692840576 and perplexity is 42.86188499161748
At time: 553.5241174697876 and batch: 1650, loss is 3.7017704010009767 and perplexity is 40.518975733008375
At time: 554.4184291362762 and batch: 1700, loss is 3.7174422216415404 and perplexity is 41.15898379995616
At time: 555.3115782737732 and batch: 1750, loss is 3.715570206642151 and perplexity is 41.08200563953893
At time: 556.2035999298096 and batch: 1800, loss is 3.681000475883484 and perplexity is 39.68607918239672
At time: 557.0981431007385 and batch: 1850, loss is 3.7122014951705933 and perplexity is 40.94384505809057
At time: 557.9925191402435 and batch: 1900, loss is 3.7910547733306883 and perplexity is 44.303105374022515
At time: 558.8878359794617 and batch: 1950, loss is 3.7311494302749635 and perplexity is 41.72704293634819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.266618311682413 and perplexity of 71.28018023312339
finished 15 epochs...
Completing Train Step...
At time: 561.8162739276886 and batch: 50, loss is 3.88296941280365 and perplexity is 48.56822025519034
At time: 562.7374663352966 and batch: 100, loss is 3.876591215133667 and perplexity is 48.259428360634615
At time: 563.6326849460602 and batch: 150, loss is 3.847024636268616 and perplexity is 46.85344957930958
At time: 564.5278375148773 and batch: 200, loss is 3.837946262359619 and perplexity is 46.43002137302415
At time: 565.423858165741 and batch: 250, loss is 3.8340567207336425 and perplexity is 46.24978062637365
At time: 566.3197598457336 and batch: 300, loss is 3.8442173624038696 and perplexity is 46.72210356321065
At time: 567.2158753871918 and batch: 350, loss is 3.8461109352111817 and perplexity is 46.810659084721586
At time: 568.1124122142792 and batch: 400, loss is 3.8120621156692507 and perplexity is 45.24364035687866
At time: 569.0094573497772 and batch: 450, loss is 3.8560692977905275 and perplexity is 47.279145407193674
At time: 569.906004190445 and batch: 500, loss is 3.869076862335205 and perplexity is 47.89814908005021
At time: 570.8018753528595 and batch: 550, loss is 3.8344708776473997 and perplexity is 46.26893925984623
At time: 571.6981649398804 and batch: 600, loss is 3.809816451072693 and perplexity is 45.14215231221469
At time: 572.5966041088104 and batch: 650, loss is 3.8408279705047605 and perplexity is 46.564012112171795
At time: 573.5171775817871 and batch: 700, loss is 3.8580952215194704 and perplexity is 47.375026440794564
At time: 574.4141805171967 and batch: 750, loss is 3.829471745491028 and perplexity is 46.038211916506754
At time: 575.310008764267 and batch: 800, loss is 3.808588156700134 and perplexity is 45.08673849976832
At time: 576.2059199810028 and batch: 850, loss is 3.811615538597107 and perplexity is 45.22344009525752
At time: 577.1025266647339 and batch: 900, loss is 3.7670438718795776 and perplexity is 43.252017162236406
At time: 577.9994401931763 and batch: 950, loss is 3.8710467481613158 and perplexity is 47.99259595926291
At time: 578.8961133956909 and batch: 1000, loss is 3.8400777053833006 and perplexity is 46.52908986008079
At time: 579.7932507991791 and batch: 1050, loss is 3.7837439012527465 and perplexity is 43.98039213297541
At time: 580.6900894641876 and batch: 1100, loss is 3.8073360109329224 and perplexity is 45.030318661301
At time: 581.586672782898 and batch: 1150, loss is 3.7882314777374266 and perplexity is 44.17820101578202
At time: 582.4829490184784 and batch: 1200, loss is 3.843484845161438 and perplexity is 46.6878913487962
At time: 583.3793106079102 and batch: 1250, loss is 3.828588104248047 and perplexity is 45.99754862223208
At time: 584.2749929428101 and batch: 1300, loss is 3.8273683834075927 and perplexity is 45.94147865537265
At time: 585.1713371276855 and batch: 1350, loss is 3.7255392265319824 and perplexity is 41.493601164121365
At time: 586.0684485435486 and batch: 1400, loss is 3.737331871986389 and perplexity is 41.98581705078099
At time: 586.9655203819275 and batch: 1450, loss is 3.6463287019729616 and perplexity is 38.3336730554885
At time: 587.8623416423798 and batch: 1500, loss is 3.655505409240723 and perplexity is 38.68706897706775
At time: 588.7587518692017 and batch: 1550, loss is 3.6737596082687376 and perplexity is 39.3997554041743
At time: 589.6548919677734 and batch: 1600, loss is 3.759047784805298 and perplexity is 42.907549299743565
At time: 590.5514965057373 and batch: 1650, loss is 3.703096604347229 and perplexity is 40.57274778266705
At time: 591.4482650756836 and batch: 1700, loss is 3.7195966386795045 and perplexity is 41.247753004528185
At time: 592.3810539245605 and batch: 1750, loss is 3.718604736328125 and perplexity is 41.20685954584561
At time: 593.3036723136902 and batch: 1800, loss is 3.684853882789612 and perplexity is 39.83930081705219
At time: 594.20068359375 and batch: 1850, loss is 3.71653058052063 and perplexity is 41.12147867603335
At time: 595.0973868370056 and batch: 1900, loss is 3.7959499549865723 and perplexity is 44.520508803254685
At time: 596.012454032898 and batch: 1950, loss is 3.735406174659729 and perplexity is 41.90504287339869
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265578159066134 and perplexity of 71.20607651343524
finished 16 epochs...
Completing Train Step...
At time: 599.0307447910309 and batch: 50, loss is 3.879766721725464 and perplexity is 48.41292007149783
At time: 599.9560887813568 and batch: 100, loss is 3.8718981647491457 and perplexity is 48.03347505165485
At time: 600.8580415248871 and batch: 150, loss is 3.8416039323806763 and perplexity is 46.60015803247491
At time: 601.7584462165833 and batch: 200, loss is 3.832004714012146 and perplexity is 46.154973071797635
At time: 602.6586761474609 and batch: 250, loss is 3.8276573181152345 and perplexity is 45.9547546609336
At time: 603.5572321414948 and batch: 300, loss is 3.837462058067322 and perplexity is 46.4075451993529
At time: 604.4566648006439 and batch: 350, loss is 3.8396060943603514 and perplexity is 46.50715140203092
At time: 605.3572759628296 and batch: 400, loss is 3.805026259422302 and perplexity is 44.926429839617576
At time: 606.258229970932 and batch: 450, loss is 3.849206414222717 and perplexity is 46.95578499866189
At time: 607.1576616764069 and batch: 500, loss is 3.8622665882110594 and perplexity is 47.57305779164293
At time: 608.0810947418213 and batch: 550, loss is 3.8278649616241456 and perplexity is 45.96429785819974
At time: 608.9878072738647 and batch: 600, loss is 3.80380250453949 and perplexity is 44.87148452838754
At time: 609.8971469402313 and batch: 650, loss is 3.8351212835311888 and perplexity is 46.2990426388237
At time: 610.7930011749268 and batch: 700, loss is 3.852821021080017 and perplexity is 47.12581881868415
At time: 611.6912169456482 and batch: 750, loss is 3.8248021602630615 and perplexity is 45.82373371406746
At time: 612.588128566742 and batch: 800, loss is 3.804023756980896 and perplexity is 44.88141355225885
At time: 613.4855372905731 and batch: 850, loss is 3.8071792411804197 and perplexity is 45.023259822709996
At time: 614.383683681488 and batch: 900, loss is 3.7629119300842286 and perplexity is 43.073671056395995
At time: 615.2817342281342 and batch: 950, loss is 3.8672979164123533 and perplexity is 47.813016608514864
At time: 616.1797943115234 and batch: 1000, loss is 3.8362696981430053 and perplexity is 46.352243678481855
At time: 617.0787734985352 and batch: 1050, loss is 3.7803454780578614 and perplexity is 43.831181831710865
At time: 617.9775776863098 and batch: 1100, loss is 3.8041524028778078 and perplexity is 44.887187733364335
At time: 618.8754653930664 and batch: 1150, loss is 3.7853864288330077 and perplexity is 44.05269049982084
At time: 619.7803092002869 and batch: 1200, loss is 3.840917911529541 and perplexity is 46.568200315481874
At time: 620.679196357727 and batch: 1250, loss is 3.8263433027267455 and perplexity is 45.894409062340394
At time: 621.5774033069611 and batch: 1300, loss is 3.8252216482162478 and perplexity is 45.84296025069883
At time: 622.4776048660278 and batch: 1350, loss is 3.723342537879944 and perplexity is 41.402552680509714
At time: 623.3768224716187 and batch: 1400, loss is 3.7355728054046633 and perplexity is 41.91202612370513
At time: 624.2748634815216 and batch: 1450, loss is 3.6449909734725954 and perplexity is 38.28242729261931
At time: 625.1740024089813 and batch: 1500, loss is 3.654795846939087 and perplexity is 38.65962782811457
At time: 626.0728240013123 and batch: 1550, loss is 3.6732288122177126 and perplexity is 39.378847718943675
At time: 626.9710764884949 and batch: 1600, loss is 3.759101881980896 and perplexity is 42.909870539758224
At time: 627.8694167137146 and batch: 1650, loss is 3.7032272100448607 and perplexity is 40.57804716075299
At time: 628.7683837413788 and batch: 1700, loss is 3.7201191329956056 and perplexity is 41.26931035233041
At time: 629.6680500507355 and batch: 1750, loss is 3.719449367523193 and perplexity is 41.241678847533
At time: 630.5671210289001 and batch: 1800, loss is 3.6860270595550535 and perplexity is 39.886066786132524
At time: 631.466145992279 and batch: 1850, loss is 3.7178681898117065 and perplexity is 41.176519951627384
At time: 632.3652868270874 and batch: 1900, loss is 3.79743643283844 and perplexity is 44.586736764548554
At time: 633.2655909061432 and batch: 1950, loss is 3.7364555740356447 and perplexity is 41.94904108104586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265253679142442 and perplexity of 71.1829753193013
finished 17 epochs...
Completing Train Step...
At time: 636.2220189571381 and batch: 50, loss is 3.8762272691726682 and perplexity is 48.24186773235637
At time: 637.1220054626465 and batch: 100, loss is 3.867709083557129 and perplexity is 47.83267979218742
At time: 638.0207629203796 and batch: 150, loss is 3.8371665048599244 and perplexity is 46.39383132721106
At time: 638.9196331501007 and batch: 200, loss is 3.8273636627197267 and perplexity is 45.941261780503716
At time: 639.8189663887024 and batch: 250, loss is 3.8228601884841917 and perplexity is 45.73483166696492
At time: 640.7182803153992 and batch: 300, loss is 3.832537202835083 and perplexity is 46.17955662373377
At time: 641.6171641349792 and batch: 350, loss is 3.834813666343689 and perplexity is 46.28480244791925
At time: 642.5177233219147 and batch: 400, loss is 3.7999996614456175 and perplexity is 44.70116935952147
At time: 643.4179525375366 and batch: 450, loss is 3.84436674118042 and perplexity is 46.7290833751837
At time: 644.3164117336273 and batch: 500, loss is 3.857405118942261 and perplexity is 47.34234409133626
At time: 645.2156896591187 and batch: 550, loss is 3.8230892705917356 and perplexity is 45.74530989873324
At time: 646.115336894989 and batch: 600, loss is 3.7994839334487915 and perplexity is 44.678121658675046
At time: 647.0150814056396 and batch: 650, loss is 3.8309729433059694 and perplexity is 46.10737628134727
At time: 647.9143576622009 and batch: 700, loss is 3.84887535572052 and perplexity is 46.94024245969754
At time: 648.8130609989166 and batch: 750, loss is 3.8212521743774412 and perplexity is 45.6613485092855
At time: 649.7132794857025 and batch: 800, loss is 3.8005471992492676 and perplexity is 44.72565164148898
At time: 650.6134853363037 and batch: 850, loss is 3.8037862586975097 and perplexity is 44.87075555926185
At time: 651.5133645534515 and batch: 900, loss is 3.7597369146347046 and perplexity is 42.93712836260944
At time: 652.4377872943878 and batch: 950, loss is 3.864367742538452 and perplexity is 47.67312121542334
At time: 653.3373668193817 and batch: 1000, loss is 3.8333253717422484 and perplexity is 46.215968261786834
At time: 654.2377610206604 and batch: 1050, loss is 3.7776863956451416 and perplexity is 43.71478592870629
At time: 655.1373479366302 and batch: 1100, loss is 3.8016173601150514 and perplexity is 44.773540903609074
At time: 656.0376515388489 and batch: 1150, loss is 3.783063473701477 and perplexity is 43.950476841201045
At time: 656.9361696243286 and batch: 1200, loss is 3.8387513542175293 and perplexity is 46.46741685657394
At time: 657.8342833518982 and batch: 1250, loss is 3.824418134689331 and perplexity is 45.8061396069472
At time: 658.7340261936188 and batch: 1300, loss is 3.8233237075805664 and perplexity is 45.756035548634436
At time: 659.6337563991547 and batch: 1350, loss is 3.721403636932373 and perplexity is 41.322355004684624
At time: 660.5323505401611 and batch: 1400, loss is 3.7339245653152466 and perplexity is 41.843001941857665
At time: 661.4322330951691 and batch: 1450, loss is 3.643611102104187 and perplexity is 38.22963889625936
At time: 662.3323681354523 and batch: 1500, loss is 3.6538001251220704 and perplexity is 38.621152751663786
At time: 663.2320241928101 and batch: 1550, loss is 3.672324733734131 and perplexity is 39.34326223847019
At time: 664.1286444664001 and batch: 1600, loss is 3.758611912727356 and perplexity is 42.88885117236274
At time: 665.0300016403198 and batch: 1650, loss is 3.7027930927276613 and perplexity is 40.560435350854796
At time: 665.9296638965607 and batch: 1700, loss is 3.7199639081954956 and perplexity is 41.26290482904119
At time: 666.8292810916901 and batch: 1750, loss is 3.719471015930176 and perplexity is 41.24257167384544
At time: 667.7292232513428 and batch: 1800, loss is 3.6862567901611327 and perplexity is 39.89523088902657
At time: 668.6270520687103 and batch: 1850, loss is 3.71821581363678 and perplexity is 41.19083637921768
At time: 669.5255508422852 and batch: 1900, loss is 3.79785343170166 and perplexity is 44.605333260183365
At time: 670.4244208335876 and batch: 1950, loss is 3.736556091308594 and perplexity is 41.95325789618599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265167094385901 and perplexity of 71.17681222553222
finished 18 epochs...
Completing Train Step...
At time: 673.3843686580658 and batch: 50, loss is 3.872850179672241 and perplexity is 48.07922541076905
At time: 674.2834734916687 and batch: 100, loss is 3.863939700126648 and perplexity is 47.65271946435893
At time: 675.2063539028168 and batch: 150, loss is 3.833285984992981 and perplexity is 46.21414800088007
At time: 676.104484796524 and batch: 200, loss is 3.8233907794952393 and perplexity is 45.75910459646884
At time: 677.0033504962921 and batch: 250, loss is 3.8188005304336547 and perplexity is 45.54954025376634
At time: 677.9024584293365 and batch: 300, loss is 3.828400731086731 and perplexity is 45.98893072354062
At time: 678.802463054657 and batch: 350, loss is 3.8307654523849486 and perplexity is 46.097810411826664
At time: 679.7041244506836 and batch: 400, loss is 3.7958183670043946 and perplexity is 44.514650824763976
At time: 680.6028914451599 and batch: 450, loss is 3.840361485481262 and perplexity is 46.542295763456984
At time: 681.5024178028107 and batch: 500, loss is 3.853374457359314 and perplexity is 47.15190717496552
At time: 682.4010033607483 and batch: 550, loss is 3.8191153240203857 and perplexity is 45.563881214019496
At time: 683.2993595600128 and batch: 600, loss is 3.795894351005554 and perplexity is 44.51803335455131
At time: 684.1982672214508 and batch: 650, loss is 3.827509489059448 and perplexity is 45.94796171505294
At time: 685.0980312824249 and batch: 700, loss is 3.8455430555343626 and perplexity is 46.78408380926246
At time: 685.9971175193787 and batch: 750, loss is 3.8182135820388794 and perplexity is 45.522812868796805
At time: 686.8956615924835 and batch: 800, loss is 3.797565121650696 and perplexity is 44.592474947957236
At time: 687.7947614192963 and batch: 850, loss is 3.8008705520629884 and perplexity is 44.74011614523572
At time: 688.6941702365875 and batch: 900, loss is 3.756979088783264 and perplexity is 42.818878371412616
At time: 689.5933513641357 and batch: 950, loss is 3.8617967176437378 and perplexity is 47.550709862717326
At time: 690.4931311607361 and batch: 1000, loss is 3.8307479333877565 and perplexity is 46.09700283148952
At time: 691.3926820755005 and batch: 1050, loss is 3.7753351640701296 and perplexity is 43.61212308309375
At time: 692.290768623352 and batch: 1100, loss is 3.7993418169021607 and perplexity is 44.67177260947812
At time: 693.1912643909454 and batch: 1150, loss is 3.7809463262557985 and perplexity is 43.85752563184777
At time: 694.0897014141083 and batch: 1200, loss is 3.8367434883117677 and perplexity is 46.3742101191677
At time: 694.9886400699615 and batch: 1250, loss is 3.822600927352905 and perplexity is 45.722975939698784
At time: 695.8878848552704 and batch: 1300, loss is 3.8215049171447752 and perplexity is 45.67289054338932
At time: 696.7861883640289 and batch: 1350, loss is 3.719541001319885 and perplexity is 41.245458152301126
At time: 697.6856732368469 and batch: 1400, loss is 3.7322866487503052 and perplexity is 41.77452269280791
At time: 698.5835869312286 and batch: 1450, loss is 3.6421745157241823 and perplexity is 38.174758147614995
At time: 699.4817259311676 and batch: 1500, loss is 3.652642874717712 and perplexity is 38.57648425832624
At time: 700.3799498081207 and batch: 1550, loss is 3.6712211751937867 and perplexity is 39.299868593539536
At time: 701.2774362564087 and batch: 1600, loss is 3.757836380004883 and perplexity is 42.85560235928701
At time: 702.1753077507019 and batch: 1650, loss is 3.702069392204285 and perplexity is 40.531092361612025
At time: 703.0744006633759 and batch: 1700, loss is 3.719465608596802 and perplexity is 41.24234866211415
At time: 703.9721646308899 and batch: 1750, loss is 3.7190965270996093 and perplexity is 41.227129683016756
At time: 704.871143579483 and batch: 1800, loss is 3.686042056083679 and perplexity is 39.88666494315997
At time: 705.7697882652283 and batch: 1850, loss is 3.71810622215271 and perplexity is 41.18632246167678
At time: 706.6676614284515 and batch: 1900, loss is 3.7977880096435546 and perplexity is 44.60241518293335
At time: 707.5658776760101 and batch: 1950, loss is 3.7362397003173826 and perplexity is 41.939986362943166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265183559683866 and perplexity of 71.177984182602
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 710.509135723114 and batch: 50, loss is 3.873520545959473 and perplexity is 48.11146690819968
At time: 711.4324584007263 and batch: 100, loss is 3.8711695718765258 and perplexity is 47.99849095021613
At time: 712.3322198390961 and batch: 150, loss is 3.8441209745407106 and perplexity is 46.717600336517584
At time: 713.2314665317535 and batch: 200, loss is 3.8356633615493774 and perplexity is 46.32414713578462
At time: 714.1322391033173 and batch: 250, loss is 3.8337841844558715 and perplexity is 46.23717760078287
At time: 715.0322678089142 and batch: 300, loss is 3.8390227699279786 and perplexity is 46.48003055523337
At time: 715.9323337078094 and batch: 350, loss is 3.8421715307235718 and perplexity is 46.62661571291028
At time: 716.8314161300659 and batch: 400, loss is 3.8070920419692995 and perplexity is 45.019334001138155
At time: 717.729101896286 and batch: 450, loss is 3.85275465965271 and perplexity is 47.122691585849296
At time: 718.6278665065765 and batch: 500, loss is 3.8644303703308105 and perplexity is 47.67610697125457
At time: 719.5289697647095 and batch: 550, loss is 3.8308247709274292 and perplexity is 46.10054494785538
At time: 720.4532990455627 and batch: 600, loss is 3.807869806289673 and perplexity is 45.054362052869884
At time: 721.3535759449005 and batch: 650, loss is 3.840173773765564 and perplexity is 46.53356004919032
At time: 722.2537059783936 and batch: 700, loss is 3.857321138381958 and perplexity is 47.33836842169524
At time: 723.1535799503326 and batch: 750, loss is 3.8252914905548097 and perplexity is 45.84616214206183
At time: 724.0542502403259 and batch: 800, loss is 3.805086860656738 and perplexity is 44.9291525192227
At time: 724.9553396701813 and batch: 850, loss is 3.807866291999817 and perplexity is 45.05420371906057
At time: 725.8565394878387 and batch: 900, loss is 3.7615209579467774 and perplexity is 43.013798430329615
At time: 726.7573597431183 and batch: 950, loss is 3.864759922027588 and perplexity is 47.691821302402715
At time: 727.657306432724 and batch: 1000, loss is 3.83069748878479 and perplexity is 46.09467754513331
At time: 728.5568153858185 and batch: 1050, loss is 3.7763425159454345 and perplexity is 43.65607797237063
At time: 729.4572308063507 and batch: 1100, loss is 3.8012360286712648 and perplexity is 44.756470599541565
At time: 730.357097864151 and batch: 1150, loss is 3.784584412574768 and perplexity is 44.01737369004166
At time: 731.2590301036835 and batch: 1200, loss is 3.8389707708358767 and perplexity is 46.477613698681346
At time: 732.1593263149261 and batch: 1250, loss is 3.826973571777344 and perplexity is 45.9233440054096
At time: 733.059633731842 and batch: 1300, loss is 3.8242204189300537 and perplexity is 45.797083906532094
At time: 733.9591908454895 and batch: 1350, loss is 3.7186499881744384 and perplexity is 41.20872427451172
At time: 734.8597540855408 and batch: 1400, loss is 3.7313489055633546 and perplexity is 41.7353672804945
At time: 735.7596526145935 and batch: 1450, loss is 3.6416024208068847 and perplexity is 38.15292480847635
At time: 736.6591999530792 and batch: 1500, loss is 3.6534349489212037 and perplexity is 38.6070518006514
At time: 737.559832572937 and batch: 1550, loss is 3.6731911420822145 and perplexity is 39.377364340354056
At time: 738.4601402282715 and batch: 1600, loss is 3.757001872062683 and perplexity is 42.81985393699621
At time: 739.3601644039154 and batch: 1650, loss is 3.6990697288513186 and perplexity is 40.40969489599124
At time: 740.2630515098572 and batch: 1700, loss is 3.7123825120925904 and perplexity is 40.95125725774425
At time: 741.1627776622772 and batch: 1750, loss is 3.712010622024536 and perplexity is 40.936030723369704
At time: 742.063197851181 and batch: 1800, loss is 3.6758001232147217 and perplexity is 39.480233274169095
At time: 742.963995218277 and batch: 1850, loss is 3.7075804901123046 and perplexity is 40.75507982143076
At time: 743.8649671077728 and batch: 1900, loss is 3.788636021614075 and perplexity is 44.196076651980086
At time: 744.7635669708252 and batch: 1950, loss is 3.7313313770294187 and perplexity is 41.73463572710435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261450479196948 and perplexity of 70.91276638644534
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
3856.394321680069


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.68864018758501}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.09000677972055571, 'batch_size': 32, 'rnn_dropout': 0.41910426663286526, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.83039238142784}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6648606163334299, 'batch_size': 32, 'rnn_dropout': 0.9502082500073664, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.91276638644534}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.3455001633105624, 'batch_size': 32, 'rnn_dropout': 0.5106234852565553, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5054216384887695 and batch: 50, loss is 7.60507345199585 and perplexity is 2008.3594062986595
At time: 2.4675509929656982 and batch: 100, loss is 6.767442388534546 and perplexity is 869.0862640622503
At time: 3.42899227142334 and batch: 150, loss is 6.462728834152221 and perplexity is 640.8073297674048
At time: 4.389566421508789 and batch: 200, loss is 6.251581478118896 and perplexity is 518.8326987514436
At time: 5.350136995315552 and batch: 250, loss is 6.123099327087402 and perplexity is 456.2766559031479
At time: 6.310705661773682 and batch: 300, loss is 6.022708997726441 and perplexity is 412.69507279086736
At time: 7.274519920349121 and batch: 350, loss is 5.93400393486023 and perplexity is 377.66363118315803
At time: 8.235908269882202 and batch: 400, loss is 5.8643475532531735 and perplexity is 352.2522552788214
At time: 9.294590711593628 and batch: 450, loss is 5.762582368850708 and perplexity is 318.1688984078116
At time: 10.2578604221344 and batch: 500, loss is 5.725331649780274 and perplexity is 306.5349106228529
At time: 11.21596646308899 and batch: 550, loss is 5.660049972534179 and perplexity is 287.1629924599565
At time: 12.179033279418945 and batch: 600, loss is 5.667652606964111 and perplexity is 289.35450780263596
At time: 13.15116548538208 and batch: 650, loss is 5.721004295349121 and perplexity is 305.2112913693937
At time: 14.122685670852661 and batch: 700, loss is 5.651869497299194 and perplexity is 284.82344506339854
At time: 15.08416199684143 and batch: 750, loss is 5.5846367359161375 and perplexity is 266.3035266598835
At time: 16.060702562332153 and batch: 800, loss is 5.5753559970855715 and perplexity is 263.8434664250581
At time: 17.02278232574463 and batch: 850, loss is 5.583911008834839 and perplexity is 266.1103330901232
At time: 17.98205542564392 and batch: 900, loss is 5.576425352096558 and perplexity is 264.12575966694146
At time: 18.95089840888977 and batch: 950, loss is 5.602410697937012 and perplexity is 271.07911022719986
At time: 19.92431378364563 and batch: 1000, loss is 5.565483961105347 and perplexity is 261.25160873708086
At time: 20.902180194854736 and batch: 1050, loss is 5.454546251296997 and perplexity is 233.81875204012894
At time: 21.87048029899597 and batch: 1100, loss is 5.540374803543091 and perplexity is 254.7734715656233
At time: 22.84489369392395 and batch: 1150, loss is 5.436696119308472 and perplexity is 229.68208630675946
At time: 23.809574127197266 and batch: 1200, loss is 5.516071166992187 and perplexity is 248.65618694435844
At time: 24.773105144500732 and batch: 1250, loss is 5.460954341888428 and perplexity is 235.32189477889435
At time: 25.74818181991577 and batch: 1300, loss is 5.471516847610474 and perplexity is 237.82065700268706
At time: 26.71862030029297 and batch: 1350, loss is 5.4214700412750245 and perplexity is 226.21141831971983
At time: 27.68668818473816 and batch: 1400, loss is 5.42806037902832 and perplexity is 227.7071512490745
At time: 28.66115117073059 and batch: 1450, loss is 5.393053255081177 and perplexity is 219.87369219254646
At time: 29.634958267211914 and batch: 1500, loss is 5.356740217208863 and perplexity is 212.03263832996146
At time: 30.59915041923523 and batch: 1550, loss is 5.335111045837403 and perplexity is 207.4957890723079
At time: 31.564807415008545 and batch: 1600, loss is 5.364495286941528 and perplexity is 213.68335867851334
At time: 32.53632068634033 and batch: 1650, loss is 5.347281351089477 and perplexity is 210.0365054507254
At time: 33.504637241363525 and batch: 1700, loss is 5.365079803466797 and perplexity is 213.80829664343122
At time: 34.46519708633423 and batch: 1750, loss is 5.375434141159058 and perplexity is 216.0336410500277
At time: 35.425689935684204 and batch: 1800, loss is 5.3466152000427245 and perplexity is 209.89663600502428
At time: 36.389129400253296 and batch: 1850, loss is 5.328601303100586 and perplexity is 206.1494318405966
At time: 37.35019779205322 and batch: 1900, loss is 5.360631103515625 and perplexity is 212.85924028331019
At time: 38.32078957557678 and batch: 1950, loss is 5.286837072372436 and perplexity is 197.717070589068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.859298351199128 and perplexity of 128.93370418327888
finished 1 epochs...
Completing Train Step...
At time: 41.48142623901367 and batch: 50, loss is 5.08452130317688 and perplexity is 161.50260994412716
At time: 42.4066424369812 and batch: 100, loss is 5.0220049858093265 and perplexity is 151.71518584733406
At time: 43.30442404747009 and batch: 150, loss is 4.952031354904175 and perplexity is 141.46203184649102
At time: 44.20171284675598 and batch: 200, loss is 4.919164257049561 and perplexity is 136.88816205083322
At time: 45.10878896713257 and batch: 250, loss is 4.924138851165772 and perplexity is 137.57082166581156
At time: 46.02901768684387 and batch: 300, loss is 4.929753522872925 and perplexity is 138.34540915831286
At time: 46.933056354522705 and batch: 350, loss is 4.921312999725342 and perplexity is 137.18261572573638
At time: 47.83136320114136 and batch: 400, loss is 4.880617418289185 and perplexity is 131.7119601594514
At time: 48.729984283447266 and batch: 450, loss is 4.846176099777222 and perplexity is 127.2528560751548
At time: 49.652729511260986 and batch: 500, loss is 4.831895542144776 and perplexity is 125.44852839637406
At time: 50.55700945854187 and batch: 550, loss is 4.789130935668945 and perplexity is 120.19686445175192
At time: 51.456974029541016 and batch: 600, loss is 4.77143012046814 and perplexity is 118.08800132653498
At time: 52.359607219696045 and batch: 650, loss is 4.850407190322876 and perplexity is 127.7924150879833
At time: 53.26352596282959 and batch: 700, loss is 4.842867860794067 and perplexity is 126.83256880465291
At time: 54.16604995727539 and batch: 750, loss is 4.804216423034668 and perplexity is 122.02383848145737
At time: 55.06816077232361 and batch: 800, loss is 4.7821785259246825 and perplexity is 119.364104797628
At time: 55.9848427772522 and batch: 850, loss is 4.771206312179565 and perplexity is 118.0615752103591
At time: 56.9307165145874 and batch: 900, loss is 4.768093519210815 and perplexity is 117.69464535378344
At time: 57.84743094444275 and batch: 950, loss is 4.829588251113892 and perplexity is 125.15941579368484
At time: 58.75226902961731 and batch: 1000, loss is 4.8055774974823 and perplexity is 122.19003508733633
At time: 59.65352129936218 and batch: 1050, loss is 4.7114500808715825 and perplexity is 111.21331133158819
At time: 60.557034730911255 and batch: 1100, loss is 4.780981378555298 and perplexity is 119.22129387348758
At time: 61.477866649627686 and batch: 1150, loss is 4.71239312171936 and perplexity is 111.31823949498633
At time: 62.38178873062134 and batch: 1200, loss is 4.7922297286987305 and perplexity is 120.56990735037155
At time: 63.28464126586914 and batch: 1250, loss is 4.749879264831543 and perplexity is 115.57033028152537
At time: 64.18760895729065 and batch: 1300, loss is 4.769436273574829 and perplexity is 117.85278650105057
At time: 65.0909035205841 and batch: 1350, loss is 4.670152406692505 and perplexity is 106.7140051217126
At time: 65.99524331092834 and batch: 1400, loss is 4.680796957015991 and perplexity is 107.85599492051186
At time: 66.89890789985657 and batch: 1450, loss is 4.626712064743042 and perplexity is 102.17755801305194
At time: 67.80113863945007 and batch: 1500, loss is 4.613618469238281 and perplexity is 100.84840707049868
At time: 68.70370388031006 and batch: 1550, loss is 4.6095438575744625 and perplexity is 100.43832500472
At time: 69.60613870620728 and batch: 1600, loss is 4.677433385848999 and perplexity is 107.49382304270873
At time: 70.5131447315216 and batch: 1650, loss is 4.640511360168457 and perplexity is 103.5973095784773
At time: 71.42096829414368 and batch: 1700, loss is 4.661643047332763 and perplexity is 105.80978990563887
At time: 72.31877398490906 and batch: 1750, loss is 4.658483104705811 and perplexity is 105.47596475211033
At time: 73.2238118648529 and batch: 1800, loss is 4.6137371921539305 and perplexity is 100.86038079818859
At time: 74.13564205169678 and batch: 1850, loss is 4.627680854797363 and perplexity is 102.27659458010443
At time: 75.03744745254517 and batch: 1900, loss is 4.715408277511597 and perplexity is 111.65438784473814
At time: 75.94626784324646 and batch: 1950, loss is 4.6381027793884275 and perplexity is 103.34808734618674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.524772324672965 and perplexity of 92.27491471550765
finished 2 epochs...
Completing Train Step...
At time: 79.00199174880981 and batch: 50, loss is 4.591438798904419 and perplexity is 98.63624583780937
At time: 79.93510365486145 and batch: 100, loss is 4.546590118408203 and perplexity is 94.31027254237458
At time: 80.84172034263611 and batch: 150, loss is 4.5091581058502195 and perplexity is 90.84530417644261
At time: 81.74500966072083 and batch: 200, loss is 4.502794389724731 and perplexity is 90.26902602938644
At time: 82.65046691894531 and batch: 250, loss is 4.500538234710693 and perplexity is 90.06559468631303
At time: 83.55416226387024 and batch: 300, loss is 4.5254194450378415 and perplexity is 92.33464701689712
At time: 84.4597954750061 and batch: 350, loss is 4.52912859916687 and perplexity is 92.67776640209313
At time: 85.37522435188293 and batch: 400, loss is 4.490639181137085 and perplexity is 89.17842883504939
At time: 86.29199576377869 and batch: 450, loss is 4.489341497421265 and perplexity is 89.06277849515857
At time: 87.23250842094421 and batch: 500, loss is 4.490259237289429 and perplexity is 89.14455247563461
At time: 88.14115071296692 and batch: 550, loss is 4.452555255889893 and perplexity is 85.84602253685067
At time: 89.0476143360138 and batch: 600, loss is 4.436939487457275 and perplexity is 84.51588352908789
At time: 89.95131182670593 and batch: 650, loss is 4.506045389175415 and perplexity is 90.5629681273318
At time: 90.85326719284058 and batch: 700, loss is 4.522188568115235 and perplexity is 92.0368065387425
At time: 91.77876091003418 and batch: 750, loss is 4.490706920623779 and perplexity is 89.1844699406513
At time: 92.68290734291077 and batch: 800, loss is 4.463344821929931 and perplexity is 86.77727875722027
At time: 93.58543586730957 and batch: 850, loss is 4.456734390258789 and perplexity is 86.20553530290015
At time: 94.49148464202881 and batch: 900, loss is 4.441436014175415 and perplexity is 84.89676714240643
At time: 95.39337873458862 and batch: 950, loss is 4.523861274719239 and perplexity is 92.19088594174325
At time: 96.29514741897583 and batch: 1000, loss is 4.501407823562622 and perplexity is 90.14394878638304
At time: 97.20287251472473 and batch: 1050, loss is 4.423841676712036 and perplexity is 83.41612839607006
At time: 98.10656762123108 and batch: 1100, loss is 4.481534729003906 and perplexity is 88.37019295380742
At time: 99.01071357727051 and batch: 1150, loss is 4.43809103012085 and perplexity is 84.61326323240193
At time: 99.91759514808655 and batch: 1200, loss is 4.509183902740478 and perplexity is 90.84764773301306
At time: 100.82214093208313 and batch: 1250, loss is 4.48047532081604 and perplexity is 88.27662242127452
At time: 101.72779774665833 and batch: 1300, loss is 4.49036808013916 and perplexity is 89.15425575082057
At time: 102.63176274299622 and batch: 1350, loss is 4.385111465454101 and perplexity is 80.2471675013681
At time: 103.53770136833191 and batch: 1400, loss is 4.398995704650879 and perplexity is 81.3691089986843
At time: 104.43760991096497 and batch: 1450, loss is 4.34294207572937 and perplexity is 76.93355103678267
At time: 105.34368634223938 and batch: 1500, loss is 4.342410879135132 and perplexity is 76.89269504873083
At time: 106.24785256385803 and batch: 1550, loss is 4.341528043746949 and perplexity is 76.82484141265168
At time: 107.15282487869263 and batch: 1600, loss is 4.419076080322266 and perplexity is 83.01954652087443
At time: 108.05638813972473 and batch: 1650, loss is 4.38379282951355 and perplexity is 80.141420438435
At time: 108.96134233474731 and batch: 1700, loss is 4.3986584663391115 and perplexity is 81.34167284425676
At time: 109.86596059799194 and batch: 1750, loss is 4.399113912582397 and perplexity is 81.37872804126084
At time: 110.77880096435547 and batch: 1800, loss is 4.3562674140930175 and perplexity is 77.96557741530738
At time: 111.69113230705261 and batch: 1850, loss is 4.387347888946533 and perplexity is 80.42683498337283
At time: 112.58741354942322 and batch: 1900, loss is 4.478130617141724 and perplexity is 88.06988236712455
At time: 113.4862596988678 and batch: 1950, loss is 4.403882884979248 and perplexity is 81.76774782399069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425763081395349 and perplexity of 83.57655861216209
finished 3 epochs...
Completing Train Step...
At time: 116.49548578262329 and batch: 50, loss is 4.3661569976806645 and perplexity is 78.74044977716245
At time: 117.43141293525696 and batch: 100, loss is 4.331184968948365 and perplexity is 76.03433153028254
At time: 118.32711029052734 and batch: 150, loss is 4.298187017440796 and perplexity is 73.56629830797542
At time: 119.22336292266846 and batch: 200, loss is 4.299313335418701 and perplexity is 73.64920403266728
At time: 120.11944556236267 and batch: 250, loss is 4.293157052993775 and perplexity is 73.19719151821866
At time: 121.01651239395142 and batch: 300, loss is 4.311952428817749 and perplexity is 74.58597067130748
At time: 121.9135890007019 and batch: 350, loss is 4.314837884902954 and perplexity is 74.80149600916468
At time: 122.81152486801147 and batch: 400, loss is 4.28008807182312 and perplexity is 72.24680263475979
At time: 123.70724868774414 and batch: 450, loss is 4.295938081741333 and perplexity is 73.40103833261554
At time: 124.60354399681091 and batch: 500, loss is 4.308737831115723 and perplexity is 74.34659174100163
At time: 125.50060510635376 and batch: 550, loss is 4.2634493923187256 and perplexity is 71.05465661154783
At time: 126.39782667160034 and batch: 600, loss is 4.257862753868103 and perplexity is 70.65880669955207
At time: 127.2947301864624 and batch: 650, loss is 4.324999103546142 and perplexity is 75.56544511876146
At time: 128.22382307052612 and batch: 700, loss is 4.344329404830932 and perplexity is 77.04035726158381
At time: 129.12785696983337 and batch: 750, loss is 4.311580476760864 and perplexity is 74.55823342488422
At time: 130.03042721748352 and batch: 800, loss is 4.285943160057068 and perplexity is 72.67105484384652
At time: 130.93273377418518 and batch: 850, loss is 4.281886940002441 and perplexity is 72.37688207187998
At time: 131.84850478172302 and batch: 900, loss is 4.2597854661941525 and perplexity is 70.79479394842363
At time: 132.7837369441986 and batch: 950, loss is 4.3512732028961185 and perplexity is 77.57717155336543
At time: 133.6906294822693 and batch: 1000, loss is 4.330421867370606 and perplexity is 75.9763317446065
At time: 134.5970494747162 and batch: 1050, loss is 4.258601655960083 and perplexity is 70.71103593340793
At time: 135.50193071365356 and batch: 1100, loss is 4.311133460998535 and perplexity is 74.52491216745042
At time: 136.40384221076965 and batch: 1150, loss is 4.275308337211609 and perplexity is 71.90230604862346
At time: 137.30853128433228 and batch: 1200, loss is 4.342364225387573 and perplexity is 76.88910780002688
At time: 138.21222639083862 and batch: 1250, loss is 4.320535593032837 and perplexity is 75.2289095837115
At time: 139.11831283569336 and batch: 1300, loss is 4.328251581192017 and perplexity is 75.8116201622079
At time: 140.0252628326416 and batch: 1350, loss is 4.216511368751526 and perplexity is 67.79655407156339
At time: 140.92766785621643 and batch: 1400, loss is 4.236941227912903 and perplexity is 69.19587340106358
At time: 141.83205199241638 and batch: 1450, loss is 4.173235626220703 and perplexity is 64.92518624878964
At time: 142.73670482635498 and batch: 1500, loss is 4.180842280387878 and perplexity is 65.42093278317317
At time: 143.63903665542603 and batch: 1550, loss is 4.184293303489685 and perplexity is 65.64709194934858
At time: 144.54443359375 and batch: 1600, loss is 4.266790580749512 and perplexity is 71.29246066101338
At time: 145.44998979568481 and batch: 1650, loss is 4.223790445327759 and perplexity is 68.29185084488763
At time: 146.3536558151245 and batch: 1700, loss is 4.247453923225403 and perplexity is 69.92714562122437
At time: 147.2530279159546 and batch: 1750, loss is 4.2482348775863645 and perplexity is 69.98177686002236
At time: 148.1546540260315 and batch: 1800, loss is 4.2072565603256225 and perplexity is 67.1720044530242
At time: 149.0526762008667 and batch: 1850, loss is 4.238656415939331 and perplexity is 69.31465917544726
At time: 149.95329666137695 and batch: 1900, loss is 4.331093339920044 and perplexity is 76.02736489754321
At time: 150.8503634929657 and batch: 1950, loss is 4.255974292755127 and perplexity is 70.52549620627052
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378317757539971 and perplexity of 79.7038393804551
finished 4 epochs...
Completing Train Step...
At time: 153.95830297470093 and batch: 50, loss is 4.224101586341858 and perplexity is 68.31310254658078
At time: 154.85437679290771 and batch: 100, loss is 4.195025329589844 and perplexity is 66.35541231138636
At time: 155.7765233516693 and batch: 150, loss is 4.167526898384094 and perplexity is 64.5556019625213
At time: 156.6750237941742 and batch: 200, loss is 4.164788427352906 and perplexity is 64.37906015428703
At time: 157.57147121429443 and batch: 250, loss is 4.159525599479675 and perplexity is 64.04113424497284
At time: 158.46875476837158 and batch: 300, loss is 4.1792485857009884 and perplexity is 65.31675482616333
At time: 159.366947889328 and batch: 350, loss is 4.177458934783935 and perplexity is 65.19996517351589
At time: 160.26286029815674 and batch: 400, loss is 4.142096343040467 and perplexity is 62.934615801689304
At time: 161.16035890579224 and batch: 450, loss is 4.165764489173889 and perplexity is 64.44192877381283
At time: 162.05570197105408 and batch: 500, loss is 4.188378939628601 and perplexity is 65.91585073207642
At time: 162.9520719051361 and batch: 550, loss is 4.139378981590271 and perplexity is 62.7638318487817
At time: 163.84865927696228 and batch: 600, loss is 4.137550220489502 and perplexity is 62.64915668326207
At time: 164.7454080581665 and batch: 650, loss is 4.199124898910522 and perplexity is 66.62799928679131
At time: 165.6513226032257 and batch: 700, loss is 4.22293671131134 and perplexity is 68.23357264935588
At time: 166.55468702316284 and batch: 750, loss is 4.194849967956543 and perplexity is 66.34377713811641
At time: 167.4508936405182 and batch: 800, loss is 4.166377511024475 and perplexity is 64.48144519522246
At time: 168.34945917129517 and batch: 850, loss is 4.16487298488617 and perplexity is 64.38450411896842
At time: 169.2472801208496 and batch: 900, loss is 4.137681789398194 and perplexity is 62.657399906701386
At time: 170.14403581619263 and batch: 950, loss is 4.235228748321533 and perplexity is 69.0774782836021
At time: 171.0417239665985 and batch: 1000, loss is 4.2106593799591066 and perplexity is 67.40096800850424
At time: 171.93887567520142 and batch: 1050, loss is 4.15007716178894 and perplexity is 63.43889516791197
At time: 172.83969020843506 and batch: 1100, loss is 4.195539507865906 and perplexity is 66.38953959589831
At time: 173.7373149394989 and batch: 1150, loss is 4.159355344772339 and perplexity is 64.0302318685213
At time: 174.63452768325806 and batch: 1200, loss is 4.228635568618774 and perplexity is 68.62353616126335
At time: 175.53048992156982 and batch: 1250, loss is 4.206263432502746 and perplexity is 67.10532718149064
At time: 176.4290053844452 and batch: 1300, loss is 4.215819768905639 and perplexity is 67.74968219537531
At time: 177.32652306556702 and batch: 1350, loss is 4.103056769371033 and perplexity is 60.52501613275393
At time: 178.22393441200256 and batch: 1400, loss is 4.128329653739929 and perplexity is 62.07415096541565
At time: 179.12795877456665 and batch: 1450, loss is 4.057621617317199 and perplexity is 57.836589823287255
At time: 180.02510738372803 and batch: 1500, loss is 4.068426065444946 and perplexity is 58.46487025769497
At time: 180.92100620269775 and batch: 1550, loss is 4.0754962682724 and perplexity is 58.879693462790705
At time: 181.83149933815002 and batch: 1600, loss is 4.15839159488678 and perplexity is 63.968552466418075
At time: 182.72785663604736 and batch: 1650, loss is 4.113225860595703 and perplexity is 61.143640636680715
At time: 183.62451338768005 and batch: 1700, loss is 4.139828052520752 and perplexity is 62.792023590722685
At time: 184.5263135433197 and batch: 1750, loss is 4.144481225013733 and perplexity is 63.084886550184684
At time: 185.4229326248169 and batch: 1800, loss is 4.101526560783387 and perplexity is 60.43247105799237
At time: 186.319580078125 and batch: 1850, loss is 4.129033460617065 and perplexity is 62.11785455739778
At time: 187.21892881393433 and batch: 1900, loss is 4.220744471549988 and perplexity is 68.08415214096654
At time: 188.11631655693054 and batch: 1950, loss is 4.148906254768372 and perplexity is 63.36465759131438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362427893350291 and perplexity of 78.44736523598013
finished 5 epochs...
Completing Train Step...
At time: 191.09363293647766 and batch: 50, loss is 4.127098088264465 and perplexity is 61.99774964044182
At time: 192.00136852264404 and batch: 100, loss is 4.094951238632202 and perplexity is 60.036411628527325
At time: 192.89742636680603 and batch: 150, loss is 4.070526504516602 and perplexity is 58.58780121480022
At time: 193.79753232002258 and batch: 200, loss is 4.068694343566895 and perplexity is 58.4805572074263
At time: 194.69410014152527 and batch: 250, loss is 4.060616745948791 and perplexity is 58.010077528723976
At time: 195.59129905700684 and batch: 300, loss is 4.079845371246338 and perplexity is 59.13632496664381
At time: 196.49149894714355 and batch: 350, loss is 4.078181629180908 and perplexity is 59.03801917561793
At time: 197.3875699043274 and batch: 400, loss is 4.040352959632873 and perplexity is 56.84640375070683
At time: 198.28423500061035 and batch: 450, loss is 4.073832726478576 and perplexity is 58.781826057736716
At time: 199.18068289756775 and batch: 500, loss is 4.09354293346405 and perplexity is 59.95192154762665
At time: 200.10108304023743 and batch: 550, loss is 4.050843524932861 and perplexity is 57.44589365741977
At time: 200.99661350250244 and batch: 600, loss is 4.04943407535553 and perplexity is 57.36498359960258
At time: 201.89249849319458 and batch: 650, loss is 4.106209044456482 and perplexity is 60.716108663028756
At time: 202.78917241096497 and batch: 700, loss is 4.1318058681488035 and perplexity is 62.29030951247542
At time: 203.68539810180664 and batch: 750, loss is 4.10812940120697 and perplexity is 60.83281727738467
At time: 204.58169031143188 and batch: 800, loss is 4.076113457679749 and perplexity is 58.91604460251914
At time: 205.49230909347534 and batch: 850, loss is 4.077637076377869 and perplexity is 59.0058786087021
At time: 206.3984591960907 and batch: 900, loss is 4.049410963058472 and perplexity is 57.363657778382375
At time: 207.29569101333618 and batch: 950, loss is 4.150107979774475 and perplexity is 63.44085025699142
At time: 208.22249937057495 and batch: 1000, loss is 4.122848815917969 and perplexity is 61.73486325084566
At time: 209.12339997291565 and batch: 1050, loss is 4.0679087686538695 and perplexity is 58.43463438905312
At time: 210.01975083351135 and batch: 1100, loss is 4.107213397026062 and perplexity is 60.77711967593454
At time: 210.91707754135132 and batch: 1150, loss is 4.072773447036743 and perplexity is 58.71959264494694
At time: 211.81368851661682 and batch: 1200, loss is 4.1426100921630855 and perplexity is 62.966956712185635
At time: 212.7093493938446 and batch: 1250, loss is 4.121914558410644 and perplexity is 61.67721392524072
At time: 213.60624146461487 and batch: 1300, loss is 4.132657790184021 and perplexity is 62.34339861040494
At time: 214.5016486644745 and batch: 1350, loss is 4.015273933410644 and perplexity is 55.43847977449108
At time: 215.3976128101349 and batch: 1400, loss is 4.044574904441833 and perplexity is 57.086913482082714
At time: 216.29124546051025 and batch: 1450, loss is 3.9709588718414306 and perplexity is 53.03536058003855
At time: 217.18680262565613 and batch: 1500, loss is 3.9852493381500245 and perplexity is 53.79870187450828
At time: 218.08326363563538 and batch: 1550, loss is 3.989582886695862 and perplexity is 54.03234705149536
At time: 218.97867131233215 and batch: 1600, loss is 4.076646680831909 and perplexity is 58.94746837873289
At time: 219.8760735988617 and batch: 1650, loss is 4.0310576629638675 and perplexity is 56.3204478085253
At time: 220.7728865146637 and batch: 1700, loss is 4.060491719245911 and perplexity is 58.0028251733752
At time: 221.67121934890747 and batch: 1750, loss is 4.063406190872192 and perplexity is 58.172119343280436
At time: 222.56805300712585 and batch: 1800, loss is 4.01889353275299 and perplexity is 55.63950846159392
At time: 223.4641399383545 and batch: 1850, loss is 4.0475478982925415 and perplexity is 57.25688506185773
At time: 224.36071181297302 and batch: 1900, loss is 4.1400163459777835 and perplexity is 62.80384803111604
At time: 225.2574179172516 and batch: 1950, loss is 4.0685447454452515 and perplexity is 58.47180928026847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355640783975291 and perplexity of 77.9167371403448
finished 6 epochs...
Completing Train Step...
At time: 228.32778215408325 and batch: 50, loss is 4.0478474807739255 and perplexity is 57.27404079121056
At time: 229.22457146644592 and batch: 100, loss is 4.017731804847717 and perplexity is 55.57490802330976
At time: 230.1223533153534 and batch: 150, loss is 3.9969819736480714 and perplexity is 54.433619780781385
At time: 231.0194308757782 and batch: 200, loss is 3.992423062324524 and perplexity is 54.186026541816055
At time: 231.9181456565857 and batch: 250, loss is 3.9844626998901367 and perplexity is 53.75639839822943
At time: 232.81719827651978 and batch: 300, loss is 4.005665926933289 and perplexity is 54.9083771942107
At time: 233.72929549217224 and batch: 350, loss is 4.001625638008118 and perplexity is 54.6869790433563
At time: 234.63413786888123 and batch: 400, loss is 3.9618231296539306 and perplexity is 52.55304968748188
At time: 235.53033208847046 and batch: 450, loss is 3.9982605457305906 and perplexity is 54.503261598938565
At time: 236.42669415473938 and batch: 500, loss is 4.020560355186462 and perplexity is 55.73232697698711
At time: 237.3236153125763 and batch: 550, loss is 3.9815024948120117 and perplexity is 53.59750373113984
At time: 238.22080445289612 and batch: 600, loss is 3.9786889362335205 and perplexity is 53.4469159578312
At time: 239.11826634407043 and batch: 650, loss is 4.033933753967285 and perplexity is 56.48266370379491
At time: 240.01551342010498 and batch: 700, loss is 4.060171642303467 and perplexity is 57.984262777296564
At time: 240.91313672065735 and batch: 750, loss is 4.037643785476685 and perplexity is 56.6926053701606
At time: 241.81158566474915 and batch: 800, loss is 4.003222236633301 and perplexity is 54.77436193805457
At time: 242.70950984954834 and batch: 850, loss is 4.00540020942688 and perplexity is 54.89378901539479
At time: 243.62540125846863 and batch: 900, loss is 3.980298833847046 and perplexity is 53.53302931853012
At time: 244.52332377433777 and batch: 950, loss is 4.08215078830719 and perplexity is 59.27281613321639
At time: 245.46367263793945 and batch: 1000, loss is 4.055650396347046 and perplexity is 57.72269341895647
At time: 246.36184549331665 and batch: 1050, loss is 3.999249358177185 and perplexity is 54.557181756455655
At time: 247.25901126861572 and batch: 1100, loss is 4.03844123840332 and perplexity is 56.73783308532171
At time: 248.15636324882507 and batch: 1150, loss is 4.000254440307617 and perplexity is 54.612043770722465
At time: 249.07846760749817 and batch: 1200, loss is 4.075385251045227 and perplexity is 58.873157165313195
At time: 249.97649598121643 and batch: 1250, loss is 4.05594081401825 and perplexity is 57.739459543626424
At time: 250.88315534591675 and batch: 1300, loss is 4.060754480361939 and perplexity is 58.01806806298218
At time: 251.808837890625 and batch: 1350, loss is 3.9461417388916016 and perplexity is 51.73537269172997
At time: 252.71331238746643 and batch: 1400, loss is 3.9776933717727663 and perplexity is 53.393732585896885
At time: 253.6344404220581 and batch: 1450, loss is 3.9054037809371946 and perplexity is 49.6701317159715
At time: 254.53270077705383 and batch: 1500, loss is 3.9190306949615477 and perplexity is 50.351615042279505
At time: 255.4310371875763 and batch: 1550, loss is 3.9226369619369508 and perplexity is 50.53352421814494
At time: 256.3286955356598 and batch: 1600, loss is 4.010252904891968 and perplexity is 55.16081924057603
At time: 257.22604727745056 and batch: 1650, loss is 3.9666662883758543 and perplexity is 52.80818979173248
At time: 258.12462735176086 and batch: 1700, loss is 3.99576162815094 and perplexity is 54.36723247395373
At time: 259.0226619243622 and batch: 1750, loss is 3.9983086442947386 and perplexity is 54.50588319060975
At time: 259.9194803237915 and batch: 1800, loss is 3.9517641925811766 and perplexity is 52.02707169243185
At time: 260.81589126586914 and batch: 1850, loss is 3.9812201976776125 and perplexity is 53.58237544486198
At time: 261.71252250671387 and batch: 1900, loss is 4.0725093269348145 and perplexity is 58.704085668094635
At time: 262.610390663147 and batch: 1950, loss is 4.004934959411621 and perplexity is 54.868255619384755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349962811137354 and perplexity of 77.47558164292127
finished 7 epochs...
Completing Train Step...
At time: 265.55008006095886 and batch: 50, loss is 3.9853001260757446 and perplexity is 53.801434268368645
At time: 266.4704375267029 and batch: 100, loss is 3.956177201271057 and perplexity is 52.257174962352934
At time: 267.36555314064026 and batch: 150, loss is 3.9362723445892334 and perplexity is 51.227287271095705
At time: 268.3076174259186 and batch: 200, loss is 3.9287986516952516 and perplexity is 50.845857378608336
At time: 269.20436096191406 and batch: 250, loss is 3.921676096916199 and perplexity is 50.484991642709474
At time: 270.098920583725 and batch: 300, loss is 3.939570178985596 and perplexity is 51.3965052541694
At time: 270.99477887153625 and batch: 350, loss is 3.938431921005249 and perplexity is 51.338036054731205
At time: 271.8917005062103 and batch: 400, loss is 3.90130389213562 and perplexity is 49.46690658406671
At time: 272.7883629798889 and batch: 450, loss is 3.941344757080078 and perplexity is 51.487793341489926
At time: 273.684298992157 and batch: 500, loss is 3.9630039739608764 and perplexity is 52.6151433112538
At time: 274.5813512802124 and batch: 550, loss is 3.9237216663360597 and perplexity is 50.58836789337738
At time: 275.47832345962524 and batch: 600, loss is 3.9240706157684326 and perplexity is 50.606023755960905
At time: 276.37397742271423 and batch: 650, loss is 3.97564658164978 and perplexity is 53.284558587655354
At time: 277.2687654495239 and batch: 700, loss is 3.995754055976868 and perplexity is 54.366820797364255
At time: 278.163152217865 and batch: 750, loss is 3.9800657510757445 and perplexity is 53.520553145747336
At time: 279.0585834980011 and batch: 800, loss is 3.948529109954834 and perplexity is 51.85903177476469
At time: 279.9547531604767 and batch: 850, loss is 3.952127914428711 and perplexity is 52.04599851691075
At time: 280.85134291648865 and batch: 900, loss is 3.9225957441329955 and perplexity is 50.53144138017584
At time: 281.74847960472107 and batch: 950, loss is 4.028290314674377 and perplexity is 56.16480497191676
At time: 282.6510875225067 and batch: 1000, loss is 3.994659090042114 and perplexity is 54.30732356027872
At time: 283.57117342948914 and batch: 1050, loss is 3.95009681224823 and perplexity is 51.94039505785022
At time: 284.4804775714874 and batch: 1100, loss is 3.97834180355072 and perplexity is 53.42836600634084
At time: 285.37742161750793 and batch: 1150, loss is 3.946981086730957 and perplexity is 51.778814894025906
At time: 286.2749104499817 and batch: 1200, loss is 4.017797298431397 and perplexity is 55.57854794239326
At time: 287.1708040237427 and batch: 1250, loss is 3.9996115875244143 and perplexity is 54.57694754844881
At time: 288.0666916370392 and batch: 1300, loss is 4.005491995811463 and perplexity is 54.89882774906459
At time: 288.9631042480469 and batch: 1350, loss is 3.8895777082443237 and perplexity is 48.890236220123455
At time: 289.85960841178894 and batch: 1400, loss is 3.926386137008667 and perplexity is 50.72333884923002
At time: 290.7558705806732 and batch: 1450, loss is 3.8476353025436403 and perplexity is 46.88207013875203
At time: 291.6534287929535 and batch: 1500, loss is 3.864771866798401 and perplexity is 47.69239097368011
At time: 292.5511176586151 and batch: 1550, loss is 3.869305815696716 and perplexity is 47.90911677778996
At time: 293.447655916214 and batch: 1600, loss is 3.9601203203201294 and perplexity is 52.46363801107742
At time: 294.3443877696991 and batch: 1650, loss is 3.911505727767944 and perplexity is 49.97414280524107
At time: 295.2411398887634 and batch: 1700, loss is 3.9430294179916383 and perplexity is 51.57460591870078
At time: 296.1383697986603 and batch: 1750, loss is 3.942301158905029 and perplexity is 51.53705991657022
At time: 297.03379011154175 and batch: 1800, loss is 3.8981556701660156 and perplexity is 49.31141866565471
At time: 297.9300305843353 and batch: 1850, loss is 3.929089994430542 and perplexity is 50.86067310789797
At time: 298.8275451660156 and batch: 1900, loss is 4.016918025016785 and perplexity is 55.52970068096102
At time: 299.724023103714 and batch: 1950, loss is 3.9506951189041137 and perplexity is 51.97148064035071
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356284917787064 and perplexity of 77.96694211286417
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 302.7399022579193 and batch: 50, loss is 3.965520534515381 and perplexity is 52.74771925320571
At time: 303.68113017082214 and batch: 100, loss is 3.953787932395935 and perplexity is 52.13246755979673
At time: 304.5860507488251 and batch: 150, loss is 3.9329421520233154 and perplexity is 51.05697428477397
At time: 305.4906551837921 and batch: 200, loss is 3.930563769340515 and perplexity is 50.935685553981884
At time: 306.3953950405121 and batch: 250, loss is 3.9217786693573 and perplexity is 50.49017027712929
At time: 307.29714822769165 and batch: 300, loss is 3.928082990646362 and perplexity is 50.80948199675958
At time: 308.1995437145233 and batch: 350, loss is 3.9255991792678833 and perplexity is 50.683437427509816
At time: 309.101989030838 and batch: 400, loss is 3.8798769998550413 and perplexity is 48.41825925216271
At time: 310.0026504993439 and batch: 450, loss is 3.9072697305679323 and perplexity is 49.762900203651746
At time: 310.905837059021 and batch: 500, loss is 3.9270052528381347 and perplexity is 50.75475219448127
At time: 311.80824518203735 and batch: 550, loss is 3.884872851371765 and perplexity is 48.66075491789336
At time: 312.74835753440857 and batch: 600, loss is 3.8739803886413573 and perplexity is 48.13359570166407
At time: 313.649218082428 and batch: 650, loss is 3.9143213033676147 and perplexity is 50.11504705253379
At time: 314.55216360092163 and batch: 700, loss is 3.9352746391296387 and perplexity is 51.176203014663386
At time: 315.45254397392273 and batch: 750, loss is 3.9061258363723756 and perplexity is 49.70600925577071
At time: 316.35295367240906 and batch: 800, loss is 3.8735286664962767 and perplexity is 48.11185760072371
At time: 317.2533640861511 and batch: 850, loss is 3.879648723602295 and perplexity is 48.407207774819035
At time: 318.15317702293396 and batch: 900, loss is 3.841763997077942 and perplexity is 46.60761766965926
At time: 319.0584418773651 and batch: 950, loss is 3.946398878097534 and perplexity is 51.74867759491535
At time: 319.9620599746704 and batch: 1000, loss is 3.9036788940429688 and perplexity is 49.58453020442656
At time: 320.8611834049225 and batch: 1050, loss is 3.841207938194275 and perplexity is 46.58170829404434
At time: 321.7691774368286 and batch: 1100, loss is 3.858778705596924 and perplexity is 47.40741758519056
At time: 322.6707372665405 and batch: 1150, loss is 3.829440631866455 and perplexity is 46.03677952314877
At time: 323.57451367378235 and batch: 1200, loss is 3.8885831785202027 and perplexity is 48.84163759737638
At time: 324.4790606498718 and batch: 1250, loss is 3.867555522918701 and perplexity is 47.82533513928005
At time: 325.3839280605316 and batch: 1300, loss is 3.8713622188568113 and perplexity is 48.00773860529376
At time: 326.2898197174072 and batch: 1350, loss is 3.749111280441284 and perplexity is 42.48330946991086
At time: 327.1940960884094 and batch: 1400, loss is 3.7733510732650757 and perplexity is 43.52567845604881
At time: 328.1007082462311 and batch: 1450, loss is 3.690035538673401 and perplexity is 40.046270123312695
At time: 329.0172827243805 and batch: 1500, loss is 3.701287727355957 and perplexity is 40.4994230104704
At time: 329.9276020526886 and batch: 1550, loss is 3.701612663269043 and perplexity is 40.51258486572969
At time: 330.8242702484131 and batch: 1600, loss is 3.788330874443054 and perplexity is 44.18259240166457
At time: 331.72047185897827 and batch: 1650, loss is 3.7300604677200315 and perplexity is 41.681628480871055
At time: 332.6164255142212 and batch: 1700, loss is 3.747159743309021 and perplexity is 42.40048256016104
At time: 333.51765966415405 and batch: 1750, loss is 3.7313241863250735 and perplexity is 41.734335626756845
At time: 334.4290597438812 and batch: 1800, loss is 3.688133955001831 and perplexity is 39.970191148132656
At time: 335.3257784843445 and batch: 1850, loss is 3.710081067085266 and perplexity is 40.85711856025406
At time: 336.2217116355896 and batch: 1900, loss is 3.7878861665725707 and perplexity is 44.16294842332481
At time: 337.11775398254395 and batch: 1950, loss is 3.718617906570435 and perplexity is 41.20740225374444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.287526117369186 and perplexity of 72.7861811174394
finished 9 epochs...
Completing Train Step...
At time: 340.1006097793579 and batch: 50, loss is 3.8794712686538695 and perplexity is 48.398618438392596
At time: 341.0247356891632 and batch: 100, loss is 3.853763179779053 and perplexity is 47.17023974132681
At time: 341.9221251010895 and batch: 150, loss is 3.8307185411453246 and perplexity is 46.0956479571184
At time: 342.8188786506653 and batch: 200, loss is 3.827111072540283 and perplexity is 45.929658934390886
At time: 343.7156386375427 and batch: 250, loss is 3.8165717458724977 and perplexity is 45.44813319090712
At time: 344.6121668815613 and batch: 300, loss is 3.830104670524597 and perplexity is 46.067359876593244
At time: 345.5086920261383 and batch: 350, loss is 3.826767954826355 and perplexity is 45.91390235815062
At time: 346.4047873020172 and batch: 400, loss is 3.7837648677825926 and perplexity is 43.98131425884656
At time: 347.30115008354187 and batch: 450, loss is 3.817974286079407 and perplexity is 45.511920746885835
At time: 348.1970806121826 and batch: 500, loss is 3.8427882385253906 and perplexity is 46.655379579131555
At time: 349.09311604499817 and batch: 550, loss is 3.802583737373352 and perplexity is 44.81682994871736
At time: 349.98958587646484 and batch: 600, loss is 3.7973526239395143 and perplexity is 44.58300015581635
At time: 350.88681650161743 and batch: 650, loss is 3.839507260322571 and perplexity is 46.50255513960952
At time: 351.78305172920227 and batch: 700, loss is 3.862001895904541 and perplexity is 47.56046723563309
At time: 352.6806209087372 and batch: 750, loss is 3.8370699739456176 and perplexity is 46.3893531044018
At time: 353.5779674053192 and batch: 800, loss is 3.8060992336273194 and perplexity is 44.9746606105183
At time: 354.4745190143585 and batch: 850, loss is 3.8143225049972536 and perplexity is 45.346024268859324
At time: 355.3715114593506 and batch: 900, loss is 3.775664072036743 and perplexity is 43.62646981706492
At time: 356.2690875530243 and batch: 950, loss is 3.8831206941604615 and perplexity is 48.57556827724382
At time: 357.16551065444946 and batch: 1000, loss is 3.8432591342926026 and perplexity is 46.67735457345287
At time: 358.0870337486267 and batch: 1050, loss is 3.7856002855300903 and perplexity is 44.06211247014855
At time: 358.98396825790405 and batch: 1100, loss is 3.802826476097107 and perplexity is 44.827710049279304
At time: 359.88077998161316 and batch: 1150, loss is 3.777512583732605 and perplexity is 43.707188438444184
At time: 360.7766764163971 and batch: 1200, loss is 3.839147200584412 and perplexity is 46.4858144557862
At time: 361.6727063655853 and batch: 1250, loss is 3.8223755025863646 and perplexity is 45.71267001017156
At time: 362.56845140457153 and batch: 1300, loss is 3.826692204475403 and perplexity is 45.91042449565972
At time: 363.4643371105194 and batch: 1350, loss is 3.7079357862472535 and perplexity is 40.76956251644128
At time: 364.35906887054443 and batch: 1400, loss is 3.7369662618637083 and perplexity is 41.97046941685432
At time: 365.2546920776367 and batch: 1450, loss is 3.654137988090515 and perplexity is 38.63420361355454
At time: 366.15161776542664 and batch: 1500, loss is 3.6681990003585816 and perplexity is 39.18127681246105
At time: 367.04841566085815 and batch: 1550, loss is 3.669858660697937 and perplexity is 39.24635841537079
At time: 367.94506192207336 and batch: 1600, loss is 3.7613697957992556 and perplexity is 43.00729686359359
At time: 368.84313464164734 and batch: 1650, loss is 3.705187129974365 and perplexity is 40.657654870969616
At time: 369.74114441871643 and batch: 1700, loss is 3.7277345752716062 and perplexity is 41.58479415271996
At time: 370.6384086608887 and batch: 1750, loss is 3.714011425971985 and perplexity is 41.01801768780398
At time: 371.5348951816559 and batch: 1800, loss is 3.6757168579101562 and perplexity is 39.476946077377825
At time: 372.43148016929626 and batch: 1850, loss is 3.7014811992645265 and perplexity is 40.50725926915971
At time: 373.32840633392334 and batch: 1900, loss is 3.782602028846741 and perplexity is 43.93020079829709
At time: 374.22538661956787 and batch: 1950, loss is 3.7152986240386965 and perplexity is 41.07084999640008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.289377895621366 and perplexity of 72.92108985667551
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 377.1848073005676 and batch: 50, loss is 3.862740297317505 and perplexity is 47.595598920887866
At time: 378.0812530517578 and batch: 100, loss is 3.8618899726867677 and perplexity is 47.55514441298055
At time: 378.9766778945923 and batch: 150, loss is 3.842431678771973 and perplexity is 46.638747113903264
At time: 379.8751242160797 and batch: 200, loss is 3.842327346801758 and perplexity is 46.63388145535481
At time: 380.81327056884766 and batch: 250, loss is 3.836302661895752 and perplexity is 46.353771647565374
At time: 381.7104766368866 and batch: 300, loss is 3.848459520339966 and perplexity is 46.9207271039799
At time: 382.60666131973267 and batch: 350, loss is 3.845456533432007 and perplexity is 46.78003612708402
At time: 383.5045254230499 and batch: 400, loss is 3.8038029193878176 and perplexity is 44.87150314325172
At time: 384.40110874176025 and batch: 450, loss is 3.8362128591537474 and perplexity is 46.34960913867433
At time: 385.29762077331543 and batch: 500, loss is 3.8567894077301026 and perplexity is 47.313203851176254
At time: 386.2157061100006 and batch: 550, loss is 3.8147150325775145 and perplexity is 45.363827327907295
At time: 387.1240265369415 and batch: 600, loss is 3.8013523483276366 and perplexity is 44.761676959617255
At time: 388.04429030418396 and batch: 650, loss is 3.841746678352356 and perplexity is 46.6068104921083
At time: 388.95054721832275 and batch: 700, loss is 3.863158550262451 and perplexity is 47.61551008396403
At time: 389.8487961292267 and batch: 750, loss is 3.8369661474227907 and perplexity is 46.38453690920151
At time: 390.74768257141113 and batch: 800, loss is 3.8040785217285156 and perplexity is 44.88387153884974
At time: 391.645635843277 and batch: 850, loss is 3.8087805891036988 and perplexity is 45.09541548406643
At time: 392.54294633865356 and batch: 900, loss is 3.7669725465774535 and perplexity is 43.24893230906019
At time: 393.44072103500366 and batch: 950, loss is 3.881848249435425 and perplexity is 48.513797859679244
At time: 394.3381097316742 and batch: 1000, loss is 3.8414824628829956 and perplexity is 46.59449787846185
At time: 395.2355127334595 and batch: 1050, loss is 3.776943340301514 and perplexity is 43.682315488587435
At time: 396.1326777935028 and batch: 1100, loss is 3.789744062423706 and perplexity is 44.24507484952416
At time: 397.02974462509155 and batch: 1150, loss is 3.7615335607528686 and perplexity is 43.01434052830645
At time: 397.9314088821411 and batch: 1200, loss is 3.8147458600997926 and perplexity is 45.365225803860525
At time: 398.85464096069336 and batch: 1250, loss is 3.794847402572632 and perplexity is 44.4714496589126
At time: 399.7525179386139 and batch: 1300, loss is 3.801812925338745 and perplexity is 44.782297907406246
At time: 400.6503348350525 and batch: 1350, loss is 3.679055485725403 and perplexity is 39.60896516628544
At time: 401.57961106300354 and batch: 1400, loss is 3.7042275524139403 and perplexity is 40.61865941027268
At time: 402.4877460002899 and batch: 1450, loss is 3.6167975521087645 and perplexity is 37.21818746343405
At time: 403.4100172519684 and batch: 1500, loss is 3.6301615190505983 and perplexity is 37.71890844747722
At time: 404.3073980808258 and batch: 1550, loss is 3.6321242523193358 and perplexity is 37.79301330419173
At time: 405.205365896225 and batch: 1600, loss is 3.721777567863464 and perplexity is 41.337809600662055
At time: 406.1016254425049 and batch: 1650, loss is 3.6607670068740843 and perplexity is 38.89116122242921
At time: 406.99785256385803 and batch: 1700, loss is 3.6756068325042723 and perplexity is 39.4726028492997
At time: 407.8948333263397 and batch: 1750, loss is 3.65843665599823 and perplexity is 38.8006366887411
At time: 408.7918050289154 and batch: 1800, loss is 3.6170304155349733 and perplexity is 37.22685522724749
At time: 409.68810653686523 and batch: 1850, loss is 3.6421158123016357 and perplexity is 38.17251722443242
At time: 410.5852243900299 and batch: 1900, loss is 3.7258231592178346 and perplexity is 41.505384226464685
At time: 411.4824023246765 and batch: 1950, loss is 3.6588880825042724 and perplexity is 38.818156278699846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2655384152434594 and perplexity of 71.20324656799373
finished 11 epochs...
Completing Train Step...
At time: 414.4482035636902 and batch: 50, loss is 3.85029589176178 and perplexity is 47.00697014922003
At time: 415.34529995918274 and batch: 100, loss is 3.8333758878707886 and perplexity is 46.218302972549935
At time: 416.2425203323364 and batch: 150, loss is 3.806611404418945 and perplexity is 44.99770121790569
At time: 417.1396915912628 and batch: 200, loss is 3.801615424156189 and perplexity is 44.77345422395966
At time: 418.03713822364807 and batch: 250, loss is 3.7929349613189696 and perplexity is 44.386481897797495
At time: 418.9341435432434 and batch: 300, loss is 3.806244821548462 and perplexity is 44.98120885452174
At time: 419.8311655521393 and batch: 350, loss is 3.8045677280426027 and perplexity is 44.90583438395045
At time: 420.729154586792 and batch: 400, loss is 3.763533582687378 and perplexity is 43.10045624081262
At time: 421.6248962879181 and batch: 450, loss is 3.798073401451111 and perplexity is 44.61514616339614
At time: 422.52128314971924 and batch: 500, loss is 3.8193053293228147 and perplexity is 45.57253941557546
At time: 423.4182198047638 and batch: 550, loss is 3.7792948055267335 and perplexity is 43.78515379738332
At time: 424.3156542778015 and batch: 600, loss is 3.7683972358703612 and perplexity is 43.31059251273707
At time: 425.2366728782654 and batch: 650, loss is 3.809488582611084 and perplexity is 45.12735405025661
At time: 426.13313031196594 and batch: 700, loss is 3.832108998298645 and perplexity is 46.159786561214105
At time: 427.0302805900574 and batch: 750, loss is 3.8074512577056883 and perplexity is 45.03550855925708
At time: 427.93573212623596 and batch: 800, loss is 3.776283597946167 and perplexity is 43.6535059193715
At time: 428.83832931518555 and batch: 850, loss is 3.7816092348098755 and perplexity is 43.88660879942502
At time: 429.7344100475311 and batch: 900, loss is 3.7413603258132935 and perplexity is 42.155296116251506
At time: 430.63000988960266 and batch: 950, loss is 3.8560665702819823 and perplexity is 47.279016453096425
At time: 431.52757453918457 and batch: 1000, loss is 3.816843395233154 and perplexity is 45.460480824268885
At time: 432.4226002693176 and batch: 1050, loss is 3.7539645051956176 and perplexity is 42.68999165093595
At time: 433.3197331428528 and batch: 1100, loss is 3.767650499343872 and perplexity is 43.27826298364634
At time: 434.2176477909088 and batch: 1150, loss is 3.741516308784485 and perplexity is 42.1618721374515
At time: 435.1125650405884 and batch: 1200, loss is 3.797171311378479 and perplexity is 44.5749174306514
At time: 436.0169470310211 and batch: 1250, loss is 3.779819755554199 and perplexity is 43.80814484912049
At time: 436.9363157749176 and batch: 1300, loss is 3.787585206031799 and perplexity is 44.14965911836378
At time: 437.83177638053894 and batch: 1350, loss is 3.6657211780548096 and perplexity is 39.084312750352815
At time: 438.7273156642914 and batch: 1400, loss is 3.6934185314178465 and perplexity is 40.18197578078409
At time: 439.6226737499237 and batch: 1450, loss is 3.6084369134902956 and perplexity is 36.90831681129
At time: 440.5170741081238 and batch: 1500, loss is 3.623403787612915 and perplexity is 37.46487351075468
At time: 441.41084909439087 and batch: 1550, loss is 3.6275211143493653 and perplexity is 37.619446631795114
At time: 442.3060839176178 and batch: 1600, loss is 3.7190675926208496 and perplexity is 41.225936814766214
At time: 443.20047521591187 and batch: 1650, loss is 3.6591102409362795 and perplexity is 38.826781017425866
At time: 444.09571719169617 and batch: 1700, loss is 3.67587149143219 and perplexity is 39.483051008590245
At time: 444.9902868270874 and batch: 1750, loss is 3.660343770980835 and perplexity is 38.874704569838414
At time: 445.88538575172424 and batch: 1800, loss is 3.6203743839263915 and perplexity is 37.35154902430218
At time: 446.7818522453308 and batch: 1850, loss is 3.647220506668091 and perplexity is 38.36787445331778
At time: 447.6763496398926 and batch: 1900, loss is 3.7315300035476686 and perplexity is 41.74292615581149
At time: 448.5742118358612 and batch: 1950, loss is 3.664818735122681 and perplexity is 39.04905729896329
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.264342126180959 and perplexity of 71.11811783234997
finished 12 epochs...
Completing Train Step...
At time: 451.5347466468811 and batch: 50, loss is 3.835556273460388 and perplexity is 46.319186637003696
At time: 452.43132996559143 and batch: 100, loss is 3.816219940185547 and perplexity is 45.432147091354516
At time: 453.3250949382782 and batch: 150, loss is 3.7889630126953127 and perplexity is 44.21053073792079
At time: 454.22003650665283 and batch: 200, loss is 3.782630319595337 and perplexity is 43.93144363414395
At time: 455.11408257484436 and batch: 250, loss is 3.7731070280075074 and perplexity is 43.515057516686824
At time: 456.00949001312256 and batch: 300, loss is 3.786930618286133 and perplexity is 44.12076874920196
At time: 456.9049708843231 and batch: 350, loss is 3.785411248207092 and perplexity is 44.05378387359415
At time: 457.8013699054718 and batch: 400, loss is 3.7442773294448854 and perplexity is 42.27844279044104
At time: 458.69824957847595 and batch: 450, loss is 3.7801147937774657 and perplexity is 43.82107183322482
At time: 459.5941321849823 and batch: 500, loss is 3.8014207172393797 and perplexity is 44.7647373713761
At time: 460.4890179634094 and batch: 550, loss is 3.7620947694778444 and perplexity is 43.03848732657318
At time: 461.408700466156 and batch: 600, loss is 3.7519395399093627 and perplexity is 42.60363336554657
At time: 462.31148886680603 and batch: 650, loss is 3.7934263229370115 and perplexity is 44.408297070492345
At time: 463.2075228691101 and batch: 700, loss is 3.816238441467285 and perplexity is 45.432987652083526
At time: 464.10400438308716 and batch: 750, loss is 3.792221508026123 and perplexity is 44.35482551014944
At time: 464.9997224807739 and batch: 800, loss is 3.7616914463043214 and perplexity is 43.021132407336815
At time: 465.8961682319641 and batch: 850, loss is 3.7671264743804933 and perplexity is 43.25559003458572
At time: 466.79308676719666 and batch: 900, loss is 3.72779513835907 and perplexity is 41.5873127325111
At time: 467.68960523605347 and batch: 950, loss is 3.8424377155303957 and perplexity is 46.63902866160255
At time: 468.5864067077637 and batch: 1000, loss is 3.803979320526123 and perplexity is 44.87941922566611
At time: 469.4825932979584 and batch: 1050, loss is 3.7418460178375246 and perplexity is 42.17577558030786
At time: 470.4030900001526 and batch: 1100, loss is 3.7557279539108275 and perplexity is 42.76533967853021
At time: 471.2988176345825 and batch: 1150, loss is 3.730273060798645 and perplexity is 41.69049064857582
At time: 472.19606590270996 and batch: 1200, loss is 3.7869539976119997 and perplexity is 44.12180027509018
At time: 473.0920729637146 and batch: 1250, loss is 3.7705704879760744 and perplexity is 43.40481970174709
At time: 473.9891300201416 and batch: 1300, loss is 3.7786914920806884 and perplexity is 43.75874559237382
At time: 474.88567662239075 and batch: 1350, loss is 3.6573392248153684 and perplexity is 38.75807901645353
At time: 475.78270840644836 and batch: 1400, loss is 3.68602623462677 and perplexity is 39.88603388300148
At time: 476.6801161766052 and batch: 1450, loss is 3.6019144105911254 and perplexity is 36.66836559980845
At time: 477.57753348350525 and batch: 1500, loss is 3.617391595840454 and perplexity is 37.240303262627116
At time: 478.47394919395447 and batch: 1550, loss is 3.622407374382019 and perplexity is 37.42756160721896
At time: 479.37146973609924 and batch: 1600, loss is 3.7149406051635743 and perplexity is 41.056148488749706
At time: 480.268342256546 and batch: 1650, loss is 3.655423493385315 and perplexity is 38.68390002251486
At time: 481.1651439666748 and batch: 1700, loss is 3.6729466009140013 and perplexity is 39.36773613097188
At time: 482.06158423423767 and batch: 1750, loss is 3.6583538818359376 and perplexity is 38.797425131461594
At time: 482.9587891101837 and batch: 1800, loss is 3.6190125703811646 and perplexity is 37.30071779808756
At time: 483.8562533855438 and batch: 1850, loss is 3.6467321586608885 and perplexity is 38.34914215260105
At time: 484.7528922557831 and batch: 1900, loss is 3.7313141345977785 and perplexity is 41.73391612670464
At time: 485.64880776405334 and batch: 1950, loss is 3.664682264328003 and perplexity is 39.04372860669599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26464105650436 and perplexity of 71.1393803721639
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 488.58616852760315 and batch: 50, loss is 3.833182554244995 and perplexity is 46.209368284173905
At time: 489.5140891075134 and batch: 100, loss is 3.827271966934204 and perplexity is 45.93704935355069
At time: 490.425838470459 and batch: 150, loss is 3.80383882522583 and perplexity is 44.87311432110013
At time: 491.3464193344116 and batch: 200, loss is 3.798571515083313 and perplexity is 44.637375111714285
At time: 492.2432041168213 and batch: 250, loss is 3.7917382431030275 and perplexity is 44.33339555739967
At time: 493.1779525279999 and batch: 300, loss is 3.804615864753723 and perplexity is 44.90799605515526
At time: 494.08370757102966 and batch: 350, loss is 3.805450406074524 and perplexity is 44.94548927614269
At time: 494.98163962364197 and batch: 400, loss is 3.7705233001708987 and perplexity is 43.402771571895066
At time: 495.87890696525574 and batch: 450, loss is 3.809732370376587 and perplexity is 45.138356888187744
At time: 496.77684211730957 and batch: 500, loss is 3.8307091093063352 and perplexity is 46.09521319243908
At time: 497.67435097694397 and batch: 550, loss is 3.7892864990234374 and perplexity is 44.22483455359332
At time: 498.57228565216064 and batch: 600, loss is 3.7725150394439697 and perplexity is 43.489304723726804
At time: 499.469651222229 and batch: 650, loss is 3.809420919418335 and perplexity is 45.12430069270239
At time: 500.3677053451538 and batch: 700, loss is 3.8277703714370728 and perplexity is 45.95995029228844
At time: 501.265784740448 and batch: 750, loss is 3.8031642198562623 and perplexity is 44.84285288564096
At time: 502.18343901634216 and batch: 800, loss is 3.7689679145812987 and perplexity is 43.33531599975504
At time: 503.08131647109985 and batch: 850, loss is 3.7713595819473267 and perplexity is 43.439083700276434
At time: 503.9789094924927 and batch: 900, loss is 3.7291947841644286 and perplexity is 41.64556099429187
At time: 504.8761532306671 and batch: 950, loss is 3.8462542295455933 and perplexity is 46.81736726756931
At time: 505.77382588386536 and batch: 1000, loss is 3.809930233955383 and perplexity is 45.14728900866413
At time: 506.67248344421387 and batch: 1050, loss is 3.7522770261764524 and perplexity is 42.61801393322113
At time: 507.59201550483704 and batch: 1100, loss is 3.76338182926178 and perplexity is 43.09391609519054
At time: 508.48969054222107 and batch: 1150, loss is 3.738220043182373 and perplexity is 42.023124209244635
At time: 509.38836550712585 and batch: 1200, loss is 3.790736885070801 and perplexity is 44.28902417519004
At time: 510.28532886505127 and batch: 1250, loss is 3.7697313165664674 and perplexity is 43.36841089676495
At time: 511.1843423843384 and batch: 1300, loss is 3.7755242490768435 and perplexity is 43.62037026136403
At time: 512.0811471939087 and batch: 1350, loss is 3.6537981843948364 and perplexity is 38.62107779861356
At time: 512.9790661334991 and batch: 1400, loss is 3.6800592947006225 and perplexity is 39.64874496333689
At time: 513.8778705596924 and batch: 1450, loss is 3.5916153383255005 and perplexity is 36.29265351658547
At time: 514.7984800338745 and batch: 1500, loss is 3.6061413049697877 and perplexity is 36.82368694043205
At time: 515.6970925331116 and batch: 1550, loss is 3.610549521446228 and perplexity is 36.98637203603925
At time: 516.5949692726135 and batch: 1600, loss is 3.701903853416443 and perplexity is 40.524383449020526
At time: 517.4931473731995 and batch: 1650, loss is 3.6413469219207766 and perplexity is 38.14317802388534
At time: 518.3906896114349 and batch: 1700, loss is 3.6563198375701904 and perplexity is 38.71858965595138
At time: 519.2867305278778 and batch: 1750, loss is 3.6420836591720582 and perplexity is 38.171289878271416
At time: 520.1932661533356 and batch: 1800, loss is 3.6034183359146117 and perplexity is 36.723553572297575
At time: 521.1020638942719 and batch: 1850, loss is 3.627476716041565 and perplexity is 37.61777642910164
At time: 522.0146536827087 and batch: 1900, loss is 3.7121943283081054 and perplexity is 40.94355162023482
At time: 522.9216697216034 and batch: 1950, loss is 3.650617308616638 and perplexity is 38.49842412418426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.254039675690407 and perplexity of 70.38918827215355
finished 14 epochs...
Completing Train Step...
At time: 525.8773839473724 and batch: 50, loss is 3.8330276155471803 and perplexity is 46.20220921944752
At time: 526.7984943389893 and batch: 100, loss is 3.816698422431946 and perplexity is 45.45389076872047
At time: 527.6952269077301 and batch: 150, loss is 3.7904707288742063 and perplexity is 44.27723794552329
At time: 528.5923545360565 and batch: 200, loss is 3.7809742641448976 and perplexity is 43.85875093565116
At time: 529.4894547462463 and batch: 250, loss is 3.7717343091964723 and perplexity is 43.45536455886701
At time: 530.3875248432159 and batch: 300, loss is 3.7848320770263673 and perplexity is 44.028276578830706
At time: 531.2830865383148 and batch: 350, loss is 3.7862868690490723 and perplexity is 44.09237517813154
At time: 532.1802494525909 and batch: 400, loss is 3.7522671461105346 and perplexity is 42.61759286651427
At time: 533.0776627063751 and batch: 450, loss is 3.7916664409637453 and perplexity is 44.33021243903572
At time: 534.0189101696014 and batch: 500, loss is 3.813576831817627 and perplexity is 45.312223558467124
At time: 534.9295897483826 and batch: 550, loss is 3.773329749107361 and perplexity is 43.52475031751269
At time: 535.8298435211182 and batch: 600, loss is 3.759107508659363 and perplexity is 42.91011198048205
At time: 536.727326631546 and batch: 650, loss is 3.7959958362579345 and perplexity is 44.52255150766085
At time: 537.6481544971466 and batch: 700, loss is 3.816399621963501 and perplexity is 45.4403111537648
At time: 538.5447158813477 and batch: 750, loss is 3.7928950500488283 and perplexity is 44.384710412279205
At time: 539.4421246051788 and batch: 800, loss is 3.7591217708587648 and perplexity is 42.91072397741968
At time: 540.3393626213074 and batch: 850, loss is 3.7606858444213866 and perplexity is 42.977892020533055
At time: 541.2376132011414 and batch: 900, loss is 3.7189368486404417 and perplexity is 41.220547124033494
At time: 542.1350855827332 and batch: 950, loss is 3.8370031213760374 and perplexity is 46.38625196060648
At time: 543.0320553779602 and batch: 1000, loss is 3.800680456161499 and perplexity is 44.73161204084765
At time: 543.9296188354492 and batch: 1050, loss is 3.7437847375869753 and perplexity is 42.25762190227835
At time: 544.8267447948456 and batch: 1100, loss is 3.755286149978638 and perplexity is 42.746449956382826
At time: 545.7248284816742 and batch: 1150, loss is 3.731082172393799 and perplexity is 41.72423655822961
At time: 546.6449987888336 and batch: 1200, loss is 3.7841378450393677 and perplexity is 43.997721348333606
At time: 547.5453794002533 and batch: 1250, loss is 3.764543013572693 and perplexity is 43.14398513852398
At time: 548.4501352310181 and batch: 1300, loss is 3.770988483428955 and perplexity is 43.42296651139326
At time: 549.3467679023743 and batch: 1350, loss is 3.649868302345276 and perplexity is 38.469599359390074
At time: 550.2434124946594 and batch: 1400, loss is 3.6773573112487794 and perplexity is 39.54175931237814
At time: 551.140168428421 and batch: 1450, loss is 3.5908738279342653 and perplexity is 36.265752111945574
At time: 552.0375654697418 and batch: 1500, loss is 3.6062257528305053 and perplexity is 36.82679675332457
At time: 552.9351019859314 and batch: 1550, loss is 3.611883492469788 and perplexity is 37.03574370747013
At time: 553.8323802947998 and batch: 1600, loss is 3.703902106285095 and perplexity is 40.605442375641765
At time: 554.7290613651276 and batch: 1650, loss is 3.644163255691528 and perplexity is 38.25075335719493
At time: 555.6256608963013 and batch: 1700, loss is 3.659504942893982 and perplexity is 38.84210904870772
At time: 556.5232393741608 and batch: 1750, loss is 3.6458509302139284 and perplexity is 38.31536268352019
At time: 557.4200859069824 and batch: 1800, loss is 3.607760815620422 and perplexity is 36.88337161056203
At time: 558.3174977302551 and batch: 1850, loss is 3.6319756841659547 and perplexity is 37.787398883066835
At time: 559.2143242359161 and batch: 1900, loss is 3.717038564682007 and perplexity is 41.14237304244747
At time: 560.1110043525696 and batch: 1950, loss is 3.654828281402588 and perplexity is 38.66088175273741
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25308951444404 and perplexity of 70.32233895713769
finished 15 epochs...
Completing Train Step...
At time: 563.0486421585083 and batch: 50, loss is 3.8294180965423585 and perplexity is 46.03574208109144
At time: 563.9718537330627 and batch: 100, loss is 3.8111088275909424 and perplexity is 45.200530685139924
At time: 564.8686611652374 and batch: 150, loss is 3.784324436187744 and perplexity is 44.00593169965155
At time: 565.7660911083221 and batch: 200, loss is 3.773990626335144 and perplexity is 43.553524340843595
At time: 566.6634907722473 and batch: 250, loss is 3.7641934728622437 and perplexity is 43.128907194638174
At time: 567.5598447322845 and batch: 300, loss is 3.7771093034744263 and perplexity is 43.6895657458873
At time: 568.476122379303 and batch: 350, loss is 3.7786554288864136 and perplexity is 43.75716754068526
At time: 569.3741202354431 and batch: 400, loss is 3.744515128135681 and perplexity is 42.28849774426553
At time: 570.2705788612366 and batch: 450, loss is 3.784172477722168 and perplexity is 43.99924513384723
At time: 571.1667730808258 and batch: 500, loss is 3.806091251373291 and perplexity is 44.974301612785275
At time: 572.0620329380035 and batch: 550, loss is 3.766162576675415 and perplexity is 43.21391615852292
At time: 572.9579677581787 and batch: 600, loss is 3.7527491998672486 and perplexity is 42.63814178970257
At time: 573.8526177406311 and batch: 650, loss is 3.7895967292785646 and perplexity is 44.23855656368113
At time: 574.7496764659882 and batch: 700, loss is 3.8106088161468508 and perplexity is 45.1779355519017
At time: 575.6460983753204 and batch: 750, loss is 3.787432518005371 and perplexity is 44.14291850866381
At time: 576.5416407585144 and batch: 800, loss is 3.7537573289871218 and perplexity is 42.68114821643124
At time: 577.4377954006195 and batch: 850, loss is 3.755275330543518 and perplexity is 42.74598746644287
At time: 578.3338463306427 and batch: 900, loss is 3.7138843297958375 and perplexity is 41.01280478587968
At time: 579.230265378952 and batch: 950, loss is 3.8322395658493043 and perplexity is 46.16581392496486
At time: 580.1607663631439 and batch: 1000, loss is 3.796033573150635 and perplexity is 44.524231682111925
At time: 581.0787184238434 and batch: 1050, loss is 3.7395834922790527 and perplexity is 42.08045967810182
At time: 581.9816663265228 and batch: 1100, loss is 3.7513209867477415 and perplexity is 42.57728890199734
At time: 582.9396393299103 and batch: 1150, loss is 3.7274727392196656 and perplexity is 41.573907179761456
At time: 583.8393044471741 and batch: 1200, loss is 3.780921597480774 and perplexity is 43.85644110237289
At time: 584.7366003990173 and batch: 1250, loss is 3.7619121885299682 and perplexity is 43.03063003607954
At time: 585.6335651874542 and batch: 1300, loss is 3.7685376262664794 and perplexity is 43.31667333081028
At time: 586.5306162834167 and batch: 1350, loss is 3.6477064085006714 and perplexity is 38.38652200389947
At time: 587.4264278411865 and batch: 1400, loss is 3.6757289028167723 and perplexity is 39.47742157637048
At time: 588.3238933086395 and batch: 1450, loss is 3.590073571205139 and perplexity is 36.236741809174376
At time: 589.2211475372314 and batch: 1500, loss is 3.605739326477051 and perplexity is 36.808887584969305
At time: 590.125669002533 and batch: 1550, loss is 3.6119593000411987 and perplexity is 37.03855140367697
At time: 591.0370616912842 and batch: 1600, loss is 3.704263834953308 and perplexity is 40.62013318511778
At time: 591.933634519577 and batch: 1650, loss is 3.6447785329818725 and perplexity is 38.27429541877942
At time: 592.8334987163544 and batch: 1700, loss is 3.6602032804489135 and perplexity is 38.86924342554363
At time: 593.7340936660767 and batch: 1750, loss is 3.6468763732910157 and perplexity is 38.354673058761485
At time: 594.6301333904266 and batch: 1800, loss is 3.608942303657532 and perplexity is 36.926974626036596
At time: 595.5452485084534 and batch: 1850, loss is 3.633282790184021 and perplexity is 37.8368233140026
At time: 596.4442639350891 and batch: 1900, loss is 3.71843656539917 and perplexity is 41.199930332658894
At time: 597.3405866622925 and batch: 1950, loss is 3.655925040245056 and perplexity is 38.703306677360274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252879723837209 and perplexity of 70.3075875383827
finished 16 epochs...
Completing Train Step...
At time: 600.3325934410095 and batch: 50, loss is 3.825534906387329 and perplexity is 45.85732318211927
At time: 601.2289690971375 and batch: 100, loss is 3.8063275957107545 and perplexity is 44.98493229050359
At time: 602.1259679794312 and batch: 150, loss is 3.779357919692993 and perplexity is 43.78791734806847
At time: 603.0219602584839 and batch: 200, loss is 3.768601031303406 and perplexity is 43.319419913155016
At time: 603.9187169075012 and batch: 250, loss is 3.758620762825012 and perplexity is 42.8892307445636
At time: 604.8146238327026 and batch: 300, loss is 3.771441688537598 and perplexity is 43.442650481749695
At time: 605.7342965602875 and batch: 350, loss is 3.7730909776687622 and perplexity is 43.514359090878166
At time: 606.6308941841125 and batch: 400, loss is 3.7388757562637327 and perplexity is 42.05068835760695
At time: 607.5271761417389 and batch: 450, loss is 3.7788109970092774 and perplexity is 43.763975290622106
At time: 608.4226746559143 and batch: 500, loss is 3.8007270812988283 and perplexity is 44.73369770702387
At time: 609.3183407783508 and batch: 550, loss is 3.7610119485855105 and perplexity is 42.99190957555352
At time: 610.2521731853485 and batch: 600, loss is 3.7480688953399657 and perplexity is 42.43904857352191
At time: 611.1878049373627 and batch: 650, loss is 3.7848881578445432 and perplexity is 44.03074578984116
At time: 612.0920631885529 and batch: 700, loss is 3.806194701194763 and perplexity is 44.978954436920716
At time: 612.9926612377167 and batch: 750, loss is 3.7832393407821656 and perplexity is 43.958206962975034
At time: 613.923965215683 and batch: 800, loss is 3.749632592201233 and perplexity is 42.505462292500845
At time: 614.8486037254333 and batch: 850, loss is 3.75120934009552 and perplexity is 42.57253555558331
At time: 615.7435834407806 and batch: 900, loss is 3.7101003456115724 and perplexity is 40.85790623288159
At time: 616.6390068531036 and batch: 950, loss is 3.8285826110839842 and perplexity is 45.99729595084499
At time: 617.5344893932343 and batch: 1000, loss is 3.792488832473755 and perplexity is 44.36668422437024
At time: 618.430169582367 and batch: 1050, loss is 3.736374921798706 and perplexity is 41.945657933476284
At time: 619.3473391532898 and batch: 1100, loss is 3.7482388019561768 and perplexity is 42.44625986126566
At time: 620.2449660301208 and batch: 1150, loss is 3.7245829486846924 and perplexity is 41.45394071874884
At time: 621.1394782066345 and batch: 1200, loss is 3.7783050680160524 and perplexity is 43.74183942672364
At time: 622.0356659889221 and batch: 1250, loss is 3.7596463680267336 and perplexity is 42.93324072728894
At time: 622.9313719272614 and batch: 1300, loss is 3.7663534688949585 and perplexity is 43.22216614629777
At time: 623.8279535770416 and batch: 1350, loss is 3.6457312154769896 and perplexity is 38.31077604450544
At time: 624.7231025695801 and batch: 1400, loss is 3.674072952270508 and perplexity is 39.412103015625384
At time: 625.6188447475433 and batch: 1450, loss is 3.5889236307144166 and perplexity is 36.19509566240066
At time: 626.5140280723572 and batch: 1500, loss is 3.604780411720276 and perplexity is 36.77360791728394
At time: 627.4064717292786 and batch: 1550, loss is 3.6113351011276245 and perplexity is 37.01543919418888
At time: 628.3036942481995 and batch: 1600, loss is 3.703848819732666 and perplexity is 40.60327870925538
At time: 629.1984841823578 and batch: 1650, loss is 3.644509677886963 and perplexity is 38.26400656261968
At time: 630.0937757492065 and batch: 1700, loss is 3.6599886226654053 and perplexity is 38.86090073534699
At time: 630.9895257949829 and batch: 1750, loss is 3.6469165086746216 and perplexity is 38.35621246916999
At time: 631.8863620758057 and batch: 1800, loss is 3.60909565448761 and perplexity is 36.932637842466136
At time: 632.7821741104126 and batch: 1850, loss is 3.633563346862793 and perplexity is 37.847440176733095
At time: 633.6780216693878 and batch: 1900, loss is 3.718787865638733 and perplexity is 41.21440642063245
At time: 634.5736184120178 and batch: 1950, loss is 3.6561162757873533 and perplexity is 38.71070883295648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252908396166425 and perplexity of 70.30960344957927
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 637.5493202209473 and batch: 50, loss is 3.825270595550537 and perplexity is 45.84520419631616
At time: 638.4566328525543 and batch: 100, loss is 3.8107356595993043 and perplexity is 45.183666440676994
At time: 639.3875329494476 and batch: 150, loss is 3.7861876821517946 and perplexity is 44.08800200912814
At time: 640.3355329036713 and batch: 200, loss is 3.7757078552246095 and perplexity is 43.628379964804736
At time: 641.232670545578 and batch: 250, loss is 3.766163954734802 and perplexity is 43.21397570990677
At time: 642.1329889297485 and batch: 300, loss is 3.777209358215332 and perplexity is 43.69393731276264
At time: 643.0306522846222 and batch: 350, loss is 3.7791979122161865 and perplexity is 43.780911514406824
At time: 643.9285390377045 and batch: 400, loss is 3.7481138706207275 and perplexity is 42.44095732456976
At time: 644.8259603977203 and batch: 450, loss is 3.7902281856536866 and perplexity is 44.26650010388425
At time: 645.7356684207916 and batch: 500, loss is 3.8143260431289674 and perplexity is 45.346184709349714
At time: 646.641996383667 and batch: 550, loss is 3.7761012363433837 and perplexity is 43.64554592188593
At time: 647.540762424469 and batch: 600, loss is 3.7610595655441283 and perplexity is 42.993956768272845
At time: 648.4390907287598 and batch: 650, loss is 3.797796721458435 and perplexity is 44.60280375261022
At time: 649.3376758098602 and batch: 700, loss is 3.8157044649124146 and perplexity is 45.40873397788257
At time: 650.2644908428192 and batch: 750, loss is 3.78969313621521 and perplexity is 44.24282167299081
At time: 651.1624028682709 and batch: 800, loss is 3.753779048919678 and perplexity is 42.68207525815952
At time: 652.0599563121796 and batch: 850, loss is 3.7549901533126833 and perplexity is 42.73379902212389
At time: 652.9576342105865 and batch: 900, loss is 3.7095535373687745 and perplexity is 40.83557090009854
At time: 653.8551380634308 and batch: 950, loss is 3.827839436531067 and perplexity is 45.96312463019205
At time: 654.7526895999908 and batch: 1000, loss is 3.7915046405792237 and perplexity is 44.32304037385426
At time: 655.6496388912201 and batch: 1050, loss is 3.737127194404602 and perplexity is 41.97722437467175
At time: 656.5474226474762 and batch: 1100, loss is 3.747634644508362 and perplexity is 42.42062338225325
At time: 657.4450018405914 and batch: 1150, loss is 3.726203284263611 and perplexity is 41.521164461585016
At time: 658.3423454761505 and batch: 1200, loss is 3.7809197902679443 and perplexity is 43.85636184452149
At time: 659.2398011684418 and batch: 1250, loss is 3.759986095428467 and perplexity is 42.94782880345351
At time: 660.1373829841614 and batch: 1300, loss is 3.7644464588165283 and perplexity is 43.13981958266431
At time: 661.0358338356018 and batch: 1350, loss is 3.6436238718032836 and perplexity is 38.23012708036162
At time: 661.9652638435364 and batch: 1400, loss is 3.6723743581771853 and perplexity is 39.34521467439059
At time: 662.8760850429535 and batch: 1450, loss is 3.5839913272857666 and perplexity is 36.01701001522191
At time: 663.7856123447418 and batch: 1500, loss is 3.5981106567382812 and perplexity is 36.5291530957801
At time: 664.6814663410187 and batch: 1550, loss is 3.604828453063965 and perplexity is 36.77537461325746
At time: 665.5782544612885 and batch: 1600, loss is 3.69664746761322 and perplexity is 40.31193051164212
At time: 666.4733219146729 and batch: 1650, loss is 3.6372054624557495 and perplexity is 37.98553625704424
At time: 667.3701817989349 and batch: 1700, loss is 3.6507126903533935 and perplexity is 38.50209634586823
At time: 668.2664268016815 and batch: 1750, loss is 3.63851402759552 and perplexity is 38.03527534192445
At time: 669.1626260280609 and batch: 1800, loss is 3.600309796333313 and perplexity is 36.60957419893097
At time: 670.0587537288666 and batch: 1850, loss is 3.6232256746292113 and perplexity is 37.458201124586544
At time: 670.954731464386 and batch: 1900, loss is 3.7074886560440063 and perplexity is 40.751337288495584
At time: 671.8504536151886 and batch: 1950, loss is 3.6471898651123045 and perplexity is 38.36669881996402
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.250425258902617 and perplexity of 70.13523163741993
finished 18 epochs...
Completing Train Step...
At time: 674.8133902549744 and batch: 50, loss is 3.8237266159057617 and perplexity is 45.77447475068948
At time: 675.7211019992828 and batch: 100, loss is 3.8066148567199707 and perplexity is 44.9978565637839
At time: 676.6302201747894 and batch: 150, loss is 3.781473746299744 and perplexity is 43.88066307098209
At time: 677.5252420902252 and batch: 200, loss is 3.7696859788894654 and perplexity is 43.36644471833094
At time: 678.4205079078674 and batch: 250, loss is 3.7605945587158205 and perplexity is 42.97396893239987
At time: 679.3181800842285 and batch: 300, loss is 3.7710385084152223 and perplexity is 43.42513879903055
At time: 680.2299723625183 and batch: 350, loss is 3.7729647874832155 and perplexity is 43.50886835227649
At time: 681.1634106636047 and batch: 400, loss is 3.7419578647613525 and perplexity is 42.18049307488028
At time: 682.0603301525116 and batch: 450, loss is 3.7838298177719114 and perplexity is 43.98417093750752
At time: 682.9560570716858 and batch: 500, loss is 3.8083242845535277 and perplexity is 45.07484293482006
At time: 683.8506281375885 and batch: 550, loss is 3.769454822540283 and perplexity is 43.35642144780877
At time: 684.7454075813293 and batch: 600, loss is 3.7557192611694337 and perplexity is 42.76496793210752
At time: 685.655868768692 and batch: 650, loss is 3.792067985534668 and perplexity is 44.348016569505205
At time: 686.5536081790924 and batch: 700, loss is 3.810992431640625 and perplexity is 45.19526983259289
At time: 687.468442440033 and batch: 750, loss is 3.785545210838318 and perplexity is 44.05968582970927
At time: 688.3695447444916 and batch: 800, loss is 3.750195274353027 and perplexity is 42.52938608760163
At time: 689.2638006210327 and batch: 850, loss is 3.751154689788818 and perplexity is 42.57020901703172
At time: 690.1586713790894 and batch: 900, loss is 3.706367835998535 and perplexity is 40.70568795990302
At time: 691.0540397167206 and batch: 950, loss is 3.8251765823364257 and perplexity is 45.84089434391279
At time: 691.9491581916809 and batch: 1000, loss is 3.788794684410095 and perplexity is 44.20308948139766
At time: 692.8437933921814 and batch: 1050, loss is 3.734685878753662 and perplexity is 41.87486971068076
At time: 693.7386622428894 and batch: 1100, loss is 3.7452512836456298 and perplexity is 42.3196401162954
At time: 694.634179353714 and batch: 1150, loss is 3.7238270092010497 and perplexity is 41.42261588953627
At time: 695.5557606220245 and batch: 1200, loss is 3.7786635112762452 and perplexity is 43.75752120460047
At time: 696.4525644779205 and batch: 1250, loss is 3.7581721782684325 and perplexity is 42.86999561262213
At time: 697.3511693477631 and batch: 1300, loss is 3.7630602502822876 and perplexity is 43.08006022562792
At time: 698.2477023601532 and batch: 1350, loss is 3.6425848817825317 and perplexity is 38.1904269874046
At time: 699.1421961784363 and batch: 1400, loss is 3.6715230178833007 and perplexity is 39.31173276203955
At time: 700.0379524230957 and batch: 1450, loss is 3.584206943511963 and perplexity is 36.02477670428227
At time: 700.9335322380066 and batch: 1500, loss is 3.5989579820632933 and perplexity is 36.56011828924306
At time: 701.8403851985931 and batch: 1550, loss is 3.6060784673690796 and perplexity is 36.8213731009943
At time: 702.7701086997986 and batch: 1600, loss is 3.6980721759796142 and perplexity is 40.36940418819982
At time: 703.6868231296539 and batch: 1650, loss is 3.6391818428039553 and perplexity is 38.06068436057503
At time: 704.5820970535278 and batch: 1700, loss is 3.6531099033355714 and perplexity is 38.5945047881753
At time: 705.4781632423401 and batch: 1750, loss is 3.641072292327881 and perplexity is 38.132704216707424
At time: 706.3739445209503 and batch: 1800, loss is 3.6033812808990477 and perplexity is 36.72219280566016
At time: 707.2697126865387 and batch: 1850, loss is 3.625901584625244 and perplexity is 37.558570128729
At time: 708.1644895076752 and batch: 1900, loss is 3.709960675239563 and perplexity is 40.852199992424154
At time: 709.0607831478119 and batch: 1950, loss is 3.649252662658691 and perplexity is 38.44592323602579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249802132539971 and perplexity of 70.09154213908916
finished 19 epochs...
Completing Train Step...
At time: 712.0531041622162 and batch: 50, loss is 3.822773284912109 and perplexity is 45.73085731941947
At time: 712.9854748249054 and batch: 100, loss is 3.8046836137771605 and perplexity is 44.91103863109714
At time: 713.8813865184784 and batch: 150, loss is 3.779260516166687 and perplexity is 43.7836524582202
At time: 714.777181148529 and batch: 200, loss is 3.7669188833236693 and perplexity is 43.24661149290162
At time: 715.6729989051819 and batch: 250, loss is 3.757851004600525 and perplexity is 42.85622910972549
At time: 716.568510055542 and batch: 300, loss is 3.76797598361969 and perplexity is 43.292351670430854
At time: 717.4647200107574 and batch: 350, loss is 3.7697595310211183 and perplexity is 43.36963453008946
At time: 718.3847372531891 and batch: 400, loss is 3.7385766458511354 and perplexity is 42.03811243975006
At time: 719.2809841632843 and batch: 450, loss is 3.780499930381775 and perplexity is 43.837952182439395
At time: 720.1770629882812 and batch: 500, loss is 3.8050824785232544 and perplexity is 44.92895563411044
At time: 721.0888769626617 and batch: 550, loss is 3.7661151027679445 and perplexity is 43.21186467376216
At time: 721.993008852005 and batch: 600, loss is 3.7529078578948973 and perplexity is 42.64490720986145
At time: 722.8973469734192 and batch: 650, loss is 3.789253177642822 and perplexity is 44.22336094559998
At time: 723.8048000335693 and batch: 700, loss is 3.8086471223831175 and perplexity is 45.08939714848121
At time: 724.6998429298401 and batch: 750, loss is 3.7834982681274414 and perplexity is 43.9695904184874
At time: 725.595947265625 and batch: 800, loss is 3.7483247995376585 and perplexity is 42.44991029391861
At time: 726.4919707775116 and batch: 850, loss is 3.7492114067077638 and perplexity is 42.4875633780362
At time: 727.3877069950104 and batch: 900, loss is 3.7046838712692263 and perplexity is 40.63719870003007
At time: 728.2836220264435 and batch: 950, loss is 3.8237128353118894 and perplexity is 45.7738439555896
At time: 729.1782627105713 and batch: 1000, loss is 3.7873718690872193 and perplexity is 44.14024136959582
At time: 730.0718522071838 and batch: 1050, loss is 3.73344048500061 and perplexity is 41.822751470135124
At time: 730.9774553775787 and batch: 1100, loss is 3.744074764251709 and perplexity is 42.269879516849855
At time: 731.8834135532379 and batch: 1150, loss is 3.7227546262741087 and perplexity is 41.37821879306596
At time: 732.7768783569336 and batch: 1200, loss is 3.777576036453247 and perplexity is 43.709961866452055
At time: 733.6727049350739 and batch: 1250, loss is 3.7573702192306517 and perplexity is 42.835629414174534
At time: 734.5674707889557 and batch: 1300, loss is 3.762444620132446 and perplexity is 43.0535470037028
At time: 735.4614315032959 and batch: 1350, loss is 3.642180895805359 and perplexity is 38.175001706447844
At time: 736.3553757667542 and batch: 1400, loss is 3.6712234449386596 and perplexity is 39.299957794316015
At time: 737.2511305809021 and batch: 1450, loss is 3.5843320417404176 and perplexity is 36.02928362192628
At time: 738.1459300518036 and batch: 1500, loss is 3.5993942785263062 and perplexity is 36.576072819739515
At time: 739.0416119098663 and batch: 1550, loss is 3.6067778158187864 and perplexity is 36.847133077738555
At time: 739.9367253780365 and batch: 1600, loss is 3.6988452768325804 and perplexity is 40.40062587621321
At time: 740.831161737442 and batch: 1650, loss is 3.640198941230774 and perplexity is 38.09941551612159
At time: 741.7254679203033 and batch: 1700, loss is 3.6542859745025633 and perplexity is 38.63992137379462
At time: 742.6205298900604 and batch: 1750, loss is 3.6423180055618287 and perplexity is 38.180236230479004
At time: 743.5151529312134 and batch: 1800, loss is 3.6048305654525756 and perplexity is 36.775452297222
At time: 744.4095838069916 and batch: 1850, loss is 3.6271723079681397 and perplexity is 37.60632701698747
At time: 745.3039033412933 and batch: 1900, loss is 3.7110774326324463 and perplexity is 40.897847472617634
At time: 746.1983325481415 and batch: 1950, loss is 3.650132098197937 and perplexity is 38.4797488187884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249544081577035 and perplexity of 70.07345728265418
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd6b01ccb38>
ELAPSED
4629.509411811829


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.68864018758501}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.09000677972055571, 'batch_size': 32, 'rnn_dropout': 0.41910426663286526, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.83039238142784}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6648606163334299, 'batch_size': 32, 'rnn_dropout': 0.9502082500073664, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.91276638644534}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.3455001633105624, 'batch_size': 32, 'rnn_dropout': 0.5106234852565553, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.07345728265418}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.7493578010911, 'batch_size': 32, 'rnn_dropout': 0.9176254272065102, 'tie_weights': 'FALSE'}, 'best_accuracy': -71.32171523625018}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.48394944989088384, 'batch_size': 32, 'rnn_dropout': 0.5901502502469885, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.647361986067}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6169874406979039, 'batch_size': 32, 'rnn_dropout': 0.7507289746383731, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.68864018758501}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.09000677972055571, 'batch_size': 32, 'rnn_dropout': 0.41910426663286526, 'tie_weights': 'FALSE'}, 'best_accuracy': -69.83039238142784}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.6648606163334299, 'batch_size': 32, 'rnn_dropout': 0.9502082500073664, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.91276638644534}, {'params': {'num_layers': 2, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'wordvec_source': 'glove', 'wordvec_dim': 300, 'dropout': 0.3455001633105624, 'batch_size': 32, 'rnn_dropout': 0.5106234852565553, 'tie_weights': 'FALSE'}, 'best_accuracy': -70.07345728265418}]
