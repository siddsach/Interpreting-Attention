TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.2005960941314697 and batch: 50, loss is 7.712119827270508 and perplexity is 2235.2756376935454
At time: 3.7339463233947754 and batch: 100, loss is 6.800751600265503 and perplexity is 898.5223675750461
At time: 5.261438846588135 and batch: 150, loss is 6.490023756027222 and perplexity is 658.5390072999834
At time: 6.797811031341553 and batch: 200, loss is 6.295947465896607 and perplexity is 542.3694796149864
At time: 8.333623170852661 and batch: 250, loss is 6.196451950073242 and perplexity is 491.00384075387393
At time: 9.866124868392944 and batch: 300, loss is 6.116938333511353 and perplexity is 453.4741802391638
At time: 11.400424242019653 and batch: 350, loss is 6.0594752979278566 and perplexity is 428.150726338105
At time: 12.931937456130981 and batch: 400, loss is 6.008168144226074 and perplexity is 406.73755287858114
At time: 14.462564468383789 and batch: 450, loss is 5.932587547302246 and perplexity is 377.12909176170416
At time: 15.995929718017578 and batch: 500, loss is 5.905449256896973 and perplexity is 367.0320804471987
At time: 17.528483629226685 and batch: 550, loss is 5.851991472244262 and perplexity is 347.9265771261483
At time: 19.06156587600708 and batch: 600, loss is 5.890529413223266 and perplexity is 361.5966677647703
At time: 20.590271949768066 and batch: 650, loss is 5.964633235931396 and perplexity is 389.4101802146599
At time: 22.118916511535645 and batch: 700, loss is 5.865640411376953 and perplexity is 352.7079619872628
At time: 23.646214246749878 and batch: 750, loss is 5.8077157497406 and perplexity is 332.8579258166737
At time: 25.17651057243347 and batch: 800, loss is 5.809445962905884 and perplexity is 333.43433949756263
At time: 26.705526113510132 and batch: 850, loss is 5.835731840133667 and perplexity is 342.3151623765367
At time: 28.235366821289062 and batch: 900, loss is 5.828355369567871 and perplexity is 339.79937488072227
At time: 29.765284538269043 and batch: 950, loss is 5.849501495361328 and perplexity is 347.0613256672564
At time: 31.29426407814026 and batch: 1000, loss is 5.824196672439575 and perplexity is 338.3891865017954
At time: 32.82655644416809 and batch: 1050, loss is 5.719186191558838 and perplexity is 304.65688969632396
At time: 34.35506534576416 and batch: 1100, loss is 5.803755559921265 and perplexity is 331.54235192808574
At time: 35.88406705856323 and batch: 1150, loss is 5.711632289886475 and perplexity is 302.36421174161467
At time: 37.41700506210327 and batch: 1200, loss is 5.796297674179077 and perplexity is 329.07894427302006
At time: 38.95774221420288 and batch: 1250, loss is 5.7217940330505375 and perplexity is 305.4524234360956
At time: 40.48776936531067 and batch: 1300, loss is 5.737897300720215 and perplexity is 310.4110232481513
At time: 42.01622796058655 and batch: 1350, loss is 5.717711582183838 and perplexity is 304.2079708619271
At time: 43.54668736457825 and batch: 1400, loss is 5.735819272994995 and perplexity is 309.7666502799519
At time: 45.07816457748413 and batch: 1450, loss is 5.707091283798218 and perplexity is 300.9942867880733
At time: 46.6106379032135 and batch: 1500, loss is 5.684637594223022 and perplexity is 294.3111656546775
At time: 48.14217805862427 and batch: 1550, loss is 5.664056425094604 and perplexity is 288.31580516902574
At time: 49.671802282333374 and batch: 1600, loss is 5.682400035858154 and perplexity is 293.6533634539508
At time: 51.20166254043579 and batch: 1650, loss is 5.655483407974243 and perplexity is 285.8546337415965
At time: 52.7323100566864 and batch: 1700, loss is 5.6654086017608645 and perplexity is 288.70592276780604
At time: 54.26441931724548 and batch: 1750, loss is 5.671517305374145 and perplexity is 290.47493937939
At time: 55.79391860961914 and batch: 1800, loss is 5.686059494018554 and perplexity is 294.7299443010233
At time: 57.32606601715088 and batch: 1850, loss is 5.6421707820892335 and perplexity is 282.0743763511214
At time: 58.855002880096436 and batch: 1900, loss is 5.628753604888916 and perplexity is 278.31501089298575
At time: 60.38401985168457 and batch: 1950, loss is 5.561650943756104 and perplexity is 260.25214349575907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.107000590479651 and perplexity of 165.17418611271464
finished 1 epochs...
Completing Train Step...
At time: 64.45814990997314 and batch: 50, loss is 5.383425207138061 and perplexity is 217.7668961840274
At time: 65.77087211608887 and batch: 100, loss is 5.314184942245483 and perplexity is 203.19882683654964
At time: 67.08747291564941 and batch: 150, loss is 5.220567111968994 and perplexity is 185.03909220446354
At time: 68.39846062660217 and batch: 200, loss is 5.181319160461426 and perplexity is 177.91735780072628
At time: 69.7539963722229 and batch: 250, loss is 5.174682159423828 and perplexity is 176.740430067969
At time: 71.07875037193298 and batch: 300, loss is 5.1683846378326415 and perplexity is 175.63090070302547
At time: 72.40428733825684 and batch: 350, loss is 5.136591863632202 and perplexity is 170.1349360427727
At time: 73.73209547996521 and batch: 400, loss is 5.100930242538452 and perplexity is 164.17455844559677
At time: 75.06852102279663 and batch: 450, loss is 5.0540117835998535 and perplexity is 156.64965007587972
At time: 76.40824127197266 and batch: 500, loss is 5.039846611022949 and perplexity is 154.44632284540714
At time: 77.73808312416077 and batch: 550, loss is 4.98661922454834 and perplexity is 146.44050321209545
At time: 79.06683588027954 and batch: 600, loss is 4.976067590713501 and perplexity is 144.90344016779363
At time: 80.39517188072205 and batch: 650, loss is 5.040166931152344 and perplexity is 154.4958030358529
At time: 81.7235631942749 and batch: 700, loss is 5.028051319122315 and perplexity is 152.63528524032222
At time: 83.04221105575562 and batch: 750, loss is 4.976268949508667 and perplexity is 144.93262068769988
At time: 84.35787558555603 and batch: 800, loss is 4.96483699798584 and perplexity is 143.28519259472904
At time: 85.67405438423157 and batch: 850, loss is 4.948001337051392 and perplexity is 140.89308453659137
At time: 86.99327087402344 and batch: 900, loss is 4.956104001998901 and perplexity is 142.03933155053986
At time: 88.31289291381836 and batch: 950, loss is 5.016521005630493 and perplexity is 150.8854599549262
At time: 89.6330201625824 and batch: 1000, loss is 4.977011108398438 and perplexity is 145.0402236448676
At time: 90.95298051834106 and batch: 1050, loss is 4.884177207946777 and perplexity is 132.18166255786863
At time: 92.27381706237793 and batch: 1100, loss is 4.962415189743042 and perplexity is 142.93860319017065
At time: 93.598313331604 and batch: 1150, loss is 4.867189912796021 and perplexity is 129.95521781927386
At time: 94.92191958427429 and batch: 1200, loss is 4.953086223602295 and perplexity is 141.61133444933472
At time: 96.24401497840881 and batch: 1250, loss is 4.894258050918579 and perplexity is 133.52090414242
At time: 97.56358504295349 and batch: 1300, loss is 4.9278161907196045 and perplexity is 138.07764760416842
At time: 98.88477897644043 and batch: 1350, loss is 4.837566871643066 and perplexity is 126.16200961716733
At time: 100.2067494392395 and batch: 1400, loss is 4.855238380432129 and perplexity is 128.41129830728997
At time: 101.53072166442871 and batch: 1450, loss is 4.792410850524902 and perplexity is 120.59174716994652
At time: 102.8532555103302 and batch: 1500, loss is 4.7689767169952395 and perplexity is 117.79863892048245
At time: 104.1747374534607 and batch: 1550, loss is 4.764970207214356 and perplexity is 117.32762171905357
At time: 105.49437880516052 and batch: 1600, loss is 4.83073130607605 and perplexity is 125.30256168119126
At time: 106.81385231018066 and batch: 1650, loss is 4.784640426635742 and perplexity is 119.6583293993756
At time: 108.13556742668152 and batch: 1700, loss is 4.811401853561401 and perplexity is 122.90378992443337
At time: 109.45612382888794 and batch: 1750, loss is 4.821965551376342 and perplexity is 124.20899015447714
At time: 110.77894234657288 and batch: 1800, loss is 4.7721155166625975 and perplexity is 118.16896613657207
At time: 112.10017538070679 and batch: 1850, loss is 4.77746503829956 and perplexity is 118.80280744004837
At time: 113.42298340797424 and batch: 1900, loss is 4.847310028076172 and perplexity is 127.3972335311522
At time: 114.7613275051117 and batch: 1950, loss is 4.759966325759888 and perplexity is 116.74199463484062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.636044524436773 and perplexity of 103.13558939616048
finished 2 epochs...
Completing Train Step...
At time: 118.83374190330505 and batch: 50, loss is 4.7148834991455075 and perplexity is 111.59580940921046
At time: 120.14950895309448 and batch: 100, loss is 4.650617294311523 and perplexity is 104.64956522405534
At time: 121.46707820892334 and batch: 150, loss is 4.601748123168945 and perplexity is 99.65837857645137
At time: 122.7841227054596 and batch: 200, loss is 4.593122997283936 and perplexity is 98.80250881382764
At time: 124.10253500938416 and batch: 250, loss is 4.600766763687134 and perplexity is 99.5606258548188
At time: 125.42128896713257 and batch: 300, loss is 4.61070704460144 and perplexity is 100.55522153446022
At time: 126.73650908470154 and batch: 350, loss is 4.621323595046997 and perplexity is 101.628458070902
At time: 128.05301189422607 and batch: 400, loss is 4.589765253067017 and perplexity is 98.47131161016063
At time: 129.3712067604065 and batch: 450, loss is 4.581715364456176 and perplexity is 97.68181048175434
At time: 130.69032168388367 and batch: 500, loss is 4.59079363822937 and perplexity is 98.57263013424208
At time: 132.00656414031982 and batch: 550, loss is 4.545092535018921 and perplexity is 94.16914074946783
At time: 133.32146549224854 and batch: 600, loss is 4.521557235717774 and perplexity is 91.97871905919898
At time: 134.6371247768402 and batch: 650, loss is 4.58176908493042 and perplexity is 97.68705813589033
At time: 135.96643495559692 and batch: 700, loss is 4.604863567352295 and perplexity is 99.96934283668934
At time: 137.28543639183044 and batch: 750, loss is 4.567811288833618 and perplexity is 96.33303367830155
At time: 138.6121678352356 and batch: 800, loss is 4.541411170959472 and perplexity is 93.82310718776216
At time: 139.93532848358154 and batch: 850, loss is 4.534696798324585 and perplexity is 93.19525406303988
At time: 141.26305675506592 and batch: 900, loss is 4.523196229934692 and perplexity is 92.1295952566492
At time: 142.62000346183777 and batch: 950, loss is 4.605441722869873 and perplexity is 100.0271573751258
At time: 143.95172238349915 and batch: 1000, loss is 4.57659764289856 and perplexity is 97.18317919082523
At time: 145.2738585472107 and batch: 1050, loss is 4.507024164199829 and perplexity is 90.65165229251467
At time: 146.59404349327087 and batch: 1100, loss is 4.570746402740479 and perplexity is 96.61619746083336
At time: 147.9134271144867 and batch: 1150, loss is 4.499324932098388 and perplexity is 89.95638413112472
At time: 149.23333835601807 and batch: 1200, loss is 4.582150068283081 and perplexity is 97.72428236926693
At time: 150.56305027008057 and batch: 1250, loss is 4.537899589538574 and perplexity is 93.49421750712375
At time: 151.89367723464966 and batch: 1300, loss is 4.556896800994873 and perplexity is 95.28732502186449
At time: 153.21394276618958 and batch: 1350, loss is 4.442281055450439 and perplexity is 84.96853873546617
At time: 154.52957010269165 and batch: 1400, loss is 4.472740726470947 and perplexity is 87.596472290139
At time: 155.84292459487915 and batch: 1450, loss is 4.402146377563477 and perplexity is 81.62588073579825
At time: 157.163316488266 and batch: 1500, loss is 4.400235824584961 and perplexity is 81.47007904731691
At time: 158.47980761528015 and batch: 1550, loss is 4.4027565574646 and perplexity is 81.67570240617988
At time: 159.80078220367432 and batch: 1600, loss is 4.488501005172729 and perplexity is 88.98795336957426
At time: 161.1188588142395 and batch: 1650, loss is 4.443390598297119 and perplexity is 85.06286729092274
At time: 162.43427801132202 and batch: 1700, loss is 4.476945486068725 and perplexity is 87.96556983715548
At time: 163.75118470191956 and batch: 1750, loss is 4.482350654602051 and perplexity is 88.4423258799001
At time: 165.06927609443665 and batch: 1800, loss is 4.427801485061646 and perplexity is 83.74709512773332
At time: 166.397794008255 and batch: 1850, loss is 4.461363668441773 and perplexity is 86.60552983538103
At time: 167.71830654144287 and batch: 1900, loss is 4.531148357391357 and perplexity is 92.86514224626328
At time: 169.03732705116272 and batch: 1950, loss is 4.457443952560425 and perplexity is 86.26672520740087
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499777150708575 and perplexity of 89.99707328163606
finished 3 epochs...
Completing Train Step...
At time: 173.03451132774353 and batch: 50, loss is 4.412647504806518 and perplexity is 82.48756088379695
At time: 174.36471724510193 and batch: 100, loss is 4.355939245223999 and perplexity is 77.93999573772928
At time: 175.67813062667847 and batch: 150, loss is 4.311474275588989 and perplexity is 74.55031567356629
At time: 176.99257373809814 and batch: 200, loss is 4.318557157516479 and perplexity is 75.08022117085245
At time: 178.3207015991211 and batch: 250, loss is 4.317216310501099 and perplexity is 74.97961754249151
At time: 179.63842606544495 and batch: 300, loss is 4.338934850692749 and perplexity is 76.62587785446567
At time: 180.95382142066956 and batch: 350, loss is 4.349554748535156 and perplexity is 77.44397320501855
At time: 182.2691526412964 and batch: 400, loss is 4.320257349014282 and perplexity is 75.20798050142847
At time: 183.58792924880981 and batch: 450, loss is 4.3285455226898195 and perplexity is 75.83390761883292
At time: 184.90944814682007 and batch: 500, loss is 4.3451621627807615 and perplexity is 77.10453995216483
At time: 186.2320113182068 and batch: 550, loss is 4.300468196868897 and perplexity is 73.73430779130864
At time: 187.55218172073364 and batch: 600, loss is 4.27674901008606 and perplexity is 72.0059684044006
At time: 188.87024211883545 and batch: 650, loss is 4.332941617965698 and perplexity is 76.16801454674182
At time: 190.18851923942566 and batch: 700, loss is 4.368493900299073 and perplexity is 78.92467371328169
At time: 191.5109052658081 and batch: 750, loss is 4.332032804489136 and perplexity is 76.0988234742906
At time: 192.83428239822388 and batch: 800, loss is 4.3044949674606325 and perplexity is 74.03181753325751
At time: 194.15345549583435 and batch: 850, loss is 4.295315599441528 and perplexity is 73.35536170338767
At time: 195.4725856781006 and batch: 900, loss is 4.277247829437256 and perplexity is 72.0418953346214
At time: 196.7917721271515 and batch: 950, loss is 4.365629568099975 and perplexity is 78.6989306849144
At time: 198.11090326309204 and batch: 1000, loss is 4.346164693832398 and perplexity is 77.18187840831335
At time: 199.4330620765686 and batch: 1050, loss is 4.289058256149292 and perplexity is 72.89778512276546
At time: 200.8008828163147 and batch: 1100, loss is 4.342959022521972 and perplexity is 76.93485482476373
At time: 202.1198091506958 and batch: 1150, loss is 4.280236473083496 and perplexity is 72.25752494691159
At time: 203.43466711044312 and batch: 1200, loss is 4.356178297996521 and perplexity is 77.95862973696659
At time: 204.7515754699707 and batch: 1250, loss is 4.326341581344605 and perplexity is 75.66695817543078
At time: 206.0801820755005 and batch: 1300, loss is 4.3339866065979 and perplexity is 76.24765085835382
At time: 207.3995418548584 and batch: 1350, loss is 4.211951270103454 and perplexity is 67.4880989244614
At time: 208.71997499465942 and batch: 1400, loss is 4.252670331001282 and perplexity is 70.292867174464
At time: 210.03839564323425 and batch: 1450, loss is 4.179449472427368 and perplexity is 65.32987741325077
At time: 211.35556054115295 and batch: 1500, loss is 4.18041428565979 and perplexity is 65.39293895986707
At time: 212.6725733280182 and batch: 1550, loss is 4.1873010683059695 and perplexity is 65.84484020384649
At time: 213.99265480041504 and batch: 1600, loss is 4.278874545097351 and perplexity is 72.15918238442173
At time: 215.31192135810852 and batch: 1650, loss is 4.232982840538025 and perplexity is 68.92251072402331
At time: 216.62897777557373 and batch: 1700, loss is 4.262977719306946 and perplexity is 71.02114995037797
At time: 217.94386506080627 and batch: 1750, loss is 4.27214015007019 and perplexity is 71.67486656283096
At time: 219.26257038116455 and batch: 1800, loss is 4.210838055610656 and perplexity is 67.41301199632989
At time: 220.58283615112305 and batch: 1850, loss is 4.249175958633423 and perplexity is 70.04766638269243
At time: 221.90191459655762 and batch: 1900, loss is 4.32504771232605 and perplexity is 75.56911835212685
At time: 223.219961643219 and batch: 1950, loss is 4.255285482406617 and perplexity is 70.47693424156179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.45894775390625 and perplexity of 86.39655081636455
finished 4 epochs...
Completing Train Step...
At time: 227.23838233947754 and batch: 50, loss is 4.216151342391968 and perplexity is 67.77214991834326
At time: 228.59352564811707 and batch: 100, loss is 4.166829471588135 and perplexity is 64.51059485229001
At time: 229.9096462726593 and batch: 150, loss is 4.127725687026977 and perplexity is 62.036671563792616
At time: 231.22661232948303 and batch: 200, loss is 4.132879886627197 and perplexity is 62.35724639520677
At time: 232.541832447052 and batch: 250, loss is 4.131166825294494 and perplexity is 62.25051605150644
At time: 233.89217138290405 and batch: 300, loss is 4.15280595779419 and perplexity is 63.61224338001068
At time: 235.20901560783386 and batch: 350, loss is 4.163325815200806 and perplexity is 64.28496738595169
At time: 236.5251305103302 and batch: 400, loss is 4.136641550064087 and perplexity is 62.59225510371323
At time: 237.8412525653839 and batch: 450, loss is 4.147508492469788 and perplexity is 63.27615073205602
At time: 239.15750908851624 and batch: 500, loss is 4.164306998252869 and perplexity is 64.34807366079406
At time: 240.47374320030212 and batch: 550, loss is 4.124839096069336 and perplexity is 61.857855277516094
At time: 241.79398608207703 and batch: 600, loss is 4.1028095149993895 and perplexity is 60.51005290785893
At time: 243.11245465278625 and batch: 650, loss is 4.159373202323914 and perplexity is 64.03137530189863
At time: 244.42981886863708 and batch: 700, loss is 4.1924821424484255 and perplexity is 66.18687248503231
At time: 245.74722290039062 and batch: 750, loss is 4.157691507339478 and perplexity is 63.923784551975594
At time: 247.06396293640137 and batch: 800, loss is 4.129601702690125 and perplexity is 62.1531625666436
At time: 248.38289523124695 and batch: 850, loss is 4.126396417617798 and perplexity is 61.95426289782929
At time: 249.7023253440857 and batch: 900, loss is 4.104019246101379 and perplexity is 60.58329809540278
At time: 251.02015471458435 and batch: 950, loss is 4.198990893363953 and perplexity is 66.61907136353902
At time: 252.33706784248352 and batch: 1000, loss is 4.177632160186768 and perplexity is 65.21126044203322
At time: 253.65322589874268 and batch: 1050, loss is 4.130542340278626 and perplexity is 62.21165367275176
At time: 254.97065210342407 and batch: 1100, loss is 4.172634687423706 and perplexity is 64.88618190625563
At time: 256.2888071537018 and batch: 1150, loss is 4.119116477966308 and perplexity is 61.50487733735248
At time: 257.6093726158142 and batch: 1200, loss is 4.195694522857666 and perplexity is 66.39983176753157
At time: 258.9317350387573 and batch: 1250, loss is 4.169858078956604 and perplexity is 64.70626827462112
At time: 260.2503595352173 and batch: 1300, loss is 4.1725757122039795 and perplexity is 64.88235534225784
At time: 261.5689470767975 and batch: 1350, loss is 4.051813411712646 and perplexity is 57.50163669808044
At time: 262.88807916641235 and batch: 1400, loss is 4.090945534706115 and perplexity is 59.79640455831316
At time: 264.205842256546 and batch: 1450, loss is 4.018146214485168 and perplexity is 55.59794357354242
At time: 265.52319264411926 and batch: 1500, loss is 4.021399297714233 and perplexity is 55.779102814636
At time: 266.8388111591339 and batch: 1550, loss is 4.029664611816406 and perplexity is 56.24204516620447
At time: 268.1539845466614 and batch: 1600, loss is 4.1224986267089845 and perplexity is 61.71324815282502
At time: 269.4717619419098 and batch: 1650, loss is 4.07529426574707 and perplexity is 58.867800817233224
At time: 270.7882604598999 and batch: 1700, loss is 4.108686423301696 and perplexity is 60.8667119398542
At time: 272.1041934490204 and batch: 1750, loss is 4.115144748687744 and perplexity is 61.26108108210265
At time: 273.4177830219269 and batch: 1800, loss is 4.056785016059876 and perplexity is 57.78822389384143
At time: 274.7334728240967 and batch: 1850, loss is 4.096360874176026 and perplexity is 60.12110076466714
At time: 276.0493588447571 and batch: 1900, loss is 4.173382105827332 and perplexity is 64.93469716109203
At time: 277.36635541915894 and batch: 1950, loss is 4.100773077011109 and perplexity is 60.38695332232263
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4563425463299415 and perplexity of 86.17176280446505
finished 5 epochs...
Completing Train Step...
At time: 281.3245267868042 and batch: 50, loss is 4.070587902069092 and perplexity is 58.591398472830875
At time: 282.6653964519501 and batch: 100, loss is 4.0255310916900635 and perplexity is 56.01004735470077
At time: 283.98463129997253 and batch: 150, loss is 3.988489270210266 and perplexity is 53.97328868549187
At time: 285.30215978622437 and batch: 200, loss is 3.9968610620498657 and perplexity is 54.427038522700805
At time: 286.61735439300537 and batch: 250, loss is 3.9905799055099487 and perplexity is 54.08624518233543
At time: 287.92963123321533 and batch: 300, loss is 4.008848037719726 and perplexity is 55.08338002507335
At time: 289.2462224960327 and batch: 350, loss is 4.020986027717591 and perplexity is 55.75605574766172
At time: 290.56527948379517 and batch: 400, loss is 3.9950688028335573 and perplexity is 54.32957852417077
At time: 291.8855257034302 and batch: 450, loss is 4.01028802394867 and perplexity is 55.162756470531306
At time: 293.21017813682556 and batch: 500, loss is 4.028713679313659 and perplexity is 56.188588198447356
At time: 294.53636479377747 and batch: 550, loss is 3.9947106981277467 and perplexity is 54.310126329605644
At time: 295.8669605255127 and batch: 600, loss is 3.971259536743164 and perplexity is 53.05130884893796
At time: 297.19247555732727 and batch: 650, loss is 4.024468836784362 and perplexity is 55.950581996405624
At time: 298.51881670951843 and batch: 700, loss is 4.0593247222900395 and perplexity is 57.935175534105056
At time: 299.87436056137085 and batch: 750, loss is 4.02534053325653 and perplexity is 55.99937518468303
At time: 301.2113287448883 and batch: 800, loss is 3.9958960437774658 and perplexity is 54.37454077073283
At time: 302.5490708351135 and batch: 850, loss is 3.99404390335083 and perplexity is 54.27392469190817
At time: 303.8874225616455 and batch: 900, loss is 3.972501640319824 and perplexity is 53.11724501069959
At time: 305.2329535484314 and batch: 950, loss is 4.0705913543701175 and perplexity is 58.59160074832507
At time: 306.569118976593 and batch: 1000, loss is 4.053670678138733 and perplexity is 57.60853179297292
At time: 307.8936593532562 and batch: 1050, loss is 4.006378684043884 and perplexity is 54.947527481152406
At time: 309.2239582538605 and batch: 1100, loss is 4.040955553054809 and perplexity is 56.880669342741044
At time: 310.55280780792236 and batch: 1150, loss is 3.995933713912964 and perplexity is 54.37658910563159
At time: 311.8817250728607 and batch: 1200, loss is 4.064364361763 and perplexity is 58.22788488688558
At time: 313.19995307922363 and batch: 1250, loss is 4.043268690109253 and perplexity is 57.01239441702039
At time: 314.51842737197876 and batch: 1300, loss is 4.044849429130554 and perplexity is 57.10258740057679
At time: 315.8338906764984 and batch: 1350, loss is 3.921805601119995 and perplexity is 50.49153008472455
At time: 317.150351524353 and batch: 1400, loss is 3.9705237531661988 and perplexity is 53.01228892402074
At time: 318.47069787979126 and batch: 1450, loss is 3.8950222873687745 and perplexity is 49.15714893398134
At time: 319.8008563518524 and batch: 1500, loss is 3.898329539299011 and perplexity is 49.31999314466191
At time: 321.13050079345703 and batch: 1550, loss is 3.9046449041366578 and perplexity is 49.63245250408079
At time: 322.468768119812 and batch: 1600, loss is 4.004236154556274 and perplexity is 54.82992680969243
At time: 323.8002681732178 and batch: 1650, loss is 3.951965789794922 and perplexity is 52.03756126242289
At time: 325.1323730945587 and batch: 1700, loss is 3.9873572158813477 and perplexity is 53.91222256199582
At time: 326.4757640361786 and batch: 1750, loss is 3.9932221031188964 and perplexity is 54.22934069008909
At time: 327.8076968193054 and batch: 1800, loss is 3.9347669219970705 and perplexity is 51.150226574512914
At time: 329.13244104385376 and batch: 1850, loss is 3.976375393867493 and perplexity is 53.32340717991421
At time: 330.45597672462463 and batch: 1900, loss is 4.053705220222473 and perplexity is 57.61052174607061
At time: 331.80186009407043 and batch: 1950, loss is 3.983197546005249 and perplexity is 53.688431285452495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.452091660610465 and perplexity of 85.80623394965818
finished 6 epochs...
Completing Train Step...
At time: 335.93708515167236 and batch: 50, loss is 3.9538432645797728 and perplexity is 52.13535224288284
At time: 337.2582473754883 and batch: 100, loss is 3.9101440858840943 and perplexity is 49.90614222601284
At time: 338.5969612598419 and batch: 150, loss is 3.8752864360809327 and perplexity is 48.1965015311447
At time: 339.91789650917053 and batch: 200, loss is 3.8845276832580566 and perplexity is 48.64396167531938
At time: 341.23683404922485 and batch: 250, loss is 3.874058680534363 and perplexity is 48.137364319512905
At time: 342.5551483631134 and batch: 300, loss is 3.891933569908142 and perplexity is 49.00555063243737
At time: 343.87102246284485 and batch: 350, loss is 3.905676941871643 and perplexity is 49.68370150884948
At time: 345.18882608413696 and batch: 400, loss is 3.8820801305770876 and perplexity is 48.52504859888005
At time: 346.5112044811249 and batch: 450, loss is 3.900468626022339 and perplexity is 49.42560580424031
At time: 347.8309323787689 and batch: 500, loss is 3.9231694459915163 and perplexity is 50.5604396794031
At time: 349.14983892440796 and batch: 550, loss is 3.8935893678665163 and perplexity is 49.086761138664436
At time: 350.4655442237854 and batch: 600, loss is 3.8619326066970827 and perplexity is 47.55717192271812
At time: 351.782830953598 and batch: 650, loss is 3.9152562046051025 and perplexity is 50.161921580152715
At time: 353.1189694404602 and batch: 700, loss is 3.9545297050476074 and perplexity is 52.17115234438063
At time: 354.4433116912842 and batch: 750, loss is 3.919735999107361 and perplexity is 50.387140771866704
At time: 355.76101636886597 and batch: 800, loss is 3.8865790033340453 and perplexity is 48.74384842530113
At time: 357.07887959480286 and batch: 850, loss is 3.884237108230591 and perplexity is 48.62982900821903
At time: 358.39502930641174 and batch: 900, loss is 3.8608955335617066 and perplexity is 47.5078772228452
At time: 359.7120840549469 and batch: 950, loss is 3.9651131296157835 and perplexity is 52.72623395084526
At time: 361.0316324234009 and batch: 1000, loss is 3.9419006586074827 and perplexity is 51.516423441472014
At time: 362.3490388393402 and batch: 1050, loss is 3.8981739234924317 and perplexity is 49.3123187712906
At time: 363.66719698905945 and batch: 1100, loss is 3.9305284643173217 and perplexity is 50.933887300165914
At time: 365.07392740249634 and batch: 1150, loss is 3.8966519975662233 and perplexity is 49.237326155949084
At time: 366.3976466655731 and batch: 1200, loss is 3.961962356567383 and perplexity is 52.560366995753675
At time: 367.7199676036835 and batch: 1250, loss is 3.935569877624512 and perplexity is 51.19131443044082
At time: 369.03754925727844 and batch: 1300, loss is 3.944290752410889 and perplexity is 51.639699788244215
At time: 370.35548996925354 and batch: 1350, loss is 3.8142320489883423 and perplexity is 45.34192263399553
At time: 371.6716396808624 and batch: 1400, loss is 3.868460865020752 and perplexity is 47.86865303452473
At time: 372.98955392837524 and batch: 1450, loss is 3.7919552373886107 and perplexity is 44.343016694724284
At time: 374.3062300682068 and batch: 1500, loss is 3.798177933692932 and perplexity is 44.6198101284069
At time: 375.6252601146698 and batch: 1550, loss is 3.805104570388794 and perplexity is 44.92994820952102
At time: 376.94328117370605 and batch: 1600, loss is 3.90264479637146 and perplexity is 49.53328145986994
At time: 378.2592296600342 and batch: 1650, loss is 3.854907021522522 and perplexity is 47.22422590051743
At time: 379.5749704837799 and batch: 1700, loss is 3.8848046922683714 and perplexity is 48.65743835749587
At time: 380.8940477371216 and batch: 1750, loss is 3.88939950466156 and perplexity is 48.88152458111257
At time: 382.2150528430939 and batch: 1800, loss is 3.8360386514663696 and perplexity is 46.34153538373092
At time: 383.5340039730072 and batch: 1850, loss is 3.8778663063049317 and perplexity is 48.32100277982409
At time: 384.8535649776459 and batch: 1900, loss is 3.952780499458313 and perplexity is 52.079974041147075
At time: 386.169429063797 and batch: 1950, loss is 3.8848202133178713 and perplexity is 48.658193577866044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473368516079215 and perplexity of 87.65148171052819
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 390.16297674179077 and batch: 50, loss is 3.897536692619324 and perplexity is 49.28090544917731
At time: 391.4814817905426 and batch: 100, loss is 3.880902690887451 and perplexity is 48.467946904215985
At time: 392.7971525192261 and batch: 150, loss is 3.856066904067993 and perplexity is 47.27903223417336
At time: 394.11553955078125 and batch: 200, loss is 3.8678495121002197 and perplexity is 47.83939733737927
At time: 395.4342381954193 and batch: 250, loss is 3.851708755493164 and perplexity is 47.073431531848875
At time: 396.75202441215515 and batch: 300, loss is 3.8625662994384764 and perplexity is 47.587318108067365
At time: 398.0825660228729 and batch: 350, loss is 3.8815767478942873 and perplexity is 48.500628076682986
At time: 399.3999254703522 and batch: 400, loss is 3.8471722841262816 and perplexity is 46.86036790148938
At time: 400.716765165329 and batch: 450, loss is 3.8556827688217163 and perplexity is 47.26087417928008
At time: 402.03600549697876 and batch: 500, loss is 3.874216389656067 and perplexity is 48.14495661963265
At time: 403.35551857948303 and batch: 550, loss is 3.8256058931350707 and perplexity is 45.86057855989509
At time: 404.6721029281616 and batch: 600, loss is 3.7955146265029907 and perplexity is 44.50113197561758
At time: 405.98923349380493 and batch: 650, loss is 3.839424242973328 and perplexity is 46.49869478098939
At time: 407.30666756629944 and batch: 700, loss is 3.8759397792816164 and perplexity is 48.228000676472554
At time: 408.623740196228 and batch: 750, loss is 3.8285528373718263 and perplexity is 45.99592646098281
At time: 409.94110202789307 and batch: 800, loss is 3.7964102029800415 and perplexity is 44.54100399417307
At time: 411.25836539268494 and batch: 850, loss is 3.784762363433838 and perplexity is 44.02520731648342
At time: 412.57584524154663 and batch: 900, loss is 3.752931389808655 and perplexity is 42.64591073794753
At time: 413.89180064201355 and batch: 950, loss is 3.8546917057037353 and perplexity is 47.21405887225139
At time: 415.20712399482727 and batch: 1000, loss is 3.819458956718445 and perplexity is 45.57954114393301
At time: 416.52712750434875 and batch: 1050, loss is 3.767882881164551 and perplexity is 43.288321233826274
At time: 417.8475434780121 and batch: 1100, loss is 3.791789937019348 and perplexity is 44.335687383476035
At time: 419.1693000793457 and batch: 1150, loss is 3.7608809804916383 and perplexity is 42.9862793758008
At time: 420.4893710613251 and batch: 1200, loss is 3.8106981325149536 and perplexity is 45.18197086123048
At time: 421.80973267555237 and batch: 1250, loss is 3.777095890045166 and perplexity is 43.688979722918056
At time: 423.1319055557251 and batch: 1300, loss is 3.777910199165344 and perplexity is 43.72457054655715
At time: 424.4557864665985 and batch: 1350, loss is 3.6381220483779906 and perplexity is 38.02036922609207
At time: 425.7770118713379 and batch: 1400, loss is 3.6725367975234984 and perplexity is 39.35160640446302
At time: 427.1076385974884 and batch: 1450, loss is 3.5933959388732912 and perplexity is 36.357333803105405
At time: 428.42563223838806 and batch: 1500, loss is 3.589715828895569 and perplexity is 36.22378071197293
At time: 429.74638509750366 and batch: 1550, loss is 3.592274045944214 and perplexity is 36.316567639302896
At time: 431.0689573287964 and batch: 1600, loss is 3.6827236938476564 and perplexity is 39.75452590434423
At time: 432.3979742527008 and batch: 1650, loss is 3.6278026485443116 and perplexity is 37.630039283443786
At time: 433.7201728820801 and batch: 1700, loss is 3.64086332321167 and perplexity is 38.124736491741736
At time: 435.039568901062 and batch: 1750, loss is 3.6236193895339968 and perplexity is 37.472951880281386
At time: 436.35891699790955 and batch: 1800, loss is 3.5640944910049437 and perplexity is 35.307467695200934
At time: 437.68117785453796 and batch: 1850, loss is 3.5917579078674318 and perplexity is 36.29782811243391
At time: 439.0030610561371 and batch: 1900, loss is 3.663079118728638 and perplexity is 38.981185970868
At time: 440.3251404762268 and batch: 1950, loss is 3.595262246131897 and perplexity is 36.42525111665975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.410252486827762 and perplexity of 82.29023808260686
finished 8 epochs...
Completing Train Step...
At time: 444.3422520160675 and batch: 50, loss is 3.7975916862487793 and perplexity is 44.59365954486587
At time: 445.663409948349 and batch: 100, loss is 3.764695086479187 and perplexity is 43.150546668644566
At time: 446.9847447872162 and batch: 150, loss is 3.730652565956116 and perplexity is 41.7063154073933
At time: 448.3047716617584 and batch: 200, loss is 3.7373188447952272 and perplexity is 41.985270097078825
At time: 449.6226804256439 and batch: 250, loss is 3.723623557090759 and perplexity is 41.41418922815987
At time: 450.9427716732025 and batch: 300, loss is 3.732952980995178 and perplexity is 41.802367680268546
At time: 452.2657721042633 and batch: 350, loss is 3.7564509439468385 and perplexity is 42.796269772732074
At time: 453.58594942092896 and batch: 400, loss is 3.7223068141937254 and perplexity is 41.35969327511064
At time: 454.9057893753052 and batch: 450, loss is 3.736862897872925 and perplexity is 41.96613140584127
At time: 456.2262694835663 and batch: 500, loss is 3.7562117624282836 and perplexity is 42.78603491998195
At time: 457.5472033023834 and batch: 550, loss is 3.713655962944031 and perplexity is 41.00343989012355
At time: 458.8698329925537 and batch: 600, loss is 3.685434341430664 and perplexity is 39.86243259633601
At time: 460.1912398338318 and batch: 650, loss is 3.730014081001282 and perplexity is 41.67969505173675
At time: 461.51215624809265 and batch: 700, loss is 3.7674351024627684 and perplexity is 43.26894198467316
At time: 462.83124685287476 and batch: 750, loss is 3.72330548286438 and perplexity is 41.40101853669979
At time: 464.16289234161377 and batch: 800, loss is 3.692043328285217 and perplexity is 40.12675538015176
At time: 465.48525381088257 and batch: 850, loss is 3.684412202835083 and perplexity is 39.821708481855744
At time: 466.8044219017029 and batch: 900, loss is 3.654637837409973 and perplexity is 38.653519721108005
At time: 468.12219190597534 and batch: 950, loss is 3.7570355224609373 and perplexity is 42.82129486637816
At time: 469.438161611557 and batch: 1000, loss is 3.7238245964050294 and perplexity is 41.42251594533407
At time: 470.75477862358093 and batch: 1050, loss is 3.679894361495972 and perplexity is 39.6422061080217
At time: 472.07189083099365 and batch: 1100, loss is 3.7023283433914185 and perplexity is 40.54158929513293
At time: 473.3894622325897 and batch: 1150, loss is 3.6764921045303343 and perplexity is 39.507562312432256
At time: 474.70817399024963 and batch: 1200, loss is 3.7288824319839478 and perplexity is 41.6325549438478
At time: 476.02570939064026 and batch: 1250, loss is 3.6991355657577514 and perplexity is 40.412355432872886
At time: 477.34166193008423 and batch: 1300, loss is 3.70060781955719 and perplexity is 40.47189649572643
At time: 478.65805220603943 and batch: 1350, loss is 3.5656534099578856 and perplexity is 35.36255210067758
At time: 479.97420287132263 and batch: 1400, loss is 3.601152572631836 and perplexity is 36.64044088539376
At time: 481.2924234867096 and batch: 1450, loss is 3.528010115623474 and perplexity is 34.056132379253924
At time: 482.61167216300964 and batch: 1500, loss is 3.5243181085586546 and perplexity is 33.930628720667166
At time: 483.92740845680237 and batch: 1550, loss is 3.5322321128845213 and perplexity is 34.20022123422146
At time: 485.247433423996 and batch: 1600, loss is 3.6265548944473265 and perplexity is 37.583115528499825
At time: 486.56513714790344 and batch: 1650, loss is 3.574418249130249 and perplexity is 35.6738614779178
At time: 487.8846974372864 and batch: 1700, loss is 3.594049344062805 and perplexity is 36.38109763654981
At time: 489.20202136039734 and batch: 1750, loss is 3.5793993425369264 and perplexity is 35.85199960712701
At time: 490.51733326911926 and batch: 1800, loss is 3.5235082864761353 and perplexity is 33.90316207130608
At time: 491.83694219589233 and batch: 1850, loss is 3.557331018447876 and perplexity is 35.06947235112277
At time: 493.1599590778351 and batch: 1900, loss is 3.627639932632446 and perplexity is 37.6239167754165
At time: 494.48295497894287 and batch: 1950, loss is 3.565936985015869 and perplexity is 35.3725814604109
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419321743277616 and perplexity of 83.03994385335653
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 498.54171538352966 and batch: 50, loss is 3.754063539505005 and perplexity is 42.6942196341311
At time: 499.89420437812805 and batch: 100, loss is 3.7627441692352295 and perplexity is 43.066445586862464
At time: 501.2179307937622 and batch: 150, loss is 3.750695881843567 and perplexity is 42.55068194683373
At time: 502.5408947467804 and batch: 200, loss is 3.768434705734253 and perplexity is 43.3122153851478
At time: 503.86228680610657 and batch: 250, loss is 3.7539627742767334 and perplexity is 42.68991775808719
At time: 505.18113923072815 and batch: 300, loss is 3.7674586820602416 and perplexity is 43.269962260937056
At time: 506.50128746032715 and batch: 350, loss is 3.808001928329468 and perplexity is 45.06031512034302
At time: 507.82397723197937 and batch: 400, loss is 3.773999638557434 and perplexity is 43.55391685665518
At time: 509.1458594799042 and batch: 450, loss is 3.784089331626892 and perplexity is 43.99558692050445
At time: 510.468444108963 and batch: 500, loss is 3.7854802227020263 and perplexity is 44.0568225658817
At time: 511.78733491897583 and batch: 550, loss is 3.735213527679443 and perplexity is 41.896970770988425
At time: 513.1064360141754 and batch: 600, loss is 3.6946466541290284 and perplexity is 40.23135449317327
At time: 514.4273335933685 and batch: 650, loss is 3.7386701250076295 and perplexity is 42.04204231071918
At time: 515.7499063014984 and batch: 700, loss is 3.7787030935287476 and perplexity is 43.75925326013277
At time: 517.0675625801086 and batch: 750, loss is 3.7310552263259886 and perplexity is 41.723112269269635
At time: 518.386298418045 and batch: 800, loss is 3.6961167812347413 and perplexity is 40.290543194710224
At time: 519.7059237957001 and batch: 850, loss is 3.687412347793579 and perplexity is 39.94135877416052
At time: 521.0256969928741 and batch: 900, loss is 3.6525264835357665 and perplexity is 38.57199455701399
At time: 522.3482303619385 and batch: 950, loss is 3.7499806547164916 and perplexity is 42.5202594256329
At time: 523.6694149971008 and batch: 1000, loss is 3.711019558906555 and perplexity is 40.895480630293115
At time: 524.9897606372833 and batch: 1050, loss is 3.666528010368347 and perplexity is 39.11585996177562
At time: 526.3096127510071 and batch: 1100, loss is 3.703020815849304 and perplexity is 40.569672951575804
At time: 527.6292579174042 and batch: 1150, loss is 3.675748748779297 and perplexity is 39.47820505157403
At time: 528.9793939590454 and batch: 1200, loss is 3.7145401191711427 and perplexity is 41.0397093684152
At time: 530.3013691902161 and batch: 1250, loss is 3.6731070375442503 and perplexity is 39.37405266458539
At time: 531.6271450519562 and batch: 1300, loss is 3.6825064754486085 and perplexity is 39.745891427689926
At time: 532.9458153247833 and batch: 1350, loss is 3.5488571882247926 and perplexity is 34.77355514320838
At time: 534.2666220664978 and batch: 1400, loss is 3.573311142921448 and perplexity is 35.634388578761325
At time: 535.5865194797516 and batch: 1450, loss is 3.4899683094024656 and perplexity is 32.78490871642153
At time: 536.9093101024628 and batch: 1500, loss is 3.483468589782715 and perplexity is 32.572507025490495
At time: 538.2315244674683 and batch: 1550, loss is 3.486610698699951 and perplexity is 32.675014350525466
At time: 539.5513050556183 and batch: 1600, loss is 3.5739918041229246 and perplexity is 35.658651781078696
At time: 540.8707294464111 and batch: 1650, loss is 3.5153682231903076 and perplexity is 33.62830836739138
At time: 542.1909334659576 and batch: 1700, loss is 3.5275685882568357 and perplexity is 34.04109898387859
At time: 543.5122728347778 and batch: 1750, loss is 3.5113317251205443 and perplexity is 33.492841355676504
At time: 544.8335466384888 and batch: 1800, loss is 3.4445067644119263 and perplexity is 31.327827635817723
At time: 546.1565742492676 and batch: 1850, loss is 3.4795500946044924 and perplexity is 32.445121556437705
At time: 547.4755172729492 and batch: 1900, loss is 3.548282790184021 and perplexity is 34.75358701663885
At time: 548.7968723773956 and batch: 1950, loss is 3.4950881004333496 and perplexity is 32.95319101553092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392362656704215 and perplexity of 80.8311698576981
finished 10 epochs...
Completing Train Step...
At time: 552.7699897289276 and batch: 50, loss is 3.757676296234131 and perplexity is 42.848742421960466
At time: 554.1129190921783 and batch: 100, loss is 3.7386325788497925 and perplexity is 42.04046382319605
At time: 555.4333882331848 and batch: 150, loss is 3.7085882234573364 and perplexity is 40.796170775231005
At time: 556.7544519901276 and batch: 200, loss is 3.7158777379989623 and perplexity is 41.09464158734928
At time: 558.0763876438141 and batch: 250, loss is 3.701850004196167 and perplexity is 40.522201301323626
At time: 559.3980312347412 and batch: 300, loss is 3.7092890548706055 and perplexity is 40.82477203441116
At time: 560.717723608017 and batch: 350, loss is 3.7455119848251344 and perplexity is 42.33067433464431
At time: 562.0640549659729 and batch: 400, loss is 3.714551706314087 and perplexity is 41.040184904149086
At time: 563.3880088329315 and batch: 450, loss is 3.725774688720703 and perplexity is 41.50337248861295
At time: 564.7113873958588 and batch: 500, loss is 3.7314432716369628 and perplexity is 41.739305869067
At time: 566.0314552783966 and batch: 550, loss is 3.6829035902023315 and perplexity is 39.761678241956695
At time: 567.3525018692017 and batch: 600, loss is 3.6445806980133058 and perplexity is 38.26672417370154
At time: 568.6715717315674 and batch: 650, loss is 3.6890546226501466 and perplexity is 40.00700735516457
At time: 569.9922800064087 and batch: 700, loss is 3.7316282749176026 and perplexity is 41.74702849191767
At time: 571.3136291503906 and batch: 750, loss is 3.688095698356628 and perplexity is 39.96866205196044
At time: 572.6363351345062 and batch: 800, loss is 3.653507571220398 and perplexity is 38.6098556353275
At time: 573.958410024643 and batch: 850, loss is 3.646048846244812 and perplexity is 38.322946658494736
At time: 575.2779817581177 and batch: 900, loss is 3.611142807006836 and perplexity is 37.00832202717005
At time: 576.5982837677002 and batch: 950, loss is 3.7103517627716065 and perplexity is 40.86817990306597
At time: 577.9198226928711 and batch: 1000, loss is 3.671537356376648 and perplexity is 39.31229643709934
At time: 579.2422289848328 and batch: 1050, loss is 3.6295663595199583 and perplexity is 37.69646635860335
At time: 580.5637302398682 and batch: 1100, loss is 3.6680919551849365 and perplexity is 39.17708287035566
At time: 581.8831400871277 and batch: 1150, loss is 3.6439710426330567 and perplexity is 38.24340176946152
At time: 583.2041614055634 and batch: 1200, loss is 3.682405767440796 and perplexity is 39.7418888996922
At time: 584.525536775589 and batch: 1250, loss is 3.6450365591049194 and perplexity is 38.28417246105134
At time: 585.8461043834686 and batch: 1300, loss is 3.6557623386383056 and perplexity is 38.697010099422876
At time: 587.1668014526367 and batch: 1350, loss is 3.523243632316589 and perplexity is 33.89419064565706
At time: 588.487690448761 and batch: 1400, loss is 3.5497823667526247 and perplexity is 34.80574177665848
At time: 589.8074154853821 and batch: 1450, loss is 3.4693351125717165 and perplexity is 32.11538223057149
At time: 591.1262059211731 and batch: 1500, loss is 3.4649866008758545 and perplexity is 31.97603131944676
At time: 592.4495809078217 and batch: 1550, loss is 3.4713661670684814 and perplexity is 32.180676607839565
At time: 593.7703278064728 and batch: 1600, loss is 3.561335644721985 and perplexity is 35.210194062387174
At time: 595.0909259319305 and batch: 1650, loss is 3.504934468269348 and perplexity is 33.279262933249996
At time: 596.4098274707794 and batch: 1700, loss is 3.5211071872711184 and perplexity is 33.821854868202685
At time: 597.7303366661072 and batch: 1750, loss is 3.506830987930298 and perplexity is 33.34243759676505
At time: 599.05118227005 and batch: 1800, loss is 3.4427203512191773 and perplexity is 31.271913149286995
At time: 600.3736522197723 and batch: 1850, loss is 3.479884076118469 and perplexity is 32.455959436981416
At time: 601.6951463222504 and batch: 1900, loss is 3.5489213562011717 and perplexity is 34.775786563465516
At time: 603.0145697593689 and batch: 1950, loss is 3.4954284620285034 and perplexity is 32.964408925154885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.394781068313954 and perplexity of 81.02688946720633
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 607.0037784576416 and batch: 50, loss is 3.7471702766418455 and perplexity is 42.400929180907966
At time: 608.3520355224609 and batch: 100, loss is 3.7503675651550292 and perplexity is 42.536714140899285
At time: 609.6715738773346 and batch: 150, loss is 3.737499308586121 and perplexity is 41.99284760179428
At time: 610.9936764240265 and batch: 200, loss is 3.756882276535034 and perplexity is 42.814733180186664
At time: 612.3148765563965 and batch: 250, loss is 3.7541468143463135 and perplexity is 42.69777513653582
At time: 613.6379294395447 and batch: 300, loss is 3.769650921821594 and perplexity is 43.36492444458344
At time: 614.9605400562286 and batch: 350, loss is 3.809296646118164 and perplexity is 45.1186932953695
At time: 616.2824444770813 and batch: 400, loss is 3.7860536575317383 and perplexity is 44.08209352735968
At time: 617.6011383533478 and batch: 450, loss is 3.7987968826293947 and perplexity is 44.6474360610699
At time: 618.9228644371033 and batch: 500, loss is 3.811614193916321 and perplexity is 45.223379284207425
At time: 620.2454833984375 and batch: 550, loss is 3.771077423095703 and perplexity is 43.42682870731265
At time: 621.5664653778076 and batch: 600, loss is 3.7155754232406615 and perplexity is 41.08221994842734
At time: 622.8867692947388 and batch: 650, loss is 3.7256880712509157 and perplexity is 41.499777727187166
At time: 624.2049169540405 and batch: 700, loss is 3.759737753868103 and perplexity is 42.93716439689671
At time: 625.5243391990662 and batch: 750, loss is 3.713110799789429 and perplexity is 40.981092417546314
At time: 626.8460218906403 and batch: 800, loss is 3.6816466236114502 and perplexity is 39.71173053868264
At time: 628.2089686393738 and batch: 850, loss is 3.6820235109329222 and perplexity is 39.72670020719832
At time: 629.5282607078552 and batch: 900, loss is 3.6421174955368043 and perplexity is 38.17258147780996
At time: 630.8467514514923 and batch: 950, loss is 3.746290726661682 and perplexity is 42.36365184053315
At time: 632.1656727790833 and batch: 1000, loss is 3.705755662918091 and perplexity is 40.6807766593048
At time: 633.4882106781006 and batch: 1050, loss is 3.6545818281173705 and perplexity is 38.65135482543953
At time: 634.8103125095367 and batch: 1100, loss is 3.6813938188552857 and perplexity is 39.701692493213216
At time: 636.1316967010498 and batch: 1150, loss is 3.6616363859176637 and perplexity is 38.92498708459379
At time: 637.4529106616974 and batch: 1200, loss is 3.7041854000091554 and perplexity is 40.61694727218502
At time: 638.7728612422943 and batch: 1250, loss is 3.6645529890060424 and perplexity is 39.03868154234728
At time: 640.093512058258 and batch: 1300, loss is 3.671017870903015 and perplexity is 39.291879573756226
At time: 641.4166784286499 and batch: 1350, loss is 3.544441032409668 and perplexity is 34.620328291301284
At time: 642.7375109195709 and batch: 1400, loss is 3.5815890502929686 and perplexity is 35.93059102345067
At time: 644.0589566230774 and batch: 1450, loss is 3.499901657104492 and perplexity is 33.11219544939054
At time: 645.3770971298218 and batch: 1500, loss is 3.4790543842315675 and perplexity is 32.429042158822725
At time: 646.6974153518677 and batch: 1550, loss is 3.476131224632263 and perplexity is 32.334385308882155
At time: 648.0197353363037 and batch: 1600, loss is 3.5622862720489503 and perplexity is 35.24368174968409
At time: 649.3411695957184 and batch: 1650, loss is 3.4999452114105223 and perplexity is 33.11363765949148
At time: 650.6641232967377 and batch: 1700, loss is 3.5108256721496582 and perplexity is 33.475896491666056
At time: 651.9838857650757 and batch: 1750, loss is 3.506188015937805 and perplexity is 33.32100623385029
At time: 653.3047199249268 and batch: 1800, loss is 3.432840175628662 and perplexity is 30.964462490619677
At time: 654.6259121894836 and batch: 1850, loss is 3.464150938987732 and perplexity is 31.949321330553932
At time: 655.9479684829712 and batch: 1900, loss is 3.5447003984451295 and perplexity is 34.629308793164824
At time: 657.2698752880096 and batch: 1950, loss is 3.496016516685486 and perplexity is 32.98379950013817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37371343568314 and perplexity of 79.33770080747723
finished 12 epochs...
Completing Train Step...
At time: 661.2464230060577 and batch: 50, loss is 3.758505115509033 and perplexity is 42.88427100693928
At time: 662.5706243515015 and batch: 100, loss is 3.7413138866424562 and perplexity is 42.15333850470875
At time: 663.892671585083 and batch: 150, loss is 3.714041385650635 and perplexity is 41.019246592841476
At time: 665.2106878757477 and batch: 200, loss is 3.7234178733825685 and perplexity is 41.4056718801176
At time: 666.5333087444305 and batch: 250, loss is 3.7179233598709107 and perplexity is 41.17879172533731
At time: 667.8548991680145 and batch: 300, loss is 3.731393995285034 and perplexity is 41.73724915901574
At time: 669.1776418685913 and batch: 350, loss is 3.7678254365921022 and perplexity is 43.285834626142716
At time: 670.5000281333923 and batch: 400, loss is 3.7451126861572264 and perplexity is 42.31377512691093
At time: 671.8215870857239 and batch: 450, loss is 3.760998272895813 and perplexity is 42.99132163555891
At time: 673.1384744644165 and batch: 500, loss is 3.776966209411621 and perplexity is 43.683314475693024
At time: 674.4582517147064 and batch: 550, loss is 3.7372108936309814 and perplexity is 41.98073798291857
At time: 675.779746055603 and batch: 600, loss is 3.686300902366638 and perplexity is 39.896990794466596
At time: 677.102942943573 and batch: 650, loss is 3.701105899810791 and perplexity is 40.49205976924409
At time: 678.4253675937653 and batch: 700, loss is 3.7394094371795656 and perplexity is 42.073135996886606
At time: 679.7483050823212 and batch: 750, loss is 3.695121755599976 and perplexity is 40.250473010129326
At time: 681.0789852142334 and batch: 800, loss is 3.664656777381897 and perplexity is 39.042733513970205
At time: 682.4014804363251 and batch: 850, loss is 3.664116702079773 and perplexity is 39.02165319086522
At time: 683.7238278388977 and batch: 900, loss is 3.625347352027893 and perplexity is 37.53775971229205
At time: 685.0457699298859 and batch: 950, loss is 3.7320855903625487 and perplexity is 41.766124418926
At time: 686.3669698238373 and batch: 1000, loss is 3.6913172578811646 and perplexity is 40.097631105076125
At time: 687.6859176158905 and batch: 1050, loss is 3.6395974922180176 and perplexity is 38.07650754995021
At time: 689.0079970359802 and batch: 1100, loss is 3.6667773151397705 and perplexity is 39.1256129479849
At time: 690.3303997516632 and batch: 1150, loss is 3.647241625785828 and perplexity is 38.368684757532094
At time: 691.6496088504791 and batch: 1200, loss is 3.6907518100738526 and perplexity is 40.07496439651362
At time: 692.9667992591858 and batch: 1250, loss is 3.652040138244629 and perplexity is 38.553239810102504
At time: 694.2821762561798 and batch: 1300, loss is 3.6601776266098023 and perplexity is 38.86824629301661
At time: 695.5986201763153 and batch: 1350, loss is 3.5354465198516847 and perplexity is 34.31033153849113
At time: 696.9168972969055 and batch: 1400, loss is 3.5739424419403076 and perplexity is 35.65689163564027
At time: 698.235812664032 and batch: 1450, loss is 3.492895317077637 and perplexity is 32.88101097327401
At time: 699.5528683662415 and batch: 1500, loss is 3.474445524215698 and perplexity is 32.27992513676112
At time: 700.8697233200073 and batch: 1550, loss is 3.473259325027466 and perplexity is 32.24165741682397
At time: 702.1836733818054 and batch: 1600, loss is 3.561083426475525 and perplexity is 35.20131452882052
At time: 703.5011122226715 and batch: 1650, loss is 3.5004142045974733 and perplexity is 33.12917137226695
At time: 704.8207383155823 and batch: 1700, loss is 3.512630343437195 and perplexity is 33.53636402648999
At time: 706.139372587204 and batch: 1750, loss is 3.508788409233093 and perplexity is 33.40776671184583
At time: 707.4575905799866 and batch: 1800, loss is 3.437578535079956 and perplexity is 31.11153140163215
At time: 708.7744634151459 and batch: 1850, loss is 3.4700374507904055 and perplexity is 32.13794601369593
At time: 710.0911042690277 and batch: 1900, loss is 3.550244827270508 and perplexity is 34.82184178054694
At time: 711.4098765850067 and batch: 1950, loss is 3.500921893119812 and perplexity is 33.145994942532646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372765261627907 and perplexity of 79.26251051034747
finished 13 epochs...
Completing Train Step...
At time: 715.3854322433472 and batch: 50, loss is 3.751342692375183 and perplexity is 42.5782130787976
At time: 716.7139048576355 and batch: 100, loss is 3.7315010166168214 and perplexity is 41.741716174034565
At time: 718.0376777648926 and batch: 150, loss is 3.7023133850097656 and perplexity is 40.54098286310307
At time: 719.3645842075348 and batch: 200, loss is 3.7108271408081053 and perplexity is 40.88761235669844
At time: 720.681962966919 and batch: 250, loss is 3.70455313205719 and perplexity is 40.63188617197809
At time: 721.9980638027191 and batch: 300, loss is 3.7173118591308594 and perplexity is 41.153618561211516
At time: 723.3144376277924 and batch: 350, loss is 3.7529407119750977 and perplexity is 42.646308292078565
At time: 724.6326026916504 and batch: 400, loss is 3.730422010421753 and perplexity is 41.69670089394048
At time: 725.9645783901215 and batch: 450, loss is 3.746494812965393 and perplexity is 42.37229856395788
At time: 727.2831923961639 and batch: 500, loss is 3.762500691413879 and perplexity is 43.055961138934734
At time: 728.6001408100128 and batch: 550, loss is 3.722363567352295 and perplexity is 41.36204063495088
At time: 729.9159500598907 and batch: 600, loss is 3.673158450126648 and perplexity is 39.376077038351035
At time: 731.2419707775116 and batch: 650, loss is 3.689076066017151 and perplexity is 40.00786524930406
At time: 732.5682530403137 and batch: 700, loss is 3.7283203744888307 and perplexity is 41.60916162911053
At time: 733.8932609558105 and batch: 750, loss is 3.6850686836242676 and perplexity is 39.847859251266286
At time: 735.2181255817413 and batch: 800, loss is 3.6550498676300047 and perplexity is 38.66944942087718
At time: 736.5388078689575 and batch: 850, loss is 3.654320549964905 and perplexity is 38.641257390037524
At time: 737.854930639267 and batch: 900, loss is 3.6160693836212157 and perplexity is 37.191096216852564
At time: 739.1722848415375 and batch: 950, loss is 3.7231923151016235 and perplexity is 41.39633354115639
At time: 740.4903213977814 and batch: 1000, loss is 3.682168641090393 and perplexity is 39.73246616785246
At time: 741.8086259365082 and batch: 1050, loss is 3.630429301261902 and perplexity is 37.729010252670754
At time: 743.1240632534027 and batch: 1100, loss is 3.6576914596557617 and perplexity is 38.77173336685763
At time: 744.4417676925659 and batch: 1150, loss is 3.638528356552124 and perplexity is 38.03582035163894
At time: 745.7597539424896 and batch: 1200, loss is 3.6821325731277468 and perplexity is 39.7310331245905
At time: 747.077389717102 and batch: 1250, loss is 3.644244394302368 and perplexity is 38.253857096100745
At time: 748.3959445953369 and batch: 1300, loss is 3.6535924530029296 and perplexity is 38.61313304779146
At time: 749.7122476100922 and batch: 1350, loss is 3.530097713470459 and perplexity is 34.127302148967644
At time: 751.0279467105865 and batch: 1400, loss is 3.569076452255249 and perplexity is 35.48380702422945
At time: 752.3446393013 and batch: 1450, loss is 3.4882355737686157 and perplexity is 32.72815032468084
At time: 753.6638007164001 and batch: 1500, loss is 3.4710325479507445 and perplexity is 32.1699423095846
At time: 754.9808003902435 and batch: 1550, loss is 3.4706033945083616 and perplexity is 32.15613943008965
At time: 756.2981719970703 and batch: 1600, loss is 3.5592069673538207 and perplexity is 35.135322635985226
At time: 757.6133036613464 and batch: 1650, loss is 3.4992193508148195 and perplexity is 33.089610495974625
At time: 758.9302003383636 and batch: 1700, loss is 3.512233757972717 and perplexity is 33.52306662893723
At time: 760.247948884964 and batch: 1750, loss is 3.508341727256775 and perplexity is 33.392847396929206
At time: 761.5667865276337 and batch: 1800, loss is 3.438033685684204 and perplexity is 31.125695057002314
At time: 762.8843224048615 and batch: 1850, loss is 3.470845351219177 and perplexity is 32.16392076515383
At time: 764.2006139755249 and batch: 1900, loss is 3.5505650568008424 and perplexity is 34.83299454821318
At time: 765.5293936729431 and batch: 1950, loss is 3.500790228843689 and perplexity is 33.14163108639046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373041197311046 and perplexity of 79.28438488315368
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 769.6307389736176 and batch: 50, loss is 3.7490709018707276 and perplexity is 42.4815940892345
At time: 770.951199054718 and batch: 100, loss is 3.737336287498474 and perplexity is 41.98600244007286
At time: 772.286509513855 and batch: 150, loss is 3.7134879493713377 and perplexity is 40.996551334396536
At time: 773.6096909046173 and batch: 200, loss is 3.723705530166626 and perplexity is 41.41758421578232
At time: 774.9325747489929 and batch: 250, loss is 3.7214559268951417 and perplexity is 41.32451580558294
At time: 776.252158164978 and batch: 300, loss is 3.738060245513916 and perplexity is 42.01640954848257
At time: 777.5726230144501 and batch: 350, loss is 3.777211093902588 and perplexity is 43.694013151838604
At time: 778.8924443721771 and batch: 400, loss is 3.7609431886672975 and perplexity is 42.98895355699625
At time: 780.2138569355011 and batch: 450, loss is 3.781798095703125 and perplexity is 43.89489804629722
At time: 781.5358924865723 and batch: 500, loss is 3.807240891456604 and perplexity is 45.02603560467576
At time: 782.8584547042847 and batch: 550, loss is 3.780050196647644 and perplexity is 43.81824120918477
At time: 784.1793982982635 and batch: 600, loss is 3.7337128782272337 and perplexity is 41.834145256078955
At time: 785.499281167984 and batch: 650, loss is 3.739730257987976 and perplexity is 42.08663609983067
At time: 786.8248097896576 and batch: 700, loss is 3.7715326881408693 and perplexity is 43.44660392558678
At time: 788.1468963623047 and batch: 750, loss is 3.721841263771057 and perplexity is 41.34044273382148
At time: 789.4694664478302 and batch: 800, loss is 3.683562684059143 and perplexity is 39.78789355805037
At time: 790.7926876544952 and batch: 850, loss is 3.6858380794525147 and perplexity is 39.878529825331654
At time: 792.277773141861 and batch: 900, loss is 3.643955612182617 and perplexity is 38.242811661098706
At time: 793.6142723560333 and batch: 950, loss is 3.754063940048218 and perplexity is 42.69423673501443
At time: 794.9490716457367 and batch: 1000, loss is 3.7147709369659423 and perplexity is 41.04918315694826
At time: 796.2753508090973 and batch: 1050, loss is 3.663890872001648 and perplexity is 39.012841922838696
At time: 797.5984449386597 and batch: 1100, loss is 3.682264189720154 and perplexity is 39.73626273192717
At time: 798.9203300476074 and batch: 1150, loss is 3.6578550720214844 and perplexity is 38.77807742084564
At time: 800.2416265010834 and batch: 1200, loss is 3.6998236751556397 and perplexity is 40.44017312414682
At time: 801.5627839565277 and batch: 1250, loss is 3.658505668640137 and perplexity is 38.80331451558755
At time: 802.8854887485504 and batch: 1300, loss is 3.657623596191406 and perplexity is 38.7691022719909
At time: 804.2057881355286 and batch: 1350, loss is 3.525813813209534 and perplexity is 33.981416892435966
At time: 805.5273597240448 and batch: 1400, loss is 3.565466170310974 and perplexity is 35.35593144875196
At time: 806.8475613594055 and batch: 1450, loss is 3.480749554634094 and perplexity is 32.48406153170357
At time: 808.1679708957672 and batch: 1500, loss is 3.463431730270386 and perplexity is 31.926351361230914
At time: 809.4905712604523 and batch: 1550, loss is 3.4656827545166013 and perplexity is 31.998299300135034
At time: 810.8123083114624 and batch: 1600, loss is 3.5535429763793944 and perplexity is 34.936879007670115
At time: 812.1341645717621 and batch: 1650, loss is 3.493402976989746 and perplexity is 32.897707582155675
At time: 813.4496169090271 and batch: 1700, loss is 3.500850577354431 and perplexity is 33.14363119482126
At time: 814.7686166763306 and batch: 1750, loss is 3.5000888872146607 and perplexity is 33.118395629804574
At time: 816.0893263816833 and batch: 1800, loss is 3.43182692527771 and perplexity is 30.933103628006247
At time: 817.4118230342865 and batch: 1850, loss is 3.4636689138412478 and perplexity is 31.933924665347515
At time: 818.7314116954803 and batch: 1900, loss is 3.54762490272522 and perplexity is 34.73073058689588
At time: 820.0507862567902 and batch: 1950, loss is 3.5070333766937254 and perplexity is 33.34918641439931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366208098655523 and perplexity of 78.74447359371648
finished 15 epochs...
Completing Train Step...
At time: 824.0757162570953 and batch: 50, loss is 3.7584569549560545 and perplexity is 42.882205726466424
At time: 825.4132354259491 and batch: 100, loss is 3.7375082111358644 and perplexity is 41.993221446873015
At time: 826.734041929245 and batch: 150, loss is 3.7059308910369873 and perplexity is 40.68790569985998
At time: 828.0544285774231 and batch: 200, loss is 3.7122817420959473 and perplexity is 40.947130807602534
At time: 829.3746335506439 and batch: 250, loss is 3.7082066488265992 and perplexity is 40.78060696099913
At time: 830.6975417137146 and batch: 300, loss is 3.721022119522095 and perplexity is 41.306592813782956
At time: 832.0184595584869 and batch: 350, loss is 3.7597189807891844 and perplexity is 42.93635834168704
At time: 833.3421723842621 and batch: 400, loss is 3.7419130039215087 and perplexity is 42.1786008649793
At time: 834.6614229679108 and batch: 450, loss is 3.7634063529968262 and perplexity is 43.094972931929696
At time: 835.9824721813202 and batch: 500, loss is 3.7882742404937746 and perplexity is 44.18009023782183
At time: 837.3043720722198 and batch: 550, loss is 3.7589455699920653 and perplexity is 42.90316373674419
At time: 838.6268839836121 and batch: 600, loss is 3.7123174238204957 and perplexity is 40.94859189791201
At time: 839.9500060081482 and batch: 650, loss is 3.719478087425232 and perplexity is 41.24286332151833
At time: 841.2689175605774 and batch: 700, loss is 3.7533924055099486 and perplexity is 42.665575704974685
At time: 842.5885281562805 and batch: 750, loss is 3.7044757318496706 and perplexity is 40.62874137726193
At time: 843.9101650714874 and batch: 800, loss is 3.668005180358887 and perplexity is 39.17368343329937
At time: 845.234870672226 and batch: 850, loss is 3.6700958108901975 and perplexity is 39.255666800513566
At time: 846.5539362430573 and batch: 900, loss is 3.62918110370636 and perplexity is 37.68194637292063
At time: 847.8745710849762 and batch: 950, loss is 3.7402675676345827 and perplexity is 42.10925573172934
At time: 849.1950554847717 and batch: 1000, loss is 3.701565508842468 and perplexity is 40.510674563061244
At time: 850.5134012699127 and batch: 1050, loss is 3.6507370615005494 and perplexity is 38.50303469755839
At time: 851.8387584686279 and batch: 1100, loss is 3.670948567390442 and perplexity is 39.28915660284297
At time: 853.1610746383667 and batch: 1150, loss is 3.6476937437057497 and perplexity is 38.38603584954907
At time: 854.4842791557312 and batch: 1200, loss is 3.6893420934677126 and perplexity is 40.0185098555147
At time: 855.8059396743774 and batch: 1250, loss is 3.648560848236084 and perplexity is 38.41933498996715
At time: 857.1298894882202 and batch: 1300, loss is 3.6498323917388915 and perplexity is 38.468217917554064
At time: 858.4745903015137 and batch: 1350, loss is 3.519639024734497 and perplexity is 33.77223532165871
At time: 859.7964787483215 and batch: 1400, loss is 3.561646008491516 and perplexity is 35.22112372694051
At time: 861.1181893348694 and batch: 1450, loss is 3.4795300197601318 and perplexity is 32.44447023220983
At time: 862.4370594024658 and batch: 1500, loss is 3.46506890296936 and perplexity is 31.978663122066305
At time: 863.7562863826752 and batch: 1550, loss is 3.4683381509780884 and perplexity is 32.0833803828801
At time: 865.0792708396912 and batch: 1600, loss is 3.5578378105163573 and perplexity is 35.08724978590712
At time: 866.4010314941406 and batch: 1650, loss is 3.4986135530471802 and perplexity is 33.069570954371756
At time: 867.7227363586426 and batch: 1700, loss is 3.507864899635315 and perplexity is 33.37692856050322
At time: 869.0439648628235 and batch: 1750, loss is 3.5091764450073244 and perplexity is 33.4207326359257
At time: 870.3650674819946 and batch: 1800, loss is 3.4405434846878054 and perplexity is 31.20391240930103
At time: 871.6883082389832 and batch: 1850, loss is 3.472570390701294 and perplexity is 32.21945268197712
At time: 873.0120232105255 and batch: 1900, loss is 3.5573616790771485 and perplexity is 35.07054761969743
At time: 874.3341708183289 and batch: 1950, loss is 3.516047477722168 and perplexity is 33.651158307832965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364426723746366 and perplexity of 78.60432502985051
finished 16 epochs...
Completing Train Step...
At time: 878.3962736129761 and batch: 50, loss is 3.759760785102844 and perplexity is 42.93815330419689
At time: 879.7445893287659 and batch: 100, loss is 3.735904936790466 and perplexity is 41.925948734963505
At time: 881.0667796134949 and batch: 150, loss is 3.702231459617615 and perplexity is 40.53766166323099
At time: 882.3887786865234 and batch: 200, loss is 3.707060651779175 and perplexity is 40.73389927437693
At time: 883.7087500095367 and batch: 250, loss is 3.7017488956451414 and perplexity is 40.518104367386705
At time: 885.0283772945404 and batch: 300, loss is 3.713381905555725 and perplexity is 40.992204134167004
At time: 886.3525743484497 and batch: 350, loss is 3.7520128870010376 and perplexity is 42.60675833275095
At time: 887.6725125312805 and batch: 400, loss is 3.7335801839828493 and perplexity is 41.82859447407129
At time: 888.9921216964722 and batch: 450, loss is 3.755093102455139 and perplexity is 42.738198656552505
At time: 890.3469614982605 and batch: 500, loss is 3.779570779800415 and perplexity is 43.79723904093204
At time: 891.6616792678833 and batch: 550, loss is 3.7492920398712157 and perplexity is 42.490989422803295
At time: 892.9789600372314 and batch: 600, loss is 3.703178997039795 and perplexity is 40.57609081832063
At time: 894.3056826591492 and batch: 650, loss is 3.7108459424972535 and perplexity is 40.88838112010299
At time: 895.621649980545 and batch: 700, loss is 3.745808925628662 and perplexity is 42.3432459055089
At time: 896.938369512558 and batch: 750, loss is 3.6973968648910525 and perplexity is 40.34215148497495
At time: 898.2523145675659 and batch: 800, loss is 3.6617887687683104 and perplexity is 38.93091903703956
At time: 899.569375038147 and batch: 850, loss is 3.6635550594329835 and perplexity is 38.99974311967615
At time: 900.8880839347839 and batch: 900, loss is 3.6230948305130006 and perplexity is 37.45330025999719
At time: 902.2058770656586 and batch: 950, loss is 3.7343069887161255 and perplexity is 41.859006745073835
At time: 903.522588968277 and batch: 1000, loss is 3.69634060382843 and perplexity is 40.29956213787317
At time: 904.839129447937 and batch: 1050, loss is 3.645749077796936 and perplexity is 38.311460369956336
At time: 906.1567089557648 and batch: 1100, loss is 3.6667780303955078 and perplexity is 39.12564093281404
At time: 907.4765403270721 and batch: 1150, loss is 3.6439894962310793 and perplexity is 38.24410750433645
At time: 908.796318769455 and batch: 1200, loss is 3.68569504737854 and perplexity is 39.87282632440519
At time: 910.1188478469849 and batch: 1250, loss is 3.645284581184387 and perplexity is 38.2936689587377
At time: 911.4455409049988 and batch: 1300, loss is 3.6473673820495605 and perplexity is 38.37351016337769
At time: 912.7679469585419 and batch: 1350, loss is 3.5176900243759155 and perplexity is 33.70647732490204
At time: 914.0937769412994 and batch: 1400, loss is 3.560520577430725 and perplexity is 35.181507077387735
At time: 915.4218788146973 and batch: 1450, loss is 3.479132652282715 and perplexity is 32.431580416084
At time: 916.7459495067596 and batch: 1500, loss is 3.4657502460479734 and perplexity is 32.000458987235575
At time: 918.0746567249298 and batch: 1550, loss is 3.4695029497146606 and perplexity is 32.12077283692896
At time: 919.4129345417023 and batch: 1600, loss is 3.5596790504455567 and perplexity is 35.1519133435125
At time: 920.7402067184448 and batch: 1650, loss is 3.5007290744781496 and perplexity is 33.13960439293963
At time: 922.062073469162 and batch: 1700, loss is 3.5104855918884277 and perplexity is 33.46451393564326
At time: 923.3844602108002 and batch: 1750, loss is 3.512350850105286 and perplexity is 33.52699214611816
At time: 924.7060239315033 and batch: 1800, loss is 3.443617467880249 and perplexity is 31.29998029146483
At time: 926.0250916481018 and batch: 1850, loss is 3.475643153190613 and perplexity is 32.318607669450394
At time: 927.3451247215271 and batch: 1900, loss is 3.5602567625045776 and perplexity is 35.17222689487552
At time: 928.6670942306519 and batch: 1950, loss is 3.518426327705383 and perplexity is 33.73130465548241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3637422783430235 and perplexity of 78.55054306840874
finished 17 epochs...
Completing Train Step...
At time: 932.6319501399994 and batch: 50, loss is 3.7581767988204957 and perplexity is 42.87019369612643
At time: 933.9776563644409 and batch: 100, loss is 3.7332176399230956 and perplexity is 41.81343251422218
At time: 935.3079030513763 and batch: 150, loss is 3.6988407802581786 and perplexity is 40.40044421220151
At time: 936.6304461956024 and batch: 200, loss is 3.703087286949158 and perplexity is 40.57236975198625
At time: 937.9525365829468 and batch: 250, loss is 3.6971309566497803 and perplexity is 40.331425600538175
At time: 939.273378610611 and batch: 300, loss is 3.7083255195617677 and perplexity is 40.785454869860736
At time: 940.5922629833221 and batch: 350, loss is 3.747032675743103 and perplexity is 42.395095176336504
At time: 941.9134588241577 and batch: 400, loss is 3.7283734130859374 and perplexity is 41.61136857919637
At time: 943.235780954361 and batch: 450, loss is 3.7499422645568847 and perplexity is 42.518627097419895
At time: 944.557855129242 and batch: 500, loss is 3.7741224241256712 and perplexity is 43.559264977414685
At time: 945.8792412281036 and batch: 550, loss is 3.743450722694397 and perplexity is 42.24350958423145
At time: 947.199282169342 and batch: 600, loss is 3.6978880977630615 and perplexity is 40.36197374418599
At time: 948.5200216770172 and batch: 650, loss is 3.7058198404312135 and perplexity is 40.68338753416151
At time: 949.8412907123566 and batch: 700, loss is 3.741299376487732 and perplexity is 42.15272685768245
At time: 951.1609826087952 and batch: 750, loss is 3.6931929445266722 and perplexity is 40.17291227612883
At time: 952.4822707176208 and batch: 800, loss is 3.657949194908142 and perplexity is 38.78172749720669
At time: 953.8017597198486 and batch: 850, loss is 3.659499697685242 and perplexity is 38.84190531427216
At time: 955.1224219799042 and batch: 900, loss is 3.6193145656585695 and perplexity is 37.31198413981176
At time: 956.5055639743805 and batch: 950, loss is 3.7306034755706787 and perplexity is 41.70426807854728
At time: 957.8281700611115 and batch: 1000, loss is 3.693157548904419 and perplexity is 40.17149035606611
At time: 959.1514148712158 and batch: 1050, loss is 3.6427722358703614 and perplexity is 38.19758279033019
At time: 960.4712479114532 and batch: 1100, loss is 3.6641634702682495 and perplexity is 39.02347820557231
At time: 961.7923398017883 and batch: 1150, loss is 3.6415902757644654 and perplexity is 38.15246144239993
At time: 963.1135597229004 and batch: 1200, loss is 3.683437285423279 and perplexity is 39.7829045232899
At time: 964.4362742900848 and batch: 1250, loss is 3.643263521194458 and perplexity is 38.21635331263457
At time: 965.7555718421936 and batch: 1300, loss is 3.645736780166626 and perplexity is 38.31098923267701
At time: 967.0736644268036 and batch: 1350, loss is 3.516292290687561 and perplexity is 33.65939755618348
At time: 968.3893654346466 and batch: 1400, loss is 3.5594811630249024 and perplexity is 35.14495791026895
At time: 969.7070653438568 and batch: 1450, loss is 3.4782938528060914 and perplexity is 32.40438822939523
At time: 971.0314509868622 and batch: 1500, loss is 3.4654926300048827 and perplexity is 31.99221621739466
At time: 972.3572044372559 and batch: 1550, loss is 3.46954216003418 and perplexity is 32.12203232738745
At time: 973.6822745800018 and batch: 1600, loss is 3.5600887870788576 and perplexity is 35.16631932126682
At time: 975.0040555000305 and batch: 1650, loss is 3.501281476020813 and perplexity is 33.15791581869382
At time: 976.3246154785156 and batch: 1700, loss is 3.511294040679932 and perplexity is 33.491579220467074
At time: 977.6449754238129 and batch: 1750, loss is 3.513285799026489 and perplexity is 33.55835282929037
At time: 978.969069480896 and batch: 1800, loss is 3.444619059562683 and perplexity is 31.331345796477464
At time: 980.2944128513336 and batch: 1850, loss is 3.4766995668411256 and perplexity is 32.35276752805153
At time: 981.6163055896759 and batch: 1900, loss is 3.5610503816604613 and perplexity is 35.20015132711091
At time: 982.9461884498596 and batch: 1950, loss is 3.5188482761383058 and perplexity is 33.74554052981345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36347173646439 and perplexity of 78.5292947313314
finished 18 epochs...
Completing Train Step...
At time: 987.0621581077576 and batch: 50, loss is 3.7559826040267943 and perplexity is 42.776231263951594
At time: 988.3907933235168 and batch: 100, loss is 3.7304796266555784 and perplexity is 41.699103370019074
At time: 989.7373838424683 and batch: 150, loss is 3.6958395624160767 and perplexity is 40.27937544594901
At time: 991.0609564781189 and batch: 200, loss is 3.6998294305801394 and perplexity is 40.44040587517978
At time: 992.3856592178345 and batch: 250, loss is 3.693485698699951 and perplexity is 40.18467478552828
At time: 993.7265224456787 and batch: 300, loss is 3.704470405578613 and perplexity is 40.62852497814893
At time: 995.064783334732 and batch: 350, loss is 3.7432476711273193 and perplexity is 42.234932844201225
At time: 996.3894715309143 and batch: 400, loss is 3.724501667022705 and perplexity is 41.45057141048464
At time: 997.7191941738129 and batch: 450, loss is 3.7461186456680298 and perplexity is 42.35636248842715
At time: 999.041740655899 and batch: 500, loss is 3.7700681114196777 and perplexity is 43.383019614279235
At time: 1000.363400220871 and batch: 550, loss is 3.739184513092041 and perplexity is 42.06367379934118
At time: 1001.6853387355804 and batch: 600, loss is 3.6940857791900634 and perplexity is 40.2087960614983
At time: 1003.0039255619049 and batch: 650, loss is 3.7021862363815305 and perplexity is 40.535828460439284
At time: 1004.3234055042267 and batch: 700, loss is 3.7379426908493043 and perplexity is 42.011470613853014
At time: 1005.6493539810181 and batch: 750, loss is 3.6900205707550047 and perplexity is 40.045670718495344
At time: 1006.9745483398438 and batch: 800, loss is 3.654947962760925 and perplexity is 38.66550901647317
At time: 1008.2974145412445 and batch: 850, loss is 3.6563723039627076 and perplexity is 38.72062113396567
At time: 1009.6163685321808 and batch: 900, loss is 3.6163737678527834 and perplexity is 37.20241832314359
At time: 1010.9403030872345 and batch: 950, loss is 3.7277267742156983 and perplexity is 41.5844697486812
At time: 1012.2611203193665 and batch: 1000, loss is 3.6906318283081054 and perplexity is 40.070156419963595
At time: 1013.5834753513336 and batch: 1050, loss is 3.6404259490966795 and perplexity is 38.10806536488486
At time: 1014.9068751335144 and batch: 1100, loss is 3.66200439453125 and perplexity is 38.939314451260124
At time: 1016.2281348705292 and batch: 1150, loss is 3.6395641422271727 and perplexity is 38.075237719946536
At time: 1017.5457310676575 and batch: 1200, loss is 3.6815296697616575 and perplexity is 39.70708637049618
At time: 1018.8659360408783 and batch: 1250, loss is 3.641533446311951 and perplexity is 38.15029332051125
At time: 1020.1863780021667 and batch: 1300, loss is 3.6442592668533327 and perplexity is 38.25442603277076
At time: 1021.5073537826538 and batch: 1350, loss is 3.5149658870697023 and perplexity is 33.614781205675676
At time: 1022.8295395374298 and batch: 1400, loss is 3.5583358240127563 and perplexity is 35.1047280616994
At time: 1024.1486818790436 and batch: 1450, loss is 3.477199492454529 and perplexity is 32.36894554876981
At time: 1025.4653329849243 and batch: 1500, loss is 3.4648016691207886 and perplexity is 31.97011848260731
At time: 1026.7939050197601 and batch: 1550, loss is 3.4690583324432374 and perplexity is 32.10649456097346
At time: 1028.115460395813 and batch: 1600, loss is 3.5598566198348998 and perplexity is 35.158155801517466
At time: 1029.4371511936188 and batch: 1650, loss is 3.5011622667312623 and perplexity is 33.1539633226979
At time: 1030.7579703330994 and batch: 1700, loss is 3.511372990608215 and perplexity is 33.49422348262541
At time: 1032.0822732448578 and batch: 1750, loss is 3.5133673048019407 and perplexity is 33.56108814033091
At time: 1033.4065430164337 and batch: 1800, loss is 3.444826912879944 and perplexity is 31.337858797486494
At time: 1034.736431837082 and batch: 1850, loss is 3.47698691368103 and perplexity is 32.36206532934582
At time: 1036.059471130371 and batch: 1900, loss is 3.5611282110214235 and perplexity is 35.2028910390081
At time: 1037.3794600963593 and batch: 1950, loss is 3.5186383867263795 and perplexity is 33.738458441410195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363392816587936 and perplexity of 78.52309745364064
finished 19 epochs...
Completing Train Step...
At time: 1041.4719023704529 and batch: 50, loss is 3.7537440824508668 and perplexity is 42.680582842798614
At time: 1042.7987759113312 and batch: 100, loss is 3.727922978401184 and perplexity is 41.59262959616903
At time: 1044.1260964870453 and batch: 150, loss is 3.6931696844100954 and perplexity is 40.1719778603734
At time: 1045.4484617710114 and batch: 200, loss is 3.697011880874634 and perplexity is 40.32662339069114
At time: 1046.7719938755035 and batch: 250, loss is 3.6904034948349 and perplexity is 40.061008106449194
At time: 1048.0979335308075 and batch: 300, loss is 3.701248288154602 and perplexity is 40.49782577706854
At time: 1049.4234154224396 and batch: 350, loss is 3.7400651121139528 and perplexity is 42.1007313433707
At time: 1050.7491602897644 and batch: 400, loss is 3.72127329826355 and perplexity is 41.316969454920994
At time: 1052.0719878673553 and batch: 450, loss is 3.7429316663742065 and perplexity is 42.221588513222116
At time: 1053.4002668857574 and batch: 500, loss is 3.766688795089722 and perplexity is 43.23666210110189
At time: 1054.7461323738098 and batch: 550, loss is 3.735657572746277 and perplexity is 41.915579045325
At time: 1056.0650472640991 and batch: 600, loss is 3.6909456396102907 and perplexity is 40.082732861139995
At time: 1057.383903503418 and batch: 650, loss is 3.6991789722442627 and perplexity is 40.41410962930535
At time: 1058.6993534564972 and batch: 700, loss is 3.735106406211853 and perplexity is 41.89248294636732
At time: 1060.0162332057953 and batch: 750, loss is 3.687306604385376 and perplexity is 39.93713546205313
At time: 1061.3325340747833 and batch: 800, loss is 3.6523302030563354 and perplexity is 38.56442437039396
At time: 1062.6490459442139 and batch: 850, loss is 3.6536809682846068 and perplexity is 38.61655105141016
At time: 1063.9686329364777 and batch: 900, loss is 3.613828477859497 and perplexity is 37.107847785837045
At time: 1065.2884023189545 and batch: 950, loss is 3.7252357959747315 and perplexity is 41.481012647564675
At time: 1066.6083028316498 and batch: 1000, loss is 3.6883922672271727 and perplexity is 39.980517270779906
At time: 1067.9266583919525 and batch: 1050, loss is 3.6383428812026977 and perplexity is 38.02876629876519
At time: 1069.2482283115387 and batch: 1100, loss is 3.660042586326599 and perplexity is 38.86299786841194
At time: 1070.567397594452 and batch: 1150, loss is 3.6377077960968016 and perplexity is 38.00462246319993
At time: 1071.8871912956238 and batch: 1200, loss is 3.679756455421448 and perplexity is 39.63673958393399
At time: 1073.2042598724365 and batch: 1250, loss is 3.63991400718689 and perplexity is 38.0885612420385
At time: 1074.5217552185059 and batch: 1300, loss is 3.64283269405365 and perplexity is 38.19989221660286
At time: 1075.8416261672974 and batch: 1350, loss is 3.5136542558670043 and perplexity is 33.57071991217497
At time: 1077.1614406108856 and batch: 1400, loss is 3.557122106552124 and perplexity is 35.06214668640677
At time: 1078.480794429779 and batch: 1450, loss is 3.47599268913269 and perplexity is 32.329906158927805
At time: 1079.7980389595032 and batch: 1500, loss is 3.463915910720825 and perplexity is 31.941813219276508
At time: 1081.1170408725739 and batch: 1550, loss is 3.4683292961120604 and perplexity is 32.08309629010289
At time: 1082.436984539032 and batch: 1600, loss is 3.5593270587921144 and perplexity is 35.13954234078563
At time: 1083.7579729557037 and batch: 1650, loss is 3.500738263130188 and perplexity is 33.1399089026321
At time: 1085.077574968338 and batch: 1700, loss is 3.511127290725708 and perplexity is 33.48599496676514
At time: 1086.3959503173828 and batch: 1750, loss is 3.513085250854492 and perplexity is 33.551623437781366
At time: 1087.713630437851 and batch: 1800, loss is 3.4446862316131592 and perplexity is 31.33345045790521
At time: 1089.0352516174316 and batch: 1850, loss is 3.4769270849227905 and perplexity is 32.36012920508163
At time: 1090.3617923259735 and batch: 1900, loss is 3.5609179973602294 and perplexity is 35.19549168814774
At time: 1091.6850848197937 and batch: 1950, loss is 3.5181884956359863 and perplexity is 33.72328322340745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3634206372638085 and perplexity of 78.52528204967173
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -78.52309745364064
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
1124.894710302353


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9817171096801758 and batch: 50, loss is 7.654107484817505 and perplexity is 2109.2917040218836
At time: 3.5086052417755127 and batch: 100, loss is 6.698967323303223 and perplexity is 811.5673056378737
At time: 5.040752410888672 and batch: 150, loss is 6.329374208450317 and perplexity is 560.8055366542794
At time: 6.572534799575806 and batch: 200, loss is 6.186742334365845 and perplexity is 486.2594525162636
At time: 8.105144500732422 and batch: 250, loss is 6.064012432098389 and perplexity is 430.0977171680295
At time: 9.633926630020142 and batch: 300, loss is 5.983074092864991 and perplexity is 396.65785895070445
At time: 11.167200565338135 and batch: 350, loss is 5.909649209976196 and perplexity is 368.5768396509894
At time: 12.70442509651184 and batch: 400, loss is 5.842589654922485 and perplexity is 344.6707642683492
At time: 14.231644868850708 and batch: 450, loss is 5.768323497772217 and perplexity is 320.0008006341039
At time: 15.796157121658325 and batch: 500, loss is 5.731135578155517 and perplexity is 308.3191901953341
At time: 17.32859754562378 and batch: 550, loss is 5.671870708465576 and perplexity is 290.5776122623384
At time: 18.866657972335815 and batch: 600, loss is 5.69750940322876 and perplexity is 298.1239689621551
At time: 20.40410614013672 and batch: 650, loss is 5.757735624313354 and perplexity is 316.63054604938554
At time: 21.94522261619568 and batch: 700, loss is 5.674670038223266 and perplexity is 291.39217440135474
At time: 23.487030744552612 and batch: 750, loss is 5.614608402252197 and perplexity is 274.4059014197471
At time: 25.024747610092163 and batch: 800, loss is 5.612185506820679 and perplexity is 273.7418494039686
At time: 26.56190061569214 and batch: 850, loss is 5.6255796432495115 and perplexity is 277.43305011997967
At time: 28.10342502593994 and batch: 900, loss is 5.608653841018676 and perplexity is 272.77678981290074
At time: 29.641220331192017 and batch: 950, loss is 5.644862937927246 and perplexity is 282.83478764374956
At time: 31.182445287704468 and batch: 1000, loss is 5.611044216156006 and perplexity is 273.42960859936346
At time: 32.72220516204834 and batch: 1050, loss is 5.517910223007203 and perplexity is 249.11390035192315
At time: 34.26219344139099 and batch: 1100, loss is 5.60532060623169 and perplexity is 271.86907438276546
At time: 35.805819511413574 and batch: 1150, loss is 5.507084398269654 and perplexity is 246.4315822766286
At time: 37.35536432266235 and batch: 1200, loss is 5.5766819477081295 and perplexity is 264.1935418737116
At time: 38.89512348175049 and batch: 1250, loss is 5.5092821788787845 and perplexity is 246.9737804276794
At time: 40.437663316726685 and batch: 1300, loss is 5.531088066101074 and perplexity is 252.41840957489273
At time: 41.979867696762085 and batch: 1350, loss is 5.479968385696411 and perplexity is 239.8391249074914
At time: 43.52098798751831 and batch: 1400, loss is 5.495478086471557 and perplexity is 243.5879544327099
At time: 45.06146836280823 and batch: 1450, loss is 5.451587705612183 and perplexity is 233.12801087873078
At time: 46.60089826583862 and batch: 1500, loss is 5.428455896377564 and perplexity is 227.79723119085597
At time: 48.14230990409851 and batch: 1550, loss is 5.409848203659058 and perplexity is 223.59764380016063
At time: 49.68637943267822 and batch: 1600, loss is 5.442255945205688 and perplexity is 230.96263523422272
At time: 51.22694277763367 and batch: 1650, loss is 5.422181224822998 and perplexity is 226.37235337919262
At time: 52.767099380493164 and batch: 1700, loss is 5.433235874176026 and perplexity is 228.88870342684774
At time: 54.30540633201599 and batch: 1750, loss is 5.4525845432281494 and perplexity is 233.36051751573783
At time: 55.843310832977295 and batch: 1800, loss is 5.438002185821533 and perplexity is 229.982262370617
At time: 57.39167094230652 and batch: 1850, loss is 5.416045608520508 and perplexity is 224.98767175887778
At time: 58.93263339996338 and batch: 1900, loss is 5.422847242355346 and perplexity is 226.5231715535814
At time: 60.46929574012756 and batch: 1950, loss is 5.35480429649353 and perplexity is 211.6225570236146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.0193302598110465 and perplexity of 151.3099315091759
finished 1 epochs...
Completing Train Step...
At time: 64.56318354606628 and batch: 50, loss is 5.245775279998779 and perplexity is 189.76287757840203
At time: 65.88552570343018 and batch: 100, loss is 5.183683080673218 and perplexity is 178.33843774246554
At time: 67.20173764228821 and batch: 150, loss is 5.100884380340577 and perplexity is 164.16702921216609
At time: 68.52025175094604 and batch: 200, loss is 5.077747526168824 and perplexity is 160.41232412354978
At time: 69.86773943901062 and batch: 250, loss is 5.0808203983306885 and perplexity is 160.90600881527217
At time: 71.18821215629578 and batch: 300, loss is 5.099929437637329 and perplexity is 164.01033393491971
At time: 72.50863218307495 and batch: 350, loss is 5.074176406860351 and perplexity is 159.84049421966768
At time: 73.82740473747253 and batch: 400, loss is 5.037472620010376 and perplexity is 154.0801035357179
At time: 75.14484667778015 and batch: 450, loss is 5.003444509506226 and perplexity is 148.925251086492
At time: 76.46268653869629 and batch: 500, loss is 4.983616762161255 and perplexity is 146.00148051363257
At time: 77.78206324577332 and batch: 550, loss is 4.939805355072021 and perplexity is 139.74304663738513
At time: 79.10222840309143 and batch: 600, loss is 4.923173704147339 and perplexity is 137.43810965106198
At time: 80.42092394828796 and batch: 650, loss is 4.9859357357025145 and perplexity is 146.34044695913448
At time: 81.73694372177124 and batch: 700, loss is 4.9783663558959965 and perplexity is 145.2369223025832
At time: 83.05948281288147 and batch: 750, loss is 4.9342091941833495 and perplexity is 138.96320615691596
At time: 84.38011264801025 and batch: 800, loss is 4.9193606948852535 and perplexity is 136.9150547063995
At time: 85.70112538337708 and batch: 850, loss is 4.906402635574341 and perplexity is 135.152346609804
At time: 87.02193474769592 and batch: 900, loss is 4.911590785980224 and perplexity is 135.85535940286763
At time: 88.34370470046997 and batch: 950, loss is 4.973024549484253 and perplexity is 144.46316325525243
At time: 89.6609160900116 and batch: 1000, loss is 4.93573187828064 and perplexity is 139.17496440058
At time: 90.98091125488281 and batch: 1050, loss is 4.8465156078338625 and perplexity is 127.29606677979896
At time: 92.30009818077087 and batch: 1100, loss is 4.925433874130249 and perplexity is 137.74909444786928
At time: 93.62175679206848 and batch: 1150, loss is 4.829769325256348 and perplexity is 125.18208097954762
At time: 94.94001984596252 and batch: 1200, loss is 4.912907848358154 and perplexity is 136.03440726829882
At time: 96.25760245323181 and batch: 1250, loss is 4.869283561706543 and perplexity is 130.22758343897948
At time: 97.57589936256409 and batch: 1300, loss is 4.897415580749512 and perplexity is 133.94316668275704
At time: 98.89686369895935 and batch: 1350, loss is 4.803494281768799 and perplexity is 121.93575184159701
At time: 100.21798515319824 and batch: 1400, loss is 4.812111606597901 and perplexity is 122.99105222620815
At time: 101.5394856929779 and batch: 1450, loss is 4.751549482345581 and perplexity is 115.76351916007854
At time: 102.85622310638428 and batch: 1500, loss is 4.730176219940185 and perplexity is 113.31552904509357
At time: 104.17558479309082 and batch: 1550, loss is 4.7279989051818845 and perplexity is 113.06907387396384
At time: 105.49578666687012 and batch: 1600, loss is 4.807385892868042 and perplexity is 122.41120290212609
At time: 106.82232189178467 and batch: 1650, loss is 4.7459465026855465 and perplexity is 115.11671223200207
At time: 108.14258694648743 and batch: 1700, loss is 4.7863065624237064 and perplexity is 119.8578626028627
At time: 109.45698571205139 and batch: 1750, loss is 4.798678789138794 and perplexity is 121.34998264284764
At time: 110.77493524551392 and batch: 1800, loss is 4.74796760559082 and perplexity is 115.34961022967
At time: 112.09540963172913 and batch: 1850, loss is 4.752747821807861 and perplexity is 115.90232630580988
At time: 113.41461849212646 and batch: 1900, loss is 4.817334461212158 and perplexity is 123.6350970229777
At time: 114.73496913909912 and batch: 1950, loss is 4.747788734436035 and perplexity is 115.32897935687329
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6309723610101745 and perplexity of 102.61379326794348
finished 2 epochs...
Completing Train Step...
At time: 118.70568943023682 and batch: 50, loss is 4.703940601348877 and perplexity is 110.38128519907761
At time: 120.05447602272034 and batch: 100, loss is 4.653525943756104 and perplexity is 104.95439723363488
At time: 121.37500977516174 and batch: 150, loss is 4.59909366607666 and perplexity is 99.39419047974259
At time: 122.69381046295166 and batch: 200, loss is 4.59635142326355 and perplexity is 99.1220008508312
At time: 124.01161789894104 and batch: 250, loss is 4.607036323547363 and perplexity is 100.18678798776
At time: 125.33066487312317 and batch: 300, loss is 4.62163028717041 and perplexity is 101.65963149858496
At time: 126.6517333984375 and batch: 350, loss is 4.6268062496185305 and perplexity is 102.18718204684316
At time: 127.97289419174194 and batch: 400, loss is 4.585643892288208 and perplexity is 98.0663109588178
At time: 129.28990936279297 and batch: 450, loss is 4.5909465789794925 and perplexity is 98.58770705914503
At time: 130.60540127754211 and batch: 500, loss is 4.5885562992095945 and perplexity is 98.3523362704829
At time: 131.9224934577942 and batch: 550, loss is 4.543481855392456 and perplexity is 94.0175865184417
At time: 133.24157428741455 and batch: 600, loss is 4.522226810455322 and perplexity is 92.04032630890042
At time: 134.56202793121338 and batch: 650, loss is 4.58312954902649 and perplexity is 97.82004831480447
At time: 135.92320823669434 and batch: 700, loss is 4.606601314544678 and perplexity is 100.14321531097566
At time: 137.2406702041626 and batch: 750, loss is 4.5662947940826415 and perplexity is 96.18705585366126
At time: 138.55749559402466 and batch: 800, loss is 4.548014669418335 and perplexity is 94.44471807591457
At time: 139.87722277641296 and batch: 850, loss is 4.537799339294434 and perplexity is 93.48484515879095
At time: 141.19699048995972 and batch: 900, loss is 4.529709329605103 and perplexity is 92.73160283270421
At time: 142.51559686660767 and batch: 950, loss is 4.5999128532409665 and perplexity is 99.47564628400966
At time: 143.83642172813416 and batch: 1000, loss is 4.570131530761719 and perplexity is 96.55680912830219
At time: 145.15440773963928 and batch: 1050, loss is 4.502434883117676 and perplexity is 90.23657955082759
At time: 146.47477412223816 and batch: 1100, loss is 4.5634091854095455 and perplexity is 95.90989772831409
At time: 147.79830980300903 and batch: 1150, loss is 4.496323623657227 and perplexity is 89.68680202797941
At time: 149.118248462677 and batch: 1200, loss is 4.579634351730347 and perplexity is 97.47874475552322
At time: 150.43784093856812 and batch: 1250, loss is 4.553894500732422 and perplexity is 95.0016728822577
At time: 151.75494003295898 and batch: 1300, loss is 4.5710692214965825 and perplexity is 96.64739201634002
At time: 153.07183957099915 and batch: 1350, loss is 4.4467653560638425 and perplexity is 85.35041879840406
At time: 154.39021277427673 and batch: 1400, loss is 4.477940807342529 and perplexity is 88.05316742681727
At time: 155.71143555641174 and batch: 1450, loss is 4.404328308105469 and perplexity is 81.80417718248752
At time: 157.0316276550293 and batch: 1500, loss is 4.400733194351196 and perplexity is 81.51060988005774
At time: 158.34971165657043 and batch: 1550, loss is 4.40218225479126 and perplexity is 81.62880929864846
At time: 159.66719579696655 and batch: 1600, loss is 4.487385902404785 and perplexity is 88.88877796212054
At time: 160.9883234500885 and batch: 1650, loss is 4.43874737739563 and perplexity is 84.66881714647045
At time: 162.30851316452026 and batch: 1700, loss is 4.471923303604126 and perplexity is 87.52489818777552
At time: 163.6297504901886 and batch: 1750, loss is 4.487217807769776 and perplexity is 88.87383749117423
At time: 164.94866275787354 and batch: 1800, loss is 4.434215316772461 and perplexity is 84.28596115286514
At time: 166.26492881774902 and batch: 1850, loss is 4.454344968795777 and perplexity is 85.99979983886807
At time: 167.58248281478882 and batch: 1900, loss is 4.532111310958863 and perplexity is 92.95461013608455
At time: 168.9023997783661 and batch: 1950, loss is 4.462608480453492 and perplexity is 86.71340456715251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.513466910428779 and perplexity of 91.23758335927376
finished 3 epochs...
Completing Train Step...
At time: 172.8879611492157 and batch: 50, loss is 4.435607967376709 and perplexity is 84.40342382083739
At time: 174.23449897766113 and batch: 100, loss is 4.378235092163086 and perplexity is 79.69725090485669
At time: 175.55584478378296 and batch: 150, loss is 4.334377603530884 and perplexity is 76.27746928506346
At time: 176.87650203704834 and batch: 200, loss is 4.338380126953125 and perplexity is 76.5833834483679
At time: 178.1958658695221 and batch: 250, loss is 4.33891095161438 and perplexity is 76.62404658848855
At time: 179.51410365104675 and batch: 300, loss is 4.350530729293824 and perplexity is 77.51959392892452
At time: 180.845938205719 and batch: 350, loss is 4.364047336578369 and perplexity is 78.57450921381177
At time: 182.1640202999115 and batch: 400, loss is 4.3246299743652346 and perplexity is 75.53755685540241
At time: 183.48112201690674 and batch: 450, loss is 4.346744318008422 and perplexity is 77.2266278586686
At time: 184.79888892173767 and batch: 500, loss is 4.348561210632324 and perplexity is 77.367067892791
At time: 186.1133394241333 and batch: 550, loss is 4.308450937271118 and perplexity is 74.32526522083377
At time: 187.4274022579193 and batch: 600, loss is 4.2892138338088985 and perplexity is 72.90912727183499
At time: 188.74571919441223 and batch: 650, loss is 4.346705846786499 and perplexity is 77.22365691307816
At time: 190.06367993354797 and batch: 700, loss is 4.379417657852173 and perplexity is 79.79155388803751
At time: 191.38136219978333 and batch: 750, loss is 4.338614997863769 and perplexity is 76.60137276988007
At time: 192.69749689102173 and batch: 800, loss is 4.325295133590698 and perplexity is 75.58781807221666
At time: 194.01953721046448 and batch: 850, loss is 4.309446582794189 and perplexity is 74.39930369032105
At time: 195.34236025810242 and batch: 900, loss is 4.299212312698364 and perplexity is 73.64176416552935
At time: 196.66595911979675 and batch: 950, loss is 4.376631832122802 and perplexity is 79.56957786105315
At time: 197.98875617980957 and batch: 1000, loss is 4.349150619506836 and perplexity is 77.4126821706115
At time: 199.3137731552124 and batch: 1050, loss is 4.290681219100952 and perplexity is 73.01619158593896
At time: 200.6363022327423 and batch: 1100, loss is 4.34076231956482 and perplexity is 76.76603729053619
At time: 201.97781991958618 and batch: 1150, loss is 4.282559485435486 and perplexity is 72.42557518570567
At time: 203.3121120929718 and batch: 1200, loss is 4.368716278076172 and perplexity is 78.94222675841159
At time: 204.6278636455536 and batch: 1250, loss is 4.345989751815796 and perplexity is 77.16837723585508
At time: 205.9452133178711 and batch: 1300, loss is 4.354296178817749 and perplexity is 77.81204029745848
At time: 207.26021337509155 and batch: 1350, loss is 4.222074937820435 and perplexity is 68.17479609493267
At time: 208.5762460231781 and batch: 1400, loss is 4.262255187034607 and perplexity is 70.96985341145425
At time: 209.89314937591553 and batch: 1450, loss is 4.186043028831482 and perplexity is 65.76205687894218
At time: 211.21150541305542 and batch: 1500, loss is 4.188277015686035 and perplexity is 65.90913267106366
At time: 212.53012609481812 and batch: 1550, loss is 4.197580242156983 and perplexity is 66.52516134282777
At time: 213.84697890281677 and batch: 1600, loss is 4.289363927841187 and perplexity is 72.92007131803531
At time: 215.16189908981323 and batch: 1650, loss is 4.231119103431702 and perplexity is 68.79417691071839
At time: 216.47637748718262 and batch: 1700, loss is 4.264401245117187 and perplexity is 71.12232238410586
At time: 217.79366874694824 and batch: 1750, loss is 4.283166446685791 and perplexity is 72.46954804693593
At time: 219.1107473373413 and batch: 1800, loss is 4.224603924751282 and perplexity is 68.34742746249687
At time: 220.42858791351318 and batch: 1850, loss is 4.256057529449463 and perplexity is 70.53136675976049
At time: 221.74301838874817 and batch: 1900, loss is 4.336259088516235 and perplexity is 76.42111929353437
At time: 223.05791068077087 and batch: 1950, loss is 4.267548561096191 and perplexity is 71.34651943021494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462568700036337 and perplexity of 86.70995514035624
finished 4 epochs...
Completing Train Step...
At time: 227.0439007282257 and batch: 50, loss is 4.242425746917725 and perplexity is 69.57642209314737
At time: 228.37336921691895 and batch: 100, loss is 4.194368739128112 and perplexity is 66.31185828072373
At time: 229.68743228912354 and batch: 150, loss is 4.149162583351135 and perplexity is 63.38090184603648
At time: 231.00414085388184 and batch: 200, loss is 4.155370254516601 and perplexity is 63.77557337099594
At time: 232.32100820541382 and batch: 250, loss is 4.152676095962525 and perplexity is 63.603983113927285
At time: 233.65504717826843 and batch: 300, loss is 4.161851854324341 and perplexity is 64.19028365627871
At time: 234.97075986862183 and batch: 350, loss is 4.177965068817139 and perplexity is 65.23297344745467
At time: 236.28444528579712 and batch: 400, loss is 4.144906907081604 and perplexity is 63.11174637160937
At time: 237.60113787651062 and batch: 450, loss is 4.172265973091125 and perplexity is 64.86226185110495
At time: 238.9177951812744 and batch: 500, loss is 4.179843907356262 and perplexity is 65.3556508814468
At time: 240.23469185829163 and batch: 550, loss is 4.14255205154419 and perplexity is 62.963302177104836
At time: 241.54654479026794 and batch: 600, loss is 4.121879081726075 and perplexity is 61.675025860990026
At time: 242.86018586158752 and batch: 650, loss is 4.1734285116195675 and perplexity is 64.9377105770768
At time: 244.17496919631958 and batch: 700, loss is 4.214619812965393 and perplexity is 67.66843431846044
At time: 245.49326300621033 and batch: 750, loss is 4.172596702575683 and perplexity is 64.88371726130704
At time: 246.80956864356995 and batch: 800, loss is 4.157085390090942 and perplexity is 63.885050983294825
At time: 248.12561559677124 and batch: 850, loss is 4.143828430175781 and perplexity is 63.043718500499075
At time: 249.43982434272766 and batch: 900, loss is 4.127848587036133 and perplexity is 62.0442963398287
At time: 250.75441598892212 and batch: 950, loss is 4.218261070251465 and perplexity is 67.91528164252769
At time: 252.07167053222656 and batch: 1000, loss is 4.1834090089797975 and perplexity is 65.58906624603435
At time: 253.38813877105713 and batch: 1050, loss is 4.1320485019683835 and perplexity is 62.305425081895265
At time: 254.7058548927307 and batch: 1100, loss is 4.173031830787659 and perplexity is 64.91195614050623
At time: 256.022088766098 and batch: 1150, loss is 4.119802742004395 and perplexity is 61.54710040926683
At time: 257.3362672328949 and batch: 1200, loss is 4.208841195106507 and perplexity is 67.27853192886236
At time: 258.65172147750854 and batch: 1250, loss is 4.190949792861939 and perplexity is 66.08552872521363
At time: 259.96876668930054 and batch: 1300, loss is 4.19357771396637 and perplexity is 66.25942467318728
At time: 261.2857413291931 and batch: 1350, loss is 4.059002223014832 and perplexity is 57.91649449445907
At time: 262.60584783554077 and batch: 1400, loss is 4.105715961456299 and perplexity is 60.68617796177615
At time: 263.9235508441925 and batch: 1450, loss is 4.031884393692017 and perplexity is 56.367028905710804
At time: 265.2415392398834 and batch: 1500, loss is 4.031732592582703 and perplexity is 56.35847297761031
At time: 266.5624430179596 and batch: 1550, loss is 4.043815369606018 and perplexity is 57.04357044498089
At time: 267.8863015174866 and batch: 1600, loss is 4.136740584373474 and perplexity is 62.59845419142651
At time: 269.2056164741516 and batch: 1650, loss is 4.075028762817383 and perplexity is 58.85217331831719
At time: 270.5249488353729 and batch: 1700, loss is 4.114592952728271 and perplexity is 61.2272867897231
At time: 271.84357714653015 and batch: 1750, loss is 4.13065327167511 and perplexity is 62.218555281166694
At time: 273.1641399860382 and batch: 1800, loss is 4.070682015419006 and perplexity is 58.59691296510691
At time: 274.4860394001007 and batch: 1850, loss is 4.1111037111282345 and perplexity is 61.01402227567727
At time: 275.8068871498108 and batch: 1900, loss is 4.1872178745269775 and perplexity is 65.8393625506193
At time: 277.1270172595978 and batch: 1950, loss is 4.116601052284241 and perplexity is 61.3503608082221
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.444682844295058 and perplexity of 85.17286049458477
finished 5 epochs...
Completing Train Step...
At time: 281.1288628578186 and batch: 50, loss is 4.094252510070801 and perplexity is 59.99447712512216
At time: 282.44836163520813 and batch: 100, loss is 4.04590720653534 and perplexity is 57.16302118439449
At time: 283.7676258087158 and batch: 150, loss is 4.006976747512818 and perplexity is 54.98039941881982
At time: 285.0844192504883 and batch: 200, loss is 4.013510046005249 and perplexity is 55.34077873039458
At time: 286.400767326355 and batch: 250, loss is 4.015511522293091 and perplexity is 55.45165290577802
At time: 287.7179317474365 and batch: 300, loss is 4.017620892524719 and perplexity is 55.56874442297644
At time: 289.03443694114685 and batch: 350, loss is 4.029872550964355 and perplexity is 56.25374130515569
At time: 290.3514893054962 and batch: 400, loss is 4.009479546546936 and perplexity is 55.1181766518238
At time: 291.6649203300476 and batch: 450, loss is 4.040574188232422 and perplexity is 56.85898119219157
At time: 292.98050689697266 and batch: 500, loss is 4.046281814575195 and perplexity is 57.184438923090696
At time: 294.2974591255188 and batch: 550, loss is 4.008357558250427 and perplexity is 55.05636938269572
At time: 295.6155183315277 and batch: 600, loss is 3.991179013252258 and perplexity is 54.11865837910568
At time: 296.9323136806488 and batch: 650, loss is 4.040359411239624 and perplexity is 56.84677050253211
At time: 298.24915194511414 and batch: 700, loss is 4.081951193809509 and perplexity is 59.26098678582975
At time: 299.5837423801422 and batch: 750, loss is 4.040769200325013 and perplexity is 56.87007046233218
At time: 300.9001429080963 and batch: 800, loss is 4.0254329538345335 and perplexity is 56.00455091847388
At time: 302.21763467788696 and batch: 850, loss is 4.014754319190979 and perplexity is 55.40968063495283
At time: 303.5335605144501 and batch: 900, loss is 3.996121196746826 and perplexity is 54.386784738376065
At time: 304.85056805610657 and batch: 950, loss is 4.0900647068023686 and perplexity is 59.743757406578496
At time: 306.1637690067291 and batch: 1000, loss is 4.058441348075867 and perplexity is 57.884019692147135
At time: 307.4828519821167 and batch: 1050, loss is 4.012141551971435 and perplexity is 55.265097001683806
At time: 308.80664563179016 and batch: 1100, loss is 4.046440138816833 and perplexity is 57.193493322763246
At time: 310.1311767101288 and batch: 1150, loss is 3.9956549215316772 and perplexity is 54.361431439887625
At time: 311.4547894001007 and batch: 1200, loss is 4.08632598400116 and perplexity is 59.52080908920994
At time: 312.7761387825012 and batch: 1250, loss is 4.066682577133179 and perplexity is 58.363026247470785
At time: 314.09758949279785 and batch: 1300, loss is 4.068905715942383 and perplexity is 58.49291968822053
At time: 315.4131999015808 and batch: 1350, loss is 3.9377062129974365 and perplexity is 51.300793146233886
At time: 316.73457527160645 and batch: 1400, loss is 3.9831520700454712 and perplexity is 53.685989808025504
At time: 318.05371022224426 and batch: 1450, loss is 3.908758864402771 and perplexity is 49.837059024565335
At time: 319.36901926994324 and batch: 1500, loss is 3.9075071144104006 and perplexity is 49.774714514322206
At time: 320.68497705459595 and batch: 1550, loss is 3.9229921102523804 and perplexity is 50.55147430142598
At time: 322.0009808540344 and batch: 1600, loss is 4.021254434585571 and perplexity is 55.77102306453135
At time: 323.3185188770294 and batch: 1650, loss is 3.955822186470032 and perplexity is 52.238626184521685
At time: 324.63620162010193 and batch: 1700, loss is 3.9931402730941774 and perplexity is 54.224903283358955
At time: 325.9532263278961 and batch: 1750, loss is 4.007803974151611 and perplexity is 55.02589948667
At time: 327.2678589820862 and batch: 1800, loss is 3.9476829862594602 and perplexity is 51.81517117752298
At time: 328.5858142375946 and batch: 1850, loss is 3.993200602531433 and perplexity is 54.228174739940854
At time: 329.9018745422363 and batch: 1900, loss is 4.07104932308197 and perplexity is 58.61844001354794
At time: 331.22339963912964 and batch: 1950, loss is 4.000694370269775 and perplexity is 54.63607453060997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437772529069767 and perplexity of 84.58631811037952
finished 6 epochs...
Completing Train Step...
At time: 335.2213144302368 and batch: 50, loss is 3.9791862201690673 and perplexity is 53.47350086011612
At time: 336.5406928062439 and batch: 100, loss is 3.9319652128219604 and perplexity is 51.007119081808874
At time: 337.85918068885803 and batch: 150, loss is 3.894095630645752 and perplexity is 49.11161823036143
At time: 339.1777138710022 and batch: 200, loss is 3.9006124448776247 and perplexity is 49.432714649469624
At time: 340.4954376220703 and batch: 250, loss is 3.9015345478057863 and perplexity is 49.47831772252722
At time: 341.81148171424866 and batch: 300, loss is 3.895811243057251 and perplexity is 49.19594704924646
At time: 343.12925386428833 and batch: 350, loss is 3.913096284866333 and perplexity is 50.05369278043377
At time: 344.44919419288635 and batch: 400, loss is 3.894331703186035 and perplexity is 49.12321350344341
At time: 345.7674095630646 and batch: 450, loss is 3.9307781744003294 and perplexity is 50.946607593518195
At time: 347.084153175354 and batch: 500, loss is 3.940449824333191 and perplexity is 51.441735841420176
At time: 348.4011356830597 and batch: 550, loss is 3.9018357229232787 and perplexity is 49.49322160490724
At time: 349.7176456451416 and batch: 600, loss is 3.8842769289016723 and perplexity is 48.631765519201046
At time: 351.03701639175415 and batch: 650, loss is 3.932476201057434 and perplexity is 51.033189779927824
At time: 352.3520128726959 and batch: 700, loss is 3.973106107711792 and perplexity is 53.14936235922675
At time: 353.6685218811035 and batch: 750, loss is 3.9310174798965454 and perplexity is 50.95880085562801
At time: 354.98408007621765 and batch: 800, loss is 3.9148105001449585 and perplexity is 50.1395691696296
At time: 356.3008887767792 and batch: 850, loss is 3.9067406988143922 and perplexity is 49.73658101175373
At time: 357.61898851394653 and batch: 900, loss is 3.885434103012085 and perplexity is 48.68807351199599
At time: 358.9374876022339 and batch: 950, loss is 3.987654938697815 and perplexity is 53.928275850335524
At time: 360.25555515289307 and batch: 1000, loss is 3.9499589920043947 and perplexity is 51.93323711320462
At time: 361.5727787017822 and batch: 1050, loss is 3.908031077384949 and perplexity is 49.800801455495254
At time: 362.8890047073364 and batch: 1100, loss is 3.939146862030029 and perplexity is 51.37475284644477
At time: 364.23735785484314 and batch: 1150, loss is 3.897657871246338 and perplexity is 49.28687760347908
At time: 365.5567989349365 and batch: 1200, loss is 3.9788949584960935 and perplexity is 53.457928346744076
At time: 366.87450647354126 and batch: 1250, loss is 3.962499260902405 and perplexity is 52.58859446169036
At time: 368.1928162574768 and batch: 1300, loss is 3.966582040786743 and perplexity is 52.80374101645913
At time: 369.5083465576172 and batch: 1350, loss is 3.8365435123443605 and perplexity is 46.364937318835885
At time: 370.8260931968689 and batch: 1400, loss is 3.8799999570846557 and perplexity is 48.42421299320336
At time: 372.14403438568115 and batch: 1450, loss is 3.8074139881134035 and perplexity is 45.033830135492025
At time: 373.4623420238495 and batch: 1500, loss is 3.808652148246765 and perplexity is 45.08962376221269
At time: 374.7809724807739 and batch: 1550, loss is 3.8198439502716064 and perplexity is 45.59709235176363
At time: 376.09797167778015 and batch: 1600, loss is 3.9178375816345214 and perplexity is 50.291575683337186
At time: 377.41414642333984 and batch: 1650, loss is 3.859017653465271 and perplexity is 47.418746840063115
At time: 378.7317268848419 and batch: 1700, loss is 3.89509880065918 and perplexity is 49.16091025308683
At time: 380.0517921447754 and batch: 1750, loss is 3.91257221698761 and perplexity is 50.02746812018732
At time: 381.37032079696655 and batch: 1800, loss is 3.8470703983306884 and perplexity is 46.855593738837754
At time: 382.6874179840088 and batch: 1850, loss is 3.8923054790496825 and perplexity is 49.0237796342599
At time: 384.00336742401123 and batch: 1900, loss is 3.974494857788086 and perplexity is 53.22322481663369
At time: 385.3289656639099 and batch: 1950, loss is 3.897258133888245 and perplexity is 49.267179734486554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.455004315043604 and perplexity of 86.05652218198286
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 389.3047308921814 and batch: 50, loss is 3.9116756391525267 and perplexity is 49.98263470245301
At time: 390.6199197769165 and batch: 100, loss is 3.9015298795700075 and perplexity is 49.47808674661328
At time: 391.9362692832947 and batch: 150, loss is 3.8632635641098023 and perplexity is 47.620510634430474
At time: 393.2566192150116 and batch: 200, loss is 3.8727646684646606 and perplexity is 48.07511427392127
At time: 394.5751485824585 and batch: 250, loss is 3.8704588747024538 and perplexity is 47.964390677257214
At time: 395.8972313404083 and batch: 300, loss is 3.858157081604004 and perplexity is 47.37795715458113
At time: 397.2434380054474 and batch: 350, loss is 3.8762841176986695 and perplexity is 48.244610289382926
At time: 398.561030626297 and batch: 400, loss is 3.8484521102905274 and perplexity is 46.92037942036055
At time: 399.8809986114502 and batch: 450, loss is 3.8802227354049683 and perplexity is 48.435002059776885
At time: 401.2007968425751 and batch: 500, loss is 3.8872137451171875 and perplexity is 48.77479800402409
At time: 402.5199222564697 and batch: 550, loss is 3.8392228174209593 and perplexity is 46.48932969892379
At time: 403.8360822200775 and batch: 600, loss is 3.804589896202087 and perplexity is 44.90682987468291
At time: 405.15296697616577 and batch: 650, loss is 3.8467902326583863 and perplexity is 46.84246824865854
At time: 406.47117733955383 and batch: 700, loss is 3.8867690801620483 and perplexity is 48.7531143819884
At time: 407.7955734729767 and batch: 750, loss is 3.8348961305618285 and perplexity is 46.288619445345546
At time: 409.11381483078003 and batch: 800, loss is 3.819018898010254 and perplexity is 45.559487882567026
At time: 410.431006193161 and batch: 850, loss is 3.805229811668396 and perplexity is 44.93557564611355
At time: 411.7459509372711 and batch: 900, loss is 3.7792407703399657 and perplexity is 43.78278792234106
At time: 413.0630428791046 and batch: 950, loss is 3.8718180370330813 and perplexity is 48.029626393198484
At time: 414.3882303237915 and batch: 1000, loss is 3.820220947265625 and perplexity is 45.61428555920636
At time: 415.7055938243866 and batch: 1050, loss is 3.7733495569229127 and perplexity is 43.525612456277436
At time: 417.0225749015808 and batch: 1100, loss is 3.7960057926177977 and perplexity is 44.52299479241243
At time: 418.33811807632446 and batch: 1150, loss is 3.7492493104934694 and perplexity is 42.4891738480549
At time: 419.6555423736572 and batch: 1200, loss is 3.8120650386810304 and perplexity is 45.24377260476566
At time: 420.97394728660583 and batch: 1250, loss is 3.7871248435974123 and perplexity is 44.12933895149432
At time: 422.292964220047 and batch: 1300, loss is 3.805474514961243 and perplexity is 44.9465728749143
At time: 423.610102891922 and batch: 1350, loss is 3.67743679523468 and perplexity is 39.544902373927684
At time: 424.9264039993286 and batch: 1400, loss is 3.70251033782959 and perplexity is 40.54896831034876
At time: 426.24158930778503 and batch: 1450, loss is 3.61407187461853 and perplexity is 37.116880814983226
At time: 427.55820751190186 and batch: 1500, loss is 3.600591549873352 and perplexity is 36.6198905293239
At time: 428.8782856464386 and batch: 1550, loss is 3.610640077590942 and perplexity is 36.98972153095417
At time: 430.1974587440491 and batch: 1600, loss is 3.698770523071289 and perplexity is 40.3976058903495
At time: 431.51447463035583 and batch: 1650, loss is 3.6265055179595946 and perplexity is 37.58125985207077
At time: 432.83044481277466 and batch: 1700, loss is 3.6481423568725586 and perplexity is 38.40326019389773
At time: 434.1486711502075 and batch: 1750, loss is 3.653670015335083 and perplexity is 38.61612808859206
At time: 435.4689681529999 and batch: 1800, loss is 3.5772190618515016 and perplexity is 35.773917336414236
At time: 436.78779649734497 and batch: 1850, loss is 3.61288920879364 and perplexity is 37.07300989594867
At time: 438.1059641838074 and batch: 1900, loss is 3.6963933372497557 and perplexity is 40.30168732769639
At time: 439.4222106933594 and batch: 1950, loss is 3.621399259567261 and perplexity is 37.389849340223876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39549077943314 and perplexity of 81.08441556265447
finished 8 epochs...
Completing Train Step...
At time: 443.37174797058105 and batch: 50, loss is 3.817299838066101 and perplexity is 45.48123567126369
At time: 444.72177362442017 and batch: 100, loss is 3.788418970108032 and perplexity is 44.18648486797483
At time: 446.037798166275 and batch: 150, loss is 3.737631278038025 and perplexity is 41.99838974056465
At time: 447.3566040992737 and batch: 200, loss is 3.7465115690231325 and perplexity is 42.37300856258754
At time: 448.6747581958771 and batch: 250, loss is 3.74125581741333 and perplexity is 42.15089076390659
At time: 449.99359250068665 and batch: 300, loss is 3.7314975118637084 and perplexity is 41.74156987988122
At time: 451.31220054626465 and batch: 350, loss is 3.7493275117874147 and perplexity is 42.49249668635192
At time: 452.62886118888855 and batch: 400, loss is 3.727033381462097 and perplexity is 41.55564537315656
At time: 453.9459331035614 and batch: 450, loss is 3.7615429019927977 and perplexity is 43.014742337458415
At time: 455.2644684314728 and batch: 500, loss is 3.7721610689163207 and perplexity is 43.473913515764366
At time: 456.5849287509918 and batch: 550, loss is 3.727118821144104 and perplexity is 41.559196025964
At time: 457.9095928668976 and batch: 600, loss is 3.6994633054733277 and perplexity is 40.42560233739801
At time: 459.23527669906616 and batch: 650, loss is 3.736510491371155 and perplexity is 41.95134487386775
At time: 460.5592873096466 and batch: 700, loss is 3.781629800796509 and perplexity is 43.887511380116166
At time: 461.87500858306885 and batch: 750, loss is 3.7324126243591307 and perplexity is 41.77978559522924
At time: 463.20360827445984 and batch: 800, loss is 3.7156155157089232 and perplexity is 41.083867069045084
At time: 464.51886010169983 and batch: 850, loss is 3.7107208251953123 and perplexity is 40.883265596203444
At time: 465.8385548591614 and batch: 900, loss is 3.6860930633544924 and perplexity is 39.88869950496885
At time: 467.1542980670929 and batch: 950, loss is 3.778579897880554 and perplexity is 43.75386264262006
At time: 468.47167706489563 and batch: 1000, loss is 3.732313084602356 and perplexity is 41.775627052506586
At time: 469.78874468803406 and batch: 1050, loss is 3.6876245641708376 and perplexity is 39.94983588408133
At time: 471.1093716621399 and batch: 1100, loss is 3.7107376575469972 and perplexity is 40.88395376349971
At time: 472.4271595478058 and batch: 1150, loss is 3.6667608404159546 and perplexity is 39.1249683696271
At time: 473.74263548851013 and batch: 1200, loss is 3.7339441633224486 and perplexity is 41.843821989346694
At time: 475.0587589740753 and batch: 1250, loss is 3.7106533336639402 and perplexity is 40.88050641511259
At time: 476.37691617012024 and batch: 1300, loss is 3.7265096044540407 and perplexity is 41.53388518079685
At time: 477.695604801178 and batch: 1350, loss is 3.6051944065093995 and perplexity is 36.788835151119216
At time: 479.01298451423645 and batch: 1400, loss is 3.635206518173218 and perplexity is 37.90968112687206
At time: 480.3305342197418 and batch: 1450, loss is 3.547459616661072 and perplexity is 34.72499055551886
At time: 481.6456537246704 and batch: 1500, loss is 3.536948676109314 and perplexity is 34.361909747278816
At time: 482.9644367694855 and batch: 1550, loss is 3.552186508178711 and perplexity is 34.88952036976993
At time: 484.2819800376892 and batch: 1600, loss is 3.6415589475631713 and perplexity is 38.15126621313029
At time: 485.6004695892334 and batch: 1650, loss is 3.573380832672119 and perplexity is 35.63687201695079
At time: 486.9186828136444 and batch: 1700, loss is 3.5990821313858032 and perplexity is 36.564657484922755
At time: 488.23476362228394 and batch: 1750, loss is 3.609721827507019 and perplexity is 36.95577130583813
At time: 489.55065083503723 and batch: 1800, loss is 3.536711597442627 and perplexity is 34.3537642371326
At time: 490.8695023059845 and batch: 1850, loss is 3.576877875328064 and perplexity is 35.76171383988114
At time: 492.1885070800781 and batch: 1900, loss is 3.6611496591567994 and perplexity is 38.90604586168739
At time: 493.507285118103 and batch: 1950, loss is 3.592828516960144 and perplexity is 36.33670970703729
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.408541515261628 and perplexity of 82.14956220560805
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 497.4721944332123 and batch: 50, loss is 3.7761859941482543 and perplexity is 43.64924537932738
At time: 498.80253553390503 and batch: 100, loss is 3.7833918380737304 and perplexity is 43.96491098163828
At time: 500.12047243118286 and batch: 150, loss is 3.7522728872299194 and perplexity is 42.61783753990516
At time: 501.4343967437744 and batch: 200, loss is 3.7667539596557615 and perplexity is 43.23947969122724
At time: 502.7488715648651 and batch: 250, loss is 3.7615849590301513 and perplexity is 43.01655144812631
At time: 504.06597447395325 and batch: 300, loss is 3.753714656829834 and perplexity is 42.6793269586201
At time: 505.3849141597748 and batch: 350, loss is 3.7772484970092775 and perplexity is 43.69564747423839
At time: 506.70444083213806 and batch: 400, loss is 3.7431675243377684 and perplexity is 42.23154798557146
At time: 508.02438974380493 and batch: 450, loss is 3.776582794189453 and perplexity is 43.666568838439545
At time: 509.3410382270813 and batch: 500, loss is 3.7835487508773804 and perplexity is 43.97181018035479
At time: 510.65787982940674 and batch: 550, loss is 3.74183132648468 and perplexity is 42.17515596565882
At time: 511.9756224155426 and batch: 600, loss is 3.7117323684692383 and perplexity is 40.9246417118711
At time: 513.2969090938568 and batch: 650, loss is 3.747701892852783 and perplexity is 42.4234761948674
At time: 514.6167032718658 and batch: 700, loss is 3.7942677545547485 and perplexity is 44.445679340843846
At time: 515.9326543807983 and batch: 750, loss is 3.738668456077576 and perplexity is 42.0419721455498
At time: 517.2474148273468 and batch: 800, loss is 3.713706555366516 and perplexity is 41.00551440595477
At time: 518.564640045166 and batch: 850, loss is 3.713150882720947 and perplexity is 40.98273509278864
At time: 519.8838908672333 and batch: 900, loss is 3.694555711746216 and perplexity is 40.2276959242939
At time: 521.2028985023499 and batch: 950, loss is 3.8030561923980715 and perplexity is 44.83800888787279
At time: 522.5201840400696 and batch: 1000, loss is 3.7427785348892213 and perplexity is 42.215123553681714
At time: 523.8370711803436 and batch: 1050, loss is 3.6818165588378906 and perplexity is 39.718479534033854
At time: 525.1539690494537 and batch: 1100, loss is 3.6937961959838868 and perplexity is 40.197153955178905
At time: 526.4750022888184 and batch: 1150, loss is 3.6480742788314817 and perplexity is 38.400645864162996
At time: 527.7948076725006 and batch: 1200, loss is 3.6993954372406006 and perplexity is 40.42285881631046
At time: 529.1435930728912 and batch: 1250, loss is 3.6677089023590086 and perplexity is 39.16207885189986
At time: 530.4595909118652 and batch: 1300, loss is 3.6822879409790037 and perplexity is 39.737206529397184
At time: 531.7816123962402 and batch: 1350, loss is 3.572595820426941 and perplexity is 35.60890761367321
At time: 533.1030278205872 and batch: 1400, loss is 3.6138506507873536 and perplexity is 37.108670584590804
At time: 534.4228227138519 and batch: 1450, loss is 3.529808216094971 and perplexity is 34.11742381450796
At time: 535.7402982711792 and batch: 1500, loss is 3.506001043319702 and perplexity is 33.31477670047114
At time: 537.0565421581268 and batch: 1550, loss is 3.5099096727371215 and perplexity is 33.445246629916305
At time: 538.3721971511841 and batch: 1600, loss is 3.590998396873474 and perplexity is 36.270269979602915
At time: 539.687561750412 and batch: 1650, loss is 3.5222883129119875 and perplexity is 33.86182632922115
At time: 541.0046360492706 and batch: 1700, loss is 3.533957076072693 and perplexity is 34.25926626749154
At time: 542.317939043045 and batch: 1750, loss is 3.5377660751342774 and perplexity is 34.39000862123371
At time: 543.6304025650024 and batch: 1800, loss is 3.4648238468170165 and perplexity is 31.970827514045702
At time: 544.940756559372 and batch: 1850, loss is 3.494530005455017 and perplexity is 32.93480513611582
At time: 546.2520053386688 and batch: 1900, loss is 3.583692650794983 and perplexity is 36.006254187398454
At time: 547.5671420097351 and batch: 1950, loss is 3.53590416431427 and perplexity is 34.32603706522875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385360930686773 and perplexity of 80.26718887689482
finished 10 epochs...
Completing Train Step...
At time: 551.4940845966339 and batch: 50, loss is 3.7848745012283325 and perplexity is 44.030144482950355
At time: 552.8181338310242 and batch: 100, loss is 3.765680708885193 and perplexity is 43.19309778049251
At time: 554.1321203708649 and batch: 150, loss is 3.7180218172073363 and perplexity is 41.18284627908481
At time: 555.4454915523529 and batch: 200, loss is 3.7213071250915526 and perplexity is 41.31836710057916
At time: 556.7599420547485 and batch: 250, loss is 3.7142984008789064 and perplexity is 41.029790518784786
At time: 558.0736362934113 and batch: 300, loss is 3.7020931386947633 and perplexity is 40.532054844238615
At time: 559.3846678733826 and batch: 350, loss is 3.7268816232681274 and perplexity is 41.54933944196595
At time: 560.70964884758 and batch: 400, loss is 3.692581362724304 and perplexity is 40.14835076548465
At time: 562.0290939807892 and batch: 450, loss is 3.7275361585617066 and perplexity is 41.57654385320803
At time: 563.3440701961517 and batch: 500, loss is 3.732907524108887 and perplexity is 41.80046751798226
At time: 564.6588177680969 and batch: 550, loss is 3.6929739570617675 and perplexity is 40.164115875097565
At time: 565.9816896915436 and batch: 600, loss is 3.6638965511322024 and perplexity is 39.013063482490395
At time: 567.300933599472 and batch: 650, loss is 3.700175323486328 and perplexity is 40.45439634415789
At time: 568.6271932125092 and batch: 700, loss is 3.749321904182434 and perplexity is 42.492258405883945
At time: 569.9486916065216 and batch: 750, loss is 3.6960365390777588 and perplexity is 40.28731032432626
At time: 571.2698972225189 and batch: 800, loss is 3.669797773361206 and perplexity is 39.2439688818774
At time: 572.5882177352905 and batch: 850, loss is 3.6690814447402955 and perplexity is 39.21586736992947
At time: 573.902197599411 and batch: 900, loss is 3.6499269914627077 and perplexity is 38.47185717247831
At time: 575.216924905777 and batch: 950, loss is 3.75884437084198 and perplexity is 42.89882219272206
At time: 576.5321743488312 and batch: 1000, loss is 3.7023560619354248 and perplexity is 40.542713064534446
At time: 577.8466761112213 and batch: 1050, loss is 3.6464746046066283 and perplexity is 38.339266447380794
At time: 579.1594302654266 and batch: 1100, loss is 3.6617879343032835 and perplexity is 38.93088655056271
At time: 580.4714047908783 and batch: 1150, loss is 3.6180507230758665 and perplexity is 37.26485745204107
At time: 581.7966573238373 and batch: 1200, loss is 3.670017971992493 and perplexity is 39.25261130160102
At time: 583.1257791519165 and batch: 1250, loss is 3.6405218839645386 and perplexity is 38.11172143246938
At time: 584.4392488002777 and batch: 1300, loss is 3.656387457847595 and perplexity is 38.72120790624703
At time: 585.7539248466492 and batch: 1350, loss is 3.54695595741272 and perplexity is 34.707505396527274
At time: 587.0667409896851 and batch: 1400, loss is 3.5913350915908815 and perplexity is 36.28248404399408
At time: 588.3781456947327 and batch: 1450, loss is 3.5082984352111817 and perplexity is 33.39140178354921
At time: 589.6915853023529 and batch: 1500, loss is 3.4859598159790037 and perplexity is 32.653753668133994
At time: 591.0054888725281 and batch: 1550, loss is 3.4931976318359377 and perplexity is 32.89095289087757
At time: 592.3206379413605 and batch: 1600, loss is 3.578124933242798 and perplexity is 35.8063385872086
At time: 593.6332411766052 and batch: 1650, loss is 3.5117220783233645 and perplexity is 33.505917945649585
At time: 594.9471793174744 and batch: 1700, loss is 3.52551157951355 and perplexity is 33.97114811507723
At time: 596.2637000083923 and batch: 1750, loss is 3.5322126388549804 and perplexity is 34.199555224587805
At time: 597.5791349411011 and batch: 1800, loss is 3.461037588119507 and perplexity is 31.850006564328186
At time: 598.8945941925049 and batch: 1850, loss is 3.493699984550476 and perplexity is 32.907479901192744
At time: 600.2071948051453 and batch: 1900, loss is 3.582853441238403 and perplexity is 35.97605007035225
At time: 601.5213057994843 and batch: 1950, loss is 3.536364212036133 and perplexity is 34.341832313386575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389393509265989 and perplexity of 80.5915261416041
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 605.4827671051025 and batch: 50, loss is 3.7772799062728883 and perplexity is 43.69701994390258
At time: 606.7968144416809 and batch: 100, loss is 3.7789082765579223 and perplexity is 43.76823283746805
At time: 608.1082804203033 and batch: 150, loss is 3.7504062366485598 and perplexity is 42.5383591309719
At time: 609.421448469162 and batch: 200, loss is 3.762128081321716 and perplexity is 43.039921041823206
At time: 610.7369065284729 and batch: 250, loss is 3.7627539443969726 and perplexity is 43.06686657039136
At time: 612.0506467819214 and batch: 300, loss is 3.75471161365509 and perplexity is 42.72189762195953
At time: 613.3658261299133 and batch: 350, loss is 3.7892841482162476 and perplexity is 44.22473058965648
At time: 614.6778011322021 and batch: 400, loss is 3.7574650859832763 and perplexity is 42.839693283993704
At time: 615.9900813102722 and batch: 450, loss is 3.7820505619049074 and perplexity is 43.90598142351479
At time: 617.3054423332214 and batch: 500, loss is 3.7819564867019655 and perplexity is 43.90185115368304
At time: 618.6209523677826 and batch: 550, loss is 3.7359630632400513 and perplexity is 41.928385812337595
At time: 619.9346919059753 and batch: 600, loss is 3.693403415679932 and perplexity is 40.18136840515977
At time: 621.2484006881714 and batch: 650, loss is 3.719807801246643 and perplexity is 41.25646390561707
At time: 622.5609681606293 and batch: 700, loss is 3.771593928337097 and perplexity is 43.44926468560851
At time: 623.8738334178925 and batch: 750, loss is 3.722543125152588 and perplexity is 41.36946817879968
At time: 625.1880021095276 and batch: 800, loss is 3.7015488529205323 and perplexity is 40.50999982604735
At time: 626.5378322601318 and batch: 850, loss is 3.699463586807251 and perplexity is 40.42561371049291
At time: 627.8551371097565 and batch: 900, loss is 3.664124774932861 and perplexity is 39.02196820821024
At time: 629.1665239334106 and batch: 950, loss is 3.786382780075073 and perplexity is 44.0966043258814
At time: 630.4804520606995 and batch: 1000, loss is 3.73634428024292 and perplexity is 41.944372672950024
At time: 631.7958176136017 and batch: 1050, loss is 3.6787102699279783 and perplexity is 39.59529388569718
At time: 633.1078009605408 and batch: 1100, loss is 3.7011395406723024 and perplexity is 40.493421979931945
At time: 634.4217145442963 and batch: 1150, loss is 3.6646185445785524 and perplexity is 39.04124082935267
At time: 635.7321422100067 and batch: 1200, loss is 3.7064536905288694 and perplexity is 40.709182877649866
At time: 637.0423452854156 and batch: 1250, loss is 3.668837699890137 and perplexity is 39.206309869056675
At time: 638.3551440238953 and batch: 1300, loss is 3.6646400833129884 and perplexity is 39.04208173732696
At time: 639.6690599918365 and batch: 1350, loss is 3.540357036590576 and perplexity is 34.47922733927188
At time: 640.9839901924133 and batch: 1400, loss is 3.5852812337875366 and perplexity is 36.063498567111665
At time: 642.2982378005981 and batch: 1450, loss is 3.517799892425537 and perplexity is 33.710180793268044
At time: 643.611644744873 and batch: 1500, loss is 3.5055335903167726 and perplexity is 33.299207247337904
At time: 644.925815820694 and batch: 1550, loss is 3.5190728378295897 and perplexity is 33.75311933639108
At time: 646.2416400909424 and batch: 1600, loss is 3.6017964982986452 and perplexity is 36.664042203654866
At time: 647.5567831993103 and batch: 1650, loss is 3.530829544067383 and perplexity is 34.15228669398287
At time: 648.8712995052338 and batch: 1700, loss is 3.526737608909607 and perplexity is 34.01282328355461
At time: 650.1846420764923 and batch: 1750, loss is 3.526428418159485 and perplexity is 34.002308458836836
At time: 651.4978537559509 and batch: 1800, loss is 3.4520608520507814 and perplexity is 31.565376895647695
At time: 652.8140997886658 and batch: 1850, loss is 3.464418020248413 and perplexity is 31.957855535185132
At time: 654.1282258033752 and batch: 1900, loss is 3.5455968236923217 and perplexity is 34.66036529769751
At time: 655.4441990852356 and batch: 1950, loss is 3.5139165496826172 and perplexity is 33.57952645929455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378632585392442 and perplexity of 79.7289363194413
finished 12 epochs...
Completing Train Step...
At time: 659.3941810131073 and batch: 50, loss is 3.783230185508728 and perplexity is 43.95780451541272
At time: 660.7092950344086 and batch: 100, loss is 3.7703080320358278 and perplexity is 43.393429343779964
At time: 662.0247025489807 and batch: 150, loss is 3.7352930068969727 and perplexity is 41.900300841776115
At time: 663.336676120758 and batch: 200, loss is 3.743351225852966 and perplexity is 42.239306697547306
At time: 664.6509735584259 and batch: 250, loss is 3.741642031669617 and perplexity is 42.167173182883566
At time: 665.9674234390259 and batch: 300, loss is 3.732556366920471 and perplexity is 41.78579156026901
At time: 667.2845115661621 and batch: 350, loss is 3.765575604438782 and perplexity is 43.18855823242903
At time: 668.5980722904205 and batch: 400, loss is 3.7371074676513674 and perplexity is 41.9763963084926
At time: 669.9113643169403 and batch: 450, loss is 3.7669370651245115 and perplexity is 43.24739780132711
At time: 671.2231373786926 and batch: 500, loss is 3.770559163093567 and perplexity is 43.4043281500471
At time: 672.5362775325775 and batch: 550, loss is 3.727107253074646 and perplexity is 41.55871526907846
At time: 673.8586957454681 and batch: 600, loss is 3.684461078643799 and perplexity is 39.823654847626955
At time: 675.1702437400818 and batch: 650, loss is 3.705404968261719 and perplexity is 40.66651262961899
At time: 676.4829792976379 and batch: 700, loss is 3.756967349052429 and perplexity is 42.81837569225654
At time: 677.7946906089783 and batch: 750, loss is 3.7051171875 and perplexity is 40.65481127343134
At time: 679.1086299419403 and batch: 800, loss is 3.6818975973129273 and perplexity is 39.72169838946988
At time: 680.4241125583649 and batch: 850, loss is 3.678580870628357 and perplexity is 39.590170613881114
At time: 681.7390847206116 and batch: 900, loss is 3.643305163383484 and perplexity is 38.21794475837851
At time: 683.0553126335144 and batch: 950, loss is 3.76587176322937 and perplexity is 43.20135079782425
At time: 684.3679070472717 and batch: 1000, loss is 3.7173630380630494 and perplexity is 41.15572481336264
At time: 685.6806828975677 and batch: 1050, loss is 3.66213641166687 and perplexity is 38.944455447359324
At time: 686.9941236972809 and batch: 1100, loss is 3.6858662223815917 and perplexity is 39.87965213976075
At time: 688.3159227371216 and batch: 1150, loss is 3.6500027656555174 and perplexity is 38.47477245685171
At time: 689.6308538913727 and batch: 1200, loss is 3.6935312938690186 and perplexity is 40.18650705434003
At time: 690.944995880127 and batch: 1250, loss is 3.6562902688980103 and perplexity is 38.71744481559235
At time: 692.2573227882385 and batch: 1300, loss is 3.654275097846985 and perplexity is 38.63950110296384
At time: 693.5715584754944 and batch: 1350, loss is 3.530854482650757 and perplexity is 34.153138414252304
At time: 694.8877165317535 and batch: 1400, loss is 3.576786117553711 and perplexity is 35.75843257515522
At time: 696.2026424407959 and batch: 1450, loss is 3.510174899101257 and perplexity is 33.454118367534925
At time: 697.517383813858 and batch: 1500, loss is 3.499379448890686 and perplexity is 33.09490850303526
At time: 698.8291275501251 and batch: 1550, loss is 3.513631362915039 and perplexity is 33.569951388093514
At time: 700.1419019699097 and batch: 1600, loss is 3.598937363624573 and perplexity is 36.55936448445567
At time: 701.456426858902 and batch: 1650, loss is 3.5294362545013427 and perplexity is 34.10473580304819
At time: 702.771871805191 and batch: 1700, loss is 3.5271934986114504 and perplexity is 34.0283329144921
At time: 704.0866656303406 and batch: 1750, loss is 3.5281055116653444 and perplexity is 34.059381354451546
At time: 705.3990797996521 and batch: 1800, loss is 3.4544380140304565 and perplexity is 31.64050216656991
At time: 706.7112908363342 and batch: 1850, loss is 3.468359389305115 and perplexity is 32.0840617874407
At time: 708.025398015976 and batch: 1900, loss is 3.549202175140381 and perplexity is 34.78555363428349
At time: 709.3405768871307 and batch: 1950, loss is 3.5171691751480103 and perplexity is 33.688925903430906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3773900231649705 and perplexity of 79.62992967842904
finished 13 epochs...
Completing Train Step...
At time: 713.2879655361176 and batch: 50, loss is 3.7752379179000854 and perplexity is 43.60788217736568
At time: 714.6015150547028 and batch: 100, loss is 3.7601716709136963 and perplexity is 42.95579960719327
At time: 715.9178805351257 and batch: 150, loss is 3.7248012256622314 and perplexity is 41.46299014724103
At time: 717.2322187423706 and batch: 200, loss is 3.7320878505706787 and perplexity is 41.766218819166646
At time: 718.5455696582794 and batch: 250, loss is 3.7299547481536863 and perplexity is 41.677222150105294
At time: 719.8567233085632 and batch: 300, loss is 3.721183476448059 and perplexity is 41.31325845638078
At time: 721.1699335575104 and batch: 350, loss is 3.7548179626464844 and perplexity is 42.72644129428527
At time: 722.4843378067017 and batch: 400, loss is 3.727420425415039 and perplexity is 41.57173234739107
At time: 723.8112056255341 and batch: 450, loss is 3.757568483352661 and perplexity is 42.844123024592335
At time: 725.1258623600006 and batch: 500, loss is 3.761911978721619 and perplexity is 43.03062100789503
At time: 726.4384000301361 and batch: 550, loss is 3.7192789363861083 and perplexity is 41.23465058024653
At time: 727.7529218196869 and batch: 600, loss is 3.677057704925537 and perplexity is 39.52991412579103
At time: 729.0679943561554 and batch: 650, loss is 3.695812029838562 and perplexity is 40.2782664661889
At time: 730.3832459449768 and batch: 700, loss is 3.7469990158081057 and perplexity is 42.39366818420502
At time: 731.6976494789124 and batch: 750, loss is 3.6945521211624146 and perplexity is 40.22755148363986
At time: 733.0129010677338 and batch: 800, loss is 3.6707079124450686 and perplexity is 39.279702610627574
At time: 734.324875831604 and batch: 850, loss is 3.6672614765167237 and perplexity is 39.144560645125374
At time: 735.6386284828186 and batch: 900, loss is 3.6328058195114137 and perplexity is 37.818780562210996
At time: 736.9543304443359 and batch: 950, loss is 3.7550203895568846 and perplexity is 42.73509115124124
At time: 738.2692718505859 and batch: 1000, loss is 3.707423768043518 and perplexity is 40.74869310149064
At time: 739.5835108757019 and batch: 1050, loss is 3.6531935596466063 and perplexity is 38.597733597125334
At time: 740.8959879875183 and batch: 1100, loss is 3.6775485038757325 and perplexity is 39.54932012797848
At time: 742.2101616859436 and batch: 1150, loss is 3.6420751142501833 and perplexity is 38.17096370897509
At time: 743.5258641242981 and batch: 1200, loss is 3.686539044380188 and perplexity is 39.906493075590255
At time: 744.8416557312012 and batch: 1250, loss is 3.649464101791382 and perplexity is 38.45405306814236
At time: 746.1555111408234 and batch: 1300, loss is 3.64819465637207 and perplexity is 38.40526871770742
At time: 747.468023777008 and batch: 1350, loss is 3.5249137020111085 and perplexity is 33.95084360029824
At time: 748.7828180789948 and batch: 1400, loss is 3.5713348245620726 and perplexity is 35.564033227573816
At time: 750.098629951477 and batch: 1450, loss is 3.505444760322571 and perplexity is 33.29624941032547
At time: 751.4145622253418 and batch: 1500, loss is 3.4952602052688597 and perplexity is 32.95886290711616
At time: 752.7286460399628 and batch: 1550, loss is 3.5100781440734865 and perplexity is 33.450881669969135
At time: 754.0453016757965 and batch: 1600, loss is 3.596682939529419 and perplexity is 36.47703700765072
At time: 755.3571619987488 and batch: 1650, loss is 3.527842574119568 and perplexity is 34.05042704157166
At time: 756.6726551055908 and batch: 1700, loss is 3.5261882066726686 and perplexity is 33.9941416946813
At time: 757.988038778305 and batch: 1750, loss is 3.527615337371826 and perplexity is 34.04269041232803
At time: 759.3022923469543 and batch: 1800, loss is 3.453984160423279 and perplexity is 31.626145268740075
At time: 760.6164820194244 and batch: 1850, loss is 3.468638153076172 and perplexity is 32.093006908225284
At time: 761.9265344142914 and batch: 1900, loss is 3.5489177894592285 and perplexity is 34.77566252743018
At time: 763.2391273975372 and batch: 1950, loss is 3.5163993358612062 and perplexity is 33.6630008250925
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377477175690407 and perplexity of 79.63686993032668
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 767.1818103790283 and batch: 50, loss is 3.771800742149353 and perplexity is 43.45825152294687
At time: 768.5068225860596 and batch: 100, loss is 3.7640107583999636 and perplexity is 43.121027639427645
At time: 769.819929599762 and batch: 150, loss is 3.737403197288513 and perplexity is 41.988811808666796
At time: 771.1347851753235 and batch: 200, loss is 3.752980637550354 and perplexity is 42.648011004460336
At time: 772.4508671760559 and batch: 250, loss is 3.7558561038970946 and perplexity is 42.77082040739288
At time: 773.7676451206207 and batch: 300, loss is 3.755492858886719 and perplexity is 42.75528694168798
At time: 775.0842177867889 and batch: 350, loss is 3.7989082622528074 and perplexity is 44.65240915263011
At time: 776.4011063575745 and batch: 400, loss is 3.783460760116577 and perplexity is 43.96794123754122
At time: 777.7181284427643 and batch: 450, loss is 3.8179496145248413 and perplexity is 45.510797910900855
At time: 779.0376009941101 and batch: 500, loss is 3.82332932472229 and perplexity is 45.756292567492686
At time: 780.3543491363525 and batch: 550, loss is 3.790184473991394 and perplexity is 44.26456518387044
At time: 781.6723909378052 and batch: 600, loss is 3.7478944206237794 and perplexity is 42.43164467848186
At time: 782.9876432418823 and batch: 650, loss is 3.750057063102722 and perplexity is 42.52350845416265
At time: 784.3031988143921 and batch: 700, loss is 3.7989050436019896 and perplexity is 44.652265432348166
At time: 785.6207404136658 and batch: 750, loss is 3.732765531539917 and perplexity is 41.7945325835835
At time: 786.9380443096161 and batch: 800, loss is 3.6945099067687988 and perplexity is 40.22585333779068
At time: 788.2609069347382 and batch: 850, loss is 3.6937231063842773 and perplexity is 40.19421606865666
At time: 789.6034381389618 and batch: 900, loss is 3.6535746669769287 and perplexity is 38.61244627971055
At time: 790.9168937206268 and batch: 950, loss is 3.7743726062774656 and perplexity is 43.57016409138236
At time: 792.2313735485077 and batch: 1000, loss is 3.725691170692444 and perplexity is 41.499906353521006
At time: 793.5490479469299 and batch: 1050, loss is 3.6710987520217895 and perplexity is 39.2950576734573
At time: 794.8632867336273 and batch: 1100, loss is 3.6911991930007932 and perplexity is 40.09289726251231
At time: 796.1767964363098 and batch: 1150, loss is 3.659605374336243 and perplexity is 38.84601021363646
At time: 797.4916398525238 and batch: 1200, loss is 3.7107360792160033 and perplexity is 40.88388923513926
At time: 798.804675579071 and batch: 1250, loss is 3.6809211444854735 and perplexity is 39.682930955131916
At time: 800.1199517250061 and batch: 1300, loss is 3.6772990083694457 and perplexity is 39.53945398116068
At time: 801.4356999397278 and batch: 1350, loss is 3.5384154415130613 and perplexity is 34.41234758890071
At time: 802.7600991725922 and batch: 1400, loss is 3.5731203079223635 and perplexity is 35.627588939074776
At time: 804.0761134624481 and batch: 1450, loss is 3.4948407983779908 and perplexity is 32.94504263125976
At time: 805.3895363807678 and batch: 1500, loss is 3.4756633043289185 and perplexity is 32.31925893274521
At time: 806.7080495357513 and batch: 1550, loss is 3.49528564453125 and perplexity is 32.959701366942596
At time: 808.0266647338867 and batch: 1600, loss is 3.5848486948013307 and perplexity is 36.04790307107558
At time: 809.349371433258 and batch: 1650, loss is 3.5212904834747314 and perplexity is 33.828054853998744
At time: 810.6618416309357 and batch: 1700, loss is 3.528751239776611 and perplexity is 34.08138155675457
At time: 811.97558426857 and batch: 1750, loss is 3.5390324115753176 and perplexity is 34.43358552804765
At time: 813.2901840209961 and batch: 1800, loss is 3.465826849937439 and perplexity is 32.00291044075292
At time: 814.6065266132355 and batch: 1850, loss is 3.4804678773880005 and perplexity is 32.47491279926475
At time: 815.9211094379425 and batch: 1900, loss is 3.559104156494141 and perplexity is 35.131710528944986
At time: 817.2395062446594 and batch: 1950, loss is 3.5248549079895017 and perplexity is 33.94884755234446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361673896257267 and perplexity of 78.38823844415259
finished 15 epochs...
Completing Train Step...
At time: 821.2702205181122 and batch: 50, loss is 3.774797568321228 and perplexity is 43.588683692146674
At time: 822.5942113399506 and batch: 100, loss is 3.755012879371643 and perplexity is 42.73477020399556
At time: 823.9075655937195 and batch: 150, loss is 3.72013370513916 and perplexity is 41.269911739026995
At time: 825.2198965549469 and batch: 200, loss is 3.728427734375 and perplexity is 41.61362902377183
At time: 826.531754732132 and batch: 250, loss is 3.7315634441375733 and perplexity is 41.74432208722674
At time: 827.8446321487427 and batch: 300, loss is 3.7272646617889404 and perplexity is 41.56525748790432
At time: 829.1597034931183 and batch: 350, loss is 3.770154504776001 and perplexity is 43.386767780857156
At time: 830.4746589660645 and batch: 400, loss is 3.7528574419021608 and perplexity is 42.64275727872521
At time: 831.7888259887695 and batch: 450, loss is 3.7878085374832153 and perplexity is 44.15952022692107
At time: 833.1028063297272 and batch: 500, loss is 3.795592098236084 and perplexity is 44.504579688984784
At time: 834.4178297519684 and batch: 550, loss is 3.7613812255859376 and perplexity is 43.007788430631756
At time: 835.7329704761505 and batch: 600, loss is 3.722875199317932 and perplexity is 41.38320819164127
At time: 837.0475783348083 and batch: 650, loss is 3.7304446935653686 and perplexity is 41.69764671692222
At time: 838.361471414566 and batch: 700, loss is 3.7815108060836793 and perplexity is 43.88228930900827
At time: 839.6736164093018 and batch: 750, loss is 3.717958631515503 and perplexity is 41.18024419465912
At time: 840.9869956970215 and batch: 800, loss is 3.685273013114929 and perplexity is 39.85600217594255
At time: 842.3024005889893 and batch: 850, loss is 3.6830434656143187 and perplexity is 39.76724031207145
At time: 843.6173138618469 and batch: 900, loss is 3.6403835678100585 and perplexity is 38.10645033026792
At time: 844.9322769641876 and batch: 950, loss is 3.760456066131592 and perplexity is 42.968017768493404
At time: 846.2448244094849 and batch: 1000, loss is 3.7112140083312988 and perplexity is 40.9034335061673
At time: 847.5558211803436 and batch: 1050, loss is 3.6569839191436766 and perplexity is 38.74431049731642
At time: 848.8693273067474 and batch: 1100, loss is 3.6783968019485473 and perplexity is 39.58288397408443
At time: 850.1839509010315 and batch: 1150, loss is 3.6471184062957764 and perplexity is 38.363957279027055
At time: 851.497038602829 and batch: 1200, loss is 3.6981934309005737 and perplexity is 40.37429947389659
At time: 852.8074734210968 and batch: 1250, loss is 3.669939789772034 and perplexity is 39.249542565252526
At time: 854.1187059879303 and batch: 1300, loss is 3.6676108264923095 and perplexity is 39.158238185416145
At time: 855.4313712120056 and batch: 1350, loss is 3.5327289867401124 and perplexity is 34.217218652444835
At time: 856.7459981441498 and batch: 1400, loss is 3.5715241765975954 and perplexity is 35.570767987256964
At time: 858.0600683689117 and batch: 1450, loss is 3.497463812828064 and perplexity is 33.03157138761768
At time: 859.372752904892 and batch: 1500, loss is 3.481303186416626 and perplexity is 32.502050719826904
At time: 860.6829493045807 and batch: 1550, loss is 3.5017795515060426 and perplexity is 33.174435077281785
At time: 861.9959862232208 and batch: 1600, loss is 3.593585662841797 and perplexity is 36.36423231514467
At time: 863.3101480007172 and batch: 1650, loss is 3.5309264993667604 and perplexity is 34.15559809969028
At time: 864.6320548057556 and batch: 1700, loss is 3.5388384532928465 and perplexity is 34.42690749659
At time: 865.9457914829254 and batch: 1750, loss is 3.5492456436157225 and perplexity is 34.787065742128156
At time: 867.2569329738617 and batch: 1800, loss is 3.4757131862640382 and perplexity is 32.32087112013159
At time: 868.5693325996399 and batch: 1850, loss is 3.490085597038269 and perplexity is 32.78875420636472
At time: 869.8828284740448 and batch: 1900, loss is 3.5676412391662597 and perplexity is 35.43291672788628
At time: 871.1959958076477 and batch: 1950, loss is 3.531345920562744 and perplexity is 34.16992668614118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359136820948401 and perplexity of 78.18961364946311
finished 16 epochs...
Completing Train Step...
At time: 875.1519479751587 and batch: 50, loss is 3.773383617401123 and perplexity is 43.527094984699765
At time: 876.4852049350739 and batch: 100, loss is 3.7504748773574828 and perplexity is 42.5412790943121
At time: 877.8056802749634 and batch: 150, loss is 3.713829278945923 and perplexity is 41.010547058264315
At time: 879.1242713928223 and batch: 200, loss is 3.7207048606872557 and perplexity is 41.29349001087557
At time: 880.439689874649 and batch: 250, loss is 3.7232586908340455 and perplexity is 41.39908134430748
At time: 881.7556476593018 and batch: 300, loss is 3.717983808517456 and perplexity is 41.18128100279944
At time: 883.0724081993103 and batch: 350, loss is 3.7610867261886596 and perplexity is 42.99512452770809
At time: 884.3904428482056 and batch: 400, loss is 3.743147711753845 and perplexity is 42.23071127777148
At time: 885.7097187042236 and batch: 450, loss is 3.778319854736328 and perplexity is 43.742486229849625
At time: 887.0282282829285 and batch: 500, loss is 3.7862545442581177 and perplexity is 44.090949924356856
At time: 888.3625411987305 and batch: 550, loss is 3.751403579711914 and perplexity is 42.58080563172074
At time: 889.6786458492279 and batch: 600, loss is 3.7142271327972414 and perplexity is 41.02686650851893
At time: 890.99778008461 and batch: 650, loss is 3.722967119216919 and perplexity is 41.38701230679227
At time: 892.3149807453156 and batch: 700, loss is 3.7744940900802613 and perplexity is 43.57545748212872
At time: 893.631932258606 and batch: 750, loss is 3.7117353010177614 and perplexity is 40.92476172554468
At time: 894.9481773376465 and batch: 800, loss is 3.680032663345337 and perplexity is 39.64768907758304
At time: 896.2642984390259 and batch: 850, loss is 3.6770874786376955 and perplexity is 39.53109109559715
At time: 897.582231760025 and batch: 900, loss is 3.6344527339935304 and perplexity is 37.881116176238095
At time: 898.9009163379669 and batch: 950, loss is 3.7543974256515504 and perplexity is 42.70847702264431
At time: 900.21897315979 and batch: 1000, loss is 3.706064991950989 and perplexity is 40.69336235106593
At time: 901.5332701206207 and batch: 1050, loss is 3.6522101593017577 and perplexity is 38.55979522995467
At time: 902.8497731685638 and batch: 1100, loss is 3.674883861541748 and perplexity is 39.444075617047254
At time: 904.1675329208374 and batch: 1150, loss is 3.6440768527984617 and perplexity is 38.24744852421852
At time: 905.4855546951294 and batch: 1200, loss is 3.6955822849273683 and perplexity is 40.269013802353506
At time: 906.80313539505 and batch: 1250, loss is 3.668083381652832 and perplexity is 39.17674698581778
At time: 908.1192984580994 and batch: 1300, loss is 3.666366491317749 and perplexity is 39.10954251541897
At time: 909.4337801933289 and batch: 1350, loss is 3.532570147514343 and perplexity is 34.21178404755175
At time: 910.749883890152 and batch: 1400, loss is 3.5720021152496337 and perplexity is 35.58777269544073
At time: 912.0680179595947 and batch: 1450, loss is 3.498804235458374 and perplexity is 33.07587734113789
At time: 913.3843624591827 and batch: 1500, loss is 3.483225917816162 and perplexity is 32.5646035501698
At time: 914.7031452655792 and batch: 1550, loss is 3.5038802194595338 and perplexity is 33.24419679737495
At time: 916.0181403160095 and batch: 1600, loss is 3.596266202926636 and perplexity is 36.4618388582011
At time: 917.3341805934906 and batch: 1650, loss is 3.5336700534820555 and perplexity is 34.24943449517198
At time: 918.6511840820312 and batch: 1700, loss is 3.541431918144226 and perplexity is 34.51630834999999
At time: 919.9695234298706 and batch: 1750, loss is 3.551871032714844 and perplexity is 34.87851531815034
At time: 921.2915954589844 and batch: 1800, loss is 3.47834352016449 and perplexity is 32.40599770972809
At time: 922.6121327877045 and batch: 1850, loss is 3.492551574707031 and perplexity is 32.86971031898226
At time: 923.9223382472992 and batch: 1900, loss is 3.5694190073013305 and perplexity is 35.49596426352273
At time: 925.2392075061798 and batch: 1950, loss is 3.532099070549011 and perplexity is 34.19567145957652
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35832036927689 and perplexity of 78.12580166195085
finished 17 epochs...
Completing Train Step...
At time: 929.262570142746 and batch: 50, loss is 3.7705694389343263 and perplexity is 43.40477416830303
At time: 930.5777668952942 and batch: 100, loss is 3.746595888137817 and perplexity is 42.37658156779027
At time: 931.8944053649902 and batch: 150, loss is 3.7094195461273194 and perplexity is 40.830099657815566
At time: 933.2129821777344 and batch: 200, loss is 3.7159204196929934 and perplexity is 41.096395613699976
At time: 934.5296094417572 and batch: 250, loss is 3.7180955743789674 and perplexity is 41.18588392136866
At time: 935.8472080230713 and batch: 300, loss is 3.712557053565979 and perplexity is 40.95840557434384
At time: 937.1618132591248 and batch: 350, loss is 3.7557355785369873 and perplexity is 42.76566574950093
At time: 938.4755127429962 and batch: 400, loss is 3.737720685005188 and perplexity is 42.002144857081376
At time: 939.7913408279419 and batch: 450, loss is 3.773044590950012 and perplexity is 43.512340649356226
At time: 941.1064660549164 and batch: 500, loss is 3.780881004333496 and perplexity is 43.85466086753305
At time: 942.421600818634 and batch: 550, loss is 3.7460079526901247 and perplexity is 42.351674196015395
At time: 943.7349381446838 and batch: 600, loss is 3.709641146659851 and perplexity is 40.839148632234796
At time: 945.0469200611115 and batch: 650, loss is 3.7186788845062257 and perplexity is 41.209915072685654
At time: 946.3600306510925 and batch: 700, loss is 3.77032506942749 and perplexity is 43.39416866092927
At time: 947.6755261421204 and batch: 750, loss is 3.7079346704483034 and perplexity is 40.769517025831604
At time: 948.9899320602417 and batch: 800, loss is 3.6764896059036256 and perplexity is 39.50746359790519
At time: 950.3065900802612 and batch: 850, loss is 3.673159260749817 and perplexity is 39.37610895752432
At time: 951.6185626983643 and batch: 900, loss is 3.6308152008056642 and perplexity is 37.74357267014827
At time: 952.9617164134979 and batch: 950, loss is 3.750806493759155 and perplexity is 42.55538881958676
At time: 954.2855708599091 and batch: 1000, loss is 3.7031281900405886 and perplexity is 40.574029321276306
At time: 955.6074969768524 and batch: 1050, loss is 3.649489941596985 and perplexity is 38.45504672623618
At time: 956.9225471019745 and batch: 1100, loss is 3.6728709888458253 and perplexity is 39.36475956755708
At time: 958.2359299659729 and batch: 1150, loss is 3.6423874855041505 and perplexity is 38.18288908324909
At time: 959.5497760772705 and batch: 1200, loss is 3.6941661500930785 and perplexity is 40.21202780861439
At time: 960.8639538288116 and batch: 1250, loss is 3.6671056747436523 and perplexity is 39.13846232824739
At time: 962.1787765026093 and batch: 1300, loss is 3.6657188749313354 and perplexity is 39.08422273445831
At time: 963.4940235614777 and batch: 1350, loss is 3.532312846183777 and perplexity is 34.20298244237619
At time: 964.8057487010956 and batch: 1400, loss is 3.571818299293518 and perplexity is 35.58123169616511
At time: 966.1206319332123 and batch: 1450, loss is 3.4988158559799194 and perplexity is 33.0762617023164
At time: 967.4331357479095 and batch: 1500, loss is 3.483433084487915 and perplexity is 32.57135054955682
At time: 968.7481369972229 and batch: 1550, loss is 3.5041434001922607 and perplexity is 33.25294718086266
At time: 970.0637209415436 and batch: 1600, loss is 3.596789813041687 and perplexity is 36.480935645039686
At time: 971.3782649040222 and batch: 1650, loss is 3.53423406124115 and perplexity is 34.26875689045007
At time: 972.6910834312439 and batch: 1700, loss is 3.541826357841492 and perplexity is 34.529925637639145
At time: 974.0138697624207 and batch: 1750, loss is 3.5523083639144897 and perplexity is 34.89377211699019
At time: 975.3312375545502 and batch: 1800, loss is 3.4789155530929565 and perplexity is 32.42454031048135
At time: 976.6483471393585 and batch: 1850, loss is 3.493049421310425 and perplexity is 32.8860784666944
At time: 977.9639015197754 and batch: 1900, loss is 3.5696018028259275 and perplexity is 35.502453360002185
At time: 979.2759258747101 and batch: 1950, loss is 3.5317129135131835 and perplexity is 34.18246910970176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357991347202035 and perplexity of 78.10010077689947
finished 18 epochs...
Completing Train Step...
At time: 983.2325518131256 and batch: 50, loss is 3.767880597114563 and perplexity is 43.2882223612496
At time: 984.547388792038 and batch: 100, loss is 3.743406209945679 and perplexity is 42.241629251354055
At time: 985.8698930740356 and batch: 150, loss is 3.7059701538085936 and perplexity is 40.689503251170564
At time: 987.1821994781494 and batch: 200, loss is 3.7122850370407106 and perplexity is 40.947265726359035
At time: 988.5036253929138 and batch: 250, loss is 3.7142138624191285 and perplexity is 41.026322070100036
At time: 989.8225312232971 and batch: 300, loss is 3.708578152656555 and perplexity is 40.79575992719127
At time: 991.1409504413605 and batch: 350, loss is 3.7517222929000855 and perplexity is 42.59437885890691
At time: 992.4571375846863 and batch: 400, loss is 3.733720440864563 and perplexity is 41.834461633743835
At time: 993.7718141078949 and batch: 450, loss is 3.7692044973373413 and perplexity is 43.34556960111305
At time: 995.0870735645294 and batch: 500, loss is 3.776895866394043 and perplexity is 43.680241767608024
At time: 996.4026753902435 and batch: 550, loss is 3.7421457052230833 and perplexity is 42.18841702237118
At time: 997.7180469036102 and batch: 600, loss is 3.7063490629196165 and perplexity is 40.70492379598339
At time: 999.032877445221 and batch: 650, loss is 3.7154885292053224 and perplexity is 41.07865030364799
At time: 1000.3459689617157 and batch: 700, loss is 3.7671892499923705 and perplexity is 43.25830551594936
At time: 1001.6617333889008 and batch: 750, loss is 3.7050559091567994 and perplexity is 40.65232009028195
At time: 1002.9778831005096 and batch: 800, loss is 3.6737418460845945 and perplexity is 39.3990555846788
At time: 1004.2947678565979 and batch: 850, loss is 3.6701816606521604 and perplexity is 39.25903703482892
At time: 1005.6094172000885 and batch: 900, loss is 3.628102912902832 and perplexity is 37.641339939557554
At time: 1006.923175573349 and batch: 950, loss is 3.7481201028823854 and perplexity is 42.44122182854504
At time: 1008.2360291481018 and batch: 1000, loss is 3.700860004425049 and perplexity is 40.482104182654204
At time: 1009.550812959671 and batch: 1050, loss is 3.647368240356445 and perplexity is 38.37354309963978
At time: 1010.8661198616028 and batch: 1100, loss is 3.6711705923080444 and perplexity is 39.297880743052815
At time: 1012.187061548233 and batch: 1150, loss is 3.6409101629257203 and perplexity is 38.126522285319965
At time: 1013.5012307167053 and batch: 1200, loss is 3.692857265472412 and perplexity is 40.15942933402633
At time: 1014.8157725334167 and batch: 1250, loss is 3.666064305305481 and perplexity is 39.09772594421579
At time: 1016.129912853241 and batch: 1300, loss is 3.664907250404358 and perplexity is 39.05251389024766
At time: 1017.4555151462555 and batch: 1350, loss is 3.5316656160354616 and perplexity is 34.180852403363936
At time: 1018.7796683311462 and batch: 1400, loss is 3.5711599731445314 and perplexity is 35.55781534956873
At time: 1020.1008412837982 and batch: 1450, loss is 3.4982153844833372 and perplexity is 33.05640631184528
At time: 1021.4189431667328 and batch: 1500, loss is 3.482958745956421 and perplexity is 32.55590436661784
At time: 1022.7366449832916 and batch: 1550, loss is 3.50369092464447 and perplexity is 33.23790443886446
At time: 1024.05748128891 and batch: 1600, loss is 3.5965234565734865 and perplexity is 36.47122000583373
At time: 1025.378148317337 and batch: 1650, loss is 3.534042444229126 and perplexity is 34.26219104273309
At time: 1026.6986000537872 and batch: 1700, loss is 3.5415087366104125 and perplexity is 34.51895994171015
At time: 1028.0163006782532 and batch: 1750, loss is 3.5520356130599975 and perplexity is 34.88425610863752
At time: 1029.3333098888397 and batch: 1800, loss is 3.4787836122512816 and perplexity is 32.4202624715589
At time: 1030.6487483978271 and batch: 1850, loss is 3.4929043436050415 and perplexity is 32.881307775960195
At time: 1031.966403245926 and batch: 1900, loss is 3.5693390703201295 and perplexity is 35.493126936699866
At time: 1033.285224199295 and batch: 1950, loss is 3.531117901802063 and perplexity is 34.162136190029024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357869276889535 and perplexity of 78.09056765505878
finished 19 epochs...
Completing Train Step...
At time: 1037.2643129825592 and batch: 50, loss is 3.765470223426819 and perplexity is 43.18400721825673
At time: 1038.58252120018 and batch: 100, loss is 3.7406936740875243 and perplexity is 42.12720258068773
At time: 1039.8950247764587 and batch: 150, loss is 3.7030821561813356 and perplexity is 40.57216158511108
At time: 1041.2098915576935 and batch: 200, loss is 3.7092500257492067 and perplexity is 40.823178710520565
At time: 1042.5227501392365 and batch: 250, loss is 3.7110019302368165 and perplexity is 40.89475970372579
At time: 1043.8359849452972 and batch: 300, loss is 3.7052952814102174 and perplexity is 40.662052292511746
At time: 1045.1520006656647 and batch: 350, loss is 3.748365602493286 and perplexity is 42.45164241106224
At time: 1046.4676785469055 and batch: 400, loss is 3.7303945875167845 and perplexity is 41.69555746495251
At time: 1047.7838597297668 and batch: 450, loss is 3.766020450592041 and perplexity is 43.20777477030813
At time: 1049.1089663505554 and batch: 500, loss is 3.773591089248657 and perplexity is 43.536126568381306
At time: 1050.427621126175 and batch: 550, loss is 3.7389507055282594 and perplexity is 42.05384014388275
At time: 1051.7849900722504 and batch: 600, loss is 3.7035831212997437 and perplexity is 40.59249191481147
At time: 1053.1018846035004 and batch: 650, loss is 3.7127686071395876 and perplexity is 40.967071388022006
At time: 1054.4169869422913 and batch: 700, loss is 3.7645074367523192 and perplexity is 43.14245024001807
At time: 1055.729290485382 and batch: 750, loss is 3.7025918436050413 and perplexity is 40.552273420145596
At time: 1057.0415351390839 and batch: 800, loss is 3.6713782787322997 and perplexity is 39.30604322697436
At time: 1058.3547666072845 and batch: 850, loss is 3.6676799058914185 and perplexity is 39.160943306413145
At time: 1059.671065568924 and batch: 900, loss is 3.6258094453811647 and perplexity is 37.55510966989311
At time: 1060.9875984191895 and batch: 950, loss is 3.7458267974853516 and perplexity is 42.344002664693825
At time: 1062.3025915622711 and batch: 1000, loss is 3.6988539552688597 and perplexity is 40.40097649199192
At time: 1063.6142480373383 and batch: 1050, loss is 3.645487484931946 and perplexity is 38.30143967600437
At time: 1064.9261338710785 and batch: 1100, loss is 3.669552693367004 and perplexity is 39.23435214869396
At time: 1066.2416062355042 and batch: 1150, loss is 3.6394857358932495 and perplexity is 38.07225249717538
At time: 1067.5582149028778 and batch: 1200, loss is 3.6915472984313964 and perplexity is 40.10685624723624
At time: 1068.8734216690063 and batch: 1250, loss is 3.66492573261261 and perplexity is 39.05323567361219
At time: 1070.1861641407013 and batch: 1300, loss is 3.663945460319519 and perplexity is 39.01497162638256
At time: 1071.4996929168701 and batch: 1350, loss is 3.5307804346084595 and perplexity is 34.150609534844854
At time: 1072.815006494522 and batch: 1400, loss is 3.57025776386261 and perplexity is 35.52574922586781
At time: 1074.1319205760956 and batch: 1450, loss is 3.4973445749282837 and perplexity is 33.027633007225745
At time: 1075.4472634792328 and batch: 1500, loss is 3.482192325592041 and perplexity is 32.53096241776012
At time: 1076.7609462738037 and batch: 1550, loss is 3.502930455207825 and perplexity is 33.212637636933565
At time: 1078.0733971595764 and batch: 1600, loss is 3.595925045013428 and perplexity is 36.44940173497664
At time: 1079.3857340812683 and batch: 1650, loss is 3.5335354232788085 and perplexity is 34.244823797221365
At time: 1080.7014698982239 and batch: 1700, loss is 3.5409146118164063 and perplexity is 34.49845746286407
At time: 1082.0170044898987 and batch: 1750, loss is 3.5514860105514527 and perplexity is 34.86508890162651
At time: 1083.3323678970337 and batch: 1800, loss is 3.4783558368682863 and perplexity is 32.406396847261135
At time: 1084.644430398941 and batch: 1850, loss is 3.492503490447998 and perplexity is 32.86812984131529
At time: 1085.9643068313599 and batch: 1900, loss is 3.5689150142669677 and perplexity is 35.478079052175474
At time: 1087.2813484668732 and batch: 1950, loss is 3.5304916191101072 and perplexity is 34.14074773372207
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357863315316134 and perplexity of 78.09010211379544
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
2238.3627636432648


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9611997604370117 and batch: 50, loss is 7.645704584121704 and perplexity is 2091.6417943666074
At time: 3.4818105697631836 and batch: 100, loss is 6.6930871677398684 and perplexity is 806.8091666392102
At time: 5.0038228034973145 and batch: 150, loss is 6.345881490707398 and perplexity is 570.1397411575838
At time: 6.523043155670166 and batch: 200, loss is 6.186508378982544 and perplexity is 486.1457028063637
At time: 8.04471755027771 and batch: 250, loss is 6.092921867370605 and perplexity is 442.71307207590485
At time: 9.56541633605957 and batch: 300, loss is 6.004718151092529 and perplexity is 405.3367289199509
At time: 11.087302446365356 and batch: 350, loss is 5.937069520950318 and perplexity is 378.82316797948926
At time: 12.60753083229065 and batch: 400, loss is 5.881021242141724 and perplexity is 358.17483823469905
At time: 14.128629684448242 and batch: 450, loss is 5.8013945579528805 and perplexity is 330.76050311905965
At time: 15.65175461769104 and batch: 500, loss is 5.770413208007812 and perplexity is 320.67020877350546
At time: 17.184054613113403 and batch: 550, loss is 5.715956163406372 and perplexity is 303.6744269111657
At time: 18.717100620269775 and batch: 600, loss is 5.748307600021362 and perplexity is 313.6593737204343
At time: 20.246384382247925 and batch: 650, loss is 5.820264511108398 and perplexity is 337.0611982708303
At time: 21.777427673339844 and batch: 700, loss is 5.724954481124878 and perplexity is 306.41931706328546
At time: 23.310031175613403 and batch: 750, loss is 5.667068271636963 and perplexity is 289.1854771317631
At time: 24.84340500831604 and batch: 800, loss is 5.656184291839599 and perplexity is 286.05505486998635
At time: 26.375583171844482 and batch: 850, loss is 5.678028564453125 and perplexity is 292.3724679115398
At time: 27.908279180526733 and batch: 900, loss is 5.673948173522949 and perplexity is 291.18190457901767
At time: 29.439252853393555 and batch: 950, loss is 5.700735197067261 and perplexity is 299.0872081946649
At time: 30.968973875045776 and batch: 1000, loss is 5.666063642501831 and perplexity is 288.8950988616373
At time: 32.500678062438965 and batch: 1050, loss is 5.5773101329803465 and perplexity is 264.35955650424506
At time: 34.03213047981262 and batch: 1100, loss is 5.658062753677368 and perplexity is 286.59290337985533
At time: 35.565372467041016 and batch: 1150, loss is 5.564767665863037 and perplexity is 261.0645424580379
At time: 37.09891724586487 and batch: 1200, loss is 5.633666820526123 and perplexity is 279.6857972836109
At time: 38.63006949424744 and batch: 1250, loss is 5.565943241119385 and perplexity is 261.3716239377909
At time: 40.164178133010864 and batch: 1300, loss is 5.580440435409546 and perplexity is 265.1883784209943
At time: 41.69622731208801 and batch: 1350, loss is 5.54712142944336 and perplexity is 256.4981441862589
At time: 43.22920203208923 and batch: 1400, loss is 5.553551149368286 and perplexity is 258.15266877949944
At time: 44.763697147369385 and batch: 1450, loss is 5.516441144943237 and perplexity is 248.74820127150653
At time: 46.29646611213684 and batch: 1500, loss is 5.48566689491272 and perplexity is 241.20975192753133
At time: 47.82784175872803 and batch: 1550, loss is 5.461781578063965 and perplexity is 235.5166421030614
At time: 49.36256146430969 and batch: 1600, loss is 5.49855302810669 and perplexity is 244.33812595134063
At time: 50.89578366279602 and batch: 1650, loss is 5.479303560256958 and perplexity is 239.67972674772358
At time: 52.42982864379883 and batch: 1700, loss is 5.482698249816894 and perplexity is 240.49474760255006
At time: 53.962788581848145 and batch: 1750, loss is 5.495761137008667 and perplexity is 243.6569118928083
At time: 55.49752140045166 and batch: 1800, loss is 5.492949647903442 and perplexity is 242.97283522726033
At time: 57.03088736534119 and batch: 1850, loss is 5.466421384811401 and perplexity is 236.6119328119021
At time: 58.56332445144653 and batch: 1900, loss is 5.463626165390014 and perplexity is 235.9514740356012
At time: 60.097307205200195 and batch: 1950, loss is 5.399911375045776 and perplexity is 221.38679494016577
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.995958621002907 and perplexity of 147.81457564450392
finished 1 epochs...
Completing Train Step...
At time: 64.12137079238892 and batch: 50, loss is 5.255659799575806 and perplexity is 191.64789334672068
At time: 65.43400621414185 and batch: 100, loss is 5.193304824829101 and perplexity is 180.06264620799212
At time: 66.74709582328796 and batch: 150, loss is 5.106215858459473 and perplexity is 165.0446194841552
At time: 68.06068301200867 and batch: 200, loss is 5.077883739471435 and perplexity is 160.43417590421603
At time: 69.37108302116394 and batch: 250, loss is 5.073692512512207 and perplexity is 159.76316701851692
At time: 70.68196654319763 and batch: 300, loss is 5.084886484146118 and perplexity is 161.56159839383514
At time: 72.00459170341492 and batch: 350, loss is 5.058364782333374 and perplexity is 157.33303210572777
At time: 73.31690740585327 and batch: 400, loss is 5.023539724349976 and perplexity is 151.94820775837084
At time: 74.62811803817749 and batch: 450, loss is 4.9854820728302 and perplexity is 146.274072788518
At time: 75.94461035728455 and batch: 500, loss is 4.9768883419036865 and perplexity is 145.02241865796307
At time: 77.25625562667847 and batch: 550, loss is 4.931068229675293 and perplexity is 138.52741242305936
At time: 78.56851029396057 and batch: 600, loss is 4.920039310455322 and perplexity is 137.00799892743092
At time: 79.883216381073 and batch: 650, loss is 4.987708864212036 and perplexity is 146.6001575598251
At time: 81.19548106193542 and batch: 700, loss is 4.966133327484131 and perplexity is 143.4710578618437
At time: 82.50820994377136 and batch: 750, loss is 4.922933864593506 and perplexity is 137.40515050877457
At time: 83.81841516494751 and batch: 800, loss is 4.902948703765869 and perplexity is 134.68634485327317
At time: 85.13088488578796 and batch: 850, loss is 4.894439287185669 and perplexity is 133.54510516565054
At time: 86.44451022148132 and batch: 900, loss is 4.900271043777466 and perplexity is 134.32618302732322
At time: 87.75976181030273 and batch: 950, loss is 4.9688921070098875 and perplexity is 143.8674093506163
At time: 89.07225751876831 and batch: 1000, loss is 4.926815309524536 and perplexity is 137.93951742070482
At time: 90.38252186775208 and batch: 1050, loss is 4.837912693023681 and perplexity is 126.20564668239453
At time: 91.6941020488739 and batch: 1100, loss is 4.917247085571289 and perplexity is 136.62597537954704
At time: 93.00662636756897 and batch: 1150, loss is 4.831365213394165 and perplexity is 125.38201707303607
At time: 94.3218514919281 and batch: 1200, loss is 4.9112622165679936 and perplexity is 135.81072881980396
At time: 95.63550400733948 and batch: 1250, loss is 4.8566281032562255 and perplexity is 128.58987847914838
At time: 96.94672989845276 and batch: 1300, loss is 4.890151758193969 and perplexity is 132.97375237663695
At time: 98.25696134567261 and batch: 1350, loss is 4.785777282714844 and perplexity is 119.7944410535895
At time: 99.58487176895142 and batch: 1400, loss is 4.8101654052734375 and perplexity is 122.75191965301393
At time: 100.90195274353027 and batch: 1450, loss is 4.7487666797637935 and perplexity is 115.44181996036775
At time: 102.21550989151001 and batch: 1500, loss is 4.726055803298951 and perplexity is 112.849582459768
At time: 103.53418183326721 and batch: 1550, loss is 4.7164083766937255 and perplexity is 111.76610916359058
At time: 104.84549069404602 and batch: 1600, loss is 4.790406665802002 and perplexity is 120.35030106467761
At time: 106.15578985214233 and batch: 1650, loss is 4.742147274017334 and perplexity is 114.68018727284121
At time: 107.47010159492493 and batch: 1700, loss is 4.7733687400817875 and perplexity is 118.31715108738669
At time: 108.78392839431763 and batch: 1750, loss is 4.783926200866699 and perplexity is 119.57289684973391
At time: 110.09861183166504 and batch: 1800, loss is 4.740546340942383 and perplexity is 114.49673885149846
At time: 111.41120624542236 and batch: 1850, loss is 4.751455707550049 and perplexity is 115.75266396871884
At time: 112.72307896614075 and batch: 1900, loss is 4.80583010673523 and perplexity is 122.2209053197042
At time: 114.03995966911316 and batch: 1950, loss is 4.729242935180664 and perplexity is 113.2098227235408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6270263671875 and perplexity of 102.2096777166904
finished 2 epochs...
Completing Train Step...
At time: 117.95570039749146 and batch: 50, loss is 4.687780475616455 and perplexity is 108.61184544343325
At time: 119.27471566200256 and batch: 100, loss is 4.6274448585510255 and perplexity is 102.25246053557929
At time: 120.5879385471344 and batch: 150, loss is 4.576281642913818 and perplexity is 97.15247415933402
At time: 121.90062499046326 and batch: 200, loss is 4.564268999099731 and perplexity is 95.99239783368266
At time: 123.2120509147644 and batch: 250, loss is 4.5702437400817875 and perplexity is 96.56764431009529
At time: 124.524254322052 and batch: 300, loss is 4.595139856338501 and perplexity is 99.00198063399962
At time: 125.83657789230347 and batch: 350, loss is 4.600059127807617 and perplexity is 99.49019810531685
At time: 127.14965844154358 and batch: 400, loss is 4.576838750839233 and perplexity is 97.20661365203182
At time: 128.46270561218262 and batch: 450, loss is 4.562674140930175 and perplexity is 95.83942559072274
At time: 129.7745966911316 and batch: 500, loss is 4.574665632247925 and perplexity is 96.99560151294877
At time: 131.08480882644653 and batch: 550, loss is 4.538324584960938 and perplexity is 93.53396056629268
At time: 132.39358830451965 and batch: 600, loss is 4.50526912689209 and perplexity is 90.49269478970814
At time: 133.70387816429138 and batch: 650, loss is 4.570276327133179 and perplexity is 96.57079121615709
At time: 135.0145857334137 and batch: 700, loss is 4.591057205200196 and perplexity is 98.59861404787313
At time: 136.3261067867279 and batch: 750, loss is 4.548551177978515 and perplexity is 94.49540207060885
At time: 137.67251467704773 and batch: 800, loss is 4.529890050888062 and perplexity is 92.74836292134573
At time: 138.98748874664307 and batch: 850, loss is 4.519410409927368 and perplexity is 91.7814685799206
At time: 140.2995228767395 and batch: 900, loss is 4.514264421463013 and perplexity is 91.31037536109383
At time: 141.6120707988739 and batch: 950, loss is 4.589351434707641 and perplexity is 98.43057080377275
At time: 142.9256272315979 and batch: 1000, loss is 4.562127141952515 and perplexity is 95.78701585824686
At time: 144.23885846138 and batch: 1050, loss is 4.488641529083252 and perplexity is 89.00045918343355
At time: 145.55300545692444 and batch: 1100, loss is 4.549789276123047 and perplexity is 94.61246910786582
At time: 146.8649196624756 and batch: 1150, loss is 4.484584693908691 and perplexity is 88.64013038153325
At time: 148.177827835083 and batch: 1200, loss is 4.568124666213989 and perplexity is 96.36322700274418
At time: 149.49195623397827 and batch: 1250, loss is 4.526307001113891 and perplexity is 92.41663557322529
At time: 150.80572032928467 and batch: 1300, loss is 4.546203327178955 and perplexity is 94.27380120997763
At time: 152.12037563323975 and batch: 1350, loss is 4.4231228923797605 and perplexity is 83.3561917332675
At time: 153.43138480186462 and batch: 1400, loss is 4.456131534576416 and perplexity is 86.1535814679966
At time: 154.74919891357422 and batch: 1450, loss is 4.387017431259156 and perplexity is 80.40026170839444
At time: 156.0621781349182 and batch: 1500, loss is 4.390210833549499 and perplexity is 80.65742247863473
At time: 157.37647104263306 and batch: 1550, loss is 4.384778985977173 and perplexity is 80.2204913999661
At time: 158.68895530700684 and batch: 1600, loss is 4.470632276535034 and perplexity is 87.41197408471717
At time: 159.99935483932495 and batch: 1650, loss is 4.422985639572143 and perplexity is 83.34475164702977
At time: 161.3104271888733 and batch: 1700, loss is 4.4616502666473385 and perplexity is 86.63035438198928
At time: 162.62325620651245 and batch: 1750, loss is 4.46767671585083 and perplexity is 87.15400410154163
At time: 163.93965554237366 and batch: 1800, loss is 4.418690404891968 and perplexity is 82.98753409514669
At time: 165.25283813476562 and batch: 1850, loss is 4.440888366699219 and perplexity is 84.85028637084399
At time: 166.57311058044434 and batch: 1900, loss is 4.515486440658569 and perplexity is 91.42202659862194
At time: 167.88376235961914 and batch: 1950, loss is 4.441187105178833 and perplexity is 84.8756382029846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504529092478197 and perplexity of 90.42575185445092
finished 3 epochs...
Completing Train Step...
At time: 171.82680320739746 and batch: 50, loss is 4.413288855552674 and perplexity is 82.54048131098207
At time: 173.15209555625916 and batch: 100, loss is 4.348306436538696 and perplexity is 77.34735927892066
At time: 174.46614718437195 and batch: 150, loss is 4.3098295879364015 and perplexity is 74.42780446383445
At time: 175.77788972854614 and batch: 200, loss is 4.314183988571167 and perplexity is 74.75259957365427
At time: 177.09159755706787 and batch: 250, loss is 4.314054098129272 and perplexity is 74.74289055603082
At time: 178.40599727630615 and batch: 300, loss is 4.33671236038208 and perplexity is 76.455766688618
At time: 179.72076153755188 and batch: 350, loss is 4.338998336791992 and perplexity is 76.63074268697467
At time: 181.0331928730011 and batch: 400, loss is 4.311951608657837 and perplexity is 74.58590949890939
At time: 182.3435342311859 and batch: 450, loss is 4.321067552566529 and perplexity is 75.26893896543548
At time: 183.6560573577881 and batch: 500, loss is 4.345896921157837 and perplexity is 77.16121397711281
At time: 184.96978521347046 and batch: 550, loss is 4.301822137832642 and perplexity is 73.83420730482153
At time: 186.2827489376068 and batch: 600, loss is 4.276762623786926 and perplexity is 72.00694867878761
At time: 187.59575843811035 and batch: 650, loss is 4.332488174438477 and perplexity is 76.13348448287292
At time: 188.9052379131317 and batch: 700, loss is 4.3640570545196535 and perplexity is 78.57527279998901
At time: 190.21725797653198 and batch: 750, loss is 4.321169357299805 and perplexity is 75.2766020897554
At time: 191.53172183036804 and batch: 800, loss is 4.30072829246521 and perplexity is 73.7534882543312
At time: 192.8447780609131 and batch: 850, loss is 4.292320518493653 and perplexity is 73.13598514639176
At time: 194.15762615203857 and batch: 900, loss is 4.279530377388 and perplexity is 72.20652222809852
At time: 195.46839261054993 and batch: 950, loss is 4.36453577041626 and perplexity is 78.61289703710021
At time: 196.77948212623596 and batch: 1000, loss is 4.345284938812256 and perplexity is 77.11400712274929
At time: 198.09372758865356 and batch: 1050, loss is 4.274252548217773 and perplexity is 71.8264324455714
At time: 199.40843057632446 and batch: 1100, loss is 4.330517272949219 and perplexity is 75.98358065628531
At time: 200.72189331054688 and batch: 1150, loss is 4.269164185523987 and perplexity is 71.4618817758628
At time: 202.0325744152069 and batch: 1200, loss is 4.359592185020447 and perplexity is 78.22522649811674
At time: 203.3693130016327 and batch: 1250, loss is 4.320347690582276 and perplexity is 75.21477521523053
At time: 204.68076133728027 and batch: 1300, loss is 4.332771368026734 and perplexity is 76.1550480507181
At time: 205.9941279888153 and batch: 1350, loss is 4.204127464294434 and perplexity is 66.96214530642641
At time: 207.30599689483643 and batch: 1400, loss is 4.24401017665863 and perplexity is 69.68674842465752
At time: 208.6181778907776 and batch: 1450, loss is 4.1687577438354495 and perplexity is 64.63510885186533
At time: 209.9270350933075 and batch: 1500, loss is 4.175072712898254 and perplexity is 65.04456906820309
At time: 211.2366645336151 and batch: 1550, loss is 4.1745769929885865 and perplexity is 65.01233317094838
At time: 212.55147552490234 and batch: 1600, loss is 4.2657929801940915 and perplexity is 71.2213747262401
At time: 213.87431454658508 and batch: 1650, loss is 4.21747058391571 and perplexity is 67.86161675387537
At time: 215.18612504005432 and batch: 1700, loss is 4.260287251472473 and perplexity is 70.83032664795589
At time: 216.4977788925171 and batch: 1750, loss is 4.263946552276611 and perplexity is 71.08999092431131
At time: 217.80907344818115 and batch: 1800, loss is 4.212143306732178 and perplexity is 67.50106035595277
At time: 219.13287711143494 and batch: 1850, loss is 4.238967409133911 and perplexity is 69.33621891502787
At time: 220.45222091674805 and batch: 1900, loss is 4.319477996826172 and perplexity is 75.14938983161029
At time: 221.7679364681244 and batch: 1950, loss is 4.249163169860839 and perplexity is 70.0467705647453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4711119186046515 and perplexity of 87.45391060133134
finished 4 epochs...
Completing Train Step...
At time: 225.71407890319824 and batch: 50, loss is 4.222416834831238 and perplexity is 68.19810883898131
At time: 227.045423746109 and batch: 100, loss is 4.164635305404663 and perplexity is 64.36920306185803
At time: 228.35986399650574 and batch: 150, loss is 4.128067417144775 and perplexity is 62.057874985591475
At time: 229.67317152023315 and batch: 200, loss is 4.13769832611084 and perplexity is 62.65843606268609
At time: 230.9833860397339 and batch: 250, loss is 4.133468298912049 and perplexity is 62.393948962096864
At time: 232.29604983329773 and batch: 300, loss is 4.152576184272766 and perplexity is 63.59762864994688
At time: 233.61197590827942 and batch: 350, loss is 4.158736386299133 and perplexity is 63.990612076732745
At time: 234.9493944644928 and batch: 400, loss is 4.130171117782592 and perplexity is 62.18856359343659
At time: 236.26641845703125 and batch: 450, loss is 4.152945985794068 and perplexity is 63.62115149889741
At time: 237.57905840873718 and batch: 500, loss is 4.177768578529358 and perplexity is 65.22015706091814
At time: 238.89134216308594 and batch: 550, loss is 4.134395842552185 and perplexity is 62.451848920857785
At time: 240.2041187286377 and batch: 600, loss is 4.1145137643814085 and perplexity is 61.22243849406612
At time: 241.51918244361877 and batch: 650, loss is 4.160789127349854 and perplexity is 64.1221031453881
At time: 242.8329393863678 and batch: 700, loss is 4.196890993118286 and perplexity is 66.47932473755576
At time: 244.1455900669098 and batch: 750, loss is 4.159036598205566 and perplexity is 64.0098257043137
At time: 245.453919172287 and batch: 800, loss is 4.138898768424988 and perplexity is 62.733699066082835
At time: 246.76519584655762 and batch: 850, loss is 4.129094347953797 and perplexity is 62.121636863271355
At time: 248.07950735092163 and batch: 900, loss is 4.111383924484253 and perplexity is 61.03112161524308
At time: 249.3932228088379 and batch: 950, loss is 4.198955612182617 and perplexity is 66.61672100546379
At time: 250.70705723762512 and batch: 1000, loss is 4.182300553321839 and perplexity is 65.51640395335828
At time: 252.01852703094482 and batch: 1050, loss is 4.120582752227783 and perplexity is 61.595126504793726
At time: 253.34816527366638 and batch: 1100, loss is 4.164869346618652 and perplexity is 64.38426987134459
At time: 254.66493105888367 and batch: 1150, loss is 4.107933850288391 and perplexity is 60.820922527138904
At time: 255.97913074493408 and batch: 1200, loss is 4.19867262840271 and perplexity is 66.59787222102453
At time: 257.2922639846802 and batch: 1250, loss is 4.167438836097717 and perplexity is 64.54991729891996
At time: 258.6035361289978 and batch: 1300, loss is 4.167578325271607 and perplexity is 64.55892194156911
At time: 259.9142646789551 and batch: 1350, loss is 4.051608867645264 and perplexity is 57.48987628223172
At time: 261.22792863845825 and batch: 1400, loss is 4.08963216304779 and perplexity is 59.717921205483776
At time: 262.542733669281 and batch: 1450, loss is 4.010786423683166 and perplexity is 55.19025642612634
At time: 263.8566427230835 and batch: 1500, loss is 4.020707464218139 and perplexity is 55.740526308724895
At time: 265.1703305244446 and batch: 1550, loss is 4.0220448732376095 and perplexity is 55.815124064096445
At time: 266.4812767505646 and batch: 1600, loss is 4.116866846084594 and perplexity is 61.36666952105573
At time: 267.7945191860199 and batch: 1650, loss is 4.0661537456512455 and perplexity is 58.332170201353634
At time: 269.10919880867004 and batch: 1700, loss is 4.110154738426209 and perplexity is 60.956149098472665
At time: 270.42277789115906 and batch: 1750, loss is 4.110339179039001 and perplexity is 60.9673929248431
At time: 271.73543190956116 and batch: 1800, loss is 4.0594170904159546 and perplexity is 57.94052714484903
At time: 273.0501582622528 and batch: 1850, loss is 4.0931792831420895 and perplexity is 59.930123975640925
At time: 274.3628509044647 and batch: 1900, loss is 4.1689073276519775 and perplexity is 64.64477794128071
At time: 275.677072763443 and batch: 1950, loss is 4.104859356880188 and perplexity is 60.63421616256226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.458297658521076 and perplexity of 86.34040307005674
finished 5 epochs...
Completing Train Step...
At time: 279.6416394710541 and batch: 50, loss is 4.080009064674377 and perplexity is 59.1460059867373
At time: 280.96244859695435 and batch: 100, loss is 4.024077296257019 and perplexity is 55.92867936418948
At time: 282.27776312828064 and batch: 150, loss is 3.989911913871765 and perplexity is 54.05012808711468
At time: 283.5932881832123 and batch: 200, loss is 3.999563579559326 and perplexity is 54.574327483148785
At time: 284.9071395397186 and batch: 250, loss is 3.9928155946731567 and perplexity is 54.20730048515991
At time: 286.22031903266907 and batch: 300, loss is 4.0099289894104 and perplexity is 55.14295469070638
At time: 287.53318786621094 and batch: 350, loss is 4.016763863563537 and perplexity is 55.52114080142433
At time: 288.84365606307983 and batch: 400, loss is 3.9895494985580444 and perplexity is 54.03054304216182
At time: 290.15594267845154 and batch: 450, loss is 4.025471963882446 and perplexity is 56.00673570130252
At time: 291.4696853160858 and batch: 500, loss is 4.045632891654968 and perplexity is 57.14734266760016
At time: 292.78278636932373 and batch: 550, loss is 3.9999171447753907 and perplexity is 54.59362647856265
At time: 294.0946295261383 and batch: 600, loss is 3.984265947341919 and perplexity is 53.74582273029049
At time: 295.41250252723694 and batch: 650, loss is 4.028867526054382 and perplexity is 56.197233294600395
At time: 296.72650170326233 and batch: 700, loss is 4.063003158569336 and perplexity is 58.14867882401998
At time: 298.0401723384857 and batch: 750, loss is 4.025593371391296 and perplexity is 56.013535752343095
At time: 299.3548958301544 and batch: 800, loss is 4.006357736587525 and perplexity is 54.946376482273706
At time: 300.6792013645172 and batch: 850, loss is 4.003690667152405 and perplexity is 54.80002593128039
At time: 301.99068212509155 and batch: 900, loss is 3.982695155143738 and perplexity is 53.661465482459484
At time: 303.30421352386475 and batch: 950, loss is 4.071368012428284 and perplexity is 58.63712406292338
At time: 304.6192555427551 and batch: 1000, loss is 4.0556000089645385 and perplexity is 57.719784996798325
At time: 305.9327464103699 and batch: 1050, loss is 3.994939022064209 and perplexity is 54.32252804718961
At time: 307.24566435813904 and batch: 1100, loss is 4.039937100410461 and perplexity is 56.82276856424191
At time: 308.5580804347992 and batch: 1150, loss is 3.983416118621826 and perplexity is 53.70016738890717
At time: 309.87206983566284 and batch: 1200, loss is 4.075626492500305 and perplexity is 58.88736152468407
At time: 311.18764328956604 and batch: 1250, loss is 4.044451570510864 and perplexity is 57.07987316280011
At time: 312.50285601615906 and batch: 1300, loss is 4.042443761825561 and perplexity is 56.96538267366918
At time: 313.8157424926758 and batch: 1350, loss is 3.9275674343109133 and perplexity is 50.78329359779285
At time: 315.1280815601349 and batch: 1400, loss is 3.967917766571045 and perplexity is 52.874319461072915
At time: 316.44414734840393 and batch: 1450, loss is 3.8913683557510375 and perplexity is 48.977859827797815
At time: 317.7590363025665 and batch: 1500, loss is 3.8966115379333495 and perplexity is 49.23533407210889
At time: 319.07370948791504 and batch: 1550, loss is 3.899332032203674 and perplexity is 49.36946087923103
At time: 320.38694524765015 and batch: 1600, loss is 4.001384506225586 and perplexity is 54.67379386436502
At time: 321.6991262435913 and batch: 1650, loss is 3.9452649927139283 and perplexity is 51.69003377973516
At time: 323.01147389411926 and batch: 1700, loss is 3.9895302295684814 and perplexity is 54.029501938222396
At time: 324.3249261379242 and batch: 1750, loss is 3.9872767782211302 and perplexity is 53.907886163363024
At time: 325.6396207809448 and batch: 1800, loss is 3.9371914529800414 and perplexity is 51.27439234468305
At time: 326.95428252220154 and batch: 1850, loss is 3.9778210592269896 and perplexity is 53.40055073096879
At time: 328.2663176059723 and batch: 1900, loss is 4.052262411117554 and perplexity is 57.52746069578506
At time: 329.5774745941162 and batch: 1950, loss is 3.982395958900452 and perplexity is 53.645412575182434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.449343943041424 and perplexity of 85.57078627309508
finished 6 epochs...
Completing Train Step...
At time: 333.5276429653168 and batch: 50, loss is 3.9640334129333494 and perplexity is 52.66933527919675
At time: 334.8406913280487 and batch: 100, loss is 3.908472862243652 and perplexity is 49.822807556152696
At time: 336.1629436016083 and batch: 150, loss is 3.8821854066848753 and perplexity is 48.53015739603917
At time: 337.4863278865814 and batch: 200, loss is 3.8881136083602907 and perplexity is 48.81870840565285
At time: 338.80393290519714 and batch: 250, loss is 3.8832789278030395 and perplexity is 48.58325517449946
At time: 340.12085485458374 and batch: 300, loss is 3.8905646705627444 and perplexity is 48.938512860705124
At time: 341.4407308101654 and batch: 350, loss is 3.906003074645996 and perplexity is 49.69990763479346
At time: 342.7521936893463 and batch: 400, loss is 3.8732005310058595 and perplexity is 48.09607298262335
At time: 344.06569385528564 and batch: 450, loss is 3.9105450916290283 and perplexity is 49.92615888888314
At time: 345.38043761253357 and batch: 500, loss is 3.935447726249695 and perplexity is 51.18506172290064
At time: 346.6954617500305 and batch: 550, loss is 3.8927926445007324 and perplexity is 49.04766814433353
At time: 348.00882840156555 and batch: 600, loss is 3.878598899841309 and perplexity is 48.35641540407786
At time: 349.3217098712921 and batch: 650, loss is 3.9250668716430663 and perplexity is 50.65646542665296
At time: 350.63223791122437 and batch: 700, loss is 3.9541166830062866 and perplexity is 52.1496089577943
At time: 351.94519543647766 and batch: 750, loss is 3.920931758880615 and perplexity is 50.44742772506434
At time: 353.260365486145 and batch: 800, loss is 3.898135504722595 and perplexity is 49.310424289057686
At time: 354.57779240608215 and batch: 850, loss is 3.8957705307006836 and perplexity is 49.193944207079014
At time: 355.89301085472107 and batch: 900, loss is 3.8750064373016357 and perplexity is 48.18300845865966
At time: 357.2044460773468 and batch: 950, loss is 3.965236110687256 and perplexity is 52.732718678332425
At time: 358.5170500278473 and batch: 1000, loss is 3.950342254638672 and perplexity is 51.95314499719751
At time: 359.83210372924805 and batch: 1050, loss is 3.8966660261154176 and perplexity is 49.238016889046236
At time: 361.146226644516 and batch: 1100, loss is 3.9398994302749633 and perplexity is 51.41343040595443
At time: 362.4647994041443 and batch: 1150, loss is 3.882134222984314 and perplexity is 48.527673506562685
At time: 363.7775151729584 and batch: 1200, loss is 3.974999647140503 and perplexity is 53.25009811592946
At time: 365.0895335674286 and batch: 1250, loss is 3.9435153865814208 and perplexity is 51.599675648264856
At time: 366.40218591690063 and batch: 1300, loss is 3.9372991800308226 and perplexity is 51.2799162812843
At time: 367.71880292892456 and batch: 1350, loss is 3.820902099609375 and perplexity is 45.64536642092269
At time: 369.0329279899597 and batch: 1400, loss is 3.873273091316223 and perplexity is 48.099562975222184
At time: 370.3465144634247 and batch: 1450, loss is 3.791698637008667 and perplexity is 44.33163971952307
At time: 371.65791273117065 and batch: 1500, loss is 3.7931411266326904 and perplexity is 44.39563379413229
At time: 372.9697787761688 and batch: 1550, loss is 3.8035329294204714 and perplexity is 44.859389922880865
At time: 374.28370666503906 and batch: 1600, loss is 3.9016217470169066 and perplexity is 49.48263238091485
At time: 375.5966372489929 and batch: 1650, loss is 3.849158320426941 and perplexity is 46.95352677103146
At time: 376.90947699546814 and batch: 1700, loss is 3.8938931131362917 and perplexity is 49.10167327479965
At time: 378.2203359603882 and batch: 1750, loss is 3.886430916786194 and perplexity is 48.73663065149963
At time: 379.5326564311981 and batch: 1800, loss is 3.8396706056594847 and perplexity is 46.510151735563525
At time: 380.8464798927307 and batch: 1850, loss is 3.87856680393219 and perplexity is 48.35486338587059
At time: 382.1612665653229 and batch: 1900, loss is 3.954979157447815 and perplexity is 52.19460606429394
At time: 383.4737939834595 and batch: 1950, loss is 3.889674711227417 and perplexity is 48.89497894890664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.46312993958939 and perplexity of 86.75863385575687
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 387.4246416091919 and batch: 50, loss is 3.9096180152893067 and perplexity is 49.87989497664682
At time: 388.7392547130585 and batch: 100, loss is 3.8843176698684694 and perplexity is 48.63374686470603
At time: 390.0534520149231 and batch: 150, loss is 3.8592005157470703 and perplexity is 47.42741873316727
At time: 391.3684673309326 and batch: 200, loss is 3.8702297401428223 and perplexity is 47.953401636753945
At time: 392.67842173576355 and batch: 250, loss is 3.855436611175537 and perplexity is 47.24924198547119
At time: 393.9896454811096 and batch: 300, loss is 3.86408887386322 and perplexity is 47.65982852880893
At time: 395.30335688591003 and batch: 350, loss is 3.870659685134888 and perplexity is 47.974023394433225
At time: 396.6174147129059 and batch: 400, loss is 3.842101640701294 and perplexity is 46.62335709157324
At time: 397.94342279434204 and batch: 450, loss is 3.864561471939087 and perplexity is 47.68235779529246
At time: 399.2569034099579 and batch: 500, loss is 3.8872080087661742 and perplexity is 48.77451821546462
At time: 400.57576084136963 and batch: 550, loss is 3.842702794075012 and perplexity is 46.65139330617108
At time: 401.8879098892212 and batch: 600, loss is 3.8214525413513183 and perplexity is 45.670498452152025
At time: 403.2009975910187 and batch: 650, loss is 3.8562113571166994 and perplexity is 47.28586232782151
At time: 404.5143311023712 and batch: 700, loss is 3.873352828025818 and perplexity is 48.103398429017965
At time: 405.82801055908203 and batch: 750, loss is 3.830979971885681 and perplexity is 46.107700351855634
At time: 407.13928031921387 and batch: 800, loss is 3.7930534410476686 and perplexity is 44.39174110767938
At time: 408.4511706829071 and batch: 850, loss is 3.7968871545791627 and perplexity is 44.56225296421686
At time: 409.7651798725128 and batch: 900, loss is 3.7636800813674927 and perplexity is 43.10677086329487
At time: 411.0793523788452 and batch: 950, loss is 3.859767713546753 and perplexity is 47.45432709117668
At time: 412.39540433883667 and batch: 1000, loss is 3.8279643869400024 and perplexity is 45.96886810022754
At time: 413.70812368392944 and batch: 1050, loss is 3.763794150352478 and perplexity is 43.1116882893508
At time: 415.0233316421509 and batch: 1100, loss is 3.7952115106582642 and perplexity is 44.48764502156551
At time: 416.33617424964905 and batch: 1150, loss is 3.740942258834839 and perplexity is 42.1376760624163
At time: 417.6517732143402 and batch: 1200, loss is 3.808858132362366 and perplexity is 45.09891246511591
At time: 418.96162486076355 and batch: 1250, loss is 3.7770337438583375 and perplexity is 43.68626470378676
At time: 420.27562499046326 and batch: 1300, loss is 3.770537896156311 and perplexity is 43.40340508273913
At time: 421.5898880958557 and batch: 1350, loss is 3.64700053691864 and perplexity is 38.35943560976649
At time: 422.9051854610443 and batch: 1400, loss is 3.685444312095642 and perplexity is 39.862830053278095
At time: 424.22470784187317 and batch: 1450, loss is 3.593713889122009 and perplexity is 36.368895464349954
At time: 425.54287242889404 and batch: 1500, loss is 3.5952568578720094 and perplexity is 36.42505484846903
At time: 426.8593988418579 and batch: 1550, loss is 3.5902606534957884 and perplexity is 36.24352169601631
At time: 428.1756019592285 and batch: 1600, loss is 3.683420958518982 and perplexity is 39.78225499691749
At time: 429.4898874759674 and batch: 1650, loss is 3.613419313430786 and perplexity is 37.09266768028845
At time: 430.80711126327515 and batch: 1700, loss is 3.6400120449066162 and perplexity is 38.0922955407784
At time: 432.125625371933 and batch: 1750, loss is 3.626966094970703 and perplexity is 37.59857290309773
At time: 433.44317173957825 and batch: 1800, loss is 3.5719267416000364 and perplexity is 35.58509041621949
At time: 434.75907731056213 and batch: 1850, loss is 3.597158679962158 and perplexity is 36.494394737581366
At time: 436.075345993042 and batch: 1900, loss is 3.672493896484375 and perplexity is 39.34991821586987
At time: 437.3929033279419 and batch: 1950, loss is 3.6009054040908812 and perplexity is 36.631385640212144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4119787881540695 and perplexity of 82.43241851757826
finished 8 epochs...
Completing Train Step...
At time: 441.3449430465698 and batch: 50, loss is 3.804914336204529 and perplexity is 44.92140181040871
At time: 442.67202162742615 and batch: 100, loss is 3.7649667978286745 and perplexity is 43.162272754894246
At time: 443.98684906959534 and batch: 150, loss is 3.736813898086548 and perplexity is 41.964075124746394
At time: 445.3048174381256 and batch: 200, loss is 3.7399338388442995 and perplexity is 42.09520500545062
At time: 446.6223464012146 and batch: 250, loss is 3.7259029150009155 and perplexity is 41.508694652896814
At time: 447.939710855484 and batch: 300, loss is 3.731926040649414 and perplexity is 41.75946117732949
At time: 449.25105905532837 and batch: 350, loss is 3.743447976112366 and perplexity is 42.243393559126424
At time: 450.5735082626343 and batch: 400, loss is 3.7171144390106203 and perplexity is 41.14549481080916
At time: 451.88985109329224 and batch: 450, loss is 3.745324201583862 and perplexity is 42.32272608970946
At time: 453.2078115940094 and batch: 500, loss is 3.7680688095092774 and perplexity is 43.29637050801019
At time: 454.5243647098541 and batch: 550, loss is 3.7283144903182985 and perplexity is 41.608916794428126
At time: 455.8387098312378 and batch: 600, loss is 3.7117023611068727 and perplexity is 40.92341368974251
At time: 457.15421080589294 and batch: 650, loss is 3.744556336402893 and perplexity is 42.29024041588655
At time: 458.4713809490204 and batch: 700, loss is 3.7672645044326782 and perplexity is 43.26156101801358
At time: 459.7895953655243 and batch: 750, loss is 3.7262428998947144 and perplexity is 41.522809381301364
At time: 461.10267066955566 and batch: 800, loss is 3.6913148260116575 and perplexity is 40.097533592988306
At time: 462.4138686656952 and batch: 850, loss is 3.6932988357543945 and perplexity is 40.177166460367346
At time: 463.7663857936859 and batch: 900, loss is 3.6644527959823607 and perplexity is 39.03477033474414
At time: 465.08108925819397 and batch: 950, loss is 3.7620099925994874 and perplexity is 43.03483881262543
At time: 466.39602065086365 and batch: 1000, loss is 3.7344360542297363 and perplexity is 41.86440964793534
At time: 467.71043157577515 and batch: 1050, loss is 3.674225354194641 and perplexity is 39.41810995368193
At time: 469.02468037605286 and batch: 1100, loss is 3.7053849124908447 and perplexity is 40.66569703953811
At time: 470.33578610420227 and batch: 1150, loss is 3.6568303680419922 and perplexity is 38.73836172248771
At time: 471.65670442581177 and batch: 1200, loss is 3.728934235572815 and perplexity is 41.63471171547137
At time: 472.97545075416565 and batch: 1250, loss is 3.700540795326233 and perplexity is 40.4691839888913
At time: 474.2951354980469 and batch: 1300, loss is 3.6961750602722168 and perplexity is 40.292891357210635
At time: 475.61045598983765 and batch: 1350, loss is 3.5728986978530886 and perplexity is 35.61969438141094
At time: 476.9243733882904 and batch: 1400, loss is 3.6168803548812867 and perplexity is 37.221269360137306
At time: 478.24031710624695 and batch: 1450, loss is 3.5264312410354615 and perplexity is 34.00240444327201
At time: 479.557329416275 and batch: 1500, loss is 3.531534538269043 and perplexity is 34.1763723472009
At time: 480.87436151504517 and batch: 1550, loss is 3.531963472366333 and perplexity is 34.191034903032566
At time: 482.1862587928772 and batch: 1600, loss is 3.6283343553543093 and perplexity is 37.65005275176847
At time: 483.4989969730377 and batch: 1650, loss is 3.5619988775253297 and perplexity is 35.23355436390432
At time: 484.81146478652954 and batch: 1700, loss is 3.5907450103759766 and perplexity is 36.261080747192366
At time: 486.12369751930237 and batch: 1750, loss is 3.581273703575134 and perplexity is 35.919262215846594
At time: 487.43973445892334 and batch: 1800, loss is 3.531854190826416 and perplexity is 34.18729865824202
At time: 488.754421710968 and batch: 1850, loss is 3.5596875238418577 and perplexity is 35.15221120086692
At time: 490.0681662559509 and batch: 1900, loss is 3.639926538467407 and perplexity is 38.089038543474516
At time: 491.37832903862 and batch: 1950, loss is 3.57196234703064 and perplexity is 35.58635746124352
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.422667889262355 and perplexity of 83.3182730333913
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 495.31175208091736 and batch: 50, loss is 3.7630529832839965 and perplexity is 43.079747164041386
At time: 496.63714027404785 and batch: 100, loss is 3.7582783365249632 and perplexity is 42.87454685818572
At time: 497.9492735862732 and batch: 150, loss is 3.7492726612091065 and perplexity is 42.4901660122549
At time: 499.26065492630005 and batch: 200, loss is 3.769396810531616 and perplexity is 43.35390632766626
At time: 500.57405495643616 and batch: 250, loss is 3.7702551555633543 and perplexity is 43.39113491296898
At time: 501.8889420032501 and batch: 300, loss is 3.7680621099472047 and perplexity is 43.29608044226011
At time: 503.20150899887085 and batch: 350, loss is 3.780405321121216 and perplexity is 43.833804902387634
At time: 504.5110182762146 and batch: 400, loss is 3.760649127960205 and perplexity is 42.97631405339788
At time: 505.82102227211 and batch: 450, loss is 3.791529755592346 and perplexity is 44.32415356157368
At time: 507.1355028152466 and batch: 500, loss is 3.8019148826599123 and perplexity is 44.78686402330711
At time: 508.4505047798157 and batch: 550, loss is 3.7491635131835936 and perplexity is 42.48552854762061
At time: 509.76411390304565 and batch: 600, loss is 3.7261929321289062 and perplexity is 41.52073463112225
At time: 511.07701539993286 and batch: 650, loss is 3.751808910369873 and perplexity is 42.59806843601944
At time: 512.3885359764099 and batch: 700, loss is 3.781181740760803 and perplexity is 43.86785154492229
At time: 513.7004284858704 and batch: 750, loss is 3.7348304271697996 and perplexity is 41.88092309426637
At time: 515.0146157741547 and batch: 800, loss is 3.695976901054382 and perplexity is 40.28490774041475
At time: 516.3291893005371 and batch: 850, loss is 3.690693807601929 and perplexity is 40.072640016926904
At time: 517.6411895751953 and batch: 900, loss is 3.6608121490478513 and perplexity is 38.89291689361423
At time: 518.9508953094482 and batch: 950, loss is 3.7691980981826783 and perplexity is 43.3452922269967
At time: 520.2639214992523 and batch: 1000, loss is 3.7394378757476807 and perplexity is 42.074332513644
At time: 521.5779037475586 and batch: 1050, loss is 3.6768808794021606 and perplexity is 39.52292484599645
At time: 522.8924486637115 and batch: 1100, loss is 3.7009004831314085 and perplexity is 40.48374287902816
At time: 524.2086186408997 and batch: 1150, loss is 3.648882994651794 and perplexity is 38.43171363478912
At time: 525.5214321613312 and batch: 1200, loss is 3.7040212631225584 and perplexity is 40.61028108001567
At time: 526.8341083526611 and batch: 1250, loss is 3.666217522621155 and perplexity is 39.103716851777584
At time: 528.1509258747101 and batch: 1300, loss is 3.6616770887374877 and perplexity is 38.92657147357407
At time: 529.4751846790314 and batch: 1350, loss is 3.53754497051239 and perplexity is 34.382405671935395
At time: 530.7936663627625 and batch: 1400, loss is 3.5737314939498903 and perplexity is 35.64937067929841
At time: 532.112279176712 and batch: 1450, loss is 3.4809018087387087 and perplexity is 32.48900773993702
At time: 533.4288773536682 and batch: 1500, loss is 3.4890713453292848 and perplexity is 32.75551501567788
At time: 534.7576875686646 and batch: 1550, loss is 3.4910618257522583 and perplexity is 32.8207791590127
At time: 536.0853016376495 and batch: 1600, loss is 3.579297776222229 and perplexity is 35.84835843656566
At time: 537.4045917987823 and batch: 1650, loss is 3.5085084295272826 and perplexity is 33.39841452442249
At time: 538.7242946624756 and batch: 1700, loss is 3.519958539009094 and perplexity is 33.783027757005804
At time: 540.0406165122986 and batch: 1750, loss is 3.5090647172927856 and perplexity is 33.41699882243918
At time: 541.3577263355255 and batch: 1800, loss is 3.454338541030884 and perplexity is 31.637354947445683
At time: 542.6758427619934 and batch: 1850, loss is 3.482310748100281 and perplexity is 32.534815044039426
At time: 543.9956569671631 and batch: 1900, loss is 3.5756281852722167 and perplexity is 35.71705069507198
At time: 545.3134627342224 and batch: 1950, loss is 3.5143357849121095 and perplexity is 33.59360713112656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39363162018532 and perplexity of 80.93380676785519
finished 10 epochs...
Completing Train Step...
At time: 549.2816858291626 and batch: 50, loss is 3.7646368503570558 and perplexity is 43.148033821308694
At time: 550.6096153259277 and batch: 100, loss is 3.735573229789734 and perplexity is 41.91204391054707
At time: 551.9254043102264 and batch: 150, loss is 3.7126028871536256 and perplexity is 40.960282888037284
At time: 553.2396841049194 and batch: 200, loss is 3.719578971862793 and perplexity is 41.247024294473114
At time: 554.5534827709198 and batch: 250, loss is 3.714302649497986 and perplexity is 41.02996483910593
At time: 555.8674511909485 and batch: 300, loss is 3.71032395362854 and perplexity is 40.8670434098067
At time: 557.1824102401733 and batch: 350, loss is 3.7203538179397584 and perplexity is 41.27899677470996
At time: 558.4973392486572 and batch: 400, loss is 3.701400294303894 and perplexity is 40.50398216351206
At time: 559.812105178833 and batch: 450, loss is 3.7361098670959474 and perplexity is 41.934541512875576
At time: 561.1246929168701 and batch: 500, loss is 3.7472563409805297 and perplexity is 42.40457854587535
At time: 562.4484689235687 and batch: 550, loss is 3.6956779384613037 and perplexity is 40.27286586006033
At time: 563.7635924816132 and batch: 600, loss is 3.674941368103027 and perplexity is 39.446343975420945
At time: 565.0799252986908 and batch: 650, loss is 3.7017236804962157 and perplexity is 40.51708271023157
At time: 566.3959062099457 and batch: 700, loss is 3.7332703495025634 and perplexity is 41.81563654075226
At time: 567.710569858551 and batch: 750, loss is 3.688939456939697 and perplexity is 40.00240018503866
At time: 569.0237529277802 and batch: 800, loss is 3.6515372037887572 and perplexity is 38.53385493248656
At time: 570.3376224040985 and batch: 850, loss is 3.6470674085617065 and perplexity is 38.36200085402292
At time: 571.6530165672302 and batch: 900, loss is 3.6165612936019897 and perplexity is 37.2093953886812
At time: 572.9687340259552 and batch: 950, loss is 3.7273175859451295 and perplexity is 41.56745735229612
At time: 574.2850422859192 and batch: 1000, loss is 3.6981137084960936 and perplexity is 40.37108086596261
At time: 575.5970344543457 and batch: 1050, loss is 3.6389041709899903 and perplexity is 38.050117448442606
At time: 576.9111158847809 and batch: 1100, loss is 3.665089821815491 and perplexity is 39.05964441371194
At time: 578.2261500358582 and batch: 1150, loss is 3.615909442901611 and perplexity is 37.18514832182875
At time: 579.5426964759827 and batch: 1200, loss is 3.6737673807144167 and perplexity is 39.400061637823036
At time: 580.8582980632782 and batch: 1250, loss is 3.6386170768737793 and perplexity is 38.039195051554984
At time: 582.1714792251587 and batch: 1300, loss is 3.6359375286102296 and perplexity is 37.93740363092497
At time: 583.4850072860718 and batch: 1350, loss is 3.5130271673202516 and perplexity is 33.549674697507996
At time: 584.7997498512268 and batch: 1400, loss is 3.5518453025817873 and perplexity is 34.87761790085577
At time: 586.1164653301239 and batch: 1450, loss is 3.4624241638183593 and perplexity is 31.894199640881133
At time: 587.4316425323486 and batch: 1500, loss is 3.472610845565796 and perplexity is 32.22075614193516
At time: 588.7448000907898 and batch: 1550, loss is 3.4775332975387574 and perplexity is 32.37975227093416
At time: 590.056613445282 and batch: 1600, loss is 3.569951710700989 and perplexity is 35.514878121651044
At time: 591.367995262146 and batch: 1650, loss is 3.500018720626831 and perplexity is 33.11607190651366
At time: 592.6847529411316 and batch: 1700, loss is 3.514800157546997 and perplexity is 33.60921070564152
At time: 594.0002274513245 and batch: 1750, loss is 3.5053795337677003 and perplexity is 33.29407768151429
At time: 595.3218989372253 and batch: 1800, loss is 3.452382650375366 and perplexity is 31.575536215585995
At time: 596.6345660686493 and batch: 1850, loss is 3.4816300535202025 and perplexity is 32.51267630748891
At time: 597.9473969936371 and batch: 1900, loss is 3.5770480680465697 and perplexity is 35.76780074113642
At time: 599.2651875019073 and batch: 1950, loss is 3.5160312366485598 and perplexity is 33.65061178133199
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396355775345204 and perplexity of 81.15458359380322
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 603.221111536026 and batch: 50, loss is 3.756332068443298 and perplexity is 42.7911826469865
At time: 604.5357913970947 and batch: 100, loss is 3.7487330770492555 and perplexity is 42.46724517614142
At time: 605.8507540225983 and batch: 150, loss is 3.739565472602844 and perplexity is 42.07970140867562
At time: 607.1747453212738 and batch: 200, loss is 3.7585361003875732 and perplexity is 42.88559979145372
At time: 608.5008971691132 and batch: 250, loss is 3.761838083267212 and perplexity is 43.027441358084516
At time: 609.8212537765503 and batch: 300, loss is 3.7629340267181397 and perplexity is 43.074622850052215
At time: 611.1400058269501 and batch: 350, loss is 3.7787729358673094 and perplexity is 43.762309615444444
At time: 612.4562799930573 and batch: 400, loss is 3.7643236351013183 and perplexity is 43.134521315132794
At time: 613.7729518413544 and batch: 450, loss is 3.79751802444458 and perplexity is 44.59037481642894
At time: 615.087277173996 and batch: 500, loss is 3.8080086088180543 and perplexity is 45.060616146269375
At time: 616.4019639492035 and batch: 550, loss is 3.7618111038208006 and perplexity is 43.02628051719568
At time: 617.714138507843 and batch: 600, loss is 3.7184770584106444 and perplexity is 41.201598675688494
At time: 619.0282785892487 and batch: 650, loss is 3.7359828901290895 and perplexity is 41.92921713003184
At time: 620.3446941375732 and batch: 700, loss is 3.7571941900253294 and perplexity is 42.82808975598876
At time: 621.6596789360046 and batch: 750, loss is 3.71004282951355 and perplexity is 40.855556313121454
At time: 622.9741714000702 and batch: 800, loss is 3.6748678159713744 and perplexity is 39.443442719433726
At time: 624.2938599586487 and batch: 850, loss is 3.666542830467224 and perplexity is 39.116439666983545
At time: 625.6084539890289 and batch: 900, loss is 3.629121017456055 and perplexity is 37.679682274080164
At time: 626.9371755123138 and batch: 950, loss is 3.7438368940353395 and perplexity is 42.25982596723069
At time: 628.255622625351 and batch: 1000, loss is 3.720042653083801 and perplexity is 41.266154199807104
At time: 629.5705530643463 and batch: 1050, loss is 3.669482736587524 and perplexity is 39.231607535775915
At time: 630.8845582008362 and batch: 1100, loss is 3.6942336702346803 and perplexity is 40.21474302209089
At time: 632.1989543437958 and batch: 1150, loss is 3.650485496520996 and perplexity is 38.493349900650905
At time: 633.5210905075073 and batch: 1200, loss is 3.7098994779586794 and perplexity is 40.84970002536288
At time: 634.8354794979095 and batch: 1250, loss is 3.6690829944610597 and perplexity is 39.21592814362051
At time: 636.1506938934326 and batch: 1300, loss is 3.6621158647537233 and perplexity is 38.94365526723634
At time: 637.463187456131 and batch: 1350, loss is 3.531665897369385 and perplexity is 34.18086201959859
At time: 638.7741689682007 and batch: 1400, loss is 3.5685651779174803 and perplexity is 35.46566970126061
At time: 640.0877091884613 and batch: 1450, loss is 3.4666936588287354 and perplexity is 32.030662874360765
At time: 641.401330947876 and batch: 1500, loss is 3.4646201705932618 and perplexity is 31.96431647972128
At time: 642.714718580246 and batch: 1550, loss is 3.470194625854492 and perplexity is 32.14299769440896
At time: 644.0269396305084 and batch: 1600, loss is 3.568021020889282 and perplexity is 35.44637605769487
At time: 645.3378703594208 and batch: 1650, loss is 3.504351553916931 and perplexity is 33.25986962611602
At time: 646.6495316028595 and batch: 1700, loss is 3.5171776819229126 and perplexity is 33.689212488759225
At time: 647.9627251625061 and batch: 1750, loss is 3.5059607315063475 and perplexity is 33.31343374847945
At time: 649.2771015167236 and batch: 1800, loss is 3.4398289203643797 and perplexity is 31.18162317123761
At time: 650.5890679359436 and batch: 1850, loss is 3.4634907627105713 and perplexity is 31.92823610728802
At time: 651.9061198234558 and batch: 1900, loss is 3.555093388557434 and perplexity is 34.99108758230466
At time: 653.217164516449 and batch: 1950, loss is 3.5093847370147704 and perplexity is 33.4276946324557
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376671795512355 and perplexity of 79.57275779462977
finished 12 epochs...
Completing Train Step...
At time: 657.1770448684692 and batch: 50, loss is 3.7690777587890625 and perplexity is 43.34007639465535
At time: 658.4905023574829 and batch: 100, loss is 3.743901972770691 and perplexity is 42.26257627275304
At time: 659.8175773620605 and batch: 150, loss is 3.721463513374329 and perplexity is 41.32482931435123
At time: 661.1385562419891 and batch: 200, loss is 3.7305922651290895 and perplexity is 41.703800557906526
At time: 662.4523746967316 and batch: 250, loss is 3.7309301328659057 and perplexity is 41.717893307226255
At time: 663.7675678730011 and batch: 300, loss is 3.727268500328064 and perplexity is 41.565417038077584
At time: 665.0823557376862 and batch: 350, loss is 3.7413248205184937 and perplexity is 42.15379940660624
At time: 666.3965666294098 and batch: 400, loss is 3.728863067626953 and perplexity is 41.63174876399687
At time: 667.7109785079956 and batch: 450, loss is 3.7642337322235107 and perplexity is 43.130643571846456
At time: 669.0266635417938 and batch: 500, loss is 3.777625412940979 and perplexity is 43.712120164132074
At time: 670.3441386222839 and batch: 550, loss is 3.7327179765701293 and perplexity is 41.792545093107094
At time: 671.660947561264 and batch: 600, loss is 3.6951863288879396 and perplexity is 40.253072199431884
At time: 672.9763798713684 and batch: 650, loss is 3.712188205718994 and perplexity is 40.943300940458904
At time: 674.2920198440552 and batch: 700, loss is 3.7380105304718017 and perplexity is 42.0143207528351
At time: 675.6078279018402 and batch: 750, loss is 3.6931329107284547 and perplexity is 40.17050061601071
At time: 676.9246654510498 and batch: 800, loss is 3.658159656524658 and perplexity is 38.789890421228
At time: 678.2398564815521 and batch: 850, loss is 3.649929418563843 and perplexity is 38.47195054767984
At time: 679.5558068752289 and batch: 900, loss is 3.6131336975097654 and perplexity is 37.08207493664595
At time: 680.8682479858398 and batch: 950, loss is 3.72700701713562 and perplexity is 41.554549800997044
At time: 682.1811988353729 and batch: 1000, loss is 3.7010091447830202 and perplexity is 40.488142148404435
At time: 683.4984498023987 and batch: 1050, loss is 3.6510949325561524 and perplexity is 38.51681628509808
At time: 684.8161218166351 and batch: 1100, loss is 3.676411747932434 and perplexity is 39.504387746683854
At time: 686.1324136257172 and batch: 1150, loss is 3.6339722442626954 and perplexity is 37.862919061036436
At time: 687.4458739757538 and batch: 1200, loss is 3.693456563949585 and perplexity is 40.18350403211475
At time: 688.7597923278809 and batch: 1250, loss is 3.654838466644287 and perplexity is 38.66127552516769
At time: 690.0748982429504 and batch: 1300, loss is 3.649656262397766 and perplexity is 38.46144313231471
At time: 691.3914484977722 and batch: 1350, loss is 3.5207875299453737 and perplexity is 33.81104519231188
At time: 692.7076683044434 and batch: 1400, loss is 3.5596604919433594 and perplexity is 35.15126098270491
At time: 694.022943019867 and batch: 1450, loss is 3.459377408027649 and perplexity is 31.79717368568602
At time: 695.3383910655975 and batch: 1500, loss is 3.4597244310379027 and perplexity is 31.808209951424313
At time: 696.6542282104492 and batch: 1550, loss is 3.4668655824661254 and perplexity is 32.03617017583422
At time: 697.9699008464813 and batch: 1600, loss is 3.56669264793396 and perplexity is 35.3993213104218
At time: 699.2856180667877 and batch: 1650, loss is 3.5043449783325196 and perplexity is 33.25965092375482
At time: 700.605363368988 and batch: 1700, loss is 3.5186791753768922 and perplexity is 33.73983461566636
At time: 701.9179463386536 and batch: 1750, loss is 3.509171657562256 and perplexity is 33.42057263638706
At time: 703.2315139770508 and batch: 1800, loss is 3.4444277763366697 and perplexity is 31.325353208737205
At time: 704.5463807582855 and batch: 1850, loss is 3.4691709327697753 and perplexity is 32.1101099662891
At time: 705.8632361888885 and batch: 1900, loss is 3.5619410276412964 and perplexity is 35.23151616582561
At time: 707.1778523921967 and batch: 1950, loss is 3.514822397232056 and perplexity is 33.60995817221437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375908714117005 and perplexity of 79.51206046502683
finished 13 epochs...
Completing Train Step...
At time: 711.1310975551605 and batch: 50, loss is 3.763140263557434 and perplexity is 43.0835073402457
At time: 712.4474685192108 and batch: 100, loss is 3.735261907577515 and perplexity is 41.898997791196955
At time: 713.7615752220154 and batch: 150, loss is 3.7109735202789307 and perplexity is 40.89359790182831
At time: 715.0769557952881 and batch: 200, loss is 3.718629264831543 and perplexity is 41.207870300836916
At time: 716.3895330429077 and batch: 250, loss is 3.7183583307266237 and perplexity is 41.19670719568257
At time: 717.7030789852142 and batch: 300, loss is 3.714043850898743 and perplexity is 41.01934771558617
At time: 719.018328666687 and batch: 350, loss is 3.72818085193634 and perplexity is 41.60335661764747
At time: 720.3340039253235 and batch: 400, loss is 3.7156186866760255 and perplexity is 41.083997344842544
At time: 721.6483175754547 and batch: 450, loss is 3.751251425743103 and perplexity is 42.57432728601422
At time: 722.960791349411 and batch: 500, loss is 3.764658155441284 and perplexity is 43.148953103596206
At time: 724.2748081684113 and batch: 550, loss is 3.720040702819824 and perplexity is 41.266073719991574
At time: 725.6210830211639 and batch: 600, loss is 3.6836394596099855 and perplexity is 39.79094841276273
At time: 726.9361491203308 and batch: 650, loss is 3.6999906206130984 and perplexity is 40.446924990929794
At time: 728.251327753067 and batch: 700, loss is 3.7273576354980467 and perplexity is 41.56912214371584
At time: 729.5640587806702 and batch: 750, loss is 3.6828582382202146 and perplexity is 39.75987501192647
At time: 730.8776631355286 and batch: 800, loss is 3.648288550376892 and perplexity is 38.408874911490926
At time: 732.1929605007172 and batch: 850, loss is 3.639888606071472 and perplexity is 38.08759376238588
At time: 733.509937286377 and batch: 900, loss is 3.6033591413497925 and perplexity is 36.72137980186358
At time: 734.8239073753357 and batch: 950, loss is 3.7170606565475466 and perplexity is 41.14328196426055
At time: 736.1356866359711 and batch: 1000, loss is 3.690833420753479 and perplexity is 40.078235075053364
At time: 737.4470646381378 and batch: 1050, loss is 3.6411609077453613 and perplexity is 38.13608351193786
At time: 738.76176404953 and batch: 1100, loss is 3.666964201927185 and perplexity is 39.132925691400644
At time: 740.0790979862213 and batch: 1150, loss is 3.625421853065491 and perplexity is 37.54055641851717
At time: 741.3942728042603 and batch: 1200, loss is 3.6851852893829347 and perplexity is 39.852506012039804
At time: 742.7083957195282 and batch: 1250, loss is 3.647712860107422 and perplexity is 38.386769659442855
At time: 744.0210182666779 and batch: 1300, loss is 3.6433587408065797 and perplexity is 38.219992432228736
At time: 745.3338224887848 and batch: 1350, loss is 3.5150041675567625 and perplexity is 33.616068020502446
At time: 746.6493549346924 and batch: 1400, loss is 3.5543773221969603 and perplexity is 34.96604061028786
At time: 747.9666085243225 and batch: 1450, loss is 3.454960279464722 and perplexity is 31.65703122307604
At time: 749.2813303470612 and batch: 1500, loss is 3.4560743522644044 and perplexity is 31.69231911346997
At time: 750.5945506095886 and batch: 1550, loss is 3.4638618755340578 and perplexity is 31.940087284064557
At time: 751.9067828655243 and batch: 1600, loss is 3.5644382762908937 and perplexity is 35.319607969783014
At time: 753.2187790870667 and batch: 1650, loss is 3.5026040840148926 and perplexity is 33.2017997574496
At time: 754.5354161262512 and batch: 1700, loss is 3.5177764797210695 and perplexity is 33.70939155600671
At time: 755.8514161109924 and batch: 1750, loss is 3.509002995491028 and perplexity is 33.4149363287136
At time: 757.1649458408356 and batch: 1800, loss is 3.444790873527527 and perplexity is 31.336729421700404
At time: 758.4765403270721 and batch: 1850, loss is 3.4699262142181397 and perplexity is 32.134371297564975
At time: 759.7927582263947 and batch: 1900, loss is 3.563114333152771 and perplexity is 35.27287775806762
At time: 761.1086325645447 and batch: 1950, loss is 3.5149923276901247 and perplexity is 33.61567001309638
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3762451171875 and perplexity of 79.53881306588484
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 765.0477833747864 and batch: 50, loss is 3.7611992454528806 and perplexity is 42.99996257966696
At time: 766.371652841568 and batch: 100, loss is 3.740591549873352 and perplexity is 42.1229005929012
At time: 767.6869006156921 and batch: 150, loss is 3.7209709548950194 and perplexity is 41.30447943143155
At time: 769.0027649402618 and batch: 200, loss is 3.7326815271377565 and perplexity is 41.791021806322675
At time: 770.3172264099121 and batch: 250, loss is 3.733988347053528 and perplexity is 41.845670846369195
At time: 771.6455883979797 and batch: 300, loss is 3.731847162246704 and perplexity is 41.75616738763994
At time: 772.9585087299347 and batch: 350, loss is 3.752475214004517 and perplexity is 42.626461141878295
At time: 774.2735643386841 and batch: 400, loss is 3.745290536880493 and perplexity is 42.321301331672046
At time: 775.6005837917328 and batch: 450, loss is 3.7822503662109375 and perplexity is 43.9147549041241
At time: 776.9179503917694 and batch: 500, loss is 3.797622618675232 and perplexity is 44.59503895629416
At time: 778.231059551239 and batch: 550, loss is 3.7621037101745607 and perplexity is 43.03887212235567
At time: 779.5457882881165 and batch: 600, loss is 3.724699158668518 and perplexity is 41.45875836045289
At time: 780.8597965240479 and batch: 650, loss is 3.73769118309021 and perplexity is 42.000905731653276
At time: 782.1763017177582 and batch: 700, loss is 3.7647451305389406 and perplexity is 43.15270615121464
At time: 783.4923741817474 and batch: 750, loss is 3.713847322463989 and perplexity is 41.01128703948699
At time: 784.8083202838898 and batch: 800, loss is 3.67669695854187 and perplexity is 39.51565642408527
At time: 786.1201183795929 and batch: 850, loss is 3.6690923738479615 and perplexity is 39.21629596670826
At time: 787.4379329681396 and batch: 900, loss is 3.628930616378784 and perplexity is 37.67250870493328
At time: 788.7582547664642 and batch: 950, loss is 3.7436964893341065 and perplexity is 42.253892905516224
At time: 790.1032791137695 and batch: 1000, loss is 3.7142162704467774 and perplexity is 41.02642086273686
At time: 791.4181580543518 and batch: 1050, loss is 3.6615461683273316 and perplexity is 38.921475524459936
At time: 792.7311131954193 and batch: 1100, loss is 3.6827102279663086 and perplexity is 39.753990578219685
At time: 794.0440564155579 and batch: 1150, loss is 3.6378550481796266 and perplexity is 38.01021913506529
At time: 795.3603422641754 and batch: 1200, loss is 3.701641845703125 and perplexity is 40.513767138817734
At time: 796.6753141880035 and batch: 1250, loss is 3.667168927192688 and perplexity is 39.14093801013679
At time: 797.9879367351532 and batch: 1300, loss is 3.6632445526123045 and perplexity is 38.98763531330827
At time: 799.300865650177 and batch: 1350, loss is 3.5275789499282837 and perplexity is 34.041451708389395
At time: 800.6143620014191 and batch: 1400, loss is 3.565568552017212 and perplexity is 35.35955143464631
At time: 801.9294757843018 and batch: 1450, loss is 3.465780191421509 and perplexity is 32.00141726728121
At time: 803.2457180023193 and batch: 1500, loss is 3.4525679779052734 and perplexity is 31.581388574003142
At time: 804.5613424777985 and batch: 1550, loss is 3.456745409965515 and perplexity is 31.713593625691395
At time: 805.8766531944275 and batch: 1600, loss is 3.55276641368866 and perplexity is 34.909758862511396
At time: 807.1900744438171 and batch: 1650, loss is 3.490426626205444 and perplexity is 32.79993803480188
At time: 808.504340171814 and batch: 1700, loss is 3.5055702924728394 and perplexity is 33.30042942246729
At time: 809.8272552490234 and batch: 1750, loss is 3.5021276092529297 and perplexity is 33.185983706087306
At time: 811.1431946754456 and batch: 1800, loss is 3.4386604738235476 and perplexity is 31.14521038884323
At time: 812.4589879512787 and batch: 1850, loss is 3.4655001735687256 and perplexity is 31.992457553630437
At time: 813.7725789546967 and batch: 1900, loss is 3.559167981147766 and perplexity is 35.13395286975831
At time: 815.087345123291 and batch: 1950, loss is 3.517522587776184 and perplexity is 33.70083409940427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368579669331395 and perplexity of 78.9314432964786
finished 15 epochs...
Completing Train Step...
At time: 819.0157108306885 and batch: 50, loss is 3.7675225734710693 and perplexity is 43.27272692819068
At time: 820.3457434177399 and batch: 100, loss is 3.739081916809082 and perplexity is 42.05935844413525
At time: 821.659104347229 and batch: 150, loss is 3.713612937927246 and perplexity is 41.001675754385296
At time: 822.993515253067 and batch: 200, loss is 3.722090930938721 and perplexity is 41.35076537362731
At time: 824.3192930221558 and batch: 250, loss is 3.7189622354507446 and perplexity is 41.221593595527146
At time: 825.6338984966278 and batch: 300, loss is 3.7143406963348387 and perplexity is 41.03152592918131
At time: 826.9479722976685 and batch: 350, loss is 3.734005093574524 and perplexity is 41.846371621642376
At time: 828.2598602771759 and batch: 400, loss is 3.7242607402801515 and perplexity is 41.44058606225474
At time: 829.573760509491 and batch: 450, loss is 3.761702313423157 and perplexity is 43.02159992563541
At time: 830.8901240825653 and batch: 500, loss is 3.778782019615173 and perplexity is 43.76270714303644
At time: 832.2053771018982 and batch: 550, loss is 3.741484022140503 and perplexity is 42.1605108940713
At time: 833.520001411438 and batch: 600, loss is 3.7052857065200806 and perplexity is 40.66166295969222
At time: 834.8347861766815 and batch: 650, loss is 3.718983554840088 and perplexity is 41.22247242409836
At time: 836.1479172706604 and batch: 700, loss is 3.7467223453521727 and perplexity is 42.38194073109453
At time: 837.4619863033295 and batch: 750, loss is 3.6981269788742064 and perplexity is 40.371616609025274
At time: 838.7779998779297 and batch: 800, loss is 3.662514319419861 and perplexity is 38.95917564027121
At time: 840.0931270122528 and batch: 850, loss is 3.6548823738098144 and perplexity is 38.66297306945858
At time: 841.4049723148346 and batch: 900, loss is 3.616771926879883 and perplexity is 37.217233751081345
At time: 842.716322183609 and batch: 950, loss is 3.7312849044799803 and perplexity is 41.73269625724863
At time: 844.030225276947 and batch: 1000, loss is 3.702530446052551 and perplexity is 40.54978368624226
At time: 845.3512215614319 and batch: 1050, loss is 3.6502599334716797 and perplexity is 38.48466820244088
At time: 846.6730170249939 and batch: 1100, loss is 3.6732720851898195 and perplexity is 39.38055179559259
At time: 847.9923610687256 and batch: 1150, loss is 3.628867521286011 and perplexity is 37.67013182948692
At time: 849.3052616119385 and batch: 1200, loss is 3.6926128101348876 and perplexity is 40.14961334700778
At time: 850.6191501617432 and batch: 1250, loss is 3.658289837837219 and perplexity is 38.79494046878091
At time: 851.9356410503387 and batch: 1300, loss is 3.6551447439193727 and perplexity is 38.67311840879736
At time: 853.2504394054413 and batch: 1350, loss is 3.521927585601807 and perplexity is 33.84961364654812
At time: 854.5649614334106 and batch: 1400, loss is 3.5615805196762085 and perplexity is 35.218817212800104
At time: 855.8869059085846 and batch: 1450, loss is 3.4626343345642088 and perplexity is 31.900903573068465
At time: 857.2010612487793 and batch: 1500, loss is 3.4535663890838624 and perplexity is 31.612935531187578
At time: 858.5188791751862 and batch: 1550, loss is 3.45877432346344 and perplexity is 31.77800308237923
At time: 859.837212562561 and batch: 1600, loss is 3.556616048812866 and perplexity is 35.044407704574205
At time: 861.1531188488007 and batch: 1650, loss is 3.4964282369613646 and perplexity is 32.99738239515266
At time: 862.4669814109802 and batch: 1700, loss is 3.51280827999115 and perplexity is 33.542331902472945
At time: 863.7813668251038 and batch: 1750, loss is 3.5111573123931885 and perplexity is 33.487000287261914
At time: 865.0968585014343 and batch: 1800, loss is 3.4473154497146608 and perplexity is 31.41594132875691
At time: 866.412590265274 and batch: 1850, loss is 3.474423232078552 and perplexity is 32.279205556263435
At time: 867.729250907898 and batch: 1900, loss is 3.567941036224365 and perplexity is 35.44354100456526
At time: 869.044575214386 and batch: 1950, loss is 3.524602928161621 and perplexity is 33.94029420526219
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366780693586483 and perplexity of 78.78957519137815
finished 16 epochs...
Completing Train Step...
At time: 872.9913718700409 and batch: 50, loss is 3.767681517601013 and perplexity is 43.279605420756106
At time: 874.3210663795471 and batch: 100, loss is 3.7364034938812254 and perplexity is 41.94685642539772
At time: 875.6350417137146 and batch: 150, loss is 3.7096298933029175 and perplexity is 40.838689057304265
At time: 876.9491260051727 and batch: 200, loss is 3.7165638828277587 and perplexity is 41.12284813894882
At time: 878.2625203132629 and batch: 250, loss is 3.712036828994751 and perplexity is 40.93710354676524
At time: 879.5786061286926 and batch: 300, loss is 3.706508159637451 and perplexity is 40.71140033094311
At time: 880.895081281662 and batch: 350, loss is 3.7260461187362672 and perplexity is 41.51463927865683
At time: 882.2111177444458 and batch: 400, loss is 3.7156619310379027 and perplexity is 41.08577403450671
At time: 883.5247890949249 and batch: 450, loss is 3.753290681838989 and perplexity is 42.66123582672829
At time: 884.8374650478363 and batch: 500, loss is 3.770835447311401 and perplexity is 43.41632173764384
At time: 886.1498589515686 and batch: 550, loss is 3.7330825185775756 and perplexity is 41.80778300865304
At time: 887.4663031101227 and batch: 600, loss is 3.6975307703018188 and perplexity is 40.34755387903756
At time: 888.7925913333893 and batch: 650, loss is 3.7110313510894777 and perplexity is 40.8959628801248
At time: 890.1067130565643 and batch: 700, loss is 3.7391353845596313 and perplexity is 42.06160732354153
At time: 891.4182770252228 and batch: 750, loss is 3.6917317056655885 and perplexity is 40.11425292364829
At time: 892.7316431999207 and batch: 800, loss is 3.6566859674453736 and perplexity is 38.73276828380061
At time: 894.0477104187012 and batch: 850, loss is 3.6491814136505125 and perplexity is 38.44318409970825
At time: 895.3693945407867 and batch: 900, loss is 3.6117336177825927 and perplexity is 37.03019340290241
At time: 896.6866509914398 and batch: 950, loss is 3.725970997810364 and perplexity is 41.51152077764948
At time: 897.9992291927338 and batch: 1000, loss is 3.6977017307281494 and perplexity is 40.35445230371214
At time: 899.3119053840637 and batch: 1050, loss is 3.64571674823761 and perplexity is 38.3102217973468
At time: 900.6269555091858 and batch: 1100, loss is 3.66934853553772 and perplexity is 39.22634296612239
At time: 901.9445602893829 and batch: 1150, loss is 3.625396656990051 and perplexity is 37.53961055574166
At time: 903.2593741416931 and batch: 1200, loss is 3.6891170167922973 and perplexity is 40.00950363594435
At time: 904.5723614692688 and batch: 1250, loss is 3.65513129234314 and perplexity is 38.67259819789576
At time: 905.8852770328522 and batch: 1300, loss is 3.6524315595626833 and perplexity is 38.56833332381304
At time: 907.1992783546448 and batch: 1350, loss is 3.5201510906219484 and perplexity is 33.78953335979957
At time: 908.5143399238586 and batch: 1400, loss is 3.5603646850585937 and perplexity is 35.17602297627016
At time: 909.8281955718994 and batch: 1450, loss is 3.461799874305725 and perplexity is 31.874294640419468
At time: 911.1440961360931 and batch: 1500, loss is 3.45417076587677 and perplexity is 31.63204743059079
At time: 912.4565126895905 and batch: 1550, loss is 3.459562301635742 and perplexity is 31.8030533233929
At time: 913.7701704502106 and batch: 1600, loss is 3.55809202671051 and perplexity is 35.09617066687914
At time: 915.0861079692841 and batch: 1650, loss is 3.4984989261627195 and perplexity is 33.06578050973039
At time: 916.401533126831 and batch: 1700, loss is 3.5152011919021606 and perplexity is 33.62269185680612
At time: 917.717779636383 and batch: 1750, loss is 3.514133152961731 and perplexity is 33.58680068261859
At time: 919.0312173366547 and batch: 1800, loss is 3.4502011203765868 and perplexity is 31.506728316640487
At time: 920.3438992500305 and batch: 1850, loss is 3.477349319458008 and perplexity is 32.373795654216465
At time: 921.6587979793549 and batch: 1900, loss is 3.570703206062317 and perplexity is 35.54157741876004
At time: 922.9743421077728 and batch: 1950, loss is 3.5263745975494385 and perplexity is 34.00047848309824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3661138490188955 and perplexity of 78.73705230542619
finished 17 epochs...
Completing Train Step...
At time: 926.9355957508087 and batch: 50, loss is 3.765851459503174 and perplexity is 43.200473658330964
At time: 928.2529957294464 and batch: 100, loss is 3.7332784652709963 and perplexity is 41.8159759081524
At time: 929.567690372467 and batch: 150, loss is 3.706002721786499 and perplexity is 40.690828447592786
At time: 930.8827660083771 and batch: 200, loss is 3.7122738265991213 and perplexity is 40.94680669200136
At time: 932.19704246521 and batch: 250, loss is 3.7071906995773314 and perplexity is 40.73919697275743
At time: 933.508855342865 and batch: 300, loss is 3.7014262580871584 and perplexity is 40.505033813778645
At time: 934.8249306678772 and batch: 350, loss is 3.7210117101669313 and perplexity is 41.30616284102563
At time: 936.1415514945984 and batch: 400, loss is 3.7104895448684694 and perplexity is 40.87381119452465
At time: 937.4566757678986 and batch: 450, loss is 3.7482549571990966 and perplexity is 42.446945596443854
At time: 938.7721154689789 and batch: 500, loss is 3.7659261560440065 and perplexity is 43.20370070479868
At time: 940.102522611618 and batch: 550, loss is 3.7281774520874023 and perplexity is 41.60321517276011
At time: 941.4162063598633 and batch: 600, loss is 3.6929690217971802 and perplexity is 40.163917655047946
At time: 942.7324917316437 and batch: 650, loss is 3.706303858757019 and perplexity is 40.70308380557752
At time: 944.0486133098602 and batch: 700, loss is 3.734712657928467 and perplexity is 41.875991100151545
At time: 945.3629541397095 and batch: 750, loss is 3.687974143028259 and perplexity is 39.96380394339072
At time: 946.6769282817841 and batch: 800, loss is 3.6532423973083494 and perplexity is 38.599618666213615
At time: 947.988683462143 and batch: 850, loss is 3.645776615142822 and perplexity is 38.31251538041798
At time: 949.3023228645325 and batch: 900, loss is 3.608617606163025 and perplexity is 36.914986476262214
At time: 950.6174638271332 and batch: 950, loss is 3.7227845668792723 and perplexity is 41.37945770052394
At time: 951.9335420131683 and batch: 1000, loss is 3.6947014474868776 and perplexity is 40.233558964571415
At time: 953.2650163173676 and batch: 1050, loss is 3.642853469848633 and perplexity is 38.20068585797616
At time: 954.5810635089874 and batch: 1100, loss is 3.666757655143738 and perplexity is 39.12484374615085
At time: 955.8954951763153 and batch: 1150, loss is 3.623140912055969 and perplexity is 37.45502620562925
At time: 957.2194797992706 and batch: 1200, loss is 3.686821098327637 and perplexity is 39.917750447009446
At time: 958.5341739654541 and batch: 1250, loss is 3.653144807815552 and perplexity is 38.595851932805594
At time: 959.855062007904 and batch: 1300, loss is 3.6506977033615113 and perplexity is 38.501519319586805
At time: 961.169855594635 and batch: 1350, loss is 3.518865532875061 and perplexity is 33.746122872747684
At time: 962.4843039512634 and batch: 1400, loss is 3.559323205947876 and perplexity is 35.1394069538632
At time: 963.7989988327026 and batch: 1450, loss is 3.4609168004989623 and perplexity is 31.846159710151806
At time: 965.1159965991974 and batch: 1500, loss is 3.4539702415466307 and perplexity is 31.625705071388758
At time: 966.4306001663208 and batch: 1550, loss is 3.459441890716553 and perplexity is 31.799224119052838
At time: 967.7431573867798 and batch: 1600, loss is 3.5582863807678224 and perplexity is 35.10299241293991
At time: 969.0566010475159 and batch: 1650, loss is 3.4989050674438475 and perplexity is 33.079212615669825
At time: 970.3714818954468 and batch: 1700, loss is 3.5157583284378053 and perplexity is 33.641429506096095
At time: 971.6927812099457 and batch: 1750, loss is 3.5149446392059325 and perplexity is 33.614066970971976
At time: 973.0068168640137 and batch: 1800, loss is 3.4510461711883544 and perplexity is 31.533364355798774
At time: 974.3175666332245 and batch: 1850, loss is 3.4782369422912596 and perplexity is 32.40254413145307
At time: 975.628748178482 and batch: 1900, loss is 3.5714831924438477 and perplexity is 35.56931017930657
At time: 976.9409918785095 and batch: 1950, loss is 3.5265458154678346 and perplexity is 34.00630047264884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365859204669332 and perplexity of 78.71700491254128
finished 18 epochs...
Completing Train Step...
At time: 980.8926010131836 and batch: 50, loss is 3.7636225605010987 and perplexity is 43.104291395798604
At time: 982.203742980957 and batch: 100, loss is 3.7303471612930297 and perplexity is 41.69358004900565
At time: 983.5148973464966 and batch: 150, loss is 3.702793207168579 and perplexity is 40.5604399926285
At time: 984.8313057422638 and batch: 200, loss is 3.708734393119812 and perplexity is 40.802134373581474
At time: 986.1553635597229 and batch: 250, loss is 3.70338143825531 and perplexity is 40.58430592297657
At time: 987.4697580337524 and batch: 300, loss is 3.697564206123352 and perplexity is 40.34890295520198
At time: 988.7831842899323 and batch: 350, loss is 3.717194743156433 and perplexity is 41.14879909729616
At time: 990.0967898368835 and batch: 400, loss is 3.7066587924957277 and perplexity is 40.71753326743868
At time: 991.4102132320404 and batch: 450, loss is 3.7445400619506835 and perplexity is 42.2895521709904
At time: 992.72536444664 and batch: 500, loss is 3.7622158575057982 and perplexity is 43.043699087664244
At time: 994.0457677841187 and batch: 550, loss is 3.7245879983901977 and perplexity is 41.45415004947004
At time: 995.3582549095154 and batch: 600, loss is 3.6896116590499877 and perplexity is 40.02929892254092
At time: 996.6689484119415 and batch: 650, loss is 3.7028125858306886 and perplexity is 40.561226007306075
At time: 997.9893200397491 and batch: 700, loss is 3.731489748954773 and perplexity is 41.74124584513316
At time: 999.3053181171417 and batch: 750, loss is 3.6851508951187135 and perplexity is 39.85113533798995
At time: 1000.6242182254791 and batch: 800, loss is 3.6506261110305784 and perplexity is 38.49876300474094
At time: 1001.9393074512482 and batch: 850, loss is 3.6431410837173464 and perplexity is 38.21167448518832
At time: 1003.2515618801117 and batch: 900, loss is 3.606144380569458 and perplexity is 36.82380019552563
At time: 1004.5647733211517 and batch: 950, loss is 3.720298447608948 and perplexity is 41.27671120627994
At time: 1005.881502866745 and batch: 1000, loss is 3.692277636528015 and perplexity is 40.1361585112666
At time: 1007.2029449939728 and batch: 1050, loss is 3.6405102586746216 and perplexity is 38.11127837523384
At time: 1008.5254230499268 and batch: 1100, loss is 3.664551019668579 and perplexity is 39.0386046620849
At time: 1009.8376626968384 and batch: 1150, loss is 3.621209855079651 and perplexity is 37.382768205588285
At time: 1011.1502614021301 and batch: 1200, loss is 3.6848632669448853 and perplexity is 39.839674676991216
At time: 1012.472802400589 and batch: 1250, loss is 3.6514496660232543 and perplexity is 38.53048191256502
At time: 1013.7885551452637 and batch: 1300, loss is 3.6491813468933105 and perplexity is 38.44318153334893
At time: 1015.1087620258331 and batch: 1350, loss is 3.5176159381866454 and perplexity is 33.70398023294448
At time: 1016.4251668453217 and batch: 1400, loss is 3.5582107734680175 and perplexity is 35.10033847079846
At time: 1017.7409381866455 and batch: 1450, loss is 3.459902639389038 and perplexity is 31.813878945188343
At time: 1019.0578217506409 and batch: 1500, loss is 3.4533816146850587 and perplexity is 31.607094809654903
At time: 1020.3768389225006 and batch: 1550, loss is 3.4589183378219603 and perplexity is 31.78257990066406
At time: 1021.6959273815155 and batch: 1600, loss is 3.5579452896118164 and perplexity is 35.09102113444319
At time: 1023.0159041881561 and batch: 1650, loss is 3.4986750793457033 and perplexity is 33.0716056652598
At time: 1024.3378286361694 and batch: 1700, loss is 3.515626783370972 and perplexity is 33.63700443305799
At time: 1025.6551296710968 and batch: 1750, loss is 3.5149690914154053 and perplexity is 33.614888919227965
At time: 1026.974078655243 and batch: 1800, loss is 3.4511437797546387 and perplexity is 31.536442432504547
At time: 1028.2956099510193 and batch: 1850, loss is 3.478391604423523 and perplexity is 32.40755596557968
At time: 1029.6138360500336 and batch: 1900, loss is 3.5715892934799194 and perplexity is 35.57308432018554
At time: 1030.930884361267 and batch: 1950, loss is 3.5262171411514283 and perplexity is 33.99512531168227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365806118277616 and perplexity of 78.71282622170062
finished 19 epochs...
Completing Train Step...
At time: 1034.9134752750397 and batch: 50, loss is 3.7614055919647216 and perplexity is 43.00883638746273
At time: 1036.2319464683533 and batch: 100, loss is 3.7276801443099976 and perplexity is 41.58253071398706
At time: 1037.5557882785797 and batch: 150, loss is 3.6999373388290406 and perplexity is 40.44476996401898
At time: 1038.8777260780334 and batch: 200, loss is 3.7056786012649536 and perplexity is 40.67764185219278
At time: 1040.1980595588684 and batch: 250, loss is 3.700170593261719 and perplexity is 40.454204986229335
At time: 1041.5171360969543 and batch: 300, loss is 3.694342379570007 and perplexity is 40.21911497770705
At time: 1042.837703704834 and batch: 350, loss is 3.7139926862716677 and perplexity is 41.01724902964714
At time: 1044.1564855575562 and batch: 400, loss is 3.7034705448150635 and perplexity is 40.5879224119814
At time: 1045.4721937179565 and batch: 450, loss is 3.7414525604248046 and perplexity is 42.1591844729297
At time: 1046.7885949611664 and batch: 500, loss is 3.75908833026886 and perplexity is 42.909289041489316
At time: 1048.1082537174225 and batch: 550, loss is 3.7215979957580565 and perplexity is 41.33038714961165
At time: 1049.4288160800934 and batch: 600, loss is 3.6868065881729124 and perplexity is 39.91717123847643
At time: 1050.746661901474 and batch: 650, loss is 3.699894871711731 and perplexity is 40.443052427698014
At time: 1052.075588464737 and batch: 700, loss is 3.7288097238540647 and perplexity is 41.62952802867759
At time: 1053.3930525779724 and batch: 750, loss is 3.682732930183411 and perplexity is 39.754893092188965
At time: 1054.7131419181824 and batch: 800, loss is 3.6483590698242185 and perplexity is 38.41158357962789
At time: 1056.0326099395752 and batch: 850, loss is 3.6408297491073607 and perplexity is 38.12345650934925
At time: 1057.3492033481598 and batch: 900, loss is 3.6039392232894896 and perplexity is 36.742687390563596
At time: 1058.6674482822418 and batch: 950, loss is 3.718095202445984 and perplexity is 41.185868602982815
At time: 1059.983544588089 and batch: 1000, loss is 3.6900885009765627 and perplexity is 40.048391122177456
At time: 1061.3151338100433 and batch: 1050, loss is 3.63838641166687 and perplexity is 38.03042174464498
At time: 1062.640823841095 and batch: 1100, loss is 3.6625024366378782 and perplexity is 38.95871269963136
At time: 1063.969537973404 and batch: 1150, loss is 3.6194013071060183 and perplexity is 37.31522077569645
At time: 1065.2891545295715 and batch: 1200, loss is 3.683044638633728 and perplexity is 39.767286959843545
At time: 1066.604457616806 and batch: 1250, loss is 3.649853992462158 and perplexity is 38.46904886785839
At time: 1067.9216191768646 and batch: 1300, loss is 3.647736964225769 and perplexity is 38.387694949833296
At time: 1069.2395603656769 and batch: 1350, loss is 3.516358370780945 and perplexity is 33.66162184580706
At time: 1070.5587599277496 and batch: 1400, loss is 3.5570457792282104 and perplexity is 35.05947058871051
At time: 1071.8834524154663 and batch: 1450, loss is 3.4588220739364623 and perplexity is 31.77952053328733
At time: 1073.200024843216 and batch: 1500, loss is 3.4526164674758912 and perplexity is 31.5829199791029
At time: 1074.516144990921 and batch: 1550, loss is 3.4582127809524534 and perplexity is 31.76016339207524
At time: 1075.8368401527405 and batch: 1600, loss is 3.557365756034851 and perplexity is 35.07069060112814
At time: 1077.156315088272 and batch: 1650, loss is 3.4981792068481443 and perplexity is 33.055210430869145
At time: 1078.4753501415253 and batch: 1700, loss is 3.515205535888672 and perplexity is 33.62283791364326
At time: 1079.792406320572 and batch: 1750, loss is 3.5146655321121214 and perplexity is 33.60468635558758
At time: 1081.1086201667786 and batch: 1800, loss is 3.450927004814148 and perplexity is 31.5296068629898
At time: 1082.4257836341858 and batch: 1850, loss is 3.478241891860962 and perplexity is 32.40270451050069
At time: 1083.7512257099152 and batch: 1900, loss is 3.57143424987793 and perplexity is 35.56756936859868
At time: 1085.0704369544983 and batch: 1950, loss is 3.525715780258179 and perplexity is 33.97808575712996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365860340207122 and perplexity of 78.71709429872583
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
3349.463842391968


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.71282622170062}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.8965078080331692, 'wordvec_dim': 300, 'dropout': 0.6142191105838335, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9714994430541992 and batch: 50, loss is 7.664757709503174 and perplexity is 2131.8761860269115
At time: 3.4964611530303955 and batch: 100, loss is 6.806419076919556 and perplexity is 903.6291798166492
At time: 5.027538299560547 and batch: 150, loss is 6.5877188777923585 and perplexity is 726.1226048658698
At time: 6.55667781829834 and batch: 200, loss is 6.524922275543213 and perplexity is 681.9267692031464
At time: 8.08044695854187 and batch: 250, loss is 6.48232780456543 and perplexity is 653.4903749968848
At time: 9.603585481643677 and batch: 300, loss is 6.401504821777344 and perplexity is 602.7513891692082
At time: 11.125471353530884 and batch: 350, loss is 6.3589951705932615 and perplexity is 577.665609275238
At time: 12.650057554244995 and batch: 400, loss is 6.332428340911865 and perplexity is 562.5209292330784
At time: 14.174107551574707 and batch: 450, loss is 6.247453393936158 and perplexity is 516.6953283519669
At time: 15.696357011795044 and batch: 500, loss is 6.2296233749389645 and perplexity is 507.56428606296345
At time: 17.22190761566162 and batch: 550, loss is 6.182245998382569 and perplexity is 484.0779746466777
At time: 18.7563738822937 and batch: 600, loss is 6.234438829421997 and perplexity is 510.0143330902544
At time: 20.292312622070312 and batch: 650, loss is 6.320812492370606 and perplexity is 556.0245746978067
At time: 21.831333875656128 and batch: 700, loss is 6.217205934524536 and perplexity is 501.3006067012378
At time: 23.36916422843933 and batch: 750, loss is 6.151763257980346 and perplexity is 469.54458552325974
At time: 24.903992652893066 and batch: 800, loss is 6.152195510864257 and perplexity is 469.7475913962532
At time: 26.440532207489014 and batch: 850, loss is 6.207157859802246 and perplexity is 496.2887228068778
At time: 27.976665258407593 and batch: 900, loss is 6.202845268249511 and perplexity is 494.1530407254649
At time: 29.515552043914795 and batch: 950, loss is 6.204523029327393 and perplexity is 494.9828073441379
At time: 31.05589461326599 and batch: 1000, loss is 6.19927267074585 and perplexity is 492.39078060317564
At time: 32.59105825424194 and batch: 1050, loss is 6.093161525726319 and perplexity is 442.81918467768946
At time: 34.12802839279175 and batch: 1100, loss is 6.169012336730957 and perplexity is 477.71405238993304
At time: 35.65888428688049 and batch: 1150, loss is 6.073303098678589 and perplexity is 434.1122315358565
At time: 37.192904472351074 and batch: 1200, loss is 6.157512121200561 and perplexity is 472.2517071013309
At time: 38.725772857666016 and batch: 1250, loss is 6.093972387313843 and perplexity is 443.1783953601539
At time: 40.25912928581238 and batch: 1300, loss is 6.109577045440674 and perplexity is 450.14828262979364
At time: 41.791972398757935 and batch: 1350, loss is 6.110426778793335 and perplexity is 450.5309511992851
At time: 43.32469606399536 and batch: 1400, loss is 6.122420892715454 and perplexity is 455.9672071188808
At time: 44.85600972175598 and batch: 1450, loss is 6.106094007492065 and perplexity is 448.5831264104611
At time: 46.386696100234985 and batch: 1500, loss is 6.093792819976807 and perplexity is 443.09882214045655
At time: 47.92045879364014 and batch: 1550, loss is 6.075049304962159 and perplexity is 434.87094328315817
At time: 49.452104330062866 and batch: 1600, loss is 6.0647735595703125 and perplexity is 430.42520096882663
At time: 50.98443841934204 and batch: 1650, loss is 6.06069522857666 and perplexity is 428.67335925461214
At time: 52.51553821563721 and batch: 1700, loss is 6.076423416137695 and perplexity is 435.4689150519948
At time: 54.04856014251709 and batch: 1750, loss is 6.097305221557617 and perplexity is 444.65789959399734
At time: 55.58123016357422 and batch: 1800, loss is 6.106524686813355 and perplexity is 448.7763634955069
At time: 57.11298608779907 and batch: 1850, loss is 6.056271171569824 and perplexity is 426.7810727539964
At time: 58.64612650871277 and batch: 1900, loss is 6.018151407241821 and perplexity is 410.8184573248245
At time: 60.17778277397156 and batch: 1950, loss is 5.961497087478637 and perplexity is 388.1908450878667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.517019440406977 and perplexity of 248.89209282982287
finished 1 epochs...
Completing Train Step...
At time: 64.20748043060303 and batch: 50, loss is 5.8350377368927 and perplexity is 342.0776427540052
At time: 65.52151346206665 and batch: 100, loss is 5.77422986984253 and perplexity is 321.8964370817253
At time: 66.83324575424194 and batch: 150, loss is 5.625695676803589 and perplexity is 277.46524353052536
At time: 68.14431548118591 and batch: 200, loss is 5.573251533508301 and perplexity is 263.2888013008483
At time: 69.46804213523865 and batch: 250, loss is 5.544429273605346 and perplexity is 255.8085398875715
At time: 70.79356622695923 and batch: 300, loss is 5.520326499938965 and perplexity is 249.71655632137129
At time: 72.12282037734985 and batch: 350, loss is 5.453261337280273 and perplexity is 233.51850798346683
At time: 73.4384593963623 and batch: 400, loss is 5.4066589832305905 and perplexity is 222.8856775389265
At time: 74.75570034980774 and batch: 450, loss is 5.341227979660034 and perplexity is 208.76891693226793
At time: 76.0704665184021 and batch: 500, loss is 5.3090921401977536 and perplexity is 202.16660611407124
At time: 77.38670802116394 and batch: 550, loss is 5.260935287475586 and perplexity is 192.66160103940175
At time: 78.69895386695862 and batch: 600, loss is 5.259288034439087 and perplexity is 192.3444998767023
At time: 80.01087617874146 and batch: 650, loss is 5.319455242156982 and perplexity is 204.27257259135337
At time: 81.32176995277405 and batch: 700, loss is 5.267860555648804 and perplexity is 194.00046493813946
At time: 82.63364744186401 and batch: 750, loss is 5.208039627075196 and perplexity is 182.73547715046436
At time: 83.95192098617554 and batch: 800, loss is 5.197280788421631 and perplexity is 180.7799938627661
At time: 85.26946520805359 and batch: 850, loss is 5.197534513473511 and perplexity is 180.8258680955627
At time: 86.58122181892395 and batch: 900, loss is 5.196972455978393 and perplexity is 180.72426211796395
At time: 87.8912992477417 and batch: 950, loss is 5.236218252182007 and perplexity is 187.95794710220272
At time: 89.20113492012024 and batch: 1000, loss is 5.199147701263428 and perplexity is 181.11780959299332
At time: 90.51125073432922 and batch: 1050, loss is 5.094449710845947 and perplexity is 163.11406002480246
At time: 91.82478356361389 and batch: 1100, loss is 5.179866132736206 and perplexity is 177.6590266736399
At time: 93.13645076751709 and batch: 1150, loss is 5.0738178253173825 and perplexity is 159.78318864359647
At time: 94.44865107536316 and batch: 1200, loss is 5.149589366912842 and perplexity is 172.36069877733118
At time: 95.75829744338989 and batch: 1250, loss is 5.087608051300049 and perplexity is 162.00189801408033
At time: 97.0698630809784 and batch: 1300, loss is 5.114400157928467 and perplexity is 166.40093675831878
At time: 98.38373470306396 and batch: 1350, loss is 5.0327151584625245 and perplexity is 153.3488142873962
At time: 99.69884777069092 and batch: 1400, loss is 5.046263971328735 and perplexity is 155.4406476047336
At time: 101.01321458816528 and batch: 1450, loss is 4.987315940856933 and perplexity is 146.54256624928462
At time: 102.32405185699463 and batch: 1500, loss is 4.95754415512085 and perplexity is 142.2440373057474
At time: 103.63995552062988 and batch: 1550, loss is 4.942728471755982 and perplexity is 140.15212947562532
At time: 104.95762896537781 and batch: 1600, loss is 5.00333604812622 and perplexity is 148.90909932417858
At time: 106.27142643928528 and batch: 1650, loss is 4.9676752853393555 and perplexity is 143.6924548350454
At time: 107.58589100837708 and batch: 1700, loss is 4.974760427474975 and perplexity is 144.71415146024313
At time: 108.89745259284973 and batch: 1750, loss is 4.986664609909058 and perplexity is 146.447149617981
At time: 110.20981001853943 and batch: 1800, loss is 4.947569704055786 and perplexity is 140.83228355525148
At time: 111.52334761619568 and batch: 1850, loss is 4.940230350494385 and perplexity is 139.80244941457326
At time: 112.83901834487915 and batch: 1900, loss is 4.992651453018189 and perplexity is 147.3265354724963
At time: 114.15405368804932 and batch: 1950, loss is 4.911760540008545 and perplexity is 135.87842335493917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.750047408702762 and perplexity of 115.58976435807155
finished 2 epochs...
Completing Train Step...
At time: 118.12189817428589 and batch: 50, loss is 4.897444496154785 and perplexity is 133.94703975970071
At time: 119.44746351242065 and batch: 100, loss is 4.84836410522461 and perplexity is 127.53159084283743
At time: 120.7608642578125 and batch: 150, loss is 4.788960247039795 and perplexity is 120.1763499645752
At time: 122.07156586647034 and batch: 200, loss is 4.773664970397949 and perplexity is 118.35220540628026
At time: 123.38286566734314 and batch: 250, loss is 4.794951238632202 and perplexity is 120.89848646375893
At time: 124.6957516670227 and batch: 300, loss is 4.8187417221069335 and perplexity is 123.80920634012303
At time: 126.00883531570435 and batch: 350, loss is 4.804742164611817 and perplexity is 122.08800835365719
At time: 127.32381534576416 and batch: 400, loss is 4.763729248046875 and perplexity is 117.18211323499956
At time: 128.63813710212708 and batch: 450, loss is 4.745508489608764 and perplexity is 115.06630064796077
At time: 129.95085096359253 and batch: 500, loss is 4.75825047492981 and perplexity is 116.5418545408181
At time: 131.2634515762329 and batch: 550, loss is 4.711708478927612 and perplexity is 111.24205234819237
At time: 132.5773425102234 and batch: 600, loss is 4.6905362510681154 and perplexity is 108.91156809534715
At time: 133.89243245124817 and batch: 650, loss is 4.755112609863281 and perplexity is 116.17673507406244
At time: 135.206200838089 and batch: 700, loss is 4.763501968383789 and perplexity is 117.15548315013677
At time: 136.51937127113342 and batch: 750, loss is 4.716830787658691 and perplexity is 111.81333036628757
At time: 137.840660572052 and batch: 800, loss is 4.707947635650635 and perplexity is 110.82447413878567
At time: 139.15283131599426 and batch: 850, loss is 4.704128742218018 and perplexity is 110.40205438371682
At time: 140.46685552597046 and batch: 900, loss is 4.693342170715332 and perplexity is 109.21759434582603
At time: 141.78093433380127 and batch: 950, loss is 4.7531760311126705 and perplexity is 115.9519673880112
At time: 143.09956979751587 and batch: 1000, loss is 4.734008493423462 and perplexity is 113.7506183003162
At time: 144.4129958152771 and batch: 1050, loss is 4.659446411132812 and perplexity is 105.57761938126808
At time: 145.7231924533844 and batch: 1100, loss is 4.720934019088745 and perplexity is 112.27306889951271
At time: 147.03456807136536 and batch: 1150, loss is 4.646160717010498 and perplexity is 104.18422403179436
At time: 148.34999799728394 and batch: 1200, loss is 4.727800483703613 and perplexity is 113.04664076685778
At time: 149.6746950149536 and batch: 1250, loss is 4.6865997409820555 and perplexity is 108.48367935577156
At time: 150.9997913837433 and batch: 1300, loss is 4.708120489120484 and perplexity is 110.84363218940477
At time: 152.31084656715393 and batch: 1350, loss is 4.599595403671264 and perplexity is 99.44407279466141
At time: 153.62452507019043 and batch: 1400, loss is 4.618396606445312 and perplexity is 101.33142764691581
At time: 154.93981051445007 and batch: 1450, loss is 4.551999025344848 and perplexity is 94.82177010403845
At time: 156.2514090538025 and batch: 1500, loss is 4.544245433807373 and perplexity is 94.08940373367803
At time: 157.56581616401672 and batch: 1550, loss is 4.539019174575806 and perplexity is 93.59895085211541
At time: 158.87611842155457 and batch: 1600, loss is 4.621782703399658 and perplexity is 101.6751272571573
At time: 160.1875193119049 and batch: 1650, loss is 4.57707350730896 and perplexity is 97.22943621225389
At time: 161.50128388404846 and batch: 1700, loss is 4.603116178512574 and perplexity is 99.7948100554287
At time: 162.81621623039246 and batch: 1750, loss is 4.606689357757569 and perplexity is 100.1520326295477
At time: 164.12766337394714 and batch: 1800, loss is 4.552716703414917 and perplexity is 94.88984603438641
At time: 165.4370448589325 and batch: 1850, loss is 4.577268648147583 and perplexity is 97.24841149734151
At time: 166.75268149375916 and batch: 1900, loss is 4.659012069702149 and perplexity is 105.53177260431808
At time: 168.06914639472961 and batch: 1950, loss is 4.590103244781494 and perplexity is 98.50459972283477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5710710392441865 and perplexity of 96.64756769706496
finished 3 epochs...
Completing Train Step...
At time: 172.01771759986877 and batch: 50, loss is 4.567439908981323 and perplexity is 96.29726417293091
At time: 173.33972191810608 and batch: 100, loss is 4.513391771316528 and perplexity is 91.23072810580832
At time: 174.65229868888855 and batch: 150, loss is 4.460472545623779 and perplexity is 86.52838804808863
At time: 175.96740555763245 and batch: 200, loss is 4.46207221031189 and perplexity is 86.66691522394397
At time: 177.28126430511475 and batch: 250, loss is 4.477604885101318 and perplexity is 88.02359337703817
At time: 178.5951693058014 and batch: 300, loss is 4.501050443649292 and perplexity is 90.1117389057035
At time: 179.90634417533875 and batch: 350, loss is 4.513345460891724 and perplexity is 91.22650326986226
At time: 181.21971011161804 and batch: 400, loss is 4.46207067489624 and perplexity is 86.66678215430818
At time: 182.53385281562805 and batch: 450, loss is 4.466824474334717 and perplexity is 87.07975948261786
At time: 183.8476219177246 and batch: 500, loss is 4.480140933990478 and perplexity is 88.2471088164871
At time: 185.16310024261475 and batch: 550, loss is 4.436192111968994 and perplexity is 84.4527420275122
At time: 186.47482347488403 and batch: 600, loss is 4.418248882293701 and perplexity is 82.95090131116537
At time: 187.78635787963867 and batch: 650, loss is 4.4776748943328855 and perplexity is 88.02975605689002
At time: 189.1040177345276 and batch: 700, loss is 4.49947413444519 and perplexity is 89.96980683607153
At time: 190.41689205169678 and batch: 750, loss is 4.460534887313843 and perplexity is 86.53378254218721
At time: 191.7303605079651 and batch: 800, loss is 4.4416789531707765 and perplexity is 84.91739438320458
At time: 193.0430998802185 and batch: 850, loss is 4.442701215744019 and perplexity is 85.00424664264335
At time: 194.35404324531555 and batch: 900, loss is 4.421983995437622 and perplexity is 83.26131166096191
At time: 195.66651844978333 and batch: 950, loss is 4.493514728546143 and perplexity is 89.43523468677492
At time: 196.98125886917114 and batch: 1000, loss is 4.479004764556885 and perplexity is 88.14690208553878
At time: 198.2950005531311 and batch: 1050, loss is 4.418151397705078 and perplexity is 82.94281527081365
At time: 199.60881733894348 and batch: 1100, loss is 4.468604335784912 and perplexity is 87.23488740176221
At time: 200.91909170150757 and batch: 1150, loss is 4.400881061553955 and perplexity is 81.52266351708269
At time: 202.2323043346405 and batch: 1200, loss is 4.490398654937744 and perplexity is 89.15698166590495
At time: 203.5856351852417 and batch: 1250, loss is 4.458168296813965 and perplexity is 86.32923465052144
At time: 204.91057324409485 and batch: 1300, loss is 4.466060647964477 and perplexity is 87.01327106204798
At time: 206.22857356071472 and batch: 1350, loss is 4.34652204990387 and perplexity is 77.20946474994994
At time: 207.5439260005951 and batch: 1400, loss is 4.374460744857788 and perplexity is 79.39701275860844
At time: 208.86742210388184 and batch: 1450, loss is 4.314727873802185 and perplexity is 74.7932674668733
At time: 210.1855673789978 and batch: 1500, loss is 4.3086885070800784 and perplexity is 74.34292475749652
At time: 211.5027723312378 and batch: 1550, loss is 4.307178516387939 and perplexity is 74.23075234404982
At time: 212.8196473121643 and batch: 1600, loss is 4.401184482574463 and perplexity is 81.54740295988526
At time: 214.13383507728577 and batch: 1650, loss is 4.345378727912903 and perplexity is 77.12123991529783
At time: 215.44491362571716 and batch: 1700, loss is 4.380088100433349 and perplexity is 79.84506748027326
At time: 216.759046792984 and batch: 1750, loss is 4.380065717697144 and perplexity is 79.84328034919102
At time: 218.0732123851776 and batch: 1800, loss is 4.327233819961548 and perplexity is 75.73450128534616
At time: 219.38556241989136 and batch: 1850, loss is 4.36254412651062 and perplexity is 78.4564839510993
At time: 220.70041394233704 and batch: 1900, loss is 4.4502081871032715 and perplexity is 85.6447722833791
At time: 222.01206612586975 and batch: 1950, loss is 4.377649698257446 and perplexity is 79.65061027278355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497150367914244 and perplexity of 89.7609807356715
finished 4 epochs...
Completing Train Step...
At time: 225.9628529548645 and batch: 50, loss is 4.353680438995362 and perplexity is 77.76414307321362
At time: 227.28624176979065 and batch: 100, loss is 4.303503856658936 and perplexity is 73.9584801479717
At time: 228.59762167930603 and batch: 150, loss is 4.258344869613648 and perplexity is 70.69288063595394
At time: 229.90906405448914 and batch: 200, loss is 4.268973722457885 and perplexity is 71.44827222285011
At time: 231.22146034240723 and batch: 250, loss is 4.271456117630005 and perplexity is 71.62585539348193
At time: 232.53675198554993 and batch: 300, loss is 4.294127149581909 and perplexity is 73.26823431758869
At time: 233.85054397583008 and batch: 350, loss is 4.309813299179077 and perplexity is 74.42659213726303
At time: 235.17372393608093 and batch: 400, loss is 4.262828216552735 and perplexity is 71.01053288651308
At time: 236.48497486114502 and batch: 450, loss is 4.274184617996216 and perplexity is 71.82155342582003
At time: 237.79829025268555 and batch: 500, loss is 4.299465274810791 and perplexity is 73.66039509811618
At time: 239.1152367591858 and batch: 550, loss is 4.253065333366394 and perplexity is 70.32063850775855
At time: 240.42836952209473 and batch: 600, loss is 4.239708638191223 and perplexity is 69.3876319872894
At time: 241.74173998832703 and batch: 650, loss is 4.2901673412323 and perplexity is 72.97867982008829
At time: 243.05301213264465 and batch: 700, loss is 4.3172103309631344 and perplexity is 74.9791692003623
At time: 244.36569666862488 and batch: 750, loss is 4.280946807861328 and perplexity is 72.30887021384686
At time: 245.68070888519287 and batch: 800, loss is 4.263562569618225 and perplexity is 71.06269884079028
At time: 246.99582386016846 and batch: 850, loss is 4.260756969451904 and perplexity is 70.86360474091886
At time: 248.30954241752625 and batch: 900, loss is 4.240159573554993 and perplexity is 69.41892838015556
At time: 249.62033534049988 and batch: 950, loss is 4.3122395992279055 and perplexity is 74.6073926308263
At time: 250.93191361427307 and batch: 1000, loss is 4.305967054367065 and perplexity is 74.14087905683301
At time: 252.2464439868927 and batch: 1050, loss is 4.25046778678894 and perplexity is 70.13821440400322
At time: 253.5613088607788 and batch: 1100, loss is 4.29042839050293 and perplexity is 72.99773333807217
At time: 254.87424993515015 and batch: 1150, loss is 4.229091086387634 and perplexity is 68.65480252199764
At time: 256.18752694129944 and batch: 1200, loss is 4.32278968334198 and perplexity is 75.39867359960326
At time: 257.49875235557556 and batch: 1250, loss is 4.289317779541015 and perplexity is 72.91670625834209
At time: 258.813113451004 and batch: 1300, loss is 4.293624448776245 and perplexity is 73.2314115733547
At time: 260.1335196495056 and batch: 1350, loss is 4.168759174346924 and perplexity is 64.63520131319633
At time: 261.44854760169983 and batch: 1400, loss is 4.205472168922424 and perplexity is 67.05225018176401
At time: 262.7624979019165 and batch: 1450, loss is 4.142809820175171 and perplexity is 62.979534233276674
At time: 264.0809373855591 and batch: 1500, loss is 4.141832718849182 and perplexity is 62.91802690120858
At time: 265.39302802085876 and batch: 1550, loss is 4.142312474250794 and perplexity is 62.94821940640281
At time: 266.70867824554443 and batch: 1600, loss is 4.238611159324646 and perplexity is 69.31152229960766
At time: 268.0242450237274 and batch: 1650, loss is 4.183567733764648 and perplexity is 65.59947768271748
At time: 269.33819127082825 and batch: 1700, loss is 4.219046444892883 and perplexity is 67.96864153350435
At time: 270.65076994895935 and batch: 1750, loss is 4.213973278999329 and perplexity is 67.62469851710723
At time: 271.9622676372528 and batch: 1800, loss is 4.166618123054504 and perplexity is 64.496962073349
At time: 273.27614736557007 and batch: 1850, loss is 4.203487977981568 and perplexity is 66.91933761994642
At time: 274.59224915504456 and batch: 1900, loss is 4.302556829452515 and perplexity is 73.88847260987987
At time: 275.9066503047943 and batch: 1950, loss is 4.219453468322754 and perplexity is 67.99631199398581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475540232103924 and perplexity of 87.84204268521364
finished 5 epochs...
Completing Train Step...
At time: 279.9255578517914 and batch: 50, loss is 4.199136128425598 and perplexity is 66.62874749111475
At time: 281.239871263504 and batch: 100, loss is 4.151823744773865 and perplexity is 63.54979328098166
At time: 282.55437302589417 and batch: 150, loss is 4.101302351951599 and perplexity is 60.41892308309899
At time: 283.8678710460663 and batch: 200, loss is 4.1128092908859255 and perplexity is 61.11817535244723
At time: 285.1791090965271 and batch: 250, loss is 4.1223167085647585 and perplexity is 61.702022414360606
At time: 286.4913806915283 and batch: 300, loss is 4.133806533813477 and perplexity is 62.41505634269895
At time: 287.80523657798767 and batch: 350, loss is 4.155055446624756 and perplexity is 63.75549947706769
At time: 289.1192591190338 and batch: 400, loss is 4.112736225128174 and perplexity is 61.11370986979163
At time: 290.4326982498169 and batch: 450, loss is 4.1303511905670165 and perplexity is 62.19976306957236
At time: 291.7441806793213 and batch: 500, loss is 4.160128803253174 and perplexity is 64.0797757519883
At time: 293.0560131072998 and batch: 550, loss is 4.1060696220397945 and perplexity is 60.70764406651807
At time: 294.36774373054504 and batch: 600, loss is 4.097687726020813 and perplexity is 60.20092550421766
At time: 295.6823329925537 and batch: 650, loss is 4.144015836715698 and perplexity is 63.055534412801784
At time: 296.99681401252747 and batch: 700, loss is 4.1772024536132815 and perplexity is 65.18324475444959
At time: 298.30985736846924 and batch: 750, loss is 4.142988700866699 and perplexity is 62.99080106359157
At time: 299.6212685108185 and batch: 800, loss is 4.119921941757202 and perplexity is 61.55443724568746
At time: 300.96531558036804 and batch: 850, loss is 4.11497950553894 and perplexity is 61.25095894449553
At time: 302.28083753585815 and batch: 900, loss is 4.096798958778382 and perplexity is 60.14744466319568
At time: 303.59445357322693 and batch: 950, loss is 4.172029299736023 and perplexity is 64.84691249843615
At time: 304.9081494808197 and batch: 1000, loss is 4.1708363342285155 and perplexity is 64.76959849419656
At time: 306.21966075897217 and batch: 1050, loss is 4.113830275535584 and perplexity is 61.18060793722919
At time: 307.53245401382446 and batch: 1100, loss is 4.157022256851196 and perplexity is 63.88101784036892
At time: 308.84786915779114 and batch: 1150, loss is 4.100025162696839 and perplexity is 60.34180594082867
At time: 310.16187834739685 and batch: 1200, loss is 4.1907595443725585 and perplexity is 66.07295724909386
At time: 311.4762179851532 and batch: 1250, loss is 4.157732582092285 and perplexity is 63.92641025954933
At time: 312.7874047756195 and batch: 1300, loss is 4.165093235969543 and perplexity is 64.39868643753125
At time: 314.0993776321411 and batch: 1350, loss is 4.0330151128768925 and perplexity is 56.43080023362647
At time: 315.41304421424866 and batch: 1400, loss is 4.074262704849243 and perplexity is 58.807106406141855
At time: 316.7276117801666 and batch: 1450, loss is 4.008212037086487 and perplexity is 55.04835809866065
At time: 318.0409655570984 and batch: 1500, loss is 4.01152319431305 and perplexity is 55.230933969286305
At time: 319.352680683136 and batch: 1550, loss is 4.012946147918701 and perplexity is 55.309580968166344
At time: 320.6645288467407 and batch: 1600, loss is 4.114944348335266 and perplexity is 61.24880556991019
At time: 321.9778594970703 and batch: 1650, loss is 4.057595815658569 and perplexity is 57.83509756259179
At time: 323.2919964790344 and batch: 1700, loss is 4.0958828401565555 and perplexity is 60.09236770145166
At time: 324.60843443870544 and batch: 1750, loss is 4.08569139957428 and perplexity is 59.483050092589366
At time: 325.9215841293335 and batch: 1800, loss is 4.033380374908448 and perplexity is 56.4514160272162
At time: 327.2325441837311 and batch: 1850, loss is 4.077963657379151 and perplexity is 59.025151954602656
At time: 328.54556941986084 and batch: 1900, loss is 4.179340095520019 and perplexity is 65.32273222406829
At time: 329.8587956428528 and batch: 1950, loss is 4.094256830215454 and perplexity is 59.994736310501615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463179619367732 and perplexity of 86.76294411252155
finished 6 epochs...
Completing Train Step...
At time: 333.79820728302 and batch: 50, loss is 4.079399185180664 and perplexity is 59.1099450480822
At time: 335.1113052368164 and batch: 100, loss is 4.028508615493775 and perplexity is 56.17706713323465
At time: 336.4237108230591 and batch: 150, loss is 3.9777080154418947 and perplexity is 53.39451447177523
At time: 337.73675894737244 and batch: 200, loss is 3.9932759857177733 and perplexity is 54.23226278662523
At time: 339.05006217956543 and batch: 250, loss is 3.998656210899353 and perplexity is 54.524830907967974
At time: 340.3628010749817 and batch: 300, loss is 4.011137175559997 and perplexity is 55.209617907490056
At time: 341.6755361557007 and batch: 350, loss is 4.029689345359802 and perplexity is 56.24343624847242
At time: 342.9878420829773 and batch: 400, loss is 3.994069204330444 and perplexity is 54.27529789274196
At time: 344.3029828071594 and batch: 450, loss is 4.017307119369507 and perplexity is 55.551311177892856
At time: 345.61762857437134 and batch: 500, loss is 4.043313894271851 and perplexity is 57.014971672818625
At time: 346.9321711063385 and batch: 550, loss is 3.9956075525283814 and perplexity is 54.358856454050326
At time: 348.2432658672333 and batch: 600, loss is 3.9829739809036253 and perplexity is 53.67642976746642
At time: 349.5552270412445 and batch: 650, loss is 4.024880743026733 and perplexity is 55.973633137522754
At time: 350.8688852787018 and batch: 700, loss is 4.061198906898499 and perplexity is 58.043858562596014
At time: 352.1827187538147 and batch: 750, loss is 4.03359824180603 and perplexity is 56.46371626194851
At time: 353.49451756477356 and batch: 800, loss is 4.005667300224304 and perplexity is 54.908452599443535
At time: 354.8070955276489 and batch: 850, loss is 4.000824990272522 and perplexity is 54.64321156092457
At time: 356.1193459033966 and batch: 900, loss is 3.9824292421340943 and perplexity is 53.64719809769684
At time: 357.4328603744507 and batch: 950, loss is 4.064474639892578 and perplexity is 58.23430650319557
At time: 358.7472765445709 and batch: 1000, loss is 4.056200757026672 and perplexity is 57.754470463352156
At time: 360.0617005825043 and batch: 1050, loss is 4.006932826042175 and perplexity is 54.97798465185127
At time: 361.3819046020508 and batch: 1100, loss is 4.046557292938233 and perplexity is 57.20019416873144
At time: 362.6928496360779 and batch: 1150, loss is 3.9899896669387815 and perplexity is 54.05433081373141
At time: 364.0123133659363 and batch: 1200, loss is 4.085028219223022 and perplexity is 59.44361518020992
At time: 365.33179926872253 and batch: 1250, loss is 4.051852831840515 and perplexity is 57.50390346462955
At time: 366.6513113975525 and batch: 1300, loss is 4.056148090362549 and perplexity is 57.751428808152276
At time: 367.9706618785858 and batch: 1350, loss is 3.9239330196380617 and perplexity is 50.59906104195087
At time: 369.2878484725952 and batch: 1400, loss is 3.9701415300369263 and perplexity is 52.99203027296744
At time: 370.60437393188477 and batch: 1450, loss is 3.8988132762908934 and perplexity is 49.343856821191565
At time: 371.9242367744446 and batch: 1500, loss is 3.903739070892334 and perplexity is 49.58751413501239
At time: 373.2434642314911 and batch: 1550, loss is 3.904363670349121 and perplexity is 49.61849614407031
At time: 374.5605409145355 and batch: 1600, loss is 4.006741061210632 and perplexity is 54.96744281869467
At time: 375.87744402885437 and batch: 1650, loss is 3.9530429077148437 and perplexity is 52.09364204955607
At time: 377.19310545921326 and batch: 1700, loss is 3.9883816909790037 and perplexity is 53.96748259289947
At time: 378.5116431713104 and batch: 1750, loss is 3.979787230491638 and perplexity is 53.50564864572487
At time: 379.83005452156067 and batch: 1800, loss is 3.923894238471985 and perplexity is 50.597098789410744
At time: 381.1474509239197 and batch: 1850, loss is 3.972438383102417 and perplexity is 53.11388506785531
At time: 382.4651710987091 and batch: 1900, loss is 4.072551550865174 and perplexity is 58.70656443765102
At time: 383.78445839881897 and batch: 1950, loss is 3.989332184791565 and perplexity is 54.01880273705955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463497569949128 and perplexity of 86.79053482705515
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 387.7675485610962 and batch: 50, loss is 4.012600283622742 and perplexity is 55.290454666628094
At time: 389.0907187461853 and batch: 100, loss is 3.988521795272827 and perplexity is 53.97504419863193
At time: 390.40336656570435 and batch: 150, loss is 3.9300913047790527 and perplexity is 50.91162593175082
At time: 391.71598958969116 and batch: 200, loss is 3.9494059324264525 and perplexity is 51.90452288007836
At time: 393.0321714878082 and batch: 250, loss is 3.9517636489868164 and perplexity is 52.02704341081679
At time: 394.34727144241333 and batch: 300, loss is 3.9505261993408203 and perplexity is 51.96270238196789
At time: 395.662784576416 and batch: 350, loss is 3.9605873250961303 and perplexity is 52.48814450247385
At time: 396.97709226608276 and batch: 400, loss is 3.925474877357483 and perplexity is 50.67713777094971
At time: 398.30185079574585 and batch: 450, loss is 3.9436721181869507 and perplexity is 51.6077635820749
At time: 399.61685276031494 and batch: 500, loss is 3.964134545326233 and perplexity is 52.6746621244589
At time: 400.93330097198486 and batch: 550, loss is 3.9207455635070803 and perplexity is 50.43803552183473
At time: 402.2487995624542 and batch: 600, loss is 3.901207971572876 and perplexity is 49.46216191810911
At time: 403.56200981140137 and batch: 650, loss is 3.927678484916687 and perplexity is 50.78893342645747
At time: 404.8746874332428 and batch: 700, loss is 3.9490560340881347 and perplexity is 51.88636475070634
At time: 406.1896243095398 and batch: 750, loss is 3.921520161628723 and perplexity is 50.47711986478438
At time: 407.50788855552673 and batch: 800, loss is 3.8940234422683715 and perplexity is 49.10807307029206
At time: 408.82329177856445 and batch: 850, loss is 3.8793532180786134 and perplexity is 48.39290529087116
At time: 410.1390242576599 and batch: 900, loss is 3.8484216785430907 and perplexity is 46.91895157295045
At time: 411.45215463638306 and batch: 950, loss is 3.9381118297576903 and perplexity is 51.32160582844933
At time: 412.7644622325897 and batch: 1000, loss is 3.9163317394256594 and perplexity is 50.215901496914704
At time: 414.07746171951294 and batch: 1050, loss is 3.863747353553772 and perplexity is 47.643554508533924
At time: 415.3950295448303 and batch: 1100, loss is 3.8976591300964354 and perplexity is 49.2869396483088
At time: 416.71073055267334 and batch: 1150, loss is 3.848304662704468 and perplexity is 46.91346163369602
At time: 418.02518248558044 and batch: 1200, loss is 3.921482844352722 and perplexity is 50.475236231316906
At time: 419.33667850494385 and batch: 1250, loss is 3.875338749885559 and perplexity is 48.19902293946113
At time: 420.6523747444153 and batch: 1300, loss is 3.869406180381775 and perplexity is 47.91392540251083
At time: 421.96831488609314 and batch: 1350, loss is 3.737065243721008 and perplexity is 41.974623937476636
At time: 423.28278064727783 and batch: 1400, loss is 3.775899496078491 and perplexity is 43.63674174599851
At time: 424.5971083641052 and batch: 1450, loss is 3.6972890996932986 and perplexity is 40.33780423928745
At time: 425.90855503082275 and batch: 1500, loss is 3.698855605125427 and perplexity is 40.4010431478633
At time: 427.22045707702637 and batch: 1550, loss is 3.694806847572327 and perplexity is 40.23779980861295
At time: 428.53521156311035 and batch: 1600, loss is 3.7790270805358888 and perplexity is 43.773432986530786
At time: 429.84896993637085 and batch: 1650, loss is 3.720458536148071 and perplexity is 41.283319663631794
At time: 431.1616268157959 and batch: 1700, loss is 3.7439672136306763 and perplexity is 42.265333609518805
At time: 432.4724049568176 and batch: 1750, loss is 3.7288146781921387 and perplexity is 41.629734275944216
At time: 433.78208589553833 and batch: 1800, loss is 3.661945552825928 and perplexity is 38.93702326300312
At time: 435.0957591533661 and batch: 1850, loss is 3.700950026512146 and perplexity is 40.48574863020074
At time: 436.41365218162537 and batch: 1900, loss is 3.789847183227539 and perplexity is 44.24963767246523
At time: 437.7317454814911 and batch: 1950, loss is 3.708092737197876 and perplexity is 40.77596184021153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407634788335756 and perplexity of 82.0751087451873
finished 8 epochs...
Completing Train Step...
At time: 441.7027676105499 and batch: 50, loss is 3.9031762504577636 and perplexity is 49.55961312112454
At time: 443.0328631401062 and batch: 100, loss is 3.874534363746643 and perplexity is 48.16026790259623
At time: 444.3470139503479 and batch: 150, loss is 3.809243011474609 and perplexity is 45.1162734352317
At time: 445.66446137428284 and batch: 200, loss is 3.826122479438782 and perplexity is 45.884275626922545
At time: 446.98094391822815 and batch: 250, loss is 3.835174922943115 and perplexity is 46.30152615885028
At time: 448.29512119293213 and batch: 300, loss is 3.834261722564697 and perplexity is 46.25926288799522
At time: 449.61363196372986 and batch: 350, loss is 3.8458207941055296 and perplexity is 46.797079358452095
At time: 450.9341139793396 and batch: 400, loss is 3.815433883666992 and perplexity is 45.39644888822216
At time: 452.2524034976959 and batch: 450, loss is 3.8374122095108034 and perplexity is 46.40523190787075
At time: 453.5704801082611 and batch: 500, loss is 3.856938714981079 and perplexity is 47.320268582972886
At time: 454.8881540298462 and batch: 550, loss is 3.815409026145935 and perplexity is 45.395320459063036
At time: 456.2065327167511 and batch: 600, loss is 3.800922975540161 and perplexity is 44.74246163917209
At time: 457.52728486061096 and batch: 650, loss is 3.8259178256988524 and perplexity is 45.87488619913507
At time: 458.8461945056915 and batch: 700, loss is 3.851444787979126 and perplexity is 47.06100731501712
At time: 460.1666793823242 and batch: 750, loss is 3.8247456550598145 and perplexity is 45.821144507832905
At time: 461.483656167984 and batch: 800, loss is 3.8000274085998536 and perplexity is 44.7024097069702
At time: 462.8019800186157 and batch: 850, loss is 3.7895518589019774 and perplexity is 44.23657160752164
At time: 464.13321352005005 and batch: 900, loss is 3.7584730529785157 and perplexity is 42.88289605073381
At time: 465.4534590244293 and batch: 950, loss is 3.848991045951843 and perplexity is 46.945673301347654
At time: 466.7735826969147 and batch: 1000, loss is 3.8286997747421263 and perplexity is 46.002685478025434
At time: 468.0915005207062 and batch: 1050, loss is 3.7781104469299316 and perplexity is 43.733327170784605
At time: 469.4092252254486 and batch: 1100, loss is 3.8115692472457887 and perplexity is 45.22134668955791
At time: 470.7281656265259 and batch: 1150, loss is 3.7685521173477174 and perplexity is 43.317301040790575
At time: 472.04942870140076 and batch: 1200, loss is 3.8435282135009765 and perplexity is 46.68991616902679
At time: 473.3672332763672 and batch: 1250, loss is 3.803017272949219 and perplexity is 44.83626385123738
At time: 474.6848523616791 and batch: 1300, loss is 3.796784086227417 and perplexity is 44.55766024293993
At time: 476.0023798942566 and batch: 1350, loss is 3.6657787704467775 and perplexity is 39.086563774232836
At time: 477.32070875167847 and batch: 1400, loss is 3.7097508096694947 and perplexity is 40.84362742175938
At time: 478.6427481174469 and batch: 1450, loss is 3.6320507526397705 and perplexity is 37.790235631904324
At time: 479.9617381095886 and batch: 1500, loss is 3.6386031532287597 and perplexity is 38.038665410993524
At time: 481.2766082286835 and batch: 1550, loss is 3.6355397844314576 and perplexity is 37.92231724993204
At time: 482.59328842163086 and batch: 1600, loss is 3.7257527112960815 and perplexity is 41.502460361395684
At time: 483.90919947624207 and batch: 1650, loss is 3.6686707401275633 and perplexity is 39.19976453928811
At time: 485.2258152961731 and batch: 1700, loss is 3.69513484954834 and perplexity is 40.25100005119508
At time: 486.54360032081604 and batch: 1750, loss is 3.6855919790267944 and perplexity is 39.86871690969542
At time: 487.8590772151947 and batch: 1800, loss is 3.620554404258728 and perplexity is 37.35827366783894
At time: 489.1727976799011 and batch: 1850, loss is 3.663812313079834 and perplexity is 39.009777236421144
At time: 490.48631381988525 and batch: 1900, loss is 3.755634093284607 and perplexity is 42.76132588533896
At time: 491.80314779281616 and batch: 1950, loss is 3.6789229488372803 and perplexity is 39.60371586517124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413877123455668 and perplexity of 82.58905151157938
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 495.7575523853302 and batch: 50, loss is 3.863027420043945 and perplexity is 47.6092666610821
At time: 497.0787920951843 and batch: 100, loss is 3.8635692501068117 and perplexity is 47.63506978285238
At time: 498.391165971756 and batch: 150, loss is 3.8286568784713744 and perplexity is 46.00071217669779
At time: 499.70812010765076 and batch: 200, loss is 3.8381303405761718 and perplexity is 46.43856891523703
At time: 501.0228385925293 and batch: 250, loss is 3.847162404060364 and perplexity is 46.859904920252724
At time: 502.3373739719391 and batch: 300, loss is 3.8661012077331542 and perplexity is 47.755832579697056
At time: 503.6542544364929 and batch: 350, loss is 3.870404405593872 and perplexity is 47.96177817080445
At time: 504.96848011016846 and batch: 400, loss is 3.825079846382141 and perplexity is 45.836460095732235
At time: 506.28654289245605 and batch: 450, loss is 3.8494807577133177 and perplexity is 46.96866877983225
At time: 507.60223484039307 and batch: 500, loss is 3.8693406343460084 and perplexity is 47.91078493756631
At time: 508.9172172546387 and batch: 550, loss is 3.824778871536255 and perplexity is 45.822666550078225
At time: 510.23123049736023 and batch: 600, loss is 3.8074181604385378 and perplexity is 45.03401803166537
At time: 511.54532527923584 and batch: 650, loss is 3.8345967817306517 and perplexity is 46.274765074966034
At time: 512.8607120513916 and batch: 700, loss is 3.8540126514434814 and perplexity is 47.18200884751479
At time: 514.1758806705475 and batch: 750, loss is 3.8092947721481325 and perplexity is 45.11860874436963
At time: 515.491203546524 and batch: 800, loss is 3.781162657737732 and perplexity is 43.867014421686626
At time: 516.8046975135803 and batch: 850, loss is 3.7827588653564455 and perplexity is 43.93709119797992
At time: 518.1162753105164 and batch: 900, loss is 3.7591128873825075 and perplexity is 42.91034278271521
At time: 519.4380798339844 and batch: 950, loss is 3.8473684406280517 and perplexity is 46.86956076891948
At time: 520.7576062679291 and batch: 1000, loss is 3.811212034225464 and perplexity is 45.20519592052801
At time: 522.0739960670471 and batch: 1050, loss is 3.7474270391464235 and perplexity is 42.4118175474832
At time: 523.3880677223206 and batch: 1100, loss is 3.781612877845764 and perplexity is 43.886768680207126
At time: 524.7018265724182 and batch: 1150, loss is 3.7409491443634035 and perplexity is 42.137966203587354
At time: 526.0166673660278 and batch: 1200, loss is 3.8051193046569822 and perplexity is 44.930610224304765
At time: 527.3318645954132 and batch: 1250, loss is 3.7696533679962156 and perplexity is 43.36503052289082
At time: 528.6464829444885 and batch: 1300, loss is 3.760679612159729 and perplexity is 42.97762417189913
At time: 529.9624617099762 and batch: 1350, loss is 3.61781946182251 and perplexity is 37.256240530818964
At time: 531.2821893692017 and batch: 1400, loss is 3.6590972185134887 and perplexity is 38.82627540196003
At time: 532.5956485271454 and batch: 1450, loss is 3.5829417848587037 and perplexity is 35.97922846525297
At time: 533.9112503528595 and batch: 1500, loss is 3.587144303321838 and perplexity is 36.1307500001878
At time: 535.2276928424835 and batch: 1550, loss is 3.5947043085098267 and perplexity is 36.40493376710231
At time: 536.5433061122894 and batch: 1600, loss is 3.677557339668274 and perplexity is 39.54966957911014
At time: 537.8574492931366 and batch: 1650, loss is 3.6102017688751222 and perplexity is 36.97351216622383
At time: 539.1708409786224 and batch: 1700, loss is 3.627738552093506 and perplexity is 37.62762740877917
At time: 540.4827599525452 and batch: 1750, loss is 3.6152721071243286 and perplexity is 37.16145644706136
At time: 541.7976145744324 and batch: 1800, loss is 3.5507543182373045 and perplexity is 34.83958771469405
At time: 543.1130845546722 and batch: 1850, loss is 3.5899731397628782 and perplexity is 36.233102683676016
At time: 544.4271125793457 and batch: 1900, loss is 3.6865831661224364 and perplexity is 39.908253858435884
At time: 545.7394094467163 and batch: 1950, loss is 3.6072915410995483 and perplexity is 36.86606724458786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393158952579942 and perplexity of 80.89556101869147
finished 10 epochs...
Completing Train Step...
At time: 549.7039408683777 and batch: 50, loss is 3.863223967552185 and perplexity is 47.61862506346868
At time: 551.0301547050476 and batch: 100, loss is 3.8336871242523194 and perplexity is 46.23269002869911
At time: 552.3425388336182 and batch: 150, loss is 3.785150465965271 and perplexity is 44.04229692693584
At time: 553.6552801132202 and batch: 200, loss is 3.789469475746155 and perplexity is 44.23292740926218
At time: 554.9699692726135 and batch: 250, loss is 3.7994599676132204 and perplexity is 44.677050922988336
At time: 556.2860112190247 and batch: 300, loss is 3.82154402256012 and perplexity is 45.67467663566672
At time: 557.6015529632568 and batch: 350, loss is 3.8253347158432005 and perplexity is 45.84814389847272
At time: 558.9161262512207 and batch: 400, loss is 3.7765381002426146 and perplexity is 43.664617250745664
At time: 560.2284505367279 and batch: 450, loss is 3.8021954917907714 and perplexity is 44.79943338975162
At time: 561.5432598590851 and batch: 500, loss is 3.8243338108062743 and perplexity is 45.8022772182358
At time: 562.871830701828 and batch: 550, loss is 3.779865231513977 and perplexity is 43.81013711185328
At time: 564.1889147758484 and batch: 600, loss is 3.763210220336914 and perplexity is 43.086521429094674
At time: 565.5036201477051 and batch: 650, loss is 3.792330813407898 and perplexity is 44.35967399626338
At time: 566.8161237239838 and batch: 700, loss is 3.8132048654556274 and perplexity is 45.295372069803726
At time: 568.1305496692657 and batch: 750, loss is 3.7702643394470217 and perplexity is 43.391533413934106
At time: 569.4462502002716 and batch: 800, loss is 3.7438677072525026 and perplexity is 42.261128148487586
At time: 570.7617740631104 and batch: 850, loss is 3.745021677017212 and perplexity is 42.30992436185594
At time: 572.0764410495758 and batch: 900, loss is 3.7226280403137206 and perplexity is 41.372981223009305
At time: 573.3896791934967 and batch: 950, loss is 3.8127976274490356 and perplexity is 45.27692982821991
At time: 574.7044861316681 and batch: 1000, loss is 3.776595549583435 and perplexity is 43.667125826281215
At time: 576.0197865962982 and batch: 1050, loss is 3.714883394241333 and perplexity is 41.053799695819926
At time: 577.3363652229309 and batch: 1100, loss is 3.7484399843215943 and perplexity is 42.454800159277546
At time: 578.6516609191895 and batch: 1150, loss is 3.710355086326599 and perplexity is 40.86831573093504
At time: 579.9661183357239 and batch: 1200, loss is 3.777248959541321 and perplexity is 43.69566768488018
At time: 581.2784035205841 and batch: 1250, loss is 3.744087462425232 and perplexity is 42.270416270522645
At time: 582.5918152332306 and batch: 1300, loss is 3.7362434387207033 and perplexity is 41.94014315182053
At time: 583.9062058925629 and batch: 1350, loss is 3.595564966201782 and perplexity is 36.43627944038661
At time: 585.2191410064697 and batch: 1400, loss is 3.6384275722503663 and perplexity is 38.031987131210485
At time: 586.5333588123322 and batch: 1450, loss is 3.5636380910873413 and perplexity is 35.2913570465831
At time: 587.8459734916687 and batch: 1500, loss is 3.5704844188690186 and perplexity is 35.53380222737836
At time: 589.1592235565186 and batch: 1550, loss is 3.579767680168152 and perplexity is 35.86520768010283
At time: 590.4746963977814 and batch: 1600, loss is 3.6652002906799317 and perplexity is 39.06395952661421
At time: 591.7912471294403 and batch: 1650, loss is 3.5998678827285766 and perplexity is 36.59339950420092
At time: 593.10733294487 and batch: 1700, loss is 3.6201310777664184 and perplexity is 37.342462267816764
At time: 594.421555519104 and batch: 1750, loss is 3.608445906639099 and perplexity is 36.90864873476768
At time: 595.7349820137024 and batch: 1800, loss is 3.5464763927459715 and perplexity is 34.69086489368564
At time: 597.0501718521118 and batch: 1850, loss is 3.58710262298584 and perplexity is 36.12924408977157
At time: 598.3666832447052 and batch: 1900, loss is 3.683820614814758 and perplexity is 39.79815740312389
At time: 599.6821775436401 and batch: 1950, loss is 3.60528103351593 and perplexity is 36.792022195822184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.394874466297239 and perplexity of 81.03445756869165
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 603.6295654773712 and batch: 50, loss is 3.8594861888885497 and perplexity is 47.440969408308845
At time: 604.9470829963684 and batch: 100, loss is 3.861152629852295 and perplexity is 47.520092892087256
At time: 606.2629287242889 and batch: 150, loss is 3.8297324800491332 and perplexity is 46.050217234379375
At time: 607.5770576000214 and batch: 200, loss is 3.843780870437622 and perplexity is 46.70171419058153
At time: 608.8919186592102 and batch: 250, loss is 3.859985613822937 and perplexity is 47.46466852881611
At time: 610.2051515579224 and batch: 300, loss is 3.8725780344009397 and perplexity is 48.066142657211174
At time: 611.5289239883423 and batch: 350, loss is 3.8909839630126952 and perplexity is 48.95903671210673
At time: 612.8450090885162 and batch: 400, loss is 3.8571137189865112 and perplexity is 47.32855054418008
At time: 614.1593465805054 and batch: 450, loss is 3.865186276435852 and perplexity is 47.71215925593313
At time: 615.4731252193451 and batch: 500, loss is 3.8610463380813598 and perplexity is 47.51504216568884
At time: 616.7873334884644 and batch: 550, loss is 3.80678427696228 and perplexity is 45.00548075737447
At time: 618.1019809246063 and batch: 600, loss is 3.7860596799850463 and perplexity is 44.082359010509094
At time: 619.418285369873 and batch: 650, loss is 3.8158936882019043 and perplexity is 45.41732718088886
At time: 620.7327423095703 and batch: 700, loss is 3.8455973720550536 and perplexity is 46.78662502693312
At time: 622.04660987854 and batch: 750, loss is 3.8021416664123535 and perplexity is 44.79702210819116
At time: 623.3605065345764 and batch: 800, loss is 3.7756164693832397 and perplexity is 43.62439313076692
At time: 624.6767830848694 and batch: 850, loss is 3.768554520606995 and perplexity is 43.317405143621265
At time: 625.9927649497986 and batch: 900, loss is 3.744220328330994 and perplexity is 42.27603294079109
At time: 627.3361148834229 and batch: 950, loss is 3.8527594375610352 and perplexity is 47.12291673428761
At time: 628.6498234272003 and batch: 1000, loss is 3.8207155418395997 and perplexity is 45.63685171742936
At time: 629.9585728645325 and batch: 1050, loss is 3.7486832618713377 and perplexity is 42.46512971545876
At time: 631.2708578109741 and batch: 1100, loss is 3.7620120525360106 and perplexity is 43.03492746175297
At time: 632.5855209827423 and batch: 1150, loss is 3.715543894767761 and perplexity is 41.08092470918756
At time: 633.8998770713806 and batch: 1200, loss is 3.7745705032348633 and perplexity is 43.578787347519295
At time: 635.2122511863708 and batch: 1250, loss is 3.7403777933120725 and perplexity is 42.11389750878778
At time: 636.523987531662 and batch: 1300, loss is 3.744345393180847 and perplexity is 42.281320517141296
At time: 637.8353509902954 and batch: 1350, loss is 3.60369206905365 and perplexity is 36.73360740186395
At time: 639.1497070789337 and batch: 1400, loss is 3.6486418294906615 and perplexity is 38.42244636189437
At time: 640.4642972946167 and batch: 1450, loss is 3.571434416770935 and perplexity is 35.56757530457772
At time: 641.7782700061798 and batch: 1500, loss is 3.5697051668167115 and perplexity is 35.50612322492677
At time: 643.0906970500946 and batch: 1550, loss is 3.582191710472107 and perplexity is 35.95225148616698
At time: 644.4011015892029 and batch: 1600, loss is 3.669879884719849 and perplexity is 39.247191389781264
At time: 645.7170314788818 and batch: 1650, loss is 3.615652298927307 and perplexity is 37.175587614296035
At time: 647.0326206684113 and batch: 1700, loss is 3.629669117927551 and perplexity is 37.70034018648902
At time: 648.3488194942474 and batch: 1750, loss is 3.616619462966919 and perplexity is 37.211559898533835
At time: 649.6627752780914 and batch: 1800, loss is 3.5494415950775147 and perplexity is 34.79388298641447
At time: 650.9759635925293 and batch: 1850, loss is 3.5818368768692017 and perplexity is 35.93949668228993
At time: 652.2882871627808 and batch: 1900, loss is 3.6909755420684816 and perplexity is 40.08393145130386
At time: 653.602415561676 and batch: 1950, loss is 3.611044235229492 and perplexity is 37.00467423087915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37960091524346 and perplexity of 79.80617761996231
finished 12 epochs...
Completing Train Step...
At time: 657.5410048961639 and batch: 50, loss is 3.8747004318237304 and perplexity is 48.168266449812116
At time: 658.8525834083557 and batch: 100, loss is 3.8548258352279663 and perplexity is 47.2203920962316
At time: 660.1776616573334 and batch: 150, loss is 3.8100209188461305 and perplexity is 45.15138337128103
At time: 661.4918966293335 and batch: 200, loss is 3.8181550979614256 and perplexity is 45.52015058693438
At time: 662.805732011795 and batch: 250, loss is 3.827803611755371 and perplexity is 45.96147804105642
At time: 664.1180121898651 and batch: 300, loss is 3.8402641105651854 and perplexity is 46.537763931959944
At time: 665.4304106235504 and batch: 350, loss is 3.863201069831848 and perplexity is 47.6175347179924
At time: 666.742582321167 and batch: 400, loss is 3.8321995306015015 and perplexity is 46.16396570216163
At time: 668.0567467212677 and batch: 450, loss is 3.8387214517593384 and perplexity is 46.46602738735852
At time: 669.3724050521851 and batch: 500, loss is 3.835786533355713 and perplexity is 46.32985331607735
At time: 670.685802936554 and batch: 550, loss is 3.784197936058044 and perplexity is 44.00036529566682
At time: 671.996335029602 and batch: 600, loss is 3.7628534698486327 and perplexity is 43.07115303304089
At time: 673.3076627254486 and batch: 650, loss is 3.7921804428100585 and perplexity is 44.35300410705477
At time: 674.6216263771057 and batch: 700, loss is 3.8272393226623533 and perplexity is 45.935549796499686
At time: 675.9376969337463 and batch: 750, loss is 3.7839965343475344 and perplexity is 43.991504439158994
At time: 677.2531998157501 and batch: 800, loss is 3.7579090642929076 and perplexity is 42.858717401438305
At time: 678.5651490688324 and batch: 850, loss is 3.752226243019104 and perplexity is 42.61584971086716
At time: 679.8774719238281 and batch: 900, loss is 3.728058223724365 and perplexity is 41.59825518520945
At time: 681.1933953762054 and batch: 950, loss is 3.83614755153656 and perplexity is 46.34658225498427
At time: 682.5096273422241 and batch: 1000, loss is 3.804107837677002 and perplexity is 44.88518737140299
At time: 683.8323822021484 and batch: 1050, loss is 3.7329105043411257 and perplexity is 41.80059209326878
At time: 685.1556351184845 and batch: 1100, loss is 3.745606608390808 and perplexity is 42.334680003499564
At time: 686.4682865142822 and batch: 1150, loss is 3.6993783044815065 and perplexity is 40.42216626714112
At time: 687.7971255779266 and batch: 1200, loss is 3.7609001493453977 and perplexity is 42.98710338140141
At time: 689.1180217266083 and batch: 1250, loss is 3.7285785913467406 and perplexity is 41.61990720337117
At time: 690.4412806034088 and batch: 1300, loss is 3.7336476707458495 and perplexity is 41.83141744576873
At time: 691.7603883743286 and batch: 1350, loss is 3.5956848812103273 and perplexity is 36.44064895912726
At time: 693.0826730728149 and batch: 1400, loss is 3.6410708236694336 and perplexity is 38.13264821283038
At time: 694.3997058868408 and batch: 1450, loss is 3.564721636772156 and perplexity is 35.32961756899077
At time: 695.7129809856415 and batch: 1500, loss is 3.563947558403015 and perplexity is 35.30228025821611
At time: 697.029834985733 and batch: 1550, loss is 3.577593698501587 and perplexity is 35.78732206776063
At time: 698.3438305854797 and batch: 1600, loss is 3.667462043762207 and perplexity is 39.15241254922069
At time: 699.6562085151672 and batch: 1650, loss is 3.6140331172943116 and perplexity is 37.115442291876334
At time: 700.9689047336578 and batch: 1700, loss is 3.6307151746749877 and perplexity is 37.739797515426375
At time: 702.2832560539246 and batch: 1750, loss is 3.6185870027542113 and perplexity is 37.28484719737704
At time: 703.598375082016 and batch: 1800, loss is 3.553874955177307 and perplexity is 34.948479236174315
At time: 704.912605047226 and batch: 1850, loss is 3.5860069179534912 and perplexity is 36.08967877512304
At time: 706.2254979610443 and batch: 1900, loss is 3.6933704948425294 and perplexity is 40.18004562263758
At time: 707.5371720790863 and batch: 1950, loss is 3.611977858543396 and perplexity is 37.03923879009299
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379131370367006 and perplexity of 79.7687138343041
finished 13 epochs...
Completing Train Step...
At time: 711.4956936836243 and batch: 50, loss is 3.8662374687194823 and perplexity is 47.76234027991004
At time: 712.8101284503937 and batch: 100, loss is 3.8440489768981934 and perplexity is 46.71423690051048
At time: 714.1217083930969 and batch: 150, loss is 3.797823657989502 and perplexity is 44.6040052136007
At time: 715.4338746070862 and batch: 200, loss is 3.8065625333786013 and perplexity is 44.99550218716898
At time: 716.7471163272858 and batch: 250, loss is 3.815070405006409 and perplexity is 45.37995124623707
At time: 718.0632162094116 and batch: 300, loss is 3.8279943799972536 and perplexity is 45.97024686779687
At time: 719.3765163421631 and batch: 350, loss is 3.851805205345154 and perplexity is 47.07797197631186
At time: 720.6882917881012 and batch: 400, loss is 3.8221139812469485 and perplexity is 45.70071673456866
At time: 722.0010299682617 and batch: 450, loss is 3.8280433320999148 and perplexity is 45.97249726312124
At time: 723.3161497116089 and batch: 500, loss is 3.8270089292526244 and perplexity is 45.92496776761597
At time: 724.6305561065674 and batch: 550, loss is 3.775652871131897 and perplexity is 43.6259811638644
At time: 725.9569492340088 and batch: 600, loss is 3.7528535652160646 and perplexity is 42.6425919664614
At time: 727.2739970684052 and batch: 650, loss is 3.7813649940490723 and perplexity is 43.8758912095922
At time: 728.5950930118561 and batch: 700, loss is 3.8161973094940187 and perplexity is 45.43111894208213
At time: 729.9151589870453 and batch: 750, loss is 3.773779926300049 and perplexity is 43.54434857843714
At time: 731.2314462661743 and batch: 800, loss is 3.7482058238983154 and perplexity is 42.444860089132966
At time: 732.5455141067505 and batch: 850, loss is 3.7436713695526125 and perplexity is 42.252831510290235
At time: 733.8593521118164 and batch: 900, loss is 3.7197117614746094 and perplexity is 41.252501834489905
At time: 735.170577287674 and batch: 950, loss is 3.826951084136963 and perplexity is 45.922311309376006
At time: 736.4832620620728 and batch: 1000, loss is 3.7946056270599366 and perplexity is 44.460698851064414
At time: 737.7988228797913 and batch: 1050, loss is 3.7248197031021117 and perplexity is 41.46375628422684
At time: 739.1239287853241 and batch: 1100, loss is 3.7376277923583983 and perplexity is 41.99824334788831
At time: 740.4573731422424 and batch: 1150, loss is 3.691613082885742 and perplexity is 40.109494741674986
At time: 741.7742605209351 and batch: 1200, loss is 3.7535814332962034 and perplexity is 42.67364144660011
At time: 743.0903360843658 and batch: 1250, loss is 3.72194354057312 and perplexity is 41.34467111832931
At time: 744.4057922363281 and batch: 1300, loss is 3.7276906156539917 and perplexity is 41.58296614125006
At time: 745.72145652771 and batch: 1350, loss is 3.5899686861038207 and perplexity is 36.232941314149414
At time: 747.0360736846924 and batch: 1400, loss is 3.6356156349182127 and perplexity is 37.92519378524626
At time: 748.3493709564209 and batch: 1450, loss is 3.559611930847168 and perplexity is 35.14955404038491
At time: 749.6621692180634 and batch: 1500, loss is 3.5596575927734375 and perplexity is 35.151159073374075
At time: 750.9758472442627 and batch: 1550, loss is 3.5740921258926392 and perplexity is 35.6622292995795
At time: 752.291722536087 and batch: 1600, loss is 3.665933141708374 and perplexity is 39.09259808214401
At time: 753.606009721756 and batch: 1650, loss is 3.6132045364379883 and perplexity is 37.084701884134724
At time: 754.9208645820618 and batch: 1700, loss is 3.6311098909378052 and perplexity is 37.75469696759575
At time: 756.2388846874237 and batch: 1750, loss is 3.619822144508362 and perplexity is 37.3309277210788
At time: 757.5545217990875 and batch: 1800, loss is 3.5564205932617186 and perplexity is 35.03755874990657
At time: 758.8695096969604 and batch: 1850, loss is 3.5869351530075075 and perplexity is 36.12319403266229
At time: 760.1820771694183 and batch: 1900, loss is 3.6921077394485473 and perplexity is 40.12934007438714
At time: 761.4954648017883 and batch: 1950, loss is 3.6100665140151977 and perplexity is 36.968511657194064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379661098746366 and perplexity of 79.8109807798191
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 765.4410026073456 and batch: 50, loss is 3.864920930862427 and perplexity is 47.69950072519283
At time: 766.7679030895233 and batch: 100, loss is 3.8544735050201417 and perplexity is 47.203757856215475
At time: 768.0866017341614 and batch: 150, loss is 3.81947265625 and perplexity is 45.580165566572305
At time: 769.4044864177704 and batch: 200, loss is 3.8375853967666624 and perplexity is 46.413269398617764
At time: 770.718202829361 and batch: 250, loss is 3.8511881589889527 and perplexity is 47.04893164578302
At time: 772.035325050354 and batch: 300, loss is 3.86576247215271 and perplexity is 47.73965871951418
At time: 773.3558218479156 and batch: 350, loss is 3.8976298809051513 and perplexity is 49.28549806626588
At time: 774.6760268211365 and batch: 400, loss is 3.8772841596603396 and perplexity is 48.29288105647013
At time: 775.9931225776672 and batch: 450, loss is 3.8914579248428343 and perplexity is 48.982246926692035
At time: 777.3097846508026 and batch: 500, loss is 3.905023555755615 and perplexity is 49.6512494711007
At time: 778.6283004283905 and batch: 550, loss is 3.869389953613281 and perplexity is 47.913147920643716
At time: 779.9470453262329 and batch: 600, loss is 3.83887779712677 and perplexity is 46.47329270341794
At time: 781.2675240039825 and batch: 650, loss is 3.8558210229873655 and perplexity is 47.26740864370564
At time: 782.5862727165222 and batch: 700, loss is 3.8861139488220213 and perplexity is 48.721185148895465
At time: 783.8997106552124 and batch: 750, loss is 3.8289474868774414 and perplexity is 46.01408231298431
At time: 785.2206208705902 and batch: 800, loss is 3.7937398386001586 and perplexity is 44.42222194991748
At time: 786.5349652767181 and batch: 850, loss is 3.7865985774993898 and perplexity is 44.106121286346884
At time: 787.8504989147186 and batch: 900, loss is 3.750443024635315 and perplexity is 42.53992406034932
At time: 789.1709792613983 and batch: 950, loss is 3.850768733024597 and perplexity is 47.02920224005732
At time: 790.4942328929901 and batch: 1000, loss is 3.8181166648864746 and perplexity is 45.51840114119359
At time: 791.8054859638214 and batch: 1050, loss is 3.7520325422286986 and perplexity is 42.60759578651602
At time: 793.1193962097168 and batch: 1100, loss is 3.7686112928390503 and perplexity is 43.31986443920731
At time: 794.4351027011871 and batch: 1150, loss is 3.7242028284072877 and perplexity is 41.43818622979337
At time: 795.7505269050598 and batch: 1200, loss is 3.7822546625137328 and perplexity is 43.91494357561364
At time: 797.0665674209595 and batch: 1250, loss is 3.7395327425003053 and perplexity is 42.07832415827261
At time: 798.3788938522339 and batch: 1300, loss is 3.742624521255493 and perplexity is 42.2086223497548
At time: 799.7043726444244 and batch: 1350, loss is 3.5983298587799073 and perplexity is 36.537161238386105
At time: 801.0271472930908 and batch: 1400, loss is 3.6392861080169676 and perplexity is 38.06465297282779
At time: 802.3534305095673 and batch: 1450, loss is 3.5633775854110716 and perplexity is 35.28216464513757
At time: 803.6731789112091 and batch: 1500, loss is 3.562531409263611 and perplexity is 35.25232234668526
At time: 804.9883439540863 and batch: 1550, loss is 3.5804201412200927 and perplexity is 35.888615966901156
At time: 806.3060169219971 and batch: 1600, loss is 3.669913482666016 and perplexity is 39.248510036956574
At time: 807.6229770183563 and batch: 1650, loss is 3.618931746482849 and perplexity is 37.29770313049539
At time: 808.9422380924225 and batch: 1700, loss is 3.6384536457061767 and perplexity is 38.032978769474
At time: 810.2603425979614 and batch: 1750, loss is 3.6342942190170286 and perplexity is 37.87511192789177
At time: 811.5787625312805 and batch: 1800, loss is 3.5739952611923216 and perplexity is 35.65877505572559
At time: 812.8964743614197 and batch: 1850, loss is 3.6027211999893187 and perplexity is 36.69796118552051
At time: 814.2146601676941 and batch: 1900, loss is 3.709391565322876 and perplexity is 40.828957214764955
At time: 815.5354676246643 and batch: 1950, loss is 3.6415491199493406 and perplexity is 38.150891279061156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357399732013081 and perplexity of 78.05390923617685
finished 15 epochs...
Completing Train Step...
At time: 819.5154826641083 and batch: 50, loss is 3.885652027130127 and perplexity is 48.69868497367996
At time: 820.8444125652313 and batch: 100, loss is 3.8626022863388063 and perplexity is 47.5890306589556
At time: 822.1625518798828 and batch: 150, loss is 3.819421801567078 and perplexity is 45.57784766064357
At time: 823.4932894706726 and batch: 200, loss is 3.82565306186676 and perplexity is 45.86274179623845
At time: 824.8119134902954 and batch: 250, loss is 3.8370090389251708 and perplexity is 46.38652645434373
At time: 826.1349303722382 and batch: 300, loss is 3.841328067779541 and perplexity is 46.58730447146919
At time: 827.4519798755646 and batch: 350, loss is 3.8681643342971803 and perplexity is 47.85446061255257
At time: 828.7725584506989 and batch: 400, loss is 3.8404955577850344 and perplexity is 46.54853621459933
At time: 830.0920743942261 and batch: 450, loss is 3.8524244022369385 and perplexity is 47.107131537054144
At time: 831.4117283821106 and batch: 500, loss is 3.858121476173401 and perplexity is 47.376270272046824
At time: 832.7289016246796 and batch: 550, loss is 3.818600883483887 and perplexity is 45.540447334708325
At time: 834.0469489097595 and batch: 600, loss is 3.7902317094802855 and perplexity is 44.2666560916296
At time: 835.3652138710022 and batch: 650, loss is 3.8063514709472654 and perplexity is 44.98600632922287
At time: 836.6841907501221 and batch: 700, loss is 3.8385644865036013 and perplexity is 46.45873440787375
At time: 838.0031769275665 and batch: 750, loss is 3.787569537162781 and perplexity is 44.14896734855749
At time: 839.3203737735748 and batch: 800, loss is 3.758834228515625 and perplexity is 42.898387101073546
At time: 840.6379342079163 and batch: 850, loss is 3.7499127197265625 and perplexity is 42.517370910353776
At time: 841.9550309181213 and batch: 900, loss is 3.7202612924575806 and perplexity is 41.27517759231814
At time: 843.2743275165558 and batch: 950, loss is 3.8297566318511964 and perplexity is 46.05132944354186
At time: 844.5919280052185 and batch: 1000, loss is 3.8088237476348876 and perplexity is 45.09736177796136
At time: 845.9101586341858 and batch: 1050, loss is 3.7529721450805664 and perplexity is 42.647648819053316
At time: 847.2241523265839 and batch: 1100, loss is 3.777766251564026 and perplexity is 43.718276952493056
At time: 848.5412974357605 and batch: 1150, loss is 3.735982646942139 and perplexity is 41.929206933394624
At time: 849.8611290454865 and batch: 1200, loss is 3.7914394617080687 and perplexity is 44.32015154226295
At time: 851.1788194179535 and batch: 1250, loss is 3.7489106607437135 and perplexity is 42.474787336095744
At time: 852.4975361824036 and batch: 1300, loss is 3.7500184392929077 and perplexity is 42.52186606597732
At time: 853.8137748241425 and batch: 1350, loss is 3.602710680961609 and perplexity is 36.697575160680216
At time: 855.1326911449432 and batch: 1400, loss is 3.6429251861572265 and perplexity is 38.203425568391424
At time: 856.451402425766 and batch: 1450, loss is 3.565214262008667 and perplexity is 35.34702611779471
At time: 857.770182132721 and batch: 1500, loss is 3.5620059728622437 and perplexity is 35.233804358730104
At time: 859.0901215076447 and batch: 1550, loss is 3.576375389099121 and perplexity is 35.743748585177755
At time: 860.4078612327576 and batch: 1600, loss is 3.6675964164733887 and perplexity is 39.157673918528545
At time: 861.7235238552094 and batch: 1650, loss is 3.617159533500671 and perplexity is 37.23166219338993
At time: 863.0432505607605 and batch: 1700, loss is 3.637882957458496 and perplexity is 38.01127998767476
At time: 864.3629438877106 and batch: 1750, loss is 3.6341166353225707 and perplexity is 37.86838652276643
At time: 865.6825771331787 and batch: 1800, loss is 3.5754205131530763 and perplexity is 35.709634029608665
At time: 867.0001871585846 and batch: 1850, loss is 3.605566267967224 and perplexity is 36.80251804490292
At time: 868.3166992664337 and batch: 1900, loss is 3.7139488458633423 and perplexity is 41.015450856117916
At time: 869.6353528499603 and batch: 1950, loss is 3.6466110801696776 and perplexity is 38.344499177417866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356101528433866 and perplexity of 77.95264511677782
finished 16 epochs...
Completing Train Step...
At time: 873.6091208457947 and batch: 50, loss is 3.885297112464905 and perplexity is 48.68140416299374
At time: 874.9364302158356 and batch: 100, loss is 3.8592206716537474 and perplexity is 47.4283746854272
At time: 876.2533700466156 and batch: 150, loss is 3.8136866998672487 and perplexity is 45.31720219758519
At time: 877.5722417831421 and batch: 200, loss is 3.8185641717910768 and perplexity is 45.538775498483496
At time: 878.8915703296661 and batch: 250, loss is 3.8294343900680543 and perplexity is 46.03649217174876
At time: 880.2104704380035 and batch: 300, loss is 3.8326203775405885 and perplexity is 46.183397754496575
At time: 881.5326459407806 and batch: 350, loss is 3.859732370376587 and perplexity is 47.452649934457376
At time: 882.8463096618652 and batch: 400, loss is 3.834457688331604 and perplexity is 46.26832900821921
At time: 884.1633961200714 and batch: 450, loss is 3.847066969871521 and perplexity is 46.855433096623244
At time: 885.4831328392029 and batch: 500, loss is 3.853897132873535 and perplexity is 47.176558764124515
At time: 886.8018796443939 and batch: 550, loss is 3.8158395147323607 and perplexity is 45.414866833341456
At time: 888.1208789348602 and batch: 600, loss is 3.7876035165786743 and perplexity is 44.150467530167795
At time: 889.4463036060333 and batch: 650, loss is 3.8033971691131594 and perplexity is 44.85330021169899
At time: 890.7628509998322 and batch: 700, loss is 3.8353809928894043 and perplexity is 46.31106849501952
At time: 892.0815024375916 and batch: 750, loss is 3.784473705291748 and perplexity is 44.01250091592553
At time: 893.3999755382538 and batch: 800, loss is 3.7556405735015868 and perplexity is 42.761602988906894
At time: 894.7195699214935 and batch: 850, loss is 3.7477200078964232 and perplexity is 42.424244704950816
At time: 896.0367243289948 and batch: 900, loss is 3.7180648326873778 and perplexity is 41.18461781708849
At time: 897.3539242744446 and batch: 950, loss is 3.827538800239563 and perplexity is 45.94930852377287
At time: 898.671097278595 and batch: 1000, loss is 3.8062630462646485 and perplexity is 44.98202863175691
At time: 899.9909875392914 and batch: 1050, loss is 3.7511846017837525 and perplexity is 42.57148239595275
At time: 901.3106594085693 and batch: 1100, loss is 3.775759572982788 and perplexity is 43.63063638515749
At time: 902.6286447048187 and batch: 1150, loss is 3.733804168701172 and perplexity is 41.83796448935333
At time: 903.9451541900635 and batch: 1200, loss is 3.789454336166382 and perplexity is 44.2322577463983
At time: 905.2644085884094 and batch: 1250, loss is 3.7471748065948485 and perplexity is 42.40112125555948
At time: 906.5847005844116 and batch: 1300, loss is 3.747885980606079 and perplexity is 42.431286556161
At time: 907.9036421775818 and batch: 1350, loss is 3.600697464942932 and perplexity is 36.62376933298558
At time: 909.2263655662537 and batch: 1400, loss is 3.6411816358566282 and perplexity is 38.13687400911291
At time: 910.5430083274841 and batch: 1450, loss is 3.563264045715332 and perplexity is 35.27815894630594
At time: 911.859804391861 and batch: 1500, loss is 3.560274429321289 and perplexity is 35.172848281650346
At time: 913.1800258159637 and batch: 1550, loss is 3.5744050979614257 and perplexity is 35.673392328027866
At time: 914.4987683296204 and batch: 1600, loss is 3.6665583515167235 and perplexity is 39.11704679989151
At time: 915.8177380561829 and batch: 1650, loss is 3.6165337419509886 and perplexity is 37.20837022252806
At time: 917.1349439620972 and batch: 1700, loss is 3.6379870271682737 and perplexity is 38.01523601639917
At time: 918.4522926807404 and batch: 1750, loss is 3.634828429222107 and perplexity is 37.89535060457464
At time: 919.7693140506744 and batch: 1800, loss is 3.5766956043243407 and perplexity is 35.75519611041927
At time: 921.0953288078308 and batch: 1850, loss is 3.607070736885071 and perplexity is 36.857927960196264
At time: 922.4141829013824 and batch: 1900, loss is 3.7154076957702635 and perplexity is 41.07532990943761
At time: 923.7440311908722 and batch: 1950, loss is 3.6477759218215944 and perplexity is 38.389190471268584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355584858739099 and perplexity of 77.91237975026206
finished 17 epochs...
Completing Train Step...
At time: 927.8780219554901 and batch: 50, loss is 3.8834333086013793 and perplexity is 48.59075607520187
At time: 929.1968908309937 and batch: 100, loss is 3.8560967302322386 and perplexity is 47.280442407384065
At time: 930.5159060955048 and batch: 150, loss is 3.8100181579589845 and perplexity is 45.15125871357914
At time: 931.8315646648407 and batch: 200, loss is 3.814444971084595 and perplexity is 45.351577959090434
At time: 933.154102563858 and batch: 250, loss is 3.8250532960891723 and perplexity is 45.83524314044338
At time: 934.4753856658936 and batch: 300, loss is 3.8279514503479004 and perplexity is 45.96827342357809
At time: 935.7947328090668 and batch: 350, loss is 3.8552316188812257 and perplexity is 47.23955724763435
At time: 937.1139833927155 and batch: 400, loss is 3.8308305311203004 and perplexity is 46.10081049665055
At time: 938.4274363517761 and batch: 450, loss is 3.843568081855774 and perplexity is 46.691777656277054
At time: 939.7434713840485 and batch: 500, loss is 3.850910019874573 and perplexity is 47.03584731731866
At time: 941.0632588863373 and batch: 550, loss is 3.813123197555542 and perplexity is 45.29167304293114
At time: 942.3821060657501 and batch: 600, loss is 3.784733843803406 and perplexity is 44.023951751745265
At time: 943.7039170265198 and batch: 650, loss is 3.8005439376831056 and perplexity is 44.7255057660549
At time: 945.0212724208832 and batch: 700, loss is 3.8325342321395874 and perplexity is 46.17941943853669
At time: 946.3384830951691 and batch: 750, loss is 3.7815282106399537 and perplexity is 43.88305306742842
At time: 947.6579909324646 and batch: 800, loss is 3.7529415893554687 and perplexity is 42.646345709128774
At time: 948.9832179546356 and batch: 850, loss is 3.7454104948043825 and perplexity is 42.326378411627985
At time: 950.301017999649 and batch: 900, loss is 3.715677433013916 and perplexity is 41.086410950127004
At time: 951.6195464134216 and batch: 950, loss is 3.8250881576538087 and perplexity is 45.83684105658751
At time: 952.9367160797119 and batch: 1000, loss is 3.803939380645752 and perplexity is 44.87762678282633
At time: 954.2861378192902 and batch: 1050, loss is 3.7491940689086913 and perplexity is 42.486826743585105
At time: 955.6198313236237 and batch: 1100, loss is 3.773922142982483 and perplexity is 43.550541751606545
At time: 956.9384672641754 and batch: 1150, loss is 3.7319273710250855 and perplexity is 41.759516733137644
At time: 958.2518413066864 and batch: 1200, loss is 3.7877928256988525 and perplexity is 44.15882640751228
At time: 959.5635209083557 and batch: 1250, loss is 3.745703406333923 and perplexity is 42.33877811178737
At time: 960.8776187896729 and batch: 1300, loss is 3.746437420845032 and perplexity is 42.3698667976815
At time: 962.1920523643494 and batch: 1350, loss is 3.5994947862625124 and perplexity is 36.57974918276631
At time: 963.5172934532166 and batch: 1400, loss is 3.6400532054901125 and perplexity is 38.09386347415788
At time: 964.8317091464996 and batch: 1450, loss is 3.5618466758728027 and perplexity is 35.228192166783714
At time: 966.1435873508453 and batch: 1500, loss is 3.5589642667770387 and perplexity is 35.12679630763031
At time: 967.4578557014465 and batch: 1550, loss is 3.572968759536743 and perplexity is 35.622190044594724
At time: 968.7720944881439 and batch: 1600, loss is 3.665713562965393 and perplexity is 39.08401512094969
At time: 970.0874593257904 and batch: 1650, loss is 3.6158427476882933 and perplexity is 37.18266833313177
At time: 971.4028551578522 and batch: 1700, loss is 3.637694392204285 and perplexity is 38.00411305673931
At time: 972.7162086963654 and batch: 1750, loss is 3.6347875881195066 and perplexity is 37.89380294827673
At time: 974.0286862850189 and batch: 1800, loss is 3.5768930912017822 and perplexity is 35.76225798974272
At time: 975.3410584926605 and batch: 1850, loss is 3.60740779876709 and perplexity is 36.870353456724835
At time: 976.6535873413086 and batch: 1900, loss is 3.7155600118637087 and perplexity is 41.08158681972836
At time: 977.9674973487854 and batch: 1950, loss is 3.64755774974823 and perplexity is 38.38081593556682
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355391533430232 and perplexity of 77.89731877126344
finished 18 epochs...
Completing Train Step...
At time: 981.9431028366089 and batch: 50, loss is 3.8812074089050292 and perplexity is 48.482718211340135
At time: 983.2582488059998 and batch: 100, loss is 3.8532366132736207 and perplexity is 47.145408011378215
At time: 984.5853803157806 and batch: 150, loss is 3.806939721107483 and perplexity is 45.01247713961948
At time: 985.9066114425659 and batch: 200, loss is 3.8112233591079714 and perplexity is 45.20570786695939
At time: 987.2359602451324 and batch: 250, loss is 3.8216033220291137 and perplexity is 45.6773852000451
At time: 988.5532476902008 and batch: 300, loss is 3.824304795265198 and perplexity is 45.8009482596601
At time: 989.871994972229 and batch: 350, loss is 3.8517097282409667 and perplexity is 47.073477322448234
At time: 991.1920046806335 and batch: 400, loss is 3.8276699113845827 and perplexity is 45.955333385180886
At time: 992.5114550590515 and batch: 450, loss is 3.8406500673294066 and perplexity is 46.5557289633809
At time: 993.826159954071 and batch: 500, loss is 3.8483221435546877 and perplexity is 46.91428172806009
At time: 995.1438140869141 and batch: 550, loss is 3.810681743621826 and perplexity is 45.181230384806554
At time: 996.4629998207092 and batch: 600, loss is 3.7821865463256836 and perplexity is 43.911952358935174
At time: 997.7825536727905 and batch: 650, loss is 3.798106937408447 and perplexity is 44.61664240012314
At time: 999.1007354259491 and batch: 700, loss is 3.83036319732666 and perplexity is 46.0792710634358
At time: 1000.4185748100281 and batch: 750, loss is 3.779326682090759 and perplexity is 43.78654953988734
At time: 1001.7353711128235 and batch: 800, loss is 3.7508452892303468 and perplexity is 42.557039807972984
At time: 1003.0530927181244 and batch: 850, loss is 3.7435306549072265 and perplexity is 42.24688633638404
At time: 1004.3732659816742 and batch: 900, loss is 3.713488883972168 and perplexity is 40.996589649825346
At time: 1005.6992435455322 and batch: 950, loss is 3.8230224657058716 and perplexity is 45.74225399060257
At time: 1007.0182399749756 and batch: 1000, loss is 3.801951913833618 and perplexity is 44.78852256415716
At time: 1008.3341917991638 and batch: 1050, loss is 3.7475201225280763 and perplexity is 42.4157655666272
At time: 1009.6526038646698 and batch: 1100, loss is 3.7723132276535036 and perplexity is 43.48052895483099
At time: 1010.9733936786652 and batch: 1150, loss is 3.730329113006592 and perplexity is 41.69282755812091
At time: 1012.294153213501 and batch: 1200, loss is 3.786380639076233 and perplexity is 44.096509915203754
At time: 1013.6124229431152 and batch: 1250, loss is 3.744420299530029 and perplexity is 42.28448777512222
At time: 1014.9292516708374 and batch: 1300, loss is 3.7453432512283324 and perplexity is 42.32353233027376
At time: 1016.245851278305 and batch: 1350, loss is 3.5985426616668703 and perplexity is 36.54493727913168
At time: 1017.5644109249115 and batch: 1400, loss is 3.6390691566467286 and perplexity is 38.05639568995446
At time: 1018.8832528591156 and batch: 1450, loss is 3.5605925130844116 and perplexity is 35.184037973126756
At time: 1020.2011346817017 and batch: 1500, loss is 3.5576927614212037 and perplexity is 35.08216078116093
At time: 1021.519623041153 and batch: 1550, loss is 3.5715631675720214 and perplexity is 35.57215495320127
At time: 1022.8355610370636 and batch: 1600, loss is 3.664764447212219 and perplexity is 39.04693746477824
At time: 1024.153362751007 and batch: 1650, loss is 3.6149927949905396 and perplexity is 37.15107825081196
At time: 1025.4730968475342 and batch: 1700, loss is 3.6371346044540407 and perplexity is 37.98284477320894
At time: 1026.791485786438 and batch: 1750, loss is 3.6343557167053224 and perplexity is 37.87744123134186
At time: 1028.110740184784 and batch: 1800, loss is 3.5766501140594484 and perplexity is 35.75356963407163
At time: 1029.4317908287048 and batch: 1850, loss is 3.6072570657730103 and perplexity is 36.86479629678973
At time: 1030.7468283176422 and batch: 1900, loss is 3.7152642822265625 and perplexity is 41.0694395732037
At time: 1032.0649361610413 and batch: 1950, loss is 3.6469217586517333 and perplexity is 38.356413838936135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355335324309593 and perplexity of 77.89294035452974
finished 19 epochs...
Completing Train Step...
At time: 1036.056777715683 and batch: 50, loss is 3.8789823722839354 and perplexity is 48.374962312696425
At time: 1037.3780784606934 and batch: 100, loss is 3.850591502189636 and perplexity is 47.02086795384484
At time: 1038.7059848308563 and batch: 150, loss is 3.804184317588806 and perplexity is 44.88862031784851
At time: 1040.0270981788635 and batch: 200, loss is 3.8084025478363035 and perplexity is 45.078370778047244
At time: 1041.344391822815 and batch: 250, loss is 3.8185931062698364 and perplexity is 45.5400931582787
At time: 1042.657548904419 and batch: 300, loss is 3.8211790418624876 and perplexity is 45.65800930213664
At time: 1043.97616147995 and batch: 350, loss is 3.8486421632766725 and perplexity is 46.92929762601941
At time: 1045.2934176921844 and batch: 400, loss is 3.824726309776306 and perplexity is 45.82025809337571
At time: 1046.6124737262726 and batch: 450, loss is 3.8381023979187012 and perplexity is 46.43727131634167
At time: 1047.930730342865 and batch: 500, loss is 3.8459492349624633 and perplexity is 46.80309040145038
At time: 1049.2511341571808 and batch: 550, loss is 3.808532223701477 and perplexity is 45.08421673380999
At time: 1050.5671956539154 and batch: 600, loss is 3.7802082443237306 and perplexity is 43.82516712767632
At time: 1051.8844151496887 and batch: 650, loss is 3.7962027025222778 and perplexity is 44.53176267427723
At time: 1053.2367429733276 and batch: 700, loss is 3.828576374053955 and perplexity is 45.99700906522354
At time: 1054.5546734333038 and batch: 750, loss is 3.777513098716736 and perplexity is 43.70721094695843
At time: 1055.8861260414124 and batch: 800, loss is 3.7491628408432005 and perplexity is 42.48549998289325
At time: 1057.2117257118225 and batch: 850, loss is 3.7419020652771 and perplexity is 42.17813949078618
At time: 1058.5274503231049 and batch: 900, loss is 3.7115655183792113 and perplexity is 40.917814001335046
At time: 1059.8463916778564 and batch: 950, loss is 3.821160478591919 and perplexity is 45.65716174802305
At time: 1061.1661818027496 and batch: 1000, loss is 3.800029411315918 and perplexity is 44.70249923329389
At time: 1062.4832627773285 and batch: 1050, loss is 3.7458426189422607 and perplexity is 42.34467261380711
At time: 1063.816947221756 and batch: 1100, loss is 3.770556721687317 and perplexity is 43.40422218257843
At time: 1065.142951965332 and batch: 1150, loss is 3.7286064195632935 and perplexity is 41.621065427277316
At time: 1066.4619431495667 and batch: 1200, loss is 3.7848565101623537 and perplexity is 44.02935234084167
At time: 1067.779617547989 and batch: 1250, loss is 3.7430801248550414 and perplexity is 42.227857131414474
At time: 1069.0966567993164 and batch: 1300, loss is 3.7441491174697874 and perplexity is 42.27302253526504
At time: 1070.4151327610016 and batch: 1350, loss is 3.5974847269058228 and perplexity is 36.50629556345498
At time: 1071.7316055297852 and batch: 1400, loss is 3.637999153137207 and perplexity is 38.01569699076498
At time: 1073.0483446121216 and batch: 1450, loss is 3.559350471496582 and perplexity is 35.14036506213661
At time: 1074.371000289917 and batch: 1500, loss is 3.556514902114868 and perplexity is 35.04086325770916
At time: 1075.70405960083 and batch: 1550, loss is 3.5702582740783693 and perplexity is 35.52576735166956
At time: 1077.0307638645172 and batch: 1600, loss is 3.6638767910003662 and perplexity is 39.012292586829176
At time: 1078.3478214740753 and batch: 1650, loss is 3.6142058801651 and perplexity is 37.12185501616164
At time: 1079.6659157276154 and batch: 1700, loss is 3.636592411994934 and perplexity is 37.962256343147615
At time: 1080.9845497608185 and batch: 1750, loss is 3.633895788192749 and perplexity is 37.86002432170994
At time: 1082.3036615848541 and batch: 1800, loss is 3.5763575267791747 and perplexity is 35.74311012460666
At time: 1083.6214017868042 and batch: 1850, loss is 3.607031235694885 and perplexity is 36.8564720569292
At time: 1084.9392294883728 and batch: 1900, loss is 3.7149429321289062 and perplexity is 41.056244025095054
At time: 1086.2560272216797 and batch: 1950, loss is 3.646302375793457 and perplexity is 38.33266388961438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3553375953851745 and perplexity of 77.89311725548546
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
4461.844224452972


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.71282622170062}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.8965078080331692, 'wordvec_dim': 300, 'dropout': 0.6142191105838335, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.89294035452974}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.3068549984979113, 'wordvec_dim': 300, 'dropout': 0.6482131084882298, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9799416065216064 and batch: 50, loss is 7.636412000656128 and perplexity is 2072.295068165387
At time: 3.5020508766174316 and batch: 100, loss is 6.748986129760742 and perplexity is 853.1932965734718
At time: 5.022351980209351 and batch: 150, loss is 6.461120471954346 and perplexity is 639.7775078673905
At time: 6.545114278793335 and batch: 200, loss is 6.315134916305542 and perplexity is 552.8766476346698
At time: 8.066500186920166 and batch: 250, loss is 6.237803688049317 and perplexity is 511.7333497210492
At time: 9.591031551361084 and batch: 300, loss is 6.16637993812561 and perplexity is 476.4581722983885
At time: 11.114582300186157 and batch: 350, loss is 6.106664123535157 and perplexity is 448.8389437633472
At time: 12.639997482299805 and batch: 400, loss is 6.064218149185181 and perplexity is 430.1862047188297
At time: 14.163378715515137 and batch: 450, loss is 5.984577312469482 and perplexity is 397.25457120296835
At time: 15.68775463104248 and batch: 500, loss is 5.958208827972412 and perplexity is 386.91646923880865
At time: 17.21293544769287 and batch: 550, loss is 5.910505428314209 and perplexity is 368.89255704228725
At time: 18.742889165878296 and batch: 600, loss is 5.951853427886963 and perplexity is 384.46525774261335
At time: 20.276635885238647 and batch: 650, loss is 6.0298202610015865 and perplexity is 415.64031589364436
At time: 21.810970067977905 and batch: 700, loss is 5.923581743240357 and perplexity is 373.7479886830403
At time: 23.347461462020874 and batch: 750, loss is 5.864542684555054 and perplexity is 352.3209974266385
At time: 24.883779287338257 and batch: 800, loss is 5.863880290985107 and perplexity is 352.08769953942635
At time: 26.420589685440063 and batch: 850, loss is 5.897554016113281 and perplexity is 364.1456831909702
At time: 27.954994201660156 and batch: 900, loss is 5.889689741134643 and perplexity is 361.2931725715621
At time: 29.487882614135742 and batch: 950, loss is 5.90505012512207 and perplexity is 366.8856155128326
At time: 31.027340173721313 and batch: 1000, loss is 5.890839996337891 and perplexity is 361.7089910260339
At time: 32.56342554092407 and batch: 1050, loss is 5.785985822677612 and perplexity is 325.70296726930627
At time: 34.10044622421265 and batch: 1100, loss is 5.866947164535523 and perplexity is 353.1691655045895
At time: 35.64004707336426 and batch: 1150, loss is 5.773552923202515 and perplexity is 321.67860410917814
At time: 37.17681264877319 and batch: 1200, loss is 5.855306692123413 and perplexity is 349.0819443210787
At time: 38.71637320518494 and batch: 1250, loss is 5.780874700546264 and perplexity is 324.0425066483261
At time: 40.25436019897461 and batch: 1300, loss is 5.79951325416565 and perplexity is 330.13882709596203
At time: 41.7901554107666 and batch: 1350, loss is 5.776403856277466 and perplexity is 322.596996797138
At time: 43.32593870162964 and batch: 1400, loss is 5.803802404403687 and perplexity is 331.55788322173765
At time: 44.85966348648071 and batch: 1450, loss is 5.7726652050018314 and perplexity is 321.3931708684259
At time: 46.3937554359436 and batch: 1500, loss is 5.750518417358398 and perplexity is 314.3535844055299
At time: 47.93147110939026 and batch: 1550, loss is 5.72828236579895 and perplexity is 307.44074386500364
At time: 49.46775770187378 and batch: 1600, loss is 5.734536924362183 and perplexity is 309.3696760235713
At time: 51.004156827926636 and batch: 1650, loss is 5.7223389530181885 and perplexity is 305.6189159192128
At time: 52.54362392425537 and batch: 1700, loss is 5.736014900207519 and perplexity is 309.8272549940515
At time: 54.08035230636597 and batch: 1750, loss is 5.7470040607452395 and perplexity is 313.2507727790118
At time: 55.617501974105835 and batch: 1800, loss is 5.7497287845611575 and perplexity is 314.1054584824291
At time: 57.153873443603516 and batch: 1850, loss is 5.706398811340332 and perplexity is 300.7859286839417
At time: 58.694223403930664 and batch: 1900, loss is 5.686459922790528 and perplexity is 294.8479862828092
At time: 60.23693633079529 and batch: 1950, loss is 5.622535161972046 and perplexity is 276.58969483424016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.163186432594477 and perplexity of 174.72030401969286
finished 1 epochs...
Completing Train Step...
At time: 64.29214525222778 and batch: 50, loss is 5.436201057434082 and perplexity is 229.56840760391623
At time: 65.6062068939209 and batch: 100, loss is 5.371291894912719 and perplexity is 215.14062732954673
At time: 66.91980290412903 and batch: 150, loss is 5.2716027355194095 and perplexity is 194.72780965148607
At time: 68.23627853393555 and batch: 200, loss is 5.226796255111695 and perplexity is 186.19532462673607
At time: 69.55180525779724 and batch: 250, loss is 5.2249730205535885 and perplexity is 185.85615616210654
At time: 70.86702370643616 and batch: 300, loss is 5.218064498901367 and perplexity is 184.57658992780196
At time: 72.19958162307739 and batch: 350, loss is 5.176267566680909 and perplexity is 177.02085786581293
At time: 73.5194981098175 and batch: 400, loss is 5.145411128997803 and perplexity is 171.64203718570508
At time: 74.84080743789673 and batch: 450, loss is 5.091277561187744 and perplexity is 162.5974576183142
At time: 76.16294550895691 and batch: 500, loss is 5.08052092552185 and perplexity is 160.85782905547737
At time: 77.47821879386902 and batch: 550, loss is 5.033235025405884 and perplexity is 153.42855599248992
At time: 78.79227662086487 and batch: 600, loss is 5.021486158370972 and perplexity is 151.63649226206223
At time: 80.10917735099792 and batch: 650, loss is 5.0937766838073735 and perplexity is 163.0043167862601
At time: 81.4278392791748 and batch: 700, loss is 5.052314777374267 and perplexity is 156.38404007911672
At time: 82.74476861953735 and batch: 750, loss is 5.00589997291565 and perplexity is 149.29138091651566
At time: 84.06270122528076 and batch: 800, loss is 4.987989110946655 and perplexity is 146.6412475326724
At time: 85.3816328048706 and batch: 850, loss is 4.985531549453736 and perplexity is 146.2813101147882
At time: 86.69749784469604 and batch: 900, loss is 4.992487306594849 and perplexity is 147.30235433331347
At time: 88.01487064361572 and batch: 950, loss is 5.0489051723480225 and perplexity is 155.85174025180524
At time: 89.33223700523376 and batch: 1000, loss is 5.0107882213592525 and perplexity is 150.022940843545
At time: 90.65075182914734 and batch: 1050, loss is 4.914028911590576 and perplexity is 136.18699595543418
At time: 91.96821761131287 and batch: 1100, loss is 4.986906156539917 and perplexity is 146.48252770612723
At time: 93.28223586082458 and batch: 1150, loss is 4.903940811157226 and perplexity is 134.82003447778368
At time: 94.5998125076294 and batch: 1200, loss is 4.981933870315552 and perplexity is 145.7559824439056
At time: 95.91636300086975 and batch: 1250, loss is 4.915763740539551 and perplexity is 136.423462153388
At time: 97.23876523971558 and batch: 1300, loss is 4.945414552688598 and perplexity is 140.5290954922384
At time: 98.55429553985596 and batch: 1350, loss is 4.855943422317505 and perplexity is 128.5018655742588
At time: 99.86941170692444 and batch: 1400, loss is 4.869657583236695 and perplexity is 130.27630046904642
At time: 101.18548488616943 and batch: 1450, loss is 4.810127964019776 and perplexity is 122.74732375329137
At time: 102.50252485275269 and batch: 1500, loss is 4.791439447402954 and perplexity is 120.47466084848068
At time: 103.81721878051758 and batch: 1550, loss is 4.776658134460449 and perplexity is 118.70698366411335
At time: 105.1330931186676 and batch: 1600, loss is 4.837535076141357 and perplexity is 126.15799829654627
At time: 106.44691777229309 and batch: 1650, loss is 4.798945636749267 and perplexity is 121.38236891665456
At time: 107.76405954360962 and batch: 1700, loss is 4.8263735008239745 and perplexity is 124.75770557046465
At time: 109.08152103424072 and batch: 1750, loss is 4.833062353134156 and perplexity is 125.59498854694861
At time: 110.4020323753357 and batch: 1800, loss is 4.791590633392334 and perplexity is 120.49287630620259
At time: 111.7200493812561 and batch: 1850, loss is 4.792388305664063 and perplexity is 120.58902847643456
At time: 113.04088234901428 and batch: 1900, loss is 4.853534536361694 and perplexity is 128.1926917667073
At time: 114.35620927810669 and batch: 1950, loss is 4.7795435905456545 and perplexity is 119.05000209680179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.634517793877181 and perplexity of 102.97824927859273
finished 2 epochs...
Completing Train Step...
At time: 118.3432514667511 and batch: 50, loss is 4.729380359649658 and perplexity is 113.22538159237372
At time: 119.66922616958618 and batch: 100, loss is 4.667680168151856 and perplexity is 106.45050849289099
At time: 120.98236727714539 and batch: 150, loss is 4.614625492095947 and perplexity is 100.95001487368143
At time: 122.29719185829163 and batch: 200, loss is 4.600895233154297 and perplexity is 99.57341717700237
At time: 123.6145544052124 and batch: 250, loss is 4.621094875335693 and perplexity is 101.60521629733896
At time: 124.93507027626038 and batch: 300, loss is 4.634561443328858 and perplexity is 102.98274432081077
At time: 126.25882649421692 and batch: 350, loss is 4.635956974029541 and perplexity is 103.12656022856811
At time: 127.5793023109436 and batch: 400, loss is 4.605669689178467 and perplexity is 100.0499627962868
At time: 128.8963282108307 and batch: 450, loss is 4.601313076019287 and perplexity is 99.61503191251713
At time: 130.2135627269745 and batch: 500, loss is 4.606257524490356 and perplexity is 100.10879298690934
At time: 131.53197479248047 and batch: 550, loss is 4.560881052017212 and perplexity is 95.66773095714542
At time: 132.86069226264954 and batch: 600, loss is 4.536147918701172 and perplexity is 93.33058976566119
At time: 134.18138360977173 and batch: 650, loss is 4.600549631118774 and perplexity is 99.53901034721967
At time: 135.50679326057434 and batch: 700, loss is 4.618171186447143 and perplexity is 101.3085880910242
At time: 136.82605504989624 and batch: 750, loss is 4.576883287429809 and perplexity is 97.21094299959184
At time: 138.15494585037231 and batch: 800, loss is 4.554804954528809 and perplexity is 95.08820690263256
At time: 139.47908425331116 and batch: 850, loss is 4.5575807094573975 and perplexity is 95.35251511930696
At time: 140.79248332977295 and batch: 900, loss is 4.540977411270141 and perplexity is 93.78241933095033
At time: 142.10479354858398 and batch: 950, loss is 4.615625915527343 and perplexity is 101.05105816857332
At time: 143.42183923721313 and batch: 1000, loss is 4.589292669296265 and perplexity is 98.42478666074291
At time: 144.73826909065247 and batch: 1050, loss is 4.518940401077271 and perplexity is 91.73834061346999
At time: 146.05531930923462 and batch: 1100, loss is 4.578906679153443 and perplexity is 97.40783794773219
At time: 147.37283158302307 and batch: 1150, loss is 4.50908447265625 and perplexity is 90.83861519280758
At time: 148.68802309036255 and batch: 1200, loss is 4.596104516983032 and perplexity is 99.09753002740794
At time: 150.00393199920654 and batch: 1250, loss is 4.555985813140869 and perplexity is 95.2005589535468
At time: 151.32222723960876 and batch: 1300, loss is 4.568049440383911 and perplexity is 96.35597827165323
At time: 152.64122796058655 and batch: 1350, loss is 4.458588228225708 and perplexity is 86.36549462072034
At time: 153.98315405845642 and batch: 1400, loss is 4.479997882843017 and perplexity is 88.23448586919586
At time: 155.30004596710205 and batch: 1450, loss is 4.413651332855225 and perplexity is 82.57040578514265
At time: 156.6239936351776 and batch: 1500, loss is 4.40950792312622 and perplexity is 82.228990562509
At time: 157.94710493087769 and batch: 1550, loss is 4.408631744384766 and perplexity is 82.15697482298401
At time: 159.2764072418213 and batch: 1600, loss is 4.488695402145385 and perplexity is 89.00525403985665
At time: 160.5989646911621 and batch: 1650, loss is 4.4471845531463625 and perplexity is 85.38620494515632
At time: 161.92207169532776 and batch: 1700, loss is 4.477207880020142 and perplexity is 87.98865449911905
At time: 163.23651671409607 and batch: 1750, loss is 4.4828612422943115 and perplexity is 88.48749497337955
At time: 164.55358242988586 and batch: 1800, loss is 4.431077995300293 and perplexity is 84.0219433680265
At time: 165.87102127075195 and batch: 1850, loss is 4.454680995941162 and perplexity is 86.02870296195665
At time: 167.18811202049255 and batch: 1900, loss is 4.5345791244506835 and perplexity is 93.1842880616836
At time: 168.504554271698 and batch: 1950, loss is 4.464784498214722 and perplexity is 86.90229992091398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506708473382994 and perplexity of 90.62303891508286
finished 3 epochs...
Completing Train Step...
At time: 172.46461653709412 and batch: 50, loss is 4.423254985809326 and perplexity is 83.36720326576857
At time: 173.79436111450195 and batch: 100, loss is 4.368439464569092 and perplexity is 78.92037750798923
At time: 175.1174213886261 and batch: 150, loss is 4.325547819137573 and perplexity is 75.60692043470715
At time: 176.43171954154968 and batch: 200, loss is 4.329738607406616 and perplexity is 75.9244378894303
At time: 177.74645280838013 and batch: 250, loss is 4.342243289947509 and perplexity is 76.87980974418252
At time: 179.059250831604 and batch: 300, loss is 4.352445545196534 and perplexity is 77.66817188447028
At time: 180.37693786621094 and batch: 350, loss is 4.357651700973511 and perplexity is 78.07357887650991
At time: 181.69448256492615 and batch: 400, loss is 4.32661992073059 and perplexity is 75.68802220144677
At time: 183.02924489974976 and batch: 450, loss is 4.342281379699707 and perplexity is 76.88273813285514
At time: 184.34613299369812 and batch: 500, loss is 4.354988842010498 and perplexity is 77.86595650445564
At time: 185.6679723262787 and batch: 550, loss is 4.311567487716675 and perplexity is 74.55726499098516
At time: 186.9882297515869 and batch: 600, loss is 4.286233458518982 and perplexity is 72.69215420170077
At time: 188.3081316947937 and batch: 650, loss is 4.345236053466797 and perplexity is 77.1102374700125
At time: 189.64323353767395 and batch: 700, loss is 4.3705149745941165 and perplexity is 79.08434764465527
At time: 190.959969997406 and batch: 750, loss is 4.339713859558105 and perplexity is 76.68559334905994
At time: 192.27821898460388 and batch: 800, loss is 4.314115400314331 and perplexity is 74.7474725989827
At time: 193.59844875335693 and batch: 850, loss is 4.309222011566162 and perplexity is 74.38259762324817
At time: 194.9151611328125 and batch: 900, loss is 4.293593111038208 and perplexity is 73.22911670252098
At time: 196.23129844665527 and batch: 950, loss is 4.37698203086853 and perplexity is 79.59744790716093
At time: 197.54523754119873 and batch: 1000, loss is 4.350808448791504 and perplexity is 77.54112562135788
At time: 198.8618049621582 and batch: 1050, loss is 4.287406396865845 and perplexity is 72.77746764080105
At time: 200.17970252037048 and batch: 1100, loss is 4.339673089981079 and perplexity is 76.68246697358603
At time: 201.4982087612152 and batch: 1150, loss is 4.278477048873901 and perplexity is 72.13050508187398
At time: 202.81661891937256 and batch: 1200, loss is 4.3651981544494625 and perplexity is 78.66498621451657
At time: 204.16265416145325 and batch: 1250, loss is 4.339773254394531 and perplexity is 76.6901482125995
At time: 205.47501301765442 and batch: 1300, loss is 4.34059781074524 and perplexity is 76.75340963906618
At time: 206.79065823554993 and batch: 1350, loss is 4.221586399078369 and perplexity is 68.14149820012595
At time: 208.1069405078888 and batch: 1400, loss is 4.255929312705994 and perplexity is 70.5223240373287
At time: 209.42270302772522 and batch: 1450, loss is 4.182866349220276 and perplexity is 65.55348335469284
At time: 210.737242937088 and batch: 1500, loss is 4.189048109054565 and perplexity is 65.95997436551947
At time: 212.0506932735443 and batch: 1550, loss is 4.191165366172791 and perplexity is 66.09977653710914
At time: 213.36533784866333 and batch: 1600, loss is 4.2757156944274906 and perplexity is 71.93160193837183
At time: 214.68022680282593 and batch: 1650, loss is 4.234174180030823 and perplexity is 69.00466976292819
At time: 215.99304580688477 and batch: 1700, loss is 4.260880002975464 and perplexity is 70.87232387626422
At time: 217.3089578151703 and batch: 1750, loss is 4.269563717842102 and perplexity is 71.49043881149501
At time: 218.62462735176086 and batch: 1800, loss is 4.2143270826339725 and perplexity is 67.64862861426232
At time: 219.93902158737183 and batch: 1850, loss is 4.244587125778199 and perplexity is 69.72696573336155
At time: 221.2535285949707 and batch: 1900, loss is 4.326625747680664 and perplexity is 75.68846323305824
At time: 222.57153296470642 and batch: 1950, loss is 4.259333086013794 and perplexity is 70.76277502967697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457755439226017 and perplexity of 86.29360032739073
finished 4 epochs...
Completing Train Step...
At time: 226.52723479270935 and batch: 50, loss is 4.230859661102295 and perplexity is 68.77633110428997
At time: 227.8563437461853 and batch: 100, loss is 4.1707883024215695 and perplexity is 64.76648756805801
At time: 229.181702375412 and batch: 150, loss is 4.137868900299072 and perplexity is 62.669124886146136
At time: 230.49705600738525 and batch: 200, loss is 4.14630606174469 and perplexity is 63.200111269504674
At time: 231.8259460926056 and batch: 250, loss is 4.154792981147766 and perplexity is 63.73876805529308
At time: 233.1467125415802 and batch: 300, loss is 4.159635930061341 and perplexity is 64.04820033036009
At time: 234.4709222316742 and batch: 350, loss is 4.162940721511841 and perplexity is 64.26021641674295
At time: 235.81184577941895 and batch: 400, loss is 4.142093892097473 and perplexity is 62.93446155272269
At time: 237.1340355873108 and batch: 450, loss is 4.160705952644348 and perplexity is 64.11677003013583
At time: 238.4552195072174 and batch: 500, loss is 4.177443475723266 and perplexity is 65.19895725108944
At time: 239.78240084648132 and batch: 550, loss is 4.138153939247132 and perplexity is 62.68699057366694
At time: 241.13378500938416 and batch: 600, loss is 4.116200046539307 and perplexity is 61.32576389316594
At time: 242.47329711914062 and batch: 650, loss is 4.1694128036499025 and perplexity is 64.67746258487672
At time: 243.8007938861847 and batch: 700, loss is 4.195272316932678 and perplexity is 66.37180328245373
At time: 245.12770652770996 and batch: 750, loss is 4.1658184480667115 and perplexity is 64.44540608275584
At time: 246.45247411727905 and batch: 800, loss is 4.145030946731567 and perplexity is 63.119575216071375
At time: 247.77490973472595 and batch: 850, loss is 4.133558840751648 and perplexity is 62.3995984807708
At time: 249.1012613773346 and batch: 900, loss is 4.121258420944214 and perplexity is 61.63675846798133
At time: 250.42560625076294 and batch: 950, loss is 4.205602173805237 and perplexity is 67.06096786834985
At time: 251.7479772567749 and batch: 1000, loss is 4.183904862403869 and perplexity is 65.62159687365913
At time: 253.07072854042053 and batch: 1050, loss is 4.126257605552674 and perplexity is 61.945663495517394
At time: 254.38848567008972 and batch: 1100, loss is 4.172415475845337 and perplexity is 64.87195966280282
At time: 255.70599722862244 and batch: 1150, loss is 4.117538933753967 and perplexity is 61.40792716577544
At time: 257.02693486213684 and batch: 1200, loss is 4.200879993438721 and perplexity is 66.74504040283152
At time: 258.34555292129517 and batch: 1250, loss is 4.177977132797241 and perplexity is 65.23376042149533
At time: 259.6639668941498 and batch: 1300, loss is 4.176683306694031 and perplexity is 65.14941385611169
At time: 260.9804847240448 and batch: 1350, loss is 4.053333773612976 and perplexity is 57.58912648694089
At time: 262.3062822818756 and batch: 1400, loss is 4.0963399124145505 and perplexity is 60.11984053370167
At time: 263.63334012031555 and batch: 1450, loss is 4.017567753791809 and perplexity is 55.56579164876244
At time: 264.9715356826782 and batch: 1500, loss is 4.028179879188538 and perplexity is 56.15860272687287
At time: 266.297621011734 and batch: 1550, loss is 4.033905353546142 and perplexity is 56.48105959513724
At time: 267.6114864349365 and batch: 1600, loss is 4.121893248558044 and perplexity is 61.675899606907215
At time: 268.9273633956909 and batch: 1650, loss is 4.075096316337586 and perplexity is 58.856149124084745
At time: 270.2459719181061 and batch: 1700, loss is 4.105229687690735 and perplexity is 60.65667503933098
At time: 271.5644040107727 and batch: 1750, loss is 4.1100142431259155 and perplexity is 60.947585647576744
At time: 272.8850076198578 and batch: 1800, loss is 4.05616030216217 and perplexity is 57.75213406133492
At time: 274.20419549942017 and batch: 1850, loss is 4.08982400894165 and perplexity is 59.72937894248165
At time: 275.52390122413635 and batch: 1900, loss is 4.17658227443695 and perplexity is 65.14283199627802
At time: 276.844349861145 and batch: 1950, loss is 4.100213294029236 and perplexity is 60.35315919309731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.446818790879361 and perplexity of 85.35497960413878
finished 5 epochs...
Completing Train Step...
At time: 280.85620403289795 and batch: 50, loss is 4.079522895812988 and perplexity is 59.11725802909816
At time: 282.1746678352356 and batch: 100, loss is 4.026560430526733 and perplexity is 56.06773035426939
At time: 283.4945125579834 and batch: 150, loss is 3.991381759643555 and perplexity is 54.12963185417251
At time: 284.8168857097626 and batch: 200, loss is 4.001108412742615 and perplexity is 54.65870086982435
At time: 286.1375377178192 and batch: 250, loss is 4.0066469860076905 and perplexity is 54.96227198858359
At time: 287.4579746723175 and batch: 300, loss is 4.0177232456207275 and perplexity is 55.57443234709279
At time: 288.7759618759155 and batch: 350, loss is 4.023610458374024 and perplexity is 55.90257583144944
At time: 290.0926728248596 and batch: 400, loss is 3.9927077007293703 and perplexity is 54.2014521612336
At time: 291.41749930381775 and batch: 450, loss is 4.022675552368164 and perplexity is 55.850336600751824
At time: 292.75565481185913 and batch: 500, loss is 4.039085025787354 and perplexity is 56.774371946826484
At time: 294.07487440109253 and batch: 550, loss is 4.000700802803039 and perplexity is 54.63642598010716
At time: 295.391154050827 and batch: 600, loss is 3.981984405517578 and perplexity is 53.623339166665986
At time: 296.7079174518585 and batch: 650, loss is 4.0326322746276855 and perplexity is 56.40920049972964
At time: 298.0215997695923 and batch: 700, loss is 4.0644821929931645 and perplexity is 58.2347463544313
At time: 299.33402156829834 and batch: 750, loss is 4.032433762550354 and perplexity is 56.39800370354422
At time: 300.6449627876282 and batch: 800, loss is 4.009462862014771 and perplexity is 55.11725703850423
At time: 301.9907937049866 and batch: 850, loss is 4.001756653785706 and perplexity is 54.69414436981476
At time: 303.29953789711 and batch: 900, loss is 3.9847275686264036 and perplexity is 53.770638673358015
At time: 304.6104955673218 and batch: 950, loss is 4.0770860862731935 and perplexity is 58.97337590862639
At time: 305.9240164756775 and batch: 1000, loss is 4.052564845085144 and perplexity is 57.54486158514605
At time: 307.2389304637909 and batch: 1050, loss is 4.004022693634033 and perplexity is 54.81822401203864
At time: 308.5499620437622 and batch: 1100, loss is 4.048815584182739 and perplexity is 57.32951483330904
At time: 309.86065578460693 and batch: 1150, loss is 3.9916365051269533 and perplexity is 54.143422889932836
At time: 311.17181515693665 and batch: 1200, loss is 4.073658146858215 and perplexity is 58.771564844584844
At time: 312.4843707084656 and batch: 1250, loss is 4.052222008705139 and perplexity is 57.52513649454484
At time: 313.8009819984436 and batch: 1300, loss is 4.047427091598511 and perplexity is 57.24996846465695
At time: 315.11732268333435 and batch: 1350, loss is 3.921289477348328 and perplexity is 50.465476929684634
At time: 316.43138790130615 and batch: 1400, loss is 3.96929075717926 and perplexity is 52.946965264699735
At time: 317.7427980899811 and batch: 1450, loss is 3.889982271194458 and perplexity is 48.91001939982237
At time: 319.0563266277313 and batch: 1500, loss is 3.9014422941207885 and perplexity is 49.473753375931956
At time: 320.3738088607788 and batch: 1550, loss is 3.908247194290161 and perplexity is 49.81156541367767
At time: 321.70139956474304 and batch: 1600, loss is 4.0018523406982425 and perplexity is 54.69937813402071
At time: 323.0192985534668 and batch: 1650, loss is 3.9542988252639772 and perplexity is 52.15910847041263
At time: 324.33605909347534 and batch: 1700, loss is 3.98194703578949 and perplexity is 53.621335314504094
At time: 325.65188908576965 and batch: 1750, loss is 3.989973521232605 and perplexity is 54.05345807543403
At time: 326.9673960208893 and batch: 1800, loss is 3.9332340717315675 and perplexity is 51.07188099748716
At time: 328.28803968429565 and batch: 1850, loss is 3.969816484451294 and perplexity is 52.97480824657698
At time: 329.6013717651367 and batch: 1900, loss is 4.06301374912262 and perplexity is 58.14929465396245
At time: 330.91306471824646 and batch: 1950, loss is 3.9817147731781004 and perplexity is 53.60888252935193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4481715002725295 and perplexity of 85.4705182142667
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 334.87452936172485 and batch: 50, loss is 3.997900867462158 and perplexity is 54.483661485261514
At time: 336.1875102519989 and batch: 100, loss is 3.97470477104187 and perplexity is 53.23439824961664
At time: 337.4994287490845 and batch: 150, loss is 3.9409371995925904 and perplexity is 51.4668133813597
At time: 338.81027007102966 and batch: 200, loss is 3.9508342266082765 and perplexity is 51.9787107765767
At time: 340.1245639324188 and batch: 250, loss is 3.96496789932251 and perplexity is 52.71857706044504
At time: 341.4385230541229 and batch: 300, loss is 3.9630031394958496 and perplexity is 52.61509940577515
At time: 342.7530734539032 and batch: 350, loss is 3.976417942047119 and perplexity is 53.32567604208882
At time: 344.066029548645 and batch: 400, loss is 3.9404955959320067 and perplexity is 51.44409046580253
At time: 345.3772306442261 and batch: 450, loss is 3.9595288896560668 and perplexity is 52.43261858063475
At time: 346.69043231010437 and batch: 500, loss is 3.9646253776550293 and perplexity is 52.700522897670574
At time: 348.0043053627014 and batch: 550, loss is 3.927294282913208 and perplexity is 50.76942396450762
At time: 349.31654238700867 and batch: 600, loss is 3.8946772384643555 and perplexity is 49.14019023955503
At time: 350.63566851615906 and batch: 650, loss is 3.951112403869629 and perplexity is 51.99317208329926
At time: 351.9467089176178 and batch: 700, loss is 3.973266353607178 and perplexity is 53.157880008828165
At time: 353.25920128822327 and batch: 750, loss is 3.9189887857437133 and perplexity is 50.34950488969412
At time: 354.5872600078583 and batch: 800, loss is 3.8965600538253784 and perplexity is 49.232799300104325
At time: 355.91051721572876 and batch: 850, loss is 3.8831870698928834 and perplexity is 48.57879262317402
At time: 357.23214054107666 and batch: 900, loss is 3.847835478782654 and perplexity is 46.89145575458687
At time: 358.55897188186646 and batch: 950, loss is 3.9434712171554565 and perplexity is 51.597396570544674
At time: 359.87634229660034 and batch: 1000, loss is 3.911427631378174 and perplexity is 49.970240157499454
At time: 361.19412207603455 and batch: 1050, loss is 3.859153289794922 and perplexity is 47.42517898104729
At time: 362.51201033592224 and batch: 1100, loss is 3.8889479637145996 and perplexity is 48.85945755367251
At time: 363.8342955112457 and batch: 1150, loss is 3.832750749588013 and perplexity is 46.189419171122516
At time: 365.15087389945984 and batch: 1200, loss is 3.899474310874939 and perplexity is 49.37648560024811
At time: 366.46383929252625 and batch: 1250, loss is 3.8687750816345217 and perplexity is 47.88369652392033
At time: 367.7775704860687 and batch: 1300, loss is 3.870366625785828 and perplexity is 47.959966218259524
At time: 369.09435987472534 and batch: 1350, loss is 3.731865572929382 and perplexity is 41.756936154264295
At time: 370.4098074436188 and batch: 1400, loss is 3.767394027709961 and perplexity is 43.26716476007668
At time: 371.7297852039337 and batch: 1450, loss is 3.6882569456100462 and perplexity is 39.97510740857318
At time: 373.0437002182007 and batch: 1500, loss is 3.6842886352539064 and perplexity is 39.81678811366558
At time: 374.35816287994385 and batch: 1550, loss is 3.687968444824219 and perplexity is 39.96357622213043
At time: 375.6752893924713 and batch: 1600, loss is 3.771968111991882 and perplexity is 43.46552573238552
At time: 376.99227929115295 and batch: 1650, loss is 3.707896614074707 and perplexity is 40.76796551538294
At time: 378.3080177307129 and batch: 1700, loss is 3.722417688369751 and perplexity is 41.36427925125165
At time: 379.62251448631287 and batch: 1750, loss is 3.7181419801712035 and perplexity is 41.187795229288504
At time: 380.9372832775116 and batch: 1800, loss is 3.6558210039138794 and perplexity is 38.69928033677564
At time: 382.2575378417969 and batch: 1850, loss is 3.6759292125701903 and perplexity is 39.48533008100088
At time: 383.5802011489868 and batch: 1900, loss is 3.765652070045471 and perplexity is 43.19186079800104
At time: 384.90012860298157 and batch: 1950, loss is 3.680795679092407 and perplexity is 39.67795243292425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.391316542514535 and perplexity of 80.74665543751605
finished 7 epochs...
Completing Train Step...
At time: 388.88060092926025 and batch: 50, loss is 3.8901486873626707 and perplexity is 48.918159495141055
At time: 390.1993958950043 and batch: 100, loss is 3.8573063087463377 and perplexity is 47.33766641614594
At time: 391.5180912017822 and batch: 150, loss is 3.8164564418792724 and perplexity is 45.442893141770675
At time: 392.8341190814972 and batch: 200, loss is 3.824261646270752 and perplexity is 45.79897203743433
At time: 394.14918541908264 and batch: 250, loss is 3.8296835899353026 and perplexity is 46.047965889051575
At time: 395.46525263786316 and batch: 300, loss is 3.828472127914429 and perplexity is 45.992214304520736
At time: 396.7888231277466 and batch: 350, loss is 3.843042950630188 and perplexity is 46.667264782652616
At time: 398.106369972229 and batch: 400, loss is 3.8147174453735353 and perplexity is 45.3639367817014
At time: 399.4389576911926 and batch: 450, loss is 3.8380965566635132 and perplexity is 46.437000065181905
At time: 400.75409865379333 and batch: 500, loss is 3.850321788787842 and perplexity is 47.008187505713956
At time: 402.0716555118561 and batch: 550, loss is 3.812265491485596 and perplexity is 45.25284275491155
At time: 403.3912558555603 and batch: 600, loss is 3.7848379898071287 and perplexity is 44.02853690914706
At time: 404.7106056213379 and batch: 650, loss is 3.8344074583053587 and perplexity is 46.2660050072066
At time: 406.0284478664398 and batch: 700, loss is 3.860197353363037 and perplexity is 47.474719739983264
At time: 407.34511137008667 and batch: 750, loss is 3.811547694206238 and perplexity is 45.220372042587506
At time: 408.6605455875397 and batch: 800, loss is 3.7900859546661376 and perplexity is 44.2602044835859
At time: 409.97801995277405 and batch: 850, loss is 3.781608853340149 and perplexity is 43.88659205801556
At time: 411.2976326942444 and batch: 900, loss is 3.75002667427063 and perplexity is 42.5222162340389
At time: 412.6191954612732 and batch: 950, loss is 3.8465271472930906 and perplexity is 46.83014630172102
At time: 413.9412007331848 and batch: 1000, loss is 3.817990436553955 and perplexity is 45.51265579193915
At time: 415.2565758228302 and batch: 1050, loss is 3.77044349193573 and perplexity is 43.39930781151463
At time: 416.5787453651428 and batch: 1100, loss is 3.800742297172546 and perplexity is 44.73437837449758
At time: 417.90646600723267 and batch: 1150, loss is 3.748104524612427 and perplexity is 42.440560672883876
At time: 419.2262372970581 and batch: 1200, loss is 3.8162964534759523 and perplexity is 45.43562338740838
At time: 420.5429742336273 and batch: 1250, loss is 3.7870049905776977 and perplexity is 44.12405023390369
At time: 421.85738921165466 and batch: 1300, loss is 3.789108004570007 and perplexity is 44.2169413703873
At time: 423.17339038848877 and batch: 1350, loss is 3.656970138549805 and perplexity is 38.74377658138746
At time: 424.49273777008057 and batch: 1400, loss is 3.6984657192230226 and perplexity is 40.3852944210003
At time: 425.81134390830994 and batch: 1450, loss is 3.61828462600708 and perplexity is 37.27357483090085
At time: 427.1278829574585 and batch: 1500, loss is 3.6173712682723997 and perplexity is 37.23954626552217
At time: 428.4439170360565 and batch: 1550, loss is 3.6257268381118775 and perplexity is 37.55200747296928
At time: 429.7597415447235 and batch: 1600, loss is 3.713459348678589 and perplexity is 40.995378821395484
At time: 431.0793707370758 and batch: 1650, loss is 3.6553600072860717 and perplexity is 38.681444210554695
At time: 432.4003851413727 and batch: 1700, loss is 3.672154302597046 and perplexity is 39.33655749291519
At time: 433.71915912628174 and batch: 1750, loss is 3.672216544151306 and perplexity is 39.3390059375895
At time: 435.03694772720337 and batch: 1800, loss is 3.6151010179519654 and perplexity is 37.15509906808888
At time: 436.35107827186584 and batch: 1850, loss is 3.6380031728744506 and perplexity is 38.015849804185144
At time: 437.6658682823181 and batch: 1900, loss is 3.7326080560684205 and perplexity is 41.78795148805309
At time: 438.98434114456177 and batch: 1950, loss is 3.6520857048034667 and perplexity is 38.55499658859757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402161496184593 and perplexity of 81.62711481589119
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 442.95948600769043 and batch: 50, loss is 3.843612937927246 and perplexity is 46.69387211296695
At time: 444.2860233783722 and batch: 100, loss is 3.85088029384613 and perplexity is 47.03444914916457
At time: 445.60434126853943 and batch: 150, loss is 3.833842043876648 and perplexity is 46.239852934493065
At time: 446.92168831825256 and batch: 200, loss is 3.843214201927185 and perplexity is 46.675257296618604
At time: 448.2397491931915 and batch: 250, loss is 3.8451603412628175 and perplexity is 46.76618229850782
At time: 449.55632972717285 and batch: 300, loss is 3.843204827308655 and perplexity is 46.674819735937646
At time: 450.87894320487976 and batch: 350, loss is 3.858094801902771 and perplexity is 47.37500656144652
At time: 452.1961064338684 and batch: 400, loss is 3.8282283115386964 and perplexity is 45.98100201644236
At time: 453.51401233673096 and batch: 450, loss is 3.860058627128601 and perplexity is 47.468134207686454
At time: 454.8316743373871 and batch: 500, loss is 3.8762063074111937 and perplexity is 48.240856508430426
At time: 456.1481668949127 and batch: 550, loss is 3.840320935249329 and perplexity is 46.540408500833806
At time: 457.46317172050476 and batch: 600, loss is 3.796137766838074 and perplexity is 44.52887106768441
At time: 458.78123116493225 and batch: 650, loss is 3.832405619621277 and perplexity is 46.173480569023255
At time: 460.1001272201538 and batch: 700, loss is 3.861325159072876 and perplexity is 47.52829220396598
At time: 461.4170649051666 and batch: 750, loss is 3.8021781396865846 and perplexity is 44.79865603206034
At time: 462.73455357551575 and batch: 800, loss is 3.7777650213241576 and perplexity is 43.718223168558865
At time: 464.0498306751251 and batch: 850, loss is 3.773845067024231 and perplexity is 43.54718518122576
At time: 465.39560770988464 and batch: 900, loss is 3.740162582397461 and perplexity is 42.10483511358522
At time: 466.71306014060974 and batch: 950, loss is 3.840867347717285 and perplexity is 46.56584570927346
At time: 468.0333762168884 and batch: 1000, loss is 3.8087950229644774 and perplexity is 45.0960663897128
At time: 469.35061264038086 and batch: 1050, loss is 3.751199469566345 and perplexity is 42.57211534420291
At time: 470.667870759964 and batch: 1100, loss is 3.780029926300049 and perplexity is 43.81735300720656
At time: 471.98337483406067 and batch: 1150, loss is 3.7259538316726686 and perplexity is 41.51080819128406
At time: 473.3021082878113 and batch: 1200, loss is 3.7847808027267456 and perplexity is 44.026019117660944
At time: 474.620920419693 and batch: 1250, loss is 3.748563871383667 and perplexity is 42.46006008555184
At time: 475.938761472702 and batch: 1300, loss is 3.7472638082504273 and perplexity is 42.40489519349049
At time: 477.25482988357544 and batch: 1350, loss is 3.6085542583465577 and perplexity is 36.91264806654139
At time: 478.5706353187561 and batch: 1400, loss is 3.650580735206604 and perplexity is 38.497016131280816
At time: 479.88864064216614 and batch: 1450, loss is 3.567800908088684 and perplexity is 35.438574715208915
At time: 481.2074463367462 and batch: 1500, loss is 3.56226233959198 and perplexity is 35.24283829188018
At time: 482.525625705719 and batch: 1550, loss is 3.569243211746216 and perplexity is 35.48972477923356
At time: 483.8450243473053 and batch: 1600, loss is 3.650446491241455 and perplexity is 38.4918484860593
At time: 485.1598699092865 and batch: 1650, loss is 3.593309407234192 and perplexity is 36.35418787953106
At time: 486.47623443603516 and batch: 1700, loss is 3.6093079042434693 and perplexity is 36.940477617797214
At time: 487.7952506542206 and batch: 1750, loss is 3.604388852119446 and perplexity is 36.7592116767238
At time: 489.1117603778839 and batch: 1800, loss is 3.5449638605117797 and perplexity is 34.63843350438099
At time: 490.4285526275635 and batch: 1850, loss is 3.5549033498764038 and perplexity is 34.984438553979
At time: 491.7435231208801 and batch: 1900, loss is 3.651759605407715 and perplexity is 38.54242587726889
At time: 493.05919885635376 and batch: 1950, loss is 3.579072217941284 and perplexity is 35.84027345431363
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3804934479469475 and perplexity of 79.8774390402719
finished 9 epochs...
Completing Train Step...
At time: 497.01547741889954 and batch: 50, loss is 3.837764344215393 and perplexity is 46.42157567793547
At time: 498.34410762786865 and batch: 100, loss is 3.819100651741028 and perplexity is 45.56321269293008
At time: 499.6600034236908 and batch: 150, loss is 3.7914865827560424 and perplexity is 44.32224000345483
At time: 500.98766899108887 and batch: 200, loss is 3.796151328086853 and perplexity is 44.52947493887743
At time: 502.3266839981079 and batch: 250, loss is 3.7950932264328 and perplexity is 44.48238314613598
At time: 503.6469702720642 and batch: 300, loss is 3.792027959823608 and perplexity is 44.34624154413148
At time: 504.96859908103943 and batch: 350, loss is 3.8042653799057007 and perplexity is 44.89225924090145
At time: 506.28574299812317 and batch: 400, loss is 3.775221109390259 and perplexity is 43.60714920000973
At time: 507.6085259914398 and batch: 450, loss is 3.8082776737213133 and perplexity is 45.072742007842294
At time: 508.926864862442 and batch: 500, loss is 3.8237391757965087 and perplexity is 45.77504967670185
At time: 510.2453410625458 and batch: 550, loss is 3.7895727729797364 and perplexity is 44.237496784294606
At time: 511.5627586841583 and batch: 600, loss is 3.747863473892212 and perplexity is 42.43033157808221
At time: 512.8788416385651 and batch: 650, loss is 3.7830900716781617 and perplexity is 43.95164585050592
At time: 514.1957414150238 and batch: 700, loss is 3.815739269256592 and perplexity is 45.410314426591675
At time: 515.5138566493988 and batch: 750, loss is 3.759866886138916 and perplexity is 42.94270932844466
At time: 516.833338022232 and batch: 800, loss is 3.734680576324463 and perplexity is 41.87464767273757
At time: 518.1505351066589 and batch: 850, loss is 3.730293412208557 and perplexity is 41.69133911747418
At time: 519.4669587612152 and batch: 900, loss is 3.6981328773498534 and perplexity is 40.371854740724984
At time: 520.7826931476593 and batch: 950, loss is 3.8006706762313844 and perplexity is 44.731174570947196
At time: 522.1014721393585 and batch: 1000, loss is 3.7709369134902953 and perplexity is 43.42072724941364
At time: 523.4203505516052 and batch: 1050, loss is 3.7156733655929566 and perplexity is 41.086243834737814
At time: 524.7390615940094 and batch: 1100, loss is 3.745421152114868 and perplexity is 42.32682949938814
At time: 526.0554430484772 and batch: 1150, loss is 3.6953188705444338 and perplexity is 40.25840776188451
At time: 527.3708400726318 and batch: 1200, loss is 3.756774754524231 and perplexity is 42.81012990146447
At time: 528.6993343830109 and batch: 1250, loss is 3.722357807159424 and perplexity is 41.36180238230547
At time: 530.019186258316 and batch: 1300, loss is 3.7242308378219606 and perplexity is 41.43934690538962
At time: 531.3528339862823 and batch: 1350, loss is 3.586196823120117 and perplexity is 36.09653304239409
At time: 532.6794674396515 and batch: 1400, loss is 3.630148758888245 and perplexity is 37.718427151152355
At time: 533.9981410503387 and batch: 1450, loss is 3.548655586242676 and perplexity is 34.766545432175825
At time: 535.3137629032135 and batch: 1500, loss is 3.545054349899292 and perplexity is 34.641568056832924
At time: 536.6324944496155 and batch: 1550, loss is 3.5547130823135378 and perplexity is 34.97778278332581
At time: 537.949718952179 and batch: 1600, loss is 3.6378659439086913 and perplexity is 38.01063328637091
At time: 539.2670214176178 and batch: 1650, loss is 3.583785228729248 and perplexity is 36.009587726335454
At time: 540.5819447040558 and batch: 1700, loss is 3.601732292175293 and perplexity is 36.66168822320933
At time: 541.8992602825165 and batch: 1750, loss is 3.6002079486846923 and perplexity is 36.605845789749885
At time: 543.218269109726 and batch: 1800, loss is 3.5430858182907103 and perplexity is 34.57344211118056
At time: 544.5443148612976 and batch: 1850, loss is 3.5556562328338623 and perplexity is 35.010787659194044
At time: 545.8620254993439 and batch: 1900, loss is 3.6535280418395994 and perplexity is 38.61064601106935
At time: 547.1792666912079 and batch: 1950, loss is 3.5808868503570555 and perplexity is 35.90536942107683
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38205935456032 and perplexity of 80.00261763373915
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 551.1542236804962 and batch: 50, loss is 3.8275708866119387 and perplexity is 45.95078289405003
At time: 552.4857795238495 and batch: 100, loss is 3.8311829805374145 and perplexity is 46.11706156410999
At time: 553.8035395145416 and batch: 150, loss is 3.817683444023132 and perplexity is 45.498685890990444
At time: 555.1193535327911 and batch: 200, loss is 3.8346162366867067 and perplexity is 46.27566535724448
At time: 556.435188293457 and batch: 250, loss is 3.8348940134048464 and perplexity is 46.288521445175434
At time: 557.7537605762482 and batch: 300, loss is 3.8301783323287966 and perplexity is 46.07075340642169
At time: 559.0724275112152 and batch: 350, loss is 3.8529463624954223 and perplexity is 47.131726005716885
At time: 560.3911139965057 and batch: 400, loss is 3.8270173835754395 and perplexity is 45.92535603376001
At time: 561.7071330547333 and batch: 450, loss is 3.857805361747742 and perplexity is 47.36129631644629
At time: 563.0303478240967 and batch: 500, loss is 3.8662387037277224 and perplexity is 47.76239926683028
At time: 564.3595771789551 and batch: 550, loss is 3.8391549253463744 and perplexity is 46.48617354902446
At time: 565.679342508316 and batch: 600, loss is 3.7906809282302856 and perplexity is 44.286545970664584
At time: 566.9965345859528 and batch: 650, loss is 3.8098096466064453 and perplexity is 45.141845145007984
At time: 568.3114547729492 and batch: 700, loss is 3.8426091480255127 and perplexity is 46.64702479203456
At time: 569.6248316764832 and batch: 750, loss is 3.7912533569335936 and perplexity is 44.3119041179218
At time: 570.9392805099487 and batch: 800, loss is 3.763509349822998 and perplexity is 43.09941180595669
At time: 572.254949092865 and batch: 850, loss is 3.763640103340149 and perplexity is 43.10504757407768
At time: 573.5709059238434 and batch: 900, loss is 3.72252779006958 and perplexity is 41.368833779435455
At time: 574.885570526123 and batch: 950, loss is 3.8294819688796995 and perplexity is 46.03868258544683
At time: 576.2020149230957 and batch: 1000, loss is 3.8001988983154296 and perplexity is 44.71007636785437
At time: 577.526257276535 and batch: 1050, loss is 3.7377058267593384 and perplexity is 42.001520783523205
At time: 578.8451416492462 and batch: 1100, loss is 3.7647391748428345 and perplexity is 43.152449147575965
At time: 580.1617743968964 and batch: 1150, loss is 3.7226537799835206 and perplexity is 41.37404616359018
At time: 581.476989030838 and batch: 1200, loss is 3.7813358688354493 and perplexity is 43.874613333497116
At time: 582.7903022766113 and batch: 1250, loss is 3.7425183343887327 and perplexity is 42.204140586353624
At time: 584.1030941009521 and batch: 1300, loss is 3.7441460037231447 and perplexity is 42.27289090798797
At time: 585.4163687229156 and batch: 1350, loss is 3.599380125999451 and perplexity is 36.57555517954964
At time: 586.7292330265045 and batch: 1400, loss is 3.635337886810303 and perplexity is 37.91466159714565
At time: 588.0436265468597 and batch: 1450, loss is 3.549771952629089 and perplexity is 34.80537930725127
At time: 589.3582689762115 and batch: 1500, loss is 3.5397096776962282 and perplexity is 34.45691412789072
At time: 590.6724107265472 and batch: 1550, loss is 3.548027081489563 and perplexity is 34.74470135839355
At time: 591.9874894618988 and batch: 1600, loss is 3.624156284332275 and perplexity is 37.49307631509082
At time: 593.3056585788727 and batch: 1650, loss is 3.5675331068038942 and perplexity is 35.42908549003913
At time: 594.6290633678436 and batch: 1700, loss is 3.5828100061416626 and perplexity is 35.974487481072956
At time: 595.9429707527161 and batch: 1750, loss is 3.5931506395339965 and perplexity is 36.34841646689804
At time: 597.2557497024536 and batch: 1800, loss is 3.5338037490844725 and perplexity is 34.25401380005889
At time: 598.5693662166595 and batch: 1850, loss is 3.551120080947876 and perplexity is 34.85233306747707
At time: 599.8846569061279 and batch: 1900, loss is 3.652423629760742 and perplexity is 38.5680274857812
At time: 601.1999804973602 and batch: 1950, loss is 3.58867084980011 and perplexity is 36.185947389328824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360572992369186 and perplexity of 78.30198801309828
finished 11 epochs...
Completing Train Step...
At time: 605.1759886741638 and batch: 50, loss is 3.8442699909210205 and perplexity is 46.724562542945016
At time: 606.4914727210999 and batch: 100, loss is 3.828578858375549 and perplexity is 45.99712333672837
At time: 607.8082928657532 and batch: 150, loss is 3.80159574508667 and perplexity is 44.772573132710946
At time: 609.1242728233337 and batch: 200, loss is 3.8085918378829957 and perplexity is 45.08690447260287
At time: 610.4379987716675 and batch: 250, loss is 3.8069510507583617 and perplexity is 45.01298711815959
At time: 611.7530243396759 and batch: 300, loss is 3.7974434518814086 and perplexity is 44.58704972186807
At time: 613.0685088634491 and batch: 350, loss is 3.816835379600525 and perplexity is 45.46011643121587
At time: 614.3876187801361 and batch: 400, loss is 3.7918148851394653 and perplexity is 44.33679348932794
At time: 615.7052924633026 and batch: 450, loss is 3.822778735160828 and perplexity is 45.7311065646452
At time: 617.0189788341522 and batch: 500, loss is 3.8352360486984254 and perplexity is 46.30435646111006
At time: 618.3355696201324 and batch: 550, loss is 3.81189866065979 and perplexity is 45.23624566158255
At time: 619.6583213806152 and batch: 600, loss is 3.7674949741363526 and perplexity is 43.27153264619685
At time: 620.9807164669037 and batch: 650, loss is 3.78675940990448 and perplexity is 44.113215550391054
At time: 622.3072142601013 and batch: 700, loss is 3.822381687164307 and perplexity is 45.712952724616414
At time: 623.6574177742004 and batch: 750, loss is 3.7734852266311645 and perplexity is 43.53151796401105
At time: 624.9888668060303 and batch: 800, loss is 3.7447112894058225 and perplexity is 42.29679392336333
At time: 626.3231475353241 and batch: 850, loss is 3.74280752658844 and perplexity is 42.21634745958773
At time: 627.6495184898376 and batch: 900, loss is 3.70160783290863 and perplexity is 40.51238917581615
At time: 629.0161519050598 and batch: 950, loss is 3.807892851829529 and perplexity is 45.05540036693047
At time: 630.3384742736816 and batch: 1000, loss is 3.778408055305481 and perplexity is 43.746344512180094
At time: 631.6628215312958 and batch: 1050, loss is 3.717748637199402 and perplexity is 41.17159748535427
At time: 632.9870426654816 and batch: 1100, loss is 3.7463519763946533 and perplexity is 42.36624668236194
At time: 634.3155269622803 and batch: 1150, loss is 3.7049494123458864 and perplexity is 40.647990978358514
At time: 635.645537853241 and batch: 1200, loss is 3.7658035945892334 and perplexity is 43.19840592086356
At time: 636.9733839035034 and batch: 1250, loss is 3.7292559051513674 and perplexity is 41.64810648987227
At time: 638.2992508411407 and batch: 1300, loss is 3.732487926483154 and perplexity is 41.78293182028303
At time: 639.6229765415192 and batch: 1350, loss is 3.589398865699768 and perplexity is 36.21230092610538
At time: 640.9469447135925 and batch: 1400, loss is 3.627884588241577 and perplexity is 37.6331228038004
At time: 642.2730941772461 and batch: 1450, loss is 3.5447791051864623 and perplexity is 34.63203446047733
At time: 643.5987551212311 and batch: 1500, loss is 3.5373654556274414 and perplexity is 34.37623407230051
At time: 644.9310665130615 and batch: 1550, loss is 3.54719557762146 and perplexity is 34.715823012709905
At time: 646.2526478767395 and batch: 1600, loss is 3.624526300430298 and perplexity is 37.50695192383278
At time: 647.5732057094574 and batch: 1650, loss is 3.569547357559204 and perplexity is 35.500520472078435
At time: 648.9008777141571 and batch: 1700, loss is 3.5855920028686525 and perplexity is 36.07470772906346
At time: 650.2274653911591 and batch: 1750, loss is 3.596638674736023 and perplexity is 36.475422394879395
At time: 651.5555973052979 and batch: 1800, loss is 3.538896389007568 and perplexity is 34.42890210186035
At time: 652.8785393238068 and batch: 1850, loss is 3.5570839977264406 and perplexity is 35.060810534630356
At time: 654.2016623020172 and batch: 1900, loss is 3.6585500764846803 and perplexity is 38.80503772540806
At time: 655.5264172554016 and batch: 1950, loss is 3.5943908214569094 and perplexity is 36.393523080348736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358946334484012 and perplexity of 78.17472100487568
finished 12 epochs...
Completing Train Step...
At time: 659.6460690498352 and batch: 50, loss is 3.838522028923035 and perplexity is 46.456761924288344
At time: 660.9685432910919 and batch: 100, loss is 3.8198995923995973 and perplexity is 45.599629541598944
At time: 662.304388999939 and batch: 150, loss is 3.7914292192459107 and perplexity is 44.3196975971127
At time: 663.6310257911682 and batch: 200, loss is 3.7970834159851075 and perplexity is 44.57099967292828
At time: 664.9568207263947 and batch: 250, loss is 3.7947664308547973 and perplexity is 44.46784887502191
At time: 666.281236410141 and batch: 300, loss is 3.784511213302612 and perplexity is 44.01415176824795
At time: 667.6039252281189 and batch: 350, loss is 3.803305130004883 and perplexity is 44.849172143919
At time: 668.9277346134186 and batch: 400, loss is 3.7789620208740233 and perplexity is 43.770585194421194
At time: 670.2540578842163 and batch: 450, loss is 3.809889245033264 and perplexity is 45.14543850787634
At time: 671.5834693908691 and batch: 500, loss is 3.822616448402405 and perplexity is 45.723685613779054
At time: 672.9145879745483 and batch: 550, loss is 3.799076156616211 and perplexity is 44.659906669817055
At time: 674.2362697124481 and batch: 600, loss is 3.7556169509887694 and perplexity is 42.76059286432308
At time: 675.559611082077 and batch: 650, loss is 3.7752786445617676 and perplexity is 43.60965821699563
At time: 676.8872654438019 and batch: 700, loss is 3.8114661502838136 and perplexity is 45.21668474641801
At time: 678.214507818222 and batch: 750, loss is 3.7638189601898193 and perplexity is 43.11275789659311
At time: 679.5394775867462 and batch: 800, loss is 3.7347436475753786 and perplexity is 41.877288842438006
At time: 680.8641223907471 and batch: 850, loss is 3.732499852180481 and perplexity is 41.7834301138526
At time: 682.1883215904236 and batch: 900, loss is 3.691541509628296 and perplexity is 40.10662407721444
At time: 683.5115745067596 and batch: 950, loss is 3.7977319240570067 and perplexity is 44.59991370046557
At time: 684.8388018608093 and batch: 1000, loss is 3.7679883813858033 and perplexity is 43.29288840220849
At time: 686.1639060974121 and batch: 1050, loss is 3.708241548538208 and perplexity is 40.78203021725676
At time: 687.4883971214294 and batch: 1100, loss is 3.7369899320602418 and perplexity is 41.97146287787168
At time: 688.8123576641083 and batch: 1150, loss is 3.6959757804870605 and perplexity is 40.28486259848887
At time: 690.1425426006317 and batch: 1200, loss is 3.7579901456832885 and perplexity is 42.86219258671968
At time: 691.4689757823944 and batch: 1250, loss is 3.722313361167908 and perplexity is 41.3599640568411
At time: 692.7956554889679 and batch: 1300, loss is 3.726303496360779 and perplexity is 41.525325593046944
At time: 694.1202199459076 and batch: 1350, loss is 3.584001269340515 and perplexity is 36.0173681000874
At time: 695.443510055542 and batch: 1400, loss is 3.6233198738098142 and perplexity is 37.46172982263696
At time: 696.7695825099945 and batch: 1450, loss is 3.541156711578369 and perplexity is 34.50681054230238
At time: 698.092376947403 and batch: 1500, loss is 3.5347218704223633 and perplexity is 34.28547758261201
At time: 699.4167237281799 and batch: 1550, loss is 3.545162863731384 and perplexity is 34.645327350096416
At time: 700.7412927150726 and batch: 1600, loss is 3.6230274200439454 and perplexity is 37.450775600554195
At time: 702.0648419857025 and batch: 1650, loss is 3.5688062477111817 and perplexity is 35.474220433559196
At time: 703.387941122055 and batch: 1700, loss is 3.58483549118042 and perplexity is 36.047427111371
At time: 704.7123956680298 and batch: 1750, loss is 3.5960221481323242 and perplexity is 36.45294125741356
At time: 706.0383014678955 and batch: 1800, loss is 3.539286036491394 and perplexity is 34.44231985086154
At time: 707.3635265827179 and batch: 1850, loss is 3.5579478549957275 and perplexity is 35.0911111564997
At time: 708.6870679855347 and batch: 1900, loss is 3.6595279026031493 and perplexity is 38.84300086247277
At time: 710.0138623714447 and batch: 1950, loss is 3.5951313018798827 and perplexity is 36.42048175166512
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358966490279797 and perplexity of 78.17629669446741
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 714.1974744796753 and batch: 50, loss is 3.837070722579956 and perplexity is 46.38938783307747
At time: 715.5217015743256 and batch: 100, loss is 3.82581832408905 and perplexity is 45.870321801195
At time: 716.841543674469 and batch: 150, loss is 3.803513112068176 and perplexity is 44.858500937355714
At time: 718.1663358211517 and batch: 200, loss is 3.8149675512313843 and perplexity is 45.3752839869677
At time: 719.4915351867676 and batch: 250, loss is 3.816565580368042 and perplexity is 45.44785298110324
At time: 720.8167572021484 and batch: 300, loss is 3.803691182136536 and perplexity is 44.86648960493432
At time: 722.1434223651886 and batch: 350, loss is 3.8261639404296877 and perplexity is 45.88617807389543
At time: 723.4662237167358 and batch: 400, loss is 3.812583718299866 and perplexity is 45.26724571448053
At time: 724.7908668518066 and batch: 450, loss is 3.8490647077560425 and perplexity is 46.94913153171057
At time: 726.119268655777 and batch: 500, loss is 3.8559641361236574 and perplexity is 47.27417371487476
At time: 727.4451036453247 and batch: 550, loss is 3.836545538902283 and perplexity is 46.36503128016214
At time: 728.8202121257782 and batch: 600, loss is 3.789128293991089 and perplexity is 44.217838515630966
At time: 730.1442718505859 and batch: 650, loss is 3.798355903625488 and perplexity is 44.62775181967627
At time: 731.4684374332428 and batch: 700, loss is 3.8281178140640257 and perplexity is 45.97592151253331
At time: 732.7946131229401 and batch: 750, loss is 3.78171594619751 and perplexity is 43.89129225023289
At time: 734.1209444999695 and batch: 800, loss is 3.749185771942139 and perplexity is 42.486474233267074
At time: 735.4467849731445 and batch: 850, loss is 3.7496601009368895 and perplexity is 42.50663158010974
At time: 736.770524263382 and batch: 900, loss is 3.7043542575836184 and perplexity is 40.623806330469165
At time: 738.093544960022 and batch: 950, loss is 3.813756070137024 and perplexity is 45.32034597316811
At time: 739.4192011356354 and batch: 1000, loss is 3.7876038789749145 and perplexity is 44.15048353013413
At time: 740.7445833683014 and batch: 1050, loss is 3.7307478904724123 and perplexity is 41.710291231229746
At time: 742.0698328018188 and batch: 1100, loss is 3.7572720098495482 and perplexity is 42.83142276009041
At time: 743.3957343101501 and batch: 1150, loss is 3.7139753675460816 and perplexity is 41.01653866931819
At time: 744.7208087444305 and batch: 1200, loss is 3.772348518371582 and perplexity is 43.48206344099663
At time: 746.0440127849579 and batch: 1250, loss is 3.7343415594100953 and perplexity is 41.86045386499972
At time: 747.3689441680908 and batch: 1300, loss is 3.7354023933410643 and perplexity is 41.90488441737751
At time: 748.6951711177826 and batch: 1350, loss is 3.592703728675842 and perplexity is 36.33217559428373
At time: 750.016982793808 and batch: 1400, loss is 3.6292131662368776 and perplexity is 37.68315457084501
At time: 751.3383498191833 and batch: 1450, loss is 3.543325972557068 and perplexity is 34.58174606788164
At time: 752.6621506214142 and batch: 1500, loss is 3.5379126596450807 and perplexity is 34.395050033311406
At time: 753.9878787994385 and batch: 1550, loss is 3.5510896968841554 and perplexity is 34.851274128055856
At time: 755.3133463859558 and batch: 1600, loss is 3.625671901702881 and perplexity is 37.54994455719321
At time: 756.6387138366699 and batch: 1650, loss is 3.568106174468994 and perplexity is 35.44939457202082
At time: 757.9623019695282 and batch: 1700, loss is 3.5762977457046508 and perplexity is 35.74097342694426
At time: 759.2828912734985 and batch: 1750, loss is 3.5877699184417726 and perplexity is 36.15336101584164
At time: 760.6110103130341 and batch: 1800, loss is 3.5281331443786623 and perplexity is 34.060322520575724
At time: 761.9323892593384 and batch: 1850, loss is 3.5473957109451293 and perplexity is 34.722771501042196
At time: 763.2513580322266 and batch: 1900, loss is 3.6474246740341187 and perplexity is 38.375708720908676
At time: 764.5748097896576 and batch: 1950, loss is 3.5926031494140624 and perplexity is 36.32852151464901
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351724030250727 and perplexity of 77.6121533491776
finished 14 epochs...
Completing Train Step...
At time: 768.6437902450562 and batch: 50, loss is 3.8418420934677124 and perplexity is 46.61125769846978
At time: 769.9803478717804 and batch: 100, loss is 3.821770749092102 and perplexity is 45.68503347074002
At time: 771.3068063259125 and batch: 150, loss is 3.7951268196105956 and perplexity is 44.483877475841275
At time: 772.627278804779 and batch: 200, loss is 3.8037633895874023 and perplexity is 44.86972941674589
At time: 773.9480171203613 and batch: 250, loss is 3.80514696598053 and perplexity is 44.93185308164083
At time: 775.2702326774597 and batch: 300, loss is 3.792153363227844 and perplexity is 44.35180306249556
At time: 776.5935482978821 and batch: 350, loss is 3.8135864448547365 and perplexity is 45.31265914864737
At time: 777.9155421257019 and batch: 400, loss is 3.79601122379303 and perplexity is 44.523236605255676
At time: 779.2352838516235 and batch: 450, loss is 3.8321228981018067 and perplexity is 46.16042817762046
At time: 780.5540888309479 and batch: 500, loss is 3.8404605865478514 and perplexity is 46.54690838316266
At time: 781.8746938705444 and batch: 550, loss is 3.820781235694885 and perplexity is 45.63984987664101
At time: 783.1983833312988 and batch: 600, loss is 3.774581036567688 and perplexity is 43.57924637980809
At time: 784.524439573288 and batch: 650, loss is 3.7855767107009886 and perplexity is 44.06107372562136
At time: 785.8466420173645 and batch: 700, loss is 3.8174771595001222 and perplexity is 45.489301184267
At time: 787.1691126823425 and batch: 750, loss is 3.7713805294036864 and perplexity is 43.43999364811706
At time: 788.4934556484222 and batch: 800, loss is 3.739946880340576 and perplexity is 42.09575399348977
At time: 789.8192782402039 and batch: 850, loss is 3.7406602048873903 and perplexity is 42.12579264050839
At time: 791.1444189548492 and batch: 900, loss is 3.695878086090088 and perplexity is 40.280927185367226
At time: 792.469731092453 and batch: 950, loss is 3.8056955242156985 and perplexity is 44.95650758126631
At time: 793.8217692375183 and batch: 1000, loss is 3.779816737174988 and perplexity is 43.80801261972636
At time: 795.1453087329865 and batch: 1050, loss is 3.7216404628753663 and perplexity is 41.33214236928049
At time: 796.4719173908234 and batch: 1100, loss is 3.7486771965026855 and perplexity is 42.46487214957328
At time: 797.7985119819641 and batch: 1150, loss is 3.7059632635116575 and perplexity is 40.689222889376865
At time: 799.1237468719482 and batch: 1200, loss is 3.764660038948059 and perplexity is 43.149034375018246
At time: 800.4452016353607 and batch: 1250, loss is 3.7267673683166502 and perplexity is 41.54459249539034
At time: 801.7658004760742 and batch: 1300, loss is 3.7285344982147217 and perplexity is 41.61807209176644
At time: 803.0876471996307 and batch: 1350, loss is 3.5865674448013305 and perplexity is 36.109913679580195
At time: 804.4137420654297 and batch: 1400, loss is 3.625108880996704 and perplexity is 37.528809111296866
At time: 805.7404980659485 and batch: 1450, loss is 3.541111307144165 and perplexity is 34.50524381566196
At time: 807.065146446228 and batch: 1500, loss is 3.5372305059432985 and perplexity is 34.371595323376326
At time: 808.3889451026917 and batch: 1550, loss is 3.5519768476486204 and perplexity is 34.882206181209725
At time: 809.7139301300049 and batch: 1600, loss is 3.6276057052612303 and perplexity is 37.622629029688625
At time: 811.0425674915314 and batch: 1650, loss is 3.571649069786072 and perplexity is 35.57521081132091
At time: 812.368311882019 and batch: 1700, loss is 3.581350965499878 and perplexity is 35.92203751439184
At time: 813.6942825317383 and batch: 1750, loss is 3.5945819139480593 and perplexity is 36.400478273857345
At time: 815.0112040042877 and batch: 1800, loss is 3.5349172449111936 and perplexity is 34.292176744670385
At time: 816.3372962474823 and batch: 1850, loss is 3.5542474937438966 and perplexity is 34.96150131799669
At time: 817.6564066410065 and batch: 1900, loss is 3.6539451265335083 and perplexity is 38.62675327935653
At time: 818.9748287200928 and batch: 1950, loss is 3.5983606719970704 and perplexity is 36.53828708321523
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350099075672238 and perplexity of 77.4861395363356
finished 15 epochs...
Completing Train Step...
At time: 823.1776614189148 and batch: 50, loss is 3.842020564079285 and perplexity is 46.61957718050682
At time: 824.5303246974945 and batch: 100, loss is 3.818937759399414 and perplexity is 45.55579139897546
At time: 825.8553931713104 and batch: 150, loss is 3.7911223411560058 and perplexity is 44.30609893964067
At time: 827.1951413154602 and batch: 200, loss is 3.7988376998901368 and perplexity is 44.649258484301974
At time: 828.5186550617218 and batch: 250, loss is 3.799776511192322 and perplexity is 44.69119539514401
At time: 829.8414528369904 and batch: 300, loss is 3.786416435241699 and perplexity is 44.09808842942137
At time: 831.1683919429779 and batch: 350, loss is 3.8068175888061524 and perplexity is 45.00697999789395
At time: 832.4941396713257 and batch: 400, loss is 3.787111086845398 and perplexity is 44.12873187929748
At time: 833.8192224502563 and batch: 450, loss is 3.819429802894592 and perplexity is 45.578212345389076
At time: 835.1438105106354 and batch: 500, loss is 3.8325188636779783 and perplexity is 46.17870973735544
At time: 836.4675121307373 and batch: 550, loss is 3.8131024265289306 and perplexity is 45.290732298155234
At time: 837.7918083667755 and batch: 600, loss is 3.767960557937622 and perplexity is 43.29168386152872
At time: 839.116986989975 and batch: 650, loss is 3.77966468334198 and perplexity is 43.801351949894084
At time: 840.4423851966858 and batch: 700, loss is 3.812289614677429 and perplexity is 45.253934411085396
At time: 841.7719943523407 and batch: 750, loss is 3.7665882110595703 and perplexity is 43.232313402085964
At time: 843.0964403152466 and batch: 800, loss is 3.7356292247772216 and perplexity is 41.91439084062897
At time: 844.4206557273865 and batch: 850, loss is 3.7360558128356933 and perplexity is 41.9322748335174
At time: 845.7442564964294 and batch: 900, loss is 3.691235032081604 and perplexity is 40.09433418084599
At time: 847.0695314407349 and batch: 950, loss is 3.80091166973114 and perplexity is 44.74195579230518
At time: 848.397248506546 and batch: 1000, loss is 3.7750622844696045 and perplexity is 43.60022384797188
At time: 849.7183105945587 and batch: 1050, loss is 3.7167928075790404 and perplexity is 41.132263254366386
At time: 851.0355463027954 and batch: 1100, loss is 3.7442378902435305 and perplexity is 42.27677539530344
At time: 852.3553597927094 and batch: 1150, loss is 3.7018533325195313 and perplexity is 40.52233617253744
At time: 853.6719787120819 and batch: 1200, loss is 3.760891470909119 and perplexity is 42.98673032218269
At time: 854.9894456863403 and batch: 1250, loss is 3.7233374452590944 and perplexity is 41.402341833543595
At time: 856.306806564331 and batch: 1300, loss is 3.7254487037658692 and perplexity is 41.48984521856985
At time: 857.6241059303284 and batch: 1350, loss is 3.5839800596237184 and perplexity is 36.01660419001143
At time: 858.9431276321411 and batch: 1400, loss is 3.6234981298446653 and perplexity is 37.46840819726641
At time: 860.2625765800476 and batch: 1450, loss is 3.5404048776626587 and perplexity is 34.48087690193047
At time: 861.5809013843536 and batch: 1500, loss is 3.5371678829193116 and perplexity is 34.36944293753308
At time: 862.8985238075256 and batch: 1550, loss is 3.552574381828308 and perplexity is 34.903055720201635
At time: 864.2153811454773 and batch: 1600, loss is 3.628601760864258 and perplexity is 37.660121929540956
At time: 865.5327820777893 and batch: 1650, loss is 3.573324007987976 and perplexity is 35.634847020490014
At time: 866.8516509532928 and batch: 1700, loss is 3.583397889137268 and perplexity is 35.99564248826392
At time: 868.1715033054352 and batch: 1750, loss is 3.5972793197631834 and perplexity is 36.49879767968074
At time: 869.490975856781 and batch: 1800, loss is 3.537589988708496 and perplexity is 34.3839535406574
At time: 870.8133766651154 and batch: 1850, loss is 3.5569150829315186 and perplexity is 35.0548887451621
At time: 872.1369948387146 and batch: 1900, loss is 3.6562499237060546 and perplexity is 38.71588278435967
At time: 873.4646391868591 and batch: 1950, loss is 3.6001991176605226 and perplexity is 36.60552252406835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349439612100291 and perplexity of 77.43505709533632
finished 16 epochs...
Completing Train Step...
At time: 877.6600539684296 and batch: 50, loss is 3.8405365467071535 and perplexity is 46.55044422802843
At time: 879.0368065834045 and batch: 100, loss is 3.816110806465149 and perplexity is 45.4271891826592
At time: 880.3636562824249 and batch: 150, loss is 3.787761564254761 and perplexity is 44.15744596040689
At time: 881.6901230812073 and batch: 200, loss is 3.7950347089767456 and perplexity is 44.479780226393885
At time: 883.0162165164948 and batch: 250, loss is 3.795663194656372 and perplexity is 44.507743917768444
At time: 884.340000629425 and batch: 300, loss is 3.782071409225464 and perplexity is 43.90689675512495
At time: 885.6640455722809 and batch: 350, loss is 3.8020260524749756 and perplexity is 44.79184324746243
At time: 886.9892485141754 and batch: 400, loss is 3.781544804573059 and perplexity is 43.88378126591731
At time: 888.3154759407043 and batch: 450, loss is 3.813710346221924 and perplexity is 45.3182737968909
At time: 889.6385695934296 and batch: 500, loss is 3.82776225566864 and perplexity is 45.95957729348827
At time: 890.9662880897522 and batch: 550, loss is 3.8082555103302003 and perplexity is 45.07174305410278
At time: 892.2900297641754 and batch: 600, loss is 3.76383807182312 and perplexity is 43.113581859686235
At time: 893.7528612613678 and batch: 650, loss is 3.7758669424057008 and perplexity is 43.635321232907664
At time: 895.0799915790558 and batch: 700, loss is 3.80881817817688 and perplexity is 45.09711061079811
At time: 896.4083213806152 and batch: 750, loss is 3.763392424583435 and perplexity is 43.09437269151183
At time: 897.7348730564117 and batch: 800, loss is 3.7326286458969116 and perplexity is 41.78881190366509
At time: 899.0573904514313 and batch: 850, loss is 3.7328282690048216 and perplexity is 41.79715474885781
At time: 900.3811628818512 and batch: 900, loss is 3.6880161428451537 and perplexity is 39.96548245108701
At time: 901.7068150043488 and batch: 950, loss is 3.7975778675079344 and perplexity is 44.59304332089903
At time: 903.0330884456635 and batch: 1000, loss is 3.771781311035156 and perplexity is 43.457407088902904
At time: 904.3551061153412 and batch: 1050, loss is 3.713584008216858 and perplexity is 41.00048960493786
At time: 905.6705288887024 and batch: 1100, loss is 3.7412866878509523 and perplexity is 42.1521920004354
At time: 906.9860835075378 and batch: 1150, loss is 3.6990595293045043 and perplexity is 40.40928273751832
At time: 908.3048832416534 and batch: 1200, loss is 3.758413829803467 and perplexity is 42.88035646467631
At time: 909.6257953643799 and batch: 1250, loss is 3.7211002254486085 and perplexity is 41.30981922948525
At time: 910.9458959102631 and batch: 1300, loss is 3.723383846282959 and perplexity is 41.40426298916651
At time: 912.2662172317505 and batch: 1350, loss is 3.5822364044189454 and perplexity is 35.953858370092355
At time: 913.5827362537384 and batch: 1400, loss is 3.6222733449935913 and perplexity is 37.422545550183436
At time: 914.9054329395294 and batch: 1450, loss is 3.5396426248550417 and perplexity is 34.45460377135878
At time: 916.231219291687 and batch: 1500, loss is 3.5367940711975097 and perplexity is 34.35659763790259
At time: 917.5499856472015 and batch: 1550, loss is 3.5525577688217163 and perplexity is 34.902475880323344
At time: 918.8691415786743 and batch: 1600, loss is 3.6287801265716553 and perplexity is 37.666839802930895
At time: 920.1838488578796 and batch: 1650, loss is 3.5738692235946656 and perplexity is 35.65428099259862
At time: 921.5148890018463 and batch: 1700, loss is 3.584050331115723 and perplexity is 36.01913521945336
At time: 922.8428297042847 and batch: 1750, loss is 3.598176121711731 and perplexity is 36.531544554095184
At time: 924.1688184738159 and batch: 1800, loss is 3.538520722389221 and perplexity is 34.41597074172659
At time: 925.4968347549438 and batch: 1850, loss is 3.557901701927185 and perplexity is 35.089491631414575
At time: 926.8202936649323 and batch: 1900, loss is 3.656978631019592 and perplexity is 38.744105613136675
At time: 928.1432771682739 and batch: 1950, loss is 3.6006194448471067 and perplexity is 36.62091205445676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349148630541424 and perplexity of 77.41252819961734
finished 17 epochs...
Completing Train Step...
At time: 932.2279171943665 and batch: 50, loss is 3.838548631668091 and perplexity is 46.457997818120965
At time: 933.5512862205505 and batch: 100, loss is 3.8134267807006834 and perplexity is 45.30542491879547
At time: 934.8782761096954 and batch: 150, loss is 3.78476722240448 and perplexity is 44.025421234193
At time: 936.204264163971 and batch: 200, loss is 3.7918126344680787 and perplexity is 44.33669370188775
At time: 937.5297088623047 and batch: 250, loss is 3.7922624921798707 and perplexity is 44.35664339238952
At time: 938.8548910617828 and batch: 300, loss is 3.778516960144043 and perplexity is 43.7511089601979
At time: 940.1794984340668 and batch: 350, loss is 3.798247742652893 and perplexity is 44.62292509967079
At time: 941.5027437210083 and batch: 400, loss is 3.777473559379578 and perplexity is 43.70548282697314
At time: 942.8268022537231 and batch: 450, loss is 3.8097621536254884 and perplexity is 45.139701275125944
At time: 944.1594398021698 and batch: 500, loss is 3.824168677330017 and perplexity is 45.794714353436525
At time: 945.4875798225403 and batch: 550, loss is 3.8046273946762086 and perplexity is 44.90851384385378
At time: 946.8131501674652 and batch: 600, loss is 3.7607105493545534 and perplexity is 42.97895379959861
At time: 948.1359043121338 and batch: 650, loss is 3.7729041385650635 and perplexity is 43.50622966649843
At time: 949.460396528244 and batch: 700, loss is 3.8060350227355957 and perplexity is 44.97177284016968
At time: 950.7890341281891 and batch: 750, loss is 3.7607988500595093 and perplexity is 42.982749039076076
At time: 952.1140139102936 and batch: 800, loss is 3.730146536827087 and perplexity is 41.685216135805945
At time: 953.4420356750488 and batch: 850, loss is 3.7301966381072997 and perplexity is 41.68730467081899
At time: 954.764285326004 and batch: 900, loss is 3.685383901596069 and perplexity is 39.860421992537
At time: 956.0853357315063 and batch: 950, loss is 3.794890809059143 and perplexity is 44.473380050187785
At time: 957.41059923172 and batch: 1000, loss is 3.7691529512405397 and perplexity is 43.34333536377007
At time: 958.7710433006287 and batch: 1050, loss is 3.7110637187957765 and perplexity is 40.89728661006304
At time: 960.0951015949249 and batch: 1100, loss is 3.7389397382736207 and perplexity is 42.053378931238484
At time: 961.4190423488617 and batch: 1150, loss is 3.6967923831939697 and perplexity is 40.31777276176966
At time: 962.7482259273529 and batch: 1200, loss is 3.7564123010635377 and perplexity is 42.79461603342637
At time: 964.0743451118469 and batch: 1250, loss is 3.719284915924072 and perplexity is 41.23489714514228
At time: 965.4022197723389 and batch: 1300, loss is 3.721676092147827 and perplexity is 41.333615029677105
At time: 966.7282938957214 and batch: 1350, loss is 3.580760474205017 and perplexity is 35.90083212536091
At time: 968.0528118610382 and batch: 1400, loss is 3.6211160612106323 and perplexity is 37.37926209555204
At time: 969.3821315765381 and batch: 1450, loss is 3.5387683868408204 and perplexity is 34.42449540983165
At time: 970.7053525447845 and batch: 1500, loss is 3.536200747489929 and perplexity is 34.33621910014483
At time: 972.0318570137024 and batch: 1550, loss is 3.5521973323822023 and perplexity is 34.889898023082026
At time: 973.3567273616791 and batch: 1600, loss is 3.6285390424728394 and perplexity is 37.657760021341225
At time: 974.681010723114 and batch: 1650, loss is 3.5738837575912474 and perplexity is 35.65479919556246
At time: 975.9999766349792 and batch: 1700, loss is 3.584090847969055 and perplexity is 36.02059463103739
At time: 977.3261029720306 and batch: 1750, loss is 3.5982993268966674 and perplexity is 36.53604570707498
At time: 978.6523652076721 and batch: 1800, loss is 3.538707427978516 and perplexity is 34.422396995715175
At time: 979.9787471294403 and batch: 1850, loss is 3.558165693283081 and perplexity is 35.09875617671418
At time: 981.3091585636139 and batch: 1900, loss is 3.6570656633377077 and perplexity is 38.74747774920177
At time: 982.6342527866364 and batch: 1950, loss is 3.6004777812957762 and perplexity is 36.61572457344933
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349045296602471 and perplexity of 77.40452927144165
finished 18 epochs...
Completing Train Step...
At time: 986.718269109726 and batch: 50, loss is 3.8364530038833617 and perplexity is 46.36074108961484
At time: 988.047171831131 and batch: 100, loss is 3.8109071588516237 and perplexity is 45.19141607019746
At time: 989.3715670108795 and batch: 150, loss is 3.7820279598236084 and perplexity is 43.904989068167836
At time: 990.6945207118988 and batch: 200, loss is 3.788942589759827 and perplexity is 44.2096278383237
At time: 992.0306494235992 and batch: 250, loss is 3.7892961263656617 and perplexity is 44.22526032325989
At time: 993.357747554779 and batch: 300, loss is 3.7754316091537476 and perplexity is 43.61632946079022
At time: 994.6828224658966 and batch: 350, loss is 3.7950428104400635 and perplexity is 44.48014057916147
At time: 996.0041284561157 and batch: 400, loss is 3.7741603660583496 and perplexity is 43.56091773146812
At time: 997.3204469680786 and batch: 450, loss is 3.806571226119995 and perplexity is 44.9958933231334
At time: 998.6380867958069 and batch: 500, loss is 3.8211690950393677 and perplexity is 45.65755515225278
At time: 999.9571802616119 and batch: 550, loss is 3.801607494354248 and perplexity is 44.773099180743166
At time: 1001.2741992473602 and batch: 600, loss is 3.758049964904785 and perplexity is 42.86475664640112
At time: 1002.5932085514069 and batch: 650, loss is 3.7703380823135375 and perplexity is 43.39473334797527
At time: 1003.9091391563416 and batch: 700, loss is 3.8035886096954346 and perplexity is 44.86188777558637
At time: 1005.2261037826538 and batch: 750, loss is 3.758495879173279 and perplexity is 42.88387491524291
At time: 1006.5440804958344 and batch: 800, loss is 3.727922434806824 and perplexity is 41.59260698665631
At time: 1007.8630201816559 and batch: 850, loss is 3.7278719043731687 and perplexity is 41.59050534728725
At time: 1009.1820075511932 and batch: 900, loss is 3.683055968284607 and perplexity is 39.767737511873506
At time: 1010.4955470561981 and batch: 950, loss is 3.792545156478882 and perplexity is 44.36918320409558
At time: 1011.8151369094849 and batch: 1000, loss is 3.7668616199493408 and perplexity is 43.24413511690276
At time: 1013.1326537132263 and batch: 1050, loss is 3.708885040283203 and perplexity is 40.80828156240181
At time: 1014.4520099163055 and batch: 1100, loss is 3.7368844747543335 and perplexity is 41.96703691385078
At time: 1015.7726924419403 and batch: 1150, loss is 3.6947912836074828 and perplexity is 40.23717355378484
At time: 1017.1007952690125 and batch: 1200, loss is 3.7546349143981934 and perplexity is 42.71862100981717
At time: 1018.4202680587769 and batch: 1250, loss is 3.7176604318618773 and perplexity is 41.167966090858194
At time: 1019.75177526474 and batch: 1300, loss is 3.7201310205459595 and perplexity is 41.269800946251266
At time: 1021.0729990005493 and batch: 1350, loss is 3.579403305053711 and perplexity is 35.852141671558684
At time: 1022.4095056056976 and batch: 1400, loss is 3.619979214668274 and perplexity is 37.336791756386056
At time: 1023.7580525875092 and batch: 1450, loss is 3.537832350730896 and perplexity is 34.39228791510275
At time: 1025.089765548706 and batch: 1500, loss is 3.535487508773804 and perplexity is 34.31173791082109
At time: 1026.408537864685 and batch: 1550, loss is 3.551655583381653 and perplexity is 34.871001574726925
At time: 1027.7265124320984 and batch: 1600, loss is 3.628084921836853 and perplexity is 37.640662737818964
At time: 1029.0452938079834 and batch: 1650, loss is 3.5736352252960204 and perplexity is 35.64593892755951
At time: 1030.3642416000366 and batch: 1700, loss is 3.583837628364563 and perplexity is 36.01147466503716
At time: 1031.6805670261383 and batch: 1750, loss is 3.598064351081848 and perplexity is 36.5274616285296
At time: 1032.99622964859 and batch: 1800, loss is 3.53854745388031 and perplexity is 34.41689074423826
At time: 1034.3147838115692 and batch: 1850, loss is 3.5580872821807863 and perplexity is 35.09600415244923
At time: 1035.6341121196747 and batch: 1900, loss is 3.6568627882003786 and perplexity is 38.7396176466689
At time: 1036.9512491226196 and batch: 1950, loss is 3.6000910902023318 and perplexity is 36.60156833609861
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3490515420603195 and perplexity of 77.40501269967612
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 1040.9785947799683 and batch: 50, loss is 3.8357437658309936 and perplexity is 46.32787194529987
At time: 1042.2986538410187 and batch: 100, loss is 3.812074022293091 and perplexity is 45.2441790590926
At time: 1043.6203660964966 and batch: 150, loss is 3.784549217224121 and perplexity is 44.01582451040221
At time: 1044.9376327991486 and batch: 200, loss is 3.79254433631897 and perplexity is 44.36914681428511
At time: 1046.2547438144684 and batch: 250, loss is 3.794185972213745 and perplexity is 44.44204461776998
At time: 1047.5702865123749 and batch: 300, loss is 3.780160388946533 and perplexity is 43.823069907954704
At time: 1048.8876502513885 and batch: 350, loss is 3.800955238342285 and perplexity is 44.743905179644706
At time: 1050.2070899009705 and batch: 400, loss is 3.7830260515213014 and perplexity is 43.94883214931206
At time: 1051.5245215892792 and batch: 450, loss is 3.8185400676727297 and perplexity is 45.5376778396786
At time: 1052.8421850204468 and batch: 500, loss is 3.8309104585647584 and perplexity is 46.10449536388005
At time: 1054.163084745407 and batch: 550, loss is 3.8124001359939577 and perplexity is 45.25893621189231
At time: 1055.4819707870483 and batch: 600, loss is 3.7688964128494264 and perplexity is 43.33221756038304
At time: 1056.8019669055939 and batch: 650, loss is 3.7785099172592163 and perplexity is 43.750800827261514
At time: 1058.1533336639404 and batch: 700, loss is 3.8101046657562256 and perplexity is 45.15516481846495
At time: 1059.4784111976624 and batch: 750, loss is 3.7648601770401 and perplexity is 43.15767100466193
At time: 1060.798734664917 and batch: 800, loss is 3.7321203327178956 and perplexity is 41.76757549766882
At time: 1062.1142301559448 and batch: 850, loss is 3.7328554153442384 and perplexity is 41.798289404008074
At time: 1063.433488368988 and batch: 900, loss is 3.685552191734314 and perplexity is 39.86713067295116
At time: 1064.7592465877533 and batch: 950, loss is 3.7954691314697264 and perplexity is 44.49910744119154
At time: 1066.0799913406372 and batch: 1000, loss is 3.7722591495513917 and perplexity is 43.47817767392327
At time: 1067.3968827724457 and batch: 1050, loss is 3.7165326261520386 and perplexity is 41.12156279550774
At time: 1068.7165696620941 and batch: 1100, loss is 3.744470000267029 and perplexity is 42.28658939755396
At time: 1070.0372204780579 and batch: 1150, loss is 3.7011095905303955 and perplexity is 40.49220921435868
At time: 1071.3596403598785 and batch: 1200, loss is 3.7602926778793333 and perplexity is 42.96099787266707
At time: 1072.6796281337738 and batch: 1250, loss is 3.721378879547119 and perplexity is 41.32133198388589
At time: 1073.9975564479828 and batch: 1300, loss is 3.7219786500930785 and perplexity is 41.34612273536775
At time: 1075.3154666423798 and batch: 1350, loss is 3.5789266300201414 and perplexity is 35.83505592322221
At time: 1076.6365370750427 and batch: 1400, loss is 3.6182298946380613 and perplexity is 37.27153485294804
At time: 1077.9629843235016 and batch: 1450, loss is 3.5328096914291383 and perplexity is 34.21998025387111
At time: 1079.283792257309 and batch: 1500, loss is 3.5297799110412598 and perplexity is 34.11645813266131
At time: 1080.6032650470734 and batch: 1550, loss is 3.5465323686599732 and perplexity is 34.69280680090508
At time: 1081.9264397621155 and batch: 1600, loss is 3.623007769584656 and perplexity is 37.45003968284348
At time: 1083.2508742809296 and batch: 1650, loss is 3.5687776899337766 and perplexity is 35.47320738313374
At time: 1084.5791821479797 and batch: 1700, loss is 3.577464208602905 and perplexity is 35.78268827107338
At time: 1085.9040727615356 and batch: 1750, loss is 3.5911143684387206 and perplexity is 36.27447654350055
At time: 1087.229782819748 and batch: 1800, loss is 3.531657462120056 and perplexity is 34.180573696721225
At time: 1088.552992105484 and batch: 1850, loss is 3.5508281135559083 and perplexity is 34.84215880803564
At time: 1089.8766083717346 and batch: 1900, loss is 3.649324026107788 and perplexity is 38.44866696761154
At time: 1091.2012102603912 and batch: 1950, loss is 3.5952785444259643 and perplexity is 36.42584479095185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348068734102471 and perplexity of 77.32897580816895
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
5579.521661281586


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.71282622170062}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.8965078080331692, 'wordvec_dim': 300, 'dropout': 0.6142191105838335, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.89294035452974}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3068549984979113, 'wordvec_dim': 300, 'dropout': 0.6482131084882298, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.32897580816895}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'rnn_dropout': 0.3094886478122048, 'wordvec_dim': 300, 'dropout': 0.6498577281799143, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9564709663391113 and batch: 50, loss is 7.654066791534424 and perplexity is 2109.2058717638815
At time: 3.479473829269409 and batch: 100, loss is 6.720024309158325 and perplexity is 828.8376595824698
At time: 5.00968861579895 and batch: 150, loss is 6.482466239929199 and perplexity is 653.580847436815
At time: 6.578061819076538 and batch: 200, loss is 6.320854063034058 and perplexity is 556.0476894887178
At time: 8.099708795547485 and batch: 250, loss is 6.236723279953003 and perplexity is 511.1807674278
At time: 9.624431610107422 and batch: 300, loss is 6.166854162216186 and perplexity is 476.684173825293
At time: 11.150457859039307 and batch: 350, loss is 6.110297889709472 and perplexity is 450.4728864197718
At time: 12.678096771240234 and batch: 400, loss is 6.06787257194519 and perplexity is 431.76116300532885
At time: 14.203693628311157 and batch: 450, loss is 5.985284471511841 and perplexity is 397.5355927168544
At time: 15.789509534835815 and batch: 500, loss is 5.963613662719727 and perplexity is 389.01335035948296
At time: 17.315169095993042 and batch: 550, loss is 5.911044645309448 and perplexity is 369.09152381677404
At time: 18.86018705368042 and batch: 600, loss is 5.953251066207886 and perplexity is 385.00297680074743
At time: 20.409548044204712 and batch: 650, loss is 6.029811115264892 and perplexity is 415.63651457413863
At time: 21.947163105010986 and batch: 700, loss is 5.926803503036499 and perplexity is 374.9540567143937
At time: 23.484822273254395 and batch: 750, loss is 5.870728893280029 and perplexity is 354.5072840954658
At time: 25.024665594100952 and batch: 800, loss is 5.875187244415283 and perplexity is 356.0913305417785
At time: 26.564162969589233 and batch: 850, loss is 5.899940891265869 and perplexity is 365.015891600372
At time: 28.103435516357422 and batch: 900, loss is 5.8920192527771 and perplexity is 362.1357902862485
At time: 29.64409828186035 and batch: 950, loss is 5.918017835617065 and perplexity is 371.674263756282
At time: 31.184422969818115 and batch: 1000, loss is 5.888407592773437 and perplexity is 360.83023796127895
At time: 32.723350286483765 and batch: 1050, loss is 5.787196369171142 and perplexity is 326.0974845968723
At time: 34.26410365104675 and batch: 1100, loss is 5.865147171020507 and perplexity is 352.53403508378113
At time: 35.804657220840454 and batch: 1150, loss is 5.77919075012207 and perplexity is 323.4972943159056
At time: 37.34572720527649 and batch: 1200, loss is 5.855957260131836 and perplexity is 349.3091197548943
At time: 38.885074615478516 and batch: 1250, loss is 5.78092095375061 and perplexity is 324.05749499922973
At time: 40.4248526096344 and batch: 1300, loss is 5.803880052566528 and perplexity is 331.58362908179197
At time: 41.96613550186157 and batch: 1350, loss is 5.783621435165405 and perplexity is 324.93378891698126
At time: 43.50442028045654 and batch: 1400, loss is 5.804204940795898 and perplexity is 331.6913742015453
At time: 45.04619264602661 and batch: 1450, loss is 5.775669393539428 and perplexity is 322.36014831242795
At time: 46.584999084472656 and batch: 1500, loss is 5.753565435409546 and perplexity is 315.31288621441536
At time: 48.12496781349182 and batch: 1550, loss is 5.735671300888061 and perplexity is 309.72081684717057
At time: 49.664162158966064 and batch: 1600, loss is 5.7457380294799805 and perplexity is 312.8544384455741
At time: 51.208924531936646 and batch: 1650, loss is 5.724099264144898 and perplexity is 306.1573740853456
At time: 52.75055694580078 and batch: 1700, loss is 5.7362060546875 and perplexity is 309.88648552277385
At time: 54.29140114784241 and batch: 1750, loss is 5.7476847457885745 and perplexity is 313.4640704808977
At time: 55.8318727016449 and batch: 1800, loss is 5.749782257080078 and perplexity is 314.12225494157127
At time: 57.373111724853516 and batch: 1850, loss is 5.7131329536437985 and perplexity is 302.8182993869063
At time: 58.91431021690369 and batch: 1900, loss is 5.689201412200927 and perplexity is 295.6574179320706
At time: 60.45474147796631 and batch: 1950, loss is 5.62774827003479 and perplexity is 278.03535171122394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.163737168422965 and perplexity of 174.8165552531493
finished 1 epochs...
Completing Train Step...
At time: 64.66726469993591 and batch: 50, loss is 5.4308748531341555 and perplexity is 228.3489298409514
At time: 65.98515295982361 and batch: 100, loss is 5.360128555297852 and perplexity is 212.75229512626905
At time: 67.30828952789307 and batch: 150, loss is 5.263867788314819 and perplexity is 193.2274105591073
At time: 68.63071346282959 and batch: 200, loss is 5.233213481903076 and perplexity is 187.39402430258323
At time: 70.00200963020325 and batch: 250, loss is 5.219411849975586 and perplexity is 184.82544700579547
At time: 71.32678627967834 and batch: 300, loss is 5.207566032409668 and perplexity is 182.64895509309278
At time: 72.65190887451172 and batch: 350, loss is 5.175143013000488 and perplexity is 176.821900298788
At time: 73.97620892524719 and batch: 400, loss is 5.130195150375366 and perplexity is 169.0501050175223
At time: 75.29580879211426 and batch: 450, loss is 5.08192135810852 and perplexity is 161.08325741287373
At time: 76.6153666973114 and batch: 500, loss is 5.063895654678345 and perplexity is 158.20563191659167
At time: 77.93688416481018 and batch: 550, loss is 5.003884954452515 and perplexity is 148.99085890796394
At time: 79.25981020927429 and batch: 600, loss is 5.003390522003174 and perplexity is 148.91721120107306
At time: 80.5816912651062 and batch: 650, loss is 5.074419841766358 and perplexity is 159.8794097118565
At time: 81.90222835540771 and batch: 700, loss is 5.044328517913819 and perplexity is 155.14009042354493
At time: 83.22327470779419 and batch: 750, loss is 5.0009842872619625 and perplexity is 148.5593122011058
At time: 84.54628944396973 and batch: 800, loss is 4.972440376281738 and perplexity is 144.3787963913579
At time: 85.8657054901123 and batch: 850, loss is 4.969371614456176 and perplexity is 143.93641138685118
At time: 87.18431615829468 and batch: 900, loss is 4.971057071685791 and perplexity is 144.17921461177437
At time: 88.5019474029541 and batch: 950, loss is 5.031601190567017 and perplexity is 153.1780837432936
At time: 89.82013130187988 and batch: 1000, loss is 4.990643310546875 and perplexity is 147.03097965787686
At time: 91.14150404930115 and batch: 1050, loss is 4.894627618789673 and perplexity is 133.57025829800372
At time: 92.46512055397034 and batch: 1100, loss is 4.9829897212982175 and perplexity is 145.9099603157372
At time: 93.7856183052063 and batch: 1150, loss is 4.89487624168396 and perplexity is 133.60347105076676
At time: 95.10633945465088 and batch: 1200, loss is 4.967597274780274 and perplexity is 143.6812457435273
At time: 96.42461013793945 and batch: 1250, loss is 4.907891597747803 and perplexity is 135.3537332328863
At time: 97.75968050956726 and batch: 1300, loss is 4.939296360015869 and perplexity is 139.67193621647667
At time: 99.07905602455139 and batch: 1350, loss is 4.8485182189941405 and perplexity is 127.55124673161914
At time: 100.3975043296814 and batch: 1400, loss is 4.863131713867188 and perplexity is 129.4289023622583
At time: 101.7148187160492 and batch: 1450, loss is 4.815684719085693 and perplexity is 123.4312991483011
At time: 103.03075814247131 and batch: 1500, loss is 4.784184551239013 and perplexity is 119.60379254293876
At time: 104.3534996509552 and batch: 1550, loss is 4.774543886184692 and perplexity is 118.45627275452611
At time: 105.67394542694092 and batch: 1600, loss is 4.8443567752838135 and perplexity is 127.02155230934453
At time: 106.99562954902649 and batch: 1650, loss is 4.795133123397827 and perplexity is 120.920478056541
At time: 108.31915426254272 and batch: 1700, loss is 4.8262613582611085 and perplexity is 124.74371570606897
At time: 109.63578486442566 and batch: 1750, loss is 4.8396718883514405 and perplexity is 126.42786246955342
At time: 110.95320773124695 and batch: 1800, loss is 4.794743490219116 and perplexity is 120.87337260382421
At time: 112.28818416595459 and batch: 1850, loss is 4.798797073364258 and perplexity is 121.36433728050149
At time: 113.62904906272888 and batch: 1900, loss is 4.856875925064087 and perplexity is 128.6217498043474
At time: 114.95248055458069 and batch: 1950, loss is 4.775992708206177 and perplexity is 118.62801919604661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.63315798737282 and perplexity of 102.83831394946392
finished 2 epochs...
Completing Train Step...
At time: 119.10620880126953 and batch: 50, loss is 4.72832573890686 and perplexity is 113.10603470025086
At time: 120.45183515548706 and batch: 100, loss is 4.666333866119385 and perplexity is 106.3072903859959
At time: 121.76968812942505 and batch: 150, loss is 4.605680112838745 and perplexity is 100.05100568854519
At time: 123.08807063102722 and batch: 200, loss is 4.607635097503662 and perplexity is 100.24679519075464
At time: 124.40303111076355 and batch: 250, loss is 4.610197048187256 and perplexity is 100.50395180685003
At time: 125.72795510292053 and batch: 300, loss is 4.6217512607574465 and perplexity is 101.67193037276863
At time: 127.0479211807251 and batch: 350, loss is 4.641011400222778 and perplexity is 103.64912533668408
At time: 128.365825176239 and batch: 400, loss is 4.59621639251709 and perplexity is 99.10861723668576
At time: 129.68350744247437 and batch: 450, loss is 4.592001581192017 and perplexity is 98.6917721930411
At time: 130.9983787536621 and batch: 500, loss is 4.598202352523804 and perplexity is 99.30563856031816
At time: 132.31678295135498 and batch: 550, loss is 4.55049695968628 and perplexity is 94.67944849444045
At time: 133.63573384284973 and batch: 600, loss is 4.526690273284912 and perplexity is 92.45206308653619
At time: 134.9595263004303 and batch: 650, loss is 4.593745441436767 and perplexity is 98.86402700155584
At time: 136.34579920768738 and batch: 700, loss is 4.612248134613037 and perplexity is 100.71030565057885
At time: 137.662104845047 and batch: 750, loss is 4.571522903442383 and perplexity is 96.69124914104712
At time: 138.98119473457336 and batch: 800, loss is 4.547047986984253 and perplexity is 94.35346413985343
At time: 140.30074381828308 and batch: 850, loss is 4.5422935962677 and perplexity is 93.90593561161522
At time: 141.62113308906555 and batch: 900, loss is 4.537622566223145 and perplexity is 93.46832101614797
At time: 142.9430274963379 and batch: 950, loss is 4.611663208007813 and perplexity is 100.65141473849324
At time: 144.2657539844513 and batch: 1000, loss is 4.585761632919311 and perplexity is 98.07785802792634
At time: 145.58644843101501 and batch: 1050, loss is 4.512083606719971 and perplexity is 91.11146132448096
At time: 146.9094307422638 and batch: 1100, loss is 4.574958076477051 and perplexity is 97.02397146497405
At time: 148.23380780220032 and batch: 1150, loss is 4.506639318466187 and perplexity is 90.61677210305879
At time: 149.561181306839 and batch: 1200, loss is 4.585551233291626 and perplexity is 98.05722465381629
At time: 150.88759016990662 and batch: 1250, loss is 4.546169490814209 and perplexity is 94.27061138122026
At time: 152.20092582702637 and batch: 1300, loss is 4.570840635299683 and perplexity is 96.62530228135917
At time: 153.52528357505798 and batch: 1350, loss is 4.451017169952393 and perplexity is 85.71408546808189
At time: 154.84690141677856 and batch: 1400, loss is 4.476962308883667 and perplexity is 87.96704967810562
At time: 156.16739082336426 and batch: 1450, loss is 4.425666837692261 and perplexity is 83.56851528173605
At time: 157.48474383354187 and batch: 1500, loss is 4.409754753112793 and perplexity is 82.24928964825388
At time: 158.80053544044495 and batch: 1550, loss is 4.402295827865601 and perplexity is 81.63808065995381
At time: 160.12046599388123 and batch: 1600, loss is 4.493356866836548 and perplexity is 89.42111740204791
At time: 161.44031405448914 and batch: 1650, loss is 4.4421448898315425 and perplexity is 84.95696972947081
At time: 162.7599959373474 and batch: 1700, loss is 4.474423274993897 and perplexity is 87.74398166624827
At time: 164.0775043964386 and batch: 1750, loss is 4.484961137771607 and perplexity is 88.67350469600723
At time: 165.3935055732727 and batch: 1800, loss is 4.434122362136841 and perplexity is 84.27812674618615
At time: 166.71005773544312 and batch: 1850, loss is 4.461906986236572 and perplexity is 86.65259694591019
At time: 168.0384407043457 and batch: 1900, loss is 4.535829954147339 and perplexity is 93.30091866375668
At time: 169.36190271377563 and batch: 1950, loss is 4.467464570999145 and perplexity is 87.13551678933116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509988758175872 and perplexity of 90.92079638918175
finished 3 epochs...
Completing Train Step...
At time: 173.38773894309998 and batch: 50, loss is 4.428301801681519 and perplexity is 83.78900567468918
At time: 174.8224995136261 and batch: 100, loss is 4.366412153244019 and perplexity is 78.76054340437548
At time: 176.14705753326416 and batch: 150, loss is 4.3222257518768314 and perplexity is 75.35616590197063
At time: 177.464453458786 and batch: 200, loss is 4.327332334518433 and perplexity is 75.74196260369936
At time: 178.78722643852234 and batch: 250, loss is 4.324101467132568 and perplexity is 75.49764525797933
At time: 180.10183477401733 and batch: 300, loss is 4.340720205307007 and perplexity is 76.76280441392606
At time: 181.4162929058075 and batch: 350, loss is 4.358660545349121 and perplexity is 78.15238271116225
At time: 182.73874139785767 and batch: 400, loss is 4.318081178665161 and perplexity is 75.04449307700591
At time: 184.0569863319397 and batch: 450, loss is 4.336696062088013 and perplexity is 76.45452060020396
At time: 185.37505674362183 and batch: 500, loss is 4.350070428848267 and perplexity is 77.48391983632989
At time: 186.69054555892944 and batch: 550, loss is 4.302691755294799 and perplexity is 73.89844274688133
At time: 188.01123523712158 and batch: 600, loss is 4.283342752456665 and perplexity is 72.48232597284718
At time: 189.3276014328003 and batch: 650, loss is 4.339935894012451 and perplexity is 76.70262208334832
At time: 190.644376039505 and batch: 700, loss is 4.3715439128875735 and perplexity is 79.16576243657552
At time: 191.9619698524475 and batch: 750, loss is 4.332366094589234 and perplexity is 76.12419068586911
At time: 193.28270387649536 and batch: 800, loss is 4.305453214645386 and perplexity is 74.10279231425199
At time: 194.5990138053894 and batch: 850, loss is 4.298057126998901 and perplexity is 73.55674336954067
At time: 195.9143340587616 and batch: 900, loss is 4.289932947158814 and perplexity is 72.96157605463658
At time: 197.23167300224304 and batch: 950, loss is 4.376345796585083 and perplexity is 79.54682138879859
At time: 198.54971075057983 and batch: 1000, loss is 4.348908224105835 and perplexity is 77.39391996650205
At time: 199.86782360076904 and batch: 1050, loss is 4.284367914199829 and perplexity is 72.55667018139826
At time: 201.18380069732666 and batch: 1100, loss is 4.333495321273804 and perplexity is 76.21020070659853
At time: 202.530579328537 and batch: 1150, loss is 4.283541078567505 and perplexity is 72.49670253623883
At time: 203.84983229637146 and batch: 1200, loss is 4.361131882667541 and perplexity is 78.34576246595977
At time: 205.16473650932312 and batch: 1250, loss is 4.326436328887939 and perplexity is 75.67412777347504
At time: 206.4875087738037 and batch: 1300, loss is 4.338618974685669 and perplexity is 76.60167740050262
At time: 207.8030457496643 and batch: 1350, loss is 4.2143373918533324 and perplexity is 67.64932602240897
At time: 209.11600375175476 and batch: 1400, loss is 4.249841370582581 and perplexity is 70.09429244796421
At time: 210.4296281337738 and batch: 1450, loss is 4.195153074264526 and perplexity is 66.36388940338567
At time: 211.7478301525116 and batch: 1500, loss is 4.189298181533814 and perplexity is 65.97647120245672
At time: 213.06619024276733 and batch: 1550, loss is 4.182551755905151 and perplexity is 65.53286391058602
At time: 214.39042258262634 and batch: 1600, loss is 4.275039825439453 and perplexity is 71.88300202479908
At time: 215.70504546165466 and batch: 1650, loss is 4.228278069496155 and perplexity is 68.59900769200904
At time: 217.02169132232666 and batch: 1700, loss is 4.261481623649598 and perplexity is 70.91497496013255
At time: 218.34966254234314 and batch: 1750, loss is 4.2724200630187985 and perplexity is 71.69493209424166
At time: 219.66748809814453 and batch: 1800, loss is 4.2164139080047605 and perplexity is 67.78994689075107
At time: 220.9970302581787 and batch: 1850, loss is 4.2528314113616945 and perplexity is 70.30419088683227
At time: 222.3139410018921 and batch: 1900, loss is 4.329375839233398 and perplexity is 75.89689991504684
At time: 223.62958216667175 and batch: 1950, loss is 4.264028873443603 and perplexity is 71.09584337621271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465089310047238 and perplexity of 86.92879280767035
finished 4 epochs...
Completing Train Step...
At time: 227.6380398273468 and batch: 50, loss is 4.229589366912842 and perplexity is 68.68902039739882
At time: 228.96751046180725 and batch: 100, loss is 4.173107981681824 and perplexity is 64.91689943222397
At time: 230.28343749046326 and batch: 150, loss is 4.134172110557556 and perplexity is 62.43787800705896
At time: 231.60090136528015 and batch: 200, loss is 4.140081253051758 and perplexity is 62.80792457742297
At time: 232.91974186897278 and batch: 250, loss is 4.128996958732605 and perplexity is 62.11558718002985
At time: 234.25007843971252 and batch: 300, loss is 4.145888924598694 and perplexity is 63.17375365321566
At time: 235.5671353340149 and batch: 350, loss is 4.162381563186646 and perplexity is 64.22429482561895
At time: 236.88341522216797 and batch: 400, loss is 4.132349820137024 and perplexity is 62.32420166719838
At time: 238.2010796070099 and batch: 450, loss is 4.151972298622131 and perplexity is 63.559234548581024
At time: 239.51969695091248 and batch: 500, loss is 4.171107206344605 and perplexity is 64.78714514874136
At time: 240.8379340171814 and batch: 550, loss is 4.128827962875366 and perplexity is 62.105090790074655
At time: 242.15507197380066 and batch: 600, loss is 4.1114048624038695 and perplexity is 61.03239949333959
At time: 243.4778175354004 and batch: 650, loss is 4.164677357673645 and perplexity is 64.37190998981517
At time: 244.79444336891174 and batch: 700, loss is 4.197197098731994 and perplexity is 66.49967754694913
At time: 246.11350512504578 and batch: 750, loss is 4.160920090675354 and perplexity is 64.1305013391698
At time: 247.4311180114746 and batch: 800, loss is 4.130513348579407 and perplexity is 62.20985007734533
At time: 248.74899792671204 and batch: 850, loss is 4.128146758079529 and perplexity is 62.062798910733484
At time: 250.06472277641296 and batch: 900, loss is 4.110603632926941 and perplexity is 60.98351812103108
At time: 251.3826813697815 and batch: 950, loss is 4.205677390098572 and perplexity is 67.06601213548353
At time: 252.70100831985474 and batch: 1000, loss is 4.181563372612 and perplexity is 65.46812432177877
At time: 254.01938104629517 and batch: 1050, loss is 4.122630200386047 and perplexity is 61.72136852600994
At time: 255.33701753616333 and batch: 1100, loss is 4.166263999938965 and perplexity is 64.47412625178158
At time: 256.65338683128357 and batch: 1150, loss is 4.120464906692505 and perplexity is 61.58786822182679
At time: 257.96625304222107 and batch: 1200, loss is 4.198329930305481 and perplexity is 66.5750531671814
At time: 259.27915620803833 and batch: 1250, loss is 4.160640597343445 and perplexity is 64.11257979626603
At time: 260.5925064086914 and batch: 1300, loss is 4.170699191093445 and perplexity is 64.76071639747502
At time: 261.9051809310913 and batch: 1350, loss is 4.04860366821289 and perplexity is 57.31736708076903
At time: 263.2191710472107 and batch: 1400, loss is 4.092703032493591 and perplexity is 59.90158901067007
At time: 264.53081345558167 and batch: 1450, loss is 4.033686928749084 and perplexity is 56.468724078397955
At time: 265.8439028263092 and batch: 1500, loss is 4.026686797142029 and perplexity is 56.07481589125979
At time: 267.1570146083832 and batch: 1550, loss is 4.024461607933045 and perplexity is 55.95017753942912
At time: 268.47174763679504 and batch: 1600, loss is 4.122748565673828 and perplexity is 61.72867462594353
At time: 269.78749918937683 and batch: 1650, loss is 4.073907375335693 and perplexity is 58.78621421765471
At time: 271.1040494441986 and batch: 1700, loss is 4.106927514076233 and perplexity is 60.7597470170713
At time: 272.4205710887909 and batch: 1750, loss is 4.114824776649475 and perplexity is 61.241482384807036
At time: 273.73935651779175 and batch: 1800, loss is 4.0585320520401 and perplexity is 57.88927024031811
At time: 275.0665955543518 and batch: 1850, loss is 4.096459698677063 and perplexity is 60.127042496041526
At time: 276.39513993263245 and batch: 1900, loss is 4.17905490398407 and perplexity is 65.30410538996685
At time: 277.71477937698364 and batch: 1950, loss is 4.10857967376709 and perplexity is 60.860214793471435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4513035973837205 and perplexity of 85.73863984976748
finished 5 epochs...
Completing Train Step...
At time: 281.6797480583191 and batch: 50, loss is 4.083169865608215 and perplexity is 59.333250503122706
At time: 283.00070667266846 and batch: 100, loss is 4.0272519445419315 and perplexity is 56.10651538426008
At time: 284.32003355026245 and batch: 150, loss is 3.992967734336853 and perplexity is 54.215548193011436
At time: 285.635036945343 and batch: 200, loss is 4.001603498458862 and perplexity is 54.685768311692684
At time: 286.95759654045105 and batch: 250, loss is 3.9832997512817383 and perplexity is 53.69391880683834
At time: 288.28219842910767 and batch: 300, loss is 3.9979994106292724 and perplexity is 54.48903074236771
At time: 289.6070759296417 and batch: 350, loss is 4.018232688903809 and perplexity is 55.602751581272415
At time: 290.93167448043823 and batch: 400, loss is 3.9902775382995603 and perplexity is 54.069893747452724
At time: 292.25430727005005 and batch: 450, loss is 4.0138675451278685 and perplexity is 55.360566547088595
At time: 293.5775873661041 and batch: 500, loss is 4.03461754322052 and perplexity is 56.5212991499757
At time: 294.9008095264435 and batch: 550, loss is 3.994980607032776 and perplexity is 54.324787094781804
At time: 296.2262706756592 and batch: 600, loss is 3.9775947189331053 and perplexity is 53.388465402372766
At time: 297.55036520957947 and batch: 650, loss is 4.03102942943573 and perplexity is 56.31885770602458
At time: 298.87463212013245 and batch: 700, loss is 4.059609522819519 and perplexity is 57.95167785259565
At time: 300.2072832584381 and batch: 750, loss is 4.030465750694275 and perplexity is 56.28712090871199
At time: 301.5305366516113 and batch: 800, loss is 3.995795974731445 and perplexity is 54.369099834549274
At time: 302.85634112358093 and batch: 850, loss is 3.9906120681762696 and perplexity is 54.08798476816649
At time: 304.1802020072937 and batch: 900, loss is 3.975214056968689 and perplexity is 53.261516684400306
At time: 305.503874540329 and batch: 950, loss is 4.070578961372376 and perplexity is 58.59087462724872
At time: 306.8289740085602 and batch: 1000, loss is 4.055954909324646 and perplexity is 57.74027340473562
At time: 308.1467056274414 and batch: 1050, loss is 3.9965818977355956 and perplexity is 54.41184655643995
At time: 309.4665107727051 and batch: 1100, loss is 4.032567629814148 and perplexity is 56.40555405534465
At time: 310.7860300540924 and batch: 1150, loss is 3.9932086944580076 and perplexity is 54.22861355212454
At time: 312.1041271686554 and batch: 1200, loss is 4.070503287315368 and perplexity is 58.586440985820005
At time: 313.423787355423 and batch: 1250, loss is 4.038483576774597 and perplexity is 56.74023532361742
At time: 314.74023723602295 and batch: 1300, loss is 4.039583854675293 and perplexity is 56.80269970841366
At time: 316.0584042072296 and batch: 1350, loss is 3.919230694770813 and perplexity is 50.36168636278169
At time: 317.3794193267822 and batch: 1400, loss is 3.9676154327392577 and perplexity is 52.85833618173191
At time: 318.6973395347595 and batch: 1450, loss is 3.9088645505905153 and perplexity is 49.842326391681105
At time: 320.0141546726227 and batch: 1500, loss is 3.8996812868118287 and perplexity is 49.38670640230911
At time: 321.3331081867218 and batch: 1550, loss is 3.9037562465667723 and perplexity is 49.58836584132567
At time: 322.65191626548767 and batch: 1600, loss is 4.004044890403748 and perplexity is 54.81944081303768
At time: 323.97238087654114 and batch: 1650, loss is 3.949957308769226 and perplexity is 51.93314969742706
At time: 325.29208874702454 and batch: 1700, loss is 3.9844371366500853 and perplexity is 53.75502422807707
At time: 326.60965275764465 and batch: 1750, loss is 3.990235462188721 and perplexity is 54.0676187444723
At time: 327.92540669441223 and batch: 1800, loss is 3.9363088464736937 and perplexity is 51.229157197744605
At time: 329.2427954673767 and batch: 1850, loss is 3.9710554122924804 and perplexity is 53.04048088482483
At time: 330.5603737831116 and batch: 1900, loss is 4.051413722038269 and perplexity is 57.47865848001659
At time: 331.8777811527252 and batch: 1950, loss is 3.9866641998291015 and perplexity is 53.87487346960317
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.45876095793968 and perplexity of 86.38041379635861
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 335.8625099658966 and batch: 50, loss is 4.0011688280105595 and perplexity is 54.66200318963718
At time: 337.1808490753174 and batch: 100, loss is 3.978017740249634 and perplexity is 53.41105463882214
At time: 338.49931740760803 and batch: 150, loss is 3.953653807640076 and perplexity is 52.12547577420919
At time: 339.81762290000916 and batch: 200, loss is 3.95967511177063 and perplexity is 52.44028594955148
At time: 341.13845324516296 and batch: 250, loss is 3.944857177734375 and perplexity is 51.668958107445704
At time: 342.4554224014282 and batch: 300, loss is 3.948984508514404 and perplexity is 51.88265368141852
At time: 343.77077531814575 and batch: 350, loss is 3.9605965709686277 and perplexity is 52.488629803409054
At time: 345.0902819633484 and batch: 400, loss is 3.932443633079529 and perplexity is 51.031527759195114
At time: 346.40930557250977 and batch: 450, loss is 3.949327096939087 and perplexity is 51.90043112301057
At time: 347.7270977497101 and batch: 500, loss is 3.963564248085022 and perplexity is 52.64463047426518
At time: 349.04293489456177 and batch: 550, loss is 3.921934404373169 and perplexity is 50.49803397690943
At time: 350.3600215911865 and batch: 600, loss is 3.88878990650177 and perplexity is 48.851735574264566
At time: 351.6795063018799 and batch: 650, loss is 3.933316082954407 and perplexity is 51.076069636655845
At time: 352.9978106021881 and batch: 700, loss is 3.9634839248657228 and perplexity is 52.64040205788894
At time: 354.3151834011078 and batch: 750, loss is 3.9166530847549437 and perplexity is 50.23204073531209
At time: 355.6312310695648 and batch: 800, loss is 3.877141737937927 and perplexity is 48.28600359093168
At time: 356.95145535469055 and batch: 850, loss is 3.87430410861969 and perplexity is 48.14918003056491
At time: 358.27358508110046 and batch: 900, loss is 3.8478408813476563 and perplexity is 46.89170908940898
At time: 359.59668159484863 and batch: 950, loss is 3.937310848236084 and perplexity is 51.280514629364085
At time: 360.91896748542786 and batch: 1000, loss is 3.9077551412582396 and perplexity is 49.78706151099532
At time: 362.23910665512085 and batch: 1050, loss is 3.8509127283096314 and perplexity is 47.03597471102906
At time: 363.5585398674011 and batch: 1100, loss is 3.8748450231552125 and perplexity is 48.17523166713617
At time: 364.9079532623291 and batch: 1150, loss is 3.8419187831878663 and perplexity is 46.6148324398499
At time: 366.22672986984253 and batch: 1200, loss is 3.8929868793487548 and perplexity is 49.057195835976316
At time: 367.54510617256165 and batch: 1250, loss is 3.856274118423462 and perplexity is 47.28883014346363
At time: 368.8623149394989 and batch: 1300, loss is 3.857726421356201 and perplexity is 47.35755774473529
At time: 370.1778450012207 and batch: 1350, loss is 3.7276595497131346 and perplexity is 41.58167434734876
At time: 371.4949653148651 and batch: 1400, loss is 3.7661288738250733 and perplexity is 43.212459750916636
At time: 372.81988167762756 and batch: 1450, loss is 3.6937053060531615 and perplexity is 40.19350060466947
At time: 374.14273285865784 and batch: 1500, loss is 3.6813810205459596 and perplexity is 39.70118438192341
At time: 375.4716157913208 and batch: 1550, loss is 3.6773680353164675 and perplexity is 39.54218336315528
At time: 376.78680753707886 and batch: 1600, loss is 3.7690489387512205 and perplexity is 43.33882735001242
At time: 378.10421442985535 and batch: 1650, loss is 3.7084747076034548 and perplexity is 40.791540025907054
At time: 379.42903757095337 and batch: 1700, loss is 3.728022780418396 and perplexity is 41.596780831651266
At time: 380.74804520606995 and batch: 1750, loss is 3.718825311660767 and perplexity is 41.21594976509927
At time: 382.0667870044708 and batch: 1800, loss is 3.659793176651001 and perplexity is 38.85330626936033
At time: 383.38366508483887 and batch: 1850, loss is 3.67773898601532 and perplexity is 39.55685428463404
At time: 384.6993727684021 and batch: 1900, loss is 3.751222414970398 and perplexity is 42.57309218979788
At time: 386.0184717178345 and batch: 1950, loss is 3.6889653491973875 and perplexity is 40.00343595090158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407141681050145 and perplexity of 82.03464688793595
finished 7 epochs...
Completing Train Step...
At time: 389.99987721443176 and batch: 50, loss is 3.8940505027770995 and perplexity is 49.10940197771237
At time: 391.3128571510315 and batch: 100, loss is 3.8546419191360473 and perplexity is 47.21170830482735
At time: 392.6309356689453 and batch: 150, loss is 3.826874794960022 and perplexity is 45.9188080676744
At time: 393.9505319595337 and batch: 200, loss is 3.8343406343460082 and perplexity is 46.26291343286546
At time: 395.26503348350525 and batch: 250, loss is 3.817513360977173 and perplexity is 45.49094799396816
At time: 396.58354663848877 and batch: 300, loss is 3.8186064338684083 and perplexity is 45.54070010240379
At time: 397.9319143295288 and batch: 350, loss is 3.8312910270690916 and perplexity is 46.12204462185934
At time: 399.24870324134827 and batch: 400, loss is 3.806022629737854 and perplexity is 44.971215508543935
At time: 400.56779861450195 and batch: 450, loss is 3.828104476928711 and perplexity is 45.97530832953594
At time: 401.8857855796814 and batch: 500, loss is 3.845422649383545 and perplexity is 46.778451056927274
At time: 403.2042944431305 and batch: 550, loss is 3.8090735054016114 and perplexity is 45.108626601004126
At time: 404.5217764377594 and batch: 600, loss is 3.7803246212005615 and perplexity is 43.83026766053952
At time: 405.8387830257416 and batch: 650, loss is 3.823746819496155 and perplexity is 45.7753995687701
At time: 407.15591835975647 and batch: 700, loss is 3.853129324913025 and perplexity is 47.140350129173854
At time: 408.47492575645447 and batch: 750, loss is 3.8153820848464965 and perplexity is 45.394097466616024
At time: 409.7922661304474 and batch: 800, loss is 3.775329422950745 and perplexity is 43.611872701407236
At time: 411.10983777046204 and batch: 850, loss is 3.7738103675842285 and perplexity is 43.54567414450249
At time: 412.4270398616791 and batch: 900, loss is 3.7491242122650146 and perplexity is 42.48385886013271
At time: 413.74453258514404 and batch: 950, loss is 3.839249835014343 and perplexity is 46.490585745697885
At time: 415.0647397041321 and batch: 1000, loss is 3.8154686641693116 and perplexity is 45.398027826976
At time: 416.3838129043579 and batch: 1050, loss is 3.7611201715469362 and perplexity is 42.996562539099344
At time: 417.7030339241028 and batch: 1100, loss is 3.78481586933136 and perplexity is 44.02756298773507
At time: 419.02001428604126 and batch: 1150, loss is 3.7566440439224245 and perplexity is 42.804534529316825
At time: 420.33502888679504 and batch: 1200, loss is 3.810655298233032 and perplexity is 45.180035565401646
At time: 421.65255904197693 and batch: 1250, loss is 3.7787513542175293 and perplexity is 43.76136516279621
At time: 422.9719340801239 and batch: 1300, loss is 3.782561812400818 and perplexity is 43.92843411727736
At time: 424.29008316993713 and batch: 1350, loss is 3.6515736103057863 and perplexity is 38.535257841469715
At time: 425.60736203193665 and batch: 1400, loss is 3.6938672494888305 and perplexity is 40.20001020532827
At time: 426.9232130050659 and batch: 1450, loss is 3.6248069906234743 and perplexity is 37.51748123508182
At time: 428.2416481971741 and batch: 1500, loss is 3.6151803827285764 and perplexity is 37.15804799124515
At time: 429.5616900920868 and batch: 1550, loss is 3.6148908376693725 and perplexity is 37.1472906194867
At time: 430.8807234764099 and batch: 1600, loss is 3.7139608573913576 and perplexity is 41.01594351731374
At time: 432.200811624527 and batch: 1650, loss is 3.653129291534424 and perplexity is 38.59525307336268
At time: 433.5164384841919 and batch: 1700, loss is 3.6782833242416384 and perplexity is 39.57839245402673
At time: 434.833270072937 and batch: 1750, loss is 3.6727889823913573 and perplexity is 39.3615315355555
At time: 436.1532518863678 and batch: 1800, loss is 3.6195533752441404 and perplexity is 37.32089566331729
At time: 437.471773147583 and batch: 1850, loss is 3.639398245811462 and perplexity is 38.068921698398626
At time: 438.7897424697876 and batch: 1900, loss is 3.718370265960693 and perplexity is 41.19719889096009
At time: 440.1049394607544 and batch: 1950, loss is 3.657458987236023 and perplexity is 38.76272105578184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413727800236192 and perplexity of 82.57671996922988
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 444.0785355567932 and batch: 50, loss is 3.851850700378418 and perplexity is 47.08011383893462
At time: 445.4098560810089 and batch: 100, loss is 3.841587195396423 and perplexity is 46.59937809289066
At time: 446.7241976261139 and batch: 150, loss is 3.8290790557861327 and perplexity is 46.0201367338567
At time: 448.0389139652252 and batch: 200, loss is 3.8550032663345335 and perplexity is 47.22877120598915
At time: 449.35466265678406 and batch: 250, loss is 3.8477225065231324 and perplexity is 46.886158620098286
At time: 450.67341709136963 and batch: 300, loss is 3.8536878347396852 and perplexity is 47.16668583164294
At time: 451.9905745983124 and batch: 350, loss is 3.870154423713684 and perplexity is 47.9497900937836
At time: 453.30650997161865 and batch: 400, loss is 3.8420359325408935 and perplexity is 46.62029365719449
At time: 454.62291288375854 and batch: 450, loss is 3.8607205295562745 and perplexity is 47.49956388149686
At time: 455.94107723236084 and batch: 500, loss is 3.874162001609802 and perplexity is 48.142338180711135
At time: 457.2604305744171 and batch: 550, loss is 3.837542338371277 and perplexity is 46.41127096073793
At time: 458.5775125026703 and batch: 600, loss is 3.796957116127014 and perplexity is 44.56537071747013
At time: 459.89603090286255 and batch: 650, loss is 3.8213680601119995 and perplexity is 45.666640314814885
At time: 461.2126326560974 and batch: 700, loss is 3.8532815885543825 and perplexity is 47.14752843702317
At time: 462.52961683273315 and batch: 750, loss is 3.8083365249633787 and perplexity is 45.075394672748295
At time: 463.8796331882477 and batch: 800, loss is 3.7682509279251097 and perplexity is 43.304256292469894
At time: 465.19863390922546 and batch: 850, loss is 3.7595945692062376 and perplexity is 42.93101689365567
At time: 466.5165424346924 and batch: 900, loss is 3.7366666555404664 and perplexity is 41.957896682357024
At time: 467.8309164047241 and batch: 950, loss is 3.8408253622055053 and perplexity is 46.56389065945208
At time: 469.1478018760681 and batch: 1000, loss is 3.8073424005508425 and perplexity is 45.0306063887513
At time: 470.4661900997162 and batch: 1050, loss is 3.7398852825164797 and perplexity is 42.093161066500215
At time: 471.7845799922943 and batch: 1100, loss is 3.7699815368652345 and perplexity is 43.37926391126223
At time: 473.1036477088928 and batch: 1150, loss is 3.739057197570801 and perplexity is 42.0583187816818
At time: 474.42331099510193 and batch: 1200, loss is 3.7809693145751955 and perplexity is 43.85853385424358
At time: 475.74020981788635 and batch: 1250, loss is 3.7488809061050414 and perplexity is 42.473523532947986
At time: 477.0571165084839 and batch: 1300, loss is 3.7494690227508545 and perplexity is 42.49851026598065
At time: 478.3778295516968 and batch: 1350, loss is 3.616460666656494 and perplexity is 37.20565130926029
At time: 479.69444704055786 and batch: 1400, loss is 3.652137041091919 and perplexity is 38.55697590982878
At time: 481.0119230747223 and batch: 1450, loss is 3.568309335708618 and perplexity is 35.45659724659336
At time: 482.3263108730316 and batch: 1500, loss is 3.558897128105164 and perplexity is 35.12443802034602
At time: 483.6425483226776 and batch: 1550, loss is 3.5574620389938354 and perplexity is 35.07406747355787
At time: 484.96170473098755 and batch: 1600, loss is 3.6511410522460936 and perplexity is 38.51859270968643
At time: 486.2857413291931 and batch: 1650, loss is 3.592238173484802 and perplexity is 36.31526489807068
At time: 487.61959886550903 and batch: 1700, loss is 3.6172084045410156 and perplexity is 37.23348178791745
At time: 488.93533539772034 and batch: 1750, loss is 3.605589122772217 and perplexity is 36.80335916888791
At time: 490.252468585968 and batch: 1800, loss is 3.5433366537094115 and perplexity is 34.58211544275237
At time: 491.57110714912415 and batch: 1850, loss is 3.554531440734863 and perplexity is 34.97142994063016
At time: 492.8934395313263 and batch: 1900, loss is 3.6364439630508425 and perplexity is 37.95662130454626
At time: 494.21307826042175 and batch: 1950, loss is 3.5781037282943724 and perplexity is 35.805579323695646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382152468659157 and perplexity of 80.0100673522163
finished 9 epochs...
Completing Train Step...
At time: 498.1846721172333 and batch: 50, loss is 3.846226706504822 and perplexity is 46.81607872899353
At time: 499.51099371910095 and batch: 100, loss is 3.8135339069366454 and perplexity is 45.31027857840817
At time: 500.82903385162354 and batch: 150, loss is 3.786259503364563 and perplexity is 44.09116857661297
At time: 502.14813709259033 and batch: 200, loss is 3.801001982688904 and perplexity is 44.74599675314174
At time: 503.46360659599304 and batch: 250, loss is 3.791971650123596 and perplexity is 44.34374449087829
At time: 504.78060150146484 and batch: 300, loss is 3.794296703338623 and perplexity is 44.44696600783287
At time: 506.0999286174774 and batch: 350, loss is 3.813938841819763 and perplexity is 45.328630006084204
At time: 507.4174015522003 and batch: 400, loss is 3.786895260810852 and perplexity is 44.119208777790014
At time: 508.7351243495941 and batch: 450, loss is 3.808518762588501 and perplexity is 45.083609854159754
At time: 510.051153421402 and batch: 500, loss is 3.8213337326049803 and perplexity is 45.665072719804904
At time: 511.36697363853455 and batch: 550, loss is 3.7871253633499147 and perplexity is 44.12936188783463
At time: 512.6854524612427 and batch: 600, loss is 3.748181414604187 and perplexity is 42.44382405270333
At time: 514.005172252655 and batch: 650, loss is 3.772617678642273 and perplexity is 43.49376866018192
At time: 515.3244166374207 and batch: 700, loss is 3.80703999042511 and perplexity is 45.01699073627082
At time: 516.6409924030304 and batch: 750, loss is 3.765893087387085 and perplexity is 43.20227204006447
At time: 517.9603340625763 and batch: 800, loss is 3.7266534471511843 and perplexity is 41.53985995656774
At time: 519.2838759422302 and batch: 850, loss is 3.719263210296631 and perplexity is 41.23400212554078
At time: 520.6036884784698 and batch: 900, loss is 3.6977102184295654 and perplexity is 40.354794821707685
At time: 521.9216742515564 and batch: 950, loss is 3.801932439804077 and perplexity is 44.78765035963835
At time: 523.2397375106812 and batch: 1000, loss is 3.7696315383911134 and perplexity is 43.36408389173159
At time: 524.5561108589172 and batch: 1050, loss is 3.705737886428833 and perplexity is 40.6800535043431
At time: 525.8779785633087 and batch: 1100, loss is 3.7350813293457032 and perplexity is 41.89143242735172
At time: 527.1975781917572 and batch: 1150, loss is 3.7037027406692506 and perplexity is 40.59734785352741
At time: 528.5206024646759 and batch: 1200, loss is 3.74972177028656 and perplexity is 42.5092530172663
At time: 529.8790380954742 and batch: 1250, loss is 3.7203865480422973 and perplexity is 41.2803478626176
At time: 531.1949756145477 and batch: 1300, loss is 3.7231736040115355 and perplexity is 41.39555897787667
At time: 532.511561870575 and batch: 1350, loss is 3.5921020889282227 and perplexity is 36.31032328759603
At time: 533.8305983543396 and batch: 1400, loss is 3.6302559041976927 and perplexity is 37.72246872021507
At time: 535.1497480869293 and batch: 1450, loss is 3.5501307249069214 and perplexity is 34.81786875276559
At time: 536.4675345420837 and batch: 1500, loss is 3.5418446397781373 and perplexity is 34.530556917322514
At time: 537.7830898761749 and batch: 1550, loss is 3.542748351097107 and perplexity is 34.56177667715944
At time: 539.1075546741486 and batch: 1600, loss is 3.640120892524719 and perplexity is 38.096442022079295
At time: 540.432416677475 and batch: 1650, loss is 3.5837336730957032 and perplexity is 36.007731277082144
At time: 541.7502310276031 and batch: 1700, loss is 3.6114838552474975 and perplexity is 37.02094580282313
At time: 543.0677578449249 and batch: 1750, loss is 3.600596480369568 and perplexity is 36.6200710840007
At time: 544.3858876228333 and batch: 1800, loss is 3.541563696861267 and perplexity is 34.52085716454322
At time: 545.7020342350006 and batch: 1850, loss is 3.5552211570739747 and perplexity is 34.9955586272805
At time: 547.0199065208435 and batch: 1900, loss is 3.637634425163269 and perplexity is 38.00183413086376
At time: 548.3384275436401 and batch: 1950, loss is 3.57981707572937 and perplexity is 35.86697930591926
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384123762263808 and perplexity of 80.16794624799778
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 552.283371925354 and batch: 50, loss is 3.8382703685760498 and perplexity is 46.445072070460704
At time: 553.6194951534271 and batch: 100, loss is 3.826168909072876 and perplexity is 45.886406066507966
At time: 554.9375758171082 and batch: 150, loss is 3.8097912645339966 and perplexity is 45.14101535196674
At time: 556.2567617893219 and batch: 200, loss is 3.8299045610427855 and perplexity is 46.058142283374565
At time: 557.574667930603 and batch: 250, loss is 3.825624747276306 and perplexity is 45.86144322987167
At time: 558.8971314430237 and batch: 300, loss is 3.824799380302429 and perplexity is 45.82360632606877
At time: 560.2125632762909 and batch: 350, loss is 3.8546660327911377 and perplexity is 47.21284676540381
At time: 561.5438196659088 and batch: 400, loss is 3.8335588932037354 and perplexity is 46.22676194246836
At time: 562.8629331588745 and batch: 450, loss is 3.859765067100525 and perplexity is 47.45420150601793
At time: 564.1820528507233 and batch: 500, loss is 3.8753186321258544 and perplexity is 48.198053292853224
At time: 565.4999976158142 and batch: 550, loss is 3.8472082376480103 and perplexity is 46.86205272703247
At time: 566.8153731822968 and batch: 600, loss is 3.8037463235855102 and perplexity is 44.86896367639285
At time: 568.1316592693329 and batch: 650, loss is 3.8127219915390014 and perplexity is 45.27350539593546
At time: 569.4550514221191 and batch: 700, loss is 3.8476164722442627 and perplexity is 46.88118734364755
At time: 570.772088766098 and batch: 750, loss is 3.805756754875183 and perplexity is 44.959260382150674
At time: 572.0886540412903 and batch: 800, loss is 3.757945666313171 and perplexity is 42.86028614579054
At time: 573.4043521881104 and batch: 850, loss is 3.744409065246582 and perplexity is 42.284012741869475
At time: 574.7199020385742 and batch: 900, loss is 3.7151525020599365 and perplexity is 41.06484908097275
At time: 576.0385274887085 and batch: 950, loss is 3.830053615570068 and perplexity is 46.06500796966824
At time: 577.3563759326935 and batch: 1000, loss is 3.7978731489181516 and perplexity is 44.606212761866566
At time: 578.675749540329 and batch: 1050, loss is 3.727923665046692 and perplexity is 41.59265815557112
At time: 579.9925050735474 and batch: 1100, loss is 3.756141576766968 and perplexity is 42.78303205920613
At time: 581.30859541893 and batch: 1150, loss is 3.723655924797058 and perplexity is 41.41552973216781
At time: 582.6336493492126 and batch: 1200, loss is 3.76680242061615 and perplexity is 43.241575168713794
At time: 583.961686372757 and batch: 1250, loss is 3.734072585105896 and perplexity is 41.84919599265498
At time: 585.2875072956085 and batch: 1300, loss is 3.728805866241455 and perplexity is 41.62936743839507
At time: 586.6056432723999 and batch: 1350, loss is 3.596667795181274 and perplexity is 36.47648459088599
At time: 587.9218416213989 and batch: 1400, loss is 3.6365081310272216 and perplexity is 37.95905698227098
At time: 589.2398028373718 and batch: 1450, loss is 3.547392177581787 and perplexity is 34.72264881309098
At time: 590.5582985877991 and batch: 1500, loss is 3.5351194286346437 and perplexity is 34.299110765599295
At time: 591.8780143260956 and batch: 1550, loss is 3.53651650428772 and perplexity is 34.347062706617265
At time: 593.1960632801056 and batch: 1600, loss is 3.6288493394851686 and perplexity is 37.66944692487871
At time: 594.511935710907 and batch: 1650, loss is 3.5690806198120115 and perplexity is 35.48395490531752
At time: 595.8285918235779 and batch: 1700, loss is 3.594608883857727 and perplexity is 36.40146000470679
At time: 597.1483883857727 and batch: 1750, loss is 3.5961041927337645 and perplexity is 36.45593214714185
At time: 598.4671802520752 and batch: 1800, loss is 3.539010553359985 and perplexity is 34.43283287954632
At time: 599.78653216362 and batch: 1850, loss is 3.551720151901245 and perplexity is 34.87325321636709
At time: 601.1025893688202 and batch: 1900, loss is 3.637467122077942 and perplexity is 37.99547683857773
At time: 602.4194166660309 and batch: 1950, loss is 3.582888970375061 and perplexity is 35.977328291058505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356072856104651 and perplexity of 77.95041006491608
finished 11 epochs...
Completing Train Step...
At time: 606.3978364467621 and batch: 50, loss is 3.85000253200531 and perplexity is 46.993182218415555
At time: 607.7140200138092 and batch: 100, loss is 3.819212779998779 and perplexity is 45.568321903024945
At time: 609.0301349163055 and batch: 150, loss is 3.7906420183181764 and perplexity is 44.28482281857731
At time: 610.3470344543457 and batch: 200, loss is 3.799277048110962 and perplexity is 44.668879366462434
At time: 611.6655783653259 and batch: 250, loss is 3.794291739463806 and perplexity is 44.446745379205204
At time: 612.9864971637726 and batch: 300, loss is 3.7900265979766847 and perplexity is 44.257577422340844
At time: 614.3042209148407 and batch: 350, loss is 3.81795880317688 and perplexity is 45.51121609570814
At time: 615.6208333969116 and batch: 400, loss is 3.7978160429000853 and perplexity is 44.60366555140593
At time: 616.9396510124207 and batch: 450, loss is 3.824971385002136 and perplexity is 45.83148887961307
At time: 618.2588987350464 and batch: 500, loss is 3.842240891456604 and perplexity is 46.629849881315785
At time: 619.5768966674805 and batch: 550, loss is 3.814243459701538 and perplexity is 45.34244002062231
At time: 620.8948378562927 and batch: 600, loss is 3.7729399394989014 and perplexity is 43.50778725802971
At time: 622.2104887962341 and batch: 650, loss is 3.78465943813324 and perplexity is 44.02067624197158
At time: 623.5264298915863 and batch: 700, loss is 3.8224039459228516 and perplexity is 45.713970249517864
At time: 624.8456284999847 and batch: 750, loss is 3.783116183280945 and perplexity is 43.95279351340763
At time: 626.1747353076935 and batch: 800, loss is 3.7358601570129393 and perplexity is 41.92407134234147
At time: 627.5034472942352 and batch: 850, loss is 3.724007067680359 and perplexity is 41.430075054285126
At time: 628.8189685344696 and batch: 900, loss is 3.6966670846939085 and perplexity is 40.31272132179233
At time: 630.1346786022186 and batch: 950, loss is 3.8124509620666505 and perplexity is 45.261236604333675
At time: 631.4520409107208 and batch: 1000, loss is 3.7809141063690186 and perplexity is 43.856112570101935
At time: 632.7705097198486 and batch: 1050, loss is 3.7120423316955566 and perplexity is 40.9373288120177
At time: 634.0887410640717 and batch: 1100, loss is 3.740076808929443 and perplexity is 42.10122379073726
At time: 635.4065535068512 and batch: 1150, loss is 3.708983235359192 and perplexity is 40.81228893145954
At time: 636.7223298549652 and batch: 1200, loss is 3.752015652656555 and perplexity is 42.606876168530164
At time: 638.0399119853973 and batch: 1250, loss is 3.72057936668396 and perplexity is 41.28830825065077
At time: 639.3588101863861 and batch: 1300, loss is 3.7179454660415647 and perplexity is 41.17970204079627
At time: 640.6782636642456 and batch: 1350, loss is 3.5877418422698977 and perplexity is 36.1523459821131
At time: 642.0030996799469 and batch: 1400, loss is 3.629442982673645 and perplexity is 37.69181577435999
At time: 643.3201787471771 and batch: 1450, loss is 3.54241735458374 and perplexity is 34.55033874264619
At time: 644.6363010406494 and batch: 1500, loss is 3.532322688102722 and perplexity is 34.20331906701358
At time: 645.9542372226715 and batch: 1550, loss is 3.5346353912353514 and perplexity is 34.282512730585196
At time: 647.2733960151672 and batch: 1600, loss is 3.629094080924988 and perplexity is 37.67866732781762
At time: 648.5909676551819 and batch: 1650, loss is 3.570038604736328 and perplexity is 35.51796428680834
At time: 649.907794713974 and batch: 1700, loss is 3.5970998001098633 and perplexity is 36.49224601626845
At time: 651.224348783493 and batch: 1750, loss is 3.6005206537246703 and perplexity is 36.61729441214867
At time: 652.5416646003723 and batch: 1800, loss is 3.5441790056228637 and perplexity is 34.611258026299105
At time: 653.8611304759979 and batch: 1850, loss is 3.5582152128219606 and perplexity is 35.100494293970335
At time: 655.1801099777222 and batch: 1900, loss is 3.6447049522399904 and perplexity is 38.27147927133587
At time: 656.4954578876495 and batch: 1950, loss is 3.58919132232666 and perplexity is 36.20478608287811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355119004360465 and perplexity of 77.87609237997705
finished 12 epochs...
Completing Train Step...
At time: 660.4848186969757 and batch: 50, loss is 3.8444989681243897 and perplexity is 46.73526262759573
At time: 661.8034198284149 and batch: 100, loss is 3.8111700582504273 and perplexity is 45.20329842817735
At time: 663.1275835037231 and batch: 150, loss is 3.7804678010940553 and perplexity is 43.83654372288721
At time: 664.4435331821442 and batch: 200, loss is 3.787293748855591 and perplexity is 44.13679325840127
At time: 665.7612919807434 and batch: 250, loss is 3.7816508436203002 and perplexity is 43.88843490700155
At time: 667.0810582637787 and batch: 300, loss is 3.7765973901748655 and perplexity is 43.667206199692764
At time: 668.4014599323273 and batch: 350, loss is 3.804508242607117 and perplexity is 44.90316322028472
At time: 669.722216129303 and batch: 400, loss is 3.784055061340332 and perplexity is 43.99407920496837
At time: 671.0378494262695 and batch: 450, loss is 3.8114725971221923 and perplexity is 45.21697625201623
At time: 672.3537273406982 and batch: 500, loss is 3.8284587383270265 and perplexity is 45.99159849187023
At time: 673.6739604473114 and batch: 550, loss is 3.8005644369125364 and perplexity is 44.726422613856315
At time: 674.9935672283173 and batch: 600, loss is 3.760299186706543 and perplexity is 42.961277499289004
At time: 676.311666727066 and batch: 650, loss is 3.7726942110061645 and perplexity is 43.497097468491205
At time: 677.6281208992004 and batch: 700, loss is 3.811049165725708 and perplexity is 45.197834017614575
At time: 678.9440357685089 and batch: 750, loss is 3.7727065181732176 and perplexity is 43.497632797830256
At time: 680.2620260715485 and batch: 800, loss is 3.725949902534485 and perplexity is 41.51064508990299
At time: 681.5810465812683 and batch: 850, loss is 3.7145656538009644 and perplexity is 41.040757315581324
At time: 682.8982684612274 and batch: 900, loss is 3.6877550363540648 and perplexity is 39.95504856643632
At time: 684.2171964645386 and batch: 950, loss is 3.803388543128967 and perplexity is 44.852913309509105
At time: 685.5329060554504 and batch: 1000, loss is 3.7720161056518555 and perplexity is 43.46761185210794
At time: 686.8492562770844 and batch: 1050, loss is 3.7038108921051025 and perplexity is 40.60173875242627
At time: 688.1690053939819 and batch: 1100, loss is 3.73188108921051 and perplexity is 41.75758407165133
At time: 689.4861054420471 and batch: 1150, loss is 3.701613817214966 and perplexity is 40.51263161508879
At time: 690.8042390346527 and batch: 1200, loss is 3.744598388671875 and perplexity is 42.292018853845256
At time: 692.1210203170776 and batch: 1250, loss is 3.713893995285034 and perplexity is 41.01320119661701
At time: 693.4390437602997 and batch: 1300, loss is 3.71200786113739 and perplexity is 40.93591770376469
At time: 694.7585437297821 and batch: 1350, loss is 3.582671823501587 and perplexity is 35.969516774858015
At time: 696.0780384540558 and batch: 1400, loss is 3.624860305786133 and perplexity is 37.51948153901919
At time: 697.3965654373169 and batch: 1450, loss is 3.5387819528579714 and perplexity is 34.42496241629449
At time: 698.7146441936493 and batch: 1500, loss is 3.5293062353134155 and perplexity is 34.100301821252216
At time: 700.0307874679565 and batch: 1550, loss is 3.5322340965270995 and perplexity is 34.200289075303765
At time: 701.348363161087 and batch: 1600, loss is 3.6275681161880495 and perplexity is 37.62121485651167
At time: 702.6676108837128 and batch: 1650, loss is 3.5685517740249635 and perplexity is 35.46519432642184
At time: 703.986953496933 and batch: 1700, loss is 3.5960432958602904 and perplexity is 36.45371216245025
At time: 705.3035929203033 and batch: 1750, loss is 3.599958481788635 and perplexity is 36.59671498198766
At time: 706.6196205615997 and batch: 1800, loss is 3.544006338119507 and perplexity is 34.605282302709156
At time: 707.9350571632385 and batch: 1850, loss is 3.558950309753418 and perplexity is 35.12630604552583
At time: 709.2522594928741 and batch: 1900, loss is 3.645731978416443 and perplexity is 38.310805273319126
At time: 710.5770945549011 and batch: 1950, loss is 3.5901007604599 and perplexity is 36.237727072573364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35566775299782 and perplexity of 77.9188385069199
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 714.5617690086365 and batch: 50, loss is 3.8447067546844482 and perplexity is 46.74497459602386
At time: 715.8799300193787 and batch: 100, loss is 3.8202449607849123 and perplexity is 45.61538093188423
At time: 717.1981427669525 and batch: 150, loss is 3.7942861700057984 and perplexity is 44.446497835612575
At time: 718.5314259529114 and batch: 200, loss is 3.8031353759765625 and perplexity is 44.84155946244069
At time: 719.8579297065735 and batch: 250, loss is 3.8015194082260133 and perplexity is 44.769155465483124
At time: 721.1733522415161 and batch: 300, loss is 3.794612946510315 and perplexity is 44.46102428013442
At time: 722.4907064437866 and batch: 350, loss is 3.8228369665145876 and perplexity is 45.733769626425484
At time: 723.8146934509277 and batch: 400, loss is 3.8038063192367555 and perplexity is 44.87165569984336
At time: 725.1455533504486 and batch: 450, loss is 3.834522204399109 and perplexity is 46.271314155150776
At time: 726.4628722667694 and batch: 500, loss is 3.8566094398498536 and perplexity is 47.304689760325786
At time: 727.7774908542633 and batch: 550, loss is 3.826575450897217 and perplexity is 45.90506460222328
At time: 729.0944385528564 and batch: 600, loss is 3.786027455329895 and perplexity is 44.08093849457966
At time: 730.4133064746857 and batch: 650, loss is 3.8005025482177732 and perplexity is 44.723654639593356
At time: 731.7333402633667 and batch: 700, loss is 3.836599760055542 and perplexity is 46.367545313785335
At time: 733.0588731765747 and batch: 750, loss is 3.794998540878296 and perplexity is 44.47817150641599
At time: 734.3758244514465 and batch: 800, loss is 3.74548752784729 and perplexity is 42.329639066939784
At time: 735.6929574012756 and batch: 850, loss is 3.7357020139694215 and perplexity is 41.91744186631931
At time: 737.0113549232483 and batch: 900, loss is 3.7030720472335816 and perplexity is 40.5717514453224
At time: 738.3313271999359 and batch: 950, loss is 3.819475407600403 and perplexity is 45.58029097375173
At time: 739.6485834121704 and batch: 1000, loss is 3.7896667766571044 and perplexity is 44.24165546713256
At time: 740.9648842811584 and batch: 1050, loss is 3.721232604980469 and perplexity is 41.31528816599573
At time: 742.2815968990326 and batch: 1100, loss is 3.7464985132217405 and perplexity is 42.37245535261468
At time: 743.5990533828735 and batch: 1150, loss is 3.7168121767044067 and perplexity is 41.133059958045656
At time: 744.9185252189636 and batch: 1200, loss is 3.76208872795105 and perplexity is 43.038227309184265
At time: 746.2372562885284 and batch: 1250, loss is 3.733469090461731 and perplexity is 41.82394784633763
At time: 747.5525944232941 and batch: 1300, loss is 3.7237304878234863 and perplexity is 41.418617914536455
At time: 748.8660762310028 and batch: 1350, loss is 3.59137930393219 and perplexity is 36.28408821302393
At time: 750.1841952800751 and batch: 1400, loss is 3.632027792930603 and perplexity is 37.789367989045296
At time: 751.5040552616119 and batch: 1450, loss is 3.5435566234588625 and perplexity is 34.5897232987402
At time: 752.823094367981 and batch: 1500, loss is 3.530288701057434 and perplexity is 34.133820662512804
At time: 754.1422154903412 and batch: 1550, loss is 3.5377211999893188 and perplexity is 34.388465399238115
At time: 755.4584450721741 and batch: 1600, loss is 3.6300770950317385 and perplexity is 37.71572420005445
At time: 756.7749183177948 and batch: 1650, loss is 3.563678183555603 and perplexity is 35.29277199255955
At time: 758.0940759181976 and batch: 1700, loss is 3.5837451934814455 and perplexity is 36.008146102425634
At time: 759.4142124652863 and batch: 1750, loss is 3.5834936237335206 and perplexity is 35.99908868152172
At time: 760.7304511070251 and batch: 1800, loss is 3.53047025680542 and perplexity is 34.140018416456705
At time: 762.0475730895996 and batch: 1850, loss is 3.5496581602096557 and perplexity is 34.80141894426452
At time: 763.3649251461029 and batch: 1900, loss is 3.635805745124817 and perplexity is 37.93240443705981
At time: 764.6834940910339 and batch: 1950, loss is 3.589844012260437 and perplexity is 36.228424295681556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346825887990552 and perplexity of 77.23292749024989
finished 14 epochs...
Completing Train Step...
At time: 768.6518959999084 and batch: 50, loss is 3.851760787963867 and perplexity is 47.075880942519845
At time: 769.9854512214661 and batch: 100, loss is 3.8207021045684812 and perplexity is 45.636238486799925
At time: 771.3037497997284 and batch: 150, loss is 3.790127983093262 and perplexity is 44.26206470945545
At time: 772.6281518936157 and batch: 200, loss is 3.794665131568909 and perplexity is 44.46334454183259
At time: 773.9484391212463 and batch: 250, loss is 3.7927697992324827 and perplexity is 44.37915153920076
At time: 775.2664692401886 and batch: 300, loss is 3.782443017959595 and perplexity is 43.92321597344197
At time: 776.5812623500824 and batch: 350, loss is 3.808791060447693 and perplexity is 45.09588769614686
At time: 777.9095442295074 and batch: 400, loss is 3.789281530380249 and perplexity is 44.22461481671625
At time: 779.240163564682 and batch: 450, loss is 3.819470987319946 and perplexity is 45.58008949652762
At time: 780.5627884864807 and batch: 500, loss is 3.841904921531677 and perplexity is 46.614186285547696
At time: 781.8796517848969 and batch: 550, loss is 3.8129167127609254 and perplexity is 45.28232196658578
At time: 783.1957495212555 and batch: 600, loss is 3.773702788352966 and perplexity is 43.54098978632757
At time: 784.5118551254272 and batch: 650, loss is 3.786457962989807 and perplexity is 44.09991976175499
At time: 785.828547000885 and batch: 700, loss is 3.823867316246033 and perplexity is 45.78091568797304
At time: 787.1471803188324 and batch: 750, loss is 3.783347821235657 and perplexity is 43.962975827860674
At time: 788.464691400528 and batch: 800, loss is 3.7334524154663087 and perplexity is 41.82325043801341
At time: 789.7823510169983 and batch: 850, loss is 3.72318395614624 and perplexity is 41.3959875124975
At time: 791.1149454116821 and batch: 900, loss is 3.691906747817993 and perplexity is 40.12127522340345
At time: 792.4361524581909 and batch: 950, loss is 3.8083342838287355 and perplexity is 45.07529365283294
At time: 793.7543890476227 and batch: 1000, loss is 3.7796610832214355 and perplexity is 43.80119426003091
At time: 795.0738861560822 and batch: 1050, loss is 3.711354012489319 and perplexity is 40.90916055783164
At time: 796.3902807235718 and batch: 1100, loss is 3.7379992151260377 and perplexity is 42.01384534895843
At time: 797.7092034816742 and batch: 1150, loss is 3.70855842590332 and perplexity is 40.794955167239834
At time: 799.0258529186249 and batch: 1200, loss is 3.7540930891036988 and perplexity is 42.69548124982786
At time: 800.3506217002869 and batch: 1250, loss is 3.726352324485779 and perplexity is 41.52735324633852
At time: 801.66810131073 and batch: 1300, loss is 3.7177621221542356 and perplexity is 41.17215268623021
At time: 802.9885122776031 and batch: 1350, loss is 3.586213970184326 and perplexity is 36.0971519972705
At time: 804.3062200546265 and batch: 1400, loss is 3.627732768058777 and perplexity is 37.62740976990488
At time: 805.6267595291138 and batch: 1450, loss is 3.5404718589782713 and perplexity is 34.48318655377974
At time: 806.947824716568 and batch: 1500, loss is 3.5296791696548464 and perplexity is 34.11302136648471
At time: 808.265869140625 and batch: 1550, loss is 3.537746858596802 and perplexity is 34.38934777069391
At time: 809.5811984539032 and batch: 1600, loss is 3.631026949882507 and perplexity is 37.75156568304462
At time: 810.8937201499939 and batch: 1650, loss is 3.5658424377441404 and perplexity is 35.36923723743589
At time: 812.21302318573 and batch: 1700, loss is 3.587817220687866 and perplexity is 36.15507119146877
At time: 813.536758184433 and batch: 1750, loss is 3.58970823764801 and perplexity is 36.22350572932975
At time: 814.8623676300049 and batch: 1800, loss is 3.5373128271102905 and perplexity is 34.374424949682194
At time: 816.1833963394165 and batch: 1850, loss is 3.5573060131072998 and perplexity is 35.068595437986595
At time: 817.504997253418 and batch: 1900, loss is 3.643796863555908 and perplexity is 38.236741149121485
At time: 818.8277323246002 and batch: 1950, loss is 3.597285408973694 and perplexity is 36.499019929219855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344915629542151 and perplexity of 77.08553346318077
finished 15 epochs...
Completing Train Step...
At time: 823.021258354187 and batch: 50, loss is 3.8525666856765746 and perplexity is 47.11383457861522
At time: 824.4260170459747 and batch: 100, loss is 3.8192401552200317 and perplexity is 45.56956936299382
At time: 825.7518770694733 and batch: 150, loss is 3.7871958684921263 and perplexity is 44.132473344455796
At time: 827.0781879425049 and batch: 200, loss is 3.790240797996521 and perplexity is 44.26705841168042
At time: 828.4062623977661 and batch: 250, loss is 3.787902717590332 and perplexity is 44.1636793711175
At time: 829.7338290214539 and batch: 300, loss is 3.7768976354598998 and perplexity is 43.680319040900706
At time: 831.0586190223694 and batch: 350, loss is 3.802845125198364 and perplexity is 44.82854605357848
At time: 832.3829565048218 and batch: 400, loss is 3.783009243011475 and perplexity is 43.94809344114332
At time: 833.7065601348877 and batch: 450, loss is 3.812906084060669 and perplexity is 45.28184067691643
At time: 835.0323438644409 and batch: 500, loss is 3.8353197717666627 and perplexity is 46.30823336619667
At time: 836.3576698303223 and batch: 550, loss is 3.8062487745285036 and perplexity is 44.98138666469402
At time: 837.6817352771759 and batch: 600, loss is 3.767541823387146 and perplexity is 43.273559932570066
At time: 839.0052843093872 and batch: 650, loss is 3.7800491762161257 and perplexity is 43.81819649569317
At time: 840.3287665843964 and batch: 700, loss is 3.8177207708358765 and perplexity is 45.500384243615656
At time: 841.6556460857391 and batch: 750, loss is 3.7775225687026976 and perplexity is 43.70762485559237
At time: 842.980316400528 and batch: 800, loss is 3.7278511571884154 and perplexity is 41.58964247033999
At time: 844.3056814670563 and batch: 850, loss is 3.7173545455932615 and perplexity is 41.15537530109718
At time: 845.6310920715332 and batch: 900, loss is 3.6865191745758055 and perplexity is 39.905700149256916
At time: 846.9555127620697 and batch: 950, loss is 3.8030404472351074 and perplexity is 44.83730291167374
At time: 848.2790584564209 and batch: 1000, loss is 3.7747383403778074 and perplexity is 43.58610210050713
At time: 849.6049101352692 and batch: 1050, loss is 3.7069139862060547 and perplexity is 40.727925451782205
At time: 850.9313862323761 and batch: 1100, loss is 3.7339840364456176 and perplexity is 41.84549046647821
At time: 852.2585065364838 and batch: 1150, loss is 3.7048313283920287 and perplexity is 40.6431913862504
At time: 853.5811882019043 and batch: 1200, loss is 3.75043176651001 and perplexity is 42.539445143249644
At time: 854.9047529697418 and batch: 1250, loss is 3.7231491136550905 and perplexity is 41.39454519829602
At time: 856.2287242412567 and batch: 1300, loss is 3.715335445404053 and perplexity is 41.07236230901583
At time: 857.5555174350739 and batch: 1350, loss is 3.584165873527527 and perplexity is 36.023297197645576
At time: 858.8811526298523 and batch: 1400, loss is 3.626034278869629 and perplexity is 37.56355426548823
At time: 860.204920053482 and batch: 1450, loss is 3.539431304931641 and perplexity is 34.44732359637911
At time: 861.5343363285065 and batch: 1500, loss is 3.529510726928711 and perplexity is 34.10727576008542
At time: 862.8609888553619 and batch: 1550, loss is 3.53780827999115 and perplexity is 34.39146007725444
At time: 864.1871531009674 and batch: 1600, loss is 3.631651086807251 and perplexity is 37.775135183687
At time: 865.5170016288757 and batch: 1650, loss is 3.5669025325775148 and perplexity is 35.406751864109395
At time: 866.8419225215912 and batch: 1700, loss is 3.589493918418884 and perplexity is 36.21574316736846
At time: 868.1647801399231 and batch: 1750, loss is 3.592203392982483 and perplexity is 36.31400185688041
At time: 869.4948580265045 and batch: 1800, loss is 3.5399935817718506 and perplexity is 34.466697975016324
At time: 870.8222668170929 and batch: 1850, loss is 3.560176215171814 and perplexity is 35.16939397990518
At time: 872.1536967754364 and batch: 1900, loss is 3.6466782331466674 and perplexity is 38.34707421114844
At time: 873.4794087409973 and batch: 1950, loss is 3.5997213649749757 and perplexity is 36.588038314273284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34430414244186 and perplexity of 77.03841106268733
finished 16 epochs...
Completing Train Step...
At time: 877.5199627876282 and batch: 50, loss is 3.8512948417663573 and perplexity is 47.05395122423143
At time: 878.8744106292725 and batch: 100, loss is 3.816943507194519 and perplexity is 45.465032189988065
At time: 880.2004730701447 and batch: 150, loss is 3.7843250894546507 and perplexity is 44.00596044727982
At time: 881.5236489772797 and batch: 200, loss is 3.7867513370513914 and perplexity is 44.11285943232009
At time: 882.8475666046143 and batch: 250, loss is 3.7841824531555175 and perplexity is 43.999684047573666
At time: 884.1718709468842 and batch: 300, loss is 3.772946753501892 and perplexity is 43.50808372123225
At time: 885.49871134758 and batch: 350, loss is 3.798751254081726 and perplexity is 44.645398909881784
At time: 886.8237133026123 and batch: 400, loss is 3.778727068901062 and perplexity is 43.760302417098806
At time: 888.1461827754974 and batch: 450, loss is 3.8085795879364013 and perplexity is 45.08635216381385
At time: 889.4663269519806 and batch: 500, loss is 3.8309288597106934 and perplexity is 46.105343747233086
At time: 890.8391857147217 and batch: 550, loss is 3.8017570877075197 and perplexity is 44.779797439781014
At time: 892.1652989387512 and batch: 600, loss is 3.7633668088912966 and perplexity is 43.09326881346642
At time: 893.4892783164978 and batch: 650, loss is 3.7758524799346924 and perplexity is 43.63469016290282
At time: 894.8137810230255 and batch: 700, loss is 3.813622822761536 and perplexity is 45.314307558321374
At time: 896.1370077133179 and batch: 750, loss is 3.77358286857605 and perplexity is 43.535768673609276
At time: 897.4651391506195 and batch: 800, loss is 3.724155592918396 and perplexity is 41.43622892303554
At time: 898.7897882461548 and batch: 850, loss is 3.7135809326171874 and perplexity is 41.000363504039456
At time: 900.1139307022095 and batch: 900, loss is 3.6829715538024903 and perplexity is 39.76438068059107
At time: 901.4386699199677 and batch: 950, loss is 3.7995491790771485 and perplexity is 44.681036805895744
At time: 902.7619595527649 and batch: 1000, loss is 3.7714523792266847 and perplexity is 43.44311491610166
At time: 904.0852906703949 and batch: 1050, loss is 3.7040880298614502 and perplexity is 40.61299258656708
At time: 905.4107668399811 and batch: 1100, loss is 3.731363444328308 and perplexity is 41.73597406560057
At time: 906.7365984916687 and batch: 1150, loss is 3.702417182922363 and perplexity is 40.54519115090088
At time: 908.0618350505829 and batch: 1200, loss is 3.748060817718506 and perplexity is 42.43870576833695
At time: 909.3858144283295 and batch: 1250, loss is 3.721072721481323 and perplexity is 41.308683061193236
At time: 910.7085108757019 and batch: 1300, loss is 3.7137093257904055 and perplexity is 41.00562800876884
At time: 912.0330107212067 and batch: 1350, loss is 3.5827809381484985 and perplexity is 35.97344179011492
At time: 913.3658354282379 and batch: 1400, loss is 3.6248076725006104 and perplexity is 37.517506817403195
At time: 914.6912183761597 and batch: 1450, loss is 3.5385844612121584 and perplexity is 34.41816444510321
At time: 916.0158007144928 and batch: 1500, loss is 3.529098858833313 and perplexity is 34.09323095388123
At time: 917.3390049934387 and batch: 1550, loss is 3.5375204992294313 and perplexity is 34.38156430065216
At time: 918.6614623069763 and batch: 1600, loss is 3.631743288040161 and perplexity is 37.778618258293704
At time: 919.9881246089935 and batch: 1650, loss is 3.56716881275177 and perplexity is 35.416181235537195
At time: 921.3128724098206 and batch: 1700, loss is 3.589995789527893 and perplexity is 36.23392336423163
At time: 922.6384212970734 and batch: 1750, loss is 3.5931405639648437 and perplexity is 36.34805023775932
At time: 923.9621093273163 and batch: 1800, loss is 3.5409927225112914 and perplexity is 34.50115226659408
At time: 925.2847123146057 and batch: 1850, loss is 3.5612555885314943 and perplexity is 35.20737538121205
At time: 926.608277797699 and batch: 1900, loss is 3.6477144956588745 and perplexity is 38.38683244303107
At time: 927.9344205856323 and batch: 1950, loss is 3.6004048681259153 and perplexity is 36.61305490223221
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34412359193314 and perplexity of 77.02450299397115
finished 17 epochs...
Completing Train Step...
At time: 932.0263366699219 and batch: 50, loss is 3.8494063234329223 and perplexity is 46.96517283088133
At time: 933.3466293811798 and batch: 100, loss is 3.8145108222961426 and perplexity is 45.35456451377768
At time: 934.666793346405 and batch: 150, loss is 3.7816375875473023 and perplexity is 43.887853122560756
At time: 935.9867875576019 and batch: 200, loss is 3.7837436962127686 and perplexity is 43.9803831152377
At time: 937.3047161102295 and batch: 250, loss is 3.781040449142456 and perplexity is 43.86165382303749
At time: 938.621283531189 and batch: 300, loss is 3.769657769203186 and perplexity is 43.36522138178543
At time: 939.9399499893188 and batch: 350, loss is 3.7953972148895265 and perplexity is 44.49590733263423
At time: 941.2598328590393 and batch: 400, loss is 3.775265431404114 and perplexity is 43.60908199951322
At time: 942.5782835483551 and batch: 450, loss is 3.8051695728302004 and perplexity is 44.932868860770604
At time: 943.8962821960449 and batch: 500, loss is 3.82746018409729 and perplexity is 45.945696308387696
At time: 945.211935043335 and batch: 550, loss is 3.7982464170455934 and perplexity is 44.62286594723476
At time: 946.5303275585175 and batch: 600, loss is 3.760101318359375 and perplexity is 42.95277766326998
At time: 947.8505959510803 and batch: 650, loss is 3.7726142835617065 and perplexity is 43.49362099558385
At time: 949.1732983589172 and batch: 700, loss is 3.8104230117797853 and perplexity is 45.16954207397772
At time: 950.4949569702148 and batch: 750, loss is 3.7704751968383787 and perplexity is 43.40068380415655
At time: 951.8150644302368 and batch: 800, loss is 3.721249165534973 and perplexity is 41.31597237574269
At time: 953.1353750228882 and batch: 850, loss is 3.710659246444702 and perplexity is 40.88074813329907
At time: 954.4589698314667 and batch: 900, loss is 3.680194392204285 and perplexity is 39.65410177164234
At time: 955.8034484386444 and batch: 950, loss is 3.7968087673187254 and perplexity is 44.55875998819228
At time: 957.1268427371979 and batch: 1000, loss is 3.768851842880249 and perplexity is 43.33028628782068
At time: 958.4552819728851 and batch: 1050, loss is 3.70187698841095 and perplexity is 40.523294775860236
At time: 959.7769436836243 and batch: 1100, loss is 3.72928747177124 and perplexity is 41.649421200568625
At time: 961.0989201068878 and batch: 1150, loss is 3.7004960107803346 and perplexity is 40.4673716354465
At time: 962.4253301620483 and batch: 1200, loss is 3.746165542602539 and perplexity is 42.358348918563195
At time: 963.7482211589813 and batch: 1250, loss is 3.719404835700989 and perplexity is 41.239842321315386
At time: 965.0711336135864 and batch: 1300, loss is 3.7123148012161256 and perplexity is 40.948484506096776
At time: 966.3920736312866 and batch: 1350, loss is 3.5815807247161864 and perplexity is 35.93029188180154
At time: 967.7148878574371 and batch: 1400, loss is 3.6236976146698 and perplexity is 37.47588332168587
At time: 969.038384437561 and batch: 1450, loss is 3.53772057056427 and perplexity is 34.38844375428341
At time: 970.3610992431641 and batch: 1500, loss is 3.5284974479675295 and perplexity is 34.07273307877613
At time: 971.6838274002075 and batch: 1550, loss is 3.5370077419281007 and perplexity is 34.36393942155471
At time: 973.0060937404633 and batch: 1600, loss is 3.631518602371216 and perplexity is 37.77013089770836
At time: 974.3275904655457 and batch: 1650, loss is 3.5670155477523804 and perplexity is 35.41075359048638
At time: 975.6538283824921 and batch: 1700, loss is 3.58994649887085 and perplexity is 36.232137414357446
At time: 976.9827613830566 and batch: 1750, loss is 3.593374910354614 and perplexity is 36.356569270271
At time: 978.3098421096802 and batch: 1800, loss is 3.5412506914138793 and perplexity is 34.51005363907159
At time: 979.63307762146 and batch: 1850, loss is 3.5615754747390747 and perplexity is 35.218639536529516
At time: 980.9578423500061 and batch: 1900, loss is 3.6479858446121214 and perplexity is 38.3972500831769
At time: 982.2844848632812 and batch: 1950, loss is 3.600407910346985 and perplexity is 36.61316628740868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344117062590843 and perplexity of 77.02400007626777
finished 18 epochs...
Completing Train Step...
At time: 986.3500609397888 and batch: 50, loss is 3.8473684120178224 and perplexity is 46.869559427970614
At time: 987.6737279891968 and batch: 100, loss is 3.8121369600296022 and perplexity is 45.24702671492446
At time: 989.0254952907562 and batch: 150, loss is 3.779141454696655 and perplexity is 43.778439822513356
At time: 990.3498539924622 and batch: 200, loss is 3.781041536331177 and perplexity is 43.861701508958724
At time: 991.6749475002289 and batch: 250, loss is 3.778247194290161 and perplexity is 43.73930799675102
At time: 992.9962792396545 and batch: 300, loss is 3.7667386627197263 and perplexity is 43.238818264731115
At time: 994.3218472003937 and batch: 350, loss is 3.7924408292770386 and perplexity is 44.36455453281618
At time: 995.6466629505157 and batch: 400, loss is 3.772249765396118 and perplexity is 43.47776966986734
At time: 996.970577955246 and batch: 450, loss is 3.8022367000579833 and perplexity is 44.80127953481164
At time: 998.2974283695221 and batch: 500, loss is 3.824478816986084 and perplexity is 45.80891931304257
At time: 999.623064994812 and batch: 550, loss is 3.7952634716033935 and perplexity is 44.48995670170543
At time: 1000.9467737674713 and batch: 600, loss is 3.7573277711868287 and perplexity is 42.833811164090825
At time: 1002.2702987194061 and batch: 650, loss is 3.769869313240051 and perplexity is 43.37439600616041
At time: 1003.5942673683167 and batch: 700, loss is 3.807693600654602 and perplexity is 45.046423919784075
At time: 1004.9189438819885 and batch: 750, loss is 3.7678096389770506 and perplexity is 43.28515081859138
At time: 1006.2437126636505 and batch: 800, loss is 3.718746614456177 and perplexity is 41.212706312695225
At time: 1007.5687212944031 and batch: 850, loss is 3.7081679248809816 and perplexity is 40.779027805568674
At time: 1008.8918726444244 and batch: 900, loss is 3.67780415058136 and perplexity is 39.55943207386676
At time: 1010.2148728370667 and batch: 950, loss is 3.79444833278656 and perplexity is 44.45370598772792
At time: 1011.5402247905731 and batch: 1000, loss is 3.7665944337844848 and perplexity is 43.232582425716714
At time: 1012.8688499927521 and batch: 1050, loss is 3.699952063560486 and perplexity is 40.44536550677966
At time: 1014.193945646286 and batch: 1100, loss is 3.7274640893936155 and perplexity is 41.57354757425139
At time: 1015.517763376236 and batch: 1150, loss is 3.698795671463013 and perplexity is 40.3986218379418
At time: 1016.841658115387 and batch: 1200, loss is 3.74447615146637 and perplexity is 42.2868495115948
At time: 1018.1664960384369 and batch: 1250, loss is 3.7179077196121217 and perplexity is 41.178147683414615
At time: 1019.4929378032684 and batch: 1300, loss is 3.7110031270980834 and perplexity is 40.89480864910899
At time: 1020.8180058002472 and batch: 1350, loss is 3.580435428619385 and perplexity is 35.88916461469718
At time: 1022.1416816711426 and batch: 1400, loss is 3.6226179027557373 and perplexity is 37.43544200039044
At time: 1023.4639928340912 and batch: 1450, loss is 3.5368186378479005 and perplexity is 34.357441674792916
At time: 1024.7877235412598 and batch: 1500, loss is 3.527772698402405 and perplexity is 34.04804782668806
At time: 1026.1137042045593 and batch: 1550, loss is 3.5363536930084227 and perplexity is 34.341471072600804
At time: 1027.4394001960754 and batch: 1600, loss is 3.631100606918335 and perplexity is 37.754346453881105
At time: 1028.7660031318665 and batch: 1650, loss is 3.5666293621063234 and perplexity is 35.397081105962236
At time: 1030.0885863304138 and batch: 1700, loss is 3.5896148252487183 and perplexity is 36.22012216278481
At time: 1031.4128005504608 and batch: 1750, loss is 3.593255672454834 and perplexity is 36.35223444775071
At time: 1032.7414829730988 and batch: 1800, loss is 3.5411439657211305 and perplexity is 34.506370726224375
At time: 1034.0669882297516 and batch: 1850, loss is 3.561533126831055 and perplexity is 35.217148132400986
At time: 1035.3921616077423 and batch: 1900, loss is 3.64782639503479 and perplexity is 38.39112814596357
At time: 1036.7161209583282 and batch: 1950, loss is 3.5999951696395875 and perplexity is 36.59805766144213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34421500272529 and perplexity of 77.03154418662045
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 1040.7755315303802 and batch: 50, loss is 3.8470352268218995 and perplexity is 46.853945785891426
At time: 1042.1000423431396 and batch: 100, loss is 3.8143578720092775 and perplexity is 45.347628050605195
At time: 1043.4219419956207 and batch: 150, loss is 3.7832295894622803 and perplexity is 43.957778314527296
At time: 1044.7405586242676 and batch: 200, loss is 3.7858701848983767 and perplexity is 44.07400641148103
At time: 1046.0645582675934 and batch: 250, loss is 3.7847682142257693 and perplexity is 44.02546489956469
At time: 1047.3911385536194 and batch: 300, loss is 3.7729274368286134 and perplexity is 43.507243297911145
At time: 1048.7173402309418 and batch: 350, loss is 3.798848009109497 and perplexity is 44.64971878567464
At time: 1050.041622877121 and batch: 400, loss is 3.7794757318496703 and perplexity is 43.79307640094126
At time: 1051.3662946224213 and batch: 450, loss is 3.8111495065689085 and perplexity is 45.202369433930684
At time: 1052.6893291473389 and batch: 500, loss is 3.8364710235595703 and perplexity is 46.361576502684976
At time: 1054.0146629810333 and batch: 550, loss is 3.8062184286117553 and perplexity is 44.98002168398997
At time: 1055.3909528255463 and batch: 600, loss is 3.7683163595199587 and perplexity is 43.307089851723994
At time: 1056.7144148349762 and batch: 650, loss is 3.7815818214416503 and perplexity is 43.88540573614792
At time: 1058.0368905067444 and batch: 700, loss is 3.8175988149642945 and perplexity is 45.494835542953105
At time: 1059.3610651493073 and batch: 750, loss is 3.774614839553833 and perplexity is 43.58071951336768
At time: 1060.6856672763824 and batch: 800, loss is 3.726037311553955 and perplexity is 41.51427365327014
At time: 1062.0120677947998 and batch: 850, loss is 3.7145697402954103 and perplexity is 41.040925028750834
At time: 1063.3357717990875 and batch: 900, loss is 3.6808651876449585 and perplexity is 39.68071048581909
At time: 1064.659176826477 and batch: 950, loss is 3.796420497894287 and perplexity is 44.541462542349954
At time: 1065.9849693775177 and batch: 1000, loss is 3.7681174755096434 and perplexity is 43.298477620465135
At time: 1067.3144626617432 and batch: 1050, loss is 3.703216066360474 and perplexity is 40.57759497432191
At time: 1068.6364064216614 and batch: 1100, loss is 3.728645586967468 and perplexity is 41.62269564829464
At time: 1069.954649925232 and batch: 1150, loss is 3.7007074213027953 and perplexity is 40.47592776802292
At time: 1071.2724196910858 and batch: 1200, loss is 3.7469206619262696 and perplexity is 42.390346605868494
At time: 1072.599863767624 and batch: 1250, loss is 3.719198684692383 and perplexity is 41.2313415624762
At time: 1073.9233541488647 and batch: 1300, loss is 3.7101094722747803 and perplexity is 40.85827913093281
At time: 1075.2498252391815 and batch: 1350, loss is 3.5786200189590454 and perplexity is 35.824070182961954
At time: 1076.5761914253235 and batch: 1400, loss is 3.6188491439819335 and perplexity is 37.29462237417924
At time: 1077.9037461280823 and batch: 1450, loss is 3.532494101524353 and perplexity is 34.20918247748527
At time: 1079.2289547920227 and batch: 1500, loss is 3.521374378204346 and perplexity is 33.830892968563866
At time: 1080.5498070716858 and batch: 1550, loss is 3.530924844741821 and perplexity is 34.15554158503261
At time: 1081.8686821460724 and batch: 1600, loss is 3.6262769174575804 and perplexity is 37.572669739091744
At time: 1083.192167520523 and batch: 1650, loss is 3.561390838623047 and perplexity is 35.2121375039872
At time: 1084.5103814601898 and batch: 1700, loss is 3.5824559259414674 and perplexity is 35.9617518821885
At time: 1085.827585697174 and batch: 1750, loss is 3.584769911766052 and perplexity is 36.04506321972374
At time: 1087.1430268287659 and batch: 1800, loss is 3.5336806535720826 and perplexity is 34.24979754418518
At time: 1088.4619324207306 and batch: 1850, loss is 3.554795517921448 and perplexity is 34.98066631696419
At time: 1089.7819831371307 and batch: 1900, loss is 3.6403443002700806 and perplexity is 38.1049540130847
At time: 1091.101220369339 and batch: 1950, loss is 3.5956983518600465 and perplexity is 36.44113984165118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342813181322675 and perplexity of 76.92363537141745
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5a73671b38>
ELAPSED
6697.647419691086


RESULTS SO FAR:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.71282622170062}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.8965078080331692, 'wordvec_dim': 300, 'dropout': 0.6142191105838335, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.89294035452974}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3068549984979113, 'wordvec_dim': 300, 'dropout': 0.6482131084882298, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.32897580816895}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3094886478122048, 'wordvec_dim': 300, 'dropout': 0.6498577281799143, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -76.92363537141745}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3072086347599874, 'wordvec_dim': 300, 'dropout': 0.5864718458692036, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.52309745364064}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.6509491832540216, 'wordvec_dim': 300, 'dropout': 0.14949393525727273, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.09010211379544}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.4079103385246615, 'wordvec_dim': 300, 'dropout': 0.3905826204917884, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -78.71282622170062}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.8965078080331692, 'wordvec_dim': 300, 'dropout': 0.6142191105838335, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.89294035452974}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3068549984979113, 'wordvec_dim': 300, 'dropout': 0.6482131084882298, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -77.32897580816895}, {'params': {'wordvec_source': 'None', 'rnn_dropout': 0.3094886478122048, 'wordvec_dim': 300, 'dropout': 0.6498577281799143, 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE'}, 'best_accuracy': -76.92363537141745}]
