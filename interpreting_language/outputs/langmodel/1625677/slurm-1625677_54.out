FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.743032693862915 and batch: 50, loss is 7.637336473464966 and perplexity is 2074.2117344242097
At time: 2.6468746662139893 and batch: 100, loss is 6.896280546188354 and perplexity is 988.5908508612348
At time: 3.552943229675293 and batch: 150, loss is 6.54649920463562 and perplexity is 696.8005428752291
At time: 4.459280967712402 and batch: 200, loss is 6.406525993347168 and perplexity is 605.7855183750863
At time: 5.365962505340576 and batch: 250, loss is 6.337167329788208 and perplexity is 565.1930362011735
At time: 6.275131940841675 and batch: 300, loss is 6.246785659790039 and perplexity is 516.3504284016379
At time: 7.182204484939575 and batch: 350, loss is 6.173638620376587 and perplexity is 479.9292131279092
At time: 8.088756322860718 and batch: 400, loss is 6.12312578201294 and perplexity is 456.28872682777126
At time: 8.995332956314087 and batch: 450, loss is 6.032945909500122 and perplexity is 416.94149387611105
At time: 9.901445627212524 and batch: 500, loss is 6.005272798538208 and perplexity is 405.5616102604515
At time: 10.804867029190063 and batch: 550, loss is 5.951342849731446 and perplexity is 384.269008285061
At time: 11.715841054916382 and batch: 600, loss is 5.986673984527588 and perplexity is 398.0883575451815
At time: 12.623463869094849 and batch: 650, loss is 6.040209360122681 and perplexity is 419.9809529469183
At time: 13.530466318130493 and batch: 700, loss is 5.954010410308838 and perplexity is 385.29543756515517
At time: 14.438603162765503 and batch: 750, loss is 5.886806802749634 and perplexity is 360.2530865883911
At time: 15.344224691390991 and batch: 800, loss is 5.886199026107788 and perplexity is 360.0341997011165
At time: 16.254696369171143 and batch: 850, loss is 5.915195398330688 and perplexity is 370.62671547095016
At time: 17.161667585372925 and batch: 900, loss is 5.897617797851563 and perplexity is 364.1689097763402
At time: 18.081052541732788 and batch: 950, loss is 5.9122419261932375 and perplexity is 369.5336946911559
At time: 19.000258684158325 and batch: 1000, loss is 5.897325487136841 and perplexity is 364.06247485883506
At time: 19.907772541046143 and batch: 1050, loss is 5.793712387084961 and perplexity is 328.22927951235823
At time: 20.814234972000122 and batch: 1100, loss is 5.885188484191895 and perplexity is 359.67055382181127
At time: 21.72616744041443 and batch: 1150, loss is 5.790259256362915 and perplexity is 327.0978155741504
At time: 22.63782262802124 and batch: 1200, loss is 5.855556688308716 and perplexity is 349.1692243849039
At time: 23.552706480026245 and batch: 1250, loss is 5.7982808780670165 and perplexity is 329.73222249257657
At time: 24.45828080177307 and batch: 1300, loss is 5.817031364440918 and perplexity is 335.97318977419417
At time: 25.363780736923218 and batch: 1350, loss is 5.77642484664917 and perplexity is 322.60376829907926
At time: 26.27734899520874 and batch: 1400, loss is 5.788860359191895 and perplexity is 326.64055926714155
At time: 27.18962836265564 and batch: 1450, loss is 5.760224542617798 and perplexity is 317.41959514323247
At time: 28.09600305557251 and batch: 1500, loss is 5.733146781921387 and perplexity is 308.939906896398
At time: 28.997098207473755 and batch: 1550, loss is 5.703398971557617 and perplexity is 299.884971128799
At time: 29.903608798980713 and batch: 1600, loss is 5.721657056808471 and perplexity is 305.4105865763966
At time: 30.807464361190796 and batch: 1650, loss is 5.726673469543457 and perplexity is 306.94650130253143
At time: 31.718173503875732 and batch: 1700, loss is 5.738365535736084 and perplexity is 310.55640259174123
At time: 32.62429881095886 and batch: 1750, loss is 5.742515325546265 and perplexity is 311.84782409733447
At time: 33.53052306175232 and batch: 1800, loss is 5.7465298461914065 and perplexity is 313.1022599198233
At time: 34.435951471328735 and batch: 1850, loss is 5.716953353881836 and perplexity is 303.9773991927542
At time: 35.34094429016113 and batch: 1900, loss is 5.7161786746978756 and perplexity is 303.7420054183059
At time: 36.24608063697815 and batch: 1950, loss is 5.647760848999024 and perplexity is 283.65560646188817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.20762456849564 and perplexity of 182.65964696095784
finished 1 epochs...
Completing Train Step...
At time: 39.499892711639404 and batch: 50, loss is 5.460899419784546 and perplexity is 235.30897076025406
At time: 40.342634439468384 and batch: 100, loss is 5.37968147277832 and perplexity is 216.95315893084054
At time: 41.18505859375 and batch: 150, loss is 5.284315547943115 and perplexity is 197.2191501885291
At time: 42.029550075531006 and batch: 200, loss is 5.229652156829834 and perplexity is 186.72784021840292
At time: 42.874719858169556 and batch: 250, loss is 5.224046096801758 and perplexity is 185.68396149452863
At time: 43.719353914260864 and batch: 300, loss is 5.228406372070313 and perplexity is 186.49536235963393
At time: 44.5882294178009 and batch: 350, loss is 5.197185754776001 and perplexity is 180.76281449721412
At time: 45.431769609451294 and batch: 400, loss is 5.156047201156616 and perplexity is 173.47737738205
At time: 46.277650594711304 and batch: 450, loss is 5.09761381149292 and perplexity is 163.63098670040262
At time: 47.12394595146179 and batch: 500, loss is 5.088098831176758 and perplexity is 162.0814247990909
At time: 47.967060804367065 and batch: 550, loss is 5.034274654388428 and perplexity is 153.5881477097626
At time: 48.80888891220093 and batch: 600, loss is 5.016477270126343 and perplexity is 150.8788610475704
At time: 49.65301251411438 and batch: 650, loss is 5.080543479919434 and perplexity is 160.86145714782285
At time: 50.49497318267822 and batch: 700, loss is 5.060963582992554 and perplexity is 157.7424410489697
At time: 51.341002225875854 and batch: 750, loss is 5.00243649482727 and perplexity is 148.77520788291037
At time: 52.18439817428589 and batch: 800, loss is 4.986322946548462 and perplexity is 146.39712253938944
At time: 53.02800941467285 and batch: 850, loss is 4.977508888244629 and perplexity is 145.1124397174467
At time: 53.87219262123108 and batch: 900, loss is 4.9792070388793945 and perplexity is 145.35907184905258
At time: 54.724069356918335 and batch: 950, loss is 5.032047319412231 and perplexity is 153.24643615076283
At time: 55.57276368141174 and batch: 1000, loss is 4.999480199813843 and perplexity is 148.33603396141484
At time: 56.41967463493347 and batch: 1050, loss is 4.904800195693969 and perplexity is 134.9359465300359
At time: 57.262017011642456 and batch: 1100, loss is 4.9791450023651125 and perplexity is 145.35005455861932
At time: 58.11190223693848 and batch: 1150, loss is 4.88439621925354 and perplexity is 132.21061500685667
At time: 58.954867124557495 and batch: 1200, loss is 4.962956094741822 and perplexity is 143.0159403092864
At time: 59.79825806617737 and batch: 1250, loss is 4.915939846038818 and perplexity is 136.44748919088698
At time: 60.650245904922485 and batch: 1300, loss is 4.935929288864136 and perplexity is 139.20244172357832
At time: 61.499242067337036 and batch: 1350, loss is 4.839524459838867 and perplexity is 126.40922477173953
At time: 62.34624171257019 and batch: 1400, loss is 4.850623540878296 and perplexity is 127.82006603900741
At time: 63.19054341316223 and batch: 1450, loss is 4.802999668121338 and perplexity is 121.87545566750723
At time: 64.03531432151794 and batch: 1500, loss is 4.7780585193634035 and perplexity is 118.87333558308401
At time: 64.88439083099365 and batch: 1550, loss is 4.773793878555298 and perplexity is 118.3674629543875
At time: 65.74027991294861 and batch: 1600, loss is 4.831687927246094 and perplexity is 125.42248611633747
At time: 66.58564352989197 and batch: 1650, loss is 4.799280824661255 and perplexity is 121.42306163891719
At time: 67.43404245376587 and batch: 1700, loss is 4.822888336181641 and perplexity is 124.32366122349599
At time: 68.28530383110046 and batch: 1750, loss is 4.822108631134033 and perplexity is 124.22676321814394
At time: 69.13107824325562 and batch: 1800, loss is 4.781211500167847 and perplexity is 119.24873242686488
At time: 69.97820901870728 and batch: 1850, loss is 4.789920892715454 and perplexity is 120.29185232502415
At time: 70.82604241371155 and batch: 1900, loss is 4.8571506595611575 and perplexity is 128.65709149066012
At time: 71.67500042915344 and batch: 1950, loss is 4.782337608337403 and perplexity is 119.38309503787798
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.630827863826308 and perplexity of 102.5989669349979
finished 2 epochs...
Completing Train Step...
At time: 74.88110947608948 and batch: 50, loss is 4.752621221542358 and perplexity is 115.8876539693076
At time: 75.72777795791626 and batch: 100, loss is 4.693715209960938 and perplexity is 109.2583443950389
At time: 76.57195806503296 and batch: 150, loss is 4.653366136550903 and perplexity is 104.93762610484877
At time: 77.41762042045593 and batch: 200, loss is 4.63692048072815 and perplexity is 103.22597124405185
At time: 78.263925075531 and batch: 250, loss is 4.642477169036865 and perplexity is 103.80116239057534
At time: 79.10759949684143 and batch: 300, loss is 4.666612596511841 and perplexity is 106.33692558869006
At time: 79.95508742332458 and batch: 350, loss is 4.671258497238159 and perplexity is 106.83210577683488
At time: 80.80103611946106 and batch: 400, loss is 4.6358668327331545 and perplexity is 103.11726468569968
At time: 81.64935207366943 and batch: 450, loss is 4.6207100296020505 and perplexity is 101.56612148654918
At time: 82.49727654457092 and batch: 500, loss is 4.627736654281616 and perplexity is 102.2823017205594
At time: 83.34639072418213 and batch: 550, loss is 4.595262422561645 and perplexity is 99.01411567650769
At time: 84.19181752204895 and batch: 600, loss is 4.570887145996093 and perplexity is 96.62979649597288
At time: 85.03637337684631 and batch: 650, loss is 4.637068252563477 and perplexity is 103.2412262623793
At time: 85.88374757766724 and batch: 700, loss is 4.647423667907715 and perplexity is 104.31588671526258
At time: 86.72936153411865 and batch: 750, loss is 4.606168622970581 and perplexity is 100.09989355866216
At time: 87.62327241897583 and batch: 800, loss is 4.5943355369567875 and perplexity is 98.92238343722286
At time: 88.47161817550659 and batch: 850, loss is 4.579496698379517 and perplexity is 97.46532740316587
At time: 89.31877326965332 and batch: 900, loss is 4.568039264678955 and perplexity is 96.35499778663616
At time: 90.16621971130371 and batch: 950, loss is 4.639714736938476 and perplexity is 103.51481441824676
At time: 91.01475930213928 and batch: 1000, loss is 4.617510385513306 and perplexity is 101.24166539513308
At time: 91.85633754730225 and batch: 1050, loss is 4.537931661605835 and perplexity is 93.49721610804161
At time: 92.70282649993896 and batch: 1100, loss is 4.60153302192688 and perplexity is 99.63694424079613
At time: 93.54829788208008 and batch: 1150, loss is 4.5378610801696775 and perplexity is 93.49061717313583
At time: 94.39500498771667 and batch: 1200, loss is 4.613321170806885 and perplexity is 100.81842945363789
At time: 95.24038624763489 and batch: 1250, loss is 4.587155799865723 and perplexity is 98.21469029711376
At time: 96.09045338630676 and batch: 1300, loss is 4.598270521163941 and perplexity is 99.31240832139684
At time: 96.93566155433655 and batch: 1350, loss is 4.49190523147583 and perplexity is 89.29140471657068
At time: 97.78396844863892 and batch: 1400, loss is 4.503611288070679 and perplexity is 90.34279677493772
At time: 98.62821054458618 and batch: 1450, loss is 4.457013702392578 and perplexity is 86.2296169178971
At time: 99.47957396507263 and batch: 1500, loss is 4.4518884181976315 and perplexity is 85.7887962557336
At time: 100.32971715927124 and batch: 1550, loss is 4.454841690063477 and perplexity is 86.0425283796749
At time: 101.17644333839417 and batch: 1600, loss is 4.519870309829712 and perplexity is 91.82368857609939
At time: 102.02277278900146 and batch: 1650, loss is 4.488133382797241 and perplexity is 88.95524541922231
At time: 102.86911153793335 and batch: 1700, loss is 4.512982797622681 and perplexity is 91.19342476650466
At time: 103.71764588356018 and batch: 1750, loss is 4.512422189712525 and perplexity is 91.14231533873965
At time: 104.5632119178772 and batch: 1800, loss is 4.468704423904419 and perplexity is 87.24361901455572
At time: 105.41008234024048 and batch: 1850, loss is 4.489764204025269 and perplexity is 89.1004338778282
At time: 106.25550937652588 and batch: 1900, loss is 4.575841913223266 and perplexity is 97.10976272336711
At time: 107.10703229904175 and batch: 1950, loss is 4.504580698013306 and perplexity is 90.43041844417283
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483014057957849 and perplexity of 88.50101828189905
finished 3 epochs...
Completing Train Step...
At time: 110.26966285705566 and batch: 50, loss is 4.474421787261963 and perplexity is 87.74385112682182
At time: 111.14118313789368 and batch: 100, loss is 4.429040298461914 and perplexity is 83.850906439557
At time: 111.98762559890747 and batch: 150, loss is 4.395460929870605 and perplexity is 81.08199526444416
At time: 112.8342957496643 and batch: 200, loss is 4.392774820327759 and perplexity is 80.86449239225851
At time: 113.681645154953 and batch: 250, loss is 4.391015157699585 and perplexity is 80.72232328856347
At time: 114.52801394462585 and batch: 300, loss is 4.413808145523071 and perplexity is 82.58335488602397
At time: 115.37371015548706 and batch: 350, loss is 4.418159561157227 and perplexity is 82.94349237328096
At time: 116.2243299484253 and batch: 400, loss is 4.38539535522461 and perplexity is 80.26995208533614
At time: 117.07126832008362 and batch: 450, loss is 4.384904146194458 and perplexity is 80.23053244245688
At time: 117.92170715332031 and batch: 500, loss is 4.403327350616455 and perplexity is 81.72233564548698
At time: 118.76875233650208 and batch: 550, loss is 4.371130762100219 and perplexity is 79.1330617951064
At time: 119.61581039428711 and batch: 600, loss is 4.352530455589294 and perplexity is 77.67476699944292
At time: 120.46817111968994 and batch: 650, loss is 4.411825122833252 and perplexity is 82.41975248673079
At time: 121.31443500518799 and batch: 700, loss is 4.433227672576904 and perplexity is 84.2027577070291
At time: 122.16238856315613 and batch: 750, loss is 4.397489614486695 and perplexity is 81.24665202272394
At time: 123.00767660140991 and batch: 800, loss is 4.380878973007202 and perplexity is 79.90823973160857
At time: 123.85148167610168 and batch: 850, loss is 4.367959003448487 and perplexity is 78.88246844261842
At time: 124.70346307754517 and batch: 900, loss is 4.348824300765991 and perplexity is 77.38742508279485
At time: 125.55011463165283 and batch: 950, loss is 4.430138788223267 and perplexity is 83.9430664108861
At time: 126.39669799804688 and batch: 1000, loss is 4.413447618484497 and perplexity is 82.55358672008818
At time: 127.24466896057129 and batch: 1050, loss is 4.336245574951172 and perplexity is 76.42008657874443
At time: 128.09302234649658 and batch: 1100, loss is 4.392165555953979 and perplexity is 80.81523954346673
At time: 128.9410982131958 and batch: 1150, loss is 4.335888733863831 and perplexity is 76.3928216168736
At time: 129.8362114429474 and batch: 1200, loss is 4.412473335266113 and perplexity is 82.47319531428731
At time: 130.68578386306763 and batch: 1250, loss is 4.397020597457885 and perplexity is 81.20855489419093
At time: 131.5342423915863 and batch: 1300, loss is 4.407928142547608 and perplexity is 82.09918935592749
At time: 132.38037252426147 and batch: 1350, loss is 4.292606854438782 and perplexity is 73.1569296062544
At time: 133.22679829597473 and batch: 1400, loss is 4.309853353500366 and perplexity is 74.42957330360085
At time: 134.07585430145264 and batch: 1450, loss is 4.258755679130554 and perplexity is 70.72192791013654
At time: 134.92427134513855 and batch: 1500, loss is 4.2618863487243654 and perplexity is 70.94368183748014
At time: 135.7719690799713 and batch: 1550, loss is 4.268153429031372 and perplexity is 71.3896877063419
At time: 136.62272453308105 and batch: 1600, loss is 4.340721597671509 and perplexity is 76.7629112958044
At time: 137.4710569381714 and batch: 1650, loss is 4.303878345489502 and perplexity is 73.9861819593985
At time: 138.31686520576477 and batch: 1700, loss is 4.3307199382781985 and perplexity is 75.99898145420721
At time: 139.16498064994812 and batch: 1750, loss is 4.326520910263062 and perplexity is 75.68052866595764
At time: 140.00848126411438 and batch: 1800, loss is 4.283363752365112 and perplexity is 72.48384811103895
At time: 140.85619521141052 and batch: 1850, loss is 4.309736213684082 and perplexity is 74.42085514768951
At time: 141.7045772075653 and batch: 1900, loss is 4.398940773010254 and perplexity is 81.36463938279356
At time: 142.55403351783752 and batch: 1950, loss is 4.329676122665405 and perplexity is 75.91969391879158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.408770042242006 and perplexity of 82.16833774227494
finished 4 epochs...
Completing Train Step...
At time: 145.81976580619812 and batch: 50, loss is 4.297389874458313 and perplexity is 73.5076788166941
At time: 146.69489812850952 and batch: 100, loss is 4.259147453308105 and perplexity is 70.7496403634357
At time: 147.5402820110321 and batch: 150, loss is 4.236230926513672 and perplexity is 69.14674092686413
At time: 148.38829851150513 and batch: 200, loss is 4.2332857942581175 and perplexity is 68.94339421825168
At time: 149.23668837547302 and batch: 250, loss is 4.229769434928894 and perplexity is 68.7013902066964
At time: 150.08502435684204 and batch: 300, loss is 4.247158946990967 and perplexity is 69.90652181703976
At time: 150.93557476997375 and batch: 350, loss is 4.255364484786988 and perplexity is 70.48250230707043
At time: 151.8103003501892 and batch: 400, loss is 4.222044825553894 and perplexity is 68.1727432282097
At time: 152.65858960151672 and batch: 450, loss is 4.235685791969299 and perplexity is 69.1090569221137
At time: 153.51081085205078 and batch: 500, loss is 4.255338726043701 and perplexity is 70.48068678977012
At time: 154.3558542728424 and batch: 550, loss is 4.218357434272766 and perplexity is 67.92182654751618
At time: 155.2061083316803 and batch: 600, loss is 4.205426306724548 and perplexity is 67.04917508871395
At time: 156.0566713809967 and batch: 650, loss is 4.2611122322082515 and perplexity is 70.88878441289881
At time: 156.90516114234924 and batch: 700, loss is 4.2857655334472655 and perplexity is 72.65814767710593
At time: 157.75140643119812 and batch: 750, loss is 4.254914660453796 and perplexity is 70.4508046921822
At time: 158.60291457176208 and batch: 800, loss is 4.2386661148071285 and perplexity is 69.31533145242321
At time: 159.45754766464233 and batch: 850, loss is 4.22468828201294 and perplexity is 68.35319330751099
At time: 160.30682492256165 and batch: 900, loss is 4.206040573120117 and perplexity is 67.09037379601688
At time: 161.15551233291626 and batch: 950, loss is 4.291013622283936 and perplexity is 73.04046643472648
At time: 162.00385189056396 and batch: 1000, loss is 4.2750355052948 and perplexity is 71.882691480503
At time: 162.84892010688782 and batch: 1050, loss is 4.20088005065918 and perplexity is 66.74504422201345
At time: 163.6943118572235 and batch: 1100, loss is 4.249483833312988 and perplexity is 70.06923560567274
At time: 164.54605078697205 and batch: 1150, loss is 4.202525372505188 and perplexity is 66.85495169317232
At time: 165.39311337471008 and batch: 1200, loss is 4.281995811462402 and perplexity is 72.38476227765554
At time: 166.2412028312683 and batch: 1250, loss is 4.264300260543823 and perplexity is 71.11514048935963
At time: 167.0894386768341 and batch: 1300, loss is 4.268057103157044 and perplexity is 71.38281136344574
At time: 167.943195104599 and batch: 1350, loss is 4.155142431259155 and perplexity is 63.76104546708511
At time: 168.78811383247375 and batch: 1400, loss is 4.176507749557495 and perplexity is 65.1379774154719
At time: 169.63605618476868 and batch: 1450, loss is 4.122880201339722 and perplexity is 61.73680085597178
At time: 170.48501062393188 and batch: 1500, loss is 4.127233152389526 and perplexity is 62.00612387776955
At time: 171.33345580101013 and batch: 1550, loss is 4.133098502159118 and perplexity is 62.370880148017335
At time: 172.1800537109375 and batch: 1600, loss is 4.214203162193298 and perplexity is 67.64024608578747
At time: 173.02788519859314 and batch: 1650, loss is 4.175742931365967 and perplexity is 65.08817775165713
At time: 173.8765504360199 and batch: 1700, loss is 4.19795316696167 and perplexity is 66.54997485212733
At time: 174.71417760849 and batch: 1750, loss is 4.199840607643128 and perplexity is 66.67570259651828
At time: 175.5628855228424 and batch: 1800, loss is 4.154690861701965 and perplexity is 63.73225941995801
At time: 176.41278886795044 and batch: 1850, loss is 4.1901058578491215 and perplexity is 66.02978036098892
At time: 177.25926160812378 and batch: 1900, loss is 4.270327081680298 and perplexity is 71.5450328621714
At time: 178.11175346374512 and batch: 1950, loss is 4.200582590103149 and perplexity is 66.72519315664773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37904052734375 and perplexity of 79.76146773231206
finished 5 epochs...
Completing Train Step...
At time: 181.3095977306366 and batch: 50, loss is 4.174589924812317 and perplexity is 65.01317390441733
At time: 182.14679884910583 and batch: 100, loss is 4.14169590473175 and perplexity is 62.90941941571374
At time: 182.99635791778564 and batch: 150, loss is 4.1217699098587035 and perplexity is 61.66829305077003
At time: 183.85335683822632 and batch: 200, loss is 4.116433172225952 and perplexity is 61.340062170565716
At time: 184.69382524490356 and batch: 250, loss is 4.108775100708008 and perplexity is 60.87210968132504
At time: 185.53833055496216 and batch: 300, loss is 4.127763795852661 and perplexity is 62.03903575354319
At time: 186.38389039039612 and batch: 350, loss is 4.136789493560791 and perplexity is 62.60151590582069
At time: 187.2292549610138 and batch: 400, loss is 4.102417497634888 and perplexity is 60.48633656530491
At time: 188.07616186141968 and batch: 450, loss is 4.12381290435791 and perplexity is 61.79440981831362
At time: 188.92396759986877 and batch: 500, loss is 4.138369636535645 and perplexity is 62.70051344592973
At time: 189.77359652519226 and batch: 550, loss is 4.102924313545227 and perplexity is 60.51699977267865
At time: 190.61838245391846 and batch: 600, loss is 4.095444493293762 and perplexity is 60.06603217306171
At time: 191.4646716117859 and batch: 650, loss is 4.149368600845337 and perplexity is 63.393960765751835
At time: 192.3111228942871 and batch: 700, loss is 4.174704537391663 and perplexity is 65.02062565899426
At time: 193.15870785713196 and batch: 750, loss is 4.146827430725097 and perplexity is 63.233070438276386
At time: 194.00488758087158 and batch: 800, loss is 4.134596157073974 and perplexity is 62.464360186161464
At time: 194.87925601005554 and batch: 850, loss is 4.118170623779297 and perplexity is 61.44673019529527
At time: 195.7252209186554 and batch: 900, loss is 4.0947156476974484 and perplexity is 60.02226926016481
At time: 196.57142782211304 and batch: 950, loss is 4.183212184906006 and perplexity is 65.5761580091872
At time: 197.4236283302307 and batch: 1000, loss is 4.169041419029236 and perplexity is 64.65344682978605
At time: 198.27021074295044 and batch: 1050, loss is 4.098836164474488 and perplexity is 60.27010227704336
At time: 199.11604046821594 and batch: 1100, loss is 4.1423820114135745 and perplexity is 62.95259679917641
At time: 199.9624650478363 and batch: 1150, loss is 4.102065095901489 and perplexity is 60.46502483081899
At time: 200.81278252601624 and batch: 1200, loss is 4.176097645759582 and perplexity is 65.11126956041616
At time: 201.66194939613342 and batch: 1250, loss is 4.165204348564148 and perplexity is 64.40584234021858
At time: 202.50835871696472 and batch: 1300, loss is 4.167398176193237 and perplexity is 64.54729275880554
At time: 203.35259366035461 and batch: 1350, loss is 4.053676538467407 and perplexity is 57.608869398892885
At time: 204.19993138313293 and batch: 1400, loss is 4.075819587707519 and perplexity is 58.89873348986061
At time: 205.04950833320618 and batch: 1450, loss is 4.020253114700317 and perplexity is 55.71520637995766
At time: 205.89704942703247 and batch: 1500, loss is 4.0301229429245 and perplexity is 56.26782855329979
At time: 206.74401569366455 and batch: 1550, loss is 4.036305418014527 and perplexity is 56.616780583819924
At time: 207.59292840957642 and batch: 1600, loss is 4.1201397323608395 and perplexity is 61.56784468368579
At time: 208.43728756904602 and batch: 1650, loss is 4.082408027648926 and perplexity is 59.28806539469225
At time: 209.28495693206787 and batch: 1700, loss is 4.099240188598633 and perplexity is 60.294457772100436
At time: 210.13292336463928 and batch: 1750, loss is 4.1048681640625 and perplexity is 60.634750181509965
At time: 210.97890782356262 and batch: 1800, loss is 4.056330399513245 and perplexity is 57.76195838187942
At time: 211.82432675361633 and batch: 1850, loss is 4.095556421279907 and perplexity is 60.07275561934245
At time: 212.66934728622437 and batch: 1900, loss is 4.178571176528931 and perplexity is 65.27252364035195
At time: 213.5144567489624 and batch: 1950, loss is 4.102110466957092 and perplexity is 60.467768255058196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367191474382268 and perplexity of 78.82194708419556
finished 6 epochs...
Completing Train Step...
At time: 216.6892774105072 and batch: 50, loss is 4.075891127586365 and perplexity is 58.90294724884276
At time: 217.53586149215698 and batch: 100, loss is 4.048824405670166 and perplexity is 57.330020567133985
At time: 218.3848752975464 and batch: 150, loss is 4.033366484642029 and perplexity is 56.45063190745369
At time: 219.2313470840454 and batch: 200, loss is 4.025237073898316 and perplexity is 55.993581824959804
At time: 220.07744455337524 and batch: 250, loss is 4.016602096557617 and perplexity is 55.5121600391267
At time: 220.92326521873474 and batch: 300, loss is 4.033862934112549 and perplexity is 56.47866375139599
At time: 221.77017092704773 and batch: 350, loss is 4.044954934120178 and perplexity is 57.10861232629226
At time: 222.61846566200256 and batch: 400, loss is 4.013763346672058 and perplexity is 55.35479836206481
At time: 223.46528673171997 and batch: 450, loss is 4.038307900428772 and perplexity is 56.73026828192687
At time: 224.31157517433167 and batch: 500, loss is 4.058282775878906 and perplexity is 57.874841623688106
At time: 225.15621280670166 and batch: 550, loss is 4.0214870643615725 and perplexity is 55.783998574320684
At time: 226.0066134929657 and batch: 600, loss is 4.0126184511184695 and perplexity is 55.291459164851595
At time: 226.85219645500183 and batch: 650, loss is 4.059828419685363 and perplexity is 57.9643646817509
At time: 227.70120525360107 and batch: 700, loss is 4.0928487920761105 and perplexity is 59.9103208776377
At time: 228.54719877243042 and batch: 750, loss is 4.065097646713257 and perplexity is 58.27059817715094
At time: 229.39464020729065 and batch: 800, loss is 4.048953194618225 and perplexity is 57.3374045156503
At time: 230.24191737174988 and batch: 850, loss is 4.036460967063904 and perplexity is 56.625587955189886
At time: 231.0892379283905 and batch: 900, loss is 4.013044075965881 and perplexity is 55.31499759263634
At time: 231.9356529712677 and batch: 950, loss is 4.1001278591156005 and perplexity is 60.34800314641038
At time: 232.78569674491882 and batch: 1000, loss is 4.091073403358459 and perplexity is 59.804051132847206
At time: 233.6318235397339 and batch: 1050, loss is 4.017106947898864 and perplexity is 55.54019250309612
At time: 234.481201171875 and batch: 1100, loss is 4.0586072444915775 and perplexity is 57.89362324011605
At time: 235.32735872268677 and batch: 1150, loss is 4.020184783935547 and perplexity is 55.711399447363185
At time: 236.17412662506104 and batch: 1200, loss is 4.094750409126282 and perplexity is 60.024355756270694
At time: 237.02038168907166 and batch: 1250, loss is 4.084216055870056 and perplexity is 59.395356853867405
At time: 237.86713314056396 and batch: 1300, loss is 4.090192370414734 and perplexity is 59.751384997337816
At time: 238.71453762054443 and batch: 1350, loss is 3.9720786714553835 and perplexity is 53.09478282063359
At time: 239.56164836883545 and batch: 1400, loss is 4.001676816940307 and perplexity is 54.68977793616995
At time: 240.40709972381592 and batch: 1450, loss is 3.9407798528671263 and perplexity is 51.458715883878135
At time: 241.25500798225403 and batch: 1500, loss is 3.949172368049622 and perplexity is 51.892401248182985
At time: 242.10048127174377 and batch: 1550, loss is 3.9597364187240602 and perplexity is 52.4435010022716
At time: 242.94944429397583 and batch: 1600, loss is 4.045254516601562 and perplexity is 57.12572362907667
At time: 243.79679894447327 and batch: 1650, loss is 4.004665093421936 and perplexity is 54.85345054106316
At time: 244.64300799369812 and batch: 1700, loss is 4.022247219085694 and perplexity is 55.82641916543101
At time: 245.49304604530334 and batch: 1750, loss is 4.027563543319702 and perplexity is 56.12400082995905
At time: 246.34385704994202 and batch: 1800, loss is 3.97811888217926 and perplexity is 53.41645700915015
At time: 247.18907761573792 and batch: 1850, loss is 4.015843744277954 and perplexity is 55.47007822444885
At time: 248.03683948516846 and batch: 1900, loss is 4.096436161994934 and perplexity is 60.12562732160923
At time: 248.88069009780884 and batch: 1950, loss is 4.0268199634552 and perplexity is 56.08228366497069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356590093568314 and perplexity of 77.99073936632317
finished 7 epochs...
Completing Train Step...
At time: 252.1461477279663 and batch: 50, loss is 3.998464298248291 and perplexity is 54.51436790714295
At time: 252.99237942695618 and batch: 100, loss is 3.9778582715988158 and perplexity is 53.40253792909226
At time: 253.83702087402344 and batch: 150, loss is 3.962930474281311 and perplexity is 52.611276257195506
At time: 254.68382477760315 and batch: 200, loss is 3.9521166849136353 and perplexity is 52.04541406886732
At time: 255.53204584121704 and batch: 250, loss is 3.947052116394043 and perplexity is 51.78249285642349
At time: 256.37899684906006 and batch: 300, loss is 3.9608224058151245 and perplexity is 52.50048490366052
At time: 257.22644090652466 and batch: 350, loss is 3.9713705015182494 and perplexity is 53.05719600211964
At time: 258.07740235328674 and batch: 400, loss is 3.9423615884780885 and perplexity is 51.540174373199406
At time: 258.9529058933258 and batch: 450, loss is 3.9686089849472044 and perplexity is 52.91087979644351
At time: 259.8035407066345 and batch: 500, loss is 3.986355447769165 and perplexity is 53.85824205906387
At time: 260.65330934524536 and batch: 550, loss is 3.9555395603179933 and perplexity is 52.22386426876536
At time: 261.50257658958435 and batch: 600, loss is 3.9438130855560303 and perplexity is 51.6150391055248
At time: 262.35009694099426 and batch: 650, loss is 3.989978675842285 and perplexity is 54.05373670063037
At time: 263.19801664352417 and batch: 700, loss is 4.021562690734863 and perplexity is 55.7882174753486
At time: 264.0358669757843 and batch: 750, loss is 3.998183779716492 and perplexity is 54.499077761380555
At time: 264.85803413391113 and batch: 800, loss is 3.9815969276428222 and perplexity is 53.602565334128535
At time: 265.7053470611572 and batch: 850, loss is 3.971307773590088 and perplexity is 53.05386793852272
At time: 266.55456614494324 and batch: 900, loss is 3.9443789768218993 and perplexity is 51.64425587131871
At time: 267.39838433265686 and batch: 950, loss is 4.0352273941040036 and perplexity is 56.55577922698201
At time: 268.2540111541748 and batch: 1000, loss is 4.023389234542846 and perplexity is 55.89021021728602
At time: 269.1032614707947 and batch: 1050, loss is 3.9533998727798463 and perplexity is 52.11224097926309
At time: 269.9519681930542 and batch: 1100, loss is 3.990711278915405 and perplexity is 54.093351143310315
At time: 270.7990882396698 and batch: 1150, loss is 3.9520298194885255 and perplexity is 52.04089331820052
At time: 271.64730620384216 and batch: 1200, loss is 4.029131903648376 and perplexity is 56.21209254806822
At time: 272.493775844574 and batch: 1250, loss is 4.022067761421203 and perplexity is 55.81640158552335
At time: 273.3412253856659 and batch: 1300, loss is 4.027687301635742 and perplexity is 56.13094707160994
At time: 274.1879198551178 and batch: 1350, loss is 3.9081339836120605 and perplexity is 49.805926531776784
At time: 275.03519916534424 and batch: 1400, loss is 3.942240390777588 and perplexity is 51.53392820110048
At time: 275.88299584388733 and batch: 1450, loss is 3.869528012275696 and perplexity is 47.919763202395686
At time: 276.7308084964752 and batch: 1500, loss is 3.8804116296768187 and perplexity is 48.44415201838322
At time: 277.57965207099915 and batch: 1550, loss is 3.8965299224853513 and perplexity is 49.231315872237076
At time: 278.42901396751404 and batch: 1600, loss is 3.9844116306304933 and perplexity is 53.75365316886115
At time: 279.2836649417877 and batch: 1650, loss is 3.939188952445984 and perplexity is 51.376915276670125
At time: 280.1345090866089 and batch: 1700, loss is 3.962394285202026 and perplexity is 52.58307422690515
At time: 280.984530210495 and batch: 1750, loss is 3.964772801399231 and perplexity is 52.70829277879594
At time: 281.835871219635 and batch: 1800, loss is 3.915463924407959 and perplexity is 50.17234228687035
At time: 282.6804168224335 and batch: 1850, loss is 3.953684663772583 and perplexity is 52.127084189611296
At time: 283.5260810852051 and batch: 1900, loss is 4.036205101013183 and perplexity is 56.611101243038036
At time: 284.36783623695374 and batch: 1950, loss is 3.9639179611206057 and perplexity is 52.663254859967225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359436886809593 and perplexity of 78.21307920364893
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 287.5131676197052 and batch: 50, loss is 3.9692224884033203 and perplexity is 52.943350763571566
At time: 288.36173272132874 and batch: 100, loss is 3.968868541717529 and perplexity is 52.924614955968224
At time: 289.2106087207794 and batch: 150, loss is 3.9446037912368777 and perplexity is 51.65586754967685
At time: 290.05724692344666 and batch: 200, loss is 3.945519733428955 and perplexity is 51.70320301319872
At time: 290.9033432006836 and batch: 250, loss is 3.93479953289032 and perplexity is 51.15189465629009
At time: 291.7544572353363 and batch: 300, loss is 3.949008917808533 and perplexity is 51.88392011582872
At time: 292.6055769920349 and batch: 350, loss is 3.9565655899047854 and perplexity is 52.27747499703525
At time: 293.45420122146606 and batch: 400, loss is 3.914374895095825 and perplexity is 50.117732876483004
At time: 294.3036208152771 and batch: 450, loss is 3.9377068519592284 and perplexity is 51.300825925491075
At time: 295.1527202129364 and batch: 500, loss is 3.951082453727722 and perplexity is 51.991614903736156
At time: 296.0018787384033 and batch: 550, loss is 3.9170012283325195 and perplexity is 50.24953174219681
At time: 296.8513298034668 and batch: 600, loss is 3.8984361934661864 and perplexity is 49.32525360797602
At time: 297.6997447013855 and batch: 650, loss is 3.9303909397125243 and perplexity is 50.926883119078816
At time: 298.54714012145996 and batch: 700, loss is 3.9558414936065676 and perplexity is 52.23963477254632
At time: 299.3944854736328 and batch: 750, loss is 3.9198838329315184 and perplexity is 50.39459024620394
At time: 300.2412898540497 and batch: 800, loss is 3.894464678764343 and perplexity is 49.129746125497356
At time: 301.09092140197754 and batch: 850, loss is 3.8901139879226685 and perplexity is 48.91646209185028
At time: 301.9649679660797 and batch: 900, loss is 3.8509519958496092 and perplexity is 47.037821734310214
At time: 302.81068563461304 and batch: 950, loss is 3.9386913871765135 and perplexity is 51.35135826664348
At time: 303.6587862968445 and batch: 1000, loss is 3.9204405117034913 and perplexity is 50.42265165468681
At time: 304.50639271736145 and batch: 1050, loss is 3.843383436203003 and perplexity is 46.683157018418804
At time: 305.35462856292725 and batch: 1100, loss is 3.867568573951721 and perplexity is 47.8259593133812
At time: 306.20522022247314 and batch: 1150, loss is 3.835036106109619 and perplexity is 46.29509917370005
At time: 307.0554006099701 and batch: 1200, loss is 3.8933596563339234 and perplexity is 49.07548663852418
At time: 307.9054944515228 and batch: 1250, loss is 3.8838305854797364 and perplexity is 48.61006389411351
At time: 308.75320959091187 and batch: 1300, loss is 3.8942526292800905 and perplexity is 49.11932929265103
At time: 309.60014605522156 and batch: 1350, loss is 3.777980647087097 and perplexity is 43.727650960184796
At time: 310.4460413455963 and batch: 1400, loss is 3.7937127161026 and perplexity is 44.421017124650106
At time: 311.29561281204224 and batch: 1450, loss is 3.7124210882186888 and perplexity is 40.952837029078644
At time: 312.1471269130707 and batch: 1500, loss is 3.7202032613754272 and perplexity is 41.27278241859431
At time: 312.99574756622314 and batch: 1550, loss is 3.727207131385803 and perplexity is 41.56286629066846
At time: 313.8448255062103 and batch: 1600, loss is 3.812869501113892 and perplexity is 45.28018416404922
At time: 314.6953673362732 and batch: 1650, loss is 3.762138671875 and perplexity is 43.04037686081401
At time: 315.54306149482727 and batch: 1700, loss is 3.7667008113861082 and perplexity is 43.23718164876997
At time: 316.3888478279114 and batch: 1750, loss is 3.7622917032241823 and perplexity is 43.0469638917526
At time: 317.23746156692505 and batch: 1800, loss is 3.7134988260269166 and perplexity is 40.99699724219031
At time: 318.08810448646545 and batch: 1850, loss is 3.732720398902893 and perplexity is 41.792646328680966
At time: 318.9352250099182 and batch: 1900, loss is 3.812433762550354 and perplexity is 45.260458139651725
At time: 319.78399324417114 and batch: 1950, loss is 3.73501624584198 and perplexity is 41.888706074874605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2888087073037795 and perplexity of 72.87959583430002
finished 9 epochs...
Completing Train Step...
At time: 322.98524165153503 and batch: 50, loss is 3.8819232892990114 and perplexity is 48.51743846504625
At time: 323.85636258125305 and batch: 100, loss is 3.8715733528137206 and perplexity is 48.017875739216706
At time: 324.7041554450989 and batch: 150, loss is 3.8434628009796143 and perplexity is 46.686862163774165
At time: 325.55169916152954 and batch: 200, loss is 3.8421585988998412 and perplexity is 46.626012749633446
At time: 326.3959996700287 and batch: 250, loss is 3.8334112644195555 and perplexity is 46.21993804552041
At time: 327.24232244491577 and batch: 300, loss is 3.849697551727295 and perplexity is 46.97885240990333
At time: 328.08603715896606 and batch: 350, loss is 3.862748203277588 and perplexity is 47.595975211280525
At time: 328.9327278137207 and batch: 400, loss is 3.8178715181350706 and perplexity is 45.50724382067104
At time: 329.77628469467163 and batch: 450, loss is 3.8480285739898683 and perplexity is 46.90051114420042
At time: 330.62483286857605 and batch: 500, loss is 3.865826869010925 and perplexity is 47.74273310253723
At time: 331.4707627296448 and batch: 550, loss is 3.83107816696167 and perplexity is 46.11222812329416
At time: 332.3202292919159 and batch: 600, loss is 3.819081573486328 and perplexity is 45.56234343464536
At time: 333.1686234474182 and batch: 650, loss is 3.8504367780685427 and perplexity is 47.0135932541779
At time: 334.01825881004333 and batch: 700, loss is 3.8798208618164063 and perplexity is 48.415541222347315
At time: 334.8682291507721 and batch: 750, loss is 3.8474787521362304 and perplexity is 46.8747313060352
At time: 335.7119369506836 and batch: 800, loss is 3.8253695344924927 and perplexity is 45.84974029670787
At time: 336.55923891067505 and batch: 850, loss is 3.8203316593170165 and perplexity is 45.61933588989445
At time: 337.41258335113525 and batch: 900, loss is 3.782993588447571 and perplexity is 43.94740545829114
At time: 338.25744557380676 and batch: 950, loss is 3.8743900775909426 and perplexity is 48.15331954397109
At time: 339.1081020832062 and batch: 1000, loss is 3.8595455408096315 and perplexity is 47.44378520454185
At time: 339.95548462867737 and batch: 1050, loss is 3.7871345329284667 and perplexity is 44.12976653734014
At time: 340.8004250526428 and batch: 1100, loss is 3.8109005546569823 and perplexity is 45.19111761827513
At time: 341.6477324962616 and batch: 1150, loss is 3.779722323417664 and perplexity is 43.803876735899266
At time: 342.4934768676758 and batch: 1200, loss is 3.8421411180496214 and perplexity is 46.62519769441217
At time: 343.3420226573944 and batch: 1250, loss is 3.835556902885437 and perplexity is 46.31921579146919
At time: 344.1942284107208 and batch: 1300, loss is 3.84713050365448 and perplexity is 46.858410094109
At time: 345.0401728153229 and batch: 1350, loss is 3.729930396080017 and perplexity is 41.67620723567885
At time: 345.8891599178314 and batch: 1400, loss is 3.7503825998306275 and perplexity is 42.537353671404965
At time: 346.73549485206604 and batch: 1450, loss is 3.671034083366394 and perplexity is 39.292516597078745
At time: 347.58541798591614 and batch: 1500, loss is 3.681354126930237 and perplexity is 39.70011668788404
At time: 348.4334135055542 and batch: 1550, loss is 3.690080599784851 and perplexity is 40.04807469341154
At time: 349.2787411212921 and batch: 1600, loss is 3.7812732458114624 and perplexity is 43.87186585856241
At time: 350.1271321773529 and batch: 1650, loss is 3.732037892341614 and perplexity is 41.764132304959425
At time: 350.9770390987396 and batch: 1700, loss is 3.7420227193832396 and perplexity is 42.183228763519736
At time: 351.82309579849243 and batch: 1750, loss is 3.739541435241699 and perplexity is 42.0786899358526
At time: 352.6700279712677 and batch: 1800, loss is 3.6953389501571654 and perplexity is 40.25921614323752
At time: 353.51959347724915 and batch: 1850, loss is 3.7178619384765623 and perplexity is 41.17626254420567
At time: 354.3704831600189 and batch: 1900, loss is 3.7997258567810057 and perplexity is 44.68893164628517
At time: 355.21842670440674 and batch: 1950, loss is 3.725049419403076 and perplexity is 41.473282279040795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.289892862009448 and perplexity of 72.9586514375797
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 358.40412044525146 and batch: 50, loss is 3.8599289989471437 and perplexity is 47.46198139856928
At time: 359.27603673934937 and batch: 100, loss is 3.8789506483078005 and perplexity is 48.37342769088877
At time: 360.1256814002991 and batch: 150, loss is 3.853516101837158 and perplexity is 47.1585864552671
At time: 360.9724700450897 and batch: 200, loss is 3.8624051284790037 and perplexity is 47.5796490323819
At time: 361.82314372062683 and batch: 250, loss is 3.8597889041900633 and perplexity is 47.455332689550204
At time: 362.67177271842957 and batch: 300, loss is 3.8806695556640625 and perplexity is 48.456648635650645
At time: 363.52127027511597 and batch: 350, loss is 3.8922756052017213 and perplexity is 49.02231512719597
At time: 364.3696665763855 and batch: 400, loss is 3.848796215057373 and perplexity is 46.93652772477621
At time: 365.21949100494385 and batch: 450, loss is 3.873957176208496 and perplexity is 48.132478416772976
At time: 366.0926640033722 and batch: 500, loss is 3.883815860748291 and perplexity is 48.60934812924686
At time: 366.94296431541443 and batch: 550, loss is 3.8532380199432374 and perplexity is 47.14547432943788
At time: 367.79121589660645 and batch: 600, loss is 3.831617774963379 and perplexity is 46.137117365179215
At time: 368.6466073989868 and batch: 650, loss is 3.862468304634094 and perplexity is 47.5826550266209
At time: 369.4945499897003 and batch: 700, loss is 3.8874552726745604 and perplexity is 48.7865798846145
At time: 370.34353971481323 and batch: 750, loss is 3.848086733818054 and perplexity is 46.90323894919396
At time: 371.192036151886 and batch: 800, loss is 3.821549987792969 and perplexity is 45.6749490965608
At time: 372.03890228271484 and batch: 850, loss is 3.809401149749756 and perplexity is 45.12340860905096
At time: 372.88540625572205 and batch: 900, loss is 3.7722757911682128 and perplexity is 43.47890122711672
At time: 373.7317078113556 and batch: 950, loss is 3.8637837839126585 and perplexity is 47.64529021193925
At time: 374.5790784358978 and batch: 1000, loss is 3.8478513288497926 and perplexity is 46.892198993198996
At time: 375.42782282829285 and batch: 1050, loss is 3.770597367286682 and perplexity is 43.40598640905778
At time: 376.27529668807983 and batch: 1100, loss is 3.7957865810394287 and perplexity is 44.51323590611979
At time: 377.1226258277893 and batch: 1150, loss is 3.773903684616089 and perplexity is 43.54973788716927
At time: 377.972936630249 and batch: 1200, loss is 3.8206535053253172 and perplexity is 45.63402065404154
At time: 378.817547082901 and batch: 1250, loss is 3.8103547382354734 and perplexity is 45.166458294516865
At time: 379.6662292480469 and batch: 1300, loss is 3.8229641723632812 and perplexity is 45.73958759943703
At time: 380.51371359825134 and batch: 1350, loss is 3.708039050102234 and perplexity is 40.77377275601163
At time: 381.35994267463684 and batch: 1400, loss is 3.7238731145858766 and perplexity is 41.42452573920922
At time: 382.21129179000854 and batch: 1450, loss is 3.6387225723266603 and perplexity is 38.04320822534625
At time: 383.0587148666382 and batch: 1500, loss is 3.646124591827393 and perplexity is 38.32584956235528
At time: 383.90731954574585 and batch: 1550, loss is 3.649900755882263 and perplexity is 38.47084785421469
At time: 384.75404024124146 and batch: 1600, loss is 3.737652368545532 and perplexity is 41.99927551725946
At time: 385.60219526290894 and batch: 1650, loss is 3.6871824932098387 and perplexity is 39.932179124798125
At time: 386.451242685318 and batch: 1700, loss is 3.691393060684204 and perplexity is 40.10067073311384
At time: 387.29954290390015 and batch: 1750, loss is 3.68485857963562 and perplexity is 39.839487936552636
At time: 388.1481251716614 and batch: 1800, loss is 3.646053376197815 and perplexity is 38.32312026003523
At time: 389.00086736679077 and batch: 1850, loss is 3.6647393035888673 and perplexity is 39.04595569563225
At time: 389.8574147224426 and batch: 1900, loss is 3.745172929763794 and perplexity is 42.31632433811814
At time: 390.70993161201477 and batch: 1950, loss is 3.6736737203598024 and perplexity is 39.39637158688665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260591160973838 and perplexity of 70.85185592851971
finished 11 epochs...
Completing Train Step...
At time: 393.89995527267456 and batch: 50, loss is 3.8487539196014406 and perplexity is 46.93454256491813
At time: 394.7907633781433 and batch: 100, loss is 3.848925094604492 and perplexity is 46.94257727303588
At time: 395.6719892024994 and batch: 150, loss is 3.8164565134048463 and perplexity is 45.4428963920998
At time: 396.5205717086792 and batch: 200, loss is 3.8183753585815428 and perplexity is 45.53017798781071
At time: 397.37185883522034 and batch: 250, loss is 3.817669324874878 and perplexity is 45.49804349283405
At time: 398.2211995124817 and batch: 300, loss is 3.834168710708618 and perplexity is 46.25496042818616
At time: 399.06932520866394 and batch: 350, loss is 3.845691819190979 and perplexity is 46.79104409834757
At time: 399.9233138561249 and batch: 400, loss is 3.8024656057357786 and perplexity is 44.81153597590367
At time: 400.76982951164246 and batch: 450, loss is 3.8301116609573365 and perplexity is 46.06768190849951
At time: 401.6180877685547 and batch: 500, loss is 3.843480358123779 and perplexity is 46.687681858939506
At time: 402.4685847759247 and batch: 550, loss is 3.8135407829284667 and perplexity is 45.310590132584224
At time: 403.32069087028503 and batch: 600, loss is 3.796158332824707 and perplexity is 44.52978685726861
At time: 404.17528080940247 and batch: 650, loss is 3.825618953704834 and perplexity is 45.86117752909219
At time: 405.0283393859863 and batch: 700, loss is 3.854629855155945 and perplexity is 47.21113874715333
At time: 405.8763761520386 and batch: 750, loss is 3.8170916748046877 and perplexity is 45.471769134240034
At time: 406.72393584251404 and batch: 800, loss is 3.7919500207901002 and perplexity is 44.34278537561279
At time: 407.5702266693115 and batch: 850, loss is 3.78148588180542 and perplexity is 43.88119558824903
At time: 408.42184114456177 and batch: 900, loss is 3.744856915473938 and perplexity is 42.30295388767108
At time: 409.3221776485443 and batch: 950, loss is 3.8377384996414183 and perplexity is 46.42037594759217
At time: 410.1724832057953 and batch: 1000, loss is 3.823441171646118 and perplexity is 45.76141055427234
At time: 411.02220129966736 and batch: 1050, loss is 3.7481981801986692 and perplexity is 42.44453565461086
At time: 411.8725838661194 and batch: 1100, loss is 3.7740800189971924 and perplexity is 43.55741788035034
At time: 412.72105503082275 and batch: 1150, loss is 3.751712040901184 and perplexity is 42.593942183620044
At time: 413.57272839546204 and batch: 1200, loss is 3.802092399597168 and perplexity is 44.79481515594728
At time: 414.42326760292053 and batch: 1250, loss is 3.792718834877014 and perplexity is 44.37688984197978
At time: 415.27246499061584 and batch: 1300, loss is 3.806810402870178 and perplexity is 45.00665658177931
At time: 416.12176275253296 and batch: 1350, loss is 3.6927048444747923 and perplexity is 40.15330866021485
At time: 416.9720461368561 and batch: 1400, loss is 3.7103739738464356 and perplexity is 40.86908763934879
At time: 417.81766629219055 and batch: 1450, loss is 3.627938666343689 and perplexity is 37.63515798668709
At time: 418.6715724468231 and batch: 1500, loss is 3.63716438293457 and perplexity is 37.98397586145343
At time: 419.5210118293762 and batch: 1550, loss is 3.6424243354797365 and perplexity is 38.1842961477046
At time: 420.3709421157837 and batch: 1600, loss is 3.7326652097702024 and perplexity is 41.790339892422935
At time: 421.22055554389954 and batch: 1650, loss is 3.684140224456787 and perplexity is 39.81087931087882
At time: 422.06913137435913 and batch: 1700, loss is 3.689728021621704 and perplexity is 40.033957105721385
At time: 422.9121413230896 and batch: 1750, loss is 3.684962673187256 and perplexity is 39.843635186194525
At time: 423.76190757751465 and batch: 1800, loss is 3.647990164756775 and perplexity is 38.39741596520987
At time: 424.6106331348419 and batch: 1850, loss is 3.6683203268051146 and perplexity is 39.18603082593528
At time: 425.45927333831787 and batch: 1900, loss is 3.748661789894104 and perplexity is 42.4642179149494
At time: 426.3077404499054 and batch: 1950, loss is 3.6771511602401734 and perplexity is 39.53360857898366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259745185319767 and perplexity of 70.7919423296547
finished 12 epochs...
Completing Train Step...
At time: 429.4953582286835 and batch: 50, loss is 3.8322641372680666 and perplexity is 46.16694829844784
At time: 430.346914768219 and batch: 100, loss is 3.8301045942306517 and perplexity is 46.06735636193274
At time: 431.2248754501343 and batch: 150, loss is 3.7973693799972534 and perplexity is 44.58374719739986
At time: 432.0726361274719 and batch: 200, loss is 3.7981005477905274 and perplexity is 44.61635731773613
At time: 432.92300486564636 and batch: 250, loss is 3.7976666116714477 and perplexity is 44.5970008688291
At time: 433.77273893356323 and batch: 300, loss is 3.8141275453567505 and perplexity is 45.337184485998065
At time: 434.62117409706116 and batch: 350, loss is 3.825441126823425 and perplexity is 45.853022903991715
At time: 435.468496799469 and batch: 400, loss is 3.782205967903137 and perplexity is 43.91280520660084
At time: 436.316260099411 and batch: 450, loss is 3.8105665683746337 and perplexity is 45.17602692508916
At time: 437.1607129573822 and batch: 500, loss is 3.824303822517395 and perplexity is 45.800903706909985
At time: 438.0110602378845 and batch: 550, loss is 3.794666075706482 and perplexity is 44.463386521366616
At time: 438.8610990047455 and batch: 600, loss is 3.7782953119277956 and perplexity is 43.74141267955937
At time: 439.70786452293396 and batch: 650, loss is 3.807783637046814 and perplexity is 45.05047991986693
At time: 440.5586459636688 and batch: 700, loss is 3.8378295278549195 and perplexity is 46.42460170381334
At time: 441.4114682674408 and batch: 750, loss is 3.801086368560791 and perplexity is 44.74977284241326
At time: 442.2622449398041 and batch: 800, loss is 3.776191725730896 and perplexity is 43.64949555930149
At time: 443.11211109161377 and batch: 850, loss is 3.766321988105774 and perplexity is 43.22080549981445
At time: 443.9680082798004 and batch: 900, loss is 3.7301578664779664 and perplexity is 41.68568841742698
At time: 444.81721568107605 and batch: 950, loss is 3.823830008506775 and perplexity is 45.779207737367656
At time: 445.66939425468445 and batch: 1000, loss is 3.8101070165634154 and perplexity is 45.155270969675826
At time: 446.5170884132385 and batch: 1050, loss is 3.735883708000183 and perplexity is 41.92505870723753
At time: 447.3648178577423 and batch: 1100, loss is 3.761584930419922 and perplexity is 43.01655021741292
At time: 448.21590209007263 and batch: 1150, loss is 3.739414191246033 and perplexity is 42.07333601584707
At time: 449.0689380168915 and batch: 1200, loss is 3.7908557271957397 and perplexity is 44.294287889703796
At time: 449.91976618766785 and batch: 1250, loss is 3.7816378974914553 and perplexity is 43.88786672534633
At time: 450.77522444725037 and batch: 1300, loss is 3.7965406942367554 and perplexity is 44.546816584997465
At time: 451.6258111000061 and batch: 1350, loss is 3.682781949043274 and perplexity is 39.756841879485606
At time: 452.4744770526886 and batch: 1400, loss is 3.7010851383209227 and perplexity is 40.49121910248222
At time: 453.3279411792755 and batch: 1450, loss is 3.61978090763092 and perplexity is 37.3293883419274
At time: 454.17547821998596 and batch: 1500, loss is 3.629373517036438 and perplexity is 37.68919757929807
At time: 455.0241012573242 and batch: 1550, loss is 3.635050582885742 and perplexity is 37.90377013072584
At time: 455.873238325119 and batch: 1600, loss is 3.7267092180252077 and perplexity is 41.542176735468125
At time: 456.7228379249573 and batch: 1650, loss is 3.678864989280701 and perplexity is 39.60142051788009
At time: 457.5729169845581 and batch: 1700, loss is 3.6849388694763183 and perplexity is 39.8426867711078
At time: 458.42427611351013 and batch: 1750, loss is 3.681126370429993 and perplexity is 39.6910757578523
At time: 459.27310705184937 and batch: 1800, loss is 3.644861788749695 and perplexity is 38.277482107285635
At time: 460.12150955200195 and batch: 1850, loss is 3.666232132911682 and perplexity is 39.10428817261505
At time: 460.9772551059723 and batch: 1900, loss is 3.7464618635177613 and perplexity is 42.37090244312614
At time: 461.8282084465027 and batch: 1950, loss is 3.674821696281433 and perplexity is 39.44162364203326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260456599745639 and perplexity of 70.84232265718458
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 465.00835514068604 and batch: 50, loss is 3.8275970220565796 and perplexity is 45.951983853886304
At time: 465.861958026886 and batch: 100, loss is 3.8408702850341796 and perplexity is 46.56598248811966
At time: 466.7092504501343 and batch: 150, loss is 3.813553447723389 and perplexity is 45.31116398554991
At time: 467.5562376976013 and batch: 200, loss is 3.8184558010101317 and perplexity is 45.53384069321862
At time: 468.4057698249817 and batch: 250, loss is 3.8244640684127806 and perplexity is 45.80824370182029
At time: 469.25732421875 and batch: 300, loss is 3.8426519346237185 and perplexity is 46.64902070224063
At time: 470.1098675727844 and batch: 350, loss is 3.8564956855773924 and perplexity is 47.299308955808655
At time: 470.9594156742096 and batch: 400, loss is 3.819361128807068 and perplexity is 45.57508241071921
At time: 471.81085777282715 and batch: 450, loss is 3.8501100826263426 and perplexity is 46.99823663614545
At time: 472.6603207588196 and batch: 500, loss is 3.8577082443237303 and perplexity is 47.35669693269396
At time: 473.53447914123535 and batch: 550, loss is 3.8285883617401124 and perplexity is 45.9975604662374
At time: 474.3869254589081 and batch: 600, loss is 3.804453191757202 and perplexity is 44.90069133102601
At time: 475.23675560951233 and batch: 650, loss is 3.830981078147888 and perplexity is 46.10775135909021
At time: 476.09108567237854 and batch: 700, loss is 3.8570070552825926 and perplexity is 47.323502574900274
At time: 476.94000458717346 and batch: 750, loss is 3.818571729660034 and perplexity is 45.539119675881814
At time: 477.7500343322754 and batch: 800, loss is 3.7934838819503782 and perplexity is 44.41085324182166
At time: 478.60880994796753 and batch: 850, loss is 3.778626141548157 and perplexity is 43.75588602848447
At time: 479.4572787284851 and batch: 900, loss is 3.7381529903411863 and perplexity is 42.0203065338385
At time: 480.3245680332184 and batch: 950, loss is 3.834865608215332 and perplexity is 46.287206629625324
At time: 481.173709154129 and batch: 1000, loss is 3.8171873044967652 and perplexity is 45.47611779344772
At time: 482.0248644351959 and batch: 1050, loss is 3.7441779518127443 and perplexity is 42.27424146766812
At time: 482.87436842918396 and batch: 1100, loss is 3.7650723552703855 and perplexity is 43.16682909445823
At time: 483.7222273349762 and batch: 1150, loss is 3.743575749397278 and perplexity is 42.24879148113508
At time: 484.5720052719116 and batch: 1200, loss is 3.793336901664734 and perplexity is 44.40432620161135
At time: 485.4191153049469 and batch: 1250, loss is 3.780952353477478 and perplexity is 43.85778997167369
At time: 486.26627564430237 and batch: 1300, loss is 3.7929820823669433 and perplexity is 44.38857348461888
At time: 487.1192865371704 and batch: 1350, loss is 3.6787604093551636 and perplexity is 39.597279220823204
At time: 487.965722322464 and batch: 1400, loss is 3.698389048576355 and perplexity is 40.38219817305837
At time: 488.81696939468384 and batch: 1450, loss is 3.6168105459213256 and perplexity is 37.21867107272777
At time: 489.6660912036896 and batch: 1500, loss is 3.627800693511963 and perplexity is 37.62996571557162
At time: 490.51390504837036 and batch: 1550, loss is 3.6337613582611086 and perplexity is 37.85493514330508
At time: 491.3632402420044 and batch: 1600, loss is 3.72332097530365 and perplexity is 41.40165994443366
At time: 492.21235752105713 and batch: 1650, loss is 3.6700510358810425 and perplexity is 39.253909167022506
At time: 493.0554099082947 and batch: 1700, loss is 3.669881534576416 and perplexity is 39.247256142071144
At time: 493.88795232772827 and batch: 1750, loss is 3.664696063995361 and perplexity is 39.04426740088076
At time: 494.70767974853516 and batch: 1800, loss is 3.6238594007492066 and perplexity is 37.48194688840791
At time: 495.5546700954437 and batch: 1850, loss is 3.6459282302856444 and perplexity is 38.31832457827932
At time: 496.40507650375366 and batch: 1900, loss is 3.7298857307434083 and perplexity is 41.67434579542533
At time: 497.2530653476715 and batch: 1950, loss is 3.663330078125 and perplexity is 38.99096989340102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245937613553779 and perplexity of 69.82119476146667
finished 14 epochs...
Completing Train Step...
At time: 500.4689633846283 and batch: 50, loss is 3.8284137439727783 and perplexity is 45.989529176149354
At time: 501.318838596344 and batch: 100, loss is 3.831379337310791 and perplexity is 46.12611785061882
At time: 502.1654419898987 and batch: 150, loss is 3.798733186721802 and perplexity is 44.644592292677466
At time: 503.01217103004456 and batch: 200, loss is 3.7964183473587036 and perplexity is 44.54136675445282
At time: 503.8627173900604 and batch: 250, loss is 3.8019892501831056 and perplexity is 44.79019483530671
At time: 504.7107779979706 and batch: 300, loss is 3.8165355110168457 and perplexity is 45.44648641419683
At time: 505.55916380882263 and batch: 350, loss is 3.8297035980224607 and perplexity is 46.04888722998364
At time: 506.4093680381775 and batch: 400, loss is 3.793869457244873 and perplexity is 44.42798027130667
At time: 507.25949907302856 and batch: 450, loss is 3.8258711290359497 and perplexity is 45.87274404505464
At time: 508.1078231334686 and batch: 500, loss is 3.836091136932373 and perplexity is 46.343967704641045
At time: 508.95975613594055 and batch: 550, loss is 3.8088437128067016 and perplexity is 45.09826216352576
At time: 509.80777645111084 and batch: 600, loss is 3.7865795516967773 and perplexity is 44.105282139972026
At time: 510.6560525894165 and batch: 650, loss is 3.8123896169662475 and perplexity is 45.2584601343921
At time: 511.5018482208252 and batch: 700, loss is 3.84086163520813 and perplexity is 46.56557970221332
At time: 512.3511712551117 and batch: 750, loss is 3.804522366523743 and perplexity is 44.903797433297065
At time: 513.2036077976227 and batch: 800, loss is 3.7796102571487427 and perplexity is 43.79896807392205
At time: 514.0509729385376 and batch: 850, loss is 3.765430002212524 and perplexity is 43.18227033997821
At time: 514.8987283706665 and batch: 900, loss is 3.7254870176315307 and perplexity is 41.491434885378816
At time: 515.7454655170441 and batch: 950, loss is 3.8226371383666993 and perplexity is 45.72463164498845
At time: 516.6173958778381 and batch: 1000, loss is 3.80624098777771 and perplexity is 44.9810364072094
At time: 517.4674217700958 and batch: 1050, loss is 3.7341178131103514 and perplexity is 41.85108879108122
At time: 518.3135113716125 and batch: 1100, loss is 3.756108436584473 and perplexity is 42.78161424520943
At time: 519.1667749881744 and batch: 1150, loss is 3.735918560028076 and perplexity is 41.926519906015734
At time: 520.0205180644989 and batch: 1200, loss is 3.786614599227905 and perplexity is 44.10682794830896
At time: 520.867347240448 and batch: 1250, loss is 3.775010542869568 and perplexity is 43.59796796099014
At time: 521.7165055274963 and batch: 1300, loss is 3.787536425590515 and perplexity is 44.14750553103634
At time: 522.5657076835632 and batch: 1350, loss is 3.6745686435699465 and perplexity is 39.43164409495419
At time: 523.413144826889 and batch: 1400, loss is 3.6947495985031127 and perplexity is 40.235496297964225
At time: 524.2619524002075 and batch: 1450, loss is 3.6147778844833374 and perplexity is 37.14309495162014
At time: 525.1108720302582 and batch: 1500, loss is 3.6274077796936037 and perplexity is 37.61518328635812
At time: 525.9608066082001 and batch: 1550, loss is 3.634379096031189 and perplexity is 37.878326790735244
At time: 526.8077704906464 and batch: 1600, loss is 3.724468502998352 and perplexity is 41.449196765519446
At time: 527.6543545722961 and batch: 1650, loss is 3.6719843101501466 and perplexity is 39.32987114358492
At time: 528.5050709247589 and batch: 1700, loss is 3.6731761503219604 and perplexity is 39.376774008773495
At time: 529.3589103221893 and batch: 1750, loss is 3.6691685152053832 and perplexity is 39.21928206239746
At time: 530.2004408836365 and batch: 1800, loss is 3.6289195346832277 and perplexity is 37.67209123197412
At time: 531.052273273468 and batch: 1850, loss is 3.6510511016845704 and perplexity is 38.5151280964674
At time: 531.925281047821 and batch: 1900, loss is 3.735198483467102 and perplexity is 41.8963404688049
At time: 532.7858240604401 and batch: 1950, loss is 3.667719144821167 and perplexity is 39.16247997006476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244729117460029 and perplexity of 69.73686708543312
finished 15 epochs...
Completing Train Step...
At time: 535.9521346092224 and batch: 50, loss is 3.823993501663208 and perplexity is 45.78669293641238
At time: 536.8240728378296 and batch: 100, loss is 3.825266180038452 and perplexity is 45.84500176670991
At time: 537.6734008789062 and batch: 150, loss is 3.791940441131592 and perplexity is 44.342360588906246
At time: 538.5472984313965 and batch: 200, loss is 3.7887341451644896 and perplexity is 44.20041354070756
At time: 539.3955478668213 and batch: 250, loss is 3.7936990737915037 and perplexity is 44.420411123448915
At time: 540.2463729381561 and batch: 300, loss is 3.8079545497894287 and perplexity is 45.058180278972145
At time: 541.0947313308716 and batch: 350, loss is 3.8213077449798583 and perplexity is 45.66388600843386
At time: 541.9484593868256 and batch: 400, loss is 3.7854251289367675 and perplexity is 44.05439537650332
At time: 542.7986907958984 and batch: 450, loss is 3.8174933099746706 and perplexity is 45.490035864000696
At time: 543.648624420166 and batch: 500, loss is 3.827996530532837 and perplexity is 45.97034572855483
At time: 544.4985611438751 and batch: 550, loss is 3.800884313583374 and perplexity is 44.74073184149254
At time: 545.3506708145142 and batch: 600, loss is 3.7792815923690797 and perplexity is 43.784575261065456
At time: 546.1998767852783 and batch: 650, loss is 3.804661207199097 and perplexity is 44.91003233967795
At time: 547.0492296218872 and batch: 700, loss is 3.834203004837036 and perplexity is 46.25654672893929
At time: 547.8975024223328 and batch: 750, loss is 3.7982692193984984 and perplexity is 44.623883465172575
At time: 548.7452247142792 and batch: 800, loss is 3.77338258266449 and perplexity is 43.52704994564334
At time: 549.5944037437439 and batch: 850, loss is 3.7594813108444214 and perplexity is 42.926154872348675
At time: 550.4422795772552 and batch: 900, loss is 3.719757595062256 and perplexity is 41.254392627978966
At time: 551.2888495922089 and batch: 950, loss is 3.8172312068939207 and perplexity is 45.47811434785862
At time: 552.1369605064392 and batch: 1000, loss is 3.801201786994934 and perplexity is 44.7549380891996
At time: 552.9847464561462 and batch: 1050, loss is 3.729590253829956 and perplexity is 41.66203380740324
At time: 553.8343229293823 and batch: 1100, loss is 3.751887712478638 and perplexity is 42.60142538590714
At time: 554.6819183826447 and batch: 1150, loss is 3.7320375776290895 and perplexity is 41.76411916126598
At time: 555.5261585712433 and batch: 1200, loss is 3.78332820892334 and perplexity is 43.96211362070332
At time: 556.3746485710144 and batch: 1250, loss is 3.7720592164993287 and perplexity is 43.46948581808637
At time: 557.2225074768066 and batch: 1300, loss is 3.7847495651245118 and perplexity is 44.02464387186761
At time: 558.0700154304504 and batch: 1350, loss is 3.672143578529358 and perplexity is 39.33613564727197
At time: 558.9225568771362 and batch: 1400, loss is 3.6925350427627563 and perplexity is 40.14649113849025
At time: 559.7717137336731 and batch: 1450, loss is 3.6131234645843504 and perplexity is 37.08169548048037
At time: 560.6183018684387 and batch: 1500, loss is 3.6263672971725462 and perplexity is 37.57606569973393
At time: 561.4670143127441 and batch: 1550, loss is 3.633740634918213 and perplexity is 37.85415067063229
At time: 562.3166456222534 and batch: 1600, loss is 3.7241595363616944 and perplexity is 41.43639232477699
At time: 563.1704931259155 and batch: 1650, loss is 3.6719430446624757 and perplexity is 39.32824821075793
At time: 564.0195937156677 and batch: 1700, loss is 3.673703155517578 and perplexity is 39.397531242367336
At time: 564.8658347129822 and batch: 1750, loss is 3.670144963264465 and perplexity is 39.25759635716102
At time: 565.7123260498047 and batch: 1800, loss is 3.630064687728882 and perplexity is 37.71525625254483
At time: 566.561861038208 and batch: 1850, loss is 3.6522531080245972 and perplexity is 38.56145135947682
At time: 567.4139394760132 and batch: 1900, loss is 3.7364029932022094 and perplexity is 41.946835423492175
At time: 568.2567336559296 and batch: 1950, loss is 3.668411364555359 and perplexity is 39.189598396412016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244492073946221 and perplexity of 69.72033837250673
finished 16 epochs...
Completing Train Step...
At time: 571.4360795021057 and batch: 50, loss is 3.8195114374160766 and perplexity is 45.58193325281919
At time: 572.3127369880676 and batch: 100, loss is 3.819992208480835 and perplexity is 45.603852996169856
At time: 573.1603510379791 and batch: 150, loss is 3.786443409919739 and perplexity is 44.099277977202675
At time: 574.0060396194458 and batch: 200, loss is 3.782885956764221 and perplexity is 43.94267557960978
At time: 574.8534610271454 and batch: 250, loss is 3.787629580497742 and perplexity is 44.15161827937675
At time: 575.6999957561493 and batch: 300, loss is 3.801858859062195 and perplexity is 44.78435497233773
At time: 576.5448093414307 and batch: 350, loss is 3.815340509414673 and perplexity is 45.39221022664329
At time: 577.3916115760803 and batch: 400, loss is 3.77945538520813 and perplexity is 43.792185367978576
At time: 578.2389707565308 and batch: 450, loss is 3.8115993785858153 and perplexity is 45.22270928985986
At time: 579.0851349830627 and batch: 500, loss is 3.822174139022827 and perplexity is 45.703466070739616
At time: 579.931530714035 and batch: 550, loss is 3.795126190185547 and perplexity is 44.48384947658335
At time: 580.8043410778046 and batch: 600, loss is 3.774006586074829 and perplexity is 43.5542194493013
At time: 581.6528465747833 and batch: 650, loss is 3.7990428400039673 and perplexity is 44.658418777809594
At time: 582.4997527599335 and batch: 700, loss is 3.829274444580078 and perplexity is 46.029129431377875
At time: 583.3539745807648 and batch: 750, loss is 3.793627686500549 and perplexity is 44.417240183819466
At time: 584.2007265090942 and batch: 800, loss is 3.768800597190857 and perplexity is 43.32806585432262
At time: 585.0458943843842 and batch: 850, loss is 3.7551054430007933 and perplexity is 42.7387260724985
At time: 585.8940334320068 and batch: 900, loss is 3.715553560256958 and perplexity is 41.081321778340474
At time: 586.7401583194733 and batch: 950, loss is 3.813245663642883 and perplexity is 45.29722007657265
At time: 587.5942447185516 and batch: 1000, loss is 3.7973668003082275 and perplexity is 44.583632185344825
At time: 588.4432377815247 and batch: 1050, loss is 3.726099720001221 and perplexity is 41.51686457547509
At time: 589.2878727912903 and batch: 1100, loss is 3.7485694456100465 and perplexity is 42.4602967681985
At time: 590.1368815898895 and batch: 1150, loss is 3.728876442909241 and perplexity is 41.632305604112666
At time: 590.982038974762 and batch: 1200, loss is 3.7805900955200196 and perplexity is 43.841905015659485
At time: 591.8291299343109 and batch: 1250, loss is 3.7694982194900515 and perplexity is 43.35830302507954
At time: 592.6825442314148 and batch: 1300, loss is 3.782326993942261 and perplexity is 43.91812012109685
At time: 593.5376949310303 and batch: 1350, loss is 3.6699097681045534 and perplexity is 39.24836424622451
At time: 594.3859584331512 and batch: 1400, loss is 3.690412163734436 and perplexity is 40.06135539280907
At time: 595.2348742485046 and batch: 1450, loss is 3.6112968635559084 and perplexity is 37.0140238407381
At time: 596.0839328765869 and batch: 1500, loss is 3.624879627227783 and perplexity is 37.520206476495886
At time: 596.9315643310547 and batch: 1550, loss is 3.6324841022491454 and perplexity is 37.80661556461598
At time: 597.7902221679688 and batch: 1600, loss is 3.72315824508667 and perplexity is 41.394923191479066
At time: 598.6426050662994 and batch: 1650, loss is 3.6711047077178955 and perplexity is 39.295291703576176
At time: 599.4958760738373 and batch: 1700, loss is 3.6732180643081667 and perplexity is 39.378424480924835
At time: 600.348658323288 and batch: 1750, loss is 3.669936919212341 and perplexity is 39.2494298972594
At time: 601.1973083019257 and batch: 1800, loss is 3.6299278020858763 and perplexity is 37.71009392877365
At time: 602.0454547405243 and batch: 1850, loss is 3.652213706970215 and perplexity is 38.55993202756658
At time: 602.8895206451416 and batch: 1900, loss is 3.736355490684509 and perplexity is 41.94484289052554
At time: 603.7363858222961 and batch: 1950, loss is 3.6680896186828615 and perplexity is 39.176991333127184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244553392986918 and perplexity of 69.7246136878506
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 606.9011180400848 and batch: 50, loss is 3.8185856103897096 and perplexity is 45.539751796478825
At time: 607.771874666214 and batch: 100, loss is 3.824292321205139 and perplexity is 45.800376939444114
At time: 608.619047164917 and batch: 150, loss is 3.7934157180786134 and perplexity is 44.40782612928735
At time: 609.4653580188751 and batch: 200, loss is 3.789804849624634 and perplexity is 44.24776446552539
At time: 610.3102328777313 and batch: 250, loss is 3.79673779964447 and perplexity is 44.55559786883367
At time: 611.1563169956207 and batch: 300, loss is 3.809312400817871 and perplexity is 45.11940413243305
At time: 612.0075814723969 and batch: 350, loss is 3.8229136848449707 and perplexity is 45.73727837946447
At time: 612.8512101173401 and batch: 400, loss is 3.7893510627746583 and perplexity is 44.227689966986325
At time: 613.6977705955505 and batch: 450, loss is 3.8254706144332884 and perplexity is 45.85437501997739
At time: 614.5435767173767 and batch: 500, loss is 3.8377512216567995 and perplexity is 46.420966512085556
At time: 615.3905098438263 and batch: 550, loss is 3.8127137088775633 and perplexity is 45.27313041237108
At time: 616.2353875637054 and batch: 600, loss is 3.7915346479415892 and perplexity is 44.32437041134326
At time: 617.0812735557556 and batch: 650, loss is 3.813460278511047 and perplexity is 45.30694257674681
At time: 617.9265351295471 and batch: 700, loss is 3.8418009233474733 and perplexity is 46.609338746887836
At time: 618.7731862068176 and batch: 750, loss is 3.80524178981781 and perplexity is 44.93611389437625
At time: 619.6164791584015 and batch: 800, loss is 3.7807147312164306 and perplexity is 43.84736962255857
At time: 620.4619770050049 and batch: 850, loss is 3.769954128265381 and perplexity is 43.37807496266952
At time: 621.3084738254547 and batch: 900, loss is 3.726370105743408 and perplexity is 41.5280916614702
At time: 622.1560175418854 and batch: 950, loss is 3.8271954536437987 and perplexity is 45.93353469321397
At time: 623.0037579536438 and batch: 1000, loss is 3.8092460203170777 and perplexity is 45.11640918319545
At time: 623.8760545253754 and batch: 1050, loss is 3.7409893894195556 and perplexity is 42.139662082528496
At time: 624.7266523838043 and batch: 1100, loss is 3.75836941242218 and perplexity is 42.87845187383229
At time: 625.5765242576599 and batch: 1150, loss is 3.734148898124695 and perplexity is 41.85238975299668
At time: 626.4230086803436 and batch: 1200, loss is 3.788470115661621 and perplexity is 44.18874486799853
At time: 627.2751865386963 and batch: 1250, loss is 3.775031108856201 and perplexity is 43.59886460543662
At time: 628.1239514350891 and batch: 1300, loss is 3.780274958610535 and perplexity is 43.828090989975934
At time: 628.9721810817719 and batch: 1350, loss is 3.6613032007217408 and perplexity is 38.9120200154834
At time: 629.82164478302 and batch: 1400, loss is 3.6821980714797973 and perplexity is 39.73363552701103
At time: 630.669763803482 and batch: 1450, loss is 3.601383476257324 and perplexity is 36.6489022728786
At time: 631.516542673111 and batch: 1500, loss is 3.61299955368042 and perplexity is 37.077100938736905
At time: 632.3664982318878 and batch: 1550, loss is 3.623345694541931 and perplexity is 37.46269712441551
At time: 633.2165696620941 and batch: 1600, loss is 3.7155319595336915 and perplexity is 41.08043440166134
At time: 634.0674481391907 and batch: 1650, loss is 3.6617377328872682 and perplexity is 38.92893221398678
At time: 634.9188678264618 and batch: 1700, loss is 3.6634073448181153 and perplexity is 38.993982713099854
At time: 635.7699460983276 and batch: 1750, loss is 3.6611568975448607 and perplexity is 38.9063274797645
At time: 636.616795539856 and batch: 1800, loss is 3.6199966049194336 and perplexity is 37.337441058217934
At time: 637.4638330936432 and batch: 1850, loss is 3.643492202758789 and perplexity is 38.225093687436335
At time: 638.3104021549225 and batch: 1900, loss is 3.728502144813538 and perplexity is 41.61672562736503
At time: 639.1589331626892 and batch: 1950, loss is 3.665178503990173 and perplexity is 39.06310846151825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2416126339934594 and perplexity of 69.51987159920374
finished 18 epochs...
Completing Train Step...
At time: 642.3510789871216 and batch: 50, loss is 3.822513709068298 and perplexity is 45.718988234073144
At time: 643.1997103691101 and batch: 100, loss is 3.8240520906448365 and perplexity is 45.78937561071047
At time: 644.0485887527466 and batch: 150, loss is 3.7906668376922608 and perplexity is 44.28592195380097
At time: 644.8956246376038 and batch: 200, loss is 3.783668727874756 and perplexity is 43.977086102597724
At time: 645.7910490036011 and batch: 250, loss is 3.79014289855957 and perplexity is 44.2627249037139
At time: 646.6393930912018 and batch: 300, loss is 3.800530433654785 and perplexity is 44.72490179563642
At time: 647.4862651824951 and batch: 350, loss is 3.812067356109619 and perplexity is 45.243877454099234
At time: 648.3365912437439 and batch: 400, loss is 3.778110499382019 and perplexity is 43.73332946468897
At time: 649.1854000091553 and batch: 450, loss is 3.8136185789108277 and perplexity is 45.31411525157321
At time: 650.0371649265289 and batch: 500, loss is 3.8270116233825684 and perplexity is 45.92509149561347
At time: 650.8886392116547 and batch: 550, loss is 3.801896414756775 and perplexity is 44.786036911478035
At time: 651.7409560680389 and batch: 600, loss is 3.7812169408798217 and perplexity is 43.86939572569528
At time: 652.5874977111816 and batch: 650, loss is 3.8039254903793336 and perplexity is 44.877003424963405
At time: 653.4360399246216 and batch: 700, loss is 3.833586869239807 and perplexity is 46.22805520211799
At time: 654.285238981247 and batch: 750, loss is 3.7977514982223513 and perplexity is 44.600786715094934
At time: 655.1329321861267 and batch: 800, loss is 3.773842620849609 and perplexity is 43.5470786573368
At time: 655.9832792282104 and batch: 850, loss is 3.762255597114563 and perplexity is 43.04540966141431
At time: 656.8342604637146 and batch: 900, loss is 3.719357171058655 and perplexity is 41.23787668582726
At time: 657.681129693985 and batch: 950, loss is 3.8197821235656737 and perplexity is 45.594273320890004
At time: 658.5308685302734 and batch: 1000, loss is 3.8022939920425416 and perplexity is 44.80384636255557
At time: 659.389631986618 and batch: 1050, loss is 3.733562593460083 and perplexity is 41.827858693699305
At time: 660.2427864074707 and batch: 1100, loss is 3.7519195461273194 and perplexity is 42.602781566302184
At time: 661.0974588394165 and batch: 1150, loss is 3.7292981147766113 and perplexity is 41.64986447794107
At time: 661.949827671051 and batch: 1200, loss is 3.7839316654205324 and perplexity is 43.988650850024456
At time: 662.8044037818909 and batch: 1250, loss is 3.771018190383911 and perplexity is 43.424256494664114
At time: 663.6597709655762 and batch: 1300, loss is 3.7780861711502074 and perplexity is 43.73226552305381
At time: 664.5086944103241 and batch: 1350, loss is 3.6606685495376587 and perplexity is 38.88733229078105
At time: 665.3597049713135 and batch: 1400, loss is 3.682036681175232 and perplexity is 39.72722342091163
At time: 666.2086191177368 and batch: 1450, loss is 3.6023112964630126 and perplexity is 36.68292164441337
At time: 667.0592133998871 and batch: 1500, loss is 3.6156270408630373 and perplexity is 37.17464864277316
At time: 667.9101228713989 and batch: 1550, loss is 3.626793375015259 and perplexity is 37.59207944005261
At time: 668.7584345340729 and batch: 1600, loss is 3.7192160987854006 and perplexity is 41.23205957514518
At time: 669.6081852912903 and batch: 1650, loss is 3.6651417064666747 and perplexity is 39.06167106231324
At time: 670.4562082290649 and batch: 1700, loss is 3.6673900175094603 and perplexity is 39.1495926492134
At time: 671.3033194541931 and batch: 1750, loss is 3.6654989337921142 and perplexity is 39.07562745124736
At time: 672.150500535965 and batch: 1800, loss is 3.6240766763687136 and perplexity is 37.49009168643939
At time: 672.9969520568848 and batch: 1850, loss is 3.647382435798645 and perplexity is 38.374087832919216
At time: 673.8478381633759 and batch: 1900, loss is 3.732729477882385 and perplexity is 41.79302576498235
At time: 674.6954336166382 and batch: 1950, loss is 3.6695249605178835 and perplexity is 39.23326408341312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240752748001453 and perplexity of 69.46011812971705
finished 19 epochs...
Completing Train Step...
At time: 677.9114229679108 and batch: 50, loss is 3.8229887104034423 and perplexity is 45.740709973044865
At time: 678.7599999904633 and batch: 100, loss is 3.823094129562378 and perplexity is 45.74553217439108
At time: 679.6077032089233 and batch: 150, loss is 3.7888683891296386 and perplexity is 44.20634757777791
At time: 680.4541246891022 and batch: 200, loss is 3.780751791000366 and perplexity is 43.84899462671388
At time: 681.3007614612579 and batch: 250, loss is 3.7867891693115237 and perplexity is 44.11452835306263
At time: 682.1494452953339 and batch: 300, loss is 3.7966940021514892 and perplexity is 44.55364648808186
At time: 682.9966557025909 and batch: 350, loss is 3.807974724769592 and perplexity is 45.05908933603554
At time: 683.8481087684631 and batch: 400, loss is 3.773642497062683 and perplexity is 43.53836472300818
At time: 684.6961810588837 and batch: 450, loss is 3.8090635204315184 and perplexity is 45.108176194965225
At time: 685.541020154953 and batch: 500, loss is 3.8227230978012083 and perplexity is 45.72856227740284
At time: 686.3883674144745 and batch: 550, loss is 3.7974546432495115 and perplexity is 44.587548714746326
At time: 687.236300945282 and batch: 600, loss is 3.7771154689788817 and perplexity is 43.689835114929956
At time: 688.133663892746 and batch: 650, loss is 3.799949440956116 and perplexity is 44.69892450128435
At time: 688.9825489521027 and batch: 700, loss is 3.8300006866455076 and perplexity is 46.06256986286028
At time: 689.8337218761444 and batch: 750, loss is 3.7944770288467407 and perplexity is 44.45498165225338
At time: 690.6842889785767 and batch: 800, loss is 3.770725603103638 and perplexity is 43.41155296809422
At time: 691.5373048782349 and batch: 850, loss is 3.7589666128158568 and perplexity is 42.90406654995764
At time: 692.3838467597961 and batch: 900, loss is 3.7164083433151247 and perplexity is 41.11645240859845
At time: 693.2328288555145 and batch: 950, loss is 3.81669951915741 and perplexity is 45.453940619187236
At time: 694.0791025161743 and batch: 1000, loss is 3.799531674385071 and perplexity is 44.680254684950164
At time: 694.9265055656433 and batch: 1050, loss is 3.730730514526367 and perplexity is 41.70956648175641
At time: 695.7763533592224 and batch: 1100, loss is 3.7496158361434935 and perplexity is 42.504750074487426
At time: 696.6217653751373 and batch: 1150, loss is 3.7275136852264406 and perplexity is 41.57560950009787
At time: 697.4686295986176 and batch: 1200, loss is 3.7822296237945556 and perplexity is 43.91384401543962
At time: 698.3143861293793 and batch: 1250, loss is 3.769623031616211 and perplexity is 43.3637150048001
At time: 699.1652753353119 and batch: 1300, loss is 3.7772664070129394 and perplexity is 43.6964300704528
At time: 700.0151669979095 and batch: 1350, loss is 3.6604451608657835 and perplexity is 38.87864627148313
At time: 700.8638577461243 and batch: 1400, loss is 3.6819801712036133 and perplexity is 39.724978500074435
At time: 701.71244764328 and batch: 1450, loss is 3.602740545272827 and perplexity is 36.69867112485079
At time: 702.5600206851959 and batch: 1500, loss is 3.6167212104797364 and perplexity is 37.21534627482548
At time: 703.407479763031 and batch: 1550, loss is 3.6281874704360964 and perplexity is 37.644522932982746
At time: 704.255095243454 and batch: 1600, loss is 3.72068452835083 and perplexity is 41.29265042627987
At time: 705.1028161048889 and batch: 1650, loss is 3.66659321308136 and perplexity is 39.118410505117225
At time: 705.9527297019958 and batch: 1700, loss is 3.6690859270095824 and perplexity is 39.21604314640128
At time: 706.80433177948 and batch: 1750, loss is 3.6673993635177613 and perplexity is 39.14995854334111
At time: 707.6485633850098 and batch: 1800, loss is 3.6257740831375123 and perplexity is 37.55378166043541
At time: 708.4946830272675 and batch: 1850, loss is 3.6490441751480103 and perplexity is 38.4379085767017
At time: 709.3462085723877 and batch: 1900, loss is 3.734413595199585 and perplexity is 41.86346942445509
At time: 710.1959118843079 and batch: 1950, loss is 3.671034965515137 and perplexity is 39.29255125893816
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240371775072674 and perplexity of 69.43366074517346
Finished Training.
Improved accuracyfrom -10000000 to -69.43366074517346
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
747.8903527259827


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.484945297241211 and batch: 50, loss is 7.668237028121948 and perplexity is 2139.3065813945313
At time: 2.376108407974243 and batch: 100, loss is 6.82273084640503 and perplexity is 918.4898430533957
At time: 3.2692067623138428 and batch: 150, loss is 6.53215178489685 and perplexity is 686.8746289083016
At time: 4.160879850387573 and batch: 200, loss is 6.431060428619385 and perplexity is 620.8319470350195
At time: 5.056366682052612 and batch: 250, loss is 6.373107271194458 and perplexity is 585.8754774599561
At time: 5.949017286300659 and batch: 300, loss is 6.2877343559265135 and perplexity is 537.9331822710326
At time: 6.8469977378845215 and batch: 350, loss is 6.222196769714356 and perplexity is 503.80876911626365
At time: 7.741199970245361 and batch: 400, loss is 6.164809694290161 and perplexity is 475.71060387644525
At time: 8.640356063842773 and batch: 450, loss is 6.068181571960449 and perplexity is 431.89459782590467
At time: 9.53774905204773 and batch: 500, loss is 6.038865242004395 and perplexity is 419.4168281488398
At time: 10.43131709098816 and batch: 550, loss is 5.98093620300293 and perplexity is 395.8107539665721
At time: 11.332741022109985 and batch: 600, loss is 6.009879026412964 and perplexity is 407.4340285365498
At time: 12.230810403823853 and batch: 650, loss is 6.081801071166992 and perplexity is 437.8170246560577
At time: 13.123997211456299 and batch: 700, loss is 5.975696048736572 and perplexity is 393.74206940232915
At time: 14.019848823547363 and batch: 750, loss is 5.899749326705932 and perplexity is 364.9459741887906
At time: 14.917465448379517 and batch: 800, loss is 5.905012979507446 and perplexity is 366.87198757425824
At time: 15.815499544143677 and batch: 850, loss is 5.927208423614502 and perplexity is 375.1059140707723
At time: 16.713414907455444 and batch: 900, loss is 5.896179437637329 and perplexity is 363.64548023561287
At time: 17.612998962402344 and batch: 950, loss is 5.923088846206665 and perplexity is 373.5638148011788
At time: 18.508214473724365 and batch: 1000, loss is 5.889561624526977 and perplexity is 361.24688788090145
At time: 19.403770446777344 and batch: 1050, loss is 5.784340438842773 and perplexity is 325.1675015161543
At time: 20.299179553985596 and batch: 1100, loss is 5.8568000221252445 and perplexity is 349.6036282878427
At time: 21.19213557243347 and batch: 1150, loss is 5.7634329509735105 and perplexity is 318.4396423134686
At time: 22.088871479034424 and batch: 1200, loss is 5.842380266189576 and perplexity is 344.59860164903137
At time: 22.983120918273926 and batch: 1250, loss is 5.767121276855469 and perplexity is 319.6163201397602
At time: 23.880469799041748 and batch: 1300, loss is 5.776211519241333 and perplexity is 322.53495541352765
At time: 24.77763605117798 and batch: 1350, loss is 5.744809370040894 and perplexity is 312.5640380806418
At time: 25.67324209213257 and batch: 1400, loss is 5.766848020553589 and perplexity is 319.52899489772796
At time: 26.56986975669861 and batch: 1450, loss is 5.736699209213257 and perplexity is 310.039345134187
At time: 27.464350700378418 and batch: 1500, loss is 5.708862104415894 and perplexity is 301.5277658854053
At time: 28.35953974723816 and batch: 1550, loss is 5.669521799087525 and perplexity is 289.8958727694387
At time: 29.24991774559021 and batch: 1600, loss is 5.690247497558594 and perplexity is 295.9668626524316
At time: 30.146350383758545 and batch: 1650, loss is 5.683798761367798 and perplexity is 294.0643912949573
At time: 31.04671359062195 and batch: 1700, loss is 5.6920319938659665 and perplexity is 296.4954859488196
At time: 31.943573713302612 and batch: 1750, loss is 5.701413717269897 and perplexity is 299.29021377167925
At time: 32.8394410610199 and batch: 1800, loss is 5.692149925231933 and perplexity is 296.53045412836263
At time: 33.73388648033142 and batch: 1850, loss is 5.659534196853638 and perplexity is 287.0149189617315
At time: 34.62684416770935 and batch: 1900, loss is 5.656501893997192 and perplexity is 286.14592100147934
At time: 35.522125005722046 and batch: 1950, loss is 5.585839576721192 and perplexity is 266.62404013297794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.058051530704942 and perplexity of 157.28375499568492
finished 1 epochs...
Completing Train Step...
At time: 38.74276161193848 and batch: 50, loss is 5.313866796493531 and perplexity is 203.13419027545865
At time: 39.577412605285645 and batch: 100, loss is 5.2210953998565675 and perplexity is 185.13687194125393
At time: 40.40867280960083 and batch: 150, loss is 5.120076551437378 and perplexity is 167.3481798744881
At time: 41.23688006401062 and batch: 200, loss is 5.08118236541748 and perplexity is 160.96426203676876
At time: 42.06685185432434 and batch: 250, loss is 5.080481939315796 and perplexity is 160.8515579412526
At time: 42.90041446685791 and batch: 300, loss is 5.07816439628601 and perplexity is 160.47920916812492
At time: 43.755340576171875 and batch: 350, loss is 5.067429800033569 and perplexity is 158.76574278942928
At time: 44.584770917892456 and batch: 400, loss is 5.018745031356811 and perplexity is 151.22140653804095
At time: 45.41518521308899 and batch: 450, loss is 4.974528837203979 and perplexity is 144.68064095119323
At time: 46.24441838264465 and batch: 500, loss is 4.958732280731201 and perplexity is 142.4131415280259
At time: 47.074488401412964 and batch: 550, loss is 4.89973069190979 and perplexity is 134.25361923020384
At time: 47.9043447971344 and batch: 600, loss is 4.891866874694824 and perplexity is 133.20201354481188
At time: 48.73140740394592 and batch: 650, loss is 4.965423173904419 and perplexity is 143.3692075454819
At time: 49.5621235370636 and batch: 700, loss is 4.9431655311584475 and perplexity is 140.21339766953307
At time: 50.39298462867737 and batch: 750, loss is 4.90771183013916 and perplexity is 135.32940320288336
At time: 51.22633218765259 and batch: 800, loss is 4.8815348434448245 and perplexity is 131.8328514708862
At time: 52.06035757064819 and batch: 850, loss is 4.868669595718384 and perplexity is 130.14765267192482
At time: 52.89485716819763 and batch: 900, loss is 4.862660636901856 and perplexity is 129.3679457464633
At time: 53.72444438934326 and batch: 950, loss is 4.925116653442383 and perplexity is 137.70540451541717
At time: 54.57145714759827 and batch: 1000, loss is 4.889024782180786 and perplexity is 132.82397855892748
At time: 55.40050172805786 and batch: 1050, loss is 4.805677757263184 and perplexity is 122.20228644762945
At time: 56.231136322021484 and batch: 1100, loss is 4.875570459365845 and perplexity is 131.0488899583133
At time: 57.06469416618347 and batch: 1150, loss is 4.786080446243286 and perplexity is 119.83076386462463
At time: 57.896870136260986 and batch: 1200, loss is 4.869172048568726 and perplexity is 130.21306216219148
At time: 58.73039650917053 and batch: 1250, loss is 4.820964965820313 and perplexity is 124.08477058951452
At time: 59.56372833251953 and batch: 1300, loss is 4.843371629714966 and perplexity is 126.89647920766019
At time: 60.39287352561951 and batch: 1350, loss is 4.745919561386108 and perplexity is 115.11361087996487
At time: 61.22538876533508 and batch: 1400, loss is 4.759465951919555 and perplexity is 116.68359460679874
At time: 62.056984424591064 and batch: 1450, loss is 4.706111402511596 and perplexity is 110.6211612887786
At time: 62.88769268989563 and batch: 1500, loss is 4.693014640808105 and perplexity is 109.18182817484745
At time: 63.71834421157837 and batch: 1550, loss is 4.68109655380249 and perplexity is 107.88831307096001
At time: 64.54726696014404 and batch: 1600, loss is 4.747570152282715 and perplexity is 115.30377325512757
At time: 65.37583565711975 and batch: 1650, loss is 4.7032633399963375 and perplexity is 110.30655352986086
At time: 66.20425772666931 and batch: 1700, loss is 4.734550361633301 and perplexity is 113.81227284703344
At time: 67.03345084190369 and batch: 1750, loss is 4.731410684585572 and perplexity is 113.45549943594733
At time: 67.86474943161011 and batch: 1800, loss is 4.687662601470947 and perplexity is 108.59904366947353
At time: 68.69523334503174 and batch: 1850, loss is 4.693725490570069 and perplexity is 109.25946764314577
At time: 69.53080582618713 and batch: 1900, loss is 4.777691907882691 and perplexity is 118.82976324105707
At time: 70.36134648323059 and batch: 1950, loss is 4.696714029312134 and perplexity is 109.58648219957985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.545954930505087 and perplexity of 94.25038681947294
finished 2 epochs...
Completing Train Step...
At time: 73.50445032119751 and batch: 50, loss is 4.653149280548096 and perplexity is 104.91487221795524
At time: 74.36266469955444 and batch: 100, loss is 4.593872528076172 and perplexity is 98.87659209691647
At time: 75.19464325904846 and batch: 150, loss is 4.546892433166504 and perplexity is 94.33878823976441
At time: 76.02627205848694 and batch: 200, loss is 4.541538286209106 and perplexity is 93.83503429349621
At time: 76.85758376121521 and batch: 250, loss is 4.5422846221923825 and perplexity is 93.90509289645757
At time: 77.68553400039673 and batch: 300, loss is 4.557789945602417 and perplexity is 95.37246839938938
At time: 78.51373600959778 and batch: 350, loss is 4.568320951461792 and perplexity is 96.38214353909329
At time: 79.34147620201111 and batch: 400, loss is 4.520726547241211 and perplexity is 91.90234512305364
At time: 80.14911270141602 and batch: 450, loss is 4.522306346893311 and perplexity is 92.04764715973967
At time: 80.97451710700989 and batch: 500, loss is 4.521901273727417 and perplexity is 92.01036867865754
At time: 81.80716753005981 and batch: 550, loss is 4.483589792251587 and perplexity is 88.55198602368526
At time: 82.63597130775452 and batch: 600, loss is 4.471952219009399 and perplexity is 87.52742904226825
At time: 83.47387957572937 and batch: 650, loss is 4.535328960418701 and perplexity is 93.25418719569366
At time: 84.30967569351196 and batch: 700, loss is 4.552680215835571 and perplexity is 94.88638379676486
At time: 85.14586806297302 and batch: 750, loss is 4.5263405036926265 and perplexity is 92.41973182070087
At time: 86.0294144153595 and batch: 800, loss is 4.502097787857056 and perplexity is 90.20616635388673
At time: 86.86271715164185 and batch: 850, loss is 4.489667587280273 and perplexity is 89.091825699783
At time: 87.6964259147644 and batch: 900, loss is 4.4690563678741455 and perplexity is 87.27432928399509
At time: 88.5259006023407 and batch: 950, loss is 4.545173959732056 and perplexity is 94.17680875691791
At time: 89.35307717323303 and batch: 1000, loss is 4.522647352218628 and perplexity is 92.0790412500758
At time: 90.18083477020264 and batch: 1050, loss is 4.4513546752929685 and perplexity is 85.7430193120787
At time: 91.0082802772522 and batch: 1100, loss is 4.506101951599121 and perplexity is 90.56809073317928
At time: 91.84146428108215 and batch: 1150, loss is 4.452283573150635 and perplexity is 85.8227028222189
At time: 92.67702078819275 and batch: 1200, loss is 4.533811111450195 and perplexity is 93.11274879207193
At time: 93.50776410102844 and batch: 1250, loss is 4.50520393371582 and perplexity is 90.48679547580518
At time: 94.34010910987854 and batch: 1300, loss is 4.5115574359893795 and perplexity is 91.06353375045968
At time: 95.1703724861145 and batch: 1350, loss is 4.402402935028076 and perplexity is 81.6468251514137
At time: 96.00066828727722 and batch: 1400, loss is 4.423236227035522 and perplexity is 83.36563941392788
At time: 96.82995390892029 and batch: 1450, loss is 4.365390400886536 and perplexity is 78.68011073160945
At time: 97.65925979614258 and batch: 1500, loss is 4.373136286735535 and perplexity is 79.29192434813913
At time: 98.49245977401733 and batch: 1550, loss is 4.363449172973633 and perplexity is 78.52752285630552
At time: 99.32602906227112 and batch: 1600, loss is 4.441049175262451 and perplexity is 84.86393212063246
At time: 100.158931016922 and batch: 1650, loss is 4.395719795227051 and perplexity is 81.10298730098789
At time: 100.99031615257263 and batch: 1700, loss is 4.426366090774536 and perplexity is 83.62697125900725
At time: 101.82014513015747 and batch: 1750, loss is 4.421905498504639 and perplexity is 83.25477615987214
At time: 102.65092253684998 and batch: 1800, loss is 4.380421257019043 and perplexity is 79.87167282196575
At time: 103.48335814476013 and batch: 1850, loss is 4.4021953678131105 and perplexity is 81.62987970602656
At time: 104.31441307067871 and batch: 1900, loss is 4.492950916290283 and perplexity is 89.38482421770837
At time: 105.14946007728577 and batch: 1950, loss is 4.423897657394409 and perplexity is 83.42079821856731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.423532317405523 and perplexity of 83.39032683162027
finished 3 epochs...
Completing Train Step...
At time: 108.29864931106567 and batch: 50, loss is 4.389650406837464 and perplexity is 80.61223256855288
At time: 109.15422177314758 and batch: 100, loss is 4.333924942016601 and perplexity is 76.24294922385226
At time: 109.98526883125305 and batch: 150, loss is 4.3087764167785645 and perplexity is 74.34946050887028
At time: 110.821209192276 and batch: 200, loss is 4.3101033687591555 and perplexity is 74.44818415903389
At time: 111.65050935745239 and batch: 250, loss is 4.303277740478515 and perplexity is 73.94175882948251
At time: 112.48270606994629 and batch: 300, loss is 4.311731758117676 and perplexity is 74.56951354881298
At time: 113.31477689743042 and batch: 350, loss is 4.3223059940338135 and perplexity is 75.36221288587276
At time: 114.14507031440735 and batch: 400, loss is 4.287083897590637 and perplexity is 72.75400074446736
At time: 114.97425365447998 and batch: 450, loss is 4.303161735534668 and perplexity is 73.93318171740485
At time: 115.8062744140625 and batch: 500, loss is 4.304963235855102 and perplexity is 74.06649241153467
At time: 116.63525128364563 and batch: 550, loss is 4.276167840957641 and perplexity is 71.96413291642666
At time: 117.46796798706055 and batch: 600, loss is 4.259767165184021 and perplexity is 70.79349834403781
At time: 118.29794096946716 and batch: 650, loss is 4.319040975570679 and perplexity is 75.11655512617122
At time: 119.12998366355896 and batch: 700, loss is 4.349211807250977 and perplexity is 77.41741902291858
At time: 119.96026086807251 and batch: 750, loss is 4.3212255764007566 and perplexity is 75.28083419160893
At time: 120.79306125640869 and batch: 800, loss is 4.295773463249207 and perplexity is 73.38895615886659
At time: 121.62387251853943 and batch: 850, loss is 4.286632528305054 and perplexity is 72.72116923325329
At time: 122.45320057868958 and batch: 900, loss is 4.25886935710907 and perplexity is 70.72996789291395
At time: 123.28326678276062 and batch: 950, loss is 4.349262981414795 and perplexity is 77.42138089597397
At time: 124.11404204368591 and batch: 1000, loss is 4.326363611221313 and perplexity is 75.6686251275516
At time: 124.94514036178589 and batch: 1050, loss is 4.26318962097168 and perplexity is 71.03620104490346
At time: 125.77360200881958 and batch: 1100, loss is 4.304580292701721 and perplexity is 74.03813458543492
At time: 126.60592746734619 and batch: 1150, loss is 4.267161121368408 and perplexity is 71.31888230835384
At time: 127.43701672554016 and batch: 1200, loss is 4.34590304851532 and perplexity is 77.16168677290314
At time: 128.291424036026 and batch: 1250, loss is 4.327087059020996 and perplexity is 75.7233872342795
At time: 129.12291288375854 and batch: 1300, loss is 4.320332021713257 and perplexity is 75.21359669400245
At time: 129.9530475139618 and batch: 1350, loss is 4.209283180236817 and perplexity is 67.30827461199166
At time: 130.78023076057434 and batch: 1400, loss is 4.240283660888672 and perplexity is 69.42754292435194
At time: 131.610759973526 and batch: 1450, loss is 4.172728915214538 and perplexity is 64.89229627589944
At time: 132.4420871734619 and batch: 1500, loss is 4.187519927024841 and perplexity is 65.85925249828841
At time: 133.27558064460754 and batch: 1550, loss is 4.179566903114319 and perplexity is 65.33754959609983
At time: 134.10899257659912 and batch: 1600, loss is 4.2673449087142945 and perplexity is 71.33199102101571
At time: 134.94007062911987 and batch: 1650, loss is 4.215575828552246 and perplexity is 67.733157329581
At time: 135.76962542533875 and batch: 1700, loss is 4.2517287015914915 and perplexity is 70.22670849680074
At time: 136.60118436813354 and batch: 1750, loss is 4.244724183082581 and perplexity is 69.73652297825787
At time: 137.43148398399353 and batch: 1800, loss is 4.207240128517151 and perplexity is 67.17090070458072
At time: 138.26370573043823 and batch: 1850, loss is 4.232872476577759 and perplexity is 68.914904582518
At time: 139.10041880607605 and batch: 1900, loss is 4.323609228134155 and perplexity is 75.46049151770517
At time: 139.93197774887085 and batch: 1950, loss is 4.25619873046875 and perplexity is 70.54132656378934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371214400890262 and perplexity of 79.13968066544057
finished 4 epochs...
Completing Train Step...
At time: 143.08051753044128 and batch: 50, loss is 4.22893150806427 and perplexity is 68.64384757782932
At time: 143.94005823135376 and batch: 100, loss is 4.1783020257949826 and perplexity is 65.25495785673532
At time: 144.77338004112244 and batch: 150, loss is 4.154921846389771 and perplexity is 63.7469822963173
At time: 145.6059136390686 and batch: 200, loss is 4.159267482757568 and perplexity is 64.02460629048399
At time: 146.43580031394958 and batch: 250, loss is 4.149078335762024 and perplexity is 63.37556238278187
At time: 147.26618695259094 and batch: 300, loss is 4.159995112419129 and perplexity is 64.07120944595364
At time: 148.0970618724823 and batch: 350, loss is 4.16562520980835 and perplexity is 64.43295396787623
At time: 148.9542932510376 and batch: 400, loss is 4.135301241874695 and perplexity is 62.508418387674276
At time: 149.7833433151245 and batch: 450, loss is 4.160665426254273 and perplexity is 64.11417166155479
At time: 150.6130633354187 and batch: 500, loss is 4.169079322814941 and perplexity is 64.65589748662406
At time: 151.4434609413147 and batch: 550, loss is 4.135177779197693 and perplexity is 62.5007014073943
At time: 152.27224612236023 and batch: 600, loss is 4.122109079360962 and perplexity is 61.68921260246564
At time: 153.10296654701233 and batch: 650, loss is 4.172911152839661 and perplexity is 64.90412317148149
At time: 153.9326319694519 and batch: 700, loss is 4.2109493637084965 and perplexity is 67.42051602808688
At time: 154.76056337356567 and batch: 750, loss is 4.1862541723251345 and perplexity is 65.7759435753726
At time: 155.59447050094604 and batch: 800, loss is 4.1621343040466305 and perplexity is 64.2084167447935
At time: 156.42655396461487 and batch: 850, loss is 4.1528199720382695 and perplexity is 63.613134863762596
At time: 157.25861072540283 and batch: 900, loss is 4.125860285758972 and perplexity is 61.92105614609388
At time: 158.08712124824524 and batch: 950, loss is 4.2163172674179075 and perplexity is 67.78339594704944
At time: 158.9228436946869 and batch: 1000, loss is 4.191188282966614 and perplexity is 66.10129134941708
At time: 159.7573642730713 and batch: 1050, loss is 4.137911438941956 and perplexity is 62.67179080237133
At time: 160.59298515319824 and batch: 1100, loss is 4.171742787361145 and perplexity is 64.82833571689872
At time: 161.42463493347168 and batch: 1150, loss is 4.140170478820801 and perplexity is 62.81352891281727
At time: 162.25548720359802 and batch: 1200, loss is 4.215327105522156 and perplexity is 67.71631262837184
At time: 163.09367108345032 and batch: 1250, loss is 4.202644200325012 and perplexity is 66.86289639334281
At time: 163.924081325531 and batch: 1300, loss is 4.190716934204102 and perplexity is 66.0701419292361
At time: 164.75411534309387 and batch: 1350, loss is 4.0805049324035645 and perplexity is 59.17534185517056
At time: 165.5896337032318 and batch: 1400, loss is 4.113073601722717 and perplexity is 61.134331683570444
At time: 166.42249202728271 and batch: 1450, loss is 4.046260070800781 and perplexity is 57.18319553106883
At time: 167.25758934020996 and batch: 1500, loss is 4.065262765884399 and perplexity is 58.28022056442236
At time: 168.09199976921082 and batch: 1550, loss is 4.056883549690246 and perplexity is 57.79391825787293
At time: 168.9274423122406 and batch: 1600, loss is 4.146925616264343 and perplexity is 63.239279316201554
At time: 169.7583885192871 and batch: 1650, loss is 4.096713147163391 and perplexity is 60.142283535277095
At time: 170.58923077583313 and batch: 1700, loss is 4.133447561264038 and perplexity is 62.39265507176148
At time: 171.42551565170288 and batch: 1750, loss is 4.1261777639389035 and perplexity is 61.940717851214586
At time: 172.2585005760193 and batch: 1800, loss is 4.086109199523926 and perplexity is 59.50790730023129
At time: 173.08950757980347 and batch: 1850, loss is 4.110853199958801 and perplexity is 60.998739495938594
At time: 173.92429757118225 and batch: 1900, loss is 4.203207240104676 and perplexity is 66.90055346401536
At time: 174.75596857070923 and batch: 1950, loss is 4.141598539352417 and perplexity is 62.903294514410206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349615052688954 and perplexity of 77.44864353910828
finished 5 epochs...
Completing Train Step...
At time: 177.94646215438843 and batch: 50, loss is 4.117279562950134 and perplexity is 61.39200180772048
At time: 178.77981400489807 and batch: 100, loss is 4.061896333694458 and perplexity is 58.08435402456715
At time: 179.61675119400024 and batch: 150, loss is 4.046422271728516 and perplexity is 57.19247145069584
At time: 180.4477608203888 and batch: 200, loss is 4.052455258369446 and perplexity is 57.53855577828226
At time: 181.27945113182068 and batch: 250, loss is 4.040120038986206 and perplexity is 56.83316459148114
At time: 182.1088089942932 and batch: 300, loss is 4.050950388908387 and perplexity is 57.45203288201874
At time: 182.94094467163086 and batch: 350, loss is 4.057259578704834 and perplexity is 57.81565453448379
At time: 183.7768144607544 and batch: 400, loss is 4.02810528755188 and perplexity is 56.154413921009954
At time: 184.61593389511108 and batch: 450, loss is 4.057230386734009 and perplexity is 57.81396680621759
At time: 185.45100045204163 and batch: 500, loss is 4.067058100700378 and perplexity is 58.38494705491209
At time: 186.28310179710388 and batch: 550, loss is 4.035435581207276 and perplexity is 56.56755463653425
At time: 187.11678838729858 and batch: 600, loss is 4.022952885627746 and perplexity is 55.86582790467769
At time: 187.9484522342682 and batch: 650, loss is 4.073179683685303 and perplexity is 58.74345154131873
At time: 188.78122925758362 and batch: 700, loss is 4.107182793617248 and perplexity is 60.77525971735528
At time: 189.61358046531677 and batch: 750, loss is 4.0877239751815795 and perplexity is 59.604076845601206
At time: 190.44675183296204 and batch: 800, loss is 4.065155277252197 and perplexity is 58.273956439896565
At time: 191.30801033973694 and batch: 850, loss is 4.053289122581482 and perplexity is 57.58655513044773
At time: 192.1406044960022 and batch: 900, loss is 4.02757465839386 and perplexity is 56.12462465585725
At time: 192.9719889163971 and batch: 950, loss is 4.120679831504821 and perplexity is 61.60110640540142
At time: 193.80745458602905 and batch: 1000, loss is 4.094490909576416 and perplexity is 60.00878148381673
At time: 194.637540102005 and batch: 1050, loss is 4.0445332431793215 and perplexity is 57.08453521873522
At time: 195.47301697731018 and batch: 1100, loss is 4.072086901664734 and perplexity is 58.67929281578378
At time: 196.30259680747986 and batch: 1150, loss is 4.042745094299317 and perplexity is 56.98255077987272
At time: 197.13267135620117 and batch: 1200, loss is 4.119526858329773 and perplexity is 61.53012291105859
At time: 197.9666304588318 and batch: 1250, loss is 4.110251679420471 and perplexity is 60.96205853460135
At time: 198.79908752441406 and batch: 1300, loss is 4.095409655570984 and perplexity is 60.06393964573416
At time: 199.63326740264893 and batch: 1350, loss is 3.983789048194885 and perplexity is 53.72019750408372
At time: 200.46918201446533 and batch: 1400, loss is 4.020932388305664 and perplexity is 55.75306510582893
At time: 201.30363845825195 and batch: 1450, loss is 3.9498255252838135 and perplexity is 51.92630621689024
At time: 202.140540599823 and batch: 1500, loss is 3.9713148784637453 and perplexity is 53.05424488089052
At time: 202.97293186187744 and batch: 1550, loss is 3.9652095222473145 and perplexity is 52.731316616248314
At time: 203.8056514263153 and batch: 1600, loss is 4.054730043411255 and perplexity is 57.66959260809843
At time: 204.63690900802612 and batch: 1650, loss is 4.006792430877685 and perplexity is 54.9702665504575
At time: 205.46938562393188 and batch: 1700, loss is 4.042656393051147 and perplexity is 56.97749658065486
At time: 206.3012716770172 and batch: 1750, loss is 4.0384809923172 and perplexity is 56.740088681086
At time: 207.1388065814972 and batch: 1800, loss is 3.9942005014419557 and perplexity is 54.282424550426256
At time: 207.97197365760803 and batch: 1850, loss is 4.022259445190429 and perplexity is 55.82710170925117
At time: 208.80922532081604 and batch: 1900, loss is 4.113647966384888 and perplexity is 61.169455169213826
At time: 209.6414656639099 and batch: 1950, loss is 4.0470826530456545 and perplexity is 57.230252763986535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341863020076308 and perplexity of 76.85058022673775
finished 6 epochs...
Completing Train Step...
At time: 212.81404566764832 and batch: 50, loss is 4.03130919456482 and perplexity is 56.334615962723475
At time: 213.65064549446106 and batch: 100, loss is 3.9802915906906127 and perplexity is 53.53264157182867
At time: 214.48481607437134 and batch: 150, loss is 3.9631644344329833 and perplexity is 52.623586639381585
At time: 215.3195984363556 and batch: 200, loss is 3.970064039230347 and perplexity is 52.98792403689913
At time: 216.15172624588013 and batch: 250, loss is 3.9547986459732054 and perplexity is 52.185185189300206
At time: 216.9835205078125 and batch: 300, loss is 3.9660280179977416 and perplexity is 52.77449464291827
At time: 217.81714844703674 and batch: 350, loss is 3.9701897573471068 and perplexity is 52.99458599767588
At time: 218.65181922912598 and batch: 400, loss is 3.9396901321411133 and perplexity is 51.40267079693796
At time: 219.48407816886902 and batch: 450, loss is 3.977427988052368 and perplexity is 53.37956463855173
At time: 220.31913375854492 and batch: 500, loss is 3.985790657997131 and perplexity is 53.827832063244855
At time: 221.1492805480957 and batch: 550, loss is 3.954856071472168 and perplexity is 52.18818203564504
At time: 221.98453855514526 and batch: 600, loss is 3.944866828918457 and perplexity is 51.6694567764781
At time: 222.82246351242065 and batch: 650, loss is 3.991938982009888 and perplexity is 54.159802500821925
At time: 223.65693545341492 and batch: 700, loss is 4.0306001472473145 and perplexity is 56.29468621210659
At time: 224.48840475082397 and batch: 750, loss is 4.010726871490479 and perplexity is 55.186969823204365
At time: 225.32013964653015 and batch: 800, loss is 3.9871587228775023 and perplexity is 53.901522424981806
At time: 226.15350079536438 and batch: 850, loss is 3.9714888286590577 and perplexity is 53.06347447987171
At time: 226.986567735672 and batch: 900, loss is 3.9509519004821776 and perplexity is 51.98482767272654
At time: 227.82123017311096 and batch: 950, loss is 4.043116631507874 and perplexity is 57.00372585114579
At time: 228.6563515663147 and batch: 1000, loss is 4.015816378593445 and perplexity is 55.46856026855848
At time: 229.48819041252136 and batch: 1050, loss is 3.970410966873169 and perplexity is 53.00631020163327
At time: 230.32023215293884 and batch: 1100, loss is 3.99244113445282 and perplexity is 54.187005807488255
At time: 231.1523494720459 and batch: 1150, loss is 3.9689723777770998 and perplexity is 52.9301107247641
At time: 231.98134565353394 and batch: 1200, loss is 4.042346806526184 and perplexity is 56.95985984567595
At time: 232.8146710395813 and batch: 1250, loss is 4.032290635108947 and perplexity is 56.3899321792158
At time: 233.64728689193726 and batch: 1300, loss is 4.020206565856934 and perplexity is 55.71261296190258
At time: 234.48100876808167 and batch: 1350, loss is 3.910080351829529 and perplexity is 49.90296160657902
At time: 235.3136167526245 and batch: 1400, loss is 3.948439507484436 and perplexity is 51.85438528557678
At time: 236.14524149894714 and batch: 1450, loss is 3.875218915939331 and perplexity is 48.19324740639732
At time: 236.97642731666565 and batch: 1500, loss is 3.9011391019821167 and perplexity is 49.458755596557076
At time: 237.80627465248108 and batch: 1550, loss is 3.8913818979263306 and perplexity is 48.97852309905214
At time: 238.64320373535156 and batch: 1600, loss is 3.980161943435669 and perplexity is 53.525701661678866
At time: 239.4763000011444 and batch: 1650, loss is 3.9310559606552125 and perplexity is 50.96076182667529
At time: 240.31195163726807 and batch: 1700, loss is 3.9722122859954836 and perplexity is 53.101877529589466
At time: 241.14352416992188 and batch: 1750, loss is 3.969785189628601 and perplexity is 52.97315043528631
At time: 241.97499108314514 and batch: 1800, loss is 3.9242690896987913 and perplexity is 50.61606872919526
At time: 242.80734944343567 and batch: 1850, loss is 3.95174400806427 and perplexity is 52.02602156172189
At time: 243.6391248703003 and batch: 1900, loss is 4.04356662273407 and perplexity is 57.02938279990725
At time: 244.47464227676392 and batch: 1950, loss is 3.9794693422317504 and perplexity is 53.48864253134797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336597531340843 and perplexity of 76.44698785027452
finished 7 epochs...
Completing Train Step...
At time: 247.67512845993042 and batch: 50, loss is 3.9630093383789062 and perplexity is 52.615425561634275
At time: 248.50896286964417 and batch: 100, loss is 3.9125705051422117 and perplexity is 50.02738248096953
At time: 249.34443712234497 and batch: 150, loss is 3.89643931388855 and perplexity is 49.226855293873626
At time: 250.1785671710968 and batch: 200, loss is 3.901654267311096 and perplexity is 49.4842415968431
At time: 251.01192831993103 and batch: 250, loss is 3.887535753250122 and perplexity is 48.790506414645876
At time: 251.84603190422058 and batch: 300, loss is 3.899215612411499 and perplexity is 49.363713631408864
At time: 252.6783788204193 and batch: 350, loss is 3.9041215991973877 and perplexity is 49.606486391227435
At time: 253.50759434700012 and batch: 400, loss is 3.8739378595352174 and perplexity is 48.13154866639318
At time: 254.36571526527405 and batch: 450, loss is 3.9112280797958374 and perplexity is 49.96026951186843
At time: 255.20192527770996 and batch: 500, loss is 3.9247166299819947 and perplexity is 50.63872652868979
At time: 256.0361454486847 and batch: 550, loss is 3.891677050590515 and perplexity is 48.9929813742269
At time: 256.870911359787 and batch: 600, loss is 3.883510766029358 and perplexity is 48.5945199359586
At time: 257.70558643341064 and batch: 650, loss is 3.9298842620849608 and perplexity is 50.90108614268812
At time: 258.53307843208313 and batch: 700, loss is 3.9593593788146975 and perplexity is 52.423731436598864
At time: 259.3698675632477 and batch: 750, loss is 3.948753595352173 and perplexity is 51.87067467690012
At time: 260.20354652404785 and batch: 800, loss is 3.9274088191986083 and perplexity is 50.77523923876404
At time: 261.0387625694275 and batch: 850, loss is 3.9108556127548217 and perplexity is 49.941664423221255
At time: 261.87432980537415 and batch: 900, loss is 3.8828716564178465 and perplexity is 48.56347263357223
At time: 262.70737314224243 and batch: 950, loss is 3.9770692873001097 and perplexity is 53.360420782223756
At time: 263.5409619808197 and batch: 1000, loss is 3.9584658432006834 and perplexity is 52.376909887017
At time: 264.3725383281708 and batch: 1050, loss is 3.9094855308532717 and perplexity is 49.87328710462111
At time: 265.20938754081726 and batch: 1100, loss is 3.9297591161727907 and perplexity is 50.894716478409386
At time: 266.04045152664185 and batch: 1150, loss is 3.905875153541565 and perplexity is 49.693550374341235
At time: 266.8740379810333 and batch: 1200, loss is 3.9821046018600463 and perplexity is 53.62978488327278
At time: 267.7045452594757 and batch: 1250, loss is 3.9734209775924683 and perplexity is 53.1661001275821
At time: 268.53502202033997 and batch: 1300, loss is 3.953525037765503 and perplexity is 52.11876401537715
At time: 269.3744673728943 and batch: 1350, loss is 3.851940727233887 and perplexity is 47.08435250433264
At time: 270.20716428756714 and batch: 1400, loss is 3.889473671913147 and perplexity is 48.88515012389074
At time: 271.04328751564026 and batch: 1450, loss is 3.8115333938598632 and perplexity is 45.219725380227864
At time: 271.87575221061707 and batch: 1500, loss is 3.8424227666854858 and perplexity is 46.63833146720748
At time: 272.7085301876068 and batch: 1550, loss is 3.8310479497909546 and perplexity is 46.11083476327669
At time: 273.5436325073242 and batch: 1600, loss is 3.9224243688583376 and perplexity is 50.52278228252926
At time: 274.37430000305176 and batch: 1650, loss is 3.877201209068298 and perplexity is 48.28887529953736
At time: 275.2094039916992 and batch: 1700, loss is 3.9179696369171144 and perplexity is 50.29821739010267
At time: 276.047509431839 and batch: 1750, loss is 3.9077594900131225 and perplexity is 49.78727802319295
At time: 276.88039350509644 and batch: 1800, loss is 3.867219395637512 and perplexity is 47.80926244079527
At time: 277.7125053405762 and batch: 1850, loss is 3.8965860557556153 and perplexity is 49.2340794645604
At time: 278.5450813770294 and batch: 1900, loss is 3.987393870353699 and perplexity is 53.91419872228444
At time: 279.3781781196594 and batch: 1950, loss is 3.925101194381714 and perplexity is 50.658204125114885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344209608920785 and perplexity of 77.03112869465092
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 282.51978278160095 and batch: 50, loss is 3.9427608489990233 and perplexity is 51.56075643859839
At time: 283.38006567955017 and batch: 100, loss is 3.918430552482605 and perplexity is 50.32140596499123
At time: 284.2169463634491 and batch: 150, loss is 3.8977130365371706 and perplexity is 49.28959660341283
At time: 285.05383229255676 and batch: 200, loss is 3.903296504020691 and perplexity is 49.565573199532814
At time: 285.8844015598297 and batch: 250, loss is 3.891101498603821 and perplexity is 48.964791479616
At time: 286.71482586860657 and batch: 300, loss is 3.895727291107178 and perplexity is 49.19181712691593
At time: 287.54720401763916 and batch: 350, loss is 3.899952459335327 and perplexity is 49.40010053608994
At time: 288.3786680698395 and batch: 400, loss is 3.858282194137573 and perplexity is 47.383885101658585
At time: 289.21093940734863 and batch: 450, loss is 3.888503336906433 and perplexity is 48.8377381578823
At time: 290.0445365905762 and batch: 500, loss is 3.902644324302673 and perplexity is 49.53325807675938
At time: 290.87728571891785 and batch: 550, loss is 3.8635767889022827 and perplexity is 47.63542889525436
At time: 291.7095284461975 and batch: 600, loss is 3.837815384864807 and perplexity is 46.423945125773464
At time: 292.54436898231506 and batch: 650, loss is 3.877457523345947 and perplexity is 48.30125401408111
At time: 293.3773407936096 and batch: 700, loss is 3.9050881052017212 and perplexity is 49.65445453519397
At time: 294.20754861831665 and batch: 750, loss is 3.884020028114319 and perplexity is 48.61927358501134
At time: 295.03749895095825 and batch: 800, loss is 3.8548481559753416 and perplexity is 47.2214461024376
At time: 295.866765499115 and batch: 850, loss is 3.83678994178772 and perplexity is 46.37636441245909
At time: 296.72454619407654 and batch: 900, loss is 3.7979578590393066 and perplexity is 44.60999151960114
At time: 297.5576183795929 and batch: 950, loss is 3.897751221656799 and perplexity is 49.29147876849069
At time: 298.3911123275757 and batch: 1000, loss is 3.8668410110473634 and perplexity is 47.791175574732804
At time: 299.2266445159912 and batch: 1050, loss is 3.8110020685195924 and perplexity is 45.1957053760368
At time: 300.0621190071106 and batch: 1100, loss is 3.8213010120391844 and perplexity is 45.66357855723346
At time: 300.8943395614624 and batch: 1150, loss is 3.796965727806091 and perplexity is 44.56575450179321
At time: 301.727392911911 and batch: 1200, loss is 3.858020057678223 and perplexity is 47.37146568564977
At time: 302.5588698387146 and batch: 1250, loss is 3.8460883140563964 and perplexity is 46.80960018553363
At time: 303.3916254043579 and batch: 1300, loss is 3.828681674003601 and perplexity is 46.001852802980174
At time: 304.222060918808 and batch: 1350, loss is 3.7163671922683714 and perplexity is 41.11476045835605
At time: 305.0539610385895 and batch: 1400, loss is 3.740244674682617 and perplexity is 42.108291737594946
At time: 305.8901505470276 and batch: 1450, loss is 3.6574309730529784 and perplexity is 38.76163516502912
At time: 306.7239816188812 and batch: 1500, loss is 3.6785745668411254 and perplexity is 39.58992104665571
At time: 307.55923557281494 and batch: 1550, loss is 3.661657657623291 and perplexity is 38.92581509426715
At time: 308.3905248641968 and batch: 1600, loss is 3.745673642158508 and perplexity is 42.337517951722695
At time: 309.22341299057007 and batch: 1650, loss is 3.6936765193939207 and perplexity is 40.192343584717314
At time: 310.058021068573 and batch: 1700, loss is 3.7272220849990845 and perplexity is 41.56348781034481
At time: 310.8918659687042 and batch: 1750, loss is 3.707810707092285 and perplexity is 40.76446341291572
At time: 311.723046541214 and batch: 1800, loss is 3.6599158382415773 and perplexity is 38.858072370009246
At time: 312.55335211753845 and batch: 1850, loss is 3.674266662597656 and perplexity is 39.41973828648567
At time: 313.3843514919281 and batch: 1900, loss is 3.761278524398804 and perplexity is 43.00337170650923
At time: 314.21736311912537 and batch: 1950, loss is 3.6954600048065185 and perplexity is 40.264090003526746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.282269429051599 and perplexity of 72.40457073165166
finished 9 epochs...
Completing Train Step...
At time: 317.4315083026886 and batch: 50, loss is 3.8582529544830324 and perplexity is 47.38249963348282
At time: 318.2919273376465 and batch: 100, loss is 3.8163506174087525 and perplexity is 45.438084426109434
At time: 319.127140045166 and batch: 150, loss is 3.794603343009949 and perplexity is 44.46059730072172
At time: 319.9633631706238 and batch: 200, loss is 3.7964204502105714 and perplexity is 44.54146041844757
At time: 320.79491567611694 and batch: 250, loss is 3.7834879302978517 and perplexity is 43.969135870704044
At time: 321.630823135376 and batch: 300, loss is 3.7886763429641723 and perplexity is 44.19785873338743
At time: 322.46076703071594 and batch: 350, loss is 3.796492509841919 and perplexity is 44.54467017531057
At time: 323.26500129699707 and batch: 400, loss is 3.7576728200912477 and perplexity is 42.84859347386832
At time: 324.10519766807556 and batch: 450, loss is 3.7952058362960814 and perplexity is 44.487392583271216
At time: 324.93810629844666 and batch: 500, loss is 3.8104634523391723 and perplexity is 45.17136879246296
At time: 325.7716393470764 and batch: 550, loss is 3.775479106903076 and perplexity is 43.61840118747436
At time: 326.6052851676941 and batch: 600, loss is 3.7543726539611817 and perplexity is 42.707419074579015
At time: 327.4421806335449 and batch: 650, loss is 3.7933116960525513 and perplexity is 44.403206977491294
At time: 328.27777910232544 and batch: 700, loss is 3.8246449041366577 and perplexity is 45.816528217775286
At time: 329.10852098464966 and batch: 750, loss is 3.8056148004531862 and perplexity is 44.952878669296624
At time: 329.94309878349304 and batch: 800, loss is 3.7777132558822633 and perplexity is 43.71596013399171
At time: 330.776873588562 and batch: 850, loss is 3.763135905265808 and perplexity is 43.08331957016563
At time: 331.60870027542114 and batch: 900, loss is 3.7239065885543825 and perplexity is 41.425912405687676
At time: 332.4381277561188 and batch: 950, loss is 3.8258205318450926 and perplexity is 45.87042307178692
At time: 333.27052879333496 and batch: 1000, loss is 3.799654960632324 and perplexity is 44.685763485449286
At time: 334.10012912750244 and batch: 1050, loss is 3.747531280517578 and perplexity is 42.41623884393451
At time: 334.9350845813751 and batch: 1100, loss is 3.7586414432525634 and perplexity is 42.89011772136424
At time: 335.7714169025421 and batch: 1150, loss is 3.7373552703857422 and perplexity is 41.9867994631889
At time: 336.60643124580383 and batch: 1200, loss is 3.799325456619263 and perplexity is 44.67104177261905
At time: 337.44123363494873 and batch: 1250, loss is 3.7928807067871095 and perplexity is 44.38407379532704
At time: 338.27383947372437 and batch: 1300, loss is 3.7754900741577146 and perplexity is 43.618879564210346
At time: 339.1147711277008 and batch: 1350, loss is 3.665579037666321 and perplexity is 39.07875768576354
At time: 339.9450364112854 and batch: 1400, loss is 3.6940542125701903 and perplexity is 40.207526825750314
At time: 340.7738094329834 and batch: 1450, loss is 3.6130702352523802 and perplexity is 37.07972169913362
At time: 341.6079638004303 and batch: 1500, loss is 3.6360066890716554 and perplexity is 37.94002748999799
At time: 342.44228172302246 and batch: 1550, loss is 3.6228539896011354 and perplexity is 37.444281059150086
At time: 343.2765121459961 and batch: 1600, loss is 3.7117148876190185 and perplexity is 40.923926320591875
At time: 344.1092507839203 and batch: 1650, loss is 3.6609420156478882 and perplexity is 38.89796811248193
At time: 344.9420907497406 and batch: 1700, loss is 3.6987361526489257 and perplexity is 40.396217431433676
At time: 345.77757120132446 and batch: 1750, loss is 3.6830071687698362 and perplexity is 39.76579691292992
At time: 346.6122508049011 and batch: 1800, loss is 3.6377022504806518 and perplexity is 38.00441170473622
At time: 347.4459824562073 and batch: 1850, loss is 3.657483549118042 and perplexity is 38.76367315285576
At time: 348.2780349254608 and batch: 1900, loss is 3.746773705482483 and perplexity is 42.38411752899311
At time: 349.1099228858948 and batch: 1950, loss is 3.6827925157547 and perplexity is 39.75726198078049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.285287688499273 and perplexity of 72.62343664221474
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 352.33953309059143 and batch: 50, loss is 3.8375738430023194 and perplexity is 46.41273315373857
At time: 353.19973707199097 and batch: 100, loss is 3.8323658657073976 and perplexity is 46.17164502893839
At time: 354.0331745147705 and batch: 150, loss is 3.8249722051620485 and perplexity is 45.831526468778385
At time: 354.8686406612396 and batch: 200, loss is 3.8359811210632326 and perplexity is 46.338869413206226
At time: 355.7062420845032 and batch: 250, loss is 3.8281437444686888 and perplexity is 45.977113702239805
At time: 356.54241037368774 and batch: 300, loss is 3.827336239814758 and perplexity is 45.94000195492188
At time: 357.3755033016205 and batch: 350, loss is 3.838670253753662 and perplexity is 46.46364848032276
At time: 358.2110574245453 and batch: 400, loss is 3.805389084815979 and perplexity is 44.94273324667682
At time: 359.039662361145 and batch: 450, loss is 3.8340394735336303 and perplexity is 46.2489829540355
At time: 359.8697512149811 and batch: 500, loss is 3.8450537967681884 and perplexity is 46.76119988467819
At time: 360.72273349761963 and batch: 550, loss is 3.810133528709412 and perplexity is 45.1564681486821
At time: 361.55026602745056 and batch: 600, loss is 3.7789264917373657 and perplexity is 43.76903009094414
At time: 362.3780212402344 and batch: 650, loss is 3.8127601623535154 and perplexity is 45.275233555494744
At time: 363.21310019493103 and batch: 700, loss is 3.8461371660232544 and perplexity is 46.81188698242734
At time: 364.0464382171631 and batch: 750, loss is 3.817985453605652 and perplexity is 45.51242900529323
At time: 364.87809777259827 and batch: 800, loss is 3.782998685836792 and perplexity is 43.94762947589297
At time: 365.70815539360046 and batch: 850, loss is 3.7686811304092407 and perplexity is 43.32288989892486
At time: 366.53851532936096 and batch: 900, loss is 3.7230986022949217 and perplexity is 41.39245435632057
At time: 367.3687596321106 and batch: 950, loss is 3.837101535797119 and perplexity is 46.39081726138137
At time: 368.1967453956604 and batch: 1000, loss is 3.8039314985275268 and perplexity is 44.877273053460435
At time: 369.02696084976196 and batch: 1050, loss is 3.748499093055725 and perplexity is 42.457309682939396
At time: 369.8484501838684 and batch: 1100, loss is 3.7566917753219604 and perplexity is 42.80657769841766
At time: 370.66184163093567 and batch: 1150, loss is 3.7389280509948732 and perplexity is 42.052887444548716
At time: 371.4757990837097 and batch: 1200, loss is 3.796306462287903 and perplexity is 44.53638351925995
At time: 372.30409383773804 and batch: 1250, loss is 3.785885200500488 and perplexity is 44.07466821419344
At time: 373.13296484947205 and batch: 1300, loss is 3.7674107694625856 and perplexity is 43.2678891343095
At time: 373.9598665237427 and batch: 1350, loss is 3.649693365097046 and perplexity is 38.462870182146666
At time: 374.790415763855 and batch: 1400, loss is 3.6738634443283082 and perplexity is 39.40384673193352
At time: 375.619695186615 and batch: 1450, loss is 3.5859920454025267 and perplexity is 36.08914203352754
At time: 376.44704961776733 and batch: 1500, loss is 3.60534556388855 and perplexity is 36.79439647532966
At time: 377.27640557289124 and batch: 1550, loss is 3.5889548158645628 and perplexity is 36.19622442949374
At time: 378.0902373790741 and batch: 1600, loss is 3.6765021181106565 and perplexity is 39.50795792656156
At time: 378.93443965911865 and batch: 1650, loss is 3.6231967306137083 and perplexity is 37.45711694952274
At time: 379.77319836616516 and batch: 1700, loss is 3.6523200178146364 and perplexity is 38.56403158441108
At time: 380.60840344429016 and batch: 1750, loss is 3.639046573638916 and perplexity is 38.055536271777434
At time: 381.4377303123474 and batch: 1800, loss is 3.5903278017044067 and perplexity is 36.245955465282925
At time: 382.2667136192322 and batch: 1850, loss is 3.6065049600601196 and perplexity is 36.83708049680259
At time: 383.1037697792053 and batch: 1900, loss is 3.6962070894241332 and perplexity is 40.29418192501685
At time: 383.9369914531708 and batch: 1950, loss is 3.6359817123413087 and perplexity is 37.93907988399612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260379383175872 and perplexity of 70.83685266722428
finished 11 epochs...
Completing Train Step...
At time: 387.0922348499298 and batch: 50, loss is 3.836862659454346 and perplexity is 46.37973691608457
At time: 387.9382231235504 and batch: 100, loss is 3.8072280406951906 and perplexity is 45.02545698955265
At time: 388.7814848423004 and batch: 150, loss is 3.788853964805603 and perplexity is 44.205709935694806
At time: 389.6148407459259 and batch: 200, loss is 3.7899871349334715 and perplexity is 44.255830918111926
At time: 390.45344638824463 and batch: 250, loss is 3.7826247024536133 and perplexity is 43.931196865691994
At time: 391.2843191623688 and batch: 300, loss is 3.7781922578811646 and perplexity is 43.7369051822393
At time: 392.11410546302795 and batch: 350, loss is 3.7906838607788087 and perplexity is 44.28667584329999
At time: 392.944198846817 and batch: 400, loss is 3.7561291456222534 and perplexity is 42.782500220448966
At time: 393.77415680885315 and batch: 450, loss is 3.7878018283843993 and perplexity is 44.15922395733005
At time: 394.6040334701538 and batch: 500, loss is 3.7986535167694093 and perplexity is 44.64103560181749
At time: 395.4352910518646 and batch: 550, loss is 3.765389199256897 and perplexity is 43.18050841166384
At time: 396.2651913166046 and batch: 600, loss is 3.7382037448883056 and perplexity is 42.02243930959001
At time: 397.0964357852936 and batch: 650, loss is 3.7729220724105836 and perplexity is 43.50700990749677
At time: 397.92819261550903 and batch: 700, loss is 3.80824912071228 and perplexity is 45.07145506380575
At time: 398.75649309158325 and batch: 750, loss is 3.783166346549988 and perplexity is 43.95499838451514
At time: 399.58680295944214 and batch: 800, loss is 3.7490516090393067 and perplexity is 42.4807745069073
At time: 400.4172101020813 and batch: 850, loss is 3.737194104194641 and perplexity is 41.98003315590752
At time: 401.2474904060364 and batch: 900, loss is 3.6920857572555543 and perplexity is 40.12845795318446
At time: 402.1267948150635 and batch: 950, loss is 3.8060869121551515 and perplexity is 44.97410645990331
At time: 402.9570047855377 and batch: 1000, loss is 3.7741307115554807 and perplexity is 43.5596259732616
At time: 403.78842997550964 and batch: 1050, loss is 3.7211603927612305 and perplexity is 41.31230480506764
At time: 404.6185348033905 and batch: 1100, loss is 3.7308190870285034 and perplexity is 41.71326096603516
At time: 405.44904136657715 and batch: 1150, loss is 3.713280634880066 and perplexity is 40.988053036153374
At time: 406.2812008857727 and batch: 1200, loss is 3.77255343914032 and perplexity is 43.490974731886375
At time: 407.1098530292511 and batch: 1250, loss is 3.764061994552612 and perplexity is 43.12323705158255
At time: 407.94024753570557 and batch: 1300, loss is 3.747602014541626 and perplexity is 42.41923922130604
At time: 408.76965618133545 and batch: 1350, loss is 3.6317368841171263 and perplexity is 37.77837632770466
At time: 409.59985637664795 and batch: 1400, loss is 3.6585115718841554 and perplexity is 38.80354358169798
At time: 410.43304562568665 and batch: 1450, loss is 3.5734781646728515 and perplexity is 35.640340793812804
At time: 411.2659296989441 and batch: 1500, loss is 3.5945307207107544 and perplexity is 36.39861486323248
At time: 412.09759974479675 and batch: 1550, loss is 3.5797276401519778 and perplexity is 35.863771665356445
At time: 412.92809224128723 and batch: 1600, loss is 3.670537061691284 and perplexity is 39.27299221708233
At time: 413.756023645401 and batch: 1650, loss is 3.619018654823303 and perplexity is 37.300944752837175
At time: 414.5863387584686 and batch: 1700, loss is 3.650719895362854 and perplexity is 38.50237375483602
At time: 415.42061972618103 and batch: 1750, loss is 3.639286894798279 and perplexity is 38.06468292139714
At time: 416.2573480606079 and batch: 1800, loss is 3.5919780254364015 and perplexity is 36.30581878152797
At time: 417.09253787994385 and batch: 1850, loss is 3.610280590057373 and perplexity is 36.976426577021876
At time: 417.925724029541 and batch: 1900, loss is 3.7006466960906983 and perplexity is 40.4734699333514
At time: 418.7529227733612 and batch: 1950, loss is 3.6398126602172853 and perplexity is 38.084701277381185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259640715843023 and perplexity of 70.78454711877545
finished 12 epochs...
Completing Train Step...
At time: 421.9501996040344 and batch: 50, loss is 3.8195843505859375 and perplexity is 45.5852568972283
At time: 422.7809216976166 and batch: 100, loss is 3.7877830028533936 and perplexity is 44.158392644315235
At time: 423.6384902000427 and batch: 150, loss is 3.7690124130249023 and perplexity is 43.33724439677512
At time: 424.47353172302246 and batch: 200, loss is 3.769286060333252 and perplexity is 43.34910513981177
At time: 425.3095746040344 and batch: 250, loss is 3.761174421310425 and perplexity is 42.99889515571929
At time: 426.1440496444702 and batch: 300, loss is 3.756591830253601 and perplexity is 42.80229960587406
At time: 426.9764428138733 and batch: 350, loss is 3.768659720420837 and perplexity is 43.32196236628379
At time: 427.8067362308502 and batch: 400, loss is 3.734083695411682 and perplexity is 41.84966095260228
At time: 428.6392710208893 and batch: 450, loss is 3.766765570640564 and perplexity is 43.239981747083476
At time: 429.47196412086487 and batch: 500, loss is 3.778062310218811 and perplexity is 43.731222042915604
At time: 430.3068525791168 and batch: 550, loss is 3.744732627868652 and perplexity is 42.29769648155784
At time: 431.14018273353577 and batch: 600, loss is 3.719174942970276 and perplexity is 41.23036267104306
At time: 431.9753363132477 and batch: 650, loss is 3.753954458236694 and perplexity is 42.68956274849798
At time: 432.8083531856537 and batch: 700, loss is 3.7901744747161867 and perplexity is 44.264122572514125
At time: 433.64233350753784 and batch: 750, loss is 3.765862154960632 and perplexity is 43.20093570963008
At time: 434.47359824180603 and batch: 800, loss is 3.731753249168396 and perplexity is 41.75224612155418
At time: 435.3089804649353 and batch: 850, loss is 3.720996923446655 and perplexity is 41.305552062865736
At time: 436.140020608902 and batch: 900, loss is 3.6760043811798098 and perplexity is 39.48829824991861
At time: 436.97215604782104 and batch: 950, loss is 3.7899944019317626 and perplexity is 44.256152526328144
At time: 437.8047857284546 and batch: 1000, loss is 3.7586293601989746 and perplexity is 42.88959948090435
At time: 438.639493227005 and batch: 1050, loss is 3.7066644716262815 and perplexity is 40.717764508282556
At time: 439.46987652778625 and batch: 1100, loss is 3.7171262454986573 and perplexity is 41.14598059746913
At time: 440.2999486923218 and batch: 1150, loss is 3.699440765380859 and perplexity is 40.42469115085238
At time: 441.13997745513916 and batch: 1200, loss is 3.759513258934021 and perplexity is 42.92752630289788
At time: 441.9726002216339 and batch: 1250, loss is 3.7515633869171143 and perplexity is 42.58761089501451
At time: 442.80669140815735 and batch: 1300, loss is 3.7358396434783936 and perplexity is 41.923211340276566
At time: 443.640020608902 and batch: 1350, loss is 3.620727744102478 and perplexity is 37.36474990643816
At time: 444.4712755680084 and batch: 1400, loss is 3.64865535736084 and perplexity is 38.422966139276426
At time: 445.3055942058563 and batch: 1450, loss is 3.564586887359619 and perplexity is 35.32485724451086
At time: 446.1357729434967 and batch: 1500, loss is 3.585942854881287 and perplexity is 36.087366833481674
At time: 446.96760296821594 and batch: 1550, loss is 3.571609926223755 and perplexity is 35.57381829809372
At time: 447.79884243011475 and batch: 1600, loss is 3.6640068244934083 and perplexity is 39.01736582134388
At time: 448.63328528404236 and batch: 1650, loss is 3.6131771326065065 and perplexity is 37.08368563513836
At time: 449.46871757507324 and batch: 1700, loss is 3.6457201623916626 and perplexity is 38.310352594569096
At time: 450.30113887786865 and batch: 1750, loss is 3.6352607870101927 and perplexity is 37.91173849700194
At time: 451.1365110874176 and batch: 1800, loss is 3.588498282432556 and perplexity is 36.17970341441406
At time: 451.9724340438843 and batch: 1850, loss is 3.607810573577881 and perplexity is 36.88520689745725
At time: 452.80140686035156 and batch: 1900, loss is 3.6986604261398317 and perplexity is 40.39315848273021
At time: 453.6372971534729 and batch: 1950, loss is 3.637469835281372 and perplexity is 37.99557992817566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260582644440407 and perplexity of 70.85125251888957
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 456.83982253074646 and batch: 50, loss is 3.817814073562622 and perplexity is 45.50462975158921
At time: 457.6714925765991 and batch: 100, loss is 3.8070266008377076 and perplexity is 45.016387981374095
At time: 458.50238156318665 and batch: 150, loss is 3.7966230392456053 and perplexity is 44.550484944036846
At time: 459.3352687358856 and batch: 200, loss is 3.803416714668274 and perplexity is 44.85417690291802
At time: 460.17271089553833 and batch: 250, loss is 3.8049173545837403 and perplexity is 44.921537400438716
At time: 461.00815200805664 and batch: 300, loss is 3.7965520286560057 and perplexity is 44.547321500154354
At time: 461.84271597862244 and batch: 350, loss is 3.8181507349014283 and perplexity is 45.51995198021955
At time: 462.66027212142944 and batch: 400, loss is 3.788227605819702 and perplexity is 44.178029961753616
At time: 463.4747977256775 and batch: 450, loss is 3.8268791818618775 and perplexity is 45.91900950942057
At time: 464.31411719322205 and batch: 500, loss is 3.8314052963256837 and perplexity is 46.1273152547407
At time: 465.1704947948456 and batch: 550, loss is 3.79936354637146 and perplexity is 44.672743313935996
At time: 466.0041997432709 and batch: 600, loss is 3.763907675743103 and perplexity is 43.11658283842689
At time: 466.8381733894348 and batch: 650, loss is 3.79290141582489 and perplexity is 44.38499295630556
At time: 467.6702871322632 and batch: 700, loss is 3.8288313436508177 and perplexity is 46.00873839933004
At time: 468.50328183174133 and batch: 750, loss is 3.793546028137207 and perplexity is 44.41361329276688
At time: 469.3381013870239 and batch: 800, loss is 3.7512993907928465 and perplexity is 42.5763694147153
At time: 470.170530796051 and batch: 850, loss is 3.7378824234008787 and perplexity is 42.00893876600928
At time: 471.0025324821472 and batch: 900, loss is 3.6838715505599975 and perplexity is 39.80018460355842
At time: 471.8356080055237 and batch: 950, loss is 3.801208109855652 and perplexity is 44.755221069334205
At time: 472.66731667518616 and batch: 1000, loss is 3.7721056509017945 and perplexity is 43.47150434455
At time: 473.5001275539398 and batch: 1050, loss is 3.717410821914673 and perplexity is 41.157691439396686
At time: 474.33271837234497 and batch: 1100, loss is 3.728692498207092 and perplexity is 41.6246482663435
At time: 475.16428780555725 and batch: 1150, loss is 3.7137143993377686 and perplexity is 41.005836053292455
At time: 475.99826741218567 and batch: 1200, loss is 3.7726480674743654 and perplexity is 43.49509040509785
At time: 476.8284215927124 and batch: 1250, loss is 3.760411710739136 and perplexity is 42.966111947469265
At time: 477.6590950489044 and batch: 1300, loss is 3.7425739049911497 and perplexity is 42.20648596103683
At time: 478.4915723800659 and batch: 1350, loss is 3.623471670150757 and perplexity is 37.46741680777027
At time: 479.3258821964264 and batch: 1400, loss is 3.6511418199539185 and perplexity is 38.51862228072281
At time: 480.1578371524811 and batch: 1450, loss is 3.5636634349823 and perplexity is 35.292251478363184
At time: 480.9930205345154 and batch: 1500, loss is 3.5859394598007204 and perplexity is 36.08724431417182
At time: 481.82373237609863 and batch: 1550, loss is 3.570434322357178 and perplexity is 35.53202215242248
At time: 482.6577031612396 and batch: 1600, loss is 3.6630844497680664 and perplexity is 38.9813937816613
At time: 483.49160385131836 and batch: 1650, loss is 3.609339156150818 and perplexity is 36.94163209622087
At time: 484.32377433776855 and batch: 1700, loss is 3.634278860092163 and perplexity is 37.87453021136067
At time: 485.1570146083832 and batch: 1750, loss is 3.621072030067444 and perplexity is 37.37761628014427
At time: 485.98881673812866 and batch: 1800, loss is 3.575036849975586 and perplexity is 35.695936185797
At time: 486.82291054725647 and batch: 1850, loss is 3.591466670036316 and perplexity is 36.28725835093214
At time: 487.65654706954956 and batch: 1900, loss is 3.6911020612716676 and perplexity is 40.0890031591991
At time: 488.4886610507965 and batch: 1950, loss is 3.6307798337936403 and perplexity is 37.742237816364856
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243478606468023 and perplexity of 69.64971487035344
finished 14 epochs...
Completing Train Step...
At time: 491.7133719921112 and batch: 50, loss is 3.8204658460617065 and perplexity is 45.62545781080357
At time: 492.58611965179443 and batch: 100, loss is 3.7969607877731324 and perplexity is 44.565534346040934
At time: 493.4234323501587 and batch: 150, loss is 3.7785808992385865 and perplexity is 43.753906455923804
At time: 494.2573473453522 and batch: 200, loss is 3.7792555284500122 and perplexity is 43.783434078311366
At time: 495.09002590179443 and batch: 250, loss is 3.7772247648239134 and perplexity is 43.6946104933379
At time: 495.9254221916199 and batch: 300, loss is 3.7666832637786865 and perplexity is 43.2364229463371
At time: 496.758504152298 and batch: 350, loss is 3.7876479196548463 and perplexity is 44.15242799026547
At time: 497.588561296463 and batch: 400, loss is 3.7587905502319336 and perplexity is 42.89651341407186
At time: 498.4195866584778 and batch: 450, loss is 3.7969245147705077 and perplexity is 44.56391784961439
At time: 499.2531142234802 and batch: 500, loss is 3.8017425394058226 and perplexity is 44.77914597451679
At time: 500.08622097969055 and batch: 550, loss is 3.76958279132843 and perplexity is 43.3619700715376
At time: 500.91823649406433 and batch: 600, loss is 3.738263192176819 and perplexity is 42.02493750391838
At time: 501.74997186660767 and batch: 650, loss is 3.7689915895462036 and perplexity is 43.336341973985384
At time: 502.58256101608276 and batch: 700, loss is 3.8074314260482787 and perplexity is 45.03461543933612
At time: 503.4153320789337 and batch: 750, loss is 3.7752065515518187 and perplexity is 43.60651437879767
At time: 504.25148463249207 and batch: 800, loss is 3.7356516981124877 and perplexity is 41.915332807371335
At time: 505.0863153934479 and batch: 850, loss is 3.7238306617736816 and perplexity is 41.42276718892572
At time: 505.91672372817993 and batch: 900, loss is 3.672067813873291 and perplexity is 39.33315547138109
At time: 506.7483420372009 and batch: 950, loss is 3.7897922945022584 and perplexity is 44.24720893291508
At time: 507.6293933391571 and batch: 1000, loss is 3.759841022491455 and perplexity is 42.941598687712236
At time: 508.4651024341583 and batch: 1050, loss is 3.7064282274246216 and perplexity is 40.7081463086796
At time: 509.30020213127136 and batch: 1100, loss is 3.7181502628326415 and perplexity is 41.18813637526456
At time: 510.1361427307129 and batch: 1150, loss is 3.702583365440369 and perplexity is 40.551929612751124
At time: 510.97335481643677 and batch: 1200, loss is 3.7629704999923708 and perplexity is 43.076193951235254
At time: 511.80740761756897 and batch: 1250, loss is 3.7525729942321777 and perplexity is 42.63062937073499
At time: 512.6412756443024 and batch: 1300, loss is 3.736225652694702 and perplexity is 41.93939720997762
At time: 513.4748907089233 and batch: 1350, loss is 3.61790798664093 and perplexity is 37.259538778733216
At time: 514.3116867542267 and batch: 1400, loss is 3.6469290494918822 and perplexity is 38.35669349043757
At time: 515.1424379348755 and batch: 1450, loss is 3.5612945222854613 and perplexity is 35.20874616318764
At time: 515.9819943904877 and batch: 1500, loss is 3.5847622919082642 and perplexity is 36.04478856251447
At time: 516.8133671283722 and batch: 1550, loss is 3.5708766555786133 and perplexity is 35.54774262283211
At time: 517.6445786952972 and batch: 1600, loss is 3.6645518064498903 and perplexity is 39.03863537694155
At time: 518.4758744239807 and batch: 1650, loss is 3.611766905784607 and perplexity is 37.03142608457164
At time: 519.3086075782776 and batch: 1700, loss is 3.6379936504364014 and perplexity is 38.01548780233407
At time: 520.1385834217072 and batch: 1750, loss is 3.6261762380599976 and perplexity is 37.56888713575514
At time: 520.9719450473785 and batch: 1800, loss is 3.580697469711304 and perplexity is 35.89857028286283
At time: 521.8014435768127 and batch: 1850, loss is 3.597419514656067 and perplexity is 36.50391498341337
At time: 522.6382832527161 and batch: 1900, loss is 3.697528920173645 and perplexity is 40.347479230960445
At time: 523.4726495742798 and batch: 1950, loss is 3.6355746507644655 and perplexity is 37.923639485124326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24190304778343 and perplexity of 69.54006406053584
finished 15 epochs...
Completing Train Step...
At time: 526.6500856876373 and batch: 50, loss is 3.8157330846786497 and perplexity is 45.41003358383117
At time: 527.5072431564331 and batch: 100, loss is 3.790216255187988 and perplexity is 44.26597198707351
At time: 528.3384947776794 and batch: 150, loss is 3.7709520864486694 and perplexity is 43.421386075298926
At time: 529.224636554718 and batch: 200, loss is 3.7704216718673704 and perplexity is 43.398360845982886
At time: 530.0604286193848 and batch: 250, loss is 3.767572522163391 and perplexity is 43.27488839829479
At time: 530.8941693305969 and batch: 300, loss is 3.7570544624328615 and perplexity is 42.822105908181214
At time: 531.7267022132874 and batch: 350, loss is 3.7778407621383665 and perplexity is 43.721534547779115
At time: 532.5589914321899 and batch: 400, loss is 3.748754096031189 and perplexity is 42.46813780378158
At time: 533.3908352851868 and batch: 450, loss is 3.7871769285202026 and perplexity is 44.13163748456533
At time: 534.2262697219849 and batch: 500, loss is 3.7914877700805665 and perplexity is 44.32229262836859
At time: 535.058096408844 and batch: 550, loss is 3.7594036722183226 and perplexity is 42.92282227403153
At time: 535.8929693698883 and batch: 600, loss is 3.7291170167922973 and perplexity is 41.64232245438041
At time: 536.7266488075256 and batch: 650, loss is 3.7601303005218507 and perplexity is 42.9540225456906
At time: 537.5557332038879 and batch: 700, loss is 3.799184627532959 and perplexity is 44.66475123357779
At time: 538.3846573829651 and batch: 750, loss is 3.7676207876205443 and perplexity is 43.276977130973
At time: 539.2203395366669 and batch: 800, loss is 3.7287694597244263 and perplexity is 41.6278518857087
At time: 540.0476496219635 and batch: 850, loss is 3.71736759185791 and perplexity is 41.15591222851751
At time: 540.8814661502838 and batch: 900, loss is 3.666204047203064 and perplexity is 39.10318991639445
At time: 541.7132833003998 and batch: 950, loss is 3.784013476371765 and perplexity is 43.99224975060667
At time: 542.5429520606995 and batch: 1000, loss is 3.754054379463196 and perplexity is 42.693828555085396
At time: 543.3776776790619 and batch: 1050, loss is 3.7012388563156127 and perplexity is 40.49744380989772
At time: 544.2109279632568 and batch: 1100, loss is 3.7133207511901856 and perplexity is 40.98969735858203
At time: 545.0446245670319 and batch: 1150, loss is 3.697741594314575 and perplexity is 40.35606100897337
At time: 545.8811016082764 and batch: 1200, loss is 3.7587214517593384 and perplexity is 42.893549432919755
At time: 546.7140130996704 and batch: 1250, loss is 3.7487297296524047 and perplexity is 42.46710302165658
At time: 547.5483293533325 and batch: 1300, loss is 3.7328501987457274 and perplexity is 41.79807135968253
At time: 548.3819727897644 and batch: 1350, loss is 3.6149117755889892 and perplexity is 37.14806841461434
At time: 549.2142078876495 and batch: 1400, loss is 3.6443307495117185 and perplexity is 38.2571606585766
At time: 550.0456714630127 and batch: 1450, loss is 3.559536881446838 and perplexity is 35.14691618641824
At time: 550.8794441223145 and batch: 1500, loss is 3.583373103141785 and perplexity is 35.99475031148859
At time: 551.7108774185181 and batch: 1550, loss is 3.56991427898407 and perplexity is 35.51354876366702
At time: 552.5441665649414 and batch: 1600, loss is 3.664053192138672 and perplexity is 39.019175006664916
At time: 553.3772480487823 and batch: 1650, loss is 3.6115924072265626 and perplexity is 37.024964717883535
At time: 554.2106523513794 and batch: 1700, loss is 3.638272409439087 and perplexity is 38.026086438964505
At time: 555.0472888946533 and batch: 1750, loss is 3.62695631980896 and perplexity is 37.59820537276263
At time: 555.8792016506195 and batch: 1800, loss is 3.581591486930847 and perplexity is 35.93067857339641
At time: 556.7123806476593 and batch: 1850, loss is 3.59863431930542 and perplexity is 36.54828705529758
At time: 557.5414111614227 and batch: 1900, loss is 3.6987294292449953 and perplexity is 40.395945832259656
At time: 558.3749375343323 and batch: 1950, loss is 3.6360874128341676 and perplexity is 37.94309027538491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241579703397529 and perplexity of 69.5175823060971
finished 16 epochs...
Completing Train Step...
At time: 561.5425944328308 and batch: 50, loss is 3.810684962272644 and perplexity is 45.18137580764472
At time: 562.4030470848083 and batch: 100, loss is 3.7843573760986327 and perplexity is 44.00738127499462
At time: 563.2366197109222 and batch: 150, loss is 3.7649502611160277 and perplexity is 43.16155899869412
At time: 564.0698328018188 and batch: 200, loss is 3.7639166116714478 and perplexity is 43.11696812684307
At time: 564.902720451355 and batch: 250, loss is 3.760668172836304 and perplexity is 42.97713253976817
At time: 565.7362332344055 and batch: 300, loss is 3.7501885509490966 and perplexity is 42.5291001463213
At time: 566.5694952011108 and batch: 350, loss is 3.7708743524551394 and perplexity is 43.418010888739744
At time: 567.402247428894 and batch: 400, loss is 3.7417268705368043 and perplexity is 42.17075074984512
At time: 568.2325575351715 and batch: 450, loss is 3.780372815132141 and perplexity is 43.83238006436238
At time: 569.0671260356903 and batch: 500, loss is 3.7844609212875366 and perplexity is 44.011938263524954
At time: 569.8963315486908 and batch: 550, loss is 3.752447094917297 and perplexity is 42.625262541551436
At time: 570.7289617061615 and batch: 600, loss is 3.7227629041671753 and perplexity is 41.37856131895411
At time: 571.5893123149872 and batch: 650, loss is 3.754034833908081 and perplexity is 42.69299408866139
At time: 572.422792673111 and batch: 700, loss is 3.7933628368377685 and perplexity is 44.40547785042891
At time: 573.2522103786469 and batch: 750, loss is 3.7621364164352418 and perplexity is 43.0402797859463
At time: 574.0865924358368 and batch: 800, loss is 3.723696551322937 and perplexity is 41.4172123354372
At time: 574.9206023216248 and batch: 850, loss is 3.7125059175491333 and perplexity is 40.95631117817641
At time: 575.7535350322723 and batch: 900, loss is 3.661573281288147 and perplexity is 38.92253081520668
At time: 576.5863597393036 and batch: 950, loss is 3.779448266029358 and perplexity is 43.79187360469188
At time: 577.4173910617828 and batch: 1000, loss is 3.7496898889541628 and perplexity is 42.50789778724428
At time: 578.2469666004181 and batch: 1050, loss is 3.6972051191329958 and perplexity is 40.33441679012798
At time: 579.0802595615387 and batch: 1100, loss is 3.7095815992355345 and perplexity is 40.83671683852672
At time: 579.91730427742 and batch: 1150, loss is 3.6940542364120486 and perplexity is 40.20752778437248
At time: 580.7483756542206 and batch: 1200, loss is 3.755382318496704 and perplexity is 42.75056101680185
At time: 581.5795502662659 and batch: 1250, loss is 3.7455742740631104 and perplexity is 42.33331116221376
At time: 582.4111504554749 and batch: 1300, loss is 3.729936971664429 and perplexity is 41.67648128199849
At time: 583.2431502342224 and batch: 1350, loss is 3.612227063179016 and perplexity is 37.048470290317866
At time: 584.0749855041504 and batch: 1400, loss is 3.6418790769577027 and perplexity is 38.163481510017185
At time: 584.9090452194214 and batch: 1450, loss is 3.557576756477356 and perplexity is 35.07809131311323
At time: 585.7431924343109 and batch: 1500, loss is 3.5815725231170656 and perplexity is 35.92999719715967
At time: 586.5758173465729 and batch: 1550, loss is 3.5682707405090333 and perplexity is 35.45522881855358
At time: 587.4070692062378 and batch: 1600, loss is 3.662780342102051 and perplexity is 38.96954104332597
At time: 588.238391160965 and batch: 1650, loss is 3.610492329597473 and perplexity is 36.98425677753211
At time: 589.0729765892029 and batch: 1700, loss is 3.6374365711212158 and perplexity is 37.994316058140605
At time: 589.9086179733276 and batch: 1750, loss is 3.6264168310165403 and perplexity is 37.57792703280933
At time: 590.7412440776825 and batch: 1800, loss is 3.5811354446411134 and perplexity is 35.91429640023392
At time: 591.5785245895386 and batch: 1850, loss is 3.598461308479309 and perplexity is 36.54196435292496
At time: 592.4115047454834 and batch: 1900, loss is 3.6985626125335695 and perplexity is 40.3892076754552
At time: 593.245680809021 and batch: 1950, loss is 3.6355422496795655 and perplexity is 37.92241073796813
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241675372456395 and perplexity of 69.52423330591333
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 596.4399509429932 and batch: 50, loss is 3.810223798751831 and perplexity is 45.16054460896574
At time: 597.2732856273651 and batch: 100, loss is 3.790793056488037 and perplexity is 44.291512022318265
At time: 598.1041893959045 and batch: 150, loss is 3.775157871246338 and perplexity is 43.60439165202467
At time: 598.9360144138336 and batch: 200, loss is 3.7759162092208864 and perplexity is 43.63747105917153
At time: 599.7677347660065 and batch: 250, loss is 3.7742880821228026 and perplexity is 43.5664815157295
At time: 600.5983369350433 and batch: 300, loss is 3.762988796234131 and perplexity is 43.07698209090387
At time: 601.433833360672 and batch: 350, loss is 3.7880645418167114 and perplexity is 44.17082670265591
At time: 602.2644097805023 and batch: 400, loss is 3.7646563768386843 and perplexity is 43.14887635882428
At time: 603.0946593284607 and batch: 450, loss is 3.808259153366089 and perplexity is 45.071907252379376
At time: 603.9279828071594 and batch: 500, loss is 3.8130628061294556 and perplexity is 45.288937896796746
At time: 604.7623372077942 and batch: 550, loss is 3.785565581321716 and perplexity is 44.06058335594948
At time: 605.5969793796539 and batch: 600, loss is 3.753085436820984 and perplexity is 42.65248071911475
At time: 606.4296538829803 and batch: 650, loss is 3.7795110273361208 and perplexity is 43.794622126154394
At time: 607.2615079879761 and batch: 700, loss is 3.819945282936096 and perplexity is 45.60171306073503
At time: 608.094532251358 and batch: 750, loss is 3.7827473497390747 and perplexity is 43.93658523816252
At time: 608.9250071048737 and batch: 800, loss is 3.7420080041885377 and perplexity is 42.18260803366242
At time: 609.7558970451355 and batch: 850, loss is 3.729293088912964 and perplexity is 41.64965515192729
At time: 610.5863614082336 and batch: 900, loss is 3.67416214466095 and perplexity is 39.41561843207755
At time: 611.4198484420776 and batch: 950, loss is 3.7900604104995725 and perplexity is 44.259073907990235
At time: 612.2568762302399 and batch: 1000, loss is 3.7563535022735595 and perplexity is 42.792099835761434
At time: 613.1142065525055 and batch: 1050, loss is 3.703272523880005 and perplexity is 40.579885949353475
At time: 613.948873758316 and batch: 1100, loss is 3.7102861833572387 and perplexity is 40.86549987963979
At time: 614.7854239940643 and batch: 1150, loss is 3.6978577375411987 and perplexity is 40.36074836430979
At time: 615.6263699531555 and batch: 1200, loss is 3.754424738883972 and perplexity is 42.70964354513428
At time: 616.4597697257996 and batch: 1250, loss is 3.7407422256469727 and perplexity is 42.129247971721284
At time: 617.2918474674225 and batch: 1300, loss is 3.725669584274292 and perplexity is 41.499010528858044
At time: 618.1263508796692 and batch: 1350, loss is 3.609019603729248 and perplexity is 36.92982919415118
At time: 618.9611144065857 and batch: 1400, loss is 3.6362372922897337 and perplexity is 37.948777591293144
At time: 619.7945024967194 and batch: 1450, loss is 3.5504768800735476 and perplexity is 34.82992322416368
At time: 620.6287910938263 and batch: 1500, loss is 3.5729238891601565 and perplexity is 35.62059169937202
At time: 621.4618186950684 and batch: 1550, loss is 3.560569725036621 and perplexity is 35.18323620672334
At time: 622.2922456264496 and batch: 1600, loss is 3.6570558738708496 and perplexity is 38.747098433909166
At time: 623.1279134750366 and batch: 1650, loss is 3.6019755935668947 and perplexity is 36.67060914816523
At time: 623.9597573280334 and batch: 1700, loss is 3.6273242092132567 and perplexity is 37.61203989877157
At time: 624.7915396690369 and batch: 1750, loss is 3.6158559131622314 and perplexity is 37.18315786380511
At time: 625.6252925395966 and batch: 1800, loss is 3.5695841789245604 and perplexity is 35.50182767377941
At time: 626.4572689533234 and batch: 1850, loss is 3.587310619354248 and perplexity is 36.13675962291027
At time: 627.2903904914856 and batch: 1900, loss is 3.691448240280151 and perplexity is 40.10288353297224
At time: 628.1221671104431 and batch: 1950, loss is 3.6336787128448487 and perplexity is 37.85180673570873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.237315758993459 and perplexity of 69.22179426007918
finished 18 epochs...
Completing Train Step...
At time: 631.2851581573486 and batch: 50, loss is 3.813042206764221 and perplexity is 45.28800498303268
At time: 632.1201665401459 and batch: 100, loss is 3.7877039194107054 and perplexity is 44.15490058468521
At time: 632.9532604217529 and batch: 150, loss is 3.7700514507293703 and perplexity is 43.3822968292459
At time: 633.790219783783 and batch: 200, loss is 3.767894997596741 and perplexity is 43.28884573701267
At time: 634.6485586166382 and batch: 250, loss is 3.763358864784241 and perplexity is 43.09292647728537
At time: 635.480063199997 and batch: 300, loss is 3.750156478881836 and perplexity is 42.52773617203373
At time: 636.3136701583862 and batch: 350, loss is 3.7735763216018676 and perplexity is 43.535483646988794
At time: 637.1432590484619 and batch: 400, loss is 3.749842448234558 and perplexity is 42.51438325623848
At time: 637.9751434326172 and batch: 450, loss is 3.7922619009017944 and perplexity is 44.3566171652865
At time: 638.8161525726318 and batch: 500, loss is 3.797442021369934 and perplexity is 44.58698593962744
At time: 639.6627643108368 and batch: 550, loss is 3.7686774492263795 and perplexity is 43.32273041973861
At time: 640.4921889305115 and batch: 600, loss is 3.738107056617737 and perplexity is 42.018376429027704
At time: 641.327850818634 and batch: 650, loss is 3.7661781883239747 and perplexity is 43.21459080426103
At time: 642.1630156040192 and batch: 700, loss is 3.8079374551773073 and perplexity is 45.057410033440924
At time: 642.9977879524231 and batch: 750, loss is 3.7728156423568726 and perplexity is 43.502379700496476
At time: 643.8349709510803 and batch: 800, loss is 3.7326059341430664 and perplexity is 41.7878628172334
At time: 644.6676585674286 and batch: 850, loss is 3.7207783126831053 and perplexity is 41.296523211528424
At time: 645.5023672580719 and batch: 900, loss is 3.66620578289032 and perplexity is 39.10325778736175
At time: 646.3373539447784 and batch: 950, loss is 3.7827610778808594 and perplexity is 43.93718840997441
At time: 647.1700432300568 and batch: 1000, loss is 3.7506341457366945 and perplexity is 42.5480551144716
At time: 648.0037965774536 and batch: 1050, loss is 3.6976481819152833 and perplexity is 40.352291428554075
At time: 648.8344039916992 and batch: 1100, loss is 3.7059230375289918 and perplexity is 40.68758615832201
At time: 649.6649694442749 and batch: 1150, loss is 3.6932950592041016 and perplexity is 40.17701472956409
At time: 650.4949762821198 and batch: 1200, loss is 3.7516608095169066 and perplexity is 42.59176009289638
At time: 651.3250422477722 and batch: 1250, loss is 3.739177722930908 and perplexity is 42.06338818118793
At time: 652.1582658290863 and batch: 1300, loss is 3.723909268379211 and perplexity is 41.42602342002505
At time: 652.9896185398102 and batch: 1350, loss is 3.607486910820007 and perplexity is 36.87327046146218
At time: 653.8230226039886 and batch: 1400, loss is 3.6362190580368043 and perplexity is 37.9480856299929
At time: 654.6508548259735 and batch: 1450, loss is 3.5511918449401856 and perplexity is 34.85483429978743
At time: 655.4822640419006 and batch: 1500, loss is 3.5747198915481566 and perplexity is 35.68462385086259
At time: 656.3146786689758 and batch: 1550, loss is 3.5632844829559325 and perplexity is 35.27887994189582
At time: 657.1515955924988 and batch: 1600, loss is 3.660289978981018 and perplexity is 38.87261347797983
At time: 657.984587430954 and batch: 1650, loss is 3.6062454748153687 and perplexity is 36.827523058014776
At time: 658.8195021152496 and batch: 1700, loss is 3.6322994327545164 and perplexity is 37.799634480642496
At time: 659.6505725383759 and batch: 1750, loss is 3.6210297107696534 and perplexity is 37.37603451913995
At time: 660.4831879138947 and batch: 1800, loss is 3.574899826049805 and perplexity is 35.691045323576624
At time: 661.314035654068 and batch: 1850, loss is 3.592133836746216 and perplexity is 36.31147607943025
At time: 662.1450362205505 and batch: 1900, loss is 3.6977706956863403 and perplexity is 40.35723544279651
At time: 662.978542804718 and batch: 1950, loss is 3.639176149368286 and perplexity is 38.06046766513397
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.236274754723837 and perplexity of 69.14977157117107
finished 19 epochs...
Completing Train Step...
At time: 666.1735606193542 and batch: 50, loss is 3.813428463935852 and perplexity is 45.3055011785442
At time: 667.0111801624298 and batch: 100, loss is 3.78623770236969 and perplexity is 44.0902073557507
At time: 667.8421061038971 and batch: 150, loss is 3.767763433456421 and perplexity is 43.28315085186738
At time: 668.6761054992676 and batch: 200, loss is 3.7646127939224243 and perplexity is 43.14699584593864
At time: 669.5094921588898 and batch: 250, loss is 3.7589111852645876 and perplexity is 42.90168854851329
At time: 670.3417708873749 and batch: 300, loss is 3.745044636726379 and perplexity is 42.310895796566065
At time: 671.1754353046417 and batch: 350, loss is 3.7678873634338377 and perplexity is 43.28851526417387
At time: 672.0103847980499 and batch: 400, loss is 3.743938627243042 and perplexity is 42.26412541357781
At time: 672.8414421081543 and batch: 450, loss is 3.7859042739868163 and perplexity is 44.075508879792224
At time: 673.674934387207 and batch: 500, loss is 3.791165051460266 and perplexity is 44.30799130701848
At time: 674.507785320282 and batch: 550, loss is 3.7619382619857786 and perplexity is 43.031752007937065
At time: 675.3394634723663 and batch: 600, loss is 3.7321448516845703 and perplexity is 41.76859960801554
At time: 676.1730573177338 and batch: 650, loss is 3.7607793378829957 and perplexity is 42.98191036027203
At time: 677.0322864055634 and batch: 700, loss is 3.8028386926651 and perplexity is 44.82825769339224
At time: 677.8664934635162 and batch: 750, loss is 3.768462142944336 and perplexity is 43.313403767803365
At time: 678.6972811222076 and batch: 800, loss is 3.7287275075912474 and perplexity is 41.626105545154054
At time: 679.5298519134521 and batch: 850, loss is 3.71724235534668 and perplexity is 41.150758328388484
At time: 680.3631961345673 and batch: 900, loss is 3.6632514572143555 and perplexity is 38.98790450834436
At time: 681.1971025466919 and batch: 950, loss is 3.7800434684753417 and perplexity is 43.81794639349971
At time: 682.0299828052521 and batch: 1000, loss is 3.74820294380188 and perplexity is 42.44473784401875
At time: 682.863988161087 and batch: 1050, loss is 3.695312623977661 and perplexity is 40.25815628583769
At time: 683.6994209289551 and batch: 1100, loss is 3.7039776039123535 and perplexity is 40.608508105921125
At time: 684.5324599742889 and batch: 1150, loss is 3.6912128829956057 and perplexity is 40.09344613782489
At time: 685.3638997077942 and batch: 1200, loss is 3.750331597328186 and perplexity is 42.535184215244804
At time: 686.1942195892334 and batch: 1250, loss is 3.7384351778030394 and perplexity is 42.03216581067649
At time: 687.0243756771088 and batch: 1300, loss is 3.723410310745239 and perplexity is 41.40535874522187
At time: 687.8564760684967 and batch: 1350, loss is 3.6069709062576294 and perplexity is 36.85424859378159
At time: 688.6903598308563 and batch: 1400, loss is 3.636200728416443 and perplexity is 37.94739006236462
At time: 689.523184299469 and batch: 1450, loss is 3.5516046667099 and perplexity is 34.86922610458694
At time: 690.3551766872406 and batch: 1500, loss is 3.5756066179275514 and perplexity is 35.71628038143605
At time: 691.1894640922546 and batch: 1550, loss is 3.564633164405823 and perplexity is 35.32649201238753
At time: 692.0271451473236 and batch: 1600, loss is 3.661775588989258 and perplexity is 38.9304059395096
At time: 692.8642604351044 and batch: 1650, loss is 3.6080715370178225 and perplexity is 36.89483384401807
At time: 693.7008798122406 and batch: 1700, loss is 3.634454855918884 and perplexity is 37.881196557224214
At time: 694.5320332050323 and batch: 1750, loss is 3.6233374547958372 and perplexity is 37.46238844257495
At time: 695.365149974823 and batch: 1800, loss is 3.5771598052978515 and perplexity is 35.77179756016825
At time: 696.1965610980988 and batch: 1850, loss is 3.594142689704895 and perplexity is 36.38449381197526
At time: 697.0300095081329 and batch: 1900, loss is 3.7002349376678465 and perplexity is 40.45680807177064
At time: 697.8625428676605 and batch: 1950, loss is 3.641067695617676 and perplexity is 38.132528932119676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.235831611101017 and perplexity of 69.11913507956415
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
1477.7998116016388


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4797296524047852 and batch: 50, loss is 7.667218971252441 and perplexity is 2137.129753888473
At time: 2.377251625061035 and batch: 100, loss is 6.741279611587524 and perplexity is 846.6434177249903
At time: 3.2675161361694336 and batch: 150, loss is 6.5205151462554936 and perplexity is 678.9280425082671
At time: 4.161935567855835 and batch: 200, loss is 6.335194644927978 and perplexity is 564.0791874530435
At time: 5.059172630310059 and batch: 250, loss is 6.238985424041748 and perplexity is 512.3384408975355
At time: 5.95307183265686 and batch: 300, loss is 6.15122537612915 and perplexity is 469.29209392379136
At time: 6.85183572769165 and batch: 350, loss is 6.064039936065674 and perplexity is 430.10954672425095
At time: 7.747107744216919 and batch: 400, loss is 5.990654382705689 and perplexity is 399.6760654769106
At time: 8.644401788711548 and batch: 450, loss is 5.8933901023864745 and perplexity is 362.63256441641806
At time: 9.542963027954102 and batch: 500, loss is 5.855119504928589 and perplexity is 349.01660676652494
At time: 10.439513444900513 and batch: 550, loss is 5.795338687896728 and perplexity is 328.76351335079005
At time: 11.337913751602173 and batch: 600, loss is 5.807350788116455 and perplexity is 332.73646761259795
At time: 12.23357367515564 and batch: 650, loss is 5.859230976104737 and perplexity is 350.4545324546717
At time: 13.13236403465271 and batch: 700, loss is 5.782835187911988 and perplexity is 324.67841102614125
At time: 14.028838872909546 and batch: 750, loss is 5.713301744461059 and perplexity is 302.8694166490822
At time: 14.926770687103271 and batch: 800, loss is 5.701852521896362 and perplexity is 299.42157252044353
At time: 15.820661067962646 and batch: 850, loss is 5.713105459213256 and perplexity is 302.8099736846627
At time: 16.71753191947937 and batch: 900, loss is 5.7005605792999265 and perplexity is 299.0349868136548
At time: 17.612497568130493 and batch: 950, loss is 5.715465002059936 and perplexity is 303.5253103938983
At time: 18.508508682250977 and batch: 1000, loss is 5.687212038040161 and perplexity is 295.0698293649411
At time: 19.403825759887695 and batch: 1050, loss is 5.58148494720459 and perplexity is 265.4655155214523
At time: 20.298563718795776 and batch: 1100, loss is 5.657957935333252 and perplexity is 286.5628647606145
At time: 21.198301792144775 and batch: 1150, loss is 5.557224769592285 and perplexity is 259.10276772725797
At time: 22.096020936965942 and batch: 1200, loss is 5.625946464538575 and perplexity is 277.5348371367344
At time: 22.993120908737183 and batch: 1250, loss is 5.572899379730225 and perplexity is 263.19609947835164
At time: 23.889785528182983 and batch: 1300, loss is 5.586268424987793 and perplexity is 266.73840591145336
At time: 24.79078769683838 and batch: 1350, loss is 5.543705434799194 and perplexity is 255.62344273778737
At time: 25.68697953224182 and batch: 1400, loss is 5.548620243072509 and perplexity is 256.88287534874877
At time: 26.579498767852783 and batch: 1450, loss is 5.518588733673096 and perplexity is 249.28298414642634
At time: 27.474756717681885 and batch: 1500, loss is 5.475908832550049 and perplexity is 238.8674588328065
At time: 28.373193502426147 and batch: 1550, loss is 5.45573522567749 and perplexity is 234.0969218816211
At time: 29.271404266357422 and batch: 1600, loss is 5.475166845321655 and perplexity is 238.6902879664621
At time: 30.167563676834106 and batch: 1650, loss is 5.4659716796875 and perplexity is 236.5055511353258
At time: 31.059708833694458 and batch: 1700, loss is 5.4860726261138915 and perplexity is 241.30763810631078
At time: 31.956358671188354 and batch: 1750, loss is 5.487004547119141 and perplexity is 241.53262258058507
At time: 32.85276198387146 and batch: 1800, loss is 5.478784465789795 and perplexity is 239.5553426140286
At time: 33.749351501464844 and batch: 1850, loss is 5.4467698097229 and perplexity is 232.0075257511886
At time: 34.64223074913025 and batch: 1900, loss is 5.467250747680664 and perplexity is 236.80825136180576
At time: 35.53458118438721 and batch: 1950, loss is 5.396749114990234 and perplexity is 220.68781807748243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.963987554505814 and perplexity of 143.16353160147938
finished 1 epochs...
Completing Train Step...
At time: 38.729623556137085 and batch: 50, loss is 5.190985507965088 and perplexity is 179.6455078011242
At time: 39.56330585479736 and batch: 100, loss is 5.124823570251465 and perplexity is 168.1444733475864
At time: 40.40146040916443 and batch: 150, loss is 5.0461509323120115 and perplexity is 155.42307773982827
At time: 41.241074085235596 and batch: 200, loss is 5.001343851089477 and perplexity is 148.61273836049537
At time: 42.06473708152771 and batch: 250, loss is 5.014064836502075 and perplexity is 150.51531450225806
At time: 42.91765642166138 and batch: 300, loss is 5.014107160568237 and perplexity is 150.5216850572004
At time: 43.77958011627197 and batch: 350, loss is 5.010268583297729 and perplexity is 149.945003464749
At time: 44.61566162109375 and batch: 400, loss is 4.96630518913269 and perplexity is 143.49571715330094
At time: 45.45100235939026 and batch: 450, loss is 4.9250192451477055 and perplexity is 137.69199152007457
At time: 46.28694176673889 and batch: 500, loss is 4.909139127731323 and perplexity is 135.52269644489874
At time: 47.125696659088135 and batch: 550, loss is 4.862616243362427 and perplexity is 129.3622027729394
At time: 47.96061301231384 and batch: 600, loss is 4.846302671432495 and perplexity is 127.26896369914928
At time: 48.79718327522278 and batch: 650, loss is 4.919443397521973 and perplexity is 136.92637841067395
At time: 49.63252353668213 and batch: 700, loss is 4.90298487663269 and perplexity is 134.69121693260618
At time: 50.47197341918945 and batch: 750, loss is 4.862698774337769 and perplexity is 129.37287960228514
At time: 51.309895038604736 and batch: 800, loss is 4.841422100067138 and perplexity is 126.64933174816683
At time: 52.14610004425049 and batch: 850, loss is 4.83398362159729 and perplexity is 125.7107485638636
At time: 52.98289203643799 and batch: 900, loss is 4.833550109863281 and perplexity is 125.65626329012615
At time: 53.82067561149597 and batch: 950, loss is 4.889130640029907 and perplexity is 132.83803976384075
At time: 54.66656279563904 and batch: 1000, loss is 4.860577945709228 and perplexity is 129.09879264393683
At time: 55.50797176361084 and batch: 1050, loss is 4.769217939376831 and perplexity is 117.82705801623423
At time: 56.344484090805054 and batch: 1100, loss is 4.837117004394531 and perplexity is 126.10526622548494
At time: 57.177733182907104 and batch: 1150, loss is 4.758964586257934 and perplexity is 116.62510812197111
At time: 58.014193058013916 and batch: 1200, loss is 4.840817279815674 and perplexity is 126.57275482746172
At time: 58.84937644004822 and batch: 1250, loss is 4.79516562461853 and perplexity is 120.92440818355246
At time: 59.68616962432861 and batch: 1300, loss is 4.814057607650756 and perplexity is 123.23062597311018
At time: 60.51871395111084 and batch: 1350, loss is 4.717257928848267 and perplexity is 111.86110064683159
At time: 61.356908321380615 and batch: 1400, loss is 4.733472166061401 and perplexity is 113.68962708836025
At time: 62.19176745414734 and batch: 1450, loss is 4.678216857910156 and perplexity is 107.57807444981182
At time: 63.02665138244629 and batch: 1500, loss is 4.652763051986694 and perplexity is 104.8743589219885
At time: 63.862151861190796 and batch: 1550, loss is 4.652408428192139 and perplexity is 104.83717457249327
At time: 64.6997401714325 and batch: 1600, loss is 4.717014007568359 and perplexity is 111.83381867145236
At time: 65.5355064868927 and batch: 1650, loss is 4.676104173660279 and perplexity is 107.35103586116237
At time: 66.37270450592041 and batch: 1700, loss is 4.7139262771606445 and perplexity is 111.48903855688158
At time: 67.20784950256348 and batch: 1750, loss is 4.704093151092529 and perplexity is 110.39812512026892
At time: 68.04414463043213 and batch: 1800, loss is 4.663228302001953 and perplexity is 105.9776583911281
At time: 68.8780369758606 and batch: 1850, loss is 4.671772480010986 and perplexity is 106.88702975256857
At time: 69.71265172958374 and batch: 1900, loss is 4.7524786472320555 and perplexity is 115.87113254476367
At time: 70.55211281776428 and batch: 1950, loss is 4.6716539096832275 and perplexity is 106.87435687374618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.556886468931686 and perplexity of 95.28634051228744
finished 2 epochs...
Completing Train Step...
At time: 73.72399520874023 and batch: 50, loss is 4.631956462860107 and perplexity is 102.71482539652564
At time: 74.58300995826721 and batch: 100, loss is 4.580027208328247 and perplexity is 97.51704744679537
At time: 75.42005157470703 and batch: 150, loss is 4.542410001754761 and perplexity is 93.91686741403656
At time: 76.25057554244995 and batch: 200, loss is 4.531497964859009 and perplexity is 92.8976142693772
At time: 77.08578896522522 and batch: 250, loss is 4.533884468078614 and perplexity is 93.11957947992117
At time: 77.92042779922485 and batch: 300, loss is 4.553343067169189 and perplexity is 94.94930021261817
At time: 78.75470280647278 and batch: 350, loss is 4.570932569503785 and perplexity is 96.63418585996662
At time: 79.59446716308594 and batch: 400, loss is 4.526640329360962 and perplexity is 92.44744578303244
At time: 80.42901706695557 and batch: 450, loss is 4.522986125946045 and perplexity is 92.11024049454089
At time: 81.2648286819458 and batch: 500, loss is 4.525510187149048 and perplexity is 92.3430260378642
At time: 82.09976029396057 and batch: 550, loss is 4.489751625061035 and perplexity is 89.0993130937064
At time: 82.93429684638977 and batch: 600, loss is 4.47251293182373 and perplexity is 87.5765205551717
At time: 83.7673556804657 and batch: 650, loss is 4.540424165725708 and perplexity is 93.73054897515392
At time: 84.60061526298523 and batch: 700, loss is 4.548674879074096 and perplexity is 94.50709197838465
At time: 85.43643021583557 and batch: 750, loss is 4.517876529693604 and perplexity is 91.64079471545136
At time: 86.2970495223999 and batch: 800, loss is 4.4930431842803955 and perplexity is 89.39307195628076
At time: 87.1390655040741 and batch: 850, loss is 4.486123323440552 and perplexity is 88.77661968015222
At time: 87.97470664978027 and batch: 900, loss is 4.474233083724975 and perplexity is 87.72729511390352
At time: 88.8054792881012 and batch: 950, loss is 4.543415613174439 and perplexity is 94.01135879124956
At time: 89.64275789260864 and batch: 1000, loss is 4.5304085159301755 and perplexity is 92.79646217304655
At time: 90.47371363639832 and batch: 1050, loss is 4.453013639450074 and perplexity is 85.88538196245614
At time: 91.30871725082397 and batch: 1100, loss is 4.514696397781372 and perplexity is 91.34982780151681
At time: 92.14561796188354 and batch: 1150, loss is 4.454102563858032 and perplexity is 85.97895558921866
At time: 92.98282980918884 and batch: 1200, loss is 4.5303612899780275 and perplexity is 92.79207987524437
At time: 93.81789350509644 and batch: 1250, loss is 4.496265859603882 and perplexity is 89.68162150438819
At time: 94.65234231948853 and batch: 1300, loss is 4.510418119430542 and perplexity is 90.95984263826841
At time: 95.48638010025024 and batch: 1350, loss is 4.394813966751099 and perplexity is 81.02955516908501
At time: 96.32043266296387 and batch: 1400, loss is 4.4201988697052 and perplexity is 83.11281233541929
At time: 97.1550509929657 and batch: 1450, loss is 4.365382604598999 and perplexity is 78.67949732123388
At time: 97.98695492744446 and batch: 1500, loss is 4.361113085746765 and perplexity is 78.34428982071017
At time: 98.82363486289978 and batch: 1550, loss is 4.3661229705810545 and perplexity is 78.73777051361859
At time: 99.65494275093079 and batch: 1600, loss is 4.4383830738067624 and perplexity is 84.63797761033678
At time: 100.48904919624329 and batch: 1650, loss is 4.395186090469361 and perplexity is 81.05971379946645
At time: 101.32714080810547 and batch: 1700, loss is 4.426704216003418 and perplexity is 83.65525242882394
At time: 102.16183614730835 and batch: 1750, loss is 4.423323850631714 and perplexity is 83.37294453109783
At time: 102.99603986740112 and batch: 1800, loss is 4.383416376113892 and perplexity is 80.11125660625231
At time: 103.82828760147095 and batch: 1850, loss is 4.407714548110962 and perplexity is 82.08165529848321
At time: 104.6597490310669 and batch: 1900, loss is 4.497830114364624 and perplexity is 89.82201618567426
At time: 105.49509835243225 and batch: 1950, loss is 4.419870386123657 and perplexity is 83.08551562465732
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.430098564680232 and perplexity of 83.93968999124814
finished 3 epochs...
Completing Train Step...
At time: 108.6413402557373 and batch: 50, loss is 4.390011129379272 and perplexity is 80.6413164632787
At time: 109.50006413459778 and batch: 100, loss is 4.343767290115356 and perplexity is 76.9970639121282
At time: 110.3360002040863 and batch: 150, loss is 4.311886148452759 and perplexity is 74.58102724977593
At time: 111.16772699356079 and batch: 200, loss is 4.310120611190796 and perplexity is 74.44946783782687
At time: 112.00881934165955 and batch: 250, loss is 4.299832191467285 and perplexity is 73.68742728297781
At time: 112.84341812133789 and batch: 300, loss is 4.329531908035278 and perplexity is 75.90874597765936
At time: 113.67726373672485 and batch: 350, loss is 4.342383537292481 and perplexity is 76.8905926895031
At time: 114.51284193992615 and batch: 400, loss is 4.296428442001343 and perplexity is 73.43704011105662
At time: 115.34591579437256 and batch: 450, loss is 4.317533493041992 and perplexity is 75.00340354015103
At time: 116.18120527267456 and batch: 500, loss is 4.323033142089844 and perplexity is 75.41703230097096
At time: 117.01924443244934 and batch: 550, loss is 4.291738471984863 and perplexity is 73.09342898760369
At time: 117.85066556930542 and batch: 600, loss is 4.27817485332489 and perplexity is 72.10871085751496
At time: 118.68400144577026 and batch: 650, loss is 4.3321969699859615 and perplexity is 76.11131730095369
At time: 119.5187120437622 and batch: 700, loss is 4.354112825393677 and perplexity is 77.79777450131716
At time: 120.3507947921753 and batch: 750, loss is 4.326566619873047 and perplexity is 75.68398807246989
At time: 121.18730068206787 and batch: 800, loss is 4.300436000823975 and perplexity is 73.73193387643826
At time: 122.02243947982788 and batch: 850, loss is 4.293565998077392 and perplexity is 73.22713127126482
At time: 122.8557288646698 and batch: 900, loss is 4.278873691558838 and perplexity is 72.15912079380674
At time: 123.68834590911865 and batch: 950, loss is 4.354887742996215 and perplexity is 77.85808473092783
At time: 124.52278542518616 and batch: 1000, loss is 4.342790374755859 and perplexity is 76.92188102739301
At time: 125.35496973991394 and batch: 1050, loss is 4.27372935295105 and perplexity is 71.78886302501877
At time: 126.18605732917786 and batch: 1100, loss is 4.325558099746704 and perplexity is 75.60769772389924
At time: 127.01964020729065 and batch: 1150, loss is 4.274022445678711 and perplexity is 71.80990690245154
At time: 127.85487961769104 and batch: 1200, loss is 4.349667615890503 and perplexity is 77.45271459476128
At time: 128.71605396270752 and batch: 1250, loss is 4.325670642852783 and perplexity is 75.61620732788421
At time: 129.54873037338257 and batch: 1300, loss is 4.331976690292358 and perplexity is 76.09455336974351
At time: 130.3868715763092 and batch: 1350, loss is 4.2188140535354615 and perplexity is 67.95284804384261
At time: 131.22369122505188 and batch: 1400, loss is 4.241438517570495 and perplexity is 69.5077681015754
At time: 132.06251978874207 and batch: 1450, loss is 4.183053326606751 and perplexity is 65.56574151964895
At time: 132.89597392082214 and batch: 1500, loss is 4.185460867881775 and perplexity is 65.72378391904715
At time: 133.73109483718872 and batch: 1550, loss is 4.197722473144531 and perplexity is 66.53462395514478
At time: 134.5643274784088 and batch: 1600, loss is 4.27227162361145 and perplexity is 71.68429053084496
At time: 135.39500164985657 and batch: 1650, loss is 4.229460983276367 and perplexity is 68.68020241722861
At time: 136.23192954063416 and batch: 1700, loss is 4.260295081138611 and perplexity is 70.83088122793704
At time: 137.0568995475769 and batch: 1750, loss is 4.255591559410095 and perplexity is 70.4985089119956
At time: 137.88906741142273 and batch: 1800, loss is 4.215055804252625 and perplexity is 67.69794359867102
At time: 138.73427033424377 and batch: 1850, loss is 4.2470660972595216 and perplexity is 69.90003131658803
At time: 139.57143783569336 and batch: 1900, loss is 4.335166683197022 and perplexity is 76.33768203826608
At time: 140.40901589393616 and batch: 1950, loss is 4.258125200271606 and perplexity is 70.67735328288177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382654660247093 and perplexity of 80.05025782580498
finished 4 epochs...
Completing Train Step...
At time: 143.58527421951294 and batch: 50, loss is 4.237160663604737 and perplexity is 69.21105911149792
At time: 144.4484372138977 and batch: 100, loss is 4.190946345329285 and perplexity is 66.08530089358813
At time: 145.28632402420044 and batch: 150, loss is 4.165573005676269 and perplexity is 64.42959038923408
At time: 146.1248254776001 and batch: 200, loss is 4.161410846710205 and perplexity is 64.16198149362609
At time: 146.96353721618652 and batch: 250, loss is 4.1521389245986935 and perplexity is 63.5698260504924
At time: 147.79957342147827 and batch: 300, loss is 4.179333910942078 and perplexity is 65.32232823178877
At time: 148.6365361213684 and batch: 350, loss is 4.192422375679016 and perplexity is 66.18291682769619
At time: 149.50033926963806 and batch: 400, loss is 4.147989573478699 and perplexity is 63.3065990099471
At time: 150.3361246585846 and batch: 450, loss is 4.180390944480896 and perplexity is 65.39141262939366
At time: 151.17445039749146 and batch: 500, loss is 4.189145364761353 and perplexity is 65.96638966140308
At time: 152.0103418827057 and batch: 550, loss is 4.156019263267517 and perplexity is 63.81697771064443
At time: 152.84489488601685 and batch: 600, loss is 4.144726076126099 and perplexity is 63.100334846019
At time: 153.68456411361694 and batch: 650, loss is 4.1945839738845825 and perplexity is 66.32613243348365
At time: 154.52080035209656 and batch: 700, loss is 4.219316935539245 and perplexity is 67.98702890197859
At time: 155.3599054813385 and batch: 750, loss is 4.189037165641785 and perplexity is 65.95925254224261
At time: 156.19541549682617 and batch: 800, loss is 4.163469166755676 and perplexity is 64.29418339653017
At time: 157.03235149383545 and batch: 850, loss is 4.161668424606323 and perplexity is 64.1785103304701
At time: 157.87058687210083 and batch: 900, loss is 4.145879421234131 and perplexity is 63.173153292856625
At time: 158.7080316543579 and batch: 950, loss is 4.231419930458069 and perplexity is 68.81487517153182
At time: 159.54265689849854 and batch: 1000, loss is 4.21367205619812 and perplexity is 67.60433148365043
At time: 160.3785753250122 and batch: 1050, loss is 4.157620372772217 and perplexity is 63.919237522951214
At time: 161.20989084243774 and batch: 1100, loss is 4.199003067016601 and perplexity is 66.61988236591
At time: 162.04381251335144 and batch: 1150, loss is 4.1469795656204225 and perplexity is 63.24269112663125
At time: 162.8731667995453 and batch: 1200, loss is 4.224070372581482 and perplexity is 68.31097027104572
At time: 163.70478224754333 and batch: 1250, loss is 4.208215985298157 and perplexity is 67.23648187723117
At time: 164.53579902648926 and batch: 1300, loss is 4.210246410369873 and perplexity is 67.37313920505208
At time: 165.37305760383606 and batch: 1350, loss is 4.092696604728698 and perplexity is 59.90120397857666
At time: 166.20301604270935 and batch: 1400, loss is 4.1231448936462405 and perplexity is 61.75314427508064
At time: 167.04019141197205 and batch: 1450, loss is 4.057591648101806 and perplexity is 57.834856532042075
At time: 167.88280296325684 and batch: 1500, loss is 4.067863054275513 and perplexity is 58.43196314712508
At time: 168.7099006175995 and batch: 1550, loss is 4.077139930725098 and perplexity is 58.97655138321921
At time: 169.49698877334595 and batch: 1600, loss is 4.160786604881286 and perplexity is 64.12194139960243
At time: 170.32820987701416 and batch: 1650, loss is 4.111543822288513 and perplexity is 61.04088113782323
At time: 171.16282868385315 and batch: 1700, loss is 4.142902250289917 and perplexity is 62.98535570788814
At time: 171.9980628490448 and batch: 1750, loss is 4.13811086177826 and perplexity is 62.684290234944115
At time: 172.8326108455658 and batch: 1800, loss is 4.095745167732239 and perplexity is 60.084095208967376
At time: 173.66565489768982 and batch: 1850, loss is 4.13205988407135 and perplexity is 62.30613425269486
At time: 174.49923706054688 and batch: 1900, loss is 4.214468603134155 and perplexity is 67.65820295948757
At time: 175.33306002616882 and batch: 1950, loss is 4.1403798532485965 and perplexity is 62.82668183638607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370926825944768 and perplexity of 79.11692534817317
finished 5 epochs...
Completing Train Step...
At time: 178.5417594909668 and batch: 50, loss is 4.1290131950378415 and perplexity is 62.11659571585066
At time: 179.3770935535431 and batch: 100, loss is 4.082108092308045 and perplexity is 59.27028547513431
At time: 180.2126441001892 and batch: 150, loss is 4.062684860229492 and perplexity is 58.130173141406466
At time: 181.04687905311584 and batch: 200, loss is 4.056474642753601 and perplexity is 57.770290754855544
At time: 181.88138222694397 and batch: 250, loss is 4.049561843872071 and perplexity is 57.372313506714214
At time: 182.71377182006836 and batch: 300, loss is 4.071855540275574 and perplexity is 58.6657182634572
At time: 183.55474185943604 and batch: 350, loss is 4.080820078849793 and perplexity is 59.19399369273634
At time: 184.39059138298035 and batch: 400, loss is 4.038701415061951 and perplexity is 56.75259686566404
At time: 185.22646594047546 and batch: 450, loss is 4.078455376625061 and perplexity is 59.05418289476256
At time: 186.07802057266235 and batch: 500, loss is 4.087843904495239 and perplexity is 59.61122555028967
At time: 186.9121232032776 and batch: 550, loss is 4.05536901473999 and perplexity is 57.70645359961905
At time: 187.74902868270874 and batch: 600, loss is 4.0485939693450925 and perplexity is 57.316811169899054
At time: 188.58851099014282 and batch: 650, loss is 4.0898068189620975 and perplexity is 59.728352204503764
At time: 189.4259753227234 and batch: 700, loss is 4.119048752784729 and perplexity is 61.50071204941583
At time: 190.26348161697388 and batch: 750, loss is 4.089328665733337 and perplexity is 59.69979972682233
At time: 191.11387085914612 and batch: 800, loss is 4.063836445808411 and perplexity is 58.19715356994178
At time: 191.9793782234192 and batch: 850, loss is 4.062013835906982 and perplexity is 58.09117946567245
At time: 192.8164095878601 and batch: 900, loss is 4.04668312549591 and perplexity is 57.207392268331496
At time: 193.6570131778717 and batch: 950, loss is 4.134358658790588 and perplexity is 62.449526769369655
At time: 194.49402832984924 and batch: 1000, loss is 4.1146970558166505 and perplexity is 61.23366107115642
At time: 195.3259093761444 and batch: 1050, loss is 4.059933710098266 and perplexity is 57.97046809495172
At time: 196.1617124080658 and batch: 1100, loss is 4.099640612602234 and perplexity is 60.31860595470982
At time: 196.9985053539276 and batch: 1150, loss is 4.052725253105163 and perplexity is 57.5540929828305
At time: 197.83302426338196 and batch: 1200, loss is 4.128803510665893 and perplexity is 62.1035722019518
At time: 198.6657738685608 and batch: 1250, loss is 4.1131000995635985 and perplexity is 61.13595163282628
At time: 199.5012195110321 and batch: 1300, loss is 4.118153533935547 and perplexity is 61.44568008925039
At time: 200.33587217330933 and batch: 1350, loss is 3.9992111921310425 and perplexity is 54.55509956427411
At time: 201.17008543014526 and batch: 1400, loss is 4.033820276260376 and perplexity is 56.47625454429291
At time: 202.00522685050964 and batch: 1450, loss is 3.964047574996948 and perplexity is 52.67008119095449
At time: 202.83831095695496 and batch: 1500, loss is 3.979923791885376 and perplexity is 53.512955950613275
At time: 203.6734492778778 and batch: 1550, loss is 3.9862846183776854 and perplexity is 53.854427447647566
At time: 204.5083887577057 and batch: 1600, loss is 4.070132131576538 and perplexity is 58.56470032686522
At time: 205.34388089179993 and batch: 1650, loss is 4.02698673248291 and perplexity is 56.091637232810285
At time: 206.1785261631012 and batch: 1700, loss is 4.056273460388184 and perplexity is 57.75866956013954
At time: 207.0157172679901 and batch: 1750, loss is 4.048572654724121 and perplexity is 57.31558949681348
At time: 207.8517246246338 and batch: 1800, loss is 4.00859290599823 and perplexity is 55.06932830009835
At time: 208.68812370300293 and batch: 1850, loss is 4.037729740142822 and perplexity is 56.697478573561945
At time: 209.52475500106812 and batch: 1900, loss is 4.125215477943421 and perplexity is 61.881141835056475
At time: 210.3618516921997 and batch: 1950, loss is 4.052593779563904 and perplexity is 57.54652663980994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356493005087209 and perplexity of 77.98316773146308
finished 6 epochs...
Completing Train Step...
At time: 213.52315616607666 and batch: 50, loss is 4.046554012298584 and perplexity is 57.200006515814344
At time: 214.3581395149231 and batch: 100, loss is 4.00261432170868 and perplexity is 54.74107390511701
At time: 215.19063210487366 and batch: 150, loss is 3.981475133895874 and perplexity is 53.59603727439695
At time: 216.02739238739014 and batch: 200, loss is 3.97595534324646 and perplexity is 53.30101335321238
At time: 216.8642542362213 and batch: 250, loss is 3.966341018676758 and perplexity is 52.791015680989425
At time: 217.69988536834717 and batch: 300, loss is 3.986068162918091 and perplexity is 53.842771624331995
At time: 218.54330921173096 and batch: 350, loss is 3.997935013771057 and perplexity is 54.485521932960076
At time: 219.3816783428192 and batch: 400, loss is 3.954985899925232 and perplexity is 52.194957986433025
At time: 220.21882343292236 and batch: 450, loss is 3.9970305967330932 and perplexity is 54.436266575651175
At time: 221.0569303035736 and batch: 500, loss is 4.01402711391449 and perplexity is 55.369401070357526
At time: 221.8964066505432 and batch: 550, loss is 3.9786859273910524 and perplexity is 53.44675514472261
At time: 222.73330950737 and batch: 600, loss is 3.971494598388672 and perplexity is 53.063780642655075
At time: 223.56785988807678 and batch: 650, loss is 4.0118707132339475 and perplexity is 55.250131099349254
At time: 224.40552806854248 and batch: 700, loss is 4.039114146232605 and perplexity is 56.77602526588903
At time: 225.246915102005 and batch: 750, loss is 4.012240447998047 and perplexity is 55.270562770454525
At time: 226.08736872673035 and batch: 800, loss is 3.987595763206482 and perplexity is 53.925084712534826
At time: 226.92364358901978 and batch: 850, loss is 3.9833667278289795 and perplexity is 53.697515160562205
At time: 227.75921058654785 and batch: 900, loss is 3.970487241744995 and perplexity is 53.01035340534534
At time: 228.5952262878418 and batch: 950, loss is 4.061534066200256 and perplexity is 58.063315762151724
At time: 229.43266797065735 and batch: 1000, loss is 4.0336427927017215 and perplexity is 56.466231827116985
At time: 230.27101373672485 and batch: 1050, loss is 3.985481538772583 and perplexity is 53.81119541702443
At time: 231.10921239852905 and batch: 1100, loss is 4.01933424949646 and perplexity is 55.66403512883081
At time: 231.946923494339 and batch: 1150, loss is 3.9778162097930907 and perplexity is 53.400291769155764
At time: 232.78876399993896 and batch: 1200, loss is 4.056173005104065 and perplexity is 57.7528676879978
At time: 233.6260702610016 and batch: 1250, loss is 4.040185608863831 and perplexity is 56.83689125730559
At time: 234.46392607688904 and batch: 1300, loss is 4.045961928367615 and perplexity is 57.166149335240384
At time: 235.30042910575867 and batch: 1350, loss is 3.929140553474426 and perplexity is 50.86324463990815
At time: 236.13556623458862 and batch: 1400, loss is 3.959134931564331 and perplexity is 52.41196639458904
At time: 236.97616600990295 and batch: 1450, loss is 3.8921485805511473 and perplexity is 49.0160884802238
At time: 237.8131239414215 and batch: 1500, loss is 3.9073399353027343 and perplexity is 49.76639391749971
At time: 238.6557056903839 and batch: 1550, loss is 3.913335375785828 and perplexity is 50.06566159462513
At time: 239.49200320243835 and batch: 1600, loss is 3.9990583801269532 and perplexity is 54.54676352711589
At time: 240.32903242111206 and batch: 1650, loss is 3.9561268663406373 and perplexity is 52.254544667285685
At time: 241.1655671596527 and batch: 1700, loss is 3.9854547643661498 and perplexity is 53.809754673495284
At time: 242.00374841690063 and batch: 1750, loss is 3.977219362258911 and perplexity is 53.3684294461092
At time: 242.84302258491516 and batch: 1800, loss is 3.933487277030945 and perplexity is 51.084814305726894
At time: 243.6828773021698 and batch: 1850, loss is 3.9692206525802614 and perplexity is 52.943253569036635
At time: 244.52012181282043 and batch: 1900, loss is 4.050042471885681 and perplexity is 57.39989487544947
At time: 245.3576409816742 and batch: 1950, loss is 3.977094988822937 and perplexity is 53.36179224392082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35569216706032 and perplexity of 77.92074084553491
finished 7 epochs...
Completing Train Step...
At time: 248.55718064308167 and batch: 50, loss is 3.9752765130996703 and perplexity is 53.26484329654518
At time: 249.3951027393341 and batch: 100, loss is 3.940411605834961 and perplexity is 51.43976985309876
At time: 250.23324537277222 and batch: 150, loss is 3.9160388565063475 and perplexity is 50.201196270648325
At time: 251.0682978630066 and batch: 200, loss is 3.9115743923187254 and perplexity is 49.97757437511972
At time: 251.90577363967896 and batch: 250, loss is 3.9009130573272706 and perplexity is 49.44757697270082
At time: 252.74252557754517 and batch: 300, loss is 3.9205491971969604 and perplexity is 50.42813216328442
At time: 253.58061838150024 and batch: 350, loss is 3.9267425870895387 and perplexity is 50.74142241021683
At time: 254.41770958900452 and batch: 400, loss is 3.8907906866073607 and perplexity is 48.94957499987469
At time: 255.2808449268341 and batch: 450, loss is 3.933696117401123 and perplexity is 51.09548399134875
At time: 256.11810779571533 and batch: 500, loss is 3.951619725227356 and perplexity is 52.01955602195499
At time: 256.95225048065186 and batch: 550, loss is 3.915190691947937 and perplexity is 50.15863544702431
At time: 257.7896583080292 and batch: 600, loss is 3.9096412372589113 and perplexity is 49.88105329950106
At time: 258.62856578826904 and batch: 650, loss is 3.9451016426086425 and perplexity is 51.681590896866695
At time: 259.4689772129059 and batch: 700, loss is 3.974896831512451 and perplexity is 53.24462345509302
At time: 260.30822563171387 and batch: 750, loss is 3.950628547668457 and perplexity is 51.968020949824776
At time: 261.14553570747375 and batch: 800, loss is 3.9275467872619627 and perplexity is 50.78224508346846
At time: 261.98250794410706 and batch: 850, loss is 3.9256109523773195 and perplexity is 50.68403413267779
At time: 262.8188576698303 and batch: 900, loss is 3.9076190900802614 and perplexity is 49.78028838338512
At time: 263.6573312282562 and batch: 950, loss is 3.9974535131454467 and perplexity is 54.45929343508845
At time: 264.49043321609497 and batch: 1000, loss is 3.9725875425338746 and perplexity is 53.121808095637014
At time: 265.32867646217346 and batch: 1050, loss is 3.927076859474182 and perplexity is 50.7583867016752
At time: 266.16644287109375 and batch: 1100, loss is 3.9604522943496705 and perplexity is 52.48105746763596
At time: 267.00518465042114 and batch: 1150, loss is 3.9154987955093383 and perplexity is 50.17409188220965
At time: 267.84185433387756 and batch: 1200, loss is 3.9958869552612306 and perplexity is 54.37404658908194
At time: 268.6831736564636 and batch: 1250, loss is 3.983983178138733 and perplexity is 53.73062721533555
At time: 269.53177857398987 and batch: 1300, loss is 3.9881504249572752 and perplexity is 53.95500319098395
At time: 270.39788913726807 and batch: 1350, loss is 3.8672684955596925 and perplexity is 47.811609929490906
At time: 271.24059081077576 and batch: 1400, loss is 3.899820718765259 and perplexity is 49.39359296734872
At time: 272.07395005226135 and batch: 1450, loss is 3.8312102603912352 and perplexity is 46.11831964796819
At time: 272.91147923469543 and batch: 1500, loss is 3.8467618083953856 and perplexity is 46.841136804944185
At time: 273.7484862804413 and batch: 1550, loss is 3.857811532020569 and perplexity is 47.361588549467584
At time: 274.58537435531616 and batch: 1600, loss is 3.9437341833114625 and perplexity is 51.610966723748064
At time: 275.4216561317444 and batch: 1650, loss is 3.902090802192688 and perplexity is 49.50584791000081
At time: 276.2618124485016 and batch: 1700, loss is 3.9285366582870482 and perplexity is 50.83253784403202
At time: 277.10499143600464 and batch: 1750, loss is 3.9189101028442384 and perplexity is 50.34554340051504
At time: 277.9445335865021 and batch: 1800, loss is 3.874484615325928 and perplexity is 48.15787206492191
At time: 278.7956759929657 and batch: 1850, loss is 3.9124973678588866 and perplexity is 50.02372374791953
At time: 279.6420404911041 and batch: 1900, loss is 3.9912563514709474 and perplexity is 54.122843981594
At time: 280.48010778427124 and batch: 1950, loss is 3.9197720956802367 and perplexity is 50.388959607792245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359817575853924 and perplexity of 78.24285973422633
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 283.6878328323364 and batch: 50, loss is 3.9533270502090456 and perplexity is 52.108446170080356
At time: 284.54994225502014 and batch: 100, loss is 3.944928183555603 and perplexity is 51.67262703450417
At time: 285.39372992515564 and batch: 150, loss is 3.9183022117614748 and perplexity is 50.31494809387418
At time: 286.23368859291077 and batch: 200, loss is 3.9155747747421263 and perplexity is 50.17790421604396
At time: 287.0721971988678 and batch: 250, loss is 3.9003736782073974 and perplexity is 49.420913173748076
At time: 287.9067611694336 and batch: 300, loss is 3.919181742668152 and perplexity is 50.35922111268074
At time: 288.74218368530273 and batch: 350, loss is 3.91290075302124 and perplexity is 50.04390664631231
At time: 289.5796694755554 and batch: 400, loss is 3.86611234664917 and perplexity is 47.756364530868105
At time: 290.41730666160583 and batch: 450, loss is 3.9057389068603516 and perplexity is 49.686780254238705
At time: 291.2513780593872 and batch: 500, loss is 3.9190926218032835 and perplexity is 50.35473325532492
At time: 292.08538603782654 and batch: 550, loss is 3.876087784767151 and perplexity is 48.23513921338731
At time: 292.91773867607117 and batch: 600, loss is 3.8636241722106934 and perplexity is 47.63768607294883
At time: 293.75863099098206 and batch: 650, loss is 3.8888884973526 and perplexity is 48.856552145870396
At time: 294.597412109375 and batch: 700, loss is 3.9138167905807495 and perplexity is 50.08976974737943
At time: 295.4331569671631 and batch: 750, loss is 3.8807490921020507 and perplexity is 48.4605028581535
At time: 296.2696714401245 and batch: 800, loss is 3.8482635116577146 and perplexity is 46.911531135364264
At time: 297.1064155101776 and batch: 850, loss is 3.8468581008911134 and perplexity is 46.84564747207807
At time: 297.9927406311035 and batch: 900, loss is 3.8187690925598146 and perplexity is 45.54810829557534
At time: 298.8289475440979 and batch: 950, loss is 3.9116143131256105 and perplexity is 49.979569560039366
At time: 299.66753911972046 and batch: 1000, loss is 3.878777208328247 and perplexity is 48.365038532107924
At time: 300.50700330734253 and batch: 1050, loss is 3.8272418117523195 and perplexity is 45.93566413435807
At time: 301.35111808776855 and batch: 1100, loss is 3.8434970951080323 and perplexity is 46.68846327647486
At time: 302.19001722335815 and batch: 1150, loss is 3.7983198881149294 and perplexity is 44.62614455735276
At time: 303.02565002441406 and batch: 1200, loss is 3.8647046852111817 and perplexity is 47.68918703078042
At time: 303.8633654117584 and batch: 1250, loss is 3.8498272132873534 and perplexity is 46.98494415612068
At time: 304.69640469551086 and batch: 1300, loss is 3.8561932039260864 and perplexity is 47.28500394634058
At time: 305.5328438282013 and batch: 1350, loss is 3.7315227794647217 and perplexity is 41.74262460253971
At time: 306.37405943870544 and batch: 1400, loss is 3.7528899097442627 and perplexity is 42.64414181951174
At time: 307.2143738269806 and batch: 1450, loss is 3.678465600013733 and perplexity is 39.5856072935948
At time: 308.0517656803131 and batch: 1500, loss is 3.684972004890442 and perplexity is 39.84400699690675
At time: 308.8919050693512 and batch: 1550, loss is 3.695189471244812 and perplexity is 40.25319868914869
At time: 309.7281675338745 and batch: 1600, loss is 3.771925730705261 and perplexity is 43.463683646516586
At time: 310.56476354599 and batch: 1650, loss is 3.7257189321517945 and perplexity is 41.50105846747639
At time: 311.4011723995209 and batch: 1700, loss is 3.7283746910095217 and perplexity is 41.61142175537963
At time: 312.23902559280396 and batch: 1750, loss is 3.714898467063904 and perplexity is 41.054418497122136
At time: 313.0778121948242 and batch: 1800, loss is 3.6689690351486206 and perplexity is 39.211459378046165
At time: 313.9142653942108 and batch: 1850, loss is 3.6876926898956297 and perplexity is 39.95255758831424
At time: 314.75154852867126 and batch: 1900, loss is 3.762299256324768 and perplexity is 43.04728903102869
At time: 315.5884072780609 and batch: 1950, loss is 3.6855223417282104 and perplexity is 39.86594065661832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.289637082122093 and perplexity of 72.93999246832969
finished 9 epochs...
Completing Train Step...
At time: 318.74044489860535 and batch: 50, loss is 3.8669654941558838 and perplexity is 47.79712513913064
At time: 319.6030135154724 and batch: 100, loss is 3.843062300682068 and perplexity is 46.668167805383995
At time: 320.43691325187683 and batch: 150, loss is 3.811584553718567 and perplexity is 45.222038874167445
At time: 321.27330136299133 and batch: 200, loss is 3.8097370433807374 and perplexity is 45.13856782040966
At time: 322.11065673828125 and batch: 250, loss is 3.7946850538253782 and perplexity is 44.46423036080977
At time: 322.9473171234131 and batch: 300, loss is 3.81143036365509 and perplexity is 45.215066622662654
At time: 323.78435158729553 and batch: 350, loss is 3.8119007396697997 and perplexity is 45.23633970828784
At time: 324.6237587928772 and batch: 400, loss is 3.769944362640381 and perplexity is 43.37765135072464
At time: 325.4602575302124 and batch: 450, loss is 3.816268243789673 and perplexity is 45.43434168080507
At time: 326.2985405921936 and batch: 500, loss is 3.829063220024109 and perplexity is 46.01940797569331
At time: 327.1358880996704 and batch: 550, loss is 3.790416970252991 and perplexity is 44.27485772623934
At time: 327.972056388855 and batch: 600, loss is 3.782902383804321 and perplexity is 43.943397433632576
At time: 328.8078284263611 and batch: 650, loss is 3.8081585788726806 and perplexity is 45.067374396089214
At time: 329.6475887298584 and batch: 700, loss is 3.8381113147735597 and perplexity is 46.43768539259615
At time: 330.4852020740509 and batch: 750, loss is 3.8063102674484255 and perplexity is 44.98415278654975
At time: 331.3194851875305 and batch: 800, loss is 3.7753612661361693 and perplexity is 43.613261464467584
At time: 332.1552474498749 and batch: 850, loss is 3.7752773571014404 and perplexity is 43.60960207132694
At time: 332.99375581741333 and batch: 900, loss is 3.7486189651489257 and perplexity is 42.46239943457625
At time: 333.8297002315521 and batch: 950, loss is 3.844034972190857 and perplexity is 46.713582685875295
At time: 334.66619968414307 and batch: 1000, loss is 3.8125147294998167 and perplexity is 45.26412288923838
At time: 335.50709676742554 and batch: 1050, loss is 3.763489227294922 and perplexity is 43.098544545558326
At time: 336.344304561615 and batch: 1100, loss is 3.780752730369568 and perplexity is 43.84903581712832
At time: 337.18462085723877 and batch: 1150, loss is 3.74165433883667 and perplexity is 42.167692144521546
At time: 338.01911449432373 and batch: 1200, loss is 3.8097352886199953 and perplexity is 45.13848861309239
At time: 338.85844564437866 and batch: 1250, loss is 3.797254204750061 and perplexity is 44.57861254899351
At time: 339.6966428756714 and batch: 1300, loss is 3.8066407442092896 and perplexity is 44.999021460393124
At time: 340.5332386493683 and batch: 1350, loss is 3.6842549657821655 and perplexity is 39.81544752601194
At time: 341.3704195022583 and batch: 1400, loss is 3.7095437908172606 and perplexity is 40.83517289604275
At time: 342.20638489723206 and batch: 1450, loss is 3.633986711502075 and perplexity is 37.8634668369125
At time: 343.04457092285156 and batch: 1500, loss is 3.644755334854126 and perplexity is 38.27340753708353
At time: 343.883647441864 and batch: 1550, loss is 3.656313695907593 and perplexity is 38.71835186016769
At time: 344.72143030166626 and batch: 1600, loss is 3.7385744857788086 and perplexity is 42.03802163448478
At time: 345.5614643096924 and batch: 1650, loss is 3.693502779006958 and perplexity is 40.185361157972295
At time: 346.4003150463104 and batch: 1700, loss is 3.7009997081756594 and perplexity is 40.48776007950693
At time: 347.2360956668854 and batch: 1750, loss is 3.6912607860565188 and perplexity is 40.09536678261946
At time: 348.07497572898865 and batch: 1800, loss is 3.6496860790252685 and perplexity is 38.46258993993469
At time: 348.9142391681671 and batch: 1850, loss is 3.6709795951843263 and perplexity is 39.290375677608445
At time: 349.7533473968506 and batch: 1900, loss is 3.7488053369522096 and perplexity is 42.470313966030474
At time: 350.5890758037567 and batch: 1950, loss is 3.6748330211639404 and perplexity is 39.44207031631616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.292405239371366 and perplexity of 73.14218155372461
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 353.7366886138916 and batch: 50, loss is 3.8430125284194947 and perplexity is 46.66584508288623
At time: 354.6017394065857 and batch: 100, loss is 3.8494420623779297 and perplexity is 46.96685134660441
At time: 355.4373302459717 and batch: 150, loss is 3.834472990036011 and perplexity is 46.269036997929796
At time: 356.27359533309937 and batch: 200, loss is 3.8331637716293336 and perplexity is 46.208500359520436
At time: 357.1119031906128 and batch: 250, loss is 3.828466305732727 and perplexity is 45.99194653027169
At time: 357.95109391212463 and batch: 300, loss is 3.8469139671325685 and perplexity is 46.84826463543573
At time: 358.78906989097595 and batch: 350, loss is 3.853751049041748 and perplexity is 47.16966753501055
At time: 359.62604689598083 and batch: 400, loss is 3.808581213951111 and perplexity is 45.08642547494527
At time: 360.46322751045227 and batch: 450, loss is 3.8465996026992797 and perplexity is 46.833539521920294
At time: 361.30046701431274 and batch: 500, loss is 3.8530947542190552 and perplexity is 47.13872048272508
At time: 362.1648449897766 and batch: 550, loss is 3.8142399549484254 and perplexity is 45.342281106843
At time: 363.002543926239 and batch: 600, loss is 3.801300115585327 and perplexity is 44.75933899553895
At time: 363.8397316932678 and batch: 650, loss is 3.825263509750366 and perplexity is 45.84487934751133
At time: 364.67602276802063 and batch: 700, loss is 3.8506505918502807 and perplexity is 47.02364648306581
At time: 365.5138006210327 and batch: 750, loss is 3.8131692171096803 and perplexity is 45.293757393490814
At time: 366.3509187698364 and batch: 800, loss is 3.778211531639099 and perplexity is 43.73774816488628
At time: 367.1906542778015 and batch: 850, loss is 3.776508240699768 and perplexity is 43.663313464701304
At time: 368.0275251865387 and batch: 900, loss is 3.7423345327377318 and perplexity is 42.19638410848333
At time: 368.86712288856506 and batch: 950, loss is 3.8357405138015745 and perplexity is 46.32772128594235
At time: 369.7063193321228 and batch: 1000, loss is 3.795168538093567 and perplexity is 44.48573331443737
At time: 370.5455677509308 and batch: 1050, loss is 3.7513134622573854 and perplexity is 42.57696853080292
At time: 371.3913154602051 and batch: 1100, loss is 3.7626370429992675 and perplexity is 43.061832287757575
At time: 372.22598910331726 and batch: 1150, loss is 3.72229615688324 and perplexity is 41.35925249436659
At time: 373.0666239261627 and batch: 1200, loss is 3.781727695465088 and perplexity is 43.891807943799385
At time: 373.9027829170227 and batch: 1250, loss is 3.7690237092971803 and perplexity is 43.33773394885265
At time: 374.73828768730164 and batch: 1300, loss is 3.783233017921448 and perplexity is 43.9579290222337
At time: 375.5777106285095 and batch: 1350, loss is 3.6588011407852172 and perplexity is 38.81478150816872
At time: 376.41661381721497 and batch: 1400, loss is 3.6816173791885376 and perplexity is 39.710569209021465
At time: 377.2538335323334 and batch: 1450, loss is 3.603878016471863 and perplexity is 36.74043855642006
At time: 378.09314584732056 and batch: 1500, loss is 3.61242618560791 and perplexity is 37.05584820623877
At time: 378.9299867153168 and batch: 1550, loss is 3.6202857875823975 and perplexity is 37.34823996020376
At time: 379.76986742019653 and batch: 1600, loss is 3.696752052307129 and perplexity is 40.316146743028334
At time: 380.61009311676025 and batch: 1650, loss is 3.6474701976776123 and perplexity is 38.377455762756846
At time: 381.4528510570526 and batch: 1700, loss is 3.6520282936096193 and perplexity is 38.55278316375292
At time: 382.29261565208435 and batch: 1750, loss is 3.6393333959579466 and perplexity is 38.066453014450744
At time: 383.13465571403503 and batch: 1800, loss is 3.598808693885803 and perplexity is 36.554660703201506
At time: 383.97445249557495 and batch: 1850, loss is 3.6134917020797728 and perplexity is 37.09535286557643
At time: 384.81344962120056 and batch: 1900, loss is 3.6926146745681763 and perplexity is 40.149688203353215
At time: 385.6567578315735 and batch: 1950, loss is 3.616976261138916 and perplexity is 37.22483928397213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260631188680959 and perplexity of 70.85469202261862
finished 11 epochs...
Completing Train Step...
At time: 388.84400629997253 and batch: 50, loss is 3.8312053442001344 and perplexity is 46.11809292205287
At time: 389.6799235343933 and batch: 100, loss is 3.8147874307632446 and perplexity is 45.367111705593665
At time: 390.51869893074036 and batch: 150, loss is 3.7934460496902465 and perplexity is 44.409173110650926
At time: 391.35083961486816 and batch: 200, loss is 3.787380328178406 and perplexity is 44.14061475750182
At time: 392.18954133987427 and batch: 250, loss is 3.7833973026275634 and perplexity is 43.96515123091753
At time: 393.023809671402 and batch: 300, loss is 3.7995679998397827 and perplexity is 44.68187774499725
At time: 393.8678207397461 and batch: 350, loss is 3.806395721435547 and perplexity is 44.987997026013105
At time: 394.70530939102173 and batch: 400, loss is 3.762933692932129 and perplexity is 43.07460847234808
At time: 395.54402446746826 and batch: 450, loss is 3.803209753036499 and perplexity is 44.84489476983013
At time: 396.3821280002594 and batch: 500, loss is 3.8096629428863524 and perplexity is 45.13522315414058
At time: 397.2202076911926 and batch: 550, loss is 3.774242696762085 and perplexity is 43.56450428011983
At time: 398.0588791370392 and batch: 600, loss is 3.7630060577392577 and perplexity is 43.07772567086871
At time: 398.89422702789307 and batch: 650, loss is 3.78823166847229 and perplexity is 44.17820944210596
At time: 399.7323338985443 and batch: 700, loss is 3.815241255760193 and perplexity is 45.38770510747183
At time: 400.571546792984 and batch: 750, loss is 3.780302715301514 and perplexity is 43.82930752963722
At time: 401.41150665283203 and batch: 800, loss is 3.7466168546676637 and perplexity is 42.37747006696684
At time: 402.2469656467438 and batch: 850, loss is 3.746115288734436 and perplexity is 42.356220301169664
At time: 403.08235120773315 and batch: 900, loss is 3.7127072954177858 and perplexity is 40.964559703336676
At time: 403.9449427127838 and batch: 950, loss is 3.8068532848358156 and perplexity is 45.00858659706144
At time: 404.7805986404419 and batch: 1000, loss is 3.7674410581588744 and perplexity is 43.269199682109836
At time: 405.6153552532196 and batch: 1050, loss is 3.7261654806137083 and perplexity is 41.51959483968907
At time: 406.4527189731598 and batch: 1100, loss is 3.7386772108078 and perplexity is 42.0423402132852
At time: 407.2875361442566 and batch: 1150, loss is 3.7005571508407593 and perplexity is 40.469845888630736
At time: 408.1255819797516 and batch: 1200, loss is 3.7620544147491457 and perplexity is 43.036750555137225
At time: 408.9648869037628 and batch: 1250, loss is 3.751320161819458 and perplexity is 42.57725377880198
At time: 409.80043292045593 and batch: 1300, loss is 3.767027277946472 and perplexity is 43.25129944711182
At time: 410.63467240333557 and batch: 1350, loss is 3.644003381729126 and perplexity is 38.24463854650339
At time: 411.4718368053436 and batch: 1400, loss is 3.668667793273926 and perplexity is 39.19964902348959
At time: 412.306734085083 and batch: 1450, loss is 3.5925494050979614 and perplexity is 36.32656911557089
At time: 413.13930344581604 and batch: 1500, loss is 3.6027354335784914 and perplexity is 36.69848353294093
At time: 413.97615337371826 and batch: 1550, loss is 3.6122352647781373 and perplexity is 37.0487741482653
At time: 414.8121871948242 and batch: 1600, loss is 3.6909938526153563 and perplexity is 40.08466541672926
At time: 415.64637780189514 and batch: 1650, loss is 3.6428793048858643 and perplexity is 38.20167278686618
At time: 416.47981905937195 and batch: 1700, loss is 3.6499949502944946 and perplexity is 38.4744717637897
At time: 417.3200056552887 and batch: 1750, loss is 3.6393690967559813 and perplexity is 38.06781204146074
At time: 418.1515259742737 and batch: 1800, loss is 3.6005716037750246 and perplexity is 36.61916011267117
At time: 418.9924509525299 and batch: 1850, loss is 3.616908144950867 and perplexity is 37.22230375617559
At time: 419.8313319683075 and batch: 1900, loss is 3.697242922782898 and perplexity is 40.335941607120965
At time: 420.6669044494629 and batch: 1950, loss is 3.621553406715393 and perplexity is 37.39561332310811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260367743913517 and perplexity of 70.83602818330989
finished 12 epochs...
Completing Train Step...
At time: 423.8419659137726 and batch: 50, loss is 3.81479887008667 and perplexity is 45.36763067762568
At time: 424.67800879478455 and batch: 100, loss is 3.7957855463027954 and perplexity is 44.51318984666776
At time: 425.5440528392792 and batch: 150, loss is 3.774113140106201 and perplexity is 43.55886057422778
At time: 426.3856017589569 and batch: 200, loss is 3.7672964668273927 and perplexity is 43.26294378320093
At time: 427.2237105369568 and batch: 250, loss is 3.7629427814483645 and perplexity is 43.074999958405535
At time: 428.0613307952881 and batch: 300, loss is 3.7786137437820435 and perplexity is 43.755343556606135
At time: 428.8963785171509 and batch: 350, loss is 3.785086569786072 and perplexity is 44.03948288234336
At time: 429.73121428489685 and batch: 400, loss is 3.742237129211426 and perplexity is 42.19227423203528
At time: 430.5680363178253 and batch: 450, loss is 3.7830689001083373 and perplexity is 43.95071533501717
At time: 431.40345573425293 and batch: 500, loss is 3.78952841758728 and perplexity is 44.235534656279256
At time: 432.237188577652 and batch: 550, loss is 3.755014781951904 and perplexity is 42.73485151040317
At time: 433.0734534263611 and batch: 600, loss is 3.744482703208923 and perplexity is 42.28712656505378
At time: 433.91279220581055 and batch: 650, loss is 3.7702204418182372 and perplexity is 43.38962867031508
At time: 434.7488250732422 and batch: 700, loss is 3.797412185668945 and perplexity is 44.58565567549173
At time: 435.5843114852905 and batch: 750, loss is 3.7633687543869017 and perplexity is 43.09335265131306
At time: 436.42125368118286 and batch: 800, loss is 3.7301079750061037 and perplexity is 41.68360870895651
At time: 437.2559564113617 and batch: 850, loss is 3.7296793127059935 and perplexity is 41.66574434653333
At time: 438.0916476249695 and batch: 900, loss is 3.696769757270813 and perplexity is 40.31686054526121
At time: 438.9235565662384 and batch: 950, loss is 3.7912091493606566 and perplexity is 44.309945239487476
At time: 439.761638879776 and batch: 1000, loss is 3.752158489227295 and perplexity is 42.61296242327153
At time: 440.5982093811035 and batch: 1050, loss is 3.7122488498687742 and perplexity is 40.945783987424
At time: 441.4324827194214 and batch: 1100, loss is 3.7252124643325804 and perplexity is 41.48004483871184
At time: 442.27080941200256 and batch: 1150, loss is 3.6878686904907227 and perplexity is 39.959589881050974
At time: 443.103750705719 and batch: 1200, loss is 3.7502751207351683 and perplexity is 42.5327820407909
At time: 443.94216084480286 and batch: 1250, loss is 3.740544762611389 and perplexity is 42.120929823820326
At time: 444.77996611595154 and batch: 1300, loss is 3.756972727775574 and perplexity is 42.818606001064275
At time: 445.6178231239319 and batch: 1350, loss is 3.634342460632324 and perplexity is 37.87693912854387
At time: 446.4535188674927 and batch: 1400, loss is 3.659750370979309 and perplexity is 38.85164316308346
At time: 447.2897491455078 and batch: 1450, loss is 3.5842191553115845 and perplexity is 36.02521663432296
At time: 448.1253454685211 and batch: 1500, loss is 3.594963855743408 and perplexity is 36.414383793261294
At time: 448.9611883163452 and batch: 1550, loss is 3.6047795391082764 and perplexity is 36.773575828206404
At time: 449.7967653274536 and batch: 1600, loss is 3.6846888399124147 and perplexity is 39.83272616678433
At time: 450.63227343559265 and batch: 1650, loss is 3.6367385721206666 and perplexity is 37.96780531681729
At time: 451.466912984848 and batch: 1700, loss is 3.6451386165618898 and perplexity is 38.28807984572041
At time: 452.30187368392944 and batch: 1750, loss is 3.6354427480697633 and perplexity is 37.91863758477264
At time: 453.1351923942566 and batch: 1800, loss is 3.5973492527008055 and perplexity is 36.50135023707504
At time: 453.9713213443756 and batch: 1850, loss is 3.6144006633758545 and perplexity is 37.12908643452743
At time: 454.8076000213623 and batch: 1900, loss is 3.695618624687195 and perplexity is 40.270477195233056
At time: 455.64202070236206 and batch: 1950, loss is 3.6199280548095705 and perplexity is 37.33488166025589
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261716478924418 and perplexity of 70.93163167194747
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 458.80975556373596 and batch: 50, loss is 3.8104701042175293 and perplexity is 45.17166926791275
At time: 459.6465468406677 and batch: 100, loss is 3.8043495178222657 and perplexity is 44.89603654096873
At time: 460.4821820259094 and batch: 150, loss is 3.7922418403625486 and perplexity is 44.3557273565521
At time: 461.31954646110535 and batch: 200, loss is 3.7873457860946655 and perplexity is 44.139090075023525
At time: 462.15608191490173 and batch: 250, loss is 3.7918476009368898 and perplexity is 44.33824402660979
At time: 462.9956121444702 and batch: 300, loss is 3.8129472064971925 and perplexity is 45.2837028148229
At time: 463.8321933746338 and batch: 350, loss is 3.8295505809783936 and perplexity is 46.041841504448925
At time: 464.6687982082367 and batch: 400, loss is 3.792580556869507 and perplexity is 44.3707539183145
At time: 465.50682258605957 and batch: 450, loss is 3.835585503578186 and perplexity is 46.320540572073135
At time: 466.3450129032135 and batch: 500, loss is 3.8387470769882204 and perplexity is 46.4672181052017
At time: 467.228675365448 and batch: 550, loss is 3.809323229789734 and perplexity is 45.11989273183637
At time: 468.06268095970154 and batch: 600, loss is 3.783204607963562 and perplexity is 43.95668019706105
At time: 468.91117238998413 and batch: 650, loss is 3.794911708831787 and perplexity is 44.47430954343261
At time: 469.75087690353394 and batch: 700, loss is 3.818994302749634 and perplexity is 45.5583673488688
At time: 470.58654952049255 and batch: 750, loss is 3.785436162948608 and perplexity is 44.05488147590535
At time: 471.4210014343262 and batch: 800, loss is 3.7525089454650877 and perplexity is 42.627899018922285
At time: 472.259813785553 and batch: 850, loss is 3.751107106208801 and perplexity is 42.56818342227753
At time: 473.096266746521 and batch: 900, loss is 3.7087023305892943 and perplexity is 40.80082617487513
At time: 473.93207716941833 and batch: 950, loss is 3.8029322624206543 and perplexity is 44.832452458755064
At time: 474.7667179107666 and batch: 1000, loss is 3.760461678504944 and perplexity is 42.96825892172805
At time: 475.6033606529236 and batch: 1050, loss is 3.721800994873047 and perplexity is 41.3387780332674
At time: 476.4406385421753 and batch: 1100, loss is 3.7291393852233887 and perplexity is 41.64325393821859
At time: 477.2779767513275 and batch: 1150, loss is 3.694639687538147 and perplexity is 40.23107421876219
At time: 478.1160697937012 and batch: 1200, loss is 3.7535970497131346 and perplexity is 42.6743078611804
At time: 478.95365142822266 and batch: 1250, loss is 3.738802499771118 and perplexity is 42.04760798449588
At time: 479.7893617153168 and batch: 1300, loss is 3.7535793590545654 and perplexity is 42.673552931247976
At time: 480.62876319885254 and batch: 1350, loss is 3.628447117805481 and perplexity is 37.65429850337968
At time: 481.46587920188904 and batch: 1400, loss is 3.6548847818374632 and perplexity is 38.66306617107881
At time: 482.30258417129517 and batch: 1450, loss is 3.5796863508224486 and perplexity is 35.86229090484001
At time: 483.1378972530365 and batch: 1500, loss is 3.592347278594971 and perplexity is 36.31922729520315
At time: 483.9734399318695 and batch: 1550, loss is 3.6045643377304075 and perplexity is 36.7656629554801
At time: 484.8077223300934 and batch: 1600, loss is 3.6800863361358642 and perplexity is 39.64981713680272
At time: 485.6469376087189 and batch: 1650, loss is 3.62436683177948 and perplexity is 37.50097121769345
At time: 486.48340106010437 and batch: 1700, loss is 3.6327221727371217 and perplexity is 37.81561727551052
At time: 487.32461404800415 and batch: 1750, loss is 3.620212197303772 and perplexity is 37.345491593946676
At time: 488.16349053382874 and batch: 1800, loss is 3.580533604621887 and perplexity is 35.892688242377204
At time: 489.00446033477783 and batch: 1850, loss is 3.5978443670272826 and perplexity is 36.51942705318921
At time: 489.84395003318787 and batch: 1900, loss is 3.6846030569076538 and perplexity is 39.829309342400755
At time: 490.67879724502563 and batch: 1950, loss is 3.613981065750122 and perplexity is 37.1135104260705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24708621002907 and perplexity of 69.90143721394753
finished 14 epochs...
Completing Train Step...
At time: 493.8250620365143 and batch: 50, loss is 3.8172080945968627 and perplexity is 45.47706325631679
At time: 494.68961358070374 and batch: 100, loss is 3.7955737590789793 and perplexity is 44.503763519989946
At time: 495.52498841285706 and batch: 150, loss is 3.7750483989715575 and perplexity is 43.59961844135199
At time: 496.36178946495056 and batch: 200, loss is 3.7659502744674684 and perplexity is 43.20474272251327
At time: 497.19707131385803 and batch: 250, loss is 3.7678161239624024 and perplexity is 43.28543152307058
At time: 498.03388142585754 and batch: 300, loss is 3.7816418409347534 and perplexity is 43.88803979500148
At time: 498.87011075019836 and batch: 350, loss is 3.7987227392196656 and perplexity is 44.644125870640586
At time: 499.7060766220093 and batch: 400, loss is 3.7622883796691893 and perplexity is 43.046820823038566
At time: 500.5398573875427 and batch: 450, loss is 3.8060094165802 and perplexity is 44.970621300709226
At time: 501.3714499473572 and batch: 500, loss is 3.8109757709503174 and perplexity is 45.194516854471416
At time: 502.20708870887756 and batch: 550, loss is 3.7816463804244993 and perplexity is 43.888239024760296
At time: 503.0501751899719 and batch: 600, loss is 3.7604046297073364 and perplexity is 42.96580770414144
At time: 503.88947916030884 and batch: 650, loss is 3.7743253231048586 and perplexity is 43.568104004497215
At time: 504.73335695266724 and batch: 700, loss is 3.8004544019699096 and perplexity is 44.721501415266964
At time: 505.5752685070038 and batch: 750, loss is 3.7680115032196047 and perplexity is 43.2938894247516
At time: 506.4044313430786 and batch: 800, loss is 3.7358452796936037 and perplexity is 41.92344762918387
At time: 507.23854970932007 and batch: 850, loss is 3.735129461288452 and perplexity is 41.893448791904355
At time: 508.06902837753296 and batch: 900, loss is 3.694913215637207 and perplexity is 40.24208005315025
At time: 508.8974289894104 and batch: 950, loss is 3.7907490634918215 and perplexity is 44.28956354885739
At time: 509.7676329612732 and batch: 1000, loss is 3.7495522785186766 and perplexity is 42.50204865937793
At time: 510.60712599754333 and batch: 1050, loss is 3.7123268604278565 and perplexity is 40.948978315518964
At time: 511.44521284103394 and batch: 1100, loss is 3.7209557485580445 and perplexity is 41.30385134637419
At time: 512.2822256088257 and batch: 1150, loss is 3.686453061103821 and perplexity is 39.90306193207988
At time: 513.1171817779541 and batch: 1200, loss is 3.746656131744385 and perplexity is 42.379134562797965
At time: 513.9547510147095 and batch: 1250, loss is 3.7325376415252687 and perplexity is 41.78500911213405
At time: 514.7949705123901 and batch: 1300, loss is 3.748419818878174 and perplexity is 42.45394404803897
At time: 515.6355276107788 and batch: 1350, loss is 3.623915205001831 and perplexity is 37.484038598803544
At time: 516.4776003360748 and batch: 1400, loss is 3.651461124420166 and perplexity is 38.530923412649415
At time: 517.3138527870178 and batch: 1450, loss is 3.578437747955322 and perplexity is 35.817541088782605
At time: 518.1519663333893 and batch: 1500, loss is 3.592090916633606 and perplexity is 36.30991762023275
At time: 518.9918842315674 and batch: 1550, loss is 3.6051518392562865 and perplexity is 36.787269184791285
At time: 519.8296797275543 and batch: 1600, loss is 3.6821298599243164 and perplexity is 39.73092532636137
At time: 520.6619884967804 and batch: 1650, loss is 3.6273654985427854 and perplexity is 37.613592906742305
At time: 521.5020039081573 and batch: 1700, loss is 3.636707787513733 and perplexity is 37.966636510845184
At time: 522.3373608589172 and batch: 1750, loss is 3.6251383447647094 and perplexity is 37.52991486771184
At time: 523.1707367897034 and batch: 1800, loss is 3.5858868026733397 and perplexity is 36.085344113581144
At time: 524.0073578357697 and batch: 1850, loss is 3.6035629415512087 and perplexity is 36.72886438911777
At time: 524.8473348617554 and batch: 1900, loss is 3.690456976890564 and perplexity is 40.06315070880958
At time: 525.6825113296509 and batch: 1950, loss is 3.619000630378723 and perplexity is 37.30027243008484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245812420512355 and perplexity of 69.81245418087995
finished 15 epochs...
Completing Train Step...
At time: 528.8254504203796 and batch: 50, loss is 3.813052911758423 and perplexity is 45.288489793458375
At time: 529.6889753341675 and batch: 100, loss is 3.7892807865142824 and perplexity is 44.224581919542636
At time: 530.5237259864807 and batch: 150, loss is 3.767745614051819 and perplexity is 43.282379578761734
At time: 531.386203289032 and batch: 200, loss is 3.757835569381714 and perplexity is 42.8555676195569
At time: 532.223141670227 and batch: 250, loss is 3.759060106277466 and perplexity is 42.90807798717515
At time: 533.0616185665131 and batch: 300, loss is 3.7718310260772707 and perplexity is 43.45956762943176
At time: 533.8989844322205 and batch: 350, loss is 3.7892033576965334 and perplexity is 44.22115779501383
At time: 534.733384847641 and batch: 400, loss is 3.752566547393799 and perplexity is 42.63035453884335
At time: 535.5675368309021 and batch: 450, loss is 3.796384167671204 and perplexity is 44.53984437047379
At time: 536.4043021202087 and batch: 500, loss is 3.801451425552368 and perplexity is 44.76611204204895
At time: 537.2416939735413 and batch: 550, loss is 3.772431173324585 and perplexity is 43.48565759744219
At time: 538.0792458057404 and batch: 600, loss is 3.7520232820510864 and perplexity is 42.60720123443822
At time: 538.9175245761871 and batch: 650, loss is 3.7663596868515015 and perplexity is 43.222434900684114
At time: 539.7581269741058 and batch: 700, loss is 3.7927918100357054 and perplexity is 44.38012837072287
At time: 540.5912635326385 and batch: 750, loss is 3.760917992591858 and perplexity is 42.98787041772486
At time: 541.430018901825 and batch: 800, loss is 3.728969707489014 and perplexity is 41.6361886046702
At time: 542.2676639556885 and batch: 850, loss is 3.7284323596954345 and perplexity is 41.613821500585644
At time: 543.1046934127808 and batch: 900, loss is 3.688759961128235 and perplexity is 39.99522056613204
At time: 543.9402441978455 and batch: 950, loss is 3.7850385236740114 and perplexity is 44.0373670072439
At time: 544.7801170349121 and batch: 1000, loss is 3.744061841964722 and perplexity is 42.26933329686504
At time: 545.6196451187134 and batch: 1050, loss is 3.707605829238892 and perplexity is 40.756112532641374
At time: 546.4544684886932 and batch: 1100, loss is 3.7165759897232054 and perplexity is 41.12334601198555
At time: 547.2895958423615 and batch: 1150, loss is 3.6823859310150144 and perplexity is 39.741100570481464
At time: 548.1224412918091 and batch: 1200, loss is 3.743268275260925 and perplexity is 42.23580306736545
At time: 548.9582402706146 and batch: 1250, loss is 3.729431700706482 and perplexity is 41.65542868545799
At time: 549.7935540676117 and batch: 1300, loss is 3.7456640148162843 and perplexity is 42.337110355910504
At time: 550.62832903862 and batch: 1350, loss is 3.621249589920044 and perplexity is 37.38425363342781
At time: 551.4635553359985 and batch: 1400, loss is 3.649255003929138 and perplexity is 38.44601324843504
At time: 552.3019032478333 and batch: 1450, loss is 3.5768877029418946 and perplexity is 35.76206529392166
At time: 553.1373553276062 and batch: 1500, loss is 3.590972490310669 and perplexity is 36.269330353747016
At time: 553.9707174301147 and batch: 1550, loss is 3.6043365955352784 and perplexity is 36.75729081607414
At time: 554.8061029911041 and batch: 1600, loss is 3.6819528102874757 and perplexity is 39.72389160313844
At time: 555.6393222808838 and batch: 1650, loss is 3.6274688482284545 and perplexity is 37.61748046063138
At time: 556.4737672805786 and batch: 1700, loss is 3.6371482181549073 and perplexity is 37.983361863815496
At time: 557.3114399909973 and batch: 1750, loss is 3.626072497367859 and perplexity is 37.56498991555446
At time: 558.1485040187836 and batch: 1800, loss is 3.58702476978302 and perplexity is 36.12643142189274
At time: 558.9842121601105 and batch: 1850, loss is 3.60471755027771 and perplexity is 36.77129634789696
At time: 559.8203828334808 and batch: 1900, loss is 3.691587462425232 and perplexity is 40.10846713111287
At time: 560.6548728942871 and batch: 1950, loss is 3.6197562646865844 and perplexity is 37.3284684472229
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245713060955668 and perplexity of 69.80551799097543
finished 16 epochs...
Completing Train Step...
At time: 563.8210678100586 and batch: 50, loss is 3.808369779586792 and perplexity is 45.07689366294738
At time: 564.6800048351288 and batch: 100, loss is 3.7838201379776 and perplexity is 43.983745181840504
At time: 565.515721321106 and batch: 150, loss is 3.762017250061035 and perplexity is 43.03515113744667
At time: 566.3513672351837 and batch: 200, loss is 3.7518425464630125 and perplexity is 42.59950129271464
At time: 567.1865451335907 and batch: 250, loss is 3.752802629470825 and perplexity is 42.64041998957675
At time: 568.0251262187958 and batch: 300, loss is 3.765154709815979 and perplexity is 43.17038422544161
At time: 568.8571910858154 and batch: 350, loss is 3.78262704372406 and perplexity is 43.93129972062532
At time: 569.6947803497314 and batch: 400, loss is 3.7459491157531737 and perplexity is 42.34918242653571
At time: 570.5326180458069 and batch: 450, loss is 3.7898770999908447 and perplexity is 44.250961498204035
At time: 571.3686149120331 and batch: 500, loss is 3.7949529552459715 and perplexity is 44.47614398705646
At time: 572.2014009952545 and batch: 550, loss is 3.7662211990356447 and perplexity is 43.21644953453842
At time: 573.0367646217346 and batch: 600, loss is 3.74621994972229 and perplexity is 42.36065357701962
At time: 573.8991730213165 and batch: 650, loss is 3.760801100730896 and perplexity is 42.98284577922832
At time: 574.7349283695221 and batch: 700, loss is 3.787422847747803 and perplexity is 44.14249163733601
At time: 575.5691752433777 and batch: 750, loss is 3.7558782958984374 and perplexity is 42.77176958802887
At time: 576.3750014305115 and batch: 800, loss is 3.7240764617919924 and perplexity is 41.432950157294876
At time: 577.2006249427795 and batch: 850, loss is 3.7236377382278443 and perplexity is 41.414776532618895
At time: 578.038932800293 and batch: 900, loss is 3.6842100524902346 and perplexity is 39.81365932335118
At time: 578.8778138160706 and batch: 950, loss is 3.780722131729126 and perplexity is 43.84769411677484
At time: 579.7090442180634 and batch: 1000, loss is 3.7398094511032105 and perplexity is 42.089969203630844
At time: 580.5466773509979 and batch: 1050, loss is 3.7039226579666136 and perplexity is 40.60627689433673
At time: 581.382922410965 and batch: 1100, loss is 3.713058466911316 and perplexity is 40.978947815149
At time: 582.2202203273773 and batch: 1150, loss is 3.679167685508728 and perplexity is 39.61340953291865
At time: 583.0556678771973 and batch: 1200, loss is 3.7404180002212524 and perplexity is 42.11559081248115
At time: 583.8906164169312 and batch: 1250, loss is 3.726826558113098 and perplexity is 41.5470515841394
At time: 584.7240741252899 and batch: 1300, loss is 3.7432366228103637 and perplexity is 42.23446622185427
At time: 585.558474779129 and batch: 1350, loss is 3.6188195085525514 and perplexity is 37.29351714840854
At time: 586.3907678127289 and batch: 1400, loss is 3.6471469354629518 and perplexity is 38.365051786390396
At time: 587.2274894714355 and batch: 1450, loss is 3.5750915384292603 and perplexity is 35.697888394730626
At time: 588.066175699234 and batch: 1500, loss is 3.5894087409973143 and perplexity is 36.212658535117605
At time: 588.9007062911987 and batch: 1550, loss is 3.602915816307068 and perplexity is 36.70510390261745
At time: 589.740713596344 and batch: 1600, loss is 3.6809085512161257 and perplexity is 39.68243122044054
At time: 590.5789787769318 and batch: 1650, loss is 3.626611189842224 and perplexity is 37.58523134438477
At time: 591.4135205745697 and batch: 1700, loss is 3.636504497528076 and perplexity is 37.95891905832044
At time: 592.2493209838867 and batch: 1750, loss is 3.625763087272644 and perplexity is 37.55336872639726
At time: 593.08780169487 and batch: 1800, loss is 3.5868640327453614 and perplexity is 36.12062503298818
At time: 593.9239332675934 and batch: 1850, loss is 3.6045510005950927 and perplexity is 36.76517261012824
At time: 594.7649810314178 and batch: 1900, loss is 3.6914872312545777 and perplexity is 40.10444721396303
At time: 595.6017737388611 and batch: 1950, loss is 3.6193885707855227 and perplexity is 37.3147455201118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245967421420785 and perplexity of 69.82327601337299
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 598.8252332210541 and batch: 50, loss is 3.8077204608917237 and perplexity is 45.04763389366206
At time: 599.6611602306366 and batch: 100, loss is 3.788183846473694 and perplexity is 44.17609680235177
At time: 600.4967334270477 and batch: 150, loss is 3.7692436170578003 and perplexity is 43.347265300846416
At time: 601.3302681446075 and batch: 200, loss is 3.759830451011658 and perplexity is 42.94114473386873
At time: 602.164422750473 and batch: 250, loss is 3.761248064041138 and perplexity is 43.00206182837598
At time: 602.9996771812439 and batch: 300, loss is 3.7717674207687377 and perplexity is 43.456803458132896
At time: 603.8361675739288 and batch: 350, loss is 3.7924572944641115 and perplexity is 44.36528500951967
At time: 604.6710741519928 and batch: 400, loss is 3.7601596546173095 and perplexity is 42.95528344067487
At time: 605.5086932182312 and batch: 450, loss is 3.8061057043075563 and perplexity is 44.97495162810742
At time: 606.3432610034943 and batch: 500, loss is 3.8115368604660036 and perplexity is 45.21988213947725
At time: 607.1772618293762 and batch: 550, loss is 3.7858296489715575 and perplexity is 44.07221986699237
At time: 608.014511346817 and batch: 600, loss is 3.762655644416809 and perplexity is 43.06263330633008
At time: 608.8491468429565 and batch: 650, loss is 3.7732523822784425 and perplexity is 43.52138307585924
At time: 609.6850645542145 and batch: 700, loss is 3.7970773363113404 and perplexity is 44.57072869661452
At time: 610.5220103263855 and batch: 750, loss is 3.7662754583358766 and perplexity is 43.21879449246598
At time: 611.3574569225311 and batch: 800, loss is 3.735787010192871 and perplexity is 41.921004841992215
At time: 612.1897089481354 and batch: 850, loss is 3.7350741147994997 and perplexity is 41.89113020076715
At time: 613.0237650871277 and batch: 900, loss is 3.6915917348861695 and perplexity is 40.10863849333801
At time: 613.8593735694885 and batch: 950, loss is 3.7889210891723635 and perplexity is 44.208677315572075
At time: 614.6954414844513 and batch: 1000, loss is 3.7466339254379273 and perplexity is 42.37819348919738
At time: 615.5586547851562 and batch: 1050, loss is 3.7099483585357667 and perplexity is 40.85169683107607
At time: 616.3938882350922 and batch: 1100, loss is 3.7178340339660645 and perplexity is 41.17511355678628
At time: 617.228111743927 and batch: 1150, loss is 3.6888015508651733 and perplexity is 39.996883991424646
At time: 618.0688259601593 and batch: 1200, loss is 3.7487336730957033 and perplexity is 42.467270488599596
At time: 618.9013934135437 and batch: 1250, loss is 3.730651445388794 and perplexity is 41.70626867268531
At time: 619.7424504756927 and batch: 1300, loss is 3.7411392450332643 and perplexity is 42.14597742063397
At time: 620.5792737007141 and batch: 1350, loss is 3.6131724548339843 and perplexity is 37.083512166498394
At time: 621.4139487743378 and batch: 1400, loss is 3.6393828773498536 and perplexity is 38.068336642132735
At time: 622.2512714862823 and batch: 1450, loss is 3.564556498527527 and perplexity is 35.32378377966614
At time: 623.0872249603271 and batch: 1500, loss is 3.579094605445862 and perplexity is 35.84107583758131
At time: 623.9246218204498 and batch: 1550, loss is 3.5942728233337404 and perplexity is 36.38922896628343
At time: 624.7597658634186 and batch: 1600, loss is 3.6736994552612305 and perplexity is 39.397385461671995
At time: 625.5939300060272 and batch: 1650, loss is 3.6168567085266115 and perplexity is 37.22038922320661
At time: 626.4315049648285 and batch: 1700, loss is 3.62600248336792 and perplexity is 37.5623599324217
At time: 627.2651588916779 and batch: 1750, loss is 3.6156886291503905 and perplexity is 37.17693823622137
At time: 628.1008851528168 and batch: 1800, loss is 3.5749656629562376 and perplexity is 35.69339518894117
At time: 628.9390110969543 and batch: 1850, loss is 3.5929358291625975 and perplexity is 36.34060928861847
At time: 629.7750248908997 and batch: 1900, loss is 3.68119348526001 and perplexity is 39.69373970704924
At time: 630.6093063354492 and batch: 1950, loss is 3.612892646789551 and perplexity is 37.07313735302419
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243491665152616 and perplexity of 69.65062440995061
finished 18 epochs...
Completing Train Step...
At time: 633.7951707839966 and batch: 50, loss is 3.808748903274536 and perplexity is 45.09398662107285
At time: 634.6289117336273 and batch: 100, loss is 3.7872052812576293 and perplexity is 44.132888755033534
At time: 635.4645645618439 and batch: 150, loss is 3.765823802947998 and perplexity is 43.19927889856916
At time: 636.2997634410858 and batch: 200, loss is 3.755380754470825 and perplexity is 42.75049415387036
At time: 637.1632306575775 and batch: 250, loss is 3.7554327774047853 and perplexity is 42.75271821785517
At time: 637.9979305267334 and batch: 300, loss is 3.764116849899292 and perplexity is 43.12560265658341
At time: 638.8320004940033 and batch: 350, loss is 3.783726487159729 and perplexity is 43.97962626100437
At time: 639.6631412506104 and batch: 400, loss is 3.7504665279388427 and perplexity is 42.540923900846295
At time: 640.4961159229279 and batch: 450, loss is 3.795864772796631 and perplexity is 44.51671661033347
At time: 641.3290321826935 and batch: 500, loss is 3.8014812660217285 and perplexity is 44.76744790377499
At time: 642.1621840000153 and batch: 550, loss is 3.775641655921936 and perplexity is 43.625491892069554
At time: 642.9948334693909 and batch: 600, loss is 3.753663296699524 and perplexity is 42.67713499911611
At time: 643.8264360427856 and batch: 650, loss is 3.764847378730774 and perplexity is 43.15711866297315
At time: 644.668224811554 and batch: 700, loss is 3.7905139350891113 and perplexity is 44.27915103870982
At time: 645.5102918148041 and batch: 750, loss is 3.7595823335647585 and perplexity is 42.93049160833824
At time: 646.3481783866882 and batch: 800, loss is 3.7291817331314085 and perplexity is 41.64501748024691
At time: 647.191826581955 and batch: 850, loss is 3.7286770391464232 and perplexity is 41.62400479335439
At time: 648.0327792167664 and batch: 900, loss is 3.6862201118469238 and perplexity is 39.893767626047755
At time: 648.872307062149 and batch: 950, loss is 3.7838804054260256 and perplexity is 43.98639604981454
At time: 649.7080678939819 and batch: 1000, loss is 3.741845908164978 and perplexity is 42.175770954783395
At time: 650.5370452404022 and batch: 1050, loss is 3.705767207145691 and perplexity is 40.68124629016025
At time: 651.3690314292908 and batch: 1100, loss is 3.7143890714645384 and perplexity is 41.033510882580714
At time: 652.1932039260864 and batch: 1150, loss is 3.684939060211182 and perplexity is 39.842694370497945
At time: 653.0230493545532 and batch: 1200, loss is 3.745088677406311 and perplexity is 42.31275923821878
At time: 653.8599865436554 and batch: 1250, loss is 3.7276137399673464 and perplexity is 41.57976954504704
At time: 654.6937282085419 and batch: 1300, loss is 3.7389715003967283 and perplexity is 42.05471465704982
At time: 655.5280239582062 and batch: 1350, loss is 3.6119967222213747 and perplexity is 37.039937492956135
At time: 656.3649656772614 and batch: 1400, loss is 3.638908586502075 and perplexity is 38.05028545956696
At time: 657.200040102005 and batch: 1450, loss is 3.5653314924240114 and perplexity is 35.35117010724375
At time: 658.0326426029205 and batch: 1500, loss is 3.5807383346557615 and perplexity is 35.900037305918254
At time: 658.8661799430847 and batch: 1550, loss is 3.5964647150039672 and perplexity is 36.469077692050355
At time: 659.701628446579 and batch: 1600, loss is 3.6760075759887694 and perplexity is 39.48842440768918
At time: 660.5511643886566 and batch: 1650, loss is 3.61981436252594 and perplexity is 37.330637213585845
At time: 661.3898813724518 and batch: 1700, loss is 3.6294059419631957 and perplexity is 37.69041966858211
At time: 662.2241778373718 and batch: 1750, loss is 3.6194792699813845 and perplexity is 37.318130091010865
At time: 663.0584142208099 and batch: 1800, loss is 3.578635935783386 and perplexity is 35.824640392932174
At time: 663.8936815261841 and batch: 1850, loss is 3.5970588445663454 and perplexity is 36.4907514871035
At time: 664.7364201545715 and batch: 1900, loss is 3.685996856689453 and perplexity is 39.88486213081016
At time: 665.5675692558289 and batch: 1950, loss is 3.61689163684845 and perplexity is 37.22168929164482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242635753542878 and perplexity of 69.59103513710568
finished 19 epochs...
Completing Train Step...
At time: 668.7219290733337 and batch: 50, loss is 3.8089381074905395 and perplexity is 45.10251940065144
At time: 669.5643103122711 and batch: 100, loss is 3.786060118675232 and perplexity is 44.08237834901159
At time: 670.4048631191254 and batch: 150, loss is 3.7637839841842653 and perplexity is 43.11125001090353
At time: 671.2355630397797 and batch: 200, loss is 3.7527034378051756 and perplexity is 42.63619062505631
At time: 672.0785219669342 and batch: 250, loss is 3.752206072807312 and perplexity is 42.614990148821605
At time: 672.9193384647369 and batch: 300, loss is 3.7602145624160768 and perplexity is 42.95764208548743
At time: 673.7534916400909 and batch: 350, loss is 3.7795374631881713 and perplexity is 43.795779889608696
At time: 674.5860254764557 and batch: 400, loss is 3.7457745122909545 and perplexity is 42.341788758160725
At time: 675.4208762645721 and batch: 450, loss is 3.7910011911392214 and perplexity is 44.3007315801449
At time: 676.2573115825653 and batch: 500, loss is 3.796574387550354 and perplexity is 44.54831754014442
At time: 677.0950560569763 and batch: 550, loss is 3.7706227350234984 and perplexity is 43.407087534663745
At time: 677.9295558929443 and batch: 600, loss is 3.7492699909210203 and perplexity is 42.49005255142231
At time: 678.7622900009155 and batch: 650, loss is 3.7607844352722166 and perplexity is 42.98212945635701
At time: 679.6210210323334 and batch: 700, loss is 3.7870723247528075 and perplexity is 44.12702139045776
At time: 680.4516923427582 and batch: 750, loss is 3.7560677671432496 and perplexity is 42.77987437624344
At time: 681.2854700088501 and batch: 800, loss is 3.7256548833847045 and perplexity is 41.49840046097055
At time: 682.1193010807037 and batch: 850, loss is 3.7252563285827636 and perplexity is 41.48186436968215
At time: 682.9522063732147 and batch: 900, loss is 3.6833109998703004 and perplexity is 39.77788083440943
At time: 683.7897145748138 and batch: 950, loss is 3.7811594152450563 and perplexity is 43.86687218344426
At time: 684.6225454807281 and batch: 1000, loss is 3.739355983734131 and perplexity is 42.070887102913424
At time: 685.4560606479645 and batch: 1050, loss is 3.703822364807129 and perplexity is 40.60220456674881
At time: 686.2898209095001 and batch: 1100, loss is 3.7127503490448 and perplexity is 40.966323414177744
At time: 687.1239869594574 and batch: 1150, loss is 3.6831323194503782 and perplexity is 39.77077394090859
At time: 687.9588413238525 and batch: 1200, loss is 3.7434897899627684 and perplexity is 42.245159954994854
At time: 688.792816400528 and batch: 1250, loss is 3.7262338972091675 and perplexity is 41.52243556618816
At time: 689.6269979476929 and batch: 1300, loss is 3.7381209707260132 and perplexity is 42.01896108133438
At time: 690.4640069007874 and batch: 1350, loss is 3.6115312576293945 and perplexity is 37.02270072542769
At time: 691.2967519760132 and batch: 1400, loss is 3.6387476205825804 and perplexity is 38.044161153296436
At time: 692.1369712352753 and batch: 1450, loss is 3.565851302146912 and perplexity is 35.3695507659901
At time: 692.9703824520111 and batch: 1500, loss is 3.581656537055969 and perplexity is 35.933015944555656
At time: 693.798858165741 and batch: 1550, loss is 3.59756528377533 and perplexity is 36.5092365147982
At time: 694.6265151500702 and batch: 1600, loss is 3.677183918952942 and perplexity is 39.534903670324454
At time: 695.4137544631958 and batch: 1650, loss is 3.6213112831115724 and perplexity is 37.38656005849199
At time: 696.2699780464172 and batch: 1700, loss is 3.631086015701294 and perplexity is 37.753795576036744
At time: 697.1094117164612 and batch: 1750, loss is 3.621293053627014 and perplexity is 37.38587852698472
At time: 697.9434010982513 and batch: 1800, loss is 3.580420789718628 and perplexity is 35.88863924062359
At time: 698.779242515564 and batch: 1850, loss is 3.5990375471115112 and perplexity is 36.56302731254435
At time: 699.6181483268738 and batch: 1900, loss is 3.6882391595840454 and perplexity is 39.9743964165963
At time: 700.4545493125916 and batch: 1950, loss is 3.6186891651153563 and perplexity is 37.28865649998201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242262445494186 and perplexity of 69.56506109203387
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
2210.6060926914215


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}, 'best_accuracy': -69.56506109203387}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.0664099827407102, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3472414743178278}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4729700088500977 and batch: 50, loss is 7.6521468925476075 and perplexity is 2105.160294340363
At time: 2.364081382751465 and batch: 100, loss is 6.841489686965942 and perplexity is 935.8822684219497
At time: 3.256808280944824 and batch: 150, loss is 6.4991632843017575 and perplexity is 664.5853313640687
At time: 4.142786741256714 and batch: 200, loss is 6.310816173553467 and perplexity is 550.4940642055997
At time: 5.02990198135376 and batch: 250, loss is 6.146126680374145 and perplexity is 466.9054059849741
At time: 5.914823293685913 and batch: 300, loss is 6.00616623878479 and perplexity is 405.92411724057575
At time: 6.79970383644104 and batch: 350, loss is 5.882698850631714 and perplexity is 358.7762196844928
At time: 7.68913722038269 and batch: 400, loss is 5.788288173675537 and perplexity is 326.45371373032657
At time: 8.575746059417725 and batch: 450, loss is 5.672798490524292 and perplexity is 290.84733005797835
At time: 9.463603019714355 and batch: 500, loss is 5.614297218322754 and perplexity is 274.3205239978107
At time: 10.352354526519775 and batch: 550, loss is 5.527910871505737 and perplexity is 251.6176998471055
At time: 11.240195512771606 and batch: 600, loss is 5.531419124603271 and perplexity is 252.5019886695151
At time: 12.126407861709595 and batch: 650, loss is 5.577499828338623 and perplexity is 264.40970904173133
At time: 13.016274690628052 and batch: 700, loss is 5.501562480926514 and perplexity is 245.07455758579505
At time: 13.907112121582031 and batch: 750, loss is 5.438463544845581 and perplexity is 230.08839124260646
At time: 14.794102668762207 and batch: 800, loss is 5.409789304733277 and perplexity is 223.58447452696547
At time: 15.683498859405518 and batch: 850, loss is 5.408714637756348 and perplexity is 223.3443247392731
At time: 16.57580828666687 and batch: 900, loss is 5.402848634719849 and perplexity is 222.0380213877029
At time: 17.465809106826782 and batch: 950, loss is 5.425456600189209 and perplexity is 227.11502340664663
At time: 18.360670804977417 and batch: 1000, loss is 5.38195143699646 and perplexity is 217.4461942131438
At time: 19.249008417129517 and batch: 1050, loss is 5.270617570877075 and perplexity is 194.53606516399103
At time: 20.138097524642944 and batch: 1100, loss is 5.349968576431275 and perplexity is 210.60167990633283
At time: 21.027275562286377 and batch: 1150, loss is 5.237630033493042 and perplexity is 188.223490019341
At time: 21.917773723602295 and batch: 1200, loss is 5.314204807281494 and perplexity is 203.2028634286555
At time: 22.806215047836304 and batch: 1250, loss is 5.259421510696411 and perplexity is 192.37017501413524
At time: 23.69680690765381 and batch: 1300, loss is 5.279065713882447 and perplexity is 196.186495381371
At time: 24.590991735458374 and batch: 1350, loss is 5.20265383720398 and perplexity is 181.75394779652075
At time: 25.480326652526855 and batch: 1400, loss is 5.2236755847930905 and perplexity is 185.61517610067204
At time: 26.368874549865723 and batch: 1450, loss is 5.1709834003448485 and perplexity is 176.08791728533078
At time: 27.263831615447998 and batch: 1500, loss is 5.141005125045776 and perplexity is 170.88744527972347
At time: 28.152087688446045 and batch: 1550, loss is 5.11962773323059 and perplexity is 167.27308781708953
At time: 29.02262568473816 and batch: 1600, loss is 5.160198221206665 and perplexity is 174.19898211548917
At time: 29.867732524871826 and batch: 1650, loss is 5.127188673019409 and perplexity is 168.5426229536886
At time: 30.76604199409485 and batch: 1700, loss is 5.14707992553711 and perplexity is 171.92871195776434
At time: 31.66539239883423 and batch: 1750, loss is 5.143590250015259 and perplexity is 171.32978218323424
At time: 32.56613898277283 and batch: 1800, loss is 5.116176795959473 and perplexity is 166.69683376406368
At time: 33.46452975273132 and batch: 1850, loss is 5.101241474151611 and perplexity is 164.22566271048032
At time: 34.36044692993164 and batch: 1900, loss is 5.153701181411743 and perplexity is 173.07087304946182
At time: 35.25281810760498 and batch: 1950, loss is 5.076008777618409 and perplexity is 160.1336497700338
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.779432571765988 and perplexity of 119.03678604447832
finished 1 epochs...
Completing Train Step...
At time: 38.437097787857056 and batch: 50, loss is 4.993660659790039 and perplexity is 147.4752934609272
At time: 39.262983083724976 and batch: 100, loss is 4.9505354690551755 and perplexity is 141.25057898897995
At time: 40.09104251861572 and batch: 150, loss is 4.896170568466187 and perplexity is 133.7765095615783
At time: 40.919082164764404 and batch: 200, loss is 4.869063549041748 and perplexity is 130.19893487295647
At time: 41.74626445770264 and batch: 250, loss is 4.8727661228179935 and perplexity is 130.68189958941028
At time: 42.57096481323242 and batch: 300, loss is 4.878162660598755 and perplexity is 131.38903572510517
At time: 43.44247889518738 and batch: 350, loss is 4.876518745422363 and perplexity is 131.17322073463677
At time: 44.26777768135071 and batch: 400, loss is 4.828691530227661 and perplexity is 125.04723303726185
At time: 45.09333372116089 and batch: 450, loss is 4.801880359649658 and perplexity is 121.73911575493285
At time: 45.915594816207886 and batch: 500, loss is 4.79066653251648 and perplexity is 120.38158016602432
At time: 46.741851568222046 and batch: 550, loss is 4.748451194763184 and perplexity is 115.40540554213055
At time: 47.56869626045227 and batch: 600, loss is 4.727846956253051 and perplexity is 113.05189445453479
At time: 48.40241050720215 and batch: 650, loss is 4.802759113311768 and perplexity is 121.8461414664553
At time: 49.229145765304565 and batch: 700, loss is 4.798199977874756 and perplexity is 121.29189281240976
At time: 50.05349540710449 and batch: 750, loss is 4.75913296699524 and perplexity is 116.64474719703955
At time: 50.87914538383484 and batch: 800, loss is 4.740281000137329 and perplexity is 114.46636222489303
At time: 51.706231355667114 and batch: 850, loss is 4.729208221435547 and perplexity is 113.2058928548207
At time: 52.53855514526367 and batch: 900, loss is 4.725630683898926 and perplexity is 112.80161810899003
At time: 53.36417555809021 and batch: 950, loss is 4.782409954071045 and perplexity is 119.39173220790038
At time: 54.19267463684082 and batch: 1000, loss is 4.757549610137939 and perplexity is 116.46020307485237
At time: 55.01840782165527 and batch: 1050, loss is 4.66985592842102 and perplexity is 106.68237142751407
At time: 55.84327745437622 and batch: 1100, loss is 4.733860454559326 and perplexity is 113.73378003437787
At time: 56.670745611190796 and batch: 1150, loss is 4.670088939666748 and perplexity is 106.70723251612169
At time: 57.49533033370972 and batch: 1200, loss is 4.746448268890381 and perplexity is 115.17448840166426
At time: 58.33073830604553 and batch: 1250, loss is 4.709739904403687 and perplexity is 111.02327948394472
At time: 59.159483194351196 and batch: 1300, loss is 4.724210433959961 and perplexity is 112.64152533054538
At time: 59.986061573028564 and batch: 1350, loss is 4.617854967117309 and perplexity is 101.27655742181692
At time: 60.81258273124695 and batch: 1400, loss is 4.636958951950073 and perplexity is 103.22994254968987
At time: 61.64609932899475 and batch: 1450, loss is 4.578355703353882 and perplexity is 97.35418336888004
At time: 62.47389101982117 and batch: 1500, loss is 4.563672742843628 and perplexity is 95.93517882622677
At time: 63.29983305931091 and batch: 1550, loss is 4.562880535125732 and perplexity is 95.85920833332153
At time: 64.12975907325745 and batch: 1600, loss is 4.63258246421814 and perplexity is 102.77914514673895
At time: 64.9550154209137 and batch: 1650, loss is 4.587429008483887 and perplexity is 98.2415270627841
At time: 65.78923225402832 and batch: 1700, loss is 4.619349842071533 and perplexity is 101.4280664262507
At time: 66.62958645820618 and batch: 1750, loss is 4.612676181793213 and perplexity is 100.75342364053584
At time: 67.46370434761047 and batch: 1800, loss is 4.577648019790649 and perplexity is 97.28531178601584
At time: 68.2988920211792 and batch: 1850, loss is 4.594904775619507 and perplexity is 98.97870991256647
At time: 69.13493466377258 and batch: 1900, loss is 4.676381692886353 and perplexity is 107.38083197185838
At time: 69.9613687992096 and batch: 1950, loss is 4.605786123275757 and perplexity is 100.06161270159883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.513697708484738 and perplexity of 91.25864324634051
finished 2 epochs...
Completing Train Step...
At time: 73.0767502784729 and batch: 50, loss is 4.572425584793091 and perplexity is 96.77856993391974
At time: 73.93383812904358 and batch: 100, loss is 4.533709077835083 and perplexity is 93.10324864637504
At time: 74.75907921791077 and batch: 150, loss is 4.501072130203247 and perplexity is 90.11369313998152
At time: 75.58271503448486 and batch: 200, loss is 4.496123514175415 and perplexity is 89.66885664408088
At time: 76.40730500221252 and batch: 250, loss is 4.491433811187744 and perplexity is 89.24932085720759
At time: 77.23297595977783 and batch: 300, loss is 4.503780937194824 and perplexity is 90.35812465142706
At time: 78.06067967414856 and batch: 350, loss is 4.514097967147827 and perplexity is 91.29517761999364
At time: 78.8863537311554 and batch: 400, loss is 4.473456583023071 and perplexity is 87.65920124856
At time: 79.71154356002808 and batch: 450, loss is 4.477002964019776 and perplexity is 87.97062606318205
At time: 80.53666687011719 and batch: 500, loss is 4.474316091537475 and perplexity is 87.73457746700939
At time: 81.3621985912323 and batch: 550, loss is 4.44439772605896 and perplexity is 85.14857962046162
At time: 82.18774104118347 and batch: 600, loss is 4.423518285751343 and perplexity is 83.38915673560143
At time: 83.0153067111969 and batch: 650, loss is 4.493684225082397 and perplexity is 89.45039493404184
At time: 83.84057402610779 and batch: 700, loss is 4.515461616516113 and perplexity is 91.41975715337864
At time: 84.6665940284729 and batch: 750, loss is 4.4705522346496585 and perplexity is 87.40497774551085
At time: 85.52541422843933 and batch: 800, loss is 4.452254648208618 and perplexity is 85.82022044141758
At time: 86.35193395614624 and batch: 850, loss is 4.447028379440308 and perplexity is 85.37287090632435
At time: 87.17777991294861 and batch: 900, loss is 4.426359786987304 and perplexity is 83.62644409403516
At time: 88.00249314308167 and batch: 950, loss is 4.499762544631958 and perplexity is 89.99575878708819
At time: 88.82922863960266 and batch: 1000, loss is 4.485640459060669 and perplexity is 88.73376296056661
At time: 89.65154600143433 and batch: 1050, loss is 4.40747486114502 and perplexity is 82.06198375316586
At time: 90.47950100898743 and batch: 1100, loss is 4.460465278625488 and perplexity is 86.52775924872529
At time: 91.31067371368408 and batch: 1150, loss is 4.412072505950928 and perplexity is 82.44014426424572
At time: 92.13503241539001 and batch: 1200, loss is 4.489557657241821 and perplexity is 89.08203237025849
At time: 92.96109890937805 and batch: 1250, loss is 4.461652774810791 and perplexity is 86.63057166535047
At time: 93.79163813591003 and batch: 1300, loss is 4.466701850891114 and perplexity is 87.06908211730295
At time: 94.6350679397583 and batch: 1350, loss is 4.352702770233154 and perplexity is 77.68815265249427
At time: 95.4612488746643 and batch: 1400, loss is 4.3795503234863284 and perplexity is 79.80214018733787
At time: 96.29319643974304 and batch: 1450, loss is 4.323538708686828 and perplexity is 75.45517027317614
At time: 97.11812257766724 and batch: 1500, loss is 4.318263487815857 and perplexity is 75.05817562199186
At time: 97.95161557197571 and batch: 1550, loss is 4.31876431465149 and perplexity is 75.09577618547665
At time: 98.78673958778381 and batch: 1600, loss is 4.400549345016479 and perplexity is 81.49562558612736
At time: 99.61549592018127 and batch: 1650, loss is 4.351466808319092 and perplexity is 77.59219236848583
At time: 100.4771339893341 and batch: 1700, loss is 4.386563091278076 and perplexity is 80.36374095205917
At time: 101.31438064575195 and batch: 1750, loss is 4.3741734600067135 and perplexity is 79.37420647572898
At time: 102.14930558204651 and batch: 1800, loss is 4.33974555015564 and perplexity is 76.68802359984332
At time: 102.9916341304779 and batch: 1850, loss is 4.373536787033081 and perplexity is 79.32368714751433
At time: 103.82223701477051 and batch: 1900, loss is 4.45523097038269 and perplexity is 86.07602956284104
At time: 104.66246318817139 and batch: 1950, loss is 4.392709455490112 and perplexity is 80.85920687058743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429137615824855 and perplexity of 83.85906698572684
finished 3 epochs...
Completing Train Step...
At time: 107.7737934589386 and batch: 50, loss is 4.363374910354614 and perplexity is 78.52169141332496
At time: 108.62622928619385 and batch: 100, loss is 4.321624326705932 and perplexity is 75.31085843290658
At time: 109.45365238189697 and batch: 150, loss is 4.295357103347778 and perplexity is 73.35840630062368
At time: 110.28125500679016 and batch: 200, loss is 4.295782022476196 and perplexity is 73.38958431428914
At time: 111.10726618766785 and batch: 250, loss is 4.28987024307251 and perplexity is 72.95700120910706
At time: 111.93295669555664 and batch: 300, loss is 4.304694652557373 and perplexity is 74.04660205997921
At time: 112.76185393333435 and batch: 350, loss is 4.307064695358276 and perplexity is 74.22230380420525
At time: 113.588552236557 and batch: 400, loss is 4.27127893447876 and perplexity is 71.61316562295265
At time: 114.41431951522827 and batch: 450, loss is 4.294681043624878 and perplexity is 73.3088283974877
At time: 115.24393439292908 and batch: 500, loss is 4.294187831878662 and perplexity is 73.27268053722815
At time: 116.07505989074707 and batch: 550, loss is 4.260459938049316 and perplexity is 70.84255915076554
At time: 116.90813875198364 and batch: 600, loss is 4.247771854400635 and perplexity is 69.94938117531295
At time: 117.73682308197021 and batch: 650, loss is 4.31771333694458 and perplexity is 75.01689365797243
At time: 118.564377784729 and batch: 700, loss is 4.34423638343811 and perplexity is 77.0331911935518
At time: 119.39432501792908 and batch: 750, loss is 4.30011365890503 and perplexity is 73.70817081350638
At time: 120.22427272796631 and batch: 800, loss is 4.279999461174011 and perplexity is 72.24040108230932
At time: 121.05506110191345 and batch: 850, loss is 4.2713734149932865 and perplexity is 71.61993199132753
At time: 121.88532638549805 and batch: 900, loss is 4.249654808044434 and perplexity is 70.08121669861592
At time: 122.7167854309082 and batch: 950, loss is 4.330752143859863 and perplexity is 76.00142908502434
At time: 123.54893612861633 and batch: 1000, loss is 4.311776924133301 and perplexity is 74.57288163268792
At time: 124.37958669662476 and batch: 1050, loss is 4.246135396957397 and perplexity is 69.83500560074367
At time: 125.20595073699951 and batch: 1100, loss is 4.289698371887207 and perplexity is 72.94446308033545
At time: 126.03278040885925 and batch: 1150, loss is 4.2488536405563355 and perplexity is 70.02509239175764
At time: 126.85968160629272 and batch: 1200, loss is 4.3303635835647585 and perplexity is 75.97190368388146
At time: 127.73255228996277 and batch: 1250, loss is 4.308277764320374 and perplexity is 74.31239520974167
At time: 128.55877685546875 and batch: 1300, loss is 4.308872146606445 and perplexity is 74.35657831061535
At time: 129.38987278938293 and batch: 1350, loss is 4.193527565002442 and perplexity is 66.25610191500658
At time: 130.22113347053528 and batch: 1400, loss is 4.222316761016845 and perplexity is 68.19128433557817
At time: 131.05138206481934 and batch: 1450, loss is 4.162649917602539 and perplexity is 64.24153201147706
At time: 131.88650512695312 and batch: 1500, loss is 4.164140319824218 and perplexity is 64.33734911878933
At time: 132.71942400932312 and batch: 1550, loss is 4.163993034362793 and perplexity is 64.32787386043852
At time: 133.5466911792755 and batch: 1600, loss is 4.249639568328857 and perplexity is 70.08014868894426
At time: 134.38574719429016 and batch: 1650, loss is 4.202380375862122 and perplexity is 66.84525865235062
At time: 135.2153615951538 and batch: 1700, loss is 4.235851612091064 and perplexity is 69.12051754452223
At time: 136.0470998287201 and batch: 1750, loss is 4.225688447952271 and perplexity is 68.42159204264247
At time: 136.87590909004211 and batch: 1800, loss is 4.189964785575866 and perplexity is 66.02046604678205
At time: 137.70998978614807 and batch: 1850, loss is 4.22610915184021 and perplexity is 68.45038332831206
At time: 138.53965592384338 and batch: 1900, loss is 4.306420803070068 and perplexity is 74.17452801805348
At time: 139.36938571929932 and batch: 1950, loss is 4.246859836578369 and perplexity is 69.88561517530876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382496820494186 and perplexity of 80.0376237099987
finished 4 epochs...
Completing Train Step...
At time: 142.4758756160736 and batch: 50, loss is 4.219687805175782 and perplexity is 68.01224790286844
At time: 143.33580446243286 and batch: 100, loss is 4.185621552467346 and perplexity is 65.73434556655256
At time: 144.16650676727295 and batch: 150, loss is 4.158981113433838 and perplexity is 64.00627423227334
At time: 144.99928855895996 and batch: 200, loss is 4.155847201347351 and perplexity is 63.80599818352669
At time: 145.8308789730072 and batch: 250, loss is 4.154150028228759 and perplexity is 63.69780019993043
At time: 146.6647024154663 and batch: 300, loss is 4.164532642364502 and perplexity is 64.36259506298342
At time: 147.49435710906982 and batch: 350, loss is 4.167711577415466 and perplexity is 64.56752512950698
At time: 148.35019850730896 and batch: 400, loss is 4.131364817619324 and perplexity is 62.262842396121854
At time: 149.18522191047668 and batch: 450, loss is 4.166324782371521 and perplexity is 64.47804526511443
At time: 150.01712083816528 and batch: 500, loss is 4.169934511184692 and perplexity is 64.71121410788473
At time: 150.84763097763062 and batch: 550, loss is 4.132166600227356 and perplexity is 62.31278367863214
At time: 151.67899990081787 and batch: 600, loss is 4.125211253166198 and perplexity is 61.88088040157022
At time: 152.5072557926178 and batch: 650, loss is 4.192228307723999 and perplexity is 66.17007409059254
At time: 153.3396270275116 and batch: 700, loss is 4.217750668525696 and perplexity is 67.88062641036872
At time: 154.18046236038208 and batch: 750, loss is 4.177608766555786 and perplexity is 65.20973493171427
At time: 155.01309084892273 and batch: 800, loss is 4.157134585380554 and perplexity is 63.88819390418763
At time: 155.8460533618927 and batch: 850, loss is 4.1479627132415775 and perplexity is 63.3048986025231
At time: 156.65643334388733 and batch: 900, loss is 4.1272747564315795 and perplexity is 62.008703636818744
At time: 157.50147247314453 and batch: 950, loss is 4.2123301267623905 and perplexity is 67.51367208411291
At time: 158.33443212509155 and batch: 1000, loss is 4.1946949911117555 and perplexity is 66.33349618553963
At time: 159.16657495498657 and batch: 1050, loss is 4.1315825128555295 and perplexity is 62.27639819576708
At time: 159.99926209449768 and batch: 1100, loss is 4.172685580253601 and perplexity is 64.88948423170557
At time: 160.83083391189575 and batch: 1150, loss is 4.136313586235047 and perplexity is 62.57173047391322
At time: 161.6602725982666 and batch: 1200, loss is 4.214982218742371 and perplexity is 67.69296219423
At time: 162.48951625823975 and batch: 1250, loss is 4.19939836025238 and perplexity is 66.6462219603664
At time: 163.32285046577454 and batch: 1300, loss is 4.196246738433838 and perplexity is 66.43650891480277
At time: 164.15533804893494 and batch: 1350, loss is 4.080483407974243 and perplexity is 59.17406815341512
At time: 164.98923802375793 and batch: 1400, loss is 4.113141512870788 and perplexity is 61.13848352719828
At time: 165.82174015045166 and batch: 1450, loss is 4.046784219741821 and perplexity is 57.21317589885433
At time: 166.65186548233032 and batch: 1500, loss is 4.053812747001648 and perplexity is 57.616716752979144
At time: 167.4828748703003 and batch: 1550, loss is 4.053853554725647 and perplexity is 57.61906800802849
At time: 168.3146688938141 and batch: 1600, loss is 4.143468551635742 and perplexity is 63.021034501113576
At time: 169.14609169960022 and batch: 1650, loss is 4.096474657058716 and perplexity is 60.127941906017654
At time: 169.9721496105194 and batch: 1700, loss is 4.129691395759583 and perplexity is 62.158737524584524
At time: 170.80304336547852 and batch: 1750, loss is 4.11971688747406 and perplexity is 61.541816538693084
At time: 171.6355218887329 and batch: 1800, loss is 4.084230799674987 and perplexity is 59.39623257387841
At time: 172.46838188171387 and batch: 1850, loss is 4.114175343513489 and perplexity is 61.20172304876201
At time: 173.30314946174622 and batch: 1900, loss is 4.1982027053833 and perplexity is 66.5665836999981
At time: 174.13314962387085 and batch: 1950, loss is 4.137900452613831 and perplexity is 62.67110227329563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36049691133721 and perplexity of 78.29603094365729
finished 5 epochs...
Completing Train Step...
At time: 177.2917833328247 and batch: 50, loss is 4.117502193450928 and perplexity is 61.405671061367606
At time: 178.12255597114563 and batch: 100, loss is 4.082532677650452 and perplexity is 59.295456112751104
At time: 178.9519498348236 and batch: 150, loss is 4.058311648368836 and perplexity is 57.87651263859312
At time: 179.77941274642944 and batch: 200, loss is 4.052109026908875 and perplexity is 57.518637568430414
At time: 180.61089706420898 and batch: 250, loss is 4.054165463447571 and perplexity is 57.63704270097537
At time: 181.44080448150635 and batch: 300, loss is 4.063806438446045 and perplexity is 58.19540725306727
At time: 182.2733678817749 and batch: 350, loss is 4.065894412994385 and perplexity is 58.31704472602448
At time: 183.10521292686462 and batch: 400, loss is 4.02559732913971 and perplexity is 56.013757440264044
At time: 183.93535709381104 and batch: 450, loss is 4.066934428215027 and perplexity is 58.37772688987978
At time: 184.76885056495667 and batch: 500, loss is 4.074615774154663 and perplexity is 58.82787305617204
At time: 185.6023724079132 and batch: 550, loss is 4.036880259513855 and perplexity is 56.64933561495286
At time: 186.4320843219757 and batch: 600, loss is 4.027797226905823 and perplexity is 56.13711762027005
At time: 187.26162886619568 and batch: 650, loss is 4.092683620452881 and perplexity is 59.90042620987181
At time: 188.08988189697266 and batch: 700, loss is 4.124663157463074 and perplexity is 61.84697305000223
At time: 188.92405486106873 and batch: 750, loss is 4.093609948158264 and perplexity is 59.95593934194079
At time: 189.75548839569092 and batch: 800, loss is 4.0651363134384155 and perplexity is 58.272851353916685
At time: 190.608891248703 and batch: 850, loss is 4.057879152297974 and perplexity is 57.851486686484826
At time: 191.4411106109619 and batch: 900, loss is 4.034365692138672 and perplexity is 56.50706599203066
At time: 192.27156257629395 and batch: 950, loss is 4.123763203620911 and perplexity is 61.79133866692306
At time: 193.10169076919556 and batch: 1000, loss is 4.103811593055725 and perplexity is 60.57071909511654
At time: 193.93150639533997 and batch: 1050, loss is 4.05003080368042 and perplexity is 57.39922512560147
At time: 194.76379203796387 and batch: 1100, loss is 4.080859236717224 and perplexity is 59.1963116486769
At time: 195.5942726135254 and batch: 1150, loss is 4.049682970046997 and perplexity is 57.37926321648335
At time: 196.42726922035217 and batch: 1200, loss is 4.1268383455276485 and perplexity is 61.98164826647173
At time: 197.25971817970276 and batch: 1250, loss is 4.1126746702194215 and perplexity is 61.10994813673483
At time: 198.09454989433289 and batch: 1300, loss is 4.109206480979919 and perplexity is 60.89837437317887
At time: 198.92503428459167 and batch: 1350, loss is 3.9917195987701417 and perplexity is 54.147922051118705
At time: 199.75515174865723 and batch: 1400, loss is 4.028131294250488 and perplexity is 56.155874330918444
At time: 200.58413791656494 and batch: 1450, loss is 3.959612488746643 and perplexity is 52.43700208309048
At time: 201.41271305084229 and batch: 1500, loss is 3.9658216524124144 and perplexity is 52.76360492711087
At time: 202.241694688797 and batch: 1550, loss is 3.9667102527618407 and perplexity is 52.810511522408085
At time: 203.07042121887207 and batch: 1600, loss is 4.06233705997467 and perplexity is 58.10995896782617
At time: 203.90247321128845 and batch: 1650, loss is 4.011721124649048 and perplexity is 55.24186692855081
At time: 204.73703360557556 and batch: 1700, loss is 4.047856588363647 and perplexity is 57.274562422051176
At time: 205.5678310394287 and batch: 1750, loss is 4.0354264450073245 and perplexity is 56.567037826405176
At time: 206.4007329940796 and batch: 1800, loss is 3.9988647270202637 and perplexity is 54.53620139962642
At time: 207.22916412353516 and batch: 1850, loss is 4.031519923210144 and perplexity is 56.34648853093135
At time: 208.05789637565613 and batch: 1900, loss is 4.113541798591614 and perplexity is 61.16296128786936
At time: 208.8872435092926 and batch: 1950, loss is 4.057610807418823 and perplexity is 57.83596461900803
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355409702034883 and perplexity of 77.89873406970854
finished 6 epochs...
Completing Train Step...
At time: 212.06034564971924 and batch: 50, loss is 4.035070395469665 and perplexity is 56.54690074385253
At time: 212.8920636177063 and batch: 100, loss is 3.999303970336914 and perplexity is 54.56016132333966
At time: 213.72217059135437 and batch: 150, loss is 3.9756761264801024 and perplexity is 53.286132894153816
At time: 214.55735111236572 and batch: 200, loss is 3.973681592941284 and perplexity is 53.179957834999215
At time: 215.39048194885254 and batch: 250, loss is 3.97525438785553 and perplexity is 53.26366481192033
At time: 216.22119235992432 and batch: 300, loss is 3.9841301107406615 and perplexity is 53.73852257622431
At time: 217.05791521072388 and batch: 350, loss is 3.9904491662979127 and perplexity is 54.07917445147927
At time: 217.88949823379517 and batch: 400, loss is 3.948508982658386 and perplexity is 51.85798800316285
At time: 218.71668362617493 and batch: 450, loss is 3.9877595949172973 and perplexity is 53.933920075155676
At time: 219.5474305152893 and batch: 500, loss is 4.000606122016907 and perplexity is 54.63125320522898
At time: 220.38246035575867 and batch: 550, loss is 3.958084135055542 and perplexity is 52.356921009097235
At time: 221.21661520004272 and batch: 600, loss is 3.952823395729065 and perplexity is 52.0822081257309
At time: 222.05221796035767 and batch: 650, loss is 4.0184093189239505 and perplexity is 55.612573563807096
At time: 222.88195729255676 and batch: 700, loss is 4.052753047943115 and perplexity is 57.55569271175044
At time: 223.71212768554688 and batch: 750, loss is 4.016884417533874 and perplexity is 55.52783449885338
At time: 224.54404473304749 and batch: 800, loss is 3.990004091262817 and perplexity is 54.05511051653792
At time: 225.3737030029297 and batch: 850, loss is 3.983931746482849 and perplexity is 53.7278638312695
At time: 226.20246291160583 and batch: 900, loss is 3.9584048271179197 and perplexity is 52.37371415064508
At time: 227.03807163238525 and batch: 950, loss is 4.050699934959412 and perplexity is 57.43764559525842
At time: 227.86798477172852 and batch: 1000, loss is 4.034329528808594 and perplexity is 56.50502254530059
At time: 228.6994128227234 and batch: 1050, loss is 3.9822115087509156 and perplexity is 53.63551858331319
At time: 229.53039741516113 and batch: 1100, loss is 4.007894978523255 and perplexity is 55.03090731194046
At time: 230.3604292869568 and batch: 1150, loss is 3.980657172203064 and perplexity is 53.552215693650545
At time: 231.19518852233887 and batch: 1200, loss is 4.05866623878479 and perplexity is 57.89703873424694
At time: 232.0273048877716 and batch: 1250, loss is 4.043069605827331 and perplexity is 57.00104527517263
At time: 232.85969161987305 and batch: 1300, loss is 4.0437708568573 and perplexity is 57.04103133537548
At time: 233.69270491600037 and batch: 1350, loss is 3.918392186164856 and perplexity is 50.31947535497583
At time: 234.52377462387085 and batch: 1400, loss is 3.9647836208343508 and perplexity is 52.708863055834975
At time: 235.35652470588684 and batch: 1450, loss is 3.8886812257766725 and perplexity is 48.84642662071576
At time: 236.18983602523804 and batch: 1500, loss is 3.898245053291321 and perplexity is 49.31582647135708
At time: 237.0231420993805 and batch: 1550, loss is 3.901148200035095 and perplexity is 49.45920557698272
At time: 237.86084175109863 and batch: 1600, loss is 3.993097243309021 and perplexity is 54.22257004762022
At time: 238.697016954422 and batch: 1650, loss is 3.946417350769043 and perplexity is 51.74963354006699
At time: 239.52888011932373 and batch: 1700, loss is 3.9785619735717774 and perplexity is 53.44013062587025
At time: 240.36240410804749 and batch: 1750, loss is 3.969587688446045 and perplexity is 52.962689208517936
At time: 241.19423818588257 and batch: 1800, loss is 3.9315454292297365 and perplexity is 50.98571162369592
At time: 242.02446913719177 and batch: 1850, loss is 3.9661376094818115 and perplexity is 52.78027859503738
At time: 242.85571098327637 and batch: 1900, loss is 4.0476984024047855 and perplexity is 57.26550310702318
At time: 243.68700170516968 and batch: 1950, loss is 3.990628924369812 and perplexity is 54.088896493390145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350570323855378 and perplexity of 77.52266334402371
finished 7 epochs...
Completing Train Step...
At time: 246.84698176383972 and batch: 50, loss is 3.9656755828857424 and perplexity is 52.75589833517648
At time: 247.6760811805725 and batch: 100, loss is 3.9364776039123535 and perplexity is 51.23780322861849
At time: 248.50770211219788 and batch: 150, loss is 3.9140696048736574 and perplexity is 50.10243475798042
At time: 249.3411786556244 and batch: 200, loss is 3.912992491722107 and perplexity is 50.04849781988528
At time: 250.17412328720093 and batch: 250, loss is 3.909118423461914 and perplexity is 49.85498161254
At time: 251.00565719604492 and batch: 300, loss is 3.9181095647811888 and perplexity is 50.30525600466648
At time: 251.83562350273132 and batch: 350, loss is 3.930113425254822 and perplexity is 50.91275213359464
At time: 252.66646194458008 and batch: 400, loss is 3.884297947883606 and perplexity is 48.63278772014467
At time: 253.51960444450378 and batch: 450, loss is 3.9261404943466185 and perplexity is 50.71088056345299
At time: 254.36020588874817 and batch: 500, loss is 3.9387740898132324 and perplexity is 51.355605334990685
At time: 255.19565796852112 and batch: 550, loss is 3.900157904624939 and perplexity is 49.41025059665681
At time: 256.0295293331146 and batch: 600, loss is 3.8955724000930787 and perplexity is 49.1841983465313
At time: 256.8623707294464 and batch: 650, loss is 3.95764976978302 and perplexity is 52.33418391929331
At time: 257.6952724456787 and batch: 700, loss is 3.9898354625701904 and perplexity is 54.04599604242425
At time: 258.5285475254059 and batch: 750, loss is 3.9606020498275756 and perplexity is 52.48891738199592
At time: 259.36160707473755 and batch: 800, loss is 3.929553360939026 and perplexity is 50.88424570136851
At time: 260.1944410800934 and batch: 850, loss is 3.923117980957031 and perplexity is 50.55783765158872
At time: 261.02607464790344 and batch: 900, loss is 3.9016179037094116 and perplexity is 49.482442204308406
At time: 261.86053562164307 and batch: 950, loss is 3.9938810062408447 and perplexity is 54.2650843464812
At time: 262.68785405158997 and batch: 1000, loss is 3.9728236103057863 and perplexity is 53.134349922816426
At time: 263.51430320739746 and batch: 1050, loss is 3.9265327978134157 and perplexity is 50.73077852046593
At time: 264.3871078491211 and batch: 1100, loss is 3.9516579246520998 and perplexity is 52.02154317702431
At time: 265.2309613227844 and batch: 1150, loss is 3.924987111091614 and perplexity is 50.652425200163385
At time: 266.06597232818604 and batch: 1200, loss is 4.002276844978333 and perplexity is 54.72260318337454
At time: 266.88006043434143 and batch: 1250, loss is 3.987529592514038 and perplexity is 53.921516570393834
At time: 267.71487975120544 and batch: 1300, loss is 3.983565535545349 and perplexity is 53.70819170218025
At time: 268.545592546463 and batch: 1350, loss is 3.8628762197494506 and perplexity is 47.60206867012517
At time: 269.3783712387085 and batch: 1400, loss is 3.9107834482192994 and perplexity is 49.938060536242915
At time: 270.2089717388153 and batch: 1450, loss is 3.834694604873657 and perplexity is 46.279292039344845
At time: 271.0422546863556 and batch: 1500, loss is 3.8417069578170775 and perplexity is 46.604959281413706
At time: 271.87506890296936 and batch: 1550, loss is 3.8472141885757445 and perplexity is 46.8623316005515
At time: 272.7036304473877 and batch: 1600, loss is 3.9404066896438597 and perplexity is 51.439516965981575
At time: 273.5361044406891 and batch: 1650, loss is 3.8902849531173707 and perplexity is 48.92482581924872
At time: 274.36811566352844 and batch: 1700, loss is 3.9218122482299806 and perplexity is 50.49186570859382
At time: 275.19659876823425 and batch: 1750, loss is 3.91712956905365 and perplexity is 50.25598121719336
At time: 276.02811217308044 and batch: 1800, loss is 3.8721011304855346 and perplexity is 48.043225190728634
At time: 276.85815715789795 and batch: 1850, loss is 3.9110973834991456 and perplexity is 49.95374031634164
At time: 277.68990302085876 and batch: 1900, loss is 3.986702103614807 and perplexity is 53.87691556996351
At time: 278.5210862159729 and batch: 1950, loss is 3.9334629011154174 and perplexity is 51.08356908178544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35886344022529 and perplexity of 78.16824103790698
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 281.6706223487854 and batch: 50, loss is 3.943737425804138 and perplexity is 51.61113407220096
At time: 282.5339081287384 and batch: 100, loss is 3.9380167531967163 and perplexity is 51.31672657861832
At time: 283.3679347038269 and batch: 150, loss is 3.9190560960769654 and perplexity is 50.35289404570865
At time: 284.19680285453796 and batch: 200, loss is 3.91199077129364 and perplexity is 49.9983883192504
At time: 285.0280590057373 and batch: 250, loss is 3.9120714902877807 and perplexity is 50.00242430175222
At time: 285.85666966438293 and batch: 300, loss is 3.911933937072754 and perplexity is 49.9955467805538
At time: 286.68725204467773 and batch: 350, loss is 3.921013174057007 and perplexity is 50.451535078489265
At time: 287.51698327064514 and batch: 400, loss is 3.86939649105072 and perplexity is 47.91346115087461
At time: 288.3465886116028 and batch: 450, loss is 3.9000936126708985 and perplexity is 49.40707401721166
At time: 289.1787886619568 and batch: 500, loss is 3.9078968715667726 and perplexity is 49.794118346656155
At time: 290.00688552856445 and batch: 550, loss is 3.8678086519241335 and perplexity is 47.83744265111489
At time: 290.8390498161316 and batch: 600, loss is 3.847406029701233 and perplexity is 46.871322585381506
At time: 291.6744751930237 and batch: 650, loss is 3.898824291229248 and perplexity is 49.344400343726065
At time: 292.50729060173035 and batch: 700, loss is 3.9338291025161745 and perplexity is 51.10227938199884
At time: 293.3424620628357 and batch: 750, loss is 3.891124339103699 and perplexity is 48.9659098727021
At time: 294.1808936595917 and batch: 800, loss is 3.8571028900146485 and perplexity is 47.32803802741295
At time: 295.01615500450134 and batch: 850, loss is 3.8400839710235597 and perplexity is 46.52938139553276
At time: 295.89273262023926 and batch: 900, loss is 3.814546837806702 and perplexity is 45.356198010990276
At time: 296.7262153625488 and batch: 950, loss is 3.90694607257843 and perplexity is 49.74679664958257
At time: 297.55775237083435 and batch: 1000, loss is 3.877497601509094 and perplexity is 48.30318987841237
At time: 298.39073061943054 and batch: 1050, loss is 3.8266400718688964 and perplexity is 45.90803112795174
At time: 299.22222900390625 and batch: 1100, loss is 3.8393308448791506 and perplexity is 46.4943520943176
At time: 300.057914018631 and batch: 1150, loss is 3.810177373886108 and perplexity is 45.15844808541209
At time: 300.8878843784332 and batch: 1200, loss is 3.8781419372558594 and perplexity is 48.33432337947052
At time: 301.7263729572296 and batch: 1250, loss is 3.854859070777893 and perplexity is 47.221961518010836
At time: 302.55424070358276 and batch: 1300, loss is 3.854176850318909 and perplexity is 47.18975671638623
At time: 303.39267230033875 and batch: 1350, loss is 3.725858759880066 and perplexity is 41.50686187193174
At time: 304.22532987594604 and batch: 1400, loss is 3.7583654022216795 and perplexity is 42.8782799229879
At time: 305.06373739242554 and batch: 1450, loss is 3.6761929512023928 and perplexity is 39.495745261330846
At time: 305.89713501930237 and batch: 1500, loss is 3.6755416631698608 and perplexity is 39.4700305298636
At time: 306.72738003730774 and batch: 1550, loss is 3.6738689231872557 and perplexity is 39.40406262064316
At time: 307.559366941452 and batch: 1600, loss is 3.7690098237991334 and perplexity is 43.33713218701044
At time: 308.3895766735077 and batch: 1650, loss is 3.7079143953323364 and perplexity is 40.768690427525705
At time: 309.23046946525574 and batch: 1700, loss is 3.723124632835388 and perplexity is 41.39353183830235
At time: 310.06276774406433 and batch: 1750, loss is 3.7088024950027467 and perplexity is 40.80491317037964
At time: 310.89057636260986 and batch: 1800, loss is 3.6629930257797243 and perplexity is 38.977830110075665
At time: 311.7234945297241 and batch: 1850, loss is 3.6883358335494996 and perplexity is 39.97826108681802
At time: 312.55880522727966 and batch: 1900, loss is 3.759566140174866 and perplexity is 42.92979642377806
At time: 313.3902425765991 and batch: 1950, loss is 3.704777297973633 and perplexity is 40.64099547693834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2799427121184594 and perplexity of 72.23630162409653
finished 9 epochs...
Completing Train Step...
At time: 316.549435377121 and batch: 50, loss is 3.8585514497756956 and perplexity is 47.396645197665165
At time: 317.41499161720276 and batch: 100, loss is 3.8381410598754884 and perplexity is 46.439066706825045
At time: 318.2514488697052 and batch: 150, loss is 3.8122421169281004 and perplexity is 45.25178500209904
At time: 319.08311772346497 and batch: 200, loss is 3.8043829870223997 and perplexity is 44.89753920054721
At time: 319.91282510757446 and batch: 250, loss is 3.80175172328949 and perplexity is 44.77955722287257
At time: 320.7413034439087 and batch: 300, loss is 3.8066816997528075 and perplexity is 45.00086445751503
At time: 321.5713937282562 and batch: 350, loss is 3.818949751853943 and perplexity is 45.55633772800825
At time: 322.39903140068054 and batch: 400, loss is 3.7702634382247924 and perplexity is 43.39149430853725
At time: 323.23226404190063 and batch: 450, loss is 3.8103361034393313 and perplexity is 45.165616634616185
At time: 324.06131052970886 and batch: 500, loss is 3.8194086074829103 and perplexity is 45.577246306652526
At time: 324.8944935798645 and batch: 550, loss is 3.7805666065216066 and perplexity is 43.840875225316566
At time: 325.7216124534607 and batch: 600, loss is 3.763437719345093 and perplexity is 43.096324685058896
At time: 326.5495095252991 and batch: 650, loss is 3.816718273162842 and perplexity is 45.45479307062994
At time: 327.38440203666687 and batch: 700, loss is 3.8530150508880614 and perplexity is 47.13496351940705
At time: 328.21502685546875 and batch: 750, loss is 3.815000615119934 and perplexity is 45.376784295103235
At time: 329.04085516929626 and batch: 800, loss is 3.7827489376068115 and perplexity is 43.936655003704075
At time: 329.8710253238678 and batch: 850, loss is 3.7669485425949096 and perplexity is 43.24789417490372
At time: 330.70102763175964 and batch: 900, loss is 3.742688050270081 and perplexity is 42.21130390711723
At time: 331.530668258667 and batch: 950, loss is 3.839214687347412 and perplexity is 46.4889517387906
At time: 332.3638861179352 and batch: 1000, loss is 3.8128668165206907 and perplexity is 45.28006260533784
At time: 333.19151759147644 and batch: 1050, loss is 3.766928038597107 and perplexity is 43.24700742926753
At time: 334.02193665504456 and batch: 1100, loss is 3.7776485586166384 and perplexity is 43.713131922396634
At time: 334.8527727127075 and batch: 1150, loss is 3.7525946044921876 and perplexity is 42.63155063967447
At time: 335.6804838180542 and batch: 1200, loss is 3.8223231506347655 and perplexity is 45.710276925325594
At time: 336.5106716156006 and batch: 1250, loss is 3.801549482345581 and perplexity is 44.77050187866353
At time: 337.3424644470215 and batch: 1300, loss is 3.8032767581939697 and perplexity is 44.84789970973804
At time: 338.1770923137665 and batch: 1350, loss is 3.678213186264038 and perplexity is 39.575616602970754
At time: 339.00574231147766 and batch: 1400, loss is 3.713279118537903 and perplexity is 40.987990884287505
At time: 339.84106731414795 and batch: 1450, loss is 3.6337371969223025 and perplexity is 37.854020528440806
At time: 340.6723666191101 and batch: 1500, loss is 3.6347679805755617 and perplexity is 37.89305995115438
At time: 341.51599740982056 and batch: 1550, loss is 3.637605838775635 and perplexity is 38.00074781122955
At time: 342.36439752578735 and batch: 1600, loss is 3.735938696861267 and perplexity is 41.92736418185384
At time: 343.2000877857208 and batch: 1650, loss is 3.6758697175979616 and perplexity is 39.48298097226504
At time: 344.03584265708923 and batch: 1700, loss is 3.695863995552063 and perplexity is 40.28035960942978
At time: 344.8665101528168 and batch: 1750, loss is 3.684769535064697 and perplexity is 39.835940604381214
At time: 345.7021825313568 and batch: 1800, loss is 3.641250071525574 and perplexity is 38.13948402090515
At time: 346.5445828437805 and batch: 1850, loss is 3.6716605949401857 and perplexity is 39.31714152658642
At time: 347.38582825660706 and batch: 1900, loss is 3.7460416316986085 and perplexity is 42.35310058242945
At time: 348.225204706192 and batch: 1950, loss is 3.692396025657654 and perplexity is 40.14091047742481
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283060047238372 and perplexity of 72.46183773726266
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 351.4166567325592 and batch: 50, loss is 3.835381169319153 and perplexity is 46.31107666567041
At time: 352.29169511795044 and batch: 100, loss is 3.8472477436065673 and perplexity is 46.86390409391517
At time: 353.13136863708496 and batch: 150, loss is 3.829071035385132 and perplexity is 46.01976763538615
At time: 353.985214471817 and batch: 200, loss is 3.8310844707489013 and perplexity is 46.11251880588521
At time: 354.83560609817505 and batch: 250, loss is 3.8286970472335815 and perplexity is 46.00256000547883
At time: 355.676100730896 and batch: 300, loss is 3.8323510122299194 and perplexity is 46.17095922454213
At time: 356.5165090560913 and batch: 350, loss is 3.8505371379852296 and perplexity is 47.01831177125107
At time: 357.353723526001 and batch: 400, loss is 3.8040193462371827 and perplexity is 44.88121559228275
At time: 358.1831798553467 and batch: 450, loss is 3.846523151397705 and perplexity is 46.82995917372938
At time: 359.01786279678345 and batch: 500, loss is 3.848151459693909 and perplexity is 46.90627490066662
At time: 359.92120695114136 and batch: 550, loss is 3.815061984062195 and perplexity is 45.37956910580819
At time: 360.7541456222534 and batch: 600, loss is 3.7831411361694336 and perplexity is 43.95389027624658
At time: 361.59226989746094 and batch: 650, loss is 3.825082793235779 and perplexity is 45.83659516927044
At time: 362.4296832084656 and batch: 700, loss is 3.855346665382385 and perplexity is 47.244992306048246
At time: 363.27346777915955 and batch: 750, loss is 3.819564142227173 and perplexity is 45.58433570331048
At time: 364.10851788520813 and batch: 800, loss is 3.793078727722168 and perplexity is 44.39286364137973
At time: 364.94184923171997 and batch: 850, loss is 3.7765673780441285 and perplexity is 43.66589567345732
At time: 365.7764632701874 and batch: 900, loss is 3.7447633361816406 and perplexity is 42.29899539240367
At time: 366.6146695613861 and batch: 950, loss is 3.837995090484619 and perplexity is 46.432288519261306
At time: 367.44381403923035 and batch: 1000, loss is 3.8021888256073 and perplexity is 44.799134749504624
At time: 368.27609491348267 and batch: 1050, loss is 3.754724941253662 and perplexity is 42.72246700605552
At time: 369.11292791366577 and batch: 1100, loss is 3.7618450498580933 and perplexity is 43.02774111370927
At time: 369.9426655769348 and batch: 1150, loss is 3.7438253688812257 and perplexity is 42.259338919030256
At time: 370.77396059036255 and batch: 1200, loss is 3.806111421585083 and perplexity is 44.97520876312267
At time: 371.6108064651489 and batch: 1250, loss is 3.7861557054519652 and perplexity is 44.08659224286177
At time: 372.4440948963165 and batch: 1300, loss is 3.785418539047241 and perplexity is 44.0541050638612
At time: 373.27640175819397 and batch: 1350, loss is 3.656805701255798 and perplexity is 38.73740618338668
At time: 374.1120755672455 and batch: 1400, loss is 3.684346604347229 and perplexity is 39.819096323673314
At time: 374.9444577693939 and batch: 1450, loss is 3.5969259119033814 and perplexity is 36.485900996736206
At time: 375.7774724960327 and batch: 1500, loss is 3.597796368598938 and perplexity is 36.51767422015356
At time: 376.6075963973999 and batch: 1550, loss is 3.599158205986023 and perplexity is 36.567439232431916
At time: 377.43843173980713 and batch: 1600, loss is 3.6967104721069335 and perplexity is 40.31447042442673
At time: 378.2710220813751 and batch: 1650, loss is 3.634458107948303 and perplexity is 37.88131974819016
At time: 379.10338854789734 and batch: 1700, loss is 3.652091636657715 and perplexity is 38.555225291896186
At time: 379.93358063697815 and batch: 1750, loss is 3.6354916524887084 and perplexity is 37.92049201905556
At time: 380.7663359642029 and batch: 1800, loss is 3.5913936424255373 and perplexity is 36.28460847591127
At time: 381.5959007740021 and batch: 1850, loss is 3.614407444000244 and perplexity is 37.12933819377001
At time: 382.4274504184723 and batch: 1900, loss is 3.6900465440750123 and perplexity is 40.046710851023626
At time: 383.2634618282318 and batch: 1950, loss is 3.6345152854919434 and perplexity is 37.88348577092655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2542628088662795 and perplexity of 70.40489618769314
finished 11 epochs...
Completing Train Step...
At time: 386.5347967147827 and batch: 50, loss is 3.82370698928833 and perplexity is 45.77357636140161
At time: 387.3743669986725 and batch: 100, loss is 3.8163102102279662 and perplexity is 45.436248438311246
At time: 388.21126794815063 and batch: 150, loss is 3.7872617197036744 and perplexity is 44.135379616983876
At time: 389.05434465408325 and batch: 200, loss is 3.783792243003845 and perplexity is 43.98251827353538
At time: 389.88983511924744 and batch: 250, loss is 3.781719193458557 and perplexity is 43.89143477694793
At time: 390.73112058639526 and batch: 300, loss is 3.7835764360427855 and perplexity is 43.97302756404444
At time: 391.5692095756531 and batch: 350, loss is 3.8027899169921877 and perplexity is 44.8260712182816
At time: 392.39791202545166 and batch: 400, loss is 3.75649827003479 and perplexity is 42.79829520068675
At time: 393.24130725860596 and batch: 450, loss is 3.8026393842697144 and perplexity is 44.819323935599485
At time: 394.1136748790741 and batch: 500, loss is 3.803860778808594 and perplexity is 44.87409945754285
At time: 394.948721408844 and batch: 550, loss is 3.773000726699829 and perplexity is 43.51043205501976
At time: 395.7787923812866 and batch: 600, loss is 3.7450647926330567 and perplexity is 42.31174861962786
At time: 396.61136269569397 and batch: 650, loss is 3.7891142320632936 and perplexity is 44.21721673195023
At time: 397.4431207180023 and batch: 700, loss is 3.8208448839187623 and perplexity is 45.64275486447136
At time: 398.27203345298767 and batch: 750, loss is 3.7875173044204713 and perplexity is 44.14666138714661
At time: 399.1083285808563 and batch: 800, loss is 3.7613758134841917 and perplexity is 43.007555668734774
At time: 399.9419493675232 and batch: 850, loss is 3.745993094444275 and perplexity is 42.351044929102954
At time: 400.781964302063 and batch: 900, loss is 3.713897361755371 and perplexity is 41.013339266574675
At time: 401.6661546230316 and batch: 950, loss is 3.8086283111572268 and perplexity is 45.08854896962384
At time: 402.4964966773987 and batch: 1000, loss is 3.775220489501953 and perplexity is 43.60712216845628
At time: 403.3279721736908 and batch: 1050, loss is 3.7297606801986696 and perplexity is 41.66913472161258
At time: 404.1624665260315 and batch: 1100, loss is 3.737750978469849 and perplexity is 42.003417266845034
At time: 404.9934597015381 and batch: 1150, loss is 3.7203353595733644 and perplexity is 41.27823483889518
At time: 405.8306813240051 and batch: 1200, loss is 3.785672564506531 and perplexity is 44.065297349636225
At time: 406.664737701416 and batch: 1250, loss is 3.7664669799804686 and perplexity is 43.22707261975944
At time: 407.4966928958893 and batch: 1300, loss is 3.7677952909469603 and perplexity is 43.284529766400425
At time: 408.3297667503357 and batch: 1350, loss is 3.640682272911072 and perplexity is 38.11783462155138
At time: 409.1617970466614 and batch: 1400, loss is 3.670021948814392 and perplexity is 39.25276740255565
At time: 409.9955279827118 and batch: 1450, loss is 3.5847999382019045 and perplexity is 36.04614554075134
At time: 410.8269190788269 and batch: 1500, loss is 3.5877676677703856 and perplexity is 36.15327964659802
At time: 411.6583001613617 and batch: 1550, loss is 3.592496385574341 and perplexity is 36.32464314923898
At time: 412.48992800712585 and batch: 1600, loss is 3.691474742889404 and perplexity is 40.10394637810845
At time: 413.31876850128174 and batch: 1650, loss is 3.6311366081237795 and perplexity is 37.755705680330955
At time: 414.1513431072235 and batch: 1700, loss is 3.6506163692474365 and perplexity is 38.49838795996732
At time: 414.9863369464874 and batch: 1750, loss is 3.635368432998657 and perplexity is 37.91581976322888
At time: 415.8211064338684 and batch: 1800, loss is 3.593023729324341 and perplexity is 36.34380377444865
At time: 416.6548042297363 and batch: 1850, loss is 3.617508263587952 and perplexity is 37.244648258380415
At time: 417.4852964878082 and batch: 1900, loss is 3.694379062652588 and perplexity is 40.22059036588384
At time: 418.3157272338867 and batch: 1950, loss is 3.63846962928772 and perplexity is 38.03358667754975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253854015261628 and perplexity of 70.37612099835287
finished 12 epochs...
Completing Train Step...
At time: 421.4800019264221 and batch: 50, loss is 3.806435217857361 and perplexity is 44.98977392601057
At time: 422.3145229816437 and batch: 100, loss is 3.7973904275894164 and perplexity is 44.584685587803364
At time: 423.1918103694916 and batch: 150, loss is 3.767006058692932 and perplexity is 43.25038169655994
At time: 424.0246138572693 and batch: 200, loss is 3.7629747772216797 and perplexity is 43.07637819838857
At time: 424.8647997379303 and batch: 250, loss is 3.7600645303726195 and perplexity is 42.951197546119026
At time: 425.6931822299957 and batch: 300, loss is 3.7625096035003662 and perplexity is 43.05634485909406
At time: 426.5245761871338 and batch: 350, loss is 3.781590881347656 and perplexity is 43.88580333560003
At time: 427.36682891845703 and batch: 400, loss is 3.735684242248535 and perplexity is 41.91669692786163
At time: 428.19788432121277 and batch: 450, loss is 3.7832533740997314 and perplexity is 43.95882384678142
At time: 429.0263841152191 and batch: 500, loss is 3.7833585929870606 and perplexity is 43.96344938865779
At time: 429.855589389801 and batch: 550, loss is 3.753546643257141 and perplexity is 42.6721568547719
At time: 430.68688559532166 and batch: 600, loss is 3.726315641403198 and perplexity is 41.525829922950294
At time: 431.5214967727661 and batch: 650, loss is 3.7712934732437136 and perplexity is 43.436212093687004
At time: 432.35109758377075 and batch: 700, loss is 3.803088412284851 and perplexity is 44.839453586716466
At time: 433.18383026123047 and batch: 750, loss is 3.770760989189148 and perplexity is 43.41308916019943
At time: 434.0140435695648 and batch: 800, loss is 3.7448506784439086 and perplexity is 42.30269004370016
At time: 434.84685230255127 and batch: 850, loss is 3.7300490617752073 and perplexity is 41.68115306522771
At time: 435.6807336807251 and batch: 900, loss is 3.698121190071106 and perplexity is 40.371382906362314
At time: 436.514431476593 and batch: 950, loss is 3.7932688856124877 and perplexity is 44.4013060973494
At time: 437.3492019176483 and batch: 1000, loss is 3.760487189292908 and perplexity is 42.96935508985258
At time: 438.18207931518555 and batch: 1050, loss is 3.7160700607299804 and perplexity is 41.102545781103274
At time: 439.01243329048157 and batch: 1100, loss is 3.7241720962524414 and perplexity is 41.436912764605864
At time: 439.84441471099854 and batch: 1150, loss is 3.7069786739349366 and perplexity is 40.73056013399663
At time: 440.67675852775574 and batch: 1200, loss is 3.7736044120788574 and perplexity is 43.53670659666696
At time: 441.5088801383972 and batch: 1250, loss is 3.7544938564300536 and perplexity is 42.71259563290949
At time: 442.34074687957764 and batch: 1300, loss is 3.7568060302734376 and perplexity is 42.81146884128883
At time: 443.17395091056824 and batch: 1350, loss is 3.6302967405319215 and perplexity is 37.7240091990092
At time: 444.00380086898804 and batch: 1400, loss is 3.6604815340042114 and perplexity is 38.88006043558448
At time: 444.8338899612427 and batch: 1450, loss is 3.575842318534851 and perplexity is 35.724699722595375
At time: 445.66201615333557 and batch: 1500, loss is 3.579868001937866 and perplexity is 35.86880592169643
At time: 446.49084186553955 and batch: 1550, loss is 3.585865845680237 and perplexity is 36.084587881197656
At time: 447.32503962516785 and batch: 1600, loss is 3.6854552125930784 and perplexity is 39.86326458032317
At time: 448.16373443603516 and batch: 1650, loss is 3.625892448425293 and perplexity is 37.55822698768993
At time: 448.99275398254395 and batch: 1700, loss is 3.646039118766785 and perplexity is 38.322573874686306
At time: 449.82642555236816 and batch: 1750, loss is 3.6316108179092406 and perplexity is 37.77361405124833
At time: 450.6610174179077 and batch: 1800, loss is 3.5900923156738282 and perplexity is 36.23742105401264
At time: 451.4955883026123 and batch: 1850, loss is 3.615141954421997 and perplexity is 37.15662009782098
At time: 452.32788920402527 and batch: 1900, loss is 3.692555251121521 and perplexity is 40.147302441383836
At time: 453.1580128669739 and batch: 1950, loss is 3.6363325786590575 and perplexity is 37.95239376481338
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.254952080305233 and perplexity of 70.45344100015222
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 456.3734645843506 and batch: 50, loss is 3.801962208747864 and perplexity is 44.78898366052963
At time: 457.21365237236023 and batch: 100, loss is 3.809802737236023 and perplexity is 45.14153324435585
At time: 458.0444896221161 and batch: 150, loss is 3.7850423669815063 and perplexity is 44.03753625671182
At time: 458.8749837875366 and batch: 200, loss is 3.7874179697036743 and perplexity is 44.142276308839044
At time: 459.704389333725 and batch: 250, loss is 3.7847932529449464 and perplexity is 44.026567254617675
At time: 460.535418510437 and batch: 300, loss is 3.7852504301071166 and perplexity is 44.04669979741397
At time: 461.3685965538025 and batch: 350, loss is 3.809139380455017 and perplexity is 45.111598232067614
At time: 462.20685029029846 and batch: 400, loss is 3.7746336221694947 and perplexity is 43.58153808095997
At time: 463.03858494758606 and batch: 450, loss is 3.832069072723389 and perplexity is 46.157943641972
At time: 463.8732764720917 and batch: 500, loss is 3.8289595365524294 and perplexity is 46.01463677106157
At time: 464.753555059433 and batch: 550, loss is 3.807789626121521 and perplexity is 45.05074973136471
At time: 465.5867714881897 and batch: 600, loss is 3.7699255561828613 and perplexity is 43.376835578438126
At time: 466.41669845581055 and batch: 650, loss is 3.807489676475525 and perplexity is 45.03723880133157
At time: 467.25052785873413 and batch: 700, loss is 3.8315862607955933 and perplexity is 46.13566341523156
At time: 468.09202694892883 and batch: 750, loss is 3.7934772872924807 and perplexity is 44.410560368403296
At time: 468.92420959472656 and batch: 800, loss is 3.76613676071167 and perplexity is 43.21280056403023
At time: 469.75770926475525 and batch: 850, loss is 3.751213631629944 and perplexity is 42.57271825747719
At time: 470.58770513534546 and batch: 900, loss is 3.715234160423279 and perplexity is 41.068202506255346
At time: 471.42573833465576 and batch: 950, loss is 3.812110548019409 and perplexity is 45.24583166577555
At time: 472.26297545433044 and batch: 1000, loss is 3.7743237352371217 and perplexity is 43.56803482416544
At time: 473.0988121032715 and batch: 1050, loss is 3.7315379762649536 and perplexity is 41.74325896168706
At time: 473.9326775074005 and batch: 1100, loss is 3.733431115150452 and perplexity is 41.822359599056526
At time: 474.7620587348938 and batch: 1150, loss is 3.717607021331787 and perplexity is 41.16576734668511
At time: 475.59773898124695 and batch: 1200, loss is 3.7818830585479737 and perplexity is 43.898627640145776
At time: 476.4308717250824 and batch: 1250, loss is 3.7592989730834963 and perplexity is 42.91832852692496
At time: 477.2613613605499 and batch: 1300, loss is 3.760772786140442 and perplexity is 42.98162875478339
At time: 478.09644961357117 and batch: 1350, loss is 3.631120138168335 and perplexity is 37.7550838506614
At time: 478.92974877357483 and batch: 1400, loss is 3.6604084873199465 and perplexity is 38.877220479811584
At time: 479.7596182823181 and batch: 1450, loss is 3.5735860538482664 and perplexity is 35.64418620822812
At time: 480.59132266044617 and batch: 1500, loss is 3.573785815238953 and perplexity is 35.65130725166605
At time: 481.42622351646423 and batch: 1550, loss is 3.5810757064819336 and perplexity is 35.91215101036019
At time: 482.2586042881012 and batch: 1600, loss is 3.6779545164108276 and perplexity is 39.56538090792329
At time: 483.0893907546997 and batch: 1650, loss is 3.6162719345092773 and perplexity is 37.198630069387775
At time: 483.91859698295593 and batch: 1700, loss is 3.63381685256958 and perplexity is 37.85703593504355
At time: 484.7559280395508 and batch: 1750, loss is 3.6206477785110476 and perplexity is 37.36176213157443
At time: 485.58919167518616 and batch: 1800, loss is 3.577685861587524 and perplexity is 35.79062048979386
At time: 486.42226004600525 and batch: 1850, loss is 3.600344433784485 and perplexity is 36.61084228323119
At time: 487.2553312778473 and batch: 1900, loss is 3.6810086870193484 and perplexity is 39.68640505152269
At time: 488.08686780929565 and batch: 1950, loss is 3.625861792564392 and perplexity is 37.5570756255558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242163369821948 and perplexity of 69.55816922825557
finished 14 epochs...
Completing Train Step...
At time: 491.2477626800537 and batch: 50, loss is 3.8062912368774415 and perplexity is 44.98329672058273
At time: 492.1043622493744 and batch: 100, loss is 3.8009004831314086 and perplexity is 44.741455284754025
At time: 492.93417024612427 and batch: 150, loss is 3.7706007194519042 and perplexity is 43.40613191333974
At time: 493.7659709453583 and batch: 200, loss is 3.7681984806060793 and perplexity is 43.301985159882676
At time: 494.5974383354187 and batch: 250, loss is 3.7644845724105833 and perplexity is 43.14146382756933
At time: 495.4340171813965 and batch: 300, loss is 3.7612012672424315 and perplexity is 43.00004951662988
At time: 496.26730942726135 and batch: 350, loss is 3.782192726135254 and perplexity is 43.912223727277116
At time: 497.10489320755005 and batch: 400, loss is 3.7459630489349367 and perplexity is 42.3497724895027
At time: 497.93755555152893 and batch: 450, loss is 3.8028017854690552 and perplexity is 44.82660323862804
At time: 498.7738790512085 and batch: 500, loss is 3.801844220161438 and perplexity is 44.78369938340839
At time: 499.60193395614624 and batch: 550, loss is 3.779827790260315 and perplexity is 43.80849683610389
At time: 500.43185806274414 and batch: 600, loss is 3.747173647880554 and perplexity is 42.40107212480265
At time: 501.2683982849121 and batch: 650, loss is 3.786056594848633 and perplexity is 44.082223010627914
At time: 502.1009304523468 and batch: 700, loss is 3.812267699241638 and perplexity is 45.25294266225886
At time: 502.93257093429565 and batch: 750, loss is 3.7774162912368774 and perplexity is 43.70297996681357
At time: 503.76893377304077 and batch: 800, loss is 3.751044306755066 and perplexity is 42.56551024754995
At time: 504.6012167930603 and batch: 850, loss is 3.737335777282715 and perplexity is 41.98598101815822
At time: 505.43393087387085 and batch: 900, loss is 3.7020457410812377 and perplexity is 40.53013376709531
At time: 506.2654287815094 and batch: 950, loss is 3.7996247005462647 and perplexity is 44.68441131085914
At time: 507.1226191520691 and batch: 1000, loss is 3.7622924709320067 and perplexity is 43.04699693925628
At time: 507.95351934432983 and batch: 1050, loss is 3.720273151397705 and perplexity is 41.2756670750802
At time: 508.78795766830444 and batch: 1100, loss is 3.723700475692749 and perplexity is 41.41737487221393
At time: 509.61975026130676 and batch: 1150, loss is 3.7088642215728758 and perplexity is 40.80743199545248
At time: 510.4549217224121 and batch: 1200, loss is 3.772961959838867 and perplexity is 43.508745324844725
At time: 511.2883999347687 and batch: 1250, loss is 3.752261691093445 and perplexity is 42.61736038745096
At time: 512.1242582798004 and batch: 1300, loss is 3.7548677349090576 and perplexity is 42.728567938863705
At time: 512.9600992202759 and batch: 1350, loss is 3.6260753059387207 and perplexity is 37.565095419638716
At time: 513.7916610240936 and batch: 1400, loss is 3.6570066356658937 and perplexity is 38.74519064330351
At time: 514.6200878620148 and batch: 1450, loss is 3.571313753128052 and perplexity is 35.56328385028941
At time: 515.450211763382 and batch: 1500, loss is 3.5737220811843873 and perplexity is 35.64903512171114
At time: 516.2855653762817 and batch: 1550, loss is 3.5823972749710085 and perplexity is 35.959642752393066
At time: 517.1158277988434 and batch: 1600, loss is 3.6803867864608764 and perplexity is 39.66173172702976
At time: 517.953661441803 and batch: 1650, loss is 3.6196535634994507 and perplexity is 37.32463496605439
At time: 518.7896504402161 and batch: 1700, loss is 3.637964606285095 and perplexity is 38.01438369078843
At time: 519.6198601722717 and batch: 1750, loss is 3.6259261703491212 and perplexity is 37.55949354471478
At time: 520.4500257968903 and batch: 1800, loss is 3.5843143844604493 and perplexity is 36.02864744839488
At time: 521.2813510894775 and batch: 1850, loss is 3.6063710975646974 and perplexity is 36.832149723313414
At time: 522.1263456344604 and batch: 1900, loss is 3.6873572301864623 and perplexity is 39.93915736270873
At time: 522.981995344162 and batch: 1950, loss is 3.631088366508484 and perplexity is 37.75388432803516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240808957122093 and perplexity of 69.46402253160711
finished 15 epochs...
Completing Train Step...
At time: 526.1438593864441 and batch: 50, loss is 3.802353444099426 and perplexity is 44.80651012256038
At time: 527.009251832962 and batch: 100, loss is 3.794896306991577 and perplexity is 44.47362456249858
At time: 527.8393681049347 and batch: 150, loss is 3.7634984731674193 and perplexity is 43.09894303104819
At time: 528.6944360733032 and batch: 200, loss is 3.75991304397583 and perplexity is 42.9446915167649
At time: 529.5271611213684 and batch: 250, loss is 3.755778775215149 and perplexity is 42.76751312410062
At time: 530.3585500717163 and batch: 300, loss is 3.752068839073181 and perplexity is 42.60914233586132
At time: 531.1896040439606 and batch: 350, loss is 3.772610421180725 and perplexity is 43.49345300697373
At time: 532.0187854766846 and batch: 400, loss is 3.735911626815796 and perplexity is 41.926229221560746
At time: 532.8500733375549 and batch: 450, loss is 3.793033037185669 and perplexity is 44.39083535396036
At time: 533.6821701526642 and batch: 500, loss is 3.791796989440918 and perplexity is 44.336000058536605
At time: 534.511960029602 and batch: 550, loss is 3.7698988056182863 and perplexity is 43.37567523911686
At time: 535.3488590717316 and batch: 600, loss is 3.7387095308303833 and perplexity is 42.04369904462895
At time: 536.1810164451599 and batch: 650, loss is 3.7776909017562867 and perplexity is 43.71498291283419
At time: 537.0146250724792 and batch: 700, loss is 3.80439254283905 and perplexity is 44.89796823524975
At time: 537.8469545841217 and batch: 750, loss is 3.7702676343917845 and perplexity is 43.39167638687542
At time: 538.6809914112091 and batch: 800, loss is 3.7440800619125367 and perplexity is 42.27010344892793
At time: 539.5081667900085 and batch: 850, loss is 3.7307024431228637 and perplexity is 41.708395652119236
At time: 540.3413379192352 and batch: 900, loss is 3.6956967306137085 and perplexity is 40.273622681004476
At time: 541.1710216999054 and batch: 950, loss is 3.7935340785980225 and perplexity is 44.41308257372545
At time: 542.0014731884003 and batch: 1000, loss is 3.756526403427124 and perplexity is 42.799499278854185
At time: 542.8330528736115 and batch: 1050, loss is 3.714980568885803 and perplexity is 41.0577892780495
At time: 543.6701710224152 and batch: 1100, loss is 3.718960247039795 and perplexity is 41.22151163014057
At time: 544.501268863678 and batch: 1150, loss is 3.7045155000686645 and perplexity is 40.6303571420743
At time: 545.335720539093 and batch: 1200, loss is 3.768642783164978 and perplexity is 43.321228617336736
At time: 546.1677756309509 and batch: 1250, loss is 3.7486785411834718 and perplexity is 42.46492925130935
At time: 547.0026843547821 and batch: 1300, loss is 3.75171555519104 and perplexity is 42.59409187134201
At time: 547.8354046344757 and batch: 1350, loss is 3.6230951261520388 and perplexity is 37.4533113326565
At time: 548.6727623939514 and batch: 1400, loss is 3.6547572946548463 and perplexity is 38.658137439883035
At time: 549.5072441101074 and batch: 1450, loss is 3.5694346809387207 and perplexity is 35.496520618755454
At time: 550.3386740684509 and batch: 1500, loss is 3.5727436447143557 and perplexity is 35.61417186414928
At time: 551.170324087143 and batch: 1550, loss is 3.582109475135803 and perplexity is 35.949295062238065
At time: 552.0021522045135 and batch: 1600, loss is 3.680494465827942 and perplexity is 39.666002707142944
At time: 552.8351712226868 and batch: 1650, loss is 3.6199370193481446 and perplexity is 37.33521635174287
At time: 553.6700901985168 and batch: 1700, loss is 3.6384556341171264 and perplexity is 38.03305439474062
At time: 554.5142185688019 and batch: 1750, loss is 3.626784949302673 and perplexity is 37.59176270133012
At time: 555.3450393676758 and batch: 1800, loss is 3.5856440448760987 and perplexity is 36.0765851781244
At time: 556.1790311336517 and batch: 1850, loss is 3.6075746631622314 and perplexity is 36.87650631928561
At time: 557.0096728801727 and batch: 1900, loss is 3.688731560707092 and perplexity is 39.99408470115386
At time: 557.8444066047668 and batch: 1950, loss is 3.6319658660888674 and perplexity is 37.787027885292915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240663040515988 and perplexity of 69.45388731665899
finished 16 epochs...
Completing Train Step...
At time: 561.0687055587769 and batch: 50, loss is 3.797806987762451 and perplexity is 44.60326166090401
At time: 561.9340784549713 and batch: 100, loss is 3.78963565826416 and perplexity is 44.24027875933381
At time: 562.7688572406769 and batch: 150, loss is 3.757727370262146 and perplexity is 42.85093093571896
At time: 563.6049304008484 and batch: 200, loss is 3.7536886405944823 and perplexity is 42.6782166176488
At time: 564.4361600875854 and batch: 250, loss is 3.749353065490723 and perplexity is 42.493582540878805
At time: 565.2655594348907 and batch: 300, loss is 3.745585732460022 and perplexity is 42.333796236874726
At time: 566.0978000164032 and batch: 350, loss is 3.7660027503967286 and perplexity is 43.207009991024066
At time: 566.9314162731171 and batch: 400, loss is 3.7291990327835083 and perplexity is 41.64573793079276
At time: 567.7680289745331 and batch: 450, loss is 3.7865967893600465 and perplexity is 44.10604241852664
At time: 568.6029498577118 and batch: 500, loss is 3.785043954849243 and perplexity is 44.03760618255037
At time: 569.436311006546 and batch: 550, loss is 3.7633455896377566 and perplexity is 43.09235441617105
At time: 570.2720980644226 and batch: 600, loss is 3.732866816520691 and perplexity is 41.79876595639762
At time: 571.1516053676605 and batch: 650, loss is 3.7718863344192504 and perplexity is 43.461971372533405
At time: 571.9859802722931 and batch: 700, loss is 3.798851613998413 and perplexity is 44.6498797432411
At time: 572.8158354759216 and batch: 750, loss is 3.765099468231201 and perplexity is 43.167999490870386
At time: 573.6469759941101 and batch: 800, loss is 3.73891667842865 and perplexity is 42.05240919802082
At time: 574.4950666427612 and batch: 850, loss is 3.7257480096817015 and perplexity is 41.502265233289954
At time: 575.3252241611481 and batch: 900, loss is 3.6909141540527344 and perplexity is 40.08147085381509
At time: 576.1605265140533 and batch: 950, loss is 3.7889555740356444 and perplexity is 44.21020187205204
At time: 576.9982736110687 and batch: 1000, loss is 3.7522338962554933 and perplexity is 42.61617586128699
At time: 577.8318040370941 and batch: 1050, loss is 3.7110637855529784 and perplexity is 40.89728934025156
At time: 578.6638805866241 and batch: 1100, loss is 3.71532922744751 and perplexity is 41.07210692364586
At time: 579.5081987380981 and batch: 1150, loss is 3.701052732467651 and perplexity is 40.48990697123768
At time: 580.342029094696 and batch: 1200, loss is 3.7652414512634276 and perplexity is 43.174129049469606
At time: 581.1736764907837 and batch: 1250, loss is 3.745654430389404 and perplexity is 42.336704580916546
At time: 582.0049843788147 and batch: 1300, loss is 3.748916254043579 and perplexity is 42.475024910982455
At time: 582.8345291614532 and batch: 1350, loss is 3.6203516626358034 and perplexity is 37.35070035854431
At time: 583.6684086322784 and batch: 1400, loss is 3.652430338859558 and perplexity is 38.56828624335676
At time: 584.5037994384766 and batch: 1450, loss is 3.5673386907577513 and perplexity is 35.42219817684349
At time: 585.3364341259003 and batch: 1500, loss is 3.5711524581909178 and perplexity is 35.55754813523983
At time: 586.1701848506927 and batch: 1550, loss is 3.580969762802124 and perplexity is 35.908346546465296
At time: 587.006826877594 and batch: 1600, loss is 3.679607620239258 and perplexity is 39.63084068156959
At time: 587.83900141716 and batch: 1650, loss is 3.619090209007263 and perplexity is 37.303613886992615
At time: 588.6701757907867 and batch: 1700, loss is 3.637778148651123 and perplexity is 38.00729627952003
At time: 589.5030267238617 and batch: 1750, loss is 3.6263299655914305 and perplexity is 37.57466295197281
At time: 590.332855463028 and batch: 1800, loss is 3.5854658460617066 and perplexity is 36.07015694618701
At time: 591.1650359630585 and batch: 1850, loss is 3.607419090270996 and perplexity is 36.87076978081537
At time: 591.9957954883575 and batch: 1900, loss is 3.688759779930115 and perplexity is 39.99521331907392
At time: 592.8267891407013 and batch: 1950, loss is 3.631690435409546 and perplexity is 37.776621611702225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240876521620639 and perplexity of 69.46871599201033
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 596.0750994682312 and batch: 50, loss is 3.7971855354309083 and perplexity is 44.57555147112327
At time: 596.9059619903564 and batch: 100, loss is 3.7950168085098266 and perplexity is 44.478984024685595
At time: 597.7410514354706 and batch: 150, loss is 3.7663662910461424 and perplexity is 43.22272035099964
At time: 598.5773203372955 and batch: 200, loss is 3.764344596862793 and perplexity is 43.13542550015654
At time: 599.4078757762909 and batch: 250, loss is 3.7589216518402098 and perplexity is 42.90213758463074
At time: 600.2390246391296 and batch: 300, loss is 3.7530173540115355 and perplexity is 42.64957691724807
At time: 601.0689322948456 and batch: 350, loss is 3.774480948448181 and perplexity is 43.574884833261535
At time: 601.9058427810669 and batch: 400, loss is 3.7412086629867556 and perplexity is 42.14890320968436
At time: 602.7397620677948 and batch: 450, loss is 3.8010439586639406 and perplexity is 44.74787504940582
At time: 603.5738408565521 and batch: 500, loss is 3.8005713033676147 and perplexity is 44.7267297268824
At time: 604.4055280685425 and batch: 550, loss is 3.7811748695373537 and perplexity is 43.86755012014766
At time: 605.2387113571167 and batch: 600, loss is 3.7488045406341555 and perplexity is 42.47028014616616
At time: 606.0683724880219 and batch: 650, loss is 3.7869592237472536 and perplexity is 44.1220308621886
At time: 606.8986148834229 and batch: 700, loss is 3.8129840326309203 and perplexity is 45.285370469224894
At time: 607.7289304733276 and batch: 750, loss is 3.7759839582443235 and perplexity is 43.64042755536978
At time: 608.5611464977264 and batch: 800, loss is 3.749986605644226 and perplexity is 42.520512461376896
At time: 609.390867471695 and batch: 850, loss is 3.7376932525634765 and perplexity is 42.0009926514948
At time: 610.2226119041443 and batch: 900, loss is 3.7000772190093993 and perplexity is 40.450427781435145
At time: 611.055104970932 and batch: 950, loss is 3.799422764778137 and perplexity is 44.675388840948116
At time: 611.887410402298 and batch: 1000, loss is 3.7620678091049196 and perplexity is 43.037327008546114
At time: 612.7683298587799 and batch: 1050, loss is 3.7214352798461916 and perplexity is 41.32366258509053
At time: 613.5986008644104 and batch: 1100, loss is 3.7206570386886595 and perplexity is 41.291515320871426
At time: 614.4287667274475 and batch: 1150, loss is 3.7051608467102053 and perplexity is 40.65658626912976
At time: 615.2551913261414 and batch: 1200, loss is 3.7692193365097046 and perplexity is 43.34621281826394
At time: 616.0948083400726 and batch: 1250, loss is 3.7472174644470213 and perplexity is 42.402930034901004
At time: 616.9269983768463 and batch: 1300, loss is 3.7502374267578125 and perplexity is 42.53117884128344
At time: 617.7573416233063 and batch: 1350, loss is 3.6185111522674562 and perplexity is 37.282019230821206
At time: 618.5903992652893 and batch: 1400, loss is 3.6503047513961793 and perplexity is 38.48639304404639
At time: 619.4195430278778 and batch: 1450, loss is 3.5650296020507812 and perplexity is 35.34049954005775
At time: 620.2496676445007 and batch: 1500, loss is 3.565998425483704 and perplexity is 35.37475483513025
At time: 621.0828070640564 and batch: 1550, loss is 3.5765468740463255 and perplexity is 35.749878625606584
At time: 621.9202253818512 and batch: 1600, loss is 3.672974076271057 and perplexity is 39.368817788437944
At time: 622.7525179386139 and batch: 1650, loss is 3.6068218612670897 and perplexity is 36.84875606197593
At time: 623.5918622016907 and batch: 1700, loss is 3.6245486831665037 and perplexity is 37.50779144143889
At time: 624.4244914054871 and batch: 1750, loss is 3.6148600912094118 and perplexity is 37.14614848936133
At time: 625.25408411026 and batch: 1800, loss is 3.5723137426376343 and perplexity is 35.598864548263364
At time: 626.0825574398041 and batch: 1850, loss is 3.5964071798324584 and perplexity is 36.46697949777114
At time: 626.9127149581909 and batch: 1900, loss is 3.6786962938308716 and perplexity is 39.59474050189195
At time: 627.7443799972534 and batch: 1950, loss is 3.6242773056030275 and perplexity is 37.49761404940653
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.239428143168604 and perplexity of 69.36817183125171
finished 18 epochs...
Completing Train Step...
At time: 630.9285800457001 and batch: 50, loss is 3.7983804655075075 and perplexity is 44.62884797471302
At time: 631.7626297473907 and batch: 100, loss is 3.792418222427368 and perplexity is 44.36355160133776
At time: 632.5960972309113 and batch: 150, loss is 3.7632095527648928 and perplexity is 43.086492665748075
At time: 633.4290025234222 and batch: 200, loss is 3.760144052505493 and perplexity is 42.954613252767714
At time: 634.2901151180267 and batch: 250, loss is 3.7546628093719483 and perplexity is 42.71981266124955
At time: 635.1209447383881 and batch: 300, loss is 3.7478748512268067 and perplexity is 42.43081432490772
At time: 635.9484963417053 and batch: 350, loss is 3.7685854291915892 and perplexity is 43.31874404399421
At time: 636.7797179222107 and batch: 400, loss is 3.7341187953948975 and perplexity is 41.85112990077916
At time: 637.6142730712891 and batch: 450, loss is 3.7933796548843386 and perplexity is 44.40622467010337
At time: 638.4475119113922 and batch: 500, loss is 3.7930989027023316 and perplexity is 44.393759275557784
At time: 639.2806096076965 and batch: 550, loss is 3.772646527290344 and perplexity is 43.495023414706196
At time: 640.1084859371185 and batch: 600, loss is 3.740857582092285 and perplexity is 42.13410813233102
At time: 640.9412987232208 and batch: 650, loss is 3.778844599723816 and perplexity is 43.765445903699025
At time: 641.7722692489624 and batch: 700, loss is 3.806008062362671 and perplexity is 44.9705604007468
At time: 642.6077935695648 and batch: 750, loss is 3.769706473350525 and perplexity is 43.36733349935101
At time: 643.4389548301697 and batch: 800, loss is 3.743917326927185 and perplexity is 42.263225183944705
At time: 644.2735848426819 and batch: 850, loss is 3.7316361141204832 and perplexity is 41.74735575662642
At time: 645.1038680076599 and batch: 900, loss is 3.6945345544815065 and perplexity is 40.22684482528607
At time: 645.9383029937744 and batch: 950, loss is 3.7944466972351076 and perplexity is 44.453633281463986
At time: 646.7731919288635 and batch: 1000, loss is 3.7573790693283082 and perplexity is 42.836008515355566
At time: 647.6018152236938 and batch: 1050, loss is 3.7168254232406617 and perplexity is 41.13360483222451
At time: 648.4323873519897 and batch: 1100, loss is 3.7170655155181884 and perplexity is 41.14348187874541
At time: 649.2624900341034 and batch: 1150, loss is 3.7020364379882813 and perplexity is 40.529756713247224
At time: 650.0984606742859 and batch: 1200, loss is 3.7662636375427248 and perplexity is 43.218283615055505
At time: 650.9282503128052 and batch: 1250, loss is 3.745059428215027 and perplexity is 42.311521642329495
At time: 651.7578439712524 and batch: 1300, loss is 3.7479254055023192 and perplexity is 42.43295943820719
At time: 652.589560508728 and batch: 1350, loss is 3.6171921730041503 and perplexity is 37.23287743618997
At time: 653.4208085536957 and batch: 1400, loss is 3.6494559335708616 and perplexity is 38.45373896823981
At time: 654.2551634311676 and batch: 1450, loss is 3.564728021621704 and perplexity is 35.329843144003675
At time: 655.0861713886261 and batch: 1500, loss is 3.5666201972961424 and perplexity is 35.3967566999195
At time: 655.9162192344666 and batch: 1550, loss is 3.577857336997986 and perplexity is 35.796758227353514
At time: 656.7503731250763 and batch: 1600, loss is 3.674853229522705 and perplexity is 39.44286738387722
At time: 657.5857722759247 and batch: 1650, loss is 3.609059247970581 and perplexity is 36.93129327823321
At time: 658.4176473617554 and batch: 1700, loss is 3.6274001836776733 and perplexity is 37.61489756191183
At time: 659.2486248016357 and batch: 1750, loss is 3.618538541793823 and perplexity is 37.283040381654295
At time: 660.0829017162323 and batch: 1800, loss is 3.576372699737549 and perplexity is 35.743652457443126
At time: 660.9149219989777 and batch: 1850, loss is 3.600462431907654 and perplexity is 36.61516254879485
At time: 661.7484757900238 and batch: 1900, loss is 3.6827329206466675 and perplexity is 39.754892713056755
At time: 662.5769209861755 and batch: 1950, loss is 3.627508449554443 and perplexity is 37.61897019223545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.238827727561773 and perplexity of 69.32653459933968
finished 19 epochs...
Completing Train Step...
At time: 665.758885383606 and batch: 50, loss is 3.7982691526412964 and perplexity is 44.62388048620707
At time: 666.5884847640991 and batch: 100, loss is 3.790838599205017 and perplexity is 44.29352922404899
At time: 667.4226408004761 and batch: 150, loss is 3.761421298980713 and perplexity is 43.00951193324903
At time: 668.2518000602722 and batch: 200, loss is 3.757840857505798 and perplexity is 42.85579424571539
At time: 669.0874717235565 and batch: 250, loss is 3.7519873189926147 and perplexity is 42.60566897672142
At time: 669.9186112880707 and batch: 300, loss is 3.744880166053772 and perplexity is 42.30393746731201
At time: 670.7468748092651 and batch: 350, loss is 3.76510009765625 and perplexity is 43.16802666189913
At time: 671.574423789978 and batch: 400, loss is 3.7300267219543457 and perplexity is 41.68022192613571
At time: 672.413893699646 and batch: 450, loss is 3.788980689048767 and perplexity is 44.211312225795425
At time: 673.2481532096863 and batch: 500, loss is 3.7887841844558716 and perplexity is 44.202625353418235
At time: 674.0781207084656 and batch: 550, loss is 3.7679046821594238 and perplexity is 43.289264972582735
At time: 674.9097831249237 and batch: 600, loss is 3.736672601699829 and perplexity is 41.95814617143897
At time: 675.7405672073364 and batch: 650, loss is 3.7746550035476685 and perplexity is 43.582469924269084
At time: 676.6228866577148 and batch: 700, loss is 3.802144546508789 and perplexity is 44.79715112812065
At time: 677.4549524784088 and batch: 750, loss is 3.7663035345077516 and perplexity is 43.22000792780261
At time: 678.2847218513489 and batch: 800, loss is 3.740678415298462 and perplexity is 42.12655977549399
At time: 679.1148500442505 and batch: 850, loss is 3.7285504961013793 and perplexity is 41.61873789829241
At time: 679.9455094337463 and batch: 900, loss is 3.691740689277649 and perplexity is 40.11461329615337
At time: 680.7751796245575 and batch: 950, loss is 3.7919323778152467 and perplexity is 44.342003043866825
At time: 681.6060981750488 and batch: 1000, loss is 3.7550363063812258 and perplexity is 42.7357713635937
At time: 682.4400200843811 and batch: 1050, loss is 3.714586877822876 and perplexity is 41.041628374757515
At time: 683.2699491977692 and batch: 1100, loss is 3.7153845739364626 and perplexity is 41.07438018346587
At time: 684.0996055603027 and batch: 1150, loss is 3.700626244544983 and perplexity is 40.472642196795086
At time: 684.9329817295074 and batch: 1200, loss is 3.7647891521453856 and perplexity is 43.15460584447533
At time: 685.7642638683319 and batch: 1250, loss is 3.7439944887161256 and perplexity is 42.26648641582592
At time: 686.5965576171875 and batch: 1300, loss is 3.747025990486145 and perplexity is 42.39481175517885
At time: 687.4291396141052 and batch: 1350, loss is 3.6165456342697144 and perplexity is 37.20881271895716
At time: 688.2622842788696 and batch: 1400, loss is 3.649056053161621 and perplexity is 38.43836514541451
At time: 689.0895111560822 and batch: 1450, loss is 3.564712953567505 and perplexity is 35.32931079602307
At time: 689.923454284668 and batch: 1500, loss is 3.567134590148926 and perplexity is 35.41496922237176
At time: 690.7557373046875 and batch: 1550, loss is 3.578678789138794 and perplexity is 35.82617563187413
At time: 691.5907526016235 and batch: 1600, loss is 3.675926504135132 and perplexity is 39.485223137693424
At time: 692.4229810237885 and batch: 1650, loss is 3.6102748775482176 and perplexity is 36.97621534944984
At time: 693.2591359615326 and batch: 1700, loss is 3.628844656944275 and perplexity is 37.66927053656602
At time: 694.0911738872528 and batch: 1750, loss is 3.6203323078155516 and perplexity is 37.349977449448495
At time: 694.9273672103882 and batch: 1800, loss is 3.5783118486404417 and perplexity is 35.81303196875234
At time: 695.7626292705536 and batch: 1850, loss is 3.602357668876648 and perplexity is 36.68462275947132
At time: 696.598037481308 and batch: 1900, loss is 3.6845963621139526 and perplexity is 39.82904269428403
At time: 697.4359741210938 and batch: 1950, loss is 3.628941831588745 and perplexity is 37.672931212397415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.238551791878634 and perplexity of 69.30740757369114
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
2940.191222667694


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}, 'best_accuracy': -69.56506109203387}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.0664099827407102, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3472414743178278}, 'best_accuracy': -69.30740757369114}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.49972324366546084, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.08468759351567401}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4714488983154297 and batch: 50, loss is 7.685285120010376 and perplexity is 2176.0903320620864
At time: 2.3884291648864746 and batch: 100, loss is 6.844855136871338 and perplexity is 939.0372392840343
At time: 3.277176856994629 and batch: 150, loss is 6.520287027359009 and perplexity is 678.7731838561817
At time: 4.167793035507202 and batch: 200, loss is 6.357049942016602 and perplexity is 576.5430098345632
At time: 5.066586017608643 and batch: 250, loss is 6.236776361465454 and perplexity is 511.20790239624733
At time: 5.961760520935059 and batch: 300, loss is 6.1313980865478515 and perplexity is 460.07894142263143
At time: 6.859205484390259 and batch: 350, loss is 6.04234450340271 and perplexity is 420.87863045035715
At time: 7.7520976066589355 and batch: 400, loss is 5.964742631912231 and perplexity is 389.45278245348595
At time: 8.64577031135559 and batch: 450, loss is 5.861665573120117 and perplexity is 351.30878747482416
At time: 9.540874481201172 and batch: 500, loss is 5.8205516815185545 and perplexity is 337.1580061729027
At time: 10.428316831588745 and batch: 550, loss is 5.750190353393554 and perplexity is 314.2504732367212
At time: 11.316386222839355 and batch: 600, loss is 5.76449312210083 and perplexity is 318.77742184846073
At time: 12.212036371231079 and batch: 650, loss is 5.810218324661255 and perplexity is 333.6919709088351
At time: 13.10746145248413 and batch: 700, loss is 5.729884929656983 and perplexity is 307.93383228692056
At time: 14.000664472579956 and batch: 750, loss is 5.659630222320557 and perplexity is 287.04248102664627
At time: 14.89383602142334 and batch: 800, loss is 5.648200464248657 and perplexity is 283.78033320601355
At time: 15.787768125534058 and batch: 850, loss is 5.6588421726226805 and perplexity is 286.81636639268197
At time: 16.67996311187744 and batch: 900, loss is 5.6327516555786135 and perplexity is 279.4299557320868
At time: 17.576703786849976 and batch: 950, loss is 5.663239364624023 and perplexity is 288.0803299334318
At time: 18.46840262413025 and batch: 1000, loss is 5.629496126174927 and perplexity is 278.5217424545843
At time: 19.363547801971436 and batch: 1050, loss is 5.5218633270263675 and perplexity is 250.1006225353876
At time: 20.2549729347229 and batch: 1100, loss is 5.590522661209106 and perplexity is 267.8755913120435
At time: 21.14871835708618 and batch: 1150, loss is 5.491741752624511 and perplexity is 242.67952666535615
At time: 22.04532480239868 and batch: 1200, loss is 5.566863527297974 and perplexity is 261.6122713460339
At time: 22.935874223709106 and batch: 1250, loss is 5.501318626403808 and perplexity is 245.01480233261825
At time: 23.82887101173401 and batch: 1300, loss is 5.515638732910157 and perplexity is 248.5486827803234
At time: 24.721309661865234 and batch: 1350, loss is 5.460043468475342 and perplexity is 235.107643913945
At time: 25.61680817604065 and batch: 1400, loss is 5.47952938079834 and perplexity is 239.7338574650599
At time: 26.512834548950195 and batch: 1450, loss is 5.4449177169799805 and perplexity is 231.57822397251414
At time: 27.406065940856934 and batch: 1500, loss is 5.407640657424927 and perplexity is 223.10458608771035
At time: 28.29927682876587 and batch: 1550, loss is 5.376773643493652 and perplexity is 216.3232125140938
At time: 29.18185067176819 and batch: 1600, loss is 5.411842994689941 and perplexity is 224.04411953938887
At time: 30.082903146743774 and batch: 1650, loss is 5.398055458068848 and perplexity is 220.9763004686245
At time: 31.003456592559814 and batch: 1700, loss is 5.413482828140259 and perplexity is 224.41181597902084
At time: 31.90380883216858 and batch: 1750, loss is 5.41167384147644 and perplexity is 224.0062249616879
At time: 32.79754042625427 and batch: 1800, loss is 5.3984715938568115 and perplexity is 221.06827575131737
At time: 33.69129514694214 and batch: 1850, loss is 5.366351585388184 and perplexity is 214.0803871529665
At time: 34.58422017097473 and batch: 1900, loss is 5.398150300979614 and perplexity is 220.9972594980632
At time: 35.482666015625 and batch: 1950, loss is 5.323114309310913 and perplexity is 205.0213888010928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.864176621547965 and perplexity of 129.56421429838036
finished 1 epochs...
Completing Train Step...
At time: 38.78871035575867 and batch: 50, loss is 5.115065889358521 and perplexity is 166.5117519744026
At time: 39.6196973323822 and batch: 100, loss is 5.047991161346435 and perplexity is 155.7093551272963
At time: 40.45542764663696 and batch: 150, loss is 4.974277534484863 and perplexity is 144.64428688084843
At time: 41.28510093688965 and batch: 200, loss is 4.939992733001709 and perplexity is 139.76923385352887
At time: 42.12284207344055 and batch: 250, loss is 4.945015697479248 and perplexity is 140.47305590701924
At time: 42.949347734451294 and batch: 300, loss is 4.9477713012695315 and perplexity is 140.86067781322714
At time: 43.78705096244812 and batch: 350, loss is 4.941366596221924 and perplexity is 139.96138963089084
At time: 44.61680054664612 and batch: 400, loss is 4.8955348873138425 and perplexity is 133.69149737900742
At time: 45.45218324661255 and batch: 450, loss is 4.86160984992981 and perplexity is 129.2320789904826
At time: 46.3486225605011 and batch: 500, loss is 4.848449077606201 and perplexity is 127.54242796626107
At time: 47.179837465286255 and batch: 550, loss is 4.801997394561767 and perplexity is 121.75336431541872
At time: 48.007094860076904 and batch: 600, loss is 4.793286628723145 and perplexity is 120.69740505268783
At time: 48.84377717971802 and batch: 650, loss is 4.866858930587768 and perplexity is 129.91221207176733
At time: 49.67413282394409 and batch: 700, loss is 4.852505350112915 and perplexity is 128.06082548027106
At time: 50.50129222869873 and batch: 750, loss is 4.820653629302979 and perplexity is 124.04614448235584
At time: 51.33030700683594 and batch: 800, loss is 4.79773904800415 and perplexity is 121.23599863858695
At time: 52.15974760055542 and batch: 850, loss is 4.7828029537200925 and perplexity is 119.43866233791557
At time: 52.996746301651 and batch: 900, loss is 4.779234323501587 and perplexity is 119.01318954730469
At time: 53.840211629867554 and batch: 950, loss is 4.8420758724212645 and perplexity is 126.73215865195213
At time: 54.67362689971924 and batch: 1000, loss is 4.811708812713623 and perplexity is 122.94152215842442
At time: 55.50835371017456 and batch: 1050, loss is 4.729706621170044 and perplexity is 113.26232870440097
At time: 56.34003019332886 and batch: 1100, loss is 4.796398687362671 and perplexity is 121.07360753331658
At time: 57.16813516616821 and batch: 1150, loss is 4.7141937828063964 and perplexity is 111.51886649352787
At time: 57.998801946640015 and batch: 1200, loss is 4.794277381896973 and perplexity is 120.81704564717941
At time: 58.82903981208801 and batch: 1250, loss is 4.757489233016968 and perplexity is 116.45317175535052
At time: 59.65638303756714 and batch: 1300, loss is 4.77533263206482 and perplexity is 118.549741508338
At time: 60.48439049720764 and batch: 1350, loss is 4.667585573196411 and perplexity is 106.44043928803853
At time: 61.31181025505066 and batch: 1400, loss is 4.687528762817383 and perplexity is 108.58450989230272
At time: 62.146355867385864 and batch: 1450, loss is 4.632369003295898 and perplexity is 102.75720815705708
At time: 62.97290301322937 and batch: 1500, loss is 4.617177410125732 and perplexity is 101.20796002420043
At time: 63.80336284637451 and batch: 1550, loss is 4.618253965377807 and perplexity is 101.31697465472405
At time: 64.63302421569824 and batch: 1600, loss is 4.68434063911438 and perplexity is 108.23888029025152
At time: 65.4611804485321 and batch: 1650, loss is 4.643860607147217 and perplexity is 103.94486425292251
At time: 66.29180335998535 and batch: 1700, loss is 4.670163698196411 and perplexity is 106.71521009012122
At time: 67.12191486358643 and batch: 1750, loss is 4.665482854843139 and perplexity is 106.21686016715589
At time: 67.94961285591125 and batch: 1800, loss is 4.623429203033448 and perplexity is 101.84267321127687
At time: 68.78510642051697 and batch: 1850, loss is 4.639642839431763 and perplexity is 103.50737222872282
At time: 69.61808681488037 and batch: 1900, loss is 4.720837860107422 and perplexity is 112.2622733546299
At time: 70.4460232257843 and batch: 1950, loss is 4.644867610931397 and perplexity is 104.04958984525533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.519710381086482 and perplexity of 91.80900450322063
finished 2 epochs...
Completing Train Step...
At time: 73.59832644462585 and batch: 50, loss is 4.608089323043823 and perplexity is 100.29234018851713
At time: 74.46057915687561 and batch: 100, loss is 4.550891799926758 and perplexity is 94.7168391318307
At time: 75.29054951667786 and batch: 150, loss is 4.5112402057647705 and perplexity is 91.03465022679991
At time: 76.12255239486694 and batch: 200, loss is 4.508683605194092 and perplexity is 90.80220824533714
At time: 76.95315194129944 and batch: 250, loss is 4.501234474182129 and perplexity is 90.12832374304067
At time: 77.78532767295837 and batch: 300, loss is 4.517956619262695 and perplexity is 91.64813448112673
At time: 78.61288452148438 and batch: 350, loss is 4.53018367767334 and perplexity is 92.77560032360985
At time: 79.44190788269043 and batch: 400, loss is 4.487478523254395 and perplexity is 88.8970112975395
At time: 80.27097082138062 and batch: 450, loss is 4.4906644439697265 and perplexity is 89.18068176322987
At time: 81.09746527671814 and batch: 500, loss is 4.486375741958618 and perplexity is 88.79903137137475
At time: 81.93843698501587 and batch: 550, loss is 4.46121600151062 and perplexity is 86.59274200676238
At time: 82.77333950996399 and batch: 600, loss is 4.437323875427246 and perplexity is 84.54837666257268
At time: 83.60535764694214 and batch: 650, loss is 4.505718221664429 and perplexity is 90.53334371279931
At time: 84.43640112876892 and batch: 700, loss is 4.520848245620727 and perplexity is 91.91353017011608
At time: 85.263498544693 and batch: 750, loss is 4.491988410949707 and perplexity is 89.29883223754116
At time: 86.09351634979248 and batch: 800, loss is 4.471205215454102 and perplexity is 87.46207015628703
At time: 86.92078900337219 and batch: 850, loss is 4.454883670806884 and perplexity is 86.04614058480196
At time: 87.79792261123657 and batch: 900, loss is 4.443219194412231 and perplexity is 85.04828843448135
At time: 88.62779903411865 and batch: 950, loss is 4.523460283279419 and perplexity is 92.15392559653745
At time: 89.4583113193512 and batch: 1000, loss is 4.497641382217407 and perplexity is 89.8050654833137
At time: 90.28978395462036 and batch: 1050, loss is 4.429334859848023 and perplexity is 83.87560931686255
At time: 91.12164616584778 and batch: 1100, loss is 4.483101043701172 and perplexity is 88.5087169435912
At time: 91.95169305801392 and batch: 1150, loss is 4.423233394622803 and perplexity is 83.36540328836485
At time: 92.7798330783844 and batch: 1200, loss is 4.503720760345459 and perplexity is 90.35268734777257
At time: 93.61027026176453 and batch: 1250, loss is 4.478651704788208 and perplexity is 88.11578645384098
At time: 94.44589447975159 and batch: 1300, loss is 4.485300703048706 and perplexity is 88.70362025200987
At time: 95.27883338928223 and batch: 1350, loss is 4.372910757064819 and perplexity is 79.27404368293655
At time: 96.11132550239563 and batch: 1400, loss is 4.399447746276856 and perplexity is 81.40589953782141
At time: 96.94568943977356 and batch: 1450, loss is 4.339649224281311 and perplexity is 76.68063691468971
At time: 97.77471113204956 and batch: 1500, loss is 4.333703198432922 and perplexity is 76.22604471336376
At time: 98.60696220397949 and batch: 1550, loss is 4.34809832572937 and perplexity is 77.33126413222699
At time: 99.43642020225525 and batch: 1600, loss is 4.417162733078003 and perplexity is 82.86085316647828
At time: 100.26863408088684 and batch: 1650, loss is 4.37976484298706 and perplexity is 79.81926113893152
At time: 101.09737968444824 and batch: 1700, loss is 4.3998237991333005 and perplexity is 81.43651821563385
At time: 101.92852401733398 and batch: 1750, loss is 4.399394178390503 and perplexity is 81.40153891264232
At time: 102.7616069316864 and batch: 1800, loss is 4.357446222305298 and perplexity is 78.05753806957802
At time: 103.58983755111694 and batch: 1850, loss is 4.384966669082641 and perplexity is 80.23554884388398
At time: 104.41728734970093 and batch: 1900, loss is 4.475493364334106 and perplexity is 87.83792582105161
At time: 105.24633359909058 and batch: 1950, loss is 4.397615766525268 and perplexity is 81.25690210002436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411541889989099 and perplexity of 82.39641181139851
finished 3 epochs...
Completing Train Step...
At time: 108.39776515960693 and batch: 50, loss is 4.373886570930481 and perplexity is 79.35143814910475
At time: 109.24998164176941 and batch: 100, loss is 4.322564811706543 and perplexity is 75.38172048277013
At time: 110.08047676086426 and batch: 150, loss is 4.29651370048523 and perplexity is 73.44330150867248
At time: 110.90905261039734 and batch: 200, loss is 4.292209091186524 and perplexity is 73.12783625452566
At time: 111.73649621009827 and batch: 250, loss is 4.277257876396179 and perplexity is 72.04261914022062
At time: 112.56422853469849 and batch: 300, loss is 4.299754099845886 and perplexity is 73.6816731369828
At time: 113.39067530632019 and batch: 350, loss is 4.3129121208190915 and perplexity is 74.65758458892863
At time: 114.21704483032227 and batch: 400, loss is 4.2712698173522945 and perplexity is 71.61251271964139
At time: 115.04780292510986 and batch: 450, loss is 4.294261016845703 and perplexity is 73.27804319216877
At time: 115.87819027900696 and batch: 500, loss is 4.294528789520264 and perplexity is 73.29766767711406
At time: 116.70780324935913 and batch: 550, loss is 4.266410264968872 and perplexity is 71.26535216840388
At time: 117.53724241256714 and batch: 600, loss is 4.248095054626464 and perplexity is 69.9719924848988
At time: 118.36467909812927 and batch: 650, loss is 4.309914245605468 and perplexity is 74.43410561499076
At time: 119.19986844062805 and batch: 700, loss is 4.330421752929688 and perplexity is 75.97632304980583
At time: 120.03263783454895 and batch: 750, loss is 4.303991289138794 and perplexity is 73.9945387006977
At time: 120.87098097801208 and batch: 800, loss is 4.28261923789978 and perplexity is 72.42990292159614
At time: 121.70609092712402 and batch: 850, loss is 4.269751768112183 and perplexity is 71.50388387195574
At time: 122.539546251297 and batch: 900, loss is 4.251496868133545 and perplexity is 70.21042948321265
At time: 123.37016272544861 and batch: 950, loss is 4.340257968902588 and perplexity is 76.72733005062332
At time: 124.20539236068726 and batch: 1000, loss is 4.3196492099761965 and perplexity is 75.16225749689112
At time: 125.03813028335571 and batch: 1050, loss is 4.256075649261475 and perplexity is 70.53264478644587
At time: 125.87182569503784 and batch: 1100, loss is 4.303237428665161 and perplexity is 73.93877816317995
At time: 126.70493125915527 and batch: 1150, loss is 4.248922629356384 and perplexity is 70.0299235054995
At time: 127.53991746902466 and batch: 1200, loss is 4.333224792480468 and perplexity is 76.18958644146336
At time: 128.37026047706604 and batch: 1250, loss is 4.310843420028687 and perplexity is 74.50330002400253
At time: 129.19944405555725 and batch: 1300, loss is 4.315864295959472 and perplexity is 74.87831250762028
At time: 130.02998185157776 and batch: 1350, loss is 4.198588705062866 and perplexity is 66.59228333968332
At time: 130.86136174201965 and batch: 1400, loss is 4.228097596168518 and perplexity is 68.58662851790724
At time: 131.69204473495483 and batch: 1450, loss is 4.167681245803833 and perplexity is 64.56556672211163
At time: 132.52057766914368 and batch: 1500, loss is 4.168243608474731 and perplexity is 64.6018861980631
At time: 133.3540427684784 and batch: 1550, loss is 4.184476757049561 and perplexity is 65.65913624681302
At time: 134.1929726600647 and batch: 1600, loss is 4.258827815055847 and perplexity is 70.72702968585327
At time: 135.02278518676758 and batch: 1650, loss is 4.214651479721069 and perplexity is 67.67057719216575
At time: 135.85502934455872 and batch: 1700, loss is 4.239668321609497 and perplexity is 69.38483457154514
At time: 136.6826183795929 and batch: 1750, loss is 4.240918092727661 and perplexity is 69.47160394346474
At time: 137.51414561271667 and batch: 1800, loss is 4.196824789047241 and perplexity is 66.47492368130334
At time: 138.346515417099 and batch: 1850, loss is 4.2271360206604 and perplexity is 68.52070899411909
At time: 139.17952919006348 and batch: 1900, loss is 4.314057483673095 and perplexity is 74.74314360179059
At time: 140.01213121414185 and batch: 1950, loss is 4.240333671569824 and perplexity is 69.4310151298873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371074729742006 and perplexity of 79.1286279072631
finished 4 epochs...
Completing Train Step...
At time: 143.19904041290283 and batch: 50, loss is 4.220187139511109 and perplexity is 68.04621723378993
At time: 144.05467200279236 and batch: 100, loss is 4.174959812164307 and perplexity is 65.03722590314814
At time: 144.89566898345947 and batch: 150, loss is 4.153799057006836 and perplexity is 63.67544802787444
At time: 145.72617149353027 and batch: 200, loss is 4.15108630657196 and perplexity is 63.50294651111497
At time: 146.55720710754395 and batch: 250, loss is 4.136745848655701 and perplexity is 62.598783728223744
At time: 147.38900351524353 and batch: 300, loss is 4.155068578720093 and perplexity is 63.756336725862504
At time: 148.22197651863098 and batch: 350, loss is 4.170260629653931 and perplexity is 64.73232107147041
At time: 149.05451107025146 and batch: 400, loss is 4.133945784568787 and perplexity is 62.42374829160355
At time: 149.88772630691528 and batch: 450, loss is 4.163148722648621 and perplexity is 64.2735840049959
At time: 150.7181477546692 and batch: 500, loss is 4.1615941619873045 and perplexity is 64.17374444317407
At time: 151.57614612579346 and batch: 550, loss is 4.134276580810547 and perplexity is 62.44440124870698
At time: 152.40977692604065 and batch: 600, loss is 4.117179436683655 and perplexity is 61.38585516351317
At time: 153.24546217918396 and batch: 650, loss is 4.175507860183716 and perplexity is 65.07287919495782
At time: 154.07827472686768 and batch: 700, loss is 4.200581703186035 and perplexity is 66.72513397695823
At time: 154.91590237617493 and batch: 750, loss is 4.1801904106140135 and perplexity is 65.37830075128991
At time: 155.75666189193726 and batch: 800, loss is 4.156175627708435 and perplexity is 63.826957196883285
At time: 156.59945559501648 and batch: 850, loss is 4.145824627876282 and perplexity is 63.16969191849281
At time: 157.434396982193 and batch: 900, loss is 4.126212711334229 and perplexity is 61.94288255579323
At time: 158.2760305404663 and batch: 950, loss is 4.218475437164306 and perplexity is 67.929841992361
At time: 159.13139939308167 and batch: 1000, loss is 4.194099688529969 and perplexity is 66.29401943547288
At time: 159.9810655117035 and batch: 1050, loss is 4.138019819259643 and perplexity is 62.67858355906246
At time: 160.8161838054657 and batch: 1100, loss is 4.178572173118591 and perplexity is 65.27258869030655
At time: 161.65530443191528 and batch: 1150, loss is 4.128788862228394 and perplexity is 62.10266248831886
At time: 162.49330186843872 and batch: 1200, loss is 4.211709098815918 and perplexity is 67.47175722347674
At time: 163.32640075683594 and batch: 1250, loss is 4.194818773269653 and perplexity is 66.34170759704102
At time: 164.1619873046875 and batch: 1300, loss is 4.195118927955628 and perplexity is 66.36162336020712
At time: 165.00355124473572 and batch: 1350, loss is 4.082721238136291 and perplexity is 59.30663794695672
At time: 165.83435821533203 and batch: 1400, loss is 4.110791130065918 and perplexity is 60.99495342821369
At time: 166.67271041870117 and batch: 1450, loss is 4.045774712562561 and perplexity is 57.15544793033806
At time: 167.51080107688904 and batch: 1500, loss is 4.05391836643219 and perplexity is 57.62280251917422
At time: 168.34491872787476 and batch: 1550, loss is 4.063626985549927 and perplexity is 58.18496485568219
At time: 169.17666172981262 and batch: 1600, loss is 4.145995435714721 and perplexity is 63.18048271857468
At time: 170.00539374351501 and batch: 1650, loss is 4.105006737709045 and perplexity is 60.64315314215097
At time: 170.81752276420593 and batch: 1700, loss is 4.122993216514588 and perplexity is 61.74377844559549
At time: 171.64713835716248 and batch: 1750, loss is 4.126588587760925 and perplexity is 61.966169801436756
At time: 172.47868537902832 and batch: 1800, loss is 4.081604590415955 and perplexity is 59.24045028592029
At time: 173.30693888664246 and batch: 1850, loss is 4.113951873779297 and perplexity is 61.1880478440343
At time: 174.1364688873291 and batch: 1900, loss is 4.197788968086242 and perplexity is 66.5390483181837
At time: 174.9673776626587 and batch: 1950, loss is 4.1241490840911865 and perplexity is 61.815187338819264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349317825672238 and perplexity of 77.42562713055915
finished 5 epochs...
Completing Train Step...
At time: 178.15473890304565 and batch: 50, loss is 4.111045150756836 and perplexity is 61.010449376488474
At time: 178.98495769500732 and batch: 100, loss is 4.068929738998413 and perplexity is 58.49432488378608
At time: 179.8150613307953 and batch: 150, loss is 4.051451783180237 and perplexity is 57.480846225030895
At time: 180.6458842754364 and batch: 200, loss is 4.04704707622528 and perplexity is 57.22821672978201
At time: 181.48108792304993 and batch: 250, loss is 4.03189416885376 and perplexity is 56.36757990522839
At time: 182.3128945827484 and batch: 300, loss is 4.049494853019715 and perplexity is 57.368470215264885
At time: 183.1509919166565 and batch: 350, loss is 4.063801431655884 and perplexity is 58.19511588160424
At time: 183.98604273796082 and batch: 400, loss is 4.027351994514465 and perplexity is 56.11212912040561
At time: 184.81718635559082 and batch: 450, loss is 4.063520164489746 and perplexity is 58.17874980800459
At time: 185.6486463546753 and batch: 500, loss is 4.070136651992798 and perplexity is 58.56496506428721
At time: 186.48588490486145 and batch: 550, loss is 4.034236397743225 and perplexity is 56.499760417389844
At time: 187.3175904750824 and batch: 600, loss is 4.0202705812454225 and perplexity is 55.7161795406218
At time: 188.14845633506775 and batch: 650, loss is 4.074240980148315 and perplexity is 58.80582885322002
At time: 188.98169803619385 and batch: 700, loss is 4.108546094894409 and perplexity is 60.858171210378366
At time: 189.81526398658752 and batch: 750, loss is 4.081095700263977 and perplexity is 59.21031107359565
At time: 190.6473569869995 and batch: 800, loss is 4.061007008552552 and perplexity is 58.032721110808936
At time: 191.48143458366394 and batch: 850, loss is 4.0523045539855955 and perplexity is 57.529885119055635
At time: 192.31199169158936 and batch: 900, loss is 4.028865189552307 and perplexity is 56.19710198980157
At time: 193.19312930107117 and batch: 950, loss is 4.1254190254211425 and perplexity is 61.893738867399136
At time: 194.02367234230042 and batch: 1000, loss is 4.101309776306152 and perplexity is 60.41937165627087
At time: 194.85463738441467 and batch: 1050, loss is 4.049454393386841 and perplexity is 57.366149154976405
At time: 195.69133591651917 and batch: 1100, loss is 4.082140645980835 and perplexity is 59.27221497201979
At time: 196.52289652824402 and batch: 1150, loss is 4.0395634698867795 and perplexity is 56.80154180919494
At time: 197.35696959495544 and batch: 1200, loss is 4.118659801483155 and perplexity is 61.47679591882303
At time: 198.1889910697937 and batch: 1250, loss is 4.1049605560302735 and perplexity is 60.640352604200125
At time: 199.0192530155182 and batch: 1300, loss is 4.107312726974487 and perplexity is 60.783156963934196
At time: 199.85189366340637 and batch: 1350, loss is 3.9902517223358154 and perplexity is 54.06849789905371
At time: 200.68718719482422 and batch: 1400, loss is 4.023190951347351 and perplexity is 55.879129226430656
At time: 201.51909732818604 and batch: 1450, loss is 3.9559614849090576 and perplexity is 52.24590345045017
At time: 202.3514518737793 and batch: 1500, loss is 3.9634576559066774 and perplexity is 52.639019267485466
At time: 203.1887035369873 and batch: 1550, loss is 3.976593542098999 and perplexity is 53.33504085577516
At time: 204.0255310535431 and batch: 1600, loss is 4.060470509529114 and perplexity is 58.0015949629261
At time: 204.8552634716034 and batch: 1650, loss is 4.021143779754639 and perplexity is 55.76485207283456
At time: 205.68396854400635 and batch: 1700, loss is 4.033190059661865 and perplexity is 56.44067348432232
At time: 206.51572036743164 and batch: 1750, loss is 4.037508354187012 and perplexity is 56.68492793739446
At time: 207.34654545783997 and batch: 1800, loss is 3.997497992515564 and perplexity is 54.461715804029794
At time: 208.18078541755676 and batch: 1850, loss is 4.024752683639527 and perplexity is 55.96646564730545
At time: 209.0102560520172 and batch: 1900, loss is 4.108116788864136 and perplexity is 60.83205003787595
At time: 209.8428304195404 and batch: 1950, loss is 4.040738825798035 and perplexity is 56.86834308707691
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336823219476744 and perplexity of 76.46424297552302
finished 6 epochs...
Completing Train Step...
At time: 213.06438779830933 and batch: 50, loss is 4.026182851791382 and perplexity is 56.04656436771288
At time: 213.90238857269287 and batch: 100, loss is 3.9869116067886354 and perplexity is 53.88820413722554
At time: 214.76247692108154 and batch: 150, loss is 3.972679762840271 and perplexity is 53.12670723095232
At time: 215.59632110595703 and batch: 200, loss is 3.967871975898743 and perplexity is 52.8718983658695
At time: 216.42741656303406 and batch: 250, loss is 3.9478190469741823 and perplexity is 51.822221666383236
At time: 217.25843787193298 and batch: 300, loss is 3.964240117073059 and perplexity is 52.68022337410309
At time: 218.08993697166443 and batch: 350, loss is 3.9822279691696165 and perplexity is 53.636401453672505
At time: 218.92481660842896 and batch: 400, loss is 3.943453087806702 and perplexity is 51.59646115182671
At time: 219.75599884986877 and batch: 450, loss is 3.9857586002349854 and perplexity is 53.826106491066895
At time: 220.5919153690338 and batch: 500, loss is 3.9956016826629637 and perplexity is 54.35853737581515
At time: 221.42331719398499 and batch: 550, loss is 3.9593927478790283 and perplexity is 52.42548079665273
At time: 222.2581238746643 and batch: 600, loss is 3.946147108078003 and perplexity is 51.73565046933521
At time: 223.08951330184937 and batch: 650, loss is 3.997162690162659 and perplexity is 54.443457723737154
At time: 223.92431211471558 and batch: 700, loss is 4.032317886352539 and perplexity is 56.39146889593235
At time: 224.7537603378296 and batch: 750, loss is 4.012216081619263 and perplexity is 55.269216043393946
At time: 225.586932182312 and batch: 800, loss is 3.9909775018692017 and perplexity is 54.10775395212653
At time: 226.4194619655609 and batch: 850, loss is 3.976223545074463 and perplexity is 53.31531069962964
At time: 227.2510702610016 and batch: 900, loss is 3.9527614068984986 and perplexity is 52.07897971061974
At time: 228.07812762260437 and batch: 950, loss is 4.051599111557007 and perplexity is 57.48931540866079
At time: 228.91004538536072 and batch: 1000, loss is 4.028687295913696 and perplexity is 56.18710577200735
At time: 229.74166989326477 and batch: 1050, loss is 3.97927348613739 and perplexity is 53.47816748056389
At time: 230.5688374042511 and batch: 1100, loss is 4.006690220832825 and perplexity is 54.96464832417185
At time: 231.40602493286133 and batch: 1150, loss is 3.9667426109313966 and perplexity is 52.812220401542206
At time: 232.23900294303894 and batch: 1200, loss is 4.042592892646789 and perplexity is 56.973878601455475
At time: 233.07319450378418 and batch: 1250, loss is 4.037611536979675 and perplexity is 56.69077714832471
At time: 233.90702295303345 and batch: 1300, loss is 4.034450469017028 and perplexity is 56.51185668775779
At time: 234.73701572418213 and batch: 1350, loss is 3.9186186027526855 and perplexity is 50.33086980878508
At time: 235.5724287033081 and batch: 1400, loss is 3.9501982021331785 and perplexity is 51.9456615555096
At time: 236.40347003936768 and batch: 1450, loss is 3.884337592124939 and perplexity is 48.63471576833548
At time: 237.23387694358826 and batch: 1500, loss is 3.8942734718322756 and perplexity is 49.1203530755042
At time: 238.06941151618958 and batch: 1550, loss is 3.9063794803619385 and perplexity is 49.71861848532363
At time: 238.89670729637146 and batch: 1600, loss is 3.9897326707839964 and perplexity is 54.04044084347372
At time: 239.72764468193054 and batch: 1650, loss is 3.950273060798645 and perplexity is 51.949550283961116
At time: 240.55965566635132 and batch: 1700, loss is 3.9670826244354247 and perplexity is 52.83018032279129
At time: 241.3899347782135 and batch: 1750, loss is 3.965753979682922 and perplexity is 52.76003439076294
At time: 242.22137832641602 and batch: 1800, loss is 3.9277110624313356 and perplexity is 50.790588030631454
At time: 243.05311107635498 and batch: 1850, loss is 3.957864537239075 and perplexity is 52.34542480588346
At time: 243.89551615715027 and batch: 1900, loss is 4.042847051620483 and perplexity is 56.988360864288744
At time: 244.72802257537842 and batch: 1950, loss is 3.970933141708374 and perplexity is 53.033995990709734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3324922783430235 and perplexity of 76.13379692806717
finished 7 epochs...
Completing Train Step...
At time: 247.92611026763916 and batch: 50, loss is 3.9588928508758543 and perplexity is 52.399280005306686
At time: 248.7543430328369 and batch: 100, loss is 3.9209239959716795 and perplexity is 50.44703610779692
At time: 249.592036485672 and batch: 150, loss is 3.9115231084823607 and perplexity is 49.97501139909375
At time: 250.42046189308167 and batch: 200, loss is 3.902973928451538 and perplexity is 49.549587135043126
At time: 251.2533576488495 and batch: 250, loss is 3.8828105831146242 and perplexity is 48.56050679245033
At time: 252.08448147773743 and batch: 300, loss is 3.8959043836593628 and perplexity is 49.20052940277436
At time: 252.92128324508667 and batch: 350, loss is 3.913415174484253 and perplexity is 50.06965692866528
At time: 253.75453543663025 and batch: 400, loss is 3.8755262422561647 and perplexity is 48.20806073576537
At time: 254.58361506462097 and batch: 450, loss is 3.9255698347091674 and perplexity is 50.681950166225924
At time: 255.41852736473083 and batch: 500, loss is 3.9357370567321777 and perplexity is 51.19987326411669
At time: 256.298499584198 and batch: 550, loss is 3.9007362508773804 and perplexity is 49.438835094993564
At time: 257.1318209171295 and batch: 600, loss is 3.8877337980270386 and perplexity is 48.8001700764917
At time: 257.9644227027893 and batch: 650, loss is 3.937572636604309 and perplexity is 51.29394102897158
At time: 258.8000154495239 and batch: 700, loss is 3.975795226097107 and perplexity is 53.29247963011258
At time: 259.6328082084656 and batch: 750, loss is 3.9523952770233155 and perplexity is 52.05991553047454
At time: 260.4659650325775 and batch: 800, loss is 3.9319507694244384 and perplexity is 51.00638237103184
At time: 261.2943985462189 and batch: 850, loss is 3.916348752975464 and perplexity is 50.21675585492361
At time: 262.1268222332001 and batch: 900, loss is 3.893360319137573 and perplexity is 49.075519165946616
At time: 262.9563162326813 and batch: 950, loss is 3.989381055831909 and perplexity is 54.021442756657194
At time: 263.7941641807556 and batch: 1000, loss is 3.968171772956848 and perplexity is 52.88775158171103
At time: 264.6251337528229 and batch: 1050, loss is 3.919300174713135 and perplexity is 50.36518561140779
At time: 265.45736026763916 and batch: 1100, loss is 3.9454180097579954 and perplexity is 51.697943841083536
At time: 266.28920793533325 and batch: 1150, loss is 3.908978910446167 and perplexity is 49.84802667886841
At time: 267.1214506626129 and batch: 1200, loss is 3.9856301593780517 and perplexity is 53.819193463790846
At time: 267.9512903690338 and batch: 1250, loss is 3.977696352005005 and perplexity is 53.3938917118572
At time: 268.7810106277466 and batch: 1300, loss is 3.9788535022735596 and perplexity is 53.455712228906584
At time: 269.61525297164917 and batch: 1350, loss is 3.859345636367798 and perplexity is 47.43430192904808
At time: 270.445289850235 and batch: 1400, loss is 3.8952176904678346 and perplexity is 49.16675533175338
At time: 271.27996039390564 and batch: 1450, loss is 3.8282786893844603 and perplexity is 45.98331849861921
At time: 272.11319947242737 and batch: 1500, loss is 3.831828098297119 and perplexity is 46.14682209804274
At time: 272.9501748085022 and batch: 1550, loss is 3.849720792770386 and perplexity is 46.97994426012437
At time: 273.78229331970215 and batch: 1600, loss is 3.9292247772216795 and perplexity is 50.86752871337702
At time: 274.61320877075195 and batch: 1650, loss is 3.8953671503067016 and perplexity is 49.17410433625971
At time: 275.44482040405273 and batch: 1700, loss is 3.907092547416687 and perplexity is 49.75408383725742
At time: 276.28078532218933 and batch: 1750, loss is 3.911028299331665 and perplexity is 49.95028942298177
At time: 277.1117787361145 and batch: 1800, loss is 3.8675145387649534 and perplexity is 47.82337509855724
At time: 277.9428014755249 and batch: 1850, loss is 3.9053878164291382 and perplexity is 49.669338763083125
At time: 278.77619218826294 and batch: 1900, loss is 3.982295832633972 and perplexity is 53.640041529203394
At time: 279.6086800098419 and batch: 1950, loss is 3.9127407312393188 and perplexity is 50.035899171898706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330058253088663 and perplexity of 75.94871068730431
finished 8 epochs...
Completing Train Step...
At time: 282.8208739757538 and batch: 50, loss is 3.905023684501648 and perplexity is 49.65125586350251
At time: 283.70065236091614 and batch: 100, loss is 3.8707513093948362 and perplexity is 47.978419180200724
At time: 284.53670740127563 and batch: 150, loss is 3.860158267021179 and perplexity is 47.472864163122
At time: 285.3684320449829 and batch: 200, loss is 3.8523651456832884 and perplexity is 47.104340213489834
At time: 286.2007141113281 and batch: 250, loss is 3.8315424013137815 and perplexity is 46.133639973315006
At time: 287.03147196769714 and batch: 300, loss is 3.843329668045044 and perplexity is 46.68064701853786
At time: 287.86572766304016 and batch: 350, loss is 3.8552527379989625 and perplexity is 47.2405549159406
At time: 288.69831347465515 and batch: 400, loss is 3.8239969491958616 and perplexity is 45.78685078780348
At time: 289.5266513824463 and batch: 450, loss is 3.87374351978302 and perplexity is 48.1221957020083
At time: 290.35828828811646 and batch: 500, loss is 3.8865023612976075 and perplexity is 48.74011274065107
At time: 291.186559677124 and batch: 550, loss is 3.8507246828079222 and perplexity is 47.027130639136175
At time: 292.02026629447937 and batch: 600, loss is 3.8390948152542115 and perplexity is 46.483379344828904
At time: 292.8520863056183 and batch: 650, loss is 3.8885713815689087 and perplexity is 48.84106141835511
At time: 293.6878442764282 and batch: 700, loss is 3.9221339273452758 and perplexity is 50.50811049994954
At time: 294.51874685287476 and batch: 750, loss is 3.9022164869308473 and perplexity is 49.512070430562474
At time: 295.35263895988464 and batch: 800, loss is 3.8813066148757933 and perplexity is 48.48752822505267
At time: 296.23231172561646 and batch: 850, loss is 3.8682396602630615 and perplexity is 47.85806543178648
At time: 297.0753526687622 and batch: 900, loss is 3.838298854827881 and perplexity is 46.446395135324515
At time: 297.90989875793457 and batch: 950, loss is 3.938795623779297 and perplexity is 51.356711236760376
At time: 298.7876498699188 and batch: 1000, loss is 3.917925224304199 and perplexity is 50.29598356444878
At time: 299.622519493103 and batch: 1050, loss is 3.8689833164215086 and perplexity is 47.89366861349807
At time: 300.4574954509735 and batch: 1100, loss is 3.891591968536377 and perplexity is 48.98881312805722
At time: 301.3172161579132 and batch: 1150, loss is 3.8590794897079466 and perplexity is 47.42167912785999
At time: 302.17262625694275 and batch: 1200, loss is 3.934601707458496 and perplexity is 51.14177651148728
At time: 303.0185213088989 and batch: 1250, loss is 3.934822750091553 and perplexity is 51.1530822739083
At time: 303.86947083473206 and batch: 1300, loss is 3.9328156185150145 and perplexity is 51.05051427540693
At time: 304.70650124549866 and batch: 1350, loss is 3.8101975965499877 and perplexity is 45.15936131876301
At time: 305.54217171669006 and batch: 1400, loss is 3.8446184492111204 and perplexity is 46.7408469411664
At time: 306.3793296813965 and batch: 1450, loss is 3.7782456159591673 and perplexity is 43.739238961700046
At time: 307.2170581817627 and batch: 1500, loss is 3.7814073038101195 and perplexity is 43.87774762733702
At time: 308.04850339889526 and batch: 1550, loss is 3.797765612602234 and perplexity is 44.60141623198431
At time: 308.88148498535156 and batch: 1600, loss is 3.8796995782852175 and perplexity is 48.40966957061798
At time: 309.716903924942 and batch: 1650, loss is 3.843887357711792 and perplexity is 46.7066875936221
At time: 310.5489137172699 and batch: 1700, loss is 3.862391128540039 and perplexity is 47.57898292486224
At time: 311.3844916820526 and batch: 1750, loss is 3.8636468982696535 and perplexity is 47.63876870211314
At time: 312.2154698371887 and batch: 1800, loss is 3.824396014213562 and perplexity is 45.8051263645527
At time: 313.0481119155884 and batch: 1850, loss is 3.8571210050582887 and perplexity is 47.32889538465273
At time: 313.88257479667664 and batch: 1900, loss is 3.9321264314651487 and perplexity is 51.01534304325033
At time: 314.7156047821045 and batch: 1950, loss is 3.8607200813293456 and perplexity is 47.49954259091799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3376555686773255 and perplexity of 76.52791442179947
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 317.86282110214233 and batch: 50, loss is 3.894102387428284 and perplexity is 49.11195006800667
At time: 318.72328901290894 and batch: 100, loss is 3.881295304298401 and perplexity is 48.48697980621358
At time: 319.5577688217163 and batch: 150, loss is 3.8681386709213257 and perplexity is 47.853232521302104
At time: 320.4149794578552 and batch: 200, loss is 3.864062480926514 and perplexity is 47.6585706625706
At time: 321.24652767181396 and batch: 250, loss is 3.8330332803726197 and perplexity is 46.20247094763898
At time: 322.07424235343933 and batch: 300, loss is 3.8439077138900757 and perplexity is 46.70763837295889
At time: 322.90847635269165 and batch: 350, loss is 3.856413025856018 and perplexity is 47.295399369694046
At time: 323.7385869026184 and batch: 400, loss is 3.8193186044692995 and perplexity is 45.57314440172752
At time: 324.5696949958801 and batch: 450, loss is 3.8600382900238035 and perplexity is 47.46716885308282
At time: 325.4018943309784 and batch: 500, loss is 3.8714640808105467 and perplexity is 48.0126290164117
At time: 326.23131370544434 and batch: 550, loss is 3.8265646791458128 and perplexity is 45.904570126942374
At time: 327.06027030944824 and batch: 600, loss is 3.80365225315094 and perplexity is 44.864743032003126
At time: 327.8883876800537 and batch: 650, loss is 3.8500377321243286 and perplexity is 46.99483641313646
At time: 328.7188997268677 and batch: 700, loss is 3.872791357040405 and perplexity is 48.076397347371625
At time: 329.54720091819763 and batch: 750, loss is 3.84653528213501 and perplexity is 46.830527259107754
At time: 330.3783836364746 and batch: 800, loss is 3.815293035507202 and perplexity is 45.390055332206124
At time: 331.2076814174652 and batch: 850, loss is 3.8054478645324705 and perplexity is 44.94537504543675
At time: 332.04481744766235 and batch: 900, loss is 3.7711090230941773 and perplexity is 43.42820101671592
At time: 332.8767008781433 and batch: 950, loss is 3.8623081636428833 and perplexity is 47.57503570317978
At time: 333.70592045783997 and batch: 1000, loss is 3.8335554218292236 and perplexity is 46.22660147234371
At time: 334.5347833633423 and batch: 1050, loss is 3.771900873184204 and perplexity is 43.46260326051304
At time: 335.36777782440186 and batch: 1100, loss is 3.785280227661133 and perplexity is 44.04801230088502
At time: 336.2136642932892 and batch: 1150, loss is 3.7581755447387697 and perplexity is 42.870139933433634
At time: 337.0441348552704 and batch: 1200, loss is 3.8133469343185427 and perplexity is 45.30180758894162
At time: 337.87504601478577 and batch: 1250, loss is 3.8019611167907716 and perplexity is 44.78893475290797
At time: 338.70590901374817 and batch: 1300, loss is 3.8083409118652343 and perplexity is 45.07559241451457
At time: 339.53945446014404 and batch: 1350, loss is 3.6838496923446655 and perplexity is 39.79931465206093
At time: 340.3775210380554 and batch: 1400, loss is 3.7031984758377074 and perplexity is 40.57688119949157
At time: 341.208975315094 and batch: 1450, loss is 3.6313964700698853 and perplexity is 37.76551822638408
At time: 342.00703024864197 and batch: 1500, loss is 3.623625602722168 and perplexity is 37.47318470750604
At time: 342.83021998405457 and batch: 1550, loss is 3.637913236618042 and perplexity is 38.01243095471112
At time: 343.66263818740845 and batch: 1600, loss is 3.7132974529266356 and perplexity is 40.98874238093484
At time: 344.49253153800964 and batch: 1650, loss is 3.671234540939331 and perplexity is 39.30039386909343
At time: 345.3277373313904 and batch: 1700, loss is 3.669483184814453 and perplexity is 39.231625120442814
At time: 346.16556906700134 and batch: 1750, loss is 3.656998076438904 and perplexity is 38.744859015841264
At time: 346.9991936683655 and batch: 1800, loss is 3.6211796045303344 and perplexity is 37.38163737341932
At time: 347.83380484580994 and batch: 1850, loss is 3.6398515415191652 and perplexity is 38.08618208893631
At time: 348.6659927368164 and batch: 1900, loss is 3.713542547225952 and perplexity is 40.99878971925093
At time: 349.49662923812866 and batch: 1950, loss is 3.6375684261322023 and perplexity is 37.999326129396124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.277442257903343 and perplexity of 72.05590369159287
finished 10 epochs...
Completing Train Step...
At time: 352.6210482120514 and batch: 50, loss is 3.8009867906570434 and perplexity is 44.745316975697044
At time: 353.4781472682953 and batch: 100, loss is 3.7813386297225953 and perplexity is 43.87473446652032
At time: 354.30958247184753 and batch: 150, loss is 3.7616292524337767 and perplexity is 43.018456839799995
At time: 355.15144991874695 and batch: 200, loss is 3.758019766807556 and perplexity is 42.863462231856744
At time: 355.9831929206848 and batch: 250, loss is 3.728476643562317 and perplexity is 41.61566436232166
At time: 356.8142056465149 and batch: 300, loss is 3.7369730854034424 and perplexity is 41.97075580499713
At time: 357.6429364681244 and batch: 350, loss is 3.7521265506744386 and perplexity is 42.61160144865271
At time: 358.4741904735565 and batch: 400, loss is 3.7199430799484254 and perplexity is 41.26204540401476
At time: 359.3085765838623 and batch: 450, loss is 3.764684805870056 and perplexity is 43.15010305702078
At time: 360.1399428844452 and batch: 500, loss is 3.7815864086151123 and perplexity is 43.88560704657821
At time: 360.9668083190918 and batch: 550, loss is 3.738457274436951 and perplexity is 42.03309459031833
At time: 361.79746317863464 and batch: 600, loss is 3.7176879024505616 and perplexity is 41.169097014655144
At time: 362.6540608406067 and batch: 650, loss is 3.7650747537612914 and perplexity is 43.16693262982941
At time: 363.4829773902893 and batch: 700, loss is 3.7931236124038694 and perplexity is 44.39485624565247
At time: 364.3170347213745 and batch: 750, loss is 3.7714337873458863 and perplexity is 43.44230723439581
At time: 365.1467230319977 and batch: 800, loss is 3.7408403396606444 and perplexity is 42.13338164411504
At time: 365.9755835533142 and batch: 850, loss is 3.7324599170684816 and perplexity is 41.78176152120922
At time: 366.80360674858093 and batch: 900, loss is 3.6954555892944336 and perplexity is 40.26391221734326
At time: 367.63870787620544 and batch: 950, loss is 3.793419904708862 and perplexity is 44.40801204882469
At time: 368.47012591362 and batch: 1000, loss is 3.76715181350708 and perplexity is 43.256686107343896
At time: 369.30255603790283 and batch: 1050, loss is 3.7089076709747313 and perplexity is 40.809205092483666
At time: 370.1339156627655 and batch: 1100, loss is 3.722016649246216 and perplexity is 41.34769388286816
At time: 370.9624400138855 and batch: 1150, loss is 3.698305244445801 and perplexity is 40.37881411985141
At time: 371.7949073314667 and batch: 1200, loss is 3.757325596809387 and perplexity is 42.83371802731935
At time: 372.62550473213196 and batch: 1250, loss is 3.7506650638580323 and perplexity is 42.54937064073901
At time: 373.4575626850128 and batch: 1300, loss is 3.758841562271118 and perplexity is 42.89870170850922
At time: 374.2871313095093 and batch: 1350, loss is 3.6338957595825194 and perplexity is 37.86002323852596
At time: 375.12257742881775 and batch: 1400, loss is 3.65919716835022 and perplexity is 38.83015627579046
At time: 375.9526948928833 and batch: 1450, loss is 3.5871335649490357 and perplexity is 36.13036201680782
At time: 376.7821159362793 and batch: 1500, loss is 3.5826154470443727 and perplexity is 35.96748899809452
At time: 377.61063170433044 and batch: 1550, loss is 3.6014084959030153 and perplexity is 36.649819226899325
At time: 378.4423260688782 and batch: 1600, loss is 3.680475978851318 and perplexity is 39.66526940945639
At time: 379.2754280567169 and batch: 1650, loss is 3.6380184745788573 and perplexity is 38.0164315159322
At time: 380.1072278022766 and batch: 1700, loss is 3.6422867441177367 and perplexity is 38.17904267981482
At time: 380.9362289905548 and batch: 1750, loss is 3.6342730283737184 and perplexity is 37.874309338408295
At time: 381.7662444114685 and batch: 1800, loss is 3.6035644674301146 and perplexity is 36.72892043295994
At time: 382.5992238521576 and batch: 1850, loss is 3.622356753349304 and perplexity is 37.425667033351445
At time: 383.428341627121 and batch: 1900, loss is 3.699507598876953 and perplexity is 40.427392964575326
At time: 384.26322770118713 and batch: 1950, loss is 3.6271659326553345 and perplexity is 37.60608726565353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.282380143986192 and perplexity of 72.41258744274106
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 387.41083788871765 and batch: 50, loss is 3.7797206115722655 and perplexity is 43.80380175049863
At time: 388.2408366203308 and batch: 100, loss is 3.7916050148010254 and perplexity is 44.32748948782411
At time: 389.0707628726959 and batch: 150, loss is 3.7850928020477297 and perplexity is 44.03975734877923
At time: 389.90046763420105 and batch: 200, loss is 3.78745551109314 and perplexity is 44.14393350233233
At time: 390.73592138290405 and batch: 250, loss is 3.7737029552459718 and perplexity is 43.54099705301483
At time: 391.56905341148376 and batch: 300, loss is 3.777884578704834 and perplexity is 43.723450317274605
At time: 392.40327525138855 and batch: 350, loss is 3.7954099130630494 and perplexity is 44.49647235297395
At time: 393.23353600502014 and batch: 400, loss is 3.7664498043060304 and perplexity is 43.22633017200924
At time: 394.05906200408936 and batch: 450, loss is 3.8097383689880373 and perplexity is 45.13862765646433
At time: 394.88721537590027 and batch: 500, loss is 3.8177870225906374 and perplexity is 45.5033988237736
At time: 395.7188947200775 and batch: 550, loss is 3.7823265647888182 and perplexity is 43.91810127348845
At time: 396.5486469268799 and batch: 600, loss is 3.7533395719528198 and perplexity is 42.66332159039021
At time: 397.37869358062744 and batch: 650, loss is 3.790096473693848 and perplexity is 44.26067006035203
At time: 398.21369910240173 and batch: 700, loss is 3.8140166902542116 and perplexity is 45.33215890632377
At time: 399.04415249824524 and batch: 750, loss is 3.7861649894714358 and perplexity is 44.08700154554253
At time: 399.88001894950867 and batch: 800, loss is 3.7533698320388793 and perplexity is 42.66461260570614
At time: 400.7106909751892 and batch: 850, loss is 3.7432611322402956 and perplexity is 42.23550137723032
At time: 401.5419089794159 and batch: 900, loss is 3.706587553024292 and perplexity is 40.7146326752101
At time: 402.3701741695404 and batch: 950, loss is 3.8042846393585203 and perplexity is 44.893123849576185
At time: 403.20121717453003 and batch: 1000, loss is 3.775285792350769 and perplexity is 43.60996993074503
At time: 404.0583128929138 and batch: 1050, loss is 3.717084903717041 and perplexity is 41.14427958448658
At time: 404.89110708236694 and batch: 1100, loss is 3.723656349182129 and perplexity is 41.41554730830407
At time: 405.7287395000458 and batch: 1150, loss is 3.6969129037857056 and perplexity is 40.32263217642426
At time: 406.55615186691284 and batch: 1200, loss is 3.7474245548248293 and perplexity is 42.4117121830199
At time: 407.38744950294495 and batch: 1250, loss is 3.7326100349426268 and perplexity is 41.78803418123424
At time: 408.2177562713623 and batch: 1300, loss is 3.737513709068298 and perplexity is 41.993452323401876
At time: 409.04961609840393 and batch: 1350, loss is 3.6141922187805178 and perplexity is 37.121347883687925
At time: 409.880078792572 and batch: 1400, loss is 3.6316438627243044 and perplexity is 37.774862293962805
At time: 410.70960760116577 and batch: 1450, loss is 3.5527423810958862 and perplexity is 34.908919900574084
At time: 411.5455002784729 and batch: 1500, loss is 3.549936947822571 and perplexity is 34.811122501330956
At time: 412.38235425949097 and batch: 1550, loss is 3.5663531255722045 and perplexity is 35.38730448935111
At time: 413.21392917633057 and batch: 1600, loss is 3.647813138961792 and perplexity is 38.39061923373949
At time: 414.04990887641907 and batch: 1650, loss is 3.603396134376526 and perplexity is 36.7227382619749
At time: 414.8821406364441 and batch: 1700, loss is 3.601184778213501 and perplexity is 36.641620931106864
At time: 415.7161867618561 and batch: 1750, loss is 3.591841721534729 and perplexity is 36.30087049401773
At time: 416.5520279407501 and batch: 1800, loss is 3.556647310256958 and perplexity is 35.04550326049063
At time: 417.38468408584595 and batch: 1850, loss is 3.5742748308181764 and perplexity is 35.668745559786466
At time: 418.2236852645874 and batch: 1900, loss is 3.6555677604675294 and perplexity is 38.68948123848297
At time: 419.0590441226959 and batch: 1950, loss is 3.5920759630203247 and perplexity is 36.309374659826005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257773323946221 and perplexity of 70.65248797053458
finished 12 epochs...
Completing Train Step...
At time: 422.1957337856293 and batch: 50, loss is 3.77855233669281 and perplexity is 43.75265675081522
At time: 423.0275936126709 and batch: 100, loss is 3.7624171924591066 and perplexity is 43.05236616127343
At time: 423.8593940734863 and batch: 150, loss is 3.747114748954773 and perplexity is 42.39857482074752
At time: 424.6958112716675 and batch: 200, loss is 3.74409601688385 and perplexity is 42.270777872596064
At time: 425.5547025203705 and batch: 250, loss is 3.7253529453277587 and perplexity is 41.48587240601247
At time: 426.3848731517792 and batch: 300, loss is 3.728747353553772 and perplexity is 41.62693166348227
At time: 427.2203600406647 and batch: 350, loss is 3.7448927974700927 and perplexity is 42.30447182933304
At time: 428.0518524646759 and batch: 400, loss is 3.715729217529297 and perplexity is 41.08853864509714
At time: 428.8887367248535 and batch: 450, loss is 3.7616713762283327 and perplexity is 43.02026897860485
At time: 429.72014021873474 and batch: 500, loss is 3.771483235359192 and perplexity is 43.44445542329337
At time: 430.5549623966217 and batch: 550, loss is 3.738054757118225 and perplexity is 42.01617894643428
At time: 431.38960671424866 and batch: 600, loss is 3.7111344385147094 and perplexity is 40.900178956949
At time: 432.2221357822418 and batch: 650, loss is 3.748906888961792 and perplexity is 42.47462713076288
At time: 433.05319476127625 and batch: 700, loss is 3.7761837244033813 and perplexity is 43.64914630678891
At time: 433.8830108642578 and batch: 750, loss is 3.750510506629944 and perplexity is 42.54279483613803
At time: 434.7188153266907 and batch: 800, loss is 3.719360980987549 and perplexity is 41.23803379950448
At time: 435.5547046661377 and batch: 850, loss is 3.7104350996017454 and perplexity is 40.87158586955189
At time: 436.3933024406433 and batch: 900, loss is 3.673071765899658 and perplexity is 39.37266390148578
At time: 437.2216069698334 and batch: 950, loss is 3.7732232141494753 and perplexity is 43.52011365705823
At time: 438.0510711669922 and batch: 1000, loss is 3.7444338417053222 and perplexity is 42.285060402945156
At time: 438.885525226593 and batch: 1050, loss is 3.6890550088882446 and perplexity is 40.00702280739798
At time: 439.71656131744385 and batch: 1100, loss is 3.6964578104019163 and perplexity is 40.304285788280374
At time: 440.54979491233826 and batch: 1150, loss is 3.671251068115234 and perplexity is 39.301043398983396
At time: 441.3809959888458 and batch: 1200, loss is 3.724309720993042 and perplexity is 41.442615901413745
At time: 442.2148983478546 and batch: 1250, loss is 3.712125401496887 and perplexity is 40.940729609038925
At time: 443.04586815834045 and batch: 1300, loss is 3.7198912525177 and perplexity is 41.25990695363068
At time: 443.877649307251 and batch: 1350, loss is 3.59765043258667 and perplexity is 36.51234536524594
At time: 444.70721411705017 and batch: 1400, loss is 3.6176183223724365 and perplexity is 37.24874758467559
At time: 445.54532957077026 and batch: 1450, loss is 3.5403171825408934 and perplexity is 34.47785322981457
At time: 446.3737111091614 and batch: 1500, loss is 3.5401905584335327 and perplexity is 34.47348777881713
At time: 447.2069761753082 and batch: 1550, loss is 3.559722857475281 and perplexity is 35.15345327815493
At time: 448.0405352115631 and batch: 1600, loss is 3.643396077156067 and perplexity is 38.221419453863305
At time: 448.8759956359863 and batch: 1650, loss is 3.600017294883728 and perplexity is 36.59886741136087
At time: 449.7061576843262 and batch: 1700, loss is 3.599523162841797 and perplexity is 36.58078720564691
At time: 450.5421373844147 and batch: 1750, loss is 3.5923361015319824 and perplexity is 36.31882135518059
At time: 451.371497631073 and batch: 1800, loss is 3.559091663360596 and perplexity is 35.13127162653532
At time: 452.2039966583252 and batch: 1850, loss is 3.577591824531555 and perplexity is 35.78725500345438
At time: 453.03751516342163 and batch: 1900, loss is 3.6596850776672363 and perplexity is 38.84910649343656
At time: 453.8727216720581 and batch: 1950, loss is 3.5964574813842773 and perplexity is 36.468813889566015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258043298055959 and perplexity of 70.67156488809626
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 457.0230875015259 and batch: 50, loss is 3.774250545501709 and perplexity is 43.564846207912616
At time: 457.85782980918884 and batch: 100, loss is 3.772150821685791 and perplexity is 43.47346803083303
At time: 458.68720293045044 and batch: 150, loss is 3.764822144508362 and perplexity is 43.15602964038251
At time: 459.5232129096985 and batch: 200, loss is 3.766801347732544 and perplexity is 43.241528775561584
At time: 460.35367155075073 and batch: 250, loss is 3.7601924896240235 and perplexity is 42.95669390085116
At time: 461.19310426712036 and batch: 300, loss is 3.7670228385925295 and perplexity is 43.251107439711284
At time: 462.0288197994232 and batch: 350, loss is 3.790529975891113 and perplexity is 44.27986131750115
At time: 462.8605492115021 and batch: 400, loss is 3.760435461997986 and perplexity is 42.967132458835074
At time: 463.69269728660583 and batch: 450, loss is 3.8112756776809693 and perplexity is 45.20807302695671
At time: 464.52284121513367 and batch: 500, loss is 3.8153138971328735 and perplexity is 45.39100225242678
At time: 465.3569884300232 and batch: 550, loss is 3.780865874290466 and perplexity is 43.8539973496466
At time: 466.1983916759491 and batch: 600, loss is 3.7461958026885984 and perplexity is 42.3596307052402
At time: 467.0269286632538 and batch: 650, loss is 3.7745103549957277 and perplexity is 43.576166239025
At time: 467.8829662799835 and batch: 700, loss is 3.7999839639663695 and perplexity is 44.70046766935049
At time: 468.71867418289185 and batch: 750, loss is 3.7650551128387453 and perplexity is 43.166084799775184
At time: 469.5546963214874 and batch: 800, loss is 3.7359408712387085 and perplexity is 41.92745534786782
At time: 470.3887014389038 and batch: 850, loss is 3.7248304748535155 and perplexity is 41.46420292390734
At time: 471.2180013656616 and batch: 900, loss is 3.684088206291199 and perplexity is 39.80880847582759
At time: 472.04793763160706 and batch: 950, loss is 3.791340093612671 and perplexity is 44.3157477520182
At time: 472.8804759979248 and batch: 1000, loss is 3.7599031591415404 and perplexity is 42.94426701770368
At time: 473.7111191749573 and batch: 1050, loss is 3.710279941558838 and perplexity is 40.865244806224055
At time: 474.5436804294586 and batch: 1100, loss is 3.7176128387451173 and perplexity is 41.16600682566539
At time: 475.3728539943695 and batch: 1150, loss is 3.6910218095779417 and perplexity is 40.08578607788563
At time: 476.2062976360321 and batch: 1200, loss is 3.735068664550781 and perplexity is 41.890901884310644
At time: 477.0378530025482 and batch: 1250, loss is 3.720436482429504 and perplexity is 41.28240922295776
At time: 477.8713421821594 and batch: 1300, loss is 3.720499105453491 and perplexity is 41.2849945332099
At time: 478.7008354663849 and batch: 1350, loss is 3.5952401161193848 and perplexity is 36.424445034316115
At time: 479.53881573677063 and batch: 1400, loss is 3.613636293411255 and perplexity is 37.10071691982759
At time: 480.36980295181274 and batch: 1450, loss is 3.5326609802246094 and perplexity is 34.214891737757654
At time: 481.2034869194031 and batch: 1500, loss is 3.5316564655303955 and perplexity is 34.18053963273186
At time: 482.0367314815521 and batch: 1550, loss is 3.549069938659668 and perplexity is 34.780954019216395
At time: 482.8732306957245 and batch: 1600, loss is 3.634872455596924 and perplexity is 37.8970190362114
At time: 483.7053849697113 and batch: 1650, loss is 3.5877202129364014 and perplexity is 36.15156403942166
At time: 484.5414354801178 and batch: 1700, loss is 3.5874147748947145 and perplexity is 36.1405236626589
At time: 485.3734838962555 and batch: 1750, loss is 3.5813436698913574 and perplexity is 35.92177544222487
At time: 486.21199131011963 and batch: 1800, loss is 3.542966284751892 and perplexity is 34.56930967228333
At time: 487.0471601486206 and batch: 1850, loss is 3.5588770389556883 and perplexity is 35.12373240734799
At time: 487.8769648075104 and batch: 1900, loss is 3.645821113586426 and perplexity is 38.31422026565504
At time: 488.7130892276764 and batch: 1950, loss is 3.59361168384552 and perplexity is 36.3651785612802
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244055743550145 and perplexity of 69.68992390551088
finished 14 epochs...
Completing Train Step...
At time: 491.8950340747833 and batch: 50, loss is 3.787587947845459 and perplexity is 44.149780168668165
At time: 492.755254983902 and batch: 100, loss is 3.7673346281051634 and perplexity is 43.264594783917765
At time: 493.58621525764465 and batch: 150, loss is 3.7516465759277344 and perplexity is 42.59115386359552
At time: 494.41668486595154 and batch: 200, loss is 3.7463639640808104 and perplexity is 42.36675455867495
At time: 495.24818658828735 and batch: 250, loss is 3.7368283462524414 and perplexity is 41.96468143304537
At time: 496.08265709877014 and batch: 300, loss is 3.741382513046265 and perplexity is 42.15623143600345
At time: 496.91721200942993 and batch: 350, loss is 3.762170424461365 and perplexity is 43.04174352579492
At time: 497.7454843521118 and batch: 400, loss is 3.730412383079529 and perplexity is 41.69629946746369
At time: 498.5745759010315 and batch: 450, loss is 3.781635589599609 and perplexity is 43.88776543701346
At time: 499.40528202056885 and batch: 500, loss is 3.786194267272949 and perplexity is 44.08829233491875
At time: 500.2385642528534 and batch: 550, loss is 3.7528420877456665 and perplexity is 42.6421025401831
At time: 501.0697455406189 and batch: 600, loss is 3.720536479949951 and perplexity is 41.28653756792682
At time: 501.9044246673584 and batch: 650, loss is 3.7508727502822876 and perplexity is 42.55820848510008
At time: 502.7361445426941 and batch: 700, loss is 3.779476499557495 and perplexity is 43.793110021241596
At time: 503.5687084197998 and batch: 750, loss is 3.747241725921631 and perplexity is 42.40395880499112
At time: 504.4087610244751 and batch: 800, loss is 3.7184500455856324 and perplexity is 41.20048571914537
At time: 505.2386894226074 and batch: 850, loss is 3.7077549171447752 and perplexity is 40.76218922908053
At time: 506.06797647476196 and batch: 900, loss is 3.667314496040344 and perplexity is 39.146636126103125
At time: 506.88794708251953 and batch: 950, loss is 3.774644570350647 and perplexity is 43.582015222145685
At time: 507.718425989151 and batch: 1000, loss is 3.745172724723816 and perplexity is 42.31631566158081
At time: 508.51242899894714 and batch: 1050, loss is 3.696552901268005 and perplexity is 40.30811853995002
At time: 509.36372113227844 and batch: 1100, loss is 3.7039325523376463 and perplexity is 40.60667866989424
At time: 510.19611120224 and batch: 1150, loss is 3.678523840904236 and perplexity is 39.58791286175319
At time: 511.0305733680725 and batch: 1200, loss is 3.724362711906433 and perplexity is 41.4448120416709
At time: 511.8606526851654 and batch: 1250, loss is 3.711239233016968 and perplexity is 40.90446529543351
At time: 512.6939649581909 and batch: 1300, loss is 3.712698402404785 and perplexity is 40.96419540659452
At time: 513.5245509147644 and batch: 1350, loss is 3.5889483308792114 and perplexity is 36.195989698269656
At time: 514.3584897518158 and batch: 1400, loss is 3.6084954929351807 and perplexity is 36.91047894332807
At time: 515.1876866817474 and batch: 1450, loss is 3.5295294237136843 and perplexity is 34.1079134624478
At time: 516.0216288566589 and batch: 1500, loss is 3.530925087928772 and perplexity is 34.155549891215635
At time: 516.8541185855865 and batch: 1550, loss is 3.5503481435775757 and perplexity is 34.82543963050009
At time: 517.686407327652 and batch: 1600, loss is 3.6376733779907227 and perplexity is 38.00331443858249
At time: 518.5198202133179 and batch: 1650, loss is 3.591860809326172 and perplexity is 36.301563404075964
At time: 519.3525071144104 and batch: 1700, loss is 3.5924646520614623 and perplexity is 36.32349045899734
At time: 520.1845750808716 and batch: 1750, loss is 3.587332510948181 and perplexity is 36.13755072283718
At time: 521.021897315979 and batch: 1800, loss is 3.5497338724136354 and perplexity is 34.80405393614367
At time: 521.8568592071533 and batch: 1850, loss is 3.566348361968994 and perplexity is 35.387135918675334
At time: 522.7160184383392 and batch: 1900, loss is 3.65331422328949 and perplexity is 38.60239122126551
At time: 523.5586285591125 and batch: 1950, loss is 3.600497245788574 and perplexity is 36.61643728689286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242898630541425 and perplexity of 69.60933142427946
finished 15 epochs...
Completing Train Step...
At time: 526.7402725219727 and batch: 50, loss is 3.783872141838074 and perplexity is 43.986032565863944
At time: 527.6081883907318 and batch: 100, loss is 3.7607876300811767 and perplexity is 42.98226677626867
At time: 528.4570376873016 and batch: 150, loss is 3.7439644050598146 and perplexity is 42.26521490450107
At time: 529.3103139400482 and batch: 200, loss is 3.7377918434143065 and perplexity is 42.005133769230824
At time: 530.1783454418182 and batch: 250, loss is 3.7269533824920655 and perplexity is 41.5523210972988
At time: 531.0694432258606 and batch: 300, loss is 3.730938229560852 and perplexity is 41.71823108564962
At time: 531.9185173511505 and batch: 350, loss is 3.7514181756973266 and perplexity is 42.5814271450744
At time: 532.7539615631104 and batch: 400, loss is 3.7192481470108034 and perplexity is 41.23338101065898
At time: 533.5927793979645 and batch: 450, loss is 3.770865077972412 and perplexity is 43.41760821101503
At time: 534.4296231269836 and batch: 500, loss is 3.7753522062301634 and perplexity is 43.61286633420803
At time: 535.272429227829 and batch: 550, loss is 3.7421962594985962 and perplexity is 42.190549881140896
At time: 536.115903377533 and batch: 600, loss is 3.7104501295089722 and perplexity is 40.872200170312155
At time: 536.9608106613159 and batch: 650, loss is 3.741205987930298 and perplexity is 42.148790459139455
At time: 537.8038213253021 and batch: 700, loss is 3.770447840690613 and perplexity is 43.39949654487677
At time: 538.6469256877899 and batch: 750, loss is 3.739026255607605 and perplexity is 42.057017434863184
At time: 539.4897377490997 and batch: 800, loss is 3.7103645515441896 and perplexity is 40.868702560266705
At time: 540.3323476314545 and batch: 850, loss is 3.699786691665649 and perplexity is 40.438677533065125
At time: 541.1816020011902 and batch: 900, loss is 3.6596559190750124 and perplexity is 38.847973724697106
At time: 542.0360264778137 and batch: 950, loss is 3.767237968444824 and perplexity is 43.260413044987224
At time: 542.8708486557007 and batch: 1000, loss is 3.7378656005859376 and perplexity is 42.00823206335093
At time: 543.710061788559 and batch: 1050, loss is 3.6899939727783204 and perplexity is 40.04460559884434
At time: 544.5426969528198 and batch: 1100, loss is 3.697547926902771 and perplexity is 40.34824611185704
At time: 545.3842890262604 and batch: 1150, loss is 3.6725632095336915 and perplexity is 39.35264577321834
At time: 546.2239370346069 and batch: 1200, loss is 3.719208493232727 and perplexity is 41.231745983736765
At time: 547.0632627010345 and batch: 1250, loss is 3.706817002296448 and perplexity is 40.72397568987649
At time: 547.9026870727539 and batch: 1300, loss is 3.7091171741485596 and perplexity is 40.81775564612474
At time: 548.7536399364471 and batch: 1350, loss is 3.585748453140259 and perplexity is 36.08035206840349
At time: 549.5839734077454 and batch: 1400, loss is 3.6057598543167115 and perplexity is 36.80964319966728
At time: 550.4181447029114 and batch: 1450, loss is 3.5275462579727175 and perplexity is 34.04033884495367
At time: 551.2502555847168 and batch: 1500, loss is 3.529911131858826 and perplexity is 34.12093521592678
At time: 552.0977463722229 and batch: 1550, loss is 3.550132541656494 and perplexity is 34.81793200817122
At time: 552.9442157745361 and batch: 1600, loss is 3.638136477470398 and perplexity is 38.02091782947092
At time: 553.7883777618408 and batch: 1650, loss is 3.5926375198364258 and perplexity is 36.329770162735464
At time: 554.6513910293579 and batch: 1700, loss is 3.5934507989883424 and perplexity is 36.3593284253329
At time: 555.5023076534271 and batch: 1750, loss is 3.5886715126037596 and perplexity is 36.185971373514775
At time: 556.3337686061859 and batch: 1800, loss is 3.551435613632202 and perplexity is 34.863331852831756
At time: 557.1721727848053 and batch: 1850, loss is 3.568269901275635 and perplexity is 35.455199063353895
At time: 558.0185599327087 and batch: 1900, loss is 3.6550689220428465 and perplexity is 38.670186251550724
At time: 558.8643021583557 and batch: 1950, loss is 3.6017820692062377 and perplexity is 36.66351317861856
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242839866460756 and perplexity of 69.60524101609803
finished 16 epochs...
Completing Train Step...
At time: 562.0346972942352 and batch: 50, loss is 3.77890438079834 and perplexity is 43.768062327287694
At time: 562.9047844409943 and batch: 100, loss is 3.7548553371429443 and perplexity is 42.728038203355815
At time: 563.7354776859283 and batch: 150, loss is 3.7375621128082277 and perplexity is 41.99548501274137
At time: 564.571366071701 and batch: 200, loss is 3.731086883544922 and perplexity is 41.724433127876566
At time: 565.4034540653229 and batch: 250, loss is 3.719678854942322 and perplexity is 41.251144380041026
At time: 566.2386901378632 and batch: 300, loss is 3.723437910079956 and perplexity is 41.4065015213468
At time: 567.0762844085693 and batch: 350, loss is 3.743679304122925 and perplexity is 42.253166769682814
At time: 567.9122092723846 and batch: 400, loss is 3.711430892944336 and perplexity is 40.91230579361171
At time: 568.761227607727 and batch: 450, loss is 3.7633866024017335 and perplexity is 43.09412178897411
At time: 569.601175069809 and batch: 500, loss is 3.767857942581177 and perplexity is 43.28724169787917
At time: 570.4421427249908 and batch: 550, loss is 3.734831700325012 and perplexity is 41.880976415215855
At time: 571.2853257656097 and batch: 600, loss is 3.7034242057800295 and perplexity is 40.586041650399466
At time: 572.1430277824402 and batch: 650, loss is 3.73440101146698 and perplexity is 41.862942629064456
At time: 572.9923493862152 and batch: 700, loss is 3.763971939086914 and perplexity is 43.11935374324666
At time: 573.8879132270813 and batch: 750, loss is 3.7330990409851075 and perplexity is 41.808473779588496
At time: 574.7426681518555 and batch: 800, loss is 3.7044763660430906 and perplexity is 40.62876714375055
At time: 575.5752720832825 and batch: 850, loss is 3.6940487003326417 and perplexity is 40.20730519292206
At time: 576.4147839546204 and batch: 900, loss is 3.654035882949829 and perplexity is 38.6302590641421
At time: 577.2516360282898 and batch: 950, loss is 3.7618517160415648 and perplexity is 43.02802794548193
At time: 578.092031955719 and batch: 1000, loss is 3.7324676084518433 and perplexity is 41.78208288199046
At time: 578.928172826767 and batch: 1050, loss is 3.6851011753082275 and perplexity is 39.84915399634966
At time: 579.7661061286926 and batch: 1100, loss is 3.692844190597534 and perplexity is 40.15890425794528
At time: 580.6043362617493 and batch: 1150, loss is 3.6680980348587036 and perplexity is 39.1773210549627
At time: 581.4509196281433 and batch: 1200, loss is 3.7152114009857176 and perplexity is 41.067267827701066
At time: 582.2924151420593 and batch: 1250, loss is 3.703344521522522 and perplexity is 40.582807710654144
At time: 583.1401417255402 and batch: 1300, loss is 3.706144413948059 and perplexity is 40.69659442751863
At time: 583.9783525466919 and batch: 1350, loss is 3.5829678773880005 and perplexity is 35.980167266573574
At time: 584.8234858512878 and batch: 1400, loss is 3.6032606077194216 and perplexity is 36.71776168925528
At time: 585.6629977226257 and batch: 1450, loss is 3.52545111656189 and perplexity is 33.96909418128498
At time: 586.4972951412201 and batch: 1500, loss is 3.528387088775635 and perplexity is 34.068973046968765
At time: 587.3395390510559 and batch: 1550, loss is 3.5489926385879516 and perplexity is 34.778265552887
At time: 588.1793043613434 and batch: 1600, loss is 3.6374375581741334 and perplexity is 37.99435356055963
At time: 589.0177686214447 and batch: 1650, loss is 3.5920863008499144 and perplexity is 36.309750021893954
At time: 589.8540766239166 and batch: 1700, loss is 3.5930503463745116 and perplexity is 36.34477115217142
At time: 590.6967737674713 and batch: 1750, loss is 3.58847044467926 and perplexity is 36.17869626677452
At time: 591.5327663421631 and batch: 1800, loss is 3.5515499019622805 and perplexity is 34.867316552508186
At time: 592.3747448921204 and batch: 1850, loss is 3.568474016189575 and perplexity is 35.462436736892876
At time: 593.2126767635345 and batch: 1900, loss is 3.655220947265625 and perplexity is 38.6760655421194
At time: 594.0477559566498 and batch: 1950, loss is 3.601596531867981 and perplexity is 36.65671135898752
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243108421148256 and perplexity of 69.6239363400936
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 597.2126929759979 and batch: 50, loss is 3.7785595417022706 and perplexity is 43.75297199025668
At time: 598.0467121601105 and batch: 100, loss is 3.760524563789368 and perplexity is 42.970961077873575
At time: 598.8865745067596 and batch: 150, loss is 3.7462125396728516 and perplexity is 42.36033968364535
At time: 599.7218780517578 and batch: 200, loss is 3.7405093479156495 and perplexity is 42.119438150320086
At time: 600.5596644878387 and batch: 250, loss is 3.7330909538269044 and perplexity is 41.80813566921399
At time: 601.3926525115967 and batch: 300, loss is 3.73773512840271 and perplexity is 42.00275151513741
At time: 602.2267889976501 and batch: 350, loss is 3.7606322956085205 and perplexity is 42.975590667053794
At time: 603.0600326061249 and batch: 400, loss is 3.7283682012557984 and perplexity is 41.61115170837663
At time: 603.8933475017548 and batch: 450, loss is 3.7838556241989134 and perplexity is 43.985306026450296
At time: 604.7226967811584 and batch: 500, loss is 3.787015190124512 and perplexity is 44.12450028151482
At time: 605.5519368648529 and batch: 550, loss is 3.753016486167908 and perplexity is 42.64953990410058
At time: 606.3825612068176 and batch: 600, loss is 3.7178069972991943 and perplexity is 41.174000334006685
At time: 607.2145562171936 and batch: 650, loss is 3.7460304403305056 and perplexity is 42.352626595942816
At time: 608.0506811141968 and batch: 700, loss is 3.7761642122268677 and perplexity is 43.64829462525061
At time: 608.8823556900024 and batch: 750, loss is 3.741136555671692 and perplexity is 42.145864075014266
At time: 609.7115793228149 and batch: 800, loss is 3.711600489616394 and perplexity is 40.919244972934756
At time: 610.5413815975189 and batch: 850, loss is 3.702313289642334 and perplexity is 40.540978996813834
At time: 611.3717818260193 and batch: 900, loss is 3.6574373197555543 and perplexity is 38.761881174379546
At time: 612.20232462883 and batch: 950, loss is 3.7666557264328 and perplexity is 43.2352323463966
At time: 613.0318033695221 and batch: 1000, loss is 3.733479585647583 and perplexity is 41.82438679874678
At time: 613.8621349334717 and batch: 1050, loss is 3.6866737031936645 and perplexity is 39.911867198426194
At time: 614.6976692676544 and batch: 1100, loss is 3.6922495985031127 and perplexity is 40.13503318843077
At time: 615.5629138946533 and batch: 1150, loss is 3.670604329109192 and perplexity is 39.275634098717575
At time: 616.3925638198853 and batch: 1200, loss is 3.7196286869049073 and perplexity is 41.249074942996614
At time: 617.2226936817169 and batch: 1250, loss is 3.7057248735427857 and perplexity is 40.67952414288672
At time: 618.0561437606812 and batch: 1300, loss is 3.708454923629761 and perplexity is 40.79073301513521
At time: 618.8947591781616 and batch: 1350, loss is 3.5822060823440554 and perplexity is 35.9527681910346
At time: 619.7328383922577 and batch: 1400, loss is 3.6020322704315184 and perplexity is 36.67268758221459
At time: 620.5725569725037 and batch: 1450, loss is 3.5225226736068724 and perplexity is 33.8697631403717
At time: 621.4064009189606 and batch: 1500, loss is 3.5243104887008667 and perplexity is 33.9303701750867
At time: 622.2498672008514 and batch: 1550, loss is 3.5439176034927367 and perplexity is 34.60221175213383
At time: 623.0866956710815 and batch: 1600, loss is 3.6303637170791627 and perplexity is 37.72653590750761
At time: 623.9205753803253 and batch: 1650, loss is 3.580089135169983 and perplexity is 35.876738583737335
At time: 624.7520430088043 and batch: 1700, loss is 3.5803804349899293 and perplexity is 35.88719099354568
At time: 625.5884492397308 and batch: 1750, loss is 3.576132616996765 and perplexity is 35.73507205344019
At time: 626.4380435943604 and batch: 1800, loss is 3.538139672279358 and perplexity is 34.40285903056255
At time: 627.2790083885193 and batch: 1850, loss is 3.555251913070679 and perplexity is 34.99663496711817
At time: 628.1134524345398 and batch: 1900, loss is 3.6412370824813842 and perplexity is 38.13898862867918
At time: 628.9544529914856 and batch: 1950, loss is 3.590970129966736 and perplexity is 36.2692447457542
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240273267169331 and perplexity of 69.4268213177064
finished 18 epochs...
Completing Train Step...
At time: 632.1040506362915 and batch: 50, loss is 3.7778212213516236 and perplexity is 43.720680202943754
At time: 632.9387602806091 and batch: 100, loss is 3.7573481369018555 and perplexity is 42.83468351416549
At time: 633.7750239372253 and batch: 150, loss is 3.7414403533935547 and perplexity is 42.15866983758846
At time: 634.6115701198578 and batch: 200, loss is 3.7344087266922 and perplexity is 41.86326561234115
At time: 635.4482021331787 and batch: 250, loss is 3.7263345956802367 and perplexity is 41.526617022494335
At time: 636.2870581150055 and batch: 300, loss is 3.729149842262268 and perplexity is 41.64368940562093
At time: 637.154215335846 and batch: 350, loss is 3.7513967514038087 and perplexity is 42.580514877853204
At time: 637.9966163635254 and batch: 400, loss is 3.719111580848694 and perplexity is 41.22775031055386
At time: 638.8314576148987 and batch: 450, loss is 3.77390052318573 and perplexity is 43.549600207923426
At time: 639.6650822162628 and batch: 500, loss is 3.777837285995483 and perplexity is 43.721382565742104
At time: 640.5002312660217 and batch: 550, loss is 3.7438010358810425 and perplexity is 42.258310635039265
At time: 641.3383440971375 and batch: 600, loss is 3.7095086908340456 and perplexity is 40.833739607313866
At time: 642.1763687133789 and batch: 650, loss is 3.7385739040374757 and perplexity is 42.03799717923716
At time: 643.0147864818573 and batch: 700, loss is 3.76954984664917 and perplexity is 43.36054154887274
At time: 643.8540434837341 and batch: 750, loss is 3.735737929344177 and perplexity is 41.91894737398801
At time: 644.6911067962646 and batch: 800, loss is 3.7062896919250488 and perplexity is 40.7025071759131
At time: 645.5291488170624 and batch: 850, loss is 3.6965735292434694 and perplexity is 40.308950023406155
At time: 646.3648126125336 and batch: 900, loss is 3.6520903062820436 and perplexity is 38.55517399899657
At time: 647.2018251419067 and batch: 950, loss is 3.7609482049942016 and perplexity is 42.98916920418144
At time: 648.0400545597076 and batch: 1000, loss is 3.7289296054840086 and perplexity is 41.634518943504986
At time: 648.8766551017761 and batch: 1050, loss is 3.6827845621109008 and perplexity is 39.7569457669378
At time: 649.7125082015991 and batch: 1100, loss is 3.689286193847656 and perplexity is 40.01627289854166
At time: 650.5480167865753 and batch: 1150, loss is 3.667655515670776 and perplexity is 39.159988174013336
At time: 651.383145570755 and batch: 1200, loss is 3.716766805648804 and perplexity is 41.13119375003142
At time: 652.219996213913 and batch: 1250, loss is 3.70388108253479 and perplexity is 40.60458870593393
At time: 653.0527367591858 and batch: 1300, loss is 3.706201419830322 and perplexity is 40.698914438915594
At time: 653.8884572982788 and batch: 1350, loss is 3.580964641571045 and perplexity is 35.90816265199584
At time: 654.7249393463135 and batch: 1400, loss is 3.6013066577911377 and perplexity is 36.64608706854981
At time: 655.5641040802002 and batch: 1450, loss is 3.5223322916030884 and perplexity is 33.863315560768385
At time: 656.3959357738495 and batch: 1500, loss is 3.5254945659637453 and perplexity is 33.97057015017349
At time: 657.2306532859802 and batch: 1550, loss is 3.545539016723633 and perplexity is 34.65836174495622
At time: 658.0697524547577 and batch: 1600, loss is 3.6325593519210817 and perplexity is 37.809460607077156
At time: 658.9087481498718 and batch: 1650, loss is 3.5831879138946534 and perplexity is 35.98808508796063
At time: 659.7446327209473 and batch: 1700, loss is 3.583981547355652 and perplexity is 36.01665777310348
At time: 660.5828433036804 and batch: 1750, loss is 3.579903554916382 and perplexity is 35.87008118725236
At time: 661.4196286201477 and batch: 1800, loss is 3.5418564176559446 and perplexity is 34.53096361639753
At time: 662.2584073543549 and batch: 1850, loss is 3.5589460802078245 and perplexity is 35.12615747752707
At time: 663.1092557907104 and batch: 1900, loss is 3.6450942659378054 and perplexity is 38.28638178313961
At time: 663.9701099395752 and batch: 1950, loss is 3.594250354766846 and perplexity is 36.3884113616434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.239424168786337 and perplexity of 69.36789613616757
finished 19 epochs...
Completing Train Step...
At time: 667.1907525062561 and batch: 50, loss is 3.7769112586975098 and perplexity is 43.68091411231927
At time: 668.0353994369507 and batch: 100, loss is 3.75517719745636 and perplexity is 42.741792876546555
At time: 668.8778312206268 and batch: 150, loss is 3.73859290599823 and perplexity is 42.038795991199216
At time: 669.7240478992462 and batch: 200, loss is 3.7309805059432986 and perplexity is 41.71999481882385
At time: 670.5639581680298 and batch: 250, loss is 3.7222401666641236 and perplexity is 41.35693684558439
At time: 671.4000747203827 and batch: 300, loss is 3.7244195461273195 and perplexity is 41.447167592210384
At time: 672.2377896308899 and batch: 350, loss is 3.746294836997986 and perplexity is 42.36382596974713
At time: 673.0715928077698 and batch: 400, loss is 3.713970355987549 and perplexity is 41.016333113048915
At time: 673.9054837226868 and batch: 450, loss is 3.7686085891723633 and perplexity is 43.31974731689127
At time: 674.7401673793793 and batch: 500, loss is 3.772774200439453 and perplexity is 43.50057691582506
At time: 675.577791929245 and batch: 550, loss is 3.7388529539108277 and perplexity is 42.04972951390312
At time: 676.4204947948456 and batch: 600, loss is 3.7050365304946897 and perplexity is 40.65153231034002
At time: 677.2553129196167 and batch: 650, loss is 3.734539408683777 and perplexity is 41.86873674474674
At time: 678.0907111167908 and batch: 700, loss is 3.765931053161621 and perplexity is 43.20391227892047
At time: 678.933785200119 and batch: 750, loss is 3.732693700790405 and perplexity is 41.791530558802656
At time: 679.8042755126953 and batch: 800, loss is 3.7033216667175295 and perplexity is 40.58188020909684
At time: 680.644951581955 and batch: 850, loss is 3.693455686569214 and perplexity is 40.18346877591254
At time: 681.4864590167999 and batch: 900, loss is 3.6492387008666993 and perplexity is 38.44538646578978
At time: 682.3286435604095 and batch: 950, loss is 3.758060975074768 and perplexity is 42.8652285972562
At time: 683.1678898334503 and batch: 1000, loss is 3.7265541696548463 and perplexity is 41.53573618797512
At time: 684.0059716701508 and batch: 1050, loss is 3.680681743621826 and perplexity is 39.67343196426788
At time: 684.8448185920715 and batch: 1100, loss is 3.687608585357666 and perplexity is 39.94919753821751
At time: 685.6885097026825 and batch: 1150, loss is 3.666143183708191 and perplexity is 39.10081003202022
At time: 686.5296576023102 and batch: 1200, loss is 3.7152994585037233 and perplexity is 41.07088426860232
At time: 687.3700475692749 and batch: 1250, loss is 3.7029404640197754 and perplexity is 40.56641323509461
At time: 688.2109379768372 and batch: 1300, loss is 3.7052359056472777 and perplexity is 40.659638023809414
At time: 689.0523910522461 and batch: 1350, loss is 3.580381851196289 and perplexity is 35.88724181724978
At time: 689.8900349140167 and batch: 1400, loss is 3.6009542417526244 and perplexity is 36.63317467511901
At time: 690.7359354496002 and batch: 1450, loss is 3.5223655319213867 and perplexity is 33.864441206864576
At time: 691.5782699584961 and batch: 1500, loss is 3.5262370109558105 and perplexity is 33.99580079488301
At time: 692.4190261363983 and batch: 1550, loss is 3.5464963006973265 and perplexity is 34.691555524610905
At time: 693.2725303173065 and batch: 1600, loss is 3.633826608657837 and perplexity is 37.85740527342892
At time: 694.1198189258575 and batch: 1650, loss is 3.584842481613159 and perplexity is 36.0476790993664
At time: 694.9593794345856 and batch: 1700, loss is 3.5858315086364745 and perplexity is 36.08334886439663
At time: 695.8038501739502 and batch: 1750, loss is 3.5818458509445192 and perplexity is 35.93981920748721
At time: 696.6484723091125 and batch: 1800, loss is 3.5437482833862304 and perplexity is 34.596353397937186
At time: 697.4837110042572 and batch: 1850, loss is 3.560849232673645 and perplexity is 35.1930715644031
At time: 698.3175265789032 and batch: 1900, loss is 3.6469078540802 and perplexity is 38.355880513143994
At time: 699.1593928337097 and batch: 1950, loss is 3.5957008314132692 and perplexity is 36.44123019950894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.239057106195494 and perplexity of 69.3424384490586
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
3671.519993543625


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}, 'best_accuracy': -69.56506109203387}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.0664099827407102, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3472414743178278}, 'best_accuracy': -69.30740757369114}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.49972324366546084, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.08468759351567401}, 'best_accuracy': -69.3424384490586}]
SETTINGS FOR THIS RUN
{'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7948334406587833, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4480485916137695 and batch: 50, loss is 7.657544755935669 and perplexity is 2116.554386229184
At time: 2.2948033809661865 and batch: 100, loss is 6.862686862945557 and perplexity is 955.9320785117558
At time: 3.1380069255828857 and batch: 150, loss is 6.58890851020813 and perplexity is 726.986937871788
At time: 3.9765172004699707 and batch: 200, loss is 6.509297714233399 and perplexity is 671.3547690957906
At time: 4.821521759033203 and batch: 250, loss is 6.462862033843994 and perplexity is 640.8926907911201
At time: 5.663451671600342 and batch: 300, loss is 6.390010900497437 and perplexity is 595.8630748565364
At time: 6.50707483291626 and batch: 350, loss is 6.327477941513061 and perplexity is 559.7431073000802
At time: 7.348491668701172 and batch: 400, loss is 6.274815454483032 and perplexity is 531.028373809066
At time: 8.192361831665039 and batch: 450, loss is 6.18718674659729 and perplexity is 486.47560019039537
At time: 9.035392045974731 and batch: 500, loss is 6.162378520965576 and perplexity is 474.5554736759031
At time: 9.876754999160767 and batch: 550, loss is 6.115678300857544 and perplexity is 452.9031477997148
At time: 10.720327138900757 and batch: 600, loss is 6.154303245544433 and perplexity is 470.73873885657105
At time: 11.563977241516113 and batch: 650, loss is 6.2126828479766845 and perplexity is 499.0383008301759
At time: 12.408355236053467 and batch: 700, loss is 6.115267381668091 and perplexity is 452.7170794374688
At time: 13.253655433654785 and batch: 750, loss is 6.0437382888793945 and perplexity is 421.46565397032293
At time: 14.10172414779663 and batch: 800, loss is 6.053389253616333 and perplexity is 425.5528953215602
At time: 14.945371627807617 and batch: 850, loss is 6.0868214511871335 and perplexity is 440.02055916122595
At time: 15.790072202682495 and batch: 900, loss is 6.062021284103394 and perplexity is 429.2421809930679
At time: 16.634463787078857 and batch: 950, loss is 6.080840768814087 and perplexity is 437.3967897457198
At time: 17.47905421257019 and batch: 1000, loss is 6.057807540893554 and perplexity is 427.43727005374956
At time: 18.325247049331665 and batch: 1050, loss is 5.944262170791626 and perplexity is 381.5577329735728
At time: 19.172650814056396 and batch: 1100, loss is 6.023942699432373 and perplexity is 413.20452960045
At time: 20.0147545337677 and batch: 1150, loss is 5.925581264495849 and perplexity is 374.4960533669922
At time: 20.860198497772217 and batch: 1200, loss is 6.006270952224732 and perplexity is 405.96662517678476
At time: 21.70210075378418 and batch: 1250, loss is 5.933979825973511 and perplexity is 377.65452624321136
At time: 22.549079418182373 and batch: 1300, loss is 5.946567277908326 and perplexity is 382.4382789057295
At time: 23.397101640701294 and batch: 1350, loss is 5.919819192886353 and perplexity is 372.3443852760362
At time: 24.254772901535034 and batch: 1400, loss is 5.936438989639282 and perplexity is 378.58438339922094
At time: 25.100494384765625 and batch: 1450, loss is 5.920367879867554 and perplexity is 372.5487418515297
At time: 25.943565130233765 and batch: 1500, loss is 5.8943720626831055 and perplexity is 362.9888300876853
At time: 26.791526317596436 and batch: 1550, loss is 5.859513034820557 and perplexity is 350.5533951519365
At time: 27.641605615615845 and batch: 1600, loss is 5.85962329864502 and perplexity is 350.59205064107636
At time: 28.484114170074463 and batch: 1650, loss is 5.859457759857178 and perplexity is 350.53401886137397
At time: 29.32662272453308 and batch: 1700, loss is 5.869749231338501 and perplexity is 354.1601568626749
At time: 30.173846006393433 and batch: 1750, loss is 5.879683418273926 and perplexity is 357.69598377014984
At time: 31.02153491973877 and batch: 1800, loss is 5.885914421081543 and perplexity is 359.93174673826684
At time: 31.86576223373413 and batch: 1850, loss is 5.8403616142272945 and perplexity is 343.90367864543737
At time: 32.71544432640076 and batch: 1900, loss is 5.816665277481079 and perplexity is 335.85021688132196
At time: 33.56511831283569 and batch: 1950, loss is 5.758511514663696 and perplexity is 316.87631196606094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.209736101017442 and perplexity of 183.04574623306743
finished 1 epochs...
Completing Train Step...
At time: 36.86035513877869 and batch: 50, loss is 5.4670265197753904 and perplexity is 236.7551582963473
At time: 37.700586557388306 and batch: 100, loss is 5.362953433990478 and perplexity is 213.35414422670206
At time: 38.53599143028259 and batch: 150, loss is 5.245634107589722 and perplexity is 189.7360901866895
At time: 39.372201919555664 and batch: 200, loss is 5.191395082473755 and perplexity is 179.71910109165518
At time: 40.20818901062012 and batch: 250, loss is 5.190365781784058 and perplexity is 179.53421126688548
At time: 41.04388093948364 and batch: 300, loss is 5.173012199401856 and perplexity is 176.44552692225588
At time: 41.904494762420654 and batch: 350, loss is 5.157763519287109 and perplexity is 173.77537540663528
At time: 42.73947310447693 and batch: 400, loss is 5.109493579864502 and perplexity is 165.58647731060256
At time: 43.5786509513855 and batch: 450, loss is 5.050992269515991 and perplexity is 156.1773576568913
At time: 44.41711950302124 and batch: 500, loss is 5.031784582138061 and perplexity is 153.2061778887569
At time: 45.25286054611206 and batch: 550, loss is 4.977446641921997 and perplexity is 145.10340728282694
At time: 46.08726406097412 and batch: 600, loss is 4.969337825775146 and perplexity is 143.9315480475216
At time: 46.922903299331665 and batch: 650, loss is 5.039000930786133 and perplexity is 154.31576585504203
At time: 47.756651163101196 and batch: 700, loss is 5.012043600082397 and perplexity is 150.21139471720537
At time: 48.58949637413025 and batch: 750, loss is 4.9653716659545895 and perplexity is 143.36182308171345
At time: 49.424631118774414 and batch: 800, loss is 4.943558912277222 and perplexity is 140.26856582311908
At time: 50.25954723358154 and batch: 850, loss is 4.930084657669068 and perplexity is 138.39122772281357
At time: 51.09577393531799 and batch: 900, loss is 4.931134147644043 and perplexity is 138.53654416967228
At time: 51.93174505233765 and batch: 950, loss is 4.988859481811524 and perplexity is 146.7689353619352
At time: 52.76404023170471 and batch: 1000, loss is 4.948754606246948 and perplexity is 140.99925493946643
At time: 53.602898359298706 and batch: 1050, loss is 4.862547531127929 and perplexity is 129.35331431230384
At time: 54.43824100494385 and batch: 1100, loss is 4.932553033828736 and perplexity is 138.73325127776727
At time: 55.280749797821045 and batch: 1150, loss is 4.842061443328857 and perplexity is 126.73033003511667
At time: 56.11947226524353 and batch: 1200, loss is 4.923379507064819 and perplexity is 137.46639772578547
At time: 56.957045555114746 and batch: 1250, loss is 4.873995475769043 and perplexity is 130.8426525591425
At time: 57.79436540603638 and batch: 1300, loss is 4.898807563781738 and perplexity is 134.12974312355587
At time: 58.629878759384155 and batch: 1350, loss is 4.800147428512573 and perplexity is 121.52833293944124
At time: 59.465025901794434 and batch: 1400, loss is 4.813050127029419 and perplexity is 123.10653602509203
At time: 60.29573369026184 and batch: 1450, loss is 4.756215038299561 and perplexity is 116.30488223400016
At time: 61.13849472999573 and batch: 1500, loss is 4.7359508037567135 and perplexity is 113.97177200669272
At time: 61.98384475708008 and batch: 1550, loss is 4.732018022537232 and perplexity is 113.52442619537908
At time: 62.8273446559906 and batch: 1600, loss is 4.785499515533448 and perplexity is 119.76117071026975
At time: 63.67220616340637 and batch: 1650, loss is 4.756486768722534 and perplexity is 116.3364901030588
At time: 64.51296591758728 and batch: 1700, loss is 4.780530118942261 and perplexity is 119.16750625555107
At time: 65.34745717048645 and batch: 1750, loss is 4.790677261352539 and perplexity is 120.38287172719097
At time: 66.17362260818481 and batch: 1800, loss is 4.737526836395264 and perplexity is 114.15153685967698
At time: 67.03176712989807 and batch: 1850, loss is 4.747217493057251 and perplexity is 115.2631174849959
At time: 67.8724536895752 and batch: 1900, loss is 4.822198505401611 and perplexity is 124.23792850923047
At time: 68.71299695968628 and batch: 1950, loss is 4.736478233337403 and perplexity is 114.0318999458456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.571876419422239 and perplexity of 96.72543708536698
finished 2 epochs...
Completing Train Step...
At time: 72.0714464187622 and batch: 50, loss is 4.6969961643219 and perplexity is 109.61740474476656
At time: 72.95364189147949 and batch: 100, loss is 4.639074583053588 and perplexity is 103.44857021315833
At time: 73.79720616340637 and batch: 150, loss is 4.592575130462646 and perplexity is 98.74839302286517
At time: 74.63010573387146 and batch: 200, loss is 4.577738943099976 and perplexity is 97.2941576906557
At time: 75.43917107582092 and batch: 250, loss is 4.57788203239441 and perplexity is 97.30808043910653
At time: 76.28952240943909 and batch: 300, loss is 4.598181629180909 and perplexity is 99.30358063684247
At time: 77.1256742477417 and batch: 350, loss is 4.608837194442749 and perplexity is 100.36737401560481
At time: 77.96554017066956 and batch: 400, loss is 4.564460802078247 and perplexity is 96.01081122731745
At time: 78.80306720733643 and batch: 450, loss is 4.560561084747315 and perplexity is 95.63712531111742
At time: 79.6452853679657 and batch: 500, loss is 4.564700832366944 and perplexity is 96.03385949608499
At time: 80.4866533279419 and batch: 550, loss is 4.5254449462890625 and perplexity is 92.33700169595059
At time: 81.32669615745544 and batch: 600, loss is 4.510456314086914 and perplexity is 90.96331688455003
At time: 82.1707215309143 and batch: 650, loss is 4.576282739639282 and perplexity is 97.15258070898477
At time: 83.01352071762085 and batch: 700, loss is 4.59102858543396 and perplexity is 98.59579221896811
At time: 83.85695672035217 and batch: 750, loss is 4.557237806320191 and perplexity is 95.31982404798778
At time: 84.75326919555664 and batch: 800, loss is 4.526698255538941 and perplexity is 92.45280106533457
At time: 85.59231495857239 and batch: 850, loss is 4.521920509338379 and perplexity is 92.01213857133632
At time: 86.42801666259766 and batch: 900, loss is 4.503444242477417 and perplexity is 90.32770666925644
At time: 87.2648503780365 and batch: 950, loss is 4.581477956771851 and perplexity is 97.65862282190035
At time: 88.10510420799255 and batch: 1000, loss is 4.557135334014893 and perplexity is 95.31005690631629
At time: 88.94099020957947 and batch: 1050, loss is 4.488127155303955 and perplexity is 88.95469145275358
At time: 89.77652668952942 and batch: 1100, loss is 4.540860538482666 and perplexity is 93.77145935866066
At time: 90.61473250389099 and batch: 1150, loss is 4.481058721542358 and perplexity is 88.32813809259093
At time: 91.45930933952332 and batch: 1200, loss is 4.561314449310303 and perplexity is 95.70920207886522
At time: 92.30124402046204 and batch: 1250, loss is 4.531133575439453 and perplexity is 92.86376952834276
At time: 93.14264798164368 and batch: 1300, loss is 4.547419672012329 and perplexity is 94.38854042808312
At time: 93.98042273521423 and batch: 1350, loss is 4.436545896530151 and perplexity is 84.48262538961329
At time: 94.81800556182861 and batch: 1400, loss is 4.457860946655273 and perplexity is 86.30270542364177
At time: 95.65573930740356 and batch: 1450, loss is 4.3983378505706785 and perplexity is 81.31559760160253
At time: 96.48861742019653 and batch: 1500, loss is 4.393013067245484 and perplexity is 80.88376040350536
At time: 97.32406234741211 and batch: 1550, loss is 4.395310859680176 and perplexity is 81.06982818695509
At time: 98.15688228607178 and batch: 1600, loss is 4.470459947586059 and perplexity is 87.39691176896915
At time: 98.99394249916077 and batch: 1650, loss is 4.431599855422974 and perplexity is 84.06580251287438
At time: 99.83010911941528 and batch: 1700, loss is 4.464131755828857 and perplexity is 86.8455936156444
At time: 100.67432379722595 and batch: 1750, loss is 4.4595041179656985 and perplexity is 86.44463212621523
At time: 101.52780270576477 and batch: 1800, loss is 4.413277969360352 and perplexity is 82.53958276431908
At time: 102.3734016418457 and batch: 1850, loss is 4.443285865783691 and perplexity is 85.0539589095387
At time: 103.21339344978333 and batch: 1900, loss is 4.527385492324829 and perplexity is 92.51635986865735
At time: 104.05682897567749 and batch: 1950, loss is 4.456066694259643 and perplexity is 86.14799542358551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.432243311682413 and perplexity of 84.11991258657193
finished 3 epochs...
Completing Train Step...
At time: 107.36692595481873 and batch: 50, loss is 4.426359081268311 and perplexity is 83.62638507728603
At time: 108.23477029800415 and batch: 100, loss is 4.377529878616333 and perplexity is 79.64106713698513
At time: 109.07652616500854 and batch: 150, loss is 4.343912487030029 and perplexity is 77.00824445991799
At time: 109.92369484901428 and batch: 200, loss is 4.336952877044678 and perplexity is 76.47415778605233
At time: 110.76399254798889 and batch: 250, loss is 4.326626863479614 and perplexity is 75.68854768621317
At time: 111.59868574142456 and batch: 300, loss is 4.347330684661865 and perplexity is 77.27192425685364
At time: 112.4340283870697 and batch: 350, loss is 4.358079404830932 and perplexity is 78.10697838939919
At time: 113.27434158325195 and batch: 400, loss is 4.311382446289063 and perplexity is 74.54347008458629
At time: 114.10817980766296 and batch: 450, loss is 4.331677255630493 and perplexity is 76.07177143390626
At time: 114.94406223297119 and batch: 500, loss is 4.3393748760223385 and perplexity is 76.65960260095083
At time: 115.77859663963318 and batch: 550, loss is 4.299371690750122 and perplexity is 73.65350198178037
At time: 116.61921572685242 and batch: 600, loss is 4.295121593475342 and perplexity is 73.3411317059623
At time: 117.46175599098206 and batch: 650, loss is 4.355542821884155 and perplexity is 77.9091046276946
At time: 118.30793190002441 and batch: 700, loss is 4.38094160079956 and perplexity is 79.91324436496713
At time: 119.14331245422363 and batch: 750, loss is 4.343660068511963 and perplexity is 76.98880860606046
At time: 119.97995114326477 and batch: 800, loss is 4.317932205200195 and perplexity is 75.033314271539
At time: 120.81540250778198 and batch: 850, loss is 4.308866128921509 and perplexity is 74.35613085750047
At time: 121.65570545196533 and batch: 900, loss is 4.283920936584472 and perplexity is 72.52424622091443
At time: 122.50029516220093 and batch: 950, loss is 4.379121427536011 and perplexity is 79.7679207114067
At time: 123.33767104148865 and batch: 1000, loss is 4.356766347885132 and perplexity is 78.00448678229343
At time: 124.17599129676819 and batch: 1050, loss is 4.29248309135437 and perplexity is 73.14787603926045
At time: 125.01702094078064 and batch: 1100, loss is 4.337916326522827 and perplexity is 76.54787227785552
At time: 125.86197638511658 and batch: 1150, loss is 4.289221348762513 and perplexity is 72.90967518260324
At time: 126.70486164093018 and batch: 1200, loss is 4.368156108856201 and perplexity is 78.89801813613633
At time: 127.61745285987854 and batch: 1250, loss is 4.344556703567505 and perplexity is 77.0578704277393
At time: 128.45700335502625 and batch: 1300, loss is 4.355717239379882 and perplexity is 77.92269452374147
At time: 129.29462814331055 and batch: 1350, loss is 4.239054365158081 and perplexity is 69.342248379101
At time: 130.13674330711365 and batch: 1400, loss is 4.263039031028748 and perplexity is 71.02550451285727
At time: 130.97323966026306 and batch: 1450, loss is 4.2011702299118046 and perplexity is 66.76441505943384
At time: 131.8102855682373 and batch: 1500, loss is 4.205223550796509 and perplexity is 67.03558184909612
At time: 132.64225363731384 and batch: 1550, loss is 4.207592353820801 and perplexity is 67.19456416266753
At time: 133.4790916442871 and batch: 1600, loss is 4.290551619529724 and perplexity is 73.00672933198202
At time: 134.3229730129242 and batch: 1650, loss is 4.250554132461548 and perplexity is 70.1442707967693
At time: 135.1613712310791 and batch: 1700, loss is 4.2833343553543095 and perplexity is 72.48171733389242
At time: 136.00410866737366 and batch: 1750, loss is 4.276451969146729 and perplexity is 71.98458286025665
At time: 136.84799814224243 and batch: 1800, loss is 4.230649189949036 and perplexity is 68.76185719378923
At time: 137.69112038612366 and batch: 1850, loss is 4.2650684642791745 and perplexity is 71.16979239513499
At time: 138.53016781806946 and batch: 1900, loss is 4.348029413223267 and perplexity is 77.3259352246318
At time: 139.37637281417847 and batch: 1950, loss is 4.2834757137298585 and perplexity is 72.4919639559176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383383391624273 and perplexity of 80.10861422091955
finished 4 epochs...
Completing Train Step...
At time: 142.6183841228485 and batch: 50, loss is 4.260823884010315 and perplexity is 70.86834670638898
At time: 143.4856996536255 and batch: 100, loss is 4.21702320098877 and perplexity is 67.8312634154341
At time: 144.32895636558533 and batch: 150, loss is 4.187393922805786 and perplexity is 65.85095447741361
At time: 145.1641354560852 and batch: 200, loss is 4.185597524642945 and perplexity is 65.73276613221542
At time: 146.00211215019226 and batch: 250, loss is 4.165591850280761 and perplexity is 64.43080455082271
At time: 146.8431432247162 and batch: 300, loss is 4.194535102844238 and perplexity is 66.32289108559428
At time: 147.68373084068298 and batch: 350, loss is 4.199579849243164 and perplexity is 66.65831861360101
At time: 148.56722688674927 and batch: 400, loss is 4.151880750656128 and perplexity is 63.553416096275164
At time: 149.41570138931274 and batch: 450, loss is 4.181043939590454 and perplexity is 65.43412684661743
At time: 150.2578501701355 and batch: 500, loss is 4.1941002130508425 and perplexity is 66.294054208079
At time: 151.10318446159363 and batch: 550, loss is 4.155865740776062 and perplexity is 63.807181121246835
At time: 151.94601440429688 and batch: 600, loss is 4.149806780815124 and perplexity is 63.42174481632755
At time: 152.79044270515442 and batch: 650, loss is 4.214118738174438 and perplexity is 67.63453586541948
At time: 153.63553833961487 and batch: 700, loss is 4.239492650032044 and perplexity is 69.37264669876735
At time: 154.47239899635315 and batch: 750, loss is 4.204798603057862 and perplexity is 67.00710128198531
At time: 155.30700659751892 and batch: 800, loss is 4.17795756816864 and perplexity is 65.2324841596853
At time: 156.14150214195251 and batch: 850, loss is 4.171766319274902 and perplexity is 64.82986126965335
At time: 156.98096108436584 and batch: 900, loss is 4.140967388153076 and perplexity is 62.863605550820914
At time: 157.8181643486023 and batch: 950, loss is 4.245309071540833 and perplexity is 69.77732299623314
At time: 158.6574831008911 and batch: 1000, loss is 4.2209033203125 and perplexity is 68.09496808330756
At time: 159.5044071674347 and batch: 1050, loss is 4.163652558326721 and perplexity is 64.30597548908445
At time: 160.34506678581238 and batch: 1100, loss is 4.19966598033905 and perplexity is 66.66406021489482
At time: 161.19305038452148 and batch: 1150, loss is 4.158744792938233 and perplexity is 63.9911500249754
At time: 162.02678179740906 and batch: 1200, loss is 4.238009057044983 and perplexity is 69.26980223515751
At time: 162.86572790145874 and batch: 1250, loss is 4.2163791513443 and perplexity is 67.78759077952985
At time: 163.7055368423462 and batch: 1300, loss is 4.222644677162171 and perplexity is 68.2136490253533
At time: 164.54754519462585 and batch: 1350, loss is 4.107669286727905 and perplexity is 60.80483365568149
At time: 165.3852789402008 and batch: 1400, loss is 4.137314920425415 and perplexity is 62.634417066863826
At time: 166.22484278678894 and batch: 1450, loss is 4.073022146224975 and perplexity is 58.73419797606276
At time: 167.06100726127625 and batch: 1500, loss is 4.074854397773743 and perplexity is 58.841912451142505
At time: 167.89825177192688 and batch: 1550, loss is 4.081159949302673 and perplexity is 59.21411540137393
At time: 168.736829996109 and batch: 1600, loss is 4.166850147247314 and perplexity is 64.51192866515132
At time: 169.5863959789276 and batch: 1650, loss is 4.1231194543838505 and perplexity is 61.75157334062181
At time: 170.4319965839386 and batch: 1700, loss is 4.158500814437867 and perplexity is 63.975539464553584
At time: 171.274498462677 and batch: 1750, loss is 4.150368041992188 and perplexity is 63.457350970715936
At time: 172.1146321296692 and batch: 1800, loss is 4.107047400474548 and perplexity is 60.76703172096346
At time: 172.94834661483765 and batch: 1850, loss is 4.140670037269592 and perplexity is 62.84491578101889
At time: 173.7887670993805 and batch: 1900, loss is 4.221427145004273 and perplexity is 68.13064725297428
At time: 174.62237787246704 and batch: 1950, loss is 4.162008380889892 and perplexity is 64.20033192731137
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366486589298692 and perplexity of 78.76640624669112
finished 5 epochs...
Completing Train Step...
At time: 177.87433505058289 and batch: 50, loss is 4.143496809005737 and perplexity is 63.02281533496367
At time: 178.71060824394226 and batch: 100, loss is 4.1055027294158934 and perplexity is 60.67323910376354
At time: 179.54767441749573 and batch: 150, loss is 4.071136932373047 and perplexity is 58.62357575848776
At time: 180.38827347755432 and batch: 200, loss is 4.074633288383484 and perplexity is 58.82890339002452
At time: 181.22575163841248 and batch: 250, loss is 4.053567771911621 and perplexity is 57.60260382133446
At time: 182.065819978714 and batch: 300, loss is 4.080158357620239 and perplexity is 59.15483672737426
At time: 182.89983320236206 and batch: 350, loss is 4.086573204994202 and perplexity is 59.535525701792444
At time: 183.73662686347961 and batch: 400, loss is 4.0412885856628415 and perplexity is 56.89961561508701
At time: 184.5736837387085 and batch: 450, loss is 4.075937395095825 and perplexity is 58.905672604559044
At time: 185.41824650764465 and batch: 500, loss is 4.089737391471862 and perplexity is 59.72420555886159
At time: 186.2513632774353 and batch: 550, loss is 4.0521443605422975 and perplexity is 57.520669946790676
At time: 187.09641981124878 and batch: 600, loss is 4.044734220504761 and perplexity is 57.096009068900685
At time: 187.93664813041687 and batch: 650, loss is 4.108527312278747 and perplexity is 60.85702814547355
At time: 188.77260971069336 and batch: 700, loss is 4.138305006027221 and perplexity is 62.69646121081773
At time: 189.61487698554993 and batch: 750, loss is 4.105417995452881 and perplexity is 60.66809823757154
At time: 190.4503345489502 and batch: 800, loss is 4.078058242797852 and perplexity is 59.030735137353844
At time: 191.33793830871582 and batch: 850, loss is 4.075516123771667 and perplexity is 58.88086256010756
At time: 192.1702389717102 and batch: 900, loss is 4.039146037101745 and perplexity is 56.77783593155279
At time: 193.00911402702332 and batch: 950, loss is 4.1468701696395875 and perplexity is 63.23577300881885
At time: 193.849458694458 and batch: 1000, loss is 4.119008946418762 and perplexity is 61.49826397828949
At time: 194.69336605072021 and batch: 1050, loss is 4.069681386947632 and perplexity is 58.53830855117181
At time: 195.53683948516846 and batch: 1100, loss is 4.101542963981628 and perplexity is 60.433462351925535
At time: 196.37627625465393 and batch: 1150, loss is 4.058789386749267 and perplexity is 57.90416907575084
At time: 197.22106671333313 and batch: 1200, loss is 4.13840754032135 and perplexity is 62.702890077796404
At time: 198.06287622451782 and batch: 1250, loss is 4.119454355239868 and perplexity is 61.52566194874403
At time: 198.90739798545837 and batch: 1300, loss is 4.1228947257995605 and perplexity is 61.73769755616839
At time: 199.74980354309082 and batch: 1350, loss is 4.002469840049744 and perplexity is 54.73316539527836
At time: 200.58904242515564 and batch: 1400, loss is 4.046131725311279 and perplexity is 57.175856796803906
At time: 201.4616184234619 and batch: 1450, loss is 3.9745705032348635 and perplexity is 53.22725106353559
At time: 202.31737875938416 and batch: 1500, loss is 3.980863265991211 and perplexity is 53.56325361003044
At time: 203.15673327445984 and batch: 1550, loss is 3.9837172174453737 and perplexity is 53.71633888061866
At time: 203.9989893436432 and batch: 1600, loss is 4.077351036071778 and perplexity is 58.98900296279623
At time: 204.84011101722717 and batch: 1650, loss is 4.0306128311157225 and perplexity is 56.295400251026955
At time: 205.67991018295288 and batch: 1700, loss is 4.060217342376709 and perplexity is 57.98691272290327
At time: 206.52440881729126 and batch: 1750, loss is 4.059397406578064 and perplexity is 57.939386664129984
At time: 207.3631637096405 and batch: 1800, loss is 4.013023419380188 and perplexity is 55.31385498544965
At time: 208.2002718448639 and batch: 1850, loss is 4.046610412597656 and perplexity is 57.203232704266895
At time: 209.04021859169006 and batch: 1900, loss is 4.124544973373413 and perplexity is 61.83966415370019
At time: 209.87943983078003 and batch: 1950, loss is 4.0709388256073 and perplexity is 58.61196318180068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354269338208575 and perplexity of 77.80995180292423
finished 6 epochs...
Completing Train Step...
At time: 213.04858016967773 and batch: 50, loss is 4.053833141326904 and perplexity is 57.6178918190231
At time: 213.89048552513123 and batch: 100, loss is 4.0154674625396725 and perplexity is 55.44920977344666
At time: 214.73221468925476 and batch: 150, loss is 3.990366163253784 and perplexity is 54.07468590166006
At time: 215.57648420333862 and batch: 200, loss is 3.990735287666321 and perplexity is 54.09464987269449
At time: 216.4149191379547 and batch: 250, loss is 3.9714010190963744 and perplexity is 53.05881520395066
At time: 217.25445866584778 and batch: 300, loss is 3.9929665088653565 and perplexity is 54.215481753443186
At time: 218.1002242565155 and batch: 350, loss is 3.997864508628845 and perplexity is 54.48168055890759
At time: 218.94026947021484 and batch: 400, loss is 3.957172408103943 and perplexity is 52.30920754724021
At time: 219.7764220237732 and batch: 450, loss is 3.9935489654541017 and perplexity is 54.24706911624324
At time: 220.61454319953918 and batch: 500, loss is 4.009925589561463 and perplexity is 55.14276721330916
At time: 221.45050811767578 and batch: 550, loss is 3.969539680480957 and perplexity is 52.96014663861575
At time: 222.2946605682373 and batch: 600, loss is 3.964449920654297 and perplexity is 52.69127703313547
At time: 223.13303971290588 and batch: 650, loss is 4.0276390647888185 and perplexity is 56.12823955700986
At time: 223.9769949913025 and batch: 700, loss is 4.05712555885315 and perplexity is 57.80790660823763
At time: 224.81557869911194 and batch: 750, loss is 4.028978309631348 and perplexity is 56.20345936998741
At time: 225.65337705612183 and batch: 800, loss is 4.000640072822571 and perplexity is 54.633108011775626
At time: 226.4905982017517 and batch: 850, loss is 3.996618666648865 and perplexity is 54.413847257688374
At time: 227.32695603370667 and batch: 900, loss is 3.9574942636489867 and perplexity is 52.32604626541818
At time: 228.1605794429779 and batch: 950, loss is 4.067641053199768 and perplexity is 58.41899262823639
At time: 229.00042080879211 and batch: 1000, loss is 4.042467923164367 and perplexity is 56.96675905020766
At time: 229.8331069946289 and batch: 1050, loss is 3.9923504257202147 and perplexity is 54.1820907957884
At time: 230.66872715950012 and batch: 1100, loss is 4.022422971725464 and perplexity is 55.83623166822965
At time: 231.50579524040222 and batch: 1150, loss is 3.9817357063293457 and perplexity is 53.61000474394371
At time: 232.34233832359314 and batch: 1200, loss is 4.0597471475601195 and perplexity is 57.95965398607152
At time: 233.18781280517578 and batch: 1250, loss is 4.04126428604126 and perplexity is 56.89823299275809
At time: 234.0236279964447 and batch: 1300, loss is 4.046146359443664 and perplexity is 57.17669352198385
At time: 234.86159658432007 and batch: 1350, loss is 3.93310417175293 and perplexity is 51.06524719211153
At time: 235.70802783966064 and batch: 1400, loss is 3.9756447410583498 and perplexity is 53.284460512643705
At time: 236.54641437530518 and batch: 1450, loss is 3.9009366464614867 and perplexity is 49.44874341198829
At time: 237.3851499557495 and batch: 1500, loss is 3.906613302230835 and perplexity is 49.73024514484749
At time: 238.22772073745728 and batch: 1550, loss is 3.913133683204651 and perplexity is 50.05556474037431
At time: 239.06608390808105 and batch: 1600, loss is 4.000910658836364 and perplexity is 54.64789296690451
At time: 239.90214490890503 and batch: 1650, loss is 3.9558938217163084 and perplexity is 52.24236844541086
At time: 240.73975110054016 and batch: 1700, loss is 3.984275050163269 and perplexity is 53.746311971139846
At time: 241.58394360542297 and batch: 1750, loss is 3.9853090143203733 and perplexity is 53.80191247080298
At time: 242.42102003097534 and batch: 1800, loss is 3.93544150352478 and perplexity is 51.18474321333279
At time: 243.263840675354 and batch: 1850, loss is 3.973544201850891 and perplexity is 53.172651884502955
At time: 244.10838556289673 and batch: 1900, loss is 4.051250648498535 and perplexity is 57.46928599594194
At time: 244.95407629013062 and batch: 1950, loss is 3.9951043701171876 and perplexity is 54.33151091406438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357667151162791 and perplexity of 78.07478513739977
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 248.254390001297 and batch: 50, loss is 4.0192724609375 and perplexity is 55.66059583456991
At time: 249.0933907032013 and batch: 100, loss is 4.00591136932373 and perplexity is 54.92185569159414
At time: 249.9358103275299 and batch: 150, loss is 3.9806015253067017 and perplexity is 53.54923576196661
At time: 250.7683207988739 and batch: 200, loss is 3.9828078985214233 and perplexity is 53.66751579838964
At time: 251.609881401062 and batch: 250, loss is 3.96114869594574 and perplexity is 52.517618088779706
At time: 252.4514319896698 and batch: 300, loss is 3.9752649545669554 and perplexity is 53.26422763666945
At time: 253.29220533370972 and batch: 350, loss is 3.9734393167495727 and perplexity is 53.167075157985565
At time: 254.12912344932556 and batch: 400, loss is 3.932279553413391 and perplexity is 51.023155210059194
At time: 255.0193314552307 and batch: 450, loss is 3.9623610591888427 and perplexity is 52.581327130012355
At time: 255.86510729789734 and batch: 500, loss is 3.9687608432769776 and perplexity is 52.918915364394756
At time: 256.7064061164856 and batch: 550, loss is 3.92653892993927 and perplexity is 50.73108960893832
At time: 257.5411558151245 and batch: 600, loss is 3.912822041511536 and perplexity is 50.039967769888165
At time: 258.3788528442383 and batch: 650, loss is 3.959597010612488 and perplexity is 52.43619046241874
At time: 259.2220208644867 and batch: 700, loss is 3.9915499687194824 and perplexity is 54.13873771534978
At time: 260.0699553489685 and batch: 750, loss is 3.945661392211914 and perplexity is 51.71052774480668
At time: 260.9129571914673 and batch: 800, loss is 3.916226887702942 and perplexity is 50.21063654915918
At time: 261.75004029273987 and batch: 850, loss is 3.9095140314102172 and perplexity is 49.87470854133608
At time: 262.5918619632721 and batch: 900, loss is 3.8585853290557863 and perplexity is 47.39825098908455
At time: 263.4298851490021 and batch: 950, loss is 3.9731616306304933 and perplexity is 53.15231344887785
At time: 264.2686514854431 and batch: 1000, loss is 3.936431369781494 and perplexity is 51.23543434808106
At time: 265.11407685279846 and batch: 1050, loss is 3.8849964570999145 and perplexity is 48.66677003768125
At time: 265.9517126083374 and batch: 1100, loss is 3.900190553665161 and perplexity is 49.41186382025088
At time: 266.79211473464966 and batch: 1150, loss is 3.87124858379364 and perplexity is 48.00228355283313
At time: 267.6317358016968 and batch: 1200, loss is 3.929434924125671 and perplexity is 50.87821949032734
At time: 268.47140526771545 and batch: 1250, loss is 3.904300184249878 and perplexity is 49.61534615929101
At time: 269.30637979507446 and batch: 1300, loss is 3.905783381462097 and perplexity is 49.68899010314323
At time: 270.14777660369873 and batch: 1350, loss is 3.7851281785964965 and perplexity is 44.04131535096097
At time: 270.9878330230713 and batch: 1400, loss is 3.8163593769073487 and perplexity is 45.43848244268939
At time: 271.82586097717285 and batch: 1450, loss is 3.73393150806427 and perplexity is 41.84329244832698
At time: 272.6657905578613 and batch: 1500, loss is 3.7354525470733644 and perplexity is 41.906986156437235
At time: 273.5131332874298 and batch: 1550, loss is 3.7399847078323365 and perplexity is 42.09734640039529
At time: 274.3561453819275 and batch: 1600, loss is 3.818106760978699 and perplexity is 45.517950333378984
At time: 275.19545888900757 and batch: 1650, loss is 3.7669320201873777 and perplexity is 43.24717962147436
At time: 276.0382332801819 and batch: 1700, loss is 3.7837043714523317 and perplexity is 43.97865363121377
At time: 276.88212633132935 and batch: 1750, loss is 3.768842568397522 and perplexity is 43.329884423692505
At time: 277.72178959846497 and batch: 1800, loss is 3.711880073547363 and perplexity is 40.930686935716516
At time: 278.5618212223053 and batch: 1850, loss is 3.7440555810928347 and perplexity is 42.26906865481296
At time: 279.4041380882263 and batch: 1900, loss is 3.8189852905273436 and perplexity is 45.5579567685852
At time: 280.23580622673035 and batch: 1950, loss is 3.75256591796875 and perplexity is 42.6303277062388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2834288131359015 and perplexity of 72.48856411947875
finished 8 epochs...
Completing Train Step...
At time: 283.4343113899231 and batch: 50, loss is 3.93097505569458 and perplexity is 50.95663901502611
At time: 284.300977230072 and batch: 100, loss is 3.90296471118927 and perplexity is 49.549130425608034
At time: 285.1459126472473 and batch: 150, loss is 3.871793794631958 and perplexity is 48.0284620538429
At time: 285.98654413223267 and batch: 200, loss is 3.8743334674835204 and perplexity is 48.15059365653609
At time: 286.8218879699707 and batch: 250, loss is 3.8528054094314577 and perplexity is 47.1250831127055
At time: 287.6636731624603 and batch: 300, loss is 3.86601092338562 and perplexity is 47.75152117014098
At time: 288.49982810020447 and batch: 350, loss is 3.869209842681885 and perplexity is 47.904519016048944
At time: 289.34237360954285 and batch: 400, loss is 3.831534576416016 and perplexity is 46.133278983711016
At time: 290.17861104011536 and batch: 450, loss is 3.8673065090179444 and perplexity is 47.81342744867379
At time: 291.02015376091003 and batch: 500, loss is 3.880578374862671 and perplexity is 48.452230521021974
At time: 291.862895488739 and batch: 550, loss is 3.8384594678878785 and perplexity is 46.453855632083624
At time: 292.71261191368103 and batch: 600, loss is 3.8265647077560425 and perplexity is 45.904571440282695
At time: 293.5583608150482 and batch: 650, loss is 3.8731012392044066 and perplexity is 48.09129767397251
At time: 294.4068958759308 and batch: 700, loss is 3.909566488265991 and perplexity is 49.87732488035065
At time: 295.24208521842957 and batch: 750, loss is 3.8689599657058715 and perplexity is 47.892550275118516
At time: 296.08059310913086 and batch: 800, loss is 3.839206976890564 and perplexity is 46.4885932891162
At time: 296.91846537590027 and batch: 850, loss is 3.83439649105072 and perplexity is 46.26549759893101
At time: 297.8034336566925 and batch: 900, loss is 3.7859943151474 and perplexity is 44.07947766843955
At time: 298.63861060142517 and batch: 950, loss is 3.902513093948364 and perplexity is 49.5267582362494
At time: 299.480103969574 and batch: 1000, loss is 3.868482747077942 and perplexity is 47.86970051058846
At time: 300.315673828125 and batch: 1050, loss is 3.8216979694366455 and perplexity is 45.681708650735594
At time: 301.1583869457245 and batch: 1100, loss is 3.836900863647461 and perplexity is 46.38150885035779
At time: 302.00114130973816 and batch: 1150, loss is 3.8114544582366943 and perplexity is 45.21615607390001
At time: 302.83878684043884 and batch: 1200, loss is 3.8726847314834596 and perplexity is 48.07127144800932
At time: 303.6803934574127 and batch: 1250, loss is 3.8504638290405273 and perplexity is 47.01486503477329
At time: 304.5192675590515 and batch: 1300, loss is 3.854594211578369 and perplexity is 47.20945600325664
At time: 305.35432720184326 and batch: 1350, loss is 3.7337930011749267 and perplexity is 41.83749726539573
At time: 306.19657039642334 and batch: 1400, loss is 3.7707378244400025 and perplexity is 43.41208351852717
At time: 307.0414354801178 and batch: 1450, loss is 3.6888317680358886 and perplexity is 39.998092602356614
At time: 307.8808743953705 and batch: 1500, loss is 3.693116660118103 and perplexity is 40.16984782616171
At time: 308.72046303749084 and batch: 1550, loss is 3.701032528877258 and perplexity is 40.489088938005814
At time: 309.56718134880066 and batch: 1600, loss is 3.7831704425811767 and perplexity is 43.95517842592816
At time: 310.4058439731598 and batch: 1650, loss is 3.734185256958008 and perplexity is 41.85391148472349
At time: 311.24595761299133 and batch: 1700, loss is 3.7556261920928957 and perplexity is 42.76098802124009
At time: 312.08407258987427 and batch: 1750, loss is 3.7435603380203246 and perplexity is 42.248140374100984
At time: 312.9249703884125 and batch: 1800, loss is 3.6887831258773804 and perplexity is 39.99614705611439
At time: 313.7628891468048 and batch: 1850, loss is 3.726515293121338 and perplexity is 41.53412145392325
At time: 314.60388827323914 and batch: 1900, loss is 3.8045393371582032 and perplexity is 44.90455948569542
At time: 315.4412999153137 and batch: 1950, loss is 3.7399169540405275 and perplexity is 42.094494242174925
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284838583303053 and perplexity of 72.59082840226442
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 318.69089245796204 and batch: 50, loss is 3.906638445854187 and perplexity is 49.73149555912051
At time: 319.5547471046448 and batch: 100, loss is 3.909473614692688 and perplexity is 49.872692810064
At time: 320.3915090560913 and batch: 150, loss is 3.8875262403488158 and perplexity is 48.79004227758132
At time: 321.22847080230713 and batch: 200, loss is 3.902010540962219 and perplexity is 49.50187466918288
At time: 322.0729033946991 and batch: 250, loss is 3.887359132766724 and perplexity is 48.7818897727778
At time: 322.9101781845093 and batch: 300, loss is 3.8977438735961916 and perplexity is 49.29111657304799
At time: 323.75161242485046 and batch: 350, loss is 3.9011768293380737 and perplexity is 49.46062157983375
At time: 324.58942008018494 and batch: 400, loss is 3.863268051147461 and perplexity is 47.6207243099344
At time: 325.4259922504425 and batch: 450, loss is 3.9010985326766967 and perplexity is 49.456749129896345
At time: 326.2629773616791 and batch: 500, loss is 3.908744902610779 and perplexity is 49.83636321477113
At time: 327.1008241176605 and batch: 550, loss is 3.8659550666809084 and perplexity is 47.74885400201375
At time: 327.9384503364563 and batch: 600, loss is 3.8490486097335816 and perplexity is 46.94837574961997
At time: 328.7769250869751 and batch: 650, loss is 3.8834946012496947 and perplexity is 48.59373442259984
At time: 329.6230278015137 and batch: 700, loss is 3.918680286407471 and perplexity is 50.33397449653667
At time: 330.4630877971649 and batch: 750, loss is 3.8743207025527955 and perplexity is 48.14997902146659
At time: 331.30148673057556 and batch: 800, loss is 3.8405100440979005 and perplexity is 46.5492105361426
At time: 332.1445224285126 and batch: 850, loss is 3.829952960014343 and perplexity is 46.0603715040385
At time: 332.9857544898987 and batch: 900, loss is 3.7816078758239744 and perplexity is 43.88654915818294
At time: 333.8361611366272 and batch: 950, loss is 3.8982521295547485 and perplexity is 49.316175444371055
At time: 334.67318081855774 and batch: 1000, loss is 3.8578371000289917 and perplexity is 47.36279950644335
At time: 335.51489520072937 and batch: 1050, loss is 3.811663155555725 and perplexity is 45.225593549203154
At time: 336.35514998435974 and batch: 1100, loss is 3.8238476419448855 and perplexity is 45.78001498931133
At time: 337.1920328140259 and batch: 1150, loss is 3.798777995109558 and perplexity is 44.64659278969932
At time: 338.03498363494873 and batch: 1200, loss is 3.851903772354126 and perplexity is 47.08261253989752
At time: 338.8777983188629 and batch: 1250, loss is 3.8285878229141237 and perplexity is 45.997535681563086
At time: 339.7162539958954 and batch: 1300, loss is 3.8298789644241333 and perplexity is 46.056963365758925
At time: 340.5578279495239 and batch: 1350, loss is 3.7090228509902956 and perplexity is 40.81390576806813
At time: 341.4000406265259 and batch: 1400, loss is 3.7416393661499026 and perplexity is 42.16706078560195
At time: 342.23679995536804 and batch: 1450, loss is 3.655192704200745 and perplexity is 38.67497322691623
At time: 343.0779013633728 and batch: 1500, loss is 3.6551607751846316 and perplexity is 38.67373839278651
At time: 343.91760516166687 and batch: 1550, loss is 3.6603169727325437 and perplexity is 38.87366280981184
At time: 344.7542281150818 and batch: 1600, loss is 3.7407135581970214 and perplexity is 42.12804025092479
At time: 345.59109449386597 and batch: 1650, loss is 3.6935773277282715 and perplexity is 40.18835703693023
At time: 346.42793893814087 and batch: 1700, loss is 3.7110673999786377 and perplexity is 40.89743716073068
At time: 347.2646961212158 and batch: 1750, loss is 3.692640542984009 and perplexity is 40.15072682561691
At time: 348.10201144218445 and batch: 1800, loss is 3.635631356239319 and perplexity is 37.92579002408259
At time: 348.9448392391205 and batch: 1850, loss is 3.667383241653442 and perplexity is 39.14932737810917
At time: 349.78756833076477 and batch: 1900, loss is 3.7458206701278685 and perplexity is 42.343743208647126
At time: 350.62630558013916 and batch: 1950, loss is 3.6805070543289187 and perplexity is 39.666502045799724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261290652252907 and perplexity of 70.90143352137301
finished 10 epochs...
Completing Train Step...
At time: 353.8164749145508 and batch: 50, loss is 3.896980338096619 and perplexity is 49.25349542010151
At time: 354.6838834285736 and batch: 100, loss is 3.879807357788086 and perplexity is 48.41488742192198
At time: 355.52534198760986 and batch: 150, loss is 3.8489955139160155 and perplexity is 46.945883053402596
At time: 356.36676597595215 and batch: 200, loss is 3.8573981952667236 and perplexity is 47.34201630944133
At time: 357.2051372528076 and batch: 250, loss is 3.839899706840515 and perplexity is 46.52080848694659
At time: 358.0447087287903 and batch: 300, loss is 3.8476851034164428 and perplexity is 46.88440496490143
At time: 358.88222098350525 and batch: 350, loss is 3.8554546356201174 and perplexity is 47.25009363449005
At time: 359.72092509269714 and batch: 400, loss is 3.8179757499694826 and perplexity is 45.51198737138371
At time: 360.559823513031 and batch: 450, loss is 3.856231551170349 and perplexity is 47.28681723070388
At time: 361.407753944397 and batch: 500, loss is 3.8660812044143675 and perplexity is 47.75487731410831
At time: 362.29615235328674 and batch: 550, loss is 3.823040566444397 and perplexity is 45.743081966675085
At time: 363.16832280158997 and batch: 600, loss is 3.809050340652466 and perplexity is 45.10758168308729
At time: 363.9995949268341 and batch: 650, loss is 3.844591245651245 and perplexity is 46.73957544103275
At time: 364.83789443969727 and batch: 700, loss is 3.8824734497070312 and perplexity is 48.54413818267858
At time: 365.70400500297546 and batch: 750, loss is 3.84090292930603 and perplexity is 46.56750262552274
At time: 366.54350423812866 and batch: 800, loss is 3.8077891635894776 and perplexity is 45.0507288939542
At time: 367.40796852111816 and batch: 850, loss is 3.798788266181946 and perplexity is 44.64705136044073
At time: 368.26785492897034 and batch: 900, loss is 3.750268330574036 and perplexity is 42.53249323732794
At time: 369.1147668361664 and batch: 950, loss is 3.8689485454559325 and perplexity is 47.89200333334727
At time: 369.96338295936584 and batch: 1000, loss is 3.8305943536758424 and perplexity is 46.089923810685455
At time: 370.81534337997437 and batch: 1050, loss is 3.7867378520965578 and perplexity is 44.11226457641387
At time: 371.6794822216034 and batch: 1100, loss is 3.8004842090606687 and perplexity is 44.722834452985424
At time: 372.5378189086914 and batch: 1150, loss is 3.776906981468201 and perplexity is 43.68072727943275
At time: 373.37956976890564 and batch: 1200, loss is 3.831791067123413 and perplexity is 46.145113258698
At time: 374.2273979187012 and batch: 1250, loss is 3.810657558441162 and perplexity is 45.180137681800744
At time: 375.0721399784088 and batch: 1300, loss is 3.813618330955505 and perplexity is 45.31410401569855
At time: 375.9260492324829 and batch: 1350, loss is 3.6935501670837403 and perplexity is 40.18726551007381
At time: 376.77602434158325 and batch: 1400, loss is 3.7287284564971923 and perplexity is 41.62614504443181
At time: 377.63302302360535 and batch: 1450, loss is 3.6436964893341064 and perplexity is 38.23290335859525
At time: 378.46666383743286 and batch: 1500, loss is 3.646057028770447 and perplexity is 38.323260238271104
At time: 379.30933690071106 and batch: 1550, loss is 3.652325739860535 and perplexity is 38.564252250201164
At time: 380.15484738349915 and batch: 1600, loss is 3.7355434322357177 and perplexity is 41.910795052761266
At time: 381.003915309906 and batch: 1650, loss is 3.6897583055496215 and perplexity is 40.035169509550705
At time: 381.84804916381836 and batch: 1700, loss is 3.7097529649734495 and perplexity is 40.843715452285956
At time: 382.6822166442871 and batch: 1750, loss is 3.6930039644241335 and perplexity is 40.16532111235965
At time: 383.5190715789795 and batch: 1800, loss is 3.6374780416488646 and perplexity is 37.99589173514705
At time: 384.35458397865295 and batch: 1850, loss is 3.6710916566848755 and perplexity is 39.29477886277318
At time: 385.19341015815735 and batch: 1900, loss is 3.750043034553528 and perplexity is 42.52291191521668
At time: 386.0185613632202 and batch: 1950, loss is 3.684704966545105 and perplexity is 39.83336853970792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260651344476744 and perplexity of 70.85612016971413
finished 11 epochs...
Completing Train Step...
At time: 389.3514804840088 and batch: 50, loss is 3.879373803138733 and perplexity is 48.393901471989125
At time: 390.1906816959381 and batch: 100, loss is 3.8604911947250367 and perplexity is 47.488671826041816
At time: 391.0316436290741 and batch: 150, loss is 3.8286183309555053 and perplexity is 45.99893899769121
At time: 391.87264800071716 and batch: 200, loss is 3.8368851947784424 and perplexity is 46.380782110264335
At time: 392.7152154445648 and batch: 250, loss is 3.818541612625122 and perplexity is 45.53774819327726
At time: 393.5573637485504 and batch: 300, loss is 3.825383338928223 and perplexity is 45.85037323086968
At time: 394.39272809028625 and batch: 350, loss is 3.834418716430664 and perplexity is 46.26652587862036
At time: 395.23525047302246 and batch: 400, loss is 3.7966582441329955 and perplexity is 44.55205336645038
At time: 396.07959270477295 and batch: 450, loss is 3.8355750036239624 and perplexity is 46.32005421107092
At time: 396.92403984069824 and batch: 500, loss is 3.8462389421463015 and perplexity is 46.81665155725279
At time: 397.76135325431824 and batch: 550, loss is 3.803400468826294 and perplexity is 44.853448214967024
At time: 398.59922790527344 and batch: 600, loss is 3.7904649353027344 and perplexity is 44.27698142292377
At time: 399.4481620788574 and batch: 650, loss is 3.8261638259887696 and perplexity is 45.88617282263938
At time: 400.2867958545685 and batch: 700, loss is 3.864917321205139 and perplexity is 47.69932854665317
At time: 401.12393140792847 and batch: 750, loss is 3.823449382781982 and perplexity is 45.761786308974415
At time: 401.9609344005585 and batch: 800, loss is 3.790864796638489 and perplexity is 44.294689616033644
At time: 402.795254945755 and batch: 850, loss is 3.782618441581726 and perplexity is 43.930921818957586
At time: 403.63638949394226 and batch: 900, loss is 3.7341912508010866 and perplexity is 41.85416235125299
At time: 404.5206620693207 and batch: 950, loss is 3.853401041030884 and perplexity is 47.15316066244083
At time: 405.3637979030609 and batch: 1000, loss is 3.815733456611633 and perplexity is 45.41005047332359
At time: 406.2017254829407 and batch: 1050, loss is 3.772839946746826 and perplexity is 43.50343701214523
At time: 407.0374948978424 and batch: 1100, loss is 3.78721061706543 and perplexity is 44.133124240273865
At time: 407.8728539943695 and batch: 1150, loss is 3.764002652168274 and perplexity is 43.120678091803676
At time: 408.7151951789856 and batch: 1200, loss is 3.819595193862915 and perplexity is 45.58575119347482
At time: 409.5583095550537 and batch: 1250, loss is 3.7996147537231444 and perplexity is 44.683966845134115
At time: 410.3958704471588 and batch: 1300, loss is 3.8031401681900023 and perplexity is 44.84177435327951
At time: 411.23845410346985 and batch: 1350, loss is 3.683241286277771 and perplexity is 39.77510787209096
At time: 412.07674860954285 and batch: 1400, loss is 3.719597339630127 and perplexity is 41.24778191717646
At time: 412.9275553226471 and batch: 1450, loss is 3.6350107765197754 and perplexity is 37.90226134941025
At time: 413.776789188385 and batch: 1500, loss is 3.638462233543396 and perplexity is 38.03330539190712
At time: 414.6339931488037 and batch: 1550, loss is 3.6449789333343507 and perplexity is 38.28196636967716
At time: 415.473836183548 and batch: 1600, loss is 3.729651675224304 and perplexity is 41.66459282619951
At time: 416.31684136390686 and batch: 1650, loss is 3.6841862344741823 and perplexity is 39.812711052267325
At time: 417.1594822406769 and batch: 1700, loss is 3.7051929569244386 and perplexity is 40.65789178178489
At time: 417.9946758747101 and batch: 1750, loss is 3.6893840265274047 and perplexity is 40.02018798926166
At time: 418.8407692909241 and batch: 1800, loss is 3.6340717935562132 and perplexity is 37.86668847549765
At time: 419.6837511062622 and batch: 1850, loss is 3.668858871459961 and perplexity is 39.2071399369705
At time: 420.52833223342896 and batch: 1900, loss is 3.7478355169296265 and perplexity is 42.429145371471236
At time: 421.36504650115967 and batch: 1950, loss is 3.682593264579773 and perplexity is 39.74934108876867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.261614848292151 and perplexity of 70.9244232116793
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 424.57293033599854 and batch: 50, loss is 3.8756090450286864 and perplexity is 48.212052662121195
At time: 425.4148979187012 and batch: 100, loss is 3.8715869092941286 and perplexity is 48.01852669702074
At time: 426.30400705337524 and batch: 150, loss is 3.847677273750305 and perplexity is 46.88403787710058
At time: 427.14800119400024 and batch: 200, loss is 3.8624905872344972 and perplexity is 47.583715303721796
At time: 427.9881772994995 and batch: 250, loss is 3.8528453302383423 and perplexity is 47.1269644215993
At time: 428.83087968826294 and batch: 300, loss is 3.8603871488571166 and perplexity is 47.483731083001715
At time: 429.6688838005066 and batch: 350, loss is 3.8735033798217775 and perplexity is 48.11064102722262
At time: 430.50591564178467 and batch: 400, loss is 3.8375145483016966 and perplexity is 46.40998120620989
At time: 431.3517553806305 and batch: 450, loss is 3.8808011770248414 and perplexity is 48.46302698543718
At time: 432.19142150878906 and batch: 500, loss is 3.88795693397522 and perplexity is 48.81106036367522
At time: 433.03641533851624 and batch: 550, loss is 3.8489687871932983 and perplexity is 46.944628360570505
At time: 433.8728919029236 and batch: 600, loss is 3.8280850982666017 and perplexity is 45.97441739820301
At time: 434.7188618183136 and batch: 650, loss is 3.8564157676696778 and perplexity is 47.29552904504385
At time: 435.55903935432434 and batch: 700, loss is 3.8902371168136596 and perplexity is 48.92248549239856
At time: 436.39381885528564 and batch: 750, loss is 3.8507704591751097 and perplexity is 47.029283419608944
At time: 437.2322962284088 and batch: 800, loss is 3.8175319766998292 and perplexity is 45.491794848721774
At time: 438.0699255466461 and batch: 850, loss is 3.8085359382629393 and perplexity is 45.08438420221506
At time: 438.90844917297363 and batch: 900, loss is 3.755352997779846 and perplexity is 42.749307558083004
At time: 439.7630133628845 and batch: 950, loss is 3.8763852977752684 and perplexity is 48.24949192970569
At time: 440.61227440834045 and batch: 1000, loss is 3.8339043951034544 and perplexity is 46.24273613593552
At time: 441.45386815071106 and batch: 1050, loss is 3.786894679069519 and perplexity is 44.11918311183016
At time: 442.29909229278564 and batch: 1100, loss is 3.7977532958984375 and perplexity is 44.600866892934704
At time: 443.140905380249 and batch: 1150, loss is 3.7709549713134765 and perplexity is 43.42151134030817
At time: 443.9794554710388 and batch: 1200, loss is 3.8188212490081788 and perplexity is 45.55048398508697
At time: 444.8215801715851 and batch: 1250, loss is 3.797895836830139 and perplexity is 44.60722479517621
At time: 445.6574172973633 and batch: 1300, loss is 3.8001928758621215 and perplexity is 44.70980710431785
At time: 446.5010914802551 and batch: 1350, loss is 3.677355980873108 and perplexity is 39.541706707018534
At time: 447.34392380714417 and batch: 1400, loss is 3.712334680557251 and perplexity is 40.94929854308006
At time: 448.1827201843262 and batch: 1450, loss is 3.628270401954651 and perplexity is 37.6476449798911
At time: 449.0213408470154 and batch: 1500, loss is 3.6290954303741456 and perplexity is 37.67871817329782
At time: 449.8626387119293 and batch: 1550, loss is 3.6369157695770262 and perplexity is 37.97453371145259
At time: 450.7005925178528 and batch: 1600, loss is 3.7227825355529784 and perplexity is 41.37937364542886
At time: 451.5342330932617 and batch: 1650, loss is 3.6744044113159178 and perplexity is 39.42516867891505
At time: 452.37649750709534 and batch: 1700, loss is 3.691622805595398 and perplexity is 40.109884716542616
At time: 453.21263909339905 and batch: 1750, loss is 3.6807550477981565 and perplexity is 39.67634029911546
At time: 454.04737639427185 and batch: 1800, loss is 3.6260714864730836 and perplexity is 37.56495194132161
At time: 454.8898379802704 and batch: 1850, loss is 3.6546094465255736 and perplexity is 38.65242232907601
At time: 455.72723031044006 and batch: 1900, loss is 3.733763222694397 and perplexity is 41.836251426847674
At time: 456.56385684013367 and batch: 1950, loss is 3.6731555700302123 and perplexity is 39.37596363161522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247467466842297 and perplexity of 69.92809269410851
finished 13 epochs...
Completing Train Step...
At time: 459.76420068740845 and batch: 50, loss is 3.8781867694854735 and perplexity is 48.33649036352951
At time: 460.6053469181061 and batch: 100, loss is 3.8620207595825193 and perplexity is 47.561364409433494
At time: 461.44301676750183 and batch: 150, loss is 3.8308725547790528 and perplexity is 46.10274786208638
At time: 462.2783257961273 and batch: 200, loss is 3.8407912349700926 and perplexity is 46.562301589709236
At time: 463.11816930770874 and batch: 250, loss is 3.827442555427551 and perplexity is 45.944886354020774
At time: 463.95212626457214 and batch: 300, loss is 3.830949487686157 and perplexity is 46.10629481694194
At time: 464.78750252723694 and batch: 350, loss is 3.845777130126953 and perplexity is 46.795036056391226
At time: 465.6286735534668 and batch: 400, loss is 3.810644497871399 and perplexity is 45.179547607314014
At time: 466.47343611717224 and batch: 450, loss is 3.8535361957550047 and perplexity is 47.15953406554966
At time: 467.3187644481659 and batch: 500, loss is 3.8618854522705077 and perplexity is 47.55492944441838
At time: 468.193635225296 and batch: 550, loss is 3.822555842399597 and perplexity is 45.72091456793221
At time: 469.0384178161621 and batch: 600, loss is 3.8052344799041746 and perplexity is 44.93578541646515
At time: 469.8825852870941 and batch: 650, loss is 3.8348784017562867 and perplexity is 46.28779881068706
At time: 470.7389371395111 and batch: 700, loss is 3.8720345163345335 and perplexity is 48.04002493866342
At time: 471.5886085033417 and batch: 750, loss is 3.8333733654022217 and perplexity is 46.21818638848051
At time: 472.43075466156006 and batch: 800, loss is 3.8005815315246583 and perplexity is 44.72718720123764
At time: 473.2735929489136 and batch: 850, loss is 3.7915649127960207 and perplexity is 44.32571190226144
At time: 474.11141872406006 and batch: 900, loss is 3.739279022216797 and perplexity is 42.06764938819772
At time: 474.9475574493408 and batch: 950, loss is 3.8609362602233888 and perplexity is 47.50981209948836
At time: 475.78399419784546 and batch: 1000, loss is 3.81965802192688 and perplexity is 45.58861534794038
At time: 476.6260290145874 and batch: 1050, loss is 3.7741491174697877 and perplexity is 43.560427735383065
At time: 477.466365814209 and batch: 1100, loss is 3.786707921028137 and perplexity is 44.110944268963856
At time: 478.30385065078735 and batch: 1150, loss is 3.7617375659942627 and perplexity is 43.0231165743786
At time: 479.13976216316223 and batch: 1200, loss is 3.8106732845306395 and perplexity is 45.1808481942753
At time: 479.9739649295807 and batch: 1250, loss is 3.7917390871047973 and perplexity is 44.33343297487977
At time: 480.8106219768524 and batch: 1300, loss is 3.795632152557373 and perplexity is 44.50636232541939
At time: 481.6464874744415 and batch: 1350, loss is 3.6738603925704956 and perplexity is 39.40372648111989
At time: 482.4834771156311 and batch: 1400, loss is 3.710157470703125 and perplexity is 40.86024031118237
At time: 483.3309772014618 and batch: 1450, loss is 3.627339916229248 and perplexity is 37.61263067632339
At time: 484.17489528656006 and batch: 1500, loss is 3.629873652458191 and perplexity is 37.708051996512864
At time: 485.0166132450104 and batch: 1550, loss is 3.6387053680419923 and perplexity is 38.04255372479238
At time: 485.86161255836487 and batch: 1600, loss is 3.7255292654037477 and perplexity is 41.49318784309783
At time: 486.6996982097626 and batch: 1650, loss is 3.678500995635986 and perplexity is 39.587008475594935
At time: 487.53750109672546 and batch: 1700, loss is 3.696793584823608 and perplexity is 40.31782120882947
At time: 488.3737156391144 and batch: 1750, loss is 3.686446576118469 and perplexity is 39.90280316214682
At time: 489.2074844837189 and batch: 1800, loss is 3.6325751066207888 and perplexity is 37.810056288467486
At time: 490.04271483421326 and batch: 1850, loss is 3.6610390186309814 and perplexity is 38.90174151443777
At time: 490.88075256347656 and batch: 1900, loss is 3.740386862754822 and perplexity is 42.114279460102225
At time: 491.72394132614136 and batch: 1950, loss is 3.6790436124801635 and perplexity is 39.60849488212024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246265500090843 and perplexity of 69.8440919448646
finished 14 epochs...
Completing Train Step...
At time: 494.87915420532227 and batch: 50, loss is 3.874382119178772 and perplexity is 48.1529363215317
At time: 495.7386772632599 and batch: 100, loss is 3.85633496761322 and perplexity is 47.29170771801061
At time: 496.5747151374817 and batch: 150, loss is 3.8238366985321046 and perplexity is 45.77951400245145
At time: 497.41211342811584 and batch: 200, loss is 3.8325013446807863 and perplexity is 46.17790073975566
At time: 498.24630546569824 and batch: 250, loss is 3.8184190464019774 and perplexity is 45.53216714550167
At time: 499.08306550979614 and batch: 300, loss is 3.820707950592041 and perplexity is 45.63650527810513
At time: 499.9177918434143 and batch: 350, loss is 3.8359574699401855 and perplexity is 46.33777345986418
At time: 500.7478938102722 and batch: 400, loss is 3.8008328008651735 and perplexity is 44.73842718414121
At time: 501.5794286727905 and batch: 450, loss is 3.8437533569335938 and perplexity is 46.700429280456284
At time: 502.4104800224304 and batch: 500, loss is 3.8521149158477783 and perplexity is 47.092554776781846
At time: 503.2391142845154 and batch: 550, loss is 3.8127206325531007 and perplexity is 45.273443869921756
At time: 504.0683493614197 and batch: 600, loss is 3.7965475845336916 and perplexity is 44.54712352684875
At time: 504.89780473709106 and batch: 650, loss is 3.826489815711975 and perplexity is 45.90113368182747
At time: 505.7288248538971 and batch: 700, loss is 3.86425386428833 and perplexity is 47.66769259290835
At time: 506.572146654129 and batch: 750, loss is 3.826012110710144 and perplexity is 45.879211717210914
At time: 507.40640568733215 and batch: 800, loss is 3.7934671592712403 and perplexity is 44.41011057958233
At time: 508.2358090877533 and batch: 850, loss is 3.7844657564163207 and perplexity is 44.01215106742896
At time: 509.0721390247345 and batch: 900, loss is 3.7325857782363894 and perplexity is 41.787020553458554
At time: 509.90486574172974 and batch: 950, loss is 3.854638705253601 and perplexity is 47.21155657219059
At time: 510.79046297073364 and batch: 1000, loss is 3.8137459087371828 and perplexity is 45.31988545735148
At time: 511.6278374195099 and batch: 1050, loss is 3.7688355922698973 and perplexity is 43.32958214994314
At time: 512.4724497795105 and batch: 1100, loss is 3.7819381856918337 and perplexity is 43.901047712812186
At time: 513.3115682601929 and batch: 1150, loss is 3.757543454170227 and perplexity is 42.84305068464087
At time: 514.145877122879 and batch: 1200, loss is 3.8068569564819335 and perplexity is 45.008751852967066
At time: 514.968879699707 and batch: 1250, loss is 3.7886411905288697 and perplexity is 44.19630509832498
At time: 515.8026428222656 and batch: 1300, loss is 3.7931156587600707 and perplexity is 44.39450314618361
At time: 516.6475994586945 and batch: 1350, loss is 3.6715545415878297 and perplexity is 39.31297203302076
At time: 517.4845869541168 and batch: 1400, loss is 3.7083280277252197 and perplexity is 40.785557166576304
At time: 518.3242304325104 and batch: 1450, loss is 3.6259647703170774 and perplexity is 37.560943367943445
At time: 519.169007062912 and batch: 1500, loss is 3.629081325531006 and perplexity is 37.67818672463629
At time: 520.0160455703735 and batch: 1550, loss is 3.6382360315322875 and perplexity is 38.02470315469673
At time: 520.8636498451233 and batch: 1600, loss is 3.7256361055374145 and perplexity is 41.497621217660196
At time: 521.7058155536652 and batch: 1650, loss is 3.6790746736526487 and perplexity is 39.60972518751892
At time: 522.5435600280762 and batch: 1700, loss is 3.697655234336853 and perplexity is 40.35257601092803
At time: 523.37864112854 and batch: 1750, loss is 3.6875082635879517 and perplexity is 39.94518996504859
At time: 524.2229330539703 and batch: 1800, loss is 3.633949637413025 and perplexity is 37.86206310939236
At time: 525.0606715679169 and batch: 1850, loss is 3.6625334882736205 and perplexity is 38.959922450169366
At time: 525.8991708755493 and batch: 1900, loss is 3.7419496965408325 and perplexity is 42.18014853671834
At time: 526.7380378246307 and batch: 1950, loss is 3.6802851247787474 and perplexity is 39.65769985361323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246052302870639 and perplexity of 69.8292029658152
finished 15 epochs...
Completing Train Step...
At time: 529.9252502918243 and batch: 50, loss is 3.86987340927124 and perplexity is 47.936317403354046
At time: 530.7889220714569 and batch: 100, loss is 3.8510324573516845 and perplexity is 47.04160662036807
At time: 531.6270310878754 and batch: 150, loss is 3.8180213260650633 and perplexity is 45.514061677339235
At time: 532.5345766544342 and batch: 200, loss is 3.8262402772903443 and perplexity is 45.88968101437716
At time: 533.3750376701355 and batch: 250, loss is 3.8118854331970216 and perplexity is 45.23564730478465
At time: 534.2186813354492 and batch: 300, loss is 3.8136548471450804 and perplexity is 45.31575874432322
At time: 535.0486109256744 and batch: 350, loss is 3.829224400520325 and perplexity is 46.02682600451113
At time: 535.8816869258881 and batch: 400, loss is 3.7940452671051026 and perplexity is 44.43579183496329
At time: 536.7220931053162 and batch: 450, loss is 3.837152433395386 and perplexity is 46.39317850265185
At time: 537.5568587779999 and batch: 500, loss is 3.8454650831222534 and perplexity is 46.78043608361237
At time: 538.3936758041382 and batch: 550, loss is 3.806165490150452 and perplexity is 44.977640573879334
At time: 539.2310883998871 and batch: 600, loss is 3.7906426620483398 and perplexity is 44.284851326062714
At time: 540.065055847168 and batch: 650, loss is 3.8206991577148437 and perplexity is 45.63610400368268
At time: 540.9146032333374 and batch: 700, loss is 3.8587155961990356 and perplexity is 47.404425826016364
At time: 541.7526443004608 and batch: 750, loss is 3.820814151763916 and perplexity is 45.64135218581503
At time: 542.5922672748566 and batch: 800, loss is 3.7884112930297853 and perplexity is 44.18614564617516
At time: 543.4276394844055 and batch: 850, loss is 3.7794590854644774 and perplexity is 43.79234741059025
At time: 544.2636382579803 and batch: 900, loss is 3.7278146314620972 and perplexity is 41.588123406184074
At time: 545.1007196903229 and batch: 950, loss is 3.8501402378082275 and perplexity is 46.99965389788827
At time: 545.9348957538605 and batch: 1000, loss is 3.8094605207443237 and perplexity is 45.126087710228035
At time: 546.7677958011627 and batch: 1050, loss is 3.7649203872680665 and perplexity is 43.16026961610233
At time: 547.6105310916901 and batch: 1100, loss is 3.7782673978805543 and perplexity is 43.740191696740794
At time: 548.4520814418793 and batch: 1150, loss is 3.754161796569824 and perplexity is 42.69841484893846
At time: 549.2969808578491 and batch: 1200, loss is 3.8036688709259034 and perplexity is 44.86548859040138
At time: 550.1296789646149 and batch: 1250, loss is 3.785884213447571 and perplexity is 44.07462471018507
At time: 550.9644243717194 and batch: 1300, loss is 3.7907023286819457 and perplexity is 44.28749373289205
At time: 551.8029358386993 and batch: 1350, loss is 3.669197826385498 and perplexity is 39.220431642685654
At time: 552.6437613964081 and batch: 1400, loss is 3.706289176940918 and perplexity is 40.70248621477321
At time: 553.481479883194 and batch: 1450, loss is 3.6241553354263307 and perplexity is 37.4930407377047
At time: 554.3234620094299 and batch: 1500, loss is 3.6275747776031495 and perplexity is 37.62146546787511
At time: 555.1650416851044 and batch: 1550, loss is 3.6369020748138428 and perplexity is 37.97401366276739
At time: 556.0037250518799 and batch: 1600, loss is 3.7247657632827758 and perplexity is 41.46151979702228
At time: 556.8403775691986 and batch: 1650, loss is 3.6784365606307983 and perplexity is 39.58445776867673
At time: 557.6757109165192 and batch: 1700, loss is 3.6971710252761842 and perplexity is 40.33304165773928
At time: 558.517028093338 and batch: 1750, loss is 3.6872081184387206 and perplexity is 39.93320240913884
At time: 559.3600826263428 and batch: 1800, loss is 3.6338125896453857 and perplexity is 37.856874553713105
At time: 560.1972165107727 and batch: 1850, loss is 3.6625836420059206 and perplexity is 38.96187648469102
At time: 561.0368993282318 and batch: 1900, loss is 3.7420557355880737 and perplexity is 42.18462151663274
At time: 561.8750412464142 and batch: 1950, loss is 3.680235366821289 and perplexity is 39.655726616563555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246161030614099 and perplexity of 69.8367957502469
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 564.9852788448334 and batch: 50, loss is 3.8694832372665404 and perplexity is 47.91761764259366
At time: 565.8711829185486 and batch: 100, loss is 3.8560637521743772 and perplexity is 47.27888321592834
At time: 566.7411179542542 and batch: 150, loss is 3.8255916118621824 and perplexity is 45.85992361713458
At time: 567.5790817737579 and batch: 200, loss is 3.8344821882247926 and perplexity is 46.2694625912242
At time: 568.42462682724 and batch: 250, loss is 3.8224690628051756 and perplexity is 45.71694709765965
At time: 569.2587945461273 and batch: 300, loss is 3.823456673622131 and perplexity is 45.76211995205959
At time: 570.097131729126 and batch: 350, loss is 3.840768518447876 and perplexity is 46.56124386816464
At time: 570.9372029304504 and batch: 400, loss is 3.8094899797439576 and perplexity is 45.12741709921051
At time: 571.7740144729614 and batch: 450, loss is 3.8571404075622557 and perplexity is 47.3298136926419
At time: 572.6105623245239 and batch: 500, loss is 3.8650149154663085 and perplexity is 47.70398395454781
At time: 573.4484210014343 and batch: 550, loss is 3.8271605873107912 and perplexity is 45.93193318721663
At time: 574.2900242805481 and batch: 600, loss is 3.806534171104431 and perplexity is 44.99422603049697
At time: 575.1841697692871 and batch: 650, loss is 3.8330099105834963 and perplexity is 46.201391218252525
At time: 576.0255994796753 and batch: 700, loss is 3.8705198431015013 and perplexity is 47.96731507851522
At time: 576.8811666965485 and batch: 750, loss is 3.832593336105347 and perplexity is 46.182148906022356
At time: 577.7219970226288 and batch: 800, loss is 3.7991201972961424 and perplexity is 44.661873565783864
At time: 578.5602350234985 and batch: 850, loss is 3.791705322265625 and perplexity is 44.33193608891662
At time: 579.4027886390686 and batch: 900, loss is 3.736609797477722 and perplexity is 41.95551110545512
At time: 580.2437262535095 and batch: 950, loss is 3.8635342359542846 and perplexity is 47.6334019104531
At time: 581.0860185623169 and batch: 1000, loss is 3.820123929977417 and perplexity is 45.60986039957982
At time: 581.9289178848267 and batch: 1050, loss is 3.775759081840515 and perplexity is 43.63061495631282
At time: 582.7685279846191 and batch: 1100, loss is 3.784661545753479 and perplexity is 44.02076902093754
At time: 583.6086633205414 and batch: 1150, loss is 3.7594782161712645 and perplexity is 42.926022030135016
At time: 584.4458856582642 and batch: 1200, loss is 3.8072496891021728 and perplexity is 45.026431729520866
At time: 585.2834448814392 and batch: 1250, loss is 3.7860548448562623 and perplexity is 44.08214586714147
At time: 586.1193869113922 and batch: 1300, loss is 3.7899668550491334 and perplexity is 44.25493342408019
At time: 586.9547860622406 and batch: 1350, loss is 3.6657517528533936 and perplexity is 39.0855077636115
At time: 587.8001878261566 and batch: 1400, loss is 3.700515112876892 and perplexity is 40.46814465447002
At time: 588.6360032558441 and batch: 1450, loss is 3.6172228813171388 and perplexity is 37.23402081259923
At time: 589.4711356163025 and batch: 1500, loss is 3.6181263875961305 and perplexity is 37.26767718627846
At time: 590.3043186664581 and batch: 1550, loss is 3.626972126960754 and perplexity is 37.598799697999425
At time: 591.1432223320007 and batch: 1600, loss is 3.7140855836868285 and perplexity is 41.02105960305247
At time: 591.9810066223145 and batch: 1650, loss is 3.665264172554016 and perplexity is 39.06645508526756
At time: 592.8170902729034 and batch: 1700, loss is 3.6825086212158205 and perplexity is 39.74597671321206
At time: 593.6536190509796 and batch: 1750, loss is 3.674071545600891 and perplexity is 39.412047575856526
At time: 594.4988749027252 and batch: 1800, loss is 3.6219154167175294 and perplexity is 37.40915335983359
At time: 595.340537071228 and batch: 1850, loss is 3.6512166118621825 and perplexity is 38.52150326972288
At time: 596.179411649704 and batch: 1900, loss is 3.7318844747543336 and perplexity is 41.757725444021474
At time: 597.0143785476685 and batch: 1950, loss is 3.6752385187149046 and perplexity is 39.45806722236831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242544342750727 and perplexity of 69.58467405619736
finished 17 epochs...
Completing Train Step...
At time: 600.2305016517639 and batch: 50, loss is 3.8710997247695924 and perplexity is 47.99513851156652
At time: 601.0693295001984 and batch: 100, loss is 3.8536851310729983 and perplexity is 47.166558308818104
At time: 601.9054069519043 and batch: 150, loss is 3.8210532379150393 and perplexity is 45.65226570562493
At time: 602.7388615608215 and batch: 200, loss is 3.827978868484497 and perplexity is 45.96953380525651
At time: 603.5750031471252 and batch: 250, loss is 3.815121922492981 and perplexity is 45.38228916748745
At time: 604.4119427204132 and batch: 300, loss is 3.815117335319519 and perplexity is 45.382080991532405
At time: 605.247841835022 and batch: 350, loss is 3.8321789693832398 and perplexity is 46.163016524545164
At time: 606.0867621898651 and batch: 400, loss is 3.800623588562012 and perplexity is 44.72906833377764
At time: 606.9198770523071 and batch: 450, loss is 3.8473877811431887 and perplexity is 46.870467259134955
At time: 607.7611665725708 and batch: 500, loss is 3.8557990169525147 and perplexity is 47.266368486908625
At time: 608.6003329753876 and batch: 550, loss is 3.818204321861267 and perplexity is 45.52239132141603
At time: 609.4465503692627 and batch: 600, loss is 3.7986028718948366 and perplexity is 44.63877481941765
At time: 610.2807183265686 and batch: 650, loss is 3.8255170822143554 and perplexity is 45.856505820543184
At time: 611.1195924282074 and batch: 700, loss is 3.8638319778442383 and perplexity is 47.6475864811285
At time: 611.9567849636078 and batch: 750, loss is 3.8261044025421143 and perplexity is 45.883446189110224
At time: 612.7928123474121 and batch: 800, loss is 3.7929908847808838 and perplexity is 44.38896421293659
At time: 613.6294445991516 and batch: 850, loss is 3.7853827905654907 and perplexity is 44.05253022463952
At time: 614.4665832519531 and batch: 900, loss is 3.7309825897216795 and perplexity is 41.72008175413768
At time: 615.308899641037 and batch: 950, loss is 3.8573131561279297 and perplexity is 47.337990556321316
At time: 616.1509206295013 and batch: 1000, loss is 3.814669065475464 and perplexity is 45.36174213215268
At time: 617.0461766719818 and batch: 1050, loss is 3.7702911710739135 and perplexity is 43.39269769498864
At time: 617.8890368938446 and batch: 1100, loss is 3.7796106481552125 and perplexity is 43.79898519960528
At time: 618.725658416748 and batch: 1150, loss is 3.754738907814026 and perplexity is 42.72306369613669
At time: 619.5650222301483 and batch: 1200, loss is 3.8031827211380005 and perplexity is 44.843682543570985
At time: 620.4041798114777 and batch: 1250, loss is 3.78306640625 and perplexity is 43.95060572829598
At time: 621.2467696666718 and batch: 1300, loss is 3.7872406101226805 and perplexity is 44.134447947446766
At time: 622.086329460144 and batch: 1350, loss is 3.663887553215027 and perplexity is 39.01271244775572
At time: 622.9226965904236 and batch: 1400, loss is 3.6998529195785523 and perplexity is 40.44135579096544
At time: 623.7588365077972 and batch: 1450, loss is 3.617545943260193 and perplexity is 37.246051650959046
At time: 624.5993142127991 and batch: 1500, loss is 3.619232473373413 and perplexity is 37.30892123949197
At time: 625.4430899620056 and batch: 1550, loss is 3.6290403461456298 and perplexity is 37.676642727338475
At time: 626.280999660492 and batch: 1600, loss is 3.7169260740280152 and perplexity is 41.13774517029821
At time: 627.1168293952942 and batch: 1650, loss is 3.6686835384368894 and perplexity is 39.200266233210606
At time: 627.9569692611694 and batch: 1700, loss is 3.6862916421890257 and perplexity is 39.89662134295624
At time: 628.7954778671265 and batch: 1750, loss is 3.6787824726104734 and perplexity is 39.59815287534202
At time: 629.6317265033722 and batch: 1800, loss is 3.626498384475708 and perplexity is 37.58099176771537
At time: 630.4670379161835 and batch: 1850, loss is 3.655640411376953 and perplexity is 38.69229216658707
At time: 631.3059012889862 and batch: 1900, loss is 3.7363409566879273 and perplexity is 41.94423326875248
At time: 632.1470086574554 and batch: 1950, loss is 3.679483437538147 and perplexity is 39.6259195222942
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241616608375727 and perplexity of 69.52014789829774
finished 18 epochs...
Completing Train Step...
At time: 635.3357751369476 and batch: 50, loss is 3.871133337020874 and perplexity is 47.99675176333482
At time: 636.1706120967865 and batch: 100, loss is 3.8522775745391846 and perplexity is 47.10021541313447
At time: 637.0173532962799 and batch: 150, loss is 3.8188620138168337 and perplexity is 45.55234087969848
At time: 637.8557314872742 and batch: 200, loss is 3.8248475980758667 and perplexity is 45.82581589160643
At time: 638.720959186554 and batch: 250, loss is 3.8114056539535524 and perplexity is 45.21394938566475
At time: 639.5582711696625 and batch: 300, loss is 3.810898475646973 and perplexity is 45.191023665586926
At time: 640.4002754688263 and batch: 350, loss is 3.8279215908050537 and perplexity is 45.96690085244049
At time: 641.2450408935547 and batch: 400, loss is 3.7961481285095213 and perplexity is 44.52933246360676
At time: 642.081844329834 and batch: 450, loss is 3.8427099227905273 and perplexity is 46.65172587186773
At time: 642.922110080719 and batch: 500, loss is 3.851141805648804 and perplexity is 47.04675082119544
At time: 643.7570881843567 and batch: 550, loss is 3.81339394569397 and perplexity is 45.30393733928657
At time: 644.5966238975525 and batch: 600, loss is 3.7943622064590454 and perplexity is 44.44987751815516
At time: 645.4417188167572 and batch: 650, loss is 3.821515374183655 and perplexity is 45.67336814907865
At time: 646.2900717258453 and batch: 700, loss is 3.860255823135376 and perplexity is 47.47749565719115
At time: 647.126291513443 and batch: 750, loss is 3.8226493549346925 and perplexity is 45.72519024647199
At time: 647.9752633571625 and batch: 800, loss is 3.7896688270568846 and perplexity is 44.24174618030621
At time: 648.8165690898895 and batch: 850, loss is 3.7820295333862304 and perplexity is 43.905058155471906
At time: 649.6510853767395 and batch: 900, loss is 3.727874422073364 and perplexity is 41.590610059842504
At time: 650.4929246902466 and batch: 950, loss is 3.8541113328933716 and perplexity is 47.186665066294026
At time: 651.3299548625946 and batch: 1000, loss is 3.8118074226379393 and perplexity is 45.23211858428847
At time: 652.1679177284241 and batch: 1050, loss is 3.7675515604019165 and perplexity is 43.27398128991368
At time: 653.0080168247223 and batch: 1100, loss is 3.7772747898101806 and perplexity is 43.69679637030155
At time: 653.8420612812042 and batch: 1150, loss is 3.7527314043045044 and perplexity is 42.63738302672638
At time: 654.6764318943024 and batch: 1200, loss is 3.8014229679107667 and perplexity is 44.76483812220303
At time: 655.5163550376892 and batch: 1250, loss is 3.781798071861267 and perplexity is 43.89489699976129
At time: 656.3523464202881 and batch: 1300, loss is 3.786219620704651 and perplexity is 44.08941013859732
At time: 657.1866705417633 and batch: 1350, loss is 3.663225393295288 and perplexity is 38.98688834399931
At time: 658.0231125354767 and batch: 1400, loss is 3.6996989965438845 and perplexity is 40.43513141380581
At time: 658.8590054512024 and batch: 1450, loss is 3.6178611516952515 and perplexity is 37.25779377112249
At time: 659.6966860294342 and batch: 1500, loss is 3.6199914407730103 and perplexity is 37.3372482427031
At time: 660.5400927066803 and batch: 1550, loss is 3.6302361917495727 and perplexity is 37.721725125336526
At time: 661.379655122757 and batch: 1600, loss is 3.718412508964539 and perplexity is 41.198939221149395
At time: 662.2228786945343 and batch: 1650, loss is 3.670459842681885 and perplexity is 39.26995971261219
At time: 663.0573105812073 and batch: 1700, loss is 3.6882467555999754 and perplexity is 39.97470006390153
At time: 663.8913536071777 and batch: 1750, loss is 3.68105504989624 and perplexity is 39.68824507008832
At time: 664.7284741401672 and batch: 1800, loss is 3.628687605857849 and perplexity is 37.66335500123616
At time: 665.5643520355225 and batch: 1850, loss is 3.657800989151001 and perplexity is 38.77598024781798
At time: 666.4013769626617 and batch: 1900, loss is 3.7384017658233644 and perplexity is 42.03076145626799
At time: 667.243980884552 and batch: 1950, loss is 3.6813270378112795 and perplexity is 39.69904126126671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2412458552870635 and perplexity of 69.49437786619478
finished 19 epochs...
Completing Train Step...
At time: 670.4779152870178 and batch: 50, loss is 3.870460662841797 and perplexity is 47.96447644434794
At time: 671.3161389827728 and batch: 100, loss is 3.850882205963135 and perplexity is 47.03453908462058
At time: 672.1583385467529 and batch: 150, loss is 3.817065215110779 and perplexity is 45.47056598106485
At time: 673.0061945915222 and batch: 200, loss is 3.822553553581238 and perplexity is 45.7208099211833
At time: 673.8463525772095 and batch: 250, loss is 3.8087994956970217 and perplexity is 45.09626809280765
At time: 674.6814141273499 and batch: 300, loss is 3.80795440196991 and perplexity is 45.05817361849411
At time: 675.5165832042694 and batch: 350, loss is 3.8250096893310546 and perplexity is 45.83324445766084
At time: 676.3562383651733 and batch: 400, loss is 3.7930878400802612 and perplexity is 44.39326816689311
At time: 677.1950314044952 and batch: 450, loss is 3.839600195884705 and perplexity is 46.506877081540026
At time: 678.0306334495544 and batch: 500, loss is 3.848011293411255 and perplexity is 46.89970068323322
At time: 678.8659381866455 and batch: 550, loss is 3.8101589393615725 and perplexity is 45.15761561856595
At time: 679.7013528347015 and batch: 600, loss is 3.7915046501159666 and perplexity is 44.3230407965517
At time: 680.5392520427704 and batch: 650, loss is 3.8188255405426026 and perplexity is 45.550679466976476
At time: 681.4046850204468 and batch: 700, loss is 3.8578075122833253 and perplexity is 47.36139816870882
At time: 682.2472312450409 and batch: 750, loss is 3.820283818244934 and perplexity is 45.61715346416299
At time: 683.0841133594513 and batch: 800, loss is 3.7873956871032717 and perplexity is 44.14129271509375
At time: 683.9273283481598 and batch: 850, loss is 3.779749574661255 and perplexity is 43.805070462279616
At time: 684.7743227481842 and batch: 900, loss is 3.725744433403015 and perplexity is 41.502116809888754
At time: 685.6098110675812 and batch: 950, loss is 3.852020363807678 and perplexity is 47.08810229015334
At time: 686.4499571323395 and batch: 1000, loss is 3.809886293411255 and perplexity is 45.14530525580309
At time: 687.2972707748413 and batch: 1050, loss is 3.7657591247558595 and perplexity is 43.196484937663456
At time: 688.1348297595978 and batch: 1100, loss is 3.7757660865783693 and perplexity is 43.630920578403405
At time: 688.9820449352264 and batch: 1150, loss is 3.751479425430298 and perplexity is 42.584035325990946
At time: 689.8244707584381 and batch: 1200, loss is 3.800291657447815 and perplexity is 44.71422382810157
At time: 690.6670746803284 and batch: 1250, loss is 3.7809608507156374 and perplexity is 43.858162643343555
At time: 691.5082125663757 and batch: 1300, loss is 3.78557701587677 and perplexity is 44.06108717199603
At time: 692.3483290672302 and batch: 1350, loss is 3.6627601480484007 and perplexity is 38.96875409826925
At time: 693.1904819011688 and batch: 1400, loss is 3.6994978618621825 and perplexity is 40.42699932436935
At time: 694.0284955501556 and batch: 1450, loss is 3.6179253578186037 and perplexity is 37.26018602642309
At time: 694.8641862869263 and batch: 1500, loss is 3.620323042869568 and perplexity is 37.34963140552797
At time: 695.6931099891663 and batch: 1550, loss is 3.6308088207244875 and perplexity is 37.74333186385892
At time: 696.532185792923 and batch: 1600, loss is 3.719126987457275 and perplexity is 41.22838549525859
At time: 697.3679184913635 and batch: 1650, loss is 3.67133864402771 and perplexity is 39.304485374435174
At time: 698.2099165916443 and batch: 1700, loss is 3.6892245292663572 and perplexity is 40.013805387908015
At time: 699.0550212860107 and batch: 1750, loss is 3.682163996696472 and perplexity is 39.732281635056644
At time: 699.9012491703033 and batch: 1800, loss is 3.6297541522979735 and perplexity is 37.703546147488
At time: 700.7360241413116 and batch: 1850, loss is 3.658892607688904 and perplexity is 38.8183319384215
At time: 701.5398533344269 and batch: 1900, loss is 3.7394139051437376 and perplexity is 42.07332397857079
At time: 702.3836493492126 and batch: 1950, loss is 3.682171468734741 and perplexity is 39.73257851729469
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241076944040698 and perplexity of 69.48264047553053
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f092a560b38>
ELAPSED
4406.351914405823


RESULTS SO FAR:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}, 'best_accuracy': -69.56506109203387}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.0664099827407102, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3472414743178278}, 'best_accuracy': -69.30740757369114}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.49972324366546084, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.08468759351567401}, 'best_accuracy': -69.3424384490586}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7948334406587833, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0}, 'best_accuracy': -69.48264047553053}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.33084560505087823, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8185698134951926}, 'best_accuracy': -69.43366074517346}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7191641367921272, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.014537151514742774}, 'best_accuracy': -69.11913507956415}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.39325123379275617, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.553677290247818}, 'best_accuracy': -69.56506109203387}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.0664099827407102, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3472414743178278}, 'best_accuracy': -69.30740757369114}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.49972324366546084, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.08468759351567401}, 'best_accuracy': -69.3424384490586}, {'params': {'data': 'wikitext', 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'dropout': 0.7948334406587833, 'num_layers': 3, 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0}, 'best_accuracy': -69.48264047553053}]
