Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 30], 'type': 'continuous', 'name': 'lr'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [2, 8], 'type': 'continuous', 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'dropout': 0.052955126623090765, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 9.519869146181783, 'wordvec_source': '', 'anneal': 5.67024530226525, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.754244089126587 and batch: 50, loss is 7.012878437042236 and perplexity is 1110.8474117437318
At time: 2.8714756965637207 and batch: 100, loss is 6.021400032043457 and perplexity is 412.15522250287916
At time: 3.949347496032715 and batch: 150, loss is 5.743008394241333 and perplexity is 312.001624410966
At time: 5.0326087474823 and batch: 200, loss is 5.6257960224151615 and perplexity is 277.4930873470567
At time: 6.12008810043335 and batch: 250, loss is 5.612596521377563 and perplexity is 273.8543844140815
At time: 7.208069086074829 and batch: 300, loss is 5.5490634155273435 and perplexity is 256.9967439930816
At time: 8.29332947731018 and batch: 350, loss is 5.521453857421875 and perplexity is 249.99823489613834
At time: 9.379091501235962 and batch: 400, loss is 5.523269844055176 and perplexity is 250.45264082172346
At time: 10.466068983078003 and batch: 450, loss is 5.4768564319610595 and perplexity is 239.09391677486678
At time: 11.553708553314209 and batch: 500, loss is 5.485683526992798 and perplexity is 241.21376378080353
At time: 12.639951467514038 and batch: 550, loss is 5.442282924652099 and perplexity is 230.96886656232152
At time: 13.725462198257446 and batch: 600, loss is 5.384576396942139 and perplexity is 218.01773156644603
At time: 14.811883449554443 and batch: 650, loss is 5.392868547439575 and perplexity is 219.8330835918863
At time: 15.89978289604187 and batch: 700, loss is 5.39306396484375 and perplexity is 219.87604700019574
At time: 16.98699426651001 and batch: 750, loss is 5.3507974815368655 and perplexity is 210.77632108453588
At time: 18.073692560195923 and batch: 800, loss is 5.300718879699707 and perplexity is 200.4808798188252
At time: 19.1662437915802 and batch: 850, loss is 5.297835206985473 and perplexity is 199.90359133153578
At time: 20.261658668518066 and batch: 900, loss is 5.339907789230347 and perplexity is 208.49348405804452
At time: 21.3765652179718 and batch: 950, loss is 5.2849267482757565 and perplexity is 197.3397274434031
At time: 22.54294991493225 and batch: 1000, loss is 5.303531522750855 and perplexity is 201.0455547145364
At time: 23.750260591506958 and batch: 1050, loss is 5.237956085205078 and perplexity is 188.2848706165878
At time: 24.960241317749023 and batch: 1100, loss is 5.213804712295532 and perplexity is 183.79200531020751
At time: 26.17016887664795 and batch: 1150, loss is 5.2283495330810545 and perplexity is 186.4847624529829
At time: 27.38016629219055 and batch: 1200, loss is 5.215770053863525 and perplexity is 184.15357456526962
At time: 28.59075427055359 and batch: 1250, loss is 5.24683952331543 and perplexity is 189.96493895477647
At time: 29.80271077156067 and batch: 1300, loss is 5.2102511119842525 and perplexity is 183.14004107916122
At time: 31.012814044952393 and batch: 1350, loss is 5.1804541492462155 and perplexity is 177.76352383449324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.972127685546875 and perplexity of 144.33365753703418
Finished 1 epochs...
Completing Train Step...
At time: 34.562997579574585 and batch: 50, loss is 5.179507122039795 and perplexity is 177.59525663049894
At time: 35.76412773132324 and batch: 100, loss is 5.1656607723236085 and perplexity is 175.15315670086775
At time: 36.9658317565918 and batch: 150, loss is 5.087687511444091 and perplexity is 162.01477121967827
At time: 38.1681022644043 and batch: 200, loss is 5.068587894439697 and perplexity is 158.94971501608015
At time: 39.36982798576355 and batch: 250, loss is 5.088220443725586 and perplexity is 162.10113713288766
At time: 40.57091975212097 and batch: 300, loss is 5.054306383132935 and perplexity is 156.69580578804124
At time: 41.772984981536865 and batch: 350, loss is 5.053419370651245 and perplexity is 156.55687627769268
At time: 42.97482681274414 and batch: 400, loss is 5.070565052032471 and perplexity is 159.26429453615847
At time: 44.1761429309845 and batch: 450, loss is 5.037507219314575 and perplexity is 154.08543469231785
At time: 45.37875533103943 and batch: 500, loss is 5.0827314567565915 and perplexity is 161.2138036124414
At time: 46.580166816711426 and batch: 550, loss is 5.057784128189087 and perplexity is 157.24170254661183
At time: 47.78261852264404 and batch: 600, loss is 5.006908311843872 and perplexity is 149.44199314886907
At time: 48.984477043151855 and batch: 650, loss is 5.017861852645874 and perplexity is 151.08790997048905
At time: 50.18713974952698 and batch: 700, loss is 5.033193292617798 and perplexity is 153.42215312468207
At time: 51.38900399208069 and batch: 750, loss is 4.983631811141968 and perplexity is 146.00367770362962
At time: 52.59046721458435 and batch: 800, loss is 4.948468770980835 and perplexity is 140.95895813930673
At time: 53.7913019657135 and batch: 850, loss is 4.9313920307159425 and perplexity is 138.57227500624404
At time: 54.99687886238098 and batch: 900, loss is 4.975254993438721 and perplexity is 144.78573985516033
At time: 56.198121309280396 and batch: 950, loss is 4.923014163970947 and perplexity is 137.4161844998231
At time: 57.398415327072144 and batch: 1000, loss is 4.957152023315429 and perplexity is 142.1882698294036
At time: 58.59673619270325 and batch: 1050, loss is 4.893469142913818 and perplexity is 133.41560997150728
At time: 59.79322862625122 and batch: 1100, loss is 4.87090497970581 and perplexity is 130.4389080632456
At time: 60.99119973182678 and batch: 1150, loss is 4.895853052139282 and perplexity is 133.73404007837016
At time: 62.18771243095398 and batch: 1200, loss is 4.865377216339112 and perplexity is 129.71986183530086
At time: 63.384281635284424 and batch: 1250, loss is 4.91145320892334 and perplexity is 135.83667010799755
At time: 64.5819501876831 and batch: 1300, loss is 4.894516935348511 and perplexity is 133.55547510032113
At time: 65.7781970500946 and batch: 1350, loss is 4.873172101974487 and perplexity is 130.734964487667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.872542317708334 and perplexity of 130.65265558514295
Finished 2 epochs...
Completing Train Step...
At time: 69.32493495941162 and batch: 50, loss is 4.92224455833435 and perplexity is 137.3104689145454
At time: 70.5624611377716 and batch: 100, loss is 4.920763921737671 and perplexity is 137.10731244672863
At time: 71.76040649414062 and batch: 150, loss is 4.861496086120606 and perplexity is 129.21737789314756
At time: 72.95856547355652 and batch: 200, loss is 4.839065933227539 and perplexity is 126.35127606479176
At time: 74.15569829940796 and batch: 250, loss is 4.860779514312744 and perplexity is 129.12481753009752
At time: 75.35330414772034 and batch: 300, loss is 4.826328992843628 and perplexity is 124.75215298052522
At time: 76.55138182640076 and batch: 350, loss is 4.837775392532349 and perplexity is 126.18831977461976
At time: 77.74968957901001 and batch: 400, loss is 4.8471243190765385 and perplexity is 127.37357691504832
At time: 78.9506847858429 and batch: 450, loss is 4.808224258422851 and perplexity is 122.51387126895975
At time: 80.15169835090637 and batch: 500, loss is 4.872616415023804 and perplexity is 130.66233695485818
At time: 81.34915447235107 and batch: 550, loss is 4.848495435714722 and perplexity is 127.54834072902892
At time: 82.54688477516174 and batch: 600, loss is 4.803786001205444 and perplexity is 121.97132805931595
At time: 83.74491262435913 and batch: 650, loss is 4.811813907623291 and perplexity is 122.95444336555478
At time: 84.94379019737244 and batch: 700, loss is 4.837613334655762 and perplexity is 126.16787162040403
At time: 86.14171409606934 and batch: 750, loss is 4.78183180809021 and perplexity is 119.32272630744363
At time: 87.33973598480225 and batch: 800, loss is 4.748999300003052 and perplexity is 115.4686771877936
At time: 88.5379285812378 and batch: 850, loss is 4.724278812408447 and perplexity is 112.64922784662268
At time: 89.735769033432 and batch: 900, loss is 4.766627607345581 and perplexity is 117.52224177178613
At time: 91.0886914730072 and batch: 950, loss is 4.729825448989868 and perplexity is 113.27578821965578
At time: 92.2870819568634 and batch: 1000, loss is 4.757425909042358 and perplexity is 116.44579771113843
At time: 93.4859185218811 and batch: 1050, loss is 4.689221420288086 and perplexity is 108.76846191413664
At time: 94.68475031852722 and batch: 1100, loss is 4.664754610061646 and perplexity is 106.13953645174598
At time: 95.88383531570435 and batch: 1150, loss is 4.7003374195098875 and perplexity is 109.98427703271847
At time: 97.08296632766724 and batch: 1200, loss is 4.676727380752563 and perplexity is 107.41795863928415
At time: 98.28155970573425 and batch: 1250, loss is 4.717237043380737 and perplexity is 111.85876439984308
At time: 99.48039054870605 and batch: 1300, loss is 4.700861101150513 and perplexity is 110.04188886317024
At time: 100.67876362800598 and batch: 1350, loss is 4.669264316558838 and perplexity is 106.61927553707075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.815447591145833 and perplexity of 123.40203360859553
Finished 3 epochs...
Completing Train Step...
At time: 104.15970063209534 and batch: 50, loss is 4.74500072479248 and perplexity is 115.00788885993221
At time: 105.38539338111877 and batch: 100, loss is 4.741838331222534 and perplexity is 114.64476312757593
At time: 106.58465838432312 and batch: 150, loss is 4.6853506374359135 and perplexity is 108.3482566033178
At time: 107.78421187400818 and batch: 200, loss is 4.667232332229614 and perplexity is 106.40284680435164
At time: 108.9879744052887 and batch: 250, loss is 4.6896003723144535 and perplexity is 108.8096877539983
At time: 110.18696904182434 and batch: 300, loss is 4.6725814914703365 and perplexity is 106.97353757268493
At time: 111.38527607917786 and batch: 350, loss is 4.688516969680786 and perplexity is 108.6918668869604
At time: 112.58391785621643 and batch: 400, loss is 4.693451061248779 and perplexity is 109.22948775546425
At time: 113.79012894630432 and batch: 450, loss is 4.6505028247833256 and perplexity is 104.6375867232978
At time: 114.98854875564575 and batch: 500, loss is 4.715225591659546 and perplexity is 111.6339920308295
At time: 116.19117212295532 and batch: 550, loss is 4.701313400268555 and perplexity is 110.09167197002975
At time: 117.38935732841492 and batch: 600, loss is 4.65086275100708 and perplexity is 104.67525531329989
At time: 118.59448599815369 and batch: 650, loss is 4.662260437011719 and perplexity is 105.87513594776941
At time: 119.79287433624268 and batch: 700, loss is 4.686080102920532 and perplexity is 108.42732175097062
At time: 121.04010772705078 and batch: 750, loss is 4.635739889144897 and perplexity is 103.10417544092465
At time: 122.24373960494995 and batch: 800, loss is 4.5987967681884765 and perplexity is 99.36468493477514
At time: 123.44208788871765 and batch: 850, loss is 4.595109987258911 and perplexity is 98.99902358012294
At time: 124.64697217941284 and batch: 900, loss is 4.625015563964844 and perplexity is 102.00436066262843
At time: 125.84552955627441 and batch: 950, loss is 4.5938161277770995 and perplexity is 98.87101558481085
At time: 127.04407858848572 and batch: 1000, loss is 4.627869787216187 and perplexity is 102.29591977002744
At time: 128.24205660820007 and batch: 1050, loss is 4.556250982284546 and perplexity is 95.22580655153608
At time: 129.44494104385376 and batch: 1100, loss is 4.5404722785949705 and perplexity is 93.73505872929044
At time: 130.64406442642212 and batch: 1150, loss is 4.558494758605957 and perplexity is 95.43971184954233
At time: 131.8485870361328 and batch: 1200, loss is 4.530591440200806 and perplexity is 92.81343845084591
At time: 133.0502655506134 and batch: 1250, loss is 4.578673038482666 and perplexity is 97.38508217357587
At time: 134.2519552707672 and batch: 1300, loss is 4.564973058700562 and perplexity is 96.06000600028085
At time: 135.4512164592743 and batch: 1350, loss is 4.541256799697876 and perplexity is 93.80862471420627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.807639567057292 and perplexity of 122.4422594037273
Finished 4 epochs...
Completing Train Step...
At time: 138.9662890434265 and batch: 50, loss is 4.6228532791137695 and perplexity is 101.78403646650325
At time: 140.14913058280945 and batch: 100, loss is 4.621401472091675 and perplexity is 101.6363729030596
At time: 141.3513445854187 and batch: 150, loss is 4.5744699859619145 and perplexity is 96.97662654000546
At time: 142.55380296707153 and batch: 200, loss is 4.55455189704895 and perplexity is 95.06414716500616
At time: 143.75191140174866 and batch: 250, loss is 4.568742818832398 and perplexity is 96.42281259843288
At time: 144.95622658729553 and batch: 300, loss is 4.55637638092041 and perplexity is 95.23774848651226
At time: 146.15495133399963 and batch: 350, loss is 4.5751839542388915 and perplexity is 97.04588949779834
At time: 147.35312175750732 and batch: 400, loss is 4.573507251739502 and perplexity is 96.88330875018391
At time: 148.55691981315613 and batch: 450, loss is 4.528567094802856 and perplexity is 92.6257420391316
At time: 149.76143383979797 and batch: 500, loss is 4.606035737991333 and perplexity is 100.08659267014762
At time: 150.9934163093567 and batch: 550, loss is 4.587566385269165 and perplexity is 98.25502409502103
At time: 152.19187259674072 and batch: 600, loss is 4.534910593032837 and perplexity is 93.21518084523713
At time: 153.39011240005493 and batch: 650, loss is 4.549999666213989 and perplexity is 94.6323767279553
At time: 154.58852815628052 and batch: 700, loss is 4.580631990432739 and perplexity is 97.57604184955541
At time: 155.7866086959839 and batch: 750, loss is 4.525856027603149 and perplexity is 92.37496751493133
At time: 156.98622179031372 and batch: 800, loss is 4.492066383361816 and perplexity is 89.30579535435123
At time: 158.18980741500854 and batch: 850, loss is 4.482271118164062 and perplexity is 88.43529177206983
At time: 159.38876843452454 and batch: 900, loss is 4.520665712356568 and perplexity is 91.89675442454606
At time: 160.59402704238892 and batch: 950, loss is 4.4933625507354735 and perplexity is 89.4216256640855
At time: 161.79585886001587 and batch: 1000, loss is 4.52178165435791 and perplexity is 91.99936311462048
At time: 162.9960503578186 and batch: 1050, loss is 4.446309003829956 and perplexity is 85.311477830197
At time: 164.19522190093994 and batch: 1100, loss is 4.43393232345581 and perplexity is 84.2621121638828
At time: 165.3936731815338 and batch: 1150, loss is 4.463930835723877 and perplexity is 86.82814634267073
At time: 166.5918161869049 and batch: 1200, loss is 4.429174137115479 and perplexity is 83.86212968301015
At time: 167.7897629737854 and batch: 1250, loss is 4.474651679992676 and perplexity is 87.76402511919892
At time: 168.98770785331726 and batch: 1300, loss is 4.470860643386841 and perplexity is 87.43193836155186
At time: 170.18579506874084 and batch: 1350, loss is 4.440927677154541 and perplexity is 84.85362193979637
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.804685872395833 and perplexity of 122.08113594255536
Finished 5 epochs...
Completing Train Step...
At time: 173.70062923431396 and batch: 50, loss is 4.51773097038269 and perplexity is 91.62745651529416
At time: 174.88395619392395 and batch: 100, loss is 4.520043239593506 and perplexity is 91.83956899793478
At time: 176.0701289176941 and batch: 150, loss is 4.479675350189209 and perplexity is 88.20603195521588
At time: 177.2623417377472 and batch: 200, loss is 4.456581859588623 and perplexity is 86.19238731758942
At time: 178.45264887809753 and batch: 250, loss is 4.4689099216461186 and perplexity is 87.26154922348654
At time: 179.64642000198364 and batch: 300, loss is 4.454987688064575 and perplexity is 86.05509133388858
At time: 180.87003827095032 and batch: 350, loss is 4.478511304855346 and perplexity is 88.10341587177355
At time: 182.06729221343994 and batch: 400, loss is 4.476370935440063 and perplexity is 87.91504368001253
At time: 183.2680425643921 and batch: 450, loss is 4.431676177978516 and perplexity is 84.07221887460933
At time: 184.4686779975891 and batch: 500, loss is 4.50794246673584 and perplexity is 90.73493616875321
At time: 185.6654555797577 and batch: 550, loss is 4.499097681045532 and perplexity is 89.93594377075443
At time: 186.86926007270813 and batch: 600, loss is 4.441202306747437 and perplexity is 84.87692845562846
At time: 188.06555819511414 and batch: 650, loss is 4.459899129867554 and perplexity is 86.47878552981298
At time: 189.2624900341034 and batch: 700, loss is 4.479707040786743 and perplexity is 88.20882730136755
At time: 190.45915126800537 and batch: 750, loss is 4.431557683944702 and perplexity is 84.06225740846203
At time: 191.65663051605225 and batch: 800, loss is 4.403582201004029 and perplexity is 81.74316526850568
At time: 192.85361695289612 and batch: 850, loss is 4.3921058654785154 and perplexity is 80.81041578736125
At time: 194.0514419078827 and batch: 900, loss is 4.429104566574097 and perplexity is 83.85629555219083
At time: 195.25703239440918 and batch: 950, loss is 4.400692577362061 and perplexity is 81.50729923173654
At time: 196.45567154884338 and batch: 1000, loss is 4.427566175460815 and perplexity is 83.72739095059006
At time: 197.65171766281128 and batch: 1050, loss is 4.35542106628418 and perplexity is 77.89961933537255
At time: 198.85177659988403 and batch: 1100, loss is 4.341456689834595 and perplexity is 76.81935985521854
At time: 200.04959058761597 and batch: 1150, loss is 4.368747892379761 and perplexity is 78.94472250138472
At time: 201.24774146080017 and batch: 1200, loss is 4.33384141921997 and perplexity is 76.2365814654399
At time: 202.44639825820923 and batch: 1250, loss is 4.382616195678711 and perplexity is 80.04717878640618
At time: 203.64843153953552 and batch: 1300, loss is 4.373317651748657 and perplexity is 79.30630643320313
At time: 204.84496474266052 and batch: 1350, loss is 4.360551052093506 and perplexity is 78.30027006474111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.808130696614583 and perplexity of 122.50240918584089
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 208.40078687667847 and batch: 50, loss is 4.426432275772095 and perplexity is 83.63250629306198
At time: 209.6180820465088 and batch: 100, loss is 4.428929796218872 and perplexity is 83.84164123823649
At time: 210.80481958389282 and batch: 150, loss is 4.3913108921051025 and perplexity is 80.74619918714151
At time: 212.03784036636353 and batch: 200, loss is 4.364205493927002 and perplexity is 78.58693733263239
At time: 213.2320466041565 and batch: 250, loss is 4.362753734588623 and perplexity is 78.47293078754183
At time: 214.42623901367188 and batch: 300, loss is 4.335407371520996 and perplexity is 76.35605783834352
At time: 215.62590169906616 and batch: 350, loss is 4.347089595794678 and perplexity is 77.25329710165927
At time: 216.8274269104004 and batch: 400, loss is 4.349305934906006 and perplexity is 77.42470648600016
At time: 218.02793335914612 and batch: 450, loss is 4.275676078796387 and perplexity is 71.92875237900867
At time: 219.22998785972595 and batch: 500, loss is 4.344987277984619 and perplexity is 77.0910567194542
At time: 220.4335072040558 and batch: 550, loss is 4.32366397857666 and perplexity is 75.46462312611007
At time: 221.63058352470398 and batch: 600, loss is 4.266435537338257 and perplexity is 71.26715323546674
At time: 222.82748222351074 and batch: 650, loss is 4.264463410377503 and perplexity is 71.12674385922075
At time: 224.02480149269104 and batch: 700, loss is 4.265182065963745 and perplexity is 71.17787786269427
At time: 225.22222018241882 and batch: 750, loss is 4.200634551048279 and perplexity is 66.72866035082669
At time: 226.41970252990723 and batch: 800, loss is 4.1603875160217285 and perplexity is 64.09635615286969
At time: 227.61684846878052 and batch: 850, loss is 4.136553020477295 and perplexity is 62.586714082508294
At time: 228.81427764892578 and batch: 900, loss is 4.151298160552979 and perplexity is 63.51640128831349
At time: 230.01149368286133 and batch: 950, loss is 4.1219312191009525 and perplexity is 61.67824151876119
At time: 231.20930004119873 and batch: 1000, loss is 4.130952978134156 and perplexity is 62.23720537869472
At time: 232.40536451339722 and batch: 1050, loss is 4.047574105262757 and perplexity is 57.2583856110015
At time: 233.60886812210083 and batch: 1100, loss is 4.004080047607422 and perplexity is 54.82136814516328
At time: 234.80653834342957 and batch: 1150, loss is 4.01601514339447 and perplexity is 55.479586561686595
At time: 236.00291776657104 and batch: 1200, loss is 3.9658812141418456 and perplexity is 52.766747712265285
At time: 237.20486545562744 and batch: 1250, loss is 3.9877253007888793 and perplexity is 53.93207049008967
At time: 238.40435552597046 and batch: 1300, loss is 3.9551460456848146 and perplexity is 52.20331745697517
At time: 239.60146832466125 and batch: 1350, loss is 3.9163615560531615 and perplexity is 50.2173987880663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.662708740234375 and perplexity of 105.92261075317299
Finished 7 epochs...
Completing Train Step...
At time: 243.06864094734192 and batch: 50, loss is 4.264858541488647 and perplexity is 71.15485380174461
At time: 244.27872967720032 and batch: 100, loss is 4.270272436141968 and perplexity is 71.54112335215544
At time: 245.47082042694092 and batch: 150, loss is 4.2377845287323 and perplexity is 69.2542509492591
At time: 246.66500735282898 and batch: 200, loss is 4.21910749912262 and perplexity is 67.9727914332426
At time: 247.86182618141174 and batch: 250, loss is 4.225186128616333 and perplexity is 68.38723118474796
At time: 249.05949544906616 and batch: 300, loss is 4.201865177154541 and perplexity is 66.81082893132051
At time: 250.25585913658142 and batch: 350, loss is 4.218542766571045 and perplexity is 67.93441582229711
At time: 251.45223331451416 and batch: 400, loss is 4.226625623703003 and perplexity is 68.48574515620707
At time: 252.64953708648682 and batch: 450, loss is 4.154921813011169 and perplexity is 63.74698016853223
At time: 253.8466944694519 and batch: 500, loss is 4.229150123596192 and perplexity is 68.65885582953939
At time: 255.05355620384216 and batch: 550, loss is 4.214814882278443 and perplexity is 67.68163564100271
At time: 256.25069403648376 and batch: 600, loss is 4.162554535865784 and perplexity is 64.23540483479702
At time: 257.44708013534546 and batch: 650, loss is 4.163870024681091 and perplexity is 64.31996139581524
At time: 258.64984011650085 and batch: 700, loss is 4.167975959777832 and perplexity is 64.5845979011032
At time: 259.8514542579651 and batch: 750, loss is 4.115469756126404 and perplexity is 61.28099462500421
At time: 261.0560128688812 and batch: 800, loss is 4.081330180168152 and perplexity is 59.22419632950547
At time: 262.25750184059143 and batch: 850, loss is 4.06067536354065 and perplexity is 58.013478039436144
At time: 263.45460987091064 and batch: 900, loss is 4.080306978225708 and perplexity is 59.16362900836595
At time: 264.65087938308716 and batch: 950, loss is 4.059945721626281 and perplexity is 57.97116441303519
At time: 265.8541839122772 and batch: 1000, loss is 4.070949182510376 and perplexity is 58.612570223366006
At time: 267.0527927875519 and batch: 1050, loss is 3.9956965494155883 and perplexity is 54.363694438346435
At time: 268.25065994262695 and batch: 1100, loss is 3.960824203491211 and perplexity is 52.500579282611604
At time: 269.4476137161255 and batch: 1150, loss is 3.9805067586898804 and perplexity is 53.544161322507605
At time: 270.6450068950653 and batch: 1200, loss is 3.939651403427124 and perplexity is 51.400680076151666
At time: 271.88203597068787 and batch: 1250, loss is 3.96630672454834 and perplexity is 52.78920529016141
At time: 273.0857801437378 and batch: 1300, loss is 3.9417636585235596 and perplexity is 51.509366170571504
At time: 274.2853698730469 and batch: 1350, loss is 3.913414325714111 and perplexity is 50.06961443105351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.655911865234375 and perplexity of 105.20510915477844
Finished 8 epochs...
Completing Train Step...
At time: 277.73064398765564 and batch: 50, loss is 4.202092638015747 and perplexity is 66.8260275084823
At time: 278.9001159667969 and batch: 100, loss is 4.2027922534942626 and perplexity is 66.87279638990397
At time: 280.0905251502991 and batch: 150, loss is 4.175047578811646 and perplexity is 65.0429342529156
At time: 281.2874550819397 and batch: 200, loss is 4.155783548355102 and perplexity is 63.80193687007765
At time: 282.4826571941376 and batch: 250, loss is 4.163325142860413 and perplexity is 64.28492416458596
At time: 283.67778491973877 and batch: 300, loss is 4.140591678619384 and perplexity is 62.83999153117718
At time: 284.8788847923279 and batch: 350, loss is 4.158349642753601 and perplexity is 63.96586890547669
At time: 286.07635474205017 and batch: 400, loss is 4.163988380432129 and perplexity is 64.32757448367046
At time: 287.2770071029663 and batch: 450, loss is 4.098486986160278 and perplexity is 60.24906093813643
At time: 288.47596883773804 and batch: 500, loss is 4.174034929275512 and perplexity is 64.97710189389522
At time: 289.6779191493988 and batch: 550, loss is 4.159745426177978 and perplexity is 64.05521374353765
At time: 290.8791229724884 and batch: 600, loss is 4.109528179168701 and perplexity is 60.917968421430416
At time: 292.07625365257263 and batch: 650, loss is 4.1131463098526 and perplexity is 61.138776808095194
At time: 293.2727291584015 and batch: 700, loss is 4.118656587600708 and perplexity is 61.47659833994526
At time: 294.47130250930786 and batch: 750, loss is 4.068122763633728 and perplexity is 58.447140445531154
At time: 295.67139315605164 and batch: 800, loss is 4.037406296730041 and perplexity is 56.679143112997856
At time: 296.8668258190155 and batch: 850, loss is 4.01975751876831 and perplexity is 55.68760099144898
At time: 298.0633759498596 and batch: 900, loss is 4.039375581741333 and perplexity is 56.79087047538586
At time: 299.25884771347046 and batch: 950, loss is 4.022208185195923 and perplexity is 55.82424008566825
At time: 300.460387468338 and batch: 1000, loss is 4.0355458211898805 and perplexity is 56.57379098651461
At time: 301.65726041793823 and batch: 1050, loss is 3.9617876482009886 and perplexity is 52.55118506200244
At time: 302.88992857933044 and batch: 1100, loss is 3.933928656578064 and perplexity is 51.10736707472916
At time: 304.09288573265076 and batch: 1150, loss is 3.9545409870147705 and perplexity is 52.171740940928494
At time: 305.2970163822174 and batch: 1200, loss is 3.9169241046905516 and perplexity is 50.24565646474135
At time: 306.4976658821106 and batch: 1250, loss is 3.947952733039856 and perplexity is 51.829150038415364
At time: 307.7000367641449 and batch: 1300, loss is 3.925683479309082 and perplexity is 50.687710223468954
At time: 308.9033441543579 and batch: 1350, loss is 3.8993961906433103 and perplexity is 49.37262844841878
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.657751057942709 and perplexity of 105.39877966852069
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 312.4004535675049 and batch: 50, loss is 4.173813009262085 and perplexity is 64.9626837744643
At time: 313.57911562919617 and batch: 100, loss is 4.18331084728241 and perplexity is 65.58262822795014
At time: 314.7710795402527 and batch: 150, loss is 4.161036772727966 and perplexity is 64.13798465427688
At time: 315.97293996810913 and batch: 200, loss is 4.146117477416992 and perplexity is 63.18819384276576
At time: 317.1700212955475 and batch: 250, loss is 4.153151717185974 and perplexity is 63.63424171343783
At time: 318.37041759490967 and batch: 300, loss is 4.136992273330688 and perplexity is 62.61421151397405
At time: 319.5738956928253 and batch: 350, loss is 4.148322920799256 and perplexity is 63.327705612819926
At time: 320.77149844169617 and batch: 400, loss is 4.149215803146363 and perplexity is 63.384275054414005
At time: 321.9703416824341 and batch: 450, loss is 4.078731932640076 and perplexity is 59.07051694278941
At time: 323.1672456264496 and batch: 500, loss is 4.147650027275086 and perplexity is 63.28510714353691
At time: 324.36420702934265 and batch: 550, loss is 4.131807370185852 and perplexity is 62.290403074898336
At time: 325.5619053840637 and batch: 600, loss is 4.0820661067962645 and perplexity is 59.26779703410488
At time: 326.75986981391907 and batch: 650, loss is 4.085123972892761 and perplexity is 59.44930739702695
At time: 327.95708298683167 and batch: 700, loss is 4.089482684135437 and perplexity is 59.70899530270769
At time: 329.15375304222107 and batch: 750, loss is 4.029865484237671 and perplexity is 56.25334377674556
At time: 330.35347986221313 and batch: 800, loss is 3.994604630470276 and perplexity is 54.30436608722202
At time: 331.55420184135437 and batch: 850, loss is 3.9671087217330934 and perplexity is 52.83155906572372
At time: 332.7782895565033 and batch: 900, loss is 3.978733253479004 and perplexity is 53.44928463041218
At time: 333.97539949417114 and batch: 950, loss is 3.962514238357544 and perplexity is 52.58938211090322
At time: 335.17773818969727 and batch: 1000, loss is 3.9692626428604125 and perplexity is 52.94547671776111
At time: 336.37521529197693 and batch: 1050, loss is 3.891944704055786 and perplexity is 49.0060962705111
At time: 337.57288432121277 and batch: 1100, loss is 3.849055700302124 and perplexity is 46.94870864147638
At time: 338.7697696685791 and batch: 1150, loss is 3.8645946550369263 and perplexity is 47.68394006988863
At time: 339.9668138027191 and batch: 1200, loss is 3.8294528341293335 and perplexity is 46.03734127946193
At time: 341.1701946258545 and batch: 1250, loss is 3.8522186136245726 and perplexity is 47.097438423223025
At time: 342.3672196865082 and batch: 1300, loss is 3.819421896934509 and perplexity is 45.57785200728603
At time: 343.5694842338562 and batch: 1350, loss is 3.7930408334732055 and perplexity is 44.39118143902586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.622879638671875 and perplexity of 101.7867194840881
Finished 10 epochs...
Completing Train Step...
At time: 346.9908056259155 and batch: 50, loss is 4.150012221336365 and perplexity is 63.43477555111522
At time: 348.1980712413788 and batch: 100, loss is 4.149068450927734 and perplexity is 63.3749359289459
At time: 349.38651990890503 and batch: 150, loss is 4.125635237693786 and perplexity is 61.90712250014277
At time: 350.58994340896606 and batch: 200, loss is 4.11070499420166 and perplexity is 60.98969980145086
At time: 351.7947311401367 and batch: 250, loss is 4.117597713470459 and perplexity is 61.41153681241054
At time: 352.9945466518402 and batch: 300, loss is 4.100758728981018 and perplexity is 60.38608689471503
At time: 354.19808983802795 and batch: 350, loss is 4.111966137886047 and perplexity is 61.06666509811605
At time: 355.4013001918793 and batch: 400, loss is 4.1150137090682986 and perplexity is 61.25305397929659
At time: 356.60984992980957 and batch: 450, loss is 4.046096720695496 and perplexity is 57.17385541293366
At time: 357.8082449436188 and batch: 500, loss is 4.118324770927429 and perplexity is 61.45620276358285
At time: 359.0074586868286 and batch: 550, loss is 4.104027471542358 and perplexity is 60.58379642179506
At time: 360.2057161331177 and batch: 600, loss is 4.0543687057495115 and perplexity is 57.64875817671075
At time: 361.40834975242615 and batch: 650, loss is 4.0595134973526 and perplexity is 57.94611328284558
At time: 362.6569380760193 and batch: 700, loss is 4.065776391029358 and perplexity is 58.310162439949806
At time: 363.85525918006897 and batch: 750, loss is 4.0093454742431645 and perplexity is 55.110787326263406
At time: 365.05358028411865 and batch: 800, loss is 3.9751892948150633 and perplexity is 53.260197830870716
At time: 366.2520544528961 and batch: 850, loss is 3.9518490076065063 and perplexity is 52.031484556971236
At time: 367.45106387138367 and batch: 900, loss is 3.9646973752975465 and perplexity is 52.70431734767272
At time: 368.652676820755 and batch: 950, loss is 3.9494349908828736 and perplexity is 51.90603116730867
At time: 369.8586585521698 and batch: 1000, loss is 3.9591336488723754 and perplexity is 52.41189916622447
At time: 371.0596179962158 and batch: 1050, loss is 3.884832010269165 and perplexity is 48.65876759959156
At time: 372.25807881355286 and batch: 1100, loss is 3.8460066747665405 and perplexity is 46.80577883900418
At time: 373.4620370864868 and batch: 1150, loss is 3.86445698261261 and perplexity is 47.67737575813098
At time: 374.6618309020996 and batch: 1200, loss is 3.8333357477188112 and perplexity is 46.21644780007818
At time: 375.8600730895996 and batch: 1250, loss is 3.8591591024398806 and perplexity is 47.42545464757598
At time: 377.0585629940033 and batch: 1300, loss is 3.8273306465148926 and perplexity is 45.93974499943375
At time: 378.2652714252472 and batch: 1350, loss is 3.802850193977356 and perplexity is 44.82877328014682
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.620235595703125 and perplexity of 101.51794650435954
Finished 11 epochs...
Completing Train Step...
At time: 381.7113473415375 and batch: 50, loss is 4.1376031255722046 and perplexity is 62.65247122975503
At time: 382.9223964214325 and batch: 100, loss is 4.13341917514801 and perplexity is 62.39088401175217
At time: 384.1243541240692 and batch: 150, loss is 4.109118413925171 and perplexity is 60.893011468859925
At time: 385.32303047180176 and batch: 200, loss is 4.094111366271973 and perplexity is 59.98600987427604
At time: 386.52102494239807 and batch: 250, loss is 4.100875878334046 and perplexity is 60.393161500111276
At time: 387.7197835445404 and batch: 300, loss is 4.083490190505981 and perplexity is 59.352259464883566
At time: 388.91764998435974 and batch: 350, loss is 4.095190124511719 and perplexity is 60.0507551926915
At time: 390.1190981864929 and batch: 400, loss is 4.098881258964538 and perplexity is 60.27282018785177
At time: 391.32486033439636 and batch: 450, loss is 4.030120983123779 and perplexity is 56.26771827967689
At time: 392.5227909088135 and batch: 500, loss is 4.103907346725464 and perplexity is 60.57651924143684
At time: 393.7476875782013 and batch: 550, loss is 4.090131483078003 and perplexity is 59.7477470053943
At time: 394.9463334083557 and batch: 600, loss is 4.041196856498718 and perplexity is 56.89439650028388
At time: 396.1443588733673 and batch: 650, loss is 4.046886253356933 and perplexity is 57.21901386385263
At time: 397.34258246421814 and batch: 700, loss is 4.054274578094482 and perplexity is 57.643332089664646
At time: 398.5470051765442 and batch: 750, loss is 3.9986644840240477 and perplexity is 54.525282000558995
At time: 399.7448408603668 and batch: 800, loss is 3.9655089664459227 and perplexity is 52.747109067454964
At time: 400.9432737827301 and batch: 850, loss is 3.943365020751953 and perplexity is 51.591917403537806
At time: 402.14179611206055 and batch: 900, loss is 3.957173638343811 and perplexity is 52.309271900152396
At time: 403.339985370636 and batch: 950, loss is 3.9434464979171753 and perplexity is 51.59612113796808
At time: 404.5377469062805 and batch: 1000, loss is 3.9541252946853636 and perplexity is 52.150058055424374
At time: 405.73679184913635 and batch: 1050, loss is 3.8809892892837525 and perplexity is 48.47214433243257
At time: 406.9425961971283 and batch: 1100, loss is 3.8439330863952637 and perplexity is 46.7088234777903
At time: 408.14098286628723 and batch: 1150, loss is 3.8633549308776853 and perplexity is 47.62486176534343
At time: 409.3390431404114 and batch: 1200, loss is 3.8339208602905273 and perplexity is 46.24349753750506
At time: 410.5372152328491 and batch: 1250, loss is 3.861194577217102 and perplexity is 47.522086276567784
At time: 411.7451014518738 and batch: 1300, loss is 3.8306141757965086 and perplexity is 46.09083741977153
At time: 412.95184206962585 and batch: 1350, loss is 3.8060897397994995 and perplexity is 44.97423363086104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.619612223307292 and perplexity of 101.45468273931809
Finished 12 epochs...
Completing Train Step...
At time: 416.40357756614685 and batch: 50, loss is 4.1268155002594 and perplexity is 61.98023229526476
At time: 417.57563877105713 and batch: 100, loss is 4.12091784954071 and perplexity is 61.61577032482603
At time: 418.7705101966858 and batch: 150, loss is 4.096330456733703 and perplexity is 60.119272062364644
At time: 419.9609806537628 and batch: 200, loss is 4.081255416870118 and perplexity is 59.21976869877865
At time: 421.16240429878235 and batch: 250, loss is 4.08813262462616 and perplexity is 59.628438995949445
At time: 422.3658182621002 and batch: 300, loss is 4.070922317504883 and perplexity is 58.61099561749598
At time: 423.60279726982117 and batch: 350, loss is 4.082881999015808 and perplexity is 59.3161729006375
At time: 424.80421328544617 and batch: 400, loss is 4.087130241394043 and perplexity is 59.56869839503306
At time: 426.00288486480713 and batch: 450, loss is 4.018407950401306 and perplexity is 55.61249745679293
At time: 427.2015235424042 and batch: 500, loss is 4.092497825622559 and perplexity is 59.88929805415681
At time: 428.40554642677307 and batch: 550, loss is 4.07976499080658 and perplexity is 59.13157175387252
At time: 429.604856967926 and batch: 600, loss is 4.031320295333862 and perplexity is 56.33524132375537
At time: 430.80168175697327 and batch: 650, loss is 4.037303915023804 and perplexity is 56.67334050266352
At time: 431.99844551086426 and batch: 700, loss is 4.045431423187256 and perplexity is 57.13583043975348
At time: 433.19582176208496 and batch: 750, loss is 3.9904319715499876 and perplexity is 54.07824458170104
At time: 434.3925702571869 and batch: 800, loss is 3.958089165687561 and perplexity is 52.35718439816301
At time: 435.59554982185364 and batch: 850, loss is 3.936532220840454 and perplexity is 51.24060175645626
At time: 436.7914581298828 and batch: 900, loss is 3.9512996578216555 and perplexity is 52.002908921852544
At time: 437.9953565597534 and batch: 950, loss is 3.938323678970337 and perplexity is 51.33247942197629
At time: 439.19440484046936 and batch: 1000, loss is 3.9498479986190795 and perplexity is 51.92747318729179
At time: 440.3919677734375 and batch: 1050, loss is 3.877286796569824 and perplexity is 48.29300840059412
At time: 441.59543538093567 and batch: 1100, loss is 3.8413055896759034 and perplexity is 46.58625728898047
At time: 442.79111433029175 and batch: 1150, loss is 3.861333956718445 and perplexity is 47.528710342874604
At time: 443.98822140693665 and batch: 1200, loss is 3.8327814054489138 and perplexity is 46.19083516923593
At time: 445.1853914260864 and batch: 1250, loss is 3.861130032539368 and perplexity is 47.519019077810555
At time: 446.38268876075745 and batch: 1300, loss is 3.8312770032882693 and perplexity is 46.12139782094979
At time: 447.5804533958435 and batch: 1350, loss is 3.80697633266449 and perplexity is 45.01412514666017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.619578450520834 and perplexity of 101.45125638984177
Finished 13 epochs...
Completing Train Step...
At time: 451.07471084594727 and batch: 50, loss is 4.117119851112366 and perplexity is 61.38219756123545
At time: 452.25059151649475 and batch: 100, loss is 4.110097508430481 and perplexity is 60.9526606781423
At time: 453.469678401947 and batch: 150, loss is 4.085168490409851 and perplexity is 59.45195399149443
At time: 454.6661150455475 and batch: 200, loss is 4.0702427387237545 and perplexity is 58.57117835954771
At time: 455.8627095222473 and batch: 250, loss is 4.077321190834045 and perplexity is 58.987242448250804
At time: 457.05880999565125 and batch: 300, loss is 4.060631895065308 and perplexity is 58.01095633680417
At time: 458.25530791282654 and batch: 350, loss is 4.072711319923401 and perplexity is 58.71594467947921
At time: 459.45169043540955 and batch: 400, loss is 4.0770293760299685 and perplexity is 58.97003160896374
At time: 460.64995884895325 and batch: 450, loss is 4.0072407913208 and perplexity is 54.99491856960835
At time: 461.84655237197876 and batch: 500, loss is 4.08325963973999 and perplexity is 59.338577333274195
At time: 463.04318857192993 and batch: 550, loss is 4.07108551979065 and perplexity is 58.6205618465458
At time: 464.240270614624 and batch: 600, loss is 4.02288978099823 and perplexity is 55.86230262353708
At time: 465.43733286857605 and batch: 650, loss is 4.029265065193176 and perplexity is 56.2195783355468
At time: 466.63349771499634 and batch: 700, loss is 4.037726745605469 and perplexity is 56.697308791098735
At time: 467.8370134830475 and batch: 750, loss is 3.9833289766311646 and perplexity is 53.69548805330831
At time: 469.0337197780609 and batch: 800, loss is 3.9515767812728884 and perplexity is 52.01732214447587
At time: 470.2299256324768 and batch: 850, loss is 3.9305366039276124 and perplexity is 50.934301883846395
At time: 471.43318367004395 and batch: 900, loss is 3.9459281730651856 and perplexity is 51.72432496385668
At time: 472.6296238899231 and batch: 950, loss is 3.933414521217346 and perplexity is 51.081097723702655
At time: 473.82539463043213 and batch: 1000, loss is 3.9456496620178223 and perplexity is 51.709921173837266
At time: 475.0228364467621 and batch: 1050, loss is 3.8734513092041016 and perplexity is 48.1081359416488
At time: 476.2205092906952 and batch: 1100, loss is 3.8382674264907837 and perplexity is 46.4449354252995
At time: 477.4246666431427 and batch: 1150, loss is 3.8587205028533935 and perplexity is 47.40465842371957
At time: 478.6269385814667 and batch: 1200, loss is 3.830999422073364 and perplexity is 46.10859716400267
At time: 479.8256721496582 and batch: 1250, loss is 3.859887466430664 and perplexity is 47.460010223978884
At time: 481.0234763622284 and batch: 1300, loss is 3.83050838470459 and perplexity is 46.085961677663036
At time: 482.2207262516022 and batch: 1350, loss is 3.8067251014709473 and perplexity is 45.00281761473514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.61969970703125 and perplexity of 101.4635587610252
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 485.66255140304565 and batch: 50, loss is 4.113967061042786 and perplexity is 61.1889771300959
At time: 486.87192249298096 and batch: 100, loss is 4.111276407241821 and perplexity is 61.02456007009043
At time: 488.06655740737915 and batch: 150, loss is 4.08876549243927 and perplexity is 59.66618785949644
At time: 489.26343512535095 and batch: 200, loss is 4.075929675102234 and perplexity is 58.9052178548994
At time: 490.4607021808624 and batch: 250, loss is 4.085151052474975 and perplexity is 59.45091728123157
At time: 491.65885305404663 and batch: 300, loss is 4.069682288169861 and perplexity is 58.53836130722046
At time: 492.8641345500946 and batch: 350, loss is 4.081220865249634 and perplexity is 59.21772259515373
At time: 494.0607690811157 and batch: 400, loss is 4.086816091537475 and perplexity is 59.54998783608993
At time: 495.2570655345917 and batch: 450, loss is 4.017551698684692 and perplexity is 55.56489954118696
At time: 496.45324516296387 and batch: 500, loss is 4.091841616630554 and perplexity is 59.85001104990136
At time: 497.6527781486511 and batch: 550, loss is 4.080529646873474 and perplexity is 59.17680436044868
At time: 498.8519477844238 and batch: 600, loss is 4.032172288894653 and perplexity is 56.38325903909631
At time: 500.05504846572876 and batch: 650, loss is 4.038037238121032 and perplexity is 56.71491561438293
At time: 501.26101875305176 and batch: 700, loss is 4.041629962921142 and perplexity is 56.91904316573737
At time: 502.45800280570984 and batch: 750, loss is 3.988837037086487 and perplexity is 53.992062071689126
At time: 503.65498447418213 and batch: 800, loss is 3.955166053771973 and perplexity is 52.20436195594997
At time: 504.85244369506836 and batch: 850, loss is 3.925382914543152 and perplexity is 50.672477573023784
At time: 506.04972887039185 and batch: 900, loss is 3.934675540924072 and perplexity is 51.14555262548292
At time: 507.25327014923096 and batch: 950, loss is 3.9218350076675415 and perplexity is 50.49301488813604
At time: 508.4493567943573 and batch: 1000, loss is 3.934993681907654 and perplexity is 51.161826710490466
At time: 509.6485643386841 and batch: 1050, loss is 3.8629828882217407 and perplexity is 47.60714658088974
At time: 510.8458983898163 and batch: 1100, loss is 3.8227648067474367 and perplexity is 45.730469607324046
At time: 512.0435168743134 and batch: 1150, loss is 3.839290018081665 and perplexity is 46.49245391756893
At time: 513.2397971153259 and batch: 1200, loss is 3.8092580890655516 and perplexity is 45.11695368507565
At time: 514.4705193042755 and batch: 1250, loss is 3.837980046272278 and perplexity is 46.43158998730778
At time: 515.6735022068024 and batch: 1300, loss is 3.8091664028167727 and perplexity is 45.112817270464994
At time: 516.8706791400909 and batch: 1350, loss is 3.784832339286804 and perplexity is 44.02828812570727
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.604312744140625 and perplexity of 99.91429256507507
Finished 15 epochs...
Completing Train Step...
At time: 520.3012549877167 and batch: 50, loss is 4.1080208587646485 and perplexity is 60.826214693160885
At time: 521.504045009613 and batch: 100, loss is 4.103468642234803 and perplexity is 60.549949878892456
At time: 522.6900880336761 and batch: 150, loss is 4.080487709045411 and perplexity is 59.17432266584086
At time: 523.8793923854828 and batch: 200, loss is 4.067303519248963 and perplexity is 58.399277562291736
At time: 525.0754325389862 and batch: 250, loss is 4.075976939201355 and perplexity is 58.90800202274989
At time: 526.2774183750153 and batch: 300, loss is 4.060041732788086 and perplexity is 57.97673055908347
At time: 527.4794895648956 and batch: 350, loss is 4.071259913444519 and perplexity is 58.63078579198776
At time: 528.6793603897095 and batch: 400, loss is 4.075739631652832 and perplexity is 58.8940243677686
At time: 529.8799111843109 and batch: 450, loss is 4.006298961639405 and perplexity is 54.9431471067507
At time: 531.0808157920837 and batch: 500, loss is 4.080556778907776 and perplexity is 59.178409969316085
At time: 532.2807552814484 and batch: 550, loss is 4.0696821212768555 and perplexity is 58.538351537578244
At time: 533.483464717865 and batch: 600, loss is 4.021103549003601 and perplexity is 55.76260865608162
At time: 534.6827278137207 and batch: 650, loss is 4.02842227935791 and perplexity is 56.172217231698056
At time: 535.8869507312775 and batch: 700, loss is 4.0341107416152955 and perplexity is 56.492661322298595
At time: 537.0881314277649 and batch: 750, loss is 3.9821802282333376 and perplexity is 53.63384086277147
At time: 538.2948739528656 and batch: 800, loss is 3.949100594520569 and perplexity is 51.888676881071454
At time: 539.502815246582 and batch: 850, loss is 3.9205042505264283 and perplexity is 50.4258656375793
At time: 540.7027161121368 and batch: 900, loss is 3.931610116958618 and perplexity is 50.989009880263474
At time: 541.9038667678833 and batch: 950, loss is 3.9196992444992067 and perplexity is 50.38528884628523
At time: 543.1042692661285 and batch: 1000, loss is 3.9337559270858766 and perplexity is 51.09854008752977
At time: 544.3489949703217 and batch: 1050, loss is 3.862863554954529 and perplexity is 47.601465803505214
At time: 545.5432901382446 and batch: 1100, loss is 3.8243374633789062 and perplexity is 45.80244451468558
At time: 546.741001367569 and batch: 1150, loss is 3.8414423274993896 and perplexity is 46.592627827943424
At time: 547.94806432724 and batch: 1200, loss is 3.8125278997421264 and perplexity is 45.26471903263043
At time: 549.1530251502991 and batch: 1250, loss is 3.8421579694747923 and perplexity is 46.625983402062325
At time: 550.3527293205261 and batch: 1300, loss is 3.81379047870636 and perplexity is 45.32190540826367
At time: 551.5509178638458 and batch: 1350, loss is 3.7898998498916625 and perplexity is 44.25196821464052
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.602549641927084 and perplexity of 99.73828865672218
Finished 16 epochs...
Completing Train Step...
At time: 555.0483560562134 and batch: 50, loss is 4.106190605163574 and perplexity is 60.71498911123881
At time: 556.2345674037933 and batch: 100, loss is 4.100857138633728 and perplexity is 60.39202976096778
At time: 557.4217834472656 and batch: 150, loss is 4.077075262069702 and perplexity is 58.9727375722597
At time: 558.6135766506195 and batch: 200, loss is 4.063363814353943 and perplexity is 58.16965426363461
At time: 559.8221206665039 and batch: 250, loss is 4.071898293495178 and perplexity is 58.66822646540985
At time: 561.0216858386993 and batch: 300, loss is 4.055870413780212 and perplexity is 57.73539481501101
At time: 562.2220911979675 and batch: 350, loss is 4.066911063194275 and perplexity is 58.37636290901433
At time: 563.4221353530884 and batch: 400, loss is 4.071123595237732 and perplexity is 58.62279389313914
At time: 564.6225929260254 and batch: 450, loss is 4.001694936752319 and perplexity is 54.690768913643254
At time: 565.8227763175964 and batch: 500, loss is 4.076406064033509 and perplexity is 58.933286333905315
At time: 567.0219674110413 and batch: 550, loss is 4.065740780830383 and perplexity is 58.30808604043381
At time: 568.2191455364227 and batch: 600, loss is 4.01705602645874 and perplexity is 55.53736438851554
At time: 569.4173762798309 and batch: 650, loss is 4.024505500793457 and perplexity is 55.95263340665901
At time: 570.6140458583832 and batch: 700, loss is 4.030679631233215 and perplexity is 56.29916091598305
At time: 571.8117592334747 and batch: 750, loss is 3.9791780424118044 and perplexity is 53.47306356859412
At time: 573.0099949836731 and batch: 800, loss is 3.946362919807434 and perplexity is 51.74681683440918
At time: 574.2364761829376 and batch: 850, loss is 3.9184882736206053 and perplexity is 50.32431065763958
At time: 575.433981180191 and batch: 900, loss is 3.9302330589294434 and perplexity is 50.918843377569154
At time: 576.6320593357086 and batch: 950, loss is 3.9187899732589724 and perplexity is 50.33949577452302
At time: 577.8295521736145 and batch: 1000, loss is 3.9333587980270384 and perplexity is 51.07825140127689
At time: 579.027704000473 and batch: 1050, loss is 3.8628777503967284 and perplexity is 47.60214153215776
At time: 580.2267084121704 and batch: 1100, loss is 3.8250582122802737 and perplexity is 45.83546847581173
At time: 581.4246878623962 and batch: 1150, loss is 3.8426539659500123 and perplexity is 46.649115461719205
At time: 582.622718334198 and batch: 1200, loss is 3.814073295593262 and perplexity is 45.334725021175764
At time: 583.8200187683105 and batch: 1250, loss is 3.844183840751648 and perplexity is 46.72053738735449
At time: 585.0202648639679 and batch: 1300, loss is 3.816030011177063 and perplexity is 45.423519028089835
At time: 586.2225449085236 and batch: 1350, loss is 3.792134370803833 and perplexity is 44.350960722245205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601978352864584 and perplexity of 99.68132553605328
Finished 17 epochs...
Completing Train Step...
At time: 589.675413608551 and batch: 50, loss is 4.104315762519836 and perplexity is 60.60126470153756
At time: 590.8509559631348 and batch: 100, loss is 4.098461127281189 and perplexity is 60.247502985097924
At time: 592.0432131290436 and batch: 150, loss is 4.074340472221374 and perplexity is 58.81167985810007
At time: 593.2376022338867 and batch: 200, loss is 4.060361342430115 and perplexity is 57.99526344266983
At time: 594.4358699321747 and batch: 250, loss is 4.068801536560058 and perplexity is 58.486826249387924
At time: 595.634569644928 and batch: 300, loss is 4.052803463935852 and perplexity is 57.55859451228413
At time: 596.8335678577423 and batch: 350, loss is 4.063810625076294 and perplexity is 58.19565089622964
At time: 598.0400493144989 and batch: 400, loss is 4.067976884841919 and perplexity is 58.43861486916378
At time: 599.2397770881653 and batch: 450, loss is 3.9986824417114257 and perplexity is 54.526261157319034
At time: 600.4383778572083 and batch: 500, loss is 4.073646926879883 and perplexity is 58.77090543260004
At time: 601.6371212005615 and batch: 550, loss is 4.063156538009643 and perplexity is 58.157598319848795
At time: 602.8370461463928 and batch: 600, loss is 4.014385676383972 and perplexity is 55.38925801930463
At time: 604.0371124744415 and batch: 650, loss is 4.02190176486969 and perplexity is 55.80713702430615
At time: 605.2887439727783 and batch: 700, loss is 4.028376593589782 and perplexity is 56.169651019426524
At time: 606.4876823425293 and batch: 750, loss is 3.9771323823928832 and perplexity is 53.363787669139356
At time: 607.6867623329163 and batch: 800, loss is 3.9444732427597047 and perplexity is 51.649124394995056
At time: 608.8860561847687 and batch: 850, loss is 3.9170766925811766 and perplexity is 50.25332392844055
At time: 610.0875928401947 and batch: 900, loss is 3.9292407178878785 and perplexity is 50.868339582135484
At time: 611.2899255752563 and batch: 950, loss is 3.918094763755798 and perplexity is 50.30451144080524
At time: 612.4882726669312 and batch: 1000, loss is 3.93301052570343 and perplexity is 51.06046535734871
At time: 613.6878354549408 and batch: 1050, loss is 3.862830023765564 and perplexity is 47.59986969652018
At time: 614.8874938488007 and batch: 1100, loss is 3.8253111839294434 and perplexity is 45.847065016598705
At time: 616.086678981781 and batch: 1150, loss is 3.843220901489258 and perplexity is 46.67557000144963
At time: 617.285694360733 and batch: 1200, loss is 3.8148644304275514 and perplexity is 45.370605092458646
At time: 618.487842798233 and batch: 1250, loss is 3.845239996910095 and perplexity is 46.76990763739969
At time: 619.6866524219513 and batch: 1300, loss is 3.8172951698303224 and perplexity is 45.48102335462763
At time: 620.8854260444641 and batch: 1350, loss is 3.79334481716156 and perplexity is 44.404677685305536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.60172607421875 and perplexity of 99.65618123805018
Finished 18 epochs...
Completing Train Step...
At time: 624.3355162143707 and batch: 50, loss is 4.102433085441589 and perplexity is 60.487279421975884
At time: 625.5353944301605 and batch: 100, loss is 4.0961996364593505 and perplexity is 60.111407757116055
At time: 626.7171914577484 and batch: 150, loss is 4.07190390586853 and perplexity is 58.668555734324656
At time: 627.912962436676 and batch: 200, loss is 4.057760829925537 and perplexity is 57.84464196628084
At time: 629.1100823879242 and batch: 250, loss is 4.0661747884750366 and perplexity is 58.33339768784737
At time: 630.302497625351 and batch: 300, loss is 4.050225234031677 and perplexity is 57.41038636211095
At time: 631.505279302597 and batch: 350, loss is 4.061247062683106 and perplexity is 58.04665377744906
At time: 632.70671916008 and batch: 400, loss is 4.065402030944824 and perplexity is 58.28833752805244
At time: 633.9057886600494 and batch: 450, loss is 3.9962576246261596 and perplexity is 54.39420511824353
At time: 635.1365160942078 and batch: 500, loss is 4.071434631347656 and perplexity is 58.641030534884564
At time: 636.343775510788 and batch: 550, loss is 4.061084680557251 and perplexity is 58.03722880365426
At time: 637.5432171821594 and batch: 600, loss is 4.0122911071777345 and perplexity is 55.273362802748416
At time: 638.7476482391357 and batch: 650, loss is 4.019862451553345 and perplexity is 55.69344475310863
At time: 639.94664478302 and batch: 700, loss is 4.0265559959411625 and perplexity is 56.067481717672685
At time: 641.1449117660522 and batch: 750, loss is 3.9755303478240966 and perplexity is 53.27836547949216
At time: 642.3435575962067 and batch: 800, loss is 3.942968683242798 and perplexity is 51.57147364308371
At time: 643.5518977642059 and batch: 850, loss is 3.9158895111083982 and perplexity is 50.19369951283083
At time: 644.7507245540619 and batch: 900, loss is 3.9283528661727907 and perplexity is 50.82319608292589
At time: 645.951574087143 and batch: 950, loss is 3.9174038553237915 and perplexity is 50.26976763345964
At time: 647.1494791507721 and batch: 1000, loss is 3.9325726938247683 and perplexity is 51.038114351224515
At time: 648.3535568714142 and batch: 1050, loss is 3.862631802558899 and perplexity is 47.59043532798868
At time: 649.5578818321228 and batch: 1100, loss is 3.825295124053955 and perplexity is 45.84632872435544
At time: 650.7567975521088 and batch: 1150, loss is 3.8434227228164675 and perplexity is 46.684991077590645
At time: 651.9550614356995 and batch: 1200, loss is 3.81524507522583 and perplexity is 45.387878464582904
At time: 653.1598856449127 and batch: 1250, loss is 3.845825505256653 and perplexity is 46.79729982708442
At time: 654.3627381324768 and batch: 1300, loss is 3.818060212135315 and perplexity is 45.515831574751026
At time: 655.5661759376526 and batch: 1350, loss is 3.794073143005371 and perplexity is 44.437030539929765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601606852213542 and perplexity of 99.64430073651431
Finished 19 epochs...
Completing Train Step...
At time: 659.0239734649658 and batch: 50, loss is 4.100602149963379 and perplexity is 60.37663244075388
At time: 660.2322313785553 and batch: 100, loss is 4.094065918922424 and perplexity is 59.983283731065725
At time: 661.4134480953217 and batch: 150, loss is 4.069678063392639 and perplexity is 58.53811399620745
At time: 662.5948069095612 and batch: 200, loss is 4.055415587425232 and perplexity is 57.709141206703016
At time: 663.7760891914368 and batch: 250, loss is 4.063833842277527 and perplexity is 58.197002052052326
At time: 664.9971089363098 and batch: 300, loss is 4.047937016487122 and perplexity is 57.27916909288009
At time: 666.19344830513 and batch: 350, loss is 4.058987922668457 and perplexity is 57.915666274448924
At time: 667.391078710556 and batch: 400, loss is 4.063138885498047 and perplexity is 58.15657170123126
At time: 668.5884795188904 and batch: 450, loss is 3.994130644798279 and perplexity is 54.27863269488122
At time: 669.7909634113312 and batch: 500, loss is 4.069512462615966 and perplexity is 58.528420841683825
At time: 670.9886410236359 and batch: 550, loss is 4.0592849159240725 and perplexity is 57.93286939120527
At time: 672.1874394416809 and batch: 600, loss is 4.010504913330078 and perplexity is 55.17472198420851
At time: 673.3889462947845 and batch: 650, loss is 4.01811574459076 and perplexity is 55.59624953588112
At time: 674.5869579315186 and batch: 700, loss is 4.025009398460388 and perplexity is 55.980834912831135
At time: 675.7896683216095 and batch: 750, loss is 3.974154357910156 and perplexity is 53.20510540008522
At time: 676.9909801483154 and batch: 800, loss is 3.9416578817367554 and perplexity is 51.50391796347966
At time: 678.1952195167542 and batch: 850, loss is 3.9147824573516847 and perplexity is 50.1381631357712
At time: 679.393559217453 and batch: 900, loss is 3.92747962474823 and perplexity is 50.77883453476746
At time: 680.5991716384888 and batch: 950, loss is 3.916673183441162 and perplexity is 50.23305034348281
At time: 681.7984256744385 and batch: 1000, loss is 3.932043390274048 and perplexity is 51.01110684429154
At time: 682.9964826107025 and batch: 1050, loss is 3.8622699308395387 and perplexity is 47.57321681096652
At time: 684.2000524997711 and batch: 1100, loss is 3.825114016532898 and perplexity is 45.83802636124348
At time: 685.397670507431 and batch: 1150, loss is 3.8434165334701538 and perplexity is 46.68470212890742
At time: 686.5992658138275 and batch: 1200, loss is 3.8153888034820556 and perplexity is 45.39440245403798
At time: 687.8016946315765 and batch: 1250, loss is 3.846150803565979 and perplexity is 46.81252538588919
At time: 689.005352973938 and batch: 1300, loss is 3.8185385608673097 and perplexity is 45.53760922331051
At time: 690.2066056728363 and batch: 1350, loss is 3.7945364475250245 and perplexity is 44.45762318698376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6015547688802085 and perplexity of 99.63911106433318
Finished 20 epochs...
Completing Train Step...
At time: 693.6732883453369 and batch: 50, loss is 4.098843145370483 and perplexity is 60.270523017827564
At time: 694.8460841178894 and batch: 100, loss is 4.09204511642456 and perplexity is 59.86219175416465
At time: 696.0459890365601 and batch: 150, loss is 4.067609934806824 and perplexity is 58.41717475135323
At time: 697.2374920845032 and batch: 200, loss is 4.053253393173218 and perplexity is 57.58449763366574
At time: 698.4353022575378 and batch: 250, loss is 4.061678419113159 and perplexity is 58.07169797589873
At time: 699.63649559021 and batch: 300, loss is 4.045833172798157 and perplexity is 57.15878934895879
At time: 700.8395719528198 and batch: 350, loss is 4.056923022270203 and perplexity is 57.79619957795687
At time: 702.0454823970795 and batch: 400, loss is 4.0610709524154665 and perplexity is 58.03643206581735
At time: 703.2440180778503 and batch: 450, loss is 3.9921835327148436 and perplexity is 54.17304893835057
At time: 704.4487957954407 and batch: 500, loss is 4.06776704788208 and perplexity is 58.42635357436388
At time: 705.6489882469177 and batch: 550, loss is 4.057635746002197 and perplexity is 57.83740698401892
At time: 706.8544812202454 and batch: 600, loss is 4.0088742113113405 and perplexity is 55.08482177383464
At time: 708.0547955036163 and batch: 650, loss is 4.016531190872192 and perplexity is 55.508224050913356
At time: 709.2586634159088 and batch: 700, loss is 4.0235855007171635 and perplexity is 55.90118065155451
At time: 710.4622449874878 and batch: 750, loss is 3.9728910970687865 and perplexity is 53.13793590909878
At time: 711.6591610908508 and batch: 800, loss is 3.9404446697235107 and perplexity is 51.44147068003403
At time: 712.8651585578918 and batch: 850, loss is 3.9137154626846313 and perplexity is 50.084694513529605
At time: 714.0677397251129 and batch: 900, loss is 3.926601619720459 and perplexity is 50.734270029534294
At time: 715.2676529884338 and batch: 950, loss is 3.9159122467041017 and perplexity is 50.19484070946265
At time: 716.4638810157776 and batch: 1000, loss is 3.9314564990997316 and perplexity is 50.98117765933884
At time: 717.6632542610168 and batch: 1050, loss is 3.861775288581848 and perplexity is 47.54969090653045
At time: 718.8668723106384 and batch: 1100, loss is 3.824828519821167 and perplexity is 45.82494162335882
At time: 720.064567565918 and batch: 1150, loss is 3.84328070640564 and perplexity is 46.678361513482876
At time: 721.2664458751678 and batch: 1200, loss is 3.815379023551941 and perplexity is 45.393958502125294
At time: 722.4726119041443 and batch: 1250, loss is 3.8463094282150267 and perplexity is 46.81995159527393
At time: 723.6693952083588 and batch: 1300, loss is 3.81884388923645 and perplexity is 45.55151527011648
At time: 724.872615814209 and batch: 1350, loss is 3.794835271835327 and perplexity is 44.470910190711294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601550699869792 and perplexity of 99.63870563257721
Finished 21 epochs...
Completing Train Step...
At time: 728.3410873413086 and batch: 50, loss is 4.097149920463562 and perplexity is 60.16855781647118
At time: 729.5234694480896 and batch: 100, loss is 4.090117793083191 and perplexity is 59.746929064646615
At time: 730.7196533679962 and batch: 150, loss is 4.065662155151367 and perplexity is 58.303501707802226
At time: 731.9179060459137 and batch: 200, loss is 4.051221208572388 and perplexity is 57.467594129310804
At time: 733.1217963695526 and batch: 250, loss is 4.059651207923889 and perplexity is 57.95409362468587
At time: 734.3230721950531 and batch: 300, loss is 4.043854999542236 and perplexity is 57.04583112283423
At time: 735.5196945667267 and batch: 350, loss is 4.054996418952942 and perplexity is 57.684956423249695
At time: 736.7219088077545 and batch: 400, loss is 4.059139347076416 and perplexity is 57.9244367839439
At time: 737.9215123653412 and batch: 450, loss is 3.9903574705123903 and perplexity is 54.074215846442605
At time: 739.1241323947906 and batch: 500, loss is 4.066135144233703 and perplexity is 58.331085150391345
At time: 740.3217396736145 and batch: 550, loss is 4.0560753583908085 and perplexity is 57.74722858561132
At time: 741.5269598960876 and batch: 600, loss is 4.007330675125122 and perplexity is 54.99986194426906
At time: 742.7259378433228 and batch: 650, loss is 4.01504946231842 and perplexity is 55.42603683497721
At time: 743.9280993938446 and batch: 700, loss is 4.022244963645935 and perplexity is 55.82629325244765
At time: 745.1254200935364 and batch: 750, loss is 3.97168728351593 and perplexity is 53.07400622910859
At time: 746.3225739002228 and batch: 800, loss is 3.93929283618927 and perplexity is 51.38225278018267
At time: 747.5197999477386 and batch: 850, loss is 3.9126714181900026 and perplexity is 50.032431151342756
At time: 748.7176582813263 and batch: 900, loss is 3.925719075202942 and perplexity is 50.68951452993484
At time: 749.914243221283 and batch: 950, loss is 3.91513231754303 and perplexity is 50.15570755198703
At time: 751.1174356937408 and batch: 1000, loss is 3.9308323001861574 and perplexity is 50.94936519331742
At time: 752.3152778148651 and batch: 1050, loss is 3.8611793375015258 and perplexity is 47.52136205900779
At time: 753.5146734714508 and batch: 1100, loss is 3.824472179412842 and perplexity is 45.808615253994596
At time: 754.7120940685272 and batch: 1150, loss is 3.8430576086044312 and perplexity is 46.6679488352312
At time: 755.9426720142365 and batch: 1200, loss is 3.815262017250061 and perplexity is 45.38864743363358
At time: 757.1399259567261 and batch: 1250, loss is 3.8463550710678103 and perplexity is 46.82208864020197
At time: 758.3381414413452 and batch: 1300, loss is 3.819034552574158 and perplexity is 45.56020110206407
At time: 759.5357532501221 and batch: 1350, loss is 3.795021662712097 and perplexity is 44.47919993519487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601576741536459 and perplexity of 99.6413004243226
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 762.9779887199402 and batch: 50, loss is 4.096924777030945 and perplexity is 60.15501278567333
At time: 764.1734757423401 and batch: 100, loss is 4.09136360168457 and perplexity is 59.821408686825336
At time: 765.3563725948334 and batch: 150, loss is 4.067916893959046 and perplexity is 58.43510919021935
At time: 766.557382106781 and batch: 200, loss is 4.053818259239197 and perplexity is 57.617034350884026
At time: 767.7530062198639 and batch: 250, loss is 4.06241427898407 and perplexity is 58.11444633454671
At time: 768.9494004249573 and batch: 300, loss is 4.046770691871643 and perplexity is 57.212401931673384
At time: 770.1491632461548 and batch: 350, loss is 4.0577483749389645 and perplexity is 57.84392151652845
At time: 771.3486068248749 and batch: 400, loss is 4.062691216468811 and perplexity is 58.130542631872885
At time: 772.5445055961609 and batch: 450, loss is 3.9938912343978883 and perplexity is 54.265639381124366
At time: 773.7459237575531 and batch: 500, loss is 4.0704755687713625 and perplexity is 58.584817077483684
At time: 774.9467537403107 and batch: 550, loss is 4.060171928405762 and perplexity is 57.98427936672958
At time: 776.1429617404938 and batch: 600, loss is 4.011407256126404 and perplexity is 55.22453096613861
At time: 777.3447856903076 and batch: 650, loss is 4.018079180717468 and perplexity is 55.59421675882092
At time: 778.5411639213562 and batch: 700, loss is 4.0230947732925415 and perplexity is 55.87375513891601
At time: 779.7372601032257 and batch: 750, loss is 3.974037055969238 and perplexity is 53.19886470398509
At time: 780.9333958625793 and batch: 800, loss is 3.9419158935546874 and perplexity is 51.517208297441925
At time: 782.1297347545624 and batch: 850, loss is 3.913155617713928 and perplexity is 50.05666269666501
At time: 783.3262431621552 and batch: 900, loss is 3.9236722564697266 and perplexity is 50.58586839063232
At time: 784.5227499008179 and batch: 950, loss is 3.9120261096954345 and perplexity is 50.00015521360533
At time: 785.7191064357758 and batch: 1000, loss is 3.926044373512268 and perplexity is 50.70600642555943
At time: 786.9461600780487 and batch: 1050, loss is 3.855138282775879 and perplexity is 47.23514829710288
At time: 788.1425087451935 and batch: 1100, loss is 3.8175908803939818 and perplexity is 45.494474562413735
At time: 789.3387100696564 and batch: 1150, loss is 3.8366169548034668 and perplexity is 46.36834259889343
At time: 790.5353763103485 and batch: 1200, loss is 3.806229519844055 and perplexity is 44.98052057062594
At time: 791.7313766479492 and batch: 1250, loss is 3.8376386642456053 and perplexity is 46.41574178231637
At time: 792.9329702854156 and batch: 1300, loss is 3.8110980701446535 and perplexity is 45.200044445474205
At time: 794.1294634342194 and batch: 1350, loss is 3.7887856006622314 and perplexity is 44.20268795350171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601315511067709 and perplexity of 99.61527448023868
Finished 23 epochs...
Completing Train Step...
At time: 797.5687944889069 and batch: 50, loss is 4.09620023727417 and perplexity is 60.11144387295149
At time: 798.7787101268768 and batch: 100, loss is 4.09118236541748 and perplexity is 59.81056786042801
At time: 799.9608910083771 and batch: 150, loss is 4.067274312973023 and perplexity is 58.3975719617838
At time: 801.1523537635803 and batch: 200, loss is 4.0527039957046505 and perplexity is 57.552869545428415
At time: 802.347179889679 and batch: 250, loss is 4.06048159122467 and perplexity is 58.00223772250471
At time: 803.5480687618256 and batch: 300, loss is 4.045006833076477 and perplexity is 57.11157628058007
At time: 804.7486975193024 and batch: 350, loss is 4.055741376876831 and perplexity is 57.727945299090166
At time: 805.9461078643799 and batch: 400, loss is 4.06032000541687 and perplexity is 57.99286614124577
At time: 807.143527507782 and batch: 450, loss is 3.9916554069519044 and perplexity is 54.14444630910676
At time: 808.3409442901611 and batch: 500, loss is 4.068003754615784 and perplexity is 58.44018512262641
At time: 809.5413274765015 and batch: 550, loss is 4.0578655338287355 and perplexity is 57.85069884315761
At time: 810.7432019710541 and batch: 600, loss is 4.00898386478424 and perplexity is 55.09086234702507
At time: 811.9407112598419 and batch: 650, loss is 4.01613754272461 and perplexity is 55.486377641521514
At time: 813.1377527713776 and batch: 700, loss is 4.021694345474243 and perplexity is 55.79556274208976
At time: 814.3345711231232 and batch: 750, loss is 3.97269829750061 and perplexity is 53.12769192555126
At time: 815.5317189693451 and batch: 800, loss is 3.940654797554016 and perplexity is 51.45228110041134
At time: 816.7612764835358 and batch: 850, loss is 3.912092938423157 and perplexity is 50.003496772018984
At time: 817.9597156047821 and batch: 900, loss is 3.9230136394500734 and perplexity is 50.55256264582544
At time: 819.1616153717041 and batch: 950, loss is 3.911433629989624 and perplexity is 49.97053991045328
At time: 820.3585350513458 and batch: 1000, loss is 3.925938220024109 and perplexity is 50.70062409178856
At time: 821.5685033798218 and batch: 1050, loss is 3.855463080406189 and perplexity is 47.25049265310748
At time: 822.7662291526794 and batch: 1100, loss is 3.8183355951309204 and perplexity is 45.5283675868206
At time: 823.963757276535 and batch: 1150, loss is 3.8377444696426393 and perplexity is 46.42065307812049
At time: 825.1612894535065 and batch: 1200, loss is 3.807494945526123 and perplexity is 45.03747610544679
At time: 826.3583467006683 and batch: 1250, loss is 3.8391185092926023 and perplexity is 46.4844807368518
At time: 827.5578217506409 and batch: 1300, loss is 3.812707633972168 and perplexity is 45.27285538322227
At time: 828.7554383277893 and batch: 1350, loss is 3.7902120780944824 and perplexity is 44.26578708435558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6008642578125 and perplexity of 99.57033290413983
Finished 24 epochs...
Completing Train Step...
At time: 832.2097845077515 and batch: 50, loss is 4.0959807395935055 and perplexity is 60.09825099839565
At time: 833.3939788341522 and batch: 100, loss is 4.09105339050293 and perplexity is 59.80285429498793
At time: 834.5761563777924 and batch: 150, loss is 4.06683735370636 and perplexity is 58.37206017577604
At time: 835.7643902301788 and batch: 200, loss is 4.051957831382752 and perplexity is 57.509941665168775
At time: 836.9599673748016 and batch: 250, loss is 4.059309163093567 and perplexity is 57.93427411633893
At time: 838.1588132381439 and batch: 300, loss is 4.043950438499451 and perplexity is 57.051275777281965
At time: 839.3574917316437 and batch: 350, loss is 4.054522342681885 and perplexity is 57.6576158354865
At time: 840.5553607940674 and batch: 400, loss is 4.05892849445343 and perplexity is 57.91222455204885
At time: 841.7538440227509 and batch: 450, loss is 3.9903014850616456 and perplexity is 54.071188561837516
At time: 842.9525012969971 and batch: 500, loss is 4.066495680809021 and perplexity is 58.35211943165208
At time: 844.1504590511322 and batch: 550, loss is 4.056503825187683 and perplexity is 57.77197665715662
At time: 845.3494501113892 and batch: 600, loss is 4.007634181976318 and perplexity is 55.01655731263517
At time: 846.5747146606445 and batch: 650, loss is 4.015104169845581 and perplexity is 55.42906913933696
At time: 847.7721364498138 and batch: 700, loss is 4.020899529457092 and perplexity is 55.75123315440327
At time: 848.9709420204163 and batch: 750, loss is 3.9720055723190306 and perplexity is 53.09090177971665
At time: 850.1689500808716 and batch: 800, loss is 3.9400151586532592 and perplexity is 51.41938074318274
At time: 851.3669669628143 and batch: 850, loss is 3.911551456451416 and perplexity is 49.97642810925076
At time: 852.5654835700989 and batch: 900, loss is 3.922729558944702 and perplexity is 50.53820368792777
At time: 853.7637507915497 and batch: 950, loss is 3.9112411642074587 and perplexity is 49.9609232168761
At time: 854.9610028266907 and batch: 1000, loss is 3.9260245513916017 and perplexity is 50.705001334943105
At time: 856.16370844841 and batch: 1050, loss is 3.8557707023620607 and perplexity is 47.265030177989594
At time: 857.3625559806824 and batch: 1100, loss is 3.8188936853408815 and perplexity is 45.55378361460477
At time: 858.5620708465576 and batch: 1150, loss is 3.8384516429901123 and perplexity is 46.45349213683462
At time: 859.7611548900604 and batch: 1200, loss is 3.8082852602005004 and perplexity is 45.07308395255852
At time: 860.970912694931 and batch: 1250, loss is 3.8400086164474487 and perplexity is 46.52587532582185
At time: 862.169764995575 and batch: 1300, loss is 3.8136591577529906 and perplexity is 45.31595408321233
At time: 863.3685188293457 and batch: 1350, loss is 3.791083583831787 and perplexity is 44.30438178707553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600568033854167 and perplexity of 99.5408421541434
Finished 25 epochs...
Completing Train Step...
At time: 866.8074553012848 and batch: 50, loss is 4.095729918479919 and perplexity is 60.083178978425074
At time: 867.9829535484314 and batch: 100, loss is 4.0907991504669186 and perplexity is 59.787651947762924
At time: 869.1804616451263 and batch: 150, loss is 4.066371998786926 and perplexity is 58.3449027698221
At time: 870.3735105991364 and batch: 200, loss is 4.051328692436218 and perplexity is 57.47377130034003
At time: 871.5736525058746 and batch: 250, loss is 4.058436017036438 and perplexity is 57.8837111109784
At time: 872.7724366188049 and batch: 300, loss is 4.043137540817261 and perplexity is 57.004917772146904
At time: 873.9761071205139 and batch: 350, loss is 4.053636965751648 and perplexity is 57.606589704586085
At time: 875.1744990348816 and batch: 400, loss is 4.057976460456848 and perplexity is 57.85711638204561
At time: 876.3721709251404 and batch: 450, loss is 3.9893658113479615 and perplexity is 54.020619233917365
At time: 877.6212816238403 and batch: 500, loss is 4.065518636703491 and perplexity is 58.29513468015715
At time: 878.821724653244 and batch: 550, loss is 4.055594224929809 and perplexity is 57.719451144522836
At time: 880.0250334739685 and batch: 600, loss is 4.006772532463073 and perplexity is 54.96917274018493
At time: 881.2228589057922 and batch: 650, loss is 4.014428482055664 and perplexity is 55.391629044445
At time: 882.4212896823883 and batch: 700, loss is 4.020353236198425 and perplexity is 55.72078494915052
At time: 883.6199276447296 and batch: 750, loss is 3.971566529273987 and perplexity is 53.067597704655554
At time: 884.8179380893707 and batch: 800, loss is 3.9396235704422 and perplexity is 51.39924946170723
At time: 886.0154967308044 and batch: 850, loss is 3.9112222623825073 and perplexity is 49.95997887317598
At time: 887.2138063907623 and batch: 900, loss is 3.922555694580078 and perplexity is 50.52941765906512
At time: 888.4135384559631 and batch: 950, loss is 3.9111387872695924 and perplexity is 49.9558086323564
At time: 889.6109664440155 and batch: 1000, loss is 3.9260912895202638 and perplexity is 50.708385404767995
At time: 890.8092758655548 and batch: 1050, loss is 3.855966272354126 and perplexity is 47.274274703512894
At time: 892.0096552371979 and batch: 1100, loss is 3.819261465072632 and perplexity is 45.570540454146865
At time: 893.2183864116669 and batch: 1150, loss is 3.8389091205596926 and perplexity is 46.47474842928367
At time: 894.419887304306 and batch: 1200, loss is 3.808795495033264 and perplexity is 45.09608767816318
At time: 895.618155002594 and batch: 1250, loss is 3.840577702522278 and perplexity is 46.55236008892917
At time: 896.8160729408264 and batch: 1300, loss is 3.814256730079651 and perplexity is 45.343041735938435
At time: 898.0145130157471 and batch: 1350, loss is 3.791643223762512 and perplexity is 44.329183227520566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600367024739583 and perplexity of 99.52083554841953
Finished 26 epochs...
Completing Train Step...
At time: 901.4605526924133 and batch: 50, loss is 4.095444173812866 and perplexity is 60.066012983114994
At time: 902.6678738594055 and batch: 100, loss is 4.090477857589722 and perplexity is 59.76844568663046
At time: 903.8524549007416 and batch: 150, loss is 4.065909795761108 and perplexity is 58.317941810419306
At time: 905.0412986278534 and batch: 200, loss is 4.050760850906372 and perplexity is 57.44114457040164
At time: 906.2296659946442 and batch: 250, loss is 4.0577192735672 and perplexity is 57.842238203557535
At time: 907.4455051422119 and batch: 300, loss is 4.042454442977905 and perplexity is 56.96599113284937
At time: 908.641227722168 and batch: 350, loss is 4.0529290962219235 and perplexity is 57.56582618435199
At time: 909.833648443222 and batch: 400, loss is 4.057249932289124 and perplexity is 57.81509682333558
At time: 911.0305800437927 and batch: 450, loss is 3.988651967048645 and perplexity is 53.982070683300186
At time: 912.2276840209961 and batch: 500, loss is 4.064814081192017 and perplexity is 58.25407698713649
At time: 913.4289450645447 and batch: 550, loss is 4.054921140670777 and perplexity is 57.680614162264405
At time: 914.6250379085541 and batch: 600, loss is 4.006152443885803 and perplexity is 54.935097549976696
At time: 915.8219563961029 and batch: 650, loss is 4.013919734954834 and perplexity is 55.36345588087368
At time: 917.0179724693298 and batch: 700, loss is 4.01992862701416 and perplexity is 55.69713041442837
At time: 918.217449426651 and batch: 750, loss is 3.971236991882324 and perplexity is 53.05011282804469
At time: 919.4179811477661 and batch: 800, loss is 3.939337344169617 and perplexity is 51.38453975137345
At time: 920.6194040775299 and batch: 850, loss is 3.910977673530579 and perplexity is 49.947760713574745
At time: 921.816935300827 and batch: 900, loss is 3.922416410446167 and perplexity is 50.52238020300381
At time: 923.0138199329376 and batch: 950, loss is 3.9110583066940308 and perplexity is 49.95178832190564
At time: 924.209356546402 and batch: 1000, loss is 3.9261209058761595 and perplexity is 50.709887224596145
At time: 925.4073054790497 and batch: 1050, loss is 3.8560784673690796 and perplexity is 47.279578939019004
At time: 926.6050124168396 and batch: 1100, loss is 3.8195003604888917 and perplexity is 45.58142834786001
At time: 927.8018555641174 and batch: 1150, loss is 3.839217119216919 and perplexity is 46.48906479399221
At time: 929.0040652751923 and batch: 1200, loss is 3.809138464927673 and perplexity is 45.11155693118482
At time: 930.2004981040955 and batch: 1250, loss is 3.840962643623352 and perplexity is 46.57028345517826
At time: 931.3970730304718 and batch: 1300, loss is 3.8146550369262697 and perplexity is 45.361105777185216
At time: 932.600358247757 and batch: 1350, loss is 3.7920244455337526 and perplexity is 44.34608569885854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600222981770833 and perplexity of 99.50650130421297
Finished 27 epochs...
Completing Train Step...
At time: 936.0213963985443 and batch: 50, loss is 4.095141453742981 and perplexity is 60.04783254739725
At time: 937.2236821651459 and batch: 100, loss is 4.090128512382507 and perplexity is 59.747569513295026
At time: 938.4196894168854 and batch: 150, loss is 4.065464239120484 and perplexity is 58.2919636519784
At time: 939.6206686496735 and batch: 200, loss is 4.050234580039978 and perplexity is 57.410922922565824
At time: 940.818514585495 and batch: 250, loss is 4.057097573280334 and perplexity is 57.806288843495075
At time: 942.0157647132874 and batch: 300, loss is 4.041855216026306 and perplexity is 56.9318658010684
At time: 943.2126877307892 and batch: 350, loss is 4.052328190803528 and perplexity is 57.531244958546935
At time: 944.4101369380951 and batch: 400, loss is 4.056651620864868 and perplexity is 57.78051573657299
At time: 945.6073639392853 and batch: 450, loss is 3.9880670928955078 and perplexity is 53.950507196658215
At time: 946.8109257221222 and batch: 500, loss is 4.064254260063171 and perplexity is 58.22147425069952
At time: 948.0079789161682 and batch: 550, loss is 4.054380736351013 and perplexity is 57.64945173011936
At time: 949.2052755355835 and batch: 600, loss is 4.005659427642822 and perplexity is 54.90802032987794
At time: 950.4020771980286 and batch: 650, loss is 4.013498072624206 and perplexity is 55.34011611813053
At time: 951.5987746715546 and batch: 700, loss is 4.0195691108703615 and perplexity is 55.67710999592861
At time: 952.7956850528717 and batch: 750, loss is 3.970958127975464 and perplexity is 53.03532112885346
At time: 953.9978029727936 and batch: 800, loss is 3.939099168777466 and perplexity is 51.37230267581066
At time: 955.1955091953278 and batch: 850, loss is 3.9107697772979737 and perplexity is 49.93737784161271
At time: 956.3948123455048 and batch: 900, loss is 3.922288064956665 and perplexity is 50.51589629948464
At time: 957.5958704948425 and batch: 950, loss is 3.9109827375411985 and perplexity is 49.948013650205866
At time: 958.7922730445862 and batch: 1000, loss is 3.9261218786239622 and perplexity is 50.70993655255151
At time: 959.9915673732758 and batch: 1050, loss is 3.8561344861984255 and perplexity is 47.282227559868765
At time: 961.1888740062714 and batch: 1100, loss is 3.8196567726135253 and perplexity is 45.58855839350999
At time: 962.3872497081757 and batch: 1150, loss is 3.8394298362731933 and perplexity is 46.49895486286001
At time: 963.5846076011658 and batch: 1200, loss is 3.809376449584961 and perplexity is 45.12229406718696
At time: 964.7815670967102 and batch: 1250, loss is 3.8412352418899536 and perplexity is 46.58298016419509
At time: 965.9780323505402 and batch: 1300, loss is 3.8149348211288454 and perplexity is 45.37379887357417
At time: 967.1755533218384 and batch: 1350, loss is 3.792298603057861 and perplexity is 44.35824517864791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600123697916667 and perplexity of 99.49662240566455
Finished 28 epochs...
Completing Train Step...
At time: 970.6359763145447 and batch: 50, loss is 4.0948326206207275 and perplexity is 60.02929065111032
At time: 971.8074460029602 and batch: 100, loss is 4.089770112037659 and perplexity is 59.726159800630995
At time: 972.9912142753601 and batch: 150, loss is 4.065038084983826 and perplexity is 58.26712758290684
At time: 974.1872193813324 and batch: 200, loss is 4.04974139213562 and perplexity is 57.38261553080775
At time: 975.3867723941803 and batch: 250, loss is 4.056538915634155 and perplexity is 57.77400393717997
At time: 976.5839626789093 and batch: 300, loss is 4.04131365776062 and perplexity is 56.901042225697246
At time: 977.7808997631073 and batch: 350, loss is 4.0517964363098145 and perplexity is 57.50066059291891
At time: 978.9836838245392 and batch: 400, loss is 4.0561318111419675 and perplexity is 57.75048866755622
At time: 980.1803553104401 and batch: 450, loss is 3.9875622510910036 and perplexity is 53.92327759914903
At time: 981.3776347637177 and batch: 500, loss is 4.063778967857361 and perplexity is 58.19380861292918
At time: 982.5746829509735 and batch: 550, loss is 4.053919706344605 and perplexity is 57.62287972873442
At time: 983.771646976471 and batch: 600, loss is 4.005239539146423 and perplexity is 54.8849699234203
At time: 984.9691073894501 and batch: 650, loss is 4.013127317428589 and perplexity is 55.319602285593646
At time: 986.1667621135712 and batch: 700, loss is 4.019248461723327 and perplexity is 55.65926004003859
At time: 987.3639707565308 and batch: 750, loss is 3.9707053995132444 and perplexity is 53.02191928728599
At time: 988.5676302909851 and batch: 800, loss is 3.9388852071762086 and perplexity is 51.361312151486885
At time: 989.7647881507874 and batch: 850, loss is 3.9105784416198732 and perplexity is 49.927823953589794
At time: 990.9625821113586 and batch: 900, loss is 3.9221622371673583 and perplexity is 50.50954039581147
At time: 992.1598205566406 and batch: 950, loss is 3.910906238555908 and perplexity is 49.94419282399088
At time: 993.3616118431091 and batch: 1000, loss is 3.9261016273498535 and perplexity is 50.70890962212471
At time: 994.5597546100616 and batch: 1050, loss is 3.856152057647705 and perplexity is 47.283058384431534
At time: 995.7635586261749 and batch: 1100, loss is 3.8197594356536864 and perplexity is 45.59323889376431
At time: 996.9660775661469 and batch: 1150, loss is 3.839579391479492 and perplexity is 46.505909543688595
At time: 998.1890211105347 and batch: 1200, loss is 3.809545841217041 and perplexity is 45.12993805361757
At time: 999.3859367370605 and batch: 1250, loss is 3.841436104774475 and perplexity is 46.5923378957395
At time: 1000.588983297348 and batch: 1300, loss is 3.815140376091003 and perplexity is 45.38312664173625
At time: 1001.7856380939484 and batch: 1350, loss is 3.7925052785873414 and perplexity is 44.367413889898515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600051676432292 and perplexity of 99.48945676927161
Finished 29 epochs...
Completing Train Step...
At time: 1005.2396862506866 and batch: 50, loss is 4.094523115158081 and perplexity is 60.01071413265027
At time: 1006.4197404384613 and batch: 100, loss is 4.08941134929657 and perplexity is 59.70473612306461
At time: 1007.6180453300476 and batch: 150, loss is 4.06462993144989 and perplexity is 58.243350501551554
At time: 1008.8089156150818 and batch: 200, loss is 4.049276113510132 and perplexity is 57.355922836578245
At time: 1010.0141265392303 and batch: 250, loss is 4.056024265289307 and perplexity is 57.744278175973186
At time: 1011.2188079357147 and batch: 300, loss is 4.040813694000244 and perplexity is 56.87260087707102
At time: 1012.4222111701965 and batch: 350, loss is 4.0513126039505005 and perplexity is 57.47284664182951
At time: 1013.6277904510498 and batch: 400, loss is 4.0556631803512575 and perplexity is 57.723431350829095
At time: 1014.8300039768219 and batch: 450, loss is 3.9871099472045897 and perplexity is 53.89889340607112
At time: 1016.0349719524384 and batch: 500, loss is 4.063356256484985 and perplexity is 58.1692146266717
At time: 1017.2362856864929 and batch: 550, loss is 4.053509268760681 and perplexity is 57.59923398608254
At time: 1018.4362642765045 and batch: 600, loss is 4.004865097999573 and perplexity is 54.86442257946291
At time: 1019.6427619457245 and batch: 650, loss is 4.012789158821106 and perplexity is 55.30089864849442
At time: 1020.8482201099396 and batch: 700, loss is 4.018952779769897 and perplexity is 55.64280503414751
At time: 1022.0493047237396 and batch: 750, loss is 3.970468134880066 and perplexity is 53.00934055335923
At time: 1023.2559764385223 and batch: 800, loss is 3.938684892654419 and perplexity is 51.35102476519561
At time: 1024.4549098014832 and batch: 850, loss is 3.910398087501526 and perplexity is 49.91882007688717
At time: 1025.6539461612701 and batch: 900, loss is 3.922035756111145 and perplexity is 50.50315229978844
At time: 1026.8496966362 and batch: 950, loss is 3.910826678276062 and perplexity is 49.94021940809826
At time: 1028.0840191841125 and batch: 1000, loss is 3.926065330505371 and perplexity is 50.70706908212138
At time: 1029.275535106659 and batch: 1050, loss is 3.8561422204971314 and perplexity is 47.28259325615439
At time: 1030.4721298217773 and batch: 1100, loss is 3.8198248195648192 and perplexity is 45.596220055503345
At time: 1031.6678721904755 and batch: 1150, loss is 3.8396851921081545 and perplexity is 46.510830158452315
At time: 1032.8644559383392 and batch: 1200, loss is 3.809668292999268 and perplexity is 45.13546463332688
At time: 1034.0649707317352 and batch: 1250, loss is 3.841588354110718 and perplexity is 46.599432088287465
At time: 1035.2659249305725 and batch: 1300, loss is 3.8152973556518557 and perplexity is 45.39025142423456
At time: 1036.4677226543427 and batch: 1350, loss is 3.7926670837402345 and perplexity is 44.374593346907346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.600002848307292 and perplexity of 99.48459900423903
Finished 30 epochs...
Completing Train Step...
At time: 1039.923168182373 and batch: 50, loss is 4.0942149829864505 and perplexity is 59.99222574956258
At time: 1041.144582271576 and batch: 100, loss is 4.089056177139282 and perplexity is 59.68353442848419
At time: 1042.3260695934296 and batch: 150, loss is 4.064237222671509 and perplexity is 58.220482317089576
At time: 1043.507245540619 and batch: 200, loss is 4.048833141326904 and perplexity is 57.330521384701946
At time: 1044.6887328624725 and batch: 250, loss is 4.055542144775391 and perplexity is 57.71644518487039
At time: 1045.883288860321 and batch: 300, loss is 4.040344672203064 and perplexity is 56.84593264207799
At time: 1047.0803887844086 and batch: 350, loss is 4.050863194465637 and perplexity is 57.44702360242061
At time: 1048.2782464027405 and batch: 400, loss is 4.055229301452637 and perplexity is 57.6983918044682
At time: 1049.4758224487305 and batch: 450, loss is 3.9866936016082763 and perplexity is 53.87645751002269
At time: 1050.6731462478638 and batch: 500, loss is 4.062968940734863 and perplexity is 58.14668913619478
At time: 1051.870833158493 and batch: 550, loss is 4.053132843971253 and perplexity is 57.57755628682573
At time: 1053.0681111812592 and batch: 600, loss is 4.004520959854126 and perplexity is 54.84554488727873
At time: 1054.2656388282776 and batch: 650, loss is 4.012474856376648 and perplexity is 55.28352017206033
At time: 1055.4634356498718 and batch: 700, loss is 4.01867461681366 and perplexity is 55.627329419477
At time: 1056.6611111164093 and batch: 750, loss is 3.9702409982681273 and perplexity is 52.99730155864482
At time: 1057.8927471637726 and batch: 800, loss is 3.9384925985336303 and perplexity is 51.3411512143801
At time: 1059.0917582511902 and batch: 850, loss is 3.9102245235443114 and perplexity is 49.91015672078008
At time: 1060.289890050888 and batch: 900, loss is 3.9219077730178835 and perplexity is 50.496689163732555
At time: 1061.4870891571045 and batch: 950, loss is 3.910743441581726 and perplexity is 49.9360627223171
At time: 1062.6834766864777 and batch: 1000, loss is 3.9260165309906006 and perplexity is 50.704594662130475
At time: 1063.8817451000214 and batch: 1050, loss is 3.8561129474639895 and perplexity is 47.281209171493245
At time: 1065.0824530124664 and batch: 1100, loss is 3.819863409996033 and perplexity is 45.59797966724887
At time: 1066.2843267917633 and batch: 1150, loss is 3.8397596168518064 and perplexity is 46.514291843879825
At time: 1067.4825398921967 and batch: 1200, loss is 3.8097573280334474 and perplexity is 45.1394834498683
At time: 1068.686934709549 and batch: 1250, loss is 3.8417058849334715 and perplexity is 46.60490927974376
At time: 1069.8963603973389 and batch: 1300, loss is 3.815420823097229 and perplexity is 45.39585598860627
At time: 1071.0935933589935 and batch: 1350, loss is 3.7927973890304565 and perplexity is 44.38037596791677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5999658203125 and perplexity of 99.48091535722466
Finished 31 epochs...
Completing Train Step...
At time: 1074.5582075119019 and batch: 50, loss is 4.093909134864807 and perplexity is 59.97388004564644
At time: 1075.7697269916534 and batch: 100, loss is 4.088706188201904 and perplexity is 59.66264950664958
At time: 1076.950386762619 and batch: 150, loss is 4.063857302665711 and perplexity is 58.19836739232726
At time: 1078.1276371479034 and batch: 200, loss is 4.048410000801087 and perplexity is 57.306267649468865
At time: 1079.3184032440186 and batch: 250, loss is 4.055084528923035 and perplexity is 57.6900392669563
At time: 1080.5206422805786 and batch: 300, loss is 4.039899578094483 and perplexity is 56.82063648236563
At time: 1081.7252988815308 and batch: 350, loss is 4.05043993473053 and perplexity is 57.42271373548481
At time: 1082.9237897396088 and batch: 400, loss is 4.0548201751708985 and perplexity is 57.67479070421136
At time: 1084.1223063468933 and batch: 450, loss is 3.98630304813385 and perplexity is 53.85541998075986
At time: 1085.3203451633453 and batch: 500, loss is 4.062606434822083 and perplexity is 58.12561443765653
At time: 1086.5246624946594 and batch: 550, loss is 4.052780566215515 and perplexity is 57.557276566773
At time: 1087.7295680046082 and batch: 600, loss is 4.004198412895203 and perplexity is 54.827857476228516
At time: 1088.9552278518677 and batch: 650, loss is 4.012178564071656 and perplexity is 55.26714251684688
At time: 1090.1539442539215 and batch: 700, loss is 4.018409118652344 and perplexity is 55.61256242618877
At time: 1091.3524742126465 and batch: 750, loss is 3.970021057128906 and perplexity is 52.985646553518905
At time: 1092.550874710083 and batch: 800, loss is 3.9383059120178223 and perplexity is 51.33156740835382
At time: 1093.7552740573883 and batch: 850, loss is 3.9100541353225706 and perplexity is 49.90165334238796
At time: 1094.9539289474487 and batch: 900, loss is 3.9217778301239012 and perplexity is 50.49012790410986
At time: 1096.1528143882751 and batch: 950, loss is 3.910656590461731 and perplexity is 49.931725907672856
At time: 1097.350521326065 and batch: 1000, loss is 3.9259575843811034 and perplexity is 50.70160588627919
At time: 1098.5603685379028 and batch: 1050, loss is 3.856069355010986 and perplexity is 47.279148112528134
At time: 1099.7617001533508 and batch: 1100, loss is 3.819881944656372 and perplexity is 45.59882481814641
At time: 1100.9601233005524 and batch: 1150, loss is 3.8398105573654173 and perplexity is 46.516661366148426
At time: 1102.1587381362915 and batch: 1200, loss is 3.8098215532302855 and perplexity is 45.14238263517742
At time: 1103.3582100868225 and batch: 1250, loss is 3.841797947883606 and perplexity is 46.60920006269084
At time: 1104.5579462051392 and batch: 1300, loss is 3.815520443916321 and perplexity is 45.40037858623193
At time: 1105.7560374736786 and batch: 1350, loss is 3.7929046678543092 and perplexity is 44.38513729784312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599939371744791 and perplexity of 99.47828426429362
Finished 32 epochs...
Completing Train Step...
At time: 1109.2188968658447 and batch: 50, loss is 4.093606147766113 and perplexity is 59.95571148629252
At time: 1110.3879086971283 and batch: 100, loss is 4.088362011909485 and perplexity is 59.6421185704799
At time: 1111.5614566802979 and batch: 150, loss is 4.063488564491272 and perplexity is 58.17691138864662
At time: 1112.7517652511597 and batch: 200, loss is 4.04800386428833 and perplexity is 57.282998207371506
At time: 1113.9518330097198 and batch: 250, loss is 4.054646286964417 and perplexity is 57.6647626102055
At time: 1115.151400089264 and batch: 300, loss is 4.0394736003875735 and perplexity is 56.79643731245113
At time: 1116.3567719459534 and batch: 350, loss is 4.050037136077881 and perplexity is 57.39958860145978
At time: 1117.556758403778 and batch: 400, loss is 4.054429316520691 and perplexity is 57.652252418294665
At time: 1118.7821729183197 and batch: 450, loss is 3.98593159198761 and perplexity is 53.83541876901615
At time: 1119.9802033901215 and batch: 500, loss is 4.062262167930603 and perplexity is 58.10560715717846
At time: 1121.1856372356415 and batch: 550, loss is 4.052446045875549 and perplexity is 57.538025707129975
At time: 1122.3835892677307 and batch: 600, loss is 4.003892030715942 and perplexity is 54.811061770854536
At time: 1123.5873928070068 and batch: 650, loss is 4.011897163391113 and perplexity is 55.25159249332723
At time: 1124.7911200523376 and batch: 700, loss is 4.01815345287323 and perplexity is 55.598346014489984
At time: 1125.991851568222 and batch: 750, loss is 3.9698068141937255 and perplexity is 52.974295969013525
At time: 1127.1942586898804 and batch: 800, loss is 3.938122982978821 and perplexity is 51.32217823285998
At time: 1128.398488521576 and batch: 850, loss is 3.909885816574097 and perplexity is 49.893254665397826
At time: 1129.5980801582336 and batch: 900, loss is 3.9216455888748167 and perplexity is 50.48345146798924
At time: 1130.8081629276276 and batch: 950, loss is 3.910566530227661 and perplexity is 49.92722924723828
At time: 1132.0079274177551 and batch: 1000, loss is 3.9258901929855345 and perplexity is 50.69818914943155
At time: 1133.21168923378 and batch: 1050, loss is 3.8560153532028196 and perplexity is 47.276595021977855
At time: 1134.412672996521 and batch: 1100, loss is 3.8198846864700315 and perplexity is 45.598949841798564
At time: 1135.6119303703308 and batch: 1150, loss is 3.8398434257507326 and perplexity is 46.51819031882476
At time: 1136.8174080848694 and batch: 1200, loss is 3.8098669481277465 and perplexity is 45.14443191552137
At time: 1138.0146992206573 and batch: 1250, loss is 3.8418710088729857 and perplexity is 46.61260550136246
At time: 1139.2129719257355 and batch: 1300, loss is 3.815602226257324 and perplexity is 45.40409168730613
At time: 1140.4119470119476 and batch: 1350, loss is 3.7929946422576903 and perplexity is 44.38913100375344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5999239095052085 and perplexity of 99.47674611912063
Finished 33 epochs...
Completing Train Step...
At time: 1143.8851075172424 and batch: 50, loss is 4.093305568695069 and perplexity is 59.937692762391464
At time: 1145.0494401454926 and batch: 100, loss is 4.088023328781128 and perplexity is 59.62192221145671
At time: 1146.232625246048 and batch: 150, loss is 4.063128671646118 and perplexity is 58.15597770165274
At time: 1147.423645734787 and batch: 200, loss is 4.047609257698059 and perplexity is 57.26039841807453
At time: 1148.6424582004547 and batch: 250, loss is 4.054223527908325 and perplexity is 57.64038946194227
At time: 1149.8379890918732 and batch: 300, loss is 4.039063239097596 and perplexity is 56.77313503467283
At time: 1151.027449131012 and batch: 350, loss is 4.049650659561157 and perplexity is 57.377409294562426
At time: 1152.229161977768 and batch: 400, loss is 4.054052639007568 and perplexity is 57.630540200736576
At time: 1153.4299132823944 and batch: 450, loss is 3.985574498176575 and perplexity is 53.81619790618908
At time: 1154.6338963508606 and batch: 500, loss is 4.0619318151474 and perplexity is 58.08641497840374
At time: 1155.8327791690826 and batch: 550, loss is 4.052125005722046 and perplexity is 57.51955665533693
At time: 1157.0306551456451 and batch: 600, loss is 4.003597760200501 and perplexity is 54.794934864408255
At time: 1158.2341265678406 and batch: 650, loss is 4.011627802848816 and perplexity is 55.23671189862292
At time: 1159.4362652301788 and batch: 700, loss is 4.0179054021835325 and perplexity is 55.58455651673295
At time: 1160.6335611343384 and batch: 750, loss is 3.9695967388153077 and perplexity is 52.9631685425815
At time: 1161.8308005332947 and batch: 800, loss is 3.9379428482055663 and perplexity is 51.31293415653587
At time: 1163.0308487415314 and batch: 850, loss is 3.9097186613082884 and perplexity is 49.884915442144134
At time: 1164.228563785553 and batch: 900, loss is 3.921511149406433 and perplexity is 50.47666495580948
At time: 1165.4263987541199 and batch: 950, loss is 3.910472288131714 and perplexity is 49.922524222218385
At time: 1166.6225912570953 and batch: 1000, loss is 3.925815825462341 and perplexity is 50.694418990864534
At time: 1167.8207020759583 and batch: 1050, loss is 3.855953779220581 and perplexity is 47.27368410337501
At time: 1169.0183913707733 and batch: 1100, loss is 3.8198748588562013 and perplexity is 45.59850171513046
At time: 1170.2152836322784 and batch: 1150, loss is 3.8398619174957274 and perplexity is 46.51905052929112
At time: 1171.4157276153564 and batch: 1200, loss is 3.809897427558899 and perplexity is 45.14580791309556
At time: 1172.6120779514313 and batch: 1250, loss is 3.841929388046265 and perplexity is 46.615326786168424
At time: 1173.8088715076447 and batch: 1300, loss is 3.8156701040267946 and perplexity is 45.407173720374274
At time: 1175.0058908462524 and batch: 1350, loss is 3.7930711936950683 and perplexity is 44.39252918560193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599911702473959 and perplexity of 99.47553181078369
Finished 34 epochs...
Completing Train Step...
At time: 1178.4385778903961 and batch: 50, loss is 4.09300738811493 and perplexity is 59.91982317070637
At time: 1179.6377725601196 and batch: 100, loss is 4.0876900625228885 and perplexity is 59.602055547160546
At time: 1180.8129134178162 and batch: 150, loss is 4.062776827812195 and perplexity is 58.13551947875349
At time: 1182.0010561943054 and batch: 200, loss is 4.047224230766297 and perplexity is 57.23835586632048
At time: 1183.1955218315125 and batch: 250, loss is 4.053813815116882 and perplexity is 57.616778294304936
At time: 1184.3930208683014 and batch: 300, loss is 4.038665914535523 and perplexity is 56.75058215436103
At time: 1185.5914239883423 and batch: 350, loss is 4.049277496337891 and perplexity is 57.35600214999532
At time: 1186.7962651252747 and batch: 400, loss is 4.053687405586243 and perplexity is 57.609495444724296
At time: 1187.9956576824188 and batch: 450, loss is 3.985228867530823 and perplexity is 53.79760059304067
At time: 1189.1932225227356 and batch: 500, loss is 4.061612529754639 and perplexity is 58.067871795024594
At time: 1190.3915066719055 and batch: 550, loss is 4.051814775466919 and perplexity is 57.50171511623667
At time: 1191.5953030586243 and batch: 600, loss is 4.003312883377075 and perplexity is 54.779327280649234
At time: 1192.7971246242523 and batch: 650, loss is 4.011367497444152 and perplexity is 55.222335355207036
At time: 1193.9946126937866 and batch: 700, loss is 4.01766345500946 and perplexity is 55.57110961714694
At time: 1195.1985368728638 and batch: 750, loss is 3.969389967918396 and perplexity is 52.95221843283969
At time: 1196.3999853134155 and batch: 800, loss is 3.937764449119568 and perplexity is 51.303780792482605
At time: 1197.6045677661896 and batch: 850, loss is 3.9095508527755736 and perplexity is 49.87654503001212
At time: 1198.8118963241577 and batch: 900, loss is 3.921374826431274 and perplexity is 50.46978429567329
At time: 1200.0150825977325 and batch: 950, loss is 3.910374140739441 and perplexity is 49.91762469709203
At time: 1201.2110922336578 and batch: 1000, loss is 3.9257355070114137 and perplexity is 50.69034745717235
At time: 1202.4149079322815 and batch: 1050, loss is 3.8558867454528807 and perplexity is 47.270515276426885
At time: 1203.6124567985535 and batch: 1100, loss is 3.819854907989502 and perplexity is 45.59759199457595
At time: 1204.812609910965 and batch: 1150, loss is 3.839868731498718 and perplexity is 46.51936751132051
At time: 1206.0102858543396 and batch: 1200, loss is 3.809916067123413 and perplexity is 45.146649419137326
At time: 1207.2073049545288 and batch: 1250, loss is 3.8419761276245117 and perplexity is 46.61750561780069
At time: 1208.4036598205566 and batch: 1300, loss is 3.815727219581604 and perplexity is 45.409767250358385
At time: 1209.5999398231506 and batch: 1350, loss is 3.793136839866638 and perplexity is 44.395443480844385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599903564453125 and perplexity of 99.47472228012742
Finished 35 epochs...
Completing Train Step...
At time: 1213.0619571208954 and batch: 50, loss is 4.092711672782898 and perplexity is 59.90210657996506
At time: 1214.2626531124115 and batch: 100, loss is 4.087361564636231 and perplexity is 59.58247961337532
At time: 1215.4374778270721 and batch: 150, loss is 4.062431535720825 and perplexity is 58.11544920890192
At time: 1216.6161079406738 and batch: 200, loss is 4.046847133636475 and perplexity is 57.21677551580742
At time: 1217.8182871341705 and batch: 250, loss is 4.0534149932861325 and perplexity is 57.59380404692392
At time: 1219.0156400203705 and batch: 300, loss is 4.038279919624329 and perplexity is 56.72868094559164
At time: 1220.2175333499908 and batch: 350, loss is 4.048915581703186 and perplexity is 57.335247929283724
At time: 1221.4224920272827 and batch: 400, loss is 4.053331613540649 and perplexity is 57.589002090396825
At time: 1222.620793581009 and batch: 450, loss is 3.9848926067352295 and perplexity is 53.77951361020628
At time: 1223.8219769001007 and batch: 500, loss is 4.061302399635315 and perplexity is 58.049865991231265
At time: 1225.0304725170135 and batch: 550, loss is 4.05151319026947 and perplexity is 57.48437606486171
At time: 1226.2298245429993 and batch: 600, loss is 4.003035726547242 and perplexity is 54.76414691972727
At time: 1227.4326062202454 and batch: 650, loss is 4.011114220619202 and perplexity is 55.208350588525335
At time: 1228.639996290207 and batch: 700, loss is 4.017426314353943 and perplexity is 55.557933010200884
At time: 1229.839971780777 and batch: 750, loss is 3.9691855239868166 and perplexity is 52.94139377967245
At time: 1231.0364127159119 and batch: 800, loss is 3.937587513923645 and perplexity is 51.29470415098886
At time: 1232.2378137111664 and batch: 850, loss is 3.9093815898895263 and perplexity is 49.86810349649359
At time: 1233.4402136802673 and batch: 900, loss is 3.9212366580963134 and perplexity is 50.46281145133556
At time: 1234.6386597156525 and batch: 950, loss is 3.9102723884582518 and perplexity is 49.912545723310515
At time: 1235.8345184326172 and batch: 1000, loss is 3.925650339126587 and perplexity is 50.68603045133602
At time: 1237.03782248497 and batch: 1050, loss is 3.8558157157897948 and perplexity is 47.26715778689499
At time: 1238.2409014701843 and batch: 1100, loss is 3.8198260116577147 and perplexity is 45.59627441046573
At time: 1239.4659821987152 and batch: 1150, loss is 3.8398657131195066 and perplexity is 46.519227098440595
At time: 1240.6671960353851 and batch: 1200, loss is 3.8099246883392333 and perplexity is 45.14703863982331
At time: 1241.8639013767242 and batch: 1250, loss is 3.8420131826400756 and perplexity is 46.61923306220195
At time: 1243.0614643096924 and batch: 1300, loss is 3.815775303840637 and perplexity is 45.4119507978662
At time: 1244.2580780982971 and batch: 1350, loss is 3.7931935596466064 and perplexity is 44.3979616520446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599901123046875 and perplexity of 99.47447942221514
Finished 36 epochs...
Completing Train Step...
At time: 1247.7199065685272 and batch: 50, loss is 4.09241813659668 and perplexity is 59.88452572448801
At time: 1248.8917019367218 and batch: 100, loss is 4.087037620544433 and perplexity is 59.56318134707836
At time: 1250.0653896331787 and batch: 150, loss is 4.062092266082764 and perplexity is 58.09573574576188
At time: 1251.2552382946014 and batch: 200, loss is 4.046476101875305 and perplexity is 57.19555021269362
At time: 1252.4507339000702 and batch: 250, loss is 4.053025646209717 and perplexity is 57.57138443248747
At time: 1253.6458010673523 and batch: 300, loss is 4.037903594970703 and perplexity is 56.707336560845135
At time: 1254.8414783477783 and batch: 350, loss is 4.04856285572052 and perplexity is 57.315027863897306
At time: 1256.0414032936096 and batch: 400, loss is 4.0529841041564945 and perplexity is 57.56899284864729
At time: 1257.2375943660736 and batch: 450, loss is 3.9845637464523316 and perplexity is 53.76183057193017
At time: 1258.4368586540222 and batch: 500, loss is 4.060999684333801 and perplexity is 58.03229606802138
At time: 1259.638920545578 and batch: 550, loss is 4.0512185335159305 and perplexity is 57.46744040045766
At time: 1260.8367793560028 and batch: 600, loss is 4.002764744758606 and perplexity is 54.74930884375683
At time: 1262.0337462425232 and batch: 650, loss is 4.010866022109985 and perplexity is 55.19464965855846
At time: 1263.229662179947 and batch: 700, loss is 4.017192759513855 and perplexity is 55.544958701206355
At time: 1264.4254534244537 and batch: 750, loss is 3.968983111381531 and perplexity is 52.93067885868417
At time: 1265.6218235492706 and batch: 800, loss is 3.9374113416671754 and perplexity is 51.285668243175145
At time: 1266.82363820076 and batch: 850, loss is 3.909211611747742 and perplexity is 49.85962772929493
At time: 1268.0193500518799 and batch: 900, loss is 3.921096739768982 and perplexity is 50.45575127310054
At time: 1269.2612235546112 and batch: 950, loss is 3.9101674795150756 and perplexity is 49.90730972554375
At time: 1270.4564054012299 and batch: 1000, loss is 3.925560779571533 and perplexity is 50.68149123626943
At time: 1271.6525373458862 and batch: 1050, loss is 3.855741791725159 and perplexity is 47.26366373561642
At time: 1272.8485941886902 and batch: 1100, loss is 3.819790077209473 and perplexity is 45.59463596294144
At time: 1274.0435512065887 and batch: 1150, loss is 3.8398544073104857 and perplexity is 46.518701163916276
At time: 1275.2466080188751 and batch: 1200, loss is 3.8099254417419433 and perplexity is 45.14707265373738
At time: 1276.4468178749084 and batch: 1250, loss is 3.842042098045349 and perplexity is 46.62058109570884
At time: 1277.6472578048706 and batch: 1300, loss is 3.815815691947937 and perplexity is 45.413784937646184
At time: 1278.8488252162933 and batch: 1350, loss is 3.7932430505752563 and perplexity is 44.400159002770934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599901936848958 and perplexity of 99.47456037478668
Annealing...
Finished 37 epochs...
Completing Train Step...
At time: 1282.3204567432404 and batch: 50, loss is 4.092419033050537 and perplexity is 59.884579408226124
At time: 1283.4845788478851 and batch: 100, loss is 4.08751811504364 and perplexity is 59.59180800499594
At time: 1284.670972585678 and batch: 150, loss is 4.062875080108642 and perplexity is 58.14123170766264
At time: 1285.8656914234161 and batch: 200, loss is 4.0472481822967525 and perplexity is 57.23972682896252
At time: 1287.0685918331146 and batch: 250, loss is 4.053658018112182 and perplexity is 57.607802472047496
At time: 1288.267211675644 and batch: 300, loss is 4.038569145202636 and perplexity is 56.74509070409131
At time: 1289.4753460884094 and batch: 350, loss is 4.04897572517395 and perplexity is 57.33869637379096
At time: 1290.6829943656921 and batch: 400, loss is 4.053483290672302 and perplexity is 57.59773768752705
At time: 1291.88601064682 and batch: 450, loss is 3.9851576471328736 and perplexity is 53.79376924295447
At time: 1293.087067604065 and batch: 500, loss is 4.061431217193603 and perplexity is 58.057344314886606
At time: 1294.2914009094238 and batch: 550, loss is 4.051322736740112 and perplexity is 57.4734290050434
At time: 1295.4954164028168 and batch: 600, loss is 4.002992868423462 and perplexity is 54.76179988143508
At time: 1296.6930921077728 and batch: 650, loss is 4.010814747810364 and perplexity is 55.19181966410799
At time: 1297.891078710556 and batch: 700, loss is 4.016928286552429 and perplexity is 55.5302705038875
At time: 1299.1007924079895 and batch: 750, loss is 3.9689669179916383 and perplexity is 52.92982173850399
At time: 1300.332534313202 and batch: 800, loss is 3.9373476028442385 and perplexity is 51.282399459223114
At time: 1301.5319018363953 and batch: 850, loss is 3.90887375831604 and perplexity is 49.84278532825491
At time: 1302.732186794281 and batch: 900, loss is 3.920012707710266 and perplexity is 50.40108525638451
At time: 1303.938956975937 and batch: 950, loss is 3.9091239547729493 and perplexity is 49.855257376712636
At time: 1305.1356766223907 and batch: 1000, loss is 3.924212818145752 and perplexity is 50.61322056453519
At time: 1306.3316304683685 and batch: 1050, loss is 3.8541861057281492 and perplexity is 47.1901934789178
At time: 1307.5324902534485 and batch: 1100, loss is 3.8179324436187745 and perplexity is 45.51001645597407
At time: 1308.7311532497406 and batch: 1150, loss is 3.8377870893478394 and perplexity is 46.42263155483062
At time: 1309.9272356033325 and batch: 1200, loss is 3.807639117240906 and perplexity is 45.04396970369176
At time: 1311.1234800815582 and batch: 1250, loss is 3.839912300109863 and perplexity is 46.52139433970706
At time: 1312.3198246955872 and batch: 1300, loss is 3.8137168312072753 and perplexity is 45.31856768618555
At time: 1313.516697883606 and batch: 1350, loss is 3.791625962257385 and perplexity is 44.32841804570113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.59994384765625 and perplexity of 99.47872952128247
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 1316.9510927200317 and batch: 50, loss is 4.0923810482025145 and perplexity is 59.88230474478006
At time: 1318.1588668823242 and batch: 100, loss is 4.087552618980408 and perplexity is 59.59386419244432
At time: 1319.3499093055725 and batch: 150, loss is 4.062959651947022 and perplexity is 58.14614902644422
At time: 1320.5491907596588 and batch: 200, loss is 4.047317366600037 and perplexity is 57.243687056574586
At time: 1321.7461230754852 and batch: 250, loss is 4.053675527572632 and perplexity is 57.60881116241725
At time: 1322.9435255527496 and batch: 300, loss is 4.038596301078797 and perplexity is 56.74663168767045
At time: 1324.1409747600555 and batch: 350, loss is 4.048955445289612 and perplexity is 57.337533563451274
At time: 1325.3380658626556 and batch: 400, loss is 4.053448581695557 and perplexity is 57.59573856368305
At time: 1326.5352568626404 and batch: 450, loss is 3.9851470804214477 and perplexity is 53.79320082272154
At time: 1327.7329335212708 and batch: 500, loss is 4.061408925056457 and perplexity is 58.05605010703019
At time: 1328.935694694519 and batch: 550, loss is 4.051277589797974 and perplexity is 57.47083431404123
At time: 1330.1638383865356 and batch: 600, loss is 4.002932367324829 and perplexity is 54.758486832601676
At time: 1331.3611941337585 and batch: 650, loss is 4.010771284103393 and perplexity is 55.18942087516145
At time: 1332.5694870948792 and batch: 700, loss is 4.016869015693665 and perplexity is 55.52697927460529
At time: 1333.7672848701477 and batch: 750, loss is 3.968938956260681 and perplexity is 52.92834174976054
At time: 1334.9648931026459 and batch: 800, loss is 3.9373289012908934 and perplexity is 51.281440407661876
At time: 1336.163562297821 and batch: 850, loss is 3.9087920141220094 and perplexity is 49.83871113646304
At time: 1337.3611567020416 and batch: 900, loss is 3.9198160934448243 and perplexity is 50.39117665814715
At time: 1338.5598046779633 and batch: 950, loss is 3.9089110279083252 and perplexity is 49.84464298315926
At time: 1339.7576801776886 and batch: 1000, loss is 3.923965334892273 and perplexity is 50.60069618989125
At time: 1340.9572451114655 and batch: 1050, loss is 3.853937258720398 and perplexity is 47.17845180147661
At time: 1342.1558237075806 and batch: 1100, loss is 3.8176166009902954 and perplexity is 45.495644722477
At time: 1343.3539505004883 and batch: 1150, loss is 3.8374439239501954 and perplexity is 46.40670364712313
At time: 1344.5520296096802 and batch: 1200, loss is 3.8072543954849243 and perplexity is 45.026643641641186
At time: 1345.7499697208405 and batch: 1250, loss is 3.8395442533493043 and perplexity is 46.50427544169436
At time: 1346.9476463794708 and batch: 1300, loss is 3.813356652259827 and perplexity is 45.30224783138696
At time: 1348.145497560501 and batch: 1350, loss is 3.7913413667678832 and perplexity is 44.31580417287935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599951578776042 and perplexity of 99.47949860623014
Annealing...
Finished 39 epochs...
Completing Train Step...
At time: 1351.5940735340118 and batch: 50, loss is 4.092373476028443 and perplexity is 59.88185130726146
At time: 1352.7937052249908 and batch: 100, loss is 4.087557392120361 and perplexity is 59.59414864297734
At time: 1353.9720015525818 and batch: 150, loss is 4.062973728179932 and perplexity is 58.14696751094131
At time: 1355.144897699356 and batch: 200, loss is 4.047328896522522 and perplexity is 57.2443470756541
At time: 1356.3260889053345 and batch: 250, loss is 4.0536779069900515 and perplexity is 57.608948237989125
At time: 1357.525508403778 and batch: 300, loss is 4.0386006546020505 and perplexity is 56.74687873598885
At time: 1358.7227048873901 and batch: 350, loss is 4.04895058631897 and perplexity is 57.33725496273587
At time: 1359.921710729599 and batch: 400, loss is 4.0534412288665775 and perplexity is 57.59531507362437
At time: 1361.1532196998596 and batch: 450, loss is 3.9851439809799194 and perplexity is 53.793034094099355
At time: 1362.3510477542877 and batch: 500, loss is 4.0614035987854 and perplexity is 58.05574088559431
At time: 1363.549216747284 and batch: 550, loss is 4.051268630027771 and perplexity is 57.4703193908792
At time: 1364.7470481395721 and batch: 600, loss is 4.0029207134246825 and perplexity is 54.757848686382424
At time: 1365.9453883171082 and batch: 650, loss is 4.01076301574707 and perplexity is 55.18896455125091
At time: 1367.1433169841766 and batch: 700, loss is 4.016857657432556 and perplexity is 55.526348588257875
At time: 1368.3419036865234 and batch: 750, loss is 3.9689329433441163 and perplexity is 52.92802349701451
At time: 1369.5403327941895 and batch: 800, loss is 3.937325129508972 and perplexity is 51.28124698561681
At time: 1370.7446427345276 and batch: 850, loss is 3.908777265548706 and perplexity is 49.83797609199893
At time: 1371.9424126148224 and batch: 900, loss is 3.9197809648513795 and perplexity is 50.38940651808058
At time: 1373.1477839946747 and batch: 950, loss is 3.9088728713989256 and perplexity is 49.84274112185518
At time: 1374.3450593948364 and batch: 1000, loss is 3.923921127319336 and perplexity is 50.59845930536776
At time: 1375.5437042713165 and batch: 1050, loss is 3.853893208503723 and perplexity is 47.17637362622473
At time: 1376.7422676086426 and batch: 1100, loss is 3.8175603771209716 and perplexity is 45.49308685320065
At time: 1377.9495868682861 and batch: 1150, loss is 3.837383279800415 and perplexity is 46.40388943736987
At time: 1379.1476922035217 and batch: 1200, loss is 3.8071864318847655 and perplexity is 45.02358357282406
At time: 1380.3517739772797 and batch: 1250, loss is 3.839479088783264 and perplexity is 46.501245109502406
At time: 1381.55038189888 and batch: 1300, loss is 3.8132928562164308 and perplexity is 45.29935781940502
At time: 1382.7487094402313 and batch: 1350, loss is 3.7912908172607422 and perplexity is 44.313564087437946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.599954020182292 and perplexity of 99.47974147639621
Annealing...
Finished 40 epochs...
Completing Train Step...
At time: 1386.2327806949615 and batch: 50, loss is 4.09237277507782 and perplexity is 59.8818093330552
At time: 1387.4073948860168 and batch: 100, loss is 4.08755889415741 and perplexity is 59.5942381556637
At time: 1388.594756603241 and batch: 150, loss is 4.062977027893067 and perplexity is 58.147159379570304
At time: 1389.7864334583282 and batch: 200, loss is 4.047331657409668 and perplexity is 57.24450512105427
At time: 1391.0113701820374 and batch: 250, loss is 4.053679084777832 and perplexity is 57.60901608914435
At time: 1392.2102267742157 and batch: 300, loss is 4.038602142333985 and perplexity is 56.74696316019531
At time: 1393.4108719825745 and batch: 350, loss is 4.048950252532959 and perplexity is 57.33723582436543
At time: 1394.6162297725677 and batch: 400, loss is 4.053440704345703 and perplexity is 57.595284863687255
At time: 1395.8225195407867 and batch: 450, loss is 3.9851440382003784 and perplexity is 53.79303717216155
At time: 1397.0192625522614 and batch: 500, loss is 4.061403388977051 and perplexity is 58.05572870501642
At time: 1398.2259488105774 and batch: 550, loss is 4.05126793384552 and perplexity is 57.47027938107683
At time: 1399.4291985034943 and batch: 600, loss is 4.002919187545777 and perplexity is 54.75776513259993
At time: 1400.6294643878937 and batch: 650, loss is 4.0107621717453 and perplexity is 55.18891797168681
At time: 1401.8280353546143 and batch: 700, loss is 4.016856408119201 and perplexity is 55.52627921849236
At time: 1403.0329587459564 and batch: 750, loss is 3.9689326381683347 and perplexity is 52.928007344666035
At time: 1404.2288916110992 and batch: 800, loss is 3.9373252487182615 and perplexity is 51.2812530988182
At time: 1405.4316337108612 and batch: 850, loss is 3.9087754344940184 and perplexity is 49.837884836022745
At time: 1406.6281623840332 and batch: 900, loss is 3.919775586128235 and perplexity is 50.38913548814239
At time: 1407.8281574249268 and batch: 950, loss is 3.9088669538497927 and perplexity is 49.84244617585835
At time: 1409.0275745391846 and batch: 1000, loss is 3.9239143180847167 and perplexity is 50.59811476975999
At time: 1410.2247812747955 and batch: 1050, loss is 3.8538864994049074 and perplexity is 47.17605711633406
At time: 1411.4250757694244 and batch: 1100, loss is 3.8175516271591188 and perplexity is 45.49268879216763
At time: 1412.6287364959717 and batch: 1150, loss is 3.83737380027771 and perplexity is 46.4034495527313
At time: 1413.8264634609222 and batch: 1200, loss is 3.8071755838394163 and perplexity is 45.02309515759686
At time: 1415.0229358673096 and batch: 1250, loss is 3.839468593597412 and perplexity is 46.50075707285366
At time: 1416.2266380786896 and batch: 1300, loss is 3.8132826232910157 and perplexity is 45.29889427682681
At time: 1417.427500486374 and batch: 1350, loss is 3.79128306388855 and perplexity is 44.313220509214354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.59995361328125 and perplexity of 99.47970099799402
Annealing...
Model not improving. Stopping early with 99.47447942221514loss at 40 epochs.
Finished Training.
Improved accuracyfrom -10000000 to -99.47447942221514
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77d2aa7860>
SETTINGS FOR THIS RUN
{'dropout': 0.012553500039072074, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 8.76493760953503, 'wordvec_source': '', 'anneal': 4.189047699677582, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5590178966522217 and batch: 50, loss is 7.022768039703369 and perplexity is 1121.8877535774734
At time: 2.641763210296631 and batch: 100, loss is 6.000678949356079 and perplexity is 403.7027942180831
At time: 3.759704351425171 and batch: 150, loss is 5.7131374740600585 and perplexity is 302.81966825476457
At time: 4.847636461257935 and batch: 200, loss is 5.597021627426147 and perplexity is 269.6221750773232
At time: 5.937704563140869 and batch: 250, loss is 5.576538219451904 and perplexity is 264.1555725253315
At time: 7.027333736419678 and batch: 300, loss is 5.509629468917847 and perplexity is 247.05956685705556
At time: 8.119646310806274 and batch: 350, loss is 5.477770690917969 and perplexity is 239.31261048592947
At time: 9.201195240020752 and batch: 400, loss is 5.477875747680664 and perplexity is 239.33775321474306
At time: 10.288533926010132 and batch: 450, loss is 5.429853763580322 and perplexity is 228.11588413457818
At time: 11.37086272239685 and batch: 500, loss is 5.440438261032105 and perplexity is 230.5431994238693
At time: 12.461249113082886 and batch: 550, loss is 5.401295957565307 and perplexity is 221.69353553132166
At time: 13.542564153671265 and batch: 600, loss is 5.335910625457764 and perplexity is 207.66176482313207
At time: 14.626575231552124 and batch: 650, loss is 5.351630449295044 and perplexity is 210.9519641065183
At time: 15.72589111328125 and batch: 700, loss is 5.352713575363159 and perplexity is 211.18057546307224
At time: 16.83885645866394 and batch: 750, loss is 5.311179552078247 and perplexity is 202.58905184523874
At time: 18.002867460250854 and batch: 800, loss is 5.245906343460083 and perplexity is 189.78775018787405
At time: 19.212573051452637 and batch: 850, loss is 5.2452625560760495 and perplexity is 189.66560655014413
At time: 20.42613673210144 and batch: 900, loss is 5.285323123931885 and perplexity is 197.41796361178066
At time: 21.63723111152649 and batch: 950, loss is 5.234714956283569 and perplexity is 187.6756029678072
At time: 22.84427285194397 and batch: 1000, loss is 5.257323808670044 and perplexity is 191.9670626608155
At time: 24.05037212371826 and batch: 1050, loss is 5.193915500640869 and perplexity is 180.1726396923961
At time: 25.256165504455566 and batch: 1100, loss is 5.173294973373413 and perplexity is 176.4954281797231
At time: 26.46198010444641 and batch: 1150, loss is 5.174781007766724 and perplexity is 176.7579014300973
At time: 27.670112133026123 and batch: 1200, loss is 5.152569789886474 and perplexity is 172.8751728580672
At time: 28.880778074264526 and batch: 1250, loss is 5.191086349487304 and perplexity is 179.66362444102958
At time: 30.088199615478516 and batch: 1300, loss is 5.159857959747314 and perplexity is 174.13971899866624
At time: 31.298015356063843 and batch: 1350, loss is 5.11443832397461 and perplexity is 166.4072877453446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.945307210286458 and perplexity of 140.51401157114432
Finished 1 epochs...
Completing Train Step...
At time: 34.82590365409851 and batch: 50, loss is 5.151509456634521 and perplexity is 172.6919647118586
At time: 36.023690938949585 and batch: 100, loss is 5.132354564666748 and perplexity is 169.4155486603619
At time: 37.25398278236389 and batch: 150, loss is 5.0586190605163575 and perplexity is 157.37304355005796
At time: 38.45221400260925 and batch: 200, loss is 5.038352975845337 and perplexity is 154.21580857951596
At time: 39.64986801147461 and batch: 250, loss is 5.0455837821960445 and perplexity is 155.33495451517487
At time: 40.85275340080261 and batch: 300, loss is 5.025828266143799 and perplexity is 152.29634579459986
At time: 42.05206298828125 and batch: 350, loss is 5.023678283691407 and perplexity is 151.96926306064015
At time: 43.250863552093506 and batch: 400, loss is 5.038827772140503 and perplexity is 154.2890470593892
At time: 44.449339628219604 and batch: 450, loss is 5.005053949356079 and perplexity is 149.16513030404616
At time: 45.64673709869385 and batch: 500, loss is 5.046952686309814 and perplexity is 155.54773878082324
At time: 46.84398126602173 and batch: 550, loss is 5.023066253662109 and perplexity is 151.87628176469187
At time: 48.04822111129761 and batch: 600, loss is 4.961772117614746 and perplexity is 142.84671290760807
At time: 49.253047466278076 and batch: 650, loss is 4.9911771011352535 and perplexity is 147.10948436169028
At time: 50.46237754821777 and batch: 700, loss is 4.992076425552368 and perplexity is 147.2418430207321
At time: 51.66772198677063 and batch: 750, loss is 4.946642560958862 and perplexity is 140.7017723863428
At time: 52.87499213218689 and batch: 800, loss is 4.899325742721557 and perplexity is 134.19926434230592
At time: 54.07763457298279 and batch: 850, loss is 4.8899706268310545 and perplexity is 132.94966884084477
At time: 55.277037382125854 and batch: 900, loss is 4.9335704517364505 and perplexity is 138.87447280048383
At time: 56.47573256492615 and batch: 950, loss is 4.8929143905639645 and perplexity is 133.34161787391102
At time: 57.67519497871399 and batch: 1000, loss is 4.908450527191162 and perplexity is 135.42940756599515
At time: 58.88078308105469 and batch: 1050, loss is 4.849519376754761 and perplexity is 127.67900959688176
At time: 60.08385515213013 and batch: 1100, loss is 4.826532278060913 and perplexity is 124.77751582690921
At time: 61.282063484191895 and batch: 1150, loss is 4.844665231704712 and perplexity is 127.06073896612413
At time: 62.483084201812744 and batch: 1200, loss is 4.8221781539916995 and perplexity is 124.23540011794901
At time: 63.691699266433716 and batch: 1250, loss is 4.87219687461853 and perplexity is 130.6075303226604
At time: 64.8919186592102 and batch: 1300, loss is 4.855006628036499 and perplexity is 128.38154212944715
At time: 66.09553241729736 and batch: 1350, loss is 4.814074592590332 and perplexity is 123.23271905562159
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.842422688802083 and perplexity of 126.77611906320384
Finished 2 epochs...
Completing Train Step...
At time: 69.56151032447815 and batch: 50, loss is 4.882932348251343 and perplexity is 132.01721731054147
At time: 70.78446316719055 and batch: 100, loss is 4.878521966934204 and perplexity is 131.43625312029636
At time: 71.98890018463135 and batch: 150, loss is 4.8159455299377445 and perplexity is 123.46349556900721
At time: 73.19211053848267 and batch: 200, loss is 4.797685756683349 and perplexity is 121.22953798424084
At time: 74.389643907547 and batch: 250, loss is 4.804530124664307 and perplexity is 122.06212356317612
At time: 75.59152603149414 and batch: 300, loss is 4.790753316879273 and perplexity is 120.39202785809263
At time: 76.7960102558136 and batch: 350, loss is 4.78920464515686 and perplexity is 120.20572442760779
At time: 77.99291753768921 and batch: 400, loss is 4.807952718734741 and perplexity is 122.48060840686422
At time: 79.19844222068787 and batch: 450, loss is 4.767195587158203 and perplexity is 117.58901099263642
At time: 80.39936065673828 and batch: 500, loss is 4.825114068984985 and perplexity is 124.60068064576043
At time: 81.59704065322876 and batch: 550, loss is 4.807234592437744 and perplexity is 122.39268343549075
At time: 82.79745125770569 and batch: 600, loss is 4.7483362865448 and perplexity is 115.39214527445928
At time: 83.99999499320984 and batch: 650, loss is 4.774591083526611 and perplexity is 118.4618637076718
At time: 85.19745302200317 and batch: 700, loss is 4.782134370803833 and perplexity is 119.35883437751446
At time: 86.4000449180603 and batch: 750, loss is 4.737299509048462 and perplexity is 114.12559004299155
At time: 87.60152411460876 and batch: 800, loss is 4.701496992111206 and perplexity is 110.11188575843383
At time: 88.79932570457458 and batch: 850, loss is 4.683314685821533 and perplexity is 108.12788920017644
At time: 89.9964644908905 and batch: 900, loss is 4.733241167068481 and perplexity is 113.66336793203352
At time: 91.19651913642883 and batch: 950, loss is 4.690493717193603 and perplexity is 108.90693576289307
At time: 92.39762353897095 and batch: 1000, loss is 4.70604681968689 and perplexity is 110.61401729240244
At time: 93.65745067596436 and batch: 1050, loss is 4.64235897064209 and perplexity is 103.78889398487223
At time: 94.85976600646973 and batch: 1100, loss is 4.625115613937378 and perplexity is 102.0145667066598
At time: 96.05644369125366 and batch: 1150, loss is 4.640168523788452 and perplexity is 103.56179873943472
At time: 97.25797486305237 and batch: 1200, loss is 4.614914131164551 and perplexity is 100.97915719755437
At time: 98.45510911941528 and batch: 1250, loss is 4.670682506561279 and perplexity is 106.77058919810467
At time: 99.66180920600891 and batch: 1300, loss is 4.661803722381592 and perplexity is 105.82679226468935
At time: 100.86443662643433 and batch: 1350, loss is 4.6230105209350585 and perplexity is 101.800042432146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.790367838541667 and perplexity of 120.34562828292303
Finished 3 epochs...
Completing Train Step...
At time: 104.40056538581848 and batch: 50, loss is 4.698694171905518 and perplexity is 109.80369404488235
At time: 105.60092282295227 and batch: 100, loss is 4.696744537353515 and perplexity is 109.58982551951242
At time: 106.80931329727173 and batch: 150, loss is 4.651017017364502 and perplexity is 104.69140442924997
At time: 108.01824879646301 and batch: 200, loss is 4.632689437866211 and perplexity is 102.79014039493136
At time: 109.22696995735168 and batch: 250, loss is 4.633431415557862 and perplexity is 102.86643668759933
At time: 110.4268147945404 and batch: 300, loss is 4.6258664894104005 and perplexity is 102.09119570850945
At time: 111.63659501075745 and batch: 350, loss is 4.630401487350464 and perplexity is 102.55523047381259
At time: 112.83548164367676 and batch: 400, loss is 4.6482695293426515 and perplexity is 104.40416082945748
At time: 114.04081463813782 and batch: 450, loss is 4.593421506881714 and perplexity is 98.83200671347716
At time: 115.24233913421631 and batch: 500, loss is 4.665354785919189 and perplexity is 106.20325795919757
At time: 116.44915676116943 and batch: 550, loss is 4.654564924240113 and perplexity is 105.06349947180519
At time: 117.65159869194031 and batch: 600, loss is 4.5922157669067385 and perplexity is 98.71291282473523
At time: 118.85878777503967 and batch: 650, loss is 4.622461318969727 and perplexity is 101.74414899856806
At time: 120.06293392181396 and batch: 700, loss is 4.627680921554566 and perplexity is 102.276601407804
At time: 121.26440930366516 and batch: 750, loss is 4.579646434783935 and perplexity is 97.47992260353585
At time: 122.46983671188354 and batch: 800, loss is 4.5465250587463375 and perplexity is 94.30413694752453
At time: 123.69758200645447 and batch: 850, loss is 4.538652572631836 and perplexity is 93.56464358371936
At time: 124.89605760574341 and batch: 900, loss is 4.580956926345825 and perplexity is 97.60775296156973
At time: 126.09461045265198 and batch: 950, loss is 4.549150562286377 and perplexity is 94.55205810944913
At time: 127.2931878566742 and batch: 1000, loss is 4.560952110290527 and perplexity is 95.67452918245144
At time: 128.49489569664001 and batch: 1050, loss is 4.5035164928436275 and perplexity is 90.33423311490847
At time: 129.70218110084534 and batch: 1100, loss is 4.475996389389038 and perplexity is 87.88212161337633
At time: 130.9010045528412 and batch: 1150, loss is 4.497124195098877 and perplexity is 89.7586314688391
At time: 132.0982255935669 and batch: 1200, loss is 4.476184511184693 and perplexity is 87.89865571106353
At time: 133.29896450042725 and batch: 1250, loss is 4.528141021728516 and perplexity is 92.5862851108222
At time: 134.50309896469116 and batch: 1300, loss is 4.5189298820495605 and perplexity is 91.73737562039838
At time: 135.70407676696777 and batch: 1350, loss is 4.489212141036988 and perplexity is 89.05125840127369
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.777525227864583 and perplexity of 118.80995834455442
Finished 4 epochs...
Completing Train Step...
At time: 139.18159127235413 and batch: 50, loss is 4.571182012557983 and perplexity is 96.65829359305583
At time: 140.35598492622375 and batch: 100, loss is 4.562584285736084 and perplexity is 95.83081430742472
At time: 141.55170965194702 and batch: 150, loss is 4.523846015930176 and perplexity is 92.18947923119354
At time: 142.74922442436218 and batch: 200, loss is 4.513299856185913 and perplexity is 91.222343006883
At time: 143.9458086490631 and batch: 250, loss is 4.507857570648193 and perplexity is 90.72723345462937
At time: 145.14407992362976 and batch: 300, loss is 4.501072416305542 and perplexity is 90.1137189217196
At time: 146.34422540664673 and batch: 350, loss is 4.511993360519409 and perplexity is 91.10323923228069
At time: 147.5440764427185 and batch: 400, loss is 4.520512437820434 and perplexity is 91.88267007155338
At time: 148.74387979507446 and batch: 450, loss is 4.473158340454102 and perplexity is 87.63306144138122
At time: 149.9447181224823 and batch: 500, loss is 4.540274782180786 and perplexity is 93.71654821924788
At time: 151.14889788627625 and batch: 550, loss is 4.530316247940063 and perplexity is 92.78790042498603
At time: 152.34857082366943 and batch: 600, loss is 4.469279527664185 and perplexity is 87.29380757829911
At time: 153.54766726493835 and batch: 650, loss is 4.492230119705201 and perplexity is 89.3204191559168
At time: 154.79492735862732 and batch: 700, loss is 4.518352775573731 and perplexity is 91.68444866056682
At time: 156.00490951538086 and batch: 750, loss is 4.463330917358398 and perplexity is 86.77607216472893
At time: 157.20713472366333 and batch: 800, loss is 4.428894586563111 and perplexity is 83.83868925487947
At time: 158.4100296497345 and batch: 850, loss is 4.426020622253418 and perplexity is 83.59808576272293
At time: 159.61292028427124 and batch: 900, loss is 4.459790620803833 and perplexity is 86.46940230685499
At time: 160.81733107566833 and batch: 950, loss is 4.4343670463562015 and perplexity is 84.29875079692519
At time: 162.01878547668457 and batch: 1000, loss is 4.446492118835449 and perplexity is 85.32710107230987
At time: 163.21880865097046 and batch: 1050, loss is 4.384297676086426 and perplexity is 80.18188977443202
At time: 164.41901564598083 and batch: 1100, loss is 4.3670731544494625 and perplexity is 78.81262142842935
At time: 165.62138438224792 and batch: 1150, loss is 4.380465536117554 and perplexity is 79.87520954593579
At time: 166.82789874076843 and batch: 1200, loss is 4.362347393035889 and perplexity is 78.44105045258905
At time: 168.03783702850342 and batch: 1250, loss is 4.41865816116333 and perplexity is 82.98485831075591
At time: 169.24728536605835 and batch: 1300, loss is 4.413600559234619 and perplexity is 82.56621349311588
At time: 170.45899963378906 and batch: 1350, loss is 4.378869152069091 and perplexity is 79.74779976008197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765926106770833 and perplexity of 117.43982876140434
Finished 5 epochs...
Completing Train Step...
At time: 173.91089153289795 and batch: 50, loss is 4.46143367767334 and perplexity is 86.61159323421877
At time: 175.11161160469055 and batch: 100, loss is 4.4583769702911376 and perplexity is 86.34725115181521
At time: 176.28726744651794 and batch: 150, loss is 4.413837251663208 and perplexity is 82.58575860370551
At time: 177.47148323059082 and batch: 200, loss is 4.403259420394898 and perplexity is 81.71678441767062
At time: 178.67153358459473 and batch: 250, loss is 4.408641958236695 and perplexity is 82.1578139664452
At time: 179.87967681884766 and batch: 300, loss is 4.404051074981689 and perplexity is 81.78150149827962
At time: 181.0787992477417 and batch: 350, loss is 4.414104166030884 and perplexity is 82.60780487134421
At time: 182.2837405204773 and batch: 400, loss is 4.4267418098449705 and perplexity is 83.65839741024439
At time: 183.48911428451538 and batch: 450, loss is 4.385286588668823 and perplexity is 80.26122187390077
At time: 184.71454906463623 and batch: 500, loss is 4.445301656723022 and perplexity is 85.2255828301199
At time: 185.91295886039734 and batch: 550, loss is 4.434785537719726 and perplexity is 84.33403647895125
At time: 187.112154006958 and batch: 600, loss is 4.38039722442627 and perplexity is 79.86975332164411
At time: 188.31070733070374 and batch: 650, loss is 4.398807144165039 and perplexity is 81.35376744640983
At time: 189.50975036621094 and batch: 700, loss is 4.425323867797852 and perplexity is 83.53985871132532
At time: 190.7222089767456 and batch: 750, loss is 4.370718240737915 and perplexity is 79.10042444891546
At time: 191.93100094795227 and batch: 800, loss is 4.340253629684448 and perplexity is 76.72699711472332
At time: 193.1396403312683 and batch: 850, loss is 4.340881500244141 and perplexity is 76.77518686422464
At time: 194.3397936820984 and batch: 900, loss is 4.3690948486328125 and perplexity is 78.97211761868078
At time: 195.5401554107666 and batch: 950, loss is 4.347610931396485 and perplexity is 77.29358249598803
At time: 196.74153518676758 and batch: 1000, loss is 4.3497818756103515 and perplexity is 77.4615648258352
At time: 197.94865441322327 and batch: 1050, loss is 4.2908040809631345 and perplexity is 73.02516304232032
At time: 199.15773129463196 and batch: 1100, loss is 4.270273847579956 and perplexity is 71.54122432808589
At time: 200.35945296287537 and batch: 1150, loss is 4.2917548942565915 and perplexity is 73.09462935761245
At time: 201.5616602897644 and batch: 1200, loss is 4.276829843521118 and perplexity is 72.01178912942288
At time: 202.7672634124756 and batch: 1250, loss is 4.328673105239869 and perplexity is 75.84358331935928
At time: 203.97159504890442 and batch: 1300, loss is 4.320718679428101 and perplexity is 75.24268423452394
At time: 205.17641592025757 and batch: 1350, loss is 4.293883638381958 and perplexity is 73.25039485407446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7686962890625 and perplexity of 117.76560952308976
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 208.65031123161316 and batch: 50, loss is 4.371509952545166 and perplexity is 79.16307398582684
At time: 209.84588027000427 and batch: 100, loss is 4.372510213851928 and perplexity is 79.24229736109226
At time: 211.02297592163086 and batch: 150, loss is 4.323085994720459 and perplexity is 75.4210183948581
At time: 212.2044279575348 and batch: 200, loss is 4.304568967819214 and perplexity is 74.03729611700747
At time: 213.3926980495453 and batch: 250, loss is 4.2928180980682376 and perplexity is 73.17238517397186
At time: 214.61963152885437 and batch: 300, loss is 4.279430027008057 and perplexity is 72.19927663971337
At time: 215.8190450668335 and batch: 350, loss is 4.278748235702515 and perplexity is 72.15006857735469
At time: 217.02163887023926 and batch: 400, loss is 4.278266324996948 and perplexity is 72.11530706354546
At time: 218.22169733047485 and batch: 450, loss is 4.215376672744751 and perplexity is 67.71966922110099
At time: 219.43047285079956 and batch: 500, loss is 4.272307615280152 and perplexity is 71.68687061451132
At time: 220.62981939315796 and batch: 550, loss is 4.2521484756469725 and perplexity is 70.25619403522857
At time: 221.8387598991394 and batch: 600, loss is 4.187048707008362 and perplexity is 65.82822561106016
At time: 223.04542016983032 and batch: 650, loss is 4.192289390563965 and perplexity is 66.17411607008526
At time: 224.24770617485046 and batch: 700, loss is 4.204794840812683 and perplexity is 67.00684918531582
At time: 225.44554090499878 and batch: 750, loss is 4.134778156280517 and perplexity is 62.475729684741026
At time: 226.64922785758972 and batch: 800, loss is 4.101318216323852 and perplexity is 60.41988159898902
At time: 227.85299611091614 and batch: 850, loss is 4.092659106254578 and perplexity is 59.898957816943565
At time: 229.06173276901245 and batch: 900, loss is 4.109438586235046 and perplexity is 60.91251084641096
At time: 230.2604022026062 and batch: 950, loss is 4.076442704200745 and perplexity is 58.93544569893188
At time: 231.4582097530365 and batch: 1000, loss is 4.068846893310547 and perplexity is 58.48947908193447
At time: 232.65686774253845 and batch: 1050, loss is 3.993163924217224 and perplexity is 54.22618577838487
At time: 233.85493993759155 and batch: 1100, loss is 3.956811647415161 and perplexity is 52.29033984506309
At time: 235.05234551429749 and batch: 1150, loss is 3.968877992630005 and perplexity is 52.925115144235605
At time: 236.25033903121948 and batch: 1200, loss is 3.9321058702468874 and perplexity is 51.01429411643098
At time: 237.44851064682007 and batch: 1250, loss is 3.971413984298706 and perplexity is 53.05950312668478
At time: 238.64615964889526 and batch: 1300, loss is 3.94104820728302 and perplexity is 51.47252691056391
At time: 239.8436141014099 and batch: 1350, loss is 3.9042032670974733 and perplexity is 49.61053781423499
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.632434895833334 and perplexity of 102.7639793133242
Finished 7 epochs...
Completing Train Step...
At time: 243.3056309223175 and batch: 50, loss is 4.213168697357178 and perplexity is 67.57031080873423
At time: 244.47951364517212 and batch: 100, loss is 4.21558970451355 and perplexity is 67.73409719877192
At time: 245.68849158287048 and batch: 150, loss is 4.172873492240906 and perplexity is 64.90167888936803
At time: 246.8846571445465 and batch: 200, loss is 4.163588585853577 and perplexity is 64.30186180837705
At time: 248.08390498161316 and batch: 250, loss is 4.154549512863159 and perplexity is 63.72325157573368
At time: 249.27965688705444 and batch: 300, loss is 4.147596912384033 and perplexity is 63.28174585123386
At time: 250.47504925727844 and batch: 350, loss is 4.152433757781982 and perplexity is 63.58857130789415
At time: 251.6742069721222 and batch: 400, loss is 4.1589552021026615 and perplexity is 64.00461576599095
At time: 252.88050270080566 and batch: 450, loss is 4.102840557098388 and perplexity is 60.51193129606612
At time: 254.08091711997986 and batch: 500, loss is 4.162645769119263 and perplexity is 64.24126550710868
At time: 255.28484916687012 and batch: 550, loss is 4.150921406745911 and perplexity is 63.492475749618784
At time: 256.484246969223 and batch: 600, loss is 4.085541281700134 and perplexity is 59.47412129376468
At time: 257.6846981048584 and batch: 650, loss is 4.099547033309936 and perplexity is 60.312961646351525
At time: 258.8828115463257 and batch: 700, loss is 4.116581649780273 and perplexity is 61.349170469150906
At time: 260.0830874443054 and batch: 750, loss is 4.055604057312012 and perplexity is 57.72001866701706
At time: 261.2841942310333 and batch: 800, loss is 4.024862351417542 and perplexity is 55.9726037018036
At time: 262.4857521057129 and batch: 850, loss is 4.017646331787109 and perplexity is 55.57015806882747
At time: 263.6832172870636 and batch: 900, loss is 4.04127275466919 and perplexity is 56.89871484476347
At time: 264.8881359100342 and batch: 950, loss is 4.017235746383667 and perplexity is 55.54734645643546
At time: 266.0865559577942 and batch: 1000, loss is 4.0138591957092284 and perplexity is 55.36010432047201
At time: 267.29064416885376 and batch: 1050, loss is 3.9428179168701174 and perplexity is 51.56369898516197
At time: 268.48851323127747 and batch: 1100, loss is 3.9170315265655518 and perplexity is 50.25105423728364
At time: 269.68619775772095 and batch: 1150, loss is 3.9338684606552126 and perplexity is 51.10429071219677
At time: 270.88359689712524 and batch: 1200, loss is 3.9021480464935303 and perplexity is 49.50868191876667
At time: 272.08066844940186 and batch: 1250, loss is 3.9496932554244997 and perplexity is 51.91943838588578
At time: 273.28062891960144 and batch: 1300, loss is 3.924617977142334 and perplexity is 50.63373112093057
At time: 274.48466444015503 and batch: 1350, loss is 3.895481572151184 and perplexity is 49.179731249893415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.628310139973959 and perplexity of 102.34097597999205
Finished 8 epochs...
Completing Train Step...
At time: 277.98345947265625 and batch: 50, loss is 4.146690216064453 and perplexity is 63.22439452921926
At time: 279.158748626709 and batch: 100, loss is 4.149954771995544 and perplexity is 63.43113136975362
At time: 280.34484243392944 and batch: 150, loss is 4.1105686378479005 and perplexity is 60.981384035335715
At time: 281.534775018692 and batch: 200, loss is 4.1008841419219975 and perplexity is 60.39366056637505
At time: 282.716748714447 and batch: 250, loss is 4.090896415710449 and perplexity is 59.79346749111028
At time: 283.9123651981354 and batch: 300, loss is 4.08938277721405 and perplexity is 59.703030258787464
At time: 285.1143035888672 and batch: 350, loss is 4.094606909751892 and perplexity is 60.01574291675486
At time: 286.311252117157 and batch: 400, loss is 4.101213135719299 and perplexity is 60.41353297486806
At time: 287.51705622673035 and batch: 450, loss is 4.045733575820923 and perplexity is 57.15309678980281
At time: 288.7171685695648 and batch: 500, loss is 4.108976683616638 and perplexity is 60.88438169512163
At time: 289.9203917980194 and batch: 550, loss is 4.099788875579834 and perplexity is 60.32754963382521
At time: 291.12767148017883 and batch: 600, loss is 4.03421395778656 and perplexity is 56.49849257943964
At time: 292.33003783226013 and batch: 650, loss is 4.05052526473999 and perplexity is 57.42761382525047
At time: 293.53211736679077 and batch: 700, loss is 4.068535394668579 and perplexity is 58.47126252599457
At time: 294.73737359046936 and batch: 750, loss is 4.010687460899353 and perplexity is 55.18479491495869
At time: 295.93463253974915 and batch: 800, loss is 3.9842761850357054 and perplexity is 53.746372966382474
At time: 297.13246035575867 and batch: 850, loss is 3.976149435043335 and perplexity is 53.311359646702236
At time: 298.33678364753723 and batch: 900, loss is 3.9995956420898438 and perplexity is 54.57607730224086
At time: 299.5337197780609 and batch: 950, loss is 3.979150052070618 and perplexity is 53.47156686024733
At time: 300.73163890838623 and batch: 1000, loss is 3.977774906158447 and perplexity is 53.39808618856423
At time: 301.9376873970032 and batch: 1050, loss is 3.9083783292770384 and perplexity is 49.818097880962675
At time: 303.13857769966125 and batch: 1100, loss is 3.8843811559677124 and perplexity is 48.63683452959691
At time: 304.3442313671112 and batch: 1150, loss is 3.9038047933578492 and perplexity is 49.590773255797664
At time: 305.57803201675415 and batch: 1200, loss is 3.8746098184585573 and perplexity is 48.16390195883814
At time: 306.78099846839905 and batch: 1250, loss is 3.924153518676758 and perplexity is 50.610219316418736
At time: 307.9815754890442 and batch: 1300, loss is 3.900771040916443 and perplexity is 49.440555103917134
At time: 309.1827552318573 and batch: 1350, loss is 3.8751478958129884 and perplexity is 48.18982483741474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.631254069010416 and perplexity of 102.64270446650897
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 312.6340527534485 and batch: 50, loss is 4.115307002067566 and perplexity is 61.2710217059879
At time: 313.83180046081543 and batch: 100, loss is 4.132363071441651 and perplexity is 62.3250275496523
At time: 315.0296516418457 and batch: 150, loss is 4.097041921615601 and perplexity is 60.1620600324264
At time: 316.21595907211304 and batch: 200, loss is 4.089411821365356 and perplexity is 59.70476430781361
At time: 317.411500453949 and batch: 250, loss is 4.077518539428711 and perplexity is 58.99888464639913
At time: 318.6056237220764 and batch: 300, loss is 4.0797890233993535 and perplexity is 59.132992855932855
At time: 319.79873180389404 and batch: 350, loss is 4.079857892990113 and perplexity is 59.137065461188925
At time: 320.9936366081238 and batch: 400, loss is 4.080489506721497 and perplexity is 59.174429042201254
At time: 322.187876701355 and batch: 450, loss is 4.020260696411133 and perplexity is 55.715628798141786
At time: 323.38181018829346 and batch: 500, loss is 4.083187880516053 and perplexity is 59.33431939579019
At time: 324.5751233100891 and batch: 550, loss is 4.069008855819702 and perplexity is 58.49895295191094
At time: 325.76863265037537 and batch: 600, loss is 4.002396354675293 and perplexity is 54.729143455903056
At time: 326.9622993469238 and batch: 650, loss is 4.010341558456421 and perplexity is 55.16570966059324
At time: 328.1561315059662 and batch: 700, loss is 4.018027815818787 and perplexity is 55.59136124084717
At time: 329.34931540489197 and batch: 750, loss is 3.9606017208099367 and perplexity is 52.48890011221909
At time: 330.5430545806885 and batch: 800, loss is 3.9307848024368286 and perplexity is 50.946945270611906
At time: 331.7365942001343 and batch: 850, loss is 3.912667279243469 and perplexity is 50.03222407021383
At time: 332.9305362701416 and batch: 900, loss is 3.9320373582839965 and perplexity is 51.010799146730555
At time: 334.12409353256226 and batch: 950, loss is 3.9039565658569337 and perplexity is 49.59830034257416
At time: 335.31836676597595 and batch: 1000, loss is 3.903860592842102 and perplexity is 49.59354047257295
At time: 336.55472922325134 and batch: 1050, loss is 3.8241019105911254 and perplexity is 45.791656891770174
At time: 337.74878454208374 and batch: 1100, loss is 3.791701307296753 and perplexity is 44.3317580979305
At time: 338.9425480365753 and batch: 1150, loss is 3.809230933189392 and perplexity is 45.115728511304084
At time: 340.13585805892944 and batch: 1200, loss is 3.7732383966445924 and perplexity is 43.52077440598722
At time: 341.3295202255249 and batch: 1250, loss is 3.816865348815918 and perplexity is 45.46147885565228
At time: 342.5230791568756 and batch: 1300, loss is 3.792325668334961 and perplexity is 44.359445763092346
At time: 343.7167341709137 and batch: 1350, loss is 3.7639934730529787 and perplexity is 43.12028228394444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.595623372395833 and perplexity of 99.04986125593578
Finished 10 epochs...
Completing Train Step...
At time: 347.19163608551025 and batch: 50, loss is 4.084095735549926 and perplexity is 59.38821081543198
At time: 348.3826434612274 and batch: 100, loss is 4.091259622573853 and perplexity is 59.81518883332126
At time: 349.550057888031 and batch: 150, loss is 4.054663681983948 and perplexity is 57.665765698601724
At time: 350.72954058647156 and batch: 200, loss is 4.046821985244751 and perplexity is 57.215336624016565
At time: 351.9092650413513 and batch: 250, loss is 4.033525681495666 and perplexity is 56.459619385809354
At time: 353.0815088748932 and batch: 300, loss is 4.038176703453064 and perplexity is 56.72282593051484
At time: 354.253737449646 and batch: 350, loss is 4.038302688598633 and perplexity is 56.72997261417533
At time: 355.4468367099762 and batch: 400, loss is 4.039444317817688 and perplexity is 56.79477419115665
At time: 356.6356670856476 and batch: 450, loss is 3.9827582740783694 and perplexity is 53.66485264388738
At time: 357.82497572898865 and batch: 500, loss is 4.048512477874755 and perplexity is 57.31214052899307
At time: 359.0158803462982 and batch: 550, loss is 4.035410237312317 and perplexity is 56.56612101253835
At time: 360.2048749923706 and batch: 600, loss is 3.970240616798401 and perplexity is 52.99728134178255
At time: 361.3938338756561 and batch: 650, loss is 3.9806835508346556 and perplexity is 53.55362834645108
At time: 362.58505153656006 and batch: 700, loss is 3.991206660270691 and perplexity is 54.12015461933465
At time: 363.77396941185 and batch: 750, loss is 3.9366645288467406 and perplexity is 51.24738174682919
At time: 364.9628689289093 and batch: 800, loss is 3.9095204210281373 and perplexity is 49.87502722268566
At time: 366.1783585548401 and batch: 850, loss is 3.8943514156341554 and perplexity is 49.12418185178533
At time: 367.3698134422302 and batch: 900, loss is 3.9165508127212525 and perplexity is 50.22690366504342
At time: 368.56298661231995 and batch: 950, loss is 3.891978702545166 and perplexity is 49.00776243207803
At time: 369.7520959377289 and batch: 1000, loss is 3.8933276319503785 and perplexity is 49.0739150514821
At time: 370.9414384365082 and batch: 1050, loss is 3.81711229801178 and perplexity is 45.47270691762176
At time: 372.1305365562439 and batch: 1100, loss is 3.7879166412353515 and perplexity is 44.16429429479281
At time: 373.32480669021606 and batch: 1150, loss is 3.8078432130813598 and perplexity is 45.05316392876545
At time: 374.52158093452454 and batch: 1200, loss is 3.774373950958252 and perplexity is 43.57022267938426
At time: 375.7200448513031 and batch: 1250, loss is 3.821068549156189 and perplexity is 45.652964703825425
At time: 376.9167022705078 and batch: 1300, loss is 3.798225417137146 and perplexity is 44.621928880974394
At time: 378.11989736557007 and batch: 1350, loss is 3.771840934753418 and perplexity is 43.459998258346374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.594043375651042 and perplexity of 98.89348636601896
Finished 11 epochs...
Completing Train Step...
At time: 381.59294867515564 and batch: 50, loss is 4.066727390289307 and perplexity is 58.365641737481866
At time: 382.7661759853363 and batch: 100, loss is 4.071701126098633 and perplexity is 58.65666014422592
At time: 383.93951773643494 and batch: 150, loss is 4.034957647323608 and perplexity is 56.54052554503108
At time: 385.11254262924194 and batch: 200, loss is 4.026482300758362 and perplexity is 56.06334996660527
At time: 386.28773617744446 and batch: 250, loss is 4.0123174858093265 and perplexity is 55.274820857653296
At time: 387.46750950813293 and batch: 300, loss is 4.018260703086853 and perplexity is 55.60430926875156
At time: 388.6490514278412 and batch: 350, loss is 4.01869954586029 and perplexity is 55.62871617305118
At time: 389.8397250175476 and batch: 400, loss is 4.019938955307007 and perplexity is 55.697705673672736
At time: 391.02967739105225 and batch: 450, loss is 3.9641655111312866 and perplexity is 52.67629326303213
At time: 392.22219681739807 and batch: 500, loss is 4.031478605270386 and perplexity is 56.34416045820854
At time: 393.4196255207062 and batch: 550, loss is 4.019119825363159 and perplexity is 55.652100695903236
At time: 394.61674404144287 and batch: 600, loss is 3.9546605157852173 and perplexity is 52.17797733768223
At time: 395.8398222923279 and batch: 650, loss is 3.9650974607467653 and perplexity is 52.725407796864125
At time: 397.0368914604187 and batch: 700, loss is 3.977038221359253 and perplexity is 53.35876311629626
At time: 398.23458194732666 and batch: 750, loss is 3.9244112825393676 and perplexity is 50.623266483509106
At time: 399.43218326568604 and batch: 800, loss is 3.8976711940765383 and perplexity is 49.28753424855467
At time: 400.63715267181396 and batch: 850, loss is 3.883761134147644 and perplexity is 48.60668797765526
At time: 401.83370304107666 and batch: 900, loss is 3.906954221725464 and perplexity is 49.747202045194754
At time: 403.0391356945038 and batch: 950, loss is 3.8838849115371703 and perplexity is 48.61270475896973
At time: 404.23866605758667 and batch: 1000, loss is 3.88563871383667 and perplexity is 48.69803663811169
At time: 405.4380359649658 and batch: 1050, loss is 3.811160283088684 and perplexity is 45.20285656078355
At time: 406.63775992393494 and batch: 1100, loss is 3.783316831588745 and perplexity is 43.96161345187246
At time: 407.83682441711426 and batch: 1150, loss is 3.804429364204407 and perplexity is 44.899621470178914
At time: 409.0380549430847 and batch: 1200, loss is 3.771728777885437 and perplexity is 43.45512419439424
At time: 410.2382140159607 and batch: 1250, loss is 3.820056881904602 and perplexity is 45.60680244885466
At time: 411.43793869018555 and batch: 1300, loss is 3.797708353996277 and perplexity is 44.5988624901797
At time: 412.64019656181335 and batch: 1350, loss is 3.772468810081482 and perplexity is 43.48729428736534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.594300944010417 and perplexity of 98.91896147970591
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 416.0812726020813 and batch: 50, loss is 4.059653396606445 and perplexity is 57.95422046793844
At time: 417.23641204833984 and batch: 100, loss is 4.073102116584778 and perplexity is 58.73889515882282
At time: 418.40561270713806 and batch: 150, loss is 4.043120231628418 and perplexity is 57.00393107179971
At time: 419.58542346954346 and batch: 200, loss is 4.036704955101013 and perplexity is 56.63940560684754
At time: 420.7644855976105 and batch: 250, loss is 4.022345399856567 and perplexity is 55.83190051537695
At time: 421.9455440044403 and batch: 300, loss is 4.030381860733033 and perplexity is 56.28239918237599
At time: 423.1343445777893 and batch: 350, loss is 4.029344658851624 and perplexity is 56.2240532355474
At time: 424.3245484828949 and batch: 400, loss is 4.035952138900757 and perplexity is 56.596782590395456
At time: 425.5135090351105 and batch: 450, loss is 3.972266969680786 and perplexity is 53.10478141534613
At time: 426.7331030368805 and batch: 500, loss is 4.040695924758911 and perplexity is 56.865903428397544
At time: 427.9297184944153 and batch: 550, loss is 4.025972499847412 and perplexity is 56.03477610383087
At time: 429.12654662132263 and batch: 600, loss is 3.9655407857894898 and perplexity is 52.748787472543285
At time: 430.3240485191345 and batch: 650, loss is 3.972581639289856 and perplexity is 53.12149450556672
At time: 431.5207214355469 and batch: 700, loss is 3.9800246477127077 and perplexity is 53.51835331623196
At time: 432.717134475708 and batch: 750, loss is 3.9242686080932616 and perplexity is 50.61604435222254
At time: 433.9200048446655 and batch: 800, loss is 3.8952085828781127 and perplexity is 49.166307543157
At time: 435.1188998222351 and batch: 850, loss is 3.8760391426086427 and perplexity is 48.23279300916271
At time: 436.3159987926483 and batch: 900, loss is 3.8958867740631105 and perplexity is 49.199663008944626
At time: 437.51281237602234 and batch: 950, loss is 3.868559308052063 and perplexity is 47.87336560179011
At time: 438.7102301120758 and batch: 1000, loss is 3.8679273319244385 and perplexity is 47.84312033573046
At time: 439.90814995765686 and batch: 1050, loss is 3.791969575881958 and perplexity is 44.34365251133247
At time: 441.1060836315155 and batch: 1100, loss is 3.7583048486709596 and perplexity is 42.875683569499806
At time: 442.30361318588257 and batch: 1150, loss is 3.7779702711105347 and perplexity is 43.72719724545718
At time: 443.50595140457153 and batch: 1200, loss is 3.741547088623047 and perplexity is 42.16316989304161
At time: 444.7071011066437 and batch: 1250, loss is 3.7876626873016357 and perplexity is 44.15308002254141
At time: 445.9100263118744 and batch: 1300, loss is 3.7638433027267455 and perplexity is 43.11380738326773
At time: 447.1137933731079 and batch: 1350, loss is 3.7419142055511476 and perplexity is 42.178651548066675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.578783772786458 and perplexity of 97.39586663994429
Finished 13 epochs...
Completing Train Step...
At time: 450.5664427280426 and batch: 50, loss is 4.053626775741577 and perplexity is 57.60600269584769
At time: 451.7640063762665 and batch: 100, loss is 4.062260451316834 and perplexity is 58.10550741237875
At time: 452.9339282512665 and batch: 150, loss is 4.029156565666199 and perplexity is 56.21347886879115
At time: 454.1098430156708 and batch: 200, loss is 4.021089243888855 and perplexity is 55.76181097127175
At time: 455.2950658798218 and batch: 250, loss is 4.005969486236572 and perplexity is 54.92504767304766
At time: 456.50913071632385 and batch: 300, loss is 4.012999377250671 and perplexity is 55.31252513857027
At time: 457.6983127593994 and batch: 350, loss is 4.011986203193665 and perplexity is 55.25651230323969
At time: 458.8883430957794 and batch: 400, loss is 4.0164021348953245 and perplexity is 55.50106084507147
At time: 460.0781559944153 and batch: 450, loss is 3.9547836875915525 and perplexity is 52.18440458922179
At time: 461.27346086502075 and batch: 500, loss is 4.02424340724945 and perplexity is 55.93797050428292
At time: 462.4691219329834 and batch: 550, loss is 4.0106193590164185 and perplexity is 55.181036854482564
At time: 463.66512727737427 and batch: 600, loss is 3.951850342750549 and perplexity is 52.03155402654426
At time: 464.86744451522827 and batch: 650, loss is 3.9596105289459227 and perplexity is 52.436899317116726
At time: 466.06233048439026 and batch: 700, loss is 3.967745990753174 and perplexity is 52.86523771163793
At time: 467.2576344013214 and batch: 750, loss is 3.912656321525574 and perplexity is 50.03167583422051
At time: 468.4553129673004 and batch: 800, loss is 3.8864446306228637 and perplexity is 48.737299022275174
At time: 469.6523525714874 and batch: 850, loss is 3.869612193107605 and perplexity is 47.92379729772132
At time: 470.8481025695801 and batch: 900, loss is 3.890907497406006 and perplexity is 48.955293172789446
At time: 472.04954743385315 and batch: 950, loss is 3.8659010219573973 and perplexity is 47.74627349813317
At time: 473.2473044395447 and batch: 1000, loss is 3.8666558122634886 and perplexity is 47.78232552667078
At time: 474.4426038265228 and batch: 1050, loss is 3.791645998954773 and perplexity is 44.329306249697495
At time: 475.64460277557373 and batch: 1100, loss is 3.7600057458877565 and perplexity is 42.948672756307
At time: 476.84681391716003 and batch: 1150, loss is 3.7810192680358887 and perplexity is 43.860724794512606
At time: 478.0419731140137 and batch: 1200, loss is 3.7457422399520874 and perplexity is 42.34042231165501
At time: 479.23721861839294 and batch: 1250, loss is 3.793091444969177 and perplexity is 44.39342819998191
At time: 480.4352171421051 and batch: 1300, loss is 3.769439015388489 and perplexity is 43.35573611169031
At time: 481.6321518421173 and batch: 1350, loss is 3.7472099685668945 and perplexity is 42.40261218881171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577711995442709 and perplexity of 97.29153587636615
Finished 14 epochs...
Completing Train Step...
At time: 485.059068441391 and batch: 50, loss is 4.049127769470215 and perplexity is 57.34741505832621
At time: 486.2569103240967 and batch: 100, loss is 4.056523380279541 and perplexity is 57.77310640451308
At time: 487.4442675113678 and batch: 150, loss is 4.022879381179809 and perplexity is 55.86172166875415
At time: 488.6323592662811 and batch: 200, loss is 4.014479765892029 and perplexity is 55.39446981252698
At time: 489.8275818824768 and batch: 250, loss is 3.9987581539154053 and perplexity is 54.53038961701144
At time: 491.0233099460602 and batch: 300, loss is 4.005518221855164 and perplexity is 54.9002675470003
At time: 492.21858739852905 and batch: 350, loss is 4.0048314523696895 and perplexity is 54.86257666246075
At time: 493.41763639450073 and batch: 400, loss is 4.0090109157562255 and perplexity is 55.09235262855575
At time: 494.62435483932495 and batch: 450, loss is 3.9480348777770997 and perplexity is 51.833407705196905
At time: 495.81976342201233 and batch: 500, loss is 4.017785925865173 and perplexity is 55.57791587527028
At time: 497.01533579826355 and batch: 550, loss is 4.004662365913391 and perplexity is 54.85330092801211
At time: 498.21000576019287 and batch: 600, loss is 3.9460965633392333 and perplexity is 51.733035570482414
At time: 499.4054424762726 and batch: 650, loss is 3.95422869682312 and perplexity is 52.15545076171531
At time: 500.60119342803955 and batch: 700, loss is 3.9628183174133302 and perplexity is 52.605375872120554
At time: 501.79721546173096 and batch: 750, loss is 3.908331341743469 and perplexity is 49.815757106410175
At time: 502.9934468269348 and batch: 800, loss is 3.8827382850646974 and perplexity is 48.556996089415804
At time: 504.1949667930603 and batch: 850, loss is 3.866512432098389 and perplexity is 47.775474980075906
At time: 505.39283537864685 and batch: 900, loss is 3.8883527421951296 and perplexity is 48.830384006565744
At time: 506.58856081962585 and batch: 950, loss is 3.8642481756210327 and perplexity is 47.66742142803565
At time: 507.7839267253876 and batch: 1000, loss is 3.8655141973495484 and perplexity is 47.72780763636614
At time: 508.97953486442566 and batch: 1050, loss is 3.791260976791382 and perplexity is 44.31224176961594
At time: 510.175416469574 and batch: 1100, loss is 3.7602911043167113 and perplexity is 42.96093027089981
At time: 511.3716881275177 and batch: 1150, loss is 3.7818782424926756 and perplexity is 43.89841622243665
At time: 512.567079782486 and batch: 1200, loss is 3.7470274782180786 and perplexity is 42.394874827341035
At time: 513.7622716426849 and batch: 1250, loss is 3.7949785947799684 and perplexity is 44.47728434928138
At time: 514.9572033882141 and batch: 1300, loss is 3.771465039253235 and perplexity is 43.443664910571385
At time: 516.1585063934326 and batch: 1350, loss is 3.7491347122192384 and perplexity is 42.48430494104791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577449137369792 and perplexity of 97.2659653715886
Finished 15 epochs...
Completing Train Step...
At time: 519.6599009037018 and batch: 50, loss is 4.044732689857483 and perplexity is 57.09592167511669
At time: 520.8319857120514 and batch: 100, loss is 4.051576957702637 and perplexity is 57.48804181284699
At time: 522.0103151798248 and batch: 150, loss is 4.017764644622803 and perplexity is 55.576733120757396
At time: 523.2012491226196 and batch: 200, loss is 4.009255785942077 and perplexity is 55.10584475502525
At time: 524.4007427692413 and batch: 250, loss is 3.9932996797561646 and perplexity is 54.23354778316506
At time: 525.6004164218903 and batch: 300, loss is 4.0000121831893924 and perplexity is 54.59881521679859
At time: 526.7966575622559 and batch: 350, loss is 3.9995914840698243 and perplexity is 54.575850374290646
At time: 527.9927854537964 and batch: 400, loss is 4.003682742118835 and perplexity is 54.79959164095614
At time: 529.1888632774353 and batch: 450, loss is 3.9431313180923464 and perplexity is 51.5798616440128
At time: 530.3847358226776 and batch: 500, loss is 4.013139867782593 and perplexity is 55.320296570542446
At time: 531.5807089805603 and batch: 550, loss is 4.00032335281372 and perplexity is 54.61580735319959
At time: 532.7773604393005 and batch: 600, loss is 3.9420620918273928 and perplexity is 51.52474057489918
At time: 533.9742965698242 and batch: 650, loss is 3.9503353786468507 and perplexity is 51.95278776902557
At time: 535.1713013648987 and batch: 700, loss is 3.9592819309234617 and perplexity is 52.41967148636771
At time: 536.3675646781921 and batch: 750, loss is 3.9051216173172 and perplexity is 49.65611858889121
At time: 537.5631046295166 and batch: 800, loss is 3.879868116378784 and perplexity is 48.41782913161671
At time: 538.7658925056458 and batch: 850, loss is 3.8639997673034667 and perplexity is 47.65558191465368
At time: 539.9615867137909 and batch: 900, loss is 3.8861311435699464 and perplexity is 48.722022904595185
At time: 541.1573479175568 and batch: 950, loss is 3.8625560712814333 and perplexity is 47.58683137999366
At time: 542.35284948349 and batch: 1000, loss is 3.8641481399536133 and perplexity is 47.66265322421813
At time: 543.5485301017761 and batch: 1050, loss is 3.790494441986084 and perplexity is 44.27828790906923
At time: 544.7455325126648 and batch: 1100, loss is 3.7598749351501466 and perplexity is 42.943054976185365
At time: 545.9413747787476 and batch: 1150, loss is 3.7818242263793946 and perplexity is 43.89604506465407
At time: 547.170731306076 and batch: 1200, loss is 3.747243356704712 and perplexity is 42.40402795670609
At time: 548.366297006607 and batch: 1250, loss is 3.7956228160858156 and perplexity is 44.50594679497322
At time: 549.5618717670441 and batch: 1300, loss is 3.7722695684432983 and perplexity is 43.478630670716605
At time: 550.7574393749237 and batch: 1350, loss is 3.749919543266296 and perplexity is 42.51766103031338
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577429606119792 and perplexity of 97.26406566425437
Finished 16 epochs...
Completing Train Step...
At time: 554.2545845508575 and batch: 50, loss is 4.040574703216553 and perplexity is 56.85901047367213
At time: 555.4399378299713 and batch: 100, loss is 4.047132205963135 and perplexity is 57.2330887602445
At time: 556.6210997104645 and batch: 150, loss is 4.013271450996399 and perplexity is 55.327576271886635
At time: 557.8145725727081 and batch: 200, loss is 4.004684553146363 and perplexity is 54.85451798448058
At time: 559.0037910938263 and batch: 250, loss is 3.988616418838501 and perplexity is 53.98015175141503
At time: 560.1988849639893 and batch: 300, loss is 3.9953744840621948 and perplexity is 54.3461885950495
At time: 561.3955545425415 and batch: 350, loss is 3.995184473991394 and perplexity is 54.33586325289737
At time: 562.5926396846771 and batch: 400, loss is 3.9992103576660156 and perplexity is 54.55505403997048
At time: 563.7889795303345 and batch: 450, loss is 3.938983154296875 and perplexity is 51.366343090504756
At time: 564.9867215156555 and batch: 500, loss is 4.009234352111816 and perplexity is 55.104663638360364
At time: 566.1847517490387 and batch: 550, loss is 3.9966536140441895 and perplexity is 54.415748913148384
At time: 567.386926651001 and batch: 600, loss is 3.9387090539932252 and perplexity is 51.352265489691725
At time: 568.5924599170685 and batch: 650, loss is 3.9470255088806154 and perplexity is 51.78111507137929
At time: 569.7905986309052 and batch: 700, loss is 3.9562522077560427 and perplexity is 52.26109473636454
At time: 570.9877960681915 and batch: 750, loss is 3.9023356771469118 and perplexity is 49.517972136640715
At time: 572.1848692893982 and batch: 800, loss is 3.877317337989807 and perplexity is 48.29448336016948
At time: 573.3818554878235 and batch: 850, loss is 3.861687297821045 and perplexity is 47.545507157119985
At time: 574.5835309028625 and batch: 900, loss is 3.884014120101929 and perplexity is 48.618986342589125
At time: 575.7807919979095 and batch: 950, loss is 3.860791354179382 and perplexity is 47.502928139341286
At time: 577.0056726932526 and batch: 1000, loss is 3.8626549243927 and perplexity is 47.591535718846345
At time: 578.2087783813477 and batch: 1050, loss is 3.7895006799697875 and perplexity is 44.234307684956086
At time: 579.4059569835663 and batch: 1100, loss is 3.7591071033477785 and perplexity is 42.9100945885201
At time: 580.6115386486053 and batch: 1150, loss is 3.7813561296463014 and perplexity is 43.87550227774441
At time: 581.8187417984009 and batch: 1200, loss is 3.7469515800476074 and perplexity is 42.39165725600972
At time: 583.0163233280182 and batch: 1250, loss is 3.795698113441467 and perplexity is 44.50929810124831
At time: 584.2115149497986 and batch: 1300, loss is 3.7724998998641968 and perplexity is 43.48864631891267
At time: 585.4067575931549 and batch: 1350, loss is 3.7501746940612795 and perplexity is 42.528510829434666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577520751953125 and perplexity of 97.27293128259868
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 588.8589582443237 and batch: 50, loss is 4.038980140686035 and perplexity is 56.76841747334577
At time: 590.0817260742188 and batch: 100, loss is 4.048644633293152 and perplexity is 57.31971513940574
At time: 591.2598323822021 and batch: 150, loss is 4.0182807779312135 and perplexity is 55.605425527810205
At time: 592.4532146453857 and batch: 200, loss is 4.012509231567383 and perplexity is 55.2854205862741
At time: 593.6526665687561 and batch: 250, loss is 3.998231225013733 and perplexity is 54.50166354766553
At time: 594.851725101471 and batch: 300, loss is 4.004580245018006 and perplexity is 54.848796510780986
At time: 596.0516364574432 and batch: 350, loss is 4.0023022603988645 and perplexity is 54.72399399902104
At time: 597.2518632411957 and batch: 400, loss is 4.008371877670288 and perplexity is 55.057157763609474
At time: 598.4505643844604 and batch: 450, loss is 3.9474557638168335 and perplexity is 51.80339894527123
At time: 599.6468274593353 and batch: 500, loss is 4.018021750450134 and perplexity is 55.59102405976991
At time: 600.8440279960632 and batch: 550, loss is 4.005306444168091 and perplexity is 54.8886421263653
At time: 602.0416991710663 and batch: 600, loss is 3.9487615871429442 and perplexity is 51.87108921813577
At time: 603.240642786026 and batch: 650, loss is 3.956092472076416 and perplexity is 52.25274744157695
At time: 604.4400351047516 and batch: 700, loss is 3.9647798252105715 and perplexity is 52.70866299320066
At time: 605.637971162796 and batch: 750, loss is 3.911533670425415 and perplexity is 49.97553923510577
At time: 606.8833165168762 and batch: 800, loss is 3.8826173448562624 and perplexity is 48.551123951283735
At time: 608.0816135406494 and batch: 850, loss is 3.861428394317627 and perplexity is 47.533199052119734
At time: 609.2799150943756 and batch: 900, loss is 3.881284031867981 and perplexity is 48.48643324318801
At time: 610.4817345142365 and batch: 950, loss is 3.854218373298645 and perplexity is 47.191716216379966
At time: 611.6805114746094 and batch: 1000, loss is 3.8527856922149657 and perplexity is 47.12415394639988
At time: 612.8788425922394 and batch: 1050, loss is 3.78124653339386 and perplexity is 43.87069395061292
At time: 614.0771632194519 and batch: 1100, loss is 3.7493825340270996 and perplexity is 42.49483478301247
At time: 615.2819786071777 and batch: 1150, loss is 3.7718754386901856 and perplexity is 43.461497825248536
At time: 616.4804151058197 and batch: 1200, loss is 3.7351373291015624 and perplexity is 41.89377840302665
At time: 617.6782088279724 and batch: 1250, loss is 3.7829070854187012 and perplexity is 43.94360403902755
At time: 618.876574754715 and batch: 1300, loss is 3.7611327505111696 and perplexity is 42.997103394723375
At time: 620.0755586624146 and batch: 1350, loss is 3.7404130268096925 and perplexity is 42.11538135483581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.57332763671875 and perplexity of 96.86590861538173
Finished 18 epochs...
Completing Train Step...
At time: 623.5348172187805 and batch: 50, loss is 4.038123874664307 and perplexity is 56.71982941147799
At time: 624.7423188686371 and batch: 100, loss is 4.045777173042297 and perplexity is 57.155588560332525
At time: 625.9364264011383 and batch: 150, loss is 4.013663320541382 and perplexity is 55.34926171267973
At time: 627.14208984375 and batch: 200, loss is 4.007075042724609 and perplexity is 54.98580399444267
At time: 628.3425304889679 and batch: 250, loss is 3.9919570159912108 and perplexity is 54.16077922649578
At time: 629.5437989234924 and batch: 300, loss is 3.9986060094833373 and perplexity is 54.522093752953474
At time: 630.7431511878967 and batch: 350, loss is 3.9964530992507936 and perplexity is 54.404838844349236
At time: 631.9428904056549 and batch: 400, loss is 4.001259355545044 and perplexity is 54.66695183000666
At time: 633.1432206630707 and batch: 450, loss is 3.94054621219635 and perplexity is 51.44669443938561
At time: 634.3425369262695 and batch: 500, loss is 4.0108298540115355 and perplexity is 55.19265340913621
At time: 635.5420589447021 and batch: 550, loss is 3.9983144903182986 and perplexity is 54.50620183421844
At time: 636.7408716678619 and batch: 600, loss is 3.9416756629943848 and perplexity is 51.50483377605602
At time: 637.9872889518738 and batch: 650, loss is 3.949967803955078 and perplexity is 51.93369474834521
At time: 639.1859564781189 and batch: 700, loss is 3.959102363586426 and perplexity is 52.41025947062121
At time: 640.385002374649 and batch: 750, loss is 3.905836863517761 and perplexity is 49.69164764354255
At time: 641.5848152637482 and batch: 800, loss is 3.8783368968963625 and perplexity is 48.3437475404162
At time: 642.7874524593353 and batch: 850, loss is 3.858505334854126 and perplexity is 47.39445955548495
At time: 643.9927241802216 and batch: 900, loss is 3.879307732582092 and perplexity is 48.39070416560591
At time: 645.1907238960266 and batch: 950, loss is 3.853190083503723 and perplexity is 47.14321439742629
At time: 646.388186454773 and batch: 1000, loss is 3.8532330274581907 and perplexity is 47.14523895694982
At time: 647.5865387916565 and batch: 1050, loss is 3.782436556816101 and perplexity is 43.922932180157666
At time: 648.7880756855011 and batch: 1100, loss is 3.7513264656066894 and perplexity is 42.577522177596656
At time: 649.9880881309509 and batch: 1150, loss is 3.7742839241027832 and perplexity is 43.5663003658038
At time: 651.1871762275696 and batch: 1200, loss is 3.7381260061264037 and perplexity is 42.019172664160116
At time: 652.3870794773102 and batch: 1250, loss is 3.7860802268981932 and perplexity is 44.08326477621631
At time: 653.5866546630859 and batch: 1300, loss is 3.764166784286499 and perplexity is 43.12775616089153
At time: 654.7875778675079 and batch: 1350, loss is 3.743277044296265 and perplexity is 42.236173436239035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572431233723958 and perplexity of 96.77911663091484
Finished 19 epochs...
Completing Train Step...
At time: 658.2899994850159 and batch: 50, loss is 4.037337551116943 and perplexity is 56.67524680448327
At time: 659.4727694988251 and batch: 100, loss is 4.0441905117034915 and perplexity is 57.06497390406324
At time: 660.6578624248505 and batch: 150, loss is 4.0114302062988285 and perplexity is 55.22579839319013
At time: 661.8476009368896 and batch: 200, loss is 4.004581804275513 and perplexity is 54.84888203424538
At time: 663.0373623371124 and batch: 250, loss is 3.9891275930404664 and perplexity is 54.00775206609194
At time: 664.2272675037384 and batch: 300, loss is 3.995657901763916 and perplexity is 54.361593449819566
At time: 665.4245073795319 and batch: 350, loss is 3.993483386039734 and perplexity is 54.243511741865966
At time: 666.6238148212433 and batch: 400, loss is 3.9978703022003175 and perplexity is 54.4819962033322
At time: 667.8661119937897 and batch: 450, loss is 3.937348952293396 and perplexity is 51.28246866226057
At time: 669.0631592273712 and batch: 500, loss is 4.007682948112488 and perplexity is 55.01924032298019
At time: 670.2601537704468 and batch: 550, loss is 3.9954398584365847 and perplexity is 54.349741559264515
At time: 671.4570162296295 and batch: 600, loss is 3.939104633331299 and perplexity is 51.37258340329117
At time: 672.6539561748505 and batch: 650, loss is 3.947647008895874 and perplexity is 51.81330703780387
At time: 673.8510282039642 and batch: 700, loss is 3.9569751977920533 and perplexity is 52.29889264924068
At time: 675.0540237426758 and batch: 750, loss is 3.9038041257858276 and perplexity is 49.59074015039596
At time: 676.2524588108063 and batch: 800, loss is 3.8768406200408934 and perplexity is 48.27146599994847
At time: 677.4518911838531 and batch: 850, loss is 3.8574948263168336 and perplexity is 47.346591239228204
At time: 678.6510319709778 and batch: 900, loss is 3.8786651563644408 and perplexity is 48.359619438176566
At time: 679.850492477417 and batch: 950, loss is 3.8528805112838747 and perplexity is 47.128622426645414
At time: 681.0497899055481 and batch: 1000, loss is 3.8534440183639527 and perplexity is 47.15518722307964
At time: 682.2541425228119 and batch: 1050, loss is 3.7829678153991697 and perplexity is 43.94627281427906
At time: 683.4531359672546 and batch: 1100, loss is 3.752156238555908 and perplexity is 42.61286651560424
At time: 684.6503596305847 and batch: 1150, loss is 3.7753599786758425 and perplexity is 43.61320531415987
At time: 685.8477258682251 and batch: 1200, loss is 3.7394869470596315 and perplexity is 42.07639720699809
At time: 687.044116973877 and batch: 1250, loss is 3.7875433731079102 and perplexity is 44.147812247664426
At time: 688.2448563575745 and batch: 1300, loss is 3.7657085180282595 and perplexity is 43.194298960229986
At time: 689.4426021575928 and batch: 1350, loss is 3.744628028869629 and perplexity is 42.29327241622532
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572098388671875 and perplexity of 96.74690954108179
Finished 20 epochs...
Completing Train Step...
At time: 692.9271652698517 and batch: 50, loss is 4.036352014541626 and perplexity is 56.61941879063582
At time: 694.1059956550598 and batch: 100, loss is 4.04278347492218 and perplexity is 56.984737847634214
At time: 695.285240650177 and batch: 150, loss is 4.009746255874634 and perplexity is 55.13287914422131
At time: 696.4721653461456 and batch: 200, loss is 4.002837591171264 and perplexity is 54.753297279771495
At time: 697.6945068836212 and batch: 250, loss is 3.987224884033203 and perplexity is 53.9050887299736
At time: 698.8900194168091 and batch: 300, loss is 3.993678107261658 and perplexity is 54.254075133178645
At time: 700.0858738422394 and batch: 350, loss is 3.9915530633926393 and perplexity is 54.13890525730737
At time: 701.2827422618866 and batch: 400, loss is 3.995797805786133 and perplexity is 54.36919938743554
At time: 702.4863276481628 and batch: 450, loss is 3.935430059432983 and perplexity is 51.1841574537846
At time: 703.6819496154785 and batch: 500, loss is 4.005821332931519 and perplexity is 54.91691094846088
At time: 704.8794434070587 and batch: 550, loss is 3.9937555408477783 and perplexity is 54.2582763834347
At time: 706.0755887031555 and batch: 600, loss is 3.937618193626404 and perplexity is 51.296277881405985
At time: 707.2725722789764 and batch: 650, loss is 3.9462592458724974 and perplexity is 51.741452316372666
At time: 708.4692490100861 and batch: 700, loss is 3.95571391582489 and perplexity is 52.232970580936815
At time: 709.6693580150604 and batch: 750, loss is 3.902658624649048 and perplexity is 49.53396642457174
At time: 710.8728303909302 and batch: 800, loss is 3.875935821533203 and perplexity is 48.22780980255711
At time: 712.0687458515167 and batch: 850, loss is 3.8568122720718385 and perplexity is 47.314285648804976
At time: 713.2658207416534 and batch: 900, loss is 3.8781838321685793 and perplexity is 48.33634838414827
At time: 714.46204829216 and batch: 950, loss is 3.8525757932662965 and perplexity is 47.1142636740448
At time: 715.658364534378 and batch: 1000, loss is 3.853384118080139 and perplexity is 47.152362698577456
At time: 716.8548636436462 and batch: 1050, loss is 3.7831168746948243 and perplexity is 43.95282390298961
At time: 718.0517692565918 and batch: 1100, loss is 3.7525246858596804 and perplexity is 42.62857000415427
At time: 719.2478783130646 and batch: 1150, loss is 3.775932049751282 and perplexity is 43.638162305333054
At time: 720.4445195198059 and batch: 1200, loss is 3.7402021503448486 and perplexity is 42.10650114844633
At time: 721.6418342590332 and batch: 1250, loss is 3.788359546661377 and perplexity is 44.183859232761314
At time: 722.8432145118713 and batch: 1300, loss is 3.766519160270691 and perplexity is 43.22932827980419
At time: 724.041380405426 and batch: 1350, loss is 3.745373401641846 and perplexity is 42.3248084215121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571960042317708 and perplexity of 96.7335258846813
Finished 21 epochs...
Completing Train Step...
At time: 727.4874732494354 and batch: 50, loss is 4.035330777168274 and perplexity is 56.56162643898683
At time: 728.693336725235 and batch: 100, loss is 4.041482310295105 and perplexity is 56.91063953996641
At time: 729.8753180503845 and batch: 150, loss is 4.008303542137146 and perplexity is 55.05339553192891
At time: 731.0675880908966 and batch: 200, loss is 4.0013935756683345 and perplexity is 54.67428972745692
At time: 732.2669067382812 and batch: 250, loss is 3.985689806938171 and perplexity is 53.82240374311028
At time: 733.4625356197357 and batch: 300, loss is 3.992103796005249 and perplexity is 54.16872952988952
At time: 734.6585829257965 and batch: 350, loss is 3.9900450849533082 and perplexity is 54.05732648042786
At time: 735.8640191555023 and batch: 400, loss is 3.9942247104644775 and perplexity is 54.28373869077169
At time: 737.0589642524719 and batch: 450, loss is 3.933976583480835 and perplexity is 51.10981655123929
At time: 738.2557790279388 and batch: 500, loss is 4.004419817924499 and perplexity is 54.83999798355438
At time: 739.4512887001038 and batch: 550, loss is 3.992485132217407 and perplexity is 54.18938996706192
At time: 740.6506237983704 and batch: 600, loss is 3.9364783191680908 and perplexity is 51.23783987676432
At time: 741.8497898578644 and batch: 650, loss is 3.9451808023452757 and perplexity is 51.68568215992039
At time: 743.0454564094543 and batch: 700, loss is 3.954749593734741 and perplexity is 52.182625451932935
At time: 744.2413432598114 and batch: 750, loss is 3.901803388595581 and perplexity is 49.49162130073358
At time: 745.437370300293 and batch: 800, loss is 3.875214486122131 and perplexity is 48.1930339195939
At time: 746.6337060928345 and batch: 850, loss is 3.8562225198745725 and perplexity is 47.28639017139959
At time: 747.8298170566559 and batch: 900, loss is 3.8777256536483766 and perplexity is 48.3142067803646
At time: 749.025815486908 and batch: 950, loss is 3.852243757247925 and perplexity is 47.09862263836326
At time: 750.2217183113098 and batch: 1000, loss is 3.85319109916687 and perplexity is 47.1432622790761
At time: 751.4223248958588 and batch: 1050, loss is 3.783094439506531 and perplexity is 43.951837824170795
At time: 752.6274783611298 and batch: 1100, loss is 3.75267683506012 and perplexity is 42.635056400433776
At time: 753.8270349502563 and batch: 1150, loss is 3.776247191429138 and perplexity is 43.65191667619444
At time: 755.0235712528229 and batch: 1200, loss is 3.7406203889846803 and perplexity is 42.12411539743773
At time: 756.2203345298767 and batch: 1250, loss is 3.7888764190673827 and perplexity is 44.20670255342207
At time: 757.4155960083008 and batch: 1300, loss is 3.767035460472107 and perplexity is 43.25165335342621
At time: 758.6116034984589 and batch: 1350, loss is 3.7458528232574464 and perplexity is 42.34510471439754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571899820963542 and perplexity of 96.72770063616316
Finished 22 epochs...
Completing Train Step...
At time: 762.0567142963409 and batch: 50, loss is 4.034317951202393 and perplexity is 56.504368356188166
At time: 763.2645461559296 and batch: 100, loss is 4.040264663696289 and perplexity is 56.84138466583186
At time: 764.4523859024048 and batch: 150, loss is 4.007000904083252 and perplexity is 54.98172757275267
At time: 765.6457891464233 and batch: 200, loss is 4.000107045173645 and perplexity is 54.60399481441747
At time: 766.841607093811 and batch: 250, loss is 3.9843471813201905 and perplexity is 53.7501888946244
At time: 768.0443291664124 and batch: 300, loss is 3.990741658210754 and perplexity is 54.09499448616279
At time: 769.2403528690338 and batch: 350, loss is 3.9887493562698366 and perplexity is 53.987328211131455
At time: 770.4364187717438 and batch: 400, loss is 3.9928896617889404 and perplexity is 54.21131561225388
At time: 771.6320526599884 and batch: 450, loss is 3.9327386474609374 and perplexity is 51.04658501473358
At time: 772.8277716636658 and batch: 500, loss is 4.003234996795654 and perplexity is 54.77506087226495
At time: 774.0233697891235 and batch: 550, loss is 3.991402087211609 and perplexity is 54.130732189131294
At time: 775.2197380065918 and batch: 600, loss is 3.9355010414123535 and perplexity is 51.18779073554031
At time: 776.4156076908112 and batch: 650, loss is 3.9442435121536255 and perplexity is 51.63726037316097
At time: 777.6115276813507 and batch: 700, loss is 3.953916835784912 and perplexity is 52.13918804467826
At time: 778.8072280883789 and batch: 750, loss is 3.9010702753067017 and perplexity is 49.45535163198233
At time: 780.0026063919067 and batch: 800, loss is 3.874567065238953 and perplexity is 48.161842840977954
At time: 781.1986045837402 and batch: 850, loss is 3.855664839744568 and perplexity is 47.26002684301683
At time: 782.3945388793945 and batch: 900, loss is 3.877266974449158 and perplexity is 48.29205114024177
At time: 783.5908086299896 and batch: 950, loss is 3.8518817377090455 and perplexity is 47.081575102670556
At time: 784.7877817153931 and batch: 1000, loss is 3.8529231452941897 and perplexity is 47.13063175165257
At time: 785.9844536781311 and batch: 1050, loss is 3.7829789972305297 and perplexity is 43.946764216837956
At time: 787.1805331707001 and batch: 1100, loss is 3.75270546913147 and perplexity is 42.636277233159376
At time: 788.4210102558136 and batch: 1150, loss is 3.776417307853699 and perplexity is 43.6593432158549
At time: 789.6155636310577 and batch: 1200, loss is 3.740872039794922 and perplexity is 42.13471729914084
At time: 790.8113629817963 and batch: 1250, loss is 3.789222922325134 and perplexity is 44.22202297400581
At time: 792.0142798423767 and batch: 1300, loss is 3.767386989593506 and perplexity is 43.266860241804046
At time: 793.2115998268127 and batch: 1350, loss is 3.746187505722046 and perplexity is 42.35927925025907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571878662109375 and perplexity of 96.72565401050375
Finished 23 epochs...
Completing Train Step...
At time: 796.6484506130219 and batch: 50, loss is 4.033322582244873 and perplexity is 56.44815364379324
At time: 797.8386337757111 and batch: 100, loss is 4.039110922813416 and perplexity is 56.77584225325466
At time: 799.0378313064575 and batch: 150, loss is 4.005787787437439 and perplexity is 54.915068764448414
At time: 800.2372357845306 and batch: 200, loss is 3.9989161539077758 and perplexity is 54.53900609883899
At time: 801.4322137832642 and batch: 250, loss is 3.9831197452545166 and perplexity is 53.6842544476755
At time: 802.627035856247 and batch: 300, loss is 3.9895071268081663 and perplexity is 54.02825372200785
At time: 803.8218476772308 and batch: 350, loss is 3.9875787544250487 and perplexity is 53.924167520355375
At time: 805.0169372558594 and batch: 400, loss is 3.991690826416016 and perplexity is 54.14636411034319
At time: 806.2116301059723 and batch: 450, loss is 3.931621775627136 and perplexity is 50.98960434769308
At time: 807.4061646461487 and batch: 500, loss is 4.002172236442566 and perplexity is 54.71687903138497
At time: 808.6007316112518 and batch: 550, loss is 3.9904219055175782 and perplexity is 54.07770023107817
At time: 809.7954182624817 and batch: 600, loss is 3.9346162128448485 and perplexity is 51.14251834809463
At time: 810.9911057949066 and batch: 650, loss is 3.943386926651001 and perplexity is 51.5930475832509
At time: 812.1859216690063 and batch: 700, loss is 3.953156814575195 and perplexity is 52.099576210730625
At time: 813.3806269168854 and batch: 750, loss is 3.900401473045349 and perplexity is 49.42228683911148
At time: 814.5751571655273 and batch: 800, loss is 3.873958044052124 and perplexity is 48.1325201882558
At time: 815.7720444202423 and batch: 850, loss is 3.8551214838027956 and perplexity is 47.23435480178303
At time: 816.9667899608612 and batch: 900, loss is 3.87680597782135 and perplexity is 48.269793798190186
At time: 818.1880326271057 and batch: 950, loss is 3.8514980125427245 and perplexity is 47.06351218325365
At time: 819.3825442790985 and batch: 1000, loss is 3.8526093053817747 and perplexity is 47.11584259914613
At time: 820.5809471607208 and batch: 1050, loss is 3.7828053712844847 and perplexity is 43.93913458069576
At time: 821.7752034664154 and batch: 1100, loss is 3.7526568222045897 and perplexity is 42.634203159747436
At time: 822.9695777893066 and batch: 1150, loss is 3.7764955663681032 and perplexity is 43.66276006489186
At time: 824.1645333766937 and batch: 1200, loss is 3.74101851940155 and perplexity is 42.14088962800532
At time: 825.3641066551208 and batch: 1250, loss is 3.7894594717025756 and perplexity is 44.23248490334217
At time: 826.5590634346008 and batch: 1300, loss is 3.7676326847076416 and perplexity is 43.27749200400198
At time: 827.7527797222137 and batch: 1350, loss is 3.746430907249451 and perplexity is 42.36959081840317
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571881917317708 and perplexity of 96.72596887317117
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 831.1977083683014 and batch: 50, loss is 4.0331089353561405 and perplexity is 56.43609495958861
At time: 832.3817994594574 and batch: 100, loss is 4.039954934120178 and perplexity is 56.82378193403785
At time: 833.5771641731262 and batch: 150, loss is 4.0071868896484375 and perplexity is 54.99195433141541
At time: 834.7725625038147 and batch: 200, loss is 4.0010166835784915 and perplexity is 54.65368730283017
At time: 835.9687027931213 and batch: 250, loss is 3.985732526779175 and perplexity is 53.82470307675386
At time: 837.1642370223999 and batch: 300, loss is 3.9923071384429933 and perplexity is 54.17974545136584
At time: 838.3603465557098 and batch: 350, loss is 3.989763031005859 and perplexity is 54.04208154815324
At time: 839.5588591098785 and batch: 400, loss is 3.993908281326294 and perplexity is 54.266564451478565
At time: 840.7578511238098 and batch: 450, loss is 3.9337765884399416 and perplexity is 51.09959586346557
At time: 841.9537727832794 and batch: 500, loss is 4.004178018569946 and perplexity is 54.826739310472156
At time: 843.1495976448059 and batch: 550, loss is 3.9927116870880126 and perplexity is 54.2016682280915
At time: 844.3457579612732 and batch: 600, loss is 3.937141089439392 and perplexity is 51.271810049767225
At time: 845.5410931110382 and batch: 650, loss is 3.945380516052246 and perplexity is 51.696005529926765
At time: 846.7387042045593 and batch: 700, loss is 3.9547641897201538 and perplexity is 52.183387114331424
At time: 847.9342932701111 and batch: 750, loss is 3.902375411987305 and perplexity is 49.519939764451586
At time: 849.1652002334595 and batch: 800, loss is 3.875227508544922 and perplexity is 48.193661513743564
At time: 850.3641788959503 and batch: 850, loss is 3.854320306777954 and perplexity is 47.196526877388024
At time: 851.5598378181458 and batch: 900, loss is 3.875601387023926 and perplexity is 48.21168345540609
At time: 852.754873752594 and batch: 950, loss is 3.8497145843505858 and perplexity is 46.979652589813625
At time: 853.9490420818329 and batch: 1000, loss is 3.848310832977295 and perplexity is 46.913751103446614
At time: 855.1520791053772 and batch: 1050, loss is 3.778024187088013 and perplexity is 43.729554903596195
At time: 856.347742319107 and batch: 1100, loss is 3.7473804330825806 and perplexity is 42.409840945668066
At time: 857.5438916683197 and batch: 1150, loss is 3.771212549209595 and perplexity is 43.43269720239906
At time: 858.7389376163483 and batch: 1200, loss is 3.7359616231918333 and perplexity is 41.9283254334838
At time: 859.9338929653168 and batch: 1250, loss is 3.784273920059204 and perplexity is 44.00370874649726
At time: 861.1292777061462 and batch: 1300, loss is 3.763052520751953 and perplexity is 43.079727238282516
At time: 862.3249380588531 and batch: 1350, loss is 3.742818660736084 and perplexity is 42.216817505250106
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572113444010417 and perplexity of 96.74836610952238
Annealing...
Finished 25 epochs...
Completing Train Step...
At time: 865.7508912086487 and batch: 50, loss is 4.033044638633728 and perplexity is 56.43246642030981
At time: 866.9706223011017 and batch: 100, loss is 4.03989622592926 and perplexity is 56.82044601052333
At time: 868.1573059558868 and batch: 150, loss is 4.006987290382385 and perplexity is 54.98097907305527
At time: 869.3523244857788 and batch: 200, loss is 4.000981392860413 and perplexity is 54.65175856899302
At time: 870.5559530258179 and batch: 250, loss is 3.985568380355835 and perplexity is 53.8158686693445
At time: 871.7536628246307 and batch: 300, loss is 3.99220664024353 and perplexity is 54.17430075809612
At time: 872.9523842334747 and batch: 350, loss is 3.9896472883224487 and perplexity is 54.03582693458763
At time: 874.1510901451111 and batch: 400, loss is 3.9935977554321287 and perplexity is 54.249715894121046
At time: 875.3516364097595 and batch: 450, loss is 3.933449501991272 and perplexity is 51.08288461128719
At time: 876.5536594390869 and batch: 500, loss is 4.003789052963257 and perplexity is 54.80541774150081
At time: 877.7538006305695 and batch: 550, loss is 3.992293395996094 and perplexity is 54.17900089420698
At time: 878.983181476593 and batch: 600, loss is 3.9364965200424193 and perplexity is 51.23877245873567
At time: 880.1846125125885 and batch: 650, loss is 3.944931492805481 and perplexity is 51.6727980324218
At time: 881.3834977149963 and batch: 700, loss is 3.9543526649475096 and perplexity is 52.161916775904466
At time: 882.5888872146606 and batch: 750, loss is 3.9020161294937132 and perplexity is 49.502151312741496
At time: 883.7857434749603 and batch: 800, loss is 3.874902424812317 and perplexity is 48.17799708463427
At time: 884.9825847148895 and batch: 850, loss is 3.8538675498962403 and perplexity is 47.17516316170088
At time: 886.1788275241852 and batch: 900, loss is 3.8750759983062744 and perplexity is 48.18636023370962
At time: 887.3814270496368 and batch: 950, loss is 3.8492102098464964 and perplexity is 46.955963225494244
At time: 888.5773966312408 and batch: 1000, loss is 3.8475835800170897 and perplexity is 46.879645342343366
At time: 889.774619102478 and batch: 1050, loss is 3.7771594524383545 and perplexity is 43.6917567872827
At time: 890.9703452587128 and batch: 1100, loss is 3.7463098526000977 and perplexity is 42.36446209287771
At time: 892.1681339740753 and batch: 1150, loss is 3.770034556388855 and perplexity is 43.38156392014196
At time: 893.3706860542297 and batch: 1200, loss is 3.7348042011260985 and perplexity is 41.87982473774989
At time: 894.567791223526 and batch: 1250, loss is 3.783055682182312 and perplexity is 43.95013440155249
At time: 895.7637910842896 and batch: 1300, loss is 3.761954026222229 and perplexity is 43.032430375997556
At time: 896.9598727226257 and batch: 1350, loss is 3.7419397974014283 and perplexity is 42.179730991614555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572142333984375 and perplexity of 96.75116120767473
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 900.4044115543365 and batch: 50, loss is 4.033026585578918 and perplexity is 56.43144765109643
At time: 901.6114950180054 and batch: 100, loss is 4.039855923652649 and perplexity is 56.818156063336396
At time: 902.8013226985931 and batch: 150, loss is 4.006924366950988 and perplexity is 54.97751959003285
At time: 903.9975347518921 and batch: 200, loss is 4.000955233573913 and perplexity is 54.650328936682065
At time: 905.1944110393524 and batch: 250, loss is 3.9855043935775756 and perplexity is 53.81242527545613
At time: 906.393355846405 and batch: 300, loss is 3.9921466493606568 and perplexity is 54.171050891446754
At time: 907.5938484668732 and batch: 350, loss is 3.9895881938934328 and perplexity is 54.03263381259732
At time: 908.790899515152 and batch: 400, loss is 3.993481407165527 and perplexity is 54.24340440088591
At time: 910.0136535167694 and batch: 450, loss is 3.933345217704773 and perplexity is 51.07755774687214
At time: 911.2109289169312 and batch: 500, loss is 4.00367874622345 and perplexity is 54.79937266795828
At time: 912.4072985649109 and batch: 550, loss is 3.9921596956253054 and perplexity is 54.17175762592309
At time: 913.6039142608643 and batch: 600, loss is 3.936280093193054 and perplexity is 51.22768421258745
At time: 914.8066711425781 and batch: 650, loss is 3.9447818899154665 and perplexity is 51.66506821071727
At time: 916.0037093162537 and batch: 700, loss is 3.9542201566696167 and perplexity is 52.155005348061714
At time: 917.199720621109 and batch: 750, loss is 3.901898560523987 and perplexity is 49.49633173791983
At time: 918.3942084312439 and batch: 800, loss is 3.8747986936569214 and perplexity is 48.17299978452437
At time: 919.5910375118256 and batch: 850, loss is 3.853743233680725 and perplexity is 47.16929888846999
At time: 920.7873256206512 and batch: 900, loss is 3.874935483932495 and perplexity is 48.179589833157124
At time: 921.9837560653687 and batch: 950, loss is 3.8490733814239504 and perplexity is 46.949538754652096
At time: 923.1799516677856 and batch: 1000, loss is 3.847410798072815 and perplexity is 46.871546085797
At time: 924.3765790462494 and batch: 1050, loss is 3.7769575405120848 and perplexity is 43.6829357910698
At time: 925.5728850364685 and batch: 1100, loss is 3.746060304641724 and perplexity is 42.35389144685124
At time: 926.7696802616119 and batch: 1150, loss is 3.7697587871551512 and perplexity is 43.369602268906334
At time: 927.9727730751038 and batch: 1200, loss is 3.734528856277466 and perplexity is 41.86829493115599
At time: 929.1692526340485 and batch: 1250, loss is 3.7827597188949587 and perplexity is 43.93712869999541
At time: 930.3655662536621 and batch: 1300, loss is 3.76169246673584 and perplexity is 43.021176307478676
At time: 931.5626299381256 and batch: 1350, loss is 3.7417271184921264 and perplexity is 42.1707612063085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572148844401042 and perplexity of 96.75179110009763
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 935.002213716507 and batch: 50, loss is 4.0330220079422 and perplexity is 56.43118932902083
At time: 936.1777098178864 and batch: 100, loss is 4.039845266342163 and perplexity is 56.817550537832645
At time: 937.3724370002747 and batch: 150, loss is 4.006909632682801 and perplexity is 54.97670954248265
At time: 938.56858253479 and batch: 200, loss is 4.0009486198425295 and perplexity is 54.64996749528168
At time: 939.7930727005005 and batch: 250, loss is 3.9854888248443605 and perplexity is 53.811587490685
At time: 940.9889914989471 and batch: 300, loss is 3.99213152885437 and perplexity is 54.17023180392373
At time: 942.1908180713654 and batch: 350, loss is 3.989571866989136 and perplexity is 54.031751634157786
At time: 943.386157989502 and batch: 400, loss is 3.993452343940735 and perplexity is 54.24182793553901
At time: 944.5876870155334 and batch: 450, loss is 3.9333194208145144 and perplexity is 51.07624012171566
At time: 945.7828278541565 and batch: 500, loss is 4.003651781082153 and perplexity is 54.79789501505397
At time: 946.9785189628601 and batch: 550, loss is 3.9921268033981323 and perplexity is 54.16997582546875
At time: 948.1735851764679 and batch: 600, loss is 3.9362266063690186 and perplexity is 51.22494427973203
At time: 949.369194984436 and batch: 650, loss is 3.944744987487793 and perplexity is 51.66316167945241
At time: 950.5644495487213 and batch: 700, loss is 3.954186773300171 and perplexity is 52.15326426731147
At time: 951.7618055343628 and batch: 750, loss is 3.9018688297271726 and perplexity is 49.49486019441307
At time: 952.9567801952362 and batch: 800, loss is 3.8747727203369142 and perplexity is 48.1717485880342
At time: 954.1515793800354 and batch: 850, loss is 3.8537124395370483 and perplexity is 47.16784637266749
At time: 955.3463916778564 and batch: 900, loss is 3.874900932312012 and perplexity is 48.177925179012576
At time: 956.5416357517242 and batch: 950, loss is 3.849039902687073 and perplexity is 46.947966969708446
At time: 957.7369680404663 and batch: 1000, loss is 3.8473692417144774 and perplexity is 46.869598315503424
At time: 958.932678937912 and batch: 1050, loss is 3.7769089698791505 and perplexity is 43.680814134755515
At time: 960.1279649734497 and batch: 1100, loss is 3.7460004758834837 and perplexity is 42.351357541920294
At time: 961.3227398395538 and batch: 1150, loss is 3.769692840576172 and perplexity is 43.366742286309076
At time: 962.5183985233307 and batch: 1200, loss is 3.73446261882782 and perplexity is 41.86552177392316
At time: 963.713351726532 and batch: 1250, loss is 3.7826882076263426 and perplexity is 43.93398681252425
At time: 964.9087579250336 and batch: 1300, loss is 3.7616290712356566 and perplexity is 43.0184490449372
At time: 966.1037719249725 and batch: 1350, loss is 3.7416754817962645 and perplexity is 42.168583703757825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572150065104167 and perplexity of 96.7519092053835
Annealing...
Model not improving. Stopping early with 96.72565401050375loss at 27 epochs.
Finished Training.
Improved accuracyfrom -99.47447942221514 to -96.72565401050375
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77ca218eb8>
SETTINGS FOR THIS RUN
{'dropout': 0.6288785410858434, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 10.020794858963564, 'wordvec_source': '', 'anneal': 7.111214822875256, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.542309284210205 and batch: 50, loss is 7.26647985458374 and perplexity is 1431.5024765623764
At time: 2.6149404048919678 and batch: 100, loss is 6.535675973892212 and perplexity is 689.2995753917481
At time: 3.726768970489502 and batch: 150, loss is 6.352711114883423 and perplexity is 574.04690837227
At time: 4.804652690887451 and batch: 200, loss is 6.249288568496704 and perplexity is 517.644425086834
At time: 5.882586479187012 and batch: 250, loss is 6.235987911224365 and perplexity is 510.804999257767
At time: 6.960913181304932 and batch: 300, loss is 6.220032548904419 and perplexity is 502.71959472598155
At time: 8.039139747619629 and batch: 350, loss is 6.198803358078003 and perplexity is 492.1597495894387
At time: 9.12440800666809 and batch: 400, loss is 6.221354999542236 and perplexity is 503.3848563655552
At time: 10.203150272369385 and batch: 450, loss is 6.176850662231446 and perplexity is 481.4732442666589
At time: 11.282299518585205 and batch: 500, loss is 6.165108060836792 and perplexity is 475.85256118312185
At time: 12.367141723632812 and batch: 550, loss is 6.115578088760376 and perplexity is 452.8577636995157
At time: 13.455349683761597 and batch: 600, loss is 6.063167667388916 and perplexity is 429.734539216497
At time: 14.542598962783813 and batch: 650, loss is 6.085667533874512 and perplexity is 439.5131046566767
At time: 15.631123304367065 and batch: 700, loss is 6.087532587051392 and perplexity is 440.3335848505618
At time: 16.719071865081787 and batch: 750, loss is 6.05978907585144 and perplexity is 428.2850916633301
At time: 17.81613326072693 and batch: 800, loss is 6.020059194564819 and perplexity is 411.60295966362787
At time: 18.96322751045227 and batch: 850, loss is 6.015790843963623 and perplexity is 409.84983805378164
At time: 20.159986972808838 and batch: 900, loss is 6.038334054946899 and perplexity is 419.1940985188169
At time: 21.362393856048584 and batch: 950, loss is 6.0120306396484375 and perplexity is 408.3116127572834
At time: 22.563887357711792 and batch: 1000, loss is 6.02035002708435 and perplexity is 411.72268459854166
At time: 23.765066146850586 and batch: 1050, loss is 6.000010805130005 and perplexity is 403.43315261684694
At time: 24.967162370681763 and batch: 1100, loss is 5.98892560005188 and perplexity is 398.9857093375694
At time: 26.168960094451904 and batch: 1150, loss is 5.981185674667358 and perplexity is 395.90950985204825
At time: 27.37018609046936 and batch: 1200, loss is 5.960616111755371 and perplexity is 387.8490089741177
At time: 28.57230281829834 and batch: 1250, loss is 5.962984943389893 and perplexity is 388.76884701659156
At time: 29.774143934249878 and batch: 1300, loss is 5.9372868156433105 and perplexity is 378.9054931875654
At time: 30.976381540298462 and batch: 1350, loss is 5.914850187301636 and perplexity is 370.49879312248135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.351418050130208 and perplexity of 210.90716284356546
Finished 1 epochs...
Completing Train Step...
At time: 34.47772479057312 and batch: 50, loss is 5.657487564086914 and perplexity is 286.42810552468217
At time: 35.67338299751282 and batch: 100, loss is 5.603159790039062 and perplexity is 271.2822495232239
At time: 36.89594769477844 and batch: 150, loss is 5.490056657791138 and perplexity is 242.27093300502486
At time: 38.0962610244751 and batch: 200, loss is 5.4488397884368895 and perplexity is 232.4882737884213
At time: 39.29640293121338 and batch: 250, loss is 5.467410612106323 and perplexity is 236.84611160307327
At time: 40.49176645278931 and batch: 300, loss is 5.428182182312011 and perplexity is 227.73488841702138
At time: 41.6885244846344 and batch: 350, loss is 5.428477506637574 and perplexity is 227.80215400144294
At time: 42.88585138320923 and batch: 400, loss is 5.448887414932251 and perplexity is 232.49934665379334
At time: 44.0841269493103 and batch: 450, loss is 5.404606370925904 and perplexity is 222.42864886647337
At time: 45.279831647872925 and batch: 500, loss is 5.425294313430786 and perplexity is 227.07816863631032
At time: 46.4764621257782 and batch: 550, loss is 5.389459648132324 and perplexity is 219.08497059092406
At time: 47.67272686958313 and batch: 600, loss is 5.339697036743164 and perplexity is 208.44954816767958
At time: 48.868099212646484 and batch: 650, loss is 5.36330361366272 and perplexity is 213.42886959388744
At time: 50.06407880783081 and batch: 700, loss is 5.375158224105835 and perplexity is 215.97404190698023
At time: 51.26034069061279 and batch: 750, loss is 5.33397159576416 and perplexity is 207.25949262981743
At time: 52.45751214027405 and batch: 800, loss is 5.2948308849334715 and perplexity is 199.30391782105178
At time: 53.6532940864563 and batch: 850, loss is 5.293701515197754 and perplexity is 199.0789570639012
At time: 54.84829878807068 and batch: 900, loss is 5.3382753658294675 and perplexity is 208.15341206199824
At time: 56.04395532608032 and batch: 950, loss is 5.290932207107544 and perplexity is 198.52840876828742
At time: 57.23928618431091 and batch: 1000, loss is 5.311677322387696 and perplexity is 202.68991976271113
At time: 58.435036420822144 and batch: 1050, loss is 5.267698564529419 and perplexity is 193.9690411309205
At time: 59.63251805305481 and batch: 1100, loss is 5.254419784545899 and perplexity is 191.41039436010945
At time: 60.82893395423889 and batch: 1150, loss is 5.262843170166016 and perplexity is 193.02952764192847
At time: 62.02471423149109 and batch: 1200, loss is 5.248646831512451 and perplexity is 190.30857458030093
At time: 63.22041344642639 and batch: 1250, loss is 5.278037700653076 and perplexity is 195.9849166992237
At time: 64.41727566719055 and batch: 1300, loss is 5.239197931289673 and perplexity is 188.51883669080985
At time: 65.61343550682068 and batch: 1350, loss is 5.210324382781982 and perplexity is 183.15346038768303
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.043249104817709 and perplexity of 154.9727205250909
Finished 2 epochs...
Completing Train Step...
At time: 69.06494522094727 and batch: 50, loss is 5.235709161758423 and perplexity is 187.8622838639818
At time: 70.2858338356018 and batch: 100, loss is 5.256613149642944 and perplexity is 191.8306879985116
At time: 71.4867730140686 and batch: 150, loss is 5.1931053829193115 and perplexity is 180.02673775089522
At time: 72.68237948417664 and batch: 200, loss is 5.177846794128418 and perplexity is 177.30063492099256
At time: 73.87964677810669 and batch: 250, loss is 5.201090421676636 and perplexity is 181.47001286435486
At time: 75.07428359985352 and batch: 300, loss is 5.194082336425781 and perplexity is 180.20270144377716
At time: 76.27003407478333 and batch: 350, loss is 5.193117475509643 and perplexity is 180.0289147536464
At time: 77.46566653251648 and batch: 400, loss is 5.203657245635986 and perplexity is 181.93641276842666
At time: 78.67187714576721 and batch: 450, loss is 5.172632789611816 and perplexity is 176.37859446015148
At time: 79.86695528030396 and batch: 500, loss is 5.222822847366333 and perplexity is 185.45696255992792
At time: 81.06228709220886 and batch: 550, loss is 5.190564489364624 and perplexity is 179.56988962029737
At time: 82.25739002227783 and batch: 600, loss is 5.148405675888061 and perplexity is 172.15679766692827
At time: 83.45314621925354 and batch: 650, loss is 5.177787361145019 and perplexity is 177.29009772843222
At time: 84.64985370635986 and batch: 700, loss is 5.183077116012573 and perplexity is 178.23040368727456
At time: 85.84662628173828 and batch: 750, loss is 5.1465256690979 and perplexity is 171.8334457654658
At time: 87.0420708656311 and batch: 800, loss is 5.107559633255005 and perplexity is 165.2665513637935
At time: 88.23851895332336 and batch: 850, loss is 5.094030666351318 and perplexity is 163.0457222952271
At time: 89.43507218360901 and batch: 900, loss is 5.144996280670166 and perplexity is 171.5708465413073
At time: 90.63146662712097 and batch: 950, loss is 5.100967025756836 and perplexity is 164.1805974252989
At time: 91.8337414264679 and batch: 1000, loss is 5.122855834960937 and perplexity is 167.81393484626338
At time: 93.07688021659851 and batch: 1050, loss is 5.081351404190063 and perplexity is 160.99147353788777
At time: 94.27780055999756 and batch: 1100, loss is 5.0845525932312015 and perplexity is 161.50766344862723
At time: 95.47537899017334 and batch: 1150, loss is 5.0900350761413575 and perplexity is 162.3955581631438
At time: 96.67404055595398 and batch: 1200, loss is 5.077804498672485 and perplexity is 160.42146347561666
At time: 97.87180781364441 and batch: 1250, loss is 5.118042211532593 and perplexity is 167.00808284794473
At time: 99.06870770454407 and batch: 1300, loss is 5.083970994949341 and perplexity is 161.4137581792768
At time: 100.265389919281 and batch: 1350, loss is 5.051890392303466 and perplexity is 156.3176871077967
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.995632731119792 and perplexity of 147.76641221813742
Finished 3 epochs...
Completing Train Step...
At time: 103.7408218383789 and batch: 50, loss is 5.094743299484253 and perplexity is 163.16195549001176
At time: 104.94379305839539 and batch: 100, loss is 5.115521135330201 and perplexity is 166.5875730360333
At time: 106.14818906784058 and batch: 150, loss is 5.065174570083618 and perplexity is 158.4080929741377
At time: 107.35157012939453 and batch: 200, loss is 5.046981019973755 and perplexity is 155.55214608061772
At time: 108.54982423782349 and batch: 250, loss is 5.07121768951416 and perplexity is 159.36827030982053
At time: 109.74851512908936 and batch: 300, loss is 5.062561645507812 and perplexity is 157.99472486003597
At time: 110.95250821113586 and batch: 350, loss is 5.0679159832000735 and perplexity is 158.84295078808492
At time: 112.15096998214722 and batch: 400, loss is 5.082688369750977 and perplexity is 161.2068575420237
At time: 113.34897255897522 and batch: 450, loss is 5.042513132095337 and perplexity is 154.8587067907183
At time: 114.54655885696411 and batch: 500, loss is 5.103483428955078 and perplexity is 164.59426226122045
At time: 115.74442052841187 and batch: 550, loss is 5.076444072723389 and perplexity is 160.2033703373312
At time: 116.9417359828949 and batch: 600, loss is 5.034968366622925 and perplexity is 153.6947306515737
At time: 118.13882088661194 and batch: 650, loss is 5.061075830459595 and perplexity is 157.760148232197
At time: 119.33628797531128 and batch: 700, loss is 5.070222797393799 and perplexity is 159.20979491948398
At time: 120.53298377990723 and batch: 750, loss is 5.0278534412384035 and perplexity is 152.605085081139
At time: 121.73796105384827 and batch: 800, loss is 4.9935606098175045 and perplexity is 147.46053929995594
At time: 122.95978808403015 and batch: 850, loss is 4.989063692092896 and perplexity is 146.79891014799773
At time: 124.15566158294678 and batch: 900, loss is 5.040734415054321 and perplexity is 154.5835017984633
At time: 125.3523256778717 and batch: 950, loss is 4.991726875305176 and perplexity is 147.190383592459
At time: 126.54813957214355 and batch: 1000, loss is 5.026183214187622 and perplexity is 152.35041267952087
At time: 127.74496269226074 and batch: 1050, loss is 4.977537088394165 and perplexity is 145.11653196764698
At time: 128.94566297531128 and batch: 1100, loss is 4.981140155792236 and perplexity is 145.64033970351204
At time: 130.14164757728577 and batch: 1150, loss is 4.976590824127197 and perplexity is 144.9792783282486
At time: 131.33794903755188 and batch: 1200, loss is 4.954815921783447 and perplexity is 141.85649127950106
At time: 132.5346212387085 and batch: 1250, loss is 4.997549324035645 and perplexity is 148.0498918477445
At time: 133.73727560043335 and batch: 1300, loss is 4.965511083602905 and perplexity is 143.3818116432925
At time: 134.9341905117035 and batch: 1350, loss is 4.938686828613282 and perplexity is 139.58682772607628
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.968235677083333 and perplexity of 143.7730014671328
Finished 4 epochs...
Completing Train Step...
At time: 138.41786742210388 and batch: 50, loss is 4.997349786758423 and perplexity is 148.02035332254863
At time: 139.59855961799622 and batch: 100, loss is 5.014154071807861 and perplexity is 150.52874638166324
At time: 140.77948331832886 and batch: 150, loss is 4.970751523971558 and perplexity is 144.1351677118673
At time: 141.9661226272583 and batch: 200, loss is 4.948434047698974 and perplexity is 140.95406366664906
At time: 143.16254210472107 and batch: 250, loss is 4.9700299263000485 and perplexity is 144.03119762726078
At time: 144.35820055007935 and batch: 300, loss is 4.967203607559204 and perplexity is 143.624694278755
At time: 145.55954432487488 and batch: 350, loss is 4.971682052612305 and perplexity is 144.26935203505775
At time: 146.7567811012268 and batch: 400, loss is 4.976530055999756 and perplexity is 144.97046847666863
At time: 147.9534044265747 and batch: 450, loss is 4.938505868911744 and perplexity is 139.56157042073846
At time: 149.150141954422 and batch: 500, loss is 5.012948169708252 and perplexity is 150.3473328558101
At time: 150.34654569625854 and batch: 550, loss is 4.980176467895507 and perplexity is 145.5000554768268
At time: 151.54419922828674 and batch: 600, loss is 4.938979177474976 and perplexity is 139.62764174194436
At time: 152.74053192138672 and batch: 650, loss is 4.966638851165771 and perplexity is 143.5436042146276
At time: 153.9841763973236 and batch: 700, loss is 4.975013103485107 and perplexity is 144.7507218746824
At time: 155.18089365959167 and batch: 750, loss is 4.932935390472412 and perplexity is 138.78630700054984
At time: 156.37820434570312 and batch: 800, loss is 4.9100918674469 and perplexity is 135.6518758275565
At time: 157.5747230052948 and batch: 850, loss is 4.91283860206604 and perplexity is 136.0249877161339
At time: 158.7712483406067 and batch: 900, loss is 4.954774951934814 and perplexity is 141.85067955957922
At time: 159.9678885936737 and batch: 950, loss is 4.911021614074707 and perplexity is 135.7780563505313
At time: 161.16641092300415 and batch: 1000, loss is 4.931370458602905 and perplexity is 138.56928574170627
At time: 162.36300015449524 and batch: 1050, loss is 4.896913833618164 and perplexity is 133.87597794039928
At time: 163.5634322166443 and batch: 1100, loss is 4.888938617706299 and perplexity is 132.81253434366516
At time: 164.75981497764587 and batch: 1150, loss is 4.890035953521728 and perplexity is 132.95835428642894
At time: 165.95744800567627 and batch: 1200, loss is 4.871724376678467 and perplexity is 130.54583311067677
At time: 167.15531301498413 and batch: 1250, loss is 4.909362649917602 and perplexity is 135.55299216005466
At time: 168.35253620147705 and batch: 1300, loss is 4.882070531845093 and perplexity is 131.903491719085
At time: 169.54922342300415 and batch: 1350, loss is 4.863455181121826 and perplexity is 129.47077514584836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.988860677083333 and perplexity of 146.769110790811
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 172.99553394317627 and batch: 50, loss is 4.91604022026062 and perplexity is 136.46118568880746
At time: 174.20221281051636 and batch: 100, loss is 4.91440902709961 and perplexity is 136.23877258465194
At time: 175.3828752040863 and batch: 150, loss is 4.877212324142456 and perplexity is 131.26423124701336
At time: 176.56323409080505 and batch: 200, loss is 4.853186159133911 and perplexity is 128.14804013038582
At time: 177.7447509765625 and batch: 250, loss is 4.857346525192261 and perplexity is 128.68229346110022
At time: 178.93383622169495 and batch: 300, loss is 4.8422422695159915 and perplexity is 126.75324826953718
At time: 180.12470316886902 and batch: 350, loss is 4.832373466491699 and perplexity is 125.50849763161773
At time: 181.32149410247803 and batch: 400, loss is 4.833651762008667 and perplexity is 125.66903716810589
At time: 182.517404794693 and batch: 450, loss is 4.787844600677491 and perplexity is 120.04235041885377
At time: 183.7581729888916 and batch: 500, loss is 4.837951898574829 and perplexity is 126.21059474132572
At time: 184.94950103759766 and batch: 550, loss is 4.813492946624756 and perplexity is 123.16106208327051
At time: 186.1397557258606 and batch: 600, loss is 4.766199340820313 and perplexity is 117.47192170562988
At time: 187.33166480064392 and batch: 650, loss is 4.785619897842407 and perplexity is 119.77558870434184
At time: 188.52809309959412 and batch: 700, loss is 4.76291241645813 and perplexity is 117.08643426539557
At time: 189.7248499393463 and batch: 750, loss is 4.710399961471557 and perplexity is 111.09658537464041
At time: 190.9211127758026 and batch: 800, loss is 4.681503124237061 and perplexity is 107.93218618744203
At time: 192.1181128025055 and batch: 850, loss is 4.653720102310181 and perplexity is 104.97477700603534
At time: 193.32226967811584 and batch: 900, loss is 4.6761407470703125 and perplexity is 107.3549621264125
At time: 194.51923727989197 and batch: 950, loss is 4.628539924621582 and perplexity is 102.36449506715414
At time: 195.71491622924805 and batch: 1000, loss is 4.636162014007568 and perplexity is 103.14770746415168
At time: 196.91853666305542 and batch: 1050, loss is 4.585759878158569 and perplexity is 98.07768592490241
At time: 198.11661624908447 and batch: 1100, loss is 4.551283168792724 and perplexity is 94.75391560856575
At time: 199.31391596794128 and batch: 1150, loss is 4.546460733413697 and perplexity is 94.29807099764518
At time: 200.51144647598267 and batch: 1200, loss is 4.503863401412964 and perplexity is 90.36557627077083
At time: 201.70821952819824 and batch: 1250, loss is 4.529472913742065 and perplexity is 92.70968220208417
At time: 202.9115400314331 and batch: 1300, loss is 4.4796622848510745 and perplexity is 88.20487952111141
At time: 204.10819506645203 and batch: 1350, loss is 4.4544343090057374 and perplexity is 86.00748342226362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.825940348307292 and perplexity of 124.70367815822073
Finished 6 epochs...
Completing Train Step...
At time: 207.53354740142822 and batch: 50, loss is 4.759932413101196 and perplexity is 116.73803567055144
At time: 208.73004508018494 and batch: 100, loss is 4.773252096176147 and perplexity is 118.30335091764815
At time: 209.9069709777832 and batch: 150, loss is 4.740404634475708 and perplexity is 114.48051507272437
At time: 211.08691120147705 and batch: 200, loss is 4.724512720108033 and perplexity is 112.67558045028665
At time: 212.2755045890808 and batch: 250, loss is 4.734375801086426 and perplexity is 113.79240744835204
At time: 213.49800157546997 and batch: 300, loss is 4.723273906707764 and perplexity is 112.53608285492709
At time: 214.6944341659546 and batch: 350, loss is 4.720931968688965 and perplexity is 112.27283869507286
At time: 215.89080452919006 and batch: 400, loss is 4.722441749572754 and perplexity is 112.44247410462992
At time: 217.08706283569336 and batch: 450, loss is 4.680024328231812 and perplexity is 107.77269445860121
At time: 218.2826874256134 and batch: 500, loss is 4.739460306167603 and perplexity is 114.37245890989138
At time: 219.47906160354614 and batch: 550, loss is 4.721807937622071 and perplexity is 112.371229301067
At time: 220.6758201122284 and batch: 600, loss is 4.6761214065551755 and perplexity is 107.3528858462207
At time: 221.87282347679138 and batch: 650, loss is 4.6971821594238286 and perplexity is 109.63779494131481
At time: 223.07030320167542 and batch: 700, loss is 4.684016122817993 and perplexity is 108.20376070844117
At time: 224.2664453983307 and batch: 750, loss is 4.634599590301514 and perplexity is 102.9866728756732
At time: 225.46231245994568 and batch: 800, loss is 4.6078087329864506 and perplexity is 100.26420310270744
At time: 226.65807461738586 and batch: 850, loss is 4.58869776725769 and perplexity is 98.36625096774003
At time: 227.85534143447876 and batch: 900, loss is 4.612190132141113 and perplexity is 100.70446437330877
At time: 229.05222535133362 and batch: 950, loss is 4.57144323348999 and perplexity is 96.68354606068738
At time: 230.25025916099548 and batch: 1000, loss is 4.583922872543335 and perplexity is 97.89768204981372
At time: 231.4470031261444 and batch: 1050, loss is 4.5382709884643555 and perplexity is 93.52894760803456
At time: 232.64308977127075 and batch: 1100, loss is 4.509506454467774 and perplexity is 90.87695552509547
At time: 233.839670419693 and batch: 1150, loss is 4.514790182113647 and perplexity is 91.35839538586694
At time: 235.0362105369568 and batch: 1200, loss is 4.478877143859863 and perplexity is 88.13565343424995
At time: 236.23241519927979 and batch: 1250, loss is 4.512516031265259 and perplexity is 91.15086867645375
At time: 237.43525004386902 and batch: 1300, loss is 4.469973487854004 and perplexity is 87.35440702994771
At time: 238.6317217350006 and batch: 1350, loss is 4.452315883636475 and perplexity is 85.8254758402417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.812150065104166 and perplexity of 122.99578236931738
Finished 7 epochs...
Completing Train Step...
At time: 242.1002802848816 and batch: 50, loss is 4.704821557998657 and perplexity is 110.47856917147452
At time: 243.28022146224976 and batch: 100, loss is 4.715999307632447 and perplexity is 111.72039845628774
At time: 244.4851791858673 and batch: 150, loss is 4.6823157787323 and perplexity is 108.01993341298781
At time: 245.66536140441895 and batch: 200, loss is 4.665401268005371 and perplexity is 106.20819462291915
At time: 246.8534140586853 and batch: 250, loss is 4.675606126785278 and perplexity is 107.29758332526283
At time: 248.04307985305786 and batch: 300, loss is 4.667840051651001 and perplexity is 106.4675295333301
At time: 249.23879027366638 and batch: 350, loss is 4.668028526306152 and perplexity is 106.48759785536932
At time: 250.43498134613037 and batch: 400, loss is 4.6682973480224605 and perplexity is 106.51622788220443
At time: 251.63071537017822 and batch: 450, loss is 4.626683025360108 and perplexity is 102.17459088289948
At time: 252.82681393623352 and batch: 500, loss is 4.6899333000183105 and perplexity is 108.84591954444838
At time: 254.02278304100037 and batch: 550, loss is 4.6740701961517335 and perplexity is 107.13290817730392
At time: 255.21993207931519 and batch: 600, loss is 4.628856754302978 and perplexity is 102.39693231578278
At time: 256.4159617424011 and batch: 650, loss is 4.648557519912719 and perplexity is 104.4342325732337
At time: 257.6121115684509 and batch: 700, loss is 4.640837574005127 and perplexity is 103.63110996708112
At time: 258.80864548683167 and batch: 750, loss is 4.592202863693237 and perplexity is 98.7116391191632
At time: 260.0056805610657 and batch: 800, loss is 4.567634057998657 and perplexity is 96.31596200716638
At time: 261.2042455673218 and batch: 850, loss is 4.550286684036255 and perplexity is 94.6595418048837
At time: 262.40051436424255 and batch: 900, loss is 4.575736875534058 and perplexity is 97.09956307397422
At time: 263.59694719314575 and batch: 950, loss is 4.538724813461304 and perplexity is 93.57140301533124
At time: 264.8037874698639 and batch: 1000, loss is 4.553752002716064 and perplexity is 94.98813629681246
At time: 266.0012969970703 and batch: 1050, loss is 4.509114608764649 and perplexity is 90.8413527564114
At time: 267.19780564308167 and batch: 1100, loss is 4.483143129348755 and perplexity is 88.51244196864499
At time: 268.39368295669556 and batch: 1150, loss is 4.492524375915528 and perplexity is 89.3467061113227
At time: 269.5897901058197 and batch: 1200, loss is 4.4574951076507565 and perplexity is 86.27113830239664
At time: 270.78506803512573 and batch: 1250, loss is 4.496769075393677 and perplexity is 89.72676206915352
At time: 271.9813904762268 and batch: 1300, loss is 4.455791730880737 and perplexity is 86.12431113598292
At time: 273.17753195762634 and batch: 1350, loss is 4.441638031005859 and perplexity is 84.91391945068867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.806432698567709 and perplexity of 122.29457683370504
Finished 8 epochs...
Completing Train Step...
At time: 276.63742423057556 and batch: 50, loss is 4.663763217926025 and perplexity is 106.03436269286225
At time: 277.81044697761536 and batch: 100, loss is 4.673510475158691 and perplexity is 107.07296041812614
At time: 278.98869800567627 and batch: 150, loss is 4.642031421661377 and perplexity is 103.75490360549912
At time: 280.1740303039551 and batch: 200, loss is 4.622795248031617 and perplexity is 101.77813000010218
At time: 281.36986923217773 and batch: 250, loss is 4.633084135055542 and perplexity is 102.83071938211549
At time: 282.5664768218994 and batch: 300, loss is 4.627772607803345 and perplexity is 102.28597919562546
At time: 283.7656464576721 and batch: 350, loss is 4.629668016433715 and perplexity is 102.48003677446644
At time: 284.9617540836334 and batch: 400, loss is 4.627115516662598 and perplexity is 102.21879006198314
At time: 286.16016840934753 and batch: 450, loss is 4.588875017166138 and perplexity is 98.38368792202202
At time: 287.36097478866577 and batch: 500, loss is 4.6541124534606935 and perplexity is 105.01597206150372
At time: 288.5565617084503 and batch: 550, loss is 4.6386253356933596 and perplexity is 103.40210665366779
At time: 289.7524163722992 and batch: 600, loss is 4.592725028991699 and perplexity is 98.76319637119803
At time: 290.9511194229126 and batch: 650, loss is 4.613218851089478 and perplexity is 100.80811426815919
At time: 292.1491799354553 and batch: 700, loss is 4.608209733963013 and perplexity is 100.3044172084748
At time: 293.34575748443604 and batch: 750, loss is 4.558247795104981 and perplexity is 95.41614463441253
At time: 294.5411043167114 and batch: 800, loss is 4.538335390090943 and perplexity is 93.53497121835657
At time: 295.7367784976959 and batch: 850, loss is 4.522498540878296 and perplexity is 92.06533986401698
At time: 296.93345880508423 and batch: 900, loss is 4.547953090667725 and perplexity is 94.43890246723447
At time: 298.12982273101807 and batch: 950, loss is 4.514119987487793 and perplexity is 91.29718799297653
At time: 299.3262665271759 and batch: 1000, loss is 4.52820011138916 and perplexity is 92.5917561646295
At time: 300.5219976902008 and batch: 1050, loss is 4.4837679767608645 and perplexity is 88.56776602169425
At time: 301.7179329395294 and batch: 1100, loss is 4.460393972396851 and perplexity is 86.52158950051418
At time: 302.9139132499695 and batch: 1150, loss is 4.4717667770385745 and perplexity is 87.51119928821075
At time: 304.15953159332275 and batch: 1200, loss is 4.437146215438843 and perplexity is 84.53335713317949
At time: 305.35064578056335 and batch: 1250, loss is 4.479363412857055 and perplexity is 88.17852149192129
At time: 306.5423834323883 and batch: 1300, loss is 4.440408687591553 and perplexity is 84.80959522131984
At time: 307.7383999824524 and batch: 1350, loss is 4.427992830276489 and perplexity is 83.76312126685667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.802978922526042 and perplexity of 121.87292731485363
Finished 9 epochs...
Completing Train Step...
At time: 311.1447606086731 and batch: 50, loss is 4.630740671157837 and perplexity is 102.5900214472846
At time: 312.3400983810425 and batch: 100, loss is 4.6413602447509765 and perplexity is 103.68528907430458
At time: 313.51958870887756 and batch: 150, loss is 4.610741205215454 and perplexity is 100.55865662124214
At time: 314.7144196033478 and batch: 200, loss is 4.590482501983643 and perplexity is 98.54196538687518
At time: 315.90907287597656 and batch: 250, loss is 4.600804862976074 and perplexity is 99.56441911613008
At time: 317.10411405563354 and batch: 300, loss is 4.596621866226196 and perplexity is 99.1488113235932
At time: 318.2986340522766 and batch: 350, loss is 4.60036340713501 and perplexity is 99.52047552204093
At time: 319.4932565689087 and batch: 400, loss is 4.596810312271118 and perplexity is 99.1674972855383
At time: 320.6879904270172 and batch: 450, loss is 4.559521226882935 and perplexity is 95.53772798273933
At time: 321.8832507133484 and batch: 500, loss is 4.626037454605102 and perplexity is 102.10865124176289
At time: 323.07979369163513 and batch: 550, loss is 4.61208740234375 and perplexity is 100.69411955545976
At time: 324.2746057510376 and batch: 600, loss is 4.565473785400391 and perplexity is 96.10811785451067
At time: 325.4702606201172 and batch: 650, loss is 4.5837758350372315 and perplexity is 97.8832884770153
At time: 326.665625333786 and batch: 700, loss is 4.582076101303101 and perplexity is 97.7170542665531
At time: 327.8603594303131 and batch: 750, loss is 4.53343243598938 and perplexity is 93.07749595412893
At time: 329.05538153648376 and batch: 800, loss is 4.515265092849732 and perplexity is 91.40179277279397
At time: 330.2505831718445 and batch: 850, loss is 4.5003448009490965 and perplexity is 90.04817464440885
At time: 331.4459707736969 and batch: 900, loss is 4.525333490371704 and perplexity is 92.3267107642237
At time: 332.6404564380646 and batch: 950, loss is 4.493399181365967 and perplexity is 89.42490129460715
At time: 333.8366770744324 and batch: 1000, loss is 4.507356796264649 and perplexity is 90.68181095438693
At time: 335.0577561855316 and batch: 1050, loss is 4.462753524780274 and perplexity is 86.72598276671712
At time: 336.25367856025696 and batch: 1100, loss is 4.440114841461182 and perplexity is 84.7846779110526
At time: 337.44797706604004 and batch: 1150, loss is 4.454318323135376 and perplexity is 85.99750834793632
At time: 338.6432375907898 and batch: 1200, loss is 4.418771409988404 and perplexity is 82.99425678063126
At time: 339.8384220600128 and batch: 1250, loss is 4.4628869247436525 and perplexity is 86.7375527813448
At time: 341.03403973579407 and batch: 1300, loss is 4.425428228378296 and perplexity is 83.54857743440824
At time: 342.2301914691925 and batch: 1350, loss is 4.413694705963135 and perplexity is 82.57398719793086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.800857747395833 and perplexity of 121.61468747517706
Finished 10 epochs...
Completing Train Step...
At time: 345.67575550079346 and batch: 50, loss is 4.6028044891357425 and perplexity is 99.76370992031418
At time: 346.89049458503723 and batch: 100, loss is 4.61312165260315 and perplexity is 100.79831634822195
At time: 348.0800995826721 and batch: 150, loss is 4.584198961257934 and perplexity is 97.92471422648089
At time: 349.2715060710907 and batch: 200, loss is 4.563342924118042 and perplexity is 95.90354282516702
At time: 350.4683451652527 and batch: 250, loss is 4.573626222610474 and perplexity is 96.8948357274822
At time: 351.66598629951477 and batch: 300, loss is 4.570220050811767 and perplexity is 96.56535672018978
At time: 352.8632392883301 and batch: 350, loss is 4.575078048706055 and perplexity is 97.03561234537472
At time: 354.0610992908478 and batch: 400, loss is 4.570228776931763 and perplexity is 96.56619936475643
At time: 355.2591016292572 and batch: 450, loss is 4.534470624923706 and perplexity is 93.17417815897696
At time: 356.4628767967224 and batch: 500, loss is 4.601360921859741 and perplexity is 99.61979819146323
At time: 357.6597692966461 and batch: 550, loss is 4.588286333084106 and perplexity is 98.32578805504788
At time: 358.8571174144745 and batch: 600, loss is 4.541117153167725 and perplexity is 93.79552557991231
At time: 360.0562551021576 and batch: 650, loss is 4.5596152019500735 and perplexity is 95.54670656901581
At time: 361.2574653625488 and batch: 700, loss is 4.5589469623565675 and perplexity is 95.48287980481788
At time: 362.45457434654236 and batch: 750, loss is 4.511142807006836 and perplexity is 91.02578399672572
At time: 363.6515016555786 and batch: 800, loss is 4.492281951904297 and perplexity is 89.32504894965102
At time: 364.8938248157501 and batch: 850, loss is 4.480880336761475 and perplexity is 88.31238310229845
At time: 366.09591245651245 and batch: 900, loss is 4.5059104347229 and perplexity is 90.55074707621127
At time: 367.2987542152405 and batch: 950, loss is 4.473760204315186 and perplexity is 87.68582048938846
At time: 368.49507451057434 and batch: 1000, loss is 4.488712930679322 and perplexity is 89.00681418514608
At time: 369.69154810905457 and batch: 1050, loss is 4.443900680541992 and perplexity is 85.10626741710168
At time: 370.88785433769226 and batch: 1100, loss is 4.422068424224854 and perplexity is 83.26834160928959
At time: 372.08472990989685 and batch: 1150, loss is 4.437616338729859 and perplexity is 84.57310757630799
At time: 373.2817385196686 and batch: 1200, loss is 4.403426723480225 and perplexity is 81.73045703153004
At time: 374.47779512405396 and batch: 1250, loss is 4.44778733253479 and perplexity is 85.43768950491014
At time: 375.6814935207367 and batch: 1300, loss is 4.411640596389771 and perplexity is 82.40454526604209
At time: 376.8776571750641 and batch: 1350, loss is 4.399802713394165 and perplexity is 81.43480108455823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.799645182291667 and perplexity of 121.46731111876157
Finished 11 epochs...
Completing Train Step...
At time: 380.33439326286316 and batch: 50, loss is 4.57875503540039 and perplexity is 97.3930677775394
At time: 381.51592922210693 and batch: 100, loss is 4.5881016731262205 and perplexity is 98.30763289548366
At time: 382.70145773887634 and batch: 150, loss is 4.561299972534179 and perplexity is 95.70781652820293
At time: 383.89159393310547 and batch: 200, loss is 4.539883117675782 and perplexity is 93.67984996095059
At time: 385.08267974853516 and batch: 250, loss is 4.550636281967163 and perplexity is 94.69264037009727
At time: 386.28145146369934 and batch: 300, loss is 4.546322965621949 and perplexity is 94.28508065548365
At time: 387.47859239578247 and batch: 350, loss is 4.551975288391113 and perplexity is 94.81951935078153
At time: 388.67576599121094 and batch: 400, loss is 4.547863264083862 and perplexity is 94.43041972423572
At time: 389.8733389377594 and batch: 450, loss is 4.512028961181641 and perplexity is 91.10648262566193
At time: 391.075480222702 and batch: 500, loss is 4.579088735580444 and perplexity is 97.42557328503797
At time: 392.2728090286255 and batch: 550, loss is 4.566673393249512 and perplexity is 96.22347908733907
At time: 393.470223903656 and batch: 600, loss is 4.5196577835083005 and perplexity is 91.80417569892131
At time: 394.6943006515503 and batch: 650, loss is 4.538528146743775 and perplexity is 93.5530024440949
At time: 395.8916380405426 and batch: 700, loss is 4.538156805038452 and perplexity is 93.51826876206071
At time: 397.08904576301575 and batch: 750, loss is 4.491782379150391 and perplexity is 89.28043573365588
At time: 398.28613352775574 and batch: 800, loss is 4.472603235244751 and perplexity is 87.58442937167015
At time: 399.48333191871643 and batch: 850, loss is 4.4628844070434575 and perplexity is 86.73733440246616
At time: 400.68022298812866 and batch: 900, loss is 4.487318553924561 and perplexity is 88.88279163960289
At time: 401.87702441215515 and batch: 950, loss is 4.457319021224976 and perplexity is 86.2559484634064
At time: 403.07398414611816 and batch: 1000, loss is 4.471475811004638 and perplexity is 87.48574020567263
At time: 404.2728352546692 and batch: 1050, loss is 4.426571092605591 and perplexity is 83.64411669860411
At time: 405.47011137008667 and batch: 1100, loss is 4.404368753433228 and perplexity is 81.80748584615526
At time: 406.6675271987915 and batch: 1150, loss is 4.4212586784362795 and perplexity is 83.20094271201924
At time: 407.86529541015625 and batch: 1200, loss is 4.389234142303467 and perplexity is 80.57868353824846
At time: 409.06742763519287 and batch: 1250, loss is 4.433145866394043 and perplexity is 84.19586968258007
At time: 410.26509380340576 and batch: 1300, loss is 4.39677960395813 and perplexity is 81.18898651835731
At time: 411.46171259880066 and batch: 1350, loss is 4.385589103698731 and perplexity is 80.2855057727734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.799459228515625 and perplexity of 121.44472591356052
Finished 12 epochs...
Completing Train Step...
At time: 414.9337100982666 and batch: 50, loss is 4.556339406967163 and perplexity is 95.2342272355501
At time: 416.1102488040924 and batch: 100, loss is 4.565652723312378 and perplexity is 96.12531677916851
At time: 417.3008234500885 and batch: 150, loss is 4.538903141021729 and perplexity is 93.58809086326389
At time: 418.49078345298767 and batch: 200, loss is 4.5197461891174315 and perplexity is 91.81229206175546
At time: 419.68279480934143 and batch: 250, loss is 4.529669256210327 and perplexity is 92.72788683703247
At time: 420.8795726299286 and batch: 300, loss is 4.525797319412232 and perplexity is 92.3695445068915
At time: 422.083359003067 and batch: 350, loss is 4.531627054214478 and perplexity is 92.90960713658694
At time: 423.28056383132935 and batch: 400, loss is 4.526779508590698 and perplexity is 92.46031344276227
At time: 424.4774134159088 and batch: 450, loss is 4.4912162780761715 and perplexity is 89.2299082862508
At time: 425.70026993751526 and batch: 500, loss is 4.559000511169433 and perplexity is 95.48799293658028
At time: 426.89697670936584 and batch: 550, loss is 4.546236219406128 and perplexity is 94.27690213626141
At time: 428.0940012931824 and batch: 600, loss is 4.499758358001709 and perplexity is 89.99538200891091
At time: 429.29097604751587 and batch: 650, loss is 4.518771209716797 and perplexity is 91.7228205917778
At time: 430.4880061149597 and batch: 700, loss is 4.5198385047912595 and perplexity is 91.82076816659547
At time: 431.6838917732239 and batch: 750, loss is 4.472980594635009 and perplexity is 87.61748641533461
At time: 432.8838667869568 and batch: 800, loss is 4.454477214813233 and perplexity is 86.01117372195758
At time: 434.0815758705139 and batch: 850, loss is 4.445000839233399 and perplexity is 85.19994933993561
At time: 435.27847814559937 and batch: 900, loss is 4.470149641036987 and perplexity is 87.36979614217442
At time: 436.474728345871 and batch: 950, loss is 4.440663261413574 and perplexity is 84.83118827251555
At time: 437.67146587371826 and batch: 1000, loss is 4.454944496154785 and perplexity is 86.05137453041522
At time: 438.87558364868164 and batch: 1050, loss is 4.41093861579895 and perplexity is 82.34671917344188
At time: 440.07305431365967 and batch: 1100, loss is 4.3886134147644045 and perplexity is 80.52868165069466
At time: 441.2698953151703 and batch: 1150, loss is 4.40560733795166 and perplexity is 81.90887410762014
At time: 442.4717447757721 and batch: 1200, loss is 4.373675394058227 and perplexity is 79.33468272982836
At time: 443.6700699329376 and batch: 1250, loss is 4.418847742080689 and perplexity is 83.00059214769182
At time: 444.8677291870117 and batch: 1300, loss is 4.383320751190186 and perplexity is 80.10359633971342
At time: 446.06619453430176 and batch: 1350, loss is 4.371363229751587 and perplexity is 79.15145981051631
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.800120849609375 and perplexity of 121.52510289256993
Annealing...
Finished 13 epochs...
Completing Train Step...
At time: 449.490496635437 and batch: 50, loss is 4.543653564453125 and perplexity is 94.03373157599579
At time: 450.6895570755005 and batch: 100, loss is 4.559511251449585 and perplexity is 95.53677495725489
At time: 451.8736264705658 and batch: 150, loss is 4.536230716705322 and perplexity is 93.33831767214319
At time: 453.0661311149597 and batch: 200, loss is 4.516080932617188 and perplexity is 91.47639241669506
At time: 454.264502286911 and batch: 250, loss is 4.5219941997528075 and perplexity is 92.01891923379192
At time: 455.490514755249 and batch: 300, loss is 4.5229904842376705 and perplexity is 92.11064193870546
At time: 456.6874599456787 and batch: 350, loss is 4.522064075469971 and perplexity is 92.02534934641774
At time: 457.8852581977844 and batch: 400, loss is 4.514907398223877 and perplexity is 91.36910468925008
At time: 459.08182668685913 and batch: 450, loss is 4.476109504699707 and perplexity is 87.8920629891152
At time: 460.27974915504456 and batch: 500, loss is 4.537537336349487 and perplexity is 93.46035506243024
At time: 461.48151540756226 and batch: 550, loss is 4.523794679641724 and perplexity is 92.18474668697215
At time: 462.6777331829071 and batch: 600, loss is 4.475609178543091 and perplexity is 87.8480992900542
At time: 463.8775403499603 and batch: 650, loss is 4.488811893463135 and perplexity is 89.01562298312058
At time: 465.0812213420868 and batch: 700, loss is 4.485480422973633 and perplexity is 88.7195634925984
At time: 466.28318667411804 and batch: 750, loss is 4.434266128540039 and perplexity is 84.29024398034144
At time: 467.4814636707306 and batch: 800, loss is 4.414697980880737 and perplexity is 82.65687317989384
At time: 468.6771788597107 and batch: 850, loss is 4.393447637557983 and perplexity is 80.91891772315046
At time: 469.87428283691406 and batch: 900, loss is 4.409717664718628 and perplexity is 82.2462392107479
At time: 471.0703499317169 and batch: 950, loss is 4.379646625518799 and perplexity is 79.80982566569104
At time: 472.2667908668518 and batch: 1000, loss is 4.391380529403687 and perplexity is 80.75182233011184
At time: 473.46297216415405 and batch: 1050, loss is 4.342083387374878 and perplexity is 76.86751744763211
At time: 474.65884494781494 and batch: 1100, loss is 4.313267946243286 and perplexity is 74.68415438245802
At time: 475.85468554496765 and batch: 1150, loss is 4.324504795074463 and perplexity is 75.52810170941524
At time: 477.0515055656433 and batch: 1200, loss is 4.284924488067627 and perplexity is 72.59706456814294
At time: 478.24842166900635 and batch: 1250, loss is 4.323859596252442 and perplexity is 75.47938678425889
At time: 479.4492928981781 and batch: 1300, loss is 4.286788558959961 and perplexity is 72.73251685017937
At time: 480.6486897468567 and batch: 1350, loss is 4.2793990421295165 and perplexity is 72.19703958855357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.770948893229167 and perplexity of 118.03118783489701
Finished 14 epochs...
Completing Train Step...
At time: 484.0798215866089 and batch: 50, loss is 4.522688703536987 and perplexity is 92.0828489185503
At time: 485.2912771701813 and batch: 100, loss is 4.5345808792114255 and perplexity is 93.18445157795753
At time: 486.4800477027893 and batch: 150, loss is 4.511122074127197 and perplexity is 91.02389678966577
At time: 487.66891717910767 and batch: 200, loss is 4.491884832382202 and perplexity is 89.28958327142371
At time: 488.8576419353485 and batch: 250, loss is 4.4999072456359865 and perplexity is 90.00878220597119
At time: 490.0479271411896 and batch: 300, loss is 4.500062999725341 and perplexity is 90.02280253371096
At time: 491.2440128326416 and batch: 350, loss is 4.500193300247193 and perplexity is 90.03453331610656
At time: 492.44019055366516 and batch: 400, loss is 4.49365195274353 and perplexity is 89.4475082071657
At time: 493.6369824409485 and batch: 450, loss is 4.455172958374024 and perplexity is 86.07103626430514
At time: 494.8328330516815 and batch: 500, loss is 4.519003582000733 and perplexity is 91.74413690965255
At time: 496.0287194252014 and batch: 550, loss is 4.506193675994873 and perplexity is 90.576398417579
At time: 497.22429752349854 and batch: 600, loss is 4.458652772903442 and perplexity is 86.37106923364185
At time: 498.4207022190094 and batch: 650, loss is 4.473300876617432 and perplexity is 87.64555321198331
At time: 499.61721873283386 and batch: 700, loss is 4.470831050872802 and perplexity is 87.42935106897093
At time: 500.81401920318604 and batch: 750, loss is 4.421241340637207 and perplexity is 83.19950020329682
At time: 502.00912261009216 and batch: 800, loss is 4.403334112167358 and perplexity is 81.7228882170875
At time: 503.204874753952 and batch: 850, loss is 4.3838011837005615 and perplexity is 80.14208995764535
At time: 504.4004304409027 and batch: 900, loss is 4.401908960342407 and perplexity is 81.60650364634499
At time: 505.5957317352295 and batch: 950, loss is 4.373347520828247 and perplexity is 79.30867527495937
At time: 506.79093074798584 and batch: 1000, loss is 4.3872366142272945 and perplexity is 80.41788600779739
At time: 507.98640751838684 and batch: 1050, loss is 4.339221038818359 and perplexity is 76.64781040909072
At time: 509.18230271339417 and batch: 1100, loss is 4.313163356781006 and perplexity is 74.6763436153794
At time: 510.37947607040405 and batch: 1150, loss is 4.325936498641968 and perplexity is 75.6363130068457
At time: 511.57493805885315 and batch: 1200, loss is 4.288556137084961 and perplexity is 72.86119094319427
At time: 512.7706258296967 and batch: 1250, loss is 4.32954773902893 and perplexity is 75.90994769804726
At time: 513.9685716629028 and batch: 1300, loss is 4.2936169528961186 and perplexity is 73.23086264152943
At time: 515.1642026901245 and batch: 1350, loss is 4.286634740829467 and perplexity is 72.72133013079359
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7678450520833335 and perplexity of 117.66540573602477
Finished 15 epochs...
Completing Train Step...
At time: 518.5978004932404 and batch: 50, loss is 4.51464961051941 and perplexity is 91.34555389317624
At time: 519.7759916782379 and batch: 100, loss is 4.5247540855407715 and perplexity is 92.27323171648824
At time: 520.9667789936066 and batch: 150, loss is 4.500576848983765 and perplexity is 90.06907257092816
At time: 522.1619486808777 and batch: 200, loss is 4.4814605712890625 and perplexity is 88.36363986522171
At time: 523.3633599281311 and batch: 250, loss is 4.4895000076293945 and perplexity is 89.07689697364638
At time: 524.5655009746552 and batch: 300, loss is 4.489010257720947 and perplexity is 89.03328225253337
At time: 525.7609753608704 and batch: 350, loss is 4.489857883453369 and perplexity is 89.10878114649492
At time: 526.9577388763428 and batch: 400, loss is 4.48306824684143 and perplexity is 88.50581418321664
At time: 528.1529276371002 and batch: 450, loss is 4.445112285614013 and perplexity is 85.20944509504204
At time: 529.3481981754303 and batch: 500, loss is 4.5093975925445555 and perplexity is 90.86706302340895
At time: 530.5433776378632 and batch: 550, loss is 4.4975317764282225 and perplexity is 89.79522286765234
At time: 531.7390041351318 and batch: 600, loss is 4.450577116012573 and perplexity is 85.67637494501426
At time: 532.9399976730347 and batch: 650, loss is 4.465551881790161 and perplexity is 86.9690129124944
At time: 534.1371440887451 and batch: 700, loss is 4.4636124420166015 and perplexity is 86.80050520787601
At time: 535.3317472934723 and batch: 750, loss is 4.4146917533874515 and perplexity is 82.65635843637389
At time: 536.5317149162292 and batch: 800, loss is 4.39766131401062 and perplexity is 81.26060323187052
At time: 537.733090877533 and batch: 850, loss is 4.379216175079346 and perplexity is 79.77547888398458
At time: 538.9359269142151 and batch: 900, loss is 4.397986421585083 and perplexity is 81.28702596436909
At time: 540.1315324306488 and batch: 950, loss is 4.3702084350585935 and perplexity is 79.06010888072065
At time: 541.328165769577 and batch: 1000, loss is 4.385173358917236 and perplexity is 80.25213443018016
At time: 542.5240981578827 and batch: 1050, loss is 4.338290004730225 and perplexity is 76.57648189461065
At time: 543.7194428443909 and batch: 1100, loss is 4.313178386688232 and perplexity is 74.6774660023306
At time: 544.9145185947418 and batch: 1150, loss is 4.326798553466797 and perplexity is 75.70154376761191
At time: 546.1548590660095 and batch: 1200, loss is 4.2902627944946286 and perplexity is 72.9856462056344
At time: 547.3497519493103 and batch: 1250, loss is 4.332540206909179 and perplexity is 76.1374459992366
At time: 548.5451815128326 and batch: 1300, loss is 4.296507825851441 and perplexity is 73.44287005743915
At time: 549.7403905391693 and batch: 1350, loss is 4.289778270721436 and perplexity is 72.95029149073751
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.766735026041666 and perplexity of 117.53486653581402
Finished 16 epochs...
Completing Train Step...
At time: 553.1867525577545 and batch: 50, loss is 4.508572340011597 and perplexity is 90.7921056831079
At time: 554.3657073974609 and batch: 100, loss is 4.517490139007569 and perplexity is 91.60539240591424
At time: 555.5460715293884 and batch: 150, loss is 4.493283882141113 and perplexity is 89.41459126718576
At time: 556.7310538291931 and batch: 200, loss is 4.4742339324951175 and perplexity is 87.72736957424387
At time: 557.9183988571167 and batch: 250, loss is 4.482217655181885 and perplexity is 88.43056388402658
At time: 559.1061182022095 and batch: 300, loss is 4.4814094543457035 and perplexity is 88.3591231014903
At time: 560.2931940555573 and batch: 350, loss is 4.482414350509644 and perplexity is 88.44795947353316
At time: 561.4835267066956 and batch: 400, loss is 4.4761960983276365 and perplexity is 87.89967421125256
At time: 562.6784956455231 and batch: 450, loss is 4.438254384994507 and perplexity is 84.62708635033309
At time: 563.8733530044556 and batch: 500, loss is 4.5029002285003665 and perplexity is 90.2785804981869
At time: 565.0680930614471 and batch: 550, loss is 4.491567525863648 and perplexity is 89.26125559912789
At time: 566.2620768547058 and batch: 600, loss is 4.444851760864258 and perplexity is 85.18724881714726
At time: 567.4561398029327 and batch: 650, loss is 4.46008710861206 and perplexity is 86.49504323134659
At time: 568.6573059558868 and batch: 700, loss is 4.458712463378906 and perplexity is 86.37622491770179
At time: 569.8516607284546 and batch: 750, loss is 4.410149669647216 and perplexity is 82.28177766728626
At time: 571.0463216304779 and batch: 800, loss is 4.393651790618897 and perplexity is 80.93543925429263
At time: 572.2491118907928 and batch: 850, loss is 4.375900745391846 and perplexity is 79.51142685779463
At time: 573.4444043636322 and batch: 900, loss is 4.39496036529541 and perplexity is 81.04141864638467
At time: 574.6398284435272 and batch: 950, loss is 4.368078699111939 and perplexity is 78.89191089711254
At time: 575.8611600399017 and batch: 1000, loss is 4.3835679721832275 and perplexity is 80.12340207844304
At time: 577.0565619468689 and batch: 1050, loss is 4.337617406845093 and perplexity is 76.52499403209222
At time: 578.2519011497498 and batch: 1100, loss is 4.312630672454834 and perplexity is 74.63657529052165
At time: 579.446715593338 and batch: 1150, loss is 4.326732730865478 and perplexity is 75.6965610590665
At time: 580.6420795917511 and batch: 1200, loss is 4.291066360473633 and perplexity is 73.044318558277
At time: 581.8370635509491 and batch: 1250, loss is 4.334041376113891 and perplexity is 76.2518270196489
At time: 583.0338191986084 and batch: 1300, loss is 4.298074445724487 and perplexity is 73.5580172896254
At time: 584.2364356517792 and batch: 1350, loss is 4.291059446334839 and perplexity is 73.04381352146633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.766315511067709 and perplexity of 117.4855692405399
Finished 17 epochs...
Completing Train Step...
At time: 587.6580975055695 and batch: 50, loss is 4.503371391296387 and perplexity is 90.32112642883791
At time: 588.8556342124939 and batch: 100, loss is 4.511549730300903 and perplexity is 91.06283204594058
At time: 590.0379030704498 and batch: 150, loss is 4.487312936782837 and perplexity is 88.8822923737677
At time: 591.2309777736664 and batch: 200, loss is 4.468450603485107 and perplexity is 87.22147761268398
At time: 592.4277200698853 and batch: 250, loss is 4.476288251876831 and perplexity is 87.90777485144977
At time: 593.6311790943146 and batch: 300, loss is 4.475425510406494 and perplexity is 87.83196587499654
At time: 594.827644109726 and batch: 350, loss is 4.476365747451783 and perplexity is 87.91458757897934
At time: 596.0254654884338 and batch: 400, loss is 4.470471324920655 and perplexity is 87.39790611853344
At time: 597.2270150184631 and batch: 450, loss is 4.43274377822876 and perplexity is 84.16202232508194
At time: 598.4239494800568 and batch: 500, loss is 4.49776837348938 and perplexity is 89.81647066697309
At time: 599.6204631328583 and batch: 550, loss is 4.486647148132324 and perplexity is 88.82313524753049
At time: 600.8175070285797 and batch: 600, loss is 4.440527372360229 and perplexity is 84.81966142585095
At time: 602.0141332149506 and batch: 650, loss is 4.4557804679870605 and perplexity is 86.12334113248617
At time: 603.2121331691742 and batch: 700, loss is 4.454718732833863 and perplexity is 86.03194947914584
At time: 604.4094486236572 and batch: 750, loss is 4.4064429759979244 and perplexity is 81.97734888523121
At time: 605.6346924304962 and batch: 800, loss is 4.390478420257568 and perplexity is 80.67900822069713
At time: 606.8316428661346 and batch: 850, loss is 4.373181829452514 and perplexity is 79.29553560004099
At time: 608.0287520885468 and batch: 900, loss is 4.392500267028809 and perplexity is 80.84229382658847
At time: 609.2254810333252 and batch: 950, loss is 4.365988245010376 and perplexity is 78.72716323710394
At time: 610.4220144748688 and batch: 1000, loss is 4.38200475692749 and perplexity is 79.99824979943395
At time: 611.6188929080963 and batch: 1050, loss is 4.336678085327148 and perplexity is 76.4531462079237
At time: 612.8222436904907 and batch: 1100, loss is 4.311715831756592 and perplexity is 74.56832593727151
At time: 614.0184783935547 and batch: 1150, loss is 4.326250867843628 and perplexity is 75.66009447206642
At time: 615.215603351593 and batch: 1200, loss is 4.291094655990601 and perplexity is 73.0463854142734
At time: 616.4125652313232 and batch: 1250, loss is 4.334369850158692 and perplexity is 76.2768778797469
At time: 617.6094768047333 and batch: 1300, loss is 4.298648023605347 and perplexity is 73.60022064360075
At time: 618.819657087326 and batch: 1350, loss is 4.29126537322998 and perplexity is 73.05885675604422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765923258463542 and perplexity of 117.43949425716018
Finished 18 epochs...
Completing Train Step...
At time: 622.2397179603577 and batch: 50, loss is 4.498609037399292 and perplexity is 89.89200787863373
At time: 623.4438569545746 and batch: 100, loss is 4.506230192184448 and perplexity is 90.57970598290413
At time: 624.6349430084229 and batch: 150, loss is 4.48214599609375 and perplexity is 88.42422725749651
At time: 625.8329305648804 and batch: 200, loss is 4.463154363632202 and perplexity is 86.76075287822194
At time: 627.0297813415527 and batch: 250, loss is 4.471237392425537 and perplexity is 87.46488446609783
At time: 628.2335741519928 and batch: 300, loss is 4.470520305633545 and perplexity is 87.40218703512055
At time: 629.431072473526 and batch: 350, loss is 4.470858907699585 and perplexity is 87.43178660718237
At time: 630.6314549446106 and batch: 400, loss is 4.465742740631104 and perplexity is 86.98561330161189
At time: 631.8316297531128 and batch: 450, loss is 4.428116455078125 and perplexity is 83.77347710621378
At time: 633.0338263511658 and batch: 500, loss is 4.493453121185302 and perplexity is 89.42972498772048
At time: 634.2340586185455 and batch: 550, loss is 4.48243486404419 and perplexity is 88.44977387241512
At time: 635.4327054023743 and batch: 600, loss is 4.436730861663818 and perplexity is 84.49825317496418
At time: 636.6686918735504 and batch: 650, loss is 4.452189273834229 and perplexity is 85.81461018158187
At time: 637.8664331436157 and batch: 700, loss is 4.4511706733703615 and perplexity is 85.72724388307431
At time: 639.0644142627716 and batch: 750, loss is 4.403194265365601 and perplexity is 81.7114603316352
At time: 640.26100730896 and batch: 800, loss is 4.387561054229736 and perplexity is 80.44398101983408
At time: 641.4579408168793 and batch: 850, loss is 4.3707319927215575 and perplexity is 79.10151224413825
At time: 642.6562616825104 and batch: 900, loss is 4.390118017196655 and perplexity is 80.6499364982665
At time: 643.8593146800995 and batch: 950, loss is 4.3641109275817875 and perplexity is 78.57950600456958
At time: 645.0550322532654 and batch: 1000, loss is 4.380438947677613 and perplexity is 79.87308581695743
At time: 646.255618095398 and batch: 1050, loss is 4.335572471618653 and perplexity is 76.36866527166488
At time: 647.4555230140686 and batch: 1100, loss is 4.310767269134521 and perplexity is 74.49762674710271
At time: 648.6516542434692 and batch: 1150, loss is 4.325492734909058 and perplexity is 75.60275580052846
At time: 649.8478977680206 and batch: 1200, loss is 4.290614757537842 and perplexity is 73.0113389769716
At time: 651.0437505245209 and batch: 1250, loss is 4.33407341003418 and perplexity is 76.25426970372169
At time: 652.2390604019165 and batch: 1300, loss is 4.298655366897583 and perplexity is 73.60076111351395
At time: 653.4352087974548 and batch: 1350, loss is 4.290953636169434 and perplexity is 73.036085152353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765606689453125 and perplexity of 117.40232243671294
Finished 19 epochs...
Completing Train Step...
At time: 656.8825843334198 and batch: 50, loss is 4.494296617507935 and perplexity is 89.50519045482926
At time: 658.0540697574615 and batch: 100, loss is 4.501488533020019 and perplexity is 90.15122454918472
At time: 659.2355401515961 and batch: 150, loss is 4.477604742050171 and perplexity is 88.02358078516308
At time: 660.4259300231934 and batch: 200, loss is 4.4586773872375485 and perplexity is 86.3731952261619
At time: 661.6219294071198 and batch: 250, loss is 4.466689071655273 and perplexity is 87.06796944807775
At time: 662.8178856372833 and batch: 300, loss is 4.466224622726441 and perplexity is 87.02754021231631
At time: 664.0143663883209 and batch: 350, loss is 4.466357822418213 and perplexity is 87.03913302591076
At time: 665.2130556106567 and batch: 400, loss is 4.461608343124389 and perplexity is 86.62672260846816
At time: 666.4397141933441 and batch: 450, loss is 4.424081211090088 and perplexity is 83.43611181976783
At time: 667.638608455658 and batch: 500, loss is 4.489680614471435 and perplexity is 89.0929863235872
At time: 668.8388698101044 and batch: 550, loss is 4.478561601638794 and perplexity is 88.10784730164504
At time: 670.0356557369232 and batch: 600, loss is 4.4331959629058835 and perplexity is 84.20008770761581
At time: 671.2327909469604 and batch: 650, loss is 4.448933305740357 and perplexity is 85.5356549299833
At time: 672.4301476478577 and batch: 700, loss is 4.4478707695007325 and perplexity is 85.4448184639048
At time: 673.6277995109558 and batch: 750, loss is 4.400098857879638 and perplexity is 81.45892112315694
At time: 674.825799703598 and batch: 800, loss is 4.384870090484619 and perplexity is 80.22780018124861
At time: 676.023255109787 and batch: 850, loss is 4.368546829223633 and perplexity is 78.92885122193718
At time: 677.2202825546265 and batch: 900, loss is 4.387865209579468 and perplexity is 80.46845220834781
At time: 678.4198970794678 and batch: 950, loss is 4.362197656631469 and perplexity is 78.42930585105454
At time: 679.6175203323364 and batch: 1000, loss is 4.378794765472412 and perplexity is 79.74186781329652
At time: 680.814784526825 and batch: 1050, loss is 4.334284725189209 and perplexity is 76.27038508919841
At time: 682.012701511383 and batch: 1100, loss is 4.30958441734314 and perplexity is 74.40955919155239
At time: 683.2097253799438 and batch: 1150, loss is 4.324403495788574 and perplexity is 75.52045115415193
At time: 684.4074182510376 and batch: 1200, loss is 4.289738254547119 and perplexity is 72.94737235756345
At time: 685.6043326854706 and batch: 1250, loss is 4.333357172012329 and perplexity is 76.19967305086473
At time: 686.8008716106415 and batch: 1300, loss is 4.298203945159912 and perplexity is 73.56754362814978
At time: 687.9984221458435 and batch: 1350, loss is 4.290266122817993 and perplexity is 72.9858891258702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765323079427083 and perplexity of 117.36903068215014
Finished 20 epochs...
Completing Train Step...
At time: 691.4487009048462 and batch: 50, loss is 4.490287227630615 and perplexity is 89.14704769699418
At time: 692.6223483085632 and batch: 100, loss is 4.497172956466675 and perplexity is 89.76300832919115
At time: 693.8082277774811 and batch: 150, loss is 4.47338306427002 and perplexity is 87.6527568902842
At time: 694.9968597888947 and batch: 200, loss is 4.454541921615601 and perplexity is 86.01673941004401
At time: 696.2170650959015 and batch: 250, loss is 4.4625693035125735 and perplexity is 86.71000746776939
At time: 697.4150893688202 and batch: 300, loss is 4.46227029800415 and perplexity is 86.68408457363833
At time: 698.6110599040985 and batch: 350, loss is 4.462249145507813 and perplexity is 86.68225100824917
At time: 699.8074424266815 and batch: 400, loss is 4.457813949584961 and perplexity is 86.29864954463476
At time: 701.0110728740692 and batch: 450, loss is 4.420374612808228 and perplexity is 83.12742012253179
At time: 702.2072916030884 and batch: 500, loss is 4.486080436706543 and perplexity is 88.77281242251883
At time: 703.4044802188873 and batch: 550, loss is 4.475193920135498 and perplexity is 87.81162720142781
At time: 704.6030104160309 and batch: 600, loss is 4.430031862258911 and perplexity is 83.93409119740939
At time: 705.7994589805603 and batch: 650, loss is 4.445771522521973 and perplexity is 85.26563682595189
At time: 707.0038437843323 and batch: 700, loss is 4.444913883209228 and perplexity is 85.19254101318548
At time: 708.2004806995392 and batch: 750, loss is 4.397281332015991 and perplexity is 81.2297315314863
At time: 709.3972508907318 and batch: 800, loss is 4.382279787063599 and perplexity is 80.020254754839
At time: 710.593715429306 and batch: 850, loss is 4.366436614990234 and perplexity is 78.76247004836446
At time: 711.7905764579773 and batch: 900, loss is 4.385713958740235 and perplexity is 80.29553044873147
At time: 712.9875104427338 and batch: 950, loss is 4.360253629684448 and perplexity is 78.27698527266972
At time: 714.1842324733734 and batch: 1000, loss is 4.377142171859742 and perplexity is 79.61019574206492
At time: 715.3802797794342 and batch: 1050, loss is 4.332864780426025 and perplexity is 76.16216220874476
At time: 716.576370716095 and batch: 1100, loss is 4.30827618598938 and perplexity is 74.31227792027764
At time: 717.772997379303 and batch: 1150, loss is 4.3232103443145755 and perplexity is 75.43039755101842
At time: 718.9696180820465 and batch: 1200, loss is 4.288782396316528 and perplexity is 72.87767832540905
At time: 720.1709289550781 and batch: 1250, loss is 4.332418203353882 and perplexity is 76.12815752675829
At time: 721.3678567409515 and batch: 1300, loss is 4.2976211643219 and perplexity is 73.52468236399847
At time: 722.5644423961639 and batch: 1350, loss is 4.289428215026856 and perplexity is 72.92475929488593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7651289876302085 and perplexity of 117.34625252668567
Finished 21 epochs...
Completing Train Step...
At time: 726.0030224323273 and batch: 50, loss is 4.486622037887574 and perplexity is 88.82090490486729
At time: 727.2085475921631 and batch: 100, loss is 4.493190832138062 and perplexity is 89.40627162627284
At time: 728.3955609798431 and batch: 150, loss is 4.469505405426025 and perplexity is 87.31352753524345
At time: 729.5928337574005 and batch: 200, loss is 4.45065936088562 and perplexity is 85.68342167736958
At time: 730.7897663116455 and batch: 250, loss is 4.458723268508911 and perplexity is 86.37715822908363
At time: 731.9862687587738 and batch: 300, loss is 4.458521223068237 and perplexity is 86.35970788102605
At time: 733.1834397315979 and batch: 350, loss is 4.4584717941284175 and perplexity is 86.35543931771853
At time: 734.3805503845215 and batch: 400, loss is 4.454304656982422 and perplexity is 85.99633310086412
At time: 735.5767514705658 and batch: 450, loss is 4.4169657516479495 and perplexity is 82.84453272459085
At time: 736.7738831043243 and batch: 500, loss is 4.482706756591797 and perplexity is 88.4738259764143
At time: 737.97070145607 and batch: 550, loss is 4.471927824020386 and perplexity is 87.52529383764269
At time: 739.1740319728851 and batch: 600, loss is 4.426993541717529 and perplexity is 83.67945954617396
At time: 740.3710792064667 and batch: 650, loss is 4.44273624420166 and perplexity is 85.0072242624466
At time: 741.567839384079 and batch: 700, loss is 4.442096433639526 and perplexity is 84.95285313797046
At time: 742.7715015411377 and batch: 750, loss is 4.394508876800537 and perplexity is 81.00483763683151
At time: 743.9681379795074 and batch: 800, loss is 4.37973466873169 and perplexity is 79.8168526884992
At time: 745.1648893356323 and batch: 850, loss is 4.364363632202148 and perplexity is 78.59936591804286
At time: 746.3613150119781 and batch: 900, loss is 4.383604955673218 and perplexity is 80.12636537627802
At time: 747.5574312210083 and batch: 950, loss is 4.358265466690064 and perplexity is 78.12151247108666
At time: 748.7539415359497 and batch: 1000, loss is 4.375420408248901 and perplexity is 79.47324373730598
At time: 749.9521598815918 and batch: 1050, loss is 4.33149302482605 and perplexity is 76.0577579611559
At time: 751.1489233970642 and batch: 1100, loss is 4.306889533996582 and perplexity is 74.20930406296225
At time: 752.3453679084778 and batch: 1150, loss is 4.32178466796875 and perplexity is 75.32293483919882
At time: 753.5417931079865 and batch: 1200, loss is 4.287642469406128 and perplexity is 72.794650430575
At time: 754.7449741363525 and batch: 1250, loss is 4.331395053863526 and perplexity is 76.05030687440207
At time: 755.941751241684 and batch: 1300, loss is 4.296733083724976 and perplexity is 73.4594155056009
At time: 757.138671875 and batch: 1350, loss is 4.288350505828857 and perplexity is 72.84620994531292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.764914143880208 and perplexity of 117.32104412577503
Finished 22 epochs...
Completing Train Step...
At time: 760.5609450340271 and batch: 50, loss is 4.483015260696411 and perplexity is 88.50112472555054
At time: 761.7661912441254 and batch: 100, loss is 4.48924147605896 and perplexity is 89.05387076021216
At time: 762.9451682567596 and batch: 150, loss is 4.4656272220611575 and perplexity is 86.97556542832655
At time: 764.1458051204681 and batch: 200, loss is 4.446698179244995 and perplexity is 85.34468542135909
At time: 765.3414478302002 and batch: 250, loss is 4.454920234680176 and perplexity is 86.04928682250252
At time: 766.5436985492706 and batch: 300, loss is 4.455156593322754 and perplexity is 86.06962771890933
At time: 767.7450792789459 and batch: 350, loss is 4.454555149078369 and perplexity is 86.01787720078707
At time: 768.9438006877899 and batch: 400, loss is 4.451182918548584 and perplexity is 85.72829363488135
At time: 770.1418824195862 and batch: 450, loss is 4.413359851837158 and perplexity is 82.54634158650113
At time: 771.3385562896729 and batch: 500, loss is 4.4795379638671875 and perplexity is 88.19391448531185
At time: 772.5352666378021 and batch: 550, loss is 4.46878212928772 and perplexity is 87.25039857681266
At time: 773.7308201789856 and batch: 600, loss is 4.423699426651001 and perplexity is 83.40426329064039
At time: 774.9272162914276 and batch: 650, loss is 4.43958818435669 and perplexity is 84.74003721428052
At time: 776.1232290267944 and batch: 700, loss is 4.439106903076172 and perplexity is 84.69926323332284
At time: 777.32000041008 and batch: 750, loss is 4.391609706878662 and perplexity is 80.77033094965142
At time: 778.5166053771973 and batch: 800, loss is 4.37699221611023 and perplexity is 79.59825863053524
At time: 779.713719367981 and batch: 850, loss is 4.3621054458618165 and perplexity is 78.42207415782379
At time: 780.9094996452332 and batch: 900, loss is 4.381196899414062 and perplexity is 79.93364871002356
At time: 782.1056864261627 and batch: 950, loss is 4.356067390441894 and perplexity is 77.94998401542722
At time: 783.3015389442444 and batch: 1000, loss is 4.373406763076782 and perplexity is 79.31337383838637
At time: 784.4982461929321 and batch: 1050, loss is 4.3298031520843505 and perplexity is 75.9293385659606
At time: 785.7001328468323 and batch: 1100, loss is 4.30521258354187 and perplexity is 74.08496302279086
At time: 786.9241828918457 and batch: 1150, loss is 4.320117769241333 and perplexity is 75.19748372117223
At time: 788.1243467330933 and batch: 1200, loss is 4.286258687973023 and perplexity is 72.69398820819971
At time: 789.3215889930725 and batch: 1250, loss is 4.330289735794067 and perplexity is 75.96629353531026
At time: 790.5188171863556 and batch: 1300, loss is 4.29565089225769 and perplexity is 73.37996135300624
At time: 791.7141351699829 and batch: 1350, loss is 4.287489166259766 and perplexity is 72.7834916369866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7649072265625 and perplexity of 117.32023258164584
Finished 23 epochs...
Completing Train Step...
At time: 795.1516723632812 and batch: 50, loss is 4.479723110198974 and perplexity is 88.21024477676485
At time: 796.3337466716766 and batch: 100, loss is 4.485559377670288 and perplexity is 88.72656859536059
At time: 797.5212876796722 and batch: 150, loss is 4.462132740020752 and perplexity is 86.67216130586075
At time: 798.7125267982483 and batch: 200, loss is 4.443268222808838 and perplexity is 85.05245831791795
At time: 799.9116821289062 and batch: 250, loss is 4.451497926712036 and perplexity is 85.75530300107721
At time: 801.106767654419 and batch: 300, loss is 4.451696748733521 and perplexity is 85.77235473884724
At time: 802.3013458251953 and batch: 350, loss is 4.451103639602661 and perplexity is 85.72149745552676
At time: 803.4965288639069 and batch: 400, loss is 4.447978315353393 and perplexity is 85.45400819391176
At time: 804.6914720535278 and batch: 450, loss is 4.41003828048706 and perplexity is 82.27261287961424
At time: 805.8857979774475 and batch: 500, loss is 4.476480379104614 and perplexity is 87.92466595110069
At time: 807.0810945034027 and batch: 550, loss is 4.466025266647339 and perplexity is 87.0101924723719
At time: 808.2760560512543 and batch: 600, loss is 4.420890779495239 and perplexity is 83.17033880321992
At time: 809.4720394611359 and batch: 650, loss is 4.436794033050537 and perplexity is 84.5035912153965
At time: 810.6737112998962 and batch: 700, loss is 4.436398839950561 and perplexity is 84.47020257713925
At time: 811.8685395717621 and batch: 750, loss is 4.389088706970215 and perplexity is 80.5669654026912
At time: 813.0636920928955 and batch: 800, loss is 4.374679002761841 and perplexity is 79.41434367543721
At time: 814.2591338157654 and batch: 850, loss is 4.359977550506592 and perplexity is 78.25537760978077
At time: 815.4542241096497 and batch: 900, loss is 4.378962965011596 and perplexity is 79.75528148677168
At time: 816.6752300262451 and batch: 950, loss is 4.354219951629639 and perplexity is 77.80610913048646
At time: 817.8701589107513 and batch: 1000, loss is 4.371576261520386 and perplexity is 79.16832338217722
At time: 819.0664618015289 and batch: 1050, loss is 4.328261890411377 and perplexity is 75.81240172485883
At time: 820.2670493125916 and batch: 1100, loss is 4.303626222610474 and perplexity is 73.9675307014978
At time: 821.4679045677185 and batch: 1150, loss is 4.3184552669525145 and perplexity is 75.0725715944912
At time: 822.6642565727234 and batch: 1200, loss is 4.284897699356079 and perplexity is 72.59511981236982
At time: 823.8635039329529 and batch: 1250, loss is 4.329049806594849 and perplexity is 75.87215908188857
At time: 825.0606944561005 and batch: 1300, loss is 4.294538736343384 and perplexity is 73.29839675967557
At time: 826.2634949684143 and batch: 1350, loss is 4.286389398574829 and perplexity is 72.70349070417105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765060221354167 and perplexity of 117.33818333933915
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 829.6841311454773 and batch: 50, loss is 4.478014144897461 and perplexity is 88.0596252676186
At time: 830.8697607517242 and batch: 100, loss is 4.485224800109863 and perplexity is 88.69688764206244
At time: 832.0633990764618 and batch: 150, loss is 4.462770767211914 and perplexity is 86.7274781464384
At time: 833.2597365379333 and batch: 200, loss is 4.445405340194702 and perplexity is 85.23441977253816
At time: 834.4561953544617 and batch: 250, loss is 4.451458263397217 and perplexity is 85.75190172895017
At time: 835.6523468494415 and batch: 300, loss is 4.45160475730896 and perplexity is 85.76446478065672
At time: 836.8487234115601 and batch: 350, loss is 4.450816011428833 and perplexity is 85.69684508328413
At time: 838.0455267429352 and batch: 400, loss is 4.447010297775268 and perplexity is 85.37132723662522
At time: 839.2414915561676 and batch: 450, loss is 4.407780389785767 and perplexity is 82.08705987005987
At time: 840.4380979537964 and batch: 500, loss is 4.473300085067749 and perplexity is 87.64548383620094
At time: 841.6340978145599 and batch: 550, loss is 4.461585149765015 and perplexity is 86.62471346705873
At time: 842.8302268981934 and batch: 600, loss is 4.416557493209839 and perplexity is 82.81071764816956
At time: 844.0302605628967 and batch: 650, loss is 4.431952695846558 and perplexity is 84.0954695598009
At time: 845.2297673225403 and batch: 700, loss is 4.429512701034546 and perplexity is 83.89052718120983
At time: 846.4260802268982 and batch: 750, loss is 4.381893577575684 and perplexity is 79.98935614028044
At time: 847.6469783782959 and batch: 800, loss is 4.368454961776734 and perplexity is 78.92160056294357
At time: 848.8436243534088 and batch: 850, loss is 4.350351943969726 and perplexity is 77.50573580205182
At time: 850.0395214557648 and batch: 900, loss is 4.366773080825806 and perplexity is 78.78897538748146
At time: 851.2359352111816 and batch: 950, loss is 4.341291351318359 and perplexity is 76.80665970618274
At time: 852.4323945045471 and batch: 1000, loss is 4.358220586776733 and perplexity is 78.11800646305295
At time: 853.6355333328247 and batch: 1050, loss is 4.313182954788208 and perplexity is 74.67780713724039
At time: 854.8320910930634 and batch: 1100, loss is 4.288047552108765 and perplexity is 72.82414425762518
At time: 856.0280368328094 and batch: 1150, loss is 4.301793203353882 and perplexity is 73.83207098142539
At time: 857.2241079807281 and batch: 1200, loss is 4.267496938705444 and perplexity is 71.34283644737349
At time: 858.4226274490356 and batch: 1250, loss is 4.309786520004272 and perplexity is 74.42459908122838
At time: 859.6217424869537 and batch: 1300, loss is 4.275283117294311 and perplexity is 71.90049270127773
At time: 860.8179597854614 and batch: 1350, loss is 4.268271427154541 and perplexity is 71.39811205252364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.76563232421875 and perplexity of 117.4053320563077
Annealing...
Finished 25 epochs...
Completing Train Step...
At time: 864.264769077301 and batch: 50, loss is 4.476382827758789 and perplexity is 87.91608919994954
At time: 865.4622278213501 and batch: 100, loss is 4.48313684463501 and perplexity is 88.51188569503236
At time: 866.6457798480988 and batch: 150, loss is 4.460733280181885 and perplexity is 86.55095193057409
At time: 867.8426532745361 and batch: 200, loss is 4.443774909973144 and perplexity is 85.09556422652342
At time: 869.0392591953278 and batch: 250, loss is 4.44953537940979 and perplexity is 85.58716920175154
At time: 870.2365629673004 and batch: 300, loss is 4.449752006530762 and perplexity is 85.60571171214066
At time: 871.4330060482025 and batch: 350, loss is 4.44941481590271 and perplexity is 85.5768511344752
At time: 872.6306946277618 and batch: 400, loss is 4.445829801559448 and perplexity is 85.27060616999869
At time: 873.8273997306824 and batch: 450, loss is 4.406800365447998 and perplexity is 82.00665196086089
At time: 875.0260570049286 and batch: 500, loss is 4.472281847000122 and perplexity is 87.55628528848857
At time: 876.2252144813538 and batch: 550, loss is 4.460275058746338 and perplexity is 86.51130151416162
At time: 877.4526147842407 and batch: 600, loss is 4.415095233917237 and perplexity is 82.68971539665539
At time: 878.6570143699646 and batch: 650, loss is 4.430725317001343 and perplexity is 83.99231587675872
At time: 879.8539137840271 and batch: 700, loss is 4.427797012329101 and perplexity is 83.74672055021314
At time: 881.0515792369843 and batch: 750, loss is 4.3805623054504395 and perplexity is 79.88293939067756
At time: 882.2490682601929 and batch: 800, loss is 4.367189893722534 and perplexity is 78.82182249361614
At time: 883.4483051300049 and batch: 850, loss is 4.348590517044068 and perplexity is 77.36933527716235
At time: 884.6517586708069 and batch: 900, loss is 4.364665594100952 and perplexity is 78.62310351556488
At time: 885.8496658802032 and batch: 950, loss is 4.339275665283203 and perplexity is 76.65199752237396
At time: 887.0473368167877 and batch: 1000, loss is 4.3559543418884275 and perplexity is 77.94117238057218
At time: 888.2450034618378 and batch: 1050, loss is 4.310698556900024 and perplexity is 74.49250802456565
At time: 889.4421598911285 and batch: 1100, loss is 4.284734106063842 and perplexity is 72.58324470908953
At time: 890.6396687030792 and batch: 1150, loss is 4.298684825897217 and perplexity is 73.60292935024556
At time: 891.8361487388611 and batch: 1200, loss is 4.263500728607178 and perplexity is 71.05830438752635
At time: 893.0325331687927 and batch: 1250, loss is 4.307273912429809 and perplexity is 74.2378340017842
At time: 894.2294807434082 and batch: 1300, loss is 4.272499752044678 and perplexity is 71.70064562119043
At time: 895.4265382289886 and batch: 1350, loss is 4.264994268417358 and perplexity is 71.16451208694387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.766588541666667 and perplexity of 117.5176507752996
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 898.8425445556641 and batch: 50, loss is 4.476264371871948 and perplexity is 87.9056756384218
At time: 900.044270992279 and batch: 100, loss is 4.483027963638306 and perplexity is 88.50224895733606
At time: 901.2238802909851 and batch: 150, loss is 4.460714540481567 and perplexity is 86.54933000686992
At time: 902.4178564548492 and batch: 200, loss is 4.443991184234619 and perplexity is 85.11397019712841
At time: 903.6150343418121 and batch: 250, loss is 4.449519567489624 and perplexity is 85.58581591496393
At time: 904.8117098808289 and batch: 300, loss is 4.449733228683471 and perplexity is 85.60410423625146
At time: 906.0090026855469 and batch: 350, loss is 4.44958194732666 and perplexity is 85.59115491073443
At time: 907.2059488296509 and batch: 400, loss is 4.445863332748413 and perplexity is 85.27346544274447
At time: 908.42671251297 and batch: 450, loss is 4.406908369064331 and perplexity is 82.01550945414807
At time: 909.6231470108032 and batch: 500, loss is 4.472456140518188 and perplexity is 87.57154711146008
At time: 910.8263027667999 and batch: 550, loss is 4.460401430130005 and perplexity is 86.52223475784679
At time: 912.0233833789825 and batch: 600, loss is 4.4152912998199465 and perplexity is 82.70592961982567
At time: 913.2252597808838 and batch: 650, loss is 4.430962581634521 and perplexity is 84.01224664711494
At time: 914.4222538471222 and batch: 700, loss is 4.427972383499146 and perplexity is 83.76140859847588
At time: 915.6175675392151 and batch: 750, loss is 4.380919799804688 and perplexity is 79.91150219572707
At time: 916.817873954773 and batch: 800, loss is 4.367562713623047 and perplexity is 78.85121431622423
At time: 918.0148527622223 and batch: 850, loss is 4.348668022155762 and perplexity is 77.37533202852113
At time: 919.2173585891724 and batch: 900, loss is 4.364630498886108 and perplexity is 78.62034426927379
At time: 920.412966966629 and batch: 950, loss is 4.339341659545898 and perplexity is 76.65705628135723
At time: 921.6075789928436 and batch: 1000, loss is 4.355959033966064 and perplexity is 77.94153808746205
At time: 922.8027973175049 and batch: 1050, loss is 4.310581073760987 and perplexity is 74.48375692495154
At time: 923.998162984848 and batch: 1100, loss is 4.284456558227539 and perplexity is 72.56310218195537
At time: 925.1936681270599 and batch: 1150, loss is 4.298327770233154 and perplexity is 73.57665369864371
At time: 926.3919699192047 and batch: 1200, loss is 4.262945737838745 and perplexity is 71.01887862604958
At time: 927.5865058898926 and batch: 1250, loss is 4.306705598831177 and perplexity is 74.19565561759782
At time: 928.7812783718109 and batch: 1300, loss is 4.272002382278442 and perplexity is 71.66499275490273
At time: 929.9767999649048 and batch: 1350, loss is 4.264457492828369 and perplexity is 71.1263229644646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.766017659505208 and perplexity of 117.45058119105164
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 933.4070842266083 and batch: 50, loss is 4.47609073638916 and perplexity is 87.89041341906231
At time: 934.5849897861481 and batch: 100, loss is 4.482924976348877 and perplexity is 88.49313481993579
At time: 935.7637975215912 and batch: 150, loss is 4.460475425720215 and perplexity is 86.52863725854952
At time: 936.9444043636322 and batch: 200, loss is 4.443727884292603 and perplexity is 85.0915626437939
At time: 938.1479260921478 and batch: 250, loss is 4.449387798309326 and perplexity is 85.57453908514132
At time: 939.3375599384308 and batch: 300, loss is 4.449594459533691 and perplexity is 85.59222585168463
At time: 940.526111125946 and batch: 350, loss is 4.449376316070556 and perplexity is 85.57355650349209
At time: 941.7149376869202 and batch: 400, loss is 4.445737838745117 and perplexity is 85.26276480563808
At time: 942.9044024944305 and batch: 450, loss is 4.406794338226319 and perplexity is 82.00615769007992
At time: 944.0984697341919 and batch: 500, loss is 4.472370691299439 and perplexity is 87.56406451087045
At time: 945.2955005168915 and batch: 550, loss is 4.460338621139527 and perplexity is 86.51680055428795
At time: 946.491601228714 and batch: 600, loss is 4.41522910118103 and perplexity is 82.70078558355065
At time: 947.6873993873596 and batch: 650, loss is 4.430910682678222 and perplexity is 84.00788661233925
At time: 948.8894944190979 and batch: 700, loss is 4.427944602966309 and perplexity is 83.75908169423532
At time: 950.0874078273773 and batch: 750, loss is 4.380924987792969 and perplexity is 79.91191677673937
At time: 951.2849402427673 and batch: 800, loss is 4.367587766647339 and perplexity is 78.85318980235776
At time: 952.4911062717438 and batch: 850, loss is 4.348674631118774 and perplexity is 77.3758434009184
At time: 953.6923129558563 and batch: 900, loss is 4.364636468887329 and perplexity is 78.62081363422608
At time: 954.8891053199768 and batch: 950, loss is 4.339370012283325 and perplexity is 76.65922974955765
At time: 956.0862627029419 and batch: 1000, loss is 4.35597716331482 and perplexity is 77.9429511295973
At time: 957.283607006073 and batch: 1050, loss is 4.310574855804443 and perplexity is 74.48329378962767
At time: 958.4807317256927 and batch: 1100, loss is 4.284428815841675 and perplexity is 72.56108913629862
At time: 959.6779539585114 and batch: 1150, loss is 4.298283472061157 and perplexity is 73.57339445957288
At time: 960.8756160736084 and batch: 1200, loss is 4.262893333435058 and perplexity is 71.01515702157978
At time: 962.0725831985474 and batch: 1250, loss is 4.30664834022522 and perplexity is 74.19140739941378
At time: 963.2709827423096 and batch: 1300, loss is 4.271948308944702 and perplexity is 71.66111769460166
At time: 964.4719161987305 and batch: 1350, loss is 4.264391994476318 and perplexity is 71.1216644600868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.765959065755208 and perplexity of 117.44369952267328
Annealing...
Model not improving. Stopping early with 117.32023258164584loss at 27 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77ca218eb8>
SETTINGS FOR THIS RUN
{'dropout': 0.6711892764208761, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 15.143887740344653, 'wordvec_source': '', 'anneal': 2.692297021307107, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5358326435089111 and batch: 50, loss is 7.273261060714722 and perplexity is 1441.242778103801
At time: 2.6176164150238037 and batch: 100, loss is 6.633348970413208 and perplexity is 760.0232085753119
At time: 3.7234232425689697 and batch: 150, loss is 6.426538496017456 and perplexity is 618.03092460364
At time: 4.803212642669678 and batch: 200, loss is 6.362094135284424 and perplexity is 579.4585512988042
At time: 5.883718729019165 and batch: 250, loss is 6.35686429977417 and perplexity is 576.4359890314574
At time: 6.964416265487671 and batch: 300, loss is 6.348886241912842 and perplexity is 571.8554455736979
At time: 8.043615818023682 and batch: 350, loss is 6.332283229827881 and perplexity is 562.4393071335523
At time: 9.1295645236969 and batch: 400, loss is 6.359024085998535 and perplexity is 577.6823129519386
At time: 10.210824251174927 and batch: 450, loss is 6.319632511138916 and perplexity is 555.3688630750913
At time: 11.299708604812622 and batch: 500, loss is 6.30409013748169 and perplexity is 546.8038454566421
At time: 12.38303279876709 and batch: 550, loss is 6.263237810134887 and perplexity is 524.915769217912
At time: 13.465742826461792 and batch: 600, loss is 6.205750551223755 and perplexity is 495.5907826536359
At time: 14.55691385269165 and batch: 650, loss is 6.225364894866943 and perplexity is 505.40742939055957
At time: 15.640297889709473 and batch: 700, loss is 6.23255612373352 and perplexity is 509.0550295306358
At time: 16.720890998840332 and batch: 750, loss is 6.202326526641846 and perplexity is 493.8967694577176
At time: 17.828073978424072 and batch: 800, loss is 6.168451890945435 and perplexity is 477.4463945734398
At time: 18.983741283416748 and batch: 850, loss is 6.153908205032349 and perplexity is 470.552814710318
At time: 20.182157516479492 and batch: 900, loss is 6.189163255691528 and perplexity is 487.43807449457154
At time: 21.38899278640747 and batch: 950, loss is 6.164873695373535 and perplexity is 475.7410508447747
At time: 22.593645811080933 and batch: 1000, loss is 6.181079530715943 and perplexity is 483.51364254269095
At time: 23.795671463012695 and batch: 1050, loss is 6.154390840530396 and perplexity is 470.77997501580717
At time: 24.998231410980225 and batch: 1100, loss is 6.146950416564941 and perplexity is 467.2901713163698
At time: 26.200119733810425 and batch: 1150, loss is 6.1484348106384275 and perplexity is 467.9843291516982
At time: 27.406768560409546 and batch: 1200, loss is 6.120013780593872 and perplexity is 454.8709628483374
At time: 28.608347415924072 and batch: 1250, loss is 6.11613284111023 and perplexity is 453.10905730449184
At time: 29.810861349105835 and batch: 1300, loss is 6.086914863586426 and perplexity is 440.0616644572373
At time: 31.014020204544067 and batch: 1350, loss is 6.081223821640014 and perplexity is 437.56436791568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.492503255208334 and perplexity of 242.86439813306907
Finished 1 epochs...
Completing Train Step...
At time: 34.5199773311615 and batch: 50, loss is 5.848250970840454 and perplexity is 346.6275882254396
At time: 35.716288328170776 and batch: 100, loss is 5.822858448028565 and perplexity is 337.9366486981001
At time: 36.93961143493652 and batch: 150, loss is 5.708870325088501 and perplexity is 301.53024465663924
At time: 38.13645958900452 and batch: 200, loss is 5.6691161727905275 and perplexity is 289.7783072255026
At time: 39.33367872238159 and batch: 250, loss is 5.66301908493042 and perplexity is 288.0168786753894
At time: 40.536930561065674 and batch: 300, loss is 5.654405479431152 and perplexity is 285.5466688845859
At time: 41.73732304573059 and batch: 350, loss is 5.648015804290772 and perplexity is 283.7279351796925
At time: 42.93930220603943 and batch: 400, loss is 5.654594926834107 and perplexity is 285.60077008393245
At time: 44.14286756515503 and batch: 450, loss is 5.647487897872924 and perplexity is 283.57819291021866
At time: 45.34144043922424 and batch: 500, loss is 5.662288208007812 and perplexity is 287.80645069328915
At time: 46.540334939956665 and batch: 550, loss is 5.628905448913574 and perplexity is 278.3572745730249
At time: 47.739277362823486 and batch: 600, loss is 5.5812173843383786 and perplexity is 265.3944963087148
At time: 48.937740325927734 and batch: 650, loss is 5.623961095809936 and perplexity is 276.9843747661764
At time: 50.13489532470703 and batch: 700, loss is 5.620261487960815 and perplexity is 275.9615344199369
At time: 51.332712173461914 and batch: 750, loss is 5.603316164016723 and perplexity is 271.32467432463164
At time: 52.5371356010437 and batch: 800, loss is 5.541694183349609 and perplexity is 255.10983638692568
At time: 53.739163637161255 and batch: 850, loss is 5.553147029876709 and perplexity is 258.0483653311907
At time: 54.938854455947876 and batch: 900, loss is 5.604215106964111 and perplexity is 271.5686893884461
At time: 56.13663625717163 and batch: 950, loss is 5.574967651367188 and perplexity is 263.74102383740603
At time: 57.33471417427063 and batch: 1000, loss is 5.588566179275513 and perplexity is 267.3520099129796
At time: 58.53223752975464 and batch: 1050, loss is 5.5429670524597165 and perplexity is 255.43476456899958
At time: 59.72997188568115 and batch: 1100, loss is 5.551542081832886 and perplexity is 257.6345432823134
At time: 60.92732334136963 and batch: 1150, loss is 5.551264734268188 and perplexity is 257.56309887707596
At time: 62.12484121322632 and batch: 1200, loss is 5.5247964096069335 and perplexity is 250.83526517181895
At time: 63.32225465774536 and batch: 1250, loss is 5.546432332992554 and perplexity is 256.3214531110501
At time: 64.51952910423279 and batch: 1300, loss is 5.548109865188598 and perplexity is 256.75180146186705
At time: 65.717768907547 and batch: 1350, loss is 5.501943378448487 and perplexity is 245.16792365780202
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.276997477213541 and perplexity of 195.78115459251126
Finished 2 epochs...
Completing Train Step...
At time: 69.1779408454895 and batch: 50, loss is 5.545483417510987 and perplexity is 256.0783410805623
At time: 70.42069840431213 and batch: 100, loss is 5.5521101474761965 and perplexity is 257.7809381919046
At time: 71.6190836429596 and batch: 150, loss is 5.507736358642578 and perplexity is 246.59229828745256
At time: 72.81678366661072 and batch: 200, loss is 5.509358310699463 and perplexity is 246.99258370699815
At time: 74.01753187179565 and batch: 250, loss is 5.544442338943481 and perplexity is 255.8118821344767
At time: 75.22206020355225 and batch: 300, loss is 5.536668310165405 and perplexity is 253.83090327111682
At time: 76.41998481750488 and batch: 350, loss is 5.5296275806427 and perplexity is 252.05002523375006
At time: 77.61775326728821 and batch: 400, loss is 5.579412651062012 and perplexity is 264.9159619731662
At time: 78.81580638885498 and batch: 450, loss is 5.556753778457642 and perplexity is 258.9807613549123
At time: 80.0134699344635 and batch: 500, loss is 5.57061725616455 and perplexity is 262.5961383104859
At time: 81.21126341819763 and batch: 550, loss is 5.5405231285095216 and perplexity is 254.81126363492518
At time: 82.4150652885437 and batch: 600, loss is 5.4898751354217525 and perplexity is 242.22695940244955
At time: 83.61341309547424 and batch: 650, loss is 5.555945253372192 and perplexity is 258.7714535394199
At time: 84.81107378005981 and batch: 700, loss is 5.568090515136719 and perplexity is 261.9334634305365
At time: 86.0091438293457 and batch: 750, loss is 5.534294929504394 and perplexity is 253.22918025546616
At time: 87.20662641525269 and batch: 800, loss is 5.4692644596099855 and perplexity is 237.285595417941
At time: 88.40435290336609 and batch: 850, loss is 5.484766483306885 and perplexity is 240.9926616174395
At time: 89.60630989074707 and batch: 900, loss is 5.538727264404297 and perplexity is 254.3540678865494
At time: 90.80617666244507 and batch: 950, loss is 5.501498918533326 and perplexity is 245.05898055546731
At time: 92.00433492660522 and batch: 1000, loss is 5.547324724197388 and perplexity is 256.55029421412394
At time: 93.22987866401672 and batch: 1050, loss is 5.481130867004395 and perplexity is 240.11809552476765
At time: 94.42882013320923 and batch: 1100, loss is 5.4805699157714844 and perplexity is 239.9834387545106
At time: 95.6289963722229 and batch: 1150, loss is 5.520731248855591 and perplexity is 249.81764928425946
At time: 96.82897186279297 and batch: 1200, loss is 5.514421405792237 and perplexity is 248.24630181426775
At time: 98.02859687805176 and batch: 1250, loss is 5.544327907562256 and perplexity is 255.7826109022758
At time: 99.22622799873352 and batch: 1300, loss is 5.495109062194825 and perplexity is 243.49808114773649
At time: 100.43009614944458 and batch: 1350, loss is 5.524278440475464 and perplexity is 250.7053738901172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3833349609375 and perplexity of 217.74724443579987
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 103.91842889785767 and batch: 50, loss is 5.5106651496887205 and perplexity is 247.31557424779209
At time: 105.11668848991394 and batch: 100, loss is 5.491132869720459 and perplexity is 242.53180822658575
At time: 106.31559920310974 and batch: 150, loss is 5.431763734817505 and perplexity is 228.5519952592945
At time: 107.51328921318054 and batch: 200, loss is 5.415345220565796 and perplexity is 224.83014827383425
At time: 108.71192073822021 and batch: 250, loss is 5.422499122619629 and perplexity is 226.4443280912452
At time: 109.91214275360107 and batch: 300, loss is 5.421745138168335 and perplexity is 226.2736569385638
At time: 111.11247158050537 and batch: 350, loss is 5.404791145324707 and perplexity is 222.46975178361086
At time: 112.31160020828247 and batch: 400, loss is 5.443140010833741 and perplexity is 231.16691164496967
At time: 113.51433253288269 and batch: 450, loss is 5.415040140151977 and perplexity is 224.76156746102325
At time: 114.7164695262909 and batch: 500, loss is 5.440167589187622 and perplexity is 230.48080631525812
At time: 115.91863918304443 and batch: 550, loss is 5.425194892883301 and perplexity is 227.0555935226962
At time: 117.12136101722717 and batch: 600, loss is 5.3610356903076175 and perplexity is 212.94537774434687
At time: 118.32339477539062 and batch: 650, loss is 5.387621479034424 and perplexity is 218.6826252708257
At time: 119.52590751647949 and batch: 700, loss is 5.384421367645263 and perplexity is 217.98393505060764
At time: 120.725905418396 and batch: 750, loss is 5.349856433868408 and perplexity is 210.5780638184131
At time: 121.9303891658783 and batch: 800, loss is 5.309572219848633 and perplexity is 202.26368548880555
At time: 123.1550657749176 and batch: 850, loss is 5.285913467407227 and perplexity is 197.5345424258995
At time: 124.3541910648346 and batch: 900, loss is 5.311839418411255 and perplexity is 202.72277765571516
At time: 125.55129146575928 and batch: 950, loss is 5.279349250793457 and perplexity is 196.24212938102687
At time: 126.75414395332336 and batch: 1000, loss is 5.321794891357422 and perplexity is 204.75105827854875
At time: 127.95130753517151 and batch: 1050, loss is 5.263261852264404 and perplexity is 193.11036257050043
At time: 129.15239357948303 and batch: 1100, loss is 5.249974908828736 and perplexity is 190.5614869877375
At time: 130.34957146644592 and batch: 1150, loss is 5.275673179626465 and perplexity is 195.52205368311078
At time: 131.5474293231964 and batch: 1200, loss is 5.25207257270813 and perplexity is 190.96164048283237
At time: 132.74428749084473 and batch: 1250, loss is 5.258349208831787 and perplexity is 192.16400667387234
At time: 133.94269156455994 and batch: 1300, loss is 5.213554191589355 and perplexity is 183.74596737421638
At time: 135.1431119441986 and batch: 1350, loss is 5.212317218780518 and perplexity is 183.5188191259076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.163285725911458 and perplexity of 174.73765343954935
Finished 4 epochs...
Completing Train Step...
At time: 138.6309850215912 and batch: 50, loss is 5.333667039871216 and perplexity is 207.19638014109645
At time: 139.81208777427673 and batch: 100, loss is 5.352368268966675 and perplexity is 211.1076660483197
At time: 140.99450397491455 and batch: 150, loss is 5.328747491836548 and perplexity is 206.17957076838886
At time: 142.19734597206116 and batch: 200, loss is 5.289656887054443 and perplexity is 198.27538288625993
At time: 143.39493370056152 and batch: 250, loss is 5.3009262371063235 and perplexity is 200.52245532448623
At time: 144.5927095413208 and batch: 300, loss is 5.296909008026123 and perplexity is 199.71852654990798
At time: 145.79697394371033 and batch: 350, loss is 5.289575300216675 and perplexity is 198.25920688464632
At time: 146.99497294425964 and batch: 400, loss is 5.327089786529541 and perplexity is 205.8380689326359
At time: 148.19336652755737 and batch: 450, loss is 5.295059862136841 and perplexity is 199.34955909998183
At time: 149.39065432548523 and batch: 500, loss is 5.324288425445556 and perplexity is 205.2622490929387
At time: 150.58944988250732 and batch: 550, loss is 5.313595752716065 and perplexity is 203.079139478119
At time: 151.78789019584656 and batch: 600, loss is 5.254087505340576 and perplexity is 191.34680323197074
At time: 152.99188256263733 and batch: 650, loss is 5.278323431015014 and perplexity is 196.04092354145317
At time: 154.21624279022217 and batch: 700, loss is 5.290424098968506 and perplexity is 198.4275604910469
At time: 155.4135856628418 and batch: 750, loss is 5.255942468643188 and perplexity is 191.70207393522622
At time: 156.61229801177979 and batch: 800, loss is 5.220958089828491 and perplexity is 185.11145253737914
At time: 157.8099067211151 and batch: 850, loss is 5.196331386566162 and perplexity is 180.6084424496619
At time: 159.01528930664062 and batch: 900, loss is 5.2265620803833 and perplexity is 186.15172749203614
At time: 160.21401190757751 and batch: 950, loss is 5.202792530059814 and perplexity is 181.77915751876367
At time: 161.41191625595093 and batch: 1000, loss is 5.234088249206543 and perplexity is 187.55802218744424
At time: 162.6173460483551 and batch: 1050, loss is 5.18133713722229 and perplexity is 177.9205562072694
At time: 163.82265329360962 and batch: 1100, loss is 5.17744330406189 and perplexity is 177.22911030671887
At time: 165.02072095870972 and batch: 1150, loss is 5.204952230453491 and perplexity is 182.17217027896473
At time: 166.21995639801025 and batch: 1200, loss is 5.185960750579834 and perplexity is 178.74509677702244
At time: 167.41919374465942 and batch: 1250, loss is 5.191015453338623 and perplexity is 179.65088743350628
At time: 168.62158608436584 and batch: 1300, loss is 5.150989694595337 and perplexity is 172.60222930667797
At time: 169.8200752735138 and batch: 1350, loss is 5.151840534210205 and perplexity is 172.74914861450702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.141105143229167 and perplexity of 170.90453798634107
Finished 5 epochs...
Completing Train Step...
At time: 173.25799894332886 and batch: 50, loss is 5.252361602783203 and perplexity is 191.01684211719925
At time: 174.44561862945557 and batch: 100, loss is 5.2718143653869625 and perplexity is 194.76902423301587
At time: 175.6145224571228 and batch: 150, loss is 5.239853191375732 and perplexity is 188.6424060405737
At time: 176.8000431060791 and batch: 200, loss is 5.210173807144165 and perplexity is 183.12588401478382
At time: 177.99069023132324 and batch: 250, loss is 5.230219888687134 and perplexity is 186.8338816606438
At time: 179.1859574317932 and batch: 300, loss is 5.223552770614624 and perplexity is 185.59238132509785
At time: 180.38954067230225 and batch: 350, loss is 5.220904788970947 and perplexity is 185.10158620116218
At time: 181.58772230148315 and batch: 400, loss is 5.256116027832031 and perplexity is 191.73534847914584
At time: 182.78483033180237 and batch: 450, loss is 5.225718460083008 and perplexity is 185.99475233881216
At time: 184.00908708572388 and batch: 500, loss is 5.259865713119507 and perplexity is 192.45564529365515
At time: 185.2057328224182 and batch: 550, loss is 5.2507781887054445 and perplexity is 190.71462269269122
At time: 186.40346312522888 and batch: 600, loss is 5.183857412338257 and perplexity is 178.36953048940404
At time: 187.60728311538696 and batch: 650, loss is 5.20802080154419 and perplexity is 182.73203709045393
At time: 188.81234049797058 and batch: 700, loss is 5.223600692749024 and perplexity is 185.60127552125195
At time: 190.010666847229 and batch: 750, loss is 5.18744743347168 and perplexity is 179.01103168586033
At time: 191.20916748046875 and batch: 800, loss is 5.16260950088501 and perplexity is 174.61953140826876
At time: 192.40801668167114 and batch: 850, loss is 5.13786358833313 and perplexity is 170.35143847999885
At time: 193.6060266494751 and batch: 900, loss is 5.1678304195404055 and perplexity is 175.5335898134023
At time: 194.80418395996094 and batch: 950, loss is 5.156642570495605 and perplexity is 173.5806912454531
At time: 196.0029661655426 and batch: 1000, loss is 5.186358289718628 and perplexity is 178.8161690749328
At time: 197.20193314552307 and batch: 1050, loss is 5.125189437866211 and perplexity is 168.20600322019027
At time: 198.4015564918518 and batch: 1100, loss is 5.12460599899292 and perplexity is 168.10789392236293
At time: 199.5998878479004 and batch: 1150, loss is 5.154802732467651 and perplexity is 173.26162449435571
At time: 200.79851746559143 and batch: 1200, loss is 5.130633058547974 and perplexity is 169.12414965128158
At time: 202.00362706184387 and batch: 1250, loss is 5.134804172515869 and perplexity is 169.83105902907852
At time: 203.20193815231323 and batch: 1300, loss is 5.098834733963013 and perplexity is 163.83088945692018
At time: 204.40019059181213 and batch: 1350, loss is 5.100743894577026 and perplexity is 164.14396770166232
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.138028157552084 and perplexity of 170.37947539012004
Finished 6 epochs...
Completing Train Step...
At time: 207.8365032672882 and batch: 50, loss is 5.205001907348633 and perplexity is 182.18122025155077
At time: 209.03608059883118 and batch: 100, loss is 5.216407232284546 and perplexity is 184.27095063991615
At time: 210.20921921730042 and batch: 150, loss is 5.181921644210815 and perplexity is 178.02458241483592
At time: 211.38281893730164 and batch: 200, loss is 5.152312002182007 and perplexity is 172.8306135077698
At time: 212.56230306625366 and batch: 250, loss is 5.176300935745239 and perplexity is 177.02676498476384
At time: 213.78030276298523 and batch: 300, loss is 5.176356143951416 and perplexity is 177.036538584693
At time: 214.97893571853638 and batch: 350, loss is 5.172297773361206 and perplexity is 176.31951466164637
At time: 216.17725253105164 and batch: 400, loss is 5.202494258880615 and perplexity is 181.7249461203475
At time: 217.37501859664917 and batch: 450, loss is 5.17598861694336 and perplexity is 176.97148483058837
At time: 218.57357740402222 and batch: 500, loss is 5.212031230926514 and perplexity is 183.46634247685628
At time: 219.77257442474365 and batch: 550, loss is 5.191693592071533 and perplexity is 179.77275697623492
At time: 220.97080039978027 and batch: 600, loss is 5.13758843421936 and perplexity is 170.30457202895852
At time: 222.16946005821228 and batch: 650, loss is 5.157409181594849 and perplexity is 173.7138111490546
At time: 223.36832976341248 and batch: 700, loss is 5.173354940414429 and perplexity is 176.506012405653
At time: 224.56672835350037 and batch: 750, loss is 5.1369147300720215 and perplexity is 170.18987577248188
At time: 225.7650101184845 and batch: 800, loss is 5.11871301651001 and perplexity is 167.1201502846828
At time: 226.96420311927795 and batch: 850, loss is 5.093786897659302 and perplexity is 163.00598169671804
At time: 228.16211080551147 and batch: 900, loss is 5.122209758758545 and perplexity is 167.7055492729693
At time: 229.36094069480896 and batch: 950, loss is 5.102916612625122 and perplexity is 164.50099398104288
At time: 230.55977511405945 and batch: 1000, loss is 5.127301034927368 and perplexity is 168.56156178835786
At time: 231.76589941978455 and batch: 1050, loss is 5.079390459060669 and perplexity is 160.67608742047796
At time: 232.96493291854858 and batch: 1100, loss is 5.081972980499268 and perplexity is 161.0915731303676
At time: 234.16914916038513 and batch: 1150, loss is 5.119082841873169 and perplexity is 167.18196698494032
At time: 235.36849641799927 and batch: 1200, loss is 5.089650859832764 and perplexity is 162.33317512631183
At time: 236.57021713256836 and batch: 1250, loss is 5.096584739685059 and perplexity is 163.4626852770742
At time: 237.76788568496704 and batch: 1300, loss is 5.065064487457275 and perplexity is 158.3906559550031
At time: 238.96614956855774 and batch: 1350, loss is 5.065815114974976 and perplexity is 158.50959297302444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1396390787760415 and perplexity of 170.65416449500427
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 242.44543957710266 and batch: 50, loss is 5.144954071044922 and perplexity is 171.56360475300968
At time: 243.6184322834015 and batch: 100, loss is 5.1396403408050535 and perplexity is 170.65437986564677
At time: 244.81767010688782 and batch: 150, loss is 5.112861280441284 and perplexity is 166.14506303254888
At time: 245.9948754310608 and batch: 200, loss is 5.076300649642945 and perplexity is 160.1803951240872
At time: 247.1837558746338 and batch: 250, loss is 5.087299385070801 and perplexity is 161.95190121564784
At time: 248.38218474388123 and batch: 300, loss is 5.08726993560791 and perplexity is 161.94713188937035
At time: 249.58023619651794 and batch: 350, loss is 5.082872447967529 and perplexity is 161.2365349442539
At time: 250.77863430976868 and batch: 400, loss is 5.109035911560059 and perplexity is 165.51071096754254
At time: 251.97769331932068 and batch: 450, loss is 5.079730300903321 and perplexity is 160.73070115758793
At time: 253.17605137825012 and batch: 500, loss is 5.1118343067169185 and perplexity is 165.9745240029212
At time: 254.37857842445374 and batch: 550, loss is 5.0900271701812745 and perplexity is 162.39427427541847
At time: 255.57782816886902 and batch: 600, loss is 5.032279281616211 and perplexity is 153.28198765498766
At time: 256.7856252193451 and batch: 650, loss is 5.046162557601929 and perplexity is 155.4248845886694
At time: 257.98721837997437 and batch: 700, loss is 5.060366554260254 and perplexity is 157.6482923868851
At time: 259.18614530563354 and batch: 750, loss is 5.036378803253174 and perplexity is 153.91166027634335
At time: 260.38675689697266 and batch: 800, loss is 5.022239952087403 and perplexity is 151.75083798824164
At time: 261.58615922927856 and batch: 850, loss is 5.001879396438599 and perplexity is 148.69234853687166
At time: 262.78471302986145 and batch: 900, loss is 5.0274573421478275 and perplexity is 152.54465031558908
At time: 263.9836616516113 and batch: 950, loss is 4.992803354263305 and perplexity is 147.34891625646472
At time: 265.1810927391052 and batch: 1000, loss is 5.011952114105225 and perplexity is 150.197653109569
At time: 266.3792326450348 and batch: 1050, loss is 4.954502210617066 and perplexity is 141.81199629381487
At time: 267.57718539237976 and batch: 1100, loss is 4.949296178817749 and perplexity is 141.07563694977904
At time: 268.77720403671265 and batch: 1150, loss is 4.991446485519409 and perplexity is 147.14911869773448
At time: 269.9788897037506 and batch: 1200, loss is 4.953976325988769 and perplexity is 141.7374391508019
At time: 271.17696809768677 and batch: 1250, loss is 4.951066513061523 and perplexity is 141.32560918274925
At time: 272.37457036972046 and batch: 1300, loss is 4.92127649307251 and perplexity is 137.17760773902242
At time: 273.5718228816986 and batch: 1350, loss is 4.933081245422363 and perplexity is 138.80655114672982
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.069503580729167 and perplexity of 159.0953297493683
Finished 8 epochs...
Completing Train Step...
At time: 277.04776906967163 and batch: 50, loss is 5.073997535705566 and perplexity is 159.8119059227723
At time: 278.2288885116577 and batch: 100, loss is 5.076703243255615 and perplexity is 160.24489571093014
At time: 279.41269731521606 and batch: 150, loss is 5.056613779067993 and perplexity is 157.05778250456007
At time: 280.6024181842804 and batch: 200, loss is 5.023078880310059 and perplexity is 151.87819946514063
At time: 281.7924966812134 and batch: 250, loss is 5.0399642753601075 and perplexity is 154.46449673879985
At time: 282.9827034473419 and batch: 300, loss is 5.039614295959472 and perplexity is 154.4104468055451
At time: 284.1744637489319 and batch: 350, loss is 5.041142272949219 and perplexity is 154.64656275917386
At time: 285.37408351898193 and batch: 400, loss is 5.071028003692627 and perplexity is 159.33804327545099
At time: 286.57283067703247 and batch: 450, loss is 5.0402645778656 and perplexity is 154.51088977980478
At time: 287.77069306373596 and batch: 500, loss is 5.0767409324646 and perplexity is 160.2509353281068
At time: 288.96860432624817 and batch: 550, loss is 5.057995586395264 and perplexity is 157.2749561107142
At time: 290.1665070056915 and batch: 600, loss is 5.001414566040039 and perplexity is 148.6232478745269
At time: 291.3669202327728 and batch: 650, loss is 5.015177879333496 and perplexity is 150.68293776271292
At time: 292.5715935230255 and batch: 700, loss is 5.035647211074829 and perplexity is 153.79910088833336
At time: 293.7694523334503 and batch: 750, loss is 5.011543807983398 and perplexity is 150.13633900663396
At time: 294.966933965683 and batch: 800, loss is 4.995525941848755 and perplexity is 147.7506331932232
At time: 296.1644163131714 and batch: 850, loss is 4.976449489593506 and perplexity is 144.95878919749612
At time: 297.36183285713196 and batch: 900, loss is 5.008438844680786 and perplexity is 149.6708941521643
At time: 298.5596191883087 and batch: 950, loss is 4.974384536743164 and perplexity is 144.65976497427573
At time: 299.75763416290283 and batch: 1000, loss is 4.996843357086181 and perplexity is 147.94541040179155
At time: 300.9552345275879 and batch: 1050, loss is 4.941125612258912 and perplexity is 139.92766524423027
At time: 302.1529037952423 and batch: 1100, loss is 4.9378994274139405 and perplexity is 139.4769601511192
At time: 303.3494153022766 and batch: 1150, loss is 4.9761208152771 and perplexity is 144.91115279540938
At time: 304.6079623699188 and batch: 1200, loss is 4.941235847473145 and perplexity is 139.94309105060353
At time: 305.8050787448883 and batch: 1250, loss is 4.94447925567627 and perplexity is 140.39772049597707
At time: 307.00286316871643 and batch: 1300, loss is 4.918102521896362 and perplexity is 136.74290020557675
At time: 308.2009563446045 and batch: 1350, loss is 4.923865003585815 and perplexity is 137.53315338714464
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.067934977213541 and perplexity of 158.84596788188472
Finished 9 epochs...
Completing Train Step...
At time: 311.6526837348938 and batch: 50, loss is 5.04687463760376 and perplexity is 155.5355989548367
At time: 312.8509113788605 and batch: 100, loss is 5.047794332504273 and perplexity is 155.67871005122905
At time: 314.03050684928894 and batch: 150, loss is 5.0283346843719485 and perplexity is 152.67854290459724
At time: 315.21988248825073 and batch: 200, loss is 4.997444925308227 and perplexity is 148.03443643421807
At time: 316.4164934158325 and batch: 250, loss is 5.016476621627808 and perplexity is 150.8787632028818
At time: 317.6139614582062 and batch: 300, loss is 5.014917583465576 and perplexity is 150.6437207208856
At time: 318.81158804893494 and batch: 350, loss is 5.018740978240967 and perplexity is 151.22079362140417
At time: 320.00889682769775 and batch: 400, loss is 5.0501810073852536 and perplexity is 156.05070826082127
At time: 321.20684909820557 and batch: 450, loss is 5.018703212738037 and perplexity is 151.21508279991636
At time: 322.40599632263184 and batch: 500, loss is 5.056530885696411 and perplexity is 157.0447639950166
At time: 323.60362458229065 and batch: 550, loss is 5.038156385421753 and perplexity is 154.1854942082392
At time: 324.8015933036804 and batch: 600, loss is 4.981462507247925 and perplexity is 145.68729464661308
At time: 325.99899220466614 and batch: 650, loss is 4.995808200836182 and perplexity is 147.79234302355027
At time: 327.19667768478394 and batch: 700, loss is 5.01880560874939 and perplexity is 151.23056741401928
At time: 328.3955554962158 and batch: 750, loss is 4.995163650512695 and perplexity is 147.6971141142546
At time: 329.602347612381 and batch: 800, loss is 4.976856079101562 and perplexity is 145.0177399038416
At time: 330.80048727989197 and batch: 850, loss is 4.957776460647583 and perplexity is 142.27708522021635
At time: 331.99791073799133 and batch: 900, loss is 4.990116128921509 and perplexity is 146.95348805491093
At time: 333.1947708129883 and batch: 950, loss is 4.958771524429321 and perplexity is 142.4187304560247
At time: 334.3920707702637 and batch: 1000, loss is 4.982969751358032 and perplexity is 145.90704653165145
At time: 335.6161079406738 and batch: 1050, loss is 4.928428163528443 and perplexity is 138.16217323106517
At time: 336.8126986026764 and batch: 1100, loss is 4.92350477218628 and perplexity is 137.48361854935507
At time: 338.009699344635 and batch: 1150, loss is 4.962027196884155 and perplexity is 142.88315479036083
At time: 339.2130661010742 and batch: 1200, loss is 4.9278889083862305 and perplexity is 138.0876886535918
At time: 340.4112603664398 and batch: 1250, loss is 4.934158964157104 and perplexity is 138.95622620672663
At time: 341.6088480949402 and batch: 1300, loss is 4.907276201248169 and perplexity is 135.2704626440848
At time: 342.8064544200897 and batch: 1350, loss is 4.911936531066894 and perplexity is 135.90233884686694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065523681640625 and perplexity of 158.46340472454216
Finished 10 epochs...
Completing Train Step...
At time: 346.27454471588135 and batch: 50, loss is 5.024837064743042 and perplexity is 152.14546423267896
At time: 347.4830470085144 and batch: 100, loss is 5.025923690795898 and perplexity is 152.31087931383027
At time: 348.6687364578247 and batch: 150, loss is 5.00852557182312 and perplexity is 149.6838752440031
At time: 349.8675892353058 and batch: 200, loss is 4.9759048748016355 and perplexity is 144.8798639905559
At time: 351.06576323509216 and batch: 250, loss is 4.997687740325928 and perplexity is 148.07038578286534
At time: 352.26282691955566 and batch: 300, loss is 4.995597057342529 and perplexity is 147.761140926085
At time: 353.46153712272644 and batch: 350, loss is 5.000263605117798 and perplexity is 148.45228672775917
At time: 354.67174220085144 and batch: 400, loss is 5.031057367324829 and perplexity is 153.09480458778285
At time: 355.8718948364258 and batch: 450, loss is 5.001586055755615 and perplexity is 148.6487374185677
At time: 357.06998586654663 and batch: 500, loss is 5.041599073410034 and perplexity is 154.7172215175538
At time: 358.26861476898193 and batch: 550, loss is 5.022218847274781 and perplexity is 151.74763534903633
At time: 359.4663977622986 and batch: 600, loss is 4.96435001373291 and perplexity is 143.2154319498039
At time: 360.6641719341278 and batch: 650, loss is 4.978288364410401 and perplexity is 145.22559550095224
At time: 361.8615016937256 and batch: 700, loss is 5.004430980682373 and perplexity is 149.07223403939312
At time: 363.0598213672638 and batch: 750, loss is 4.981154413223266 and perplexity is 145.64241617541316
At time: 364.25717782974243 and batch: 800, loss is 4.961100044250489 and perplexity is 142.75074169015298
At time: 365.48189401626587 and batch: 850, loss is 4.941909971237183 and perplexity is 140.0374618191087
At time: 366.67977261543274 and batch: 900, loss is 4.974370155334473 and perplexity is 144.65768457803395
At time: 367.87861466407776 and batch: 950, loss is 4.945740327835083 and perplexity is 140.57488383685518
At time: 369.07613348960876 and batch: 1000, loss is 4.970398120880127 and perplexity is 144.08423889774426
At time: 370.2739632129669 and batch: 1050, loss is 4.9165673828125 and perplexity is 136.53314188032607
At time: 371.4713499546051 and batch: 1100, loss is 4.911104011535644 and perplexity is 135.78924457856002
At time: 372.67604660987854 and batch: 1150, loss is 4.948616571426392 and perplexity is 140.97979347582304
At time: 373.87539768218994 and batch: 1200, loss is 4.91458589553833 and perplexity is 136.26287105471877
At time: 375.07495403289795 and batch: 1250, loss is 4.922270421981811 and perplexity is 137.31402031003194
At time: 376.2720260620117 and batch: 1300, loss is 4.896657543182373 and perplexity is 133.84167120410294
At time: 377.4756829738617 and batch: 1350, loss is 4.899547252655029 and perplexity is 134.22899410501972
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0653914388020835 and perplexity of 158.44245045965278
Finished 11 epochs...
Completing Train Step...
At time: 380.947203874588 and batch: 50, loss is 5.007319602966309 and perplexity is 149.50346995553627
At time: 382.1369254589081 and batch: 100, loss is 5.008009080886841 and perplexity is 149.60658484074696
At time: 383.3280212879181 and batch: 150, loss is 4.990865287780761 and perplexity is 147.0636208106993
At time: 384.51929783821106 and batch: 200, loss is 4.957654514312744 and perplexity is 142.25973610899393
At time: 385.71393370628357 and batch: 250, loss is 4.9800310134887695 and perplexity is 145.47889339167367
At time: 386.9123725891113 and batch: 300, loss is 4.977198648452759 and perplexity is 145.0674270470727
At time: 388.11101484298706 and batch: 350, loss is 4.982650928497314 and perplexity is 145.8605354444702
At time: 389.3097929954529 and batch: 400, loss is 5.013980216979981 and perplexity is 150.50257850714152
At time: 390.5081853866577 and batch: 450, loss is 4.983894996643066 and perplexity is 146.04210881174163
At time: 391.7089958190918 and batch: 500, loss is 5.025240097045899 and perplexity is 152.2067961280352
At time: 392.9117531776428 and batch: 550, loss is 5.006867322921753 and perplexity is 149.43586780818703
At time: 394.1096978187561 and batch: 600, loss is 4.9482300758361815 and perplexity is 140.92531593567853
At time: 395.35396695137024 and batch: 650, loss is 4.960934114456177 and perplexity is 142.72705705399423
At time: 396.55157589912415 and batch: 700, loss is 4.990451736450195 and perplexity is 147.0028150286578
At time: 397.7498514652252 and batch: 750, loss is 4.968558216094971 and perplexity is 143.8193813481846
At time: 398.95205187797546 and batch: 800, loss is 4.947387781143188 and perplexity is 140.8066652663869
At time: 400.15159940719604 and batch: 850, loss is 4.928704900741577 and perplexity is 138.20041313680417
At time: 401.3497281074524 and batch: 900, loss is 4.960109052658081 and perplexity is 142.60934697738537
At time: 402.54798889160156 and batch: 950, loss is 4.932373037338257 and perplexity is 138.70828202668076
At time: 403.7459635734558 and batch: 1000, loss is 4.957510290145874 and perplexity is 142.23922029654793
At time: 404.94462633132935 and batch: 1050, loss is 4.904792013168335 and perplexity is 134.93484241771168
At time: 406.14950799942017 and batch: 1100, loss is 4.898539066314697 and perplexity is 134.0937344616059
At time: 407.3467946052551 and batch: 1150, loss is 4.934726581573487 and perplexity is 139.035122570193
At time: 408.5452723503113 and batch: 1200, loss is 4.901212873458863 and perplexity is 134.4527550087553
At time: 409.75272488594055 and batch: 1250, loss is 4.910924425125122 and perplexity is 135.76486086509595
At time: 410.9513554573059 and batch: 1300, loss is 4.885195236206055 and perplexity is 132.31629574427745
At time: 412.14957070350647 and batch: 1350, loss is 4.886787452697754 and perplexity is 132.52713974258415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.066119384765625 and perplexity of 158.5578299918559
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 415.6194517612457 and batch: 50, loss is 4.9892500877380375 and perplexity is 146.8262753758613
At time: 416.79294204711914 and batch: 100, loss is 4.992121419906616 and perplexity is 147.24846822142425
At time: 417.98299527168274 and batch: 150, loss is 4.973370389938355 and perplexity is 144.51313310153265
At time: 419.18191385269165 and batch: 200, loss is 4.941276350021362 and perplexity is 139.94875921718335
At time: 420.3809859752655 and batch: 250, loss is 4.95814884185791 and perplexity is 142.33007639925978
At time: 421.5793466567993 and batch: 300, loss is 4.954317378997803 and perplexity is 141.785787375102
At time: 422.7779393196106 and batch: 350, loss is 4.95806471824646 and perplexity is 142.31810358282044
At time: 423.97679591178894 and batch: 400, loss is 4.985997743606568 and perplexity is 146.34952150487248
At time: 425.1752395629883 and batch: 450, loss is 4.951700649261475 and perplexity is 141.4152572890628
At time: 426.3992648124695 and batch: 500, loss is 4.994174528121948 and perplexity is 147.55109581852327
At time: 427.59746742248535 and batch: 550, loss is 4.970414113998413 and perplexity is 144.0865432724472
At time: 428.796418428421 and batch: 600, loss is 4.911416492462158 and perplexity is 135.83168275773198
At time: 429.9945831298828 and batch: 650, loss is 4.920095710754395 and perplexity is 137.0157264374607
At time: 431.19352078437805 and batch: 700, loss is 4.944930467605591 and perplexity is 140.4610839164049
At time: 432.3917465209961 and batch: 750, loss is 4.922938184738159 and perplexity is 137.40574412018316
At time: 433.5909631252289 and batch: 800, loss is 4.901027669906616 and perplexity is 134.4278561866647
At time: 434.7968339920044 and batch: 850, loss is 4.8739742660522465 and perplexity is 130.83987745296656
At time: 435.9968776702881 and batch: 900, loss is 4.903802604675293 and perplexity is 134.8014027626659
At time: 437.20249342918396 and batch: 950, loss is 4.878322143554687 and perplexity is 131.4099917079163
At time: 438.40363478660583 and batch: 1000, loss is 4.898682889938354 and perplexity is 134.11302169535253
At time: 439.60188388824463 and batch: 1050, loss is 4.847953758239746 and perplexity is 127.47926937477274
At time: 440.80098366737366 and batch: 1100, loss is 4.8374569606781 and perplexity is 126.1481437909654
At time: 441.99943351745605 and batch: 1150, loss is 4.8684422969818115 and perplexity is 130.1180736366707
At time: 443.1998646259308 and batch: 1200, loss is 4.833824100494385 and perplexity is 125.69069664600025
At time: 444.3993124961853 and batch: 1250, loss is 4.843188104629516 and perplexity is 126.87319265736878
At time: 445.5972828865051 and batch: 1300, loss is 4.8164464950561525 and perplexity is 123.5253619688443
At time: 446.79688024520874 and batch: 1350, loss is 4.827765331268311 and perplexity is 124.93146803913922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.017553304036459 and perplexity of 151.04129919718264
Finished 13 epochs...
Completing Train Step...
At time: 450.23436188697815 and batch: 50, loss is 4.961498346328735 and perplexity is 142.8076109320562
At time: 451.47189378738403 and batch: 100, loss is 4.9637617588043215 and perplexity is 143.13120954066179
At time: 452.67439007759094 and batch: 150, loss is 4.947044916152954 and perplexity is 140.75839586589208
At time: 453.8792428970337 and batch: 200, loss is 4.91754566192627 and perplexity is 136.66677475583296
At time: 455.07712841033936 and batch: 250, loss is 4.9350783729553225 and perplexity is 139.08404253239172
At time: 456.29884004592896 and batch: 300, loss is 4.932878198623658 and perplexity is 138.7783697820449
At time: 457.4922888278961 and batch: 350, loss is 4.937717590332031 and perplexity is 139.4516003734356
At time: 458.69059920310974 and batch: 400, loss is 4.966201753616333 and perplexity is 143.48087536729926
At time: 459.8881814479828 and batch: 450, loss is 4.933363256454467 and perplexity is 138.84570164565838
At time: 461.08647990226746 and batch: 500, loss is 4.976886138916016 and perplexity is 145.02209917571471
At time: 462.2887554168701 and batch: 550, loss is 4.956094121932983 and perplexity is 142.03792819951377
At time: 463.48891401290894 and batch: 600, loss is 4.897726707458496 and perplexity is 133.9848464629081
At time: 464.68725180625916 and batch: 650, loss is 4.90826005935669 and perplexity is 135.40361507640995
At time: 465.8860185146332 and batch: 700, loss is 4.93480429649353 and perplexity is 139.04592809349649
At time: 467.09074807167053 and batch: 750, loss is 4.911879720687867 and perplexity is 135.89461840278904
At time: 468.2887065410614 and batch: 800, loss is 4.891726112365722 and perplexity is 133.18326503871685
At time: 469.4960515499115 and batch: 850, loss is 4.8666273212432865 and perplexity is 129.88212667365337
At time: 470.7055444717407 and batch: 900, loss is 4.897343769073486 and perplexity is 133.93354834482392
At time: 471.908145904541 and batch: 950, loss is 4.87271674156189 and perplexity is 130.67544651239035
At time: 473.10805916786194 and batch: 1000, loss is 4.89584228515625 and perplexity is 133.73260017398152
At time: 474.30795884132385 and batch: 1050, loss is 4.846133394241333 and perplexity is 127.24742178978057
At time: 475.50865387916565 and batch: 1100, loss is 4.835830316543579 and perplexity is 125.94311245450649
At time: 476.70825815200806 and batch: 1150, loss is 4.867847719192505 and perplexity is 130.04073131539067
At time: 477.9112093448639 and batch: 1200, loss is 4.834414873123169 and perplexity is 125.76497320739092
At time: 479.114177942276 and batch: 1250, loss is 4.845945148468018 and perplexity is 127.22347025492172
At time: 480.31807136535645 and batch: 1300, loss is 4.818002223968506 and perplexity is 123.71768350716742
At time: 481.5213224887848 and batch: 1350, loss is 4.826424531936645 and perplexity is 124.76407225744234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.015639241536459 and perplexity of 150.75247321410907
Finished 14 epochs...
Completing Train Step...
At time: 484.9999907016754 and batch: 50, loss is 4.950371112823486 and perplexity is 141.22736548378776
At time: 486.2116150856018 and batch: 100, loss is 4.95171591758728 and perplexity is 141.41741647976852
At time: 487.4123408794403 and batch: 150, loss is 4.935614433288574 and perplexity is 139.15861995779548
At time: 488.6039719581604 and batch: 200, loss is 4.906908617019654 and perplexity is 135.2207484930616
At time: 489.81018328666687 and batch: 250, loss is 4.925335941314697 and perplexity is 137.73560495175317
At time: 491.008793592453 and batch: 300, loss is 4.922741661071777 and perplexity is 137.3787432928044
At time: 492.20667266845703 and batch: 350, loss is 4.928506889343262 and perplexity is 138.17305058888877
At time: 493.4045855998993 and batch: 400, loss is 4.956951494216919 and perplexity is 142.1597598024765
At time: 494.60982275009155 and batch: 450, loss is 4.924547863006592 and perplexity is 137.62710126955182
At time: 495.814861536026 and batch: 500, loss is 4.9680538082122805 and perplexity is 143.74685601126242
At time: 497.01387095451355 and batch: 550, loss is 4.948461599349976 and perplexity is 140.9579472373176
At time: 498.2135126590729 and batch: 600, loss is 4.890904846191407 and perplexity is 133.07393103046226
At time: 499.4120898246765 and batch: 650, loss is 4.90104868888855 and perplexity is 134.43068175304043
At time: 500.6109890937805 and batch: 700, loss is 4.928315505981446 and perplexity is 138.14660909626627
At time: 501.81368136405945 and batch: 750, loss is 4.905340824127197 and perplexity is 135.00891646242738
At time: 503.0147018432617 and batch: 800, loss is 4.886689233779907 and perplexity is 132.5141237095541
At time: 504.21397590637207 and batch: 850, loss is 4.861561307907104 and perplexity is 129.2258059562241
At time: 505.4124150276184 and batch: 900, loss is 4.892714605331421 and perplexity is 133.3149808487071
At time: 506.61137557029724 and batch: 950, loss is 4.868608503341675 and perplexity is 130.13970188536874
At time: 507.8093001842499 and batch: 1000, loss is 4.893034009933472 and perplexity is 133.35756906818708
At time: 509.0088520050049 and batch: 1050, loss is 4.843932809829712 and perplexity is 126.96771097347876
At time: 510.20865082740784 and batch: 1100, loss is 4.832772216796875 and perplexity is 125.55855416271577
At time: 511.4072484970093 and batch: 1150, loss is 4.865525617599487 and perplexity is 129.73911385476958
At time: 512.6058554649353 and batch: 1200, loss is 4.832967023849488 and perplexity is 125.58301623719748
At time: 513.8044528961182 and batch: 1250, loss is 4.845045671463013 and perplexity is 127.1090871191426
At time: 515.0031132698059 and batch: 1300, loss is 4.816079301834106 and perplexity is 123.4800126196749
At time: 516.208699464798 and batch: 1350, loss is 4.823316316604615 and perplexity is 124.37688070424771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.014968668619792 and perplexity of 150.6514165751606
Finished 15 epochs...
Completing Train Step...
At time: 519.6746830940247 and batch: 50, loss is 4.941998863220215 and perplexity is 140.04991058007792
At time: 520.8549976348877 and batch: 100, loss is 4.942932357788086 and perplexity is 140.18070745042107
At time: 522.0534377098083 and batch: 150, loss is 4.927134675979614 and perplexity is 137.98357771071346
At time: 523.2586879730225 and batch: 200, loss is 4.898505449295044 and perplexity is 134.0892267056682
At time: 524.4564261436462 and batch: 250, loss is 4.91778299331665 and perplexity is 136.69921392076836
At time: 525.654913187027 and batch: 300, loss is 4.914527654647827 and perplexity is 136.25493521486348
At time: 526.8532705307007 and batch: 350, loss is 4.921558380126953 and perplexity is 137.21628178140344
At time: 528.0520644187927 and batch: 400, loss is 4.949502487182617 and perplexity is 141.1047450362784
At time: 529.2518997192383 and batch: 450, loss is 4.917665176391601 and perplexity is 136.68310938843948
At time: 530.4527812004089 and batch: 500, loss is 4.961370191574097 and perplexity is 142.78931063037706
At time: 531.6542854309082 and batch: 550, loss is 4.942705783843994 and perplexity is 140.14894975251772
At time: 532.8523411750793 and batch: 600, loss is 4.884679594039917 and perplexity is 132.24808547048252
At time: 534.0505797863007 and batch: 650, loss is 4.895197992324829 and perplexity is 133.64646496948922
At time: 535.2483110427856 and batch: 700, loss is 4.9225070190429685 and perplexity is 137.34651224728984
At time: 536.4471111297607 and batch: 750, loss is 4.899270181655884 and perplexity is 134.19180829530134
At time: 537.6449925899506 and batch: 800, loss is 4.881845455169678 and perplexity is 131.87380666052573
At time: 538.8432338237762 and batch: 850, loss is 4.856706457138062 and perplexity is 128.59995439003026
At time: 540.0424852371216 and batch: 900, loss is 4.888860111236572 and perplexity is 132.80210810972713
At time: 541.2463536262512 and batch: 950, loss is 4.864511585235595 and perplexity is 129.60762087479432
At time: 542.4439969062805 and batch: 1000, loss is 4.889522008895874 and perplexity is 132.89003861152167
At time: 543.6423528194427 and batch: 1050, loss is 4.840664367675782 and perplexity is 126.55340179636339
At time: 544.8409976959229 and batch: 1100, loss is 4.829027948379516 and perplexity is 125.08930827333461
At time: 546.0403335094452 and batch: 1150, loss is 4.861917266845703 and perplexity is 129.27181322481528
At time: 547.2648777961731 and batch: 1200, loss is 4.83005763053894 and perplexity is 125.21817683784322
At time: 548.4630055427551 and batch: 1250, loss is 4.842427015304565 and perplexity is 126.77666756158423
At time: 549.6612079143524 and batch: 1300, loss is 4.812814598083496 and perplexity is 123.07754428675666
At time: 550.8667569160461 and batch: 1350, loss is 4.819041709899903 and perplexity is 123.84635316220029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.01454833984375 and perplexity of 150.58810675602405
Finished 16 epochs...
Completing Train Step...
At time: 554.3356158733368 and batch: 50, loss is 4.934518728256226 and perplexity is 139.00622666191023
At time: 555.5190875530243 and batch: 100, loss is 4.9351628875732425 and perplexity is 139.09579766383834
At time: 556.7211017608643 and batch: 150, loss is 4.919763660430908 and perplexity is 136.9702378738384
At time: 557.9248242378235 and batch: 200, loss is 4.891189336776733 and perplexity is 133.11179469666578
At time: 559.1229827404022 and batch: 250, loss is 4.911122179031372 and perplexity is 135.79171155149
At time: 560.3210144042969 and batch: 300, loss is 4.908329935073852 and perplexity is 135.41307683168947
At time: 561.5188789367676 and batch: 350, loss is 4.915307607650757 and perplexity is 136.36124911528174
At time: 562.7171447277069 and batch: 400, loss is 4.942992630004883 and perplexity is 140.18915670703643
At time: 563.9147074222565 and batch: 450, loss is 4.911860675811767 and perplexity is 135.89203033126384
At time: 565.1192874908447 and batch: 500, loss is 4.956050710678101 and perplexity is 142.03176228864567
At time: 566.316935300827 and batch: 550, loss is 4.936980571746826 and perplexity is 139.34885981772396
At time: 567.5153799057007 and batch: 600, loss is 4.8794303894042965 and perplexity is 131.55570701510194
At time: 568.712739944458 and batch: 650, loss is 4.889705648422241 and perplexity is 132.91444471616543
At time: 569.9104878902435 and batch: 700, loss is 4.917176713943482 and perplexity is 136.6163611255481
At time: 571.1093628406525 and batch: 750, loss is 4.894279670715332 and perplexity is 133.5237908684349
At time: 572.3069839477539 and batch: 800, loss is 4.877152481079102 and perplexity is 131.25637622834319
At time: 573.5049142837524 and batch: 850, loss is 4.852159404754639 and perplexity is 128.0165310942795
At time: 574.7030029296875 and batch: 900, loss is 4.884254150390625 and perplexity is 132.19183332929464
At time: 575.9002904891968 and batch: 950, loss is 4.860075073242188 and perplexity is 129.03388873614983
At time: 577.1440243721008 and batch: 1000, loss is 4.885661277770996 and perplexity is 132.37797500924756
At time: 578.3414900302887 and batch: 1050, loss is 4.837148752212524 and perplexity is 126.10926985607799
At time: 579.5391182899475 and batch: 1100, loss is 4.8251396179199215 and perplexity is 124.60386410111008
At time: 580.7411589622498 and batch: 1150, loss is 4.858827266693115 and perplexity is 128.87297981721227
At time: 581.9403548240662 and batch: 1200, loss is 4.826999502182007 and perplexity is 124.83582851355978
At time: 583.1431291103363 and batch: 1250, loss is 4.839660482406616 and perplexity is 126.42642044855367
At time: 584.3424518108368 and batch: 1300, loss is 4.809322652816772 and perplexity is 122.6485137500755
At time: 585.5405716896057 and batch: 1350, loss is 4.815277070999145 and perplexity is 123.3809928697089
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.014726969401042 and perplexity of 150.61500864553204
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 588.9860355854034 and batch: 50, loss is 4.929950609207153 and perplexity is 138.3726778349146
At time: 590.1851716041565 and batch: 100, loss is 4.931658878326416 and perplexity is 138.609257620849
At time: 591.3754048347473 and batch: 150, loss is 4.916745948791504 and perplexity is 136.55752423133683
At time: 592.5728566646576 and batch: 200, loss is 4.888717565536499 and perplexity is 132.78317908941273
At time: 593.7701127529144 and batch: 250, loss is 4.907588062286377 and perplexity is 135.31265480970816
At time: 594.9683871269226 and batch: 300, loss is 4.903223848342895 and perplexity is 134.7234081693104
At time: 596.1656341552734 and batch: 350, loss is 4.90966492652893 and perplexity is 135.59397285262057
At time: 597.3638570308685 and batch: 400, loss is 4.935795583724976 and perplexity is 139.18383088594624
At time: 598.5617341995239 and batch: 450, loss is 4.90151162147522 and perplexity is 134.49292850318503
At time: 599.7601327896118 and batch: 500, loss is 4.944477567672729 and perplexity is 140.3974835043278
At time: 600.9572958946228 and batch: 550, loss is 4.924014759063721 and perplexity is 137.5537512725426
At time: 602.1560525894165 and batch: 600, loss is 4.866916465759277 and perplexity is 129.91968680819804
At time: 603.3544299602509 and batch: 650, loss is 4.876027498245239 and perplexity is 131.10879808525456
At time: 604.5519342422485 and batch: 700, loss is 4.901209487915039 and perplexity is 134.45229981383153
At time: 605.7489676475525 and batch: 750, loss is 4.875307836532593 and perplexity is 131.01447804641265
At time: 606.9726850986481 and batch: 800, loss is 4.859055891036987 and perplexity is 128.90244668595918
At time: 608.1706054210663 and batch: 850, loss is 4.827375631332398 and perplexity is 124.88279173924235
At time: 609.3680799007416 and batch: 900, loss is 4.857324419021606 and perplexity is 128.67944881980287
At time: 610.5660510063171 and batch: 950, loss is 4.8334754371643065 and perplexity is 125.64688054812493
At time: 611.7642376422882 and batch: 1000, loss is 4.860925846099853 and perplexity is 129.14371397794858
At time: 612.9626834392548 and batch: 1050, loss is 4.807427473068238 and perplexity is 122.4162928902696
At time: 614.1617710590363 and batch: 1100, loss is 4.794992742538452 and perplexity is 120.90350432733658
At time: 615.359668970108 and batch: 1150, loss is 4.826685886383057 and perplexity is 124.79668416392701
At time: 616.5576775074005 and batch: 1200, loss is 4.794028587341309 and perplexity is 120.78699076289182
At time: 617.7557597160339 and batch: 1250, loss is 4.804986228942871 and perplexity is 122.11780931827413
At time: 618.9531939029694 and batch: 1300, loss is 4.777719287872315 and perplexity is 118.83301684328322
At time: 620.1509592533112 and batch: 1350, loss is 4.787928314208984 and perplexity is 120.05240000857357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.000136311848959 and perplexity of 148.43339095359283
Finished 18 epochs...
Completing Train Step...
At time: 623.6172688007355 and batch: 50, loss is 4.919480543136597 and perplexity is 136.93146471962473
At time: 624.8195967674255 and batch: 100, loss is 4.919602870941162 and perplexity is 136.94821626964904
At time: 626.0130906105042 and batch: 150, loss is 4.904757795333862 and perplexity is 134.93022531860316
At time: 627.2045907974243 and batch: 200, loss is 4.877862520217896 and perplexity is 131.34960648733113
At time: 628.4032821655273 and batch: 250, loss is 4.8964730072021485 and perplexity is 133.81697487886277
At time: 629.6022596359253 and batch: 300, loss is 4.892278995513916 and perplexity is 133.25692018104542
At time: 630.8002195358276 and batch: 350, loss is 4.899813690185547 and perplexity is 134.26476251154426
At time: 631.9977622032166 and batch: 400, loss is 4.926159086227417 and perplexity is 137.8490279896637
At time: 633.1970686912537 and batch: 450, loss is 4.892559461593628 and perplexity is 133.29429946860915
At time: 634.3951404094696 and batch: 500, loss is 4.9367186546325685 and perplexity is 139.3123667457741
At time: 635.5933592319489 and batch: 550, loss is 4.917080307006836 and perplexity is 136.60319099553251
At time: 636.7912530899048 and batch: 600, loss is 4.860594568252563 and perplexity is 129.10093861204768
At time: 638.0194668769836 and batch: 650, loss is 4.870233325958252 and perplexity is 130.35132769695062
At time: 639.2203311920166 and batch: 700, loss is 4.896369857788086 and perplexity is 133.80317244818093
At time: 640.419272184372 and batch: 750, loss is 4.871474838256836 and perplexity is 130.51326097370068
At time: 641.6230204105377 and batch: 800, loss is 4.855240516662597 and perplexity is 128.41157262371084
At time: 642.8237061500549 and batch: 850, loss is 4.824668369293213 and perplexity is 124.545158534815
At time: 644.0282683372498 and batch: 900, loss is 4.855178298950196 and perplexity is 128.40358339795455
At time: 645.2277870178223 and batch: 950, loss is 4.832028388977051 and perplexity is 125.46519494300955
At time: 646.4270143508911 and batch: 1000, loss is 4.8603355503082275 and perplexity is 129.06750348265277
At time: 647.6287846565247 and batch: 1050, loss is 4.807573289871216 and perplexity is 122.43414454423521
At time: 648.8336284160614 and batch: 1100, loss is 4.795930290222168 and perplexity is 121.01691028120963
At time: 650.0402593612671 and batch: 1150, loss is 4.828235311508179 and perplexity is 124.99019716013747
At time: 651.2387793064117 and batch: 1200, loss is 4.796261310577393 and perplexity is 121.05697597275294
At time: 652.4386386871338 and batch: 1250, loss is 4.807935218811036 and perplexity is 122.47846502431625
At time: 653.6400420665741 and batch: 1300, loss is 4.780712385177612 and perplexity is 119.18922844784338
At time: 654.8478698730469 and batch: 1350, loss is 4.788706760406495 and perplexity is 120.14589072688823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998853759765625 and perplexity of 148.24313942861326
Finished 19 epochs...
Completing Train Step...
At time: 658.309561252594 and batch: 50, loss is 4.914685430526734 and perplexity is 136.27643465302413
At time: 659.4875831604004 and batch: 100, loss is 4.914122409820557 and perplexity is 136.19972979378878
At time: 660.6703724861145 and batch: 150, loss is 4.898945751190186 and perplexity is 134.14827944586753
At time: 661.8672432899475 and batch: 200, loss is 4.87241946220398 and perplexity is 130.63660517320682
At time: 663.0647540092468 and batch: 250, loss is 4.891228151321411 and perplexity is 133.11696147064052
At time: 664.2647840976715 and batch: 300, loss is 4.886983909606934 and perplexity is 132.55317817247138
At time: 665.4632878303528 and batch: 350, loss is 4.895123376846313 and perplexity is 133.6364932465806
At time: 666.6624360084534 and batch: 400, loss is 4.92149432182312 and perplexity is 137.20749222065945
At time: 667.8867149353027 and batch: 450, loss is 4.888253965377808 and perplexity is 132.72163505353
At time: 669.0841083526611 and batch: 500, loss is 4.9327077960968015 and perplexity is 138.75472361190185
At time: 670.2820649147034 and batch: 550, loss is 4.913429470062256 and perplexity is 136.10538427759948
At time: 671.4805088043213 and batch: 600, loss is 4.857422170639038 and perplexity is 128.6920280588657
At time: 672.6789784431458 and batch: 650, loss is 4.867009420394897 and perplexity is 129.93176400665223
At time: 673.8795564174652 and batch: 700, loss is 4.89366907119751 and perplexity is 133.44228619200322
At time: 675.0794849395752 and batch: 750, loss is 4.869084882736206 and perplexity is 130.20171252688053
At time: 676.2776539325714 and batch: 800, loss is 4.852880353927612 and perplexity is 128.10885778392506
At time: 677.4753696918488 and batch: 850, loss is 4.823076744079589 and perplexity is 124.34708698990282
At time: 678.6734280586243 and batch: 900, loss is 4.853620414733887 and perplexity is 128.20370121913334
At time: 679.87096118927 and batch: 950, loss is 4.830926322937012 and perplexity is 125.3270001763227
At time: 681.0689208507538 and batch: 1000, loss is 4.859431438446045 and perplexity is 128.95086475690476
At time: 682.2674918174744 and batch: 1050, loss is 4.807124300003052 and perplexity is 122.37918519283679
At time: 683.466183423996 and batch: 1100, loss is 4.7958215141296385 and perplexity is 121.00374725050372
At time: 684.664968252182 and batch: 1150, loss is 4.828499698638916 and perplexity is 125.02324732856206
At time: 685.863461971283 and batch: 1200, loss is 4.7968486881256105 and perplexity is 121.12810300966179
At time: 687.0614233016968 and batch: 1250, loss is 4.808727035522461 and perplexity is 122.57548392523671
At time: 688.2662868499756 and batch: 1300, loss is 4.781787271499634 and perplexity is 119.31741219837265
At time: 689.4647798538208 and batch: 1350, loss is 4.78879898071289 and perplexity is 120.15697112865442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998711344401042 and perplexity of 148.222028831137
Finished 20 epochs...
Completing Train Step...
At time: 692.9430632591248 and batch: 50, loss is 4.911101484298706 and perplexity is 135.78890140739898
At time: 694.1182637214661 and batch: 100, loss is 4.9100277137756345 and perplexity is 135.64317354085296
At time: 695.31538438797 and batch: 150, loss is 4.894752054214478 and perplexity is 133.58688020399188
At time: 696.5129904747009 and batch: 200, loss is 4.868506908416748 and perplexity is 130.12648102372327
At time: 697.7369999885559 and batch: 250, loss is 4.88737361907959 and perplexity is 132.6048454685993
At time: 698.9346206188202 and batch: 300, loss is 4.88306830406189 and perplexity is 132.0351670384844
At time: 700.1322438716888 and batch: 350, loss is 4.891619091033935 and perplexity is 133.1690123510051
At time: 701.3301913738251 and batch: 400, loss is 4.918116359710694 and perplexity is 136.74479244153315
At time: 702.5278923511505 and batch: 450, loss is 4.884898509979248 and perplexity is 132.27703985351036
At time: 703.7308523654938 and batch: 500, loss is 4.929731988906861 and perplexity is 138.34243006504283
At time: 704.9301447868347 and batch: 550, loss is 4.910784721374512 and perplexity is 135.74589532964106
At time: 706.1277577877045 and batch: 600, loss is 4.855036516189575 and perplexity is 128.38537927397275
At time: 707.3247833251953 and batch: 650, loss is 4.864699668884278 and perplexity is 129.63200024163373
At time: 708.5222234725952 and batch: 700, loss is 4.891672410964966 and perplexity is 133.17611310286318
At time: 709.7266187667847 and batch: 750, loss is 4.867207832336426 and perplexity is 129.9575465779155
At time: 710.923942565918 and batch: 800, loss is 4.850938501358033 and perplexity is 127.86033064887465
At time: 712.1213111877441 and batch: 850, loss is 4.821477584838867 and perplexity is 124.14839510900775
At time: 713.319650888443 and batch: 900, loss is 4.852239828109742 and perplexity is 128.02682702722987
At time: 714.5177342891693 and batch: 950, loss is 4.829834499359131 and perplexity is 125.19023987523144
At time: 715.7151169776917 and batch: 1000, loss is 4.858535976409912 and perplexity is 128.83544583733124
At time: 716.9191648960114 and batch: 1050, loss is 4.806254148483276 and perplexity is 122.27274307595343
At time: 718.1171007156372 and batch: 1100, loss is 4.79498664855957 and perplexity is 120.90276754617948
At time: 719.314858675003 and batch: 1150, loss is 4.827891435623169 and perplexity is 124.94722343470887
At time: 720.5131874084473 and batch: 1200, loss is 4.796563186645508 and perplexity is 121.0935256931429
At time: 721.7105674743652 and batch: 1250, loss is 4.808516044616699 and perplexity is 122.5496243410236
At time: 722.9084374904633 and batch: 1300, loss is 4.781836252212525 and perplexity is 119.32325659341258
At time: 724.1059336662292 and batch: 1350, loss is 4.787975473403931 and perplexity is 120.05806171660912
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998489176432292 and perplexity of 148.1891023018131
Finished 21 epochs...
Completing Train Step...
At time: 727.5219705104828 and batch: 50, loss is 4.908020305633545 and perplexity is 135.3711554468821
At time: 728.7230868339539 and batch: 100, loss is 4.906427431106567 and perplexity is 135.15569782571725
At time: 729.9074273109436 and batch: 150, loss is 4.89146800994873 and perplexity is 133.14889455185119
At time: 731.1049659252167 and batch: 200, loss is 4.865198831558228 and perplexity is 129.69672384996468
At time: 732.3024814128876 and batch: 250, loss is 4.884226274490357 and perplexity is 132.1881484142929
At time: 733.4998643398285 and batch: 300, loss is 4.879916009902954 and perplexity is 131.61960867786667
At time: 734.7022948265076 and batch: 350, loss is 4.888908348083496 and perplexity is 132.8085142191912
At time: 735.9002838134766 and batch: 400, loss is 4.915273294448853 and perplexity is 136.35657020448366
At time: 737.0983231067657 and batch: 450, loss is 4.882094774246216 and perplexity is 131.90668941520053
At time: 738.2963309288025 and batch: 500, loss is 4.927451686859131 and perplexity is 138.0273269401669
At time: 739.4940187931061 and batch: 550, loss is 4.908580513000488 and perplexity is 135.4470126113224
At time: 740.6921305656433 and batch: 600, loss is 4.853071928024292 and perplexity is 128.13340247361998
At time: 741.8900337219238 and batch: 650, loss is 4.862501945495605 and perplexity is 129.34741779407696
At time: 743.0877795219421 and batch: 700, loss is 4.889792013168335 and perplexity is 132.9259243341455
At time: 744.2862374782562 and batch: 750, loss is 4.865303211212158 and perplexity is 129.71026225567076
At time: 745.4849524497986 and batch: 800, loss is 4.84913670539856 and perplexity is 127.63015984441755
At time: 746.6847791671753 and batch: 850, loss is 4.819891767501831 and perplexity is 123.95167445441739
At time: 747.8900609016418 and batch: 900, loss is 4.85086142539978 and perplexity is 127.85047607114782
At time: 749.0881071090698 and batch: 950, loss is 4.828712530136109 and perplexity is 125.04985904528014
At time: 750.2862040996552 and batch: 1000, loss is 4.857433967590332 and perplexity is 128.69354624140757
At time: 751.4845769405365 and batch: 1050, loss is 4.80528697013855 and perplexity is 122.15454069730471
At time: 752.6829071044922 and batch: 1100, loss is 4.794076061248779 and perplexity is 120.7927251294302
At time: 753.8802375793457 and batch: 1150, loss is 4.827120304107666 and perplexity is 124.85090983294334
At time: 755.0771446228027 and batch: 1200, loss is 4.796020965576172 and perplexity is 121.0278840299066
At time: 756.2745099067688 and batch: 1250, loss is 4.80792350769043 and perplexity is 122.4770306726397
At time: 757.472275018692 and batch: 1300, loss is 4.781499519348144 and perplexity is 119.28308329564707
At time: 758.6700196266174 and batch: 1350, loss is 4.786867160797119 and perplexity is 119.92507356309582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998465169270833 and perplexity of 148.1855447448113
Finished 22 epochs...
Completing Train Step...
At time: 762.1104063987732 and batch: 50, loss is 4.904994964599609 and perplexity is 134.96223041623185
At time: 763.3178086280823 and batch: 100, loss is 4.903216962814331 and perplexity is 134.72248053062884
At time: 764.5050156116486 and batch: 150, loss is 4.888287220001221 and perplexity is 132.72604873490974
At time: 765.6952886581421 and batch: 200, loss is 4.862359085083008 and perplexity is 129.32894048847166
At time: 766.8901453018188 and batch: 250, loss is 4.88136854171753 and perplexity is 131.81092926287346
At time: 768.0897450447083 and batch: 300, loss is 4.87709566116333 and perplexity is 131.24891846397819
At time: 769.2917957305908 and batch: 350, loss is 4.886455917358399 and perplexity is 132.48320959493643
At time: 770.489128112793 and batch: 400, loss is 4.912663202285767 and perplexity is 136.00113105546447
At time: 771.6932156085968 and batch: 450, loss is 4.879574117660522 and perplexity is 131.57461664635937
At time: 772.8907299041748 and batch: 500, loss is 4.925202827453614 and perplexity is 137.71727165380454
At time: 774.0878398418427 and batch: 550, loss is 4.9062426662445064 and perplexity is 135.13072810868596
At time: 775.2868020534515 and batch: 600, loss is 4.851055335998535 and perplexity is 127.87527003734262
At time: 776.4849789142609 and batch: 650, loss is 4.860654497146607 and perplexity is 129.10867572035457
At time: 777.682849407196 and batch: 700, loss is 4.8880163764953615 and perplexity is 132.69010561425165
At time: 778.8805222511292 and batch: 750, loss is 4.863613862991333 and perplexity is 129.4913214406141
At time: 780.0779299736023 and batch: 800, loss is 4.847317018508911 and perplexity is 127.39812409605709
At time: 781.2761626243591 and batch: 850, loss is 4.81839373588562 and perplexity is 123.7661299376769
At time: 782.4739093780518 and batch: 900, loss is 4.849203186035156 and perplexity is 127.6386450607411
At time: 783.677892446518 and batch: 950, loss is 4.827276496887207 and perplexity is 124.8704121666006
At time: 784.8757953643799 and batch: 1000, loss is 4.856241836547851 and perplexity is 128.54021808175457
At time: 786.0740630626678 and batch: 1050, loss is 4.803940782546997 and perplexity is 121.99020840622893
At time: 787.2713007926941 and batch: 1100, loss is 4.792862634658814 and perplexity is 120.64624091677679
At time: 788.4969685077667 and batch: 1150, loss is 4.826162824630737 and perplexity is 124.7314248604352
At time: 789.694845199585 and batch: 1200, loss is 4.794996900558472 and perplexity is 120.9040070475732
At time: 790.8924026489258 and batch: 1250, loss is 4.807067642211914 and perplexity is 122.37225165494382
At time: 792.0901551246643 and batch: 1300, loss is 4.780945644378662 and perplexity is 119.2170336748314
At time: 793.2880463600159 and batch: 1350, loss is 4.785779762268066 and perplexity is 119.79473809065009
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998336181640625 and perplexity of 148.16643187525196
Finished 23 epochs...
Completing Train Step...
At time: 796.7965745925903 and batch: 50, loss is 4.902409753799438 and perplexity is 134.61377520969592
At time: 797.9676733016968 and batch: 100, loss is 4.900571899414063 and perplexity is 134.36660189644692
At time: 799.1464130878448 and batch: 150, loss is 4.8855850124359135 and perplexity is 132.36787954359784
At time: 800.3362898826599 and batch: 200, loss is 4.859505519866944 and perplexity is 128.9604179740457
At time: 801.5260639190674 and batch: 250, loss is 4.87860728263855 and perplexity is 131.44746717516855
At time: 802.7157609462738 and batch: 300, loss is 4.874549522399902 and perplexity is 130.91516557590697
At time: 803.9126498699188 and batch: 350, loss is 4.8843016433715825 and perplexity is 132.19811166260493
At time: 805.110381603241 and batch: 400, loss is 4.910308103561402 and perplexity is 135.68121183374805
At time: 806.3079524040222 and batch: 450, loss is 4.877131214141846 and perplexity is 131.2535848369078
At time: 807.5049858093262 and batch: 500, loss is 4.923141307830811 and perplexity is 137.43365723468006
At time: 808.7084641456604 and batch: 550, loss is 4.904254293441772 and perplexity is 134.862304795346
At time: 809.9089021682739 and batch: 600, loss is 4.849133625030517 and perplexity is 127.62976669715744
At time: 811.1068062782288 and batch: 650, loss is 4.85898588180542 and perplexity is 128.89342264060656
At time: 812.3040764331818 and batch: 700, loss is 4.886426210403442 and perplexity is 132.47927398065434
At time: 813.5016572475433 and batch: 750, loss is 4.86181676864624 and perplexity is 129.25882229313845
At time: 814.698878288269 and batch: 800, loss is 4.845454692840576 and perplexity is 127.16108808708566
At time: 815.8964548110962 and batch: 850, loss is 4.816815118789673 and perplexity is 123.57090474251568
At time: 817.0939257144928 and batch: 900, loss is 4.847610387802124 and perplexity is 127.43550427651027
At time: 818.3284583091736 and batch: 950, loss is 4.825963716506958 and perplexity is 124.70659229272002
At time: 819.5286977291107 and batch: 1000, loss is 4.8549629592895505 and perplexity is 128.3759359907785
At time: 820.7262063026428 and batch: 1050, loss is 4.802685098648071 and perplexity is 121.83712339901066
At time: 821.9244284629822 and batch: 1100, loss is 4.791667499542236 and perplexity is 120.50213848566435
At time: 823.121933221817 and batch: 1150, loss is 4.825189304351807 and perplexity is 124.61005537632629
At time: 824.3199145793915 and batch: 1200, loss is 4.794028968811035 and perplexity is 120.78703683948088
At time: 825.5174901485443 and batch: 1250, loss is 4.806112813949585 and perplexity is 122.25546293599662
At time: 826.720440864563 and batch: 1300, loss is 4.7802574348449705 and perplexity is 119.13501560172503
At time: 827.9182391166687 and batch: 1350, loss is 4.784667339324951 and perplexity is 119.66154977014018
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998324788411458 and perplexity of 148.16474379075513
Finished 24 epochs...
Completing Train Step...
At time: 831.3619494438171 and batch: 50, loss is 4.899746503829956 and perplexity is 134.25574205449604
At time: 832.5283915996552 and batch: 100, loss is 4.897931480407715 and perplexity is 134.01228574438443
At time: 833.7143409252167 and batch: 150, loss is 4.882941961288452 and perplexity is 132.01848640305047
At time: 834.9109992980957 and batch: 200, loss is 4.857073011398316 and perplexity is 128.64710189171132
At time: 836.1095869541168 and batch: 250, loss is 4.876389141082764 and perplexity is 131.15622121761976
At time: 837.3074672222137 and batch: 300, loss is 4.872365684509277 and perplexity is 130.62958002663657
At time: 838.5113606452942 and batch: 350, loss is 4.882017183303833 and perplexity is 131.8964550479144
At time: 839.7097816467285 and batch: 400, loss is 4.908159322738648 and perplexity is 135.38997566116234
At time: 840.9071073532104 and batch: 450, loss is 4.875007629394531 and perplexity is 130.9751524681187
At time: 842.1048538684845 and batch: 500, loss is 4.921113834381104 and perplexity is 137.1552964234713
At time: 843.3024473190308 and batch: 550, loss is 4.902383832931519 and perplexity is 134.61028594903107
At time: 844.5009288787842 and batch: 600, loss is 4.847354345321655 and perplexity is 127.40287955073157
At time: 845.6988456249237 and batch: 650, loss is 4.857191591262818 and perplexity is 128.66235775212326
At time: 846.8968279361725 and batch: 700, loss is 4.88481559753418 and perplexity is 132.26607289536472
At time: 848.0942525863647 and batch: 750, loss is 4.860077514648437 and perplexity is 129.03420376067677
At time: 849.3180387020111 and batch: 800, loss is 4.843582611083985 and perplexity is 126.923254825046
At time: 850.5161416530609 and batch: 850, loss is 4.815210676193237 and perplexity is 123.37280128457691
At time: 851.7144401073456 and batch: 900, loss is 4.845998096466064 and perplexity is 127.23020666131428
At time: 852.9121241569519 and batch: 950, loss is 4.824665861129761 and perplexity is 124.54484615559198
At time: 854.1104998588562 and batch: 1000, loss is 4.853503913879394 and perplexity is 128.18876624837753
At time: 855.309642791748 and batch: 1050, loss is 4.801208200454712 and perplexity is 121.6573151834765
At time: 856.5085120201111 and batch: 1100, loss is 4.790472440719604 and perplexity is 120.3582173561574
At time: 857.7070202827454 and batch: 1150, loss is 4.824000864028931 and perplexity is 124.46205172605413
At time: 858.9051909446716 and batch: 1200, loss is 4.792955045700073 and perplexity is 120.65739047668721
At time: 860.102826833725 and batch: 1250, loss is 4.805246305465698 and perplexity is 122.14957342386691
At time: 861.3007125854492 and batch: 1300, loss is 4.779457702636718 and perplexity is 119.03977758015033
At time: 862.4976019859314 and batch: 1350, loss is 4.783219232559204 and perplexity is 119.48839247570248
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998316650390625 and perplexity of 148.16353802788967
Finished 25 epochs...
Completing Train Step...
At time: 865.9539895057678 and batch: 50, loss is 4.897112007141113 and perplexity is 133.9025112435982
At time: 867.1478288173676 and batch: 100, loss is 4.895517816543579 and perplexity is 133.68921518164902
At time: 868.3225085735321 and batch: 150, loss is 4.880517616271972 and perplexity is 131.69881569606937
At time: 869.5129346847534 and batch: 200, loss is 4.854540529251099 and perplexity is 128.32171759174813
At time: 870.7080068588257 and batch: 250, loss is 4.873999948501587 and perplexity is 130.84323778464156
At time: 871.9060530662537 and batch: 300, loss is 4.869906196594238 and perplexity is 130.308692923946
At time: 873.1041522026062 and batch: 350, loss is 4.879871387481689 and perplexity is 131.6137356232775
At time: 874.3029127120972 and batch: 400, loss is 4.905840320587158 and perplexity is 135.07636978320852
At time: 875.507896900177 and batch: 450, loss is 4.872816257476806 and perplexity is 130.6884514460954
At time: 876.7055609226227 and batch: 500, loss is 4.918934898376465 and perplexity is 136.85676916387578
At time: 877.9038422107697 and batch: 550, loss is 4.900477247238159 and perplexity is 134.3538844070872
At time: 879.1286873817444 and batch: 600, loss is 4.845659532546997 and perplexity is 127.18713839501521
At time: 880.3263349533081 and batch: 650, loss is 4.855328845977783 and perplexity is 128.42291563093528
At time: 881.5246391296387 and batch: 700, loss is 4.882961587905884 and perplexity is 132.0210775048042
At time: 882.7224586009979 and batch: 750, loss is 4.858298130035401 and perplexity is 128.80480643750982
At time: 883.9210476875305 and batch: 800, loss is 4.841793355941772 and perplexity is 126.69635978577423
At time: 885.1259729862213 and batch: 850, loss is 4.813524713516236 and perplexity is 123.16497458950802
At time: 886.3246335983276 and batch: 900, loss is 4.844399538040161 and perplexity is 127.02698421717767
At time: 887.5227732658386 and batch: 950, loss is 4.823172378540039 and perplexity is 124.35897942512982
At time: 888.7200133800507 and batch: 1000, loss is 4.852199296951294 and perplexity is 128.02163805677634
At time: 889.9188861846924 and batch: 1050, loss is 4.799864711761475 and perplexity is 121.49397970033316
At time: 891.116751909256 and batch: 1100, loss is 4.789286708831787 and perplexity is 120.21558935587213
At time: 892.3141894340515 and batch: 1150, loss is 4.822810935974121 and perplexity is 124.31403891870669
At time: 893.5120282173157 and batch: 1200, loss is 4.791637363433838 and perplexity is 120.4985070748753
At time: 894.7096335887909 and batch: 1250, loss is 4.8041418838500975 and perplexity is 122.0147432630181
At time: 895.9076826572418 and batch: 1300, loss is 4.778670682907104 and perplexity is 118.94612778353856
At time: 897.105929851532 and batch: 1350, loss is 4.7816595935821535 and perplexity is 119.302178972158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.998515625 and perplexity of 148.1930217431504
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 900.5356996059418 and batch: 50, loss is 4.8957287883758545 and perplexity is 133.7174228157348
At time: 901.7350828647614 and batch: 100, loss is 4.894962453842163 and perplexity is 133.6149897908701
At time: 902.9076368808746 and batch: 150, loss is 4.8801281452178955 and perplexity is 131.6475328067483
At time: 904.0845959186554 and batch: 200, loss is 4.854422721862793 and perplexity is 128.3066012357624
At time: 905.2756502628326 and batch: 250, loss is 4.873154525756836 and perplexity is 130.73266668167
At time: 906.4663276672363 and batch: 300, loss is 4.868759250640869 and perplexity is 130.15932157271612
At time: 907.6568696498871 and batch: 350, loss is 4.878151502609253 and perplexity is 131.38756969580282
At time: 908.8542850017548 and batch: 400, loss is 4.903150844573974 and perplexity is 134.71357321175105
At time: 910.0808744430542 and batch: 450, loss is 4.868646192550659 and perplexity is 130.14460684022157
At time: 911.2783935070038 and batch: 500, loss is 4.913404026031494 and perplexity is 136.10192125207197
At time: 912.4771704673767 and batch: 550, loss is 4.894184112548828 and perplexity is 133.51103218940253
At time: 913.6792116165161 and batch: 600, loss is 4.839968118667603 and perplexity is 126.46531978294647
At time: 914.882884979248 and batch: 650, loss is 4.849781064987183 and perplexity is 127.7124260633779
At time: 916.0859830379486 and batch: 700, loss is 4.875803604125976 and perplexity is 131.0794468822831
At time: 917.2908840179443 and batch: 750, loss is 4.850669441223144 and perplexity is 127.82593315876755
At time: 918.4871592521667 and batch: 800, loss is 4.834248104095459 and perplexity is 125.74400125387389
At time: 919.6835956573486 and batch: 850, loss is 4.803812637329101 and perplexity is 121.97457694596142
At time: 920.8811388015747 and batch: 900, loss is 4.830683736801148 and perplexity is 125.29660127095602
At time: 922.0795469284058 and batch: 950, loss is 4.810325288772583 and perplexity is 122.77154722847584
At time: 923.277398109436 and batch: 1000, loss is 4.840120887756347 and perplexity is 126.48464125043142
At time: 924.4756345748901 and batch: 1050, loss is 4.78624080657959 and perplexity is 119.84998150705015
At time: 925.6742973327637 and batch: 1100, loss is 4.774968147277832 and perplexity is 118.50653980471704
At time: 926.87246966362 and batch: 1150, loss is 4.807855548858643 and perplexity is 122.46870755953218
At time: 928.0708734989166 and batch: 1200, loss is 4.77505916595459 and perplexity is 118.51732660404991
At time: 929.2703545093536 and batch: 1250, loss is 4.787848949432373 and perplexity is 120.04287245474636
At time: 930.4698407649994 and batch: 1300, loss is 4.764590559005737 and perplexity is 117.28308695195359
At time: 931.6686041355133 and batch: 1350, loss is 4.769249534606933 and perplexity is 117.83078084805611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.993948567708333 and perplexity of 147.51775887843903
Finished 27 epochs...
Completing Train Step...
At time: 935.1694707870483 and batch: 50, loss is 4.892139835357666 and perplexity is 133.2383774174485
At time: 936.3411042690277 and batch: 100, loss is 4.890659427642822 and perplexity is 133.0412762266655
At time: 937.5141086578369 and batch: 150, loss is 4.875833721160888 and perplexity is 131.0833946660086
At time: 938.695122718811 and batch: 200, loss is 4.85021330833435 and perplexity is 127.76764084214513
At time: 939.9124042987823 and batch: 250, loss is 4.869263429641723 and perplexity is 130.22496171521883
At time: 941.1032769680023 and batch: 300, loss is 4.864820194244385 and perplexity is 129.64762512672283
At time: 942.2947125434875 and batch: 350, loss is 4.874720840454102 and perplexity is 130.9375956286203
At time: 943.4866802692413 and batch: 400, loss is 4.899773216247558 and perplexity is 134.25932839784303
At time: 944.6780045032501 and batch: 450, loss is 4.865585546493531 and perplexity is 129.74688920935898
At time: 945.8697125911713 and batch: 500, loss is 4.910579242706299 and perplexity is 135.7180053093536
At time: 947.0685503482819 and batch: 550, loss is 4.891760559082031 and perplexity is 133.18785284388167
At time: 948.2667984962463 and batch: 600, loss is 4.837601985931396 and perplexity is 126.16643978412999
At time: 949.4653367996216 and batch: 650, loss is 4.847719326019287 and perplexity is 127.4493876293495
At time: 950.6636409759521 and batch: 700, loss is 4.87409273147583 and perplexity is 130.85537837261404
At time: 951.8616771697998 and batch: 750, loss is 4.8493398094177245 and perplexity is 127.65608467547817
At time: 953.0593183040619 and batch: 800, loss is 4.83334002494812 and perplexity is 125.62986757748098
At time: 954.2579638957977 and batch: 850, loss is 4.803069314956665 and perplexity is 121.88394420289494
At time: 955.4566216468811 and batch: 900, loss is 4.830290107727051 and perplexity is 125.24729059150552
At time: 956.6547255516052 and batch: 950, loss is 4.810037460327148 and perplexity is 122.73621516992307
At time: 957.8531894683838 and batch: 1000, loss is 4.840340566635132 and perplexity is 126.51243030682743
At time: 959.0514628887177 and batch: 1050, loss is 4.786782426834106 and perplexity is 119.9149122668578
At time: 960.2494397163391 and batch: 1100, loss is 4.775814933776855 and perplexity is 118.60693204206642
At time: 961.4477059841156 and batch: 1150, loss is 4.808809566497803 and perplexity is 122.58560061694253
At time: 962.6455547809601 and batch: 1200, loss is 4.776466035842896 and perplexity is 118.68418240677266
At time: 963.8430142402649 and batch: 1250, loss is 4.7891003608703615 and perplexity is 120.19318951301148
At time: 965.0411570072174 and batch: 1300, loss is 4.765869998931885 and perplexity is 117.43323965125818
At time: 966.2391800880432 and batch: 1350, loss is 4.769745674133301 and perplexity is 117.88925586054057
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.993549397786459 and perplexity of 147.45888597707983
Finished 28 epochs...
Completing Train Step...
At time: 969.7237265110016 and batch: 50, loss is 4.890404844284058 and perplexity is 133.00741044272488
At time: 970.8960564136505 and batch: 100, loss is 4.888706884384155 and perplexity is 132.78176081962255
At time: 972.0691447257996 and batch: 150, loss is 4.873604574203491 and perplexity is 130.79151595675634
At time: 973.242639541626 and batch: 200, loss is 4.848050012588501 and perplexity is 127.49154039938638
At time: 974.4270768165588 and batch: 250, loss is 4.867251253128051 and perplexity is 129.96318955997612
At time: 975.6181483268738 and batch: 300, loss is 4.862712697982788 and perplexity is 129.37468095687652
At time: 976.813854932785 and batch: 350, loss is 4.872865114212036 and perplexity is 130.69483661314322
At time: 978.0113005638123 and batch: 400, loss is 4.897839946746826 and perplexity is 134.000019670654
At time: 979.2096264362335 and batch: 450, loss is 4.863758401870728 and perplexity is 129.51003932380485
At time: 980.4077286720276 and batch: 500, loss is 4.908881406784058 and perplexity is 135.48777390752306
At time: 981.6054701805115 and batch: 550, loss is 4.890294961929321 and perplexity is 132.99279607821308
At time: 982.8104736804962 and batch: 600, loss is 4.8364561080932615 and perplexity is 126.02195125577613
At time: 984.0100140571594 and batch: 650, loss is 4.8465110206604 and perplexity is 127.29548285199884
At time: 985.2102520465851 and batch: 700, loss is 4.873158569335938 and perplexity is 130.7331953106177
At time: 986.409893989563 and batch: 750, loss is 4.848516387939453 and perplexity is 127.55101317852476
At time: 987.6149351596832 and batch: 800, loss is 4.83284026145935 and perplexity is 125.56709804283408
At time: 988.8146812915802 and batch: 850, loss is 4.802591981887818 and perplexity is 121.8257788489932
At time: 990.0138590335846 and batch: 900, loss is 4.829866542816162 and perplexity is 125.19425146757587
At time: 991.2132563591003 and batch: 950, loss is 4.809726285934448 and perplexity is 122.69802874433228
At time: 992.4132778644562 and batch: 1000, loss is 4.8403785705566404 and perplexity is 126.51723836666064
At time: 993.6137862205505 and batch: 1050, loss is 4.787027778625489 and perplexity is 119.94433721498018
At time: 994.8208839893341 and batch: 1100, loss is 4.776106061935425 and perplexity is 118.64146688657436
At time: 996.0210523605347 and batch: 1150, loss is 4.8091654777526855 and perplexity is 122.62923797694184
At time: 997.2191557884216 and batch: 1200, loss is 4.777056512832641 and perplexity is 118.75428337999963
At time: 998.4243822097778 and batch: 1250, loss is 4.789555768966675 and perplexity is 120.2479389303552
At time: 999.6357579231262 and batch: 1300, loss is 4.76642858505249 and perplexity is 117.49885455310573
At time: 1000.8392145633698 and batch: 1350, loss is 4.769738636016846 and perplexity is 117.88842614514886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9933768717447915 and perplexity of 147.43344767362157
Finished 29 epochs...
Completing Train Step...
At time: 1004.3309342861176 and batch: 50, loss is 4.88906078338623 and perplexity is 132.82876046834426
At time: 1005.5325083732605 and batch: 100, loss is 4.887187519073486 and perplexity is 132.58017000217174
At time: 1006.7066831588745 and batch: 150, loss is 4.871874866485595 and perplexity is 130.56548040624483
At time: 1007.8838725090027 and batch: 200, loss is 4.846354637145996 and perplexity is 127.27557749349825
At time: 1009.0819537639618 and batch: 250, loss is 4.865720891952515 and perplexity is 129.7644510500617
At time: 1010.2749156951904 and batch: 300, loss is 4.861112604141235 and perplexity is 129.1678348573419
At time: 1011.4707052707672 and batch: 350, loss is 4.871450653076172 and perplexity is 130.51010452507484
At time: 1012.6699175834656 and batch: 400, loss is 4.8963500595092775 and perplexity is 133.80052340189073
At time: 1013.8731534481049 and batch: 450, loss is 4.86238510131836 and perplexity is 129.3323051843934
At time: 1015.0707838535309 and batch: 500, loss is 4.907491827011109 and perplexity is 135.29963358568594
At time: 1016.2748489379883 and batch: 550, loss is 4.889114093780518 and perplexity is 132.83584181069043
At time: 1017.4734556674957 and batch: 600, loss is 4.835519800186157 and perplexity is 125.90401112909943
At time: 1018.6714854240417 and batch: 650, loss is 4.845692729949951 and perplexity is 127.19136074778423
At time: 1019.8695530891418 and batch: 700, loss is 4.872328758239746 and perplexity is 130.62475645261463
At time: 1021.0673048496246 and batch: 750, loss is 4.847888336181641 and perplexity is 127.47092969140711
At time: 1022.2720544338226 and batch: 800, loss is 4.8323729038238525 and perplexity is 125.50842701204151
At time: 1023.4715611934662 and batch: 850, loss is 4.802202987670898 and perplexity is 121.77839854147949
At time: 1024.6713740825653 and batch: 900, loss is 4.829411764144897 and perplexity is 125.13732873684647
At time: 1025.8713591098785 and batch: 950, loss is 4.8093554878234865 and perplexity is 122.65254098096472
At time: 1027.072261095047 and batch: 1000, loss is 4.840288953781128 and perplexity is 126.5059008077368
At time: 1028.2777116298676 and batch: 1050, loss is 4.787095079421997 and perplexity is 119.95240983605527
At time: 1029.477464914322 and batch: 1100, loss is 4.776145734786987 and perplexity is 118.64617382524749
At time: 1030.7459893226624 and batch: 1150, loss is 4.8093295001983645 and perplexity is 122.64935357412618
At time: 1031.9543075561523 and batch: 1200, loss is 4.777340393066407 and perplexity is 118.78800015926335
At time: 1033.154260635376 and batch: 1250, loss is 4.789778041839599 and perplexity is 120.2746697558631
At time: 1034.356695175171 and batch: 1300, loss is 4.766640520095825 and perplexity is 117.52375931694009
At time: 1035.5560009479523 and batch: 1350, loss is 4.769557075500488 and perplexity is 117.86702420455788
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.99330078125 and perplexity of 147.42222981643087
Finished 30 epochs...
Completing Train Step...
At time: 1039.032743692398 and batch: 50, loss is 4.887846412658692 and perplexity is 132.66755501126113
At time: 1040.237687587738 and batch: 100, loss is 4.885925903320312 and perplexity is 132.41301023900573
At time: 1041.4267084598541 and batch: 150, loss is 4.870447721481323 and perplexity is 130.37927743407738
At time: 1042.6101179122925 and batch: 200, loss is 4.844946174621582 and perplexity is 127.09644079560216
At time: 1043.7932913303375 and batch: 250, loss is 4.864521913528442 and perplexity is 129.60895950717077
At time: 1044.9931597709656 and batch: 300, loss is 4.859829721450805 and perplexity is 129.00223392384066
At time: 1046.186458349228 and batch: 350, loss is 4.87034423828125 and perplexity is 130.36578606730225
At time: 1047.3784697055817 and batch: 400, loss is 4.895147132873535 and perplexity is 133.63966795646112
At time: 1048.5784561634064 and batch: 450, loss is 4.861263093948364 and perplexity is 129.1872747626139
At time: 1049.7759618759155 and batch: 500, loss is 4.906268348693848 and perplexity is 135.13419864133078
At time: 1050.9744794368744 and batch: 550, loss is 4.888066787719726 and perplexity is 132.6967948535417
At time: 1052.1733047962189 and batch: 600, loss is 4.834773483276368 and perplexity is 125.81008189143246
At time: 1053.3719403743744 and batch: 650, loss is 4.844872798919678 and perplexity is 127.08711534718404
At time: 1054.570470571518 and batch: 700, loss is 4.871607618331909 and perplexity is 130.53059168485197
At time: 1055.7693839073181 and batch: 750, loss is 4.847283716201782 and perplexity is 127.39388151524506
At time: 1056.9694693088531 and batch: 800, loss is 4.831939191818237 and perplexity is 125.45400430318467
At time: 1058.1699125766754 and batch: 850, loss is 4.801794071197509 and perplexity is 121.72861152827164
At time: 1059.3688571453094 and batch: 900, loss is 4.828969097137451 and perplexity is 125.08194682879082
At time: 1060.5942196846008 and batch: 950, loss is 4.808968725204468 and perplexity is 122.60511273531313
At time: 1061.793050289154 and batch: 1000, loss is 4.840125646591186 and perplexity is 126.48524317138103
At time: 1062.9925813674927 and batch: 1050, loss is 4.787035436630249 and perplexity is 119.94525575280261
At time: 1064.1916527748108 and batch: 1100, loss is 4.776022272109985 and perplexity is 118.63152635523753
At time: 1065.3902311325073 and batch: 1150, loss is 4.8093358993530275 and perplexity is 122.65013842882023
At time: 1066.5897793769836 and batch: 1200, loss is 4.777442588806152 and perplexity is 118.80014040714273
At time: 1067.7886745929718 and batch: 1250, loss is 4.789825677871704 and perplexity is 120.28039930035827
At time: 1068.988695383072 and batch: 1300, loss is 4.766660509109497 and perplexity is 117.52610852445092
At time: 1070.187608242035 and batch: 1350, loss is 4.769298667907715 and perplexity is 117.83657040548172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.99327392578125 and perplexity of 147.41827077650615
Finished 31 epochs...
Completing Train Step...
At time: 1073.6804630756378 and batch: 50, loss is 4.886796970367431 and perplexity is 132.52840109812607
At time: 1074.8540997505188 and batch: 100, loss is 4.884838619232178 and perplexity is 132.26911792000092
At time: 1076.0340027809143 and batch: 150, loss is 4.869202356338501 and perplexity is 130.21700868950617
At time: 1077.2317192554474 and batch: 200, loss is 4.843718338012695 and perplexity is 126.94048289773556
At time: 1078.4337809085846 and batch: 250, loss is 4.86338436126709 and perplexity is 129.4616063690295
At time: 1079.6435329914093 and batch: 300, loss is 4.8586780548095705 and perplexity is 128.85375187171036
At time: 1080.844262123108 and batch: 350, loss is 4.869371671676635 and perplexity is 130.2390582929786
At time: 1082.0482382774353 and batch: 400, loss is 4.894113645553589 and perplexity is 133.50162439960613
At time: 1083.245182275772 and batch: 450, loss is 4.860226831436157 and perplexity is 129.05347217200116
At time: 1084.4419977664948 and batch: 500, loss is 4.905172042846679 and perplexity is 134.98613140752497
At time: 1085.6393468379974 and batch: 550, loss is 4.887122793197632 and perplexity is 132.57158891225967
At time: 1086.837017774582 and batch: 600, loss is 4.833998928070068 and perplexity is 125.71267276674075
At time: 1088.0344097614288 and batch: 650, loss is 4.844136981964112 and perplexity is 126.99363688861266
At time: 1089.231887102127 and batch: 700, loss is 4.870963764190674 and perplexity is 130.4465760726401
At time: 1090.4748780727386 and batch: 750, loss is 4.846635179519653 and perplexity is 127.31128869513527
At time: 1091.671992778778 and batch: 800, loss is 4.831453151702881 and perplexity is 125.39304344037379
At time: 1092.8696506023407 and batch: 850, loss is 4.80133171081543 and perplexity is 121.6723420503265
At time: 1094.0699670314789 and batch: 900, loss is 4.828433437347412 and perplexity is 125.01496340118089
At time: 1095.271044254303 and batch: 950, loss is 4.808580951690674 and perplexity is 122.5575789367083
At time: 1096.4682519435883 and batch: 1000, loss is 4.83989068031311 and perplexity is 126.45552689585955
At time: 1097.666121006012 and batch: 1050, loss is 4.786869153976441 and perplexity is 119.92531259551086
At time: 1098.8653450012207 and batch: 1100, loss is 4.775828704833985 and perplexity is 118.60856539614997
At time: 1100.0642290115356 and batch: 1150, loss is 4.809187974929809 and perplexity is 122.63199681966213
At time: 1101.26735329628 and batch: 1200, loss is 4.777417697906494 and perplexity is 118.79718340156994
At time: 1102.4666488170624 and batch: 1250, loss is 4.789738569259644 and perplexity is 120.26992229804233
At time: 1103.671842098236 and batch: 1300, loss is 4.766574163436889 and perplexity is 117.51596109166121
At time: 1104.8703088760376 and batch: 1350, loss is 4.768967847824097 and perplexity is 117.79759414882666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.993223063151041 and perplexity of 147.4107728861964
Finished 32 epochs...
Completing Train Step...
At time: 1108.391914844513 and batch: 50, loss is 4.88585693359375 and perplexity is 132.4038780648217
At time: 1109.5662982463837 and batch: 100, loss is 4.883728647232056 and perplexity is 132.1223843527696
At time: 1110.7483053207397 and batch: 150, loss is 4.868028154373169 and perplexity is 130.0641973552252
At time: 1111.9302055835724 and batch: 200, loss is 4.842638130187988 and perplexity is 126.80343482836203
At time: 1113.1122288703918 and batch: 250, loss is 4.862374238967895 and perplexity is 129.33090033919808
At time: 1114.2945301532745 and batch: 300, loss is 4.857615098953247 and perplexity is 128.71685879008984
At time: 1115.4878690242767 and batch: 350, loss is 4.868515453338623 and perplexity is 130.12759294908813
At time: 1116.680193901062 and batch: 400, loss is 4.893192348480224 and perplexity is 133.37868638367016
At time: 1117.8731269836426 and batch: 450, loss is 4.8592943096160885 and perplexity is 128.93318308805982
At time: 1119.0667226314545 and batch: 500, loss is 4.904181594848633 and perplexity is 134.85250085189065
At time: 1120.2669672966003 and batch: 550, loss is 4.8862736034393315 and perplexity is 132.4590582634134
At time: 1121.5159981250763 and batch: 600, loss is 4.833314085006714 and perplexity is 125.62660878834382
At time: 1122.7159855365753 and batch: 650, loss is 4.8434133720397945 and perplexity is 126.90177627227003
At time: 1123.916297674179 and batch: 700, loss is 4.8703720664978025 and perplexity is 130.36941396510667
At time: 1125.1158368587494 and batch: 750, loss is 4.846005954742432 and perplexity is 127.23120647536892
At time: 1126.316045999527 and batch: 800, loss is 4.83105938911438 and perplexity is 125.34367807076431
At time: 1127.5162243843079 and batch: 850, loss is 4.800849599838257 and perplexity is 121.6136966165453
At time: 1128.7170917987823 and batch: 900, loss is 4.827871017456054 and perplexity is 124.94467226746546
At time: 1129.9165711402893 and batch: 950, loss is 4.808161792755127 and perplexity is 122.50621859720252
At time: 1131.1173071861267 and batch: 1000, loss is 4.839594125747681 and perplexity is 126.41803149202616
At time: 1132.3179306983948 and batch: 1050, loss is 4.786663494110107 and perplexity is 119.90065130775797
At time: 1133.5180723667145 and batch: 1100, loss is 4.775576343536377 and perplexity is 118.5786369612274
At time: 1134.7177839279175 and batch: 1150, loss is 4.809009485244751 and perplexity is 122.61011022649534
At time: 1135.9180252552032 and batch: 1200, loss is 4.777313032150269 and perplexity is 118.7847500552159
At time: 1137.1186146736145 and batch: 1250, loss is 4.7896153926849365 and perplexity is 120.25510877333171
At time: 1138.322732925415 and batch: 1300, loss is 4.766439657211304 and perplexity is 117.50015552628606
At time: 1139.5221092700958 and batch: 1350, loss is 4.768644018173218 and perplexity is 117.75945397083257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.993227132161459 and perplexity of 147.4113727033873
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 1143.0066435337067 and batch: 50, loss is 4.885567665100098 and perplexity is 132.36558333345678
At time: 1144.2081503868103 and batch: 100, loss is 4.883554544448852 and perplexity is 132.09938348024633
At time: 1145.3832886219025 and batch: 150, loss is 4.867836799621582 and perplexity is 130.039311334155
At time: 1146.5634846687317 and batch: 200, loss is 4.842578029632568 and perplexity is 126.79581410050692
At time: 1147.752336025238 and batch: 250, loss is 4.861963806152343 and perplexity is 129.27782958536847
At time: 1148.950335741043 and batch: 300, loss is 4.85731201171875 and perplexity is 128.67785226481448
At time: 1150.1528651714325 and batch: 350, loss is 4.867917127609253 and perplexity is 130.04975754990878
At time: 1151.3811733722687 and batch: 400, loss is 4.8925107479095455 and perplexity is 133.28780637036755
At time: 1152.5812499523163 and batch: 450, loss is 4.858007650375367 and perplexity is 128.76739669477283
At time: 1153.7806253433228 and batch: 500, loss is 4.9020701599121095 and perplexity is 134.5680689557059
At time: 1154.9875919818878 and batch: 550, loss is 4.883735942840576 and perplexity is 132.12334826947873
At time: 1156.2018675804138 and batch: 600, loss is 4.830742435455322 and perplexity is 125.30395622868423
At time: 1157.4001564979553 and batch: 650, loss is 4.840972557067871 and perplexity is 126.5924102230127
At time: 1158.5986001491547 and batch: 700, loss is 4.86722804069519 and perplexity is 129.96017283317693
At time: 1159.7970683574677 and batch: 750, loss is 4.842599697113037 and perplexity is 126.79856147609678
At time: 1160.995019197464 and batch: 800, loss is 4.82818359375 and perplexity is 124.9837331145005
At time: 1162.193989276886 and batch: 850, loss is 4.796839380264283 and perplexity is 121.12697557132309
At time: 1163.3923666477203 and batch: 900, loss is 4.822723169326782 and perplexity is 124.30312877107416
At time: 1164.589509487152 and batch: 950, loss is 4.8024380588531494 and perplexity is 121.80702849850438
At time: 1165.7937874794006 and batch: 1000, loss is 4.834248933792114 and perplexity is 125.74410558329446
At time: 1166.9919083118439 and batch: 1050, loss is 4.781048412322998 and perplexity is 119.229285993874
At time: 1168.1899015903473 and batch: 1100, loss is 4.769524116516113 and perplexity is 117.86313949116719
At time: 1169.387897014618 and batch: 1150, loss is 4.802962684631348 and perplexity is 121.87094837116085
At time: 1170.5856850147247 and batch: 1200, loss is 4.770709867477417 and perplexity is 118.00297871298245
At time: 1171.7835674285889 and batch: 1250, loss is 4.782788696289063 and perplexity is 119.43695946156437
At time: 1172.9811635017395 and batch: 1300, loss is 4.759970455169678 and perplexity is 116.74247671137152
At time: 1174.1799612045288 and batch: 1350, loss is 4.7632387924194335 and perplexity is 117.12465469971073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990621337890625 and perplexity of 147.02774903219557
Finished 34 epochs...
Completing Train Step...
At time: 1177.6542990207672 and batch: 50, loss is 4.884041366577148 and perplexity is 132.16370803929772
At time: 1178.8538892269135 and batch: 100, loss is 4.882133684158325 and perplexity is 131.91182199274573
At time: 1180.0264801979065 and batch: 150, loss is 4.866462821960449 and perplexity is 129.86076291417191
At time: 1181.229595899582 and batch: 200, loss is 4.841234197616577 and perplexity is 126.62553626405435
At time: 1182.4196543693542 and batch: 250, loss is 4.860636920928955 and perplexity is 129.10640649811157
At time: 1183.613109111786 and batch: 300, loss is 4.856156330108643 and perplexity is 128.5292275352993
At time: 1184.8182635307312 and batch: 350, loss is 4.866763467788696 and perplexity is 129.89981088030498
At time: 1186.0167763233185 and batch: 400, loss is 4.891412668228149 and perplexity is 133.14152606682737
At time: 1187.215012550354 and batch: 450, loss is 4.857104902267456 and perplexity is 128.65120462502253
At time: 1188.4130067825317 and batch: 500, loss is 4.901127519607544 and perplexity is 134.441279438044
At time: 1189.622318983078 and batch: 550, loss is 4.88291639328003 and perplexity is 132.0151109964296
At time: 1190.8242189884186 and batch: 600, loss is 4.830097227096558 and perplexity is 125.22313514476245
At time: 1192.026210308075 and batch: 650, loss is 4.840493621826172 and perplexity is 126.53179517292584
At time: 1193.2288892269135 and batch: 700, loss is 4.866785154342652 and perplexity is 129.902627990109
At time: 1194.4277987480164 and batch: 750, loss is 4.842292337417603 and perplexity is 126.7595946975753
At time: 1195.6254980564117 and batch: 800, loss is 4.827946290969849 and perplexity is 124.95407764596045
At time: 1196.8261783123016 and batch: 850, loss is 4.796651973724365 and perplexity is 121.10427771087075
At time: 1198.0288791656494 and batch: 900, loss is 4.82274528503418 and perplexity is 124.30587785309753
At time: 1199.2276785373688 and batch: 950, loss is 4.802348470687866 and perplexity is 121.79611651910196
At time: 1200.4258358478546 and batch: 1000, loss is 4.834322528839111 and perplexity is 125.75336006719236
At time: 1201.6242380142212 and batch: 1050, loss is 4.7811524868011475 and perplexity is 119.24169536533216
At time: 1202.8234314918518 and batch: 1100, loss is 4.7697485828399655 and perplexity is 117.88959876630351
At time: 1204.0219676494598 and batch: 1150, loss is 4.803354921340943 and perplexity is 121.91876000707154
At time: 1205.219830274582 and batch: 1200, loss is 4.7712626457214355 and perplexity is 118.06822622438531
At time: 1206.4185824394226 and batch: 1250, loss is 4.7832776641845705 and perplexity is 119.49537458067317
At time: 1207.6166696548462 and batch: 1300, loss is 4.760409297943116 and perplexity is 116.79371954658112
At time: 1208.8146789073944 and batch: 1350, loss is 4.76345118522644 and perplexity is 117.14953377586698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990477294921875 and perplexity of 147.00657224395667
Finished 35 epochs...
Completing Train Step...
At time: 1212.2979204654694 and batch: 50, loss is 4.883289985656738 and perplexity is 132.0644400494135
At time: 1213.4596002101898 and batch: 100, loss is 4.8813324069976805 and perplexity is 131.8061663979244
At time: 1214.6357419490814 and batch: 150, loss is 4.865666399002075 and perplexity is 129.75737999492483
At time: 1215.8079617023468 and batch: 200, loss is 4.8404130935668945 and perplexity is 126.52160619797299
At time: 1217.0016739368439 and batch: 250, loss is 4.859871158599853 and perplexity is 129.00757951938763
At time: 1218.2005019187927 and batch: 300, loss is 4.855404348373413 and perplexity is 128.432612234773
At time: 1219.4001967906952 and batch: 350, loss is 4.866056785583496 and perplexity is 129.8080454238236
At time: 1220.599718093872 and batch: 400, loss is 4.8907741451263425 and perplexity is 133.05653926253038
At time: 1221.7999951839447 and batch: 450, loss is 4.856534614562988 and perplexity is 128.57785734137477
At time: 1222.9988417625427 and batch: 500, loss is 4.9005351161956785 and perplexity is 134.36165955128408
At time: 1224.1991484165192 and batch: 550, loss is 4.882501573562622 and perplexity is 131.9603598820985
At time: 1225.4034101963043 and batch: 600, loss is 4.829701461791992 and perplexity is 125.17358597811048
At time: 1226.6080400943756 and batch: 650, loss is 4.840180044174194 and perplexity is 126.49212385004016
At time: 1227.808916568756 and batch: 700, loss is 4.86650146484375 and perplexity is 129.8657812054385
At time: 1229.0089519023895 and batch: 750, loss is 4.842037382125855 and perplexity is 126.72728078760355
At time: 1230.2128071784973 and batch: 800, loss is 4.827830667495728 and perplexity is 124.9396308566075
At time: 1231.413230895996 and batch: 850, loss is 4.796558294296265 and perplexity is 121.09293326277331
At time: 1232.6120111942291 and batch: 900, loss is 4.8227638912200925 and perplexity is 124.3081907328878
At time: 1233.8110058307648 and batch: 950, loss is 4.802260990142822 and perplexity is 121.78546219447453
At time: 1235.0089755058289 and batch: 1000, loss is 4.83434868812561 and perplexity is 125.75664972839394
At time: 1236.206800699234 and batch: 1050, loss is 4.78119005203247 and perplexity is 119.2461747913367
At time: 1237.4048283100128 and batch: 1100, loss is 4.76985279083252 and perplexity is 117.9018844448558
At time: 1238.6020925045013 and batch: 1150, loss is 4.803566913604737 and perplexity is 121.94460858075642
At time: 1239.7995746135712 and batch: 1200, loss is 4.771605157852173 and perplexity is 118.1086729504736
At time: 1241.0003979206085 and batch: 1250, loss is 4.783544855117798 and perplexity is 119.5273069271505
At time: 1242.2050569057465 and batch: 1300, loss is 4.760632266998291 and perplexity is 116.81976383530618
At time: 1243.4021849632263 and batch: 1350, loss is 4.7634867000579835 and perplexity is 117.15369439570581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990410563151042 and perplexity of 146.99676256237913
Finished 36 epochs...
Completing Train Step...
At time: 1246.8609154224396 and batch: 50, loss is 4.8826793384552 and perplexity is 131.98381988641833
At time: 1248.0372211933136 and batch: 100, loss is 4.880683832168579 and perplexity is 131.7207079521724
At time: 1249.2223949432373 and batch: 150, loss is 4.865039739608765 and perplexity is 129.67609178656951
At time: 1250.4120514392853 and batch: 200, loss is 4.839768743515014 and perplexity is 126.44010825387734
At time: 1251.6088387966156 and batch: 250, loss is 4.8592720890045165 and perplexity is 128.93031814571017
At time: 1252.804946422577 and batch: 300, loss is 4.854799613952637 and perplexity is 128.3549680928133
At time: 1254.00306224823 and batch: 350, loss is 4.865504293441773 and perplexity is 129.73634730694127
At time: 1255.2022240161896 and batch: 400, loss is 4.8902685260772705 and perplexity is 132.98928034680304
At time: 1256.4012491703033 and batch: 450, loss is 4.856076602935791 and perplexity is 128.51898067184118
At time: 1257.6001212596893 and batch: 500, loss is 4.900045146942139 and perplexity is 134.29584259470866
At time: 1258.7987229824066 and batch: 550, loss is 4.882156229019165 and perplexity is 131.91479595993934
At time: 1259.9978437423706 and batch: 600, loss is 4.8293924903869625 and perplexity is 125.13491689350654
At time: 1261.1963698863983 and batch: 650, loss is 4.83991886138916 and perplexity is 126.45909059889415
At time: 1262.395057439804 and batch: 700, loss is 4.866268730163574 and perplexity is 129.83556045122907
At time: 1263.5939028263092 and batch: 750, loss is 4.841813659667968 and perplexity is 126.69893222008831
At time: 1264.792716741562 and batch: 800, loss is 4.82773609161377 and perplexity is 124.92781513957746
At time: 1265.991501569748 and batch: 850, loss is 4.796464424133301 and perplexity is 121.08156678288921
At time: 1267.19078707695 and batch: 900, loss is 4.822756395339966 and perplexity is 124.30725893708365
At time: 1268.3895573616028 and batch: 950, loss is 4.802146368026733 and perplexity is 121.77150368708101
At time: 1269.5948708057404 and batch: 1000, loss is 4.8343244075775145 and perplexity is 125.75359632508116
At time: 1270.7942283153534 and batch: 1050, loss is 4.781176357269287 and perplexity is 119.2445417543945
At time: 1272.0411975383759 and batch: 1100, loss is 4.7698805713653565 and perplexity is 117.90515986752442
At time: 1273.241231918335 and batch: 1150, loss is 4.8036754608154295 and perplexity is 121.95784604630886
At time: 1274.4422535896301 and batch: 1200, loss is 4.7718305587768555 and perplexity is 118.1352977550847
At time: 1275.6419651508331 and batch: 1250, loss is 4.783706398010254 and perplexity is 119.54661727372158
At time: 1276.8418946266174 and batch: 1300, loss is 4.760756664276123 and perplexity is 116.83429679983608
At time: 1278.0406901836395 and batch: 1350, loss is 4.763442544937134 and perplexity is 117.14852157437593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990368245442708 and perplexity of 146.99054212787317
Finished 37 epochs...
Completing Train Step...
At time: 1281.50843667984 and batch: 50, loss is 4.882137451171875 and perplexity is 131.9123189073025
At time: 1282.7193341255188 and batch: 100, loss is 4.880116834640503 and perplexity is 131.64604380556065
At time: 1283.8941404819489 and batch: 150, loss is 4.864500970840454 and perplexity is 129.60624517559413
At time: 1285.071708202362 and batch: 200, loss is 4.839215288162231 and perplexity is 126.37014866069923
At time: 1286.2639327049255 and batch: 250, loss is 4.8587519073486325 and perplexity is 128.8632683998593
At time: 1287.4632563591003 and batch: 300, loss is 4.8542710971832275 and perplexity is 128.2871482632765
At time: 1288.6682155132294 and batch: 350, loss is 4.865029277801514 and perplexity is 129.67473514738867
At time: 1289.867904663086 and batch: 400, loss is 4.889820890426636 and perplexity is 132.92976292582114
At time: 1291.0730328559875 and batch: 450, loss is 4.85567190170288 and perplexity is 128.46697940510902
At time: 1292.2721862792969 and batch: 500, loss is 4.899604978561402 and perplexity is 134.2367428190145
At time: 1293.4711515903473 and batch: 550, loss is 4.881839275360107 and perplexity is 131.87299170803132
At time: 1294.6699073314667 and batch: 600, loss is 4.829125709533692 and perplexity is 125.10153774626038
At time: 1295.8718633651733 and batch: 650, loss is 4.839685869216919 and perplexity is 126.4296300528475
At time: 1297.0769498348236 and batch: 700, loss is 4.86605881690979 and perplexity is 129.80830910658722
At time: 1298.278110742569 and batch: 750, loss is 4.841593170166016 and perplexity is 126.67099951517247
At time: 1299.4778413772583 and batch: 800, loss is 4.827644996643066 and perplexity is 124.91643536224537
At time: 1300.6802804470062 and batch: 850, loss is 4.796356153488159 and perplexity is 121.06845791320454
At time: 1301.9067287445068 and batch: 900, loss is 4.8227278423309325 and perplexity is 124.30370964146805
At time: 1303.1118726730347 and batch: 950, loss is 4.80201584815979 and perplexity is 121.75561112379253
At time: 1304.3088948726654 and batch: 1000, loss is 4.834266834259033 and perplexity is 125.74635648164265
At time: 1305.512615442276 and batch: 1050, loss is 4.781120748519897 and perplexity is 119.23791089892444
At time: 1306.7097589969635 and batch: 1100, loss is 4.769855632781982 and perplexity is 117.90221951652904
At time: 1307.9074671268463 and batch: 1150, loss is 4.80371660232544 and perplexity is 121.96286367946861
At time: 1309.104907989502 and batch: 1200, loss is 4.771979188919067 and perplexity is 118.15285752611355
At time: 1310.3039276599884 and batch: 1250, loss is 4.783793878555298 and perplexity is 119.55707573440814
At time: 1311.5010857582092 and batch: 1300, loss is 4.760825996398926 and perplexity is 116.8423974504638
At time: 1312.6986751556396 and batch: 1350, loss is 4.7633467864990235 and perplexity is 117.13730415201302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.99033203125 and perplexity of 146.98521908043986
Finished 38 epochs...
Completing Train Step...
At time: 1316.187608242035 and batch: 50, loss is 4.881631240844727 and perplexity is 131.84556042753508
At time: 1317.3878345489502 and batch: 100, loss is 4.879603862762451 and perplexity is 131.57853040495007
At time: 1318.5677835941315 and batch: 150, loss is 4.864012174606323 and perplexity is 129.5429096113861
At time: 1319.7522947788239 and batch: 200, loss is 4.838710346221924 and perplexity is 126.30635517999495
At time: 1320.950073003769 and batch: 250, loss is 4.858276376724243 and perplexity is 128.80200453695218
At time: 1322.153035402298 and batch: 300, loss is 4.85378664970398 and perplexity is 128.22501492906423
At time: 1323.3510155677795 and batch: 350, loss is 4.864594879150391 and perplexity is 129.6184168505376
At time: 1324.5492551326752 and batch: 400, loss is 4.8894176197052 and perplexity is 132.87616705197544
At time: 1325.747275352478 and batch: 450, loss is 4.855278253555298 and perplexity is 128.41641856888333
At time: 1326.945062637329 and batch: 500, loss is 4.899192113876342 and perplexity is 134.1813326477057
At time: 1328.1428771018982 and batch: 550, loss is 4.881525888442993 and perplexity is 131.83167091274578
At time: 1329.3409729003906 and batch: 600, loss is 4.82887469291687 and perplexity is 125.0701391224492
At time: 1330.5392546653748 and batch: 650, loss is 4.839453258514404 and perplexity is 126.40022458792774
At time: 1331.737105846405 and batch: 700, loss is 4.8658734321594235 and perplexity is 129.78424685606402
At time: 1332.9616510868073 and batch: 750, loss is 4.841347732543945 and perplexity is 126.63991350126086
At time: 1334.165250301361 and batch: 800, loss is 4.8275644397735595 and perplexity is 124.90637289056872
At time: 1335.3634383678436 and batch: 850, loss is 4.796217174530029 and perplexity is 121.05163311423492
At time: 1336.5604164600372 and batch: 900, loss is 4.822680683135986 and perplexity is 124.29784771681541
At time: 1337.760666847229 and batch: 950, loss is 4.801874475479126 and perplexity is 121.73839942332283
At time: 1338.9632186889648 and batch: 1000, loss is 4.834175910949707 and perplexity is 125.73492372653548
At time: 1340.1651864051819 and batch: 1050, loss is 4.781036443710327 and perplexity is 119.22785899327056
At time: 1341.3642873764038 and batch: 1100, loss is 4.769770412445069 and perplexity is 117.89217227777961
At time: 1342.5618932247162 and batch: 1150, loss is 4.803705940246582 and perplexity is 121.96156330873065
At time: 1343.7592089176178 and batch: 1200, loss is 4.772062358856201 and perplexity is 118.16268470050325
At time: 1344.9569704532623 and batch: 1250, loss is 4.783817014694214 and perplexity is 119.55984185551927
At time: 1346.159584760666 and batch: 1300, loss is 4.760866060256958 and perplexity is 116.84707870146124
At time: 1347.359548330307 and batch: 1350, loss is 4.763219976425171 and perplexity is 117.1224509036133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990305989583334 and perplexity of 146.98139139019958
Finished 39 epochs...
Completing Train Step...
At time: 1350.82399892807 and batch: 50, loss is 4.881135625839233 and perplexity is 131.78023197959627
At time: 1352.0062766075134 and batch: 100, loss is 4.879139680862426 and perplexity is 131.51746820578444
At time: 1353.187910079956 and batch: 150, loss is 4.863558349609375 and perplexity is 129.48413313895202
At time: 1354.3772621154785 and batch: 200, loss is 4.83823091506958 and perplexity is 126.24581449228816
At time: 1355.567568063736 and batch: 250, loss is 4.857820730209351 and perplexity is 128.74332972097667
At time: 1356.7575404644012 and batch: 300, loss is 4.853322706222534 and perplexity is 128.1655395668997
At time: 1357.951396226883 and batch: 350, loss is 4.864176502227783 and perplexity is 129.56419883875574
At time: 1359.1490077972412 and batch: 400, loss is 4.8890423011779784 and perplexity is 132.82630552221792
At time: 1360.3477029800415 and batch: 450, loss is 4.854880533218384 and perplexity is 128.36535490282716
At time: 1361.545184135437 and batch: 500, loss is 4.898795576095581 and perplexity is 134.1281352279284
At time: 1362.7846958637238 and batch: 550, loss is 4.881206531524658 and perplexity is 131.7895762785482
At time: 1363.9816181659698 and batch: 600, loss is 4.828645858764649 and perplexity is 125.04152207759833
At time: 1365.1796188354492 and batch: 650, loss is 4.839218521118164 and perplexity is 126.37055721048152
At time: 1366.3767640590668 and batch: 700, loss is 4.865697879791259 and perplexity is 129.7614649239476
At time: 1367.5748386383057 and batch: 750, loss is 4.841094608306885 and perplexity is 126.6078619264608
At time: 1368.779272556305 and batch: 800, loss is 4.827485542297364 and perplexity is 124.89651848173598
At time: 1369.9770858287811 and batch: 850, loss is 4.796075563430787 and perplexity is 121.034492073114
At time: 1371.1747250556946 and batch: 900, loss is 4.8225914573669435 and perplexity is 124.2867576405302
At time: 1372.3720345497131 and batch: 950, loss is 4.801714019775391 and perplexity is 121.71886736982835
At time: 1373.5698249340057 and batch: 1000, loss is 4.834068727493286 and perplexity is 125.72144774503174
At time: 1374.7670736312866 and batch: 1050, loss is 4.78094747543335 and perplexity is 119.21725196793959
At time: 1375.9649195671082 and batch: 1100, loss is 4.769671688079834 and perplexity is 117.88053402240448
At time: 1377.1625740528107 and batch: 1150, loss is 4.803677787780762 and perplexity is 121.95812983831883
At time: 1378.366721868515 and batch: 1200, loss is 4.772129869461059 and perplexity is 118.17066220409909
At time: 1379.5640275478363 and batch: 1250, loss is 4.783820886611938 and perplexity is 119.56030478228625
At time: 1380.7615728378296 and batch: 1300, loss is 4.760853281021118 and perplexity is 116.84558549462643
At time: 1381.95951962471 and batch: 1350, loss is 4.763075876235962 and perplexity is 117.10557475223492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990271809895833 and perplexity of 146.97636769802804
Finished 40 epochs...
Completing Train Step...
At time: 1385.431020975113 and batch: 50, loss is 4.880670833587646 and perplexity is 131.71899578101753
At time: 1386.6203174591064 and batch: 100, loss is 4.878704633712768 and perplexity is 131.46026435020067
At time: 1387.802256822586 and batch: 150, loss is 4.863145122528076 and perplexity is 129.43063784215443
At time: 1388.9925963878632 and batch: 200, loss is 4.837775630950928 and perplexity is 126.18834986026324
At time: 1390.182996749878 and batch: 250, loss is 4.857392892837525 and perplexity is 128.6882602943681
At time: 1391.3745296001434 and batch: 300, loss is 4.852880935668946 and perplexity is 128.10893231016448
At time: 1392.5984394550323 and batch: 350, loss is 4.863787908554077 and perplexity is 129.51386079190485
At time: 1393.7983906269073 and batch: 400, loss is 4.888665857315064 and perplexity is 132.7763132848963
At time: 1394.9962630271912 and batch: 450, loss is 4.854504833221435 and perplexity is 128.31713709766368
At time: 1396.1942853927612 and batch: 500, loss is 4.898415317535401 and perplexity is 134.07714155235226
At time: 1397.3926150798798 and batch: 550, loss is 4.880936059951782 and perplexity is 131.75393576465376
At time: 1398.590707540512 and batch: 600, loss is 4.8283921813964845 and perplexity is 125.00980589637523
At time: 1399.7879509925842 and batch: 650, loss is 4.8390025806427 and perplexity is 126.34327163840851
At time: 1400.9861164093018 and batch: 700, loss is 4.8654955291748045 and perplexity is 129.7352102679407
At time: 1402.1843001842499 and batch: 750, loss is 4.840810546875 and perplexity is 126.5719026234814
At time: 1403.382777929306 and batch: 800, loss is 4.827372493743897 and perplexity is 124.88239990904572
At time: 1404.5812437534332 and batch: 850, loss is 4.795933055877685 and perplexity is 121.01724497275802
At time: 1405.78546500206 and batch: 900, loss is 4.822489023208618 and perplexity is 124.2740270831534
At time: 1406.9830124378204 and batch: 950, loss is 4.801532115936279 and perplexity is 121.69672825421758
At time: 1408.1811242103577 and batch: 1000, loss is 4.833951005935669 and perplexity is 125.70664849148994
At time: 1409.3789684772491 and batch: 1050, loss is 4.780833768844604 and perplexity is 119.20369695156063
At time: 1410.5786881446838 and batch: 1100, loss is 4.769537992477417 and perplexity is 117.86477496687685
At time: 1411.7762458324432 and batch: 1150, loss is 4.803629026412964 and perplexity is 121.95218313807965
At time: 1412.9740402698517 and batch: 1200, loss is 4.772159271240234 and perplexity is 118.17413668289184
At time: 1414.1717100143433 and batch: 1250, loss is 4.783793268203735 and perplexity is 119.55700276258237
At time: 1415.3698041439056 and batch: 1300, loss is 4.760807456970215 and perplexity is 116.84023127924577
At time: 1416.5676953792572 and batch: 1350, loss is 4.762902517318725 and perplexity is 117.08527521619713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990249837239583 and perplexity of 146.9731382723034
Finished 41 epochs...
Completing Train Step...
At time: 1420.0265069007874 and batch: 50, loss is 4.880234985351563 and perplexity is 131.66159879814316
At time: 1421.224931716919 and batch: 100, loss is 4.878280792236328 and perplexity is 131.40455784386316
At time: 1422.412422657013 and batch: 150, loss is 4.8627446842193605 and perplexity is 129.37881923221164
At time: 1423.6345746517181 and batch: 200, loss is 4.837330522537232 and perplexity is 126.13219486248816
At time: 1424.837070465088 and batch: 250, loss is 4.85696683883667 and perplexity is 128.63344382442403
At time: 1426.0347001552582 and batch: 300, loss is 4.852457475662232 and perplexity is 128.05469478535008
At time: 1427.2319202423096 and batch: 350, loss is 4.8634230995178225 and perplexity is 129.46662158233696
At time: 1428.4302010536194 and batch: 400, loss is 4.888280887603759 and perplexity is 132.72520826347676
At time: 1429.6280572414398 and batch: 450, loss is 4.854133977890014 and perplexity is 128.26955882613146
At time: 1430.826045036316 and batch: 500, loss is 4.898018388748169 and perplexity is 134.02393303585498
At time: 1432.0240638256073 and batch: 550, loss is 4.880640592575073 and perplexity is 131.7150125254391
At time: 1433.2217781543732 and batch: 600, loss is 4.828127660751343 and perplexity is 124.97674259502617
At time: 1434.419049024582 and batch: 650, loss is 4.838778076171875 and perplexity is 126.31491019282178
At time: 1435.6170570850372 and batch: 700, loss is 4.865299959182739 and perplexity is 129.7098404347678
At time: 1436.8145053386688 and batch: 750, loss is 4.840555686950683 and perplexity is 126.53964862825815
At time: 1438.0122385025024 and batch: 800, loss is 4.8272438240051265 and perplexity is 124.86633235699844
At time: 1439.210789680481 and batch: 850, loss is 4.795799207687378 and perplexity is 121.00104811750651
At time: 1440.413096189499 and batch: 900, loss is 4.8223824787139895 and perplexity is 124.26078707507986
At time: 1441.6117193698883 and batch: 950, loss is 4.801345643997192 and perplexity is 121.67403734499412
At time: 1442.8091535568237 and batch: 1000, loss is 4.833809318542481 and perplexity is 125.68883870589964
At time: 1444.0070831775665 and batch: 1050, loss is 4.780716638565064 and perplexity is 119.18973540689022
At time: 1445.2047936916351 and batch: 1100, loss is 4.769393510818482 and perplexity is 117.84774689881095
At time: 1446.4030401706696 and batch: 1150, loss is 4.803571662902832 and perplexity is 121.94518773342897
At time: 1447.6010553836823 and batch: 1200, loss is 4.772182283401489 and perplexity is 118.17685615647169
At time: 1448.7989754676819 and batch: 1250, loss is 4.783758583068848 and perplexity is 119.55285598373108
At time: 1449.997667312622 and batch: 1300, loss is 4.760760154724121 and perplexity is 116.83470460458518
At time: 1451.1954498291016 and batch: 1350, loss is 4.762741403579712 and perplexity is 117.06641268927059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990245361328125 and perplexity of 146.97248043502194
Finished 42 epochs...
Completing Train Step...
At time: 1454.639277935028 and batch: 50, loss is 4.879827423095703 and perplexity is 131.60794943339758
At time: 1455.8460161685944 and batch: 100, loss is 4.877873907089233 and perplexity is 131.3511021569159
At time: 1457.0275311470032 and batch: 150, loss is 4.862353057861328 and perplexity is 129.3281609966268
At time: 1458.208818912506 and batch: 200, loss is 4.836920557022094 and perplexity is 126.08049561042529
At time: 1459.3894469738007 and batch: 250, loss is 4.856581697463989 and perplexity is 128.58391130242083
At time: 1460.579472541809 and batch: 300, loss is 4.852064189910888 and perplexity is 128.0043426005458
At time: 1461.7763359546661 and batch: 350, loss is 4.863088121414185 and perplexity is 129.42326036189007
At time: 1462.9735887050629 and batch: 400, loss is 4.887948055267334 and perplexity is 132.68104037296666
At time: 1464.1709625720978 and batch: 450, loss is 4.8538056755065915 and perplexity is 128.2274545360958
At time: 1465.367139339447 and batch: 500, loss is 4.897665376663208 and perplexity is 133.97662931770265
At time: 1466.5640182495117 and batch: 550, loss is 4.880391483306885 and perplexity is 131.68220518153583
At time: 1467.760934829712 and batch: 600, loss is 4.827898750305176 and perplexity is 124.94813738725856
At time: 1468.9577176570892 and batch: 650, loss is 4.838567581176758 and perplexity is 126.28832433461076
At time: 1470.1554579734802 and batch: 700, loss is 4.865115442276001 and perplexity is 129.68590898418387
At time: 1471.359765291214 and batch: 750, loss is 4.8403405094146725 and perplexity is 126.51242306772824
At time: 1472.5573689937592 and batch: 800, loss is 4.827122659683227 and perplexity is 124.85120392904173
At time: 1473.7615773677826 and batch: 850, loss is 4.795668849945068 and perplexity is 120.98527572210604
At time: 1474.959953069687 and batch: 900, loss is 4.822285184860229 and perplexity is 124.24869785234712
At time: 1476.1572930812836 and batch: 950, loss is 4.8011743927001955 and perplexity is 121.65320229235381
At time: 1477.3601441383362 and batch: 1000, loss is 4.8336842918395995 and perplexity is 125.67312522712993
At time: 1478.5572755336761 and batch: 1050, loss is 4.780608911514282 and perplexity is 119.17689613979195
At time: 1479.7550456523895 and batch: 1100, loss is 4.769273900985718 and perplexity is 117.83365199247432
At time: 1480.9520773887634 and batch: 1150, loss is 4.80350887298584 and perplexity is 121.93753104559751
At time: 1482.1491420269012 and batch: 1200, loss is 4.772198104858399 and perplexity is 118.17872590130013
At time: 1483.3975806236267 and batch: 1250, loss is 4.783724555969238 and perplexity is 119.54878801600283
At time: 1484.5921387672424 and batch: 1300, loss is 4.760712299346924 and perplexity is 116.82911356950824
At time: 1485.789977312088 and batch: 1350, loss is 4.762588520050048 and perplexity is 117.04851653094238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9902421061197915 and perplexity of 146.97200200975757
Finished 43 epochs...
Completing Train Step...
At time: 1489.2360162734985 and batch: 50, loss is 4.8794337749481205 and perplexity is 131.55615240346728
At time: 1490.4059653282166 and batch: 100, loss is 4.877475109100342 and perplexity is 131.29873004517756
At time: 1491.6009390354156 and batch: 150, loss is 4.861974868774414 and perplexity is 129.27925974504996
At time: 1492.7977511882782 and batch: 200, loss is 4.836525764465332 and perplexity is 126.03072979343882
At time: 1494.0017940998077 and batch: 250, loss is 4.8562193775177 and perplexity is 128.53733122553913
At time: 1495.201877117157 and batch: 300, loss is 4.851688060760498 and perplexity is 127.95620548937009
At time: 1496.3987414836884 and batch: 350, loss is 4.86276912689209 and perplexity is 129.3819816349969
At time: 1497.5950424671173 and batch: 400, loss is 4.887632217407226 and perplexity is 132.63914129410446
At time: 1498.7912657260895 and batch: 450, loss is 4.853497953414917 and perplexity is 128.188002186067
At time: 1499.9938220977783 and batch: 500, loss is 4.897324924468994 and perplexity is 133.9310244438582
At time: 1501.1905212402344 and batch: 550, loss is 4.880151357650757 and perplexity is 131.65058870173215
At time: 1502.3874199390411 and batch: 600, loss is 4.827678928375244 and perplexity is 124.92067406518754
At time: 1503.5828201770782 and batch: 650, loss is 4.838356723785401 and perplexity is 126.26169831522785
At time: 1504.778212070465 and batch: 700, loss is 4.864930114746094 and perplexity is 129.6618768419856
At time: 1505.9733555316925 and batch: 750, loss is 4.840123472213745 and perplexity is 126.48496814502059
At time: 1507.1690165996552 and batch: 800, loss is 4.826996002197266 and perplexity is 124.83539159082945
At time: 1508.3665826320648 and batch: 850, loss is 4.79553864479065 and perplexity is 120.96952384110861
At time: 1509.5633571147919 and batch: 900, loss is 4.822186012268066 and perplexity is 124.23637639789358
At time: 1510.7604622840881 and batch: 950, loss is 4.801000308990479 and perplexity is 121.6320262948514
At time: 1511.9580705165863 and batch: 1000, loss is 4.833555421829224 and perplexity is 125.65693077369005
At time: 1513.1565959453583 and batch: 1050, loss is 4.780497455596924 and perplexity is 119.16361390971016
At time: 1514.385279417038 and batch: 1100, loss is 4.769148530960083 and perplexity is 117.81888011049836
At time: 1515.5817589759827 and batch: 1150, loss is 4.803431463241577 and perplexity is 121.92809225783505
At time: 1516.77694606781 and batch: 1200, loss is 4.7722008228302 and perplexity is 118.17904710818117
At time: 1517.9717507362366 and batch: 1250, loss is 4.783677453994751 and perplexity is 119.5431571646529
At time: 1519.1672604084015 and batch: 1300, loss is 4.760660181045532 and perplexity is 116.82302479322558
At time: 1520.3637371063232 and batch: 1350, loss is 4.7624357795715335 and perplexity is 117.03063984979916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990240885416667 and perplexity of 146.97182260068504
Finished 44 epochs...
Completing Train Step...
At time: 1523.7871050834656 and batch: 50, loss is 4.879054098129273 and perplexity is 131.50621306302776
At time: 1524.94504737854 and batch: 100, loss is 4.877075939178467 and perplexity is 131.24633000031986
At time: 1526.1207857131958 and batch: 150, loss is 4.861612348556519 and perplexity is 129.23240189361024
At time: 1527.3014872074127 and batch: 200, loss is 4.836137809753418 and perplexity is 125.98184506111377
At time: 1528.4811232089996 and batch: 250, loss is 4.855851802825928 and perplexity is 128.49009283798244
At time: 1529.6688406467438 and batch: 300, loss is 4.85131869316101 and perplexity is 127.90895134052192
At time: 1530.8652753829956 and batch: 350, loss is 4.86245512008667 and perplexity is 129.34136119014664
At time: 1532.0619957447052 and batch: 400, loss is 4.887332096099853 and perplexity is 132.59933943460223
At time: 1533.2587580680847 and batch: 450, loss is 4.85319673538208 and perplexity is 128.14939546302773
At time: 1534.456176519394 and batch: 500, loss is 4.896994752883911 and perplexity is 133.88681152455226
At time: 1535.6531898975372 and batch: 550, loss is 4.879912986755371 and perplexity is 131.6192107729663
At time: 1536.8562018871307 and batch: 600, loss is 4.8274607086181645 and perplexity is 124.89341688017515
At time: 1538.058646440506 and batch: 650, loss is 4.83814169883728 and perplexity is 126.23455181878957
At time: 1539.2556993961334 and batch: 700, loss is 4.864743614196778 and perplexity is 129.63769708556825
At time: 1540.4552731513977 and batch: 750, loss is 4.8399015808105466 and perplexity is 126.45690533151908
At time: 1541.6572620868683 and batch: 800, loss is 4.826865310668945 and perplexity is 124.81907772877898
At time: 1542.854098558426 and batch: 850, loss is 4.795408134460449 and perplexity is 120.95373709879676
At time: 1544.0935673713684 and batch: 900, loss is 4.822084140777588 and perplexity is 124.22372089768663
At time: 1545.2834494113922 and batch: 950, loss is 4.800824327468872 and perplexity is 121.61062318911871
At time: 1546.4739603996277 and batch: 1000, loss is 4.8334228134155275 and perplexity is 125.64026871221942
At time: 1547.6636128425598 and batch: 1050, loss is 4.780380306243896 and perplexity is 119.14965478710322
At time: 1548.8541853427887 and batch: 1100, loss is 4.769020185470581 and perplexity is 117.80375955900604
At time: 1550.0447947978973 and batch: 1150, loss is 4.803343152999878 and perplexity is 121.91732523396401
At time: 1551.2347543239594 and batch: 1200, loss is 4.77219072341919 and perplexity is 118.17785357543858
At time: 1552.4244089126587 and batch: 1250, loss is 4.783616189956665 and perplexity is 119.53583369245446
At time: 1553.626920223236 and batch: 1300, loss is 4.7606023502349855 and perplexity is 116.81626901835915
At time: 1554.825726032257 and batch: 1350, loss is 4.762268495559693 and perplexity is 117.0110641322547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990234375 and perplexity of 146.9708657559963
Finished 45 epochs...
Completing Train Step...
At time: 1558.2419261932373 and batch: 50, loss is 4.878684387207032 and perplexity is 131.4576027661483
At time: 1559.4458620548248 and batch: 100, loss is 4.876684923171997 and perplexity is 131.19502061654816
At time: 1560.6237185001373 and batch: 150, loss is 4.861259412765503 and perplexity is 129.18679920150754
At time: 1561.795571565628 and batch: 200, loss is 4.835760164260864 and perplexity is 125.9342775675729
At time: 1562.9685852527618 and batch: 250, loss is 4.8554997158050535 and perplexity is 128.44486110720317
At time: 1564.1469883918762 and batch: 300, loss is 4.85095365524292 and perplexity is 127.86226824428797
At time: 1565.3277716636658 and batch: 350, loss is 4.862147598266602 and perplexity is 129.30159201460137
At time: 1566.5227093696594 and batch: 400, loss is 4.887045021057129 and perplexity is 132.56127893693971
At time: 1567.7121319770813 and batch: 450, loss is 4.852902812957764 and perplexity is 128.1117350169345
At time: 1568.9094321727753 and batch: 500, loss is 4.896674470901489 and perplexity is 133.84393685749524
At time: 1570.1100034713745 and batch: 550, loss is 4.879679737091064 and perplexity is 131.5885142163571
At time: 1571.3090209960938 and batch: 600, loss is 4.827248907089233 and perplexity is 124.86696706468102
At time: 1572.5051457881927 and batch: 650, loss is 4.837927331924439 and perplexity is 126.20749420785417
At time: 1573.7279994487762 and batch: 700, loss is 4.86455512046814 and perplexity is 129.6132634955341
At time: 1574.9268674850464 and batch: 750, loss is 4.8396769046783445 and perplexity is 126.42849667463204
At time: 1576.1237485408783 and batch: 800, loss is 4.826727809906006 and perplexity is 124.80191619025126
At time: 1577.3209085464478 and batch: 850, loss is 4.795272407531738 and perplexity is 120.93732153358653
At time: 1578.519427537918 and batch: 900, loss is 4.8219781017303465 and perplexity is 124.21054903105626
At time: 1579.7235958576202 and batch: 950, loss is 4.800643701553344 and perplexity is 121.58865914266501
At time: 1580.92085647583 and batch: 1000, loss is 4.833285684585571 and perplexity is 125.6230409904112
At time: 1582.1179926395416 and batch: 1050, loss is 4.780258960723877 and perplexity is 119.13519738747108
At time: 1583.3150143623352 and batch: 1100, loss is 4.768891630172729 and perplexity is 117.78861623500593
At time: 1584.5116539001465 and batch: 1150, loss is 4.803247632980347 and perplexity is 121.90568024485019
At time: 1585.7078042030334 and batch: 1200, loss is 4.772168703079224 and perplexity is 118.17525128757818
At time: 1586.9048008918762 and batch: 1250, loss is 4.783544387817383 and perplexity is 119.5272510720034
At time: 1588.101845741272 and batch: 1300, loss is 4.760543985366821 and perplexity is 116.80945125117942
At time: 1589.2987411022186 and batch: 1350, loss is 4.762100563049317 and perplexity is 116.99141582035458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990230305989583 and perplexity of 146.97026773122928
Finished 46 epochs...
Completing Train Step...
At time: 1592.73952126503 and batch: 50, loss is 4.878323774337769 and perplexity is 131.41020600928232
At time: 1593.9260301589966 and batch: 100, loss is 4.87631196975708 and perplexity is 131.14610010869146
At time: 1595.0860748291016 and batch: 150, loss is 4.860910949707031 and perplexity is 129.14179021678322
At time: 1596.2582430839539 and batch: 200, loss is 4.83540470123291 and perplexity is 125.88952054315055
At time: 1597.4356763362885 and batch: 250, loss is 4.85515570640564 and perplexity is 128.4006824670453
At time: 1598.616031885147 and batch: 300, loss is 4.850586700439453 and perplexity is 127.81535717842041
At time: 1599.8058497905731 and batch: 350, loss is 4.8618412208557125 and perplexity is 129.26198299558024
At time: 1600.9963035583496 and batch: 400, loss is 4.886768894195557 and perplexity is 132.52468026019227
At time: 1602.186018705368 and batch: 450, loss is 4.85261752128601 and perplexity is 128.07519101897728
At time: 1603.3761508464813 and batch: 500, loss is 4.896356191635132 and perplexity is 133.80134388605524
At time: 1604.5956709384918 and batch: 550, loss is 4.879445314407349 and perplexity is 131.55767049908314
At time: 1605.7937088012695 and batch: 600, loss is 4.827039012908935 and perplexity is 124.84076096533279
At time: 1606.992158651352 and batch: 650, loss is 4.837714681625366 and perplexity is 126.18065899982429
At time: 1608.196730852127 and batch: 700, loss is 4.864357900619507 and perplexity is 129.5877037078583
At time: 1609.39408659935 and batch: 750, loss is 4.839441776275635 and perplexity is 126.39877323870088
At time: 1610.5914804935455 and batch: 800, loss is 4.826574277877808 and perplexity is 124.78275656978084
At time: 1611.7887618541718 and batch: 850, loss is 4.795125188827515 and perplexity is 120.91951860831212
At time: 1612.985903263092 and batch: 900, loss is 4.821875143051147 and perplexity is 124.19776113530915
At time: 1614.1833231449127 and batch: 950, loss is 4.800456590652466 and perplexity is 121.56591070742273
At time: 1615.380268573761 and batch: 1000, loss is 4.833140640258789 and perplexity is 125.60482140235831
At time: 1616.577586889267 and batch: 1050, loss is 4.780136766433716 and perplexity is 119.1206406359872
At time: 1617.7757091522217 and batch: 1100, loss is 4.768761758804321 and perplexity is 117.77331985953472
At time: 1618.973560810089 and batch: 1150, loss is 4.803148241043091 and perplexity is 121.89356440524645
At time: 1620.1732692718506 and batch: 1200, loss is 4.772136192321778 and perplexity is 118.17140938309937
At time: 1621.373324394226 and batch: 1250, loss is 4.783464555740356 and perplexity is 119.51770934416211
At time: 1622.5720059871674 and batch: 1300, loss is 4.760482397079468 and perplexity is 116.80225737866158
At time: 1623.7705309391022 and batch: 1350, loss is 4.761926288604736 and perplexity is 116.97102898284581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990227864583333 and perplexity of 146.96990891753703
Finished 47 epochs...
Completing Train Step...
At time: 1627.241849899292 and batch: 50, loss is 4.877968807220459 and perplexity is 131.3635679852422
At time: 1628.4040105342865 and batch: 100, loss is 4.875942897796631 and perplexity is 131.09770669129512
At time: 1629.5743145942688 and batch: 150, loss is 4.860565786361694 and perplexity is 129.0972228963944
At time: 1630.7553255558014 and batch: 200, loss is 4.835060958862305 and perplexity is 125.84625441755094
At time: 1631.942997932434 and batch: 250, loss is 4.854815874099732 and perplexity is 128.35705518044293
At time: 1633.1339621543884 and batch: 300, loss is 4.850218057632446 and perplexity is 127.76824765019947
At time: 1634.3703410625458 and batch: 350, loss is 4.861537036895752 and perplexity is 129.22266955328266
At time: 1635.5626940727234 and batch: 400, loss is 4.886498317718506 and perplexity is 132.48882704982165
At time: 1636.7611713409424 and batch: 450, loss is 4.8523389434814455 and perplexity is 128.03951708265814
At time: 1637.9588527679443 and batch: 500, loss is 4.896034145355225 and perplexity is 133.75826059878875
At time: 1639.1575729846954 and batch: 550, loss is 4.879209899902344 and perplexity is 131.52670356037933
At time: 1640.3628289699554 and batch: 600, loss is 4.826826915740967 and perplexity is 124.81428540128039
At time: 1641.5625576972961 and batch: 650, loss is 4.837504415512085 and perplexity is 126.15413027222914
At time: 1642.759874343872 and batch: 700, loss is 4.864154911041259 and perplexity is 129.56140142417163
At time: 1643.9569973945618 and batch: 750, loss is 4.839196634292603 and perplexity is 126.36779139040735
At time: 1645.1544976234436 and batch: 800, loss is 4.826414461135864 and perplexity is 124.76281578965285
At time: 1646.3514955043793 and batch: 850, loss is 4.794978523254395 and perplexity is 120.90178517828764
At time: 1647.5538792610168 and batch: 900, loss is 4.821777610778809 and perplexity is 124.18564843614541
At time: 1648.751809835434 and batch: 950, loss is 4.800269889831543 and perplexity is 121.54321637068892
At time: 1649.9486682415009 and batch: 1000, loss is 4.832994899749756 and perplexity is 125.58651702562706
At time: 1651.1549367904663 and batch: 1050, loss is 4.78001763343811 and perplexity is 119.10645028251614
At time: 1652.3585007190704 and batch: 1100, loss is 4.768621282577515 and perplexity is 117.75677666993201
At time: 1653.558572769165 and batch: 1150, loss is 4.803037490844726 and perplexity is 121.8800654163309
At time: 1654.7574150562286 and batch: 1200, loss is 4.772090539932251 and perplexity is 118.16601469902837
At time: 1655.9562149047852 and batch: 1250, loss is 4.783380479812622 and perplexity is 119.50766120427755
At time: 1657.155324935913 and batch: 1300, loss is 4.760409908294678 and perplexity is 116.79379083183204
At time: 1658.3529267311096 and batch: 1350, loss is 4.7617449283599855 and perplexity is 116.94981701196298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.9902266438802085 and perplexity of 146.96972951101952
Finished 48 epochs...
Completing Train Step...
At time: 1661.8221445083618 and batch: 50, loss is 4.877615041732788 and perplexity is 131.31710430765918
At time: 1662.9828379154205 and batch: 100, loss is 4.875563383102417 and perplexity is 131.0479626251271
At time: 1664.1883854866028 and batch: 150, loss is 4.860219440460205 and perplexity is 129.05251834441665
At time: 1665.3689258098602 and batch: 200, loss is 4.834733457565307 and perplexity is 125.80504635422236
At time: 1666.5590574741364 and batch: 250, loss is 4.854476566314697 and perplexity is 128.31351002037982
At time: 1667.7527565956116 and batch: 300, loss is 4.849852094650268 and perplexity is 127.72149775614884
At time: 1668.9556255340576 and batch: 350, loss is 4.861236152648925 and perplexity is 129.1837943364447
At time: 1670.1564991474152 and batch: 400, loss is 4.886230316162109 and perplexity is 132.4533245955361
At time: 1671.3532457351685 and batch: 450, loss is 4.852062158584594 and perplexity is 128.00408258222305
At time: 1672.5509719848633 and batch: 500, loss is 4.895711460113525 and perplexity is 133.71510574522978
At time: 1673.754680633545 and batch: 550, loss is 4.878984975814819 and perplexity is 131.49712336336998
At time: 1674.9536023139954 and batch: 600, loss is 4.8266135597229 and perplexity is 124.78765836296972
At time: 1676.1551060676575 and batch: 650, loss is 4.837290925979614 and perplexity is 126.12720056064609
At time: 1677.3524317741394 and batch: 700, loss is 4.863947162628174 and perplexity is 129.53448804433137
At time: 1678.5558409690857 and batch: 750, loss is 4.838959817886352 and perplexity is 126.33786896738467
At time: 1679.7594916820526 and batch: 800, loss is 4.826265668869018 and perplexity is 124.74425342847553
At time: 1680.9568979740143 and batch: 850, loss is 4.79484001159668 and perplexity is 120.88504003132769
At time: 1682.155597448349 and batch: 900, loss is 4.821666259765625 and perplexity is 124.17182100823244
At time: 1683.3535325527191 and batch: 950, loss is 4.800091190338135 and perplexity is 121.52149860003139
At time: 1684.5580234527588 and batch: 1000, loss is 4.832851715087891 and perplexity is 125.56853624996832
At time: 1685.7611908912659 and batch: 1050, loss is 4.7798916721344 and perplexity is 119.09144842360496
At time: 1686.9590678215027 and batch: 1100, loss is 4.7684694480896 and perplexity is 117.73889848734451
At time: 1688.1569147109985 and batch: 1150, loss is 4.802907047271728 and perplexity is 121.86416798200234
At time: 1689.3539826869965 and batch: 1200, loss is 4.772035675048828 and perplexity is 118.15953171225311
At time: 1690.5515825748444 and batch: 1250, loss is 4.783293304443359 and perplexity is 119.49724353387106
At time: 1691.748458147049 and batch: 1300, loss is 4.760338907241821 and perplexity is 116.78549864409638
At time: 1692.9452934265137 and batch: 1350, loss is 4.761559953689575 and perplexity is 116.92818625873906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.99022705078125 and perplexity of 146.96978931316772
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1696.3945572376251 and batch: 50, loss is 4.877513589859009 and perplexity is 131.30378261713457
At time: 1697.5870246887207 and batch: 100, loss is 4.875484418869019 and perplexity is 131.03761493177421
At time: 1698.7630224227905 and batch: 150, loss is 4.860243558883667 and perplexity is 129.05563092523803
At time: 1699.9389734268188 and batch: 200, loss is 4.834775152206421 and perplexity is 125.8102918598344
At time: 1701.1162419319153 and batch: 250, loss is 4.854334850311279 and perplexity is 128.29532723098168
At time: 1702.305688381195 and batch: 300, loss is 4.849706668853759 and perplexity is 127.70292510611027
At time: 1703.4948813915253 and batch: 350, loss is 4.86114242553711 and perplexity is 129.17168687991548
At time: 1704.6896703243256 and batch: 400, loss is 4.886363916397094 and perplexity is 132.47102157296047
At time: 1705.885847568512 and batch: 450, loss is 4.851846666336059 and perplexity is 127.97650166648923
At time: 1707.0829734802246 and batch: 500, loss is 4.895293531417846 and perplexity is 133.65923404150044
At time: 1708.2792613506317 and batch: 550, loss is 4.8780920028686525 and perplexity is 131.3797524020536
At time: 1709.476492881775 and batch: 600, loss is 4.82557222366333 and perplexity is 124.65778010971772
At time: 1710.6731946468353 and batch: 650, loss is 4.836247930526733 and perplexity is 125.99571904320837
At time: 1711.8704323768616 and batch: 700, loss is 4.862520093917847 and perplexity is 129.34976526693234
At time: 1713.0684280395508 and batch: 750, loss is 4.837517137527466 and perplexity is 126.15573521722385
At time: 1714.2656342983246 and batch: 800, loss is 4.825026731491089 and perplexity is 124.58979880977819
At time: 1715.463147163391 and batch: 850, loss is 4.793071250915528 and perplexity is 120.67141230943301
At time: 1716.6603047847748 and batch: 900, loss is 4.81960464477539 and perplexity is 123.91609022046674
At time: 1717.85800242424 and batch: 950, loss is 4.797832384109497 and perplexity is 121.24731486262563
At time: 1719.0546052455902 and batch: 1000, loss is 4.830608215332031 and perplexity is 125.28713904485782
At time: 1720.2519264221191 and batch: 1050, loss is 4.7775146007537845 and perplexity is 118.80869574467204
At time: 1721.4494636058807 and batch: 1100, loss is 4.765976448059082 and perplexity is 117.44574098248901
At time: 1722.6469526290894 and batch: 1150, loss is 4.800480451583862 and perplexity is 121.5688114178849
At time: 1723.8439004421234 and batch: 1200, loss is 4.769312162399292 and perplexity is 117.83816056081763
At time: 1725.0669746398926 and batch: 1250, loss is 4.780685482025146 and perplexity is 119.18602192499115
At time: 1726.26451587677 and batch: 1300, loss is 4.757416305541992 and perplexity is 116.44467942924715
At time: 1727.4616684913635 and batch: 1350, loss is 4.759147396087647 and perplexity is 116.64643028701836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.990057373046875 and perplexity of 146.94485392784517
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77ca218eb8>
SETTINGS FOR THIS RUN
{'dropout': 0.2495671056082589, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 25.49355568496804, 'wordvec_source': '', 'anneal': 6.4309190347271565, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5492215156555176 and batch: 50, loss is 6.951401100158692 and perplexity is 1044.6123098024032
At time: 2.6289000511169434 and batch: 100, loss is 6.174788970947265 and perplexity is 480.4816176406226
At time: 3.707273483276367 and batch: 150, loss is 6.026001472473144 and perplexity is 414.05610024086906
At time: 4.785337686538696 and batch: 200, loss is 5.9749686145782475 and perplexity is 393.4557521225868
At time: 5.865355968475342 and batch: 250, loss is 5.978064165115357 and perplexity is 394.6756013657951
At time: 6.945714473724365 and batch: 300, loss is 5.9476344013214115 and perplexity is 382.84660557593645
At time: 8.027320384979248 and batch: 350, loss is 5.941982698440552 and perplexity is 380.6889732040306
At time: 9.111220121383667 and batch: 400, loss is 5.974050817489624 and perplexity is 393.09480524212137
At time: 10.196489095687866 and batch: 450, loss is 5.9317302417755124 and perplexity is 376.80591545725457
At time: 11.277998447418213 and batch: 500, loss is 5.940063982009888 and perplexity is 379.9592393162463
At time: 12.357065677642822 and batch: 550, loss is 5.904728755950928 and perplexity is 366.76772873027465
At time: 13.464589834213257 and batch: 600, loss is 5.866037092208862 and perplexity is 352.8479022290157
At time: 14.562658071517944 and batch: 650, loss is 5.881828908920288 and perplexity is 358.4642410072292
At time: 15.662736654281616 and batch: 700, loss is 5.900225629806519 and perplexity is 365.11984049108565
At time: 16.76149606704712 and batch: 750, loss is 5.881729173660278 and perplexity is 358.4284912657326
At time: 17.90431809425354 and batch: 800, loss is 5.830606927871704 and perplexity is 340.56531494064484
At time: 19.097220420837402 and batch: 850, loss is 5.83665132522583 and perplexity is 342.6300608151874
At time: 20.30308747291565 and batch: 900, loss is 5.883880729675293 and perplexity is 359.2005004547603
At time: 21.508638858795166 and batch: 950, loss is 5.842936897277832 and perplexity is 344.7904693384854
At time: 22.71564292907715 and batch: 1000, loss is 5.86253851890564 and perplexity is 351.61559489390606
At time: 23.922282934188843 and batch: 1050, loss is 5.849405002593994 and perplexity is 347.027838375175
At time: 25.12903118133545 and batch: 1100, loss is 5.837742042541504 and perplexity is 343.00397723687723
At time: 26.334860801696777 and batch: 1150, loss is 5.845102491378785 and perplexity is 345.5379546276863
At time: 27.54121994972229 and batch: 1200, loss is 5.844705171585083 and perplexity is 345.40069282905813
At time: 28.747392416000366 and batch: 1250, loss is 5.835965147018433 and perplexity is 342.39503617787057
At time: 29.953094005584717 and batch: 1300, loss is 5.823944139480591 and perplexity is 338.3037428683607
At time: 31.160210371017456 and batch: 1350, loss is 5.799349193572998 and perplexity is 330.0846687670766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.387638346354167 and perplexity of 218.68631389169678
Finished 1 epochs...
Completing Train Step...
At time: 34.64503002166748 and batch: 50, loss is 5.715529298782348 and perplexity is 303.54482670393634
At time: 35.84281373023987 and batch: 100, loss is 5.75937650680542 and perplexity is 317.1505260652331
At time: 37.04094958305359 and batch: 150, loss is 5.743397531509399 and perplexity is 312.1230594966479
At time: 38.23892164230347 and batch: 200, loss is 5.718485279083252 and perplexity is 304.4434266997404
At time: 39.43630862236023 and batch: 250, loss is 5.724549179077148 and perplexity is 306.2951498509282
At time: 40.63392972946167 and batch: 300, loss is 5.7275956344604495 and perplexity is 307.22968714938446
At time: 41.831764221191406 and batch: 350, loss is 5.7633766841888425 and perplexity is 318.4217252427575
At time: 43.03065752983093 and batch: 400, loss is 5.789593372344971 and perplexity is 326.8800788681969
At time: 44.23691391944885 and batch: 450, loss is 5.736080904006958 and perplexity is 309.847705444947
At time: 45.4363112449646 and batch: 500, loss is 5.7989339351654055 and perplexity is 329.94762678903976
At time: 46.63386154174805 and batch: 550, loss is 5.75271056175232 and perplexity is 315.04344871812464
At time: 47.83173847198486 and batch: 600, loss is 5.683301229476928 and perplexity is 293.91812127233675
At time: 49.02903652191162 and batch: 650, loss is 5.74713324546814 and perplexity is 313.2912426072771
At time: 50.22689652442932 and batch: 700, loss is 5.7569589424133305 and perplexity is 316.3847203118324
At time: 51.42451238632202 and batch: 750, loss is 5.7049863815307615 and perplexity is 300.36138955840545
At time: 52.62229585647583 and batch: 800, loss is 5.644259099960327 and perplexity is 282.66405281387887
At time: 53.82130765914917 and batch: 850, loss is 5.646083536148072 and perplexity is 283.18022606020554
At time: 55.07018852233887 and batch: 900, loss is 5.745393257141114 and perplexity is 312.74659348115495
At time: 56.26761507987976 and batch: 950, loss is 5.712320356369019 and perplexity is 302.57233001262745
At time: 57.46502757072449 and batch: 1000, loss is 5.7137118911743165 and perplexity is 302.99366302274615
At time: 58.66215634346008 and batch: 1050, loss is 5.697722911834717 and perplexity is 298.1876277907826
At time: 59.85917592048645 and batch: 1100, loss is 5.740768404006958 and perplexity is 311.3035259779083
At time: 61.05662488937378 and batch: 1150, loss is 5.739569644927979 and perplexity is 310.93057163568807
At time: 62.2586452960968 and batch: 1200, loss is 5.692394456863403 and perplexity is 296.60297407043964
At time: 63.455413579940796 and batch: 1250, loss is 5.740069332122803 and perplexity is 311.08597848498647
At time: 64.65219235420227 and batch: 1300, loss is 5.746416425704956 and perplexity is 313.0667497230244
At time: 65.84930348396301 and batch: 1350, loss is 5.722724275588989 and perplexity is 305.73670047664706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4363916015625 and perplexity of 229.61215468379763
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 69.32164072990417 and batch: 50, loss is 5.650590057373047 and perplexity is 284.4592635997135
At time: 70.54510021209717 and batch: 100, loss is 5.646470308303833 and perplexity is 283.28977347028615
At time: 71.74178051948547 and batch: 150, loss is 5.588806695938111 and perplexity is 267.41632025968767
At time: 72.93944025039673 and batch: 200, loss is 5.578011541366577 and perplexity is 264.5450455583418
At time: 74.13665437698364 and batch: 250, loss is 5.598297080993652 and perplexity is 269.96628504389696
At time: 75.33370518684387 and batch: 300, loss is 5.567833518981933 and perplexity is 261.8661561868471
At time: 76.53039026260376 and batch: 350, loss is 5.5616553592681885 and perplexity is 260.2532926447808
At time: 77.72812533378601 and batch: 400, loss is 5.600610466003418 and perplexity is 270.59154395430244
At time: 78.9253203868866 and batch: 450, loss is 5.55083158493042 and perplexity is 257.4515597496574
At time: 80.12242126464844 and batch: 500, loss is 5.569717779159546 and perplexity is 262.360045318499
At time: 81.31988430023193 and batch: 550, loss is 5.552189226150513 and perplexity is 257.8013239727905
At time: 82.51719117164612 and batch: 600, loss is 5.503054981231689 and perplexity is 245.44060453242324
At time: 83.71437311172485 and batch: 650, loss is 5.528523473739624 and perplexity is 251.77188863549344
At time: 84.91283202171326 and batch: 700, loss is 5.532037086486817 and perplexity is 252.65807349630194
At time: 86.13650798797607 and batch: 750, loss is 5.507545013427734 and perplexity is 246.5451185451107
At time: 87.33402800559998 and batch: 800, loss is 5.474231853485107 and perplexity is 238.46721879592766
At time: 88.53075885772705 and batch: 850, loss is 5.428314638137818 and perplexity is 227.76505522757236
At time: 89.72724032402039 and batch: 900, loss is 5.457535953521728 and perplexity is 234.51884649879523
At time: 90.92407250404358 and batch: 950, loss is 5.437292680740357 and perplexity is 229.8191466594402
At time: 92.1205837726593 and batch: 1000, loss is 5.443380298614502 and perplexity is 231.22246490327166
At time: 93.31789135932922 and batch: 1050, loss is 5.390182466506958 and perplexity is 219.24338647933345
At time: 94.51465320587158 and batch: 1100, loss is 5.396092205047608 and perplexity is 220.5428936619272
At time: 95.71189022064209 and batch: 1150, loss is 5.406363677978516 and perplexity is 222.81986794517462
At time: 96.9094409942627 and batch: 1200, loss is 5.374931106567383 and perplexity is 215.92499598401815
At time: 98.10701251029968 and batch: 1250, loss is 5.358119039535523 and perplexity is 212.32519531137075
At time: 99.30320596694946 and batch: 1300, loss is 5.31189884185791 and perplexity is 202.73482449980787
At time: 100.49965715408325 and batch: 1350, loss is 5.332770595550537 and perplexity is 207.01072335077438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.229975992838542 and perplexity of 186.78831920900274
Finished 3 epochs...
Completing Train Step...
At time: 103.97522449493408 and batch: 50, loss is 5.465628147125244 and perplexity is 236.4243177313152
At time: 105.1694438457489 and batch: 100, loss is 5.476232461929321 and perplexity is 238.94477587059453
At time: 106.36733531951904 and batch: 150, loss is 5.425814266204834 and perplexity is 227.1962692607314
At time: 107.5643835067749 and batch: 200, loss is 5.428738203048706 and perplexity is 227.86154894712752
At time: 108.76148080825806 and batch: 250, loss is 5.455764284133911 and perplexity is 234.10372447566
At time: 109.95890307426453 and batch: 300, loss is 5.426421203613281 and perplexity is 227.3342050305604
At time: 111.15650367736816 and batch: 350, loss is 5.431511945724488 and perplexity is 228.49445560393372
At time: 112.36060190200806 and batch: 400, loss is 5.473921899795532 and perplexity is 238.3933164553624
At time: 113.55861949920654 and batch: 450, loss is 5.425356245040893 and perplexity is 227.09223238840502
At time: 114.75571012496948 and batch: 500, loss is 5.452359428405762 and perplexity is 233.30799051680984
At time: 115.99872088432312 and batch: 550, loss is 5.441332674026489 and perplexity is 230.74949249905202
At time: 117.196218252182 and batch: 600, loss is 5.392284746170044 and perplexity is 219.70478221349816
At time: 118.39330983161926 and batch: 650, loss is 5.422250537872315 and perplexity is 226.38804448107916
At time: 119.59782409667969 and batch: 700, loss is 5.436892061233521 and perplexity is 229.7270950663071
At time: 120.79508924484253 and batch: 750, loss is 5.412473945617676 and perplexity is 224.1855249897247
At time: 121.99408483505249 and batch: 800, loss is 5.379701414108276 and perplexity is 216.95748530850454
At time: 123.19130563735962 and batch: 850, loss is 5.3450103378295895 and perplexity is 209.5600509837686
At time: 124.38911437988281 and batch: 900, loss is 5.377952222824097 and perplexity is 216.57831688189637
At time: 125.58645534515381 and batch: 950, loss is 5.357863874435425 and perplexity is 212.2710242432327
At time: 126.78317379951477 and batch: 1000, loss is 5.365774040222168 and perplexity is 213.95678175751257
At time: 127.98113322257996 and batch: 1050, loss is 5.319509382247925 and perplexity is 204.2836322263927
At time: 129.1781244277954 and batch: 1100, loss is 5.324699220657348 and perplexity is 205.34658716367952
At time: 130.37407064437866 and batch: 1150, loss is 5.339101896286011 and perplexity is 208.3255283165657
At time: 131.57137393951416 and batch: 1200, loss is 5.312715139389038 and perplexity is 202.90038400023323
At time: 132.76790618896484 and batch: 1250, loss is 5.312759046554565 and perplexity is 202.9092929765616
At time: 133.9655635356903 and batch: 1300, loss is 5.279899587631226 and perplexity is 196.350158377389
At time: 135.16233944892883 and batch: 1350, loss is 5.2904707717895505 and perplexity is 198.43682188119388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.214390055338542 and perplexity of 183.89961817402454
Finished 4 epochs...
Completing Train Step...
At time: 138.59374475479126 and batch: 50, loss is 5.3909741878509525 and perplexity is 219.41703487944062
At time: 139.75940418243408 and batch: 100, loss is 5.405924768447876 and perplexity is 222.72209164056315
At time: 140.931734085083 and batch: 150, loss is 5.3602317237854 and perplexity is 212.77424559105836
At time: 142.10631704330444 and batch: 200, loss is 5.359047794342041 and perplexity is 212.5224849597342
At time: 143.28600549697876 and batch: 250, loss is 5.385301246643066 and perplexity is 218.17581894184053
At time: 144.48031783103943 and batch: 300, loss is 5.356352853775024 and perplexity is 211.95052054483256
At time: 145.69588828086853 and batch: 350, loss is 5.366152763366699 and perplexity is 214.03782748867195
At time: 146.8865451812744 and batch: 400, loss is 5.404427461624145 and perplexity is 222.3888578718093
At time: 148.08120965957642 and batch: 450, loss is 5.361614494323731 and perplexity is 213.0686670609319
At time: 149.27863073349 and batch: 500, loss is 5.393268709182739 and perplexity is 219.9210699850416
At time: 150.47667241096497 and batch: 550, loss is 5.384042205810547 and perplexity is 217.90129952896322
At time: 151.67461800575256 and batch: 600, loss is 5.3339167499542235 and perplexity is 207.24812562679625
At time: 152.87175488471985 and batch: 650, loss is 5.361653251647949 and perplexity is 213.07692519237244
At time: 154.075829744339 and batch: 700, loss is 5.376524219512939 and perplexity is 216.2692630457332
At time: 155.27488255500793 and batch: 750, loss is 5.356658945083618 and perplexity is 212.01540668705874
At time: 156.48028898239136 and batch: 800, loss is 5.325987253189087 and perplexity is 205.61125065923366
At time: 157.6777045726776 and batch: 850, loss is 5.2980210399627685 and perplexity is 199.9407434630236
At time: 158.875426530838 and batch: 900, loss is 5.328596172332763 and perplexity is 206.1483741384384
At time: 160.0724973678589 and batch: 950, loss is 5.3128657722473145 and perplexity is 202.9309497670672
At time: 161.26922702789307 and batch: 1000, loss is 5.321508617401123 and perplexity is 204.69245177219733
At time: 162.466055393219 and batch: 1050, loss is 5.276461954116821 and perplexity is 195.67633733086174
At time: 163.66288566589355 and batch: 1100, loss is 5.282452640533447 and perplexity is 196.85209117694484
At time: 164.8593339920044 and batch: 1150, loss is 5.294877557754517 and perplexity is 199.3132201142223
At time: 166.0563313961029 and batch: 1200, loss is 5.271545429229736 and perplexity is 194.71665084295668
At time: 167.25351285934448 and batch: 1250, loss is 5.277613716125488 and perplexity is 195.90183973981982
At time: 168.45054411888123 and batch: 1300, loss is 5.247959241867066 and perplexity is 190.17776535168073
At time: 169.64729380607605 and batch: 1350, loss is 5.252918176651001 and perplexity is 191.1231866913911
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.205386555989583 and perplexity of 182.25130948932804
Finished 5 epochs...
Completing Train Step...
At time: 173.08900141716003 and batch: 50, loss is 5.339305076599121 and perplexity is 208.36786026300135
At time: 174.27527260780334 and batch: 100, loss is 5.355843896865845 and perplexity is 211.84267430986833
At time: 175.44268035888672 and batch: 150, loss is 5.3154272365570066 and perplexity is 203.45141644606935
At time: 176.64142298698425 and batch: 200, loss is 5.310701942443847 and perplexity is 202.49231646496716
At time: 177.8134744167328 and batch: 250, loss is 5.334367208480835 and perplexity is 207.34150334192407
At time: 179.0006229877472 and batch: 300, loss is 5.310062952041626 and perplexity is 202.36296714910944
At time: 180.18717098236084 and batch: 350, loss is 5.321678104400635 and perplexity is 204.72714742181876
At time: 181.3678743839264 and batch: 400, loss is 5.356601028442383 and perplexity is 212.0031278223921
At time: 182.55058574676514 and batch: 450, loss is 5.315871868133545 and perplexity is 203.54189748398537
At time: 183.73025965690613 and batch: 500, loss is 5.34879919052124 and perplexity is 210.3555492081539
At time: 184.91387104988098 and batch: 550, loss is 5.34097297668457 and perplexity is 208.71568702444677
At time: 186.09628200531006 and batch: 600, loss is 5.2895321273803715 and perplexity is 198.25064765712625
At time: 187.2981879711151 and batch: 650, loss is 5.317132568359375 and perplexity is 203.7986646192939
At time: 188.49562573432922 and batch: 700, loss is 5.332527847290039 and perplexity is 206.9604779565143
At time: 189.69235110282898 and batch: 750, loss is 5.3154028701782225 and perplexity is 203.4464591321882
At time: 190.8893895149231 and batch: 800, loss is 5.285038366317749 and perplexity is 197.36175534672043
At time: 192.093159198761 and batch: 850, loss is 5.2596478939056395 and perplexity is 192.4137293215107
At time: 193.2898669242859 and batch: 900, loss is 5.291133775711059 and perplexity is 198.56842989576677
At time: 194.48681807518005 and batch: 950, loss is 5.276148099899292 and perplexity is 195.61493312360844
At time: 195.68942308425903 and batch: 1000, loss is 5.286236267089844 and perplexity is 197.5983168061217
At time: 196.88614296913147 and batch: 1050, loss is 5.244341840744019 and perplexity is 189.49105888492085
At time: 198.08302998542786 and batch: 1100, loss is 5.244643020629883 and perplexity is 189.5481383755738
At time: 199.27959775924683 and batch: 1150, loss is 5.256615991592407 and perplexity is 191.83123317240708
At time: 200.4761962890625 and batch: 1200, loss is 5.2288862991333005 and perplexity is 186.5848880123254
At time: 201.6738109588623 and batch: 1250, loss is 5.240643167495728 and perplexity is 188.79148791437134
At time: 202.870703458786 and batch: 1300, loss is 5.216267261505127 and perplexity is 184.24515989634824
At time: 204.06772089004517 and batch: 1350, loss is 5.219689636230469 and perplexity is 184.87679610623326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.199956868489584 and perplexity of 181.26442349817296
Finished 6 epochs...
Completing Train Step...
At time: 207.50412487983704 and batch: 50, loss is 5.297219839096069 and perplexity is 199.7806149222012
At time: 208.70890498161316 and batch: 100, loss is 5.317871074676514 and perplexity is 203.9492268092611
At time: 209.88234424591064 and batch: 150, loss is 5.277575998306275 and perplexity is 195.89445088899143
At time: 211.0595064163208 and batch: 200, loss is 5.275605869293213 and perplexity is 195.50889347143334
At time: 212.23064255714417 and batch: 250, loss is 5.2998568725585935 and perplexity is 200.30813833165885
At time: 213.4026174545288 and batch: 300, loss is 5.272441473007202 and perplexity is 194.8912036781255
At time: 214.58065056800842 and batch: 350, loss is 5.286248683929443 and perplexity is 197.60077036795926
At time: 215.7640025615692 and batch: 400, loss is 5.322172298431396 and perplexity is 204.8283473601524
At time: 216.95325422286987 and batch: 450, loss is 5.2799469757080075 and perplexity is 196.35946325423868
At time: 218.1429626941681 and batch: 500, loss is 5.315407419204712 and perplexity is 203.4473846176251
At time: 219.33263778686523 and batch: 550, loss is 5.307395935058594 and perplexity is 201.82398074142063
At time: 220.5325367450714 and batch: 600, loss is 5.255351648330689 and perplexity is 191.5888459079999
At time: 221.72875928878784 and batch: 650, loss is 5.284778184890747 and perplexity is 197.31041216313986
At time: 222.9255108833313 and batch: 700, loss is 5.30054404258728 and perplexity is 200.44583138467368
At time: 224.12202978134155 and batch: 750, loss is 5.2826385593414305 and perplexity is 196.8886930854717
At time: 225.31876587867737 and batch: 800, loss is 5.252391309738159 and perplexity is 191.0225167302111
At time: 226.51612281799316 and batch: 850, loss is 5.228226995468139 and perplexity is 186.4619124553675
At time: 227.72103428840637 and batch: 900, loss is 5.258279504776001 and perplexity is 192.15061253004956
At time: 228.91793632507324 and batch: 950, loss is 5.244037599563598 and perplexity is 189.4334166704989
At time: 230.11444759368896 and batch: 1000, loss is 5.255938386917114 and perplexity is 191.70129146146945
At time: 231.31092071533203 and batch: 1050, loss is 5.2133217048645015 and perplexity is 183.70325384141353
At time: 232.50744915008545 and batch: 1100, loss is 5.22050479888916 and perplexity is 185.02756220797716
At time: 233.7067255973816 and batch: 1150, loss is 5.244828872680664 and perplexity is 189.58336955960516
At time: 234.90773153305054 and batch: 1200, loss is 5.218857755661011 and perplexity is 184.7230646437826
At time: 236.15061140060425 and batch: 1250, loss is 5.225321292877197 and perplexity is 185.92089599036095
At time: 237.3466386795044 and batch: 1300, loss is 5.198850860595703 and perplexity is 181.0640544402094
At time: 238.54272437095642 and batch: 1350, loss is 5.199969224929809 and perplexity is 181.26666329502487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.200816243489584 and perplexity of 181.42026456548427
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 241.98315024375916 and batch: 50, loss is 5.2632435131073 and perplexity is 193.10682112169653
At time: 243.13863039016724 and batch: 100, loss is 5.281463193893432 and perplexity is 196.65741286453363
At time: 244.31097888946533 and batch: 150, loss is 5.245277013778686 and perplexity is 189.6683486989066
At time: 245.49100613594055 and batch: 200, loss is 5.237588167190552 and perplexity is 188.2156099627276
At time: 246.67280840873718 and batch: 250, loss is 5.245071134567261 and perplexity is 189.62930394823323
At time: 247.8675811290741 and batch: 300, loss is 5.228173437118531 and perplexity is 186.45192613049946
At time: 249.06466674804688 and batch: 350, loss is 5.235533456802369 and perplexity is 187.82927842934538
At time: 250.26121163368225 and batch: 400, loss is 5.264273233413697 and perplexity is 193.30576954974825
At time: 251.45759320259094 and batch: 450, loss is 5.218659811019897 and perplexity is 184.6865033217245
At time: 252.66060519218445 and batch: 500, loss is 5.250442571640015 and perplexity is 190.6506263504216
At time: 253.8576364517212 and batch: 550, loss is 5.235209197998047 and perplexity is 187.76838300557745
At time: 255.05385398864746 and batch: 600, loss is 5.179415254592896 and perplexity is 177.5789421570868
At time: 256.25066351890564 and batch: 650, loss is 5.199331254959106 and perplexity is 181.15105748759092
At time: 257.447057723999 and batch: 700, loss is 5.2057281112670895 and perplexity is 182.31356901784656
At time: 258.64345145225525 and batch: 750, loss is 5.187220735549927 and perplexity is 178.97045485652154
At time: 259.8396785259247 and batch: 800, loss is 5.163459930419922 and perplexity is 174.7680961781311
At time: 261.03600573539734 and batch: 850, loss is 5.118949375152588 and perplexity is 167.15965524503702
At time: 262.2319462299347 and batch: 900, loss is 5.144900064468384 and perplexity is 171.5543394402546
At time: 263.42789483070374 and batch: 950, loss is 5.129436273574829 and perplexity is 168.92186547985548
At time: 264.6245219707489 and batch: 1000, loss is 5.133389949798584 and perplexity is 169.59104984052448
At time: 265.82080602645874 and batch: 1050, loss is 5.08350305557251 and perplexity is 161.3382439952705
At time: 267.04359221458435 and batch: 1100, loss is 5.0814047527313235 and perplexity is 161.00006242725664
At time: 268.23992443084717 and batch: 1150, loss is 5.097094593048095 and perplexity is 163.54604852660438
At time: 269.4445662498474 and batch: 1200, loss is 5.063925828933716 and perplexity is 158.21040572575293
At time: 270.6476540565491 and batch: 1250, loss is 5.0655479240417485 and perplexity is 158.46724630452732
At time: 271.8471055030823 and batch: 1300, loss is 5.036520624160767 and perplexity is 153.93348971559172
At time: 273.0444645881653 and batch: 1350, loss is 5.05222671508789 and perplexity is 156.3702691493532
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.123870442708333 and perplexity of 167.9842865701551
Finished 8 epochs...
Completing Train Step...
At time: 276.49060440063477 and batch: 50, loss is 5.211708002090454 and perplexity is 183.40705044748432
At time: 277.6618731021881 and batch: 100, loss is 5.230888385772705 and perplexity is 186.95882132226689
At time: 278.8327841758728 and batch: 150, loss is 5.1957066631317135 and perplexity is 180.4956473597408
At time: 280.00370168685913 and batch: 200, loss is 5.19147213935852 and perplexity is 179.7329502192966
At time: 281.1834499835968 and batch: 250, loss is 5.202579870223999 and perplexity is 181.74050450308866
At time: 282.35969614982605 and batch: 300, loss is 5.1887358283996585 and perplexity is 179.2418172306748
At time: 283.53864789009094 and batch: 350, loss is 5.197483854293823 and perplexity is 180.81670783744622
At time: 284.71772933006287 and batch: 400, loss is 5.227020330429077 and perplexity is 186.23705107795632
At time: 285.8969326019287 and batch: 450, loss is 5.18252049446106 and perplexity is 178.13122440867005
At time: 287.0755732059479 and batch: 500, loss is 5.217274007797241 and perplexity is 184.43074142899923
At time: 288.2581877708435 and batch: 550, loss is 5.2058947658538814 and perplexity is 182.34395494226433
At time: 289.44765996932983 and batch: 600, loss is 5.151645364761353 and perplexity is 172.71543654827198
At time: 290.6426899433136 and batch: 650, loss is 5.1729582405090335 and perplexity is 176.43600637384114
At time: 291.83839082717896 and batch: 700, loss is 5.182720441818237 and perplexity is 178.16684483720786
At time: 293.0340065956116 and batch: 750, loss is 5.165363035202026 and perplexity is 175.10101486682058
At time: 294.2298221588135 and batch: 800, loss is 5.142589426040649 and perplexity is 171.1583970071628
At time: 295.4254584312439 and batch: 850, loss is 5.1020646667480465 and perplexity is 164.36090771887572
At time: 296.6674621105194 and batch: 900, loss is 5.13161192893982 and perplexity is 169.28978132666728
At time: 297.863906621933 and batch: 950, loss is 5.118525667190552 and perplexity is 167.08884337101526
At time: 299.0598495006561 and batch: 1000, loss is 5.126689405441284 and perplexity is 168.45849608917106
At time: 300.25630617141724 and batch: 1050, loss is 5.079355068206787 and perplexity is 160.67040105716907
At time: 301.4582452774048 and batch: 1100, loss is 5.081643972396851 and perplexity is 161.03858141540638
At time: 302.6576683521271 and batch: 1150, loss is 5.099418153762818 and perplexity is 163.9264995293416
At time: 303.8545665740967 and batch: 1200, loss is 5.070389738082886 and perplexity is 159.23637573100496
At time: 305.05677247047424 and batch: 1250, loss is 5.076554489135742 and perplexity is 160.2210603953492
At time: 306.253511428833 and batch: 1300, loss is 5.04834056854248 and perplexity is 155.763770602495
At time: 307.4555723667145 and batch: 1350, loss is 5.059572458267212 and perplexity is 157.52315420203223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120272216796875 and perplexity of 167.38092731993027
Finished 9 epochs...
Completing Train Step...
At time: 310.8846821784973 and batch: 50, loss is 5.198424825668335 and perplexity is 180.98693125867794
At time: 312.08309721946716 and batch: 100, loss is 5.21380732536316 and perplexity is 183.7924855717742
At time: 313.2549731731415 and batch: 150, loss is 5.178423480987549 and perplexity is 177.4029113551704
At time: 314.4268789291382 and batch: 200, loss is 5.174151687622071 and perplexity is 176.64669911659882
At time: 315.6012933254242 and batch: 250, loss is 5.186271896362305 and perplexity is 178.8007212132275
At time: 316.79122591018677 and batch: 300, loss is 5.173986740112305 and perplexity is 176.6175640864126
At time: 317.9803555011749 and batch: 350, loss is 5.1831571483612064 and perplexity is 178.24466845589342
At time: 319.1698260307312 and batch: 400, loss is 5.212696132659912 and perplexity is 183.58837012969258
At time: 320.3586428165436 and batch: 450, loss is 5.169562959671021 and perplexity is 175.8379724034125
At time: 321.5478229522705 and batch: 500, loss is 5.20453179359436 and perplexity is 182.09559448264318
At time: 322.7369363307953 and batch: 550, loss is 5.194319448471069 and perplexity is 180.24543474097243
At time: 323.9266028404236 and batch: 600, loss is 5.140242204666138 and perplexity is 170.75712148475606
At time: 325.1160171031952 and batch: 650, loss is 5.162286443710327 and perplexity is 174.56312842699202
At time: 326.3442380428314 and batch: 700, loss is 5.173523654937744 and perplexity is 176.5357940456253
At time: 327.54058957099915 and batch: 750, loss is 5.156590003967285 and perplexity is 173.5715669509492
At time: 328.7369043827057 and batch: 800, loss is 5.134459085464478 and perplexity is 169.77246264069248
At time: 329.9396233558655 and batch: 850, loss is 5.095724086761475 and perplexity is 163.32206116205177
At time: 331.1402897834778 and batch: 900, loss is 5.126541709899902 and perplexity is 168.43361735767488
At time: 332.3445568084717 and batch: 950, loss is 5.115163993835449 and perplexity is 166.52808832405398
At time: 333.5419406890869 and batch: 1000, loss is 5.124475793838501 and perplexity is 168.08600683301253
At time: 334.7385296821594 and batch: 1050, loss is 5.078161258697509 and perplexity is 160.4787056511935
At time: 335.9356064796448 and batch: 1100, loss is 5.082096090316773 and perplexity is 161.11140630534146
At time: 337.13590908050537 and batch: 1150, loss is 5.100915231704712 and perplexity is 164.17209406709176
At time: 338.3353691101074 and batch: 1200, loss is 5.072837791442871 and perplexity is 159.62667241427903
At time: 339.5318989753723 and batch: 1250, loss is 5.0801339530944825 and perplexity is 160.79559355339495
At time: 340.72789430618286 and batch: 1300, loss is 5.0516447162628175 and perplexity is 156.27928831436958
At time: 341.9243025779724 and batch: 1350, loss is 5.060208253860473 and perplexity is 157.62333857432688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11889404296875 and perplexity of 167.15040619215029
Finished 10 epochs...
Completing Train Step...
At time: 345.3527066707611 and batch: 50, loss is 5.188070669174194 and perplexity is 179.12263252515228
At time: 346.54395389556885 and batch: 100, loss is 5.20175085067749 and perplexity is 181.58990050791664
At time: 347.7158741950989 and batch: 150, loss is 5.16715934753418 and perplexity is 175.4158336509775
At time: 348.8873212337494 and batch: 200, loss is 5.1628752613067626 and perplexity is 174.6659445356951
At time: 350.07209730148315 and batch: 250, loss is 5.17575436592102 and perplexity is 176.93003393448876
At time: 351.25745582580566 and batch: 300, loss is 5.164652175903321 and perplexity is 174.97658691281342
At time: 352.44683027267456 and batch: 350, loss is 5.173816795349121 and perplexity is 176.58755140663098
At time: 353.6366000175476 and batch: 400, loss is 5.203232927322388 and perplexity is 181.85923019272684
At time: 354.82613134384155 and batch: 450, loss is 5.1607100296020505 and perplexity is 174.2881614364194
At time: 356.01545763015747 and batch: 500, loss is 5.195954532623291 and perplexity is 180.54039226930368
At time: 357.23048520088196 and batch: 550, loss is 5.186592931747437 and perplexity is 178.85813178654368
At time: 358.4198751449585 and batch: 600, loss is 5.132728662490845 and perplexity is 169.47893850474597
At time: 359.6096248626709 and batch: 650, loss is 5.155040369033814 and perplexity is 173.3028026843764
At time: 360.79848861694336 and batch: 700, loss is 5.167192726135254 and perplexity is 175.42168888383026
At time: 361.99364042282104 and batch: 750, loss is 5.150995063781738 and perplexity is 172.6031560427083
At time: 363.1907608509064 and batch: 800, loss is 5.129258260726929 and perplexity is 168.8917978937966
At time: 364.388156414032 and batch: 850, loss is 5.091978950500488 and perplexity is 162.71154174138246
At time: 365.5929958820343 and batch: 900, loss is 5.1226021099090575 and perplexity is 167.77136164811023
At time: 366.78986144065857 and batch: 950, loss is 5.1117656040191655 and perplexity is 165.96312149705986
At time: 367.9866876602173 and batch: 1000, loss is 5.122187185287475 and perplexity is 167.70176361933247
At time: 369.1842031478882 and batch: 1050, loss is 5.076824073791504 and perplexity is 160.26425935738865
At time: 370.38114285469055 and batch: 1100, loss is 5.081113996505738 and perplexity is 160.95325746153355
At time: 371.578654050827 and batch: 1150, loss is 5.100167236328125 and perplexity is 164.04934001522
At time: 372.77501606941223 and batch: 1200, loss is 5.073447055816651 and perplexity is 159.72395689185984
At time: 373.97164964675903 and batch: 1250, loss is 5.080960464477539 and perplexity is 160.92854787837507
At time: 375.16886258125305 and batch: 1300, loss is 5.051940069198609 and perplexity is 156.32545267803118
At time: 376.36676502227783 and batch: 1350, loss is 5.058520698547364 and perplexity is 157.35756478890102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.118700358072917 and perplexity of 167.1180348181627
Finished 11 epochs...
Completing Train Step...
At time: 379.79805874824524 and batch: 50, loss is 5.180062532424927 and perplexity is 177.69392227780781
At time: 380.9596154689789 and batch: 100, loss is 5.192671766281128 and perplexity is 179.94869208426124
At time: 382.13470101356506 and batch: 150, loss is 5.158623189926147 and perplexity is 173.92482922598603
At time: 383.3185749053955 and batch: 200, loss is 5.154365692138672 and perplexity is 173.18591872143023
At time: 384.5138809680939 and batch: 250, loss is 5.168163480758667 and perplexity is 175.59206298170326
At time: 385.70773911476135 and batch: 300, loss is 5.157480039596558 and perplexity is 173.7261205986882
At time: 386.92624616622925 and batch: 350, loss is 5.166965408325195 and perplexity is 175.38181694164933
At time: 388.1100332736969 and batch: 400, loss is 5.196105070114136 and perplexity is 180.56757241271606
At time: 389.30296993255615 and batch: 450, loss is 5.154223537445068 and perplexity is 173.16130128000174
At time: 390.4963617324829 and batch: 500, loss is 5.1898220348358155 and perplexity is 179.43661662320343
At time: 391.69622349739075 and batch: 550, loss is 5.180856475830078 and perplexity is 177.83505721469825
At time: 392.8948004245758 and batch: 600, loss is 5.1270404815673825 and perplexity is 168.51764822823077
At time: 394.09463119506836 and batch: 650, loss is 5.14934344291687 and perplexity is 172.31831635718004
At time: 395.2926619052887 and batch: 700, loss is 5.161781215667725 and perplexity is 174.47495651464322
At time: 396.492960691452 and batch: 750, loss is 5.145857086181641 and perplexity is 171.7185992556703
At time: 397.6936275959015 and batch: 800, loss is 5.124614496231079 and perplexity is 168.10932238124286
At time: 398.8940386772156 and batch: 850, loss is 5.087793045043945 and perplexity is 162.03187012395315
At time: 400.09216713905334 and batch: 900, loss is 5.1192880153656 and perplexity is 167.2162718120784
At time: 401.2904942035675 and batch: 950, loss is 5.10884765625 and perplexity is 165.47955563000212
At time: 402.4941372871399 and batch: 1000, loss is 5.119824028015136 and perplexity is 167.3059258746872
At time: 403.69185853004456 and batch: 1050, loss is 5.074791135787964 and perplexity is 159.93878300265234
At time: 404.88965940475464 and batch: 1100, loss is 5.079215030670166 and perplexity is 160.64790274533797
At time: 406.08688855171204 and batch: 1150, loss is 5.098587884902954 and perplexity is 163.79045294691164
At time: 407.284366607666 and batch: 1200, loss is 5.072813844680786 and perplexity is 159.62284991810063
At time: 408.48163986206055 and batch: 1250, loss is 5.080560121536255 and perplexity is 160.86413416482893
At time: 409.6795485019684 and batch: 1300, loss is 5.050777835845947 and perplexity is 156.1438715633125
At time: 410.87715220451355 and batch: 1350, loss is 5.056153249740601 and perplexity is 156.98546944204264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1184004720052085 and perplexity of 167.06792596170746
Finished 12 epochs...
Completing Train Step...
At time: 414.345534324646 and batch: 50, loss is 5.172703905105591 and perplexity is 176.3911381570081
At time: 415.5171036720276 and batch: 100, loss is 5.185013313293457 and perplexity is 178.5758272063919
At time: 416.7209281921387 and batch: 150, loss is 5.151662864685059 and perplexity is 172.71845908168135
At time: 417.89205384254456 and batch: 200, loss is 5.147323169708252 and perplexity is 171.970537701528
At time: 419.0635576248169 and batch: 250, loss is 5.16163182258606 and perplexity is 174.4488931101107
At time: 420.24224185943604 and batch: 300, loss is 5.151310520172119 and perplexity is 172.65761340029104
At time: 421.43241238594055 and batch: 350, loss is 5.161165790557861 and perplexity is 174.36761327961088
At time: 422.6239950656891 and batch: 400, loss is 5.189744691848755 and perplexity is 179.4227389959613
At time: 423.81444239616394 and batch: 450, loss is 5.14843918800354 and perplexity is 172.1625671020845
At time: 425.0034019947052 and batch: 500, loss is 5.184749374389648 and perplexity is 178.52870031789558
At time: 426.19326090812683 and batch: 550, loss is 5.175835390090942 and perplexity is 176.94437012440366
At time: 427.3898515701294 and batch: 600, loss is 5.122510385513306 and perplexity is 167.75597362707788
At time: 428.5881040096283 and batch: 650, loss is 5.144254121780396 and perplexity is 171.44356095122976
At time: 429.78561520576477 and batch: 700, loss is 5.157003602981567 and perplexity is 173.6433708279304
At time: 430.9894003868103 and batch: 750, loss is 5.14109203338623 and perplexity is 170.90229746937737
At time: 432.18688225746155 and batch: 800, loss is 5.120759801864624 and perplexity is 167.4625596604554
At time: 433.38944268226624 and batch: 850, loss is 5.0840279006958005 and perplexity is 161.42294381103002
At time: 434.58702278137207 and batch: 900, loss is 5.116289606094361 and perplexity is 166.71563991710838
At time: 435.78375816345215 and batch: 950, loss is 5.1061405849456785 and perplexity is 165.0321964632818
At time: 436.9810390472412 and batch: 1000, loss is 5.117140188217163 and perplexity is 166.85750558566093
At time: 438.1788537502289 and batch: 1050, loss is 5.072492942810059 and perplexity is 159.57163486489387
At time: 439.3783977031708 and batch: 1100, loss is 5.077385091781617 and perplexity is 160.35419571565885
At time: 440.5769217014313 and batch: 1150, loss is 5.096827611923218 and perplexity is 163.50239064677376
At time: 441.7751896381378 and batch: 1200, loss is 5.071352291107178 and perplexity is 159.3897229766298
At time: 442.9729046821594 and batch: 1250, loss is 5.079003391265869 and perplexity is 160.61390691645465
At time: 444.17170667648315 and batch: 1300, loss is 5.049189414978027 and perplexity is 155.89604625687463
At time: 445.37013506889343 and batch: 1350, loss is 5.0532105445861815 and perplexity is 156.52418653461504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.118241373697916 and perplexity of 167.04134785180636
Finished 13 epochs...
Completing Train Step...
At time: 448.8132586479187 and batch: 50, loss is 5.166571369171143 and perplexity is 175.31272325256884
At time: 450.00141072273254 and batch: 100, loss is 5.178319091796875 and perplexity is 177.38439337538614
At time: 451.16457414627075 and batch: 150, loss is 5.14549488067627 and perplexity is 171.6564130964098
At time: 452.34407019615173 and batch: 200, loss is 5.140866022109986 and perplexity is 170.8636759876228
At time: 453.5237250328064 and batch: 250, loss is 5.1558476829528805 and perplexity is 173.44276893994794
At time: 454.7148423194885 and batch: 300, loss is 5.1458916664123535 and perplexity is 171.7245374271213
At time: 455.9111502170563 and batch: 350, loss is 5.155314283370972 and perplexity is 173.3502793086685
At time: 457.1085958480835 and batch: 400, loss is 5.183965215682983 and perplexity is 178.38876035789156
At time: 458.306738615036 and batch: 450, loss is 5.143111371994019 and perplexity is 171.2477557580565
At time: 459.50362968444824 and batch: 500, loss is 5.179214448928833 and perplexity is 177.543286879694
At time: 460.7008101940155 and batch: 550, loss is 5.170865058898926 and perplexity is 176.0670800195701
At time: 461.8979299068451 and batch: 600, loss is 5.117407932281494 and perplexity is 166.90218667365173
At time: 463.09439849853516 and batch: 650, loss is 5.139019479751587 and perplexity is 170.54846009171834
At time: 464.29106068611145 and batch: 700, loss is 5.151885490417481 and perplexity is 172.75691493560976
At time: 465.49415612220764 and batch: 750, loss is 5.136533451080322 and perplexity is 170.12499831724128
At time: 466.69065403938293 and batch: 800, loss is 5.116355991363525 and perplexity is 166.72670774710457
At time: 467.8876574039459 and batch: 850, loss is 5.080019311904907 and perplexity is 160.77716081186745
At time: 469.08473539352417 and batch: 900, loss is 5.112629117965699 and perplexity is 166.10649486062331
At time: 470.2815520763397 and batch: 950, loss is 5.102527351379394 and perplexity is 164.43697258053587
At time: 471.479487657547 and batch: 1000, loss is 5.113835601806641 and perplexity is 166.3070206037588
At time: 472.6763515472412 and batch: 1050, loss is 5.069659032821655 and perplexity is 159.12006337367995
At time: 473.8729090690613 and batch: 1100, loss is 5.074599895477295 and perplexity is 159.90819918462552
At time: 475.0693576335907 and batch: 1150, loss is 5.0939168357849125 and perplexity is 163.02716376459227
At time: 476.26662516593933 and batch: 1200, loss is 5.0689068698883055 and perplexity is 159.00042415978953
At time: 477.51108956336975 and batch: 1250, loss is 5.077095336914063 and perplexity is 160.30773903776685
At time: 478.7148766517639 and batch: 1300, loss is 5.046605587005615 and perplexity is 155.49375763787322
At time: 479.91214871406555 and batch: 1350, loss is 5.049793539047241 and perplexity is 155.99025526481302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11843505859375 and perplexity of 167.07370437124834
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 483.3419978618622 and batch: 50, loss is 5.164074697494507 and perplexity is 174.875570881919
At time: 484.53764820098877 and batch: 100, loss is 5.177529668807983 and perplexity is 177.24441731481429
At time: 485.7130582332611 and batch: 150, loss is 5.146997728347778 and perplexity is 171.9145804816678
At time: 486.8896346092224 and batch: 200, loss is 5.143095750808715 and perplexity is 171.24508068602498
At time: 488.0852653980255 and batch: 250, loss is 5.159068536758423 and perplexity is 174.00230334788284
At time: 489.2980794906616 and batch: 300, loss is 5.1517413711547855 and perplexity is 172.73201913042934
At time: 490.48746252059937 and batch: 350, loss is 5.154642667770386 and perplexity is 173.23389364430759
At time: 491.6740276813507 and batch: 400, loss is 5.182125778198242 and perplexity is 178.06092699215975
At time: 492.8651690483093 and batch: 450, loss is 5.137519903182984 and perplexity is 170.29290128004655
At time: 494.04983401298523 and batch: 500, loss is 5.172409658432007 and perplexity is 176.3392432866766
At time: 495.235063791275 and batch: 550, loss is 5.160528812408447 and perplexity is 174.25658028653575
At time: 496.4260334968567 and batch: 600, loss is 5.108049764633178 and perplexity is 165.34757354051297
At time: 497.6245048046112 and batch: 650, loss is 5.12911361694336 and perplexity is 168.8673705118125
At time: 498.82463455200195 and batch: 700, loss is 5.138836908340454 and perplexity is 170.51732566090777
At time: 500.0224449634552 and batch: 750, loss is 5.122456827163696 and perplexity is 167.74698913459272
At time: 501.2258222103119 and batch: 800, loss is 5.1018648433685305 and perplexity is 164.32806784803128
At time: 502.45538210868835 and batch: 850, loss is 5.058199920654297 and perplexity is 157.3070960558696
At time: 503.66384768486023 and batch: 900, loss is 5.08338475227356 and perplexity is 161.31915827773298
At time: 504.88524436950684 and batch: 950, loss is 5.074270343780517 and perplexity is 159.85550984866242
At time: 506.08932995796204 and batch: 1000, loss is 5.08591061592102 and perplexity is 161.72714351589482
At time: 507.35041761398315 and batch: 1050, loss is 5.038920183181762 and perplexity is 154.303305729702
At time: 508.545352935791 and batch: 1100, loss is 5.040115995407104 and perplexity is 154.48793387740133
At time: 509.7392451763153 and batch: 1150, loss is 5.056495056152344 and perplexity is 157.039137253527
At time: 510.9344701766968 and batch: 1200, loss is 5.027660655975342 and perplexity is 152.57566790535716
At time: 512.1288638114929 and batch: 1250, loss is 5.034270877838135 and perplexity is 153.58756767749364
At time: 513.3229212760925 and batch: 1300, loss is 5.008779220581054 and perplexity is 149.72184718860623
At time: 514.5195126533508 and batch: 1350, loss is 5.018474006652832 and perplexity is 151.18042735453506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.102777506510416 and perplexity of 164.47811247842037
Finished 15 epochs...
Completing Train Step...
At time: 518.1128175258636 and batch: 50, loss is 5.156223888397217 and perplexity is 173.50803132916727
At time: 519.2746436595917 and batch: 100, loss is 5.168344230651855 and perplexity is 175.623804096847
At time: 520.4561903476715 and batch: 150, loss is 5.137445688247681 and perplexity is 170.28026347235834
At time: 521.6383397579193 and batch: 200, loss is 5.134069452285766 and perplexity is 169.70632654166207
At time: 522.8318026065826 and batch: 250, loss is 5.15006908416748 and perplexity is 172.4434030142949
At time: 524.0248668193817 and batch: 300, loss is 5.142365636825562 and perplexity is 171.12009788946557
At time: 525.2183694839478 and batch: 350, loss is 5.146214141845703 and perplexity is 171.7799233015568
At time: 526.4114556312561 and batch: 400, loss is 5.174403734207154 and perplexity is 176.6912279253087
At time: 527.606329202652 and batch: 450, loss is 5.129997320175171 and perplexity is 169.01666510922465
At time: 528.8069417476654 and batch: 500, loss is 5.165864381790161 and perplexity is 175.1888231725611
At time: 530.0091485977173 and batch: 550, loss is 5.15504937171936 and perplexity is 173.30436288203623
At time: 531.2094986438751 and batch: 600, loss is 5.102287340164184 and perplexity is 164.3975105987699
At time: 532.4099607467651 and batch: 650, loss is 5.123743343353271 and perplexity is 167.96293723244375
At time: 533.6105706691742 and batch: 700, loss is 5.134278602600098 and perplexity is 169.74182438526546
At time: 534.8110945224762 and batch: 750, loss is 5.119069881439209 and perplexity is 167.1798002481389
At time: 536.0111207962036 and batch: 800, loss is 5.098514051437378 and perplexity is 163.77836017657336
At time: 537.2604756355286 and batch: 850, loss is 5.055669794082641 and perplexity is 156.90959227172502
At time: 538.461731672287 and batch: 900, loss is 5.082098026275634 and perplexity is 161.11171821069814
At time: 539.6633260250092 and batch: 950, loss is 5.072834062576294 and perplexity is 159.62607718882518
At time: 540.8677501678467 and batch: 1000, loss is 5.085855627059937 and perplexity is 161.71825056897538
At time: 542.0733799934387 and batch: 1050, loss is 5.039664993286133 and perplexity is 154.41827520084425
At time: 543.2769157886505 and batch: 1100, loss is 5.041738481521606 and perplexity is 154.73879185673843
At time: 544.4784874916077 and batch: 1150, loss is 5.059093427658081 and perplexity is 157.44771386008173
At time: 545.6797521114349 and batch: 1200, loss is 5.031409711837768 and perplexity is 153.1487562063591
At time: 546.8815529346466 and batch: 1250, loss is 5.038747100830078 and perplexity is 154.27660086181103
At time: 548.0838928222656 and batch: 1300, loss is 5.013434991836548 and perplexity is 150.42054308310813
At time: 549.2849018573761 and batch: 1350, loss is 5.0212406826019285 and perplexity is 151.59927374581804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.101084798177084 and perplexity of 164.19993451028077
Finished 16 epochs...
Completing Train Step...
At time: 552.7959060668945 and batch: 50, loss is 5.153346529006958 and perplexity is 173.0095039311325
At time: 553.9590187072754 and batch: 100, loss is 5.164386358261108 and perplexity is 174.93008123032718
At time: 555.1332540512085 and batch: 150, loss is 5.1331511402130126 and perplexity is 169.55055470770083
At time: 556.3098990917206 and batch: 200, loss is 5.129823131561279 and perplexity is 168.98722689457998
At time: 557.4914646148682 and batch: 250, loss is 5.145684080123901 and perplexity is 171.6888934674873
At time: 558.6668267250061 and batch: 300, loss is 5.137753248214722 and perplexity is 170.3326429190772
At time: 559.8474640846252 and batch: 350, loss is 5.14206467628479 and perplexity is 171.06860524128416
At time: 561.0426316261292 and batch: 400, loss is 5.170368976593018 and perplexity is 175.97975791778515
At time: 562.2427246570587 and batch: 450, loss is 5.126204223632812 and perplexity is 168.37678291586164
At time: 563.4437811374664 and batch: 500, loss is 5.162338428497314 and perplexity is 174.57220328991448
At time: 564.644923210144 and batch: 550, loss is 5.152067918777465 and perplexity is 172.78843357113652
At time: 565.8473691940308 and batch: 600, loss is 5.099422302246094 and perplexity is 163.927179577094
At time: 567.0472941398621 and batch: 650, loss is 5.121080446243286 and perplexity is 167.51626419841583
At time: 568.3171103000641 and batch: 700, loss is 5.13213885307312 and perplexity is 169.37900770367065
At time: 569.5178897380829 and batch: 750, loss is 5.117404623031616 and perplexity is 166.90163435352477
At time: 570.7185273170471 and batch: 800, loss is 5.097115001678467 and perplexity is 163.54938631151714
At time: 571.9190199375153 and batch: 850, loss is 5.054766588211059 and perplexity is 156.767934589333
At time: 573.1200103759766 and batch: 900, loss is 5.081637659072876 and perplexity is 161.03756472987882
At time: 574.3212244510651 and batch: 950, loss is 5.072552785873413 and perplexity is 159.5811844060827
At time: 575.5221030712128 and batch: 1000, loss is 5.086272354125977 and perplexity is 161.7856569851236
At time: 576.7231776714325 and batch: 1050, loss is 5.0406575012207036 and perplexity is 154.57161264595194
At time: 577.9278120994568 and batch: 1100, loss is 5.043072757720947 and perplexity is 154.94539394530133
At time: 579.1306254863739 and batch: 1150, loss is 5.060902967453003 and perplexity is 157.73287969558163
At time: 580.3384373188019 and batch: 1200, loss is 5.033899726867676 and perplexity is 153.53057407996852
At time: 581.5410981178284 and batch: 1250, loss is 5.0414768505096434 and perplexity is 154.69831268556922
At time: 582.7378947734833 and batch: 1300, loss is 5.0161243915557865 and perplexity is 150.82562852361764
At time: 583.9356544017792 and batch: 1350, loss is 5.022597827911377 and perplexity is 151.8051556633371
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.100333251953125 and perplexity of 164.0765770297559
Finished 17 epochs...
Completing Train Step...
At time: 587.4693248271942 and batch: 50, loss is 5.151193628311157 and perplexity is 172.63743231007697
At time: 588.6812279224396 and batch: 100, loss is 5.161565189361572 and perplexity is 174.4372694051213
At time: 589.8447353839874 and batch: 150, loss is 5.130029659271241 and perplexity is 169.02213104377617
At time: 591.021155834198 and batch: 200, loss is 5.126667547225952 and perplexity is 168.45481392733194
At time: 592.1949033737183 and batch: 250, loss is 5.142454509735107 and perplexity is 171.1353065062537
At time: 593.3917801380157 and batch: 300, loss is 5.134472789764405 and perplexity is 169.77478926938218
At time: 594.5883119106293 and batch: 350, loss is 5.139238929748535 and perplexity is 170.58589105772737
At time: 595.7853355407715 and batch: 400, loss is 5.167592439651489 and perplexity is 175.49182131942538
At time: 596.979293346405 and batch: 450, loss is 5.123610191345215 and perplexity is 167.94057411895193
At time: 598.2265312671661 and batch: 500, loss is 5.159864997863769 and perplexity is 174.14094461860103
At time: 599.4208014011383 and batch: 550, loss is 5.1500084018707275 and perplexity is 172.43293907003138
At time: 600.6212859153748 and batch: 600, loss is 5.097603006362915 and perplexity is 163.6292186558705
At time: 601.8220555782318 and batch: 650, loss is 5.119340715408325 and perplexity is 167.2250843489556
At time: 603.0294857025146 and batch: 700, loss is 5.130796976089478 and perplexity is 169.15187433832054
At time: 604.2346224784851 and batch: 750, loss is 5.116478462219238 and perplexity is 166.74712816009972
At time: 605.4356555938721 and batch: 800, loss is 5.096196823120117 and perplexity is 163.39928769098722
At time: 606.6368968486786 and batch: 850, loss is 5.054251956939697 and perplexity is 156.68727766391467
At time: 607.8376469612122 and batch: 900, loss is 5.081285972595214 and perplexity is 160.98093995363547
At time: 609.038896560669 and batch: 950, loss is 5.072382936477661 and perplexity is 159.55408194007177
At time: 610.2401943206787 and batch: 1000, loss is 5.086651935577392 and perplexity is 161.84707947630193
At time: 611.4408688545227 and batch: 1050, loss is 5.041389503479004 and perplexity is 154.6848008374297
At time: 612.6421911716461 and batch: 1100, loss is 5.044064483642578 and perplexity is 155.09913353007946
At time: 613.8416466712952 and batch: 1150, loss is 5.062205123901367 and perplexity is 157.93840636689538
At time: 615.0419461727142 and batch: 1200, loss is 5.035594043731689 and perplexity is 153.79092401613508
At time: 616.2419307231903 and batch: 1250, loss is 5.043296308517456 and perplexity is 154.98003598351656
At time: 617.4420123100281 and batch: 1300, loss is 5.017852067947388 and perplexity is 151.0864316280777
At time: 618.6408424377441 and batch: 1350, loss is 5.023357172012329 and perplexity is 151.92047178955323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099925537109375 and perplexity of 164.00969420927495
Finished 18 epochs...
Completing Train Step...
At time: 622.0996072292328 and batch: 50, loss is 5.1494138717651365 and perplexity is 172.3304529651149
At time: 623.2951560020447 and batch: 100, loss is 5.159311456680298 and perplexity is 174.04457710817954
At time: 624.4717319011688 and batch: 150, loss is 5.127547273635864 and perplexity is 168.60307328029307
At time: 625.65030169487 and batch: 200, loss is 5.124194898605347 and perplexity is 168.0387989054845
At time: 626.8355042934418 and batch: 250, loss is 5.139918098449707 and perplexity is 170.7017870077913
At time: 628.0728921890259 and batch: 300, loss is 5.1318956470489505 and perplexity is 169.33781871753706
At time: 629.2686326503754 and batch: 350, loss is 5.137102584838868 and perplexity is 170.2218497550532
At time: 630.4642426967621 and batch: 400, loss is 5.165521821975708 and perplexity is 175.12882079958842
At time: 631.6599035263062 and batch: 450, loss is 5.121606740951538 and perplexity is 167.6044503257202
At time: 632.8617703914642 and batch: 500, loss is 5.157959127426148 and perplexity is 173.80937060919004
At time: 634.0595982074738 and batch: 550, loss is 5.148435220718384 and perplexity is 172.16188408544255
At time: 635.2612164020538 and batch: 600, loss is 5.096245374679565 and perplexity is 163.4072211738073
At time: 636.4633545875549 and batch: 650, loss is 5.118000564575195 and perplexity is 167.00112761426635
At time: 637.6652977466583 and batch: 700, loss is 5.129840545654297 and perplexity is 168.99016967949075
At time: 638.8663375377655 and batch: 750, loss is 5.115801916122437 and perplexity is 166.63435419408503
At time: 640.067045211792 and batch: 800, loss is 5.095582828521729 and perplexity is 163.2989922045588
At time: 641.2678956985474 and batch: 850, loss is 5.053861055374146 and perplexity is 156.6260403314382
At time: 642.4688949584961 and batch: 900, loss is 5.080943021774292 and perplexity is 160.92574087395138
At time: 643.6700389385223 and batch: 950, loss is 5.072183074951172 and perplexity is 159.5221964041498
At time: 644.8698780536652 and batch: 1000, loss is 5.0869112300872805 and perplexity is 161.88905097670624
At time: 646.0709419250488 and batch: 1050, loss is 5.041882848739624 and perplexity is 154.7611326782405
At time: 647.2720642089844 and batch: 1100, loss is 5.044732723236084 and perplexity is 155.2028115490433
At time: 648.4724032878876 and batch: 1150, loss is 5.063023862838745 and perplexity is 158.06776964004337
At time: 649.6728706359863 and batch: 1200, loss is 5.036749200820923 and perplexity is 153.96867934016728
At time: 650.8738758563995 and batch: 1250, loss is 5.0445210647583005 and perplexity is 155.16996503444736
At time: 652.0748636722565 and batch: 1300, loss is 5.0189917850494385 and perplexity is 151.25872558262515
At time: 653.2764992713928 and batch: 1350, loss is 5.0237593078613285 and perplexity is 151.98157674287947
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099688313802083 and perplexity of 163.9707919016363
Finished 19 epochs...
Completing Train Step...
At time: 656.740626335144 and batch: 50, loss is 5.147799558639527 and perplexity is 172.0524820793419
At time: 657.9044494628906 and batch: 100, loss is 5.157343282699585 and perplexity is 173.70236397798985
At time: 659.1000151634216 and batch: 150, loss is 5.12548861503601 and perplexity is 168.25633414473336
At time: 660.2784225940704 and batch: 200, loss is 5.122100534439087 and perplexity is 167.6872327488039
At time: 661.4707202911377 and batch: 250, loss is 5.137726240158081 and perplexity is 170.32804262753217
At time: 662.6657412052155 and batch: 300, loss is 5.129719505310058 and perplexity is 168.96971628904757
At time: 663.8609201908112 and batch: 350, loss is 5.135365982055664 and perplexity is 169.92649854509946
At time: 665.0540838241577 and batch: 400, loss is 5.163723201751709 and perplexity is 174.81411366484244
At time: 666.252649307251 and batch: 450, loss is 5.119935569763183 and perplexity is 167.32458851093003
At time: 667.4539759159088 and batch: 500, loss is 5.15643871307373 and perplexity is 173.5453091398235
At time: 668.6543967723846 and batch: 550, loss is 5.14714937210083 and perplexity is 171.94065223061529
At time: 669.8551592826843 and batch: 600, loss is 5.0951243019104 and perplexity is 163.22413243493966
At time: 671.0570311546326 and batch: 650, loss is 5.116884098052979 and perplexity is 166.814780490632
At time: 672.2575216293335 and batch: 700, loss is 5.1290366649627686 and perplexity is 168.85437633316468
At time: 673.4583246707916 and batch: 750, loss is 5.11522068977356 and perplexity is 166.5375300578947
At time: 674.659006357193 and batch: 800, loss is 5.095047101974488 and perplexity is 163.21153202875786
At time: 675.85879778862 and batch: 850, loss is 5.053516988754272 and perplexity is 156.57215980893338
At time: 677.0587236881256 and batch: 900, loss is 5.080601673126221 and perplexity is 160.8708184642427
At time: 678.2588083744049 and batch: 950, loss is 5.071995477676392 and perplexity is 159.4922732816733
At time: 679.4592561721802 and batch: 1000, loss is 5.0870176029205325 and perplexity is 161.90627248966544
At time: 680.6600170135498 and batch: 1050, loss is 5.042221908569336 and perplexity is 154.81361485832917
At time: 681.8595764636993 and batch: 1100, loss is 5.045171175003052 and perplexity is 155.2708754162764
At time: 683.0588159561157 and batch: 1150, loss is 5.063527173995972 and perplexity is 158.1473469364919
At time: 684.2588675022125 and batch: 1200, loss is 5.037539644241333 and perplexity is 154.09043098225393
At time: 685.4590389728546 and batch: 1250, loss is 5.045339422225952 and perplexity is 155.297001507622
At time: 686.6586821079254 and batch: 1300, loss is 5.019812936782837 and perplexity is 151.3829829574262
At time: 687.8592112064362 and batch: 1350, loss is 5.023929510116577 and perplexity is 152.0074465514848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09954833984375 and perplexity of 163.9478418670838
Finished 20 epochs...
Completing Train Step...
At time: 691.3206903934479 and batch: 50, loss is 5.146334342956543 and perplexity is 171.80057268017188
At time: 692.488124370575 and batch: 100, loss is 5.155623302459717 and perplexity is 173.40385613171838
At time: 693.6652784347534 and batch: 150, loss is 5.123658094406128 and perplexity is 167.94861917919374
At time: 694.8446192741394 and batch: 200, loss is 5.120211133956909 and perplexity is 167.37070352978571
At time: 696.0383050441742 and batch: 250, loss is 5.135821828842163 and perplexity is 170.0039766511335
At time: 697.2365777492523 and batch: 300, loss is 5.127846174240112 and perplexity is 168.65347637315682
At time: 698.4308490753174 and batch: 350, loss is 5.133825883865357 and perplexity is 169.66499647332682
At time: 699.6247277259827 and batch: 400, loss is 5.162222480773925 and perplexity is 174.5519632137941
At time: 700.8186883926392 and batch: 450, loss is 5.118477144241333 and perplexity is 167.0807359242536
At time: 702.0127377510071 and batch: 500, loss is 5.155105323791504 and perplexity is 173.31405989153237
At time: 703.2062258720398 and batch: 550, loss is 5.146012620925903 and perplexity is 171.74530954122554
At time: 704.4005265235901 and batch: 600, loss is 5.094164419174194 and perplexity is 163.06753157933608
At time: 705.5978038311005 and batch: 650, loss is 5.115945653915405 and perplexity is 166.65830756985105
At time: 706.798145532608 and batch: 700, loss is 5.128351707458496 and perplexity is 168.73875786235592
At time: 707.9990274906158 and batch: 750, loss is 5.114677743911743 and perplexity is 166.44713373748732
At time: 709.2006154060364 and batch: 800, loss is 5.094593143463134 and perplexity is 163.13745757927794
At time: 710.4018778800964 and batch: 850, loss is 5.053175210952759 and perplexity is 156.51865606409262
At time: 711.6026923656464 and batch: 900, loss is 5.080214881896973 and perplexity is 160.80860707480426
At time: 712.8033337593079 and batch: 950, loss is 5.071679935455323 and perplexity is 159.4419546747586
At time: 714.0043938159943 and batch: 1000, loss is 5.087070713043213 and perplexity is 161.9148715800074
At time: 715.2038581371307 and batch: 1050, loss is 5.042435464859008 and perplexity is 154.84667980999765
At time: 716.4047515392303 and batch: 1100, loss is 5.045453157424927 and perplexity is 155.31466524746403
At time: 717.6049482822418 and batch: 1150, loss is 5.063894166946411 and perplexity is 158.205396549196
At time: 718.8327991962433 and batch: 1200, loss is 5.038093814849853 and perplexity is 154.17584703550565
At time: 720.0336961746216 and batch: 1250, loss is 5.045952949523926 and perplexity is 155.39230969143702
At time: 721.2350149154663 and batch: 1300, loss is 5.0203854274749755 and perplexity is 151.46967311840493
At time: 722.4370481967926 and batch: 1350, loss is 5.023969869613648 and perplexity is 152.0135816193819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099464925130208 and perplexity of 163.93416677517854
Finished 21 epochs...
Completing Train Step...
At time: 725.8754041194916 and batch: 50, loss is 5.145020532608032 and perplexity is 171.5750075172729
At time: 727.0785055160522 and batch: 100, loss is 5.154123554229736 and perplexity is 173.14398892181575
At time: 728.2546513080597 and batch: 150, loss is 5.121991615295411 and perplexity is 167.6689693936399
At time: 729.4383866786957 and batch: 200, loss is 5.118565196990967 and perplexity is 167.095448490194
At time: 730.6320278644562 and batch: 250, loss is 5.134127655029297 and perplexity is 169.71620420291197
At time: 731.8257758617401 and batch: 300, loss is 5.126195755004883 and perplexity is 168.37535700157292
At time: 733.020037651062 and batch: 350, loss is 5.132397775650024 and perplexity is 169.42286943096946
At time: 734.2143590450287 and batch: 400, loss is 5.160956506729126 and perplexity is 174.33112477625627
At time: 735.4082403182983 and batch: 450, loss is 5.117224340438843 and perplexity is 166.87154760628528
At time: 736.601998090744 and batch: 500, loss is 5.1539151477813725 and perplexity is 173.1079083578707
At time: 737.7948956489563 and batch: 550, loss is 5.145023946762085 and perplexity is 171.57559330178015
At time: 738.9886763095856 and batch: 600, loss is 5.093313045501709 and perplexity is 162.92875925804503
At time: 740.1826751232147 and batch: 650, loss is 5.1151589012146 and perplexity is 166.5272402617988
At time: 741.3759641647339 and batch: 700, loss is 5.1277095985412595 and perplexity is 168.63044397962565
At time: 742.5688796043396 and batch: 750, loss is 5.114214963912964 and perplexity is 166.37012315399278
At time: 743.76735496521 and batch: 800, loss is 5.094181156158447 and perplexity is 163.07026086088416
At time: 744.9685442447662 and batch: 850, loss is 5.05282509803772 and perplexity is 156.4638664529949
At time: 746.1699879169464 and batch: 900, loss is 5.07988712310791 and perplexity is 160.75590927703342
At time: 747.3696112632751 and batch: 950, loss is 5.071405668258667 and perplexity is 159.3982309730832
At time: 748.5699255466461 and batch: 1000, loss is 5.087067947387696 and perplexity is 161.91442377986877
At time: 749.8181881904602 and batch: 1050, loss is 5.042587938308716 and perplexity is 154.8702916174852
At time: 751.0206322669983 and batch: 1100, loss is 5.045604381561279 and perplexity is 155.33815434959385
At time: 752.2208001613617 and batch: 1150, loss is 5.0641624641418455 and perplexity is 158.24784830798203
At time: 753.4220583438873 and batch: 1200, loss is 5.0385348510742185 and perplexity is 154.24385916577464
At time: 754.62380027771 and batch: 1250, loss is 5.046397352218628 and perplexity is 155.4613817993786
At time: 755.824465751648 and batch: 1300, loss is 5.020834836959839 and perplexity is 151.53776032454567
At time: 757.0358612537384 and batch: 1350, loss is 5.023927440643311 and perplexity is 152.00713197646337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0993558756510415 and perplexity of 163.91629081437392
Finished 22 epochs...
Completing Train Step...
At time: 760.506210565567 and batch: 50, loss is 5.1438013935089115 and perplexity is 171.36596117135574
At time: 761.7007577419281 and batch: 100, loss is 5.152680463790894 and perplexity is 172.8943066872129
At time: 762.8761298656464 and batch: 150, loss is 5.12046820640564 and perplexity is 167.41373545731247
At time: 764.0565276145935 and batch: 200, loss is 5.117043838500977 and perplexity is 166.84142968682085
At time: 765.2450838088989 and batch: 250, loss is 5.13254672050476 and perplexity is 169.44810597502587
At time: 766.4389219284058 and batch: 300, loss is 5.124751625061035 and perplexity is 168.1323765965884
At time: 767.6324639320374 and batch: 350, loss is 5.131216516494751 and perplexity is 169.22285527287707
At time: 768.8244395256042 and batch: 400, loss is 5.159786500930786 and perplexity is 174.12727562503576
At time: 770.018009185791 and batch: 450, loss is 5.1160555267333985 and perplexity is 166.6766197937351
At time: 771.2120068073273 and batch: 500, loss is 5.152841539382934 and perplexity is 172.9221579830447
At time: 772.4119107723236 and batch: 550, loss is 5.144084367752075 and perplexity is 171.4144601861846
At time: 773.6129701137543 and batch: 600, loss is 5.09251877784729 and perplexity is 162.79940159369656
At time: 774.8140842914581 and batch: 650, loss is 5.114426517486573 and perplexity is 166.40532307129055
At time: 776.0147132873535 and batch: 700, loss is 5.127052869796753 and perplexity is 168.51973587644108
At time: 777.2165987491608 and batch: 750, loss is 5.113724927902222 and perplexity is 166.28861577494223
At time: 778.4166276454926 and batch: 800, loss is 5.093734169006348 and perplexity is 162.99738683747938
At time: 779.6445472240448 and batch: 850, loss is 5.05246054649353 and perplexity is 156.4068377044604
At time: 780.844633102417 and batch: 900, loss is 5.079467630386352 and perplexity is 160.68848748560842
At time: 782.0465121269226 and batch: 950, loss is 5.071078987121582 and perplexity is 159.34616708234816
At time: 783.2470571994781 and batch: 1000, loss is 5.08697738647461 and perplexity is 161.8997613257421
At time: 784.4489524364471 and batch: 1050, loss is 5.0425825023651125 and perplexity is 154.86944975360225
At time: 785.6502828598022 and batch: 1100, loss is 5.045648393630981 and perplexity is 155.34499125372244
At time: 786.8510630130768 and batch: 1150, loss is 5.064258012771607 and perplexity is 158.2629693954386
At time: 788.0511829853058 and batch: 1200, loss is 5.038761796951294 and perplexity is 154.27886814609818
At time: 789.251220703125 and batch: 1250, loss is 5.0466570472717285 and perplexity is 155.5017595939098
At time: 790.45139336586 and batch: 1300, loss is 5.021143779754639 and perplexity is 151.5845840562929
At time: 791.6523535251617 and batch: 1350, loss is 5.023753480911255 and perplexity is 151.98069115639984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099258626302083 and perplexity of 163.90035083689727
Finished 23 epochs...
Completing Train Step...
At time: 795.1222221851349 and batch: 50, loss is 5.1426089572906495 and perplexity is 171.1617399772505
At time: 796.2882709503174 and batch: 100, loss is 5.15133430480957 and perplexity is 172.66172004786623
At time: 797.4583551883698 and batch: 150, loss is 5.119037628173828 and perplexity is 167.1744082406305
At time: 798.6339573860168 and batch: 200, loss is 5.115662317276001 and perplexity is 166.6110938540591
At time: 799.8121907711029 and batch: 250, loss is 5.131087064743042 and perplexity is 169.20095049566925
At time: 801.0028343200684 and batch: 300, loss is 5.123381090164185 and perplexity is 167.9021031421198
At time: 802.1963140964508 and batch: 350, loss is 5.1301363086700436 and perplexity is 169.04015811370738
At time: 803.3959996700287 and batch: 400, loss is 5.158674907684326 and perplexity is 173.93382446085
At time: 804.5968954563141 and batch: 450, loss is 5.114962301254272 and perplexity is 166.4945042310265
At time: 805.7971966266632 and batch: 500, loss is 5.151829862594605 and perplexity is 172.74730511183438
At time: 807.0041790008545 and batch: 550, loss is 5.143188457489014 and perplexity is 171.26095698488095
At time: 808.2055556774139 and batch: 600, loss is 5.091787242889405 and perplexity is 162.6803516902001
At time: 809.4408891201019 and batch: 650, loss is 5.113672685623169 and perplexity is 166.27992870559171
At time: 810.6406378746033 and batch: 700, loss is 5.126435356140137 and perplexity is 168.41570476175087
At time: 811.8406774997711 and batch: 750, loss is 5.113193473815918 and perplexity is 166.200264489988
At time: 813.0403821468353 and batch: 800, loss is 5.0933543395996095 and perplexity is 162.93548739309577
At time: 814.2407021522522 and batch: 850, loss is 5.052137498855591 and perplexity is 156.3563190053949
At time: 815.4416923522949 and batch: 900, loss is 5.0790315437316895 and perplexity is 160.61842865762824
At time: 816.6433439254761 and batch: 950, loss is 5.070803718566895 and perplexity is 159.30231012973738
At time: 817.8434088230133 and batch: 1000, loss is 5.086790657043457 and perplexity is 161.86953269778104
At time: 819.0438795089722 and batch: 1050, loss is 5.042526836395264 and perplexity is 154.86082903542433
At time: 820.2453353404999 and batch: 1100, loss is 5.04562747001648 and perplexity is 155.34174090901533
At time: 821.4453401565552 and batch: 1150, loss is 5.064248371124267 and perplexity is 158.261443487057
At time: 822.6465044021606 and batch: 1200, loss is 5.038950071334839 and perplexity is 154.3079176394443
At time: 823.8469281196594 and batch: 1250, loss is 5.046841402053833 and perplexity is 155.53042972957368
At time: 825.0468301773071 and batch: 1300, loss is 5.021420249938965 and perplexity is 151.62649846796344
At time: 826.2473504543304 and batch: 1350, loss is 5.023539342880249 and perplexity is 151.9481497947406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099219970703125 and perplexity of 163.89401529311914
Finished 24 epochs...
Completing Train Step...
At time: 829.7178335189819 and batch: 50, loss is 5.14151291847229 and perplexity is 170.9742428368596
At time: 830.8930172920227 and batch: 100, loss is 5.150119895935059 and perplexity is 172.4521653910233
At time: 832.0679214000702 and batch: 150, loss is 5.117745151519776 and perplexity is 166.9584787927687
At time: 833.2444453239441 and batch: 200, loss is 5.114396448135376 and perplexity is 166.4003194464184
At time: 834.422337770462 and batch: 250, loss is 5.129719123840332 and perplexity is 168.96965183222846
At time: 835.6056649684906 and batch: 300, loss is 5.12210527420044 and perplexity is 167.68802754815252
At time: 836.7908270359039 and batch: 350, loss is 5.12918023109436 and perplexity is 168.878619843009
At time: 837.9852228164673 and batch: 400, loss is 5.157659482955933 and perplexity is 173.75729739453047
At time: 839.1787767410278 and batch: 450, loss is 5.113975124359131 and perplexity is 166.33022580255707
At time: 840.392566204071 and batch: 500, loss is 5.150902519226074 and perplexity is 172.58718329943272
At time: 841.5786397457123 and batch: 550, loss is 5.142352905273437 and perplexity is 171.1179192788883
At time: 842.77179646492 and batch: 600, loss is 5.091093492507935 and perplexity is 162.56753127328597
At time: 843.9700825214386 and batch: 650, loss is 5.112988147735596 and perplexity is 166.1661427442938
At time: 845.1704216003418 and batch: 700, loss is 5.1258668613433835 and perplexity is 168.31998851957295
At time: 846.3783309459686 and batch: 750, loss is 5.112695846557617 and perplexity is 166.11757928295376
At time: 847.5792896747589 and batch: 800, loss is 5.092953042984009 and perplexity is 162.87011505117076
At time: 848.7811012268066 and batch: 850, loss is 5.0517672920227055 and perplexity is 156.29844554097127
At time: 849.9820103645325 and batch: 900, loss is 5.0785801887512205 and perplexity is 160.54594908813633
At time: 851.1823861598969 and batch: 950, loss is 5.07043643951416 and perplexity is 159.24381247131436
At time: 852.3835065364838 and batch: 1000, loss is 5.086610097885131 and perplexity is 161.84030830964346
At time: 853.5839085578918 and batch: 1050, loss is 5.042429943084716 and perplexity is 154.8458247839425
At time: 854.7854204177856 and batch: 1100, loss is 5.0455830287933345 and perplexity is 155.33483748544327
At time: 855.9867613315582 and batch: 1150, loss is 5.064198684692383 and perplexity is 158.2535802359753
At time: 857.1886239051819 and batch: 1200, loss is 5.039057054519653 and perplexity is 154.32442687500497
At time: 858.3897016048431 and batch: 1250, loss is 5.046998538970947 and perplexity is 155.554871222099
At time: 859.590886592865 and batch: 1300, loss is 5.021594762802124 and perplexity is 151.652961551349
At time: 860.7917385101318 and batch: 1350, loss is 5.023293437957764 and perplexity is 151.9107895904609
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0991813151041665 and perplexity of 163.8876799942405
Finished 25 epochs...
Completing Train Step...
At time: 864.2613496780396 and batch: 50, loss is 5.140476684570313 and perplexity is 170.79716529278963
At time: 865.4603064060211 and batch: 100, loss is 5.148915691375732 and perplexity is 172.24462269420457
At time: 866.6366539001465 and batch: 150, loss is 5.116530294418335 and perplexity is 166.75577125443877
At time: 867.8302984237671 and batch: 200, loss is 5.1131214427947995 and perplexity is 166.18829334637866
At time: 869.0247094631195 and batch: 250, loss is 5.12844313621521 and perplexity is 168.75418614248025
At time: 870.245992898941 and batch: 300, loss is 5.120911512374878 and perplexity is 167.48796741809312
At time: 871.4403955936432 and batch: 350, loss is 5.128260202407837 and perplexity is 168.72331812018766
At time: 872.634654045105 and batch: 400, loss is 5.156639766693115 and perplexity is 173.5802045601611
At time: 873.8281881809235 and batch: 450, loss is 5.113052148818969 and perplexity is 166.17677789777647
At time: 875.0223126411438 and batch: 500, loss is 5.150025291442871 and perplexity is 172.43585141318977
At time: 876.2146122455597 and batch: 550, loss is 5.141524820327759 and perplexity is 170.97627775969644
At time: 877.4088230133057 and batch: 600, loss is 5.0904436206817625 and perplexity is 162.46191753627414
At time: 878.6024014949799 and batch: 650, loss is 5.1123115348815915 and perplexity is 166.05375062347733
At time: 879.7962324619293 and batch: 700, loss is 5.125299758911133 and perplexity is 168.22456090586056
At time: 880.9923167228699 and batch: 750, loss is 5.112193078994751 and perplexity is 166.03408174415426
At time: 882.1930181980133 and batch: 800, loss is 5.092554693222046 and perplexity is 162.80524870021472
At time: 883.3940198421478 and batch: 850, loss is 5.051348123550415 and perplexity is 156.2329438894052
At time: 884.5950982570648 and batch: 900, loss is 5.078144798278808 and perplexity is 160.47606412624626
At time: 885.795928478241 and batch: 950, loss is 5.070051574707032 and perplexity is 159.18253692429832
At time: 886.9960885047913 and batch: 1000, loss is 5.086470346450806 and perplexity is 161.81769247476004
At time: 888.1976816654205 and batch: 1050, loss is 5.042314739227295 and perplexity is 154.82798697513368
At time: 889.3991825580597 and batch: 1100, loss is 5.045425090789795 and perplexity is 155.31030614859688
At time: 890.6001362800598 and batch: 1150, loss is 5.064093809127808 and perplexity is 158.236984172678
At time: 891.8006157875061 and batch: 1200, loss is 5.039095039367676 and perplexity is 154.33028897624078
At time: 893.0008924007416 and batch: 1250, loss is 5.04709150314331 and perplexity is 155.56933292415883
At time: 894.2010226249695 and batch: 1300, loss is 5.021682643890381 and perplexity is 151.6662895642791
At time: 895.4019236564636 and batch: 1350, loss is 5.023006210327148 and perplexity is 151.86716288000014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099138590494792 and perplexity of 163.8806781067089
Finished 26 epochs...
Completing Train Step...
At time: 898.8415613174438 and batch: 50, loss is 5.139437780380249 and perplexity is 170.61981554276664
At time: 900.0444660186768 and batch: 100, loss is 5.14776533126831 and perplexity is 172.04659327594877
At time: 901.2209930419922 and batch: 150, loss is 5.115415649414063 and perplexity is 166.57000132007494
At time: 902.4066259860992 and batch: 200, loss is 5.111939153671265 and perplexity is 165.99192683856316
At time: 903.5949018001556 and batch: 250, loss is 5.12722806930542 and perplexity is 168.54926303786388
At time: 904.7797365188599 and batch: 300, loss is 5.119768705368042 and perplexity is 167.29667032401636
At time: 905.9726462364197 and batch: 350, loss is 5.127379989624023 and perplexity is 168.5748710407437
At time: 907.1668376922607 and batch: 400, loss is 5.1556846714019775 and perplexity is 173.41449806949194
At time: 908.3599059581757 and batch: 450, loss is 5.112141008377075 and perplexity is 166.02543647204695
At time: 909.5531542301178 and batch: 500, loss is 5.14916314125061 and perplexity is 172.2872498783668
At time: 910.7474656105042 and batch: 550, loss is 5.140695238113404 and perplexity is 170.83449769783033
At time: 911.9411981105804 and batch: 600, loss is 5.089779233932495 and perplexity is 162.35401583920037
At time: 913.1370024681091 and batch: 650, loss is 5.111661500930786 and perplexity is 165.94584512283257
At time: 914.3365156650543 and batch: 700, loss is 5.12478458404541 and perplexity is 168.1379181602833
At time: 915.5370597839355 and batch: 750, loss is 5.111756629943848 and perplexity is 165.96163213819045
At time: 916.737934589386 and batch: 800, loss is 5.0921057605743405 and perplexity is 162.73217651232807
At time: 917.9390363693237 and batch: 850, loss is 5.05097864151001 and perplexity is 156.17522928542988
At time: 919.1389410495758 and batch: 900, loss is 5.077569875717163 and perplexity is 160.38382933284848
At time: 920.3397867679596 and batch: 950, loss is 5.069611396789551 and perplexity is 159.1124837057667
At time: 921.5400598049164 and batch: 1000, loss is 5.08622576713562 and perplexity is 161.7781200538446
At time: 922.7408218383789 and batch: 1050, loss is 5.042039947509766 and perplexity is 154.78544737170424
At time: 923.9410085678101 and batch: 1100, loss is 5.045131902694703 and perplexity is 155.26477769031604
At time: 925.1410129070282 and batch: 1150, loss is 5.06399206161499 and perplexity is 158.2208847721535
At time: 926.3420536518097 and batch: 1200, loss is 5.039087285995484 and perplexity is 154.32909240070856
At time: 927.5426781177521 and batch: 1250, loss is 5.0471217155456545 and perplexity is 155.5740331184393
At time: 928.7431485652924 and batch: 1300, loss is 5.021733989715576 and perplexity is 151.67407719500054
At time: 929.9439861774445 and batch: 1350, loss is 5.022619218826294 and perplexity is 151.80840294923692
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099110921223958 and perplexity of 163.87614371057398
Finished 27 epochs...
Completing Train Step...
At time: 933.4269211292267 and batch: 50, loss is 5.1384070682525635 and perplexity is 170.44404622900583
At time: 934.591463804245 and batch: 100, loss is 5.146614751815796 and perplexity is 171.84875383767218
At time: 935.771461725235 and batch: 150, loss is 5.114344453811645 and perplexity is 166.3916677992604
At time: 936.9550940990448 and batch: 200, loss is 5.110763769149781 and perplexity is 165.79693711346687
At time: 938.1390686035156 and batch: 250, loss is 5.126048879623413 and perplexity is 168.35062862282274
At time: 939.3284933567047 and batch: 300, loss is 5.118643760681152 and perplexity is 167.1085766409318
At time: 940.5214877128601 and batch: 350, loss is 5.126470861434936 and perplexity is 168.42168451715312
At time: 941.7141628265381 and batch: 400, loss is 5.154779214859008 and perplexity is 173.25754984319127
At time: 942.9083344936371 and batch: 450, loss is 5.111260290145874 and perplexity is 165.879279214431
At time: 944.1017272472382 and batch: 500, loss is 5.148287925720215 and perplexity is 172.136527368546
At time: 945.2953994274139 and batch: 550, loss is 5.139959354400634 and perplexity is 170.70882961761313
At time: 946.4894497394562 and batch: 600, loss is 5.089145994186401 and perplexity is 162.25123936794074
At time: 947.6922452449799 and batch: 650, loss is 5.111035633087158 and perplexity is 165.84201744917675
At time: 948.8930339813232 and batch: 700, loss is 5.124299945831299 and perplexity is 168.0564518423417
At time: 950.0935916900635 and batch: 750, loss is 5.111276884078979 and perplexity is 165.88203182693206
At time: 951.2953946590424 and batch: 800, loss is 5.09176230430603 and perplexity is 162.67629472327383
At time: 952.4956655502319 and batch: 850, loss is 5.050633583068848 and perplexity is 156.1213490007226
At time: 953.6960170269012 and batch: 900, loss is 5.077076263427735 and perplexity is 160.30468143945765
At time: 954.8961956501007 and batch: 950, loss is 5.069229011535644 and perplexity is 159.0516530693956
At time: 956.0968334674835 and batch: 1000, loss is 5.086038341522217 and perplexity is 161.7478015317809
At time: 957.2973580360413 and batch: 1050, loss is 5.04189715385437 and perplexity is 154.76334656983664
At time: 958.4981317520142 and batch: 1100, loss is 5.044912157058715 and perplexity is 155.23066268144552
At time: 959.6985890865326 and batch: 1150, loss is 5.063853588104248 and perplexity is 158.1989768876322
At time: 960.9451506137848 and batch: 1200, loss is 5.039040307998658 and perplexity is 154.32184249938987
At time: 962.1496467590332 and batch: 1250, loss is 5.047099523544311 and perplexity is 155.57058065759603
At time: 963.3527057170868 and batch: 1300, loss is 5.021802568435669 and perplexity is 151.6844791657587
At time: 964.5536563396454 and batch: 1350, loss is 5.022350187301636 and perplexity is 151.76756719643433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099107666015625 and perplexity of 163.8756102604536
Finished 28 epochs...
Completing Train Step...
At time: 968.0152361392975 and batch: 50, loss is 5.1374596118927 and perplexity is 170.2826344108067
At time: 969.1832914352417 and batch: 100, loss is 5.14554352760315 and perplexity is 171.6647638565039
At time: 970.3587763309479 and batch: 150, loss is 5.113275165557861 and perplexity is 166.21384223369287
At time: 971.5368006229401 and batch: 200, loss is 5.1097015762329105 and perplexity is 165.6209222786307
At time: 972.727680683136 and batch: 250, loss is 5.124981832504273 and perplexity is 168.17108637659896
At time: 973.9197690486908 and batch: 300, loss is 5.117563133239746 and perplexity is 166.92809206317648
At time: 975.1132690906525 and batch: 350, loss is 5.1255919456481935 and perplexity is 168.27372107302975
At time: 976.3089027404785 and batch: 400, loss is 5.153920392990113 and perplexity is 173.10881634736594
At time: 977.5089852809906 and batch: 450, loss is 5.110390567779541 and perplexity is 165.73507301395603
At time: 978.7098844051361 and batch: 500, loss is 5.147489042282104 and perplexity is 171.99906526314794
At time: 979.9099314212799 and batch: 550, loss is 5.1392316722869875 and perplexity is 170.58465304167493
At time: 981.1106536388397 and batch: 600, loss is 5.088488311767578 and perplexity is 162.1445646632602
At time: 982.3112335205078 and batch: 650, loss is 5.110379819869995 and perplexity is 165.7332917179552
At time: 983.5105259418488 and batch: 700, loss is 5.12377818107605 and perplexity is 167.96878878061483
At time: 984.7108845710754 and batch: 750, loss is 5.110794010162354 and perplexity is 165.80195105653968
At time: 985.9110221862793 and batch: 800, loss is 5.091309566497802 and perplexity is 162.6026616836384
At time: 987.1107420921326 and batch: 850, loss is 5.050226202011109 and perplexity is 156.05776107356894
At time: 988.3107874393463 and batch: 900, loss is 5.076603727340698 and perplexity is 160.22894958698245
At time: 989.5113496780396 and batch: 950, loss is 5.068850030899048 and perplexity is 158.9913869932229
At time: 990.7600610256195 and batch: 1000, loss is 5.08578161239624 and perplexity is 161.70628148999506
At time: 991.9656205177307 and batch: 1050, loss is 5.041738662719727 and perplexity is 154.73881989511924
At time: 993.1664040088654 and batch: 1100, loss is 5.044662027359009 and perplexity is 155.19183973799178
At time: 994.3668830394745 and batch: 1150, loss is 5.063605079650879 and perplexity is 158.15966798906035
At time: 995.5680069923401 and batch: 1200, loss is 5.039004640579224 and perplexity is 154.31633833566585
At time: 996.7685632705688 and batch: 1250, loss is 5.047067899703979 and perplexity is 155.56566099618263
At time: 997.96999335289 and batch: 1300, loss is 5.021808052062989 and perplexity is 151.68531094919317
At time: 999.1701955795288 and batch: 1350, loss is 5.0220414161682125 and perplexity is 151.72071298668016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099071451822916 and perplexity of 163.8696757449809
Finished 29 epochs...
Completing Train Step...
At time: 1002.5869889259338 and batch: 50, loss is 5.136506433486939 and perplexity is 170.12040201130316
At time: 1003.776201248169 and batch: 100, loss is 5.144490823745728 and perplexity is 171.48414678223395
At time: 1004.9484281539917 and batch: 150, loss is 5.112237405776978 and perplexity is 166.04144166385757
At time: 1006.1247820854187 and batch: 200, loss is 5.108641862869263 and perplexity is 165.4455045366711
At time: 1007.3084087371826 and batch: 250, loss is 5.123905963897705 and perplexity is 167.99025367778864
At time: 1008.4916014671326 and batch: 300, loss is 5.1165283584594725 and perplexity is 166.75544842243804
At time: 1009.6835012435913 and batch: 350, loss is 5.124716663360596 and perplexity is 168.12649850555837
At time: 1010.8776607513428 and batch: 400, loss is 5.1530787467956545 and perplexity is 172.96318126606292
At time: 1012.0783939361572 and batch: 450, loss is 5.1095643234252925 and perplexity is 165.59819190198735
At time: 1013.2795178890228 and batch: 500, loss is 5.146749382019043 and perplexity is 171.87189142780338
At time: 1014.4810597896576 and batch: 550, loss is 5.138531618118286 and perplexity is 170.46527633415275
At time: 1015.6818110942841 and batch: 600, loss is 5.087870407104492 and perplexity is 162.04440572818405
At time: 1016.881885766983 and batch: 650, loss is 5.109732179641724 and perplexity is 165.6259909209817
At time: 1018.0819666385651 and batch: 700, loss is 5.123273134231567 and perplexity is 167.88397809235764
At time: 1019.2819333076477 and batch: 750, loss is 5.110300340652466 and perplexity is 165.7201198890612
At time: 1020.5294244289398 and batch: 800, loss is 5.090949583053589 and perplexity is 162.54413795186647
At time: 1021.7276387214661 and batch: 850, loss is 5.04981164932251 and perplexity is 155.99308031685626
At time: 1022.9214153289795 and batch: 900, loss is 5.076064519882202 and perplexity is 160.1425762309697
At time: 1024.1145813465118 and batch: 950, loss is 5.0684036445617675 and perplexity is 158.9204312483396
At time: 1025.308734178543 and batch: 1000, loss is 5.085446548461914 and perplexity is 161.65210862330753
At time: 1026.5025007724762 and batch: 1050, loss is 5.041471633911133 and perplexity is 154.6975056886866
At time: 1027.6960322856903 and batch: 1100, loss is 5.0443402194976805 and perplexity is 155.14190581894485
At time: 1028.889814376831 and batch: 1150, loss is 5.063435144424439 and perplexity is 158.1327933736036
At time: 1030.0825390815735 and batch: 1200, loss is 5.038937873840332 and perplexity is 154.30603548094535
At time: 1031.2764747142792 and batch: 1250, loss is 5.047007598876953 and perplexity is 155.55628054099517
At time: 1032.4698853492737 and batch: 1300, loss is 5.021786251068115 and perplexity is 151.6820040945533
At time: 1033.6631932258606 and batch: 1350, loss is 5.021714811325073 and perplexity is 151.67116835821236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09904541015625 and perplexity of 163.86540836107352
Finished 30 epochs...
Completing Train Step...
At time: 1037.0944640636444 and batch: 50, loss is 5.135592517852783 and perplexity is 169.96499734041205
At time: 1038.2955610752106 and batch: 100, loss is 5.143496208190918 and perplexity is 171.31367077553872
At time: 1039.4702858924866 and batch: 150, loss is 5.111229257583618 and perplexity is 165.87413163524351
At time: 1040.6449036598206 and batch: 200, loss is 5.107659282684327 and perplexity is 165.28302090189922
At time: 1041.8359863758087 and batch: 250, loss is 5.122875776290893 and perplexity is 167.8172813126758
At time: 1043.0356793403625 and batch: 300, loss is 5.115482168197632 and perplexity is 166.58108172246526
At time: 1044.2286942005157 and batch: 350, loss is 5.123872117996216 and perplexity is 167.98456799243058
At time: 1045.425766468048 and batch: 400, loss is 5.152298574447632 and perplexity is 172.82829279978068
At time: 1046.6258461475372 and batch: 450, loss is 5.1087627124786374 and perplexity is 165.46549976945087
At time: 1047.824889421463 and batch: 500, loss is 5.14600606918335 and perplexity is 171.7441843138587
At time: 1049.0235714912415 and batch: 550, loss is 5.137863683700561 and perplexity is 170.3514547259787
At time: 1050.2236602306366 and batch: 600, loss is 5.087258319854737 and perplexity is 161.94525076238452
At time: 1051.449870109558 and batch: 650, loss is 5.109075107574463 and perplexity is 165.5171984548946
At time: 1052.6495966911316 and batch: 700, loss is 5.122787628173828 and perplexity is 167.80248918727565
At time: 1053.8499369621277 and batch: 750, loss is 5.10982349395752 and perplexity is 165.64111563556165
At time: 1055.0528931617737 and batch: 800, loss is 5.090559129714966 and perplexity is 162.48068443915366
At time: 1056.2526414394379 and batch: 850, loss is 5.049394178390503 and perplexity is 155.9279713317297
At time: 1057.4523737430573 and batch: 900, loss is 5.075609750747681 and perplexity is 160.06976488760787
At time: 1058.6519041061401 and batch: 950, loss is 5.0679761505126955 and perplexity is 158.85250822908267
At time: 1059.8515677452087 and batch: 1000, loss is 5.085165729522705 and perplexity is 161.60672002293063
At time: 1061.050038576126 and batch: 1050, loss is 5.041244821548462 and perplexity is 154.66242236073867
At time: 1062.2495503425598 and batch: 1100, loss is 5.044085083007812 and perplexity is 155.10232850668567
At time: 1063.4520180225372 and batch: 1150, loss is 5.063220596313476 and perplexity is 158.09886992074053
At time: 1064.6547901630402 and batch: 1200, loss is 5.038826284408569 and perplexity is 154.28881751881755
At time: 1065.8566401004791 and batch: 1250, loss is 5.046931772232056 and perplexity is 155.54448567733718
At time: 1067.0569994449615 and batch: 1300, loss is 5.021741704940796 and perplexity is 151.67524739918025
At time: 1068.2572405338287 and batch: 1350, loss is 5.021342163085937 and perplexity is 151.6146588941261
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099039306640625 and perplexity of 163.8644082090455
Finished 31 epochs...
Completing Train Step...
At time: 1071.7341878414154 and batch: 50, loss is 5.134690637588501 and perplexity is 169.81177836666185
At time: 1072.9101860523224 and batch: 100, loss is 5.14256609916687 and perplexity is 171.1544044634065
At time: 1074.086349248886 and batch: 150, loss is 5.110203876495361 and perplexity is 165.70413460839652
At time: 1075.2626988887787 and batch: 200, loss is 5.106674871444702 and perplexity is 165.12039449716764
At time: 1076.439801454544 and batch: 250, loss is 5.121866531372071 and perplexity is 167.64799801274444
At time: 1077.6178741455078 and batch: 300, loss is 5.114491357803344 and perplexity is 166.41611319496474
At time: 1078.793380022049 and batch: 350, loss is 5.123130264282227 and perplexity is 167.8599942302399
At time: 1079.968966960907 and batch: 400, loss is 5.151498146057129 and perplexity is 172.69001147707286
At time: 1081.1796460151672 and batch: 450, loss is 5.107945079803467 and perplexity is 165.33026506391693
At time: 1082.3691687583923 and batch: 500, loss is 5.14529932975769 and perplexity is 171.62284880901927
At time: 1083.5620102882385 and batch: 550, loss is 5.137214555740356 and perplexity is 170.2409107161399
At time: 1084.761305809021 and batch: 600, loss is 5.086652097702026 and perplexity is 161.84710571570255
At time: 1085.961385011673 and batch: 650, loss is 5.108518705368042 and perplexity is 165.4251299364124
At time: 1087.1619386672974 and batch: 700, loss is 5.122246036529541 and perplexity is 167.7116333668386
At time: 1088.3619232177734 and batch: 750, loss is 5.109351024627686 and perplexity is 165.5628737735599
At time: 1089.5618300437927 and batch: 800, loss is 5.090177516937256 and perplexity is 162.4186915632298
At time: 1090.7621879577637 and batch: 850, loss is 5.048998870849609 and perplexity is 155.86634401050102
At time: 1091.960904598236 and batch: 900, loss is 5.075132942199707 and perplexity is 159.99346044818734
At time: 1093.1618576049805 and batch: 950, loss is 5.067612504959106 and perplexity is 158.79475272269164
At time: 1094.362015247345 and batch: 1000, loss is 5.084891920089722 and perplexity is 161.56247663595957
At time: 1095.5625920295715 and batch: 1050, loss is 5.041004314422607 and perplexity is 154.62522941882202
At time: 1096.763151884079 and batch: 1100, loss is 5.043805961608887 and perplexity is 155.05904216912884
At time: 1097.9630165100098 and batch: 1150, loss is 5.0630114650726314 and perplexity is 158.06580996495313
At time: 1099.1626660823822 and batch: 1200, loss is 5.0387091541290285 and perplexity is 154.2707466848332
At time: 1100.362981081009 and batch: 1250, loss is 5.046841802597046 and perplexity is 155.5304920262443
At time: 1101.5628213882446 and batch: 1300, loss is 5.021694011688233 and perplexity is 151.66801368579948
At time: 1102.762779712677 and batch: 1350, loss is 5.020970544815063 and perplexity is 151.55832658445476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0990283203125 and perplexity of 163.86260795077797
Finished 32 epochs...
Completing Train Step...
At time: 1106.2178630828857 and batch: 50, loss is 5.133826522827149 and perplexity is 169.66510488281165
At time: 1107.3937327861786 and batch: 100, loss is 5.141653566360474 and perplexity is 170.99829169421932
At time: 1108.5697078704834 and batch: 150, loss is 5.109246616363525 and perplexity is 165.54558854367588
At time: 1109.744289636612 and batch: 200, loss is 5.105765943527222 and perplexity is 164.9703801473069
At time: 1110.946212053299 and batch: 250, loss is 5.1209120941162105 and perplexity is 167.4880648527948
At time: 1112.1280570030212 and batch: 300, loss is 5.113564071655273 and perplexity is 166.26186936351968
At time: 1113.312239408493 and batch: 350, loss is 5.122412748336792 and perplexity is 167.739595207054
At time: 1114.4965133666992 and batch: 400, loss is 5.1507439708709715 and perplexity is 172.55982205450633
At time: 1115.6865210533142 and batch: 450, loss is 5.107160625457763 and perplexity is 165.20062187524078
At time: 1116.8800163269043 and batch: 500, loss is 5.1445849418640135 and perplexity is 171.50028730699088
At time: 1118.0736389160156 and batch: 550, loss is 5.136588916778565 and perplexity is 170.13443468075624
At time: 1119.266794204712 and batch: 600, loss is 5.086088485717774 and perplexity is 161.7559124485278
At time: 1120.4598801136017 and batch: 650, loss is 5.107852869033813 and perplexity is 165.31502053579396
At time: 1121.6539409160614 and batch: 700, loss is 5.121703090667725 and perplexity is 167.6205997449242
At time: 1122.8473472595215 and batch: 750, loss is 5.108872137069702 and perplexity is 165.48360675475513
At time: 1124.0406079292297 and batch: 800, loss is 5.089758110046387 and perplexity is 162.35058632768306
At time: 1125.2367486953735 and batch: 850, loss is 5.048567295074463 and perplexity is 155.7990903858269
At time: 1126.4369904994965 and batch: 900, loss is 5.074657306671143 and perplexity is 159.91737996878413
At time: 1127.637615442276 and batch: 950, loss is 5.0672253894805905 and perplexity is 158.73329271283373
At time: 1128.838357925415 and batch: 1000, loss is 5.084628620147705 and perplexity is 161.51994284504735
At time: 1130.040640115738 and batch: 1050, loss is 5.0407563495635985 and perplexity is 154.5868925489047
At time: 1131.2414770126343 and batch: 1100, loss is 5.043527116775513 and perplexity is 155.0158107840564
At time: 1132.44300532341 and batch: 1150, loss is 5.062778768539428 and perplexity is 158.0290328780726
At time: 1133.643349647522 and batch: 1200, loss is 5.038609371185303 and perplexity is 154.25535386358155
At time: 1134.843009710312 and batch: 1250, loss is 5.046757154464721 and perplexity is 155.5173272177708
At time: 1136.0439765453339 and batch: 1300, loss is 5.021592416763306 and perplexity is 151.65260576803163
At time: 1137.2448275089264 and batch: 1350, loss is 5.020588703155518 and perplexity is 151.50046634894102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09904296875 and perplexity of 163.8650082995298
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 1140.6742367744446 and batch: 50, loss is 5.133716077804565 and perplexity is 169.64636725122935
At time: 1141.8613488674164 and batch: 100, loss is 5.141810607910156 and perplexity is 171.0251476396345
At time: 1143.0298347473145 and batch: 150, loss is 5.109823207855225 and perplexity is 165.64106824526513
At time: 1144.219938993454 and batch: 200, loss is 5.106640424728393 and perplexity is 165.11470673974446
At time: 1145.4198961257935 and batch: 250, loss is 5.1209850025177 and perplexity is 167.5002765850353
At time: 1146.6207447052002 and batch: 300, loss is 5.113819408416748 and perplexity is 166.30432755113708
At time: 1147.820764541626 and batch: 350, loss is 5.12226411819458 and perplexity is 167.71466589983285
At time: 1149.0217950344086 and batch: 400, loss is 5.150907049179077 and perplexity is 172.58796511303277
At time: 1150.222018480301 and batch: 450, loss is 5.106260118484497 and perplexity is 165.051924524803
At time: 1151.4220139980316 and batch: 500, loss is 5.143292570114136 and perplexity is 171.2787883409121
At time: 1152.6217522621155 and batch: 550, loss is 5.133851490020752 and perplexity is 169.6693409972147
At time: 1153.8226199150085 and batch: 600, loss is 5.083013992309571 and perplexity is 161.25935867875282
At time: 1155.0234682559967 and batch: 650, loss is 5.105003747940064 and perplexity is 164.84468835849523
At time: 1156.2241563796997 and batch: 700, loss is 5.118234977722168 and perplexity is 167.04027946281326
At time: 1157.4237222671509 and batch: 750, loss is 5.105408067703247 and perplexity is 164.91135179961964
At time: 1158.6233983039856 and batch: 800, loss is 5.086477355957031 and perplexity is 161.8188267408581
At time: 1159.8239405155182 and batch: 850, loss is 5.04372130393982 and perplexity is 155.04591578768333
At time: 1161.0243360996246 and batch: 900, loss is 5.068218431472778 and perplexity is 158.8909998299907
At time: 1162.2251389026642 and batch: 950, loss is 5.060434770584107 and perplexity is 157.65904694066728
At time: 1163.4256978034973 and batch: 1000, loss is 5.078319902420044 and perplexity is 160.50416661000278
At time: 1164.625813484192 and batch: 1050, loss is 5.0336794090270995 and perplexity is 153.49675228133435
At time: 1165.826907157898 and batch: 1100, loss is 5.036120882034302 and perplexity is 153.87196831224614
At time: 1167.0278737545013 and batch: 1150, loss is 5.055280323028565 and perplexity is 156.8484924265111
At time: 1168.2280101776123 and batch: 1200, loss is 5.030644311904907 and perplexity is 153.03158100730616
At time: 1169.428185224533 and batch: 1250, loss is 5.03822850227356 and perplexity is 154.19661398163248
At time: 1170.628261566162 and batch: 1300, loss is 5.013321514129639 and perplexity is 150.4034746732673
At time: 1171.8291010856628 and batch: 1350, loss is 5.014264678955078 and perplexity is 150.54539685768842
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096609700520833 and perplexity of 163.46676549323922
Finished 34 epochs...
Completing Train Step...
At time: 1175.2422318458557 and batch: 50, loss is 5.132567443847656 and perplexity is 169.45161754261463
At time: 1176.4328799247742 and batch: 100, loss is 5.140712242126465 and perplexity is 170.83740259455794
At time: 1177.6019110679626 and batch: 150, loss is 5.108737564086914 and perplexity is 165.4613386305691
At time: 1178.7781805992126 and batch: 200, loss is 5.105635108947754 and perplexity is 164.9487977288899
At time: 1179.9525134563446 and batch: 250, loss is 5.120083169937134 and perplexity is 167.3492874720411
At time: 1181.1292128562927 and batch: 300, loss is 5.113078832626343 and perplexity is 166.18121218606942
At time: 1182.3114857673645 and batch: 350, loss is 5.121405944824219 and perplexity is 167.5707993797762
At time: 1183.4993076324463 and batch: 400, loss is 5.150058574676514 and perplexity is 172.44159073143177
At time: 1184.6968486309052 and batch: 450, loss is 5.105627880096436 and perplexity is 164.94760534286576
At time: 1185.8973829746246 and batch: 500, loss is 5.142603616714478 and perplexity is 171.16082587738143
At time: 1187.0978915691376 and batch: 550, loss is 5.133391170501709 and perplexity is 169.5912568609754
At time: 1188.301022052765 and batch: 600, loss is 5.082700586318969 and perplexity is 161.20882694858943
At time: 1189.5017726421356 and batch: 650, loss is 5.10456802368164 and perplexity is 164.77287717497867
At time: 1190.7019543647766 and batch: 700, loss is 5.1178686237335205 and perplexity is 166.97909479847445
At time: 1191.9028210639954 and batch: 750, loss is 5.105088119506836 and perplexity is 164.85859714987112
At time: 1193.1033132076263 and batch: 800, loss is 5.086149263381958 and perplexity is 161.7657438938175
At time: 1194.3038492202759 and batch: 850, loss is 5.043523874282837 and perplexity is 155.01530814724018
At time: 1195.5048174858093 and batch: 900, loss is 5.068181295394897 and perplexity is 158.88509935100737
At time: 1196.7064445018768 and batch: 950, loss is 5.060323362350464 and perplexity is 157.6414834031093
At time: 1197.907717704773 and batch: 1000, loss is 5.0782701587677 and perplexity is 160.49618274511414
At time: 1199.109049797058 and batch: 1050, loss is 5.033690137863159 and perplexity is 153.49839913165965
At time: 1200.310814857483 and batch: 1100, loss is 5.0362693977355955 and perplexity is 153.8948224125838
At time: 1201.5606067180634 and batch: 1150, loss is 5.055589580535889 and perplexity is 156.89700650159082
At time: 1202.7650091648102 and batch: 1200, loss is 5.031025342941284 and perplexity is 153.0899018995452
At time: 1203.9649682044983 and batch: 1250, loss is 5.038670539855957 and perplexity is 154.2647897471059
At time: 1205.166075706482 and batch: 1300, loss is 5.0136738300323485 and perplexity is 150.45647354484194
At time: 1206.367202281952 and batch: 1350, loss is 5.014550361633301 and perplexity is 150.58841121379257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096437174479167 and perplexity of 163.4385656519181
Finished 35 epochs...
Completing Train Step...
At time: 1209.8315968513489 and batch: 50, loss is 5.132125797271729 and perplexity is 169.37679633942184
At time: 1210.9976634979248 and batch: 100, loss is 5.1401817417144775 and perplexity is 170.746797317292
At time: 1212.166853427887 and batch: 150, loss is 5.10816385269165 and perplexity is 165.36643880028114
At time: 1213.3456978797913 and batch: 200, loss is 5.105089645385743 and perplexity is 164.85884870431903
At time: 1214.5295207500458 and batch: 250, loss is 5.119590873718262 and perplexity is 167.26692232627607
At time: 1215.7140476703644 and batch: 300, loss is 5.112648525238037 and perplexity is 166.10971856588785
At time: 1216.8977432250977 and batch: 350, loss is 5.120949649810791 and perplexity is 167.49435510152094
At time: 1218.082362651825 and batch: 400, loss is 5.149648704528809 and perplexity is 172.3709265537259
At time: 1219.2724277973175 and batch: 450, loss is 5.105302381515503 and perplexity is 164.89392386849417
At time: 1220.4661657810211 and batch: 500, loss is 5.142239503860473 and perplexity is 171.09851536529501
At time: 1221.6590511798859 and batch: 550, loss is 5.133112916946411 and perplexity is 169.54407405550242
At time: 1222.8515841960907 and batch: 600, loss is 5.0825277519226075 and perplexity is 161.18096692595003
At time: 1224.0449421405792 and batch: 650, loss is 5.10431303024292 and perplexity is 164.73086652886712
At time: 1225.240795135498 and batch: 700, loss is 5.117672481536865 and perplexity is 166.94634636380513
At time: 1226.4416906833649 and batch: 750, loss is 5.104917583465576 and perplexity is 164.83048521446273
At time: 1227.6420314311981 and batch: 800, loss is 5.0859987163543705 and perplexity is 161.7413923749792
At time: 1228.8421773910522 and batch: 850, loss is 5.043436183929443 and perplexity is 155.00171539607257
At time: 1230.043060541153 and batch: 900, loss is 5.068203945159912 and perplexity is 158.88869810192728
At time: 1231.2714631557465 and batch: 950, loss is 5.0603040504455565 and perplexity is 157.63843907516838
At time: 1232.4720594882965 and batch: 1000, loss is 5.078279209136963 and perplexity is 160.49763530140635
At time: 1233.6719148159027 and batch: 1050, loss is 5.033737545013428 and perplexity is 153.50567622582503
At time: 1234.8719053268433 and batch: 1100, loss is 5.03642463684082 and perplexity is 153.91871476157934
At time: 1236.0716173648834 and batch: 1150, loss is 5.055802755355835 and perplexity is 156.93045655793
At time: 1237.272873878479 and batch: 1200, loss is 5.031327362060547 and perplexity is 153.1361449596776
At time: 1238.4729480743408 and batch: 1250, loss is 5.038971319198608 and perplexity is 154.31119638788985
At time: 1239.673893213272 and batch: 1300, loss is 5.013876819610596 and perplexity is 150.48701774092328
At time: 1240.874567747116 and batch: 1350, loss is 5.014685821533203 and perplexity is 150.60881128656675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09635986328125 and perplexity of 163.425930509047
Finished 36 epochs...
Completing Train Step...
At time: 1244.336725950241 and batch: 50, loss is 5.131793870925903 and perplexity is 169.3205850478656
At time: 1245.5073182582855 and batch: 100, loss is 5.139750757217407 and perplexity is 170.67322395035296
At time: 1246.6834919452667 and batch: 150, loss is 5.10771222114563 and perplexity is 165.2917709623107
At time: 1247.866482257843 and batch: 200, loss is 5.104670314788819 and perplexity is 164.78973283709536
At time: 1249.0604536533356 and batch: 250, loss is 5.119199552536011 and perplexity is 167.20148004179106
At time: 1250.2547998428345 and batch: 300, loss is 5.112303676605225 and perplexity is 166.05244573234035
At time: 1251.4481451511383 and batch: 350, loss is 5.120602369308472 and perplexity is 167.4361976767999
At time: 1252.6414957046509 and batch: 400, loss is 5.1493645191192625 and perplexity is 172.32194821116417
At time: 1253.8417086601257 and batch: 450, loss is 5.105060291290283 and perplexity is 164.85400949296255
At time: 1255.0417907238007 and batch: 500, loss is 5.141969327926636 and perplexity is 171.0522949082367
At time: 1256.2413806915283 and batch: 550, loss is 5.132833871841431 and perplexity is 169.4967702118188
At time: 1257.4433362483978 and batch: 600, loss is 5.082387933731079 and perplexity is 161.15843247004577
At time: 1258.6437652111053 and batch: 650, loss is 5.104118432998657 and perplexity is 164.69881347501476
At time: 1259.8437616825104 and batch: 700, loss is 5.117524404525756 and perplexity is 166.92162727802935
At time: 1261.044322013855 and batch: 750, loss is 5.104799995422363 and perplexity is 164.81110425975115
At time: 1262.2806289196014 and batch: 800, loss is 5.085906715393066 and perplexity is 161.7265126958809
At time: 1263.4812104701996 and batch: 850, loss is 5.043381023406982 and perplexity is 154.99316565627524
At time: 1264.6829013824463 and batch: 900, loss is 5.068234529495239 and perplexity is 158.8935576814629
At time: 1265.8828265666962 and batch: 950, loss is 5.060301370620728 and perplexity is 157.63801663233141
At time: 1267.0829629898071 and batch: 1000, loss is 5.078295907974243 and perplexity is 160.5003154476797
At time: 1268.2827081680298 and batch: 1050, loss is 5.033773288726807 and perplexity is 153.51116318677975
At time: 1269.483187198639 and batch: 1100, loss is 5.036551418304444 and perplexity is 153.93823003857742
At time: 1270.6825954914093 and batch: 1150, loss is 5.055953388214111 and perplexity is 156.95409722163762
At time: 1271.8830037117004 and batch: 1200, loss is 5.0315695476531985 and perplexity is 153.17323681907672
At time: 1273.082325220108 and batch: 1250, loss is 5.039191427230835 and perplexity is 154.34516525995107
At time: 1274.2820417881012 and batch: 1300, loss is 5.01400634765625 and perplexity is 150.5065112926811
At time: 1275.481917142868 and batch: 1350, loss is 5.014758834838867 and perplexity is 150.61980813519412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096310628255209 and perplexity of 163.41788442717876
Finished 37 epochs...
Completing Train Step...
At time: 1278.8991961479187 and batch: 50, loss is 5.131506681442261 and perplexity is 169.27196493840194
At time: 1280.0896136760712 and batch: 100, loss is 5.13936827659607 and perplexity is 170.6079572320339
At time: 1281.2620944976807 and batch: 150, loss is 5.107329778671264 and perplexity is 165.2285684548636
At time: 1282.4435937404633 and batch: 200, loss is 5.104314117431641 and perplexity is 164.7310456225046
At time: 1283.626059770584 and batch: 250, loss is 5.118861961364746 and perplexity is 167.14504382502676
At time: 1284.8082058429718 and batch: 300, loss is 5.1120035934448245 and perplexity is 166.00262366538826
At time: 1285.9898908138275 and batch: 350, loss is 5.120314025878907 and perplexity is 167.38792550914408
At time: 1287.1718263626099 and batch: 400, loss is 5.149139776229858 and perplexity is 172.2832244302256
At time: 1288.3617677688599 and batch: 450, loss is 5.104857501983642 and perplexity is 164.8205822521385
At time: 1289.5541687011719 and batch: 500, loss is 5.141745662689209 and perplexity is 171.01404073430754
At time: 1290.7468070983887 and batch: 550, loss is 5.1326539516448975 and perplexity is 169.46627706285946
At time: 1291.9684236049652 and batch: 600, loss is 5.082279539108276 and perplexity is 161.14096470926944
At time: 1293.162395477295 and batch: 650, loss is 5.103952665328979 and perplexity is 164.67151399925402
At time: 1294.5886542797089 and batch: 700, loss is 5.117395868301392 and perplexity is 166.9001731811381
At time: 1295.7631793022156 and batch: 750, loss is 5.104698877334595 and perplexity is 164.79443971860294
At time: 1296.9394793510437 and batch: 800, loss is 5.08584358215332 and perplexity is 161.71630269948
At time: 1298.114957332611 and batch: 850, loss is 5.043338871002197 and perplexity is 154.98663245931348
At time: 1299.2980744838715 and batch: 900, loss is 5.068262147903442 and perplexity is 158.89794612920048
At time: 1300.4814171791077 and batch: 950, loss is 5.060298452377319 and perplexity is 157.63755660689966
At time: 1301.6655759811401 and batch: 1000, loss is 5.0783051490783695 and perplexity is 160.5017986546603
At time: 1302.8491678237915 and batch: 1050, loss is 5.0338037109375 and perplexity is 153.51583340676876
At time: 1304.032906293869 and batch: 1100, loss is 5.036656103134155 and perplexity is 153.9543458795024
At time: 1305.2173442840576 and batch: 1150, loss is 5.0560964012145995 and perplexity is 156.97654530316572
At time: 1306.4120314121246 and batch: 1200, loss is 5.031763191223145 and perplexity is 153.2029007034921
At time: 1307.6078624725342 and batch: 1250, loss is 5.039362707138062 and perplexity is 154.37160374966402
At time: 1308.8142025470734 and batch: 1300, loss is 5.0140966796875 and perplexity is 150.52010746563832
At time: 1310.022987127304 and batch: 1350, loss is 5.014798021316528 and perplexity is 150.6257105105868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096279296875 and perplexity of 163.41276439951807
Finished 38 epochs...
Completing Train Step...
At time: 1313.5267925262451 and batch: 50, loss is 5.131243448257447 and perplexity is 169.22741280402883
At time: 1314.6917164325714 and batch: 100, loss is 5.139023218154907 and perplexity is 170.54909767183958
At time: 1315.860872745514 and batch: 150, loss is 5.106992473602295 and perplexity is 165.1728454195447
At time: 1317.0361757278442 and batch: 200, loss is 5.1039975643157955 and perplexity is 164.67890774937484
At time: 1318.2167835235596 and batch: 250, loss is 5.118558654785156 and perplexity is 167.0943553209558
At time: 1319.3995051383972 and batch: 300, loss is 5.111735525131226 and perplexity is 165.95812958600223
At time: 1320.5883350372314 and batch: 350, loss is 5.120065240859986 and perplexity is 167.34628708065253
At time: 1321.8087086677551 and batch: 400, loss is 5.148947515487671 and perplexity is 172.25010431358137
At time: 1323.0032308101654 and batch: 450, loss is 5.104681873321534 and perplexity is 164.7916375756214
At time: 1324.197316646576 and batch: 500, loss is 5.1415498828887936 and perplexity is 170.98056291679154
At time: 1325.3912539482117 and batch: 550, loss is 5.132523736953735 and perplexity is 169.44421150059068
At time: 1326.5844585895538 and batch: 600, loss is 5.0821849060058595 and perplexity is 161.12571616137268
At time: 1327.7778098583221 and batch: 650, loss is 5.103803958892822 and perplexity is 164.64702810592073
At time: 1328.971394777298 and batch: 700, loss is 5.117277393341064 and perplexity is 166.88040086102734
At time: 1330.1644442081451 and batch: 750, loss is 5.104602737426758 and perplexity is 164.77859715791965
At time: 1331.3577225208282 and batch: 800, loss is 5.085793323516846 and perplexity is 161.70817526284938
At time: 1332.5513668060303 and batch: 850, loss is 5.043305883407593 and perplexity is 154.98151990743867
At time: 1333.7450120449066 and batch: 900, loss is 5.068279790878296 and perplexity is 158.90074958639892
At time: 1334.9380447864532 and batch: 950, loss is 5.06029257774353 and perplexity is 157.6366305467033
At time: 1336.130897283554 and batch: 1000, loss is 5.0783103084564205 and perplexity is 160.5026267462536
At time: 1337.3245732784271 and batch: 1050, loss is 5.0338230800628665 and perplexity is 153.5188069029887
At time: 1338.5179421901703 and batch: 1100, loss is 5.03673939704895 and perplexity is 153.9671698737433
At time: 1339.7117257118225 and batch: 1150, loss is 5.056220235824585 and perplexity is 156.99598563609845
At time: 1340.9057447910309 and batch: 1200, loss is 5.031916618347168 and perplexity is 153.22640798722043
At time: 1342.0996370315552 and batch: 1250, loss is 5.039500379562378 and perplexity is 154.39285792562129
At time: 1343.2933402061462 and batch: 1300, loss is 5.014160165786743 and perplexity is 150.52966370345982
At time: 1344.4868125915527 and batch: 1350, loss is 5.0148166847229 and perplexity is 150.62852172566554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0962548828125 and perplexity of 163.40877487877506
Finished 39 epochs...
Completing Train Step...
At time: 1347.9248490333557 and batch: 50, loss is 5.13099250793457 and perplexity is 169.1849521501881
At time: 1349.0978031158447 and batch: 100, loss is 5.138704423904419 and perplexity is 170.49473626558805
At time: 1350.2778697013855 and batch: 150, loss is 5.106683778762817 and perplexity is 165.12186528359908
At time: 1351.4685761928558 and batch: 200, loss is 5.103710298538208 and perplexity is 164.63160792902303
At time: 1352.6613647937775 and batch: 250, loss is 5.118279504776001 and perplexity is 167.04771743992347
At time: 1353.8460319042206 and batch: 300, loss is 5.111490898132324 and perplexity is 165.9175367120771
At time: 1355.039938211441 and batch: 350, loss is 5.119843053817749 and perplexity is 167.30910903448978
At time: 1356.2389423847198 and batch: 400, loss is 5.1487751388549805 and perplexity is 172.22041497956644
At time: 1357.440009355545 and batch: 450, loss is 5.104525127410889 and perplexity is 164.76580918462318
At time: 1358.6403186321259 and batch: 500, loss is 5.141373109817505 and perplexity is 170.95034082885846
At time: 1359.8412516117096 and batch: 550, loss is 5.13241135597229 and perplexity is 169.42517026375853
At time: 1361.0415697097778 and batch: 600, loss is 5.082097215652466 and perplexity is 161.11158760985955
At time: 1362.242068529129 and batch: 650, loss is 5.1036668872833255 and perplexity is 164.62446121945447
At time: 1363.4432446956635 and batch: 700, loss is 5.11716474533081 and perplexity is 166.8616031747008
At time: 1364.6446161270142 and batch: 750, loss is 5.1045130443573 and perplexity is 164.76381832254907
At time: 1365.8448247909546 and batch: 800, loss is 5.0857442855834964 and perplexity is 161.70024562255693
At time: 1367.0458858013153 and batch: 850, loss is 5.043274078369141 and perplexity is 154.97659079262448
At time: 1368.2464249134064 and batch: 900, loss is 5.0682874584198 and perplexity is 158.90196796916237
At time: 1369.4468131065369 and batch: 950, loss is 5.0602795600891115 and perplexity is 157.6345785008796
At time: 1370.6478369235992 and batch: 1000, loss is 5.0783090400695805 and perplexity is 160.50242316696318
At time: 1371.8490555286407 and batch: 1050, loss is 5.033829975128174 and perplexity is 153.51986542883748
At time: 1373.0497207641602 and batch: 1100, loss is 5.036804122924805 and perplexity is 153.9771358561912
At time: 1374.2503290176392 and batch: 1150, loss is 5.056323347091674 and perplexity is 157.0121745257194
At time: 1375.4979498386383 and batch: 1200, loss is 5.032041311264038 and perplexity is 153.24551542623027
At time: 1376.6987702846527 and batch: 1250, loss is 5.03961519241333 and perplexity is 154.41058522744788
At time: 1377.899775981903 and batch: 1300, loss is 5.014204988479614 and perplexity is 150.53641099955883
At time: 1379.1007814407349 and batch: 1350, loss is 5.014821424484253 and perplexity is 150.62923567060332
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096234944661458 and perplexity of 163.40551684241976
Finished 40 epochs...
Completing Train Step...
At time: 1382.5721518993378 and batch: 50, loss is 5.130751981735229 and perplexity is 169.14426363018546
At time: 1383.7291269302368 and batch: 100, loss is 5.138406248092651 and perplexity is 170.44390643768915
At time: 1384.8920049667358 and batch: 150, loss is 5.1063979053497315 and perplexity is 165.0746680789298
At time: 1386.0609357357025 and batch: 200, loss is 5.103446855545044 and perplexity is 164.58824259785789
At time: 1387.2438797950745 and batch: 250, loss is 5.1180188083648686 and perplexity is 167.00417437550595
At time: 1388.4269797801971 and batch: 300, loss is 5.111261758804321 and perplexity is 165.87952283461456
At time: 1389.6099646091461 and batch: 350, loss is 5.119639759063721 and perplexity is 167.2750994274264
At time: 1390.7936797142029 and batch: 400, loss is 5.148613815307617 and perplexity is 172.1926340122159
At time: 1391.9775698184967 and batch: 450, loss is 5.104380264282226 and perplexity is 164.74194242275672
At time: 1393.1648631095886 and batch: 500, loss is 5.141207065582275 and perplexity is 170.92195786673207
At time: 1394.3576757907867 and batch: 550, loss is 5.132304716110229 and perplexity is 169.40710375029434
At time: 1395.5510561466217 and batch: 600, loss is 5.082014245986938 and perplexity is 161.09822078985096
At time: 1396.7446563243866 and batch: 650, loss is 5.103536214828491 and perplexity is 164.60295074242515
At time: 1397.9380469322205 and batch: 700, loss is 5.117055416107178 and perplexity is 166.8433613223736
At time: 1399.1314475536346 and batch: 750, loss is 5.104423761367798 and perplexity is 164.74910837297136
At time: 1400.3243346214294 and batch: 800, loss is 5.085688734054566 and perplexity is 161.69126317618077
At time: 1401.5184803009033 and batch: 850, loss is 5.0432396984100345 and perplexity is 154.97126279535928
At time: 1402.7113609313965 and batch: 900, loss is 5.068280296325684 and perplexity is 158.900829902388
At time: 1403.904197692871 and batch: 950, loss is 5.060249586105346 and perplexity is 157.62985363539465
At time: 1405.1260290145874 and batch: 1000, loss is 5.078292808532715 and perplexity is 160.4998179871076
At time: 1406.3257901668549 and batch: 1050, loss is 5.033815078735351 and perplexity is 153.51757855364914
At time: 1407.5266375541687 and batch: 1100, loss is 5.03684853553772 and perplexity is 153.98397453498447
At time: 1408.7273411750793 and batch: 1150, loss is 5.056404438018799 and perplexity is 157.02490730477092
At time: 1409.9280223846436 and batch: 1200, loss is 5.0321418571472165 and perplexity is 153.26092440656373
At time: 1411.1279854774475 and batch: 1250, loss is 5.039708242416382 and perplexity is 154.4249538013621
At time: 1412.328034877777 and batch: 1300, loss is 5.014238529205322 and perplexity is 150.54146018470541
At time: 1413.5280151367188 and batch: 1350, loss is 5.014818935394287 and perplexity is 150.62886074135096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096204427083333 and perplexity of 163.40053017788432
Finished 41 epochs...
Completing Train Step...
At time: 1416.992747783661 and batch: 50, loss is 5.130512371063232 and perplexity is 169.10373971468778
At time: 1418.1961085796356 and batch: 100, loss is 5.138119373321533 and perplexity is 170.3950173938933
At time: 1419.3793399333954 and batch: 150, loss is 5.106130790710449 and perplexity is 165.03058010704478
At time: 1420.563815355301 and batch: 200, loss is 5.103195466995239 and perplexity is 164.5468721984766
At time: 1421.7468605041504 and batch: 250, loss is 5.1177645015716555 and perplexity is 166.961709479252
At time: 1422.9353477954865 and batch: 300, loss is 5.111030054092407 and perplexity is 165.8410922200129
At time: 1424.127115726471 and batch: 350, loss is 5.119433107376099 and perplexity is 167.2405353173215
At time: 1425.3200798034668 and batch: 400, loss is 5.148437376022339 and perplexity is 172.16225514703206
At time: 1426.5135827064514 and batch: 450, loss is 5.104247198104859 and perplexity is 164.72002230067218
At time: 1427.7083699703217 and batch: 500, loss is 5.141018104553223 and perplexity is 170.88966332898656
At time: 1428.908971786499 and batch: 550, loss is 5.132167825698852 and perplexity is 169.38391512935792
At time: 1430.1088845729828 and batch: 600, loss is 5.081888780593872 and perplexity is 161.07800980617333
At time: 1431.3078486919403 and batch: 650, loss is 5.103405132293701 and perplexity is 164.58137558450198
At time: 1432.5086801052094 and batch: 700, loss is 5.116925735473632 and perplexity is 166.8217263724218
At time: 1433.7090327739716 and batch: 750, loss is 5.104311923980713 and perplexity is 164.73068429343607
At time: 1434.9368305206299 and batch: 800, loss is 5.0855796432495115 and perplexity is 161.67362510820365
At time: 1436.1368145942688 and batch: 850, loss is 5.0432110691070555 and perplexity is 154.96682613963316
At time: 1437.3370139598846 and batch: 900, loss is 5.068215084075928 and perplexity is 158.8904679596485
At time: 1438.5370254516602 and batch: 950, loss is 5.060151863098144 and perplexity is 157.61445032471377
At time: 1439.737099647522 and batch: 1000, loss is 5.0782217502594 and perplexity is 160.48841355236857
At time: 1440.9373273849487 and batch: 1050, loss is 5.033749141693115 and perplexity is 153.50745639230445
At time: 1442.1385533809662 and batch: 1100, loss is 5.036858415603637 and perplexity is 153.98549591431876
At time: 1443.3389735221863 and batch: 1150, loss is 5.056448383331299 and perplexity is 157.03180796501746
At time: 1444.538889169693 and batch: 1200, loss is 5.032208251953125 and perplexity is 153.2711004737083
At time: 1445.7386634349823 and batch: 1250, loss is 5.039778242111206 and perplexity is 154.43576387934803
At time: 1446.9389536380768 and batch: 1300, loss is 5.014285907745362 and perplexity is 150.54859278826925
At time: 1448.1386168003082 and batch: 1350, loss is 5.014815492630005 and perplexity is 150.62834216258193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096156819661458 and perplexity of 163.39275128507754
Finished 42 epochs...
Completing Train Step...
At time: 1451.5611271858215 and batch: 50, loss is 5.130248794555664 and perplexity is 169.05917381507714
At time: 1452.7591760158539 and batch: 100, loss is 5.137860536575317 and perplexity is 170.3509186094588
At time: 1453.9329316616058 and batch: 150, loss is 5.105882959365845 and perplexity is 164.9896854241774
At time: 1455.1154856681824 and batch: 200, loss is 5.102931003570557 and perplexity is 164.50336132290542
At time: 1456.2983572483063 and batch: 250, loss is 5.117529392242432 and perplexity is 166.92245983788948
At time: 1457.4809176921844 and batch: 300, loss is 5.110802421569824 and perplexity is 165.80334569017475
At time: 1458.6638915538788 and batch: 350, loss is 5.119219036102295 and perplexity is 167.20473775464603
At time: 1459.8521513938904 and batch: 400, loss is 5.148279142379761 and perplexity is 172.13501544146146
At time: 1461.044896364212 and batch: 450, loss is 5.10413462638855 and perplexity is 164.70148052871053
At time: 1462.2370507717133 and batch: 500, loss is 5.140857973098755 and perplexity is 170.86230070951066
At time: 1463.4307100772858 and batch: 550, loss is 5.132046718597412 and perplexity is 169.36340277648682
At time: 1464.6238808631897 and batch: 600, loss is 5.081795482635498 and perplexity is 161.06298225775015
At time: 1465.8568584918976 and batch: 650, loss is 5.103295211791992 and perplexity is 164.563285711368
At time: 1467.0548694133759 and batch: 700, loss is 5.116816158294678 and perplexity is 166.80344751974843
At time: 1468.255005121231 and batch: 750, loss is 5.1042178440093995 and perplexity is 164.71518716437942
At time: 1469.4549279212952 and batch: 800, loss is 5.085505495071411 and perplexity is 161.66163774788092
At time: 1470.6551403999329 and batch: 850, loss is 5.043179759979248 and perplexity is 154.9619743394208
At time: 1471.8550362586975 and batch: 900, loss is 5.068188076019287 and perplexity is 158.88617669483978
At time: 1473.0556354522705 and batch: 950, loss is 5.060112104415894 and perplexity is 157.6081839064383
At time: 1474.255763053894 and batch: 1000, loss is 5.078198413848877 and perplexity is 160.48466837256552
At time: 1475.4558289051056 and batch: 1050, loss is 5.033717975616455 and perplexity is 153.50267224170267
At time: 1476.6557772159576 and batch: 1100, loss is 5.036891937255859 and perplexity is 153.99065784907785
At time: 1477.856253862381 and batch: 1150, loss is 5.0565118312835695 and perplexity is 157.04177162775787
At time: 1479.055775642395 and batch: 1200, loss is 5.032286043167114 and perplexity is 153.28302408245364
At time: 1480.255860567093 and batch: 1250, loss is 5.039852027893066 and perplexity is 154.44715946334395
At time: 1481.4541275501251 and batch: 1300, loss is 5.014290170669556 and perplexity is 150.54923456687575
At time: 1482.6532564163208 and batch: 1350, loss is 5.01479718208313 and perplexity is 150.62558410051292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096137288411458 and perplexity of 163.38956005156842
Finished 43 epochs...
Completing Train Step...
At time: 1486.1253798007965 and batch: 50, loss is 5.130035343170166 and perplexity is 169.02309175121553
At time: 1487.2876813411713 and batch: 100, loss is 5.1376142501831055 and perplexity is 170.3089686623671
At time: 1488.4617602825165 and batch: 150, loss is 5.105639753341674 and perplexity is 164.9495638178622
At time: 1489.6366567611694 and batch: 200, loss is 5.102694234848022 and perplexity is 164.46441668281062
At time: 1490.818763256073 and batch: 250, loss is 5.1173101425170895 and perplexity is 166.8858661461416
At time: 1492.0023591518402 and batch: 300, loss is 5.110601444244384 and perplexity is 165.77002632553956
At time: 1493.1919391155243 and batch: 350, loss is 5.11904932975769 and perplexity is 167.1763644574335
At time: 1494.3889482021332 and batch: 400, loss is 5.148146467208862 and perplexity is 172.11217891382373
At time: 1495.6161715984344 and batch: 450, loss is 5.104010038375854 and perplexity is 164.68096197677275
At time: 1496.8102757930756 and batch: 500, loss is 5.140718460083008 and perplexity is 170.83846485740565
At time: 1498.003571987152 and batch: 550, loss is 5.131948509216309 and perplexity is 169.3467705182539
At time: 1499.1989986896515 and batch: 600, loss is 5.081731605529785 and perplexity is 161.05269434919038
At time: 1500.3996286392212 and batch: 650, loss is 5.103185081481934 and perplexity is 164.54516330361992
At time: 1501.6011760234833 and batch: 700, loss is 5.116721181869507 and perplexity is 166.78760587690007
At time: 1502.8012156486511 and batch: 750, loss is 5.104128608703613 and perplexity is 164.70048941007417
At time: 1504.0013253688812 and batch: 800, loss is 5.0854450130462645 and perplexity is 161.6518604203207
At time: 1505.2024219036102 and batch: 850, loss is 5.043140935897827 and perplexity is 154.95595819989822
At time: 1506.402673482895 and batch: 900, loss is 5.0681617736816404 and perplexity is 158.88199767193225
At time: 1507.6020622253418 and batch: 950, loss is 5.060082683563232 and perplexity is 157.60354700749244
At time: 1508.8022367954254 and batch: 1000, loss is 5.078173313140869 and perplexity is 160.48064014432083
At time: 1510.002762556076 and batch: 1050, loss is 5.0336878204345705 and perplexity is 153.49804341049338
At time: 1511.2037937641144 and batch: 1100, loss is 5.036914415359497 and perplexity is 153.9941193059476
At time: 1512.405199766159 and batch: 1150, loss is 5.056565780639648 and perplexity is 157.05024415875636
At time: 1513.6071877479553 and batch: 1200, loss is 5.0323562335968015 and perplexity is 153.29378346137602
At time: 1514.8106360435486 and batch: 1250, loss is 5.0399242115020755 and perplexity is 154.45830841909634
At time: 1516.0128684043884 and batch: 1300, loss is 5.014290285110474 and perplexity is 150.54925179586937
At time: 1517.2150032520294 and batch: 1350, loss is 5.0147722053527835 and perplexity is 150.62182201289815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09611328125 and perplexity of 163.38563757910364
Finished 44 epochs...
Completing Train Step...
At time: 1520.6926550865173 and batch: 50, loss is 5.129833736419678 and perplexity is 168.98901898969478
At time: 1521.8684191703796 and batch: 100, loss is 5.137364387512207 and perplexity is 170.2664201244462
At time: 1523.0449495315552 and batch: 150, loss is 5.105405387878418 and perplexity is 164.91090986667655
At time: 1524.2226059436798 and batch: 200, loss is 5.102466125488281 and perplexity is 164.42690508855637
At time: 1525.4416518211365 and batch: 250, loss is 5.11709602355957 and perplexity is 166.85013654378685
At time: 1526.6251103878021 and batch: 300, loss is 5.110409326553345 and perplexity is 165.73818202986257
At time: 1527.808617591858 and batch: 350, loss is 5.118894557952881 and perplexity is 167.15049227197912
At time: 1529.0051333904266 and batch: 400, loss is 5.148015575408936 and perplexity is 172.08965231524206
At time: 1530.2060132026672 and batch: 450, loss is 5.103889064788818 and perplexity is 164.66104113505804
At time: 1531.4070072174072 and batch: 500, loss is 5.140586853027344 and perplexity is 170.81598278948343
At time: 1532.606951713562 and batch: 550, loss is 5.131852540969849 and perplexity is 169.33051938545245
At time: 1533.8078973293304 and batch: 600, loss is 5.081672830581665 and perplexity is 161.0432287636078
At time: 1535.0087354183197 and batch: 650, loss is 5.103071994781494 and perplexity is 164.52655648614027
At time: 1536.2091886997223 and batch: 700, loss is 5.116627721786499 and perplexity is 166.77201862181457
At time: 1537.4096398353577 and batch: 750, loss is 5.104043178558349 and perplexity is 164.68641962433935
At time: 1538.6096439361572 and batch: 800, loss is 5.0853892517089845 and perplexity is 161.6428467477194
At time: 1539.8099732398987 and batch: 850, loss is 5.043100118637085 and perplexity is 154.94963345122918
At time: 1541.0107905864716 and batch: 900, loss is 5.06812744140625 and perplexity is 158.87654298507002
At time: 1542.2111401557922 and batch: 950, loss is 5.060054159164428 and perplexity is 157.59905152518047
At time: 1543.4122080802917 and batch: 1000, loss is 5.07814133644104 and perplexity is 160.47550858510812
At time: 1544.6131517887115 and batch: 1050, loss is 5.033657093048095 and perplexity is 153.49332688925386
At time: 1545.8135991096497 and batch: 1100, loss is 5.036930847167969 and perplexity is 153.9966497286114
At time: 1547.0135760307312 and batch: 1150, loss is 5.056608800888061 and perplexity is 157.05700064460527
At time: 1548.2138879299164 and batch: 1200, loss is 5.0324170112609865 and perplexity is 153.30310058260247
At time: 1549.413999080658 and batch: 1250, loss is 5.039982290267944 and perplexity is 154.4672794275375
At time: 1550.6146471500397 and batch: 1300, loss is 5.01428484916687 and perplexity is 150.54843342085135
At time: 1551.815612077713 and batch: 1350, loss is 5.014744472503662 and perplexity is 150.6176448985558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096098225911458 and perplexity of 163.38317777153364
Finished 45 epochs...
Completing Train Step...
At time: 1555.2558677196503 and batch: 50, loss is 5.12963791847229 and perplexity is 168.95593114656765
At time: 1556.4672784805298 and batch: 100, loss is 5.137116146087647 and perplexity is 170.22415819155796
At time: 1557.6510541439056 and batch: 150, loss is 5.105179700851441 and perplexity is 164.87369581323514
At time: 1558.8350248336792 and batch: 200, loss is 5.102246599197388 and perplexity is 164.39081302168296
At time: 1560.0188772678375 and batch: 250, loss is 5.116886625289917 and perplexity is 166.81520207163976
At time: 1561.2027280330658 and batch: 300, loss is 5.110214252471923 and perplexity is 165.70585395953344
At time: 1562.3941915035248 and batch: 350, loss is 5.118738603591919 and perplexity is 167.12442645636395
At time: 1563.5882391929626 and batch: 400, loss is 5.147890796661377 and perplexity is 172.0681805235979
At time: 1564.7809753417969 and batch: 450, loss is 5.103780107498169 and perplexity is 164.64310109150748
At time: 1565.97584939003 and batch: 500, loss is 5.140475473403931 and perplexity is 170.79695842913011
At time: 1567.1755833625793 and batch: 550, loss is 5.1317602729797365 and perplexity is 169.3148963195296
At time: 1568.3751382827759 and batch: 600, loss is 5.081614456176758 and perplexity is 161.03382823534218
At time: 1569.5734322071075 and batch: 650, loss is 5.102955312728882 and perplexity is 164.50736030976654
At time: 1570.7735719680786 and batch: 700, loss is 5.116529941558838 and perplexity is 166.75571241309154
At time: 1571.9743838310242 and batch: 750, loss is 5.103960561752319 and perplexity is 164.67281432037456
At time: 1573.174525976181 and batch: 800, loss is 5.085334005355835 and perplexity is 161.63391681659928
At time: 1574.3761630058289 and batch: 850, loss is 5.0430529499053955 and perplexity is 154.94232484591373
At time: 1575.5768253803253 and batch: 900, loss is 5.0680928134918215 and perplexity is 158.8710415169876
At time: 1576.7767186164856 and batch: 950, loss is 5.060021095275879 and perplexity is 157.59384077384962
At time: 1577.9803767204285 and batch: 1000, loss is 5.078103742599487 and perplexity is 160.46947580766366
At time: 1579.18203830719 and batch: 1050, loss is 5.033622627258301 and perplexity is 153.48803671168002
At time: 1580.3843953609467 and batch: 1100, loss is 5.036937971115112 and perplexity is 153.99774679651202
At time: 1581.585993528366 and batch: 1150, loss is 5.056642227172851 and perplexity is 157.0622505643792
At time: 1582.7877128124237 and batch: 1200, loss is 5.03246675491333 and perplexity is 153.3107266284132
At time: 1583.9886639118195 and batch: 1250, loss is 5.040033445358277 and perplexity is 154.47518141728182
At time: 1585.189959526062 and batch: 1300, loss is 5.014269466400147 and perplexity is 150.54611758723146
At time: 1586.3916909694672 and batch: 1350, loss is 5.014713830947876 and perplexity is 150.6130298102944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096083984375 and perplexity of 163.38085096061954
Finished 46 epochs...
Completing Train Step...
At time: 1589.8372316360474 and batch: 50, loss is 5.129454288482666 and perplexity is 168.92490861910468
At time: 1591.030813217163 and batch: 100, loss is 5.136877813339233 and perplexity is 170.18359303428457
At time: 1592.2059478759766 and batch: 150, loss is 5.104961624145508 and perplexity is 164.83774462095855
At time: 1593.3856749534607 and batch: 200, loss is 5.102040662765503 and perplexity is 164.3569624498672
At time: 1594.5767846107483 and batch: 250, loss is 5.1166913700103756 and perplexity is 166.782633702404
At time: 1595.771725177765 and batch: 300, loss is 5.110054950714112 and perplexity is 165.67945882816926
At time: 1596.972987651825 and batch: 350, loss is 5.118610639572143 and perplexity is 167.1030419112072
At time: 1598.1732032299042 and batch: 400, loss is 5.147769165039063 and perplexity is 172.04725286441047
At time: 1599.3739066123962 and batch: 450, loss is 5.1036753082275395 and perplexity is 164.62584751869562
At time: 1600.5746376514435 and batch: 500, loss is 5.140360498428345 and perplexity is 170.7773221818648
At time: 1601.775720834732 and batch: 550, loss is 5.131671752929687 and perplexity is 169.29990921977253
At time: 1602.9767663478851 and batch: 600, loss is 5.081558752059936 and perplexity is 161.02485823799717
At time: 1604.1780331134796 and batch: 650, loss is 5.102846794128418 and perplexity is 164.48950916986757
At time: 1605.3794791698456 and batch: 700, loss is 5.116432390213013 and perplexity is 166.7394459623416
At time: 1606.5810317993164 and batch: 750, loss is 5.103881282806396 and perplexity is 164.6597597507162
At time: 1607.782103061676 and batch: 800, loss is 5.0852807521820065 and perplexity is 161.6253095267152
At time: 1608.9838452339172 and batch: 850, loss is 5.043003520965576 and perplexity is 154.9346664003394
At time: 1610.186286687851 and batch: 900, loss is 5.068057727813721 and perplexity is 158.86546751654978
At time: 1611.3863413333893 and batch: 950, loss is 5.059984092712402 and perplexity is 157.5880095056395
At time: 1612.5872583389282 and batch: 1000, loss is 5.078066844940185 and perplexity is 160.4635549688501
At time: 1613.7923061847687 and batch: 1050, loss is 5.033587312698364 and perplexity is 153.48261644491572
At time: 1614.9981381893158 and batch: 1100, loss is 5.0369406414031985 and perplexity is 153.9981580154097
At time: 1616.2281835079193 and batch: 1150, loss is 5.056669254302978 and perplexity is 157.06649556362805
At time: 1617.4300179481506 and batch: 1200, loss is 5.03251205444336 and perplexity is 153.31767168958072
At time: 1618.6316993236542 and batch: 1250, loss is 5.0400769233703615 and perplexity is 154.4818978370935
At time: 1619.8328247070312 and batch: 1300, loss is 5.014255952835083 and perplexity is 150.54408318622242
At time: 1621.0350759029388 and batch: 1350, loss is 5.0146801471710205 and perplexity is 150.60795668004826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096067708333333 and perplexity of 163.37819178872212
Finished 47 epochs...
Completing Train Step...
At time: 1624.5150351524353 and batch: 50, loss is 5.129268913269043 and perplexity is 168.89359703036908
At time: 1625.6884701251984 and batch: 100, loss is 5.136658935546875 and perplexity is 170.14634770138244
At time: 1626.8652136325836 and batch: 150, loss is 5.10475022315979 and perplexity is 164.8029014423331
At time: 1628.0578482151031 and batch: 200, loss is 5.101839828491211 and perplexity is 164.3239572529871
At time: 1629.2527170181274 and batch: 250, loss is 5.116497888565063 and perplexity is 166.75036747894072
At time: 1630.4466798305511 and batch: 300, loss is 5.109895801544189 and perplexity is 165.65309317791483
At time: 1631.6394882202148 and batch: 350, loss is 5.11848352432251 and perplexity is 167.08180191631246
At time: 1632.8336374759674 and batch: 400, loss is 5.14765115737915 and perplexity is 172.02695116860698
At time: 1634.028118610382 and batch: 450, loss is 5.10357105255127 and perplexity is 164.6086852342794
At time: 1635.2221524715424 and batch: 500, loss is 5.140243730545044 and perplexity is 170.75738203964454
At time: 1636.4232995510101 and batch: 550, loss is 5.131584568023682 and perplexity is 169.28514946652362
At time: 1637.624983549118 and batch: 600, loss is 5.081502075195313 and perplexity is 161.0157321125283
At time: 1638.8257839679718 and batch: 650, loss is 5.102736377716065 and perplexity is 164.47134783106875
At time: 1640.0270569324493 and batch: 700, loss is 5.116333656311035 and perplexity is 166.7229839389214
At time: 1641.2295017242432 and batch: 750, loss is 5.103803272247315 and perplexity is 164.64691505181736
At time: 1642.4300000667572 and batch: 800, loss is 5.085221862792968 and perplexity is 161.61579179123365
At time: 1643.6303865909576 and batch: 850, loss is 5.04294563293457 and perplexity is 154.92569779715683
At time: 1644.8313915729523 and batch: 900, loss is 5.068018436431885 and perplexity is 158.85922559543266
At time: 1646.0680222511292 and batch: 950, loss is 5.059936618804931 and perplexity is 157.5805283646386
At time: 1647.269245147705 and batch: 1000, loss is 5.078029136657715 and perplexity is 160.45750427787453
At time: 1648.4705245494843 and batch: 1050, loss is 5.033546762466431 and perplexity is 153.47639281540683
At time: 1649.6713981628418 and batch: 1100, loss is 5.03693639755249 and perplexity is 153.99750447160451
At time: 1650.8727881908417 and batch: 1150, loss is 5.056677370071411 and perplexity is 157.06777028410733
At time: 1652.0742695331573 and batch: 1200, loss is 5.032549371719361 and perplexity is 153.3233931942058
At time: 1653.274998664856 and batch: 1250, loss is 5.040113248825073 and perplexity is 154.48750956420085
At time: 1654.4766254425049 and batch: 1300, loss is 5.01423713684082 and perplexity is 150.54125057626612
At time: 1655.6783170700073 and batch: 1350, loss is 5.014638500213623 and perplexity is 150.60168444750332
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096050211588541 and perplexity of 163.3753332272037
Finished 48 epochs...
Completing Train Step...
At time: 1659.1495151519775 and batch: 50, loss is 5.129083700180054 and perplexity is 168.8623186222273
At time: 1660.325434923172 and batch: 100, loss is 5.1364446640014645 and perplexity is 170.10989408614017
At time: 1661.501983165741 and batch: 150, loss is 5.104544286727905 and perplexity is 164.7689660152361
At time: 1662.683263540268 and batch: 200, loss is 5.1016371631622315 and perplexity is 164.2906578585616
At time: 1663.8666543960571 and batch: 250, loss is 5.116303768157959 and perplexity is 166.71800097132237
At time: 1665.0518839359283 and batch: 300, loss is 5.109739751815796 and perplexity is 165.6272450745641
At time: 1666.2494778633118 and batch: 350, loss is 5.118355979919434 and perplexity is 167.0604929265722
At time: 1667.4505259990692 and batch: 400, loss is 5.147535142898559 and perplexity is 172.00699470886101
At time: 1668.6516008377075 and batch: 450, loss is 5.103469161987305 and perplexity is 164.59191401693627
At time: 1669.8524520397186 and batch: 500, loss is 5.14011848449707 and perplexity is 170.73599669162485
At time: 1671.052878856659 and batch: 550, loss is 5.131498689651489 and perplexity is 169.27061215768026
At time: 1672.2542777061462 and batch: 600, loss is 5.081441879272461 and perplexity is 161.0060399136585
At time: 1673.4553475379944 and batch: 650, loss is 5.102616958618164 and perplexity is 164.45170798378996
At time: 1674.655911207199 and batch: 700, loss is 5.116235513687133 and perplexity is 166.70662211072244
At time: 1675.8557813167572 and batch: 750, loss is 5.103727369308472 and perplexity is 164.63441834136808
At time: 1677.0957312583923 and batch: 800, loss is 5.08516074180603 and perplexity is 161.60591397640852
At time: 1678.2966871261597 and batch: 850, loss is 5.042884321212768 and perplexity is 154.9161993270603
At time: 1679.4976377487183 and batch: 900, loss is 5.067974119186402 and perplexity is 158.8521855481336
At time: 1680.6983964443207 and batch: 950, loss is 5.059883012771606 and perplexity is 157.57208132399188
At time: 1681.8999392986298 and batch: 1000, loss is 5.0779923248291015 and perplexity is 160.45159765244478
At time: 1683.1001334190369 and batch: 1050, loss is 5.033505430221558 and perplexity is 153.47004942265102
At time: 1684.3001823425293 and batch: 1100, loss is 5.036931810379028 and perplexity is 153.99679805995896
At time: 1685.5006170272827 and batch: 1150, loss is 5.056681060791016 and perplexity is 157.0683499782761
At time: 1686.7009484767914 and batch: 1200, loss is 5.03258282661438 and perplexity is 153.32852269803217
At time: 1687.9009878635406 and batch: 1250, loss is 5.040142745971679 and perplexity is 154.4920665721283
At time: 1689.101689338684 and batch: 1300, loss is 5.0142173576354985 and perplexity is 150.53827301940856
At time: 1690.302517414093 and batch: 1350, loss is 5.014596157073974 and perplexity is 150.5953076343555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09603271484375 and perplexity of 163.37247471570038
Finished 49 epochs...
Completing Train Step...
At time: 1693.7512805461884 and batch: 50, loss is 5.128904104232788 and perplexity is 168.83199435729588
At time: 1694.9545164108276 and batch: 100, loss is 5.136238021850586 and perplexity is 170.0747458434198
At time: 1696.1315541267395 and batch: 150, loss is 5.104343757629395 and perplexity is 164.73592835563534
At time: 1697.3190741539001 and batch: 200, loss is 5.101446514129639 and perplexity is 164.25933898912774
At time: 1698.5121765136719 and batch: 250, loss is 5.116117916107178 and perplexity is 166.6870189680633
At time: 1699.704698562622 and batch: 300, loss is 5.109587717056274 and perplexity is 165.6020658902931
At time: 1700.8977739810944 and batch: 350, loss is 5.118234033584595 and perplexity is 167.04012175388357
At time: 1702.0907397270203 and batch: 400, loss is 5.147425699234009 and perplexity is 171.9881706631368
At time: 1703.28378033638 and batch: 450, loss is 5.1033726501464844 and perplexity is 164.5760297148543
At time: 1704.48170876503 and batch: 500, loss is 5.140004615783692 and perplexity is 170.71655631020082
At time: 1705.6818568706512 and batch: 550, loss is 5.131417217254639 and perplexity is 169.25682183696432
At time: 1706.9086966514587 and batch: 600, loss is 5.081387939453125 and perplexity is 160.99735551117328
At time: 1708.1077902317047 and batch: 650, loss is 5.1025087356567385 and perplexity is 164.43391149595217
At time: 1709.3080320358276 and batch: 700, loss is 5.1161463165283205 and perplexity is 166.6917530168252
At time: 1710.508279800415 and batch: 750, loss is 5.103653221130371 and perplexity is 164.6222114517603
At time: 1711.7087452411652 and batch: 800, loss is 5.085107526779175 and perplexity is 161.5973143421732
At time: 1712.9086265563965 and batch: 850, loss is 5.042833480834961 and perplexity is 154.908323529164
At time: 1714.1090664863586 and batch: 900, loss is 5.067929763793945 and perplexity is 158.84513975336165
At time: 1715.309047460556 and batch: 950, loss is 5.059836835861206 and perplexity is 157.56480530010444
At time: 1716.5092051029205 and batch: 1000, loss is 5.077952537536621 and perplexity is 160.4452138447981
At time: 1717.7130680084229 and batch: 1050, loss is 5.033465738296509 and perplexity is 153.4639580218426
At time: 1718.9177114963531 and batch: 1100, loss is 5.036923971176147 and perplexity is 153.99559085254776
At time: 1720.117751121521 and batch: 1150, loss is 5.05669358253479 and perplexity is 157.07031676022333
At time: 1721.3172051906586 and batch: 1200, loss is 5.032615032196045 and perplexity is 153.33346081180844
At time: 1722.5179250240326 and batch: 1250, loss is 5.040166072845459 and perplexity is 154.49567043109835
At time: 1723.7190337181091 and batch: 1300, loss is 5.014197673797607 and perplexity is 150.5353098776091
At time: 1724.9192447662354 and batch: 1350, loss is 5.014554862976074 and perplexity is 150.5890890653747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096023356119792 and perplexity of 163.37094576496176
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77ca218eb8>
SETTINGS FOR THIS RUN
{'dropout': 0.0, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 6.642218321471463, 'wordvec_source': '', 'anneal': 5.512638265068215, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7452073097229004 and batch: 50, loss is 7.198893394470215 and perplexity is 1337.9493627185916
At time: 2.8209948539733887 and batch: 100, loss is 6.173646907806397 and perplexity is 479.9331905240579
At time: 3.9291000366210938 and batch: 150, loss is 5.814685001373291 and perplexity is 335.1857988037844
At time: 5.00407862663269 and batch: 200, loss is 5.658996305465698 and perplexity is 286.86057762177177
At time: 6.079619646072388 and batch: 250, loss is 5.615888137817382 and perplexity is 274.7572932074178
At time: 7.155457496643066 and batch: 300, loss is 5.542288808822632 and perplexity is 255.26157630379902
At time: 8.231220245361328 and batch: 350, loss is 5.504308910369873 and perplexity is 245.74856269664633
At time: 9.307782649993896 and batch: 400, loss is 5.502961368560791 and perplexity is 245.4176292572912
At time: 10.383581161499023 and batch: 450, loss is 5.435751256942749 and perplexity is 229.46517084109527
At time: 11.463037252426147 and batch: 500, loss is 5.441007537841797 and perplexity is 230.67447968479217
At time: 12.54103422164917 and batch: 550, loss is 5.395845737457275 and perplexity is 220.48854368439052
At time: 13.61715054512024 and batch: 600, loss is 5.317897691726684 and perplexity is 203.95465540830955
At time: 14.693091869354248 and batch: 650, loss is 5.33268630027771 and perplexity is 206.9932740608281
At time: 15.76921820640564 and batch: 700, loss is 5.328426561355591 and perplexity is 206.11341207631685
At time: 16.8787522315979 and batch: 750, loss is 5.278650217056274 and perplexity is 196.10499744744104
At time: 18.047510862350464 and batch: 800, loss is 5.21901083946228 and perplexity is 184.751344917271
At time: 19.24946641921997 and batch: 850, loss is 5.203616027832031 and perplexity is 181.92891390357735
At time: 20.44833540916443 and batch: 900, loss is 5.241733236312866 and perplexity is 188.9973958348004
At time: 21.647178888320923 and batch: 950, loss is 5.198971757888794 and perplexity is 181.0859459175507
At time: 22.845738649368286 and batch: 1000, loss is 5.206053161621094 and perplexity is 182.3728397404585
At time: 24.048085689544678 and batch: 1050, loss is 5.141053342819214 and perplexity is 170.89568529049924
At time: 25.247772216796875 and batch: 1100, loss is 5.11060751914978 and perplexity is 165.77103336582573
At time: 26.447694778442383 and batch: 1150, loss is 5.120763731002808 and perplexity is 167.46321764528557
At time: 27.64769196510315 and batch: 1200, loss is 5.104098958969116 and perplexity is 164.69560615668559
At time: 28.84687352180481 and batch: 1250, loss is 5.145918560028076 and perplexity is 171.7291557829429
At time: 30.04779028892517 and batch: 1300, loss is 5.097237720489502 and perplexity is 163.5694581293204
At time: 31.24796485900879 and batch: 1350, loss is 5.068292942047119 and perplexity is 158.9028393307241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.89380126953125 and perplexity of 133.45992820598494
Finished 1 epochs...
Completing Train Step...
At time: 34.785908222198486 and batch: 50, loss is 5.122381620407104 and perplexity is 167.7343739019931
At time: 35.98552179336548 and batch: 100, loss is 5.10540078163147 and perplexity is 164.91015024805085
At time: 37.2128050327301 and batch: 150, loss is 5.0307190895080565 and perplexity is 153.0430247700033
At time: 38.41271138191223 and batch: 200, loss is 5.011275434494019 and perplexity is 150.0960517997031
At time: 39.61275029182434 and batch: 250, loss is 5.018936347961426 and perplexity is 151.25034047176757
At time: 40.8133065700531 and batch: 300, loss is 4.989234457015991 and perplexity is 146.82398039309794
At time: 42.01341485977173 and batch: 350, loss is 4.98433183670044 and perplexity is 146.1059197915152
At time: 43.213977098464966 and batch: 400, loss is 5.000317220687866 and perplexity is 148.46024629511643
At time: 44.41410422325134 and batch: 450, loss is 4.9548121929168705 and perplexity is 141.8559623165583
At time: 45.615081787109375 and batch: 500, loss is 5.008891401290893 and perplexity is 149.73864403382564
At time: 46.81587529182434 and batch: 550, loss is 4.978773021697998 and perplexity is 145.29599720312842
At time: 48.01650905609131 and batch: 600, loss is 4.924225187301635 and perplexity is 137.58269951169805
At time: 49.21683311462402 and batch: 650, loss is 4.9417425155639645 and perplexity is 140.0140137149778
At time: 50.419313192367554 and batch: 700, loss is 4.943175659179688 and perplexity is 140.2148177609942
At time: 51.62052512168884 and batch: 750, loss is 4.901816339492798 and perplexity is 134.5339171664117
At time: 52.82063674926758 and batch: 800, loss is 4.859098310470581 and perplexity is 128.9079147707122
At time: 54.02077555656433 and batch: 850, loss is 4.837528944015503 and perplexity is 126.15722468219515
At time: 55.22008490562439 and batch: 900, loss is 4.883555727005005 and perplexity is 132.0995396952774
At time: 56.42061734199524 and batch: 950, loss is 4.8458805179595945 and perplexity is 127.2152480030628
At time: 57.62082886695862 and batch: 1000, loss is 4.8579240417480465 and perplexity is 128.75663107954702
At time: 58.82192897796631 and batch: 1050, loss is 4.794697751998902 and perplexity is 120.86784419732065
At time: 60.02192044258118 and batch: 1100, loss is 4.778861989974976 and perplexity is 118.96888519523695
At time: 61.22227716445923 and batch: 1150, loss is 4.795437622070312 and perplexity is 120.95730378799414
At time: 62.42308187484741 and batch: 1200, loss is 4.776892814636231 and perplexity is 118.73484510904265
At time: 63.62369632720947 and batch: 1250, loss is 4.834982948303223 and perplexity is 125.83643746380346
At time: 64.82384204864502 and batch: 1300, loss is 4.80821626663208 and perplexity is 122.51289216764637
At time: 66.02401852607727 and batch: 1350, loss is 4.779747905731202 and perplexity is 119.07432830509184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.777659912109375 and perplexity of 118.82596125171331
Finished 2 epochs...
Completing Train Step...
At time: 69.48207950592041 and batch: 50, loss is 4.847092571258545 and perplexity is 127.36953314610204
At time: 70.71106743812561 and batch: 100, loss is 4.84646502494812 and perplexity is 127.28962794024652
At time: 71.91235423088074 and batch: 150, loss is 4.784661417007446 and perplexity is 119.66084109854782
At time: 73.11418604850769 and batch: 200, loss is 4.772667560577393 and perplexity is 118.23421860470224
At time: 74.31553173065186 and batch: 250, loss is 4.779283981323243 and perplexity is 119.0190996297856
At time: 75.51724624633789 and batch: 300, loss is 4.765301828384399 and perplexity is 117.36653649437149
At time: 76.71889758110046 and batch: 350, loss is 4.757503938674927 and perplexity is 116.45488428845452
At time: 77.92103052139282 and batch: 400, loss is 4.777822456359863 and perplexity is 118.84527729833721
At time: 79.1228654384613 and batch: 450, loss is 4.7289376544952395 and perplexity is 113.17526722609435
At time: 80.32413721084595 and batch: 500, loss is 4.794937467575073 and perplexity is 120.89682157525866
At time: 81.52591800689697 and batch: 550, loss is 4.769395980834961 and perplexity is 117.84803798504734
At time: 82.72772121429443 and batch: 600, loss is 4.712458095550537 and perplexity is 111.32547250246171
At time: 83.92907381057739 and batch: 650, loss is 4.72820294380188 and perplexity is 113.09214668555352
At time: 85.1304497718811 and batch: 700, loss is 4.737132377624512 and perplexity is 114.10651766445979
At time: 86.33218455314636 and batch: 750, loss is 4.694604463577271 and perplexity is 109.35554598493407
At time: 87.53183794021606 and batch: 800, loss is 4.664770021438598 and perplexity is 106.14117222075649
At time: 88.73387742042542 and batch: 850, loss is 4.641223077774048 and perplexity is 103.67106785201359
At time: 89.93521046638489 and batch: 900, loss is 4.684993963241578 and perplexity is 108.30961846720875
At time: 91.13735628128052 and batch: 950, loss is 4.6540471458435055 and perplexity is 105.00911394254786
At time: 92.33877086639404 and batch: 1000, loss is 4.67302529335022 and perplexity is 107.02102316607585
At time: 93.58606052398682 and batch: 1050, loss is 4.606759796142578 and perplexity is 100.15908742544282
At time: 94.78687500953674 and batch: 1100, loss is 4.592995767593384 and perplexity is 98.78993900084917
At time: 95.98839712142944 and batch: 1150, loss is 4.615449161529541 and perplexity is 101.0331985684842
At time: 97.19007706642151 and batch: 1200, loss is 4.594174489974976 and perplexity is 98.90645356869975
At time: 98.39085054397583 and batch: 1250, loss is 4.649460983276367 and perplexity is 104.5286277111279
At time: 99.5924460887909 and batch: 1300, loss is 4.625551862716675 and perplexity is 102.05908014561678
At time: 100.79388523101807 and batch: 1350, loss is 4.596608266830445 and perplexity is 99.14746296883811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7278145345052085 and perplexity of 113.04822917393736
Finished 3 epochs...
Completing Train Step...
At time: 104.27690124511719 and batch: 50, loss is 4.670167436599732 and perplexity is 106.71560903536265
At time: 105.4772138595581 and batch: 100, loss is 4.674437370300293 and perplexity is 107.17225183419144
At time: 106.6798849105835 and batch: 150, loss is 4.626216716766358 and perplexity is 102.1269570999922
At time: 107.88062191009521 and batch: 200, loss is 4.610055465698242 and perplexity is 100.48972321448095
At time: 109.08205199241638 and batch: 250, loss is 4.620245161056519 and perplexity is 101.51891756403792
At time: 110.28346610069275 and batch: 300, loss is 4.60277153968811 and perplexity is 99.76042281533299
At time: 111.48659181594849 and batch: 350, loss is 4.606686639785766 and perplexity is 100.151760419517
At time: 112.68770337104797 and batch: 400, loss is 4.617387809753418 and perplexity is 101.22925638160262
At time: 113.88887691497803 and batch: 450, loss is 4.573185443878174 and perplexity is 96.85213595589074
At time: 115.08916902542114 and batch: 500, loss is 4.640791606903076 and perplexity is 103.62634645475687
At time: 116.2903733253479 and batch: 550, loss is 4.624352598190308 and perplexity is 101.9367576743655
At time: 117.49104189872742 and batch: 600, loss is 4.569036149978638 and perplexity is 96.45110056124354
At time: 118.69099831581116 and batch: 650, loss is 4.584904584884644 and perplexity is 97.99383660280076
At time: 119.89152503013611 and batch: 700, loss is 4.5974051380157475 and perplexity is 99.22650221303944
At time: 121.09285068511963 and batch: 750, loss is 4.554132690429688 and perplexity is 95.02430399710343
At time: 122.2927474975586 and batch: 800, loss is 4.521926298141479 and perplexity is 92.012671213031
At time: 123.52151346206665 and batch: 850, loss is 4.503325653076172 and perplexity is 90.31699539574103
At time: 124.72316932678223 and batch: 900, loss is 4.54196717262268 and perplexity is 93.87528749623078
At time: 125.92421126365662 and batch: 950, loss is 4.520021114349365 and perplexity is 91.83753704752769
At time: 127.12554478645325 and batch: 1000, loss is 4.534371290206909 and perplexity is 93.1649231880543
At time: 128.32663702964783 and batch: 1050, loss is 4.467562875747681 and perplexity is 87.14408304544256
At time: 129.52715492248535 and batch: 1100, loss is 4.4578683471679685 and perplexity is 86.30334411027218
At time: 130.72708988189697 and batch: 1150, loss is 4.47623496055603 and perplexity is 87.90309025484457
At time: 131.92871594429016 and batch: 1200, loss is 4.456108837127686 and perplexity is 86.15162602369018
At time: 133.12887454032898 and batch: 1250, loss is 4.514280643463135 and perplexity is 91.31185661002844
At time: 134.32933688163757 and batch: 1300, loss is 4.49385027885437 and perplexity is 89.46524974283946
At time: 135.5306007862091 and batch: 1350, loss is 4.467082500457764 and perplexity is 87.1022312343778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.709908854166667 and perplexity of 111.0420384253135
Finished 4 epochs...
Completing Train Step...
At time: 139.00822472572327 and batch: 50, loss is 4.541832599639893 and perplexity is 93.86265526877972
At time: 140.19236707687378 and batch: 100, loss is 4.547375545501709 and perplexity is 94.38437548304447
At time: 141.38623881340027 and batch: 150, loss is 4.504282350540161 and perplexity is 90.4034427815951
At time: 142.57929944992065 and batch: 200, loss is 4.4837672996521 and perplexity is 88.56770605170392
At time: 143.7785940170288 and batch: 250, loss is 4.499395761489868 and perplexity is 89.9627559127245
At time: 144.97782254219055 and batch: 300, loss is 4.4882510471343995 and perplexity is 88.96571289502351
At time: 146.1783287525177 and batch: 350, loss is 4.486860599517822 and perplexity is 88.84209669241473
At time: 147.3787763118744 and batch: 400, loss is 4.49889365196228 and perplexity is 89.91759609438897
At time: 148.57867336273193 and batch: 450, loss is 4.452077493667603 and perplexity is 85.8050183462553
At time: 149.77866911888123 and batch: 500, loss is 4.524600334167481 and perplexity is 92.2590456709838
At time: 150.97736763954163 and batch: 550, loss is 4.510981073379517 and perplexity is 91.01106325695177
At time: 152.1766767501831 and batch: 600, loss is 4.452184705734253 and perplexity is 85.81421817275856
At time: 153.37650656700134 and batch: 650, loss is 4.47165018081665 and perplexity is 87.50099640781788
At time: 154.61316800117493 and batch: 700, loss is 4.485607900619507 and perplexity is 88.73087397459689
At time: 155.81342792510986 and batch: 750, loss is 4.444588689804077 and perplexity is 85.16484146477929
At time: 157.01347994804382 and batch: 800, loss is 4.409381866455078 and perplexity is 82.21862570298086
At time: 158.2130742073059 and batch: 850, loss is 4.3923430824279786 and perplexity is 80.82958766153602
At time: 159.41296935081482 and batch: 900, loss is 4.4314874649047855 and perplexity is 84.05635484469217
At time: 160.61205196380615 and batch: 950, loss is 4.412535076141357 and perplexity is 82.4782874387447
At time: 161.81140446662903 and batch: 1000, loss is 4.4254600620269775 and perplexity is 83.55123713280385
At time: 163.0107033252716 and batch: 1050, loss is 4.360185871124267 and perplexity is 78.27168151654185
At time: 164.21067309379578 and batch: 1100, loss is 4.350029191970825 and perplexity is 77.48072470730293
At time: 165.41044998168945 and batch: 1150, loss is 4.365949497222901 and perplexity is 78.72411279281364
At time: 166.61130118370056 and batch: 1200, loss is 4.344991998672485 and perplexity is 77.09142064312925
At time: 167.81076955795288 and batch: 1250, loss is 4.404762048721313 and perplexity is 81.83966667273758
At time: 169.0115270614624 and batch: 1300, loss is 4.386324405670166 and perplexity is 80.34456157270805
At time: 170.2111792564392 and batch: 1350, loss is 4.3576164722442625 and perplexity is 78.07082849198477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.706560465494792 and perplexity of 110.67084831293812
Finished 5 epochs...
Completing Train Step...
At time: 173.65215969085693 and batch: 50, loss is 4.4374849987030025 and perplexity is 84.5620004715073
At time: 174.85475420951843 and batch: 100, loss is 4.449338293075561 and perplexity is 85.57030280243956
At time: 176.03231072425842 and batch: 150, loss is 4.412399511337281 and perplexity is 82.46710704371866
At time: 177.2150433063507 and batch: 200, loss is 4.385256242752075 and perplexity is 80.25878631049862
At time: 178.40640878677368 and batch: 250, loss is 4.393995141983032 and perplexity is 80.96323331905944
At time: 179.5987446308136 and batch: 300, loss is 4.3907500171661376 and perplexity is 80.70092336582444
At time: 180.79125833511353 and batch: 350, loss is 4.392653980255127 and perplexity is 80.85472131150544
At time: 181.98773860931396 and batch: 400, loss is 4.4022012710571286 and perplexity is 81.63036158854796
At time: 183.18712258338928 and batch: 450, loss is 4.352534351348877 and perplexity is 77.67506960225022
At time: 184.4132649898529 and batch: 500, loss is 4.428187446594238 and perplexity is 83.77942452346925
At time: 185.6125590801239 and batch: 550, loss is 4.417105646133423 and perplexity is 82.85612302856151
At time: 186.81283736228943 and batch: 600, loss is 4.355319585800171 and perplexity is 77.89171444540109
At time: 188.01336860656738 and batch: 650, loss is 4.371080894470214 and perplexity is 79.12911571525129
At time: 189.21416091918945 and batch: 700, loss is 4.391769514083863 and perplexity is 80.78323966192875
At time: 190.41380047798157 and batch: 750, loss is 4.349865255355835 and perplexity is 77.46802382066602
At time: 191.6125135421753 and batch: 800, loss is 4.3136113739013675 and perplexity is 74.70980739141764
At time: 192.81189823150635 and batch: 850, loss is 4.299513034820556 and perplexity is 73.66391320331711
At time: 194.00991535186768 and batch: 900, loss is 4.340498542785644 and perplexity is 76.74579086285576
At time: 195.2080478668213 and batch: 950, loss is 4.320637855529785 and perplexity is 75.23660307321929
At time: 196.40604877471924 and batch: 1000, loss is 4.334959573745728 and perplexity is 76.32187341993973
At time: 197.6036193370819 and batch: 1050, loss is 4.26922529220581 and perplexity is 71.46624870775796
At time: 198.80205011367798 and batch: 1100, loss is 4.258813571929932 and perplexity is 70.7260223190379
At time: 200.00031161308289 and batch: 1150, loss is 4.276203575134278 and perplexity is 71.96670454141096
At time: 201.20234417915344 and batch: 1200, loss is 4.2594875240325925 and perplexity is 70.77370433638575
At time: 202.40237617492676 and batch: 1250, loss is 4.315866174697876 and perplexity is 74.87845318451376
At time: 203.59848141670227 and batch: 1300, loss is 4.298262252807617 and perplexity is 73.57183330362538
At time: 204.80078625679016 and batch: 1350, loss is 4.268181085586548 and perplexity is 71.39166212648163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.711836344401042 and perplexity of 111.2562772753003
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 208.27013492584229 and batch: 50, loss is 4.361884593963623 and perplexity is 78.40475640628532
At time: 209.46973323822021 and batch: 100, loss is 4.377717046737671 and perplexity is 79.65597480097877
At time: 210.64434170722961 and batch: 150, loss is 4.345131788253784 and perplexity is 77.10219797380441
At time: 211.82392978668213 and batch: 200, loss is 4.323967552185058 and perplexity is 75.48753567170496
At time: 213.01388597488403 and batch: 250, loss is 4.319722728729248 and perplexity is 75.16778353547008
At time: 214.23773193359375 and batch: 300, loss is 4.311066961288452 and perplexity is 74.5199564471761
At time: 215.43328094482422 and batch: 350, loss is 4.298613023757935 and perplexity is 73.59764469218793
At time: 216.6335325241089 and batch: 400, loss is 4.29910270690918 and perplexity is 73.63369304417996
At time: 217.83199501037598 and batch: 450, loss is 4.239889616966248 and perplexity is 69.40019081233444
At time: 219.02830982208252 and batch: 500, loss is 4.305184087753296 and perplexity is 74.08285194342662
At time: 220.2244040966034 and batch: 550, loss is 4.286411008834839 and perplexity is 72.70506186248531
At time: 221.42819809913635 and batch: 600, loss is 4.217359871864319 and perplexity is 67.85410407095375
At time: 222.62402939796448 and batch: 650, loss is 4.22524896144867 and perplexity is 68.391528283177
At time: 223.82051467895508 and batch: 700, loss is 4.22169695854187 and perplexity is 68.14903230408473
At time: 225.01632046699524 and batch: 750, loss is 4.173179507255554 and perplexity is 64.92154281675906
At time: 226.21217966079712 and batch: 800, loss is 4.128829746246338 and perplexity is 62.105201546589534
At time: 227.40886235237122 and batch: 850, loss is 4.09867175579071 and perplexity is 60.26019416336914
At time: 228.60569620132446 and batch: 900, loss is 4.119126605987549 and perplexity is 61.50550026321104
At time: 229.80325961112976 and batch: 950, loss is 4.085648012161255 and perplexity is 59.48046933291366
At time: 230.99901914596558 and batch: 1000, loss is 4.094022760391235 and perplexity is 59.980694996507395
At time: 232.19960594177246 and batch: 1050, loss is 4.012470078468323 and perplexity is 55.28325603310008
At time: 233.39858531951904 and batch: 1100, loss is 3.984919910430908 and perplexity is 53.78098200972591
At time: 234.59836649894714 and batch: 1150, loss is 3.990593991279602 and perplexity is 54.0870070340921
At time: 235.79735279083252 and batch: 1200, loss is 3.9518659353256225 and perplexity is 52.03236533878181
At time: 236.9974808692932 and batch: 1250, loss is 3.9921014213562014 and perplexity is 54.16860089832025
At time: 238.1965937614441 and batch: 1300, loss is 3.9595556020736695 and perplexity is 52.43401920134519
At time: 239.39659023284912 and batch: 1350, loss is 3.914844264984131 and perplexity is 50.14126215270029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6068343098958335 and perplexity of 100.16655093303307
Finished 7 epochs...
Completing Train Step...
At time: 242.89565777778625 and batch: 50, loss is 4.2444940948486325 and perplexity is 69.72047927064905
At time: 244.0585916042328 and batch: 100, loss is 4.260702877044678 and perplexity is 70.85977166162486
At time: 245.26530504226685 and batch: 150, loss is 4.226515102386474 and perplexity is 68.4781764397489
At time: 246.44869995117188 and batch: 200, loss is 4.207493286132813 and perplexity is 67.18790768227707
At time: 247.6416530609131 and batch: 250, loss is 4.203656377792359 and perplexity is 66.93060777265903
At time: 248.839369058609 and batch: 300, loss is 4.201800937652588 and perplexity is 66.80653717479649
At time: 250.03832054138184 and batch: 350, loss is 4.193715968132019 and perplexity is 66.26858594793947
At time: 251.23605918884277 and batch: 400, loss is 4.198586959838867 and perplexity is 66.5921671213337
At time: 252.43481969833374 and batch: 450, loss is 4.1428328800201415 and perplexity is 62.98098654831742
At time: 253.63277292251587 and batch: 500, loss is 4.213139400482178 and perplexity is 67.56833123878252
At time: 254.83133625984192 and batch: 550, loss is 4.19745701789856 and perplexity is 66.51696433420037
At time: 256.0302822589874 and batch: 600, loss is 4.133577604293823 and perplexity is 62.400769329253194
At time: 257.22952032089233 and batch: 650, loss is 4.144136509895325 and perplexity is 63.063143983758756
At time: 258.42893266677856 and batch: 700, loss is 4.14808385848999 and perplexity is 63.312568154745556
At time: 259.6282768249512 and batch: 750, loss is 4.1036059856414795 and perplexity is 60.55826658639234
At time: 260.8276529312134 and batch: 800, loss is 4.062864689826966 and perplexity is 58.14062760702655
At time: 262.0268521308899 and batch: 850, loss is 4.038175926208496 and perplexity is 56.72278184302367
At time: 263.2256100177765 and batch: 900, loss is 4.064356851577759 and perplexity is 58.22744758632596
At time: 264.4244453907013 and batch: 950, loss is 4.035736856460571 and perplexity is 56.58459960837084
At time: 265.62249636650085 and batch: 1000, loss is 4.051582889556885 and perplexity is 57.48838282454343
At time: 266.82153248786926 and batch: 1050, loss is 3.9766872358322143 and perplexity is 53.3400382489727
At time: 268.02002573013306 and batch: 1100, loss is 3.9536126852035522 and perplexity is 52.12333229171332
At time: 269.2191107273102 and batch: 1150, loss is 3.9672786474227903 and perplexity is 52.8405372676277
At time: 270.4173412322998 and batch: 1200, loss is 3.9353865671157835 and perplexity is 51.18193138458183
At time: 271.61474680900574 and batch: 1250, loss is 3.982954421043396 and perplexity is 53.675379874270476
At time: 272.8133177757263 and batch: 1300, loss is 3.9580122423171997 and perplexity is 52.35315706197659
At time: 274.0115215778351 and batch: 1350, loss is 3.922880325317383 and perplexity is 50.54582372398777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.601914876302083 and perplexity of 99.6749983089802
Finished 8 epochs...
Completing Train Step...
At time: 277.4943552017212 and batch: 50, loss is 4.196417398452759 and perplexity is 66.44784793820267
At time: 278.66775131225586 and batch: 100, loss is 4.210296602249145 and perplexity is 67.37652087438673
At time: 279.8506689071655 and batch: 150, loss is 4.175270700454712 and perplexity is 65.05744835842128
At time: 281.0447835922241 and batch: 200, loss is 4.156813583374023 and perplexity is 63.867688956991444
At time: 282.2441623210907 and batch: 250, loss is 4.152650542259217 and perplexity is 63.60235781737984
At time: 283.443008184433 and batch: 300, loss is 4.152343111038208 and perplexity is 63.58280747220425
At time: 284.64177417755127 and batch: 350, loss is 4.145298767089844 and perplexity is 63.13648218723448
At time: 285.84018898010254 and batch: 400, loss is 4.150533490180969 and perplexity is 63.467850743059095
At time: 287.0396966934204 and batch: 450, loss is 4.0959158754348755 and perplexity is 60.09435290233423
At time: 288.23869729042053 and batch: 500, loss is 4.168587532043457 and perplexity is 64.62410813041483
At time: 289.4375960826874 and batch: 550, loss is 4.155455431938171 and perplexity is 63.78100584125347
At time: 290.63796210289 and batch: 600, loss is 4.091854195594788 and perplexity is 59.85076390578481
At time: 291.8444402217865 and batch: 650, loss is 4.103050708770752 and perplexity is 60.52464931593571
At time: 293.0441665649414 and batch: 700, loss is 4.110192551612854 and perplexity is 60.958454088294914
At time: 294.26167368888855 and batch: 750, loss is 4.0679612159729 and perplexity is 58.43769920933548
At time: 295.46489906311035 and batch: 800, loss is 4.027798719406128 and perplexity is 56.137201404997775
At time: 296.66395235061646 and batch: 850, loss is 4.006503472328186 and perplexity is 54.95438471667581
At time: 297.8621492385864 and batch: 900, loss is 4.034545292854309 and perplexity is 56.517215612933704
At time: 299.06106543540955 and batch: 950, loss is 4.008537979125976 and perplexity is 55.06630359720718
At time: 300.26044154167175 and batch: 1000, loss is 4.02627498626709 and perplexity is 56.05172842642642
At time: 301.45957708358765 and batch: 1050, loss is 3.954187355041504 and perplexity is 52.153294607029764
At time: 302.6593973636627 and batch: 1100, loss is 3.933508801460266 and perplexity is 51.08591388903571
At time: 303.8588047027588 and batch: 1150, loss is 3.9495261478424073 and perplexity is 51.910762978956846
At time: 305.11269879341125 and batch: 1200, loss is 3.920395226478577 and perplexity is 50.42036830526723
At time: 306.3114912509918 and batch: 1250, loss is 3.971256823539734 and perplexity is 53.05116491014009
At time: 307.50987672805786 and batch: 1300, loss is 3.9493281126022337 and perplexity is 51.90048383639254
At time: 308.70843505859375 and batch: 1350, loss is 3.916462254524231 and perplexity is 50.222455857960675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.60225830078125 and perplexity of 99.70923502188653
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 312.14180302619934 and batch: 50, loss is 4.173285489082336 and perplexity is 64.92842368508134
At time: 313.34710001945496 and batch: 100, loss is 4.199440240859985 and perplexity is 66.64901320308574
At time: 314.52994775772095 and batch: 150, loss is 4.1746422481536865 and perplexity is 65.01657569990495
At time: 315.7175896167755 and batch: 200, loss is 4.161198801994324 and perplexity is 64.1483777268443
At time: 316.91703510284424 and batch: 250, loss is 4.153289608955383 and perplexity is 63.643016956625694
At time: 318.11680340766907 and batch: 300, loss is 4.152728605270386 and perplexity is 63.60732300274465
At time: 319.3171103000641 and batch: 350, loss is 4.14345531463623 and perplexity is 63.02020029723185
At time: 320.5175256729126 and batch: 400, loss is 4.148925504684448 and perplexity is 63.36587736739548
At time: 321.71684312820435 and batch: 450, loss is 4.0893499326705935 and perplexity is 59.70106937221803
At time: 322.91879963874817 and batch: 500, loss is 4.162118682861328 and perplexity is 64.20741374105161
At time: 324.1189296245575 and batch: 550, loss is 4.145876135826111 and perplexity is 63.17294574361307
At time: 325.31913709640503 and batch: 600, loss is 4.084664855003357 and perplexity is 59.42201942116656
At time: 326.5198886394501 and batch: 650, loss is 4.090840864181518 and perplexity is 59.79014596482986
At time: 327.7207272052765 and batch: 700, loss is 4.089102606773377 and perplexity is 59.686305577480404
At time: 328.9211814403534 and batch: 750, loss is 4.041939511299133 and perplexity is 56.936665090504505
At time: 330.1218967437744 and batch: 800, loss is 3.9977002429962156 and perplexity is 54.47273182618861
At time: 331.3219666481018 and batch: 850, loss is 3.9684959173202516 and perplexity is 52.904897627026166
At time: 332.5223009586334 and batch: 900, loss is 3.9873668909072877 and perplexity is 53.912744166670855
At time: 333.7228693962097 and batch: 950, loss is 3.960187177658081 and perplexity is 52.46714570751042
At time: 334.92373991012573 and batch: 1000, loss is 3.9727830123901366 and perplexity is 53.13219282274734
At time: 336.1515517234802 and batch: 1050, loss is 3.8956351709365844 and perplexity is 49.18728577704796
At time: 337.3521091938019 and batch: 1100, loss is 3.8676275539398195 and perplexity is 47.82878017107855
At time: 338.55271196365356 and batch: 1150, loss is 3.880911045074463 and perplexity is 48.46835181619986
At time: 339.75319743156433 and batch: 1200, loss is 3.8463531827926634 and perplexity is 46.822000227299135
At time: 340.953795671463 and batch: 1250, loss is 3.892241539955139 and perplexity is 49.02064519838655
At time: 342.15377926826477 and batch: 1300, loss is 3.8678041648864747 and perplexity is 47.837228003189786
At time: 343.35439443588257 and batch: 1350, loss is 3.8348040437698363 and perplexity is 46.28435707113227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.574478352864583 and perplexity of 96.97743793739527
Finished 10 epochs...
Completing Train Step...
At time: 346.786034822464 and batch: 50, loss is 4.155964431762695 and perplexity is 63.81347862565429
At time: 347.9858703613281 and batch: 100, loss is 4.174396004676819 and perplexity is 65.00056776325644
At time: 349.1759088039398 and batch: 150, loss is 4.144205093383789 and perplexity is 63.06746922248498
At time: 350.3753077983856 and batch: 200, loss is 4.131002554893493 and perplexity is 62.24029097413391
At time: 351.58275270462036 and batch: 250, loss is 4.123111243247986 and perplexity is 61.75106629214499
At time: 352.78263759613037 and batch: 300, loss is 4.123211736679077 and perplexity is 61.75727218049052
At time: 353.9835104942322 and batch: 350, loss is 4.112952733039856 and perplexity is 61.12694290396731
At time: 355.18451952934265 and batch: 400, loss is 4.1199082136154175 and perplexity is 61.553592223445804
At time: 356.384868144989 and batch: 450, loss is 4.061387205123902 and perplexity is 58.054789147231446
At time: 357.58489632606506 and batch: 500, loss is 4.13544047832489 and perplexity is 62.51712244390478
At time: 358.78575587272644 and batch: 550, loss is 4.119821753501892 and perplexity is 61.54827052293499
At time: 359.98609352111816 and batch: 600, loss is 4.059107608795166 and perplexity is 57.922598391051906
At time: 361.18643069267273 and batch: 650, loss is 4.066716437339783 and perplexity is 58.365002465054935
At time: 362.3868319988251 and batch: 700, loss is 4.068523211479187 and perplexity is 58.47055016386863
At time: 363.586532831192 and batch: 750, loss is 4.023319897651672 and perplexity is 55.88633509820838
At time: 364.78758358955383 and batch: 800, loss is 3.9816828775405884 and perplexity is 53.60717266713607
At time: 366.01496839523315 and batch: 850, loss is 3.955106077194214 and perplexity is 52.20123101086839
At time: 367.22133350372314 and batch: 900, loss is 3.9761079692840577 and perplexity is 53.30914909652777
At time: 368.42147874832153 and batch: 950, loss is 3.9510515213012694 and perplexity is 51.990006701804916
At time: 369.62185764312744 and batch: 1000, loss is 3.966133546829224 and perplexity is 52.780064167537546
At time: 370.82182264328003 and batch: 1050, loss is 3.892303910255432 and perplexity is 49.0237027260966
At time: 372.0218143463135 and batch: 1100, loss is 3.866709575653076 and perplexity is 47.78489453551216
At time: 373.2218918800354 and batch: 1150, loss is 3.8819639921188354 and perplexity is 48.51941330179285
At time: 374.42078018188477 and batch: 1200, loss is 3.850413465499878 and perplexity is 47.01249725933226
At time: 375.6210503578186 and batch: 1250, loss is 3.8987860679626465 and perplexity is 49.3425142756025
At time: 376.8203454017639 and batch: 1300, loss is 3.8760806131362915 and perplexity is 48.23479329001484
At time: 378.0198516845703 and batch: 1350, loss is 3.8441311883926392 and perplexity is 46.71807750560674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.572367350260417 and perplexity of 96.77293424322426
Finished 11 epochs...
Completing Train Step...
At time: 381.4980103969574 and batch: 50, loss is 4.146189751625061 and perplexity is 63.192760884472726
At time: 382.68398118019104 and batch: 100, loss is 4.162369647026062 and perplexity is 64.22352952316818
At time: 383.8699679374695 and batch: 150, loss is 4.131048202514648 and perplexity is 62.243132160203075
At time: 385.06233310699463 and batch: 200, loss is 4.117521314620972 and perplexity is 61.40684522087123
At time: 386.2630572319031 and batch: 250, loss is 4.109328074455261 and perplexity is 60.90577966837023
At time: 387.4620931148529 and batch: 300, loss is 4.109601030349731 and perplexity is 60.92240652903459
At time: 388.6613130569458 and batch: 350, loss is 4.09903697013855 and perplexity is 60.28220607016863
At time: 389.8611309528351 and batch: 400, loss is 4.106439571380616 and perplexity is 60.730106974236044
At time: 391.0601921081543 and batch: 450, loss is 4.048373875617981 and perplexity is 57.30419748744961
At time: 392.2588150501251 and batch: 500, loss is 4.122954421043396 and perplexity is 61.741383113081845
At time: 393.45904445648193 and batch: 550, loss is 4.107701687812805 and perplexity is 60.80680383017685
At time: 394.6578252315521 and batch: 600, loss is 4.047529873847961 and perplexity is 57.255853047606855
At time: 395.8945565223694 and batch: 650, loss is 4.055632848739624 and perplexity is 57.72168053267989
At time: 397.09441089630127 and batch: 700, loss is 4.059091038703919 and perplexity is 57.92163861626307
At time: 398.294540643692 and batch: 750, loss is 4.0144430446624755 and perplexity is 55.39243569683286
At time: 399.49394273757935 and batch: 800, loss is 3.9738520526885988 and perplexity is 53.189023649830276
At time: 400.69337129592896 and batch: 850, loss is 3.9481515884399414 and perplexity is 51.839457569602494
At time: 401.8922371864319 and batch: 900, loss is 3.970344796180725 and perplexity is 53.00280285342645
At time: 403.0918378829956 and batch: 950, loss is 3.946242642402649 and perplexity is 51.740593235861105
At time: 404.2902796268463 and batch: 1000, loss is 3.9623427200317383 and perplexity is 52.5803628416355
At time: 405.4887788295746 and batch: 1050, loss is 3.89002336025238 and perplexity is 48.91202910773069
At time: 406.6890687942505 and batch: 1100, loss is 3.8655081367492676 and perplexity is 47.72751837807832
At time: 407.88788890838623 and batch: 1150, loss is 3.8815716075897218 and perplexity is 48.50037876932381
At time: 409.0864055156708 and batch: 1200, loss is 3.8512780237197877 and perplexity is 47.05315987534295
At time: 410.28273034095764 and batch: 1250, loss is 3.9006935787200927 and perplexity is 49.436725478257536
At time: 411.48225450515747 and batch: 1300, loss is 3.878911786079407 and perplexity is 48.37154782822173
At time: 412.6813454627991 and batch: 1350, loss is 3.847237629890442 and perplexity is 46.86343012808941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571746826171875 and perplexity of 96.7129029337705
Finished 12 epochs...
Completing Train Step...
At time: 416.14335322380066 and batch: 50, loss is 4.137359204292298 and perplexity is 62.63719082246736
At time: 417.31718850135803 and batch: 100, loss is 4.152423911094665 and perplexity is 63.58794517419822
At time: 418.50303983688354 and batch: 150, loss is 4.12077570438385 and perplexity is 61.60701256393954
At time: 419.7018265724182 and batch: 200, loss is 4.107220969200134 and perplexity is 60.77757989260678
At time: 420.9008786678314 and batch: 250, loss is 4.098934512138367 and perplexity is 60.27602999228777
At time: 422.09967851638794 and batch: 300, loss is 4.099446477890015 and perplexity is 60.30689715608027
At time: 423.29966282844543 and batch: 350, loss is 4.088781237602234 and perplexity is 59.667127320743674
At time: 424.4985179901123 and batch: 400, loss is 4.096512126922607 and perplexity is 60.13019493402702
At time: 425.6978256702423 and batch: 450, loss is 4.038857288360596 and perplexity is 56.761443769624314
At time: 426.9242956638336 and batch: 500, loss is 4.113834886550904 and perplexity is 61.18089004260006
At time: 428.1235065460205 and batch: 550, loss is 4.098929896354675 and perplexity is 60.27575177181361
At time: 429.3233916759491 and batch: 600, loss is 4.039116702079773 and perplexity is 56.77617037691785
At time: 430.52148389816284 and batch: 650, loss is 4.047502784729004 and perplexity is 57.254302058000235
At time: 431.72102451324463 and batch: 700, loss is 4.05203691482544 and perplexity is 57.514489929188244
At time: 432.92007517814636 and batch: 750, loss is 4.007677936553955 and perplexity is 55.01896459152781
At time: 434.12285923957825 and batch: 800, loss is 3.9678030729293825 and perplexity is 52.86825546058131
At time: 435.3240740299225 and batch: 850, loss is 3.9426389932632446 and perplexity is 51.55447384747791
At time: 436.524151802063 and batch: 900, loss is 3.9655425786972045 and perplexity is 52.748882046336064
At time: 437.72360944747925 and batch: 950, loss is 3.942176637649536 and perplexity is 51.53064285670346
At time: 438.9205732345581 and batch: 1000, loss is 3.9588272619247435 and perplexity is 52.39584330419822
At time: 440.1227550506592 and batch: 1050, loss is 3.887490038871765 and perplexity is 48.78827603795594
At time: 441.3215456008911 and batch: 1100, loss is 3.8636689710617067 and perplexity is 47.63982023435346
At time: 442.52580308914185 and batch: 1150, loss is 3.880224709510803 and perplexity is 48.43509767569144
At time: 443.72482204437256 and batch: 1200, loss is 3.8506847763061525 and perplexity is 47.02525398830963
At time: 444.92318773269653 and batch: 1250, loss is 3.9007644128799437 and perplexity is 49.440227411199345
At time: 446.1242892742157 and batch: 1300, loss is 3.8796541118621826 and perplexity is 48.40746860613767
At time: 447.32418727874756 and batch: 1350, loss is 3.8480990028381346 and perplexity is 46.903814409504626
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571639811197917 and perplexity of 96.70255375874986
Finished 13 epochs...
Completing Train Step...
At time: 450.78048729896545 and batch: 50, loss is 4.129318208694458 and perplexity is 62.1355450155972
At time: 451.98228907585144 and batch: 100, loss is 4.143711857795715 and perplexity is 63.036369772522924
At time: 453.17149090766907 and batch: 150, loss is 4.112019329071045 and perplexity is 61.06991339278604
At time: 454.3677079677582 and batch: 200, loss is 4.098471446037292 and perplexity is 60.248124667594574
At time: 455.5663640499115 and batch: 250, loss is 4.09012128829956 and perplexity is 59.747137893456014
At time: 456.79255294799805 and batch: 300, loss is 4.090930123329162 and perplexity is 59.79548302048316
At time: 457.9904716014862 and batch: 350, loss is 4.08021671295166 and perplexity is 59.15828882819992
At time: 459.1888864040375 and batch: 400, loss is 4.088217930793762 and perplexity is 59.63352588652881
At time: 460.3874397277832 and batch: 450, loss is 4.030947256088257 and perplexity is 56.31422998710119
At time: 461.58636569976807 and batch: 500, loss is 4.10622718334198 and perplexity is 60.717209995560154
At time: 462.78506565093994 and batch: 550, loss is 4.091617460250855 and perplexity is 59.83659679160139
At time: 463.9844434261322 and batch: 600, loss is 4.0320685720443725 and perplexity is 56.3774114483123
At time: 465.1842405796051 and batch: 650, loss is 4.040622639656067 and perplexity is 56.86173615751778
At time: 466.38336515426636 and batch: 700, loss is 4.04596896648407 and perplexity is 57.166551678672555
At time: 467.58335876464844 and batch: 750, loss is 4.001807427406311 and perplexity is 54.69692146005116
At time: 468.7826147079468 and batch: 800, loss is 3.9625009202957155 and perplexity is 52.58868172692464
At time: 469.9816737174988 and batch: 850, loss is 3.9377086210250853 and perplexity is 51.30091668011093
At time: 471.18121886253357 and batch: 900, loss is 3.961090383529663 and perplexity is 52.51455574886944
At time: 472.3795840740204 and batch: 950, loss is 3.9383475828170775 and perplexity is 51.33370648036286
At time: 473.57695865631104 and batch: 1000, loss is 3.955341644287109 and perplexity is 52.21352935158849
At time: 474.77440309524536 and batch: 1050, loss is 3.884736909866333 and perplexity is 48.65414035122162
At time: 475.97223949432373 and batch: 1100, loss is 3.861426901817322 and perplexity is 47.533128108858584
At time: 477.1708734035492 and batch: 1150, loss is 3.8783285236358642 and perplexity is 48.343342747319305
At time: 478.3684980869293 and batch: 1200, loss is 3.8493140745162964 and perplexity is 46.96084054439597
At time: 479.56587314605713 and batch: 1250, loss is 3.899893035888672 and perplexity is 49.397165099068744
At time: 480.7697207927704 and batch: 1300, loss is 3.879332871437073 and perplexity is 48.39192066779103
At time: 481.9682128429413 and batch: 1350, loss is 3.84785053730011 and perplexity is 46.892161875708446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.571784261067708 and perplexity of 96.71652343898371
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 485.3865978717804 and batch: 50, loss is 4.125693006515503 and perplexity is 61.910698904966814
At time: 486.5863239765167 and batch: 100, loss is 4.144259176254272 and perplexity is 63.07088018449113
At time: 487.7601902484894 and batch: 150, loss is 4.116077919006347 and perplexity is 61.3182747862372
At time: 488.941974401474 and batch: 200, loss is 4.106775608062744 and perplexity is 60.7505179471147
At time: 490.1321601867676 and batch: 250, loss is 4.09917179107666 and perplexity is 60.29033392163234
At time: 491.3299994468689 and batch: 300, loss is 4.100563426017761 and perplexity is 60.37429446459076
At time: 492.5273163318634 and batch: 350, loss is 4.088703999519348 and perplexity is 59.662518924192256
At time: 493.7251007556915 and batch: 400, loss is 4.09834361076355 and perplexity is 60.24042332434736
At time: 494.9223232269287 and batch: 450, loss is 4.040413084030152 and perplexity is 56.849821709220116
At time: 496.1192991733551 and batch: 500, loss is 4.114775972366333 and perplexity is 61.23849361109377
At time: 497.3173191547394 and batch: 550, loss is 4.101161136627197 and perplexity is 60.410391607677504
At time: 498.515513420105 and batch: 600, loss is 4.043193125724793 and perplexity is 57.00808647329529
At time: 499.715859413147 and batch: 650, loss is 4.050344405174255 and perplexity is 57.41722843113006
At time: 500.91427779197693 and batch: 700, loss is 4.051340460777283 and perplexity is 57.474447675262844
At time: 502.1120445728302 and batch: 750, loss is 4.0055531311035155 and perplexity is 54.90218410752732
At time: 503.3100039958954 and batch: 800, loss is 3.9644770765304567 and perplexity is 52.69270793035783
At time: 504.5088758468628 and batch: 850, loss is 3.9342466402053833 and perplexity is 51.123620964792835
At time: 505.70749163627625 and batch: 900, loss is 3.953165545463562 and perplexity is 52.10003108830023
At time: 506.91309237480164 and batch: 950, loss is 3.928266854286194 and perplexity is 50.81882487193867
At time: 508.11105942726135 and batch: 1000, loss is 3.9439795064926146 and perplexity is 51.623629643477436
At time: 509.31087493896484 and batch: 1050, loss is 3.870486550331116 and perplexity is 47.965718140291706
At time: 510.5086522102356 and batch: 1100, loss is 3.8436429500579834 and perplexity is 46.695273516590895
At time: 511.70772218704224 and batch: 1150, loss is 3.859293932914734 and perplexity is 47.43184947524539
At time: 512.906044960022 and batch: 1200, loss is 3.828000240325928 and perplexity is 45.97051626934214
At time: 514.104585647583 and batch: 1250, loss is 3.8772525072097777 and perplexity is 48.29135249263152
At time: 515.3021528720856 and batch: 1300, loss is 3.857160696983337 and perplexity is 47.33077399690359
At time: 516.5007274150848 and batch: 1350, loss is 3.8279042434692383 and perplexity is 45.966103456091375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.56239990234375 and perplexity of 95.81314632568386
Finished 15 epochs...
Completing Train Step...
At time: 519.9646716117859 and batch: 50, loss is 4.123546380996704 and perplexity is 61.77794235908383
At time: 521.1275956630707 and batch: 100, loss is 4.138944697380066 and perplexity is 62.736580425497536
At time: 522.2964923381805 and batch: 150, loss is 4.108804006576538 and perplexity is 60.8738692679557
At time: 523.4700982570648 and batch: 200, loss is 4.098416633605957 and perplexity is 60.244822411901325
At time: 524.6452522277832 and batch: 250, loss is 4.0907159471511845 and perplexity is 59.78267762382391
At time: 525.8180339336395 and batch: 300, loss is 4.091435947418213 and perplexity is 59.825736667077905
At time: 526.9955897331238 and batch: 350, loss is 4.079082107543945 and perplexity is 59.09120557749028
At time: 528.1787374019623 and batch: 400, loss is 4.088146419525146 and perplexity is 59.629261569915776
At time: 529.3709342479706 and batch: 450, loss is 4.03094934463501 and perplexity is 56.31434760212622
At time: 530.561558008194 and batch: 500, loss is 4.105582256317138 and perplexity is 60.67806445032784
At time: 531.7537529468536 and batch: 550, loss is 4.092009592056274 and perplexity is 59.86006522539038
At time: 532.945481300354 and batch: 600, loss is 4.033904905319214 and perplexity is 56.48103427881106
At time: 534.1462297439575 and batch: 650, loss is 4.041449112892151 and perplexity is 56.90875028589254
At time: 535.3456692695618 and batch: 700, loss is 4.0439399766922 and perplexity is 57.05067892095348
At time: 536.5454776287079 and batch: 750, loss is 3.998899941444397 and perplexity is 54.53812189436748
At time: 537.7436873912811 and batch: 800, loss is 3.958778853416443 and perplexity is 52.393306960973504
At time: 538.9488363265991 and batch: 850, loss is 3.930048899650574 and perplexity is 50.909467063485984
At time: 540.1481869220734 and batch: 900, loss is 3.950337209701538 and perplexity is 51.95288289750823
At time: 541.3494637012482 and batch: 950, loss is 3.9263679456710814 and perplexity is 50.722416132242294
At time: 542.5557012557983 and batch: 1000, loss is 3.9429785871505736 and perplexity is 51.57198440473179
At time: 543.7540419101715 and batch: 1050, loss is 3.8705953979492187 and perplexity is 47.970939378616386
At time: 544.9540803432465 and batch: 1100, loss is 3.845246515274048 and perplexity is 46.770212501673306
At time: 546.1529829502106 and batch: 1150, loss is 3.86171612739563 and perplexity is 47.54687789362353
At time: 547.3794138431549 and batch: 1200, loss is 3.8315806579589844 and perplexity is 46.135404925371745
At time: 548.5776824951172 and batch: 1250, loss is 3.8817762088775636 and perplexity is 48.510303024503905
At time: 549.7775127887726 and batch: 1300, loss is 3.8615534496307373 and perplexity is 47.53914370290766
At time: 550.9765498638153 and batch: 1350, loss is 3.8322771787643433 and perplexity is 46.167550388458245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560877278645833 and perplexity of 95.66736996794862
Finished 16 epochs...
Completing Train Step...
At time: 554.4394316673279 and batch: 50, loss is 4.122212052345276 and perplexity is 61.69556525185729
At time: 555.6141633987427 and batch: 100, loss is 4.13645631313324 and perplexity is 62.580661780272024
At time: 556.7892484664917 and batch: 150, loss is 4.105425682067871 and perplexity is 60.66856457167712
At time: 557.9641609191895 and batch: 200, loss is 4.094532990455628 and perplexity is 60.01130675923451
At time: 559.1476764678955 and batch: 250, loss is 4.08676598072052 and perplexity is 59.54700381231633
At time: 560.3307952880859 and batch: 300, loss is 4.087293915748596 and perplexity is 59.578449061239674
At time: 561.5137622356415 and batch: 350, loss is 4.074784002304077 and perplexity is 58.837770392872244
At time: 562.6970582008362 and batch: 400, loss is 4.083674840927124 and perplexity is 59.36321989648254
At time: 563.880252122879 and batch: 450, loss is 4.026734585762024 and perplexity is 56.077495693359246
At time: 565.0687193870544 and batch: 500, loss is 4.10150936126709 and perplexity is 60.43143165766019
At time: 566.2709934711456 and batch: 550, loss is 4.088110308647156 and perplexity is 59.62710834380427
At time: 567.4839959144592 and batch: 600, loss is 4.029920639991761 and perplexity is 56.256446557908944
At time: 568.6905653476715 and batch: 650, loss is 4.037735662460327 and perplexity is 56.69781435502608
At time: 569.8977701663971 and batch: 700, loss is 4.040986704826355 and perplexity is 56.882441303957485
At time: 571.1055955886841 and batch: 750, loss is 3.996245150566101 and perplexity is 54.39352660589395
At time: 572.3058710098267 and batch: 800, loss is 3.956577248573303 and perplexity is 52.2780844863401
At time: 573.506383895874 and batch: 850, loss is 3.9284196090698242 and perplexity is 50.82658828347036
At time: 574.7077329158783 and batch: 900, loss is 3.949230785369873 and perplexity is 51.895432751750604
At time: 575.9079480171204 and batch: 950, loss is 3.925809373855591 and perplexity is 50.69409193146381
At time: 577.1452827453613 and batch: 1000, loss is 3.942882704734802 and perplexity is 51.567039795335276
At time: 578.3458795547485 and batch: 1050, loss is 3.870971345901489 and perplexity is 47.988977345500174
At time: 579.5468776226044 and batch: 1100, loss is 3.8461339569091795 and perplexity is 46.81173675798299
At time: 580.7474679946899 and batch: 1150, loss is 3.862992916107178 and perplexity is 47.6076239822953
At time: 581.9481995105743 and batch: 1200, loss is 3.833333806991577 and perplexity is 46.21635810664631
At time: 583.148814201355 and batch: 1250, loss is 3.883888564109802 and perplexity is 48.61288232072897
At time: 584.3492829799652 and batch: 1300, loss is 3.8636245012283323 and perplexity is 47.6377017465904
At time: 585.5498311519623 and batch: 1350, loss is 3.834213042259216 and perplexity is 46.257011027757585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.56034423828125 and perplexity of 95.61638898684964
Finished 17 epochs...
Completing Train Step...
At time: 588.9831519126892 and batch: 50, loss is 4.120599007606506 and perplexity is 61.596127765040464
At time: 590.1854376792908 and batch: 100, loss is 4.134276475906372 and perplexity is 62.444394698028916
At time: 591.3615963459015 and batch: 150, loss is 4.102859783172607 and perplexity is 60.51309471413229
At time: 592.5401475429535 and batch: 200, loss is 4.091744790077209 and perplexity is 59.84421626016302
At time: 593.7198767662048 and batch: 250, loss is 4.083931407928467 and perplexity is 59.378452493808794
At time: 594.910651922226 and batch: 300, loss is 4.0844422578811646 and perplexity is 59.40879372270436
At time: 596.1036400794983 and batch: 350, loss is 4.071880331039429 and perplexity is 58.66717264945266
At time: 597.29953789711 and batch: 400, loss is 4.080748624801636 and perplexity is 59.18976419336966
At time: 598.4997086524963 and batch: 450, loss is 4.023957738876343 and perplexity is 55.921993077485425
At time: 599.6999225616455 and batch: 500, loss is 4.098868894577026 and perplexity is 60.2720749559537
At time: 600.8998837471008 and batch: 550, loss is 4.085594000816346 and perplexity is 59.47725679952654
At time: 602.1012861728668 and batch: 600, loss is 4.027440319061279 and perplexity is 56.117085417659084
At time: 603.3008072376251 and batch: 650, loss is 4.035421090126038 and perplexity is 56.566734917443895
At time: 604.5010631084442 and batch: 700, loss is 4.039125304222107 and perplexity is 56.776658775717266
At time: 605.7016994953156 and batch: 750, loss is 3.9945778226852418 and perplexity is 54.30291032696249
At time: 606.9295825958252 and batch: 800, loss is 3.95519362449646 and perplexity is 52.2058012878721
At time: 608.1299061775208 and batch: 850, loss is 3.927356104850769 and perplexity is 50.772562725687116
At time: 609.3309602737427 and batch: 900, loss is 3.9484383249282837 and perplexity is 51.85432396489071
At time: 610.5307121276855 and batch: 950, loss is 3.925368113517761 and perplexity is 50.67172757394701
At time: 611.7308778762817 and batch: 1000, loss is 3.9427129364013673 and perplexity is 51.55828608800123
At time: 612.9318680763245 and batch: 1050, loss is 3.8711109066009524 and perplexity is 47.99567518811197
At time: 614.132453918457 and batch: 1100, loss is 3.8465239572525025 and perplexity is 46.829996911891854
At time: 615.3328719139099 and batch: 1150, loss is 3.8636164140701292 and perplexity is 47.63731649451775
At time: 616.5339179039001 and batch: 1200, loss is 3.834242696762085 and perplexity is 46.25838277676298
At time: 617.7343583106995 and batch: 1250, loss is 3.884990782737732 and perplexity is 48.66649388558531
At time: 618.9344577789307 and batch: 1300, loss is 3.8647403049468996 and perplexity is 47.69088573727261
At time: 620.1345338821411 and batch: 1350, loss is 3.8352281427383423 and perplexity is 46.30399038216331
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.56010498046875 and perplexity of 95.59351475530993
Finished 18 epochs...
Completing Train Step...
At time: 623.581258058548 and batch: 50, loss is 4.118954296112061 and perplexity is 61.49490317113688
At time: 624.7834281921387 and batch: 100, loss is 4.132278170585632 and perplexity is 62.31973632607984
At time: 625.958872795105 and batch: 150, loss is 4.100675973892212 and perplexity is 60.381089845499915
At time: 627.1403024196625 and batch: 200, loss is 4.089440569877625 and perplexity is 59.70648075563535
At time: 628.3223445415497 and batch: 250, loss is 4.081605911254883 and perplexity is 59.24052853306481
At time: 629.5115468502045 and batch: 300, loss is 4.0821374416351315 and perplexity is 59.272025043656704
At time: 630.711748123169 and batch: 350, loss is 4.0695596408844 and perplexity is 58.53118217637025
At time: 631.91060090065 and batch: 400, loss is 4.078454113006591 and perplexity is 59.05410827285351
At time: 633.1100318431854 and batch: 450, loss is 4.021766471862793 and perplexity is 55.79958721966121
At time: 634.3088393211365 and batch: 500, loss is 4.096794266700744 and perplexity is 60.14716244737771
At time: 635.5068490505219 and batch: 550, loss is 4.08362060546875 and perplexity is 59.36000039234732
At time: 636.7052369117737 and batch: 600, loss is 4.0255444049835205 and perplexity is 56.010793037861475
At time: 637.9320323467255 and batch: 650, loss is 4.033629517555237 and perplexity is 56.46548223459355
At time: 639.1304988861084 and batch: 700, loss is 4.037650437355041 and perplexity is 56.692982483729494
At time: 640.3299822807312 and batch: 750, loss is 3.99325279712677 and perplexity is 54.231005231444804
At time: 641.5288004875183 and batch: 800, loss is 3.9540769910812377 and perplexity is 52.14753908050319
At time: 642.7285323143005 and batch: 850, loss is 3.926452970504761 and perplexity is 50.72672898058477
At time: 643.927900314331 and batch: 900, loss is 3.947716040611267 and perplexity is 51.816883922726696
At time: 645.1277165412903 and batch: 950, loss is 3.92489324092865 and perplexity is 50.647670671912984
At time: 646.3273293972015 and batch: 1000, loss is 3.9424229097366332 and perplexity is 51.543334978462745
At time: 647.5261051654816 and batch: 1050, loss is 3.871066994667053 and perplexity is 47.99356765146899
At time: 648.725376367569 and batch: 1100, loss is 3.846638102531433 and perplexity is 46.83534264004069
At time: 649.9244601726532 and batch: 1150, loss is 3.863888363838196 and perplexity is 47.650273213398236
At time: 651.1242179870605 and batch: 1200, loss is 3.8347220325469973 and perplexity is 46.280561390056896
At time: 652.323600769043 and batch: 1250, loss is 3.8856023263931276 and perplexity is 48.69626467329173
At time: 653.5226306915283 and batch: 1300, loss is 3.865395550727844 and perplexity is 47.72214522914812
At time: 654.7215685844421 and batch: 1350, loss is 3.8358162117004393 and perplexity is 46.33122832983914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559988606770833 and perplexity of 95.58239083177963
Finished 19 epochs...
Completing Train Step...
At time: 658.1547436714172 and batch: 50, loss is 4.117346668243409 and perplexity is 61.39612167423736
At time: 659.328516960144 and batch: 100, loss is 4.130417456626892 and perplexity is 62.20388493936472
At time: 660.5038657188416 and batch: 150, loss is 4.0987199115753175 and perplexity is 60.26309611017186
At time: 661.6860258579254 and batch: 200, loss is 4.087411212921142 and perplexity is 59.58543785473411
At time: 662.8782494068146 and batch: 250, loss is 4.079570269584655 and perplexity is 59.120058702920346
At time: 664.0755233764648 and batch: 300, loss is 4.0801288557052615 and perplexity is 59.15309157215345
At time: 665.2748682498932 and batch: 350, loss is 4.067550954818725 and perplexity is 58.41372940868576
At time: 666.4745917320251 and batch: 400, loss is 4.076485123634338 and perplexity is 58.93794576018221
At time: 667.7010908126831 and batch: 450, loss is 4.019877767562866 and perplexity is 55.694297760971054
At time: 668.9026343822479 and batch: 500, loss is 4.095005536079407 and perplexity is 60.03967154091977
At time: 670.105874300003 and batch: 550, loss is 4.0819216108322145 and perplexity is 59.25923369533417
At time: 671.305606842041 and batch: 600, loss is 4.023930487632751 and perplexity is 55.920469154394446
At time: 672.5047533512115 and batch: 650, loss is 4.032085742950439 and perplexity is 56.378379507859776
At time: 673.7040033340454 and batch: 700, loss is 4.036354808807373 and perplexity is 56.61957700055944
At time: 674.9035863876343 and batch: 750, loss is 3.9920781373977663 and perplexity is 54.16733965355189
At time: 676.1028904914856 and batch: 800, loss is 3.953068299293518 and perplexity is 52.09496480615997
At time: 677.3025977611542 and batch: 850, loss is 3.9256047344207765 and perplexity is 50.68371898253592
At time: 678.5023617744446 and batch: 900, loss is 3.9470083045959474 and perplexity is 51.78022422199841
At time: 679.7023820877075 and batch: 950, loss is 3.924374527931213 and perplexity is 50.62140587937911
At time: 680.901533126831 and batch: 1000, loss is 3.942044634819031 and perplexity is 51.52384111492307
At time: 682.0999233722687 and batch: 1050, loss is 3.8708991193771363 and perplexity is 47.9855113936276
At time: 683.299102306366 and batch: 1100, loss is 3.8465867376327516 and perplexity is 46.832937009194296
At time: 684.4981808662415 and batch: 1150, loss is 3.863954854011536 and perplexity is 47.653441593655806
At time: 685.6973440647125 and batch: 1200, loss is 3.8349542236328125 and perplexity is 46.291308571509774
At time: 686.8974862098694 and batch: 1250, loss is 3.885939154624939 and perplexity is 48.712669712702564
At time: 688.0960817337036 and batch: 1300, loss is 3.8657925748825073 and perplexity is 47.74109583519168
At time: 689.2955152988434 and batch: 1350, loss is 3.8361694908142088 and perplexity is 46.34759907667456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559936116536458 and perplexity of 95.57737382135593
Finished 20 epochs...
Completing Train Step...
At time: 692.7445542812347 and batch: 50, loss is 4.115787806510926 and perplexity is 61.30048816870877
At time: 693.9186782836914 and batch: 100, loss is 4.128661451339721 and perplexity is 62.09475043695375
At time: 695.0983169078827 and batch: 150, loss is 4.096914868354798 and perplexity is 60.15441673208607
At time: 696.2868733406067 and batch: 200, loss is 4.0855586004257205 and perplexity is 59.47515131867018
At time: 697.5124127864838 and batch: 250, loss is 4.077720279693604 and perplexity is 59.01078829769857
At time: 698.7112884521484 and batch: 300, loss is 4.078306102752686 and perplexity is 59.04536830611218
At time: 699.9097409248352 and batch: 350, loss is 4.065735259056091 and perplexity is 58.3077640772322
At time: 701.1075766086578 and batch: 400, loss is 4.074710574150085 and perplexity is 58.83345020262104
At time: 702.306028842926 and batch: 450, loss is 4.018171730041504 and perplexity is 55.599362204102356
At time: 703.5058784484863 and batch: 500, loss is 4.0933869934082034 and perplexity is 59.942573370528955
At time: 704.704583644867 and batch: 550, loss is 4.080385227203369 and perplexity is 59.168258682981865
At time: 705.9028146266937 and batch: 600, loss is 4.022476944923401 and perplexity is 55.83924540954342
At time: 707.1019139289856 and batch: 650, loss is 4.030681896209717 and perplexity is 56.29928843240399
At time: 708.3007681369781 and batch: 700, loss is 4.0351595258712765 and perplexity is 56.55194101644312
At time: 709.4997038841248 and batch: 750, loss is 3.990983204841614 and perplexity is 54.1080625280345
At time: 710.6989207267761 and batch: 800, loss is 3.9521127223968504 and perplexity is 52.04520783844909
At time: 711.8987753391266 and batch: 850, loss is 3.9247785997390747 and perplexity is 50.64186469550633
At time: 713.0969939231873 and batch: 900, loss is 3.946300578117371 and perplexity is 51.74359095094689
At time: 714.2966406345367 and batch: 950, loss is 3.9238214015960695 and perplexity is 50.5934135890154
At time: 715.4984085559845 and batch: 1000, loss is 3.941606798171997 and perplexity is 51.50128702695045
At time: 716.6979146003723 and batch: 1050, loss is 3.8706461572647095 and perplexity is 47.9733744124625
At time: 717.8968482017517 and batch: 1100, loss is 3.8464282989501952 and perplexity is 46.82551744814257
At time: 719.0954093933105 and batch: 1150, loss is 3.8638906574249265 and perplexity is 47.65038250355793
At time: 720.2938709259033 and batch: 1200, loss is 3.8350304889678957 and perplexity is 46.294839128297255
At time: 721.4925494194031 and batch: 1250, loss is 3.8861051988601685 and perplexity is 48.720758842249076
At time: 722.6908214092255 and batch: 1300, loss is 3.8660277557373046 and perplexity is 47.7523249473035
At time: 723.8899338245392 and batch: 1350, loss is 3.8363764762878416 and perplexity is 46.357193349324476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559920654296875 and perplexity of 95.5758959925285
Finished 21 epochs...
Completing Train Step...
At time: 727.2926650047302 and batch: 50, loss is 4.114276242256165 and perplexity is 61.207898537211484
At time: 728.4833950996399 and batch: 100, loss is 4.126987156867981 and perplexity is 61.99087252494636
At time: 729.669285774231 and batch: 150, loss is 4.095217452049256 and perplexity is 60.05239625438113
At time: 730.8614821434021 and batch: 200, loss is 4.0838292646408085 and perplexity is 59.37238769319963
At time: 732.060996055603 and batch: 250, loss is 4.075998544692993 and perplexity is 58.90927477284418
At time: 733.2583956718445 and batch: 300, loss is 4.076611170768738 and perplexity is 58.94537518757184
At time: 734.4585800170898 and batch: 350, loss is 4.064050970077514 and perplexity is 58.2096396110068
At time: 735.657541513443 and batch: 400, loss is 4.073065190315247 and perplexity is 58.73672619059443
At time: 736.8559498786926 and batch: 450, loss is 4.016588034629822 and perplexity is 55.51137943662891
At time: 738.0554895401001 and batch: 500, loss is 4.09188172340393 and perplexity is 59.85241148886771
At time: 739.2540345191956 and batch: 550, loss is 4.078956851959228 and perplexity is 59.083804537504534
At time: 740.4528722763062 and batch: 600, loss is 4.021125574111938 and perplexity is 55.763836847103896
At time: 741.6517658233643 and batch: 650, loss is 4.029367470741272 and perplexity is 56.22533582707451
At time: 742.8505573272705 and batch: 700, loss is 4.034028720855713 and perplexity is 56.48802794132541
At time: 744.0480117797852 and batch: 750, loss is 3.9899367666244507 and perplexity is 54.05147139827307
At time: 745.2463490962982 and batch: 800, loss is 3.951188097000122 and perplexity is 51.997107758208394
At time: 746.4448647499084 and batch: 850, loss is 3.9239638090133666 and perplexity is 50.6006189794152
At time: 747.6436188220978 and batch: 900, loss is 3.945589942932129 and perplexity is 51.70683319682998
At time: 748.8422830104828 and batch: 950, loss is 3.923243498802185 and perplexity is 50.564183960705584
At time: 750.0402483940125 and batch: 1000, loss is 3.9411278581619262 and perplexity is 51.476626905853806
At time: 751.2374892234802 and batch: 1050, loss is 3.870333218574524 and perplexity is 47.9583640362963
At time: 752.4345684051514 and batch: 1100, loss is 3.8461963176727294 and perplexity is 46.81465606465447
At time: 753.6313755512238 and batch: 1150, loss is 3.8637379360198976 and perplexity is 47.64310582585818
At time: 754.8299517631531 and batch: 1200, loss is 3.8350008153915405 and perplexity is 46.293465415235126
At time: 756.036826133728 and batch: 1250, loss is 3.886156597137451 and perplexity is 48.72326306967741
At time: 757.2416398525238 and batch: 1300, loss is 3.8661530780792237 and perplexity is 47.75830975550523
At time: 758.4398686885834 and batch: 1350, loss is 3.8364845085144044 and perplexity is 46.362201690665465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559932454427083 and perplexity of 95.57702380720013
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 761.8844788074493 and batch: 50, loss is 4.113708300590515 and perplexity is 61.173145891037365
At time: 763.0884082317352 and batch: 100, loss is 4.127403297424316 and perplexity is 62.0166748094428
At time: 764.2717416286469 and batch: 150, loss is 4.096195225715637 and perplexity is 60.11114262168691
At time: 765.4609649181366 and batch: 200, loss is 4.085704216957092 and perplexity is 59.48381251449934
At time: 766.6530270576477 and batch: 250, loss is 4.078266463279724 and perplexity is 59.04302782521971
At time: 767.8496143817902 and batch: 300, loss is 4.078902068138123 and perplexity is 59.080567789588045
At time: 769.0496470928192 and batch: 350, loss is 4.065762729644775 and perplexity is 58.30936584783692
At time: 770.2492067813873 and batch: 400, loss is 4.07468035697937 and perplexity is 58.831672449071995
At time: 771.4499270915985 and batch: 450, loss is 4.018183875083923 and perplexity is 55.60003746481531
At time: 772.6484649181366 and batch: 500, loss is 4.092774047851562 and perplexity is 59.90584309450756
At time: 773.8502550125122 and batch: 550, loss is 4.080197916030884 and perplexity is 59.157176844982516
At time: 775.0556039810181 and batch: 600, loss is 4.022251563072205 and perplexity is 55.826661675169554
At time: 776.2563891410828 and batch: 650, loss is 4.030551400184631 and perplexity is 56.291942078393845
At time: 777.4553170204163 and batch: 700, loss is 4.033889918327332 and perplexity is 56.48018780435189
At time: 778.6534309387207 and batch: 750, loss is 3.990296792984009 and perplexity is 54.07093485621808
At time: 779.8548882007599 and batch: 800, loss is 3.9504841661453245 and perplexity is 51.960518269443114
At time: 781.0554521083832 and batch: 850, loss is 3.9213688802719116 and perplexity is 50.469484195185096
At time: 782.2546656131744 and batch: 900, loss is 3.9417161035537718 and perplexity is 51.50691670246213
At time: 783.4535658359528 and batch: 950, loss is 3.9195054960250855 and perplexity is 50.37552771908538
At time: 784.6518335342407 and batch: 1000, loss is 3.937172737121582 and perplexity is 51.27343270939356
At time: 785.8502032756805 and batch: 1050, loss is 3.8657895708084107 and perplexity is 47.740952417617756
At time: 787.0485467910767 and batch: 1100, loss is 3.840277066230774 and perplexity is 46.53836686357238
At time: 788.2998905181885 and batch: 1150, loss is 3.857252125740051 and perplexity is 47.335101588554586
At time: 789.5055530071259 and batch: 1200, loss is 3.828072872161865 and perplexity is 45.97385531359676
At time: 790.7058219909668 and batch: 1250, loss is 3.878911862373352 and perplexity is 48.371551518678075
At time: 791.9048511981964 and batch: 1300, loss is 3.859332590103149 and perplexity is 47.433683092628456
At time: 793.1047179698944 and batch: 1350, loss is 3.830741009712219 and perplexity is 46.09668367190355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5597932942708335 and perplexity of 95.56372421904106
Finished 23 epochs...
Completing Train Step...
At time: 796.5634121894836 and batch: 50, loss is 4.113362398147583 and perplexity is 61.15198960964746
At time: 797.7383337020874 and batch: 100, loss is 4.126767234802246 and perplexity is 61.97724086321055
At time: 798.9205601215363 and batch: 150, loss is 4.095350251197815 and perplexity is 60.06037169102655
At time: 800.114049911499 and batch: 200, loss is 4.084678521156311 and perplexity is 59.42283149712178
At time: 801.3080785274506 and batch: 250, loss is 4.077159085273743 and perplexity is 58.97768106326082
At time: 802.5092191696167 and batch: 300, loss is 4.0777423620224 and perplexity is 59.012091407716106
At time: 803.7117726802826 and batch: 350, loss is 4.064671349525452 and perplexity is 58.24576287900128
At time: 804.9173662662506 and batch: 400, loss is 4.07355224609375 and perplexity is 58.765341220488075
At time: 806.1261928081512 and batch: 450, loss is 4.017097988128662 and perplexity is 55.53969487796361
At time: 807.3312108516693 and batch: 500, loss is 4.091757106781006 and perplexity is 59.84495334818787
At time: 808.5321311950684 and batch: 550, loss is 4.079109153747559 and perplexity is 59.09280379188082
At time: 809.7327916622162 and batch: 600, loss is 4.021222171783447 and perplexity is 55.769223764075356
At time: 810.9338924884796 and batch: 650, loss is 4.029537320137024 and perplexity is 56.234886477453806
At time: 812.1346001625061 and batch: 700, loss is 4.033105783462524 and perplexity is 56.435917079301504
At time: 813.335090637207 and batch: 750, loss is 3.9895818614959717 and perplexity is 54.032291657567484
At time: 814.5350615978241 and batch: 800, loss is 3.9500388002395628 and perplexity is 51.937381978600186
At time: 815.7362506389618 and batch: 850, loss is 3.9211900568008424 and perplexity is 50.46045987374253
At time: 816.937371969223 and batch: 900, loss is 3.9417154693603518 and perplexity is 51.50688403712483
At time: 818.1652100086212 and batch: 950, loss is 3.9195415496826174 and perplexity is 50.37734397385087
At time: 819.365692615509 and batch: 1000, loss is 3.9372864294052126 and perplexity is 51.27926243443897
At time: 820.56591963768 and batch: 1050, loss is 3.8660337781906127 and perplexity is 47.75261253431683
At time: 821.7667229175568 and batch: 1100, loss is 3.840653886795044 and perplexity is 46.555906781727494
At time: 822.9668555259705 and batch: 1150, loss is 3.857778615951538 and perplexity is 47.36002961780657
At time: 824.1681787967682 and batch: 1200, loss is 3.828722987174988 and perplexity is 46.00375332466716
At time: 825.3685929775238 and batch: 1250, loss is 3.87958824634552 and perplexity is 48.40428032820754
At time: 826.5700676441193 and batch: 1300, loss is 3.860046834945679 and perplexity is 47.46757445806524
At time: 827.7710380554199 and batch: 1350, loss is 3.831401643753052 and perplexity is 46.127146771679115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559548746744792 and perplexity of 95.54035720399327
Finished 24 epochs...
Completing Train Step...
At time: 831.2076778411865 and batch: 50, loss is 4.113119683265686 and perplexity is 61.137148912813444
At time: 832.3822245597839 and batch: 100, loss is 4.126268444061279 and perplexity is 61.946334897762746
At time: 833.5586543083191 and batch: 150, loss is 4.094698452949524 and perplexity is 60.02123720124807
At time: 834.7464094161987 and batch: 200, loss is 4.083881993293762 and perplexity is 59.37551840176361
At time: 835.9464106559753 and batch: 250, loss is 4.076347222328186 and perplexity is 58.929818700858895
At time: 837.1464967727661 and batch: 300, loss is 4.076889395713806 and perplexity is 58.96177754301186
At time: 838.3461036682129 and batch: 350, loss is 4.063868618011474 and perplexity is 58.199025930702966
At time: 839.5467462539673 and batch: 400, loss is 4.072706627845764 and perplexity is 58.715669180354595
At time: 840.7478749752045 and batch: 450, loss is 4.0162830686569215 and perplexity is 55.494452935926525
At time: 841.948490858078 and batch: 500, loss is 4.090994520187378 and perplexity is 59.79933378571243
At time: 843.1489307880402 and batch: 550, loss is 4.0783138799667356 and perplexity is 59.045827516365826
At time: 844.3498823642731 and batch: 600, loss is 4.0204804992675784 and perplexity is 55.72787659850173
At time: 845.5497834682465 and batch: 650, loss is 4.028813924789429 and perplexity is 56.19422113253747
At time: 846.7509152889252 and batch: 700, loss is 4.032538084983826 and perplexity is 56.40388758743876
At time: 847.9519808292389 and batch: 750, loss is 3.9890744924545287 and perplexity is 54.00488429895279
At time: 849.1895680427551 and batch: 800, loss is 3.9497038459777833 and perplexity is 51.919988244376114
At time: 850.3898549079895 and batch: 850, loss is 3.9210456943511964 and perplexity is 50.45317580393063
At time: 851.5897130966187 and batch: 900, loss is 3.9417159509658815 and perplexity is 51.50690884313097
At time: 852.7907609939575 and batch: 950, loss is 3.9195800495147703 and perplexity is 50.37928353047424
At time: 853.9909451007843 and batch: 1000, loss is 3.9373931455612183 and perplexity is 51.28473505221196
At time: 855.1909132003784 and batch: 1050, loss is 3.8662323188781738 and perplexity is 47.762094312070424
At time: 856.3908410072327 and batch: 1100, loss is 3.8409605836868286 and perplexity is 46.57018752344926
At time: 857.5908551216125 and batch: 1150, loss is 3.858190588951111 and perplexity is 47.37954469083366
At time: 858.793347120285 and batch: 1200, loss is 3.8292230987548828 and perplexity is 46.026766088418626
At time: 859.9976780414581 and batch: 1250, loss is 3.8801183795928953 and perplexity is 48.429947849526876
At time: 861.1978151798248 and batch: 1300, loss is 3.8605692481994627 and perplexity is 47.492378626536166
At time: 862.3977491855621 and batch: 1350, loss is 3.8318827962875366 and perplexity is 46.14934630550956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559388427734375 and perplexity of 95.52504149620385
Finished 25 epochs...
Completing Train Step...
At time: 865.8186447620392 and batch: 50, loss is 4.112869963645935 and perplexity is 61.121883673328526
At time: 867.0160222053528 and batch: 100, loss is 4.125821080207825 and perplexity is 61.91862854454806
At time: 868.1972570419312 and batch: 150, loss is 4.0941379308700565 and perplexity is 59.9876033996846
At time: 869.3806629180908 and batch: 200, loss is 4.0832154130935665 and perplexity is 59.335953045027374
At time: 870.5727603435516 and batch: 250, loss is 4.075676965713501 and perplexity is 58.890333834047205
At time: 871.7689073085785 and batch: 300, loss is 4.07619119644165 and perplexity is 58.92062484091141
At time: 872.9680163860321 and batch: 350, loss is 4.063211059570312 and perplexity is 58.16076924931517
At time: 874.1674084663391 and batch: 400, loss is 4.072010507583618 and perplexity is 58.67481023635208
At time: 875.3668205738068 and batch: 450, loss is 4.015615735054016 and perplexity is 55.45743197674646
At time: 876.5651299953461 and batch: 500, loss is 4.090372233390808 and perplexity is 59.76213302582525
At time: 877.7648746967316 and batch: 550, loss is 4.077680158615112 and perplexity is 59.00842076872365
At time: 878.9916265010834 and batch: 600, loss is 4.019890503883362 and perplexity is 55.69500710591435
At time: 880.1896834373474 and batch: 650, loss is 4.028244385719299 and perplexity is 56.16222544035027
At time: 881.3890552520752 and batch: 700, loss is 4.032092022895813 and perplexity is 56.37873356211505
At time: 882.5877153873444 and batch: 750, loss is 3.988676738739014 and perplexity is 53.98340792700344
At time: 883.7861511707306 and batch: 800, loss is 3.9494277906417845 and perplexity is 51.90565743271578
At time: 884.9849274158478 and batch: 850, loss is 3.9209111881256105 and perplexity is 50.446389994061484
At time: 886.1846189498901 and batch: 900, loss is 3.9417002153396608 and perplexity is 51.50609835604241
At time: 887.3834674358368 and batch: 950, loss is 3.919603843688965 and perplexity is 50.38048227818391
At time: 888.5824480056763 and batch: 1000, loss is 3.937476062774658 and perplexity is 51.288987615837414
At time: 889.781646490097 and batch: 1050, loss is 3.8663872480392456 and perplexity is 47.76949462652068
At time: 890.9804887771606 and batch: 1100, loss is 3.8412026929855347 and perplexity is 46.58146396390164
At time: 892.1816599369049 and batch: 1150, loss is 3.858509135246277 and perplexity is 47.394639673359315
At time: 893.3806416988373 and batch: 1200, loss is 3.8296103143692015 and perplexity is 46.0445918219031
At time: 894.578455209732 and batch: 1250, loss is 3.88053261756897 and perplexity is 48.45001352880172
At time: 895.7777893543243 and batch: 1300, loss is 3.86096378326416 and perplexity is 47.511119731978745
At time: 896.9778044223785 and batch: 1350, loss is 3.8322435235977172 and perplexity is 46.16599663800322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55927978515625 and perplexity of 95.51466397315086
Finished 26 epochs...
Completing Train Step...
At time: 900.385148525238 and batch: 50, loss is 4.112607250213623 and perplexity is 61.1058282425603
At time: 901.5813274383545 and batch: 100, loss is 4.125406103134155 and perplexity is 61.89293906391044
At time: 902.7689056396484 and batch: 150, loss is 4.093634562492371 and perplexity is 59.95741513562621
At time: 903.9628624916077 and batch: 200, loss is 4.082633919715882 and perplexity is 59.30145961109672
At time: 905.1614801883698 and batch: 250, loss is 4.075094294548035 and perplexity is 58.85603012945773
At time: 906.3613064289093 and batch: 300, loss is 4.075592312812805 and perplexity is 58.885348807466684
At time: 907.5600271224976 and batch: 350, loss is 4.062643508911133 and perplexity is 58.12776943180927
At time: 908.7593286037445 and batch: 400, loss is 4.071413292884826 and perplexity is 58.63977923878462
At time: 909.9952533245087 and batch: 450, loss is 4.015045833587647 and perplexity is 55.4258357091766
At time: 911.1959991455078 and batch: 500, loss is 4.089842209815979 and perplexity is 59.7304660792949
At time: 912.3948397636414 and batch: 550, loss is 4.077150263786316 and perplexity is 58.97716079468363
At time: 913.5934762954712 and batch: 600, loss is 4.019395766258239 and perplexity is 55.66745950534672
At time: 914.7923550605774 and batch: 650, loss is 4.02777069568634 and perplexity is 56.135628253838775
At time: 915.9909899234772 and batch: 700, loss is 4.031721782684326 and perplexity is 56.357863751537614
At time: 917.1902875900269 and batch: 750, loss is 3.9883467054367063 and perplexity is 53.965594544281934
At time: 918.3886427879333 and batch: 800, loss is 3.9491886854171754 and perplexity is 51.893248002475765
At time: 919.5877974033356 and batch: 850, loss is 3.9207798194885255 and perplexity is 50.43976335583785
At time: 920.7874064445496 and batch: 900, loss is 3.9416663074493408 and perplexity is 51.50435192251765
At time: 921.9874229431152 and batch: 950, loss is 3.9196101903915403 and perplexity is 50.38080202913522
At time: 923.1861009597778 and batch: 1000, loss is 3.9375344371795653 and perplexity is 51.29198166735492
At time: 924.3848078250885 and batch: 1050, loss is 3.8665052127838133 and perplexity is 47.775130075138016
At time: 925.5836372375488 and batch: 1100, loss is 3.8413908767700193 and perplexity is 46.59023066492682
At time: 926.7817339897156 and batch: 1150, loss is 3.858755660057068 and perplexity is 47.406325068247995
At time: 927.9790728092194 and batch: 1200, loss is 3.829912738800049 and perplexity is 46.05851893722225
At time: 929.1772892475128 and batch: 1250, loss is 3.8808584594726563 and perplexity is 48.465803145763296
At time: 930.3745603561401 and batch: 1300, loss is 3.861268010139465 and perplexity is 47.52557609037192
At time: 931.5712177753448 and batch: 1350, loss is 3.832519841194153 and perplexity is 46.1787548778132
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559204508463542 and perplexity of 95.50747421575576
Finished 27 epochs...
Completing Train Step...
At time: 935.0132887363434 and batch: 50, loss is 4.112334518432617 and perplexity is 61.089165013593245
At time: 936.182256937027 and batch: 100, loss is 4.12501365184784 and perplexity is 61.86865386605122
At time: 937.3543803691864 and batch: 150, loss is 4.093171687126159 and perplexity is 59.92966874719348
At time: 938.5371778011322 and batch: 200, loss is 4.08211238861084 and perplexity is 59.270540118774484
At time: 939.75439286232 and batch: 250, loss is 4.074571895599365 and perplexity is 58.82529183072174
At time: 940.9518594741821 and batch: 300, loss is 4.0750621318817135 and perplexity is 58.854137193040785
At time: 942.1491949558258 and batch: 350, loss is 4.062137145996093 and perplexity is 58.098343135856254
At time: 943.3466453552246 and batch: 400, loss is 4.07088577747345 and perplexity is 58.608854009001234
At time: 944.543999671936 and batch: 450, loss is 4.014544677734375 and perplexity is 55.39806568632446
At time: 945.7423679828644 and batch: 500, loss is 4.089376463890075 and perplexity is 59.70265333540499
At time: 946.9406607151031 and batch: 550, loss is 4.076691188812256 and perplexity is 58.950092069884136
At time: 948.13933801651 and batch: 600, loss is 4.0189662313461305 and perplexity is 55.64355352261542
At time: 949.3368031978607 and batch: 650, loss is 4.027361664772034 and perplexity is 56.11267174177058
At time: 950.5356392860413 and batch: 700, loss is 4.031400990486145 and perplexity is 56.339787488057134
At time: 951.7379212379456 and batch: 750, loss is 3.988060975074768 and perplexity is 53.950177138135984
At time: 952.9388542175293 and batch: 800, loss is 3.948973970413208 and perplexity is 51.882106939644515
At time: 954.1483016014099 and batch: 850, loss is 3.9206491613388064 and perplexity is 50.43317342020928
At time: 955.3535528182983 and batch: 900, loss is 3.9416162538528443 and perplexity is 51.50177400898617
At time: 956.549188375473 and batch: 950, loss is 3.919600658416748 and perplexity is 50.38032180288903
At time: 957.7472891807556 and batch: 1000, loss is 3.9375703382492064 and perplexity is 51.29382313741596
At time: 958.9499759674072 and batch: 1050, loss is 3.866592493057251 and perplexity is 47.77930008353158
At time: 960.1477255821228 and batch: 1100, loss is 3.8415354919433593 and perplexity is 46.59696880641739
At time: 961.3428373336792 and batch: 1150, loss is 3.8589467859268187 and perplexity is 47.415386509268664
At time: 962.5388586521149 and batch: 1200, loss is 3.8301504945755003 and perplexity is 46.06947091800507
At time: 963.7448828220367 and batch: 1250, loss is 3.8811173677444457 and perplexity is 48.478352967652896
At time: 964.9502034187317 and batch: 1300, loss is 3.861507077217102 and perplexity is 47.536939249185316
At time: 966.1492388248444 and batch: 1350, loss is 3.8327356290817263 and perplexity is 46.18872076899968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559149576822917 and perplexity of 95.50222797759872
Finished 28 epochs...
Completing Train Step...
At time: 969.7301297187805 and batch: 50, loss is 4.112055149078369 and perplexity is 61.07210095671008
At time: 970.8960976600647 and batch: 100, loss is 4.124637956619263 and perplexity is 61.845414473733015
At time: 972.364976644516 and batch: 150, loss is 4.092739081382751 and perplexity is 59.903748435335025
At time: 973.5248548984528 and batch: 200, loss is 4.081635103225708 and perplexity is 59.24225790608722
At time: 974.6993930339813 and batch: 250, loss is 4.0740938472747805 and perplexity is 58.79717721912577
At time: 975.8812811374664 and batch: 300, loss is 4.074581933021546 and perplexity is 58.82588228797407
At time: 977.0834028720856 and batch: 350, loss is 4.061675381660462 and perplexity is 58.071521586130956
At time: 978.282553434372 and batch: 400, loss is 4.070409374237061 and perplexity is 58.58093921114827
At time: 979.4759268760681 and batch: 450, loss is 4.0140929031372075 and perplexity is 55.373043900044436
At time: 980.6675307750702 and batch: 500, loss is 4.088956747055054 and perplexity is 59.67760038464505
At time: 981.858555316925 and batch: 550, loss is 4.076282396316528 and perplexity is 58.925998639565776
At time: 983.0587906837463 and batch: 600, loss is 4.018582944869995 and perplexity is 55.62223018780006
At time: 984.2576916217804 and batch: 650, loss is 4.026997661590576 and perplexity is 56.092250267702724
At time: 985.4568417072296 and batch: 700, loss is 4.031113948822021 and perplexity is 56.32361794247783
At time: 986.65625 and batch: 750, loss is 3.9878050184249876 and perplexity is 53.93636999863062
At time: 987.8555490970612 and batch: 800, loss is 3.9487758922576903 and perplexity is 51.871831245326426
At time: 989.0548148155212 and batch: 850, loss is 3.9205184459686278 and perplexity is 50.426581460121014
At time: 990.2535326480865 and batch: 900, loss is 3.941552734375 and perplexity is 51.49850274708859
At time: 991.4527630805969 and batch: 950, loss is 3.9195770835876464 and perplexity is 50.37913410941232
At time: 992.6516070365906 and batch: 1000, loss is 3.9375872135162355 and perplexity is 51.29468874168198
At time: 993.8500845432281 and batch: 1050, loss is 3.866654872894287 and perplexity is 47.78228064144689
At time: 995.047966003418 and batch: 1100, loss is 3.841645474433899 and perplexity is 46.60209393893057
At time: 996.2464802265167 and batch: 1150, loss is 3.8590946340560914 and perplexity is 47.42239730371645
At time: 997.4446284770966 and batch: 1200, loss is 3.830339107513428 and perplexity is 46.07816103577224
At time: 998.6424343585968 and batch: 1250, loss is 3.881324973106384 and perplexity is 48.4884183784474
At time: 999.8604190349579 and batch: 1300, loss is 3.8616974544525147 and perplexity is 47.54599006176656
At time: 1001.0711843967438 and batch: 1350, loss is 3.8329065656661987 and perplexity is 46.196616786008946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559108479817708 and perplexity of 95.49830320268688
Finished 29 epochs...
Completing Train Step...
At time: 1004.7063612937927 and batch: 50, loss is 4.111772027015686 and perplexity is 61.0548125449957
At time: 1005.9060697555542 and batch: 100, loss is 4.124275398254395 and perplexity is 61.822995965641226
At time: 1007.0672850608826 and batch: 150, loss is 4.092329926490784 and perplexity is 59.87924353710689
At time: 1008.2457613945007 and batch: 200, loss is 4.0811915826797485 and perplexity is 59.21598857344182
At time: 1009.4313855171204 and batch: 250, loss is 4.073649587631226 and perplexity is 58.77106180757363
At time: 1010.6272399425507 and batch: 300, loss is 4.074139356613159 and perplexity is 58.79985310064788
At time: 1011.8244199752808 and batch: 350, loss is 4.061247191429138 and perplexity is 58.04666125072591
At time: 1013.019784450531 and batch: 400, loss is 4.069971652030945 and perplexity is 58.555302644457015
At time: 1014.2181594371796 and batch: 450, loss is 4.013678226470947 and perplexity is 55.35008675102527
At time: 1015.4225492477417 and batch: 500, loss is 4.088571176528931 and perplexity is 59.65459489627113
At time: 1016.6180226802826 and batch: 550, loss is 4.075910186767578 and perplexity is 58.90406990148673
At time: 1017.8136503696442 and batch: 600, loss is 4.018233981132507 and perplexity is 55.60282343279014
At time: 1019.0093433856964 and batch: 650, loss is 4.0266660833358765 and perplexity is 56.0736543804231
At time: 1020.2054271697998 and batch: 700, loss is 4.030850305557251 and perplexity is 56.30877055725234
At time: 1021.4012894630432 and batch: 750, loss is 3.987569713592529 and perplexity is 53.923680003191855
At time: 1022.6444041728973 and batch: 800, loss is 3.948589243888855 and perplexity is 51.86215035612518
At time: 1023.84077501297 and batch: 850, loss is 3.9203871488571167 and perplexity is 50.41996103026309
At time: 1025.037823677063 and batch: 900, loss is 3.941478452682495 and perplexity is 51.494677493217985
At time: 1026.2327587604523 and batch: 950, loss is 3.9195416307449342 and perplexity is 50.37734805755526
At time: 1027.429402589798 and batch: 1000, loss is 3.937587785720825 and perplexity is 51.29471809274669
At time: 1028.6245021820068 and batch: 1050, loss is 3.8666970491409303 and perplexity is 47.784295961199405
At time: 1029.8203644752502 and batch: 1100, loss is 3.8417274856567385 and perplexity is 46.60591599036479
At time: 1031.0156004428864 and batch: 1150, loss is 3.8592085790634156 and perplexity is 47.42780115698976
At time: 1032.2106680870056 and batch: 1200, loss is 3.830489363670349 and perplexity is 46.08508508334483
At time: 1033.4062943458557 and batch: 1250, loss is 3.88149302482605 and perplexity is 48.496567625268064
At time: 1034.601436138153 and batch: 1300, loss is 3.86185106754303 and perplexity is 47.55329430924121
At time: 1035.7975165843964 and batch: 1350, loss is 3.8330439376831054 and perplexity is 46.20296334434088
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559080403645833 and perplexity of 95.4956220135513
Finished 30 epochs...
Completing Train Step...
At time: 1039.2270634174347 and batch: 50, loss is 4.111487336158753 and perplexity is 61.037433272069805
At time: 1040.4137539863586 and batch: 100, loss is 4.123923687934876 and perplexity is 61.80125600328518
At time: 1041.5956525802612 and batch: 150, loss is 4.091939826011657 and perplexity is 59.85588917108418
At time: 1042.7925691604614 and batch: 200, loss is 4.080774517059326 and perplexity is 59.191296769837614
At time: 1043.9912841320038 and batch: 250, loss is 4.07323191165924 and perplexity is 58.74651967289529
At time: 1045.191294670105 and batch: 300, loss is 4.073725724220276 and perplexity is 58.7755366061003
At time: 1046.3960497379303 and batch: 350, loss is 4.060844902992248 and perplexity is 58.02331444649424
At time: 1047.5963671207428 and batch: 400, loss is 4.069563384056091 and perplexity is 58.53140126904451
At time: 1048.79558634758 and batch: 450, loss is 4.013291673660278 and perplexity is 55.3286951541782
At time: 1049.9947612285614 and batch: 500, loss is 4.088211917877198 and perplexity is 59.633167316191226
At time: 1051.1942489147186 and batch: 550, loss is 4.075565185546875 and perplexity is 58.883751430616506
At time: 1052.39351272583 and batch: 600, loss is 4.017910475730896 and perplexity is 55.584838528328525
At time: 1053.625827550888 and batch: 650, loss is 4.026358423233032 and perplexity is 56.05640540769596
At time: 1054.825365781784 and batch: 700, loss is 4.030603375434875 and perplexity is 56.29486794220569
At time: 1056.0230915546417 and batch: 750, loss is 3.9873490047454836 and perplexity is 53.91177988322907
At time: 1057.2203726768494 and batch: 800, loss is 3.948410277366638 and perplexity is 51.85286959793853
At time: 1058.4192609786987 and batch: 850, loss is 3.920254974365234 and perplexity is 50.413297237934565
At time: 1059.616324186325 and batch: 900, loss is 3.941395378112793 and perplexity is 51.49039977273065
At time: 1060.8137090206146 and batch: 950, loss is 3.9194961643218993 and perplexity is 50.37505763180622
At time: 1062.0109753608704 and batch: 1000, loss is 3.937574782371521 and perplexity is 51.2940510939465
At time: 1063.2086398601532 and batch: 1050, loss is 3.8667223167419436 and perplexity is 47.78550337097857
At time: 1064.406044960022 and batch: 1100, loss is 3.841787118911743 and perplexity is 46.60869533570766
At time: 1065.603406906128 and batch: 1150, loss is 3.859295811653137 and perplexity is 47.43193858736624
At time: 1066.800743818283 and batch: 1200, loss is 3.8306095933914186 and perplexity is 46.09062621336745
At time: 1068.0013880729675 and batch: 1250, loss is 3.8816301012039185 and perplexity is 48.50321581474165
At time: 1069.2022693157196 and batch: 1300, loss is 3.8619764471054077 and perplexity is 47.559256894256656
At time: 1070.3997430801392 and batch: 1350, loss is 3.833155703544617 and perplexity is 46.20812754692884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5590576171875 and perplexity of 95.49344603133089
Finished 31 epochs...
Completing Train Step...
At time: 1073.8583557605743 and batch: 50, loss is 4.111202411651611 and perplexity is 61.020044688811964
At time: 1075.0268092155457 and batch: 100, loss is 4.123581166267395 and perplexity is 61.78009135890811
At time: 1076.2198827266693 and batch: 150, loss is 4.091565270423889 and perplexity is 59.833474011457994
At time: 1077.4144592285156 and batch: 200, loss is 4.080378637313843 and perplexity is 59.167868771978455
At time: 1078.6054923534393 and batch: 250, loss is 4.072835612297058 and perplexity is 58.72324307717314
At time: 1079.7992358207703 and batch: 300, loss is 4.073334841728211 and perplexity is 58.75256676742558
At time: 1080.9974455833435 and batch: 350, loss is 4.0604634189605715 and perplexity is 58.0011837000995
At time: 1082.1953229904175 and batch: 400, loss is 4.069178714752197 and perplexity is 58.50889036556674
At time: 1083.4350922107697 and batch: 450, loss is 4.012927284240723 and perplexity is 55.308537635882445
At time: 1084.626036643982 and batch: 500, loss is 4.087872571945191 and perplexity is 59.61293447660985
At time: 1085.821980714798 and batch: 550, loss is 4.075240941047668 and perplexity is 58.8646617931447
At time: 1087.0200624465942 and batch: 600, loss is 4.017606716156006 and perplexity is 55.567956665550376
At time: 1088.2186539173126 and batch: 650, loss is 4.026068987846375 and perplexity is 56.0401830480979
At time: 1089.4155220985413 and batch: 700, loss is 4.030368995666504 and perplexity is 56.28167511022375
At time: 1090.6140615940094 and batch: 750, loss is 3.987138910293579 and perplexity is 53.90045450712431
At time: 1091.8108377456665 and batch: 800, loss is 3.948236927986145 and perplexity is 51.84388171416148
At time: 1093.0074338912964 and batch: 850, loss is 3.9201221084594726 and perplexity is 50.40659947449667
At time: 1094.2044961452484 and batch: 900, loss is 3.9413054513931276 and perplexity is 51.48576961817525
At time: 1095.4011495113373 and batch: 950, loss is 3.9194421100616457 and perplexity is 50.37233471892389
At time: 1096.5983827114105 and batch: 1000, loss is 3.9375502681732177 and perplexity is 51.292793676818555
At time: 1097.7957832813263 and batch: 1050, loss is 3.866733903884888 and perplexity is 47.786057071644684
At time: 1098.9923875331879 and batch: 1100, loss is 3.8418286085128783 and perplexity is 46.61062915200292
At time: 1100.1958830356598 and batch: 1150, loss is 3.85936137676239 and perplexity is 47.43504856955384
At time: 1101.3981311321259 and batch: 1200, loss is 3.830705943107605 and perplexity is 46.095067246064644
At time: 1102.5946073532104 and batch: 1250, loss is 3.881742544174194 and perplexity is 48.50866996703058
At time: 1103.7912702560425 and batch: 1300, loss is 3.862079825401306 and perplexity is 47.564173743331935
At time: 1104.9881007671356 and batch: 1350, loss is 3.8332478523254396 and perplexity is 46.21238576573822
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559041341145833 and perplexity of 95.49189178867283
Finished 32 epochs...
Completing Train Step...
At time: 1108.4713180065155 and batch: 50, loss is 4.110918307304383 and perplexity is 61.002711091239604
At time: 1109.6437690258026 and batch: 100, loss is 4.123246269226074 and perplexity is 61.759404853217596
At time: 1110.8224577903748 and batch: 150, loss is 4.091203589439392 and perplexity is 59.81183729470202
At time: 1112.0148491859436 and batch: 200, loss is 4.079999904632569 and perplexity is 59.145464209331
At time: 1113.251222372055 and batch: 250, loss is 4.072456841468811 and perplexity is 58.7010046376574
At time: 1114.4486002922058 and batch: 300, loss is 4.072962455749511 and perplexity is 58.73069220849109
At time: 1115.6467051506042 and batch: 350, loss is 4.060098958015442 and perplexity is 57.98004838560184
At time: 1116.84499168396 and batch: 400, loss is 4.068813014030456 and perplexity is 58.4874975340572
At time: 1118.042881011963 and batch: 450, loss is 4.012580561637878 and perplexity is 55.289364239870764
At time: 1119.2417385578156 and batch: 500, loss is 4.087549333572388 and perplexity is 59.59366840260657
At time: 1120.4390547275543 and batch: 550, loss is 4.074932851791382 and perplexity is 58.84652901667154
At time: 1121.6369915008545 and batch: 600, loss is 4.017318391799927 and perplexity is 55.55193737971226
At time: 1122.8337187767029 and batch: 650, loss is 4.025793414115906 and perplexity is 56.02474197347417
At time: 1124.031614780426 and batch: 700, loss is 4.0301438999176025 and perplexity is 56.26900777015106
At time: 1125.2286188602448 and batch: 750, loss is 3.9869365310668945 and perplexity is 53.88954727855868
At time: 1126.426421880722 and batch: 800, loss is 3.9480677366256716 and perplexity is 51.83511091927433
At time: 1127.6238613128662 and batch: 850, loss is 3.9199881410598754 and perplexity is 50.39984708575261
At time: 1128.8210866451263 and batch: 900, loss is 3.941209807395935 and perplexity is 51.480845548853026
At time: 1130.018185377121 and batch: 950, loss is 3.9193810987472535 and perplexity is 50.36926153032427
At time: 1131.2169575691223 and batch: 1000, loss is 3.937516031265259 and perplexity is 51.29103760022397
At time: 1132.4193496704102 and batch: 1050, loss is 3.866733875274658 and perplexity is 47.786055704474634
At time: 1133.617215871811 and batch: 1100, loss is 3.8418552350997923 and perplexity is 46.611870250494185
At time: 1134.8147797584534 and batch: 1150, loss is 3.859409489631653 and perplexity is 47.437330860747494
At time: 1136.011889219284 and batch: 1200, loss is 3.8307829189300535 and perplexity is 46.098615588343264
At time: 1137.2088294029236 and batch: 1250, loss is 3.8818352031707763 and perplexity is 48.51316493996188
At time: 1138.4060447216034 and batch: 1300, loss is 3.862165479660034 and perplexity is 47.56824799186181
At time: 1139.6060366630554 and batch: 1350, loss is 3.8333240604400634 and perplexity is 46.2159076587264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559031575520834 and perplexity of 95.49095925522053
Finished 33 epochs...
Completing Train Step...
At time: 1143.0651407241821 and batch: 50, loss is 4.1106355047225955 and perplexity is 60.98546180623311
At time: 1144.2541725635529 and batch: 100, loss is 4.122918410301208 and perplexity is 61.73915980008409
At time: 1145.4283680915833 and batch: 150, loss is 4.0908530950546265 and perplexity is 59.79087725499042
At time: 1146.6123311519623 and batch: 200, loss is 4.079635376930237 and perplexity is 59.12390797831981
At time: 1147.8069117069244 and batch: 250, loss is 4.072092757225037 and perplexity is 58.67963641692741
At time: 1149.00350689888 and batch: 300, loss is 4.072605066299438 and perplexity is 58.70970622900749
At time: 1150.2018504142761 and batch: 350, loss is 4.059748387336731 and perplexity is 57.959725843139466
At time: 1151.4008357524872 and batch: 400, loss is 4.06846254825592 and perplexity is 58.467003259413914
At time: 1152.5982115268707 and batch: 450, loss is 4.0122480392456055 and perplexity is 55.270982344571756
At time: 1153.7979640960693 and batch: 500, loss is 4.087238945960999 and perplexity is 59.57517413656118
At time: 1155.000012397766 and batch: 550, loss is 4.074637565612793 and perplexity is 58.82915501527247
At time: 1156.200157880783 and batch: 600, loss is 4.017042255401611 and perplexity is 55.53659958556382
At time: 1157.4041967391968 and batch: 650, loss is 4.025528812408448 and perplexity is 56.00991969217502
At time: 1158.6013185977936 and batch: 700, loss is 4.029925928115845 and perplexity is 56.25674404976547
At time: 1159.7992658615112 and batch: 750, loss is 3.98673996925354 and perplexity is 53.878955692409555
At time: 1160.9968690872192 and batch: 800, loss is 3.947901110649109 and perplexity is 51.82647456283781
At time: 1162.194002866745 and batch: 850, loss is 3.9198537635803223 and perplexity is 50.39307493635375
At time: 1163.3938093185425 and batch: 900, loss is 3.9411095714569093 and perplexity is 51.47568557656925
At time: 1164.590897321701 and batch: 950, loss is 3.9193140506744384 and perplexity is 50.36588448162311
At time: 1165.7883470058441 and batch: 1000, loss is 3.937473726272583 and perplexity is 51.288867779151424
At time: 1166.9862158298492 and batch: 1050, loss is 3.8667244482040406 and perplexity is 47.785605224076335
At time: 1168.1886143684387 and batch: 1100, loss is 3.8418697261810304 and perplexity is 46.612545711786716
At time: 1169.3882868289948 and batch: 1150, loss is 3.8594432353973387 and perplexity is 47.43893169681005
At time: 1170.585652589798 and batch: 1200, loss is 3.830843963623047 and perplexity is 46.10142975007322
At time: 1171.7834177017212 and batch: 1250, loss is 3.8819117832183836 and perplexity is 48.516880222699015
At time: 1172.9807074069977 and batch: 1300, loss is 3.8622367668151854 and perplexity is 47.57163911780711
At time: 1174.1786954402924 and batch: 1350, loss is 3.833387589454651 and perplexity is 46.21884380306242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559025472005208 and perplexity of 95.4903764264373
Finished 34 epochs...
Completing Train Step...
At time: 1177.660071849823 and batch: 50, loss is 4.11035445690155 and perplexity is 60.96832438340752
At time: 1178.8597860336304 and batch: 100, loss is 4.122596769332886 and perplexity is 61.71930515014816
At time: 1180.0362203121185 and batch: 150, loss is 4.090512022972107 and perplexity is 59.770487733315385
At time: 1181.2176342010498 and batch: 200, loss is 4.079282841682434 and perplexity is 59.10306839033009
At time: 1182.3999156951904 and batch: 250, loss is 4.071741032600403 and perplexity is 58.659000973044606
At time: 1183.592541694641 and batch: 300, loss is 4.072260198593139 and perplexity is 58.68946263816381
At time: 1184.7888927459717 and batch: 350, loss is 4.0594093799591064 and perplexity is 57.94008039863703
At time: 1185.9865992069244 and batch: 400, loss is 4.068124985694885 and perplexity is 58.44727031879599
At time: 1187.1841957569122 and batch: 450, loss is 4.011927275657654 and perplexity is 55.25325626905709
At time: 1188.3804051876068 and batch: 500, loss is 4.0869390439987185 and perplexity is 59.55731010379758
At time: 1189.5784571170807 and batch: 550, loss is 4.074352693557739 and perplexity is 58.812398619813926
At time: 1190.7750573158264 and batch: 600, loss is 4.0167761898040775 and perplexity is 55.52182517257877
At time: 1191.977639913559 and batch: 650, loss is 4.0252730178833005 and perplexity is 55.99559449359562
At time: 1193.1749114990234 and batch: 700, loss is 4.029713358879089 and perplexity is 56.244786867530024
At time: 1194.3725924491882 and batch: 750, loss is 3.986547966003418 and perplexity is 53.8686117508704
At time: 1195.5696551799774 and batch: 800, loss is 3.9477366971969605 and perplexity is 51.817954293684885
At time: 1196.7665214538574 and batch: 850, loss is 3.91971848487854 and perplexity is 50.38625828768163
At time: 1197.9637229442596 and batch: 900, loss is 3.9410057353973387 and perplexity is 51.47034082170922
At time: 1199.1614212989807 and batch: 950, loss is 3.9192417287826538 and perplexity is 50.36224205729109
At time: 1200.3589067459106 and batch: 1000, loss is 3.937424421310425 and perplexity is 51.28633904580649
At time: 1201.555839061737 and batch: 1050, loss is 3.8667066717147827 and perplexity is 47.784755771328555
At time: 1202.752779006958 and batch: 1100, loss is 3.8418739461898803 and perplexity is 46.612742417557186
At time: 1203.9762604236603 and batch: 1150, loss is 3.8594650650024414 and perplexity is 47.439967281258646
At time: 1205.1730167865753 and batch: 1200, loss is 3.8308921527862547 and perplexity is 46.10365139292468
At time: 1206.3698391914368 and batch: 1250, loss is 3.881975235939026 and perplexity is 48.519958848418774
At time: 1207.5677087306976 and batch: 1300, loss is 3.8622965526580813 and perplexity is 47.57448331337017
At time: 1208.7650938034058 and batch: 1350, loss is 3.8334408617019653 and perplexity is 46.22130605032422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559020589192708 and perplexity of 95.48991016597198
Finished 35 epochs...
Completing Train Step...
At time: 1212.2366452217102 and batch: 50, loss is 4.110075435638428 and perplexity is 60.95131529758624
At time: 1213.4095554351807 and batch: 100, loss is 4.122280344963074 and perplexity is 61.69977874738856
At time: 1214.581634759903 and batch: 150, loss is 4.090179257392883 and perplexity is 59.75060148125789
At time: 1215.7623155117035 and batch: 200, loss is 4.078940448760986 and perplexity is 59.08283538209444
At time: 1216.9523327350616 and batch: 250, loss is 4.07139974117279 and perplexity is 58.63898457476706
At time: 1218.1475551128387 and batch: 300, loss is 4.071925883293152 and perplexity is 58.669845132254736
At time: 1219.3442332744598 and batch: 350, loss is 4.0590805816650395 and perplexity is 57.921032930602955
At time: 1220.5412247180939 and batch: 400, loss is 4.067798051834107 and perplexity is 58.42816505030847
At time: 1221.741457939148 and batch: 450, loss is 4.011616220474243 and perplexity is 55.23607213004059
At time: 1222.9396312236786 and batch: 500, loss is 4.086648025512695 and perplexity is 59.53998034734161
At time: 1224.136770248413 and batch: 550, loss is 4.07407654762268 and perplexity is 58.796160057213704
At time: 1225.3330514431 and batch: 600, loss is 4.016518177986145 and perplexity is 55.50750173341884
At time: 1226.533667564392 and batch: 650, loss is 4.025024352073669 and perplexity is 55.981672034846554
At time: 1227.7296395301819 and batch: 700, loss is 4.029505453109741 and perplexity is 56.23309446734536
At time: 1228.9248046875 and batch: 750, loss is 3.9863594484329226 and perplexity is 53.85845752821193
At time: 1230.1193070411682 and batch: 800, loss is 3.9475739765167237 and perplexity is 51.80952312689494
At time: 1231.3223052024841 and batch: 850, loss is 3.91958251953125 and perplexity is 50.37940796828848
At time: 1232.5172612667084 and batch: 900, loss is 3.9408985662460325 and perplexity is 51.464825084529636
At time: 1233.751428604126 and batch: 950, loss is 3.9191651821136473 and perplexity is 50.35838714296022
At time: 1234.946708202362 and batch: 1000, loss is 3.9373691654205323 and perplexity is 51.28350525179581
At time: 1236.1483294963837 and batch: 1050, loss is 3.8666819286346437 and perplexity is 47.78357344391435
At time: 1237.3433556556702 and batch: 1100, loss is 3.841869592666626 and perplexity is 46.61253948834085
At time: 1238.5444951057434 and batch: 1150, loss is 3.8594767904281615 and perplexity is 47.440523538332336
At time: 1239.740308046341 and batch: 1200, loss is 3.8309291982650757 and perplexity is 46.1053593564019
At time: 1240.9354345798492 and batch: 1250, loss is 3.882027325630188 and perplexity is 48.522486303917006
At time: 1242.1309187412262 and batch: 1300, loss is 3.8623465204238894 and perplexity is 47.57686056340326
At time: 1243.324556350708 and batch: 1350, loss is 3.8334854793548585 and perplexity is 46.22336838252171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559017333984375 and perplexity of 95.4895993269266
Finished 36 epochs...
Completing Train Step...
At time: 1246.806275844574 and batch: 50, loss is 4.109798178672791 and perplexity is 60.93441846334599
At time: 1247.9813482761383 and batch: 100, loss is 4.121968884468078 and perplexity is 61.68056469612305
At time: 1249.1716017723083 and batch: 150, loss is 4.0898537349700925 and perplexity is 59.731154486088734
At time: 1250.361214876175 and batch: 200, loss is 4.078606786727906 and perplexity is 59.06312497161138
At time: 1251.5526900291443 and batch: 250, loss is 4.0710674667358395 and perplexity is 58.61950357588232
At time: 1252.7425274848938 and batch: 300, loss is 4.071600499153138 and perplexity is 58.65075800064496
At time: 1253.934221982956 and batch: 350, loss is 4.058760256767273 and perplexity is 57.90248235291548
At time: 1255.1278989315033 and batch: 400, loss is 4.0674805116653445 and perplexity is 58.40961470631349
At time: 1256.325001001358 and batch: 450, loss is 4.011313624382019 and perplexity is 55.21936043903795
At time: 1257.5220177173615 and batch: 500, loss is 4.086364378929138 and perplexity is 59.5230944302606
At time: 1258.7187678813934 and batch: 550, loss is 4.073807554244995 and perplexity is 58.78034640650401
At time: 1259.9164967536926 and batch: 600, loss is 4.016267142295837 and perplexity is 55.493569118268915
At time: 1261.1138179302216 and batch: 650, loss is 4.024781637191772 and perplexity is 55.968086098751364
At time: 1262.3117175102234 and batch: 700, loss is 4.029301347732544 and perplexity is 56.22161816161585
At time: 1263.5087413787842 and batch: 750, loss is 3.9861738300323486 and perplexity is 53.84846133523554
At time: 1264.7380456924438 and batch: 800, loss is 3.947412428855896 and perplexity is 51.8011540956421
At time: 1265.9352688789368 and batch: 850, loss is 3.9194460248947145 and perplexity is 50.3725319185916
At time: 1267.1325714588165 and batch: 900, loss is 3.940788941383362 and perplexity is 51.45918356937819
At time: 1268.3302052021027 and batch: 950, loss is 3.9190847158432005 and perplexity is 50.3543351543875
At time: 1269.5278451442719 and batch: 1000, loss is 3.937308988571167 and perplexity is 51.280419264878766
At time: 1270.725091457367 and batch: 1050, loss is 3.8666512680053713 and perplexity is 47.7821083919435
At time: 1271.924792766571 and batch: 1100, loss is 3.841857810020447 and perplexity is 46.61199027251616
At time: 1273.126329421997 and batch: 1150, loss is 3.8594801807403565 and perplexity is 47.44068437679047
At time: 1274.3261115550995 and batch: 1200, loss is 3.830956959724426 and perplexity is 46.10663932622835
At time: 1275.5243785381317 and batch: 1250, loss is 3.882069916725159 and perplexity is 48.52455297374995
At time: 1276.7226366996765 and batch: 1300, loss is 3.8623881483078004 and perplexity is 47.57884112865473
At time: 1277.9201226234436 and batch: 1350, loss is 3.83352294921875 and perplexity is 46.22510039829262
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559016927083333 and perplexity of 95.48956047211706
Finished 37 epochs...
Completing Train Step...
At time: 1281.3586299419403 and batch: 50, loss is 4.109523019790649 and perplexity is 60.917654123411964
At time: 1282.5554087162018 and batch: 100, loss is 4.121662044525147 and perplexity is 61.66164153851049
At time: 1283.7520701885223 and batch: 150, loss is 4.089534597396851 and perplexity is 59.71209507184848
At time: 1284.9440257549286 and batch: 200, loss is 4.078280777931213 and perplexity is 59.04387301163515
At time: 1286.1356735229492 and batch: 250, loss is 4.070743288993835 and perplexity is 58.600503517440096
At time: 1287.3319227695465 and batch: 300, loss is 4.0712830305099486 and perplexity is 58.63214117936535
At time: 1288.5367586612701 and batch: 350, loss is 4.058447618484497 and perplexity is 57.88438264974168
At time: 1289.7366156578064 and batch: 400, loss is 4.067170600891114 and perplexity is 58.391515742074205
At time: 1290.9348094463348 and batch: 450, loss is 4.011018180847168 and perplexity is 55.203048645723214
At time: 1292.1341807842255 and batch: 500, loss is 4.086087226867676 and perplexity is 59.506599767805056
At time: 1293.3322982788086 and batch: 550, loss is 4.0735445404052735 and perplexity is 58.764888394820076
At time: 1294.5576257705688 and batch: 600, loss is 4.0160217237472535 and perplexity is 55.479951638139624
At time: 1295.7563762664795 and batch: 650, loss is 4.024543814659118 and perplexity is 55.95477720940718
At time: 1296.9556257724762 and batch: 700, loss is 4.029100170135498 and perplexity is 56.21030876920839
At time: 1298.1563923358917 and batch: 750, loss is 3.9859905147552492 and perplexity is 53.83859099434427
At time: 1299.3596835136414 and batch: 800, loss is 3.9472518396377563 and perplexity is 51.792836056718706
At time: 1300.5583267211914 and batch: 850, loss is 3.91930899143219 and perplexity is 50.36562966905706
At time: 1301.7575845718384 and batch: 900, loss is 3.940677056312561 and perplexity is 51.4534263770591
At time: 1302.9566040039062 and batch: 950, loss is 3.9190009689331053 and perplexity is 50.35011831098469
At time: 1304.156772851944 and batch: 1000, loss is 3.937244429588318 and perplexity is 51.27710876003352
At time: 1305.361513376236 and batch: 1050, loss is 3.866615538597107 and perplexity is 47.780401195983764
At time: 1306.5635783672333 and batch: 1100, loss is 3.841839838027954 and perplexity is 46.61115256970452
At time: 1307.7636415958405 and batch: 1150, loss is 3.8594760942459105 and perplexity is 47.440490511093365
At time: 1308.9626750946045 and batch: 1200, loss is 3.8309767293930053 and perplexity is 46.10755084821733
At time: 1310.162174463272 and batch: 1250, loss is 3.8821044826507567 and perplexity is 48.52623029882669
At time: 1311.3615181446075 and batch: 1300, loss is 3.862422909736633 and perplexity is 47.58049506590101
At time: 1312.5720353126526 and batch: 1350, loss is 3.8335541343688964 and perplexity is 46.226541957466566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559019368489583 and perplexity of 95.48979360121135
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 1316.00377035141 and batch: 50, loss is 4.109417867660523 and perplexity is 60.91124883908911
At time: 1317.203379869461 and batch: 100, loss is 4.121757187843323 and perplexity is 61.66750851078782
At time: 1318.3753168582916 and batch: 150, loss is 4.089690618515014 and perplexity is 59.72141214650079
At time: 1319.5522692203522 and batch: 200, loss is 4.078593745231628 and perplexity is 59.06235470510965
At time: 1320.7428524494171 and batch: 250, loss is 4.0711093473434445 and perplexity is 58.621958647719175
At time: 1321.9393067359924 and batch: 300, loss is 4.071681981086731 and perplexity is 58.655537172519004
At time: 1323.1358997821808 and batch: 350, loss is 4.0587550115585325 and perplexity is 57.90217864310547
At time: 1324.3326575756073 and batch: 400, loss is 4.067401041984558 and perplexity is 58.40497309731398
At time: 1325.5564460754395 and batch: 450, loss is 4.0112210416793825 and perplexity is 55.214248318061266
At time: 1326.753300189972 and batch: 500, loss is 4.086126484870911 and perplexity is 59.508935923947355
At time: 1327.9494762420654 and batch: 550, loss is 4.073603086471557 and perplexity is 58.76832894858567
At time: 1329.146512746811 and batch: 600, loss is 4.015932593345642 and perplexity is 55.4750069081349
At time: 1330.3430383205414 and batch: 650, loss is 4.024503183364868 and perplexity is 55.952503740576994
At time: 1331.540411233902 and batch: 700, loss is 4.028774981498718 and perplexity is 56.192032787258626
At time: 1332.738088130951 and batch: 750, loss is 3.985825848579407 and perplexity is 53.82972632932777
At time: 1333.940493106842 and batch: 800, loss is 3.9468355989456176 and perplexity is 51.77128225688611
At time: 1335.1371541023254 and batch: 850, loss is 3.9185192251205443 and perplexity is 50.32586829464331
At time: 1336.3366272449493 and batch: 900, loss is 3.9395733213424684 and perplexity is 51.39666676058466
At time: 1337.5360841751099 and batch: 950, loss is 3.9179965972900392 and perplexity is 50.29957346708105
At time: 1338.735207080841 and batch: 1000, loss is 3.9362696981430054 and perplexity is 51.22715170101393
At time: 1339.932344675064 and batch: 1050, loss is 3.865553493499756 and perplexity is 47.72968319231492
At time: 1341.1303117275238 and batch: 1100, loss is 3.8405912351608276 and perplexity is 46.55299006945453
At time: 1342.3286046981812 and batch: 1150, loss is 3.8580791664123537 and perplexity is 47.37426583577622
At time: 1343.528210401535 and batch: 1200, loss is 3.829489297866821 and perplexity is 46.03902000359506
At time: 1344.7279863357544 and batch: 1250, loss is 3.8805759811401366 and perplexity is 48.45211453996475
At time: 1345.930989742279 and batch: 1300, loss is 3.8609572505950926 and perplexity is 47.51080935857029
At time: 1347.1295204162598 and batch: 1350, loss is 3.8323266649246217 and perplexity is 46.169835099786766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55907470703125 and perplexity of 95.49507801334784
Annealing...
Finished 39 epochs...
Completing Train Step...
At time: 1350.5936608314514 and batch: 50, loss is 4.1093775653839115 and perplexity is 60.908794026557274
At time: 1351.756906747818 and batch: 100, loss is 4.121732382774353 and perplexity is 61.665978862957616
At time: 1352.9412381649017 and batch: 150, loss is 4.089694819450378 and perplexity is 59.72166303282004
At time: 1354.130343914032 and batch: 200, loss is 4.078627462387085 and perplexity is 59.06434615327769
At time: 1355.346299648285 and batch: 250, loss is 4.071134161949158 and perplexity is 58.623413346557975
At time: 1356.541476726532 and batch: 300, loss is 4.071699151992798 and perplexity is 58.656544349885145
At time: 1357.7402625083923 and batch: 350, loss is 4.0587685108184814 and perplexity is 57.90296028494237
At time: 1358.9380495548248 and batch: 400, loss is 4.067392597198486 and perplexity is 58.40447988189317
At time: 1360.1355645656586 and batch: 450, loss is 4.011220245361328 and perplexity is 55.214204349975994
At time: 1361.3336470127106 and batch: 500, loss is 4.086107807159424 and perplexity is 59.50782444359127
At time: 1362.5325815677643 and batch: 550, loss is 4.073586478233337 and perplexity is 58.76735291828378
At time: 1363.731892824173 and batch: 600, loss is 4.0158754110336305 and perplexity is 55.471834809675855
At time: 1364.9297134876251 and batch: 650, loss is 4.024464702606201 and perplexity is 55.95035068720954
At time: 1366.127897977829 and batch: 700, loss is 4.0287007713317875 and perplexity is 56.187862921850424
At time: 1367.325877904892 and batch: 750, loss is 3.985787034034729 and perplexity is 53.827636993558734
At time: 1368.5251941680908 and batch: 800, loss is 3.946761269569397 and perplexity is 51.76743427278071
At time: 1369.7253849506378 and batch: 850, loss is 3.91837899684906 and perplexity is 50.31881167990141
At time: 1370.9337983131409 and batch: 900, loss is 3.9393818521499635 and perplexity is 51.38682682435495
At time: 1372.140070438385 and batch: 950, loss is 3.9178133535385133 and perplexity is 50.290357228973605
At time: 1373.3370685577393 and batch: 1000, loss is 3.936092700958252 and perplexity is 51.21808544175475
At time: 1374.540275335312 and batch: 1050, loss is 3.865365056991577 and perplexity is 47.72069002482482
At time: 1375.7378897666931 and batch: 1100, loss is 3.8403692960739138 and perplexity is 46.54265928778994
At time: 1376.9357957839966 and batch: 1150, loss is 3.8578345727920533 and perplexity is 47.36267980957818
At time: 1378.1342587471008 and batch: 1200, loss is 3.82922137260437 and perplexity is 46.02668663936131
At time: 1379.332160949707 and batch: 1250, loss is 3.880298585891724 and perplexity is 48.43867601759311
At time: 1380.5297756195068 and batch: 1300, loss is 3.860694227218628 and perplexity is 47.49831454835985
At time: 1381.731288909912 and batch: 1350, loss is 3.832104105949402 and perplexity is 46.159560731969684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559084879557291 and perplexity of 95.49604944445666
Annealing...
Finished 40 epochs...
Completing Train Step...
At time: 1385.2368359565735 and batch: 50, loss is 4.109370694160462 and perplexity is 60.90837551006132
At time: 1386.4011838436127 and batch: 100, loss is 4.1217282772064205 and perplexity is 61.66572568961197
At time: 1387.5852763652802 and batch: 150, loss is 4.089695482254029 and perplexity is 59.72170261656942
At time: 1388.7659726142883 and batch: 200, loss is 4.078633179664612 and perplexity is 59.064683841501925
At time: 1389.9545395374298 and batch: 250, loss is 4.071138806343079 and perplexity is 58.623685617414814
At time: 1391.1544833183289 and batch: 300, loss is 4.071701879501343 and perplexity is 58.65670433632927
At time: 1392.360035419464 and batch: 350, loss is 4.0587697601318355 and perplexity is 57.903032623929086
At time: 1393.5608105659485 and batch: 400, loss is 4.067390470504761 and perplexity is 58.40435567358436
At time: 1394.7634887695312 and batch: 450, loss is 4.0112195444107055 and perplexity is 55.21416564755862
At time: 1395.963641166687 and batch: 500, loss is 4.08610357761383 and perplexity is 59.50757275306687
At time: 1397.1669158935547 and batch: 550, loss is 4.073583240509033 and perplexity is 58.767162646104985
At time: 1398.3695747852325 and batch: 600, loss is 4.015864915847779 and perplexity is 55.47125262551505
At time: 1399.5695972442627 and batch: 650, loss is 4.024457340240478 and perplexity is 55.94993876178186
At time: 1400.785518169403 and batch: 700, loss is 4.028686647415161 and perplexity is 56.18706933476339
At time: 1401.9844155311584 and batch: 750, loss is 3.985779390335083 and perplexity is 53.82722555284136
At time: 1403.1853606700897 and batch: 800, loss is 3.9467475986480713 and perplexity is 51.766726569097024
At time: 1404.3850569725037 and batch: 850, loss is 3.91835364818573 and perplexity is 50.31753618145114
At time: 1405.590339422226 and batch: 900, loss is 3.939346957206726 and perplexity is 51.38503371523515
At time: 1406.787588596344 and batch: 950, loss is 3.917779793739319 and perplexity is 50.288669523003286
At time: 1407.984192609787 and batch: 1000, loss is 3.9360601902008057 and perplexity is 51.21642033006927
At time: 1409.1805074214935 and batch: 1050, loss is 3.865330448150635 and perplexity is 47.71903849563303
At time: 1410.3763394355774 and batch: 1100, loss is 3.840328588485718 and perplexity is 46.54076468694469
At time: 1411.5715901851654 and batch: 1150, loss is 3.8577896308898927 and perplexity is 47.36055128848636
At time: 1412.7677538394928 and batch: 1200, loss is 3.8291719579696655 and perplexity is 46.024412303647566
At time: 1413.9627339839935 and batch: 1250, loss is 3.880247435569763 and perplexity is 48.436198427084776
At time: 1415.157809495926 and batch: 1300, loss is 3.8606457138061523 and perplexity is 47.49601029892822
At time: 1416.3547859191895 and batch: 1350, loss is 3.8320632076263426 and perplexity is 46.15767292194698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5590869140625 and perplexity of 95.49624373186431
Annealing...
Finished 41 epochs...
Completing Train Step...
At time: 1419.7899370193481 and batch: 50, loss is 4.109369931221008 and perplexity is 60.9083290406763
At time: 1420.9963552951813 and batch: 100, loss is 4.121728086471558 and perplexity is 61.66571392780937
At time: 1422.1865849494934 and batch: 150, loss is 4.089695963859558 and perplexity is 59.72173137887856
At time: 1423.3840613365173 and batch: 200, loss is 4.078634781837463 and perplexity is 59.064778473410655
At time: 1424.5845613479614 and batch: 250, loss is 4.071140208244324 and perplexity is 58.62376780209027
At time: 1425.7817797660828 and batch: 300, loss is 4.071702847480774 and perplexity is 58.65676111484003
At time: 1426.979329586029 and batch: 350, loss is 4.058770432472229 and perplexity is 57.90307155448989
At time: 1428.1773254871368 and batch: 400, loss is 4.067390456199646 and perplexity is 58.40435483810332
At time: 1429.3754441738129 and batch: 450, loss is 4.011219840049744 and perplexity is 55.21418197102388
At time: 1430.573319196701 and batch: 500, loss is 4.0861035299301145 and perplexity is 59.507569915524755
At time: 1431.7750849723816 and batch: 550, loss is 4.073583083152771 and perplexity is 58.76715339872466
At time: 1432.9855787754059 and batch: 600, loss is 4.015863633155822 and perplexity is 55.471181473031145
At time: 1434.1929187774658 and batch: 650, loss is 4.024456667900085 and perplexity is 55.94990114439068
At time: 1435.391654253006 and batch: 700, loss is 4.028684859275818 and perplexity is 56.18696886454396
At time: 1436.5975811481476 and batch: 750, loss is 3.9857785224914553 and perplexity is 53.82717883924694
At time: 1437.7957258224487 and batch: 800, loss is 3.9467455911636353 and perplexity is 51.766622648303446
At time: 1439.0001034736633 and batch: 850, loss is 3.918349585533142 and perplexity is 50.31733175919779
At time: 1440.2043542861938 and batch: 900, loss is 3.939341216087341 and perplexity is 51.38473870846884
At time: 1441.4113714694977 and batch: 950, loss is 3.917774510383606 and perplexity is 50.28840383077574
At time: 1442.616619348526 and batch: 1000, loss is 3.936055073738098 and perplexity is 51.216158283835
At time: 1443.8185985088348 and batch: 1050, loss is 3.865324845314026 and perplexity is 47.7187711344062
At time: 1445.022183895111 and batch: 1100, loss is 3.8403219842910765 and perplexity is 46.54045732369089
At time: 1446.254777431488 and batch: 1150, loss is 3.8577823734283445 and perplexity is 47.360207572353744
At time: 1447.4567048549652 and batch: 1200, loss is 3.8291639280319214 and perplexity is 46.02404273196588
At time: 1448.6610777378082 and batch: 1250, loss is 3.8802389764785765 and perplexity is 48.4357887025985
At time: 1449.8635354042053 and batch: 1300, loss is 3.860637650489807 and perplexity is 47.49562732511606
At time: 1451.0795302391052 and batch: 1350, loss is 3.832056403160095 and perplexity is 46.1573588446881
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.559087320963542 and perplexity of 95.49628258939327
Annealing...
Model not improving. Stopping early with 95.48956047211706loss at 41 epochs.
Finished Training.
Improved accuracyfrom -96.72565401050375 to -95.48956047211706
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f77bee00828>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'dropout': 0.052955126623090765, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 9.519869146181783, 'wordvec_source': '', 'anneal': 5.67024530226525, 'data': 'wikitext'}, 'best_accuracy': -99.47447942221514}, {'params': {'dropout': 0.012553500039072074, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 8.76493760953503, 'wordvec_source': '', 'anneal': 4.189047699677582, 'data': 'wikitext'}, 'best_accuracy': -96.72565401050375}, {'params': {'dropout': 0.6288785410858434, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 10.020794858963564, 'wordvec_source': '', 'anneal': 7.111214822875256, 'data': 'wikitext'}, 'best_accuracy': -117.32023258164584}, {'params': {'dropout': 0.6711892764208761, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 15.143887740344653, 'wordvec_source': '', 'anneal': 2.692297021307107, 'data': 'wikitext'}, 'best_accuracy': -146.94485392784517}, {'params': {'dropout': 0.2495671056082589, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 25.49355568496804, 'wordvec_source': '', 'anneal': 6.4309190347271565, 'data': 'wikitext'}, 'best_accuracy': -163.37094576496176}, {'params': {'dropout': 0.0, 'tune_wordvecs': True, 'batch_size': 80, 'wordvec_dim': 200, 'seq_len': 20, 'num_layers': 1, 'lr': 6.642218321471463, 'wordvec_source': '', 'anneal': 5.512638265068215, 'data': 'wikitext'}, 'best_accuracy': -95.48956047211706}]
