(In Progress) Pytorch implementation of my research in applying self-attention to what models learn. Trying to see whether one 
can use learned attention weights to understand:

-->choice of dataset for unsupervised pretraining via language model

-->choice of word embeddings

-->hyperpameter choice

-->what subjective language is
