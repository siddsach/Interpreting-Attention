Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'lr', 'type': 'continuous', 'domain': [0, 30]}, {'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'anneal', 'type': 'continuous', 'domain': [2, 8]}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 4.823538421298158, 'wordvec_source': 'glove', 'dropout': 0.0008680664032081342, 'data': 'wikitext', 'lr': 25.690914877339633, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7939355373382568 and batch: 50, loss is 7.788176774978638 and perplexity is 2411.9161051803862
At time: 2.8440403938293457 and batch: 100, loss is 6.808425979614258 and perplexity is 905.4444966254424
At time: 3.8613269329071045 and batch: 150, loss is 6.348097677230835 and perplexity is 571.4046783190321
At time: 4.8788251876831055 and batch: 200, loss is 6.177829780578613 and perplexity is 481.94489441676865
At time: 5.898236989974976 and batch: 250, loss is 6.20892481803894 and perplexity is 497.1664194517201
At time: 6.91940450668335 and batch: 300, loss is 6.178108339309692 and perplexity is 482.07916307499266
At time: 7.941101312637329 and batch: 350, loss is 6.208355941772461 and perplexity is 496.8836737065007
At time: 8.96173882484436 and batch: 400, loss is 6.28486364364624 and perplexity is 536.3911453099333
At time: 9.980544567108154 and batch: 450, loss is 6.281858606338501 and perplexity is 534.7816893554791
At time: 11.01194453239441 and batch: 500, loss is 6.277753067016602 and perplexity is 532.5906229334919
At time: 12.033519983291626 and batch: 550, loss is 6.312622222900391 and perplexity is 551.4891819961709
At time: 13.054539442062378 and batch: 600, loss is 6.291625308990478 and perplexity is 540.0303323452328
At time: 14.07894492149353 and batch: 650, loss is 6.341353769302368 and perplexity is 567.5641424444345
At time: 15.10146188735962 and batch: 700, loss is 6.370275154113769 and perplexity is 584.218556917068
At time: 16.125580072402954 and batch: 750, loss is 6.357069530487061 and perplexity is 576.5543035408926
At time: 17.147449016571045 and batch: 800, loss is 6.352853260040283 and perplexity is 574.1285121597598
At time: 18.169572591781616 and batch: 850, loss is 6.352613706588745 and perplexity is 573.9909941651581
At time: 19.194729566574097 and batch: 900, loss is 6.364483232498169 and perplexity is 580.8445891394977
At time: 20.219785451889038 and batch: 950, loss is 6.336796808242798 and perplexity is 564.9836587957602
At time: 21.244717836380005 and batch: 1000, loss is 6.330020189285278 and perplexity is 561.1679233179163
At time: 22.268685579299927 and batch: 1050, loss is 6.3674188899993895 and perplexity is 582.5522552496606
At time: 23.291502237319946 and batch: 1100, loss is 6.409366273880005 and perplexity is 607.5085649995482
At time: 24.316032886505127 and batch: 1150, loss is 6.4291555786132815 and perplexity is 619.6504809120377
At time: 25.340582370758057 and batch: 1200, loss is 6.440654191970825 and perplexity is 626.8167241803919
At time: 26.365710973739624 and batch: 1250, loss is 6.421478929519654 and perplexity is 614.91185327113
At time: 27.39033055305481 and batch: 1300, loss is 6.38787314414978 and perplexity is 594.5906253640088
At time: 28.4143283367157 and batch: 1350, loss is 6.445915861129761 and perplexity is 630.1235184058211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.188634847005209 and perplexity of 487.1805760201725
Finished 1 epochs...
Completing Train Step...
At time: 31.760642051696777 and batch: 50, loss is 6.469489965438843 and perplexity is 645.1545918979099
At time: 32.7806351184845 and batch: 100, loss is 6.47822078704834 and perplexity is 650.8119824469181
At time: 33.80070090293884 and batch: 150, loss is 6.476483030319214 and perplexity is 649.6820116365719
At time: 34.82041835784912 and batch: 200, loss is 6.463947477340699 and perplexity is 641.5887212769693
At time: 35.84678530693054 and batch: 250, loss is 6.468958292007446 and perplexity is 644.8116715111616
At time: 36.867045640945435 and batch: 300, loss is 6.497148694992066 and perplexity is 663.2478125880064
At time: 37.89033365249634 and batch: 350, loss is 6.475353679656982 and perplexity is 648.9487069834781
At time: 38.91766428947449 and batch: 400, loss is 6.489597749710083 and perplexity is 658.2585252705912
At time: 39.94525909423828 and batch: 450, loss is 6.489335374832153 and perplexity is 658.0858374258439
At time: 40.97655367851257 and batch: 500, loss is 6.50342583656311 and perplexity is 667.4242072010693
At time: 42.01069116592407 and batch: 550, loss is 6.478633575439453 and perplexity is 651.0806855330113
At time: 43.04102897644043 and batch: 600, loss is 6.5346728038787845 and perplexity is 688.6084374498369
At time: 44.062769412994385 and batch: 650, loss is 6.471416110992432 and perplexity is 646.3984510888328
At time: 45.08758592605591 and batch: 700, loss is 6.513551206588745 and perplexity is 674.2164532351584
At time: 46.111523151397705 and batch: 750, loss is 6.511133937835694 and perplexity is 672.5886590705708
At time: 47.13434147834778 and batch: 800, loss is 6.407800655364991 and perplexity is 606.5581825044986
At time: 48.16170120239258 and batch: 850, loss is 6.435289545059204 and perplexity is 623.4630773853274
At time: 49.185521841049194 and batch: 900, loss is 6.462798357009888 and perplexity is 640.8518820728676
At time: 50.21160316467285 and batch: 950, loss is 6.426814785003662 and perplexity is 618.2017033322971
At time: 51.239288091659546 and batch: 1000, loss is 6.4765206146240235 and perplexity is 649.7064299421962
At time: 52.26579260826111 and batch: 1050, loss is 6.495424413681031 and perplexity is 662.1051721800293
At time: 53.321221351623535 and batch: 1100, loss is 6.5110338306427 and perplexity is 672.5213314779161
At time: 54.41147255897522 and batch: 1150, loss is 6.510764636993408 and perplexity is 672.3403173714862
At time: 55.517085313797 and batch: 1200, loss is 6.4001210594177245 and perplexity is 601.9179012922399
At time: 56.621506452560425 and batch: 1250, loss is 6.388232021331787 and perplexity is 594.8040486661735
At time: 57.726383686065674 and batch: 1300, loss is 6.411573486328125 and perplexity is 608.8509463820204
At time: 58.83259320259094 and batch: 1350, loss is 6.433885478973389 and perplexity is 622.5883082831376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.227288411458333 and perplexity of 506.380524548714
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 62.31127977371216 and batch: 50, loss is 6.267118873596192 and perplexity is 526.9569590616022
At time: 63.44304299354553 and batch: 100, loss is 6.136505031585694 and perplexity is 462.43454914944846
At time: 64.5274076461792 and batch: 150, loss is 6.0300608825683595 and perplexity is 415.7403399511588
At time: 65.61114144325256 and batch: 200, loss is 5.999610757827758 and perplexity is 403.27179255048736
At time: 66.6937906742096 and batch: 250, loss is 5.989868335723877 and perplexity is 399.3620247534911
At time: 67.77691006660461 and batch: 300, loss is 5.983771200180054 and perplexity is 396.9344684478065
At time: 68.85965085029602 and batch: 350, loss is 5.949686918258667 and perplexity is 383.6332117032987
At time: 69.94446539878845 and batch: 400, loss is 5.967357158660889 and perplexity is 390.4723494323268
At time: 71.04932117462158 and batch: 450, loss is 5.918114757537841 and perplexity is 371.71028888561256
At time: 72.1326756477356 and batch: 500, loss is 5.934952945709228 and perplexity is 378.0222081862442
At time: 73.22230505943298 and batch: 550, loss is 5.909419765472412 and perplexity is 368.4922814219908
At time: 74.30904173851013 and batch: 600, loss is 5.868665447235108 and perplexity is 353.77653163562337
At time: 75.39507150650024 and batch: 650, loss is 5.89952467918396 and perplexity is 364.8639991881205
At time: 76.48104810714722 and batch: 700, loss is 5.908428525924682 and perplexity is 368.1271982719332
At time: 77.56468987464905 and batch: 750, loss is 5.877530870437622 and perplexity is 356.92685414536334
At time: 78.6580650806427 and batch: 800, loss is 5.843526782989502 and perplexity is 344.9939163091994
At time: 79.75963926315308 and batch: 850, loss is 5.829447984695435 and perplexity is 340.17084771951966
At time: 80.86091446876526 and batch: 900, loss is 5.847533178329468 and perplexity is 346.3788708129369
At time: 82.01273274421692 and batch: 950, loss is 5.812489852905274 and perplexity is 334.45082319646264
At time: 83.10955786705017 and batch: 1000, loss is 5.826227722167968 and perplexity is 339.07717019517423
At time: 84.20872759819031 and batch: 1050, loss is 5.7859851837158205 and perplexity is 325.70275915762113
At time: 85.3094437122345 and batch: 1100, loss is 5.766820726394653 and perplexity is 319.5202737415755
At time: 86.41316318511963 and batch: 1150, loss is 5.775846881866455 and perplexity is 322.41736855366423
At time: 87.51355862617493 and batch: 1200, loss is 5.7586285018920895 and perplexity is 316.9133846160124
At time: 88.61938571929932 and batch: 1250, loss is 5.73949875831604 and perplexity is 310.9085316020976
At time: 89.7255744934082 and batch: 1300, loss is 5.724529085159301 and perplexity is 306.2889952431855
At time: 90.82998180389404 and batch: 1350, loss is 5.716083364486694 and perplexity is 303.7130570831828
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.528628743489583 and perplexity of 251.79839399433854
Finished 3 epochs...
Completing Train Step...
At time: 94.28028535842896 and batch: 50, loss is 5.813155946731567 and perplexity is 334.67367303620415
At time: 95.3912444114685 and batch: 100, loss is 5.838038368225098 and perplexity is 343.10563318579767
At time: 96.4727668762207 and batch: 150, loss is 5.795205163955688 and perplexity is 328.7196184813905
At time: 97.55371356010437 and batch: 200, loss is 5.783225841522217 and perplexity is 324.8052725974242
At time: 98.63777875900269 and batch: 250, loss is 5.806315660476685 and perplexity is 332.39222109849135
At time: 99.72014880180359 and batch: 300, loss is 5.814202251434327 and perplexity is 335.0240269306929
At time: 100.80086946487427 and batch: 350, loss is 5.792121448516846 and perplexity is 327.7075020603889
At time: 101.88227272033691 and batch: 400, loss is 5.830459280014038 and perplexity is 340.5150349134589
At time: 102.96791791915894 and batch: 450, loss is 5.795668973922729 and perplexity is 328.8721172793015
At time: 104.05549764633179 and batch: 500, loss is 5.817534675598145 and perplexity is 336.1423313909973
At time: 105.14437222480774 and batch: 550, loss is 5.792172384262085 and perplexity is 327.7241945113445
At time: 106.2309741973877 and batch: 600, loss is 5.747891302108765 and perplexity is 313.5288251533213
At time: 107.31953740119934 and batch: 650, loss is 5.784476289749145 and perplexity is 325.2116788166533
At time: 108.41442346572876 and batch: 700, loss is 5.801602239608765 and perplexity is 330.8292031416688
At time: 109.56950736045837 and batch: 750, loss is 5.773123235702514 and perplexity is 321.540412525699
At time: 110.67578315734863 and batch: 800, loss is 5.730392541885376 and perplexity is 308.09018294512117
At time: 111.78234219551086 and batch: 850, loss is 5.729682817459106 and perplexity is 307.8716013922998
At time: 112.89111351966858 and batch: 900, loss is 5.755148382186889 and perplexity is 315.81240498301133
At time: 113.9987964630127 and batch: 950, loss is 5.723354167938233 and perplexity is 305.929342350612
At time: 115.1046667098999 and batch: 1000, loss is 5.749028739929199 and perplexity is 313.88564759004396
At time: 116.21166133880615 and batch: 1050, loss is 5.715890626907349 and perplexity is 303.65452580451466
At time: 117.31908369064331 and batch: 1100, loss is 5.707538318634033 and perplexity is 301.1288717995019
At time: 118.42784929275513 and batch: 1150, loss is 5.720479621887207 and perplexity is 305.0511971068137
At time: 119.5337781906128 and batch: 1200, loss is 5.702767200469971 and perplexity is 299.69557230906895
At time: 120.6400887966156 and batch: 1250, loss is 5.704842872619629 and perplexity is 300.31828811523826
At time: 121.74464678764343 and batch: 1300, loss is 5.684332780838012 and perplexity is 294.2214693430408
At time: 122.84788608551025 and batch: 1350, loss is 5.672042417526245 and perplexity is 290.6275113551319
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.488959554036458 and perplexity of 242.00528240455637
Finished 4 epochs...
Completing Train Step...
At time: 126.28678107261658 and batch: 50, loss is 5.752225399017334 and perplexity is 314.8906384488267
At time: 127.35868859291077 and batch: 100, loss is 5.7707986068725585 and perplexity is 320.7938185259238
At time: 128.4322805404663 and batch: 150, loss is 5.723039779663086 and perplexity is 305.8331768697956
At time: 129.50942420959473 and batch: 200, loss is 5.707792892456054 and perplexity is 301.20554108589937
At time: 130.60481071472168 and batch: 250, loss is 5.726652069091797 and perplexity is 306.93993257905504
At time: 131.71133852005005 and batch: 300, loss is 5.728513345718384 and perplexity is 307.5117647051304
At time: 132.81833243370056 and batch: 350, loss is 5.725483675003051 and perplexity is 306.58151520337555
At time: 133.92412900924683 and batch: 400, loss is 5.75729546546936 and perplexity is 316.4912089817341
At time: 135.0333924293518 and batch: 450, loss is 5.722243852615357 and perplexity is 305.589852819174
At time: 136.1383113861084 and batch: 500, loss is 5.748184785842896 and perplexity is 313.6208542675485
At time: 137.27516674995422 and batch: 550, loss is 5.720907754898072 and perplexity is 305.1818275559073
At time: 138.38244032859802 and batch: 600, loss is 5.67396879196167 and perplexity is 291.1879083571679
At time: 139.48998951911926 and batch: 650, loss is 5.707011890411377 and perplexity is 300.9703907808305
At time: 140.59570813179016 and batch: 700, loss is 5.7227311706542965 and perplexity is 305.7388085584313
At time: 141.70309042930603 and batch: 750, loss is 5.702166156768799 and perplexity is 299.5154962952614
At time: 142.8079915046692 and batch: 800, loss is 5.662363805770874 and perplexity is 287.8282090395872
At time: 143.91478943824768 and batch: 850, loss is 5.643264465332031 and perplexity is 282.38304513192804
At time: 145.02238202095032 and batch: 900, loss is 5.678152685165405 and perplexity is 292.4087596427391
At time: 146.1306414604187 and batch: 950, loss is 5.649340877532959 and perplexity is 284.10414467217976
At time: 147.23771142959595 and batch: 1000, loss is 5.678895664215088 and perplexity is 292.62609395251917
At time: 148.34398102760315 and batch: 1050, loss is 5.646626949310303 and perplexity is 283.3341517411629
At time: 149.45197224617004 and batch: 1100, loss is 5.638741598129273 and perplexity is 281.1087480290583
At time: 150.55939388275146 and batch: 1150, loss is 5.646612749099732 and perplexity is 283.33012836511267
At time: 151.66526651382446 and batch: 1200, loss is 5.631680202484131 and perplexity is 279.13071997849084
At time: 152.77255964279175 and batch: 1250, loss is 5.63997407913208 and perplexity is 281.4554228118855
At time: 153.87935256958008 and batch: 1300, loss is 5.620928869247437 and perplexity is 276.1457674538378
At time: 154.98359179496765 and batch: 1350, loss is 5.606423711776733 and perplexity is 272.1691401379144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.438957926432292 and perplexity of 230.20217082950174
Finished 5 epochs...
Completing Train Step...
At time: 158.4331784248352 and batch: 50, loss is 5.678733291625977 and perplexity is 292.5785833533165
At time: 159.50591397285461 and batch: 100, loss is 5.695127382278442 and perplexity is 297.41467653238766
At time: 160.5808243751526 and batch: 150, loss is 5.648627004623413 and perplexity is 283.9014027943857
At time: 161.6672432422638 and batch: 200, loss is 5.6353646183013915 and perplexity is 280.16105053580975
At time: 162.76066040992737 and batch: 250, loss is 5.657295627593994 and perplexity is 286.3731347942475
At time: 163.86253118515015 and batch: 300, loss is 5.6511610317230225 and perplexity is 284.62172892019345
At time: 164.99111032485962 and batch: 350, loss is 5.658624753952027 and perplexity is 286.7540139381186
At time: 166.09170031547546 and batch: 400, loss is 5.688002424240112 and perplexity is 295.3031406769678
At time: 167.19395208358765 and batch: 450, loss is 5.649646797180176 and perplexity is 284.19107100744975
At time: 168.29481649398804 and batch: 500, loss is 5.677036781311035 and perplexity is 292.08264157284896
At time: 169.39535880088806 and batch: 550, loss is 5.651324081420898 and perplexity is 284.66814019067175
At time: 170.49615335464478 and batch: 600, loss is 5.606956663131714 and perplexity is 272.31423170987557
At time: 171.5966920852661 and batch: 650, loss is 5.633670425415039 and perplexity is 279.6868055216586
At time: 172.69676971435547 and batch: 700, loss is 5.645688457489014 and perplexity is 283.06836969370846
At time: 173.7988784313202 and batch: 750, loss is 5.623205709457397 and perplexity is 276.7752235545422
At time: 174.89870762825012 and batch: 800, loss is 5.5834331035614015 and perplexity is 265.98318794271137
At time: 175.99878191947937 and batch: 850, loss is 5.568071050643921 and perplexity is 261.92836507814263
At time: 177.1007845401764 and batch: 900, loss is 5.604219026565552 and perplexity is 271.5697538315584
At time: 178.20217728614807 and batch: 950, loss is 5.579033279418946 and perplexity is 264.8154794307167
At time: 179.30262112617493 and batch: 1000, loss is 5.606705322265625 and perplexity is 272.2457966156573
At time: 180.40458297729492 and batch: 1050, loss is 5.572638816833496 and perplexity is 263.12752927407746
At time: 181.50618386268616 and batch: 1100, loss is 5.565239639282226 and perplexity is 261.1877870645722
At time: 182.60760021209717 and batch: 1150, loss is 5.577721529006958 and perplexity is 264.46833534944574
At time: 183.70830368995667 and batch: 1200, loss is 5.559624404907226 and perplexity is 259.72526646516434
At time: 184.80769848823547 and batch: 1250, loss is 5.577322111129761 and perplexity is 264.36272306147674
At time: 185.90759539604187 and batch: 1300, loss is 5.557383918762207 and perplexity is 259.1440069991773
At time: 187.00668787956238 and batch: 1350, loss is 5.531029109954834 and perplexity is 252.40352839689677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.374192301432291 and perplexity of 215.765528403178
Finished 6 epochs...
Completing Train Step...
At time: 190.35529732704163 and batch: 50, loss is 5.607155704498291 and perplexity is 272.3684389012513
At time: 191.4755425453186 and batch: 100, loss is 5.626271057128906 and perplexity is 277.6249375105936
At time: 192.56152153015137 and batch: 150, loss is 5.5834230709075925 and perplexity is 265.9805194388538
At time: 193.68219137191772 and batch: 200, loss is 5.57156195640564 and perplexity is 262.84433016064895
At time: 194.7814745903015 and batch: 250, loss is 5.601503925323486 and perplexity is 270.8334145258485
At time: 195.88224053382874 and batch: 300, loss is 5.594053344726563 and perplexity is 268.82304684560927
At time: 196.98350954055786 and batch: 350, loss is 5.607870578765869 and perplexity is 272.56321770240345
At time: 198.08393597602844 and batch: 400, loss is 5.627712345123291 and perplexity is 278.0253634952341
At time: 199.18573808670044 and batch: 450, loss is 5.589178094863891 and perplexity is 267.515656839376
At time: 200.2871973514557 and batch: 500, loss is 5.615440578460693 and perplexity is 274.6343505241505
At time: 201.3895833492279 and batch: 550, loss is 5.586959867477417 and perplexity is 266.92290395645836
At time: 202.49291515350342 and batch: 600, loss is 5.548064794540405 and perplexity is 256.7402297525246
At time: 203.59353256225586 and batch: 650, loss is 5.577530431747436 and perplexity is 264.41780100397153
At time: 204.6953558921814 and batch: 700, loss is 5.593113241195678 and perplexity is 268.5704441050549
At time: 205.7977375984192 and batch: 750, loss is 5.561375284194947 and perplexity is 260.1804123912295
At time: 206.8982162475586 and batch: 800, loss is 5.527788047790527 and perplexity is 251.58679712423015
At time: 208.00090885162354 and batch: 850, loss is 5.512288961410523 and perplexity is 247.71749440926052
At time: 209.10344815254211 and batch: 900, loss is 5.552674446105957 and perplexity is 257.92644467279746
At time: 210.20434951782227 and batch: 950, loss is 5.5338343906402585 and perplexity is 253.11258522675706
At time: 211.3053412437439 and batch: 1000, loss is 5.563932466506958 and perplexity is 260.8465925487631
At time: 212.4073052406311 and batch: 1050, loss is 5.523996496200562 and perplexity is 250.63469890893305
At time: 213.50925397872925 and batch: 1100, loss is 5.522789649963379 and perplexity is 250.33240381418656
At time: 214.61167693138123 and batch: 1150, loss is 5.5340236473083495 and perplexity is 253.1604930045792
At time: 215.71775436401367 and batch: 1200, loss is 5.519856176376343 and perplexity is 249.59913635580926
At time: 216.81943941116333 and batch: 1250, loss is 5.536446475982666 and perplexity is 253.77460114523478
At time: 217.9215109348297 and batch: 1300, loss is 5.516928415298462 and perplexity is 248.8694384311398
At time: 219.02304816246033 and batch: 1350, loss is 5.487327365875244 and perplexity is 241.61060642801203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.331675618489584 and perplexity of 206.78417541236726
Finished 7 epochs...
Completing Train Step...
At time: 222.39371299743652 and batch: 50, loss is 5.567235088348388 and perplexity is 261.7094943373964
At time: 223.50650668144226 and batch: 100, loss is 5.582821521759033 and perplexity is 265.8205671982425
At time: 224.59946727752686 and batch: 150, loss is 5.53548189163208 and perplexity is 253.52993215730268
At time: 225.706716299057 and batch: 200, loss is 5.524625263214111 and perplexity is 250.7923392944015
At time: 226.80810952186584 and batch: 250, loss is 5.558610734939575 and perplexity is 259.462124154969
At time: 227.9089982509613 and batch: 300, loss is 5.555796909332275 and perplexity is 258.7330691837023
At time: 229.0101592540741 and batch: 350, loss is 5.568938980102539 and perplexity is 262.15579910631084
At time: 230.10986948013306 and batch: 400, loss is 5.581908798217773 and perplexity is 265.57805719793816
At time: 231.21184420585632 and batch: 450, loss is 5.5504688549041745 and perplexity is 257.35819127343103
At time: 232.31313943862915 and batch: 500, loss is 5.580102815628051 and perplexity is 265.09886069094546
At time: 233.41586637496948 and batch: 550, loss is 5.552699670791626 and perplexity is 257.9329508683481
At time: 234.51705813407898 and batch: 600, loss is 5.5137077331542965 and perplexity is 248.06919842563136
At time: 235.61822962760925 and batch: 650, loss is 5.550504245758057 and perplexity is 257.3672995607479
At time: 236.7193284034729 and batch: 700, loss is 5.561072196960449 and perplexity is 260.10156697868996
At time: 237.8222575187683 and batch: 750, loss is 5.529045104980469 and perplexity is 251.90325497758744
At time: 238.92216897010803 and batch: 800, loss is 5.496894845962524 and perplexity is 243.93330456030736
At time: 240.02507615089417 and batch: 850, loss is 5.4820759487152095 and perplexity is 240.34513401334652
At time: 241.12740182876587 and batch: 900, loss is 5.520825290679932 and perplexity is 249.84114369646215
At time: 242.22903990745544 and batch: 950, loss is 5.505567502975464 and perplexity is 246.0580547418364
At time: 243.33091259002686 and batch: 1000, loss is 5.5281783294677735 and perplexity is 251.68500600470153
At time: 244.43262267112732 and batch: 1050, loss is 5.495641307830811 and perplexity is 243.62771643464586
At time: 245.53391218185425 and batch: 1100, loss is 5.496811256408692 and perplexity is 243.91291513639757
At time: 246.6357319355011 and batch: 1150, loss is 5.507358551025391 and perplexity is 246.49915143572278
At time: 247.73632073402405 and batch: 1200, loss is 5.493253240585327 and perplexity is 243.04661120028817
At time: 248.86745977401733 and batch: 1250, loss is 5.5114592170715335 and perplexity is 247.51203747075937
At time: 249.96874952316284 and batch: 1300, loss is 5.490041465759277 and perplexity is 242.2672524452493
At time: 251.0697476863861 and batch: 1350, loss is 5.460094289779663 and perplexity is 235.11959269468838
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.317250162760416 and perplexity of 203.82263161035723
Finished 8 epochs...
Completing Train Step...
At time: 254.4564962387085 and batch: 50, loss is 5.531330404281616 and perplexity is 252.47958760559118
At time: 255.5550971031189 and batch: 100, loss is 5.550103759765625 and perplexity is 257.2642481990545
At time: 256.6587710380554 and batch: 150, loss is 5.506998271942138 and perplexity is 246.41035894342036
At time: 257.7613968849182 and batch: 200, loss is 5.496998882293701 and perplexity is 243.95868380652453
At time: 258.86460399627686 and batch: 250, loss is 5.534971218109131 and perplexity is 253.40049418676014
At time: 259.9661388397217 and batch: 300, loss is 5.525984926223755 and perplexity is 251.13356428417225
At time: 261.06916880607605 and batch: 350, loss is 5.537543687820435 and perplexity is 254.05319845391915
At time: 262.1703839302063 and batch: 400, loss is 5.5566195869445805 and perplexity is 258.9460106663682
At time: 263.2731742858887 and batch: 450, loss is 5.519722738265991 and perplexity is 249.56583254075707
At time: 264.3767080307007 and batch: 500, loss is 5.5510578536987305 and perplexity is 257.50981958792386
At time: 265.47995471954346 and batch: 550, loss is 5.522757396697998 and perplexity is 250.3243299069387
At time: 266.5824863910675 and batch: 600, loss is 5.482003221511841 and perplexity is 240.3276550195133
At time: 267.685870885849 and batch: 650, loss is 5.51800684928894 and perplexity is 249.13797246482397
At time: 268.7872259616852 and batch: 700, loss is 5.532866773605346 and perplexity is 252.86778763180246
At time: 269.88925409317017 and batch: 750, loss is 5.500485057830811 and perplexity is 244.81065079244954
At time: 270.99107336997986 and batch: 800, loss is 5.46709038734436 and perplexity is 236.77027975562893
At time: 272.0936396121979 and batch: 850, loss is 5.461922979354858 and perplexity is 235.54994681489072
At time: 273.19632744789124 and batch: 900, loss is 5.497369766235352 and perplexity is 244.04918094570513
At time: 274.29850721359253 and batch: 950, loss is 5.483119688034058 and perplexity is 240.59612264037395
At time: 275.3997428417206 and batch: 1000, loss is 5.502725200653076 and perplexity is 245.35967633285307
At time: 276.5022919178009 and batch: 1050, loss is 5.468479080200195 and perplexity is 237.09930935925277
At time: 277.6497664451599 and batch: 1100, loss is 5.470706224441528 and perplexity is 237.62795218411458
At time: 278.7528712749481 and batch: 1150, loss is 5.481963348388672 and perplexity is 240.3180725963657
At time: 279.8555238246918 and batch: 1200, loss is 5.469476985931396 and perplexity is 237.33603021182972
At time: 280.95763897895813 and batch: 1250, loss is 5.48579176902771 and perplexity is 241.23987466256597
At time: 282.05916380882263 and batch: 1300, loss is 5.459643859863281 and perplexity is 235.01371164399762
At time: 283.1612067222595 and batch: 1350, loss is 5.431104040145874 and perplexity is 228.40127044747518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.310072021484375 and perplexity of 202.36480247677716
Finished 9 epochs...
Completing Train Step...
At time: 286.5554828643799 and batch: 50, loss is 5.502202157974243 and perplexity is 245.23137630658596
At time: 287.6564738750458 and batch: 100, loss is 5.524500751495362 and perplexity is 250.76111465314392
At time: 288.76046919822693 and batch: 150, loss is 5.479713506698609 and perplexity is 239.77800274141023
At time: 289.863653421402 and batch: 200, loss is 5.47419960975647 and perplexity is 238.45952984759674
At time: 290.96659564971924 and batch: 250, loss is 5.51033574104309 and perplexity is 247.23411977607606
At time: 292.0684275627136 and batch: 300, loss is 5.502182369232178 and perplexity is 245.22652353414918
At time: 293.1720983982086 and batch: 350, loss is 5.514348106384277 and perplexity is 248.22810617418966
At time: 294.2740111351013 and batch: 400, loss is 5.5342011070251464 and perplexity is 253.2054227804667
At time: 295.3772392272949 and batch: 450, loss is 5.499003190994262 and perplexity is 244.44814266852666
At time: 296.4803464412689 and batch: 500, loss is 5.530488433837891 and perplexity is 252.26709672325785
At time: 297.5839204788208 and batch: 550, loss is 5.502761688232422 and perplexity is 245.36862907684244
At time: 298.6881332397461 and batch: 600, loss is 5.465877752304078 and perplexity is 236.48333783097794
At time: 299.7915048599243 and batch: 650, loss is 5.501329984664917 and perplexity is 245.01758529052336
At time: 300.89370107650757 and batch: 700, loss is 5.514489021301269 and perplexity is 248.2630876818165
At time: 301.99571895599365 and batch: 750, loss is 5.481250314712525 and perplexity is 240.14677879399986
At time: 303.09813690185547 and batch: 800, loss is 5.449692325592041 and perplexity is 232.68656319249516
At time: 304.2011158466339 and batch: 850, loss is 5.442791948318481 and perplexity is 231.0864651092817
At time: 305.332825422287 and batch: 900, loss is 5.479384965896607 and perplexity is 239.69923882337602
At time: 306.4349398612976 and batch: 950, loss is 5.4664059829711915 and perplexity is 236.6082885807853
At time: 307.53776144981384 and batch: 1000, loss is 5.485736808776855 and perplexity is 241.22661642287986
At time: 308.6415927410126 and batch: 1050, loss is 5.44903003692627 and perplexity is 232.53250853897197
At time: 309.74471378326416 and batch: 1100, loss is 5.453446664810181 and perplexity is 233.56178940223438
At time: 310.8482780456543 and batch: 1150, loss is 5.46594482421875 and perplexity is 236.49919975317312
At time: 311.9505887031555 and batch: 1200, loss is 5.449210004806519 and perplexity is 232.57436068753097
At time: 313.05393147468567 and batch: 1250, loss is 5.4683144092559814 and perplexity is 237.06026920658576
At time: 314.1575632095337 and batch: 1300, loss is 5.440905818939209 and perplexity is 230.651016923187
At time: 315.2603814601898 and batch: 1350, loss is 5.418711681365966 and perplexity is 225.5883055921208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.309581705729166 and perplexity of 202.26560414706242
Finished 10 epochs...
Completing Train Step...
At time: 318.6370368003845 and batch: 50, loss is 5.490561389923096 and perplexity is 242.3932457945528
At time: 319.76871728897095 and batch: 100, loss is 5.515440454483032 and perplexity is 248.49940582387808
At time: 320.87330389022827 and batch: 150, loss is 5.467093667984009 and perplexity is 236.7710565148705
At time: 321.9772062301636 and batch: 200, loss is 5.459629650115967 and perplexity is 235.01037218226637
At time: 323.07985186576843 and batch: 250, loss is 5.495315761566162 and perplexity is 243.54841725007267
At time: 324.1813817024231 and batch: 300, loss is 5.493755359649658 and perplexity is 243.1686801813094
At time: 325.2845413684845 and batch: 350, loss is 5.492956094741821 and perplexity is 242.97440163890863
At time: 326.38679790496826 and batch: 400, loss is 5.515821542739868 and perplexity is 248.59412407612868
At time: 327.4915189743042 and batch: 450, loss is 5.4837496471405025 and perplexity is 240.74773610893521
At time: 328.5953176021576 and batch: 500, loss is 5.516281700134277 and perplexity is 248.70854282382638
At time: 329.69868206977844 and batch: 550, loss is 5.491438112258911 and perplexity is 242.60585055124295
At time: 330.80227613449097 and batch: 600, loss is 5.451020994186401 and perplexity is 232.99593200013578
At time: 331.905611038208 and batch: 650, loss is 5.487320384979248 and perplexity is 241.60891977538412
At time: 333.05066680908203 and batch: 700, loss is 5.497056188583374 and perplexity is 243.9726645741163
At time: 334.1529881954193 and batch: 750, loss is 5.4698886299133305 and perplexity is 237.43374827150828
At time: 335.25740909576416 and batch: 800, loss is 5.433183765411377 and perplexity is 228.8767766300181
At time: 336.3612234592438 and batch: 850, loss is 5.426969652175903 and perplexity is 227.45892034538562
At time: 337.4644408226013 and batch: 900, loss is 5.463760776519775 and perplexity is 235.98323786792466
At time: 338.5665943622589 and batch: 950, loss is 5.452010431289673 and perplexity is 233.22658090764466
At time: 339.66825461387634 and batch: 1000, loss is 5.466477661132813 and perplexity is 236.62524883576782
At time: 340.77237939834595 and batch: 1050, loss is 5.435361881256103 and perplexity is 229.37584007538055
At time: 341.87572860717773 and batch: 1100, loss is 5.437769927978516 and perplexity is 229.928853388994
At time: 342.98053669929504 and batch: 1150, loss is 5.447955389022827 and perplexity is 232.28275219029277
At time: 344.083687543869 and batch: 1200, loss is 5.434777536392212 and perplexity is 229.24184463491832
At time: 345.1868007183075 and batch: 1250, loss is 5.452734832763672 and perplexity is 233.39559179510707
At time: 346.2894959449768 and batch: 1300, loss is 5.422144689559937 and perplexity is 226.36408295679408
At time: 347.3927834033966 and batch: 1350, loss is 5.4021141147613525 and perplexity is 221.874989911715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.306241048177084 and perplexity of 201.59103141464058
Finished 11 epochs...
Completing Train Step...
At time: 350.764577627182 and batch: 50, loss is 5.475393667221069 and perplexity is 238.74443429150432
At time: 351.8947660923004 and batch: 100, loss is 5.492908067703247 and perplexity is 242.96273257816617
At time: 352.9983332157135 and batch: 150, loss is 5.448537998199463 and perplexity is 232.4181216832184
At time: 354.1003465652466 and batch: 200, loss is 5.4438864040374755 and perplexity is 231.33951746464194
At time: 355.2044167518616 and batch: 250, loss is 5.477339630126953 and perplexity is 239.20947443330462
At time: 356.30558371543884 and batch: 300, loss is 5.470588512420655 and perplexity is 237.599982163883
At time: 357.40895414352417 and batch: 350, loss is 5.476636371612549 and perplexity is 239.04130747303745
At time: 358.51080536842346 and batch: 400, loss is 5.503395442962646 and perplexity is 245.52418189212844
At time: 359.6131389141083 and batch: 450, loss is 5.471079845428466 and perplexity is 237.71675156175627
At time: 360.7154610157013 and batch: 500, loss is 5.508026523590088 and perplexity is 246.66386111075073
At time: 361.84676122665405 and batch: 550, loss is 5.482112379074096 and perplexity is 240.35389003232683
At time: 362.95016169548035 and batch: 600, loss is 5.443732652664185 and perplexity is 231.3039514303687
At time: 364.05379343032837 and batch: 650, loss is 5.47620587348938 and perplexity is 238.93842278623168
At time: 365.155264377594 and batch: 700, loss is 5.492680931091309 and perplexity is 242.9075531131367
At time: 366.2571291923523 and batch: 750, loss is 5.462469434738159 and perplexity is 235.67869952696628
At time: 367.359094619751 and batch: 800, loss is 5.427727861404419 and perplexity is 227.6314471953594
At time: 368.46203875541687 and batch: 850, loss is 5.41938735961914 and perplexity is 225.74078221114652
At time: 369.56576013565063 and batch: 900, loss is 5.456142311096191 and perplexity is 234.19223872481422
At time: 370.66848039627075 and batch: 950, loss is 5.442605266571045 and perplexity is 231.0433295106059
At time: 371.77051186561584 and batch: 1000, loss is 5.458489055633545 and perplexity is 234.74247345938963
At time: 372.873991727829 and batch: 1050, loss is 5.422388477325439 and perplexity is 226.41927447800367
At time: 373.9768579006195 and batch: 1100, loss is 5.429004421234131 and perplexity is 227.92221791044875
At time: 375.08024859428406 and batch: 1150, loss is 5.4354919338226315 and perplexity is 229.40567293195969
At time: 376.18240547180176 and batch: 1200, loss is 5.426967439651489 and perplexity is 227.45841708752783
At time: 377.2850317955017 and batch: 1250, loss is 5.444749879837036 and perplexity is 231.53935980655092
At time: 378.38785433769226 and batch: 1300, loss is 5.415783176422119 and perplexity is 224.92863551890736
At time: 379.4902355670929 and batch: 1350, loss is 5.3928642845153805 and perplexity is 219.83214646211286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.303891194661459 and perplexity of 201.11787815889505
Finished 12 epochs...
Completing Train Step...
At time: 382.8873975276947 and batch: 50, loss is 5.463976573944092 and perplexity is 236.03416793792977
At time: 383.9898338317871 and batch: 100, loss is 5.485549402236939 and perplexity is 241.1814132131811
At time: 385.09467244148254 and batch: 150, loss is 5.438109378814698 and perplexity is 230.0069161790294
At time: 386.19636249542236 and batch: 200, loss is 5.432138204574585 and perplexity is 228.63759709608865
At time: 387.30001401901245 and batch: 250, loss is 5.468369989395142 and perplexity is 237.07344541550202
At time: 388.42224073410034 and batch: 300, loss is 5.457824993133545 and perplexity is 234.586641532404
At time: 389.56866979599 and batch: 350, loss is 5.4623407459259035 and perplexity is 235.6483722664817
At time: 390.6706051826477 and batch: 400, loss is 5.4883692169189455 and perplexity is 241.86245986458994
At time: 391.77342224121094 and batch: 450, loss is 5.460929756164551 and perplexity is 235.31610929088754
At time: 392.87642908096313 and batch: 500, loss is 5.494778680801391 and perplexity is 243.41764720006006
At time: 393.9789938926697 and batch: 550, loss is 5.472230997085571 and perplexity is 237.990557159886
At time: 395.08092617988586 and batch: 600, loss is 5.431166162490845 and perplexity is 228.41545971072037
At time: 396.1828200817108 and batch: 650, loss is 5.466495971679688 and perplexity is 236.62958161314612
At time: 397.28400444984436 and batch: 700, loss is 5.476863651275635 and perplexity is 239.09564287529568
At time: 398.38795733451843 and batch: 750, loss is 5.448116645812989 and perplexity is 232.32021238159487
At time: 399.4900207519531 and batch: 800, loss is 5.411793432235718 and perplexity is 224.03301563814074
At time: 400.5917932987213 and batch: 850, loss is 5.4047762966156006 and perplexity is 222.46644841950697
At time: 401.69332695007324 and batch: 900, loss is 5.4392421913146975 and perplexity is 230.26761852432202
At time: 402.7952153682709 and batch: 950, loss is 5.428205528259277 and perplexity is 227.74020516577903
At time: 403.89562249183655 and batch: 1000, loss is 5.443293008804321 and perplexity is 231.2022824190761
At time: 404.99868535995483 and batch: 1050, loss is 5.4056945896148685 and perplexity is 222.67083162913553
At time: 406.1011242866516 and batch: 1100, loss is 5.409221410751343 and perplexity is 223.457538296
At time: 407.20353841781616 and batch: 1150, loss is 5.4247619247436525 and perplexity is 226.9573069637816
At time: 408.3054418563843 and batch: 1200, loss is 5.411861581802368 and perplexity is 224.04828391132904
At time: 409.4085133075714 and batch: 1250, loss is 5.431779851913452 and perplexity is 228.5556788834157
At time: 410.51094365119934 and batch: 1300, loss is 5.3971023273468015 and perplexity is 220.7657815097846
At time: 411.61419701576233 and batch: 1350, loss is 5.381331863403321 and perplexity is 217.31151202035406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.303996175130209 and perplexity of 201.13899271630686
Annealing...
Finished 13 epochs...
Completing Train Step...
At time: 415.010618686676 and batch: 50, loss is 5.430596036911011 and perplexity is 228.2852713296992
At time: 416.1126048564911 and batch: 100, loss is 5.437250919342041 and perplexity is 229.8095492909172
At time: 417.24385118484497 and batch: 150, loss is 5.392051181793213 and perplexity is 219.65347299518967
At time: 418.3460600376129 and batch: 200, loss is 5.38845983505249 and perplexity is 218.86603603678537
At time: 419.4498028755188 and batch: 250, loss is 5.3971749114990235 and perplexity is 220.78180618843695
At time: 420.55308723449707 and batch: 300, loss is 5.392063283920288 and perplexity is 219.65613128551792
At time: 421.65618658065796 and batch: 350, loss is 5.391566190719605 and perplexity is 219.54696885036736
At time: 422.7591652870178 and batch: 400, loss is 5.41939453125 and perplexity is 225.74240114651175
At time: 423.86193084716797 and batch: 450, loss is 5.378619756698608 and perplexity is 216.72293850944715
At time: 424.96559715270996 and batch: 500, loss is 5.41338849067688 and perplexity is 224.39064653610063
At time: 426.06925439834595 and batch: 550, loss is 5.380460233688354 and perplexity is 217.12217937503962
At time: 427.1729700565338 and batch: 600, loss is 5.335620241165161 and perplexity is 207.60147186294122
At time: 428.2758946418762 and batch: 650, loss is 5.356271171569825 and perplexity is 211.9332086659671
At time: 429.37896966934204 and batch: 700, loss is 5.370514030456543 and perplexity is 214.97334215349886
At time: 430.48221731185913 and batch: 750, loss is 5.343540983200073 and perplexity is 209.25235906232754
At time: 431.5852451324463 and batch: 800, loss is 5.314034204483033 and perplexity is 203.16819940847265
At time: 432.68834257125854 and batch: 850, loss is 5.286318798065185 and perplexity is 197.61462546090877
At time: 433.7913603782654 and batch: 900, loss is 5.323041467666626 and perplexity is 205.00645524991734
At time: 434.8935933113098 and batch: 950, loss is 5.301557359695434 and perplexity is 200.64904951969154
At time: 435.9959681034088 and batch: 1000, loss is 5.3094032287597654 and perplexity is 202.22950761631574
At time: 437.09766960144043 and batch: 1050, loss is 5.270064115524292 and perplexity is 194.42842792636688
At time: 438.1997706890106 and batch: 1100, loss is 5.263656759262085 and perplexity is 193.18663826391557
At time: 439.3021824359894 and batch: 1150, loss is 5.276436986923218 and perplexity is 195.671451902852
At time: 440.40588569641113 and batch: 1200, loss is 5.245035037994385 and perplexity is 189.62245910378235
At time: 441.50878381729126 and batch: 1250, loss is 5.258672008514404 and perplexity is 192.22604716702403
At time: 442.61176681518555 and batch: 1300, loss is 5.238645496368409 and perplexity is 188.41472106330784
At time: 443.7138946056366 and batch: 1350, loss is 5.238302459716797 and perplexity is 188.35009899278302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1800048828125 and perplexity of 177.6836785873331
Finished 14 epochs...
Completing Train Step...
At time: 447.09075474739075 and batch: 50, loss is 5.356176290512085 and perplexity is 211.91310117288393
At time: 448.2238097190857 and batch: 100, loss is 5.368033208847046 and perplexity is 214.44069261823884
At time: 449.3264706134796 and batch: 150, loss is 5.333122806549072 and perplexity is 207.08364764596885
At time: 450.4282500743866 and batch: 200, loss is 5.332852191925049 and perplexity is 207.02761536443913
At time: 451.5306005477905 and batch: 250, loss is 5.3484617042541505 and perplexity is 210.28456907717344
At time: 452.63339042663574 and batch: 300, loss is 5.346739349365234 and perplexity is 209.9226961478224
At time: 453.73601388931274 and batch: 350, loss is 5.346949501037598 and perplexity is 209.96681638929383
At time: 454.8392584323883 and batch: 400, loss is 5.3772626304626465 and perplexity is 216.42901761265318
At time: 455.9472463130951 and batch: 450, loss is 5.3391783618927 and perplexity is 208.34145866353134
At time: 457.05037236213684 and batch: 500, loss is 5.375804624557495 and perplexity is 216.11369275553898
At time: 458.1525583267212 and batch: 550, loss is 5.347047491073608 and perplexity is 209.98739205328144
At time: 459.25514245033264 and batch: 600, loss is 5.304335060119629 and perplexity is 201.2071672527367
At time: 460.35777711868286 and batch: 650, loss is 5.325801115036011 and perplexity is 205.5729821225122
At time: 461.46028661727905 and batch: 700, loss is 5.341473388671875 and perplexity is 208.82015699300453
At time: 462.5632104873657 and batch: 750, loss is 5.3160255336761475 and perplexity is 203.57317726335515
At time: 463.6659367084503 and batch: 800, loss is 5.286235408782959 and perplexity is 197.59814720619866
At time: 464.768194437027 and batch: 850, loss is 5.262736263275147 and perplexity is 193.00889255831837
At time: 465.87068796157837 and batch: 900, loss is 5.304452705383301 and perplexity is 201.23083971542994
At time: 466.97323179244995 and batch: 950, loss is 5.284848232269287 and perplexity is 197.3242337243468
At time: 468.0765550136566 and batch: 1000, loss is 5.296383800506592 and perplexity is 199.6136604186252
At time: 469.1794455051422 and batch: 1050, loss is 5.261785469055176 and perplexity is 192.82546803217866
At time: 470.2818033695221 and batch: 1100, loss is 5.25873833656311 and perplexity is 192.23879756849303
At time: 471.38470911979675 and batch: 1150, loss is 5.27618878364563 and perplexity is 195.62289163381746
At time: 472.48771572113037 and batch: 1200, loss is 5.24824104309082 and perplexity is 190.2313652305887
At time: 473.63346767425537 and batch: 1250, loss is 5.2647364044189455 and perplexity is 193.39532391524278
At time: 474.7360780239105 and batch: 1300, loss is 5.245764541625976 and perplexity is 189.76083984481951
At time: 475.83927607536316 and batch: 1350, loss is 5.237358331680298 and perplexity is 188.17235630277796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172697347005208 and perplexity of 176.3899813700106
Finished 15 epochs...
Completing Train Step...
At time: 479.21904969215393 and batch: 50, loss is 5.340226821899414 and perplexity is 208.56001090230066
At time: 480.3504636287689 and batch: 100, loss is 5.350729055404663 and perplexity is 210.76189896955466
At time: 481.45417189598083 and batch: 150, loss is 5.316086912155152 and perplexity is 203.58567265881192
At time: 482.5571324825287 and batch: 200, loss is 5.315993394851684 and perplexity is 203.56663476588037
At time: 483.65963554382324 and batch: 250, loss is 5.3316880893707275 and perplexity is 206.78675420932115
At time: 484.76272535324097 and batch: 300, loss is 5.331318378448486 and perplexity is 206.710317018418
At time: 485.8655331134796 and batch: 350, loss is 5.33326189994812 and perplexity is 207.1124536177209
At time: 486.9684684276581 and batch: 400, loss is 5.365227470397949 and perplexity is 213.839871389667
At time: 488.0720286369324 and batch: 450, loss is 5.325794076919555 and perplexity is 205.57153528101537
At time: 489.17549419403076 and batch: 500, loss is 5.36317006111145 and perplexity is 213.40036752714283
At time: 490.27895426750183 and batch: 550, loss is 5.33443603515625 and perplexity is 207.35577445938577
At time: 491.38237380981445 and batch: 600, loss is 5.292408533096314 and perplexity is 198.82171787431588
At time: 492.4861226081848 and batch: 650, loss is 5.315069427490235 and perplexity is 203.3786327067348
At time: 493.5887098312378 and batch: 700, loss is 5.3296332263946535 and perplexity is 206.36227203986422
At time: 494.6924138069153 and batch: 750, loss is 5.306118898391723 and perplexity is 201.56640861728806
At time: 495.79625058174133 and batch: 800, loss is 5.275324363708496 and perplexity is 195.45386437192204
At time: 496.9000165462494 and batch: 850, loss is 5.254865198135376 and perplexity is 191.49567014101066
At time: 498.00376296043396 and batch: 900, loss is 5.297517032623291 and perplexity is 199.8399972514053
At time: 499.1075687408447 and batch: 950, loss is 5.277986526489258 and perplexity is 195.97488759160836
At time: 500.2105677127838 and batch: 1000, loss is 5.290953283309936 and perplexity is 198.5325930373053
At time: 501.3423569202423 and batch: 1050, loss is 5.256805372238159 and perplexity is 191.8675657354542
At time: 502.4460048675537 and batch: 1100, loss is 5.255759534835815 and perplexity is 191.66700835239797
At time: 503.5500400066376 and batch: 1150, loss is 5.272752342224121 and perplexity is 194.95179877208398
At time: 504.6540415287018 and batch: 1200, loss is 5.245841236114502 and perplexity is 189.77539401347866
At time: 505.7578749656677 and batch: 1250, loss is 5.263459625244141 and perplexity is 193.1485583592471
At time: 506.8606939315796 and batch: 1300, loss is 5.243865251541138 and perplexity is 189.4007710090362
At time: 507.96491384506226 and batch: 1350, loss is 5.231906156539917 and perplexity is 187.14919940947345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.167034912109375 and perplexity of 175.394007065228
Finished 16 epochs...
Completing Train Step...
At time: 511.3682653903961 and batch: 50, loss is 5.327834510803223 and perplexity is 205.9914186335527
At time: 512.4714913368225 and batch: 100, loss is 5.338293905258179 and perplexity is 208.15727114311466
At time: 513.5754113197327 and batch: 150, loss is 5.304304180145263 and perplexity is 201.20095407650152
At time: 514.6779096126556 and batch: 200, loss is 5.303121271133423 and perplexity is 200.9630923668497
At time: 515.7816708087921 and batch: 250, loss is 5.319753046035767 and perplexity is 204.3334148148758
At time: 516.8857796192169 and batch: 300, loss is 5.319403162002564 and perplexity is 204.26193432125314
At time: 517.990226984024 and batch: 350, loss is 5.320445394515991 and perplexity is 204.47493372863127
At time: 519.0943515300751 and batch: 400, loss is 5.354117040634155 and perplexity is 211.47716814672555
At time: 520.1980428695679 and batch: 450, loss is 5.3144894790649415 and perplexity is 203.26071778454994
At time: 521.3026468753815 and batch: 500, loss is 5.352299737930298 and perplexity is 211.09319911690076
At time: 522.4064424037933 and batch: 550, loss is 5.32394642829895 and perplexity is 205.19206199202122
At time: 523.510463476181 and batch: 600, loss is 5.281552381515503 and perplexity is 196.67495305372185
At time: 524.614227771759 and batch: 650, loss is 5.3040141677856445 and perplexity is 201.14261177345566
At time: 525.7172908782959 and batch: 700, loss is 5.319580459594727 and perplexity is 204.29815268099802
At time: 526.820531129837 and batch: 750, loss is 5.296025133132934 and perplexity is 199.5420783491404
At time: 527.9238333702087 and batch: 800, loss is 5.265952415466309 and perplexity is 193.63063780878298
At time: 529.0735538005829 and batch: 850, loss is 5.245080480575561 and perplexity is 189.63107623356385
At time: 530.1774578094482 and batch: 900, loss is 5.287914276123047 and perplexity is 197.93016691253987
At time: 531.2819728851318 and batch: 950, loss is 5.270721321105957 and perplexity is 194.55624937231758
At time: 532.3856663703918 and batch: 1000, loss is 5.283428554534912 and perplexity is 197.044295661211
At time: 533.4890697002411 and batch: 1050, loss is 5.249799747467041 and perplexity is 190.52811090137578
At time: 534.5929026603699 and batch: 1100, loss is 5.24826584815979 and perplexity is 190.23608399124794
At time: 535.6963229179382 and batch: 1150, loss is 5.266286115646363 and perplexity is 193.6952631696313
At time: 536.8002667427063 and batch: 1200, loss is 5.239943246841431 and perplexity is 188.6593950852669
At time: 537.9048182964325 and batch: 1250, loss is 5.259367246627807 and perplexity is 192.35973650898137
At time: 539.0091848373413 and batch: 1300, loss is 5.238795566558838 and perplexity is 188.4429986181334
At time: 540.1125564575195 and batch: 1350, loss is 5.224444227218628 and perplexity is 185.75790264565845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.161634114583333 and perplexity of 174.44929294695635
Finished 17 epochs...
Completing Train Step...
At time: 543.5185763835907 and batch: 50, loss is 5.317121229171753 and perplexity is 203.7963537211006
At time: 544.6224820613861 and batch: 100, loss is 5.327470531463623 and perplexity is 205.9164556563503
At time: 545.7270066738129 and batch: 150, loss is 5.294806699752808 and perplexity is 199.29909767808059
At time: 546.8305826187134 and batch: 200, loss is 5.292215051651001 and perplexity is 198.7832532821945
At time: 547.9341630935669 and batch: 250, loss is 5.309806404113769 and perplexity is 202.3110580080883
At time: 549.037614107132 and batch: 300, loss is 5.309932041168213 and perplexity is 202.33647737027127
At time: 550.14182472229 and batch: 350, loss is 5.3122436046600345 and perplexity is 202.80473197604695
At time: 551.2458250522614 and batch: 400, loss is 5.344275741577149 and perplexity is 209.4061654844303
At time: 552.3505582809448 and batch: 450, loss is 5.306323699951172 and perplexity is 201.6076939596122
At time: 553.4552090167999 and batch: 500, loss is 5.343080730438232 and perplexity is 209.15607224598364
At time: 554.5592126846313 and batch: 550, loss is 5.313521032333374 and perplexity is 203.06396589399571
At time: 555.663019657135 and batch: 600, loss is 5.273675270080567 and perplexity is 195.13180827294875
At time: 556.7667095661163 and batch: 650, loss is 5.296543207168579 and perplexity is 199.6454827021941
At time: 557.8981931209564 and batch: 700, loss is 5.311804761886597 and perplexity is 202.7157521105138
At time: 559.0026171207428 and batch: 750, loss is 5.286884994506836 and perplexity is 197.72654584013313
At time: 560.1065123081207 and batch: 800, loss is 5.259461240768433 and perplexity is 192.37781804687145
At time: 561.2106034755707 and batch: 850, loss is 5.237210350036621 and perplexity is 188.1445123084486
At time: 562.3145108222961 and batch: 900, loss is 5.280203475952148 and perplexity is 196.40983596453276
At time: 563.4181818962097 and batch: 950, loss is 5.264428300857544 and perplexity is 193.33574730554017
At time: 564.5213122367859 and batch: 1000, loss is 5.277487554550171 and perplexity is 195.87712601410473
At time: 565.6250681877136 and batch: 1050, loss is 5.245157012939453 and perplexity is 189.64558970346332
At time: 566.729410648346 and batch: 1100, loss is 5.241934289932251 and perplexity is 189.03539826542243
At time: 567.8350377082825 and batch: 1150, loss is 5.260589532852173 and perplexity is 192.59499891474783
At time: 568.9387245178223 and batch: 1200, loss is 5.235735912322998 and perplexity is 187.86730935335453
At time: 570.0429129600525 and batch: 1250, loss is 5.254299077987671 and perplexity is 191.38729126457284
At time: 571.1472337245941 and batch: 1300, loss is 5.232242012023926 and perplexity is 187.21206505071723
At time: 572.2515993118286 and batch: 1350, loss is 5.216491432189941 and perplexity is 184.28646688975138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.157977294921875 and perplexity of 173.8125283188717
Finished 18 epochs...
Completing Train Step...
At time: 575.626832485199 and batch: 50, loss is 5.308005504608154 and perplexity is 201.9470439984481
At time: 576.7581896781921 and batch: 100, loss is 5.317361679077148 and perplexity is 203.84536242690598
At time: 577.8621373176575 and batch: 150, loss is 5.28532187461853 and perplexity is 197.41771697503629
At time: 578.9644651412964 and batch: 200, loss is 5.282796602249146 and perplexity is 196.91981240605242
At time: 580.0683100223541 and batch: 250, loss is 5.300287456512451 and perplexity is 200.3944063733359
At time: 581.1723091602325 and batch: 300, loss is 5.300979251861572 and perplexity is 200.53308625517278
At time: 582.2751684188843 and batch: 350, loss is 5.304401159286499 and perplexity is 201.2204673184171
At time: 583.3786947727203 and batch: 400, loss is 5.336273956298828 and perplexity is 207.73722845510437
At time: 584.4824397563934 and batch: 450, loss is 5.297152996063232 and perplexity is 199.76726142629687
At time: 585.6158607006073 and batch: 500, loss is 5.335000543594361 and perplexity is 207.47286158898612
At time: 586.719625711441 and batch: 550, loss is 5.304715776443482 and perplexity is 201.28378468961495
At time: 587.8264148235321 and batch: 600, loss is 5.264549169540405 and perplexity is 193.35911695496796
At time: 588.9302659034729 and batch: 650, loss is 5.2890456104278565 and perplexity is 198.15421881522917
At time: 590.0332159996033 and batch: 700, loss is 5.304530649185181 and perplexity is 201.24652502341127
At time: 591.136650800705 and batch: 750, loss is 5.280847654342652 and perplexity is 196.53639969697755
At time: 592.2399821281433 and batch: 800, loss is 5.253141841888428 and perplexity is 191.16593908525417
At time: 593.3434834480286 and batch: 850, loss is 5.230038633346558 and perplexity is 186.80002009068022
At time: 594.4476625919342 and batch: 900, loss is 5.274790916442871 and perplexity is 195.34962784723348
At time: 595.5512912273407 and batch: 950, loss is 5.258795938491821 and perplexity is 192.2498712129347
At time: 596.6538174152374 and batch: 1000, loss is 5.272135744094848 and perplexity is 194.8316289097263
At time: 597.7568480968475 and batch: 1050, loss is 5.238144760131836 and perplexity is 188.32039860227562
At time: 598.8596408367157 and batch: 1100, loss is 5.236954336166382 and perplexity is 188.09635086894951
At time: 599.96338057518 and batch: 1150, loss is 5.253261976242065 and perplexity is 191.18890606131745
At time: 601.067485332489 and batch: 1200, loss is 5.229904756546021 and perplexity is 186.7750135755837
At time: 602.1715459823608 and batch: 1250, loss is 5.249561805725097 and perplexity is 190.4827817038467
At time: 603.2748460769653 and batch: 1300, loss is 5.226346025466919 and perplexity is 186.11151284056157
At time: 604.3781044483185 and batch: 1350, loss is 5.209180564880371 and perplexity is 182.9440859468937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.152513834635417 and perplexity of 172.86549985499852
Finished 19 epochs...
Completing Train Step...
At time: 607.7744274139404 and batch: 50, loss is 5.300619249343872 and perplexity is 200.4609068324052
At time: 608.9053881168365 and batch: 100, loss is 5.3104364204406735 and perplexity is 202.43855743689036
At time: 610.0077195167542 and batch: 150, loss is 5.276551094055176 and perplexity is 195.693780684947
At time: 611.1104533672333 and batch: 200, loss is 5.272695684432984 and perplexity is 194.94075354668936
At time: 612.2135713100433 and batch: 250, loss is 5.29187572479248 and perplexity is 198.71581222825927
At time: 613.3448283672333 and batch: 300, loss is 5.293999834060669 and perplexity is 199.13835493131438
At time: 614.4482262134552 and batch: 350, loss is 5.295035314559937 and perplexity is 199.34466561141085
At time: 615.5514035224915 and batch: 400, loss is 5.3274124908447265 and perplexity is 205.90450448465305
At time: 616.6550028324127 and batch: 450, loss is 5.288693981170654 and perplexity is 198.08455424322437
At time: 617.7571907043457 and batch: 500, loss is 5.327105350494385 and perplexity is 205.84127261403526
At time: 618.8600130081177 and batch: 550, loss is 5.297336254119873 and perplexity is 199.80387374105467
At time: 619.962893486023 and batch: 600, loss is 5.256285743713379 and perplexity is 191.76789177427736
At time: 621.0657382011414 and batch: 650, loss is 5.281069707870484 and perplexity is 196.58004614362204
At time: 622.1689095497131 and batch: 700, loss is 5.2957529449462895 and perplexity is 199.48777274368263
At time: 623.2720365524292 and batch: 750, loss is 5.274144163131714 and perplexity is 195.2233256761662
At time: 624.374924659729 and batch: 800, loss is 5.24567587852478 and perplexity is 189.74401580612005
At time: 625.4778873920441 and batch: 850, loss is 5.221093292236328 and perplexity is 185.1364817434468
At time: 626.5803470611572 and batch: 900, loss is 5.26738471031189 and perplexity is 193.9081726817009
At time: 627.6853284835815 and batch: 950, loss is 5.251683568954467 and perplexity is 190.88737013453772
At time: 628.788400888443 and batch: 1000, loss is 5.264787759780884 and perplexity is 193.40525605713177
At time: 629.8932621479034 and batch: 1050, loss is 5.232389917373657 and perplexity is 187.2397567644983
At time: 630.9961550235748 and batch: 1100, loss is 5.227948274612427 and perplexity is 186.4099488735735
At time: 632.0998899936676 and batch: 1150, loss is 5.246478633880615 and perplexity is 189.89639498446383
At time: 633.2029139995575 and batch: 1200, loss is 5.221386299133301 and perplexity is 185.19073595752022
At time: 634.3066072463989 and batch: 1250, loss is 5.241156482696534 and perplexity is 188.888422331727
At time: 635.4099025726318 and batch: 1300, loss is 5.219295253753662 and perplexity is 184.80389831323174
At time: 636.5128259658813 and batch: 1350, loss is 5.200761671066284 and perplexity is 181.41036429215472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.148095296223958 and perplexity of 172.1033719894461
Finished 20 epochs...
Completing Train Step...
At time: 639.9234170913696 and batch: 50, loss is 5.290170316696167 and perplexity is 198.37720948321757
At time: 641.0265038013458 and batch: 100, loss is 5.300490293502808 and perplexity is 200.43505789428573
At time: 642.1579632759094 and batch: 150, loss is 5.267897529602051 and perplexity is 194.00763803486797
At time: 643.2605993747711 and batch: 200, loss is 5.261904735565185 and perplexity is 192.84846702426927
At time: 644.3637008666992 and batch: 250, loss is 5.283392114639282 and perplexity is 197.03711551846527
At time: 645.466539144516 and batch: 300, loss is 5.284359064102173 and perplexity is 197.22773259517322
At time: 646.5707161426544 and batch: 350, loss is 5.285348529815674 and perplexity is 197.42297925333514
At time: 647.6737139225006 and batch: 400, loss is 5.3194584274292 and perplexity is 204.27322325613991
At time: 648.7770557403564 and batch: 450, loss is 5.279972066879273 and perplexity is 196.36439020497193
At time: 649.8801724910736 and batch: 500, loss is 5.321398725509644 and perplexity is 204.66995896741167
At time: 650.9832727909088 and batch: 550, loss is 5.2901135921478275 and perplexity is 198.3659569447594
At time: 652.0865750312805 and batch: 600, loss is 5.249057054519653 and perplexity is 190.3866595510924
At time: 653.189691066742 and batch: 650, loss is 5.273964252471924 and perplexity is 195.1882060781271
At time: 654.29301404953 and batch: 700, loss is 5.286871013641357 and perplexity is 197.72378147121836
At time: 655.3961012363434 and batch: 750, loss is 5.2640422916412355 and perplexity is 193.2611323271995
At time: 656.4986510276794 and batch: 800, loss is 5.2374101257324215 and perplexity is 188.18210276401072
At time: 657.6023573875427 and batch: 850, loss is 5.213961353302002 and perplexity is 183.82079692981566
At time: 658.70507979393 and batch: 900, loss is 5.2593288993835445 and perplexity is 192.35236018461092
At time: 659.8082151412964 and batch: 950, loss is 5.241667356491089 and perplexity is 188.98494513017602
At time: 660.9109375476837 and batch: 1000, loss is 5.254460201263428 and perplexity is 191.41813069628807
At time: 662.0131611824036 and batch: 1050, loss is 5.22219690322876 and perplexity is 185.34091318544318
At time: 663.1161651611328 and batch: 1100, loss is 5.218011474609375 and perplexity is 184.56680314427354
At time: 664.2194755077362 and batch: 1150, loss is 5.235321025848389 and perplexity is 187.78938191432078
At time: 665.3234512805939 and batch: 1200, loss is 5.212182035446167 and perplexity is 183.49401211680697
At time: 666.4262175559998 and batch: 1250, loss is 5.232013330459595 and perplexity is 187.16925799759827
At time: 667.5294892787933 and batch: 1300, loss is 5.211297817230225 and perplexity is 183.33183507928874
At time: 668.63165974617 and batch: 1350, loss is 5.189981298446655 and perplexity is 179.46519662250026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1378096516927085 and perplexity of 170.34225054350168
Finished 21 epochs...
Completing Train Step...
At time: 672.0525822639465 and batch: 50, loss is 5.278960828781128 and perplexity is 196.1659194200003
At time: 673.1560525894165 and batch: 100, loss is 5.288995895385742 and perplexity is 198.14436781476917
At time: 674.2590487003326 and batch: 150, loss is 5.257595071792602 and perplexity is 192.01914330912143
At time: 675.3615839481354 and batch: 200, loss is 5.250653657913208 and perplexity is 190.69087432836824
At time: 676.4641551971436 and batch: 250, loss is 5.272179040908814 and perplexity is 194.84006468113745
At time: 677.5671679973602 and batch: 300, loss is 5.271823453903198 and perplexity is 194.7707944024989
At time: 678.6705496311188 and batch: 350, loss is 5.271937112808228 and perplexity is 194.7929330958285
At time: 679.7738502025604 and batch: 400, loss is 5.306728839874268 and perplexity is 201.68938983325108
At time: 680.8765752315521 and batch: 450, loss is 5.267957496643066 and perplexity is 194.0192724476925
At time: 681.9798333644867 and batch: 500, loss is 5.309779329299927 and perplexity is 202.30558054800542
At time: 683.0816283226013 and batch: 550, loss is 5.278000898361206 and perplexity is 195.97770413783743
At time: 684.1848146915436 and batch: 600, loss is 5.237361125946045 and perplexity is 188.1728821070823
At time: 685.2878289222717 and batch: 650, loss is 5.261805877685547 and perplexity is 192.82940337603927
At time: 686.390379190445 and batch: 700, loss is 5.273947811126709 and perplexity is 195.18499694783034
At time: 687.4947576522827 and batch: 750, loss is 5.251532831192017 and perplexity is 190.85859836803385
At time: 688.5978951454163 and batch: 800, loss is 5.225035076141357 and perplexity is 185.8676899329814
At time: 689.7011060714722 and batch: 850, loss is 5.200278444290161 and perplexity is 181.32272312364756
At time: 690.8039865493774 and batch: 900, loss is 5.245801076889038 and perplexity is 189.76777293367243
At time: 691.9079315662384 and batch: 950, loss is 5.229091548919678 and perplexity is 186.6231884511752
At time: 693.0112090110779 and batch: 1000, loss is 5.242646312713623 and perplexity is 189.17004370509477
At time: 694.1146676540375 and batch: 1050, loss is 5.208799848556518 and perplexity is 182.87444940374692
At time: 695.2173218727112 and batch: 1100, loss is 5.205960531234741 and perplexity is 182.35594725624372
At time: 696.3207442760468 and batch: 1150, loss is 5.223411893844604 and perplexity is 185.56623751144767
At time: 697.4521536827087 and batch: 1200, loss is 5.198466806411743 and perplexity is 180.9945293840858
At time: 698.5554552078247 and batch: 1250, loss is 5.218670806884766 and perplexity is 184.68853412072323
At time: 699.6590888500214 and batch: 1300, loss is 5.19816026687622 and perplexity is 180.93905590795737
At time: 700.7625424861908 and batch: 1350, loss is 5.175820913314819 and perplexity is 176.9418085589128
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1265283203125 and perplexity of 168.43136211613216
Finished 22 epochs...
Completing Train Step...
At time: 704.1466429233551 and batch: 50, loss is 5.264665870666504 and perplexity is 193.38168349840296
At time: 705.2788190841675 and batch: 100, loss is 5.274430656433106 and perplexity is 195.27926386382327
At time: 706.3832671642303 and batch: 150, loss is 5.241323184967041 and perplexity is 188.91991308531945
At time: 707.4880454540253 and batch: 200, loss is 5.234369831085205 and perplexity is 187.6108425639713
At time: 708.5909023284912 and batch: 250, loss is 5.25631688117981 and perplexity is 191.7738630335345
At time: 709.695164680481 and batch: 300, loss is 5.256138010025024 and perplexity is 191.7395632889049
At time: 710.799684047699 and batch: 350, loss is 5.257314395904541 and perplexity is 191.96525572837447
At time: 711.90398478508 and batch: 400, loss is 5.292345237731934 and perplexity is 198.809133779498
At time: 713.0078711509705 and batch: 450, loss is 5.251364479064941 and perplexity is 190.82646962157523
At time: 714.1112742424011 and batch: 500, loss is 5.295711574554443 and perplexity is 199.4795200270659
At time: 715.2157607078552 and batch: 550, loss is 5.262739753723144 and perplexity is 193.0095662469966
At time: 716.3193128108978 and batch: 600, loss is 5.221606254577637 and perplexity is 185.23147414826377
At time: 717.423299074173 and batch: 650, loss is 5.243966970443726 and perplexity is 189.42003762748558
At time: 718.5267655849457 and batch: 700, loss is 5.258203582763672 and perplexity is 192.13602462265462
At time: 719.6306488513947 and batch: 750, loss is 5.235988836288453 and perplexity is 187.91483150770807
At time: 720.7351236343384 and batch: 800, loss is 5.209693803787231 and perplexity is 183.0380040687371
At time: 721.8391885757446 and batch: 850, loss is 5.184156436920166 and perplexity is 178.42287533899713
At time: 722.9423418045044 and batch: 900, loss is 5.230432100296021 and perplexity is 186.87353418648001
At time: 724.0459978580475 and batch: 950, loss is 5.21455719947815 and perplexity is 183.93035848643845
At time: 725.1492214202881 and batch: 1000, loss is 5.228136434555053 and perplexity is 186.4450270589098
At time: 726.2986927032471 and batch: 1050, loss is 5.19450156211853 and perplexity is 180.27826288366697
At time: 727.4021203517914 and batch: 1100, loss is 5.1919199657440185 and perplexity is 179.8134574020231
At time: 728.5055155754089 and batch: 1150, loss is 5.208831949234009 and perplexity is 182.88031989169127
At time: 729.6099729537964 and batch: 1200, loss is 5.1832218360900875 and perplexity is 178.25619907162164
At time: 730.7124359607697 and batch: 1250, loss is 5.204854707717896 and perplexity is 182.15440521683254
At time: 731.8160524368286 and batch: 1300, loss is 5.184786310195923 and perplexity is 178.53529454116577
At time: 732.9205603599548 and batch: 1350, loss is 5.160471000671387 and perplexity is 174.24650650212942
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.109410400390625 and perplexity of 165.5727044873548
Finished 23 epochs...
Completing Train Step...
At time: 736.3079452514648 and batch: 50, loss is 5.2478040504455565 and perplexity is 190.14825368397442
At time: 737.4510123729706 and batch: 100, loss is 5.258963527679444 and perplexity is 192.2820929126006
At time: 738.5603868961334 and batch: 150, loss is 5.224552879333496 and perplexity is 185.77808673113626
At time: 739.6702055931091 and batch: 200, loss is 5.21818281173706 and perplexity is 184.59842899945463
At time: 740.7796807289124 and batch: 250, loss is 5.239165802001953 and perplexity is 188.51277981216725
At time: 741.8899364471436 and batch: 300, loss is 5.24254301071167 and perplexity is 189.15050307018132
At time: 742.9992182254791 and batch: 350, loss is 5.24502537727356 and perplexity is 189.62062722299146
At time: 744.1071991920471 and batch: 400, loss is 5.279849748611451 and perplexity is 196.34037272181854
At time: 745.2129786014557 and batch: 450, loss is 5.240246953964234 and perplexity is 188.71670098900304
At time: 746.3184380531311 and batch: 500, loss is 5.283067474365234 and perplexity is 196.97315971716188
At time: 747.4240288734436 and batch: 550, loss is 5.250752658843994 and perplexity is 190.70975383694812
At time: 748.528550863266 and batch: 600, loss is 5.20668285369873 and perplexity is 182.48771463692938
At time: 749.6325993537903 and batch: 650, loss is 5.231834239959717 and perplexity is 187.1357407630204
At time: 750.7346017360687 and batch: 700, loss is 5.247619905471802 and perplexity is 190.11324206249628
At time: 751.838621377945 and batch: 750, loss is 5.227255058288574 and perplexity is 186.28077123328336
At time: 752.9424209594727 and batch: 800, loss is 5.200840301513672 and perplexity is 181.42462923108172
At time: 754.0738389492035 and batch: 850, loss is 5.176130352020263 and perplexity is 176.99656967525974
At time: 755.1772809028625 and batch: 900, loss is 5.221877317428589 and perplexity is 185.28169032529513
At time: 756.2820885181427 and batch: 950, loss is 5.206182336807251 and perplexity is 182.39639930760484
At time: 757.3855834007263 and batch: 1000, loss is 5.221047077178955 and perplexity is 185.12792584802833
At time: 758.4896507263184 and batch: 1050, loss is 5.1846699714660645 and perplexity is 178.5145251799279
At time: 759.5925385951996 and batch: 1100, loss is 5.18300085067749 and perplexity is 178.21681140413202
At time: 760.6961627006531 and batch: 1150, loss is 5.200387878417969 and perplexity is 181.3425671034888
At time: 761.7999362945557 and batch: 1200, loss is 5.177750577926636 and perplexity is 177.28357654798603
At time: 762.9120342731476 and batch: 1250, loss is 5.198214426040649 and perplexity is 180.94885568140924
At time: 764.0168089866638 and batch: 1300, loss is 5.174343452453614 and perplexity is 176.680576989286
At time: 765.1206297874451 and batch: 1350, loss is 5.151264877319336 and perplexity is 172.64973299410414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.100197347005208 and perplexity of 164.05427972629155
Finished 24 epochs...
Completing Train Step...
At time: 768.5285103321075 and batch: 50, loss is 5.238224000930786 and perplexity is 188.33532185237678
At time: 769.632655620575 and batch: 100, loss is 5.253856554031372 and perplexity is 191.3026165399359
At time: 770.7366552352905 and batch: 150, loss is 5.217874040603638 and perplexity is 184.5414391321702
At time: 771.8405044078827 and batch: 200, loss is 5.209325075149536 and perplexity is 182.9705251563187
At time: 772.9448750019073 and batch: 250, loss is 5.2312976741790775 and perplexity is 187.03535706183024
At time: 774.0492098331451 and batch: 300, loss is 5.233567218780518 and perplexity is 187.4603242052603
At time: 775.1518580913544 and batch: 350, loss is 5.239018459320068 and perplexity is 188.48500587981326
At time: 776.2557120323181 and batch: 400, loss is 5.27319640159607 and perplexity is 195.03838816940086
At time: 777.3599627017975 and batch: 450, loss is 5.230634050369263 and perplexity is 186.9112771213619
At time: 778.4645910263062 and batch: 500, loss is 5.2766831111907955 and perplexity is 195.7196173227336
At time: 779.5699903964996 and batch: 550, loss is 5.243362989425659 and perplexity is 189.30566606292092
At time: 780.674248456955 and batch: 600, loss is 5.1994290447235105 and perplexity is 181.16877307301158
At time: 781.808352470398 and batch: 650, loss is 5.2255504703521725 and perplexity is 185.9635097547201
At time: 782.9100558757782 and batch: 700, loss is 5.240926380157471 and perplexity is 188.84496362631992
At time: 784.0143892765045 and batch: 750, loss is 5.2202145385742185 and perplexity is 184.9738638431269
At time: 785.1189188957214 and batch: 800, loss is 5.193482713699341 and perplexity is 180.09468019785905
At time: 786.2233240604401 and batch: 850, loss is 5.170540637969971 and perplexity is 176.00996943834662
At time: 787.3267154693604 and batch: 900, loss is 5.216016702651977 and perplexity is 184.19900142333472
At time: 788.4331951141357 and batch: 950, loss is 5.201188163757324 and perplexity is 181.48775098786126
At time: 789.5361413955688 and batch: 1000, loss is 5.214993114471436 and perplexity is 184.0105539653591
At time: 790.6404604911804 and batch: 1050, loss is 5.178621253967285 and perplexity is 177.4380003272739
At time: 791.7444670200348 and batch: 1100, loss is 5.179545059204101 and perplexity is 177.60199421873136
At time: 792.8478345870972 and batch: 1150, loss is 5.195711879730225 and perplexity is 180.49658893552203
At time: 793.9512577056885 and batch: 1200, loss is 5.1722407722473145 and perplexity is 176.3094645393467
At time: 795.0540187358856 and batch: 1250, loss is 5.19230167388916 and perplexity is 179.8821067644964
At time: 796.1593787670135 and batch: 1300, loss is 5.169667901992798 and perplexity is 175.85642621676922
At time: 797.2637267112732 and batch: 1350, loss is 5.145456676483154 and perplexity is 171.6498552269242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096996663411458 and perplexity of 163.53003330569388
Finished 25 epochs...
Completing Train Step...
At time: 800.6887164115906 and batch: 50, loss is 5.231597185134888 and perplexity is 187.0913845904046
At time: 801.7923285961151 and batch: 100, loss is 5.248069610595703 and perplexity is 190.19875618820234
At time: 802.8964107036591 and batch: 150, loss is 5.211896371841431 and perplexity is 183.44160204204
At time: 804.0002028942108 and batch: 200, loss is 5.2038650226593015 and perplexity is 181.97421890219132
At time: 805.1066811084747 and batch: 250, loss is 5.225010528564453 and perplexity is 185.86312738756865
At time: 806.2109167575836 and batch: 300, loss is 5.228835458755493 and perplexity is 186.57540220725875
At time: 807.3126239776611 and batch: 350, loss is 5.234747247695923 and perplexity is 187.68166337594045
At time: 808.4171476364136 and batch: 400, loss is 5.267742233276367 and perplexity is 193.97751170084166
At time: 809.5387461185455 and batch: 450, loss is 5.225359716415405 and perplexity is 185.92803986625734
At time: 810.6801664829254 and batch: 500, loss is 5.271018743515015 and perplexity is 194.61412336678794
At time: 811.784193277359 and batch: 550, loss is 5.2385837364196775 and perplexity is 188.4030849391217
At time: 812.8904323577881 and batch: 600, loss is 5.195065441131592 and perplexity is 180.37994667860303
At time: 813.9937705993652 and batch: 650, loss is 5.22223536491394 and perplexity is 185.3480418463865
At time: 815.0962815284729 and batch: 700, loss is 5.235917978286743 and perplexity is 187.90151670999137
At time: 816.19970703125 and batch: 750, loss is 5.215336961746216 and perplexity is 184.07383637198888
At time: 817.3039333820343 and batch: 800, loss is 5.1877710819244385 and perplexity is 179.0689777058563
At time: 818.4082765579224 and batch: 850, loss is 5.168096351623535 and perplexity is 175.5802760340074
At time: 819.5119652748108 and batch: 900, loss is 5.212465000152588 and perplexity is 183.54594179286187
At time: 820.6157891750336 and batch: 950, loss is 5.198996000289917 and perplexity is 181.09033592890137
At time: 821.7217104434967 and batch: 1000, loss is 5.209106159210205 and perplexity is 182.9304743759713
At time: 822.8255393505096 and batch: 1050, loss is 5.174192752838135 and perplexity is 176.65395330041133
At time: 823.9284927845001 and batch: 1100, loss is 5.176424522399902 and perplexity is 177.0486444824132
At time: 825.0310964584351 and batch: 1150, loss is 5.192886304855347 and perplexity is 179.9873021616209
At time: 826.1338777542114 and batch: 1200, loss is 5.16960973739624 and perplexity is 175.84619789615218
At time: 827.2375626564026 and batch: 1250, loss is 5.188063325881958 and perplexity is 179.12131718014513
At time: 828.341728925705 and batch: 1300, loss is 5.165032272338867 and perplexity is 175.04310753112716
At time: 829.4452702999115 and batch: 1350, loss is 5.140807991027832 and perplexity is 170.8537608712997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.09616943359375 and perplexity of 163.39481232317806
Finished 26 epochs...
Completing Train Step...
At time: 832.8251912593842 and batch: 50, loss is 5.227113904953003 and perplexity is 186.25447893673737
At time: 833.9635639190674 and batch: 100, loss is 5.244811315536499 and perplexity is 189.58004104627415
At time: 835.0716667175293 and batch: 150, loss is 5.208546209335327 and perplexity is 182.8280711527447
At time: 836.1797688007355 and batch: 200, loss is 5.199610166549682 and perplexity is 181.20158966384656
At time: 837.2874481678009 and batch: 250, loss is 5.221455745697021 and perplexity is 185.20359726434688
At time: 838.4273936748505 and batch: 300, loss is 5.224925260543824 and perplexity is 185.84727988224068
At time: 839.5341131687164 and batch: 350, loss is 5.230168962478638 and perplexity is 186.82436716170307
At time: 840.6430826187134 and batch: 400, loss is 5.262951021194458 and perplexity is 193.05034719768943
At time: 841.7511970996857 and batch: 450, loss is 5.220858354568481 and perplexity is 185.09299131916202
At time: 842.8607096672058 and batch: 500, loss is 5.265526618957519 and perplexity is 193.5482081095938
At time: 843.9679925441742 and batch: 550, loss is 5.233993768692017 and perplexity is 187.5403024461027
At time: 845.0767931938171 and batch: 600, loss is 5.190074625015259 and perplexity is 179.4819462750665
At time: 846.1857142448425 and batch: 650, loss is 5.217248258590698 and perplexity is 184.42599254488556
At time: 847.2946417331696 and batch: 700, loss is 5.230342178344727 and perplexity is 186.85673090914383
At time: 848.403183221817 and batch: 750, loss is 5.210691804885864 and perplexity is 183.22076738171347
At time: 849.5124306678772 and batch: 800, loss is 5.183344631195069 and perplexity is 178.2780894042855
At time: 850.6198031902313 and batch: 850, loss is 5.165031242370605 and perplexity is 175.04292724237482
At time: 851.7284231185913 and batch: 900, loss is 5.208616437911988 and perplexity is 182.84091135882483
At time: 852.8368282318115 and batch: 950, loss is 5.194146842956543 and perplexity is 180.21432606980923
At time: 853.9457201957703 and batch: 1000, loss is 5.2043499088287355 and perplexity is 182.0624770799862
At time: 855.0548629760742 and batch: 1050, loss is 5.171177463531494 and perplexity is 176.1220927836848
At time: 856.1628227233887 and batch: 1100, loss is 5.171649408340454 and perplexity is 176.2052323082076
At time: 857.2698605060577 and batch: 1150, loss is 5.189764480590821 and perplexity is 179.42628958139466
At time: 858.3773324489594 and batch: 1200, loss is 5.164872541427612 and perplexity is 175.01514996895517
At time: 859.4861996173859 and batch: 1250, loss is 5.184403715133667 and perplexity is 178.4670008842768
At time: 860.5945556163788 and batch: 1300, loss is 5.16103494644165 and perplexity is 174.34479979589307
At time: 861.7033128738403 and batch: 1350, loss is 5.136585378646851 and perplexity is 170.1338327237822
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.091206461588541 and perplexity of 162.58589741521394
Finished 27 epochs...
Completing Train Step...
At time: 865.1499443054199 and batch: 50, loss is 5.222665414810181 and perplexity is 185.42776789441155
At time: 866.2881941795349 and batch: 100, loss is 5.240348434448242 and perplexity is 188.7358530229222
At time: 867.3960630893707 and batch: 150, loss is 5.202683076858521 and perplexity is 181.75926229686252
At time: 868.505514383316 and batch: 200, loss is 5.194960947036743 and perplexity is 180.3610990240974
At time: 869.613098859787 and batch: 250, loss is 5.216385822296143 and perplexity is 184.26700544323347
At time: 870.7209107875824 and batch: 300, loss is 5.220443143844604 and perplexity is 185.01615467705466
At time: 871.8257055282593 and batch: 350, loss is 5.226310997009278 and perplexity is 186.10499375549492
At time: 872.9296674728394 and batch: 400, loss is 5.258433361053466 and perplexity is 192.18017838239373
At time: 874.0331707000732 and batch: 450, loss is 5.21610918045044 and perplexity is 184.21603652913774
At time: 875.1362173557281 and batch: 500, loss is 5.262836084365845 and perplexity is 193.02815987811442
At time: 876.2394711971283 and batch: 550, loss is 5.23107831954956 and perplexity is 186.99433448978536
At time: 877.3425192832947 and batch: 600, loss is 5.186668395996094 and perplexity is 178.87162969037334
At time: 878.4458148479462 and batch: 650, loss is 5.212447586059571 and perplexity is 183.5427455345886
At time: 879.5471279621124 and batch: 700, loss is 5.228465280532837 and perplexity is 186.5063488382935
At time: 880.650057554245 and batch: 750, loss is 5.20797028541565 and perplexity is 182.72280640853106
At time: 881.7531225681305 and batch: 800, loss is 5.180772972106934 and perplexity is 177.82020794530854
At time: 882.8560581207275 and batch: 850, loss is 5.161561985015869 and perplexity is 174.43671044870212
At time: 883.9588861465454 and batch: 900, loss is 5.20481351852417 and perplexity is 182.1469025782629
At time: 885.0614666938782 and batch: 950, loss is 5.192087345123291 and perplexity is 179.8435569858624
At time: 886.1634359359741 and batch: 1000, loss is 5.202826690673828 and perplexity is 181.78536731246402
At time: 887.2662644386292 and batch: 1050, loss is 5.16759575843811 and perplexity is 175.4924037403005
At time: 888.3680186271667 and batch: 1100, loss is 5.168438529968261 and perplexity is 175.64036608239766
At time: 889.469161272049 and batch: 1150, loss is 5.18732069015503 and perplexity is 178.98834467173165
At time: 890.571209192276 and batch: 1200, loss is 5.162814807891846 and perplexity is 174.65538570204026
At time: 891.6740765571594 and batch: 1250, loss is 5.182399311065674 and perplexity is 178.1096391699846
At time: 892.7770416736603 and batch: 1300, loss is 5.158478136062622 and perplexity is 173.8996025871988
At time: 893.8789644241333 and batch: 1350, loss is 5.134505987167358 and perplexity is 169.78042544502563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.091425374348958 and perplexity of 162.6214934388917
Annealing...
Finished 28 epochs...
Completing Train Step...
At time: 897.2946417331696 and batch: 50, loss is 5.224640350341797 and perplexity is 185.7943376384342
At time: 898.4019343852997 and batch: 100, loss is 5.239268445968628 and perplexity is 188.53213050475514
At time: 899.5100469589233 and batch: 150, loss is 5.201833610534668 and perplexity is 181.604929484037
At time: 900.617912530899 and batch: 200, loss is 5.195255517959595 and perplexity is 180.41423598540106
At time: 901.7264800071716 and batch: 250, loss is 5.213966274261475 and perplexity is 183.8217015067333
At time: 902.8349432945251 and batch: 300, loss is 5.217349977493286 and perplexity is 184.44475310859173
At time: 903.9438643455505 and batch: 350, loss is 5.219112644195556 and perplexity is 184.77015443609554
At time: 905.0512864589691 and batch: 400, loss is 5.250377025604248 and perplexity is 190.63813036718338
At time: 906.1540341377258 and batch: 450, loss is 5.205922956466675 and perplexity is 182.34909540254935
At time: 907.256632566452 and batch: 500, loss is 5.2498214817047115 and perplexity is 190.532251929622
At time: 908.3594074249268 and batch: 550, loss is 5.216603746414185 and perplexity is 184.30716604370167
At time: 909.462247133255 and batch: 600, loss is 5.173426733016968 and perplexity is 176.51868468652998
At time: 910.5655076503754 and batch: 650, loss is 5.198737554550171 and perplexity is 181.04353995044247
At time: 911.6693847179413 and batch: 700, loss is 5.207480525970459 and perplexity is 182.6333380990038
At time: 912.7725434303284 and batch: 750, loss is 5.185241594314575 and perplexity is 178.6165973319195
At time: 913.875027179718 and batch: 800, loss is 5.157425794601441 and perplexity is 173.71669708171623
At time: 914.9776246547699 and batch: 850, loss is 5.131609592437744 and perplexity is 169.28938578120398
At time: 916.0806200504303 and batch: 900, loss is 5.167709541320801 and perplexity is 175.5123729079416
At time: 917.1842665672302 and batch: 950, loss is 5.154594631195068 and perplexity is 173.22557228119447
At time: 918.2854111194611 and batch: 1000, loss is 5.165964078903198 and perplexity is 175.2062898631426
At time: 919.3877069950104 and batch: 1050, loss is 5.129001789093017 and perplexity is 168.84848749261857
At time: 920.4906423091888 and batch: 1100, loss is 5.125635452270508 and perplexity is 168.2810422535167
At time: 921.5956540107727 and batch: 1150, loss is 5.137799806594849 and perplexity is 170.34057351563072
At time: 922.7435395717621 and batch: 1200, loss is 5.10998345375061 and perplexity is 165.66761367339979
At time: 923.8464086055756 and batch: 1250, loss is 5.130380296707154 and perplexity is 169.0814069219816
At time: 924.9502761363983 and batch: 1300, loss is 5.110401878356933 and perplexity is 165.73694758392713
At time: 926.053049325943 and batch: 1350, loss is 5.09660532951355 and perplexity is 163.46605098037824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065526936848959 and perplexity of 158.46392055677742
Finished 29 epochs...
Completing Train Step...
At time: 929.469735622406 and batch: 50, loss is 5.206513261795044 and perplexity is 182.4567688221587
At time: 930.5735476016998 and batch: 100, loss is 5.222458581924439 and perplexity is 185.38941930009318
At time: 931.6778249740601 and batch: 150, loss is 5.18540060043335 and perplexity is 178.64500072190657
At time: 932.780953168869 and batch: 200, loss is 5.179387216567993 and perplexity is 177.5739632640839
At time: 933.8840460777283 and batch: 250, loss is 5.199359006881714 and perplexity is 181.15608484747779
At time: 934.9876358509064 and batch: 300, loss is 5.202099380493164 and perplexity is 181.65320103288826
At time: 936.0911221504211 and batch: 350, loss is 5.204318380355835 and perplexity is 182.05673701859948
At time: 937.1947524547577 and batch: 400, loss is 5.237519931793213 and perplexity is 188.20276743395897
At time: 938.3011696338654 and batch: 450, loss is 5.194042196273804 and perplexity is 180.1954682251267
At time: 939.4054429531097 and batch: 500, loss is 5.239628553390503 and perplexity is 188.60003454985326
At time: 940.5093553066254 and batch: 550, loss is 5.207707443237305 and perplexity is 182.67478545930322
At time: 941.612943649292 and batch: 600, loss is 5.164688949584961 and perplexity is 174.98302156442725
At time: 942.7169749736786 and batch: 650, loss is 5.190957355499267 and perplexity is 179.64045040829535
At time: 943.8209187984467 and batch: 700, loss is 5.200423278808594 and perplexity is 181.3489868148307
At time: 944.9251222610474 and batch: 750, loss is 5.178911113739014 and perplexity is 177.489439920319
At time: 946.0297420024872 and batch: 800, loss is 5.152500982284546 and perplexity is 172.86327814121807
At time: 947.1337571144104 and batch: 850, loss is 5.128350925445557 and perplexity is 168.7386259065156
At time: 948.2370519638062 and batch: 900, loss is 5.165537261962891 and perplexity is 175.1315248072118
At time: 949.3388900756836 and batch: 950, loss is 5.153627767562866 and perplexity is 173.05816771692207
At time: 950.4694879055023 and batch: 1000, loss is 5.16611424446106 and perplexity is 175.23260178892377
At time: 951.5722742080688 and batch: 1050, loss is 5.129936552047729 and perplexity is 169.0063945950426
At time: 952.6762375831604 and batch: 1100, loss is 5.127754287719727 and perplexity is 168.637980104022
At time: 953.7803559303284 and batch: 1150, loss is 5.140815896987915 and perplexity is 170.85511163965276
At time: 954.8838987350464 and batch: 1200, loss is 5.114897546768188 and perplexity is 166.48372331402928
At time: 955.9877197742462 and batch: 1250, loss is 5.135909929275512 and perplexity is 170.01895473492576
At time: 957.091465473175 and batch: 1300, loss is 5.115574331283569 and perplexity is 166.59643505651002
At time: 958.1952741146088 and batch: 1350, loss is 5.099494142532349 and perplexity is 163.93895657562618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.062548014322917 and perplexity of 157.99257121940727
Finished 30 epochs...
Completing Train Step...
At time: 961.5699141025543 and batch: 50, loss is 5.201857395172119 and perplexity is 181.60924894281237
At time: 962.7035553455353 and batch: 100, loss is 5.216696786880493 and perplexity is 184.32431486612916
At time: 963.8078248500824 and batch: 150, loss is 5.1796186161041256 and perplexity is 177.61505855134425
At time: 964.9120695590973 and batch: 200, loss is 5.173155097961426 and perplexity is 176.47074253549016
At time: 966.0159153938293 and batch: 250, loss is 5.1929703712463375 and perplexity is 180.00243368055496
At time: 967.1208350658417 and batch: 300, loss is 5.196669225692749 and perplexity is 180.66946935617128
At time: 968.2231886386871 and batch: 350, loss is 5.199140930175782 and perplexity is 181.1165832325822
At time: 969.326456785202 and batch: 400, loss is 5.232864151000976 and perplexity is 187.32857321173546
At time: 970.4300153255463 and batch: 450, loss is 5.189928503036499 and perplexity is 179.45572193394798
At time: 971.5332720279694 and batch: 500, loss is 5.235423994064331 and perplexity is 187.80871924749763
At time: 972.6380136013031 and batch: 550, loss is 5.20404691696167 and perplexity is 182.00732198632755
At time: 973.7428278923035 and batch: 600, loss is 5.161371221542359 and perplexity is 174.40343746964467
At time: 974.8471248149872 and batch: 650, loss is 5.1880090618133545 and perplexity is 179.11159759241582
At time: 975.9514939785004 and batch: 700, loss is 5.197835626602173 and perplexity is 180.88032533693175
At time: 977.0557866096497 and batch: 750, loss is 5.1763553810119625 and perplexity is 177.03640351658447
At time: 978.1885311603546 and batch: 800, loss is 5.150783977508545 and perplexity is 172.56672573086252
At time: 979.2931296825409 and batch: 850, loss is 5.127615337371826 and perplexity is 168.61454942590544
At time: 980.3960249423981 and batch: 900, loss is 5.165595836639405 and perplexity is 175.1417833800681
At time: 981.4982759952545 and batch: 950, loss is 5.154079427719116 and perplexity is 173.13634885031593
At time: 982.6012773513794 and batch: 1000, loss is 5.16671875 and perplexity is 175.33856289111796
At time: 983.7039310932159 and batch: 1050, loss is 5.130834302902222 and perplexity is 169.15818835649958
At time: 984.8078258037567 and batch: 1100, loss is 5.128966293334961 and perplexity is 168.8424941939273
At time: 985.9121341705322 and batch: 1150, loss is 5.142215003967285 and perplexity is 171.09432352129403
At time: 987.0183079242706 and batch: 1200, loss is 5.117215156555176 and perplexity is 166.870015084442
At time: 988.1234211921692 and batch: 1250, loss is 5.1382814884185795 and perplexity is 170.42264323789698
At time: 989.2270677089691 and batch: 1300, loss is 5.117972545623779 and perplexity is 166.99644848333782
At time: 990.3299732208252 and batch: 1350, loss is 5.100292644500732 and perplexity is 164.06991443324188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.061417236328125 and perplexity of 157.81401766777105
Finished 31 epochs...
Completing Train Step...
At time: 993.7215323448181 and batch: 50, loss is 5.1986760330200195 and perplexity is 181.03240221744943
At time: 994.8541383743286 and batch: 100, loss is 5.213009138107299 and perplexity is 183.64584328385615
At time: 995.9583532810211 and batch: 150, loss is 5.175560512542725 and perplexity is 176.8957387739124
At time: 997.062139749527 and batch: 200, loss is 5.169122972488403 and perplexity is 175.76062296696568
At time: 998.1663947105408 and batch: 250, loss is 5.18934178352356 and perplexity is 179.35046264204053
At time: 999.2694845199585 and batch: 300, loss is 5.193491640090943 and perplexity is 180.09628780067496
At time: 1000.3721959590912 and batch: 350, loss is 5.196223468780517 and perplexity is 180.58895263815157
At time: 1001.4745242595673 and batch: 400, loss is 5.230371875762939 and perplexity is 186.8622801540262
At time: 1002.5783889293671 and batch: 450, loss is 5.18732382774353 and perplexity is 178.98890626438455
At time: 1003.6815056800842 and batch: 500, loss is 5.232582340240478 and perplexity is 187.27578944192214
At time: 1004.785614490509 and batch: 550, loss is 5.202044105529785 and perplexity is 181.64316043635287
At time: 1005.8892040252686 and batch: 600, loss is 5.159718151092529 and perplexity is 174.11537446063664
At time: 1007.0214998722076 and batch: 650, loss is 5.186389484405518 and perplexity is 178.82174727634256
At time: 1008.1257135868073 and batch: 700, loss is 5.196242485046387 and perplexity is 180.59238679834039
At time: 1009.23064661026 and batch: 750, loss is 5.174749383926391 and perplexity is 176.75231175482898
At time: 1010.3344917297363 and batch: 800, loss is 5.149800262451172 and perplexity is 172.3970527129934
At time: 1011.4379134178162 and batch: 850, loss is 5.1272117710113525 and perplexity is 168.54651599479618
At time: 1012.5402889251709 and batch: 900, loss is 5.165444316864014 and perplexity is 175.11524794676106
At time: 1013.6429715156555 and batch: 950, loss is 5.154006223678589 and perplexity is 173.12367503391093
At time: 1014.7465002536774 and batch: 1000, loss is 5.166163234710694 and perplexity is 175.24118668811587
At time: 1015.8500516414642 and batch: 1050, loss is 5.1309941864013675 and perplexity is 169.18523612175125
At time: 1016.9543261528015 and batch: 1100, loss is 5.129556112289428 and perplexity is 168.94211007210112
At time: 1018.0585358142853 and batch: 1150, loss is 5.142692384719848 and perplexity is 171.17602015686504
At time: 1019.1625983715057 and batch: 1200, loss is 5.118431558609009 and perplexity is 167.0731196168557
At time: 1020.2662622928619 and batch: 1250, loss is 5.139672412872314 and perplexity is 170.6598531921661
At time: 1021.3702058792114 and batch: 1300, loss is 5.119314603805542 and perplexity is 167.22071789098555
At time: 1022.475200176239 and batch: 1350, loss is 5.100262327194214 and perplexity is 164.0649403507563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.06074462890625 and perplexity of 157.70790647779924
Finished 32 epochs...
Completing Train Step...
At time: 1025.883995294571 and batch: 50, loss is 5.196072158813476 and perplexity is 180.56162979684112
At time: 1026.9935319423676 and batch: 100, loss is 5.2103707981109615 and perplexity is 183.16196171309502
At time: 1028.1021347045898 and batch: 150, loss is 5.172657079696656 and perplexity is 176.3828787632076
At time: 1029.2106795310974 and batch: 200, loss is 5.166303186416626 and perplexity is 175.26571370740157
At time: 1030.3189244270325 and batch: 250, loss is 5.1869135665893555 and perplexity is 178.915489130245
At time: 1031.4268996715546 and batch: 300, loss is 5.191342210769653 and perplexity is 179.70959928771128
At time: 1032.5345418453217 and batch: 350, loss is 5.19421724319458 and perplexity is 180.22701364786133
At time: 1033.6416492462158 and batch: 400, loss is 5.228724737167358 and perplexity is 186.5547454260163
At time: 1034.78115940094 and batch: 450, loss is 5.185204305648804 and perplexity is 178.60993708149712
At time: 1035.890222787857 and batch: 500, loss is 5.230375270843506 and perplexity is 186.86291456759915
At time: 1036.9979989528656 and batch: 550, loss is 5.201058750152588 and perplexity is 181.4642655234925
At time: 1038.107543706894 and batch: 600, loss is 5.158747797012329 and perplexity is 173.94650284248561
At time: 1039.2158205509186 and batch: 650, loss is 5.185547552108765 and perplexity is 178.6712548330627
At time: 1040.324074268341 and batch: 700, loss is 5.1952304267883305 and perplexity is 180.4097092376984
At time: 1041.4334049224854 and batch: 750, loss is 5.173830270767212 and perplexity is 176.58993101374887
At time: 1042.5423130989075 and batch: 800, loss is 5.149022197723388 and perplexity is 172.26296881684303
At time: 1043.6513149738312 and batch: 850, loss is 5.12660771369934 and perplexity is 168.44473498327235
At time: 1044.7581086158752 and batch: 900, loss is 5.164961700439453 and perplexity is 175.03075484243084
At time: 1045.8656551837921 and batch: 950, loss is 5.153313932418823 and perplexity is 173.0038645035029
At time: 1046.9738059043884 and batch: 1000, loss is 5.165286808013916 and perplexity is 175.08766791752873
At time: 1048.0822684764862 and batch: 1050, loss is 5.1308935546875 and perplexity is 169.1682115780981
At time: 1049.1904327869415 and batch: 1100, loss is 5.1294826221466066 and perplexity is 168.92969494850348
At time: 1050.300611257553 and batch: 1150, loss is 5.142976989746094 and perplexity is 171.22474464586278
At time: 1051.4105155467987 and batch: 1200, loss is 5.11911470413208 and perplexity is 167.18729386492043
At time: 1052.5181272029877 and batch: 1250, loss is 5.140353317260742 and perplexity is 170.77609580569487
At time: 1053.626592874527 and batch: 1300, loss is 5.120225973129273 and perplexity is 167.37318719093173
At time: 1054.7341434955597 and batch: 1350, loss is 5.0999070739746095 and perplexity is 164.00666610414223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.059982503255208 and perplexity of 157.5877590264431
Finished 33 epochs...
Completing Train Step...
At time: 1058.2048814296722 and batch: 50, loss is 5.1939599895477295 and perplexity is 180.18065555448936
At time: 1059.307864189148 and batch: 100, loss is 5.207747354507446 and perplexity is 182.6820763875078
At time: 1060.4110922813416 and batch: 150, loss is 5.17038670539856 and perplexity is 175.9828778563489
At time: 1061.5138251781464 and batch: 200, loss is 5.164236192703247 and perplexity is 174.90381472930375
At time: 1062.6456289291382 and batch: 250, loss is 5.184890336990357 and perplexity is 178.5538679616001
At time: 1063.7480018138885 and batch: 300, loss is 5.189471101760864 and perplexity is 179.37365742745115
At time: 1064.851184129715 and batch: 350, loss is 5.192249145507812 and perplexity is 179.8726580967584
At time: 1065.9528648853302 and batch: 400, loss is 5.226748380661011 and perplexity is 186.18641084122268
At time: 1067.0552384853363 and batch: 450, loss is 5.183160095214844 and perplexity is 178.24519371761698
At time: 1068.1580979824066 and batch: 500, loss is 5.229013252258301 and perplexity is 186.60857705060326
At time: 1069.2604537010193 and batch: 550, loss is 5.200112543106079 and perplexity is 181.29264396433342
At time: 1070.3629536628723 and batch: 600, loss is 5.157979402542114 and perplexity is 173.81289465006026
At time: 1071.4672780036926 and batch: 650, loss is 5.184763536453247 and perplexity is 178.53122867060708
At time: 1072.5706808567047 and batch: 700, loss is 5.1944517898559575 and perplexity is 180.26929024992657
At time: 1073.6727492809296 and batch: 750, loss is 5.172951602935791 and perplexity is 176.43483527081293
At time: 1074.775175333023 and batch: 800, loss is 5.148429641723633 and perplexity is 172.1609235978741
At time: 1075.8773965835571 and batch: 850, loss is 5.1260816192626955 and perplexity is 168.35614045190397
At time: 1076.9788649082184 and batch: 900, loss is 5.164035596847534 and perplexity is 174.86873326763626
At time: 1078.081195116043 and batch: 950, loss is 5.152547416687011 and perplexity is 172.87130513060956
At time: 1079.184621334076 and batch: 1000, loss is 5.164750471115112 and perplexity is 174.99378711881766
At time: 1080.2868449687958 and batch: 1050, loss is 5.131061067581177 and perplexity is 169.19655180834843
At time: 1081.3890283107758 and batch: 1100, loss is 5.129677324295044 and perplexity is 168.96258912522438
At time: 1082.4912178516388 and batch: 1150, loss is 5.143126049041748 and perplexity is 171.2502691879861
At time: 1083.5943052768707 and batch: 1200, loss is 5.119533414840698 and perplexity is 167.2573116327782
At time: 1084.6968553066254 and batch: 1250, loss is 5.140968198776245 and perplexity is 170.8811351603649
At time: 1085.7996847629547 and batch: 1300, loss is 5.12058391571045 and perplexity is 167.43310790502244
At time: 1086.9023134708405 and batch: 1350, loss is 5.099481811523438 and perplexity is 163.93693505535555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.05929443359375 and perplexity of 157.47936496604856
Finished 34 epochs...
Completing Train Step...
At time: 1090.2774586677551 and batch: 50, loss is 5.192393894195557 and perplexity is 179.89869631243232
At time: 1091.4088160991669 and batch: 100, loss is 5.2062204074859615 and perplexity is 182.4033433945031
At time: 1092.5116617679596 and batch: 150, loss is 5.168814420700073 and perplexity is 175.70640007814606
At time: 1093.6147146224976 and batch: 200, loss is 5.162537202835083 and perplexity is 174.60690721302674
At time: 1094.7162864208221 and batch: 250, loss is 5.183114500045776 and perplexity is 178.23706678314977
At time: 1095.8202075958252 and batch: 300, loss is 5.1877122974395755 and perplexity is 179.05845153763764
At time: 1096.9223783016205 and batch: 350, loss is 5.190367164611817 and perplexity is 179.53445953194816
At time: 1098.0243225097656 and batch: 400, loss is 5.224858179092407 and perplexity is 185.83481339510402
At time: 1099.1272373199463 and batch: 450, loss is 5.1815688419342045 and perplexity is 177.96178601487506
At time: 1100.2290546894073 and batch: 500, loss is 5.227922058105468 and perplexity is 186.4050619199115
At time: 1101.3305127620697 and batch: 550, loss is 5.19952956199646 and perplexity is 181.18698457929463
At time: 1102.4323725700378 and batch: 600, loss is 5.157274913787842 and perplexity is 173.69048854235749
At time: 1103.5340497493744 and batch: 650, loss is 5.183942604064941 and perplexity is 178.3847267449828
At time: 1104.6365673542023 and batch: 700, loss is 5.193860216140747 and perplexity is 180.16267921340767
At time: 1105.7382028102875 and batch: 750, loss is 5.172090644836426 and perplexity is 176.2829976426733
At time: 1106.841412782669 and batch: 800, loss is 5.147683801651001 and perplexity is 172.03256695482776
At time: 1107.945511341095 and batch: 850, loss is 5.125609607696533 and perplexity is 168.27669315787205
At time: 1109.046484708786 and batch: 900, loss is 5.163241052627564 and perplexity is 174.7298475091098
At time: 1110.1482048034668 and batch: 950, loss is 5.151632404327392 and perplexity is 172.7131980957683
At time: 1111.2506656646729 and batch: 1000, loss is 5.164464292526245 and perplexity is 174.9437148089127
At time: 1112.3533766269684 and batch: 1050, loss is 5.131161642074585 and perplexity is 169.21356952159258
At time: 1113.455124616623 and batch: 1100, loss is 5.1298527336120605 and perplexity is 168.99222933709282
At time: 1114.5580384731293 and batch: 1150, loss is 5.143290605545044 and perplexity is 171.2784518522289
At time: 1115.6610009670258 and batch: 1200, loss is 5.119779253005982 and perplexity is 167.2984349180296
At time: 1116.763210773468 and batch: 1250, loss is 5.141186370849609 and perplexity is 170.91842071910753
At time: 1117.8655989170074 and batch: 1300, loss is 5.120804252624512 and perplexity is 167.47000366392967
At time: 1118.9683802127838 and batch: 1350, loss is 5.099135255813598 and perplexity is 163.88013161780484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.059182535807292 and perplexity of 157.46174435956786
Finished 35 epochs...
Completing Train Step...
At time: 1122.3584706783295 and batch: 50, loss is 5.1909130859375 and perplexity is 179.63249798030662
At time: 1123.4892663955688 and batch: 100, loss is 5.204612121582032 and perplexity is 182.11022244282123
At time: 1124.5917389392853 and batch: 150, loss is 5.167383432388306 and perplexity is 175.45514608696877
At time: 1125.6937391757965 and batch: 200, loss is 5.161317586898804 and perplexity is 174.39408365428775
At time: 1126.7966113090515 and batch: 250, loss is 5.1814212894439695 and perplexity is 177.93552924735525
At time: 1127.8991012573242 and batch: 300, loss is 5.185883350372315 and perplexity is 178.7312624048373
At time: 1129.0018010139465 and batch: 350, loss is 5.188610506057739 and perplexity is 179.21935563386896
At time: 1130.1041889190674 and batch: 400, loss is 5.223437509536743 and perplexity is 185.57099097994058
At time: 1131.206779241562 and batch: 450, loss is 5.1803217697143555 and perplexity is 177.7399931399518
At time: 1132.3085191249847 and batch: 500, loss is 5.226967067718506 and perplexity is 186.22713185197176
At time: 1133.4108004570007 and batch: 550, loss is 5.19885371208191 and perplexity is 181.0645707425992
At time: 1134.5134010314941 and batch: 600, loss is 5.156301546096802 and perplexity is 173.52150608694234
At time: 1135.6164765357971 and batch: 650, loss is 5.182760629653931 and perplexity is 178.1740051209715
At time: 1136.7192735671997 and batch: 700, loss is 5.193039598464966 and perplexity is 180.01489517971754
At time: 1137.8219780921936 and batch: 750, loss is 5.171051397323608 and perplexity is 176.09989113879058
At time: 1138.9245805740356 and batch: 800, loss is 5.146830072402954 and perplexity is 171.88576039624493
At time: 1140.028212070465 and batch: 850, loss is 5.124871807098389 and perplexity is 168.15258430243023
At time: 1141.130095243454 and batch: 900, loss is 5.16212986946106 and perplexity is 174.53579847584794
At time: 1142.233282327652 and batch: 950, loss is 5.150885982513428 and perplexity is 172.58432929837403
At time: 1143.335974931717 and batch: 1000, loss is 5.164180746078491 and perplexity is 174.89411717197103
At time: 1144.4387662410736 and batch: 1050, loss is 5.1309113025665285 and perplexity is 169.17121398169573
At time: 1145.5401272773743 and batch: 1100, loss is 5.129995050430298 and perplexity is 169.01628148495095
At time: 1146.6725046634674 and batch: 1150, loss is 5.143132886886597 and perplexity is 171.2514401747606
At time: 1147.7755753993988 and batch: 1200, loss is 5.120034265518188 and perplexity is 167.34110355249288
At time: 1148.8795940876007 and batch: 1250, loss is 5.141255702972412 and perplexity is 170.9302712668492
At time: 1149.9826760292053 and batch: 1300, loss is 5.120803623199463 and perplexity is 167.4698982541476
At time: 1151.0859014987946 and batch: 1350, loss is 5.098784646987915 and perplexity is 163.82268386873793
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.059327392578125 and perplexity of 157.48455541151338
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 1154.4984080791473 and batch: 50, loss is 5.190435867309571 and perplexity is 179.5467944573743
At time: 1155.6071074008942 and batch: 100, loss is 5.20565013885498 and perplexity is 182.29935414330126
At time: 1156.717255115509 and batch: 150, loss is 5.168937921524048 and perplexity is 175.72810130336532
At time: 1157.8249626159668 and batch: 200, loss is 5.162278347015381 and perplexity is 174.5617150483141
At time: 1158.9335861206055 and batch: 250, loss is 5.180348682403564 and perplexity is 177.74477666551562
At time: 1160.041633605957 and batch: 300, loss is 5.186517286300659 and perplexity is 178.844602494976
At time: 1161.1519219875336 and batch: 350, loss is 5.188348321914673 and perplexity is 179.17237331996918
At time: 1162.2608125209808 and batch: 400, loss is 5.22198564529419 and perplexity is 185.3017625825157
At time: 1163.3695032596588 and batch: 450, loss is 5.178447666168213 and perplexity is 177.40720192851586
At time: 1164.4815168380737 and batch: 500, loss is 5.224145603179932 and perplexity is 185.70243915232905
At time: 1165.5894095897675 and batch: 550, loss is 5.193758134841919 and perplexity is 180.1442889117821
At time: 1166.6975493431091 and batch: 600, loss is 5.152362937927246 and perplexity is 172.83941698807303
At time: 1167.8064246177673 and batch: 650, loss is 5.179096937179565 and perplexity is 177.52242468328268
At time: 1168.9140305519104 and batch: 700, loss is 5.1870401573181155 and perplexity is 178.93813960604032
At time: 1170.0227930545807 and batch: 750, loss is 5.165219240188598 and perplexity is 175.07583802423216
At time: 1171.1301181316376 and batch: 800, loss is 5.1412489795684815 and perplexity is 170.92912203745487
At time: 1172.2372024059296 and batch: 850, loss is 5.11813081741333 and perplexity is 167.02288140182537
At time: 1173.3447768688202 and batch: 900, loss is 5.149724111557007 and perplexity is 172.38392502312695
At time: 1174.4806549549103 and batch: 950, loss is 5.140076990127564 and perplexity is 170.72891225607316
At time: 1175.588877916336 and batch: 1000, loss is 5.15344617843628 and perplexity is 173.02674508848793
At time: 1176.6954958438873 and batch: 1050, loss is 5.119342403411865 and perplexity is 167.2253666257283
At time: 1177.8011546134949 and batch: 1100, loss is 5.118492574691772 and perplexity is 167.08331407515956
At time: 1178.9036724567413 and batch: 1150, loss is 5.131201858520508 and perplexity is 169.2203748268023
At time: 1180.0059003829956 and batch: 1200, loss is 5.105508737564087 and perplexity is 164.9279542381247
At time: 1181.1087112426758 and batch: 1250, loss is 5.127352666854859 and perplexity is 168.57026517137814
At time: 1182.211727142334 and batch: 1300, loss is 5.108424997329712 and perplexity is 165.40962899828804
At time: 1183.3148250579834 and batch: 1350, loss is 5.088738975524902 and perplexity is 162.18521352345357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.051967366536458 and perplexity of 156.32972000497048
Finished 37 epochs...
Completing Train Step...
At time: 1186.7092535495758 and batch: 50, loss is 5.187904481887817 and perplexity is 179.09286709431086
At time: 1187.8124310970306 and batch: 100, loss is 5.202822465896606 and perplexity is 181.78459931140716
At time: 1188.9153852462769 and batch: 150, loss is 5.16525239944458 and perplexity is 175.08164350501363
At time: 1190.0176045894623 and batch: 200, loss is 5.159000988006592 and perplexity is 173.99055010643883
At time: 1191.1208186149597 and batch: 250, loss is 5.17780912399292 and perplexity is 177.2939561078479
At time: 1192.2238914966583 and batch: 300, loss is 5.183417158126831 and perplexity is 178.2910198360071
At time: 1193.3262808322906 and batch: 350, loss is 5.185752601623535 and perplexity is 178.70789504356995
At time: 1194.4295139312744 and batch: 400, loss is 5.21958815574646 and perplexity is 184.8580356714075
At time: 1195.5319929122925 and batch: 450, loss is 5.176452035903931 and perplexity is 177.05351577801937
At time: 1196.6355543136597 and batch: 500, loss is 5.2220714664459225 and perplexity is 185.3176660756169
At time: 1197.7381439208984 and batch: 550, loss is 5.192213869094848 and perplexity is 179.86631294650817
At time: 1198.8416690826416 and batch: 600, loss is 5.150884084701538 and perplexity is 172.58400176609268
At time: 1199.9449472427368 and batch: 650, loss is 5.177634019851684 and perplexity is 177.2629139198045
At time: 1201.0480995178223 and batch: 700, loss is 5.186109170913697 and perplexity is 178.77162815281142
At time: 1202.1505739688873 and batch: 750, loss is 5.16449613571167 and perplexity is 174.94928566275874
At time: 1203.2976551055908 and batch: 800, loss is 5.140861463546753 and perplexity is 170.86289709652698
At time: 1204.4046759605408 and batch: 850, loss is 5.117944107055664 and perplexity is 166.99169941099146
At time: 1205.5079350471497 and batch: 900, loss is 5.149894227981568 and perplexity is 172.41325285460576
At time: 1206.609529018402 and batch: 950, loss is 5.13993091583252 and perplexity is 170.7039749719642
At time: 1207.7125370502472 and batch: 1000, loss is 5.1538159370422365 and perplexity is 173.0907350462348
At time: 1208.8145234584808 and batch: 1050, loss is 5.119817819595337 and perplexity is 167.30488717248875
At time: 1209.917501449585 and batch: 1100, loss is 5.119383859634399 and perplexity is 167.23229930144072
At time: 1211.0209941864014 and batch: 1150, loss is 5.1322150230407715 and perplexity is 169.39190978857775
At time: 1212.1248850822449 and batch: 1200, loss is 5.106926918029785 and perplexity is 165.16201777401025
At time: 1213.2283298969269 and batch: 1250, loss is 5.128771018981934 and perplexity is 168.80952680405773
At time: 1214.331267118454 and batch: 1300, loss is 5.1098207759857175 and perplexity is 165.64066542829187
At time: 1215.4333906173706 and batch: 1350, loss is 5.089592552185058 and perplexity is 162.32371013666895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.051312662760417 and perplexity of 156.22740384401885
Finished 38 epochs...
Completing Train Step...
At time: 1218.8158612251282 and batch: 50, loss is 5.186897478103638 and perplexity is 178.91261067410846
At time: 1219.9559676647186 and batch: 100, loss is 5.201617507934571 and perplexity is 181.565688426785
At time: 1221.0635516643524 and batch: 150, loss is 5.163827171325684 and perplexity is 174.8322899586394
At time: 1222.171956539154 and batch: 200, loss is 5.15756669998169 and perplexity is 173.74117642356913
At time: 1223.2801260948181 and batch: 250, loss is 5.176394910812378 and perplexity is 177.04340186860253
At time: 1224.3893749713898 and batch: 300, loss is 5.181873836517334 and perplexity is 178.01607167360876
At time: 1225.4976868629456 and batch: 350, loss is 5.184311561584472 and perplexity is 178.45055527450359
At time: 1226.6067855358124 and batch: 400, loss is 5.218329963684082 and perplexity is 184.6255950164161
At time: 1227.715084552765 and batch: 450, loss is 5.1753918647766115 and perplexity is 176.86590821823222
At time: 1228.8241891860962 and batch: 500, loss is 5.220935382843018 and perplexity is 185.10724926203747
At time: 1229.9313337802887 and batch: 550, loss is 5.191335849761963 and perplexity is 179.70845615720393
At time: 1231.0708620548248 and batch: 600, loss is 5.150163688659668 and perplexity is 172.45971770657758
At time: 1232.1782758235931 and batch: 650, loss is 5.176925249099732 and perplexity is 177.13731966503724
At time: 1233.2881128787994 and batch: 700, loss is 5.185697298049927 and perplexity is 178.6980121316248
At time: 1234.3963735103607 and batch: 750, loss is 5.164249973297119 and perplexity is 174.90622502434886
At time: 1235.5050292015076 and batch: 800, loss is 5.140866289138794 and perplexity is 170.86372161315262
At time: 1236.613395690918 and batch: 850, loss is 5.118014717102051 and perplexity is 167.00349111893468
At time: 1237.7227716445923 and batch: 900, loss is 5.150141735076904 and perplexity is 172.45593163945045
At time: 1238.8300864696503 and batch: 950, loss is 5.1399624729156494 and perplexity is 170.70936197649158
At time: 1239.9390335083008 and batch: 1000, loss is 5.154165029525757 and perplexity is 173.1511702689337
At time: 1241.047081708908 and batch: 1050, loss is 5.120197162628174 and perplexity is 167.36836515500127
At time: 1242.1560034751892 and batch: 1100, loss is 5.120019254684448 and perplexity is 167.3385916418625
At time: 1243.2640595436096 and batch: 1150, loss is 5.132889127731323 and perplexity is 169.50613616545036
At time: 1244.3730533123016 and batch: 1200, loss is 5.107820520401001 and perplexity is 165.309672907391
At time: 1245.4814791679382 and batch: 1250, loss is 5.129648609161377 and perplexity is 168.95773741155202
At time: 1246.590077161789 and batch: 1300, loss is 5.110628538131714 and perplexity is 165.77451774080006
At time: 1247.6997861862183 and batch: 1350, loss is 5.090007209777832 and perplexity is 162.39103285253742
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.050938313802083 and perplexity of 156.1689312233919
Finished 39 epochs...
Completing Train Step...
At time: 1251.1231713294983 and batch: 50, loss is 5.186157722473144 and perplexity is 178.7803080048517
At time: 1252.2622256278992 and batch: 100, loss is 5.200743055343628 and perplexity is 181.40698723855925
At time: 1253.370878458023 and batch: 150, loss is 5.1628804111480715 and perplexity is 174.6668440399077
At time: 1254.4778227806091 and batch: 200, loss is 5.156555166244507 and perplexity is 173.56552021814548
At time: 1255.5852394104004 and batch: 250, loss is 5.175334453582764 and perplexity is 176.85575442676387
At time: 1256.6939737796783 and batch: 300, loss is 5.180782251358032 and perplexity is 177.82185799132398
At time: 1257.8029313087463 and batch: 350, loss is 5.183269176483154 and perplexity is 178.2646379899016
At time: 1258.9106748104095 and batch: 400, loss is 5.217436943054199 and perplexity is 184.46079414750224
At time: 1260.0658979415894 and batch: 450, loss is 5.174654569625854 and perplexity is 176.7355539024762
At time: 1261.1739709377289 and batch: 500, loss is 5.2201228523254395 and perplexity is 184.95690506088442
At time: 1262.2821261882782 and batch: 550, loss is 5.190681877136231 and perplexity is 179.59097016676262
At time: 1263.3898122310638 and batch: 600, loss is 5.1496812915802 and perplexity is 172.3765437054906
At time: 1264.4984862804413 and batch: 650, loss is 5.176424160003662 and perplexity is 177.04858032066176
At time: 1265.6054668426514 and batch: 700, loss is 5.185410203933716 and perplexity is 178.64671634747447
At time: 1266.7138741016388 and batch: 750, loss is 5.164109811782837 and perplexity is 174.88171162095009
At time: 1267.8227002620697 and batch: 800, loss is 5.140919351577759 and perplexity is 170.87278829950026
At time: 1268.930184841156 and batch: 850, loss is 5.11811863899231 and perplexity is 167.02084733924153
At time: 1270.0380041599274 and batch: 900, loss is 5.15034068107605 and perplexity is 172.49024447016612
At time: 1271.1474072933197 and batch: 950, loss is 5.140001735687256 and perplexity is 170.71606463076347
At time: 1272.2547373771667 and batch: 1000, loss is 5.154433565139771 and perplexity is 173.19767376840252
At time: 1273.3622121810913 and batch: 1050, loss is 5.120557813644409 and perplexity is 167.42873761201966
At time: 1274.4721031188965 and batch: 1100, loss is 5.120473318099975 and perplexity is 167.41459122734287
At time: 1275.5804765224457 and batch: 1150, loss is 5.133349313735962 and perplexity is 169.58415846802302
At time: 1276.6884429454803 and batch: 1200, loss is 5.10842827796936 and perplexity is 165.41017164856535
At time: 1277.796543598175 and batch: 1250, loss is 5.13026421546936 and perplexity is 169.06178088210774
At time: 1278.9028103351593 and batch: 1300, loss is 5.111164150238037 and perplexity is 165.8633323623919
At time: 1280.0111236572266 and batch: 1350, loss is 5.0902376556396485 and perplexity is 162.42845950629743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.050677490234375 and perplexity of 156.12820399712615
Finished 40 epochs...
Completing Train Step...
At time: 1283.4711673259735 and batch: 50, loss is 5.185541715621948 and perplexity is 178.67021202368258
At time: 1284.578316450119 and batch: 100, loss is 5.200051851272583 and perplexity is 181.2816413152608
At time: 1285.6854453086853 and batch: 150, loss is 5.162156629562378 and perplexity is 174.54046913399213
At time: 1286.790744304657 and batch: 200, loss is 5.15574912071228 and perplexity is 173.42567487445385
At time: 1287.93008518219 and batch: 250, loss is 5.174469394683838 and perplexity is 176.70282993645282
At time: 1289.0373849868774 and batch: 300, loss is 5.17990969657898 and perplexity is 177.66676635212914
At time: 1290.1442322731018 and batch: 350, loss is 5.182447862625122 and perplexity is 178.11828688064733
At time: 1291.2509353160858 and batch: 400, loss is 5.216735916137695 and perplexity is 184.3315274807654
At time: 1292.356770992279 and batch: 450, loss is 5.174084577560425 and perplexity is 176.63484474350992
At time: 1293.4634490013123 and batch: 500, loss is 5.219474086761474 and perplexity is 184.836950305528
At time: 1294.5708038806915 and batch: 550, loss is 5.190149774551392 and perplexity is 179.49543476689385
At time: 1295.678138256073 and batch: 600, loss is 5.149310083389282 and perplexity is 172.3125679954334
At time: 1296.7850053310394 and batch: 650, loss is 5.176006565093994 and perplexity is 176.97466116996065
At time: 1297.8918843269348 and batch: 700, loss is 5.185169372558594 and perplexity is 178.6036977934321
At time: 1298.9994430541992 and batch: 750, loss is 5.163987445831299 and perplexity is 174.8603133631367
At time: 1300.106588602066 and batch: 800, loss is 5.140964622497559 and perplexity is 170.88052404289607
At time: 1301.2131943702698 and batch: 850, loss is 5.11821249961853 and perplexity is 167.03652475629926
At time: 1302.3204383850098 and batch: 900, loss is 5.150485830307007 and perplexity is 172.51528311362452
At time: 1303.4267311096191 and batch: 950, loss is 5.140021505355835 and perplexity is 170.71943966414395
At time: 1304.53377866745 and batch: 1000, loss is 5.154647359848022 and perplexity is 173.23470647309279
At time: 1305.6394302845001 and batch: 1050, loss is 5.1207901096344 and perplexity is 167.4676351540727
At time: 1306.7465238571167 and batch: 1100, loss is 5.120796318054199 and perplexity is 167.46867486668205
At time: 1307.8535764217377 and batch: 1150, loss is 5.133672246932983 and perplexity is 169.63893166604728
At time: 1308.960974931717 and batch: 1200, loss is 5.108866128921509 and perplexity is 165.48261250770898
At time: 1310.0685665607452 and batch: 1250, loss is 5.130729627609253 and perplexity is 169.1404826002691
At time: 1311.1789507865906 and batch: 1300, loss is 5.111557111740113 and perplexity is 165.92852307449755
At time: 1312.285457611084 and batch: 1350, loss is 5.090367088317871 and perplexity is 162.4494844174568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.050469563802083 and perplexity of 156.09574419143158
Finished 41 epochs...
Completing Train Step...
At time: 1315.7414858341217 and batch: 50, loss is 5.18500280380249 and perplexity is 178.5739504752108
At time: 1316.8484768867493 and batch: 100, loss is 5.199478130340577 and perplexity is 181.17766607228836
At time: 1317.9555575847626 and batch: 150, loss is 5.161570453643799 and perplexity is 174.43818769455544
At time: 1319.0600497722626 and batch: 200, loss is 5.155068473815918 and perplexity is 173.30767339032863
At time: 1320.1654663085938 and batch: 250, loss is 5.173709154129028 and perplexity is 176.56854433013515
At time: 1321.2728009223938 and batch: 300, loss is 5.179173374176026 and perplexity is 177.53599448284058
At time: 1322.3796858787537 and batch: 350, loss is 5.181769075393677 and perplexity is 177.9974234867308
At time: 1323.4868338108063 and batch: 400, loss is 5.216153869628906 and perplexity is 184.2242691764243
At time: 1324.5935814380646 and batch: 450, loss is 5.173615922927857 and perplexity is 176.55208340000618
At time: 1325.6999912261963 and batch: 500, loss is 5.218924856185913 and perplexity is 184.73546007424696
At time: 1326.806928396225 and batch: 550, loss is 5.189693880081177 and perplexity is 179.41362244106526
At time: 1327.913512468338 and batch: 600, loss is 5.148999900817871 and perplexity is 172.25912792852327
At time: 1329.020102739334 and batch: 650, loss is 5.175624380111694 and perplexity is 176.90703703550136
At time: 1330.1282517910004 and batch: 700, loss is 5.184944458007813 and perplexity is 178.56353174010928
At time: 1331.2348203659058 and batch: 750, loss is 5.1638655090332035 and perplexity is 174.83899275632095
At time: 1332.3414726257324 and batch: 800, loss is 5.140992584228516 and perplexity is 170.88530222493802
At time: 1333.4472651481628 and batch: 850, loss is 5.118286399841309 and perplexity is 167.04886924881566
At time: 1334.5541155338287 and batch: 900, loss is 5.150583906173706 and perplexity is 172.5322035292634
At time: 1335.6599440574646 and batch: 950, loss is 5.140001916885376 and perplexity is 170.7160955641963
At time: 1336.7670454978943 and batch: 1000, loss is 5.154758596420288 and perplexity is 173.25397757984445
At time: 1337.8744938373566 and batch: 1050, loss is 5.120952558517456 and perplexity is 167.4948422941765
At time: 1338.98193359375 and batch: 1100, loss is 5.121023836135865 and perplexity is 167.50678135311972
At time: 1340.088222026825 and batch: 1150, loss is 5.133913688659668 and perplexity is 169.67989452749467
At time: 1341.1948592662811 and batch: 1200, loss is 5.109197158813476 and perplexity is 165.53740126690806
At time: 1342.3013045787811 and batch: 1250, loss is 5.131086835861206 and perplexity is 169.20091176864946
At time: 1343.4070510864258 and batch: 1300, loss is 5.111865739822388 and perplexity is 165.97974117963506
At time: 1344.514100074768 and batch: 1350, loss is 5.0904326820373536 and perplexity is 162.4601404328478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0502921549479165 and perplexity of 156.0680538806401
Finished 42 epochs...
Completing Train Step...
At time: 1348.153614282608 and batch: 50, loss is 5.184518299102783 and perplexity is 178.48745151322922
At time: 1349.2602303028107 and batch: 100, loss is 5.198979539871216 and perplexity is 181.08735513068194
At time: 1350.3663420677185 and batch: 150, loss is 5.161077070236206 and perplexity is 174.35214401510362
At time: 1351.4725306034088 and batch: 200, loss is 5.154475908279419 and perplexity is 173.20500765695857
At time: 1352.5786867141724 and batch: 250, loss is 5.173036422729492 and perplexity is 176.4498010718313
At time: 1353.6859560012817 and batch: 300, loss is 5.17852933883667 and perplexity is 177.4216918398076
At time: 1354.7945568561554 and batch: 350, loss is 5.181185026168823 and perplexity is 177.89349458226965
At time: 1355.9012789726257 and batch: 400, loss is 5.215655784606934 and perplexity is 184.13253267544889
At time: 1357.0395774841309 and batch: 450, loss is 5.173215808868409 and perplexity is 176.48145655955116
At time: 1358.1459395885468 and batch: 500, loss is 5.218441390991211 and perplexity is 184.6461684954984
At time: 1359.2518906593323 and batch: 550, loss is 5.18928858757019 and perplexity is 179.34092217695235
At time: 1360.3582603931427 and batch: 600, loss is 5.148728885650635 and perplexity is 172.2124494177377
At time: 1361.4644510746002 and batch: 650, loss is 5.175274457931518 and perplexity is 176.84514416888842
At time: 1362.5712645053864 and batch: 700, loss is 5.1847234725952145 and perplexity is 178.52407616408664
At time: 1363.6775331497192 and batch: 750, loss is 5.163736324310303 and perplexity is 174.81640768834384
At time: 1364.7842438220978 and batch: 800, loss is 5.1410001850128175 and perplexity is 170.8866010921967
At time: 1365.8915467262268 and batch: 850, loss is 5.118337869644165 and perplexity is 167.05746744245502
At time: 1366.998420715332 and batch: 900, loss is 5.150640296936035 and perplexity is 172.541933026071
At time: 1368.1040658950806 and batch: 950, loss is 5.139936952590943 and perplexity is 170.70500547373337
At time: 1369.2111382484436 and batch: 1000, loss is 5.154813241958618 and perplexity is 173.26344539540167
At time: 1370.3169295787811 and batch: 1050, loss is 5.121061038970947 and perplexity is 167.51301319620205
At time: 1371.42338514328 and batch: 1100, loss is 5.12117919921875 and perplexity is 167.53280774479276
At time: 1372.5300285816193 and batch: 1150, loss is 5.134089975357056 and perplexity is 169.70980947244004
At time: 1373.6367638111115 and batch: 1200, loss is 5.109451093673706 and perplexity is 165.57944232138036
At time: 1374.7444939613342 and batch: 1250, loss is 5.1313778591156005 and perplexity is 169.25016033453028
At time: 1375.85080909729 and batch: 1300, loss is 5.11211404800415 and perplexity is 166.0209604247028
At time: 1376.957125902176 and batch: 1350, loss is 5.090450315475464 and perplexity is 162.46300518893725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.050127360026042 and perplexity of 156.04233677697593
Finished 43 epochs...
Completing Train Step...
At time: 1380.4012401103973 and batch: 50, loss is 5.184074201583862 and perplexity is 178.40820327712868
At time: 1381.509435415268 and batch: 100, loss is 5.198541917800903 and perplexity is 181.00812464519126
At time: 1382.6160173416138 and batch: 150, loss is 5.1606580257415775 and perplexity is 174.27909801485845
At time: 1383.7216906547546 and batch: 200, loss is 5.1539528369903564 and perplexity is 173.11443278095498
At time: 1384.8274466991425 and batch: 250, loss is 5.172421875 and perplexity is 176.34139756019107
At time: 1385.9348738193512 and batch: 300, loss is 5.1779538440704345 and perplexity is 177.31961595962179
At time: 1387.042180299759 and batch: 350, loss is 5.180666999816895 and perplexity is 177.80136492909378
At time: 1388.1519832611084 and batch: 400, loss is 5.215212736129761 and perplexity is 184.0509711064476
At time: 1389.258961200714 and batch: 450, loss is 5.1728620529174805 and perplexity is 176.41903623549626
At time: 1390.364858865738 and batch: 500, loss is 5.2180044555664065 and perplexity is 184.5655076664983
At time: 1391.470796585083 and batch: 550, loss is 5.188921699523926 and perplexity is 179.27513620518081
At time: 1392.6228947639465 and batch: 600, loss is 5.148483991622925 and perplexity is 172.17028078101237
At time: 1393.7300260066986 and batch: 650, loss is 5.174954776763916 and perplexity is 176.78861914219033
At time: 1394.8379559516907 and batch: 700, loss is 5.18452184677124 and perplexity is 178.48808472865412
At time: 1395.9453463554382 and batch: 750, loss is 5.163603811264038 and perplexity is 174.79324376841868
At time: 1397.0517120361328 and batch: 800, loss is 5.140992650985718 and perplexity is 170.88531363276294
At time: 1398.158860206604 and batch: 850, loss is 5.118361110687256 and perplexity is 167.0613500773726
At time: 1399.2651777267456 and batch: 900, loss is 5.150665683746338 and perplexity is 172.54631337099528
At time: 1400.3702626228333 and batch: 950, loss is 5.139836530685425 and perplexity is 170.68786381251587
At time: 1401.4782946109772 and batch: 1000, loss is 5.154834175109864 and perplexity is 173.26707238327143
At time: 1402.5850477218628 and batch: 1050, loss is 5.121134719848633 and perplexity is 167.52535615675257
At time: 1403.6922674179077 and batch: 1100, loss is 5.1212824440002445 and perplexity is 167.550105525859
At time: 1404.7994439601898 and batch: 1150, loss is 5.13421739578247 and perplexity is 169.73143534631978
At time: 1405.9065840244293 and batch: 1200, loss is 5.109651670455933 and perplexity is 165.61265704406384
At time: 1407.0147967338562 and batch: 1250, loss is 5.13164436340332 and perplexity is 169.2952722389477
At time: 1408.1214220523834 and batch: 1300, loss is 5.112312383651734 and perplexity is 166.05389156500266
At time: 1409.2281029224396 and batch: 1350, loss is 5.0904339408874515 and perplexity is 162.46034494594022
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049977620442708 and perplexity of 156.0189728117834
Finished 44 epochs...
Completing Train Step...
At time: 1412.6568567752838 and batch: 50, loss is 5.183662605285645 and perplexity is 178.33478623121678
At time: 1413.7958946228027 and batch: 100, loss is 5.198140983581543 and perplexity is 180.9355668404641
At time: 1414.9035143852234 and batch: 150, loss is 5.160289440155029 and perplexity is 174.21487308821182
At time: 1416.0110819339752 and batch: 200, loss is 5.153482522964477 and perplexity is 173.03303377818278
At time: 1417.1178176403046 and batch: 250, loss is 5.171856956481934 and perplexity is 176.24180717208333
At time: 1418.2260863780975 and batch: 300, loss is 5.1774327754974365 and perplexity is 177.227244348431
At time: 1419.334760427475 and batch: 350, loss is 5.180204420089722 and perplexity is 177.71913664224945
At time: 1420.4736094474792 and batch: 400, loss is 5.214820480346679 and perplexity is 183.9787902062626
At time: 1421.5826439857483 and batch: 450, loss is 5.172552680969238 and perplexity is 176.36446557629984
At time: 1422.6904077529907 and batch: 500, loss is 5.2176117324829105 and perplexity is 184.4930387622577
At time: 1423.8115799427032 and batch: 550, loss is 5.188590393066407 and perplexity is 179.2157510327722
At time: 1424.9177260398865 and batch: 600, loss is 5.1482656383514405 and perplexity is 172.13269094103308
At time: 1426.0222735404968 and batch: 650, loss is 5.174671421051025 and perplexity is 176.7385321735318
At time: 1427.127705335617 and batch: 700, loss is 5.184327268600464 and perplexity is 178.45335822224195
At time: 1428.2326836585999 and batch: 750, loss is 5.163467521667481 and perplexity is 174.76942289105023
At time: 1429.3377187252045 and batch: 800, loss is 5.140970706939697 and perplexity is 170.88156375872026
At time: 1430.4427008628845 and batch: 850, loss is 5.118375005722046 and perplexity is 167.06367141677154
At time: 1431.5477788448334 and batch: 900, loss is 5.150665006637573 and perplexity is 172.54619653841374
At time: 1432.651818037033 and batch: 950, loss is 5.139720296859741 and perplexity is 170.6680252620847
At time: 1433.7566998004913 and batch: 1000, loss is 5.1548324394226075 and perplexity is 173.266771646083
At time: 1434.8610610961914 and batch: 1050, loss is 5.12116961479187 and perplexity is 167.53120204654184
At time: 1435.9655294418335 and batch: 1100, loss is 5.1213453578948975 and perplexity is 167.56064708714905
At time: 1437.0706343650818 and batch: 1150, loss is 5.134303569793701 and perplexity is 169.7460624151631
At time: 1438.1774859428406 and batch: 1200, loss is 5.109808521270752 and perplexity is 165.6386355615881
At time: 1439.28240275383 and batch: 1250, loss is 5.131841373443604 and perplexity is 169.328628392992
At time: 1440.387306213379 and batch: 1300, loss is 5.112474641799927 and perplexity is 166.08083734797555
At time: 1441.4927673339844 and batch: 1350, loss is 5.090401601791382 and perplexity is 162.45509121018853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049842529296875 and perplexity of 155.99789745355372
Finished 45 epochs...
Completing Train Step...
At time: 1444.9071464538574 and batch: 50, loss is 5.183280744552612 and perplexity is 178.2667001795435
At time: 1446.0558898448944 and batch: 100, loss is 5.197767562866211 and perplexity is 180.86801436519738
At time: 1447.1604115962982 and batch: 150, loss is 5.159959506988526 and perplexity is 174.15740330459693
At time: 1448.3038527965546 and batch: 200, loss is 5.153053960800171 and perplexity is 172.95889425456238
At time: 1449.4072198867798 and batch: 250, loss is 5.171337270736695 and perplexity is 176.1502406121596
At time: 1450.5127122402191 and batch: 300, loss is 5.176957864761352 and perplexity is 177.1430972101345
At time: 1451.6180424690247 and batch: 350, loss is 5.179791097640991 and perplexity is 177.64569651177894
At time: 1452.723373889923 and batch: 400, loss is 5.2144703197479245 and perplexity is 183.91437936065407
At time: 1453.8425967693329 and batch: 450, loss is 5.172280654907227 and perplexity is 176.31649636998338
At time: 1454.949345111847 and batch: 500, loss is 5.2172630023956295 and perplexity is 184.42871170578928
At time: 1456.0536637306213 and batch: 550, loss is 5.1882858562469485 and perplexity is 179.16118154758635
At time: 1457.158574104309 and batch: 600, loss is 5.148067388534546 and perplexity is 172.09856904901366
At time: 1458.2636587619781 and batch: 650, loss is 5.174411830902099 and perplexity is 176.69265854607244
At time: 1459.368481874466 and batch: 700, loss is 5.184144020080566 and perplexity is 178.42065990452758
At time: 1460.4726874828339 and batch: 750, loss is 5.163333196640014 and perplexity is 174.74594856015045
At time: 1461.5768840312958 and batch: 800, loss is 5.140942268371582 and perplexity is 170.87670420082938
At time: 1462.6814935207367 and batch: 850, loss is 5.118379859924317 and perplexity is 167.0644823795929
At time: 1463.7867720127106 and batch: 900, loss is 5.150642137527466 and perplexity is 172.54225060556672
At time: 1464.8913848400116 and batch: 950, loss is 5.13960259437561 and perplexity is 170.64793839371
At time: 1465.9967949390411 and batch: 1000, loss is 5.154816560745239 and perplexity is 173.2640204207603
At time: 1467.1020939350128 and batch: 1050, loss is 5.12119125366211 and perplexity is 167.53482727170675
At time: 1468.2064809799194 and batch: 1100, loss is 5.121382532119751 and perplexity is 167.5668761400998
At time: 1469.3113729953766 and batch: 1150, loss is 5.134445533752442 and perplexity is 169.77016194875628
At time: 1470.416044473648 and batch: 1200, loss is 5.109930171966552 and perplexity is 165.65878684253943
At time: 1471.521823644638 and batch: 1250, loss is 5.132000122070313 and perplexity is 169.35551121396088
At time: 1472.6272785663605 and batch: 1300, loss is 5.11260760307312 and perplexity is 166.10292113567408
At time: 1473.7334628105164 and batch: 1350, loss is 5.090357780456543 and perplexity is 162.44797236722005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049718831380209 and perplexity of 155.97860203206073
Finished 46 epochs...
Completing Train Step...
At time: 1477.2202224731445 and batch: 50, loss is 5.1829197978973385 and perplexity is 178.20236702148455
At time: 1478.3251132965088 and batch: 100, loss is 5.197409257888794 and perplexity is 180.80322006414832
At time: 1479.4302952289581 and batch: 150, loss is 5.159660234451294 and perplexity is 174.10529057497558
At time: 1480.5340774059296 and batch: 200, loss is 5.152661123275757 and perplexity is 172.89096285459314
At time: 1481.6373391151428 and batch: 250, loss is 5.170848703384399 and perplexity is 176.06420037543427
At time: 1482.741492986679 and batch: 300, loss is 5.176498975753784 and perplexity is 177.06182683852444
At time: 1483.8461151123047 and batch: 350, loss is 5.179414710998535 and perplexity is 177.5788456262015
At time: 1484.9515240192413 and batch: 400, loss is 5.214150114059448 and perplexity is 183.85549835770934
At time: 1486.0567967891693 and batch: 450, loss is 5.172037897109985 and perplexity is 176.27369936057121
At time: 1487.1614301204681 and batch: 500, loss is 5.2169485187530515 and perplexity is 184.3707210117764
At time: 1488.2653834819794 and batch: 550, loss is 5.188003959655762 and perplexity is 179.1106837391496
At time: 1489.3700087070465 and batch: 600, loss is 5.147882041931152 and perplexity is 172.06667411969116
At time: 1490.4750351905823 and batch: 650, loss is 5.174163045883179 and perplexity is 176.648705527326
At time: 1491.5798411369324 and batch: 700, loss is 5.183970937728882 and perplexity is 178.38978110948648
At time: 1492.684751033783 and batch: 750, loss is 5.163195466995239 and perplexity is 174.72188252007098
At time: 1493.7894122600555 and batch: 800, loss is 5.140907039642334 and perplexity is 170.87068453771553
At time: 1494.8936777114868 and batch: 850, loss is 5.118372774124145 and perplexity is 167.06329859824905
At time: 1495.9979975223541 and batch: 900, loss is 5.15060152053833 and perplexity is 172.5352426011713
At time: 1497.1045358181 and batch: 950, loss is 5.139483366012573 and perplexity is 170.6275935322261
At time: 1498.2084214687347 and batch: 1000, loss is 5.154788970947266 and perplexity is 173.25924016738426
At time: 1499.3118929862976 and batch: 1050, loss is 5.121198225021362 and perplexity is 167.53599522124608
At time: 1500.4170920848846 and batch: 1100, loss is 5.121393899917603 and perplexity is 167.5687810173016
At time: 1501.5220885276794 and batch: 1150, loss is 5.134527568817139 and perplexity is 169.7840896262465
At time: 1502.6264276504517 and batch: 1200, loss is 5.110021600723266 and perplexity is 165.6739335118692
At time: 1503.7301592826843 and batch: 1250, loss is 5.132131938934326 and perplexity is 169.3778365977512
At time: 1504.8359656333923 and batch: 1300, loss is 5.112717742919922 and perplexity is 166.1212166934778
At time: 1505.9400918483734 and batch: 1350, loss is 5.090328016281128 and perplexity is 162.4431373092308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049595947265625 and perplexity of 155.9594359172857
Finished 47 epochs...
Completing Train Step...
At time: 1509.3903465270996 and batch: 50, loss is 5.182574090957641 and perplexity is 178.14077187408316
At time: 1510.4952437877655 and batch: 100, loss is 5.197080020904541 and perplexity is 180.74370275541835
At time: 1511.5997154712677 and batch: 150, loss is 5.159386758804321 and perplexity is 174.05768352797497
At time: 1512.7028498649597 and batch: 200, loss is 5.152296953201294 and perplexity is 172.82801260277103
At time: 1513.8077692985535 and batch: 250, loss is 5.170398721694946 and perplexity is 175.9849925314734
At time: 1514.9128143787384 and batch: 300, loss is 5.176075391769409 and perplexity is 176.98684216670563
At time: 1516.0172092914581 and batch: 350, loss is 5.1790672874450685 and perplexity is 177.5171612685534
At time: 1517.1213738918304 and batch: 400, loss is 5.2138509178161625 and perplexity is 183.80049771169692
At time: 1518.2254855632782 and batch: 450, loss is 5.171818990707397 and perplexity is 176.23511614238416
At time: 1519.3292782306671 and batch: 500, loss is 5.216662139892578 and perplexity is 184.31792869445098
At time: 1520.4327733516693 and batch: 550, loss is 5.187742843627929 and perplexity is 179.0639211743625
At time: 1521.540281534195 and batch: 600, loss is 5.147705087661743 and perplexity is 172.0362288808696
At time: 1522.64413189888 and batch: 650, loss is 5.173920078277588 and perplexity is 176.60579082796522
At time: 1523.7481760978699 and batch: 700, loss is 5.183773880004883 and perplexity is 178.35463148860228
At time: 1524.851705789566 and batch: 750, loss is 5.163044519424439 and perplexity is 174.6955106667726
At time: 1525.955271244049 and batch: 800, loss is 5.140851402282715 and perplexity is 170.86117800845312
At time: 1527.0597348213196 and batch: 850, loss is 5.118352794647217 and perplexity is 167.05996079427308
At time: 1528.1643662452698 and batch: 900, loss is 5.150547485351563 and perplexity is 172.52591987899325
At time: 1529.2682147026062 and batch: 950, loss is 5.13934720993042 and perplexity is 170.60436312909965
At time: 1530.3723628520966 and batch: 1000, loss is 5.154678421020508 and perplexity is 173.24008742976002
At time: 1531.474622964859 and batch: 1050, loss is 5.1211307334899905 and perplexity is 167.52468834193232
At time: 1532.721883058548 and batch: 1100, loss is 5.121375713348389 and perplexity is 167.56573354377912
At time: 1533.825189590454 and batch: 1150, loss is 5.134561023712158 and perplexity is 169.78976983015573
At time: 1534.929480791092 and batch: 1200, loss is 5.110086431503296 and perplexity is 165.68467463038314
At time: 1536.033212184906 and batch: 1250, loss is 5.132200889587402 and perplexity is 169.3895157128379
At time: 1537.1368777751923 and batch: 1300, loss is 5.112808704376221 and perplexity is 166.13632800853355
At time: 1538.2405071258545 and batch: 1350, loss is 5.090463037490845 and perplexity is 162.4650720589354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049489339192708 and perplexity of 155.94281026859926
Finished 48 epochs...
Completing Train Step...
At time: 1541.657835483551 and batch: 50, loss is 5.182237167358398 and perplexity is 178.0807621539645
At time: 1542.78897356987 and batch: 100, loss is 5.196780281066895 and perplexity is 180.6895347858536
At time: 1543.891078710556 and batch: 150, loss is 5.159129495620728 and perplexity is 174.0129106536347
At time: 1544.9934420585632 and batch: 200, loss is 5.151951379776001 and perplexity is 172.76829815292714
At time: 1546.093754529953 and batch: 250, loss is 5.169982137680054 and perplexity is 175.9116952650187
At time: 1547.2004680633545 and batch: 300, loss is 5.175677719116211 and perplexity is 176.91647333240803
At time: 1548.303073644638 and batch: 350, loss is 5.178746271133423 and perplexity is 177.46018450991286
At time: 1549.405574798584 and batch: 400, loss is 5.213576965332031 and perplexity is 183.75015200524473
At time: 1550.5083560943604 and batch: 450, loss is 5.17161940574646 and perplexity is 176.19994577346827
At time: 1551.6105201244354 and batch: 500, loss is 5.216397895812988 and perplexity is 184.26923020745798
At time: 1552.711368560791 and batch: 550, loss is 5.1875009346008305 and perplexity is 179.02060923438856
At time: 1553.8133590221405 and batch: 600, loss is 5.1475411224365235 and perplexity is 172.00802323429104
At time: 1554.9156937599182 and batch: 650, loss is 5.17369815826416 and perplexity is 176.56660281695602
At time: 1556.0188159942627 and batch: 700, loss is 5.183586158752441 and perplexity is 178.32115367614728
At time: 1557.1214790344238 and batch: 750, loss is 5.1628932762146 and perplexity is 174.66909115493118
At time: 1558.2239508628845 and batch: 800, loss is 5.140792646408081 and perplexity is 170.85113920542042
At time: 1559.3256833553314 and batch: 850, loss is 5.1183257484436036 and perplexity is 167.05544251765915
At time: 1560.4557230472565 and batch: 900, loss is 5.1504823589324955 and perplexity is 172.51468424950735
At time: 1561.5571591854095 and batch: 950, loss is 5.139209489822388 and perplexity is 170.5808690956164
At time: 1562.6597394943237 and batch: 1000, loss is 5.154618425369263 and perplexity is 173.22969408967361
At time: 1563.7614102363586 and batch: 1050, loss is 5.1210854053497314 and perplexity is 167.51709493146117
At time: 1564.8642783164978 and batch: 1100, loss is 5.121343040466309 and perplexity is 167.5602587777651
At time: 1565.9718747138977 and batch: 1150, loss is 5.134573316574096 and perplexity is 169.79185704518366
At time: 1567.079665184021 and batch: 1200, loss is 5.110130939483643 and perplexity is 165.69204908473515
At time: 1568.1886208057404 and batch: 1250, loss is 5.132274990081787 and perplexity is 169.40206802475637
At time: 1569.2977755069733 and batch: 1300, loss is 5.112882871627807 and perplexity is 166.1486503403217
At time: 1570.4077498912811 and batch: 1350, loss is 5.090352849960327 and perplexity is 162.44717142008156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049391276041667 and perplexity of 155.92751877502036
Finished 49 epochs...
Completing Train Step...
At time: 1574.0970323085785 and batch: 50, loss is 5.181907148361206 and perplexity is 178.02200181596646
At time: 1575.2534160614014 and batch: 100, loss is 5.196505432128906 and perplexity is 180.63987928330573
At time: 1576.3600895404816 and batch: 150, loss is 5.158888940811157 and perplexity is 173.97105604541508
At time: 1577.4690339565277 and batch: 200, loss is 5.151628465652466 and perplexity is 172.71251783596512
At time: 1578.5751476287842 and batch: 250, loss is 5.16958625793457 and perplexity is 175.84206917055917
At time: 1579.6821393966675 and batch: 300, loss is 5.175300550460816 and perplexity is 176.8497585661941
At time: 1580.790212392807 and batch: 350, loss is 5.1784406089782715 and perplexity is 177.4059499366126
At time: 1581.8986494541168 and batch: 400, loss is 5.2133154201507566 and perplexity is 183.70209932267701
At time: 1583.0068078041077 and batch: 450, loss is 5.171435651779174 and perplexity is 176.16757130895613
At time: 1584.1136622428894 and batch: 500, loss is 5.216153879165649 and perplexity is 184.2242709333238
At time: 1585.219373703003 and batch: 550, loss is 5.187276277542114 and perplexity is 178.98039550818626
At time: 1586.3258645534515 and batch: 600, loss is 5.147379550933838 and perplexity is 171.9802338845471
At time: 1587.433494091034 and batch: 650, loss is 5.173483810424805 and perplexity is 176.52876020302605
At time: 1588.5401170253754 and batch: 700, loss is 5.183416709899903 and perplexity is 178.29093992118882
At time: 1589.694138765335 and batch: 750, loss is 5.162751770019531 and perplexity is 174.6443761451504
At time: 1590.8012764453888 and batch: 800, loss is 5.140733261108398 and perplexity is 170.84099346057454
At time: 1591.910499572754 and batch: 850, loss is 5.118294763565063 and perplexity is 167.05026640525426
At time: 1593.0183827877045 and batch: 900, loss is 5.150407114028931 and perplexity is 172.50170388708665
At time: 1594.1251347064972 and batch: 950, loss is 5.139078979492187 and perplexity is 170.558607982749
At time: 1595.2313067913055 and batch: 1000, loss is 5.154558572769165 and perplexity is 173.21932615234536
At time: 1596.3404867649078 and batch: 1050, loss is 5.121030178070068 and perplexity is 167.5078436734743
At time: 1597.448177576065 and batch: 1100, loss is 5.121299085617065 and perplexity is 167.55289385371452
At time: 1598.55641913414 and batch: 1150, loss is 5.134569482803345 and perplexity is 169.79120610337606
At time: 1599.6621017456055 and batch: 1200, loss is 5.110157442092896 and perplexity is 165.69644041455896
At time: 1600.7694034576416 and batch: 1250, loss is 5.132371139526367 and perplexity is 169.4183567225698
At time: 1601.8754692077637 and batch: 1300, loss is 5.112942914962769 and perplexity is 166.15862675889326
At time: 1602.9821102619171 and batch: 1350, loss is 5.090196285247803 and perplexity is 162.42173991627777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.049294840494792 and perplexity of 155.91248254449962
Finished Training.
Improved accuracyfrom -10000000 to -155.91248254449962
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2f9ec4898>
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 3.931361136456256, 'wordvec_source': 'glove', 'dropout': 0.4448398761434641, 'data': 'wikitext', 'lr': 1.452568867888998, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.596484899520874 and batch: 50, loss is 7.76338152885437 and perplexity is 2352.8473896680453
At time: 2.621372699737549 and batch: 100, loss is 6.70792631149292 and perplexity is 818.8707946298236
At time: 3.645789384841919 and batch: 150, loss is 6.489784612655639 and perplexity is 658.3815408907334
At time: 4.672966718673706 and batch: 200, loss is 6.400550861358642 and perplexity is 602.1766623785135
At time: 5.7006120681762695 and batch: 250, loss is 6.339481182098389 and perplexity is 566.502323578346
At time: 6.728090763092041 and batch: 300, loss is 6.294313659667969 and perplexity is 541.4840764665101
At time: 7.783267974853516 and batch: 350, loss is 6.265670747756958 and perplexity is 526.1944113388109
At time: 8.815950393676758 and batch: 400, loss is 6.274597415924072 and perplexity is 530.9126017695169
At time: 9.84316873550415 and batch: 450, loss is 6.209602508544922 and perplexity is 497.5034586052936
At time: 10.872375965118408 and batch: 500, loss is 6.177012357711792 and perplexity is 481.551102608666
At time: 11.903103351593018 and batch: 550, loss is 6.116053600311279 and perplexity is 453.073154003301
At time: 12.934515714645386 and batch: 600, loss is 6.0430511856079105 and perplexity is 421.1761630071451
At time: 13.967448234558105 and batch: 650, loss is 6.052096395492554 and perplexity is 425.0030713025558
At time: 14.998527765274048 and batch: 700, loss is 6.0446208953857425 and perplexity is 421.83780650668564
At time: 16.030359029769897 and batch: 750, loss is 6.004656085968017 and perplexity is 405.3115724260798
At time: 17.062736988067627 and batch: 800, loss is 5.953195972442627 and perplexity is 384.9817661214129
At time: 18.095221281051636 and batch: 850, loss is 5.930766706466675 and perplexity is 376.4430245103286
At time: 19.128634691238403 and batch: 900, loss is 5.9635289287567135 and perplexity is 388.9803891131302
At time: 20.164605379104614 and batch: 950, loss is 5.917613687515259 and perplexity is 371.52408265784186
At time: 21.1979501247406 and batch: 1000, loss is 5.91358362197876 and perplexity is 370.02982924832753
At time: 22.231391668319702 and batch: 1050, loss is 5.8809001255035405 and perplexity is 358.1314599293804
At time: 23.265881776809692 and batch: 1100, loss is 5.860876731872558 and perplexity is 351.03176988844837
At time: 24.299855709075928 and batch: 1150, loss is 5.846088371276855 and perplexity is 345.8787815307646
At time: 25.3333523273468 and batch: 1200, loss is 5.8208834743499756 and perplexity is 337.2698913427293
At time: 26.367098331451416 and batch: 1250, loss is 5.82511715888977 and perplexity is 338.7008125646439
At time: 27.400660037994385 and batch: 1300, loss is 5.777845201492309 and perplexity is 323.06230568961143
At time: 28.434523820877075 and batch: 1350, loss is 5.756251182556152 and perplexity is 316.1608751310318
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.27853271484375 and perplexity of 196.08195603008915
Finished 1 epochs...
Completing Train Step...
At time: 31.734634160995483 and batch: 50, loss is 5.610030918121338 and perplexity is 273.15268324200497
At time: 32.76374173164368 and batch: 100, loss is 5.582533178329467 and perplexity is 265.74393063360327
At time: 33.793139696121216 and batch: 150, loss is 5.5028571605682375 and perplexity is 245.39205611129537
At time: 34.82256531715393 and batch: 200, loss is 5.478127737045288 and perplexity is 239.3980713825553
At time: 35.85352969169617 and batch: 250, loss is 5.483215160369873 and perplexity is 240.6190940107384
At time: 36.885051250457764 and batch: 300, loss is 5.457839441299439 and perplexity is 234.59003090360238
At time: 37.91774129867554 and batch: 350, loss is 5.452941312789917 and perplexity is 233.44378829866278
At time: 38.9512722492218 and batch: 400, loss is 5.475433359146118 and perplexity is 238.75391070576336
At time: 40.03569197654724 and batch: 450, loss is 5.433611993789673 and perplexity is 228.97480914955935
At time: 41.13006663322449 and batch: 500, loss is 5.448708248138428 and perplexity is 232.45769422276504
At time: 42.23782300949097 and batch: 550, loss is 5.403139200210571 and perplexity is 222.1025473484012
At time: 43.34655952453613 and batch: 600, loss is 5.338770942687988 and perplexity is 208.256593641128
At time: 44.45601415634155 and batch: 650, loss is 5.361602611541748 and perplexity is 213.06613522745656
At time: 45.564088582992554 and batch: 700, loss is 5.359612646102906 and perplexity is 212.64256256941894
At time: 46.671857595443726 and batch: 750, loss is 5.3224076080322265 and perplexity is 204.87655110798835
At time: 47.78059959411621 and batch: 800, loss is 5.276900911331177 and perplexity is 195.76224972536502
At time: 48.88941740989685 and batch: 850, loss is 5.252285060882568 and perplexity is 191.00222188458756
At time: 49.997748374938965 and batch: 900, loss is 5.295243740081787 and perplexity is 199.3862184575554
At time: 51.10774374008179 and batch: 950, loss is 5.252408838272094 and perplexity is 191.02586510422398
At time: 52.2174596786499 and batch: 1000, loss is 5.258431377410889 and perplexity is 192.17979716598748
At time: 53.32557964324951 and batch: 1050, loss is 5.2132827663421635 and perplexity is 183.69610084742465
At time: 54.43421745300293 and batch: 1100, loss is 5.187483835220337 and perplexity is 179.0175481190467
At time: 55.54238176345825 and batch: 1150, loss is 5.190493087768555 and perplexity is 179.55706850130224
At time: 56.65169978141785 and batch: 1200, loss is 5.17259744644165 and perplexity is 176.37236079163333
At time: 57.7604296207428 and batch: 1250, loss is 5.199746770858765 and perplexity is 181.22634427256182
At time: 58.869532108306885 and batch: 1300, loss is 5.172159423828125 and perplexity is 176.2951226264722
At time: 59.97809290885925 and batch: 1350, loss is 5.137468748092651 and perplexity is 170.2841901541097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.907244873046875 and perplexity of 135.26622493018235
Finished 2 epochs...
Completing Train Step...
At time: 63.41853618621826 and batch: 50, loss is 5.19302716255188 and perplexity is 180.01265654404668
At time: 64.54551720619202 and batch: 100, loss is 5.195397977828979 and perplexity is 180.43993960471832
At time: 65.64625644683838 and batch: 150, loss is 5.136523914337158 and perplexity is 170.1233758865629
At time: 66.77714014053345 and batch: 200, loss is 5.132231035232544 and perplexity is 169.3946221460373
At time: 67.88314890861511 and batch: 250, loss is 5.140165929794311 and perplexity is 170.74409750390888
At time: 68.99248671531677 and batch: 300, loss is 5.130042219161988 and perplexity is 169.02425395660768
At time: 70.10085248947144 and batch: 350, loss is 5.131191568374634 and perplexity is 169.21863353341956
At time: 71.20849823951721 and batch: 400, loss is 5.157444934844971 and perplexity is 173.72002209342438
At time: 72.31691074371338 and batch: 450, loss is 5.11751347541809 and perplexity is 166.91980298356202
At time: 73.42481970787048 and batch: 500, loss is 5.161346502304077 and perplexity is 174.39912640280016
At time: 74.532710313797 and batch: 550, loss is 5.124663877487182 and perplexity is 168.11762403571618
At time: 75.64030170440674 and batch: 600, loss is 5.0660919666290285 and perplexity is 158.55348269121242
At time: 76.74809622764587 and batch: 650, loss is 5.096384563446045 and perplexity is 163.42996720631572
At time: 77.85643362998962 and batch: 700, loss is 5.102459869384766 and perplexity is 164.42587642003517
At time: 78.9636070728302 and batch: 750, loss is 5.065382957458496 and perplexity is 158.44110666049022
At time: 80.07360506057739 and batch: 800, loss is 5.028911409378051 and perplexity is 152.766621834405
At time: 81.18128561973572 and batch: 850, loss is 5.005286159515381 and perplexity is 149.19977198463576
At time: 82.28865575790405 and batch: 900, loss is 5.048415899276733 and perplexity is 155.77550484367345
At time: 83.39724159240723 and batch: 950, loss is 5.014979524612427 and perplexity is 150.65305205470668
At time: 84.50543189048767 and batch: 1000, loss is 5.025259876251221 and perplexity is 152.2098066872804
At time: 85.61401081085205 and batch: 1050, loss is 4.975643606185913 and perplexity is 144.84201637345757
At time: 86.72194647789001 and batch: 1100, loss is 4.953628883361817 and perplexity is 141.68820207663032
At time: 87.82965731620789 and batch: 1150, loss is 4.96366849899292 and perplexity is 143.11786177346917
At time: 88.93803358078003 and batch: 1200, loss is 4.950824785232544 and perplexity is 141.2914509787229
At time: 90.04658579826355 and batch: 1250, loss is 4.988833465576172 and perplexity is 146.76511703643993
At time: 91.15453457832336 and batch: 1300, loss is 4.9713924121856685 and perplexity is 144.22757184929122
At time: 92.26303458213806 and batch: 1350, loss is 4.938022623062134 and perplexity is 139.4941441641091
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7620772298177085 and perplexity of 116.98868606440021
Finished 3 epochs...
Completing Train Step...
At time: 95.70461845397949 and batch: 50, loss is 5.00234622001648 and perplexity is 148.76177783537506
At time: 96.80330300331116 and batch: 100, loss is 5.011293067932129 and perplexity is 150.09869853247844
At time: 97.91223859786987 and batch: 150, loss is 4.953913125991821 and perplexity is 141.72848162814086
At time: 99.01916980743408 and batch: 200, loss is 4.954959859848023 and perplexity is 141.87691129787706
At time: 100.12704205513 and batch: 250, loss is 4.960972785949707 and perplexity is 142.7325766291821
At time: 101.23597812652588 and batch: 300, loss is 4.951255884170532 and perplexity is 141.35237470431983
At time: 102.34384322166443 and batch: 350, loss is 4.953945560455322 and perplexity is 141.73307858995483
At time: 103.45214700698853 and batch: 400, loss is 4.9805511951446535 and perplexity is 145.55458852923846
At time: 104.55950665473938 and batch: 450, loss is 4.9393593692779545 and perplexity is 139.68073711937797
At time: 105.66789960861206 and batch: 500, loss is 4.996109685897827 and perplexity is 147.8369069245351
At time: 106.77539491653442 and batch: 550, loss is 4.962910060882568 and perplexity is 143.0093568851506
At time: 107.883216381073 and batch: 600, loss is 4.911123857498169 and perplexity is 135.79193947356052
At time: 108.99125790596008 and batch: 650, loss is 4.9396953201293945 and perplexity is 139.7276708652175
At time: 110.09861254692078 and batch: 700, loss is 4.950994186401367 and perplexity is 141.31538794308105
At time: 111.20547723770142 and batch: 750, loss is 4.913256483078003 and perplexity is 136.08184185395788
At time: 112.31483435630798 and batch: 800, loss is 4.878774862289429 and perplexity is 131.4694969416455
At time: 113.4231173992157 and batch: 850, loss is 4.853045082092285 and perplexity is 128.12996265918204
At time: 114.53143072128296 and batch: 900, loss is 4.897425308227539 and perplexity is 133.9444696183049
At time: 115.63966417312622 and batch: 950, loss is 4.86696566581726 and perplexity is 129.9260790215695
At time: 116.74726128578186 and batch: 1000, loss is 4.8814323616027835 and perplexity is 131.8193416896914
At time: 117.85502171516418 and batch: 1050, loss is 4.8284725856781 and perplexity is 125.01985762410881
At time: 118.96311545372009 and batch: 1100, loss is 4.806561908721924 and perplexity is 122.3103795557515
At time: 120.07077169418335 and batch: 1150, loss is 4.819535541534424 and perplexity is 123.9075275128834
At time: 121.1795825958252 and batch: 1200, loss is 4.8097450733184814 and perplexity is 122.70033394097267
At time: 122.28727912902832 and batch: 1250, loss is 4.8517386341094975 and perplexity is 127.96267682684415
At time: 123.39574098587036 and batch: 1300, loss is 4.839521741867065 and perplexity is 126.40888119549797
At time: 124.50315499305725 and batch: 1350, loss is 4.805079936981201 and perplexity is 122.12925327481747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.673030598958333 and perplexity of 107.02159097919099
Finished 4 epochs...
Completing Train Step...
At time: 127.96535468101501 and batch: 50, loss is 4.871267261505127 and perplexity is 130.4861722665231
At time: 129.06726002693176 and batch: 100, loss is 4.8829248332977295 and perplexity is 132.01622521100504
At time: 130.17290258407593 and batch: 150, loss is 4.828987903594971 and perplexity is 125.08429919923022
At time: 131.27891612052917 and batch: 200, loss is 4.831180696487427 and perplexity is 125.35888410536255
At time: 132.3848738670349 and batch: 250, loss is 4.837777338027954 and perplexity is 126.18856527368015
At time: 133.49181818962097 and batch: 300, loss is 4.827311677932739 and perplexity is 124.87480531553396
At time: 134.59855937957764 and batch: 350, loss is 4.830286674499511 and perplexity is 125.24686058979634
At time: 135.70442175865173 and batch: 400, loss is 4.857045574188232 and perplexity is 128.64357222257246
At time: 136.81052994728088 and batch: 450, loss is 4.81342776298523 and perplexity is 123.15303425864028
At time: 137.9170458316803 and batch: 500, loss is 4.876810369491577 and perplexity is 131.21147958136842
At time: 139.02391648292542 and batch: 550, loss is 4.847586278915405 and perplexity is 127.4324319854086
At time: 140.12970685958862 and batch: 600, loss is 4.79948148727417 and perplexity is 121.44742915247642
At time: 141.23575568199158 and batch: 650, loss is 4.824900388717651 and perplexity is 124.57405878339472
At time: 142.3423182964325 and batch: 700, loss is 4.840981979370117 and perplexity is 126.59360302058332
At time: 143.44928979873657 and batch: 750, loss is 4.803891706466675 and perplexity is 121.98422175186464
At time: 144.55544066429138 and batch: 800, loss is 4.771080884933472 and perplexity is 118.0467680007442
At time: 145.6615538597107 and batch: 850, loss is 4.742487602233886 and perplexity is 114.7192228185217
At time: 146.76682114601135 and batch: 900, loss is 4.786899518966675 and perplexity is 119.92895418174474
At time: 147.8735373020172 and batch: 950, loss is 4.758688220977783 and perplexity is 116.59288144466476
At time: 148.9797613620758 and batch: 1000, loss is 4.774872741699219 and perplexity is 118.49523415903691
At time: 150.08553886413574 and batch: 1050, loss is 4.720905075073242 and perplexity is 112.26981931309412
At time: 151.221529006958 and batch: 1100, loss is 4.697388172149658 and perplexity is 109.66038404904657
At time: 152.32747650146484 and batch: 1150, loss is 4.712892417907715 and perplexity is 111.37383414560409
At time: 153.43382382392883 and batch: 1200, loss is 4.702550468444824 and perplexity is 110.22794714735971
At time: 154.53996229171753 and batch: 1250, loss is 4.747499341964722 and perplexity is 115.29560884734312
At time: 155.6466863155365 and batch: 1300, loss is 4.740768156051636 and perplexity is 114.52213877507516
At time: 156.75331377983093 and batch: 1350, loss is 4.704340372085571 and perplexity is 110.42542122833761
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.611938883463542 and perplexity of 100.67916568807313
Finished 5 epochs...
Completing Train Step...
At time: 160.18372225761414 and batch: 50, loss is 4.771950979232788 and perplexity is 118.1495245180815
At time: 161.31933450698853 and batch: 100, loss is 4.785858316421509 and perplexity is 119.80414883450933
At time: 162.42627024650574 and batch: 150, loss is 4.7342915439605715 and perplexity is 113.78282003106621
At time: 163.53294920921326 and batch: 200, loss is 4.735457553863525 and perplexity is 113.91556930445184
At time: 164.6506962776184 and batch: 250, loss is 4.743428440093994 and perplexity is 114.82720579590283
At time: 165.757750749588 and batch: 300, loss is 4.734312038421631 and perplexity is 113.78515197253647
At time: 166.86095595359802 and batch: 350, loss is 4.7350621509552 and perplexity is 113.87053566084896
At time: 167.96481323242188 and batch: 400, loss is 4.761801509857178 and perplexity is 116.95643439491485
At time: 169.0681014060974 and batch: 450, loss is 4.716882371902466 and perplexity is 111.81909832114502
At time: 170.17132306098938 and batch: 500, loss is 4.784581527709961 and perplexity is 119.65128185986151
At time: 171.2755308151245 and batch: 550, loss is 4.758886184692383 and perplexity is 116.61596488933827
At time: 172.3787648677826 and batch: 600, loss is 4.7108982563018795 and perplexity is 111.15195802360567
At time: 173.48219394683838 and batch: 650, loss is 4.735016164779663 and perplexity is 113.86529931080825
At time: 174.58579277992249 and batch: 700, loss is 4.755418014526367 and perplexity is 116.21222140926648
At time: 175.68937873840332 and batch: 750, loss is 4.7181158447265625 and perplexity is 111.9571092389993
At time: 176.79327082633972 and batch: 800, loss is 4.686381120681762 and perplexity is 108.4599652135048
At time: 177.8965241909027 and batch: 850, loss is 4.655707578659058 and perplexity is 105.18361935843652
At time: 179.05614495277405 and batch: 900, loss is 4.699093284606934 and perplexity is 109.84752684036891
At time: 180.1591444015503 and batch: 950, loss is 4.673300762176513 and perplexity is 107.05050818263115
At time: 181.2617542743683 and batch: 1000, loss is 4.689816055297851 and perplexity is 108.83315868312468
At time: 182.36496663093567 and batch: 1050, loss is 4.635327730178833 and perplexity is 103.06168888678657
At time: 183.46842050552368 and batch: 1100, loss is 4.611678295135498 and perplexity is 100.65293329069434
At time: 184.5724070072174 and batch: 1150, loss is 4.628491497039795 and perplexity is 102.35953792222939
At time: 185.676176071167 and batch: 1200, loss is 4.616988554000854 and perplexity is 101.18884808582355
At time: 186.78002619743347 and batch: 1250, loss is 4.664245471954346 and perplexity is 106.08551052354373
At time: 187.88392567634583 and batch: 1300, loss is 4.660976305007934 and perplexity is 105.73926555372529
At time: 188.98783206939697 and batch: 1350, loss is 4.623188962936402 and perplexity is 101.81820945628627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5678515625 and perplexity of 96.33691344088702
Finished 6 epochs...
Completing Train Step...
At time: 192.41230273246765 and batch: 50, loss is 4.691823930740356 and perplexity is 109.05190164059135
At time: 193.55279302597046 and batch: 100, loss is 4.706891059875488 and perplexity is 110.70744152191865
At time: 194.65511751174927 and batch: 150, loss is 4.657986488342285 and perplexity is 105.42359666655616
At time: 195.7576892375946 and batch: 200, loss is 4.658962192535401 and perplexity is 105.52650910976388
At time: 196.86076617240906 and batch: 250, loss is 4.666596584320068 and perplexity is 106.33522291507684
At time: 197.9642312526703 and batch: 300, loss is 4.660396823883056 and perplexity is 105.6780093952864
At time: 199.06827759742737 and batch: 350, loss is 4.658446493148804 and perplexity is 105.47210318350344
At time: 200.1716170310974 and batch: 400, loss is 4.684534435272217 and perplexity is 108.25985860207278
At time: 201.2750108242035 and batch: 450, loss is 4.638810939788819 and perplexity is 103.4213002892954
At time: 202.37792563438416 and batch: 500, loss is 4.70975619316101 and perplexity is 111.02508792993012
At time: 203.48116445541382 and batch: 550, loss is 4.6868432426452635 and perplexity is 108.51009852855134
At time: 204.5840106010437 and batch: 600, loss is 4.637356109619141 and perplexity is 103.27094925557573
At time: 205.68756771087646 and batch: 650, loss is 4.661717777252197 and perplexity is 105.8176973581718
At time: 206.79092478752136 and batch: 700, loss is 4.684732608795166 and perplexity is 108.28131496561728
At time: 207.931946516037 and batch: 750, loss is 4.646830158233643 and perplexity is 104.25399259653365
At time: 209.03469610214233 and batch: 800, loss is 4.6165062427520756 and perplexity is 101.14005533373327
At time: 210.1380274295807 and batch: 850, loss is 4.584527149200439 and perplexity is 97.95685721114475
At time: 211.2412371635437 and batch: 900, loss is 4.626132831573487 and perplexity is 102.11839051980817
At time: 212.344633102417 and batch: 950, loss is 4.602942399978637 and perplexity is 99.77746936640622
At time: 213.44765496253967 and batch: 1000, loss is 4.619143152236939 and perplexity is 101.40710444236694
At time: 214.55072355270386 and batch: 1050, loss is 4.56494631767273 and perplexity is 96.05743729133195
At time: 215.652996301651 and batch: 1100, loss is 4.541151990890503 and perplexity is 93.79879325934925
At time: 216.75616884231567 and batch: 1150, loss is 4.5597601413726805 and perplexity is 95.56055605714208
At time: 217.85906672477722 and batch: 1200, loss is 4.546176404953003 and perplexity is 94.27126318356487
At time: 218.96213006973267 and batch: 1250, loss is 4.594935312271118 and perplexity is 98.98173243709662
At time: 220.06602501869202 and batch: 1300, loss is 4.593460807800293 and perplexity is 98.83589097845311
At time: 221.17054748535156 and batch: 1350, loss is 4.554517650604248 and perplexity is 95.06089161169308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.536394856770833 and perplexity of 93.35363948714804
Finished 7 epochs...
Completing Train Step...
At time: 224.7413604259491 and batch: 50, loss is 4.625019989013672 and perplexity is 102.00481203790369
At time: 225.84555077552795 and batch: 100, loss is 4.640421028137207 and perplexity is 103.58795184572894
At time: 226.95042610168457 and batch: 150, loss is 4.59430643081665 and perplexity is 98.91950423036934
At time: 228.05463337898254 and batch: 200, loss is 4.594238634109497 and perplexity is 98.91279804104065
At time: 229.1583468914032 and batch: 250, loss is 4.601946468353272 and perplexity is 99.6781472963702
At time: 230.26236200332642 and batch: 300, loss is 4.598920621871948 and perplexity is 99.37699237915676
At time: 231.36993646621704 and batch: 350, loss is 4.594378604888916 and perplexity is 98.92664391146295
At time: 232.47330617904663 and batch: 400, loss is 4.619340152740478 and perplexity is 101.427083660898
At time: 233.57688975334167 and batch: 450, loss is 4.572611989974976 and perplexity is 96.79661164233255
At time: 234.67990159988403 and batch: 500, loss is 4.646482658386231 and perplexity is 104.21777064394026
At time: 235.81126356124878 and batch: 550, loss is 4.6257462978363035 and perplexity is 102.0789259443717
At time: 236.91439032554626 and batch: 600, loss is 4.574419393539428 and perplexity is 96.97172038165253
At time: 238.01800775527954 and batch: 650, loss is 4.599887218475342 and perplexity is 99.47309628181628
At time: 239.12152314186096 and batch: 700, loss is 4.623726243972778 and perplexity is 101.87292914799498
At time: 240.22525906562805 and batch: 750, loss is 4.586179037094116 and perplexity is 98.1188046803804
At time: 241.33630108833313 and batch: 800, loss is 4.557523622512817 and perplexity is 95.34707189093085
At time: 242.4403576850891 and batch: 850, loss is 4.523474416732788 and perplexity is 92.1552280589518
At time: 243.54301261901855 and batch: 900, loss is 4.563506946563721 and perplexity is 95.9192744489449
At time: 244.64604425430298 and batch: 950, loss is 4.542917633056641 and perplexity is 93.96455465845537
At time: 245.7486674785614 and batch: 1000, loss is 4.558178834915161 and perplexity is 95.40956494583757
At time: 246.85584020614624 and batch: 1050, loss is 4.504799299240112 and perplexity is 90.45018880541923
At time: 247.95931482315063 and batch: 1100, loss is 4.481015605926514 and perplexity is 88.32432985261855
At time: 249.0632197856903 and batch: 1150, loss is 4.501200742721558 and perplexity is 90.12528363431589
At time: 250.1662905216217 and batch: 1200, loss is 4.486161823272705 and perplexity is 88.7800376309039
At time: 251.2693648338318 and batch: 1250, loss is 4.535474538803101 and perplexity is 93.26776397782315
At time: 252.37447500228882 and batch: 1300, loss is 4.534959602355957 and perplexity is 93.21974937010408
At time: 253.47744178771973 and batch: 1350, loss is 4.495832347869873 and perplexity is 89.64275189496578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5131319173177085 and perplexity of 91.20702451616444
Finished 8 epochs...
Completing Train Step...
At time: 256.926953792572 and batch: 50, loss is 4.567888097763062 and perplexity is 96.34043319965943
At time: 258.03147053718567 and batch: 100, loss is 4.582601308822632 and perplexity is 97.7683894778798
At time: 259.1370816230774 and batch: 150, loss is 4.540135717391967 and perplexity is 93.70351645341185
At time: 260.2411572933197 and batch: 200, loss is 4.538990783691406 and perplexity is 93.59629353284382
At time: 261.3459267616272 and batch: 250, loss is 4.546159410476685 and perplexity is 94.26966110642852
At time: 262.4552586078644 and batch: 300, loss is 4.544171667098999 and perplexity is 94.0824633240604
At time: 263.58844923973083 and batch: 350, loss is 4.539736318588257 and perplexity is 93.66609885380653
At time: 264.69318413734436 and batch: 400, loss is 4.563328294754029 and perplexity is 95.90213982759136
At time: 265.7975814342499 and batch: 450, loss is 4.515926208496094 and perplexity is 91.46223990717309
At time: 266.9025766849518 and batch: 500, loss is 4.591124868392944 and perplexity is 98.60528577061264
At time: 268.01225757598877 and batch: 550, loss is 4.572757911682129 and perplexity is 96.81073739975228
At time: 269.1166081428528 and batch: 600, loss is 4.520190095901489 and perplexity is 91.85305720835468
At time: 270.2200982570648 and batch: 650, loss is 4.5466645812988284 and perplexity is 94.31729541935235
At time: 271.3237040042877 and batch: 700, loss is 4.571501426696777 and perplexity is 96.6891725499863
At time: 272.4269235134125 and batch: 750, loss is 4.5332764148712155 and perplexity is 93.06297503194892
At time: 273.5338411331177 and batch: 800, loss is 4.505794954299927 and perplexity is 90.54029084139518
At time: 274.63721203804016 and batch: 850, loss is 4.469714117050171 and perplexity is 87.33175278522985
At time: 275.7412893772125 and batch: 900, loss is 4.508981122970581 and perplexity is 90.82922753559487
At time: 276.8454396724701 and batch: 950, loss is 4.489898672103882 and perplexity is 89.11241584755354
At time: 277.94942331314087 and batch: 1000, loss is 4.50496958732605 and perplexity is 90.46559270645682
At time: 279.05258774757385 and batch: 1050, loss is 4.45248049736023 and perplexity is 85.83960505431219
At time: 280.15568590164185 and batch: 1100, loss is 4.428418111801148 and perplexity is 83.79875175073543
At time: 281.2595901489258 and batch: 1150, loss is 4.449671726226807 and perplexity is 85.59883953543805
At time: 282.36415338516235 and batch: 1200, loss is 4.434168281555176 and perplexity is 84.28199683760022
At time: 283.4678375720978 and batch: 1250, loss is 4.482767906188965 and perplexity is 88.47923628064996
At time: 284.57091331481934 and batch: 1300, loss is 4.484032955169678 and perplexity is 88.59123767701043
At time: 285.6740138530731 and batch: 1350, loss is 4.444910259246826 and perplexity is 85.19223227917932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.495032958984375 and perplexity of 89.57112110967671
Finished 9 epochs...
Completing Train Step...
At time: 289.0946378707886 and batch: 50, loss is 4.517973260879517 and perplexity is 91.64965966695391
At time: 290.2276220321655 and batch: 100, loss is 4.531620597839355 and perplexity is 92.90900727924723
At time: 291.3312256336212 and batch: 150, loss is 4.491836309432983 and perplexity is 89.2852507826223
At time: 292.4635338783264 and batch: 200, loss is 4.491039609909057 and perplexity is 89.21414559432604
At time: 293.5672376155853 and batch: 250, loss is 4.496700954437256 and perplexity is 89.72065000448706
At time: 294.6707775592804 and batch: 300, loss is 4.496701784133911 and perplexity is 89.72072444544116
At time: 295.77424359321594 and batch: 350, loss is 4.491535320281982 and perplexity is 89.2583809347615
At time: 296.8790738582611 and batch: 400, loss is 4.513452873229981 and perplexity is 91.23630264816711
At time: 297.9827356338501 and batch: 450, loss is 4.466138572692871 and perplexity is 87.02005181175274
At time: 299.08660984039307 and batch: 500, loss is 4.5423667621612545 and perplexity is 93.91280657466132
At time: 300.1912131309509 and batch: 550, loss is 4.526059494018555 and perplexity is 92.39376463067084
At time: 301.2954034805298 and batch: 600, loss is 4.472837448120117 and perplexity is 87.60494517514947
At time: 302.39875173568726 and batch: 650, loss is 4.49988787651062 and perplexity is 90.0070388314684
At time: 303.5035219192505 and batch: 700, loss is 4.52516466140747 and perplexity is 92.31112465700447
At time: 304.6078927516937 and batch: 750, loss is 4.485815315246582 and perplexity is 88.74927996450218
At time: 305.71149730682373 and batch: 800, loss is 4.460057945251465 and perplexity is 86.49252078199281
At time: 306.81537795066833 and batch: 850, loss is 4.4223525333404545 and perplexity is 83.2920022651266
At time: 307.91918301582336 and batch: 900, loss is 4.460715322494507 and perplexity is 86.54939768959238
At time: 309.0242660045624 and batch: 950, loss is 4.4430216121673585 and perplexity is 85.03148606270972
At time: 310.12841725349426 and batch: 1000, loss is 4.458356809616089 and perplexity is 86.34551035049134
At time: 311.2331500053406 and batch: 1050, loss is 4.405973720550537 and perplexity is 81.93888959202657
At time: 312.3367431163788 and batch: 1100, loss is 4.381393032073975 and perplexity is 79.94932784670668
At time: 313.44088649749756 and batch: 1150, loss is 4.404425621032715 and perplexity is 81.81213817377751
At time: 314.5449118614197 and batch: 1200, loss is 4.3880860805511475 and perplexity is 80.48622731650704
At time: 315.6492123603821 and batch: 1250, loss is 4.435699586868286 and perplexity is 84.41115717387277
At time: 316.7550103664398 and batch: 1300, loss is 4.439386806488037 and perplexity is 84.72297416431475
At time: 317.8592722415924 and batch: 1350, loss is 4.399416179656982 and perplexity is 81.40332986929332
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.478308919270833 and perplexity of 88.08558681468763
Finished 10 epochs...
Completing Train Step...
At time: 321.2691867351532 and batch: 50, loss is 4.473815546035767 and perplexity is 87.69067330784534
At time: 322.4011414051056 and batch: 100, loss is 4.486396036148071 and perplexity is 88.80083349402693
At time: 323.50450587272644 and batch: 150, loss is 4.449178647994995 and perplexity is 85.55664301494257
At time: 324.60879611968994 and batch: 200, loss is 4.448528890609741 and perplexity is 85.50107001072617
At time: 325.7124423980713 and batch: 250, loss is 4.452404680252076 and perplexity is 85.83309719039869
At time: 326.8171217441559 and batch: 300, loss is 4.454003343582153 and perplexity is 85.97042515672824
At time: 327.91999435424805 and batch: 350, loss is 4.448924770355225 and perplexity is 85.53492485334169
At time: 329.0233631134033 and batch: 400, loss is 4.469368619918823 and perplexity is 87.30158512688676
At time: 330.1270065307617 and batch: 450, loss is 4.422260723114014 and perplexity is 83.28435555856623
At time: 331.23032307624817 and batch: 500, loss is 4.498471593856811 and perplexity is 89.87965365165401
At time: 332.3338813781738 and batch: 550, loss is 4.484120826721192 and perplexity is 88.5990226685503
At time: 333.4377634525299 and batch: 600, loss is 4.430376262664795 and perplexity is 83.96300311083684
At time: 334.5412542819977 and batch: 650, loss is 4.457951421737671 and perplexity is 86.31051402126253
At time: 335.6446988582611 and batch: 700, loss is 4.4842346668243405 and perplexity is 88.60910936455412
At time: 336.74763345718384 and batch: 750, loss is 4.443667335510254 and perplexity is 85.08641060926395
At time: 337.85138988494873 and batch: 800, loss is 4.41909273147583 and perplexity is 83.0209289036015
At time: 338.9551179409027 and batch: 850, loss is 4.380355405807495 and perplexity is 79.86641334871531
At time: 340.05827808380127 and batch: 900, loss is 4.4177790451049805 and perplexity is 82.9119370470384
At time: 341.1615505218506 and batch: 950, loss is 4.401153764724731 and perplexity is 81.54489803748827
At time: 342.2649607658386 and batch: 1000, loss is 4.416794662475586 and perplexity is 82.83036013447507
At time: 343.3690083026886 and batch: 1050, loss is 4.364653549194336 and perplexity is 78.62215651332846
At time: 344.4745032787323 and batch: 1100, loss is 4.339667510986328 and perplexity is 76.68203916369869
At time: 345.57839488983154 and batch: 1150, loss is 4.363993606567383 and perplexity is 78.57028751798536
At time: 346.68216347694397 and batch: 1200, loss is 4.346355972290039 and perplexity is 77.19664305100714
At time: 347.81403040885925 and batch: 1250, loss is 4.393436250686645 and perplexity is 80.9179963150915
At time: 348.9167001247406 and batch: 1300, loss is 4.399069719314575 and perplexity is 81.37513172880448
At time: 350.0206699371338 and batch: 1350, loss is 4.358463010787964 and perplexity is 78.1369464391888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.467626953125 and perplexity of 87.14966718863975
Finished 11 epochs...
Completing Train Step...
At time: 353.4466333389282 and batch: 50, loss is 4.436624040603638 and perplexity is 84.48922746405322
At time: 354.54783868789673 and batch: 100, loss is 4.4460860538482665 and perplexity is 85.29245975789506
At time: 355.649475812912 and batch: 150, loss is 4.410825920104981 and perplexity is 82.33743957567368
At time: 356.7508342266083 and batch: 200, loss is 4.410807323455811 and perplexity is 82.33590838943385
At time: 357.85261273384094 and batch: 250, loss is 4.412456617355347 and perplexity is 82.47181654629256
At time: 358.9539041519165 and batch: 300, loss is 4.415534706115722 and perplexity is 82.72606321401551
At time: 360.0552308559418 and batch: 350, loss is 4.410966482162475 and perplexity is 82.3490139090263
At time: 361.1566812992096 and batch: 400, loss is 4.430270128250122 and perplexity is 83.95409221953197
At time: 362.2579560279846 and batch: 450, loss is 4.382634925842285 and perplexity is 80.0486780971996
At time: 363.3587739467621 and batch: 500, loss is 4.4588298320770265 and perplexity is 86.38636337772623
At time: 364.459951877594 and batch: 550, loss is 4.4467448902130124 and perplexity is 85.3486720473391
At time: 365.5611035823822 and batch: 600, loss is 4.392595071792602 and perplexity is 80.84995842447366
At time: 366.6631190776825 and batch: 650, loss is 4.419522924423218 and perplexity is 83.05665160497757
At time: 367.7651832103729 and batch: 700, loss is 4.446753158569336 and perplexity is 85.34937774348876
At time: 368.86752438545227 and batch: 750, loss is 4.4059170055389405 and perplexity is 81.93424255873268
At time: 369.9684474468231 and batch: 800, loss is 4.382370576858521 and perplexity is 80.02752010716273
At time: 371.06936860084534 and batch: 850, loss is 4.343218469619751 and perplexity is 76.95481793914013
At time: 372.17000102996826 and batch: 900, loss is 4.378971929550171 and perplexity is 79.75599645927377
At time: 373.27166628837585 and batch: 950, loss is 4.363638715744019 and perplexity is 78.5424085912364
At time: 374.37246584892273 and batch: 1000, loss is 4.3793918418884275 and perplexity is 79.78949401876402
At time: 375.4730567932129 and batch: 1050, loss is 4.327483882904053 and perplexity is 75.75344204567914
At time: 376.6029591560364 and batch: 1100, loss is 4.302376880645752 and perplexity is 73.87517766364091
At time: 377.70314168930054 and batch: 1150, loss is 4.327289714813232 and perplexity is 75.73873457237124
At time: 378.80516028404236 and batch: 1200, loss is 4.3084742450714115 and perplexity is 74.32699759946118
At time: 379.90675711631775 and batch: 1250, loss is 4.355171880722046 and perplexity is 77.8802102932654
At time: 381.00841999053955 and batch: 1300, loss is 4.362485189437866 and perplexity is 78.4518600918563
At time: 382.1093945503235 and batch: 1350, loss is 4.321761922836304 and perplexity is 75.32122162855336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.45424072265625 and perplexity of 85.99083515900954
Finished 12 epochs...
Completing Train Step...
At time: 385.51173186302185 and batch: 50, loss is 4.3994018173217775 and perplexity is 81.40216073577872
At time: 386.61235666275024 and batch: 100, loss is 4.408721046447754 and perplexity is 82.16431193792944
At time: 387.7136859893799 and batch: 150, loss is 4.376500263214111 and perplexity is 79.55910966718847
At time: 388.8152058124542 and batch: 200, loss is 4.376489286422729 and perplexity is 79.55823636823216
At time: 389.9160780906677 and batch: 250, loss is 4.376392021179199 and perplexity is 79.55049849331618
At time: 391.01677083969116 and batch: 300, loss is 4.380675582885742 and perplexity is 79.8919888377156
At time: 392.11715054512024 and batch: 350, loss is 4.375991382598877 and perplexity is 79.51863387805925
At time: 393.2176492214203 and batch: 400, loss is 4.3949299335479735 and perplexity is 81.03895245192601
At time: 394.3187448978424 and batch: 450, loss is 4.346537609100341 and perplexity is 77.21066607652727
At time: 395.42045545578003 and batch: 500, loss is 4.42295199394226 and perplexity is 83.34194750753694
At time: 396.52419662475586 and batch: 550, loss is 4.4125044059753415 and perplexity is 82.47575785476785
At time: 397.6245844364166 and batch: 600, loss is 4.3581616306304936 and perplexity is 78.11340106219964
At time: 398.72493982315063 and batch: 650, loss is 4.384283504486084 and perplexity is 80.18075347678706
At time: 399.8252577781677 and batch: 700, loss is 4.413307342529297 and perplexity is 82.54200724903549
At time: 400.9262754917145 and batch: 750, loss is 4.371601114273071 and perplexity is 79.17029095738847
At time: 402.02985548973083 and batch: 800, loss is 4.348766670227051 and perplexity is 77.38296533229028
At time: 403.13039994239807 and batch: 850, loss is 4.309445686340332 and perplexity is 74.39923699480819
At time: 404.2599058151245 and batch: 900, loss is 4.3443092918396 and perplexity is 77.03880776512848
At time: 405.3602945804596 and batch: 950, loss is 4.329851579666138 and perplexity is 75.93301572925141
At time: 406.46190905570984 and batch: 1000, loss is 4.345640478134155 and perplexity is 77.14142905905007
At time: 407.5627052783966 and batch: 1050, loss is 4.293781852722168 and perplexity is 73.24293939374024
At time: 408.66367840766907 and batch: 1100, loss is 4.269054908752441 and perplexity is 71.4540730787961
At time: 409.7648859024048 and batch: 1150, loss is 4.294099731445312 and perplexity is 73.26622546667159
At time: 410.86600637435913 and batch: 1200, loss is 4.274253907203675 and perplexity is 71.82653005674678
At time: 411.967077255249 and batch: 1250, loss is 4.320781917572021 and perplexity is 75.24744259267182
At time: 413.07902002334595 and batch: 1300, loss is 4.329018077850342 and perplexity is 75.86975179172819
At time: 414.1946234703064 and batch: 1350, loss is 4.288381776809692 and perplexity is 72.8484879533656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.443782958984375 and perplexity of 85.09624916443211
Finished 13 epochs...
Completing Train Step...
At time: 417.60130429267883 and batch: 50, loss is 4.366501684188843 and perplexity is 78.76759522591475
At time: 418.73099279403687 and batch: 100, loss is 4.374968643188477 and perplexity is 79.43734861123923
At time: 419.8323881626129 and batch: 150, loss is 4.345163459777832 and perplexity is 77.10463995659214
At time: 420.9340169429779 and batch: 200, loss is 4.345003080368042 and perplexity is 77.09227495151644
At time: 422.03587675094604 and batch: 250, loss is 4.343678131103515 and perplexity is 76.99019923602356
At time: 423.13798356056213 and batch: 300, loss is 4.348860406875611 and perplexity is 77.39021929209177
At time: 424.2397174835205 and batch: 350, loss is 4.344128818511963 and perplexity is 77.02490556965941
At time: 425.3408679962158 and batch: 400, loss is 4.363041496276855 and perplexity is 78.49551553994313
At time: 426.4424784183502 and batch: 450, loss is 4.3132571029663085 and perplexity is 74.68334456587675
At time: 427.54379630088806 and batch: 500, loss is 4.390261926651001 and perplexity is 80.66154362178838
At time: 428.6459586620331 and batch: 550, loss is 4.381233968734741 and perplexity is 79.9366118510011
At time: 429.74806451797485 and batch: 600, loss is 4.32604115486145 and perplexity is 75.64422923165438
At time: 430.84996581077576 and batch: 650, loss is 4.351887893676758 and perplexity is 77.62487218457454
At time: 431.97953963279724 and batch: 700, loss is 4.382054710388184 and perplexity is 80.00224608867431
At time: 433.0812301635742 and batch: 750, loss is 4.340010356903076 and perplexity is 76.7083337949598
At time: 434.1821894645691 and batch: 800, loss is 4.317732315063477 and perplexity is 75.018317351009
At time: 435.2835249900818 and batch: 850, loss is 4.279416055679321 and perplexity is 72.1982679269315
At time: 436.38546895980835 and batch: 900, loss is 4.312498035430909 and perplexity is 74.6266763737951
At time: 437.48678374290466 and batch: 950, loss is 4.298864583969117 and perplexity is 73.61616126014741
At time: 438.5879182815552 and batch: 1000, loss is 4.314737405776977 and perplexity is 74.79398039781127
At time: 439.690105676651 and batch: 1050, loss is 4.2625710105896 and perplexity is 70.99227090265552
At time: 440.79172539711 and batch: 1100, loss is 4.2385409116745 and perplexity is 69.30665349905098
At time: 441.8929102420807 and batch: 1150, loss is 4.263704862594604 and perplexity is 71.07281128316559
At time: 442.9939024448395 and batch: 1200, loss is 4.242645788192749 and perplexity is 69.59173346228117
At time: 444.0957787036896 and batch: 1250, loss is 4.288731336593628 and perplexity is 72.87395730634603
At time: 445.1977770328522 and batch: 1300, loss is 4.298431797027588 and perplexity is 73.58430804019454
At time: 446.29901146888733 and batch: 1350, loss is 4.2577257823944095 and perplexity is 70.64912912146019
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.4358935546875 and perplexity of 84.42753180997197
Finished 14 epochs...
Completing Train Step...
At time: 449.68684935569763 and batch: 50, loss is 4.337435607910156 and perplexity is 76.5110831342127
At time: 450.81741881370544 and batch: 100, loss is 4.344230127334595 and perplexity is 77.03270926744106
At time: 451.92021107673645 and batch: 150, loss is 4.316964282989502 and perplexity is 74.96072299713441
At time: 453.02191710472107 and batch: 200, loss is 4.31599570274353 and perplexity is 74.88815267238061
At time: 454.1267490386963 and batch: 250, loss is 4.313323087692261 and perplexity is 74.68827268848977
At time: 455.22891330718994 and batch: 300, loss is 4.319513511657715 and perplexity is 75.1520587969244
At time: 456.3313434123993 and batch: 350, loss is 4.314791097640991 and perplexity is 74.7979963338464
At time: 457.4333517551422 and batch: 400, loss is 4.333327894210815 and perplexity is 76.1974421246202
At time: 458.5363631248474 and batch: 450, loss is 4.282702894210815 and perplexity is 72.43596239353617
At time: 459.63878417015076 and batch: 500, loss is 4.360115480422974 and perplexity is 78.26617211189617
At time: 460.78637290000916 and batch: 550, loss is 4.351968431472779 and perplexity is 77.63112417245397
At time: 461.8886091709137 and batch: 600, loss is 4.296939392089843 and perplexity is 73.47457236093723
At time: 462.990886926651 and batch: 650, loss is 4.3219767093658445 and perplexity is 75.33740134987862
At time: 464.093302488327 and batch: 700, loss is 4.353156051635742 and perplexity is 77.72337522955952
At time: 465.19590306282043 and batch: 750, loss is 4.3110560703277585 and perplexity is 74.51914485767908
At time: 466.29868626594543 and batch: 800, loss is 4.288878889083862 and perplexity is 72.88471083355515
At time: 467.40093994140625 and batch: 850, loss is 4.25100567817688 and perplexity is 70.17595129376076
At time: 468.50303626060486 and batch: 900, loss is 4.283009748458863 and perplexity is 72.45819308692495
At time: 469.60524463653564 and batch: 950, loss is 4.270524911880493 and perplexity is 71.5591880304592
At time: 470.7074947357178 and batch: 1000, loss is 4.2863924598693846 and perplexity is 72.703713271312
At time: 471.8105013370514 and batch: 1050, loss is 4.23370023727417 and perplexity is 68.97197324826902
At time: 472.91318225860596 and batch: 1100, loss is 4.210224266052246 and perplexity is 67.37164728937681
At time: 474.0153489112854 and batch: 1150, loss is 4.235503387451172 and perplexity is 69.09645226749552
At time: 475.1177704334259 and batch: 1200, loss is 4.213671112060547 and perplexity is 67.60426765589114
At time: 476.220383644104 and batch: 1250, loss is 4.259740648269653 and perplexity is 70.79162114379328
At time: 477.32295751571655 and batch: 1300, loss is 4.2699082088470455 and perplexity is 71.51507086712223
At time: 478.42562675476074 and batch: 1350, loss is 4.229199438095093 and perplexity is 68.66224179009755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.429551595052083 and perplexity of 83.89379008429853
Finished 15 epochs...
Completing Train Step...
At time: 481.8383116722107 and batch: 50, loss is 4.309251489639283 and perplexity is 74.38479031121774
At time: 482.94216871261597 and batch: 100, loss is 4.316243619918823 and perplexity is 74.90672103326675
At time: 484.0459740161896 and batch: 150, loss is 4.290849599838257 and perplexity is 73.02848714125169
At time: 485.149924993515 and batch: 200, loss is 4.288912782669067 and perplexity is 72.88718119957649
At time: 486.25456261634827 and batch: 250, loss is 4.285389895439148 and perplexity is 72.63085964077167
At time: 487.3593590259552 and batch: 300, loss is 4.292384986877441 and perplexity is 73.1407002571371
At time: 488.5057406425476 and batch: 350, loss is 4.2881855773925786 and perplexity is 72.83419652452238
At time: 489.6093680858612 and batch: 400, loss is 4.306341524124146 and perplexity is 74.16864777275079
At time: 490.71363711357117 and batch: 450, loss is 4.255496678352356 and perplexity is 70.49182025621936
At time: 491.8179988861084 and batch: 500, loss is 4.332252502441406 and perplexity is 76.1155440666508
At time: 492.9224078655243 and batch: 550, loss is 4.325265102386474 and perplexity is 75.58554811310027
At time: 494.02712392807007 and batch: 600, loss is 4.270160541534424 and perplexity is 71.53311873407984
At time: 495.12944865226746 and batch: 650, loss is 4.29485785484314 and perplexity is 73.32179136671145
At time: 496.23105549812317 and batch: 700, loss is 4.3264128112792966 and perplexity is 75.67234811988035
At time: 497.333621263504 and batch: 750, loss is 4.284093208312989 and perplexity is 72.53674117440296
At time: 498.43544268608093 and batch: 800, loss is 4.262475252151489 and perplexity is 70.98547311915372
At time: 499.5375831127167 and batch: 850, loss is 4.224557294845581 and perplexity is 68.34424050270378
At time: 500.63992381095886 and batch: 900, loss is 4.25601173877716 and perplexity is 70.52813715500157
At time: 501.7421579360962 and batch: 950, loss is 4.243411207199097 and perplexity is 69.64502068868426
At time: 502.84349966049194 and batch: 1000, loss is 4.260198173522949 and perplexity is 70.82401750870072
At time: 503.94526076316833 and batch: 1050, loss is 4.206658744812012 and perplexity is 67.13185998736964
At time: 505.04689359664917 and batch: 1100, loss is 4.1842735528945925 and perplexity is 65.64579539302039
At time: 506.14850521087646 and batch: 1150, loss is 4.208992280960083 and perplexity is 67.28869753120622
At time: 507.25081872940063 and batch: 1200, loss is 4.186041336059571 and perplexity is 65.7619455588737
At time: 508.3522915840149 and batch: 1250, loss is 4.232448444366455 and perplexity is 68.88568863782469
At time: 509.4540102481842 and batch: 1300, loss is 4.243730907440185 and perplexity is 69.66728977811599
At time: 510.5559632778168 and batch: 1350, loss is 4.203406419754028 and perplexity is 66.91388001994113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.424976806640625 and perplexity of 83.51087030195286
Finished 16 epochs...
Completing Train Step...
At time: 513.9631311893463 and batch: 50, loss is 4.282554588317871 and perplexity is 72.42522051001413
At time: 515.0649952888489 and batch: 100, loss is 4.289944114685059 and perplexity is 72.96239085950172
At time: 516.1942193508148 and batch: 150, loss is 4.266763687133789 and perplexity is 71.29054337475392
At time: 517.2966642379761 and batch: 200, loss is 4.26349440574646 and perplexity is 71.05785509718527
At time: 518.3991456031799 and batch: 250, loss is 4.259569625854493 and perplexity is 70.77951522499339
At time: 519.5012905597687 and batch: 300, loss is 4.26704400062561 and perplexity is 71.31052987701337
At time: 520.6031973361969 and batch: 350, loss is 4.263260498046875 and perplexity is 71.041236061498
At time: 521.7047305107117 and batch: 400, loss is 4.281291933059692 and perplexity is 72.33383013392381
At time: 522.8059232234955 and batch: 450, loss is 4.229586977958679 and perplexity is 68.68885630267357
At time: 523.9069540500641 and batch: 500, loss is 4.3061863231658934 and perplexity is 74.15713762076061
At time: 525.0082361698151 and batch: 550, loss is 4.300744876861573 and perplexity is 73.75471142155627
At time: 526.1100559234619 and batch: 600, loss is 4.2453450059890745 and perplexity is 69.77983045088654
At time: 527.2129340171814 and batch: 650, loss is 4.2692288970947265 and perplexity is 71.46650633611017
At time: 528.317946434021 and batch: 700, loss is 4.3018926334381105 and perplexity is 73.83941247543845
At time: 529.4198722839355 and batch: 750, loss is 4.259179487228393 and perplexity is 70.75190678807655
At time: 530.5216953754425 and batch: 800, loss is 4.237453889846802 and perplexity is 69.23135658600118
At time: 531.6233258247375 and batch: 850, loss is 4.200270700454712 and perplexity is 66.70438550462649
At time: 532.724974155426 and batch: 900, loss is 4.230452270507812 and perplexity is 68.74831798040405
At time: 533.8275134563446 and batch: 950, loss is 4.2196159839630125 and perplexity is 68.00736335615004
At time: 534.929497718811 and batch: 1000, loss is 4.235669078826905 and perplexity is 69.10790190225664
At time: 536.0318949222565 and batch: 1050, loss is 4.181521940231323 and perplexity is 65.46541187772159
At time: 537.1342601776123 and batch: 1100, loss is 4.159606528282166 and perplexity is 64.04631722700086
At time: 538.2359781265259 and batch: 1150, loss is 4.184573817253113 and perplexity is 65.66550944522913
At time: 539.3374552726746 and batch: 1200, loss is 4.16055808544159 and perplexity is 64.10728996361428
At time: 540.439534664154 and batch: 1250, loss is 4.207497820854187 and perplexity is 67.18821236140896
At time: 541.5420587062836 and batch: 1300, loss is 4.218964710235595 and perplexity is 67.9630863669102
At time: 542.6439778804779 and batch: 1350, loss is 4.178924942016602 and perplexity is 65.29561889141962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.423776041666667 and perplexity of 83.41065355437097
Finished 17 epochs...
Completing Train Step...
At time: 546.0290668010712 and batch: 50, loss is 4.259055137634277 and perplexity is 70.7431093641739
At time: 547.1592092514038 and batch: 100, loss is 4.266498327255249 and perplexity is 71.27162823459359
At time: 548.2603816986084 and batch: 150, loss is 4.244235162734985 and perplexity is 69.70242873661932
At time: 549.3634331226349 and batch: 200, loss is 4.23957332611084 and perplexity is 69.37824363764523
At time: 550.4643166065216 and batch: 250, loss is 4.235602011680603 and perplexity is 69.10326718790945
At time: 551.5652265548706 and batch: 300, loss is 4.243723802566528 and perplexity is 69.66679480258243
At time: 552.6654675006866 and batch: 350, loss is 4.240111899375916 and perplexity is 69.41561896861998
At time: 553.7666127681732 and batch: 400, loss is 4.257495346069336 and perplexity is 70.6328508713979
At time: 554.8679151535034 and batch: 450, loss is 4.205435199737549 and perplexity is 67.04977136055102
At time: 555.9690933227539 and batch: 500, loss is 4.2818600463867185 and perplexity is 72.37493562199998
At time: 557.0722074508667 and batch: 550, loss is 4.277503728866577 and perplexity is 72.06033317354037
At time: 558.1733329296112 and batch: 600, loss is 4.22218955039978 and perplexity is 68.18261023195011
At time: 559.2751388549805 and batch: 650, loss is 4.244875998497009 and perplexity is 69.74711086107617
At time: 560.375937461853 and batch: 700, loss is 4.278718776702881 and perplexity is 72.1479431398177
At time: 561.4777467250824 and batch: 750, loss is 4.235668215751648 and perplexity is 69.10784225696221
At time: 562.5797581672668 and batch: 800, loss is 4.2135868692398075 and perplexity is 67.5985727215718
At time: 563.6813414096832 and batch: 850, loss is 4.177392573356628 and perplexity is 65.1956385543285
At time: 564.785769701004 and batch: 900, loss is 4.206549696922302 and perplexity is 67.12453979883851
At time: 565.8871829509735 and batch: 950, loss is 4.195945100784302 and perplexity is 66.41647218447837
At time: 566.9884123802185 and batch: 1000, loss is 4.212782921791077 and perplexity is 67.54424886118488
At time: 568.0897214412689 and batch: 1050, loss is 4.158209686279297 and perplexity is 63.95691709443545
At time: 569.1910789012909 and batch: 1100, loss is 4.136624484062195 and perplexity is 62.59118691328412
At time: 570.2925181388855 and batch: 1150, loss is 4.161649327278138 and perplexity is 64.177284704099
At time: 571.3940751552582 and batch: 1200, loss is 4.136781640052796 and perplexity is 62.601024266245574
At time: 572.5241038799286 and batch: 1250, loss is 4.183789868354797 and perplexity is 65.6140512143893
At time: 573.6249656677246 and batch: 1300, loss is 4.195686068534851 and perplexity is 66.39927040429191
At time: 574.726265668869 and batch: 1350, loss is 4.156010365486145 and perplexity is 63.81640988365513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.419295247395834 and perplexity of 83.03774366596902
Finished 18 epochs...
Completing Train Step...
At time: 578.0981531143188 and batch: 50, loss is 4.236160793304443 and perplexity is 69.14189161406615
At time: 579.2240326404572 and batch: 100, loss is 4.243670310974121 and perplexity is 69.66306831445932
At time: 580.3232474327087 and batch: 150, loss is 4.223087253570557 and perplexity is 68.2438454587635
At time: 581.4226181507111 and batch: 200, loss is 4.217482714653015 and perplexity is 67.86243997031443
At time: 582.5222091674805 and batch: 250, loss is 4.21320191860199 and perplexity is 67.57255561585906
At time: 583.621616601944 and batch: 300, loss is 4.221421117782593 and perplexity is 68.13023661569758
At time: 584.721596956253 and batch: 350, loss is 4.218597040176392 and perplexity is 67.93810296802735
At time: 585.8205645084381 and batch: 400, loss is 4.235462217330933 and perplexity is 69.09360761680527
At time: 586.9207701683044 and batch: 450, loss is 4.183297395706177 and perplexity is 65.58174604416035
At time: 588.0205302238464 and batch: 500, loss is 4.2590478324890135 and perplexity is 70.74259257737118
At time: 589.1202845573425 and batch: 550, loss is 4.255820608139038 and perplexity is 70.51465835528838
At time: 590.2196800708771 and batch: 600, loss is 4.200630989074707 and perplexity is 66.72842266552533
At time: 591.3198175430298 and batch: 650, loss is 4.2223388290405275 and perplexity is 68.19278919906043
At time: 592.4194257259369 and batch: 700, loss is 4.25713632106781 and perplexity is 70.60749646371146
At time: 593.5191583633423 and batch: 750, loss is 4.213823790550232 and perplexity is 67.61459016136531
At time: 594.6178584098816 and batch: 800, loss is 4.191205697059631 and perplexity is 66.10244245347589
At time: 595.7174594402313 and batch: 850, loss is 4.155832147598266 and perplexity is 63.805037671269616
At time: 596.8177573680878 and batch: 900, loss is 4.184380269050598 and perplexity is 65.6528012337742
At time: 597.9177289009094 and batch: 950, loss is 4.174751620292664 and perplexity is 65.02368709074517
At time: 599.0174417495728 and batch: 1000, loss is 4.191282176971436 and perplexity is 66.10749815577216
At time: 600.1441104412079 and batch: 1050, loss is 4.1362855434417725 and perplexity is 62.56997581241365
At time: 601.2437760829926 and batch: 1100, loss is 4.115468444824219 and perplexity is 61.28091426715474
At time: 602.3437058925629 and batch: 1150, loss is 4.140392022132874 and perplexity is 62.82744637165862
At time: 603.443526506424 and batch: 1200, loss is 4.1147305154800415 and perplexity is 61.23570996312149
At time: 604.5437068939209 and batch: 1250, loss is 4.161440315246582 and perplexity is 64.16387228117101
At time: 605.6435766220093 and batch: 1300, loss is 4.174100127220154 and perplexity is 64.98133840549188
At time: 606.7444598674774 and batch: 1350, loss is 4.134209327697754 and perplexity is 62.44020180956074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.418094889322917 and perplexity of 82.9381284389347
Finished 19 epochs...
Completing Train Step...
At time: 610.1600036621094 and batch: 50, loss is 4.2146071434021 and perplexity is 67.6675769943799
At time: 611.2597665786743 and batch: 100, loss is 4.222792720794677 and perplexity is 68.2237483692949
At time: 612.359522819519 and batch: 150, loss is 4.202426872253418 and perplexity is 66.8483667879112
At time: 613.4591488838196 and batch: 200, loss is 4.196840834617615 and perplexity is 66.47599031792673
At time: 614.5581753253937 and batch: 250, loss is 4.192501769065857 and perplexity is 66.18817152220538
At time: 615.6575312614441 and batch: 300, loss is 4.200879325866699 and perplexity is 66.74499584572483
At time: 616.7579381465912 and batch: 350, loss is 4.198589234352112 and perplexity is 66.5923185862721
At time: 617.8571393489838 and batch: 400, loss is 4.2146108436584475 and perplexity is 67.66782738222444
At time: 618.9571723937988 and batch: 450, loss is 4.162475366592407 and perplexity is 64.23031956577236
At time: 620.056492805481 and batch: 500, loss is 4.237327251434326 and perplexity is 69.22258979202775
At time: 621.1563537120819 and batch: 550, loss is 4.2354535961151125 and perplexity is 69.09301194846991
At time: 622.2551310062408 and batch: 600, loss is 4.180295882225036 and perplexity is 65.38519666965149
At time: 623.354683637619 and batch: 650, loss is 4.201395688056945 and perplexity is 66.7794693376056
At time: 624.453958272934 and batch: 700, loss is 4.236539344787598 and perplexity is 69.16807033436886
At time: 625.5536823272705 and batch: 750, loss is 4.193322386741638 and perplexity is 66.24250899778127
At time: 626.6538288593292 and batch: 800, loss is 4.170389957427979 and perplexity is 64.74069329983271
At time: 627.7802910804749 and batch: 850, loss is 4.135060482025146 and perplexity is 62.493370681782146
At time: 628.8789536952972 and batch: 900, loss is 4.163608903884888 and perplexity is 64.30316830889133
At time: 629.9776692390442 and batch: 950, loss is 4.155081706047058 and perplexity is 63.757173681634285
At time: 631.0767385959625 and batch: 1000, loss is 4.170852389335632 and perplexity is 64.77063838538604
At time: 632.175763130188 and batch: 1050, loss is 4.115657377243042 and perplexity is 61.29249331230896
At time: 633.2757534980774 and batch: 1100, loss is 4.095252060890198 and perplexity is 60.05447463417626
At time: 634.376083612442 and batch: 1150, loss is 4.120381836891174 and perplexity is 61.58275234233969
At time: 635.4773938655853 and batch: 1200, loss is 4.0937814092636104 and perplexity is 59.966220334942484
At time: 636.5958688259125 and batch: 1250, loss is 4.140527491569519 and perplexity is 62.835958146954134
At time: 637.6984758377075 and batch: 1300, loss is 4.153585710525513 and perplexity is 63.66186454413677
At time: 638.8012690544128 and batch: 1350, loss is 4.114070386886596 and perplexity is 61.19529985943483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.417984212239583 and perplexity of 82.92894959673504
Finished 20 epochs...
Completing Train Step...
At time: 642.3733968734741 and batch: 50, loss is 4.194317293167114 and perplexity is 66.30844689120077
At time: 643.4735152721405 and batch: 100, loss is 4.20266863822937 and perplexity is 66.86453040237576
At time: 644.5729336738586 and batch: 150, loss is 4.183306140899658 and perplexity is 65.58231957172615
At time: 645.6731338500977 and batch: 200, loss is 4.176742396354675 and perplexity is 65.15326362660734
At time: 646.7743582725525 and batch: 250, loss is 4.1725708103179935 and perplexity is 64.88203729712896
At time: 647.8780493736267 and batch: 300, loss is 4.180913515090943 and perplexity is 65.42559318988354
At time: 648.9822731018066 and batch: 350, loss is 4.179730467796325 and perplexity is 65.34823738567124
At time: 650.0860407352448 and batch: 400, loss is 4.19547125339508 and perplexity is 66.3850083676449
At time: 651.18918800354 and batch: 450, loss is 4.142770037651062 and perplexity is 62.977028798274276
At time: 652.2933311462402 and batch: 500, loss is 4.217762680053711 and perplexity is 67.88144176531134
At time: 653.3959500789642 and batch: 550, loss is 4.216072311401367 and perplexity is 67.76679402984345
At time: 654.5005915164948 and batch: 600, loss is 4.161152534484863 and perplexity is 64.14540980983051
At time: 655.6056518554688 and batch: 650, loss is 4.181563024520874 and perplexity is 65.46810153290964
At time: 656.7425179481506 and batch: 700, loss is 4.217306652069092 and perplexity is 67.85049298552126
At time: 657.8470039367676 and batch: 750, loss is 4.173960795402527 and perplexity is 64.97228506822366
At time: 658.9519703388214 and batch: 800, loss is 4.1507974004745485 and perplexity is 63.484602772600844
At time: 660.0579009056091 and batch: 850, loss is 4.115567603111267 and perplexity is 61.28699107892035
At time: 661.1636936664581 and batch: 900, loss is 4.144406352043152 and perplexity is 63.08016337415123
At time: 662.2693960666656 and batch: 950, loss is 4.13697271823883 and perplexity is 62.6129870992881
At time: 663.3747553825378 and batch: 1000, loss is 4.152303562164307 and perplexity is 63.58029289349396
At time: 664.4799218177795 and batch: 1050, loss is 4.096549978256226 and perplexity is 60.13247098517153
At time: 665.584216594696 and batch: 1100, loss is 4.0767542552948 and perplexity is 58.953809962072576
At time: 666.6894834041595 and batch: 1150, loss is 4.101584029197693 and perplexity is 60.43594411607131
At time: 667.7957887649536 and batch: 1200, loss is 4.0751340866088865 and perplexity is 58.858372178787306
At time: 668.9015901088715 and batch: 1250, loss is 4.120861988067627 and perplexity is 61.612328473264895
At time: 670.0074889659882 and batch: 1300, loss is 4.134408864974976 and perplexity is 62.45266220053392
At time: 671.1139328479767 and batch: 1350, loss is 4.094771256446839 and perplexity is 60.02560711630007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.41732177734375 and perplexity of 82.87403275807073
Finished 21 epochs...
Completing Train Step...
At time: 674.5209698677063 and batch: 50, loss is 4.175259642601013 and perplexity is 65.05672896665276
At time: 675.6575183868408 and batch: 100, loss is 4.182679319381714 and perplexity is 65.54122404374809
At time: 676.7646491527557 and batch: 150, loss is 4.165097713470459 and perplexity is 64.39897478335429
At time: 677.8711929321289 and batch: 200, loss is 4.157942471504211 and perplexity is 63.939829144396924
At time: 678.9770805835724 and batch: 250, loss is 4.154059228897094 and perplexity is 63.692016744814644
At time: 680.0829482078552 and batch: 300, loss is 4.162154741287232 and perplexity is 64.20972900106453
At time: 681.1904423236847 and batch: 350, loss is 4.161886019706726 and perplexity is 64.19247677932948
At time: 682.2970037460327 and batch: 400, loss is 4.177539892196656 and perplexity is 65.20524380767519
At time: 683.4035482406616 and batch: 450, loss is 4.12372428894043 and perplexity is 61.78893412350869
At time: 684.5395359992981 and batch: 500, loss is 4.198677415847778 and perplexity is 66.59819105544268
At time: 685.6465148925781 and batch: 550, loss is 4.197996468544006 and perplexity is 66.55285663373523
At time: 686.753027677536 and batch: 600, loss is 4.143084454536438 and perplexity is 62.99683295273636
At time: 687.859087228775 and batch: 650, loss is 4.162277989387512 and perplexity is 64.21764321587936
At time: 688.9670124053955 and batch: 700, loss is 4.1986414289474485 and perplexity is 66.59579443610272
At time: 690.0735259056091 and batch: 750, loss is 4.155982713699341 and perplexity is 63.81464527029194
At time: 691.1800262928009 and batch: 800, loss is 4.132532596588135 and perplexity is 62.33559410470037
At time: 692.2863926887512 and batch: 850, loss is 4.097546520233155 and perplexity is 60.1924253852612
At time: 693.3926780223846 and batch: 900, loss is 4.125598459243775 and perplexity is 61.90484569400149
At time: 694.4991381168365 and batch: 950, loss is 4.11858561038971 and perplexity is 61.47223505730207
At time: 695.6060855388641 and batch: 1000, loss is 4.1339246368408205 and perplexity is 62.42242818511473
At time: 696.7141807079315 and batch: 1050, loss is 4.078058953285217 and perplexity is 59.03077707796025
At time: 697.8200845718384 and batch: 1100, loss is 4.059162321090699 and perplexity is 57.92576755606843
At time: 698.9267778396606 and batch: 1150, loss is 4.083837676048279 and perplexity is 59.37288710064534
At time: 700.0333735942841 and batch: 1200, loss is 4.056361966133117 and perplexity is 57.76378176044156
At time: 701.1398258209229 and batch: 1250, loss is 4.1019567775726316 and perplexity is 60.45847571507603
At time: 702.2463476657867 and batch: 1300, loss is 4.116251544952393 and perplexity is 61.32892215400973
At time: 703.360098361969 and batch: 1350, loss is 4.076638193130493 and perplexity is 58.946968052345355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.4167919921875 and perplexity of 82.83013895384657
Finished 22 epochs...
Completing Train Step...
At time: 706.7655255794525 and batch: 50, loss is 4.157304821014404 and perplexity is 63.89907087717037
At time: 707.9036667346954 and batch: 100, loss is 4.164062705039978 and perplexity is 64.33235578309971
At time: 709.0112986564636 and batch: 150, loss is 4.147974967956543 and perplexity is 63.30567439076492
At time: 710.120566368103 and batch: 200, loss is 4.14014006614685 and perplexity is 62.811618614491536
At time: 711.2281377315521 and batch: 250, loss is 4.136316137313843 and perplexity is 62.57189009953168
At time: 712.3636083602905 and batch: 300, loss is 4.144793100357056 and perplexity is 63.104564239169534
At time: 713.4692118167877 and batch: 350, loss is 4.1447657871246335 and perplexity is 63.102840673077736
At time: 714.5754525661469 and batch: 400, loss is 4.1603739023208615 and perplexity is 64.09548357018991
At time: 715.6808667182922 and batch: 450, loss is 4.1058660364151 and perplexity is 60.69528612086979
At time: 716.7876436710358 and batch: 500, loss is 4.181107902526856 and perplexity is 65.4383123393682
At time: 717.8956568241119 and batch: 550, loss is 4.180770082473755 and perplexity is 65.41620969878667
At time: 719.0010631084442 and batch: 600, loss is 4.125763907432556 and perplexity is 61.91508858590893
At time: 720.1068935394287 and batch: 650, loss is 4.144701442718506 and perplexity is 63.09878048889613
At time: 721.2128329277039 and batch: 700, loss is 4.181602845191955 and perplexity is 65.47070856855373
At time: 722.3189680576324 and batch: 750, loss is 4.139091734886169 and perplexity is 62.745805734041305
At time: 723.4251370429993 and batch: 800, loss is 4.115704469680786 and perplexity is 61.29537979319963
At time: 724.5323865413666 and batch: 850, loss is 4.079969897270202 and perplexity is 59.1436894365824
At time: 725.6387300491333 and batch: 900, loss is 4.107743010520935 and perplexity is 60.809316583900376
At time: 726.7439539432526 and batch: 950, loss is 4.102082557678223 and perplexity is 60.466080666801155
At time: 727.8504507541656 and batch: 1000, loss is 4.116728591918945 and perplexity is 61.358185909823234
At time: 728.957154750824 and batch: 1050, loss is 4.0609156084060665 and perplexity is 58.02741715399338
At time: 730.0622758865356 and batch: 1100, loss is 4.042285022735595 and perplexity is 56.95634075833569
At time: 731.1683166027069 and batch: 1150, loss is 4.0671937465667725 and perplexity is 58.39286726879973
At time: 732.2756090164185 and batch: 1200, loss is 4.038836274147034 and perplexity is 56.760250985055606
At time: 733.3822050094604 and batch: 1250, loss is 4.084776210784912 and perplexity is 59.42863677501424
At time: 734.4887654781342 and batch: 1300, loss is 4.098949837684631 and perplexity is 60.27695376245265
At time: 735.5950229167938 and batch: 1350, loss is 4.0597969436645505 and perplexity is 57.96254022291528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.417359619140625 and perplexity of 82.87716891972325
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 739.0220079421997 and batch: 50, loss is 4.149761047363281 and perplexity is 63.41884438733899
At time: 740.1280791759491 and batch: 100, loss is 4.161725158691406 and perplexity is 64.18215154282515
At time: 741.2639734745026 and batch: 150, loss is 4.145739002227783 and perplexity is 63.16428320422247
At time: 742.3689072132111 and batch: 200, loss is 4.137326297760009 and perplexity is 62.63512968363776
At time: 743.4753978252411 and batch: 250, loss is 4.134447145462036 and perplexity is 62.455052964620684
At time: 744.5800406932831 and batch: 300, loss is 4.139077434539795 and perplexity is 62.744908453701484
At time: 745.6868581771851 and batch: 350, loss is 4.135037088394165 and perplexity is 62.49190875202966
At time: 746.794545173645 and batch: 400, loss is 4.144557404518127 and perplexity is 63.0896925086323
At time: 747.9013168811798 and batch: 450, loss is 4.086527328491211 and perplexity is 59.532794482719424
At time: 749.0076665878296 and batch: 500, loss is 4.160568819046021 and perplexity is 64.10797806959881
At time: 750.1144304275513 and batch: 550, loss is 4.156330676078796 and perplexity is 63.83685422982138
At time: 751.2209734916687 and batch: 600, loss is 4.0977356910705565 and perplexity is 60.203813113855695
At time: 752.3265798091888 and batch: 650, loss is 4.114919543266296 and perplexity is 61.247286307906506
At time: 753.4323554039001 and batch: 700, loss is 4.144907240867615 and perplexity is 63.11176743743091
At time: 754.5402040481567 and batch: 750, loss is 4.102249999046325 and perplexity is 60.47620603775111
At time: 755.6457765102386 and batch: 800, loss is 4.0765074396133425 and perplexity is 58.93926103281809
At time: 756.7527034282684 and batch: 850, loss is 4.038427481651306 and perplexity is 56.737052562390886
At time: 757.8602519035339 and batch: 900, loss is 4.064896006584167 and perplexity is 58.258849670737334
At time: 758.9667439460754 and batch: 950, loss is 4.0525044393539424 and perplexity is 57.54138565068933
At time: 760.0736410617828 and batch: 1000, loss is 4.0651380777359005 and perplexity is 58.27295416465247
At time: 761.1807553768158 and batch: 1050, loss is 4.007588562965393 and perplexity is 55.014047568952506
At time: 762.2864515781403 and batch: 1100, loss is 3.9813022422790527 and perplexity is 53.586771769844475
At time: 763.3929522037506 and batch: 1150, loss is 4.00753119468689 and perplexity is 55.010891598277176
At time: 764.5000138282776 and batch: 1200, loss is 3.9721784591674805 and perplexity is 53.10008129189231
At time: 765.6058661937714 and batch: 1250, loss is 4.01890540599823 and perplexity is 55.64016908704476
At time: 766.7124569416046 and batch: 1300, loss is 4.024227151870727 and perplexity is 55.93706121877779
At time: 767.8186926841736 and batch: 1350, loss is 3.982895669937134 and perplexity is 53.67222647895746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.379759114583333 and perplexity of 79.81880390328811
Finished 24 epochs...
Completing Train Step...
At time: 771.2522120475769 and batch: 50, loss is 4.126261053085327 and perplexity is 61.945877055583146
At time: 772.3579416275024 and batch: 100, loss is 4.137402358055115 and perplexity is 62.639893911267464
At time: 773.4642131328583 and batch: 150, loss is 4.119594430923462 and perplexity is 61.53428080153181
At time: 774.5699417591095 and batch: 200, loss is 4.112078609466553 and perplexity is 61.073533748712606
At time: 775.6767845153809 and batch: 250, loss is 4.108957948684693 and perplexity is 60.88324104105911
At time: 776.7820405960083 and batch: 300, loss is 4.115852336883545 and perplexity is 61.3044440396876
At time: 777.8875200748444 and batch: 350, loss is 4.113149795532227 and perplexity is 61.138989918655334
At time: 778.9941358566284 and batch: 400, loss is 4.124037537574768 and perplexity is 61.80829245456718
At time: 780.1004831790924 and batch: 450, loss is 4.067809014320374 and perplexity is 58.4288055717763
At time: 781.2076687812805 and batch: 500, loss is 4.143440456390381 and perplexity is 63.019263934558715
At time: 782.3137097358704 and batch: 550, loss is 4.140085697174072 and perplexity is 62.80820370414236
At time: 783.4207479953766 and batch: 600, loss is 4.082711772918701 and perplexity is 59.30607659938065
At time: 784.5257444381714 and batch: 650, loss is 4.100219235420227 and perplexity is 60.3535177758789
At time: 785.6310677528381 and batch: 700, loss is 4.132603907585144 and perplexity is 62.34003947656523
At time: 786.7377934455872 and batch: 750, loss is 4.090786285400391 and perplexity is 59.78688278059079
At time: 787.843859910965 and batch: 800, loss is 4.066242938041687 and perplexity is 58.337373219084874
At time: 788.9500215053558 and batch: 850, loss is 4.028321900367737 and perplexity is 56.16657900424107
At time: 790.0556123256683 and batch: 900, loss is 4.056606931686401 and perplexity is 57.77793363048984
At time: 791.1606783866882 and batch: 950, loss is 4.045640058517456 and perplexity is 57.14775223621429
At time: 792.2661888599396 and batch: 1000, loss is 4.058746981620788 and perplexity is 57.90171369408248
At time: 793.3725981712341 and batch: 1050, loss is 4.002697958946228 and perplexity is 54.745652488786234
At time: 794.4798712730408 and batch: 1100, loss is 3.9776822471618654 and perplexity is 53.393138604701235
At time: 795.5852873325348 and batch: 1150, loss is 4.005645627975464 and perplexity is 54.90726262269016
At time: 796.7219607830048 and batch: 1200, loss is 3.971920442581177 and perplexity is 53.086382357537076
At time: 797.8277292251587 and batch: 1250, loss is 4.019426479339599 and perplexity is 55.66916925081525
At time: 798.9331500530243 and batch: 1300, loss is 4.025298299789429 and perplexity is 55.99701018685486
At time: 800.0382747650146 and batch: 1350, loss is 3.985498366355896 and perplexity is 53.81210093701731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.377294108072917 and perplexity of 79.62229233266793
Finished 25 epochs...
Completing Train Step...
At time: 803.4360342025757 and batch: 50, loss is 4.116016116142273 and perplexity is 61.31448525833835
At time: 804.561607837677 and batch: 100, loss is 4.126266646385193 and perplexity is 61.94622353841797
At time: 805.6629257202148 and batch: 150, loss is 4.108589096069336 and perplexity is 60.860788239511564
At time: 806.7667670249939 and batch: 200, loss is 4.101168565750122 and perplexity is 60.41084040556978
At time: 807.8714182376862 and batch: 250, loss is 4.09809594631195 and perplexity is 60.22550576029204
At time: 808.9748759269714 and batch: 300, loss is 4.105715041160583 and perplexity is 60.6861221125723
At time: 810.0783162117004 and batch: 350, loss is 4.103411812782287 and perplexity is 60.54650895616481
At time: 811.1815614700317 and batch: 400, loss is 4.114432229995727 and perplexity is 61.21744696364704
At time: 812.2858648300171 and batch: 450, loss is 4.058654179573059 and perplexity is 57.89634054580809
At time: 813.3880355358124 and batch: 500, loss is 4.134836688041687 and perplexity is 62.4793866062518
At time: 814.4910323619843 and batch: 550, loss is 4.131814908981323 and perplexity is 62.29087267127704
At time: 815.5962314605713 and batch: 600, loss is 4.07476927280426 and perplexity is 58.836903748326634
At time: 816.7002556324005 and batch: 650, loss is 4.092541999816895 and perplexity is 59.891943674081354
At time: 817.8041803836823 and batch: 700, loss is 4.1257820272445676 and perplexity is 61.91621048583907
At time: 818.9076473712921 and batch: 750, loss is 4.084284539222717 and perplexity is 59.39942458632168
At time: 820.0101661682129 and batch: 800, loss is 4.060053014755249 and perplexity is 57.977384654343595
At time: 821.1132283210754 and batch: 850, loss is 4.022169976234436 and perplexity is 55.82210714017789
At time: 822.2165262699127 and batch: 900, loss is 4.0510933256149295 and perplexity is 57.460245473309485
At time: 823.3204393386841 and batch: 950, loss is 4.040861177444458 and perplexity is 56.875301448157764
At time: 824.4248931407928 and batch: 1000, loss is 4.0540656566619875 and perplexity is 57.63129042007594
At time: 825.5594327449799 and batch: 1050, loss is 3.998540925979614 and perplexity is 54.51854537953324
At time: 826.6631100177765 and batch: 1100, loss is 3.974049491882324 and perplexity is 53.19952628455649
At time: 827.7662088871002 and batch: 1150, loss is 4.002928519248963 and perplexity is 54.75827611819546
At time: 828.8699266910553 and batch: 1200, loss is 3.969633355140686 and perplexity is 52.965107894699685
At time: 829.9738907814026 and batch: 1250, loss is 4.017463145256042 and perplexity is 55.55997929667545
At time: 831.0780384540558 and batch: 1300, loss is 4.023513097763061 and perplexity is 55.897133387456236
At time: 832.1813623905182 and batch: 1350, loss is 3.984496302604675 and perplexity is 53.75820478948908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.376004638671875 and perplexity of 79.51968798986135
Finished 26 epochs...
Completing Train Step...
At time: 835.5781502723694 and batch: 50, loss is 4.107995624542236 and perplexity is 60.82467981029671
At time: 836.71124958992 and batch: 100, loss is 4.117724099159241 and perplexity is 61.41929884228415
At time: 837.8162162303925 and batch: 150, loss is 4.10032301902771 and perplexity is 60.35978180672416
At time: 838.9197025299072 and batch: 200, loss is 4.093005948066711 and perplexity is 59.9197368833339
At time: 840.0221979618073 and batch: 250, loss is 4.089916610717774 and perplexity is 59.73491024515876
At time: 841.1266882419586 and batch: 300, loss is 4.098051714897156 and perplexity is 60.22284195987779
At time: 842.2293887138367 and batch: 350, loss is 4.096140627861023 and perplexity is 60.10786077185315
At time: 843.332448720932 and batch: 400, loss is 4.1070878267288204 and perplexity is 60.769488354095074
At time: 844.4370312690735 and batch: 450, loss is 4.0516127014160155 and perplexity is 57.49009668566041
At time: 845.539801120758 and batch: 500, loss is 4.12822919845581 and perplexity is 62.06791560213683
At time: 846.6426260471344 and batch: 550, loss is 4.125352201461792 and perplexity is 61.88960302089735
At time: 847.746072769165 and batch: 600, loss is 4.06847044467926 and perplexity is 58.4674649414459
At time: 848.8494515419006 and batch: 650, loss is 4.086334838867187 and perplexity is 59.52133614033373
At time: 849.9523451328278 and batch: 700, loss is 4.120127158164978 and perplexity is 61.567070522415214
At time: 851.056168794632 and batch: 750, loss is 4.078841490745544 and perplexity is 59.07698895123873
At time: 852.1605677604675 and batch: 800, loss is 4.054723348617554 and perplexity is 57.66920652336544
At time: 853.2934927940369 and batch: 850, loss is 4.016864981651306 and perplexity is 55.526755276870645
At time: 854.3968451023102 and batch: 900, loss is 4.046082620620727 and perplexity is 57.17304926298095
At time: 855.5008509159088 and batch: 950, loss is 4.036531281471253 and perplexity is 56.62956968983276
At time: 856.6038670539856 and batch: 1000, loss is 4.049624552726746 and perplexity is 57.3759113715921
At time: 857.7078070640564 and batch: 1050, loss is 3.994496340751648 and perplexity is 54.29848580109119
At time: 858.8109123706818 and batch: 1100, loss is 3.970252070426941 and perplexity is 52.99788835643294
At time: 859.9142572879791 and batch: 1150, loss is 3.9997135257720946 and perplexity is 54.58251131042089
At time: 861.0163486003876 and batch: 1200, loss is 3.966759214401245 and perplexity is 52.81309727493082
At time: 862.1187975406647 and batch: 1250, loss is 4.014631609916687 and perplexity is 55.40288177040376
At time: 863.2226309776306 and batch: 1300, loss is 4.020712523460388 and perplexity is 55.74080831426395
At time: 864.3262116909027 and batch: 1350, loss is 3.9822133684158327 and perplexity is 53.635618327498165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.375320638020833 and perplexity of 79.46531506918205
Finished 27 epochs...
Completing Train Step...
At time: 867.7544114589691 and batch: 50, loss is 4.101054720878601 and perplexity is 60.4039633326725
At time: 868.8575735092163 and batch: 100, loss is 4.110506772994995 and perplexity is 60.9776115476758
At time: 869.9608469009399 and batch: 150, loss is 4.093455896377564 and perplexity is 59.94670373412081
At time: 871.0632956027985 and batch: 200, loss is 4.085974502563476 and perplexity is 59.499892305805055
At time: 872.1676452159882 and batch: 250, loss is 4.083031330108643 and perplexity is 59.32503131096109
At time: 873.2709596157074 and batch: 300, loss is 4.091616010665893 and perplexity is 59.8365100534334
At time: 874.3747801780701 and batch: 350, loss is 4.089936108589172 and perplexity is 59.7360749601114
At time: 875.4772479534149 and batch: 400, loss is 4.100825791358948 and perplexity is 60.39013666508817
At time: 876.5802962779999 and batch: 450, loss is 4.045555295944214 and perplexity is 57.1429084509685
At time: 877.6848583221436 and batch: 500, loss is 4.122353706359863 and perplexity is 61.70430529537398
At time: 878.7877511978149 and batch: 550, loss is 4.119730529785156 and perplexity is 61.542656117026596
At time: 879.8910481929779 and batch: 600, loss is 4.062877793312072 and perplexity is 58.14138945686593
At time: 881.0255327224731 and batch: 650, loss is 4.080830059051514 and perplexity is 59.19458446368207
At time: 882.1279761791229 and batch: 700, loss is 4.1149928855896 and perplexity is 61.25177849091192
At time: 883.23184466362 and batch: 750, loss is 4.073896646499634 and perplexity is 58.785583513383166
At time: 884.3355121612549 and batch: 800, loss is 4.049806060791016 and perplexity is 57.38632650738787
At time: 885.438948392868 and batch: 850, loss is 4.01200692653656 and perplexity is 55.257657414756565
At time: 886.5419125556946 and batch: 900, loss is 4.0414240407943725 and perplexity is 56.907323482027486
At time: 887.6468372344971 and batch: 950, loss is 4.032385311126709 and perplexity is 56.39527120617129
At time: 888.7499077320099 and batch: 1000, loss is 4.045321431159973 and perplexity is 57.12954629954192
At time: 889.853354215622 and batch: 1050, loss is 3.990444760322571 and perplexity is 54.078936180495035
At time: 890.9571905136108 and batch: 1100, loss is 3.9664127254486083 and perplexity is 52.7948012900319
At time: 892.0609745979309 and batch: 1150, loss is 3.996285667419434 and perplexity is 54.395730505080934
At time: 893.1642348766327 and batch: 1200, loss is 3.9635343027114867 and perplexity is 52.643054034744644
At time: 894.267608165741 and batch: 1250, loss is 4.011259059906006 and perplexity is 55.21634750577012
At time: 895.3726899623871 and batch: 1300, loss is 4.017427945137024 and perplexity is 55.55802361321193
At time: 896.476001739502 and batch: 1350, loss is 3.9794313049316408 and perplexity is 53.48660800649371
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.374917399088542 and perplexity of 79.43327802010621
Finished 28 epochs...
Completing Train Step...
At time: 899.9042322635651 and batch: 50, loss is 4.09491199016571 and perplexity is 60.03405533767793
At time: 901.0081403255463 and batch: 100, loss is 4.1040464115142825 and perplexity is 60.5849438880648
At time: 902.1146941184998 and batch: 150, loss is 4.087301297187805 and perplexity is 59.57888883756269
At time: 903.2187170982361 and batch: 200, loss is 4.0797254800796505 and perplexity is 59.12923546864252
At time: 904.3228895664215 and batch: 250, loss is 4.0768081569671635 and perplexity is 58.9569877566652
At time: 905.4267008304596 and batch: 300, loss is 4.08584547996521 and perplexity is 59.492215970324196
At time: 906.5326318740845 and batch: 350, loss is 4.084259300231934 and perplexity is 59.39792542371075
At time: 907.6366398334503 and batch: 400, loss is 4.095086665153503 and perplexity is 60.04454270147462
At time: 908.7414152622223 and batch: 450, loss is 4.03999605178833 and perplexity is 56.82611844348213
At time: 909.8758764266968 and batch: 500, loss is 4.117017607688904 and perplexity is 61.375921956042326
At time: 910.9797077178955 and batch: 550, loss is 4.114474191665649 and perplexity is 61.220015803846024
At time: 912.3494267463684 and batch: 600, loss is 4.057643504142761 and perplexity is 57.837855696492724
At time: 913.454790353775 and batch: 650, loss is 4.075676207542419 and perplexity is 58.89028918511604
At time: 914.5592226982117 and batch: 700, loss is 4.1101491355896 and perplexity is 60.95580757208572
At time: 915.6639635562897 and batch: 750, loss is 4.069250292778015 and perplexity is 58.51307846631814
At time: 916.7687306404114 and batch: 800, loss is 4.045133299827576 and perplexity is 57.118799452818344
At time: 917.8726255893707 and batch: 850, loss is 4.007423272132874 and perplexity is 55.004955002709224
At time: 918.9765539169312 and batch: 900, loss is 4.03693395614624 and perplexity is 56.652377575173006
At time: 920.0814130306244 and batch: 950, loss is 4.028414273262024 and perplexity is 56.171767513341024
At time: 921.1858503818512 and batch: 1000, loss is 4.041147327423095 and perplexity is 56.891578643200596
At time: 922.2905497550964 and batch: 1050, loss is 3.9864485359191892 and perplexity is 53.86325585653965
At time: 923.3956520557404 and batch: 1100, loss is 3.9625767183303835 and perplexity is 52.59266799671912
At time: 924.5016939640045 and batch: 1150, loss is 3.99278208732605 and perplexity is 54.20548417275691
At time: 925.6050910949707 and batch: 1200, loss is 3.960067448616028 and perplexity is 52.46086424246
At time: 926.7091586589813 and batch: 1250, loss is 4.007764234542846 and perplexity is 55.02371282240136
At time: 927.8145499229431 and batch: 1300, loss is 4.013951444625855 and perplexity is 55.36521146568058
At time: 928.9191687107086 and batch: 1350, loss is 3.976285376548767 and perplexity is 53.318607365811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.374653727213541 and perplexity of 79.4123364597248
Finished 29 epochs...
Completing Train Step...
At time: 932.3458993434906 and batch: 50, loss is 4.089125761985779 and perplexity is 59.68768764256446
At time: 933.4514672756195 and batch: 100, loss is 4.09810480594635 and perplexity is 60.22603933861824
At time: 934.5581469535828 and batch: 150, loss is 4.081712794303894 and perplexity is 59.24686067977302
At time: 935.6642978191376 and batch: 200, loss is 4.073960180282593 and perplexity is 58.78931850253497
At time: 936.7706348896027 and batch: 250, loss is 4.071107659339905 and perplexity is 58.62185969372899
At time: 937.9064049720764 and batch: 300, loss is 4.080460228919983 and perplexity is 59.17269657037467
At time: 939.014092206955 and batch: 350, loss is 4.079063153266906 and perplexity is 59.09008555702385
At time: 940.1170032024384 and batch: 400, loss is 4.089798040390015 and perplexity is 59.72782787715999
At time: 941.2220311164856 and batch: 450, loss is 4.0347662353515625 and perplexity is 56.52970404725115
At time: 942.3350303173065 and batch: 500, loss is 4.11203763961792 and perplexity is 61.071031626535586
At time: 943.4494853019714 and batch: 550, loss is 4.109553303718567 and perplexity is 60.9194989771929
At time: 944.5653595924377 and batch: 600, loss is 4.052711229324341 and perplexity is 57.55328586250456
At time: 945.6794216632843 and batch: 650, loss is 4.070812873840332 and perplexity is 58.60458136635857
At time: 946.7954668998718 and batch: 700, loss is 4.105579357147217 and perplexity is 60.67788853456352
At time: 947.9023673534393 and batch: 750, loss is 4.064758644104004 and perplexity is 58.250847640257085
At time: 949.0079593658447 and batch: 800, loss is 4.040616807937622 and perplexity is 56.861404556849116
At time: 950.1164743900299 and batch: 850, loss is 4.003046441078186 and perplexity is 54.764733695017576
At time: 951.2229940891266 and batch: 900, loss is 4.032531385421753 and perplexity is 56.403509707358516
At time: 952.3315737247467 and batch: 950, loss is 4.024476971626282 and perplexity is 55.95103714739674
At time: 953.4388236999512 and batch: 1000, loss is 4.037025446891785 and perplexity is 56.657560980547444
At time: 954.5451185703278 and batch: 1050, loss is 3.9824485063552855 and perplexity is 53.64823157914185
At time: 955.6519393920898 and batch: 1100, loss is 3.958705282211304 and perplexity is 52.389452464030896
At time: 956.759119272232 and batch: 1150, loss is 3.9892045783996584 and perplexity is 54.01191003233311
At time: 957.8658490180969 and batch: 1200, loss is 3.9565948915481566 and perplexity is 52.27900683540654
At time: 958.9730768203735 and batch: 1250, loss is 4.004041547775269 and perplexity is 54.81925757231988
At time: 960.0801720619202 and batch: 1300, loss is 4.0103788089752195 and perplexity is 55.16776465017246
At time: 961.186291217804 and batch: 1350, loss is 3.9731182718276976 and perplexity is 53.15000887816296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.374436848958333 and perplexity of 79.39511551824278
Finished 30 epochs...
Completing Train Step...
At time: 964.5924692153931 and batch: 50, loss is 4.083741998672485 and perplexity is 59.36720673036006
At time: 965.7284770011902 and batch: 100, loss is 4.092447800636291 and perplexity is 59.88630216777931
At time: 966.8352055549622 and batch: 150, loss is 4.076640934944153 and perplexity is 58.947129674169126
At time: 967.9429032802582 and batch: 200, loss is 4.068712558746338 and perplexity is 58.481622450971535
At time: 969.0491650104523 and batch: 250, loss is 4.065812201499939 and perplexity is 58.312250591695054
At time: 970.1558957099915 and batch: 300, loss is 4.075474853515625 and perplexity is 58.87843258197699
At time: 971.2631831169128 and batch: 350, loss is 4.074076704978943 and perplexity is 58.796169309158415
At time: 972.369467496872 and batch: 400, loss is 4.084668622016907 and perplexity is 59.422243265140494
At time: 973.4766438007355 and batch: 450, loss is 4.0301567029953 and perplexity is 56.269728191241306
At time: 974.5857439041138 and batch: 500, loss is 4.107363867759704 and perplexity is 60.7862655417962
At time: 975.6926136016846 and batch: 550, loss is 4.104921655654907 and perplexity is 60.63799371760256
At time: 976.7988576889038 and batch: 600, loss is 4.048133516311646 and perplexity is 57.29042554546498
At time: 977.9055376052856 and batch: 650, loss is 4.06607982635498 and perplexity is 58.3278584877441
At time: 979.0128545761108 and batch: 700, loss is 4.101045088768005 and perplexity is 60.403381517819334
At time: 980.1200940608978 and batch: 750, loss is 4.060365138053894 and perplexity is 57.995483571288574
At time: 981.2267458438873 and batch: 800, loss is 4.036168513298034 and perplexity is 56.60903001008255
At time: 982.3343484401703 and batch: 850, loss is 3.9987176132202147 and perplexity is 54.5281789619184
At time: 983.440012216568 and batch: 900, loss is 4.028291721343994 and perplexity is 56.16488397729699
At time: 984.5469439029694 and batch: 950, loss is 4.020635070800782 and perplexity is 55.73649120759924
At time: 985.6536254882812 and batch: 1000, loss is 4.032994203567505 and perplexity is 56.42962031690104
At time: 986.7838172912598 and batch: 1050, loss is 3.9784226608276367 and perplexity is 53.432686253185565
At time: 987.8853213787079 and batch: 1100, loss is 3.954853754043579 and perplexity is 52.18806109340012
At time: 988.9875121116638 and batch: 1150, loss is 3.9856059312820435 and perplexity is 53.817889543000355
At time: 990.0890870094299 and batch: 1200, loss is 3.9530130434036255 and perplexity is 52.09208633204774
At time: 991.1907622814178 and batch: 1250, loss is 4.000315518379211 and perplexity is 54.61537947090983
At time: 992.2927603721619 and batch: 1300, loss is 4.006624989509582 and perplexity is 54.9610630243683
At time: 993.3950705528259 and batch: 1350, loss is 3.9698103618621827 and perplexity is 52.97448390458574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.374381510416667 and perplexity of 79.3907220299003
Finished 31 epochs...
Completing Train Step...
At time: 996.7926115989685 and batch: 50, loss is 4.078616552352905 and perplexity is 59.0637017627575
At time: 997.893292427063 and batch: 100, loss is 4.087145056724548 and perplexity is 59.56958093152509
At time: 998.9943611621857 and batch: 150, loss is 4.071886758804322 and perplexity is 58.66754974945733
At time: 1000.0950696468353 and batch: 200, loss is 4.06370861530304 and perplexity is 58.18971467385882
At time: 1001.1958878040314 and batch: 250, loss is 4.060615878105164 and perplexity is 58.010027185069724
At time: 1002.2964675426483 and batch: 300, loss is 4.0706849813461305 and perplexity is 58.59708675953821
At time: 1003.3973641395569 and batch: 350, loss is 4.069620623588562 and perplexity is 58.5347516749749
At time: 1004.4975204467773 and batch: 400, loss is 4.0801035499572755 and perplexity is 59.151594677865624
At time: 1005.5984196662903 and batch: 450, loss is 4.025820112228393 and perplexity is 56.02623774830453
At time: 1006.700891494751 and batch: 500, loss is 4.102686777114868 and perplexity is 60.50262648773359
At time: 1007.8044209480286 and batch: 550, loss is 4.100310893058777 and perplexity is 60.35904989032277
At time: 1008.9098246097565 and batch: 600, loss is 4.043370866775513 and perplexity is 57.018220051034305
At time: 1010.0148365497589 and batch: 650, loss is 4.061568737030029 and perplexity is 58.06532890038697
At time: 1011.1218783855438 and batch: 700, loss is 4.096769080162049 and perplexity is 60.14564756762067
At time: 1012.2269930839539 and batch: 750, loss is 4.056052899360656 and perplexity is 57.745931653427284
At time: 1013.3323202133179 and batch: 800, loss is 4.031923575401306 and perplexity is 56.369237505518974
At time: 1014.469886302948 and batch: 850, loss is 3.994536962509155 and perplexity is 54.300691545814715
At time: 1015.5748360157013 and batch: 900, loss is 4.024078788757325 and perplexity is 55.92876283782281
At time: 1016.680900812149 and batch: 950, loss is 4.016799659729004 and perplexity is 55.52312828093921
At time: 1017.7869169712067 and batch: 1000, loss is 4.028951253890991 and perplexity is 56.2019387643542
At time: 1018.8928327560425 and batch: 1050, loss is 3.974518918991089 and perplexity is 53.22450544685716
At time: 1019.9989995956421 and batch: 1100, loss is 3.9510326528549196 and perplexity is 51.98902574040737
At time: 1021.1059000492096 and batch: 1150, loss is 3.982042350769043 and perplexity is 53.62644647456439
At time: 1022.2116823196411 and batch: 1200, loss is 3.9493824148178103 and perplexity is 51.90330222417601
At time: 1023.316810131073 and batch: 1250, loss is 3.9965468883514403 and perplexity is 54.409941664546
At time: 1024.4236705303192 and batch: 1300, loss is 4.002866945266724 and perplexity is 54.754904536876225
At time: 1025.5308451652527 and batch: 1350, loss is 3.966466898918152 and perplexity is 52.797661445063206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3742724609375 and perplexity of 79.38206498504398
Finished 32 epochs...
Completing Train Step...
At time: 1028.9540162086487 and batch: 50, loss is 4.073660836219788 and perplexity is 58.771722902785434
At time: 1030.0570566654205 and batch: 100, loss is 4.082129034996033 and perplexity is 59.27152676722794
At time: 1031.1607871055603 and batch: 150, loss is 4.067470970153809 and perplexity is 58.409057392959795
At time: 1032.2642359733582 and batch: 200, loss is 4.0587447023391725 and perplexity is 57.90158171992133
At time: 1033.368108034134 and batch: 250, loss is 4.0557985544204715 and perplexity is 57.73124613556773
At time: 1034.4709720611572 and batch: 300, loss is 4.0661101913452145 and perplexity is 58.329629639487834
At time: 1035.5745260715485 and batch: 350, loss is 4.065074949264527 and perplexity is 58.26927559824597
At time: 1036.678878068924 and batch: 400, loss is 4.07530113697052 and perplexity is 58.868205312436324
At time: 1037.7819032669067 and batch: 450, loss is 4.0212423658370975 and perplexity is 55.770349982143514
At time: 1038.8857536315918 and batch: 500, loss is 4.098218097686767 and perplexity is 60.23286283794912
At time: 1039.991014957428 and batch: 550, loss is 4.095960745811462 and perplexity is 60.0970494190761
At time: 1041.0938766002655 and batch: 600, loss is 4.039017939567566 and perplexity is 56.77056329658718
At time: 1042.1975464820862 and batch: 650, loss is 4.057306923866272 and perplexity is 57.81839189078117
At time: 1043.3319981098175 and batch: 700, loss is 4.0925266075134275 and perplexity is 59.89102180620392
At time: 1044.434559583664 and batch: 750, loss is 4.051985011100769 and perplexity is 57.51150479040899
At time: 1045.5383458137512 and batch: 800, loss is 4.027646460533142 and perplexity is 56.12865466865399
At time: 1046.6433005332947 and batch: 850, loss is 3.9904906654357912 and perplexity is 54.08141873716383
At time: 1047.747784614563 and batch: 900, loss is 4.019999289512635 and perplexity is 55.70106625187775
At time: 1048.8515710830688 and batch: 950, loss is 4.013012294769287 and perplexity is 55.31323964375823
At time: 1049.9558990001678 and batch: 1000, loss is 4.025029335021973 and perplexity is 55.981950989319266
At time: 1051.0609338283539 and batch: 1050, loss is 3.9706403112411497 and perplexity is 53.01846829448723
At time: 1052.1649050712585 and batch: 1100, loss is 3.947286887168884 and perplexity is 51.79465129956231
At time: 1053.268704175949 and batch: 1150, loss is 3.9784442520141603 and perplexity is 53.43383994073561
At time: 1054.372475862503 and batch: 1200, loss is 3.9458380222320555 and perplexity is 51.71966218304804
At time: 1055.47532081604 and batch: 1250, loss is 3.9928094148635864 and perplexity is 54.20696549540068
At time: 1056.5804257392883 and batch: 1300, loss is 3.9991010999679566 and perplexity is 54.54909380595524
At time: 1057.6837871074677 and batch: 1350, loss is 3.9630470514297484 and perplexity is 52.61740988727082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3744384765625 and perplexity of 79.3952447421688
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 1061.0820889472961 and batch: 50, loss is 4.076429662704467 and perplexity is 58.93467709754805
At time: 1062.215721130371 and batch: 100, loss is 4.093215889930725 and perplexity is 59.93231786517761
At time: 1063.3188107013702 and batch: 150, loss is 4.080828437805176 and perplexity is 59.19448849475657
At time: 1064.4220931529999 and batch: 200, loss is 4.0726520490646365 and perplexity is 58.71246463814845
At time: 1065.5262253284454 and batch: 250, loss is 4.073893737792969 and perplexity is 58.78541252361329
At time: 1066.6289672851562 and batch: 300, loss is 4.0833197116851805 and perplexity is 59.34214202410733
At time: 1067.7322030067444 and batch: 350, loss is 4.079034466743469 and perplexity is 59.08839049221246
At time: 1068.8370871543884 and batch: 400, loss is 4.086916613578796 and perplexity is 59.55597422330475
At time: 1069.9407305717468 and batch: 450, loss is 4.032488927841187 and perplexity is 56.401115001637976
At time: 1071.0744383335114 and batch: 500, loss is 4.1106474542617795 and perplexity is 60.98619055875274
At time: 1072.1778285503387 and batch: 550, loss is 4.104348711967468 and perplexity is 60.60326151263198
At time: 1073.2804403305054 and batch: 600, loss is 4.046527147293091 and perplexity is 57.198469857966344
At time: 1074.3825769424438 and batch: 650, loss is 4.062077860832215 and perplexity is 58.09489886816037
At time: 1075.4877524375916 and batch: 700, loss is 4.093441076278687 and perplexity is 59.9458153246273
At time: 1076.5915086269379 and batch: 750, loss is 4.050302352905273 and perplexity is 57.414813957163304
At time: 1077.6939494609833 and batch: 800, loss is 4.025891819000244 and perplexity is 56.030255352995425
At time: 1078.7970750331879 and batch: 850, loss is 3.985457921028137 and perplexity is 53.809924532970506
At time: 1079.9009454250336 and batch: 900, loss is 4.016295294761658 and perplexity is 55.495131421068024
At time: 1081.0039975643158 and batch: 950, loss is 4.007287497520447 and perplexity is 54.9974872332404
At time: 1082.10808968544 and batch: 1000, loss is 4.020637340545655 and perplexity is 55.73661771535796
At time: 1083.212547302246 and batch: 1050, loss is 3.963971495628357 and perplexity is 52.66607423685904
At time: 1084.3159313201904 and batch: 1100, loss is 3.9368909215927124 and perplexity is 51.25898509571417
At time: 1085.4192686080933 and batch: 1150, loss is 3.963583788871765 and perplexity is 52.64565920181348
At time: 1086.5220980644226 and batch: 1200, loss is 3.9302834177017214 and perplexity is 50.92140765257379
At time: 1087.6258444786072 and batch: 1250, loss is 3.9769995832443237 and perplexity is 53.35670147410373
At time: 1088.7279646396637 and batch: 1300, loss is 3.9828347110748292 and perplexity is 53.66895478081446
At time: 1089.8326692581177 and batch: 1350, loss is 3.9447228479385377 and perplexity is 51.66201789300123
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361150309244792 and perplexity of 78.3472061235049
Finished 34 epochs...
Completing Train Step...
At time: 1093.2235536575317 and batch: 50, loss is 4.0737216806411745 and perplexity is 58.77529894304929
At time: 1094.3575413227081 and batch: 100, loss is 4.085138106346131 and perplexity is 59.45014762697855
At time: 1095.4605195522308 and batch: 150, loss is 4.071053156852722 and perplexity is 58.61866474363955
At time: 1096.5628776550293 and batch: 200, loss is 4.062149767875671 and perplexity is 58.099076450774895
At time: 1097.6670351028442 and batch: 250, loss is 4.061565713882446 and perplexity is 58.0651533605936
At time: 1098.7999286651611 and batch: 300, loss is 4.072324380874634 and perplexity is 58.69322958265989
At time: 1099.9026441574097 and batch: 350, loss is 4.068651261329651 and perplexity is 58.47803778845805
At time: 1101.0052304267883 and batch: 400, loss is 4.077491879463196 and perplexity is 58.99731175913567
At time: 1102.109052658081 and batch: 450, loss is 4.0238287019729615 and perplexity is 55.91477754221299
At time: 1103.2117099761963 and batch: 500, loss is 4.10247917175293 and perplexity is 60.49006712180437
At time: 1104.3159546852112 and batch: 550, loss is 4.097165484428405 and perplexity is 60.16949428507726
At time: 1105.4202873706818 and batch: 600, loss is 4.03958918094635 and perplexity is 56.80300225579481
At time: 1106.5229420661926 and batch: 650, loss is 4.054930930137634 and perplexity is 57.68117882748895
At time: 1107.6260571479797 and batch: 700, loss is 4.087643189430237 and perplexity is 59.59926187996307
At time: 1108.7308542728424 and batch: 750, loss is 4.045600490570068 and perplexity is 57.14549106169578
At time: 1109.833654165268 and batch: 800, loss is 4.022000913619995 and perplexity is 55.81267050651461
At time: 1110.9373145103455 and batch: 850, loss is 3.9819049930572508 and perplexity is 53.619080974450796
At time: 1112.0418334007263 and batch: 900, loss is 4.01364501953125 and perplexity is 55.34824877454923
At time: 1113.1459980010986 and batch: 950, loss is 4.005316815376282 and perplexity is 54.88921139085208
At time: 1114.2484364509583 and batch: 1000, loss is 4.019531655311584 and perplexity is 55.67502461771736
At time: 1115.3528859615326 and batch: 1050, loss is 3.9637925243377685 and perplexity is 52.65664936499854
At time: 1116.4566841125488 and batch: 1100, loss is 3.9373669815063477 and perplexity is 51.28339325314355
At time: 1117.5593512058258 and batch: 1150, loss is 3.964816255569458 and perplexity is 52.71058322368706
At time: 1118.6635053157806 and batch: 1200, loss is 3.9321200466156006 and perplexity is 51.0150173190002
At time: 1119.7678730487823 and batch: 1250, loss is 3.979287977218628 and perplexity is 53.478942442648325
At time: 1120.8718285560608 and batch: 1300, loss is 3.984983229637146 and perplexity is 53.78438748663237
At time: 1121.9756917953491 and batch: 1350, loss is 3.9471138763427733 and perplexity is 51.78569103928621
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3604203287760415 and perplexity of 78.29003506267121
Finished 35 epochs...
Completing Train Step...
At time: 1125.3987393379211 and batch: 50, loss is 4.071194167137146 and perplexity is 58.62693116103885
At time: 1126.5028085708618 and batch: 100, loss is 4.08193459033966 and perplexity is 59.26000285599079
At time: 1127.6371011734009 and batch: 150, loss is 4.06748411655426 and perplexity is 58.409825266865624
At time: 1128.7405805587769 and batch: 200, loss is 4.058568692207336 and perplexity is 57.891391351719605
At time: 1129.845377445221 and batch: 250, loss is 4.057604532241822 and perplexity is 57.835601689231744
At time: 1130.948853969574 and batch: 300, loss is 4.0687631368637085 and perplexity is 58.484580416139416
At time: 1132.0524852275848 and batch: 350, loss is 4.065239663124085 and perplexity is 58.278874146008626
At time: 1133.1562540531158 and batch: 400, loss is 4.07426203250885 and perplexity is 58.80706686776211
At time: 1134.2610638141632 and batch: 450, loss is 4.020713691711426 and perplexity is 55.740873433559116
At time: 1135.3652534484863 and batch: 500, loss is 4.0994427156448365 and perplexity is 60.30667026717401
At time: 1136.468992948532 and batch: 550, loss is 4.094383521080017 and perplexity is 60.00233757700935
At time: 1137.574025630951 and batch: 600, loss is 4.036873326301575 and perplexity is 56.648942854445075
At time: 1138.6786699295044 and batch: 650, loss is 4.052327446937561 and perplexity is 57.531202163027686
At time: 1139.7825224399567 and batch: 700, loss is 4.0853453540802 and perplexity is 59.46246981219271
At time: 1140.887858390808 and batch: 750, loss is 4.043545527458191 and perplexity is 57.02817976203313
At time: 1141.9921238422394 and batch: 800, loss is 4.02028260231018 and perplexity is 55.716849312449796
At time: 1143.0957264900208 and batch: 850, loss is 3.980174112319946 and perplexity is 53.52635301371135
At time: 1144.2006313800812 and batch: 900, loss is 4.0123512744903564 and perplexity is 55.276688552497546
At time: 1145.3048222064972 and batch: 950, loss is 4.00429584980011 and perplexity is 54.83319999323862
At time: 1146.4088397026062 and batch: 1000, loss is 4.018726358413696 and perplexity is 55.63020774097076
At time: 1147.5127444267273 and batch: 1050, loss is 3.9633476829528806 and perplexity is 52.63323071734946
At time: 1148.6188416481018 and batch: 1100, loss is 3.9371405410766602 and perplexity is 51.27178193422512
At time: 1149.722365617752 and batch: 1150, loss is 3.9647946882247926 and perplexity is 52.70944640863025
At time: 1150.8243143558502 and batch: 1200, loss is 3.9323373937606814 and perplexity is 51.026106492427175
At time: 1151.9285106658936 and batch: 1250, loss is 3.9796583890914916 and perplexity is 53.498755347118255
At time: 1153.032902956009 and batch: 1300, loss is 3.9852960109710693 and perplexity is 53.80121287029049
At time: 1154.1373915672302 and batch: 1350, loss is 3.94761625289917 and perplexity is 51.81171349240905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.360118408203125 and perplexity of 78.2664012583768
Finished 36 epochs...
Completing Train Step...
At time: 1157.5571217536926 and batch: 50, loss is 4.0689456129074095 and perplexity is 58.49525342474585
At time: 1158.6636371612549 and batch: 100, loss is 4.0794052362442015 and perplexity is 59.11030272719754
At time: 1159.768616437912 and batch: 150, loss is 4.064870438575745 and perplexity is 58.25736012702068
At time: 1160.8739457130432 and batch: 200, loss is 4.055992136001587 and perplexity is 57.74242292324961
At time: 1161.979854106903 and batch: 250, loss is 4.054904627799988 and perplexity is 57.6796616975997
At time: 1163.0874016284943 and batch: 300, loss is 4.066264767646789 and perplexity is 58.33864671480485
At time: 1164.1939098834991 and batch: 350, loss is 4.062865118980408 and perplexity is 58.1406525582824
At time: 1165.2986469268799 and batch: 400, loss is 4.071973466873169 and perplexity is 58.6726369199463
At time: 1166.4047694206238 and batch: 450, loss is 4.01860011100769 and perplexity is 55.623185014857704
At time: 1167.510314464569 and batch: 500, loss is 4.097367572784424 and perplexity is 60.18165506799471
At time: 1168.6168596744537 and batch: 550, loss is 4.092449712753296 and perplexity is 59.886416677505494
At time: 1169.7235612869263 and batch: 600, loss is 4.034960169792175 and perplexity is 56.54066816690938
At time: 1170.8293566703796 and batch: 650, loss is 4.050417566299439 and perplexity is 57.42142929383507
At time: 1171.9351449012756 and batch: 700, loss is 4.0836611223220824 and perplexity is 59.362405521500854
At time: 1173.042142868042 and batch: 750, loss is 4.041980357170105 and perplexity is 56.93899076567715
At time: 1174.1479284763336 and batch: 800, loss is 4.018910059928894 and perplexity is 55.64042803313638
At time: 1175.253615140915 and batch: 850, loss is 3.9787517023086547 and perplexity is 53.45027071625531
At time: 1176.3605029582977 and batch: 900, loss is 4.011188554763794 and perplexity is 55.2124546065731
At time: 1177.4673020839691 and batch: 950, loss is 4.0033193731307986 and perplexity is 54.77968278614601
At time: 1178.573088645935 and batch: 1000, loss is 4.017838892936706 and perplexity is 55.58085975267971
At time: 1179.6790764331818 and batch: 1050, loss is 3.9626755619049074 and perplexity is 52.59786670094269
At time: 1180.7860012054443 and batch: 1100, loss is 3.9365944194793703 and perplexity is 51.24378895126132
At time: 1181.8918623924255 and batch: 1150, loss is 3.9643470907211302 and perplexity is 52.685859071208796
At time: 1183.0282518863678 and batch: 1200, loss is 3.932031955718994 and perplexity is 51.010523558316784
At time: 1184.1350302696228 and batch: 1250, loss is 3.9794384336471555 and perplexity is 53.4869892986651
At time: 1185.2410442829132 and batch: 1300, loss is 3.985045886039734 and perplexity is 53.787757528443926
At time: 1186.346307516098 and batch: 1350, loss is 3.947524166107178 and perplexity is 51.80694253760024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.35994384765625 and perplexity of 78.25274022494469
Finished 37 epochs...
Completing Train Step...
At time: 1189.748551607132 and batch: 50, loss is 4.066947803497315 and perplexity is 58.378507713678125
At time: 1190.8845944404602 and batch: 100, loss is 4.077194170951843 and perplexity is 58.97975037149505
At time: 1191.991449356079 and batch: 150, loss is 4.06262617111206 and perplexity is 58.12676163295884
At time: 1193.0976333618164 and batch: 200, loss is 4.053796410560608 and perplexity is 57.61577550857131
At time: 1194.2033870220184 and batch: 250, loss is 4.052660064697266 and perplexity is 57.55034124542719
At time: 1195.310643196106 and batch: 300, loss is 4.064237518310547 and perplexity is 58.22049952933949
At time: 1196.4163892269135 and batch: 350, loss is 4.060925626754761 and perplexity is 58.02799849580432
At time: 1197.5231246948242 and batch: 400, loss is 4.070118918418884 and perplexity is 58.56392650735914
At time: 1198.6302633285522 and batch: 450, loss is 4.01685402393341 and perplexity is 55.52614683368424
At time: 1199.7367436885834 and batch: 500, loss is 4.0956788873672485 and perplexity is 60.08011294518123
At time: 1200.8417189121246 and batch: 550, loss is 4.090854721069336 and perplexity is 59.79097447591538
At time: 1201.9487018585205 and batch: 600, loss is 4.03333722114563 and perplexity is 56.44897998876075
At time: 1203.0547297000885 and batch: 650, loss is 4.0488060235977175 and perplexity is 57.328966732228324
At time: 1204.1608674526215 and batch: 700, loss is 4.0822049999237064 and perplexity is 59.27602949549446
At time: 1205.2677373886108 and batch: 750, loss is 4.040582599639893 and perplexity is 56.85945945826221
At time: 1206.375160932541 and batch: 800, loss is 4.017645478248596 and perplexity is 55.57011063757764
At time: 1207.4811298847198 and batch: 850, loss is 3.977434811592102 and perplexity is 53.37992887737473
At time: 1208.5873992443085 and batch: 900, loss is 4.010039057731628 and perplexity is 55.14902451719842
At time: 1209.6910598278046 and batch: 950, loss is 4.002324299812317 and perplexity is 54.72520009704135
At time: 1210.8258392810822 and batch: 1000, loss is 4.016901082992554 and perplexity is 55.52875990339592
At time: 1211.9323782920837 and batch: 1050, loss is 3.9618805551528933 and perplexity is 52.55606765923563
At time: 1213.0391385555267 and batch: 1100, loss is 3.9358936309814454 and perplexity is 51.207890473463515
At time: 1214.1450901031494 and batch: 1150, loss is 3.9637129163742064 and perplexity is 52.65245764322402
At time: 1215.2508754730225 and batch: 1200, loss is 3.9314898300170897 and perplexity is 50.98287693707731
At time: 1216.3568561077118 and batch: 1250, loss is 3.978978977203369 and perplexity is 53.46242000146626
At time: 1217.4636762142181 and batch: 1300, loss is 3.9845889949798585 and perplexity is 53.76318799612567
At time: 1218.5697765350342 and batch: 1350, loss is 3.9471930980682375 and perplexity is 51.78979375359461
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359779866536458 and perplexity of 78.23990930501886
Finished 38 epochs...
Completing Train Step...
At time: 1221.9694068431854 and batch: 50, loss is 4.065088305473328 and perplexity is 58.27005386005485
At time: 1223.1045548915863 and batch: 100, loss is 4.075221123695374 and perplexity is 58.86349526296306
At time: 1224.2103707790375 and batch: 150, loss is 4.06063554763794 and perplexity is 58.011168226422605
At time: 1225.3164069652557 and batch: 200, loss is 4.051882543563843 and perplexity is 57.50561203008166
At time: 1226.4225907325745 and batch: 250, loss is 4.050693550109863 and perplexity is 57.43727886570362
At time: 1227.529091835022 and batch: 300, loss is 4.062399611473084 and perplexity is 58.11359394651787
At time: 1228.6343176364899 and batch: 350, loss is 4.059207010269165 and perplexity is 57.92835626887583
At time: 1229.7394258975983 and batch: 400, loss is 4.068370032310486 and perplexity is 58.46159437953833
At time: 1230.8462245464325 and batch: 450, loss is 4.015291366577149 and perplexity is 55.43944625116407
At time: 1231.9519910812378 and batch: 500, loss is 4.094163155555725 and perplexity is 59.989116587209104
At time: 1233.0590076446533 and batch: 550, loss is 4.089432220458985 and perplexity is 59.705982243313144
At time: 1234.1643760204315 and batch: 600, loss is 4.031891736984253 and perplexity is 56.367442826796335
At time: 1235.2716307640076 and batch: 650, loss is 4.047367453575134 and perplexity is 57.24655429150763
At time: 1236.3779182434082 and batch: 700, loss is 4.080855665206909 and perplexity is 59.196100228816775
At time: 1237.4829647541046 and batch: 750, loss is 4.039275784492492 and perplexity is 56.785203185547815
At time: 1238.5890097618103 and batch: 800, loss is 4.016434984207153 and perplexity is 55.5028840466713
At time: 1239.7256836891174 and batch: 850, loss is 3.976153769493103 and perplexity is 53.31159072261348
At time: 1240.8290088176727 and batch: 900, loss is 4.0089040899276736 and perplexity is 55.08646765667842
At time: 1241.929748058319 and batch: 950, loss is 4.001333847045898 and perplexity is 54.67102420497236
At time: 1243.031078338623 and batch: 1000, loss is 4.0159557867050175 and perplexity is 55.47629357482747
At time: 1244.1317145824432 and batch: 1050, loss is 3.9610316133499146 and perplexity is 52.51146954967779
At time: 1245.2330884933472 and batch: 1100, loss is 3.935128173828125 and perplexity is 51.16870802554983
At time: 1246.3344328403473 and batch: 1150, loss is 3.9629829025268553 and perplexity is 52.61403464641363
At time: 1247.4358539581299 and batch: 1200, loss is 3.9308666086196897 and perplexity is 50.95111321621246
At time: 1248.5370125770569 and batch: 1250, loss is 3.9783952140808108 and perplexity is 53.431219719899616
At time: 1249.637110710144 and batch: 1300, loss is 3.983997354507446 and perplexity is 53.73138892591728
At time: 1250.7375764846802 and batch: 1350, loss is 3.9466907167434693 and perplexity is 51.76378206284012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359661458333333 and perplexity of 78.23064560640515
Finished 39 epochs...
Completing Train Step...
At time: 1254.151925086975 and batch: 50, loss is 4.0633666038513185 and perplexity is 58.16981652795882
At time: 1255.2547760009766 and batch: 100, loss is 4.073409337997436 and perplexity is 58.756943777490605
At time: 1256.35449385643 and batch: 150, loss is 4.05879047870636 and perplexity is 57.90423230465349
At time: 1257.453543663025 and batch: 200, loss is 4.050096001625061 and perplexity is 57.402967559101825
At time: 1258.5527658462524 and batch: 250, loss is 4.04884295463562 and perplexity is 57.33108398956764
At time: 1259.6519706249237 and batch: 300, loss is 4.060721368789673 and perplexity is 58.01614702533323
At time: 1260.7514867782593 and batch: 350, loss is 4.057610402107239 and perplexity is 57.835941177426335
At time: 1261.8510558605194 and batch: 400, loss is 4.066784143447876 and perplexity is 58.368954265999726
At time: 1262.9541013240814 and batch: 450, loss is 4.013814902305603 and perplexity is 55.357652287331426
At time: 1264.0530219078064 and batch: 500, loss is 4.092765922546387 and perplexity is 59.905356343228135
At time: 1265.1516280174255 and batch: 550, loss is 4.088093090057373 and perplexity is 59.62608165792479
At time: 1266.2501192092896 and batch: 600, loss is 4.030539340972901 and perplexity is 56.291263246038696
At time: 1267.3813860416412 and batch: 650, loss is 4.046015253067017 and perplexity is 57.169197784247736
At time: 1268.484789609909 and batch: 700, loss is 4.079576625823974 and perplexity is 59.120434485356284
At time: 1269.587794303894 and batch: 750, loss is 4.038018651008606 and perplexity is 56.713861457667065
At time: 1270.6910212039948 and batch: 800, loss is 4.015258355140686 and perplexity is 55.437616145614
At time: 1271.7943224906921 and batch: 850, loss is 3.974914355278015 and perplexity is 53.24555650956728
At time: 1272.896785736084 and batch: 900, loss is 4.007800312042236 and perplexity is 55.02569797617661
At time: 1274.0019855499268 and batch: 950, loss is 4.000333094596863 and perplexity is 54.61633941114259
At time: 1275.1054673194885 and batch: 1000, loss is 4.01497640132904 and perplexity is 55.42198750181457
At time: 1276.2088060379028 and batch: 1050, loss is 3.960145092010498 and perplexity is 52.46493764017079
At time: 1277.3117942810059 and batch: 1100, loss is 3.934289855957031 and perplexity is 51.125830358239746
At time: 1278.4109604358673 and batch: 1150, loss is 3.9621986675262453 and perplexity is 52.572789054153056
At time: 1279.5105471611023 and batch: 1200, loss is 3.930163016319275 and perplexity is 50.91527701377241
At time: 1280.60959815979 and batch: 1250, loss is 3.9777358055114744 and perplexity is 53.39599832966574
At time: 1281.7093875408173 and batch: 1300, loss is 3.9833342361450197 and perplexity is 53.69577046621436
At time: 1282.8084256649017 and batch: 1350, loss is 3.9461046123504637 and perplexity is 51.73345197194251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359576416015625 and perplexity of 78.22399297386865
Finished 40 epochs...
Completing Train Step...
At time: 1286.2015841007233 and batch: 50, loss is 4.06174861907959 and perplexity is 58.075774750240264
At time: 1287.304372549057 and batch: 100, loss is 4.071709079742432 and perplexity is 58.65712668026245
At time: 1288.4072678089142 and batch: 150, loss is 4.057084994316101 and perplexity is 57.80556170482861
At time: 1289.512243270874 and batch: 200, loss is 4.048425941467285 and perplexity is 57.307181156833494
At time: 1290.6153752803802 and batch: 250, loss is 4.047140817642212 and perplexity is 57.23358163535975
At time: 1291.7179605960846 and batch: 300, loss is 4.05911838054657 and perplexity is 57.92322232224284
At time: 1292.821357011795 and batch: 350, loss is 4.056102333068847 and perplexity is 57.74878631951964
At time: 1293.9252438545227 and batch: 400, loss is 4.065296511650086 and perplexity is 58.282187308274146
At time: 1295.0299925804138 and batch: 450, loss is 4.012445640563965 and perplexity is 55.28190504268431
At time: 1296.1642363071442 and batch: 500, loss is 4.091433100700378 and perplexity is 59.825566360328764
At time: 1297.2671911716461 and batch: 550, loss is 4.086828837394714 and perplexity is 59.55074685657065
At time: 1298.3704929351807 and batch: 600, loss is 4.029292130470276 and perplexity is 56.22109995460435
At time: 1299.474478006363 and batch: 650, loss is 4.044755749702453 and perplexity is 57.09723831339964
At time: 1300.5786318778992 and batch: 700, loss is 4.078359460830688 and perplexity is 59.048518937535
At time: 1301.6817948818207 and batch: 750, loss is 4.036823673248291 and perplexity is 56.64613013129776
At time: 1302.7853937149048 and batch: 800, loss is 4.014092597961426 and perplexity is 55.373027001535064
At time: 1303.8904919624329 and batch: 850, loss is 3.9737048816680907 and perplexity is 53.1811963429304
At time: 1304.9929604530334 and batch: 900, loss is 4.0066588020324705 and perplexity is 54.962921427988256
At time: 1306.0959913730621 and batch: 950, loss is 3.999335107803345 and perplexity is 54.56186021498077
At time: 1307.1998081207275 and batch: 1000, loss is 4.013900666236878 and perplexity is 55.362400180813836
At time: 1308.303457736969 and batch: 1050, loss is 3.959178023338318 and perplexity is 52.414224967861735
At time: 1309.4060912132263 and batch: 1100, loss is 3.93339873790741 and perplexity is 51.08029150126784
At time: 1310.5100831985474 and batch: 1150, loss is 3.9613325119018556 and perplexity is 52.527272552256655
At time: 1311.6127727031708 and batch: 1200, loss is 3.9293902778625487 and perplexity is 50.87594801865951
At time: 1312.7150094509125 and batch: 1250, loss is 3.9770321655273437 and perplexity is 53.35843998557436
At time: 1313.8196229934692 and batch: 1300, loss is 3.9826237630844115 and perplexity is 53.65763461668054
At time: 1314.9221839904785 and batch: 1350, loss is 3.945470857620239 and perplexity is 51.700676039092706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359501953125 and perplexity of 78.21816840609534
Finished 41 epochs...
Completing Train Step...
At time: 1318.3152372837067 and batch: 50, loss is 4.060208592414856 and perplexity is 57.986405341848766
At time: 1319.448519706726 and batch: 100, loss is 4.070078473091126 and perplexity is 58.561557918056266
At time: 1320.5516138076782 and batch: 150, loss is 4.055459699630737 and perplexity is 57.71168694034801
At time: 1321.655860900879 and batch: 200, loss is 4.0468202543258665 and perplexity is 57.21523758899562
At time: 1322.75879240036 and batch: 250, loss is 4.045485816001892 and perplexity is 57.13893830290963
At time: 1323.8936228752136 and batch: 300, loss is 4.057603969573974 and perplexity is 57.83556914700739
At time: 1324.9960989952087 and batch: 350, loss is 4.054657416343689 and perplexity is 57.66540438679052
At time: 1326.0998034477234 and batch: 400, loss is 4.063860507011413 and perplexity is 58.1985538803145
At time: 1327.2028903961182 and batch: 450, loss is 4.011142883300781 and perplexity is 55.209933030577176
At time: 1328.3056871891022 and batch: 500, loss is 4.0901662588119505 and perplexity is 59.74982481327657
At time: 1329.4089589118958 and batch: 550, loss is 4.0856148147583005 and perplexity is 59.47849476858067
At time: 1330.5122928619385 and batch: 600, loss is 4.028071441650391 and perplexity is 56.152513356411525
At time: 1331.6155812740326 and batch: 650, loss is 4.0434650754928585 and perplexity is 57.02359191744498
At time: 1332.7199053764343 and batch: 700, loss is 4.0771331167221065 and perplexity is 58.97614951819083
At time: 1333.821992635727 and batch: 750, loss is 4.035596737861633 and perplexity is 56.576671608995305
At time: 1334.9258151054382 and batch: 800, loss is 4.012938213348389 and perplexity is 55.3091421121483
At time: 1336.0297682285309 and batch: 850, loss is 3.972511954307556 and perplexity is 53.11779286413825
At time: 1337.1332788467407 and batch: 900, loss is 4.005555334091187 and perplexity is 54.90230505649526
At time: 1338.2364134788513 and batch: 950, loss is 3.9983101320266723 and perplexity is 54.50596428081307
At time: 1339.3390016555786 and batch: 1000, loss is 4.012894344329834 and perplexity is 55.306715807586926
At time: 1340.4423735141754 and batch: 1050, loss is 3.9582349824905396 and perplexity is 52.36481951205532
At time: 1341.5454256534576 and batch: 1100, loss is 3.9325070142745973 and perplexity is 51.03476230091413
At time: 1342.6478629112244 and batch: 1150, loss is 3.9604790878295897 and perplexity is 52.482463636633355
At time: 1343.7521917819977 and batch: 1200, loss is 3.928635473251343 and perplexity is 50.8375611076268
At time: 1344.855798482895 and batch: 1250, loss is 3.976294603347778 and perplexity is 53.31909932815433
At time: 1345.9589095115662 and batch: 1300, loss is 3.98187331199646 and perplexity is 53.61738229199507
At time: 1347.0626437664032 and batch: 1350, loss is 3.944796929359436 and perplexity is 51.66584523045876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359432779947917 and perplexity of 78.21275799401093
Finished 42 epochs...
Completing Train Step...
At time: 1350.4558882713318 and batch: 50, loss is 4.058729782104492 and perplexity is 57.900717821178496
At time: 1351.590754032135 and batch: 100, loss is 4.068526229858398 and perplexity is 58.47072665042808
At time: 1352.694396018982 and batch: 150, loss is 4.053914270401001 and perplexity is 57.62256649486129
At time: 1353.7989211082458 and batch: 200, loss is 4.045299124717713 and perplexity is 57.12827195682911
At time: 1354.9028561115265 and batch: 250, loss is 4.043963294029236 and perplexity is 57.05200920637133
At time: 1356.0066990852356 and batch: 300, loss is 4.056155271530152 and perplexity is 57.751843532330945
At time: 1357.1102237701416 and batch: 350, loss is 4.0533020973205565 and perplexity is 57.58730230582192
At time: 1358.2172513008118 and batch: 400, loss is 4.062480373382568 and perplexity is 58.118287500859644
At time: 1359.321188211441 and batch: 450, loss is 4.009857201576233 and perplexity is 55.13899623950559
At time: 1360.4252879619598 and batch: 500, loss is 4.088940758705139 and perplexity is 59.67664624591558
At time: 1361.5296566486359 and batch: 550, loss is 4.08442551612854 and perplexity is 59.407799123701835
At time: 1362.6332039833069 and batch: 600, loss is 4.026880655288696 and perplexity is 56.085687504884596
At time: 1363.7381992340088 and batch: 650, loss is 4.042246913909912 and perplexity is 56.95417026043199
At time: 1364.84281873703 and batch: 700, loss is 4.07593801021576 and perplexity is 58.90570883862367
At time: 1365.9464852809906 and batch: 750, loss is 4.03440447807312 and perplexity is 56.5092577138918
At time: 1367.0508260726929 and batch: 800, loss is 4.01179901599884 and perplexity is 55.2461699597132
At time: 1368.1549854278564 and batch: 850, loss is 3.9713418245315553 and perplexity is 53.05567450343196
At time: 1369.2587776184082 and batch: 900, loss is 4.004456605911255 and perplexity is 54.84201547378335
At time: 1370.3617007732391 and batch: 950, loss is 3.997298550605774 and perplexity is 54.450854938511284
At time: 1371.4650666713715 and batch: 1000, loss is 4.0118584728240965 and perplexity is 55.249454819239254
At time: 1372.5699846744537 and batch: 1050, loss is 3.9572783088684083 and perplexity is 52.314747425641535
At time: 1373.6742534637451 and batch: 1100, loss is 3.9315953254699707 and perplexity is 50.98825568248056
At time: 1374.7783644199371 and batch: 1150, loss is 3.959598813056946 and perplexity is 52.436284975824826
At time: 1375.8829917907715 and batch: 1200, loss is 3.927836050987244 and perplexity is 50.79693666962848
At time: 1376.9864945411682 and batch: 1250, loss is 3.975529613494873 and perplexity is 53.27832635564576
At time: 1378.0899095535278 and batch: 1300, loss is 3.9810899686813355 and perplexity is 53.575397920237535
At time: 1379.1951761245728 and batch: 1350, loss is 3.9440867376327513 and perplexity is 51.62916560095031
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359369303385416 and perplexity of 78.20779347455677
Finished 43 epochs...
Completing Train Step...
At time: 1382.6185176372528 and batch: 50, loss is 4.057304334640503 and perplexity is 57.81824218610478
At time: 1383.723572731018 and batch: 100, loss is 4.067010746002198 and perplexity is 58.38218231882816
At time: 1384.8288779258728 and batch: 150, loss is 4.052430167198181 and perplexity is 57.53711208663691
At time: 1385.9350078105927 and batch: 200, loss is 4.043824634552002 and perplexity is 57.044098953028076
At time: 1387.042093038559 and batch: 250, loss is 4.042442460060119 and perplexity is 56.96530851815089
At time: 1388.1470806598663 and batch: 300, loss is 4.054743995666504 and perplexity is 57.67039723458776
At time: 1389.2539546489716 and batch: 350, loss is 4.051948070526123 and perplexity is 57.50938032161305
At time: 1390.3604953289032 and batch: 400, loss is 4.061133952140808 and perplexity is 58.04008846027201
At time: 1391.4659774303436 and batch: 450, loss is 4.008644118309021 and perplexity is 55.07214859987068
At time: 1392.571329832077 and batch: 500, loss is 4.087747626304626 and perplexity is 59.60548656562743
At time: 1393.6773817539215 and batch: 550, loss is 4.083280191421509 and perplexity is 59.3397968533489
At time: 1394.7837138175964 and batch: 600, loss is 4.025715508460999 and perplexity is 56.020377499270516
At time: 1395.888596534729 and batch: 650, loss is 4.04106481552124 and perplexity is 56.8868846045069
At time: 1396.9952754974365 and batch: 700, loss is 4.074766011238098 and perplexity is 58.83671184818524
At time: 1398.1002945899963 and batch: 750, loss is 4.033272724151612 and perplexity is 56.445339316643526
At time: 1399.2057027816772 and batch: 800, loss is 4.010670557022094 and perplexity is 55.18386208584313
At time: 1400.3120193481445 and batch: 850, loss is 3.970179853439331 and perplexity is 52.994061146782585
At time: 1401.419272661209 and batch: 900, loss is 4.003351626396179 and perplexity is 54.78144963828558
At time: 1402.5247037410736 and batch: 950, loss is 3.996282153129578 and perplexity is 54.3955393430529
At time: 1403.6297445297241 and batch: 1000, loss is 4.010825228691101 and perplexity is 55.192398126018965
At time: 1404.7357404232025 and batch: 1050, loss is 3.9563101959228515 and perplexity is 52.26412534931272
At time: 1405.8419337272644 and batch: 1100, loss is 3.9306725883483886 and perplexity is 50.94122862633957
At time: 1406.9490206241608 and batch: 1150, loss is 3.958699440956116 and perplexity is 52.38914644476366
At time: 1408.0854337215424 and batch: 1200, loss is 3.9270280981063843 and perplexity is 50.75591171365481
At time: 1409.1910963058472 and batch: 1250, loss is 3.974748229980469 and perplexity is 53.236711810333595
At time: 1410.2958533763885 and batch: 1300, loss is 3.980294733047485 and perplexity is 53.53280979075711
At time: 1411.4021356105804 and batch: 1350, loss is 3.9433632469177247 and perplexity is 51.59182588810997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359320882161458 and perplexity of 78.20400664915573
Finished 44 epochs...
Completing Train Step...
At time: 1414.818325996399 and batch: 50, loss is 4.0559196949005125 and perplexity is 57.73824015005854
At time: 1415.9256811141968 and batch: 100, loss is 4.06555184841156 and perplexity is 58.29707079330262
At time: 1417.0309569835663 and batch: 150, loss is 4.050978331565857 and perplexity is 57.453638266923804
At time: 1418.1360120773315 and batch: 200, loss is 4.0423967647552494 and perplexity is 56.96270553048376
At time: 1419.2422933578491 and batch: 250, loss is 4.040932660102844 and perplexity is 56.87936719121513
At time: 1420.347648859024 and batch: 300, loss is 4.053370251655578 and perplexity is 57.59122726386621
At time: 1421.4540555477142 and batch: 350, loss is 4.050623931884766 and perplexity is 57.43328032348187
At time: 1422.560429096222 and batch: 400, loss is 4.059819374084473 and perplexity is 57.963840361613514
At time: 1423.6668300628662 and batch: 450, loss is 4.0074044132232665 and perplexity is 55.003917679016304
At time: 1424.7723834514618 and batch: 500, loss is 4.086571440696717 and perplexity is 59.53542066350684
At time: 1425.8797252178192 and batch: 550, loss is 4.082141189575196 and perplexity is 59.272247192070346
At time: 1426.985121011734 and batch: 600, loss is 4.024576549530029 and perplexity is 55.95660891179608
At time: 1428.090502500534 and batch: 650, loss is 4.039891324043274 and perplexity is 56.820167483857965
At time: 1429.1974737644196 and batch: 700, loss is 4.0736326265335085 and perplexity is 58.7700649943049
At time: 1430.3039543628693 and batch: 750, loss is 4.032122869491577 and perplexity is 56.380472680941736
At time: 1431.4098160266876 and batch: 800, loss is 4.009546508789063 and perplexity is 55.12186761209043
At time: 1432.5158307552338 and batch: 850, loss is 3.9690476560592653 and perplexity is 52.93409536255076
At time: 1433.6227390766144 and batch: 900, loss is 4.002297854423523 and perplexity is 54.72375288698404
At time: 1434.7288000583649 and batch: 950, loss is 3.9952851581573485 and perplexity is 54.34133428938915
At time: 1435.8647165298462 and batch: 1000, loss is 4.009810199737549 and perplexity is 55.136404666203966
At time: 1436.9712963104248 and batch: 1050, loss is 3.9553281021118165 and perplexity is 52.21282227160907
At time: 1438.0768892765045 and batch: 1100, loss is 3.9297403144836425 and perplexity is 50.89375958076655
At time: 1439.1817047595978 and batch: 1150, loss is 3.957796139717102 and perplexity is 52.34184463097907
At time: 1440.2881059646606 and batch: 1200, loss is 3.9261940813064573 and perplexity is 50.713598078184155
At time: 1441.395887851715 and batch: 1250, loss is 3.973958764076233 and perplexity is 53.19469982720186
At time: 1442.5026223659515 and batch: 1300, loss is 3.979494404792786 and perplexity is 53.48998311051522
At time: 1443.608033657074 and batch: 1350, loss is 3.942628879547119 and perplexity is 51.55395244280109
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359252522786458 and perplexity of 78.19866085485839
Finished 45 epochs...
Completing Train Step...
At time: 1447.0046532154083 and batch: 50, loss is 4.05456015586853 and perplexity is 57.65979609489661
At time: 1448.141483783722 and batch: 100, loss is 4.064120211601257 and perplexity is 58.213670274693044
At time: 1449.2468132972717 and batch: 150, loss is 4.049594416618347 and perplexity is 57.374182310961224
At time: 1450.3531398773193 and batch: 200, loss is 4.040993804931641 and perplexity is 56.88284517671343
At time: 1451.4593122005463 and batch: 250, loss is 4.039462018013 and perplexity is 56.79577947864941
At time: 1452.56489944458 and batch: 300, loss is 4.052040719985962 and perplexity is 57.51470878147119
At time: 1453.6697361469269 and batch: 350, loss is 4.049333281517029 and perplexity is 57.35920185409712
At time: 1454.7755570411682 and batch: 400, loss is 4.058518986701966 and perplexity is 57.888513902369006
At time: 1455.882262468338 and batch: 450, loss is 4.006208095550537 and perplexity is 54.938154864679234
At time: 1456.9882192611694 and batch: 500, loss is 4.085418109893799 and perplexity is 59.46679620994586
At time: 1458.093862771988 and batch: 550, loss is 4.081033215522766 and perplexity is 59.20661144821749
At time: 1459.2003283500671 and batch: 600, loss is 4.02347496509552 and perplexity is 55.89500192129179
At time: 1460.3058876991272 and batch: 650, loss is 4.038757214546203 and perplexity is 56.755763719652734
At time: 1461.4130594730377 and batch: 700, loss is 4.072501177787781 and perplexity is 58.70360728181828
At time: 1462.5191819667816 and batch: 750, loss is 4.031006393432617 and perplexity is 56.31756035958604
At time: 1463.6550345420837 and batch: 800, loss is 4.008438091278077 and perplexity is 55.0608034173542
At time: 1464.7615704536438 and batch: 850, loss is 3.967922053337097 and perplexity is 52.87454612139644
At time: 1465.8681859970093 and batch: 900, loss is 4.001210598945618 and perplexity is 54.664286520310675
At time: 1466.9733333587646 and batch: 950, loss is 3.994271559715271 and perplexity is 54.28628190283295
At time: 1468.0785882472992 and batch: 1000, loss is 4.008765139579773 and perplexity is 55.07881390459099
At time: 1469.1859140396118 and batch: 1050, loss is 3.9543591356277465 and perplexity is 52.16225430008048
At time: 1470.2918009757996 and batch: 1100, loss is 3.9287999773025515 and perplexity is 50.84592478029273
At time: 1471.395502090454 and batch: 1150, loss is 3.9568935012817383 and perplexity is 52.29462018674291
At time: 1472.4962329864502 and batch: 1200, loss is 3.925377187728882 and perplexity is 50.672187381987065
At time: 1473.5967972278595 and batch: 1250, loss is 3.973167643547058 and perplexity is 53.152633050264704
At time: 1474.6969487667084 and batch: 1300, loss is 3.978698787689209 and perplexity is 53.447442490349005
At time: 1475.799899339676 and batch: 1350, loss is 3.9418865966796877 and perplexity is 51.51569902633867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359216715494791 and perplexity of 78.19586082273229
Finished 46 epochs...
Completing Train Step...
At time: 1479.1660306453705 and batch: 50, loss is 4.053244533538819 and perplexity is 57.58398745832962
At time: 1480.2919192314148 and batch: 100, loss is 4.06272671699524 and perplexity is 58.13260633336893
At time: 1481.3903441429138 and batch: 150, loss is 4.048203363418579 and perplexity is 57.2944272556966
At time: 1482.489631652832 and batch: 200, loss is 4.039618525505066 and perplexity is 56.80466913928663
At time: 1483.596774339676 and batch: 250, loss is 4.038106961250305 and perplexity is 56.71887009363374
At time: 1484.6971278190613 and batch: 300, loss is 4.050711975097657 and perplexity is 57.43833715661506
At time: 1485.8001284599304 and batch: 350, loss is 4.048083701133728 and perplexity is 57.287571683806846
At time: 1486.9046835899353 and batch: 400, loss is 4.057252192497254 and perplexity is 57.815227497635135
At time: 1488.008787870407 and batch: 450, loss is 4.005043926239014 and perplexity is 54.87423476488254
At time: 1489.112187385559 and batch: 500, loss is 4.084276146888733 and perplexity is 59.398926088603865
At time: 1490.2147853374481 and batch: 550, loss is 4.079915170669556 and perplexity is 59.14045279207591
At time: 1491.3195352554321 and batch: 600, loss is 4.02241762638092 and perplexity is 55.83593320513105
At time: 1492.451014995575 and batch: 650, loss is 4.0376775932312015 and perplexity is 56.69452205224505
At time: 1493.554973602295 and batch: 700, loss is 4.071410245895386 and perplexity is 58.63960056426871
At time: 1494.6591260433197 and batch: 750, loss is 4.02996027469635 and perplexity is 56.258676309737005
At time: 1495.7617645263672 and batch: 800, loss is 4.007338790893555 and perplexity is 55.000308312223765
At time: 1496.8658471107483 and batch: 850, loss is 3.966804304122925 and perplexity is 52.81547865647551
At time: 1497.9698572158813 and batch: 900, loss is 4.00012571811676 and perplexity is 54.605014441226196
At time: 1499.073840379715 and batch: 950, loss is 3.993268232345581 and perplexity is 54.23184230533709
At time: 1500.176885843277 and batch: 1000, loss is 4.007731928825378 and perplexity is 55.021935270593566
At time: 1501.2791755199432 and batch: 1050, loss is 3.9533760929107666 and perplexity is 52.11100177172931
At time: 1502.3838648796082 and batch: 1100, loss is 3.9279097652435304 and perplexity is 50.80068126605009
At time: 1503.487645149231 and batch: 1150, loss is 3.9560006856918335 and perplexity is 52.24795157090596
At time: 1504.5912404060364 and batch: 1200, loss is 3.924516339302063 and perplexity is 50.62858507937527
At time: 1505.6962728500366 and batch: 1250, loss is 3.9723550605773927 and perplexity is 53.10945966920787
At time: 1506.7999093532562 and batch: 1300, loss is 3.977849850654602 and perplexity is 53.40208823119292
At time: 1507.904688835144 and batch: 1350, loss is 3.941093711853027 and perplexity is 51.474869199060166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359200032552083 and perplexity of 78.19455629654786
Finished 47 epochs...
Completing Train Step...
At time: 1511.3267650604248 and batch: 50, loss is 4.0519412326812745 and perplexity is 57.508987082737534
At time: 1512.4310059547424 and batch: 100, loss is 4.06134831905365 and perplexity is 58.05253166851473
At time: 1513.5350034236908 and batch: 150, loss is 4.0468552303314205 and perplexity is 57.217238784460015
At time: 1514.6378231048584 and batch: 200, loss is 4.038272972106934 and perplexity is 56.72828682346305
At time: 1515.7415211200714 and batch: 250, loss is 4.036676297187805 and perplexity is 56.63778246293558
At time: 1516.8434319496155 and batch: 300, loss is 4.049421691894532 and perplexity is 57.364273226963974
At time: 1517.942940711975 and batch: 350, loss is 4.046829538345337 and perplexity is 57.21576877884119
At time: 1519.0427961349487 and batch: 400, loss is 4.055980868339539 and perplexity is 57.74177230480777
At time: 1520.1758584976196 and batch: 450, loss is 4.003856201171875 and perplexity is 54.809097950683025
At time: 1521.2794306278229 and batch: 500, loss is 4.083150715827942 and perplexity is 59.33211429529176
At time: 1522.3828601837158 and batch: 550, loss is 4.0788449907302855 and perplexity is 59.077195720160454
At time: 1523.4872436523438 and batch: 600, loss is 4.021380729675293 and perplexity is 55.77806711569836
At time: 1524.5906779766083 and batch: 650, loss is 4.036500611305237 and perplexity is 56.62783287816326
At time: 1525.6930890083313 and batch: 700, loss is 4.070282783508301 and perplexity is 58.57352387672828
At time: 1526.7985122203827 and batch: 750, loss is 4.028889055252075 and perplexity is 56.198443188969776
At time: 1527.9026877880096 and batch: 800, loss is 4.006224632263184 and perplexity is 54.93906336867136
At time: 1529.0060503482819 and batch: 850, loss is 3.965706844329834 and perplexity is 52.75754758652164
At time: 1530.1091811656952 and batch: 900, loss is 3.999085102081299 and perplexity is 54.548221142715654
At time: 1531.2141036987305 and batch: 950, loss is 3.99225661277771 and perplexity is 54.17700805283706
At time: 1532.3177697658539 and batch: 1000, loss is 4.006715965270996 and perplexity is 54.966063376377036
At time: 1533.420931339264 and batch: 1050, loss is 3.9523963832855227 and perplexity is 52.05997312242346
At time: 1534.5281455516815 and batch: 1100, loss is 3.9269339179992677 and perplexity is 50.75113174154549
At time: 1535.6320099830627 and batch: 1150, loss is 3.9550770854949953 and perplexity is 52.19971763041792
At time: 1536.734739780426 and batch: 1200, loss is 3.9236873292922976 and perplexity is 50.586630868197496
At time: 1537.8382439613342 and batch: 1250, loss is 3.9715400409698485 and perplexity is 53.06619205260441
At time: 1538.9386518001556 and batch: 1300, loss is 3.977025184631348 and perplexity is 53.358067497154465
At time: 1540.0378489494324 and batch: 1350, loss is 3.9403364658355713 and perplexity is 51.43590481403473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359160970052083 and perplexity of 78.19150188134947
Finished 48 epochs...
Completing Train Step...
At time: 1543.4354169368744 and batch: 50, loss is 4.050671596527099 and perplexity is 57.43601792548942
At time: 1544.5340349674225 and batch: 100, loss is 4.060018200874328 and perplexity is 57.97536627171219
At time: 1545.6330723762512 and batch: 150, loss is 4.0455447816848755 and perplexity is 57.14230763876822
At time: 1546.7322340011597 and batch: 200, loss is 4.036947808265686 and perplexity is 56.653162336109375
At time: 1547.8636195659637 and batch: 250, loss is 4.035325436592102 and perplexity is 56.56132436811906
At time: 1548.963972568512 and batch: 300, loss is 4.048155026435852 and perplexity is 57.2916578828881
At time: 1550.0670704841614 and batch: 350, loss is 4.045609803199768 and perplexity is 57.14602323897101
At time: 1551.170912027359 and batch: 400, loss is 4.054745264053345 and perplexity is 57.67047038300711
At time: 1552.274024963379 and batch: 450, loss is 4.002712688446045 and perplexity is 54.746458870803345
At time: 1553.3780274391174 and batch: 500, loss is 4.082031636238098 and perplexity is 59.26575407527101
At time: 1554.4816780090332 and batch: 550, loss is 4.077759075164795 and perplexity is 59.01307769344474
At time: 1555.5849692821503 and batch: 600, loss is 4.020306553840637 and perplexity is 55.71818383224489
At time: 1556.6890223026276 and batch: 650, loss is 4.035400805473327 and perplexity is 56.565587492508726
At time: 1557.7917404174805 and batch: 700, loss is 4.069195895195008 and perplexity is 58.509895582846596
At time: 1558.8945896625519 and batch: 750, loss is 4.027846674919129 and perplexity is 56.139893557840836
At time: 1559.9987969398499 and batch: 800, loss is 4.005142817497253 and perplexity is 54.879661615332964
At time: 1561.1012213230133 and batch: 850, loss is 3.964619221687317 and perplexity is 52.70019847595175
At time: 1562.2051763534546 and batch: 900, loss is 3.9980506086349488 and perplexity is 54.49182054348847
At time: 1563.3103053569794 and batch: 950, loss is 3.9912839555740356 and perplexity is 54.124338014779326
At time: 1564.4128861427307 and batch: 1000, loss is 4.005689678192138 and perplexity is 54.90968135277809
At time: 1565.5155220031738 and batch: 1050, loss is 3.9514160776138305 and perplexity is 52.00896344212788
At time: 1566.6204931735992 and batch: 1100, loss is 3.925967326164246 and perplexity is 50.70209981273456
At time: 1567.7241094112396 and batch: 1150, loss is 3.954122929573059 and perplexity is 52.14993471482623
At time: 1568.8286051750183 and batch: 1200, loss is 3.922837495803833 and perplexity is 50.54365891730483
At time: 1569.9320142269135 and batch: 1250, loss is 3.9707244300842284 and perplexity is 53.02292833428603
At time: 1571.0316274166107 and batch: 1300, loss is 3.97618727684021 and perplexity is 53.31337708251656
At time: 1572.1303820610046 and batch: 1350, loss is 3.9395564079284666 and perplexity is 51.39579747483274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359133707682291 and perplexity of 78.18937022476773
Finished 49 epochs...
Completing Train Step...
At time: 1575.4969487190247 and batch: 50, loss is 4.049435596466065 and perplexity is 57.36507085814986
At time: 1576.6240808963776 and batch: 100, loss is 4.058678741455078 and perplexity is 57.89776260635807
At time: 1577.7274379730225 and batch: 150, loss is 4.044254651069641 and perplexity is 57.06863413269992
At time: 1578.8314862251282 and batch: 200, loss is 4.035643739700317 and perplexity is 56.57933087908236
At time: 1579.9352314472198 and batch: 250, loss is 4.03400173664093 and perplexity is 56.48650367681243
At time: 1581.0420339107513 and batch: 300, loss is 4.04690336227417 and perplexity is 57.219992827599675
At time: 1582.1471073627472 and batch: 350, loss is 4.044405169487 and perplexity is 57.07722465969042
At time: 1583.2525720596313 and batch: 400, loss is 4.053522047996521 and perplexity is 57.599970064981065
At time: 1584.3570017814636 and batch: 450, loss is 4.001564202308654 and perplexity is 54.68361941374887
At time: 1585.4628083705902 and batch: 500, loss is 4.0809415912628175 and perplexity is 59.201186934771776
At time: 1586.5679006576538 and batch: 550, loss is 4.076717624664306 and perplexity is 58.95165048639541
At time: 1587.6733074188232 and batch: 600, loss is 4.019255609512329 and perplexity is 55.65965788210718
At time: 1588.7780482769012 and batch: 650, loss is 4.0343044471740725 and perplexity is 56.503605324749664
At time: 1589.8835952281952 and batch: 700, loss is 4.068107538223266 and perplexity is 58.446250570601954
At time: 1590.9889013767242 and batch: 750, loss is 4.02693742275238 and perplexity is 56.08887143748423
At time: 1592.093938112259 and batch: 800, loss is 4.00405565738678 and perplexity is 54.820031056204314
At time: 1593.1984679698944 and batch: 850, loss is 3.9635387897491454 and perplexity is 52.64329024664052
At time: 1594.3038365840912 and batch: 900, loss is 3.9969911050796507 and perplexity is 54.43411683992545
At time: 1595.408986568451 and batch: 950, loss is 3.9902900886535644 and perplexity is 54.070572348018544
At time: 1596.5129475593567 and batch: 1000, loss is 4.004677805900574 and perplexity is 54.85414786881375
At time: 1597.6185841560364 and batch: 1050, loss is 3.9504367971420287 and perplexity is 51.95805700977613
At time: 1598.7226254940033 and batch: 1100, loss is 3.9250145769119262 and perplexity is 50.65381642967786
At time: 1599.8285593986511 and batch: 1150, loss is 3.9532270765304567 and perplexity is 52.10323695742759
At time: 1600.9326610565186 and batch: 1200, loss is 3.921990180015564 and perplexity is 50.50085061574337
At time: 1602.0381700992584 and batch: 1250, loss is 3.9698978328704833 and perplexity is 52.97911783877157
At time: 1603.144005060196 and batch: 1300, loss is 3.975337195396423 and perplexity is 53.268075627644244
At time: 1604.2492833137512 and batch: 1350, loss is 3.9387668895721437 and perplexity is 51.35523556358224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.359112548828125 and perplexity of 78.18771584478822
Finished Training.
Improved accuracyfrom -155.91248254449962 to -78.18771584478822
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2f1671c50>
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 3.7626052696443346, 'wordvec_source': 'glove', 'dropout': 0.025015537523082942, 'data': 'wikitext', 'lr': 27.819570388589018, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.587411642074585 and batch: 50, loss is 7.906950311660767 and perplexity is 2716.094580866385
At time: 2.6118111610412598 and batch: 100, loss is 7.124123048782349 and perplexity is 1241.5589029173484
At time: 3.6369645595550537 and batch: 150, loss is 7.165625143051147 and perplexity is 1294.1703895966318
At time: 4.662067174911499 and batch: 200, loss is 6.84737195968628 and perplexity is 941.4036062459977
At time: 5.687978506088257 and batch: 250, loss is 7.170249938964844 and perplexity is 1300.1695252222046
At time: 6.715630769729614 and batch: 300, loss is 6.856079730987549 and perplexity is 949.6369284704361
At time: 7.744016408920288 and batch: 350, loss is 6.958750476837158 and perplexity is 1052.3178398882396
At time: 8.773748397827148 and batch: 400, loss is 6.968287420272827 and perplexity is 1062.4017439848503
At time: 9.799312591552734 and batch: 450, loss is 6.481890363693237 and perplexity is 653.2045741123281
At time: 10.822572231292725 and batch: 500, loss is 6.513619871139526 and perplexity is 674.2627495944903
At time: 11.844775199890137 and batch: 550, loss is 6.609667634963989 and perplexity is 742.236284326583
At time: 12.867639303207397 and batch: 600, loss is 6.358966178894043 and perplexity is 577.6488620104122
At time: 13.897913217544556 and batch: 650, loss is 6.4466068553924565 and perplexity is 630.5590806099905
At time: 14.927143096923828 and batch: 700, loss is 6.4990753650665285 and perplexity is 664.5269040984685
At time: 15.95767879486084 and batch: 750, loss is 6.489875249862671 and perplexity is 658.4412174591786
At time: 16.991517305374146 and batch: 800, loss is 6.490463590621948 and perplexity is 658.8287192453679
At time: 18.038012504577637 and batch: 850, loss is 6.517387533187867 and perplexity is 676.8079354560344
At time: 19.06738257408142 and batch: 900, loss is 6.655721759796142 and perplexity is 777.2186858946336
At time: 20.09340786933899 and batch: 950, loss is 6.56718186378479 and perplexity is 711.3622998369702
At time: 21.121995449066162 and batch: 1000, loss is 6.5573473072052 and perplexity is 704.4006555030751
At time: 22.150927305221558 and batch: 1050, loss is 6.635368957519531 and perplexity is 761.5599972812728
At time: 23.17849564552307 and batch: 1100, loss is 6.798779048919678 and perplexity is 896.7517329775831
At time: 24.20550560951233 and batch: 1150, loss is 6.7928452301025395 and perplexity is 891.4463268963854
At time: 25.231850624084473 and batch: 1200, loss is 6.63752179145813 and perplexity is 763.2012755555832
At time: 26.25801110267639 and batch: 1250, loss is 6.611416711807251 and perplexity is 743.5356486364811
At time: 27.28521966934204 and batch: 1300, loss is 6.563833646774292 and perplexity is 708.9844874214008
At time: 28.316338539123535 and batch: 1350, loss is 6.581231241226196 and perplexity is 721.4270333532289
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.421663004557292 and perplexity of 615.025053612024
Finished 1 epochs...
Completing Train Step...
At time: 31.576630353927612 and batch: 50, loss is 6.721368188858032 and perplexity is 829.9522664685696
At time: 32.64469814300537 and batch: 100, loss is 6.759423151016235 and perplexity is 862.1447250117942
At time: 33.67413878440857 and batch: 150, loss is 6.599193267822265 and perplexity is 734.5024034409531
At time: 34.70337390899658 and batch: 200, loss is 6.52554690361023 and perplexity is 682.3528528608928
At time: 35.734208822250366 and batch: 250, loss is 6.619006280899048 and perplexity is 749.2002324986086
At time: 36.76262331008911 and batch: 300, loss is 6.684405336380005 and perplexity is 799.8349040074352
At time: 37.792020320892334 and batch: 350, loss is 6.58073205947876 and perplexity is 721.0670000145836
At time: 38.830504417419434 and batch: 400, loss is 6.6251735019683835 and perplexity is 753.8349930640283
At time: 39.90426564216614 and batch: 450, loss is 6.581331329345703 and perplexity is 721.4992432419745
At time: 41.01147270202637 and batch: 500, loss is 6.652127571105957 and perplexity is 774.4302294051969
At time: 42.12308740615845 and batch: 550, loss is 6.599322395324707 and perplexity is 734.5972540256247
At time: 43.2358934879303 and batch: 600, loss is 6.547283210754395 and perplexity is 697.3470529700443
At time: 44.34687852859497 and batch: 650, loss is 6.57261381149292 and perplexity is 715.2368964272531
At time: 45.45406937599182 and batch: 700, loss is 6.669581651687622 and perplexity is 788.0658494730503
At time: 46.56066536903381 and batch: 750, loss is 6.675773487091065 and perplexity is 792.9605614875162
At time: 47.66814422607422 and batch: 800, loss is 6.750384407043457 and perplexity is 854.3871318396878
At time: 48.776445388793945 and batch: 850, loss is 6.892331552505493 and perplexity is 984.694610014837
At time: 49.87874674797058 and batch: 900, loss is 6.863479928970337 and perplexity is 956.690496463225
At time: 50.98168587684631 and batch: 950, loss is 6.495135412216187 and perplexity is 661.9138504628485
At time: 52.083083629608154 and batch: 1000, loss is 6.725661869049072 and perplexity is 833.5234774069703
At time: 53.185667276382446 and batch: 1050, loss is 6.594743223190307 and perplexity is 731.241096825301
At time: 54.41279196739197 and batch: 1100, loss is 6.533883972167969 and perplexity is 688.0654554669005
At time: 55.514854431152344 and batch: 1150, loss is 6.479289207458496 and perplexity is 651.5076948426195
At time: 56.61578369140625 and batch: 1200, loss is 6.581374750137329 and perplexity is 721.5305719904284
At time: 57.71931600570679 and batch: 1250, loss is 6.463693351745605 and perplexity is 641.4256978764563
At time: 58.8225679397583 and batch: 1300, loss is 6.49838080406189 and perplexity is 664.0655098761146
At time: 59.938732624053955 and batch: 1350, loss is 6.480309295654297 and perplexity is 652.1726292398066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.068898111979166 and perplexity of 432.2041784893363
Finished 2 epochs...
Completing Train Step...
At time: 63.391902923583984 and batch: 50, loss is 6.4467097187042235 and perplexity is 630.6239453413302
At time: 64.4765784740448 and batch: 100, loss is 6.54102991104126 and perplexity is 692.9999389129931
At time: 65.57355999946594 and batch: 150, loss is 6.6424813747406 and perplexity is 766.9958377886484
At time: 66.6737334728241 and batch: 200, loss is 6.630763921737671 and perplexity is 758.0610488185207
At time: 67.7753221988678 and batch: 250, loss is 6.718167295455933 and perplexity is 827.2999249306323
At time: 68.87538719177246 and batch: 300, loss is 6.826004610061646 and perplexity is 921.501689066602
At time: 69.97566986083984 and batch: 350, loss is 6.663375329971314 and perplexity is 783.1900054566977
At time: 71.07551646232605 and batch: 400, loss is 6.606142597198486 and perplexity is 739.6244794533125
At time: 72.1757960319519 and batch: 450, loss is 6.670756530761719 and perplexity is 788.9922756614125
At time: 73.28173732757568 and batch: 500, loss is 6.759992580413819 and perplexity is 862.6357953648662
At time: 74.38140845298767 and batch: 550, loss is 6.6208602333068844 and perplexity is 750.590502422525
At time: 75.48081517219543 and batch: 600, loss is 6.547114725112915 and perplexity is 697.2295699018738
At time: 76.58113622665405 and batch: 650, loss is 6.54506947517395 and perplexity is 695.8050184450576
At time: 77.68055152893066 and batch: 700, loss is 6.713779926300049 and perplexity is 823.6782054769781
At time: 78.77993893623352 and batch: 750, loss is 6.655112161636352 and perplexity is 776.7450391957035
At time: 79.87972617149353 and batch: 800, loss is 6.695412864685059 and perplexity is 808.6877439073737
At time: 80.97958612442017 and batch: 850, loss is 6.654638624191284 and perplexity is 776.3773084083936
At time: 82.12102794647217 and batch: 900, loss is 6.7459601879119875 and perplexity is 850.6154853925977
At time: 83.221022605896 and batch: 950, loss is 6.757003183364868 and perplexity is 860.0608850960186
At time: 84.32088494300842 and batch: 1000, loss is 6.655944213867188 and perplexity is 777.3916005874792
At time: 85.42078614234924 and batch: 1050, loss is 6.708428812026978 and perplexity is 819.2823810439853
At time: 86.5202100276947 and batch: 1100, loss is 6.595990180969238 and perplexity is 732.1534923403799
At time: 87.61902642250061 and batch: 1150, loss is 6.51585391998291 and perplexity is 675.7707693780782
At time: 88.71821069717407 and batch: 1200, loss is 6.5345765209198 and perplexity is 688.5421393836358
At time: 89.81756114959717 and batch: 1250, loss is 6.552507772445678 and perplexity is 700.9999196731775
At time: 90.91863870620728 and batch: 1300, loss is 6.5498401641845705 and perplexity is 699.1324184846693
At time: 92.01868176460266 and batch: 1350, loss is 6.573902597427368 and perplexity is 716.1592779276486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.315671793619791 and perplexity of 553.1735542584468
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 95.39371991157532 and batch: 50, loss is 6.169491081237793 and perplexity is 477.9428101222377
At time: 96.52691316604614 and batch: 100, loss is 6.028178873062134 and perplexity is 414.95864848536075
At time: 97.63070011138916 and batch: 150, loss is 5.957246780395508 and perplexity is 386.54441618217953
At time: 98.7327446937561 and batch: 200, loss is 5.936517295837402 and perplexity is 378.614030063696
At time: 99.83577728271484 and batch: 250, loss is 5.975465612411499 and perplexity is 393.65134738005554
At time: 100.93822503089905 and batch: 300, loss is 5.95771502494812 and perplexity is 386.7254558815183
At time: 102.04141449928284 and batch: 350, loss is 5.940770502090454 and perplexity is 380.22778300320283
At time: 103.14450097084045 and batch: 400, loss is 5.96787205696106 and perplexity is 390.6734547512636
At time: 104.24911856651306 and batch: 450, loss is 5.94870153427124 and perplexity is 383.2553718686755
At time: 105.35144901275635 and batch: 500, loss is 5.966161823272705 and perplexity is 390.0058828624838
At time: 106.4542338848114 and batch: 550, loss is 5.935786619186401 and perplexity is 378.3374866763888
At time: 107.55682611465454 and batch: 600, loss is 5.874577121734619 and perplexity is 355.874137408593
At time: 108.66091322898865 and batch: 650, loss is 5.922404527664185 and perplexity is 373.30826560441034
At time: 109.76293396949768 and batch: 700, loss is 5.941682596206665 and perplexity is 380.5747447337227
At time: 110.89388298988342 and batch: 750, loss is 5.916414966583252 and perplexity is 371.078995783988
At time: 111.99568343162537 and batch: 800, loss is 5.886709327697754 and perplexity is 360.2179726114822
At time: 113.09834265708923 and batch: 850, loss is 5.896689167022705 and perplexity is 363.83088827269614
At time: 114.20231509208679 and batch: 900, loss is 5.932188215255738 and perplexity is 376.9785220953405
At time: 115.30275869369507 and batch: 950, loss is 5.899534149169922 and perplexity is 364.8674544614314
At time: 116.40447735786438 and batch: 1000, loss is 5.910895004272461 and perplexity is 369.0362967106306
At time: 117.50839567184448 and batch: 1050, loss is 5.870593824386597 and perplexity is 354.4594044224893
At time: 118.61080980300903 and batch: 1100, loss is 5.844964332580567 and perplexity is 345.49021881677334
At time: 119.71495842933655 and batch: 1150, loss is 5.844240112304687 and perplexity is 345.2400983772673
At time: 120.81592130661011 and batch: 1200, loss is 5.849587936401367 and perplexity is 347.0913273058721
At time: 121.91744875907898 and batch: 1250, loss is 5.852829494476318 and perplexity is 348.21826953819544
At time: 123.01898002624512 and batch: 1300, loss is 5.818327350616455 and perplexity is 336.4088886523713
At time: 124.12254619598389 and batch: 1350, loss is 5.825255298614502 and perplexity is 338.74760383345017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.59409423828125 and perplexity of 268.8340402003538
Finished 4 epochs...
Completing Train Step...
At time: 127.52645874023438 and batch: 50, loss is 5.882185869216919 and perplexity is 358.59222134962215
At time: 128.6210231781006 and batch: 100, loss is 5.90764232635498 and perplexity is 367.8378905687541
At time: 129.72339725494385 and batch: 150, loss is 5.868807554244995 and perplexity is 353.82680933302447
At time: 130.82497835159302 and batch: 200, loss is 5.851400547027588 and perplexity is 347.72103927290436
At time: 131.92954993247986 and batch: 250, loss is 5.8817360305786135 and perplexity is 358.43094898905247
At time: 133.03386330604553 and batch: 300, loss is 5.887514295578003 and perplexity is 360.50805324645614
At time: 134.13718700408936 and batch: 350, loss is 5.881246948242188 and perplexity is 358.25568960470173
At time: 135.23981356620789 and batch: 400, loss is 5.907853107452393 and perplexity is 367.9154320148466
At time: 136.34229111671448 and batch: 450, loss is 5.886984348297119 and perplexity is 360.31705359824355
At time: 137.44312810897827 and batch: 500, loss is 5.9142882347106935 and perplexity is 370.29064885482785
At time: 138.58695554733276 and batch: 550, loss is 5.8802053737640385 and perplexity is 357.8827338860543
At time: 139.69016981124878 and batch: 600, loss is 5.822843675613403 and perplexity is 337.9316565945001
At time: 140.79279398918152 and batch: 650, loss is 5.868131875991821 and perplexity is 353.5878170026209
At time: 141.89432072639465 and batch: 700, loss is 5.8890116500854495 and perplexity is 361.04826594898503
At time: 142.99701046943665 and batch: 750, loss is 5.860020837783813 and perplexity is 350.7314524099497
At time: 144.09795212745667 and batch: 800, loss is 5.833359289169311 and perplexity is 341.5039648921328
At time: 145.2003049850464 and batch: 850, loss is 5.843837080001831 and perplexity is 345.1009835011574
At time: 146.30302715301514 and batch: 900, loss is 5.870927028656006 and perplexity is 354.5775314885034
At time: 147.40440487861633 and batch: 950, loss is 5.841279554367065 and perplexity is 344.2195065696685
At time: 148.5061583518982 and batch: 1000, loss is 5.855301609039307 and perplexity is 349.0801699127054
At time: 149.60958576202393 and batch: 1050, loss is 5.8162630176544186 and perplexity is 335.7151450001124
At time: 150.71285247802734 and batch: 1100, loss is 5.79587721824646 and perplexity is 328.94061016233775
At time: 151.81580209732056 and batch: 1150, loss is 5.8002985572814945 and perplexity is 330.39818797066437
At time: 152.91771459579468 and batch: 1200, loss is 5.809375286102295 and perplexity is 333.4107742570078
At time: 154.01952123641968 and batch: 1250, loss is 5.810633850097656 and perplexity is 333.83065722252064
At time: 155.12171721458435 and batch: 1300, loss is 5.773229961395264 and perplexity is 321.57473098027054
At time: 156.22415900230408 and batch: 1350, loss is 5.768685340881348 and perplexity is 320.1166116701787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.571011555989584 and perplexity of 262.699700337779
Finished 5 epochs...
Completing Train Step...
At time: 159.6041235923767 and batch: 50, loss is 5.835446043014526 and perplexity is 342.2173436681098
At time: 160.73567080497742 and batch: 100, loss is 5.858608188629151 and perplexity is 350.2363417113801
At time: 161.83938455581665 and batch: 150, loss is 5.815504817962647 and perplexity is 335.46070235200807
At time: 162.9420464038849 and batch: 200, loss is 5.793139419555664 and perplexity is 328.04126866023347
At time: 164.04590511322021 and batch: 250, loss is 5.8198149871826175 and perplexity is 336.9097152479277
At time: 165.15027785301208 and batch: 300, loss is 5.82410945892334 and perplexity is 338.35967567787486
At time: 166.25274562835693 and batch: 350, loss is 5.826382722854614 and perplexity is 339.1297314627915
At time: 167.39067482948303 and batch: 400, loss is 5.860570287704467 and perplexity is 350.9242147304186
At time: 168.4934024810791 and batch: 450, loss is 5.840901584625244 and perplexity is 344.08942659633607
At time: 169.59609246253967 and batch: 500, loss is 5.865391864776611 and perplexity is 352.6203085158348
At time: 170.69799137115479 and batch: 550, loss is 5.827921152114868 and perplexity is 339.65186009069566
At time: 171.7997009754181 and batch: 600, loss is 5.771946649551392 and perplexity is 321.16231500506683
At time: 172.90135049819946 and batch: 650, loss is 5.814036121368408 and perplexity is 334.9683739899561
At time: 174.00249409675598 and batch: 700, loss is 5.832582874298096 and perplexity is 341.23891904129607
At time: 175.10601782798767 and batch: 750, loss is 5.8029851055145265 and perplexity is 331.2870120385248
At time: 176.20719623565674 and batch: 800, loss is 5.773702087402344 and perplexity is 321.72659061960803
At time: 177.30927515029907 and batch: 850, loss is 5.778475933074951 and perplexity is 323.26613556318296
At time: 178.4111738204956 and batch: 900, loss is 5.8076303100585935 and perplexity is 332.8294877562252
At time: 179.51373171806335 and batch: 950, loss is 5.786085805892944 and perplexity is 325.73553372723944
At time: 180.61528182029724 and batch: 1000, loss is 5.792705192565918 and perplexity is 327.8988552097502
At time: 181.719220161438 and batch: 1050, loss is 5.759886360168457 and perplexity is 317.3122675562541
At time: 182.82152271270752 and batch: 1100, loss is 5.742875871658325 and perplexity is 311.9602798893983
At time: 183.9249575138092 and batch: 1150, loss is 5.7473383808135985 and perplexity is 313.3555163067369
At time: 185.026043176651 and batch: 1200, loss is 5.751727781295776 and perplexity is 314.7339822674606
At time: 186.1276571750641 and batch: 1250, loss is 5.760135087966919 and perplexity is 317.39120175414615
At time: 187.23241090774536 and batch: 1300, loss is 5.72818211555481 and perplexity is 307.4099244002276
At time: 188.33579277992249 and batch: 1350, loss is 5.724782152175903 and perplexity is 306.3665166940771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.5405517578125 and perplexity of 254.81855880822138
Finished 6 epochs...
Completing Train Step...
At time: 191.73425340652466 and batch: 50, loss is 5.794930438995362 and perplexity is 328.62932340096876
At time: 192.86706137657166 and batch: 100, loss is 5.810746154785156 and perplexity is 333.86815007543004
At time: 193.97148871421814 and batch: 150, loss is 5.76751953125 and perplexity is 319.7436340938077
At time: 195.10360193252563 and batch: 200, loss is 5.752940769195557 and perplexity is 315.1159824135405
At time: 196.20859575271606 and batch: 250, loss is 5.778916873931885 and perplexity is 323.4087082407652
At time: 197.31505727767944 and batch: 300, loss is 5.784241323471069 and perplexity is 325.13527401552227
At time: 198.41838026046753 and batch: 350, loss is 5.783828134536743 and perplexity is 325.00095946869317
At time: 199.5221335887909 and batch: 400, loss is 5.815357427597046 and perplexity is 335.41126232002557
At time: 200.62604904174805 and batch: 450, loss is 5.799976625442505 and perplexity is 330.2918393938271
At time: 201.72891306877136 and batch: 500, loss is 5.81726655960083 and perplexity is 336.0522183354923
At time: 202.83355712890625 and batch: 550, loss is 5.783055362701416 and perplexity is 324.7499048972059
At time: 203.9370288848877 and batch: 600, loss is 5.729984197616577 and perplexity is 307.96440176740174
At time: 205.04066562652588 and batch: 650, loss is 5.773230514526367 and perplexity is 321.5749088533056
At time: 206.14349508285522 and batch: 700, loss is 5.791809015274048 and perplexity is 327.60513133567235
At time: 207.24848747253418 and batch: 750, loss is 5.767309236526489 and perplexity is 319.67640076433673
At time: 208.350998878479 and batch: 800, loss is 5.737489194869995 and perplexity is 310.2843685396125
At time: 209.45453453063965 and batch: 850, loss is 5.742763528823852 and perplexity is 311.92523535585065
At time: 210.55899024009705 and batch: 900, loss is 5.773667421340942 and perplexity is 321.7154378191759
At time: 211.66161561012268 and batch: 950, loss is 5.746691074371338 and perplexity is 313.1527448970137
At time: 212.76418209075928 and batch: 1000, loss is 5.749119482040405 and perplexity is 313.91413152871047
At time: 213.8688292503357 and batch: 1050, loss is 5.717791051864624 and perplexity is 304.2321471328916
At time: 214.97466206550598 and batch: 1100, loss is 5.692090873718262 and perplexity is 296.51294407319926
At time: 216.08024859428406 and batch: 1150, loss is 5.699494953155518 and perplexity is 298.7164970392671
At time: 217.18391513824463 and batch: 1200, loss is 5.70315541267395 and perplexity is 299.81194037400775
At time: 218.28849291801453 and batch: 1250, loss is 5.70044882774353 and perplexity is 299.0015710556278
At time: 219.3913323879242 and batch: 1300, loss is 5.66808590888977 and perplexity is 289.4799128352239
At time: 220.49676537513733 and batch: 1350, loss is 5.661853075027466 and perplexity is 287.6812438574235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4887076822916665 and perplexity of 241.94433578751597
Finished 7 epochs...
Completing Train Step...
At time: 223.90463209152222 and batch: 50, loss is 5.723503952026367 and perplexity is 305.97516913016506
At time: 225.00825905799866 and batch: 100, loss is 5.747936449050903 and perplexity is 313.54298034057854
At time: 226.11208581924438 and batch: 150, loss is 5.711003065109253 and perplexity is 302.1740165318862
At time: 227.21620750427246 and batch: 200, loss is 5.689766855239868 and perplexity is 295.8246426345179
At time: 228.32112002372742 and batch: 250, loss is 5.71443925857544 and perplexity is 303.2141309068316
At time: 229.4278678894043 and batch: 300, loss is 5.719507007598877 and perplexity is 304.75464419301386
At time: 230.53229928016663 and batch: 350, loss is 5.718245325088501 and perplexity is 304.37038304723666
At time: 231.63731908798218 and batch: 400, loss is 5.7570482349395755 and perplexity is 316.4129723641041
At time: 232.73995351791382 and batch: 450, loss is 5.73723611831665 and perplexity is 310.2058527767341
At time: 233.84194374084473 and batch: 500, loss is 5.753871412277221 and perplexity is 315.4093794252694
At time: 234.9458487033844 and batch: 550, loss is 5.726328315734864 and perplexity is 306.84057582991414
At time: 236.0498616695404 and batch: 600, loss is 5.672430830001831 and perplexity is 290.74041663178036
At time: 237.15355348587036 and batch: 650, loss is 5.709463987350464 and perplexity is 301.70930492913664
At time: 238.25798869132996 and batch: 700, loss is 5.725624732971191 and perplexity is 306.6247640192027
At time: 239.36295199394226 and batch: 750, loss is 5.7053234577178955 and perplexity is 300.46265129586146
At time: 240.46803545951843 and batch: 800, loss is 5.674500026702881 and perplexity is 291.34263858570534
At time: 241.57151794433594 and batch: 850, loss is 5.680452299118042 and perplexity is 293.0819606608441
At time: 242.67550921440125 and batch: 900, loss is 5.710659790039062 and perplexity is 302.07030552687115
At time: 243.77959060668945 and batch: 950, loss is 5.688230762481689 and perplexity is 295.3705773757377
At time: 244.88350558280945 and batch: 1000, loss is 5.697639827728271 and perplexity is 298.162854167336
At time: 245.98842549324036 and batch: 1050, loss is 5.663855895996094 and perplexity is 288.2579952570074
At time: 247.09398460388184 and batch: 1100, loss is 5.64647837638855 and perplexity is 283.2920590853982
At time: 248.19979190826416 and batch: 1150, loss is 5.661969451904297 and perplexity is 287.7147252502987
At time: 249.30341577529907 and batch: 1200, loss is 5.670346517562866 and perplexity is 290.13505386661495
At time: 250.4074878692627 and batch: 1250, loss is 5.670615091323852 and perplexity is 290.21298699415405
At time: 251.5118227005005 and batch: 1300, loss is 5.643148641586304 and perplexity is 282.35034036394205
At time: 252.61693215370178 and batch: 1350, loss is 5.63440465927124 and perplexity is 279.8922364513483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.476551106770834 and perplexity of 239.020926522694
Finished 8 epochs...
Completing Train Step...
At time: 256.0244562625885 and batch: 50, loss is 5.69949200630188 and perplexity is 298.7156167667682
At time: 257.15598344802856 and batch: 100, loss is 5.726337203979492 and perplexity is 306.84330311613434
At time: 258.25935435295105 and batch: 150, loss is 5.6859022235870365 and perplexity is 294.68359564023433
At time: 259.36352157592773 and batch: 200, loss is 5.666256732940674 and perplexity is 288.95088712897336
At time: 260.4680700302124 and batch: 250, loss is 5.691700143814087 and perplexity is 296.39711023032186
At time: 261.5721492767334 and batch: 300, loss is 5.700320119857788 and perplexity is 298.9630896720655
At time: 262.6759192943573 and batch: 350, loss is 5.6936722755432125 and perplexity is 296.98222114408776
At time: 263.7793273925781 and batch: 400, loss is 5.732004041671753 and perplexity is 308.58707046865925
At time: 264.8825480937958 and batch: 450, loss is 5.71083104133606 and perplexity is 302.12203988813883
At time: 265.98509645462036 and batch: 500, loss is 5.730109024047851 and perplexity is 308.00284626402856
At time: 267.0887966156006 and batch: 550, loss is 5.702293853759766 and perplexity is 299.55374596501827
At time: 268.1907410621643 and batch: 600, loss is 5.650641765594482 and perplexity is 284.47397286259667
At time: 269.2929458618164 and batch: 650, loss is 5.6934637928009035 and perplexity is 296.92031192993227
At time: 270.3948769569397 and batch: 700, loss is 5.7059738731384275 and perplexity is 300.6581404052322
At time: 271.49676489830017 and batch: 750, loss is 5.685473480224609 and perplexity is 294.5572790852147
At time: 272.5989761352539 and batch: 800, loss is 5.650764656066895 and perplexity is 284.50893415167144
At time: 273.70288348197937 and batch: 850, loss is 5.657799091339111 and perplexity is 286.5173495856052
At time: 274.8058166503906 and batch: 900, loss is 5.689044466018677 and perplexity is 295.6110192702138
At time: 275.9086196422577 and batch: 950, loss is 5.666755456924438 and perplexity is 289.09502980723215
At time: 277.01026678085327 and batch: 1000, loss is 5.676819553375244 and perplexity is 292.0191999544353
At time: 278.1142385005951 and batch: 1050, loss is 5.648559713363648 and perplexity is 283.88229935409703
At time: 279.21765065193176 and batch: 1100, loss is 5.626187953948975 and perplexity is 277.6018669540898
At time: 280.3497939109802 and batch: 1150, loss is 5.645320634841919 and perplexity is 282.96426988296673
At time: 281.45266914367676 and batch: 1200, loss is 5.651927890777588 and perplexity is 284.8400773806886
At time: 282.5552349090576 and batch: 1250, loss is 5.649624814987183 and perplexity is 284.1848239331424
At time: 283.65662598609924 and batch: 1300, loss is 5.623186492919922 and perplexity is 276.7699049441894
At time: 284.7595739364624 and batch: 1350, loss is 5.61715630531311 and perplexity is 275.1059525083463
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.463924153645833 and perplexity of 236.02179528073927
Finished 9 epochs...
Completing Train Step...
At time: 288.161696434021 and batch: 50, loss is 5.687711753845215 and perplexity is 295.21731727021876
At time: 289.2655613422394 and batch: 100, loss is 5.703252458572388 and perplexity is 299.8410373049699
At time: 290.3682644367218 and batch: 150, loss is 5.659574861526489 and perplexity is 287.02659056682387
At time: 291.471120595932 and batch: 200, loss is 5.639489278793335 and perplexity is 281.319006197647
At time: 292.57513308525085 and batch: 250, loss is 5.669800844192505 and perplexity is 289.97677808127963
At time: 293.6795036792755 and batch: 300, loss is 5.669829301834106 and perplexity is 289.98503025392114
At time: 294.78294801712036 and batch: 350, loss is 5.668916072845459 and perplexity is 289.7203284031177
At time: 295.88590955734253 and batch: 400, loss is 5.704680490493774 and perplexity is 300.26952575235623
At time: 296.98711037635803 and batch: 450, loss is 5.683339233398438 and perplexity is 293.92929152580314
At time: 298.0939235687256 and batch: 500, loss is 5.70592059135437 and perplexity is 300.64212122988886
At time: 299.19666385650635 and batch: 550, loss is 5.673908262252808 and perplexity is 291.1702833712739
At time: 300.29884600639343 and batch: 600, loss is 5.6236121940612795 and perplexity is 276.88775129049986
At time: 301.40132784843445 and batch: 650, loss is 5.664748916625976 and perplexity is 288.51553056855846
At time: 302.50347876548767 and batch: 700, loss is 5.678123369216919 and perplexity is 292.40018752825483
At time: 303.6057798862457 and batch: 750, loss is 5.656942195892334 and perplexity is 286.27193933380283
At time: 304.7065920829773 and batch: 800, loss is 5.62375150680542 and perplexity is 276.9263279700003
At time: 305.80925250053406 and batch: 850, loss is 5.627669420242309 and perplexity is 278.0134295457298
At time: 306.9130017757416 and batch: 900, loss is 5.659927053451538 and perplexity is 287.12769681765326
At time: 308.0615990161896 and batch: 950, loss is 5.640681781768799 and perplexity is 281.65468005585035
At time: 309.1634593009949 and batch: 1000, loss is 5.647840118408203 and perplexity is 283.67809256544103
At time: 310.2666759490967 and batch: 1050, loss is 5.613451261520385 and perplexity is 274.08855881460136
At time: 311.3694279193878 and batch: 1100, loss is 5.595135488510132 and perplexity is 269.1141094920464
At time: 312.47260761260986 and batch: 1150, loss is 5.615327672958374 and perplexity is 274.6033445452563
At time: 313.57580065727234 and batch: 1200, loss is 5.622422065734863 and perplexity is 276.55841534934035
At time: 314.67858958244324 and batch: 1250, loss is 5.6195508575439455 and perplexity is 275.7654974228684
At time: 315.78085684776306 and batch: 1300, loss is 5.5949755859375 and perplexity is 269.07108089389055
At time: 316.8837103843689 and batch: 1350, loss is 5.582966022491455 and perplexity is 265.8589812402571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.465430908203125 and perplexity of 236.37769025225109
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 320.2811188697815 and batch: 50, loss is 5.6171964836120605 and perplexity is 275.11700601960325
At time: 321.38499665260315 and batch: 100, loss is 5.608265705108643 and perplexity is 272.67093588953406
At time: 322.48937702178955 and batch: 150, loss is 5.565862226486206 and perplexity is 261.3504498692705
At time: 323.5930745601654 and batch: 200, loss is 5.538786363601685 and perplexity is 254.36910045201563
At time: 324.6957335472107 and batch: 250, loss is 5.549949502944946 and perplexity is 257.2245664947185
At time: 325.799036026001 and batch: 300, loss is 5.554199819564819 and perplexity is 258.32017904547706
At time: 326.90174555778503 and batch: 350, loss is 5.545410327911377 and perplexity is 256.059625101124
At time: 328.0041353702545 and batch: 400, loss is 5.577043695449829 and perplexity is 264.28913057931277
At time: 329.10817432403564 and batch: 450, loss is 5.549643859863282 and perplexity is 257.1459595989741
At time: 330.2111904621124 and batch: 500, loss is 5.570709209442139 and perplexity is 262.6202859962981
At time: 331.3118064403534 and batch: 550, loss is 5.542880344390869 and perplexity is 255.41261727403574
At time: 332.4150619506836 and batch: 600, loss is 5.485759439468384 and perplexity is 241.23207560979702
At time: 333.5187072753906 and batch: 650, loss is 5.499966831207275 and perplexity is 244.6838162628374
At time: 334.6215898990631 and batch: 700, loss is 5.519608116149902 and perplexity is 249.53722841629164
At time: 335.7241265773773 and batch: 750, loss is 5.506221227645874 and perplexity is 246.21896155121925
At time: 336.85556530952454 and batch: 800, loss is 5.48120306968689 and perplexity is 240.13543332129032
At time: 337.95682191848755 and batch: 850, loss is 5.459805822372436 and perplexity is 235.05177813701053
At time: 339.06031703948975 and batch: 900, loss is 5.494169797897339 and perplexity is 243.26947946911199
At time: 340.16318583488464 and batch: 950, loss is 5.459871044158936 and perplexity is 235.0671091338526
At time: 341.2657539844513 and batch: 1000, loss is 5.468408489227295 and perplexity is 237.08257287906034
At time: 342.3700556755066 and batch: 1050, loss is 5.43175163269043 and perplexity is 228.54922931074168
At time: 343.4745509624481 and batch: 1100, loss is 5.407216300964356 and perplexity is 223.00993030053888
At time: 344.578720331192 and batch: 1150, loss is 5.42313814163208 and perplexity is 226.58907656574516
At time: 345.6823949813843 and batch: 1200, loss is 5.4021512889862064 and perplexity is 221.88323809578844
At time: 346.78590536117554 and batch: 1250, loss is 5.413599157333374 and perplexity is 224.43792314298253
At time: 347.88947892189026 and batch: 1300, loss is 5.39355019569397 and perplexity is 219.98298351328052
At time: 348.9937644004822 and batch: 1350, loss is 5.397050485610962 and perplexity is 220.75433692511334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.33193359375 and perplexity of 206.83752749533204
Finished 11 epochs...
Completing Train Step...
At time: 352.3675129413605 and batch: 50, loss is 5.497509603500366 and perplexity is 244.08331050193388
At time: 353.4995698928833 and batch: 100, loss is 5.508976335525513 and perplexity is 246.89825668830878
At time: 354.60320925712585 and batch: 150, loss is 5.479755697250366 and perplexity is 239.78811932105566
At time: 355.7071113586426 and batch: 200, loss is 5.457986583709717 and perplexity is 234.62455158584274
At time: 356.81057119369507 and batch: 250, loss is 5.479105596542358 and perplexity is 239.63228355487263
At time: 357.9139995574951 and batch: 300, loss is 5.486483116149902 and perplexity is 241.40671282056695
At time: 359.0167329311371 and batch: 350, loss is 5.476833848953247 and perplexity is 239.08851737604397
At time: 360.1197805404663 and batch: 400, loss is 5.508160324096679 and perplexity is 246.69686706838286
At time: 361.22307801246643 and batch: 450, loss is 5.47954421043396 and perplexity is 239.7374126571729
At time: 362.32594084739685 and batch: 500, loss is 5.502657747268676 and perplexity is 245.34312655046486
At time: 363.4270441532135 and batch: 550, loss is 5.4777508640289305 and perplexity is 239.3078657083932
At time: 364.531197309494 and batch: 600, loss is 5.424004373550415 and perplexity is 226.7854402921975
At time: 365.67992544174194 and batch: 650, loss is 5.440726938247681 and perplexity is 230.6097615997786
At time: 366.7827534675598 and batch: 700, loss is 5.463754768371582 and perplexity is 235.98182004991966
At time: 367.88602566719055 and batch: 750, loss is 5.447792139053345 and perplexity is 232.2448351331499
At time: 368.9888234138489 and batch: 800, loss is 5.418816986083985 and perplexity is 225.61206235585712
At time: 370.0909376144409 and batch: 850, loss is 5.403346757888794 and perplexity is 222.14865122189727
At time: 371.19467091560364 and batch: 900, loss is 5.445505247116089 and perplexity is 231.71432313522928
At time: 372.2983829975128 and batch: 950, loss is 5.4124274158477785 and perplexity is 224.17509393151184
At time: 373.40039324760437 and batch: 1000, loss is 5.423895540237427 and perplexity is 226.76075982444607
At time: 374.50395107269287 and batch: 1050, loss is 5.394389677047729 and perplexity is 220.1677326619672
At time: 375.60719776153564 and batch: 1100, loss is 5.372862548828125 and perplexity is 215.47880430820024
At time: 376.7109708786011 and batch: 1150, loss is 5.396261854171753 and perplexity is 220.5803117445561
At time: 377.8149218559265 and batch: 1200, loss is 5.376676502227784 and perplexity is 216.30219962401932
At time: 378.9184310436249 and batch: 1250, loss is 5.388620433807373 and perplexity is 218.90118847230204
At time: 380.02161979675293 and batch: 1300, loss is 5.371306028366089 and perplexity is 215.14366803105872
At time: 381.12470722198486 and batch: 1350, loss is 5.36733036994934 and perplexity is 214.29002831078586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.305076090494792 and perplexity of 201.3563231330649
Finished 12 epochs...
Completing Train Step...
At time: 384.53495621681213 and batch: 50, loss is 5.453118209838867 and perplexity is 233.48508746865159
At time: 385.6407241821289 and batch: 100, loss is 5.468605079650879 and perplexity is 237.12918562414646
At time: 386.7433545589447 and batch: 150, loss is 5.43994107246399 and perplexity is 230.42860447067005
At time: 387.8447127342224 and batch: 200, loss is 5.417751350402832 and perplexity is 225.37177014682743
At time: 388.9455816745758 and batch: 250, loss is 5.441978397369385 and perplexity is 230.89854094957306
At time: 390.0473065376282 and batch: 300, loss is 5.453424844741821 and perplexity is 233.55669312362429
At time: 391.14932084083557 and batch: 350, loss is 5.449848957061768 and perplexity is 232.723012085321
At time: 392.25075125694275 and batch: 400, loss is 5.478881225585938 and perplexity is 239.57852306159438
At time: 393.3809187412262 and batch: 450, loss is 5.4533247470855715 and perplexity is 233.53331581606747
At time: 394.48443269729614 and batch: 500, loss is 5.479204692840576 and perplexity is 239.65603140374895
At time: 395.8154957294464 and batch: 550, loss is 5.454687728881836 and perplexity is 233.8518344926151
At time: 396.9170663356781 and batch: 600, loss is 5.403189334869385 and perplexity is 222.11368266296444
At time: 398.01873207092285 and batch: 650, loss is 5.4202871417999265 and perplexity is 225.9439911526392
At time: 399.1200830936432 and batch: 700, loss is 5.444324798583985 and perplexity is 231.44095768128474
At time: 400.22119975090027 and batch: 750, loss is 5.427016525268555 and perplexity is 227.46958229831085
At time: 401.32139563560486 and batch: 800, loss is 5.397159652709961 and perplexity is 220.77843735112972
At time: 402.4214606285095 and batch: 850, loss is 5.383426504135132 and perplexity is 217.767178627237
At time: 403.5233986377716 and batch: 900, loss is 5.427167253494263 and perplexity is 227.50387096892348
At time: 404.62506794929504 and batch: 950, loss is 5.395172901153565 and perplexity is 220.34024088499592
At time: 405.72603154182434 and batch: 1000, loss is 5.409172134399414 and perplexity is 223.44652739499256
At time: 406.8282513618469 and batch: 1050, loss is 5.381729526519775 and perplexity is 217.39794597812502
At time: 407.93022108078003 and batch: 1100, loss is 5.362426052093506 and perplexity is 213.24165477844934
At time: 409.0330402851105 and batch: 1150, loss is 5.385132989883423 and perplexity is 218.13911247365516
At time: 410.13521218299866 and batch: 1200, loss is 5.365609912872315 and perplexity is 213.92166847954303
At time: 411.2366580963135 and batch: 1250, loss is 5.379149866104126 and perplexity is 216.83785583422872
At time: 412.33822894096375 and batch: 1300, loss is 5.359834995269775 and perplexity is 212.68984872287086
At time: 413.43934869766235 and batch: 1350, loss is 5.351313123703003 and perplexity is 210.88503426945263
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.284696858723958 and perplexity of 197.29436631613348
Finished 13 epochs...
Completing Train Step...
At time: 416.85178089141846 and batch: 50, loss is 5.4309621429443355 and perplexity is 228.36886324567092
At time: 417.9592056274414 and batch: 100, loss is 5.45002007484436 and perplexity is 232.76283853851726
At time: 419.0657675266266 and batch: 150, loss is 5.420737924575806 and perplexity is 226.04586577210102
At time: 420.16934609413147 and batch: 200, loss is 5.398483333587646 and perplexity is 221.07087104860477
At time: 421.3144156932831 and batch: 250, loss is 5.426368322372436 and perplexity is 227.32218363356787
At time: 422.41622519493103 and batch: 300, loss is 5.437548723220825 and perplexity is 229.87799765766627
At time: 423.51879024505615 and batch: 350, loss is 5.434306783676147 and perplexity is 229.13395381086247
At time: 424.6204535961151 and batch: 400, loss is 5.466339445114135 and perplexity is 236.59254569605613
At time: 425.7212178707123 and batch: 450, loss is 5.439779300689697 and perplexity is 230.39133064148504
At time: 426.8241877555847 and batch: 500, loss is 5.466858587265015 and perplexity is 236.71540274648822
At time: 427.92515087127686 and batch: 550, loss is 5.4407820129394535 and perplexity is 230.6224627110701
At time: 429.0275688171387 and batch: 600, loss is 5.389584350585937 and perplexity is 219.11229272783984
At time: 430.12951254844666 and batch: 650, loss is 5.407005939483643 and perplexity is 222.96302253535362
At time: 431.2317957878113 and batch: 700, loss is 5.43273964881897 and perplexity is 228.77515122433493
At time: 432.3331789970398 and batch: 750, loss is 5.416936950683594 and perplexity is 225.188302158775
At time: 433.43461537361145 and batch: 800, loss is 5.387973508834839 and perplexity is 218.75962162346417
At time: 434.53530192375183 and batch: 850, loss is 5.375192098617553 and perplexity is 215.98135804610828
At time: 435.6379771232605 and batch: 900, loss is 5.4196282005310055 and perplexity is 225.79515637447815
At time: 436.7396512031555 and batch: 950, loss is 5.387116842269897 and perplexity is 218.57229781833647
At time: 437.8409638404846 and batch: 1000, loss is 5.400294008255005 and perplexity is 221.47152108848
At time: 438.943954706192 and batch: 1050, loss is 5.373780851364136 and perplexity is 215.67676992290438
At time: 440.04675555229187 and batch: 1100, loss is 5.355124282836914 and perplexity is 211.69028418711997
At time: 441.1493055820465 and batch: 1150, loss is 5.379199962615967 and perplexity is 216.84871892654036
At time: 442.25727105140686 and batch: 1200, loss is 5.361193523406983 and perplexity is 212.97899022582305
At time: 443.35951256752014 and batch: 1250, loss is 5.374564638137818 and perplexity is 215.84588078733245
At time: 444.46142530441284 and batch: 1300, loss is 5.355286026000977 and perplexity is 211.7245264126341
At time: 445.5629849433899 and batch: 1350, loss is 5.346990880966186 and perplexity is 209.97550498092738
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.291624348958333 and perplexity of 198.66586615308327
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 448.9405415058136 and batch: 50, loss is 5.425358543395996 and perplexity is 227.0927543275959
At time: 450.07163190841675 and batch: 100, loss is 5.441808443069458 and perplexity is 230.85930208419327
At time: 451.1782479286194 and batch: 150, loss is 5.411086549758911 and perplexity is 223.87470658469996
At time: 452.28777956962585 and batch: 200, loss is 5.39280520439148 and perplexity is 219.81915913531273
At time: 453.39734506607056 and batch: 250, loss is 5.413847045898438 and perplexity is 224.4935656339799
At time: 454.50742387771606 and batch: 300, loss is 5.420266485214233 and perplexity is 225.93932396942822
At time: 455.61780643463135 and batch: 350, loss is 5.417885389328003 and perplexity is 225.40198076131566
At time: 456.7290358543396 and batch: 400, loss is 5.446189365386963 and perplexity is 231.87289737289123
At time: 457.8396372795105 and batch: 450, loss is 5.416439971923828 and perplexity is 225.07641616043958
At time: 458.95001745224 and batch: 500, loss is 5.4395889568328855 and perplexity is 230.34748124039928
At time: 460.0593535900116 and batch: 550, loss is 5.411538038253784 and perplexity is 223.97580625996878
At time: 461.16401267051697 and batch: 600, loss is 5.362853317260742 and perplexity is 213.33278497673348
At time: 462.2692413330078 and batch: 650, loss is 5.376650381088257 and perplexity is 216.29654963787533
At time: 463.3749330043793 and batch: 700, loss is 5.39764331817627 and perplexity is 220.88524608474788
At time: 464.47842264175415 and batch: 750, loss is 5.3801217460632325 and perplexity is 217.04869864104285
At time: 465.58332991600037 and batch: 800, loss is 5.349988946914673 and perplexity is 210.6059700080525
At time: 466.6877405643463 and batch: 850, loss is 5.325206842422485 and perplexity is 205.4508520220372
At time: 467.7920277118683 and batch: 900, loss is 5.363345222473145 and perplexity is 213.43775030001808
At time: 468.8988449573517 and batch: 950, loss is 5.33789179801941 and perplexity is 208.07358642382886
At time: 470.00917387008667 and batch: 1000, loss is 5.345622339248657 and perplexity is 209.68834128526964
At time: 471.1847026348114 and batch: 1050, loss is 5.315784587860107 and perplexity is 203.52413306676976
At time: 472.29221415519714 and batch: 1100, loss is 5.295584630966187 and perplexity is 199.45419898821578
At time: 473.40147709846497 and batch: 1150, loss is 5.31364104270935 and perplexity is 203.08833713926182
At time: 474.50892066955566 and batch: 1200, loss is 5.288972625732422 and perplexity is 198.13975711766753
At time: 475.61673974990845 and batch: 1250, loss is 5.307391920089722 and perplexity is 201.823170426047
At time: 476.72454619407654 and batch: 1300, loss is 5.2945489406585695 and perplexity is 199.2477331433029
At time: 477.83133006095886 and batch: 1350, loss is 5.298820629119873 and perplexity is 200.10067784593812
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.229620768229167 and perplexity of 186.72197918477818
Finished 15 epochs...
Completing Train Step...
At time: 481.30541825294495 and batch: 50, loss is 5.397510118484497 and perplexity is 220.85582619745577
At time: 482.4593014717102 and batch: 100, loss is 5.414194507598877 and perplexity is 224.5715821031154
At time: 483.56542348861694 and batch: 150, loss is 5.384051179885864 and perplexity is 217.90325500041106
At time: 484.67367672920227 and batch: 200, loss is 5.368167676925659 and perplexity is 214.46952998496093
At time: 485.7798750400543 and batch: 250, loss is 5.389672975540162 and perplexity is 219.13171240527413
At time: 486.88696455955505 and batch: 300, loss is 5.399187097549438 and perplexity is 221.2265075198969
At time: 487.9944236278534 and batch: 350, loss is 5.3973776054382325 and perplexity is 220.8265618581372
At time: 489.10151648521423 and batch: 400, loss is 5.425639715194702 and perplexity is 227.15661538334655
At time: 490.20908761024475 and batch: 450, loss is 5.398536424636841 and perplexity is 221.08260824466248
At time: 491.31694054603577 and batch: 500, loss is 5.42248911857605 and perplexity is 226.44206274365004
At time: 492.4230692386627 and batch: 550, loss is 5.3980810546875 and perplexity is 220.98195678710977
At time: 493.528550863266 and batch: 600, loss is 5.3494911384582515 and perplexity is 210.501154666356
At time: 494.6364743709564 and batch: 650, loss is 5.363587341308594 and perplexity is 213.4894338560903
At time: 495.7440187931061 and batch: 700, loss is 5.38630334854126 and perplexity is 218.39456292771845
At time: 496.8503921031952 and batch: 750, loss is 5.369375400543213 and perplexity is 214.72870637679128
At time: 497.95621371269226 and batch: 800, loss is 5.340114860534668 and perplexity is 208.53666154598596
At time: 499.21522521972656 and batch: 850, loss is 5.317900762557984 and perplexity is 203.9552817196107
At time: 500.32173347473145 and batch: 900, loss is 5.358962240219117 and perplexity is 212.5043035626895
At time: 501.4294435977936 and batch: 950, loss is 5.333786993026734 and perplexity is 207.22123549141529
At time: 502.54076766967773 and batch: 1000, loss is 5.343930625915528 and perplexity is 209.33390860628896
At time: 503.6504657268524 and batch: 1050, loss is 5.315766105651855 and perplexity is 203.52037152611905
At time: 504.75661754608154 and batch: 1100, loss is 5.297239961624146 and perplexity is 199.78463505368163
At time: 505.8679127693176 and batch: 1150, loss is 5.316148939132691 and perplexity is 203.59830085439754
At time: 506.9731798171997 and batch: 1200, loss is 5.293788766860962 and perplexity is 199.09632779181607
At time: 508.0795919895172 and batch: 1250, loss is 5.313030977249145 and perplexity is 202.96447774441347
At time: 509.1857817173004 and batch: 1300, loss is 5.2980225467681885 and perplexity is 199.94104473504652
At time: 510.2911217212677 and batch: 1350, loss is 5.297895317077637 and perplexity is 199.91560791598988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.225965576171875 and perplexity of 186.04072031403916
Finished 16 epochs...
Completing Train Step...
At time: 513.7618865966797 and batch: 50, loss is 5.388701305389405 and perplexity is 218.91889207357195
At time: 514.8676843643188 and batch: 100, loss is 5.404477176666259 and perplexity is 222.3999142180752
At time: 515.9742348194122 and batch: 150, loss is 5.3751555347442626 and perplexity is 215.9734610754723
At time: 517.0829148292542 and batch: 200, loss is 5.358792676925659 and perplexity is 212.4682736878619
At time: 518.1884341239929 and batch: 250, loss is 5.3810463142395015 and perplexity is 217.2494677585735
At time: 519.293648481369 and batch: 300, loss is 5.391432447433472 and perplexity is 219.51760788075282
At time: 520.3998301029205 and batch: 350, loss is 5.389265727996826 and perplexity is 219.0424897228225
At time: 521.5053310394287 and batch: 400, loss is 5.41818172454834 and perplexity is 225.4687852047149
At time: 522.6138882637024 and batch: 450, loss is 5.391220035552979 and perplexity is 219.47098468469727
At time: 523.7193608283997 and batch: 500, loss is 5.415611934661865 and perplexity is 224.8901216411159
At time: 524.8249135017395 and batch: 550, loss is 5.392667465209961 and perplexity is 219.78888350936904
At time: 525.9304900169373 and batch: 600, loss is 5.343903703689575 and perplexity is 209.3282729473645
At time: 527.0853912830353 and batch: 650, loss is 5.358167018890381 and perplexity is 212.33538278165406
At time: 528.190315246582 and batch: 700, loss is 5.381987237930298 and perplexity is 217.45397912930892
At time: 529.2960255146027 and batch: 750, loss is 5.3648177528381344 and perplexity is 213.7522753854061
At time: 530.4010081291199 and batch: 800, loss is 5.336005363464356 and perplexity is 207.68143921671842
At time: 531.5078222751617 and batch: 850, loss is 5.314067611694336 and perplexity is 203.1749868048137
At time: 532.61363530159 and batch: 900, loss is 5.356943845748901 and perplexity is 212.07581862276592
At time: 533.7205448150635 and batch: 950, loss is 5.332159185409546 and perplexity is 206.88419357995807
At time: 534.8258631229401 and batch: 1000, loss is 5.343151693344116 and perplexity is 209.1709150952931
At time: 535.9301016330719 and batch: 1050, loss is 5.315401773452759 and perplexity is 203.44623600739843
At time: 537.0356216430664 and batch: 1100, loss is 5.297695636749268 and perplexity is 199.87569268703075
At time: 538.1417405605316 and batch: 1150, loss is 5.317165384292602 and perplexity is 203.80535257239904
At time: 539.2479910850525 and batch: 1200, loss is 5.2942862224578855 and perplexity is 199.19539401288324
At time: 540.3539471626282 and batch: 1250, loss is 5.31379002571106 and perplexity is 203.1185961033207
At time: 541.4595353603363 and batch: 1300, loss is 5.2977337074279784 and perplexity is 199.88330223515857
At time: 542.565589427948 and batch: 1350, loss is 5.295133829116821 and perplexity is 199.36430493017437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2236405436197915 and perplexity of 185.60867204107498
Finished 17 epochs...
Completing Train Step...
At time: 545.9827103614807 and batch: 50, loss is 5.383149662017822 and perplexity is 217.70689984466318
At time: 547.0873613357544 and batch: 100, loss is 5.398557929992676 and perplexity is 221.0873627559452
At time: 548.1942174434662 and batch: 150, loss is 5.369491605758667 and perplexity is 214.75366042224712
At time: 549.299747467041 and batch: 200, loss is 5.352743263244629 and perplexity is 211.18684506003035
At time: 550.4046201705933 and batch: 250, loss is 5.375588703155517 and perplexity is 216.06703422148195
At time: 551.5103490352631 and batch: 300, loss is 5.385900917053223 and perplexity is 218.30669176102842
At time: 552.6156997680664 and batch: 350, loss is 5.383981981277466 and perplexity is 217.88817692009673
At time: 553.7210321426392 and batch: 400, loss is 5.413183498382568 and perplexity is 224.34465289697698
At time: 554.8261523246765 and batch: 450, loss is 5.386395359039307 and perplexity is 218.41465844470935
At time: 555.9746119976044 and batch: 500, loss is 5.4107310962677 and perplexity is 223.79514367994432
At time: 557.0801122188568 and batch: 550, loss is 5.388919954299927 and perplexity is 218.96676368416357
At time: 558.1843152046204 and batch: 600, loss is 5.339825210571289 and perplexity is 208.47626765657205
At time: 559.2889888286591 and batch: 650, loss is 5.354931354522705 and perplexity is 211.64944707690145
At time: 560.3952136039734 and batch: 700, loss is 5.3785529136657715 and perplexity is 216.70845257509916
At time: 561.5000154972076 and batch: 750, loss is 5.361133918762207 and perplexity is 212.9662960670852
At time: 562.6061885356903 and batch: 800, loss is 5.33294075012207 and perplexity is 207.04595016862595
At time: 563.71142578125 and batch: 850, loss is 5.311322145462036 and perplexity is 202.6179417633665
At time: 564.8166587352753 and batch: 900, loss is 5.354544534683227 and perplexity is 211.56759270422592
At time: 565.9222435951233 and batch: 950, loss is 5.330427350997925 and perplexity is 206.5262144840267
At time: 567.0280132293701 and batch: 1000, loss is 5.342355070114135 and perplexity is 209.00435103849892
At time: 568.1312375068665 and batch: 1050, loss is 5.31466121673584 and perplexity is 203.29562830444732
At time: 569.2356634140015 and batch: 1100, loss is 5.297454671859741 and perplexity is 199.82753546515627
At time: 570.3400409221649 and batch: 1150, loss is 5.316879091262817 and perplexity is 203.7470128720479
At time: 571.4462776184082 and batch: 1200, loss is 5.2924394607543945 and perplexity is 198.8278670595148
At time: 572.5509467124939 and batch: 1250, loss is 5.312588272094726 and perplexity is 202.8746442103036
At time: 573.6569538116455 and batch: 1300, loss is 5.295972032546997 and perplexity is 199.53148282917758
At time: 574.7630667686462 and batch: 1350, loss is 5.292169885635376 and perplexity is 198.7742752374235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.221791585286458 and perplexity of 185.26580640997662
Finished 18 epochs...
Completing Train Step...
At time: 578.1602122783661 and batch: 50, loss is 5.377757711410522 and perplexity is 216.53619402415126
At time: 579.2948250770569 and batch: 100, loss is 5.3936897659301755 and perplexity is 220.01368873296823
At time: 580.3996350765228 and batch: 150, loss is 5.364862604141235 and perplexity is 213.76186266849737
At time: 581.506674528122 and batch: 200, loss is 5.347519330978393 and perplexity is 210.08649586308132
At time: 582.611189365387 and batch: 250, loss is 5.371084976196289 and perplexity is 215.0961153124312
At time: 583.7456185817719 and batch: 300, loss is 5.381829490661621 and perplexity is 217.41967906348032
At time: 584.8497424125671 and batch: 350, loss is 5.379739475250244 and perplexity is 216.96574311530364
At time: 585.9563295841217 and batch: 400, loss is 5.4088140487670895 and perplexity is 223.366528727981
At time: 587.0614326000214 and batch: 450, loss is 5.382512006759644 and perplexity is 217.56812214610235
At time: 588.1664819717407 and batch: 500, loss is 5.40683804512024 and perplexity is 222.92559144294523
At time: 589.2726833820343 and batch: 550, loss is 5.385457954406738 and perplexity is 218.21001146556125
At time: 590.3770453929901 and batch: 600, loss is 5.336060400009155 and perplexity is 207.69286960009347
At time: 591.4818449020386 and batch: 650, loss is 5.351957521438599 and perplexity is 211.02097190225433
At time: 592.587150812149 and batch: 700, loss is 5.3749005985260006 and perplexity is 215.91840863578932
At time: 593.6920800209045 and batch: 750, loss is 5.357618522644043 and perplexity is 212.2189495557464
At time: 594.7965595722198 and batch: 800, loss is 5.329348096847534 and perplexity is 206.3034404464063
At time: 595.9014983177185 and batch: 850, loss is 5.30792947769165 and perplexity is 201.93169117101732
At time: 597.0072596073151 and batch: 900, loss is 5.351683778762817 and perplexity is 210.96321436247226
At time: 598.1115965843201 and batch: 950, loss is 5.3278938579559325 and perplexity is 206.00364400049796
At time: 599.2162041664124 and batch: 1000, loss is 5.340454511642456 and perplexity is 208.60750328415077
At time: 600.3208394050598 and batch: 1050, loss is 5.3128243350982665 and perplexity is 202.92254106127285
At time: 601.425279378891 and batch: 1100, loss is 5.295678386688232 and perplexity is 199.47289983729902
At time: 602.5309269428253 and batch: 1150, loss is 5.315295934677124 and perplexity is 203.42470464631836
At time: 603.6371607780457 and batch: 1200, loss is 5.290330123901367 and perplexity is 198.4089141238881
At time: 604.7418954372406 and batch: 1250, loss is 5.310486612319946 and perplexity is 202.44871846352368
At time: 605.8456840515137 and batch: 1300, loss is 5.293232440948486 and perplexity is 198.9855961498836
At time: 606.9514656066895 and batch: 1350, loss is 5.28857988357544 and perplexity is 198.06195456124527
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.218914388020833 and perplexity of 184.73352624307668
Finished 19 epochs...
Completing Train Step...
At time: 610.3650858402252 and batch: 50, loss is 5.372865362167358 and perplexity is 215.47941052402714
At time: 611.50022149086 and batch: 100, loss is 5.388500452041626 and perplexity is 218.8749258967317
At time: 612.6044373512268 and batch: 150, loss is 5.360203037261963 and perplexity is 212.76814192522218
At time: 613.7098340988159 and batch: 200, loss is 5.342786121368408 and perplexity is 209.09446204599865
At time: 614.8149285316467 and batch: 250, loss is 5.366782207489013 and perplexity is 214.17259475091853
At time: 615.919960975647 and batch: 300, loss is 5.377020788192749 and perplexity is 216.37668225646783
At time: 617.0252680778503 and batch: 350, loss is 5.375571575164795 and perplexity is 216.06333345901774
At time: 618.1306629180908 and batch: 400, loss is 5.404441976547242 and perplexity is 222.39208585240567
At time: 619.2350223064423 and batch: 450, loss is 5.378422698974609 and perplexity is 216.68023578803485
At time: 620.3382797241211 and batch: 500, loss is 5.403030624389649 and perplexity is 222.07843369109762
At time: 621.4446439743042 and batch: 550, loss is 5.381809978485108 and perplexity is 217.4154367737132
At time: 622.5501112937927 and batch: 600, loss is 5.3321980953216555 and perplexity is 206.89224358235845
At time: 623.6555621623993 and batch: 650, loss is 5.34863600730896 and perplexity is 210.3212255145145
At time: 624.76025223732 and batch: 700, loss is 5.370980939865112 and perplexity is 215.07373866575605
At time: 625.8649079799652 and batch: 750, loss is 5.353673791885376 and perplexity is 211.38345192788182
At time: 626.9685649871826 and batch: 800, loss is 5.325287361145019 and perplexity is 205.46739532819953
At time: 628.0740184783936 and batch: 850, loss is 5.304220399856567 and perplexity is 201.18409810859188
At time: 629.1794486045837 and batch: 900, loss is 5.348441905975342 and perplexity is 210.2804058458583
At time: 630.2850432395935 and batch: 950, loss is 5.324348678588867 and perplexity is 205.27461716125342
At time: 631.3899772167206 and batch: 1000, loss is 5.337885427474975 and perplexity is 208.07226088602317
At time: 632.4941163063049 and batch: 1050, loss is 5.310376930236816 and perplexity is 202.42651468405631
At time: 633.5980019569397 and batch: 1100, loss is 5.292464427947998 and perplexity is 198.83283129533663
At time: 634.7021272182465 and batch: 1150, loss is 5.312720375061035 and perplexity is 202.90144632287297
At time: 635.8081090450287 and batch: 1200, loss is 5.287608232498169 and perplexity is 197.86960091517665
At time: 636.9126999378204 and batch: 1250, loss is 5.308008785247803 and perplexity is 201.94770651501435
At time: 638.0174012184143 and batch: 1300, loss is 5.2898523712158205 and perplexity is 198.31414637190554
At time: 639.1216275691986 and batch: 1350, loss is 5.284991445541382 and perplexity is 197.35249519718292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.216440836588542 and perplexity of 184.27714304100422
Finished 20 epochs...
Completing Train Step...
At time: 642.5432822704315 and batch: 50, loss is 5.368425416946411 and perplexity is 214.52481449027857
At time: 643.6501121520996 and batch: 100, loss is 5.383611001968384 and perplexity is 217.8073599064126
At time: 644.7564806938171 and batch: 150, loss is 5.355869626998901 and perplexity is 211.84812512019002
At time: 645.8642146587372 and batch: 200, loss is 5.33844069480896 and perplexity is 208.18782869814763
At time: 646.9707450866699 and batch: 250, loss is 5.362820596694946 and perplexity is 213.32580472150568
At time: 648.0766136646271 and batch: 300, loss is 5.372683095932007 and perplexity is 215.44013948207635
At time: 649.1822984218597 and batch: 350, loss is 5.3712755298614505 and perplexity is 215.13710657095928
At time: 650.2889752388 and batch: 400, loss is 5.399914808273316 and perplexity is 221.3875550127118
At time: 651.3937766551971 and batch: 450, loss is 5.374860620498657 and perplexity is 215.90977681628758
At time: 652.5020546913147 and batch: 500, loss is 5.400053691864014 and perplexity is 221.41830424652045
At time: 653.6088857650757 and batch: 550, loss is 5.37853702545166 and perplexity is 216.7050094921572
At time: 654.715918302536 and batch: 600, loss is 5.329419021606445 and perplexity is 206.3180729870811
At time: 655.8227031230927 and batch: 650, loss is 5.346825475692749 and perplexity is 209.94077679730248
At time: 656.9291226863861 and batch: 700, loss is 5.367350101470947 and perplexity is 214.29425662082497
At time: 658.035671710968 and batch: 750, loss is 5.349972085952759 and perplexity is 210.60241901875003
At time: 659.1423461437225 and batch: 800, loss is 5.3218252468109135 and perplexity is 204.75727368411088
At time: 660.2496781349182 and batch: 850, loss is 5.301088771820068 and perplexity is 200.55504983315961
At time: 661.3562045097351 and batch: 900, loss is 5.345521774291992 and perplexity is 209.6672550466012
At time: 662.4627985954285 and batch: 950, loss is 5.321512689590454 and perplexity is 204.69328532031287
At time: 663.5681042671204 and batch: 1000, loss is 5.335298461914062 and perplexity is 207.53468076336947
At time: 664.6737082004547 and batch: 1050, loss is 5.3080473899841305 and perplexity is 201.9555028034622
At time: 665.7818470001221 and batch: 1100, loss is 5.289597244262695 and perplexity is 198.26355754154147
At time: 666.887725353241 and batch: 1150, loss is 5.309855670928955 and perplexity is 202.3210254751239
At time: 668.0415318012238 and batch: 1200, loss is 5.286395635604858 and perplexity is 197.62981026590666
At time: 669.1483209133148 and batch: 1250, loss is 5.305460557937622 and perplexity is 201.43375296738907
At time: 670.2542471885681 and batch: 1300, loss is 5.287281885147094 and perplexity is 197.80503723072655
At time: 671.3602297306061 and batch: 1350, loss is 5.281768884658813 and perplexity is 196.71753840903364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2146223958333335 and perplexity of 183.94235046633187
Finished 21 epochs...
Completing Train Step...
At time: 674.7841975688934 and batch: 50, loss is 5.364430551528931 and perplexity is 213.669526245853
At time: 675.890207529068 and batch: 100, loss is 5.379751491546631 and perplexity is 216.96835025564266
At time: 676.9963624477386 and batch: 150, loss is 5.352306671142578 and perplexity is 211.09466267593484
At time: 678.1020321846008 and batch: 200, loss is 5.335011415481567 and perplexity is 207.4751172227972
At time: 679.2095913887024 and batch: 250, loss is 5.359665403366089 and perplexity is 212.65378130498863
At time: 680.3154916763306 and batch: 300, loss is 5.369735078811646 and perplexity is 214.80595351730983
At time: 681.4212276935577 and batch: 350, loss is 5.368321571350098 and perplexity is 214.50253818966175
At time: 682.5269160270691 and batch: 400, loss is 5.397398014068603 and perplexity is 220.83106867180297
At time: 683.6331050395966 and batch: 450, loss is 5.372342481613159 and perplexity is 215.36676998177472
At time: 684.7374472618103 and batch: 500, loss is 5.397546415328979 and perplexity is 220.86384271251845
At time: 685.8440699577332 and batch: 550, loss is 5.376286869049072 and perplexity is 216.21793752713788
At time: 686.9521000385284 and batch: 600, loss is 5.327005281448364 and perplexity is 205.82067530484676
At time: 688.058785200119 and batch: 650, loss is 5.3441536998748775 and perplexity is 209.38061075893134
At time: 689.1648662090302 and batch: 700, loss is 5.364695587158203 and perplexity is 213.72616378834977
At time: 690.2717664241791 and batch: 750, loss is 5.34722942352295 and perplexity is 210.02559904928927
At time: 691.3777794837952 and batch: 800, loss is 5.3198752689361575 and perplexity is 204.35839056375437
At time: 692.4833796024323 and batch: 850, loss is 5.298172693252564 and perplexity is 199.97106743384074
At time: 693.5906894207001 and batch: 900, loss is 5.343236484527588 and perplexity is 209.188651696675
At time: 694.6966633796692 and batch: 950, loss is 5.319658679962158 and perplexity is 204.31413358257407
At time: 695.8327004909515 and batch: 1000, loss is 5.333846225738525 and perplexity is 207.2335101306607
At time: 696.9377179145813 and batch: 1050, loss is 5.306492805480957 and perplexity is 201.64178981832592
At time: 698.045042514801 and batch: 1100, loss is 5.288473491668701 and perplexity is 198.0408834931625
At time: 699.150691986084 and batch: 1150, loss is 5.308370542526245 and perplexity is 202.0207757835839
At time: 700.2570037841797 and batch: 1200, loss is 5.283837614059448 and perplexity is 197.1249149950357
At time: 701.3634786605835 and batch: 1250, loss is 5.303587532043457 and perplexity is 201.0568154491867
At time: 702.4693555831909 and batch: 1300, loss is 5.2850377655029295 and perplexity is 197.3616367688887
At time: 703.5746076107025 and batch: 1350, loss is 5.279076690673828 and perplexity is 196.188648891422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.213333333333333 and perplexity of 183.7053900413954
Finished 22 epochs...
Completing Train Step...
At time: 706.9791789054871 and batch: 50, loss is 5.361020050048828 and perplexity is 212.94204724957592
At time: 708.1163642406464 and batch: 100, loss is 5.37642318725586 and perplexity is 216.24741397769967
At time: 709.2225594520569 and batch: 150, loss is 5.349534482955932 and perplexity is 210.51027893090816
At time: 710.328679561615 and batch: 200, loss is 5.332188835144043 and perplexity is 206.89032773230684
At time: 711.4344477653503 and batch: 250, loss is 5.356919393539429 and perplexity is 212.0706329638256
At time: 712.54199051857 and batch: 300, loss is 5.367026453018188 and perplexity is 214.22491183850556
At time: 713.6480643749237 and batch: 350, loss is 5.365821266174317 and perplexity is 213.96688630884643
At time: 714.7535512447357 and batch: 400, loss is 5.395257425308228 and perplexity is 220.35886574470914
At time: 715.859626531601 and batch: 450, loss is 5.369917230606079 and perplexity is 214.84508437096744
At time: 716.9652729034424 and batch: 500, loss is 5.395001392364502 and perplexity is 220.30245383759802
At time: 718.0725376605988 and batch: 550, loss is 5.373428153991699 and perplexity is 215.60071470588298
At time: 719.1787829399109 and batch: 600, loss is 5.324198665618897 and perplexity is 205.2438256158968
At time: 720.2843909263611 and batch: 650, loss is 5.341523103713989 and perplexity is 208.83053875396644
At time: 721.3904337882996 and batch: 700, loss is 5.361445512771606 and perplexity is 213.03266542875434
At time: 722.497017621994 and batch: 750, loss is 5.344446134567261 and perplexity is 209.44184986721314
At time: 723.6480374336243 and batch: 800, loss is 5.317169399261474 and perplexity is 203.80617084618825
At time: 724.7540876865387 and batch: 850, loss is 5.295727825164795 and perplexity is 199.4827617173586
At time: 725.8593900203705 and batch: 900, loss is 5.3408168697357175 and perplexity is 208.6831075983712
At time: 726.9660179615021 and batch: 950, loss is 5.317221612930298 and perplexity is 203.8168125919168
At time: 728.0718266963959 and batch: 1000, loss is 5.3314580059051515 and perplexity is 206.73918146933778
At time: 729.1773824691772 and batch: 1050, loss is 5.304337749481201 and perplexity is 201.20770837228787
At time: 730.2843434810638 and batch: 1100, loss is 5.285541944503784 and perplexity is 197.4611674502532
At time: 731.3896527290344 and batch: 1150, loss is 5.305874814987183 and perplexity is 201.51721560587484
At time: 732.495525598526 and batch: 1200, loss is 5.282544250488281 and perplexity is 196.870125614181
At time: 733.6027662754059 and batch: 1250, loss is 5.301122922897338 and perplexity is 200.56189912111802
At time: 734.708146572113 and batch: 1300, loss is 5.282537660598755 and perplexity is 196.86882826607683
At time: 735.8134677410126 and batch: 1350, loss is 5.276041803359985 and perplexity is 195.59414103826364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.211520589192708 and perplexity of 183.37268082144917
Finished 23 epochs...
Completing Train Step...
At time: 739.2137758731842 and batch: 50, loss is 5.357346506118774 and perplexity is 212.16123034513748
At time: 740.349761724472 and batch: 100, loss is 5.372937498092651 and perplexity is 215.49495489133375
At time: 741.4570696353912 and batch: 150, loss is 5.346774387359619 and perplexity is 209.93005154692975
At time: 742.5633676052094 and batch: 200, loss is 5.329346256256104 and perplexity is 206.30306072641122
At time: 743.6696105003357 and batch: 250, loss is 5.354024200439453 and perplexity is 211.4575354766244
At time: 744.7761883735657 and batch: 300, loss is 5.364279794692993 and perplexity is 213.63731653211815
At time: 745.8808798789978 and batch: 350, loss is 5.363005609512329 and perplexity is 213.36527638092653
At time: 746.9861476421356 and batch: 400, loss is 5.393067226409912 and perplexity is 219.87676414163997
At time: 748.0915126800537 and batch: 450, loss is 5.3672311401367185 and perplexity is 214.2687654064043
At time: 749.1968472003937 and batch: 500, loss is 5.392059669494629 and perplexity is 219.6553373561956
At time: 750.3028812408447 and batch: 550, loss is 5.370938692092896 and perplexity is 215.06465247137223
At time: 751.4093911647797 and batch: 600, loss is 5.322416801452636 and perplexity is 204.8784346329128
At time: 752.5441417694092 and batch: 650, loss is 5.3390890407562255 and perplexity is 208.3228501987457
At time: 753.6487836837769 and batch: 700, loss is 5.358832807540893 and perplexity is 212.47680034149158
At time: 754.7540397644043 and batch: 750, loss is 5.341414260864258 and perplexity is 208.8078102799559
At time: 755.8604960441589 and batch: 800, loss is 5.314741163253784 and perplexity is 203.31188173173737
At time: 756.9660906791687 and batch: 850, loss is 5.292277641296387 and perplexity is 198.79569544489723
At time: 758.0722258090973 and batch: 900, loss is 5.337792263031006 and perplexity is 208.05287685249766
At time: 759.1781508922577 and batch: 950, loss is 5.314858341217041 and perplexity is 203.33570679980386
At time: 760.2834961414337 and batch: 1000, loss is 5.329511251449585 and perplexity is 206.3371025481228
At time: 761.3892405033112 and batch: 1050, loss is 5.301966009140014 and perplexity is 200.7310613982463
At time: 762.4949171543121 and batch: 1100, loss is 5.283664817810059 and perplexity is 197.09085549182535
At time: 763.6005783081055 and batch: 1150, loss is 5.303663473129273 and perplexity is 201.07208450182952
At time: 764.7064197063446 and batch: 1200, loss is 5.279733552932739 and perplexity is 196.31756014433876
At time: 765.8140041828156 and batch: 1250, loss is 5.298417587280273 and perplexity is 200.02004515090033
At time: 766.9188792705536 and batch: 1300, loss is 5.27970871925354 and perplexity is 196.3126849175641
At time: 768.0236427783966 and batch: 1350, loss is 5.272332668304443 and perplexity is 194.86999975220337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.209637044270833 and perplexity of 183.02761521497965
Finished 24 epochs...
Completing Train Step...
At time: 771.452045917511 and batch: 50, loss is 5.3536000823974605 and perplexity is 211.3678715361049
At time: 772.5576846599579 and batch: 100, loss is 5.369577016830444 and perplexity is 214.7720035458936
At time: 773.6636092662811 and batch: 150, loss is 5.343365745544434 and perplexity is 209.21569338218615
At time: 774.7674324512482 and batch: 200, loss is 5.32589093208313 and perplexity is 205.5914469099478
At time: 775.8723342418671 and batch: 250, loss is 5.350679378509522 and perplexity is 210.75142923285392
At time: 776.9781851768494 and batch: 300, loss is 5.360901918411255 and perplexity is 212.91689354257966
At time: 778.0841000080109 and batch: 350, loss is 5.359879770278931 and perplexity is 212.69937212599834
At time: 779.1889855861664 and batch: 400, loss is 5.390310640335083 and perplexity is 219.27148954446992
At time: 780.3377759456635 and batch: 450, loss is 5.363812875747681 and perplexity is 213.53758850586792
At time: 781.4421346187592 and batch: 500, loss is 5.389013252258301 and perplexity is 218.9871937891958
At time: 782.5467457771301 and batch: 550, loss is 5.36758716583252 and perplexity is 214.34506417405152
At time: 783.6519913673401 and batch: 600, loss is 5.319534091949463 and perplexity is 204.28868007633935
At time: 784.7597234249115 and batch: 650, loss is 5.335941457748413 and perplexity is 207.66816760972765
At time: 785.8651502132416 and batch: 700, loss is 5.355512104034424 and perplexity is 211.7723980883612
At time: 786.9700720310211 and batch: 750, loss is 5.3383026123046875 and perplexity is 208.15908358604614
At time: 788.0752265453339 and batch: 800, loss is 5.311445856094361 and perplexity is 202.6430093075913
At time: 789.1801950931549 and batch: 850, loss is 5.28920696258545 and perplexity is 198.18619400553482
At time: 790.2855107784271 and batch: 900, loss is 5.335017108917237 and perplexity is 207.4762984723928
At time: 791.3910105228424 and batch: 950, loss is 5.312185039520264 and perplexity is 202.79285503636333
At time: 792.4966940879822 and batch: 1000, loss is 5.326630268096924 and perplexity is 205.7435042745928
At time: 793.6014561653137 and batch: 1050, loss is 5.299334793090821 and perplexity is 200.20358885934922
At time: 794.7065382003784 and batch: 1100, loss is 5.280360851287842 and perplexity is 196.44074846076967
At time: 795.8120625019073 and batch: 1150, loss is 5.300608797073364 and perplexity is 200.45881157173088
At time: 796.9172940254211 and batch: 1200, loss is 5.277950353622437 and perplexity is 195.96779874631196
At time: 798.0222837924957 and batch: 1250, loss is 5.29570013999939 and perplexity is 199.477239080553
At time: 799.128527879715 and batch: 1300, loss is 5.277050886154175 and perplexity is 195.79161133581337
At time: 800.2330074310303 and batch: 1350, loss is 5.269358711242676 and perplexity is 194.29132564279377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.208116048177083 and perplexity of 182.74944253060022
Finished 25 epochs...
Completing Train Step...
At time: 803.6542749404907 and batch: 50, loss is 5.3502702713012695 and perplexity is 210.6652269381976
At time: 804.7593564987183 and batch: 100, loss is 5.366421003341674 and perplexity is 214.0952486911479
At time: 805.8651962280273 and batch: 150, loss is 5.33990026473999 and perplexity is 208.49191525673643
At time: 806.9702091217041 and batch: 200, loss is 5.322553615570069 and perplexity is 204.9064668126833
At time: 808.104829788208 and batch: 250, loss is 5.347746820449829 and perplexity is 210.13429376553464
At time: 809.2108228206635 and batch: 300, loss is 5.357788963317871 and perplexity is 212.25512337916558
At time: 810.3155045509338 and batch: 350, loss is 5.356937217712402 and perplexity is 212.07441298115782
At time: 811.4195115566254 and batch: 400, loss is 5.387690544128418 and perplexity is 218.69772912846355
At time: 812.5236947536469 and batch: 450, loss is 5.36045470237732 and perplexity is 212.82169498263963
At time: 813.6302297115326 and batch: 500, loss is 5.3866282558441165 and perplexity is 218.46553244475075
At time: 814.7351777553558 and batch: 550, loss is 5.365087308883667 and perplexity is 213.8099013698499
At time: 815.84113240242 and batch: 600, loss is 5.317622184753418 and perplexity is 203.89847221830013
At time: 816.9470598697662 and batch: 650, loss is 5.333419246673584 and perplexity is 207.1450446480792
At time: 818.0516490936279 and batch: 700, loss is 5.352728452682495 and perplexity is 211.1837172873018
At time: 819.1565194129944 and batch: 750, loss is 5.336074542999268 and perplexity is 207.69580701906654
At time: 820.2630431652069 and batch: 800, loss is 5.309151811599731 and perplexity is 202.1786700388232
At time: 821.3683090209961 and batch: 850, loss is 5.286289329528809 and perplexity is 197.60880213293274
At time: 822.4728457927704 and batch: 900, loss is 5.332339162826538 and perplexity is 206.92143141361908
At time: 823.5774166584015 and batch: 950, loss is 5.309720458984375 and perplexity is 202.29367110520053
At time: 824.6837873458862 and batch: 1000, loss is 5.324419536590576 and perplexity is 205.28916302576636
At time: 825.7884140014648 and batch: 1050, loss is 5.2968293571472165 and perplexity is 199.70261942725088
At time: 826.8939180374146 and batch: 1100, loss is 5.277865514755249 and perplexity is 195.95117376549334
At time: 827.9989836215973 and batch: 1150, loss is 5.298165674209595 and perplexity is 199.96966383325184
At time: 829.1047127246857 and batch: 1200, loss is 5.275740919113159 and perplexity is 195.5352986952647
At time: 830.2090339660645 and batch: 1250, loss is 5.2934235572814945 and perplexity is 199.02362918159224
At time: 831.3172237873077 and batch: 1300, loss is 5.274558410644532 and perplexity is 195.3042132058438
At time: 832.4219019412994 and batch: 1350, loss is 5.266606750488282 and perplexity is 193.75737857736794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.206659749348958 and perplexity of 182.48349842564792
Finished 26 epochs...
Completing Train Step...
At time: 835.84255027771 and batch: 50, loss is 5.347388849258423 and perplexity is 210.05908520409247
At time: 836.9779577255249 and batch: 100, loss is 5.3637556552886965 and perplexity is 213.52537013661689
At time: 838.0841727256775 and batch: 150, loss is 5.336954927444458 and perplexity is 207.878739690621
At time: 839.1896238327026 and batch: 200, loss is 5.319534711837768 and perplexity is 204.28880671254223
At time: 840.2938878536224 and batch: 250, loss is 5.344925031661988 and perplexity is 209.54217498141418
At time: 841.3983974456787 and batch: 300, loss is 5.355033988952637 and perplexity is 211.67117071202495
At time: 842.505069732666 and batch: 350, loss is 5.35439024925232 and perplexity is 211.53495342496683
At time: 843.6086149215698 and batch: 400, loss is 5.385308408737183 and perplexity is 218.17738154318556
At time: 844.712399482727 and batch: 450, loss is 5.3581991958618165 and perplexity is 212.3422152011233
At time: 845.8180930614471 and batch: 500, loss is 5.384423952102662 and perplexity is 217.98449842152928
At time: 846.9233071804047 and batch: 550, loss is 5.363051300048828 and perplexity is 213.3750253775914
At time: 848.0297996997833 and batch: 600, loss is 5.315876932144165 and perplexity is 203.54292822492562
At time: 849.1543056964874 and batch: 650, loss is 5.330971622467041 and perplexity is 206.63865140552355
At time: 850.2639014720917 and batch: 700, loss is 5.349797277450562 and perplexity is 210.56560714293045
At time: 851.3661022186279 and batch: 750, loss is 5.333003444671631 and perplexity is 207.05893122812674
At time: 852.4681012630463 and batch: 800, loss is 5.305910196304321 and perplexity is 201.52434567652392
At time: 853.5700440406799 and batch: 850, loss is 5.2832545566558835 and perplexity is 197.01001335430215
At time: 854.6728837490082 and batch: 900, loss is 5.3297504043579105 and perplexity is 206.38645456739692
At time: 855.7752959728241 and batch: 950, loss is 5.307262601852417 and perplexity is 201.79707269689288
At time: 856.8778293132782 and batch: 1000, loss is 5.32207049369812 and perplexity is 204.80749592628732
At time: 857.9801001548767 and batch: 1050, loss is 5.294490880966187 and perplexity is 199.236165217027
At time: 859.0820429325104 and batch: 1100, loss is 5.275598630905152 and perplexity is 195.5074783073147
At time: 860.184112071991 and batch: 1150, loss is 5.2960066318511965 and perplexity is 199.5383865990815
At time: 861.2862691879272 and batch: 1200, loss is 5.27348991394043 and perplexity is 195.0956427460041
At time: 862.388777256012 and batch: 1250, loss is 5.291099815368653 and perplexity is 198.56168655840003
At time: 863.4907865524292 and batch: 1300, loss is 5.272019338607788 and perplexity is 194.80895075902455
At time: 864.5932219028473 and batch: 1350, loss is 5.263723125457764 and perplexity is 193.19945975160505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.205306396484375 and perplexity of 182.23670090005237
Finished 27 epochs...
Completing Train Step...
At time: 868.0371012687683 and batch: 50, loss is 5.344055242538452 and perplexity is 209.35999671651544
At time: 869.181140422821 and batch: 100, loss is 5.360583238601684 and perplexity is 212.84905203792422
At time: 870.2848787307739 and batch: 150, loss is 5.333697528839111 and perplexity is 207.20269744118207
At time: 871.3882751464844 and batch: 200, loss is 5.316313209533692 and perplexity is 203.63174877609856
At time: 872.490651845932 and batch: 250, loss is 5.341864385604858 and perplexity is 208.90182099808132
At time: 873.594279050827 and batch: 300, loss is 5.351953411102295 and perplexity is 211.02010453687535
At time: 874.6972687244415 and batch: 350, loss is 5.351562223434448 and perplexity is 210.93757221817782
At time: 875.8000385761261 and batch: 400, loss is 5.382476663589477 and perplexity is 217.56043273482342
At time: 876.9029777050018 and batch: 450, loss is 5.3548397731781 and perplexity is 211.63006482349329
At time: 878.0069017410278 and batch: 500, loss is 5.381706619262696 and perplexity is 217.39296604452645
At time: 879.1103405952454 and batch: 550, loss is 5.360401296615601 and perplexity is 212.8103293814058
At time: 880.2135560512543 and batch: 600, loss is 5.313430252075196 and perplexity is 203.04553253145053
At time: 881.3166835308075 and batch: 650, loss is 5.328755464553833 and perplexity is 206.1812145863693
At time: 882.4198710918427 and batch: 700, loss is 5.3476237773895265 and perplexity is 210.10843978956402
At time: 883.5231215953827 and batch: 750, loss is 5.3304387474060055 and perplexity is 206.52856815445793
At time: 884.6269865036011 and batch: 800, loss is 5.303470430374145 and perplexity is 201.03327273894337
At time: 885.7304787635803 and batch: 850, loss is 5.280719547271729 and perplexity is 196.51122360713464
At time: 886.833822965622 and batch: 900, loss is 5.327317714691162 and perplexity is 205.88499057245778
At time: 887.9370996952057 and batch: 950, loss is 5.304952487945557 and perplexity is 201.33143651627742
At time: 889.0401828289032 and batch: 1000, loss is 5.319866762161255 and perplexity is 204.35665214032065
At time: 890.144535779953 and batch: 1050, loss is 5.292328205108642 and perplexity is 198.80574756725358
At time: 891.248063325882 and batch: 1100, loss is 5.27349967956543 and perplexity is 195.09754798619323
At time: 892.4095325469971 and batch: 1150, loss is 5.293951053619384 and perplexity is 199.12864111140829
At time: 893.5132031440735 and batch: 1200, loss is 5.27166241645813 and perplexity is 194.73943153676018
At time: 894.6170363426208 and batch: 1250, loss is 5.288895864486694 and perplexity is 198.1245482468164
At time: 895.72030210495 and batch: 1300, loss is 5.269647989273071 and perplexity is 194.34753798490448
At time: 896.8240764141083 and batch: 1350, loss is 5.260843553543091 and perplexity is 192.64392824370745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.204106852213542 and perplexity of 182.0182309679263
Finished 28 epochs...
Completing Train Step...
At time: 900.31183385849 and batch: 50, loss is 5.341148014068604 and perplexity is 208.75222326982134
At time: 901.4156136512756 and batch: 100, loss is 5.357995719909668 and perplexity is 212.29901306215112
At time: 902.5190148353577 and batch: 150, loss is 5.330858345031738 and perplexity is 206.61524523477837
At time: 903.6230471134186 and batch: 200, loss is 5.313833026885987 and perplexity is 203.1273306293987
At time: 904.7266957759857 and batch: 250, loss is 5.339463214874268 and perplexity is 208.40081380255864
At time: 905.8299269676208 and batch: 300, loss is 5.349485874176025 and perplexity is 210.5000465317857
At time: 906.9338676929474 and batch: 350, loss is 5.349266481399536 and perplexity is 210.45386940777493
At time: 908.0370206832886 and batch: 400, loss is 5.380280523300171 and perplexity is 217.08316376976074
At time: 909.1396913528442 and batch: 450, loss is 5.3523055458068844 and perplexity is 211.09442512370978
At time: 910.2434189319611 and batch: 500, loss is 5.379742078781128 and perplexity is 216.9663079930518
At time: 911.3474862575531 and batch: 550, loss is 5.358620471954346 and perplexity is 212.43168874503152
At time: 912.4510576725006 and batch: 600, loss is 5.311806154251099 and perplexity is 202.7160343649275
At time: 913.5603847503662 and batch: 650, loss is 5.326389398574829 and perplexity is 205.69395290299119
At time: 914.6635687351227 and batch: 700, loss is 5.345675735473633 and perplexity is 209.69953815004823
At time: 915.7668867111206 and batch: 750, loss is 5.328020505905151 and perplexity is 206.02973559173057
At time: 916.8704376220703 and batch: 800, loss is 5.301079759597778 and perplexity is 200.55324239461365
At time: 917.974042892456 and batch: 850, loss is 5.27851716041565 and perplexity is 196.07890611112228
At time: 919.081353187561 and batch: 900, loss is 5.325082664489746 and perplexity is 205.42534114393044
At time: 920.2273452281952 and batch: 950, loss is 5.302766160964966 and perplexity is 200.89174099881356
At time: 921.3304190635681 and batch: 1000, loss is 5.317835254669189 and perplexity is 203.9419214773022
At time: 922.4332304000854 and batch: 1050, loss is 5.290395107269287 and perplexity is 198.42180782228658
At time: 923.5371193885803 and batch: 1100, loss is 5.271452350616455 and perplexity is 194.69852773056368
At time: 924.6423516273499 and batch: 1150, loss is 5.292168283462525 and perplexity is 198.7739567669313
At time: 925.7467486858368 and batch: 1200, loss is 5.269383544921875 and perplexity is 194.29615067115733
At time: 926.8515357971191 and batch: 1250, loss is 5.286807298660278 and perplexity is 197.7111839055542
At time: 927.9557068347931 and batch: 1300, loss is 5.267316074371338 and perplexity is 193.8948640686179
At time: 929.0644552707672 and batch: 1350, loss is 5.258423366546631 and perplexity is 192.17825764588568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.203310953776041 and perplexity of 181.87342057712846
Finished 29 epochs...
Completing Train Step...
At time: 932.514000415802 and batch: 50, loss is 5.338624401092529 and perplexity is 208.2260776236185
At time: 933.6167120933533 and batch: 100, loss is 5.355625152587891 and perplexity is 211.79634000490333
At time: 934.7292382717133 and batch: 150, loss is 5.328381614685059 and perplexity is 206.10414817288435
At time: 935.8317544460297 and batch: 200, loss is 5.311136980056762 and perplexity is 202.58042740335222
At time: 936.9342603683472 and batch: 250, loss is 5.337096490859985 and perplexity is 207.9081697980913
At time: 938.0363435745239 and batch: 300, loss is 5.346960582733154 and perplexity is 209.9691431905225
At time: 939.1391611099243 and batch: 350, loss is 5.347210988998413 and perplexity is 210.02172736291683
At time: 940.2435276508331 and batch: 400, loss is 5.378441610336304 and perplexity is 216.68433354509284
At time: 941.3459820747375 and batch: 450, loss is 5.349841108322144 and perplexity is 210.57483661928322
At time: 942.4485669136047 and batch: 500, loss is 5.377452068328857 and perplexity is 216.47002134764318
At time: 943.5514669418335 and batch: 550, loss is 5.356537027359009 and perplexity is 211.98955982672055
At time: 944.6549098491669 and batch: 600, loss is 5.309698839187622 and perplexity is 202.28929760442392
At time: 945.7630336284637 and batch: 650, loss is 5.324185962677002 and perplexity is 205.24121843206524
At time: 946.8660826683044 and batch: 700, loss is 5.343425035476685 and perplexity is 209.2280981342074
At time: 947.9691891670227 and batch: 750, loss is 5.325385656356811 and perplexity is 205.48759278197994
At time: 949.213704586029 and batch: 800, loss is 5.298538637161255 and perplexity is 200.04425901907325
At time: 950.3177361488342 and batch: 850, loss is 5.2757958984375 and perplexity is 195.54604938940204
At time: 951.4212219715118 and batch: 900, loss is 5.322821178436279 and perplexity is 204.96129950951843
At time: 952.5241043567657 and batch: 950, loss is 5.3003598499298095 and perplexity is 200.40891413435966
At time: 953.6273066997528 and batch: 1000, loss is 5.315638122558593 and perplexity is 203.4943260261567
At time: 954.7301788330078 and batch: 1050, loss is 5.288077449798584 and perplexity is 197.96246654052743
At time: 955.8333721160889 and batch: 1100, loss is 5.269291028976441 and perplexity is 194.27817601056793
At time: 956.9359760284424 and batch: 1150, loss is 5.2896902370452885 and perplexity is 198.2819954787284
At time: 958.0507054328918 and batch: 1200, loss is 5.26718584060669 and perplexity is 193.8696140547622
At time: 959.1538791656494 and batch: 1250, loss is 5.284577178955078 and perplexity is 197.27075558486302
At time: 960.2566826343536 and batch: 1300, loss is 5.264808940887451 and perplexity is 193.4093526378559
At time: 961.3600616455078 and batch: 1350, loss is 5.255758371353149 and perplexity is 191.66678535128588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.202108968098958 and perplexity of 181.65494266052008
Finished 30 epochs...
Completing Train Step...
At time: 964.7660925388336 and batch: 50, loss is 5.335784397125244 and perplexity is 207.6355536791596
At time: 965.897222995758 and batch: 100, loss is 5.352959251403808 and perplexity is 211.232463844319
At time: 966.9998087882996 and batch: 150, loss is 5.325615930557251 and perplexity is 205.53491672164012
At time: 968.1023404598236 and batch: 200, loss is 5.308169603347778 and perplexity is 201.98018597304286
At time: 969.2046368122101 and batch: 250, loss is 5.334433965682983 and perplexity is 207.3553453425979
At time: 970.3064777851105 and batch: 300, loss is 5.344563961029053 and perplexity is 209.4665291132397
At time: 971.4083003997803 and batch: 350, loss is 5.3449466514587405 and perplexity is 209.54670528962043
At time: 972.5104877948761 and batch: 400, loss is 5.376158504486084 and perplexity is 216.19018458736215
At time: 973.6117331981659 and batch: 450, loss is 5.347153902053833 and perplexity is 210.0097382064216
At time: 974.7146215438843 and batch: 500, loss is 5.37517617225647 and perplexity is 215.97791827640438
At time: 975.8171486854553 and batch: 550, loss is 5.354269065856934 and perplexity is 211.50932045424454
At time: 976.9486255645752 and batch: 600, loss is 5.3076460075378415 and perplexity is 201.8744576758393
At time: 978.0513958930969 and batch: 650, loss is 5.321936054229736 and perplexity is 204.77996356617342
At time: 979.1542403697968 and batch: 700, loss is 5.340882368087769 and perplexity is 208.69677644565846
At time: 980.2561945915222 and batch: 750, loss is 5.32264404296875 and perplexity is 204.92499680924718
At time: 981.3595395088196 and batch: 800, loss is 5.295599918365479 and perplexity is 199.457248147503
At time: 982.4619464874268 and batch: 850, loss is 5.2734489917755125 and perplexity is 195.0876591732907
At time: 983.56543135643 and batch: 900, loss is 5.320592775344848 and perplexity is 204.505071634665
At time: 984.6707301139832 and batch: 950, loss is 5.298137664794922 and perplexity is 199.96406287845562
At time: 985.7724795341492 and batch: 1000, loss is 5.313414535522461 and perplexity is 203.04234138070794
At time: 986.8753614425659 and batch: 1050, loss is 5.2860178565979 and perplexity is 197.55516397322808
At time: 987.9779160022736 and batch: 1100, loss is 5.267251825332641 and perplexity is 193.88240691017785
At time: 989.0808987617493 and batch: 1150, loss is 5.287382278442383 and perplexity is 197.82489652709225
At time: 990.1841225624084 and batch: 1200, loss is 5.2645024490356445 and perplexity is 193.3500833304531
At time: 991.2869083881378 and batch: 1250, loss is 5.282382307052612 and perplexity is 196.83824637104513
At time: 992.389652967453 and batch: 1300, loss is 5.262276630401612 and perplexity is 192.92019971104955
At time: 993.4928123950958 and batch: 1350, loss is 5.253132181167603 and perplexity is 191.1640922934061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.200131429036459 and perplexity of 181.29606787691745
Finished 31 epochs...
Completing Train Step...
At time: 996.8819081783295 and batch: 50, loss is 5.333180379867554 and perplexity is 207.0955704819824
At time: 998.0120084285736 and batch: 100, loss is 5.349654445648193 and perplexity is 210.53553382550956
At time: 999.1132164001465 and batch: 150, loss is 5.322967576980591 and perplexity is 204.99130774193395
At time: 1000.215229511261 and batch: 200, loss is 5.305859594345093 and perplexity is 201.51414840780356
At time: 1001.3163828849792 and batch: 250, loss is 5.3321099376678465 and perplexity is 206.874005251509
At time: 1002.4182622432709 and batch: 300, loss is 5.342296962738037 and perplexity is 208.99220669690826
At time: 1003.5198664665222 and batch: 350, loss is 5.342593431472778 and perplexity is 209.05417553745647
At time: 1004.6217131614685 and batch: 400, loss is 5.373941354751587 and perplexity is 215.71138955328115
At time: 1005.7507123947144 and batch: 450, loss is 5.344718999862671 and perplexity is 209.4990070772033
At time: 1006.8518323898315 and batch: 500, loss is 5.37289870262146 and perplexity is 215.4865948251868
At time: 1007.9535801410675 and batch: 550, loss is 5.352099838256836 and perplexity is 211.05100587267574
At time: 1009.0571691989899 and batch: 600, loss is 5.3054203414917 and perplexity is 201.42565218064934
At time: 1010.1596081256866 and batch: 650, loss is 5.31976058959961 and perplexity is 204.33495622284954
At time: 1011.2622652053833 and batch: 700, loss is 5.338559198379516 and perplexity is 208.21250116105332
At time: 1012.3646006584167 and batch: 750, loss is 5.320087661743164 and perplexity is 204.40179942566343
At time: 1013.4662222862244 and batch: 800, loss is 5.29323091506958 and perplexity is 198.98529252219151
At time: 1014.5680556297302 and batch: 850, loss is 5.271127376556397 and perplexity is 194.63526603928076
At time: 1015.6699018478394 and batch: 900, loss is 5.318328475952148 and perplexity is 204.04253478373468
At time: 1016.7719113826752 and batch: 950, loss is 5.295840291976929 and perplexity is 199.5051981692992
At time: 1017.8742773532867 and batch: 1000, loss is 5.311511554718018 and perplexity is 202.65632311174105
At time: 1018.9771316051483 and batch: 1050, loss is 5.283952579498291 and perplexity is 197.14757885015015
At time: 1020.0802021026611 and batch: 1100, loss is 5.264633588790893 and perplexity is 193.37544087571317
At time: 1021.1820602416992 and batch: 1150, loss is 5.284954605102539 and perplexity is 197.34522477857652
At time: 1022.2843039035797 and batch: 1200, loss is 5.262064256668091 and perplexity is 192.8792328782589
At time: 1023.3867883682251 and batch: 1250, loss is 5.280080842971802 and perplexity is 196.3857511178075
At time: 1024.4890024662018 and batch: 1300, loss is 5.259757995605469 and perplexity is 192.43491556647888
At time: 1025.591534614563 and batch: 1350, loss is 5.2509012794494625 and perplexity is 190.73809934234308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.199795328776042 and perplexity of 181.23514446005314
Finished 32 epochs...
Completing Train Step...
At time: 1029.0135939121246 and batch: 50, loss is 5.330280456542969 and perplexity is 206.49587915641615
At time: 1030.1215028762817 and batch: 100, loss is 5.347245244979859 and perplexity is 210.0289219865412
At time: 1031.228548526764 and batch: 150, loss is 5.320313901901245 and perplexity is 204.44804855258505
At time: 1032.3364005088806 and batch: 200, loss is 5.303572378158569 and perplexity is 201.0537686804348
At time: 1033.4738991260529 and batch: 250, loss is 5.329731636047363 and perplexity is 206.38258107867435
At time: 1034.5801770687103 and batch: 300, loss is 5.339794130325317 and perplexity is 208.46978826358514
At time: 1035.687350988388 and batch: 350, loss is 5.340570650100708 and perplexity is 208.63173204488027
At time: 1036.7957878112793 and batch: 400, loss is 5.371744394302368 and perplexity is 215.23800036105922
At time: 1037.903448343277 and batch: 450, loss is 5.341951026916504 and perplexity is 208.9199213099637
At time: 1039.010802268982 and batch: 500, loss is 5.3705495262145995 and perplexity is 214.98097293066982
At time: 1040.1186127662659 and batch: 550, loss is 5.3498721694946285 and perplexity is 210.5813774221864
At time: 1041.2255263328552 and batch: 600, loss is 5.303371620178223 and perplexity is 201.01340958323445
At time: 1042.333149433136 and batch: 650, loss is 5.3172966003417965 and perplexity is 203.83209686016974
At time: 1043.4404106140137 and batch: 700, loss is 5.335963163375855 and perplexity is 207.67267522652534
At time: 1044.5486917495728 and batch: 750, loss is 5.317160863876342 and perplexity is 203.80443128945168
At time: 1045.6556944847107 and batch: 800, loss is 5.290550594329834 and perplexity is 198.45266224460283
At time: 1046.7637023925781 and batch: 850, loss is 5.268979825973511 and perplexity is 194.21772546547314
At time: 1047.8706576824188 and batch: 900, loss is 5.315846757888794 and perplexity is 203.536786561291
At time: 1048.97754240036 and batch: 950, loss is 5.293532543182373 and perplexity is 199.04532113315162
At time: 1050.0850191116333 and batch: 1000, loss is 5.309243288040161 and perplexity is 202.19716546982437
At time: 1051.1925463676453 and batch: 1050, loss is 5.281667432785034 and perplexity is 196.69758205847853
At time: 1052.3009130954742 and batch: 1100, loss is 5.262193622589112 and perplexity is 192.9041864919048
At time: 1053.4069573879242 and batch: 1150, loss is 5.282572660446167 and perplexity is 196.8757187656089
At time: 1054.5098295211792 and batch: 1200, loss is 5.259578714370727 and perplexity is 192.40041868962248
At time: 1055.6112954616547 and batch: 1250, loss is 5.27763970375061 and perplexity is 195.90693082954408
At time: 1056.7138085365295 and batch: 1300, loss is 5.257036781311035 and perplexity is 191.91197076862153
At time: 1057.815545797348 and batch: 1350, loss is 5.247586040496826 and perplexity is 190.1068039913245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.19714111328125 and perplexity of 180.75474515509472
Finished 33 epochs...
Completing Train Step...
At time: 1061.2141435146332 and batch: 50, loss is 5.327088756561279 and perplexity is 205.83785692606702
At time: 1062.315826177597 and batch: 100, loss is 5.344428415298462 and perplexity is 209.4381387436569
At time: 1063.4180748462677 and batch: 150, loss is 5.31726710319519 and perplexity is 203.82608448360003
At time: 1064.5199432373047 and batch: 200, loss is 5.300786647796631 and perplexity is 200.49446648688635
At time: 1065.6214230060577 and batch: 250, loss is 5.3272946834564205 and perplexity is 205.88024884151432
At time: 1066.7231631278992 and batch: 300, loss is 5.337538766860962 and perplexity is 208.00014292925502
At time: 1067.8249740600586 and batch: 350, loss is 5.3385012912750245 and perplexity is 208.20044452707782
At time: 1068.9278967380524 and batch: 400, loss is 5.369047288894653 and perplexity is 214.65826294423633
At time: 1070.0298998355865 and batch: 450, loss is 5.338971824645996 and perplexity is 208.29843283565557
At time: 1071.132263660431 and batch: 500, loss is 5.3678077220916744 and perplexity is 214.39234453337198
At time: 1072.2342700958252 and batch: 550, loss is 5.347461290359497 and perplexity is 210.0743026666935
At time: 1073.3367519378662 and batch: 600, loss is 5.300910816192627 and perplexity is 200.51936310885097
At time: 1074.4390070438385 and batch: 650, loss is 5.3150155735015865 and perplexity is 203.3676802510771
At time: 1075.540941953659 and batch: 700, loss is 5.333796882629395 and perplexity is 207.22328483723086
At time: 1076.642410993576 and batch: 750, loss is 5.314776363372803 and perplexity is 203.31903846013034
At time: 1077.7443580627441 and batch: 800, loss is 5.288109693527222 and perplexity is 197.96884969148687
At time: 1078.8462920188904 and batch: 850, loss is 5.266536521911621 and perplexity is 193.74377175025256
At time: 1079.9493608474731 and batch: 900, loss is 5.313298025131226 and perplexity is 203.01868621613934
At time: 1081.051577091217 and batch: 950, loss is 5.290812959671021 and perplexity is 198.50473617594074
At time: 1082.1538889408112 and batch: 1000, loss is 5.3066866588592525 and perplexity is 201.68088254949433
At time: 1083.255945444107 and batch: 1050, loss is 5.279083976745605 and perplexity is 196.19007834120717
At time: 1084.357836008072 and batch: 1100, loss is 5.2597545146942135 and perplexity is 192.4342457187812
At time: 1085.4591808319092 and batch: 1150, loss is 5.280483646392822 and perplexity is 196.46487190418938
At time: 1086.561764717102 and batch: 1200, loss is 5.257283611297607 and perplexity is 191.95934624439295
At time: 1087.6646118164062 and batch: 1250, loss is 5.275413703918457 and perplexity is 195.47132704125048
At time: 1088.767233133316 and batch: 1300, loss is 5.254770231246948 and perplexity is 191.4774852565646
At time: 1089.869255065918 and batch: 1350, loss is 5.2451192665100095 and perplexity is 189.63843139469344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.196525065104167 and perplexity of 180.64342581640116
Finished 34 epochs...
Completing Train Step...
At time: 1093.2640810012817 and batch: 50, loss is 5.324328212738037 and perplexity is 205.27041608454886
At time: 1094.395848274231 and batch: 100, loss is 5.341937484741211 and perplexity is 208.91709209892417
At time: 1095.4993307590485 and batch: 150, loss is 5.31465259552002 and perplexity is 203.29387565651535
At time: 1096.6024379730225 and batch: 200, loss is 5.298231000900269 and perplexity is 199.98272761632742
At time: 1097.7047898769379 and batch: 250, loss is 5.3250179100036625 and perplexity is 205.4120393622158
At time: 1098.807406425476 and batch: 300, loss is 5.335712041854858 and perplexity is 207.620530696034
At time: 1099.9101872444153 and batch: 350, loss is 5.336369524002075 and perplexity is 207.7570823735883
At time: 1101.0138821601868 and batch: 400, loss is 5.366625461578369 and perplexity is 214.13902670341514
At time: 1102.1171538829803 and batch: 450, loss is 5.336546392440796 and perplexity is 207.7938312941472
At time: 1103.220856666565 and batch: 500, loss is 5.36554515838623 and perplexity is 213.9078165403308
At time: 1104.3234176635742 and batch: 550, loss is 5.345224161148071 and perplexity is 209.60486460021843
At time: 1105.4267585277557 and batch: 600, loss is 5.298855562210083 and perplexity is 200.1076681030633
At time: 1106.5298783779144 and batch: 650, loss is 5.312686347961426 and perplexity is 202.89454229261082
At time: 1107.6331615447998 and batch: 700, loss is 5.331498107910156 and perplexity is 206.74747229126592
At time: 1108.7361371517181 and batch: 750, loss is 5.31234920501709 and perplexity is 202.82614935897786
At time: 1109.8397028446198 and batch: 800, loss is 5.2853755855560305 and perplexity is 197.42832075046098
At time: 1110.9412348270416 and batch: 850, loss is 5.26407530784607 and perplexity is 193.26751318166612
At time: 1112.043855190277 and batch: 900, loss is 5.311083040237427 and perplexity is 202.56950054639617
At time: 1113.1468205451965 and batch: 950, loss is 5.288539657592773 and perplexity is 198.05398748473698
At time: 1114.2505068778992 and batch: 1000, loss is 5.304156513214111 and perplexity is 201.17124554260616
At time: 1115.3542733192444 and batch: 1050, loss is 5.276872663497925 and perplexity is 195.7567199440803
At time: 1116.4577238559723 and batch: 1100, loss is 5.257916746139526 and perplexity is 192.08092087723898
At time: 1117.588231086731 and batch: 1150, loss is 5.278336858749389 and perplexity is 196.04355594457468
At time: 1118.6904006004333 and batch: 1200, loss is 5.254781265258789 and perplexity is 191.47959803306023
At time: 1119.7936322689056 and batch: 1250, loss is 5.272960176467896 and perplexity is 194.99232064252462
At time: 1120.896784543991 and batch: 1300, loss is 5.2523003101348875 and perplexity is 191.0051345478706
At time: 1122.0000967979431 and batch: 1350, loss is 5.242241115570068 and perplexity is 189.0934080710579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.194130859375 and perplexity of 180.2114456224533
Finished 35 epochs...
Completing Train Step...
At time: 1125.3734111785889 and batch: 50, loss is 5.321414546966553 and perplexity is 204.6731971699645
At time: 1126.5056245326996 and batch: 100, loss is 5.3393714904785154 and perplexity is 208.3816992404875
At time: 1127.6084954738617 and batch: 150, loss is 5.312052211761475 and perplexity is 202.76592030480998
At time: 1128.713093996048 and batch: 200, loss is 5.295875835418701 and perplexity is 199.5122893967161
At time: 1129.8159980773926 and batch: 250, loss is 5.322883930206299 and perplexity is 204.97416159740328
At time: 1130.9186100959778 and batch: 300, loss is 5.333542909622192 and perplexity is 207.17066239904062
At time: 1132.0206654071808 and batch: 350, loss is 5.3340202331542965 and perplexity is 207.26957343577007
At time: 1133.1230130195618 and batch: 400, loss is 5.364266214370727 and perplexity is 213.6344152882116
At time: 1134.2255775928497 and batch: 450, loss is 5.334067058563233 and perplexity is 207.27927914554135
At time: 1135.328016281128 and batch: 500, loss is 5.3632103443145756 and perplexity is 213.40896415064353
At time: 1136.4304842948914 and batch: 550, loss is 5.342969951629638 and perplexity is 209.1329034688185
At time: 1137.533688545227 and batch: 600, loss is 5.296683702468872 and perplexity is 199.67353392472486
At time: 1138.6369485855103 and batch: 650, loss is 5.310464725494385 and perplexity is 202.4442875522271
At time: 1139.7399408817291 and batch: 700, loss is 5.329100532531738 and perplexity is 206.25237339777618
At time: 1140.8442687988281 and batch: 750, loss is 5.309946231842041 and perplexity is 202.339348681598
At time: 1141.9473655223846 and batch: 800, loss is 5.283062295913696 and perplexity is 196.97213970384107
At time: 1143.0499629974365 and batch: 850, loss is 5.261930980682373 and perplexity is 192.85352842130402
At time: 1144.1528797149658 and batch: 900, loss is 5.308875904083252 and perplexity is 202.1228951188014
At time: 1145.301732301712 and batch: 950, loss is 5.286374139785766 and perplexity is 197.62556209691712
At time: 1146.4042394161224 and batch: 1000, loss is 5.302325458526611 and perplexity is 200.80322702430485
At time: 1147.5075907707214 and batch: 1050, loss is 5.274797134399414 and perplexity is 195.35084252650645
At time: 1148.6103143692017 and batch: 1100, loss is 5.25568473815918 and perplexity is 191.65267283328382
At time: 1149.7127327919006 and batch: 1150, loss is 5.27620415687561 and perplexity is 195.62589901263652
At time: 1150.81565284729 and batch: 1200, loss is 5.252440490722656 and perplexity is 191.03191163666853
At time: 1151.918936252594 and batch: 1250, loss is 5.270845861434936 and perplexity is 194.58048098049431
At time: 1153.0218679904938 and batch: 1300, loss is 5.250338726043701 and perplexity is 190.6308291503844
At time: 1154.1245753765106 and batch: 1350, loss is 5.2399685764312744 and perplexity is 188.66417381088584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1932450358072915 and perplexity of 180.05188076034185
Finished 36 epochs...
Completing Train Step...
At time: 1157.5282106399536 and batch: 50, loss is 5.319111661911011 and perplexity is 204.20240062615807
At time: 1158.631101846695 and batch: 100, loss is 5.336764402389527 and perplexity is 207.8391373550608
At time: 1159.734662771225 and batch: 150, loss is 5.309444942474365 and perplexity is 202.23794353622566
At time: 1160.8369598388672 and batch: 200, loss is 5.293526649475098 and perplexity is 199.04414802175137
At time: 1161.9402239322662 and batch: 250, loss is 5.320368385314941 and perplexity is 204.45918788364537
At time: 1163.0423533916473 and batch: 300, loss is 5.331353054046631 and perplexity is 206.7174849465787
At time: 1164.1441507339478 and batch: 350, loss is 5.331862268447876 and perplexity is 206.82277527230247
At time: 1165.246916770935 and batch: 400, loss is 5.361893148422241 and perplexity is 213.12804779123022
At time: 1166.3498973846436 and batch: 450, loss is 5.331767435073853 and perplexity is 206.80316250068597
At time: 1167.453281879425 and batch: 500, loss is 5.361108703613281 and perplexity is 212.96092615791542
At time: 1168.5561583042145 and batch: 550, loss is 5.340811061859131 and perplexity is 208.68189559615612
At time: 1169.6589641571045 and batch: 600, loss is 5.294634027481079 and perplexity is 199.26468722108234
At time: 1170.7623269557953 and batch: 650, loss is 5.308398065567016 and perplexity is 202.02633608615022
At time: 1171.8656775951385 and batch: 700, loss is 5.326765346527099 and perplexity is 205.77129766127027
At time: 1172.9975526332855 and batch: 750, loss is 5.307466564178466 and perplexity is 201.83823589495813
At time: 1174.1011850833893 and batch: 800, loss is 5.28053650856018 and perplexity is 196.4752577376344
At time: 1175.2042067050934 and batch: 850, loss is 5.259299354553223 and perplexity is 192.34667725071833
At time: 1176.306976556778 and batch: 900, loss is 5.306671304702759 and perplexity is 201.6777859334349
At time: 1177.4102573394775 and batch: 950, loss is 5.283911199569702 and perplexity is 197.13942106620118
At time: 1178.513061761856 and batch: 1000, loss is 5.299725608825684 and perplexity is 200.28184686328512
At time: 1179.6165173053741 and batch: 1050, loss is 5.2727554988861085 and perplexity is 194.9524141699879
At time: 1180.7203080654144 and batch: 1100, loss is 5.253717823028564 and perplexity is 191.27607877695146
At time: 1181.8230392932892 and batch: 1150, loss is 5.273993740081787 and perplexity is 195.1939617966586
At time: 1182.926192522049 and batch: 1200, loss is 5.25025616645813 and perplexity is 190.61509139779284
At time: 1184.0291163921356 and batch: 1250, loss is 5.2685967063903805 and perplexity is 194.14333110333476
At time: 1185.1328370571136 and batch: 1300, loss is 5.248304586410523 and perplexity is 190.24345354710889
At time: 1186.2362332344055 and batch: 1350, loss is 5.237939081192017 and perplexity is 188.2816690454084
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192777506510416 and perplexity of 179.9677209062606
Finished 37 epochs...
Completing Train Step...
At time: 1189.6409821510315 and batch: 50, loss is 5.3164910888671875 and perplexity is 203.66797387760235
At time: 1190.7439830303192 and batch: 100, loss is 5.334020156860351 and perplexity is 207.26955762235715
At time: 1191.8486886024475 and batch: 150, loss is 5.306758375167846 and perplexity is 201.69534687656264
At time: 1192.9534561634064 and batch: 200, loss is 5.2915776824951175 and perplexity is 198.65659533606808
At time: 1194.0590229034424 and batch: 250, loss is 5.318504714965821 and perplexity is 204.07849820779833
At time: 1195.1637275218964 and batch: 300, loss is 5.329573612213135 and perplexity is 206.34997028860337
At time: 1196.2660551071167 and batch: 350, loss is 5.3300775623321535 and perplexity is 206.45398658800158
At time: 1197.371154308319 and batch: 400, loss is 5.359903497695923 and perplexity is 212.70441899256906
At time: 1198.4755663871765 and batch: 450, loss is 5.32964280128479 and perplexity is 206.3642479454069
At time: 1199.5810372829437 and batch: 500, loss is 5.359185590744018 and perplexity is 212.55177181126587
At time: 1200.6852042675018 and batch: 550, loss is 5.338587779998779 and perplexity is 208.21845229653334
At time: 1201.8337774276733 and batch: 600, loss is 5.292312269210815 and perplexity is 198.8025794444164
At time: 1202.9366436004639 and batch: 650, loss is 5.30613974571228 and perplexity is 201.57061078062378
At time: 1204.039367198944 and batch: 700, loss is 5.324386205673218 and perplexity is 205.28232066367067
At time: 1205.141758441925 and batch: 750, loss is 5.304974460601807 and perplexity is 201.33586035132583
At time: 1206.244597196579 and batch: 800, loss is 5.278456354141236 and perplexity is 196.06698364583454
At time: 1207.3477487564087 and batch: 850, loss is 5.2573424816131595 and perplexity is 191.97064728432417
At time: 1208.45148396492 and batch: 900, loss is 5.304098625183105 and perplexity is 201.15960047236499
At time: 1209.5545592308044 and batch: 950, loss is 5.28120714187622 and perplexity is 196.60706478340887
At time: 1210.657636642456 and batch: 1000, loss is 5.297683000564575 and perplexity is 199.87316703681975
At time: 1211.760113477707 and batch: 1050, loss is 5.270731897354126 and perplexity is 194.55830705837502
At time: 1212.8635551929474 and batch: 1100, loss is 5.251348705291748 and perplexity is 190.82345959186395
At time: 1213.9672005176544 and batch: 1150, loss is 5.271791114807129 and perplexity is 194.7644957929134
At time: 1215.0706632137299 and batch: 1200, loss is 5.248044843673706 and perplexity is 190.19404560877743
At time: 1216.1736018657684 and batch: 1250, loss is 5.265958795547485 and perplexity is 193.63187319191132
At time: 1217.276377916336 and batch: 1300, loss is 5.24608097076416 and perplexity is 189.8208952049644
At time: 1218.3790755271912 and batch: 1350, loss is 5.235184030532837 and perplexity is 187.76365741079655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.191822509765625 and perplexity of 179.79593435948024
Finished 38 epochs...
Completing Train Step...
At time: 1221.7564244270325 and batch: 50, loss is 5.313372325897217 and perplexity is 203.0337712204425
At time: 1222.8872022628784 and batch: 100, loss is 5.331068677902222 and perplexity is 206.65870778303523
At time: 1223.9892926216125 and batch: 150, loss is 5.304205570220947 and perplexity is 201.1811146438463
At time: 1225.0912783145905 and batch: 200, loss is 5.288917179107666 and perplexity is 198.12877124147317
At time: 1226.193085193634 and batch: 250, loss is 5.315796003341675 and perplexity is 203.52645640602043
At time: 1227.2953741550446 and batch: 300, loss is 5.327313556671142 and perplexity is 205.884134500325
At time: 1228.3958587646484 and batch: 350, loss is 5.327463703155518 and perplexity is 205.91504960014757
At time: 1229.5288569927216 and batch: 400, loss is 5.357477779388428 and perplexity is 212.189083271671
At time: 1230.630044221878 and batch: 450, loss is 5.326832294464111 and perplexity is 205.78507408629142
At time: 1231.7319667339325 and batch: 500, loss is 5.356562538146973 and perplexity is 211.99496791641388
At time: 1232.8331627845764 and batch: 550, loss is 5.336173906326294 and perplexity is 207.71644539079293
At time: 1233.935423374176 and batch: 600, loss is 5.289801206588745 and perplexity is 198.30399996213345
At time: 1235.0373573303223 and batch: 650, loss is 5.3037308406829835 and perplexity is 201.08563069256365
At time: 1236.1395797729492 and batch: 700, loss is 5.321854219436646 and perplexity is 204.7632061259061
At time: 1237.241670370102 and batch: 750, loss is 5.302119846343994 and perplexity is 200.7619436788447
At time: 1238.343355178833 and batch: 800, loss is 5.275706634521485 and perplexity is 195.52859496230906
At time: 1239.4449775218964 and batch: 850, loss is 5.254483680725098 and perplexity is 191.4226251437141
At time: 1240.5472929477692 and batch: 900, loss is 5.301414890289307 and perplexity is 200.6204652050099
At time: 1241.649172782898 and batch: 950, loss is 5.279042205810547 and perplexity is 196.1818834693406
At time: 1242.7509727478027 and batch: 1000, loss is 5.295115251541137 and perplexity is 199.36060125911357
At time: 1243.8530564308167 and batch: 1050, loss is 5.268337707519532 and perplexity is 194.09305471084167
At time: 1244.9544410705566 and batch: 1100, loss is 5.249053936004639 and perplexity is 190.38606582836186
At time: 1246.0560772418976 and batch: 1150, loss is 5.269164810180664 and perplexity is 194.25365600062176
At time: 1247.1576991081238 and batch: 1200, loss is 5.245636377334595 and perplexity is 189.73652083969614
At time: 1248.2595574855804 and batch: 1250, loss is 5.26369384765625 and perplexity is 193.19380337897334
At time: 1249.3631296157837 and batch: 1300, loss is 5.2438881301879885 and perplexity is 189.405104291959
At time: 1250.4657456874847 and batch: 1350, loss is 5.232547750473023 and perplexity is 187.2693117279472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1909883626302085 and perplexity of 179.64602062962132
Finished 39 epochs...
Completing Train Step...
At time: 1253.8637082576752 and batch: 50, loss is 5.31064248085022 and perplexity is 202.48027630709987
At time: 1255.001995563507 and batch: 100, loss is 5.328313388824463 and perplexity is 206.0900870196755
At time: 1256.1093518733978 and batch: 150, loss is 5.301607236862183 and perplexity is 200.65905757537706
At time: 1257.2477352619171 and batch: 200, loss is 5.286463775634766 and perplexity is 197.6432772259031
At time: 1258.3544347286224 and batch: 250, loss is 5.313348226547241 and perplexity is 203.02887829749127
At time: 1259.4611141681671 and batch: 300, loss is 5.325346937179566 and perplexity is 205.47963662548213
At time: 1260.5615799427032 and batch: 350, loss is 5.325092802047729 and perplexity is 205.42742366579336
At time: 1261.663156747818 and batch: 400, loss is 5.355234632492065 and perplexity is 211.71364542590754
At time: 1262.7646584510803 and batch: 450, loss is 5.324344549179077 and perplexity is 205.2737694999898
At time: 1263.8669896125793 and batch: 500, loss is 5.354498729705811 and perplexity is 211.5579020773612
At time: 1264.9692528247833 and batch: 550, loss is 5.33419641494751 and perplexity is 207.3060937779117
At time: 1266.070788383484 and batch: 600, loss is 5.287557697296142 and perplexity is 197.85960178757557
At time: 1267.172291278839 and batch: 650, loss is 5.301565685272217 and perplexity is 200.6507200457137
At time: 1268.2735965251923 and batch: 700, loss is 5.319532518386841 and perplexity is 204.2883586155611
At time: 1269.3752617835999 and batch: 750, loss is 5.299920768737793 and perplexity is 200.32093766527066
At time: 1270.4770438671112 and batch: 800, loss is 5.273583326339722 and perplexity is 195.11386794930118
At time: 1271.5791790485382 and batch: 850, loss is 5.25218994140625 and perplexity is 190.9840547173058
At time: 1272.6812648773193 and batch: 900, loss is 5.2988721370697025 and perplexity is 200.11098488705852
At time: 1273.7830941677094 and batch: 950, loss is 5.276602582931519 and perplexity is 195.70385699722857
At time: 1274.8847935199738 and batch: 1000, loss is 5.292619476318359 and perplexity is 198.8636623918972
At time: 1275.9865505695343 and batch: 1050, loss is 5.266127138137818 and perplexity is 193.66447242685823
At time: 1277.0883221626282 and batch: 1100, loss is 5.246615362167359 and perplexity is 189.92236096831058
At time: 1278.1906173229218 and batch: 1150, loss is 5.267034721374512 and perplexity is 193.8403188411345
At time: 1279.292579650879 and batch: 1200, loss is 5.243424921035767 and perplexity is 189.31739043067347
At time: 1280.3949868679047 and batch: 1250, loss is 5.261318035125733 and perplexity is 192.73535592832783
At time: 1281.4964513778687 and batch: 1300, loss is 5.241418418884277 and perplexity is 188.93790552541807
At time: 1282.5982348918915 and batch: 1350, loss is 5.229606819152832 and perplexity is 186.71937460380292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.188309733072916 and perplexity of 179.16545939900894
Finished 40 epochs...
Completing Train Step...
At time: 1286.0182478427887 and batch: 50, loss is 5.30800422668457 and perplexity is 201.9467859257228
At time: 1287.1205639839172 and batch: 100, loss is 5.325784206390381 and perplexity is 205.56950619119306
At time: 1288.2230424880981 and batch: 150, loss is 5.299000930786133 and perplexity is 200.13675958427459
At time: 1289.3254625797272 and batch: 200, loss is 5.283904390335083 and perplexity is 197.13807870220077
At time: 1290.427684545517 and batch: 250, loss is 5.311389093399048 and perplexity is 202.63150707064878
At time: 1291.5293760299683 and batch: 300, loss is 5.323338422775269 and perplexity is 205.0673420039774
At time: 1292.6306087970734 and batch: 350, loss is 5.323002271652221 and perplexity is 204.99841997142073
At time: 1293.7329649925232 and batch: 400, loss is 5.353138446807861 and perplexity is 211.27031912267137
At time: 1294.8354752063751 and batch: 450, loss is 5.321876821517944 and perplexity is 204.76783425284026
At time: 1295.9374809265137 and batch: 500, loss is 5.352467193603515 and perplexity is 211.12855083051042
At time: 1297.0399498939514 and batch: 550, loss is 5.332039060592652 and perplexity is 206.85934314669265
At time: 1298.1419069766998 and batch: 600, loss is 5.285254030227661 and perplexity is 197.40432374461432
At time: 1299.2443504333496 and batch: 650, loss is 5.299148731231689 and perplexity is 200.16634207261194
At time: 1300.346216917038 and batch: 700, loss is 5.316967859268188 and perplexity is 203.76509989074327
At time: 1301.4480443000793 and batch: 750, loss is 5.297506227493286 and perplexity is 199.8378379659205
At time: 1302.5500977039337 and batch: 800, loss is 5.271250066757202 and perplexity is 194.65914734412598
At time: 1303.652536869049 and batch: 850, loss is 5.250104608535767 and perplexity is 190.58620435965457
At time: 1304.754996061325 and batch: 900, loss is 5.296781301498413 and perplexity is 199.69302281889404
At time: 1305.857167005539 and batch: 950, loss is 5.274741592407227 and perplexity is 195.33999265285175
At time: 1306.959597826004 and batch: 1000, loss is 5.291208448410035 and perplexity is 198.58325808998214
At time: 1308.0611896514893 and batch: 1050, loss is 5.263976068496704 and perplexity is 193.24833439106553
At time: 1309.1648514270782 and batch: 1100, loss is 5.244457626342774 and perplexity is 189.51300049086905
At time: 1310.266536474228 and batch: 1150, loss is 5.265173740386963 and perplexity is 193.4799211437944
At time: 1311.3683383464813 and batch: 1200, loss is 5.241494026184082 and perplexity is 188.95219115032762
At time: 1312.4707100391388 and batch: 1250, loss is 5.259645223617554 and perplexity is 192.41321552210775
At time: 1313.5731751918793 and batch: 1300, loss is 5.2395759868621825 and perplexity is 188.59012076136486
At time: 1314.675038099289 and batch: 1350, loss is 5.227691602706909 and perplexity is 186.36210881665068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1894608561197915 and perplexity of 179.37181963875398
Annealing...
Finished 41 epochs...
Completing Train Step...
At time: 1318.0795979499817 and batch: 50, loss is 5.307069444656372 and perplexity is 201.75809790441267
At time: 1319.1834108829498 and batch: 100, loss is 5.325982542037964 and perplexity is 205.6102819958409
At time: 1320.287838459015 and batch: 150, loss is 5.299472970962524 and perplexity is 200.23125447650932
At time: 1321.391569852829 and batch: 200, loss is 5.284239950180054 and perplexity is 197.2042414254837
At time: 1322.4941267967224 and batch: 250, loss is 5.311412677764893 and perplexity is 202.6362860625978
At time: 1323.5968537330627 and batch: 300, loss is 5.323069334030151 and perplexity is 205.0121681139223
At time: 1324.7000999450684 and batch: 350, loss is 5.320812044143676 and perplexity is 204.54991813261577
At time: 1325.8038370609283 and batch: 400, loss is 5.349328289031982 and perplexity is 210.4668774651766
At time: 1326.9073779582977 and batch: 450, loss is 5.315919618606568 and perplexity is 203.5516169379226
At time: 1328.0108668804169 and batch: 500, loss is 5.346352367401123 and perplexity is 209.84147556701924
At time: 1329.1137697696686 and batch: 550, loss is 5.322696418762207 and perplexity is 204.93573019963668
At time: 1330.217229604721 and batch: 600, loss is 5.277989320755005 and perplexity is 195.9754351982891
At time: 1331.3200643062592 and batch: 650, loss is 5.292448740005494 and perplexity is 198.82971204177875
At time: 1332.4233057498932 and batch: 700, loss is 5.307577323913574 and perplexity is 201.8605926825936
At time: 1333.5259416103363 and batch: 750, loss is 5.285932712554931 and perplexity is 197.53834404392654
At time: 1334.629281282425 and batch: 800, loss is 5.260984210968018 and perplexity is 192.67102694835435
At time: 1335.7324867248535 and batch: 850, loss is 5.2344879531860355 and perplexity is 187.63300485973622
At time: 1336.835417509079 and batch: 900, loss is 5.276128797531128 and perplexity is 195.61115732859204
At time: 1337.9382269382477 and batch: 950, loss is 5.254582633972168 and perplexity is 191.44156797124643
At time: 1339.0417490005493 and batch: 1000, loss is 5.271275930404663 and perplexity is 194.664182004795
At time: 1340.145173549652 and batch: 1050, loss is 5.2420186519622805 and perplexity is 189.05134634806436
At time: 1341.2940092086792 and batch: 1100, loss is 5.220418395996094 and perplexity is 185.01157598194345
At time: 1342.3971512317657 and batch: 1150, loss is 5.239345140457154 and perplexity is 188.54659043456618
At time: 1343.5001392364502 and batch: 1200, loss is 5.214042892456055 and perplexity is 183.8357861331898
At time: 1344.602882862091 and batch: 1250, loss is 5.233260917663574 and perplexity is 187.40291369147465
At time: 1345.7058885097504 and batch: 1300, loss is 5.217797031402588 and perplexity is 184.52722829057186
At time: 1346.809173822403 and batch: 1350, loss is 5.211213111877441 and perplexity is 183.31630654920602
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.173327229817708 and perplexity of 176.50112138649135
Finished 42 epochs...
Completing Train Step...
At time: 1350.1900734901428 and batch: 50, loss is 5.301094369888306 and perplexity is 200.5561725571565
At time: 1351.3212242126465 and batch: 100, loss is 5.319106864929199 and perplexity is 204.2014210733058
At time: 1352.424528837204 and batch: 150, loss is 5.291671829223633 and perplexity is 198.67529908505153
At time: 1353.5281903743744 and batch: 200, loss is 5.277007942199707 and perplexity is 195.78320345030616
At time: 1354.6315605640411 and batch: 250, loss is 5.304375944137573 and perplexity is 201.2153935783345
At time: 1355.7353847026825 and batch: 300, loss is 5.315811195373535 and perplexity is 203.52954840991737
At time: 1356.8387598991394 and batch: 350, loss is 5.313886661529541 and perplexity is 203.13822558354397
At time: 1357.9426882266998 and batch: 400, loss is 5.342899932861328 and perplexity is 209.11826075314286
At time: 1359.0457892417908 and batch: 450, loss is 5.310013732910156 and perplexity is 202.3530072647351
At time: 1360.1533589363098 and batch: 500, loss is 5.3413939285278325 and perplexity is 208.80356477246977
At time: 1361.2557249069214 and batch: 550, loss is 5.318843545913697 and perplexity is 204.1476580348704
At time: 1362.359084367752 and batch: 600, loss is 5.2740943813323975 and perplexity is 195.2136073496454
At time: 1363.4619433879852 and batch: 650, loss is 5.28865044593811 and perplexity is 198.07593077380568
At time: 1364.5649302005768 and batch: 700, loss is 5.3047870254516605 and perplexity is 201.29812647054928
At time: 1365.6672959327698 and batch: 750, loss is 5.283683023452759 and perplexity is 197.09444369018252
At time: 1366.7702341079712 and batch: 800, loss is 5.258955173492431 and perplexity is 192.28048655874719
At time: 1367.8730614185333 and batch: 850, loss is 5.232919788360595 and perplexity is 187.3389959688748
At time: 1369.0078094005585 and batch: 900, loss is 5.274979152679443 and perplexity is 195.38640318711242
At time: 1370.1106848716736 and batch: 950, loss is 5.253770523071289 and perplexity is 191.28615930009482
At time: 1371.2133824825287 and batch: 1000, loss is 5.271172790527344 and perplexity is 194.64410540031173
At time: 1372.3161103725433 and batch: 1050, loss is 5.242784738540649 and perplexity is 189.19623153733767
At time: 1373.4193592071533 and batch: 1100, loss is 5.222270250320435 and perplexity is 185.35450790095405
At time: 1374.5223560333252 and batch: 1150, loss is 5.241559410095215 and perplexity is 188.96454598750162
At time: 1375.6254136562347 and batch: 1200, loss is 5.2173051929473875 and perplexity is 184.43649301904398
At time: 1376.728327512741 and batch: 1250, loss is 5.236447868347168 and perplexity is 188.00111024051532
At time: 1377.8307564258575 and batch: 1300, loss is 5.220747299194336 and perplexity is 185.07243688912058
At time: 1378.9335343837738 and batch: 1350, loss is 5.212872400283813 and perplexity is 183.62073366770946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171839192708333 and perplexity of 176.2386764803283
Finished 43 epochs...
Completing Train Step...
At time: 1382.311945438385 and batch: 50, loss is 5.299435205459595 and perplexity is 200.22369278526827
At time: 1383.4435782432556 and batch: 100, loss is 5.316599817276001 and perplexity is 203.69011957623974
At time: 1384.5462300777435 and batch: 150, loss is 5.288533391952515 and perplexity is 198.05274655358733
At time: 1385.6491482257843 and batch: 200, loss is 5.274013299942016 and perplexity is 195.19777980060863
At time: 1386.751571893692 and batch: 250, loss is 5.3012806224823 and perplexity is 200.59353014340243
At time: 1387.8545415401459 and batch: 300, loss is 5.312623977661133 and perplexity is 202.88188809370735
At time: 1388.9575560092926 and batch: 350, loss is 5.310726461410522 and perplexity is 202.4972814281941
At time: 1390.0607376098633 and batch: 400, loss is 5.339846525192261 and perplexity is 208.48071129655594
At time: 1391.1642632484436 and batch: 450, loss is 5.307384147644043 and perplexity is 201.82160177251424
At time: 1392.2671692371368 and batch: 500, loss is 5.339125423431397 and perplexity is 208.33042967921529
At time: 1393.3703796863556 and batch: 550, loss is 5.316999044418335 and perplexity is 203.7714544350612
At time: 1394.4729971885681 and batch: 600, loss is 5.2724233245849605 and perplexity is 194.88766674236498
At time: 1395.5764582157135 and batch: 650, loss is 5.28685001373291 and perplexity is 197.7196293335071
At time: 1396.6801068782806 and batch: 700, loss is 5.30342438697815 and perplexity is 201.0240166974498
At time: 1397.828578710556 and batch: 750, loss is 5.282648916244507 and perplexity is 196.89073225314255
At time: 1398.931354522705 and batch: 800, loss is 5.2581154727935795 and perplexity is 192.11909626906075
At time: 1400.034831047058 and batch: 850, loss is 5.232364082336426 and perplexity is 187.23491948089708
At time: 1401.1377024650574 and batch: 900, loss is 5.274290618896484 and perplexity is 195.25191935143224
At time: 1402.240770816803 and batch: 950, loss is 5.253379573822022 and perplexity is 191.21139073603058
At time: 1403.3441145420074 and batch: 1000, loss is 5.271155109405518 and perplexity is 194.64066390459624
At time: 1404.4475235939026 and batch: 1050, loss is 5.243210363388061 and perplexity is 189.27677529401282
At time: 1405.5503079891205 and batch: 1100, loss is 5.223248214721679 and perplexity is 185.53586667805084
At time: 1406.6531281471252 and batch: 1150, loss is 5.242689323425293 and perplexity is 189.1781802182786
At time: 1407.7554891109467 and batch: 1200, loss is 5.219011335372925 and perplexity is 184.75143653745235
At time: 1408.8586122989655 and batch: 1250, loss is 5.238077907562256 and perplexity is 188.3078093205424
At time: 1409.962065935135 and batch: 1300, loss is 5.22213960647583 and perplexity is 185.3302940571563
At time: 1411.0653290748596 and batch: 1350, loss is 5.213511199951172 and perplexity is 183.73806800387396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171009521484375 and perplexity of 176.09251696246136
Finished 44 epochs...
Completing Train Step...
At time: 1414.4738762378693 and batch: 50, loss is 5.298258886337281 and perplexity is 199.98830429983562
At time: 1415.5812575817108 and batch: 100, loss is 5.314906454086303 and perplexity is 203.34549009943083
At time: 1416.689969778061 and batch: 150, loss is 5.286380548477172 and perplexity is 197.62682862221692
At time: 1417.7994096279144 and batch: 200, loss is 5.271956939697265 and perplexity is 194.79679527198556
At time: 1418.9080204963684 and batch: 250, loss is 5.299209403991699 and perplexity is 200.17848708547857
At time: 1420.0163462162018 and batch: 300, loss is 5.310505533218384 and perplexity is 202.45254901140328
At time: 1421.1249063014984 and batch: 350, loss is 5.308632440567017 and perplexity is 202.07369155792313
At time: 1422.233493566513 and batch: 400, loss is 5.3377972602844235 and perplexity is 208.0539165480453
At time: 1423.3414614200592 and batch: 450, loss is 5.305636463165283 and perplexity is 201.469189334193
At time: 1424.4497005939484 and batch: 500, loss is 5.337575922012329 and perplexity is 208.00787134962437
At time: 1425.5882351398468 and batch: 550, loss is 5.31576057434082 and perplexity is 203.51924579475556
At time: 1426.6967747211456 and batch: 600, loss is 5.271321744918823 and perplexity is 194.67310065401819
At time: 1427.8046371936798 and batch: 650, loss is 5.285634622573853 and perplexity is 197.47946861821143
At time: 1428.9121797084808 and batch: 700, loss is 5.302465772628784 and perplexity is 200.8314045256223
At time: 1430.022054195404 and batch: 750, loss is 5.281856746673584 and perplexity is 196.73482316762468
At time: 1431.129409313202 and batch: 800, loss is 5.257508354187012 and perplexity is 192.00249259075179
At time: 1432.2380466461182 and batch: 850, loss is 5.231987447738647 and perplexity is 187.16441361061672
At time: 1433.3457221984863 and batch: 900, loss is 5.273633079528809 and perplexity is 195.1235757279612
At time: 1434.4531795978546 and batch: 950, loss is 5.253004961013794 and perplexity is 191.1397739151085
At time: 1435.5608477592468 and batch: 1000, loss is 5.271016397476196 and perplexity is 194.6136667950355
At time: 1436.669264793396 and batch: 1050, loss is 5.243328323364258 and perplexity is 189.29910369482403
At time: 1437.7770450115204 and batch: 1100, loss is 5.223707847595215 and perplexity is 185.62116466297317
At time: 1438.8848662376404 and batch: 1150, loss is 5.243227777481079 and perplexity is 189.28007140608315
At time: 1439.9904623031616 and batch: 1200, loss is 5.219940214157105 and perplexity is 184.9231279551115
At time: 1441.0929718017578 and batch: 1250, loss is 5.238987846374512 and perplexity is 188.47923588690878
At time: 1442.1948626041412 and batch: 1300, loss is 5.222879095077515 and perplexity is 185.46739438297487
At time: 1443.2968509197235 and batch: 1350, loss is 5.213762578964233 and perplexity is 183.7842617038907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.170478108723958 and perplexity of 175.99896401175096
Finished 45 epochs...
Completing Train Step...
At time: 1446.7013761997223 and batch: 50, loss is 5.297299880981445 and perplexity is 199.79660637926574
At time: 1447.8024680614471 and batch: 100, loss is 5.313634166717529 and perplexity is 203.08694071031758
At time: 1448.9041879177094 and batch: 150, loss is 5.28472596168518 and perplexity is 197.30010824997896
At time: 1450.0053236484528 and batch: 200, loss is 5.270352468490601 and perplexity is 194.48450002418357
At time: 1451.106788635254 and batch: 250, loss is 5.297621746063232 and perplexity is 199.86092428060684
At time: 1452.2085494995117 and batch: 300, loss is 5.308912334442138 and perplexity is 202.13025866253713
At time: 1453.3517127037048 and batch: 350, loss is 5.307053937911987 and perplexity is 201.75496931741793
At time: 1454.4540565013885 and batch: 400, loss is 5.336232604980469 and perplexity is 207.7286384244413
At time: 1455.555302143097 and batch: 450, loss is 5.304308910369873 and perplexity is 201.20190580445686
At time: 1456.6566836833954 and batch: 500, loss is 5.3363743591308594 and perplexity is 207.758086908266
At time: 1457.7572481632233 and batch: 550, loss is 5.314731550216675 and perplexity is 203.30992729646755
At time: 1458.8587675094604 and batch: 600, loss is 5.270373086929322 and perplexity is 194.48851003226937
At time: 1459.9610788822174 and batch: 650, loss is 5.284614639282227 and perplexity is 197.2781455503185
At time: 1461.0632293224335 and batch: 700, loss is 5.3015953540802006 and perplexity is 200.65667320170965
At time: 1462.1645278930664 and batch: 750, loss is 5.281071128845215 and perplexity is 196.5803254790988
At time: 1463.265990972519 and batch: 800, loss is 5.256904754638672 and perplexity is 191.8866349422736
At time: 1464.3672952651978 and batch: 850, loss is 5.231632785797119 and perplexity is 187.09804528615572
At time: 1465.4688620567322 and batch: 900, loss is 5.272963666915894 and perplexity is 194.99300125426768
At time: 1466.5704510211945 and batch: 950, loss is 5.252551202774048 and perplexity is 191.05306234228445
At time: 1467.6721086502075 and batch: 1000, loss is 5.270700597763062 and perplexity is 194.55221755822595
At time: 1468.7736241817474 and batch: 1050, loss is 5.243196125030518 and perplexity is 189.27408032279752
At time: 1469.875057220459 and batch: 1100, loss is 5.223688793182373 and perplexity is 185.61762779436617
At time: 1470.9762840270996 and batch: 1150, loss is 5.243289403915405 and perplexity is 189.2917364214059
At time: 1472.078268289566 and batch: 1200, loss is 5.220254640579224 and perplexity is 184.98128181467743
At time: 1473.1800079345703 and batch: 1250, loss is 5.239385805130005 and perplexity is 188.55425777587732
At time: 1474.2826001644135 and batch: 1300, loss is 5.223196926116944 and perplexity is 185.52635104634433
At time: 1475.3844664096832 and batch: 1350, loss is 5.213712673187256 and perplexity is 183.77509003637576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.170091552734375 and perplexity of 175.93094370572717
Finished 46 epochs...
Completing Train Step...
At time: 1478.7579910755157 and batch: 50, loss is 5.296377954483032 and perplexity is 199.6124934758744
At time: 1479.8875079154968 and batch: 100, loss is 5.312622680664062 and perplexity is 202.88162495666347
At time: 1480.9893734455109 and batch: 150, loss is 5.283415355682373 and perplexity is 197.0416949197724
At time: 1482.118795633316 and batch: 200, loss is 5.2689688110351565 and perplexity is 194.2155861809819
At time: 1483.219910144806 and batch: 250, loss is 5.296286249160767 and perplexity is 199.59418878716363
At time: 1484.3211562633514 and batch: 300, loss is 5.307553358078003 and perplexity is 201.85575498279107
At time: 1485.4224605560303 and batch: 350, loss is 5.305815849304199 and perplexity is 201.50533335594963
At time: 1486.5238840579987 and batch: 400, loss is 5.334906806945801 and perplexity is 207.45341468973152
At time: 1487.625042438507 and batch: 450, loss is 5.303122653961181 and perplexity is 200.9633702643843
At time: 1488.7268464565277 and batch: 500, loss is 5.335276899337768 and perplexity is 207.53020582922753
At time: 1489.8291490077972 and batch: 550, loss is 5.313681869506836 and perplexity is 203.09662875493285
At time: 1490.9310805797577 and batch: 600, loss is 5.269317607879639 and perplexity is 194.28333978002502
At time: 1492.032601594925 and batch: 650, loss is 5.283532161712646 and perplexity is 197.06471192219038
At time: 1493.1340630054474 and batch: 700, loss is 5.300678653717041 and perplexity is 200.47281544062866
At time: 1494.2355926036835 and batch: 750, loss is 5.2802809143066405 and perplexity is 196.42504620795648
At time: 1495.337861776352 and batch: 800, loss is 5.256186990737915 and perplexity is 191.74895505941012
At time: 1496.4401290416718 and batch: 850, loss is 5.231244583129882 and perplexity is 187.02542742207706
At time: 1497.541758298874 and batch: 900, loss is 5.272138910293579 and perplexity is 194.83224578635904
At time: 1498.6432206630707 and batch: 950, loss is 5.251961889266968 and perplexity is 190.94050536100943
At time: 1499.7457687854767 and batch: 1000, loss is 5.270293531417846 and perplexity is 194.47303801482795
At time: 1500.8473191261292 and batch: 1050, loss is 5.242895393371582 and perplexity is 189.21716817270013
At time: 1501.9490849971771 and batch: 1100, loss is 5.223506708145141 and perplexity is 185.58383267858414
At time: 1503.0512201786041 and batch: 1150, loss is 5.243217678070068 and perplexity is 189.27815979849896
At time: 1504.153086423874 and batch: 1200, loss is 5.22040319442749 and perplexity is 185.0087635371555
At time: 1505.2545030117035 and batch: 1250, loss is 5.239576168060303 and perplexity is 188.5901549335434
At time: 1506.355833530426 and batch: 1300, loss is 5.22334924697876 and perplexity is 185.55461273239285
At time: 1507.4572756290436 and batch: 1350, loss is 5.213632860183716 and perplexity is 183.76042297978276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1697021484375 and perplexity of 175.8624487772701
Finished 47 epochs...
Completing Train Step...
At time: 1510.8300805091858 and batch: 50, loss is 5.295777397155762 and perplexity is 199.49265072012733
At time: 1511.959533214569 and batch: 100, loss is 5.3117819499969485 and perplexity is 202.7111278338911
At time: 1513.0627300739288 and batch: 150, loss is 5.282308330535889 and perplexity is 196.82368550180854
At time: 1514.1649866104126 and batch: 200, loss is 5.26785572052002 and perplexity is 193.99952692317495
At time: 1515.2666602134705 and batch: 250, loss is 5.295122957229614 and perplexity is 199.36213747572017
At time: 1516.368580341339 and batch: 300, loss is 5.306422328948974 and perplexity is 201.62757930503648
At time: 1517.4706802368164 and batch: 350, loss is 5.30478102684021 and perplexity is 201.29691896492463
At time: 1518.5718667507172 and batch: 400, loss is 5.333778810501099 and perplexity is 207.2195399052809
At time: 1519.6738965511322 and batch: 450, loss is 5.302161369323731 and perplexity is 200.77028008603892
At time: 1520.774793624878 and batch: 500, loss is 5.334374189376831 and perplexity is 207.3429507764468
At time: 1521.8757936954498 and batch: 550, loss is 5.312858333587647 and perplexity is 202.92944023841028
At time: 1522.9777572154999 and batch: 600, loss is 5.268475580215454 and perplexity is 194.11981668838504
At time: 1524.0794761180878 and batch: 650, loss is 5.2826825046539305 and perplexity is 196.89734561073465
At time: 1525.1811575889587 and batch: 700, loss is 5.299860105514527 and perplexity is 200.30878592008995
At time: 1526.2822070121765 and batch: 750, loss is 5.27960976600647 and perplexity is 196.29326010104066
At time: 1527.3850252628326 and batch: 800, loss is 5.255628690719605 and perplexity is 191.641931492699
At time: 1528.486517906189 and batch: 850, loss is 5.2308881473541256 and perplexity is 186.95877674781568
At time: 1529.5881297588348 and batch: 900, loss is 5.271381921768189 and perplexity is 194.68481582035918
At time: 1530.6902823448181 and batch: 950, loss is 5.251471881866455 and perplexity is 190.84696601968116
At time: 1531.7919023036957 and batch: 1000, loss is 5.269847650527954 and perplexity is 194.3863455322747
At time: 1532.893263578415 and batch: 1050, loss is 5.242533559799194 and perplexity is 189.14871543377947
At time: 1533.9945676326752 and batch: 1100, loss is 5.223341760635376 and perplexity is 185.55322361204512
At time: 1535.0967290401459 and batch: 1150, loss is 5.243047065734864 and perplexity is 189.24586936430404
At time: 1536.1979851722717 and batch: 1200, loss is 5.220455312728882 and perplexity is 185.0184061309293
At time: 1537.3331589698792 and batch: 1250, loss is 5.239625282287598 and perplexity is 188.59941762074138
At time: 1538.4346792697906 and batch: 1300, loss is 5.223376064300537 and perplexity is 185.55958887687294
At time: 1539.5362062454224 and batch: 1350, loss is 5.213441352844239 and perplexity is 183.72523487957397
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.169361165364584 and perplexity of 175.80249288162918
Finished 48 epochs...
Completing Train Step...
At time: 1542.9432768821716 and batch: 50, loss is 5.29505184173584 and perplexity is 199.3479602429902
At time: 1544.0510125160217 and batch: 100, loss is 5.310973091125488 and perplexity is 202.54722943407222
At time: 1545.1590385437012 and batch: 150, loss is 5.28129090309143 and perplexity is 196.62353351978507
At time: 1546.2667531967163 and batch: 200, loss is 5.266862249374389 and perplexity is 193.80688969651814
At time: 1547.3737452030182 and batch: 250, loss is 5.2940818977355955 and perplexity is 199.15469762710055
At time: 1548.4812998771667 and batch: 300, loss is 5.305378122329712 and perplexity is 201.41714833792525
At time: 1549.5899996757507 and batch: 350, loss is 5.303828773498535 and perplexity is 201.10532453886546
At time: 1550.6972072124481 and batch: 400, loss is 5.332724552154541 and perplexity is 207.00119209349126
At time: 1551.8048436641693 and batch: 450, loss is 5.301265773773193 and perplexity is 200.5905516105384
At time: 1552.9115042686462 and batch: 500, loss is 5.333540706634522 and perplexity is 207.1702060051284
At time: 1554.0188162326813 and batch: 550, loss is 5.312082328796387 and perplexity is 202.7720271050697
At time: 1555.124921798706 and batch: 600, loss is 5.267663516998291 and perplexity is 193.96224311404114
At time: 1556.2311789989471 and batch: 650, loss is 5.281875410079956 and perplexity is 196.73849494384086
At time: 1557.3383176326752 and batch: 700, loss is 5.299144859313965 and perplexity is 200.1655670465047
At time: 1558.4453971385956 and batch: 750, loss is 5.278961381912231 and perplexity is 196.16602792550182
At time: 1559.5525522232056 and batch: 800, loss is 5.255102062225342 and perplexity is 191.5410339609689
At time: 1560.6599349975586 and batch: 850, loss is 5.230494623184204 and perplexity is 186.8852184248247
At time: 1561.7666659355164 and batch: 900, loss is 5.2706155109405515 and perplexity is 194.535664432458
At time: 1562.8739778995514 and batch: 950, loss is 5.250918273925781 and perplexity is 190.7413408639993
At time: 1563.9811480045319 and batch: 1000, loss is 5.269371166229248 and perplexity is 194.29374555371564
At time: 1565.0879654884338 and batch: 1050, loss is 5.242150211334229 and perplexity is 189.07621946056557
At time: 1566.2254717350006 and batch: 1100, loss is 5.223115787506104 and perplexity is 185.51129830663368
At time: 1567.3327391147614 and batch: 1150, loss is 5.2427504444122315 and perplexity is 189.1897433287315
At time: 1568.440619468689 and batch: 1200, loss is 5.220303640365601 and perplexity is 184.99034608004177
At time: 1569.5465092658997 and batch: 1250, loss is 5.239519500732422 and perplexity is 188.579468336192
At time: 1570.6534116268158 and batch: 1300, loss is 5.223234176635742 and perplexity is 185.53326212789148
At time: 1571.7605776786804 and batch: 1350, loss is 5.2131295490264895 and perplexity is 183.66795758002604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.169211832682292 and perplexity of 175.77624178393575
Finished 49 epochs...
Completing Train Step...
At time: 1575.2101061344147 and batch: 50, loss is 5.294428787231445 and perplexity is 199.22379428351582
At time: 1576.3167932033539 and batch: 100, loss is 5.310175991058349 and perplexity is 202.38584335286455
At time: 1577.4263083934784 and batch: 150, loss is 5.280216941833496 and perplexity is 196.41248081388696
At time: 1578.5346574783325 and batch: 200, loss is 5.265865278244019 and perplexity is 193.6137661079413
At time: 1579.6431045532227 and batch: 250, loss is 5.292989072799682 and perplexity is 198.93717528599691
At time: 1580.7520270347595 and batch: 300, loss is 5.3043413257598875 and perplexity is 201.2084279484136
At time: 1581.8590815067291 and batch: 350, loss is 5.302804660797119 and perplexity is 200.89947544600955
At time: 1582.9672083854675 and batch: 400, loss is 5.331607007980347 and perplexity is 206.76998833148713
At time: 1584.0749034881592 and batch: 450, loss is 5.300343227386475 and perplexity is 200.40558285618704
At time: 1585.1834630966187 and batch: 500, loss is 5.332608604431153 and perplexity is 206.9771921679245
At time: 1586.2916388511658 and batch: 550, loss is 5.311299486160278 and perplexity is 202.61335063429868
At time: 1587.4010801315308 and batch: 600, loss is 5.266824779510498 and perplexity is 193.7996279147898
At time: 1588.5089576244354 and batch: 650, loss is 5.281107406616211 and perplexity is 196.58745710448784
At time: 1589.6167340278625 and batch: 700, loss is 5.2984060859680175 and perplexity is 200.017744671133
At time: 1590.7234330177307 and batch: 750, loss is 5.2782506275177 and perplexity is 196.0266515961327
At time: 1591.8320715427399 and batch: 800, loss is 5.2545556640625 and perplexity is 191.4364048790759
At time: 1592.9394783973694 and batch: 850, loss is 5.230151138305664 and perplexity is 186.821037201544
At time: 1594.078647851944 and batch: 900, loss is 5.269778671264649 and perplexity is 194.37293736781135
At time: 1595.1870136260986 and batch: 950, loss is 5.250285301208496 and perplexity is 190.62064500179775
At time: 1596.2946445941925 and batch: 1000, loss is 5.26883415222168 and perplexity is 194.18943510136424
At time: 1597.4027557373047 and batch: 1050, loss is 5.241701259613037 and perplexity is 188.99135241843004
At time: 1598.511067390442 and batch: 1100, loss is 5.222826118469238 and perplexity is 185.45756920972912
At time: 1599.619865655899 and batch: 1150, loss is 5.242441101074219 and perplexity is 189.1312277931746
At time: 1600.7286009788513 and batch: 1200, loss is 5.220088348388672 and perplexity is 184.95052342962387
At time: 1601.8370876312256 and batch: 1250, loss is 5.239433813095093 and perplexity is 188.56331009939186
At time: 1602.9444136619568 and batch: 1300, loss is 5.223106842041016 and perplexity is 185.50963882921369
At time: 1604.0530219078064 and batch: 1350, loss is 5.212896137237549 and perplexity is 183.6250923162998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.16898681640625 and perplexity of 175.73669371823894
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2f1671c50>
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 2.929063156208457, 'wordvec_source': 'glove', 'dropout': 0.08706763329456058, 'data': 'wikitext', 'lr': 17.12435468422465, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5883755683898926 and batch: 50, loss is 7.461686639785767 and perplexity is 1740.0804726451324
At time: 2.6152584552764893 and batch: 100, loss is 6.5369850730896 and perplexity is 690.2025278108448
At time: 3.6442806720733643 and batch: 150, loss is 6.245546979904175 and perplexity is 515.7112314738366
At time: 4.675572395324707 and batch: 200, loss is 6.061703233718872 and perplexity is 429.1056820602699
At time: 5.710363388061523 and batch: 250, loss is 6.0361616325378415 and perplexity is 418.2844203258582
At time: 6.744391202926636 and batch: 300, loss is 5.996126756668091 and perplexity is 401.8692378274359
At time: 7.776487827301025 and batch: 350, loss is 6.016909790039063 and perplexity is 410.30869459157685
At time: 8.811196327209473 and batch: 400, loss is 6.051619806289673 and perplexity is 424.80056768693305
At time: 9.844141721725464 and batch: 450, loss is 6.031844921112061 and perplexity is 416.48269874325445
At time: 10.909541606903076 and batch: 500, loss is 6.054165306091309 and perplexity is 425.8832748785629
At time: 11.942079544067383 and batch: 550, loss is 6.052846746444702 and perplexity is 425.32209243571094
At time: 12.975941896438599 and batch: 600, loss is 6.0194326877594 and perplexity is 411.3451683706997
At time: 14.00856328010559 and batch: 650, loss is 6.067526731491089 and perplexity is 431.6118683462062
At time: 15.04299521446228 and batch: 700, loss is 6.064966659545899 and perplexity is 430.5083240899035
At time: 16.077762603759766 and batch: 750, loss is 6.049361047744751 and perplexity is 423.84212862349005
At time: 17.111066341400146 and batch: 800, loss is 6.018056392669678 and perplexity is 410.7794254392015
At time: 18.145120859146118 and batch: 850, loss is 6.028694143295288 and perplexity is 415.1725194208466
At time: 19.180752277374268 and batch: 900, loss is 6.063093900680542 and perplexity is 429.7028402832419
At time: 20.21553134918213 and batch: 950, loss is 6.041916236877442 and perplexity is 420.6984208133665
At time: 21.250919580459595 and batch: 1000, loss is 6.057122087478637 and perplexity is 427.14438210931695
At time: 22.284773349761963 and batch: 1050, loss is 6.05090033531189 and perplexity is 424.4950459273352
At time: 23.319804191589355 and batch: 1100, loss is 6.024233636856079 and perplexity is 413.3247637512143
At time: 24.354400873184204 and batch: 1150, loss is 6.026122198104859 and perplexity is 414.1060904426246
At time: 25.389240503311157 and batch: 1200, loss is 5.9993649673461915 and perplexity is 403.17268436281756
At time: 26.423442840576172 and batch: 1250, loss is 6.020939598083496 and perplexity is 411.96549592329563
At time: 27.45997977256775 and batch: 1300, loss is 5.990058040618896 and perplexity is 399.43779287103587
At time: 28.497573614120483 and batch: 1350, loss is 5.989201002120971 and perplexity is 399.09560595964274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.637025553385417 and perplexity of 280.62676650875704
Finished 1 epochs...
Completing Train Step...
At time: 31.754831075668335 and batch: 50, loss is 5.954402074813843 and perplexity is 385.4463736682175
At time: 32.81437659263611 and batch: 100, loss is 5.975627851486206 and perplexity is 393.71521819144226
At time: 33.84526205062866 and batch: 150, loss is 5.934105062484742 and perplexity is 377.7018253402537
At time: 34.874839067459106 and batch: 200, loss is 5.932758522033692 and perplexity is 377.193576819389
At time: 35.90618085861206 and batch: 250, loss is 5.95227692604065 and perplexity is 384.6281125513455
At time: 36.939314126968384 and batch: 300, loss is 5.961148805618286 and perplexity is 388.05566879925937
At time: 37.97227692604065 and batch: 350, loss is 5.9331458377838135 and perplexity is 377.33969812825154
At time: 39.00429964065552 and batch: 400, loss is 5.980710506439209 and perplexity is 395.72143091984964
At time: 40.05064272880554 and batch: 450, loss is 5.958517246246338 and perplexity is 387.0358197523982
At time: 41.13327622413635 and batch: 500, loss is 5.984966373443603 and perplexity is 397.40915752321683
At time: 42.239063024520874 and batch: 550, loss is 5.95112681388855 and perplexity is 384.1860013725144
At time: 43.34493565559387 and batch: 600, loss is 5.853770475387574 and perplexity is 348.5460904952237
At time: 44.45054650306702 and batch: 650, loss is 5.910185976028442 and perplexity is 368.77473229243276
At time: 45.556334495544434 and batch: 700, loss is 5.932692518234253 and perplexity is 377.1686814317993
At time: 46.69029474258423 and batch: 750, loss is 5.92128625869751 and perplexity is 372.89103988474824
At time: 47.795348167419434 and batch: 800, loss is 5.869899530410766 and perplexity is 354.2133908060906
At time: 48.90000367164612 and batch: 850, loss is 5.892326917648315 and perplexity is 362.24722388875284
At time: 50.00461268424988 and batch: 900, loss is 5.908614883422851 and perplexity is 368.19580792837456
At time: 51.11068820953369 and batch: 950, loss is 5.896207857131958 and perplexity is 363.65581500323896
At time: 52.21691823005676 and batch: 1000, loss is 5.924594659805297 and perplexity is 374.1267560093556
At time: 53.3220694065094 and batch: 1050, loss is 5.898002452850342 and perplexity is 364.30901611245935
At time: 54.42526435852051 and batch: 1100, loss is 5.880689573287964 and perplexity is 358.05606249485163
At time: 55.529988527297974 and batch: 1150, loss is 5.839356422424316 and perplexity is 343.5581631704033
At time: 56.63477420806885 and batch: 1200, loss is 5.815583791732788 and perplexity is 335.4871959945447
At time: 57.7392942905426 and batch: 1250, loss is 5.837224617004394 and perplexity is 342.8265441278942
At time: 58.84387946128845 and batch: 1300, loss is 5.820161552429199 and perplexity is 337.0264966814926
At time: 59.95007061958313 and batch: 1350, loss is 5.829870653152466 and perplexity is 340.3146575966608
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.635491129557292 and perplexity of 280.19649630426454
Finished 2 epochs...
Completing Train Step...
At time: 63.41498422622681 and batch: 50, loss is 5.897546253204346 and perplexity is 364.14285637216466
At time: 64.49822449684143 and batch: 100, loss is 5.908817472457886 and perplexity is 368.27040791812146
At time: 65.59973239898682 and batch: 150, loss is 5.882325124740601 and perplexity is 358.6421607742842
At time: 66.70461297035217 and batch: 200, loss is 5.857535305023194 and perplexity is 349.86078038496777
At time: 67.81079888343811 and batch: 250, loss is 5.870350618362426 and perplexity is 354.37320824214993
At time: 68.91767740249634 and batch: 300, loss is 5.8937261772155765 and perplexity is 362.754456574827
At time: 70.02342796325684 and batch: 350, loss is 5.862810173034668 and perplexity is 351.7111256971707
At time: 71.12841796875 and batch: 400, loss is 5.9249284553527835 and perplexity is 374.2516586995281
At time: 72.23344135284424 and batch: 450, loss is 5.901266956329346 and perplexity is 365.5002474945758
At time: 73.3375244140625 and batch: 500, loss is 5.940309667587281 and perplexity is 380.05260128971895
At time: 74.47418570518494 and batch: 550, loss is 5.897146711349487 and perplexity is 363.99739512076036
At time: 75.57961893081665 and batch: 600, loss is 5.892344989776611 and perplexity is 362.25377052621354
At time: 76.6829628944397 and batch: 650, loss is 5.924460859298706 and perplexity is 374.0767010086389
At time: 77.78665828704834 and batch: 700, loss is 5.923450164794922 and perplexity is 373.6988147388914
At time: 78.88958311080933 and batch: 750, loss is 5.879550485610962 and perplexity is 357.64843745079537
At time: 79.99232816696167 and batch: 800, loss is 5.8429671573638915 and perplexity is 344.8009028856192
At time: 81.09822940826416 and batch: 850, loss is 5.852374296188355 and perplexity is 348.05979724895775
At time: 82.20359563827515 and batch: 900, loss is 5.867851676940918 and perplexity is 353.488755910946
At time: 83.3075704574585 and batch: 950, loss is 5.842264480590821 and perplexity is 344.5587044034171
At time: 84.41064381599426 and batch: 1000, loss is 5.85826584815979 and perplexity is 350.1164621587533
At time: 85.51455068588257 and batch: 1050, loss is 5.829497556686402 and perplexity is 340.18771108368196
At time: 86.61593174934387 and batch: 1100, loss is 5.842607297897339 and perplexity is 344.6768453396199
At time: 87.71767282485962 and batch: 1150, loss is 5.807209205627442 and perplexity is 332.6893612901216
At time: 88.82225131988525 and batch: 1200, loss is 5.808602418899536 and perplexity is 333.15319155597064
At time: 89.92704558372498 and batch: 1250, loss is 5.799836778640747 and perplexity is 330.2456523660706
At time: 91.03096890449524 and batch: 1300, loss is 5.7710641002655025 and perplexity is 320.8789984720959
At time: 92.13555598258972 and batch: 1350, loss is 5.797387561798096 and perplexity is 329.4377988601264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.628963623046875 and perplexity of 278.3734682372428
Finished 3 epochs...
Completing Train Step...
At time: 95.59012174606323 and batch: 50, loss is 5.848240022659302 and perplexity is 346.6237933045849
At time: 96.69373631477356 and batch: 100, loss is 5.869698190689087 and perplexity is 354.14208075958413
At time: 97.79903531074524 and batch: 150, loss is 5.853619728088379 and perplexity is 348.49355207354876
At time: 98.90255784988403 and batch: 200, loss is 5.828807420730591 and perplexity is 339.9530163075052
At time: 100.00860571861267 and batch: 250, loss is 5.849511241912841 and perplexity is 347.06470833483
At time: 101.11271095275879 and batch: 300, loss is 5.876046123504639 and perplexity is 356.39730131662316
At time: 102.24866247177124 and batch: 350, loss is 5.837969064712524 and perplexity is 343.08185558417944
At time: 103.35480213165283 and batch: 400, loss is 5.888891267776489 and perplexity is 361.0048047411167
At time: 104.46024870872498 and batch: 450, loss is 5.8776397705078125 and perplexity is 356.9657256213476
At time: 105.56551742553711 and batch: 500, loss is 5.8940933990478515 and perplexity is 362.8876923930897
At time: 106.6710319519043 and batch: 550, loss is 5.850948972702026 and perplexity is 347.5640528273031
At time: 107.77483248710632 and batch: 600, loss is 5.826467218399048 and perplexity is 339.15838762472714
At time: 108.87867975234985 and batch: 650, loss is 5.850156803131103 and perplexity is 347.2888321858078
At time: 109.98268961906433 and batch: 700, loss is 5.858832569122314 and perplexity is 350.314936731722
At time: 111.08710098266602 and batch: 750, loss is 5.842964401245117 and perplexity is 344.79995257468704
At time: 112.18910384178162 and batch: 800, loss is 5.815045776367188 and perplexity is 335.30674727458234
At time: 113.29454112052917 and batch: 850, loss is 5.8280104637146 and perplexity is 339.6821962963396
At time: 114.39929270744324 and batch: 900, loss is 5.848267841339111 and perplexity is 346.6334360550289
At time: 115.50409603118896 and batch: 950, loss is 5.813050079345703 and perplexity is 334.6382438847512
At time: 116.60985851287842 and batch: 1000, loss is 5.833366441726684 and perplexity is 341.50640752757033
At time: 117.71530866622925 and batch: 1050, loss is 5.805965385437012 and perplexity is 332.275812788712
At time: 118.81734323501587 and batch: 1100, loss is 5.815344305038452 and perplexity is 335.4068608949616
At time: 119.92046189308167 and batch: 1150, loss is 5.776199398040771 and perplexity is 322.5310459263389
At time: 121.02440619468689 and batch: 1200, loss is 5.761813774108886 and perplexity is 317.92444941862175
At time: 122.12925124168396 and batch: 1250, loss is 5.764533290863037 and perplexity is 318.7902270000978
At time: 123.23635196685791 and batch: 1300, loss is 5.734921960830689 and perplexity is 309.4888175665379
At time: 124.34327673912048 and batch: 1350, loss is 5.796824836730957 and perplexity is 329.25246810266697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.586600341796875 and perplexity of 266.8269555667497
Finished 4 epochs...
Completing Train Step...
At time: 127.8010585308075 and batch: 50, loss is 5.810272226333618 and perplexity is 333.70995794888256
At time: 128.9362826347351 and batch: 100, loss is 5.780964918136597 and perplexity is 324.0717423012065
At time: 130.03991794586182 and batch: 150, loss is 5.750770254135132 and perplexity is 314.4327601682472
At time: 131.17429399490356 and batch: 200, loss is 5.76919376373291 and perplexity is 320.2794076518084
At time: 132.28078985214233 and batch: 250, loss is 5.808526592254639 and perplexity is 333.12793062495604
At time: 133.38513588905334 and batch: 300, loss is 5.818470067977906 and perplexity is 336.4569034675206
At time: 134.49027466773987 and batch: 350, loss is 5.798219003677368 and perplexity is 329.7118211437294
At time: 135.5949535369873 and batch: 400, loss is 5.8493999576568605 and perplexity is 347.0260876459629
At time: 136.6993944644928 and batch: 450, loss is 5.835127325057983 and perplexity is 342.10829023520904
At time: 137.80499649047852 and batch: 500, loss is 5.864099817276001 and perplexity is 352.1650005306651
At time: 138.91068816184998 and batch: 550, loss is 5.830563631057739 and perplexity is 340.5505698667705
At time: 140.01532816886902 and batch: 600, loss is 5.817098636627197 and perplexity is 335.9957921854495
At time: 141.11978006362915 and batch: 650, loss is 5.844221134185791 and perplexity is 345.23354643180437
At time: 142.2240333557129 and batch: 700, loss is 5.844250020980835 and perplexity is 345.2435192665434
At time: 143.32731938362122 and batch: 750, loss is 5.814384145736694 and perplexity is 335.0849714349089
At time: 144.42959904670715 and batch: 800, loss is 5.78523591041565 and perplexity is 325.4588101800331
At time: 145.5353343486786 and batch: 850, loss is 5.799431638717651 and perplexity is 330.11188376719787
At time: 146.6397364139557 and batch: 900, loss is 5.8175111007690425 and perplexity is 336.1344069863893
At time: 147.74276995658875 and batch: 950, loss is 5.7898686981201175 and perplexity is 326.9700897698833
At time: 148.84603905677795 and batch: 1000, loss is 5.804570055007934 and perplexity is 331.8125015475881
At time: 149.95235562324524 and batch: 1050, loss is 5.802307720184326 and perplexity is 331.06267906499465
At time: 151.0549714565277 and batch: 1100, loss is 5.799360513687134 and perplexity is 330.08840538435095
At time: 152.15690541267395 and batch: 1150, loss is 5.769222583770752 and perplexity is 320.2886382494693
At time: 153.25925254821777 and batch: 1200, loss is 5.748631458282471 and perplexity is 313.7609713505159
At time: 154.36217498779297 and batch: 1250, loss is 5.751302452087402 and perplexity is 314.600145176364
At time: 155.4660563468933 and batch: 1300, loss is 5.726953296661377 and perplexity is 307.03240527591663
At time: 156.57129955291748 and batch: 1350, loss is 5.726845083236694 and perplexity is 306.99918204548516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.619501953125 and perplexity of 275.75201160121253
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 159.99759221076965 and batch: 50, loss is 5.699807929992676 and perplexity is 298.8100030155564
At time: 161.1328160762787 and batch: 100, loss is 5.617858591079712 and perplexity is 275.29922336084127
At time: 162.23995780944824 and batch: 150, loss is 5.545486812591553 and perplexity is 256.0792104886374
At time: 163.34776639938354 and batch: 200, loss is 5.510844860076904 and perplexity is 247.36002341951342
At time: 164.45262813568115 and batch: 250, loss is 5.522430486679077 and perplexity is 250.24250975015562
At time: 165.55749893188477 and batch: 300, loss is 5.528719348907471 and perplexity is 251.82120932663057
At time: 166.66246223449707 and batch: 350, loss is 5.502262439727783 and perplexity is 245.2461597295536
At time: 167.76721262931824 and batch: 400, loss is 5.5285823535919185 and perplexity is 251.78671336354276
At time: 168.87237644195557 and batch: 450, loss is 5.501481170654297 and perplexity is 245.05463131692053
At time: 169.97829365730286 and batch: 500, loss is 5.5256493949890135 and perplexity is 251.04931526414228
At time: 171.08483815193176 and batch: 550, loss is 5.5007508277893065 and perplexity is 244.87572275565344
At time: 172.18878936767578 and batch: 600, loss is 5.460878057479858 and perplexity is 235.3039440720159
At time: 173.2943778038025 and batch: 650, loss is 5.467029047012329 and perplexity is 236.75575663348488
At time: 174.39933347702026 and batch: 700, loss is 5.4855068588256835 and perplexity is 241.1711527513907
At time: 175.5039098262787 and batch: 750, loss is 5.454767837524414 and perplexity is 233.87056879602048
At time: 176.60948181152344 and batch: 800, loss is 5.427451343536377 and perplexity is 227.5685117346723
At time: 177.71762323379517 and batch: 850, loss is 5.413556137084961 and perplexity is 224.42826797546087
At time: 178.8238959312439 and batch: 900, loss is 5.442914142608642 and perplexity is 231.1147042811492
At time: 179.92920565605164 and batch: 950, loss is 5.41610878944397 and perplexity is 225.00188713681268
At time: 181.0357642173767 and batch: 1000, loss is 5.437569332122803 and perplexity is 229.88273523960487
At time: 182.1436743736267 and batch: 1050, loss is 5.4025004196166995 and perplexity is 221.96071785509224
At time: 183.24906039237976 and batch: 1100, loss is 5.376837034225463 and perplexity is 216.336925835487
At time: 184.3557345867157 and batch: 1150, loss is 5.374804744720459 and perplexity is 215.89771302652736
At time: 185.46115279197693 and batch: 1200, loss is 5.3642005443573 and perplexity is 213.62038637393564
At time: 186.61236381530762 and batch: 1250, loss is 5.373622894287109 and perplexity is 215.6427049412182
At time: 187.71814799308777 and batch: 1300, loss is 5.3432212162017825 and perplexity is 209.1854577605692
At time: 188.82392716407776 and batch: 1350, loss is 5.351220264434814 and perplexity is 210.86545254868466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.281742350260417 and perplexity of 196.71231869674915
Finished 6 epochs...
Completing Train Step...
At time: 192.29291701316833 and batch: 50, loss is 5.447264204025268 and perplexity is 232.12225730900386
At time: 193.40118598937988 and batch: 100, loss is 5.4550534439086915 and perplexity is 233.93737326300032
At time: 194.50889372825623 and batch: 150, loss is 5.420855188369751 and perplexity is 226.0723743221433
At time: 195.61669659614563 and batch: 200, loss is 5.397574119567871 and perplexity is 220.86996166193944
At time: 196.72419548034668 and batch: 250, loss is 5.428934736251831 and perplexity is 227.9063357081098
At time: 197.8300862312317 and batch: 300, loss is 5.42909309387207 and perplexity is 227.94242927083985
At time: 198.93585848808289 and batch: 350, loss is 5.419568119049072 and perplexity is 225.7815906743975
At time: 200.04257154464722 and batch: 400, loss is 5.453447351455688 and perplexity is 233.56194977644287
At time: 201.14956212043762 and batch: 450, loss is 5.424281244277954 and perplexity is 226.8482392352399
At time: 202.25664687156677 and batch: 500, loss is 5.450140724182129 and perplexity is 232.79092291499066
At time: 203.36480569839478 and batch: 550, loss is 5.433523302078247 and perplexity is 228.95450188241892
At time: 204.47047924995422 and batch: 600, loss is 5.38943660736084 and perplexity is 219.07992276233415
At time: 205.57737064361572 and batch: 650, loss is 5.414540586471557 and perplexity is 224.64931503317223
At time: 206.68132853507996 and batch: 700, loss is 5.434789056777954 and perplexity is 229.24448560460925
At time: 207.78693413734436 and batch: 750, loss is 5.403466205596924 and perplexity is 222.17518795399423
At time: 208.893399477005 and batch: 800, loss is 5.3758820629119874 and perplexity is 216.1304288922903
At time: 210.0020363330841 and batch: 850, loss is 5.361237754821778 and perplexity is 212.98841079622335
At time: 211.1084861755371 and batch: 900, loss is 5.392031345367432 and perplexity is 219.6491158985898
At time: 212.21455812454224 and batch: 950, loss is 5.368637037277222 and perplexity is 214.57021710637704
At time: 213.3199532032013 and batch: 1000, loss is 5.392474060058594 and perplexity is 219.74637931748245
At time: 214.45814990997314 and batch: 1050, loss is 5.360598974227905 and perplexity is 212.8524013774004
At time: 215.56571507453918 and batch: 1100, loss is 5.3442903327941895 and perplexity is 209.40922099753234
At time: 216.67429518699646 and batch: 1150, loss is 5.345979089736939 and perplexity is 209.7631610486101
At time: 217.7803454399109 and batch: 1200, loss is 5.349970140457153 and perplexity is 210.60200929306788
At time: 218.88543176651 and batch: 1250, loss is 5.35668836593628 and perplexity is 212.0216444528606
At time: 219.9919033050537 and batch: 1300, loss is 5.327723417282105 and perplexity is 205.96853559263886
At time: 221.0996606349945 and batch: 1350, loss is 5.333628387451172 and perplexity is 207.18837165435428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.270869547526042 and perplexity of 194.5850898860774
Finished 7 epochs...
Completing Train Step...
At time: 224.5574324131012 and batch: 50, loss is 5.418413228988648 and perplexity is 225.52098827202835
At time: 225.66475462913513 and batch: 100, loss is 5.430080556869507 and perplexity is 228.16762515329256
At time: 226.77223443984985 and batch: 150, loss is 5.396350212097168 and perplexity is 220.59980262436352
At time: 227.87925457954407 and batch: 200, loss is 5.372554540634155 and perplexity is 215.41244529093171
At time: 228.98575139045715 and batch: 250, loss is 5.408586320877075 and perplexity is 223.31566773114744
At time: 230.0914444923401 and batch: 300, loss is 5.399441814422607 and perplexity is 221.28286482142752
At time: 231.19665670394897 and batch: 350, loss is 5.393862495422363 and perplexity is 220.05169486799312
At time: 232.30329990386963 and batch: 400, loss is 5.43001428604126 and perplexity is 228.15250479681924
At time: 233.40999722480774 and batch: 450, loss is 5.40060061454773 and perplexity is 221.539436061552
At time: 234.51567840576172 and batch: 500, loss is 5.427325820922851 and perplexity is 227.53994853302464
At time: 235.62204241752625 and batch: 550, loss is 5.413489866256714 and perplexity is 224.41339542107372
At time: 236.72770142555237 and batch: 600, loss is 5.370987739562988 and perplexity is 215.0752011071721
At time: 237.83337569236755 and batch: 650, loss is 5.393868026733398 and perplexity is 220.05291204572748
At time: 238.93731665611267 and batch: 700, loss is 5.414775915145874 and perplexity is 224.7021876796461
At time: 240.04177403450012 and batch: 750, loss is 5.38297737121582 and perplexity is 217.6693941793209
At time: 241.14919352531433 and batch: 800, loss is 5.359246692657471 and perplexity is 212.56475952801438
At time: 242.25626969337463 and batch: 850, loss is 5.345554485321045 and perplexity is 209.6741135904468
At time: 243.41124868392944 and batch: 900, loss is 5.375600728988648 and perplexity is 216.06963262320437
At time: 244.5171000957489 and batch: 950, loss is 5.355368709564209 and perplexity is 211.74203327465634
At time: 245.6211609840393 and batch: 1000, loss is 5.37545711517334 and perplexity is 216.0386042669949
At time: 246.7273485660553 and batch: 1050, loss is 5.3400295543670655 and perplexity is 208.51887284133872
At time: 247.8337845802307 and batch: 1100, loss is 5.325785083770752 and perplexity is 205.56968655392177
At time: 248.94163370132446 and batch: 1150, loss is 5.333352184295654 and perplexity is 207.13115347460143
At time: 250.04804396629333 and batch: 1200, loss is 5.3333819961547855 and perplexity is 207.13732853141508
At time: 251.15337538719177 and batch: 1250, loss is 5.341796464920044 and perplexity is 208.88763272518426
At time: 252.25958490371704 and batch: 1300, loss is 5.314838533401489 and perplexity is 203.33167920351744
At time: 253.36514163017273 and batch: 1350, loss is 5.314843168258667 and perplexity is 203.33262161899432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.265110677083333 and perplexity of 193.46772004550587
Finished 8 epochs...
Completing Train Step...
At time: 256.80075550079346 and batch: 50, loss is 5.393127851486206 and perplexity is 219.89009459131688
At time: 257.93841552734375 and batch: 100, loss is 5.4051534461975095 and perplexity is 222.55036737152128
At time: 259.0447721481323 and batch: 150, loss is 5.37519865989685 and perplexity is 215.98277516477037
At time: 260.1511459350586 and batch: 200, loss is 5.348834257125855 and perplexity is 210.3629257923616
At time: 261.25740361213684 and batch: 250, loss is 5.384138870239258 and perplexity is 217.9223638516664
At time: 262.3629856109619 and batch: 300, loss is 5.376083478927613 and perplexity is 216.17396540646158
At time: 263.46833658218384 and batch: 350, loss is 5.371238756179809 and perplexity is 215.1291953329566
At time: 264.57524013519287 and batch: 400, loss is 5.4068621635437015 and perplexity is 222.9309681215984
At time: 265.68181014060974 and batch: 450, loss is 5.379637031555176 and perplexity is 216.94351748133315
At time: 266.7879469394684 and batch: 500, loss is 5.405526313781738 and perplexity is 222.63336466191035
At time: 267.8951082229614 and batch: 550, loss is 5.389049549102783 and perplexity is 218.9951424775676
At time: 268.99986934661865 and batch: 600, loss is 5.349939422607422 and perplexity is 210.59554015155283
At time: 270.10695147514343 and batch: 650, loss is 5.37716423034668 and perplexity is 216.40772201998314
At time: 271.2407217025757 and batch: 700, loss is 5.398875389099121 and perplexity is 221.15756009437467
At time: 272.3458001613617 and batch: 750, loss is 5.363499765396118 and perplexity is 213.47073814277547
At time: 273.4516251087189 and batch: 800, loss is 5.338886241912842 and perplexity is 208.28060684927107
At time: 274.55971813201904 and batch: 850, loss is 5.326708002090454 and perplexity is 205.7594981604492
At time: 275.6658113002777 and batch: 900, loss is 5.360246467590332 and perplexity is 212.77738271615635
At time: 276.77222442626953 and batch: 950, loss is 5.338267621994018 and perplexity is 208.1518001624682
At time: 277.8778302669525 and batch: 1000, loss is 5.360954055786133 and perplexity is 212.92799475986777
At time: 278.9847888946533 and batch: 1050, loss is 5.323239698410034 and perplexity is 205.0470978601192
At time: 280.0922746658325 and batch: 1100, loss is 5.309706659317016 and perplexity is 202.29087953909183
At time: 281.20018100738525 and batch: 1150, loss is 5.322225866317749 and perplexity is 204.83931987567016
At time: 282.3053729534149 and batch: 1200, loss is 5.317911500930786 and perplexity is 203.9574718792202
At time: 283.40929198265076 and batch: 1250, loss is 5.328410367965699 and perplexity is 206.1100744284971
At time: 284.51446747779846 and batch: 1300, loss is 5.2993841648101805 and perplexity is 200.21347349876206
At time: 285.6208655834198 and batch: 1350, loss is 5.295721664428711 and perplexity is 199.481532760496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2552978515625 and perplexity of 191.578539324502
Finished 9 epochs...
Completing Train Step...
At time: 289.0616319179535 and batch: 50, loss is 5.3727835845947265 and perplexity is 215.46178986137969
At time: 290.19820857048035 and batch: 100, loss is 5.389521188735962 and perplexity is 219.09845362713506
At time: 291.30386304855347 and batch: 150, loss is 5.357887945175171 and perplexity is 212.2761338253084
At time: 292.40935587882996 and batch: 200, loss is 5.331305446624756 and perplexity is 206.70764389431935
At time: 293.5160536766052 and batch: 250, loss is 5.368739414215088 and perplexity is 214.5921852726592
At time: 294.6219320297241 and batch: 300, loss is 5.362027282714844 and perplexity is 213.1566374885411
At time: 295.7260513305664 and batch: 350, loss is 5.355405788421631 and perplexity is 211.7498845728762
At time: 296.83060789108276 and batch: 400, loss is 5.388991756439209 and perplexity is 218.98248653068805
At time: 297.9364228248596 and batch: 450, loss is 5.361239471435547 and perplexity is 212.98877641537587
At time: 299.0431604385376 and batch: 500, loss is 5.387758111953735 and perplexity is 218.7125065576563
At time: 300.1925587654114 and batch: 550, loss is 5.372872543334961 and perplexity is 215.48095792334513
At time: 301.29677963256836 and batch: 600, loss is 5.333871240615845 and perplexity is 207.2386941163313
At time: 302.4017221927643 and batch: 650, loss is 5.35582854270935 and perplexity is 211.83942166926556
At time: 303.5061616897583 and batch: 700, loss is 5.379282236099243 and perplexity is 216.86656055992697
At time: 304.61044573783875 and batch: 750, loss is 5.349401292800903 and perplexity is 210.48224290132507
At time: 305.7171676158905 and batch: 800, loss is 5.321487817764282 and perplexity is 204.6881942878137
At time: 306.82377767562866 and batch: 850, loss is 5.310305461883545 and perplexity is 202.41204811135069
At time: 307.93119168281555 and batch: 900, loss is 5.342606945037842 and perplexity is 209.05700062374783
At time: 309.0361714363098 and batch: 950, loss is 5.325326719284058 and perplexity is 205.4754823016558
At time: 310.1408371925354 and batch: 1000, loss is 5.344203796386719 and perplexity is 209.39110025991903
At time: 311.24806928634644 and batch: 1050, loss is 5.307036457061767 and perplexity is 201.75144249984416
At time: 312.35371112823486 and batch: 1100, loss is 5.296552524566651 and perplexity is 199.6473428872957
At time: 313.4617238044739 and batch: 1150, loss is 5.308408031463623 and perplexity is 202.02834946976006
At time: 314.56672954559326 and batch: 1200, loss is 5.308092126846313 and perplexity is 201.96453786105673
At time: 315.6704771518707 and batch: 1250, loss is 5.31633186340332 and perplexity is 203.6355473316212
At time: 316.77646040916443 and batch: 1300, loss is 5.2870776557922365 and perplexity is 197.76464376049188
At time: 317.88304471969604 and batch: 1350, loss is 5.284974803924561 and perplexity is 197.34921095990669
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.250775553385417 and perplexity of 190.71412009928866
Finished 10 epochs...
Completing Train Step...
At time: 321.3439300060272 and batch: 50, loss is 5.356399097442627 and perplexity is 211.960322140882
At time: 322.4509677886963 and batch: 100, loss is 5.373567361831665 and perplexity is 215.63073010481315
At time: 323.55654215812683 and batch: 150, loss is 5.342004346847534 and perplexity is 208.93106120274535
At time: 324.66245222091675 and batch: 200, loss is 5.313928279876709 and perplexity is 203.14668003666847
At time: 325.76826000213623 and batch: 250, loss is 5.356492757797241 and perplexity is 211.98017534953263
At time: 326.8733925819397 and batch: 300, loss is 5.345145511627197 and perplexity is 209.58837992630916
At time: 328.0098297595978 and batch: 350, loss is 5.3401189708709715 and perplexity is 208.5375187035581
At time: 329.11431097984314 and batch: 400, loss is 5.373979625701904 and perplexity is 215.71964519112817
At time: 330.22074484825134 and batch: 450, loss is 5.344042119979858 and perplexity is 209.3572493957172
At time: 331.3253073692322 and batch: 500, loss is 5.372728548049927 and perplexity is 215.44993191524253
At time: 332.43102502822876 and batch: 550, loss is 5.360015726089477 and perplexity is 212.72829180739328
At time: 333.53433418273926 and batch: 600, loss is 5.32246150970459 and perplexity is 204.8875945943497
At time: 334.6394965648651 and batch: 650, loss is 5.3473581695556645 and perplexity is 210.05264075265407
At time: 335.7427701950073 and batch: 700, loss is 5.366221570968628 and perplexity is 214.05255542499472
At time: 336.84635043144226 and batch: 750, loss is 5.3307906436920165 and perplexity is 206.60125757936586
At time: 337.9510145187378 and batch: 800, loss is 5.307197828292846 and perplexity is 201.78400200550544
At time: 339.0569438934326 and batch: 850, loss is 5.296042070388794 and perplexity is 199.54545807299777
At time: 340.1640269756317 and batch: 900, loss is 5.3284044933319095 and perplexity is 206.1088636108461
At time: 341.2690258026123 and batch: 950, loss is 5.305846204757691 and perplexity is 201.5114502345644
At time: 342.3742220401764 and batch: 1000, loss is 5.324858741760254 and perplexity is 205.37934689060623
At time: 343.47969007492065 and batch: 1050, loss is 5.2924228858947755 and perplexity is 198.82457154284137
At time: 344.5844395160675 and batch: 1100, loss is 5.280213308334351 and perplexity is 196.41176715060237
At time: 345.69118428230286 and batch: 1150, loss is 5.294615297317505 and perplexity is 199.2609549958489
At time: 346.79643297195435 and batch: 1200, loss is 5.291736040115357 and perplexity is 198.68805661275098
At time: 347.9006333351135 and batch: 1250, loss is 5.3004699802398685 and perplexity is 200.43098644560482
At time: 349.0065448284149 and batch: 1300, loss is 5.2679118728637695 and perplexity is 194.01042075715236
At time: 350.11301279067993 and batch: 1350, loss is 5.267779054641724 and perplexity is 193.98465434917122
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2433447265625 and perplexity of 189.30220883101603
Finished 11 epochs...
Completing Train Step...
At time: 353.57575821876526 and batch: 50, loss is 5.333420791625977 and perplexity is 207.14536467755877
At time: 354.68307065963745 and batch: 100, loss is 5.3500547695159915 and perplexity is 210.619833097099
At time: 355.8336887359619 and batch: 150, loss is 5.320998058319092 and perplexity is 204.58797085603183
At time: 356.9398682117462 and batch: 200, loss is 5.292659215927124 and perplexity is 198.8715653130666
At time: 358.0454602241516 and batch: 250, loss is 5.332920246124267 and perplexity is 207.04170494244084
At time: 359.1500060558319 and batch: 300, loss is 5.324270915985108 and perplexity is 205.2586550931712
At time: 360.2563805580139 and batch: 350, loss is 5.317962350845337 and perplexity is 203.9678433629296
At time: 361.3608138561249 and batch: 400, loss is 5.350676593780517 and perplexity is 210.75084234805328
At time: 362.4660186767578 and batch: 450, loss is 5.322735767364502 and perplexity is 204.94379429283484
At time: 363.57264471054077 and batch: 500, loss is 5.347428092956543 and perplexity is 210.06732886117425
At time: 364.6782195568085 and batch: 550, loss is 5.338740081787109 and perplexity is 208.25016675420446
At time: 365.7813398838043 and batch: 600, loss is 5.299500331878662 and perplexity is 200.23673306202048
At time: 366.88514375686646 and batch: 650, loss is 5.32275463104248 and perplexity is 204.94766032303758
At time: 367.9883897304535 and batch: 700, loss is 5.345097389221191 and perplexity is 209.57829427187116
At time: 369.0923104286194 and batch: 750, loss is 5.31282530784607 and perplexity is 202.9227384538249
At time: 370.1985740661621 and batch: 800, loss is 5.28580961227417 and perplexity is 197.51402851496843
At time: 371.3052513599396 and batch: 850, loss is 5.272474355697632 and perplexity is 194.8976123306099
At time: 372.41171741485596 and batch: 900, loss is 5.307375831604004 and perplexity is 201.8199234229718
At time: 373.5167796611786 and batch: 950, loss is 5.287378644943237 and perplexity is 197.82417773180552
At time: 374.62130856513977 and batch: 1000, loss is 5.30699595451355 and perplexity is 201.74327121779635
At time: 375.72774362564087 and batch: 1050, loss is 5.272263040542603 and perplexity is 194.85643186262712
At time: 376.8346838951111 and batch: 1100, loss is 5.26150803565979 and perplexity is 192.77197922799897
At time: 377.9423828125 and batch: 1150, loss is 5.279817533493042 and perplexity is 196.33404769534422
At time: 379.04669547080994 and batch: 1200, loss is 5.275908613204956 and perplexity is 195.56809155910167
At time: 380.1500389575958 and batch: 1250, loss is 5.285846271514893 and perplexity is 197.5212693620071
At time: 381.2561821937561 and batch: 1300, loss is 5.2513894271850585 and perplexity is 190.83123044264744
At time: 382.36224579811096 and batch: 1350, loss is 5.250687780380249 and perplexity is 190.69738128245862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.24424560546875 and perplexity of 189.47282403813992
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 385.8049714565277 and batch: 50, loss is 5.298363437652588 and perplexity is 200.0092144331682
At time: 386.94294571876526 and batch: 100, loss is 5.292216653823853 and perplexity is 198.78357176758132
At time: 388.0503046512604 and batch: 150, loss is 5.258315744400025 and perplexity is 192.15757612218175
At time: 389.1586287021637 and batch: 200, loss is 5.230441408157349 and perplexity is 186.8752735875171
At time: 390.2671539783478 and batch: 250, loss is 5.245979499816895 and perplexity is 189.80163487611566
At time: 391.374463558197 and batch: 300, loss is 5.246609363555908 and perplexity is 189.92122170127843
At time: 392.48134207725525 and batch: 350, loss is 5.236551170349121 and perplexity is 188.02053213471564
At time: 393.5889587402344 and batch: 400, loss is 5.2677036476135255 and perplexity is 193.97002709437646
At time: 394.69484758377075 and batch: 450, loss is 5.2356477642059325 and perplexity is 187.8507499336285
At time: 395.80255794525146 and batch: 500, loss is 5.262962236404419 and perplexity is 193.05251231000733
At time: 396.9082977771759 and batch: 550, loss is 5.24558744430542 and perplexity is 189.72723668413906
At time: 398.01519894599915 and batch: 600, loss is 5.202474813461304 and perplexity is 181.72141243692798
At time: 399.1222417354584 and batch: 650, loss is 5.211829557418823 and perplexity is 183.42934590676515
At time: 400.23069310188293 and batch: 700, loss is 5.2283193874359135 and perplexity is 186.47914083424385
At time: 401.33673644065857 and batch: 750, loss is 5.206367063522339 and perplexity is 182.43009590752808
At time: 402.4437162876129 and batch: 800, loss is 5.182724418640137 and perplexity is 178.16755337642718
At time: 403.55019974708557 and batch: 850, loss is 5.156732873916626 and perplexity is 173.59636688346694
At time: 404.6583480834961 and batch: 900, loss is 5.192545413970947 and perplexity is 179.92595658767388
At time: 405.7658779621124 and batch: 950, loss is 5.160161762237549 and perplexity is 174.19263111595637
At time: 406.87216091156006 and batch: 1000, loss is 5.1753083610534665 and perplexity is 176.85113987301307
At time: 407.98066091537476 and batch: 1050, loss is 5.133032989501953 and perplexity is 169.53052337248317
At time: 409.08711528778076 and batch: 1100, loss is 5.125465450286865 and perplexity is 168.25243657410405
At time: 410.19466853141785 and batch: 1150, loss is 5.138215646743775 and perplexity is 170.41142269503527
At time: 411.3029327392578 and batch: 1200, loss is 5.123916654586792 and perplexity is 167.99204961896024
At time: 412.44475841522217 and batch: 1250, loss is 5.13884539604187 and perplexity is 170.51877296719644
At time: 413.55386424064636 and batch: 1300, loss is 5.117544212341309 and perplexity is 166.9249336635802
At time: 414.66113924980164 and batch: 1350, loss is 5.123255672454834 and perplexity is 167.88104656541003
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.143312174479167 and perplexity of 171.28214618571488
Finished 13 epochs...
Completing Train Step...
At time: 418.118661403656 and batch: 50, loss is 5.224457530975342 and perplexity is 185.7603739400417
At time: 419.258442401886 and batch: 100, loss is 5.229781370162964 and perplexity is 186.75196950390486
At time: 420.36768770217896 and batch: 150, loss is 5.204086894989014 and perplexity is 182.01459842547055
At time: 421.4767761230469 and batch: 200, loss is 5.1794294834136965 and perplexity is 177.5814689140091
At time: 422.5855350494385 and batch: 250, loss is 5.206087198257446 and perplexity is 182.37904720412521
At time: 423.6936025619507 and batch: 300, loss is 5.211681098937988 and perplexity is 183.40211628601537
At time: 424.80232763290405 and batch: 350, loss is 5.2035965251922605 and perplexity is 181.925365844104
At time: 425.9117181301117 and batch: 400, loss is 5.234974279403686 and perplexity is 187.72427790173379
At time: 427.01978611946106 and batch: 450, loss is 5.206729688644409 and perplexity is 182.49626163927914
At time: 428.12636256217957 and batch: 500, loss is 5.235713882446289 and perplexity is 187.86317070527903
At time: 429.23222303390503 and batch: 550, loss is 5.219345788955689 and perplexity is 184.813237651549
At time: 430.3393204212189 and batch: 600, loss is 5.1751916790008545 and perplexity is 176.83050572284682
At time: 431.44769167900085 and batch: 650, loss is 5.1878808403015135 and perplexity is 179.08863310488638
At time: 432.55581617355347 and batch: 700, loss is 5.207718839645386 and perplexity is 182.67686730756725
At time: 433.6646842956543 and batch: 750, loss is 5.187206020355225 and perplexity is 178.9678212908092
At time: 434.77379059791565 and batch: 800, loss is 5.160562114715576 and perplexity is 174.26238352932182
At time: 435.88078594207764 and batch: 850, loss is 5.139983177185059 and perplexity is 170.71289642570156
At time: 436.98972845077515 and batch: 900, loss is 5.177837800979614 and perplexity is 177.2990404371695
At time: 438.0986557006836 and batch: 950, loss is 5.147801065444947 and perplexity is 172.05274132914974
At time: 439.2063660621643 and batch: 1000, loss is 5.165912752151489 and perplexity is 175.19729732418577
At time: 440.34636759757996 and batch: 1050, loss is 5.125914907455444 and perplexity is 168.32807583488386
At time: 441.4548373222351 and batch: 1100, loss is 5.122933864593506 and perplexity is 167.82702981683056
At time: 442.5641932487488 and batch: 1150, loss is 5.139945964813233 and perplexity is 170.7065439121211
At time: 443.6729850769043 and batch: 1200, loss is 5.124697704315185 and perplexity is 168.1233110178544
At time: 444.78112626075745 and batch: 1250, loss is 5.141297912597656 and perplexity is 170.9374863218135
At time: 445.8898735046387 and batch: 1300, loss is 5.119321689605713 and perplexity is 167.22190278777504
At time: 446.9975965023041 and batch: 1350, loss is 5.118539428710937 and perplexity is 167.09114278336116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.138973795572917 and perplexity of 170.54066890336395
Finished 14 epochs...
Completing Train Step...
At time: 450.4818365573883 and batch: 50, loss is 5.2083565044403075 and perplexity is 182.79339106229554
At time: 451.59120416641235 and batch: 100, loss is 5.213945026397705 and perplexity is 183.8177957297566
At time: 452.6995759010315 and batch: 150, loss is 5.188990850448608 and perplexity is 179.28753367526528
At time: 453.80804920196533 and batch: 200, loss is 5.164258317947388 and perplexity is 174.90768456171614
At time: 454.9176404476166 and batch: 250, loss is 5.192400922775269 and perplexity is 179.89996074920305
At time: 456.02460861206055 and batch: 300, loss is 5.2012415599823 and perplexity is 181.497442007373
At time: 457.13245820999146 and batch: 350, loss is 5.192561521530151 and perplexity is 179.92885477901325
At time: 458.2406096458435 and batch: 400, loss is 5.224568614959717 and perplexity is 185.78101008866943
At time: 459.34786438941956 and batch: 450, loss is 5.1986437511444095 and perplexity is 181.02655824628735
At time: 460.45558428764343 and batch: 500, loss is 5.227292728424072 and perplexity is 186.2877885873479
At time: 461.5622982978821 and batch: 550, loss is 5.209714946746826 and perplexity is 183.04187407477298
At time: 462.66954016685486 and batch: 600, loss is 5.166618051528931 and perplexity is 175.320907454868
At time: 463.7776939868927 and batch: 650, loss is 5.179030199050903 and perplexity is 177.51057756419536
At time: 464.88482546806335 and batch: 700, loss is 5.1998332977294925 and perplexity is 181.24202589945648
At time: 465.99386644363403 and batch: 750, loss is 5.182122077941894 and perplexity is 178.06026812230337
At time: 467.10170578956604 and batch: 800, loss is 5.155119132995606 and perplexity is 173.3164532372842
At time: 468.24304962158203 and batch: 850, loss is 5.135200061798096 and perplexity is 169.89830663556236
At time: 469.3523213863373 and batch: 900, loss is 5.172656097412109 and perplexity is 176.3827055051167
At time: 470.4598515033722 and batch: 950, loss is 5.143598613739013 and perplexity is 171.33121514419577
At time: 471.5671215057373 and batch: 1000, loss is 5.161816492080688 and perplexity is 174.48111147382278
At time: 472.6755030155182 and batch: 1050, loss is 5.121559801101685 and perplexity is 167.59658318262987
At time: 473.783714056015 and batch: 1100, loss is 5.1194548988342286 and perplexity is 167.24417977215327
At time: 474.89199018478394 and batch: 1150, loss is 5.136880645751953 and perplexity is 170.18407506514077
At time: 476.00084495544434 and batch: 1200, loss is 5.123227090835571 and perplexity is 167.8762483218267
At time: 477.10915899276733 and batch: 1250, loss is 5.139712715148926 and perplexity is 170.66673131137702
At time: 478.2170498371124 and batch: 1300, loss is 5.117362565994263 and perplexity is 166.89461511285973
At time: 479.3238174915314 and batch: 1350, loss is 5.112673254013061 and perplexity is 166.11382630653708
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.13704833984375 and perplexity of 170.2126163220803
Finished 15 epochs...
Completing Train Step...
At time: 482.81032633781433 and batch: 50, loss is 5.1977449321746825 and perplexity is 180.86392124327213
At time: 483.91908717155457 and batch: 100, loss is 5.203875904083252 and perplexity is 181.97619905158865
At time: 485.0265817642212 and batch: 150, loss is 5.17910605430603 and perplexity is 177.52404318505683
At time: 486.13437962532043 and batch: 200, loss is 5.155005187988281 and perplexity is 173.2967058178319
At time: 487.2433397769928 and batch: 250, loss is 5.183841304779053 and perplexity is 178.3666574147707
At time: 488.35091495513916 and batch: 300, loss is 5.194180345535278 and perplexity is 180.22036381559707
At time: 489.4588391780853 and batch: 350, loss is 5.186524543762207 and perplexity is 178.84590045751165
At time: 490.56656670570374 and batch: 400, loss is 5.218392305374145 and perplexity is 184.6371052468183
At time: 491.673894405365 and batch: 450, loss is 5.192224454879761 and perplexity is 179.8682169826879
At time: 492.78118920326233 and batch: 500, loss is 5.221996812820435 and perplexity is 185.30383195636745
At time: 493.8869411945343 and batch: 550, loss is 5.2034058761596675 and perplexity is 181.89068525511712
At time: 494.99425077438354 and batch: 600, loss is 5.159337940216065 and perplexity is 174.04918648499847
At time: 496.10180926322937 and batch: 650, loss is 5.173314352035522 and perplexity is 176.49884845812963
At time: 497.23954153060913 and batch: 700, loss is 5.194027423858643 and perplexity is 180.19280632252128
At time: 498.3474066257477 and batch: 750, loss is 5.178503065109253 and perplexity is 177.4170303718757
At time: 499.45498609542847 and batch: 800, loss is 5.150485906600952 and perplexity is 172.5152962754966
At time: 500.56208658218384 and batch: 850, loss is 5.130344390869141 and perplexity is 169.07533602136468
At time: 501.66983342170715 and batch: 900, loss is 5.167697486877441 and perplexity is 175.51025721673517
At time: 502.77748560905457 and batch: 950, loss is 5.139497833251953 and perplexity is 170.63006206032287
At time: 503.88490104675293 and batch: 1000, loss is 5.15704454421997 and perplexity is 173.65048014810375
At time: 504.9927673339844 and batch: 1050, loss is 5.117771005630493 and perplexity is 166.9627954115655
At time: 506.09998297691345 and batch: 1100, loss is 5.115123491287232 and perplexity is 166.52134364871625
At time: 507.2083742618561 and batch: 1150, loss is 5.133323545455933 and perplexity is 169.579788632241
At time: 508.317745923996 and batch: 1200, loss is 5.120873804092407 and perplexity is 167.48165185358258
At time: 509.4388425350189 and batch: 1250, loss is 5.137338924407959 and perplexity is 170.26208466803791
At time: 510.54793429374695 and batch: 1300, loss is 5.114516534805298 and perplexity is 166.42030310651623
At time: 511.6499276161194 and batch: 1350, loss is 5.109417037963867 and perplexity is 165.5738034919551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.136499837239583 and perplexity of 170.1192798587523
Finished 16 epochs...
Completing Train Step...
At time: 515.0619533061981 and batch: 50, loss is 5.19018741607666 and perplexity is 179.50219137600092
At time: 516.2030303478241 and batch: 100, loss is 5.197494878768921 and perplexity is 180.81870125772713
At time: 517.305501461029 and batch: 150, loss is 5.173458347320556 and perplexity is 176.52426529002966
At time: 518.4071307182312 and batch: 200, loss is 5.14887638092041 and perplexity is 172.23785181274377
At time: 519.5082685947418 and batch: 250, loss is 5.177869272232056 and perplexity is 177.30462034783164
At time: 520.6108837127686 and batch: 300, loss is 5.188272495269775 and perplexity is 179.1587877951208
At time: 521.7117569446564 and batch: 350, loss is 5.181209077835083 and perplexity is 177.8977732686858
At time: 522.8138287067413 and batch: 400, loss is 5.214067907333374 and perplexity is 183.8403848203443
At time: 523.9149169921875 and batch: 450, loss is 5.187397069931031 and perplexity is 179.0020162835151
At time: 525.061934709549 and batch: 500, loss is 5.217931184768677 and perplexity is 184.5519848999362
At time: 526.1607670783997 and batch: 550, loss is 5.198343582153321 and perplexity is 180.9722278414976
At time: 527.2611780166626 and batch: 600, loss is 5.15471640586853 and perplexity is 173.24666805313365
At time: 528.3621380329132 and batch: 650, loss is 5.167638816833496 and perplexity is 175.499960324294
At time: 529.4625113010406 and batch: 700, loss is 5.189328956604004 and perplexity is 179.3481621428381
At time: 530.5639395713806 and batch: 750, loss is 5.174589166641235 and perplexity is 176.72399524775204
At time: 531.6656589508057 and batch: 800, loss is 5.146027450561523 and perplexity is 171.74785648047052
At time: 532.7665121555328 and batch: 850, loss is 5.125735950469971 and perplexity is 168.2979550451052
At time: 533.86878657341 and batch: 900, loss is 5.163053388595581 and perplexity is 174.6970600780255
At time: 534.9706454277039 and batch: 950, loss is 5.134660015106201 and perplexity is 169.806578388103
At time: 536.0729868412018 and batch: 1000, loss is 5.15324236869812 and perplexity is 172.99148414626052
At time: 537.1743743419647 and batch: 1050, loss is 5.1125137233734135 and perplexity is 166.08732817526015
At time: 538.2758591175079 and batch: 1100, loss is 5.111377401351929 and perplexity is 165.8987066744437
At time: 539.3784878253937 and batch: 1150, loss is 5.130007410049439 and perplexity is 169.0183704747282
At time: 540.4800343513489 and batch: 1200, loss is 5.117000274658203 and perplexity is 166.83416159132403
At time: 541.5816690921783 and batch: 1250, loss is 5.132939386367798 and perplexity is 169.5146555268121
At time: 542.6825742721558 and batch: 1300, loss is 5.109747447967529 and perplexity is 165.62851977187856
At time: 543.7834279537201 and batch: 1350, loss is 5.103297653198243 and perplexity is 164.56368747769275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.134799397786458 and perplexity of 169.830248133662
Finished 17 epochs...
Completing Train Step...
At time: 547.1913902759552 and batch: 50, loss is 5.1825023365020755 and perplexity is 178.12798993856916
At time: 548.3213014602661 and batch: 100, loss is 5.190330362319946 and perplexity is 179.5278523739476
At time: 549.423097372055 and batch: 150, loss is 5.16619086265564 and perplexity is 175.24602830885567
At time: 550.525087594986 and batch: 200, loss is 5.141868286132812 and perplexity is 171.03501235066656
At time: 551.6264276504517 and batch: 250, loss is 5.170779123306274 and perplexity is 176.05195024080476
At time: 552.7738988399506 and batch: 300, loss is 5.181997117996215 and perplexity is 178.0380191110178
At time: 553.8758044242859 and batch: 350, loss is 5.176321697235108 and perplexity is 177.03044036230457
At time: 554.9776566028595 and batch: 400, loss is 5.209847011566162 and perplexity is 183.06604906310125
At time: 556.0786068439484 and batch: 450, loss is 5.1822246551513675 and perplexity is 178.07853398453997
At time: 557.1815960407257 and batch: 500, loss is 5.213982925415039 and perplexity is 183.82476237559698
At time: 558.285177230835 and batch: 550, loss is 5.194416446685791 and perplexity is 180.26291907431488
At time: 559.3914926052094 and batch: 600, loss is 5.149278268814087 and perplexity is 172.30708603148554
At time: 560.4982783794403 and batch: 650, loss is 5.16177604675293 and perplexity is 174.47405467078997
At time: 561.6043939590454 and batch: 700, loss is 5.184689483642578 and perplexity is 178.51800842083614
At time: 562.7112109661102 and batch: 750, loss is 5.170282402038574 and perplexity is 175.96452320813094
At time: 563.8175835609436 and batch: 800, loss is 5.141932401657105 and perplexity is 171.0459787017087
At time: 564.9243042469025 and batch: 850, loss is 5.122292404174805 and perplexity is 167.7194099406505
At time: 566.0321502685547 and batch: 900, loss is 5.159071426391602 and perplexity is 174.00280615143828
At time: 567.1395664215088 and batch: 950, loss is 5.130672264099121 and perplexity is 169.13078038676088
At time: 568.2461242675781 and batch: 1000, loss is 5.148831567764282 and perplexity is 172.2301334639424
At time: 569.3538432121277 and batch: 1050, loss is 5.107680597305298 and perplexity is 165.28654388438815
At time: 570.4605672359467 and batch: 1100, loss is 5.107378854751587 and perplexity is 165.23667742433722
At time: 571.5677969455719 and batch: 1150, loss is 5.125729837417603 and perplexity is 168.29692623403713
At time: 572.6746392250061 and batch: 1200, loss is 5.114173917770386 and perplexity is 166.36329444234414
At time: 573.782940864563 and batch: 1250, loss is 5.129646825790405 and perplexity is 168.95743609749633
At time: 574.8903093338013 and batch: 1300, loss is 5.10617166519165 and perplexity is 165.03732578425098
At time: 575.9960968494415 and batch: 1350, loss is 5.098807334899902 and perplexity is 163.82640070553452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.134847412109375 and perplexity of 169.83840261380126
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 579.4846014976501 and batch: 50, loss is 5.175945024490357 and perplexity is 176.9637703776002
At time: 580.5925710201263 and batch: 100, loss is 5.18321026802063 and perplexity is 178.25413700345658
At time: 581.7321400642395 and batch: 150, loss is 5.15730770111084 and perplexity is 173.6961834818674
At time: 582.8393635749817 and batch: 200, loss is 5.136201915740966 and perplexity is 170.06860521686062
At time: 583.9467694759369 and batch: 250, loss is 5.158512353897095 and perplexity is 173.9055531568222
At time: 585.0538625717163 and batch: 300, loss is 5.1610129451751705 and perplexity is 174.3409640316894
At time: 586.160694360733 and batch: 350, loss is 5.1598172283172605 and perplexity is 174.1326261833335
At time: 587.2677819728851 and batch: 400, loss is 5.192780132293701 and perplexity is 179.9681934631144
At time: 588.3750584125519 and batch: 450, loss is 5.157202816009521 and perplexity is 173.67796629543662
At time: 589.4823071956635 and batch: 500, loss is 5.189094324111938 and perplexity is 179.30608617299498
At time: 590.5899477005005 and batch: 550, loss is 5.1645235919952395 and perplexity is 174.9540891858993
At time: 591.6973206996918 and batch: 600, loss is 5.124887704849243 and perplexity is 168.15525757157042
At time: 592.8044755458832 and batch: 650, loss is 5.131548385620118 and perplexity is 169.2790244337381
At time: 593.9113674163818 and batch: 700, loss is 5.149820442199707 and perplexity is 172.40053167726757
At time: 595.0183024406433 and batch: 750, loss is 5.136024513244629 and perplexity is 170.0384372977577
At time: 596.1250112056732 and batch: 800, loss is 5.104769973754883 and perplexity is 164.80615642985347
At time: 597.2326278686523 and batch: 850, loss is 5.076741619110107 and perplexity is 160.25104536372942
At time: 598.3394572734833 and batch: 900, loss is 5.108486680984497 and perplexity is 165.41983238342922
At time: 599.447060585022 and batch: 950, loss is 5.0862147235870365 and perplexity is 161.77633345918127
At time: 600.5535402297974 and batch: 1000, loss is 5.100831747055054 and perplexity is 164.15838878943302
At time: 601.6601946353912 and batch: 1050, loss is 5.056371154785157 and perplexity is 157.01968109506655
At time: 602.7681667804718 and batch: 1100, loss is 5.05720811843872 and perplexity is 157.15115587316765
At time: 603.875529050827 and batch: 1150, loss is 5.070255002975464 and perplexity is 159.21492244610312
At time: 604.9837126731873 and batch: 1200, loss is 5.055949697494507 and perplexity is 156.95351794914296
At time: 606.0916736125946 and batch: 1250, loss is 5.073331518173218 and perplexity is 159.70550382831303
At time: 607.1982536315918 and batch: 1300, loss is 5.051532135009766 and perplexity is 156.26169518661192
At time: 608.3009233474731 and batch: 1350, loss is 5.054307832717895 and perplexity is 156.6960329320893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.078358561197916 and perplexity of 160.5103716248657
Finished 19 epochs...
Completing Train Step...
At time: 611.7504713535309 and batch: 50, loss is 5.151711664199829 and perplexity is 172.72688786433503
At time: 612.8626844882965 and batch: 100, loss is 5.159571666717529 and perplexity is 174.0898711467949
At time: 613.9654011726379 and batch: 150, loss is 5.134486255645752 and perplexity is 169.7770754519429
At time: 615.0677602291107 and batch: 200, loss is 5.114829158782959 and perplexity is 166.4723382169247
At time: 616.1707563400269 and batch: 250, loss is 5.138112936019898 and perplexity is 170.3939205132996
At time: 617.2731342315674 and batch: 300, loss is 5.14299973487854 and perplexity is 171.2286392196489
At time: 618.3760976791382 and batch: 350, loss is 5.142971181869507 and perplexity is 171.22375019656508
At time: 619.4771575927734 and batch: 400, loss is 5.175942602157593 and perplexity is 176.96334171298042
At time: 620.5796945095062 and batch: 450, loss is 5.142327098846436 and perplexity is 171.11350339377515
At time: 621.6824104785919 and batch: 500, loss is 5.175237045288086 and perplexity is 176.83852804833097
At time: 622.7847843170166 and batch: 550, loss is 5.153137722015381 and perplexity is 172.97338210847818
At time: 623.8879194259644 and batch: 600, loss is 5.114478874206543 and perplexity is 166.41403573627343
At time: 624.9920740127563 and batch: 650, loss is 5.122463140487671 and perplexity is 167.74804817902395
At time: 626.0964450836182 and batch: 700, loss is 5.1420513534545895 and perplexity is 171.06632613848592
At time: 627.202978849411 and batch: 750, loss is 5.12816180229187 and perplexity is 168.7067165429302
At time: 628.3097262382507 and batch: 800, loss is 5.096682157516479 and perplexity is 163.47861023306677
At time: 629.4179708957672 and batch: 850, loss is 5.071147041320801 and perplexity is 159.3570116271518
At time: 630.5266571044922 and batch: 900, loss is 5.106119909286499 and perplexity is 165.0287843491081
At time: 631.6342401504517 and batch: 950, loss is 5.084877853393555 and perplexity is 161.56020400167301
At time: 632.7425870895386 and batch: 1000, loss is 5.101101875305176 and perplexity is 164.20273859753792
At time: 633.8658108711243 and batch: 1050, loss is 5.059135208129883 and perplexity is 157.45429223727373
At time: 634.9781866073608 and batch: 1100, loss is 5.061421966552734 and perplexity is 157.81476416528668
At time: 636.0892534255981 and batch: 1150, loss is 5.075070886611939 and perplexity is 159.9835322680129
At time: 637.2721226215363 and batch: 1200, loss is 5.061407690048218 and perplexity is 157.81251113817603
At time: 638.3835883140564 and batch: 1250, loss is 5.078005704879761 and perplexity is 160.4537445173123
At time: 639.4894530773163 and batch: 1300, loss is 5.05470573425293 and perplexity is 156.75839493027144
At time: 640.6011910438538 and batch: 1350, loss is 5.053998374938965 and perplexity is 156.6475496279257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.081753743489584 and perplexity of 161.05625976672874
Annealing...
Finished 20 epochs...
Completing Train Step...
At time: 644.11070728302 and batch: 50, loss is 5.1470834827423095 and perplexity is 171.92932354456025
At time: 645.2727518081665 and batch: 100, loss is 5.154855718612671 and perplexity is 173.27080520314064
At time: 646.3851845264435 and batch: 150, loss is 5.130238656997681 and perplexity is 169.05745997658707
At time: 647.4983501434326 and batch: 200, loss is 5.11018030166626 and perplexity is 165.70022820778829
At time: 648.6119546890259 and batch: 250, loss is 5.134163475036621 and perplexity is 169.7222835474699
At time: 649.7245447635651 and batch: 300, loss is 5.139066352844238 and perplexity is 170.55645441284747
At time: 650.8463263511658 and batch: 350, loss is 5.1382636451721195 and perplexity is 170.4196023718009
At time: 651.9500117301941 and batch: 400, loss is 5.169365873336792 and perplexity is 175.80332055682817
At time: 653.0532398223877 and batch: 450, loss is 5.133275089263916 and perplexity is 169.57157164052447
At time: 654.1564192771912 and batch: 500, loss is 5.164288091659546 and perplexity is 174.9128922902968
At time: 655.2589044570923 and batch: 550, loss is 5.143163509368897 and perplexity is 171.2566843992514
At time: 656.3619956970215 and batch: 600, loss is 5.106185693740844 and perplexity is 165.0396410347344
At time: 657.4651432037354 and batch: 650, loss is 5.114396362304688 and perplexity is 166.40030516416505
At time: 658.5687444210052 and batch: 700, loss is 5.131187515258789 and perplexity is 169.2179476720847
At time: 659.6725409030914 and batch: 750, loss is 5.11382269859314 and perplexity is 166.30487472260958
At time: 660.7762382030487 and batch: 800, loss is 5.082024765014649 and perplexity is 161.0999153954123
At time: 661.8793020248413 and batch: 850, loss is 5.052923269271851 and perplexity is 156.4792274578536
At time: 662.9826209545135 and batch: 900, loss is 5.085677452087403 and perplexity is 161.68943899094927
At time: 664.0858387947083 and batch: 950, loss is 5.0630785083770755 and perplexity is 158.07640757441823
At time: 665.1892311573029 and batch: 1000, loss is 5.082177782058716 and perplexity is 161.12456831437592
At time: 666.3208739757538 and batch: 1050, loss is 5.038966970443726 and perplexity is 154.31052532778028
At time: 667.4243965148926 and batch: 1100, loss is 5.038391771316529 and perplexity is 154.2217915705308
At time: 668.5275692939758 and batch: 1150, loss is 5.049981899261475 and perplexity is 156.0196403901205
At time: 669.6306619644165 and batch: 1200, loss is 5.034765396118164 and perplexity is 153.66353832018297
At time: 670.7336804866791 and batch: 1250, loss is 5.050915870666504 and perplexity is 156.1654263422256
At time: 671.8364398479462 and batch: 1300, loss is 5.032513818740845 and perplexity is 153.31794218780192
At time: 672.9400897026062 and batch: 1350, loss is 5.036379423141479 and perplexity is 153.91175568441116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.066568603515625 and perplexity of 158.62907314272908
Finished 21 epochs...
Completing Train Step...
At time: 676.3311936855316 and batch: 50, loss is 5.138483486175537 and perplexity is 170.4570717066855
At time: 677.4699151515961 and batch: 100, loss is 5.144896459579468 and perplexity is 171.55372100703252
At time: 678.5775897502899 and batch: 150, loss is 5.1194713592529295 and perplexity is 167.24693270403478
At time: 679.6862528324127 and batch: 200, loss is 5.1003157424926755 and perplexity is 164.07370416257095
At time: 680.7946457862854 and batch: 250, loss is 5.124349222183228 and perplexity is 168.0647332552438
At time: 681.9031391143799 and batch: 300, loss is 5.1299676418304445 and perplexity is 169.01164904880756
At time: 683.0107781887054 and batch: 350, loss is 5.1295292186737065 and perplexity is 168.9375666690081
At time: 684.1177930831909 and batch: 400, loss is 5.160950965881348 and perplexity is 174.330158836707
At time: 685.2271919250488 and batch: 450, loss is 5.12572151184082 and perplexity is 168.29552507088823
At time: 686.3352053165436 and batch: 500, loss is 5.1579114437103275 and perplexity is 173.80108293015022
At time: 687.4430229663849 and batch: 550, loss is 5.138279275894165 and perplexity is 170.4222661740552
At time: 688.5467870235443 and batch: 600, loss is 5.1019739818573 and perplexity is 164.34600334372718
At time: 689.6515507698059 and batch: 650, loss is 5.110276441574097 and perplexity is 165.71615937825516
At time: 690.7544391155243 and batch: 700, loss is 5.127945156097412 and perplexity is 168.67017083369902
At time: 691.8578107357025 and batch: 750, loss is 5.111124048233032 and perplexity is 165.85668104357393
At time: 692.9603407382965 and batch: 800, loss is 5.080024633407593 and perplexity is 160.77801639023698
At time: 694.1108782291412 and batch: 850, loss is 5.052053489685059 and perplexity is 156.3431841924579
At time: 695.2140679359436 and batch: 900, loss is 5.08579686164856 and perplexity is 161.70874740868481
At time: 696.3174088001251 and batch: 950, loss is 5.064292373657227 and perplexity is 158.2684075446572
At time: 697.4202852249146 and batch: 1000, loss is 5.083868198394775 and perplexity is 161.3971662538875
At time: 698.522794008255 and batch: 1050, loss is 5.041678638458252 and perplexity is 154.7295320904831
At time: 699.6261534690857 and batch: 1100, loss is 5.041617031097412 and perplexity is 154.71999990599647
At time: 700.7297501564026 and batch: 1150, loss is 5.053608350753784 and perplexity is 156.58646520799635
At time: 701.8333468437195 and batch: 1200, loss is 5.039027137756348 and perplexity is 154.31981005671432
At time: 702.9405081272125 and batch: 1250, loss is 5.05568561553955 and perplexity is 156.91207482971654
At time: 704.0477993488312 and batch: 1300, loss is 5.0363063621521 and perplexity is 153.90051115003715
At time: 705.1558213233948 and batch: 1350, loss is 5.0378208827972415 and perplexity is 154.133773247015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065325520833333 and perplexity of 158.4320065993775
Finished 22 epochs...
Completing Train Step...
At time: 708.6193432807922 and batch: 50, loss is 5.135180444717407 and perplexity is 169.89497375946297
At time: 709.7286677360535 and batch: 100, loss is 5.140432052612304 and perplexity is 170.78954245099277
At time: 710.8368124961853 and batch: 150, loss is 5.114582986831665 and perplexity is 166.43136244033974
At time: 711.9452238082886 and batch: 200, loss is 5.095579061508179 and perplexity is 163.2983770562011
At time: 713.0528333187103 and batch: 250, loss is 5.1197883415222165 and perplexity is 167.29995541948097
At time: 714.1624908447266 and batch: 300, loss is 5.12584189414978 and perplexity is 168.31578609429388
At time: 715.2709562778473 and batch: 350, loss is 5.125633583068848 and perplexity is 168.28072770260712
At time: 716.3798382282257 and batch: 400, loss is 5.1571485042572025 and perplexity is 173.66853379689806
At time: 717.4885926246643 and batch: 450, loss is 5.122208986282349 and perplexity is 167.7054197244746
At time: 718.5976505279541 and batch: 500, loss is 5.154915218353271 and perplexity is 173.2811150778182
At time: 719.7065608501434 and batch: 550, loss is 5.1361485290527344 and perplexity is 170.05952605961107
At time: 720.8146488666534 and batch: 600, loss is 5.100323944091797 and perplexity is 164.07504983483722
At time: 721.9534375667572 and batch: 650, loss is 5.108681230545044 and perplexity is 165.45201786985976
At time: 723.0622820854187 and batch: 700, loss is 5.12655818939209 and perplexity is 168.43639308102746
At time: 724.1715490818024 and batch: 750, loss is 5.110007696151733 and perplexity is 165.67162990282486
At time: 725.2797682285309 and batch: 800, loss is 5.0793202781677245 and perplexity is 160.66481142487237
At time: 726.3881664276123 and batch: 850, loss is 5.051873550415039 and perplexity is 156.31505444492086
At time: 727.4944388866425 and batch: 900, loss is 5.085930671691894 and perplexity is 161.73038711095563
At time: 728.5981161594391 and batch: 950, loss is 5.065117902755738 and perplexity is 158.3991166651283
At time: 729.701922416687 and batch: 1000, loss is 5.085109176635743 and perplexity is 161.59758095478355
At time: 730.8059639930725 and batch: 1050, loss is 5.043373756408691 and perplexity is 154.9920393252978
At time: 731.9086627960205 and batch: 1100, loss is 5.0433965682983395 and perplexity is 154.99557502692315
At time: 733.0127167701721 and batch: 1150, loss is 5.055322647094727 and perplexity is 156.85513103296736
At time: 734.1167607307434 and batch: 1200, loss is 5.040418834686279 and perplexity is 154.53472597682318
At time: 735.2204446792603 and batch: 1250, loss is 5.05790620803833 and perplexity is 157.26089976172614
At time: 736.3247783184052 and batch: 1300, loss is 5.038027181625366 and perplexity is 154.16557414394134
At time: 737.4284291267395 and batch: 1350, loss is 5.038068342208862 and perplexity is 154.1719198195231
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.064844156901041 and perplexity of 158.35576149797305
Finished 23 epochs...
Completing Train Step...
At time: 740.8571259975433 and batch: 50, loss is 5.132770605087281 and perplexity is 169.48604704054225
At time: 741.9593591690063 and batch: 100, loss is 5.13741455078125 and perplexity is 170.27496145891666
At time: 743.0624363422394 and batch: 150, loss is 5.111425457000732 and perplexity is 165.90667923599034
At time: 744.165328502655 and batch: 200, loss is 5.092477321624756 and perplexity is 162.79265268536878
At time: 745.2686891555786 and batch: 250, loss is 5.116818904876709 and perplexity is 166.80390565972928
At time: 746.3711307048798 and batch: 300, loss is 5.123116235733033 and perplexity is 167.85763941457043
At time: 747.4739637374878 and batch: 350, loss is 5.123166542053223 and perplexity is 167.86608392712964
At time: 748.576587677002 and batch: 400, loss is 5.154730129241943 and perplexity is 173.2490455981658
At time: 749.680570602417 and batch: 450, loss is 5.119820528030395 and perplexity is 167.30534030752426
At time: 750.8115952014923 and batch: 500, loss is 5.152966499328613 and perplexity is 172.94376767665793
At time: 751.914820432663 and batch: 550, loss is 5.134757423400879 and perplexity is 169.8231197629494
At time: 753.0173659324646 and batch: 600, loss is 5.099270820617676 and perplexity is 163.90234950168733
At time: 754.1195073127747 and batch: 650, loss is 5.107721910476685 and perplexity is 165.29337253675928
At time: 755.222752571106 and batch: 700, loss is 5.125646724700927 and perplexity is 168.28293920054796
At time: 756.3253169059753 and batch: 750, loss is 5.109248161315918 and perplexity is 165.54584430392657
At time: 757.4283895492554 and batch: 800, loss is 5.078833112716675 and perplexity is 160.58656014175514
At time: 758.5326726436615 and batch: 850, loss is 5.051650857925415 and perplexity is 156.28024813197678
At time: 759.6393535137177 and batch: 900, loss is 5.085872325897217 and perplexity is 161.72095109827464
At time: 760.7421522140503 and batch: 950, loss is 5.065582256317139 and perplexity is 158.472686939062
At time: 761.8447422981262 and batch: 1000, loss is 5.08576455116272 and perplexity is 161.70352260489994
At time: 762.9469709396362 and batch: 1050, loss is 5.044304885864258 and perplexity is 155.1364241885597
At time: 764.0490107536316 and batch: 1100, loss is 5.044245796203613 and perplexity is 155.12725750073167
At time: 765.1518602371216 and batch: 1150, loss is 5.056204986572266 and perplexity is 156.99359158295414
At time: 766.2547545433044 and batch: 1200, loss is 5.041583642959595 and perplexity is 154.714834179554
At time: 767.3575448989868 and batch: 1250, loss is 5.059195137023925 and perplexity is 157.46372858162184
At time: 768.4600064754486 and batch: 1300, loss is 5.038956022262573 and perplexity is 154.30883591744322
At time: 769.5622880458832 and batch: 1350, loss is 5.037957305908203 and perplexity is 154.15480209024312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0644844563802085 and perplexity of 158.2988110912449
Finished 24 epochs...
Completing Train Step...
At time: 772.9410429000854 and batch: 50, loss is 5.130786066055298 and perplexity is 169.15002889565682
At time: 774.0713231563568 and batch: 100, loss is 5.135042276382446 and perplexity is 169.87150127543478
At time: 775.172730922699 and batch: 150, loss is 5.108991632461548 and perplexity is 165.50338246471787
At time: 776.2744526863098 and batch: 200, loss is 5.090086536407471 and perplexity is 162.4039152968108
At time: 777.3762114048004 and batch: 250, loss is 5.114492607116699 and perplexity is 166.4163211009673
At time: 778.5068800449371 and batch: 300, loss is 5.120925054550171 and perplexity is 167.49023558486533
At time: 779.6093459129333 and batch: 350, loss is 5.121241426467895 and perplexity is 167.5432331749299
At time: 780.7123482227325 and batch: 400, loss is 5.152840852737427 and perplexity is 172.92203924686257
At time: 781.8141753673553 and batch: 450, loss is 5.117941055297852 and perplexity is 166.99118979354574
At time: 782.9160785675049 and batch: 500, loss is 5.151412811279297 and perplexity is 172.67527564205812
At time: 784.0183873176575 and batch: 550, loss is 5.133635511398316 and perplexity is 169.63270000365452
At time: 785.120504617691 and batch: 600, loss is 5.098467035293579 and perplexity is 163.77066013065482
At time: 786.222442150116 and batch: 650, loss is 5.106967163085938 and perplexity is 165.16866486244515
At time: 787.3251702785492 and batch: 700, loss is 5.124877576828003 and perplexity is 168.15355450017444
At time: 788.4277064800262 and batch: 750, loss is 5.108562107086182 and perplexity is 165.43230982708374
At time: 789.5299789905548 and batch: 800, loss is 5.078325643539428 and perplexity is 160.50508808623013
At time: 790.6318821907043 and batch: 850, loss is 5.051335735321045 and perplexity is 156.23100845184945
At time: 791.7342917919159 and batch: 900, loss is 5.085669822692871 and perplexity is 161.68820540313342
At time: 792.836731672287 and batch: 950, loss is 5.065802888870239 and perplexity is 158.50765502998576
At time: 793.940911769867 and batch: 1000, loss is 5.086185178756714 and perplexity is 161.77155387546534
At time: 795.0429844856262 and batch: 1050, loss is 5.0448786067962645 and perplexity is 155.22545473933653
At time: 796.1439378261566 and batch: 1100, loss is 5.044726896286011 and perplexity is 155.20190719264394
At time: 797.2455599308014 and batch: 1150, loss is 5.056714839935303 and perplexity is 157.07365570234387
At time: 798.3486111164093 and batch: 1200, loss is 5.042310409545898 and perplexity is 154.82731662073002
At time: 799.4507260322571 and batch: 1250, loss is 5.05997486114502 and perplexity is 157.58655472802602
At time: 800.5529184341431 and batch: 1300, loss is 5.039462461471557 and perplexity is 154.38700375420254
At time: 801.6554043292999 and batch: 1350, loss is 5.037660837173462 and perplexity is 154.10910678506247
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.064198811848958 and perplexity of 158.25360035895983
Finished 25 epochs...
Completing Train Step...
At time: 805.0532808303833 and batch: 50, loss is 5.129048471450806 and perplexity is 168.8563699221075
At time: 806.1827974319458 and batch: 100, loss is 5.132993125915528 and perplexity is 169.5237654125121
At time: 807.2849202156067 and batch: 150, loss is 5.106981143951416 and perplexity is 165.17097407947227
At time: 808.386724948883 and batch: 200, loss is 5.08809341430664 and perplexity is 162.08054682744222
At time: 809.4882674217224 and batch: 250, loss is 5.112539339065552 and perplexity is 166.09158267161743
At time: 810.5912878513336 and batch: 300, loss is 5.118955192565918 and perplexity is 167.16062768467216
At time: 811.692654132843 and batch: 350, loss is 5.119647979736328 and perplexity is 167.27647454690637
At time: 812.793698310852 and batch: 400, loss is 5.151262331008911 and perplexity is 172.6492933748489
At time: 813.895534992218 and batch: 450, loss is 5.116314287185669 and perplexity is 166.71975469181805
At time: 814.997138261795 and batch: 500, loss is 5.150079269409179 and perplexity is 172.44515940097855
At time: 816.0990211963654 and batch: 550, loss is 5.132624616622925 and perplexity is 169.46130583881407
At time: 817.2005732059479 and batch: 600, loss is 5.097718925476074 and perplexity is 163.64818750918906
At time: 818.3023624420166 and batch: 650, loss is 5.106257629394531 and perplexity is 165.05151369622524
At time: 819.4043447971344 and batch: 700, loss is 5.124137887954712 and perplexity is 168.02921917730282
At time: 820.5074617862701 and batch: 750, loss is 5.107893915176391 and perplexity is 165.3218062189593
At time: 821.6089954376221 and batch: 800, loss is 5.07778995513916 and perplexity is 160.41913039768215
At time: 822.7107517719269 and batch: 850, loss is 5.050959358215332 and perplexity is 156.17221774149843
At time: 823.8118758201599 and batch: 900, loss is 5.0853594875335695 and perplexity is 161.6380356532737
At time: 824.913578748703 and batch: 950, loss is 5.065815114974976 and perplexity is 158.50959297302444
At time: 826.0147037506104 and batch: 1000, loss is 5.08638765335083 and perplexity is 161.80431182138975
At time: 827.1163444519043 and batch: 1050, loss is 5.0452031326293945 and perplexity is 155.27583758418396
At time: 828.216864824295 and batch: 1100, loss is 5.044970808029174 and perplexity is 155.2397673774538
At time: 829.3190338611603 and batch: 1150, loss is 5.057092351913452 and perplexity is 157.13296408293084
At time: 830.4204015731812 and batch: 1200, loss is 5.042872352600098 and perplexity is 154.91434520616977
At time: 831.5222556591034 and batch: 1250, loss is 5.060363426208496 and perplexity is 157.6477992556382
At time: 832.6237823963165 and batch: 1300, loss is 5.03969560623169 and perplexity is 154.4230024714535
At time: 833.7253909111023 and batch: 1350, loss is 5.037290296554565 and perplexity is 154.0520136795673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.063936360677084 and perplexity of 158.21207196591837
Finished 26 epochs...
Completing Train Step...
At time: 837.131055355072 and batch: 50, loss is 5.1274053001403805 and perplexity is 168.57913781177146
At time: 838.2336275577545 and batch: 100, loss is 5.1311666202545165 and perplexity is 169.21441189928524
At time: 839.3371343612671 and batch: 150, loss is 5.105162315368652 and perplexity is 164.87082942935112
At time: 840.4400599002838 and batch: 200, loss is 5.086329345703125 and perplexity is 161.79487766762327
At time: 841.5424075126648 and batch: 250, loss is 5.110829448699951 and perplexity is 165.80782693933156
At time: 842.6453733444214 and batch: 300, loss is 5.117000255584717 and perplexity is 166.834158409215
At time: 843.7485842704773 and batch: 350, loss is 5.118191232681275 and perplexity is 167.03297243878146
At time: 844.8518626689911 and batch: 400, loss is 5.14983208656311 and perplexity is 172.40253918339738
At time: 845.9549469947815 and batch: 450, loss is 5.1147657489776615 and perplexity is 166.46178257304018
At time: 847.0575671195984 and batch: 500, loss is 5.148896112442016 and perplexity is 172.24125036116735
At time: 848.1603517532349 and batch: 550, loss is 5.131625833511353 and perplexity is 169.29213524490666
At time: 849.2629156112671 and batch: 600, loss is 5.096962985992431 and perplexity is 163.52452612897304
At time: 850.3659336566925 and batch: 650, loss is 5.105530014038086 and perplexity is 164.93146336078559
At time: 851.4691321849823 and batch: 700, loss is 5.1233885383605955 and perplexity is 167.90335371461904
At time: 852.5727174282074 and batch: 750, loss is 5.107164630889892 and perplexity is 165.20128357644458
At time: 853.6751437187195 and batch: 800, loss is 5.0772798633575436 and perplexity is 160.33732278412177
At time: 854.7779357433319 and batch: 850, loss is 5.050513792037964 and perplexity is 156.10264818350024
At time: 855.8808152675629 and batch: 900, loss is 5.084956703186035 and perplexity is 161.5729434924781
At time: 856.9841146469116 and batch: 950, loss is 5.0657454872131344 and perplexity is 158.49855668905565
At time: 858.0876152515411 and batch: 1000, loss is 5.086481618881225 and perplexity is 161.81951656372001
At time: 859.1902561187744 and batch: 1050, loss is 5.045414381027221 and perplexity is 155.30864282099972
At time: 860.2924673557281 and batch: 1100, loss is 5.045206775665283 and perplexity is 155.27640326066336
At time: 861.3949708938599 and batch: 1150, loss is 5.057035322189331 and perplexity is 157.12400308886282
At time: 862.5432667732239 and batch: 1200, loss is 5.043046474456787 and perplexity is 154.9413215281004
At time: 863.6462655067444 and batch: 1250, loss is 5.060636148452759 and perplexity is 157.69079918050585
At time: 864.7501964569092 and batch: 1300, loss is 5.039726085662842 and perplexity is 154.42770926845552
At time: 865.8535420894623 and batch: 1350, loss is 5.036790494918823 and perplexity is 153.9750374691612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.063620198567708 and perplexity of 158.16205921000278
Finished 27 epochs...
Completing Train Step...
At time: 869.2636528015137 and batch: 50, loss is 5.1258941268920895 and perplexity is 168.32457791898406
At time: 870.368677854538 and batch: 100, loss is 5.129499473571777 and perplexity is 168.9325416786027
At time: 871.4730942249298 and batch: 150, loss is 5.1035066509246825 and perplexity is 164.5980845085556
At time: 872.577027797699 and batch: 200, loss is 5.084757194519043 and perplexity is 161.54071150528733
At time: 873.681275844574 and batch: 250, loss is 5.109235191345215 and perplexity is 165.5436971931
At time: 874.7844607830048 and batch: 300, loss is 5.115345506668091 and perplexity is 166.5583180525389
At time: 875.8883473873138 and batch: 350, loss is 5.11688346862793 and perplexity is 166.81467549326365
At time: 876.9919517040253 and batch: 400, loss is 5.148446941375733 and perplexity is 172.16390194771972
At time: 878.0959222316742 and batch: 450, loss is 5.113373613357544 and perplexity is 166.23020642623365
At time: 879.2003574371338 and batch: 500, loss is 5.1478056049346925 and perplexity is 172.0535223625775
At time: 880.305814743042 and batch: 550, loss is 5.1307109832763675 and perplexity is 169.13732911820446
At time: 881.4094908237457 and batch: 600, loss is 5.096236591339111 and perplexity is 163.40578591885424
At time: 882.5128610134125 and batch: 650, loss is 5.104788904190063 and perplexity is 164.80927631164536
At time: 883.6168251037598 and batch: 700, loss is 5.122639551162719 and perplexity is 167.7776433358153
At time: 884.7206678390503 and batch: 750, loss is 5.106327638626099 and perplexity is 165.06306923036047
At time: 885.8246064186096 and batch: 800, loss is 5.076599912643433 and perplexity is 160.2283383632124
At time: 886.9287147521973 and batch: 850, loss is 5.0499398803710935 and perplexity is 156.0130847556848
At time: 888.0323765277863 and batch: 900, loss is 5.084412336349487 and perplexity is 161.4850124758935
At time: 889.1359796524048 and batch: 950, loss is 5.06546763420105 and perplexity is 158.45452350532818
At time: 890.2681872844696 and batch: 1000, loss is 5.086180381774902 and perplexity is 161.770777862125
At time: 891.3712513446808 and batch: 1050, loss is 5.045270071029663 and perplexity is 155.28623184823607
At time: 892.4745707511902 and batch: 1100, loss is 5.044973859786987 and perplexity is 155.2402411323496
At time: 893.5779554843903 and batch: 1150, loss is 5.056986608505249 and perplexity is 157.11634918624105
At time: 894.6817722320557 and batch: 1200, loss is 5.043215026855469 and perplexity is 154.96743946055713
At time: 895.7849974632263 and batch: 1250, loss is 5.060536069869995 and perplexity is 157.67501849847625
At time: 896.888482093811 and batch: 1300, loss is 5.0395704364776615 and perplexity is 154.403674591876
At time: 897.9923989772797 and batch: 1350, loss is 5.03609827041626 and perplexity is 153.86848905740726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.063188883463542 and perplexity of 158.09385623450348
Finished 28 epochs...
Completing Train Step...
At time: 901.3758244514465 and batch: 50, loss is 5.12459641456604 and perplexity is 168.10628271226685
At time: 902.5143461227417 and batch: 100, loss is 5.128031873703003 and perplexity is 168.6847981412618
At time: 903.6223292350769 and batch: 150, loss is 5.101832790374756 and perplexity is 164.3228007259095
At time: 904.731317281723 and batch: 200, loss is 5.08319766998291 and perplexity is 161.2889811429685
At time: 905.8400566577911 and batch: 250, loss is 5.107689514160156 and perplexity is 165.28801772708096
At time: 906.9496188163757 and batch: 300, loss is 5.11380859375 and perplexity is 166.3025290349811
At time: 908.0591812133789 and batch: 350, loss is 5.115652561187744 and perplexity is 166.60946838945193
At time: 909.1676406860352 and batch: 400, loss is 5.1471533107757566 and perplexity is 171.94132945028477
At time: 910.276373386383 and batch: 450, loss is 5.111952819824219 and perplexity is 165.99419532512522
At time: 911.3802275657654 and batch: 500, loss is 5.146771945953369 and perplexity is 171.8757695776271
At time: 912.4838478565216 and batch: 550, loss is 5.129868087768554 and perplexity is 168.99482409014837
At time: 913.5876262187958 and batch: 600, loss is 5.0955150699615475 and perplexity is 163.28792767483048
At time: 914.6912858486176 and batch: 650, loss is 5.104018440246582 and perplexity is 164.6823456107392
At time: 915.7948930263519 and batch: 700, loss is 5.121860027313232 and perplexity is 167.64690762384726
At time: 916.8983044624329 and batch: 750, loss is 5.105551795959473 and perplexity is 164.935055924081
At time: 918.0484313964844 and batch: 800, loss is 5.0759962368011475 and perplexity is 160.1316415757869
At time: 919.1513347625732 and batch: 850, loss is 5.0493761253356935 and perplexity is 155.92515638092627
At time: 920.2555184364319 and batch: 900, loss is 5.0839262866973876 and perplexity is 161.4065418136242
At time: 921.3594627380371 and batch: 950, loss is 5.065216655731201 and perplexity is 158.4147598216012
At time: 922.4629082679749 and batch: 1000, loss is 5.086026649475098 and perplexity is 161.74591037991976
At time: 923.5657758712769 and batch: 1050, loss is 5.045192413330078 and perplexity is 155.27417314492507
At time: 924.6688995361328 and batch: 1100, loss is 5.044937810897827 and perplexity is 155.23464499497175
At time: 925.7725350856781 and batch: 1150, loss is 5.0568457698822025 and perplexity is 157.09422269413247
At time: 926.8757998943329 and batch: 1200, loss is 5.043230438232422 and perplexity is 154.96982774058543
At time: 927.9794390201569 and batch: 1250, loss is 5.060478858947754 and perplexity is 157.66599802329083
At time: 929.0860342979431 and batch: 1300, loss is 5.039346303939819 and perplexity is 154.36907158241257
At time: 930.1958656311035 and batch: 1350, loss is 5.035472764968872 and perplexity is 153.77227357411198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.062953287760417 and perplexity of 158.05661438846587
Finished 29 epochs...
Completing Train Step...
At time: 933.5762293338776 and batch: 50, loss is 5.123230724334717 and perplexity is 167.87685830113978
At time: 934.707433462143 and batch: 100, loss is 5.126603507995606 and perplexity is 168.44402655611108
At time: 935.8101737499237 and batch: 150, loss is 5.100422801971436 and perplexity is 164.09127074813486
At time: 936.9132764339447 and batch: 200, loss is 5.081795911788941 and perplexity is 161.0630513784983
At time: 938.0162241458893 and batch: 250, loss is 5.106348628997803 and perplexity is 165.0665340019015
At time: 939.1193590164185 and batch: 300, loss is 5.112409648895263 and perplexity is 166.07004362270894
At time: 940.2219219207764 and batch: 350, loss is 5.114547185897827 and perplexity is 166.4254041488013
At time: 941.3244273662567 and batch: 400, loss is 5.145940732955933 and perplexity is 171.7329635633396
At time: 942.4270079135895 and batch: 450, loss is 5.110777854919434 and perplexity is 165.79927250738007
At time: 943.5304129123688 and batch: 500, loss is 5.145854692459107 and perplexity is 171.71818820948175
At time: 944.6332249641418 and batch: 550, loss is 5.1290799999237064 and perplexity is 168.86169378951698
At time: 945.7355153560638 and batch: 600, loss is 5.094789180755615 and perplexity is 163.16944173970566
At time: 946.8670375347137 and batch: 650, loss is 5.103338003158569 and perplexity is 164.57032774992015
At time: 947.9694812297821 and batch: 700, loss is 5.121143627166748 and perplexity is 167.52684836503795
At time: 949.0727338790894 and batch: 750, loss is 5.1049073219299315 and perplexity is 164.82879380924163
At time: 950.1758871078491 and batch: 800, loss is 5.075380563735962 and perplexity is 160.03308318017272
At time: 951.2794625759125 and batch: 850, loss is 5.048846836090088 and perplexity is 155.84264870967223
At time: 952.3824164867401 and batch: 900, loss is 5.083412837982178 and perplexity is 161.32368910423236
At time: 953.4854848384857 and batch: 950, loss is 5.064924068450928 and perplexity is 158.36841645793984
At time: 954.5886166095734 and batch: 1000, loss is 5.085761661529541 and perplexity is 161.70305534171098
At time: 955.6918001174927 and batch: 1050, loss is 5.045071687698364 and perplexity is 155.25542870377333
At time: 956.7941162586212 and batch: 1100, loss is 5.0447797679901125 and perplexity is 155.21011319888794
At time: 957.8980009555817 and batch: 1150, loss is 5.0566655540466305 and perplexity is 157.06591437840612
At time: 958.9999048709869 and batch: 1200, loss is 5.043184795379639 and perplexity is 154.9627546369715
At time: 960.1028831005096 and batch: 1250, loss is 5.0604140663146975 and perplexity is 157.65578275907598
At time: 961.2055079936981 and batch: 1300, loss is 5.039092664718628 and perplexity is 154.3299224964021
At time: 962.3091151714325 and batch: 1350, loss is 5.034843616485595 and perplexity is 153.6755584087129
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0627213541666665 and perplexity of 158.01996000073103
Finished 30 epochs...
Completing Train Step...
At time: 965.7098286151886 and batch: 50, loss is 5.121932868957519 and perplexity is 167.65911974502828
At time: 966.8110265731812 and batch: 100, loss is 5.125251569747925 and perplexity is 168.21645450036144
At time: 967.9131026268005 and batch: 150, loss is 5.099120197296142 and perplexity is 163.87766384456273
At time: 969.0152862071991 and batch: 200, loss is 5.080492105484009 and perplexity is 160.85319319356006
At time: 970.1175458431244 and batch: 250, loss is 5.10506799697876 and perplexity is 164.85527981149818
At time: 971.2195439338684 and batch: 300, loss is 5.111117906570435 and perplexity is 165.85566241092752
At time: 972.3219830989838 and batch: 350, loss is 5.113479795455933 and perplexity is 166.24785803549358
At time: 973.4237053394318 and batch: 400, loss is 5.1448323440551755 and perplexity is 171.54272210286987
At time: 974.5582110881805 and batch: 450, loss is 5.109698495864868 and perplexity is 165.62041210602032
At time: 975.6596763134003 and batch: 500, loss is 5.14498351097107 and perplexity is 171.5686556472118
At time: 976.7617046833038 and batch: 550, loss is 5.128342018127442 and perplexity is 168.73712290459022
At time: 977.8635149002075 and batch: 600, loss is 5.0941329669952395 and perplexity is 163.06240283080675
At time: 978.9653525352478 and batch: 650, loss is 5.102692079544068 and perplexity is 164.4640622123849
At time: 980.0674724578857 and batch: 700, loss is 5.12045166015625 and perplexity is 167.41096541081126
At time: 981.1687309741974 and batch: 750, loss is 5.104263401031494 and perplexity is 164.72269126873135
At time: 982.2705230712891 and batch: 800, loss is 5.074720983505249 and perplexity is 159.9275633254776
At time: 983.3719282150269 and batch: 850, loss is 5.0483692932128905 and perplexity is 155.76824492972887
At time: 984.4735007286072 and batch: 900, loss is 5.082857494354248 and perplexity is 161.23412389349056
At time: 985.5754582881927 and batch: 950, loss is 5.064626550674438 and perplexity is 158.32130604724887
At time: 986.6776089668274 and batch: 1000, loss is 5.085505723953247 and perplexity is 161.66167474929762
At time: 987.779098033905 and batch: 1050, loss is 5.04492151260376 and perplexity is 155.23211495569592
At time: 988.8810434341431 and batch: 1100, loss is 5.044630079269409 and perplexity is 155.1868817343905
At time: 989.9839525222778 and batch: 1150, loss is 5.056359300613403 and perplexity is 157.01781976783042
At time: 991.0872325897217 and batch: 1200, loss is 5.043054904937744 and perplexity is 154.94262776346704
At time: 992.1907360553741 and batch: 1250, loss is 5.060318670272827 and perplexity is 157.6407437387657
At time: 993.2934930324554 and batch: 1300, loss is 5.038860588073731 and perplexity is 154.294110281532
At time: 994.395660161972 and batch: 1350, loss is 5.034255647659302 and perplexity is 153.5852285291843
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.062576904296875 and perplexity of 157.99713568660871
Finished 31 epochs...
Completing Train Step...
At time: 997.819305896759 and batch: 50, loss is 5.120732326507568 and perplexity is 167.45795863004295
At time: 998.9261472225189 and batch: 100, loss is 5.1239644718170165 and perplexity is 168.00008272553166
At time: 1000.032702922821 and batch: 150, loss is 5.097925939559937 and perplexity is 163.68206849560173
At time: 1001.1347134113312 and batch: 200, loss is 5.079255752563476 and perplexity is 160.65444476529484
At time: 1002.2645184993744 and batch: 250, loss is 5.1038487434387205 and perplexity is 164.65440191342304
At time: 1003.3699250221252 and batch: 300, loss is 5.109854784011841 and perplexity is 165.64629863615542
At time: 1004.4716417789459 and batch: 350, loss is 5.112477264404297 and perplexity is 166.08127291287653
At time: 1005.5734946727753 and batch: 400, loss is 5.143770895004272 and perplexity is 171.36073484549195
At time: 1006.6754837036133 and batch: 450, loss is 5.108652572631836 and perplexity is 165.44727642823182
At time: 1007.7777056694031 and batch: 500, loss is 5.144115314483643 and perplexity is 171.41976498555348
At time: 1008.878956079483 and batch: 550, loss is 5.127605533599853 and perplexity is 168.61289637541464
At time: 1009.9805905818939 and batch: 600, loss is 5.0933880043029784 and perplexity is 162.94097266027657
At time: 1011.082198381424 and batch: 650, loss is 5.102081460952759 and perplexity is 164.36366805278536
At time: 1012.1840448379517 and batch: 700, loss is 5.119733667373657 and perplexity is 167.2908086869115
At time: 1013.2860999107361 and batch: 750, loss is 5.103652038574219 and perplexity is 164.62201677686642
At time: 1014.3884358406067 and batch: 800, loss is 5.074058256149292 and perplexity is 159.82161006722956
At time: 1015.4906980991364 and batch: 850, loss is 5.0478311538696286 and perplexity is 155.68444245942686
At time: 1016.592348575592 and batch: 900, loss is 5.082301263809204 and perplexity is 161.14446548656153
At time: 1017.6936678886414 and batch: 950, loss is 5.064270992279052 and perplexity is 158.2650235841594
At time: 1018.7953691482544 and batch: 1000, loss is 5.08518684387207 and perplexity is 161.6101322797006
At time: 1019.896642446518 and batch: 1050, loss is 5.044680671691895 and perplexity is 155.19473321328636
At time: 1020.9984352588654 and batch: 1100, loss is 5.044369745254516 and perplexity is 155.14648656875585
At time: 1022.1002802848816 and batch: 1150, loss is 5.056085815429688 and perplexity is 156.97488359201623
At time: 1023.2022411823273 and batch: 1200, loss is 5.042916975021362 and perplexity is 154.92125801357346
At time: 1024.3038501739502 and batch: 1250, loss is 5.060194940567016 and perplexity is 157.6212401025336
At time: 1025.4055426120758 and batch: 1300, loss is 5.0385671234130855 and perplexity is 154.24883705618944
At time: 1026.5075953006744 and batch: 1350, loss is 5.033606786727905 and perplexity is 153.4856053990258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.062181803385417 and perplexity of 157.93472320471733
Finished 32 epochs...
Completing Train Step...
At time: 1029.881744146347 and batch: 50, loss is 5.119642457962036 and perplexity is 167.27555088651968
At time: 1031.014800786972 and batch: 100, loss is 5.122787923812866 and perplexity is 167.80253879624942
At time: 1032.1165254116058 and batch: 150, loss is 5.096713447570801 and perplexity is 163.48372556769056
At time: 1033.2195308208466 and batch: 200, loss is 5.078182487487793 and perplexity is 160.48211245614183
At time: 1034.3218133449554 and batch: 250, loss is 5.102745513916016 and perplexity is 164.47285048105303
At time: 1035.4248349666595 and batch: 300, loss is 5.108601865768432 and perplexity is 165.43888732847967
At time: 1036.527251958847 and batch: 350, loss is 5.11152813911438 and perplexity is 165.9237157591408
At time: 1037.629742860794 and batch: 400, loss is 5.142765302658081 and perplexity is 171.18850241441442
At time: 1038.7315094470978 and batch: 450, loss is 5.107609148025513 and perplexity is 165.27473470175326
At time: 1039.8334727287292 and batch: 500, loss is 5.143243827819824 and perplexity is 171.27044002326113
At time: 1040.9357271194458 and batch: 550, loss is 5.126983795166016 and perplexity is 168.50809583993376
At time: 1042.0383961200714 and batch: 600, loss is 5.092827863693238 and perplexity is 162.84972836170311
At time: 1043.1412489414215 and batch: 650, loss is 5.101362581253052 and perplexity is 164.2455528088651
At time: 1044.2437455654144 and batch: 700, loss is 5.119040832519532 and perplexity is 167.17494392608552
At time: 1045.3457169532776 and batch: 750, loss is 5.102955932617188 and perplexity is 164.50746228598706
At time: 1046.4477672576904 and batch: 800, loss is 5.073460121154785 and perplexity is 159.72604375299747
At time: 1047.5497634410858 and batch: 850, loss is 5.047205076217652 and perplexity is 155.5870024149425
At time: 1048.6525931358337 and batch: 900, loss is 5.081681880950928 and perplexity is 161.04468627089088
At time: 1049.7563111782074 and batch: 950, loss is 5.063814992904663 and perplexity is 158.19287128436937
At time: 1050.8579046726227 and batch: 1000, loss is 5.084829521179199 and perplexity is 161.55239562796143
At time: 1051.9596419334412 and batch: 1050, loss is 5.044287528991699 and perplexity is 155.13373152878395
At time: 1053.0599143505096 and batch: 1100, loss is 5.044017324447632 and perplexity is 155.091819352272
At time: 1054.161418914795 and batch: 1150, loss is 5.055756072998047 and perplexity is 156.9231308452013
At time: 1055.2629466056824 and batch: 1200, loss is 5.042722444534302 and perplexity is 154.89112403687972
At time: 1056.3652729988098 and batch: 1250, loss is 5.059906997680664 and perplexity is 157.57586072135658
At time: 1057.467413187027 and batch: 1300, loss is 5.0382974910736085 and perplexity is 154.20725218795695
At time: 1058.5689849853516 and batch: 1350, loss is 5.033056735992432 and perplexity is 153.40120374361584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0617822265625 and perplexity of 157.87162875617014
Finished 33 epochs...
Completing Train Step...
At time: 1061.9600126743317 and batch: 50, loss is 5.1185485458374025 and perplexity is 167.09266618138565
At time: 1063.0911848545074 and batch: 100, loss is 5.121666755676269 and perplexity is 167.61450936251234
At time: 1064.1941089630127 and batch: 150, loss is 5.09563419342041 and perplexity is 163.307380256172
At time: 1065.2969841957092 and batch: 200, loss is 5.076960887908935 and perplexity is 160.28618727057832
At time: 1066.3992667198181 and batch: 250, loss is 5.101571798324585 and perplexity is 164.27991937734717
At time: 1067.502032995224 and batch: 300, loss is 5.107306842803955 and perplexity is 165.22477883780104
At time: 1068.6049814224243 and batch: 350, loss is 5.110593118667603 and perplexity is 165.76864620020245
At time: 1069.7075190544128 and batch: 400, loss is 5.141670389175415 and perplexity is 171.00116839103273
At time: 1070.8108315467834 and batch: 450, loss is 5.1065153217315675 and perplexity is 165.09405168714272
At time: 1071.9126489162445 and batch: 500, loss is 5.142233562469483 and perplexity is 171.0974988051372
At time: 1073.0147995948792 and batch: 550, loss is 5.126270771026611 and perplexity is 168.3879883247822
At time: 1074.1171913146973 and batch: 600, loss is 5.092046995162963 and perplexity is 162.72261377001303
At time: 1075.220139503479 and batch: 650, loss is 5.100641946792603 and perplexity is 164.1272344408026
At time: 1076.322612285614 and batch: 700, loss is 5.118311948776245 and perplexity is 167.0531372240282
At time: 1077.4254400730133 and batch: 750, loss is 5.102323818206787 and perplexity is 164.40350760754419
At time: 1078.527996301651 and batch: 800, loss is 5.0728891086578365 and perplexity is 159.63486422073007
At time: 1079.6305944919586 and batch: 850, loss is 5.046591787338257 and perplexity is 155.49161189054686
At time: 1080.7330541610718 and batch: 900, loss is 5.081074752807617 and perplexity is 160.94694118442405
At time: 1081.8353898525238 and batch: 950, loss is 5.063353090286255 and perplexity is 158.11981845585487
At time: 1082.9378209114075 and batch: 1000, loss is 5.084491128921509 and perplexity is 161.49773679665384
At time: 1084.039983034134 and batch: 1050, loss is 5.044023218154908 and perplexity is 155.0927334207498
At time: 1085.1416444778442 and batch: 1100, loss is 5.043768720626831 and perplexity is 155.05326772564553
At time: 1086.2725315093994 and batch: 1150, loss is 5.055361042022705 and perplexity is 156.8611535900435
At time: 1087.3750755786896 and batch: 1200, loss is 5.042497596740723 and perplexity is 154.85630102448044
At time: 1088.477531194687 and batch: 1250, loss is 5.059636602401733 and perplexity is 157.53325871249464
At time: 1089.5795483589172 and batch: 1300, loss is 5.0379080390930175 and perplexity is 154.14720756117921
At time: 1090.6824669837952 and batch: 1350, loss is 5.032379274368286 and perplexity is 153.29731550910117
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.06136962890625 and perplexity of 157.80650472809143
Finished 34 epochs...
Completing Train Step...
At time: 1094.0918912887573 and batch: 50, loss is 5.117448968887329 and perplexity is 166.9090359134331
At time: 1095.1945688724518 and batch: 100, loss is 5.120432586669922 and perplexity is 167.40777233050298
At time: 1096.299427986145 and batch: 150, loss is 5.094434547424316 and perplexity is 163.11158667628857
At time: 1097.4026799201965 and batch: 200, loss is 5.075895233154297 and perplexity is 160.11546851279448
At time: 1098.505789756775 and batch: 250, loss is 5.100422916412353 and perplexity is 164.09128952689147
At time: 1099.6092941761017 and batch: 300, loss is 5.106130208969116 and perplexity is 165.030484101963
At time: 1100.7125279903412 and batch: 350, loss is 5.109636993408203 and perplexity is 165.61022635702938
At time: 1101.8153040409088 and batch: 400, loss is 5.140640449523926 and perplexity is 170.82513817306724
At time: 1102.9188385009766 and batch: 450, loss is 5.105486879348755 and perplexity is 164.9243492467862
At time: 1104.0215697288513 and batch: 500, loss is 5.1413421535491945 and perplexity is 170.94504892614918
At time: 1105.1247498989105 and batch: 550, loss is 5.125602779388427 and perplexity is 168.2755441166872
At time: 1106.2282147407532 and batch: 600, loss is 5.09132098197937 and perplexity is 162.6045178819204
At time: 1107.3310432434082 and batch: 650, loss is 5.099952964782715 and perplexity is 164.01419267528334
At time: 1108.4337394237518 and batch: 700, loss is 5.117594985961914 and perplexity is 166.93340926199824
At time: 1109.5387606620789 and batch: 750, loss is 5.101705446243286 and perplexity is 164.3018765138864
At time: 1110.6416606903076 and batch: 800, loss is 5.072212638854981 and perplexity is 159.52691257273347
At time: 1111.7447040081024 and batch: 850, loss is 5.0459231090545655 and perplexity is 155.38767278116495
At time: 1112.847826719284 and batch: 900, loss is 5.080392789840698 and perplexity is 160.8372187484688
At time: 1113.993022441864 and batch: 950, loss is 5.062751922607422 and perplexity is 158.0247904983465
At time: 1115.0959224700928 and batch: 1000, loss is 5.084016418457031 and perplexity is 161.42109032488742
At time: 1116.1985621452332 and batch: 1050, loss is 5.043611335754394 and perplexity is 155.02886660711746
At time: 1117.3007130622864 and batch: 1100, loss is 5.0432857894897465 and perplexity is 154.9784057527979
At time: 1118.403650522232 and batch: 1150, loss is 5.054867753982544 and perplexity is 156.78379494062858
At time: 1119.5075528621674 and batch: 1200, loss is 5.042060871124267 and perplexity is 154.7886860766181
At time: 1120.6113979816437 and batch: 1250, loss is 5.0591800498962405 and perplexity is 157.46135292416395
At time: 1121.714382648468 and batch: 1300, loss is 5.037324619293213 and perplexity is 154.05730125731253
At time: 1122.817403793335 and batch: 1350, loss is 5.031672964096069 and perplexity is 153.1890782694906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0610139973958335 and perplexity of 157.75039374047049
Finished 35 epochs...
Completing Train Step...
At time: 1126.2285323143005 and batch: 50, loss is 5.116401948928833 and perplexity is 166.7343702767387
At time: 1127.3375024795532 and batch: 100, loss is 5.119180593490601 and perplexity is 167.198310091388
At time: 1128.4453637599945 and batch: 150, loss is 5.093313264846802 and perplexity is 162.9287949956727
At time: 1129.5537776947021 and batch: 200, loss is 5.074769191741943 and perplexity is 159.93527333714584
At time: 1130.6618871688843 and batch: 250, loss is 5.099239196777344 and perplexity is 163.89716636191244
At time: 1131.7700510025024 and batch: 300, loss is 5.10488920211792 and perplexity is 164.82580716954246
At time: 1132.8789992332458 and batch: 350, loss is 5.1085912704467775 and perplexity is 165.43713445954035
At time: 1133.9875891208649 and batch: 400, loss is 5.139494638442994 and perplexity is 170.62951693074262
At time: 1135.0956852436066 and batch: 450, loss is 5.104404754638672 and perplexity is 164.7459770610529
At time: 1136.2046160697937 and batch: 500, loss is 5.140381698608398 and perplexity is 170.78094273022208
At time: 1137.3127479553223 and batch: 550, loss is 5.124844484329223 and perplexity is 168.14798997095
At time: 1138.4214508533478 and batch: 600, loss is 5.090625267028809 and perplexity is 162.4914308305387
At time: 1139.5295822620392 and batch: 650, loss is 5.099308128356934 and perplexity is 163.90846444187287
At time: 1140.6384353637695 and batch: 700, loss is 5.116768665313721 and perplexity is 166.7955257149084
At time: 1141.7468190193176 and batch: 750, loss is 5.101114950180054 and perplexity is 164.20488554183518
At time: 1142.8851263523102 and batch: 800, loss is 5.071629829406739 and perplexity is 159.43396586857673
At time: 1143.9933037757874 and batch: 850, loss is 5.045224084854126 and perplexity is 155.2790909925113
At time: 1145.1016132831573 and batch: 900, loss is 5.079727478027344 and perplexity is 160.73024743539335
At time: 1146.210666179657 and batch: 950, loss is 5.062186555862427 and perplexity is 157.93547378764202
At time: 1147.3185505867004 and batch: 1000, loss is 5.083542318344116 and perplexity is 161.34457870625417
At time: 1148.4271569252014 and batch: 1050, loss is 5.043167972564698 and perplexity is 154.96014774915517
At time: 1149.5350105762482 and batch: 1100, loss is 5.042822360992432 and perplexity is 154.9066009825771
At time: 1150.6425151824951 and batch: 1150, loss is 5.054438333511353 and perplexity is 156.7164832230792
At time: 1151.7525308132172 and batch: 1200, loss is 5.041705465316772 and perplexity is 154.73368305342782
At time: 1152.858654499054 and batch: 1250, loss is 5.058907470703125 and perplexity is 157.41843808474886
At time: 1153.962170600891 and batch: 1300, loss is 5.036897535324097 and perplexity is 153.99151990170134
At time: 1155.0657188892365 and batch: 1350, loss is 5.0311140441894535 and perplexity is 153.10348176719253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.060696207682292 and perplexity of 157.70027025281885
Finished 36 epochs...
Completing Train Step...
At time: 1158.469636440277 and batch: 50, loss is 5.115408611297608 and perplexity is 166.56882898513328
At time: 1159.6012153625488 and batch: 100, loss is 5.11809024810791 and perplexity is 167.01610553698464
At time: 1160.7048604488373 and batch: 150, loss is 5.092293739318848 and perplexity is 162.7627695778927
At time: 1161.8087840080261 and batch: 200, loss is 5.073847932815552 and perplexity is 159.78799938807543
At time: 1162.9126043319702 and batch: 250, loss is 5.098271980285644 and perplexity is 163.73871895848762
At time: 1164.015816450119 and batch: 300, loss is 5.1037388515472415 and perplexity is 164.63630872392204
At time: 1165.1192846298218 and batch: 350, loss is 5.107615327835083 and perplexity is 165.27575607129634
At time: 1166.2228989601135 and batch: 400, loss is 5.138546752929687 and perplexity is 170.46785631348428
At time: 1167.326498746872 and batch: 450, loss is 5.103393211364746 and perplexity is 164.57941363331045
At time: 1168.4306704998016 and batch: 500, loss is 5.139454383850097 and perplexity is 170.6226484472474
At time: 1169.535118818283 and batch: 550, loss is 5.124258918762207 and perplexity is 168.04955712011665
At time: 1170.6660161018372 and batch: 600, loss is 5.090032224655151 and perplexity is 162.39509509510995
At time: 1171.767965555191 and batch: 650, loss is 5.098667125701905 and perplexity is 163.80343234750592
At time: 1172.8707070350647 and batch: 700, loss is 5.116088352203369 and perplexity is 166.68209112191192
At time: 1173.9730932712555 and batch: 750, loss is 5.1004880428314205 and perplexity is 164.10197655297858
At time: 1175.0764544010162 and batch: 800, loss is 5.071029195785522 and perplexity is 159.33823322131357
At time: 1176.1798875331879 and batch: 850, loss is 5.044540319442749 and perplexity is 155.17295281192426
At time: 1177.2827668190002 and batch: 900, loss is 5.079075202941895 and perplexity is 160.62544128444964
At time: 1178.3849365711212 and batch: 950, loss is 5.06168927192688 and perplexity is 157.8569545384731
At time: 1179.4880690574646 and batch: 1000, loss is 5.083071384429932 and perplexity is 161.26861396086304
At time: 1180.5914516448975 and batch: 1050, loss is 5.042684516906738 and perplexity is 154.88524949541872
At time: 1181.694531917572 and batch: 1100, loss is 5.042366943359375 and perplexity is 154.83606984679327
At time: 1182.7978932857513 and batch: 1150, loss is 5.054009876251221 and perplexity is 156.64935129066876
At time: 1183.901028394699 and batch: 1200, loss is 5.041381349563599 and perplexity is 154.6835395557914
At time: 1185.0041468143463 and batch: 1250, loss is 5.058584365844727 and perplexity is 157.36758363870393
At time: 1186.1072354316711 and batch: 1300, loss is 5.036447954177857 and perplexity is 153.92230377797063
At time: 1187.2107059955597 and batch: 1350, loss is 5.030537786483765 and perplexity is 153.01528012193612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.06033447265625 and perplexity of 157.64323485792414
Finished 37 epochs...
Completing Train Step...
At time: 1190.5906195640564 and batch: 50, loss is 5.114415187835693 and perplexity is 166.40343776775558
At time: 1191.7212948799133 and batch: 100, loss is 5.116989555358887 and perplexity is 166.83237325559472
At time: 1192.823520898819 and batch: 150, loss is 5.091353282928467 and perplexity is 162.60977024700315
At time: 1193.9251444339752 and batch: 200, loss is 5.0729884433746335 and perplexity is 159.65072229237384
At time: 1195.0269751548767 and batch: 250, loss is 5.097359266281128 and perplexity is 163.58934051688038
At time: 1196.129474401474 and batch: 300, loss is 5.102577075958252 and perplexity is 164.44514934303746
At time: 1197.2318873405457 and batch: 350, loss is 5.106557035446167 and perplexity is 165.10093851693355
At time: 1198.3333337306976 and batch: 400, loss is 5.137657270431519 and perplexity is 170.31629555410723
At time: 1199.463606595993 and batch: 450, loss is 5.102383613586426 and perplexity is 164.41333847161275
At time: 1200.5654833316803 and batch: 500, loss is 5.138596229553222 and perplexity is 170.47629069608658
At time: 1201.6672286987305 and batch: 550, loss is 5.123675937652588 and perplexity is 167.9516159545344
At time: 1202.7692031860352 and batch: 600, loss is 5.089414196014404 and perplexity is 162.2947612830027
At time: 1203.8715689182281 and batch: 650, loss is 5.097974834442138 and perplexity is 163.69007190672068
At time: 1204.9738101959229 and batch: 700, loss is 5.115343084335327 and perplexity is 166.55791459335666
At time: 1206.0759541988373 and batch: 750, loss is 5.099758224487305 and perplexity is 163.98225561276772
At time: 1207.1779913902283 and batch: 800, loss is 5.070288753509521 and perplexity is 159.22029612544733
At time: 1208.2805213928223 and batch: 850, loss is 5.043967456817627 and perplexity is 155.08408548364423
At time: 1209.3827016353607 and batch: 900, loss is 5.0785318374633786 and perplexity is 160.53818667240301
At time: 1210.4853761196136 and batch: 950, loss is 5.061201667785644 and perplexity is 157.7800015965286
At time: 1211.588178396225 and batch: 1000, loss is 5.0826075077056885 and perplexity is 161.19382255283344
At time: 1212.6899313926697 and batch: 1050, loss is 5.042163419723511 and perplexity is 154.80456025347735
At time: 1213.7913320064545 and batch: 1100, loss is 5.04188491821289 and perplexity is 154.7614529525987
At time: 1214.8932523727417 and batch: 1150, loss is 5.0535484886169435 and perplexity is 156.577091888145
At time: 1215.9952034950256 and batch: 1200, loss is 5.041003580093384 and perplexity is 154.62511587303908
At time: 1217.0975279808044 and batch: 1250, loss is 5.058210830688477 and perplexity is 157.30881229102644
At time: 1218.1996936798096 and batch: 1300, loss is 5.035964298248291 and perplexity is 153.84787634314193
At time: 1219.3019814491272 and batch: 1350, loss is 5.029931383132935 and perplexity is 152.92251927142973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.059979654947917 and perplexity of 157.58731016871928
Finished 38 epochs...
Completing Train Step...
At time: 1222.7290573120117 and batch: 50, loss is 5.113390626907349 and perplexity is 166.23303461618858
At time: 1223.8306012153625 and batch: 100, loss is 5.115977916717529 and perplexity is 166.6636845205878
At time: 1224.9331493377686 and batch: 150, loss is 5.0903465461730955 and perplexity is 162.44614739090414
At time: 1226.0346813201904 and batch: 200, loss is 5.07204831123352 and perplexity is 159.50070004841132
At time: 1227.1646733283997 and batch: 250, loss is 5.0963107776641845 and perplexity is 163.41790884327932
At time: 1228.2658908367157 and batch: 300, loss is 5.101298666000366 and perplexity is 164.23505534833228
At time: 1229.3685626983643 and batch: 350, loss is 5.105456619262696 and perplexity is 164.91935869729235
At time: 1230.4707114696503 and batch: 400, loss is 5.136742630004883 and perplexity is 170.16058860366928
At time: 1231.573234319687 and batch: 450, loss is 5.101224641799927 and perplexity is 164.22289842963477
At time: 1232.6754894256592 and batch: 500, loss is 5.137612314224243 and perplexity is 170.30863895152902
At time: 1233.7769565582275 and batch: 550, loss is 5.122920942306519 and perplexity is 167.82486112179936
At time: 1234.878324508667 and batch: 600, loss is 5.08877028465271 and perplexity is 162.19029148052508
At time: 1235.980253458023 and batch: 650, loss is 5.097219562530517 and perplexity is 163.5664880687738
At time: 1237.0818219184875 and batch: 700, loss is 5.114568424224854 and perplexity is 166.4289387834949
At time: 1238.1843266487122 and batch: 750, loss is 5.099032764434814 and perplexity is 163.86333617786863
At time: 1239.2861092090607 and batch: 800, loss is 5.069525232315064 and perplexity is 159.09877445285764
At time: 1240.3886799812317 and batch: 850, loss is 5.043323383331299 and perplexity is 154.98423209594446
At time: 1241.493836402893 and batch: 900, loss is 5.077925672531128 and perplexity is 160.44090354114525
At time: 1242.595849275589 and batch: 950, loss is 5.060536117553711 and perplexity is 157.67502601700718
At time: 1243.6982204914093 and batch: 1000, loss is 5.08211615562439 and perplexity is 161.1146390877029
At time: 1244.7999136447906 and batch: 1050, loss is 5.041419849395752 and perplexity is 154.6894949607415
At time: 1245.9017038345337 and batch: 1100, loss is 5.041360111236572 and perplexity is 154.6802543710787
At time: 1247.0038075447083 and batch: 1150, loss is 5.052796316146851 and perplexity is 156.45936319187223
At time: 1248.1058330535889 and batch: 1200, loss is 5.040458545684815 and perplexity is 154.54086282694956
At time: 1249.2076907157898 and batch: 1250, loss is 5.057726354598999 and perplexity is 157.2326183913588
At time: 1250.3100917339325 and batch: 1300, loss is 5.035392465591431 and perplexity is 153.75992625202412
At time: 1251.412106513977 and batch: 1350, loss is 5.029215250015259 and perplexity is 152.81304559448247
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.059521077473958 and perplexity of 157.51506074533938
Finished 39 epochs...
Completing Train Step...
At time: 1254.8150763511658 and batch: 50, loss is 5.112262907028199 and perplexity is 166.0456759823645
At time: 1255.9167125225067 and batch: 100, loss is 5.114959163665771 and perplexity is 166.49398184060405
At time: 1257.0180945396423 and batch: 150, loss is 5.089364748001099 and perplexity is 162.2867363278981
At time: 1258.1196784973145 and batch: 200, loss is 5.071227121353149 and perplexity is 159.36977345277472
At time: 1259.2218763828278 and batch: 250, loss is 5.095359535217285 and perplexity is 163.26253270370978
At time: 1260.3239657878876 and batch: 300, loss is 5.100028877258301 and perplexity is 164.02664387127507
At time: 1261.4260272979736 and batch: 350, loss is 5.104425897598267 and perplexity is 164.7494603154123
At time: 1262.527506828308 and batch: 400, loss is 5.135825757980347 and perplexity is 170.00464462156182
At time: 1263.6289193630219 and batch: 450, loss is 5.1001949214935305 and perplexity is 164.05388181120287
At time: 1264.7305619716644 and batch: 500, loss is 5.1367833614349365 and perplexity is 170.1675196289362
At time: 1265.8324930667877 and batch: 550, loss is 5.122270555496216 and perplexity is 167.71574553320093
At time: 1266.934844493866 and batch: 600, loss is 5.088084316253662 and perplexity is 162.07907221674844
At time: 1268.0369250774384 and batch: 650, loss is 5.096539249420166 and perplexity is 163.4552494853502
At time: 1269.1392192840576 and batch: 700, loss is 5.113874025344849 and perplexity is 166.313410830686
At time: 1270.2408592700958 and batch: 750, loss is 5.098395156860351 and perplexity is 163.75888897524715
At time: 1271.3429415225983 and batch: 800, loss is 5.06895432472229 and perplexity is 159.00796967755568
At time: 1272.4448523521423 and batch: 850, loss is 5.042714176177978 and perplexity is 154.88984334716937
At time: 1273.5477919578552 and batch: 900, loss is 5.077363834381104 and perplexity is 160.35078703852656
At time: 1274.6503291130066 and batch: 950, loss is 5.060025825500488 and perplexity is 157.59458622987663
At time: 1275.7526891231537 and batch: 1000, loss is 5.081650247573853 and perplexity is 161.0395919641796
At time: 1276.8544073104858 and batch: 1050, loss is 5.04087911605835 and perplexity is 154.60587180482196
At time: 1277.9560270309448 and batch: 1100, loss is 5.0409064197540285 and perplexity is 154.6100931741251
At time: 1279.05793094635 and batch: 1150, loss is 5.052341146469116 and perplexity is 156.38816383907212
At time: 1280.160474061966 and batch: 1200, loss is 5.0400485420227055 and perplexity is 154.4775134948615
At time: 1281.2625877857208 and batch: 1250, loss is 5.057276439666748 and perplexity is 157.1618929999056
At time: 1282.3656477928162 and batch: 1300, loss is 5.0349056434631345 and perplexity is 153.68509073475025
At time: 1283.467435836792 and batch: 1350, loss is 5.028532266616821 and perplexity is 152.70871245423373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.05911865234375 and perplexity of 157.4516854792644
Finished 40 epochs...
Completing Train Step...
At time: 1286.86318898201 and batch: 50, loss is 5.111277351379394 and perplexity is 165.88210934369252
At time: 1287.994755268097 and batch: 100, loss is 5.113894157409668 and perplexity is 166.31675909675673
At time: 1289.097799539566 and batch: 150, loss is 5.088309869766236 and perplexity is 162.11563384394836
At time: 1290.2058145999908 and batch: 200, loss is 5.070263195037842 and perplexity is 159.21622675002172
At time: 1291.313448190689 and batch: 250, loss is 5.094323320388794 and perplexity is 163.09344526696952
At time: 1292.4224808216095 and batch: 300, loss is 5.098876657485962 and perplexity is 163.83775796894923
At time: 1293.5306096076965 and batch: 350, loss is 5.1034579086303715 and perplexity is 164.59006181580125
At time: 1294.6393485069275 and batch: 400, loss is 5.134947204589844 and perplexity is 169.85535205497635
At time: 1295.7473015785217 and batch: 450, loss is 5.099243593215943 and perplexity is 163.89788692732483
At time: 1296.8559336662292 and batch: 500, loss is 5.135909061431885 and perplexity is 170.01880718512342
At time: 1297.9638476371765 and batch: 550, loss is 5.121661386489868 and perplexity is 167.61360941138403
At time: 1299.071876525879 and batch: 600, loss is 5.087519006729126 and perplexity is 161.98747326681521
At time: 1300.1800770759583 and batch: 650, loss is 5.095878438949585 and perplexity is 163.34727222520007
At time: 1301.2882471084595 and batch: 700, loss is 5.11315770149231 and perplexity is 166.19431922668147
At time: 1302.39697098732 and batch: 750, loss is 5.097680377960205 and perplexity is 163.64187939966587
At time: 1303.5060045719147 and batch: 800, loss is 5.068308143615723 and perplexity is 158.90525492149789
At time: 1304.6141633987427 and batch: 850, loss is 5.042079620361328 and perplexity is 154.79158827359456
At time: 1305.7221355438232 and batch: 900, loss is 5.076776723861695 and perplexity is 160.25667103561184
At time: 1306.8306279182434 and batch: 950, loss is 5.059485130310058 and perplexity is 157.50939862740324
At time: 1307.938927412033 and batch: 1000, loss is 5.081174983978271 and perplexity is 160.96307389323877
At time: 1309.0481131076813 and batch: 1050, loss is 5.040309371948243 and perplexity is 154.51781110838684
At time: 1310.1559195518494 and batch: 1100, loss is 5.040415086746216 and perplexity is 154.53414679101792
At time: 1311.290602684021 and batch: 1150, loss is 5.051873016357422 and perplexity is 156.31497096369756
At time: 1312.3939056396484 and batch: 1200, loss is 5.039604663848877 and perplexity is 154.40895951420728
At time: 1313.4975309371948 and batch: 1250, loss is 5.056746463775635 and perplexity is 157.07862305309513
At time: 1314.6008722782135 and batch: 1300, loss is 5.034387083053589 and perplexity is 153.60541639092332
At time: 1315.7047564983368 and batch: 1350, loss is 5.027797508239746 and perplexity is 152.5965496598281
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.058748779296875 and perplexity of 157.39345911346592
Finished 41 epochs...
Completing Train Step...
At time: 1319.0877060890198 and batch: 50, loss is 5.110227861404419 and perplexity is 165.7081090546588
At time: 1320.2197608947754 and batch: 100, loss is 5.1128389930725096 and perplexity is 166.14136013752307
At time: 1321.3235726356506 and batch: 150, loss is 5.087320966720581 and perplexity is 161.95539644257735
At time: 1322.4275648593903 and batch: 200, loss is 5.069377164840699 and perplexity is 159.07521884310268
At time: 1323.5313699245453 and batch: 250, loss is 5.093394193649292 and perplexity is 162.94198116150602
At time: 1324.6349623203278 and batch: 300, loss is 5.097601919174195 and perplexity is 163.62904076012634
At time: 1325.7380228042603 and batch: 350, loss is 5.102487621307373 and perplexity is 164.43043961755063
At time: 1326.8415458202362 and batch: 400, loss is 5.134077548980713 and perplexity is 169.70770060758124
At time: 1327.9449999332428 and batch: 450, loss is 5.098317680358886 and perplexity is 163.7462020009231
At time: 1329.0489628314972 and batch: 500, loss is 5.135085382461548 and perplexity is 169.87882392763015
At time: 1330.1533222198486 and batch: 550, loss is 5.121046848297119 and perplexity is 167.51063609053622
At time: 1331.2569134235382 and batch: 600, loss is 5.086890497207642 and perplexity is 161.88569458529145
At time: 1332.3607091903687 and batch: 650, loss is 5.095212125778199 and perplexity is 163.23846803906306
At time: 1333.4644417762756 and batch: 700, loss is 5.112453117370605 and perplexity is 166.07726259120284
At time: 1334.5684750080109 and batch: 750, loss is 5.09699462890625 and perplexity is 163.5297006033279
At time: 1335.6726396083832 and batch: 800, loss is 5.067679414749145 and perplexity is 158.80537800171928
At time: 1336.7766633033752 and batch: 850, loss is 5.041442804336548 and perplexity is 154.69304588969553
At time: 1337.8807199001312 and batch: 900, loss is 5.076181583404541 and perplexity is 160.16132418234892
At time: 1339.0294325351715 and batch: 950, loss is 5.058946046829224 and perplexity is 157.42451079539677
At time: 1340.1326768398285 and batch: 1000, loss is 5.0806698226928715 and perplexity is 160.88178211438748
At time: 1341.235806465149 and batch: 1050, loss is 5.039742345809937 and perplexity is 154.43022030613855
At time: 1342.3391723632812 and batch: 1100, loss is 5.039917650222779 and perplexity is 154.45729497831982
At time: 1343.442911863327 and batch: 1150, loss is 5.0513906574249265 and perplexity is 156.23958922316004
At time: 1344.5467460155487 and batch: 1200, loss is 5.039155168533325 and perplexity is 154.33956900674877
At time: 1345.6500709056854 and batch: 1250, loss is 5.056205730438233 and perplexity is 156.9937083651874
At time: 1346.7532441616058 and batch: 1300, loss is 5.033851671218872 and perplexity is 153.52319624589452
At time: 1347.8566455841064 and batch: 1350, loss is 5.0269671821594235 and perplexity is 152.46989735351147
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.058422037760416 and perplexity of 157.34204053355705
Finished 42 epochs...
Completing Train Step...
At time: 1351.2740788459778 and batch: 50, loss is 5.10918025970459 and perplexity is 165.53460385597623
At time: 1352.3831207752228 and batch: 100, loss is 5.111777305603027 and perplexity is 165.96506353980652
At time: 1353.4919865131378 and batch: 150, loss is 5.08632887840271 and perplexity is 161.79480206082744
At time: 1354.6001303195953 and batch: 200, loss is 5.068546371459961 and perplexity is 158.94311508730974
At time: 1355.7082786560059 and batch: 250, loss is 5.092474937438965 and perplexity is 162.79226455790206
At time: 1356.817291021347 and batch: 300, loss is 5.096361312866211 and perplexity is 163.42616740898987
At time: 1357.9272673130035 and batch: 350, loss is 5.1014225292205815 and perplexity is 164.25539929106714
At time: 1359.0355858802795 and batch: 400, loss is 5.133171329498291 and perplexity is 169.55397784677416
At time: 1360.1423819065094 and batch: 450, loss is 5.0973921966552735 and perplexity is 163.59472766376976
At time: 1361.2458679676056 and batch: 500, loss is 5.134237432479859 and perplexity is 169.73483623779833
At time: 1362.349660873413 and batch: 550, loss is 5.120416746139527 and perplexity is 167.40512052360012
At time: 1363.4529662132263 and batch: 600, loss is 5.086244382858276 and perplexity is 161.78113169849132
At time: 1364.5566568374634 and batch: 650, loss is 5.094560995101928 and perplexity is 163.13221306166722
At time: 1365.6598989963531 and batch: 700, loss is 5.111753015518189 and perplexity is 165.96103228329287
At time: 1366.7916905879974 and batch: 750, loss is 5.096305027008056 and perplexity is 163.41696908578248
At time: 1367.8944516181946 and batch: 800, loss is 5.067060804367065 and perplexity is 158.70716972561868
At time: 1368.9982368946075 and batch: 850, loss is 5.040820512771607 and perplexity is 154.59681165806418
At time: 1370.1010038852692 and batch: 900, loss is 5.075573472976685 and perplexity is 160.06395801866464
At time: 1371.2045135498047 and batch: 950, loss is 5.058448724746704 and perplexity is 157.34623957446485
At time: 1372.308156490326 and batch: 1000, loss is 5.080169639587402 and perplexity is 160.80133188659573
At time: 1373.4112164974213 and batch: 1050, loss is 5.039178428649902 and perplexity is 154.34315900486803
At time: 1374.5140872001648 and batch: 1100, loss is 5.039403419494629 and perplexity is 154.3778887093767
At time: 1375.6172580718994 and batch: 1150, loss is 5.050903043746948 and perplexity is 156.16342323371137
At time: 1376.720555305481 and batch: 1200, loss is 5.038692760467529 and perplexity is 154.26821764316296
At time: 1377.8235330581665 and batch: 1250, loss is 5.0556802082061765 and perplexity is 156.91122635611154
At time: 1378.927190542221 and batch: 1300, loss is 5.033358936309814 and perplexity is 153.4475686414646
At time: 1380.0306680202484 and batch: 1350, loss is 5.026143436431885 and perplexity is 152.34435264254697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.05817626953125 and perplexity of 157.3033756103812
Finished 43 epochs...
Completing Train Step...
At time: 1383.4369530677795 and batch: 50, loss is 5.108127202987671 and perplexity is 165.36037828030985
At time: 1384.5398848056793 and batch: 100, loss is 5.110774755477905 and perplexity is 165.79875862302586
At time: 1385.6434762477875 and batch: 150, loss is 5.085378770828247 and perplexity is 161.6411525971987
At time: 1386.7469592094421 and batch: 200, loss is 5.067805194854737 and perplexity is 158.82535381518645
At time: 1387.8502519130707 and batch: 250, loss is 5.091590995788574 and perplexity is 162.648429275262
At time: 1388.952760219574 and batch: 300, loss is 5.095168294906617 and perplexity is 163.2313133115333
At time: 1390.0563204288483 and batch: 350, loss is 5.100472793579102 and perplexity is 164.09947413961217
At time: 1391.15926527977 and batch: 400, loss is 5.132201280593872 and perplexity is 169.38958194524741
At time: 1392.262499332428 and batch: 450, loss is 5.096448020935059 and perplexity is 163.4403383907254
At time: 1393.3662095069885 and batch: 500, loss is 5.13338041305542 and perplexity is 169.5894325019513
At time: 1394.4692685604095 and batch: 550, loss is 5.119787902832031 and perplexity is 167.29988202664856
At time: 1395.61763048172 and batch: 600, loss is 5.085622663497925 and perplexity is 161.6805804973279
At time: 1396.7209544181824 and batch: 650, loss is 5.09391939163208 and perplexity is 163.02758043763953
At time: 1397.8240132331848 and batch: 700, loss is 5.111046447753906 and perplexity is 165.8438109850265
At time: 1398.927056312561 and batch: 750, loss is 5.095625133514404 and perplexity is 163.30590071335908
At time: 1400.0307173728943 and batch: 800, loss is 5.066452102661133 and perplexity is 158.61059379661134
At time: 1401.13436627388 and batch: 850, loss is 5.040153818130493 and perplexity is 154.4937771422947
At time: 1402.237378358841 and batch: 900, loss is 5.07494026184082 and perplexity is 159.96263582055417
At time: 1403.3403615951538 and batch: 950, loss is 5.057922849655151 and perplexity is 157.2635168591373
At time: 1404.443210363388 and batch: 1000, loss is 5.079642248153687 and perplexity is 160.71654900047776
At time: 1405.5463192462921 and batch: 1050, loss is 5.038595933914184 and perplexity is 154.25328110649625
At time: 1406.6493582725525 and batch: 1100, loss is 5.038871974945068 and perplexity is 154.29586721871686
At time: 1407.753140926361 and batch: 1150, loss is 5.050401477813721 and perplexity is 156.08511662020766
At time: 1408.8559465408325 and batch: 1200, loss is 5.038185472488403 and perplexity is 154.1899790772113
At time: 1409.960389137268 and batch: 1250, loss is 5.055164499282837 and perplexity is 156.83032669863815
At time: 1411.0634944438934 and batch: 1300, loss is 5.032927341461182 and perplexity is 153.38135575090283
At time: 1412.165777206421 and batch: 1350, loss is 5.025342655181885 and perplexity is 152.22240697382648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.057980550130209 and perplexity of 157.27259130056655
Finished 44 epochs...
Completing Train Step...
At time: 1415.5454335212708 and batch: 50, loss is 5.107266235351562 and perplexity is 165.2180696166834
At time: 1416.67555809021 and batch: 100, loss is 5.109900970458984 and perplexity is 165.6539494268519
At time: 1417.7765939235687 and batch: 150, loss is 5.084396867752075 and perplexity is 161.48251454856725
At time: 1418.878011226654 and batch: 200, loss is 5.06674488067627 and perplexity is 158.6570382900743
At time: 1419.9806995391846 and batch: 250, loss is 5.090563268661499 and perplexity is 162.48135693941092
At time: 1421.0831787586212 and batch: 300, loss is 5.093826751708985 and perplexity is 163.01247827466776
At time: 1422.1852533817291 and batch: 350, loss is 5.099554128646851 and perplexity is 163.94879093160617
At time: 1423.3147552013397 and batch: 400, loss is 5.131263818740845 and perplexity is 169.2308600833431
At time: 1424.416319847107 and batch: 450, loss is 5.095496311187744 and perplexity is 163.28486462226002
At time: 1425.5182311534882 and batch: 500, loss is 5.132580299377441 and perplexity is 169.45379594693327
At time: 1426.6194932460785 and batch: 550, loss is 5.119166650772095 and perplexity is 167.19597890866729
At time: 1427.7218968868256 and batch: 600, loss is 5.084968185424804 and perplexity is 161.57479872224505
At time: 1428.8238916397095 and batch: 650, loss is 5.093293447494506 and perplexity is 162.9255662103363
At time: 1429.9256358146667 and batch: 700, loss is 5.1103420829772945 and perplexity is 165.72703757651544
At time: 1431.026710987091 and batch: 750, loss is 5.094961900711059 and perplexity is 163.19762679240318
At time: 1432.128450870514 and batch: 800, loss is 5.065788593292236 and perplexity is 158.5053890876357
At time: 1433.2302722930908 and batch: 850, loss is 5.039463119506836 and perplexity is 154.38710534633103
At time: 1434.3318011760712 and batch: 900, loss is 5.074323015213013 and perplexity is 159.8639298891043
At time: 1435.4336984157562 and batch: 950, loss is 5.057385272979737 and perplexity is 157.17899838019702
At time: 1436.535317182541 and batch: 1000, loss is 5.079097194671631 and perplexity is 160.62897375458547
At time: 1437.6365523338318 and batch: 1050, loss is 5.038036460876465 and perplexity is 154.16700469165184
At time: 1438.7373445034027 and batch: 1100, loss is 5.038335428237915 and perplexity is 154.21310248479165
At time: 1439.8393197059631 and batch: 1150, loss is 5.0498940372467045 and perplexity is 156.00593279236944
At time: 1440.9410424232483 and batch: 1200, loss is 5.0376731300354 and perplexity is 154.1110012386797
At time: 1442.043307542801 and batch: 1250, loss is 5.054685935974121 and perplexity is 156.7552914145853
At time: 1443.1451563835144 and batch: 1300, loss is 5.0325134754180905 and perplexity is 153.31788955027275
At time: 1444.247498035431 and batch: 1350, loss is 5.024556722640991 and perplexity is 152.10281743154474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.057653401692709 and perplexity of 157.22114823327934
Finished 45 epochs...
Completing Train Step...
At time: 1447.6199355125427 and batch: 50, loss is 5.106344299316406 and perplexity is 165.06581931794722
At time: 1448.7531118392944 and batch: 100, loss is 5.108978271484375 and perplexity is 165.50117119257516
At time: 1449.8545546531677 and batch: 150, loss is 5.0832315444946286 and perplexity is 161.29444482098947
At time: 1450.983897447586 and batch: 200, loss is 5.065760478973389 and perplexity is 158.50093287922982
At time: 1452.0856697559357 and batch: 250, loss is 5.089542541503906 and perplexity is 162.31559242034587
At time: 1453.187476158142 and batch: 300, loss is 5.092569274902344 and perplexity is 162.80762269161045
At time: 1454.289161682129 and batch: 350, loss is 5.098612871170044 and perplexity is 163.7945455100445
At time: 1455.390737771988 and batch: 400, loss is 5.130337495803833 and perplexity is 169.0741702398999
At time: 1456.4921875 and batch: 450, loss is 5.0945263671875 and perplexity is 163.12656423115698
At time: 1457.5932655334473 and batch: 500, loss is 5.131782073974609 and perplexity is 169.31858759295267
At time: 1458.6945116519928 and batch: 550, loss is 5.118553743362427 and perplexity is 167.0935346519565
At time: 1459.7957048416138 and batch: 600, loss is 5.084331111907959 and perplexity is 161.47189647861697
At time: 1460.8973314762115 and batch: 650, loss is 5.092674560546875 and perplexity is 162.82476489949855
At time: 1461.998543024063 and batch: 700, loss is 5.109619436264038 and perplexity is 165.6073187399348
At time: 1463.1004786491394 and batch: 750, loss is 5.094310121536255 and perplexity is 163.09129263484155
At time: 1464.2023327350616 and batch: 800, loss is 5.065104141235351 and perplexity is 158.39693686745383
At time: 1465.3038394451141 and batch: 850, loss is 5.038757028579712 and perplexity is 154.27813248888154
At time: 1466.4049134254456 and batch: 900, loss is 5.0736857032775875 and perplexity is 159.76207915733286
At time: 1467.5064232349396 and batch: 950, loss is 5.056840057373047 and perplexity is 157.09332529451024
At time: 1468.6080396175385 and batch: 1000, loss is 5.078497657775879 and perplexity is 160.53269962112415
At time: 1469.7105648517609 and batch: 1050, loss is 5.037458515167236 and perplexity is 154.07793027535337
At time: 1470.8117880821228 and batch: 1100, loss is 5.037825698852539 and perplexity is 154.13451556557771
At time: 1471.9135248661041 and batch: 1150, loss is 5.0493870544433594 and perplexity is 155.9268605130605
At time: 1473.0142772197723 and batch: 1200, loss is 5.037118711471558 and perplexity is 154.0255829196395
At time: 1474.1159386634827 and batch: 1250, loss is 5.054190702438355 and perplexity is 156.67768015680292
At time: 1475.217612504959 and batch: 1300, loss is 5.0320616054534915 and perplexity is 153.24862545131083
At time: 1476.3194806575775 and batch: 1350, loss is 5.023738145828247 and perplexity is 151.97836053775552
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.057277018229167 and perplexity of 157.16198392789678
Finished 46 epochs...
Completing Train Step...
At time: 1479.740229845047 and batch: 50, loss is 5.105323324203491 and perplexity is 164.89737722665407
At time: 1480.841099023819 and batch: 100, loss is 5.107944211959839 and perplexity is 165.33012158316214
At time: 1481.9426419734955 and batch: 150, loss is 5.08209264755249 and perplexity is 161.11085163770113
At time: 1483.0442299842834 and batch: 200, loss is 5.064788980484009 and perplexity is 158.34702423548475
At time: 1484.1456401348114 and batch: 250, loss is 5.08855414390564 and perplexity is 162.15523933799156
At time: 1485.247341632843 and batch: 300, loss is 5.0913939285278325 and perplexity is 162.61637975290026
At time: 1486.352293252945 and batch: 350, loss is 5.097706499099732 and perplexity is 163.64615396785817
At time: 1487.4538927078247 and batch: 400, loss is 5.129351835250855 and perplexity is 168.90760260282704
At time: 1488.5555481910706 and batch: 450, loss is 5.093561325073242 and perplexity is 162.96921616268767
At time: 1489.6572289466858 and batch: 500, loss is 5.130985708236694 and perplexity is 169.18380174753955
At time: 1490.7591996192932 and batch: 550, loss is 5.117901287078857 and perplexity is 166.98454898338738
At time: 1491.8607153892517 and batch: 600, loss is 5.0836422157287595 and perplexity is 161.36069741278826
At time: 1492.962984085083 and batch: 650, loss is 5.092027158737182 and perplexity is 162.7193859669762
At time: 1494.0648212432861 and batch: 700, loss is 5.108797826766968 and perplexity is 165.47131007473027
At time: 1495.1663389205933 and batch: 750, loss is 5.093650112152099 and perplexity is 162.98368636570842
At time: 1496.2679269313812 and batch: 800, loss is 5.064395370483399 and perplexity is 158.28470952782945
At time: 1497.3696365356445 and batch: 850, loss is 5.038035230636597 and perplexity is 154.16681502937297
At time: 1498.471433877945 and batch: 900, loss is 5.073004331588745 and perplexity is 159.65325887738354
At time: 1499.5731987953186 and batch: 950, loss is 5.056268148422241 and perplexity is 157.00350790179596
At time: 1500.67485165596 and batch: 1000, loss is 5.077875232696533 and perplexity is 160.4328111325999
At time: 1501.7759630680084 and batch: 1050, loss is 5.0368718338012695 and perplexity is 153.98756213599788
At time: 1502.8768346309662 and batch: 1100, loss is 5.037299528121948 and perplexity is 154.0534358276763
At time: 1503.9784598350525 and batch: 1150, loss is 5.04890733718872 and perplexity is 155.85207764636056
At time: 1505.0805666446686 and batch: 1200, loss is 5.036534719467163 and perplexity is 153.93565947058548
At time: 1506.1823329925537 and batch: 1250, loss is 5.05362135887146 and perplexity is 156.58850211641044
At time: 1507.284249305725 and batch: 1300, loss is 5.031559925079346 and perplexity is 153.17176290538464
At time: 1508.386015176773 and batch: 1350, loss is 5.022873077392578 and perplexity is 151.8469457047569
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0568994140625 and perplexity of 157.10265011097732
Finished 47 epochs...
Completing Train Step...
At time: 1511.7983779907227 and batch: 50, loss is 5.104231185913086 and perplexity is 164.71738479320254
At time: 1512.9021394252777 and batch: 100, loss is 5.106895132064819 and perplexity is 165.15676802333422
At time: 1514.0061926841736 and batch: 150, loss is 5.080921173095703 and perplexity is 160.9222248975722
At time: 1515.1093232631683 and batch: 200, loss is 5.063780717849731 and perplexity is 158.18744930793605
At time: 1516.2126846313477 and batch: 250, loss is 5.087547445297242 and perplexity is 161.99208002411206
At time: 1517.3160095214844 and batch: 300, loss is 5.090199823379517 and perplexity is 162.42231458680342
At time: 1518.4195244312286 and batch: 350, loss is 5.096827211380005 and perplexity is 163.50232515701404
At time: 1519.5231394767761 and batch: 400, loss is 5.12834942817688 and perplexity is 168.73837325964556
At time: 1520.6268148422241 and batch: 450, loss is 5.0925130271911625 and perplexity is 162.79846539301215
At time: 1521.7302558422089 and batch: 500, loss is 5.130111618041992 and perplexity is 169.03598445756296
At time: 1522.8331909179688 and batch: 550, loss is 5.1172398090362545 and perplexity is 166.8741288950391
At time: 1523.936645269394 and batch: 600, loss is 5.082945098876953 and perplexity is 161.24824935067602
At time: 1525.03995013237 and batch: 650, loss is 5.091343688964844 and perplexity is 162.6082101822662
At time: 1526.1439006328583 and batch: 700, loss is 5.108078937530518 and perplexity is 165.35239727866207
At time: 1527.247142791748 and batch: 750, loss is 5.093023653030396 and perplexity is 162.88161572357626
At time: 1528.3502366542816 and batch: 800, loss is 5.063581752777099 and perplexity is 158.15597866147863
At time: 1529.4566054344177 and batch: 850, loss is 5.037228689193726 and perplexity is 154.04252323391617
At time: 1530.565330505371 and batch: 900, loss is 5.072326650619507 and perplexity is 159.54510155438453
At time: 1531.672706604004 and batch: 950, loss is 5.055694065093994 and perplexity is 156.91340067243706
At time: 1532.7808673381805 and batch: 1000, loss is 5.077137317657471 and perplexity is 160.31446901708946
At time: 1533.888860464096 and batch: 1050, loss is 5.036226329803466 and perplexity is 153.88819462354076
At time: 1535.040679216385 and batch: 1100, loss is 5.036686191558838 and perplexity is 153.95897819293208
At time: 1536.1485149860382 and batch: 1150, loss is 5.04833643913269 and perplexity is 155.76312739138373
At time: 1537.2561616897583 and batch: 1200, loss is 5.035951538085937 and perplexity is 153.8459132317869
At time: 1538.3648064136505 and batch: 1250, loss is 5.052872982025146 and perplexity is 156.4713587461879
At time: 1539.473639011383 and batch: 1300, loss is 5.030926752090454 and perplexity is 153.07480937986784
At time: 1540.58416223526 and batch: 1350, loss is 5.021983995437622 and perplexity is 151.71200132261217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.056420084635417 and perplexity of 157.0273642325163
Finished 48 epochs...
Completing Train Step...
At time: 1544.0163922309875 and batch: 50, loss is 5.103069171905518 and perplexity is 164.52609204873198
At time: 1545.1556508541107 and batch: 100, loss is 5.10577314376831 and perplexity is 164.9715679780928
At time: 1546.2649779319763 and batch: 150, loss is 5.07983883857727 and perplexity is 160.7481474407963
At time: 1547.374022245407 and batch: 200, loss is 5.062693157196045 and perplexity is 158.01550437937908
At time: 1548.4827017784119 and batch: 250, loss is 5.086507196426392 and perplexity is 161.8236555626462
At time: 1549.5919268131256 and batch: 300, loss is 5.08893087387085 and perplexity is 162.21633958409018
At time: 1550.7007946968079 and batch: 350, loss is 5.095904359817505 and perplexity is 163.35150638314477
At time: 1551.8102338314056 and batch: 400, loss is 5.127296075820923 and perplexity is 168.56072587570318
At time: 1552.91992521286 and batch: 450, loss is 5.0911554336547855 and perplexity is 162.57760120448205
At time: 1554.0289196968079 and batch: 500, loss is 5.129198579788208 and perplexity is 168.88171857353072
At time: 1555.1383695602417 and batch: 550, loss is 5.116462688446045 and perplexity is 166.74449794946386
At time: 1556.2480084896088 and batch: 600, loss is 5.08214861869812 and perplexity is 161.119869449007
At time: 1557.356594800949 and batch: 650, loss is 5.090643758773804 and perplexity is 162.49443560842315
At time: 1558.46657705307 and batch: 700, loss is 5.107332067489624 and perplexity is 165.22894663347742
At time: 1559.5758402347565 and batch: 750, loss is 5.092361297607422 and perplexity is 162.7737659234919
At time: 1560.6846764087677 and batch: 800, loss is 5.06277753829956 and perplexity is 158.0288384645756
At time: 1561.7941710948944 and batch: 850, loss is 5.036447668075562 and perplexity is 153.9222597404526
At time: 1562.9328825473785 and batch: 900, loss is 5.071622467041015 and perplexity is 159.4327920617323
At time: 1564.0416717529297 and batch: 950, loss is 5.055108098983765 and perplexity is 156.82148167074223
At time: 1565.150181055069 and batch: 1000, loss is 5.0763771533966064 and perplexity is 160.19264999434304
At time: 1566.2590289115906 and batch: 1050, loss is 5.035552988052368 and perplexity is 153.784610154887
At time: 1567.3666961193085 and batch: 1100, loss is 5.035971889495849 and perplexity is 153.8490442448905
At time: 1568.4705746173859 and batch: 1150, loss is 5.0477457523345945 and perplexity is 155.67114733677994
At time: 1569.573976278305 and batch: 1200, loss is 5.035307941436767 and perplexity is 153.74693037347706
At time: 1570.6775999069214 and batch: 1250, loss is 5.052213668823242 and perplexity is 156.3682291147462
At time: 1571.7810685634613 and batch: 1300, loss is 5.030196704864502 and perplexity is 152.96309832205242
At time: 1572.8848412036896 and batch: 1350, loss is 5.021075706481934 and perplexity is 151.57426554877586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.055916341145833 and perplexity of 156.9482826401886
Finished 49 epochs...
Completing Train Step...
At time: 1576.2900655269623 and batch: 50, loss is 5.10188307762146 and perplexity is 164.3310642749026
At time: 1577.4211122989655 and batch: 100, loss is 5.104824810028076 and perplexity is 164.8151940330634
At time: 1578.5235900878906 and batch: 150, loss is 5.078854265213013 and perplexity is 160.5899569843063
At time: 1579.6263036727905 and batch: 200, loss is 5.061914749145508 and perplexity is 157.8925516985471
At time: 1580.7295897006989 and batch: 250, loss is 5.0855823802948 and perplexity is 161.67406761684305
At time: 1581.8325498104095 and batch: 300, loss is 5.08773663520813 and perplexity is 162.02273019055616
At time: 1582.9356832504272 and batch: 350, loss is 5.09503095626831 and perplexity is 163.20889688459016
At time: 1584.0386946201324 and batch: 400, loss is 5.126259918212891 and perplexity is 168.38616085122877
At time: 1585.1413066387177 and batch: 450, loss is 5.090014200210572 and perplexity is 162.39216804009774
At time: 1586.2437074184418 and batch: 500, loss is 5.128249073028565 and perplexity is 168.72144034483748
At time: 1587.3474736213684 and batch: 550, loss is 5.115536241531372 and perplexity is 166.5900895604318
At time: 1588.4506840705872 and batch: 600, loss is 5.081284494400024 and perplexity is 160.98070199256017
At time: 1589.554945230484 and batch: 650, loss is 5.089877700805664 and perplexity is 162.37000311858228
At time: 1590.6576187610626 and batch: 700, loss is 5.106426954269409 and perplexity is 165.0794633893526
At time: 1591.7880592346191 and batch: 750, loss is 5.0914501953125 and perplexity is 162.6255299111459
At time: 1592.890433549881 and batch: 800, loss is 5.061957416534423 and perplexity is 157.89928870518148
At time: 1593.993150472641 and batch: 850, loss is 5.0356046581268314 and perplexity is 153.79255642243538
At time: 1595.0960249900818 and batch: 900, loss is 5.070643329620362 and perplexity is 159.2767618489211
At time: 1596.1989703178406 and batch: 950, loss is 5.054439544677734 and perplexity is 156.71667303293003
At time: 1597.3019506931305 and batch: 1000, loss is 5.075537204742432 and perplexity is 160.0581528868113
At time: 1598.403754234314 and batch: 1050, loss is 5.0347143650054935 and perplexity is 153.6556968989255
At time: 1599.5057663917542 and batch: 1100, loss is 5.035061721801758 and perplexity is 153.7090795203995
At time: 1600.6089689731598 and batch: 1150, loss is 5.046780261993408 and perplexity is 155.52092088039097
At time: 1601.7113301753998 and batch: 1200, loss is 5.034464845657348 and perplexity is 153.61736161249326
At time: 1602.8142502307892 and batch: 1250, loss is 5.051479234695434 and perplexity is 156.25342911245943
At time: 1603.9167540073395 and batch: 1300, loss is 5.029208545684814 and perplexity is 152.81202108876286
At time: 1605.0195360183716 and batch: 1350, loss is 5.01994776725769 and perplexity is 151.40339537298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.055161539713541 and perplexity of 156.82986254910548
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2f1671c50>
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 2.0072738283834246, 'wordvec_source': 'glove', 'dropout': 0.6409472178020267, 'data': 'wikitext', 'lr': 23.191200163761625, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.572312593460083 and batch: 50, loss is 7.380051145553589 and perplexity is 1603.6717864163454
At time: 2.5874781608581543 and batch: 100, loss is 6.562796649932861 and perplexity is 708.2496538232325
At time: 3.602501153945923 and batch: 150, loss is 6.471629829406738 and perplexity is 646.536613104167
At time: 4.620896100997925 and batch: 200, loss is 6.499560480117798 and perplexity is 664.8493543080214
At time: 5.6395039558410645 and batch: 250, loss is 6.575707664489746 and perplexity is 717.453160873078
At time: 6.658482551574707 and batch: 300, loss is 6.628315067291259 and perplexity is 756.2069387978282
At time: 7.676266193389893 and batch: 350, loss is 6.675300626754761 and perplexity is 792.5856905275248
At time: 8.72041630744934 and batch: 400, loss is 6.748019695281982 and perplexity is 852.3691394656856
At time: 9.73468542098999 and batch: 450, loss is 6.782132339477539 and perplexity is 881.9473315938026
At time: 10.745347261428833 and batch: 500, loss is 6.968376998901367 and perplexity is 1062.4969167386935
At time: 11.759376287460327 and batch: 550, loss is 7.151965599060059 and perplexity is 1276.6127995597267
At time: 12.774576425552368 and batch: 600, loss is 6.868884353637696 and perplexity is 961.8748547997393
At time: 13.788792371749878 and batch: 650, loss is 6.926123876571655 and perplexity is 1018.5383379830666
At time: 14.80431318283081 and batch: 700, loss is 7.042490158081055 and perplexity is 1144.2333839483967
At time: 15.816812753677368 and batch: 750, loss is 6.830556154251099 and perplexity is 925.7055043932777
At time: 16.833826303482056 and batch: 800, loss is 6.943300361633301 and perplexity is 1036.1843610131755
At time: 17.85016679763794 and batch: 850, loss is 6.91413722038269 and perplexity is 1006.4023493796499
At time: 18.868122816085815 and batch: 900, loss is 7.066235618591309 and perplexity is 1171.7288873508735
At time: 19.887444734573364 and batch: 950, loss is 6.990107412338257 and perplexity is 1085.8381023318047
At time: 20.90368342399597 and batch: 1000, loss is 7.010316238403321 and perplexity is 1108.0048431850544
At time: 21.923400163650513 and batch: 1050, loss is 7.179322662353516 and perplexity is 1312.0192771601378
At time: 22.94390058517456 and batch: 1100, loss is 7.217257061004639 and perplexity is 1362.7460004167228
At time: 23.963348865509033 and batch: 1150, loss is 7.0017531299591065 and perplexity is 1098.557385089516
At time: 24.982431888580322 and batch: 1200, loss is 6.996114740371704 and perplexity is 1092.3807201536388
At time: 26.00168752670288 and batch: 1250, loss is 6.992138557434082 and perplexity is 1088.045838425375
At time: 27.02172875404358 and batch: 1300, loss is 6.883854494094849 and perplexity is 976.3825768599028
At time: 28.04170560836792 and batch: 1350, loss is 7.0886439037323 and perplexity is 1198.2817129357597
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.364049886067709 and perplexity of 580.5929367404144
Finished 1 epochs...
Completing Train Step...
At time: 31.24233889579773 and batch: 50, loss is 6.888122606277466 and perplexity is 980.5587931711844
At time: 32.25522565841675 and batch: 100, loss is 6.906137237548828 and perplexity is 998.3832668899952
At time: 33.26991868019104 and batch: 150, loss is 6.659696578979492 and perplexity is 780.3141374917129
At time: 34.284406661987305 and batch: 200, loss is 6.817703304290771 and perplexity is 913.8836852143551
At time: 35.30222678184509 and batch: 250, loss is 6.991231126785278 and perplexity is 1087.0589601138167
At time: 36.31946420669556 and batch: 300, loss is 7.1525938510894775 and perplexity is 1277.4150861345277
At time: 37.3378791809082 and batch: 350, loss is 7.043456048965454 and perplexity is 1145.3391224689901
At time: 38.36966252326965 and batch: 400, loss is 7.134098682403565 and perplexity is 1254.0062213736487
At time: 39.43729090690613 and batch: 450, loss is 7.106572675704956 and perplexity is 1219.959177015751
At time: 40.53048872947693 and batch: 500, loss is 7.047128582000733 and perplexity is 1149.5531515770188
At time: 41.653082847595215 and batch: 550, loss is 6.971177253723145 and perplexity is 1065.4763484900627
At time: 42.746747970581055 and batch: 600, loss is 6.8506083583831785 and perplexity is 944.4552992344244
At time: 43.8392071723938 and batch: 650, loss is 6.849503431320191 and perplexity is 943.4123213278866
At time: 44.93289232254028 and batch: 700, loss is 6.836035480499268 and perplexity is 930.7916685126962
At time: 46.026525020599365 and batch: 750, loss is 6.831036186218261 and perplexity is 926.1499793001118
At time: 47.12107586860657 and batch: 800, loss is 6.8884620857238765 and perplexity is 980.8917292367416
At time: 48.21545457839966 and batch: 850, loss is 6.836437206268311 and perplexity is 931.1656666288591
At time: 49.309470891952515 and batch: 900, loss is 6.860717821121216 and perplexity is 954.0516601866528
At time: 50.40275859832764 and batch: 950, loss is 6.755373363494873 and perplexity is 858.6602824511302
At time: 51.49745488166809 and batch: 1000, loss is 6.88894811630249 and perplexity is 981.3685884861613
At time: 52.59151530265808 and batch: 1050, loss is 6.8290087890625 and perplexity is 924.2742075759041
At time: 53.684972524642944 and batch: 1100, loss is 6.714258604049682 and perplexity is 824.0725762875337
At time: 54.77997088432312 and batch: 1150, loss is 6.90644172668457 and perplexity is 998.6873100346384
At time: 55.874085426330566 and batch: 1200, loss is 6.833647289276123 and perplexity is 928.5714122728717
At time: 56.96873664855957 and batch: 1250, loss is 6.905770387649536 and perplexity is 998.0170772615029
At time: 58.06162166595459 and batch: 1300, loss is 6.777223119735718 and perplexity is 877.628268631149
At time: 59.15550422668457 and batch: 1350, loss is 6.856634531021118 and perplexity is 950.1639332478466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 7.309058430989583 and perplexity of 1493.7700392533734
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 62.5604989528656 and batch: 50, loss is 6.493037414550781 and perplexity is 660.5266124697515
At time: 63.644349336624146 and batch: 100, loss is 6.452079944610595 and perplexity is 634.0196480743633
At time: 64.74234747886658 and batch: 150, loss is 6.4176160430908205 and perplexity is 612.5411005404837
At time: 65.8437168598175 and batch: 200, loss is 6.436167736053466 and perplexity is 624.0108375289512
At time: 66.94647574424744 and batch: 250, loss is 6.46325984954834 and perplexity is 641.1476986880275
At time: 68.04999828338623 and batch: 300, loss is 6.489440536499023 and perplexity is 658.1550464684564
At time: 69.18139362335205 and batch: 350, loss is 6.520741100311279 and perplexity is 679.0814663857795
At time: 70.28229665756226 and batch: 400, loss is 6.567333154678344 and perplexity is 711.4699306165267
At time: 71.38288569450378 and batch: 450, loss is 6.5176347064971925 and perplexity is 676.9752449895929
At time: 72.48428058624268 and batch: 500, loss is 6.5228471755981445 and perplexity is 680.5131701887017
At time: 73.58617949485779 and batch: 550, loss is 6.500715045928955 and perplexity is 665.6174099421441
At time: 74.6884913444519 and batch: 600, loss is 6.443561840057373 and perplexity is 628.6419388841645
At time: 75.79091715812683 and batch: 650, loss is 6.464348649978637 and perplexity is 641.8461607521398
At time: 76.89209079742432 and batch: 700, loss is 6.464403686523437 and perplexity is 641.8814867192212
At time: 77.99283504486084 and batch: 750, loss is 6.424708995819092 and perplexity is 616.901270570707
At time: 79.09546637535095 and batch: 800, loss is 6.377248678207398 and perplexity is 588.3068574630161
At time: 80.19637775421143 and batch: 850, loss is 6.401321640014649 and perplexity is 602.6409862194853
At time: 81.29290175437927 and batch: 900, loss is 6.451653099060058 and perplexity is 633.7490773586908
At time: 82.38976454734802 and batch: 950, loss is 6.398840360641479 and perplexity is 601.1475191916592
At time: 83.48559165000916 and batch: 1000, loss is 6.4110704517364505 and perplexity is 608.54475031488
At time: 84.58223152160645 and batch: 1050, loss is 6.394520778656005 and perplexity is 598.5564134728459
At time: 85.68013167381287 and batch: 1100, loss is 6.401231441497803 and perplexity is 602.5866313477391
At time: 86.77623796463013 and batch: 1150, loss is 6.419845561981202 and perplexity is 613.9082960230186
At time: 87.87385511398315 and batch: 1200, loss is 6.411155271530151 and perplexity is 608.5963691441776
At time: 88.97067070007324 and batch: 1250, loss is 6.392714052200318 and perplexity is 597.4759620993494
At time: 90.07454347610474 and batch: 1300, loss is 6.36459979057312 and perplexity is 580.9122952124216
At time: 91.17254519462585 and batch: 1350, loss is 6.382982053756714 and perplexity is 591.6895294132682
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.028806559244791 and perplexity of 415.2191940572624
Finished 3 epochs...
Completing Train Step...
At time: 94.55442905426025 and batch: 50, loss is 6.4116457748413085 and perplexity is 608.8949609025376
At time: 95.63685846328735 and batch: 100, loss is 6.408196573257446 and perplexity is 606.798377287336
At time: 96.76140999794006 and batch: 150, loss is 6.366030216217041 and perplexity is 581.7438416472479
At time: 97.85988807678223 and batch: 200, loss is 6.369628639221191 and perplexity is 583.8409729894688
At time: 98.95846629142761 and batch: 250, loss is 6.388196668624878 and perplexity is 594.7830211046652
At time: 100.05585885047913 and batch: 300, loss is 6.406203117370605 and perplexity is 605.589956357091
At time: 101.15410661697388 and batch: 350, loss is 6.406944236755371 and perplexity is 606.0389371666067
At time: 102.25165271759033 and batch: 400, loss is 6.468635559082031 and perplexity is 644.6036031311374
At time: 103.34992218017578 and batch: 450, loss is 6.43395586013794 and perplexity is 622.6321283153445
At time: 104.44645500183105 and batch: 500, loss is 6.4297528743743895 and perplexity is 620.0207060736079
At time: 105.54444527626038 and batch: 550, loss is 6.364884729385376 and perplexity is 581.0778432562557
At time: 106.64178013801575 and batch: 600, loss is 6.333728199005127 and perplexity is 563.2526020479647
At time: 107.73888111114502 and batch: 650, loss is 6.381500129699707 and perplexity is 590.8133398488984
At time: 108.83661913871765 and batch: 700, loss is 6.386676683425903 and perplexity is 593.8796464479645
At time: 109.93356275558472 and batch: 750, loss is 6.340349435806274 and perplexity is 566.9944049161281
At time: 111.03157329559326 and batch: 800, loss is 6.30589093208313 and perplexity is 547.7894140065105
At time: 112.1290123462677 and batch: 850, loss is 6.334176940917969 and perplexity is 563.505413817397
At time: 113.22508931159973 and batch: 900, loss is 6.3844450664520265 and perplexity is 592.555812243356
At time: 114.32200741767883 and batch: 950, loss is 6.339180307388306 and perplexity is 566.3319029948854
At time: 115.4180064201355 and batch: 1000, loss is 6.340984735488892 and perplexity is 567.3547307269347
At time: 116.5145435333252 and batch: 1050, loss is 6.330497074127197 and perplexity is 561.4355996146289
At time: 117.61181664466858 and batch: 1100, loss is 6.308341455459595 and perplexity is 549.1334308707101
At time: 118.70993947982788 and batch: 1150, loss is 6.316764459609986 and perplexity is 553.7783185303659
At time: 119.80851912498474 and batch: 1200, loss is 6.322133293151856 and perplexity is 556.7594576005833
At time: 120.90673851966858 and batch: 1250, loss is 6.321025447845459 and perplexity is 556.1429957839034
At time: 122.00451588630676 and batch: 1300, loss is 6.276842298507691 and perplexity is 532.105776990706
At time: 123.10215973854065 and batch: 1350, loss is 6.316732759475708 and perplexity is 553.7607639615511
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.968863118489583 and perplexity of 391.06082810619097
Finished 4 epochs...
Completing Train Step...
At time: 126.49652457237244 and batch: 50, loss is 6.316374826431274 and perplexity is 553.5625901540112
At time: 127.62753653526306 and batch: 100, loss is 6.342201461791992 and perplexity is 568.0454662838439
At time: 128.72994256019592 and batch: 150, loss is 6.316187753677368 and perplexity is 553.4590433615053
At time: 129.8349688053131 and batch: 200, loss is 6.313345851898194 and perplexity is 551.8883999856744
At time: 130.93807649612427 and batch: 250, loss is 6.345292949676514 and perplexity is 569.8042892498638
At time: 132.0410463809967 and batch: 300, loss is 6.363225107192993 and perplexity is 580.1142733742328
At time: 133.14440417289734 and batch: 350, loss is 6.360053062438965 and perplexity is 578.2770403697954
At time: 134.24847435951233 and batch: 400, loss is 6.399780406951904 and perplexity is 601.7128913954891
At time: 135.35185074806213 and batch: 450, loss is 6.385475168228149 and perplexity is 593.1665195293274
At time: 136.45501399040222 and batch: 500, loss is 6.380894622802734 and perplexity is 590.4557065824281
At time: 137.55828428268433 and batch: 550, loss is 6.335443925857544 and perplexity is 564.2198191649143
At time: 138.66097617149353 and batch: 600, loss is 6.2916687393188475 and perplexity is 540.0537865492041
At time: 139.76450991630554 and batch: 650, loss is 6.33167724609375 and perplexity is 562.0985813095739
At time: 140.8714725971222 and batch: 700, loss is 6.35326319694519 and perplexity is 574.3639168722964
At time: 141.96779322624207 and batch: 750, loss is 6.321130018234253 and perplexity is 556.2011549140061
At time: 143.06428050994873 and batch: 800, loss is 6.267452373504638 and perplexity is 527.1327284671157
At time: 144.16268038749695 and batch: 850, loss is 6.278351573944092 and perplexity is 532.9094775196552
At time: 145.2615625858307 and batch: 900, loss is 6.331783018112183 and perplexity is 562.1580387554887
At time: 146.35866165161133 and batch: 950, loss is 6.298529272079468 and perplexity is 543.7715816899193
At time: 147.45635199546814 and batch: 1000, loss is 6.305884971618652 and perplexity is 547.7861489368978
At time: 148.55440711975098 and batch: 1050, loss is 6.298222494125366 and perplexity is 543.6047901418831
At time: 149.6514391899109 and batch: 1100, loss is 6.282140302658081 and perplexity is 534.9323566093584
At time: 150.74966478347778 and batch: 1150, loss is 6.296140947341919 and perplexity is 542.4744281982701
At time: 151.87636280059814 and batch: 1200, loss is 6.31160159111023 and perplexity is 550.926601747575
At time: 152.97570991516113 and batch: 1250, loss is 6.304559326171875 and perplexity is 547.0604598322539
At time: 154.07335090637207 and batch: 1300, loss is 6.268779935836792 and perplexity is 527.8329947421919
At time: 155.17164373397827 and batch: 1350, loss is 6.286778841018677 and perplexity is 537.4194245866047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.954968668619792 and perplexity of 385.66482707739334
Finished 5 epochs...
Completing Train Step...
At time: 158.54228329658508 and batch: 50, loss is 6.327592687606812 and perplexity is 559.8073393202627
At time: 159.66926527023315 and batch: 100, loss is 6.334453592300415 and perplexity is 563.6613299353559
At time: 160.76834559440613 and batch: 150, loss is 6.287433023452759 and perplexity is 537.7711099545566
At time: 161.86895561218262 and batch: 200, loss is 6.294092931747437 and perplexity is 541.3645690021126
At time: 162.96858429908752 and batch: 250, loss is 6.327222146987915 and perplexity is 559.5999463884137
At time: 164.0681791305542 and batch: 300, loss is 6.335500173568725 and perplexity is 564.2515561309028
At time: 165.16728568077087 and batch: 350, loss is 6.32752498626709 and perplexity is 559.769440896306
At time: 166.26753950119019 and batch: 400, loss is 6.387548418045044 and perplexity is 594.3975776118402
At time: 167.36851143836975 and batch: 450, loss is 6.358880214691162 and perplexity is 577.5992070207506
At time: 168.4678053855896 and batch: 500, loss is 6.369912881851196 and perplexity is 584.0069490707573
At time: 169.5676040649414 and batch: 550, loss is 6.308519601821899 and perplexity is 549.231265708041
At time: 170.6669638156891 and batch: 600, loss is 6.282564277648926 and perplexity is 535.1592026354774
At time: 171.76694512367249 and batch: 650, loss is 6.331474733352661 and perplexity is 561.9847607105606
At time: 172.86666631698608 and batch: 700, loss is 6.33958218574524 and perplexity is 566.5595452687279
At time: 173.96620440483093 and batch: 750, loss is 6.308491344451904 and perplexity is 549.2157460962258
At time: 175.06399536132812 and batch: 800, loss is 6.264939346313477 and perplexity is 525.8096926958418
At time: 176.16286492347717 and batch: 850, loss is 6.26456298828125 and perplexity is 525.6118372291559
At time: 177.26301550865173 and batch: 900, loss is 6.310095376968384 and perplexity is 550.0974129336265
At time: 178.3622341156006 and batch: 950, loss is 6.29677716255188 and perplexity is 542.8196684924226
At time: 179.46127152442932 and batch: 1000, loss is 6.296238832473755 and perplexity is 542.5275309781356
At time: 180.6061234474182 and batch: 1050, loss is 6.28742151260376 and perplexity is 537.7649197881408
At time: 181.7038335800171 and batch: 1100, loss is 6.2686078739166256 and perplexity is 527.7421825964692
At time: 182.80437850952148 and batch: 1150, loss is 6.272886915206909 and perplexity is 530.0052516162112
At time: 183.90432572364807 and batch: 1200, loss is 6.291624364852905 and perplexity is 540.0298224825459
At time: 185.00313448905945 and batch: 1250, loss is 6.280849552154541 and perplexity is 534.2423378175561
At time: 186.10208010673523 and batch: 1300, loss is 6.257507333755493 and perplexity is 521.9163540481135
At time: 187.20076203346252 and batch: 1350, loss is 6.274574928283691 and perplexity is 530.9006629320932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.002347412109375 and perplexity of 404.37691951372716
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 190.60867643356323 and batch: 50, loss is 6.235571260452271 and perplexity is 510.59221629160834
At time: 191.70901083946228 and batch: 100, loss is 6.200242080688477 and perplexity is 492.8683405598362
At time: 192.80985856056213 and batch: 150, loss is 6.135772695541382 and perplexity is 462.09601563624835
At time: 193.91073870658875 and batch: 200, loss is 6.11963270187378 and perplexity is 454.69765422821877
At time: 195.01213455200195 and batch: 250, loss is 6.146266136169434 and perplexity is 466.97052319007054
At time: 196.11216497421265 and batch: 300, loss is 6.1553953266143795 and perplexity is 471.253104535556
At time: 197.21232891082764 and batch: 350, loss is 6.156544628143311 and perplexity is 471.7950278060822
At time: 198.31275701522827 and batch: 400, loss is 6.195466165542602 and perplexity is 490.52005525648127
At time: 199.41235280036926 and batch: 450, loss is 6.180910606384277 and perplexity is 483.4319722220195
At time: 200.51161217689514 and batch: 500, loss is 6.188887825012207 and perplexity is 487.30383758191726
At time: 201.61213541030884 and batch: 550, loss is 6.143698854446411 and perplexity is 465.7732158709075
At time: 202.71301436424255 and batch: 600, loss is 6.089009685516357 and perplexity is 440.9844815137033
At time: 203.81338953971863 and batch: 650, loss is 6.117375917434693 and perplexity is 453.67265667196716
At time: 204.91261959075928 and batch: 700, loss is 6.138835544586182 and perplexity is 463.5135156625106
At time: 206.01233172416687 and batch: 750, loss is 6.11248399734497 and perplexity is 451.45874584113915
At time: 207.11030769348145 and batch: 800, loss is 6.088229436874389 and perplexity is 440.6405381689861
At time: 208.23891639709473 and batch: 850, loss is 6.076620044708252 and perplexity is 435.55454910105806
At time: 209.34039330482483 and batch: 900, loss is 6.119662103652954 and perplexity is 454.71102334477627
At time: 210.44215607643127 and batch: 950, loss is 6.089832096099854 and perplexity is 441.34730099129735
At time: 211.5419795513153 and batch: 1000, loss is 6.084790668487549 and perplexity is 439.1278797479641
At time: 212.643328666687 and batch: 1050, loss is 6.093130130767822 and perplexity is 442.80528260599345
At time: 213.74370503425598 and batch: 1100, loss is 6.070106182098389 and perplexity is 432.7266269564235
At time: 214.84481716156006 and batch: 1150, loss is 6.069358568191529 and perplexity is 432.40323541331236
At time: 215.94479727745056 and batch: 1200, loss is 6.069409198760987 and perplexity is 432.42512878958917
At time: 217.0461609363556 and batch: 1250, loss is 6.077687168121338 and perplexity is 436.0195876407064
At time: 218.14601182937622 and batch: 1300, loss is 6.036595621109009 and perplexity is 418.46599038059145
At time: 219.24497628211975 and batch: 1350, loss is 6.046079511642456 and perplexity is 422.45355495012734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.766601155598958 and perplexity of 319.4501241225152
Finished 7 epochs...
Completing Train Step...
At time: 222.64535212516785 and batch: 50, loss is 6.08657546043396 and perplexity is 439.91233148451573
At time: 223.74781441688538 and batch: 100, loss is 6.112581987380981 and perplexity is 451.50298646743636
At time: 224.84854412078857 and batch: 150, loss is 6.055798635482788 and perplexity is 426.57945093640046
At time: 225.94965028762817 and batch: 200, loss is 6.024859275817871 and perplexity is 413.5834367368021
At time: 227.0498821735382 and batch: 250, loss is 6.040403680801392 and perplexity is 420.06257186060503
At time: 228.14980125427246 and batch: 300, loss is 6.042868995666504 and perplexity is 421.09943593634756
At time: 229.25142431259155 and batch: 350, loss is 6.038619070053101 and perplexity is 419.31359219726806
At time: 230.35459566116333 and batch: 400, loss is 6.0757296180725096 and perplexity is 435.16689234478326
At time: 231.45589566230774 and batch: 450, loss is 6.061066398620605 and perplexity is 428.83249949642317
At time: 232.55542182922363 and batch: 500, loss is 6.067414073944092 and perplexity is 431.5632467507098
At time: 233.65579628944397 and batch: 550, loss is 6.02838134765625 and perplexity is 415.0426755756761
At time: 234.75652170181274 and batch: 600, loss is 5.9742329311370845 and perplexity is 393.1663996898671
At time: 235.85675597190857 and batch: 650, loss is 6.009492835998535 and perplexity is 407.27671179928006
At time: 237.00133419036865 and batch: 700, loss is 6.01678505897522 and perplexity is 410.257519543222
At time: 238.1000738143921 and batch: 750, loss is 5.993573627471924 and perplexity is 400.8445224153465
At time: 239.1994559764862 and batch: 800, loss is 5.965213775634766 and perplexity is 389.63631391861634
At time: 240.29909825325012 and batch: 850, loss is 5.962634439468384 and perplexity is 388.63260588907127
At time: 241.40016627311707 and batch: 900, loss is 6.007425832748413 and perplexity is 406.43573895851097
At time: 242.500825881958 and batch: 950, loss is 5.986066884994507 and perplexity is 397.84675163602896
At time: 243.60044717788696 and batch: 1000, loss is 5.990213756561279 and perplexity is 399.4999965463025
At time: 244.70101690292358 and batch: 1050, loss is 5.968263235092163 and perplexity is 390.82630755755326
At time: 245.8014371395111 and batch: 1100, loss is 5.957046070098877 and perplexity is 386.4668405231238
At time: 246.90202403068542 and batch: 1150, loss is 5.960977067947388 and perplexity is 387.9890307448168
At time: 248.00365328788757 and batch: 1200, loss is 5.967547464370727 and perplexity is 390.5466656211311
At time: 249.10406374931335 and batch: 1250, loss is 5.980761137008667 and perplexity is 395.7414670284593
At time: 250.20555329322815 and batch: 1300, loss is 5.939823884963989 and perplexity is 379.86802317612546
At time: 251.30588579177856 and batch: 1350, loss is 5.945421352386474 and perplexity is 382.00028412402713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.687920328776042 and perplexity of 295.27889862368744
Finished 8 epochs...
Completing Train Step...
At time: 254.68837213516235 and batch: 50, loss is 5.986194801330567 and perplexity is 397.8976459898516
At time: 255.82373476028442 and batch: 100, loss is 6.012031736373902 and perplexity is 408.31206056327204
At time: 256.9294967651367 and batch: 150, loss is 5.967532968521118 and perplexity is 390.5410043564333
At time: 258.0344216823578 and batch: 200, loss is 5.957550439834595 and perplexity is 386.6618118660313
At time: 259.13880157470703 and batch: 250, loss is 5.987977094650269 and perplexity is 398.6074486566054
At time: 260.2424054145813 and batch: 300, loss is 5.996136503219605 and perplexity is 401.8731546857519
At time: 261.34801983833313 and batch: 350, loss is 5.997322263717652 and perplexity is 402.34996263195063
At time: 262.4552323818207 and batch: 400, loss is 6.0356768608093265 and perplexity is 418.08169700564315
At time: 263.5593373775482 and batch: 450, loss is 6.021046161651611 and perplexity is 412.0093987756624
At time: 264.695588350296 and batch: 500, loss is 6.027875127792359 and perplexity is 414.83262589908213
At time: 265.8014931678772 and batch: 550, loss is 5.9966197681427005 and perplexity is 402.067412820236
At time: 266.90735244750977 and batch: 600, loss is 5.9408893966674805 and perplexity is 380.272992712178
At time: 268.0137598514557 and batch: 650, loss is 5.9789434432983395 and perplexity is 395.0227836239561
At time: 269.1183669567108 and batch: 700, loss is 5.993401250839233 and perplexity is 400.77543214128565
At time: 270.2216730117798 and batch: 750, loss is 5.96515682220459 and perplexity is 389.61412342593604
At time: 271.3257761001587 and batch: 800, loss is 5.946672439575195 and perplexity is 382.478498867376
At time: 272.43078327178955 and batch: 850, loss is 5.941044454574585 and perplexity is 380.3319616182357
At time: 273.53729224205017 and batch: 900, loss is 5.981112785339356 and perplexity is 395.8806533256045
At time: 274.6412103176117 and batch: 950, loss is 5.965325860977173 and perplexity is 389.6799888858924
At time: 275.74539375305176 and batch: 1000, loss is 5.970618495941162 and perplexity is 391.7478903163768
At time: 276.84852957725525 and batch: 1050, loss is 5.948572473526001 and perplexity is 383.20591183650816
At time: 277.95210814476013 and batch: 1100, loss is 5.934771213531494 and perplexity is 377.9535156291318
At time: 279.05698251724243 and batch: 1150, loss is 5.9414760112762455 and perplexity is 380.496131846961
At time: 280.162957906723 and batch: 1200, loss is 5.949354047775269 and perplexity is 383.5055327821224
At time: 281.26859974861145 and batch: 1250, loss is 5.95956503868103 and perplexity is 387.44156548782456
At time: 282.3726053237915 and batch: 1300, loss is 5.918974456787109 and perplexity is 372.02998534362484
At time: 283.4767475128174 and batch: 1350, loss is 5.9249670124053955 and perplexity is 374.2660890186162
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.679643961588542 and perplexity of 292.8451472383055
Finished 9 epochs...
Completing Train Step...
At time: 286.8917362689972 and batch: 50, loss is 5.965563898086548 and perplexity is 389.77275822486257
At time: 288.0267584323883 and batch: 100, loss is 5.989531679153442 and perplexity is 399.2275995327124
At time: 289.1312966346741 and batch: 150, loss is 5.945039625167847 and perplexity is 381.8544920462261
At time: 290.23533391952515 and batch: 200, loss is 5.936866626739502 and perplexity is 378.7463147485849
At time: 291.3391547203064 and batch: 250, loss is 5.970871934890747 and perplexity is 391.847187072502
At time: 292.4749960899353 and batch: 300, loss is 5.9795510196685795 and perplexity is 395.26286305890284
At time: 293.57483553886414 and batch: 350, loss is 5.9790700340270995 and perplexity is 395.07279301130745
At time: 294.6768174171448 and batch: 400, loss is 6.020562944412231 and perplexity is 411.8103568255112
At time: 295.7764973640442 and batch: 450, loss is 6.0073393440246585 and perplexity is 406.40058837024696
At time: 296.87759613990784 and batch: 500, loss is 6.0140824890136715 and perplexity is 409.15026678236785
At time: 297.98379135131836 and batch: 550, loss is 5.981716842651367 and perplexity is 396.1198601689774
At time: 299.082035779953 and batch: 600, loss is 5.926941127777099 and perplexity is 375.00566322027055
At time: 300.1815264225006 and batch: 650, loss is 5.966331882476807 and perplexity is 390.0722125923491
At time: 301.2785675525665 and batch: 700, loss is 5.980014057159424 and perplexity is 395.44592696269206
At time: 302.3776397705078 and batch: 750, loss is 5.95460545539856 and perplexity is 385.5247739493483
At time: 303.47431659698486 and batch: 800, loss is 5.933227815628052 and perplexity is 377.3706328912148
At time: 304.57252049446106 and batch: 850, loss is 5.927089376449585 and perplexity is 375.06126143309626
At time: 305.67130398750305 and batch: 900, loss is 5.968738746643067 and perplexity is 391.01219417330776
At time: 306.77058243751526 and batch: 950, loss is 5.952010087966919 and perplexity is 384.5254928187242
At time: 307.86789751052856 and batch: 1000, loss is 5.95873517036438 and perplexity is 387.1201733830801
At time: 308.966349363327 and batch: 1050, loss is 5.939400548934937 and perplexity is 379.7072453895462
At time: 310.06462264060974 and batch: 1100, loss is 5.929030590057373 and perplexity is 375.7900425886363
At time: 311.1628894805908 and batch: 1150, loss is 5.937120981216431 and perplexity is 378.84266282212394
At time: 312.26199865341187 and batch: 1200, loss is 5.942511749267578 and perplexity is 380.8904303059683
At time: 313.36126828193665 and batch: 1250, loss is 5.947855463027954 and perplexity is 382.93124765512573
At time: 314.46000361442566 and batch: 1300, loss is 5.911594877243042 and perplexity is 369.2946656420313
At time: 315.5588092803955 and batch: 1350, loss is 5.913464250564576 and perplexity is 369.98566090059126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.671194661458333 and perplexity of 290.3812345249669
Finished 10 epochs...
Completing Train Step...
At time: 318.97395277023315 and batch: 50, loss is 5.95540605545044 and perplexity is 385.83354868941694
At time: 320.07312273979187 and batch: 100, loss is 5.983599252700806 and perplexity is 396.8662224340635
At time: 321.2015461921692 and batch: 150, loss is 5.941242399215699 and perplexity is 380.40725374347284
At time: 322.3011591434479 and batch: 200, loss is 5.933621044158936 and perplexity is 377.519054970771
At time: 323.40105867385864 and batch: 250, loss is 5.9636837768554685 and perplexity is 389.040626650551
At time: 324.4978680610657 and batch: 300, loss is 5.9724631595611575 and perplexity is 392.4712003245769
At time: 325.5972123146057 and batch: 350, loss is 5.969056434631348 and perplexity is 391.1364337843393
At time: 326.69775915145874 and batch: 400, loss is 6.002670812606811 and perplexity is 404.507716359392
At time: 327.79654717445374 and batch: 450, loss is 5.988571100234985 and perplexity is 398.84429404399424
At time: 328.8954577445984 and batch: 500, loss is 5.988583154678345 and perplexity is 398.8491019189243
At time: 329.99509048461914 and batch: 550, loss is 5.95103572845459 and perplexity is 384.15100921752014
At time: 331.09400939941406 and batch: 600, loss is 5.880179929733276 and perplexity is 357.87362802260947
At time: 332.19355964660645 and batch: 650, loss is 5.915344181060791 and perplexity is 370.6818624278828
At time: 333.2909998893738 and batch: 700, loss is 5.926342735290527 and perplexity is 374.7813297753954
At time: 334.3890552520752 and batch: 750, loss is 5.901198825836182 and perplexity is 365.47534663072594
At time: 335.4874269962311 and batch: 800, loss is 5.876775407791138 and perplexity is 356.65731106721273
At time: 336.5859730243683 and batch: 850, loss is 5.873936252593994 and perplexity is 355.64614172148475
At time: 337.6846544742584 and batch: 900, loss is 5.911737642288208 and perplexity is 369.34739177528616
At time: 338.7833547592163 and batch: 950, loss is 5.892138681411743 and perplexity is 362.179042251948
At time: 339.8809115886688 and batch: 1000, loss is 5.90100905418396 and perplexity is 365.40599635091615
At time: 340.97875475883484 and batch: 1050, loss is 5.876816844940185 and perplexity is 356.6720902355714
At time: 342.07740807533264 and batch: 1100, loss is 5.861163892745972 and perplexity is 351.1325869527507
At time: 343.17714262008667 and batch: 1150, loss is 5.869891958236694 and perplexity is 354.2107086507918
At time: 344.2775294780731 and batch: 1200, loss is 5.876385488510132 and perplexity is 356.5182706139542
At time: 345.3758382797241 and batch: 1250, loss is 5.883364791870117 and perplexity is 359.015223136834
At time: 346.4743723869324 and batch: 1300, loss is 5.8362070655822755 and perplexity is 342.4778779133624
At time: 347.572879076004 and batch: 1350, loss is 5.837634067535401 and perplexity is 342.9669433797431
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.613157958984375 and perplexity of 274.00817973347995
Finished 11 epochs...
Completing Train Step...
At time: 350.9760947227478 and batch: 50, loss is 5.884911460876465 and perplexity is 359.5709304921586
At time: 352.07506704330444 and batch: 100, loss is 5.907081851959228 and perplexity is 367.63178461325367
At time: 353.1759259700775 and batch: 150, loss is 5.861591625213623 and perplexity is 351.2828098859634
At time: 354.27578592300415 and batch: 200, loss is 5.849787931442261 and perplexity is 347.1607507920158
At time: 355.3751029968262 and batch: 250, loss is 5.8826626205444335 and perplexity is 358.7632214262049
At time: 356.473108291626 and batch: 300, loss is 5.891230335235596 and perplexity is 361.8502076742633
At time: 357.5737373828888 and batch: 350, loss is 5.889928483963013 and perplexity is 361.3794390227911
At time: 358.67561864852905 and batch: 400, loss is 5.930333013534546 and perplexity is 376.27979922863324
At time: 359.77413034439087 and batch: 450, loss is 5.915930900573731 and perplexity is 370.89941252386427
At time: 360.873699426651 and batch: 500, loss is 5.927239561080933 and perplexity is 375.11759410042214
At time: 361.974577665329 and batch: 550, loss is 5.8926417255401615 and perplexity is 362.3612801255922
At time: 363.07417392730713 and batch: 600, loss is 5.840617542266846 and perplexity is 343.99170450336965
At time: 364.17336535453796 and batch: 650, loss is 5.881688327789306 and perplexity is 358.41385124082007
At time: 365.27332282066345 and batch: 700, loss is 5.893097543716431 and perplexity is 362.5264886331096
At time: 366.3726065158844 and batch: 750, loss is 5.873520622253418 and perplexity is 355.49835510890387
At time: 367.47071862220764 and batch: 800, loss is 5.844055891036987 and perplexity is 345.17650366661235
At time: 368.57060956954956 and batch: 850, loss is 5.841941833496094 and perplexity is 344.44755147102813
At time: 369.6716284751892 and batch: 900, loss is 5.881210823059082 and perplexity is 358.24274778608014
At time: 370.7738993167877 and batch: 950, loss is 5.858927783966064 and perplexity is 350.3482935016908
At time: 371.8745183944702 and batch: 1000, loss is 5.873243980407715 and perplexity is 355.4000229898187
At time: 372.9736678600311 and batch: 1050, loss is 5.847549648284912 and perplexity is 346.3845757044854
At time: 374.07388615608215 and batch: 1100, loss is 5.839187898635864 and perplexity is 343.50027032548996
At time: 375.1751661300659 and batch: 1150, loss is 5.848118581771851 and perplexity is 346.5817015593955
At time: 376.3182852268219 and batch: 1200, loss is 5.853520221710205 and perplexity is 348.45887646761565
At time: 377.4194231033325 and batch: 1250, loss is 5.858729400634766 and perplexity is 350.2787971337996
At time: 378.51913690567017 and batch: 1300, loss is 5.808441820144654 and perplexity is 333.0996918643286
At time: 379.6191725730896 and batch: 1350, loss is 5.8129305744171145 and perplexity is 334.5982553547736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.595557861328125 and perplexity of 269.22779998503097
Finished 12 epochs...
Completing Train Step...
At time: 383.00347542762756 and batch: 50, loss is 5.8583181285858155 and perplexity is 350.13476687503857
At time: 384.1332108974457 and batch: 100, loss is 5.878324270248413 and perplexity is 357.2101522133645
At time: 385.2349417209625 and batch: 150, loss is 5.834022531509399 and perplexity is 341.7305399097239
At time: 386.33675837516785 and batch: 200, loss is 5.818585042953491 and perplexity is 336.49558981572073
At time: 387.43815779685974 and batch: 250, loss is 5.85950192451477 and perplexity is 350.5495004181578
At time: 388.5381426811218 and batch: 300, loss is 5.868900136947632 and perplexity is 353.859569091768
At time: 389.6402711868286 and batch: 350, loss is 5.864866666793823 and perplexity is 352.4351616647443
At time: 390.7437150478363 and batch: 400, loss is 5.906571111679077 and perplexity is 367.4440681938367
At time: 391.84392380714417 and batch: 450, loss is 5.888726530075073 and perplexity is 360.94533853768075
At time: 392.94633650779724 and batch: 500, loss is 5.898991842269897 and perplexity is 364.6696379667556
At time: 394.048686504364 and batch: 550, loss is 5.864148445129395 and perplexity is 352.18212597506476
At time: 395.14972257614136 and batch: 600, loss is 5.814881792068482 and perplexity is 335.25176674087436
At time: 396.25062894821167 and batch: 650, loss is 5.852920007705689 and perplexity is 348.2497893247544
At time: 397.3517906665802 and batch: 700, loss is 5.86472827911377 and perplexity is 352.386392354966
At time: 398.4539749622345 and batch: 750, loss is 5.844713754653931 and perplexity is 345.4036574397074
At time: 399.5544226169586 and batch: 800, loss is 5.815161762237548 and perplexity is 335.34564037498416
At time: 400.6551651954651 and batch: 850, loss is 5.815180177688599 and perplexity is 335.35181597307246
At time: 401.75711131095886 and batch: 900, loss is 5.854837560653687 and perplexity is 348.918217403212
At time: 402.8591649532318 and batch: 950, loss is 5.83349687576294 and perplexity is 341.55095449186825
At time: 403.9874849319458 and batch: 1000, loss is 5.849237031936646 and perplexity is 346.96955277631713
At time: 405.0878338813782 and batch: 1050, loss is 5.821481637954712 and perplexity is 337.4716942662688
At time: 406.1894884109497 and batch: 1100, loss is 5.811862239837646 and perplexity is 334.24098334535006
At time: 407.2926137447357 and batch: 1150, loss is 5.821311502456665 and perplexity is 337.4142832354539
At time: 408.39521408081055 and batch: 1200, loss is 5.829898509979248 and perplexity is 340.3241378151727
At time: 409.4968156814575 and batch: 1250, loss is 5.830535593032837 and perplexity is 340.54102163526966
At time: 410.5975503921509 and batch: 1300, loss is 5.78327784538269 and perplexity is 324.8221641647108
At time: 411.6989290714264 and batch: 1350, loss is 5.7878720092773435 and perplexity is 326.3178835828102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.579479573567708 and perplexity of 264.93369140638276
Finished 13 epochs...
Completing Train Step...
At time: 415.0875473022461 and batch: 50, loss is 5.837842283248901 and perplexity is 343.0383619215392
At time: 416.2297170162201 and batch: 100, loss is 5.856270771026612 and perplexity is 349.4186491380123
At time: 417.3329083919525 and batch: 150, loss is 5.815370931625366 and perplexity is 335.41579175379337
At time: 418.4357764720917 and batch: 200, loss is 5.797987422943115 and perplexity is 329.6354750785772
At time: 419.5382068157196 and batch: 250, loss is 5.839756917953491 and perplexity is 343.6957842352357
At time: 420.63963651657104 and batch: 300, loss is 5.848570384979248 and perplexity is 346.73832366230533
At time: 421.74287962913513 and batch: 350, loss is 5.844445915222168 and perplexity is 345.31115710854084
At time: 422.8460536003113 and batch: 400, loss is 5.887358207702636 and perplexity is 360.45178670174914
At time: 423.9466464519501 and batch: 450, loss is 5.8716965675354 and perplexity is 354.85049770032924
At time: 425.0476987361908 and batch: 500, loss is 5.88203501701355 and perplexity is 358.5381310028472
At time: 426.1501293182373 and batch: 550, loss is 5.84481276512146 and perplexity is 345.4378577103811
At time: 427.25195026397705 and batch: 600, loss is 5.798019828796387 and perplexity is 329.6461573704993
At time: 428.35341358184814 and batch: 650, loss is 5.83842547416687 and perplexity is 343.2384771257399
At time: 429.4545910358429 and batch: 700, loss is 5.851877841949463 and perplexity is 347.8870443727227
At time: 430.5570242404938 and batch: 750, loss is 5.832643451690674 and perplexity is 341.2595910313793
At time: 431.65645813941956 and batch: 800, loss is 5.798657283782959 and perplexity is 329.85635894722316
At time: 432.7861795425415 and batch: 850, loss is 5.800164012908936 and perplexity is 330.35373774410033
At time: 433.8877136707306 and batch: 900, loss is 5.843057546615601 and perplexity is 344.8320705898112
At time: 434.98890566825867 and batch: 950, loss is 5.821534366607666 and perplexity is 337.48948916326395
At time: 436.08935475349426 and batch: 1000, loss is 5.834108953475952 and perplexity is 341.76007421120187
At time: 437.1891219615936 and batch: 1050, loss is 5.807899007797241 and perplexity is 332.91893030290737
At time: 438.2893850803375 and batch: 1100, loss is 5.794531288146973 and perplexity is 328.498176903087
At time: 439.3922002315521 and batch: 1150, loss is 5.808140506744385 and perplexity is 332.9993395830473
At time: 440.49487829208374 and batch: 1200, loss is 5.813746223449707 and perplexity is 334.8712814296511
At time: 441.59604024887085 and batch: 1250, loss is 5.818776655197143 and perplexity is 336.56007266831915
At time: 442.69735741615295 and batch: 1300, loss is 5.772363119125366 and perplexity is 321.29609719374537
At time: 443.7977292537689 and batch: 1350, loss is 5.776333799362183 and perplexity is 322.5743974382927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.57321044921875 and perplexity of 263.2779844897022
Finished 14 epochs...
Completing Train Step...
At time: 447.20112919807434 and batch: 50, loss is 5.826000871658326 and perplexity is 339.00025909029875
At time: 448.3007228374481 and batch: 100, loss is 5.844174108505249 and perplexity is 345.2173119710589
At time: 449.40260314941406 and batch: 150, loss is 5.80075590133667 and perplexity is 330.5493281766764
At time: 450.5039722919464 and batch: 200, loss is 5.786884069442749 and perplexity is 325.9956603416742
At time: 451.6057584285736 and batch: 250, loss is 5.8284563636779785 and perplexity is 339.83369434920644
At time: 452.7052438259125 and batch: 300, loss is 5.835476522445679 and perplexity is 342.2277744170361
At time: 453.8069589138031 and batch: 350, loss is 5.8339176273345945 and perplexity is 341.6946928297162
At time: 454.9098641872406 and batch: 400, loss is 5.875806379318237 and perplexity is 356.3118673771375
At time: 456.0105345249176 and batch: 450, loss is 5.8597167873382565 and perplexity is 350.62482856590873
At time: 457.1110723018646 and batch: 500, loss is 5.868801965713501 and perplexity is 353.8248319662822
At time: 458.2123465538025 and batch: 550, loss is 5.836016883850098 and perplexity is 342.4127510704725
At time: 459.31246066093445 and batch: 600, loss is 5.787198209762574 and perplexity is 326.0980848096606
At time: 460.44104528427124 and batch: 650, loss is 5.827383937835694 and perplexity is 339.46944326435585
At time: 461.5424678325653 and batch: 700, loss is 5.840384731292724 and perplexity is 343.9116287811697
At time: 462.6443302631378 and batch: 750, loss is 5.822950172424316 and perplexity is 337.9676471546399
At time: 463.7438061237335 and batch: 800, loss is 5.7873101234436035 and perplexity is 326.1345816889204
At time: 464.8448531627655 and batch: 850, loss is 5.789184303283691 and perplexity is 326.74638968710144
At time: 465.9460301399231 and batch: 900, loss is 5.833437614440918 and perplexity is 341.53071433050246
At time: 467.0469787120819 and batch: 950, loss is 5.810039014816284 and perplexity is 333.63214201737827
At time: 468.14676117897034 and batch: 1000, loss is 5.825302429199219 and perplexity is 338.7635695823248
At time: 469.2463355064392 and batch: 1050, loss is 5.800896301269531 and perplexity is 330.5957405382297
At time: 470.34645557403564 and batch: 1100, loss is 5.787412233352661 and perplexity is 326.16788496166544
At time: 471.448278427124 and batch: 1150, loss is 5.7956489562988285 and perplexity is 328.8655341068363
At time: 472.5493788719177 and batch: 1200, loss is 5.804297828674317 and perplexity is 331.7221857405716
At time: 473.64944982528687 and batch: 1250, loss is 5.805899534225464 and perplexity is 332.2539327442935
At time: 474.7494034767151 and batch: 1300, loss is 5.759254369735718 and perplexity is 317.1117925947694
At time: 475.8509714603424 and batch: 1350, loss is 5.766631927490234 and perplexity is 319.4599543582495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.56898681640625 and perplexity of 262.1683399706884
Finished 15 epochs...
Completing Train Step...
At time: 479.2674970626831 and batch: 50, loss is 5.814894351959229 and perplexity is 335.2559774928806
At time: 480.36668848991394 and batch: 100, loss is 5.832115993499756 and perplexity is 341.0796383277962
At time: 481.46719312667847 and batch: 150, loss is 5.789874925613403 and perplexity is 326.97212598026215
At time: 482.56797313690186 and batch: 200, loss is 5.776397342681885 and perplexity is 322.5948955376085
At time: 483.6692245006561 and batch: 250, loss is 5.816421451568604 and perplexity is 335.76833787825274
At time: 484.7679786682129 and batch: 300, loss is 5.826467361450195 and perplexity is 339.15843614172695
At time: 485.8680303096771 and batch: 350, loss is 5.823599872589111 and perplexity is 338.1872961359549
At time: 486.96878933906555 and batch: 400, loss is 5.866706275939942 and perplexity is 353.08410132621515
At time: 488.0671684741974 and batch: 450, loss is 5.850089073181152 and perplexity is 347.26531112713445
At time: 489.196408033371 and batch: 500, loss is 5.862310886383057 and perplexity is 351.5355648581257
At time: 490.2964611053467 and batch: 550, loss is 5.826833219528198 and perplexity is 339.28254269662074
At time: 491.39655232429504 and batch: 600, loss is 5.777087287902832 and perplexity is 322.81754514327014
At time: 492.4943308830261 and batch: 650, loss is 5.821873521804809 and perplexity is 337.6039698897643
At time: 493.5937898159027 and batch: 700, loss is 5.834702558517456 and perplexity is 341.9630049386311
At time: 494.693167924881 and batch: 750, loss is 5.813566093444824 and perplexity is 334.81096649651977
At time: 495.7903757095337 and batch: 800, loss is 5.776546754837036 and perplexity is 322.64309873717394
At time: 496.89059591293335 and batch: 850, loss is 5.780210790634155 and perplexity is 323.8274430155558
At time: 497.99133014678955 and batch: 900, loss is 5.81845422744751 and perplexity is 336.4515738539264
At time: 499.0914816856384 and batch: 950, loss is 5.8023601913452145 and perplexity is 331.0800507638446
At time: 500.1914620399475 and batch: 1000, loss is 5.818794212341309 and perplexity is 336.56598175390843
At time: 501.28902316093445 and batch: 1050, loss is 5.789244995117188 and perplexity is 326.76622112637705
At time: 502.38867115974426 and batch: 1100, loss is 5.775690031051636 and perplexity is 322.3668010925722
At time: 503.48931312561035 and batch: 1150, loss is 5.785853805541993 and perplexity is 325.65997173464064
At time: 504.5892117023468 and batch: 1200, loss is 5.799777555465698 and perplexity is 330.22609474912906
At time: 505.68854308128357 and batch: 1250, loss is 5.799382762908936 and perplexity is 330.09574967619864
At time: 506.78745770454407 and batch: 1300, loss is 5.752762775421143 and perplexity is 315.05989872187473
At time: 507.88655161857605 and batch: 1350, loss is 5.756671276092529 and perplexity is 316.29372017284766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.567984619140625 and perplexity of 261.90572719412035
Finished 16 epochs...
Completing Train Step...
At time: 511.2651970386505 and batch: 50, loss is 5.806472339630127 and perplexity is 332.4443041103585
At time: 512.3931539058685 and batch: 100, loss is 5.825667543411255 and perplexity is 338.8872795588603
At time: 513.4937844276428 and batch: 150, loss is 5.778722801208496 and perplexity is 323.345949522064
At time: 514.5942165851593 and batch: 200, loss is 5.768288612365723 and perplexity is 319.98963747081217
At time: 515.6934814453125 and batch: 250, loss is 5.805269527435303 and perplexity is 332.04467643397624
At time: 516.819079875946 and batch: 300, loss is 5.8170860004425045 and perplexity is 335.99154650738825
At time: 517.9198429584503 and batch: 350, loss is 5.815810852050781 and perplexity is 335.5633804728584
At time: 519.0211384296417 and batch: 400, loss is 5.856389217376709 and perplexity is 349.46003895284633
At time: 520.1198441982269 and batch: 450, loss is 5.839812459945679 and perplexity is 343.7148743139443
At time: 521.2188313007355 and batch: 500, loss is 5.84822865486145 and perplexity is 346.6198529777686
At time: 522.3180797100067 and batch: 550, loss is 5.812836093902588 and perplexity is 334.5666438328079
At time: 523.417947769165 and batch: 600, loss is 5.765748062133789 and perplexity is 319.177719518993
At time: 524.5161201953888 and batch: 650, loss is 5.8081364250183105 and perplexity is 332.9979803737341
At time: 525.6160089969635 and batch: 700, loss is 5.817650518417358 and perplexity is 336.18127332185065
At time: 526.7157444953918 and batch: 750, loss is 5.7997454643249515 and perplexity is 330.2154975870827
At time: 527.8132343292236 and batch: 800, loss is 5.763957204818726 and perplexity is 318.6066292883777
At time: 528.9128234386444 and batch: 850, loss is 5.76666787147522 and perplexity is 319.4714372284213
At time: 530.0128309726715 and batch: 900, loss is 5.802649660110474 and perplexity is 331.17590196963687
At time: 531.1119871139526 and batch: 950, loss is 5.786639280319214 and perplexity is 325.91586991601554
At time: 532.2113127708435 and batch: 1000, loss is 5.804837923049927 and perplexity is 331.90139541806843
At time: 533.3093507289886 and batch: 1050, loss is 5.773107376098633 and perplexity is 321.53531306256224
At time: 534.4102425575256 and batch: 1100, loss is 5.761889343261719 and perplexity is 317.9484756077369
At time: 535.5105526447296 and batch: 1150, loss is 5.77260724067688 and perplexity is 321.3745420701406
At time: 536.6098515987396 and batch: 1200, loss is 5.7814164638519285 and perplexity is 324.21810855094213
At time: 537.7088425159454 and batch: 1250, loss is 5.781372194290161 and perplexity is 324.2037558750552
At time: 538.8083164691925 and batch: 1300, loss is 5.73573522567749 and perplexity is 309.74061631800106
At time: 539.9084413051605 and batch: 1350, loss is 5.737519340515137 and perplexity is 310.293722403068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.556261393229167 and perplexity of 258.85327444247383
Finished 17 epochs...
Completing Train Step...
At time: 543.3058421611786 and batch: 50, loss is 5.787107248306274 and perplexity is 326.06842380199447
At time: 544.4329333305359 and batch: 100, loss is 5.803779811859131 and perplexity is 331.5503925701048
At time: 545.532918214798 and batch: 150, loss is 5.76146333694458 and perplexity is 317.8130563953713
At time: 546.6322944164276 and batch: 200, loss is 5.749727697372436 and perplexity is 314.105116990703
At time: 547.7327127456665 and batch: 250, loss is 5.788193521499633 and perplexity is 326.42281563829914
At time: 548.8302280902863 and batch: 300, loss is 5.798552026748657 and perplexity is 329.8216410723171
At time: 549.9304964542389 and batch: 350, loss is 5.797486362457275 and perplexity is 329.47034913978047
At time: 551.0313491821289 and batch: 400, loss is 5.837088918685913 and perplexity is 342.7800262985922
At time: 552.1298983097076 and batch: 450, loss is 5.821189107894898 and perplexity is 337.3729880893255
At time: 553.2292544841766 and batch: 500, loss is 5.83114013671875 and perplexity is 340.74695580152144
At time: 554.3286745548248 and batch: 550, loss is 5.796160688400269 and perplexity is 329.03386822500863
At time: 555.427661895752 and batch: 600, loss is 5.7458623504638675 and perplexity is 312.8933352349685
At time: 556.5263242721558 and batch: 650, loss is 5.790545730590821 and perplexity is 327.1915340916457
At time: 557.6249740123749 and batch: 700, loss is 5.803759183883667 and perplexity is 331.543553427281
At time: 558.7246172428131 and batch: 750, loss is 5.779638328552246 and perplexity is 323.64211713442893
At time: 559.8237676620483 and batch: 800, loss is 5.747193222045898 and perplexity is 313.3100333073457
At time: 560.9242534637451 and batch: 850, loss is 5.748196792602539 and perplexity is 313.6246198603711
At time: 562.0245084762573 and batch: 900, loss is 5.789046449661255 and perplexity is 326.70134961820474
At time: 563.1252956390381 and batch: 950, loss is 5.77430061340332 and perplexity is 321.91920998739903
At time: 564.2250969409943 and batch: 1000, loss is 5.7872086524963375 and perplexity is 326.10149018292185
At time: 565.3232288360596 and batch: 1050, loss is 5.757457666397094 and perplexity is 316.54254831298175
At time: 566.4229505062103 and batch: 1100, loss is 5.748164272308349 and perplexity is 313.61442086130614
At time: 567.5245888233185 and batch: 1150, loss is 5.754304466247558 and perplexity is 315.54599828884653
At time: 568.6246609687805 and batch: 1200, loss is 5.763041639328003 and perplexity is 318.31505755036426
At time: 569.7239451408386 and batch: 1250, loss is 5.764743108749389 and perplexity is 318.85712190934555
At time: 570.8224864006042 and batch: 1300, loss is 5.719626312255859 and perplexity is 304.7910050102673
At time: 571.9233682155609 and batch: 1350, loss is 5.723205471038819 and perplexity is 305.88385498796345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.541569417317708 and perplexity of 255.07800933044993
Finished 18 epochs...
Completing Train Step...
At time: 575.3345370292664 and batch: 50, loss is 5.775699462890625 and perplexity is 322.36984161867434
At time: 576.442230463028 and batch: 100, loss is 5.792110977172851 and perplexity is 327.70407054037156
At time: 577.5496604442596 and batch: 150, loss is 5.7436584377288815 and perplexity is 312.2045049684675
At time: 578.6549117565155 and batch: 200, loss is 5.738365755081177 and perplexity is 310.5564707107718
At time: 579.7615044116974 and batch: 250, loss is 5.774720268249512 and perplexity is 322.0543332945446
At time: 580.8653357028961 and batch: 300, loss is 5.786718587875367 and perplexity is 325.94171853215164
At time: 581.9725658893585 and batch: 350, loss is 5.7867599296569825 and perplexity is 325.95519382204304
At time: 583.0807230472565 and batch: 400, loss is 5.82373420715332 and perplexity is 338.23272943056503
At time: 584.1859548091888 and batch: 450, loss is 5.806115159988403 and perplexity is 332.3255829765714
At time: 585.291027545929 and batch: 500, loss is 5.816878938674927 and perplexity is 335.9219827061277
At time: 586.3963787555695 and batch: 550, loss is 5.779730100631713 and perplexity is 323.67181980743874
At time: 587.5011849403381 and batch: 600, loss is 5.733806629180908 and perplexity is 309.14382731808706
At time: 588.606986284256 and batch: 650, loss is 5.77708345413208 and perplexity is 322.81630753717957
At time: 589.7117402553558 and batch: 700, loss is 5.7903795909881595 and perplexity is 327.1371791355581
At time: 590.8188843727112 and batch: 750, loss is 5.765416507720947 and perplexity is 319.0719122790036
At time: 591.9230215549469 and batch: 800, loss is 5.726881856918335 and perplexity is 307.0104717432504
At time: 593.0263526439667 and batch: 850, loss is 5.73087477684021 and perplexity is 308.2387906296086
At time: 594.1287150382996 and batch: 900, loss is 5.771820287704468 and perplexity is 321.12173490572263
At time: 595.2301774024963 and batch: 950, loss is 5.7539759349823 and perplexity is 315.44234858979723
At time: 596.3305690288544 and batch: 1000, loss is 5.773571739196777 and perplexity is 321.6846568688915
At time: 597.4297256469727 and batch: 1050, loss is 5.739568376541138 and perplexity is 310.9301772556927
At time: 598.5295195579529 and batch: 1100, loss is 5.726758966445923 and perplexity is 306.9727453994939
At time: 599.6312589645386 and batch: 1150, loss is 5.735018997192383 and perplexity is 309.51885069250864
At time: 600.7773296833038 and batch: 1200, loss is 5.746250705718994 and perplexity is 313.0148726043117
At time: 601.8771121501923 and batch: 1250, loss is 5.74774549484253 and perplexity is 313.48311370505144
At time: 602.976800441742 and batch: 1300, loss is 5.70211443901062 and perplexity is 299.5000064258072
At time: 604.0773911476135 and batch: 1350, loss is 5.704790363311767 and perplexity is 300.3025190238068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.536265869140625 and perplexity of 253.72877185459782
Finished 19 epochs...
Completing Train Step...
At time: 607.4906508922577 and batch: 50, loss is 5.755217981338501 and perplexity is 315.8343860233886
At time: 608.5979940891266 and batch: 100, loss is 5.7693023777008055 and perplexity is 320.31419635834413
At time: 609.7063632011414 and batch: 150, loss is 5.724684066772461 and perplexity is 306.33646808437516
At time: 610.8086745738983 and batch: 200, loss is 5.7189552688598635 and perplexity is 304.5865456274279
At time: 611.9112389087677 and batch: 250, loss is 5.755297985076904 and perplexity is 315.8596549657782
At time: 613.0111763477325 and batch: 300, loss is 5.765415391921997 and perplexity is 319.07155625909746
At time: 614.1133601665497 and batch: 350, loss is 5.766637153625489 and perplexity is 319.4616239035419
At time: 615.2160437107086 and batch: 400, loss is 5.80553295135498 and perplexity is 332.1321564658111
At time: 616.3175039291382 and batch: 450, loss is 5.786539831161499 and perplexity is 325.883459468889
At time: 617.4190273284912 and batch: 500, loss is 5.798014450073242 and perplexity is 329.64438429985137
At time: 618.5205948352814 and batch: 550, loss is 5.764509105682373 and perplexity is 318.78251709409716
At time: 619.6210916042328 and batch: 600, loss is 5.71333010673523 and perplexity is 302.87800683633304
At time: 620.7233335971832 and batch: 650, loss is 5.756238222122192 and perplexity is 316.1567775754421
At time: 621.8248505592346 and batch: 700, loss is 5.77025294303894 and perplexity is 320.618820690443
At time: 622.9262158870697 and batch: 750, loss is 5.750255317687988 and perplexity is 314.2708889601298
At time: 624.0264039039612 and batch: 800, loss is 5.7130914974212645 and perplexity is 302.8057459443105
At time: 625.128180027008 and batch: 850, loss is 5.7166697216033935 and perplexity is 303.8911936163461
At time: 626.2302033901215 and batch: 900, loss is 5.75847207069397 and perplexity is 316.86381335290395
At time: 627.332025051117 and batch: 950, loss is 5.739410791397095 and perplexity is 310.8811831393963
At time: 628.4617788791656 and batch: 1000, loss is 5.761299524307251 and perplexity is 317.7609988643828
At time: 629.5610666275024 and batch: 1050, loss is 5.725646123886109 and perplexity is 306.6313230735933
At time: 630.6622638702393 and batch: 1100, loss is 5.715326242446899 and perplexity is 303.483196261219
At time: 631.7641613483429 and batch: 1150, loss is 5.72645450592041 and perplexity is 306.879298542273
At time: 632.8662161827087 and batch: 1200, loss is 5.73372223854065 and perplexity is 309.1177395733641
At time: 633.9662170410156 and batch: 1250, loss is 5.737015371322632 and perplexity is 310.1373833246977
At time: 635.0660088062286 and batch: 1300, loss is 5.691375074386596 and perplexity is 296.30077624985364
At time: 636.1675221920013 and batch: 1350, loss is 5.693628120422363 and perplexity is 296.96910814772815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.526999918619792 and perplexity of 251.38859234618786
Finished 20 epochs...
Completing Train Step...
At time: 639.5417122840881 and batch: 50, loss is 5.745759239196778 and perplexity is 312.86107406998184
At time: 640.6708071231842 and batch: 100, loss is 5.75613392829895 and perplexity is 316.1238060957554
At time: 641.7726423740387 and batch: 150, loss is 5.715473394393921 and perplexity is 303.5278576903649
At time: 642.8744380474091 and batch: 200, loss is 5.7102623462677 and perplexity is 301.95027342001265
At time: 643.9758069515228 and batch: 250, loss is 5.747499542236328 and perplexity is 313.4060211971758
At time: 645.0759241580963 and batch: 300, loss is 5.754994077682495 and perplexity is 315.7636774659132
At time: 646.1783287525177 and batch: 350, loss is 5.756413745880127 and perplexity is 316.2122754715957
At time: 647.2809584140778 and batch: 400, loss is 5.79622407913208 and perplexity is 329.05472658381245
At time: 648.3815786838531 and batch: 450, loss is 5.776818132400512 and perplexity is 322.73066871690804
At time: 649.4832437038422 and batch: 500, loss is 5.788647613525391 and perplexity is 326.57107529512206
At time: 650.5844967365265 and batch: 550, loss is 5.751847114562988 and perplexity is 314.77154274292974
At time: 651.6852631568909 and batch: 600, loss is 5.7019883728027345 and perplexity is 299.4622519755657
At time: 652.7867388725281 and batch: 650, loss is 5.736369543075561 and perplexity is 309.9371525063928
At time: 653.8880143165588 and batch: 700, loss is 5.7436649608612065 and perplexity is 312.2065415264083
At time: 654.9890584945679 and batch: 750, loss is 5.718069114685059 and perplexity is 304.3167545443329
At time: 656.1341121196747 and batch: 800, loss is 5.677627630233765 and perplexity is 292.25526928039596
At time: 657.2348234653473 and batch: 850, loss is 5.681510181427002 and perplexity is 293.39217093615343
At time: 658.3369905948639 and batch: 900, loss is 5.721483163833618 and perplexity is 305.35748243829727
At time: 659.4389591217041 and batch: 950, loss is 5.7106259822845455 and perplexity is 302.0600933807609
At time: 660.541033744812 and batch: 1000, loss is 5.727601461410522 and perplexity is 307.23147736664805
At time: 661.6414358615875 and batch: 1050, loss is 5.689759225845337 and perplexity is 295.82238568021677
At time: 662.7417087554932 and batch: 1100, loss is 5.6794523334503175 and perplexity is 292.7890352444424
At time: 663.8438303470612 and batch: 1150, loss is 5.6909375 and perplexity is 296.1711509818551
At time: 664.9454460144043 and batch: 1200, loss is 5.698355369567871 and perplexity is 298.37627851242524
At time: 666.0465364456177 and batch: 1250, loss is 5.6996082592010495 and perplexity is 298.75034534185414
At time: 667.147294998169 and batch: 1300, loss is 5.662813520431518 and perplexity is 287.95767871496275
At time: 668.2489244937897 and batch: 1350, loss is 5.660094833374023 and perplexity is 287.1758751219317
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4966219075520835 and perplexity of 243.86673487703214
Finished 21 epochs...
Completing Train Step...
At time: 671.6300880908966 and batch: 50, loss is 5.714859104156494 and perplexity is 303.34146074737106
At time: 672.7580914497375 and batch: 100, loss is 5.725838279724121 and perplexity is 306.6902497338088
At time: 673.8598923683167 and batch: 150, loss is 5.678471565246582 and perplexity is 292.50201784005134
At time: 674.9608888626099 and batch: 200, loss is 5.674869022369385 and perplexity is 291.4501625935377
At time: 676.0618600845337 and batch: 250, loss is 5.713471097946167 and perplexity is 302.9207129838082
At time: 677.1612665653229 and batch: 300, loss is 5.722899160385132 and perplexity is 305.7901738528871
At time: 678.2630321979523 and batch: 350, loss is 5.722485084533691 and perplexity is 305.66357973787854
At time: 679.3656549453735 and batch: 400, loss is 5.764816980361939 and perplexity is 318.8806772691395
At time: 680.467000246048 and batch: 450, loss is 5.744450025558471 and perplexity is 312.45174009619274
At time: 681.5680246353149 and batch: 500, loss is 5.755719556808471 and perplexity is 315.99284053911816
At time: 682.6685109138489 and batch: 550, loss is 5.7252593517303465 and perplexity is 306.51274954769116
At time: 683.7684683799744 and batch: 600, loss is 5.675363550186157 and perplexity is 291.59432845021814
At time: 684.8978176116943 and batch: 650, loss is 5.716444482803345 and perplexity is 303.82275323655443
At time: 685.9984209537506 and batch: 700, loss is 5.730455198287964 and perplexity is 308.10948737242387
At time: 687.1001598834991 and batch: 750, loss is 5.701232061386109 and perplexity is 299.23585088120626
At time: 688.2005834579468 and batch: 800, loss is 5.6602513885498045 and perplexity is 287.2208375109971
At time: 689.3016645908356 and batch: 850, loss is 5.665397386550904 and perplexity is 288.7026848884221
At time: 690.403014421463 and batch: 900, loss is 5.710013303756714 and perplexity is 301.87508432875586
At time: 691.505140542984 and batch: 950, loss is 5.695870227813721 and perplexity is 297.6356917769066
At time: 692.6067612171173 and batch: 1000, loss is 5.717422466278077 and perplexity is 304.1200322117354
At time: 693.7062203884125 and batch: 1050, loss is 5.680335159301758 and perplexity is 293.0476311045343
At time: 694.807005405426 and batch: 1100, loss is 5.669393873214721 and perplexity is 289.85878995886867
At time: 695.9087800979614 and batch: 1150, loss is 5.682889966964722 and perplexity is 293.7972686201854
At time: 697.0094101428986 and batch: 1200, loss is 5.689584217071533 and perplexity is 295.77061869720546
At time: 698.1104156970978 and batch: 1250, loss is 5.6889129066467286 and perplexity is 295.5721314282637
At time: 699.2105917930603 and batch: 1300, loss is 5.652483263015747 and perplexity is 284.998313587912
At time: 700.3128201961517 and batch: 1350, loss is 5.650389232635498 and perplexity is 284.4021428785766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.496813151041667 and perplexity of 243.91337726228738
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 703.7227272987366 and batch: 50, loss is 5.680491781234741 and perplexity is 293.0935323854538
At time: 704.8292229175568 and batch: 100, loss is 5.670902328491211 and perplexity is 290.29635892365417
At time: 705.9377100467682 and batch: 150, loss is 5.622248001098633 and perplexity is 276.51028049878533
At time: 707.045047044754 and batch: 200, loss is 5.619820070266724 and perplexity is 275.8397469972946
At time: 708.1510517597198 and batch: 250, loss is 5.638293437957763 and perplexity is 280.9827945101122
At time: 709.2573783397675 and batch: 300, loss is 5.650765895843506 and perplexity is 284.50928687941234
At time: 710.3633527755737 and batch: 350, loss is 5.653011465072632 and perplexity is 285.14889004725484
At time: 711.4704365730286 and batch: 400, loss is 5.694537773132324 and perplexity is 297.23936980521785
At time: 712.6103463172913 and batch: 450, loss is 5.668349304199219 and perplexity is 289.5561705289628
At time: 713.7199425697327 and batch: 500, loss is 5.677747421264648 and perplexity is 292.2902809373835
At time: 714.8272292613983 and batch: 550, loss is 5.643112487792969 and perplexity is 282.3401325126158
At time: 715.9313654899597 and batch: 600, loss is 5.598483791351319 and perplexity is 270.01669525144285
At time: 717.0369157791138 and batch: 650, loss is 5.627253580093384 and perplexity is 277.8978444339148
At time: 718.1444292068481 and batch: 700, loss is 5.643284378051757 and perplexity is 282.38866820234637
At time: 719.2507147789001 and batch: 750, loss is 5.624114093780517 and perplexity is 277.0267560554412
At time: 720.3590586185455 and batch: 800, loss is 5.588633918762207 and perplexity is 267.37012081430254
At time: 721.4661655426025 and batch: 850, loss is 5.58083324432373 and perplexity is 265.29256724178526
At time: 722.5735874176025 and batch: 900, loss is 5.630387201309204 and perplexity is 278.770036861698
At time: 723.6805138587952 and batch: 950, loss is 5.601603803634643 and perplexity is 270.8604662608145
At time: 724.7867319583893 and batch: 1000, loss is 5.619109020233155 and perplexity is 275.6436808506133
At time: 725.8939914703369 and batch: 1050, loss is 5.58196325302124 and perplexity is 265.592519592618
At time: 727.0016849040985 and batch: 1100, loss is 5.57154333114624 and perplexity is 262.8394346624081
At time: 728.1090605258942 and batch: 1150, loss is 5.587197494506836 and perplexity is 266.9863395899215
At time: 729.2162034511566 and batch: 1200, loss is 5.586602411270142 and perplexity is 266.8275077585724
At time: 730.3228085041046 and batch: 1250, loss is 5.583652725219727 and perplexity is 266.0416100266766
At time: 731.4297547340393 and batch: 1300, loss is 5.555998764038086 and perplexity is 258.7853009427017
At time: 732.5330500602722 and batch: 1350, loss is 5.560473957061768 and perplexity is 259.94601037833553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.422917073567708 and perplexity of 226.5389904936005
Finished 23 epochs...
Completing Train Step...
At time: 735.9986474514008 and batch: 50, loss is 5.624234399795532 and perplexity is 277.0600860453737
At time: 737.105170249939 and batch: 100, loss is 5.630108222961426 and perplexity is 278.6922769045809
At time: 738.2127754688263 and batch: 150, loss is 5.592688455581665 and perplexity is 268.45638347142307
At time: 739.3196349143982 and batch: 200, loss is 5.591239748001098 and perplexity is 268.0677502495543
At time: 740.4513900279999 and batch: 250, loss is 5.6160773754119875 and perplexity is 274.80929253664334
At time: 741.552435874939 and batch: 300, loss is 5.629674320220947 and perplexity is 278.57137779300643
At time: 742.6534569263458 and batch: 350, loss is 5.633174533843994 and perplexity is 279.54814557525884
At time: 743.7548637390137 and batch: 400, loss is 5.677565584182739 and perplexity is 292.2371365575833
At time: 744.8555536270142 and batch: 450, loss is 5.651880226135254 and perplexity is 284.8265009038393
At time: 745.9576458930969 and batch: 500, loss is 5.659832439422607 and perplexity is 287.10053179455616
At time: 747.0578689575195 and batch: 550, loss is 5.627353858947754 and perplexity is 277.9257131086827
At time: 748.1572616100311 and batch: 600, loss is 5.582441720962525 and perplexity is 265.71962750479355
At time: 749.2572476863861 and batch: 650, loss is 5.6122822570800786 and perplexity is 273.768335280144
At time: 750.3590941429138 and batch: 700, loss is 5.626589450836182 and perplexity is 277.71334561722534
At time: 751.4619333744049 and batch: 750, loss is 5.609688730239868 and perplexity is 273.05922969425615
At time: 752.5629210472107 and batch: 800, loss is 5.575041103363037 and perplexity is 263.7603968534788
At time: 753.6647691726685 and batch: 850, loss is 5.572938871383667 and perplexity is 263.2064937327415
At time: 754.7661423683167 and batch: 900, loss is 5.619852085113525 and perplexity is 275.8485781058989
At time: 755.867614030838 and batch: 950, loss is 5.594951868057251 and perplexity is 269.06469917389614
At time: 756.9681828022003 and batch: 1000, loss is 5.614286432266235 and perplexity is 274.3175651770916
At time: 758.0699419975281 and batch: 1050, loss is 5.579914846420288 and perplexity is 265.04903495112154
At time: 759.1723697185516 and batch: 1100, loss is 5.5695179748535155 and perplexity is 262.3076298883028
At time: 760.2738990783691 and batch: 1150, loss is 5.58438775062561 and perplexity is 266.23722925281174
At time: 761.3748922348022 and batch: 1200, loss is 5.585138063430787 and perplexity is 266.4370654155756
At time: 762.4760122299194 and batch: 1250, loss is 5.581504383087158 and perplexity is 265.47067512817847
At time: 763.577386379242 and batch: 1300, loss is 5.555391798019409 and perplexity is 258.6282747185083
At time: 764.6763327121735 and batch: 1350, loss is 5.555658388137817 and perplexity is 258.69723165209933
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.418772379557292 and perplexity of 225.60199880982702
Finished 24 epochs...
Completing Train Step...
At time: 768.0566782951355 and batch: 50, loss is 5.615472221374512 and perplexity is 274.6430408927294
At time: 769.1850342750549 and batch: 100, loss is 5.622805213928222 and perplexity is 276.6643985088712
At time: 770.2870755195618 and batch: 150, loss is 5.585692768096924 and perplexity is 266.5849002975522
At time: 771.3890469074249 and batch: 200, loss is 5.585377912521363 and perplexity is 266.5009777677647
At time: 772.4904441833496 and batch: 250, loss is 5.607977542877197 and perplexity is 272.592373744063
At time: 773.5922529697418 and batch: 300, loss is 5.624492073059082 and perplexity is 277.1314862205075
At time: 774.69278216362 and batch: 350, loss is 5.628174648284912 and perplexity is 278.153925214744
At time: 775.7937934398651 and batch: 400, loss is 5.67330644607544 and perplexity is 290.99510510221756
At time: 776.8950455188751 and batch: 450, loss is 5.64607310295105 and perplexity is 283.1772716005266
At time: 777.9970715045929 and batch: 500, loss is 5.654357824325562 and perplexity is 285.5330614521636
At time: 779.0985398292542 and batch: 550, loss is 5.6241284847259525 and perplexity is 277.03074276105787
At time: 780.1981770992279 and batch: 600, loss is 5.577465019226074 and perplexity is 264.40050533459765
At time: 781.2982974052429 and batch: 650, loss is 5.6080007743835445 and perplexity is 272.59870654908383
At time: 782.3999700546265 and batch: 700, loss is 5.623390893936158 and perplexity is 276.8264827761096
At time: 783.501645565033 and batch: 750, loss is 5.604594068527222 and perplexity is 271.6716229861753
At time: 784.6032094955444 and batch: 800, loss is 5.571253414154053 and perplexity is 262.7632440890871
At time: 785.7058691978455 and batch: 850, loss is 5.5696806049346925 and perplexity is 262.35029246846034
At time: 786.8086955547333 and batch: 900, loss is 5.617178258895874 and perplexity is 275.11199213593886
At time: 787.909506559372 and batch: 950, loss is 5.590677509307861 and perplexity is 267.9170745497784
At time: 789.0108644962311 and batch: 1000, loss is 5.609297294616699 and perplexity is 272.9523655011092
At time: 790.1135590076447 and batch: 1050, loss is 5.577743740081787 and perplexity is 264.4742095406679
At time: 791.2154757976532 and batch: 1100, loss is 5.566078748703003 and perplexity is 261.4070441747782
At time: 792.3177132606506 and batch: 1150, loss is 5.581761083602905 and perplexity is 265.53883033476365
At time: 793.4190225601196 and batch: 1200, loss is 5.579731121063232 and perplexity is 265.00034319562985
At time: 794.5195462703705 and batch: 1250, loss is 5.5786572933197025 and perplexity is 264.7159312071332
At time: 795.6206057071686 and batch: 1300, loss is 5.551937103271484 and perplexity is 257.7363345537771
At time: 796.7195417881012 and batch: 1350, loss is 5.551794385910034 and perplexity is 257.69955372885323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.416151123046875 and perplexity of 225.0114124789752
Finished 25 epochs...
Completing Train Step...
At time: 800.1182034015656 and batch: 50, loss is 5.609741668701172 and perplexity is 273.07368541234945
At time: 801.2490341663361 and batch: 100, loss is 5.617526445388794 and perplexity is 275.20779909401745
At time: 802.3513207435608 and batch: 150, loss is 5.581313219070434 and perplexity is 265.41993153792737
At time: 803.4537665843964 and batch: 200, loss is 5.580146684646606 and perplexity is 265.11049057287784
At time: 804.5545606613159 and batch: 250, loss is 5.602580032348633 and perplexity is 271.1250171355328
At time: 805.6562352180481 and batch: 300, loss is 5.619572715759277 and perplexity is 275.7715252303705
At time: 806.7578568458557 and batch: 350, loss is 5.625607624053955 and perplexity is 277.4408130285069
At time: 807.8601756095886 and batch: 400, loss is 5.670604953765869 and perplexity is 290.2100449580834
At time: 808.9623985290527 and batch: 450, loss is 5.6425899887084965 and perplexity is 282.19264858533194
At time: 810.0653817653656 and batch: 500, loss is 5.6510152339935305 and perplexity is 284.5802347433047
At time: 811.1676955223083 and batch: 550, loss is 5.622011613845825 and perplexity is 276.4449247181462
At time: 812.2669477462769 and batch: 600, loss is 5.573030071258545 and perplexity is 263.2304992266693
At time: 813.3682136535645 and batch: 650, loss is 5.603464231491089 and perplexity is 271.3648516582968
At time: 814.4704859256744 and batch: 700, loss is 5.619873027801514 and perplexity is 275.8543551770959
At time: 815.5727305412292 and batch: 750, loss is 5.602072410583496 and perplexity is 270.98742310157945
At time: 816.6748566627502 and batch: 800, loss is 5.568755111694336 and perplexity is 262.1076013679845
At time: 817.7777252197266 and batch: 850, loss is 5.565523405075073 and perplexity is 261.2619137408605
At time: 818.8799207210541 and batch: 900, loss is 5.613767337799072 and perplexity is 274.17520539904586
At time: 819.9825744628906 and batch: 950, loss is 5.587001132965088 and perplexity is 266.9339188875272
At time: 821.0842535495758 and batch: 1000, loss is 5.605288782119751 and perplexity is 271.86042252857914
At time: 822.1858379840851 and batch: 1050, loss is 5.572994937896729 and perplexity is 263.2212512167567
At time: 823.2885563373566 and batch: 1100, loss is 5.563003568649292 and perplexity is 260.6044052088301
At time: 824.4195051193237 and batch: 1150, loss is 5.579394979476929 and perplexity is 264.91128052956867
At time: 825.5215990543365 and batch: 1200, loss is 5.576862058639526 and perplexity is 264.24113030407705
At time: 826.6235620975494 and batch: 1250, loss is 5.575023517608643 and perplexity is 263.7557584687058
At time: 827.7258882522583 and batch: 1300, loss is 5.549452676773071 and perplexity is 257.096802338951
At time: 828.8264768123627 and batch: 1350, loss is 5.550096073150635 and perplexity is 257.26227071542803
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.415696614583333 and perplexity of 224.9091661252867
Finished 26 epochs...
Completing Train Step...
At time: 832.2333674430847 and batch: 50, loss is 5.605192422866821 and perplexity is 271.834227523449
At time: 833.3359286785126 and batch: 100, loss is 5.6139804649353025 and perplexity is 274.23364580279457
At time: 834.4400186538696 and batch: 150, loss is 5.578455963134766 and perplexity is 264.66264126436454
At time: 835.5434539318085 and batch: 200, loss is 5.576369400024414 and perplexity is 264.11098169681446
At time: 836.6459348201752 and batch: 250, loss is 5.59832200050354 and perplexity is 269.9730125552292
At time: 837.7482857704163 and batch: 300, loss is 5.617131109237671 and perplexity is 275.0990210053368
At time: 838.8508021831512 and batch: 350, loss is 5.622354278564453 and perplexity is 276.53966887230314
At time: 839.9539306163788 and batch: 400, loss is 5.668434820175171 and perplexity is 289.5809332662683
At time: 841.0567922592163 and batch: 450, loss is 5.63920482635498 and perplexity is 281.2389957005085
At time: 842.1599593162537 and batch: 500, loss is 5.647455863952636 and perplexity is 283.56910893449003
At time: 843.2623627185822 and batch: 550, loss is 5.619949712753296 and perplexity is 275.87550986613417
At time: 844.3626368045807 and batch: 600, loss is 5.569319314956665 and perplexity is 262.2555250573477
At time: 845.4640974998474 and batch: 650, loss is 5.600278158187866 and perplexity is 270.50163920827634
At time: 846.5671119689941 and batch: 700, loss is 5.616720342636109 and perplexity is 274.98604272082684
At time: 847.6711111068726 and batch: 750, loss is 5.59903226852417 and perplexity is 270.1648338666879
At time: 848.7745819091797 and batch: 800, loss is 5.56642014503479 and perplexity is 261.4963028161824
At time: 849.8795158863068 and batch: 850, loss is 5.563992099761963 and perplexity is 260.8621481439446
At time: 850.9821455478668 and batch: 900, loss is 5.612386035919189 and perplexity is 273.79674811446466
At time: 852.1137161254883 and batch: 950, loss is 5.583716945648193 and perplexity is 266.0586958814871
At time: 853.2159049510956 and batch: 1000, loss is 5.602898244857788 and perplexity is 271.2113062359377
At time: 854.3188309669495 and batch: 1050, loss is 5.570463209152222 and perplexity is 262.5556892755367
At time: 855.4229345321655 and batch: 1100, loss is 5.56116720199585 and perplexity is 260.1262791111384
At time: 856.5255882740021 and batch: 1150, loss is 5.578174734115601 and perplexity is 264.58822091442374
At time: 857.628092288971 and batch: 1200, loss is 5.573554391860962 and perplexity is 263.3685525895468
At time: 858.7298419475555 and batch: 1250, loss is 5.573683738708496 and perplexity is 263.4026206848168
At time: 859.833664894104 and batch: 1300, loss is 5.546414575576782 and perplexity is 256.31690154484824
At time: 860.9345319271088 and batch: 1350, loss is 5.546437559127807 and perplexity is 256.32279268513287
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.415486653645833 and perplexity of 224.86194894297003
Finished 27 epochs...
Completing Train Step...
At time: 864.3436176776886 and batch: 50, loss is 5.601772613525391 and perplexity is 270.9061940460745
At time: 865.450813293457 and batch: 100, loss is 5.6093964099884035 and perplexity is 272.9794206170403
At time: 866.5591268539429 and batch: 150, loss is 5.5754327297210695 and perplexity is 263.86371260635735
At time: 867.6674220561981 and batch: 200, loss is 5.574102935791015 and perplexity is 263.51306144154
At time: 868.7750360965729 and batch: 250, loss is 5.59553729057312 and perplexity is 269.22226182287943
At time: 869.8829519748688 and batch: 300, loss is 5.613703918457031 and perplexity is 274.1578179392719
At time: 870.9906532764435 and batch: 350, loss is 5.620379390716553 and perplexity is 275.99407296347704
At time: 872.0979180335999 and batch: 400, loss is 5.665111360549926 and perplexity is 288.62012022237553
At time: 873.2055206298828 and batch: 450, loss is 5.636229991912842 and perplexity is 280.40359944847745
At time: 874.3140895366669 and batch: 500, loss is 5.645077800750732 and perplexity is 282.8955648539505
At time: 875.4209935665131 and batch: 550, loss is 5.61652979850769 and perplexity is 274.93365073664035
At time: 876.526688337326 and batch: 600, loss is 5.567065277099609 and perplexity is 261.6650568944413
At time: 877.6324880123138 and batch: 650, loss is 5.597384510040283 and perplexity is 269.7200340316269
At time: 878.7403717041016 and batch: 700, loss is 5.61363112449646 and perplexity is 274.13786163224063
At time: 879.8480069637299 and batch: 750, loss is 5.596640043258667 and perplexity is 269.519311150983
At time: 880.9841520786285 and batch: 800, loss is 5.563833885192871 and perplexity is 260.8208792163424
At time: 882.0932512283325 and batch: 850, loss is 5.56102970123291 and perplexity is 260.0905140082209
At time: 883.2021338939667 and batch: 900, loss is 5.609642095565796 and perplexity is 273.04649596299606
At time: 884.3094916343689 and batch: 950, loss is 5.581759262084961 and perplexity is 265.53834665145973
At time: 885.4173789024353 and batch: 1000, loss is 5.60072995185852 and perplexity is 270.62387774799237
At time: 886.5244030952454 and batch: 1050, loss is 5.5680555152893065 and perplexity is 261.92429595971527
At time: 887.6311695575714 and batch: 1100, loss is 5.558395071029663 and perplexity is 259.4061735722773
At time: 888.7334957122803 and batch: 1150, loss is 5.573352403640747 and perplexity is 263.3153606166056
At time: 889.8359551429749 and batch: 1200, loss is 5.571497945785523 and perplexity is 262.8275058705534
At time: 890.9377210140228 and batch: 1250, loss is 5.571446771621704 and perplexity is 262.8140562368518
At time: 892.0398902893066 and batch: 1300, loss is 5.544047536849976 and perplexity is 255.7109070017749
At time: 893.1397864818573 and batch: 1350, loss is 5.54364315032959 and perplexity is 255.60752186305484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.414794921875 and perplexity of 224.70645857384903
Finished 28 epochs...
Completing Train Step...
At time: 896.5120151042938 and batch: 50, loss is 5.598097944259644 and perplexity is 269.9125301920614
At time: 897.6410827636719 and batch: 100, loss is 5.607072439193725 and perplexity is 272.34576100438613
At time: 898.7440586090088 and batch: 150, loss is 5.574430265426636 and perplexity is 263.599331194476
At time: 899.8468368053436 and batch: 200, loss is 5.5716197681427 and perplexity is 262.8595260871991
At time: 900.947340965271 and batch: 250, loss is 5.593711090087891 and perplexity is 268.7310566537774
At time: 902.0492720603943 and batch: 300, loss is 5.6121718692779545 and perplexity is 273.73811626325744
At time: 903.1506986618042 and batch: 350, loss is 5.617714042663574 and perplexity is 275.25943217008654
At time: 904.2535421848297 and batch: 400, loss is 5.6629179668426515 and perplexity is 287.9877564317902
At time: 905.355574131012 and batch: 450, loss is 5.633750467300415 and perplexity is 279.70919307684665
At time: 906.4580793380737 and batch: 500, loss is 5.6421260738372805 and perplexity is 282.06176558073884
At time: 907.5591287612915 and batch: 550, loss is 5.613555889129639 and perplexity is 274.1172375455013
At time: 908.6852467060089 and batch: 600, loss is 5.563564519882203 and perplexity is 260.7506325806117
At time: 909.7867183685303 and batch: 650, loss is 5.589450006484985 and perplexity is 267.588407345701
At time: 910.8903610706329 and batch: 700, loss is 5.604720268249512 and perplexity is 271.70591003301263
At time: 911.9932067394257 and batch: 750, loss is 5.587183704376221 and perplexity is 266.98265783881203
At time: 913.0953879356384 and batch: 800, loss is 5.553093280792236 and perplexity is 258.03449584054397
At time: 914.1975524425507 and batch: 850, loss is 5.541026067733765 and perplexity is 254.93945044657193
At time: 915.2999930381775 and batch: 900, loss is 5.586670665740967 and perplexity is 266.8457205504613
At time: 916.4020259380341 and batch: 950, loss is 5.554877758026123 and perplexity is 258.4953636056489
At time: 917.5022711753845 and batch: 1000, loss is 5.572054252624512 and perplexity is 262.9737592866597
At time: 918.6046526432037 and batch: 1050, loss is 5.540916213989258 and perplexity is 254.91144593154635
At time: 919.7079679965973 and batch: 1100, loss is 5.529498586654663 and perplexity is 252.01751439270697
At time: 920.8103206157684 and batch: 1150, loss is 5.543132047653199 and perplexity is 255.4769135544961
At time: 921.9128410816193 and batch: 1200, loss is 5.538099355697632 and perplexity is 254.19440688426022
At time: 923.0149269104004 and batch: 1250, loss is 5.53541745185852 and perplexity is 253.51359527226208
At time: 924.1176905632019 and batch: 1300, loss is 5.508154125213623 and perplexity is 246.69533782809327
At time: 925.2180345058441 and batch: 1350, loss is 5.505369930267334 and perplexity is 246.00944518772266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.378016357421875 and perplexity of 216.59220749056664
Finished 29 epochs...
Completing Train Step...
At time: 928.5907883644104 and batch: 50, loss is 5.56318733215332 and perplexity is 260.6522991879443
At time: 929.719021320343 and batch: 100, loss is 5.569989166259766 and perplexity is 262.43125611282
At time: 930.8211796283722 and batch: 150, loss is 5.537076225280762 and perplexity is 253.9344658542413
At time: 931.9230930805206 and batch: 200, loss is 5.534379339218139 and perplexity is 253.2505561602377
At time: 933.0246362686157 and batch: 250, loss is 5.554295625686645 and perplexity is 258.344928885595
At time: 934.1249604225159 and batch: 300, loss is 5.569640712738037 and perplexity is 262.3398269477483
At time: 935.2247653007507 and batch: 350, loss is 5.57693193435669 and perplexity is 264.25959498767014
At time: 936.3256919384003 and batch: 400, loss is 5.621311893463135 and perplexity is 276.2515582287561
At time: 937.4541485309601 and batch: 450, loss is 5.590828275680542 and perplexity is 267.9574704803849
At time: 938.555905342102 and batch: 500, loss is 5.6004612922668455 and perplexity is 270.55118181316647
At time: 939.6575179100037 and batch: 550, loss is 5.573481388092041 and perplexity is 263.34932639439353
At time: 940.7580075263977 and batch: 600, loss is 5.520615606307984 and perplexity is 249.78876140522513
At time: 941.8589255809784 and batch: 650, loss is 5.554418210983276 and perplexity is 258.37660011650945
At time: 942.9593713283539 and batch: 700, loss is 5.572215986251831 and perplexity is 263.0162944262274
At time: 944.0607635974884 and batch: 750, loss is 5.55430235862732 and perplexity is 258.3466683125304
At time: 945.1612830162048 and batch: 800, loss is 5.5210170078277585 and perplexity is 249.88904711974845
At time: 946.2631621360779 and batch: 850, loss is 5.514724569320679 and perplexity is 248.32157244812745
At time: 947.3657882213593 and batch: 900, loss is 5.5640003490448 and perplexity is 260.86430007846207
At time: 948.4665424823761 and batch: 950, loss is 5.536748914718628 and perplexity is 253.851364022273
At time: 949.5659115314484 and batch: 1000, loss is 5.555068254470825 and perplexity is 258.5446107439412
At time: 950.6666281223297 and batch: 1050, loss is 5.525690641403198 and perplexity is 251.05967036173428
At time: 951.7679531574249 and batch: 1100, loss is 5.516192655563355 and perplexity is 248.68639766431372
At time: 952.8699729442596 and batch: 1150, loss is 5.531976490020752 and perplexity is 252.64276377378764
At time: 953.972090959549 and batch: 1200, loss is 5.52672082901001 and perplexity is 251.31844219159134
At time: 955.073787689209 and batch: 1250, loss is 5.523442554473877 and perplexity is 250.49590033776153
At time: 956.1740009784698 and batch: 1300, loss is 5.499050064086914 and perplexity is 244.4596009775076
At time: 957.2732639312744 and batch: 1350, loss is 5.4946607494354245 and perplexity is 243.38894231706158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.375413818359375 and perplexity of 216.02925068622824
Finished 30 epochs...
Completing Train Step...
At time: 960.6789608001709 and batch: 50, loss is 5.554724597930909 and perplexity is 258.45577546288575
At time: 961.7805035114288 and batch: 100, loss is 5.561264371871948 and perplexity is 260.15155677754353
At time: 962.8814849853516 and batch: 150, loss is 5.525522212982178 and perplexity is 251.0173883387206
At time: 963.981466293335 and batch: 200, loss is 5.522338218688965 and perplexity is 250.2194214419126
At time: 965.1095056533813 and batch: 250, loss is 5.544912958145142 and perplexity is 255.9323004515857
At time: 966.2107429504395 and batch: 300, loss is 5.560175838470459 and perplexity is 259.8685271900686
At time: 967.311060667038 and batch: 350, loss is 5.571267700195312 and perplexity is 262.76699796244753
At time: 968.4119739532471 and batch: 400, loss is 5.61345440864563 and perplexity is 274.0894214069815
At time: 969.5135097503662 and batch: 450, loss is 5.584320955276489 and perplexity is 266.219446438046
At time: 970.6162712574005 and batch: 500, loss is 5.592828369140625 and perplexity is 268.4939467872074
At time: 971.7168588638306 and batch: 550, loss is 5.5655588722229 and perplexity is 261.2711801201019
At time: 972.8160336017609 and batch: 600, loss is 5.516560707092285 and perplexity is 248.77794391903436
At time: 973.9175608158112 and batch: 650, loss is 5.547691202163696 and perplexity is 256.6443314744427
At time: 975.018759727478 and batch: 700, loss is 5.565927152633667 and perplexity is 261.3674188979786
At time: 976.1199440956116 and batch: 750, loss is 5.546009311676025 and perplexity is 256.213046603249
At time: 977.2195842266083 and batch: 800, loss is 5.513647146224976 and perplexity is 248.05416912993374
At time: 978.3203773498535 and batch: 850, loss is 5.506955327987671 and perplexity is 246.39977733539536
At time: 979.421676158905 and batch: 900, loss is 5.5562935638427735 and perplexity is 258.8616020450981
At time: 980.5237860679626 and batch: 950, loss is 5.5295068359375 and perplexity is 252.01959336503813
At time: 981.6240510940552 and batch: 1000, loss is 5.5476445388793945 and perplexity is 256.632355886451
At time: 982.7238562107086 and batch: 1050, loss is 5.518423557281494 and perplexity is 249.24181188305388
At time: 983.8249604701996 and batch: 1100, loss is 5.507065858840942 and perplexity is 246.42701361822705
At time: 984.9258363246918 and batch: 1150, loss is 5.521801719665527 and perplexity is 250.08521497070325
At time: 986.0263142585754 and batch: 1200, loss is 5.513844604492188 and perplexity is 248.10315431245024
At time: 987.1274538040161 and batch: 1250, loss is 5.514604005813599 and perplexity is 248.2916357331434
At time: 988.2288315296173 and batch: 1300, loss is 5.488744554519653 and perplexity is 241.95325697869623
At time: 989.3280239105225 and batch: 1350, loss is 5.488997859954834 and perplexity is 242.0145528167054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.372858072916666 and perplexity of 215.47783984630942
Finished 31 epochs...
Completing Train Step...
At time: 992.7270247936249 and batch: 50, loss is 5.54714409828186 and perplexity is 256.5039587671698
At time: 993.8287954330444 and batch: 100, loss is 5.553341665267944 and perplexity is 258.09859556386647
At time: 994.9308106899261 and batch: 150, loss is 5.522822418212891 and perplexity is 250.34060690325538
At time: 996.0322780609131 and batch: 200, loss is 5.51958662033081 and perplexity is 249.53186446682437
At time: 997.1339604854584 and batch: 250, loss is 5.542912979125976 and perplexity is 255.4209527331555
At time: 998.23375415802 and batch: 300, loss is 5.5568951225280765 and perplexity is 259.01736933698606
At time: 999.3329048156738 and batch: 350, loss is 5.560528078079224 and perplexity is 259.9600793016096
At time: 1000.4336349964142 and batch: 400, loss is 5.60691198348999 and perplexity is 272.3020650793688
At time: 1001.5342230796814 and batch: 450, loss is 5.577191228866577 and perplexity is 264.328124934171
At time: 1002.6356632709503 and batch: 500, loss is 5.587783012390137 and perplexity is 267.1427106409044
At time: 1003.7362487316132 and batch: 550, loss is 5.56019642829895 and perplexity is 259.8738778935586
At time: 1004.8345255851746 and batch: 600, loss is 5.510670757293701 and perplexity is 247.3169610997264
At time: 1005.9397642612457 and batch: 650, loss is 5.5397108364105225 and perplexity is 254.60436650056855
At time: 1007.0412855148315 and batch: 700, loss is 5.557279434204101 and perplexity is 259.1169318666115
At time: 1008.1424977779388 and batch: 750, loss is 5.539178886413574 and perplexity is 254.4689657249995
At time: 1009.2442171573639 and batch: 800, loss is 5.5077839279174805 and perplexity is 246.60402878328193
At time: 1010.3454835414886 and batch: 850, loss is 5.505178518295288 and perplexity is 245.96236054110366
At time: 1011.4481198787689 and batch: 900, loss is 5.55359070777893 and perplexity is 258.16288109076993
At time: 1012.5485439300537 and batch: 950, loss is 5.525532903671265 and perplexity is 251.02007190191927
At time: 1013.6492183208466 and batch: 1000, loss is 5.54360258102417 and perplexity is 255.5971522537781
At time: 1014.7507462501526 and batch: 1050, loss is 5.517946252822876 and perplexity is 249.1228760415297
At time: 1015.8529350757599 and batch: 1100, loss is 5.504694738388062 and perplexity is 245.84339767138303
At time: 1016.9543781280518 and batch: 1150, loss is 5.517962408065796 and perplexity is 249.12690071461887
At time: 1018.0557932853699 and batch: 1200, loss is 5.5120773601531985 and perplexity is 247.66508262137802
At time: 1019.1565442085266 and batch: 1250, loss is 5.510171613693237 and perplexity is 247.1935452249918
At time: 1020.2575838565826 and batch: 1300, loss is 5.485098476409912 and perplexity is 241.07268280148233
At time: 1021.3566970825195 and batch: 1350, loss is 5.4833195018768315 and perplexity is 240.64420187948403
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.364534098307292 and perplexity of 213.69165218244473
Finished 32 epochs...
Completing Train Step...
At time: 1024.7338871955872 and batch: 50, loss is 5.543345594406128 and perplexity is 255.53147564540546
At time: 1025.8634111881256 and batch: 100, loss is 5.548787641525268 and perplexity is 256.92588074404034
At time: 1026.9657962322235 and batch: 150, loss is 5.519508724212646 and perplexity is 249.51242766025996
At time: 1028.0675070285797 and batch: 200, loss is 5.515534439086914 and perplexity is 248.52276203964442
At time: 1029.1705923080444 and batch: 250, loss is 5.536164379119873 and perplexity is 253.7030222229644
At time: 1030.2731964588165 and batch: 300, loss is 5.549248094558716 and perplexity is 257.04421028570766
At time: 1031.3755028247833 and batch: 350, loss is 5.557359600067139 and perplexity is 259.13770503172043
At time: 1032.4782605171204 and batch: 400, loss is 5.605688524246216 and perplexity is 271.9691183156775
At time: 1033.5803835391998 and batch: 450, loss is 5.574439363479614 and perplexity is 263.60172944606603
At time: 1034.6827290058136 and batch: 500, loss is 5.582671127319336 and perplexity is 265.78059226905754
At time: 1035.7842473983765 and batch: 550, loss is 5.557290420532227 and perplexity is 259.1197786258855
At time: 1036.8859870433807 and batch: 600, loss is 5.507282018661499 and perplexity is 246.48028699484544
At time: 1037.9879710674286 and batch: 650, loss is 5.536033525466919 and perplexity is 253.66982642768392
At time: 1039.091774225235 and batch: 700, loss is 5.553787469863892 and perplexity is 258.21368275526976
At time: 1040.19486618042 and batch: 750, loss is 5.5347995185852055 and perplexity is 253.3569891775473
At time: 1041.2972502708435 and batch: 800, loss is 5.507326259613037 and perplexity is 246.49119175849418
At time: 1042.4002499580383 and batch: 850, loss is 5.501184072494507 and perplexity is 244.98183685099457
At time: 1043.5037882328033 and batch: 900, loss is 5.550538148880005 and perplexity is 257.37602526360376
At time: 1044.606183052063 and batch: 950, loss is 5.519045934677124 and perplexity is 249.39698263519128
At time: 1045.7075719833374 and batch: 1000, loss is 5.539135980606079 and perplexity is 254.45804776276623
At time: 1046.8103423118591 and batch: 1050, loss is 5.509889698028564 and perplexity is 247.12386731449547
At time: 1047.9130382537842 and batch: 1100, loss is 5.50130295753479 and perplexity is 245.01096325785002
At time: 1049.0422537326813 and batch: 1150, loss is 5.516864624023437 and perplexity is 248.8535632387023
At time: 1050.1442484855652 and batch: 1200, loss is 5.512546663284302 and perplexity is 247.78133989793534
At time: 1051.2477288246155 and batch: 1250, loss is 5.510306491851806 and perplexity is 247.22688848377
At time: 1052.350623369217 and batch: 1300, loss is 5.482021541595459 and perplexity is 240.33205788257928
At time: 1053.4506423473358 and batch: 1350, loss is 5.48080267906189 and perplexity is 240.03930459086365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.367820231119792 and perplexity of 214.39502639001157
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 1056.8259420394897 and batch: 50, loss is 5.5333895778656 and perplexity is 253.00002255193527
At time: 1057.9571211338043 and batch: 100, loss is 5.532737531661987 and perplexity is 252.8351086193111
At time: 1059.0611815452576 and batch: 150, loss is 5.50021074295044 and perplexity is 244.74350479805767
At time: 1060.1652252674103 and batch: 200, loss is 5.491677589416504 and perplexity is 242.6639560679427
At time: 1061.2688674926758 and batch: 250, loss is 5.507415103912353 and perplexity is 246.5130920685581
At time: 1062.372712612152 and batch: 300, loss is 5.522787551879883 and perplexity is 250.33187859645273
At time: 1063.474482536316 and batch: 350, loss is 5.533041009902954 and perplexity is 252.9118502174431
At time: 1064.577317237854 and batch: 400, loss is 5.569628620147705 and perplexity is 262.3366545988743
At time: 1065.6818857192993 and batch: 450, loss is 5.539311065673828 and perplexity is 254.50260346770352
At time: 1066.7848873138428 and batch: 500, loss is 5.553286991119385 and perplexity is 258.08448462866477
At time: 1067.886748790741 and batch: 550, loss is 5.523526792526245 and perplexity is 250.5170025133228
At time: 1068.9891242980957 and batch: 600, loss is 5.475041942596436 and perplexity is 238.66047676080083
At time: 1070.0918653011322 and batch: 650, loss is 5.496671180725098 and perplexity is 243.8787512608925
At time: 1071.1946852207184 and batch: 700, loss is 5.513936214447021 and perplexity is 248.12588407233113
At time: 1072.2980773448944 and batch: 750, loss is 5.50146863937378 and perplexity is 245.0515604878342
At time: 1073.4016692638397 and batch: 800, loss is 5.467685928344727 and perplexity is 236.91132816077712
At time: 1074.5052509307861 and batch: 850, loss is 5.453043375015259 and perplexity is 233.46761530708693
At time: 1075.6086311340332 and batch: 900, loss is 5.501114473342896 and perplexity is 244.96478691632706
At time: 1076.7409808635712 and batch: 950, loss is 5.472642850875855 and perplexity is 238.08859466007624
At time: 1077.84436917305 and batch: 1000, loss is 5.494617557525634 and perplexity is 243.37843011084388
At time: 1078.9478087425232 and batch: 1050, loss is 5.460569791793823 and perplexity is 235.23141911932117
At time: 1080.0509898662567 and batch: 1100, loss is 5.452278280258179 and perplexity is 233.28905877371145
At time: 1081.1544137001038 and batch: 1150, loss is 5.462844371795654 and perplexity is 235.76708077274805
At time: 1082.257621049881 and batch: 1200, loss is 5.448823766708374 and perplexity is 232.48454895425488
At time: 1083.3608801364899 and batch: 1250, loss is 5.454326124191284 and perplexity is 233.76728785951926
At time: 1084.4644713401794 and batch: 1300, loss is 5.431824979782104 and perplexity is 228.5659933468051
At time: 1085.5684988498688 and batch: 1350, loss is 5.435240840911865 and perplexity is 229.34807802493586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.309564208984375 and perplexity of 202.26206518836673
Finished 34 epochs...
Completing Train Step...
At time: 1088.9738380908966 and batch: 50, loss is 5.50804482460022 and perplexity is 246.6683753498796
At time: 1090.0815167427063 and batch: 100, loss is 5.510294523239136 and perplexity is 247.22392953860722
At time: 1091.18359541893 and batch: 150, loss is 5.481505851745606 and perplexity is 240.2081530307181
At time: 1092.285829782486 and batch: 200, loss is 5.472795896530151 and perplexity is 238.12503587334004
At time: 1093.3889076709747 and batch: 250, loss is 5.490065135955811 and perplexity is 242.27298702659738
At time: 1094.4909472465515 and batch: 300, loss is 5.509291019439697 and perplexity is 246.9759638240803
At time: 1095.5923328399658 and batch: 350, loss is 5.5178986835479735 and perplexity is 249.11102572881248
At time: 1096.693834066391 and batch: 400, loss is 5.557509536743164 and perplexity is 259.1765621908295
At time: 1097.7969303131104 and batch: 450, loss is 5.5272556400299075 and perplexity is 251.45288601179269
At time: 1098.898586511612 and batch: 500, loss is 5.542674646377564 and perplexity is 255.36008480918645
At time: 1100.0013589859009 and batch: 550, loss is 5.514169912338257 and perplexity is 248.18387734438866
At time: 1101.1033852100372 and batch: 600, loss is 5.466545362472534 and perplexity is 236.64126922442057
At time: 1102.2053492069244 and batch: 650, loss is 5.488740272521973 and perplexity is 241.95222093762933
At time: 1103.3060750961304 and batch: 700, loss is 5.509086656570434 and perplexity is 246.92549626449758
At time: 1104.4363765716553 and batch: 750, loss is 5.495463457107544 and perplexity is 243.5843909219212
At time: 1105.5390722751617 and batch: 800, loss is 5.4621971988677975 and perplexity is 235.61454806363588
At time: 1106.641681432724 and batch: 850, loss is 5.449394445419312 and perplexity is 232.61726080127622
At time: 1107.7438797950745 and batch: 900, loss is 5.50012770652771 and perplexity is 244.7231830166686
At time: 1108.8474688529968 and batch: 950, loss is 5.471657772064209 and perplexity is 237.85417411049661
At time: 1109.9495391845703 and batch: 1000, loss is 5.494355821609497 and perplexity is 243.3147375701472
At time: 1111.0517964363098 and batch: 1050, loss is 5.459892730712891 and perplexity is 235.07220698467515
At time: 1112.1542265415192 and batch: 1100, loss is 5.453589792251587 and perplexity is 233.5952208959868
At time: 1113.2565495967865 and batch: 1150, loss is 5.4642846965789795 and perplexity is 236.10690661331898
At time: 1114.3595275878906 and batch: 1200, loss is 5.450914897918701 and perplexity is 232.97121331266467
At time: 1115.4624371528625 and batch: 1250, loss is 5.455870943069458 and perplexity is 234.12869506136445
At time: 1116.5653703212738 and batch: 1300, loss is 5.432211017608642 and perplexity is 228.65424549933581
At time: 1117.6678767204285 and batch: 1350, loss is 5.434240131378174 and perplexity is 229.11868201525306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.307759602864583 and perplexity of 201.8973909733528
Finished 35 epochs...
Completing Train Step...
At time: 1121.067577123642 and batch: 50, loss is 5.50398666381836 and perplexity is 245.6693838280219
At time: 1122.1707334518433 and batch: 100, loss is 5.504415893554688 and perplexity is 245.77485506694302
At time: 1123.2730054855347 and batch: 150, loss is 5.4752770519256595 and perplexity is 238.71659466206688
At time: 1124.3749959468842 and batch: 200, loss is 5.467349843978882 and perplexity is 236.83171934567915
At time: 1125.4772379398346 and batch: 250, loss is 5.48381664276123 and perplexity is 240.76386569325433
At time: 1126.5797867774963 and batch: 300, loss is 5.5050147438049315 and perplexity is 245.9220814792905
At time: 1127.6804196834564 and batch: 350, loss is 5.513519201278687 and perplexity is 248.02243388281312
At time: 1128.782316684723 and batch: 400, loss is 5.552688026428223 and perplexity is 257.9299474208212
At time: 1129.8847606182098 and batch: 450, loss is 5.523930711746216 and perplexity is 250.61821158433588
At time: 1130.9858865737915 and batch: 500, loss is 5.540330142974853 and perplexity is 254.7620934916889
At time: 1132.0869681835175 and batch: 550, loss is 5.51097113609314 and perplexity is 247.39126103008576
At time: 1133.2174570560455 and batch: 600, loss is 5.463920240402222 and perplexity is 236.02087167176379
At time: 1134.3183481693268 and batch: 650, loss is 5.486607322692871 and perplexity is 241.4366989760157
At time: 1135.4200315475464 and batch: 700, loss is 5.50635009765625 and perplexity is 246.2506938359751
At time: 1136.5229046344757 and batch: 750, loss is 5.494888963699341 and perplexity is 243.44449348392118
At time: 1137.624968290329 and batch: 800, loss is 5.460511665344239 and perplexity is 235.21774634947573
At time: 1138.7272589206696 and batch: 850, loss is 5.447380800247192 and perplexity is 232.1493234651056
At time: 1139.829167842865 and batch: 900, loss is 5.498452625274658 and perplexity is 244.31359494303382
At time: 1140.9315135478973 and batch: 950, loss is 5.4711236572265625 and perplexity is 237.7271665882286
At time: 1142.0333647727966 and batch: 1000, loss is 5.493723011016845 and perplexity is 243.16081413419136
At time: 1143.1362798213959 and batch: 1050, loss is 5.459407453536987 and perplexity is 234.95815948249916
At time: 1144.2389409542084 and batch: 1100, loss is 5.452683572769165 and perplexity is 233.3836282449821
At time: 1145.3404612541199 and batch: 1150, loss is 5.463076581954956 and perplexity is 235.82183464108866
At time: 1146.4433183670044 and batch: 1200, loss is 5.450038204193115 and perplexity is 232.76705841544594
At time: 1147.5466215610504 and batch: 1250, loss is 5.4557522106170655 and perplexity is 234.1008980374614
At time: 1148.6504747867584 and batch: 1300, loss is 5.431769552230835 and perplexity is 228.55332484458583
At time: 1149.7552735805511 and batch: 1350, loss is 5.432390394210816 and perplexity is 228.69526439977156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.307919921875 and perplexity of 201.9297615580202
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 1153.1321425437927 and batch: 50, loss is 5.499096002578735 and perplexity is 244.4708313408387
At time: 1154.261352300644 and batch: 100, loss is 5.499184980392456 and perplexity is 244.4925847887026
At time: 1155.3632004261017 and batch: 150, loss is 5.468409767150879 and perplexity is 237.08287585266513
At time: 1156.4652304649353 and batch: 200, loss is 5.460386972427369 and perplexity is 235.18841819112862
At time: 1157.567617893219 and batch: 250, loss is 5.475600395202637 and perplexity is 238.7937945484133
At time: 1158.6692156791687 and batch: 300, loss is 5.494453659057617 and perplexity is 243.3385440277236
At time: 1159.7714943885803 and batch: 350, loss is 5.502189674377441 and perplexity is 245.22831495606943
At time: 1160.8997967243195 and batch: 400, loss is 5.5436108112335205 and perplexity is 255.59925588050714
At time: 1162.0015678405762 and batch: 450, loss is 5.51183741569519 and perplexity is 247.605663886244
At time: 1163.1035387516022 and batch: 500, loss is 5.525396919250488 and perplexity is 250.98593940363486
At time: 1164.2059907913208 and batch: 550, loss is 5.492410192489624 and perplexity is 242.8417975635525
At time: 1165.308753490448 and batch: 600, loss is 5.450890130996704 and perplexity is 232.96544340424876
At time: 1166.4097425937653 and batch: 650, loss is 5.4710492992401125 and perplexity is 237.7094903319902
At time: 1167.511679649353 and batch: 700, loss is 5.488134279251098 and perplexity is 241.80564393669167
At time: 1168.6132175922394 and batch: 750, loss is 5.477160024642944 and perplexity is 239.16651495786368
At time: 1169.7151980400085 and batch: 800, loss is 5.4398604679107665 and perplexity is 230.4100316244949
At time: 1170.8151350021362 and batch: 850, loss is 5.423998212814331 and perplexity is 226.78404313125597
At time: 1171.917004585266 and batch: 900, loss is 5.470083694458008 and perplexity is 237.48006769499776
At time: 1173.0183553695679 and batch: 950, loss is 5.443864612579346 and perplexity is 231.33447629416082
At time: 1174.119913816452 and batch: 1000, loss is 5.465422983169556 and perplexity is 236.37581695854385
At time: 1175.22225522995 and batch: 1050, loss is 5.434410057067871 and perplexity is 229.15761847337552
At time: 1176.3243927955627 and batch: 1100, loss is 5.424615249633789 and perplexity is 226.92402041706208
At time: 1177.4262783527374 and batch: 1150, loss is 5.435783948898315 and perplexity is 229.4726726288879
At time: 1178.5284349918365 and batch: 1200, loss is 5.42329776763916 and perplexity is 226.6252489622361
At time: 1179.630556344986 and batch: 1250, loss is 5.428510198593139 and perplexity is 227.80960142107403
At time: 1180.7322928905487 and batch: 1300, loss is 5.403096771240234 and perplexity is 222.09312396592156
At time: 1181.8337078094482 and batch: 1350, loss is 5.408852453231812 and perplexity is 223.37510716467773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.29018798828125 and perplexity of 198.38071515392883
Finished 37 epochs...
Completing Train Step...
At time: 1185.2056562900543 and batch: 50, loss is 5.484923095703125 and perplexity is 241.03040701127279
At time: 1186.3345520496368 and batch: 100, loss is 5.486511316299438 and perplexity is 241.41352062195764
At time: 1187.436202287674 and batch: 150, loss is 5.456095771789551 and perplexity is 234.18133983401876
At time: 1188.564953804016 and batch: 200, loss is 5.450218915939331 and perplexity is 232.80912595796883
At time: 1189.6660811901093 and batch: 250, loss is 5.465014209747315 and perplexity is 236.2792125529126
At time: 1190.7673358917236 and batch: 300, loss is 5.486032009124756 and perplexity is 241.2978371156402
At time: 1191.8691017627716 and batch: 350, loss is 5.494486713409424 and perplexity is 243.34658755850214
At time: 1192.9699873924255 and batch: 400, loss is 5.537570705413819 and perplexity is 254.06006245265678
At time: 1194.0717101097107 and batch: 450, loss is 5.5063534927368165 and perplexity is 246.25152987833957
At time: 1195.1716468334198 and batch: 500, loss is 5.5190064811706545 and perplexity is 249.38714324382386
At time: 1196.2722902297974 and batch: 550, loss is 5.487615928649903 and perplexity is 241.68033631523076
At time: 1197.3738572597504 and batch: 600, loss is 5.448610639572143 and perplexity is 232.43500546783653
At time: 1198.4755423069 and batch: 650, loss is 5.467892236709595 and perplexity is 236.96020999170065
At time: 1199.5767045021057 and batch: 700, loss is 5.485546541213989 and perplexity is 241.18072318861005
At time: 1200.6780529022217 and batch: 750, loss is 5.475428981781006 and perplexity is 238.75286559501168
At time: 1201.7787837982178 and batch: 800, loss is 5.438187227249146 and perplexity is 230.02482255434876
At time: 1202.877961397171 and batch: 850, loss is 5.422577028274536 and perplexity is 226.4619700721212
At time: 1203.9789295196533 and batch: 900, loss is 5.469798946380616 and perplexity is 237.41245532900498
At time: 1205.0802733898163 and batch: 950, loss is 5.44249831199646 and perplexity is 231.0186196910252
At time: 1206.1821608543396 and batch: 1000, loss is 5.465708780288696 and perplexity is 236.44338214057234
At time: 1207.2839906215668 and batch: 1050, loss is 5.436516437530518 and perplexity is 229.6408203286108
At time: 1208.385869026184 and batch: 1100, loss is 5.427249240875244 and perplexity is 227.52252418012083
At time: 1209.488614320755 and batch: 1150, loss is 5.439349308013916 and perplexity is 230.2922853526462
At time: 1210.590666294098 and batch: 1200, loss is 5.427290935516357 and perplexity is 227.53201084788188
At time: 1211.693308353424 and batch: 1250, loss is 5.43078610420227 and perplexity is 228.32866501658492
At time: 1212.7956323623657 and batch: 1300, loss is 5.404830236434936 and perplexity is 222.47844854318228
At time: 1213.8981051445007 and batch: 1350, loss is 5.408836603164673 and perplexity is 223.37156668229056
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.288941650390625 and perplexity of 198.13361976602113
Finished 38 epochs...
Completing Train Step...
At time: 1217.3092319965363 and batch: 50, loss is 5.4823519802093506 and perplexity is 240.41148599699505
At time: 1218.416874885559 and batch: 100, loss is 5.482109127044677 and perplexity is 240.35310839567643
At time: 1219.525542497635 and batch: 150, loss is 5.451830196380615 and perplexity is 233.18454912395603
At time: 1220.63050365448 and batch: 200, loss is 5.446070079803467 and perplexity is 231.84523992863114
At time: 1221.732729434967 and batch: 250, loss is 5.462061729431152 and perplexity is 235.582631655442
At time: 1222.8341739177704 and batch: 300, loss is 5.483862819671631 and perplexity is 240.77498368140348
At time: 1223.936184167862 and batch: 350, loss is 5.492961130142212 and perplexity is 242.97562511538598
At time: 1225.0369861125946 and batch: 400, loss is 5.5363884544372555 and perplexity is 253.7598771778481
At time: 1226.1392595767975 and batch: 450, loss is 5.5041352558135985 and perplexity is 245.70589104420688
At time: 1227.24085521698 and batch: 500, loss is 5.516859159469605 and perplexity is 248.8522033687251
At time: 1228.3433170318604 and batch: 550, loss is 5.4868154621124265 and perplexity is 241.48695670052535
At time: 1229.4449286460876 and batch: 600, loss is 5.447180900573731 and perplexity is 232.10292152917108
At time: 1230.5467796325684 and batch: 650, loss is 5.4668872261047365 and perplexity is 236.72218209804313
At time: 1231.64861369133 and batch: 700, loss is 5.48515209197998 and perplexity is 241.08560839730205
At time: 1232.750898361206 and batch: 750, loss is 5.4748810768127445 and perplexity is 238.6220875440091
At time: 1233.8527178764343 and batch: 800, loss is 5.437245016098022 and perplexity is 229.80819267307407
At time: 1234.953129529953 and batch: 850, loss is 5.421690044403076 and perplexity is 226.26119101422455
At time: 1236.0545635223389 and batch: 900, loss is 5.468992681503296 and perplexity is 237.2211151506329
At time: 1237.155781507492 and batch: 950, loss is 5.441699075698852 and perplexity is 230.8340549899737
At time: 1238.2579758167267 and batch: 1000, loss is 5.465778913497925 and perplexity is 236.45996525526945
At time: 1239.3597478866577 and batch: 1050, loss is 5.437593040466308 and perplexity is 229.88818544306525
At time: 1240.4620633125305 and batch: 1100, loss is 5.428246774673462 and perplexity is 227.74959882633388
At time: 1241.563810825348 and batch: 1150, loss is 5.440478572845459 and perplexity is 230.55249322561826
At time: 1242.6661500930786 and batch: 1200, loss is 5.427961978912354 and perplexity is 227.68474594134574
At time: 1243.767954826355 and batch: 1250, loss is 5.431527090072632 and perplexity is 228.49791602972132
At time: 1244.869785785675 and batch: 1300, loss is 5.404881753921509 and perplexity is 222.48991036890754
At time: 1245.9714670181274 and batch: 1350, loss is 5.407967004776001 and perplexity is 223.17740756029366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2884903971354165 and perplexity of 198.0442314950264
Finished 39 epochs...
Completing Train Step...
At time: 1249.3748197555542 and batch: 50, loss is 5.480557765960693 and perplexity is 239.98052301884954
At time: 1250.4777882099152 and batch: 100, loss is 5.479425725936889 and perplexity is 239.70900917312474
At time: 1251.5812163352966 and batch: 150, loss is 5.449070768356323 and perplexity is 232.5419801134728
At time: 1252.6841359138489 and batch: 200, loss is 5.443100318908692 and perplexity is 231.1577363673323
At time: 1253.7872385978699 and batch: 250, loss is 5.459945192337036 and perplexity is 235.0845395779361
At time: 1254.8901717662811 and batch: 300, loss is 5.480749530792236 and perplexity is 240.02654725619388
At time: 1255.9934163093567 and batch: 350, loss is 5.490927810668945 and perplexity is 242.48207998281651
At time: 1257.0956509113312 and batch: 400, loss is 5.535300140380859 and perplexity is 253.4838569621502
At time: 1258.197860956192 and batch: 450, loss is 5.502716407775879 and perplexity is 245.3575189248349
At time: 1259.3001022338867 and batch: 500, loss is 5.515863714218139 and perplexity is 248.6046078788877
At time: 1260.4023513793945 and batch: 550, loss is 5.486461868286133 and perplexity is 241.4015834981138
At time: 1261.5050792694092 and batch: 600, loss is 5.444976692199707 and perplexity is 231.59188175188808
At time: 1262.6083652973175 and batch: 650, loss is 5.465595531463623 and perplexity is 236.41660672151957
At time: 1263.7118818759918 and batch: 700, loss is 5.4828778266906735 and perplexity is 240.53793877543666
At time: 1264.8147084712982 and batch: 750, loss is 5.473340845108032 and perplexity is 238.25483713729187
At time: 1265.9175946712494 and batch: 800, loss is 5.434951992034912 and perplexity is 229.28184065692224
At time: 1267.0190870761871 and batch: 850, loss is 5.420349102020264 and perplexity is 225.9579911258312
At time: 1268.1220262050629 and batch: 900, loss is 5.467075958251953 and perplexity is 236.76686340003062
At time: 1269.2242765426636 and batch: 950, loss is 5.439803638458252 and perplexity is 230.39693792060137
At time: 1270.3289453983307 and batch: 1000, loss is 5.4648034954071045 and perplexity is 236.22943037962725
At time: 1271.431746006012 and batch: 1050, loss is 5.436886425018311 and perplexity is 229.72580027860857
At time: 1272.5634093284607 and batch: 1100, loss is 5.426356897354126 and perplexity is 227.31958648829382
At time: 1273.6658220291138 and batch: 1150, loss is 5.439117784500122 and perplexity is 230.23897344526
At time: 1274.7690784931183 and batch: 1200, loss is 5.426566638946533 and perplexity is 227.3672698607676
At time: 1275.8716490268707 and batch: 1250, loss is 5.430199718475341 and perplexity is 228.19481559390132
At time: 1276.97531914711 and batch: 1300, loss is 5.402929468154907 and perplexity is 222.05597020910793
At time: 1278.0778579711914 and batch: 1350, loss is 5.405186681747437 and perplexity is 222.5577640782835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.287227783203125 and perplexity of 197.79433588316994
Finished 40 epochs...
Completing Train Step...
At time: 1281.460652589798 and batch: 50, loss is 5.477884263992309 and perplexity is 239.33979149831723
At time: 1282.5916917324066 and batch: 100, loss is 5.476942739486694 and perplexity is 239.11455326974755
At time: 1283.6950252056122 and batch: 150, loss is 5.446226568222046 and perplexity is 231.8815238625163
At time: 1284.7980530261993 and batch: 200, loss is 5.4402854633331295 and perplexity is 230.50797564460768
At time: 1285.901486158371 and batch: 250, loss is 5.45817268371582 and perplexity is 234.66821927947782
At time: 1287.0046598911285 and batch: 300, loss is 5.478257246017456 and perplexity is 239.42907758846678
At time: 1288.1077978610992 and batch: 350, loss is 5.489652185440064 and perplexity is 242.17296092598957
At time: 1289.2105474472046 and batch: 400, loss is 5.534216938018798 and perplexity is 253.20943130563677
At time: 1290.314302444458 and batch: 450, loss is 5.501476221084594 and perplexity is 245.0534184049436
At time: 1291.4176115989685 and batch: 500, loss is 5.51434250831604 and perplexity is 248.22671658020238
At time: 1292.5207481384277 and batch: 550, loss is 5.485321111679077 and perplexity is 241.12636005810973
At time: 1293.6241822242737 and batch: 600, loss is 5.443167486190796 and perplexity is 231.17326312566067
At time: 1294.7276346683502 and batch: 650, loss is 5.46435658454895 and perplexity is 236.12388046963216
At time: 1295.8313970565796 and batch: 700, loss is 5.481196660995483 and perplexity is 240.13389437233363
At time: 1296.934989452362 and batch: 750, loss is 5.472131071090698 and perplexity is 237.96677690484398
At time: 1298.0391058921814 and batch: 800, loss is 5.433558044433593 and perplexity is 228.9624564392607
At time: 1299.1414024829865 and batch: 850, loss is 5.419315776824951 and perplexity is 225.7246236335384
At time: 1300.2716164588928 and batch: 900, loss is 5.465983552932739 and perplexity is 236.50835924040555
At time: 1301.3742773532867 and batch: 950, loss is 5.438932342529297 and perplexity is 230.19628143483112
At time: 1302.4777307510376 and batch: 1000, loss is 5.464303770065308 and perplexity is 236.1114100381221
At time: 1303.5811667442322 and batch: 1050, loss is 5.436624050140381 and perplexity is 229.66553390633993
At time: 1304.6852295398712 and batch: 1100, loss is 5.425797996520996 and perplexity is 227.19257287933084
At time: 1305.78795170784 and batch: 1150, loss is 5.438486976623535 and perplexity is 230.09378268586525
At time: 1306.8915240764618 and batch: 1200, loss is 5.425571565628052 and perplexity is 227.1411352859334
At time: 1307.9945878982544 and batch: 1250, loss is 5.429000253677368 and perplexity is 227.92126803364744
At time: 1309.0980610847473 and batch: 1300, loss is 5.401626415252686 and perplexity is 221.76680797043372
At time: 1310.2014908790588 and batch: 1350, loss is 5.4036010646820065 and perplexity is 222.20515231700756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.286549479166666 and perplexity of 197.66021667869288
Finished 41 epochs...
Completing Train Step...
At time: 1313.581731557846 and batch: 50, loss is 5.4765287780761716 and perplexity is 239.01558955699178
At time: 1314.7128143310547 and batch: 100, loss is 5.4751508426666256 and perplexity is 238.6864683186872
At time: 1315.8175220489502 and batch: 150, loss is 5.44391429901123 and perplexity is 231.345970764417
At time: 1316.9208483695984 and batch: 200, loss is 5.43856367111206 and perplexity is 230.11143028756942
At time: 1318.02449965477 and batch: 250, loss is 5.457208604812622 and perplexity is 234.44208962095058
At time: 1319.1283919811249 and batch: 300, loss is 5.476536874771118 and perplexity is 239.0175248011424
At time: 1320.2316870689392 and batch: 350, loss is 5.488767786026001 and perplexity is 241.9588779826136
At time: 1321.3346583843231 and batch: 400, loss is 5.533348836898804 and perplexity is 252.98971529638214
At time: 1322.4383642673492 and batch: 450, loss is 5.500245046615601 and perplexity is 244.75190054129814
At time: 1323.5416388511658 and batch: 500, loss is 5.513476676940918 and perplexity is 248.01188711730924
At time: 1324.6456334590912 and batch: 550, loss is 5.484537839889526 and perplexity is 240.93756653053347
At time: 1325.7499372959137 and batch: 600, loss is 5.441686239242554 and perplexity is 230.83109191773227
At time: 1326.853707075119 and batch: 650, loss is 5.463366441726684 and perplexity is 235.89019981192394
At time: 1327.9572744369507 and batch: 700, loss is 5.479835376739502 and perplexity is 239.8072262771103
At time: 1329.0878739356995 and batch: 750, loss is 5.470968770980835 and perplexity is 237.6903487712486
At time: 1330.1925756931305 and batch: 800, loss is 5.432625923156738 and perplexity is 228.74913509813848
At time: 1331.2947940826416 and batch: 850, loss is 5.418148241043091 and perplexity is 225.46123584585212
At time: 1332.39834856987 and batch: 900, loss is 5.465047540664673 and perplexity is 236.2870880870684
At time: 1333.501377105713 and batch: 950, loss is 5.438272867202759 and perplexity is 230.0445227130305
At time: 1334.604686498642 and batch: 1000, loss is 5.463960208892822 and perplexity is 236.03030525827663
At time: 1335.7085003852844 and batch: 1050, loss is 5.435936079025269 and perplexity is 229.50758499125104
At time: 1336.8119959831238 and batch: 1100, loss is 5.4255380439758305 and perplexity is 227.13352126740915
At time: 1337.915066242218 and batch: 1150, loss is 5.437806968688965 and perplexity is 229.93737027481106
At time: 1339.019044160843 and batch: 1200, loss is 5.425097074508667 and perplexity is 227.0333843998341
At time: 1340.1241915225983 and batch: 1250, loss is 5.428307294845581 and perplexity is 227.76338268835153
At time: 1341.2277553081512 and batch: 1300, loss is 5.400872478485107 and perplexity is 221.59967283265595
At time: 1342.3305592536926 and batch: 1350, loss is 5.402539339065552 and perplexity is 221.96935661200473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.286662190755209 and perplexity of 197.68249653128157
Annealing...
Finished 42 epochs...
Completing Train Step...
At time: 1345.7361769676208 and batch: 50, loss is 5.47542064666748 and perplexity is 238.75087557106593
At time: 1346.8399391174316 and batch: 100, loss is 5.476332960128784 and perplexity is 238.96879059703872
At time: 1347.9438469409943 and batch: 150, loss is 5.443653087615967 and perplexity is 231.28554845244687
At time: 1349.0474293231964 and batch: 200, loss is 5.438079881668091 and perplexity is 230.00013173136364
At time: 1350.1501903533936 and batch: 250, loss is 5.456827144622803 and perplexity is 234.3526763518278
At time: 1351.2531762123108 and batch: 300, loss is 5.475540494918823 and perplexity is 238.7794911607396
At time: 1352.3571963310242 and batch: 350, loss is 5.485171117782593 and perplexity is 241.09019528813465
At time: 1353.4607422351837 and batch: 400, loss is 5.526811571121216 and perplexity is 251.34124839234644
At time: 1354.5644614696503 and batch: 450, loss is 5.4949725723266605 and perplexity is 243.46484839476102
At time: 1355.6679129600525 and batch: 500, loss is 5.506045274734497 and perplexity is 246.17564241927357
At time: 1356.7992570400238 and batch: 550, loss is 5.475092849731445 and perplexity is 238.67262659116668
At time: 1357.9023170471191 and batch: 600, loss is 5.43736198425293 and perplexity is 229.83507448548104
At time: 1359.005648136139 and batch: 650, loss is 5.455545883178711 and perplexity is 234.0526015814663
At time: 1360.1097207069397 and batch: 700, loss is 5.47077244758606 and perplexity is 237.64368917540762
At time: 1361.213700056076 and batch: 750, loss is 5.459305267333985 and perplexity is 234.93415122699435
At time: 1362.3165922164917 and batch: 800, loss is 5.424269790649414 and perplexity is 226.84564101465233
At time: 1363.4191122055054 and batch: 850, loss is 5.403975515365601 and perplexity is 222.28837276819587
At time: 1364.522311449051 and batch: 900, loss is 5.45059645652771 and perplexity is 232.89703744639627
At time: 1365.6254725456238 and batch: 950, loss is 5.423105134963989 and perplexity is 226.58159773872814
At time: 1366.7288961410522 and batch: 1000, loss is 5.450774383544922 and perplexity is 232.93847980833525
At time: 1367.8329212665558 and batch: 1050, loss is 5.420887269973755 and perplexity is 226.07962720287387
At time: 1368.934787273407 and batch: 1100, loss is 5.410106639862061 and perplexity is 223.65543699382988
At time: 1370.0379965305328 and batch: 1150, loss is 5.419081478118897 and perplexity is 225.67174284148894
At time: 1371.1416466236115 and batch: 1200, loss is 5.40612491607666 and perplexity is 222.7666734004008
At time: 1372.2442517280579 and batch: 1250, loss is 5.407836980819702 and perplexity is 223.14839103726862
At time: 1373.347764492035 and batch: 1300, loss is 5.386374025344849 and perplexity is 218.4099989028237
At time: 1374.4512548446655 and batch: 1350, loss is 5.390482482910156 and perplexity is 219.3091729595881
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.269497477213542 and perplexity of 194.31828853795034
Finished 43 epochs...
Completing Train Step...
At time: 1377.8542642593384 and batch: 50, loss is 5.468587989807129 and perplexity is 237.1251331580437
At time: 1378.9558033943176 and batch: 100, loss is 5.468305826187134 and perplexity is 237.0582345107061
At time: 1380.058307170868 and batch: 150, loss is 5.436208982467651 and perplexity is 229.57022694846205
At time: 1381.1601572036743 and batch: 200, loss is 5.431876649856568 and perplexity is 228.57780367381875
At time: 1382.2627811431885 and batch: 250, loss is 5.450069417953491 and perplexity is 232.77432406402437
At time: 1383.3651781082153 and batch: 300, loss is 5.468932390213013 and perplexity is 237.20681321466353
At time: 1384.4940156936646 and batch: 350, loss is 5.478837537765503 and perplexity is 239.5680566267283
At time: 1385.596304178238 and batch: 400, loss is 5.521180086135864 and perplexity is 249.92980192578892
At time: 1386.6982915401459 and batch: 450, loss is 5.490093126296997 and perplexity is 242.27976842507084
At time: 1387.8004415035248 and batch: 500, loss is 5.501826982498169 and perplexity is 245.13938876504577
At time: 1388.9018864631653 and batch: 550, loss is 5.471749143600464 and perplexity is 237.8759082047135
At time: 1390.0058901309967 and batch: 600, loss is 5.434229936599731 and perplexity is 229.11634621295931
At time: 1391.1083340644836 and batch: 650, loss is 5.452355318069458 and perplexity is 233.3070315444772
At time: 1392.2110702991486 and batch: 700, loss is 5.468845510482788 and perplexity is 237.18620564592706
At time: 1393.313336610794 and batch: 750, loss is 5.458398475646972 and perplexity is 234.72121145226635
At time: 1394.4160652160645 and batch: 800, loss is 5.42355978012085 and perplexity is 226.6846353857826
At time: 1395.5178785324097 and batch: 850, loss is 5.403994340896606 and perplexity is 222.2925575042393
At time: 1396.6205251216888 and batch: 900, loss is 5.4513021755218505 and perplexity is 233.06145531898522
At time: 1397.7222166061401 and batch: 950, loss is 5.424457225799561 and perplexity is 226.8881638464482
At time: 1398.8242754936218 and batch: 1000, loss is 5.452577419281006 and perplexity is 233.35885507366729
At time: 1399.926635980606 and batch: 1050, loss is 5.423109378814697 and perplexity is 226.58255931924256
At time: 1401.0277335643768 and batch: 1100, loss is 5.412205581665039 and perplexity is 224.12536974822467
At time: 1402.1304292678833 and batch: 1150, loss is 5.420814037322998 and perplexity is 226.0630713987118
At time: 1403.233294725418 and batch: 1200, loss is 5.408462734222412 and perplexity is 223.2880706001924
At time: 1404.3352086544037 and batch: 1250, loss is 5.410441055297851 and perplexity is 223.73024333175894
At time: 1405.4374940395355 and batch: 1300, loss is 5.388618364334106 and perplexity is 218.90073546261323
At time: 1406.5390751361847 and batch: 1350, loss is 5.391046133041382 and perplexity is 219.43282144767545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.268761393229167 and perplexity of 194.1753065877041
Finished 44 epochs...
Completing Train Step...
At time: 1409.9116961956024 and batch: 50, loss is 5.466639928817749 and perplexity is 236.66364858252854
At time: 1411.0409188270569 and batch: 100, loss is 5.466048526763916 and perplexity is 236.5237265938432
At time: 1412.142672777176 and batch: 150, loss is 5.433773345947266 and perplexity is 229.0117577098349
At time: 1413.2716929912567 and batch: 200, loss is 5.4295716476440425 and perplexity is 228.05153808529505
At time: 1414.3733131885529 and batch: 250, loss is 5.4476856517791745 and perplexity is 232.2201053304445
At time: 1415.4758269786835 and batch: 300, loss is 5.466381597518921 and perplexity is 236.60251885100627
At time: 1416.5776557922363 and batch: 350, loss is 5.476217460632324 and perplexity is 238.9411914159317
At time: 1417.6804625988007 and batch: 400, loss is 5.519036321640015 and perplexity is 249.39458518426565
At time: 1418.781986951828 and batch: 450, loss is 5.4883154678344725 and perplexity is 241.84946032816353
At time: 1419.8843462467194 and batch: 500, loss is 5.5001616859436036 and perplexity is 244.73149870876347
At time: 1420.9860169887543 and batch: 550, loss is 5.470507946014404 and perplexity is 237.5808403582985
At time: 1422.088097333908 and batch: 600, loss is 5.433044643402099 and perplexity is 228.8449370478211
At time: 1423.1900279521942 and batch: 650, loss is 5.451216230392456 and perplexity is 233.0414256827881
At time: 1424.293003320694 and batch: 700, loss is 5.468201093673706 and perplexity is 237.03340810606554
At time: 1425.3946990966797 and batch: 750, loss is 5.4581777954101565 and perplexity is 234.66941883475107
At time: 1426.496734380722 and batch: 800, loss is 5.423632507324219 and perplexity is 226.70112212487086
At time: 1427.5972588062286 and batch: 850, loss is 5.404122848510742 and perplexity is 222.3211256260156
At time: 1428.6997165679932 and batch: 900, loss is 5.451724672317505 and perplexity is 233.1599438411256
At time: 1429.801956653595 and batch: 950, loss is 5.425229387283325 and perplexity is 227.0634258042511
At time: 1430.9040937423706 and batch: 1000, loss is 5.453339214324951 and perplexity is 233.53669442289006
At time: 1432.006123304367 and batch: 1050, loss is 5.424003925323486 and perplexity is 226.78533864087896
At time: 1433.1060192584991 and batch: 1100, loss is 5.412737331390381 and perplexity is 224.24458004424255
At time: 1434.208169221878 and batch: 1150, loss is 5.421210536956787 and perplexity is 226.1527230959926
At time: 1435.310801744461 and batch: 1200, loss is 5.40912691116333 and perplexity is 223.43642264841841
At time: 1436.4135437011719 and batch: 1250, loss is 5.411301937103271 and perplexity is 223.9229315565585
At time: 1437.515516757965 and batch: 1300, loss is 5.389559640884399 and perplexity is 219.10687859537427
At time: 1438.61749625206 and batch: 1350, loss is 5.390972356796265 and perplexity is 219.41663311521825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2685335286458335 and perplexity of 194.13106595300314
Finished 45 epochs...
Completing Train Step...
At time: 1441.9950239658356 and batch: 50, loss is 5.4655052852630615 and perplexity is 236.39527198371732
At time: 1443.1238582134247 and batch: 100, loss is 5.464757938385009 and perplexity is 236.21866871538444
At time: 1444.2261335849762 and batch: 150, loss is 5.4323693466186525 and perplexity is 228.69045096577256
At time: 1445.3282470703125 and batch: 200, loss is 5.428132123947144 and perplexity is 227.72348866621277
At time: 1446.430181503296 and batch: 250, loss is 5.446320314407348 and perplexity is 231.90326288978008
At time: 1447.5322241783142 and batch: 300, loss is 5.4647202301025395 and perplexity is 236.20976148303916
At time: 1448.6341292858124 and batch: 350, loss is 5.474716482162475 and perplexity is 238.58281485708903
At time: 1449.737769126892 and batch: 400, loss is 5.517848072052002 and perplexity is 249.09841816618373
At time: 1450.8407535552979 and batch: 450, loss is 5.487278041839599 and perplexity is 241.59868951174593
At time: 1451.9427580833435 and batch: 500, loss is 5.499151268005371 and perplexity is 244.48434249897932
At time: 1453.044866323471 and batch: 550, loss is 5.469754047393799 and perplexity is 237.40179598960165
At time: 1454.14688205719 and batch: 600, loss is 5.432257013320923 and perplexity is 228.66476285609835
At time: 1455.2488069534302 and batch: 650, loss is 5.450421352386474 and perplexity is 232.8562597809311
At time: 1456.3502848148346 and batch: 700, loss is 5.467682504653931 and perplexity is 236.91051705103197
At time: 1457.4525439739227 and batch: 750, loss is 5.458076248168945 and perplexity is 234.6455900125678
At time: 1458.5551371574402 and batch: 800, loss is 5.423657360076905 and perplexity is 226.7067563418053
At time: 1459.6562037467957 and batch: 850, loss is 5.404026184082031 and perplexity is 222.29963612006884
At time: 1460.7591950893402 and batch: 900, loss is 5.451712875366211 and perplexity is 233.1571932808485
At time: 1461.8614003658295 and batch: 950, loss is 5.425403852462768 and perplexity is 227.1030439214694
At time: 1462.963247537613 and batch: 1000, loss is 5.45364972114563 and perplexity is 233.60922041871257
At time: 1464.0649764537811 and batch: 1050, loss is 5.424344253540039 and perplexity is 226.86253322572162
At time: 1465.165913105011 and batch: 1100, loss is 5.412809000015259 and perplexity is 224.2606519208485
At time: 1466.2687993049622 and batch: 1150, loss is 5.421158514022827 and perplexity is 226.1409582738371
At time: 1467.370626449585 and batch: 1200, loss is 5.409259023666382 and perplexity is 223.46594334347103
At time: 1468.4998829364777 and batch: 1250, loss is 5.411612968444825 and perplexity is 223.9925894386958
At time: 1469.6017832756042 and batch: 1300, loss is 5.390048284530639 and perplexity is 219.21396994206958
At time: 1470.7040123939514 and batch: 1350, loss is 5.39075267791748 and perplexity is 219.36843720927388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.268380533854167 and perplexity of 194.10136718294814
Finished 46 epochs...
Completing Train Step...
At time: 1474.1076061725616 and batch: 50, loss is 5.4646198940277095 and perplexity is 236.18606231169622
At time: 1475.209928035736 and batch: 100, loss is 5.463814563751221 and perplexity is 235.99593109432084
At time: 1476.3131730556488 and batch: 150, loss is 5.431423921585083 and perplexity is 228.47434346131038
At time: 1477.41601228714 and batch: 200, loss is 5.427109708786011 and perplexity is 227.49077970171263
At time: 1478.519386291504 and batch: 250, loss is 5.445365133285523 and perplexity is 231.68185902820602
At time: 1479.62242603302 and batch: 300, loss is 5.463565759658813 and perplexity is 235.9372216447515
At time: 1480.7262523174286 and batch: 350, loss is 5.473390474319458 and perplexity is 238.26666183040007
At time: 1481.8295845985413 and batch: 400, loss is 5.516903848648071 and perplexity is 248.86332461775103
At time: 1482.9323694705963 and batch: 450, loss is 5.486440191268921 and perplexity is 241.3963506885493
At time: 1484.035270690918 and batch: 500, loss is 5.498389263153076 and perplexity is 244.29811520574648
At time: 1485.1386754512787 and batch: 550, loss is 5.469220275878906 and perplexity is 237.2751114866154
At time: 1486.242346048355 and batch: 600, loss is 5.43159743309021 and perplexity is 228.51398982797824
At time: 1487.3462941646576 and batch: 650, loss is 5.44981348991394 and perplexity is 232.71475821022005
At time: 1488.4494054317474 and batch: 700, loss is 5.467372417449951 and perplexity is 236.8370655199847
At time: 1489.5527682304382 and batch: 750, loss is 5.458045854568481 and perplexity is 234.63845839663261
At time: 1490.6557943820953 and batch: 800, loss is 5.423634777069092 and perplexity is 226.70163667916444
At time: 1491.7576365470886 and batch: 850, loss is 5.403874492645263 and perplexity is 222.2659177263332
At time: 1492.8606188297272 and batch: 900, loss is 5.451727380752564 and perplexity is 233.1605753405469
At time: 1493.9647340774536 and batch: 950, loss is 5.4254717445373535 and perplexity is 227.1184629416746
At time: 1495.0681490898132 and batch: 1000, loss is 5.4538053607940675 and perplexity is 233.645582105237
At time: 1496.1714441776276 and batch: 1050, loss is 5.424478168487549 and perplexity is 226.89291554422834
At time: 1497.3019196987152 and batch: 1100, loss is 5.412715730667114 and perplexity is 224.2397362514398
At time: 1498.4052727222443 and batch: 1150, loss is 5.420922088623047 and perplexity is 226.08749912716954
At time: 1499.5088739395142 and batch: 1200, loss is 5.409208326339722 and perplexity is 223.45461450471723
At time: 1500.6125555038452 and batch: 1250, loss is 5.411650114059448 and perplexity is 224.00090993563558
At time: 1501.7161448001862 and batch: 1300, loss is 5.390233173370361 and perplexity is 219.25450390564626
At time: 1502.8191204071045 and batch: 1350, loss is 5.390396089553833 and perplexity is 219.29022692248134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.268212890625 and perplexity of 194.06883013035232
Finished 47 epochs...
Completing Train Step...
At time: 1506.225543498993 and batch: 50, loss is 5.46385009765625 and perplexity is 236.00431710031648
At time: 1507.3298933506012 and batch: 100, loss is 5.463025054931641 and perplexity is 235.8096837569689
At time: 1508.4342319965363 and batch: 150, loss is 5.430579195022583 and perplexity is 228.28142660700604
At time: 1509.537685394287 and batch: 200, loss is 5.426236543655396 and perplexity is 227.29222938156354
At time: 1510.642043352127 and batch: 250, loss is 5.444483461380005 and perplexity is 231.477681664032
At time: 1511.7457609176636 and batch: 300, loss is 5.462441453933716 and perplexity is 235.67210513962195
At time: 1512.849356174469 and batch: 350, loss is 5.47231309890747 and perplexity is 238.0100974203582
At time: 1513.9536979198456 and batch: 400, loss is 5.516140718460083 and perplexity is 248.67348194860114
At time: 1515.057535648346 and batch: 450, loss is 5.485725202560425 and perplexity is 241.2238167108079
At time: 1516.1611976623535 and batch: 500, loss is 5.497679424285889 and perplexity is 244.12476444122697
At time: 1517.2649478912354 and batch: 550, loss is 5.468708820343018 and perplexity is 237.15378684604127
At time: 1518.3689551353455 and batch: 600, loss is 5.430922470092773 and perplexity is 228.35980338137446
At time: 1519.4721536636353 and batch: 650, loss is 5.449341945648193 and perplexity is 232.6050487688931
At time: 1520.5766205787659 and batch: 700, loss is 5.466993913650513 and perplexity is 236.74743875394338
At time: 1521.680144071579 and batch: 750, loss is 5.457780294418335 and perplexity is 234.5761560452677
At time: 1522.7837390899658 and batch: 800, loss is 5.423649272918701 and perplexity is 226.70492293581447
At time: 1523.8850910663605 and batch: 850, loss is 5.403596057891845 and perplexity is 222.20403978522228
At time: 1525.0155820846558 and batch: 900, loss is 5.451514549255371 and perplexity is 233.1109567066023
At time: 1526.1186075210571 and batch: 950, loss is 5.425456552505493 and perplexity is 227.1150125769587
At time: 1527.2217419147491 and batch: 1000, loss is 5.453878469467163 and perplexity is 233.66266424813819
At time: 1528.3251376152039 and batch: 1050, loss is 5.424579734802246 and perplexity is 226.91596139181217
At time: 1529.427880525589 and batch: 1100, loss is 5.412600936889649 and perplexity is 224.21399640247324
At time: 1530.531173467636 and batch: 1150, loss is 5.420695514678955 and perplexity is 226.0362793935301
At time: 1531.6347472667694 and batch: 1200, loss is 5.4090752696990965 and perplexity is 223.42488436231926
At time: 1532.737934589386 and batch: 1250, loss is 5.411613512039184 and perplexity is 223.99271119983712
At time: 1533.8414232730865 and batch: 1300, loss is 5.390253381729126 and perplexity is 219.25893472409166
At time: 1534.9449722766876 and batch: 1350, loss is 5.390022468566895 and perplexity is 219.20831079521776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.268090413411458 and perplexity of 194.04506257632426
Finished 48 epochs...
Completing Train Step...
At time: 1538.3176610469818 and batch: 50, loss is 5.463204984664917 and perplexity is 235.85211674783514
At time: 1539.4477097988129 and batch: 100, loss is 5.462354917526245 and perplexity is 235.65171180469775
At time: 1540.550307750702 and batch: 150, loss is 5.429885482788086 and perplexity is 228.12311990445704
At time: 1541.6537718772888 and batch: 200, loss is 5.425488624572754 and perplexity is 227.12229674172644
At time: 1542.7566194534302 and batch: 250, loss is 5.443716564178467 and perplexity is 231.30023012998475
At time: 1543.8594851493835 and batch: 300, loss is 5.461461267471313 and perplexity is 235.44121570843154
At time: 1544.962745666504 and batch: 350, loss is 5.47142107963562 and perplexity is 237.79788249053945
At time: 1546.0658884048462 and batch: 400, loss is 5.51539647102356 and perplexity is 248.4884762006961
At time: 1547.1686437129974 and batch: 450, loss is 5.485096731185913 and perplexity is 241.0722620760179
At time: 1548.2719519138336 and batch: 500, loss is 5.497133760452271 and perplexity is 243.99159072372584
At time: 1549.3747861385345 and batch: 550, loss is 5.468262338638306 and perplexity is 237.04792565331286
At time: 1550.4783668518066 and batch: 600, loss is 5.430352191925049 and perplexity is 228.22961189732916
At time: 1551.5816822052002 and batch: 650, loss is 5.448873834609985 and perplexity is 232.49618925917846
At time: 1552.7137496471405 and batch: 700, loss is 5.466613616943359 and perplexity is 236.6574216002566
At time: 1553.8167254924774 and batch: 750, loss is 5.457594747543335 and perplexity is 234.5326352102664
At time: 1554.9206187725067 and batch: 800, loss is 5.423589038848877 and perplexity is 226.69126798690752
At time: 1556.0224690437317 and batch: 850, loss is 5.403352336883545 and perplexity is 222.1498905915135
At time: 1557.1259143352509 and batch: 900, loss is 5.451316947937012 and perplexity is 233.06489822499125
At time: 1558.2289566993713 and batch: 950, loss is 5.425385389328003 and perplexity is 227.09885092607198
At time: 1559.3318974971771 and batch: 1000, loss is 5.453888187408447 and perplexity is 233.66493497922295
At time: 1560.4351217746735 and batch: 1050, loss is 5.4245514488220214 and perplexity is 226.90954294219208
At time: 1561.5373482704163 and batch: 1100, loss is 5.412419357299805 and perplexity is 224.17328741304183
At time: 1562.6407577991486 and batch: 1150, loss is 5.420395126342774 and perplexity is 225.96839092860847
At time: 1563.7436757087708 and batch: 1200, loss is 5.408866596221924 and perplexity is 223.37826637895003
At time: 1564.8470168113708 and batch: 1250, loss is 5.411513118743897 and perplexity is 223.970224962192
At time: 1565.949875831604 and batch: 1300, loss is 5.390300102233887 and perplexity is 219.26917885149888
At time: 1567.0534098148346 and batch: 1350, loss is 5.38967809677124 and perplexity is 219.13283463228353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.26798828125 and perplexity of 194.02524534666858
Finished 49 epochs...
Completing Train Step...
At time: 1570.4313242435455 and batch: 50, loss is 5.462616386413575 and perplexity is 235.71333545156284
At time: 1571.5618469715118 and batch: 100, loss is 5.461731491088867 and perplexity is 235.50484608228916
At time: 1572.6649475097656 and batch: 150, loss is 5.429238138198852 and perplexity is 227.97549342486454
At time: 1573.7678859233856 and batch: 200, loss is 5.424800958633423 and perplexity is 226.96616616318755
At time: 1574.8708803653717 and batch: 250, loss is 5.442973604202271 and perplexity is 231.12844713835878
At time: 1575.9739210605621 and batch: 300, loss is 5.460541095733642 and perplexity is 235.22466900121316
At time: 1577.0775163173676 and batch: 350, loss is 5.4705753421783445 and perplexity is 237.59685293515145
At time: 1578.1815280914307 and batch: 400, loss is 5.514750299453735 and perplexity is 248.32796187742733
At time: 1579.2850513458252 and batch: 450, loss is 5.484532356262207 and perplexity is 240.93624532233392
At time: 1580.388923883438 and batch: 500, loss is 5.4966888523101805 and perplexity is 243.88306102307524
At time: 1581.5198140144348 and batch: 550, loss is 5.467917137145996 and perplexity is 236.9661104778011
At time: 1582.6225280761719 and batch: 600, loss is 5.42977819442749 and perplexity is 228.09864626180047
At time: 1583.7259001731873 and batch: 650, loss is 5.4484547996521 and perplexity is 232.39878563749022
At time: 1584.8298094272614 and batch: 700, loss is 5.46626880645752 and perplexity is 236.5758337067261
At time: 1585.9335079193115 and batch: 750, loss is 5.457518978118896 and perplexity is 234.51486548069403
At time: 1587.0366265773773 and batch: 800, loss is 5.423469572067261 and perplexity is 226.66418752834053
At time: 1588.1385881900787 and batch: 850, loss is 5.403077564239502 and perplexity is 222.08885826409278
At time: 1589.2415130138397 and batch: 900, loss is 5.451043996810913 and perplexity is 233.00129157971432
At time: 1590.3447160720825 and batch: 950, loss is 5.425308761596679 and perplexity is 227.08144952306282
At time: 1591.4479191303253 and batch: 1000, loss is 5.453841857910156 and perplexity is 233.6541096507851
At time: 1592.5517446994781 and batch: 1050, loss is 5.424561452865601 and perplexity is 226.9118129665029
At time: 1593.6540296077728 and batch: 1100, loss is 5.412103624343872 and perplexity is 224.10251969080466
At time: 1594.7573781013489 and batch: 1150, loss is 5.419957771301269 and perplexity is 225.86958412201767
At time: 1595.8602941036224 and batch: 1200, loss is 5.40873764038086 and perplexity is 223.34946230400044
At time: 1596.9636828899384 and batch: 1250, loss is 5.411335878372192 and perplexity is 223.93053191397814
At time: 1598.0672886371613 and batch: 1300, loss is 5.390208911895752 and perplexity is 219.24918453259505
At time: 1599.1708636283875 and batch: 1350, loss is 5.389422035217285 and perplexity is 219.07673032151004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.267911376953125 and perplexity of 194.01032454534348
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2f1671c50>
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'anneal': 4.582380941004718, 'wordvec_source': 'glove', 'dropout': 0.06448342699581619, 'data': 'wikitext', 'lr': 4.119635995558076, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5697879791259766 and batch: 50, loss is 7.416302871704102 and perplexity is 1662.874269499226
At time: 2.5901622772216797 and batch: 100, loss is 6.6752153015136715 and perplexity is 792.5180658474835
At time: 3.610539197921753 and batch: 150, loss is 6.379473190307618 and perplexity is 589.6170098707579
At time: 4.662421464920044 and batch: 200, loss is 6.157073926925659 and perplexity is 472.0448144398669
At time: 5.688042640686035 and batch: 250, loss is 6.033968095779419 and perplexity is 417.36790364840164
At time: 6.710978984832764 and batch: 300, loss is 5.910675268173218 and perplexity is 368.9552150229257
At time: 7.735844373703003 and batch: 350, loss is 5.808593978881836 and perplexity is 333.150379749003
At time: 8.761679649353027 and batch: 400, loss is 5.759165229797364 and perplexity is 317.08352652896247
At time: 9.78758978843689 and batch: 450, loss is 5.656752948760986 and perplexity is 286.21776831651493
At time: 10.813370943069458 and batch: 500, loss is 5.618456773757934 and perplexity is 275.4639518515366
At time: 11.83988881111145 and batch: 550, loss is 5.536914854049683 and perplexity is 253.89349144300752
At time: 12.866677522659302 and batch: 600, loss is 5.445081615447998 and perplexity is 231.61618239922853
At time: 13.893502712249756 and batch: 650, loss is 5.433535375595093 and perplexity is 228.95726618514175
At time: 14.920299291610718 and batch: 700, loss is 5.417788181304932 and perplexity is 225.38007094529175
At time: 15.946889162063599 and batch: 750, loss is 5.361318798065185 and perplexity is 213.00567276731616
At time: 16.97372841835022 and batch: 800, loss is 5.2925848865509035 and perplexity is 198.85678386302374
At time: 18.000386714935303 and batch: 850, loss is 5.263300085067749 and perplexity is 193.11774586215762
At time: 19.02756357192993 and batch: 900, loss is 5.305201530456543 and perplexity is 201.3815828467927
At time: 20.054859161376953 and batch: 950, loss is 5.247775325775146 and perplexity is 190.1427918165038
At time: 21.0857195854187 and batch: 1000, loss is 5.238927602767944 and perplexity is 188.46788155999215
At time: 22.114271640777588 and batch: 1050, loss is 5.179418916702271 and perplexity is 177.5795924717864
At time: 23.142940521240234 and batch: 1100, loss is 5.147058448791504 and perplexity is 171.9250195282061
At time: 24.17355179786682 and batch: 1150, loss is 5.1423899364471435 and perplexity is 171.12425609361048
At time: 25.2028865814209 and batch: 1200, loss is 5.118560028076172 and perplexity is 167.09458479029033
At time: 26.233309507369995 and batch: 1250, loss is 5.153083658218383 and perplexity is 172.9640307634488
At time: 27.26652479171753 and batch: 1300, loss is 5.123892412185669 and perplexity is 167.98797713767146
At time: 28.29680037498474 and batch: 1350, loss is 5.0761735725402835 and perplexity is 160.1600411568607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.823719889322916 and perplexity of 124.42708595013977
Finished 1 epochs...
Completing Train Step...
At time: 31.51889395713806 and batch: 50, loss is 5.07990442276001 and perplexity is 160.75869032239245
At time: 32.54005670547485 and batch: 100, loss is 5.082573776245117 and perplexity is 161.1883853414667
At time: 33.56877303123474 and batch: 150, loss is 5.007631483078003 and perplexity is 149.55010438624245
At time: 34.62090802192688 and batch: 200, loss is 4.99371265411377 and perplexity is 147.48296153842423
At time: 35.64474701881409 and batch: 250, loss is 4.989750499725342 and perplexity is 146.89976739071963
At time: 36.668991565704346 and batch: 300, loss is 4.960696077346801 and perplexity is 142.69308676115898
At time: 37.69310998916626 and batch: 350, loss is 4.94622953414917 and perplexity is 140.64367078176218
At time: 38.71853470802307 and batch: 400, loss is 4.957217330932617 and perplexity is 142.19755610972734
At time: 39.76828479766846 and batch: 450, loss is 4.90534556388855 and perplexity is 135.00955637398837
At time: 40.85508489608765 and batch: 500, loss is 4.956769962310791 and perplexity is 142.13395561251755
At time: 41.95552039146423 and batch: 550, loss is 4.924044055938721 and perplexity is 137.55778122663162
At time: 43.05655288696289 and batch: 600, loss is 4.856172342300415 and perplexity is 128.53128558641575
At time: 44.15706992149353 and batch: 650, loss is 4.874714822769165 and perplexity is 130.9368076897942
At time: 45.25702953338623 and batch: 700, loss is 4.883518409729004 and perplexity is 132.09461019227336
At time: 46.35741209983826 and batch: 750, loss is 4.834848527908325 and perplexity is 125.81952361699553
At time: 47.46860432624817 and batch: 800, loss is 4.791212635040283 and perplexity is 120.44733880461744
At time: 48.56885647773743 and batch: 850, loss is 4.762886810302734 and perplexity is 117.08343617035001
At time: 49.66830921173096 and batch: 900, loss is 4.810077352523804 and perplexity is 122.7411114848171
At time: 50.76783514022827 and batch: 950, loss is 4.771150522232055 and perplexity is 118.05498874500617
At time: 51.86694121360779 and batch: 1000, loss is 4.7782845878601075 and perplexity is 118.9002121372141
At time: 52.96691179275513 and batch: 1050, loss is 4.71691367149353 and perplexity is 111.82259826796877
At time: 54.066230058670044 and batch: 1100, loss is 4.691746597290039 and perplexity is 109.04346860685584
At time: 55.167648792266846 and batch: 1150, loss is 4.702571077346802 and perplexity is 110.23021884772625
At time: 56.26744318008423 and batch: 1200, loss is 4.6847544860839845 and perplexity is 108.28368389313121
At time: 57.3669958114624 and batch: 1250, loss is 4.733417778015137 and perplexity is 113.68344389980973
At time: 58.46590757369995 and batch: 1300, loss is 4.715165853500366 and perplexity is 111.62732342083096
At time: 59.565675258636475 and batch: 1350, loss is 4.673829898834229 and perplexity is 107.1071675196818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.6146240234375 and perplexity of 100.94986661269819
Finished 2 epochs...
Completing Train Step...
At time: 62.94454216957092 and batch: 50, loss is 4.7395827579498295 and perplexity is 114.386464878833
At time: 64.0696427822113 and batch: 100, loss is 4.75333610534668 and perplexity is 115.97052979601469
At time: 65.17091917991638 and batch: 150, loss is 4.690278224945068 and perplexity is 108.88346969089358
At time: 66.27034950256348 and batch: 200, loss is 4.68906099319458 and perplexity is 108.75101390553075
At time: 67.36953401565552 and batch: 250, loss is 4.689424495697022 and perplexity is 108.79055235695613
At time: 68.46954655647278 and batch: 300, loss is 4.678359785079956 and perplexity is 107.59345137838972
At time: 69.5695059299469 and batch: 350, loss is 4.6708927249908445 and perplexity is 106.7930367030466
At time: 70.66932272911072 and batch: 400, loss is 4.6853517723083495 and perplexity is 108.34837956483747
At time: 71.768789768219 and batch: 450, loss is 4.634998760223389 and perplexity is 103.02779026370543
At time: 72.8684151172638 and batch: 500, loss is 4.7025267601013185 and perplexity is 110.2253338563034
At time: 73.96874833106995 and batch: 550, loss is 4.6844120216369625 and perplexity is 108.2466069303384
At time: 75.06854772567749 and batch: 600, loss is 4.615792951583862 and perplexity is 101.06793874863038
At time: 76.16849541664124 and batch: 650, loss is 4.643395414352417 and perplexity is 103.89652109633147
At time: 77.26845788955688 and batch: 700, loss is 4.660979242324829 and perplexity is 105.73957614391257
At time: 78.3686056137085 and batch: 750, loss is 4.61498592376709 and perplexity is 100.9864070142903
At time: 79.46838617324829 and batch: 800, loss is 4.579891757965088 and perplexity is 97.50383962182701
At time: 80.56825280189514 and batch: 850, loss is 4.554986772537231 and perplexity is 95.10549722283422
At time: 81.66804003715515 and batch: 900, loss is 4.591277418136596 and perplexity is 98.62032912908079
At time: 82.76802945137024 and batch: 950, loss is 4.565766839981079 and perplexity is 96.13628690602246
At time: 83.86766481399536 and batch: 1000, loss is 4.572462720870972 and perplexity is 96.78216397716388
At time: 84.96735715866089 and batch: 1050, loss is 4.511924533843994 and perplexity is 91.09696911498294
At time: 86.06692814826965 and batch: 1100, loss is 4.492142715454102 and perplexity is 89.3126125127445
At time: 87.19499683380127 and batch: 1150, loss is 4.508623390197754 and perplexity is 90.7967407553143
At time: 88.29478168487549 and batch: 1200, loss is 4.4868869972229 and perplexity is 88.8444419508363
At time: 89.39508557319641 and batch: 1250, loss is 4.53896388053894 and perplexity is 93.59377553135991
At time: 90.4951639175415 and batch: 1300, loss is 4.525617885589599 and perplexity is 92.35297177332477
At time: 91.59547996520996 and batch: 1350, loss is 4.482567262649536 and perplexity is 88.4614852743886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.53363037109375 and perplexity of 93.0959210814347
Finished 3 epochs...
Completing Train Step...
At time: 94.9907009601593 and batch: 50, loss is 4.5607356834411625 and perplexity is 95.65382488609966
At time: 96.08616423606873 and batch: 100, loss is 4.573348226547242 and perplexity is 96.8679030883597
At time: 97.18768119812012 and batch: 150, loss is 4.521648540496826 and perplexity is 91.98711753922501
At time: 98.28924584388733 and batch: 200, loss is 4.522603778839112 and perplexity is 92.0750291424771
At time: 99.39040064811707 and batch: 250, loss is 4.520898265838623 and perplexity is 91.91812781990951
At time: 100.49140524864197 and batch: 300, loss is 4.516784048080444 and perplexity is 91.54073349968064
At time: 101.59246468544006 and batch: 350, loss is 4.513318586349487 and perplexity is 91.22405163229048
At time: 102.6942937374115 and batch: 400, loss is 4.527252693176269 and perplexity is 92.50407459059426
At time: 103.79538798332214 and batch: 450, loss is 4.476276168823242 and perplexity is 87.90671266351262
At time: 104.89661860466003 and batch: 500, loss is 4.551639614105224 and perplexity is 94.78769621773766
At time: 105.9979338645935 and batch: 550, loss is 4.5375541305541995 and perplexity is 93.46192466794574
At time: 107.09868001937866 and batch: 600, loss is 4.469800968170166 and perplexity is 87.33933797515668
At time: 108.19983839988708 and batch: 650, loss is 4.498749523162842 and perplexity is 89.90463731310473
At time: 109.3013186454773 and batch: 700, loss is 4.519217624664306 and perplexity is 91.76377617082888
At time: 110.40273880958557 and batch: 750, loss is 4.476764707565308 and perplexity is 87.94966899039699
At time: 111.50419306755066 and batch: 800, loss is 4.442463645935058 and perplexity is 84.98405459861264
At time: 112.60582113265991 and batch: 850, loss is 4.418212747573852 and perplexity is 82.94790395773984
At time: 113.70675373077393 and batch: 900, loss is 4.45143238067627 and perplexity is 85.74968226513006
At time: 114.85225248336792 and batch: 950, loss is 4.4306613636016845 and perplexity is 83.98694445437539
At time: 115.95360088348389 and batch: 1000, loss is 4.437853946685791 and perplexity is 84.59320520710996
At time: 117.05504751205444 and batch: 1050, loss is 4.379928741455078 and perplexity is 79.83234446568984
At time: 118.15700507164001 and batch: 1100, loss is 4.361659822463989 and perplexity is 78.38713523205249
At time: 119.25873899459839 and batch: 1150, loss is 4.37970537185669 and perplexity is 79.81451433839645
At time: 120.35992121696472 and batch: 1200, loss is 4.357893276214599 and perplexity is 78.09244179846537
At time: 121.46123313903809 and batch: 1250, loss is 4.40786639213562 and perplexity is 82.09411985368448
At time: 122.56296300888062 and batch: 1300, loss is 4.398152561187744 and perplexity is 81.30053208048362
At time: 123.66448664665222 and batch: 1350, loss is 4.357721948623658 and perplexity is 78.07906355460514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.500207112630208 and perplexity of 90.03577691615384
Finished 4 epochs...
Completing Train Step...
At time: 127.06267547607422 and batch: 50, loss is 4.438247861862183 and perplexity is 84.62653431845112
At time: 128.16539406776428 and batch: 100, loss is 4.4518577766418455 and perplexity is 85.78616759382066
At time: 129.26916575431824 and batch: 150, loss is 4.407526664733886 and perplexity is 82.06623496854694
At time: 130.37188577651978 and batch: 200, loss is 4.406868658065796 and perplexity is 82.01225260103918
At time: 131.47487783432007 and batch: 250, loss is 4.4057059001922605 and perplexity is 81.9169476276428
At time: 132.5782606601715 and batch: 300, loss is 4.406048698425293 and perplexity is 81.94503342615099
At time: 133.68135905265808 and batch: 350, loss is 4.403754949569702 and perplexity is 81.75728750282217
At time: 134.78395080566406 and batch: 400, loss is 4.416030044555664 and perplexity is 82.76705076362686
At time: 135.88717436790466 and batch: 450, loss is 4.364634714126587 and perplexity is 78.62067567362986
At time: 136.99015545845032 and batch: 500, loss is 4.4411909294128415 and perplexity is 84.87596278790737
At time: 138.09338855743408 and batch: 550, loss is 4.4323392105102535 and perplexity is 84.12797997440737
At time: 139.19696402549744 and batch: 600, loss is 4.363549909591675 and perplexity is 78.53543385183805
At time: 140.30048847198486 and batch: 650, loss is 4.394650926589966 and perplexity is 81.01634517426284
At time: 141.4032700061798 and batch: 700, loss is 4.418440599441528 and perplexity is 82.96680594592128
At time: 142.5062665939331 and batch: 750, loss is 4.375706090927124 and perplexity is 79.49595110982092
At time: 143.63788056373596 and batch: 800, loss is 4.343822793960571 and perplexity is 77.00133766384933
At time: 144.7418508529663 and batch: 850, loss is 4.318988580703735 and perplexity is 75.11261950736413
At time: 145.8458650112152 and batch: 900, loss is 4.34968448638916 and perplexity is 77.45402127170092
At time: 146.94993782043457 and batch: 950, loss is 4.3327781677246096 and perplexity is 76.15556588379711
At time: 148.0529124736786 and batch: 1000, loss is 4.341020364761352 and perplexity is 76.78584895375818
At time: 149.15553402900696 and batch: 1050, loss is 4.283377685546875 and perplexity is 72.48485804870536
At time: 150.25872921943665 and batch: 1100, loss is 4.265896425247193 and perplexity is 71.2287426062094
At time: 151.3617880344391 and batch: 1150, loss is 4.283385753631592 and perplexity is 72.48544286503996
At time: 152.46552228927612 and batch: 1200, loss is 4.263083715438842 and perplexity is 71.02867831653735
At time: 153.56995749473572 and batch: 1250, loss is 4.311432266235352 and perplexity is 74.54718392877311
At time: 154.6737141609192 and batch: 1300, loss is 4.304404573440552 and perplexity is 74.02512580210758
At time: 155.7771861553192 and batch: 1350, loss is 4.2637102413177494 and perplexity is 71.07319356516872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.480095621744792 and perplexity of 88.2431102324044
Finished 5 epochs...
Completing Train Step...
At time: 159.18475484848022 and batch: 50, loss is 4.3489115524291995 and perplexity is 77.39417755892282
At time: 160.32284903526306 and batch: 100, loss is 4.359419536590576 and perplexity is 78.21172220136692
At time: 161.43082523345947 and batch: 150, loss is 4.322066583633423 and perplexity is 75.34417254791987
At time: 162.5397186279297 and batch: 200, loss is 4.3165625476837155 and perplexity is 74.93061467635187
At time: 163.6466121673584 and batch: 250, loss is 4.317204141616822 and perplexity is 74.97870512975403
At time: 164.755268573761 and batch: 300, loss is 4.319596767425537 and perplexity is 75.15831589974927
At time: 165.863196849823 and batch: 350, loss is 4.321357421875 and perplexity is 75.29076028323509
At time: 166.97129559516907 and batch: 400, loss is 4.330902013778687 and perplexity is 76.0128202666082
At time: 168.07963800430298 and batch: 450, loss is 4.279054265022278 and perplexity is 72.17215199267625
At time: 169.18785738945007 and batch: 500, loss is 4.355466213226318 and perplexity is 77.9031363443698
At time: 170.29567670822144 and batch: 550, loss is 4.351302375793457 and perplexity is 77.57943473723864
At time: 171.43438911437988 and batch: 600, loss is 4.283434448242187 and perplexity is 72.48897260139297
At time: 172.5420286655426 and batch: 650, loss is 4.312498421669006 and perplexity is 74.62670519746618
At time: 173.6502993106842 and batch: 700, loss is 4.33783802986145 and perplexity is 76.54187906964778
At time: 174.7591335773468 and batch: 750, loss is 4.297163524627686 and perplexity is 73.49104224895731
At time: 175.86809468269348 and batch: 800, loss is 4.266705532073974 and perplexity is 71.2863975894901
At time: 176.9760639667511 and batch: 850, loss is 4.241342306137085 and perplexity is 69.50108098126707
At time: 178.08397126197815 and batch: 900, loss is 4.2742165184021 and perplexity is 71.82384459907001
At time: 179.19206619262695 and batch: 950, loss is 4.255874109268189 and perplexity is 70.51843107005342
At time: 180.30033659934998 and batch: 1000, loss is 4.263911647796631 and perplexity is 71.08750960845107
At time: 181.40894985198975 and batch: 1050, loss is 4.209174966812133 and perplexity is 67.30099134716701
At time: 182.51746106147766 and batch: 1100, loss is 4.193449201583863 and perplexity is 66.25091006378706
At time: 183.62587761878967 and batch: 1150, loss is 4.207600946426392 and perplexity is 67.19514154153582
At time: 184.73285675048828 and batch: 1200, loss is 4.187919063568115 and perplexity is 65.88554457938935
At time: 185.838604927063 and batch: 1250, loss is 4.236101236343384 and perplexity is 69.1377738557415
At time: 186.941415309906 and batch: 1300, loss is 4.228690466880798 and perplexity is 68.62730357754393
At time: 188.04517817497253 and batch: 1350, loss is 4.191242198944092 and perplexity is 66.10485536123048
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.470889485677083 and perplexity of 87.43446013526123
Finished 6 epochs...
Completing Train Step...
At time: 191.435067653656 and batch: 50, loss is 4.277702922821045 and perplexity is 72.0746885859737
At time: 192.5653519630432 and batch: 100, loss is 4.286173219680786 and perplexity is 72.6877754426727
At time: 193.6683473587036 and batch: 150, loss is 4.254438781738282 and perplexity is 70.41728662963715
At time: 194.7717638015747 and batch: 200, loss is 4.245505323410034 and perplexity is 69.79101827011664
At time: 195.87432384490967 and batch: 250, loss is 4.246748600006104 and perplexity is 69.87784177137742
At time: 196.97741174697876 and batch: 300, loss is 4.250772199630737 and perplexity is 70.1595686272535
At time: 198.0798954963684 and batch: 350, loss is 4.256099557876587 and perplexity is 70.53433114446204
At time: 199.1825075149536 and batch: 400, loss is 4.263192510604858 and perplexity is 71.03640631376342
At time: 200.31392884254456 and batch: 450, loss is 4.212665815353393 and perplexity is 67.53633945794478
At time: 201.41725730895996 and batch: 500, loss is 4.287595119476318 and perplexity is 72.79120369058867
At time: 202.52052211761475 and batch: 550, loss is 4.286938943862915 and perplexity is 72.74345554515419
At time: 203.62391877174377 and batch: 600, loss is 4.22068407535553 and perplexity is 68.08004024144711
At time: 204.72687602043152 and batch: 650, loss is 4.247798233032227 and perplexity is 69.95122636860579
At time: 205.82961130142212 and batch: 700, loss is 4.27337643623352 and perplexity is 71.76353200525787
At time: 206.93234539031982 and batch: 750, loss is 4.236324472427368 and perplexity is 69.15320962447863
At time: 208.03568077087402 and batch: 800, loss is 4.207220230102539 and perplexity is 67.1695641234466
At time: 209.13928961753845 and batch: 850, loss is 4.1770387840271 and perplexity is 65.17257711276271
At time: 210.2423927783966 and batch: 900, loss is 4.210228276252747 and perplexity is 67.37191746373222
At time: 211.34518694877625 and batch: 950, loss is 4.195849280357361 and perplexity is 66.41010843465124
At time: 212.4483985900879 and batch: 1000, loss is 4.204102139472962 and perplexity is 66.96044952352393
At time: 213.5516574382782 and batch: 1050, loss is 4.147577075958252 and perplexity is 63.280490580029074
At time: 214.65516328811646 and batch: 1100, loss is 4.132973065376282 and perplexity is 62.363057036132155
At time: 215.75854659080505 and batch: 1150, loss is 4.146781015396118 and perplexity is 63.23013552262268
At time: 216.86193871498108 and batch: 1200, loss is 4.125425305366516 and perplexity is 61.89412755791866
At time: 217.9659447669983 and batch: 1250, loss is 4.173069739341736 and perplexity is 64.91441690554757
At time: 219.06927824020386 and batch: 1300, loss is 4.170369572639466 and perplexity is 64.73937358794267
At time: 220.1725811958313 and batch: 1350, loss is 4.131194014549255 and perplexity is 62.252208619656066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.46750244140625 and perplexity of 87.1388167093095
Finished 7 epochs...
Completing Train Step...
At time: 223.60234427452087 and batch: 50, loss is 4.220609159469604 and perplexity is 68.07494015595964
At time: 224.70338344573975 and batch: 100, loss is 4.227804479598999 and perplexity is 68.56652758674308
At time: 225.803950548172 and batch: 150, loss is 4.19825701713562 and perplexity is 66.5701991459845
At time: 226.9045433998108 and batch: 200, loss is 4.189624605178833 and perplexity is 65.99801099803014
At time: 228.0334780216217 and batch: 250, loss is 4.189760375022888 and perplexity is 66.00697214600437
At time: 229.13446688652039 and batch: 300, loss is 4.19652060508728 and perplexity is 66.45470615085999
At time: 230.2357997894287 and batch: 350, loss is 4.202562475204468 and perplexity is 66.85743223835756
At time: 231.33627891540527 and batch: 400, loss is 4.209072160720825 and perplexity is 67.29407275094843
At time: 232.4376256465912 and batch: 450, loss is 4.158010187149048 and perplexity is 63.94415901775665
At time: 233.5376980304718 and batch: 500, loss is 4.233681716918945 and perplexity is 68.97069587465266
At time: 234.63969159126282 and batch: 550, loss is 4.231137661933899 and perplexity is 68.7954536394488
At time: 235.7403724193573 and batch: 600, loss is 4.167109198570252 and perplexity is 64.52864273042418
At time: 236.8415687084198 and batch: 650, loss is 4.191846957206726 and perplexity is 66.14484490949648
At time: 237.94189882278442 and batch: 700, loss is 4.2190216588974 and perplexity is 67.96695688394028
At time: 239.04236888885498 and batch: 750, loss is 4.182761735916138 and perplexity is 65.54662594689567
At time: 240.1422781944275 and batch: 800, loss is 4.156906504631042 and perplexity is 63.87362389866905
At time: 241.24278473854065 and batch: 850, loss is 4.1259192895889285 and perplexity is 61.924709833351145
At time: 242.34278464317322 and batch: 900, loss is 4.156885571479798 and perplexity is 63.872286836433965
At time: 243.44309425354004 and batch: 950, loss is 4.146537203788757 and perplexity is 63.21472116082377
At time: 244.543958902359 and batch: 1000, loss is 4.151373243331909 and perplexity is 63.52117045526877
At time: 245.64542746543884 and batch: 1050, loss is 4.097764835357666 and perplexity is 60.205567736638685
At time: 246.75133895874023 and batch: 1100, loss is 4.0835867118835445 and perplexity is 59.3579885032115
At time: 247.85203528404236 and batch: 1150, loss is 4.095856137275696 and perplexity is 60.090763083540416
At time: 248.95250129699707 and batch: 1200, loss is 4.074651775360107 and perplexity is 58.82999096863926
At time: 250.05254197120667 and batch: 1250, loss is 4.122390723228454 and perplexity is 61.70658943781022
At time: 251.15297842025757 and batch: 1300, loss is 4.1204035234451295 and perplexity is 61.58408787450257
At time: 252.25388932228088 and batch: 1350, loss is 4.080932679176331 and perplexity is 59.20065933102473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.467228597005208 and perplexity of 87.11495749924491
Finished 8 epochs...
Completing Train Step...
At time: 255.659485578537 and batch: 50, loss is 4.17305757522583 and perplexity is 64.91362728385886
At time: 256.75889921188354 and batch: 100, loss is 4.179024391174316 and perplexity is 65.30211280862274
At time: 257.85913586616516 and batch: 150, loss is 4.153448195457458 and perplexity is 63.653110680409384
At time: 258.9593997001648 and batch: 200, loss is 4.141105742454529 and perplexity is 62.87230360274628
At time: 260.05967259407043 and batch: 250, loss is 4.141043605804444 and perplexity is 62.868397049788605
At time: 261.1597330570221 and batch: 300, loss is 4.1472891998291015 and perplexity is 63.26227625921001
At time: 262.2601897716522 and batch: 350, loss is 4.156075444221496 and perplexity is 63.82056311004695
At time: 263.3601942062378 and batch: 400, loss is 4.1614670562744145 and perplexity is 64.16558811200693
At time: 264.46074199676514 and batch: 450, loss is 4.111357002258301 and perplexity is 61.029478543714546
At time: 265.5615019798279 and batch: 500, loss is 4.188767166137695 and perplexity is 65.94144598075565
At time: 266.6616599559784 and batch: 550, loss is 4.183253297805786 and perplexity is 65.57885409062084
At time: 267.76248359680176 and batch: 600, loss is 4.12175696849823 and perplexity is 61.667494984323895
At time: 268.8625671863556 and batch: 650, loss is 4.1453450536727905 and perplexity is 63.13940462688857
At time: 269.9624888896942 and batch: 700, loss is 4.1734782361984255 and perplexity is 64.94093965766892
At time: 271.0623724460602 and batch: 750, loss is 4.138246183395386 and perplexity is 62.69277334842848
At time: 272.16283798217773 and batch: 800, loss is 4.1137206172943115 and perplexity is 61.17389934719564
At time: 273.26404190063477 and batch: 850, loss is 4.081876358985901 and perplexity is 59.25655216627084
At time: 274.3649871349335 and batch: 900, loss is 4.113585238456726 and perplexity is 61.165618256366315
At time: 275.46477460861206 and batch: 950, loss is 4.104605722427368 and perplexity is 60.6188391864716
At time: 276.56459736824036 and batch: 1000, loss is 4.10718451499939 and perplexity is 60.77536433489206
At time: 277.66448307037354 and batch: 1050, loss is 4.054481744766235 and perplexity is 57.65527510397698
At time: 278.7647030353546 and batch: 1100, loss is 4.041865444183349 and perplexity is 56.93244811211055
At time: 279.8652548789978 and batch: 1150, loss is 4.052516913414001 and perplexity is 57.54210342986659
At time: 280.96676087379456 and batch: 1200, loss is 4.031879696846008 and perplexity is 56.36676415907784
At time: 282.0670747756958 and batch: 1250, loss is 4.079164686203003 and perplexity is 59.09608545149297
At time: 283.1675798892975 and batch: 1300, loss is 4.077342286109924 and perplexity is 58.98848681352866
At time: 284.26751923561096 and batch: 1350, loss is 4.036733894348145 and perplexity is 56.64104473232121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.469197998046875 and perplexity of 87.28669083769024
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 287.66995191574097 and batch: 50, loss is 4.140349559783935 and perplexity is 62.82477862734762
At time: 288.7978882789612 and batch: 100, loss is 4.160682492256164 and perplexity is 64.11526584346628
At time: 289.8974072933197 and batch: 150, loss is 4.133509726524353 and perplexity is 62.39653384796705
At time: 290.99742007255554 and batch: 200, loss is 4.1173308038711545 and perplexity is 61.39514767103416
At time: 292.0980350971222 and batch: 250, loss is 4.1110598707199095 and perplexity is 61.0113474546602
At time: 293.1985821723938 and batch: 300, loss is 4.109596858024597 and perplexity is 60.92215234147687
At time: 294.29885745048523 and batch: 350, loss is 4.107952904701233 and perplexity is 60.8220814451474
At time: 295.4007406234741 and batch: 400, loss is 4.105304799079895 and perplexity is 60.6612312175633
At time: 296.5004172325134 and batch: 450, loss is 4.045394406318665 and perplexity is 57.13371548937092
At time: 297.6004765033722 and batch: 500, loss is 4.1200329160690305 and perplexity is 61.56126858604545
At time: 298.70028281211853 and batch: 550, loss is 4.109889230728149 and perplexity is 60.93996691998451
At time: 299.8003454208374 and batch: 600, loss is 4.042852764129639 and perplexity is 56.98868641175178
At time: 300.900995016098 and batch: 650, loss is 4.061217017173767 and perplexity is 58.04490976237097
At time: 302.0014660358429 and batch: 700, loss is 4.0775168800354 and perplexity is 58.99878674412583
At time: 303.1015808582306 and batch: 750, loss is 4.0400199127197265 and perplexity is 56.82747438377275
At time: 304.2019546031952 and batch: 800, loss is 4.0050629711151124 and perplexity is 54.87527984783634
At time: 305.3028380870819 and batch: 850, loss is 3.9648708581924437 and perplexity is 52.713461438368505
At time: 306.4035556316376 and batch: 900, loss is 3.985348925590515 and perplexity is 53.80405981631711
At time: 307.5038158893585 and batch: 950, loss is 3.9680226707458495 and perplexity is 52.879866488872445
At time: 308.6038341522217 and batch: 1000, loss is 3.969655685424805 and perplexity is 52.966290633812754
At time: 309.704692363739 and batch: 1050, loss is 3.90678985118866 and perplexity is 49.73902574288009
At time: 310.80403447151184 and batch: 1100, loss is 3.881484956741333 and perplexity is 48.49617635243041
At time: 311.931764125824 and batch: 1150, loss is 3.886956839561462 and perplexity is 48.76226909687931
At time: 313.03127360343933 and batch: 1200, loss is 3.8499514865875244 and perplexity is 46.99078349301863
At time: 314.1314425468445 and batch: 1250, loss is 3.8926814222335815 and perplexity is 49.04221325484227
At time: 315.2313232421875 and batch: 1300, loss is 3.882748942375183 and perplexity is 48.5575135791569
At time: 316.33181262016296 and batch: 1350, loss is 3.8344141483306884 and perplexity is 46.26631452898736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.393209228515625 and perplexity of 80.89962822095463
Finished 10 epochs...
Completing Train Step...
At time: 319.71620512008667 and batch: 50, loss is 4.072079553604126 and perplexity is 58.678861638367906
At time: 320.8454535007477 and batch: 100, loss is 4.086276340484619 and perplexity is 59.51785434028205
At time: 321.9470410346985 and batch: 150, loss is 4.059263925552369 and perplexity is 57.93165337150528
At time: 323.0487291812897 and batch: 200, loss is 4.0485693550109865 and perplexity is 57.31540037212202
At time: 324.1503221988678 and batch: 250, loss is 4.0417639255523685 and perplexity is 56.92666870128373
At time: 325.25124621391296 and batch: 300, loss is 4.04552011013031 and perplexity is 57.140897866598024
At time: 326.3526380062103 and batch: 350, loss is 4.046813883781433 and perplexity is 57.2148730979433
At time: 327.45374751091003 and batch: 400, loss is 4.047471570968628 and perplexity is 57.25251496382639
At time: 328.55504322052 and batch: 450, loss is 3.991637182235718 and perplexity is 54.14345955093143
At time: 329.656537771225 and batch: 500, loss is 4.070494556427002 and perplexity is 58.58592947637696
At time: 330.75847125053406 and batch: 550, loss is 4.06277006149292 and perplexity is 58.13512611659826
At time: 331.85931158065796 and batch: 600, loss is 3.997317337989807 and perplexity is 54.451877937243644
At time: 332.96134305000305 and batch: 650, loss is 4.018313269615174 and perplexity is 55.60723227107484
At time: 334.0642592906952 and batch: 700, loss is 4.0386304903030394 and perplexity is 56.74857184415228
At time: 335.1657826900482 and batch: 750, loss is 4.003528146743775 and perplexity is 54.791120532347215
At time: 336.2673292160034 and batch: 800, loss is 3.972228207588196 and perplexity is 53.10272300278637
At time: 337.3692853450775 and batch: 850, loss is 3.934904260635376 and perplexity is 51.15725195939703
At time: 338.47081542015076 and batch: 900, loss is 3.959177851676941 and perplexity is 52.41421597036447
At time: 339.6171381473541 and batch: 950, loss is 3.945760827064514 and perplexity is 51.71566982915783
At time: 340.71977400779724 and batch: 1000, loss is 3.9500075674057005 and perplexity is 51.93575985230954
At time: 341.82131266593933 and batch: 1050, loss is 3.890516366958618 and perplexity is 48.93614901124506
At time: 342.92285680770874 and batch: 1100, loss is 3.869171795845032 and perplexity is 47.90269643530136
At time: 344.0246422290802 and batch: 1150, loss is 3.8783895349502564 and perplexity is 48.34629232818042
At time: 345.12635803222656 and batch: 1200, loss is 3.8464831495285035 and perplexity is 46.828085925294765
At time: 346.2281012535095 and batch: 1250, loss is 3.8922532653808593 and perplexity is 49.021219989690415
At time: 347.32892966270447 and batch: 1300, loss is 3.885185580253601 and perplexity is 48.675974921111376
At time: 348.4306399822235 and batch: 1350, loss is 3.8421042776107788 and perplexity is 46.62348003330787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.388966471354166 and perplexity of 80.55711785191501
Finished 11 epochs...
Completing Train Step...
At time: 351.85404109954834 and batch: 50, loss is 4.046541771888733 and perplexity is 57.19930636857616
At time: 352.96111273765564 and batch: 100, loss is 4.057590951919556 and perplexity is 57.83481626845551
At time: 354.0700013637543 and batch: 150, loss is 4.031081109046936 and perplexity is 56.32176831790342
At time: 355.1792833805084 and batch: 200, loss is 4.01998272895813 and perplexity is 55.70014381897214
At time: 356.28746461868286 and batch: 250, loss is 4.013553214073181 and perplexity is 55.34316773645428
At time: 357.3956377506256 and batch: 300, loss is 4.018286032676697 and perplexity is 55.60571772093654
At time: 358.50333881378174 and batch: 350, loss is 4.020776290893554 and perplexity is 55.74436287586417
At time: 359.61206889152527 and batch: 400, loss is 4.022041220664978 and perplexity is 55.81492019567417
At time: 360.71929478645325 and batch: 450, loss is 3.966596965789795 and perplexity is 52.804529118336134
At time: 361.8265242576599 and batch: 500, loss is 4.047438006401062 and perplexity is 57.25059334016902
At time: 362.9347987174988 and batch: 550, loss is 4.0404516792297365 and perplexity is 56.852015881777334
At time: 364.0427758693695 and batch: 600, loss is 3.9759930896759035 and perplexity is 53.30302531412411
At time: 365.1516933441162 and batch: 650, loss is 3.997254281044006 and perplexity is 54.448444476380715
At time: 366.25974345207214 and batch: 700, loss is 4.019131994247436 and perplexity is 55.65277792399693
At time: 367.3978068828583 and batch: 750, loss is 3.9853235864639283 and perplexity is 53.802696485707415
At time: 368.5063192844391 and batch: 800, loss is 3.9551591205596925 and perplexity is 52.20400001328129
At time: 369.61433124542236 and batch: 850, loss is 3.919155445098877 and perplexity is 50.35789680498801
At time: 370.72316670417786 and batch: 900, loss is 3.944419264793396 and perplexity is 51.646336555540216
At time: 371.83172607421875 and batch: 950, loss is 3.932601389884949 and perplexity is 51.03957896503966
At time: 372.94082260131836 and batch: 1000, loss is 3.937913455963135 and perplexity is 51.31142597649977
At time: 374.04879426956177 and batch: 1050, loss is 3.8797717189788816 and perplexity is 48.413162003732616
At time: 375.1564769744873 and batch: 1100, loss is 3.859660153388977 and perplexity is 47.44922317076176
At time: 376.2647707462311 and batch: 1150, loss is 3.8703031587600707 and perplexity is 47.956922438439086
At time: 377.37333583831787 and batch: 1200, loss is 3.840633821487427 and perplexity is 46.55497263250855
At time: 378.48194885253906 and batch: 1250, loss is 3.8871491622924803 and perplexity is 48.771648091510684
At time: 379.5893585681915 and batch: 1300, loss is 3.8815142154693603 and perplexity is 48.497595309622994
At time: 380.6976263523102 and batch: 1350, loss is 3.840629186630249 and perplexity is 46.554756857359514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.38795654296875 and perplexity of 80.47580200045387
Finished 12 epochs...
Completing Train Step...
At time: 384.15020418167114 and batch: 50, loss is 4.027057881355286 and perplexity is 56.09562823152497
At time: 385.2576837539673 and batch: 100, loss is 4.036793689727784 and perplexity is 56.64443170635582
At time: 386.36599254608154 and batch: 150, loss is 4.011229300498963 and perplexity is 55.21470432445942
At time: 387.47343587875366 and batch: 200, loss is 3.9997494125366213 and perplexity is 54.5844701352993
At time: 388.5809507369995 and batch: 250, loss is 3.993785924911499 and perplexity is 54.25992499540734
At time: 389.68829798698425 and batch: 300, loss is 3.999008183479309 and perplexity is 54.544025531166675
At time: 390.7964913845062 and batch: 350, loss is 4.002437472343445 and perplexity is 54.73139383692681
At time: 391.90435099601746 and batch: 400, loss is 4.003557081222534 and perplexity is 54.79270590779637
At time: 393.0104341506958 and batch: 450, loss is 3.948677773475647 and perplexity is 51.86674189410684
At time: 394.1136140823364 and batch: 500, loss is 4.030811071395874 and perplexity is 56.3065613731994
At time: 395.2159957885742 and batch: 550, loss is 4.02406448841095 and perplexity is 55.92796304286061
At time: 396.36394739151 and batch: 600, loss is 3.9599031734466554 and perplexity is 52.45224693292551
At time: 397.4662368297577 and batch: 650, loss is 3.9819327116012575 and perplexity is 53.62056723790482
At time: 398.5690915584564 and batch: 700, loss is 4.004701256752014 and perplexity is 54.85543426036973
At time: 399.6724498271942 and batch: 750, loss is 3.971470708847046 and perplexity is 53.06251298840049
At time: 400.77635383605957 and batch: 800, loss is 3.9416911888122557 and perplexity is 51.50563343693238
At time: 401.8792793750763 and batch: 850, loss is 3.90688006401062 and perplexity is 49.743513043156874
At time: 402.9818425178528 and batch: 900, loss is 3.9324036026000977 and perplexity is 51.029484983559726
At time: 404.08434534072876 and batch: 950, loss is 3.921857089996338 and perplexity is 50.49412990380376
At time: 405.18719816207886 and batch: 1000, loss is 3.9276458120346067 and perplexity is 50.78727403273337
At time: 406.2902498245239 and batch: 1050, loss is 3.8703467082977294 and perplexity is 47.95901098571612
At time: 407.3935589790344 and batch: 1100, loss is 3.850765929222107 and perplexity is 47.02907037964783
At time: 408.496062040329 and batch: 1150, loss is 3.8620570850372316 and perplexity is 47.563092129002314
At time: 409.59863805770874 and batch: 1200, loss is 3.8337001752853395 and perplexity is 46.233293417000695
At time: 410.7014970779419 and batch: 1250, loss is 3.8804783964157106 and perplexity is 48.447386584411376
At time: 411.8040647506714 and batch: 1300, loss is 3.875682482719421 and perplexity is 48.21559337394354
At time: 412.9067370891571 and batch: 1350, loss is 3.836368832588196 and perplexity is 46.356839010216326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.387937825520833 and perplexity of 80.47429571291832
Finished 13 epochs...
Completing Train Step...
At time: 416.3121671676636 and batch: 50, loss is 4.010758609771728 and perplexity is 55.18872139056963
At time: 417.44229650497437 and batch: 100, loss is 4.01996298789978 and perplexity is 55.69904425003628
At time: 418.54411721229553 and batch: 150, loss is 3.995217809677124 and perplexity is 54.33767460634981
At time: 419.64692091941833 and batch: 200, loss is 3.9833332681655884 and perplexity is 53.69571848983816
At time: 420.7496976852417 and batch: 250, loss is 3.9776570081710814 and perplexity is 53.39179103277381
At time: 421.85308599472046 and batch: 300, loss is 3.9831191968917845 and perplexity is 53.68422500923913
At time: 422.9563989639282 and batch: 350, loss is 3.9874705505371093 and perplexity is 53.918333031438664
At time: 424.08652567863464 and batch: 400, loss is 3.9882610845565796 and perplexity is 53.96097416038398
At time: 425.19573760032654 and batch: 450, loss is 3.9340205717086794 and perplexity is 51.11206483094338
At time: 426.29959630966187 and batch: 500, loss is 4.017121663093567 and perplexity is 55.54100979385591
At time: 427.40247416496277 and batch: 550, loss is 4.010451512336731 and perplexity is 55.171775677915434
At time: 428.5048952102661 and batch: 600, loss is 3.9464560651779177 and perplexity is 51.75163703532079
At time: 429.60733461380005 and batch: 650, loss is 3.9688152503967284 and perplexity is 52.921794608485044
At time: 430.7096016407013 and batch: 700, loss is 3.992361059188843 and perplexity is 54.1826669424143
At time: 431.8114242553711 and batch: 750, loss is 3.959669680595398 and perplexity is 52.440001137942716
At time: 432.9137353897095 and batch: 800, loss is 3.9300387477874756 and perplexity is 50.90895024016932
At time: 434.015949010849 and batch: 850, loss is 3.8961050081253052 and perplexity is 49.210401222941094
At time: 435.1179473400116 and batch: 900, loss is 3.9215719175338744 and perplexity is 50.47973242141945
At time: 436.2205021381378 and batch: 950, loss is 3.9124025201797483 and perplexity is 50.01897933882184
At time: 437.32278633117676 and batch: 1000, loss is 3.9181719779968263 and perplexity is 50.30839581543903
At time: 438.42465591430664 and batch: 1050, loss is 3.861379470825195 and perplexity is 47.53087361890026
At time: 439.52738547325134 and batch: 1100, loss is 3.841858220100403 and perplexity is 46.61200938716301
At time: 440.63054728507996 and batch: 1150, loss is 3.853839325904846 and perplexity is 47.173831709091324
At time: 441.733770608902 and batch: 1200, loss is 3.8263607311248777 and perplexity is 45.89520893534381
At time: 442.8365001678467 and batch: 1250, loss is 3.873372745513916 and perplexity is 48.10435653742519
At time: 443.93916726112366 and batch: 1300, loss is 3.868762197494507 and perplexity is 47.88307958764424
At time: 445.04110884666443 and batch: 1350, loss is 3.8308487510681153 and perplexity is 46.10165045866404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.388758951822917 and perplexity of 80.54040241102977
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 448.42774415016174 and batch: 50, loss is 4.009091987609863 and perplexity is 55.09681924876074
At time: 449.5563154220581 and batch: 100, loss is 4.028411002159118 and perplexity is 56.171583770009605
At time: 450.6567440032959 and batch: 150, loss is 4.009585008621216 and perplexity is 55.12398983559385
At time: 451.78518080711365 and batch: 200, loss is 3.9980335140228274 and perplexity is 54.4908890349144
At time: 452.88518023490906 and batch: 250, loss is 3.996233410835266 and perplexity is 54.39288804428071
At time: 453.9857852458954 and batch: 300, loss is 3.9968823862075804 and perplexity is 54.42819914582882
At time: 455.0855851173401 and batch: 350, loss is 3.995788049697876 and perplexity is 54.36866895931532
At time: 456.18576979637146 and batch: 400, loss is 3.9933965826034545 and perplexity is 54.238803423003
At time: 457.28609681129456 and batch: 450, loss is 3.935277848243713 and perplexity is 51.176367245200275
At time: 458.3863146305084 and batch: 500, loss is 4.018584218025207 and perplexity is 55.62230100357743
At time: 459.4863998889923 and batch: 550, loss is 4.008804483413696 and perplexity is 55.08098095892777
At time: 460.58694100379944 and batch: 600, loss is 3.941930365562439 and perplexity is 51.51795386027464
At time: 461.6874294281006 and batch: 650, loss is 3.9653187704086306 and perplexity is 52.73707773032224
At time: 462.78788232803345 and batch: 700, loss is 3.981899962425232 and perplexity is 53.61881123726369
At time: 463.8881607055664 and batch: 750, loss is 3.94827627658844 and perplexity is 51.84592173858028
At time: 464.988728761673 and batch: 800, loss is 3.9179898929595947 and perplexity is 50.29923624324974
At time: 466.08868050575256 and batch: 850, loss is 3.8783772373199463 and perplexity is 48.34569778700624
At time: 467.1887905597687 and batch: 900, loss is 3.898461880683899 and perplexity is 49.32652065277753
At time: 468.28894782066345 and batch: 950, loss is 3.8855769729614256 and perplexity is 48.695030071521956
At time: 469.3890528678894 and batch: 1000, loss is 3.888394889831543 and perplexity is 48.83244213520911
At time: 470.48948216438293 and batch: 1050, loss is 3.8316451692581177 and perplexity is 46.13838127628262
At time: 471.58962297439575 and batch: 1100, loss is 3.8036300802230834 and perplexity is 44.863748260321124
At time: 472.6904306411743 and batch: 1150, loss is 3.8159851121902464 and perplexity is 45.421479603892216
At time: 473.7897598743439 and batch: 1200, loss is 3.7807107973098755 and perplexity is 43.84719713144307
At time: 474.88991498947144 and batch: 1250, loss is 3.8259361171722412 and perplexity is 45.875725326069606
At time: 475.9916088581085 and batch: 1300, loss is 3.819842791557312 and perplexity is 45.59703951779155
At time: 477.0921311378479 and batch: 1350, loss is 3.781458239555359 and perplexity is 43.87998263003213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.364977620442708 and perplexity of 78.6476398227204
Finished 15 epochs...
Completing Train Step...
At time: 480.5133409500122 and batch: 50, loss is 3.997943525314331 and perplexity is 54.48598569081144
At time: 481.61251950263977 and batch: 100, loss is 4.010194501876831 and perplexity is 55.15759777648748
At time: 482.7127113342285 and batch: 150, loss is 3.989062991142273 and perplexity is 54.004263175487
At time: 483.8123037815094 and batch: 200, loss is 3.977366967201233 and perplexity is 53.37630747146283
At time: 484.91321635246277 and batch: 250, loss is 3.973784260749817 and perplexity is 53.185417985014034
At time: 486.01395869255066 and batch: 300, loss is 3.9765295648574828 and perplexity is 53.33162873613523
At time: 487.11323714256287 and batch: 350, loss is 3.977326865196228 and perplexity is 53.37416701743201
At time: 488.21331548690796 and batch: 400, loss is 3.975481071472168 and perplexity is 53.27574018068771
At time: 489.31315517425537 and batch: 450, loss is 3.9190986061096194 and perplexity is 50.35503459437583
At time: 490.41299176216125 and batch: 500, loss is 4.003210911750793 and perplexity is 54.77374162835368
At time: 491.5136089324951 and batch: 550, loss is 3.9940027523040773 and perplexity is 54.27169130904905
At time: 492.61391973495483 and batch: 600, loss is 3.9284336948394776 and perplexity is 50.82730422012743
At time: 493.71392726898193 and batch: 650, loss is 3.952479066848755 and perplexity is 52.064277804463764
At time: 494.8133976459503 and batch: 700, loss is 3.9709793281555177 and perplexity is 53.03644549912899
At time: 495.91386008262634 and batch: 750, loss is 3.9384128618240357 and perplexity is 51.33705760312318
At time: 497.01371216773987 and batch: 800, loss is 3.909138226509094 and perplexity is 49.855968902868696
At time: 498.1139225959778 and batch: 850, loss is 3.870567812919617 and perplexity is 47.96961611708479
At time: 499.21417593955994 and batch: 900, loss is 3.892936124801636 and perplexity is 49.054706023403924
At time: 500.314466714859 and batch: 950, loss is 3.8810310554504395 and perplexity is 48.47416887037073
At time: 501.4138648509979 and batch: 1000, loss is 3.885583829879761 and perplexity is 48.695363970511245
At time: 502.513222694397 and batch: 1050, loss is 3.8306573486328124 and perplexity is 46.09282733490539
At time: 503.6131067276001 and batch: 1100, loss is 3.80423752784729 and perplexity is 44.89100891648702
At time: 504.7130687236786 and batch: 1150, loss is 3.818081226348877 and perplexity is 45.516788064206075
At time: 505.81412863731384 and batch: 1200, loss is 3.78432719707489 and perplexity is 44.00605319523044
At time: 506.9145667552948 and batch: 1250, loss is 3.830526294708252 and perplexity is 46.086787084796946
At time: 508.0155894756317 and batch: 1300, loss is 3.8250330781936643 and perplexity is 45.8343164576548
At time: 509.1151885986328 and batch: 1350, loss is 3.787716073989868 and perplexity is 44.15543727218139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.363538818359375 and perplexity of 78.53456280192796
Finished 16 epochs...
Completing Train Step...
At time: 512.5208876132965 and batch: 50, loss is 3.99184935092926 and perplexity is 54.15494831674332
At time: 513.6217036247253 and batch: 100, loss is 4.002486219406128 and perplexity is 54.73406189664244
At time: 514.7218375205994 and batch: 150, loss is 3.9808256340026857 and perplexity is 53.561237956211976
At time: 515.8214373588562 and batch: 200, loss is 3.9687749338150025 and perplexity is 52.919661025637296
At time: 516.9215207099915 and batch: 250, loss is 3.9647801971435546 and perplexity is 52.70868259729457
At time: 518.0218069553375 and batch: 300, loss is 3.967987051010132 and perplexity is 52.877982955549015
At time: 519.1221718788147 and batch: 350, loss is 3.969159388542175 and perplexity is 52.94001015088704
At time: 520.2229104042053 and batch: 400, loss is 3.967569694519043 and perplexity is 52.85591859080001
At time: 521.3226807117462 and batch: 450, loss is 3.911666221618652 and perplexity is 49.982163991514035
At time: 522.4230215549469 and batch: 500, loss is 3.996275153160095 and perplexity is 54.39515857727019
At time: 523.5228605270386 and batch: 550, loss is 3.9872226476669312 and perplexity is 53.90496817858609
At time: 524.622790813446 and batch: 600, loss is 3.922013325691223 and perplexity is 50.50201950557955
At time: 525.7224566936493 and batch: 650, loss is 3.9463619804382324 and perplexity is 51.746768225066
At time: 526.8226990699768 and batch: 700, loss is 3.965762047767639 and perplexity is 52.76046006490725
At time: 527.9228055477142 and batch: 750, loss is 3.9336788702011107 and perplexity is 51.094602744916166
At time: 529.022971868515 and batch: 800, loss is 3.904806823730469 and perplexity is 49.64048962129592
At time: 530.1229066848755 and batch: 850, loss is 3.8666668367385864 and perplexity is 47.782852304632385
At time: 531.2236156463623 and batch: 900, loss is 3.8899862241744994 and perplexity is 48.91021274053502
At time: 532.3234398365021 and batch: 950, loss is 3.8786194944381713 and perplexity is 48.35741129521377
At time: 533.4237864017487 and batch: 1000, loss is 3.883784818649292 and perplexity is 48.607839216469976
At time: 534.5242230892181 and batch: 1050, loss is 3.8297391891479493 and perplexity is 46.05052619087371
At time: 535.6697144508362 and batch: 1100, loss is 3.8039606046676635 and perplexity is 44.87857927666835
At time: 536.7695364952087 and batch: 1150, loss is 3.818138155937195 and perplexity is 45.51937938997299
At time: 537.8700184822083 and batch: 1200, loss is 3.785061092376709 and perplexity is 44.038360884702705
At time: 538.9702796936035 and batch: 1250, loss is 3.831870446205139 and perplexity is 46.14877636079953
At time: 540.0701630115509 and batch: 1300, loss is 3.8265570497512815 and perplexity is 45.90421990420209
At time: 541.1700489521027 and batch: 1350, loss is 3.789810314178467 and perplexity is 44.248006260476956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.362867431640625 and perplexity of 78.48185343566408
Finished 17 epochs...
Completing Train Step...
At time: 544.5542843341827 and batch: 50, loss is 3.9864291667938234 and perplexity is 53.86221258248804
At time: 545.6849315166473 and batch: 100, loss is 3.9963387775421144 and perplexity is 54.39861954571933
At time: 546.7862792015076 and batch: 150, loss is 3.974634976387024 and perplexity is 53.23068290282206
At time: 547.8877985477448 and batch: 200, loss is 3.962446141242981 and perplexity is 52.58580104765623
At time: 548.9888334274292 and batch: 250, loss is 3.958417649269104 and perplexity is 52.37438569863134
At time: 550.0900583267212 and batch: 300, loss is 3.96186710357666 and perplexity is 52.55536070203984
At time: 551.1904602050781 and batch: 350, loss is 3.9633482980728147 and perplexity is 52.63326309310883
At time: 552.2913105487823 and batch: 400, loss is 3.9619074630737305 and perplexity is 52.55748185277014
At time: 553.3921163082123 and batch: 450, loss is 3.906314630508423 and perplexity is 49.71539434474151
At time: 554.4935314655304 and batch: 500, loss is 3.9913629055023194 and perplexity is 54.12861129606941
At time: 555.5943307876587 and batch: 550, loss is 3.98244176864624 and perplexity is 53.6478701141844
At time: 556.6954190731049 and batch: 600, loss is 3.917380385398865 and perplexity is 50.26858781963233
At time: 557.7962856292725 and batch: 650, loss is 3.9419349241256714 and perplexity is 51.51818870866019
At time: 558.897479057312 and batch: 700, loss is 3.9618887281417847 and perplexity is 52.556497201148105
At time: 559.9986276626587 and batch: 750, loss is 3.930118036270142 and perplexity is 50.91298689361594
At time: 561.0999262332916 and batch: 800, loss is 3.9014670753479006 and perplexity is 49.47497941144172
At time: 562.2049362659454 and batch: 850, loss is 3.8636357164382935 and perplexity is 47.63823601641353
At time: 563.3346707820892 and batch: 900, loss is 3.8874911165237425 and perplexity is 48.788328614766414
At time: 564.4352838993073 and batch: 950, loss is 3.8764862298965452 and perplexity is 48.254362099050816
At time: 565.5364472866058 and batch: 1000, loss is 3.8819788885116577 and perplexity is 48.520136071416225
At time: 566.6374394893646 and batch: 1050, loss is 3.8284397459030153 and perplexity is 45.990725008225525
At time: 567.7382414340973 and batch: 1100, loss is 3.8029703855514527 and perplexity is 44.83416164478372
At time: 568.8397650718689 and batch: 1150, loss is 3.817436442375183 and perplexity is 45.487449028414765
At time: 569.9415740966797 and batch: 1200, loss is 3.7848570203781127 and perplexity is 44.02937480531683
At time: 571.0427203178406 and batch: 1250, loss is 3.8322040176391603 and perplexity is 46.16417284207894
At time: 572.1432712078094 and batch: 1300, loss is 3.82678307056427 and perplexity is 45.91459638591067
At time: 573.2449626922607 and batch: 1350, loss is 3.790400676727295 and perplexity is 44.27413633858429
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.362722981770833 and perplexity of 78.47051756090681
Finished 18 epochs...
Completing Train Step...
At time: 576.647962808609 and batch: 50, loss is 3.981493983268738 and perplexity is 53.59704753560893
At time: 577.779406785965 and batch: 100, loss is 3.991055059432983 and perplexity is 54.11195058044277
At time: 578.8820652961731 and batch: 150, loss is 3.969473371505737 and perplexity is 52.95663502199178
At time: 579.9854364395142 and batch: 200, loss is 3.957181224822998 and perplexity is 52.30966874486026
At time: 581.0891075134277 and batch: 250, loss is 3.9532246208190918 and perplexity is 52.10310900707355
At time: 582.192497253418 and batch: 300, loss is 3.9568322849273683 and perplexity is 52.29141899872544
At time: 583.2959208488464 and batch: 350, loss is 3.9585989570617675 and perplexity is 52.383882443785396
At time: 584.3998181819916 and batch: 400, loss is 3.9572479629516604 and perplexity is 52.31315991075889
At time: 585.5032346248627 and batch: 450, loss is 3.9018949937820433 and perplexity is 49.4961551975922
At time: 586.6062090396881 and batch: 500, loss is 3.9872957372665407 and perplexity is 53.908908215113314
At time: 587.7098367214203 and batch: 550, loss is 3.9786441850662233 and perplexity is 53.44452419947104
At time: 588.8132445812225 and batch: 600, loss is 3.9136179876327515 and perplexity is 50.079812743262785
At time: 589.9166822433472 and batch: 650, loss is 3.938180856704712 and perplexity is 51.325148524485265
At time: 591.0202748775482 and batch: 700, loss is 3.9585309076309203 and perplexity is 52.380317871684454
At time: 592.1516010761261 and batch: 750, loss is 3.9269864416122435 and perplexity is 50.75379744435273
At time: 593.2543721199036 and batch: 800, loss is 3.898514313697815 and perplexity is 49.32910705872728
At time: 594.3591628074646 and batch: 850, loss is 3.860876588821411 and perplexity is 47.506977206974526
At time: 595.4621217250824 and batch: 900, loss is 3.885094790458679 and perplexity is 48.671555839937426
At time: 596.565824508667 and batch: 950, loss is 3.87438419342041 and perplexity is 48.1530362024608
At time: 597.6692585945129 and batch: 1000, loss is 3.880069875717163 and perplexity is 48.42759886632251
At time: 598.7729442119598 and batch: 1050, loss is 3.8269248533248903 and perplexity is 45.92110674565652
At time: 599.8763263225555 and batch: 1100, loss is 3.8016053199768067 and perplexity is 44.77300182723218
At time: 600.9796762466431 and batch: 1150, loss is 3.81632061958313 and perplexity is 45.43672140282016
At time: 602.0828442573547 and batch: 1200, loss is 3.78407431602478 and perplexity is 43.99492630523635
At time: 603.186585187912 and batch: 1250, loss is 3.8316540336608886 and perplexity is 46.138790267290176
At time: 604.2902708053589 and batch: 1300, loss is 3.8263523149490357 and perplexity is 45.894822674820524
At time: 605.3942131996155 and batch: 1350, loss is 3.7902952337265017 and perplexity is 44.269468186907496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.362762451171875 and perplexity of 78.47361480635719
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 608.8103921413422 and batch: 50, loss is 3.982599482536316 and perplexity is 53.6563317957192
At time: 609.9138329029083 and batch: 100, loss is 3.9984406661987304 and perplexity is 54.5130796361211
At time: 611.0169410705566 and batch: 150, loss is 3.979530487060547 and perplexity is 53.49191318522888
At time: 612.120598077774 and batch: 200, loss is 3.970675072669983 and perplexity is 53.02031132423268
At time: 613.2241570949554 and batch: 250, loss is 3.967308301925659 and perplexity is 52.84210425072563
At time: 614.3271884918213 and batch: 300, loss is 3.9722637128829956 and perplexity is 53.10460846409298
At time: 615.4300920963287 and batch: 350, loss is 3.974294228553772 and perplexity is 53.212547752892384
At time: 616.5330016613007 and batch: 400, loss is 3.9697654151916506 and perplexity is 52.97210293141988
At time: 617.6363863945007 and batch: 450, loss is 3.912026786804199 and perplexity is 50.00018906916012
At time: 618.739394903183 and batch: 500, loss is 3.9974467086791994 and perplexity is 54.45892286992517
At time: 619.8709115982056 and batch: 550, loss is 3.985818042755127 and perplexity is 53.829306145582954
At time: 620.9737589359283 and batch: 600, loss is 3.921899561882019 and perplexity is 50.49627453025943
At time: 622.0765461921692 and batch: 650, loss is 3.945468850135803 and perplexity is 51.7005722508944
At time: 623.1801369190216 and batch: 700, loss is 3.9607491731643676 and perplexity is 52.49664029476217
At time: 624.2832472324371 and batch: 750, loss is 3.929020700454712 and perplexity is 50.85714889174981
At time: 625.3865883350372 and batch: 800, loss is 3.90148428440094 and perplexity is 49.47583083631263
At time: 626.4907393455505 and batch: 850, loss is 3.8592313861846925 and perplexity is 47.428882860937875
At time: 627.594310760498 and batch: 900, loss is 3.8823330402374268 and perplexity is 48.537322604481005
At time: 628.6978611946106 and batch: 950, loss is 3.869698233604431 and perplexity is 47.927920862444836
At time: 629.8010993003845 and batch: 1000, loss is 3.872584414482117 and perplexity is 48.066449324081475
At time: 630.9042625427246 and batch: 1050, loss is 3.818394079208374 and perplexity is 45.53103034926073
At time: 632.0080184936523 and batch: 1100, loss is 3.7937589740753173 and perplexity is 44.42307199837511
At time: 633.1114792823792 and batch: 1150, loss is 3.8078203868865965 and perplexity is 45.052135548207964
At time: 634.2151148319244 and batch: 1200, loss is 3.775294094085693 and perplexity is 43.610331970658216
At time: 635.3182351589203 and batch: 1250, loss is 3.8205944776535032 and perplexity is 45.6313270635458
At time: 636.4214687347412 and batch: 1300, loss is 3.8153356075286866 and perplexity is 45.39198771974944
At time: 637.5246322154999 and batch: 1350, loss is 3.777713828086853 and perplexity is 43.7159851484719
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.35399658203125 and perplexity of 77.78873155202143
Finished 20 epochs...
Completing Train Step...
At time: 640.958842754364 and batch: 50, loss is 3.981916298866272 and perplexity is 53.61968718496704
At time: 642.061927318573 and batch: 100, loss is 3.9931707859039305 and perplexity is 54.22655786275953
At time: 643.1650393009186 and batch: 150, loss is 3.973470287322998 and perplexity is 53.16872179828912
At time: 644.267596244812 and batch: 200, loss is 3.9630547666549685 and perplexity is 52.61781584400462
At time: 645.3709597587585 and batch: 250, loss is 3.9586527919769288 and perplexity is 52.38670260156337
At time: 646.473963022232 and batch: 300, loss is 3.963547053337097 and perplexity is 52.643725270896965
At time: 647.6044433116913 and batch: 350, loss is 3.96634370803833 and perplexity is 52.79115765530926
At time: 648.7074689865112 and batch: 400, loss is 3.9618595123291014 and perplexity is 52.55496174280052
At time: 649.810667514801 and batch: 450, loss is 3.9049975633621217 and perplexity is 49.64995893305916
At time: 650.9135897159576 and batch: 500, loss is 3.990755205154419 and perplexity is 54.0957273129694
At time: 652.0164532661438 and batch: 550, loss is 3.979990692138672 and perplexity is 53.51653610067614
At time: 653.120245218277 and batch: 600, loss is 3.916604585647583 and perplexity is 50.22960458525155
At time: 654.2232894897461 and batch: 650, loss is 3.94097336769104 and perplexity is 51.46867487179604
At time: 655.3271791934967 and batch: 700, loss is 3.9570393466949465 and perplexity is 52.302247673436064
At time: 656.4300968647003 and batch: 750, loss is 3.925721483230591 and perplexity is 50.6896365918343
At time: 657.5334405899048 and batch: 800, loss is 3.8988196277618408 and perplexity is 49.34417022825989
At time: 658.6363570690155 and batch: 850, loss is 3.8569826221466066 and perplexity is 47.32234632745196
At time: 659.7398450374603 and batch: 900, loss is 3.880755944252014 and perplexity is 48.460834917924046
At time: 660.8428757190704 and batch: 950, loss is 3.868462529182434 and perplexity is 47.86873269576916
At time: 661.9461586475372 and batch: 1000, loss is 3.872298812866211 and perplexity is 48.05272342864592
At time: 663.0487425327301 and batch: 1050, loss is 3.8191771936416625 and perplexity is 45.56670032130176
At time: 664.1519863605499 and batch: 1100, loss is 3.7949607133865357 and perplexity is 44.47648904057175
At time: 665.2556915283203 and batch: 1150, loss is 3.8095053577423097 and perplexity is 45.12811107389225
At time: 666.3590931892395 and batch: 1200, loss is 3.7776811742782592 and perplexity is 43.71455767836667
At time: 667.4625523090363 and batch: 1250, loss is 3.8232141828536985 and perplexity is 45.751024405765456
At time: 668.5659537315369 and batch: 1300, loss is 3.8178957414627077 and perplexity is 45.508346170899216
At time: 669.668524980545 and batch: 1350, loss is 3.780495562553406 and perplexity is 43.837760706206375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353256429036458 and perplexity of 77.73117729150873
Finished 21 epochs...
Completing Train Step...
At time: 673.0507838726044 and batch: 50, loss is 3.9805873012542725 and perplexity is 53.5484740802467
At time: 674.180017709732 and batch: 100, loss is 3.9909109449386597 and perplexity is 54.10415282594624
At time: 675.2810478210449 and batch: 150, loss is 3.970972671508789 and perplexity is 53.036092455422605
At time: 676.4103300571442 and batch: 200, loss is 3.960134606361389 and perplexity is 52.46438751412839
At time: 677.5106565952301 and batch: 250, loss is 3.9553658819198607 and perplexity is 52.21479489927445
At time: 678.6114702224731 and batch: 300, loss is 3.9602785301208496 and perplexity is 52.471938929418215
At time: 679.7117412090302 and batch: 350, loss is 3.963351845741272 and perplexity is 52.63344981880733
At time: 680.8129725456238 and batch: 400, loss is 3.95882936000824 and perplexity is 52.39595323516765
At time: 681.9143409729004 and batch: 450, loss is 3.9023031997680664 and perplexity is 49.516363948814984
At time: 683.01580286026 and batch: 500, loss is 3.988102831840515 and perplexity is 53.95243536532319
At time: 684.1162679195404 and batch: 550, loss is 3.977621283531189 and perplexity is 53.389883664336175
At time: 685.2175476551056 and batch: 600, loss is 3.9144159746170044 and perplexity is 50.11979173124026
At time: 686.3183190822601 and batch: 650, loss is 3.9389804220199585 and perplexity is 51.366202743622964
At time: 687.4196228981018 and batch: 700, loss is 3.9554483795166018 and perplexity is 52.219102672055975
At time: 688.5211298465729 and batch: 750, loss is 3.9243063163757324 and perplexity is 50.61795303230682
At time: 689.6226816177368 and batch: 800, loss is 3.8976136445999146 and perplexity is 49.28469785837176
At time: 690.7244770526886 and batch: 850, loss is 3.8560779666900635 and perplexity is 47.27955526713187
At time: 691.8256022930145 and batch: 900, loss is 3.880190052986145 and perplexity is 48.43341911262127
At time: 692.9263978004456 and batch: 950, loss is 3.8680796337127688 and perplexity is 47.85040748342561
At time: 694.027257680893 and batch: 1000, loss is 3.8723062753677366 and perplexity is 48.05308202350582
At time: 695.128259897232 and batch: 1050, loss is 3.819643678665161 and perplexity is 45.587961463188485
At time: 696.22922539711 and batch: 1100, loss is 3.795582404136658 and perplexity is 44.50414825925554
At time: 697.3304224014282 and batch: 1150, loss is 3.810302982330322 and perplexity is 45.16412072407741
At time: 698.431033372879 and batch: 1200, loss is 3.7787949419021607 and perplexity is 43.76327266095138
At time: 699.5326373577118 and batch: 1250, loss is 3.8243151617050173 and perplexity is 45.80142305489487
At time: 700.6334042549133 and batch: 1300, loss is 3.8188936376571654 and perplexity is 45.55378144243114
At time: 701.7346775531769 and batch: 1350, loss is 3.7815642976760864 and perplexity is 43.884636705324304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353012288411458 and perplexity of 77.71220226968389
Finished 22 epochs...
Completing Train Step...
At time: 705.1368570327759 and batch: 50, loss is 3.97918586730957 and perplexity is 53.47348199148682
At time: 706.2657675743103 and batch: 100, loss is 3.989090156555176 and perplexity is 54.005730243521356
At time: 707.36643242836 and batch: 150, loss is 3.9690892362594603 and perplexity is 52.936296418592924
At time: 708.4671900272369 and batch: 200, loss is 3.958075399398804 and perplexity is 52.356463639005156
At time: 709.5684576034546 and batch: 250, loss is 3.9531235027313234 and perplexity is 52.097840706688686
At time: 710.669408082962 and batch: 300, loss is 3.9580860567092895 and perplexity is 52.35702162106738
At time: 711.7698175907135 and batch: 350, loss is 3.961340346336365 and perplexity is 52.52768407534543
At time: 712.8708901405334 and batch: 400, loss is 3.956804437637329 and perplexity is 52.289962844689086
At time: 713.9713532924652 and batch: 450, loss is 3.900523452758789 and perplexity is 49.42831572319095
At time: 715.0730862617493 and batch: 500, loss is 3.9863311195373536 and perplexity is 53.85693179920432
At time: 716.1735968589783 and batch: 550, loss is 3.976003761291504 and perplexity is 53.30359414655579
At time: 717.2737700939178 and batch: 600, loss is 3.912926187515259 and perplexity is 50.045179503943764
At time: 718.3737990856171 and batch: 650, loss is 3.9376027154922486 and perplexity is 51.29548391687983
At time: 719.4741675853729 and batch: 700, loss is 3.9543217754364015 and perplexity is 52.160305544682004
At time: 720.5748631954193 and batch: 750, loss is 3.9233192873001097 and perplexity is 50.56801628947813
At time: 721.6749329566956 and batch: 800, loss is 3.8967347145080566 and perplexity is 49.24139908544057
At time: 722.7760820388794 and batch: 850, loss is 3.855383553504944 and perplexity is 47.246735117259036
At time: 723.8761661052704 and batch: 900, loss is 3.879730043411255 and perplexity is 48.41114439976819
At time: 724.9773306846619 and batch: 950, loss is 3.8677279949188232 and perplexity is 47.83358438184926
At time: 726.0778207778931 and batch: 1000, loss is 3.872210693359375 and perplexity is 48.04848923291563
At time: 727.1786203384399 and batch: 1050, loss is 3.819802303314209 and perplexity is 45.59519341114383
At time: 728.279381275177 and batch: 1100, loss is 3.7958349132537843 and perplexity is 44.515387381371625
At time: 729.3801403045654 and batch: 1150, loss is 3.8106690740585325 and perplexity is 45.180657961974696
At time: 730.480546951294 and batch: 1200, loss is 3.7793617343902586 and perplexity is 43.78808438603564
At time: 731.6092805862427 and batch: 1250, loss is 3.8248374795913698 and perplexity is 45.82535220614467
At time: 732.7090744972229 and batch: 1300, loss is 3.8193837785720826 and perplexity is 45.576114687316704
At time: 733.8085563182831 and batch: 1350, loss is 3.782096700668335 and perplexity is 43.908007237938676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.352919108072917 and perplexity of 77.70496135772818
Finished 23 epochs...
Completing Train Step...
At time: 737.2155051231384 and batch: 50, loss is 3.977844729423523 and perplexity is 53.40181474745929
At time: 738.3157584667206 and batch: 100, loss is 3.9874930572509766 and perplexity is 53.919546569588725
At time: 739.4165813922882 and batch: 150, loss is 3.967492036819458 and perplexity is 52.85181408112827
At time: 740.5166907310486 and batch: 200, loss is 3.956374363899231 and perplexity is 52.267479140075466
At time: 741.6170616149902 and batch: 250, loss is 3.95131986618042 and perplexity is 52.00395982591132
At time: 742.7171528339386 and batch: 300, loss is 3.956327691078186 and perplexity is 52.265039726302696
At time: 743.8175401687622 and batch: 350, loss is 3.959718098640442 and perplexity is 52.442540241748645
At time: 744.9185037612915 and batch: 400, loss is 3.955179433822632 and perplexity is 52.205060457630545
At time: 746.0193417072296 and batch: 450, loss is 3.8990951681137087 and perplexity is 49.3577684116253
At time: 747.1190688610077 and batch: 500, loss is 3.9849147176742554 and perplexity is 53.78070273889889
At time: 748.2188789844513 and batch: 550, loss is 3.974694724082947 and perplexity is 53.2338634084909
At time: 749.3189527988434 and batch: 600, loss is 3.911714596748352 and perplexity is 49.984581943663706
At time: 750.4204323291779 and batch: 650, loss is 3.9364745903015135 and perplexity is 51.23764881805193
At time: 751.5208652019501 and batch: 700, loss is 3.953374214172363 and perplexity is 52.110903868881
At time: 752.6219642162323 and batch: 750, loss is 3.922470045089722 and perplexity is 50.52509002552708
At time: 753.721937417984 and batch: 800, loss is 3.8959745168685913 and perplexity is 49.20398011480046
At time: 754.8226809501648 and batch: 850, loss is 3.8547472763061523 and perplexity is 47.216682658847496
At time: 755.9224569797516 and batch: 900, loss is 3.8792698574066162 and perplexity is 48.38887139390273
At time: 757.022670507431 and batch: 950, loss is 3.867349133491516 and perplexity is 47.81546551428387
At time: 758.123204946518 and batch: 1000, loss is 3.8720191955566405 and perplexity is 48.03928893374946
At time: 759.2241623401642 and batch: 1050, loss is 3.8197825288772584 and perplexity is 45.59429180078092
At time: 760.3703331947327 and batch: 1100, loss is 3.7958810043334963 and perplexity is 44.51743919092453
At time: 761.4704942703247 and batch: 1150, loss is 3.8108018493652343 and perplexity is 45.18665723596149
At time: 762.5704233646393 and batch: 1200, loss is 3.7796480655670166 and perplexity is 43.800624074932145
At time: 763.670520067215 and batch: 1250, loss is 3.825128130912781 and perplexity is 45.83867334112648
At time: 764.7705435752869 and batch: 1300, loss is 3.819638056755066 and perplexity is 45.587705172488135
At time: 765.8711369037628 and batch: 1350, loss is 3.7823910760879516 and perplexity is 43.92093457864619
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353030598958333 and perplexity of 77.71362523563393
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 769.2830617427826 and batch: 50, loss is 3.9783197259902954 and perplexity is 53.42718645138284
At time: 770.3836152553558 and batch: 100, loss is 3.990057282447815 and perplexity is 54.05798584839197
At time: 771.484872341156 and batch: 150, loss is 3.971960062980652 and perplexity is 53.08848570288018
At time: 772.5866503715515 and batch: 200, loss is 3.96319748878479 and perplexity is 52.62532610667603
At time: 773.6882042884827 and batch: 250, loss is 3.957912039756775 and perplexity is 52.347911404411214
At time: 774.7905611991882 and batch: 300, loss is 3.9637528753280638 and perplexity is 52.654561622385586
At time: 775.8913261890411 and batch: 350, loss is 3.9677100801467895 and perplexity is 52.863339322981396
At time: 776.9927434921265 and batch: 400, loss is 3.9622588300704957 and perplexity is 52.57595206204724
At time: 778.0940668582916 and batch: 450, loss is 3.905906624794006 and perplexity is 49.69511431721927
At time: 779.1961355209351 and batch: 500, loss is 3.9914208889007567 and perplexity is 54.131749947899024
At time: 780.2977447509766 and batch: 550, loss is 3.9796030044555666 and perplexity is 53.49579242008199
At time: 781.3995654582977 and batch: 600, loss is 3.9182658052444457 and perplexity is 50.313116335203766
At time: 782.5007758140564 and batch: 650, loss is 3.9412339401245116 and perplexity is 51.48208793711659
At time: 783.6022353172302 and batch: 700, loss is 3.955740075111389 and perplexity is 52.23433697605083
At time: 784.7033514976501 and batch: 750, loss is 3.9237802505493162 and perplexity is 50.591331659924464
At time: 785.80601811409 and batch: 800, loss is 3.8980321216583254 and perplexity is 49.3053266898015
At time: 786.9073491096497 and batch: 850, loss is 3.8562065839767454 and perplexity is 47.285636626321434
At time: 788.037290096283 and batch: 900, loss is 3.8786134243011476 and perplexity is 48.357117759992
At time: 789.1390130519867 and batch: 950, loss is 3.86537278175354 and perplexity is 47.72105865721977
At time: 790.2406349182129 and batch: 1000, loss is 3.8686465644836425 and perplexity is 47.8775430430919
At time: 791.3423848152161 and batch: 1050, loss is 3.814906344413757 and perplexity is 45.37250679522833
At time: 792.4439902305603 and batch: 1100, loss is 3.7906639337539674 and perplexity is 44.28579335040308
At time: 793.5453352928162 and batch: 1150, loss is 3.8052950620651247 and perplexity is 44.938507805912955
At time: 794.6472899913788 and batch: 1200, loss is 3.7742159032821654 and perplexity is 43.56333705108632
At time: 795.7488980293274 and batch: 1250, loss is 3.820229630470276 and perplexity is 45.614681639102486
At time: 796.8499512672424 and batch: 1300, loss is 3.8157036304473877 and perplexity is 45.40869608589796
At time: 797.9510216712952 and batch: 1350, loss is 3.778063793182373 and perplexity is 43.73128689477251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.349978841145833 and perplexity of 77.47682358710607
Finished 25 epochs...
Completing Train Step...
At time: 801.3387718200684 and batch: 50, loss is 3.9784508323669434 and perplexity is 53.434191555409846
At time: 802.4776020050049 and batch: 100, loss is 3.9880639266967775 and perplexity is 53.95033637890125
At time: 803.5859162807465 and batch: 150, loss is 3.96994170665741 and perplexity is 52.981442284289926
At time: 804.6945157051086 and batch: 200, loss is 3.9603181648254395 and perplexity is 52.47401868043183
At time: 805.8019318580627 and batch: 250, loss is 3.9544436931610107 and perplexity is 52.16666519811829
At time: 806.9105343818665 and batch: 300, loss is 3.960357012748718 and perplexity is 52.47605722668004
At time: 808.0184774398804 and batch: 350, loss is 3.9641113471984863 and perplexity is 52.67344018509132
At time: 809.1291208267212 and batch: 400, loss is 3.958821482658386 and perplexity is 52.395540495538754
At time: 810.2370910644531 and batch: 450, loss is 3.902475109100342 and perplexity is 49.52487700559413
At time: 811.3457164764404 and batch: 500, loss is 3.9879665994644165 and perplexity is 53.94508579749297
At time: 812.4539186954498 and batch: 550, loss is 3.9767055463790895 and perplexity is 53.34101494318525
At time: 813.5579128265381 and batch: 600, loss is 3.9155387449264527 and perplexity is 50.176096347972944
At time: 814.6615452766418 and batch: 650, loss is 3.939098343849182 and perplexity is 51.37226029736265
At time: 815.8105902671814 and batch: 700, loss is 3.9539541149139406 and perplexity is 52.14113178442706
At time: 816.9141144752502 and batch: 750, loss is 3.9226270484924317 and perplexity is 50.533023259339366
At time: 818.0185723304749 and batch: 800, loss is 3.8969386291503905 and perplexity is 49.25144115155046
At time: 819.1222825050354 and batch: 850, loss is 3.855107460021973 and perplexity is 47.233692402188666
At time: 820.2255520820618 and batch: 900, loss is 3.877972469329834 and perplexity is 48.326132955958194
At time: 821.3285894393921 and batch: 950, loss is 3.865013656616211 and perplexity is 47.703923902420755
At time: 822.4320728778839 and batch: 1000, loss is 3.868724136352539 and perplexity is 47.88125713763668
At time: 823.53591132164 and batch: 1050, loss is 3.815502634048462 and perplexity is 45.399570018688834
At time: 824.6392884254456 and batch: 1100, loss is 3.791646089553833 and perplexity is 44.32931026589115
At time: 825.7423949241638 and batch: 1150, loss is 3.8065556335449218 and perplexity is 44.99519172675863
At time: 826.8455464839935 and batch: 1200, loss is 3.775915713310242 and perplexity is 43.6374494188905
At time: 827.9494454860687 and batch: 1250, loss is 3.8220484590530397 and perplexity is 45.69772242144306
At time: 829.0524842739105 and batch: 1300, loss is 3.8175681018829346 and perplexity is 45.493438277824886
At time: 830.1560878753662 and batch: 1350, loss is 3.7794236040115354 and perplexity is 43.79079362204189
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.349341634114583 and perplexity of 77.42747053608292
Finished 26 epochs...
Completing Train Step...
At time: 833.5459277629852 and batch: 50, loss is 3.9783131504058837 and perplexity is 53.4268351375635
At time: 834.6779873371124 and batch: 100, loss is 3.987307171821594 and perplexity is 53.909524643016454
At time: 835.7816257476807 and batch: 150, loss is 3.9690977048873903 and perplexity is 52.93674471828953
At time: 836.8865623474121 and batch: 200, loss is 3.959181613922119 and perplexity is 52.41441316586671
At time: 837.9897608757019 and batch: 250, loss is 3.9529393100738526 and perplexity is 52.0882455506662
At time: 839.0926413536072 and batch: 300, loss is 3.9588198471069336 and perplexity is 52.39545480000647
At time: 840.1956694126129 and batch: 350, loss is 3.96254093170166 and perplexity is 52.5907859161128
At time: 841.298455953598 and batch: 400, loss is 3.9573893547058105 and perplexity is 52.320557083141075
At time: 842.4019131660461 and batch: 450, loss is 3.901112885475159 and perplexity is 49.45745897774334
At time: 843.5047664642334 and batch: 500, loss is 3.9866877889633177 and perplexity is 53.87614434621371
At time: 844.6357238292694 and batch: 550, loss is 3.975663843154907 and perplexity is 53.285478367274976
At time: 845.7397916316986 and batch: 600, loss is 3.914502935409546 and perplexity is 50.12415037756415
At time: 846.8428654670715 and batch: 650, loss is 3.9382854509353638 and perplexity is 51.33051711966541
At time: 847.9454777240753 and batch: 700, loss is 3.953304867744446 and perplexity is 52.10729028913802
At time: 849.0482094287872 and batch: 750, loss is 3.922180256843567 and perplexity is 50.51045056957534
At time: 850.1510179042816 and batch: 800, loss is 3.8965879821777345 and perplexity is 49.23417431027145
At time: 851.254691362381 and batch: 850, loss is 3.8548057460784912 and perplexity is 47.219443488244906
At time: 852.3583037853241 and batch: 900, loss is 3.8779060220718384 and perplexity is 48.32292192361707
At time: 853.4613220691681 and batch: 950, loss is 3.865003161430359 and perplexity is 47.70342324350079
At time: 854.5646381378174 and batch: 1000, loss is 3.868911557197571 and perplexity is 47.890231924315394
At time: 855.6677205562592 and batch: 1050, loss is 3.815896511077881 and perplexity is 45.41745538855163
At time: 856.7711732387543 and batch: 1100, loss is 3.7922104692459104 and perplexity is 44.35433588968168
At time: 857.8744094371796 and batch: 1150, loss is 3.8072132682800293 and perplexity is 45.02479185972197
At time: 858.9770226478577 and batch: 1200, loss is 3.7767519760131836 and perplexity is 43.67395705314988
At time: 860.0800364017487 and batch: 1250, loss is 3.822898325920105 and perplexity is 45.73657590943689
At time: 861.1832659244537 and batch: 1300, loss is 3.818397798538208 and perplexity is 45.53119969449521
At time: 862.2866775989532 and batch: 1350, loss is 3.7800556135177614 and perplexity is 43.818478567549036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3490897623697915 and perplexity of 77.40797119975322
Finished 27 epochs...
Completing Train Step...
At time: 865.7021765708923 and batch: 50, loss is 3.9780060052871704 and perplexity is 53.4104278657784
At time: 866.8048899173737 and batch: 100, loss is 3.986712875366211 and perplexity is 53.877495921830125
At time: 867.9076769351959 and batch: 150, loss is 3.968445906639099 and perplexity is 52.9022518832178
At time: 869.0103240013123 and batch: 200, loss is 3.9583925437927245 and perplexity is 52.37307083123354
At time: 870.1120851039886 and batch: 250, loss is 3.951954402923584 and perplexity is 52.03696872078166
At time: 871.2150142192841 and batch: 300, loss is 3.957818474769592 and perplexity is 52.343013701881915
At time: 872.3609840869904 and batch: 350, loss is 3.9615459346771242 and perplexity is 52.5384842649169
At time: 873.4639008045197 and batch: 400, loss is 3.9564726305007936 and perplexity is 52.272615539986944
At time: 874.5667998790741 and batch: 450, loss is 3.9002803230285643 and perplexity is 49.41629969091025
At time: 875.6693620681763 and batch: 500, loss is 3.985919303894043 and perplexity is 53.83475723841758
At time: 876.772590637207 and batch: 550, loss is 3.9750461196899414 and perplexity is 53.25257284124971
At time: 877.8763711452484 and batch: 600, loss is 3.913889307975769 and perplexity is 50.09340225870717
At time: 878.9795308113098 and batch: 650, loss is 3.9377827548980715 and perplexity is 51.30471995672624
At time: 880.0828976631165 and batch: 700, loss is 3.952919569015503 and perplexity is 52.08721728372102
At time: 881.1858184337616 and batch: 750, loss is 3.9218909215927122 and perplexity is 50.49583822972346
At time: 882.2884833812714 and batch: 800, loss is 3.8963729190826415 and perplexity is 49.223586994871155
At time: 883.3916776180267 and batch: 850, loss is 3.8546534538269044 and perplexity is 47.21225288042823
At time: 884.494818687439 and batch: 900, loss is 3.8778981447219847 and perplexity is 48.32254126855441
At time: 885.5982711315155 and batch: 950, loss is 3.86500771522522 and perplexity is 47.70364047559901
At time: 886.7012305259705 and batch: 1000, loss is 3.8690435886383057 and perplexity is 47.89655535807033
At time: 887.8037567138672 and batch: 1050, loss is 3.816148853302002 and perplexity is 45.42891757639447
At time: 888.9062793254852 and batch: 1100, loss is 3.792560167312622 and perplexity is 44.3698492275266
At time: 890.0096442699432 and batch: 1150, loss is 3.8076059007644654 and perplexity is 45.04247352658231
At time: 891.1127645969391 and batch: 1200, loss is 3.7772376585006713 and perplexity is 43.69517388115372
At time: 892.2154560089111 and batch: 1250, loss is 3.823375897407532 and perplexity is 45.75842361052807
At time: 893.3189005851746 and batch: 1300, loss is 3.81885281085968 and perplexity is 45.551921665386125
At time: 894.4221904277802 and batch: 1350, loss is 3.780417866706848 and perplexity is 43.83435482659017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348961995442708 and perplexity of 77.39808165293321
Finished 28 epochs...
Completing Train Step...
At time: 897.8374555110931 and batch: 50, loss is 3.977667899131775 and perplexity is 53.39237252383781
At time: 898.9383134841919 and batch: 100, loss is 3.9861955070495605 and perplexity is 53.84962862191034
At time: 900.0675427913666 and batch: 150, loss is 3.9678948402404783 and perplexity is 52.87310726084218
At time: 901.1687595844269 and batch: 200, loss is 3.957761077880859 and perplexity is 52.34000946196635
At time: 902.269853591919 and batch: 250, loss is 3.951212501525879 and perplexity is 51.99837673844834
At time: 903.3704507350922 and batch: 300, loss is 3.957073516845703 and perplexity is 52.304034879658346
At time: 904.4712719917297 and batch: 350, loss is 3.9608203268051145 and perplexity is 52.50037575474034
At time: 905.5719735622406 and batch: 400, loss is 3.955789079666138 and perplexity is 52.23689675919694
At time: 906.6725039482117 and batch: 450, loss is 3.8996717596054076 and perplexity is 49.3862358872041
At time: 907.7731194496155 and batch: 500, loss is 3.9853525400161742 and perplexity is 53.80425428744292
At time: 908.8738310337067 and batch: 550, loss is 3.9745877456665037 and perplexity is 53.22816883868577
At time: 909.974219083786 and batch: 600, loss is 3.9134437084197997 and perplexity is 50.071085633412125
At time: 911.0743577480316 and batch: 650, loss is 3.937402606010437 and perplexity is 51.28522023113862
At time: 912.1750717163086 and batch: 700, loss is 3.952630066871643 and perplexity is 52.07214010519275
At time: 913.2759766578674 and batch: 750, loss is 3.921658411026001 and perplexity is 50.48409877858622
At time: 914.3767981529236 and batch: 800, loss is 3.8961950826644896 and perplexity is 49.21483402679271
At time: 915.476889371872 and batch: 850, loss is 3.854534068107605 and perplexity is 47.20661674810191
At time: 916.5780146121979 and batch: 900, loss is 3.8778765535354616 and perplexity is 48.32149793881601
At time: 917.678733587265 and batch: 950, loss is 3.8649921131134035 and perplexity is 47.702896203872385
At time: 918.7801342010498 and batch: 1000, loss is 3.869121265411377 and perplexity is 47.90027595243179
At time: 919.8812131881714 and batch: 1050, loss is 3.8163098192214964 and perplexity is 45.436230672447614
At time: 920.9816746711731 and batch: 1100, loss is 3.7927853775024416 and perplexity is 44.37984289498904
At time: 922.0824360847473 and batch: 1150, loss is 3.8078577852249147 and perplexity is 45.053820454721304
At time: 923.1828510761261 and batch: 1200, loss is 3.7775500440597534 and perplexity is 43.708825754688824
At time: 924.2831892967224 and batch: 1250, loss is 3.823676118850708 and perplexity is 45.77216333287832
At time: 925.384400844574 and batch: 1300, loss is 3.819131989479065 and perplexity is 45.56464056332657
At time: 926.4852583408356 and batch: 1350, loss is 3.780651111602783 and perplexity is 43.844580158576974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3488846842447915 and perplexity of 77.39209814582321
Finished 29 epochs...
Completing Train Step...
At time: 929.869790315628 and batch: 50, loss is 3.977329626083374 and perplexity is 53.37431437768708
At time: 930.9981489181519 and batch: 100, loss is 3.985728611946106 and perplexity is 53.82449236243879
At time: 932.0983469486237 and batch: 150, loss is 3.967409191131592 and perplexity is 52.84743571760251
At time: 933.1987619400024 and batch: 200, loss is 3.957222981452942 and perplexity is 52.31185306594516
At time: 934.2990372180939 and batch: 250, loss is 3.950606179237366 and perplexity is 51.966858519730145
At time: 935.3997900485992 and batch: 300, loss is 3.9564710664749145 and perplexity is 52.272533784327415
At time: 936.5001952648163 and batch: 350, loss is 3.9602422952651977 and perplexity is 52.47003765073182
At time: 937.601452589035 and batch: 400, loss is 3.955234146118164 and perplexity is 52.207916794464246
At time: 938.7010054588318 and batch: 450, loss is 3.8991802501678468 and perplexity is 49.36196805060385
At time: 939.80140209198 and batch: 500, loss is 3.984888782501221 and perplexity is 53.77930794515462
At time: 940.9020533561707 and batch: 550, loss is 3.9742063999176027 and perplexity is 53.20787437262747
At time: 942.0029537677765 and batch: 600, loss is 3.913081178665161 and perplexity is 50.05293666499225
At time: 943.1034691333771 and batch: 650, loss is 3.9370841503143312 and perplexity is 51.268890760874385
At time: 944.2039542198181 and batch: 700, loss is 3.9523840141296387 and perplexity is 52.05932918848306
At time: 945.3043522834778 and batch: 750, loss is 3.9214528465270995 and perplexity is 50.47372210669252
At time: 946.405115365982 and batch: 800, loss is 3.896030764579773 and perplexity is 49.206747803900306
At time: 947.5053179264069 and batch: 850, loss is 3.8544195175170897 and perplexity is 47.20120951198414
At time: 948.6057548522949 and batch: 900, loss is 3.877833852767944 and perplexity is 48.31943461781944
At time: 949.7067291736603 and batch: 950, loss is 3.864956569671631 and perplexity is 47.70120070889083
At time: 950.8069832324982 and batch: 1000, loss is 3.869158639907837 and perplexity is 47.90206623458104
At time: 951.9077665805817 and batch: 1050, loss is 3.8164110660552977 and perplexity is 45.440831179832536
At time: 953.0078730583191 and batch: 1100, loss is 3.792932505607605 and perplexity is 44.3863728975433
At time: 954.1085343360901 and batch: 1150, loss is 3.8080266666412355 and perplexity is 45.061429850255024
At time: 955.2099184989929 and batch: 1200, loss is 3.7777643489837645 and perplexity is 43.71819377504139
At time: 956.3536083698273 and batch: 1250, loss is 3.82387957572937 and perplexity is 45.78147694178642
At time: 957.4535512924194 and batch: 1300, loss is 3.819316449165344 and perplexity is 45.573046177854984
At time: 958.553395986557 and batch: 1350, loss is 3.78081298828125 and perplexity is 43.85167814806579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348834228515625 and perplexity of 77.38819336958956
Finished 30 epochs...
Completing Train Step...
At time: 961.9364738464355 and batch: 50, loss is 3.976998701095581 and perplexity is 53.35665440557738
At time: 963.0646786689758 and batch: 100, loss is 3.9852982234954832 and perplexity is 53.801331906919145
At time: 964.1648530960083 and batch: 150, loss is 3.966968688964844 and perplexity is 52.82416143422431
At time: 965.2653353214264 and batch: 200, loss is 3.95674635887146 and perplexity is 52.28692599636878
At time: 966.3646190166473 and batch: 250, loss is 3.950083212852478 and perplexity is 51.93968870466532
At time: 967.4644718170166 and batch: 300, loss is 3.9559556102752684 and perplexity is 52.24559652580195
At time: 968.5640456676483 and batch: 350, loss is 3.9597531175613403 and perplexity is 52.44437675507324
At time: 969.6635980606079 and batch: 400, loss is 3.9547575950622558 and perplexity is 52.183042983880156
At time: 970.7638680934906 and batch: 450, loss is 3.8987584400177 and perplexity is 49.34115106216605
At time: 971.8635494709015 and batch: 500, loss is 3.9844858407974244 and perplexity is 53.757642384454314
At time: 972.9630300998688 and batch: 550, loss is 3.9738688611984254 and perplexity is 53.18991768557065
At time: 974.062593460083 and batch: 600, loss is 3.912765121459961 and perplexity is 50.037119573402414
At time: 975.1623477935791 and batch: 650, loss is 3.936801700592041 and perplexity is 51.254411921785135
At time: 976.2621042728424 and batch: 700, loss is 3.952161502838135 and perplexity is 52.04774668857681
At time: 977.3624544143677 and batch: 750, loss is 3.9212623405456544 and perplexity is 50.46410747657675
At time: 978.4624693393707 and batch: 800, loss is 3.895872449874878 and perplexity is 49.19895826875814
At time: 979.5615866184235 and batch: 850, loss is 3.854303231239319 and perplexity is 47.19572097815048
At time: 980.6616604328156 and batch: 900, loss is 3.877773814201355 and perplexity is 48.31653367531168
At time: 981.7615306377411 and batch: 950, loss is 3.864905834197998 and perplexity is 47.69878062727251
At time: 982.8614373207092 and batch: 1000, loss is 3.8691676235198975 and perplexity is 47.90249657009397
At time: 983.9895565509796 and batch: 1050, loss is 3.816472539901733 and perplexity is 45.44362468837336
At time: 985.0899128913879 and batch: 1100, loss is 3.79302885055542 and perplexity is 44.39064950633532
At time: 986.1898493766785 and batch: 1150, loss is 3.808143105506897 and perplexity is 45.06667705751536
At time: 987.2891979217529 and batch: 1200, loss is 3.777917799949646 and perplexity is 43.724902888849606
At time: 988.3890023231506 and batch: 1250, loss is 3.8240249156951904 and perplexity is 45.78813130364099
At time: 989.4888899326324 and batch: 1300, loss is 3.8194449043273924 and perplexity is 45.578900646897125
At time: 990.589058637619 and batch: 1350, loss is 3.7809314489364625 and perplexity is 43.85687315428723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348797607421875 and perplexity of 77.38535938119719
Finished 31 epochs...
Completing Train Step...
At time: 994.0183236598969 and batch: 50, loss is 3.9766764402389527 and perplexity is 53.33946241472344
At time: 995.1187298297882 and batch: 100, loss is 3.984895262718201 and perplexity is 53.77965644786832
At time: 996.2195730209351 and batch: 150, loss is 3.966561346054077 and perplexity is 52.80264826846212
At time: 997.3205058574677 and batch: 200, loss is 3.956313228607178 and perplexity is 52.26428385014684
At time: 998.4220118522644 and batch: 250, loss is 3.9496153163909913 and perplexity is 51.91539199272572
At time: 999.523107290268 and batch: 300, loss is 3.9554964208602907 and perplexity is 52.22161140817562
At time: 1000.6235768795013 and batch: 350, loss is 3.959320855140686 and perplexity is 52.42171192075838
At time: 1001.7241425514221 and batch: 400, loss is 3.954332404136658 and perplexity is 52.16085994388118
At time: 1002.8252065181732 and batch: 450, loss is 3.898381443023682 and perplexity is 49.322553102441944
At time: 1003.9262278079987 and batch: 500, loss is 3.9841227626800535 and perplexity is 53.73812770375421
At time: 1005.0276110172272 and batch: 550, loss is 3.9735594320297243 and perplexity is 53.173461719667145
At time: 1006.128191947937 and batch: 600, loss is 3.912477898597717 and perplexity is 50.022749832457954
At time: 1007.2286994457245 and batch: 650, loss is 3.9365420961380004 and perplexity is 51.2411077751436
At time: 1008.3292381763458 and batch: 700, loss is 3.951953091621399 and perplexity is 52.036900484635616
At time: 1009.4299387931824 and batch: 750, loss is 3.9210813999176026 and perplexity is 50.45497729531114
At time: 1010.5305638313293 and batch: 800, loss is 3.895717782974243 and perplexity is 49.191349406802956
At time: 1011.6599028110504 and batch: 850, loss is 3.854184012413025 and perplexity is 47.19009469507546
At time: 1012.7609639167786 and batch: 900, loss is 3.877701234817505 and perplexity is 48.313027018324796
At time: 1013.8618042469025 and batch: 950, loss is 3.864843339920044 and perplexity is 47.69579981956061
At time: 1014.9635007381439 and batch: 1000, loss is 3.8691560411453247 and perplexity is 47.90194174864881
At time: 1016.0638687610626 and batch: 1050, loss is 3.8165061712265014 and perplexity is 45.44515304337406
At time: 1017.1646933555603 and batch: 1100, loss is 3.793090133666992 and perplexity is 44.39336998682068
At time: 1018.2658298015594 and batch: 1150, loss is 3.808224391937256 and perplexity is 45.07034051571423
At time: 1019.3670265674591 and batch: 1200, loss is 3.778030819892883 and perplexity is 43.72984495416286
At time: 1020.4671626091003 and batch: 1250, loss is 3.8241323900222777 and perplexity is 45.7930526166941
At time: 1021.5674178600311 and batch: 1300, loss is 3.8195380210876464 and perplexity is 45.58314500406863
At time: 1022.6681141853333 and batch: 1350, loss is 3.7810213565826416 and perplexity is 43.860816399782614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348770751953125 and perplexity of 77.38328118900215
Finished 32 epochs...
Completing Train Step...
At time: 1026.0837171077728 and batch: 50, loss is 3.9763624048233033 and perplexity is 53.322714564320236
At time: 1027.186583995819 and batch: 100, loss is 3.9845136070251463 and perplexity is 53.75913505211734
At time: 1028.2886214256287 and batch: 150, loss is 3.9661788272857668 and perplexity is 52.78245412704823
At time: 1029.3912267684937 and batch: 200, loss is 3.9559112977981568 and perplexity is 52.243281445295565
At time: 1030.4935488700867 and batch: 250, loss is 3.949185872077942 and perplexity is 51.89310200937057
At time: 1031.5960865020752 and batch: 300, loss is 3.955076370239258 and perplexity is 52.19968029428375
At time: 1032.6986598968506 and batch: 350, loss is 3.958927774429321 and perplexity is 52.40111000631846
At time: 1033.8015868663788 and batch: 400, loss is 3.953942880630493 and perplexity is 52.14054601946365
At time: 1034.9038422107697 and batch: 450, loss is 3.8980359125137327 and perplexity is 49.30551359952006
At time: 1036.0060501098633 and batch: 500, loss is 3.983787326812744 and perplexity is 53.720105031174704
At time: 1037.1083295345306 and batch: 550, loss is 3.9732695913314817 and perplexity is 53.158052119666834
At time: 1038.211844921112 and batch: 600, loss is 3.9122102212905885 and perplexity is 50.00936166942129
At time: 1039.3144087791443 and batch: 650, loss is 3.936298379898071 and perplexity is 51.22862100670276
At time: 1040.4457705020905 and batch: 700, loss is 3.9517536401748656 and perplexity is 52.026522684528864
At time: 1041.5485835075378 and batch: 750, loss is 3.920906925201416 and perplexity is 50.44617494538342
At time: 1042.65114569664 and batch: 800, loss is 3.895565142631531 and perplexity is 49.183841395398325
At time: 1043.7546508312225 and batch: 850, loss is 3.8540623378753662 and perplexity is 47.184353211424636
At time: 1044.85706949234 and batch: 900, loss is 3.8776193618774415 and perplexity is 48.30907165068044
At time: 1045.9593873023987 and batch: 950, loss is 3.8647722244262694 and perplexity is 47.6924080298113
At time: 1047.0622820854187 and batch: 1000, loss is 3.8691293573379517 and perplexity is 47.90066355951594
At time: 1048.1650404930115 and batch: 1050, loss is 3.8165198087692263 and perplexity is 45.44577280781635
At time: 1049.2678122520447 and batch: 1100, loss is 3.7931267690658568 and perplexity is 44.3949963854288
At time: 1050.3709897994995 and batch: 1150, loss is 3.8082810068130493 and perplexity is 45.07289223967657
At time: 1051.4741969108582 and batch: 1200, loss is 3.7781151819229124 and perplexity is 43.733534248272036
At time: 1052.577164888382 and batch: 1250, loss is 3.8242137002944947 and perplexity is 45.7967762136493
At time: 1053.680243730545 and batch: 1300, loss is 3.8196074295043947 and perplexity is 45.58630896779536
At time: 1054.7830665111542 and batch: 1350, loss is 3.781091122627258 and perplexity is 43.86387650220086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348747965494792 and perplexity of 77.38151791817911
Finished 33 epochs...
Completing Train Step...
At time: 1058.1864857673645 and batch: 50, loss is 3.976055941581726 and perplexity is 53.30637561613655
At time: 1059.3170771598816 and batch: 100, loss is 3.9841486024856567 and perplexity is 53.73951630446807
At time: 1060.4190835952759 and batch: 150, loss is 3.9658159112930296 and perplexity is 52.763302005825366
At time: 1061.5221590995789 and batch: 200, loss is 3.9555332469940185 and perplexity is 52.22353456363179
At time: 1062.6244473457336 and batch: 250, loss is 3.9487845039367677 and perplexity is 51.872277950813704
At time: 1063.727034330368 and batch: 300, loss is 3.954684500694275 and perplexity is 52.17922883673196
At time: 1064.8286225795746 and batch: 350, loss is 3.9585624361038207 and perplexity is 52.38196936915145
At time: 1065.9309096336365 and batch: 400, loss is 3.9535793113708495 and perplexity is 52.121592765368995
At time: 1067.0333771705627 and batch: 450, loss is 3.897712721824646 and perplexity is 49.289581091361896
At time: 1068.1643846035004 and batch: 500, loss is 3.9834723806381227 and perplexity is 53.70318875359317
At time: 1069.2669718265533 and batch: 550, loss is 3.972994270324707 and perplexity is 53.14341860578838
At time: 1070.36913895607 and batch: 600, loss is 3.9119565296173096 and perplexity is 49.99667631993156
At time: 1071.4715974330902 and batch: 650, loss is 3.9360659456253053 and perplexity is 51.216715103157895
At time: 1072.5740525722504 and batch: 700, loss is 3.95156099319458 and perplexity is 52.016500897403446
At time: 1073.6761128902435 and batch: 750, loss is 3.920737042427063 and perplexity is 50.43760573712925
At time: 1074.7790274620056 and batch: 800, loss is 3.895414228439331 and perplexity is 49.17641941575997
At time: 1075.8826751708984 and batch: 850, loss is 3.8539384508132937 and perplexity is 47.17850804260735
At time: 1076.9850351810455 and batch: 900, loss is 3.877530822753906 and perplexity is 48.30479459716375
At time: 1078.0875868797302 and batch: 950, loss is 3.8646942615509032 and perplexity is 47.68868993748662
At time: 1079.1891808509827 and batch: 1000, loss is 3.8690914344787597 and perplexity is 47.898847063840144
At time: 1080.2914669513702 and batch: 1050, loss is 3.8165183305740356 and perplexity is 45.4457056301432
At time: 1081.3936893939972 and batch: 1100, loss is 3.7931450700759886 and perplexity is 44.39580886614203
At time: 1082.4967195987701 and batch: 1150, loss is 3.808319330215454 and perplexity is 45.07461961936274
At time: 1083.5992941856384 and batch: 1200, loss is 3.7781781482696535 and perplexity is 43.73628807585205
At time: 1084.7014071941376 and batch: 1250, loss is 3.8242757987976073 and perplexity is 45.799620213202694
At time: 1085.8036091327667 and batch: 1300, loss is 3.8196591663360597 and perplexity is 45.588667520000136
At time: 1086.905728816986 and batch: 1350, loss is 3.7811462926864623 and perplexity is 43.866296541620656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348730875651042 and perplexity of 77.38019549142884
Finished 34 epochs...
Completing Train Step...
At time: 1090.2887239456177 and batch: 50, loss is 3.9757573127746584 and perplexity is 53.290459173449634
At time: 1091.4191341400146 and batch: 100, loss is 3.9837973976135252 and perplexity is 53.7206460383746
At time: 1092.5216283798218 and batch: 150, loss is 3.9654684591293337 and perplexity is 52.744972466883084
At time: 1093.6237411499023 and batch: 200, loss is 3.955173683166504 and perplexity is 52.204760245142936
At time: 1094.7260692119598 and batch: 250, loss is 3.948404951095581 and perplexity is 51.85259341623547
At time: 1095.856644153595 and batch: 300, loss is 3.954314475059509 and perplexity is 52.159924756182654
At time: 1096.9594309329987 and batch: 350, loss is 3.9582188510894776 and perplexity is 52.36397480096343
At time: 1098.0620169639587 and batch: 400, loss is 3.953235635757446 and perplexity is 52.10368292276815
At time: 1099.1646194458008 and batch: 450, loss is 3.8974071168899536 and perplexity is 49.27452025360183
At time: 1100.2662031650543 and batch: 500, loss is 3.9831734800338747 and perplexity is 53.68713923674931
At time: 1101.368364572525 and batch: 550, loss is 3.972730960845947 and perplexity is 53.129427282040695
At time: 1102.47079372406 and batch: 600, loss is 3.9117138290405276 and perplexity is 49.984543570123776
At time: 1103.5738463401794 and batch: 650, loss is 3.9358430194854734 and perplexity is 51.20529883110508
At time: 1104.6766726970673 and batch: 700, loss is 3.95137336730957 and perplexity is 52.00674217091092
At time: 1105.7788689136505 and batch: 750, loss is 3.92057110786438 and perplexity is 50.429237089421626
At time: 1106.8811848163605 and batch: 800, loss is 3.8952647829055786 and perplexity is 49.16907076863727
At time: 1107.983359336853 and batch: 850, loss is 3.853813328742981 and perplexity is 47.172605339293725
At time: 1109.0855185985565 and batch: 900, loss is 3.8774373292922975 and perplexity is 48.300278625814755
At time: 1110.1893141269684 and batch: 950, loss is 3.864611225128174 and perplexity is 47.684730203672906
At time: 1111.2925345897675 and batch: 1000, loss is 3.869045181274414 and perplexity is 47.8966316399146
At time: 1112.3950414657593 and batch: 1050, loss is 3.8165055656433107 and perplexity is 45.44512552256161
At time: 1113.4971868991852 and batch: 1100, loss is 3.793148846626282 and perplexity is 44.395976529463624
At time: 1114.599616765976 and batch: 1150, loss is 3.808343138694763 and perplexity is 45.07569279028654
At time: 1115.7022213935852 and batch: 1200, loss is 3.7782258415222167 and perplexity is 43.738374051428515
At time: 1116.8047201633453 and batch: 1250, loss is 3.824324026107788 and perplexity is 45.8018290589558
At time: 1117.907764673233 and batch: 1300, loss is 3.8196969699859618 and perplexity is 45.59039097060272
At time: 1119.0106999874115 and batch: 1350, loss is 3.7811907434463503 and perplexity is 43.868246475173095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3487150065104165 and perplexity of 77.3789675439682
Finished 35 epochs...
Completing Train Step...
At time: 1122.4382371902466 and batch: 50, loss is 3.9754677486419676 and perplexity is 53.27503040177563
At time: 1123.5387773513794 and batch: 100, loss is 3.983458046913147 and perplexity is 53.70241899237203
At time: 1124.667938709259 and batch: 150, loss is 3.965134105682373 and perplexity is 52.727339951439355
At time: 1125.7684361934662 and batch: 200, loss is 3.954828476905823 and perplexity is 52.186741945262845
At time: 1126.8683607578278 and batch: 250, loss is 3.9480435037612915 and perplexity is 51.83385482128078
At time: 1127.9685864448547 and batch: 300, loss is 3.953961954116821 and perplexity is 52.141540530939665
At time: 1129.0692873001099 and batch: 350, loss is 3.9578932619094847 and perplexity is 52.34692843255396
At time: 1130.1698236465454 and batch: 400, loss is 3.9529075527191164 and perplexity is 52.08659139204065
At time: 1131.2710576057434 and batch: 450, loss is 3.897115330696106 and perplexity is 49.260144726275556
At time: 1132.3715920448303 and batch: 500, loss is 3.9828874921798705 and perplexity is 53.67178756231221
At time: 1133.476361989975 and batch: 550, loss is 3.9724778366088866 and perplexity is 53.115980638202
At time: 1134.5761070251465 and batch: 600, loss is 3.9114802408218385 and perplexity is 49.97286913318779
At time: 1135.6778132915497 and batch: 650, loss is 3.9356284761428832 and perplexity is 51.19431425351166
At time: 1136.778729915619 and batch: 700, loss is 3.9511902570724486 and perplexity is 51.99722007584324
At time: 1137.8799443244934 and batch: 750, loss is 3.92040825843811 and perplexity is 50.42102538574815
At time: 1138.9813511371613 and batch: 800, loss is 3.8951167345046995 and perplexity is 49.16179190516261
At time: 1140.0829043388367 and batch: 850, loss is 3.853687057495117 and perplexity is 47.166649171606814
At time: 1141.183657169342 and batch: 900, loss is 3.8773400354385377 and perplexity is 48.295579534169654
At time: 1142.2851078510284 and batch: 950, loss is 3.864524369239807 and perplexity is 47.68058868392982
At time: 1143.3855242729187 and batch: 1000, loss is 3.86899320602417 and perplexity is 47.89414226519276
At time: 1144.4863920211792 and batch: 1050, loss is 3.816484375 and perplexity is 45.4441625213198
At time: 1145.5889785289764 and batch: 1100, loss is 3.7931410121917724 and perplexity is 44.395628713455494
At time: 1146.6907885074615 and batch: 1150, loss is 3.8083540201187134 and perplexity is 45.07618328067826
At time: 1147.791621685028 and batch: 1200, loss is 3.7782614469528197 and perplexity is 43.739931402795406
At time: 1148.8920528888702 and batch: 1250, loss is 3.8243604421615602 and perplexity is 45.8034970111956
At time: 1149.9934258460999 and batch: 1300, loss is 3.819725332260132 and perplexity is 45.591684036108006
At time: 1151.0938391685486 and batch: 1350, loss is 3.781226010322571 and perplexity is 43.8697935984725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348702799479167 and perplexity of 77.37802298225847
Finished 36 epochs...
Completing Train Step...
At time: 1154.5028710365295 and batch: 50, loss is 3.9751825189590453 and perplexity is 53.259836948661366
At time: 1155.6037230491638 and batch: 100, loss is 3.983128099441528 and perplexity is 53.68470293785011
At time: 1156.7043707370758 and batch: 150, loss is 3.9648102569580077 and perplexity is 52.71026703432734
At time: 1157.8046264648438 and batch: 200, loss is 3.954495391845703 and perplexity is 52.16936221580935
At time: 1158.9052810668945 and batch: 250, loss is 3.9476955938339233 and perplexity is 51.81582444526997
At time: 1160.0055129528046 and batch: 300, loss is 3.953622817993164 and perplexity is 52.12386044914915
At time: 1161.1060032844543 and batch: 350, loss is 3.9575804328918456 and perplexity is 52.33055535547632
At time: 1162.2064650058746 and batch: 400, loss is 3.9525920057296755 and perplexity is 52.07015821779234
At time: 1163.3067219257355 and batch: 450, loss is 3.896834735870361 and perplexity is 49.24632452357929
At time: 1164.406950712204 and batch: 500, loss is 3.982611904144287 and perplexity is 53.656998297777434
At time: 1165.5075008869171 and batch: 550, loss is 3.972232346534729 and perplexity is 53.102942792572485
At time: 1166.6086075305939 and batch: 600, loss is 3.9112537622451784 and perplexity is 49.961552630435975
At time: 1167.7091300487518 and batch: 650, loss is 3.9354196786880493 and perplexity is 51.18362612685921
At time: 1168.809362411499 and batch: 700, loss is 3.9510104131698607 and perplexity is 51.98786953370527
At time: 1169.9114389419556 and batch: 750, loss is 3.9202478075027467 and perplexity is 50.41293593406043
At time: 1171.0125806331635 and batch: 800, loss is 3.894969692230225 and perplexity is 49.154563574911705
At time: 1172.1131365299225 and batch: 850, loss is 3.853560223579407 and perplexity is 47.16066722016664
At time: 1173.21479678154 and batch: 900, loss is 3.8772402238845824 and perplexity is 48.29075931788782
At time: 1174.3151581287384 and batch: 950, loss is 3.8644341230392456 and perplexity is 47.67628588611906
At time: 1175.4153983592987 and batch: 1000, loss is 3.868935770988464 and perplexity is 47.89139154241636
At time: 1176.5164670944214 and batch: 1050, loss is 3.816455626487732 and perplexity is 45.442856088035136
At time: 1177.6174974441528 and batch: 1100, loss is 3.7931246614456176 and perplexity is 44.3949028177345
At time: 1178.717636346817 and batch: 1150, loss is 3.808356161117554 and perplexity is 45.0762797888377
At time: 1179.863434791565 and batch: 1200, loss is 3.7782871913909912 and perplexity is 43.741057477250045
At time: 1180.964162826538 and batch: 1250, loss is 3.824386672973633 and perplexity is 45.80469848987579
At time: 1182.0644137859344 and batch: 1300, loss is 3.8197462606430053 and perplexity is 45.59263820631194
At time: 1183.1646945476532 and batch: 1350, loss is 3.7812528944015504 and perplexity is 43.87097301332208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348692220052083 and perplexity of 77.37720437143668
Finished 37 epochs...
Completing Train Step...
At time: 1186.549468755722 and batch: 50, loss is 3.974900007247925 and perplexity is 53.244792546201005
At time: 1187.677657365799 and batch: 100, loss is 3.982806029319763 and perplexity is 53.66741548307377
At time: 1188.7786302566528 and batch: 150, loss is 3.9644953393936158 and perplexity is 52.693670258859655
At time: 1189.879618883133 and batch: 200, loss is 3.954172773361206 and perplexity is 52.15253412990585
At time: 1190.9798502922058 and batch: 250, loss is 3.9473594188690186 and perplexity is 51.79840818992411
At time: 1192.080186367035 and batch: 300, loss is 3.953295097351074 and perplexity is 52.10678118290146
At time: 1193.1807568073273 and batch: 350, loss is 3.957277674674988 and perplexity is 52.314714247983446
At time: 1194.2828192710876 and batch: 400, loss is 3.9522866106033323 and perplexity is 52.05425867319
At time: 1195.3837790489197 and batch: 450, loss is 3.8965629816055296 and perplexity is 49.232943443127915
At time: 1196.484322309494 and batch: 500, loss is 3.9823450326919554 and perplexity is 53.642680687279686
At time: 1197.5849072933197 and batch: 550, loss is 3.971993536949158 and perplexity is 53.09026281492196
At time: 1198.6859242916107 and batch: 600, loss is 3.911032590866089 and perplexity is 49.950503786828286
At time: 1199.7865722179413 and batch: 650, loss is 3.9352152299880983 and perplexity is 51.173162770685025
At time: 1200.887175321579 and batch: 700, loss is 3.9508329820632935 and perplexity is 51.97864608677323
At time: 1201.9878931045532 and batch: 750, loss is 3.9200892353057863 and perplexity is 50.40494247784085
At time: 1203.0881316661835 and batch: 800, loss is 3.8948235750198363 and perplexity is 49.14738177190956
At time: 1204.1884150505066 and batch: 850, loss is 3.8534330892562867 and perplexity is 47.15467186177769
At time: 1205.290435552597 and batch: 900, loss is 3.877138385772705 and perplexity is 48.28584172854101
At time: 1206.3903059959412 and batch: 950, loss is 3.864341416358948 and perplexity is 47.671866180796904
At time: 1207.4909007549286 and batch: 1000, loss is 3.86887318611145 and perplexity is 47.88839435935678
At time: 1208.6195838451385 and batch: 1050, loss is 3.8164201879501345 and perplexity is 45.4412456882064
At time: 1209.720031261444 and batch: 1100, loss is 3.7931016540527343 and perplexity is 44.39388141851327
At time: 1210.8204319477081 and batch: 1150, loss is 3.8083512496948244 and perplexity is 45.076058400716256
At time: 1211.9200444221497 and batch: 1200, loss is 3.778305411338806 and perplexity is 43.74185444429498
At time: 1213.0205976963043 and batch: 1250, loss is 3.824404306411743 and perplexity is 45.805506191313015
At time: 1214.120647907257 and batch: 1300, loss is 3.8197610855102537 and perplexity is 45.593314116130976
At time: 1215.2210290431976 and batch: 1350, loss is 3.7812729692459106 and perplexity is 43.8718537251173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348683268229166 and perplexity of 77.37651170750566
Finished 38 epochs...
Completing Train Step...
At time: 1218.6031804084778 and batch: 50, loss is 3.974619164466858 and perplexity is 53.229841230167864
At time: 1219.7322759628296 and batch: 100, loss is 3.982490782737732 and perplexity is 53.65049968024088
At time: 1220.8333847522736 and batch: 150, loss is 3.964188103675842 and perplexity is 52.6774833679784
At time: 1221.9352779388428 and batch: 200, loss is 3.953859262466431 and perplexity is 52.1361863050105
At time: 1223.0382783412933 and batch: 250, loss is 3.9470326566696166 and perplexity is 51.78148519318684
At time: 1224.1449537277222 and batch: 300, loss is 3.9529765939712522 and perplexity is 52.09018763967314
At time: 1225.246259689331 and batch: 350, loss is 3.956982398033142 and perplexity is 52.2992692152321
At time: 1226.3471112251282 and batch: 400, loss is 3.9519899463653565 and perplexity is 52.03881832661989
At time: 1227.4482622146606 and batch: 450, loss is 3.8962985992431642 and perplexity is 49.21992884172556
At time: 1228.5492720603943 and batch: 500, loss is 3.9820857143402097 and perplexity is 53.628771959212806
At time: 1229.6520218849182 and batch: 550, loss is 3.971759934425354 and perplexity is 53.07786224399771
At time: 1230.7528462409973 and batch: 600, loss is 3.9108160305023194 and perplexity is 49.939687658772314
At time: 1231.8535141944885 and batch: 650, loss is 3.9350137233734133 and perplexity is 51.16285207876358
At time: 1232.9540419578552 and batch: 700, loss is 3.9506578063964843 and perplexity is 51.96954149026031
At time: 1234.054273366928 and batch: 750, loss is 3.9199322652816773 and perplexity is 50.39703103375091
At time: 1235.1552639007568 and batch: 800, loss is 3.894678249359131 and perplexity is 49.14023991514172
At time: 1236.3023374080658 and batch: 850, loss is 3.8533055925369264 and perplexity is 47.14866017905587
At time: 1237.4035847187042 and batch: 900, loss is 3.8770350408554077 and perplexity is 48.280851890062614
At time: 1238.5044586658478 and batch: 950, loss is 3.8642465543746947 and perplexity is 47.66734414746586
At time: 1239.6049091815948 and batch: 1000, loss is 3.8688060092926024 and perplexity is 47.885177477415155
At time: 1240.7057240009308 and batch: 1050, loss is 3.816379270553589 and perplexity is 45.43938638877616
At time: 1241.8067796230316 and batch: 1100, loss is 3.793073558807373 and perplexity is 44.39263417904311
At time: 1242.9083240032196 and batch: 1150, loss is 3.8083411121368407 and perplexity is 45.07560144187677
At time: 1244.0095267295837 and batch: 1200, loss is 3.778317255973816 and perplexity is 43.74237255366392
At time: 1245.1105825901031 and batch: 1250, loss is 3.82441547870636 and perplexity is 45.806017946782006
At time: 1246.211492061615 and batch: 1300, loss is 3.8197710275650025 and perplexity is 45.593767409609434
At time: 1247.3122346401215 and batch: 1350, loss is 3.7812876510620117 and perplexity is 43.87249784833414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348675130208333 and perplexity of 77.3758820184036
Finished 39 epochs...
Completing Train Step...
At time: 1250.7246141433716 and batch: 50, loss is 3.9743414163589477 and perplexity is 53.21505879547348
At time: 1251.8271243572235 and batch: 100, loss is 3.982181692123413 and perplexity is 53.63391937687628
At time: 1252.9299550056458 and batch: 150, loss is 3.963887677192688 and perplexity is 52.66166003390205
At time: 1254.0322623252869 and batch: 200, loss is 3.953553400039673 and perplexity is 52.12024224301439
At time: 1255.1365072727203 and batch: 250, loss is 3.946714344024658 and perplexity is 51.76500511472295
At time: 1256.239418745041 and batch: 300, loss is 3.9526664781570435 and perplexity is 52.0740361532661
At time: 1257.3423194885254 and batch: 350, loss is 3.9566937780380247 and perplexity is 52.284176778500836
At time: 1258.4449071884155 and batch: 400, loss is 3.9517008113861083 and perplexity is 52.02377425895082
At time: 1259.5478212833405 and batch: 450, loss is 3.896040539741516 and perplexity is 49.207228810169894
At time: 1260.6497132778168 and batch: 500, loss is 3.9818323993682863 and perplexity is 53.615188708842645
At time: 1261.7522068023682 and batch: 550, loss is 3.9715308237075804 and perplexity is 53.065702929848875
At time: 1262.854903936386 and batch: 600, loss is 3.910603394508362 and perplexity is 49.92906981255722
At time: 1263.986125946045 and batch: 650, loss is 3.934815034866333 and perplexity is 51.15268761788029
At time: 1265.089317560196 and batch: 700, loss is 3.950484428405762 and perplexity is 51.96053189663315
At time: 1266.1922736167908 and batch: 750, loss is 3.9197762870788573 and perplexity is 50.38917080845065
At time: 1267.294668674469 and batch: 800, loss is 3.8945332670211794 and perplexity is 49.133115964707294
At time: 1268.397274017334 and batch: 850, loss is 3.853178091049194 and perplexity is 47.14264903796131
At time: 1269.4993948936462 and batch: 900, loss is 3.8769301891326906 and perplexity is 48.27578982495545
At time: 1270.6025042533875 and batch: 950, loss is 3.8641495656967164 and perplexity is 47.66272117896569
At time: 1271.705854177475 and batch: 1000, loss is 3.868734722137451 and perplexity is 47.88176400100883
At time: 1272.8092813491821 and batch: 1050, loss is 3.8163333892822267 and perplexity is 45.43730161978501
At time: 1273.913213968277 and batch: 1100, loss is 3.7930408620834353 and perplexity is 44.39118270906777
At time: 1275.0161707401276 and batch: 1150, loss is 3.808326587677002 and perplexity is 45.074946747868466
At time: 1276.1327850818634 and batch: 1200, loss is 3.7783219051361083 and perplexity is 43.74257591952572
At time: 1277.2403645515442 and batch: 1250, loss is 3.824422392845154 and perplexity is 45.80633465704258
At time: 1278.3479800224304 and batch: 1300, loss is 3.8197726821899414 and perplexity is 45.59384285025646
At time: 1279.4523947238922 and batch: 1350, loss is 3.7812995290756226 and perplexity is 43.873018969555666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3486669921875 and perplexity of 77.37525233442594
Finished 40 epochs...
Completing Train Step...
At time: 1282.996745109558 and batch: 50, loss is 3.9740760803222654 and perplexity is 53.20094079577075
At time: 1284.107685804367 and batch: 100, loss is 3.981879620552063 and perplexity is 53.61772054129947
At time: 1285.2155690193176 and batch: 150, loss is 3.9635940551757813 and perplexity is 52.64619968093034
At time: 1286.3236782550812 and batch: 200, loss is 3.95325345993042 and perplexity is 52.10461163610189
At time: 1287.4318425655365 and batch: 250, loss is 3.946405291557312 and perplexity is 51.74900948404195
At time: 1288.5400557518005 and batch: 300, loss is 3.9523650789260865 and perplexity is 52.05834344382075
At time: 1289.6483826637268 and batch: 350, loss is 3.956417965888977 and perplexity is 52.269758155849416
At time: 1290.7560579776764 and batch: 400, loss is 3.9514191198349 and perplexity is 52.00912166513293
At time: 1291.8652229309082 and batch: 450, loss is 3.8957888507843017 and perplexity is 49.19484545250581
At time: 1293.0181663036346 and batch: 500, loss is 3.981585783958435 and perplexity is 53.60196800738632
At time: 1294.1259787082672 and batch: 550, loss is 3.9713084220886232 and perplexity is 53.05390234388953
At time: 1295.2333688735962 and batch: 600, loss is 3.9103969049453737 and perplexity is 49.91876104511429
At time: 1296.3430285453796 and batch: 650, loss is 3.934623064994812 and perplexity is 51.14286878550049
At time: 1297.4513292312622 and batch: 700, loss is 3.9503142261505126 and perplexity is 51.95168884949502
At time: 1298.5553312301636 and batch: 750, loss is 3.9196224784851075 and perplexity is 50.38142111694824
At time: 1299.6596071720123 and batch: 800, loss is 3.894389615058899 and perplexity is 49.12605840311442
At time: 1300.7634463310242 and batch: 850, loss is 3.853050260543823 and perplexity is 47.13662315446433
At time: 1301.867092847824 and batch: 900, loss is 3.8768233680725097 and perplexity is 48.27063322932669
At time: 1302.9706664085388 and batch: 950, loss is 3.8640508222579957 and perplexity is 47.658015030332166
At time: 1304.0735442638397 and batch: 1000, loss is 3.8686631774902343 and perplexity is 47.87833843963701
At time: 1305.1766338348389 and batch: 1050, loss is 3.816285500526428 and perplexity is 45.43512573604419
At time: 1306.2800302505493 and batch: 1100, loss is 3.793001356124878 and perplexity is 44.38942902748402
At time: 1307.383308172226 and batch: 1150, loss is 3.808303256034851 and perplexity is 45.07389508760951
At time: 1308.486403465271 and batch: 1200, loss is 3.7783184337615965 and perplexity is 43.74242407292615
At time: 1309.589478969574 and batch: 1250, loss is 3.824425301551819 and perplexity is 45.80646789442726
At time: 1310.6928679943085 and batch: 1300, loss is 3.819771285057068 and perplexity is 45.593779149644284
At time: 1311.795674085617 and batch: 1350, loss is 3.781307411193848 and perplexity is 43.87336478324095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348661295572916 and perplexity of 77.37481155869054
Finished 41 epochs...
Completing Train Step...
At time: 1315.1840879917145 and batch: 50, loss is 3.9738135814666746 and perplexity is 53.18697744245782
At time: 1316.315405368805 and batch: 100, loss is 3.9815824365615846 and perplexity is 53.60178858062775
At time: 1317.4194719791412 and batch: 150, loss is 3.963305993080139 and perplexity is 52.63103649039772
At time: 1318.5260756015778 and batch: 200, loss is 3.952959280014038 and perplexity is 52.089285760200646
At time: 1319.6343593597412 and batch: 250, loss is 3.946102747917175 and perplexity is 51.73335551846243
At time: 1320.772263288498 and batch: 300, loss is 3.9520696353912355 and perplexity is 52.042965414596736
At time: 1321.8797073364258 and batch: 350, loss is 3.9561478090286255 and perplexity is 52.25563902937002
At time: 1322.987387895584 and batch: 400, loss is 3.951142683029175 and perplexity is 51.99474641668669
At time: 1324.0941438674927 and batch: 450, loss is 3.8955424499511717 and perplexity is 49.1827252948704
At time: 1325.2029836177826 and batch: 500, loss is 3.9813443279266356 and perplexity is 53.58902705129344
At time: 1326.3054976463318 and batch: 550, loss is 3.971090245246887 and perplexity is 53.042328473655495
At time: 1327.4088068008423 and batch: 600, loss is 3.9101937055587768 and perplexity is 49.90861861399303
At time: 1328.5120701789856 and batch: 650, loss is 3.934433479309082 and perplexity is 51.133173748700735
At time: 1329.614829301834 and batch: 700, loss is 3.95014524936676 and perplexity is 51.94291096185322
At time: 1330.717763185501 and batch: 750, loss is 3.919469799995422 and perplexity is 50.373729544847656
At time: 1331.8208572864532 and batch: 800, loss is 3.894246664047241 and perplexity is 49.119036285288324
At time: 1332.9235100746155 and batch: 850, loss is 3.8529222774505616 and perplexity is 47.13059084965187
At time: 1334.0267369747162 and batch: 900, loss is 3.876715750694275 and perplexity is 48.26543874984597
At time: 1335.1296920776367 and batch: 950, loss is 3.8639510011672975 and perplexity is 47.65325799272161
At time: 1336.2325716018677 and batch: 1000, loss is 3.8685898303985597 and perplexity is 47.87482683154295
At time: 1337.335452079773 and batch: 1050, loss is 3.8162346410751344 and perplexity is 45.432814989241955
At time: 1338.4382510185242 and batch: 1100, loss is 3.7929584121704103 and perplexity is 44.38752281079555
At time: 1339.5412430763245 and batch: 1150, loss is 3.8082758235931395 and perplexity is 45.07265861756958
At time: 1340.6438403129578 and batch: 1200, loss is 3.7783098125457766 and perplexity is 43.74204696167332
At time: 1341.746862411499 and batch: 1250, loss is 3.824422264099121 and perplexity is 45.80632875965908
At time: 1342.8493511676788 and batch: 1300, loss is 3.8197665882110594 and perplexity is 45.59356500318758
At time: 1343.9518401622772 and batch: 1350, loss is 3.781310405731201 and perplexity is 43.873496163867316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348656819661458 and perplexity of 77.37446523665996
Finished 42 epochs...
Completing Train Step...
At time: 1347.336194038391 and batch: 50, loss is 3.973551073074341 and perplexity is 53.17301724693071
At time: 1348.4654471874237 and batch: 100, loss is 3.9812895584106447 and perplexity is 53.58609208659345
At time: 1349.5661435127258 and batch: 150, loss is 3.9630226135253905 and perplexity is 52.61612404375216
At time: 1350.6673774719238 and batch: 200, loss is 3.9526704931259156 and perplexity is 52.07424522932001
At time: 1351.7679541110992 and batch: 250, loss is 3.9458058500289916 and perplexity is 51.71799827433984
At time: 1352.8692421913147 and batch: 300, loss is 3.9517797565460206 and perplexity is 52.02788144624809
At time: 1353.9700779914856 and batch: 350, loss is 3.9558814764022827 and perplexity is 52.241723500947984
At time: 1355.0705196857452 and batch: 400, loss is 3.9508717536926268 and perplexity is 51.98066142264123
At time: 1356.1717324256897 and batch: 450, loss is 3.89530068397522 and perplexity is 49.17083602255819
At time: 1357.2727916240692 and batch: 500, loss is 3.98110737323761 and perplexity is 53.5763303843801
At time: 1358.3741590976715 and batch: 550, loss is 3.970875506401062 and perplexity is 53.03093944813605
At time: 1359.4749705791473 and batch: 600, loss is 3.9099932050704957 and perplexity is 49.89861291469881
At time: 1360.5761108398438 and batch: 650, loss is 3.93424614906311 and perplexity is 51.12359585582759
At time: 1361.6763582229614 and batch: 700, loss is 3.9499779081344606 and perplexity is 51.93421949836403
At time: 1362.7771949768066 and batch: 750, loss is 3.919318232536316 and perplexity is 50.366095105235765
At time: 1363.8783628940582 and batch: 800, loss is 3.8941042947769167 and perplexity is 49.11204374170682
At time: 1364.9795696735382 and batch: 850, loss is 3.8527947521209716 and perplexity is 47.12458088873926
At time: 1366.0800263881683 and batch: 900, loss is 3.876607656478882 and perplexity is 48.2602218170789
At time: 1367.1803319454193 and batch: 950, loss is 3.8638502550125122 and perplexity is 47.64845735204296
At time: 1368.2804775238037 and batch: 1000, loss is 3.868513808250427 and perplexity is 47.87118742270533
At time: 1369.3812692165375 and batch: 1050, loss is 3.816180257797241 and perplexity is 45.430344271022406
At time: 1370.4821684360504 and batch: 1100, loss is 3.792912745475769 and perplexity is 44.385495825628674
At time: 1371.583464384079 and batch: 1150, loss is 3.8082453346252443 and perplexity is 45.07128441967708
At time: 1372.684335231781 and batch: 1200, loss is 3.778297619819641 and perplexity is 43.741513630125496
At time: 1373.7852268218994 and batch: 1250, loss is 3.8244146966934203 and perplexity is 45.80598212589726
At time: 1374.8869543075562 and batch: 1300, loss is 3.8197587442398073 and perplexity is 45.593207369977044
At time: 1375.9878950119019 and batch: 1350, loss is 3.781309905052185 and perplexity is 43.87347419733393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348651123046875 and perplexity of 77.37402446540841
Finished 43 epochs...
Completing Train Step...
At time: 1379.412361383438 and batch: 50, loss is 3.973290786743164 and perplexity is 53.159178838406326
At time: 1380.5123040676117 and batch: 100, loss is 3.981000819206238 and perplexity is 53.570621914527166
At time: 1381.6127212047577 and batch: 150, loss is 3.9627434825897216 and perplexity is 52.60143930539428
At time: 1382.712467432022 and batch: 200, loss is 3.9523868274688723 and perplexity is 52.05947564924236
At time: 1383.813167333603 and batch: 250, loss is 3.9455145740509034 and perplexity is 51.70293625751605
At time: 1384.9142730236053 and batch: 300, loss is 3.951495132446289 and perplexity is 52.01307516454276
At time: 1386.0163490772247 and batch: 350, loss is 3.955619606971741 and perplexity is 52.22804478166165
At time: 1387.1163175106049 and batch: 400, loss is 3.950605583190918 and perplexity is 51.966827545077955
At time: 1388.2168505191803 and batch: 450, loss is 3.895062999725342 and perplexity is 49.159150278096014
At time: 1389.3170952796936 and batch: 500, loss is 3.9808747816085814 and perplexity is 53.56387042751564
At time: 1390.4178318977356 and batch: 550, loss is 3.970664076805115 and perplexity is 53.01972832325941
At time: 1391.517905473709 and batch: 600, loss is 3.9097956895828245 and perplexity is 49.888758139102286
At time: 1392.6185731887817 and batch: 650, loss is 3.934060826301575 and perplexity is 51.11412236771757
At time: 1393.7185678482056 and batch: 700, loss is 3.949811840057373 and perplexity is 51.92559559849394
At time: 1394.8184986114502 and batch: 750, loss is 3.919167523384094 and perplexity is 50.35850504570181
At time: 1395.918823003769 and batch: 800, loss is 3.89396258354187 and perplexity is 49.10508450644508
At time: 1397.0193042755127 and batch: 850, loss is 3.8526673460006715 and perplexity is 47.11857731117185
At time: 1398.1194705963135 and batch: 900, loss is 3.8764988470077513 and perplexity is 48.25497093354445
At time: 1399.219962835312 and batch: 950, loss is 3.8637484884262085 and perplexity is 47.64360857792139
At time: 1400.3197584152222 and batch: 1000, loss is 3.86843551158905 and perplexity is 47.867439415284124
At time: 1401.4200866222382 and batch: 1050, loss is 3.81612313747406 and perplexity is 45.4277493491875
At time: 1402.5205216407776 and batch: 1100, loss is 3.7928643798828126 and perplexity is 44.38334914671752
At time: 1403.6205706596375 and batch: 1150, loss is 3.8082116413116456 and perplexity is 45.06976584433989
At time: 1404.7508554458618 and batch: 1200, loss is 3.7782819271087646 and perplexity is 43.74082721258469
At time: 1405.8504602909088 and batch: 1250, loss is 3.824403414726257 and perplexity is 45.80546534722618
At time: 1406.9511296749115 and batch: 1300, loss is 3.819747724533081 and perplexity is 45.592704948971395
At time: 1408.0509896278381 and batch: 1350, loss is 3.7813062334060668 and perplexity is 43.87331310975842
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348647054036459 and perplexity of 77.37370963033742
Finished 44 epochs...
Completing Train Step...
At time: 1411.4730815887451 and batch: 50, loss is 3.9730326747894287 and perplexity is 53.14545958952461
At time: 1412.5735828876495 and batch: 100, loss is 3.9807159948349 and perplexity is 53.55536586856816
At time: 1413.6744782924652 and batch: 150, loss is 3.962468776702881 and perplexity is 52.5869913649188
At time: 1414.7743809223175 and batch: 200, loss is 3.9521077489852905 and perplexity is 52.04494899685445
At time: 1415.87526679039 and batch: 250, loss is 3.9452284812927245 and perplexity is 51.68814653759295
At time: 1416.9749422073364 and batch: 300, loss is 3.951215376853943 and perplexity is 51.99852625105521
At time: 1418.0753815174103 and batch: 350, loss is 3.9553619480133055 and perplexity is 52.21458949155455
At time: 1419.1758425235748 and batch: 400, loss is 3.9503439760208128 and perplexity is 51.95323442849044
At time: 1420.2763240337372 and batch: 450, loss is 3.8948289489746095 and perplexity is 49.1476458884261
At time: 1421.3773419857025 and batch: 500, loss is 3.980645761489868 and perplexity is 53.5516046281626
At time: 1422.4773647785187 and batch: 550, loss is 3.9704555320739745 and perplexity is 53.008672491128934
At time: 1423.5773527622223 and batch: 600, loss is 3.909600701332092 and perplexity is 49.87903136575561
At time: 1424.6773986816406 and batch: 650, loss is 3.9338774394989016 and perplexity is 51.104749571694924
At time: 1425.7774727344513 and batch: 700, loss is 3.949647078514099 and perplexity is 51.91704096198462
At time: 1426.8770785331726 and batch: 750, loss is 3.919017825126648 and perplexity is 50.350967029476905
At time: 1427.9778945446014 and batch: 800, loss is 3.893821396827698 and perplexity is 49.09815201031415
At time: 1429.077582359314 and batch: 850, loss is 3.8525402116775513 and perplexity is 47.11258730351486
At time: 1430.1774497032166 and batch: 900, loss is 3.8763896894454954 and perplexity is 48.24970382602816
At time: 1431.277015209198 and batch: 950, loss is 3.863645920753479 and perplexity is 47.638722134468956
At time: 1432.4050841331482 and batch: 1000, loss is 3.8683553409576414 and perplexity is 47.863602006268096
At time: 1433.5049178600311 and batch: 1050, loss is 3.8160635232925415 and perplexity is 45.425041291811944
At time: 1434.6067028045654 and batch: 1100, loss is 3.792813625335693 and perplexity is 44.381096547097265
At time: 1435.7067296504974 and batch: 1150, loss is 3.8081749629974366 and perplexity is 45.06811279162271
At time: 1436.8068130016327 and batch: 1200, loss is 3.7782628393173217 and perplexity is 43.73999230476561
At time: 1437.906543970108 and batch: 1250, loss is 3.824388551712036 and perplexity is 45.80478454500272
At time: 1439.007241487503 and batch: 1300, loss is 3.8197342586517333 and perplexity is 45.59209100714987
At time: 1440.1078553199768 and batch: 1350, loss is 3.7812998867034913 and perplexity is 43.873034659772735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348643798828125 and perplexity of 77.37345776320294
Finished 45 epochs...
Completing Train Step...
At time: 1443.4873552322388 and batch: 50, loss is 3.9727769756317137 and perplexity is 53.13187207750292
At time: 1444.6160852909088 and batch: 100, loss is 3.9804349040985105 and perplexity is 53.54031406689868
At time: 1445.718178510666 and batch: 150, loss is 3.962197895050049 and perplexity is 52.57274844294062
At time: 1446.8190310001373 and batch: 200, loss is 3.9518329095840454 and perplexity is 52.03064695970602
At time: 1447.9201362133026 and batch: 250, loss is 3.9449471378326417 and perplexity is 51.67360646107442
At time: 1449.0218999385834 and batch: 300, loss is 3.9509400844573976 and perplexity is 51.98421342234358
At time: 1450.1225290298462 and batch: 350, loss is 3.9551081037521363 and perplexity is 52.20133679979384
At time: 1451.2235074043274 and batch: 400, loss is 3.950086455345154 and perplexity is 51.93985711899857
At time: 1452.3241693973541 and batch: 450, loss is 3.8945983123779295 and perplexity is 49.13631194970433
At time: 1453.4256970882416 and batch: 500, loss is 3.980420241355896 and perplexity is 53.539529024809454
At time: 1454.5266139507294 and batch: 550, loss is 3.9702498960494994 and perplexity is 52.99777311914532
At time: 1455.6279079914093 and batch: 600, loss is 3.9094082927703857 and perplexity is 49.869435136299174
At time: 1456.7284910678864 and batch: 650, loss is 3.933696084022522 and perplexity is 51.095482285853016
At time: 1457.829609632492 and batch: 700, loss is 3.9494836711883545 and perplexity is 51.90855803026593
At time: 1458.9302771091461 and batch: 750, loss is 3.9188688707351687 and perplexity is 50.343467590373685
At time: 1460.0595724582672 and batch: 800, loss is 3.893680944442749 and perplexity is 49.091256542021554
At time: 1461.16073346138 and batch: 850, loss is 3.852413182258606 and perplexity is 47.10660299902408
At time: 1462.2623498439789 and batch: 900, loss is 3.876279745101929 and perplexity is 48.244399335618425
At time: 1463.3635423183441 and batch: 950, loss is 3.863542666435242 and perplexity is 47.633803484633574
At time: 1464.4645800590515 and batch: 1000, loss is 3.8682733821868895 and perplexity is 47.85967932503517
At time: 1465.565719127655 and batch: 1050, loss is 3.816001839637756 and perplexity is 45.42223939566278
At time: 1466.6665461063385 and batch: 1100, loss is 3.7927604627609255 and perplexity is 44.37873719644894
At time: 1467.7677109241486 and batch: 1150, loss is 3.8081357002258303 and perplexity is 45.066343327340704
At time: 1468.868931055069 and batch: 1200, loss is 3.7782408666610716 and perplexity is 43.739031231509024
At time: 1469.9710626602173 and batch: 1250, loss is 3.824370846748352 and perplexity is 45.803973580134866
At time: 1471.0717949867249 and batch: 1300, loss is 3.819718155860901 and perplexity is 45.59135685315575
At time: 1472.1735320091248 and batch: 1350, loss is 3.7812908124923705 and perplexity is 43.8726365484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3486421712239585 and perplexity of 77.37333182994323
Finished 46 epochs...
Completing Train Step...
At time: 1475.573915719986 and batch: 50, loss is 3.972523555755615 and perplexity is 53.11840911102785
At time: 1476.7053699493408 and batch: 100, loss is 3.980157175064087 and perplexity is 53.52544643185267
At time: 1477.8083157539368 and batch: 150, loss is 3.9619308137893676 and perplexity is 52.55870912191224
At time: 1478.9113507270813 and batch: 200, loss is 3.951561899185181 and perplexity is 52.01654802388569
At time: 1480.0139899253845 and batch: 250, loss is 3.944670114517212 and perplexity is 51.65929364987511
At time: 1481.1168353557587 and batch: 300, loss is 3.950669078826904 and perplexity is 51.97012731660254
At time: 1482.219931602478 and batch: 350, loss is 3.954857978820801 and perplexity is 52.18828157679763
At time: 1483.3225421905518 and batch: 400, loss is 3.949832782745361 and perplexity is 51.92668307142843
At time: 1484.4259667396545 and batch: 450, loss is 3.894370617866516 and perplexity is 49.12512515479651
At time: 1485.5284912586212 and batch: 500, loss is 3.9801978206634523 and perplexity is 53.52762204991854
At time: 1486.6312906742096 and batch: 550, loss is 3.9700467777252197 and perplexity is 52.98700939347078
At time: 1487.7345168590546 and batch: 600, loss is 3.909218010902405 and perplexity is 49.85994678978506
At time: 1488.865975856781 and batch: 650, loss is 3.933516273498535 and perplexity is 51.0862956063654
At time: 1489.9690318107605 and batch: 700, loss is 3.949321346282959 and perplexity is 51.900132662336475
At time: 1491.0726344585419 and batch: 750, loss is 3.918720536231995 and perplexity is 50.33600047095003
At time: 1492.175313949585 and batch: 800, loss is 3.8935407829284667 and perplexity is 49.084376319349076
At time: 1493.2781538963318 and batch: 850, loss is 3.852286195755005 and perplexity is 47.100621476007106
At time: 1494.3806366920471 and batch: 900, loss is 3.87616916179657 and perplexity is 48.239064605446316
At time: 1495.4851217269897 and batch: 950, loss is 3.8634385204315187 and perplexity is 47.62884287267695
At time: 1496.5882132053375 and batch: 1000, loss is 3.8681899976730345 and perplexity is 47.85568873532039
At time: 1497.691489458084 and batch: 1050, loss is 3.815937919616699 and perplexity is 45.41933609795456
At time: 1498.794329404831 and batch: 1100, loss is 3.7927054834365843 and perplexity is 44.37629735053392
At time: 1499.8973417282104 and batch: 1150, loss is 3.8080941343307497 and perplexity is 45.06447014337285
At time: 1501.0000848770142 and batch: 1200, loss is 3.778216280937195 and perplexity is 43.73795588898362
At time: 1502.103313446045 and batch: 1250, loss is 3.824350357055664 and perplexity is 45.80303508040715
At time: 1503.2063701152802 and batch: 1300, loss is 3.8196998023986817 and perplexity is 45.590520101588886
At time: 1504.3093929290771 and batch: 1350, loss is 3.7812795639038086 and perplexity is 43.872143045937946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348641764322917 and perplexity of 77.3733003466603
Finished 47 epochs...
Completing Train Step...
At time: 1507.7251245975494 and batch: 50, loss is 3.9722722959518433 and perplexity is 53.10506426655965
At time: 1508.827550649643 and batch: 100, loss is 3.979882798194885 and perplexity is 53.51076230202298
At time: 1509.9298441410065 and batch: 150, loss is 3.961667013168335 and perplexity is 52.544845930444865
At time: 1511.0321984291077 and batch: 200, loss is 3.9512946891784666 and perplexity is 52.00265053859523
At time: 1512.1353044509888 and batch: 250, loss is 3.9443971633911135 and perplexity is 51.64519511169338
At time: 1513.2372386455536 and batch: 300, loss is 3.9504019165039064 and perplexity is 51.956244711199275
At time: 1514.339745759964 and batch: 350, loss is 3.95461145401001 and perplexity is 52.17541745628399
At time: 1515.4422719478607 and batch: 400, loss is 3.9495826864242556 and perplexity is 51.91369802284917
At time: 1516.5734736919403 and batch: 450, loss is 3.89414608001709 and perplexity is 49.114095943125534
At time: 1517.6762664318085 and batch: 500, loss is 3.9799786472320555 and perplexity is 53.51589150287843
At time: 1518.7792012691498 and batch: 550, loss is 3.9698461055755616 and perplexity is 52.97637744319567
At time: 1519.8816993236542 and batch: 600, loss is 3.9090298128128054 and perplexity is 49.85056412597909
At time: 1520.984124660492 and batch: 650, loss is 3.933338375091553 and perplexity is 51.07720824409601
At time: 1522.0865449905396 and batch: 700, loss is 3.9491600942611695 and perplexity is 51.891764335736454
At time: 1523.1892807483673 and batch: 750, loss is 3.918573088645935 and perplexity is 50.32857909633402
At time: 1524.2919881343842 and batch: 800, loss is 3.893401255607605 and perplexity is 49.07752818558706
At time: 1525.3946640491486 and batch: 850, loss is 3.8521595430374145 and perplexity is 47.094656432049455
At time: 1526.496912240982 and batch: 900, loss is 3.87605809211731 and perplexity is 48.23370700555174
At time: 1527.5996766090393 and batch: 950, loss is 3.863333830833435 and perplexity is 47.62385688925426
At time: 1528.7021081447601 and batch: 1000, loss is 3.86810528755188 and perplexity is 47.85163504582638
At time: 1529.8048403263092 and batch: 1050, loss is 3.8158725118637085 and perplexity is 45.41636541839186
At time: 1530.9075322151184 and batch: 1100, loss is 3.792648434638977 and perplexity is 44.373765808339215
At time: 1532.0099964141846 and batch: 1150, loss is 3.8080501317977906 and perplexity is 45.062487236166874
At time: 1533.1133301258087 and batch: 1200, loss is 3.778189010620117 and perplexity is 43.73676315732135
At time: 1534.2152066230774 and batch: 1250, loss is 3.8243272495269776 and perplexity is 45.801976697688445
At time: 1535.3189120292664 and batch: 1300, loss is 3.8196793842315673 and perplexity is 45.589589236233934
At time: 1536.4217722415924 and batch: 1350, loss is 3.781266303062439 and perplexity is 43.87156126826592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348639322916667 and perplexity of 77.37311144723188
Finished 48 epochs...
Completing Train Step...
At time: 1539.8553400039673 and batch: 50, loss is 3.972023301124573 and perplexity is 53.09184302633394
At time: 1540.9575362205505 and batch: 100, loss is 3.979611487388611 and perplexity is 53.496246223232035
At time: 1542.0600152015686 and batch: 150, loss is 3.9614066076278687 and perplexity is 52.53116474284746
At time: 1543.1619963645935 and batch: 200, loss is 3.9510307788848875 and perplexity is 51.98892831462243
At time: 1544.2920248508453 and batch: 250, loss is 3.944128170013428 and perplexity is 51.63130476450851
At time: 1545.3945622444153 and batch: 300, loss is 3.9501383781433104 and perplexity is 51.94255405173158
At time: 1546.4971973896027 and batch: 350, loss is 3.954368109703064 and perplexity is 52.16272241017972
At time: 1547.5992741584778 and batch: 400, loss is 3.949335880279541 and perplexity is 51.90088698416883
At time: 1548.7008550167084 and batch: 450, loss is 3.89392418384552 and perplexity is 49.10319892231394
At time: 1549.803251504898 and batch: 500, loss is 3.9797619581222534 and perplexity is 53.50429644829481
At time: 1550.9053061008453 and batch: 550, loss is 3.9696477270126342 and perplexity is 52.96586910791808
At time: 1552.0075101852417 and batch: 600, loss is 3.908843765258789 and perplexity is 49.841290413159655
At time: 1553.1092071533203 and batch: 650, loss is 3.9331618261337282 and perplexity is 51.06819141219148
At time: 1554.2115876674652 and batch: 700, loss is 3.9489999771118165 and perplexity is 51.883456239508206
At time: 1555.3148312568665 and batch: 750, loss is 3.918426151275635 and perplexity is 50.32118449055593
At time: 1556.4169499874115 and batch: 800, loss is 3.893262014389038 and perplexity is 49.07069504649658
At time: 1557.518238544464 and batch: 850, loss is 3.852033033370972 and perplexity is 47.088698879624936
At time: 1558.6197578907013 and batch: 900, loss is 3.8759466218948364 and perplexity is 48.228330683156614
At time: 1559.721769809723 and batch: 950, loss is 3.863228507041931 and perplexity is 47.61884122821951
At time: 1560.8242874145508 and batch: 1000, loss is 3.8680193614959717 and perplexity is 47.84752352020425
At time: 1561.9260911941528 and batch: 1050, loss is 3.815805311203003 and perplexity is 45.41331351117515
At time: 1563.0281462669373 and batch: 1100, loss is 3.79258987903595 and perplexity is 44.37116755179569
At time: 1564.1300632953644 and batch: 1150, loss is 3.8080041360855104 and perplexity is 45.06041460263582
At time: 1565.2329483032227 and batch: 1200, loss is 3.7781595277786253 and perplexity is 43.73547369227446
At time: 1566.3352556228638 and batch: 1250, loss is 3.824302010536194 and perplexity is 45.80082071660867
At time: 1567.4380033016205 and batch: 1300, loss is 3.8196568775177 and perplexity is 45.58856317594034
At time: 1568.5404908657074 and batch: 1350, loss is 3.7812509393692015 and perplexity is 43.8708872442345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348640950520833 and perplexity of 77.37323738013289
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1571.919355392456 and batch: 50, loss is 3.9722097301483155 and perplexity is 53.1017418094796
At time: 1573.0470490455627 and batch: 100, loss is 3.9802457189559934 and perplexity is 53.53018599302228
At time: 1574.1474742889404 and batch: 150, loss is 3.962524104118347 and perplexity is 52.589900947727266
At time: 1575.2476036548615 and batch: 200, loss is 3.9527509212493896 and perplexity is 52.07843363157555
At time: 1576.3468525409698 and batch: 250, loss is 3.9457500553131104 and perplexity is 51.71511276381904
At time: 1577.4466009140015 and batch: 300, loss is 3.952004690170288 and perplexity is 52.03958558246229
At time: 1578.5462231636047 and batch: 350, loss is 3.956274175643921 and perplexity is 52.26224281484448
At time: 1579.6466851234436 and batch: 400, loss is 3.950972137451172 and perplexity is 51.9858796987172
At time: 1580.7464635372162 and batch: 450, loss is 3.895372943878174 and perplexity is 49.174389230773045
At time: 1581.847028017044 and batch: 500, loss is 3.9810112380981444 and perplexity is 53.5711800639539
At time: 1582.9473900794983 and batch: 550, loss is 3.9703625059127807 and perplexity is 53.00374152717499
At time: 1584.0478525161743 and batch: 600, loss is 3.9101593494415283 and perplexity is 49.906903977094515
At time: 1585.1479864120483 and batch: 650, loss is 3.9338346099853516 and perplexity is 51.10256082700244
At time: 1586.247968673706 and batch: 700, loss is 3.949355273246765 and perplexity is 51.9018935061287
At time: 1587.3478682041168 and batch: 750, loss is 3.9186052894592285 and perplexity is 50.33019974360577
At time: 1588.4496643543243 and batch: 800, loss is 3.893382248878479 and perplexity is 49.07659539116737
At time: 1589.5497443675995 and batch: 850, loss is 3.8522175121307374 and perplexity is 47.09738654571352
At time: 1590.649924993515 and batch: 900, loss is 3.8755785179138185 and perplexity is 48.21058090971585
At time: 1591.7497341632843 and batch: 950, loss is 3.8625289583206177 and perplexity is 47.5855411775898
At time: 1592.8507590293884 and batch: 1000, loss is 3.866839761734009 and perplexity is 47.79111586861623
At time: 1593.951621055603 and batch: 1050, loss is 3.813915638923645 and perplexity is 45.327578262792784
At time: 1595.052089214325 and batch: 1100, loss is 3.7903327465057375 and perplexity is 44.27112888884306
At time: 1596.1523733139038 and batch: 1150, loss is 3.805552372932434 and perplexity is 44.95007246012387
At time: 1597.2523500919342 and batch: 1200, loss is 3.7755340242385866 and perplexity is 43.620796659622684
At time: 1598.3529102802277 and batch: 1250, loss is 3.8218462753295896 and perplexity is 45.68848401972941
At time: 1599.4530782699585 and batch: 1300, loss is 3.8175336074829103 and perplexity is 45.49186903603163
At time: 1600.5535337924957 and batch: 1350, loss is 3.779715747833252 and perplexity is 43.80358870075723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348428141276042 and perplexity of 77.35677339182556
Finished Training.
Improved accuracyfrom -78.18771584478822 to -77.35677339182556
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fe2da160588>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'tune_wordvecs': True, 'anneal': 4.823538421298158, 'wordvec_source': 'glove', 'dropout': 0.0008680664032081342, 'data': 'wikitext', 'lr': 25.690914877339633, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -155.91248254449962}, {'params': {'tune_wordvecs': True, 'anneal': 3.931361136456256, 'wordvec_source': 'glove', 'dropout': 0.4448398761434641, 'data': 'wikitext', 'lr': 1.452568867888998, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -78.18771584478822}, {'params': {'tune_wordvecs': True, 'anneal': 3.7626052696443346, 'wordvec_source': 'glove', 'dropout': 0.025015537523082942, 'data': 'wikitext', 'lr': 27.819570388589018, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -175.73669371823894}, {'params': {'tune_wordvecs': True, 'anneal': 2.929063156208457, 'wordvec_source': 'glove', 'dropout': 0.08706763329456058, 'data': 'wikitext', 'lr': 17.12435468422465, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -156.82986254910548}, {'params': {'tune_wordvecs': True, 'anneal': 2.0072738283834246, 'wordvec_source': 'glove', 'dropout': 0.6409472178020267, 'data': 'wikitext', 'lr': 23.191200163761625, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -194.01032454534348}, {'params': {'tune_wordvecs': True, 'anneal': 4.582380941004718, 'wordvec_source': 'glove', 'dropout': 0.06448342699581619, 'data': 'wikitext', 'lr': 4.119635995558076, 'batch_size': 80, 'seq_len': 20, 'wordvec_dim': 200, 'num_layers': 1}, 'best_accuracy': -77.35677339182556}]
