FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7531497478485107 and batch: 50, loss is 7.586408071517944 and perplexity is 1971.2202998744647
At time: 2.70827579498291 and batch: 100, loss is 6.748347702026368 and perplexity is 852.6487681496762
At time: 3.6646888256073 and batch: 150, loss is 6.529723329544067 and perplexity is 685.2086082861523
At time: 4.624098777770996 and batch: 200, loss is 6.441351957321167 and perplexity is 627.2542477981983
At time: 5.580301523208618 and batch: 250, loss is 6.401191253662109 and perplexity is 602.562415181808
At time: 6.536568641662598 and batch: 300, loss is 6.339966077804565 and perplexity is 566.7770847324563
At time: 7.4932944774627686 and batch: 350, loss is 6.286185932159424 and perplexity is 537.1008782924245
At time: 8.450012683868408 and batch: 400, loss is 6.251968793869018 and perplexity is 519.0336897483251
At time: 9.406803131103516 and batch: 450, loss is 6.162695255279541 and perplexity is 474.7058054846605
At time: 10.361299276351929 and batch: 500, loss is 6.150080347061158 and perplexity is 468.75504835993655
At time: 11.315567970275879 and batch: 550, loss is 6.105323934555054 and perplexity is 448.2378176583393
At time: 12.277610778808594 and batch: 600, loss is 6.1504058742523195 and perplexity is 468.9076657133736
At time: 13.235304355621338 and batch: 650, loss is 6.220937843322754 and perplexity is 503.1749100351824
At time: 14.190216064453125 and batch: 700, loss is 6.12436336517334 and perplexity is 456.85377164523027
At time: 15.146023273468018 and batch: 750, loss is 6.059049730300903 and perplexity is 427.96855801473885
At time: 16.101524114608765 and batch: 800, loss is 6.061849584579468 and perplexity is 429.1684866417661
At time: 17.057504892349243 and batch: 850, loss is 6.09715124130249 and perplexity is 444.5894363283045
At time: 18.013134241104126 and batch: 900, loss is 6.082089233398437 and perplexity is 437.9432051662029
At time: 18.969109296798706 and batch: 950, loss is 6.104684429168701 and perplexity is 447.9512587973134
At time: 19.925085306167603 and batch: 1000, loss is 6.082749853134155 and perplexity is 438.2326146749505
At time: 20.882615327835083 and batch: 1050, loss is 5.979711980819702 and perplexity is 395.3264901449439
At time: 21.839821577072144 and batch: 1100, loss is 6.064598932266235 and perplexity is 430.3500435388351
At time: 22.794966459274292 and batch: 1150, loss is 5.970765991210937 and perplexity is 391.80567553856173
At time: 23.761224031448364 and batch: 1200, loss is 6.048730592727662 and perplexity is 423.57499944235997
At time: 24.716456651687622 and batch: 1250, loss is 5.983098268508911 and perplexity is 396.6674485257774
At time: 25.67243504524231 and batch: 1300, loss is 5.998996152877807 and perplexity is 403.02401586079975
At time: 26.628660202026367 and batch: 1350, loss is 5.9789305019378665 and perplexity is 395.017671524797
At time: 27.5845046043396 and batch: 1400, loss is 5.997806406021118 and perplexity is 402.54480443143177
At time: 28.541200399398804 and batch: 1450, loss is 5.982781772613525 and perplexity is 396.5419247714101
At time: 29.49814224243164 and batch: 1500, loss is 5.957609157562256 and perplexity is 386.68451643557137
At time: 30.454199075698853 and batch: 1550, loss is 5.9218284606933596 and perplexity is 373.09327697253
At time: 31.411722898483276 and batch: 1600, loss is 5.933768615722657 and perplexity is 377.5747701589351
At time: 32.36962652206421 and batch: 1650, loss is 5.930503940582275 and perplexity is 376.3441211208544
At time: 33.32636117935181 and batch: 1700, loss is 5.9429686164855955 and perplexity is 381.0644864144691
At time: 34.288331031799316 and batch: 1750, loss is 5.953894929885864 and perplexity is 385.2509460540541
At time: 35.24711799621582 and batch: 1800, loss is 5.951629495620727 and perplexity is 384.37917320507063
At time: 36.20334243774414 and batch: 1850, loss is 5.91552996635437 and perplexity is 370.75073606417453
At time: 37.15982389450073 and batch: 1900, loss is 5.897657566070556 and perplexity is 364.1833924132672
At time: 38.115896463394165 and batch: 1950, loss is 5.83880355834961 and perplexity is 343.36827470050747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.257919240552326 and perplexity of 192.0814000069442
finished 1 epochs...
Completing Train Step...
At time: 41.107736587524414 and batch: 50, loss is 5.511082067489624 and perplexity is 247.41870601037655
At time: 42.00998044013977 and batch: 100, loss is 5.385568571090698 and perplexity is 218.2341504685001
At time: 42.90165185928345 and batch: 150, loss is 5.275554933547974 and perplexity is 195.49893533385819
At time: 43.790143728256226 and batch: 200, loss is 5.213687505722046 and perplexity is 183.7704649413919
At time: 44.67856168746948 and batch: 250, loss is 5.207856130599976 and perplexity is 182.7019489107606
At time: 45.5671751499176 and batch: 300, loss is 5.195352602005005 and perplexity is 180.43175217953782
At time: 46.479875326156616 and batch: 350, loss is 5.173192911148071 and perplexity is 176.47741558277883
At time: 47.36864995956421 and batch: 400, loss is 5.116907072067261 and perplexity is 166.81861293980464
At time: 48.25745415687561 and batch: 450, loss is 5.065929355621338 and perplexity is 158.52770224576813
At time: 49.145899534225464 and batch: 500, loss is 5.045137157440186 and perplexity is 155.2655935693489
At time: 50.03396964073181 and batch: 550, loss is 4.989054460525512 and perplexity is 146.79755497022208
At time: 50.92387127876282 and batch: 600, loss is 4.9842408180236815 and perplexity is 146.0926220292108
At time: 51.81170701980591 and batch: 650, loss is 5.053166646957397 and perplexity is 156.51731564478774
At time: 52.69914793968201 and batch: 700, loss is 5.03133337020874 and perplexity is 153.1370650270942
At time: 53.5846266746521 and batch: 750, loss is 4.982985792160034 and perplexity is 145.90938701646704
At time: 54.4702730178833 and batch: 800, loss is 4.960041208267212 and perplexity is 142.5996720613056
At time: 55.35558319091797 and batch: 850, loss is 4.947548332214356 and perplexity is 140.82927374218187
At time: 56.24010229110718 and batch: 900, loss is 4.95476770401001 and perplexity is 141.8496514402462
At time: 57.125285625457764 and batch: 950, loss is 5.006854276657105 and perplexity is 149.433918241025
At time: 58.01002645492554 and batch: 1000, loss is 4.967884168624878 and perplexity is 143.72247292214536
At time: 58.89725875854492 and batch: 1050, loss is 4.87786111831665 and perplexity is 131.34942234828324
At time: 59.783878803253174 and batch: 1100, loss is 4.951001462936401 and perplexity is 141.31641623319348
At time: 60.669859409332275 and batch: 1150, loss is 4.859077787399292 and perplexity is 128.90526921153517
At time: 61.555625200271606 and batch: 1200, loss is 4.938111839294433 and perplexity is 139.50658986125012
At time: 62.44124507904053 and batch: 1250, loss is 4.8933744049072265 and perplexity is 133.40297104127333
At time: 63.32861137390137 and batch: 1300, loss is 4.918768577575683 and perplexity is 136.83400892923876
At time: 64.21769261360168 and batch: 1350, loss is 4.822912397384644 and perplexity is 124.32665263633517
At time: 65.10636949539185 and batch: 1400, loss is 4.833822641372681 and perplexity is 125.69051324811053
At time: 65.995108127594 and batch: 1450, loss is 4.780742073059082 and perplexity is 119.19276697605555
At time: 66.88409185409546 and batch: 1500, loss is 4.756824932098389 and perplexity is 116.37583749583573
At time: 67.771723985672 and batch: 1550, loss is 4.751191625595093 and perplexity is 115.72209981482497
At time: 68.66086149215698 and batch: 1600, loss is 4.809815368652344 and perplexity is 122.70895950507696
At time: 69.549560546875 and batch: 1650, loss is 4.773451290130615 and perplexity is 118.32691857713395
At time: 70.43797087669373 and batch: 1700, loss is 4.799033908843994 and perplexity is 121.39308406553913
At time: 71.32700419425964 and batch: 1750, loss is 4.804755268096923 and perplexity is 122.08960814253774
At time: 72.24393367767334 and batch: 1800, loss is 4.761068067550659 and perplexity is 116.87068504785346
At time: 73.13238072395325 and batch: 1850, loss is 4.763448162078857 and perplexity is 117.14917961607244
At time: 74.02106285095215 and batch: 1900, loss is 4.837638463973999 and perplexity is 126.171042172838
At time: 74.91100716590881 and batch: 1950, loss is 4.758783798217774 and perplexity is 116.60402560303129
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.573836357648982 and perplexity of 96.91519886694869
finished 2 epochs...
Completing Train Step...
At time: 77.85584902763367 and batch: 50, loss is 4.700161123275757 and perplexity is 109.96488892793921
At time: 78.77189373970032 and batch: 100, loss is 4.652997722625733 and perplexity is 104.89897274277303
At time: 79.65878748893738 and batch: 150, loss is 4.604700374603271 and perplexity is 99.95302989592676
At time: 80.54782438278198 and batch: 200, loss is 4.591045808792114 and perplexity is 98.59749038423406
At time: 81.43692135810852 and batch: 250, loss is 4.6029422569274905 and perplexity is 99.77745509312581
At time: 82.32608819007874 and batch: 300, loss is 4.620573034286499 and perplexity is 101.55220835672539
At time: 83.21496677398682 and batch: 350, loss is 4.629236488342285 and perplexity is 102.43582330015168
At time: 84.1041407585144 and batch: 400, loss is 4.5885346984863284 and perplexity is 98.35021181182954
At time: 84.99291801452637 and batch: 450, loss is 4.5802723407745365 and perplexity is 97.54095496932592
At time: 85.88158988952637 and batch: 500, loss is 4.577461471557617 and perplexity is 97.26716507567322
At time: 86.76798415184021 and batch: 550, loss is 4.539909601211548 and perplexity is 93.68233096746037
At time: 87.65668964385986 and batch: 600, loss is 4.529638175964355 and perplexity is 92.72500487628741
At time: 88.54560041427612 and batch: 650, loss is 4.588832931518555 and perplexity is 98.37954746793169
At time: 89.43496870994568 and batch: 700, loss is 4.60814172744751 and perplexity is 100.29759608651395
At time: 90.32432198524475 and batch: 750, loss is 4.572819480895996 and perplexity is 96.81669814424515
At time: 91.24989342689514 and batch: 800, loss is 4.544487476348877 and perplexity is 94.11218012840332
At time: 92.16361260414124 and batch: 850, loss is 4.53729546546936 and perplexity is 93.43775245766045
At time: 93.04877161979675 and batch: 900, loss is 4.529848232269287 and perplexity is 92.74448439401262
At time: 93.93282890319824 and batch: 950, loss is 4.606325273513794 and perplexity is 100.11557548962308
At time: 94.81753540039062 and batch: 1000, loss is 4.57756986618042 and perplexity is 97.27770888477849
At time: 95.70329308509827 and batch: 1050, loss is 4.510664472579956 and perplexity is 90.98225364236988
At time: 96.58898401260376 and batch: 1100, loss is 4.566061038970947 and perplexity is 96.16457426537208
At time: 97.47443294525146 and batch: 1150, loss is 4.508054876327515 and perplexity is 90.7451362191596
At time: 98.3599762916565 and batch: 1200, loss is 4.580468549728393 and perplexity is 97.56009525574503
At time: 99.24734592437744 and batch: 1250, loss is 4.557142190933227 and perplexity is 95.31071044183356
At time: 100.13294434547424 and batch: 1300, loss is 4.573641443252564 and perplexity is 96.89631054032094
At time: 101.01920199394226 and batch: 1350, loss is 4.452346153259278 and perplexity is 85.82807378434147
At time: 101.90609860420227 and batch: 1400, loss is 4.47230936050415 and perplexity is 87.55869430183658
At time: 102.79883551597595 and batch: 1450, loss is 4.417941398620606 and perplexity is 82.92539918428837
At time: 103.6842565536499 and batch: 1500, loss is 4.414810209274292 and perplexity is 82.66615014854703
At time: 104.57060980796814 and batch: 1550, loss is 4.417188320159912 and perplexity is 82.86297336103999
At time: 105.45622444152832 and batch: 1600, loss is 4.491478662490845 and perplexity is 89.25332389531897
At time: 106.34374046325684 and batch: 1650, loss is 4.4502245044708255 and perplexity is 85.64616979200933
At time: 107.23189234733582 and batch: 1700, loss is 4.472940664291382 and perplexity is 87.61398788884345
At time: 108.12116861343384 and batch: 1750, loss is 4.475154266357422 and perplexity is 87.80814520768782
At time: 109.00884294509888 and batch: 1800, loss is 4.441976308822632 and perplexity is 84.94264880495169
At time: 109.8962574005127 and batch: 1850, loss is 4.460858106613159 and perplexity is 86.56175645135781
At time: 110.78435897827148 and batch: 1900, loss is 4.5448153591156 and perplexity is 94.14304294982333
At time: 111.6723792552948 and batch: 1950, loss is 4.47450101852417 and perplexity is 87.75080345831488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.441020451035611 and perplexity of 84.86149450480512
finished 3 epochs...
Completing Train Step...
At time: 114.6553909778595 and batch: 50, loss is 4.428840866088867 and perplexity is 83.8341855217052
At time: 115.5676941871643 and batch: 100, loss is 4.391132097244263 and perplexity is 80.7317634722488
At time: 116.48026204109192 and batch: 150, loss is 4.3524042510986325 and perplexity is 77.66496471359577
At time: 117.38954710960388 and batch: 200, loss is 4.350097074508667 and perplexity is 77.485984474051
At time: 118.27960968017578 and batch: 250, loss is 4.354760866165162 and perplexity is 77.84820697050796
At time: 119.16860914230347 and batch: 300, loss is 4.372101154327392 and perplexity is 79.20988917350141
At time: 120.05603528022766 and batch: 350, loss is 4.381496725082397 and perplexity is 79.95761846286449
At time: 120.95336556434631 and batch: 400, loss is 4.3430023097991945 and perplexity is 76.93818519723344
At time: 121.86222910881042 and batch: 450, loss is 4.357123441696167 and perplexity is 78.0323466757581
At time: 122.75385928153992 and batch: 500, loss is 4.358150730133056 and perplexity is 78.1125495919123
At time: 123.63906073570251 and batch: 550, loss is 4.3192110347747805 and perplexity is 75.12933047400281
At time: 124.53672218322754 and batch: 600, loss is 4.319750556945801 and perplexity is 75.16987534993368
At time: 125.43342733383179 and batch: 650, loss is 4.3781241512298585 and perplexity is 79.68840970790001
At time: 126.34192419052124 and batch: 700, loss is 4.405282592773437 and perplexity is 81.88227891426412
At time: 127.2655839920044 and batch: 750, loss is 4.3671056747436525 and perplexity is 78.81518447973944
At time: 128.16314697265625 and batch: 800, loss is 4.338078012466431 and perplexity is 76.56024999343997
At time: 129.06433749198914 and batch: 850, loss is 4.336593170166015 and perplexity is 76.44665445232248
At time: 129.96061754226685 and batch: 900, loss is 4.322016181945801 and perplexity is 75.34037517016893
At time: 130.86831951141357 and batch: 950, loss is 4.405970525741577 and perplexity is 81.93862781334613
At time: 131.7806270122528 and batch: 1000, loss is 4.380642738342285 and perplexity is 79.88936486490816
At time: 132.69332218170166 and batch: 1050, loss is 4.319165134429932 and perplexity is 75.12588209096741
At time: 133.59446454048157 and batch: 1100, loss is 4.367017221450806 and perplexity is 78.80821332546121
At time: 134.49209237098694 and batch: 1150, loss is 4.322051033973694 and perplexity is 75.34300098078297
At time: 135.3764238357544 and batch: 1200, loss is 4.392226314544677 and perplexity is 80.82014991270039
At time: 136.30981016159058 and batch: 1250, loss is 4.3751609325408936 and perplexity is 79.45262503626127
At time: 137.20036101341248 and batch: 1300, loss is 4.3868968963623045 and perplexity is 80.39057125517323
At time: 138.09134221076965 and batch: 1350, loss is 4.262349677085877 and perplexity is 70.97655967337423
At time: 138.98190593719482 and batch: 1400, loss is 4.287129631042481 and perplexity is 72.75732811214225
At time: 139.87253165245056 and batch: 1450, loss is 4.226985006332398 and perplexity is 68.51036216657535
At time: 140.76380586624146 and batch: 1500, loss is 4.232320055961609 and perplexity is 68.87684508186092
At time: 141.65480399131775 and batch: 1550, loss is 4.235879821777344 and perplexity is 69.12246744014048
At time: 142.5455024242401 and batch: 1600, loss is 4.319829468727112 and perplexity is 75.17580737274864
At time: 143.43707013130188 and batch: 1650, loss is 4.2708231592178345 and perplexity is 71.58053355071567
At time: 144.3281238079071 and batch: 1700, loss is 4.295178122520447 and perplexity is 73.3452777272888
At time: 145.21907496452332 and batch: 1750, loss is 4.300862150192261 and perplexity is 73.76336138941399
At time: 146.10817074775696 and batch: 1800, loss is 4.265674576759339 and perplexity is 71.21294237006452
At time: 146.9982168674469 and batch: 1850, loss is 4.293663921356202 and perplexity is 73.23430226315448
At time: 147.88914799690247 and batch: 1900, loss is 4.372205638885498 and perplexity is 79.21816581615248
At time: 148.78037476539612 and batch: 1950, loss is 4.30667106628418 and perplexity is 74.19309349687175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396646189135175 and perplexity of 81.1781554266252
finished 4 epochs...
Completing Train Step...
At time: 151.7509765625 and batch: 50, loss is 4.268755278587341 and perplexity is 71.43266649027242
At time: 152.6716890335083 and batch: 100, loss is 4.234263610839844 and perplexity is 69.01084118232474
At time: 153.56248497962952 and batch: 150, loss is 4.201300811767578 and perplexity is 66.77313384989749
At time: 154.45288801193237 and batch: 200, loss is 4.202657599449157 and perplexity is 66.8637923035945
At time: 155.34358024597168 and batch: 250, loss is 4.202369060516357 and perplexity is 66.84450227941558
At time: 156.2347376346588 and batch: 300, loss is 4.217407703399658 and perplexity is 67.85734971455199
At time: 157.12622833251953 and batch: 350, loss is 4.227400531768799 and perplexity is 68.53883588007906
At time: 158.04104685783386 and batch: 400, loss is 4.190484108924866 and perplexity is 66.05476092060557
At time: 158.93204998970032 and batch: 450, loss is 4.217248740196228 and perplexity is 67.84656375017354
At time: 159.8223569393158 and batch: 500, loss is 4.224814243316651 and perplexity is 68.36180370713001
At time: 160.71300530433655 and batch: 550, loss is 4.182051692008972 and perplexity is 65.5001014836673
At time: 161.60811734199524 and batch: 600, loss is 4.184606518745422 and perplexity is 65.66765684049258
At time: 162.49977469444275 and batch: 650, loss is 4.239725975990296 and perplexity is 69.38883502653994
At time: 163.38953280448914 and batch: 700, loss is 4.271134090423584 and perplexity is 71.60279363281855
At time: 164.2801263332367 and batch: 750, loss is 4.233330273628235 and perplexity is 68.9464608452006
At time: 165.1712896823883 and batch: 800, loss is 4.2032623291015625 and perplexity is 66.90423904991356
At time: 166.06315732002258 and batch: 850, loss is 4.205049147605896 and perplexity is 67.02389164917076
At time: 166.9546172618866 and batch: 900, loss is 4.1879938697814945 and perplexity is 65.89047341184711
At time: 167.84570932388306 and batch: 950, loss is 4.2772405815124515 and perplexity is 72.04137318227352
At time: 168.7340431213379 and batch: 1000, loss is 4.248658580780029 and perplexity is 70.01143464498169
At time: 169.62350511550903 and batch: 1050, loss is 4.19302303314209 and perplexity is 66.22268203205455
At time: 170.5118489265442 and batch: 1100, loss is 4.235875272750855 and perplexity is 69.12215300092032
At time: 171.40073108673096 and batch: 1150, loss is 4.19539514541626 and perplexity is 66.37995613109425
At time: 172.28992557525635 and batch: 1200, loss is 4.264123311042786 and perplexity is 71.10255781401573
At time: 173.17857432365417 and batch: 1250, loss is 4.249155473709107 and perplexity is 70.0462314762451
At time: 174.0664255619049 and batch: 1300, loss is 4.263503322601318 and perplexity is 71.05848871259062
At time: 174.9553587436676 and batch: 1350, loss is 4.135831470489502 and perplexity is 62.541570928205886
At time: 175.8434340953827 and batch: 1400, loss is 4.1642302227020265 and perplexity is 64.34313349163764
At time: 176.73057174682617 and batch: 1450, loss is 4.101227312088013 and perplexity is 60.41438942545747
At time: 177.61762022972107 and batch: 1500, loss is 4.1106064939498905 and perplexity is 60.983692596525536
At time: 178.50559377670288 and batch: 1550, loss is 4.112076721191406 and perplexity is 61.07341842518558
At time: 179.3928461074829 and batch: 1600, loss is 4.2020890283584595 and perplexity is 66.82578628986046
At time: 180.28090453147888 and batch: 1650, loss is 4.153363213539124 and perplexity is 63.64770154679834
At time: 181.16870546340942 and batch: 1700, loss is 4.1808726024627685 and perplexity is 65.42291651167163
At time: 182.05377650260925 and batch: 1750, loss is 4.184205656051636 and perplexity is 65.64133840206934
At time: 182.93948912620544 and batch: 1800, loss is 4.147024755477905 and perplexity is 63.24554911940574
At time: 183.8264937400818 and batch: 1850, loss is 4.175360655784607 and perplexity is 65.06330088587953
At time: 184.71434092521667 and batch: 1900, loss is 4.255452089309692 and perplexity is 70.48867716351279
At time: 185.60224890708923 and batch: 1950, loss is 4.189755053520202 and perplexity is 66.00662089065943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3768395712209305 and perplexity of 79.5861092904491
finished 5 epochs...
Completing Train Step...
At time: 188.53991603851318 and batch: 50, loss is 4.153036260604859 and perplexity is 63.6268951455607
At time: 189.4280650615692 and batch: 100, loss is 4.12492190361023 and perplexity is 61.86297778648484
At time: 190.31607055664062 and batch: 150, loss is 4.098413038253784 and perplexity is 60.244605810937514
At time: 191.20385813713074 and batch: 200, loss is 4.099784321784973 and perplexity is 60.327274915165255
At time: 192.09214234352112 and batch: 250, loss is 4.094167990684509 and perplexity is 59.989406643014696
At time: 192.980464220047 and batch: 300, loss is 4.110591521263123 and perplexity is 60.98277951363402
At time: 193.86897826194763 and batch: 350, loss is 4.120318789482116 and perplexity is 61.57886983175425
At time: 194.75680208206177 and batch: 400, loss is 4.083365716934204 and perplexity is 59.344872136928025
At time: 195.6446943283081 and batch: 450, loss is 4.111297955513001 and perplexity is 61.02587505802726
At time: 196.53359985351562 and batch: 500, loss is 4.131228322982788 and perplexity is 62.25434443205577
At time: 197.42029809951782 and batch: 550, loss is 4.084852170944214 and perplexity is 59.43315115518512
At time: 198.30861449241638 and batch: 600, loss is 4.088176622390747 and perplexity is 59.6310625716864
At time: 199.1971879005432 and batch: 650, loss is 4.138647294044494 and perplexity is 62.71792513142747
At time: 200.0852689743042 and batch: 700, loss is 4.170342421531677 and perplexity is 64.73761586609436
At time: 200.97337365150452 and batch: 750, loss is 4.140307993888855 and perplexity is 62.82216731346192
At time: 201.86177015304565 and batch: 800, loss is 4.105641469955445 and perplexity is 60.681657525667816
At time: 202.78674626350403 and batch: 850, loss is 4.107760496139527 and perplexity is 60.81037988171314
At time: 203.67575597763062 and batch: 900, loss is 4.091709151268005 and perplexity is 59.84208352156211
At time: 204.56416201591492 and batch: 950, loss is 4.180854020118713 and perplexity is 65.42170081182321
At time: 205.45286083221436 and batch: 1000, loss is 4.154041295051575 and perplexity is 63.69087451226785
At time: 206.33888840675354 and batch: 1050, loss is 4.098837943077087 and perplexity is 60.27020947369926
At time: 207.22512459754944 and batch: 1100, loss is 4.13944324016571 and perplexity is 62.767865092789286
At time: 208.11112594604492 and batch: 1150, loss is 4.105012307167053 and perplexity is 60.64349089258639
At time: 208.99783897399902 and batch: 1200, loss is 4.170131206512451 and perplexity is 64.72394375324319
At time: 209.88393783569336 and batch: 1250, loss is 4.157974486351013 and perplexity is 63.94187620099946
At time: 210.77028703689575 and batch: 1300, loss is 4.169948797225953 and perplexity is 64.712138581563
At time: 211.6565043926239 and batch: 1350, loss is 4.043286361694336 and perplexity is 57.01340192530124
At time: 212.54591870307922 and batch: 1400, loss is 4.074598698616028 and perplexity is 58.826868547129166
At time: 213.43466591835022 and batch: 1450, loss is 4.009595532417297 and perplexity is 55.12456995227454
At time: 214.32439064979553 and batch: 1500, loss is 4.021947755813598 and perplexity is 55.809703706236334
At time: 215.21418738365173 and batch: 1550, loss is 4.0208691167831425 and perplexity is 55.7495376361098
At time: 216.1036913394928 and batch: 1600, loss is 4.113581638336182 and perplexity is 61.165398053163834
At time: 216.9931993484497 and batch: 1650, loss is 4.064319634437561 and perplexity is 58.225280567571176
At time: 217.88317584991455 and batch: 1700, loss is 4.094949312210083 and perplexity is 60.036295973167434
At time: 218.77211499214172 and batch: 1750, loss is 4.0977832794189455 and perplexity is 60.206678182059896
At time: 219.66202473640442 and batch: 1800, loss is 4.058055629730225 and perplexity is 57.86169706923172
At time: 220.5511770248413 and batch: 1850, loss is 4.085421309471131 and perplexity is 59.46698647886341
At time: 221.4439115524292 and batch: 1900, loss is 4.167408747673035 and perplexity is 64.54797512281371
At time: 222.33374428749084 and batch: 1950, loss is 4.100585331916809 and perplexity is 60.375617032276395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367677200672238 and perplexity of 78.86024227585881
finished 6 epochs...
Completing Train Step...
At time: 225.28755688667297 and batch: 50, loss is 4.068401021957397 and perplexity is 58.463406111778376
At time: 226.17642188072205 and batch: 100, loss is 4.041170363426208 and perplexity is 56.892889212878416
At time: 227.0651500225067 and batch: 150, loss is 4.018486623764038 and perplexity is 55.61687285108901
At time: 227.95519185066223 and batch: 200, loss is 4.022528781890869 and perplexity is 55.84214002171445
At time: 228.84003853797913 and batch: 250, loss is 4.0124994659423825 and perplexity is 55.28488069222488
At time: 229.72351241111755 and batch: 300, loss is 4.028022055625915 and perplexity is 56.149740275488845
At time: 230.60859942436218 and batch: 350, loss is 4.037977633476257 and perplexity is 56.711535242728196
At time: 231.50093269348145 and batch: 400, loss is 4.000381321907043 and perplexity is 54.61897347380064
At time: 232.38676929473877 and batch: 450, loss is 4.03277747631073 and perplexity is 56.41739180526267
At time: 233.27255606651306 and batch: 500, loss is 4.055690722465515 and perplexity is 57.72502119806449
At time: 234.15881514549255 and batch: 550, loss is 4.008435740470886 and perplexity is 55.060673980173746
At time: 235.04428625106812 and batch: 600, loss is 4.013227653503418 and perplexity is 55.32515311581769
At time: 235.93014073371887 and batch: 650, loss is 4.06017117023468 and perplexity is 57.98423540474245
At time: 236.83363580703735 and batch: 700, loss is 4.094053058624268 and perplexity is 59.98251233311277
At time: 237.71887063980103 and batch: 750, loss is 4.063547058105469 and perplexity is 58.18031446598472
At time: 238.60381937026978 and batch: 800, loss is 4.032407522201538 and perplexity is 56.39652381967095
At time: 239.48978781700134 and batch: 850, loss is 4.035222969055176 and perplexity is 56.555528965451145
At time: 240.37523865699768 and batch: 900, loss is 4.0144310426712035 and perplexity is 55.39177088129266
At time: 241.26011657714844 and batch: 950, loss is 4.109761095046997 and perplexity is 60.93215883607156
At time: 242.14544248580933 and batch: 1000, loss is 4.0821603631973264 and perplexity is 59.273383666635986
At time: 243.03043866157532 and batch: 1050, loss is 4.027541599273682 and perplexity is 56.1227692558149
At time: 243.91485214233398 and batch: 1100, loss is 4.062770524024963 and perplexity is 58.135153005963176
At time: 244.80233097076416 and batch: 1150, loss is 4.034757471084594 and perplexity is 56.52920860800434
At time: 245.68734788894653 and batch: 1200, loss is 4.10027578830719 and perplexity is 60.35693103806149
At time: 246.57908129692078 and batch: 1250, loss is 4.083620510101318 and perplexity is 59.359994731336826
At time: 247.46850752830505 and batch: 1300, loss is 4.100251655578614 and perplexity is 60.355474478202495
At time: 248.35461950302124 and batch: 1350, loss is 3.9774889278411867 and perplexity is 53.382817677066775
At time: 249.24008202552795 and batch: 1400, loss is 4.004583406448364 and perplexity is 54.848969911705495
At time: 250.12588787078857 and batch: 1450, loss is 3.9393365573883057 and perplexity is 51.3844993229938
At time: 251.01163911819458 and batch: 1500, loss is 3.953606996536255 and perplexity is 52.123035780260864
At time: 251.8971288204193 and batch: 1550, loss is 3.949838762283325 and perplexity is 51.92699356992951
At time: 252.78269267082214 and batch: 1600, loss is 4.046482934951782 and perplexity is 57.19594103559763
At time: 253.66876459121704 and batch: 1650, loss is 3.9946079635620118 and perplexity is 54.304547088957506
At time: 254.55444169044495 and batch: 1700, loss is 4.027141137123108 and perplexity is 56.10029871054431
At time: 255.44019222259521 and batch: 1750, loss is 4.028751692771912 and perplexity is 56.190724161596506
At time: 256.3260645866394 and batch: 1800, loss is 3.989253463745117 and perplexity is 54.01455048775319
At time: 257.2119052410126 and batch: 1850, loss is 4.018494024276733 and perplexity is 55.61728444598562
At time: 258.0985586643219 and batch: 1900, loss is 4.096987476348877 and perplexity is 60.158784582188495
At time: 258.9835526943207 and batch: 1950, loss is 4.0303663682937625 and perplexity is 56.281527237478976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363152934229651 and perplexity of 78.50426340691173
finished 7 epochs...
Completing Train Step...
At time: 261.9411630630493 and batch: 50, loss is 4.0052210807800295 and perplexity is 54.883956845885855
At time: 262.82660937309265 and batch: 100, loss is 3.9746772718429564 and perplexity is 53.23293436643802
At time: 263.72304487228394 and batch: 150, loss is 3.952807984352112 and perplexity is 52.08140547337392
At time: 264.61662006378174 and batch: 200, loss is 3.955997848510742 and perplexity is 52.24780333421599
At time: 265.50260949134827 and batch: 250, loss is 3.945466251373291 and perplexity is 51.70043789355998
At time: 266.3884496688843 and batch: 300, loss is 3.9594156837463377 and perplexity is 52.42668323431333
At time: 267.2750689983368 and batch: 350, loss is 3.9708909082412718 and perplexity is 53.031756228481555
At time: 268.1765115261078 and batch: 400, loss is 3.9341216135025023 and perplexity is 51.11722954658157
At time: 269.08569383621216 and batch: 450, loss is 3.9691486454010008 and perplexity is 52.93944141193924
At time: 269.972624540329 and batch: 500, loss is 3.993622555732727 and perplexity is 54.25106132006602
At time: 270.8587303161621 and batch: 550, loss is 3.9466389322280886 and perplexity is 51.76110156987634
At time: 271.77371525764465 and batch: 600, loss is 3.953265361785889 and perplexity is 52.105231781349275
At time: 272.6801116466522 and batch: 650, loss is 3.9987526512145997 and perplexity is 54.530089553418144
At time: 273.5687165260315 and batch: 700, loss is 4.0318732213974 and perplexity is 56.36639916017507
At time: 274.45661997795105 and batch: 750, loss is 4.002572875022889 and perplexity is 54.738805116044226
At time: 275.34513783454895 and batch: 800, loss is 3.9708407402038572 and perplexity is 53.02909579608582
At time: 276.24408650398254 and batch: 850, loss is 3.974280209541321 and perplexity is 53.21180177075187
At time: 277.1425051689148 and batch: 900, loss is 3.9566467237472533 and perplexity is 52.28171664152442
At time: 278.06498885154724 and batch: 950, loss is 4.051387324333191 and perplexity is 57.47714119536822
At time: 278.9780683517456 and batch: 1000, loss is 4.024025406837463 and perplexity is 55.92577733277376
At time: 279.86664628982544 and batch: 1050, loss is 3.9679067611694334 and perplexity is 52.87373756115435
At time: 280.7548727989197 and batch: 1100, loss is 4.0029361009597775 and perplexity is 54.75869128118352
At time: 281.6441125869751 and batch: 1150, loss is 3.972123370170593 and perplexity is 53.097156142251826
At time: 282.53190207481384 and batch: 1200, loss is 4.043776602745056 and perplexity is 57.04135908768062
At time: 283.42088985443115 and batch: 1250, loss is 4.027863435745239 and perplexity is 56.140834516720204
At time: 284.3070273399353 and batch: 1300, loss is 4.0413322305679324 and perplexity is 56.90209904760443
At time: 285.1948072910309 and batch: 1350, loss is 3.917773361206055 and perplexity is 50.28834604050417
At time: 286.0838463306427 and batch: 1400, loss is 3.950321927070618 and perplexity is 51.95208892684066
At time: 286.97260332107544 and batch: 1450, loss is 3.8795371866226196 and perplexity is 48.401808882163
At time: 287.8612039089203 and batch: 1500, loss is 3.897200288772583 and perplexity is 49.264329951200295
At time: 288.74959206581116 and batch: 1550, loss is 3.892198042869568 and perplexity is 49.01851298956038
At time: 289.6384699344635 and batch: 1600, loss is 3.9905244588851927 and perplexity is 54.08324636573224
At time: 290.52733850479126 and batch: 1650, loss is 3.940253190994263 and perplexity is 51.4316216755651
At time: 291.4142677783966 and batch: 1700, loss is 3.9748379373550415 and perplexity is 53.2414877501963
At time: 292.32291889190674 and batch: 1750, loss is 3.9733732557296753 and perplexity is 53.16356300278522
At time: 293.211234331131 and batch: 1800, loss is 3.932962942123413 and perplexity is 51.05803577541423
At time: 294.0992774963379 and batch: 1850, loss is 3.962656979560852 and perplexity is 52.59688931836812
At time: 294.99596524238586 and batch: 1900, loss is 4.039066443443298 and perplexity is 56.77331695571557
At time: 295.9076075553894 and batch: 1950, loss is 3.9730023622512816 and perplexity is 53.143848640169566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371031011537064 and perplexity of 79.12516862130894
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 298.87042927742004 and batch: 50, loss is 3.9841707849502566 and perplexity is 53.74070839260778
At time: 299.7841155529022 and batch: 100, loss is 3.969746174812317 and perplexity is 52.971083737870245
At time: 300.6720838546753 and batch: 150, loss is 3.949045124053955 and perplexity is 51.88579867178143
At time: 301.5598704814911 and batch: 200, loss is 3.9548978185653687 and perplexity is 52.19036078602238
At time: 302.4464428424835 and batch: 250, loss is 3.939334583282471 and perplexity is 51.384397884653985
At time: 303.3334445953369 and batch: 300, loss is 3.946380252838135 and perplexity is 51.74771377134734
At time: 304.21997833251953 and batch: 350, loss is 3.9573910522460936 and perplexity is 52.32064589946974
At time: 305.11635875701904 and batch: 400, loss is 3.918876051902771 and perplexity is 50.343829116550225
At time: 306.00343585014343 and batch: 450, loss is 3.9414079284667967 and perplexity is 51.49104599953076
At time: 306.9148826599121 and batch: 500, loss is 3.9632608699798584 and perplexity is 52.62866166844036
At time: 307.80343985557556 and batch: 550, loss is 3.9133873653411864 and perplexity is 50.06826455377293
At time: 308.6900591850281 and batch: 600, loss is 3.9017136096954346 and perplexity is 49.487178196858196
At time: 309.5769352912903 and batch: 650, loss is 3.939194221496582 and perplexity is 51.37718598494948
At time: 310.4641044139862 and batch: 700, loss is 3.966292352676392 and perplexity is 52.78844661591454
At time: 311.35025000572205 and batch: 750, loss is 3.924563055038452 and perplexity is 50.63095028625535
At time: 312.23710536956787 and batch: 800, loss is 3.8933905076980593 and perplexity is 49.07700070758804
At time: 313.1237304210663 and batch: 850, loss is 3.8966640424728394 and perplexity is 49.237919218516346
At time: 314.0522267818451 and batch: 900, loss is 3.8670191192626953 and perplexity is 47.79968833379669
At time: 314.93779397010803 and batch: 950, loss is 3.9631684541702272 and perplexity is 52.62379817279787
At time: 315.82424902915955 and batch: 1000, loss is 3.9270109796524046 and perplexity is 50.755042858352695
At time: 316.7104630470276 and batch: 1050, loss is 3.865973038673401 and perplexity is 47.7497121517707
At time: 317.5968005657196 and batch: 1100, loss is 3.888701090812683 and perplexity is 48.8473969663775
At time: 318.482470035553 and batch: 1150, loss is 3.85959032535553 and perplexity is 47.44591000049659
At time: 319.36912178993225 and batch: 1200, loss is 3.9202915477752684 and perplexity is 50.41514105784281
At time: 320.2555320262909 and batch: 1250, loss is 3.8962532091140747 and perplexity is 49.21769479350391
At time: 321.1425905227661 and batch: 1300, loss is 3.9018043851852418 and perplexity is 49.49167062359623
At time: 322.0292730331421 and batch: 1350, loss is 3.780007338523865 and perplexity is 43.816363281821744
At time: 322.9156823158264 and batch: 1400, loss is 3.801802625656128 and perplexity is 44.781836666326264
At time: 323.80183959007263 and batch: 1450, loss is 3.7150391864776613 and perplexity is 41.06019605732311
At time: 324.68601083755493 and batch: 1500, loss is 3.735419735908508 and perplexity is 41.90561116196354
At time: 325.5693266391754 and batch: 1550, loss is 3.7256187534332277 and perplexity is 41.49690115286066
At time: 326.45413422584534 and batch: 1600, loss is 3.8134801959991456 and perplexity is 45.307844986223195
At time: 327.339777469635 and batch: 1650, loss is 3.758671369552612 and perplexity is 42.891401283102326
At time: 328.2265872955322 and batch: 1700, loss is 3.781690754890442 and perplexity is 43.89018658513884
At time: 329.13376450538635 and batch: 1750, loss is 3.769377198219299 and perplexity is 43.353056065653035
At time: 330.02259063720703 and batch: 1800, loss is 3.721149730682373 and perplexity is 41.3118643323642
At time: 330.91029047966003 and batch: 1850, loss is 3.745545768737793 and perplexity is 42.33210445460619
At time: 331.8074963092804 and batch: 1900, loss is 3.815373682975769 and perplexity is 45.39371607287953
At time: 332.717520236969 and batch: 1950, loss is 3.7472513246536256 and perplexity is 42.40436583118066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298063340297965 and perplexity of 73.5572004010052
finished 9 epochs...
Completing Train Step...
At time: 335.64505553245544 and batch: 50, loss is 3.8984811115264892 and perplexity is 49.327469252452886
At time: 336.5550768375397 and batch: 100, loss is 3.8732625818252564 and perplexity is 48.09905747595586
At time: 337.4413423538208 and batch: 150, loss is 3.8507686948776243 and perplexity is 47.02920044603566
At time: 338.3279130458832 and batch: 200, loss is 3.8544910049438474 and perplexity is 47.20458392560464
At time: 339.21433758735657 and batch: 250, loss is 3.8378007650375365 and perplexity is 46.423266420675795
At time: 340.1044833660126 and batch: 300, loss is 3.8483699655532835 and perplexity is 46.91652531642102
At time: 340.99102663993835 and batch: 350, loss is 3.858459959030151 and perplexity is 47.39230904162182
At time: 341.8804907798767 and batch: 400, loss is 3.822479934692383 and perplexity is 45.717444129853796
At time: 342.7670478820801 and batch: 450, loss is 3.854029726982117 and perplexity is 47.182814512608324
At time: 343.65351605415344 and batch: 500, loss is 3.8807153940200805 and perplexity is 48.45886985967048
At time: 344.5404806137085 and batch: 550, loss is 3.831651268005371 and perplexity is 46.13866266346676
At time: 345.426780462265 and batch: 600, loss is 3.8244280099868773 and perplexity is 45.806591958438815
At time: 346.3137743473053 and batch: 650, loss is 3.862017889022827 and perplexity is 47.56122788189387
At time: 347.20083594322205 and batch: 700, loss is 3.892721471786499 and perplexity is 49.04417741288877
At time: 348.08990383148193 and batch: 750, loss is 3.855345163345337 and perplexity is 47.244921342372756
At time: 348.9968705177307 and batch: 800, loss is 3.8241902112960817 and perplexity is 45.795700505879196
At time: 349.8828320503235 and batch: 850, loss is 3.8308380317687987 and perplexity is 46.101156283922386
At time: 350.7685706615448 and batch: 900, loss is 3.801070518493652 and perplexity is 44.749063561130356
At time: 351.65435123443604 and batch: 950, loss is 3.9007425260543824 and perplexity is 49.43914533340796
At time: 352.54028606414795 and batch: 1000, loss is 3.8654570722579957 and perplexity is 47.72508125885833
At time: 353.42625880241394 and batch: 1050, loss is 3.810830845832825 and perplexity is 45.18796750840011
At time: 354.31232500076294 and batch: 1100, loss is 3.834059085845947 and perplexity is 46.24989001242825
At time: 355.19787192344666 and batch: 1150, loss is 3.8079731702804565 and perplexity is 45.05901929222515
At time: 356.08379673957825 and batch: 1200, loss is 3.869741244316101 and perplexity is 47.92998232076207
At time: 356.97090435028076 and batch: 1250, loss is 3.850031142234802 and perplexity is 46.994526723376595
At time: 357.8571763038635 and batch: 1300, loss is 3.8579378843307497 and perplexity is 47.36757317367223
At time: 358.74359107017517 and batch: 1350, loss is 3.736994981765747 and perplexity is 41.971674821933966
At time: 359.6300663948059 and batch: 1400, loss is 3.765052151679993 and perplexity is 43.16595697833462
At time: 360.51652932167053 and batch: 1450, loss is 3.6804270935058594 and perplexity is 39.6633304064534
At time: 361.4016287326813 and batch: 1500, loss is 3.7019373846054076 and perplexity is 40.52574230256149
At time: 362.2878243923187 and batch: 1550, loss is 3.696814413070679 and perplexity is 40.31866096711627
At time: 363.17356157302856 and batch: 1600, loss is 3.78665714263916 and perplexity is 44.10870444314547
At time: 364.05984473228455 and batch: 1650, loss is 3.7346646642684935 and perplexity is 41.873981366301265
At time: 364.94686222076416 and batch: 1700, loss is 3.762264313697815 and perplexity is 43.045784871946516
At time: 365.8325457572937 and batch: 1750, loss is 3.754002585411072 and perplexity is 42.69161732596859
At time: 366.7175817489624 and batch: 1800, loss is 3.7086232328414916 and perplexity is 40.79759904904708
At time: 367.60550332069397 and batch: 1850, loss is 3.7370777797698973 and perplexity is 41.97515013671264
At time: 368.49156665802 and batch: 1900, loss is 3.8107725477218626 and perplexity is 45.185333212044135
At time: 369.3777959346771 and batch: 1950, loss is 3.7440307664871217 and perplexity is 42.26801977755423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.297896984011628 and perplexity of 73.54496471608294
finished 10 epochs...
Completing Train Step...
At time: 372.32085061073303 and batch: 50, loss is 3.856645302772522 and perplexity is 47.306386275177324
At time: 373.2305603027344 and batch: 100, loss is 3.829559817314148 and perplexity is 46.042266764319734
At time: 374.11575984954834 and batch: 150, loss is 3.8073921155929566 and perplexity is 45.032845142893756
At time: 375.00839018821716 and batch: 200, loss is 3.8106832933425903 and perplexity is 45.18130040315169
At time: 375.9050238132477 and batch: 250, loss is 3.793187475204468 and perplexity is 44.39769151603767
At time: 376.79097056388855 and batch: 300, loss is 3.8044360446929932 and perplexity is 44.899921422589586
At time: 377.6770522594452 and batch: 350, loss is 3.81471736907959 and perplexity is 45.363933320707815
At time: 378.5631546974182 and batch: 400, loss is 3.779674596786499 and perplexity is 43.80178617431883
At time: 379.44906759262085 and batch: 450, loss is 3.813504514694214 and perplexity is 45.30894682728724
At time: 380.3578722476959 and batch: 500, loss is 3.842294988632202 and perplexity is 46.632372492725395
At time: 381.2694535255432 and batch: 550, loss is 3.792815618515015 and perplexity is 44.38118500666933
At time: 382.1556236743927 and batch: 600, loss is 3.787047543525696 and perplexity is 44.125927882268215
At time: 383.0409870147705 and batch: 650, loss is 3.8259590816497804 and perplexity is 45.87677885023022
At time: 383.92619585990906 and batch: 700, loss is 3.855744276046753 and perplexity is 47.26378115390271
At time: 384.8118133544922 and batch: 750, loss is 3.819309124946594 and perplexity is 45.57271239211803
At time: 385.697628736496 and batch: 800, loss is 3.7887700510025026 and perplexity is 44.20200062208883
At time: 386.60567927360535 and batch: 850, loss is 3.797163138389587 and perplexity is 44.57455312183514
At time: 387.491690158844 and batch: 900, loss is 3.76741069316864 and perplexity is 43.26788583323165
At time: 388.37858057022095 and batch: 950, loss is 3.8681418800354006 and perplexity is 47.853386088030526
At time: 389.2646312713623 and batch: 1000, loss is 3.833026285171509 and perplexity is 46.202147753193294
At time: 390.1626615524292 and batch: 1050, loss is 3.7803921842575074 and perplexity is 43.833229067449146
At time: 391.0604159832001 and batch: 1100, loss is 3.803741660118103 and perplexity is 44.868754431931045
At time: 391.9731628894806 and batch: 1150, loss is 3.7784662294387816 and perplexity is 43.748889491882444
At time: 392.88527488708496 and batch: 1200, loss is 3.840714702606201 and perplexity is 46.558738203059285
At time: 393.7715382575989 and batch: 1250, loss is 3.823348813056946 and perplexity is 45.75718429012392
At time: 394.65690207481384 and batch: 1300, loss is 3.8327391958236694 and perplexity is 46.18888551254114
At time: 395.54264211654663 and batch: 1350, loss is 3.711753749847412 and perplexity is 40.92551674646685
At time: 396.4507849216461 and batch: 1400, loss is 3.7427165937423705 and perplexity is 42.21250878149618
At time: 397.3383319377899 and batch: 1450, loss is 3.6579114818572998 and perplexity is 38.780264947524614
At time: 398.2239830493927 and batch: 1500, loss is 3.6799988317489625 and perplexity is 39.64634775565864
At time: 399.11008644104004 and batch: 1550, loss is 3.6762926530838014 and perplexity is 39.4996832577506
At time: 399.9963436126709 and batch: 1600, loss is 3.766835513114929 and perplexity is 43.24300616416474
At time: 400.8821909427643 and batch: 1650, loss is 3.7161417818069458 and perplexity is 41.1054938056692
At time: 401.76943492889404 and batch: 1700, loss is 3.745604658126831 and perplexity is 42.33459743977868
At time: 402.65589690208435 and batch: 1750, loss is 3.73875461101532 and perplexity is 42.04559442507903
At time: 403.55093216896057 and batch: 1800, loss is 3.694016251564026 and perplexity is 40.206000536546554
At time: 404.45188093185425 and batch: 1850, loss is 3.7242123556137083 and perplexity is 41.43858102182791
At time: 405.36179208755493 and batch: 1900, loss is 3.7996977615356444 and perplexity is 44.68767611742291
At time: 406.26947951316833 and batch: 1950, loss is 3.7325878667831422 and perplexity is 41.78710782769578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.301153138626454 and perplexity of 73.78482879767776
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 409.21333384513855 and batch: 50, loss is 3.84760160446167 and perplexity is 46.88049032952798
At time: 410.10874819755554 and batch: 100, loss is 3.845524296760559 and perplexity is 46.78320620544809
At time: 410.9972634315491 and batch: 150, loss is 3.834821262359619 and perplexity is 46.28515402935127
At time: 411.8911221027374 and batch: 200, loss is 3.839450645446777 and perplexity is 46.499922477750815
At time: 412.79134702682495 and batch: 250, loss is 3.8245290517807007 and perplexity is 45.81122057249703
At time: 413.6880626678467 and batch: 300, loss is 3.828938488960266 and perplexity is 46.01366828394546
At time: 414.60785698890686 and batch: 350, loss is 3.8418630743026734 and perplexity is 46.61223565183397
At time: 415.51655530929565 and batch: 400, loss is 3.815244607925415 and perplexity is 45.387857254813426
At time: 416.40994787216187 and batch: 450, loss is 3.847031216621399 and perplexity is 46.85375789255133
At time: 417.29547095298767 and batch: 500, loss is 3.8700004529953005 and perplexity is 47.94240779849976
At time: 418.18165254592896 and batch: 550, loss is 3.81921790599823 and perplexity is 45.56855548681666
At time: 419.06768250465393 and batch: 600, loss is 3.8043213987350466 and perplexity is 44.89477412315054
At time: 419.96503806114197 and batch: 650, loss is 3.837994112968445 and perplexity is 46.432243130970456
At time: 420.8592014312744 and batch: 700, loss is 3.860582880973816 and perplexity is 47.49302608383079
At time: 421.7443337440491 and batch: 750, loss is 3.822179527282715 and perplexity is 45.70371233355605
At time: 422.6453356742859 and batch: 800, loss is 3.7886663913726806 and perplexity is 44.197418896541045
At time: 423.5381860733032 and batch: 850, loss is 3.7994669389724733 and perplexity is 44.67736238384633
At time: 424.42415022850037 and batch: 900, loss is 3.7640976524353027 and perplexity is 43.12477476232616
At time: 425.3358619213104 and batch: 950, loss is 3.8696986484527587 and perplexity is 47.92794074526678
At time: 426.24121046066284 and batch: 1000, loss is 3.828385453224182 and perplexity is 45.98822811634544
At time: 427.13783740997314 and batch: 1050, loss is 3.772239632606506 and perplexity is 43.477329121006484
At time: 428.0237023830414 and batch: 1100, loss is 3.790747618675232 and perplexity is 44.28949955860746
At time: 428.91000604629517 and batch: 1150, loss is 3.7668974351882936 and perplexity is 43.24568394367091
At time: 429.7966613769531 and batch: 1200, loss is 3.819698839187622 and perplexity is 45.590476188316856
At time: 430.6830666065216 and batch: 1250, loss is 3.80330913066864 and perplexity is 44.84935157073544
At time: 431.5692458152771 and batch: 1300, loss is 3.8090383863449095 and perplexity is 45.10704245640577
At time: 432.45533776283264 and batch: 1350, loss is 3.690588312149048 and perplexity is 40.06841275860236
At time: 433.34198808670044 and batch: 1400, loss is 3.713057584762573 and perplexity is 40.97891166563764
At time: 434.2279603481293 and batch: 1450, loss is 3.6212598752975462 and perplexity is 37.384638146566495
At time: 435.11373591423035 and batch: 1500, loss is 3.6436038064956664 and perplexity is 38.2293599887975
At time: 435.99962854385376 and batch: 1550, loss is 3.642820839881897 and perplexity is 38.19943939120351
At time: 436.88628911972046 and batch: 1600, loss is 3.7244735956192017 and perplexity is 41.449407851100574
At time: 437.7720012664795 and batch: 1650, loss is 3.6707924795150757 and perplexity is 39.283024520448215
At time: 438.65760374069214 and batch: 1700, loss is 3.6967050361633302 and perplexity is 40.31425127783474
At time: 439.5434229373932 and batch: 1750, loss is 3.687736496925354 and perplexity is 39.954307829528226
At time: 440.430611371994 and batch: 1800, loss is 3.6370080041885378 and perplexity is 37.97803643935069
At time: 441.33746695518494 and batch: 1850, loss is 3.665591583251953 and perplexity is 39.079247954739834
At time: 442.2240629196167 and batch: 1900, loss is 3.741762571334839 and perplexity is 42.172256306175235
At time: 443.109472990036 and batch: 1950, loss is 3.6783299446105957 and perplexity is 39.58023765629734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2740234375 and perplexity of 71.8099781250813
finished 12 epochs...
Completing Train Step...
At time: 446.06437826156616 and batch: 50, loss is 3.8386399602890013 and perplexity is 46.462240956749
At time: 446.95057487487793 and batch: 100, loss is 3.8208786392211915 and perplexity is 45.644295575468945
At time: 447.8608331680298 and batch: 150, loss is 3.802811403274536 and perplexity is 44.827034374251646
At time: 448.74640822410583 and batch: 200, loss is 3.8009951400756834 and perplexity is 44.74569057464032
At time: 449.6427698135376 and batch: 250, loss is 3.786232423782349 and perplexity is 44.08997462235454
At time: 450.5370695590973 and batch: 300, loss is 3.7890229749679567 and perplexity is 44.213181781299134
At time: 451.4239614009857 and batch: 350, loss is 3.801827893257141 and perplexity is 44.78296821020341
At time: 452.3299901485443 and batch: 400, loss is 3.773607439994812 and perplexity is 43.536838422355046
At time: 453.22697162628174 and batch: 450, loss is 3.809556484222412 and perplexity is 45.130418374346704
At time: 454.12744545936584 and batch: 500, loss is 3.833155703544617 and perplexity is 46.20812754692884
At time: 455.01383805274963 and batch: 550, loss is 3.782849349975586 and perplexity is 43.94106700881526
At time: 455.8994243144989 and batch: 600, loss is 3.7720436477661132 and perplexity is 43.46880905852681
At time: 456.78586649894714 and batch: 650, loss is 3.806002821922302 and perplexity is 44.970324735824164
At time: 457.6727387905121 and batch: 700, loss is 3.8322097969055178 and perplexity is 46.164439637900905
At time: 458.5589485168457 and batch: 750, loss is 3.7952248859405517 and perplexity is 44.48824006035538
At time: 459.44502782821655 and batch: 800, loss is 3.762364330291748 and perplexity is 43.050090380040125
At time: 460.3315796852112 and batch: 850, loss is 3.7748863077163697 and perplexity is 43.5925518972011
At time: 461.2236089706421 and batch: 900, loss is 3.741065721511841 and perplexity is 42.1428788138718
At time: 462.11056208610535 and batch: 950, loss is 3.8469557332992554 and perplexity is 46.85022134872741
At time: 462.99703192710876 and batch: 1000, loss is 3.8065963220596313 and perplexity is 44.99702255152558
At time: 463.89138102531433 and batch: 1050, loss is 3.7524847555160523 and perplexity is 42.626867864689366
At time: 464.79249811172485 and batch: 1100, loss is 3.7719980907440185 and perplexity is 43.466828794139914
At time: 465.67929911613464 and batch: 1150, loss is 3.7495897102355955 and perplexity is 42.503639613807714
At time: 466.56532764434814 and batch: 1200, loss is 3.8039204978942873 and perplexity is 44.87677937775416
At time: 467.45163917541504 and batch: 1250, loss is 3.7890079021453857 and perplexity is 44.21251536887722
At time: 468.3357594013214 and batch: 1300, loss is 3.7963894176483155 and perplexity is 44.5400782042511
At time: 469.2223460674286 and batch: 1350, loss is 3.678472709655762 and perplexity is 39.58588873409262
At time: 470.1322922706604 and batch: 1400, loss is 3.70410210609436 and perplexity is 40.61356426853345
At time: 471.04426097869873 and batch: 1450, loss is 3.613987617492676 and perplexity is 37.11375358503263
At time: 471.9356195926666 and batch: 1500, loss is 3.6377818059921263 and perplexity is 38.00743528541734
At time: 472.8222978115082 and batch: 1550, loss is 3.639015040397644 and perplexity is 38.05433627629042
At time: 473.70929312705994 and batch: 1600, loss is 3.7219907808303834 and perplexity is 41.34662429736338
At time: 474.5969183444977 and batch: 1650, loss is 3.6693904209136963 and perplexity is 39.227986010655236
At time: 475.48372530937195 and batch: 1700, loss is 3.6973502969741823 and perplexity is 40.34027287875996
At time: 476.3702826499939 and batch: 1750, loss is 3.690148911476135 and perplexity is 40.050810538570566
At time: 477.25712275505066 and batch: 1800, loss is 3.6409487247467043 and perplexity is 38.127992541794775
At time: 478.1443021297455 and batch: 1850, loss is 3.67028995513916 and perplexity is 39.263288802322045
At time: 479.03162932395935 and batch: 1900, loss is 3.7479295778274535 and perplexity is 42.43313648267972
At time: 479.9178259372711 and batch: 1950, loss is 3.684071464538574 and perplexity is 39.80814201218271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273021325399709 and perplexity of 71.7380525218583
finished 13 epochs...
Completing Train Step...
At time: 482.9050748348236 and batch: 50, loss is 3.825564341545105 and perplexity is 45.85867301952857
At time: 483.79257559776306 and batch: 100, loss is 3.806324253082275 and perplexity is 44.98478192283908
At time: 484.6785283088684 and batch: 150, loss is 3.7873809862136842 and perplexity is 44.14064380359309
At time: 485.56317138671875 and batch: 200, loss is 3.7841203212738037 and perplexity is 43.99695034933477
At time: 486.4560010433197 and batch: 250, loss is 3.7692634725570677 and perplexity is 43.34812599098553
At time: 487.3591721057892 and batch: 300, loss is 3.7717218923568727 and perplexity is 43.45482498392545
At time: 488.2626233100891 and batch: 350, loss is 3.784587745666504 and perplexity is 44.01752040423065
At time: 489.1551887989044 and batch: 400, loss is 3.756263575553894 and perplexity is 42.788251855616316
At time: 490.039813041687 and batch: 450, loss is 3.7932255840301514 and perplexity is 44.399383492163814
At time: 490.9500267505646 and batch: 500, loss is 3.816483554840088 and perplexity is 45.44412524985474
At time: 491.849858045578 and batch: 550, loss is 3.7666583824157716 and perplexity is 43.23534717858997
At time: 492.81264877319336 and batch: 600, loss is 3.7574819898605347 and perplexity is 42.84041744703133
At time: 493.6975462436676 and batch: 650, loss is 3.7913052940368654 and perplexity is 44.31420560962803
At time: 494.5837869644165 and batch: 700, loss is 3.8183603143692015 and perplexity is 45.52949302729749
At time: 495.4705731868744 and batch: 750, loss is 3.781934313774109 and perplexity is 43.90087773189649
At time: 496.35661816596985 and batch: 800, loss is 3.74934853553772 and perplexity is 42.49339004738296
At time: 497.24264764785767 and batch: 850, loss is 3.7624990940093994 and perplexity is 43.055892361204464
At time: 498.1286098957062 and batch: 900, loss is 3.7292507171630858 and perplexity is 41.64789042054433
At time: 499.01526737213135 and batch: 950, loss is 3.835280694961548 and perplexity is 46.306423823742
At time: 499.9099078178406 and batch: 1000, loss is 3.7952377939224244 and perplexity is 44.48881431745787
At time: 500.796035528183 and batch: 1050, loss is 3.742076902389526 and perplexity is 42.185514439590854
At time: 501.7020206451416 and batch: 1100, loss is 3.7619482421875 and perplexity is 43.032181475645615
At time: 502.59313321113586 and batch: 1150, loss is 3.740070776939392 and perplexity is 42.10096983734014
At time: 503.48148584365845 and batch: 1200, loss is 3.7947710180282592 and perplexity is 44.46805285722603
At time: 504.383309841156 and batch: 1250, loss is 3.78053750038147 and perplexity is 43.839599205228645
At time: 505.26913022994995 and batch: 1300, loss is 3.7885912752151487 and perplexity is 44.19409908094816
At time: 506.15587091445923 and batch: 1350, loss is 3.6707942152023314 and perplexity is 39.28309270355241
At time: 507.042115688324 and batch: 1400, loss is 3.6976672887802122 and perplexity is 40.353062441701766
At time: 507.9279453754425 and batch: 1450, loss is 3.608271765708923 and perplexity is 36.90222198794155
At time: 508.8274278640747 and batch: 1500, loss is 3.6325256872177123 and perplexity is 37.808187784225986
At time: 509.71361327171326 and batch: 1550, loss is 3.6345455694198607 and perplexity is 37.884633049050855
At time: 510.5996026992798 and batch: 1600, loss is 3.7177631711959838 and perplexity is 41.17219587755989
At time: 511.4857075214386 and batch: 1650, loss is 3.665932717323303 and perplexity is 39.092581491832526
At time: 512.3947849273682 and batch: 1700, loss is 3.694698619842529 and perplexity is 40.233445198536636
At time: 513.2813193798065 and batch: 1750, loss is 3.6881798267364503 and perplexity is 39.97202469218729
At time: 514.1785531044006 and batch: 1800, loss is 3.639698886871338 and perplexity is 38.08036849996941
At time: 515.0952248573303 and batch: 1850, loss is 3.669534320831299 and perplexity is 39.23363132077998
At time: 515.9804906845093 and batch: 1900, loss is 3.7479635000228884 and perplexity is 42.43457593224291
At time: 516.8757321834564 and batch: 1950, loss is 3.683156156539917 and perplexity is 39.771721971707144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273664039789244 and perplexity of 71.78417442050761
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 519.8543126583099 and batch: 50, loss is 3.8236720180511474 and perplexity is 45.771975630795914
At time: 520.7816870212555 and batch: 100, loss is 3.8182606935501098 and perplexity is 45.52495756782612
At time: 521.6734101772308 and batch: 150, loss is 3.807833113670349 and perplexity is 45.05270892064326
At time: 522.5606694221497 and batch: 200, loss is 3.805373635292053 and perplexity is 44.94203890820785
At time: 523.4708569049835 and batch: 250, loss is 3.7961320877075195 and perplexity is 44.52861818313027
At time: 524.3566935062408 and batch: 300, loss is 3.793733925819397 and perplexity is 44.421959291834675
At time: 525.2663178443909 and batch: 350, loss is 3.8065924072265624 and perplexity is 44.99684639603851
At time: 526.1524922847748 and batch: 400, loss is 3.784407205581665 and perplexity is 44.009574194688724
At time: 527.0391049385071 and batch: 450, loss is 3.821939640045166 and perplexity is 45.6927499111838
At time: 527.9421353340149 and batch: 500, loss is 3.8437392330169677 and perplexity is 46.69976969214472
At time: 528.8354389667511 and batch: 550, loss is 3.7927384042739867 and perplexity is 44.37775827945088
At time: 529.7215585708618 and batch: 600, loss is 3.7805825376510622 and perplexity is 43.84157366553869
At time: 530.6061015129089 and batch: 650, loss is 3.8103920316696165 and perplexity is 45.168142738263896
At time: 531.4910364151001 and batch: 700, loss is 3.831483497619629 and perplexity is 46.130922611527986
At time: 532.377247095108 and batch: 750, loss is 3.7965392446517945 and perplexity is 44.54675201064889
At time: 533.2636969089508 and batch: 800, loss is 3.760171899795532 and perplexity is 42.95580943899667
At time: 534.1493647098541 and batch: 850, loss is 3.7734609031677246 and perplexity is 43.53045913960256
At time: 535.0570135116577 and batch: 900, loss is 3.7355167293548583 and perplexity is 41.90967592873623
At time: 535.9426162242889 and batch: 950, loss is 3.845048041343689 and perplexity is 46.76093075489724
At time: 536.8711247444153 and batch: 1000, loss is 3.8041349029541016 and perplexity is 44.886402217876864
At time: 537.7562801837921 and batch: 1050, loss is 3.7518071126937866 and perplexity is 42.597991858559325
At time: 538.6650667190552 and batch: 1100, loss is 3.7667716455459597 and perplexity is 43.24024442667977
At time: 539.5514266490936 and batch: 1150, loss is 3.7446689224243164 and perplexity is 42.29500197383742
At time: 540.4381539821625 and batch: 1200, loss is 3.796233072280884 and perplexity is 44.53311511369648
At time: 541.3469452857971 and batch: 1250, loss is 3.7786498165130613 and perplexity is 43.756921959813326
At time: 542.2336981296539 and batch: 1300, loss is 3.783874707221985 and perplexity is 43.986145407068946
At time: 543.1255490779877 and batch: 1350, loss is 3.6666443157196045 and perplexity is 39.120409610177305
At time: 544.0268969535828 and batch: 1400, loss is 3.692896661758423 and perplexity is 40.16101149755588
At time: 544.9127385616302 and batch: 1450, loss is 3.599701771736145 and perplexity is 36.58732144312317
At time: 545.7989122867584 and batch: 1500, loss is 3.6244437646865846 and perplexity is 37.503856387409286
At time: 546.7027759552002 and batch: 1550, loss is 3.6259753036499025 and perplexity is 37.56133901194489
At time: 547.5924129486084 and batch: 1600, loss is 3.7099639225006102 and perplexity is 40.85233265039727
At time: 548.4784359931946 and batch: 1650, loss is 3.6553161334991455 and perplexity is 38.679747146341995
At time: 549.3771851062775 and batch: 1700, loss is 3.678096227645874 and perplexity is 39.57098816421307
At time: 550.2730634212494 and batch: 1750, loss is 3.6693139600753786 and perplexity is 39.22498672062492
At time: 551.1592376232147 and batch: 1800, loss is 3.62084276676178 and perplexity is 37.36904794651782
At time: 552.044755935669 and batch: 1850, loss is 3.6476061487197877 and perplexity is 38.38267357253914
At time: 552.9312734603882 and batch: 1900, loss is 3.728849992752075 and perplexity is 41.63120443764934
At time: 553.8181138038635 and batch: 1950, loss is 3.66766713142395 and perplexity is 39.160443049412116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.264135458303052 and perplexity of 71.1034215205369
finished 15 epochs...
Completing Train Step...
At time: 556.7425832748413 and batch: 50, loss is 3.8240755462646483 and perplexity is 45.790449641492195
At time: 557.6757276058197 and batch: 100, loss is 3.8080093622207642 and perplexity is 45.06065009507248
At time: 558.5615537166595 and batch: 150, loss is 3.793951301574707 and perplexity is 44.4316165983822
At time: 559.476556301117 and batch: 200, loss is 3.7899348592758177 and perplexity is 44.253517475914556
At time: 560.3934562206268 and batch: 250, loss is 3.777998661994934 and perplexity is 43.72843871688244
At time: 561.2798347473145 and batch: 300, loss is 3.7773763227462767 and perplexity is 43.701233259576405
At time: 562.1788935661316 and batch: 350, loss is 3.788563723564148 and perplexity is 44.192881477327575
At time: 563.0713050365448 and batch: 400, loss is 3.7642640256881714 and perplexity is 43.13195016826386
At time: 563.9691860675812 and batch: 450, loss is 3.803389744758606 and perplexity is 44.85296720613151
At time: 564.8655242919922 and batch: 500, loss is 3.8257227087020875 and perplexity is 45.865936102299365
At time: 565.7516977787018 and batch: 550, loss is 3.7752252864837645 and perplexity is 43.60733135152989
At time: 566.6388690471649 and batch: 600, loss is 3.7649415016174315 and perplexity is 43.161180926734524
At time: 567.5259213447571 and batch: 650, loss is 3.795002369880676 and perplexity is 44.478341813766605
At time: 568.4131507873535 and batch: 700, loss is 3.818392286300659 and perplexity is 45.53094871639832
At time: 569.3016023635864 and batch: 750, loss is 3.783783450126648 and perplexity is 43.982131542353635
At time: 570.1890704631805 and batch: 800, loss is 3.7490404844284058 and perplexity is 42.48030192744878
At time: 571.0992567539215 and batch: 850, loss is 3.762837972640991 and perplexity is 43.07048555561101
At time: 571.9856007099152 and batch: 900, loss is 3.725916314125061 and perplexity is 41.509250836775756
At time: 572.8694117069244 and batch: 950, loss is 3.8358239555358886 and perplexity is 46.33158711263667
At time: 573.7560431957245 and batch: 1000, loss is 3.795114765167236 and perplexity is 44.48334125069179
At time: 574.6439390182495 and batch: 1050, loss is 3.7436220836639404 and perplexity is 42.250749093257646
At time: 575.5304877758026 and batch: 1100, loss is 3.7596704244613646 and perplexity is 42.934273560411086
At time: 576.4167895317078 and batch: 1150, loss is 3.7384263372421263 and perplexity is 42.03179422439685
At time: 577.3030288219452 and batch: 1200, loss is 3.79068922996521 and perplexity is 44.286913627356036
At time: 578.1900155544281 and batch: 1250, loss is 3.7740581130981443 and perplexity is 43.5564637264023
At time: 579.0764434337616 and batch: 1300, loss is 3.7800253105163573 and perplexity is 43.81715075624991
At time: 579.9627764225006 and batch: 1350, loss is 3.663050775527954 and perplexity is 38.9800811349485
At time: 580.8497247695923 and batch: 1400, loss is 3.690513596534729 and perplexity is 40.065419134364944
At time: 581.7411594390869 and batch: 1450, loss is 3.5988606119155886 and perplexity is 36.55655859843176
At time: 582.6285860538483 and batch: 1500, loss is 3.62473840713501 and perplexity is 37.51490824357369
At time: 583.5153291225433 and batch: 1550, loss is 3.627522139549255 and perplexity is 37.61948519926743
At time: 584.4018874168396 and batch: 1600, loss is 3.712178511619568 and perplexity is 40.94290403395257
At time: 585.289030790329 and batch: 1650, loss is 3.6582464742660523 and perplexity is 38.79325821809344
At time: 586.1756129264832 and batch: 1700, loss is 3.681714301109314 and perplexity is 39.71441822018809
At time: 587.0624890327454 and batch: 1750, loss is 3.6738335704803466 and perplexity is 39.40266960498989
At time: 587.9492526054382 and batch: 1800, loss is 3.6256285285949708 and perplexity is 37.548315934715376
At time: 588.8353388309479 and batch: 1850, loss is 3.65259334564209 and perplexity is 38.574573648035944
At time: 589.721185207367 and batch: 1900, loss is 3.734013514518738 and perplexity is 41.846724009087076
At time: 590.6083631515503 and batch: 1950, loss is 3.6719911003112795 and perplexity is 39.330138200654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.262925258902616 and perplexity of 71.01742424986233
finished 16 epochs...
Completing Train Step...
At time: 593.5430569648743 and batch: 50, loss is 3.820557408332825 and perplexity is 45.6296355726013
At time: 594.4552364349365 and batch: 100, loss is 3.8027968406677246 and perplexity is 44.826381580528725
At time: 595.3416686058044 and batch: 150, loss is 3.7879544734954833 and perplexity is 44.16596516146924
At time: 596.2277808189392 and batch: 200, loss is 3.783143177032471 and perplexity is 43.953979980208125
At time: 597.1145703792572 and batch: 250, loss is 3.770658450126648 and perplexity is 43.408637850957156
At time: 598.0007393360138 and batch: 300, loss is 3.7701419830322265 and perplexity is 43.38622450626919
At time: 598.8876581192017 and batch: 350, loss is 3.7810604763031006 and perplexity is 43.86253225622097
At time: 599.7739737033844 and batch: 400, loss is 3.7562634325027466 and perplexity is 42.788245734708234
At time: 600.6595454216003 and batch: 450, loss is 3.795697932243347 and perplexity is 44.509290036247904
At time: 601.5461113452911 and batch: 500, loss is 3.818030261993408 and perplexity is 45.514468389550245
At time: 602.4323568344116 and batch: 550, loss is 3.7678113889694216 and perplexity is 43.285226567341375
At time: 603.3187777996063 and batch: 600, loss is 3.7583689641952516 and perplexity is 42.878432654559816
At time: 604.2298257350922 and batch: 650, loss is 3.788449215888977 and perplexity is 44.18782134292813
At time: 605.116632938385 and batch: 700, loss is 3.8124734592437743 and perplexity is 45.262254865844376
At time: 606.002986907959 and batch: 750, loss is 3.7780755376815796 and perplexity is 43.73180049985276
At time: 606.8904418945312 and batch: 800, loss is 3.7436530590057373 and perplexity is 42.252057844921396
At time: 607.7766053676605 and batch: 850, loss is 3.7577081394195555 and perplexity is 42.85010688413491
At time: 608.663655757904 and batch: 900, loss is 3.721160469055176 and perplexity is 41.31230795694648
At time: 609.5501692295074 and batch: 950, loss is 3.831317648887634 and perplexity is 46.123272490906054
At time: 610.4369130134583 and batch: 1000, loss is 3.7907589530944823 and perplexity is 44.29000155720877
At time: 611.321338891983 and batch: 1050, loss is 3.739799098968506 and perplexity is 42.08953348485525
At time: 612.2064075469971 and batch: 1100, loss is 3.7562649297714232 and perplexity is 42.78830980025626
At time: 613.1000018119812 and batch: 1150, loss is 3.735308442115784 and perplexity is 41.90094758707917
At time: 614.0021121501923 and batch: 1200, loss is 3.7878916311264037 and perplexity is 44.16318975479328
At time: 614.8888690471649 and batch: 1250, loss is 3.771661787033081 and perplexity is 43.452213196091435
At time: 615.7749781608582 and batch: 1300, loss is 3.778061785697937 and perplexity is 43.73119910498282
At time: 616.661628484726 and batch: 1350, loss is 3.6611522579193116 and perplexity is 38.90614696939225
At time: 617.5473794937134 and batch: 1400, loss is 3.689178256988525 and perplexity is 40.01195390082458
At time: 618.4333572387695 and batch: 1450, loss is 3.5980234956741333 and perplexity is 36.52596931467674
At time: 619.320809841156 and batch: 1500, loss is 3.624332571029663 and perplexity is 37.49968642830971
At time: 620.207258939743 and batch: 1550, loss is 3.6276568078994753 and perplexity is 37.62455169441596
At time: 621.0930545330048 and batch: 1600, loss is 3.7126608085632324 and perplexity is 40.962655434069994
At time: 621.9795472621918 and batch: 1650, loss is 3.6588615369796753 and perplexity is 38.81712584405431
At time: 622.8685603141785 and batch: 1700, loss is 3.6826087045669555 and perplexity is 39.749954822823604
At time: 623.7561967372894 and batch: 1750, loss is 3.6751829051971434 and perplexity is 39.45587288146409
At time: 624.6437458992004 and batch: 1800, loss is 3.6271267127990723 and perplexity is 37.604612389238795
At time: 625.5318450927734 and batch: 1850, loss is 3.654106369018555 and perplexity is 38.632982055202724
At time: 626.4196662902832 and batch: 1900, loss is 3.7356243324279785 and perplexity is 41.91418578129228
At time: 627.306881904602 and batch: 1950, loss is 3.6731139326095583 and perplexity is 39.37432415218592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.262632006268168 and perplexity of 70.99660125645744
finished 17 epochs...
Completing Train Step...
At time: 630.2507383823395 and batch: 50, loss is 3.8167958498001098 and perplexity is 45.45831943740413
At time: 631.136048078537 and batch: 100, loss is 3.7984533405303953 and perplexity is 44.63210042154026
At time: 632.0217213630676 and batch: 150, loss is 3.783189368247986 and perplexity is 43.956010314861594
At time: 632.9076943397522 and batch: 200, loss is 3.777983431816101 and perplexity is 43.72777273001224
At time: 633.7933068275452 and batch: 250, loss is 3.7652944231033327 and perplexity is 43.176416123096374
At time: 634.6794469356537 and batch: 300, loss is 3.764853205680847 and perplexity is 43.15737013808156
At time: 635.5655345916748 and batch: 350, loss is 3.7757441091537474 and perplexity is 43.62996169367215
At time: 636.4512965679169 and batch: 400, loss is 3.7507455921173096 and perplexity is 42.552797205455846
At time: 637.3372621536255 and batch: 450, loss is 3.7904264879226686 and perplexity is 44.27527912171555
At time: 638.2234327793121 and batch: 500, loss is 3.8127482652664186 and perplexity is 45.274694915301936
At time: 639.10879945755 and batch: 550, loss is 3.762787733078003 and perplexity is 43.068321767593346
At time: 639.9944157600403 and batch: 600, loss is 3.753824191093445 and perplexity is 42.684002063307325
At time: 640.8810338973999 and batch: 650, loss is 3.783884787559509 and perplexity is 43.98658880449583
At time: 641.7705209255219 and batch: 700, loss is 3.8082160139083863 and perplexity is 45.06996291668199
At time: 642.6567192077637 and batch: 750, loss is 3.773979640007019 and perplexity is 43.55304585016262
At time: 643.5426225662231 and batch: 800, loss is 3.73970251083374 and perplexity is 42.08546833164873
At time: 644.4285578727722 and batch: 850, loss is 3.753980574607849 and perplexity is 42.69067765952182
At time: 645.3147206306458 and batch: 900, loss is 3.7176684093475343 and perplexity is 41.168294509027184
At time: 646.1999642848969 and batch: 950, loss is 3.82802285194397 and perplexity is 45.971555748849326
At time: 647.0853734016418 and batch: 1000, loss is 3.7875505590438845 and perplexity is 44.14812949215649
At time: 647.9977505207062 and batch: 1050, loss is 3.736985306739807 and perplexity is 41.97126874685572
At time: 648.883453130722 and batch: 1100, loss is 3.753622126579285 and perplexity is 42.67537801250465
At time: 649.7695302963257 and batch: 1150, loss is 3.7328291654586794 and perplexity is 41.79719221809522
At time: 650.6548683643341 and batch: 1200, loss is 3.785598831176758 and perplexity is 44.06204838831505
At time: 651.54052734375 and batch: 1250, loss is 3.7696042823791505 and perplexity is 43.3629019758495
At time: 652.4258849620819 and batch: 1300, loss is 3.776275215148926 and perplexity is 43.65313998241629
At time: 653.3106865882874 and batch: 1350, loss is 3.6593839359283447 and perplexity is 38.8374091673177
At time: 654.1952800750732 and batch: 1400, loss is 3.687777876853943 and perplexity is 39.955961170140355
At time: 655.101588010788 and batch: 1450, loss is 3.5968923234939574 and perplexity is 36.48467551393645
At time: 655.9866180419922 and batch: 1500, loss is 3.6234345626831055 and perplexity is 37.466026512608416
At time: 656.8721015453339 and batch: 1550, loss is 3.6270447540283204 and perplexity is 37.60153048772892
At time: 657.7596080303192 and batch: 1600, loss is 3.7122991991043093 and perplexity is 40.94784562824674
At time: 658.6436643600464 and batch: 1650, loss is 3.658567681312561 and perplexity is 38.80572088743158
At time: 659.528835773468 and batch: 1700, loss is 3.682516851425171 and perplexity is 39.74630383226737
At time: 660.4166646003723 and batch: 1750, loss is 3.6753824138641358 and perplexity is 39.463745455364936
At time: 661.3039894104004 and batch: 1800, loss is 3.627460031509399 and perplexity is 37.617148799336675
At time: 662.2051384449005 and batch: 1850, loss is 3.654451651573181 and perplexity is 38.646323653117534
At time: 663.0994210243225 and batch: 1900, loss is 3.7360999965667725 and perplexity is 41.93412759880292
At time: 663.9868450164795 and batch: 1950, loss is 3.673272738456726 and perplexity is 39.38057752161223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26265500090843 and perplexity of 70.99823381653316
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 666.9880800247192 and batch: 50, loss is 3.8163463401794435 and perplexity is 45.43789007741862
At time: 667.8757424354553 and batch: 100, loss is 3.802338480949402 and perplexity is 44.805839681043324
At time: 668.7639720439911 and batch: 150, loss is 3.790360789299011 and perplexity is 44.272370392366014
At time: 669.6511843204498 and batch: 200, loss is 3.7863645362854004 and perplexity is 44.09579984404522
At time: 670.561133146286 and batch: 250, loss is 3.775789947509766 and perplexity is 43.63196166522669
At time: 671.4471113681793 and batch: 300, loss is 3.7747218894958494 and perplexity is 43.585385076584316
At time: 672.3377995491028 and batch: 350, loss is 3.7853421115875245 and perplexity is 44.05073824918127
At time: 673.2248311042786 and batch: 400, loss is 3.761470994949341 and perplexity is 43.01164938571571
At time: 674.1112530231476 and batch: 450, loss is 3.80202702999115 and perplexity is 44.79188703223508
At time: 674.9976677894592 and batch: 500, loss is 3.8244751024246217 and perplexity is 45.80874915331229
At time: 675.885267496109 and batch: 550, loss is 3.774972496032715 and perplexity is 43.59630922777098
At time: 676.7720677852631 and batch: 600, loss is 3.7649502754211426 and perplexity is 43.16155961612518
At time: 677.6596491336823 and batch: 650, loss is 3.793172655105591 and perplexity is 44.397033542735116
At time: 678.5466079711914 and batch: 700, loss is 3.816557831764221 and perplexity is 45.447500825060345
At time: 679.4330751895905 and batch: 750, loss is 3.7827915143966675 and perplexity is 43.938525725255516
At time: 680.3191487789154 and batch: 800, loss is 3.746992406845093 and perplexity is 42.393388006945855
At time: 681.2060091495514 and batch: 850, loss is 3.761798825263977 and perplexity is 43.02575221980881
At time: 682.0935537815094 and batch: 900, loss is 3.7204281806945803 and perplexity is 41.282066508761936
At time: 682.9800479412079 and batch: 950, loss is 3.8315549182891844 and perplexity is 46.1342174305658
At time: 683.8818082809448 and batch: 1000, loss is 3.7911615133285523 and perplexity is 44.30783453978659
At time: 684.7683320045471 and batch: 1050, loss is 3.7406626319885254 and perplexity is 42.1258948841916
At time: 685.6546411514282 and batch: 1100, loss is 3.7545418787002562 and perplexity is 42.7146468379694
At time: 686.5398995876312 and batch: 1150, loss is 3.7334402418136596 and perplexity is 41.822741299388966
At time: 687.4255890846252 and batch: 1200, loss is 3.787131290435791 and perplexity is 44.129623447127344
At time: 688.3118255138397 and batch: 1250, loss is 3.7687659788131715 and perplexity is 43.326565932937065
At time: 689.1983735561371 and batch: 1300, loss is 3.774086995124817 and perplexity is 43.55772174351636
At time: 690.1042799949646 and batch: 1350, loss is 3.65472815990448 and perplexity is 38.65701116110609
At time: 690.9931919574738 and batch: 1400, loss is 3.683458752632141 and perplexity is 39.78375856037731
At time: 691.8796610832214 and batch: 1450, loss is 3.590967140197754 and perplexity is 36.269136309253355
At time: 692.7766146659851 and batch: 1500, loss is 3.615254545211792 and perplexity is 37.16080382654415
At time: 693.668803691864 and batch: 1550, loss is 3.6191181564331054 and perplexity is 37.30465644154366
At time: 694.5552875995636 and batch: 1600, loss is 3.7060980796813965 and perplexity is 40.69470882434453
At time: 695.4617958068848 and batch: 1650, loss is 3.6507316637039184 and perplexity is 38.502826866568334
At time: 696.3522346019745 and batch: 1700, loss is 3.6722145223617555 and perplexity is 39.33892640247877
At time: 697.2396519184113 and batch: 1750, loss is 3.665499095916748 and perplexity is 39.07563378636966
At time: 698.1471297740936 and batch: 1800, loss is 3.6180091667175294 and perplexity is 37.26330889244789
At time: 699.0362055301666 and batch: 1850, loss is 3.6452106380462648 and perplexity is 38.29083750936909
At time: 699.9421184062958 and batch: 1900, loss is 3.7257542610168457 and perplexity is 41.502524678670106
At time: 700.8321199417114 and batch: 1950, loss is 3.666343903541565 and perplexity is 39.10865912780289
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26062494322311 and perplexity of 70.85424950400808
finished 19 epochs...
Completing Train Step...
At time: 703.7845282554626 and batch: 50, loss is 3.8162743520736693 and perplexity is 45.43461920751485
At time: 704.7027249336243 and batch: 100, loss is 3.798917918205261 and perplexity is 44.65284031625148
At time: 705.5878260135651 and batch: 150, loss is 3.785144872665405 and perplexity is 44.04205058585128
At time: 706.4692132472992 and batch: 200, loss is 3.7811112451553344 and perplexity is 43.86475916316796
At time: 707.3519239425659 and batch: 250, loss is 3.7696749496459963 and perplexity is 43.36596642189138
At time: 708.2377183437347 and batch: 300, loss is 3.76854022026062 and perplexity is 43.31678569415284
At time: 709.1227450370789 and batch: 350, loss is 3.778866686820984 and perplexity is 43.766412566030645
At time: 710.0079655647278 and batch: 400, loss is 3.754205861091614 and perplexity is 42.70029637562394
At time: 710.8931217193604 and batch: 450, loss is 3.7948836374282835 and perplexity is 44.47306110466668
At time: 711.778382062912 and batch: 500, loss is 3.8183521032333374 and perplexity is 45.529119179979276
At time: 712.666130065918 and batch: 550, loss is 3.7689048290252685 and perplexity is 43.33258225348031
At time: 713.5509743690491 and batch: 600, loss is 3.758838620185852 and perplexity is 42.898575497056655
At time: 714.436357498169 and batch: 650, loss is 3.7872992944717407 and perplexity is 44.137038024793455
At time: 715.3487401008606 and batch: 700, loss is 3.8115723943710327 and perplexity is 45.221489007023585
At time: 716.2352550029755 and batch: 750, loss is 3.777191843986511 and perplexity is 43.69317205384793
At time: 717.1213397979736 and batch: 800, loss is 3.7417451477050783 and perplexity is 42.171521518796524
At time: 718.0068550109863 and batch: 850, loss is 3.7565139055252077 and perplexity is 42.79896437825269
At time: 718.8913714885712 and batch: 900, loss is 3.7166895961761472 and perplexity is 41.128018154846835
At time: 719.776829957962 and batch: 950, loss is 3.8282253885269166 and perplexity is 45.980867613628256
At time: 720.6638026237488 and batch: 1000, loss is 3.7878818988800047 and perplexity is 44.162759949840314
At time: 721.5490090847015 and batch: 1050, loss is 3.7377711391448973 and perplexity is 42.004264092627736
At time: 722.4346127510071 and batch: 1100, loss is 3.752229995727539 and perplexity is 42.616009636025915
At time: 723.3359620571136 and batch: 1150, loss is 3.731691541671753 and perplexity is 41.74966977445757
At time: 724.2215890884399 and batch: 1200, loss is 3.785281147956848 and perplexity is 44.04805283810065
At time: 725.106053352356 and batch: 1250, loss is 3.767195224761963 and perplexity is 43.258563975129896
At time: 725.991968870163 and batch: 1300, loss is 3.7729179573059084 and perplexity is 43.50683087196527
At time: 726.8771874904633 and batch: 1350, loss is 3.654225454330444 and perplexity is 38.63758294986404
At time: 727.7632915973663 and batch: 1400, loss is 3.683391637802124 and perplexity is 39.78108856978307
At time: 728.6481902599335 and batch: 1450, loss is 3.591628670692444 and perplexity is 36.293137386785055
At time: 729.5340704917908 and batch: 1500, loss is 3.616820983886719 and perplexity is 37.21905956195593
At time: 730.4198944568634 and batch: 1550, loss is 3.6208549404144286 and perplexity is 37.369502867096344
At time: 731.3046200275421 and batch: 1600, loss is 3.7082226610183717 and perplexity is 40.78125995312629
At time: 732.1899735927582 and batch: 1650, loss is 3.6534140872955323 and perplexity is 38.60624640318944
At time: 733.0919456481934 and batch: 1700, loss is 3.6748899316787718 and perplexity is 39.44431504871771
At time: 733.9765269756317 and batch: 1750, loss is 3.668424868583679 and perplexity is 39.19012761743191
At time: 734.8625936508179 and batch: 1800, loss is 3.6208938932418824 and perplexity is 37.370958543244726
At time: 735.7481062412262 and batch: 1850, loss is 3.648023157119751 and perplexity is 38.39868280759268
At time: 736.6326446533203 and batch: 1900, loss is 3.7286433219909667 and perplexity is 41.62260137397383
At time: 737.516902923584 and batch: 1950, loss is 3.669086804389954 and perplexity is 39.216077553802876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260080736736919 and perplexity of 70.81570065207279
Finished Training.
Improved accuracyfrom -10000000 to -70.81570065207279
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
768.4135656356812


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4122540950775146 and batch: 50, loss is 7.922140665054322 and perplexity is 2757.6679752687405
At time: 2.366159200668335 and batch: 100, loss is 7.165847511291504 and perplexity is 1294.4582039880916
At time: 3.319279909133911 and batch: 150, loss is 6.92954423904419 and perplexity is 1022.0280729682681
At time: 4.273697137832642 and batch: 200, loss is 6.854237546920777 and perplexity is 947.8891328265156
At time: 5.229381322860718 and batch: 250, loss is 6.781883955001831 and perplexity is 881.7282967717932
At time: 6.184639930725098 and batch: 300, loss is 6.71447262763977 and perplexity is 824.2489661339245
At time: 7.1397058963775635 and batch: 350, loss is 6.68206241607666 and perplexity is 797.9631481151695
At time: 8.094283103942871 and batch: 400, loss is 6.662813940048218 and perplexity is 782.7504538712244
At time: 9.049784183502197 and batch: 450, loss is 6.580590343475341 and perplexity is 720.9648205215502
At time: 10.004546642303467 and batch: 500, loss is 6.574104852676392 and perplexity is 716.3041395497644
At time: 10.95930528640747 and batch: 550, loss is 6.542479419708252 and perplexity is 694.0051767051118
At time: 11.915109634399414 and batch: 600, loss is 6.598835897445679 and perplexity is 734.239960937813
At time: 12.870002746582031 and batch: 650, loss is 6.686613359451294 and perplexity is 801.6029091084267
At time: 13.825064897537231 and batch: 700, loss is 6.574898710250855 and perplexity is 716.8730087872659
At time: 14.778682231903076 and batch: 750, loss is 6.515824060440064 and perplexity is 675.7505914730887
At time: 15.732385635375977 and batch: 800, loss is 6.521713666915893 and perplexity is 679.7422396127008
At time: 16.688335418701172 and batch: 850, loss is 6.576285963058472 and perplexity is 717.8681830009232
At time: 17.64338445663452 and batch: 900, loss is 6.565379333496094 and perplexity is 710.0812027003427
At time: 18.599170684814453 and batch: 950, loss is 6.582663726806641 and perplexity is 722.4612077189385
At time: 19.554139852523804 and batch: 1000, loss is 6.580455312728882 and perplexity is 720.8674746761529
At time: 20.50937509536743 and batch: 1050, loss is 6.483949270248413 and perplexity is 654.5508467410274
At time: 21.463852167129517 and batch: 1100, loss is 6.55810772895813 and perplexity is 704.9365007926843
At time: 22.41956090927124 and batch: 1150, loss is 6.470710611343383 and perplexity is 645.9425780364919
At time: 23.375641584396362 and batch: 1200, loss is 6.5667135047912595 and perplexity is 711.0292049162729
At time: 24.33490300178528 and batch: 1250, loss is 6.488013534545899 and perplexity is 657.2165277249886
At time: 25.293251752853394 and batch: 1300, loss is 6.506262989044189 and perplexity is 669.3204801822651
At time: 26.248329162597656 and batch: 1350, loss is 6.521016387939453 and perplexity is 679.268434845869
At time: 27.211114168167114 and batch: 1400, loss is 6.5435515308380126 and perplexity is 694.7496263742493
At time: 28.16592025756836 and batch: 1450, loss is 6.550186815261841 and perplexity is 699.3748155018582
At time: 29.12047553062439 and batch: 1500, loss is 6.530285882949829 and perplexity is 685.5941831654632
At time: 30.075599193572998 and batch: 1550, loss is 6.5010144329071045 and perplexity is 665.8167169605845
At time: 31.030017614364624 and batch: 1600, loss is 6.489058952331543 and perplexity is 657.9039528327019
At time: 31.98548436164856 and batch: 1650, loss is 6.486237716674805 and perplexity is 656.0504665324626
At time: 32.940892696380615 and batch: 1700, loss is 6.514158601760864 and perplexity is 674.6260934479667
At time: 33.89622902870178 and batch: 1750, loss is 6.533896703720092 and perplexity is 688.0742156638767
At time: 34.850366830825806 and batch: 1800, loss is 6.5409914493560795 and perplexity is 692.9732854800836
At time: 35.80656361579895 and batch: 1850, loss is 6.483268413543701 and perplexity is 654.1053430877338
At time: 36.76255202293396 and batch: 1900, loss is 6.426083707809449 and perplexity is 617.7499153316412
At time: 37.72312593460083 and batch: 1950, loss is 6.381377782821655 and perplexity is 590.7410601029474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.914352062136628 and perplexity of 370.31428430807904
finished 1 epochs...
Completing Train Step...
At time: 40.73288178443909 and batch: 50, loss is 6.141942024230957 and perplexity is 464.95564978439984
At time: 41.645100116729736 and batch: 100, loss is 5.958514318466187 and perplexity is 387.03468659826626
At time: 42.53710913658142 and batch: 150, loss is 5.764734258651734 and perplexity is 318.85430000516556
At time: 43.44171094894409 and batch: 200, loss is 5.66048641204834 and perplexity is 287.2883490901743
At time: 44.327340841293335 and batch: 250, loss is 5.603610038757324 and perplexity is 271.4044215101853
At time: 45.21306824684143 and batch: 300, loss is 5.542961492538452 and perplexity is 255.4333443757684
At time: 46.10009837150574 and batch: 350, loss is 5.492097597122193 and perplexity is 242.7658982061273
At time: 47.01740312576294 and batch: 400, loss is 5.421466789245605 and perplexity is 226.2106826747287
At time: 47.91858267784119 and batch: 450, loss is 5.3456980419158935 and perplexity is 209.70421585285925
At time: 48.80483794212341 and batch: 500, loss is 5.3030540466308596 and perplexity is 200.94958317701105
At time: 49.690677642822266 and batch: 550, loss is 5.25137095451355 and perplexity is 190.82770531257322
At time: 50.576343059539795 and batch: 600, loss is 5.238020982742309 and perplexity is 188.2970902374961
At time: 51.46285009384155 and batch: 650, loss is 5.30083662033081 and perplexity is 200.5044859538126
At time: 52.34935665130615 and batch: 700, loss is 5.258332204818726 and perplexity is 192.16073914237353
At time: 53.256622552871704 and batch: 750, loss is 5.191017103195191 and perplexity is 179.65118383194735
At time: 54.14263725280762 and batch: 800, loss is 5.169180955886841 and perplexity is 175.77081446066265
At time: 55.029088735580444 and batch: 850, loss is 5.166259155273438 and perplexity is 175.25799672756028
At time: 55.91453981399536 and batch: 900, loss is 5.176871547698974 and perplexity is 177.12780739825814
At time: 56.79982376098633 and batch: 950, loss is 5.209251480102539 and perplexity is 182.95705992741392
At time: 57.70422697067261 and batch: 1000, loss is 5.165651140213012 and perplexity is 175.15146961441624
At time: 58.592907667160034 and batch: 1050, loss is 5.065032262802124 and perplexity is 158.38555195297354
At time: 59.47913861274719 and batch: 1100, loss is 5.144352760314941 and perplexity is 171.46047272690194
At time: 60.36819863319397 and batch: 1150, loss is 5.039967432022094 and perplexity is 154.46498433177462
At time: 61.25646257400513 and batch: 1200, loss is 5.1140338325500485 and perplexity is 166.33999103585563
At time: 62.145132541656494 and batch: 1250, loss is 5.060466232299805 and perplexity is 157.66400724280882
At time: 63.0337278842926 and batch: 1300, loss is 5.088856811523438 and perplexity is 162.20432590607805
At time: 63.92314648628235 and batch: 1350, loss is 5.009249143600464 and perplexity is 149.7922214650598
At time: 64.81299757957458 and batch: 1400, loss is 5.017946166992187 and perplexity is 151.10064938590432
At time: 65.70174670219421 and batch: 1450, loss is 4.964373588562012 and perplexity is 143.2188082689347
At time: 66.59083437919617 and batch: 1500, loss is 4.933011274337769 and perplexity is 138.79683904158455
At time: 67.47975134849548 and batch: 1550, loss is 4.918854913711548 and perplexity is 136.84582315881468
At time: 68.37921404838562 and batch: 1600, loss is 4.973481864929199 and perplexity is 144.52924359966417
At time: 69.27872943878174 and batch: 1650, loss is 4.945888795852661 and perplexity is 140.595756260585
At time: 70.16699194908142 and batch: 1700, loss is 4.960158367156982 and perplexity is 142.6163798592803
At time: 71.05365633964539 and batch: 1750, loss is 4.96761736869812 and perplexity is 143.68413289168228
At time: 71.94000029563904 and batch: 1800, loss is 4.91952317237854 and perplexity is 136.9373021285851
At time: 72.82642793655396 and batch: 1850, loss is 4.913656558990478 and perplexity is 136.13629581314132
At time: 73.71245265007019 and batch: 1900, loss is 4.985866994857788 and perplexity is 146.33038773893645
At time: 74.5987069606781 and batch: 1950, loss is 4.9064930820465085 and perplexity is 135.16457121558796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.692185796693314 and perplexity of 109.09137095176968
finished 2 epochs...
Completing Train Step...
At time: 77.59028148651123 and batch: 50, loss is 4.888747653961182 and perplexity is 132.78717438620166
At time: 78.50285124778748 and batch: 100, loss is 4.8374862957000735 and perplexity is 126.15184440381393
At time: 79.39009475708008 and batch: 150, loss is 4.781727933883667 and perplexity is 119.31033239764082
At time: 80.27756762504578 and batch: 200, loss is 4.758226013183593 and perplexity is 116.53900375841646
At time: 81.16512942314148 and batch: 250, loss is 4.770859661102295 and perplexity is 118.0206561308595
At time: 82.05310440063477 and batch: 300, loss is 4.790642385482788 and perplexity is 120.37867334304791
At time: 82.94049739837646 and batch: 350, loss is 4.793726243972778 and perplexity is 120.75047713733431
At time: 83.82788920402527 and batch: 400, loss is 4.750079126358032 and perplexity is 115.59343065251305
At time: 84.71360278129578 and batch: 450, loss is 4.733887882232666 and perplexity is 113.73689953012439
At time: 85.6003532409668 and batch: 500, loss is 4.731719675064087 and perplexity is 113.49056152165463
At time: 86.4858193397522 and batch: 550, loss is 4.697679977416993 and perplexity is 109.69238819599222
At time: 87.37415719032288 and batch: 600, loss is 4.670253705978394 and perplexity is 106.72481572176952
At time: 88.26066040992737 and batch: 650, loss is 4.7477756786346434 and perplexity is 115.32747365445316
At time: 89.14842224121094 and batch: 700, loss is 4.754780244827271 and perplexity is 116.13812840543476
At time: 90.0349428653717 and batch: 750, loss is 4.709634246826172 and perplexity is 111.0115496528704
At time: 90.94574189186096 and batch: 800, loss is 4.693667888641357 and perplexity is 109.25317426833655
At time: 91.83276176452637 and batch: 850, loss is 4.683699407577515 and perplexity is 108.16949635465569
At time: 92.71999597549438 and batch: 900, loss is 4.68303484916687 and perplexity is 108.09763528666132
At time: 93.60851192474365 and batch: 950, loss is 4.743100891113281 and perplexity is 114.78960042082363
At time: 94.49548864364624 and batch: 1000, loss is 4.718680410385132 and perplexity is 112.02033422375659
At time: 95.38287019729614 and batch: 1050, loss is 4.632938489913941 and perplexity is 102.81574367802585
At time: 96.27064633369446 and batch: 1100, loss is 4.708946828842163 and perplexity is 110.93526454008949
At time: 97.15740537643433 and batch: 1150, loss is 4.647669773101807 and perplexity is 104.34156255615886
At time: 98.04432702064514 and batch: 1200, loss is 4.719337320327758 and perplexity is 112.093945670483
At time: 98.93204069137573 and batch: 1250, loss is 4.68265625 and perplexity is 108.0567173582367
At time: 99.82059812545776 and batch: 1300, loss is 4.701266431808472 and perplexity is 110.08650125516056
At time: 100.73268675804138 and batch: 1350, loss is 4.593466711044312 and perplexity is 98.83647443255751
At time: 101.61991310119629 and batch: 1400, loss is 4.60149772644043 and perplexity is 99.63342756844246
At time: 102.50786447525024 and batch: 1450, loss is 4.553498477935791 and perplexity is 94.96405750284369
At time: 103.39564776420593 and batch: 1500, loss is 4.542019939422607 and perplexity is 93.88024112543661
At time: 104.28417944908142 and batch: 1550, loss is 4.546750621795654 and perplexity is 94.32541087543343
At time: 105.17143630981445 and batch: 1600, loss is 4.617798690795898 and perplexity is 101.2708581100897
At time: 106.07088661193848 and batch: 1650, loss is 4.57880259513855 and perplexity is 97.39769987649126
At time: 106.96767163276672 and batch: 1700, loss is 4.607363014221192 and perplexity is 100.21952342392616
At time: 107.85475516319275 and batch: 1750, loss is 4.60682204246521 and perplexity is 100.16532215435572
At time: 108.74834752082825 and batch: 1800, loss is 4.5683041858673095 and perplexity is 96.38052764870508
At time: 109.63596987724304 and batch: 1850, loss is 4.590658168792725 and perplexity is 98.5592774600292
At time: 110.52299427986145 and batch: 1900, loss is 4.679156217575073 and perplexity is 107.67917643190711
At time: 111.41012954711914 and batch: 1950, loss is 4.609311771392822 and perplexity is 100.41501736217484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.519631745094477 and perplexity of 91.80178529492505
finished 3 epochs...
Completing Train Step...
At time: 114.35546731948853 and batch: 50, loss is 4.588008136749267 and perplexity is 98.29843798571174
At time: 115.26995062828064 and batch: 100, loss is 4.538061237335205 and perplexity is 93.50933186294975
At time: 116.15711951255798 and batch: 150, loss is 4.498933057785035 and perplexity is 89.92113944105694
At time: 117.06198501586914 and batch: 200, loss is 4.491187744140625 and perplexity is 89.22736224212342
At time: 117.95517826080322 and batch: 250, loss is 4.4862272167205814 and perplexity is 88.78584345349648
At time: 118.84213972091675 and batch: 300, loss is 4.523616361618042 and perplexity is 92.16830995065601
At time: 119.72963690757751 and batch: 350, loss is 4.52774751663208 and perplexity is 92.54985910315092
At time: 120.61731338500977 and batch: 400, loss is 4.486493186950684 and perplexity is 88.80946098535058
At time: 121.50668406486511 and batch: 450, loss is 4.489866924285889 and perplexity is 89.10958676770306
At time: 122.39635968208313 and batch: 500, loss is 4.499424800872803 and perplexity is 89.96536841357585
At time: 123.30923199653625 and batch: 550, loss is 4.468197526931763 and perplexity is 87.19940669468592
At time: 124.20195484161377 and batch: 600, loss is 4.442781753540039 and perplexity is 85.01109297301083
At time: 125.09067392349243 and batch: 650, loss is 4.510527420043945 and perplexity is 90.96978514821511
At time: 126.00185251235962 and batch: 700, loss is 4.530118446350098 and perplexity is 92.76954864581784
At time: 126.89084959030151 and batch: 750, loss is 4.488206624984741 and perplexity is 88.96176093458878
At time: 127.80348634719849 and batch: 800, loss is 4.469703254699707 and perplexity is 87.33080416227658
At time: 128.71620082855225 and batch: 850, loss is 4.460720205307007 and perplexity is 86.54982029510505
At time: 129.6050364971161 and batch: 900, loss is 4.453705310821533 and perplexity is 85.94480697130601
At time: 130.49448657035828 and batch: 950, loss is 4.522581701278686 and perplexity is 92.07299637289695
At time: 131.38377594947815 and batch: 1000, loss is 4.499279088973999 and perplexity is 89.95226034394177
At time: 132.2779369354248 and batch: 1050, loss is 4.4270994758605955 and perplexity is 83.68832452755706
At time: 133.16648030281067 and batch: 1100, loss is 4.489583806991577 and perplexity is 89.08436187357054
At time: 134.06151270866394 and batch: 1150, loss is 4.44426155090332 and perplexity is 85.13698528882718
At time: 134.96292400360107 and batch: 1200, loss is 4.517713556289673 and perplexity is 91.62586092013642
At time: 135.88274383544922 and batch: 1250, loss is 4.49117259979248 and perplexity is 89.22601096211777
At time: 136.7955780029297 and batch: 1300, loss is 4.496117248535156 and perplexity is 89.66829481304282
At time: 137.68588137626648 and batch: 1350, loss is 4.387256164550781 and perplexity is 80.41945821885149
At time: 138.60456204414368 and batch: 1400, loss is 4.396100473403931 and perplexity is 81.13386731563406
At time: 139.49363899230957 and batch: 1450, loss is 4.3415744543075565 and perplexity is 76.8284069793496
At time: 140.40126395225525 and batch: 1500, loss is 4.34420606136322 and perplexity is 77.03085542277229
At time: 141.2944507598877 and batch: 1550, loss is 4.349785537719726 and perplexity is 77.46184849907735
At time: 142.21987652778625 and batch: 1600, loss is 4.431784782409668 and perplexity is 84.08134998594652
At time: 143.1283838748932 and batch: 1650, loss is 4.388806266784668 and perplexity is 80.54421326724383
At time: 144.0436189174652 and batch: 1700, loss is 4.414861822128296 and perplexity is 82.67041689459424
At time: 144.95008635520935 and batch: 1750, loss is 4.414907560348511 and perplexity is 82.67419817880136
At time: 145.85819911956787 and batch: 1800, loss is 4.375746831893921 and perplexity is 79.49918991770126
At time: 146.7448534965515 and batch: 1850, loss is 4.4047802734375 and perplexity is 81.84115819102672
At time: 147.63150453567505 and batch: 1900, loss is 4.497011651992798 and perplexity is 89.74853032207407
At time: 148.54370999336243 and batch: 1950, loss is 4.423744821548462 and perplexity is 83.40804950455707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.44120611146439 and perplexity of 84.87725138893141
finished 4 epochs...
Completing Train Step...
At time: 151.4929268360138 and batch: 50, loss is 4.402828531265259 and perplexity is 81.68158112845799
At time: 152.38013792037964 and batch: 100, loss is 4.359039802551269 and perplexity is 78.18202818644515
At time: 153.26717591285706 and batch: 150, loss is 4.323839807510376 and perplexity is 75.47789315692111
At time: 154.15361785888672 and batch: 200, loss is 4.327859764099121 and perplexity is 75.78192169215225
At time: 155.04064893722534 and batch: 250, loss is 4.314101142883301 and perplexity is 74.7464068996445
At time: 155.94355535507202 and batch: 300, loss is 4.35180495262146 and perplexity is 77.61843416275006
At time: 156.83430981636047 and batch: 350, loss is 4.354349117279053 and perplexity is 77.81615965617809
At time: 157.72047591209412 and batch: 400, loss is 4.318406419754028 and perplexity is 75.06890459924762
At time: 158.6308434009552 and batch: 450, loss is 4.334319972991944 and perplexity is 76.27307350006652
At time: 159.52911734580994 and batch: 500, loss is 4.345563220977783 and perplexity is 77.13546956181239
At time: 160.43587374687195 and batch: 550, loss is 4.314606323242187 and perplexity is 74.78417685582428
At time: 161.32231211662292 and batch: 600, loss is 4.299375720024109 and perplexity is 73.65379875251786
At time: 162.21258401870728 and batch: 650, loss is 4.3575691223144535 and perplexity is 78.06713193125218
At time: 163.1056263446808 and batch: 700, loss is 4.379688758850097 and perplexity is 79.81318839035758
At time: 164.002192735672 and batch: 750, loss is 4.345283718109131 and perplexity is 77.11391298949724
At time: 164.89288234710693 and batch: 800, loss is 4.322200355529785 and perplexity is 75.35425215493046
At time: 165.77984595298767 and batch: 850, loss is 4.312956914901734 and perplexity is 74.66092888184428
At time: 166.6671643257141 and batch: 900, loss is 4.299227123260498 and perplexity is 73.64285484952998
At time: 167.55461621284485 and batch: 950, loss is 4.380220756530762 and perplexity is 79.85566011789629
At time: 168.4552161693573 and batch: 1000, loss is 4.354704294204712 and perplexity is 77.843803069392
At time: 169.36101150512695 and batch: 1050, loss is 4.289481573104858 and perplexity is 72.928650523694
At time: 170.27547025680542 and batch: 1100, loss is 4.343828716278076 and perplexity is 77.00179369156963
At time: 171.20054006576538 and batch: 1150, loss is 4.301766414642334 and perplexity is 73.83009314186484
At time: 172.09511971473694 and batch: 1200, loss is 4.378579721450806 and perplexity is 79.72472164500816
At time: 173.00525212287903 and batch: 1250, loss is 4.356195163726807 and perplexity is 77.95994457727706
At time: 173.89460039138794 and batch: 1300, loss is 4.362847738265991 and perplexity is 78.48030787834107
At time: 174.78118801116943 and batch: 1350, loss is 4.247072224617004 and perplexity is 69.90045962038015
At time: 175.69017124176025 and batch: 1400, loss is 4.264381618499756 and perplexity is 71.12092650719178
At time: 176.58600854873657 and batch: 1450, loss is 4.202118215560913 and perplexity is 66.82773677607847
At time: 177.4850299358368 and batch: 1500, loss is 4.207691850662232 and perplexity is 67.20125014217444
At time: 178.37490701675415 and batch: 1550, loss is 4.212845449447632 and perplexity is 67.54847237682182
At time: 179.28020691871643 and batch: 1600, loss is 4.301977796554565 and perplexity is 73.8457011376993
At time: 180.16711831092834 and batch: 1650, loss is 4.254252667427063 and perplexity is 70.40418218433844
At time: 181.05788040161133 and batch: 1700, loss is 4.280035858154297 and perplexity is 72.2430304626138
At time: 181.96591877937317 and batch: 1750, loss is 4.283930358886718 and perplexity is 72.52492956950185
At time: 182.877338886261 and batch: 1800, loss is 4.245325040817261 and perplexity is 69.77843729848978
At time: 183.76604652404785 and batch: 1850, loss is 4.280126628875732 and perplexity is 72.24958831223344
At time: 184.66223287582397 and batch: 1900, loss is 4.369325914382935 and perplexity is 78.99036747865468
At time: 185.56865048408508 and batch: 1950, loss is 4.294996604919434 and perplexity is 73.33196547667055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.409039448582849 and perplexity of 82.19047739562683
finished 5 epochs...
Completing Train Step...
At time: 188.53289341926575 and batch: 50, loss is 4.278321046829223 and perplexity is 72.11925345325892
At time: 189.41577315330505 and batch: 100, loss is 4.231826739311218 and perplexity is 68.84287536695753
At time: 190.30073046684265 and batch: 150, loss is 4.201110072135926 and perplexity is 66.7603987815224
At time: 191.1845302581787 and batch: 200, loss is 4.206973266601563 and perplexity is 67.15297774093146
At time: 192.06834363937378 and batch: 250, loss is 4.1915340232849125 and perplexity is 66.12414918213764
At time: 192.95143342018127 and batch: 300, loss is 4.23130696773529 and perplexity is 68.807102094907
At time: 193.83360767364502 and batch: 350, loss is 4.233047966957092 and perplexity is 68.92699954650878
At time: 194.71542143821716 and batch: 400, loss is 4.193797249794006 and perplexity is 66.2739725876574
At time: 195.60032534599304 and batch: 450, loss is 4.219141216278076 and perplexity is 67.9750833210559
At time: 196.48588109016418 and batch: 500, loss is 4.235397691726685 and perplexity is 69.0891494538585
At time: 197.36802172660828 and batch: 550, loss is 4.205053787231446 and perplexity is 67.02420261565227
At time: 198.25088477134705 and batch: 600, loss is 4.19323055267334 and perplexity is 66.23642595800514
At time: 199.1343376636505 and batch: 650, loss is 4.242265934944153 and perplexity is 69.56530383625754
At time: 200.01692628860474 and batch: 700, loss is 4.26689651966095 and perplexity is 71.3000137067632
At time: 200.90068650245667 and batch: 750, loss is 4.237736792564392 and perplexity is 69.25094509561245
At time: 201.78713941574097 and batch: 800, loss is 4.213516573905945 and perplexity is 67.59382102434675
At time: 202.71242809295654 and batch: 850, loss is 4.20353672504425 and perplexity is 66.92259982060274
At time: 203.59609055519104 and batch: 900, loss is 4.185276312828064 and perplexity is 65.7116553818017
At time: 204.47881841659546 and batch: 950, loss is 4.274816718101501 and perplexity is 71.86696618849622
At time: 205.36254024505615 and batch: 1000, loss is 4.247840528488159 and perplexity is 69.95418505018702
At time: 206.24754738807678 and batch: 1050, loss is 4.187784848213195 and perplexity is 65.87670232103623
At time: 207.13258481025696 and batch: 1100, loss is 4.235643343925476 and perplexity is 69.10612344009762
At time: 208.0183229446411 and batch: 1150, loss is 4.196469249725342 and perplexity is 66.45129343300455
At time: 208.9040184020996 and batch: 1200, loss is 4.276713123321533 and perplexity is 72.00338438953425
At time: 209.78982877731323 and batch: 1250, loss is 4.253955454826355 and perplexity is 70.38326028353097
At time: 210.6756796836853 and batch: 1300, loss is 4.2645441341400145 and perplexity is 71.13248570934903
At time: 211.57900547981262 and batch: 1350, loss is 4.142011637687683 and perplexity is 62.92928512862699
At time: 212.4651336669922 and batch: 1400, loss is 4.163746681213379 and perplexity is 64.31202843798287
At time: 213.3511004447937 and batch: 1450, loss is 4.100045909881592 and perplexity is 60.3430578764119
At time: 214.23589777946472 and batch: 1500, loss is 4.105474200248718 and perplexity is 60.67150817147323
At time: 215.12081909179688 and batch: 1550, loss is 4.111822943687439 and perplexity is 61.0579213319889
At time: 216.0064344406128 and batch: 1600, loss is 4.204200415611267 and perplexity is 66.96703046129159
At time: 216.89269423484802 and batch: 1650, loss is 4.152840366363526 and perplexity is 63.61443222395492
At time: 217.78001999855042 and batch: 1700, loss is 4.184789862632751 and perplexity is 65.67969770774549
At time: 218.66568112373352 and batch: 1750, loss is 4.18606650352478 and perplexity is 65.7636006411777
At time: 219.55202794075012 and batch: 1800, loss is 4.147805700302124 and perplexity is 63.2949596946007
At time: 220.43832635879517 and batch: 1850, loss is 4.184004702568054 and perplexity is 65.62814887173592
At time: 221.3245460987091 and batch: 1900, loss is 4.27270076751709 and perplexity is 71.7150600090512
At time: 222.21090459823608 and batch: 1950, loss is 4.194663043022156 and perplexity is 66.33137699091233
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388833689135175 and perplexity of 80.54642200917564
finished 6 epochs...
Completing Train Step...
At time: 225.16700410842896 and batch: 50, loss is 4.180700206756592 and perplexity is 65.4116388539173
At time: 226.0521104335785 and batch: 100, loss is 4.136624755859375 and perplexity is 62.591203925394545
At time: 226.93830800056458 and batch: 150, loss is 4.103782563209534 and perplexity is 60.56896076197973
At time: 227.82541871070862 and batch: 200, loss is 4.1123468542099 and perplexity is 61.089918600575245
At time: 228.71264958381653 and batch: 250, loss is 4.096378884315491 and perplexity is 60.12218356382736
At time: 229.59859228134155 and batch: 300, loss is 4.138474016189575 and perplexity is 62.707058445400946
At time: 230.50729203224182 and batch: 350, loss is 4.137007436752319 and perplexity is 62.6151609668618
At time: 231.39386534690857 and batch: 400, loss is 4.096631145477295 and perplexity is 60.13735196882266
At time: 232.27987694740295 and batch: 450, loss is 4.1343116235733035 and perplexity is 62.44658951138657
At time: 233.16626453399658 and batch: 500, loss is 4.145920386314392 and perplexity is 63.175741239158974
At time: 234.05250000953674 and batch: 550, loss is 4.1154354333877565 and perplexity is 61.27889132953727
At time: 234.93917798995972 and batch: 600, loss is 4.108829793930053 and perplexity is 60.875439064182736
At time: 235.8250789642334 and batch: 650, loss is 4.157045822143555 and perplexity is 63.882523232967976
At time: 236.71099019050598 and batch: 700, loss is 4.178761010169983 and perplexity is 65.28491573735649
At time: 237.59689950942993 and batch: 750, loss is 4.155137963294983 and perplexity is 63.760760585654815
At time: 238.4935817718506 and batch: 800, loss is 4.128030376434326 and perplexity is 62.05557636038466
At time: 239.38039302825928 and batch: 850, loss is 4.118148875236511 and perplexity is 61.44539383298662
At time: 240.26541996002197 and batch: 900, loss is 4.102562947273254 and perplexity is 60.495134920927754
At time: 241.1514003276825 and batch: 950, loss is 4.19357807636261 and perplexity is 66.25944868535801
At time: 242.03703951835632 and batch: 1000, loss is 4.163435282707215 and perplexity is 64.29200488621277
At time: 242.93998551368713 and batch: 1050, loss is 4.106656460762024 and perplexity is 60.74328011807643
At time: 243.84531164169312 and batch: 1100, loss is 4.150429425239563 and perplexity is 63.46124630854134
At time: 244.74786901474 and batch: 1150, loss is 4.113222846984863 and perplexity is 61.14345637382014
At time: 245.63551568984985 and batch: 1200, loss is 4.196445431709289 and perplexity is 66.44971071387953
At time: 246.52298951148987 and batch: 1250, loss is 4.17475652217865 and perplexity is 65.02400583022688
At time: 247.41889595985413 and batch: 1300, loss is 4.1843247938156125 and perplexity is 65.64915923021975
At time: 248.30850887298584 and batch: 1350, loss is 4.060620675086975 and perplexity is 58.01030545878241
At time: 249.2159616947174 and batch: 1400, loss is 4.088657479286194 and perplexity is 59.659743474459155
At time: 250.10404586791992 and batch: 1450, loss is 4.0224846076965335 and perplexity is 55.83967329465227
At time: 250.99167323112488 and batch: 1500, loss is 4.0272344207763675 and perplexity is 56.10553219545248
At time: 251.89018082618713 and batch: 1550, loss is 4.033310265541076 and perplexity is 56.44745839288656
At time: 252.7885546684265 and batch: 1600, loss is 4.126825685501099 and perplexity is 61.98086358212615
At time: 253.67657494544983 and batch: 1650, loss is 4.075937986373901 and perplexity is 58.90570743420212
At time: 254.56478667259216 and batch: 1700, loss is 4.107353191375733 and perplexity is 60.78561656774943
At time: 255.45102429389954 and batch: 1750, loss is 4.1067036581039424 and perplexity is 60.746147107094
At time: 256.3354637622833 and batch: 1800, loss is 4.0660381555557255 and perplexity is 58.32542796990327
At time: 257.2212014198303 and batch: 1850, loss is 4.106415185928345 and perplexity is 60.72862606116746
At time: 258.1069300174713 and batch: 1900, loss is 4.193916010856628 and perplexity is 66.28184382245496
At time: 258.99389386177063 and batch: 1950, loss is 4.11422661781311 and perplexity is 61.20486120469964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380611827761628 and perplexity of 79.88689547641718
finished 7 epochs...
Completing Train Step...
At time: 261.92284393310547 and batch: 50, loss is 4.105310463905335 and perplexity is 60.66157485382243
At time: 262.8321225643158 and batch: 100, loss is 4.060856704711914 and perplexity is 58.02399922542618
At time: 263.71786665916443 and batch: 150, loss is 4.02855122089386 and perplexity is 56.17946063064307
At time: 264.6275329589844 and batch: 200, loss is 4.038949127197266 and perplexity is 56.7666569139687
At time: 265.5364863872528 and batch: 250, loss is 4.017145376205445 and perplexity is 55.54232685965076
At time: 266.4236500263214 and batch: 300, loss is 4.061509308815002 and perplexity is 58.061878284068456
At time: 267.3089208602905 and batch: 350, loss is 4.060390329360962 and perplexity is 57.99694457172595
At time: 268.19523215293884 and batch: 400, loss is 4.019603943824768 and perplexity is 55.67904942794045
At time: 269.0798909664154 and batch: 450, loss is 4.06157705783844 and perplexity is 58.06581205287414
At time: 269.9890048503876 and batch: 500, loss is 4.078602466583252 and perplexity is 59.062869810918976
At time: 270.8747067451477 and batch: 550, loss is 4.043976306915283 and perplexity is 57.05275162249636
At time: 271.7605631351471 and batch: 600, loss is 4.041087050437927 and perplexity is 56.888149493708944
At time: 272.64541006088257 and batch: 650, loss is 4.083117642402649 and perplexity is 59.33015201149205
At time: 273.530739068985 and batch: 700, loss is 4.1100643491744995 and perplexity is 60.95063956677355
At time: 274.41669845581055 and batch: 750, loss is 4.085017032623291 and perplexity is 59.4429502119997
At time: 275.30269145965576 and batch: 800, loss is 4.059199252128601 and perplexity is 57.92790685428858
At time: 276.188364982605 and batch: 850, loss is 4.0482001209259035 and perplexity is 57.29424147923707
At time: 277.0740113258362 and batch: 900, loss is 4.0332006025314335 and perplexity is 56.44126853411798
At time: 277.9592502117157 and batch: 950, loss is 4.126286396980285 and perplexity is 61.947447025278855
At time: 278.84506249427795 and batch: 1000, loss is 4.0960849142074585 and perplexity is 60.104512036607616
At time: 279.7312099933624 and batch: 1050, loss is 4.043021893501281 and perplexity is 56.99832568759471
At time: 280.636652469635 and batch: 1100, loss is 4.080592303276062 and perplexity is 59.18051228228787
At time: 281.52202916145325 and batch: 1150, loss is 4.044749622344971 and perplexity is 57.09688845928106
At time: 282.40797662734985 and batch: 1200, loss is 4.126579151153565 and perplexity is 61.96558505378173
At time: 283.29310131073 and batch: 1250, loss is 4.107665276527404 and perplexity is 60.80458981659605
At time: 284.17897772789 and batch: 1300, loss is 4.116499786376953 and perplexity is 61.344148422829136
At time: 285.0646584033966 and batch: 1350, loss is 3.99405339717865 and perplexity is 54.27443996165024
At time: 285.9497346878052 and batch: 1400, loss is 4.025098156929016 and perplexity is 55.9858039065274
At time: 286.8492832183838 and batch: 1450, loss is 3.95598210811615 and perplexity is 52.24698093964736
At time: 287.7451376914978 and batch: 1500, loss is 3.961042256355286 and perplexity is 52.51202843250435
At time: 288.63246059417725 and batch: 1550, loss is 3.967127184867859 and perplexity is 52.83253451092348
At time: 289.5201749801636 and batch: 1600, loss is 4.061680397987366 and perplexity is 58.0718128925977
At time: 290.40832448005676 and batch: 1650, loss is 4.012654137611389 and perplexity is 55.293432358325575
At time: 291.29651951789856 and batch: 1700, loss is 4.044753222465515 and perplexity is 57.09709401533226
At time: 292.19874930381775 and batch: 1750, loss is 4.0412828063964845 and perplexity is 56.899286778002974
At time: 293.11073756217957 and batch: 1800, loss is 4.0006868314743045 and perplexity is 54.63566264197134
At time: 293.9981083869934 and batch: 1850, loss is 4.044516787528992 and perplexity is 57.08359586331331
At time: 294.88594913482666 and batch: 1900, loss is 4.127225694656372 and perplexity is 62.00566145436803
At time: 295.7730152606964 and batch: 1950, loss is 4.047279634475708 and perplexity is 57.241527171406304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381698537427326 and perplexity of 79.97375652571678
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 298.76030135154724 and batch: 50, loss is 4.0701781845092775 and perplexity is 58.56739746517536
At time: 299.6717646121979 and batch: 100, loss is 4.057823104858398 and perplexity is 57.84824434964359
At time: 300.55889868736267 and batch: 150, loss is 4.026812000274658 and perplexity is 56.08183707339883
At time: 301.44589829444885 and batch: 200, loss is 4.018023614883423 and perplexity is 55.591127705622334
At time: 302.3330125808716 and batch: 250, loss is 4.000955233573913 and perplexity is 54.650328936682065
At time: 303.218133687973 and batch: 300, loss is 4.028745727539063 and perplexity is 56.19038897184267
At time: 304.1237552165985 and batch: 350, loss is 4.027645368576049 and perplexity is 56.128593378604876
At time: 305.0150520801544 and batch: 400, loss is 3.9817372131347657 and perplexity is 53.61008552385029
At time: 305.92069149017334 and batch: 450, loss is 4.018360047340393 and perplexity is 55.60983351174582
At time: 306.8086881637573 and batch: 500, loss is 4.029735188484192 and perplexity is 56.24601468241776
At time: 307.6968996524811 and batch: 550, loss is 3.991341247558594 and perplexity is 54.12743899434689
At time: 308.6064569950104 and batch: 600, loss is 3.9707131576538086 and perplexity is 53.02233064038447
At time: 309.49773240089417 and batch: 650, loss is 4.007323989868164 and perplexity is 54.99949425728836
At time: 310.38467359542847 and batch: 700, loss is 4.034691376686096 and perplexity is 56.52547246743415
At time: 311.28540992736816 and batch: 750, loss is 3.9973533391952514 and perplexity is 54.4538383057757
At time: 312.1983561515808 and batch: 800, loss is 3.9665729141235353 and perplexity is 52.80325909669792
At time: 313.0926585197449 and batch: 850, loss is 3.961195764541626 and perplexity is 52.520090077498494
At time: 313.97955536842346 and batch: 900, loss is 3.933369174003601 and perplexity is 51.078781390765876
At time: 314.89064860343933 and batch: 950, loss is 4.035557551383972 and perplexity is 56.5744546119556
At time: 315.77765798568726 and batch: 1000, loss is 3.985249152183533 and perplexity is 53.79869186975338
At time: 316.6656024456024 and batch: 1050, loss is 3.931831340789795 and perplexity is 51.00029111216977
At time: 317.5519573688507 and batch: 1100, loss is 3.9551880502700807 and perplexity is 52.205510281728486
At time: 318.44502663612366 and batch: 1150, loss is 3.922962884902954 and perplexity is 50.549996938513836
At time: 319.3446695804596 and batch: 1200, loss is 3.9859510850906372 and perplexity is 53.83646819860902
At time: 320.2318344116211 and batch: 1250, loss is 3.967662353515625 and perplexity is 52.860816394089326
At time: 321.1189396381378 and batch: 1300, loss is 3.9738020849227906 and perplexity is 53.186365979552455
At time: 322.0069930553436 and batch: 1350, loss is 3.8454418563842774 and perplexity is 46.77934953929954
At time: 322.90915989875793 and batch: 1400, loss is 3.869604058265686 and perplexity is 47.92340744679183
At time: 323.8177604675293 and batch: 1450, loss is 3.7843804216384886 and perplexity is 44.00839546053993
At time: 324.7384943962097 and batch: 1500, loss is 3.79698646068573 and perplexity is 44.56667848779573
At time: 325.6277675628662 and batch: 1550, loss is 3.795035176277161 and perplexity is 44.479801011818516
At time: 326.5156989097595 and batch: 1600, loss is 3.8832425928115843 and perplexity is 48.581489934408026
At time: 327.40590238571167 and batch: 1650, loss is 3.8309834814071655 and perplexity is 46.10786216810457
At time: 328.292916059494 and batch: 1700, loss is 3.8487987422943117 and perplexity is 46.93664634465275
At time: 329.1817831993103 and batch: 1750, loss is 3.8369449520111085 and perplexity is 46.38355378026498
At time: 330.0719726085663 and batch: 1800, loss is 3.7966344451904295 and perplexity is 44.55099308730793
At time: 330.9609045982361 and batch: 1850, loss is 3.820422501564026 and perplexity is 45.62348024111201
At time: 331.8484237194061 and batch: 1900, loss is 3.896391453742981 and perplexity is 49.22449934579182
At time: 332.73363041877747 and batch: 1950, loss is 3.819103512763977 and perplexity is 45.563343050513716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31002083711846 and perplexity of 74.4420400817923
finished 9 epochs...
Completing Train Step...
At time: 335.6407332420349 and batch: 50, loss is 3.983416028022766 and perplexity is 53.70016252372269
At time: 336.56999254226685 and batch: 100, loss is 3.96257137298584 and perplexity is 52.592386871539574
At time: 337.4800238609314 and batch: 150, loss is 3.926811680793762 and perplexity is 50.74492844416975
At time: 338.3666195869446 and batch: 200, loss is 3.9195737266540527 and perplexity is 50.378964990288466
At time: 339.26420617103577 and batch: 250, loss is 3.901037278175354 and perplexity is 49.45371977417214
At time: 340.16041445732117 and batch: 300, loss is 3.9343932914733886 and perplexity is 51.13111885840671
At time: 341.0471611022949 and batch: 350, loss is 3.935578064918518 and perplexity is 51.191733550498355
At time: 341.93362736701965 and batch: 400, loss is 3.8912109375 and perplexity is 48.970150425580385
At time: 342.8203179836273 and batch: 450, loss is 3.938189687728882 and perplexity is 51.32560178011375
At time: 343.7071497440338 and batch: 500, loss is 3.952389512062073 and perplexity is 52.059615407944314
At time: 344.5945110321045 and batch: 550, loss is 3.9167514038085938 and perplexity is 50.23697974481549
At time: 345.48120617866516 and batch: 600, loss is 3.9007727193832396 and perplexity is 49.44063808831693
At time: 346.3680555820465 and batch: 650, loss is 3.937869625091553 and perplexity is 51.30917700126474
At time: 347.267365694046 and batch: 700, loss is 3.965855588912964 and perplexity is 52.76539556960238
At time: 348.1647689342499 and batch: 750, loss is 3.9313944816589355 and perplexity is 50.978016035210565
At time: 349.07589387893677 and batch: 800, loss is 3.902425708770752 and perplexity is 49.52243052077622
At time: 349.96325421333313 and batch: 850, loss is 3.900262703895569 and perplexity is 49.41542902622407
At time: 350.8476617336273 and batch: 900, loss is 3.871103458404541 and perplexity is 47.99531770822757
At time: 351.73280453681946 and batch: 950, loss is 3.976499037742615 and perplexity is 53.330000700228446
At time: 352.620032787323 and batch: 1000, loss is 3.9288691663742066 and perplexity is 50.849442884331495
At time: 353.5066587924957 and batch: 1050, loss is 3.8795118808746336 and perplexity is 48.400584053683026
At time: 354.3933696746826 and batch: 1100, loss is 3.904464406967163 and perplexity is 49.62349479533358
At time: 355.2821755409241 and batch: 1150, loss is 3.8749645376205444 and perplexity is 48.18098964826527
At time: 356.16895627975464 and batch: 1200, loss is 3.9382863283157348 and perplexity is 51.33056215607332
At time: 357.0556318759918 and batch: 1250, loss is 3.924650692939758 and perplexity is 50.63538767091828
At time: 357.9505639076233 and batch: 1300, loss is 3.932581248283386 and perplexity is 51.03855095652913
At time: 358.8373382091522 and batch: 1350, loss is 3.8063388204574586 and perplexity is 44.985437237808
At time: 359.72339940071106 and batch: 1400, loss is 3.8344049310684203 and perplexity is 46.2658880821975
At time: 360.6091990470886 and batch: 1450, loss is 3.752032604217529 and perplexity is 42.60759842771114
At time: 361.4964234828949 and batch: 1500, loss is 3.766468243598938 and perplexity is 43.22712724232129
At time: 362.38279151916504 and batch: 1550, loss is 3.7675700426101684 and perplexity is 43.27478109603883
At time: 363.2912108898163 and batch: 1600, loss is 3.8593481826782225 and perplexity is 47.43442271165935
At time: 364.17959451675415 and batch: 1650, loss is 3.808732466697693 and perplexity is 45.093245436387875
At time: 365.06848883628845 and batch: 1700, loss is 3.831327738761902 and perplexity is 46.12373787127411
At time: 365.9581882953644 and batch: 1750, loss is 3.822179608345032 and perplexity is 45.70371603840501
At time: 366.8596270084381 and batch: 1800, loss is 3.7858715724945067 and perplexity is 44.07406756844419
At time: 367.7590205669403 and batch: 1850, loss is 3.8121235704422 and perplexity is 45.24642087996151
At time: 368.65105533599854 and batch: 1900, loss is 3.8906623220443723 and perplexity is 48.943292012336464
At time: 369.53973746299744 and batch: 1950, loss is 3.81486581325531 and perplexity is 45.37066783223417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308704181050145 and perplexity of 74.34409001540592
finished 10 epochs...
Completing Train Step...
At time: 372.54544496536255 and batch: 50, loss is 3.9414892959594727 and perplexity is 51.495235867296216
At time: 373.4321279525757 and batch: 100, loss is 3.91910758972168 and perplexity is 50.35548696650388
At time: 374.3199245929718 and batch: 150, loss is 3.884433751106262 and perplexity is 48.63939265791958
At time: 375.2066605091095 and batch: 200, loss is 3.8766137647628782 and perplexity is 48.26051660511981
At time: 376.09371423721313 and batch: 250, loss is 3.8569815301895143 and perplexity is 47.32229465350848
At time: 376.98128938674927 and batch: 300, loss is 3.891454577445984 and perplexity is 48.98208296394738
At time: 377.8689091205597 and batch: 350, loss is 3.893405752182007 and perplexity is 49.07774886684016
At time: 378.75630164146423 and batch: 400, loss is 3.849940848350525 and perplexity is 46.99028359658606
At time: 379.64376425743103 and batch: 450, loss is 3.898801875114441 and perplexity is 49.34329424638012
At time: 380.5303330421448 and batch: 500, loss is 3.9144716453552246 and perplexity is 50.12258201471323
At time: 381.4421536922455 and batch: 550, loss is 3.879881224632263 and perplexity is 48.418463808953625
At time: 382.33001351356506 and batch: 600, loss is 3.865340814590454 and perplexity is 47.71953317473784
At time: 383.2168881893158 and batch: 650, loss is 3.902623915672302 and perplexity is 49.53224718111975
At time: 384.1043827533722 and batch: 700, loss is 3.9298413944244386 and perplexity is 50.89890417897532
At time: 384.9912781715393 and batch: 750, loss is 3.8969332456588743 and perplexity is 49.251176007548565
At time: 385.8779842853546 and batch: 800, loss is 3.867800221443176 and perplexity is 47.83703936016554
At time: 386.76561164855957 and batch: 850, loss is 3.8674110555648804 and perplexity is 47.81842643871975
At time: 387.6536066532135 and batch: 900, loss is 3.8380410432815553 and perplexity is 46.43442226181226
At time: 388.54108142852783 and batch: 950, loss is 3.9454270887374876 and perplexity is 51.69841320778614
At time: 389.42833971977234 and batch: 1000, loss is 3.89803626537323 and perplexity is 49.30553099744187
At time: 390.3161323070526 and batch: 1050, loss is 3.8507911729812623 and perplexity is 47.030257585158495
At time: 391.20416378974915 and batch: 1100, loss is 3.8757523918151855 and perplexity is 48.218964200302395
At time: 392.09229159355164 and batch: 1150, loss is 3.8472965717315675 and perplexity is 46.86619242634929
At time: 392.97967648506165 and batch: 1200, loss is 3.9102974414825438 and perplexity is 49.91379619919503
At time: 393.86809253692627 and batch: 1250, loss is 3.8980387353897097 and perplexity is 49.305652783066385
At time: 394.754962682724 and batch: 1300, loss is 3.9072385835647583 and perplexity is 49.76135026257929
At time: 395.64293789863586 and batch: 1350, loss is 3.7813991641998292 and perplexity is 43.87739048102444
At time: 396.5305106639862 and batch: 1400, loss is 3.8120079135894773 and perplexity is 45.241188123933455
At time: 397.41812920570374 and batch: 1450, loss is 3.7304296398162844 and perplexity is 41.69701901573579
At time: 398.30464911460876 and batch: 1500, loss is 3.745398874282837 and perplexity is 42.325886559893505
At time: 399.21258902549744 and batch: 1550, loss is 3.746956114768982 and perplexity is 42.39184949079984
At time: 400.1003005504608 and batch: 1600, loss is 3.840786547660828 and perplexity is 46.562083338313116
At time: 400.9886908531189 and batch: 1650, loss is 3.791308741569519 and perplexity is 44.31435838456224
At time: 401.8762927055359 and batch: 1700, loss is 3.815345368385315 and perplexity is 45.392430786595995
At time: 402.76547408103943 and batch: 1750, loss is 3.8069357442855836 and perplexity is 45.012298133370585
At time: 403.6516845226288 and batch: 1800, loss is 3.772335376739502 and perplexity is 43.48149201947152
At time: 404.537433385849 and batch: 1850, loss is 3.798858413696289 and perplexity is 44.650183349965765
At time: 405.42330265045166 and batch: 1900, loss is 3.8789833545684815 and perplexity is 48.375009830697664
At time: 406.3086373806 and batch: 1950, loss is 3.8027544689178465 and perplexity is 44.82448224853975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.309935104015262 and perplexity of 74.4356582082605
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 409.25903725624084 and batch: 50, loss is 3.931353883743286 and perplexity is 50.97594647602578
At time: 410.167640209198 and batch: 100, loss is 3.9370699739456176 and perplexity is 51.26816395932713
At time: 411.0537326335907 and batch: 150, loss is 3.917716145515442 and perplexity is 50.28546884036697
At time: 411.93967938423157 and batch: 200, loss is 3.911858501434326 and perplexity is 49.99177547681101
At time: 412.8259930610657 and batch: 250, loss is 3.894617772102356 and perplexity is 49.13726813809775
At time: 413.7116379737854 and batch: 300, loss is 3.9167920684814455 and perplexity is 50.239022656698765
At time: 414.59694719314575 and batch: 350, loss is 3.918179965019226 and perplexity is 50.30879763132796
At time: 415.48280096054077 and batch: 400, loss is 3.8737244319915773 and perplexity is 48.12127716433943
At time: 416.36840891838074 and batch: 450, loss is 3.9184128570556642 and perplexity is 50.3205155141069
At time: 417.2538321018219 and batch: 500, loss is 3.930718560218811 and perplexity is 50.94357054373189
At time: 418.14519572257996 and batch: 550, loss is 3.8939855432510377 and perplexity is 49.10621195784693
At time: 419.05212020874023 and batch: 600, loss is 3.875091800689697 and perplexity is 48.187121699066246
At time: 419.9379868507385 and batch: 650, loss is 3.9041096353530884 and perplexity is 49.60589291049818
At time: 420.82404136657715 and batch: 700, loss is 3.9291203594207764 and perplexity is 50.862217515188036
At time: 421.70900774002075 and batch: 750, loss is 3.891825680732727 and perplexity is 49.00026374919275
At time: 422.59388256073 and batch: 800, loss is 3.8577154445648194 and perplexity is 47.357037913556624
At time: 423.47970056533813 and batch: 850, loss is 3.855816879272461 and perplexity is 47.26721278144575
At time: 424.36686968803406 and batch: 900, loss is 3.825352644920349 and perplexity is 45.84896592075083
At time: 425.29636788368225 and batch: 950, loss is 3.9401282262802124 and perplexity is 51.425194939235254
At time: 426.203640460968 and batch: 1000, loss is 3.888288812637329 and perplexity is 48.82726240149146
At time: 427.09963726997375 and batch: 1050, loss is 3.837821669578552 and perplexity is 46.42423688789631
At time: 427.9863269329071 and batch: 1100, loss is 3.8567124032974243 and perplexity is 47.30956066502804
At time: 428.8731253147125 and batch: 1150, loss is 3.832577848434448 and perplexity is 46.18143365763749
At time: 429.75908875465393 and batch: 1200, loss is 3.884507761001587 and perplexity is 48.642992587492415
At time: 430.6455137729645 and batch: 1250, loss is 3.8696184015274047 and perplexity is 47.92409482969694
At time: 431.5329942703247 and batch: 1300, loss is 3.8809859132766724 and perplexity is 48.47198069040634
At time: 432.42074155807495 and batch: 1350, loss is 3.7499570417404176 and perplexity is 42.519255407618395
At time: 433.315744638443 and batch: 1400, loss is 3.7801497173309326 and perplexity is 43.82260224749356
At time: 434.20443534851074 and batch: 1450, loss is 3.688356428146362 and perplexity is 39.97908443146657
At time: 435.0929093360901 and batch: 1500, loss is 3.704059987068176 and perplexity is 40.61185370078057
At time: 435.9806237220764 and batch: 1550, loss is 3.704147319793701 and perplexity is 40.6154005995308
At time: 436.8675420284271 and batch: 1600, loss is 3.7923748111724853 and perplexity is 44.36162576569346
At time: 437.7552058696747 and batch: 1650, loss is 3.74100106716156 and perplexity is 42.14015418150375
At time: 438.6420204639435 and batch: 1700, loss is 3.760008902549744 and perplexity is 42.94880833096367
At time: 439.52890276908875 and batch: 1750, loss is 3.75283793926239 and perplexity is 42.64192564050077
At time: 440.4162714481354 and batch: 1800, loss is 3.719157576560974 and perplexity is 41.2296466539066
At time: 441.30289340019226 and batch: 1850, loss is 3.7408050155639647 and perplexity is 42.131893346754936
At time: 442.19035172462463 and batch: 1900, loss is 3.8199941682815552 and perplexity is 45.60394237072139
At time: 443.09074568748474 and batch: 1950, loss is 3.7482825756072997 and perplexity is 42.44811792970322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284191610646802 and perplexity of 72.54387931022063
finished 12 epochs...
Completing Train Step...
At time: 446.0595614910126 and batch: 50, loss is 3.915206484794617 and perplexity is 50.159427600918754
At time: 446.9440221786499 and batch: 100, loss is 3.906488971710205 and perplexity is 49.72406254192865
At time: 447.8562035560608 and batch: 150, loss is 3.8813455152511596 and perplexity is 48.489414444788295
At time: 448.74520778656006 and batch: 200, loss is 3.876334447860718 and perplexity is 48.24703850954259
At time: 449.6515951156616 and batch: 250, loss is 3.855206069946289 and perplexity is 47.23835034267743
At time: 450.55164647102356 and batch: 300, loss is 3.8771752071380616 and perplexity is 48.28761971189454
At time: 451.449658870697 and batch: 350, loss is 3.8802015924453737 and perplexity is 48.43397801131112
At time: 452.33711338043213 and batch: 400, loss is 3.836013741493225 and perplexity is 46.34038103170653
At time: 453.24561190605164 and batch: 450, loss is 3.8841887664794923 and perplexity is 48.62747821395037
At time: 454.13681292533875 and batch: 500, loss is 3.897650065422058 and perplexity is 49.28649288027474
At time: 455.02519488334656 and batch: 550, loss is 3.8638913345336916 and perplexity is 47.6504147680605
At time: 455.91254687309265 and batch: 600, loss is 3.8468081903457643 and perplexity is 46.84330943861226
At time: 456.79895639419556 and batch: 650, loss is 3.87730263710022 and perplexity is 48.293773393520524
At time: 457.6868932247162 and batch: 700, loss is 3.903886399269104 and perplexity is 49.59482032116901
At time: 458.57426500320435 and batch: 750, loss is 3.86815954208374 and perplexity is 47.854231284312746
At time: 459.4605543613434 and batch: 800, loss is 3.8352344608306885 and perplexity is 46.30428293597473
At time: 460.3635401725769 and batch: 850, loss is 3.8346557903289793 and perplexity is 46.277495764557344
At time: 461.2617654800415 and batch: 900, loss is 3.804041404724121 and perplexity is 44.882205614909836
At time: 462.18199825286865 and batch: 950, loss is 3.919499979019165 and perplexity is 50.37524979776735
At time: 463.06911444664 and batch: 1000, loss is 3.8692174530029297 and perplexity is 47.90488358620541
At time: 463.9545428752899 and batch: 1050, loss is 3.8205989694595335 and perplexity is 45.631532031076205
At time: 464.84182047843933 and batch: 1100, loss is 3.8403340768814087 and perplexity is 46.54102012177801
At time: 465.72800040245056 and batch: 1150, loss is 3.8171526622772216 and perplexity is 45.474542427078376
At time: 466.61546897888184 and batch: 1200, loss is 3.8708465671539307 and perplexity is 47.9829897145827
At time: 467.50202465057373 and batch: 1250, loss is 3.857453966140747 and perplexity is 47.344656688696375
At time: 468.4015862941742 and batch: 1300, loss is 3.8696246194839476 and perplexity is 47.924392820562396
At time: 469.29807353019714 and batch: 1350, loss is 3.7398808813095092 and perplexity is 42.09297580619401
At time: 470.1878237724304 and batch: 1400, loss is 3.7722281122207644 and perplexity is 43.47682824828912
At time: 471.1046862602234 and batch: 1450, loss is 3.681313729286194 and perplexity is 39.698512929095884
At time: 471.9990813732147 and batch: 1500, loss is 3.6987513065338136 and perplexity is 40.39682959570086
At time: 472.88659739494324 and batch: 1550, loss is 3.7006360626220705 and perplexity is 40.47303956226678
At time: 473.7746021747589 and batch: 1600, loss is 3.7904123401641847 and perplexity is 44.27465273019076
At time: 474.66290497779846 and batch: 1650, loss is 3.740577883720398 and perplexity is 42.12232493883232
At time: 475.55042552948 and batch: 1700, loss is 3.7612443733215333 and perplexity is 43.001903120116225
At time: 476.44151616096497 and batch: 1750, loss is 3.755422577857971 and perplexity is 42.75228216172806
At time: 477.3396506309509 and batch: 1800, loss is 3.722508821487427 and perplexity is 41.36804907875569
At time: 478.2504212856293 and batch: 1850, loss is 3.744468340873718 and perplexity is 42.2865192275286
At time: 479.14163398742676 and batch: 1900, loss is 3.824383931159973 and perplexity is 45.80457290209996
At time: 480.0294089317322 and batch: 1950, loss is 3.75257200717926 and perplexity is 42.630587292068654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.282989360010901 and perplexity of 72.45671579188571
finished 13 epochs...
Completing Train Step...
At time: 483.01229882240295 and batch: 50, loss is 3.9019615030288697 and perplexity is 49.49944725907025
At time: 483.9295291900635 and batch: 100, loss is 3.8915830421447755 and perplexity is 48.98837583667887
At time: 484.84302616119385 and batch: 150, loss is 3.866091480255127 and perplexity is 47.75536803814439
At time: 485.74191999435425 and batch: 200, loss is 3.8612736654281616 and perplexity is 47.52584486198516
At time: 486.62855672836304 and batch: 250, loss is 3.8392624378204347 and perplexity is 46.491171661227206
At time: 487.52722549438477 and batch: 300, loss is 3.8608272790908815 and perplexity is 47.504634708484645
At time: 488.4134066104889 and batch: 350, loss is 3.8642577600479124 and perplexity is 47.66787829514027
At time: 489.29950642585754 and batch: 400, loss is 3.8197250032424925 and perplexity is 45.59166903564222
At time: 490.18663454055786 and batch: 450, loss is 3.8689548206329345 and perplexity is 47.89230386508811
At time: 491.0729203224182 and batch: 500, loss is 3.8826560592651367 and perplexity is 48.5530036157325
At time: 491.9596755504608 and batch: 550, loss is 3.849747633934021 and perplexity is 46.98120527341929
At time: 492.8871080875397 and batch: 600, loss is 3.833584499359131 and perplexity is 46.22794564727309
At time: 493.77225136756897 and batch: 650, loss is 3.8641246271133425 and perplexity is 47.66153255304112
At time: 494.6566553115845 and batch: 700, loss is 3.8911869955062866 and perplexity is 48.968977996581955
At time: 495.5417275428772 and batch: 750, loss is 3.855752205848694 and perplexity is 47.26415594781226
At time: 496.42838644981384 and batch: 800, loss is 3.8233193445205687 and perplexity is 45.755835912741595
At time: 497.3146159648895 and batch: 850, loss is 3.8232529878616335 and perplexity is 45.7527998090776
At time: 498.20063638687134 and batch: 900, loss is 3.793013415336609 and perplexity is 44.389964332234946
At time: 499.0866241455078 and batch: 950, loss is 3.908750867843628 and perplexity is 49.836660501168744
At time: 499.97286200523376 and batch: 1000, loss is 3.8591080951690673 and perplexity is 47.42303566626067
At time: 500.8592972755432 and batch: 1050, loss is 3.8112295484542846 and perplexity is 45.20598766160659
At time: 501.74558186531067 and batch: 1100, loss is 3.831449580192566 and perplexity is 46.12935799585899
At time: 502.6317687034607 and batch: 1150, loss is 3.808670048713684 and perplexity is 45.09043089475524
At time: 503.5188899040222 and batch: 1200, loss is 3.862777380943298 and perplexity is 47.59736397099468
At time: 504.4076268672943 and batch: 1250, loss is 3.8499190330505373 and perplexity is 46.98925850063432
At time: 505.29586577415466 and batch: 1300, loss is 3.862532629966736 and perplexity is 47.585715895178105
At time: 506.1846179962158 and batch: 1350, loss is 3.7333528327941896 and perplexity is 41.819085774345695
At time: 507.07287073135376 and batch: 1400, loss is 3.7666077613830566 and perplexity is 43.233158616060116
At time: 507.9613296985626 and batch: 1450, loss is 3.6758333921432493 and perplexity is 39.481546761077176
At time: 508.8493995666504 and batch: 1500, loss is 3.6939540815353396 and perplexity is 40.20350100603858
At time: 509.7376341819763 and batch: 1550, loss is 3.6965461111068727 and perplexity is 40.30784484225942
At time: 510.63897824287415 and batch: 1600, loss is 3.7870801162719725 and perplexity is 44.12736520833005
At time: 511.52693819999695 and batch: 1650, loss is 3.7378787183761597 and perplexity is 42.00878312214106
At time: 512.4145038127899 and batch: 1700, loss is 3.759260549545288 and perplexity is 42.9166794845702
At time: 513.3020067214966 and batch: 1750, loss is 3.754039602279663 and perplexity is 42.69319766520652
At time: 514.1898558139801 and batch: 1800, loss is 3.7213966703414916 and perplexity is 41.3220671297458
At time: 515.0907261371613 and batch: 1850, loss is 3.7433774185180666 and perplexity is 42.2404130720511
At time: 515.9994928836823 and batch: 1900, loss is 3.823889765739441 and perplexity is 45.78194345787442
At time: 516.8863203525543 and batch: 1950, loss is 3.751903009414673 and perplexity is 42.60207706217059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.28295160337936 and perplexity of 72.45398012201011
finished 14 epochs...
Completing Train Step...
At time: 519.8875122070312 and batch: 50, loss is 3.890616955757141 and perplexity is 48.94107168725732
At time: 520.8210880756378 and batch: 100, loss is 3.879403371810913 and perplexity is 48.39533243655302
At time: 521.7085394859314 and batch: 150, loss is 3.8541108655929563 and perplexity is 47.186643015951
At time: 522.6015043258667 and batch: 200, loss is 3.8496552896499634 and perplexity is 46.976867027963316
At time: 523.5076403617859 and batch: 250, loss is 3.827161431312561 and perplexity is 45.93197195386589
At time: 524.3951711654663 and batch: 300, loss is 3.8483682107925414 and perplexity is 46.91644298921648
At time: 525.2841718196869 and batch: 350, loss is 3.8522254467010497 and perplexity is 47.09776024472116
At time: 526.1717839241028 and batch: 400, loss is 3.8074916219711303 and perplexity is 45.03732642116697
At time: 527.0594444274902 and batch: 450, loss is 3.8575655460357665 and perplexity is 47.349939695252615
At time: 527.9486289024353 and batch: 500, loss is 3.8714212465286253 and perplexity is 48.0105724739702
At time: 528.8544776439667 and batch: 550, loss is 3.8390414714813232 and perplexity is 46.480899812132456
At time: 529.7614645957947 and batch: 600, loss is 3.8235755729675294 and perplexity is 45.767561361649534
At time: 530.6580934524536 and batch: 650, loss is 3.8540519666671753 and perplexity is 47.18386385521174
At time: 531.5441172122955 and batch: 700, loss is 3.881427068710327 and perplexity is 48.49336908552441
At time: 532.4477458000183 and batch: 750, loss is 3.846128716468811 and perplexity is 46.81149144451075
At time: 533.342405796051 and batch: 800, loss is 3.8139594841003417 and perplexity is 45.32956570204045
At time: 534.2311329841614 and batch: 850, loss is 3.814317741394043 and perplexity is 45.34580825890703
At time: 535.1209387779236 and batch: 900, loss is 3.784362564086914 and perplexity is 44.007609585365195
At time: 536.0069577693939 and batch: 950, loss is 3.900319423675537 and perplexity is 49.41823193797497
At time: 536.8930208683014 and batch: 1000, loss is 3.8511124420166016 and perplexity is 47.04536937799021
At time: 537.8068482875824 and batch: 1050, loss is 3.803694095611572 and perplexity is 44.866620322522174
At time: 538.7242844104767 and batch: 1100, loss is 3.8244160842895507 and perplexity is 45.806045686144905
At time: 539.6215693950653 and batch: 1150, loss is 3.8017078399658204 and perplexity is 44.77759219018557
At time: 540.5096473693848 and batch: 1200, loss is 3.8559102821350097 and perplexity is 47.27162788061248
At time: 541.3953430652618 and batch: 1250, loss is 3.843373737335205 and perplexity is 46.68270424684619
At time: 542.2775614261627 and batch: 1300, loss is 3.8563156127929688 and perplexity is 47.29079240436625
At time: 543.1636686325073 and batch: 1350, loss is 3.7274939393997193 and perplexity is 41.57478856342191
At time: 544.0505967140198 and batch: 1400, loss is 3.7613096714019774 and perplexity is 43.00471115352401
At time: 544.9374141693115 and batch: 1450, loss is 3.670531949996948 and perplexity is 39.27279146606356
At time: 545.8502354621887 and batch: 1500, loss is 3.689058804512024 and perplexity is 40.00717465929327
At time: 546.7375800609589 and batch: 1550, loss is 3.692053699493408 and perplexity is 40.12717154524389
At time: 547.6259694099426 and batch: 1600, loss is 3.783106551170349 and perplexity is 43.95237015727842
At time: 548.5136692523956 and batch: 1650, loss is 3.734254450798035 and perplexity is 41.856807617775395
At time: 549.4006507396698 and batch: 1700, loss is 3.7561311435699465 and perplexity is 42.782585697731975
At time: 550.2884659767151 and batch: 1750, loss is 3.75131374835968 and perplexity is 42.57698071217307
At time: 551.1766226291656 and batch: 1800, loss is 3.718809585571289 and perplexity is 41.21530160448188
At time: 552.0641062259674 and batch: 1850, loss is 3.7408129215240478 and perplexity is 42.13222644113867
At time: 552.9517617225647 and batch: 1900, loss is 3.8218523836135865 and perplexity is 45.68876309881753
At time: 553.8395977020264 and batch: 1950, loss is 3.7497322177886963 and perplexity is 42.509697135097966
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283321504814681 and perplexity of 72.4807859106961
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 556.8200483322144 and batch: 50, loss is 3.8892640686035156 and perplexity is 48.87490470840695
At time: 557.7354109287262 and batch: 100, loss is 3.891361212730408 and perplexity is 48.977509979184155
At time: 558.6217279434204 and batch: 150, loss is 3.8754725885391235 and perplexity is 48.2054742635031
At time: 559.5319166183472 and batch: 200, loss is 3.883273711204529 and perplexity is 48.583001735823935
At time: 560.4177393913269 and batch: 250, loss is 3.868319115638733 and perplexity is 47.861868163426
At time: 561.3033542633057 and batch: 300, loss is 3.884289708137512 and perplexity is 48.63238699997294
At time: 562.1903085708618 and batch: 350, loss is 3.8874538564682006 and perplexity is 48.78651079279872
At time: 563.0775763988495 and batch: 400, loss is 3.84707528591156 and perplexity is 46.855822749901094
At time: 563.9652240276337 and batch: 450, loss is 3.8964065980911253 and perplexity is 49.22524482439203
At time: 564.8525528907776 and batch: 500, loss is 3.9073737907409667 and perplexity is 49.768078809096245
At time: 565.7449848651886 and batch: 550, loss is 3.87620343208313 and perplexity is 48.24071780034131
At time: 566.6486637592316 and batch: 600, loss is 3.8539600229263304 and perplexity is 47.17952579369324
At time: 567.5364875793457 and batch: 650, loss is 3.8733375120162963 and perplexity is 48.102661682551634
At time: 568.4251062870026 and batch: 700, loss is 3.89638240814209 and perplexity is 49.22405408263052
At time: 569.3123917579651 and batch: 750, loss is 3.8546540927886963 and perplexity is 47.21228304726357
At time: 570.2216668128967 and batch: 800, loss is 3.820134525299072 and perplexity is 45.61034365328151
At time: 571.1088936328888 and batch: 850, loss is 3.8176387262344362 and perplexity is 45.49665133585957
At time: 572.0065996646881 and batch: 900, loss is 3.7820180082321166 and perplexity is 43.904552145826216
At time: 572.905590057373 and batch: 950, loss is 3.901200489997864 and perplexity is 49.46179186461876
At time: 573.7933313846588 and batch: 1000, loss is 3.8538435888290405 and perplexity is 47.1740328079885
At time: 574.6999940872192 and batch: 1050, loss is 3.8066144704818727 and perplexity is 44.99783918390072
At time: 575.5884253978729 and batch: 1100, loss is 3.8241225242614747 and perplexity is 45.79260083561913
At time: 576.4763586521149 and batch: 1150, loss is 3.803682007789612 and perplexity is 44.8660779860816
At time: 577.3644125461578 and batch: 1200, loss is 3.8535658311843872 and perplexity is 47.16093167930051
At time: 578.2552351951599 and batch: 1250, loss is 3.8404101943969726 and perplexity is 46.544562843431365
At time: 579.144045829773 and batch: 1300, loss is 3.8515783071517946 and perplexity is 47.06729128128444
At time: 580.0328185558319 and batch: 1350, loss is 3.724514517784119 and perplexity is 41.45110408531093
At time: 580.9216570854187 and batch: 1400, loss is 3.7579134798049925 and perplexity is 42.85890664504074
At time: 581.8149456977844 and batch: 1450, loss is 3.665384135246277 and perplexity is 39.07114188351152
At time: 582.7041883468628 and batch: 1500, loss is 3.680926604270935 and perplexity is 39.683147616012874
At time: 583.6148245334625 and batch: 1550, loss is 3.683479905128479 and perplexity is 39.78460009508482
At time: 584.5049443244934 and batch: 1600, loss is 3.7712705993652342 and perplexity is 43.43521855041311
At time: 585.3947334289551 and batch: 1650, loss is 3.7185666131973267 and perplexity is 41.20528864129344
At time: 586.2847635746002 and batch: 1700, loss is 3.7390367555618287 and perplexity is 42.05745903393942
At time: 587.1907432079315 and batch: 1750, loss is 3.734170618057251 and perplexity is 41.853298793951545
At time: 588.086701631546 and batch: 1800, loss is 3.7045341396331786 and perplexity is 40.6311144812957
At time: 588.9988114833832 and batch: 1850, loss is 3.725772180557251 and perplexity is 41.503268391501486
At time: 589.9062547683716 and batch: 1900, loss is 3.8096127843856813 and perplexity is 45.132959295796056
At time: 590.790666103363 and batch: 1950, loss is 3.7438635492324828 and perplexity is 42.26095242623602
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2696805732194765 and perplexity of 71.4987933418274
finished 16 epochs...
Completing Train Step...
At time: 593.7518172264099 and batch: 50, loss is 3.8897899198532104 and perplexity is 48.90061239674421
At time: 594.6396064758301 and batch: 100, loss is 3.8793650913238524 and perplexity is 48.393479875114586
At time: 595.5284876823425 and batch: 150, loss is 3.8573278093338015 and perplexity is 47.338684214724644
At time: 596.4149127006531 and batch: 200, loss is 3.861755704879761 and perplexity is 47.548759716667504
At time: 597.3023996353149 and batch: 250, loss is 3.8454675769805906 and perplexity is 46.78055274753839
At time: 598.1926467418671 and batch: 300, loss is 3.862270531654358 and perplexity is 47.57324539366877
At time: 599.0808527469635 and batch: 350, loss is 3.8659170198440553 and perplexity is 47.74703734371489
At time: 599.9691894054413 and batch: 400, loss is 3.824328804016113 and perplexity is 45.802047896418955
At time: 600.8581147193909 and batch: 450, loss is 3.8745505809783936 and perplexity is 48.161048935155044
At time: 601.7461628913879 and batch: 500, loss is 3.886678891181946 and perplexity is 48.748717586599696
At time: 602.6343722343445 and batch: 550, loss is 3.856962218284607 and perplexity is 47.321380778678495
At time: 603.5238721370697 and batch: 600, loss is 3.837455163002014 and perplexity is 46.40722521740112
At time: 604.453901052475 and batch: 650, loss is 3.8603441858291627 and perplexity is 47.48169108195846
At time: 605.362636089325 and batch: 700, loss is 3.8857425832748413 and perplexity is 48.70309513852459
At time: 606.2529966831207 and batch: 750, loss is 3.846325259208679 and perplexity is 46.82069280749749
At time: 607.1618468761444 and batch: 800, loss is 3.8116034698486327 and perplexity is 45.22289430822735
At time: 608.0498049259186 and batch: 850, loss is 3.8094744539260863 and perplexity is 45.1267164645906
At time: 608.9648492336273 and batch: 900, loss is 3.7743814468383787 and perplexity is 43.57054927777463
At time: 609.865250825882 and batch: 950, loss is 3.8939947748184203 and perplexity is 49.10666528724399
At time: 610.7518203258514 and batch: 1000, loss is 3.8470009899139406 and perplexity is 46.85234167912203
At time: 611.6388652324677 and batch: 1050, loss is 3.801102352142334 and perplexity is 44.750488109772775
At time: 612.5259780883789 and batch: 1100, loss is 3.8192221117019653 and perplexity is 45.5687471350637
At time: 613.4351811408997 and batch: 1150, loss is 3.7988983297348025 and perplexity is 44.651965643974826
At time: 614.3230576515198 and batch: 1200, loss is 3.849273419380188 and perplexity is 46.958931383840735
At time: 615.2226231098175 and batch: 1250, loss is 3.836963562965393 and perplexity is 46.38441703049686
At time: 616.1238598823547 and batch: 1300, loss is 3.8485811710357667 and perplexity is 46.926435390281036
At time: 617.0122332572937 and batch: 1350, loss is 3.7213662481307983 and perplexity is 41.320810040235116
At time: 617.9333627223969 and batch: 1400, loss is 3.7560985708236694 and perplexity is 42.78119217411853
At time: 618.8376009464264 and batch: 1450, loss is 3.6643015050888064 and perplexity is 39.02886517617012
At time: 619.7312858104706 and batch: 1500, loss is 3.680997920036316 and perplexity is 39.68597775097326
At time: 620.6398873329163 and batch: 1550, loss is 3.6847402667999267 and perplexity is 39.834774692586414
At time: 621.5291936397552 and batch: 1600, loss is 3.7730354976654055 and perplexity is 43.511944981057766
At time: 622.4189782142639 and batch: 1650, loss is 3.7210031843185423 and perplexity is 41.30581067244499
At time: 623.3077335357666 and batch: 1700, loss is 3.7422001361846924 and perplexity is 42.19071344097604
At time: 624.1960361003876 and batch: 1750, loss is 3.7382205390930174 and perplexity is 42.023145048964416
At time: 625.0843777656555 and batch: 1800, loss is 3.7090276956558226 and perplexity is 40.8141034982694
At time: 625.9729506969452 and batch: 1850, loss is 3.7304262351989745 and perplexity is 41.69687705358474
At time: 626.8816959857941 and batch: 1900, loss is 3.8140476036071775 and perplexity is 45.333560297013484
At time: 627.7710127830505 and batch: 1950, loss is 3.748248677253723 and perplexity is 42.44667903278123
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2685373705486915 and perplexity of 71.4171024338501
finished 17 epochs...
Completing Train Step...
At time: 630.78502202034 and batch: 50, loss is 3.886692371368408 and perplexity is 48.749374732831775
At time: 631.6727817058563 and batch: 100, loss is 3.874338402748108 and perplexity is 48.15083129304223
At time: 632.5590217113495 and batch: 150, loss is 3.8514609575271606 and perplexity is 47.06176827638765
At time: 633.4447605609894 and batch: 200, loss is 3.8555290508270263 and perplexity is 47.25360989081418
At time: 634.3547930717468 and batch: 250, loss is 3.8387857913970946 and perplexity is 46.46901709090579
At time: 635.2426035404205 and batch: 300, loss is 3.8554973077774046 and perplexity is 47.252109940937224
At time: 636.1303567886353 and batch: 350, loss is 3.859408597946167 and perplexity is 47.43728856158694
At time: 637.018351316452 and batch: 400, loss is 3.817601828575134 and perplexity is 45.49497264688923
At time: 637.9024178981781 and batch: 450, loss is 3.8679573774337768 and perplexity is 47.84455782824427
At time: 638.7978110313416 and batch: 500, loss is 3.880437593460083 and perplexity is 48.44540982817533
At time: 639.6902313232422 and batch: 550, loss is 3.850881495475769 and perplexity is 47.03450566718668
At time: 640.5776224136353 and batch: 600, loss is 3.8317331790924074 and perplexity is 46.14244208626612
At time: 641.4651381969452 and batch: 650, loss is 3.8549827003479002 and perplexity is 47.22779990969969
At time: 642.3526148796082 and batch: 700, loss is 3.8808934450149537 and perplexity is 48.467498777830365
At time: 643.2410128116608 and batch: 750, loss is 3.842048783302307 and perplexity is 46.620892767314814
At time: 644.1374056339264 and batch: 800, loss is 3.8075603723526 and perplexity is 45.04042286097829
At time: 645.0358309745789 and batch: 850, loss is 3.805670504570007 and perplexity is 44.95538279944599
At time: 645.9228911399841 and batch: 900, loss is 3.7707152795791625 and perplexity is 43.41110481017793
At time: 646.8101105690002 and batch: 950, loss is 3.8906179428100587 and perplexity is 48.941119994708764
At time: 647.719587802887 and batch: 1000, loss is 3.84386754989624 and perplexity is 46.70576244533182
At time: 648.6315143108368 and batch: 1050, loss is 3.7982578706741332 and perplexity is 44.62337704389265
At time: 649.5191576480865 and batch: 1100, loss is 3.81658082485199 and perplexity is 45.44854581544942
At time: 650.4303324222565 and batch: 1150, loss is 3.7964392280578614 and perplexity is 44.54229681904226
At time: 651.3182060718536 and batch: 1200, loss is 3.8469638299942015 and perplexity is 46.850600682213496
At time: 652.2059404850006 and batch: 1250, loss is 3.8350544786453247 and perplexity is 46.29594973987613
At time: 653.0936534404755 and batch: 1300, loss is 3.8467713737487794 and perplexity is 46.841584859113986
At time: 653.9815652370453 and batch: 1350, loss is 3.719626774787903 and perplexity is 41.24899607001441
At time: 654.8697412014008 and batch: 1400, loss is 3.7548840713500975 and perplexity is 42.72926597729627
At time: 655.7569923400879 and batch: 1450, loss is 3.6633364963531494 and perplexity is 38.99122014714466
At time: 656.6450147628784 and batch: 1500, loss is 3.680438766479492 and perplexity is 39.66379339816565
At time: 657.5319530963898 and batch: 1550, loss is 3.6846640634536745 and perplexity is 39.83173926511397
At time: 658.4216601848602 and batch: 1600, loss is 3.7732250785827635 and perplexity is 43.52019479748248
At time: 659.3056857585907 and batch: 1650, loss is 3.721467685699463 and perplexity is 41.32500173533494
At time: 660.191782951355 and batch: 1700, loss is 3.742945213317871 and perplexity is 42.2221604905774
At time: 661.088222026825 and batch: 1750, loss is 3.7393837356567383 and perplexity is 42.072054667117335
At time: 661.9871914386749 and batch: 1800, loss is 3.7102986764907837 and perplexity is 40.866010420976295
At time: 662.8735973834991 and batch: 1850, loss is 3.7316859340667725 and perplexity is 41.74943565945783
At time: 663.7619075775146 and batch: 1900, loss is 3.8151941967010496 and perplexity is 45.3855692550288
At time: 664.662383556366 and batch: 1950, loss is 3.7492701959609986 and perplexity is 42.49006126358266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268166049691134 and perplexity of 71.39058869698647
finished 18 epochs...
Completing Train Step...
At time: 667.6543354988098 and batch: 50, loss is 3.883432035446167 and perplexity is 48.59069421166688
At time: 668.541002035141 and batch: 100, loss is 3.870288586616516 and perplexity is 47.95622360837262
At time: 669.426666021347 and batch: 150, loss is 3.847096076011658 and perplexity is 46.85679689727251
At time: 670.3121297359467 and batch: 200, loss is 3.8510561895370485 and perplexity is 47.04272303374362
At time: 671.2212226390839 and batch: 250, loss is 3.8341165018081664 and perplexity is 46.25254557060084
At time: 672.1062960624695 and batch: 300, loss is 3.850738773345947 and perplexity is 47.02779328137712
At time: 672.991409778595 and batch: 350, loss is 3.854817314147949 and perplexity is 47.21998972920641
At time: 673.8768765926361 and batch: 400, loss is 3.812959280014038 and perplexity is 45.28424955167217
At time: 674.7623884677887 and batch: 450, loss is 3.863483204841614 and perplexity is 47.63097118697511
At time: 675.6487748622894 and batch: 500, loss is 3.876177315711975 and perplexity is 48.239457944301954
At time: 676.5347328186035 and batch: 550, loss is 3.846729669570923 and perplexity is 46.83963141006173
At time: 677.4201536178589 and batch: 600, loss is 3.827832808494568 and perplexity is 45.962819985934004
At time: 678.3063943386078 and batch: 650, loss is 3.851201639175415 and perplexity is 47.04956587842923
At time: 679.1940262317657 and batch: 700, loss is 3.877310175895691 and perplexity is 48.29413747177301
At time: 680.0816104412079 and batch: 750, loss is 3.8387760639190676 and perplexity is 46.46856506676163
At time: 680.9680941104889 and batch: 800, loss is 3.8044848251342773 and perplexity is 44.90211171399146
At time: 681.8559565544128 and batch: 850, loss is 3.802752499580383 and perplexity is 44.824393974094505
At time: 682.742329120636 and batch: 900, loss is 3.7678741931915285 and perplexity is 43.28794514769292
At time: 683.6288506984711 and batch: 950, loss is 3.887999906539917 and perplexity is 48.813157945193545
At time: 684.516250371933 and batch: 1000, loss is 3.8414151668548584 and perplexity is 46.591362359326766
At time: 685.4047095775604 and batch: 1050, loss is 3.7959706926345826 and perplexity is 44.52143206346857
At time: 686.2890191078186 and batch: 1100, loss is 3.814417657852173 and perplexity is 45.350339277817206
At time: 687.1772673130035 and batch: 1150, loss is 3.794409279823303 and perplexity is 44.451969972679834
At time: 688.0648605823517 and batch: 1200, loss is 3.845031108856201 and perplexity is 46.76013898272566
At time: 688.9515454769135 and batch: 1250, loss is 3.8333631801605224 and perplexity is 46.21771564747854
At time: 689.8390259742737 and batch: 1300, loss is 3.845105781555176 and perplexity is 46.763630818878724
At time: 690.7334134578705 and batch: 1350, loss is 3.7180471563339235 and perplexity is 41.183889829661176
At time: 691.6331069469452 and batch: 1400, loss is 3.753619785308838 and perplexity is 42.67527809802027
At time: 692.5211362838745 and batch: 1450, loss is 3.6622096872329712 and perplexity is 38.947309228933676
At time: 693.4081664085388 and batch: 1500, loss is 3.67953369140625 and perplexity is 39.62791092806484
At time: 694.2949683666229 and batch: 1550, loss is 3.6840293502807615 and perplexity is 39.80646555712854
At time: 695.1819403171539 and batch: 1600, loss is 3.7728040599823 and perplexity is 43.501875842557915
At time: 696.069176197052 and batch: 1650, loss is 3.7212255668640135 and perplexity is 41.3149973852095
At time: 696.9765455722809 and batch: 1700, loss is 3.7428992795944214 and perplexity is 42.220221114075706
At time: 697.869143486023 and batch: 1750, loss is 3.739595680236816 and perplexity is 42.080972556092505
At time: 698.7569451332092 and batch: 1800, loss is 3.710549488067627 and perplexity is 40.87626137496451
At time: 699.6532220840454 and batch: 1850, loss is 3.7318941450119016 and perplexity is 41.75812925393445
At time: 700.5658235549927 and batch: 1900, loss is 3.815396423339844 and perplexity is 45.394748354246914
At time: 701.4558942317963 and batch: 1950, loss is 3.749378695487976 and perplexity is 42.49467166523968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268028365734011 and perplexity of 71.38076003487343
finished 19 epochs...
Completing Train Step...
At time: 704.4416134357452 and batch: 50, loss is 3.880335183143616 and perplexity is 48.440448772459426
At time: 705.3723313808441 and batch: 100, loss is 3.8667177295684816 and perplexity is 47.78528417108839
At time: 706.2594089508057 and batch: 150, loss is 3.8433731603622436 and perplexity is 46.68267731219584
At time: 707.1479568481445 and batch: 200, loss is 3.8472945404052736 and perplexity is 46.86609722591702
At time: 708.0356020927429 and batch: 250, loss is 3.8302362298965456 and perplexity is 46.07342086820731
At time: 708.9443926811218 and batch: 300, loss is 3.8467853450775147 and perplexity is 46.84223930286625
At time: 709.856018781662 and batch: 350, loss is 3.8509985208511353 and perplexity is 47.04001021994744
At time: 710.7440299987793 and batch: 400, loss is 3.809124674797058 and perplexity is 45.110934841211844
At time: 711.6320903301239 and batch: 450, loss is 3.8598235654830932 and perplexity is 47.45697758124926
At time: 712.5196769237518 and batch: 500, loss is 3.8726765441894533 and perplexity is 48.07087787598787
At time: 713.407016992569 and batch: 550, loss is 3.843320918083191 and perplexity is 46.68023856644415
At time: 714.2938189506531 and batch: 600, loss is 3.8246382427215577 and perplexity is 45.81622301587893
At time: 715.1880054473877 and batch: 650, loss is 3.848053388595581 and perplexity is 46.90167497633215
At time: 716.1316363811493 and batch: 700, loss is 3.8742895317077637 and perplexity is 48.14847816932377
At time: 717.019553899765 and batch: 750, loss is 3.835943341255188 and perplexity is 46.33711877268443
At time: 717.9204354286194 and batch: 800, loss is 3.801823935508728 and perplexity is 44.78279097083278
At time: 718.8089499473572 and batch: 850, loss is 3.8002027559280394 and perplexity is 44.71024884234142
At time: 719.7040615081787 and batch: 900, loss is 3.7653921604156495 and perplexity is 43.18063627619357
At time: 720.6001720428467 and batch: 950, loss is 3.885701141357422 and perplexity is 48.70107683069935
At time: 721.4881236553192 and batch: 1000, loss is 3.8392384243011475 and perplexity is 46.49005525798427
At time: 722.3767576217651 and batch: 1050, loss is 3.793914895057678 and perplexity is 44.42999902742114
At time: 723.2652044296265 and batch: 1100, loss is 3.8124550104141237 and perplexity is 45.261419837917416
At time: 724.1532094478607 and batch: 1150, loss is 3.792538924217224 and perplexity is 44.368906684597974
At time: 725.0407128334045 and batch: 1200, loss is 3.843232345581055 and perplexity is 46.67610416401389
At time: 725.9723875522614 and batch: 1250, loss is 3.831730442047119 and perplexity is 46.14231579248526
At time: 726.8797369003296 and batch: 1300, loss is 3.843485655784607 and perplexity is 46.68792919509798
At time: 727.7667813301086 and batch: 1350, loss is 3.71650812625885 and perplexity is 41.12055533395291
At time: 728.6537079811096 and batch: 1400, loss is 3.7523047637939455 and perplexity is 42.61919607178471
At time: 729.5518712997437 and batch: 1450, loss is 3.6609868669509886 and perplexity is 38.899712776164655
At time: 730.4516756534576 and batch: 1500, loss is 3.6784548997879027 and perplexity is 39.5851837209233
At time: 731.3401598930359 and batch: 1550, loss is 3.6831270837783814 and perplexity is 39.770565714726274
At time: 732.2274744510651 and batch: 1600, loss is 3.772093095779419 and perplexity is 43.47095855791932
At time: 733.1145038604736 and batch: 1650, loss is 3.7206457328796385 and perplexity is 41.29104848952398
At time: 733.9989037513733 and batch: 1700, loss is 3.742492022514343 and perplexity is 42.20303013091694
At time: 734.8867492675781 and batch: 1750, loss is 3.739370059967041 and perplexity is 42.071479306687024
At time: 735.7747092247009 and batch: 1800, loss is 3.710349431037903 and perplexity is 40.86808460946459
At time: 736.6616661548615 and batch: 1850, loss is 3.7316465187072754 and perplexity is 41.74779012287243
At time: 737.5486927032471 and batch: 1900, loss is 3.81519896030426 and perplexity is 45.38578545438716
At time: 738.4374792575836 and batch: 1950, loss is 3.749109835624695 and perplexity is 42.48324808936492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267999693404796 and perplexity of 71.37871341156297
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
1533.156967639923


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4452414512634277 and batch: 50, loss is 7.5672454833984375 and perplexity is 1933.8062371899362
At time: 2.3986239433288574 and batch: 100, loss is 6.633901748657227 and perplexity is 760.4434490091451
At time: 3.3579256534576416 and batch: 150, loss is 6.360626678466797 and perplexity is 578.6088445036656
At time: 4.313074111938477 and batch: 200, loss is 6.133238191604614 and perplexity is 460.9263143978022
At time: 5.26806116104126 and batch: 250, loss is 5.978893127441406 and perplexity is 395.0029082141182
At time: 6.224051237106323 and batch: 300, loss is 5.844524402618408 and perplexity is 345.338260745788
At time: 7.178837776184082 and batch: 350, loss is 5.7420017051696775 and perplexity is 311.6876938270889
At time: 8.134849548339844 and batch: 400, loss is 5.660579242706299 and perplexity is 287.31501949454065
At time: 9.091912508010864 and batch: 450, loss is 5.550815868377685 and perplexity is 257.4475135304383
At time: 10.04609489440918 and batch: 500, loss is 5.493835935592651 and perplexity is 243.1882745164269
At time: 11.001777648925781 and batch: 550, loss is 5.430734062194825 and perplexity is 228.316782643694
At time: 11.959406852722168 and batch: 600, loss is 5.433638954162598 and perplexity is 228.98098247902178
At time: 12.915168285369873 and batch: 650, loss is 5.479009189605713 and perplexity is 239.60918245406484
At time: 13.871702909469604 and batch: 700, loss is 5.420348834991455 and perplexity is 225.95793078854604
At time: 14.823699712753296 and batch: 750, loss is 5.356527023315429 and perplexity is 211.98743908453372
At time: 15.776539087295532 and batch: 800, loss is 5.335784635543823 and perplexity is 207.63560318333919
At time: 16.73715567588806 and batch: 850, loss is 5.326239032745361 and perplexity is 205.66302588638797
At time: 17.698763132095337 and batch: 900, loss is 5.328267297744751 and perplexity is 206.08058832395108
At time: 18.653656721115112 and batch: 950, loss is 5.357421760559082 and perplexity is 212.17719702055618
At time: 19.610087394714355 and batch: 1000, loss is 5.316680860519409 and perplexity is 203.70662795311767
At time: 20.566431760787964 and batch: 1050, loss is 5.202500820159912 and perplexity is 181.72613847238588
At time: 21.52845597267151 and batch: 1100, loss is 5.282123174667358 and perplexity is 196.7872458149871
At time: 22.485555171966553 and batch: 1150, loss is 5.178670511245728 and perplexity is 177.44674065552297
At time: 23.44948697090149 and batch: 1200, loss is 5.252363443374634 and perplexity is 191.01719370148547
At time: 24.405979871749878 and batch: 1250, loss is 5.200863676071167 and perplexity is 181.42887000107154
At time: 25.36179757118225 and batch: 1300, loss is 5.221688089370727 and perplexity is 185.24663314788287
At time: 26.322571992874146 and batch: 1350, loss is 5.143908882141114 and perplexity is 171.38438205412805
At time: 27.28283143043518 and batch: 1400, loss is 5.154358949661255 and perplexity is 173.18475102322085
At time: 28.238948822021484 and batch: 1450, loss is 5.094464101791382 and perplexity is 163.11640740723033
At time: 29.194632053375244 and batch: 1500, loss is 5.071091499328613 and perplexity is 159.34816086705365
At time: 30.149805307388306 and batch: 1550, loss is 5.055262470245362 and perplexity is 156.84569226937546
At time: 31.105783939361572 and batch: 1600, loss is 5.102159681320191 and perplexity is 164.3765251421295
At time: 32.0615668296814 and batch: 1650, loss is 5.073796920776367 and perplexity is 159.77984848428827
At time: 33.02215647697449 and batch: 1700, loss is 5.096615037918091 and perplexity is 163.46763798263345
At time: 33.978787899017334 and batch: 1750, loss is 5.090462818145752 and perplexity is 162.46503642302292
At time: 34.93897747993469 and batch: 1800, loss is 5.051210289001465 and perplexity is 156.2114110760699
At time: 35.8967547416687 and batch: 1850, loss is 5.040058822631836 and perplexity is 154.47910162596062
At time: 36.85176610946655 and batch: 1900, loss is 5.107622280120849 and perplexity is 165.2769051195771
At time: 37.80722618103027 and batch: 1950, loss is 5.02824517250061 and perplexity is 152.66487697414928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.737022222474564 and perplexity of 114.09394893616417
finished 1 epochs...
Completing Train Step...
At time: 40.78108334541321 and batch: 50, loss is 4.936982564926147 and perplexity is 139.34913756526657
At time: 41.71792459487915 and batch: 100, loss is 4.898752460479736 and perplexity is 134.12235233544334
At time: 42.60564351081848 and batch: 150, loss is 4.843753757476807 and perplexity is 126.94497914124071
At time: 43.49218678474426 and batch: 200, loss is 4.816473989486695 and perplexity is 123.52875827501867
At time: 44.37883901596069 and batch: 250, loss is 4.811129693984985 and perplexity is 122.87034503240788
At time: 45.26661157608032 and batch: 300, loss is 4.82356822013855 and perplexity is 124.4082156265601
At time: 46.15459370613098 and batch: 350, loss is 4.816194229125976 and perplexity is 123.49420465863602
At time: 47.06639289855957 and batch: 400, loss is 4.772409429550171 and perplexity is 118.20370262313133
At time: 47.952141761779785 and batch: 450, loss is 4.755671300888062 and perplexity is 116.24166010806469
At time: 48.8383355140686 and batch: 500, loss is 4.743866329193115 and perplexity is 114.87749838808872
At time: 49.7234320640564 and batch: 550, loss is 4.705095958709717 and perplexity is 110.50888872907589
At time: 50.60861396789551 and batch: 600, loss is 4.691145429611206 and perplexity is 108.97793489828894
At time: 51.49463987350464 and batch: 650, loss is 4.760919523239136 and perplexity is 116.85332586174187
At time: 52.38019680976868 and batch: 700, loss is 4.767821159362793 and perplexity is 117.66259442295329
At time: 53.26526951789856 and batch: 750, loss is 4.72440673828125 and perplexity is 112.66363951920872
At time: 54.15208649635315 and batch: 800, loss is 4.700387687683105 and perplexity is 109.98980588036895
At time: 55.03811311721802 and batch: 850, loss is 4.6933372211456295 and perplexity is 109.21705376706788
At time: 55.925394773483276 and batch: 900, loss is 4.686111164093018 and perplexity is 108.43068968301938
At time: 56.813019037246704 and batch: 950, loss is 4.746992540359497 and perplexity is 115.23719165191851
At time: 57.699568033218384 and batch: 1000, loss is 4.720818815231323 and perplexity is 112.26013535390229
At time: 58.59143018722534 and batch: 1050, loss is 4.636468029022216 and perplexity is 103.17927704149824
At time: 59.49782967567444 and batch: 1100, loss is 4.698839893341065 and perplexity is 109.81969596268979
At time: 60.38482475280762 and batch: 1150, loss is 4.636201257705689 and perplexity is 103.15175544107349
At time: 61.27145218849182 and batch: 1200, loss is 4.709936532974243 and perplexity is 111.04511197906395
At time: 62.157413482666016 and batch: 1250, loss is 4.680447368621826 and perplexity is 107.81829630632951
At time: 63.04233002662659 and batch: 1300, loss is 4.6951032161712645 and perplexity is 109.41010095074611
At time: 63.92866373062134 and batch: 1350, loss is 4.585662488937378 and perplexity is 98.06813468055559
At time: 64.81547164916992 and batch: 1400, loss is 4.59837685585022 and perplexity is 99.3229692366652
At time: 65.7031421661377 and batch: 1450, loss is 4.541010847091675 and perplexity is 93.78555507560888
At time: 66.61274361610413 and batch: 1500, loss is 4.537162656784058 and perplexity is 93.42534393659685
At time: 67.49936318397522 and batch: 1550, loss is 4.536502332687378 and perplexity is 93.36367329430132
At time: 68.38646459579468 and batch: 1600, loss is 4.606821146011352 and perplexity is 100.1652323608065
At time: 69.27388596534729 and batch: 1650, loss is 4.570928335189819 and perplexity is 96.6337766813502
At time: 70.16155505180359 and batch: 1700, loss is 4.598702611923218 and perplexity is 99.35532956758324
At time: 71.04941582679749 and batch: 1750, loss is 4.589573163986206 and perplexity is 98.45239816301864
At time: 71.94633913040161 and batch: 1800, loss is 4.5454238986969 and perplexity is 94.20035015284442
At time: 72.84545493125916 and batch: 1850, loss is 4.572946672439575 and perplexity is 96.82901319269476
At time: 73.75515270233154 and batch: 1900, loss is 4.652192192077637 and perplexity is 104.81450744002298
At time: 74.6431667804718 and batch: 1950, loss is 4.581779975891113 and perplexity is 97.68812204759423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5156494140625 and perplexity of 91.43692717165649
finished 2 epochs...
Completing Train Step...
At time: 77.57542395591736 and batch: 50, loss is 4.551110334396363 and perplexity is 94.73754028790871
At time: 78.50395250320435 and batch: 100, loss is 4.520202150344849 and perplexity is 91.85416445250384
At time: 79.39236617088318 and batch: 150, loss is 4.482819862365723 and perplexity is 88.48383344291403
At time: 80.27947044372559 and batch: 200, loss is 4.47554500579834 and perplexity is 87.84246201728317
At time: 81.16654348373413 and batch: 250, loss is 4.46420036315918 and perplexity is 86.85155206436696
At time: 82.05232739448547 and batch: 300, loss is 4.481461048126221 and perplexity is 88.36368200029868
At time: 82.94023013114929 and batch: 350, loss is 4.488289108276367 and perplexity is 88.96909909609322
At time: 83.8268096446991 and batch: 400, loss is 4.450918893814087 and perplexity is 85.705662232672
At time: 84.71346974372864 and batch: 450, loss is 4.460056676864624 and perplexity is 86.4924110760872
At time: 85.59937644004822 and batch: 500, loss is 4.458033266067505 and perplexity is 86.31757833652338
At time: 86.48448467254639 and batch: 550, loss is 4.4231448745727535 and perplexity is 83.35802410530104
At time: 87.36980748176575 and batch: 600, loss is 4.41124116897583 and perplexity is 82.37163720425806
At time: 88.25630903244019 and batch: 650, loss is 4.479326190948487 and perplexity is 88.1752393801402
At time: 89.14347219467163 and batch: 700, loss is 4.493929615020752 and perplexity is 89.47234785434325
At time: 90.02979803085327 and batch: 750, loss is 4.456772241592407 and perplexity is 86.20879835913179
At time: 90.95710062980652 and batch: 800, loss is 4.436528930664062 and perplexity is 84.48119208086278
At time: 91.8438413143158 and batch: 850, loss is 4.431934757232666 and perplexity is 84.09396101717303
At time: 92.7305679321289 and batch: 900, loss is 4.419297218322754 and perplexity is 83.03790732745469
At time: 93.61639189720154 and batch: 950, loss is 4.489269409179688 and perplexity is 89.05635834747825
At time: 94.50239372253418 and batch: 1000, loss is 4.465679006576538 and perplexity is 86.98006953245263
At time: 95.38863182067871 and batch: 1050, loss is 4.393323230743408 and perplexity is 80.90885148452496
At time: 96.27458500862122 and batch: 1100, loss is 4.4493247985839846 and perplexity is 85.56914808250038
At time: 97.16183519363403 and batch: 1150, loss is 4.400524635314941 and perplexity is 81.4936118784216
At time: 98.05050826072693 and batch: 1200, loss is 4.473421907424926 and perplexity is 87.65616166602378
At time: 98.95547533035278 and batch: 1250, loss is 4.454354944229126 and perplexity is 86.00065772841835
At time: 99.84424901008606 and batch: 1300, loss is 4.465131721496582 and perplexity is 86.93247966194487
At time: 100.75314378738403 and batch: 1350, loss is 4.348991327285766 and perplexity is 77.4003519146126
At time: 101.64164400100708 and batch: 1400, loss is 4.36773154258728 and perplexity is 78.8645278088857
At time: 102.5295958518982 and batch: 1450, loss is 4.301883320808411 and perplexity is 73.8387248395347
At time: 103.4166784286499 and batch: 1500, loss is 4.304336137771607 and perplexity is 74.02006001644676
At time: 104.3044548034668 and batch: 1550, loss is 4.312146444320678 and perplexity is 74.60044290979265
At time: 105.19219970703125 and batch: 1600, loss is 4.391339893341065 and perplexity is 80.74854096067418
At time: 106.07932734489441 and batch: 1650, loss is 4.354293556213379 and perplexity is 77.81183622752916
At time: 106.98221826553345 and batch: 1700, loss is 4.382106695175171 and perplexity is 80.00640509649735
At time: 107.87448859214783 and batch: 1750, loss is 4.375331964492798 and perplexity is 79.46621513594265
At time: 108.7619776725769 and batch: 1800, loss is 4.330214405059815 and perplexity is 75.96057115417811
At time: 109.64758896827698 and batch: 1850, loss is 4.362186489105224 and perplexity is 78.42842999461364
At time: 110.53228259086609 and batch: 1900, loss is 4.4415084075927735 and perplexity is 84.90291333197172
At time: 111.41949129104614 and batch: 1950, loss is 4.374998817443847 and perplexity is 79.43974561024586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.435228640534157 and perplexity of 84.37141340816707
finished 3 epochs...
Completing Train Step...
At time: 114.39159226417542 and batch: 50, loss is 4.348008651733398 and perplexity is 77.32432983967621
At time: 115.33245921134949 and batch: 100, loss is 4.319015655517578 and perplexity is 75.11465319508531
At time: 116.22276568412781 and batch: 150, loss is 4.295760202407837 and perplexity is 73.38798296601337
At time: 117.11085891723633 and batch: 200, loss is 4.289947490692139 and perplexity is 72.96263718146564
At time: 117.99915790557861 and batch: 250, loss is 4.274758496284485 and perplexity is 71.86278208494551
At time: 118.88731217384338 and batch: 300, loss is 4.2913806343078615 and perplexity is 73.06727808393903
At time: 119.77541184425354 and batch: 350, loss is 4.299110231399536 and perplexity is 73.63424710227766
At time: 120.66304874420166 and batch: 400, loss is 4.271711106300354 and perplexity is 71.64412150383797
At time: 121.55060529708862 and batch: 450, loss is 4.290334939956665 and perplexity is 72.99091197875047
At time: 122.43859314918518 and batch: 500, loss is 4.292806158065796 and perplexity is 73.17151150073005
At time: 123.34800291061401 and batch: 550, loss is 4.257591896057129 and perplexity is 70.63967080151407
At time: 124.23936009407043 and batch: 600, loss is 4.250935206413269 and perplexity is 70.17100604496224
At time: 125.1303083896637 and batch: 650, loss is 4.313522930145264 and perplexity is 74.70320006762674
At time: 126.03498983383179 and batch: 700, loss is 4.329187135696412 and perplexity is 75.88257925280887
At time: 126.92376661300659 and batch: 750, loss is 4.2984593391418455 and perplexity is 73.58633473552376
At time: 127.82104182243347 and batch: 800, loss is 4.279773125648498 and perplexity is 72.22405236338484
At time: 128.71399974822998 and batch: 850, loss is 4.271676568984986 and perplexity is 71.64164715094829
At time: 129.6213448047638 and batch: 900, loss is 4.258941941261291 and perplexity is 70.73510195399356
At time: 130.5093379020691 and batch: 950, loss is 4.334668455123901 and perplexity is 76.29965793516203
At time: 131.3973467350006 and batch: 1000, loss is 4.308857145309449 and perplexity is 74.35546287386698
At time: 132.30120825767517 and batch: 1050, loss is 4.245823564529419 and perplexity is 69.81323217639566
At time: 133.18684911727905 and batch: 1100, loss is 4.291479778289795 and perplexity is 73.07452262395766
At time: 134.07360553741455 and batch: 1150, loss is 4.254409017562867 and perplexity is 70.4151907483569
At time: 134.95999264717102 and batch: 1200, loss is 4.324898624420166 and perplexity is 75.55785275032561
At time: 135.889066696167 and batch: 1250, loss is 4.3122382068634035 and perplexity is 74.60728875021354
At time: 136.77638339996338 and batch: 1300, loss is 4.319451723098755 and perplexity is 75.14741540296424
At time: 137.66336607933044 and batch: 1350, loss is 4.202525968551636 and perplexity is 66.85499154184068
At time: 138.5501914024353 and batch: 1400, loss is 4.222674651145935 and perplexity is 68.21569369080493
At time: 139.43712067604065 and batch: 1450, loss is 4.152357339859009 and perplexity is 63.58371218701428
At time: 140.345600605011 and batch: 1500, loss is 4.16264081954956 and perplexity is 64.24094754127417
At time: 141.23156094551086 and batch: 1550, loss is 4.171084990501404 and perplexity is 64.78570586367084
At time: 142.11786317825317 and batch: 1600, loss is 4.258328809738159 and perplexity is 70.69174532620946
At time: 143.0042748451233 and batch: 1650, loss is 4.216240725517273 and perplexity is 67.77820787564714
At time: 143.88994717597961 and batch: 1700, loss is 4.247500028610229 and perplexity is 69.93036971350648
At time: 144.77593851089478 and batch: 1750, loss is 4.2413693618774415 and perplexity is 69.50296140990667
At time: 145.66229891777039 and batch: 1800, loss is 4.192595324516296 and perplexity is 66.19436407607495
At time: 146.54900908470154 and batch: 1850, loss is 4.228022174835205 and perplexity is 68.5814558180054
At time: 147.43538308143616 and batch: 1900, loss is 4.300587043762207 and perplexity is 73.74307140547388
At time: 148.32229852676392 and batch: 1950, loss is 4.237732610702515 and perplexity is 69.25065549833072
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.406402162063953 and perplexity of 81.97400313540373
finished 4 epochs...
Completing Train Step...
At time: 151.26306200027466 and batch: 50, loss is 4.216113324165344 and perplexity is 67.76957339036672
At time: 152.15028738975525 and batch: 100, loss is 4.193491683006287 and perplexity is 66.25372455646487
At time: 153.08146619796753 and batch: 150, loss is 4.168353838920593 and perplexity is 64.60900768527736
At time: 153.9730725288391 and batch: 200, loss is 4.168147282600403 and perplexity is 64.5956636645921
At time: 154.86010479927063 and batch: 250, loss is 4.147363338470459 and perplexity is 63.26696661228711
At time: 155.74735355377197 and batch: 300, loss is 4.163882374763489 and perplexity is 64.3207557575435
At time: 156.6351342201233 and batch: 350, loss is 4.174519772529602 and perplexity is 65.00861324183374
At time: 157.52020716667175 and batch: 400, loss is 4.150014786720276 and perplexity is 63.43493828587659
At time: 158.44806838035583 and batch: 450, loss is 4.16892840385437 and perplexity is 64.64614042206212
At time: 159.3367052078247 and batch: 500, loss is 4.179242339134216 and perplexity is 65.31634682196729
At time: 160.22612810134888 and batch: 550, loss is 4.145117869377136 and perplexity is 63.125061974994715
At time: 161.11431980133057 and batch: 600, loss is 4.141347637176514 and perplexity is 62.887513920720494
At time: 162.00176692008972 and batch: 650, loss is 4.199195947647095 and perplexity is 66.63273329013145
At time: 162.9025526046753 and batch: 700, loss is 4.215516405105591 and perplexity is 67.72913251150514
At time: 163.79934668540955 and batch: 750, loss is 4.187091760635376 and perplexity is 65.83105981594356
At time: 164.68627953529358 and batch: 800, loss is 4.16713442325592 and perplexity is 64.53027046568312
At time: 165.57382583618164 and batch: 850, loss is 4.157772607803345 and perplexity is 63.92896901078307
At time: 166.4612054824829 and batch: 900, loss is 4.143711447715759 and perplexity is 63.0363439225765
At time: 167.34948444366455 and batch: 950, loss is 4.222676320075989 and perplexity is 68.21580753812127
At time: 168.2371768951416 and batch: 1000, loss is 4.196383514404297 and perplexity is 66.44559645424785
At time: 169.12465977668762 and batch: 1050, loss is 4.143416500091552 and perplexity is 63.01775424432333
At time: 170.00876021385193 and batch: 1100, loss is 4.1837023878097535 and perplexity is 65.60831151248635
At time: 170.89497447013855 and batch: 1150, loss is 4.1465710210800175 and perplexity is 63.2168589476081
At time: 171.78937768936157 and batch: 1200, loss is 4.216125731468201 and perplexity is 67.77041423320449
At time: 172.69140005111694 and batch: 1250, loss is 4.20573025226593 and perplexity is 67.06955748394766
At time: 173.57721281051636 and batch: 1300, loss is 4.212364649772644 and perplexity is 67.51600289953966
At time: 174.4633936882019 and batch: 1350, loss is 4.0944064378738405 and perplexity is 60.00371265396465
At time: 175.34922003746033 and batch: 1400, loss is 4.119296431541443 and perplexity is 61.51594635584241
At time: 176.23478841781616 and batch: 1450, loss is 4.046555724143982 and perplexity is 57.200104433466066
At time: 177.1210582256317 and batch: 1500, loss is 4.062393989562988 and perplexity is 58.113267238035725
At time: 178.00762248039246 and batch: 1550, loss is 4.066987853050232 and perplexity is 58.380845793631266
At time: 178.89406633377075 and batch: 1600, loss is 4.158115091323853 and perplexity is 63.950867378853374
At time: 179.78012371063232 and batch: 1650, loss is 4.11611246585846 and perplexity is 61.320393176199666
At time: 180.66693234443665 and batch: 1700, loss is 4.146789455413819 and perplexity is 63.23066918833778
At time: 181.55223894119263 and batch: 1750, loss is 4.140135264396667 and perplexity is 62.81131700951446
At time: 182.45499658584595 and batch: 1800, loss is 4.094710378646851 and perplexity is 60.02195300062429
At time: 183.3481216430664 and batch: 1850, loss is 4.127057209014892 and perplexity is 61.995215270763225
At time: 184.2372691631317 and batch: 1900, loss is 4.200882115364075 and perplexity is 66.74518203097524
At time: 185.1324815750122 and batch: 1950, loss is 4.135703997612 and perplexity is 62.53359908230401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.394899448128633 and perplexity of 81.03648198313446
finished 5 epochs...
Completing Train Step...
At time: 188.14007425308228 and batch: 50, loss is 4.115801601409912 and perplexity is 61.301333808583635
At time: 189.02591156959534 and batch: 100, loss is 4.097531771659851 and perplexity is 60.19153763940957
At time: 189.91153502464294 and batch: 150, loss is 4.073728981018067 and perplexity is 58.77572802644977
At time: 190.79853415489197 and batch: 200, loss is 4.077846841812134 and perplexity is 59.01825730071812
At time: 191.6838722229004 and batch: 250, loss is 4.05407823562622 and perplexity is 57.63201536657636
At time: 192.57278108596802 and batch: 300, loss is 4.07086040019989 and perplexity is 58.607366694952084
At time: 193.4606499671936 and batch: 350, loss is 4.07695589542389 and perplexity is 58.965698614498095
At time: 194.3476002216339 and batch: 400, loss is 4.054124274253845 and perplexity is 57.63466872654915
At time: 195.23382806777954 and batch: 450, loss is 4.080663366317749 and perplexity is 59.184717978932255
At time: 196.12089586257935 and batch: 500, loss is 4.095025839805603 and perplexity is 60.04089058234715
At time: 197.0068256855011 and batch: 550, loss is 4.0580957937240605 and perplexity is 57.864021072746446
At time: 197.8938307762146 and batch: 600, loss is 4.05768093585968 and perplexity is 57.84002070725414
At time: 198.77900624275208 and batch: 650, loss is 4.114664101600647 and perplexity is 61.23164319711173
At time: 199.66460704803467 and batch: 700, loss is 4.131044659614563 and perplexity is 62.24291163939548
At time: 200.54970955848694 and batch: 750, loss is 4.106747016906739 and perplexity is 60.74878104440881
At time: 201.4361708164215 and batch: 800, loss is 4.080827798843384 and perplexity is 59.194450671752215
At time: 202.3645622730255 and batch: 850, loss is 4.07764769077301 and perplexity is 59.006504923737296
At time: 203.2524812221527 and batch: 900, loss is 4.054445061683655 and perplexity is 57.65316016955054
At time: 204.13978672027588 and batch: 950, loss is 4.139082508087158 and perplexity is 62.7452267937739
At time: 205.02154207229614 and batch: 1000, loss is 4.115084538459778 and perplexity is 61.257392649487045
At time: 205.9056384563446 and batch: 1050, loss is 4.0666741847991945 and perplexity is 58.36253644751748
At time: 206.80120635032654 and batch: 1100, loss is 4.1000709724426265 and perplexity is 60.34457024693479
At time: 207.72013688087463 and batch: 1150, loss is 4.066587262153625 and perplexity is 58.357463641921356
At time: 208.607590675354 and batch: 1200, loss is 4.136720013618469 and perplexity is 62.59716650720606
At time: 209.4938187599182 and batch: 1250, loss is 4.125873193740845 and perplexity is 61.92185542712269
At time: 210.37863850593567 and batch: 1300, loss is 4.130347428321838 and perplexity is 62.19952905925385
At time: 211.28708505630493 and batch: 1350, loss is 4.014697008132934 and perplexity is 55.40650513852609
At time: 212.17259192466736 and batch: 1400, loss is 4.044876217842102 and perplexity is 57.104117125808884
At time: 213.0589349269867 and batch: 1450, loss is 3.966104564666748 and perplexity is 52.77853450930887
At time: 213.945326089859 and batch: 1500, loss is 3.9833964347839355 and perplexity is 53.699110373920675
At time: 214.84801387786865 and batch: 1550, loss is 3.98559317111969 and perplexity is 53.81720282237361
At time: 215.7520933151245 and batch: 1600, loss is 4.085813384056092 and perplexity is 59.49030654420973
At time: 216.63858151435852 and batch: 1650, loss is 4.03383162021637 and perplexity is 56.47689521207302
At time: 217.52410078048706 and batch: 1700, loss is 4.069266262054444 and perplexity is 58.51401288530382
At time: 218.41104555130005 and batch: 1750, loss is 4.064705214500427 and perplexity is 58.24773540370317
At time: 219.2986192703247 and batch: 1800, loss is 4.017399339675904 and perplexity is 55.556434373058096
At time: 220.18599796295166 and batch: 1850, loss is 4.051056442260742 and perplexity is 57.45812618580744
At time: 221.0732138156891 and batch: 1900, loss is 4.121450634002685 and perplexity is 61.64860699652521
At time: 221.96059489250183 and batch: 1950, loss is 4.059899582862854 and perplexity is 57.96848975689785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385860567314681 and perplexity of 80.30730332496614
finished 6 epochs...
Completing Train Step...
At time: 224.95578622817993 and batch: 50, loss is 4.044672107696533 and perplexity is 57.09246278557474
At time: 225.8483443260193 and batch: 100, loss is 4.0246783638000485 and perplexity is 55.96230638312222
At time: 226.74338102340698 and batch: 150, loss is 4.004007935523987 and perplexity is 54.817415004625865
At time: 227.6294662952423 and batch: 200, loss is 3.99928147315979 and perplexity is 54.558933887533414
At time: 228.53356528282166 and batch: 250, loss is 3.9800916624069216 and perplexity is 53.5219399524916
At time: 229.43147659301758 and batch: 300, loss is 3.994652228355408 and perplexity is 54.306950921717046
At time: 230.33103585243225 and batch: 350, loss is 4.001185231208801 and perplexity is 54.66289982866563
At time: 231.21711683273315 and batch: 400, loss is 3.9792536687850952 and perplexity is 53.47710769537996
At time: 232.10439944267273 and batch: 450, loss is 4.0094012975692745 and perplexity is 55.11386387958742
At time: 232.99006390571594 and batch: 500, loss is 4.022274250984192 and perplexity is 55.827928279924436
At time: 233.87635135650635 and batch: 550, loss is 3.9895898485183716 and perplexity is 54.0327232164147
At time: 234.7645778656006 and batch: 600, loss is 3.994595241546631 and perplexity is 54.30385623006876
At time: 235.6520140171051 and batch: 650, loss is 4.04536346912384 and perplexity is 57.13194795982512
At time: 236.55662894248962 and batch: 700, loss is 4.063009672164917 and perplexity is 58.14905758223095
At time: 237.4673252105713 and batch: 750, loss is 4.039959411621094 and perplexity is 56.824036363143094
At time: 238.3543403148651 and batch: 800, loss is 4.012464690208435 and perplexity is 55.28295815335164
At time: 239.24154591560364 and batch: 850, loss is 4.006677913665771 and perplexity is 54.96397186922552
At time: 240.12879419326782 and batch: 900, loss is 3.9868481016159056 and perplexity is 53.884782066174466
At time: 241.01525259017944 and batch: 950, loss is 4.0734697389602665 and perplexity is 58.76049286065068
At time: 241.90200066566467 and batch: 1000, loss is 4.047805581092835 and perplexity is 57.27164107744059
At time: 242.78837633132935 and batch: 1050, loss is 4.008820276260376 and perplexity is 55.08185085128407
At time: 243.674870967865 and batch: 1100, loss is 4.033776483535767 and perplexity is 56.47378134938505
At time: 244.56081652641296 and batch: 1150, loss is 4.000844874382019 and perplexity is 54.64429810332893
At time: 245.44806027412415 and batch: 1200, loss is 4.072242197990417 and perplexity is 58.68840620197116
At time: 246.33482599258423 and batch: 1250, loss is 4.058948483467102 and perplexity is 57.913382171866985
At time: 247.22163558006287 and batch: 1300, loss is 4.062322754859924 and perplexity is 58.10912770414092
At time: 248.10829615592957 and batch: 1350, loss is 3.9488726663589477 and perplexity is 51.876851338079334
At time: 248.99489641189575 and batch: 1400, loss is 3.982793951034546 and perplexity is 53.66676727663731
At time: 249.88266253471375 and batch: 1450, loss is 3.904972414970398 and perplexity is 49.64871033214306
At time: 250.76988625526428 and batch: 1500, loss is 3.923655042648315 and perplexity is 50.58499762202255
At time: 251.66054916381836 and batch: 1550, loss is 3.9211552047729494 and perplexity is 50.45870125503341
At time: 252.5446813106537 and batch: 1600, loss is 4.022818508148194 and perplexity is 55.85832129990135
At time: 253.43236422538757 and batch: 1650, loss is 3.971458578109741 and perplexity is 53.06186930489888
At time: 254.318829536438 and batch: 1700, loss is 4.007773070335388 and perplexity is 55.024199002660644
At time: 255.20492553710938 and batch: 1750, loss is 4.002120013237 and perplexity is 54.71402161517574
At time: 256.0918142795563 and batch: 1800, loss is 3.9577239894866945 and perplexity is 52.33806829106252
At time: 256.97907066345215 and batch: 1850, loss is 3.9940078496932983 and perplexity is 54.27196795368841
At time: 257.8673315048218 and batch: 1900, loss is 4.059069108963013 and perplexity is 57.920368423662914
At time: 258.7558846473694 and batch: 1950, loss is 3.997774238586426 and perplexity is 54.476762717262694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386670773528343 and perplexity of 80.37239516646903
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 261.741854429245 and batch: 50, loss is 4.012151503562928 and perplexity is 55.265646980089514
At time: 262.6568088531494 and batch: 100, loss is 4.017759370803833 and perplexity is 55.57644001990086
At time: 263.5460033416748 and batch: 150, loss is 3.9902030086517333 and perplexity is 54.065864087480115
At time: 264.43486404418945 and batch: 200, loss is 3.985897488594055 and perplexity is 53.83358282984874
At time: 265.3253960609436 and batch: 250, loss is 3.967127537727356 and perplexity is 52.83255315338833
At time: 266.21532559394836 and batch: 300, loss is 3.967717390060425 and perplexity is 52.86372575083869
At time: 267.1048629283905 and batch: 350, loss is 3.978253712654114 and perplexity is 53.423659660971275
At time: 267.99441623687744 and batch: 400, loss is 3.9428579235076904 and perplexity is 51.5657619166444
At time: 268.9037549495697 and batch: 450, loss is 3.9736756706237792 and perplexity is 53.179642887336634
At time: 269.85267782211304 and batch: 500, loss is 3.981735768318176 and perplexity is 53.61000806716532
At time: 270.7657334804535 and batch: 550, loss is 3.9435454845428466 and perplexity is 51.60122871668408
At time: 271.6613862514496 and batch: 600, loss is 3.93608913898468 and perplexity is 51.217903004612936
At time: 272.5495340824127 and batch: 650, loss is 3.978196120262146 and perplexity is 53.42058295322205
At time: 273.4395897388458 and batch: 700, loss is 3.9899892377853394 and perplexity is 54.05430761613426
At time: 274.35324716567993 and batch: 750, loss is 3.9499183988571165 and perplexity is 51.931129022449156
At time: 275.2426929473877 and batch: 800, loss is 3.9212977838516236 and perplexity is 50.46589612307609
At time: 276.14181303977966 and batch: 850, loss is 3.915363907814026 and perplexity is 50.16732447102178
At time: 277.05266666412354 and batch: 900, loss is 3.882014317512512 and perplexity is 48.52185512181049
At time: 277.9410936832428 and batch: 950, loss is 3.969247360229492 and perplexity is 52.94466757776444
At time: 278.8362078666687 and batch: 1000, loss is 3.9400738143920897 and perplexity is 51.42239687340625
At time: 279.75702023506165 and batch: 1050, loss is 3.8904569721221924 and perplexity is 48.93324254299469
At time: 280.66705083847046 and batch: 1100, loss is 3.9071401262283327 and perplexity is 49.75645113375704
At time: 281.5618577003479 and batch: 1150, loss is 3.8795832538604738 and perplexity is 48.40403867116506
At time: 282.48542165756226 and batch: 1200, loss is 3.938007459640503 and perplexity is 51.31624966595128
At time: 283.375070810318 and batch: 1250, loss is 3.914785394668579 and perplexity is 50.13831040766111
At time: 284.263964176178 and batch: 1300, loss is 3.921402678489685 and perplexity is 50.47119000262929
At time: 285.1775851249695 and batch: 1350, loss is 3.807904963493347 and perplexity is 45.05594606609756
At time: 286.0888330936432 and batch: 1400, loss is 3.827361135482788 and perplexity is 45.94114567619663
At time: 286.98061323165894 and batch: 1450, loss is 3.748201456069946 and perplexity is 42.44467469767382
At time: 287.8715376853943 and batch: 1500, loss is 3.7524428749084473 and perplexity is 42.62508266294582
At time: 288.76243901252747 and batch: 1550, loss is 3.7461370611190796 and perplexity is 42.35714250712939
At time: 289.65598011016846 and batch: 1600, loss is 3.839748668670654 and perplexity is 46.5137825997742
At time: 290.5472366809845 and batch: 1650, loss is 3.7756632423400878 and perplexity is 43.62643362034384
At time: 291.4371955394745 and batch: 1700, loss is 3.80488995552063 and perplexity is 44.92030660926181
At time: 292.3367247581482 and batch: 1750, loss is 3.786886429786682 and perplexity is 44.11881916171131
At time: 293.2412943840027 and batch: 1800, loss is 3.7407247638702392 and perplexity is 42.12851232662211
At time: 294.1305630207062 and batch: 1850, loss is 3.7621552038192747 and perplexity is 43.04108840780745
At time: 295.02141213417053 and batch: 1900, loss is 3.8259278964996337 and perplexity is 45.87534819830119
At time: 295.9382426738739 and batch: 1950, loss is 3.7542015075683595 and perplexity is 42.700110479295354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303250193041424 and perplexity of 73.93972195158824
finished 8 epochs...
Completing Train Step...
At time: 298.9525020122528 and batch: 50, loss is 3.9212106609344484 and perplexity is 50.46149957851066
At time: 299.8629879951477 and batch: 100, loss is 3.916492295265198 and perplexity is 50.22396460040958
At time: 300.7481572628021 and batch: 150, loss is 3.885266275405884 and perplexity is 48.67990299480628
At time: 301.6336874961853 and batch: 200, loss is 3.880246706008911 and perplexity is 48.43616308994346
At time: 302.5387189388275 and batch: 250, loss is 3.863344626426697 and perplexity is 47.62437101981798
At time: 303.4315695762634 and batch: 300, loss is 3.8666569900512697 and perplexity is 47.782381804143085
At time: 304.3414204120636 and batch: 350, loss is 3.8808643436431884 and perplexity is 48.46608832765301
At time: 305.22665095329285 and batch: 400, loss is 3.8483614540100097 and perplexity is 46.916125986085
At time: 306.1131582260132 and batch: 450, loss is 3.8854285526275634 and perplexity is 48.68780327521633
At time: 307.00786805152893 and batch: 500, loss is 3.8985484981536866 and perplexity is 49.33079337623348
At time: 307.9124057292938 and batch: 550, loss is 3.86182324886322 and perplexity is 47.551971457772986
At time: 308.80259227752686 and batch: 600, loss is 3.8581130361557006 and perplexity is 47.375870417174546
At time: 309.6969802379608 and batch: 650, loss is 3.9000084829330444 and perplexity is 49.402868184975674
At time: 310.6113736629486 and batch: 700, loss is 3.915500364303589 and perplexity is 50.17417059509827
At time: 311.5035843849182 and batch: 750, loss is 3.88216561794281 and perplexity is 48.52919705477407
At time: 312.4009349346161 and batch: 800, loss is 3.852522473335266 and perplexity is 47.11175161172724
At time: 313.28623628616333 and batch: 850, loss is 3.8493516349792483 and perplexity is 46.96260444843375
At time: 314.17146706581116 and batch: 900, loss is 3.816037483215332 and perplexity is 45.42385843563036
At time: 315.0981214046478 and batch: 950, loss is 3.906238374710083 and perplexity is 49.711603402198485
At time: 315.9834403991699 and batch: 1000, loss is 3.8811251497268677 and perplexity is 48.47873022681145
At time: 316.8691756725311 and batch: 1050, loss is 3.835580654144287 and perplexity is 46.32031594421813
At time: 317.7549364566803 and batch: 1100, loss is 3.8518557596206664 and perplexity is 47.080352029238135
At time: 318.6425905227661 and batch: 1150, loss is 3.8271768140792846 and perplexity is 45.932678520110066
At time: 319.53004479408264 and batch: 1200, loss is 3.8876713800430296 and perplexity is 48.7971241633171
At time: 320.41847491264343 and batch: 1250, loss is 3.868583526611328 and perplexity is 47.87452503977207
At time: 321.3059411048889 and batch: 1300, loss is 3.8769824361801146 and perplexity is 48.27831215832753
At time: 322.19403624534607 and batch: 1350, loss is 3.7649421977996824 and perplexity is 43.16121097479307
At time: 323.0823817253113 and batch: 1400, loss is 3.789733910560608 and perplexity is 44.244625681861464
At time: 323.9702956676483 and batch: 1450, loss is 3.711198635101318 and perplexity is 40.902804693110475
At time: 324.85841822624207 and batch: 1500, loss is 3.717722988128662 and perplexity is 41.170541485680666
At time: 325.746572971344 and batch: 1550, loss is 3.715508894920349 and perplexity is 41.07948690825276
At time: 326.6341166496277 and batch: 1600, loss is 3.8109579849243165 and perplexity is 45.19371303076798
At time: 327.52071499824524 and batch: 1650, loss is 3.749993977546692 and perplexity is 42.52082591960295
At time: 328.40814208984375 and batch: 1700, loss is 3.784189920425415 and perplexity is 44.000012606316574
At time: 329.2959702014923 and batch: 1750, loss is 3.770119743347168 and perplexity is 43.385259621029704
At time: 330.18264651298523 and batch: 1800, loss is 3.726733965873718 and perplexity is 41.543204827686246
At time: 331.08395433425903 and batch: 1850, loss is 3.752111167907715 and perplexity is 42.61094596936947
At time: 331.9800612926483 and batch: 1900, loss is 3.8176457405090334 and perplexity is 45.496970462984514
At time: 332.86751341819763 and batch: 1950, loss is 3.7482325553894045 and perplexity is 42.445994718697314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3028564453125 and perplexity of 73.91061408494679
finished 9 epochs...
Completing Train Step...
At time: 335.834760427475 and batch: 50, loss is 3.8764039516448974 and perplexity is 48.25039197783248
At time: 336.74862480163574 and batch: 100, loss is 3.870350399017334 and perplexity is 47.959187989304816
At time: 337.64290952682495 and batch: 150, loss is 3.838653712272644 and perplexity is 46.462879909120055
At time: 338.5441653728485 and batch: 200, loss is 3.8341773080825807 and perplexity is 46.25535810108805
At time: 339.4305727481842 and batch: 250, loss is 3.816962471008301 and perplexity is 45.465894388567364
At time: 340.3172776699066 and batch: 300, loss is 3.821799302101135 and perplexity is 45.68633793453648
At time: 341.2042860984802 and batch: 350, loss is 3.835896224975586 and perplexity is 46.33493559147248
At time: 342.09065341949463 and batch: 400, loss is 3.803840436935425 and perplexity is 44.87318664358731
At time: 342.9786972999573 and batch: 450, loss is 3.843872685432434 and perplexity is 46.706002305081235
At time: 343.86565256118774 and batch: 500, loss is 3.858795738220215 and perplexity is 47.40822506475221
At time: 344.7701427936554 and batch: 550, loss is 3.8219764041900635 and perplexity is 45.69442979694189
At time: 345.65730714797974 and batch: 600, loss is 3.8195355892181397 and perplexity is 45.58303415194307
At time: 346.5427484512329 and batch: 650, loss is 3.8600741624832153 and perplexity is 47.468871647712426
At time: 347.42827701568604 and batch: 700, loss is 3.877116904258728 and perplexity is 48.28480448669783
At time: 348.31153202056885 and batch: 750, loss is 3.846375412940979 and perplexity is 46.82304109887794
At time: 349.1969599723816 and batch: 800, loss is 3.8167932081222533 and perplexity is 45.4581993513269
At time: 350.0838141441345 and batch: 850, loss is 3.814243025779724 and perplexity is 45.34242034555276
At time: 350.9687623977661 and batch: 900, loss is 3.780999608039856 and perplexity is 43.85986250131351
At time: 351.85463285446167 and batch: 950, loss is 3.87277645111084 and perplexity is 48.075680729319956
At time: 352.7398021221161 and batch: 1000, loss is 3.849225492477417 and perplexity is 46.956680841633265
At time: 353.62511920928955 and batch: 1050, loss is 3.804497952461243 and perplexity is 44.9027011625623
At time: 354.5110538005829 and batch: 1100, loss is 3.8209042024612425 and perplexity is 45.64546240646762
At time: 355.397696018219 and batch: 1150, loss is 3.7971747303009034 and perplexity is 44.57506982909669
At time: 356.2830572128296 and batch: 1200, loss is 3.8582321310043337 and perplexity is 47.381512975283876
At time: 357.1693592071533 and batch: 1250, loss is 3.8416085243225098 and perplexity is 46.60037201818133
At time: 358.0549910068512 and batch: 1300, loss is 3.8500002574920655 and perplexity is 46.99307533192176
At time: 358.94046235084534 and batch: 1350, loss is 3.7380155611038206 and perplexity is 42.01453211195397
At time: 359.82653188705444 and batch: 1400, loss is 3.7658150434494018 and perplexity is 43.1989004962036
At time: 360.71238827705383 and batch: 1450, loss is 3.6870209407806396 and perplexity is 39.92572850532795
At time: 361.59752321243286 and batch: 1500, loss is 3.6944479894638063 and perplexity is 40.22336273846737
At time: 362.4829204082489 and batch: 1550, loss is 3.6937179565429688 and perplexity is 40.194009075355375
At time: 363.368155002594 and batch: 1600, loss is 3.789879961013794 and perplexity is 44.251088101401514
At time: 364.253559589386 and batch: 1650, loss is 3.730243673324585 and perplexity is 41.689265488365606
At time: 365.1395683288574 and batch: 1700, loss is 3.766334476470947 and perplexity is 43.22134526038697
At time: 366.02425360679626 and batch: 1750, loss is 3.753785500526428 and perplexity is 42.68235062701265
At time: 366.91053462028503 and batch: 1800, loss is 3.7111178159713747 and perplexity is 40.8994990976024
At time: 367.7962074279785 and batch: 1850, loss is 3.7378927278518677 and perplexity is 42.00937164729019
At time: 368.6811203956604 and batch: 1900, loss is 3.804122257232666 and perplexity is 44.88583460052714
At time: 369.56640100479126 and batch: 1950, loss is 3.73556396484375 and perplexity is 41.911655599523016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.305442348746366 and perplexity of 74.10198712516818
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 372.54598665237427 and batch: 50, loss is 3.8650968408584596 and perplexity is 47.70789228223391
At time: 373.4552173614502 and batch: 100, loss is 3.8865341091156007 and perplexity is 48.74166015744275
At time: 374.3432967662811 and batch: 150, loss is 3.864337658882141 and perplexity is 47.67168705520193
At time: 375.23048663139343 and batch: 200, loss is 3.865871329307556 and perplexity is 47.744855805800604
At time: 376.1376624107361 and batch: 250, loss is 3.8517652893066407 and perplexity is 47.076092847673266
At time: 377.02605295181274 and batch: 300, loss is 3.852486085891724 and perplexity is 47.110037366713975
At time: 377.9146182537079 and batch: 350, loss is 3.865178470611572 and perplexity is 47.71178682465553
At time: 378.80246925354004 and batch: 400, loss is 3.83072808265686 and perplexity is 46.09608778137341
At time: 379.71595430374146 and batch: 450, loss is 3.8700635480880736 and perplexity is 47.94543282459872
At time: 380.6273572444916 and batch: 500, loss is 3.884074673652649 and perplexity is 48.62193048398278
At time: 381.54115056991577 and batch: 550, loss is 3.8439460611343383 and perplexity is 46.709429516519
At time: 382.42906737327576 and batch: 600, loss is 3.8341909408569337 and perplexity is 46.255988694246014
At time: 383.3180866241455 and batch: 650, loss is 3.864732766151428 and perplexity is 47.6905262067944
At time: 384.20588779449463 and batch: 700, loss is 3.884352264404297 and perplexity is 48.635429355706705
At time: 385.120991230011 and batch: 750, loss is 3.8456870889663697 and perplexity is 46.790822766722755
At time: 386.0233952999115 and batch: 800, loss is 3.8124778652191162 and perplexity is 45.26245429066256
At time: 386.9112253189087 and batch: 850, loss is 3.8091369438171387 and perplexity is 45.111488311572536
At time: 387.7993314266205 and batch: 900, loss is 3.772085666656494 and perplexity is 43.47063560802415
At time: 388.68729162216187 and batch: 950, loss is 3.8631602001190184 and perplexity is 47.61558864279086
At time: 389.57484221458435 and batch: 1000, loss is 3.839220266342163 and perplexity is 46.489211101131815
At time: 390.4627137184143 and batch: 1050, loss is 3.7875248050689696 and perplexity is 44.14699251697789
At time: 391.34976744651794 and batch: 1100, loss is 3.7977950143814088 and perplexity is 44.60272761225361
At time: 392.23751640319824 and batch: 1150, loss is 3.7793661880493166 and perplexity is 43.788279403668575
At time: 393.1396539211273 and batch: 1200, loss is 3.837455143928528 and perplexity is 46.40722433225357
At time: 394.03324484825134 and batch: 1250, loss is 3.8151964807510375 and perplexity is 45.385672918056095
At time: 394.91924929618835 and batch: 1300, loss is 3.823102436065674 and perplexity is 45.74591216138303
At time: 395.80260968208313 and batch: 1350, loss is 3.7098269128799437 and perplexity is 40.84673587121255
At time: 396.69256687164307 and batch: 1400, loss is 3.735661153793335 and perplexity is 41.915729147254794
At time: 397.5806565284729 and batch: 1450, loss is 3.649593138694763 and perplexity is 38.459015380226525
At time: 398.46818947792053 and batch: 1500, loss is 3.6609393119812013 and perplexity is 38.89786294548352
At time: 399.3580403327942 and batch: 1550, loss is 3.6612299871444702 and perplexity is 38.90917123158535
At time: 400.2458484172821 and batch: 1600, loss is 3.752643971443176 and perplexity is 42.6336552812949
At time: 401.133629322052 and batch: 1650, loss is 3.6841309595108034 and perplexity is 39.810510466941096
At time: 402.0215871334076 and batch: 1700, loss is 3.710778822898865 and perplexity is 40.8856368004833
At time: 402.9087975025177 and batch: 1750, loss is 3.6950717401504516 and perplexity is 40.24845991497151
At time: 403.7954840660095 and batch: 1800, loss is 3.651373553276062 and perplexity is 38.52754936333962
At time: 404.6790294647217 and batch: 1850, loss is 3.6781252670288085 and perplexity is 39.57213729797645
At time: 405.5837495326996 and batch: 1900, loss is 3.747341537475586 and perplexity is 42.40819142124177
At time: 406.4860134124756 and batch: 1950, loss is 3.682184963226318 and perplexity is 39.733114691858525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273380723110465 and perplexity of 71.76383964734812
finished 11 epochs...
Completing Train Step...
At time: 409.43472480773926 and batch: 50, loss is 3.8502330589294433 and perplexity is 47.00401666093498
At time: 410.3187401294708 and batch: 100, loss is 3.858914837837219 and perplexity is 47.41387170244979
At time: 411.2016382217407 and batch: 150, loss is 3.8296586751937864 and perplexity is 46.04681863017599
At time: 412.08668851852417 and batch: 200, loss is 3.826951699256897 and perplexity is 45.9223395571138
At time: 412.9692096710205 and batch: 250, loss is 3.81120005607605 and perplexity is 45.204654449179905
At time: 413.85487627983093 and batch: 300, loss is 3.8109120178222655 and perplexity is 45.19163565449489
At time: 414.73983359336853 and batch: 350, loss is 3.8239711236953737 and perplexity is 45.7856683347349
At time: 415.623309135437 and batch: 400, loss is 3.790440034866333 and perplexity is 44.27587892049026
At time: 416.5113754272461 and batch: 450, loss is 3.8329584264755248 and perplexity is 46.199012642068574
At time: 417.3955912590027 and batch: 500, loss is 3.8462774658203127 and perplexity is 46.818455141415804
At time: 418.2793834209442 and batch: 550, loss is 3.8087274742126467 and perplexity is 45.09302030959632
At time: 419.16331338882446 and batch: 600, loss is 3.801539115905762 and perplexity is 44.770037770355714
At time: 420.0485737323761 and batch: 650, loss is 3.8334920310974123 and perplexity is 46.223671227123404
At time: 420.9345464706421 and batch: 700, loss is 3.854758801460266 and perplexity is 47.21722684152777
At time: 421.82142877578735 and batch: 750, loss is 3.819148554801941 and perplexity is 45.56539536256096
At time: 422.7101936340332 and batch: 800, loss is 3.787101082801819 and perplexity is 44.1282904157489
At time: 423.59711384773254 and batch: 850, loss is 3.785024724006653 and perplexity is 44.03675931042087
At time: 424.48426055908203 and batch: 900, loss is 3.748477330207825 and perplexity is 42.456385701020785
At time: 425.3951082229614 and batch: 950, loss is 3.8419308280944824 and perplexity is 46.615393914535005
At time: 426.281347990036 and batch: 1000, loss is 3.8185806465148926 and perplexity is 45.53952574341277
At time: 427.16836190223694 and batch: 1050, loss is 3.770281238555908 and perplexity is 43.392266698377924
At time: 428.0553824901581 and batch: 1100, loss is 3.780454406738281 and perplexity is 43.83595656455698
At time: 428.94205355644226 and batch: 1150, loss is 3.762342085838318 and perplexity is 43.04913276496036
At time: 429.8279650211334 and batch: 1200, loss is 3.821940622329712 and perplexity is 45.69279479448794
At time: 430.73342204093933 and batch: 1250, loss is 3.8019586515426638 and perplexity is 44.788824337207416
At time: 431.62437176704407 and batch: 1300, loss is 3.8110424423217775 and perplexity is 45.19753013534125
At time: 432.542676448822 and batch: 1350, loss is 3.6982333993911745 and perplexity is 40.375913205954625
At time: 433.4338765144348 and batch: 1400, loss is 3.7260856151580812 and perplexity is 41.5162789907424
At time: 434.3216173648834 and batch: 1450, loss is 3.6415091943740845 and perplexity is 38.149368113187144
At time: 435.20905327796936 and batch: 1500, loss is 3.6543521785736086 and perplexity is 38.64247957857529
At time: 436.0967857837677 and batch: 1550, loss is 3.6561620378494264 and perplexity is 38.712480355350934
At time: 436.98479771614075 and batch: 1600, loss is 3.7489798069000244 and perplexity is 42.47772440592254
At time: 437.8720591068268 and batch: 1650, loss is 3.6817085552215576 and perplexity is 39.71419002625428
At time: 438.7594385147095 and batch: 1700, loss is 3.7102848291397095 and perplexity is 40.86544453890099
At time: 439.6456367969513 and batch: 1750, loss is 3.6961231899261473 and perplexity is 40.29080140519553
At time: 440.53297543525696 and batch: 1800, loss is 3.6549400329589843 and perplexity is 38.6652024078604
At time: 441.41873240470886 and batch: 1850, loss is 3.6826514530181886 and perplexity is 39.751654108149516
At time: 442.30604100227356 and batch: 1900, loss is 3.7526972675323487 and perplexity is 42.63592754893948
At time: 443.1923930644989 and batch: 1950, loss is 3.6874340200424194 and perplexity is 39.942224402606925
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.272020632721657 and perplexity of 71.66630068471858
finished 12 epochs...
Completing Train Step...
At time: 446.1461913585663 and batch: 50, loss is 3.8359930515289307 and perplexity is 46.339422260796105
At time: 447.0328679084778 and batch: 100, loss is 3.8435929107666014 and perplexity is 46.69293697665312
At time: 447.9616951942444 and batch: 150, loss is 3.81328763961792 and perplexity is 45.29912151145883
At time: 448.8491168022156 and batch: 200, loss is 3.809726538658142 and perplexity is 45.13809365476685
At time: 449.7551953792572 and batch: 250, loss is 3.7935437965393066 and perplexity is 44.413514179551306
At time: 450.64187598228455 and batch: 300, loss is 3.793501129150391 and perplexity is 44.41161921129565
At time: 451.52886295318604 and batch: 350, loss is 3.8066061210632323 and perplexity is 44.99746347967192
At time: 452.4147984981537 and batch: 400, loss is 3.773249397277832 and perplexity is 43.52125316469808
At time: 453.3118269443512 and batch: 450, loss is 3.8167630767822267 and perplexity is 45.456829655500734
At time: 454.20484352111816 and batch: 500, loss is 3.829645137786865 and perplexity is 46.04619527987405
At time: 455.11304473876953 and batch: 550, loss is 3.792860507965088 and perplexity is 44.38317729837397
At time: 456.00211811065674 and batch: 600, loss is 3.78600426197052 and perplexity is 44.07991612138776
At time: 456.89806270599365 and batch: 650, loss is 3.8184941959381105 and perplexity is 45.535588995315386
At time: 457.7844626903534 and batch: 700, loss is 3.840512523651123 and perplexity is 46.54932595753068
At time: 458.6806859970093 and batch: 750, loss is 3.805818839073181 and perplexity is 44.96205172842244
At time: 459.577659368515 and batch: 800, loss is 3.7743175506591795 and perplexity is 43.56776537509149
At time: 460.46397280693054 and batch: 850, loss is 3.772352213859558 and perplexity is 43.48222412873617
At time: 461.35032081604004 and batch: 900, loss is 3.736170802116394 and perplexity is 41.93709687287476
At time: 462.26044845581055 and batch: 950, loss is 3.8304914379119874 and perplexity is 46.08518067504636
At time: 463.1481409072876 and batch: 1000, loss is 3.8074319314956666 and perplexity is 45.034638201970616
At time: 464.03480315208435 and batch: 1050, loss is 3.760535044670105 and perplexity is 42.971411453751955
At time: 464.92084407806396 and batch: 1100, loss is 3.7706288290023804 and perplexity is 43.407352057344504
At time: 465.8293011188507 and batch: 1150, loss is 3.7527339124679564 and perplexity is 42.63748996838629
At time: 466.7163622379303 and batch: 1200, loss is 3.8129798936843873 and perplexity is 45.28518303588568
At time: 467.6026005744934 and batch: 1250, loss is 3.7939053440093993 and perplexity is 44.4295746763819
At time: 468.4893000125885 and batch: 1300, loss is 3.803332166671753 and perplexity is 44.85038473243776
At time: 469.3749186992645 and batch: 1350, loss is 3.6906921005249025 and perplexity is 40.07257160990213
At time: 470.2604513168335 and batch: 1400, loss is 3.7194502353668213 and perplexity is 41.241714638876736
At time: 471.1437256336212 and batch: 1450, loss is 3.6352168416976927 and perplexity is 37.91007249041313
At time: 472.02922010421753 and batch: 1500, loss is 3.648621940612793 and perplexity is 38.421682190150555
At time: 472.91560673713684 and batch: 1550, loss is 3.651045770645142 and perplexity is 38.51492277134822
At time: 473.80334663391113 and batch: 1600, loss is 3.7445522689819337 and perplexity is 42.290068404026144
At time: 474.68947887420654 and batch: 1650, loss is 3.6775914525985716 and perplexity is 39.55101875724385
At time: 475.5763337612152 and batch: 1700, loss is 3.7071255826950074 and perplexity is 40.73654424963165
At time: 476.4640302658081 and batch: 1750, loss is 3.693769407272339 and perplexity is 40.196077139639875
At time: 477.35077691078186 and batch: 1800, loss is 3.653978910446167 and perplexity is 38.628058264259224
At time: 478.23647141456604 and batch: 1850, loss is 3.6819237518310546 and perplexity is 39.72273730493656
At time: 479.1238486766815 and batch: 1900, loss is 3.7522178077697754 and perplexity is 42.615490237065636
At time: 480.0106348991394 and batch: 1950, loss is 3.686824793815613 and perplexity is 39.917897962848826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.272160303869913 and perplexity of 71.67631109829318
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 482.94205832481384 and batch: 50, loss is 3.8335924911499024 and perplexity is 46.228315092818754
At time: 483.8523054122925 and batch: 100, loss is 3.8554004049301147 and perplexity is 47.24753129878881
At time: 484.7393078804016 and batch: 150, loss is 3.832256484031677 and perplexity is 46.16659497323117
At time: 485.62551617622375 and batch: 200, loss is 3.832116389274597 and perplexity is 46.16012772834731
At time: 486.52391028404236 and batch: 250, loss is 3.8226628923416137 and perplexity is 45.72580925116876
At time: 487.40783953666687 and batch: 300, loss is 3.8228523921966553 and perplexity is 45.73447510645674
At time: 488.2918367385864 and batch: 350, loss is 3.8361477041244507 and perplexity is 46.34658932691204
At time: 489.1771013736725 and batch: 400, loss is 3.8047768020629884 and perplexity is 44.915224008812984
At time: 490.06233286857605 and batch: 450, loss is 3.849100284576416 and perplexity is 46.95080186224212
At time: 490.948655128479 and batch: 500, loss is 3.8572475147247314 and perplexity is 47.3348833261792
At time: 491.83466720581055 and batch: 550, loss is 3.820860810279846 and perplexity is 45.64348179325483
At time: 492.7716255187988 and batch: 600, loss is 3.8099961137771605 and perplexity is 45.15026340199293
At time: 493.65684270858765 and batch: 650, loss is 3.8328264713287354 and perplexity is 46.19291684676849
At time: 494.5440812110901 and batch: 700, loss is 3.854897699356079 and perplexity is 47.22378567047541
At time: 495.4293146133423 and batch: 750, loss is 3.8216919231414797 and perplexity is 45.681432446476414
At time: 496.3153626918793 and batch: 800, loss is 3.7854852724075316 and perplexity is 44.05704504042287
At time: 497.20140767097473 and batch: 850, loss is 3.785221481323242 and perplexity is 44.045424717477246
At time: 498.08703780174255 and batch: 900, loss is 3.7470332860946653 and perplexity is 42.39512105225697
At time: 498.97267627716064 and batch: 950, loss is 3.8422573947906495 and perplexity is 46.63061943565496
At time: 499.85845017433167 and batch: 1000, loss is 3.8144761323928833 and perplexity is 45.352991195611615
At time: 500.7435872554779 and batch: 1050, loss is 3.7705511045455933 and perplexity is 43.40397837559577
At time: 501.62883472442627 and batch: 1100, loss is 3.773913469314575 and perplexity is 43.550164010308386
At time: 502.51535868644714 and batch: 1150, loss is 3.757351975440979 and perplexity is 42.83484793708957
At time: 503.4020473957062 and batch: 1200, loss is 3.8114658975601197 and perplexity is 45.21667331909185
At time: 504.2876546382904 and batch: 1250, loss is 3.7893996477127074 and perplexity is 44.22983881876392
At time: 505.1737496852875 and batch: 1300, loss is 3.80044497013092 and perplexity is 44.72107961125545
At time: 506.05961179733276 and batch: 1350, loss is 3.6848664045333863 and perplexity is 39.83979967769246
At time: 506.9468264579773 and batch: 1400, loss is 3.710670900344849 and perplexity is 40.88122455623183
At time: 507.83205008506775 and batch: 1450, loss is 3.625486731529236 and perplexity is 37.54299207115558
At time: 508.71634888648987 and batch: 1500, loss is 3.6382470178604125 and perplexity is 38.02512090885723
At time: 509.6014025211334 and batch: 1550, loss is 3.644584884643555 and perplexity is 38.26688438266187
At time: 510.48694586753845 and batch: 1600, loss is 3.737774062156677 and perplexity is 42.00438687176592
At time: 511.3730819225311 and batch: 1650, loss is 3.6681985378265383 and perplexity is 39.18125868986922
At time: 512.2588295936584 and batch: 1700, loss is 3.688844013214111 and perplexity is 39.99858238912785
At time: 513.1443512439728 and batch: 1750, loss is 3.6776530170440673 and perplexity is 39.55345376873673
At time: 514.0313274860382 and batch: 1800, loss is 3.6397106981277467 and perplexity is 38.080818279622136
At time: 514.9163529872894 and batch: 1850, loss is 3.664408187866211 and perplexity is 39.03302910601192
At time: 515.8021109104156 and batch: 1900, loss is 3.743104166984558 and perplexity is 42.228872391229295
At time: 516.7033677101135 and batch: 1950, loss is 3.6828747510910036 and perplexity is 39.760531567025915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257332451398983 and perplexity of 70.62134609349803
finished 14 epochs...
Completing Train Step...
At time: 519.6957547664642 and batch: 50, loss is 3.8378493690490725 and perplexity is 46.42552283248733
At time: 520.6066811084747 and batch: 100, loss is 3.8481986284255982 and perplexity is 46.90848746234341
At time: 521.4939458370209 and batch: 150, loss is 3.8172329378128054 and perplexity is 45.47819306685371
At time: 522.3823843002319 and batch: 200, loss is 3.8135402011871338 and perplexity is 45.31056377354879
At time: 523.2740135192871 and batch: 250, loss is 3.801524019241333 and perplexity is 44.76936189722076
At time: 524.1802589893341 and batch: 300, loss is 3.800624747276306 and perplexity is 44.72912016201852
At time: 525.0680119991302 and batch: 350, loss is 3.813426899909973 and perplexity is 45.305430319623305
At time: 525.9563472270966 and batch: 400, loss is 3.7821020889282226 and perplexity is 43.90824382633022
At time: 526.8573863506317 and batch: 450, loss is 3.827721905708313 and perplexity is 45.95772286378118
At time: 527.753383398056 and batch: 500, loss is 3.8370523166656496 and perplexity is 46.38853400183809
At time: 528.6555352210999 and batch: 550, loss is 3.8018989753723145 and perplexity is 44.78615159144693
At time: 529.5545077323914 and batch: 600, loss is 3.792672190666199 and perplexity is 44.37481996524893
At time: 530.4412698745728 and batch: 650, loss is 3.8174937629699706 and perplexity is 45.4900564707778
At time: 531.3285200595856 and batch: 700, loss is 3.8405700302124024 and perplexity is 46.55200292616727
At time: 532.2265090942383 and batch: 750, loss is 3.808190064430237 and perplexity is 45.068793389838454
At time: 533.1339392662048 and batch: 800, loss is 3.773136034011841 and perplexity is 43.516319732939564
At time: 534.0412802696228 and batch: 850, loss is 3.7728987073898317 and perplexity is 43.5059933771831
At time: 534.9401304721832 and batch: 900, loss is 3.7355023574829103 and perplexity is 41.90907361256861
At time: 535.8245408535004 and batch: 950, loss is 3.8318260145187377 and perplexity is 46.14672593839267
At time: 536.7111587524414 and batch: 1000, loss is 3.805061602592468 and perplexity is 44.92801771013237
At time: 537.6229693889618 and batch: 1050, loss is 3.76221613407135 and perplexity is 43.04371099207028
At time: 538.5100111961365 and batch: 1100, loss is 3.7666622018814087 and perplexity is 43.23551231482819
At time: 539.3976490497589 and batch: 1150, loss is 3.7505907821655273 and perplexity is 42.5462101188587
At time: 540.2850987911224 and batch: 1200, loss is 3.8054966831207278 and perplexity is 44.947569268754165
At time: 541.1816163063049 and batch: 1250, loss is 3.7852049589157106 and perplexity is 44.04469698703211
At time: 542.0826778411865 and batch: 1300, loss is 3.7965129661560058 and perplexity is 44.545581404394724
At time: 542.991533279419 and batch: 1350, loss is 3.6811276292800903 and perplexity is 39.69112572299834
At time: 543.8791346549988 and batch: 1400, loss is 3.7086139631271364 and perplexity is 40.79722086871033
At time: 544.7664039134979 and batch: 1450, loss is 3.624755787849426 and perplexity is 37.51556028514668
At time: 545.6540079116821 and batch: 1500, loss is 3.6384535598754884 and perplexity is 38.03297550507739
At time: 546.5415847301483 and batch: 1550, loss is 3.6460530757904053 and perplexity is 38.32310874748768
At time: 547.4284222126007 and batch: 1600, loss is 3.7404746913909914 and perplexity is 42.11797846226725
At time: 548.3231446743011 and batch: 1650, loss is 3.6711627674102782 and perplexity is 39.297573242356655
At time: 549.2135500907898 and batch: 1700, loss is 3.6922646236419676 and perplexity is 40.13563622740773
At time: 550.1005721092224 and batch: 1750, loss is 3.681490421295166 and perplexity is 39.705527958830125
At time: 550.9872140884399 and batch: 1800, loss is 3.6442453145980833 and perplexity is 38.25389230097772
At time: 551.883410692215 and batch: 1850, loss is 3.669138126373291 and perplexity is 39.21809025232905
At time: 552.772971868515 and batch: 1900, loss is 3.7486401796340942 and perplexity is 42.46330026207453
At time: 553.6780614852905 and batch: 1950, loss is 3.687932457923889 and perplexity is 39.96213808277334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.256038222202035 and perplexity of 70.53000500635689
finished 15 epochs...
Completing Train Step...
At time: 556.6270818710327 and batch: 50, loss is 3.8346091413497927 and perplexity is 46.27533701697269
At time: 557.5411417484283 and batch: 100, loss is 3.8433074426651 and perplexity is 46.67960953495112
At time: 558.4271111488342 and batch: 150, loss is 3.8113136005401613 and perplexity is 45.20978747885271
At time: 559.3388566970825 and batch: 200, loss is 3.806759600639343 and perplexity is 45.00437020129964
At time: 560.2254631519318 and batch: 250, loss is 3.794236011505127 and perplexity is 44.44426852183103
At time: 561.1116161346436 and batch: 300, loss is 3.792979192733765 and perplexity is 44.38844521810951
At time: 561.9979882240295 and batch: 350, loss is 3.805703835487366 and perplexity is 44.95688122856677
At time: 562.88463306427 and batch: 400, loss is 3.7741046142578125 and perplexity is 43.558489199569685
At time: 563.7712841033936 and batch: 450, loss is 3.8199963092803957 and perplexity is 45.60404000881365
At time: 564.6583800315857 and batch: 500, loss is 3.829434480667114 and perplexity is 46.036496342611855
At time: 565.5446920394897 and batch: 550, loss is 3.7945283317565917 and perplexity is 44.457262380673015
At time: 566.4296607971191 and batch: 600, loss is 3.7857853984832763 and perplexity is 44.07026969289202
At time: 567.3155055046082 and batch: 650, loss is 3.811068935394287 and perplexity is 45.198727572646206
At time: 568.2030699253082 and batch: 700, loss is 3.834435987472534 and perplexity is 46.267324956626425
At time: 569.0902996063232 and batch: 750, loss is 3.8024674224853516 and perplexity is 44.811617387316474
At time: 569.9773681163788 and batch: 800, loss is 3.767609543800354 and perplexity is 43.27649053515936
At time: 570.8651266098022 and batch: 850, loss is 3.767372770309448 and perplexity is 43.26624502240198
At time: 571.7518458366394 and batch: 900, loss is 3.730289897918701 and perplexity is 41.69119260228148
At time: 572.6392793655396 and batch: 950, loss is 3.8271821260452272 and perplexity is 45.932922513582064
At time: 573.5269854068756 and batch: 1000, loss is 3.800653924942017 and perplexity is 44.73042527237408
At time: 574.4140915870667 and batch: 1050, loss is 3.758397355079651 and perplexity is 42.87965002846562
At time: 575.3005435466766 and batch: 1100, loss is 3.763195905685425 and perplexity is 43.08590466497093
At time: 576.1857957839966 and batch: 1150, loss is 3.7473742628097533 and perplexity is 42.409579266186185
At time: 577.0717899799347 and batch: 1200, loss is 3.8026011562347413 and perplexity is 44.81761061366527
At time: 577.9590518474579 and batch: 1250, loss is 3.7830129194259645 and perplexity is 43.948255012847845
At time: 578.8551983833313 and batch: 1300, loss is 3.794623017311096 and perplexity is 44.461472040507125
At time: 579.7423882484436 and batch: 1350, loss is 3.6792245054244996 and perplexity is 39.61566042745895
At time: 580.6479933261871 and batch: 1400, loss is 3.707282567024231 and perplexity is 40.742939750689146
At time: 581.5391173362732 and batch: 1450, loss is 3.623838534355164 and perplexity is 37.48116478349453
At time: 582.4260919094086 and batch: 1500, loss is 3.6379565095901487 and perplexity is 38.014075901166144
At time: 583.3133156299591 and batch: 1550, loss is 3.645972375869751 and perplexity is 38.32001620043835
At time: 584.2052583694458 and batch: 1600, loss is 3.7409027862548827 and perplexity is 42.136012812455355
At time: 585.1144342422485 and batch: 1650, loss is 3.671516819000244 and perplexity is 39.31148907396069
At time: 586.001179933548 and batch: 1700, loss is 3.692824025154114 and perplexity is 40.1580944439988
At time: 586.8883454799652 and batch: 1750, loss is 3.68235023021698 and perplexity is 39.73968180680199
At time: 587.7912361621857 and batch: 1800, loss is 3.6454452514648437 and perplexity is 38.29982210756985
At time: 588.6870608329773 and batch: 1850, loss is 3.670433020591736 and perplexity is 39.2689064243384
At time: 589.5925049781799 and batch: 1900, loss is 3.750074043273926 and perplexity is 42.52423051674674
At time: 590.4795951843262 and batch: 1950, loss is 3.6890037155151365 and perplexity is 40.00497076487871
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255744117914245 and perplexity of 70.50926487949627
finished 16 epochs...
Completing Train Step...
At time: 593.4573936462402 and batch: 50, loss is 3.8308707427978517 and perplexity is 46.10266432484962
At time: 594.3440494537354 and batch: 100, loss is 3.8388680982589722 and perplexity is 46.4728419672817
At time: 595.2314512729645 and batch: 150, loss is 3.8064840126037596 and perplexity is 44.99196924417938
At time: 596.1184315681458 and batch: 200, loss is 3.801597557067871 and perplexity is 44.77265425984528
At time: 597.0046072006226 and batch: 250, loss is 3.78893892288208 and perplexity is 44.2094657273204
At time: 597.9049208164215 and batch: 300, loss is 3.7875706815719603 and perplexity is 44.149017873069894
At time: 598.8149387836456 and batch: 350, loss is 3.8003597402572633 and perplexity is 44.71726820171567
At time: 599.7016367912292 and batch: 400, loss is 3.768710422515869 and perplexity is 43.32415893622153
At time: 600.5888607501984 and batch: 450, loss is 3.8147946119308473 and perplexity is 45.36743749559625
At time: 601.4887199401855 and batch: 500, loss is 3.824245548248291 and perplexity is 45.79823477048808
At time: 602.3827121257782 and batch: 550, loss is 3.789484152793884 and perplexity is 44.233576622813224
At time: 603.2688755989075 and batch: 600, loss is 3.7810290336608885 and perplexity is 43.86115312399461
At time: 604.1801352500916 and batch: 650, loss is 3.8065405750274657 and perplexity is 44.994514170980075
At time: 605.0889966487885 and batch: 700, loss is 3.830075488090515 and perplexity is 46.06601553851593
At time: 605.9755382537842 and batch: 750, loss is 3.7983993673324585 and perplexity is 44.62969154935772
At time: 606.8628044128418 and batch: 800, loss is 3.763659381866455 and perplexity is 43.105878583881555
At time: 607.7506823539734 and batch: 850, loss is 3.7634365701675416 and perplexity is 43.09627515975848
At time: 608.6384460926056 and batch: 900, loss is 3.72658203125 and perplexity is 41.53689345596279
At time: 609.524646282196 and batch: 950, loss is 3.82384033203125 and perplexity is 45.77968034257866
At time: 610.4116230010986 and batch: 1000, loss is 3.7973806715011595 and perplexity is 44.58425061779767
At time: 611.2988469600677 and batch: 1050, loss is 3.7555546665191653 and perplexity is 42.75792962641661
At time: 612.1997826099396 and batch: 1100, loss is 3.7605470418930054 and perplexity is 42.97192699444604
At time: 613.0861926078796 and batch: 1150, loss is 3.744842209815979 and perplexity is 42.30233179947468
At time: 613.9707822799683 and batch: 1200, loss is 3.800241189002991 and perplexity is 44.711967227707476
At time: 614.8580079078674 and batch: 1250, loss is 3.7811055994033813 and perplexity is 43.86451151431733
At time: 615.7457745075226 and batch: 1300, loss is 3.7929163455963133 and perplexity is 44.385655619051704
At time: 616.6328008174896 and batch: 1350, loss is 3.677444100379944 and perplexity is 39.54519125623913
At time: 617.5181002616882 and batch: 1400, loss is 3.705848870277405 and perplexity is 40.684568583786934
At time: 618.4144237041473 and batch: 1450, loss is 3.6225971460342405 and perplexity is 37.434664971411046
At time: 619.3209526538849 and batch: 1500, loss is 3.6369957065582277 and perplexity is 37.977569402370385
At time: 620.2389757633209 and batch: 1550, loss is 3.6451633405685424 and perplexity is 38.289026492163636
At time: 621.1351218223572 and batch: 1600, loss is 3.7404337549209594 and perplexity is 42.11625433619418
At time: 622.0221395492554 and batch: 1650, loss is 3.6709318590164184 and perplexity is 39.28850015040353
At time: 622.9100997447968 and batch: 1700, loss is 3.692455840110779 and perplexity is 40.14331155584185
At time: 623.7970497608185 and batch: 1750, loss is 3.6822080421447754 and perplexity is 39.73403169975428
At time: 624.6841742992401 and batch: 1800, loss is 3.645572829246521 and perplexity is 38.3047086256119
At time: 625.5713357925415 and batch: 1850, loss is 3.6706518650054933 and perplexity is 39.27750114556279
At time: 626.4583585262299 and batch: 1900, loss is 3.7503421688079834 and perplexity is 42.5356338774622
At time: 627.3456144332886 and batch: 1950, loss is 3.6890287017822265 and perplexity is 40.005970352251104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255747808412064 and perplexity of 70.50952509426472
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 630.3171677589417 and batch: 50, loss is 3.831092257499695 and perplexity is 46.1128778739756
At time: 631.2242619991302 and batch: 100, loss is 3.844153890609741 and perplexity is 46.71913812158398
At time: 632.1337769031525 and batch: 150, loss is 3.8140843534469604 and perplexity is 45.335226328704195
At time: 633.0209743976593 and batch: 200, loss is 3.8088786125183107 and perplexity is 45.099836107334276
At time: 633.9082932472229 and batch: 250, loss is 3.7985088062286376 and perplexity is 44.634576040809506
At time: 634.7952342033386 and batch: 300, loss is 3.7975117683410646 and perplexity is 44.59009585530091
At time: 635.6843674182892 and batch: 350, loss is 3.811801028251648 and perplexity is 45.231829353574206
At time: 636.5733952522278 and batch: 400, loss is 3.7821347856521608 and perplexity is 43.90967950552809
At time: 637.4687449932098 and batch: 450, loss is 3.828249444961548 and perplexity is 45.98197376266924
At time: 638.3570053577423 and batch: 500, loss is 3.837870645523071 and perplexity is 46.42651061442497
At time: 639.2444586753845 and batch: 550, loss is 3.804919424057007 and perplexity is 44.92163036445565
At time: 640.1317903995514 and batch: 600, loss is 3.795267577171326 and perplexity is 44.49013935861993
At time: 641.0213606357574 and batch: 650, loss is 3.8170868587493896 and perplexity is 45.47155014021273
At time: 641.9080719947815 and batch: 700, loss is 3.839222855567932 and perplexity is 46.48933147235101
At time: 642.7952086925507 and batch: 750, loss is 3.810277347564697 and perplexity is 45.16296296726747
At time: 643.6830801963806 and batch: 800, loss is 3.773070888519287 and perplexity is 43.51348493319465
At time: 644.5704584121704 and batch: 850, loss is 3.7732891035079956 and perplexity is 43.52298126390118
At time: 645.4577510356903 and batch: 900, loss is 3.7326320695877073 and perplexity is 41.78895497588069
At time: 646.3450443744659 and batch: 950, loss is 3.8294044494628907 and perplexity is 46.0351138319478
At time: 647.2335984706879 and batch: 1000, loss is 3.8004359912872316 and perplexity is 44.72067806947473
At time: 648.1461124420166 and batch: 1050, loss is 3.7594292640686033 and perplexity is 42.923920762528915
At time: 649.0327875614166 and batch: 1100, loss is 3.7617681646347045 and perplexity is 43.024433043394325
At time: 649.9208645820618 and batch: 1150, loss is 3.746909303665161 and perplexity is 42.38986512797764
At time: 650.8093824386597 and batch: 1200, loss is 3.8008975887298586 and perplexity is 44.74132578520391
At time: 651.6976215839386 and batch: 1250, loss is 3.7808642530441285 and perplexity is 43.85392625157164
At time: 652.5849239826202 and batch: 1300, loss is 3.7920544576644897 and perplexity is 44.34741663935229
At time: 653.4731116294861 and batch: 1350, loss is 3.675063705444336 and perplexity is 39.45117003146466
At time: 654.3743450641632 and batch: 1400, loss is 3.701578965187073 and perplexity is 40.51121969232605
At time: 655.2621991634369 and batch: 1450, loss is 3.6178091764450073 and perplexity is 37.25585733829142
At time: 656.1498305797577 and batch: 1500, loss is 3.6301216459274293 and perplexity is 37.7174045067785
At time: 657.0379955768585 and batch: 1550, loss is 3.6409302139282227 and perplexity is 38.12728676797801
At time: 657.9250092506409 and batch: 1600, loss is 3.735361251831055 and perplexity is 41.903160422619926
At time: 658.8106653690338 and batch: 1650, loss is 3.665864200592041 and perplexity is 39.089903087690914
At time: 659.6981074810028 and batch: 1700, loss is 3.6854078340530396 and perplexity is 39.86137596178652
At time: 660.5865542888641 and batch: 1750, loss is 3.675824360847473 and perplexity is 39.48119019316081
At time: 661.4720876216888 and batch: 1800, loss is 3.6380440187454224 and perplexity is 38.0174026263941
At time: 662.3834154605865 and batch: 1850, loss is 3.6606539583206175 and perplexity is 38.88676488141505
At time: 663.2705714702606 and batch: 1900, loss is 3.740711693763733 and perplexity is 42.127961706077386
At time: 664.1580650806427 and batch: 1950, loss is 3.683781361579895 and perplexity is 39.796595227364655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252395133085029 and perplexity of 70.27352538542226
finished 18 epochs...
Completing Train Step...
At time: 667.1112310886383 and batch: 50, loss is 3.8328930807113646 and perplexity is 46.19599383091837
At time: 667.997339963913 and batch: 100, loss is 3.841111879348755 and perplexity is 46.57723392382812
At time: 668.8846423625946 and batch: 150, loss is 3.8086135959625245 and perplexity is 45.08788548772855
At time: 669.7721109390259 and batch: 200, loss is 3.8030901622772215 and perplexity is 44.839532055486806
At time: 670.6834945678711 and batch: 250, loss is 3.7909845685958863 and perplexity is 44.29999519543474
At time: 671.5871143341064 and batch: 300, loss is 3.7894963026046753 and perplexity is 44.23411405566466
At time: 672.4823861122131 and batch: 350, loss is 3.8030259466171263 and perplexity is 44.836652747786815
At time: 673.385192155838 and batch: 400, loss is 3.7735056495666504 and perplexity is 43.53240701447251
At time: 674.2758316993713 and batch: 450, loss is 3.819853081703186 and perplexity is 45.59750872039369
At time: 675.1680910587311 and batch: 500, loss is 3.828942198753357 and perplexity is 46.01383898545078
At time: 676.0739891529083 and batch: 550, loss is 3.796382269859314 and perplexity is 44.539759842307774
At time: 676.9613471031189 and batch: 600, loss is 3.7876106786727903 and perplexity is 44.15078374110388
At time: 677.8485753536224 and batch: 650, loss is 3.8107011556625365 and perplexity is 45.18210745320295
At time: 678.735533952713 and batch: 700, loss is 3.8336064529418947 and perplexity is 46.22896052744394
At time: 679.6219439506531 and batch: 750, loss is 3.80398841381073 and perplexity is 44.87982732885363
At time: 680.5093991756439 and batch: 800, loss is 3.7677711963653566 and perplexity is 43.283486856330086
At time: 681.4248549938202 and batch: 850, loss is 3.7679427814483644 and perplexity is 43.29091429421574
At time: 682.3261382579803 and batch: 900, loss is 3.7286433792114257 and perplexity is 41.62260375563826
At time: 683.2138221263885 and batch: 950, loss is 3.825950336456299 and perplexity is 45.876377650677156
At time: 684.1008627414703 and batch: 1000, loss is 3.7973689222335816 and perplexity is 44.58372678858471
At time: 684.98979139328 and batch: 1050, loss is 3.7564012670516966 and perplexity is 42.79414383973142
At time: 685.876630783081 and batch: 1100, loss is 3.7591148710250852 and perplexity is 42.9104279015826
At time: 686.7638320922852 and batch: 1150, loss is 3.7445371627807615 and perplexity is 42.28942956657046
At time: 687.6502439975739 and batch: 1200, loss is 3.7987231969833375 and perplexity is 44.64414630710425
At time: 688.5362875461578 and batch: 1250, loss is 3.7789368295669554 and perplexity is 43.76948257005735
At time: 689.4340431690216 and batch: 1300, loss is 3.790024037361145 and perplexity is 44.25746409584544
At time: 690.3501667976379 and batch: 1350, loss is 3.673611011505127 and perplexity is 39.3939011630056
At time: 691.2366766929626 and batch: 1400, loss is 3.701104645729065 and perplexity is 40.49200898892372
At time: 692.1239800453186 and batch: 1450, loss is 3.6179898023605346 and perplexity is 37.26258731941811
At time: 693.0115392208099 and batch: 1500, loss is 3.6312418842315672 and perplexity is 37.759680663303456
At time: 693.8987939357758 and batch: 1550, loss is 3.642593207359314 and perplexity is 38.19074494606043
At time: 694.7855145931244 and batch: 1600, loss is 3.7378356409072877 and perplexity is 42.00697352907039
At time: 695.6721241474152 and batch: 1650, loss is 3.6686688804626466 and perplexity is 39.19969164092903
At time: 696.5608518123627 and batch: 1700, loss is 3.6881018257141114 and perplexity is 39.96890695499127
At time: 697.4635417461395 and batch: 1750, loss is 3.678616147041321 and perplexity is 39.591567237722785
At time: 698.3722860813141 and batch: 1800, loss is 3.6415191459655762 and perplexity is 38.14974776200332
At time: 699.25816822052 and batch: 1850, loss is 3.6642789030075074 and perplexity is 39.027983052555356
At time: 700.1434011459351 and batch: 1900, loss is 3.7446724510192873 and perplexity is 42.29515121603199
At time: 701.0296187400818 and batch: 1950, loss is 3.687167773246765 and perplexity is 39.93159132892213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251792162518169 and perplexity of 70.23116529021407
finished 19 epochs...
Completing Train Step...
At time: 704.0399475097656 and batch: 50, loss is 3.8326574993133544 and perplexity is 46.18511219591493
At time: 704.9507024288177 and batch: 100, loss is 3.8394269275665285 and perplexity is 46.49881961123679
At time: 705.8603727817535 and batch: 150, loss is 3.806247410774231 and perplexity is 44.9813253211776
At time: 706.7483174800873 and batch: 200, loss is 3.800340523719788 and perplexity is 44.7164088989119
At time: 707.6350538730621 and batch: 250, loss is 3.7878117465972903 and perplexity is 44.15966194008636
At time: 708.5215089321136 and batch: 300, loss is 3.786050601005554 and perplexity is 44.081958789492475
At time: 709.4061856269836 and batch: 350, loss is 3.7994236898422242 and perplexity is 44.67543016856502
At time: 710.2923374176025 and batch: 400, loss is 3.7697465658187865 and perplexity is 43.369072237647856
At time: 711.2004909515381 and batch: 450, loss is 3.816100263595581 and perplexity is 45.42671025225346
At time: 712.108850479126 and batch: 500, loss is 3.8252959203720094 and perplexity is 45.84636523262925
At time: 712.9956121444702 and batch: 550, loss is 3.7928152322769164 and perplexity is 44.381167864968134
At time: 713.8924784660339 and batch: 600, loss is 3.7843703508377073 and perplexity is 44.007952262988226
At time: 714.7921013832092 and batch: 650, loss is 3.8077640390396117 and perplexity is 45.04959702888847
At time: 715.7032468318939 and batch: 700, loss is 3.8309644412994386 and perplexity is 46.10698427779942
At time: 716.5896983146667 and batch: 750, loss is 3.8013692712783813 and perplexity is 44.762434465681295
At time: 717.483983039856 and batch: 800, loss is 3.7653623962402345 and perplexity is 43.17935105928772
At time: 718.3839719295502 and batch: 850, loss is 3.765422477722168 and perplexity is 43.181945416623925
At time: 719.2704267501831 and batch: 900, loss is 3.726452126502991 and perplexity is 41.531497966784265
At time: 720.1571235656738 and batch: 950, loss is 3.8240329599380494 and perplexity is 45.78849963597073
At time: 721.0433881282806 and batch: 1000, loss is 3.7956911754608154 and perplexity is 44.5089892976705
At time: 721.930278301239 and batch: 1050, loss is 3.7549229717254637 and perplexity is 42.73092819411214
At time: 722.8523926734924 and batch: 1100, loss is 3.7579093742370606 and perplexity is 42.858730685249235
At time: 723.7452733516693 and batch: 1150, loss is 3.743475289344788 and perplexity is 42.2445473785102
At time: 724.6313424110413 and batch: 1200, loss is 3.797707099914551 and perplexity is 44.59880655959632
At time: 725.5179674625397 and batch: 1250, loss is 3.7781692218780516 and perplexity is 43.73589767035993
At time: 726.404375076294 and batch: 1300, loss is 3.789356212615967 and perplexity is 44.22791773315758
At time: 727.3109681606293 and batch: 1350, loss is 3.6731151294708253 and perplexity is 39.374371277817616
At time: 728.2038743495941 and batch: 1400, loss is 3.70096351146698 and perplexity is 40.4862945823735
At time: 729.0903856754303 and batch: 1450, loss is 3.6181623554229736 and perplexity is 37.26901764774494
At time: 729.9770822525024 and batch: 1500, loss is 3.631838502883911 and perplexity is 37.78221551478165
At time: 730.8644647598267 and batch: 1550, loss is 3.6434539794921874 and perplexity is 38.22363262741287
At time: 731.7761957645416 and batch: 1600, loss is 3.7390124940872194 and perplexity is 42.05643867034275
At time: 732.6646661758423 and batch: 1650, loss is 3.6699430561065673 and perplexity is 39.249670767598204
At time: 733.5513496398926 and batch: 1700, loss is 3.6893563938140868 and perplexity is 40.01908213815892
At time: 734.437597990036 and batch: 1750, loss is 3.6799249839782715 and perplexity is 39.64342006936373
At time: 735.3493208885193 and batch: 1800, loss is 3.643101887702942 and perplexity is 38.210176769197226
At time: 736.2586727142334 and batch: 1850, loss is 3.6658591651916503 and perplexity is 39.08970625487319
At time: 737.1444749832153 and batch: 1900, loss is 3.7463505029678346 and perplexity is 42.36618425884386
At time: 738.0387918949127 and batch: 1950, loss is 3.6885498571395874 and perplexity is 39.98681829347067
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251524175599564 and perplexity of 70.21234677830806
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
2298.7570543289185


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}, 'best_accuracy': -70.21234677830806}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.7054039444822918, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3700134384042031, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4315226078033447 and batch: 50, loss is 7.5769010925292966 and perplexity is 1952.5687503275474
At time: 2.411351442337036 and batch: 100, loss is 6.7443177604675295 and perplexity is 849.2195578433674
At time: 3.3657970428466797 and batch: 150, loss is 6.515447931289673 and perplexity is 675.4964697715275
At time: 4.321103811264038 and batch: 200, loss is 6.398842630386352 and perplexity is 601.1488836447072
At time: 5.282323598861694 and batch: 250, loss is 6.338160848617553 and perplexity is 565.7548451625323
At time: 6.23979926109314 and batch: 300, loss is 6.2598362159729 and perplexity is 523.13325222028
At time: 7.205008506774902 and batch: 350, loss is 6.207910852432251 and perplexity is 496.66256529015936
At time: 8.161017656326294 and batch: 400, loss is 6.158563165664673 and perplexity is 472.74832558208203
At time: 9.116677045822144 and batch: 450, loss is 6.072514133453369 and perplexity is 433.7698671558864
At time: 10.072227239608765 and batch: 500, loss is 6.052215919494629 and perplexity is 425.0538724064473
At time: 11.027704238891602 and batch: 550, loss is 6.001673583984375 and perplexity is 404.1045307541677
At time: 11.982325077056885 and batch: 600, loss is 6.035678281784057 and perplexity is 418.0822910895921
At time: 12.949217557907104 and batch: 650, loss is 6.098423900604248 and perplexity is 445.15560740493754
At time: 13.905004501342773 and batch: 700, loss is 6.011460752487182 and perplexity is 408.07898750275046
At time: 14.860224485397339 and batch: 750, loss is 5.941832532882691 and perplexity is 380.63181112399303
At time: 15.81656813621521 and batch: 800, loss is 5.942779321670532 and perplexity is 380.9923597098069
At time: 16.770562648773193 and batch: 850, loss is 5.975023527145385 and perplexity is 393.4773583812131
At time: 17.725334882736206 and batch: 900, loss is 5.959431571960449 and perplexity is 387.38985838332763
At time: 18.67993688583374 and batch: 950, loss is 5.982044878005982 and perplexity is 396.24982280278186
At time: 19.634954690933228 and batch: 1000, loss is 5.958577051162719 and perplexity is 387.0589670893906
At time: 20.59082841873169 and batch: 1050, loss is 5.850299625396729 and perplexity is 347.33843630584914
At time: 21.546003818511963 and batch: 1100, loss is 5.931657428741455 and perplexity is 376.7784800741383
At time: 22.505841970443726 and batch: 1150, loss is 5.8325635528564455 and perplexity is 341.232325877128
At time: 23.46636176109314 and batch: 1200, loss is 5.912672739028931 and perplexity is 369.69292884764656
At time: 24.421828985214233 and batch: 1250, loss is 5.843149013519287 and perplexity is 344.86361275410997
At time: 25.376587390899658 and batch: 1300, loss is 5.870287322998047 and perplexity is 354.3507787706563
At time: 26.332459926605225 and batch: 1350, loss is 5.83282166481018 and perplexity is 341.32041338716823
At time: 27.287854194641113 and batch: 1400, loss is 5.842556200027466 and perplexity is 344.6592335369951
At time: 28.25294327735901 and batch: 1450, loss is 5.830997457504273 and perplexity is 340.6983417617212
At time: 29.2149977684021 and batch: 1500, loss is 5.8082476997375485 and perplexity is 333.03503669218446
At time: 30.182865858078003 and batch: 1550, loss is 5.776938829421997 and perplexity is 322.7696236981918
At time: 31.150543451309204 and batch: 1600, loss is 5.789098997116088 and perplexity is 326.71851739367537
At time: 32.124239921569824 and batch: 1650, loss is 5.783412752151489 and perplexity is 324.86598782930054
At time: 33.085217237472534 and batch: 1700, loss is 5.802204275131226 and perplexity is 331.028434039849
At time: 34.05197024345398 and batch: 1750, loss is 5.806662483215332 and perplexity is 332.5075222722965
At time: 35.01402997970581 and batch: 1800, loss is 5.805880422592163 and perplexity is 332.24758288964637
At time: 35.97273397445679 and batch: 1850, loss is 5.76597843170166 and perplexity is 319.25125682236575
At time: 36.93123435974121 and batch: 1900, loss is 5.759333362579346 and perplexity is 317.1368431464085
At time: 37.889018535614014 and batch: 1950, loss is 5.688259725570679 and perplexity is 295.37913234394364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.1163063226744185 and perplexity of 166.71842685574393
finished 1 epochs...
Completing Train Step...
At time: 40.89157009124756 and batch: 50, loss is 5.369238033294677 and perplexity is 214.6992117110617
At time: 41.80834436416626 and batch: 100, loss is 5.258264141082764 and perplexity is 192.14766040966103
At time: 42.69742012023926 and batch: 150, loss is 5.160422992706299 and perplexity is 174.238141482724
At time: 43.58589243888855 and batch: 200, loss is 5.109530706405639 and perplexity is 165.59262507788617
At time: 44.47462248802185 and batch: 250, loss is 5.106705083847046 and perplexity is 165.12538325632212
At time: 45.36325144767761 and batch: 300, loss is 5.102509040832519 and perplexity is 164.43396167720715
At time: 46.2822482585907 and batch: 350, loss is 5.095137395858765 and perplexity is 163.2262696972942
At time: 47.19528150558472 and batch: 400, loss is 5.037184972763061 and perplexity is 154.035789191825
At time: 48.0898220539093 and batch: 450, loss is 4.994155864715577 and perplexity is 147.548342038159
At time: 49.005404472351074 and batch: 500, loss is 4.976661853790283 and perplexity is 144.98957652327695
At time: 49.894190073013306 and batch: 550, loss is 4.922645425796508 and perplexity is 137.36552324775508
At time: 50.78307032585144 and batch: 600, loss is 4.911710777282715 and perplexity is 135.87166184244862
At time: 51.67241811752319 and batch: 650, loss is 4.986496639251709 and perplexity is 146.4225528598175
At time: 52.587321043014526 and batch: 700, loss is 4.967405939102173 and perplexity is 143.65375702481285
At time: 53.50063157081604 and batch: 750, loss is 4.927481708526611 and perplexity is 138.0314708128821
At time: 54.389949321746826 and batch: 800, loss is 4.903545713424682 and perplexity is 134.76677790932752
At time: 55.30018925666809 and batch: 850, loss is 4.8907753849029545 and perplexity is 133.05670422301807
At time: 56.20081353187561 and batch: 900, loss is 4.897127571105957 and perplexity is 133.9045953137939
At time: 57.086880922317505 and batch: 950, loss is 4.951474742889404 and perplexity is 141.38331428953268
At time: 57.9730281829834 and batch: 1000, loss is 4.91753306388855 and perplexity is 136.66505303349476
At time: 58.861056089401245 and batch: 1050, loss is 4.82340238571167 and perplexity is 124.38758617200672
At time: 59.76469302177429 and batch: 1100, loss is 4.889392776489258 and perplexity is 132.87286602166807
At time: 60.67162346839905 and batch: 1150, loss is 4.810358047485352 and perplexity is 122.77556913220343
At time: 61.560659885406494 and batch: 1200, loss is 4.896084470748901 and perplexity is 133.76499220529482
At time: 62.45096158981323 and batch: 1250, loss is 4.848460350036621 and perplexity is 127.54386568750922
At time: 63.36110067367554 and batch: 1300, loss is 4.8706467247009275 and perplexity is 130.40522591188613
At time: 64.24996614456177 and batch: 1350, loss is 4.765845117568969 and perplexity is 117.43031778855416
At time: 65.13916039466858 and batch: 1400, loss is 4.781412153244019 and perplexity is 119.27266245259231
At time: 66.02652525901794 and batch: 1450, loss is 4.722067623138428 and perplexity is 112.40041427106475
At time: 66.91298532485962 and batch: 1500, loss is 4.707601156234741 and perplexity is 110.78608239107854
At time: 67.79904437065125 and batch: 1550, loss is 4.708389892578125 and perplexity is 110.87349786995225
At time: 68.70678734779358 and batch: 1600, loss is 4.767948389053345 and perplexity is 117.67756555079704
At time: 69.60089135169983 and batch: 1650, loss is 4.729678821563721 and perplexity is 113.25918010001698
At time: 70.51891279220581 and batch: 1700, loss is 4.7493511581420895 and perplexity is 115.50931293025513
At time: 71.40831303596497 and batch: 1750, loss is 4.74822286605835 and perplexity is 115.3790581833959
At time: 72.29763150215149 and batch: 1800, loss is 4.711333827972412 and perplexity is 111.20038321319974
At time: 73.18667817115784 and batch: 1850, loss is 4.720929279327392 and perplexity is 112.27253675322086
At time: 74.07611751556396 and batch: 1900, loss is 4.797532873153687 and perplexity is 121.21100540127388
At time: 74.97646260261536 and batch: 1950, loss is 4.717094373703003 and perplexity is 111.84280668434256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.55146001771439 and perplexity of 94.77067421819201
finished 2 epochs...
Completing Train Step...
At time: 77.95879864692688 and batch: 50, loss is 4.661692447662354 and perplexity is 105.81501707324495
At time: 78.89883041381836 and batch: 100, loss is 4.609817705154419 and perplexity is 100.46583356336161
At time: 79.8156385421753 and batch: 150, loss is 4.553412036895752 and perplexity is 94.95584906572488
At time: 80.70319175720215 and batch: 200, loss is 4.556984748840332 and perplexity is 95.29570570532582
At time: 81.59002423286438 and batch: 250, loss is 4.554639253616333 and perplexity is 95.07245200531962
At time: 82.4757080078125 and batch: 300, loss is 4.578933000564575 and perplexity is 97.41040189322553
At time: 83.36166381835938 and batch: 350, loss is 4.588159961700439 and perplexity is 98.31336327424616
At time: 84.24801898002625 and batch: 400, loss is 4.544212675094604 and perplexity is 94.08632153641118
At time: 85.13469886779785 and batch: 450, loss is 4.544650764465332 and perplexity is 94.12754878375719
At time: 86.02071452140808 and batch: 500, loss is 4.54083134651184 and perplexity is 93.76872202490908
At time: 86.92477416992188 and batch: 550, loss is 4.500687294006347 and perplexity is 90.07902080103838
At time: 87.81448078155518 and batch: 600, loss is 4.48091911315918 and perplexity is 88.31580760478242
At time: 88.70102429389954 and batch: 650, loss is 4.554110050201416 and perplexity is 95.02215264952316
At time: 89.58776473999023 and batch: 700, loss is 4.56225959777832 and perplexity is 95.79970424684075
At time: 90.47306561470032 and batch: 750, loss is 4.53524959564209 and perplexity is 93.24678639164429
At time: 91.36015796661377 and batch: 800, loss is 4.512839937210083 and perplexity is 91.18039776675978
At time: 92.24726390838623 and batch: 850, loss is 4.501664342880249 and perplexity is 90.16707541670085
At time: 93.15922737121582 and batch: 900, loss is 4.494505605697632 and perplexity is 89.52389793730426
At time: 94.04589009284973 and batch: 950, loss is 4.571116018295288 and perplexity is 96.65191491071728
At time: 94.93280220031738 and batch: 1000, loss is 4.546195964813233 and perplexity is 94.2731071343301
At time: 95.82030773162842 and batch: 1050, loss is 4.471530313491821 and perplexity is 87.49050852604836
At time: 96.70701503753662 and batch: 1100, loss is 4.5235181903839115 and perplexity is 92.15926211804616
At time: 97.61284399032593 and batch: 1150, loss is 4.466278715133667 and perplexity is 87.03224786878447
At time: 98.50385785102844 and batch: 1200, loss is 4.554062995910645 and perplexity is 95.01768155471561
At time: 99.39042901992798 and batch: 1250, loss is 4.528142204284668 and perplexity is 92.58639459936805
At time: 100.27462983131409 and batch: 1300, loss is 4.534700679779053 and perplexity is 93.19561579687712
At time: 101.16108512878418 and batch: 1350, loss is 4.420630540847778 and perplexity is 83.14869748281703
At time: 102.04757165908813 and batch: 1400, loss is 4.437524223327637 and perplexity is 84.56531744928732
At time: 102.933340549469 and batch: 1450, loss is 4.377652087211609 and perplexity is 79.6508005546678
At time: 103.81944155693054 and batch: 1500, loss is 4.378672428131104 and perplexity is 79.73211300189833
At time: 104.7058334350586 and batch: 1550, loss is 4.392223739624024 and perplexity is 80.81994180749507
At time: 105.59149694442749 and batch: 1600, loss is 4.4629057598114015 and perplexity is 86.73918650441341
At time: 106.47795009613037 and batch: 1650, loss is 4.423205451965332 and perplexity is 83.36307387000109
At time: 107.36467003822327 and batch: 1700, loss is 4.440013217926025 and perplexity is 84.77606223014153
At time: 108.25304460525513 and batch: 1750, loss is 4.441356210708618 and perplexity is 84.88999235639795
At time: 109.14087629318237 and batch: 1800, loss is 4.405690317153931 and perplexity is 81.91567112265398
At time: 110.0278012752533 and batch: 1850, loss is 4.432644634246826 and perplexity is 84.15367858068389
At time: 110.91449522972107 and batch: 1900, loss is 4.516465797424316 and perplexity is 91.51160523647223
At time: 111.80168795585632 and batch: 1950, loss is 4.444704656600952 and perplexity is 85.17471833133352
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429979900981104 and perplexity of 83.9297299880872
finished 3 epochs...
Completing Train Step...
At time: 114.74920558929443 and batch: 50, loss is 4.408817462921142 and perplexity is 82.17223431304247
At time: 115.66363215446472 and batch: 100, loss is 4.360393495559692 and perplexity is 78.28793431740738
At time: 116.54985237121582 and batch: 150, loss is 4.318705978393555 and perplexity is 75.09139550668475
At time: 117.43600010871887 and batch: 200, loss is 4.3264133262634275 and perplexity is 75.67238708994883
At time: 118.3221287727356 and batch: 250, loss is 4.318801488876343 and perplexity is 75.09856786463502
At time: 119.20972990989685 and batch: 300, loss is 4.340501165390014 and perplexity is 76.7459921369662
At time: 120.10819911956787 and batch: 350, loss is 4.355952291488648 and perplexity is 77.94101257017334
At time: 121.01932549476624 and batch: 400, loss is 4.312507591247559 and perplexity is 74.62738949603896
At time: 121.90647315979004 and batch: 450, loss is 4.3292966651916505 and perplexity is 75.89089108859913
At time: 122.79337239265442 and batch: 500, loss is 4.33375675201416 and perplexity is 76.23012700035133
At time: 123.68008470535278 and batch: 550, loss is 4.29259370803833 and perplexity is 73.1559678622837
At time: 124.56785082817078 and batch: 600, loss is 4.283185601234436 and perplexity is 72.47093618171377
At time: 125.45560669898987 and batch: 650, loss is 4.34808916091919 and perplexity is 77.3305554091179
At time: 126.36929750442505 and batch: 700, loss is 4.363180274963379 and perplexity is 78.50640980041588
At time: 127.25577068328857 and batch: 750, loss is 4.3419835567474365 and perplexity is 76.85984409815948
At time: 128.14256858825684 and batch: 800, loss is 4.315617027282715 and perplexity is 74.85979973527739
At time: 129.0293529033661 and batch: 850, loss is 4.307497844696045 and perplexity is 74.25446010968419
At time: 129.91708278656006 and batch: 900, loss is 4.292708044052124 and perplexity is 73.16433270222642
At time: 130.80463409423828 and batch: 950, loss is 4.377655000686645 and perplexity is 79.65103261562489
At time: 131.69365429878235 and batch: 1000, loss is 4.353569765090942 and perplexity is 77.75553708811363
At time: 132.58405351638794 and batch: 1050, loss is 4.28756308555603 and perplexity is 72.78887194031974
At time: 133.47406816482544 and batch: 1100, loss is 4.330767049789428 and perplexity is 76.00256196541645
At time: 134.3633999824524 and batch: 1150, loss is 4.282192597389221 and perplexity is 72.39900798181897
At time: 135.25160264968872 and batch: 1200, loss is 4.367831363677978 and perplexity is 78.87240054499499
At time: 136.15640497207642 and batch: 1250, loss is 4.353693943023682 and perplexity is 77.76519320949451
At time: 137.0517132282257 and batch: 1300, loss is 4.353909692764282 and perplexity is 77.78197283979253
At time: 137.94129705429077 and batch: 1350, loss is 4.240128517150879 and perplexity is 69.41677251133956
At time: 138.8524992465973 and batch: 1400, loss is 4.25676546573639 and perplexity is 70.58131615206379
At time: 139.76104044914246 and batch: 1450, loss is 4.193060374259948 and perplexity is 66.22515490719887
At time: 140.6470227241516 and batch: 1500, loss is 4.202187037467956 and perplexity is 66.83233614663371
At time: 141.53213381767273 and batch: 1550, loss is 4.215984058380127 and perplexity is 67.76081366942687
At time: 142.420254945755 and batch: 1600, loss is 4.293900990486145 and perplexity is 73.25166591358548
At time: 143.3213129043579 and batch: 1650, loss is 4.256259722709656 and perplexity is 70.54562916858436
At time: 144.21798872947693 and batch: 1700, loss is 4.27248601436615 and perplexity is 71.6996606275364
At time: 145.12519574165344 and batch: 1750, loss is 4.27189218044281 and perplexity is 71.65709557630036
At time: 146.01201462745667 and batch: 1800, loss is 4.232119560241699 and perplexity is 68.86303695350267
At time: 146.90071415901184 and batch: 1850, loss is 4.262108154296875 and perplexity is 70.95941928670851
At time: 147.7877321243286 and batch: 1900, loss is 4.349368991851807 and perplexity is 77.42958880545116
At time: 148.6752963066101 and batch: 1950, loss is 4.278299074172974 and perplexity is 72.11766881910323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384017021711482 and perplexity of 80.15938953381875
finished 4 epochs...
Completing Train Step...
At time: 151.6577112674713 and batch: 50, loss is 4.2533871459960935 and perplexity is 70.34327221907058
At time: 152.54567003250122 and batch: 100, loss is 4.2083598375320435 and perplexity is 67.24615469105915
At time: 153.4340341091156 and batch: 150, loss is 4.173829374313354 and perplexity is 64.96374690081385
At time: 154.32204675674438 and batch: 200, loss is 4.180495953559875 and perplexity is 65.39827968195213
At time: 155.2279770374298 and batch: 250, loss is 4.174166574478149 and perplexity is 64.98565638070703
At time: 156.12065052986145 and batch: 300, loss is 4.191189770698547 and perplexity is 66.1013896904922
At time: 157.00885009765625 and batch: 350, loss is 4.209159979820251 and perplexity is 67.29998271531423
At time: 157.8966841697693 and batch: 400, loss is 4.166779408454895 and perplexity is 64.50736533062519
At time: 158.8073709011078 and batch: 450, loss is 4.19045741558075 and perplexity is 66.05299772167474
At time: 159.69514083862305 and batch: 500, loss is 4.200245614051819 and perplexity is 66.70271215252629
At time: 160.62466287612915 and batch: 550, loss is 4.16061851978302 and perplexity is 64.11116436253629
At time: 161.5126075744629 and batch: 600, loss is 4.154981551170349 and perplexity is 63.75078840952826
At time: 162.39955115318298 and batch: 650, loss is 4.214213757514954 and perplexity is 67.6409627597483
At time: 163.2874653339386 and batch: 700, loss is 4.231207766532898 and perplexity is 68.80027668619604
At time: 164.17500925064087 and batch: 750, loss is 4.212761392593384 and perplexity is 67.5427947033516
At time: 165.08464336395264 and batch: 800, loss is 4.186204113960266 and perplexity is 65.77265102160015
At time: 165.97311353683472 and batch: 850, loss is 4.1810899925231935 and perplexity is 65.43714034944975
At time: 166.86103081703186 and batch: 900, loss is 4.162783532142639 and perplexity is 64.25011618770473
At time: 167.7494456768036 and batch: 950, loss is 4.250681772232055 and perplexity is 70.15322456681265
At time: 168.63864874839783 and batch: 1000, loss is 4.227574119567871 and perplexity is 68.5507344184411
At time: 169.52668714523315 and batch: 1050, loss is 4.165848126411438 and perplexity is 64.44731874411578
At time: 170.4379780292511 and batch: 1100, loss is 4.208070216178894 and perplexity is 67.22668158879263
At time: 171.3401300907135 and batch: 1150, loss is 4.155584039688111 and perplexity is 63.78920910039363
At time: 172.2363796234131 and batch: 1200, loss is 4.2499466276168825 and perplexity is 70.10167075361123
At time: 173.12462306022644 and batch: 1250, loss is 4.235123662948609 and perplexity is 69.07021963243172
At time: 174.01288533210754 and batch: 1300, loss is 4.235885920524598 and perplexity is 69.12288900188446
At time: 174.90991067886353 and batch: 1350, loss is 4.11699312210083 and perplexity is 61.374419148898255
At time: 175.81203627586365 and batch: 1400, loss is 4.140501642227173 and perplexity is 62.834333899753325
At time: 176.6997458934784 and batch: 1450, loss is 4.072766847610474 and perplexity is 58.7192051306034
At time: 177.605642080307 and batch: 1500, loss is 4.084980392456055 and perplexity is 59.44077225226357
At time: 178.501567363739 and batch: 1550, loss is 4.095765838623047 and perplexity is 60.08533721357536
At time: 179.3900249004364 and batch: 1600, loss is 4.182123384475708 and perplexity is 65.50479751584714
At time: 180.27729296684265 and batch: 1650, loss is 4.14004958152771 and perplexity is 62.805935386229855
At time: 181.16538214683533 and batch: 1700, loss is 4.158359522819519 and perplexity is 63.96650089560004
At time: 182.05064821243286 and batch: 1750, loss is 4.15909248828888 and perplexity is 64.01340331878085
At time: 182.93561220169067 and batch: 1800, loss is 4.117257218360901 and perplexity is 61.3906300439837
At time: 183.8205828666687 and batch: 1850, loss is 4.148001952171326 and perplexity is 63.30738266772779
At time: 184.73312497138977 and batch: 1900, loss is 4.2337695455551145 and perplexity is 68.97675374283023
At time: 185.64702463150024 and batch: 1950, loss is 4.163137216567993 and perplexity is 64.27284447221066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365008402979651 and perplexity of 78.65006083386092
finished 5 epochs...
Completing Train Step...
At time: 188.6567873954773 and batch: 50, loss is 4.141854591369629 and perplexity is 62.9194030920888
At time: 189.54583501815796 and batch: 100, loss is 4.09965968132019 and perplexity is 60.319756164160786
At time: 190.4626019001007 and batch: 150, loss is 4.067979259490967 and perplexity is 58.43875364052972
At time: 191.3714153766632 and batch: 200, loss is 4.077843770980835 and perplexity is 59.01807606588468
At time: 192.27872729301453 and batch: 250, loss is 4.070132718086243 and perplexity is 58.564734675640395
At time: 193.16769409179688 and batch: 300, loss is 4.084141058921814 and perplexity is 59.3909025503953
At time: 194.07891869544983 and batch: 350, loss is 4.09866060256958 and perplexity is 60.25952207184626
At time: 194.98872590065002 and batch: 400, loss is 4.062160949707032 and perplexity is 58.09972610848214
At time: 195.91704201698303 and batch: 450, loss is 4.092304892539978 and perplexity is 59.87774454183287
At time: 196.8418414592743 and batch: 500, loss is 4.105081973075866 and perplexity is 60.64771582365816
At time: 197.76217222213745 and batch: 550, loss is 4.065681233406067 and perplexity is 58.304614047468405
At time: 198.6576771736145 and batch: 600, loss is 4.060782370567321 and perplexity is 58.01968622138164
At time: 199.54674816131592 and batch: 650, loss is 4.118357887268067 and perplexity is 61.45823800182751
At time: 200.46408653259277 and batch: 700, loss is 4.139203019142151 and perplexity is 62.752788742890665
At time: 201.37834310531616 and batch: 750, loss is 4.116261811256408 and perplexity is 61.32955177860148
At time: 202.2697949409485 and batch: 800, loss is 4.092804808616638 and perplexity is 59.907685872416124
At time: 203.16767740249634 and batch: 850, loss is 4.08809220790863 and perplexity is 59.62602905887504
At time: 204.09293007850647 and batch: 900, loss is 4.068359045982361 and perplexity is 58.46095210480792
At time: 205.0261127948761 and batch: 950, loss is 4.159590892791748 and perplexity is 64.04531583925016
At time: 205.91549444198608 and batch: 1000, loss is 4.134322123527527 and perplexity is 62.44724520116019
At time: 206.82750582695007 and batch: 1050, loss is 4.074490647315979 and perplexity is 58.82051257089679
At time: 207.7200071811676 and batch: 1100, loss is 4.1167854309082035 and perplexity is 61.361673546209
At time: 208.60972929000854 and batch: 1150, loss is 4.067131037712097 and perplexity is 58.38920563378178
At time: 209.49953436851501 and batch: 1200, loss is 4.160432057380676 and perplexity is 64.09921115525871
At time: 210.38960003852844 and batch: 1250, loss is 4.147574744224548 and perplexity is 63.280343026948415
At time: 211.30205941200256 and batch: 1300, loss is 4.144605226516724 and perplexity is 63.09270965596134
At time: 212.2020878791809 and batch: 1350, loss is 4.027775049209595 and perplexity is 56.135872642133776
At time: 213.08857202529907 and batch: 1400, loss is 4.055398912429809 and perplexity is 57.70817891506067
At time: 213.98768067359924 and batch: 1450, loss is 3.981208209991455 and perplexity is 53.58173312001158
At time: 214.88488960266113 and batch: 1500, loss is 3.9972598791122436 and perplexity is 54.44874928334148
At time: 215.7711865901947 and batch: 1550, loss is 4.005359497070312 and perplexity is 54.89155420537554
At time: 216.65850639343262 and batch: 1600, loss is 4.09636085987091 and perplexity is 60.12109990462787
At time: 217.54464960098267 and batch: 1650, loss is 4.054255328178406 and perplexity is 57.64222247103963
At time: 218.43230199813843 and batch: 1700, loss is 4.077046566009521 and perplexity is 58.97104531131405
At time: 219.3204517364502 and batch: 1750, loss is 4.072072763442993 and perplexity is 58.67846320079501
At time: 220.20798802375793 and batch: 1800, loss is 4.029474492073059 and perplexity is 56.23135345939666
At time: 221.09536361694336 and batch: 1850, loss is 4.059605374336242 and perplexity is 57.95143744152788
At time: 221.99619221687317 and batch: 1900, loss is 4.145990796089173 and perplexity is 63.1801895854729
At time: 222.89427781105042 and batch: 1950, loss is 4.074804773330689 and perplexity is 58.83899252645928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361874886446221 and perplexity of 78.40399529444232
finished 6 epochs...
Completing Train Step...
At time: 225.86263942718506 and batch: 50, loss is 4.059645833969117 and perplexity is 57.95378218284467
At time: 226.74935603141785 and batch: 100, loss is 4.017084002494812 and perplexity is 55.5389181255586
At time: 227.68561959266663 and batch: 150, loss is 3.989096164703369 and perplexity is 54.006054718926684
At time: 228.58238625526428 and batch: 200, loss is 3.9971250534057616 and perplexity is 54.44140868711395
At time: 229.48972392082214 and batch: 250, loss is 3.9901080894470216 and perplexity is 54.060732442208575
At time: 230.41378474235535 and batch: 300, loss is 4.006553406715393 and perplexity is 54.95712889871495
At time: 231.3089954853058 and batch: 350, loss is 4.017000660896302 and perplexity is 55.53428961621884
At time: 232.2002658843994 and batch: 400, loss is 3.9857401037216187 and perplexity is 53.825110904976164
At time: 233.09876537322998 and batch: 450, loss is 4.013373436927796 and perplexity is 55.3332191940291
At time: 233.98625016212463 and batch: 500, loss is 4.030916090011597 and perplexity is 56.31247492084178
At time: 234.8729636669159 and batch: 550, loss is 3.991336169242859 and perplexity is 54.1271641188197
At time: 235.7601044178009 and batch: 600, loss is 3.9900464630126953 and perplexity is 54.05740097468538
At time: 236.6548535823822 and batch: 650, loss is 4.044134817123413 and perplexity is 57.06179578280735
At time: 237.5548334121704 and batch: 700, loss is 4.064617681503296 and perplexity is 58.242637027988465
At time: 238.45126581192017 and batch: 750, loss is 4.039314632415771 and perplexity is 56.78740921561412
At time: 239.35128545761108 and batch: 800, loss is 4.019665484428406 and perplexity is 55.68247605568951
At time: 240.23809957504272 and batch: 850, loss is 4.011321105957031 and perplexity is 55.21977356837061
At time: 241.12579345703125 and batch: 900, loss is 3.995493383407593 and perplexity is 54.35265070546107
At time: 242.01287531852722 and batch: 950, loss is 4.086119375228882 and perplexity is 59.50851283821941
At time: 242.90028285980225 and batch: 1000, loss is 4.06213502407074 and perplexity is 58.09821985563975
At time: 243.78753900527954 and batch: 1050, loss is 4.008574075698853 and perplexity is 55.06829133792312
At time: 244.67452764511108 and batch: 1100, loss is 4.0430061674118045 and perplexity is 56.997429333873
At time: 245.56163001060486 and batch: 1150, loss is 3.996916637420654 and perplexity is 54.430063409601445
At time: 246.44861841201782 and batch: 1200, loss is 4.087438111305237 and perplexity is 59.587040628283866
At time: 247.33527302742004 and batch: 1250, loss is 4.075512762069702 and perplexity is 58.88066462052891
At time: 248.22282719612122 and batch: 1300, loss is 4.068945541381836 and perplexity is 58.49524924083942
At time: 249.1102273464203 and batch: 1350, loss is 3.955771484375 and perplexity is 52.235977643876396
At time: 249.99652481079102 and batch: 1400, loss is 3.9840181732177733 and perplexity is 53.73250755578298
At time: 250.88397431373596 and batch: 1450, loss is 3.9097520160675048 and perplexity is 49.886579369237026
At time: 251.7712516784668 and batch: 1500, loss is 3.9276958894729614 and perplexity is 50.78981739299991
At time: 252.68267250061035 and batch: 1550, loss is 3.9341157245635987 and perplexity is 51.11692852122621
At time: 253.58869528770447 and batch: 1600, loss is 4.025783610343933 and perplexity is 56.024192722371396
At time: 254.47809052467346 and batch: 1650, loss is 3.989141697883606 and perplexity is 54.00851384233552
At time: 255.3658390045166 and batch: 1700, loss is 4.008086986541748 and perplexity is 55.04147470188867
At time: 256.2749252319336 and batch: 1750, loss is 4.006993246078491 and perplexity is 54.98130652403334
At time: 257.16035199165344 and batch: 1800, loss is 3.9606270837783812 and perplexity is 52.490231403419
At time: 258.0468249320984 and batch: 1850, loss is 3.9928801393508913 and perplexity is 54.21079939081724
At time: 258.94912910461426 and batch: 1900, loss is 4.077606520652771 and perplexity is 59.00407566884139
At time: 259.84384393692017 and batch: 1950, loss is 4.004522938728332 and perplexity is 54.845653419820195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361736634720203 and perplexity of 78.39315655602061
finished 7 epochs...
Completing Train Step...
At time: 262.80728793144226 and batch: 50, loss is 3.99445188999176 and perplexity is 54.29607224577914
At time: 263.71920442581177 and batch: 100, loss is 3.952721061706543 and perplexity is 52.07687861657127
At time: 264.6051824092865 and batch: 150, loss is 3.924775686264038 and perplexity is 50.64171715191265
At time: 265.49385166168213 and batch: 200, loss is 3.9393877267837523 and perplexity is 51.38712870403082
At time: 266.40134048461914 and batch: 250, loss is 3.929798460006714 and perplexity is 50.89671891107351
At time: 267.30777049064636 and batch: 300, loss is 3.9421908330917357 and perplexity is 51.53137436215764
At time: 268.19584226608276 and batch: 350, loss is 3.951725935935974 and perplexity is 52.025081349281365
At time: 269.08360624313354 and batch: 400, loss is 3.9210525608062743 and perplexity is 50.45352223958521
At time: 269.971204996109 and batch: 450, loss is 3.9539381456375122 and perplexity is 52.14029913492873
At time: 270.8590741157532 and batch: 500, loss is 3.970953273773193 and perplexity is 53.03506368530205
At time: 271.74832797050476 and batch: 550, loss is 3.9327824831008913 and perplexity is 51.0488227235005
At time: 272.67922258377075 and batch: 600, loss is 3.9325079345703124 and perplexity is 51.034809268008814
At time: 273.5671591758728 and batch: 650, loss is 3.9836665391921997 and perplexity is 53.71361669937557
At time: 274.4543414115906 and batch: 700, loss is 4.002467851638794 and perplexity is 54.73305656336118
At time: 275.34232807159424 and batch: 750, loss is 3.980309081077576 and perplexity is 53.533577886633154
At time: 276.2297110557556 and batch: 800, loss is 3.960978651046753 and perplexity is 52.508688494954214
At time: 277.1170253753662 and batch: 850, loss is 3.951325354576111 and perplexity is 52.00424524500359
At time: 278.00408935546875 and batch: 900, loss is 3.934888315200806 and perplexity is 51.156436241286634
At time: 278.8908202648163 and batch: 950, loss is 4.030990595817566 and perplexity is 56.31667068347428
At time: 279.77663683891296 and batch: 1000, loss is 4.003233032226563 and perplexity is 54.77495326297909
At time: 280.6651921272278 and batch: 1050, loss is 3.947209186553955 and perplexity is 51.79062697965438
At time: 281.55269026756287 and batch: 1100, loss is 3.9834190797805786 and perplexity is 53.70032640386327
At time: 282.44122099876404 and batch: 1150, loss is 3.941069736480713 and perplexity is 51.47363508470053
At time: 283.32912039756775 and batch: 1200, loss is 4.032339425086975 and perplexity is 56.39268350988593
At time: 284.2161011695862 and batch: 1250, loss is 4.019649896621704 and perplexity is 55.68160809478093
At time: 285.1036419868469 and batch: 1300, loss is 4.013584446907044 and perplexity is 55.34489628741124
At time: 285.99122643470764 and batch: 1350, loss is 3.8987807703018187 and perplexity is 49.34225287638988
At time: 286.87907433509827 and batch: 1400, loss is 3.927257218360901 and perplexity is 50.7675422534101
At time: 287.7672760486603 and batch: 1450, loss is 3.8531981086730958 and perplexity is 47.14359273122469
At time: 288.6552941799164 and batch: 1500, loss is 3.8728368616104127 and perplexity is 48.078585092936265
At time: 289.5442011356354 and batch: 1550, loss is 3.8762888717651367 and perplexity is 48.24483964801212
At time: 290.4317388534546 and batch: 1600, loss is 3.9737860679626467 and perplexity is 53.18551410247062
At time: 291.3180694580078 and batch: 1650, loss is 3.9345725679397585 and perplexity is 51.140286286444685
At time: 292.20435214042664 and batch: 1700, loss is 3.953965301513672 and perplexity is 52.14171506966036
At time: 293.09204626083374 and batch: 1750, loss is 3.9505772972106934 and perplexity is 51.96535763321072
At time: 293.9786443710327 and batch: 1800, loss is 3.905604810714722 and perplexity is 49.680117895226175
At time: 294.86564588546753 and batch: 1850, loss is 3.933684883117676 and perplexity is 51.09490997342307
At time: 295.75174474716187 and batch: 1900, loss is 4.019200067520142 and perplexity is 55.65656651967498
At time: 296.6384925842285 and batch: 1950, loss is 3.9523518562316893 and perplexity is 52.05765509680548
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373050565497819 and perplexity of 79.28512763755857
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 299.5747797489166 and batch: 50, loss is 3.9727894496917724 and perplexity is 53.13253485179998
At time: 300.48671770095825 and batch: 100, loss is 3.9516532373428346 and perplexity is 52.02129933653447
At time: 301.3742368221283 and batch: 150, loss is 3.9257395839691163 and perplexity is 50.690554119996136
At time: 302.26164531707764 and batch: 200, loss is 3.9326328897476195 and perplexity is 51.04118673008988
At time: 303.17262268066406 and batch: 250, loss is 3.9214430904388426 and perplexity is 50.47322968300706
At time: 304.0593464374542 and batch: 300, loss is 3.9320479106903075 and perplexity is 51.01133743624952
At time: 304.946001291275 and batch: 350, loss is 3.9373716259002687 and perplexity is 51.28363143397653
At time: 305.8319981098175 and batch: 400, loss is 3.901438765525818 and perplexity is 49.473578803402624
At time: 306.7175316810608 and batch: 450, loss is 3.926984734535217 and perplexity is 50.75371080378506
At time: 307.60477209091187 and batch: 500, loss is 3.9473981714248656 and perplexity is 51.800415549525184
At time: 308.49229741096497 and batch: 550, loss is 3.9017332649230956 and perplexity is 49.48815088817116
At time: 309.37944626808167 and batch: 600, loss is 3.8878691577911377 and perplexity is 48.80677610308627
At time: 310.2666049003601 and batch: 650, loss is 3.9273559522628783 and perplexity is 50.77255497840945
At time: 311.1538915634155 and batch: 700, loss is 3.945994915962219 and perplexity is 51.727777310360395
At time: 312.0477862358093 and batch: 750, loss is 3.9080845880508424 and perplexity is 49.80346640084402
At time: 312.939248085022 and batch: 800, loss is 3.8836965799331664 and perplexity is 48.603550312370366
At time: 313.8497452735901 and batch: 850, loss is 3.873136796951294 and perplexity is 48.09300772256525
At time: 314.75080943107605 and batch: 900, loss is 3.843842387199402 and perplexity is 46.70458721717684
At time: 315.6490104198456 and batch: 950, loss is 3.9410952377319335 and perplexity is 51.47494774353721
At time: 316.5358624458313 and batch: 1000, loss is 3.9056875467300416 and perplexity is 49.6842284002625
At time: 317.45388293266296 and batch: 1050, loss is 3.839083309173584 and perplexity is 46.48284450639528
At time: 318.37052154541016 and batch: 1100, loss is 3.870360984802246 and perplexity is 47.959695677640575
At time: 319.2679874897003 and batch: 1150, loss is 3.827380437850952 and perplexity is 45.94203245766283
At time: 320.16136264801025 and batch: 1200, loss is 3.898380160331726 and perplexity is 49.32248983684042
At time: 321.04872393608093 and batch: 1250, loss is 3.884423279762268 and perplexity is 48.638883340774015
At time: 321.93670988082886 and batch: 1300, loss is 3.8765174102783204 and perplexity is 48.25586671194046
At time: 322.82443714141846 and batch: 1350, loss is 3.7573369216918944 and perplexity is 42.834203116890144
At time: 323.71162486076355 and batch: 1400, loss is 3.778866400718689 and perplexity is 43.76640004436137
At time: 324.5982165336609 and batch: 1450, loss is 3.693211569786072 and perplexity is 40.173660514008844
At time: 325.48517870903015 and batch: 1500, loss is 3.7053524684906005 and perplexity is 40.66437770305583
At time: 326.3726634979248 and batch: 1550, loss is 3.7083604097366334 and perplexity is 40.78687790633797
At time: 327.28903007507324 and batch: 1600, loss is 3.791455283164978 and perplexity is 44.3208527571779
At time: 328.19224524497986 and batch: 1650, loss is 3.752513723373413 and perplexity is 42.62810269160247
At time: 329.07985281944275 and batch: 1700, loss is 3.759521861076355 and perplexity is 42.92789557317744
At time: 329.96679282188416 and batch: 1750, loss is 3.7418773698806764 and perplexity is 42.177097897772384
At time: 330.85530638694763 and batch: 1800, loss is 3.6982185316085814 and perplexity is 40.37531291011763
At time: 331.7422432899475 and batch: 1850, loss is 3.7134689331054687 and perplexity is 40.995771740489154
At time: 332.6300616264343 and batch: 1900, loss is 3.7931182384490967 and perplexity is 44.394617670343905
At time: 333.51670956611633 and batch: 1950, loss is 3.7199203157424927 and perplexity is 41.26110611700709
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29818115234375 and perplexity of 73.56586683576182
finished 9 epochs...
Completing Train Step...
At time: 336.46865606307983 and batch: 50, loss is 3.884024353027344 and perplexity is 48.61948385959565
At time: 337.3912191390991 and batch: 100, loss is 3.853590240478516 and perplexity is 47.162082858402925
At time: 338.2890625 and batch: 150, loss is 3.822507929801941 and perplexity is 45.71872401262607
At time: 339.2029981613159 and batch: 200, loss is 3.8309707927703855 and perplexity is 46.107277125900524
At time: 340.09257674217224 and batch: 250, loss is 3.8198239374160767 and perplexity is 45.5961798328729
At time: 340.98572540283203 and batch: 300, loss is 3.832539076805115 and perplexity is 46.17964316292006
At time: 341.89303708076477 and batch: 350, loss is 3.8382402324676512 and perplexity is 46.44367241782436
At time: 342.81365990638733 and batch: 400, loss is 3.8047648906707763 and perplexity is 44.91468900914982
At time: 343.7048075199127 and batch: 450, loss is 3.8375641775131224 and perplexity is 46.412284554135645
At time: 344.5936448574066 and batch: 500, loss is 3.861346793174744 and perplexity is 47.52932044700364
At time: 345.49764943122864 and batch: 550, loss is 3.8183082485198976 and perplexity is 45.527122557285445
At time: 346.40460205078125 and batch: 600, loss is 3.8086353063583376 and perplexity is 45.088864374194834
At time: 347.29156017303467 and batch: 650, loss is 3.8500795650482176 and perplexity is 46.99680238567221
At time: 348.1859028339386 and batch: 700, loss is 3.8728594303131105 and perplexity is 48.079670176473776
At time: 349.09829545021057 and batch: 750, loss is 3.8364155101776123 and perplexity is 46.35900288621615
At time: 349.9953372478485 and batch: 800, loss is 3.8130453634262085 and perplexity is 45.28814794218213
At time: 350.8846170902252 and batch: 850, loss is 3.803341951370239 and perplexity is 44.85082358207635
At time: 351.79709243774414 and batch: 900, loss is 3.7786808109283445 and perplexity is 43.75827820104191
At time: 352.71054553985596 and batch: 950, loss is 3.875912780761719 and perplexity is 48.226698609413695
At time: 353.61834383010864 and batch: 1000, loss is 3.8435265493392943 and perplexity is 46.689838469522
At time: 354.53064823150635 and batch: 1050, loss is 3.781935634613037 and perplexity is 43.90093571792307
At time: 355.4474663734436 and batch: 1100, loss is 3.814327931404114 and perplexity is 45.34627033550414
At time: 356.3569424152374 and batch: 1150, loss is 3.775233573913574 and perplexity is 43.60769274572516
At time: 357.2558605670929 and batch: 1200, loss is 3.8482470703125 and perplexity is 46.910759853026796
At time: 358.16000294685364 and batch: 1250, loss is 3.8393351364135744 and perplexity is 46.494551626858275
At time: 359.062956571579 and batch: 1300, loss is 3.8325840282440184 and perplexity is 46.18171905098501
At time: 359.9671230316162 and batch: 1350, loss is 3.713622741699219 and perplexity is 41.00207772743533
At time: 360.85618472099304 and batch: 1400, loss is 3.7401556873321535 and perplexity is 42.10454479899821
At time: 361.7454113960266 and batch: 1450, loss is 3.6566591167449953 and perplexity is 38.73172829580687
At time: 362.6345908641815 and batch: 1500, loss is 3.671334581375122 and perplexity is 39.30432569429033
At time: 363.5225546360016 and batch: 1550, loss is 3.677342290878296 and perplexity is 39.541165384964216
At time: 364.4094195365906 and batch: 1600, loss is 3.7655581188201905 and perplexity is 43.18780306037462
At time: 365.2966732978821 and batch: 1650, loss is 3.728611249923706 and perplexity is 41.621266472509646
At time: 366.183810710907 and batch: 1700, loss is 3.7404678010940553 and perplexity is 42.11768825788909
At time: 367.0713629722595 and batch: 1750, loss is 3.726371750831604 and perplexity is 41.52815997889979
At time: 367.95772767066956 and batch: 1800, loss is 3.6857801342010497 and perplexity is 39.87621912084069
At time: 368.8454854488373 and batch: 1850, loss is 3.7049216842651367 and perplexity is 40.64686390320824
At time: 369.74319410324097 and batch: 1900, loss is 3.786715979576111 and perplexity is 44.1112997405567
At time: 370.6421072483063 and batch: 1950, loss is 3.7152528142929078 and perplexity is 41.068968594296024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298139137445494 and perplexity of 73.56277603828187
finished 10 epochs...
Completing Train Step...
At time: 373.6323597431183 and batch: 50, loss is 3.839872050285339 and perplexity is 46.51952189943122
At time: 374.5224561691284 and batch: 100, loss is 3.8094909143447877 and perplexity is 45.1274592753517
At time: 375.4105296134949 and batch: 150, loss is 3.7781433963775637 and perplexity is 43.73476818349815
At time: 376.29926109313965 and batch: 200, loss is 3.7868335819244385 and perplexity is 44.11648763804246
At time: 377.2083315849304 and batch: 250, loss is 3.775790252685547 and perplexity is 43.6319749806467
At time: 378.11607480049133 and batch: 300, loss is 3.7885648250579833 and perplexity is 44.19293015554089
At time: 379.0059096813202 and batch: 350, loss is 3.794338788986206 and perplexity is 44.44883662654323
At time: 379.9044916629791 and batch: 400, loss is 3.762294039726257 and perplexity is 43.04706447119055
At time: 380.79465198516846 and batch: 450, loss is 3.797022819519043 and perplexity is 44.56829890968832
At time: 381.6847927570343 and batch: 500, loss is 3.8213938999176027 and perplexity is 45.667820347169005
At time: 382.5746464729309 and batch: 550, loss is 3.7784325218200685 and perplexity is 43.747414845849875
At time: 383.47041511535645 and batch: 600, loss is 3.7710685539245605 and perplexity is 43.42644354904469
At time: 384.38928604125977 and batch: 650, loss is 3.81179087638855 and perplexity is 45.231370168565725
At time: 385.27879762649536 and batch: 700, loss is 3.8365389013290407 and perplexity is 46.3647235298925
At time: 386.1685426235199 and batch: 750, loss is 3.800748338699341 and perplexity is 44.73464863925958
At time: 387.05739283561707 and batch: 800, loss is 3.777192234992981 and perplexity is 43.693189138164236
At time: 387.94870138168335 and batch: 850, loss is 3.768699507713318 and perplexity is 43.323686064161706
At time: 388.8354470729828 and batch: 900, loss is 3.7441087198257446 and perplexity is 42.27131483924173
At time: 389.73498034477234 and batch: 950, loss is 3.8426318550109864 and perplexity is 46.648084017374764
At time: 390.6365399360657 and batch: 1000, loss is 3.810885257720947 and perplexity is 45.190426337926816
At time: 391.5269639492035 and batch: 1050, loss is 3.7511141300201416 and perplexity is 42.56848241421702
At time: 392.4166102409363 and batch: 1100, loss is 3.784029097557068 and perplexity is 43.99293696705948
At time: 393.30864787101746 and batch: 1150, loss is 3.746668267250061 and perplexity is 42.3796488581466
At time: 394.1977276802063 and batch: 1200, loss is 3.820261487960815 and perplexity is 45.61613483153867
At time: 395.0872941017151 and batch: 1250, loss is 3.8129680871963503 and perplexity is 45.284648380070124
At time: 395.9774043560028 and batch: 1300, loss is 3.8067729473114014 and perplexity is 45.00497086387832
At time: 396.8822705745697 and batch: 1350, loss is 3.687930898666382 and perplexity is 39.96207577155812
At time: 397.772616147995 and batch: 1400, loss is 3.716677622795105 and perplexity is 41.127525716362044
At time: 398.6627416610718 and batch: 1450, loss is 3.6330240058898924 and perplexity is 37.827033005232934
At time: 399.5600574016571 and batch: 1500, loss is 3.648358473777771 and perplexity is 38.411560684546764
At time: 400.4495961666107 and batch: 1550, loss is 3.6556635189056395 and perplexity is 38.69318626016837
At time: 401.33919763565063 and batch: 1600, loss is 3.7461266469955445 and perplexity is 42.35670139691162
At time: 402.2281262874603 and batch: 1650, loss is 3.7101470184326173 and perplexity is 40.85981323112961
At time: 403.1178731918335 and batch: 1700, loss is 3.72292941570282 and perplexity is 41.38545190040682
At time: 404.0071425437927 and batch: 1750, loss is 3.710913367271423 and perplexity is 40.8911381029096
At time: 404.90678811073303 and batch: 1800, loss is 3.6710932445526123 and perplexity is 39.2948412577343
At time: 405.7982635498047 and batch: 1850, loss is 3.6923127365112305 and perplexity is 40.13756731448102
At time: 406.6876485347748 and batch: 1900, loss is 3.7744553327560424 and perplexity is 43.573768646722684
At time: 407.57558369636536 and batch: 1950, loss is 3.703677430152893 and perplexity is 40.59632032669416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.301287699854651 and perplexity of 73.79475804289385
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 410.5514659881592 and batch: 50, loss is 3.830710096359253 and perplexity is 46.09525869087621
At time: 411.43956780433655 and batch: 100, loss is 3.8267143201828 and perplexity is 45.91143984840194
At time: 412.3282220363617 and batch: 150, loss is 3.7992963218688964 and perplexity is 44.66974031192735
At time: 413.22699093818665 and batch: 200, loss is 3.8175383949279786 and perplexity is 45.492086826377026
At time: 414.12680649757385 and batch: 250, loss is 3.816018829345703 and perplexity is 45.423011112800005
At time: 415.0141019821167 and batch: 300, loss is 3.823846311569214 and perplexity is 45.77995408473367
At time: 415.90213346481323 and batch: 350, loss is 3.8257540130615233 and perplexity is 45.86737192852266
At time: 416.7888123989105 and batch: 400, loss is 3.7938362693786623 and perplexity is 44.4265058259084
At time: 417.67643547058105 and batch: 450, loss is 3.825296335220337 and perplexity is 45.846384251921144
At time: 418.5641894340515 and batch: 500, loss is 3.845887932777405 and perplexity is 46.800221357681515
At time: 419.4533779621124 and batch: 550, loss is 3.8052436208724973 and perplexity is 44.93619617493356
At time: 420.3420865535736 and batch: 600, loss is 3.7893176794052126 and perplexity is 44.22621352231692
At time: 421.230268239975 and batch: 650, loss is 3.821557493209839 and perplexity is 45.67529190738077
At time: 422.1413016319275 and batch: 700, loss is 3.845922341346741 and perplexity is 46.801831714047914
At time: 423.02665424346924 and batch: 750, loss is 3.8082875919342043 and perplexity is 45.07318905111004
At time: 423.93282866477966 and batch: 800, loss is 3.783186101913452 and perplexity is 43.95586674006161
At time: 424.8260295391083 and batch: 850, loss is 3.772442307472229 and perplexity is 43.48614177586972
At time: 425.7134356498718 and batch: 900, loss is 3.7406066465377807 and perplexity is 42.123536512996345
At time: 426.6175093650818 and batch: 950, loss is 3.8469209814071657 and perplexity is 46.84859324318075
At time: 427.5104069709778 and batch: 1000, loss is 3.806440954208374 and perplexity is 44.990032003886014
At time: 428.42298769950867 and batch: 1050, loss is 3.7428202056884765 and perplexity is 42.2168827282737
At time: 429.3199610710144 and batch: 1100, loss is 3.7678748416900634 and perplexity is 43.287973219871034
At time: 430.2198133468628 and batch: 1150, loss is 3.735430655479431 and perplexity is 41.90606875575506
At time: 431.1064758300781 and batch: 1200, loss is 3.799887022972107 and perplexity is 44.69613457160141
At time: 431.99302887916565 and batch: 1250, loss is 3.7849760913848876 and perplexity is 44.03461773943709
At time: 432.8803622722626 and batch: 1300, loss is 3.7850791215896606 and perplexity is 44.03915486884656
At time: 433.7922797203064 and batch: 1350, loss is 3.661562371253967 and perplexity is 38.92210617138156
At time: 434.6901624202728 and batch: 1400, loss is 3.690221781730652 and perplexity is 40.05372915766708
At time: 435.5787310600281 and batch: 1450, loss is 3.59879581451416 and perplexity is 36.55418990517282
At time: 436.465936422348 and batch: 1500, loss is 3.6139503574371337 and perplexity is 37.11237075027508
At time: 437.35236382484436 and batch: 1550, loss is 3.6204473066329954 and perplexity is 37.35427289966785
At time: 438.2554750442505 and batch: 1600, loss is 3.7061666011810304 and perplexity is 40.697497382357334
At time: 439.1438035964966 and batch: 1650, loss is 3.6599089241027833 and perplexity is 38.85780370083243
At time: 440.0315365791321 and batch: 1700, loss is 3.6668567180633547 and perplexity is 39.128719759383316
At time: 440.91957235336304 and batch: 1750, loss is 3.659496126174927 and perplexity is 38.8417665902544
At time: 441.80762553215027 and batch: 1800, loss is 3.6151090049743653 and perplexity is 37.15539582788252
At time: 442.69511127471924 and batch: 1850, loss is 3.6355424070358278 and perplexity is 37.92241670529741
At time: 443.58258414268494 and batch: 1900, loss is 3.716631064414978 and perplexity is 41.12561092996107
At time: 444.47055864334106 and batch: 1950, loss is 3.6511688232421875 and perplexity is 38.51966242422757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2746760878452035 and perplexity of 71.85686022924027
finished 12 epochs...
Completing Train Step...
At time: 447.44015884399414 and batch: 50, loss is 3.820182595252991 and perplexity is 45.61253619309636
At time: 448.33616399765015 and batch: 100, loss is 3.799636416435242 and perplexity is 44.68493483152782
At time: 449.236741065979 and batch: 150, loss is 3.7666687250137327 and perplexity is 43.235794346715984
At time: 450.12157106399536 and batch: 200, loss is 3.7799572372436523 and perplexity is 43.81416808091871
At time: 451.0482382774353 and batch: 250, loss is 3.7767648124694824 and perplexity is 43.67451767558918
At time: 451.9336051940918 and batch: 300, loss is 3.7824944686889648 and perplexity is 43.92547591307735
At time: 452.81929206848145 and batch: 350, loss is 3.7878500413894653 and perplexity is 44.16135305754317
At time: 453.72836470603943 and batch: 400, loss is 3.75568115234375 and perplexity is 42.76333824045224
At time: 454.61540603637695 and batch: 450, loss is 3.7879476022720335 and perplexity is 44.16566168829635
At time: 455.500914812088 and batch: 500, loss is 3.8085126972198484 and perplexity is 45.08333640627507
At time: 456.3863639831543 and batch: 550, loss is 3.7687750577926638 and perplexity is 43.326959295726304
At time: 457.2730612754822 and batch: 600, loss is 3.755892486572266 and perplexity is 42.77237655256676
At time: 458.17841053009033 and batch: 650, loss is 3.7906669425964354 and perplexity is 44.285926599579305
At time: 459.07024121284485 and batch: 700, loss is 3.8174133110046387 and perplexity is 45.486396853545344
At time: 459.9659638404846 and batch: 750, loss is 3.781355867385864 and perplexity is 43.8754907709375
At time: 460.8631076812744 and batch: 800, loss is 3.757173428535461 and perplexity is 42.82720059026745
At time: 461.7508146762848 and batch: 850, loss is 3.74666654586792 and perplexity is 42.37957590663871
At time: 462.638614654541 and batch: 900, loss is 3.7163216638565064 and perplexity is 41.11288861121961
At time: 463.52618193626404 and batch: 950, loss is 3.8233228015899656 and perplexity is 45.75599409411508
At time: 464.4146249294281 and batch: 1000, loss is 3.784464998245239 and perplexity is 44.01211769870144
At time: 465.309885263443 and batch: 1050, loss is 3.7234154319763184 and perplexity is 41.405570792174885
At time: 466.20610785484314 and batch: 1100, loss is 3.748483114242554 and perplexity is 42.456631270940335
At time: 467.10646390914917 and batch: 1150, loss is 3.717496838569641 and perplexity is 41.161231838604984
At time: 467.99429059028625 and batch: 1200, loss is 3.783976716995239 and perplexity is 43.990632652655805
At time: 468.88089323043823 and batch: 1250, loss is 3.771778631210327 and perplexity is 43.457290630820424
At time: 469.76857590675354 and batch: 1300, loss is 3.772345027923584 and perplexity is 43.48191166938022
At time: 470.6530237197876 and batch: 1350, loss is 3.649321045875549 and perplexity is 38.44855238182544
At time: 471.53961420059204 and batch: 1400, loss is 3.680243983268738 and perplexity is 39.65606830952008
At time: 472.42847990989685 and batch: 1450, loss is 3.5909354448318482 and perplexity is 36.267986763924675
At time: 473.3327181339264 and batch: 1500, loss is 3.6075002098083497 and perplexity is 36.87376084191697
At time: 474.2266972064972 and batch: 1550, loss is 3.615738525390625 and perplexity is 37.178793271942055
At time: 475.1214952468872 and batch: 1600, loss is 3.7029071044921875 and perplexity is 40.56505998128523
At time: 476.03661918640137 and batch: 1650, loss is 3.6584899377822877 and perplexity is 38.80270411096394
At time: 476.9245276451111 and batch: 1700, loss is 3.6672220993041993 and perplexity is 39.14301927178937
At time: 477.81179666519165 and batch: 1750, loss is 3.6614658308029173 and perplexity is 38.91834879506828
At time: 478.6989150047302 and batch: 1800, loss is 3.619022932052612 and perplexity is 37.30110429787253
At time: 479.60092663764954 and batch: 1850, loss is 3.6407528829574587 and perplexity is 38.12052621864795
At time: 480.4947850704193 and batch: 1900, loss is 3.7217872285842897 and perplexity is 41.33820895562917
At time: 481.3823881149292 and batch: 1950, loss is 3.6564366102218626 and perplexity is 38.72311119232527
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273797181595204 and perplexity of 71.79373253140724
finished 13 epochs...
Completing Train Step...
At time: 484.3142683506012 and batch: 50, loss is 3.806863250732422 and perplexity is 45.009035150216974
At time: 485.2256178855896 and batch: 100, loss is 3.7846074962615965 and perplexity is 44.01838978503851
At time: 486.1119270324707 and batch: 150, loss is 3.7513137674331665 and perplexity is 42.57698152426453
At time: 486.9978494644165 and batch: 200, loss is 3.7633677530288696 and perplexity is 43.09330949945986
At time: 487.88455295562744 and batch: 250, loss is 3.759712038040161 and perplexity is 42.936060246361905
At time: 488.7717890739441 and batch: 300, loss is 3.7648214149475097 and perplexity is 43.15599815544424
At time: 489.69837617874146 and batch: 350, loss is 3.7702919006347657 and perplexity is 43.3927293526137
At time: 490.59256505966187 and batch: 400, loss is 3.738447217941284 and perplexity is 42.03267188681018
At time: 491.49472737312317 and batch: 450, loss is 3.7712190675735475 and perplexity is 43.432980313449576
At time: 492.3895010948181 and batch: 500, loss is 3.7917624139785766 and perplexity is 44.33446714733694
At time: 493.2922351360321 and batch: 550, loss is 3.7523226642608645 and perplexity is 42.619958982122306
At time: 494.21982765197754 and batch: 600, loss is 3.740717496871948 and perplexity is 42.12820617990741
At time: 495.1286025047302 and batch: 650, loss is 3.7761077165603636 and perplexity is 43.64582875541012
At time: 496.0419409275055 and batch: 700, loss is 3.8030932331085205 and perplexity is 44.8396697503367
At time: 496.93230843544006 and batch: 750, loss is 3.767871017456055 and perplexity is 43.287807676848225
At time: 497.84033370018005 and batch: 800, loss is 3.74394522190094 and perplexity is 42.2644041319453
At time: 498.7294833660126 and batch: 850, loss is 3.7335074090957643 and perplexity is 41.8255505135948
At time: 499.62062335014343 and batch: 900, loss is 3.703845887184143 and perplexity is 40.603159638344955
At time: 500.50968074798584 and batch: 950, loss is 3.8112723302841185 and perplexity is 45.20792169784871
At time: 501.3956639766693 and batch: 1000, loss is 3.7729421758651736 and perplexity is 43.507884557486506
At time: 502.2815239429474 and batch: 1050, loss is 3.712968964576721 and perplexity is 40.97528026777978
At time: 503.16761088371277 and batch: 1100, loss is 3.7378295183181764 and perplexity is 42.006716338419004
At time: 504.05646777153015 and batch: 1150, loss is 3.707603540420532 and perplexity is 40.7560192494095
At time: 504.94653058052063 and batch: 1200, loss is 3.775171241760254 and perplexity is 43.60497466904766
At time: 505.834184885025 and batch: 1250, loss is 3.7636627531051636 and perplexity is 43.10602390433296
At time: 506.7453649044037 and batch: 1300, loss is 3.7648059225082395 and perplexity is 43.155329568942705
At time: 507.63565707206726 and batch: 1350, loss is 3.6417822265625 and perplexity is 38.159785540731555
At time: 508.52517008781433 and batch: 1400, loss is 3.6736092805862426 and perplexity is 39.39383297541717
At time: 509.41668248176575 and batch: 1450, loss is 3.5849258661270142 and perplexity is 36.050685042886535
At time: 510.3052728176117 and batch: 1500, loss is 3.6018893671035768 and perplexity is 36.66744730754979
At time: 511.19486021995544 and batch: 1550, loss is 3.6108386659622194 and perplexity is 36.99706798894342
At time: 512.0852694511414 and batch: 1600, loss is 3.6985978841781617 and perplexity is 40.390632294357864
At time: 512.9730498790741 and batch: 1650, loss is 3.654823260307312 and perplexity is 38.66068763325403
At time: 513.8721799850464 and batch: 1700, loss is 3.6643086957931517 and perplexity is 39.02914582220956
At time: 514.7955801486969 and batch: 1750, loss is 3.659342188835144 and perplexity is 38.835787852220356
At time: 515.6997287273407 and batch: 1800, loss is 3.6179644203186037 and perplexity is 37.26164153086739
At time: 516.5968954563141 and batch: 1850, loss is 3.6403130149841307 and perplexity is 38.103761907350076
At time: 517.4853847026825 and batch: 1900, loss is 3.7211298656463625 and perplexity is 41.311043678842765
At time: 518.3884057998657 and batch: 1950, loss is 3.6557230663299563 and perplexity is 38.695490408351134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.274156579305959 and perplexity of 71.81953967176142
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 521.4009029865265 and batch: 50, loss is 3.8046818733215333 and perplexity is 44.91096046549526
At time: 522.3236858844757 and batch: 100, loss is 3.796374077796936 and perplexity is 44.53939497131138
At time: 523.2275815010071 and batch: 150, loss is 3.7686355686187745 and perplexity is 43.320916075458705
At time: 524.1480977535248 and batch: 200, loss is 3.7861997413635256 and perplexity is 44.088533678884914
At time: 525.0540108680725 and batch: 250, loss is 3.788905062675476 and perplexity is 44.207968811020116
At time: 525.9668226242065 and batch: 300, loss is 3.7916702127456663 and perplexity is 44.33037964324488
At time: 526.8560960292816 and batch: 350, loss is 3.7981190633773805 and perplexity is 44.61718342342301
At time: 527.7440731525421 and batch: 400, loss is 3.76942663192749 and perplexity is 43.35519922094739
At time: 528.6307752132416 and batch: 450, loss is 3.803208041191101 and perplexity is 44.84481800236908
At time: 529.5175788402557 and batch: 500, loss is 3.8198153829574584 and perplexity is 45.5957897839077
At time: 530.404625415802 and batch: 550, loss is 3.7843044567108155 and perplexity is 44.005052492937516
At time: 531.2920293807983 and batch: 600, loss is 3.767172083854675 and perplexity is 43.25756294429397
At time: 532.1805686950684 and batch: 650, loss is 3.7927689790725707 and perplexity is 44.37911514121467
At time: 533.0678100585938 and batch: 700, loss is 3.81571138381958 and perplexity is 45.40904815778435
At time: 533.9724073410034 and batch: 750, loss is 3.7836767435073853 and perplexity is 43.9774386081768
At time: 534.8626482486725 and batch: 800, loss is 3.7561348390579226 and perplexity is 42.78274380055514
At time: 535.7489740848541 and batch: 850, loss is 3.745069856643677 and perplexity is 42.311962887314756
At time: 536.6355831623077 and batch: 900, loss is 3.7119399166107176 and perplexity is 40.93313642669975
At time: 537.5218639373779 and batch: 950, loss is 3.82044873714447 and perplexity is 45.624677215299606
At time: 538.4070858955383 and batch: 1000, loss is 3.7810023069381713 and perplexity is 43.85998087478227
At time: 539.2923135757446 and batch: 1050, loss is 3.7190835094451904 and perplexity is 41.226593005983005
At time: 540.1933164596558 and batch: 1100, loss is 3.7388815116882324 and perplexity is 42.05093037786542
At time: 541.1078388690948 and batch: 1150, loss is 3.7132747411727904 and perplexity is 40.98781146527886
At time: 541.995133638382 and batch: 1200, loss is 3.7744355487823484 and perplexity is 43.57290659295748
At time: 542.881108045578 and batch: 1250, loss is 3.7598307609558104 and perplexity is 42.94115804322751
At time: 543.7681679725647 and batch: 1300, loss is 3.7608493328094483 and perplexity is 42.984918981219366
At time: 544.655547618866 and batch: 1350, loss is 3.6385015201568605 and perplexity is 38.03479962102624
At time: 545.5426158905029 and batch: 1400, loss is 3.6687966346740724 and perplexity is 39.204699886528175
At time: 546.4295449256897 and batch: 1450, loss is 3.577929105758667 and perplexity is 35.79932740852026
At time: 547.3165559768677 and batch: 1500, loss is 3.5946262741088866 and perplexity is 36.40209304074316
At time: 548.2028024196625 and batch: 1550, loss is 3.6068869686126708 and perplexity is 36.8511552647731
At time: 549.0957982540131 and batch: 1600, loss is 3.692354187965393 and perplexity is 40.13923110949587
At time: 549.9873335361481 and batch: 1650, loss is 3.641920347213745 and perplexity is 38.16505655917169
At time: 550.8742234706879 and batch: 1700, loss is 3.6467542600631715 and perplexity is 38.34998973178528
At time: 551.7608156204224 and batch: 1750, loss is 3.64014995098114 and perplexity is 38.09754906196395
At time: 552.6479017734528 and batch: 1800, loss is 3.601091432571411 and perplexity is 36.63820075510557
At time: 553.5353984832764 and batch: 1850, loss is 3.6209037780761717 and perplexity is 37.37132795080292
At time: 554.4226477146149 and batch: 1900, loss is 3.701150031089783 and perplexity is 40.49384677506186
At time: 555.308111667633 and batch: 1950, loss is 3.6433517074584962 and perplexity is 38.21972361866354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26123784974564 and perplexity of 70.89768984675283
finished 15 epochs...
Completing Train Step...
At time: 558.3141224384308 and batch: 50, loss is 3.8078862047195434 and perplexity is 45.05510087972415
At time: 559.2485344409943 and batch: 100, loss is 3.789156188964844 and perplexity is 44.21907198827962
At time: 560.1469955444336 and batch: 150, loss is 3.7585641145706177 and perplexity is 42.886801213324595
At time: 561.0343379974365 and batch: 200, loss is 3.7696073150634763 and perplexity is 43.363033482042056
At time: 561.9215824604034 and batch: 250, loss is 3.7697318840026854 and perplexity is 43.368435505578994
At time: 562.8504462242126 and batch: 300, loss is 3.770392351150513 and perplexity is 43.39708839358713
At time: 563.7583546638489 and batch: 350, loss is 3.7776801204681396 and perplexity is 43.71451161154768
At time: 564.6687903404236 and batch: 400, loss is 3.7492162370681763 and perplexity is 42.48776860877604
At time: 565.5567653179169 and batch: 450, loss is 3.783789048194885 and perplexity is 43.982377758016376
At time: 566.4428586959839 and batch: 500, loss is 3.8006499147415163 and perplexity is 44.73024589475993
At time: 567.3408558368683 and batch: 550, loss is 3.7649208450317384 and perplexity is 43.160289373310356
At time: 568.2291548252106 and batch: 600, loss is 3.750465807914734 and perplexity is 42.5408932703665
At time: 569.1218266487122 and batch: 650, loss is 3.7781684684753416 and perplexity is 43.735864719628516
At time: 570.007696390152 and batch: 700, loss is 3.803255920410156 and perplexity is 44.846965188636105
At time: 570.8946611881256 and batch: 750, loss is 3.7718275594711304 and perplexity is 43.45941697248889
At time: 571.781170129776 and batch: 800, loss is 3.7454470109939577 and perplexity is 42.327924037906115
At time: 572.6682629585266 and batch: 850, loss is 3.7343936204910277 and perplexity is 41.86263322220561
At time: 573.5731856822968 and batch: 900, loss is 3.7015280151367187 and perplexity is 40.509155696223615
At time: 574.4810698032379 and batch: 950, loss is 3.8111036825180054 and perplexity is 45.20029812571103
At time: 575.387533903122 and batch: 1000, loss is 3.7721734762191774 and perplexity is 43.47445291312195
At time: 576.281890630722 and batch: 1050, loss is 3.7119123411178587 and perplexity is 40.932007690851314
At time: 577.1752307415009 and batch: 1100, loss is 3.731697669029236 and perplexity is 41.74992559039282
At time: 578.0807960033417 and batch: 1150, loss is 3.706460671424866 and perplexity is 40.70946706521357
At time: 578.9671592712402 and batch: 1200, loss is 3.7688059568405152 and perplexity is 43.32829807819829
At time: 579.8521246910095 and batch: 1250, loss is 3.7549084663391112 and perplexity is 42.73030836998488
At time: 580.7383563518524 and batch: 1300, loss is 3.7561996030807494 and perplexity is 42.78551467287669
At time: 581.6258864402771 and batch: 1350, loss is 3.6345396280288695 and perplexity is 37.884407962302014
At time: 582.5126178264618 and batch: 1400, loss is 3.6663885164260863 and perplexity is 39.11040391681609
At time: 583.4148373603821 and batch: 1450, loss is 3.576645860671997 and perplexity is 35.753417560610615
At time: 584.3132195472717 and batch: 1500, loss is 3.5944213676452637 and perplexity is 36.39463478073865
At time: 585.2007791996002 and batch: 1550, loss is 3.6076689338684083 and perplexity is 36.87998285744295
At time: 586.0876789093018 and batch: 1600, loss is 3.6938060188293456 and perplexity is 40.197548807549374
At time: 586.9833493232727 and batch: 1650, loss is 3.643707218170166 and perplexity is 38.23331355534793
At time: 587.885261297226 and batch: 1700, loss is 3.6498848724365236 and perplexity is 38.470236809443
At time: 588.771680355072 and batch: 1750, loss is 3.6442343950271607 and perplexity is 38.253474587168306
At time: 589.6760983467102 and batch: 1800, loss is 3.6056906890869143 and perplexity is 36.8070973402801
At time: 590.5631020069122 and batch: 1850, loss is 3.6257595205307007 and perplexity is 37.55323478346079
At time: 591.4504039287567 and batch: 1900, loss is 3.706229815483093 and perplexity is 40.70007012756635
At time: 592.3485865592957 and batch: 1950, loss is 3.6483056497573854 and perplexity is 38.40953168507255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259924032521802 and perplexity of 70.80460440272138
finished 16 epochs...
Completing Train Step...
At time: 595.328765630722 and batch: 50, loss is 3.804663667678833 and perplexity is 44.910142840038404
At time: 596.2162365913391 and batch: 100, loss is 3.784213433265686 and perplexity is 44.00104718374778
At time: 597.1032853126526 and batch: 150, loss is 3.753361005783081 and perplexity is 42.664236038583596
At time: 597.9908401966095 and batch: 200, loss is 3.763202347755432 and perplexity is 43.08618222827915
At time: 598.878190279007 and batch: 250, loss is 3.762736954689026 and perplexity is 43.06613488312175
At time: 599.7905933856964 and batch: 300, loss is 3.7624292373657227 and perplexity is 43.05288472612647
At time: 600.6882424354553 and batch: 350, loss is 3.7698963403701784 and perplexity is 43.37556830744736
At time: 601.5752727985382 and batch: 400, loss is 3.7413147687911987 and perplexity is 42.153375690239706
At time: 602.4625725746155 and batch: 450, loss is 3.776039342880249 and perplexity is 43.64284463149539
At time: 603.368852853775 and batch: 500, loss is 3.7930371046066282 and perplexity is 44.391015910541675
At time: 604.2598886489868 and batch: 550, loss is 3.7574349737167356 and perplexity is 42.838403303153235
At time: 605.1509094238281 and batch: 600, loss is 3.743589091300964 and perplexity is 42.24935516420218
At time: 606.0553042888641 and batch: 650, loss is 3.7718453454971312 and perplexity is 43.460189949683226
At time: 606.9421336650848 and batch: 700, loss is 3.797435803413391 and perplexity is 44.58670870054842
At time: 607.878693819046 and batch: 750, loss is 3.7664514875411985 and perplexity is 43.22640293214961
At time: 608.7930157184601 and batch: 800, loss is 3.7404284954071043 and perplexity is 42.11603282575349
At time: 609.687206029892 and batch: 850, loss is 3.7293133306503297 and perplexity is 41.65049822184083
At time: 610.5998537540436 and batch: 900, loss is 3.6965720748901365 and perplexity is 40.30889139999297
At time: 611.5109827518463 and batch: 950, loss is 3.8065004539489746 and perplexity is 44.99270897875873
At time: 612.4008052349091 and batch: 1000, loss is 3.768011565208435 and perplexity is 43.29389210848926
At time: 613.2885177135468 and batch: 1050, loss is 3.708353204727173 and perplexity is 40.78658403755545
At time: 614.1778955459595 and batch: 1100, loss is 3.7282011556625365 and perplexity is 41.60420132938445
At time: 615.06503033638 and batch: 1150, loss is 3.703167281150818 and perplexity is 40.57561543613024
At time: 615.9521799087524 and batch: 1200, loss is 3.7659788942337036 and perplexity is 43.20597924984471
At time: 616.8394393920898 and batch: 1250, loss is 3.75251916885376 and perplexity is 42.628334822729926
At time: 617.7295808792114 and batch: 1300, loss is 3.754001708030701 and perplexity is 42.69157986919797
At time: 618.6186964511871 and batch: 1350, loss is 3.6325564575195313 and perplexity is 37.80935117147413
At time: 619.5034132003784 and batch: 1400, loss is 3.6649383306503296 and perplexity is 39.05372767084738
At time: 620.3858776092529 and batch: 1450, loss is 3.575582127571106 and perplexity is 35.71540568770943
At time: 621.2692561149597 and batch: 1500, loss is 3.5936993074417116 and perplexity is 36.368365148609975
At time: 622.1568794250488 and batch: 1550, loss is 3.607374167442322 and perplexity is 36.86911347874459
At time: 623.0434682369232 and batch: 1600, loss is 3.6938068103790282 and perplexity is 40.19758062591897
At time: 623.9316563606262 and batch: 1650, loss is 3.643830122947693 and perplexity is 38.23801290102467
At time: 624.8183648586273 and batch: 1700, loss is 3.6505703067779542 and perplexity is 38.49661466998816
At time: 625.7060258388519 and batch: 1750, loss is 3.6453506708145142 and perplexity is 38.29619985678753
At time: 626.594343662262 and batch: 1800, loss is 3.6070718336105347 and perplexity is 36.85796838324657
At time: 627.4825193881989 and batch: 1850, loss is 3.6271204280853273 and perplexity is 37.60437605575708
At time: 628.369532585144 and batch: 1900, loss is 3.707610831260681 and perplexity is 40.75631639611417
At time: 629.2577440738678 and batch: 1950, loss is 3.6494935083389284 and perplexity is 38.45518388570889
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259585926144622 and perplexity of 70.78066896102986
finished 17 epochs...
Completing Train Step...
At time: 632.2562050819397 and batch: 50, loss is 3.800987844467163 and perplexity is 44.745364128789724
At time: 633.1438777446747 and batch: 100, loss is 3.7797923994064333 and perplexity is 43.80694644342861
At time: 634.0308804512024 and batch: 150, loss is 3.748959584236145 and perplexity is 42.47686540186522
At time: 634.9211227893829 and batch: 200, loss is 3.75825110912323 and perplexity is 42.873379511566256
At time: 635.8086369037628 and batch: 250, loss is 3.7575182819366457 and perplexity is 42.84197224293516
At time: 636.6977241039276 and batch: 300, loss is 3.7565987873077393 and perplexity is 42.80259738482548
At time: 637.5844020843506 and batch: 350, loss is 3.764287829399109 and perplexity is 43.13297688095758
At time: 638.4729132652283 and batch: 400, loss is 3.7357469272613524 and perplexity is 41.919324558901494
At time: 639.362283706665 and batch: 450, loss is 3.770585131645203 and perplexity is 43.405455312219196
At time: 640.251086473465 and batch: 500, loss is 3.7877198791503908 and perplexity is 44.155605291027825
At time: 641.1411628723145 and batch: 550, loss is 3.75228404045105 and perplexity is 42.61831286872207
At time: 642.0310192108154 and batch: 600, loss is 3.7388031816482545 and perplexity is 42.04763665580819
At time: 642.9202456474304 and batch: 650, loss is 3.7673625993728637 and perplexity is 43.265804966405504
At time: 643.8100411891937 and batch: 700, loss is 3.7931867599487306 and perplexity is 44.39765976034545
At time: 644.6998994350433 and batch: 750, loss is 3.7625198316574098 and perplexity is 43.05678524840318
At time: 645.5893819332123 and batch: 800, loss is 3.7366662406921387 and perplexity is 41.95787927619736
At time: 646.4787101745605 and batch: 850, loss is 3.725569849014282 and perplexity is 41.494871820643795
At time: 647.3682699203491 and batch: 900, loss is 3.692893052101135 and perplexity is 40.16086653032969
At time: 648.2574234008789 and batch: 950, loss is 3.8030199575424195 and perplexity is 44.836384218528025
At time: 649.1480736732483 and batch: 1000, loss is 3.764850640296936 and perplexity is 43.157259423000575
At time: 650.0377027988434 and batch: 1050, loss is 3.7055591201782225 and perplexity is 40.67278193367857
At time: 650.9278855323792 and batch: 1100, loss is 3.725446095466614 and perplexity is 41.4897370007786
At time: 651.8660662174225 and batch: 1150, loss is 3.7005670356750486 and perplexity is 40.470245928328225
At time: 652.7561118602753 and batch: 1200, loss is 3.7636631870269777 and perplexity is 43.106042608981106
At time: 653.6460568904877 and batch: 1250, loss is 3.7504858350753785 and perplexity is 42.54174525220135
At time: 654.5453119277954 and batch: 1300, loss is 3.7521146821975706 and perplexity is 42.61109571684775
At time: 655.43514752388 and batch: 1350, loss is 3.6307434844970703 and perplexity is 37.74086593750282
At time: 656.3250465393066 and batch: 1400, loss is 3.663430304527283 and perplexity is 38.99487801388012
At time: 657.2478404045105 and batch: 1450, loss is 3.5742950868606567 and perplexity is 35.66946807472936
At time: 658.1358246803284 and batch: 1500, loss is 3.5925689220428465 and perplexity is 36.32727810613682
At time: 659.022908449173 and batch: 1550, loss is 3.6064850282669068 and perplexity is 36.836346275048776
At time: 659.9098701477051 and batch: 1600, loss is 3.693124213218689 and perplexity is 40.17015123420869
At time: 660.7976994514465 and batch: 1650, loss is 3.6432528495788574 and perplexity is 38.215945484578455
At time: 661.6864898204803 and batch: 1700, loss is 3.6503374195098877 and perplexity is 38.48765034244725
At time: 662.5755567550659 and batch: 1750, loss is 3.645443320274353 and perplexity is 38.299748143389024
At time: 663.4669075012207 and batch: 1800, loss is 3.607380919456482 and perplexity is 36.8693624203613
At time: 664.3683066368103 and batch: 1850, loss is 3.627465934753418 and perplexity is 37.61737086320078
At time: 665.267923116684 and batch: 1900, loss is 3.70791286945343 and perplexity is 40.768628219488406
At time: 666.1675612926483 and batch: 1950, loss is 3.649631071090698 and perplexity is 38.460474250494244
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2595464662063955 and perplexity of 70.77787601531014
finished 18 epochs...
Completing Train Step...
At time: 669.239944934845 and batch: 50, loss is 3.7974399614334104 and perplexity is 44.58689409336123
At time: 670.1306054592133 and batch: 100, loss is 3.775790476799011 and perplexity is 43.631984759160865
At time: 671.0465986728668 and batch: 150, loss is 3.7451273918151857 and perplexity is 42.31439738339026
At time: 671.9455173015594 and batch: 200, loss is 3.7540118980407713 and perplexity is 42.692014899043244
At time: 672.8473491668701 and batch: 250, loss is 3.753092660903931 and perplexity is 42.652788845286324
At time: 673.7428982257843 and batch: 300, loss is 3.751722197532654 and perplexity is 42.59437479679059
At time: 674.6806190013885 and batch: 350, loss is 3.759627857208252 and perplexity is 42.93244600521851
At time: 675.5720326900482 and batch: 400, loss is 3.731186032295227 and perplexity is 41.72857025837065
At time: 676.4616289138794 and batch: 450, loss is 3.7661400699615477 and perplexity is 43.212943566221824
At time: 677.3545904159546 and batch: 500, loss is 3.7833718395233156 and perplexity is 43.96403175594118
At time: 678.2505829334259 and batch: 550, loss is 3.7480822372436524 and perplexity is 42.439614794997766
At time: 679.141918182373 and batch: 600, loss is 3.7348972511291505 and perplexity is 41.88372183687929
At time: 680.0316665172577 and batch: 650, loss is 3.7636650896072386 and perplexity is 43.10612462176492
At time: 680.9228830337524 and batch: 700, loss is 3.789637608528137 and perplexity is 44.24036503963994
At time: 681.8228759765625 and batch: 750, loss is 3.7592212533950806 and perplexity is 42.91499305742203
At time: 682.721373796463 and batch: 800, loss is 3.733461284637451 and perplexity is 41.823621377224235
At time: 683.6301891803741 and batch: 850, loss is 3.722378125190735 and perplexity is 41.36264278123896
At time: 684.5382385253906 and batch: 900, loss is 3.6897687339782714 and perplexity is 40.03558701563638
At time: 685.445638179779 and batch: 950, loss is 3.8000197410583496 and perplexity is 44.702066950702495
At time: 686.3404810428619 and batch: 1000, loss is 3.7620776987075804 and perplexity is 43.03775263271444
At time: 687.2318065166473 and batch: 1050, loss is 3.703062443733215 and perplexity is 40.57136181636343
At time: 688.149129152298 and batch: 1100, loss is 3.7229695987701414 and perplexity is 41.387114928219226
At time: 689.0394041538239 and batch: 1150, loss is 3.6982254505157472 and perplexity is 40.375592264125856
At time: 689.9284524917603 and batch: 1200, loss is 3.7615387535095213 and perplexity is 43.014563891889324
At time: 690.8240942955017 and batch: 1250, loss is 3.7485490703582762 and perplexity is 42.45943163777527
At time: 691.7477498054504 and batch: 1300, loss is 3.7503126287460327 and perplexity is 42.53437739076079
At time: 692.6500446796417 and batch: 1350, loss is 3.628947443962097 and perplexity is 37.673142647545966
At time: 693.5586812496185 and batch: 1400, loss is 3.66187714099884 and perplexity is 38.93435960121436
At time: 694.4491100311279 and batch: 1450, loss is 3.5728870582580567 and perplexity is 35.61927978500605
At time: 695.3575820922852 and batch: 1500, loss is 3.5912443876266478 and perplexity is 36.27919322810632
At time: 696.2673590183258 and batch: 1550, loss is 3.605315957069397 and perplexity is 36.79330712641354
At time: 697.1628184318542 and batch: 1600, loss is 3.6921177530288696 and perplexity is 40.129741914769184
At time: 698.0532031059265 and batch: 1650, loss is 3.642344045639038 and perplexity is 38.18123045972315
At time: 698.9438652992249 and batch: 1700, loss is 3.6496855449676513 and perplexity is 38.462569398701035
At time: 699.8553593158722 and batch: 1750, loss is 3.64505304813385 and perplexity is 38.28480373508317
At time: 700.7482359409332 and batch: 1800, loss is 3.6071889448165892 and perplexity is 36.86228511714067
At time: 701.6357307434082 and batch: 1850, loss is 3.62733793258667 and perplexity is 37.61255606638171
At time: 702.524032831192 and batch: 1900, loss is 3.707737183570862 and perplexity is 40.76146637619437
At time: 703.4097261428833 and batch: 1950, loss is 3.6493179273605345 and perplexity is 38.44843247962451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25963872865189 and perplexity of 70.7844064564908
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 706.356725692749 and batch: 50, loss is 3.797229504585266 and perplexity is 44.57751146351578
At time: 707.2688038349152 and batch: 100, loss is 3.7806527757644655 and perplexity is 43.84465312310796
At time: 708.1556777954102 and batch: 150, loss is 3.7532604551315307 and perplexity is 42.659946337521745
At time: 709.0430788993835 and batch: 200, loss is 3.7641813278198244 and perplexity is 43.12838339541159
At time: 709.929591178894 and batch: 250, loss is 3.7643018102645875 and perplexity is 43.13357992152055
At time: 710.8168830871582 and batch: 300, loss is 3.76139874458313 and perplexity is 43.008541890556444
At time: 711.7043697834015 and batch: 350, loss is 3.7702183675765992 and perplexity is 43.389538669833975
At time: 712.6175236701965 and batch: 400, loss is 3.7429775285720823 and perplexity is 42.223524932473026
At time: 713.5174193382263 and batch: 450, loss is 3.778798809051514 and perplexity is 43.763441900390184
At time: 714.407466173172 and batch: 500, loss is 3.7955925703048705 and perplexity is 44.50460069821268
At time: 715.2970278263092 and batch: 550, loss is 3.762825174331665 and perplexity is 43.06993432974143
At time: 716.1869831085205 and batch: 600, loss is 3.7482507038116455 and perplexity is 42.44676505352207
At time: 717.0772440433502 and batch: 650, loss is 3.7737138509750365 and perplexity is 43.541471466506465
At time: 717.9673886299133 and batch: 700, loss is 3.7993032264709474 and perplexity is 44.67004873977271
At time: 718.8573806285858 and batch: 750, loss is 3.768227767944336 and perplexity is 43.30325337834052
At time: 719.7763783931732 and batch: 800, loss is 3.7410100936889648 and perplexity is 42.140534562477065
At time: 720.6660208702087 and batch: 850, loss is 3.7282017135620116 and perplexity is 41.60422454035301
At time: 721.5560491085052 and batch: 900, loss is 3.6930614709854126 and perplexity is 40.167630948274216
At time: 722.4450483322144 and batch: 950, loss is 3.801698007583618 and perplexity is 44.77715192194951
At time: 723.3347318172455 and batch: 1000, loss is 3.7629941749572753 and perplexity is 43.07721379068755
At time: 724.2237532138824 and batch: 1050, loss is 3.7040988779067994 and perplexity is 40.6134331605421
At time: 725.1133379936218 and batch: 1100, loss is 3.72329327583313 and perplexity is 41.40051315625734
At time: 726.0026042461395 and batch: 1150, loss is 3.6981850719451903 and perplexity is 40.37396198833916
At time: 726.8926668167114 and batch: 1200, loss is 3.761780467033386 and perplexity is 43.02496235037854
At time: 727.7833404541016 and batch: 1250, loss is 3.7491326570510863 and perplexity is 42.48421762874715
At time: 728.6726150512695 and batch: 1300, loss is 3.748710675239563 and perplexity is 42.46629384365264
At time: 729.562833070755 and batch: 1350, loss is 3.6257606744766235 and perplexity is 37.55327811788796
At time: 730.4526891708374 and batch: 1400, loss is 3.657615833282471 and perplexity is 38.768801312148625
At time: 731.3421127796173 and batch: 1450, loss is 3.568597593307495 and perplexity is 35.46681935340922
At time: 732.2315118312836 and batch: 1500, loss is 3.585957856178284 and perplexity is 36.08790819484993
At time: 733.1209576129913 and batch: 1550, loss is 3.601455206871033 and perplexity is 36.651531215417094
At time: 734.0096416473389 and batch: 1600, loss is 3.688168611526489 and perplexity is 39.97157640005164
At time: 734.898663520813 and batch: 1650, loss is 3.6368865299224855 and perplexity is 37.97342336543867
At time: 735.7870240211487 and batch: 1700, loss is 3.640648698806763 and perplexity is 38.11655487087912
At time: 736.690194606781 and batch: 1750, loss is 3.6347794580459594 and perplexity is 37.89349487012412
At time: 737.5854964256287 and batch: 1800, loss is 3.597612533569336 and perplexity is 36.51096160945771
At time: 738.4731175899506 and batch: 1850, loss is 3.6165180253982543 and perplexity is 37.2077854398107
At time: 739.3605487346649 and batch: 1900, loss is 3.6969954538345338 and perplexity is 40.32596094907259
At time: 740.2499816417694 and batch: 1950, loss is 3.640994071960449 and perplexity is 38.12972157922545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257610090388808 and perplexity of 70.64095605480648
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
3065.571511030197


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}, 'best_accuracy': -70.21234677830806}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7054039444822918, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3700134384042031, 'data': 'wikitext'}, 'best_accuracy': -70.64095605480648}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.7401099843983403, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.9299697240020345, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.451246738433838 and batch: 50, loss is 7.640673885345459 and perplexity is 2081.145797785907
At time: 2.405963897705078 and batch: 100, loss is 6.855621833801269 and perplexity is 949.2021919328167
At time: 3.3881235122680664 and batch: 150, loss is 6.628338384628296 and perplexity is 756.2245717354651
At time: 4.344343185424805 and batch: 200, loss is 6.556978635787964 and perplexity is 704.1410109798065
At time: 5.300750732421875 and batch: 250, loss is 6.527170076370239 and perplexity is 683.4613288049759
At time: 6.256234407424927 and batch: 300, loss is 6.478761119842529 and perplexity is 651.1637325263792
At time: 7.211050987243652 and batch: 350, loss is 6.4515852451324465 and perplexity is 633.7060764535782
At time: 8.164365768432617 and batch: 400, loss is 6.439391689300537 and perplexity is 626.0258657278335
At time: 9.118947267532349 and batch: 450, loss is 6.363534545898437 and perplexity is 580.2938109605018
At time: 10.0734121799469 and batch: 500, loss is 6.362284011840821 and perplexity is 579.5685873394012
At time: 11.033278703689575 and batch: 550, loss is 6.322145853042603 and perplexity is 556.7664504824579
At time: 11.993669271469116 and batch: 600, loss is 6.378520460128784 and perplexity is 589.0555314626833
At time: 12.949357032775879 and batch: 650, loss is 6.460696649551392 and perplexity is 639.506413278688
At time: 13.904564619064331 and batch: 700, loss is 6.355735206604004 and perplexity is 575.785506390064
At time: 14.8602294921875 and batch: 750, loss is 6.295614719390869 and perplexity is 542.1890380881346
At time: 15.833208799362183 and batch: 800, loss is 6.304221811294556 and perplexity is 546.8758499443121
At time: 16.78697156906128 and batch: 850, loss is 6.353685350418091 and perplexity is 574.6064377814331
At time: 17.7382595539093 and batch: 900, loss is 6.342188701629639 and perplexity is 568.0382179777149
At time: 18.689687967300415 and batch: 950, loss is 6.359983882904053 and perplexity is 578.2370368168217
At time: 19.645222902297974 and batch: 1000, loss is 6.3442560577392575 and perplexity is 569.2137699817682
At time: 20.60612416267395 and batch: 1050, loss is 6.24706727027893 and perplexity is 516.4958585745895
At time: 21.5732479095459 and batch: 1100, loss is 6.330584497451782 and perplexity is 561.4846843268307
At time: 22.534063816070557 and batch: 1150, loss is 6.239180173873901 and perplexity is 512.438228439394
At time: 23.49682116508484 and batch: 1200, loss is 6.332933559417724 and perplexity is 562.8051970190866
At time: 24.452419757843018 and batch: 1250, loss is 6.271218166351319 and perplexity is 529.1215435076407
At time: 25.40869116783142 and batch: 1300, loss is 6.279322090148926 and perplexity is 533.4269258586813
At time: 26.369783401489258 and batch: 1350, loss is 6.275939311981201 and perplexity is 531.62550951358
At time: 27.33210325241089 and batch: 1400, loss is 6.2967514801025395 and perplexity is 542.8057277328027
At time: 28.29337477684021 and batch: 1450, loss is 6.29244665145874 and perplexity is 540.4740643943805
At time: 29.249648332595825 and batch: 1500, loss is 6.277083759307861 and perplexity is 532.2342751904082
At time: 30.211119413375854 and batch: 1550, loss is 6.247424030303955 and perplexity is 516.6801565231356
At time: 31.182060480117798 and batch: 1600, loss is 6.238574361801147 and perplexity is 512.1278811896118
At time: 32.14921593666077 and batch: 1650, loss is 6.241011381149292 and perplexity is 513.3774687608912
At time: 33.10755443572998 and batch: 1700, loss is 6.266915769577026 and perplexity is 526.8499428533684
At time: 34.06997585296631 and batch: 1750, loss is 6.288024101257324 and perplexity is 538.0890684814441
At time: 35.042303800582886 and batch: 1800, loss is 6.28884786605835 and perplexity is 538.5325099365306
At time: 36.01856255531311 and batch: 1850, loss is 6.247018775939941 and perplexity is 516.4708120566495
At time: 36.97712182998657 and batch: 1900, loss is 6.2049687957763675 and perplexity is 495.2035032582336
At time: 37.93479585647583 and batch: 1950, loss is 6.147822132110596 and perplexity is 467.6976930187336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.608379133357558 and perplexity of 272.7018662304761
finished 1 epochs...
Completing Train Step...
At time: 40.92798829078674 and batch: 50, loss is 5.867734785079956 and perplexity is 353.44743836732766
At time: 41.84664058685303 and batch: 100, loss is 5.733753652572632 and perplexity is 309.1274503604479
At time: 42.73467016220093 and batch: 150, loss is 5.571876678466797 and perplexity is 262.92706608872857
At time: 43.62214422225952 and batch: 200, loss is 5.47344539642334 and perplexity is 238.2797482961177
At time: 44.50954222679138 and batch: 250, loss is 5.437186794281006 and perplexity is 229.79481321202343
At time: 45.39712119102478 and batch: 300, loss is 5.403747777938843 and perplexity is 222.2377551501653
At time: 46.286648988723755 and batch: 350, loss is 5.359886779785156 and perplexity is 212.70086304879666
At time: 47.176207304000854 and batch: 400, loss is 5.298356418609619 and perplexity is 200.0078105648248
At time: 48.06537222862244 and batch: 450, loss is 5.236173973083496 and perplexity is 187.94962467800326
At time: 48.951645374298096 and batch: 500, loss is 5.205952701568603 and perplexity is 182.35451947564803
At time: 49.8398711681366 and batch: 550, loss is 5.144138393402099 and perplexity is 171.42372121398395
At time: 50.76981973648071 and batch: 600, loss is 5.139462175369263 and perplexity is 170.623977862062
At time: 51.65735912322998 and batch: 650, loss is 5.205274000167846 and perplexity is 182.23079719783644
At time: 52.54678249359131 and batch: 700, loss is 5.163675985336304 and perplexity is 174.80585976389432
At time: 53.45092225074768 and batch: 750, loss is 5.106418323516846 and perplexity is 165.07803863549915
At time: 54.337317943573 and batch: 800, loss is 5.085187883377075 and perplexity is 161.6103002743292
At time: 55.224308252334595 and batch: 850, loss is 5.076055612564087 and perplexity is 160.1411497964523
At time: 56.11080551147461 and batch: 900, loss is 5.0928051567077635 and perplexity is 162.84603057726966
At time: 56.99757170677185 and batch: 950, loss is 5.137387208938598 and perplexity is 170.2703058913592
At time: 57.88365888595581 and batch: 1000, loss is 5.097303209304809 and perplexity is 163.58017045011857
At time: 58.76850724220276 and batch: 1050, loss is 4.988086214065552 and perplexity is 146.65548754653042
At time: 59.65313506126404 and batch: 1100, loss is 5.068105897903442 and perplexity is 158.873120264689
At time: 60.539093017578125 and batch: 1150, loss is 4.9755095195770265 and perplexity is 144.82259630067273
At time: 61.42518925666809 and batch: 1200, loss is 5.047565832138061 and perplexity is 155.64314147284236
At time: 62.31266784667969 and batch: 1250, loss is 4.998384571075439 and perplexity is 148.1736017386202
At time: 63.2016863822937 and batch: 1300, loss is 5.022959232330322 and perplexity is 151.86002863248203
At time: 64.0877194404602 and batch: 1350, loss is 4.932273378372193 and perplexity is 138.6944591915056
At time: 64.9748752117157 and batch: 1400, loss is 4.947374305725098 and perplexity is 140.80476785048674
At time: 65.86241292953491 and batch: 1450, loss is 4.886774816513062 and perplexity is 132.52546511575008
At time: 66.75188517570496 and batch: 1500, loss is 4.864472036361694 and perplexity is 129.6024951406989
At time: 67.6409056186676 and batch: 1550, loss is 4.8547586250305175 and perplexity is 128.34970706884508
At time: 68.53022933006287 and batch: 1600, loss is 4.9127858448028565 and perplexity is 136.01781159935518
At time: 69.41924285888672 and batch: 1650, loss is 4.871865129470825 and perplexity is 130.564209094423
At time: 70.30815815925598 and batch: 1700, loss is 4.899159126281738 and perplexity is 134.17690640130684
At time: 71.19750189781189 and batch: 1750, loss is 4.896609172821045 and perplexity is 133.83519739067768
At time: 72.08788514137268 and batch: 1800, loss is 4.853734283447266 and perplexity is 128.21830044082313
At time: 72.97670292854309 and batch: 1850, loss is 4.852900991439819 and perplexity is 128.11150165932278
At time: 73.86618876457214 and batch: 1900, loss is 4.9260764408111575 and perplexity is 137.8376358701242
At time: 74.75678300857544 and batch: 1950, loss is 4.849161376953125 and perplexity is 127.633308717714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.659580532340116 and perplexity of 105.59178052867763
finished 2 epochs...
Completing Train Step...
At time: 77.74607753753662 and batch: 50, loss is 4.821553201675415 and perplexity is 124.15778317285177
At time: 78.65951371192932 and batch: 100, loss is 4.7667630004882815 and perplexity is 117.53815455465339
At time: 79.57194471359253 and batch: 150, loss is 4.714403781890869 and perplexity is 111.54228781253465
At time: 80.4609055519104 and batch: 200, loss is 4.696489953994751 and perplexity is 109.56192932474946
At time: 81.35122585296631 and batch: 250, loss is 4.705270767211914 and perplexity is 110.52820831095848
At time: 82.24060726165771 and batch: 300, loss is 4.7266651630401615 and perplexity is 112.91836940800144
At time: 83.129145860672 and batch: 350, loss is 4.735973587036133 and perplexity is 113.9743686870006
At time: 84.0176796913147 and batch: 400, loss is 4.6909016990661625 and perplexity is 108.95137688344967
At time: 84.90620303153992 and batch: 450, loss is 4.677014751434326 and perplexity is 107.44883184710682
At time: 85.7946891784668 and batch: 500, loss is 4.674956569671631 and perplexity is 107.227910047573
At time: 86.6832046508789 and batch: 550, loss is 4.638064289093018 and perplexity is 103.34410952432904
At time: 87.57278776168823 and batch: 600, loss is 4.616026697158813 and perplexity is 101.09156569332158
At time: 88.46243858337402 and batch: 650, loss is 4.695252513885498 and perplexity is 109.4264368481578
At time: 89.35136151313782 and batch: 700, loss is 4.692844495773316 and perplexity is 109.16325300917521
At time: 90.23955845832825 and batch: 750, loss is 4.658389835357666 and perplexity is 105.46612753639548
At time: 91.15771722793579 and batch: 800, loss is 4.637333841323852 and perplexity is 103.26864961318762
At time: 92.05657172203064 and batch: 850, loss is 4.631764144897461 and perplexity is 102.69507338996547
At time: 92.949942111969 and batch: 900, loss is 4.629403820037842 and perplexity is 102.45296549432645
At time: 93.84015464782715 and batch: 950, loss is 4.701067438125611 and perplexity is 110.06459691632728
At time: 94.7289650440216 and batch: 1000, loss is 4.669567604064941 and perplexity is 106.6516167353437
At time: 95.66171431541443 and batch: 1050, loss is 4.586940612792969 and perplexity is 98.19355803918315
At time: 96.5659921169281 and batch: 1100, loss is 4.653072366714477 and perplexity is 104.90680312324584
At time: 97.47691774368286 and batch: 1150, loss is 4.595375413894653 and perplexity is 99.02530404550707
At time: 98.38325071334839 and batch: 1200, loss is 4.6740912818908695 and perplexity is 107.13516717767489
At time: 99.29404926300049 and batch: 1250, loss is 4.636450242996216 and perplexity is 103.17744190851398
At time: 100.20055198669434 and batch: 1300, loss is 4.6529152393341064 and perplexity is 104.89032068704293
At time: 101.10832643508911 and batch: 1350, loss is 4.5388375091552735 and perplexity is 93.58194870374544
At time: 102.0027232170105 and batch: 1400, loss is 4.552986850738526 and perplexity is 94.91548373515245
At time: 102.90996742248535 and batch: 1450, loss is 4.499331903457642 and perplexity is 89.95701125158158
At time: 103.79961609840393 and batch: 1500, loss is 4.495127840042114 and perplexity is 89.57962011558146
At time: 104.68703722953796 and batch: 1550, loss is 4.497013750076294 and perplexity is 89.7487186221819
At time: 105.57691740989685 and batch: 1600, loss is 4.567353658676147 and perplexity is 96.28895886268128
At time: 106.46720671653748 and batch: 1650, loss is 4.529122972488404 and perplexity is 92.67724493556769
At time: 107.3799901008606 and batch: 1700, loss is 4.555905561447144 and perplexity is 95.19291925400073
At time: 108.30369901657104 and batch: 1750, loss is 4.55374433517456 and perplexity is 94.98740797412724
At time: 109.1979706287384 and batch: 1800, loss is 4.518730144500733 and perplexity is 91.71905405166962
At time: 110.08751440048218 and batch: 1850, loss is 4.536515007019043 and perplexity is 93.36485662396106
At time: 110.9771933555603 and batch: 1900, loss is 4.623085279464721 and perplexity is 101.80765313811689
At time: 111.89198017120361 and batch: 1950, loss is 4.5537613677978515 and perplexity is 94.98902587264318
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507850824400436 and perplexity of 90.72662138829877
finished 3 epochs...
Completing Train Step...
At time: 114.90058946609497 and batch: 50, loss is 4.530668334960938 and perplexity is 92.82057559233347
At time: 115.81705951690674 and batch: 100, loss is 4.476996393203735 and perplexity is 87.97004802628031
At time: 116.71881484985352 and batch: 150, loss is 4.4371609878540035 and perplexity is 84.53460590424963
At time: 117.64658617973328 and batch: 200, loss is 4.435573492050171 and perplexity is 84.40051403539846
At time: 118.5543372631073 and batch: 250, loss is 4.432083501815796 and perplexity is 84.10647046868175
At time: 119.4611656665802 and batch: 300, loss is 4.457726163864136 and perplexity is 86.29107408799157
At time: 120.35116386413574 and batch: 350, loss is 4.474314985275268 and perplexity is 87.73448040961576
At time: 121.26224088668823 and batch: 400, loss is 4.430077562332153 and perplexity is 83.93792707917399
At time: 122.15150594711304 and batch: 450, loss is 4.438989324569702 and perplexity is 84.68930500590099
At time: 123.0426549911499 and batch: 500, loss is 4.441930437088013 and perplexity is 84.93875242767537
At time: 123.94194054603577 and batch: 550, loss is 4.405399332046509 and perplexity is 81.89183834995194
At time: 124.84279251098633 and batch: 600, loss is 4.3881862831115725 and perplexity is 80.49429264663974
At time: 125.75378894805908 and batch: 650, loss is 4.461597537994384 and perplexity is 86.62578660052532
At time: 126.65690517425537 and batch: 700, loss is 4.470567541122437 and perplexity is 87.40631561766241
At time: 127.55132341384888 and batch: 750, loss is 4.436699810028077 and perplexity is 84.49562940672213
At time: 128.45783877372742 and batch: 800, loss is 4.4166396045684815 and perplexity is 82.81751762787975
At time: 129.36023497581482 and batch: 850, loss is 4.411182870864868 and perplexity is 82.3668352333865
At time: 130.26068687438965 and batch: 900, loss is 4.404224147796631 and perplexity is 81.79565687787446
At time: 131.15057516098022 and batch: 950, loss is 4.488828907012939 and perplexity is 89.01713746773892
At time: 132.04017543792725 and batch: 1000, loss is 4.46020022392273 and perplexity is 86.50482769840914
At time: 132.9295630455017 and batch: 1050, loss is 4.3855330276489255 and perplexity is 80.2810038049805
At time: 133.81956958770752 and batch: 1100, loss is 4.443248119354248 and perplexity is 85.0507484868712
At time: 134.70935225486755 and batch: 1150, loss is 4.3994885921478275 and perplexity is 81.4092247005994
At time: 135.5982699394226 and batch: 1200, loss is 4.476123790740967 and perplexity is 87.89331862772255
At time: 136.4980125427246 and batch: 1250, loss is 4.443628253936768 and perplexity is 85.08308536343343
At time: 137.3942141532898 and batch: 1300, loss is 4.457312774658203 and perplexity is 86.25540966154765
At time: 138.29689764976501 and batch: 1350, loss is 4.3408565425872805 and perplexity is 76.77327075936634
At time: 139.19864654541016 and batch: 1400, loss is 4.356249675750733 and perplexity is 77.96419444747457
At time: 140.11791396141052 and batch: 1450, loss is 4.298599424362183 and perplexity is 73.59664381549703
At time: 141.03262853622437 and batch: 1500, loss is 4.301143412590027 and perplexity is 73.78411116723498
At time: 141.92367959022522 and batch: 1550, loss is 4.308904237747193 and perplexity is 74.35896453632357
At time: 142.81280827522278 and batch: 1600, loss is 4.379862365722656 and perplexity is 79.82704571121123
At time: 143.70773100852966 and batch: 1650, loss is 4.3419143581390385 and perplexity is 76.85452568792162
At time: 144.60697269439697 and batch: 1700, loss is 4.371782140731812 and perplexity is 79.18462417210435
At time: 145.5046808719635 and batch: 1750, loss is 4.371511497497559 and perplexity is 79.16319628910188
At time: 146.39343094825745 and batch: 1800, loss is 4.329851646423339 and perplexity is 75.9330207983272
At time: 147.28341484069824 and batch: 1850, loss is 4.361366453170777 and perplexity is 78.36414222647834
At time: 148.17267179489136 and batch: 1900, loss is 4.444844284057617 and perplexity is 85.18661189094071
At time: 149.06314945220947 and batch: 1950, loss is 4.3758245468139645 and perplexity is 79.50536843096745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437737611282704 and perplexity of 84.58336459490067
finished 4 epochs...
Completing Train Step...
At time: 152.07218837738037 and batch: 50, loss is 4.358689026832581 and perplexity is 78.15460863865647
At time: 152.96450328826904 and batch: 100, loss is 4.305673999786377 and perplexity is 74.11915491594411
At time: 153.85635614395142 and batch: 150, loss is 4.275403566360474 and perplexity is 71.90915357006655
At time: 154.7433271408081 and batch: 200, loss is 4.2739999389648435 and perplexity is 71.80829071561162
At time: 155.63004899024963 and batch: 250, loss is 4.266083483695984 and perplexity is 71.24206779056595
At time: 156.5172634124756 and batch: 300, loss is 4.289832267761231 and perplexity is 72.95423069688198
At time: 157.40484809875488 and batch: 350, loss is 4.307623863220215 and perplexity is 74.26381813679022
At time: 158.29295825958252 and batch: 400, loss is 4.270610380172729 and perplexity is 71.56530433342525
At time: 159.18294501304626 and batch: 450, loss is 4.286569089889526 and perplexity is 72.71655606382943
At time: 160.06896781921387 and batch: 500, loss is 4.293001117706299 and perplexity is 73.18577838299527
At time: 160.9577133655548 and batch: 550, loss is 4.251197547912597 and perplexity is 70.1894172268004
At time: 161.860835313797 and batch: 600, loss is 4.242107295989991 and perplexity is 69.55426894451595
At time: 162.791850566864 and batch: 650, loss is 4.306975431442261 and perplexity is 74.21567872640661
At time: 163.67940402030945 and batch: 700, loss is 4.323187818527222 and perplexity is 75.42869844106015
At time: 164.5670576095581 and batch: 750, loss is 4.290623378753662 and perplexity is 73.01196842619555
At time: 165.45537042617798 and batch: 800, loss is 4.272134761810303 and perplexity is 71.67448036106302
At time: 166.34461665153503 and batch: 850, loss is 4.269509925842285 and perplexity is 71.48659330125331
At time: 167.23578596115112 and batch: 900, loss is 4.252921781539917 and perplexity is 70.31054457618019
At time: 168.12565970420837 and batch: 950, loss is 4.347777404785156 and perplexity is 77.3064508916817
At time: 169.03669500350952 and batch: 1000, loss is 4.31960880279541 and perplexity is 75.15922046332354
At time: 169.9276716709137 and batch: 1050, loss is 4.253945684432983 and perplexity is 70.38257261475061
At time: 170.8359682559967 and batch: 1100, loss is 4.306288890838623 and perplexity is 74.16474413586724
At time: 171.731183052063 and batch: 1150, loss is 4.2650395154953005 and perplexity is 71.16773214601757
At time: 172.6204013824463 and batch: 1200, loss is 4.339229407310486 and perplexity is 76.64845183837257
At time: 173.52491116523743 and batch: 1250, loss is 4.311639909744263 and perplexity is 74.56266477481647
At time: 174.41574048995972 and batch: 1300, loss is 4.323451633453369 and perplexity is 75.44860028265478
At time: 175.30574822425842 and batch: 1350, loss is 4.204135107994079 and perplexity is 66.96265714690892
At time: 176.2104139328003 and batch: 1400, loss is 4.2234885787963865 and perplexity is 68.27123893193195
At time: 177.12392687797546 and batch: 1450, loss is 4.167503657341004 and perplexity is 64.55410164042898
At time: 178.02762150764465 and batch: 1500, loss is 4.168809080123902 and perplexity is 64.6384270636291
At time: 178.91666960716248 and batch: 1550, loss is 4.178351464271546 and perplexity is 65.25818404218813
At time: 179.80621314048767 and batch: 1600, loss is 4.256107130050659 and perplexity is 70.53486524471772
At time: 180.72976756095886 and batch: 1650, loss is 4.2140261888504025 and perplexity is 67.6282766244924
At time: 181.64677596092224 and batch: 1700, loss is 4.2486211824417115 and perplexity is 70.00881638262237
At time: 182.56264996528625 and batch: 1750, loss is 4.2461776494979855 and perplexity is 69.83795636949058
At time: 183.45068526268005 and batch: 1800, loss is 4.205327677726745 and perplexity is 67.04256242187716
At time: 184.33953738212585 and batch: 1850, loss is 4.238661031723023 and perplexity is 69.3149791176591
At time: 185.2538936138153 and batch: 1900, loss is 4.321333379745483 and perplexity is 75.28895015478471
At time: 186.15803813934326 and batch: 1950, loss is 4.250922889709472 and perplexity is 70.17014177478818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413342852925146 and perplexity of 82.54493840042993
finished 5 epochs...
Completing Train Step...
At time: 189.24534511566162 and batch: 50, loss is 4.237502465248108 and perplexity is 69.23471960860971
At time: 190.13596725463867 and batch: 100, loss is 4.187987170219421 and perplexity is 65.89003197600918
At time: 191.04069423675537 and batch: 150, loss is 4.161606030464172 and perplexity is 64.17450609229532
At time: 191.95240187644958 and batch: 200, loss is 4.1588600683212285 and perplexity is 63.998527054489635
At time: 192.87000608444214 and batch: 250, loss is 4.147558374404907 and perplexity is 63.27930714762484
At time: 193.78040266036987 and batch: 300, loss is 4.168327479362488 and perplexity is 64.607304642831
At time: 194.67389225959778 and batch: 350, loss is 4.189515175819397 and perplexity is 65.9907892731042
At time: 195.57695293426514 and batch: 400, loss is 4.1565641498565675 and perplexity is 63.85176020134848
At time: 196.48509049415588 and batch: 450, loss is 4.1845337629318236 and perplexity is 65.66287931049068
At time: 197.39735460281372 and batch: 500, loss is 4.184396548271179 and perplexity is 65.65387001890674
At time: 198.30305075645447 and batch: 550, loss is 4.136153178215027 and perplexity is 62.561694271483894
At time: 199.19495010375977 and batch: 600, loss is 4.136152143478394 and perplexity is 62.56162953664048
At time: 200.11821269989014 and batch: 650, loss is 4.197608346939087 and perplexity is 66.52703104426541
At time: 201.0089237689972 and batch: 700, loss is 4.21661422252655 and perplexity is 67.80352756170201
At time: 201.89996767044067 and batch: 750, loss is 4.187301106452942 and perplexity is 65.84484271562786
At time: 202.8045961856842 and batch: 800, loss is 4.166687488555908 and perplexity is 64.50143609263176
At time: 203.69477534294128 and batch: 850, loss is 4.170693755149841 and perplexity is 64.76036436282976
At time: 204.60561299324036 and batch: 900, loss is 4.1456215381622314 and perplexity is 63.15686410646686
At time: 205.50246906280518 and batch: 950, loss is 4.24568238735199 and perplexity is 69.80337683702064
At time: 206.40941905975342 and batch: 1000, loss is 4.21632303237915 and perplexity is 67.78378671682634
At time: 207.3425178527832 and batch: 1050, loss is 4.156530337333679 and perplexity is 63.849601248745245
At time: 208.2477171421051 and batch: 1100, loss is 4.2004869222640995 and perplexity is 66.7188100069442
At time: 209.14294505119324 and batch: 1150, loss is 4.161898565292359 and perplexity is 64.19328211659558
At time: 210.03211212158203 and batch: 1200, loss is 4.237734808921814 and perplexity is 69.25080772662542
At time: 210.92002725601196 and batch: 1250, loss is 4.211971039772034 and perplexity is 67.4894331549988
At time: 211.80765557289124 and batch: 1300, loss is 4.220097379684448 and perplexity is 68.04010969123622
At time: 212.69491124153137 and batch: 1350, loss is 4.1040921831130985 and perplexity is 60.58771702127562
At time: 213.58195328712463 and batch: 1400, loss is 4.122877020835876 and perplexity is 61.736604502151465
At time: 214.47017860412598 and batch: 1450, loss is 4.06618028640747 and perplexity is 58.33371840180813
At time: 215.3583390712738 and batch: 1500, loss is 4.070328569412231 and perplexity is 58.57620577986158
At time: 216.24650645256042 and batch: 1550, loss is 4.077155246734619 and perplexity is 58.977454675559116
At time: 217.1343219280243 and batch: 1600, loss is 4.164993214607239 and perplexity is 64.39224551530343
At time: 218.0230929851532 and batch: 1650, loss is 4.114284720420837 and perplexity is 61.208417470054336
At time: 218.9140431880951 and batch: 1700, loss is 4.154475388526916 and perplexity is 63.71852830706411
At time: 219.8094789981842 and batch: 1750, loss is 4.152247376441956 and perplexity is 63.57672068916482
At time: 220.69793701171875 and batch: 1800, loss is 4.111313247680664 and perplexity is 61.02680828307597
At time: 221.61041069030762 and batch: 1850, loss is 4.14487850189209 and perplexity is 63.10995369595387
At time: 222.50013184547424 and batch: 1900, loss is 4.227120394706726 and perplexity is 68.51963830105996
At time: 223.38816928863525 and batch: 1950, loss is 4.151906991004944 and perplexity is 63.55508378196224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397680947946948 and perplexity of 81.26219871304303
finished 6 epochs...
Completing Train Step...
At time: 226.4113895893097 and batch: 50, loss is 4.146454229354858 and perplexity is 63.20947617272435
At time: 227.29831314086914 and batch: 100, loss is 4.101591038703918 and perplexity is 60.43636774368253
At time: 228.21247577667236 and batch: 150, loss is 4.077113180160523 and perplexity is 58.97497374827443
At time: 229.10820817947388 and batch: 200, loss is 4.07139928817749 and perplexity is 58.63895801158867
At time: 230.03926062583923 and batch: 250, loss is 4.057958483695984 and perplexity is 57.856076307848745
At time: 230.9465262889862 and batch: 300, loss is 4.080382361412048 and perplexity is 59.16808911934263
At time: 231.83381414413452 and batch: 350, loss is 4.091568865776062 and perplexity is 59.833689134255536
At time: 232.7311770915985 and batch: 400, loss is 4.062866396903992 and perplexity is 58.140726857640956
At time: 233.62232375144958 and batch: 450, loss is 4.0980571746826175 and perplexity is 60.2231707645724
At time: 234.5094084739685 and batch: 500, loss is 4.102057490348816 and perplexity is 60.464564962636544
At time: 235.39702439308167 and batch: 550, loss is 4.053270297050476 and perplexity is 57.58547104317287
At time: 236.2837142944336 and batch: 600, loss is 4.050515384674072 and perplexity is 57.42704643944325
At time: 237.17096066474915 and batch: 650, loss is 4.1159792184829715 and perplexity is 61.31222293908846
At time: 238.05848455429077 and batch: 700, loss is 4.138415579795837 and perplexity is 62.7033941781078
At time: 238.94561290740967 and batch: 750, loss is 4.101598768234253 and perplexity is 60.43683489022575
At time: 239.8330397605896 and batch: 800, loss is 4.081721148490906 and perplexity is 59.24735564119448
At time: 240.72051858901978 and batch: 850, loss is 4.085551428794861 and perplexity is 59.47472478636905
At time: 241.60817217826843 and batch: 900, loss is 4.068203535079956 and perplexity is 58.45186149625333
At time: 242.49542593955994 and batch: 950, loss is 4.165791034698486 and perplexity is 64.44363944132337
At time: 243.382399559021 and batch: 1000, loss is 4.13937481880188 and perplexity is 62.76357057677489
At time: 244.29933214187622 and batch: 1050, loss is 4.075607953071594 and perplexity is 58.88626979676312
At time: 245.1909317970276 and batch: 1100, loss is 4.121408257484436 and perplexity is 61.64599459855834
At time: 246.07909631729126 and batch: 1150, loss is 4.083084254264832 and perplexity is 59.328171121269285
At time: 246.96638202667236 and batch: 1200, loss is 4.156484169960022 and perplexity is 63.84665354839083
At time: 247.85404777526855 and batch: 1250, loss is 4.134301776885986 and perplexity is 62.445974622372944
At time: 248.7644112110138 and batch: 1300, loss is 4.1404697751998905 and perplexity is 62.83233158822467
At time: 249.65862011909485 and batch: 1350, loss is 4.027407412528992 and perplexity is 56.11523882935848
At time: 250.54952430725098 and batch: 1400, loss is 4.045343608856201 and perplexity is 57.13081331531509
At time: 251.43952202796936 and batch: 1450, loss is 3.991430788040161 and perplexity is 54.13228580829022
At time: 252.34105777740479 and batch: 1500, loss is 3.9949005651474 and perplexity is 54.32043901041684
At time: 253.23120832443237 and batch: 1550, loss is 4.000284352302551 and perplexity is 54.61367735033078
At time: 254.1303243637085 and batch: 1600, loss is 4.090859265327453 and perplexity is 59.791246182153834
At time: 255.0502851009369 and batch: 1650, loss is 4.039447774887085 and perplexity is 56.794970534971796
At time: 255.94453716278076 and batch: 1700, loss is 4.083931007385254 and perplexity is 59.378428710177424
At time: 256.8339512348175 and batch: 1750, loss is 4.076762275695801 and perplexity is 58.95428279716518
At time: 257.7235996723175 and batch: 1800, loss is 4.032230834960938 and perplexity is 56.386560153750054
At time: 258.61443758010864 and batch: 1850, loss is 4.073011946678162 and perplexity is 58.73359891691603
At time: 259.5349442958832 and batch: 1900, loss is 4.149553227424621 and perplexity is 63.405666056395944
At time: 260.4347460269928 and batch: 1950, loss is 4.078230347633362 and perplexity is 59.040895486612236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392792173873547 and perplexity of 80.86589569010592
finished 7 epochs...
Completing Train Step...
At time: 263.46297216415405 and batch: 50, loss is 4.0735931396484375 and perplexity is 58.7677443933198
At time: 264.39548993110657 and batch: 100, loss is 4.02968991279602 and perplexity is 56.24346816304423
At time: 265.2844920158386 and batch: 150, loss is 4.010167803764343 and perplexity is 55.15612519239517
At time: 266.17141580581665 and batch: 200, loss is 4.0063175773620605 and perplexity is 54.94416992265928
At time: 267.06070256233215 and batch: 250, loss is 3.982925100326538 and perplexity is 53.67380609672719
At time: 267.9633135795593 and batch: 300, loss is 4.00610502243042 and perplexity is 54.93249250946717
At time: 268.8728210926056 and batch: 350, loss is 4.015666532516479 and perplexity is 55.460249145117494
At time: 269.76166558265686 and batch: 400, loss is 3.9915659999847413 and perplexity is 54.139605634771776
At time: 270.65168166160583 and batch: 450, loss is 4.026956257820129 and perplexity is 56.08992788512682
At time: 271.5700705051422 and batch: 500, loss is 4.033108701705933 and perplexity is 56.43608177328484
At time: 272.4590299129486 and batch: 550, loss is 3.98452290058136 and perplexity is 53.75963466798253
At time: 273.3743178844452 and batch: 600, loss is 3.9853279638290404 and perplexity is 53.802932000269415
At time: 274.2813560962677 and batch: 650, loss is 4.046808018684387 and perplexity is 57.21453752814417
At time: 275.1972715854645 and batch: 700, loss is 4.069885501861572 and perplexity is 58.55025831250468
At time: 276.0877788066864 and batch: 750, loss is 4.035889558792114 and perplexity is 56.59324086841395
At time: 276.99426007270813 and batch: 800, loss is 4.014912285804749 and perplexity is 55.41843420594054
At time: 277.89061546325684 and batch: 850, loss is 4.0181844568252565 and perplexity is 55.600069809664646
At time: 278.7802131175995 and batch: 900, loss is 3.998858003616333 and perplexity is 54.53583473194818
At time: 279.67235469818115 and batch: 950, loss is 4.099184403419494 and perplexity is 60.29109432878859
At time: 280.5842196941376 and batch: 1000, loss is 4.072938446998596 and perplexity is 58.72928217485742
At time: 281.49124240875244 and batch: 1050, loss is 4.012527594566345 and perplexity is 55.286435801716124
At time: 282.38078451156616 and batch: 1100, loss is 4.056256566047669 and perplexity is 57.75769377375096
At time: 283.2697186470032 and batch: 1150, loss is 4.016843514442444 and perplexity is 55.525563285212094
At time: 284.1600458621979 and batch: 1200, loss is 4.091750068664551 and perplexity is 59.84453215391917
At time: 285.0642936229706 and batch: 1250, loss is 4.07233690738678 and perplexity is 58.693964808718036
At time: 285.96596002578735 and batch: 1300, loss is 4.0753698778152465 and perplexity is 58.872252101685305
At time: 286.85579228401184 and batch: 1350, loss is 3.961245141029358 and perplexity is 52.52268339910591
At time: 287.74517130851746 and batch: 1400, loss is 3.9844089794158934 and perplexity is 53.75351065657999
At time: 288.63446497917175 and batch: 1450, loss is 3.927278323173523 and perplexity is 50.76861370418298
At time: 289.5250496864319 and batch: 1500, loss is 3.935679068565369 and perplexity is 51.19690436340665
At time: 290.41371154785156 and batch: 1550, loss is 3.9398397493362425 and perplexity is 51.410362095725674
At time: 291.30349469184875 and batch: 1600, loss is 4.030988621711731 and perplexity is 56.316559508515795
At time: 292.1932032108307 and batch: 1650, loss is 3.9796960020065306 and perplexity is 53.50076762910148
At time: 293.08254766464233 and batch: 1700, loss is 4.019705262184143 and perplexity is 55.68469102367384
At time: 293.9710645675659 and batch: 1750, loss is 4.015725436210633 and perplexity is 55.46351605488639
At time: 294.8602223396301 and batch: 1800, loss is 3.975431413650513 and perplexity is 53.273094689168495
At time: 295.74930238723755 and batch: 1850, loss is 4.015304098129272 and perplexity is 55.4401520858569
At time: 296.63825249671936 and batch: 1900, loss is 4.085724320411682 and perplexity is 59.4850083566433
At time: 297.5284321308136 and batch: 1950, loss is 4.01303337097168 and perplexity is 55.31440544907731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.394789868731832 and perplexity of 81.02760254083067
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 300.50420022010803 and batch: 50, loss is 4.039099078178406 and perplexity is 56.77516976810848
At time: 301.4194030761719 and batch: 100, loss is 4.0207742500305175 and perplexity is 55.74424910937056
At time: 302.30780386924744 and batch: 150, loss is 3.997438893318176 and perplexity is 54.45849725544517
At time: 303.1959640979767 and batch: 200, loss is 3.9917288875579833 and perplexity is 54.14842502201469
At time: 304.0860435962677 and batch: 250, loss is 3.9743806600570677 and perplexity is 53.21714719215422
At time: 304.97540259361267 and batch: 300, loss is 3.979923849105835 and perplexity is 53.51295901264927
At time: 305.8651089668274 and batch: 350, loss is 3.979067530632019 and perplexity is 53.46715449168589
At time: 306.75565814971924 and batch: 400, loss is 3.9522942447662355 and perplexity is 52.05465606539739
At time: 307.64154624938965 and batch: 450, loss is 3.986537537574768 and perplexity is 53.86804998882544
At time: 308.5296702384949 and batch: 500, loss is 3.9926455879211424 and perplexity is 54.198085661382294
At time: 309.4233946800232 and batch: 550, loss is 3.9436755561828614 and perplexity is 51.60794100966005
At time: 310.33660411834717 and batch: 600, loss is 3.930842385292053 and perplexity is 50.94987902565174
At time: 311.22643637657166 and batch: 650, loss is 3.9747668361663817 and perplexity is 53.237702351706
At time: 312.11652278900146 and batch: 700, loss is 3.9973100137710573 and perplexity is 54.451479121238805
At time: 313.04551887512207 and batch: 750, loss is 3.9530050802230834 and perplexity is 52.0916715150111
At time: 313.9354758262634 and batch: 800, loss is 3.9361484718322752 and perplexity is 51.220941998801244
At time: 314.8245348930359 and batch: 850, loss is 3.9336294507980347 and perplexity is 51.09207774254068
At time: 315.71392488479614 and batch: 900, loss is 3.9085590839385986 and perplexity is 49.827103548268376
At time: 316.60491609573364 and batch: 950, loss is 4.001754145622254 and perplexity is 54.694007188132844
At time: 317.495313167572 and batch: 1000, loss is 3.9670749044418336 and perplexity is 52.829772475712076
At time: 318.38301825523376 and batch: 1050, loss is 3.897602925300598 and perplexity is 49.284169563775166
At time: 319.2713499069214 and batch: 1100, loss is 3.9348104858398436 and perplexity is 51.15245492347859
At time: 320.202755689621 and batch: 1150, loss is 3.8976603603363036 and perplexity is 49.28700028310424
At time: 321.094929933548 and batch: 1200, loss is 3.961573419570923 and perplexity is 52.539928299421746
At time: 321.9865276813507 and batch: 1250, loss is 3.935710082054138 and perplexity is 51.198492182646916
At time: 322.8761394023895 and batch: 1300, loss is 3.9336069345474245 and perplexity is 51.090927353465304
At time: 323.8020167350769 and batch: 1350, loss is 3.818366904258728 and perplexity is 45.52979306261533
At time: 324.6934382915497 and batch: 1400, loss is 3.8304835414886473 and perplexity is 46.08481676838683
At time: 325.60348987579346 and batch: 1450, loss is 3.77084144115448 and perplexity is 43.416581969043285
At time: 326.51351714134216 and batch: 1500, loss is 3.767862095832825 and perplexity is 43.28742148106043
At time: 327.40562987327576 and batch: 1550, loss is 3.7744572448730467 and perplexity is 43.57385196494631
At time: 328.29688715934753 and batch: 1600, loss is 3.8632864284515382 and perplexity is 47.62159945850683
At time: 329.18669509887695 and batch: 1650, loss is 3.797249402999878 and perplexity is 44.578398494146455
At time: 330.07794880867004 and batch: 1700, loss is 3.824380645751953 and perplexity is 45.80442241563598
At time: 330.96874046325684 and batch: 1750, loss is 3.818404293060303 and perplexity is 45.53149539883785
At time: 331.8581004142761 and batch: 1800, loss is 3.775841555595398 and perplexity is 43.63421348534617
At time: 332.78517031669617 and batch: 1850, loss is 3.794918432235718 and perplexity is 44.474608563185434
At time: 333.67487716674805 and batch: 1900, loss is 3.857430143356323 and perplexity is 47.34352882058099
At time: 334.56406235694885 and batch: 1950, loss is 3.788993058204651 and perplexity is 44.21185908579027
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312454294603924 and perplexity of 74.62341221264448
finished 9 epochs...
Completing Train Step...
At time: 337.53833985328674 and batch: 50, loss is 3.9529994535446167 and perplexity is 52.091378412749286
At time: 338.4788281917572 and batch: 100, loss is 3.9262188148498534 and perplexity is 50.7148524206751
At time: 339.36820578575134 and batch: 150, loss is 3.8989099931716917 and perplexity is 49.34862943590235
At time: 340.25756096839905 and batch: 200, loss is 3.8914081048965454 and perplexity is 48.979806694567664
At time: 341.148316860199 and batch: 250, loss is 3.876001958847046 and perplexity is 48.23099956583
At time: 342.06254172325134 and batch: 300, loss is 3.8856107091903684 and perplexity is 48.69667288591585
At time: 342.952406167984 and batch: 350, loss is 3.8866965627670287 and perplexity is 48.749579061321995
At time: 343.8417935371399 and batch: 400, loss is 3.8647943782806395 and perplexity is 47.69346461217699
At time: 344.73191809654236 and batch: 450, loss is 3.903999676704407 and perplexity is 49.60043861342617
At time: 345.62376260757446 and batch: 500, loss is 3.9152454853057863 and perplexity is 50.1613838823829
At time: 346.5143804550171 and batch: 550, loss is 3.866468029022217 and perplexity is 47.77335364911837
At time: 347.4034984111786 and batch: 600, loss is 3.8552444076538084 and perplexity is 47.24016138745199
At time: 348.29342770576477 and batch: 650, loss is 3.900547022819519 and perplexity is 49.42948076532434
At time: 349.1805899143219 and batch: 700, loss is 3.928776698112488 and perplexity is 50.84474114212293
At time: 350.0711762905121 and batch: 750, loss is 3.883790521621704 and perplexity is 48.6081164264265
At time: 350.9599390029907 and batch: 800, loss is 3.8708725357055664 and perplexity is 47.98423577950793
At time: 351.8496458530426 and batch: 850, loss is 3.8702164697647095 and perplexity is 47.952765281204776
At time: 352.7401874065399 and batch: 900, loss is 3.8443832778930664 and perplexity is 46.72985612699707
At time: 353.6301908493042 and batch: 950, loss is 3.9425689029693602 and perplexity is 51.550860505886455
At time: 354.52002000808716 and batch: 1000, loss is 3.909540901184082 and perplexity is 49.8760486814807
At time: 355.40968918800354 and batch: 1050, loss is 3.8437623357772828 and perplexity is 46.700848598193495
At time: 356.29865169525146 and batch: 1100, loss is 3.8785085391998293 and perplexity is 48.35204608477252
At time: 357.1884183883667 and batch: 1150, loss is 3.846361675262451 and perplexity is 46.822397863409925
At time: 358.0779106616974 and batch: 1200, loss is 3.9123905229568483 and perplexity is 50.018379253577166
At time: 358.96722197532654 and batch: 1250, loss is 3.8923377275466917 and perplexity is 49.025360602962614
At time: 359.856240272522 and batch: 1300, loss is 3.891194748878479 and perplexity is 48.96935767276612
At time: 360.74575209617615 and batch: 1350, loss is 3.7772117328643797 and perplexity is 43.69404107065246
At time: 361.6489760875702 and batch: 1400, loss is 3.7957074546813967 and perplexity is 44.50971387522289
At time: 362.5531258583069 and batch: 1450, loss is 3.736603946685791 and perplexity is 41.9552656332074
At time: 363.44978618621826 and batch: 1500, loss is 3.735300350189209 and perplexity is 41.900608529059696
At time: 364.3409481048584 and batch: 1550, loss is 3.746526598930359 and perplexity is 42.37364542976116
At time: 365.2556805610657 and batch: 1600, loss is 3.839665560722351 and perplexity is 46.509917095363804
At time: 366.14876341819763 and batch: 1650, loss is 3.775656714439392 and perplexity is 43.626148832247004
At time: 367.03914523124695 and batch: 1700, loss is 3.805059595108032 and perplexity is 44.92792751792661
At time: 367.9589879512787 and batch: 1750, loss is 3.8020140647888185 and perplexity is 44.79130630012157
At time: 368.8663465976715 and batch: 1800, loss is 3.7614274549484255 and perplexity is 43.00977669923076
At time: 369.7587823867798 and batch: 1850, loss is 3.7880607652664184 and perplexity is 44.17065988962238
At time: 370.65931725502014 and batch: 1900, loss is 3.8523856019973755 and perplexity is 47.105303804523835
At time: 371.57108545303345 and batch: 1950, loss is 3.7863792085647585 and perplexity is 44.09644683468545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3103387876998545 and perplexity of 74.465712734884
finished 10 epochs...
Completing Train Step...
At time: 374.63553977012634 and batch: 50, loss is 3.910820336341858 and perplexity is 49.939902691516934
At time: 375.5298275947571 and batch: 100, loss is 3.8834999418258667 and perplexity is 48.59399394183299
At time: 376.43074202537537 and batch: 150, loss is 3.8572166776657104 and perplexity is 47.333423680094036
At time: 377.3425033092499 and batch: 200, loss is 3.847300796508789 and perplexity is 46.86639042598976
At time: 378.23681926727295 and batch: 250, loss is 3.832546067237854 and perplexity is 46.17996597973783
At time: 379.1487600803375 and batch: 300, loss is 3.8431507968902587 and perplexity is 46.67229794402609
At time: 380.0615146160126 and batch: 350, loss is 3.844183874130249 and perplexity is 46.7205389468207
At time: 380.9513649940491 and batch: 400, loss is 3.8227062749862672 and perplexity is 45.72779300073284
At time: 381.8608365058899 and batch: 450, loss is 3.8649075984954835 and perplexity is 47.69886478218547
At time: 382.7709159851074 and batch: 500, loss is 3.8786716270446777 and perplexity is 48.35993235882273
At time: 383.6819660663605 and batch: 550, loss is 3.830049476623535 and perplexity is 46.06481730945777
At time: 384.5949456691742 and batch: 600, loss is 3.819448347091675 and perplexity is 45.57905756457843
At time: 385.4972867965698 and batch: 650, loss is 3.863898434638977 and perplexity is 47.65075309222332
At time: 386.4171426296234 and batch: 700, loss is 3.8927596521377565 and perplexity is 49.0460499725568
At time: 387.3613238334656 and batch: 750, loss is 3.849156222343445 and perplexity is 46.95342825871519
At time: 388.25640630722046 and batch: 800, loss is 3.8367274475097655 and perplexity is 46.37346624561135
At time: 389.1464879512787 and batch: 850, loss is 3.837101712226868 and perplexity is 46.39082544610232
At time: 390.03339886665344 and batch: 900, loss is 3.8110493516921995 and perplexity is 45.19784242289797
At time: 390.92354130744934 and batch: 950, loss is 3.910531311035156 and perplexity is 49.925470881504474
At time: 391.83274269104004 and batch: 1000, loss is 3.8793844175338745 and perplexity is 48.394415146707956
At time: 392.7240970134735 and batch: 1050, loss is 3.81525456905365 and perplexity is 45.38830937133163
At time: 393.6366996765137 and batch: 1100, loss is 3.848052878379822 and perplexity is 46.90165104636454
At time: 394.5465135574341 and batch: 1150, loss is 3.8177076148986817 and perplexity is 45.499785647355765
At time: 395.4355821609497 and batch: 1200, loss is 3.884795274734497 and perplexity is 48.6569801265796
At time: 396.33935952186584 and batch: 1250, loss is 3.8671865701675414 and perplexity is 47.80769310504394
At time: 397.2541377544403 and batch: 1300, loss is 3.865364170074463 and perplexity is 47.72064770054691
At time: 398.15917229652405 and batch: 1350, loss is 3.7527210664749147 and perplexity is 42.63694225100483
At time: 399.07937598228455 and batch: 1400, loss is 3.7734639501571654 and perplexity is 43.530591776653985
At time: 399.96534872055054 and batch: 1450, loss is 3.713840742111206 and perplexity is 41.011017171638095
At time: 400.8567006587982 and batch: 1500, loss is 3.7132827472686767 and perplexity is 40.98813961894123
At time: 401.75496077537537 and batch: 1550, loss is 3.726375308036804 and perplexity is 41.52830770334916
At time: 402.6438932418823 and batch: 1600, loss is 3.8201305627822877 and perplexity is 45.610162921887316
At time: 403.5325367450714 and batch: 1650, loss is 3.7582588529586793 and perplexity is 42.87371151724785
At time: 404.420761346817 and batch: 1700, loss is 3.7877852439880373 and perplexity is 44.158491609329694
At time: 405.30986428260803 and batch: 1750, loss is 3.785856285095215 and perplexity is 44.07339379572499
At time: 406.1975665092468 and batch: 1800, loss is 3.7459107637405396 and perplexity is 42.34755828130107
At time: 407.0860869884491 and batch: 1850, loss is 3.776149773597717 and perplexity is 43.64766440826121
At time: 407.97474575042725 and batch: 1900, loss is 3.840820231437683 and perplexity is 46.563651751553095
At time: 408.86172366142273 and batch: 1950, loss is 3.7752500200271606 and perplexity is 43.60840992869072
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312310932957849 and perplexity of 74.61271484424842
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 411.86257576942444 and batch: 50, loss is 3.9013607025146486 and perplexity is 49.46971689760586
At time: 412.74993872642517 and batch: 100, loss is 3.9040101194381713 and perplexity is 49.6009565803057
At time: 413.6376395225525 and batch: 150, loss is 3.8861276721954345 and perplexity is 48.721853772500275
At time: 414.52494597435 and batch: 200, loss is 3.880900502204895 and perplexity is 48.46784082338216
At time: 415.41340589523315 and batch: 250, loss is 3.8727528715133666 and perplexity is 48.07454713748498
At time: 416.30169558525085 and batch: 300, loss is 3.874034729003906 and perplexity is 48.13621136977281
At time: 417.19170594215393 and batch: 350, loss is 3.8728568267822268 and perplexity is 48.079544999730544
At time: 418.0794093608856 and batch: 400, loss is 3.841318340301514 and perplexity is 46.58685129669273
At time: 418.9671597480774 and batch: 450, loss is 3.8811020469665527 and perplexity is 48.477610247264
At time: 419.85467863082886 and batch: 500, loss is 3.901608901023865 and perplexity is 49.48199673144638
At time: 420.74243092536926 and batch: 550, loss is 3.865246920585632 and perplexity is 47.71505280700296
At time: 421.6296036243439 and batch: 600, loss is 3.8449589681625365 and perplexity is 46.756765795537085
At time: 422.51649594306946 and batch: 650, loss is 3.878954863548279 and perplexity is 48.37363159694901
At time: 423.40405106544495 and batch: 700, loss is 3.900966167449951 and perplexity is 49.450203209319355
At time: 424.29136323928833 and batch: 750, loss is 3.854139657020569 and perplexity is 47.188001606325464
At time: 425.1787226200104 and batch: 800, loss is 3.8345471572875978 and perplexity is 46.27246877249858
At time: 426.06630969047546 and batch: 850, loss is 3.8344151639938353 and perplexity is 46.26636152000183
At time: 426.9539167881012 and batch: 900, loss is 3.806780152320862 and perplexity is 45.00529512628732
At time: 427.84237456321716 and batch: 950, loss is 3.9104824686050415 and perplexity is 49.92303245973171
At time: 428.73146510124207 and batch: 1000, loss is 3.875862407684326 and perplexity is 48.22426934337756
At time: 429.61994075775146 and batch: 1050, loss is 3.8073070526123045 and perplexity is 45.02901467777636
At time: 430.5081031322479 and batch: 1100, loss is 3.8303752326965332 and perplexity is 46.07982564784384
At time: 431.459356546402 and batch: 1150, loss is 3.8063927125930785 and perplexity is 44.98786166442072
At time: 432.3451507091522 and batch: 1200, loss is 3.866312608718872 and perplexity is 47.76592927696645
At time: 433.23262548446655 and batch: 1250, loss is 3.8444720888137818 and perplexity is 46.734006432838115
At time: 434.12008118629456 and batch: 1300, loss is 3.8433391284942626 and perplexity is 46.681088640517444
At time: 435.0164897441864 and batch: 1350, loss is 3.729462389945984 and perplexity is 41.65670707850182
At time: 435.9171738624573 and batch: 1400, loss is 3.7435581254959107 and perplexity is 42.248046899162375
At time: 436.8049349784851 and batch: 1450, loss is 3.6786549425125123 and perplexity is 39.59310324102378
At time: 437.6913146972656 and batch: 1500, loss is 3.676553936004639 and perplexity is 39.51000519877907
At time: 438.57837867736816 and batch: 1550, loss is 3.688771162033081 and perplexity is 39.995668551300824
At time: 439.47979640960693 and batch: 1600, loss is 3.7790981101989747 and perplexity is 43.77654230915369
At time: 440.3654773235321 and batch: 1650, loss is 3.7154341983795165 and perplexity is 41.07641852728168
At time: 441.27108240127563 and batch: 1700, loss is 3.7379986333847044 and perplexity is 42.01382090777513
At time: 442.1657979488373 and batch: 1750, loss is 3.7348609447479246 and perplexity is 41.88220121811137
At time: 443.05523324012756 and batch: 1800, loss is 3.6953421306610106 and perplexity is 40.2593441880329
At time: 443.9445290565491 and batch: 1850, loss is 3.719345741271973 and perplexity is 41.23740534838717
At time: 444.8327956199646 and batch: 1900, loss is 3.786596064567566 and perplexity is 44.10601045081033
At time: 445.72054290771484 and batch: 1950, loss is 3.721322150230408 and perplexity is 41.31898791944606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284583371184593 and perplexity of 72.57230470700343
finished 12 epochs...
Completing Train Step...
At time: 448.71543765068054 and batch: 50, loss is 3.890584473609924 and perplexity is 48.93948200198016
At time: 449.60508918762207 and batch: 100, loss is 3.877331099510193 and perplexity is 48.295147970259784
At time: 450.4932234287262 and batch: 150, loss is 3.854535756111145 and perplexity is 47.20669643310534
At time: 451.3817923069 and batch: 200, loss is 3.84116277217865 and perplexity is 46.5796044313916
At time: 452.27066802978516 and batch: 250, loss is 3.832609429359436 and perplexity is 46.182892133059546
At time: 453.1591739654541 and batch: 300, loss is 3.8333650493621825 and perplexity is 46.2178020377901
At time: 454.09185671806335 and batch: 350, loss is 3.8351806211471557 and perplexity is 46.30178999514542
At time: 454.9798059463501 and batch: 400, loss is 3.8053837823867798 and perplexity is 44.94249494164756
At time: 455.86996936798096 and batch: 450, loss is 3.8483871173858644 and perplexity is 46.91733002770964
At time: 456.7613229751587 and batch: 500, loss is 3.868587164878845 and perplexity is 47.874699220418265
At time: 457.671523809433 and batch: 550, loss is 3.8324326133728026 and perplexity is 46.17472698130741
At time: 458.57830810546875 and batch: 600, loss is 3.8142094802856445 and perplexity is 45.340899337171145
At time: 459.4992997646332 and batch: 650, loss is 3.850049171447754 and perplexity is 46.99537400534435
At time: 460.41465640068054 and batch: 700, loss is 3.8729904317855834 and perplexity is 48.085969096637804
At time: 461.3045105934143 and batch: 750, loss is 3.8285574436187746 and perplexity is 45.996138330066664
At time: 462.1933410167694 and batch: 800, loss is 3.809749836921692 and perplexity is 45.13914530621974
At time: 463.08291029930115 and batch: 850, loss is 3.8107455587387085 and perplexity is 45.184113722303735
At time: 463.9729311466217 and batch: 900, loss is 3.7833010482788088 and perplexity is 43.96091959757772
At time: 464.8629858493805 and batch: 950, loss is 3.8886347579956055 and perplexity is 48.84415688839277
At time: 465.7543728351593 and batch: 1000, loss is 3.8551603603363036 and perplexity is 47.236191145455315
At time: 466.64423513412476 and batch: 1050, loss is 3.78893958568573 and perplexity is 44.20949502952537
At time: 467.5346236228943 and batch: 1100, loss is 3.8125290727615355 and perplexity is 45.26477212905555
At time: 468.42516684532166 and batch: 1150, loss is 3.7896997690200807 and perplexity is 44.2431151279671
At time: 469.3173460960388 and batch: 1200, loss is 3.8510967111587524 and perplexity is 47.04462931979295
At time: 470.2079768180847 and batch: 1250, loss is 3.8312916231155394 and perplexity is 46.12207211274839
At time: 471.09936928749084 and batch: 1300, loss is 3.831163902282715 and perplexity is 46.11618173945625
At time: 471.99116373062134 and batch: 1350, loss is 3.717791686058044 and perplexity is 41.17336991378473
At time: 472.8817455768585 and batch: 1400, loss is 3.73464467048645 and perplexity is 41.87314415541408
At time: 473.7728691101074 and batch: 1450, loss is 3.67143789768219 and perplexity is 39.308386681852355
At time: 474.6643497943878 and batch: 1500, loss is 3.6709301328659056 and perplexity is 39.28843233259738
At time: 475.55548310279846 and batch: 1550, loss is 3.685424427986145 and perplexity is 39.86203742428084
At time: 476.4454183578491 and batch: 1600, loss is 3.7774438571929934 and perplexity is 43.70418469784618
At time: 477.35085129737854 and batch: 1650, loss is 3.7150680589675904 and perplexity is 41.06138158453474
At time: 478.2479453086853 and batch: 1700, loss is 3.738750514984131 and perplexity is 42.04542220536562
At time: 479.13534212112427 and batch: 1750, loss is 3.7366074991226195 and perplexity is 41.955414676902905
At time: 480.0234341621399 and batch: 1800, loss is 3.6985361194610595 and perplexity is 40.38813765542175
At time: 480.92836833000183 and batch: 1850, loss is 3.7240736627578737 and perplexity is 41.43283418521605
At time: 481.82079315185547 and batch: 1900, loss is 3.791988091468811 and perplexity is 44.344473567683075
At time: 482.7093539237976 and batch: 1950, loss is 3.72666015625 and perplexity is 41.54013865252787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283157135719477 and perplexity of 72.46887328855657
finished 13 epochs...
Completing Train Step...
At time: 485.66056871414185 and batch: 50, loss is 3.8774198579788206 and perplexity is 48.29943476387758
At time: 486.57289457321167 and batch: 100, loss is 3.862939167022705 and perplexity is 47.60506518485944
At time: 487.4797194004059 and batch: 150, loss is 3.839529585838318 and perplexity is 46.50359334472576
At time: 488.36962485313416 and batch: 200, loss is 3.825148844718933 and perplexity is 45.83962284435422
At time: 489.25714015960693 and batch: 250, loss is 3.81566734790802 and perplexity is 45.407048572982745
At time: 490.14560866355896 and batch: 300, loss is 3.8164381980895996 and perplexity is 45.44206409874854
At time: 491.0571949481964 and batch: 350, loss is 3.8179145193099977 and perplexity is 45.509200727697376
At time: 491.94351959228516 and batch: 400, loss is 3.7888589668273926 and perplexity is 44.205931054172154
At time: 492.8369781970978 and batch: 450, loss is 3.8333111238479614 and perplexity is 46.21530978624762
At time: 493.73932218551636 and batch: 500, loss is 3.853701767921448 and perplexity is 47.1673430182281
At time: 494.6251165866852 and batch: 550, loss is 3.817844591140747 and perplexity is 45.506018463872664
At time: 495.51236176490784 and batch: 600, loss is 3.7999202251434325 and perplexity is 44.69761860495548
At time: 496.39908242225647 and batch: 650, loss is 3.836360688209534 and perplexity is 46.35646146410329
At time: 497.287841796875 and batch: 700, loss is 3.8591231393814085 and perplexity is 47.423749113845716
At time: 498.1753239631653 and batch: 750, loss is 3.8157416152954102 and perplexity is 45.41042096107704
At time: 499.1057074069977 and batch: 800, loss is 3.797291388511658 and perplexity is 44.58027018031315
At time: 499.99213004112244 and batch: 850, loss is 3.799013071060181 and perplexity is 44.65708936363913
At time: 500.88044238090515 and batch: 900, loss is 3.7713817024230956 and perplexity is 43.44004460410263
At time: 501.8013913631439 and batch: 950, loss is 3.8777133417129517 and perplexity is 48.31361194263242
At time: 502.6981599330902 and batch: 1000, loss is 3.8446616411209105 and perplexity is 46.74286581121011
At time: 503.58554244041443 and batch: 1050, loss is 3.7789631700515747 and perplexity is 43.77063549462401
At time: 504.47293996810913 and batch: 1100, loss is 3.8026469373703002 and perplexity is 44.81966246173982
At time: 505.3599555492401 and batch: 1150, loss is 3.7803045988082884 and perplexity is 43.82939008251262
At time: 506.2640767097473 and batch: 1200, loss is 3.842448058128357 and perplexity is 46.63951103281978
At time: 507.1607699394226 and batch: 1250, loss is 3.823741011619568 and perplexity is 45.775133711670726
At time: 508.048832654953 and batch: 1300, loss is 3.8239247846603392 and perplexity is 45.78354672020303
At time: 508.93672943115234 and batch: 1350, loss is 3.710994687080383 and perplexity is 40.89446349765669
At time: 509.8276882171631 and batch: 1400, loss is 3.728847885131836 and perplexity is 41.63111669497275
At time: 510.7169556617737 and batch: 1450, loss is 3.665923628807068 and perplexity is 39.09222619988551
At time: 511.60675597190857 and batch: 1500, loss is 3.6659630727767945 and perplexity is 39.09376818288304
At time: 512.4967181682587 and batch: 1550, loss is 3.681180810928345 and perplexity is 39.69323661861532
At time: 513.3892180919647 and batch: 1600, loss is 3.7738197374343874 and perplexity is 43.546082162855825
At time: 514.2776901721954 and batch: 1650, loss is 3.712174210548401 and perplexity is 40.94272793598725
At time: 515.1694798469543 and batch: 1700, loss is 3.736355586051941 and perplexity is 41.944846890697676
At time: 516.0570678710938 and batch: 1750, loss is 3.734673228263855 and perplexity is 41.874339976419016
At time: 516.9521691799164 and batch: 1800, loss is 3.696996531486511 and perplexity is 40.32600440644756
At time: 517.8588960170746 and batch: 1850, loss is 3.723487796783447 and perplexity is 41.40856720673549
At time: 518.7453548908234 and batch: 1900, loss is 3.7918015766143798 and perplexity is 44.33620343592595
At time: 519.6455070972443 and batch: 1950, loss is 3.726578106880188 and perplexity is 41.536730450151886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283108023710029 and perplexity of 72.46531428396261
finished 14 epochs...
Completing Train Step...
At time: 522.6129100322723 and batch: 50, loss is 3.8660219955444335 and perplexity is 47.75204988549396
At time: 523.5239009857178 and batch: 100, loss is 3.8511194229125976 and perplexity is 47.045697797967264
At time: 524.4166808128357 and batch: 150, loss is 3.827513394355774 and perplexity is 45.94814115580939
At time: 525.3157289028168 and batch: 200, loss is 3.8127258253097533 and perplexity is 45.273678964508996
At time: 526.2035603523254 and batch: 250, loss is 3.802990083694458 and perplexity is 44.83504480320958
At time: 527.0992126464844 and batch: 300, loss is 3.8036004972457884 and perplexity is 44.862421076706084
At time: 527.995509147644 and batch: 350, loss is 3.804987826347351 and perplexity is 44.924703211952284
At time: 528.8828618526459 and batch: 400, loss is 3.776500368118286 and perplexity is 43.66296972306135
At time: 529.7697541713715 and batch: 450, loss is 3.821893949508667 and perplexity is 45.690662232620184
At time: 530.6575956344604 and batch: 500, loss is 3.8426441383361816 and perplexity is 46.64865701447963
At time: 531.5559165477753 and batch: 550, loss is 3.8070596170425417 and perplexity is 45.01787427619635
At time: 532.4428114891052 and batch: 600, loss is 3.7892651033401488 and perplexity is 44.22388834316216
At time: 533.3297505378723 and batch: 650, loss is 3.8261018991470337 and perplexity is 45.88333132486053
At time: 534.2379200458527 and batch: 700, loss is 3.8487359189987185 and perplexity is 46.933697722467336
At time: 535.148351430893 and batch: 750, loss is 3.8059354209899903 and perplexity is 44.96729379615583
At time: 536.0403065681458 and batch: 800, loss is 3.7877418184280396 and perplexity is 44.156574043738885
At time: 536.9520347118378 and batch: 850, loss is 3.7899482107162474 and perplexity is 44.25410832806129
At time: 537.8553628921509 and batch: 900, loss is 3.762226929664612 and perplexity is 43.04417567697491
At time: 538.7424657344818 and batch: 950, loss is 3.869212393760681 and perplexity is 47.904641224407534
At time: 539.6293382644653 and batch: 1000, loss is 3.836607027053833 and perplexity is 46.367882267882194
At time: 540.5385735034943 and batch: 1050, loss is 3.7711115503311157 and perplexity is 43.428310770208384
At time: 541.4533274173737 and batch: 1100, loss is 3.794679036140442 and perplexity is 44.46396278988561
At time: 542.3381338119507 and batch: 1150, loss is 3.7726557445526123 and perplexity is 43.495424321592
At time: 543.2286629676819 and batch: 1200, loss is 3.8351964807510375 and perplexity is 46.30252432901687
At time: 544.1740477085114 and batch: 1250, loss is 3.8174177265167235 and perplexity is 45.48659769972377
At time: 545.0756950378418 and batch: 1300, loss is 3.8176688671112062 and perplexity is 45.49802266548737
At time: 545.9686663150787 and batch: 1350, loss is 3.7049709367752075 and perplexity is 40.64886591258357
At time: 546.8548805713654 and batch: 1400, loss is 3.7234162282943726 and perplexity is 41.40560376419158
At time: 547.7423093318939 and batch: 1450, loss is 3.660633339881897 and perplexity is 38.885963105302025
At time: 548.6553030014038 and batch: 1500, loss is 3.660949969291687 and perplexity is 38.898277494295144
At time: 549.5457766056061 and batch: 1550, loss is 3.6765460681915285 and perplexity is 39.50969434266505
At time: 550.436674118042 and batch: 1600, loss is 3.7695046138763426 and perplexity is 43.35858027570443
At time: 551.3266370296478 and batch: 1650, loss is 3.708441138267517 and perplexity is 40.79017070398025
At time: 552.223459482193 and batch: 1700, loss is 3.73284460067749 and perplexity is 41.79783737188181
At time: 553.1296758651733 and batch: 1750, loss is 3.7314898633956908 and perplexity is 41.74125062203991
At time: 554.0176463127136 and batch: 1800, loss is 3.69407172203064 and perplexity is 40.208230844014516
At time: 554.9049932956696 and batch: 1850, loss is 3.721243405342102 and perplexity is 41.31573438845857
At time: 555.7929265499115 and batch: 1900, loss is 3.7898822021484375 and perplexity is 44.25118727415921
At time: 556.6808466911316 and batch: 1950, loss is 3.7247203397750854 and perplexity is 41.45963651213195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283565361555232 and perplexity of 72.49846299415128
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 559.6332547664642 and batch: 50, loss is 3.8654250383377073 and perplexity is 47.72355246189634
At time: 560.5468595027924 and batch: 100, loss is 3.8650902032852175 and perplexity is 47.707575618655596
At time: 561.4485521316528 and batch: 150, loss is 3.8512773513793945 and perplexity is 47.05312823961358
At time: 562.3678290843964 and batch: 200, loss is 3.844766602516174 and perplexity is 46.747772265113895
At time: 563.2535245418549 and batch: 250, loss is 3.84536376953125 and perplexity is 46.77569682972351
At time: 564.1392571926117 and batch: 300, loss is 3.8432330799102785 and perplexity is 46.67613843965381
At time: 565.0266721248627 and batch: 350, loss is 3.8478493309020996 and perplexity is 46.892105305131786
At time: 565.9621632099152 and batch: 400, loss is 3.8129895305633545 and perplexity is 45.285619445816415
At time: 566.8720943927765 and batch: 450, loss is 3.852928485870361 and perplexity is 47.13088345705358
At time: 567.7588217258453 and batch: 500, loss is 3.868296980857849 and perplexity is 47.860808763186355
At time: 568.6463243961334 and batch: 550, loss is 3.8375802850723266 and perplexity is 46.41303214877785
At time: 569.5511934757233 and batch: 600, loss is 3.8187875652313235 and perplexity is 45.54894969858919
At time: 570.4444782733917 and batch: 650, loss is 3.850484013557434 and perplexity is 47.015814016688786
At time: 571.3324377536774 and batch: 700, loss is 3.8667767381668092 and perplexity is 47.78810399692418
At time: 572.2203695774078 and batch: 750, loss is 3.823639154434204 and perplexity is 45.77047142283904
At time: 573.1078758239746 and batch: 800, loss is 3.8040021800994874 and perplexity is 44.88044516176864
At time: 573.9960942268372 and batch: 850, loss is 3.802666664123535 and perplexity is 44.820546616882
At time: 574.8849534988403 and batch: 900, loss is 3.770028657913208 and perplexity is 43.381308035798305
At time: 575.7728679180145 and batch: 950, loss is 3.884489665031433 and perplexity is 48.64211235331472
At time: 576.6608901023865 and batch: 1000, loss is 3.85018798828125 and perplexity is 47.00189820717679
At time: 577.5489242076874 and batch: 1050, loss is 3.7846763372421264 and perplexity is 44.0214201584584
At time: 578.4370365142822 and batch: 1100, loss is 3.8002917098999025 and perplexity is 44.71422617345601
At time: 579.3278164863586 and batch: 1150, loss is 3.780211877822876 and perplexity is 43.82532636667293
At time: 580.2154366970062 and batch: 1200, loss is 3.8366360902786254 and perplexity is 46.3692298876507
At time: 581.1031501293182 and batch: 1250, loss is 3.8181492710113525 and perplexity is 45.51988534406237
At time: 581.9917180538177 and batch: 1300, loss is 3.818576679229736 and perplexity is 45.53934507548664
At time: 582.8790996074677 and batch: 1350, loss is 3.7019010972976685 and perplexity is 40.52427175916039
At time: 583.7675590515137 and batch: 1400, loss is 3.721537275314331 and perplexity is 41.32787762635503
At time: 584.6742067337036 and batch: 1450, loss is 3.653103575706482 and perplexity is 38.59426057723674
At time: 585.5623798370361 and batch: 1500, loss is 3.653584656715393 and perplexity is 38.61283200987702
At time: 586.4499182701111 and batch: 1550, loss is 3.664876575469971 and perplexity is 39.0513159753195
At time: 587.3377828598022 and batch: 1600, loss is 3.7539092540740966 and perplexity is 42.68763304617789
At time: 588.2253711223602 and batch: 1650, loss is 3.6926897239685057 and perplexity is 40.15270152644892
At time: 589.1133327484131 and batch: 1700, loss is 3.715079388618469 and perplexity is 41.061846798288045
At time: 589.99875664711 and batch: 1750, loss is 3.7130614137649536 and perplexity is 40.97906857428836
At time: 590.8851780891418 and batch: 1800, loss is 3.677420539855957 and perplexity is 39.54425956178762
At time: 591.7741739749908 and batch: 1850, loss is 3.7028332948684692 and perplexity is 40.562065999965576
At time: 592.6631436347961 and batch: 1900, loss is 3.7743919944763182 and perplexity is 43.57100884657692
At time: 593.5509443283081 and batch: 1950, loss is 3.7137849807739256 and perplexity is 41.00873040623451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.270104128815407 and perplexity of 71.52908347017345
finished 16 epochs...
Completing Train Step...
At time: 596.5436367988586 and batch: 50, loss is 3.868525114059448 and perplexity is 47.87172864826743
At time: 597.4310896396637 and batch: 100, loss is 3.85512610912323 and perplexity is 47.23457327631475
At time: 598.3374311923981 and batch: 150, loss is 3.836396813392639 and perplexity is 46.35813613001042
At time: 599.2251904010773 and batch: 200, loss is 3.8256613779067994 and perplexity is 45.8631231942214
At time: 600.1134955883026 and batch: 250, loss is 3.8247120666503904 and perplexity is 45.81960547431789
At time: 601.0023937225342 and batch: 300, loss is 3.8230176734924317 and perplexity is 45.74203478448347
At time: 601.8893210887909 and batch: 350, loss is 3.829839301109314 and perplexity is 46.05513663014877
At time: 602.7778434753418 and batch: 400, loss is 3.7957011222839356 and perplexity is 44.50943202291616
At time: 603.6662077903748 and batch: 450, loss is 3.83628680229187 and perplexity is 46.3530365009382
At time: 604.5546345710754 and batch: 500, loss is 3.851698970794678 and perplexity is 47.07297093476803
At time: 605.4426596164703 and batch: 550, loss is 3.821254668235779 and perplexity is 45.66146238236218
At time: 606.3299176692963 and batch: 600, loss is 3.8041923332214354 and perplexity is 44.88898012998027
At time: 607.2171092033386 and batch: 650, loss is 3.836918840408325 and perplexity is 46.382342647145364
At time: 608.1046807765961 and batch: 700, loss is 3.85505437374115 and perplexity is 47.23118500768422
At time: 609.0069460868835 and batch: 750, loss is 3.8127415323257448 and perplexity is 45.27439008449325
At time: 609.9007842540741 and batch: 800, loss is 3.793276085853577 and perplexity is 44.40162579860893
At time: 610.8138461112976 and batch: 850, loss is 3.7924587440490725 and perplexity is 44.36534932081622
At time: 611.7023565769196 and batch: 900, loss is 3.7601906156539915 and perplexity is 42.95661340136954
At time: 612.609739780426 and batch: 950, loss is 3.8752133417129517 and perplexity is 48.19297876707506
At time: 613.4970803260803 and batch: 1000, loss is 3.84135262966156 and perplexity is 46.58844875739805
At time: 614.3851788043976 and batch: 1050, loss is 3.7767618608474733 and perplexity is 43.67438876511182
At time: 615.2728102207184 and batch: 1100, loss is 3.793293490409851 and perplexity is 44.4023985959289
At time: 616.161200761795 and batch: 1150, loss is 3.7736013746261596 and perplexity is 43.53657435618089
At time: 617.0483291149139 and batch: 1200, loss is 3.830749635696411 and perplexity is 46.097081302883176
At time: 617.9372315406799 and batch: 1250, loss is 3.8130790758132935 and perplexity is 45.289674739491765
At time: 618.845828294754 and batch: 1300, loss is 3.8139659118652345 and perplexity is 45.3298570707679
At time: 619.7352573871613 and batch: 1350, loss is 3.6982959127426147 and perplexity is 40.378437318501135
At time: 620.6448822021484 and batch: 1400, loss is 3.7187940788269045 and perplexity is 41.21466249429044
At time: 621.5352549552917 and batch: 1450, loss is 3.6520317459106444 and perplexity is 38.5529162597955
At time: 622.4229073524475 and batch: 1500, loss is 3.6534955215454104 and perplexity is 38.60939040191874
At time: 623.3154945373535 and batch: 1550, loss is 3.665862855911255 and perplexity is 39.089850524284635
At time: 624.2083985805511 and batch: 1600, loss is 3.7557468128204348 and perplexity is 42.766146193810506
At time: 625.1011054515839 and batch: 1650, loss is 3.6952682018280028 and perplexity is 40.25636797171487
At time: 625.9893290996552 and batch: 1700, loss is 3.7183049964904784 and perplexity is 41.194510059364404
At time: 626.8862500190735 and batch: 1750, loss is 3.717510714530945 and perplexity is 41.161802994227855
At time: 627.7859780788422 and batch: 1800, loss is 3.68225501537323 and perplexity is 39.73589817933967
At time: 628.6879427433014 and batch: 1850, loss is 3.707444820404053 and perplexity is 40.74955096669915
At time: 629.6038837432861 and batch: 1900, loss is 3.779383730888367 and perplexity is 43.78904758114443
At time: 630.5235080718994 and batch: 1950, loss is 3.7179764699935913 and perplexity is 41.18097879409491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26894900299782 and perplexity of 71.44650608196726
finished 17 epochs...
Completing Train Step...
At time: 633.5540254116058 and batch: 50, loss is 3.8654877853393557 and perplexity is 47.72654706567155
At time: 634.4419260025024 and batch: 100, loss is 3.850576639175415 and perplexity is 47.020169087209396
At time: 635.3302254676819 and batch: 150, loss is 3.8313003635406493 and perplexity is 46.12247524102736
At time: 636.218020439148 and batch: 200, loss is 3.8198014879226685 and perplexity is 45.59515623322399
At time: 637.1067390441895 and batch: 250, loss is 3.8182012605667115 and perplexity is 45.522251964180626
At time: 637.991993188858 and batch: 300, loss is 3.8160932779312136 and perplexity is 45.42639291761071
At time: 638.8810477256775 and batch: 350, loss is 3.8229771137237547 and perplexity is 45.74017953575828
At time: 639.76917552948 and batch: 400, loss is 3.788973722457886 and perplexity is 44.21100422474369
At time: 640.6571934223175 and batch: 450, loss is 3.8297874975204467 and perplexity is 46.052750870581534
At time: 641.5520086288452 and batch: 500, loss is 3.845224590301514 and perplexity is 46.76918707729004
At time: 642.4380583763123 and batch: 550, loss is 3.8148244190216065 and perplexity is 45.36878978707703
At time: 643.3234670162201 and batch: 600, loss is 3.7982567977905273 and perplexity is 44.62332916822866
At time: 644.2089583873749 and batch: 650, loss is 3.8312629222869874 and perplexity is 46.12074839006028
At time: 645.0957458019257 and batch: 700, loss is 3.849778971672058 and perplexity is 46.982677581192085
At time: 645.9833297729492 and batch: 750, loss is 3.807940845489502 and perplexity is 45.05756279238656
At time: 646.871541261673 and batch: 800, loss is 3.7886058950424193 and perplexity is 44.19474519576614
At time: 647.7590868473053 and batch: 850, loss is 3.787887806892395 and perplexity is 44.163020864744034
At time: 648.6478502750397 and batch: 900, loss is 3.7557513093948365 and perplexity is 42.76633849540109
At time: 649.5356171131134 and batch: 950, loss is 3.8710398626327516 and perplexity is 47.992265506010234
At time: 650.4249243736267 and batch: 1000, loss is 3.8374769401550295 and perplexity is 46.40823584564997
At time: 651.3136968612671 and batch: 1050, loss is 3.7731261444091797 and perplexity is 43.51588937595616
At time: 652.2011680603027 and batch: 1100, loss is 3.7900157880783083 and perplexity is 44.25709900501235
At time: 653.0891962051392 and batch: 1150, loss is 3.7705764102935793 and perplexity is 43.40507675963179
At time: 653.9767737388611 and batch: 1200, loss is 3.8280584192276 and perplexity is 45.97319086128966
At time: 654.8854150772095 and batch: 1250, loss is 3.81078396320343 and perplexity is 45.185849027326675
At time: 655.7874052524567 and batch: 1300, loss is 3.811911497116089 and perplexity is 45.23682633840002
At time: 656.6830475330353 and batch: 1350, loss is 3.6964966249465943 and perplexity is 40.3058502111428
At time: 657.5714337825775 and batch: 1400, loss is 3.717339286804199 and perplexity is 41.154747324697766
At time: 658.4593622684479 and batch: 1450, loss is 3.651157159805298 and perplexity is 38.519213155195885
At time: 659.3470692634583 and batch: 1500, loss is 3.652988839149475 and perplexity is 38.589832658684806
At time: 660.2354879379272 and batch: 1550, loss is 3.665865588188171 and perplexity is 39.08995732872679
At time: 661.1239631175995 and batch: 1600, loss is 3.7559794902801515 and perplexity is 42.77609806981247
At time: 662.0119585990906 and batch: 1650, loss is 3.69586962223053 and perplexity is 40.28058625469946
At time: 662.9006712436676 and batch: 1700, loss is 3.7190206146240232 and perplexity is 41.22400014832808
At time: 663.8055531978607 and batch: 1750, loss is 3.7186707878112792 and perplexity is 41.20958140992533
At time: 664.700896024704 and batch: 1800, loss is 3.6834964084625246 and perplexity is 39.785256679047954
At time: 665.5885746479034 and batch: 1850, loss is 3.708689031600952 and perplexity is 40.80028356877154
At time: 666.4765849113464 and batch: 1900, loss is 3.780659966468811 and perplexity is 43.84496839817923
At time: 667.3643178939819 and batch: 1950, loss is 3.7190229225158693 and perplexity is 41.22409528897167
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268602096202762 and perplexity of 71.42172510211793
finished 18 epochs...
Completing Train Step...
At time: 670.3768827915192 and batch: 50, loss is 3.8621557569503784 and perplexity is 47.56778550184609
At time: 671.2661678791046 and batch: 100, loss is 3.8466676902770995 and perplexity is 46.83672841274777
At time: 672.1536405086517 and batch: 150, loss is 3.827213473320007 and perplexity is 45.93436240809381
At time: 673.0417580604553 and batch: 200, loss is 3.81544141292572 and perplexity is 45.396790691117936
At time: 673.9298737049103 and batch: 250, loss is 3.8135260486602784 and perplexity is 45.30992251911585
At time: 674.8178870677948 and batch: 300, loss is 3.811192207336426 and perplexity is 45.2042996510097
At time: 675.7065427303314 and batch: 350, loss is 3.8181313467025757 and perplexity is 45.51906943889426
At time: 676.59503865242 and batch: 400, loss is 3.78417281627655 and perplexity is 43.99926002998701
At time: 677.5083031654358 and batch: 450, loss is 3.8252519464492796 and perplexity is 45.84434923243311
At time: 678.3969583511353 and batch: 500, loss is 3.840706171989441 and perplexity is 46.55834103000091
At time: 679.284303188324 and batch: 550, loss is 3.810410442352295 and perplexity is 45.16897432226202
At time: 680.1718826293945 and batch: 600, loss is 3.7940803289413454 and perplexity is 44.43734986273343
At time: 681.0597927570343 and batch: 650, loss is 3.8271824598312376 and perplexity is 45.932937845351574
At time: 681.9485313892365 and batch: 700, loss is 3.8459019660949707 and perplexity is 46.800878124658276
At time: 682.8347291946411 and batch: 750, loss is 3.8044147539138793 and perplexity is 44.89896547845678
At time: 683.720351934433 and batch: 800, loss is 3.785216488838196 and perplexity is 44.0452048219019
At time: 684.6194837093353 and batch: 850, loss is 3.784569888114929 and perplexity is 44.01673436610822
At time: 685.5169801712036 and batch: 900, loss is 3.752506399154663 and perplexity is 42.627790475196825
At time: 686.4013249874115 and batch: 950, loss is 3.868019642829895 and perplexity is 47.847536981337655
At time: 687.2882277965546 and batch: 1000, loss is 3.834658451080322 and perplexity is 46.277618897630155
At time: 688.1772019863129 and batch: 1050, loss is 3.7704504489898683 and perplexity is 43.399609743898914
At time: 689.0655550956726 and batch: 1100, loss is 3.7875187730789186 and perplexity is 44.14672622356139
At time: 689.9647204875946 and batch: 1150, loss is 3.768196678161621 and perplexity is 43.30190711052984
At time: 690.856011390686 and batch: 1200, loss is 3.825873603820801 and perplexity is 45.87285757036717
At time: 691.743882894516 and batch: 1250, loss is 3.808890438079834 and perplexity is 45.10036944137433
At time: 692.631429195404 and batch: 1300, loss is 3.810153799057007 and perplexity is 45.15738349526481
At time: 693.5194001197815 and batch: 1350, loss is 3.6948462438583376 and perplexity is 40.23938505970895
At time: 694.4074885845184 and batch: 1400, loss is 3.7159189891815188 and perplexity is 41.09633682487653
At time: 695.2957804203033 and batch: 1450, loss is 3.6500558948516844 and perplexity is 38.4768166448876
At time: 696.1853122711182 and batch: 1500, loss is 3.652109532356262 and perplexity is 38.555915270759236
At time: 697.0731627941132 and batch: 1550, loss is 3.6652713918685915 and perplexity is 39.06673711931422
At time: 697.9618234634399 and batch: 1600, loss is 3.755505323410034 and perplexity is 42.75581986928025
At time: 698.8529360294342 and batch: 1650, loss is 3.695666880607605 and perplexity is 40.27242053106382
At time: 699.7410941123962 and batch: 1700, loss is 3.7188756132125853 and perplexity is 41.218023043476244
At time: 700.6294031143188 and batch: 1750, loss is 3.7187475872039797 and perplexity is 41.21274640228424
At time: 701.5164682865143 and batch: 1800, loss is 3.6836271142959593 and perplexity is 39.79045718404137
At time: 702.4044182300568 and batch: 1850, loss is 3.708857274055481 and perplexity is 40.8071484860937
At time: 703.2999703884125 and batch: 1900, loss is 3.7808635330200193 and perplexity is 43.853894675698825
At time: 704.1993589401245 and batch: 1950, loss is 3.719175786972046 and perplexity is 41.23039746955683
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268516646984011 and perplexity of 71.41562243224405
finished 19 epochs...
Completing Train Step...
At time: 707.1681532859802 and batch: 50, loss is 3.8589645195007325 and perplexity is 47.41622736098561
At time: 708.0819911956787 and batch: 100, loss is 3.8431958103179933 and perplexity is 46.67439887142142
At time: 708.9853451251984 and batch: 150, loss is 3.8236194229125977 and perplexity is 45.769568310703136
At time: 709.8814249038696 and batch: 200, loss is 3.811756272315979 and perplexity is 45.22980500603058
At time: 710.7931201457977 and batch: 250, loss is 3.8096431493759155 and perplexity is 45.13432977847156
At time: 711.6905567646027 and batch: 300, loss is 3.807140655517578 and perplexity is 45.021522603902525
At time: 712.5789754390717 and batch: 350, loss is 3.814131054878235 and perplexity is 45.337343598100276
At time: 713.4681270122528 and batch: 400, loss is 3.7801936435699464 and perplexity is 43.82452725187289
At time: 714.3571689128876 and batch: 450, loss is 3.8215174102783203 and perplexity is 45.67346114447456
At time: 715.2459349632263 and batch: 500, loss is 3.8369933700561525 and perplexity is 46.38579963563073
At time: 716.1342213153839 and batch: 550, loss is 3.8067879915237426 and perplexity is 45.00564793330938
At time: 717.023191690445 and batch: 600, loss is 3.790612654685974 and perplexity is 44.283522474419435
At time: 717.9111614227295 and batch: 650, loss is 3.8237889337539674 and perplexity is 45.77732740634345
At time: 718.7997872829437 and batch: 700, loss is 3.8426511478424072 and perplexity is 46.64898399967739
At time: 719.6877026557922 and batch: 750, loss is 3.8014599466323853 and perplexity is 44.76649349929693
At time: 720.5833809375763 and batch: 800, loss is 3.782368288040161 and perplexity is 43.91993371769388
At time: 721.4889695644379 and batch: 850, loss is 3.78177725315094 and perplexity is 43.8939831741282
At time: 722.428631067276 and batch: 900, loss is 3.749760556221008 and perplexity is 42.510901810342055
At time: 723.3338866233826 and batch: 950, loss is 3.8654555749893187 and perplexity is 47.72500980164254
At time: 724.2219314575195 and batch: 1000, loss is 3.8322452211380007 and perplexity is 46.16607500670876
At time: 725.1107800006866 and batch: 1050, loss is 3.7681471872329713 and perplexity is 43.299764111964556
At time: 726.0005331039429 and batch: 1100, loss is 3.785288553237915 and perplexity is 44.048379027520134
At time: 726.8899219036102 and batch: 1150, loss is 3.7660416841506956 and perplexity is 43.20869223486853
At time: 727.7789986133575 and batch: 1200, loss is 3.8238615131378175 and perplexity is 45.78065001713597
At time: 728.6682913303375 and batch: 1250, loss is 3.8071201610565186 and perplexity is 45.02059992151566
At time: 729.5561306476593 and batch: 1300, loss is 3.8084905910491944 and perplexity is 45.08233979736247
At time: 730.4436476230621 and batch: 1350, loss is 3.693262219429016 and perplexity is 40.17569534710099
At time: 731.3326873779297 and batch: 1400, loss is 3.7145194673538207 and perplexity is 41.03886183258598
At time: 732.2326197624207 and batch: 1450, loss is 3.648801531791687 and perplexity is 38.42858300499436
At time: 733.1346960067749 and batch: 1500, loss is 3.651082682609558 and perplexity is 38.51634445904553
At time: 734.020182132721 and batch: 1550, loss is 3.664370608329773 and perplexity is 39.03156229043365
At time: 734.9064066410065 and batch: 1600, loss is 3.754691314697266 and perplexity is 42.72103042076319
At time: 735.7948513031006 and batch: 1650, loss is 3.695097222328186 and perplexity is 40.24948554644821
At time: 736.6836774349213 and batch: 1700, loss is 3.7183124685287474 and perplexity is 41.194817867470015
At time: 737.5721974372864 and batch: 1750, loss is 3.7183476543426512 and perplexity is 41.19626736616605
At time: 738.4628455638885 and batch: 1800, loss is 3.6832693910598753 and perplexity is 39.77622575853979
At time: 739.3523378372192 and batch: 1850, loss is 3.7085585260391234 and perplexity is 40.79495925227564
At time: 740.2500283718109 and batch: 1900, loss is 3.780623712539673 and perplexity is 43.84337887461527
At time: 741.1409494876862 and batch: 1950, loss is 3.718940033912659 and perplexity is 41.22067842290613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2685362350109015 and perplexity of 71.41702133707749
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
3834.858550786972


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}, 'best_accuracy': -70.21234677830806}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7054039444822918, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3700134384042031, 'data': 'wikitext'}, 'best_accuracy': -70.64095605480648}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7401099843983403, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.9299697240020345, 'data': 'wikitext'}, 'best_accuracy': -71.41562243224405}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'dropout': 0.15141962671034973, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3607507403598699, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.42110276222229 and batch: 50, loss is 7.6260559940338135 and perplexity is 2050.945107691472
At time: 2.3979926109313965 and batch: 100, loss is 6.68752986907959 and perplexity is 802.3379226647452
At time: 3.3510658740997314 and batch: 150, loss is 6.466984529495239 and perplexity is 643.5402215893645
At time: 4.304446220397949 and batch: 200, loss is 6.252921504974365 and perplexity is 519.5284145360771
At time: 5.258893251419067 and batch: 250, loss is 6.07106125831604 and perplexity is 433.1401112896698
At time: 6.214040994644165 and batch: 300, loss is 5.935652236938477 and perplexity is 378.28664825042273
At time: 7.168405294418335 and batch: 350, loss is 5.8321796417236325 and perplexity is 341.1013481318641
At time: 8.12274980545044 and batch: 400, loss is 5.744931640625 and perplexity is 312.60225780467493
At time: 9.077135801315308 and batch: 450, loss is 5.637707395553589 and perplexity is 280.8181749194277
At time: 10.030890703201294 and batch: 500, loss is 5.582288684844971 and perplexity is 265.6789659160676
At time: 10.985389232635498 and batch: 550, loss is 5.511661462783813 and perplexity is 247.56210078144974
At time: 11.940466403961182 and batch: 600, loss is 5.519879150390625 and perplexity is 249.6048707158031
At time: 12.89408540725708 and batch: 650, loss is 5.564382514953613 and perplexity is 260.9640125729229
At time: 13.845343351364136 and batch: 700, loss is 5.49487603187561 and perplexity is 243.44134532299893
At time: 14.797908306121826 and batch: 750, loss is 5.432844514846802 and perplexity is 228.79914322366136
At time: 15.75431513786316 and batch: 800, loss is 5.407725133895874 and perplexity is 223.12343397188536
At time: 16.718827724456787 and batch: 850, loss is 5.401496648788452 and perplexity is 221.73803194300106
At time: 17.676429986953735 and batch: 900, loss is 5.398337192535401 and perplexity is 221.0385658795021
At time: 18.632455825805664 and batch: 950, loss is 5.433067541122437 and perplexity is 228.8501771351831
At time: 19.596298217773438 and batch: 1000, loss is 5.385885963439941 and perplexity is 218.30342731159072
At time: 20.5557861328125 and batch: 1050, loss is 5.2781213188171385 and perplexity is 196.0013052833241
At time: 21.51195216178894 and batch: 1100, loss is 5.355479412078857 and perplexity is 211.76547494769878
At time: 22.468352794647217 and batch: 1150, loss is 5.246566228866577 and perplexity is 189.9130296850642
At time: 23.424697399139404 and batch: 1200, loss is 5.325003623962402 and perplexity is 205.40910485830742
At time: 24.38120675086975 and batch: 1250, loss is 5.268303413391113 and perplexity is 194.08639857283208
At time: 25.337115049362183 and batch: 1300, loss is 5.291465520858765 and perplexity is 198.63431493678928
At time: 26.294158220291138 and batch: 1350, loss is 5.212201652526855 and perplexity is 183.49761176895564
At time: 27.250979900360107 and batch: 1400, loss is 5.22138388633728 and perplexity is 185.19028913058847
At time: 28.21115469932556 and batch: 1450, loss is 5.1741695308685305 and perplexity is 176.64985109530818
At time: 29.171863317489624 and batch: 1500, loss is 5.144756927490234 and perplexity is 171.52978542785408
At time: 30.132895708084106 and batch: 1550, loss is 5.133361434936523 and perplexity is 169.58621404407788
At time: 31.093515396118164 and batch: 1600, loss is 5.173177042007446 and perplexity is 176.47461506007488
At time: 32.04982542991638 and batch: 1650, loss is 5.146036510467529 and perplexity is 171.74941250695565
At time: 33.01034903526306 and batch: 1700, loss is 5.168686866760254 and perplexity is 175.68398946387606
At time: 33.97737407684326 and batch: 1750, loss is 5.168845720291138 and perplexity is 175.71189970268352
At time: 34.93562984466553 and batch: 1800, loss is 5.131130094528198 and perplexity is 169.20823133286262
At time: 35.894949436187744 and batch: 1850, loss is 5.112213773727417 and perplexity is 166.03751781064355
At time: 36.85167193412781 and batch: 1900, loss is 5.178739395141601 and perplexity is 177.45896429933066
At time: 37.807276487350464 and batch: 1950, loss is 5.098369750976563 and perplexity is 163.75472858879385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.778444653888082 and perplexity of 118.91924554515657
finished 1 epochs...
Completing Train Step...
At time: 40.7875280380249 and batch: 50, loss is 4.975581178665161 and perplexity is 144.83297452770762
At time: 41.70132637023926 and batch: 100, loss is 4.9309915256500245 and perplexity is 138.51678722041964
At time: 42.60733914375305 and batch: 150, loss is 4.873559513092041 and perplexity is 130.7856224784634
At time: 43.493083000183105 and batch: 200, loss is 4.839070663452149 and perplexity is 126.35187373612078
At time: 44.37944030761719 and batch: 250, loss is 4.845194282531739 and perplexity is 127.12797834011162
At time: 45.26599335670471 and batch: 300, loss is 4.85467303276062 and perplexity is 128.33872179621028
At time: 46.16919660568237 and batch: 350, loss is 4.849576606750488 and perplexity is 127.6863168751512
At time: 47.05823373794556 and batch: 400, loss is 4.8019187450408936 and perplexity is 121.74378884820844
At time: 47.94367599487305 and batch: 450, loss is 4.779513101577759 and perplexity is 119.04637244044245
At time: 48.854816913604736 and batch: 500, loss is 4.773781528472901 and perplexity is 118.36600111549376
At time: 49.770334005355835 and batch: 550, loss is 4.730520210266113 and perplexity is 113.35451519590741
At time: 50.658137798309326 and batch: 600, loss is 4.710808067321778 and perplexity is 111.1419337939195
At time: 51.54637694358826 and batch: 650, loss is 4.7832921123504635 and perplexity is 119.49710108214092
At time: 52.4318745136261 and batch: 700, loss is 4.789362697601319 and perplexity is 120.22472473767465
At time: 53.325199365615845 and batch: 750, loss is 4.742761259078979 and perplexity is 114.75062081505212
At time: 54.21214461326599 and batch: 800, loss is 4.7218209171295165 and perplexity is 112.3726878337399
At time: 55.09791374206543 and batch: 850, loss is 4.709601621627808 and perplexity is 111.00792793812215
At time: 55.984094858169556 and batch: 900, loss is 4.695810251235962 and perplexity is 109.48748508197377
At time: 56.869812965393066 and batch: 950, loss is 4.762721548080444 and perplexity is 117.06408830027517
At time: 57.75586462020874 and batch: 1000, loss is 4.738041000366211 and perplexity is 114.21024455855688
At time: 58.641870737075806 and batch: 1050, loss is 4.6498177623748775 and perplexity is 104.56592799427621
At time: 59.528892993927 and batch: 1100, loss is 4.719807739257813 and perplexity is 112.14668918927305
At time: 60.41615271568298 and batch: 1150, loss is 4.652366676330566 and perplexity is 104.83279751666862
At time: 61.300270557403564 and batch: 1200, loss is 4.728137264251709 and perplexity is 113.08471908815463
At time: 62.184699058532715 and batch: 1250, loss is 4.692404594421387 and perplexity is 109.11524250731203
At time: 63.07019639015198 and batch: 1300, loss is 4.705657253265381 and perplexity is 110.57093417792933
At time: 63.96907448768616 and batch: 1350, loss is 4.599045886993408 and perplexity is 99.3894416298896
At time: 64.89466190338135 and batch: 1400, loss is 4.61844654083252 and perplexity is 101.33648769599438
At time: 65.79477643966675 and batch: 1450, loss is 4.559242525100708 and perplexity is 95.51110515776736
At time: 66.68229460716248 and batch: 1500, loss is 4.55476710319519 and perplexity is 95.0846077553066
At time: 67.56598377227783 and batch: 1550, loss is 4.554358444213867 and perplexity is 95.04575851494798
At time: 68.44756054878235 and batch: 1600, loss is 4.616874380111694 and perplexity is 101.17729562100546
At time: 69.33029651641846 and batch: 1650, loss is 4.575626211166382 and perplexity is 97.08881820677298
At time: 70.2142825126648 and batch: 1700, loss is 4.604744071960449 and perplexity is 99.95739767460465
At time: 71.09683513641357 and batch: 1750, loss is 4.601866788864136 and perplexity is 99.6702053089266
At time: 71.9801025390625 and batch: 1800, loss is 4.559706773757934 and perplexity is 95.5554563542822
At time: 72.86259174346924 and batch: 1850, loss is 4.5764275169372555 and perplexity is 97.16664721534177
At time: 73.74406719207764 and batch: 1900, loss is 4.665501480102539 and perplexity is 106.21883850215256
At time: 74.6296021938324 and batch: 1950, loss is 4.590420722961426 and perplexity is 98.53587774865234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507363962572675 and perplexity of 90.68246081050513
finished 2 epochs...
Completing Train Step...
At time: 77.56497740745544 and batch: 50, loss is 4.54392879486084 and perplexity is 94.05961608021428
At time: 78.47318577766418 and batch: 100, loss is 4.50882134437561 and perplexity is 90.81471612857393
At time: 79.35746645927429 and batch: 150, loss is 4.477300415039062 and perplexity is 87.99679690765105
At time: 80.24163365364075 and batch: 200, loss is 4.465704908370972 and perplexity is 86.98232250151135
At time: 81.15033650398254 and batch: 250, loss is 4.467425909042358 and perplexity is 87.13214802486836
At time: 82.03637504577637 and batch: 300, loss is 4.483141269683838 and perplexity is 88.51227736531499
At time: 82.92066144943237 and batch: 350, loss is 4.486850986480713 and perplexity is 88.8412426541473
At time: 83.80724906921387 and batch: 400, loss is 4.449005422592163 and perplexity is 85.54182371456798
At time: 84.6920599937439 and batch: 450, loss is 4.459090032577515 and perplexity is 86.40884407733027
At time: 85.57645797729492 and batch: 500, loss is 4.461300468444824 and perplexity is 86.60005653911767
At time: 86.46057462692261 and batch: 550, loss is 4.426556339263916 and perplexity is 83.64288267747438
At time: 87.34553861618042 and batch: 600, loss is 4.4052191257476805 and perplexity is 81.87708225446927
At time: 88.22972536087036 and batch: 650, loss is 4.4717916488647464 and perplexity is 87.51337587861532
At time: 89.11375999450684 and batch: 700, loss is 4.4943084812164305 and perplexity is 89.50625232461651
At time: 89.9973304271698 and batch: 750, loss is 4.458205604553223 and perplexity is 86.33245545917829
At time: 90.88118934631348 and batch: 800, loss is 4.4316066551208495 and perplexity is 84.0663741368766
At time: 91.76540780067444 and batch: 850, loss is 4.423821001052857 and perplexity is 83.41440373045864
At time: 92.71692657470703 and batch: 900, loss is 4.397782039642334 and perplexity is 81.27041406172653
At time: 93.60491347312927 and batch: 950, loss is 4.4860266494750975 and perplexity is 88.7680377071215
At time: 94.49124789237976 and batch: 1000, loss is 4.466833333969117 and perplexity is 87.08053098086806
At time: 95.37834739685059 and batch: 1050, loss is 4.393978242874145 and perplexity is 80.96186512412446
At time: 96.26610970497131 and batch: 1100, loss is 4.447943820953369 and perplexity is 85.45106056000816
At time: 97.15760660171509 and batch: 1150, loss is 4.397292003631592 and perplexity is 81.23059838858194
At time: 98.05639052391052 and batch: 1200, loss is 4.468828916549683 and perplexity is 87.25448087956634
At time: 98.94502115249634 and batch: 1250, loss is 4.444422101974487 and perplexity is 85.1506552203429
At time: 99.83370327949524 and batch: 1300, loss is 4.454847917556763 and perplexity is 86.04306421061118
At time: 100.72296071052551 and batch: 1350, loss is 4.341096124649048 and perplexity is 76.7916664614156
At time: 101.61191368103027 and batch: 1400, loss is 4.368798036575317 and perplexity is 78.94868122024049
At time: 102.50165677070618 and batch: 1450, loss is 4.305934042930603 and perplexity is 74.13843160031199
At time: 103.39030694961548 and batch: 1500, loss is 4.312713103294373 and perplexity is 74.64272789966205
At time: 104.27811670303345 and batch: 1550, loss is 4.312471399307251 and perplexity is 74.62468863488799
At time: 105.16604471206665 and batch: 1600, loss is 4.388462181091309 and perplexity is 80.5165039232435
At time: 106.06797075271606 and batch: 1650, loss is 4.344198994636535 and perplexity is 77.03031106869413
At time: 106.95675253868103 and batch: 1700, loss is 4.371979103088379 and perplexity is 79.20022209833694
At time: 107.84389543533325 and batch: 1750, loss is 4.372634544372558 and perplexity is 79.25215020967129
At time: 108.72964525222778 and batch: 1800, loss is 4.325718793869019 and perplexity is 75.61984841277119
At time: 109.61542677879333 and batch: 1850, loss is 4.353102645874023 and perplexity is 77.71922446434041
At time: 110.49961543083191 and batch: 1900, loss is 4.439567003250122 and perplexity is 84.73824234553048
At time: 111.3856475353241 and batch: 1950, loss is 4.36970591545105 and perplexity is 79.02038960652644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.426099200581396 and perplexity of 83.6046550186215
finished 3 epochs...
Completing Train Step...
At time: 114.34718418121338 and batch: 50, loss is 4.3316425657272335 and perplexity is 76.06913255728593
At time: 115.25949454307556 and batch: 100, loss is 4.306156902313233 and perplexity is 74.15495588663532
At time: 116.14523720741272 and batch: 150, loss is 4.279172267913818 and perplexity is 72.18066901780696
At time: 117.03100085258484 and batch: 200, loss is 4.270101432800293 and perplexity is 71.52889062694327
At time: 117.91594290733337 and batch: 250, loss is 4.2667589855194095 and perplexity is 71.290208194898
At time: 118.80180335044861 and batch: 300, loss is 4.289522695541382 and perplexity is 72.93164958915993
At time: 119.68932318687439 and batch: 350, loss is 4.2942440223693845 and perplexity is 73.27679788078079
At time: 120.57498097419739 and batch: 400, loss is 4.2576898574829105 and perplexity is 70.64659110333832
At time: 121.46115899085999 and batch: 450, loss is 4.282391052246094 and perplexity is 72.41337734237331
At time: 122.34859585762024 and batch: 500, loss is 4.290346632003784 and perplexity is 72.99176539692168
At time: 123.23380088806152 and batch: 550, loss is 4.253529386520386 and perplexity is 70.35327859463065
At time: 124.11909890174866 and batch: 600, loss is 4.2314151000976565 and perplexity is 68.81454277168584
At time: 125.00487017631531 and batch: 650, loss is 4.297720651626587 and perplexity is 73.53199750035044
At time: 125.8898491859436 and batch: 700, loss is 4.319188208580017 and perplexity is 75.1276155768453
At time: 126.77569270133972 and batch: 750, loss is 4.287231645584106 and perplexity is 72.76475079622395
At time: 127.66088581085205 and batch: 800, loss is 4.265727248191833 and perplexity is 71.21669335653536
At time: 128.54666113853455 and batch: 850, loss is 4.251712822914124 and perplexity is 70.2255933984071
At time: 129.4326617717743 and batch: 900, loss is 4.229479770660401 and perplexity is 68.68149275068787
At time: 130.31842350959778 and batch: 950, loss is 4.320104761123657 and perplexity is 75.19650554981719
At time: 131.21538376808167 and batch: 1000, loss is 4.302535972595215 and perplexity is 73.88693154462149
At time: 132.11016845703125 and batch: 1050, loss is 4.236906242370606 and perplexity is 69.1934525882549
At time: 132.99541759490967 and batch: 1100, loss is 4.284035935401916 and perplexity is 72.53258690304095
At time: 133.88208031654358 and batch: 1150, loss is 4.2415394115447995 and perplexity is 69.51478137033651
At time: 134.76851058006287 and batch: 1200, loss is 4.31220426082611 and perplexity is 74.60475617139303
At time: 135.6549391746521 and batch: 1250, loss is 4.2943667125701905 and perplexity is 73.2857887773634
At time: 136.5586404800415 and batch: 1300, loss is 4.301377668380737 and perplexity is 73.80139754717656
At time: 137.44572973251343 and batch: 1350, loss is 4.183195147514343 and perplexity is 65.57504077201688
At time: 138.33208918571472 and batch: 1400, loss is 4.217081880569458 and perplexity is 67.83524384231258
At time: 139.21906900405884 and batch: 1450, loss is 4.14959527015686 and perplexity is 63.408331859874814
At time: 140.10477566719055 and batch: 1500, loss is 4.161305060386658 and perplexity is 64.15519439248995
At time: 140.99188947677612 and batch: 1550, loss is 4.167266144752502 and perplexity is 64.53877104932621
At time: 141.87817692756653 and batch: 1600, loss is 4.247707676887512 and perplexity is 69.94489214203371
At time: 142.76561188697815 and batch: 1650, loss is 4.203284111022949 and perplexity is 66.90569636866051
At time: 143.65254735946655 and batch: 1700, loss is 4.229811792373657 and perplexity is 68.70430028366852
At time: 144.5389564037323 and batch: 1750, loss is 4.2265858602523805 and perplexity is 68.48302198080297
At time: 145.42490196228027 and batch: 1800, loss is 4.182778663635254 and perplexity is 65.54773551115989
At time: 146.31031489372253 and batch: 1850, loss is 4.214224762916565 and perplexity is 67.64170717980517
At time: 147.19542956352234 and batch: 1900, loss is 4.294809274673462 and perplexity is 73.31822946816527
At time: 148.0804784297943 and batch: 1950, loss is 4.231734204292297 and perplexity is 68.83650528491525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38760617278343 and perplexity of 80.44761061779158
finished 4 epochs...
Completing Train Step...
At time: 151.0668649673462 and batch: 50, loss is 4.193347425460815 and perplexity is 66.24416764612678
At time: 151.9537136554718 and batch: 100, loss is 4.174663224220276 and perplexity is 65.01793950622984
At time: 152.83959293365479 and batch: 150, loss is 4.147009401321411 and perplexity is 63.24457804480206
At time: 153.72529816627502 and batch: 200, loss is 4.140192446708679 and perplexity is 62.81490880853427
At time: 154.61153149604797 and batch: 250, loss is 4.129448747634887 and perplexity is 62.14365665323732
At time: 155.49685668945312 and batch: 300, loss is 4.155958647727966 and perplexity is 63.81310952734521
At time: 156.38352632522583 and batch: 350, loss is 4.16387264251709 and perplexity is 64.320129775146
At time: 157.27858877182007 and batch: 400, loss is 4.1267290210723875 and perplexity is 61.97487252692258
At time: 158.18823528289795 and batch: 450, loss is 4.158893074989319 and perplexity is 64.00063946749205
At time: 159.09998726844788 and batch: 500, loss is 4.172092347145081 and perplexity is 64.85100105713975
At time: 160.03821802139282 and batch: 550, loss is 4.132983465194702 and perplexity is 62.36370560397392
At time: 160.92249703407288 and batch: 600, loss is 4.116775813102723 and perplexity is 61.36108338440688
At time: 161.8084101676941 and batch: 650, loss is 4.174910197257995 and perplexity is 65.03399916732597
At time: 162.6944375038147 and batch: 700, loss is 4.199999442100525 and perplexity is 66.68629383666645
At time: 163.58033871650696 and batch: 750, loss is 4.172621021270752 and perplexity is 64.88529516782826
At time: 164.46694159507751 and batch: 800, loss is 4.150059113502502 and perplexity is 63.43775021489294
At time: 165.35368061065674 and batch: 850, loss is 4.140806336402893 and perplexity is 62.85348207234798
At time: 166.24262189865112 and batch: 900, loss is 4.116379208564759 and perplexity is 61.33675212554501
At time: 167.12880539894104 and batch: 950, loss is 4.205778751373291 and perplexity is 67.0728103764973
At time: 168.01648378372192 and batch: 1000, loss is 4.189288592338562 and perplexity is 65.97583854422567
At time: 168.90308690071106 and batch: 1050, loss is 4.129417119026184 and perplexity is 62.14169116692059
At time: 169.79043531417847 and batch: 1100, loss is 4.167692427635193 and perplexity is 64.56628868742678
At time: 170.67755770683289 and batch: 1150, loss is 4.131299786567688 and perplexity is 62.25879350965608
At time: 171.56642055511475 and batch: 1200, loss is 4.202805900573731 and perplexity is 66.87370901449789
At time: 172.45422911643982 and batch: 1250, loss is 4.190511746406555 and perplexity is 66.05658653307854
At time: 173.338214635849 and batch: 1300, loss is 4.190834746360779 and perplexity is 66.07792625368378
At time: 174.22166419029236 and batch: 1350, loss is 4.078735928535462 and perplexity is 59.07075298286711
At time: 175.10543179512024 and batch: 1400, loss is 4.111119122505188 and perplexity is 61.01496259301977
At time: 175.9891140460968 and batch: 1450, loss is 4.039507040977478 and perplexity is 56.798336650576644
At time: 176.872873544693 and batch: 1500, loss is 4.054894299507141 and perplexity is 57.679065968238824
At time: 177.75638961791992 and batch: 1550, loss is 4.062045207023621 and perplexity is 58.09300187942457
At time: 178.6405806541443 and batch: 1600, loss is 4.143416070938111 and perplexity is 63.01772720004301
At time: 179.52675819396973 and batch: 1650, loss is 4.10309187412262 and perplexity is 60.52714088570429
At time: 180.41302847862244 and batch: 1700, loss is 4.127136435508728 and perplexity is 62.00012712887579
At time: 181.29986000061035 and batch: 1750, loss is 4.1229361629486085 and perplexity is 61.740255843347605
At time: 182.20536971092224 and batch: 1800, loss is 4.081367449760437 and perplexity is 59.22640363228847
At time: 183.09342336654663 and batch: 1850, loss is 4.114031114578247 and perplexity is 61.192896625939795
At time: 183.97892308235168 and batch: 1900, loss is 4.192447371482849 and perplexity is 66.1845711435777
At time: 184.86471366882324 and batch: 1950, loss is 4.133235764503479 and perplexity is 62.37944190883655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371273732739826 and perplexity of 79.14437630836757
finished 5 epochs...
Completing Train Step...
At time: 187.8504090309143 and batch: 50, loss is 4.097588987350464 and perplexity is 60.19498163832911
At time: 188.73706364631653 and batch: 100, loss is 4.079614496231079 and perplexity is 59.12267344267328
At time: 189.62302708625793 and batch: 150, loss is 4.050621452331543 and perplexity is 57.43313791478313
At time: 190.5080213546753 and batch: 200, loss is 4.04745231628418 and perplexity is 57.25141259532983
At time: 191.3914167881012 and batch: 250, loss is 4.031969952583313 and perplexity is 56.37185181252798
At time: 192.27638411521912 and batch: 300, loss is 4.062439498901367 and perplexity is 58.11591199455885
At time: 193.16171431541443 and batch: 350, loss is 4.067329773902893 and perplexity is 58.400810835241586
At time: 194.0459804534912 and batch: 400, loss is 4.031624426841736 and perplexity is 56.352377251301256
At time: 194.9299533367157 and batch: 450, loss is 4.066618003845215 and perplexity is 58.35925767664628
At time: 195.81562972068787 and batch: 500, loss is 4.085054392814636 and perplexity is 59.44517105347901
At time: 196.70105576515198 and batch: 550, loss is 4.049365472793579 and perplexity is 57.36104834974707
At time: 197.6061511039734 and batch: 600, loss is 4.030996375083923 and perplexity is 56.31699615345499
At time: 198.49819087982178 and batch: 650, loss is 4.085088143348694 and perplexity is 59.44717739360653
At time: 199.38577127456665 and batch: 700, loss is 4.112502479553223 and perplexity is 61.09942647994536
At time: 200.2720148563385 and batch: 750, loss is 4.085186285972595 and perplexity is 59.453011981885695
At time: 201.15923070907593 and batch: 800, loss is 4.058190293312073 and perplexity is 57.86948945727454
At time: 202.06243014335632 and batch: 850, loss is 4.057785611152649 and perplexity is 57.84607544525224
At time: 202.9528341293335 and batch: 900, loss is 4.029089713096619 and perplexity is 56.20972097889746
At time: 203.88236045837402 and batch: 950, loss is 4.120773558616638 and perplexity is 61.60688036977378
At time: 204.76840114593506 and batch: 1000, loss is 4.102501296997071 and perplexity is 60.49140549411339
At time: 205.65491437911987 and batch: 1050, loss is 4.046518044471741 and perplexity is 57.1979491928835
At time: 206.54106998443604 and batch: 1100, loss is 4.080809350013733 and perplexity is 59.19335861348914
At time: 207.42751026153564 and batch: 1150, loss is 4.048810105323792 and perplexity is 57.329200733844225
At time: 208.31369423866272 and batch: 1200, loss is 4.121241936683655 and perplexity is 61.63574243996898
At time: 209.1988537311554 and batch: 1250, loss is 4.106108102798462 and perplexity is 60.70998018766624
At time: 210.08659386634827 and batch: 1300, loss is 4.10990348815918 and perplexity is 60.940835773553665
At time: 210.97403192520142 and batch: 1350, loss is 3.996693320274353 and perplexity is 54.41790960029533
At time: 211.86078453063965 and batch: 1400, loss is 4.029130730628967 and perplexity is 56.212026610231334
At time: 212.7476007938385 and batch: 1450, loss is 3.9586748027801515 and perplexity is 52.38785568765595
At time: 213.6340765953064 and batch: 1500, loss is 3.9737638807296753 and perplexity is 53.184334076169336
At time: 214.5208888053894 and batch: 1550, loss is 3.9779381370544433 and perplexity is 53.406803117433974
At time: 215.4064426422119 and batch: 1600, loss is 4.067063918113709 and perplexity is 58.38528670526934
At time: 216.2951889038086 and batch: 1650, loss is 4.0274520778656 and perplexity is 56.117745291365246
At time: 217.18439245224 and batch: 1700, loss is 4.052274169921875 and perplexity is 57.528137153915644
At time: 218.07346105575562 and batch: 1750, loss is 4.044051189422607 and perplexity is 57.05702403555007
At time: 218.9603238105774 and batch: 1800, loss is 4.002831306457519 and perplexity is 54.752953172052806
At time: 219.84769368171692 and batch: 1850, loss is 4.032945280075073 and perplexity is 56.42685965032983
At time: 220.73505806922913 and batch: 1900, loss is 4.114594464302063 and perplexity is 61.22737933935509
At time: 221.63111996650696 and batch: 1950, loss is 4.05739010810852 and perplexity is 57.82320166994476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365813783157703 and perplexity of 78.71342954838714
finished 6 epochs...
Completing Train Step...
At time: 224.64129948616028 and batch: 50, loss is 4.024878973960877 and perplexity is 55.973534116567095
At time: 225.52788066864014 and batch: 100, loss is 4.005348358154297 and perplexity is 54.890942776368625
At time: 226.4391531944275 and batch: 150, loss is 3.9751609897613527 and perplexity is 53.25869031944567
At time: 227.32605409622192 and batch: 200, loss is 3.974896078109741 and perplexity is 53.24458334046453
At time: 228.2138283252716 and batch: 250, loss is 3.9544659566879274 and perplexity is 52.167826625001766
At time: 229.10016441345215 and batch: 300, loss is 3.9874185276031495 and perplexity is 53.91552811452078
At time: 229.98790168762207 and batch: 350, loss is 3.9912482023239138 and perplexity is 54.122402928377625
At time: 230.8863034248352 and batch: 400, loss is 3.9568870496749877 and perplexity is 52.294282803506626
At time: 231.787837266922 and batch: 450, loss is 3.9939571380615235 and perplexity is 54.26921580341746
At time: 232.67398715019226 and batch: 500, loss is 4.013536863327026 and perplexity is 55.34226284176506
At time: 233.5602524280548 and batch: 550, loss is 3.97697331905365 and perplexity is 53.355300121925254
At time: 234.44700741767883 and batch: 600, loss is 3.9649523305892944 and perplexity is 52.71775630537236
At time: 235.333886384964 and batch: 650, loss is 4.015978493690491 and perplexity is 55.47755328852188
At time: 236.22167539596558 and batch: 700, loss is 4.044041991233826 and perplexity is 57.05649921668539
At time: 237.10889410972595 and batch: 750, loss is 4.018480453491211 and perplexity is 55.616529680868474
At time: 237.9958040714264 and batch: 800, loss is 3.9877447748184203 and perplexity is 53.933120775050206
At time: 238.88312005996704 and batch: 850, loss is 3.989129548072815 and perplexity is 54.00785765309751
At time: 239.7699098587036 and batch: 900, loss is 3.9596156311035156 and perplexity is 52.437166859123245
At time: 240.65690088272095 and batch: 950, loss is 4.0533692741394045 and perplexity is 57.59117096753761
At time: 241.54383039474487 and batch: 1000, loss is 4.035418581962586 and perplexity is 56.5665930390047
At time: 242.43075323104858 and batch: 1050, loss is 3.9804518890380858 and perplexity is 53.541223453620866
At time: 243.31772589683533 and batch: 1100, loss is 4.011679177284241 and perplexity is 55.239549726406715
At time: 244.20491242408752 and batch: 1150, loss is 3.9821466207504272 and perplexity is 53.632038394669635
At time: 245.0927414894104 and batch: 1200, loss is 4.056644835472107 and perplexity is 57.78012367440991
At time: 245.97830653190613 and batch: 1250, loss is 4.04203948020935 and perplexity is 56.94235727138084
At time: 246.8650827407837 and batch: 1300, loss is 4.042354116439819 and perplexity is 56.96027621885393
At time: 247.75340461730957 and batch: 1350, loss is 3.9308186197280883 and perplexity is 50.94866818743094
At time: 248.6403534412384 and batch: 1400, loss is 3.966800217628479 and perplexity is 52.81526282675632
At time: 249.5272605419159 and batch: 1450, loss is 3.895249605178833 and perplexity is 49.16832449958016
At time: 250.41386198997498 and batch: 1500, loss is 3.9086956691741945 and perplexity is 49.83390965974217
At time: 251.301274061203 and batch: 1550, loss is 3.918532409667969 and perplexity is 50.32653182281467
At time: 252.19041180610657 and batch: 1600, loss is 4.008169703483581 and perplexity is 55.0460277526546
At time: 253.07776546478271 and batch: 1650, loss is 3.962680606842041 and perplexity is 52.59813205454289
At time: 253.9677929878235 and batch: 1700, loss is 3.987210636138916 and perplexity is 53.90432070143925
At time: 254.8559548854828 and batch: 1750, loss is 3.981217737197876 and perplexity is 53.58224360667516
At time: 255.74599647521973 and batch: 1800, loss is 3.9421260070800783 and perplexity is 51.52803389695821
At time: 256.6349267959595 and batch: 1850, loss is 3.9697954750061033 and perplexity is 52.973695286938
At time: 257.5235974788666 and batch: 1900, loss is 4.046371536254883 and perplexity is 57.18956983717654
At time: 258.4118559360504 and batch: 1950, loss is 3.9941404342651365 and perplexity is 54.27916405635793
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366729878270349 and perplexity of 78.78557157593012
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 261.3834102153778 and batch: 50, loss is 3.997174105644226 and perplexity is 54.444079225572615
At time: 262.31471705436707 and batch: 100, loss is 3.9919863605499266 and perplexity is 54.16236857398113
At time: 263.2008490562439 and batch: 150, loss is 3.962659010887146 and perplexity is 52.596996159920884
At time: 264.08944749832153 and batch: 200, loss is 3.9669396448135377 and perplexity is 52.82262722356702
At time: 264.9847071170807 and batch: 250, loss is 3.953283886909485 and perplexity is 52.10619704614882
At time: 265.8750853538513 and batch: 300, loss is 3.9672964906692503 and perplexity is 52.84148012276901
At time: 266.75978994369507 and batch: 350, loss is 3.960357322692871 and perplexity is 52.47607349132967
At time: 267.6473331451416 and batch: 400, loss is 3.9255813646316526 and perplexity is 50.68253452855156
At time: 268.53154492378235 and batch: 450, loss is 3.9570204257965087 and perplexity is 52.301258077281815
At time: 269.4170866012573 and batch: 500, loss is 3.968012056350708 and perplexity is 52.87930520405335
At time: 270.3033232688904 and batch: 550, loss is 3.930276017189026 and perplexity is 50.921030809444396
At time: 271.22922706604004 and batch: 600, loss is 3.907136335372925 and perplexity is 49.7562625146027
At time: 272.11317205429077 and batch: 650, loss is 3.9450383234024047 and perplexity is 51.67831856315588
At time: 272.99642848968506 and batch: 700, loss is 3.967834243774414 and perplexity is 52.86990343446359
At time: 273.8808877468109 and batch: 750, loss is 3.9357650756835936 and perplexity is 51.201307850975894
At time: 274.76689553260803 and batch: 800, loss is 3.899098973274231 and perplexity is 49.357956226214455
At time: 275.6509838104248 and batch: 850, loss is 3.8958658838272093 and perplexity is 49.19863522711345
At time: 276.535640001297 and batch: 900, loss is 3.864934997558594 and perplexity is 47.70017170429607
At time: 277.42098903656006 and batch: 950, loss is 3.9624825811386106 and perplexity is 52.587717303671894
At time: 278.30565905570984 and batch: 1000, loss is 3.930471167564392 and perplexity is 50.93096903741381
At time: 279.19104623794556 and batch: 1050, loss is 3.8683330154418947 and perplexity is 47.86253343859602
At time: 280.07639932632446 and batch: 1100, loss is 3.884101600646973 and perplexity is 48.623239744056086
At time: 280.96173000335693 and batch: 1150, loss is 3.8606746053695677 and perplexity is 47.49738255274494
At time: 281.84745693206787 and batch: 1200, loss is 3.9203011846542357 and perplexity is 50.415626904796326
At time: 282.7348177433014 and batch: 1250, loss is 3.899792356491089 and perplexity is 49.392192072589104
At time: 283.62188267707825 and batch: 1300, loss is 3.901180696487427 and perplexity is 49.46081285181434
At time: 284.51229429244995 and batch: 1350, loss is 3.7818500328063966 and perplexity is 43.89717787935359
At time: 285.3995678424835 and batch: 1400, loss is 3.8092706918716432 and perplexity is 45.11752228887738
At time: 286.28578519821167 and batch: 1450, loss is 3.7251926040649415 and perplexity is 41.47922104210011
At time: 287.17255878448486 and batch: 1500, loss is 3.7379256439208985 and perplexity is 42.01075445342542
At time: 288.0588002204895 and batch: 1550, loss is 3.7436218881607055 and perplexity is 42.25074083310033
At time: 288.9462890625 and batch: 1600, loss is 3.827968134880066 and perplexity is 45.96904038911284
At time: 289.8326086997986 and batch: 1650, loss is 3.770485210418701 and perplexity is 43.40111840256581
At time: 290.71950125694275 and batch: 1700, loss is 3.7854243659973146 and perplexity is 44.054361765679836
At time: 291.61079239845276 and batch: 1750, loss is 3.7675197172164916 and perplexity is 43.27260333044281
At time: 292.51218724250793 and batch: 1800, loss is 3.722349443435669 and perplexity is 41.361456445063006
At time: 293.40733790397644 and batch: 1850, loss is 3.74287992477417 and perplexity is 42.21940395719306
At time: 294.29338812828064 and batch: 1900, loss is 3.807880458831787 and perplexity is 45.0548419989154
At time: 295.182017326355 and batch: 1950, loss is 3.758848481178284 and perplexity is 42.89899852167069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.280974915970203 and perplexity of 72.31090270800811
finished 8 epochs...
Completing Train Step...
At time: 298.160906791687 and batch: 50, loss is 3.9064574241638184 and perplexity is 49.72249389450269
At time: 299.0738949775696 and batch: 100, loss is 3.8925515937805177 and perplexity is 49.03584659345641
At time: 299.9610607624054 and batch: 150, loss is 3.8599619102478027 and perplexity is 47.46354345981355
At time: 300.8472409248352 and batch: 200, loss is 3.8599987506866453 and perplexity is 47.46529206979322
At time: 301.7340681552887 and batch: 250, loss is 3.846947875022888 and perplexity is 46.849853188186735
At time: 302.62144923210144 and batch: 300, loss is 3.8636739158630373 and perplexity is 47.64005580438237
At time: 303.50785088539124 and batch: 350, loss is 3.862274994850159 and perplexity is 47.57345772285168
At time: 304.394225358963 and batch: 400, loss is 3.8289424848556517 and perplexity is 46.013852150117586
At time: 305.2809348106384 and batch: 450, loss is 3.8683819723129274 and perplexity is 47.86487669583167
At time: 306.1662948131561 and batch: 500, loss is 3.881741614341736 and perplexity is 48.50862486211571
At time: 307.05297207832336 and batch: 550, loss is 3.8463077974319457 and perplexity is 46.81987524215127
At time: 307.93943190574646 and batch: 600, loss is 3.828060483932495 and perplexity is 45.97328578245986
At time: 308.82587146759033 and batch: 650, loss is 3.8677274703979494 and perplexity is 47.83355929214237
At time: 309.711674451828 and batch: 700, loss is 3.894016509056091 and perplexity is 49.10773259477708
At time: 310.5990192890167 and batch: 750, loss is 3.8649284648895263 and perplexity is 47.69986009587768
At time: 311.4843647480011 and batch: 800, loss is 3.8299954319000244 and perplexity is 46.0623278164153
At time: 312.3703899383545 and batch: 850, loss is 3.83020968914032 and perplexity is 46.07219806100275
At time: 313.25615072250366 and batch: 900, loss is 3.798888850212097 and perplexity is 44.651542366658894
At time: 314.1433780193329 and batch: 950, loss is 3.9000249814987185 and perplexity is 49.40368326816474
At time: 315.02991247177124 and batch: 1000, loss is 3.8703501176834108 and perplexity is 47.959174496760205
At time: 315.963595867157 and batch: 1050, loss is 3.8125559186935423 and perplexity is 45.26598732036182
At time: 316.8496198654175 and batch: 1100, loss is 3.827341628074646 and perplexity is 45.94024949225857
At time: 317.7358994483948 and batch: 1150, loss is 3.8074290418624877 and perplexity is 45.034508068573885
At time: 318.62008786201477 and batch: 1200, loss is 3.871329417228699 and perplexity is 48.00616389913212
At time: 319.52859592437744 and batch: 1250, loss is 3.85286491394043 and perplexity is 47.127887351067976
At time: 320.4144687652588 and batch: 1300, loss is 3.8567721366882326 and perplexity is 47.312386709908
At time: 321.29928636550903 and batch: 1350, loss is 3.7373162651062013 and perplexity is 41.985161788278006
At time: 322.1840069293976 and batch: 1400, loss is 3.77057168006897 and perplexity is 43.40487144435512
At time: 323.06901574134827 and batch: 1450, loss is 3.689839677810669 and perplexity is 40.03842739436404
At time: 323.9542200565338 and batch: 1500, loss is 3.70411084651947 and perplexity is 40.613919249901734
At time: 324.8394420146942 and batch: 1550, loss is 3.7123495721817017 and perplexity is 40.94990834919599
At time: 325.7431786060333 and batch: 1600, loss is 3.801047921180725 and perplexity is 44.74805236396308
At time: 326.641321182251 and batch: 1650, loss is 3.7461183357238768 and perplexity is 42.35634936032229
At time: 327.5260851383209 and batch: 1700, loss is 3.7659241914749146 and perplexity is 43.203615828226994
At time: 328.4128909111023 and batch: 1750, loss is 3.7507679414749147 and perplexity is 42.5537482437652
At time: 329.2991473674774 and batch: 1800, loss is 3.708235921859741 and perplexity is 40.781800750531076
At time: 330.1875195503235 and batch: 1850, loss is 3.733723564147949 and perplexity is 41.83459229482687
At time: 331.07570695877075 and batch: 1900, loss is 3.80277907371521 and perplexity is 44.8255851594108
At time: 331.9651017189026 and batch: 1950, loss is 3.7545493841171265 and perplexity is 42.71496743040347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.280116165515988 and perplexity of 72.24883234275457
finished 9 epochs...
Completing Train Step...
At time: 334.945396900177 and batch: 50, loss is 3.861581826210022 and perplexity is 47.540492720328224
At time: 335.86027812957764 and batch: 100, loss is 3.8468924522399903 and perplexity is 46.847256710897355
At time: 336.75159907341003 and batch: 150, loss is 3.813657021522522 and perplexity is 45.31585727799391
At time: 337.68380522727966 and batch: 200, loss is 3.81434871673584 and perplexity is 45.347212882571135
At time: 338.57283115386963 and batch: 250, loss is 3.8018634128570556 and perplexity is 44.78455891156759
At time: 339.4614431858063 and batch: 300, loss is 3.8185811758041384 and perplexity is 45.53954984700038
At time: 340.349285364151 and batch: 350, loss is 3.818967189788818 and perplexity is 45.55713214338517
At time: 341.23693227767944 and batch: 400, loss is 3.7855100297927855 and perplexity is 44.058135791162094
At time: 342.1248631477356 and batch: 450, loss is 3.8266694068908693 and perplexity is 45.90937786080673
At time: 343.01376581192017 and batch: 500, loss is 3.8414035129547117 and perplexity is 46.59081939140599
At time: 343.90083956718445 and batch: 550, loss is 3.8074355602264403 and perplexity is 45.03480162084464
At time: 344.7886338233948 and batch: 600, loss is 3.7894679594039915 and perplexity is 44.232860337060195
At time: 345.675523519516 and batch: 650, loss is 3.829856290817261 and perplexity is 46.05591910011651
At time: 346.5629599094391 and batch: 700, loss is 3.8566596603393553 and perplexity is 47.307065484655794
At time: 347.45042729377747 and batch: 750, loss is 3.828385691642761 and perplexity is 45.98823908079475
At time: 348.3537518978119 and batch: 800, loss is 3.7941926097869874 and perplexity is 44.44233960607516
At time: 349.2436683177948 and batch: 850, loss is 3.79553334236145 and perplexity is 44.501964860298976
At time: 350.131196975708 and batch: 900, loss is 3.7635662746429444 and perplexity is 43.10186530204528
At time: 351.01946210861206 and batch: 950, loss is 3.8671122455596922 and perplexity is 47.804139949046835
At time: 351.9092013835907 and batch: 1000, loss is 3.8376357746124268 and perplexity is 46.41560765804269
At time: 352.79724526405334 and batch: 1050, loss is 3.781977167129517 and perplexity is 43.90275907212323
At time: 353.68552803993225 and batch: 1100, loss is 3.79577175617218 and perplexity is 44.51257600819814
At time: 354.57448554039 and batch: 1150, loss is 3.777119097709656 and perplexity is 43.6899936538668
At time: 355.4608223438263 and batch: 1200, loss is 3.842878513336182 and perplexity is 46.659591574811145
At time: 356.3447382450104 and batch: 1250, loss is 3.8256958961486816 and perplexity is 45.864706335924765
At time: 357.2330758571625 and batch: 1300, loss is 3.8301509141922 and perplexity is 46.06949024952846
At time: 358.12042760849 and batch: 1350, loss is 3.7102198362350465 and perplexity is 40.862788661267594
At time: 359.008912563324 and batch: 1400, loss is 3.7458591222763062 and perplexity is 42.34537144785084
At time: 359.8961718082428 and batch: 1450, loss is 3.6664131259918213 and perplexity is 39.11136641871553
At time: 360.7841272354126 and batch: 1500, loss is 3.6809258890151977 and perplexity is 39.68311923242402
At time: 361.6716446876526 and batch: 1550, loss is 3.690478310585022 and perplexity is 40.06400541294278
At time: 362.5596036911011 and batch: 1600, loss is 3.7805803442001342 and perplexity is 43.841477501303714
At time: 363.44817781448364 and batch: 1650, loss is 3.726861610412598 and perplexity is 41.54850792935884
At time: 364.33618116378784 and batch: 1700, loss is 3.7484424829483034 and perplexity is 42.45490623810768
At time: 365.22548627853394 and batch: 1750, loss is 3.73518310546875 and perplexity is 41.89569619190407
At time: 366.11415338516235 and batch: 1800, loss is 3.692677526473999 and perplexity is 40.15221176707954
At time: 367.0017111301422 and batch: 1850, loss is 3.720544767379761 and perplexity is 41.28687972862682
At time: 367.88923740386963 and batch: 1900, loss is 3.7908882427215578 and perplexity is 44.2957281651808
At time: 368.77780294418335 and batch: 1950, loss is 3.741493272781372 and perplexity is 42.16090090762036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.28284912109375 and perplexity of 72.44655525299089
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 371.7768511772156 and batch: 50, loss is 3.8541888189315796 and perplexity is 47.19032151568632
At time: 372.66530990600586 and batch: 100, loss is 3.8628497838974 and perplexity is 47.600810285513816
At time: 373.55353927612305 and batch: 150, loss is 3.835054955482483 and perplexity is 46.2959718155105
At time: 374.4416925907135 and batch: 200, loss is 3.837139186859131 and perplexity is 46.39256395780113
At time: 375.32971143722534 and batch: 250, loss is 3.8329254531860353 and perplexity is 46.19748933376498
At time: 376.2191126346588 and batch: 300, loss is 3.8450015115737917 and perplexity is 46.7587550301674
At time: 377.1069242954254 and batch: 350, loss is 3.8407422304153442 and perplexity is 46.5600198807593
At time: 377.99316692352295 and batch: 400, loss is 3.8068067693710326 and perplexity is 45.006493050428176
At time: 378.88018465042114 and batch: 450, loss is 3.8474862337112428 and perplexity is 46.875082004165534
At time: 379.76695680618286 and batch: 500, loss is 3.860914249420166 and perplexity is 47.50876638187167
At time: 380.6566803455353 and batch: 550, loss is 3.8302235984802246 and perplexity is 46.07283889932255
At time: 381.545773267746 and batch: 600, loss is 3.8052067947387695 and perplexity is 44.93454137903406
At time: 382.47819805145264 and batch: 650, loss is 3.838975358009338 and perplexity is 46.47782690004645
At time: 383.367290019989 and batch: 700, loss is 3.863767604827881 and perplexity is 47.644519360985505
At time: 384.25576663017273 and batch: 750, loss is 3.8320685529708864 and perplexity is 46.15791965127152
At time: 385.14393854141235 and batch: 800, loss is 3.7933404064178466 and perplexity is 44.40448182808453
At time: 386.0319046974182 and batch: 850, loss is 3.792112112045288 and perplexity is 44.349973535906074
At time: 386.91918563842773 and batch: 900, loss is 3.750934906005859 and perplexity is 42.56085380355237
At time: 387.8064270019531 and batch: 950, loss is 3.860631194114685 and perplexity is 47.49532067651931
At time: 388.69364953041077 and batch: 1000, loss is 3.8288176441192627 and perplexity is 46.00810810548391
At time: 389.5800721645355 and batch: 1050, loss is 3.771678786277771 and perplexity is 43.452951857174206
At time: 390.4683930873871 and batch: 1100, loss is 3.7798811054229735 and perplexity is 43.81083255550261
At time: 391.3574869632721 and batch: 1150, loss is 3.7592490196228026 and perplexity is 42.91618466143505
At time: 392.24115324020386 and batch: 1200, loss is 3.818341932296753 and perplexity is 45.52865610855029
At time: 393.1474528312683 and batch: 1250, loss is 3.79890962600708 and perplexity is 44.6524700475854
At time: 394.03212428092957 and batch: 1300, loss is 3.809131393432617 and perplexity is 45.111237926160925
At time: 394.9165394306183 and batch: 1350, loss is 3.6826573991775513 and perplexity is 39.75189047852252
At time: 395.801069021225 and batch: 1400, loss is 3.7164475393295286 and perplexity is 41.118064041243876
At time: 396.686646938324 and batch: 1450, loss is 3.6307059955596923 and perplexity is 37.73945109906366
At time: 397.5733308792114 and batch: 1500, loss is 3.6441146659851076 and perplexity is 38.248894809472446
At time: 398.4595980644226 and batch: 1550, loss is 3.649792847633362 and perplexity is 38.46669675636187
At time: 399.346647977829 and batch: 1600, loss is 3.7365608263015746 and perplexity is 41.95345654503795
At time: 400.2331042289734 and batch: 1650, loss is 3.6763098287582396 and perplexity is 39.50036169727696
At time: 401.12126660346985 and batch: 1700, loss is 3.6942724323272706 and perplexity is 40.21630185989512
At time: 402.00904536247253 and batch: 1750, loss is 3.676580004692078 and perplexity is 39.51103518618046
At time: 402.9089605808258 and batch: 1800, loss is 3.6339676761627198 and perplexity is 37.862746099831845
At time: 403.80318093299866 and batch: 1850, loss is 3.6565924215316774 and perplexity is 38.729145161068324
At time: 404.6892294883728 and batch: 1900, loss is 3.7270096588134765 and perplexity is 41.554659574876084
At time: 405.5761036872864 and batch: 1950, loss is 3.6819531679153443 and perplexity is 39.72390580951167
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259421557049419 and perplexity of 70.7690357626102
finished 11 epochs...
Completing Train Step...
At time: 408.5325438976288 and batch: 50, loss is 3.841658020019531 and perplexity is 46.602678593158124
At time: 409.420462846756 and batch: 100, loss is 3.837921714782715 and perplexity is 46.428881642492705
At time: 410.3042821884155 and batch: 150, loss is 3.8022296380996705 and perplexity is 44.80096315116035
At time: 411.1887254714966 and batch: 200, loss is 3.8015805006027223 and perplexity is 44.771890603140946
At time: 412.08273005485535 and batch: 250, loss is 3.7943925523757933 and perplexity is 44.45122641090437
At time: 412.96953415870667 and batch: 300, loss is 3.8038110399246214 and perplexity is 44.87186752542392
At time: 413.856406211853 and batch: 350, loss is 3.803528318405151 and perplexity is 44.85918307602356
At time: 414.7430646419525 and batch: 400, loss is 3.769891004562378 and perplexity is 43.3753368643691
At time: 415.6282470226288 and batch: 450, loss is 3.8123413848876955 and perplexity is 45.25627727743005
At time: 416.51364946365356 and batch: 500, loss is 3.8253132772445677 and perplexity is 45.84716098905376
At time: 417.4004669189453 and batch: 550, loss is 3.79645161151886 and perplexity is 44.542848410252994
At time: 418.28925800323486 and batch: 600, loss is 3.773756785392761 and perplexity is 43.543340934362725
At time: 419.1789782047272 and batch: 650, loss is 3.807704701423645 and perplexity is 45.046923972507706
At time: 420.06877851486206 and batch: 700, loss is 3.8356113052368164 and perplexity is 46.32173573426708
At time: 420.97434759140015 and batch: 750, loss is 3.8056873369216917 and perplexity is 44.95613951062798
At time: 421.8662815093994 and batch: 800, loss is 3.7672944974899294 and perplexity is 43.262858583948855
At time: 422.75595569610596 and batch: 850, loss is 3.767519989013672 and perplexity is 43.27261509181598
At time: 423.6442303657532 and batch: 900, loss is 3.7270704030990602 and perplexity is 41.5571838596518
At time: 424.5405390262604 and batch: 950, loss is 3.8378028583526613 and perplexity is 46.42336359930325
At time: 425.43041586875916 and batch: 1000, loss is 3.8071380853652954 and perplexity is 45.021406891882144
At time: 426.359521150589 and batch: 1050, loss is 3.752503695487976 and perplexity is 42.627675224015576
At time: 427.24807620048523 and batch: 1100, loss is 3.7607096529006956 and perplexity is 42.97891527096694
At time: 428.13237500190735 and batch: 1150, loss is 3.741920928955078 and perplexity is 42.1789351331316
At time: 429.01738262176514 and batch: 1200, loss is 3.803731961250305 and perplexity is 44.868319257923915
At time: 429.90141558647156 and batch: 1250, loss is 3.785621762275696 and perplexity is 44.063058791090825
At time: 430.78563046455383 and batch: 1300, loss is 3.7968478393554688 and perplexity is 44.56050102371246
At time: 431.67008566856384 and batch: 1350, loss is 3.6711408567428587 and perplexity is 39.296712215731816
At time: 432.55770087242126 and batch: 1400, loss is 3.7073403358459474 and perplexity is 40.74529349029754
At time: 433.44452834129333 and batch: 1450, loss is 3.6231116247177124 and perplexity is 37.45392926367069
At time: 434.3331060409546 and batch: 1500, loss is 3.6381345796585083 and perplexity is 38.020845672989466
At time: 435.21942591667175 and batch: 1550, loss is 3.6449754762649538 and perplexity is 38.281834026491524
At time: 436.1051127910614 and batch: 1600, loss is 3.733637638092041 and perplexity is 41.83099776774442
At time: 436.99034357070923 and batch: 1650, loss is 3.6749464797973634 and perplexity is 39.446545613589386
At time: 437.8763806819916 and batch: 1700, loss is 3.694902629852295 and perplexity is 40.241654061401135
At time: 438.7608299255371 and batch: 1750, loss is 3.678621187210083 and perplexity is 39.59176678640611
At time: 439.64691042900085 and batch: 1800, loss is 3.6369547033309937 and perplexity is 37.97601223138712
At time: 440.53295254707336 and batch: 1850, loss is 3.661371278762817 and perplexity is 38.914669159753636
At time: 441.41969656944275 and batch: 1900, loss is 3.7325824642181398 and perplexity is 41.78688207073931
At time: 442.3056311607361 and batch: 1950, loss is 3.6872408819198608 and perplexity is 39.93451078129614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258315259356832 and perplexity of 70.69078743259354
finished 12 epochs...
Completing Train Step...
At time: 445.270712852478 and batch: 50, loss is 3.827878336906433 and perplexity is 45.96491264777022
At time: 446.1560444831848 and batch: 100, loss is 3.8223989105224607 and perplexity is 45.71374006195374
At time: 447.0414123535156 and batch: 150, loss is 3.7861247444152832 and perplexity is 44.08522729739233
At time: 447.92827343940735 and batch: 200, loss is 3.7849760961532595 and perplexity is 44.034617949410524
At time: 448.8577129840851 and batch: 250, loss is 3.7772291994094847 and perplexity is 43.69480426125677
At time: 449.75433254241943 and batch: 300, loss is 3.7863504838943483 and perplexity is 44.095180196975825
At time: 450.6391899585724 and batch: 350, loss is 3.786535658836365 and perplexity is 44.10334627546523
At time: 451.5232284069061 and batch: 400, loss is 3.7527764654159546 and perplexity is 42.639304357883226
At time: 452.40742588043213 and batch: 450, loss is 3.796102771759033 and perplexity is 44.52731280358775
At time: 453.2931067943573 and batch: 500, loss is 3.8090083503723147 and perplexity is 45.10568764286139
At time: 454.18062019348145 and batch: 550, loss is 3.7807764339447023 and perplexity is 43.85007520836197
At time: 455.06570172309875 and batch: 600, loss is 3.758621997833252 and perplexity is 42.889283713149666
At time: 455.95080494880676 and batch: 650, loss is 3.7929027557373045 and perplexity is 44.38505242834848
At time: 456.837144613266 and batch: 700, loss is 3.8216828012466433 and perplexity is 45.68101574715421
At time: 457.72217440605164 and batch: 750, loss is 3.7922924184799194 and perplexity is 44.35797084247157
At time: 458.6096897125244 and batch: 800, loss is 3.7542219734191895 and perplexity is 42.7009843823294
At time: 459.49657940864563 and batch: 850, loss is 3.7548599910736082 and perplexity is 42.72823705714575
At time: 460.38258957862854 and batch: 900, loss is 3.714740309715271 and perplexity is 41.047925952578325
At time: 461.26799273490906 and batch: 950, loss is 3.8258348941802978 and perplexity is 45.87108188291009
At time: 462.15265226364136 and batch: 1000, loss is 3.7956354570388795 and perplexity is 44.506509396113614
At time: 463.03878474235535 and batch: 1050, loss is 3.7423085737228394 and perplexity is 42.19528874613718
At time: 463.9420201778412 and batch: 1100, loss is 3.7501584672927857 and perplexity is 42.52782073473407
At time: 464.8367233276367 and batch: 1150, loss is 3.7321157598495485 and perplexity is 41.76738450048159
At time: 465.72398948669434 and batch: 1200, loss is 3.7950648784637453 and perplexity is 44.481122178788084
At time: 466.6083610057831 and batch: 1250, loss is 3.777554402351379 and perplexity is 43.70901625091321
At time: 467.4945812225342 and batch: 1300, loss is 3.7892949295043947 and perplexity is 44.22520739179046
At time: 468.38439655303955 and batch: 1350, loss is 3.663609280586243 and perplexity is 39.00185778805427
At time: 469.27151918411255 and batch: 1400, loss is 3.70101686000824 and perplexity is 40.48845452474486
At time: 470.1571764945984 and batch: 1450, loss is 3.6172403287887573 and perplexity is 37.23467045778793
At time: 471.0424211025238 and batch: 1500, loss is 3.632953281402588 and perplexity is 37.82435780231969
At time: 471.9460048675537 and batch: 1550, loss is 3.6401337003707885 and perplexity is 38.09692995856921
At time: 472.8356246948242 and batch: 1600, loss is 3.7296758842468263 and perplexity is 41.665601497475045
At time: 473.7238531112671 and batch: 1650, loss is 3.6714286041259765 and perplexity is 39.3080213688486
At time: 474.61358070373535 and batch: 1700, loss is 3.6925452899932862 and perplexity is 40.14690253094772
At time: 475.5026886463165 and batch: 1750, loss is 3.6768820524215697 and perplexity is 39.52297120718159
At time: 476.3945348262787 and batch: 1800, loss is 3.635551109313965 and perplexity is 37.92274671815114
At time: 477.2846395969391 and batch: 1850, loss is 3.660663995742798 and perplexity is 38.88715520625033
At time: 478.1964237689972 and batch: 1900, loss is 3.7324018239974976 and perplexity is 41.77933436087262
At time: 479.0872416496277 and batch: 1950, loss is 3.686567339897156 and perplexity is 39.90762226641764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.258563942132994 and perplexity of 70.70836919991214
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 482.1006796360016 and batch: 50, loss is 3.8267859411239624 and perplexity is 45.91472818668953
At time: 483.0146074295044 and batch: 100, loss is 3.835792455673218 and perplexity is 46.33012769699112
At time: 483.9066996574402 and batch: 150, loss is 3.8056840467453004 and perplexity is 44.955991597242445
At time: 484.79844307899475 and batch: 200, loss is 3.806527600288391 and perplexity is 44.99393038268617
At time: 485.6894555091858 and batch: 250, loss is 3.801301941871643 and perplexity is 44.75942073898191
At time: 486.57895159721375 and batch: 300, loss is 3.809589776992798 and perplexity is 45.131920916014806
At time: 487.4675853252411 and batch: 350, loss is 3.8121016883850096 and perplexity is 45.24543080602463
At time: 488.3561713695526 and batch: 400, loss is 3.776166067123413 and perplexity is 43.648375588396604
At time: 489.24555587768555 and batch: 450, loss is 3.821295256614685 and perplexity is 45.66331574471101
At time: 490.13496446609497 and batch: 500, loss is 3.83256573677063 and perplexity is 46.180874327025606
At time: 491.02387261390686 and batch: 550, loss is 3.80852876663208 and perplexity is 45.08406087481344
At time: 491.91126108169556 and batch: 600, loss is 3.7821940422058105 and perplexity is 43.91228151889986
At time: 492.79864168167114 and batch: 650, loss is 3.8142250919342042 and perplexity is 45.34160718888232
At time: 493.71156001091003 and batch: 700, loss is 3.838170289993286 and perplexity is 46.44042414605426
At time: 494.5993537902832 and batch: 750, loss is 3.806760368347168 and perplexity is 45.00440475152006
At time: 495.4891791343689 and batch: 800, loss is 3.768978686332703 and perplexity is 43.33578279952013
At time: 496.3794765472412 and batch: 850, loss is 3.7694166994094847 and perplexity is 43.35476859678909
At time: 497.2756071090698 and batch: 900, loss is 3.7225225830078124 and perplexity is 41.368618369923546
At time: 498.1653108596802 and batch: 950, loss is 3.832445158958435 and perplexity is 46.175306273932584
At time: 499.0526430606842 and batch: 1000, loss is 3.8001634883880615 and perplexity is 44.70849321532739
At time: 499.9397761821747 and batch: 1050, loss is 3.7477444124221804 and perplexity is 42.42528006115708
At time: 500.8260509967804 and batch: 1100, loss is 3.7524799871444703 and perplexity is 42.62666460442862
At time: 501.7131133079529 and batch: 1150, loss is 3.7334349584579467 and perplexity is 41.822520335553506
At time: 502.5987083911896 and batch: 1200, loss is 3.791981997489929 and perplexity is 44.34420333422102
At time: 503.48353481292725 and batch: 1250, loss is 3.7725518274307253 and perplexity is 43.49090463712161
At time: 504.38416481018066 and batch: 1300, loss is 3.78275444984436 and perplexity is 43.93689719365105
At time: 505.2717328071594 and batch: 1350, loss is 3.6572816038131712 and perplexity is 38.75584580143802
At time: 506.1604335308075 and batch: 1400, loss is 3.695577721595764 and perplexity is 40.26883004190944
At time: 507.0474214553833 and batch: 1450, loss is 3.610089364051819 and perplexity is 36.96935639869041
At time: 507.934654712677 and batch: 1500, loss is 3.626610445976257 and perplexity is 37.58520338602071
At time: 508.8223671913147 and batch: 1550, loss is 3.630620617866516 and perplexity is 37.736229129331214
At time: 509.7104523181915 and batch: 1600, loss is 3.716895971298218 and perplexity is 41.136506830509674
At time: 510.59703636169434 and batch: 1650, loss is 3.6565755128860475 and perplexity is 38.7284903092136
At time: 511.4838981628418 and batch: 1700, loss is 3.6756704378128053 and perplexity is 39.4751135962301
At time: 512.3712487220764 and batch: 1750, loss is 3.659333381652832 and perplexity is 38.83544581986269
At time: 513.2586011886597 and batch: 1800, loss is 3.6200020027160646 and perplexity is 37.33764259867542
At time: 514.158772945404 and batch: 1850, loss is 3.642226023674011 and perplexity is 38.1767245017834
At time: 515.0542280673981 and batch: 1900, loss is 3.71250093460083 and perplexity is 40.95610709550358
At time: 515.942182302475 and batch: 1950, loss is 3.667426338195801 and perplexity is 39.15101461511162
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247272438226744 and perplexity of 69.9144560448138
finished 14 epochs...
Completing Train Step...
At time: 518.8837242126465 and batch: 50, loss is 3.825479507446289 and perplexity is 45.8547828053438
At time: 519.7935917377472 and batch: 100, loss is 3.8248289585113526 and perplexity is 45.824961726315365
At time: 520.6773412227631 and batch: 150, loss is 3.7887977504730226 and perplexity is 44.203225011059374
At time: 521.5725266933441 and batch: 200, loss is 3.7878663110733033 and perplexity is 44.162071554640114
At time: 522.4780061244965 and batch: 250, loss is 3.781193246841431 and perplexity is 43.86835629486298
At time: 523.3638479709625 and batch: 300, loss is 3.7900854539871216 and perplexity is 44.260182323435814
At time: 524.2517645359039 and batch: 350, loss is 3.793879199028015 and perplexity is 44.42841308116408
At time: 525.1360056400299 and batch: 400, loss is 3.758648166656494 and perplexity is 42.890406089919715
At time: 526.0218775272369 and batch: 450, loss is 3.804101338386536 and perplexity is 44.88489565048062
At time: 526.9088037014008 and batch: 500, loss is 3.8155263376235964 and perplexity is 45.40064616356203
At time: 527.7954366207123 and batch: 550, loss is 3.7905001974105836 and perplexity is 44.278542750145625
At time: 528.6824297904968 and batch: 600, loss is 3.7661911344528196 and perplexity is 43.21515026954301
At time: 529.5693700313568 and batch: 650, loss is 3.798236165046692 and perplexity is 44.622408476007095
At time: 530.4556736946106 and batch: 700, loss is 3.8247909927368164 and perplexity is 45.82322197917597
At time: 531.3516700267792 and batch: 750, loss is 3.7945586395263673 and perplexity is 44.45860980156466
At time: 532.2356970310211 and batch: 800, loss is 3.7572968292236326 and perplexity is 42.83248582238668
At time: 533.1200046539307 and batch: 850, loss is 3.758230047225952 and perplexity is 42.87247652636036
At time: 534.0073733329773 and batch: 900, loss is 3.7127743101119997 and perplexity is 40.96730502276614
At time: 534.8939127922058 and batch: 950, loss is 3.823725481033325 and perplexity is 45.77442280252927
At time: 535.7794466018677 and batch: 1000, loss is 3.792529306411743 and perplexity is 44.36847995513618
At time: 536.6666593551636 and batch: 1050, loss is 3.7408510398864747 and perplexity is 42.13383248322566
At time: 537.5543100833893 and batch: 1100, loss is 3.7461705780029297 and perplexity is 42.3585622103469
At time: 538.4641947746277 and batch: 1150, loss is 3.7278080224990844 and perplexity is 41.58784855272296
At time: 539.3488817214966 and batch: 1200, loss is 3.786988558769226 and perplexity is 44.123325201918064
At time: 540.2343399524689 and batch: 1250, loss is 3.768254828453064 and perplexity is 43.30442520226153
At time: 541.120279788971 and batch: 1300, loss is 3.7793704319000243 and perplexity is 43.788465234983434
At time: 542.0079789161682 and batch: 1350, loss is 3.654479627609253 and perplexity is 38.64740483918567
At time: 542.8958148956299 and batch: 1400, loss is 3.6941286516189575 and perplexity is 40.21051994720168
At time: 543.7839231491089 and batch: 1450, loss is 3.609453945159912 and perplexity is 36.94587283295384
At time: 544.6721858978271 and batch: 1500, loss is 3.62705828666687 and perplexity is 37.602039339092975
At time: 545.5599400997162 and batch: 1550, loss is 3.631651048660278 and perplexity is 37.77513374267998
At time: 546.4485995769501 and batch: 1600, loss is 3.718718476295471 and perplexity is 41.21154667925693
At time: 547.3365459442139 and batch: 1650, loss is 3.6589139223098757 and perplexity is 38.81915934527143
At time: 548.2241864204407 and batch: 1700, loss is 3.678711576461792 and perplexity is 39.595345618321296
At time: 549.1126155853271 and batch: 1750, loss is 3.663042140007019 and perplexity is 38.97974452309523
At time: 549.9994668960571 and batch: 1800, loss is 3.624269847869873 and perplexity is 37.49733440324978
At time: 550.8901124000549 and batch: 1850, loss is 3.646831364631653 and perplexity is 38.352946805195295
At time: 551.776771068573 and batch: 1900, loss is 3.7171374702453615 and perplexity is 41.14644245327134
At time: 552.6619522571564 and batch: 1950, loss is 3.6711227989196775 and perplexity is 39.296002609058014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.246216671965843 and perplexity of 69.84068167207195
finished 15 epochs...
Completing Train Step...
At time: 555.5935981273651 and batch: 50, loss is 3.8214615201950073 and perplexity is 45.6709085222598
At time: 556.5297482013702 and batch: 100, loss is 3.819528021812439 and perplexity is 45.582689207935736
At time: 557.4197599887848 and batch: 150, loss is 3.782559218406677 and perplexity is 43.92832016732444
At time: 558.3073153495789 and batch: 200, loss is 3.7813072681427 and perplexity is 43.87335850710621
At time: 559.1933648586273 and batch: 250, loss is 3.773888921737671 and perplexity is 43.54909497242936
At time: 560.1046800613403 and batch: 300, loss is 3.782701587677002 and perplexity is 43.93457465542615
At time: 560.992311000824 and batch: 350, loss is 3.7868820238113403 and perplexity is 44.1186247757102
At time: 561.8794450759888 and batch: 400, loss is 3.751515407562256 and perplexity is 42.58556761793675
At time: 562.766768693924 and batch: 450, loss is 3.79692702293396 and perplexity is 44.564029623344595
At time: 563.6540331840515 and batch: 500, loss is 3.8084114265441893 and perplexity is 45.07877101751015
At time: 564.5425248146057 and batch: 550, loss is 3.783380136489868 and perplexity is 43.96439652555541
At time: 565.4312818050385 and batch: 600, loss is 3.759606399536133 and perplexity is 42.93152478475252
At time: 566.3200011253357 and batch: 650, loss is 3.7915942907333373 and perplexity is 44.32701411937535
At time: 567.2077970504761 and batch: 700, loss is 3.8188718366622925 and perplexity is 45.55278833550087
At time: 568.094920873642 and batch: 750, loss is 3.789037346839905 and perplexity is 44.21381721205226
At time: 568.9828526973724 and batch: 800, loss is 3.751845474243164 and perplexity is 42.599626014871575
At time: 569.8697082996368 and batch: 850, loss is 3.753061780929565 and perplexity is 42.65147174859622
At time: 570.7564496994019 and batch: 900, loss is 3.708118209838867 and perplexity is 40.77700052487752
At time: 571.6424300670624 and batch: 950, loss is 3.8193585586547854 and perplexity is 45.57496527596765
At time: 572.5318922996521 and batch: 1000, loss is 3.788492913246155 and perplexity is 44.1897522761283
At time: 573.4183151721954 and batch: 1050, loss is 3.737251014709473 and perplexity is 41.982422329190975
At time: 574.3026764392853 and batch: 1100, loss is 3.7426766204833983 and perplexity is 42.210821443675215
At time: 575.1873981952667 and batch: 1150, loss is 3.7246865034103394 and perplexity is 41.458233692481976
At time: 576.0711133480072 and batch: 1200, loss is 3.784354639053345 and perplexity is 44.007260824963915
At time: 576.9533867835999 and batch: 1250, loss is 3.7659510278701784 and perplexity is 43.20477527309578
At time: 577.8380715847015 and batch: 1300, loss is 3.777423577308655 and perplexity is 43.70329839102253
At time: 578.7234778404236 and batch: 1350, loss is 3.652663540840149 and perplexity is 38.57728149291095
At time: 579.6092712879181 and batch: 1400, loss is 3.6929092597961426 and perplexity is 40.16151745068059
At time: 580.4930050373077 and batch: 1450, loss is 3.608567781448364 and perplexity is 36.913147243414336
At time: 581.3925457000732 and batch: 1500, loss is 3.6266158771514894 and perplexity is 37.58540751840078
At time: 582.280356168747 and batch: 1550, loss is 3.631454792022705 and perplexity is 37.76772084938631
At time: 583.1668858528137 and batch: 1600, loss is 3.7189149904251098 and perplexity is 41.2196461262855
At time: 584.0536348819733 and batch: 1650, loss is 3.6593891859054564 and perplexity is 38.837613063362134
At time: 584.9626648426056 and batch: 1700, loss is 3.6795173931121825 and perplexity is 39.62726506598249
At time: 585.8483653068542 and batch: 1750, loss is 3.664079909324646 and perplexity is 39.020217503146334
At time: 586.7343609333038 and batch: 1800, loss is 3.6254452323913573 and perplexity is 37.54143410167867
At time: 587.6196691989899 and batch: 1850, loss is 3.648193120956421 and perplexity is 38.40520974970209
At time: 588.5032696723938 and batch: 1900, loss is 3.71844292640686 and perplexity is 41.20019240656611
At time: 589.3866832256317 and batch: 1950, loss is 3.672036747932434 and perplexity is 39.33193356887937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24598757721657 and perplexity of 69.82468337124854
finished 16 epochs...
Completing Train Step...
At time: 592.3780753612518 and batch: 50, loss is 3.8176310634613038 and perplexity is 45.49630270667783
At time: 593.2654829025269 and batch: 100, loss is 3.8150540924072267 and perplexity is 45.379210987319276
At time: 594.1534793376923 and batch: 150, loss is 3.777697048187256 and perplexity is 43.715251604784726
At time: 595.0415987968445 and batch: 200, loss is 3.7763154125213623 and perplexity is 43.654894759210656
At time: 595.9284596443176 and batch: 250, loss is 3.768581018447876 and perplexity is 43.31855297653762
At time: 596.8161869049072 and batch: 300, loss is 3.7773520946502686 and perplexity is 43.70017447472754
At time: 597.7041022777557 and batch: 350, loss is 3.7818482065200807 and perplexity is 43.897097710611526
At time: 598.5911209583282 and batch: 400, loss is 3.746370539665222 and perplexity is 42.36703314576173
At time: 599.4792313575745 and batch: 450, loss is 3.791858820915222 and perplexity is 44.3387415035379
At time: 600.3675467967987 and batch: 500, loss is 3.8033278083801267 and perplexity is 44.85018926180751
At time: 601.2550556659698 and batch: 550, loss is 3.77842707157135 and perplexity is 43.747176412207935
At time: 602.1441717147827 and batch: 600, loss is 3.754935874938965 and perplexity is 42.73147956395894
At time: 603.0323247909546 and batch: 650, loss is 3.7869053173065184 and perplexity is 44.11965246465286
At time: 603.9204819202423 and batch: 700, loss is 3.8146704053878784 and perplexity is 45.36180291295482
At time: 604.8333489894867 and batch: 750, loss is 3.7850397062301635 and perplexity is 44.037419083933976
At time: 605.7195365428925 and batch: 800, loss is 3.7479038763046266 and perplexity is 42.432045900468665
At time: 606.607096195221 and batch: 850, loss is 3.749270324707031 and perplexity is 42.490066734009815
At time: 607.4958081245422 and batch: 900, loss is 3.7046462726593017 and perplexity is 40.63567082657086
At time: 608.3818528652191 and batch: 950, loss is 3.8159997987747194 and perplexity is 45.42214669518794
At time: 609.2667872905731 and batch: 1000, loss is 3.785306534767151 and perplexity is 44.04917109185665
At time: 610.1514048576355 and batch: 1050, loss is 3.734428358078003 and perplexity is 41.864087454326295
At time: 611.036759853363 and batch: 1100, loss is 3.739857234954834 and perplexity is 42.091980472526814
At time: 611.9241676330566 and batch: 1150, loss is 3.7221039390563964 and perplexity is 41.35130327274778
At time: 612.8080413341522 and batch: 1200, loss is 3.782110166549683 and perplexity is 43.908598501935295
At time: 613.6919314861298 and batch: 1250, loss is 3.7639310455322263 and perplexity is 43.11759047564964
At time: 614.5797955989838 and batch: 1300, loss is 3.7756039237976076 and perplexity is 43.62384584064029
At time: 615.4659216403961 and batch: 1350, loss is 3.65088294506073 and perplexity is 38.508652067068795
At time: 616.3654522895813 and batch: 1400, loss is 3.691515016555786 and perplexity is 40.10556154358958
At time: 617.2587311267853 and batch: 1450, loss is 3.6073801851272584 and perplexity is 36.869335346120955
At time: 618.1450619697571 and batch: 1500, loss is 3.625683755874634 and perplexity is 37.55038968332361
At time: 619.031313419342 and batch: 1550, loss is 3.6306480741500855 and perplexity is 37.737265240162834
At time: 619.9167094230652 and batch: 1600, loss is 3.718379054069519 and perplexity is 41.19756093801812
At time: 620.8027937412262 and batch: 1650, loss is 3.6590585613250735 and perplexity is 38.82477451632655
At time: 621.6884407997131 and batch: 1700, loss is 3.679449381828308 and perplexity is 39.62457005645549
At time: 622.5728514194489 and batch: 1750, loss is 3.6641576194763186 and perplexity is 39.023249887988825
At time: 623.4704837799072 and batch: 1800, loss is 3.625598249435425 and perplexity is 37.547179020479
At time: 624.3594436645508 and batch: 1850, loss is 3.6485170698165894 and perplexity is 38.41765308901901
At time: 625.2430834770203 and batch: 1900, loss is 3.718744812011719 and perplexity is 41.212632029148075
At time: 626.1279973983765 and batch: 1950, loss is 3.6720886754989626 and perplexity is 39.33397603350611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2460241983103195 and perplexity of 69.82724047434597
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 629.1038022041321 and batch: 50, loss is 3.8178605794906617 and perplexity is 45.50674603583541
At time: 629.9898853302002 and batch: 100, loss is 3.820815086364746 and perplexity is 45.6413948422806
At time: 630.8759586811066 and batch: 150, loss is 3.7851176500320434 and perplexity is 44.04085166157469
At time: 631.7622926235199 and batch: 200, loss is 3.7845106601715086 and perplexity is 44.01412742265834
At time: 632.6506960391998 and batch: 250, loss is 3.777073917388916 and perplexity is 43.68801977053108
At time: 633.538976430893 and batch: 300, loss is 3.7862546396255494 and perplexity is 44.09095412919771
At time: 634.4269683361053 and batch: 350, loss is 3.793871908187866 and perplexity is 44.42808916188706
At time: 635.3139102458954 and batch: 400, loss is 3.758859272003174 and perplexity is 42.899461439749324
At time: 636.2007260322571 and batch: 450, loss is 3.8057346296310426 and perplexity is 44.95826565854264
At time: 637.0866298675537 and batch: 500, loss is 3.817550220489502 and perplexity is 45.49262479902953
At time: 637.9730863571167 and batch: 550, loss is 3.7920854663848877 and perplexity is 44.348791817316375
At time: 638.8840069770813 and batch: 600, loss is 3.7645892238616945 and perplexity is 43.14597888061125
At time: 639.772129535675 and batch: 650, loss is 3.7962552213668825 and perplexity is 44.534101492416575
At time: 640.6593985557556 and batch: 700, loss is 3.8216740798950197 and perplexity is 45.680617348690646
At time: 641.5478870868683 and batch: 750, loss is 3.790278911590576 and perplexity is 44.26874562052733
At time: 642.436437368393 and batch: 800, loss is 3.7546801280975344 and perplexity is 42.720552520368805
At time: 643.3240926265717 and batch: 850, loss is 3.758464674949646 and perplexity is 42.88253677809768
At time: 644.2125480175018 and batch: 900, loss is 3.709464440345764 and perplexity is 40.83193273437568
At time: 645.1005308628082 and batch: 950, loss is 3.821112732887268 and perplexity is 45.65498186670343
At time: 645.988703250885 and batch: 1000, loss is 3.789033546447754 and perplexity is 44.21364918252767
At time: 646.8764004707336 and batch: 1050, loss is 3.7379925537109373 and perplexity is 42.01356547822676
At time: 647.7629318237305 and batch: 1100, loss is 3.7418277645111084 and perplexity is 42.175005739135436
At time: 648.673505783081 and batch: 1150, loss is 3.7239439249038697 and perplexity is 41.42745912690537
At time: 649.5566608905792 and batch: 1200, loss is 3.783477931022644 and perplexity is 43.96869621341195
At time: 650.4402077198029 and batch: 1250, loss is 3.7638131475448606 and perplexity is 43.11250729816659
At time: 651.328958272934 and batch: 1300, loss is 3.7729058504104613 and perplexity is 43.50630414250121
At time: 652.2165932655334 and batch: 1350, loss is 3.6453596353530884 and perplexity is 38.2965431660872
At time: 653.1032631397247 and batch: 1400, loss is 3.685307116508484 and perplexity is 39.85736142404763
At time: 654.0146062374115 and batch: 1450, loss is 3.6005320882797243 and perplexity is 36.6177131170114
At time: 654.9029114246368 and batch: 1500, loss is 3.618731627464294 and perplexity is 37.2902398975429
At time: 655.7910480499268 and batch: 1550, loss is 3.6248625707626343 and perplexity is 37.51956651985947
At time: 656.6791098117828 and batch: 1600, loss is 3.7112982082366943 and perplexity is 40.90687771639793
At time: 657.566428899765 and batch: 1650, loss is 3.6519150161743164 and perplexity is 38.548416250693364
At time: 658.4519033432007 and batch: 1700, loss is 3.6710149812698365 and perplexity is 39.291766034801405
At time: 659.3366215229034 and batch: 1750, loss is 3.6560411930084227 and perplexity is 38.70780243447452
At time: 660.2215957641602 and batch: 1800, loss is 3.6174377965927125 and perplexity is 37.24202383239769
At time: 661.1074287891388 and batch: 1850, loss is 3.6412533855438234 and perplexity is 38.13961041606066
At time: 661.9937107563019 and batch: 1900, loss is 3.709407296180725 and perplexity is 40.82959949433881
At time: 662.8802542686462 and batch: 1950, loss is 3.6638347721099853 and perplexity is 39.01065336802278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243897619912791 and perplexity of 69.6789051524416
finished 18 epochs...
Completing Train Step...
At time: 665.8449153900146 and batch: 50, loss is 3.815691976547241 and perplexity is 45.40816690057153
At time: 666.7315526008606 and batch: 100, loss is 3.8149769592285154 and perplexity is 45.37571087951737
At time: 667.6180922985077 and batch: 150, loss is 3.7792615604400637 and perplexity is 43.78369818034667
At time: 668.5099847316742 and batch: 200, loss is 3.7786941051483156 and perplexity is 43.75885993708473
At time: 669.4229171276093 and batch: 250, loss is 3.770802102088928 and perplexity is 43.41487403487366
At time: 670.3098669052124 and batch: 300, loss is 3.779318332672119 and perplexity is 43.78618394918067
At time: 671.2216672897339 and batch: 350, loss is 3.7865952014923097 and perplexity is 44.10597238402049
At time: 672.109379529953 and batch: 400, loss is 3.7515377521514894 and perplexity is 42.586519185583604
At time: 672.9969520568848 and batch: 450, loss is 3.798587579727173 and perplexity is 44.63809220100818
At time: 673.8838264942169 and batch: 500, loss is 3.8098464012145996 and perplexity is 45.14350434632912
At time: 674.7699162960052 and batch: 550, loss is 3.7846393680572508 and perplexity is 44.01979275252019
At time: 675.6577224731445 and batch: 600, loss is 3.7587257385253907 and perplexity is 42.893733307925444
At time: 676.56334400177 and batch: 650, loss is 3.790123062133789 and perplexity is 44.261846898164755
At time: 677.4546682834625 and batch: 700, loss is 3.816820726394653 and perplexity is 45.459450299651344
At time: 678.3405735492706 and batch: 750, loss is 3.7857782316207884 and perplexity is 44.06995384846113
At time: 679.2275197505951 and batch: 800, loss is 3.750225315093994 and perplexity is 42.530663721063
At time: 680.1145839691162 and batch: 850, loss is 3.7536403274536134 and perplexity is 42.676154748765406
At time: 681.0027210712433 and batch: 900, loss is 3.7056033277511595 and perplexity is 40.67458001839665
At time: 681.9131429195404 and batch: 950, loss is 3.817379312515259 and perplexity is 45.48485041105349
At time: 682.7994768619537 and batch: 1000, loss is 3.785689616203308 and perplexity is 44.06604874413129
At time: 683.6855092048645 and batch: 1050, loss is 3.735306267738342 and perplexity is 41.90085647870301
At time: 684.5729489326477 and batch: 1100, loss is 3.739769763946533 and perplexity is 42.088298805575405
At time: 685.4612939357758 and batch: 1150, loss is 3.722191181182861 and perplexity is 41.35491100574825
At time: 686.3472797870636 and batch: 1200, loss is 3.781776762008667 and perplexity is 43.89396161594283
At time: 687.2328753471375 and batch: 1250, loss is 3.7624642992019655 and perplexity is 43.05439426578398
At time: 688.1190559864044 and batch: 1300, loss is 3.771890525817871 and perplexity is 43.462153539362035
At time: 689.0044341087341 and batch: 1350, loss is 3.6446572732925415 and perplexity is 38.26965457098714
At time: 689.8945682048798 and batch: 1400, loss is 3.6850891304016113 and perplexity is 39.848674019901694
At time: 690.7812221050262 and batch: 1450, loss is 3.600829906463623 and perplexity is 36.62862016190796
At time: 691.6687819957733 and batch: 1500, loss is 3.6198578786849978 and perplexity is 37.33226173487877
At time: 692.5557119846344 and batch: 1550, loss is 3.626210355758667 and perplexity is 37.570168921591446
At time: 693.4672408103943 and batch: 1600, loss is 3.712623271942139 and perplexity is 40.96111786325176
At time: 694.3546357154846 and batch: 1650, loss is 3.653707118034363 and perplexity is 38.6175608777599
At time: 695.2426936626434 and batch: 1700, loss is 3.6733344316482546 and perplexity is 39.383007110067545
At time: 696.131374835968 and batch: 1750, loss is 3.658690094947815 and perplexity is 38.81047152755969
At time: 697.0180542469025 and batch: 1800, loss is 3.6205707454681395 and perplexity is 37.358884152200204
At time: 697.9051864147186 and batch: 1850, loss is 3.6444788360595703 and perplexity is 38.26282644893245
At time: 698.7933285236359 and batch: 1900, loss is 3.712379879951477 and perplexity is 40.95114946839823
At time: 699.6806769371033 and batch: 1950, loss is 3.6659867668151858 and perplexity is 39.09469448310108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.243216865007267 and perplexity of 69.63148703783585
finished 19 epochs...
Completing Train Step...
At time: 702.6306185722351 and batch: 50, loss is 3.814610147476196 and perplexity is 45.35906958779421
At time: 703.5421283245087 and batch: 100, loss is 3.8127765035629273 and perplexity is 45.27597341361252
At time: 704.4304876327515 and batch: 150, loss is 3.7767861795425417 and perplexity is 43.6754508821691
At time: 705.3191857337952 and batch: 200, loss is 3.7760111141204833 and perplexity is 43.64161266550732
At time: 706.2079310417175 and batch: 250, loss is 3.767873167991638 and perplexity is 43.28790076891906
At time: 707.0966804027557 and batch: 300, loss is 3.776356244087219 and perplexity is 43.656677293312576
At time: 707.9839563369751 and batch: 350, loss is 3.783568434715271 and perplexity is 43.97267572285671
At time: 708.871796131134 and batch: 400, loss is 3.748419919013977 and perplexity is 42.45394829919897
At time: 709.7596480846405 and batch: 450, loss is 3.7954608631134032 and perplexity is 44.498739508236255
At time: 710.647914648056 and batch: 500, loss is 3.8065698289871217 and perplexity is 44.99583045793559
At time: 711.5369799137115 and batch: 550, loss is 3.7813589763641358 and perplexity is 43.875627179097016
At time: 712.4246454238892 and batch: 600, loss is 3.756105842590332 and perplexity is 42.78150327009668
At time: 713.3127028942108 and batch: 650, loss is 3.787275586128235 and perplexity is 44.135991621138935
At time: 714.2003335952759 and batch: 700, loss is 3.8143522787094115 and perplexity is 45.34737440843265
At time: 715.0880808830261 and batch: 750, loss is 3.7834920930862426 and perplexity is 43.96931890529337
At time: 716.0070440769196 and batch: 800, loss is 3.7480013370513916 and perplexity is 42.4361815608779
At time: 716.9109320640564 and batch: 850, loss is 3.7512646913528442 and perplexity is 42.574892064171046
At time: 717.7984762191772 and batch: 900, loss is 3.7036255836486816 and perplexity is 40.5942156039631
At time: 718.6859624385834 and batch: 950, loss is 3.8155597925186155 and perplexity is 45.402165062820394
At time: 719.574047088623 and batch: 1000, loss is 3.7841066884994508 and perplexity is 43.99635055292689
At time: 720.461923122406 and batch: 1050, loss is 3.7339998197555544 and perplexity is 41.846150932035854
At time: 721.3502762317657 and batch: 1100, loss is 3.738679585456848 and perplexity is 42.0424400492069
At time: 722.2381711006165 and batch: 1150, loss is 3.7213074779510498 and perplexity is 41.31838168015997
At time: 723.1236188411713 and batch: 1200, loss is 3.7809695482254027 and perplexity is 43.858544101800305
At time: 724.0088171958923 and batch: 1250, loss is 3.7617967557907104 and perplexity is 43.025663179256945
At time: 724.8969573974609 and batch: 1300, loss is 3.771439552307129 and perplexity is 43.442557678335206
At time: 725.7847292423248 and batch: 1350, loss is 3.6443374490737916 and perplexity is 38.25741696565775
At time: 726.6725077629089 and batch: 1400, loss is 3.685052766799927 and perplexity is 39.84722500493784
At time: 727.5597188472748 and batch: 1450, loss is 3.6009900999069213 and perplexity is 36.63448829670078
At time: 728.4485621452332 and batch: 1500, loss is 3.6204181575775145 and perplexity is 37.35318407376385
At time: 729.3365092277527 and batch: 1550, loss is 3.6269034051895144 and perplexity is 37.59621593066924
At time: 730.2241125106812 and batch: 1600, loss is 3.7133953189849853 and perplexity is 40.99275398388505
At time: 731.1121346950531 and batch: 1650, loss is 3.654627537727356 and perplexity is 38.65312160417309
At time: 731.9995954036713 and batch: 1700, loss is 3.674464364051819 and perplexity is 39.42753239649568
At time: 732.8873934745789 and batch: 1750, loss is 3.659951024055481 and perplexity is 38.85943964696656
At time: 733.7744059562683 and batch: 1800, loss is 3.622011966705322 and perplexity is 37.41276538750163
At time: 734.6617805957794 and batch: 1850, loss is 3.645968823432922 and perplexity is 38.319880071243325
At time: 735.5494976043701 and batch: 1900, loss is 3.7137459230422976 and perplexity is 41.00712872952703
At time: 736.4512572288513 and batch: 1950, loss is 3.6668904876708983 and perplexity is 39.13004114320446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.242926451217296 and perplexity of 69.61126802986536
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f939f2aab38>
ELAPSED
4597.714177846909


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}, 'best_accuracy': -70.21234677830806}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7054039444822918, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3700134384042031, 'data': 'wikitext'}, 'best_accuracy': -70.64095605480648}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7401099843983403, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.9299697240020345, 'data': 'wikitext'}, 'best_accuracy': -71.41562243224405}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.15141962671034973, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3607507403598699, 'data': 'wikitext'}, 'best_accuracy': -69.61126802986536}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7217137032742265, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.6897488522721319, 'data': 'wikitext'}, 'best_accuracy': -70.81570065207279}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.9104687125541856, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.8583249204840793, 'data': 'wikitext'}, 'best_accuracy': -71.37871341156297}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.13145607125714087, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.1156242590062675, 'data': 'wikitext'}, 'best_accuracy': -70.21234677830806}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7054039444822918, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3700134384042031, 'data': 'wikitext'}, 'best_accuracy': -70.64095605480648}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.7401099843983403, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.9299697240020345, 'data': 'wikitext'}, 'best_accuracy': -71.41562243224405}, {'params': {'tune_wordvecs': 'FALSE', 'dropout': 0.15141962671034973, 'seq_len': 35, 'batch_size': 32, 'wordvec_source': 'glove', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'num_layers': 2, 'rnn_dropout': 0.3607507403598699, 'data': 'wikitext'}, 'best_accuracy': -69.61126802986536}]
