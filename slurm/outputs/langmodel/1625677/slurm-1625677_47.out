TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'name': 'dropout', 'domain': [0, 1]}, {'type': 'continuous', 'name': 'rnn_dropout', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.862267017364502 and batch: 50, loss is 9.291298580169677 and perplexity is 10843.255796950141
At time: 3.034703254699707 and batch: 100, loss is 8.270872220993041 and perplexity is 3908.3564564566414
At time: 4.203551530838013 and batch: 150, loss is 7.775487432479858 and perplexity is 2381.5038395501383
At time: 5.370699405670166 and batch: 200, loss is 7.56043888092041 and perplexity is 1920.688281863492
At time: 6.538254022598267 and batch: 250, loss is 7.3986430168151855 and perplexity is 1633.765932206331
At time: 7.7071661949157715 and batch: 300, loss is 7.223698997497559 and perplexity is 1371.5530604113148
At time: 8.875970602035522 and batch: 350, loss is 7.053300037384033 and perplexity is 1156.6695041021453
At time: 10.054100751876831 and batch: 400, loss is 6.855379056930542 and perplexity is 948.971775565986
At time: 11.233402967453003 and batch: 450, loss is 6.73864369392395 and perplexity is 844.4146740683002
At time: 12.410943984985352 and batch: 500, loss is 6.720868930816651 and perplexity is 829.5380095447273
At time: 13.590872287750244 and batch: 550, loss is 6.714159479141236 and perplexity is 823.9908942172865
At time: 14.76618766784668 and batch: 600, loss is 6.758771133422852 and perplexity is 861.582774703696
At time: 15.943626403808594 and batch: 650, loss is 6.838003797531128 and perplexity is 932.6255658605506
At time: 17.117307901382446 and batch: 700, loss is 6.754643850326538 and perplexity is 858.0341068973822
At time: 18.29499912261963 and batch: 750, loss is 6.720229330062867 and perplexity is 829.0076060498493
At time: 19.476465940475464 and batch: 800, loss is 6.745299491882324 and perplexity is 850.0536727327626
At time: 20.65501618385315 and batch: 850, loss is 6.784172992706299 and perplexity is 883.7489178448254
At time: 21.829630136489868 and batch: 900, loss is 6.822378425598145 and perplexity is 918.1662051535059
At time: 23.008564710617065 and batch: 950, loss is 6.786394834518433 and perplexity is 885.7146511074312
At time: 24.19327735900879 and batch: 1000, loss is 6.814579086303711 and perplexity is 911.0329688154101
At time: 25.369083166122437 and batch: 1050, loss is 6.7358934020996095 and perplexity is 842.0954779887521
At time: 26.5471830368042 and batch: 1100, loss is 6.797308130264282 and perplexity is 895.4336537555963
At time: 27.72212052345276 and batch: 1150, loss is 6.720056848526001 and perplexity is 828.8646298746143
At time: 28.895729541778564 and batch: 1200, loss is 6.811201095581055 and perplexity is 907.9606998681437
At time: 30.07215642929077 and batch: 1250, loss is 6.77015438079834 and perplexity is 871.4464182002805
At time: 31.246038675308228 and batch: 1300, loss is 6.806921443939209 and perplexity is 904.0832473593146
At time: 32.41813683509827 and batch: 1350, loss is 6.7932138252258305 and perplexity is 891.7749702295991
At time: 33.593870878219604 and batch: 1400, loss is 6.785200729370117 and perplexity is 884.657645895885
At time: 34.77296805381775 and batch: 1450, loss is 6.808741483688355 and perplexity is 905.7302131229857
At time: 35.96223020553589 and batch: 1500, loss is 6.783717412948608 and perplexity is 883.3463914253803
At time: 37.14720106124878 and batch: 1550, loss is 6.778764963150024 and perplexity is 878.9824777182507
At time: 38.33315658569336 and batch: 1600, loss is 6.78112488746643 and perplexity is 881.0592594010676
At time: 39.51563882827759 and batch: 1650, loss is 6.7668953800201415 and perplexity is 868.6109964756153
At time: 40.69769501686096 and batch: 1700, loss is 6.795909252166748 and perplexity is 894.1819269402966
At time: 41.89017581939697 and batch: 1750, loss is 6.828963384628296 and perplexity is 924.2322423811704
At time: 43.077706813812256 and batch: 1800, loss is 6.832014150619507 and perplexity is 927.0561640460691
At time: 44.26526403427124 and batch: 1850, loss is 6.785189323425293 and perplexity is 884.6475555971325
At time: 45.45354890823364 and batch: 1900, loss is 6.770146465301513 and perplexity is 871.4395202962227
At time: 46.641061305999756 and batch: 1950, loss is 6.719847087860107 and perplexity is 828.690784911471
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.618859579396802 and perplexity of 749.090331760517
finished 1 epochs...
Completing Train Step...
At time: 50.34399175643921 and batch: 50, loss is 6.768039035797119 and perplexity is 869.6049567255344
At time: 51.45478415489197 and batch: 100, loss is 6.777573356628418 and perplexity is 877.9357002627072
At time: 52.56865692138672 and batch: 150, loss is 6.743564081192017 and perplexity is 848.5797597938115
At time: 53.68441605567932 and batch: 200, loss is 6.772134733200073 and perplexity is 873.1738991535036
At time: 54.80194044113159 and batch: 250, loss is 6.786246213912964 and perplexity is 885.5830254410965
At time: 55.92005968093872 and batch: 300, loss is 6.787711448669434 and perplexity is 886.8815635689907
At time: 57.067771434783936 and batch: 350, loss is 6.776051864624024 and perplexity is 876.6009437825315
At time: 58.186973333358765 and batch: 400, loss is 6.782405118942261 and perplexity is 882.1879415300605
At time: 59.301698207855225 and batch: 450, loss is 6.726112413406372 and perplexity is 833.8991013176554
At time: 60.41691756248474 and batch: 500, loss is 6.727158155441284 and perplexity is 834.7716007859514
At time: 61.54068636894226 and batch: 550, loss is 6.726764698028564 and perplexity is 834.4432183181884
At time: 62.65708827972412 and batch: 600, loss is 6.7675700187683105 and perplexity is 869.1971928240755
At time: 63.77389645576477 and batch: 650, loss is 6.849440975189209 and perplexity is 943.3534012843542
At time: 64.89156246185303 and batch: 700, loss is 6.784777851104736 and perplexity is 884.2836224938902
At time: 66.00747036933899 and batch: 750, loss is 6.7422154426574705 and perplexity is 847.4361037927368
At time: 67.12434434890747 and batch: 800, loss is 6.76180284500122 and perplexity is 864.1988087040487
At time: 68.24344539642334 and batch: 850, loss is 6.7964552211761475 and perplexity is 894.6702558552681
At time: 69.36111116409302 and batch: 900, loss is 6.834245090484619 and perplexity is 929.1266793384285
At time: 70.48037075996399 and batch: 950, loss is 6.79551607131958 and perplexity is 893.8304208400012
At time: 71.59892344474792 and batch: 1000, loss is 6.8222259902954105 and perplexity is 918.0262548770153
At time: 72.71553897857666 and batch: 1050, loss is 6.740930671691895 and perplexity is 846.3480415964287
At time: 73.8346483707428 and batch: 1100, loss is 6.810855112075806 and perplexity is 907.6466147798379
At time: 74.95594143867493 and batch: 1150, loss is 6.7322988605499265 and perplexity is 839.0739645354923
At time: 76.07593989372253 and batch: 1200, loss is 6.81873966217041 and perplexity is 914.831286714928
At time: 77.19618606567383 and batch: 1250, loss is 6.776078100204468 and perplexity is 876.6239422187969
At time: 78.31386470794678 and batch: 1300, loss is 6.814393949508667 and perplexity is 910.8643187035366
At time: 79.4329354763031 and batch: 1350, loss is 6.79824541091919 and perplexity is 896.2733198369318
At time: 80.54889488220215 and batch: 1400, loss is 6.7894163417816165 and perplexity is 888.3948915026656
At time: 81.66499209403992 and batch: 1450, loss is 6.815663604736328 and perplexity is 912.0215368260327
At time: 82.7844500541687 and batch: 1500, loss is 6.7930969142913815 and perplexity is 891.6707180787383
At time: 83.90535640716553 and batch: 1550, loss is 6.782624645233154 and perplexity is 882.3816262353998
At time: 85.0256450176239 and batch: 1600, loss is 6.787218103408813 and perplexity is 886.4441326639762
At time: 86.14295721054077 and batch: 1650, loss is 6.778742532730103 and perplexity is 878.9627619932887
At time: 87.25974225997925 and batch: 1700, loss is 6.79410041809082 and perplexity is 892.5659621474632
At time: 88.38085913658142 and batch: 1750, loss is 6.8314409255981445 and perplexity is 926.5249045367983
At time: 89.5012276172638 and batch: 1800, loss is 6.83202564239502 and perplexity is 927.066817628608
At time: 90.62906050682068 and batch: 1850, loss is 6.786621971130371 and perplexity is 885.9158521816281
At time: 91.74793577194214 and batch: 1900, loss is 6.773529424667358 and perplexity is 874.3925569683959
At time: 92.87814688682556 and batch: 1950, loss is 6.7308468246459965 and perplexity is 837.8564831401953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.6274328897165695 and perplexity of 755.5401241622999
Annealing...
finished 2 epochs...
Completing Train Step...
At time: 96.53091239929199 and batch: 50, loss is 6.770713596343994 and perplexity is 871.9338808701908
At time: 97.68915867805481 and batch: 100, loss is 6.775765600204468 and perplexity is 876.3500400362988
At time: 98.81327295303345 and batch: 150, loss is 6.72779881477356 and perplexity is 835.3065763525601
At time: 99.93813276290894 and batch: 200, loss is 6.7546452617645265 and perplexity is 858.0353179601709
At time: 101.06065154075623 and batch: 250, loss is 6.755188102722168 and perplexity is 858.50122111808
At time: 102.18101501464844 and batch: 300, loss is 6.707872266769409 and perplexity is 818.8265401800074
At time: 103.29843854904175 and batch: 350, loss is 6.643576316833496 and perplexity is 767.8361137593333
At time: 104.41906476020813 and batch: 400, loss is 6.617846956253052 and perplexity is 748.3321694849357
At time: 105.5427680015564 and batch: 450, loss is 6.525969619750977 and perplexity is 682.6413553985255
At time: 106.66541075706482 and batch: 500, loss is 6.542483224868774 and perplexity is 694.0078175112365
At time: 107.78418946266174 and batch: 550, loss is 6.507309122085571 and perplexity is 670.021044829879
At time: 108.90550303459167 and batch: 600, loss is 6.539153308868408 and perplexity is 691.7006732055623
At time: 110.02488732337952 and batch: 650, loss is 6.631097230911255 and perplexity is 758.3137596333054
At time: 111.1471483707428 and batch: 700, loss is 6.520668287277221 and perplexity is 679.0320222039517
At time: 112.27702593803406 and batch: 750, loss is 6.464216461181641 and perplexity is 641.7613214878168
At time: 113.41979122161865 and batch: 800, loss is 6.4823835086822506 and perplexity is 653.5267781149671
At time: 114.53783369064331 and batch: 850, loss is 6.553594999313354 and perplexity is 701.7624800830515
At time: 115.65595936775208 and batch: 900, loss is 6.5591957473754885 and perplexity is 705.7039020862824
At time: 116.77415323257446 and batch: 950, loss is 6.591736974716187 and perplexity is 729.046105391688
At time: 117.88900589942932 and batch: 1000, loss is 6.578719024658203 and perplexity is 719.6169270489644
At time: 119.00985169410706 and batch: 1050, loss is 6.495976839065552 and perplexity is 662.471036931548
At time: 120.13123893737793 and batch: 1100, loss is 6.547048559188843 and perplexity is 697.1834385892681
At time: 121.25564575195312 and batch: 1150, loss is 6.460141763687134 and perplexity is 639.1516586431262
At time: 122.37927055358887 and batch: 1200, loss is 6.547490634918213 and perplexity is 697.4917146020381
At time: 123.50419425964355 and batch: 1250, loss is 6.46380184173584 and perplexity is 641.4952899191071
At time: 124.63182401657104 and batch: 1300, loss is 6.446725378036499 and perplexity is 630.6338205685506
At time: 125.75220847129822 and batch: 1350, loss is 6.382169704437256 and perplexity is 591.2090660052023
At time: 126.87129855155945 and batch: 1400, loss is 6.366415348052978 and perplexity is 581.9679328705889
At time: 127.98966431617737 and batch: 1450, loss is 6.360695133209228 and perplexity is 578.6484543788109
At time: 129.10785555839539 and batch: 1500, loss is 6.329410810470581 and perplexity is 560.8260636455583
At time: 130.227557182312 and batch: 1550, loss is 6.304059610366822 and perplexity is 546.7871533676235
At time: 131.34944868087769 and batch: 1600, loss is 6.268021068572998 and perplexity is 527.4325915074004
At time: 132.46938800811768 and batch: 1650, loss is 6.255439538955688 and perplexity is 520.8382531551327
At time: 133.5896487236023 and batch: 1700, loss is 6.2502281379699705 and perplexity is 518.1310165440952
At time: 134.71300673484802 and batch: 1750, loss is 6.235037517547608 and perplexity is 510.31976403518394
At time: 135.8413586616516 and batch: 1800, loss is 6.209379806518554 and perplexity is 497.3926759131602
At time: 136.95997786521912 and batch: 1850, loss is 6.1234739398956295 and perplexity is 456.4476150022791
At time: 138.08066487312317 and batch: 1900, loss is 6.063888778686524 and perplexity is 430.0445374058634
At time: 139.2011616230011 and batch: 1950, loss is 6.015910091400147 and perplexity is 409.8987145104673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.67228152252907 and perplexity of 290.69701015547975
finished 3 epochs...
Completing Train Step...
At time: 142.83939504623413 and batch: 50, loss is 6.079273414611817 and perplexity is 436.71177102297366
At time: 143.9874668121338 and batch: 100, loss is 6.095768537521362 and perplexity is 443.97512563637554
At time: 145.10395121574402 and batch: 150, loss is 6.033434534072876 and perplexity is 417.1452715167467
At time: 146.22236347198486 and batch: 200, loss is 6.0469198894500735 and perplexity is 422.80872475996676
At time: 147.34011888504028 and batch: 250, loss is 6.066208457946777 and perplexity is 431.0432607113014
At time: 148.46033716201782 and batch: 300, loss is 6.052821836471558 and perplexity is 425.3114978057671
At time: 149.58255410194397 and batch: 350, loss is 6.0412563228607175 and perplexity is 420.4208876127544
At time: 150.70287823677063 and batch: 400, loss is 6.026545190811158 and perplexity is 414.2812913502565
At time: 151.82267260551453 and batch: 450, loss is 5.955645132064819 and perplexity is 385.92580349549553
At time: 152.9431586265564 and batch: 500, loss is 5.9506822681427005 and perplexity is 384.01525107596035
At time: 154.06345772743225 and batch: 550, loss is 5.919389724731445 and perplexity is 372.18450955312477
At time: 155.18681454658508 and batch: 600, loss is 5.954434595108032 and perplexity is 385.4589087015037
At time: 156.32122325897217 and batch: 650, loss is 6.042063446044922 and perplexity is 420.76035603625905
At time: 157.4614725112915 and batch: 700, loss is 5.946831216812134 and perplexity is 382.5392325680516
At time: 158.6050066947937 and batch: 750, loss is 5.882931261062622 and perplexity is 358.85961271063854
At time: 159.74776649475098 and batch: 800, loss is 5.896940889358521 and perplexity is 363.9224841616159
At time: 160.88934421539307 and batch: 850, loss is 5.957712259292602 and perplexity is 386.72438633360633
At time: 162.03457474708557 and batch: 900, loss is 5.945391426086426 and perplexity is 381.98885243996057
At time: 163.17971754074097 and batch: 950, loss is 5.956254940032959 and perplexity is 386.16121589646184
At time: 164.32658100128174 and batch: 1000, loss is 5.938920402526856 and perplexity is 379.5249740815088
At time: 165.47585272789001 and batch: 1050, loss is 5.823243589401245 and perplexity is 338.0668271498033
At time: 166.6275932788849 and batch: 1100, loss is 5.882796792984009 and perplexity is 358.8113607922695
At time: 167.7809362411499 and batch: 1150, loss is 5.795455904006958 and perplexity is 328.802051989641
At time: 168.92838072776794 and batch: 1200, loss is 5.8699125385284425 and perplexity is 354.21799848552934
At time: 170.10031747817993 and batch: 1250, loss is 5.810596733093262 and perplexity is 333.8182666585013
At time: 171.25794577598572 and batch: 1300, loss is 5.826174030303955 and perplexity is 339.0589649986019
At time: 172.421404838562 and batch: 1350, loss is 5.806601295471191 and perplexity is 332.4871775095302
At time: 173.58041262626648 and batch: 1400, loss is 5.819515571594239 and perplexity is 336.80885432772556
At time: 174.72892594337463 and batch: 1450, loss is 5.795053014755249 and perplexity is 328.6696078589044
At time: 175.87528347969055 and batch: 1500, loss is 5.773024711608887 and perplexity is 321.508734608535
At time: 177.0239293575287 and batch: 1550, loss is 5.748835973739624 and perplexity is 313.8251468812286
At time: 178.17614555358887 and batch: 1600, loss is 5.72617733001709 and perplexity is 306.7942507826286
At time: 179.33345246315002 and batch: 1650, loss is 5.715622386932373 and perplexity is 303.57308444551387
At time: 180.48984718322754 and batch: 1700, loss is 5.7209062576293945 and perplexity is 305.1813706170582
At time: 181.63928937911987 and batch: 1750, loss is 5.728706674575806 and perplexity is 307.571221350402
At time: 182.7939431667328 and batch: 1800, loss is 5.725676679611206 and perplexity is 306.64069255915246
At time: 183.94389486312866 and batch: 1850, loss is 5.665353260040283 and perplexity is 288.6899457274006
At time: 185.0932309627533 and batch: 1900, loss is 5.640216178894043 and perplexity is 281.5235713517913
At time: 186.2425274848938 and batch: 1950, loss is 5.585447807312011 and perplexity is 266.5196054487948
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.288831985828488 and perplexity of 198.1118927207301
finished 4 epochs...
Completing Train Step...
At time: 189.94651341438293 and batch: 50, loss is 5.641082534790039 and perplexity is 281.7675766401418
At time: 191.1006121635437 and batch: 100, loss is 5.661473741531372 and perplexity is 287.5721374206019
At time: 192.23052382469177 and batch: 150, loss is 5.595945558547974 and perplexity is 269.3321990909051
At time: 193.36546683311462 and batch: 200, loss is 5.593680896759033 and perplexity is 268.72294289110096
At time: 194.49993801116943 and batch: 250, loss is 5.620547180175781 and perplexity is 276.04038574501936
At time: 195.63416743278503 and batch: 300, loss is 5.628413953781128 and perplexity is 278.2204969430143
At time: 196.7841260433197 and batch: 350, loss is 5.606431875228882 and perplexity is 272.1713619867353
At time: 197.97425961494446 and batch: 400, loss is 5.574567975997925 and perplexity is 263.6356341085565
At time: 199.13424515724182 and batch: 450, loss is 5.519762763977051 and perplexity is 249.57582179057272
At time: 200.29030394554138 and batch: 500, loss is 5.523272714614868 and perplexity is 250.45335976201088
At time: 201.45893621444702 and batch: 550, loss is 5.502324876785278 and perplexity is 245.2614726561711
At time: 202.61839962005615 and batch: 600, loss is 5.511819677352905 and perplexity is 247.6012718111805
At time: 203.7572009563446 and batch: 650, loss is 5.601670780181885 and perplexity is 270.8786081671633
At time: 204.9042477607727 and batch: 700, loss is 5.5311277389526365 and perplexity is 252.42842393163508
At time: 206.0495913028717 and batch: 750, loss is 5.468552122116089 and perplexity is 237.11662817955758
At time: 207.19097304344177 and batch: 800, loss is 5.48622878074646 and perplexity is 241.3453223540836
At time: 208.33362865447998 and batch: 850, loss is 5.519557056427002 and perplexity is 249.52448743983348
At time: 209.47419667243958 and batch: 900, loss is 5.5119001579284665 and perplexity is 247.62119970593903
At time: 210.61896634101868 and batch: 950, loss is 5.547650241851807 and perplexity is 256.6338194578702
At time: 211.76017951965332 and batch: 1000, loss is 5.517519178390503 and perplexity is 249.0165047465003
At time: 212.90642786026 and batch: 1050, loss is 5.4273422336578365 and perplexity is 227.54368311654576
At time: 214.05411434173584 and batch: 1100, loss is 5.493755245208741 and perplexity is 243.1686523528642
At time: 215.2059862613678 and batch: 1150, loss is 5.427133054733276 and perplexity is 227.49609075145435
At time: 216.3560392856598 and batch: 1200, loss is 5.497012119293213 and perplexity is 243.96191310887625
At time: 217.50619506835938 and batch: 1250, loss is 5.4373993396759035 and perplexity is 229.84366023226372
At time: 218.65726947784424 and batch: 1300, loss is 5.450504426956177 and perplexity is 232.87560501805245
At time: 219.81255722045898 and batch: 1350, loss is 5.411320686340332 and perplexity is 223.92712998004407
At time: 220.97993659973145 and batch: 1400, loss is 5.429672689437866 and perplexity is 228.07458198596632
At time: 222.14278888702393 and batch: 1450, loss is 5.4030078029632564 and perplexity is 222.07336560230058
At time: 223.30036306381226 and batch: 1500, loss is 5.383480615615845 and perplexity is 217.77896265054582
At time: 224.44989490509033 and batch: 1550, loss is 5.367369384765625 and perplexity is 214.2983889599655
At time: 225.59964990615845 and batch: 1600, loss is 5.373783254623413 and perplexity is 215.67728825072552
At time: 226.75183367729187 and batch: 1650, loss is 5.367351064682007 and perplexity is 214.2944630315223
At time: 227.91134476661682 and batch: 1700, loss is 5.386658210754394 and perplexity is 218.47207665818905
At time: 229.0763463973999 and batch: 1750, loss is 5.383227825164795 and perplexity is 217.72391716612773
At time: 230.23241472244263 and batch: 1800, loss is 5.377756671905518 and perplexity is 216.53596893381086
At time: 231.38769221305847 and batch: 1850, loss is 5.344094562530517 and perplexity is 209.36822891176894
At time: 232.54059720039368 and batch: 1900, loss is 5.353058967590332 and perplexity is 211.25352819029428
At time: 233.69604229927063 and batch: 1950, loss is 5.299220666885376 and perplexity is 200.18074168719173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.035558798146802 and perplexity of 153.78550366059017
finished 5 epochs...
Completing Train Step...
At time: 237.44994378089905 and batch: 50, loss is 5.341014566421509 and perplexity is 208.72436763547603
At time: 238.5818510055542 and batch: 100, loss is 5.338525114059448 and perplexity is 208.2054045004646
At time: 239.7201919555664 and batch: 150, loss is 5.284772663116455 and perplexity is 197.30932266258642
At time: 240.85114908218384 and batch: 200, loss is 5.274047899246216 and perplexity is 195.20453362480916
At time: 241.98572540283203 and batch: 250, loss is 5.309923305511474 and perplexity is 202.3347098359796
At time: 243.1213984489441 and batch: 300, loss is 5.3286354351043705 and perplexity is 206.15646825386708
At time: 244.26869702339172 and batch: 350, loss is 5.318155994415283 and perplexity is 204.00734424869546
At time: 245.41575002670288 and batch: 400, loss is 5.288934412002564 and perplexity is 198.13218560318379
At time: 246.55945944786072 and batch: 450, loss is 5.245191011428833 and perplexity is 189.6520374766375
At time: 247.6991651058197 and batch: 500, loss is 5.2558303070068355 and perplexity is 191.6805735227047
At time: 248.84163761138916 and batch: 550, loss is 5.232923574447632 and perplexity is 187.33970525196162
At time: 249.98344016075134 and batch: 600, loss is 5.227665395736694 and perplexity is 186.35722489441235
At time: 251.12500929832458 and batch: 650, loss is 5.305577001571655 and perplexity is 201.45721001128666
At time: 252.2658085823059 and batch: 700, loss is 5.287450494766236 and perplexity is 197.83839187459614
At time: 253.40724062919617 and batch: 750, loss is 5.228612241744995 and perplexity is 186.53376005153714
At time: 254.55616784095764 and batch: 800, loss is 5.239752912521363 and perplexity is 188.62349014465846
At time: 255.74917936325073 and batch: 850, loss is 5.262585506439209 and perplexity is 192.979797341575
At time: 256.89045810699463 and batch: 900, loss is 5.256988315582276 and perplexity is 191.90266984049057
At time: 258.03251600265503 and batch: 950, loss is 5.30440975189209 and perplexity is 201.2221963339579
At time: 259.17523670196533 and batch: 1000, loss is 5.276707448959351 and perplexity is 195.72438075944717
At time: 260.3178548812866 and batch: 1050, loss is 5.195314216613769 and perplexity is 180.42482636906493
At time: 261.461585521698 and batch: 1100, loss is 5.258280544281006 and perplexity is 192.15081227167678
At time: 262.6032335758209 and batch: 1150, loss is 5.19288031578064 and perplexity is 179.98622420744988
At time: 263.74792885780334 and batch: 1200, loss is 5.268193883895874 and perplexity is 194.0651415517203
At time: 264.8929784297943 and batch: 1250, loss is 5.2273363018035885 and perplexity is 186.2959059527085
At time: 266.04158329963684 and batch: 1300, loss is 5.2384332656860355 and perplexity is 188.37473792146227
At time: 267.20469665527344 and batch: 1350, loss is 5.179491968154907 and perplexity is 177.59256539281466
At time: 268.36344361305237 and batch: 1400, loss is 5.199991512298584 and perplexity is 181.2707032970166
At time: 269.5179181098938 and batch: 1450, loss is 5.168277053833008 and perplexity is 175.61200664463604
At time: 270.6752233505249 and batch: 1500, loss is 5.147559366226196 and perplexity is 172.01116134111436
At time: 271.8279287815094 and batch: 1550, loss is 5.143656015396118 and perplexity is 171.34105012212817
At time: 272.9775381088257 and batch: 1600, loss is 5.166866083145141 and perplexity is 175.36439797618866
At time: 274.12878227233887 and batch: 1650, loss is 5.15721734046936 and perplexity is 173.68048889240268
At time: 275.2789235115051 and batch: 1700, loss is 5.183357601165771 and perplexity is 178.28040168087708
At time: 276.4300618171692 and batch: 1750, loss is 5.170575895309448 and perplexity is 176.01617519098903
At time: 277.5825686454773 and batch: 1800, loss is 5.161845149993897 and perplexity is 174.4861118100212
At time: 278.74210381507874 and batch: 1850, loss is 5.141455926895142 and perplexity is 170.9644990227689
At time: 279.89188385009766 and batch: 1900, loss is 5.178959302902221 and perplexity is 177.49799319399278
At time: 281.04074931144714 and batch: 1950, loss is 5.118068466186523 and perplexity is 167.01246764492385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.883226403524709 and perplexity of 132.05604337769194
finished 6 epochs...
Completing Train Step...
At time: 284.764032125473 and batch: 50, loss is 5.159424877166748 and perplexity is 174.06431844829416
At time: 285.8868591785431 and batch: 100, loss is 5.148763628005981 and perplexity is 172.21843258778455
At time: 287.00888991355896 and batch: 150, loss is 5.096485910415649 and perplexity is 163.44653117757454
At time: 288.13322854042053 and batch: 200, loss is 5.082292737960816 and perplexity is 161.14309159913697
At time: 289.26760268211365 and batch: 250, loss is 5.116268558502197 and perplexity is 166.7121309912395
At time: 290.40942215919495 and batch: 300, loss is 5.142343950271607 and perplexity is 171.11638692446903
At time: 291.5538442134857 and batch: 350, loss is 5.14212399482727 and perplexity is 171.07875308258573
At time: 292.69809341430664 and batch: 400, loss is 5.1034938335418705 and perplexity is 164.59597480541677
At time: 293.84356665611267 and batch: 450, loss is 5.077711124420166 and perplexity is 160.40648494072425
At time: 294.9880166053772 and batch: 500, loss is 5.088403959274292 and perplexity is 162.13088794179893
At time: 296.13286447525024 and batch: 550, loss is 5.06675012588501 and perplexity is 158.65787048154075
At time: 297.27492117881775 and batch: 600, loss is 5.050156278610229 and perplexity is 156.0468493656774
At time: 298.4203531742096 and batch: 650, loss is 5.130728969573974 and perplexity is 169.14037129990112
At time: 299.5638988018036 and batch: 700, loss is 5.130680713653565 and perplexity is 169.13220947253544
At time: 300.7077851295471 and batch: 750, loss is 5.070550451278686 and perplexity is 159.2619691743833
At time: 301.85059332847595 and batch: 800, loss is 5.083510236740112 and perplexity is 161.33940259640138
At time: 302.99330258369446 and batch: 850, loss is 5.104678983688355 and perplexity is 164.79116138892584
At time: 304.14262080192566 and batch: 900, loss is 5.089803390502929 and perplexity is 162.35793780278976
At time: 305.28741788864136 and batch: 950, loss is 5.144750986099243 and perplexity is 171.5287663053598
At time: 306.43716621398926 and batch: 1000, loss is 5.112068338394165 and perplexity is 166.01337184478928
At time: 307.57986330986023 and batch: 1050, loss is 5.041415395736695 and perplexity is 154.6888060280053
At time: 308.72329211235046 and batch: 1100, loss is 5.099905757904053 and perplexity is 164.00645025993992
At time: 309.86799573898315 and batch: 1150, loss is 5.043515958786011 and perplexity is 155.01408112891679
At time: 311.0137197971344 and batch: 1200, loss is 5.1157966995239255 and perplexity is 166.6334849318283
At time: 312.1579830646515 and batch: 1250, loss is 5.087762804031372 and perplexity is 162.0269701902213
At time: 313.30233216285706 and batch: 1300, loss is 5.095250215530395 and perplexity is 163.24468587027673
At time: 314.44712138175964 and batch: 1350, loss is 5.022620611190796 and perplexity is 151.80861432201542
At time: 315.5918781757355 and batch: 1400, loss is 5.0421435737609865 and perplexity is 154.80148803846166
At time: 316.7390570640564 and batch: 1450, loss is 5.006942777633667 and perplexity is 149.44714387395294
At time: 317.885938167572 and batch: 1500, loss is 4.988139533996582 and perplexity is 146.6633074154872
At time: 319.0327069759369 and batch: 1550, loss is 4.991684656143189 and perplexity is 147.18416946898967
At time: 320.1794843673706 and batch: 1600, loss is 5.02475640296936 and perplexity is 152.1331924046167
At time: 321.3262174129486 and batch: 1650, loss is 5.0087230682373045 and perplexity is 149.71344019201453
At time: 322.4736135005951 and batch: 1700, loss is 5.036507530212402 and perplexity is 153.9314741316218
At time: 323.62157464027405 and batch: 1750, loss is 5.021189165115357 and perplexity is 151.59146393344122
At time: 324.7740774154663 and batch: 1800, loss is 5.008601512908935 and perplexity is 149.69524283164617
At time: 325.92319440841675 and batch: 1850, loss is 4.9991617774963375 and perplexity is 148.28880797701402
At time: 327.07051610946655 and batch: 1900, loss is 5.05734803199768 and perplexity is 157.1731449889324
At time: 328.21609473228455 and batch: 1950, loss is 4.995513687133789 and perplexity is 147.74882256242174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.786270212572674 and perplexity of 119.85350586659587
finished 7 epochs...
Completing Train Step...
At time: 331.9131636619568 and batch: 50, loss is 5.033175497055054 and perplexity is 153.41942291542264
At time: 333.0393280982971 and batch: 100, loss is 5.01328064918518 and perplexity is 150.39732856920938
At time: 334.1655983924866 and batch: 150, loss is 4.963524580001831 and perplexity is 143.09726587730177
At time: 335.29158544540405 and batch: 200, loss is 4.950540828704834 and perplexity is 141.25133604462613
At time: 336.41917395591736 and batch: 250, loss is 4.982310619354248 and perplexity is 145.81090621576502
At time: 337.546124458313 and batch: 300, loss is 5.010414485931396 and perplexity is 149.9668824317204
At time: 338.67313742637634 and batch: 350, loss is 5.014744081497192 and perplexity is 150.6175860060937
At time: 339.8056151866913 and batch: 400, loss is 4.971876430511474 and perplexity is 144.29739753424514
At time: 340.95726919174194 and batch: 450, loss is 4.955763931274414 and perplexity is 141.99103634451208
At time: 342.09642148017883 and batch: 500, loss is 4.966171827316284 and perplexity is 143.47658157982065
At time: 343.24326491355896 and batch: 550, loss is 4.944694938659668 and perplexity is 140.42800516102204
At time: 344.3956518173218 and batch: 600, loss is 4.922767114639282 and perplexity is 137.38224011642373
At time: 345.54691100120544 and batch: 650, loss is 5.002585439682007 and perplexity is 148.79736883497586
At time: 346.7030327320099 and batch: 700, loss is 5.0147254943847654 and perplexity is 150.61478648610668
At time: 347.85430908203125 and batch: 750, loss is 4.953941917419433 and perplexity is 141.7325622522034
At time: 349.0016255378723 and batch: 800, loss is 4.968001461029052 and perplexity is 143.73933146519843
At time: 350.1485757827759 and batch: 850, loss is 4.988895168304444 and perplexity is 146.774173123966
At time: 351.296507358551 and batch: 900, loss is 4.964771814346314 and perplexity is 143.27585304878164
At time: 352.4438478946686 and batch: 950, loss is 5.024598379135131 and perplexity is 152.10915363363887
At time: 353.592093706131 and batch: 1000, loss is 4.990729293823242 and perplexity is 147.04362240676002
At time: 354.738609790802 and batch: 1050, loss is 4.925296306610107 and perplexity is 137.73014594992316
At time: 355.8846290111542 and batch: 1100, loss is 4.979614000320435 and perplexity is 145.41823942504496
At time: 357.03157114982605 and batch: 1150, loss is 4.933199043273926 and perplexity is 138.82290322333859
At time: 358.17699360847473 and batch: 1200, loss is 5.001162099838257 and perplexity is 148.58573026380304
At time: 359.3277807235718 and batch: 1250, loss is 4.984654016494751 and perplexity is 146.15299975039983
At time: 360.4765818119049 and batch: 1300, loss is 4.985326948165894 and perplexity is 146.2513838319339
At time: 361.6235089302063 and batch: 1350, loss is 4.899227285385132 and perplexity is 134.18605209062082
At time: 362.7706527709961 and batch: 1400, loss is 4.920968265533447 and perplexity is 137.1353323381306
At time: 363.9198501110077 and batch: 1450, loss is 4.882017707824707 and perplexity is 131.8965242303764
At time: 365.0693600177765 and batch: 1500, loss is 4.868380613327027 and perplexity is 130.1100477258715
At time: 366.21630811691284 and batch: 1550, loss is 4.8724187469482425 and perplexity is 130.63651173465888
At time: 367.3641085624695 and batch: 1600, loss is 4.91580207824707 and perplexity is 136.42869241643638
At time: 368.5171582698822 and batch: 1650, loss is 4.895036020278931 and perplexity is 133.62481973114012
At time: 369.66566944122314 and batch: 1700, loss is 4.921059865951538 and perplexity is 137.1478945672517
At time: 370.81412529945374 and batch: 1750, loss is 4.908311767578125 and perplexity is 135.41061673754163
At time: 371.97337079048157 and batch: 1800, loss is 4.891345901489258 and perplexity is 133.13263693807323
At time: 373.1324746608734 and batch: 1850, loss is 4.887285423278809 and perplexity is 132.59315079378396
At time: 374.2848000526428 and batch: 1900, loss is 4.960219287872315 and perplexity is 142.62506841581336
At time: 375.4329662322998 and batch: 1950, loss is 4.898144006729126 and perplexity is 134.0407699092077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.720741733284884 and perplexity of 112.25148245765702
finished 8 epochs...
Completing Train Step...
At time: 379.11924600601196 and batch: 50, loss is 4.933016376495361 and perplexity is 138.79754720673725
At time: 380.26512002944946 and batch: 100, loss is 4.908228578567505 and perplexity is 135.39935253084343
At time: 381.383261680603 and batch: 150, loss is 4.857319278717041 and perplexity is 128.6787873699447
At time: 382.5011742115021 and batch: 200, loss is 4.846837644577026 and perplexity is 127.33706739205977
At time: 383.62206959724426 and batch: 250, loss is 4.875859718322754 and perplexity is 131.08680250653455
At time: 384.74060678482056 and batch: 300, loss is 4.907136144638062 and perplexity is 135.25151844830017
At time: 385.8697907924652 and batch: 350, loss is 4.911248655319214 and perplexity is 135.8088870692117
At time: 386.9919083118439 and batch: 400, loss is 4.865040769577027 and perplexity is 129.67622534889716
At time: 388.12743854522705 and batch: 450, loss is 4.857196435928345 and perplexity is 128.66298107972244
At time: 389.2645733356476 and batch: 500, loss is 4.8675925922393795 and perplexity is 130.00755865162822
At time: 390.4009096622467 and batch: 550, loss is 4.846973657608032 and perplexity is 127.35438807044746
At time: 391.54063296318054 and batch: 600, loss is 4.821707134246826 and perplexity is 124.17689657072579
At time: 392.6865713596344 and batch: 650, loss is 4.900671844482422 and perplexity is 134.38003184677612
At time: 393.83178782463074 and batch: 700, loss is 4.9203596019744875 and perplexity is 137.05188845589188
At time: 394.9788761138916 and batch: 750, loss is 4.861025753021241 and perplexity is 129.1566169733672
At time: 396.12529015541077 and batch: 800, loss is 4.875375747680664 and perplexity is 131.02337569215197
At time: 397.2695870399475 and batch: 850, loss is 4.894743461608886 and perplexity is 133.58573234954963
At time: 398.45504355430603 and batch: 900, loss is 4.864486837387085 and perplexity is 129.6044134047163
At time: 399.6032381057739 and batch: 950, loss is 4.926365585327148 and perplexity is 137.8774966291154
At time: 400.75256752967834 and batch: 1000, loss is 4.89429799079895 and perplexity is 133.52623705785575
At time: 401.899995803833 and batch: 1050, loss is 4.830521688461304 and perplexity is 125.2762988097665
At time: 403.0473964214325 and batch: 1100, loss is 4.883356027603149 and perplexity is 132.07316213009446
At time: 404.19446539878845 and batch: 1150, loss is 4.8439556503295895 and perplexity is 126.9706110125847
At time: 405.34184980392456 and batch: 1200, loss is 4.909412670135498 and perplexity is 135.55977271984003
At time: 406.48887825012207 and batch: 1250, loss is 4.8998676300048825 and perplexity is 134.27200492390273
At time: 407.63614225387573 and batch: 1300, loss is 4.893982400894165 and perplexity is 133.48410417412242
At time: 408.78210186958313 and batch: 1350, loss is 4.800184841156006 and perplexity is 121.53287972068155
At time: 409.92741441726685 and batch: 1400, loss is 4.822675304412842 and perplexity is 124.29717915490313
At time: 411.0746810436249 and batch: 1450, loss is 4.780222959518433 and perplexity is 119.13090845395814
At time: 412.22211241722107 and batch: 1500, loss is 4.771470146179199 and perplexity is 118.0927279773488
At time: 413.3694689273834 and batch: 1550, loss is 4.7767337036132815 and perplexity is 118.71595458926247
At time: 414.51524543762207 and batch: 1600, loss is 4.825493650436401 and perplexity is 124.64798573046579
At time: 415.66168308258057 and batch: 1650, loss is 4.802794532775879 and perplexity is 121.85045726792127
At time: 416.80891513824463 and batch: 1700, loss is 4.827883243560791 and perplexity is 124.94619986345315
At time: 417.96285128593445 and batch: 1750, loss is 4.815265274047851 and perplexity is 123.37953735873072
At time: 419.1157639026642 and batch: 1800, loss is 4.795429821014404 and perplexity is 120.95636019698533
At time: 420.26348400115967 and batch: 1850, loss is 4.798510131835937 and perplexity is 121.3295178078938
At time: 421.4133529663086 and batch: 1900, loss is 4.877927827835083 and perplexity is 131.35818489726398
At time: 422.5608940124512 and batch: 1950, loss is 4.814949111938477 and perplexity is 123.34053558971138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.675688135901162 and perplexity of 107.30638306603238
finished 9 epochs...
Completing Train Step...
At time: 426.2362389564514 and batch: 50, loss is 4.848414707183838 and perplexity is 127.53804435447636
At time: 427.37978315353394 and batch: 100, loss is 4.822256231307984 and perplexity is 124.24510046326127
At time: 428.5022304058075 and batch: 150, loss is 4.768799791336059 and perplexity is 117.77779916223926
At time: 429.62396264076233 and batch: 200, loss is 4.759966402053833 and perplexity is 116.74200354154831
At time: 430.7445456981659 and batch: 250, loss is 4.786207237243652 and perplexity is 119.84595829028756
At time: 431.8764214515686 and batch: 300, loss is 4.818634786605835 and perplexity is 123.79596744846882
At time: 433.02475476264954 and batch: 350, loss is 4.823311061859131 and perplexity is 124.37622713711268
At time: 434.162517786026 and batch: 400, loss is 4.774221324920655 and perplexity is 118.41806951122769
At time: 435.300580739975 and batch: 450, loss is 4.773477725982666 and perplexity is 118.33004669139405
At time: 436.4380884170532 and batch: 500, loss is 4.784531717300415 and perplexity is 119.64532212893889
At time: 437.5771813392639 and batch: 550, loss is 4.764253253936768 and perplexity is 117.24353344339482
At time: 438.7158920764923 and batch: 600, loss is 4.736994829177856 and perplexity is 114.09082356957569
At time: 439.86231231689453 and batch: 650, loss is 4.81450737953186 and perplexity is 123.28606410988664
At time: 441.0091202259064 and batch: 700, loss is 4.839139680862427 and perplexity is 126.36059451616924
At time: 442.1564266681671 and batch: 750, loss is 4.781212959289551 and perplexity is 119.24890642540552
At time: 443.30804920196533 and batch: 800, loss is 4.794491395950318 and perplexity is 120.84290495986097
At time: 444.45432686805725 and batch: 850, loss is 4.813532047271728 and perplexity is 123.16587785462907
At time: 445.60061264038086 and batch: 900, loss is 4.779825458526611 and perplexity is 119.08356321020514
At time: 446.74682116508484 and batch: 950, loss is 4.842760000228882 and perplexity is 126.81888930985002
At time: 447.8943221569061 and batch: 1000, loss is 4.8122412109375 and perplexity is 123.00699343331102
At time: 449.04181694984436 and batch: 1050, loss is 4.750152378082276 and perplexity is 115.60189838075364
At time: 450.1970102787018 and batch: 1100, loss is 4.80155270576477 and perplexity is 121.69923399477655
At time: 451.3436040878296 and batch: 1150, loss is 4.76634859085083 and perplexity is 117.4894557019716
At time: 452.4908437728882 and batch: 1200, loss is 4.829343461990357 and perplexity is 125.12878187956804
At time: 453.63899278640747 and batch: 1250, loss is 4.824692335128784 and perplexity is 124.54814339937288
At time: 454.7863538265228 and batch: 1300, loss is 4.813410911560059 and perplexity is 123.15095897198474
At time: 455.93330240249634 and batch: 1350, loss is 4.7171783542633055 and perplexity is 111.85219970032355
At time: 457.07971262931824 and batch: 1400, loss is 4.739325580596923 and perplexity is 114.35705105303423
At time: 458.2257282733917 and batch: 1450, loss is 4.69365478515625 and perplexity is 109.25174268037398
At time: 459.37604904174805 and batch: 1500, loss is 4.688564558029174 and perplexity is 108.69703947646529
At time: 460.5275514125824 and batch: 1550, loss is 4.6973007297515865 and perplexity is 109.65079550132077
At time: 461.67570066452026 and batch: 1600, loss is 4.748454895019531 and perplexity is 115.405832572505
At time: 462.82294034957886 and batch: 1650, loss is 4.7255337524414065 and perplexity is 112.79068461364457
At time: 463.9687876701355 and batch: 1700, loss is 4.748501787185669 and perplexity is 115.41124432886275
At time: 465.1158926486969 and batch: 1750, loss is 4.734716358184815 and perplexity is 113.83116685997315
At time: 466.2617402076721 and batch: 1800, loss is 4.714241447448731 and perplexity is 111.5241821270957
At time: 467.4076051712036 and batch: 1850, loss is 4.723366441726685 and perplexity is 112.54649686530628
At time: 468.5544168949127 and batch: 1900, loss is 4.807548170089722 and perplexity is 122.4310690639047
At time: 469.70176887512207 and batch: 1950, loss is 4.74181037902832 and perplexity is 114.64155859967833
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.640357296965843 and perplexity of 103.58135027458374
finished 10 epochs...
Completing Train Step...
At time: 473.3529222011566 and batch: 50, loss is 4.773890895843506 and perplexity is 118.3789472017316
At time: 474.49915885925293 and batch: 100, loss is 4.747882328033447 and perplexity is 115.33977391608006
At time: 475.6187233924866 and batch: 150, loss is 4.693377876281739 and perplexity is 109.22149409151461
At time: 476.7477128505707 and batch: 200, loss is 4.685322046279907 and perplexity is 108.34515884569468
At time: 477.8824505805969 and batch: 250, loss is 4.707959098815918 and perplexity is 110.82574454533153
At time: 479.02090096473694 and batch: 300, loss is 4.74034104347229 and perplexity is 114.47323537336318
At time: 480.16601943969727 and batch: 350, loss is 4.7455149841308595 and perplexity is 115.06704795101943
At time: 481.3140947818756 and batch: 400, loss is 4.695845966339111 and perplexity is 109.49139550862729
At time: 482.4603145122528 and batch: 450, loss is 4.700668687820435 and perplexity is 110.02071737378972
At time: 483.6046118736267 and batch: 500, loss is 4.712903985977173 and perplexity is 111.37512253330534
At time: 484.77319073677063 and batch: 550, loss is 4.691175479888916 and perplexity is 108.98120976470194
At time: 485.9194538593292 and batch: 600, loss is 4.664751901626587 and perplexity is 106.13924898009358
At time: 487.06232714653015 and batch: 650, loss is 4.741118869781494 and perplexity is 114.5623103054582
At time: 488.2067701816559 and batch: 700, loss is 4.7677396965026855 and perplexity is 117.65300968188946
At time: 489.35158824920654 and batch: 750, loss is 4.711678972244263 and perplexity is 111.23877001260428
At time: 490.49718976020813 and batch: 800, loss is 4.722372303009033 and perplexity is 112.434665632326
At time: 491.641916513443 and batch: 850, loss is 4.742508478164673 and perplexity is 114.72161771407491
At time: 492.78690910339355 and batch: 900, loss is 4.70531512260437 and perplexity is 110.5331109417438
At time: 493.92943716049194 and batch: 950, loss is 4.770498180389405 and perplexity is 117.97800164979607
At time: 495.0718126296997 and batch: 1000, loss is 4.741874322891236 and perplexity is 114.64888945816509
At time: 496.2160210609436 and batch: 1050, loss is 4.681433534622192 and perplexity is 107.92467548950961
At time: 497.36125922203064 and batch: 1100, loss is 4.728802042007446 and perplexity is 113.15992028719096
At time: 498.505473613739 and batch: 1150, loss is 4.696739187240601 and perplexity is 109.58923920314004
At time: 499.6497116088867 and batch: 1200, loss is 4.75973334312439 and perplexity is 116.71479894544203
At time: 500.793461561203 and batch: 1250, loss is 4.756994180679321 and perplexity is 116.39553560807846
At time: 501.94257974624634 and batch: 1300, loss is 4.74385214805603 and perplexity is 114.87586930608724
At time: 503.1055340766907 and batch: 1350, loss is 4.643968486785889 and perplexity is 103.9560783921977
At time: 504.26558351516724 and batch: 1400, loss is 4.667741861343384 and perplexity is 106.45707596708182
At time: 505.4170415401459 and batch: 1450, loss is 4.618408184051514 and perplexity is 101.33260082907228
At time: 506.57176661491394 and batch: 1500, loss is 4.616516981124878 and perplexity is 101.1411414191841
At time: 507.7245502471924 and batch: 1550, loss is 4.627951555252075 and perplexity is 102.30428464845157
At time: 508.87858724594116 and batch: 1600, loss is 4.68113805770874 and perplexity is 107.89279095031523
At time: 510.0322997570038 and batch: 1650, loss is 4.657171449661255 and perplexity is 105.33770736368626
At time: 511.18619680404663 and batch: 1700, loss is 4.679947814941406 and perplexity is 107.7644487305902
At time: 512.3394637107849 and batch: 1750, loss is 4.663747129440307 and perplexity is 106.03265677425532
At time: 513.4931397438049 and batch: 1800, loss is 4.642732381820679 and perplexity is 103.82765715494963
At time: 514.6465528011322 and batch: 1850, loss is 4.65739239692688 and perplexity is 105.36098401345681
At time: 515.799732208252 and batch: 1900, loss is 4.7467366886138915 and perplexity is 115.20771178667397
At time: 516.9532406330109 and batch: 1950, loss is 4.677419672012329 and perplexity is 107.4923489000846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607113292605378 and perplexity of 100.19449956722968
finished 11 epochs...
Completing Train Step...
At time: 520.6719214916229 and batch: 50, loss is 4.706589193344116 and perplexity is 110.67402769406122
At time: 521.7942488193512 and batch: 100, loss is 4.682415437698364 and perplexity is 108.03069910430602
At time: 522.916339635849 and batch: 150, loss is 4.627221174240113 and perplexity is 102.22959082229862
At time: 524.038323879242 and batch: 200, loss is 4.619131698608398 and perplexity is 101.40594296971283
At time: 525.1591396331787 and batch: 250, loss is 4.638671941757202 and perplexity is 103.40692593115489
At time: 526.2837233543396 and batch: 300, loss is 4.670648384094238 and perplexity is 106.76694598435186
At time: 527.421792268753 and batch: 350, loss is 4.676422109603882 and perplexity is 107.38517204031731
At time: 528.5597548484802 and batch: 400, loss is 4.626325159072876 and perplexity is 102.13803258329246
At time: 529.6998555660248 and batch: 450, loss is 4.635939407348633 and perplexity is 103.12474865310315
At time: 530.8386828899384 and batch: 500, loss is 4.648288030624389 and perplexity is 104.40609245812034
At time: 531.9775171279907 and batch: 550, loss is 4.626435899734497 and perplexity is 102.14934404290513
At time: 533.1164453029633 and batch: 600, loss is 4.6007900810241695 and perplexity is 99.56294737055299
At time: 534.2542607784271 and batch: 650, loss is 4.675762109756469 and perplexity is 107.31432122649137
At time: 535.3910038471222 and batch: 700, loss is 4.704177360534668 and perplexity is 110.40742207623877
At time: 536.5439269542694 and batch: 750, loss is 4.649918012619018 and perplexity is 104.57641127955361
At time: 537.6885061264038 and batch: 800, loss is 4.657893772125244 and perplexity is 105.41382264259867
At time: 538.8342621326447 and batch: 850, loss is 4.679167346954346 and perplexity is 107.68037484097012
At time: 539.9796590805054 and batch: 900, loss is 4.638393535614013 and perplexity is 103.37814081488987
At time: 541.1472172737122 and batch: 950, loss is 4.706031494140625 and perplexity is 110.6123220851529
At time: 542.2912273406982 and batch: 1000, loss is 4.679755735397339 and perplexity is 107.74375137224455
At time: 543.4363534450531 and batch: 1050, loss is 4.620621948242188 and perplexity is 101.55717579843264
At time: 544.5893759727478 and batch: 1100, loss is 4.664320974349976 and perplexity is 106.09352053611363
At time: 545.7381176948547 and batch: 1150, loss is 4.634323320388794 and perplexity is 102.95822468641683
At time: 546.884283542633 and batch: 1200, loss is 4.698928279876709 and perplexity is 109.82940297413968
At time: 548.0294179916382 and batch: 1250, loss is 4.696702842712402 and perplexity is 109.58525630632425
At time: 549.1845862865448 and batch: 1300, loss is 4.681457452774048 and perplexity is 107.92725687915784
At time: 550.3313038349152 and batch: 1350, loss is 4.579053239822388 and perplexity is 97.42211515183503
At time: 551.4796049594879 and batch: 1400, loss is 4.604072561264038 and perplexity is 99.89029774456255
At time: 552.6265761852264 and batch: 1450, loss is 4.5522060966491695 and perplexity is 94.8414070047011
At time: 553.7740416526794 and batch: 1500, loss is 4.553220224380493 and perplexity is 94.93763709217511
At time: 554.9210212230682 and batch: 1550, loss is 4.565730361938477 and perplexity is 96.13278010641405
At time: 556.0693085193634 and batch: 1600, loss is 4.6214228439331055 and perplexity is 101.63854508271653
At time: 557.2158722877502 and batch: 1650, loss is 4.596505174636841 and perplexity is 99.1372421662419
At time: 558.3624260425568 and batch: 1700, loss is 4.618885936737061 and perplexity is 101.3810243175566
At time: 559.5099186897278 and batch: 1750, loss is 4.6003564453125 and perplexity is 99.519782680566
At time: 560.6578533649445 and batch: 1800, loss is 4.578615789413452 and perplexity is 97.3795071278507
At time: 561.8055608272552 and batch: 1850, loss is 4.598247556686402 and perplexity is 99.31012769001345
At time: 562.95299243927 and batch: 1900, loss is 4.691762266159057 and perplexity is 109.04517720806862
At time: 564.1082334518433 and batch: 1950, loss is 4.619759111404419 and perplexity is 101.46958631916277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.578702704851017 and perplexity of 97.38797127814996
finished 12 epochs...
Completing Train Step...
At time: 567.8000214099884 and batch: 50, loss is 4.645636396408081 and perplexity is 104.1296124149367
At time: 568.925858259201 and batch: 100, loss is 4.622484321594238 and perplexity is 101.74648940794144
At time: 570.072904586792 and batch: 150, loss is 4.568529376983642 and perplexity is 96.40223413128084
At time: 571.2104029655457 and batch: 200, loss is 4.560453567504883 and perplexity is 95.6268432238906
At time: 572.347558259964 and batch: 250, loss is 4.57693528175354 and perplexity is 97.21599754823512
At time: 573.4828922748566 and batch: 300, loss is 4.609428796768189 and perplexity is 100.42676915488961
At time: 574.619964838028 and batch: 350, loss is 4.615740909576416 and perplexity is 101.06267910707176
At time: 575.757798910141 and batch: 400, loss is 4.564735364913941 and perplexity is 96.03717584711204
At time: 576.8956184387207 and batch: 450, loss is 4.578098993301392 and perplexity is 97.32919477890566
At time: 578.042813539505 and batch: 500, loss is 4.5901587772369385 and perplexity is 98.51007007701968
At time: 579.188010931015 and batch: 550, loss is 4.568517742156982 and perplexity is 96.40111251452197
At time: 580.3358809947968 and batch: 600, loss is 4.544206533432007 and perplexity is 94.08574369174376
At time: 581.4921758174896 and batch: 650, loss is 4.616576194763184 and perplexity is 101.14713053146671
At time: 582.6390037536621 and batch: 700, loss is 4.646753301620484 and perplexity is 104.24598029565747
At time: 583.7863476276398 and batch: 750, loss is 4.594056472778321 and perplexity is 98.8947815950788
At time: 584.9359064102173 and batch: 800, loss is 4.600023555755615 and perplexity is 99.48665909776143
At time: 586.0896053314209 and batch: 850, loss is 4.622537527084351 and perplexity is 101.75190302379336
At time: 587.236599445343 and batch: 900, loss is 4.578635330200195 and perplexity is 97.38141001862459
At time: 588.3841705322266 and batch: 950, loss is 4.64760027885437 and perplexity is 104.33431166974302
At time: 589.5307903289795 and batch: 1000, loss is 4.62461802482605 and perplexity is 101.96381799611963
At time: 590.6802802085876 and batch: 1050, loss is 4.566506118774414 and perplexity is 96.20738470151012
At time: 591.8334350585938 and batch: 1100, loss is 4.606655864715576 and perplexity is 100.14867828948707
At time: 592.9874141216278 and batch: 1150, loss is 4.578624887466431 and perplexity is 97.38039309579587
At time: 594.1419265270233 and batch: 1200, loss is 4.644754629135132 and perplexity is 104.03783479975961
At time: 595.2972400188446 and batch: 1250, loss is 4.6430493927001955 and perplexity is 103.86057686954064
At time: 596.4527242183685 and batch: 1300, loss is 4.624961347579956 and perplexity is 101.9988305048644
At time: 597.6085357666016 and batch: 1350, loss is 4.521683349609375 and perplexity is 91.99031958488234
At time: 598.764301776886 and batch: 1400, loss is 4.546567649841308 and perplexity is 94.30815354951254
At time: 599.9199228286743 and batch: 1450, loss is 4.493660049438477 and perplexity is 89.44823243928532
At time: 601.0749268531799 and batch: 1500, loss is 4.496598253250122 and perplexity is 89.71143606037074
At time: 602.229917049408 and batch: 1550, loss is 4.510151691436768 and perplexity is 90.93561161793465
At time: 603.3848011493683 and batch: 1600, loss is 4.567608108520508 and perplexity is 96.31346269064296
At time: 604.5398983955383 and batch: 1650, loss is 4.5428221321105955 and perplexity is 93.95558138307571
At time: 605.6937127113342 and batch: 1700, loss is 4.563914194107055 and perplexity is 95.9583452930353
At time: 606.8478643894196 and batch: 1750, loss is 4.544265031814575 and perplexity is 94.09124771655915
At time: 607.9999115467072 and batch: 1800, loss is 4.5213158988952635 and perplexity is 91.95652388576671
At time: 609.1529598236084 and batch: 1850, loss is 4.545428314208984 and perplexity is 94.20076609654721
At time: 610.3068673610687 and batch: 1900, loss is 4.641034021377563 and perplexity is 103.65147002611133
At time: 611.464718580246 and batch: 1950, loss is 4.567480888366699 and perplexity is 96.30121045648767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.558265011809593 and perplexity of 95.4177874001314
finished 13 epochs...
Completing Train Step...
At time: 615.1277389526367 and batch: 50, loss is 4.590404996871948 and perplexity is 98.53432817680648
At time: 616.246431350708 and batch: 100, loss is 4.56807050704956 and perplexity is 96.35800819221254
At time: 617.3668394088745 and batch: 150, loss is 4.515504236221314 and perplexity is 91.42365351950842
At time: 618.4888305664062 and batch: 200, loss is 4.508699436187744 and perplexity is 90.80364574589797
At time: 619.6129472255707 and batch: 250, loss is 4.521718254089356 and perplexity is 91.99353051518834
At time: 620.7542321681976 and batch: 300, loss is 4.5549447727203365 and perplexity is 95.10150289324633
At time: 621.9054515361786 and batch: 350, loss is 4.560833263397217 and perplexity is 95.66315923754385
At time: 623.0507519245148 and batch: 400, loss is 4.509377479553223 and perplexity is 90.86523543333713
At time: 624.1995708942413 and batch: 450, loss is 4.525663433074951 and perplexity is 92.35717831475174
At time: 625.3467783927917 and batch: 500, loss is 4.537991704940796 and perplexity is 93.50283016124784
At time: 626.4953894615173 and batch: 550, loss is 4.517180023193359 and perplexity is 91.57698852953556
At time: 627.6652705669403 and batch: 600, loss is 4.493194799423218 and perplexity is 89.40662632715075
At time: 628.8234541416168 and batch: 650, loss is 4.5631467628479 and perplexity is 95.88473210942259
At time: 629.9719519615173 and batch: 700, loss is 4.595046663284302 and perplexity is 98.99275476695263
At time: 631.1201279163361 and batch: 750, loss is 4.543413667678833 and perplexity is 94.01117589274209
At time: 632.2667388916016 and batch: 800, loss is 4.5475306224823 and perplexity is 94.39901346198673
At time: 633.4144690036774 and batch: 850, loss is 4.571503915786743 and perplexity is 96.68941321833505
At time: 634.5609776973724 and batch: 900, loss is 4.524774007797241 and perplexity is 92.27507002578733
At time: 635.7063915729523 and batch: 950, loss is 4.5948219490051265 and perplexity is 98.97051218062855
At time: 636.8518207073212 and batch: 1000, loss is 4.574936361312866 and perplexity is 97.02186459637939
At time: 637.9998877048492 and batch: 1050, loss is 4.517283964157104 and perplexity is 91.5865076246836
At time: 639.1432867050171 and batch: 1100, loss is 4.555362710952759 and perplexity is 95.1412577542257
At time: 640.2867617607117 and batch: 1150, loss is 4.528747520446777 and perplexity is 92.64245560601539
At time: 641.4338953495026 and batch: 1200, loss is 4.595482320785522 and perplexity is 99.0358910987843
At time: 642.5781283378601 and batch: 1250, loss is 4.594538326263428 and perplexity is 98.94244587292627
At time: 643.7274830341339 and batch: 1300, loss is 4.5733559131622314 and perplexity is 96.86864767749728
At time: 644.8823733329773 and batch: 1350, loss is 4.4698075008392335 and perplexity is 87.33990853601193
At time: 646.0359230041504 and batch: 1400, loss is 4.494503221511841 and perplexity is 89.52368449595329
At time: 647.1884412765503 and batch: 1450, loss is 4.441773128509522 and perplexity is 84.92539188416374
At time: 648.3407454490662 and batch: 1500, loss is 4.4452213954925535 and perplexity is 85.21874279447304
At time: 649.492354631424 and batch: 1550, loss is 4.459836053848266 and perplexity is 86.47333096429688
At time: 650.6449158191681 and batch: 1600, loss is 4.519552602767944 and perplexity is 91.79452017554993
At time: 651.7989013195038 and batch: 1650, loss is 4.494205417633057 and perplexity is 89.49702796487355
At time: 652.9508326053619 and batch: 1700, loss is 4.514749536514282 and perplexity is 91.3546821445934
At time: 654.103687286377 and batch: 1750, loss is 4.494122152328491 and perplexity is 89.48957627782012
At time: 655.2541825771332 and batch: 1800, loss is 4.4700299263000485 and perplexity is 87.35933731606316
At time: 656.4068267345428 and batch: 1850, loss is 4.497205801010132 and perplexity is 89.76595660263617
At time: 657.5592150688171 and batch: 1900, loss is 4.5939576530456545 and perplexity is 98.88500932205416
At time: 658.7119247913361 and batch: 1950, loss is 4.520757284164429 and perplexity is 91.90516996179237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.542630927507267 and perplexity of 93.9376183607679
finished 14 epochs...
Completing Train Step...
At time: 662.4692840576172 and batch: 50, loss is 4.540592670440674 and perplexity is 93.74634434535241
At time: 663.6177599430084 and batch: 100, loss is 4.518545351028442 and perplexity is 91.70210653513965
At time: 664.7485566139221 and batch: 150, loss is 4.467463912963868 and perplexity is 87.13545945110603
At time: 665.8723442554474 and batch: 200, loss is 4.461702337265015 and perplexity is 86.63486539549608
At time: 666.9947769641876 and batch: 250, loss is 4.472013454437256 and perplexity is 87.53278898594245
At time: 668.118556022644 and batch: 300, loss is 4.5047723579406735 and perplexity is 90.44775199262395
At time: 669.2464220523834 and batch: 350, loss is 4.510651445388794 and perplexity is 90.98106840687947
At time: 670.3868954181671 and batch: 400, loss is 4.459529552459717 and perplexity is 86.44683082965531
At time: 671.5345368385315 and batch: 450, loss is 4.478979158401489 and perplexity is 88.14464501116393
At time: 672.688826084137 and batch: 500, loss is 4.49117078781128 and perplexity is 89.22584928640977
At time: 673.844765663147 and batch: 550, loss is 4.470971956253051 and perplexity is 87.44167120289443
At time: 675.0050537586212 and batch: 600, loss is 4.446650333404541 and perplexity is 85.34060213084183
At time: 676.1636552810669 and batch: 650, loss is 4.5145589542388915 and perplexity is 91.3372732203716
At time: 677.3185095787048 and batch: 700, loss is 4.547972793579102 and perplexity is 94.44076320689128
At time: 678.4714283943176 and batch: 750, loss is 4.497419195175171 and perplexity is 89.785114177979
At time: 679.6263484954834 and batch: 800, loss is 4.499798450469971 and perplexity is 89.99899021823833
At time: 680.7815585136414 and batch: 850, loss is 4.524248056411743 and perplexity is 92.22655058541226
At time: 681.9361615180969 and batch: 900, loss is 4.476227521896362 and perplexity is 87.90243637610442
At time: 683.0925629138947 and batch: 950, loss is 4.5467949390411375 and perplexity is 94.32959121045228
At time: 684.2952771186829 and batch: 1000, loss is 4.529571781158447 and perplexity is 92.71884862195972
At time: 685.4419944286346 and batch: 1050, loss is 4.471739387512207 and perplexity is 87.5088024307349
At time: 686.5893366336823 and batch: 1100, loss is 4.508766870498658 and perplexity is 90.80976923364157
At time: 687.735044002533 and batch: 1150, loss is 4.483140430450439 and perplexity is 88.51220308288683
At time: 688.8818373680115 and batch: 1200, loss is 4.5503394985198975 and perplexity is 94.66454133172851
At time: 690.0278491973877 and batch: 1250, loss is 4.550353956222534 and perplexity is 94.66590997341103
At time: 691.1764256954193 and batch: 1300, loss is 4.526812105178833 and perplexity is 92.46332738264024
At time: 692.328052520752 and batch: 1350, loss is 4.422636365890503 and perplexity is 83.31564660188559
At time: 693.4773375988007 and batch: 1400, loss is 4.446574010848999 and perplexity is 85.33408896654953
At time: 694.624293088913 and batch: 1450, loss is 4.394812593460083 and perplexity is 81.02944389200127
At time: 695.7725667953491 and batch: 1500, loss is 4.397961559295655 and perplexity is 81.28500500792572
At time: 696.921941280365 and batch: 1550, loss is 4.413799467086792 and perplexity is 82.58263819475077
At time: 698.0711212158203 and batch: 1600, loss is 4.475877876281738 and perplexity is 87.87170704721136
At time: 699.2193505764008 and batch: 1650, loss is 4.449863376617432 and perplexity is 85.61524615858971
At time: 700.3681237697601 and batch: 1700, loss is 4.470434741973877 and perplexity is 87.39470890406756
At time: 701.5173363685608 and batch: 1750, loss is 4.448665285110474 and perplexity is 85.51273268182644
At time: 702.6677587032318 and batch: 1800, loss is 4.423182954788208 and perplexity is 83.36119845725847
At time: 703.8143372535706 and batch: 1850, loss is 4.453462171554565 and perplexity is 85.92391295412024
At time: 704.9617037773132 and batch: 1900, loss is 4.551009645462036 and perplexity is 94.7280017461573
At time: 706.1100692749023 and batch: 1950, loss is 4.478318309783935 and perplexity is 88.08641398742851
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528357785247093 and perplexity of 92.60635661506117
finished 15 epochs...
Completing Train Step...
At time: 709.8014290332794 and batch: 50, loss is 4.495787019729614 and perplexity is 89.63868864782509
At time: 710.9486410617828 and batch: 100, loss is 4.473372869491577 and perplexity is 87.65186329440282
At time: 712.0712900161743 and batch: 150, loss is 4.423621530532837 and perplexity is 83.39776667532558
At time: 713.2591886520386 and batch: 200, loss is 4.418911037445068 and perplexity is 83.00584586668177
At time: 714.399733543396 and batch: 250, loss is 4.427043523788452 and perplexity is 83.68364212338186
At time: 715.5478355884552 and batch: 300, loss is 4.4586816501617434 and perplexity is 86.37356342933043
At time: 716.6960198879242 and batch: 350, loss is 4.4648659038543705 and perplexity is 86.90937454617928
At time: 717.8455085754395 and batch: 400, loss is 4.413261833190918 and perplexity is 82.53825090237223
At time: 718.9923987388611 and batch: 450, loss is 4.43582501411438 and perplexity is 84.42174529686238
At time: 720.1457543373108 and batch: 500, loss is 4.448490724563599 and perplexity is 85.49780683521459
At time: 721.2917757034302 and batch: 550, loss is 4.428999404907227 and perplexity is 83.84747754803918
At time: 722.4391665458679 and batch: 600, loss is 4.403611373901367 and perplexity is 81.74554998825862
At time: 723.5878043174744 and batch: 650, loss is 4.4695234203338625 and perplexity is 87.31510049456328
At time: 724.7406177520752 and batch: 700, loss is 4.504381608963013 and perplexity is 90.41241653009865
At time: 725.8971691131592 and batch: 750, loss is 4.455151252746582 and perplexity is 86.0691680587338
At time: 727.0462563037872 and batch: 800, loss is 4.456693363189697 and perplexity is 86.20199861499769
At time: 728.1957659721375 and batch: 850, loss is 4.480475587844849 and perplexity is 88.276645993679
At time: 729.3440763950348 and batch: 900, loss is 4.432537422180176 and perplexity is 84.14465677451892
At time: 730.4929225444794 and batch: 950, loss is 4.503051900863648 and perplexity is 90.29227430230429
At time: 731.6472489833832 and batch: 1000, loss is 4.4875940990448 and perplexity is 88.90728623364033
At time: 732.7978446483612 and batch: 1050, loss is 4.4298171710968015 and perplexity is 83.91607322404863
At time: 733.9526154994965 and batch: 1100, loss is 4.46659649848938 and perplexity is 87.05990966356363
At time: 735.1006786823273 and batch: 1150, loss is 4.4412885189056395 and perplexity is 84.88424619424671
At time: 736.2460331916809 and batch: 1200, loss is 4.508756303787232 and perplexity is 90.80880967808513
At time: 737.3915588855743 and batch: 1250, loss is 4.509483718872071 and perplexity is 90.87488940686323
At time: 738.5389053821564 and batch: 1300, loss is 4.484276571273804 and perplexity is 88.6128225582986
At time: 739.6866176128387 and batch: 1350, loss is 4.379247570037842 and perplexity is 79.77798347114864
At time: 740.8339920043945 and batch: 1400, loss is 4.402719774246216 and perplexity is 81.67269816623474
At time: 741.9815611839294 and batch: 1450, loss is 4.35207706451416 and perplexity is 77.63955793566302
At time: 743.1300084590912 and batch: 1500, loss is 4.354094762802124 and perplexity is 77.79636928458358
At time: 744.2775206565857 and batch: 1550, loss is 4.371761245727539 and perplexity is 79.18296962632988
At time: 745.4339151382446 and batch: 1600, loss is 4.435625457763672 and perplexity is 84.40490008229122
At time: 746.5899670124054 and batch: 1650, loss is 4.408728332519531 and perplexity is 82.16491059518465
At time: 747.74471616745 and batch: 1700, loss is 4.429521188735962 and perplexity is 83.891239221978
At time: 748.9069864749908 and batch: 1750, loss is 4.407397890090943 and perplexity is 82.05566759886037
At time: 750.0615358352661 and batch: 1800, loss is 4.38047116279602 and perplexity is 79.87565897932174
At time: 751.2156534194946 and batch: 1850, loss is 4.413487205505371 and perplexity is 82.55685483533593
At time: 752.3698973655701 and batch: 1900, loss is 4.511816062927246 and perplexity is 91.0870882791314
At time: 753.5241229534149 and batch: 1950, loss is 4.4394235515594485 and perplexity is 84.7260873732478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515093284429506 and perplexity of 91.38609052409976
finished 16 epochs...
Completing Train Step...
At time: 757.2174615859985 and batch: 50, loss is 4.455069351196289 and perplexity is 86.06211914909962
At time: 758.3661181926727 and batch: 100, loss is 4.4321577262878415 and perplexity is 84.1127134587364
At time: 759.4885611534119 and batch: 150, loss is 4.382878837585449 and perplexity is 80.0682052911714
At time: 760.6114671230316 and batch: 200, loss is 4.379228506088257 and perplexity is 79.77646260219068
At time: 761.7395527362823 and batch: 250, loss is 4.386030759811401 and perplexity is 80.32097218855994
At time: 762.8850121498108 and batch: 300, loss is 4.416570796966552 and perplexity is 82.81181934913876
At time: 764.0305218696594 and batch: 350, loss is 4.42179500579834 and perplexity is 83.2455776225369
At time: 765.1769459247589 and batch: 400, loss is 4.370184364318848 and perplexity is 79.05820586831908
At time: 766.3252530097961 and batch: 450, loss is 4.396311235427857 and perplexity is 81.15096905585382
At time: 767.4721879959106 and batch: 500, loss is 4.409490995407104 and perplexity is 82.22759862503473
At time: 768.6284327507019 and batch: 550, loss is 4.390841121673584 and perplexity is 80.70827591861843
At time: 769.774799823761 and batch: 600, loss is 4.3635337448120115 and perplexity is 78.53416435411468
At time: 770.9631867408752 and batch: 650, loss is 4.428251514434814 and perplexity is 83.78479226223102
At time: 772.1165957450867 and batch: 700, loss is 4.4637239551544186 and perplexity is 86.81018514428587
At time: 773.265908241272 and batch: 750, loss is 4.415636692047119 and perplexity is 82.73450053886009
At time: 774.4136798381805 and batch: 800, loss is 4.417278690338135 and perplexity is 82.87046204108225
At time: 775.5614762306213 and batch: 850, loss is 4.439958114624023 and perplexity is 84.77139091788545
At time: 776.7078177928925 and batch: 900, loss is 4.392391080856323 and perplexity is 80.83346744781862
At time: 777.8563902378082 and batch: 950, loss is 4.46316891670227 and perplexity is 86.76201552272539
At time: 779.0037682056427 and batch: 1000, loss is 4.448844242095947 and perplexity is 85.52803715206683
At time: 780.1517295837402 and batch: 1050, loss is 4.390975170135498 and perplexity is 80.71909546402453
At time: 781.2988212108612 and batch: 1100, loss is 4.427089538574219 and perplexity is 83.68749289684192
At time: 782.4458644390106 and batch: 1150, loss is 4.402529973983764 and perplexity is 81.65719813768894
At time: 783.5934660434723 and batch: 1200, loss is 4.470028247833252 and perplexity is 87.35919068643916
At time: 784.7417917251587 and batch: 1250, loss is 4.471836528778076 and perplexity is 87.51730355947628
At time: 785.8896269798279 and batch: 1300, loss is 4.44550726890564 and perplexity is 85.24310804985808
At time: 787.0378293991089 and batch: 1350, loss is 4.339150094985962 and perplexity is 76.64237291255616
At time: 788.1837158203125 and batch: 1400, loss is 4.362335844039917 and perplexity is 78.44014454244453
At time: 789.3324596881866 and batch: 1450, loss is 4.312353320121765 and perplexity is 74.615877532651
At time: 790.4870071411133 and batch: 1500, loss is 4.313350610733032 and perplexity is 74.69032836515319
At time: 791.6418282985687 and batch: 1550, loss is 4.332784767150879 and perplexity is 76.15606846849755
At time: 792.7968971729279 and batch: 1600, loss is 4.398117208480835 and perplexity is 81.29765793740614
At time: 793.9512116909027 and batch: 1650, loss is 4.370721216201782 and perplexity is 79.10065980972045
At time: 795.106085062027 and batch: 1700, loss is 4.3913844776153566 and perplexity is 80.75214115602849
At time: 796.2604820728302 and batch: 1750, loss is 4.369592514038086 and perplexity is 79.01142909076925
At time: 797.4167568683624 and batch: 1800, loss is 4.34109037399292 and perplexity is 76.79122486021802
At time: 798.5704824924469 and batch: 1850, loss is 4.376277914047241 and perplexity is 79.54142173195878
At time: 799.7340054512024 and batch: 1900, loss is 4.475531463623047 and perplexity is 87.84127244731904
At time: 800.8886706829071 and batch: 1950, loss is 4.403279132843018 and perplexity is 81.71839527142087
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.502428631449854 and perplexity of 90.23601542347025
finished 17 epochs...
Completing Train Step...
At time: 804.5715887546539 and batch: 50, loss is 4.417239923477172 and perplexity is 82.86724947567336
At time: 805.6908690929413 and batch: 100, loss is 4.394121141433716 and perplexity is 80.97343528469075
At time: 806.8091719150543 and batch: 150, loss is 4.345162773132325 and perplexity is 77.10458701305568
At time: 807.9253742694855 and batch: 200, loss is 4.342097787857056 and perplexity is 76.8686243849174
At time: 809.0542273521423 and batch: 250, loss is 4.348371181488037 and perplexity is 77.35236729189889
At time: 810.1885352134705 and batch: 300, loss is 4.377232761383056 and perplexity is 79.61740791841706
At time: 811.3255259990692 and batch: 350, loss is 4.382399988174439 and perplexity is 80.02987385645199
At time: 812.4681346416473 and batch: 400, loss is 4.330117712020874 and perplexity is 75.95322665080042
At time: 813.6121513843536 and batch: 450, loss is 4.35944637298584 and perplexity is 78.21382115022213
At time: 814.7549307346344 and batch: 500, loss is 4.3733566379547115 and perplexity is 79.30939834547775
At time: 815.9028453826904 and batch: 550, loss is 4.3552875995635985 and perplexity is 77.88922302244166
At time: 817.0540151596069 and batch: 600, loss is 4.32608024597168 and perplexity is 75.64718630635481
At time: 818.2032611370087 and batch: 650, loss is 4.390041255950928 and perplexity is 80.64374594627338
At time: 819.3539905548096 and batch: 700, loss is 4.426258335113525 and perplexity is 83.61796046493164
At time: 820.5051729679108 and batch: 750, loss is 4.378386859893799 and perplexity is 79.70934729366806
At time: 821.6562333106995 and batch: 800, loss is 4.380477800369262 and perplexity is 79.87618916161803
At time: 822.8078186511993 and batch: 850, loss is 4.4024107456207275 and perplexity is 81.64746286399672
At time: 823.9579083919525 and batch: 900, loss is 4.355265073776245 and perplexity is 77.88746852612749
At time: 825.109274148941 and batch: 950, loss is 4.426648397445678 and perplexity is 83.65058304360642
At time: 826.2607941627502 and batch: 1000, loss is 4.412874755859375 and perplexity is 82.50630839897096
At time: 827.4500796794891 and batch: 1050, loss is 4.355204496383667 and perplexity is 77.88275044927555
At time: 828.5936541557312 and batch: 1100, loss is 4.390449895858764 and perplexity is 80.67670693331311
At time: 829.7376327514648 and batch: 1150, loss is 4.3668136882781985 and perplexity is 78.7921748720096
At time: 830.879016160965 and batch: 1200, loss is 4.4340142822265625 and perplexity is 84.26901846602891
At time: 832.0205256938934 and batch: 1250, loss is 4.436956491470337 and perplexity is 84.5173206504937
At time: 833.1630053520203 and batch: 1300, loss is 4.409592943191528 and perplexity is 82.23598197385773
At time: 834.3179831504822 and batch: 1350, loss is 4.302078914642334 and perplexity is 73.85316865133227
At time: 835.4615433216095 and batch: 1400, loss is 4.324862155914307 and perplexity is 75.55509731857339
At time: 836.6057000160217 and batch: 1450, loss is 4.275154881477356 and perplexity is 71.89127307401253
At time: 837.759795665741 and batch: 1500, loss is 4.275566215515137 and perplexity is 71.92085048432807
At time: 838.9162604808807 and batch: 1550, loss is 4.297044162750244 and perplexity is 73.48227074368143
At time: 840.0679485797882 and batch: 1600, loss is 4.363221921920776 and perplexity is 78.50967942160467
At time: 841.2187058925629 and batch: 1650, loss is 4.336086540222168 and perplexity is 76.40793409734384
At time: 842.3690838813782 and batch: 1700, loss is 4.355403356552124 and perplexity is 77.89823976620279
At time: 843.5189170837402 and batch: 1750, loss is 4.334366331100464 and perplexity is 76.2766094574445
At time: 844.6718573570251 and batch: 1800, loss is 4.30428484916687 and perplexity is 74.0162637282
At time: 845.8242230415344 and batch: 1850, loss is 4.341348581314087 and perplexity is 76.81105547677333
At time: 846.975837469101 and batch: 1900, loss is 4.441640224456787 and perplexity is 84.91410570540832
At time: 848.126974105835 and batch: 1950, loss is 4.369759616851806 and perplexity is 79.02463322607976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4937318313953485 and perplexity of 89.45465343890173
finished 18 epochs...
Completing Train Step...
At time: 851.8204283714294 and batch: 50, loss is 4.381979279518127 and perplexity is 79.99621167723866
At time: 852.9422633647919 and batch: 100, loss is 4.358575429916382 and perplexity is 78.14573102037296
At time: 854.0641527175903 and batch: 150, loss is 4.310193395614624 and perplexity is 74.45488679665321
At time: 855.1875207424164 and batch: 200, loss is 4.3075798225402835 and perplexity is 74.26054757976448
At time: 856.3376975059509 and batch: 250, loss is 4.313120288848877 and perplexity is 74.67312752893652
At time: 857.4731409549713 and batch: 300, loss is 4.34057993888855 and perplexity is 76.75203792538625
At time: 858.611967086792 and batch: 350, loss is 4.345814094543457 and perplexity is 77.15482323966289
At time: 859.7501697540283 and batch: 400, loss is 4.293476896286011 and perplexity is 73.22060689336202
At time: 860.8887858390808 and batch: 450, loss is 4.325213069915772 and perplexity is 75.58161531260008
At time: 862.0277054309845 and batch: 500, loss is 4.339636507034302 and perplexity is 76.67966175428992
At time: 863.1739130020142 and batch: 550, loss is 4.3217691135406495 and perplexity is 75.32176324313635
At time: 864.3236083984375 and batch: 600, loss is 4.290728168487549 and perplexity is 73.01961973181962
At time: 865.4702458381653 and batch: 650, loss is 4.354385261535644 and perplexity is 77.81897231425005
At time: 866.6171114444733 and batch: 700, loss is 4.391902704238891 and perplexity is 80.79399991070673
At time: 867.7636668682098 and batch: 750, loss is 4.3433628749847415 and perplexity is 76.96593143011692
At time: 868.910035610199 and batch: 800, loss is 4.346122608184815 and perplexity is 77.17863022733025
At time: 870.0572848320007 and batch: 850, loss is 4.367783813476563 and perplexity is 78.86865023562765
At time: 871.2051639556885 and batch: 900, loss is 4.320526371002197 and perplexity is 75.22821582360129
At time: 872.3592267036438 and batch: 950, loss is 4.392525930404663 and perplexity is 80.84436853938178
At time: 873.5157051086426 and batch: 1000, loss is 4.379207363128662 and perplexity is 79.77477590949617
At time: 874.6705088615417 and batch: 1050, loss is 4.321939344406128 and perplexity is 75.33458642350217
At time: 875.8272042274475 and batch: 1100, loss is 4.356036605834961 and perplexity is 77.94758439274479
At time: 876.9821445941925 and batch: 1150, loss is 4.333558421134949 and perplexity is 76.21500971140313
At time: 878.1374487876892 and batch: 1200, loss is 4.400306301116943 and perplexity is 81.47582097828185
At time: 879.2927076816559 and batch: 1250, loss is 4.404130268096924 and perplexity is 81.78797828660696
At time: 880.4473118782043 and batch: 1300, loss is 4.376112174987793 and perplexity is 79.52823970395238
At time: 881.6018736362457 and batch: 1350, loss is 4.267504744529724 and perplexity is 71.34339333919189
At time: 882.7553923130035 and batch: 1400, loss is 4.290167150497436 and perplexity is 72.97866590051109
At time: 883.9100172519684 and batch: 1450, loss is 4.240549006462097 and perplexity is 69.44596765989364
At time: 885.0650460720062 and batch: 1500, loss is 4.240442676544189 and perplexity is 69.43858386841926
At time: 886.2199535369873 and batch: 1550, loss is 4.263686838150025 and perplexity is 71.07153024676253
At time: 887.3747494220734 and batch: 1600, loss is 4.330810089111328 and perplexity is 76.00583313454
At time: 888.5302536487579 and batch: 1650, loss is 4.3041329765319825 and perplexity is 74.0050235367634
At time: 889.6861174106598 and batch: 1700, loss is 4.321320600509644 and perplexity is 75.28798802568224
At time: 890.8406836986542 and batch: 1750, loss is 4.301419858932495 and perplexity is 73.80451133454534
At time: 891.9958255290985 and batch: 1800, loss is 4.2698928737640385 and perplexity is 71.5139741859831
At time: 893.148952960968 and batch: 1850, loss is 4.308342781066894 and perplexity is 74.31722691697361
At time: 894.3027148246765 and batch: 1900, loss is 4.410031061172486 and perplexity is 82.27201892988495
At time: 895.4580998420715 and batch: 1950, loss is 4.338594636917114 and perplexity is 76.59981310929355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486921727380087 and perplexity of 88.84752758585246
finished 19 epochs...
Completing Train Step...
At time: 899.16215467453 and batch: 50, loss is 4.349069390296936 and perplexity is 77.40639425498723
At time: 900.2820510864258 and batch: 100, loss is 4.32541410446167 and perplexity is 75.59681135572635
At time: 901.4027993679047 and batch: 150, loss is 4.277706899642944 and perplexity is 72.0749752147436
At time: 902.5226449966431 and batch: 200, loss is 4.2746835041046145 and perplexity is 71.85739314033229
At time: 903.6437621116638 and batch: 250, loss is 4.2795968437194825 and perplexity is 72.21132169023966
At time: 904.7648594379425 and batch: 300, loss is 4.306133861541748 and perplexity is 74.15324731892572
At time: 905.8995888233185 and batch: 350, loss is 4.311689329147339 and perplexity is 74.56634970825428
At time: 907.0464644432068 and batch: 400, loss is 4.2592348289489745 and perplexity is 70.75582242868076
At time: 908.1983206272125 and batch: 450, loss is 4.29268853187561 and perplexity is 73.16290512077988
At time: 909.3440380096436 and batch: 500, loss is 4.30827449798584 and perplexity is 74.31215248099534
At time: 910.4910645484924 and batch: 550, loss is 4.290398502349854 and perplexity is 72.99555160324813
At time: 911.6382057666779 and batch: 600, loss is 4.258296899795532 and perplexity is 70.68948959266226
At time: 912.7839386463165 and batch: 650, loss is 4.320798568725586 and perplexity is 75.24869555982539
At time: 913.9517071247101 and batch: 700, loss is 4.359806871414184 and perplexity is 78.24202219273194
At time: 915.0965161323547 and batch: 750, loss is 4.3104056453704835 and perplexity is 74.47069150541184
At time: 916.2421989440918 and batch: 800, loss is 4.313857851028442 and perplexity is 74.72822391964101
At time: 917.3875091075897 and batch: 850, loss is 4.335619373321533 and perplexity is 76.37224717611089
At time: 918.5337209701538 and batch: 900, loss is 4.288079018592835 and perplexity is 72.82643581345378
At time: 919.6823999881744 and batch: 950, loss is 4.360429630279541 and perplexity is 78.2907632810931
At time: 920.8364589214325 and batch: 1000, loss is 4.34726110458374 and perplexity is 77.2665478573743
At time: 921.9901056289673 and batch: 1050, loss is 4.290864524841308 and perplexity is 73.0295770997789
At time: 923.144725561142 and batch: 1100, loss is 4.323702144622803 and perplexity is 75.46750336736177
At time: 924.3004987239838 and batch: 1150, loss is 4.3026146936416625 and perplexity is 73.89274823013626
At time: 925.4539215564728 and batch: 1200, loss is 4.368582000732422 and perplexity is 78.93162731754109
At time: 926.6069073677063 and batch: 1250, loss is 4.373331594467163 and perplexity is 79.30741218641806
At time: 927.7616443634033 and batch: 1300, loss is 4.344466705322265 and perplexity is 77.05093566668177
At time: 928.9161880016327 and batch: 1350, loss is 4.23515109539032 and perplexity is 69.072114423195
At time: 930.0692362785339 and batch: 1400, loss is 4.257850503921508 and perplexity is 70.65794113824509
At time: 931.2218465805054 and batch: 1450, loss is 4.208146948814392 and perplexity is 67.23184026716369
At time: 932.3756186962128 and batch: 1500, loss is 4.207380089759827 and perplexity is 67.18030268525608
At time: 933.5278499126434 and batch: 1550, loss is 4.232515134811401 and perplexity is 68.89028280824229
At time: 934.6817395687103 and batch: 1600, loss is 4.300524072647095 and perplexity is 73.73842786824156
At time: 935.8351452350616 and batch: 1650, loss is 4.2742867851257325 and perplexity is 71.82889160262481
At time: 936.9866797924042 and batch: 1700, loss is 4.289005007743835 and perplexity is 72.89390353529144
At time: 938.1390604972839 and batch: 1750, loss is 4.270492238998413 and perplexity is 71.55685002374186
At time: 939.2912476062775 and batch: 1800, loss is 4.237738914489746 and perplexity is 69.25109204110457
At time: 940.4439952373505 and batch: 1850, loss is 4.277162694931031 and perplexity is 72.03576234450281
At time: 941.5972528457642 and batch: 1900, loss is 4.380036907196045 and perplexity is 79.84098005741124
At time: 942.7431373596191 and batch: 1950, loss is 4.309367752075195 and perplexity is 74.39343897088152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.481677529978198 and perplexity of 88.38281320453017
Finished Training.
Improved accuracyfrom -10000000 to -88.38281320453017
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
973.7953691482544


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.622277021408081 and batch: 50, loss is 7.62016770362854 and perplexity is 2038.9040327557389
At time: 2.8003194332122803 and batch: 100, loss is 6.850780000686646 and perplexity is 944.6174216306396
At time: 3.978794574737549 and batch: 150, loss is 6.524542951583863 and perplexity is 681.6681470949471
At time: 5.15738320350647 and batch: 200, loss is 6.421971311569214 and perplexity is 615.2146993816184
At time: 6.336414098739624 and batch: 250, loss is 6.370318365097046 and perplexity is 584.2438021207921
At time: 7.514705181121826 and batch: 300, loss is 6.308255500793457 and perplexity is 549.0862323184916
At time: 8.694475889205933 and batch: 350, loss is 6.2558981132507325 and perplexity is 521.0771509619158
At time: 9.87413477897644 and batch: 400, loss is 6.20978569984436 and perplexity is 497.5946052587326
At time: 11.051991939544678 and batch: 450, loss is 6.11820161819458 and perplexity is 454.0474092247635
At time: 12.236650705337524 and batch: 500, loss is 6.105265016555786 and perplexity is 448.21140916090224
At time: 13.417447566986084 and batch: 550, loss is 6.056794786453247 and perplexity is 427.0046001916934
At time: 14.60436749458313 and batch: 600, loss is 6.099885835647583 and perplexity is 445.8068719243582
At time: 15.783158779144287 and batch: 650, loss is 6.167287902832031 and perplexity is 476.8909759584118
At time: 16.969408750534058 and batch: 700, loss is 6.076790103912353 and perplexity is 435.6286254595255
At time: 18.155105352401733 and batch: 750, loss is 5.992938804626465 and perplexity is 400.5901379081315
At time: 19.342145681381226 and batch: 800, loss is 6.009897890090943 and perplexity is 407.4417143133525
At time: 20.529228448867798 and batch: 850, loss is 6.041341609954834 and perplexity is 420.4567456176557
At time: 21.716542959213257 and batch: 900, loss is 6.024571189880371 and perplexity is 413.46430632541734
At time: 22.904820919036865 and batch: 950, loss is 6.0360212326049805 and perplexity is 418.22569734377544
At time: 24.09210705757141 and batch: 1000, loss is 6.0226052951812745 and perplexity is 412.652277480471
At time: 25.28084421157837 and batch: 1050, loss is 5.911720809936523 and perplexity is 369.3411748424168
At time: 26.468995094299316 and batch: 1100, loss is 5.988997097015381 and perplexity is 399.0142366240622
At time: 27.65738558769226 and batch: 1150, loss is 5.899505815505981 and perplexity is 364.8571165760497
At time: 28.845094203948975 and batch: 1200, loss is 5.972856321334839 and perplexity is 392.62553533514057
At time: 30.032251119613647 and batch: 1250, loss is 5.913979444503784 and perplexity is 370.17632438079886
At time: 31.217974424362183 and batch: 1300, loss is 5.929217691421509 and perplexity is 375.8603599962697
At time: 32.40415287017822 and batch: 1350, loss is 5.906734018325806 and perplexity is 367.50393215083244
At time: 33.592280864715576 and batch: 1400, loss is 5.916954507827759 and perplexity is 371.2792622283287
At time: 34.77891302108765 and batch: 1450, loss is 5.892179689407349 and perplexity is 362.19389479305545
At time: 35.96731209754944 and batch: 1500, loss is 5.8652963447570805 and perplexity is 352.58662782569417
At time: 37.156595945358276 and batch: 1550, loss is 5.837017803192139 and perplexity is 342.75565019453575
At time: 38.344882011413574 and batch: 1600, loss is 5.844313364028931 and perplexity is 345.2653887360214
At time: 39.53363847732544 and batch: 1650, loss is 5.8462252521514895 and perplexity is 345.9261289613029
At time: 40.72175478935242 and batch: 1700, loss is 5.854216146469116 and perplexity is 348.7014620280699
At time: 41.91100835800171 and batch: 1750, loss is 5.853055257797241 and perplexity is 348.296893325982
At time: 43.09936714172363 and batch: 1800, loss is 5.862024974822998 and perplexity is 351.4350711432031
At time: 44.287774324417114 and batch: 1850, loss is 5.822691898345948 and perplexity is 337.88037014323265
At time: 45.47652220726013 and batch: 1900, loss is 5.816935873031616 and perplexity is 335.94110875257013
At time: 46.66634798049927 and batch: 1950, loss is 5.747908897399903 and perplexity is 313.53434183281365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.210663835392442 and perplexity of 183.21564286133074
finished 1 epochs...
Completing Train Step...
At time: 50.323620557785034 and batch: 50, loss is 5.484147462844849 and perplexity is 240.84352839171908
At time: 51.47019910812378 and batch: 100, loss is 5.393229961395264 and perplexity is 219.91254869525207
At time: 52.59039258956909 and batch: 150, loss is 5.2825994968414305 and perplexity is 196.88100227111025
At time: 53.710116386413574 and batch: 200, loss is 5.2401214122772215 and perplexity is 188.69301066308634
At time: 54.83327054977417 and batch: 250, loss is 5.241778764724732 and perplexity is 189.00600078196277
At time: 55.953951835632324 and batch: 300, loss is 5.239301090240478 and perplexity is 188.53828509933143
At time: 57.072877407073975 and batch: 350, loss is 5.212412242889404 and perplexity is 183.53625866673423
At time: 58.21435499191284 and batch: 400, loss is 5.154953718185425 and perplexity is 173.28778650008755
At time: 59.33365511894226 and batch: 450, loss is 5.104852342605591 and perplexity is 164.81973188263777
At time: 60.4532253742218 and batch: 500, loss is 5.089679956436157 and perplexity is 162.33789853904335
At time: 61.57312345504761 and batch: 550, loss is 5.046239824295044 and perplexity is 155.43689421949557
At time: 62.69465494155884 and batch: 600, loss is 5.023504648208618 and perplexity is 151.94287809502904
At time: 63.81438064575195 and batch: 650, loss is 5.091348199844361 and perplexity is 162.60894368996517
At time: 64.93451833724976 and batch: 700, loss is 5.083267154693604 and perplexity is 161.30018865053202
At time: 66.05454587936401 and batch: 750, loss is 5.014432573318482 and perplexity is 150.57067470320175
At time: 67.1752438545227 and batch: 800, loss is 5.014780330657959 and perplexity is 150.62304586614013
At time: 68.29471945762634 and batch: 850, loss is 5.007719345092774 and perplexity is 149.56324473698334
At time: 69.41450524330139 and batch: 900, loss is 5.00918402671814 and perplexity is 149.78246778016992
At time: 70.53375124931335 and batch: 950, loss is 5.050480365753174 and perplexity is 156.09743033913267
At time: 71.65502142906189 and batch: 1000, loss is 5.007328033447266 and perplexity is 149.50473034700556
At time: 72.77488851547241 and batch: 1050, loss is 4.927020072937012 and perplexity is 137.96776527897234
At time: 73.8976879119873 and batch: 1100, loss is 4.981335716247559 and perplexity is 145.66882397976607
At time: 75.02055239677429 and batch: 1150, loss is 4.900687637329102 and perplexity is 134.38215410677418
At time: 76.14081764221191 and batch: 1200, loss is 4.981278257369995 and perplexity is 145.66045425310404
At time: 77.25932574272156 and batch: 1250, loss is 4.945939331054688 and perplexity is 140.60286147506193
At time: 78.38010907173157 and batch: 1300, loss is 4.951779136657715 and perplexity is 141.42635703998562
At time: 79.49867272377014 and batch: 1350, loss is 4.849497003555298 and perplexity is 127.67615304088808
At time: 80.61747765541077 and batch: 1400, loss is 4.847551536560059 and perplexity is 127.42800475948049
At time: 81.73674392700195 and batch: 1450, loss is 4.805614166259765 and perplexity is 122.19451572869072
At time: 82.85753440856934 and batch: 1500, loss is 4.7853018283844 and perplexity is 119.73749780585699
At time: 83.99430322647095 and batch: 1550, loss is 4.7864463329315186 and perplexity is 119.87461636799783
At time: 85.13765263557434 and batch: 1600, loss is 4.842271118164063 and perplexity is 126.75690498213376
At time: 86.28229451179504 and batch: 1650, loss is 4.812651672363281 and perplexity is 123.05749342265658
At time: 87.42824625968933 and batch: 1700, loss is 4.820897512435913 and perplexity is 124.07640093406974
At time: 88.57286739349365 and batch: 1750, loss is 4.8168055534362795 and perplexity is 123.56972274879573
At time: 89.71786785125732 and batch: 1800, loss is 4.772319793701172 and perplexity is 118.19310780873654
At time: 90.86109042167664 and batch: 1850, loss is 4.790220432281494 and perplexity is 120.32788989133675
At time: 92.0052273273468 and batch: 1900, loss is 4.882724180221557 and perplexity is 131.98973840673005
At time: 93.15007972717285 and batch: 1950, loss is 4.79877124786377 and perplexity is 121.3612030262218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.629680402888808 and perplexity of 102.48130614670134
finished 2 epochs...
Completing Train Step...
At time: 96.75647735595703 and batch: 50, loss is 4.760165662765503 and perplexity is 116.76526795402044
At time: 97.89909529685974 and batch: 100, loss is 4.694281768798828 and perplexity is 109.3202632143401
At time: 99.01951122283936 and batch: 150, loss is 4.634239044189453 and perplexity is 102.94954812416834
At time: 100.14007043838501 and batch: 200, loss is 4.6161767578125 and perplexity is 101.10673669800875
At time: 101.27235054969788 and batch: 250, loss is 4.635210943222046 and perplexity is 103.04965332859194
At time: 102.40894865989685 and batch: 300, loss is 4.654935369491577 and perplexity is 105.10242695609243
At time: 103.54767155647278 and batch: 350, loss is 4.657342491149902 and perplexity is 105.35572602288964
At time: 104.6924889087677 and batch: 400, loss is 4.601845302581787 and perplexity is 99.66806378976028
At time: 105.83372712135315 and batch: 450, loss is 4.594120388031006 and perplexity is 98.90110268203847
At time: 106.97875809669495 and batch: 500, loss is 4.600293779373169 and perplexity is 99.5135463753063
At time: 108.1240086555481 and batch: 550, loss is 4.571028041839599 and perplexity is 96.64341219183295
At time: 109.27010536193848 and batch: 600, loss is 4.540827770233154 and perplexity is 93.76838668242668
At time: 110.41611218452454 and batch: 650, loss is 4.601598043441772 and perplexity is 99.64342299647687
At time: 111.56219935417175 and batch: 700, loss is 4.632216577529907 and perplexity is 102.74154650454263
At time: 112.70771861076355 and batch: 750, loss is 4.579384517669678 and perplexity is 97.45439428680696
At time: 113.8907859325409 and batch: 800, loss is 4.575928544998169 and perplexity is 97.1181758788902
At time: 115.03793501853943 and batch: 850, loss is 4.577608528137207 and perplexity is 97.28146990405946
At time: 116.18433570861816 and batch: 900, loss is 4.5549417495727536 and perplexity is 95.10121538780231
At time: 117.33040046691895 and batch: 950, loss is 4.612765817642212 and perplexity is 100.76245516397154
At time: 118.47465348243713 and batch: 1000, loss is 4.585828151702881 and perplexity is 98.08438226472718
At time: 119.62130832672119 and batch: 1050, loss is 4.525373792648315 and perplexity is 92.33043181584245
At time: 120.77322030067444 and batch: 1100, loss is 4.564609661102295 and perplexity is 96.02510436677979
At time: 121.92252779006958 and batch: 1150, loss is 4.516641464233398 and perplexity is 91.52768220021123
At time: 123.06967782974243 and batch: 1200, loss is 4.592969617843628 and perplexity is 98.78735570244235
At time: 124.21501064300537 and batch: 1250, loss is 4.575414762496949 and perplexity is 97.06829107564006
At time: 125.35949087142944 and batch: 1300, loss is 4.563517770767212 and perplexity is 95.92031270430937
At time: 126.50481033325195 and batch: 1350, loss is 4.4460630702972415 and perplexity is 85.29049945682159
At time: 127.6468939781189 and batch: 1400, loss is 4.463710250854493 and perplexity is 86.8089954796238
At time: 128.79120540618896 and batch: 1450, loss is 4.41918716430664 and perplexity is 83.02876917511804
At time: 129.93580770492554 and batch: 1500, loss is 4.41205623626709 and perplexity is 82.43880300007403
At time: 131.07926034927368 and batch: 1550, loss is 4.420461568832398 and perplexity is 83.134648866772
At time: 132.22382736206055 and batch: 1600, loss is 4.494137992858887 and perplexity is 89.49099385140079
At time: 133.36888790130615 and batch: 1650, loss is 4.460131368637085 and perplexity is 86.49887158884549
At time: 134.52141499519348 and batch: 1700, loss is 4.46376298904419 and perplexity is 86.8135737496186
At time: 135.66820645332336 and batch: 1750, loss is 4.462640247344971 and perplexity is 86.71615922621842
At time: 136.814772605896 and batch: 1800, loss is 4.422938566207886 and perplexity is 83.34082842151699
At time: 137.9614188671112 and batch: 1850, loss is 4.45554256439209 and perplexity is 86.10285451703623
At time: 139.10692310333252 and batch: 1900, loss is 4.551993055343628 and perplexity is 94.82120401964497
At time: 140.25261783599854 and batch: 1950, loss is 4.477281255722046 and perplexity is 87.99511096527347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492295659974564 and perplexity of 89.32627343209127
finished 3 epochs...
Completing Train Step...
At time: 143.89268803596497 and batch: 50, loss is 4.458135395050049 and perplexity is 86.32639431315023
At time: 145.04210233688354 and batch: 100, loss is 4.392394866943359 and perplexity is 80.83377349094114
At time: 146.16363167762756 and batch: 150, loss is 4.348298330307006 and perplexity is 77.34673228584705
At time: 147.2849850654602 and batch: 200, loss is 4.342278451919555 and perplexity is 76.88251303742994
At time: 148.40954303741455 and batch: 250, loss is 4.3513273334503175 and perplexity is 77.58137096231195
At time: 149.55104041099548 and batch: 300, loss is 4.371720190048218 and perplexity is 79.17971878245446
At time: 150.69784927368164 and batch: 350, loss is 4.379347200393677 and perplexity is 79.78593217598922
At time: 151.8459599018097 and batch: 400, loss is 4.3196284961700435 and perplexity is 75.16070061658382
At time: 152.99301886558533 and batch: 450, loss is 4.338894271850586 and perplexity is 76.62276852814948
At time: 154.1400842666626 and batch: 500, loss is 4.347940711975098 and perplexity is 77.31907662184938
At time: 155.28774118423462 and batch: 550, loss is 4.319122428894043 and perplexity is 75.1226738684185
At time: 156.43242144584656 and batch: 600, loss is 4.292271547317505 and perplexity is 73.13240367887546
At time: 157.579754114151 and batch: 650, loss is 4.350551805496216 and perplexity is 77.521227764793
At time: 158.7241725921631 and batch: 700, loss is 4.390802564620972 and perplexity is 80.70516410536916
At time: 159.8682940006256 and batch: 750, loss is 4.338896017074585 and perplexity is 76.62290225216067
At time: 161.01381063461304 and batch: 800, loss is 4.334225616455078 and perplexity is 76.2658769765198
At time: 162.15903234481812 and batch: 850, loss is 4.335944452285767 and perplexity is 76.39707822292591
At time: 163.30280900001526 and batch: 900, loss is 4.3064942550659175 and perplexity is 74.17997648527552
At time: 164.44914484024048 and batch: 950, loss is 4.37845739364624 and perplexity is 79.71496969131941
At time: 165.59452414512634 and batch: 1000, loss is 4.353466329574585 and perplexity is 77.74749481992052
At time: 166.73875045776367 and batch: 1050, loss is 4.303727684020996 and perplexity is 73.97503593223482
At time: 167.88432335853577 and batch: 1100, loss is 4.334713554382324 and perplexity is 76.30309907074857
At time: 169.02823853492737 and batch: 1150, loss is 4.29571720123291 and perplexity is 73.38482726437026
At time: 170.17247533798218 and batch: 1200, loss is 4.364981055259705 and perplexity is 78.6479099634343
At time: 171.341956615448 and batch: 1250, loss is 4.357244462966919 and perplexity is 78.04179082097222
At time: 172.4887490272522 and batch: 1300, loss is 4.340469312667847 and perplexity is 76.74354760713386
At time: 173.6336681842804 and batch: 1350, loss is 4.223570556640625 and perplexity is 68.27683589033322
At time: 174.78094840049744 and batch: 1400, loss is 4.246244788169861 and perplexity is 69.84264535453208
At time: 175.9246232509613 and batch: 1450, loss is 4.196412682533264 and perplexity is 66.44753457624009
At time: 177.0687131881714 and batch: 1500, loss is 4.193330221176147 and perplexity is 66.24302797241268
At time: 178.21273136138916 and batch: 1550, loss is 4.210462794303894 and perplexity is 67.38771924734722
At time: 179.35811018943787 and batch: 1600, loss is 4.289789938926697 and perplexity is 72.95114269467852
At time: 180.50544095039368 and batch: 1650, loss is 4.2525887870788575 and perplexity is 70.2871354520529
At time: 181.6502652168274 and batch: 1700, loss is 4.248951697349549 and perplexity is 70.03195916442338
At time: 182.7950849533081 and batch: 1750, loss is 4.2527791929245 and perplexity is 70.30051980770575
At time: 183.94057393074036 and batch: 1800, loss is 4.213928604125977 and perplexity is 67.6216774597487
At time: 185.08729577064514 and batch: 1850, loss is 4.251087007522583 and perplexity is 70.18165889005792
At time: 186.24058485031128 and batch: 1900, loss is 4.34423490524292 and perplexity is 77.03307732354324
At time: 187.39404368400574 and batch: 1950, loss is 4.274108061790466 and perplexity is 71.81605525066108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436244662972384 and perplexity of 84.45718022045949
finished 4 epochs...
Completing Train Step...
At time: 191.05311346054077 and batch: 50, loss is 4.262591457366943 and perplexity is 70.99372248065175
At time: 192.1708734035492 and batch: 100, loss is 4.204628648757935 and perplexity is 66.9957141046741
At time: 193.28793907165527 and batch: 150, loss is 4.165504336357117 and perplexity is 64.42516620503336
At time: 194.41921591758728 and batch: 200, loss is 4.1597529315948485 and perplexity is 64.05569450642366
At time: 195.55469346046448 and batch: 250, loss is 4.16460551738739 and perplexity is 64.36728565948331
At time: 196.68969011306763 and batch: 300, loss is 4.181894083023071 and perplexity is 65.48977889258394
At time: 197.83104252815247 and batch: 350, loss is 4.193598599433899 and perplexity is 66.26080854670114
At time: 198.96678233146667 and batch: 400, loss is 4.136649498939514 and perplexity is 62.5927526437292
At time: 200.12462043762207 and batch: 450, loss is 4.169423246383667 and perplexity is 64.67813799792565
At time: 201.26167392730713 and batch: 500, loss is 4.1799910402297975 and perplexity is 65.36526755360973
At time: 202.4048309326172 and batch: 550, loss is 4.150441465377807 and perplexity is 63.462010395319915
At time: 203.54798579216003 and batch: 600, loss is 4.129298672676087 and perplexity is 62.134331146305406
At time: 204.69146537780762 and batch: 650, loss is 4.184982151985168 and perplexity is 65.6923284286223
At time: 205.83509373664856 and batch: 700, loss is 4.225495629310608 and perplexity is 68.4084003560468
At time: 206.97876358032227 and batch: 750, loss is 4.173653602600098 and perplexity is 64.9523291152128
At time: 208.12849593162537 and batch: 800, loss is 4.170403995513916 and perplexity is 64.74160214162808
At time: 209.27120876312256 and batch: 850, loss is 4.1668753337860105 and perplexity is 64.51355351780114
At time: 210.41180872917175 and batch: 900, loss is 4.139311351776123 and perplexity is 62.759587286029664
At time: 211.5527160167694 and batch: 950, loss is 4.22038700580597 and perplexity is 68.05981873830365
At time: 212.7023162841797 and batch: 1000, loss is 4.194444952011108 and perplexity is 66.31691229120801
At time: 213.8533902168274 and batch: 1050, loss is 4.1495823097229 and perplexity is 63.40751006570265
At time: 215.0044527053833 and batch: 1100, loss is 4.175669317245483 and perplexity is 65.08338651905139
At time: 216.15418004989624 and batch: 1150, loss is 4.144108247756958 and perplexity is 63.06136170964322
At time: 217.304518699646 and batch: 1200, loss is 4.207149982452393 and perplexity is 67.1648457851336
At time: 218.45362734794617 and batch: 1250, loss is 4.204159502983093 and perplexity is 66.96429072011978
At time: 219.60381269454956 and batch: 1300, loss is 4.180530033111572 and perplexity is 65.40050846398317
At time: 220.7537350654602 and batch: 1350, loss is 4.070019845962524 and perplexity is 58.558124722709266
At time: 221.9050796031952 and batch: 1400, loss is 4.0955610179901125 and perplexity is 60.07303175702593
At time: 223.05328845977783 and batch: 1450, loss is 4.0442744064331055 and perplexity is 57.0697615554459
At time: 224.20279240608215 and batch: 1500, loss is 4.039726014137268 and perplexity is 56.81077532364193
At time: 225.353497505188 and batch: 1550, loss is 4.05957790851593 and perplexity is 57.94984577961852
At time: 226.50411176681519 and batch: 1600, loss is 4.145783166885376 and perplexity is 63.167072894764715
At time: 227.66633892059326 and batch: 1650, loss is 4.104311308860779 and perplexity is 60.60099480476713
At time: 228.81571793556213 and batch: 1700, loss is 4.098565101623535 and perplexity is 60.25376750526786
At time: 229.96342968940735 and batch: 1750, loss is 4.101159200668335 and perplexity is 60.41027465575774
At time: 231.1146833896637 and batch: 1800, loss is 4.064436964988708 and perplexity is 58.23211257262447
At time: 232.26603031158447 and batch: 1850, loss is 4.106350326538086 and perplexity is 60.72468736724192
At time: 233.41881012916565 and batch: 1900, loss is 4.194725651741027 and perplexity is 66.33553004345401
At time: 234.57377529144287 and batch: 1950, loss is 4.128086128234863 and perplexity is 62.059036166944445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.422742834756541 and perplexity of 83.32451759653651
finished 5 epochs...
Completing Train Step...
At time: 238.24919533729553 and batch: 50, loss is 4.121892914772034 and perplexity is 61.67587902035819
At time: 239.37114477157593 and batch: 100, loss is 4.066874394416809 and perplexity is 58.37422235839948
At time: 240.49313116073608 and batch: 150, loss is 4.035131940841675 and perplexity is 56.55038105099209
At time: 241.61609292030334 and batch: 200, loss is 4.025870037078858 and perplexity is 56.0290349196698
At time: 242.73779129981995 and batch: 250, loss is 4.024818687438965 and perplexity is 55.97015976859099
At time: 243.85940051078796 and batch: 300, loss is 4.044636964797974 and perplexity is 57.09045642620141
At time: 244.98245310783386 and batch: 350, loss is 4.056946358680725 and perplexity is 57.79754834953452
At time: 246.10434770584106 and batch: 400, loss is 4.0031490230560305 and perplexity is 54.77035185787235
At time: 247.22604370117188 and batch: 450, loss is 4.044315776824951 and perplexity is 57.07212260268237
At time: 248.3482780456543 and batch: 500, loss is 4.055066428184509 and perplexity is 57.68899504409061
At time: 249.47380089759827 and batch: 550, loss is 4.025511631965637 and perplexity is 56.00895742521902
At time: 250.61725997924805 and batch: 600, loss is 4.002360095977783 and perplexity is 54.72715908442112
At time: 251.7634506225586 and batch: 650, loss is 4.0604596614837645 and perplexity is 58.00096576240642
At time: 252.90980195999146 and batch: 700, loss is 4.101943821907043 and perplexity is 60.45769244035662
At time: 254.056254863739 and batch: 750, loss is 4.051277604103088 and perplexity is 57.4708351361681
At time: 255.20967626571655 and batch: 800, loss is 4.048186731338501 and perplexity is 57.293474338119
At time: 256.37878608703613 and batch: 850, loss is 4.044913625717163 and perplexity is 57.10625330944257
At time: 257.52641248703003 and batch: 900, loss is 4.017158184051514 and perplexity is 55.543038241779115
At time: 258.6727771759033 and batch: 950, loss is 4.102653083801269 and perplexity is 60.500587988107895
At time: 259.8180377483368 and batch: 1000, loss is 4.0732010650634765 and perplexity is 58.744707570699134
At time: 260.9643602371216 and batch: 1050, loss is 4.030839853286743 and perplexity is 56.30818200582637
At time: 262.11045718193054 and batch: 1100, loss is 4.054119844436645 and perplexity is 57.634413416067794
At time: 263.25668025016785 and batch: 1150, loss is 4.026741809844971 and perplexity is 56.07790080330286
At time: 264.4010908603668 and batch: 1200, loss is 4.089461317062378 and perplexity is 59.70771950987284
At time: 265.54629278182983 and batch: 1250, loss is 4.083999166488647 and perplexity is 59.38247602856844
At time: 266.6929581165314 and batch: 1300, loss is 4.062031645774841 and perplexity is 58.09221407111555
At time: 267.8397943973541 and batch: 1350, loss is 3.9532982206344602 and perplexity is 52.10694392739958
At time: 268.985951423645 and batch: 1400, loss is 3.9823497629165647 and perplexity is 53.642934429808115
At time: 270.1301763057709 and batch: 1450, loss is 3.928583526611328 and perplexity is 50.834920335730914
At time: 271.2740571498871 and batch: 1500, loss is 3.9225904417037962 and perplexity is 50.53117344149595
At time: 272.417044878006 and batch: 1550, loss is 3.9479028463363646 and perplexity is 51.82656451746728
At time: 273.56086564064026 and batch: 1600, loss is 4.0327751207351685 and perplexity is 56.417258909989826
At time: 274.70254349708557 and batch: 1650, loss is 3.987733039855957 and perplexity is 53.93248787561593
At time: 275.84773421287537 and batch: 1700, loss is 3.985408353805542 and perplexity is 53.80725739056531
At time: 276.9929575920105 and batch: 1750, loss is 3.987653546333313 and perplexity is 53.92820076257085
At time: 278.1381072998047 and batch: 1800, loss is 3.9518349075317385 and perplexity is 52.030750914320926
At time: 279.2821969985962 and batch: 1850, loss is 3.994830303192139 and perplexity is 54.31662248424119
At time: 280.4268889427185 and batch: 1900, loss is 4.079019374847412 and perplexity is 59.087498743094116
At time: 281.57158184051514 and batch: 1950, loss is 4.014278712272644 and perplexity is 55.383333673395356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429972803869913 and perplexity of 83.92913433157496
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 285.21011304855347 and batch: 50, loss is 4.053166151046753 and perplexity is 57.57947405877761
At time: 286.3305139541626 and batch: 100, loss is 4.028683500289917 and perplexity is 56.18689250729735
At time: 287.4521038532257 and batch: 150, loss is 4.002150983810425 and perplexity is 54.71571616604001
At time: 288.5728657245636 and batch: 200, loss is 3.9993582153320313 and perplexity is 54.56312101929786
At time: 289.69537472724915 and batch: 250, loss is 3.9941521072387696 and perplexity is 54.27979765930679
At time: 290.83129239082336 and batch: 300, loss is 4.006576251983643 and perplexity is 54.95838442340821
At time: 291.9679079055786 and batch: 350, loss is 4.013381886482239 and perplexity is 55.33368673705244
At time: 293.1033308506012 and batch: 400, loss is 3.9511008358001707 and perplexity is 51.992570626152094
At time: 294.2393412590027 and batch: 450, loss is 3.989496922492981 and perplexity is 54.02770240349088
At time: 295.38458824157715 and batch: 500, loss is 3.997793445587158 and perplexity is 54.477809062532636
At time: 296.5303337574005 and batch: 550, loss is 3.972572956085205 and perplexity is 53.12103324276119
At time: 297.6766474246979 and batch: 600, loss is 3.9256431245803833 and perplexity is 50.68566477594655
At time: 298.8229515552521 and batch: 650, loss is 3.9722772455215454 and perplexity is 53.10532711442726
At time: 299.9705970287323 and batch: 700, loss is 4.007695631980896 and perplexity is 55.01993818421013
At time: 301.1159086227417 and batch: 750, loss is 3.951109595298767 and perplexity is 51.99302605699618
At time: 302.2626693248749 and batch: 800, loss is 3.9494174098968506 and perplexity is 51.90511861612201
At time: 303.40862798690796 and batch: 850, loss is 3.9487352418899535 and perplexity is 51.869722679168405
At time: 304.55466866493225 and batch: 900, loss is 3.9074497509002684 and perplexity is 49.77185934387392
At time: 305.7002730369568 and batch: 950, loss is 3.9938476991653444 and perplexity is 54.2632769653193
At time: 306.8457646369934 and batch: 1000, loss is 3.955506319999695 and perplexity is 52.22212835974555
At time: 307.99172854423523 and batch: 1050, loss is 3.9013881921768188 and perplexity is 49.47107682210288
At time: 309.13851857185364 and batch: 1100, loss is 3.913752064704895 and perplexity is 50.08652774808292
At time: 310.2853994369507 and batch: 1150, loss is 3.887110071182251 and perplexity is 48.76974159090293
At time: 311.4318656921387 and batch: 1200, loss is 3.9291322374343873 and perplexity is 50.86282166088798
At time: 312.5784273147583 and batch: 1250, loss is 3.920265865325928 and perplexity is 50.41384629016307
At time: 313.72420501708984 and batch: 1300, loss is 3.9062715435028075 and perplexity is 49.71325230341361
At time: 314.8722882270813 and batch: 1350, loss is 3.792501049041748 and perplexity is 44.36722623629546
At time: 316.01988768577576 and batch: 1400, loss is 3.8080457878112792 and perplexity is 45.06229148575532
At time: 317.16300535202026 and batch: 1450, loss is 3.74879075050354 and perplexity is 42.46969447949388
At time: 318.3099911212921 and batch: 1500, loss is 3.7362446117401125 and perplexity is 41.94019234845132
At time: 319.4549889564514 and batch: 1550, loss is 3.7596399354934693 and perplexity is 42.93296455867805
At time: 320.5993962287903 and batch: 1600, loss is 3.832452402114868 and perplexity is 46.17564073011052
At time: 321.7450830936432 and batch: 1650, loss is 3.7827691650390625 and perplexity is 43.93754373840488
At time: 322.8908386230469 and batch: 1700, loss is 3.7625630855560304 and perplexity is 43.05864766250529
At time: 324.0363314151764 and batch: 1750, loss is 3.7561320066452026 and perplexity is 42.78262262233902
At time: 325.1807188987732 and batch: 1800, loss is 3.7117132425308226 and perplexity is 40.92385899717913
At time: 326.3251943588257 and batch: 1850, loss is 3.747569079399109 and perplexity is 42.41784216062316
At time: 327.4765508174896 and batch: 1900, loss is 3.824688882827759 and perplexity is 45.818543213025215
At time: 328.6231207847595 and batch: 1950, loss is 3.751093378067017 and perplexity is 42.56759904423123
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360651060592296 and perplexity of 78.30810114878616
finished 7 epochs...
Completing Train Step...
At time: 332.24840664863586 and batch: 50, loss is 3.964857048988342 and perplexity is 52.712733512446654
At time: 333.3912284374237 and batch: 100, loss is 3.9267151403427123 and perplexity is 50.74002974235451
At time: 334.51084184646606 and batch: 150, loss is 3.8911097288131713 and perplexity is 48.965194471759034
At time: 335.6319487094879 and batch: 200, loss is 3.8888202238082887 and perplexity is 48.85321664975693
At time: 336.75955867767334 and batch: 250, loss is 3.8834076833724978 and perplexity is 48.589510941909396
At time: 337.8958086967468 and batch: 300, loss is 3.8941475105285646 and perplexity is 49.1141662014536
At time: 339.0390450954437 and batch: 350, loss is 3.9038276195526125 and perplexity is 49.59190523736583
At time: 340.18319749832153 and batch: 400, loss is 3.8444554519653322 and perplexity is 46.73322893272325
At time: 341.32681941986084 and batch: 450, loss is 3.890190987586975 and perplexity is 48.92022878802572
At time: 342.49359703063965 and batch: 500, loss is 3.899545521736145 and perplexity is 49.38000186750777
At time: 343.63710021972656 and batch: 550, loss is 3.8772201108932496 and perplexity is 48.289788056031725
At time: 344.78233528137207 and batch: 600, loss is 3.836600661277771 and perplexity is 46.3675871012667
At time: 345.92720437049866 and batch: 650, loss is 3.8828728723526003 and perplexity is 48.563531683622266
At time: 347.0716407299042 and batch: 700, loss is 3.92155574798584 and perplexity is 50.47891619356034
At time: 348.21636271476746 and batch: 750, loss is 3.8674531984329223 and perplexity is 47.820441686818995
At time: 349.3615515232086 and batch: 800, loss is 3.8653319025039674 and perplexity is 47.71910789602615
At time: 350.5045323371887 and batch: 850, loss is 3.8682742977142333 and perplexity is 47.859723141900304
At time: 351.6494643688202 and batch: 900, loss is 3.8274667167663576 and perplexity is 45.94599645739714
At time: 352.7927076816559 and batch: 950, loss is 3.918007116317749 and perplexity is 50.300102572470976
At time: 353.93636679649353 and batch: 1000, loss is 3.882072186470032 and perplexity is 48.52466311223027
At time: 355.0883889198303 and batch: 1050, loss is 3.833352746963501 and perplexity is 46.21723345146074
At time: 356.2324728965759 and batch: 1100, loss is 3.844659605026245 and perplexity is 46.74277063840728
At time: 357.3819055557251 and batch: 1150, loss is 3.8222420024871826 and perplexity is 45.70656777152512
At time: 358.52622151374817 and batch: 1200, loss is 3.866969265937805 and perplexity is 47.79730541980313
At time: 359.6694960594177 and batch: 1250, loss is 3.8614493370056153 and perplexity is 47.534194535500575
At time: 360.8141539096832 and batch: 1300, loss is 3.8490133905410766 and perplexity is 46.94672229485349
At time: 361.965482711792 and batch: 1350, loss is 3.7359097385406494 and perplexity is 41.92615005337886
At time: 363.11613392829895 and batch: 1400, loss is 3.7566999578475953 and perplexity is 42.80692796577006
At time: 364.2689232826233 and batch: 1450, loss is 3.7002326345443723 and perplexity is 40.45671489485358
At time: 365.4220037460327 and batch: 1500, loss is 3.6892438554763793 and perplexity is 40.0145787105874
At time: 366.57311034202576 and batch: 1550, loss is 3.716592102050781 and perplexity is 41.12400861014549
At time: 367.7240033149719 and batch: 1600, loss is 3.7928917932510378 and perplexity is 44.38456586048778
At time: 368.876437664032 and batch: 1650, loss is 3.7450425386428834 and perplexity is 42.310807024867024
At time: 370.03620982170105 and batch: 1700, loss is 3.731976475715637 and perplexity is 41.76156737163198
At time: 371.1880671977997 and batch: 1750, loss is 3.727414493560791 and perplexity is 41.571485750665325
At time: 372.3401575088501 and batch: 1800, loss is 3.6877354907989504 and perplexity is 39.9542676304644
At time: 373.4923412799835 and batch: 1850, loss is 3.728154878616333 and perplexity is 41.602276054385634
At time: 374.6464030742645 and batch: 1900, loss is 3.808261389732361 and perplexity is 45.07200804978529
At time: 375.7988531589508 and batch: 1950, loss is 3.7362667608261106 and perplexity is 41.94112129566605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362255291606105 and perplexity of 78.4338262523733
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 379.4567289352417 and batch: 50, loss is 3.936582531929016 and perplexity is 51.24317979176053
At time: 380.60352540016174 and batch: 100, loss is 3.9270223331451417 and perplexity is 50.75561910863438
At time: 381.7332181930542 and batch: 150, loss is 3.9046112632751466 and perplexity is 49.63078285370404
At time: 382.85454511642456 and batch: 200, loss is 3.913558073043823 and perplexity is 50.07681232175407
At time: 383.9762945175171 and batch: 250, loss is 3.9164145755767823 and perplexity is 50.22006136121107
At time: 385.10901737213135 and batch: 300, loss is 3.9266665887832644 and perplexity is 50.73756629458668
At time: 386.24756503105164 and batch: 350, loss is 3.936298661231995 and perplexity is 51.22863541905374
At time: 387.39191007614136 and batch: 400, loss is 3.8811037349700928 and perplexity is 48.47769207771078
At time: 388.53953075408936 and batch: 450, loss is 3.9209807538986206 and perplexity is 50.449899458244865
At time: 389.69334840774536 and batch: 500, loss is 3.9234691286087036 and perplexity is 50.57559403492741
At time: 390.84001874923706 and batch: 550, loss is 3.9070885372161865 and perplexity is 49.75388431380557
At time: 391.9880473613739 and batch: 600, loss is 3.8600658226013183 and perplexity is 47.46847576457991
At time: 393.13492488861084 and batch: 650, loss is 3.8883407592773436 and perplexity is 48.829798879594506
At time: 394.2822370529175 and batch: 700, loss is 3.923916392326355 and perplexity is 50.59821972258532
At time: 395.4360704421997 and batch: 750, loss is 3.86045756816864 and perplexity is 47.487074972388946
At time: 396.5826005935669 and batch: 800, loss is 3.8580333614349365 and perplexity is 47.37209590829657
At time: 397.72891116142273 and batch: 850, loss is 3.8653685951232912 and perplexity is 47.72085886721032
At time: 398.8740110397339 and batch: 900, loss is 3.8198163175582884 and perplexity is 45.59583239779059
At time: 400.0441279411316 and batch: 950, loss is 3.915945358276367 and perplexity is 50.196502767074676
At time: 401.19077730178833 and batch: 1000, loss is 3.878444585800171 and perplexity is 48.34895390592369
At time: 402.33645486831665 and batch: 1050, loss is 3.819770851135254 and perplexity is 45.59375936551322
At time: 403.48211216926575 and batch: 1100, loss is 3.8317021703720093 and perplexity is 46.14101129036468
At time: 404.6288447380066 and batch: 1150, loss is 3.8139977169036867 and perplexity is 45.331298811542254
At time: 405.77663946151733 and batch: 1200, loss is 3.84846351146698 and perplexity is 46.92091437093507
At time: 406.92996549606323 and batch: 1250, loss is 3.8351552295684814 and perplexity is 46.300614334528
At time: 408.0855257511139 and batch: 1300, loss is 3.821354284286499 and perplexity is 45.666011223479856
At time: 409.2419741153717 and batch: 1350, loss is 3.7045359230041504 and perplexity is 40.631186941710425
At time: 410.39721727371216 and batch: 1400, loss is 3.7198403882980347 and perplexity is 41.25780835403228
At time: 411.55241990089417 and batch: 1450, loss is 3.6569956731796265 and perplexity is 38.744765902011274
At time: 412.7087652683258 and batch: 1500, loss is 3.6540503549575805 and perplexity is 38.63081812559607
At time: 413.86329984664917 and batch: 1550, loss is 3.6779082679748534 and perplexity is 39.563551113250476
At time: 415.0236904621124 and batch: 1600, loss is 3.7503309202194215 and perplexity is 42.53515541430852
At time: 416.1776888370514 and batch: 1650, loss is 3.7006143045425417 and perplexity is 40.47215895623339
At time: 417.33074045181274 and batch: 1700, loss is 3.677916169166565 and perplexity is 39.56386371368757
At time: 418.48657155036926 and batch: 1750, loss is 3.6744318532943727 and perplexity is 39.42625059838946
At time: 419.6405029296875 and batch: 1800, loss is 3.6300146341323853 and perplexity is 37.71336851557102
At time: 420.79490637779236 and batch: 1850, loss is 3.6687432289123536 and perplexity is 39.20260618557613
At time: 421.94934129714966 and batch: 1900, loss is 3.7478360605239867 and perplexity is 42.429168435721635
At time: 423.10422468185425 and batch: 1950, loss is 3.6830036306381224 and perplexity is 39.76565621655163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333622422329215 and perplexity of 76.21988771914316
finished 9 epochs...
Completing Train Step...
At time: 426.75379490852356 and batch: 50, loss is 3.9196564674377443 and perplexity is 50.38313355778623
At time: 427.9013247489929 and batch: 100, loss is 3.8926773500442504 and perplexity is 49.0420135460713
At time: 429.021431684494 and batch: 150, loss is 3.862707943916321 and perplexity is 47.59405906629129
At time: 430.1423752307892 and batch: 200, loss is 3.865705895423889 and perplexity is 47.73695784219293
At time: 431.263085603714 and batch: 250, loss is 3.8682018089294434 and perplexity is 47.85625397446876
At time: 432.38692259788513 and batch: 300, loss is 3.874080710411072 and perplexity is 48.138424791394954
At time: 433.52847504615784 and batch: 350, loss is 3.885137495994568 and perplexity is 48.67363442919544
At time: 434.6763083934784 and batch: 400, loss is 3.82922034740448 and perplexity is 46.026639452831425
At time: 435.8232843875885 and batch: 450, loss is 3.8724239253997803 and perplexity is 48.058735802722815
At time: 436.9695768356323 and batch: 500, loss is 3.8777070569992067 and perplexity is 48.313308306365506
At time: 438.1199486255646 and batch: 550, loss is 3.8617395544052124 and perplexity is 47.547991787835116
At time: 439.2745761871338 and batch: 600, loss is 3.818716468811035 and perplexity is 45.54571144643316
At time: 440.42877101898193 and batch: 650, loss is 3.847938003540039 and perplexity is 46.896263536165655
At time: 441.5834491252899 and batch: 700, loss is 3.886492524147034 and perplexity is 48.739633279181334
At time: 442.7365598678589 and batch: 750, loss is 3.8247685050964355 and perplexity is 45.82219153462518
At time: 443.8911945819855 and batch: 800, loss is 3.823052191734314 and perplexity is 45.743613746355685
At time: 445.0442612171173 and batch: 850, loss is 3.8311853885650633 and perplexity is 46.11717261540302
At time: 446.19786071777344 and batch: 900, loss is 3.7862302255630493 and perplexity is 44.08987770302794
At time: 447.3522324562073 and batch: 950, loss is 3.8836645793914797 and perplexity is 48.601994997318066
At time: 448.5065019130707 and batch: 1000, loss is 3.847773399353027 and perplexity is 46.888544850113846
At time: 449.66016960144043 and batch: 1050, loss is 3.793426923751831 and perplexity is 44.40832375166336
At time: 450.81440567970276 and batch: 1100, loss is 3.805845146179199 and perplexity is 44.96323456544249
At time: 451.9685127735138 and batch: 1150, loss is 3.789311532974243 and perplexity is 44.22594168978386
At time: 453.12355732917786 and batch: 1200, loss is 3.8250390243530275 and perplexity is 45.83458899661504
At time: 454.27781915664673 and batch: 1250, loss is 3.8142942237854003 and perplexity is 45.34474184647459
At time: 455.43220138549805 and batch: 1300, loss is 3.8021895265579224 and perplexity is 44.79916615149701
At time: 456.58723878860474 and batch: 1350, loss is 3.6860306310653685 and perplexity is 39.886209239885865
At time: 457.74127221107483 and batch: 1400, loss is 3.704520344734192 and perplexity is 40.63055398304173
At time: 458.8962435722351 and batch: 1450, loss is 3.6439485931396485 and perplexity is 38.24254323410247
At time: 460.0492293834686 and batch: 1500, loss is 3.643356137275696 and perplexity is 38.219892925427594
At time: 461.20440340042114 and batch: 1550, loss is 3.669048285484314 and perplexity is 39.21456702250421
At time: 462.35598492622375 and batch: 1600, loss is 3.7444158124923708 and perplexity is 42.284298043458875
At time: 463.50177693367004 and batch: 1650, loss is 3.6954928970336915 and perplexity is 40.26541440090313
At time: 464.64729619026184 and batch: 1700, loss is 3.676480703353882 and perplexity is 39.50711188231085
At time: 465.79301953315735 and batch: 1750, loss is 3.674692840576172 and perplexity is 39.436541691228435
At time: 466.93856954574585 and batch: 1800, loss is 3.6317083120346068 and perplexity is 37.77729693623908
At time: 468.0820093154907 and batch: 1850, loss is 3.6723676538467407 and perplexity is 39.34495089195424
At time: 469.2272984981537 and batch: 1900, loss is 3.7520349264144897 and perplexity is 42.60769737106158
At time: 470.3747980594635 and batch: 1950, loss is 3.687222790718079 and perplexity is 39.933788324538604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333393895348837 and perplexity of 76.20247140848215
finished 10 epochs...
Completing Train Step...
At time: 474.0528175830841 and batch: 50, loss is 3.901298789978027 and perplexity is 49.46665419675755
At time: 475.18182945251465 and batch: 100, loss is 3.871666989326477 and perplexity is 48.022372176162946
At time: 476.3036324977875 and batch: 150, loss is 3.8410593366622923 and perplexity is 46.57478669512231
At time: 477.4257094860077 and batch: 200, loss is 3.8433820247650146 and perplexity is 46.68309112808408
At time: 478.5472135543823 and batch: 250, loss is 3.844943995475769 and perplexity is 46.75606572636955
At time: 479.6737427711487 and batch: 300, loss is 3.850345702171326 and perplexity is 47.009311643969596
At time: 480.81190633773804 and batch: 350, loss is 3.8615017127990723 and perplexity is 47.53668424185531
At time: 481.95746088027954 and batch: 400, loss is 3.8054142808914184 and perplexity is 44.943865641440055
At time: 483.10295724868774 and batch: 450, loss is 3.8495997762680054 and perplexity is 46.974259255584606
At time: 484.24975848197937 and batch: 500, loss is 3.8555010557174683 and perplexity is 47.25228703934504
At time: 485.41910004615784 and batch: 550, loss is 3.839939923286438 and perplexity is 46.52267942614642
At time: 486.56648540496826 and batch: 600, loss is 3.798015289306641 and perplexity is 44.61255355690842
At time: 487.713152885437 and batch: 650, loss is 3.827272810935974 and perplexity is 45.93708812451803
At time: 488.8582000732422 and batch: 700, loss is 3.866930937767029 and perplexity is 47.79547347162619
At time: 490.00749158859253 and batch: 750, loss is 3.8057139921188354 and perplexity is 44.95733784136026
At time: 491.1545960903168 and batch: 800, loss is 3.8038196992874145 and perplexity is 44.87225608888638
At time: 492.3014245033264 and batch: 850, loss is 3.8122553205490113 and perplexity is 45.25238249345826
At time: 493.4498267173767 and batch: 900, loss is 3.7674249744415285 and perplexity is 43.2685037581289
At time: 494.599707365036 and batch: 950, loss is 3.865651235580444 and perplexity is 47.73434861886126
At time: 495.754759311676 and batch: 1000, loss is 3.8308085346221925 and perplexity is 46.09979645141246
At time: 496.9033443927765 and batch: 1050, loss is 3.7781191873550415 and perplexity is 43.73370942032605
At time: 498.0500109195709 and batch: 1100, loss is 3.7906843328475954 and perplexity is 44.28669674966226
At time: 499.1963884830475 and batch: 1150, loss is 3.7745944118499755 and perplexity is 43.57982926842843
At time: 500.34294176101685 and batch: 1200, loss is 3.810407767295837 and perplexity is 45.16885349286718
At time: 501.4890446662903 and batch: 1250, loss is 3.8010326528549196 and perplexity is 44.74736914133628
At time: 502.63551902770996 and batch: 1300, loss is 3.789063606262207 and perplexity is 44.21497825659415
At time: 503.78205156326294 and batch: 1350, loss is 3.673129663467407 and perplexity is 39.37494354895386
At time: 504.92869234085083 and batch: 1400, loss is 3.693183159828186 and perplexity is 40.17251919821797
At time: 506.07543540000916 and batch: 1450, loss is 3.6336196517944335 and perplexity is 37.84957123425898
At time: 507.22211265563965 and batch: 1500, loss is 3.634013533592224 and perplexity is 37.864482427853424
At time: 508.3699746131897 and batch: 1550, loss is 3.6604281520843505 and perplexity is 38.87798499871002
At time: 509.51622104644775 and batch: 1600, loss is 3.737212586402893 and perplexity is 41.9808090467928
At time: 510.66146898269653 and batch: 1650, loss is 3.6880598735809325 and perplexity is 39.967230209255455
At time: 511.8161242008209 and batch: 1700, loss is 3.6706565761566163 and perplexity is 39.2776861882423
At time: 512.9708619117737 and batch: 1750, loss is 3.669538097381592 and perplexity is 39.23377948884161
At time: 514.1261715888977 and batch: 1800, loss is 3.627166271209717 and perplexity is 37.606099997361326
At time: 515.281379699707 and batch: 1850, loss is 3.668844199180603 and perplexity is 39.20656468308068
At time: 516.4351708889008 and batch: 1900, loss is 3.748813409805298 and perplexity is 42.47065682401965
At time: 517.5906777381897 and batch: 1950, loss is 3.684051718711853 and perplexity is 39.80735597526894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334880030432413 and perplexity of 76.31580276669266
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 521.2546365261078 and batch: 50, loss is 3.894601655006409 and perplexity is 49.13647619441452
At time: 522.3747234344482 and batch: 100, loss is 3.8796612882614134 and perplexity is 48.407815998704656
At time: 523.4942331314087 and batch: 150, loss is 3.858444151878357 and perplexity is 47.39155991011976
At time: 524.6191823482513 and batch: 200, loss is 3.870425901412964 and perplexity is 47.96280915959227
At time: 525.7451424598694 and batch: 250, loss is 3.88172559261322 and perplexity is 48.507847676323436
At time: 526.8855166435242 and batch: 300, loss is 3.887219548225403 and perplexity is 48.775081050276356
At time: 528.0292675495148 and batch: 350, loss is 3.8989074754714967 and perplexity is 49.348505191004804
At time: 529.1724872589111 and batch: 400, loss is 3.8499258852005003 and perplexity is 46.98958047918334
At time: 530.3187775611877 and batch: 450, loss is 3.8941002893447876 and perplexity is 49.11184702714286
At time: 531.4774351119995 and batch: 500, loss is 3.9009568881988526 and perplexity is 49.449744350595836
At time: 532.6291108131409 and batch: 550, loss is 3.883696103096008 and perplexity is 48.603527136397076
At time: 533.7811217308044 and batch: 600, loss is 3.8351460981369017 and perplexity is 46.30019154556644
At time: 534.9346594810486 and batch: 650, loss is 3.8554023265838624 and perplexity is 47.247622092271634
At time: 536.0852746963501 and batch: 700, loss is 3.8941099548339846 and perplexity is 49.11232171946381
At time: 537.2373993396759 and batch: 750, loss is 3.829071841239929 and perplexity is 46.01980472065161
At time: 538.3899216651917 and batch: 800, loss is 3.8207816314697265 and perplexity is 45.639867939748925
At time: 539.541403055191 and batch: 850, loss is 3.8270477867126464 and perplexity is 45.92675232988656
At time: 540.6930351257324 and batch: 900, loss is 3.774915647506714 and perplexity is 43.593830912297264
At time: 541.8861749172211 and batch: 950, loss is 3.874949126243591 and perplexity is 48.180247118593535
At time: 543.0372326374054 and batch: 1000, loss is 3.8441449117660524 and perplexity is 46.718718639628754
At time: 544.1897006034851 and batch: 1050, loss is 3.791924090385437 and perplexity is 44.341635564151716
At time: 545.3411560058594 and batch: 1100, loss is 3.801385555267334 and perplexity is 44.76316338260446
At time: 546.4929580688477 and batch: 1150, loss is 3.7944354677200316 and perplexity is 44.4531340915217
At time: 547.6434488296509 and batch: 1200, loss is 3.8268277740478513 and perplexity is 45.91664897419494
At time: 548.7947602272034 and batch: 1250, loss is 3.8171254777908326 and perplexity is 45.47330624180133
At time: 549.9468765258789 and batch: 1300, loss is 3.7981828117370604 and perplexity is 44.620027786340565
At time: 551.098851442337 and batch: 1350, loss is 3.6757702827453613 and perplexity is 39.479055183055216
At time: 552.2507696151733 and batch: 1400, loss is 3.6924253940582275 and perplexity is 40.1420893690741
At time: 553.4010212421417 and batch: 1450, loss is 3.625025095939636 and perplexity is 37.525664889605025
At time: 554.5557053089142 and batch: 1500, loss is 3.6242383527755737 and perplexity is 37.49615343976416
At time: 555.7068452835083 and batch: 1550, loss is 3.6518458557128906 and perplexity is 38.54575031662791
At time: 556.8605344295502 and batch: 1600, loss is 3.729232602119446 and perplexity is 41.64713597402529
At time: 558.011385679245 and batch: 1650, loss is 3.682562565803528 and perplexity is 39.748120851370686
At time: 559.1612997055054 and batch: 1700, loss is 3.657722415924072 and perplexity is 38.77293361361608
At time: 560.3126254081726 and batch: 1750, loss is 3.6577092027664184 and perplexity is 38.772421304116165
At time: 561.464985370636 and batch: 1800, loss is 3.6147079563140867 and perplexity is 37.14049769380167
At time: 562.617124080658 and batch: 1850, loss is 3.6505700302124025 and perplexity is 38.49660402315216
At time: 563.76802110672 and batch: 1900, loss is 3.736054220199585 and perplexity is 41.93220805071557
At time: 564.9233849048615 and batch: 1950, loss is 3.6795566511154174 and perplexity is 39.62882078381963
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320698298964389 and perplexity of 75.24115076935477
finished 12 epochs...
Completing Train Step...
At time: 568.5793745517731 and batch: 50, loss is 3.9001646184921266 and perplexity is 49.41058233163063
At time: 569.6984841823578 and batch: 100, loss is 3.874507565498352 and perplexity is 48.158977309072114
At time: 570.8408944606781 and batch: 150, loss is 3.8455287265777587 and perplexity is 46.78341344695861
At time: 571.9605414867401 and batch: 200, loss is 3.8511950063705442 and perplexity is 47.049253808874454
At time: 573.0813720226288 and batch: 250, loss is 3.859391460418701 and perplexity is 47.4364756107173
At time: 574.2115061283112 and batch: 300, loss is 3.8620416212081907 and perplexity is 47.56235662716383
At time: 575.3485267162323 and batch: 350, loss is 3.8718810367584227 and perplexity is 48.03265234178547
At time: 576.4934606552124 and batch: 400, loss is 3.82122483253479 and perplexity is 45.66010006094683
At time: 577.6400282382965 and batch: 450, loss is 3.8672052335739138 and perplexity is 47.80858536777439
At time: 578.7855052947998 and batch: 500, loss is 3.874193434715271 and perplexity is 48.14385146768821
At time: 579.9308431148529 and batch: 550, loss is 3.8578732633590698 and perplexity is 47.364512333965905
At time: 581.0759224891663 and batch: 600, loss is 3.8132063913345338 and perplexity is 45.295441185109254
At time: 582.221973657608 and batch: 650, loss is 3.8355803155899046 and perplexity is 46.320300262274834
At time: 583.3683485984802 and batch: 700, loss is 3.876286687850952 and perplexity is 48.244734285537525
At time: 584.5138010978699 and batch: 750, loss is 3.813732843399048 and perplexity is 45.31929334159185
At time: 585.6600880622864 and batch: 800, loss is 3.8067156791687013 and perplexity is 45.002393586583324
At time: 586.8067419528961 and batch: 850, loss is 3.813566370010376 and perplexity is 45.31174951319782
At time: 587.952743768692 and batch: 900, loss is 3.7628841686248777 and perplexity is 43.07247528502612
At time: 589.1060106754303 and batch: 950, loss is 3.862902841567993 and perplexity is 47.603335940628
At time: 590.2603628635406 and batch: 1000, loss is 3.830845627784729 and perplexity is 46.10150647036994
At time: 591.4158778190613 and batch: 1050, loss is 3.779819493293762 and perplexity is 43.80813335997879
At time: 592.5687828063965 and batch: 1100, loss is 3.790660095214844 and perplexity is 44.285623357978956
At time: 593.7238330841064 and batch: 1150, loss is 3.784524450302124 and perplexity is 44.01473438740947
At time: 594.8813424110413 and batch: 1200, loss is 3.8169180583953857 and perplexity is 45.46387517423866
At time: 596.0342137813568 and batch: 1250, loss is 3.8085150718688965 and perplexity is 45.08344346350407
At time: 597.1865470409393 and batch: 1300, loss is 3.791051092147827 and perplexity is 44.30294228649049
At time: 598.3394799232483 and batch: 1350, loss is 3.669571294784546 and perplexity is 39.2350819700481
At time: 599.493992805481 and batch: 1400, loss is 3.68751823425293 and perplexity is 39.94558824714079
At time: 600.6491026878357 and batch: 1450, loss is 3.621576008796692 and perplexity is 37.39645855135258
At time: 601.8018615245819 and batch: 1500, loss is 3.6235431432724 and perplexity is 37.47009481671111
At time: 602.95645403862 and batch: 1550, loss is 3.6523630475997924 and perplexity is 38.56569102210727
At time: 604.1106238365173 and batch: 1600, loss is 3.730975098609924 and perplexity is 41.71976922551341
At time: 605.2641534805298 and batch: 1650, loss is 3.685270881652832 and perplexity is 39.85591722447511
At time: 606.4172234535217 and batch: 1700, loss is 3.6612473344802856 and perplexity is 38.9098462078995
At time: 607.5701186656952 and batch: 1750, loss is 3.6624089813232423 and perplexity is 38.955071971003576
At time: 608.7227845191956 and batch: 1800, loss is 3.6196808290481566 and perplexity is 37.32565265658087
At time: 609.8774948120117 and batch: 1850, loss is 3.656157822608948 and perplexity is 38.712317173280645
At time: 611.0327785015106 and batch: 1900, loss is 3.7423319578170777 and perplexity is 42.19627545628225
At time: 612.1871476173401 and batch: 1950, loss is 3.685298104286194 and perplexity is 39.85700222226519
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319419115643169 and perplexity of 75.14496507690373
finished 13 epochs...
Completing Train Step...
At time: 615.8671219348907 and batch: 50, loss is 3.895847840309143 and perplexity is 49.19774751865861
At time: 617.0088353157043 and batch: 100, loss is 3.868362398147583 and perplexity is 47.86393978999065
At time: 618.1275780200958 and batch: 150, loss is 3.8382454204559324 and perplexity is 46.443913367677624
At time: 619.2470662593842 and batch: 200, loss is 3.8431102561950685 and perplexity is 46.67040585497488
At time: 620.3729205131531 and batch: 250, loss is 3.850212059020996 and perplexity is 47.00302959125266
At time: 621.5188546180725 and batch: 300, loss is 3.85240234375 and perplexity is 47.10609243646896
At time: 622.6552836894989 and batch: 350, loss is 3.8621240425109864 and perplexity is 47.566276940117504
At time: 623.800365447998 and batch: 400, loss is 3.8108607149124145 and perplexity is 45.1893172515558
At time: 624.9394586086273 and batch: 450, loss is 3.857237319946289 and perplexity is 47.33440075999093
At time: 626.0862550735474 and batch: 500, loss is 3.8642437791824342 and perplexity is 47.66721186160486
At time: 627.2323412895203 and batch: 550, loss is 3.8476356935501097 and perplexity is 46.882088469948336
At time: 628.400886297226 and batch: 600, loss is 3.8038058996200563 and perplexity is 44.87163687095126
At time: 629.5468184947968 and batch: 650, loss is 3.8266641807556154 and perplexity is 45.909137932815554
At time: 630.6928119659424 and batch: 700, loss is 3.868311324119568 and perplexity is 47.861495248215725
At time: 631.8382761478424 and batch: 750, loss is 3.8063911390304566 and perplexity is 44.98779087325886
At time: 632.9843895435333 and batch: 800, loss is 3.799779944419861 and perplexity is 44.69134883045019
At time: 634.1323511600494 and batch: 850, loss is 3.806539173126221 and perplexity is 44.994451093158865
At time: 635.2857868671417 and batch: 900, loss is 3.7564583110809324 and perplexity is 42.796585059751585
At time: 636.4382665157318 and batch: 950, loss is 3.856657614707947 and perplexity is 47.30696871193579
At time: 637.5920820236206 and batch: 1000, loss is 3.824459881782532 and perplexity is 45.80805192004303
At time: 638.7458202838898 and batch: 1050, loss is 3.774072289466858 and perplexity is 43.55708120326873
At time: 639.8992493152618 and batch: 1100, loss is 3.785256266593933 and perplexity is 44.046956876146865
At time: 641.0504214763641 and batch: 1150, loss is 3.779521594047546 and perplexity is 43.795084893733346
At time: 642.2049753665924 and batch: 1200, loss is 3.8119704246521 and perplexity is 45.23949211165604
At time: 643.3588080406189 and batch: 1250, loss is 3.804070973396301 and perplexity is 44.88353274175497
At time: 644.5142214298248 and batch: 1300, loss is 3.7871277570724486 and perplexity is 44.12946752140902
At time: 645.6760079860687 and batch: 1350, loss is 3.6659739208221436 and perplexity is 39.09419227615344
At time: 646.8290643692017 and batch: 1400, loss is 3.6844628190994264 and perplexity is 39.82372415899146
At time: 647.9841203689575 and batch: 1450, loss is 3.619101881980896 and perplexity is 37.304049333635405
At time: 649.1369016170502 and batch: 1500, loss is 3.622000288963318 and perplexity is 37.41232849343074
At time: 650.2909071445465 and batch: 1550, loss is 3.6514605617523195 and perplexity is 38.53090173254381
At time: 651.4444251060486 and batch: 1600, loss is 3.730614538192749 and perplexity is 41.70472943965568
At time: 652.5985629558563 and batch: 1650, loss is 3.6851813077926634 and perplexity is 39.85234733600547
At time: 653.7510371208191 and batch: 1700, loss is 3.661703109741211 and perplexity is 38.927584395213884
At time: 654.9041879177094 and batch: 1750, loss is 3.663208494186401 and perplexity is 38.986229505894926
At time: 656.0630269050598 and batch: 1800, loss is 3.620594220161438 and perplexity is 37.35976115084125
At time: 657.2151684761047 and batch: 1850, loss is 3.657349872589111 and perplexity is 38.75849170590671
At time: 658.3662555217743 and batch: 1900, loss is 3.743697543144226 and perplexity is 42.253937433119624
At time: 659.5179522037506 and batch: 1950, loss is 3.6863443851470947 and perplexity is 39.898725664276405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319364325944767 and perplexity of 75.14084801971798
finished 14 epochs...
Completing Train Step...
At time: 663.1582522392273 and batch: 50, loss is 3.891040906906128 and perplexity is 48.961824709654785
At time: 664.2976739406586 and batch: 100, loss is 3.862796468734741 and perplexity is 47.59827250822235
At time: 665.4139726161957 and batch: 150, loss is 3.832181525230408 and perplexity is 46.163134510311
At time: 666.5318119525909 and batch: 200, loss is 3.836814675331116 and perplexity is 46.37751147846628
At time: 667.649799823761 and batch: 250, loss is 3.8434270191192628 and perplexity is 46.685191650879176
At time: 668.7784028053284 and batch: 300, loss is 3.8453801679611206 and perplexity is 46.77646388399683
At time: 669.9211099147797 and batch: 350, loss is 3.8551445150375367 and perplexity is 47.235442679823855
At time: 671.0635976791382 and batch: 400, loss is 3.803622546195984 and perplexity is 44.86341025689921
At time: 672.2056560516357 and batch: 450, loss is 3.850198678970337 and perplexity is 47.00240069254296
At time: 673.3478467464447 and batch: 500, loss is 3.857288737297058 and perplexity is 47.33683463204934
At time: 674.4979944229126 and batch: 550, loss is 3.8405243015289305 and perplexity is 46.549874213032474
At time: 675.6457388401031 and batch: 600, loss is 3.7972391271591186 and perplexity is 44.5779404159758
At time: 676.7880847454071 and batch: 650, loss is 3.820262770652771 and perplexity is 45.6161933430254
At time: 677.9307088851929 and batch: 700, loss is 3.8624973583221434 and perplexity is 47.58403749831945
At time: 679.0807893276215 and batch: 750, loss is 3.800876326560974 and perplexity is 44.740374497692194
At time: 680.2311496734619 and batch: 800, loss is 3.794475626945496 and perplexity is 44.454919330802944
At time: 681.383579492569 and batch: 850, loss is 3.801139693260193 and perplexity is 44.75215917422303
At time: 682.5337278842926 and batch: 900, loss is 3.751345934867859 and perplexity is 42.57835113856549
At time: 683.684374332428 and batch: 950, loss is 3.851729097366333 and perplexity is 47.074389103362094
At time: 684.8341372013092 and batch: 1000, loss is 3.819568815231323 and perplexity is 45.584548719598125
At time: 686.0088860988617 and batch: 1050, loss is 3.769650783538818 and perplexity is 43.36491844796172
At time: 687.1598172187805 and batch: 1100, loss is 3.7810027599334717 and perplexity is 43.860000743151986
At time: 688.313015460968 and batch: 1150, loss is 3.775538191795349 and perplexity is 43.6209784521476
At time: 689.4645326137543 and batch: 1200, loss is 3.807961983680725 and perplexity is 45.05851523783137
At time: 690.6162233352661 and batch: 1250, loss is 3.800394697189331 and perplexity is 44.71883140754473
At time: 691.766951084137 and batch: 1300, loss is 3.7836715364456177 and perplexity is 43.97720961553377
At time: 692.919563293457 and batch: 1350, loss is 3.662684063911438 and perplexity is 38.9657893070334
At time: 694.070826292038 and batch: 1400, loss is 3.6815500259399414 and perplexity is 39.70789466325232
At time: 695.222071647644 and batch: 1450, loss is 3.6165348291397095 and perplexity is 37.20841067507048
At time: 696.3739087581635 and batch: 1500, loss is 3.619937801361084 and perplexity is 37.33524554837656
At time: 697.5248084068298 and batch: 1550, loss is 3.649815502166748 and perplexity is 38.46756821129896
At time: 698.677206993103 and batch: 1600, loss is 3.7293737363815307 and perplexity is 41.653014226630596
At time: 699.8291726112366 and batch: 1650, loss is 3.684034996032715 and perplexity is 39.80669029519363
At time: 700.9805371761322 and batch: 1700, loss is 3.660958127975464 and perplexity is 38.89859485433531
At time: 702.1314680576324 and batch: 1750, loss is 3.6626762771606445 and perplexity is 38.9654858913239
At time: 703.2811732292175 and batch: 1800, loss is 3.6201502513885497 and perplexity is 37.34317826494185
At time: 704.4326183795929 and batch: 1850, loss is 3.6571427679061888 and perplexity is 38.750465471935414
At time: 705.5838603973389 and batch: 1900, loss is 3.743551778793335 and perplexity is 42.247778764225174
At time: 706.7351539134979 and batch: 1950, loss is 3.6860150146484374 and perplexity is 39.885586365076115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31968625090843 and perplexity of 75.16504162854068
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 710.379298210144 and batch: 50, loss is 3.8903787326812744 and perplexity is 48.92941418322214
At time: 711.5286619663239 and batch: 100, loss is 3.868280725479126 and perplexity is 47.86003077393719
At time: 712.6531438827515 and batch: 150, loss is 3.8411891937255858 and perplexity is 46.580835152855045
At time: 713.8148276805878 and batch: 200, loss is 3.8493435430526732 and perplexity is 46.962224432024314
At time: 714.9479038715363 and batch: 250, loss is 3.8602532529830933 and perplexity is 47.47737363295413
At time: 716.0768945217133 and batch: 300, loss is 3.862826633453369 and perplexity is 47.59970831837503
At time: 717.2210781574249 and batch: 350, loss is 3.8746659660339358 and perplexity is 48.16660632107487
At time: 718.3688700199127 and batch: 400, loss is 3.8283183193206787 and perplexity is 45.985140850708035
At time: 719.5237691402435 and batch: 450, loss is 3.877975172996521 and perplexity is 48.3262636138906
At time: 720.6784672737122 and batch: 500, loss is 3.887508554458618 and perplexity is 48.78917938988135
At time: 721.8358798027039 and batch: 550, loss is 3.865447564125061 and perplexity is 47.72462748459867
At time: 722.9968371391296 and batch: 600, loss is 3.818732647895813 and perplexity is 45.54644834032103
At time: 724.1521708965302 and batch: 650, loss is 3.8352699756622313 and perplexity is 46.30592745398513
At time: 725.3061444759369 and batch: 700, loss is 3.881871199607849 and perplexity is 48.514911272481534
At time: 726.4603326320648 and batch: 750, loss is 3.8181705617904664 and perplexity is 45.52085450820361
At time: 727.6142122745514 and batch: 800, loss is 3.8114743614196778 and perplexity is 45.21705602828411
At time: 728.7694406509399 and batch: 850, loss is 3.816841163635254 and perplexity is 45.46037937486853
At time: 729.922595500946 and batch: 900, loss is 3.7668726110458373 and perplexity is 43.24461041997678
At time: 731.0838887691498 and batch: 950, loss is 3.869501481056213 and perplexity is 47.91849184950595
At time: 732.2384543418884 and batch: 1000, loss is 3.837229151725769 and perplexity is 46.396737846379445
At time: 733.3936984539032 and batch: 1050, loss is 3.7849758291244506 and perplexity is 44.03460619090052
At time: 734.5507333278656 and batch: 1100, loss is 3.786692042350769 and perplexity is 44.110243851072276
At time: 735.7064924240112 and batch: 1150, loss is 3.783370270729065 and perplexity is 43.96396278547503
At time: 736.8613269329071 and batch: 1200, loss is 3.8156660175323487 and perplexity is 45.4069881645902
At time: 738.0168130397797 and batch: 1250, loss is 3.8109572601318358 and perplexity is 45.19368027471648
At time: 739.1727800369263 and batch: 1300, loss is 3.7927080726623537 and perplexity is 44.37641225093532
At time: 740.3269412517548 and batch: 1350, loss is 3.6687352085113525 and perplexity is 39.20229176621512
At time: 741.4824066162109 and batch: 1400, loss is 3.688261365890503 and perplexity is 39.97528411014975
At time: 742.6363928318024 and batch: 1450, loss is 3.619026193618774 and perplexity is 37.30122595809051
At time: 743.7935230731964 and batch: 1500, loss is 3.614928712844849 and perplexity is 37.14869760628215
At time: 744.94895195961 and batch: 1550, loss is 3.645562319755554 and perplexity is 38.30430606473797
At time: 746.1017878055573 and batch: 1600, loss is 3.7247907447814943 and perplexity is 41.462555580863615
At time: 747.2588839530945 and batch: 1650, loss is 3.67569748878479 and perplexity is 39.47618145086527
At time: 748.4098546504974 and batch: 1700, loss is 3.6526665830612184 and perplexity is 38.577398853708026
At time: 749.5576906204224 and batch: 1750, loss is 3.654221158027649 and perplexity is 38.63741695146499
At time: 750.7057685852051 and batch: 1800, loss is 3.6131244325637817 and perplexity is 37.08173137481624
At time: 751.853994846344 and batch: 1850, loss is 3.648601770401001 and perplexity is 38.42090722449901
At time: 753.001161813736 and batch: 1900, loss is 3.7371527338027954 and perplexity is 41.97829646141029
At time: 754.1495413780212 and batch: 1950, loss is 3.68665723323822 and perplexity is 39.91120985716494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312813976199128 and perplexity of 74.6502577082146
finished 16 epochs...
Completing Train Step...
At time: 757.8418850898743 and batch: 50, loss is 3.8986309814453124 and perplexity is 49.33486251026514
At time: 758.9677748680115 and batch: 100, loss is 3.8709455633163454 and perplexity is 47.9877400815558
At time: 760.093652009964 and batch: 150, loss is 3.838108835220337 and perplexity is 46.43757024802643
At time: 761.2187280654907 and batch: 200, loss is 3.8418116331100465 and perplexity is 46.60983792451254
At time: 762.3430423736572 and batch: 250, loss is 3.8498152446746827 and perplexity is 46.98438181488795
At time: 763.4713196754456 and batch: 300, loss is 3.8502744817733765 and perplexity is 47.00596374130788
At time: 764.6202261447906 and batch: 350, loss is 3.860963921546936 and perplexity is 47.51112630194872
At time: 765.7717645168304 and batch: 400, loss is 3.8118773031234743 and perplexity is 45.235279537140094
At time: 766.9307191371918 and batch: 450, loss is 3.861460280418396 and perplexity is 47.5347147246589
At time: 768.0756325721741 and batch: 500, loss is 3.871426429748535 and perplexity is 48.01082132397025
At time: 769.2208118438721 and batch: 550, loss is 3.8516495418548584 and perplexity is 47.07064422522444
At time: 770.3651607036591 and batch: 600, loss is 3.808139977455139 and perplexity is 45.066536086837466
At time: 771.5344483852386 and batch: 650, loss is 3.8261150217056272 and perplexity is 45.88393343551491
At time: 772.6802985668182 and batch: 700, loss is 3.8727397966384887 and perplexity is 48.073918572905555
At time: 773.8273818492889 and batch: 750, loss is 3.81066951751709 and perplexity is 45.18067799772854
At time: 774.981360912323 and batch: 800, loss is 3.8037327480316163 and perplexity is 44.86835455949286
At time: 776.1298358440399 and batch: 850, loss is 3.810288014411926 and perplexity is 45.16344471626322
At time: 777.2774832248688 and batch: 900, loss is 3.760053629875183 and perplexity is 42.95072935925203
At time: 778.4222614765167 and batch: 950, loss is 3.862046489715576 and perplexity is 47.562588185412
At time: 779.5712900161743 and batch: 1000, loss is 3.829690251350403 and perplexity is 46.048272634688566
At time: 780.7255947589874 and batch: 1050, loss is 3.77794114112854 and perplexity is 43.725923491541046
At time: 781.8834598064423 and batch: 1100, loss is 3.7803075170516967 and perplexity is 43.82951798752794
At time: 783.0421833992004 and batch: 1150, loss is 3.77748459815979 and perplexity is 43.705965284855004
At time: 784.195827960968 and batch: 1200, loss is 3.8107442092895507 and perplexity is 45.184052748680664
At time: 785.350123167038 and batch: 1250, loss is 3.80636917591095 and perplexity is 44.986802811882065
At time: 786.5042762756348 and batch: 1300, loss is 3.789155430793762 and perplexity is 44.21903846267068
At time: 787.6590881347656 and batch: 1350, loss is 3.666389350891113 and perplexity is 39.110436553093955
At time: 788.8114187717438 and batch: 1400, loss is 3.6866123867034912 and perplexity is 39.909420017840354
At time: 789.9647164344788 and batch: 1450, loss is 3.6187426376342775 and perplexity is 37.29065047168312
At time: 791.1203806400299 and batch: 1500, loss is 3.6169191789627075 and perplexity is 37.22271446978188
At time: 792.2751159667969 and batch: 1550, loss is 3.6482811546325684 and perplexity is 38.408590850322746
At time: 793.429939031601 and batch: 1600, loss is 3.727835469245911 and perplexity is 41.588990019537945
At time: 794.5864636898041 and batch: 1650, loss is 3.6798372411727907 and perplexity is 39.6399417970669
At time: 795.7400839328766 and batch: 1700, loss is 3.6568058633804323 and perplexity is 38.73741246367499
At time: 796.8931913375854 and batch: 1750, loss is 3.6596024560928346 and perplexity is 38.84589685168863
At time: 798.0480954647064 and batch: 1800, loss is 3.6181095123291014 and perplexity is 37.267048289580806
At time: 799.201756477356 and batch: 1850, loss is 3.653899073600769 and perplexity is 38.624974445046405
At time: 800.364828824997 and batch: 1900, loss is 3.7424973106384276 and perplexity is 42.2032533063671
At time: 801.5202367305756 and batch: 1950, loss is 3.691997904777527 and perplexity is 40.1249327235662
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311534225109011 and perplexity of 74.55478506317594
finished 17 epochs...
Completing Train Step...
At time: 805.205164194107 and batch: 50, loss is 3.899868679046631 and perplexity is 49.39596195477361
At time: 806.3297791481018 and batch: 100, loss is 3.870408544540405 and perplexity is 47.96197668245075
At time: 807.4532783031464 and batch: 150, loss is 3.8362359952926637 and perplexity is 46.350681502075204
At time: 808.5763421058655 and batch: 200, loss is 3.8386963272094725 and perplexity is 46.46485996400192
At time: 809.6976389884949 and batch: 250, loss is 3.8456697130203246 and perplexity is 46.79000973897453
At time: 810.8288640975952 and batch: 300, loss is 3.845503816604614 and perplexity is 46.782248087900626
At time: 811.9747219085693 and batch: 350, loss is 3.856061997413635 and perplexity is 47.278800252872934
At time: 813.1200089454651 and batch: 400, loss is 3.8062050247192385 and perplexity is 44.97941878065455
At time: 814.2664685249329 and batch: 450, loss is 3.8558770322799685 and perplexity is 47.27005613196823
At time: 815.4175398349762 and batch: 500, loss is 3.8657087802886965 and perplexity is 47.73709555706127
At time: 816.5735204219818 and batch: 550, loss is 3.8462306785583498 and perplexity is 46.81626468533352
At time: 817.7277328968048 and batch: 600, loss is 3.8035462951660155 and perplexity is 44.85998950607877
At time: 818.8831367492676 and batch: 650, loss is 3.8219121742248534 and perplexity is 45.69149493955964
At time: 820.0372939109802 and batch: 700, loss is 3.868583154678345 and perplexity is 47.87450723366047
At time: 821.1917231082916 and batch: 750, loss is 3.8070894050598145 and perplexity is 45.01921528938584
At time: 822.3447189331055 and batch: 800, loss is 3.8004830646514893 and perplexity is 44.72278327179243
At time: 823.4989666938782 and batch: 850, loss is 3.807276391983032 and perplexity is 45.02763408101591
At time: 824.6527252197266 and batch: 900, loss is 3.7570689153671264 and perplexity is 42.82272481773551
At time: 825.8067636489868 and batch: 950, loss is 3.8589632320404053 and perplexity is 47.41616631451331
At time: 826.967512845993 and batch: 1000, loss is 3.826532344818115 and perplexity is 45.90308585752563
At time: 828.161529302597 and batch: 1050, loss is 3.7750488471984864 and perplexity is 43.59963798387945
At time: 829.3228147029877 and batch: 1100, loss is 3.7779427099227907 and perplexity is 43.72599208857223
At time: 830.4775521755219 and batch: 1150, loss is 3.7754169797897337 and perplexity is 43.61569138629691
At time: 831.6337676048279 and batch: 1200, loss is 3.8089419317245485 and perplexity is 45.10269188356983
At time: 832.7930359840393 and batch: 1250, loss is 3.8048547887802124 and perplexity is 44.918726936275945
At time: 833.9463713169098 and batch: 1300, loss is 3.7879488182067873 and perplexity is 44.165715390891975
At time: 835.1013031005859 and batch: 1350, loss is 3.6656626319885253 and perplexity is 39.082024584570064
At time: 836.257828950882 and batch: 1400, loss is 3.686090326309204 and perplexity is 39.88859032794122
At time: 837.4026885032654 and batch: 1450, loss is 3.6185696363449096 and perplexity is 37.28419969908223
At time: 838.5483286380768 and batch: 1500, loss is 3.6175598764419554 and perplexity is 37.246570610582005
At time: 839.6938335895538 and batch: 1550, loss is 3.649329218864441 and perplexity is 38.44886662270112
At time: 840.8417601585388 and batch: 1600, loss is 3.7291396331787108 and perplexity is 41.643264263886316
At time: 841.9885544776917 and batch: 1650, loss is 3.6814213371276856 and perplexity is 39.70278503023428
At time: 843.1354155540466 and batch: 1700, loss is 3.6583905363082887 and perplexity is 38.798847256671834
At time: 844.281445980072 and batch: 1750, loss is 3.6615276288986207 and perplexity is 38.920753949227944
At time: 845.4278225898743 and batch: 1800, loss is 3.619851508140564 and perplexity is 37.33202390880412
At time: 846.5751428604126 and batch: 1850, loss is 3.6558095741271974 and perplexity is 38.69883801478447
At time: 847.723167181015 and batch: 1900, loss is 3.7443497467041014 and perplexity is 42.28150459025408
At time: 848.8714451789856 and batch: 1950, loss is 3.6937227725982664 and perplexity is 40.19420265239186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311016135992006 and perplexity of 74.51616904454727
finished 18 epochs...
Completing Train Step...
At time: 852.525796175003 and batch: 50, loss is 3.8992747020721437 and perplexity is 49.36663060267607
At time: 853.649331331253 and batch: 100, loss is 3.8690173292160033 and perplexity is 47.89529763870991
At time: 854.7762336730957 and batch: 150, loss is 3.8343016958236693 and perplexity is 46.261112058448944
At time: 855.9160256385803 and batch: 200, loss is 3.8362628650665282 and perplexity is 46.351926951138026
At time: 857.1021704673767 and batch: 250, loss is 3.842707438468933 and perplexity is 46.651609974121705
At time: 858.2477836608887 and batch: 300, loss is 3.8423155117034913 and perplexity is 46.63332954205121
At time: 859.3934166431427 and batch: 350, loss is 3.8528611421585084 and perplexity is 47.127709595289694
At time: 860.5399045944214 and batch: 400, loss is 3.8027161931991578 and perplexity is 44.82276659210104
At time: 861.6840767860413 and batch: 450, loss is 3.8525162982940673 and perplexity is 47.1114606956183
At time: 862.8283398151398 and batch: 500, loss is 3.862289757728577 and perplexity is 47.57416004920813
At time: 863.974086523056 and batch: 550, loss is 3.8428848218917846 and perplexity is 46.65988593036747
At time: 865.1179211139679 and batch: 600, loss is 3.800576639175415 and perplexity is 44.72696838075247
At time: 866.2619681358337 and batch: 650, loss is 3.81916533946991 and perplexity is 45.56616016901149
At time: 867.4053211212158 and batch: 700, loss is 3.8659397888183595 and perplexity is 47.74812450715802
At time: 868.5496528148651 and batch: 750, loss is 3.8047579526901245 and perplexity is 44.91437739298749
At time: 869.6951160430908 and batch: 800, loss is 3.7983994817733766 and perplexity is 44.62969665682089
At time: 870.8383631706238 and batch: 850, loss is 3.805223574638367 and perplexity is 44.935295382452885
At time: 871.987211227417 and batch: 900, loss is 3.7551266050338743 and perplexity is 42.73963052040343
At time: 873.1433625221252 and batch: 950, loss is 3.8570329189300536 and perplexity is 47.324726549115645
At time: 874.2909164428711 and batch: 1000, loss is 3.824539747238159 and perplexity is 45.81171054707802
At time: 875.4397866725922 and batch: 1050, loss is 3.773211622238159 and perplexity is 43.519609178684185
At time: 876.592277765274 and batch: 1100, loss is 3.7763670539855956 and perplexity is 43.6571492201083
At time: 877.7432279586792 and batch: 1150, loss is 3.7740293979644775 and perplexity is 43.555213014681605
At time: 878.8947749137878 and batch: 1200, loss is 3.8076618623733522 and perplexity is 45.044994246400215
At time: 880.049108505249 and batch: 1250, loss is 3.8037737083435057 and perplexity is 44.870192418928966
At time: 881.2025921344757 and batch: 1300, loss is 3.787074480056763 and perplexity is 44.127116497703994
At time: 882.3565742969513 and batch: 1350, loss is 3.6650536680221557 and perplexity is 39.05823228492713
At time: 883.5106480121613 and batch: 1400, loss is 3.685561971664429 and perplexity is 39.867520572609614
At time: 884.664023399353 and batch: 1450, loss is 3.618173236846924 and perplexity is 37.26942318993261
At time: 885.8171589374542 and batch: 1500, loss is 3.6175574541091917 and perplexity is 37.246480387102956
At time: 886.9677402973175 and batch: 1550, loss is 3.649599733352661 and perplexity is 38.45926900511233
At time: 888.1185505390167 and batch: 1600, loss is 3.7295940113067627 and perplexity is 41.66219035182309
At time: 889.269469499588 and batch: 1650, loss is 3.6819506216049196 and perplexity is 39.72380466024497
At time: 890.4211640357971 and batch: 1700, loss is 3.6589637422561645 and perplexity is 38.82109336188089
At time: 891.5712230205536 and batch: 1750, loss is 3.6622395133972168 and perplexity is 38.9484708950996
At time: 892.7242040634155 and batch: 1800, loss is 3.6204910850524903 and perplexity is 37.355908246492966
At time: 893.8745920658112 and batch: 1850, loss is 3.6565637588500977 and perplexity is 38.72803509582152
At time: 895.0301628112793 and batch: 1900, loss is 3.7450892877578736 and perplexity is 42.312785063885386
At time: 896.1846745014191 and batch: 1950, loss is 3.6943721199035644 and perplexity is 40.22031112538869
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310762059411338 and perplexity of 74.4972386361005
finished 19 epochs...
Completing Train Step...
At time: 899.833634853363 and batch: 50, loss is 3.898237175941467 and perplexity is 49.315437994868724
At time: 900.9777956008911 and batch: 100, loss is 3.8675229787826537 and perplexity is 47.823778730392895
At time: 902.1013684272766 and batch: 150, loss is 3.8324969673156737 and perplexity is 46.177698602666396
At time: 903.2227244377136 and batch: 200, loss is 3.83420708656311 and perplexity is 46.256735535877496
At time: 904.3459656238556 and batch: 250, loss is 3.8403096866607664 and perplexity is 46.53988498987144
At time: 905.4805822372437 and batch: 300, loss is 3.839802007675171 and perplexity is 46.516263664802565
At time: 906.6236221790314 and batch: 350, loss is 3.8503450679779054 and perplexity is 47.0092818309829
At time: 907.7705748081207 and batch: 400, loss is 3.8000400257110596 and perplexity is 44.702973725802785
At time: 908.9161591529846 and batch: 450, loss is 3.8499618196487426 and perplexity is 46.99126905416982
At time: 910.0620431900024 and batch: 500, loss is 3.8597267150878904 and perplexity is 47.452381576781406
At time: 911.2077314853668 and batch: 550, loss is 3.8403551816940307 and perplexity is 46.542002371651975
At time: 912.3558120727539 and batch: 600, loss is 3.7983040046691894 and perplexity is 44.625435746036295
At time: 913.510023355484 and batch: 650, loss is 3.817040357589722 and perplexity is 45.46943570956144
At time: 914.6886546611786 and batch: 700, loss is 3.863942379951477 and perplexity is 47.65284716547084
At time: 915.8433361053467 and batch: 750, loss is 3.802962875366211 and perplexity is 44.833824933189
At time: 916.9966857433319 and batch: 800, loss is 3.796768183708191 and perplexity is 44.556951669525326
At time: 918.1485321521759 and batch: 850, loss is 3.80357027053833 and perplexity is 44.86106505392249
At time: 919.3041033744812 and batch: 900, loss is 3.7535715818405153 and perplexity is 42.673221051183106
At time: 920.4572093486786 and batch: 950, loss is 3.855511198043823 and perplexity is 47.25276628989156
At time: 921.6099941730499 and batch: 1000, loss is 3.8229580116271973 and perplexity is 45.73930581077725
At time: 922.7628302574158 and batch: 1050, loss is 3.77173255443573 and perplexity is 43.455288305166135
At time: 923.9162192344666 and batch: 1100, loss is 3.775025568008423 and perplexity is 43.598623031433796
At time: 925.0690245628357 and batch: 1150, loss is 3.772821364402771 and perplexity is 43.502628623821984
At time: 926.2231793403625 and batch: 1200, loss is 3.80652512550354 and perplexity is 44.99381903252667
At time: 927.376219034195 and batch: 1250, loss is 3.8027831506729126 and perplexity is 44.82576791179802
At time: 928.530130147934 and batch: 1300, loss is 3.7862565755844115 and perplexity is 44.09103948755372
At time: 929.6832983493805 and batch: 1350, loss is 3.664417543411255 and perplexity is 39.03339428298214
At time: 930.8361625671387 and batch: 1400, loss is 3.6849686813354494 and perplexity is 39.84387457337843
At time: 931.9915909767151 and batch: 1450, loss is 3.6176525115966798 and perplexity is 37.250021112229874
At time: 933.145378112793 and batch: 1500, loss is 3.6172702503204346 and perplexity is 37.23578459282775
At time: 934.298971414566 and batch: 1550, loss is 3.649517130851746 and perplexity is 38.45609230451265
At time: 935.453352689743 and batch: 1600, loss is 3.729652829170227 and perplexity is 41.66464090491427
At time: 936.6080524921417 and batch: 1650, loss is 3.6820162391662596 and perplexity is 39.72641132495448
At time: 937.7627880573273 and batch: 1700, loss is 3.65909086227417 and perplexity is 38.82602861364604
At time: 938.9168593883514 and batch: 1750, loss is 3.662441568374634 and perplexity is 38.95634142261959
At time: 940.0713262557983 and batch: 1800, loss is 3.6206656885147095 and perplexity is 37.36243128686329
At time: 941.2244477272034 and batch: 1850, loss is 3.6568321275711058 and perplexity is 38.73842988382293
At time: 942.3775405883789 and batch: 1900, loss is 3.745366015434265 and perplexity is 42.324495802845824
At time: 943.5310010910034 and batch: 1950, loss is 3.694590983390808 and perplexity is 40.22911484631101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310633743640988 and perplexity of 74.48768007880594
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
1943.8085134029388


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6331455707550049 and batch: 50, loss is 7.704789619445801 and perplexity is 2218.950509114719
At time: 2.8163955211639404 and batch: 100, loss is 6.899703865051269 and perplexity is 991.980911887915
At time: 3.998751163482666 and batch: 150, loss is 6.524049396514893 and perplexity is 681.331789337959
At time: 5.185712814331055 and batch: 200, loss is 6.315768299102783 and perplexity is 553.2269411154994
At time: 6.371167421340942 and batch: 250, loss is 6.232116804122925 and perplexity is 508.8314407903463
At time: 7.555948257446289 and batch: 300, loss is 6.1196716690063475 and perplexity is 454.7153728372088
At time: 8.739018678665161 and batch: 350, loss is 6.030559978485107 and perplexity is 415.94788604565167
At time: 9.923327445983887 and batch: 400, loss is 5.963560228347778 and perplexity is 388.9925642307787
At time: 11.108022689819336 and batch: 450, loss is 5.861378946304321 and perplexity is 351.2081073852052
At time: 12.299683332443237 and batch: 500, loss is 5.831165008544922 and perplexity is 340.75543090596994
At time: 13.490993022918701 and batch: 550, loss is 5.771593179702759 and perplexity is 321.04881387099135
At time: 14.682075500488281 and batch: 600, loss is 5.792585563659668 and perplexity is 327.85963137454
At time: 15.873292684555054 and batch: 650, loss is 5.846387090682984 and perplexity is 345.98211766846237
At time: 17.064151763916016 and batch: 700, loss is 5.768584280014038 and perplexity is 320.0842620424315
At time: 18.25664472579956 and batch: 750, loss is 5.7008200359344485 and perplexity is 299.1125834909889
At time: 19.448105096817017 and batch: 800, loss is 5.710321197509765 and perplexity is 301.9680440915533
At time: 20.639410972595215 and batch: 850, loss is 5.713987607955932 and perplexity is 303.0772149781735
At time: 21.83228373527527 and batch: 900, loss is 5.700969829559326 and perplexity is 299.15739200504754
At time: 23.025289297103882 and batch: 950, loss is 5.710221757888794 and perplexity is 301.9380179966199
At time: 24.219336986541748 and batch: 1000, loss is 5.679029541015625 and perplexity is 292.66527242021664
At time: 25.41256356239319 and batch: 1050, loss is 5.57803448677063 and perplexity is 264.5511157209431
At time: 26.604766607284546 and batch: 1100, loss is 5.655073089599609 and perplexity is 285.73736639301734
At time: 27.796980619430542 and batch: 1150, loss is 5.561270027160645 and perplexity is 260.1530280138622
At time: 28.989797592163086 and batch: 1200, loss is 5.618720769882202 and perplexity is 275.5366828671316
At time: 30.18288540840149 and batch: 1250, loss is 5.57275221824646 and perplexity is 263.15736999964514
At time: 31.380510568618774 and batch: 1300, loss is 5.588462009429931 and perplexity is 267.3241613459067
At time: 32.57190823554993 and batch: 1350, loss is 5.541035461425781 and perplexity is 254.94184528050036
At time: 33.76136493682861 and batch: 1400, loss is 5.542492141723633 and perplexity is 255.31348465778223
At time: 34.95358180999756 and batch: 1450, loss is 5.521327686309815 and perplexity is 249.96669433062434
At time: 36.14759302139282 and batch: 1500, loss is 5.4754518795013425 and perplexity is 238.75833255394787
At time: 37.34137749671936 and batch: 1550, loss is 5.464013319015503 and perplexity is 236.04284118963483
At time: 38.53481483459473 and batch: 1600, loss is 5.47807728767395 and perplexity is 239.38599420500023
At time: 39.72867178916931 and batch: 1650, loss is 5.474929027557373 and perplexity is 238.63352992512475
At time: 40.921796798706055 and batch: 1700, loss is 5.491030216217041 and perplexity is 242.5069127646061
At time: 42.11514401435852 and batch: 1750, loss is 5.479147319793701 and perplexity is 239.64228200145163
At time: 43.30862832069397 and batch: 1800, loss is 5.47369005203247 and perplexity is 238.33805190494206
At time: 44.50239419937134 and batch: 1850, loss is 5.454342470169068 and perplexity is 233.7711090456436
At time: 45.69707679748535 and batch: 1900, loss is 5.482392110824585 and perplexity is 240.42113405142743
At time: 46.89267373085022 and batch: 1950, loss is 5.403379039764404 and perplexity is 222.15582271277688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.018915788517442 and perplexity of 151.24723088083095
finished 1 epochs...
Completing Train Step...
At time: 50.54824948310852 and batch: 50, loss is 5.290470161437988 and perplexity is 198.43670076500663
At time: 51.69549798965454 and batch: 100, loss is 5.211644372940063 and perplexity is 183.39538078395805
At time: 52.813865661621094 and batch: 150, loss is 5.11832407951355 and perplexity is 167.05516371404315
At time: 53.931437969207764 and batch: 200, loss is 5.0829264926910405 and perplexity is 161.24524916368156
At time: 55.051021099090576 and batch: 250, loss is 5.097896280288697 and perplexity is 163.6772138767277
At time: 56.169167280197144 and batch: 300, loss is 5.10221384048462 and perplexity is 164.38542787846313
At time: 57.28701901435852 and batch: 350, loss is 5.095568361282349 and perplexity is 163.29662973603735
At time: 58.448423862457275 and batch: 400, loss is 5.04095573425293 and perplexity is 154.61771788139782
At time: 59.566519260406494 and batch: 450, loss is 5.004427680969238 and perplexity is 149.071742144596
At time: 60.6860511302948 and batch: 500, loss is 4.994899969100953 and perplexity is 147.65817426477753
At time: 61.805704832077026 and batch: 550, loss is 4.960730333328247 and perplexity is 142.6979749366156
At time: 62.92550849914551 and batch: 600, loss is 4.932142086029053 and perplexity is 138.67625086631085
At time: 64.05182313919067 and batch: 650, loss is 5.000513954162598 and perplexity is 148.48945626842513
At time: 65.172602891922 and batch: 700, loss is 5.008626918792725 and perplexity is 149.6990460199009
At time: 66.29053854942322 and batch: 750, loss is 4.946931648254394 and perplexity is 140.74245336109172
At time: 67.40817213058472 and batch: 800, loss is 4.949036312103272 and perplexity is 141.03898085056835
At time: 68.52495956420898 and batch: 850, loss is 4.941521682739258 and perplexity is 139.98309743862058
At time: 69.64294338226318 and batch: 900, loss is 4.930636196136475 and perplexity is 138.46757686126242
At time: 70.76077795028687 and batch: 950, loss is 4.969404697418213 and perplexity is 143.94117330845359
At time: 71.87957453727722 and batch: 1000, loss is 4.93148247718811 and perplexity is 138.58480894647542
At time: 72.998699426651 and batch: 1050, loss is 4.858512840270996 and perplexity is 128.83246511704039
At time: 74.1198217868805 and batch: 1100, loss is 4.918456602096557 and perplexity is 136.791326731988
At time: 75.23739671707153 and batch: 1150, loss is 4.841874494552612 and perplexity is 126.70664016946812
At time: 76.35342741012573 and batch: 1200, loss is 4.913680334091186 and perplexity is 136.13953250576046
At time: 77.47206783294678 and batch: 1250, loss is 4.888707361221313 and perplexity is 132.78182413491515
At time: 78.5892596244812 and batch: 1300, loss is 4.901112327575683 and perplexity is 134.43923701735764
At time: 79.70871829986572 and batch: 1350, loss is 4.802183046340942 and perplexity is 121.77597014246547
At time: 80.82770276069641 and batch: 1400, loss is 4.807411403656006 and perplexity is 122.4143257482007
At time: 81.94580125808716 and batch: 1450, loss is 4.7604452419281005 and perplexity is 116.79791765373072
At time: 83.06334090232849 and batch: 1500, loss is 4.7235136985778805 and perplexity is 112.56307132836942
At time: 84.20318484306335 and batch: 1550, loss is 4.733016366958618 and perplexity is 113.63781926621404
At time: 85.35407948493958 and batch: 1600, loss is 4.782313642501831 and perplexity is 119.38023395653644
At time: 86.50478792190552 and batch: 1650, loss is 4.759396133422851 and perplexity is 116.67544821802088
At time: 87.6567268371582 and batch: 1700, loss is 4.774555931091308 and perplexity is 118.45769955786237
At time: 88.80663776397705 and batch: 1750, loss is 4.765045318603516 and perplexity is 117.33643469068085
At time: 89.95884680747986 and batch: 1800, loss is 4.7232553672790525 and perplexity is 112.53399651958135
At time: 91.11477017402649 and batch: 1850, loss is 4.7420192527771 and perplexity is 114.665506712768
At time: 92.26916170120239 and batch: 1900, loss is 4.843857479095459 and perplexity is 126.9581467628287
At time: 93.42079257965088 and batch: 1950, loss is 4.75295464515686 and perplexity is 115.92630009217717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.615187250181686 and perplexity of 101.00674029228166
finished 2 epochs...
Completing Train Step...
At time: 97.03505492210388 and batch: 50, loss is 4.734252223968506 and perplexity is 113.77834617944184
At time: 98.17925953865051 and batch: 100, loss is 4.667730875015259 and perplexity is 106.45590640113869
At time: 99.30141067504883 and batch: 150, loss is 4.609367446899414 and perplexity is 100.42060817477011
At time: 100.42444252967834 and batch: 200, loss is 4.600314674377441 and perplexity is 99.51562573300693
At time: 101.54588341712952 and batch: 250, loss is 4.613312788009644 and perplexity is 100.81758431672792
At time: 102.66787624359131 and batch: 300, loss is 4.630520257949829 and perplexity is 102.56741174337802
At time: 103.79145693778992 and batch: 350, loss is 4.637332000732422 and perplexity is 103.26845953797104
At time: 104.93638300895691 and batch: 400, loss is 4.5799554920196535 and perplexity is 97.51005413489777
At time: 106.08192825317383 and batch: 450, loss is 4.5782840538024905 and perplexity is 97.34720823520117
At time: 107.2338273525238 and batch: 500, loss is 4.579224796295166 and perplexity is 97.43882998000855
At time: 108.38082528114319 and batch: 550, loss is 4.545880813598632 and perplexity is 94.24340153123688
At time: 109.52633547782898 and batch: 600, loss is 4.520690288543701 and perplexity is 91.8990129241323
At time: 110.67246317863464 and batch: 650, loss is 4.593379917144776 and perplexity is 98.82789640179088
At time: 111.8183262348175 and batch: 700, loss is 4.6273374843597415 and perplexity is 102.24148184974678
At time: 112.96388721466064 and batch: 750, loss is 4.569690599441528 and perplexity is 96.51424359190854
At time: 114.14996480941772 and batch: 800, loss is 4.568224725723266 and perplexity is 96.3728695423563
At time: 115.30327820777893 and batch: 850, loss is 4.564299755096435 and perplexity is 95.99535022095563
At time: 116.4509551525116 and batch: 900, loss is 4.538671855926514 and perplexity is 93.56644783570889
At time: 117.59673523902893 and batch: 950, loss is 4.599150123596192 and perplexity is 99.39980218760297
At time: 118.74094820022583 and batch: 1000, loss is 4.573886413574218 and perplexity is 96.92005016831456
At time: 119.88612532615662 and batch: 1050, loss is 4.516487741470337 and perplexity is 91.51361339338247
At time: 121.0282154083252 and batch: 1100, loss is 4.5613769435882565 and perplexity is 95.71518354324434
At time: 122.17250919342041 and batch: 1150, loss is 4.509074659347534 and perplexity is 90.83772376980728
At time: 123.31536602973938 and batch: 1200, loss is 4.578021392822266 and perplexity is 97.32164227980041
At time: 124.4608588218689 and batch: 1250, loss is 4.568954353332519 and perplexity is 96.44321150735665
At time: 125.60344576835632 and batch: 1300, loss is 4.561268310546875 and perplexity is 95.70478627650327
At time: 126.74678802490234 and batch: 1350, loss is 4.452071647644043 and perplexity is 85.80451672956275
At time: 127.8889696598053 and batch: 1400, loss is 4.462292432785034 and perplexity is 86.686003328092
At time: 129.03409218788147 and batch: 1450, loss is 4.421070756912232 and perplexity is 83.18530893307039
At time: 130.18393063545227 and batch: 1500, loss is 4.394042601585388 and perplexity is 80.96707589310105
At time: 131.32644057273865 and batch: 1550, loss is 4.411478786468506 and perplexity is 82.39121247177904
At time: 132.46882486343384 and batch: 1600, loss is 4.47761978149414 and perplexity is 88.02490462082912
At time: 133.61055302619934 and batch: 1650, loss is 4.44356782913208 and perplexity is 85.07794438994082
At time: 134.75488471984863 and batch: 1700, loss is 4.4550715255737305 and perplexity is 86.06230628083352
At time: 135.8982903957367 and batch: 1750, loss is 4.4465834903717045 and perplexity is 85.33489789681757
At time: 137.04086899757385 and batch: 1800, loss is 4.408210029602051 and perplexity is 82.12233531670732
At time: 138.18370246887207 and batch: 1850, loss is 4.437751007080078 and perplexity is 84.5844976641032
At time: 139.32824873924255 and batch: 1900, loss is 4.55074369430542 and perplexity is 94.70281207428862
At time: 140.47001457214355 and batch: 1950, loss is 4.462599048614502 and perplexity is 86.71258670413935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496434127452762 and perplexity of 89.69671330761986
finished 3 epochs...
Completing Train Step...
At time: 144.07759618759155 and batch: 50, loss is 4.451910057067871 and perplexity is 85.79065264844884
At time: 145.22205686569214 and batch: 100, loss is 4.3947685432434085 and perplexity is 81.02587460605532
At time: 146.3426537513733 and batch: 150, loss is 4.345742692947388 and perplexity is 77.14931445880934
At time: 147.46809434890747 and batch: 200, loss is 4.343166351318359 and perplexity is 76.95080728926024
At time: 148.59241199493408 and batch: 250, loss is 4.347457094192505 and perplexity is 77.28169278193488
At time: 149.72397446632385 and batch: 300, loss is 4.363166379928589 and perplexity is 78.50531895869909
At time: 150.8615574836731 and batch: 350, loss is 4.374333801269532 and perplexity is 79.38693445661349
At time: 151.9982271194458 and batch: 400, loss is 4.3172758769989015 and perplexity is 74.98408394873788
At time: 153.13549160957336 and batch: 450, loss is 4.339438276290894 and perplexity is 76.66446299441657
At time: 154.27196955680847 and batch: 500, loss is 4.341859340667725 and perplexity is 76.85029746257344
At time: 155.4078505039215 and batch: 550, loss is 4.3071748161315915 and perplexity is 74.23047767174546
At time: 156.5439817905426 and batch: 600, loss is 4.295658197402954 and perplexity is 73.38049740624135
At time: 157.6811797618866 and batch: 650, loss is 4.35976354598999 and perplexity is 78.23863239736333
At time: 158.8180251121521 and batch: 700, loss is 4.397169694900513 and perplexity is 81.22066378472502
At time: 159.95489239692688 and batch: 750, loss is 4.3449400043487545 and perplexity is 77.0874124310505
At time: 161.09249567985535 and batch: 800, loss is 4.341792526245118 and perplexity is 76.84516292585377
At time: 162.22918248176575 and batch: 850, loss is 4.3384276962280275 and perplexity is 76.58702655103728
At time: 163.36611032485962 and batch: 900, loss is 4.310996379852295 and perplexity is 74.51469690724282
At time: 164.5018756389618 and batch: 950, loss is 4.38467957496643 and perplexity is 80.2125169962121
At time: 165.64426136016846 and batch: 1000, loss is 4.355206747055053 and perplexity is 77.88292573795071
At time: 166.78116464614868 and batch: 1050, loss is 4.310255994796753 and perplexity is 74.45954775755688
At time: 167.91858625411987 and batch: 1100, loss is 4.344319829940796 and perplexity is 77.0396196121584
At time: 169.0543999671936 and batch: 1150, loss is 4.301035308837891 and perplexity is 73.77613525909037
At time: 170.19141817092896 and batch: 1200, loss is 4.3660808944702145 and perplexity is 78.73445760415683
At time: 171.3662211894989 and batch: 1250, loss is 4.364190282821656 and perplexity is 78.5857419475414
At time: 172.50393867492676 and batch: 1300, loss is 4.346557006835938 and perplexity is 77.21216380313925
At time: 173.64121913909912 and batch: 1350, loss is 4.237898712158203 and perplexity is 69.26215908837145
At time: 174.7784333229065 and batch: 1400, loss is 4.256999711990357 and perplexity is 70.59785149756826
At time: 175.91517567634583 and batch: 1450, loss is 4.212102584838867 and perplexity is 67.49831164094142
At time: 177.0594003200531 and batch: 1500, loss is 4.194873681068421 and perplexity is 66.34535037417916
At time: 178.19489097595215 and batch: 1550, loss is 4.21578426361084 and perplexity is 67.7472767656394
At time: 179.33844470977783 and batch: 1600, loss is 4.289260439872741 and perplexity is 72.91252535846046
At time: 180.47582530975342 and batch: 1650, loss is 4.248209805488586 and perplexity is 69.98002229206567
At time: 181.61207795143127 and batch: 1700, loss is 4.256858034133911 and perplexity is 70.58785005380669
At time: 182.7498860359192 and batch: 1750, loss is 4.252336220741272 and perplexity is 70.26938552928324
At time: 183.88708567619324 and batch: 1800, loss is 4.213320083618164 and perplexity is 67.58054079976176
At time: 185.03009700775146 and batch: 1850, loss is 4.245313558578491 and perplexity is 69.77763609041158
At time: 186.16485214233398 and batch: 1900, loss is 4.356288499832154 and perplexity is 77.96722139446655
At time: 187.30154585838318 and batch: 1950, loss is 4.276166648864746 and perplexity is 71.96404712854623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.443505007721657 and perplexity of 85.07259984135615
finished 4 epochs...
Completing Train Step...
At time: 190.92943668365479 and batch: 50, loss is 4.264833059310913 and perplexity is 71.15304064421508
At time: 192.04995369911194 and batch: 100, loss is 4.217686982154846 and perplexity is 67.87630347727905
At time: 193.17002272605896 and batch: 150, loss is 4.169781613349914 and perplexity is 64.70132065972446
At time: 194.29396224021912 and batch: 200, loss is 4.17007116317749 and perplexity is 64.72005762847753
At time: 195.42895889282227 and batch: 250, loss is 4.165998196601867 and perplexity is 64.4569910912597
At time: 196.5636465549469 and batch: 300, loss is 4.18393874168396 and perplexity is 65.62382012378046
At time: 197.69949340820312 and batch: 350, loss is 4.190776600837707 and perplexity is 66.07408422979758
At time: 198.84040451049805 and batch: 400, loss is 4.138735380172729 and perplexity is 62.723449953949775
At time: 200.00765681266785 and batch: 450, loss is 4.171267647743225 and perplexity is 64.7975405228235
At time: 201.1520323753357 and batch: 500, loss is 4.18063796043396 and perplexity is 65.40756734666078
At time: 202.29633736610413 and batch: 550, loss is 4.144231200218201 and perplexity is 63.06911573595327
At time: 203.45059537887573 and batch: 600, loss is 4.140609936714172 and perplexity is 62.84113888017321
At time: 204.59719610214233 and batch: 650, loss is 4.194809484481811 and perplexity is 66.3410913658561
At time: 205.74311876296997 and batch: 700, loss is 4.240773391723633 and perplexity is 69.46155205989906
At time: 206.88843274116516 and batch: 750, loss is 4.1900934314727785 and perplexity is 66.02895985518627
At time: 208.0331060886383 and batch: 800, loss is 4.1846918821334835 and perplexity is 65.67326269343043
At time: 209.18002462387085 and batch: 850, loss is 4.179771428108215 and perplexity is 65.35091412467567
At time: 210.32672834396362 and batch: 900, loss is 4.151361985206604 and perplexity is 63.520455329997766
At time: 211.47225403785706 and batch: 950, loss is 4.231054391860962 and perplexity is 68.78972527551043
At time: 212.61756229400635 and batch: 1000, loss is 4.200657362937927 and perplexity is 66.73018257502532
At time: 213.76245427131653 and batch: 1050, loss is 4.159306321144104 and perplexity is 64.02709295117955
At time: 214.9081952571869 and batch: 1100, loss is 4.188480243682862 and perplexity is 65.92252861323813
At time: 216.05538845062256 and batch: 1150, loss is 4.152498073577881 and perplexity is 63.59266118898846
At time: 217.20237755775452 and batch: 1200, loss is 4.218991951942444 and perplexity is 67.96493782260383
At time: 218.3489682674408 and batch: 1250, loss is 4.216403656005859 and perplexity is 67.78925191185249
At time: 219.49474358558655 and batch: 1300, loss is 4.192725586891174 and perplexity is 66.20298727276987
At time: 220.64088487625122 and batch: 1350, loss is 4.084173383712769 and perplexity is 59.39282237993375
At time: 221.78755569458008 and batch: 1400, loss is 4.115923886299133 and perplexity is 61.30883049375382
At time: 222.9334592819214 and batch: 1450, loss is 4.067287139892578 and perplexity is 58.39832102754565
At time: 224.08016347885132 and batch: 1500, loss is 4.051477551460266 and perplexity is 57.482327426656646
At time: 225.23279738426208 and batch: 1550, loss is 4.075388131141662 and perplexity is 58.87332672592744
At time: 226.3787350654602 and batch: 1600, loss is 4.152365570068359 and perplexity is 63.584235496430324
At time: 227.5247836112976 and batch: 1650, loss is 4.105169906616211 and perplexity is 60.6530490265046
At time: 228.67201614379883 and batch: 1700, loss is 4.115401883125305 and perplexity is 61.276835441138395
At time: 229.82436728477478 and batch: 1750, loss is 4.113564743995666 and perplexity is 61.16436471283016
At time: 230.97811770439148 and batch: 1800, loss is 4.069531512260437 and perplexity is 58.529535797912025
At time: 232.13938355445862 and batch: 1850, loss is 4.105819730758667 and perplexity is 60.692475650874414
At time: 233.29455876350403 and batch: 1900, loss is 4.213822345733643 and perplexity is 67.61449247075436
At time: 234.44848728179932 and batch: 1950, loss is 4.137643461227417 and perplexity is 62.65499840920013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427153831304506 and perplexity of 83.69287356721829
finished 5 epochs...
Completing Train Step...
At time: 238.11073517799377 and batch: 50, loss is 4.125460009574891 and perplexity is 61.89627558189111
At time: 239.23658084869385 and batch: 100, loss is 4.083237600326538 and perplexity is 59.33726956024604
At time: 240.35396194458008 and batch: 150, loss is 4.042181997299195 and perplexity is 56.95047310873704
At time: 241.47184944152832 and batch: 200, loss is 4.04101438999176 and perplexity is 56.884016125553146
At time: 242.5945246219635 and batch: 250, loss is 4.03343361377716 and perplexity is 56.454421516746436
At time: 243.7288670539856 and batch: 300, loss is 4.050937952995301 and perplexity is 57.451318417973724
At time: 244.86736726760864 and batch: 350, loss is 4.055733594894409 and perplexity is 57.72749606298257
At time: 246.00523281097412 and batch: 400, loss is 4.006214756965637 and perplexity is 54.93852083175251
At time: 247.14894604682922 and batch: 450, loss is 4.045107531547546 and perplexity is 57.117327618562484
At time: 248.29237413406372 and batch: 500, loss is 4.057577505111694 and perplexity is 57.834038580022145
At time: 249.44442486763 and batch: 550, loss is 4.024243335723877 and perplexity is 55.937966503287676
At time: 250.5888955593109 and batch: 600, loss is 4.022564959526062 and perplexity is 55.844160294828704
At time: 251.73182916641235 and batch: 650, loss is 4.076220760345459 and perplexity is 58.92236679034583
At time: 252.88201212882996 and batch: 700, loss is 4.117421803474426 and perplexity is 61.400734859327116
At time: 254.02851843833923 and batch: 750, loss is 4.071520977020263 and perplexity is 58.64609415271609
At time: 255.1724660396576 and batch: 800, loss is 4.066795463562012 and perplexity is 58.36961501296386
At time: 256.3373456001282 and batch: 850, loss is 4.060912113189698 and perplexity is 58.02721433596955
At time: 257.48051714897156 and batch: 900, loss is 4.03210560798645 and perplexity is 56.37949947752301
At time: 258.6256437301636 and batch: 950, loss is 4.11440842628479 and perplexity is 61.21598977857847
At time: 259.7690954208374 and batch: 1000, loss is 4.0841610622406 and perplexity is 59.392090577434224
At time: 260.91185665130615 and batch: 1050, loss is 4.047114114761353 and perplexity is 57.232053354253026
At time: 262.0604386329651 and batch: 1100, loss is 4.071152348518371 and perplexity is 58.62447951501726
At time: 263.2051417827606 and batch: 1150, loss is 4.0389362239837645 and perplexity is 56.7659244464004
At time: 264.34854555130005 and batch: 1200, loss is 4.100855793952942 and perplexity is 60.39194855302032
At time: 265.4932019710541 and batch: 1250, loss is 4.100091476440429 and perplexity is 60.34580756455548
At time: 266.6375217437744 and batch: 1300, loss is 4.073243083953858 and perplexity is 58.747176009987214
At time: 267.78089356422424 and batch: 1350, loss is 3.9707744312286377 and perplexity is 53.02557960766548
At time: 268.92481422424316 and batch: 1400, loss is 4.003806090354919 and perplexity is 54.80635149082237
At time: 270.0688817501068 and batch: 1450, loss is 3.9491819763183593 and perplexity is 51.89289984671494
At time: 271.2114882469177 and batch: 1500, loss is 3.9413703584671023 and perplexity is 51.48911151728777
At time: 272.3533823490143 and batch: 1550, loss is 3.9686811923980714 and perplexity is 52.914700494136504
At time: 273.49714636802673 and batch: 1600, loss is 4.043990135192871 and perplexity is 57.05354056923782
At time: 274.64106273651123 and batch: 1650, loss is 3.998298454284668 and perplexity is 54.505327777940956
At time: 275.78639960289 and batch: 1700, loss is 4.009856557846069 and perplexity is 55.138960744881906
At time: 276.93765687942505 and batch: 1750, loss is 4.00459240436554 and perplexity is 54.849463440414304
At time: 278.08973693847656 and batch: 1800, loss is 3.9575106716156006 and perplexity is 52.32690483648202
At time: 279.2416727542877 and batch: 1850, loss is 3.99940571308136 and perplexity is 54.56571270629179
At time: 280.39796233177185 and batch: 1900, loss is 4.099535150527954 and perplexity is 60.31224496483566
At time: 281.54927825927734 and batch: 1950, loss is 4.026655831336975 and perplexity is 56.07307951632676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.42968011900436 and perplexity of 83.90457313869722
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 285.25512290000916 and batch: 50, loss is 4.050556869506836 and perplexity is 57.42942884027731
At time: 286.375857591629 and batch: 100, loss is 4.041486558914184 and perplexity is 56.91088133210899
At time: 287.49409890174866 and batch: 150, loss is 4.002005324363709 and perplexity is 54.7077468855112
At time: 288.61387968063354 and batch: 200, loss is 4.002737922668457 and perplexity is 54.747840372553256
At time: 289.73953080177307 and batch: 250, loss is 3.9915689754486086 and perplexity is 54.139766725451786
At time: 290.8754816055298 and batch: 300, loss is 4.011896257400513 and perplexity is 55.251542435926424
At time: 292.02068400382996 and batch: 350, loss is 4.0113569927215575 and perplexity is 55.22175526293994
At time: 293.16844415664673 and batch: 400, loss is 3.955352063179016 and perplexity is 52.214073361540876
At time: 294.32186222076416 and batch: 450, loss is 3.9867957735061648 and perplexity is 53.88196245115835
At time: 295.4750876426697 and batch: 500, loss is 3.98623505115509 and perplexity is 53.85175809941116
At time: 296.62865352630615 and batch: 550, loss is 3.9612673807144163 and perplexity is 52.52385150003218
At time: 297.7824811935425 and batch: 600, loss is 3.9463170051574705 and perplexity is 51.74444095197183
At time: 298.9348375797272 and batch: 650, loss is 3.988236413002014 and perplexity is 53.95964287568807
At time: 300.08797693252563 and batch: 700, loss is 4.030984992980957 and perplexity is 56.31635515125402
At time: 301.2409884929657 and batch: 750, loss is 3.973259992599487 and perplexity is 53.15754187222005
At time: 302.3945484161377 and batch: 800, loss is 3.9635333251953124 and perplexity is 52.643002575333014
At time: 303.55445671081543 and batch: 850, loss is 3.9547558546066286 and perplexity is 52.18295216168839
At time: 304.7112338542938 and batch: 900, loss is 3.9111112260818484 and perplexity is 49.954431809909295
At time: 305.8646306991577 and batch: 950, loss is 4.007495865821839 and perplexity is 55.00894816024149
At time: 307.0167922973633 and batch: 1000, loss is 3.9667811584472656 and perplexity is 52.81425622068385
At time: 308.1688916683197 and batch: 1050, loss is 3.9212813806533813 and perplexity is 50.46506832776677
At time: 309.32238960266113 and batch: 1100, loss is 3.9267196369171145 and perplexity is 50.740257899186375
At time: 310.47458124160767 and batch: 1150, loss is 3.8990394496917724 and perplexity is 49.35501835127433
At time: 311.6271731853485 and batch: 1200, loss is 3.9403766775131226 and perplexity is 51.43797317963962
At time: 312.77614879608154 and batch: 1250, loss is 3.940181655883789 and perplexity is 51.42794264041835
At time: 313.9206418991089 and batch: 1300, loss is 3.920436534881592 and perplexity is 50.42245113318021
At time: 315.06327748298645 and batch: 1350, loss is 3.811273622512817 and perplexity is 45.207980116860284
At time: 316.20970273017883 and batch: 1400, loss is 3.825296764373779 and perplexity is 45.84640392705898
At time: 317.35616970062256 and batch: 1450, loss is 3.7608404541015625 and perplexity is 42.984537332374515
At time: 318.50187039375305 and batch: 1500, loss is 3.7456836795806883 and perplexity is 42.33794291339719
At time: 319.64722537994385 and batch: 1550, loss is 3.773512635231018 and perplexity is 43.53271111831923
At time: 320.7937562465668 and batch: 1600, loss is 3.847156081199646 and perplexity is 46.859608632537366
At time: 321.93912506103516 and batch: 1650, loss is 3.7986741876602172 and perplexity is 44.64195838132728
At time: 323.0842373371124 and batch: 1700, loss is 3.7896748924255372 and perplexity is 44.242014523620426
At time: 324.2291839122772 and batch: 1750, loss is 3.7790391302108763 and perplexity is 43.77396044534921
At time: 325.3749647140503 and batch: 1800, loss is 3.730622568130493 and perplexity is 41.70506432738128
At time: 326.5198857784271 and batch: 1850, loss is 3.7545278882980346 and perplexity is 42.71404924705966
At time: 327.6641409397125 and batch: 1900, loss is 3.850492825508118 and perplexity is 47.01622831954867
At time: 328.8091335296631 and batch: 1950, loss is 3.7635887241363526 and perplexity is 43.10283292794758
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367603106831395 and perplexity of 78.85439943408072
finished 7 epochs...
Completing Train Step...
At time: 332.4456055164337 and batch: 50, loss is 3.9640004777908326 and perplexity is 52.66760063569859
At time: 333.5948634147644 and batch: 100, loss is 3.9435901403427125 and perplexity is 51.6035330622773
At time: 334.7143270969391 and batch: 150, loss is 3.895830659866333 and perplexity is 49.19690228683172
At time: 335.8352406024933 and batch: 200, loss is 3.895333571434021 and perplexity is 49.172453152993604
At time: 336.9711194038391 and batch: 250, loss is 3.883241558074951 and perplexity is 48.581439665386696
At time: 338.1070659160614 and batch: 300, loss is 3.9025841045379637 and perplexity is 49.5302752854251
At time: 339.2570788860321 and batch: 350, loss is 3.9043941497802734 and perplexity is 49.62000851065534
At time: 340.40340518951416 and batch: 400, loss is 3.8507168102264404 and perplexity is 47.02676041567567
At time: 341.55562925338745 and batch: 450, loss is 3.890045418739319 and perplexity is 48.913108044985734
At time: 342.73010444641113 and batch: 500, loss is 3.8937824296951296 and perplexity is 49.096238833391666
At time: 343.8828036785126 and batch: 550, loss is 3.8710981512069704 and perplexity is 47.99506298826994
At time: 345.03564524650574 and batch: 600, loss is 3.8563778686523436 and perplexity is 47.29373662493444
At time: 346.1883542537689 and batch: 650, loss is 3.8990559864044187 and perplexity is 49.355834527778875
At time: 347.3410267829895 and batch: 700, loss is 3.943522400856018 and perplexity is 51.60003758382833
At time: 348.50043272972107 and batch: 750, loss is 3.8910257625579834 and perplexity is 48.9610832203503
At time: 349.6536865234375 and batch: 800, loss is 3.879669523239136 and perplexity is 48.40821463763238
At time: 350.80709314346313 and batch: 850, loss is 3.8755776691436767 and perplexity is 48.21053999003163
At time: 351.9610667228699 and batch: 900, loss is 3.834913105964661 and perplexity is 46.28940521997658
At time: 353.11405849456787 and batch: 950, loss is 3.931390099525452 and perplexity is 50.97779264322904
At time: 354.2663519382477 and batch: 1000, loss is 3.8938330698013304 and perplexity is 49.098725135093005
At time: 355.4194493293762 and batch: 1050, loss is 3.852812089920044 and perplexity is 47.12539793233693
At time: 356.57452964782715 and batch: 1100, loss is 3.859694843292236 and perplexity is 47.45086920827356
At time: 357.7304196357727 and batch: 1150, loss is 3.834876914024353 and perplexity is 46.287729946901855
At time: 358.8824737071991 and batch: 1200, loss is 3.8794630432128905 and perplexity is 48.398220340050436
At time: 360.0352051258087 and batch: 1250, loss is 3.882415428161621 and perplexity is 48.541321658470956
At time: 361.18642687797546 and batch: 1300, loss is 3.8634116077423095 and perplexity is 47.627561069679786
At time: 362.33949542045593 and batch: 1350, loss is 3.754576587677002 and perplexity is 42.71612944538294
At time: 363.49099946022034 and batch: 1400, loss is 3.774965929985046 and perplexity is 43.596022973266194
At time: 364.64702892303467 and batch: 1450, loss is 3.712062735557556 and perplexity is 40.93816410014693
At time: 365.80080556869507 and batch: 1500, loss is 3.700451111793518 and perplexity is 40.4655547322498
At time: 366.9536278247833 and batch: 1550, loss is 3.7311454439163207 and perplexity is 41.72687659772149
At time: 368.10842204093933 and batch: 1600, loss is 3.808515329360962 and perplexity is 45.08345507213454
At time: 369.2621765136719 and batch: 1650, loss is 3.760329384803772 and perplexity is 42.96257486771294
At time: 370.4158298969269 and batch: 1700, loss is 3.7571372175216675 and perplexity is 42.82564980199411
At time: 371.5691382884979 and batch: 1750, loss is 3.7505729722976686 and perplexity is 42.545452383226205
At time: 372.7218813896179 and batch: 1800, loss is 3.7071582746505736 and perplexity is 40.73787602869529
At time: 373.8728804588318 and batch: 1850, loss is 3.7350199890136717 and perplexity is 41.88886287178684
At time: 375.0229723453522 and batch: 1900, loss is 3.833721594810486 and perplexity is 46.23428372279755
At time: 376.1721031665802 and batch: 1950, loss is 3.7499922847747804 and perplexity is 42.5207539416041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36986566587936 and perplexity of 79.03301415597309
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 379.8280863761902 and batch: 50, loss is 3.936263499259949 and perplexity is 51.22683415087544
At time: 380.9895136356354 and batch: 100, loss is 3.9455481290817263 and perplexity is 51.70467118024333
At time: 382.11614513397217 and batch: 150, loss is 3.911502366065979 and perplexity is 49.97397480734937
At time: 383.24204993247986 and batch: 200, loss is 3.9172233724594117 and perplexity is 50.26069562050151
At time: 384.36711835861206 and batch: 250, loss is 3.9160965871810913 and perplexity is 50.20409450323963
At time: 385.4941930770874 and batch: 300, loss is 3.9296473264694214 and perplexity is 50.889027291153404
At time: 386.62802243232727 and batch: 350, loss is 3.934340167045593 and perplexity is 51.12840261912478
At time: 387.76124715805054 and batch: 400, loss is 3.8836035346984863 and perplexity is 48.59902819400931
At time: 388.90038442611694 and batch: 450, loss is 3.924001455307007 and perplexity is 50.60252394103282
At time: 390.0395188331604 and batch: 500, loss is 3.9113998413085938 and perplexity is 49.968851500344066
At time: 391.18583703041077 and batch: 550, loss is 3.890579605102539 and perplexity is 48.939243740330596
At time: 392.33764910697937 and batch: 600, loss is 3.8685900497436525 and perplexity is 47.87483733265243
At time: 393.48907351493835 and batch: 650, loss is 3.9065677738189697 and perplexity is 49.72798105730491
At time: 394.6460177898407 and batch: 700, loss is 3.9474591779708863 and perplexity is 51.803575810357614
At time: 395.79900455474854 and batch: 750, loss is 3.8886460351943968 and perplexity is 48.84470771676568
At time: 396.95312905311584 and batch: 800, loss is 3.8774120140075685 and perplexity is 48.299055905985675
At time: 398.10808634757996 and batch: 850, loss is 3.8745847749710083 and perplexity is 48.162695781862624
At time: 399.260276556015 and batch: 900, loss is 3.8251853609085082 and perplexity is 45.84129676327444
At time: 400.4499101638794 and batch: 950, loss is 3.9277323055267335 and perplexity is 50.79166699139849
At time: 401.60065150260925 and batch: 1000, loss is 3.886901435852051 and perplexity is 48.75956756113027
At time: 402.75239300727844 and batch: 1050, loss is 3.842846574783325 and perplexity is 46.65810135877716
At time: 403.9047465324402 and batch: 1100, loss is 3.8502079010009767 and perplexity is 47.002834152120975
At time: 405.06280851364136 and batch: 1150, loss is 3.8213664865493775 and perplexity is 45.666568455553154
At time: 406.21484565734863 and batch: 1200, loss is 3.860357823371887 and perplexity is 47.48233861996462
At time: 407.3647334575653 and batch: 1250, loss is 3.8607018280029295 and perplexity is 47.49867557417546
At time: 408.51507592201233 and batch: 1300, loss is 3.847167191505432 and perplexity is 46.860129260010446
At time: 409.6730811595917 and batch: 1350, loss is 3.732873964309692 and perplexity is 41.79906472622495
At time: 410.8278057575226 and batch: 1400, loss is 3.7465808248519896 and perplexity is 42.37594324203737
At time: 411.98473501205444 and batch: 1450, loss is 3.6754063177108764 and perplexity is 39.46468880196287
At time: 413.13644909858704 and batch: 1500, loss is 3.658015170097351 and perplexity is 38.78428621342114
At time: 414.28752732276917 and batch: 1550, loss is 3.689730930328369 and perplexity is 40.03407355292859
At time: 415.4391119480133 and batch: 1600, loss is 3.7634031534194947 and perplexity is 43.09483504645179
At time: 416.5971722602844 and batch: 1650, loss is 3.7166154479980467 and perplexity is 41.12496870028891
At time: 417.7492995262146 and batch: 1700, loss is 3.7060905170440672 and perplexity is 40.694401066184206
At time: 418.90351390838623 and batch: 1750, loss is 3.6973410940170286 and perplexity is 40.33990163066538
At time: 420.05551862716675 and batch: 1800, loss is 3.653045082092285 and perplexity is 38.592003125472225
At time: 421.20640778541565 and batch: 1850, loss is 3.6742129564285277 and perplexity is 39.417621260203454
At time: 422.35046577453613 and batch: 1900, loss is 3.780720047950745 and perplexity is 43.84760274799296
At time: 423.496529340744 and batch: 1950, loss is 3.702486457824707 and perplexity is 40.54800001234905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340360703579215 and perplexity of 76.7352130129844
finished 9 epochs...
Completing Train Step...
At time: 427.13895773887634 and batch: 50, loss is 3.9260462951660156 and perplexity is 50.706103865040326
At time: 428.30225920677185 and batch: 100, loss is 3.9163584423065188 and perplexity is 50.21724242405285
At time: 429.42542481422424 and batch: 150, loss is 3.870885787010193 and perplexity is 47.984871637446474
At time: 430.5486397743225 and batch: 200, loss is 3.87236732006073 and perplexity is 48.056015498680964
At time: 431.68402791023254 and batch: 250, loss is 3.868533525466919 and perplexity is 47.87213131857694
At time: 432.81961011886597 and batch: 300, loss is 3.8790494918823244 and perplexity is 48.378209329706955
At time: 433.9548623561859 and batch: 350, loss is 3.8874164962768556 and perplexity is 48.784688153467734
At time: 435.0996687412262 and batch: 400, loss is 3.836087369918823 and perplexity is 46.343793126615566
At time: 436.2464544773102 and batch: 450, loss is 3.8780085039138794 and perplexity is 48.327874399433696
At time: 437.39265537261963 and batch: 500, loss is 3.867334108352661 and perplexity is 47.81474708567237
At time: 438.53900361061096 and batch: 550, loss is 3.8482456827163696 and perplexity is 46.910694759883114
At time: 439.68508100509644 and batch: 600, loss is 3.8290742158889772 and perplexity is 46.01991400166683
At time: 440.8307914733887 and batch: 650, loss is 3.8693548107147215 and perplexity is 47.91146414333325
At time: 441.9765799045563 and batch: 700, loss is 3.911431941986084 and perplexity is 49.97045556007621
At time: 443.12520718574524 and batch: 750, loss is 3.8545751333236695 and perplexity is 47.20855533782237
At time: 444.27858304977417 and batch: 800, loss is 3.8440472984313967 and perplexity is 46.71415849228071
At time: 445.43261790275574 and batch: 850, loss is 3.8429433584213255 and perplexity is 46.662617318100814
At time: 446.58489775657654 and batch: 900, loss is 3.7958541202545164 and perplexity is 44.516242396660765
At time: 447.7382462024689 and batch: 950, loss is 3.897120327949524 and perplexity is 49.26039089231725
At time: 448.8927843570709 and batch: 1000, loss is 3.856736421585083 and perplexity is 47.31069697331114
At time: 450.05774450302124 and batch: 1050, loss is 3.81451997756958 and perplexity is 45.35497974911824
At time: 451.21331119537354 and batch: 1100, loss is 3.820342221260071 and perplexity is 45.61981772126683
At time: 452.3736741542816 and batch: 1150, loss is 3.794778518676758 and perplexity is 44.468386397710816
At time: 453.5297281742096 and batch: 1200, loss is 3.8359571361541747 and perplexity is 46.33775799296621
At time: 454.68333625793457 and batch: 1250, loss is 3.838789839744568 and perplexity is 46.46920521401451
At time: 455.8371069431305 and batch: 1300, loss is 3.8272414588928223 and perplexity is 45.935647925525586
At time: 456.9898326396942 and batch: 1350, loss is 3.7145520782470705 and perplexity is 41.04020016835034
At time: 458.1513202190399 and batch: 1400, loss is 3.7304660511016845 and perplexity is 41.69853728543641
At time: 459.31285285949707 and batch: 1450, loss is 3.6621564960479738 and perplexity is 38.9452376304992
At time: 460.46529245376587 and batch: 1500, loss is 3.6468238973617555 and perplexity is 38.352660414459415
At time: 461.6196482181549 and batch: 1550, loss is 3.6811521005630494 and perplexity is 39.692097027651364
At time: 462.7727379798889 and batch: 1600, loss is 3.7566394901275633 and perplexity is 42.804339606691265
At time: 463.93434405326843 and batch: 1650, loss is 3.710736198425293 and perplexity is 40.883894108878934
At time: 465.0980393886566 and batch: 1700, loss is 3.7019765996932983 and perplexity is 40.52733155426884
At time: 466.2511417865753 and batch: 1750, loss is 3.6953799057006838 and perplexity is 40.260865015081286
At time: 467.41008949279785 and batch: 1800, loss is 3.652436819076538 and perplexity is 38.56853617502996
At time: 468.5752890110016 and batch: 1850, loss is 3.677001323699951 and perplexity is 39.52768544361381
At time: 469.7286207675934 and batch: 1900, loss is 3.784474458694458 and perplexity is 44.012534075075486
At time: 470.8830819129944 and batch: 1950, loss is 3.7063695049285887 and perplexity is 40.7057558949057
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33970095612282 and perplexity of 76.68460384785283
finished 10 epochs...
Completing Train Step...
At time: 474.56004881858826 and batch: 50, loss is 3.9087978076934813 and perplexity is 49.83899988143451
At time: 475.6879127025604 and batch: 100, loss is 3.896447343826294 and perplexity is 49.22725058404405
At time: 476.8102011680603 and batch: 150, loss is 3.852138376235962 and perplexity is 47.0936595993572
At time: 477.940407037735 and batch: 200, loss is 3.850069131851196 and perplexity is 46.99631206133137
At time: 479.0627017021179 and batch: 250, loss is 3.845255765914917 and perplexity is 46.77064515811371
At time: 480.1937777996063 and batch: 300, loss is 3.8561946105957032 and perplexity is 47.285070460765745
At time: 481.32933712005615 and batch: 350, loss is 3.8645569038391114 and perplexity is 47.68213997801248
At time: 482.4661588668823 and batch: 400, loss is 3.8131454944610597 and perplexity is 45.29268291834421
At time: 483.60677433013916 and batch: 450, loss is 3.855871295928955 and perplexity is 47.26978497511157
At time: 484.75853848457336 and batch: 500, loss is 3.8460091972351074 and perplexity is 46.805896905258955
At time: 485.9236261844635 and batch: 550, loss is 3.8272317028045655 and perplexity is 45.93519977547639
At time: 487.06231236457825 and batch: 600, loss is 3.8087932872772217 and perplexity is 45.095988117113016
At time: 488.2016112804413 and batch: 650, loss is 3.8495537424087525 and perplexity is 46.97209689891672
At time: 489.35755014419556 and batch: 700, loss is 3.8918539333343505 and perplexity is 49.00164815368032
At time: 490.50351119041443 and batch: 750, loss is 3.8356177854537963 and perplexity is 46.32203591013812
At time: 491.64958238601685 and batch: 800, loss is 3.8256402254104613 and perplexity is 45.86215308493614
At time: 492.802618265152 and batch: 850, loss is 3.8250081634521482 and perplexity is 45.83317452173327
At time: 493.9596962928772 and batch: 900, loss is 3.7788137197494507 and perplexity is 43.764094448718
At time: 495.12144470214844 and batch: 950, loss is 3.8795438480377196 and perplexity is 48.40213130777746
At time: 496.29142689704895 and batch: 1000, loss is 3.8393031978607177 and perplexity is 46.49306668187722
At time: 497.4395275115967 and batch: 1050, loss is 3.797823395729065 and perplexity is 44.60399351573632
At time: 498.58514738082886 and batch: 1100, loss is 3.802898631095886 and perplexity is 44.830944709340216
At time: 499.73026990890503 and batch: 1150, loss is 3.778544054031372 and perplexity is 43.7522943638731
At time: 500.87895131111145 and batch: 1200, loss is 3.821002287864685 and perplexity is 45.64993977964197
At time: 502.04251980781555 and batch: 1250, loss is 3.824878716468811 and perplexity is 45.82724193954038
At time: 503.2119483947754 and batch: 1300, loss is 3.814341735839844 and perplexity is 45.346896319499244
At time: 504.3807632923126 and batch: 1350, loss is 3.7021030235290526 and perplexity is 40.53245549886436
At time: 505.54487776756287 and batch: 1400, loss is 3.7190399074554445 and perplexity is 41.22479548368556
At time: 506.7093904018402 and batch: 1450, loss is 3.6518599939346315 and perplexity is 38.54629528884552
At time: 507.8801827430725 and batch: 1500, loss is 3.6374241161346434 and perplexity is 37.99384284239123
At time: 509.0447759628296 and batch: 1550, loss is 3.6726307392120363 and perplexity is 39.35530333446054
At time: 510.19934344291687 and batch: 1600, loss is 3.7486112022399904 and perplexity is 42.462069804115714
At time: 511.3518669605255 and batch: 1650, loss is 3.7028293895721434 and perplexity is 40.561907593387566
At time: 512.5074393749237 and batch: 1700, loss is 3.6949504613876343 and perplexity is 40.24357892753376
At time: 513.6661677360535 and batch: 1750, loss is 3.68926335811615 and perplexity is 40.01535910811145
At time: 514.8173990249634 and batch: 1800, loss is 3.64657883644104 and perplexity is 38.34326282772401
At time: 515.9624621868134 and batch: 1850, loss is 3.672850728034973 and perplexity is 39.36396201368881
At time: 517.1084685325623 and batch: 1900, loss is 3.780734519958496 and perplexity is 43.848237315431525
At time: 518.2550981044769 and batch: 1950, loss is 3.703151321411133 and perplexity is 40.57496786503787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340841319949128 and perplexity of 76.77210207654102
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 521.940271615982 and batch: 50, loss is 3.9055887269973755 and perplexity is 49.67931886067795
At time: 523.0660579204559 and batch: 100, loss is 3.9116593027114868 and perplexity is 49.981818170757805
At time: 524.1977396011353 and batch: 150, loss is 3.8717697429656983 and perplexity is 48.02730690319433
At time: 525.3204398155212 and batch: 200, loss is 3.879657893180847 and perplexity is 48.40765165054828
At time: 526.4569804668427 and batch: 250, loss is 3.8860261631011963 and perplexity is 48.71690831226306
At time: 527.5937581062317 and batch: 300, loss is 3.894409627914429 and perplexity is 49.12704156566192
At time: 528.7289505004883 and batch: 350, loss is 3.908657021522522 and perplexity is 49.83198373337665
At time: 529.8649032115936 and batch: 400, loss is 3.862626142501831 and perplexity is 47.59016596417114
At time: 531.0117728710175 and batch: 450, loss is 3.9081976652145385 and perplexity is 49.809098353983515
At time: 532.1719589233398 and batch: 500, loss is 3.8944378423690797 and perplexity is 49.128427677902415
At time: 533.327817440033 and batch: 550, loss is 3.8750687217712403 and perplexity is 48.1860096052469
At time: 534.4814360141754 and batch: 600, loss is 3.8442250061035157 and perplexity is 46.72246069430202
At time: 535.642368555069 and batch: 650, loss is 3.872408599853516 and perplexity is 48.05799928198766
At time: 536.8028690814972 and batch: 700, loss is 3.9128787231445314 and perplexity is 50.04280419736232
At time: 537.9554612636566 and batch: 750, loss is 3.854041085243225 and perplexity is 47.183350430378916
At time: 539.1095974445343 and batch: 800, loss is 3.846629095077515 and perplexity is 46.83492077475008
At time: 540.2635486125946 and batch: 850, loss is 3.843061547279358 and perplexity is 46.66813264547314
At time: 541.4255330562592 and batch: 900, loss is 3.7951217699050903 and perplexity is 44.483652845927445
At time: 542.603434085846 and batch: 950, loss is 3.8982604503631593 and perplexity is 49.3165857965257
At time: 543.757227897644 and batch: 1000, loss is 3.8578749799728396 and perplexity is 47.36459364060977
At time: 544.9118392467499 and batch: 1050, loss is 3.8111131954193116 and perplexity is 45.20072811373132
At time: 546.0607521533966 and batch: 1100, loss is 3.817131462097168 and perplexity is 45.47357836881021
At time: 547.2123267650604 and batch: 1150, loss is 3.7930345916748047 and perplexity is 44.390904359085276
At time: 548.362548828125 and batch: 1200, loss is 3.8272139692306517 and perplexity is 45.93438518743873
At time: 549.5090701580048 and batch: 1250, loss is 3.8245720863342285 and perplexity is 45.813192080342105
At time: 550.6621589660645 and batch: 1300, loss is 3.81785120010376 and perplexity is 45.506319212459374
At time: 551.819019317627 and batch: 1350, loss is 3.706727728843689 and perplexity is 40.72034028223168
At time: 552.9710919857025 and batch: 1400, loss is 3.725794668197632 and perplexity is 41.50420171256976
At time: 554.1170842647552 and batch: 1450, loss is 3.6577150583267213 and perplexity is 38.77264833903191
At time: 555.2659492492676 and batch: 1500, loss is 3.636878352165222 and perplexity is 37.973112829269674
At time: 556.4196951389313 and batch: 1550, loss is 3.6704559421539305 and perplexity is 39.26980653933529
At time: 557.5740671157837 and batch: 1600, loss is 3.741529631614685 and perplexity is 42.16243385665674
At time: 558.726149559021 and batch: 1650, loss is 3.6947015810012815 and perplexity is 40.23356433633142
At time: 559.880181312561 and batch: 1700, loss is 3.6821387243270873 and perplexity is 39.731277518846916
At time: 561.0358512401581 and batch: 1750, loss is 3.676832480430603 and perplexity is 39.52101202337065
At time: 562.2008605003357 and batch: 1800, loss is 3.6365115737915037 and perplexity is 37.9591876665815
At time: 563.3581595420837 and batch: 1850, loss is 3.6558027935028075 and perplexity is 38.69857561338919
At time: 564.5129063129425 and batch: 1900, loss is 3.7675577640533446 and perplexity is 43.27424974744221
At time: 565.6747677326202 and batch: 1950, loss is 3.7056430053710936 and perplexity is 40.67619392094129
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325729866914971 and perplexity of 75.62068575946354
finished 12 epochs...
Completing Train Step...
At time: 569.3609807491302 and batch: 50, loss is 3.9230221462249757 and perplexity is 50.55299268692573
At time: 570.4796197414398 and batch: 100, loss is 3.9087874364852904 and perplexity is 49.8384829934711
At time: 571.6204099655151 and batch: 150, loss is 3.8598903799057007 and perplexity is 47.46014849773535
At time: 572.7371034622192 and batch: 200, loss is 3.860159311294556 and perplexity is 47.47291373779604
At time: 573.856687784195 and batch: 250, loss is 3.8628970193862915 and perplexity is 47.60305878616337
At time: 574.9921417236328 and batch: 300, loss is 3.8684299993515014 and perplexity is 47.86717555931445
At time: 576.142660856247 and batch: 350, loss is 3.8819255733489992 and perplexity is 48.51754928142754
At time: 577.284065246582 and batch: 400, loss is 3.8356975984573363 and perplexity is 46.32573315849648
At time: 578.4331514835358 and batch: 450, loss is 3.8823346757888793 and perplexity is 48.53740198983441
At time: 579.5878338813782 and batch: 500, loss is 3.871164197921753 and perplexity is 47.99823300918968
At time: 580.7431533336639 and batch: 550, loss is 3.8540431547164915 and perplexity is 47.183448075162296
At time: 581.8955578804016 and batch: 600, loss is 3.8257007884979246 and perplexity is 45.86493072263498
At time: 583.0474174022675 and batch: 650, loss is 3.8562456607818603 and perplexity is 47.28748443403158
At time: 584.2084283828735 and batch: 700, loss is 3.8977402448654175 and perplexity is 49.29093770918091
At time: 585.3624093532562 and batch: 750, loss is 3.840437607765198 and perplexity is 46.54583880416058
At time: 586.5198111534119 and batch: 800, loss is 3.8327589941024782 and perplexity is 46.18979998202682
At time: 587.6804573535919 and batch: 850, loss is 3.830179600715637 and perplexity is 46.0708118419961
At time: 588.832160949707 and batch: 900, loss is 3.7826382732391357 and perplexity is 43.93179305058774
At time: 589.9849457740784 and batch: 950, loss is 3.8859712266921997 and perplexity is 48.71423205377566
At time: 591.1365594863892 and batch: 1000, loss is 3.8457096862792968 and perplexity is 46.791880125533616
At time: 592.2900943756104 and batch: 1050, loss is 3.800281958580017 and perplexity is 44.71379015285906
At time: 593.4483921527863 and batch: 1100, loss is 3.8068106269836424 and perplexity is 45.006666668378166
At time: 594.6076626777649 and batch: 1150, loss is 3.782415342330933 and perplexity is 43.922000387648175
At time: 595.7635700702667 and batch: 1200, loss is 3.817511200904846 and perplexity is 45.490849730336414
At time: 596.9183804988861 and batch: 1250, loss is 3.8164762115478514 and perplexity is 45.44379154158786
At time: 598.0707914829254 and batch: 1300, loss is 3.810158052444458 and perplexity is 45.15757556752157
At time: 599.2258412837982 and batch: 1350, loss is 3.700447974205017 and perplexity is 40.46542776818976
At time: 600.3808765411377 and batch: 1400, loss is 3.7208649587631224 and perplexity is 41.30010154840523
At time: 601.5312428474426 and batch: 1450, loss is 3.6550026035308836 and perplexity is 38.667621787377854
At time: 602.6914687156677 and batch: 1500, loss is 3.635765805244446 and perplexity is 37.93088945161878
At time: 603.8498990535736 and batch: 1550, loss is 3.670498571395874 and perplexity is 39.27148061710142
At time: 605.0049159526825 and batch: 1600, loss is 3.742897596359253 and perplexity is 42.22015004757451
At time: 606.1637823581696 and batch: 1650, loss is 3.6970393323898314 and perplexity is 40.327730432800934
At time: 607.3230285644531 and batch: 1700, loss is 3.685176453590393 and perplexity is 39.85215388512008
At time: 608.4783914089203 and batch: 1750, loss is 3.6808764505386353 and perplexity is 39.68115740795913
At time: 609.6292791366577 and batch: 1800, loss is 3.6410408782958985 and perplexity is 38.131506333532855
At time: 610.7873315811157 and batch: 1850, loss is 3.6606480646133424 and perplexity is 38.886535694881346
At time: 611.9386856555939 and batch: 1900, loss is 3.772517352104187 and perplexity is 43.48940529982801
At time: 613.0971856117249 and batch: 1950, loss is 3.7101355171203614 and perplexity is 40.85934329236138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324464026162791 and perplexity of 75.52502257367479
finished 13 epochs...
Completing Train Step...
At time: 616.7479808330536 and batch: 50, loss is 3.9187899351119997 and perplexity is 50.33949385422368
At time: 617.8931686878204 and batch: 100, loss is 3.9024462604522707 and perplexity is 49.523448300454824
At time: 619.0131969451904 and batch: 150, loss is 3.8527732276916504 and perplexity is 47.12356656994499
At time: 620.1324520111084 and batch: 200, loss is 3.8517363357543943 and perplexity is 47.074729847291394
At time: 621.2622463703156 and batch: 250, loss is 3.85361225605011 and perplexity is 47.16312117004409
At time: 622.4000227451324 and batch: 300, loss is 3.8590719175338744 and perplexity is 47.42132004401036
At time: 623.5367376804352 and batch: 350, loss is 3.872456555366516 and perplexity is 48.060303983258116
At time: 624.6723248958588 and batch: 400, loss is 3.8257590103149415 and perplexity is 45.86760113997653
At time: 625.8158302307129 and batch: 450, loss is 3.8726847267150877 and perplexity is 48.07127121878762
At time: 626.9673728942871 and batch: 500, loss is 3.861952977180481 and perplexity is 47.55814069516639
At time: 628.1139485836029 and batch: 550, loss is 3.84494779586792 and perplexity is 46.75624341809238
At time: 629.2827293872833 and batch: 600, loss is 3.8172368812561035 and perplexity is 45.47837240788298
At time: 630.4286389350891 and batch: 650, loss is 3.8483465623855593 and perplexity is 46.915427333958185
At time: 631.5772550106049 and batch: 700, loss is 3.890210494995117 and perplexity is 48.92118310420318
At time: 632.736123085022 and batch: 750, loss is 3.833413519859314 and perplexity is 46.220042291923875
At time: 633.8946163654327 and batch: 800, loss is 3.8256662607192995 and perplexity is 45.86334713579936
At time: 635.0482230186462 and batch: 850, loss is 3.8234754943847657 and perplexity is 45.76298123816187
At time: 636.2080874443054 and batch: 900, loss is 3.776196393966675 and perplexity is 43.649699325914
At time: 637.3704800605774 and batch: 950, loss is 3.8794993925094605 and perplexity is 48.39997961328902
At time: 638.5234339237213 and batch: 1000, loss is 3.8395164442062377 and perplexity is 46.502982215627235
At time: 639.6829364299774 and batch: 1050, loss is 3.7946038007736207 and perplexity is 44.460617653172655
At time: 640.8382804393768 and batch: 1100, loss is 3.8009997987747193 and perplexity is 44.74589903183143
At time: 641.9921405315399 and batch: 1150, loss is 3.7766231060028077 and perplexity is 43.66832915249288
At time: 643.1542074680328 and batch: 1200, loss is 3.8123171091079713 and perplexity is 45.25517865934668
At time: 644.3067772388458 and batch: 1250, loss is 3.8118551683425905 and perplexity is 45.234278275220724
At time: 645.4634139537811 and batch: 1300, loss is 3.8059731912612915 and perplexity is 44.96899225511762
At time: 646.6163804531097 and batch: 1350, loss is 3.6967503786087037 and perplexity is 40.31607926601349
At time: 647.7740252017975 and batch: 1400, loss is 3.7177521562576294 and perplexity is 41.17174237085807
At time: 648.9268684387207 and batch: 1450, loss is 3.653030891418457 and perplexity is 38.591455482829225
At time: 650.0888407230377 and batch: 1500, loss is 3.6343088865280153 and perplexity is 37.87566746558627
At time: 651.2437508106232 and batch: 1550, loss is 3.6698239183425905 and perplexity is 39.24499492812619
At time: 652.406391620636 and batch: 1600, loss is 3.7427056550979616 and perplexity is 42.212047036398445
At time: 653.5605626106262 and batch: 1650, loss is 3.6971258544921874 and perplexity is 40.33121982377377
At time: 654.7144210338593 and batch: 1700, loss is 3.685355181694031 and perplexity is 39.8592772215611
At time: 655.8666806221008 and batch: 1750, loss is 3.681481671333313 and perplexity is 39.7051805384951
At time: 657.0284996032715 and batch: 1800, loss is 3.6416623878479 and perplexity is 38.15521279508441
At time: 658.1803410053253 and batch: 1850, loss is 3.6615091657638548 and perplexity is 38.92003535673634
At time: 659.3323202133179 and batch: 1900, loss is 3.7731775569915773 and perplexity is 43.51812669771706
At time: 660.4856488704681 and batch: 1950, loss is 3.7104267072677612 and perplexity is 40.871242862992126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3243834029796515 and perplexity of 75.51893375140165
finished 14 epochs...
Completing Train Step...
At time: 664.1481592655182 and batch: 50, loss is 3.9139972352981567 and perplexity is 50.0988089972444
At time: 665.2984039783478 and batch: 100, loss is 3.896846890449524 and perplexity is 49.24692309556687
At time: 666.4189374446869 and batch: 150, loss is 3.846869988441467 and perplexity is 46.84620435538124
At time: 667.5397353172302 and batch: 200, loss is 3.8451710319519044 and perplexity is 46.766682263895035
At time: 668.660231590271 and batch: 250, loss is 3.8467843389511107 and perplexity is 46.842192173676175
At time: 669.795334815979 and batch: 300, loss is 3.8521503973007203 and perplexity is 47.094225718691625
At time: 670.9331305027008 and batch: 350, loss is 3.865579676628113 and perplexity is 47.730932921097214
At time: 672.0674088001251 and batch: 400, loss is 3.818585042953491 and perplexity is 45.53972595558161
At time: 673.2012321949005 and batch: 450, loss is 3.865755386352539 and perplexity is 47.73932044703073
At time: 674.3520710468292 and batch: 500, loss is 3.8552582263946533 and perplexity is 47.24081419151013
At time: 675.5025537014008 and batch: 550, loss is 3.838286123275757 and perplexity is 46.445803804388156
At time: 676.652880191803 and batch: 600, loss is 3.8110112142562866 and perplexity is 45.19611872594807
At time: 677.8043563365936 and batch: 650, loss is 3.842486548423767 and perplexity is 46.641306235925946
At time: 678.9545066356659 and batch: 700, loss is 3.8845691537857054 and perplexity is 48.64597900790662
At time: 680.1130254268646 and batch: 750, loss is 3.828026309013367 and perplexity is 45.971714675982554
At time: 681.2650444507599 and batch: 800, loss is 3.820293049812317 and perplexity is 45.61757458393281
At time: 682.4164729118347 and batch: 850, loss is 3.818368926048279 and perplexity is 45.529885114368255
At time: 683.5664849281311 and batch: 900, loss is 3.7712620592117307 and perplexity is 43.43484760856318
At time: 684.71653175354 and batch: 950, loss is 3.8745342683792114 and perplexity is 48.16026330967539
At time: 685.8673062324524 and batch: 1000, loss is 3.834735255241394 and perplexity is 46.281173347822524
At time: 687.0405271053314 and batch: 1050, loss is 3.7900908994674682 and perplexity is 44.26042334204503
At time: 688.1907069683075 and batch: 1100, loss is 3.7962383127212522 and perplexity is 44.53334848744214
At time: 689.3403697013855 and batch: 1150, loss is 3.7718739748001098 and perplexity is 43.461434202439754
At time: 690.4904041290283 and batch: 1200, loss is 3.807994394302368 and perplexity is 45.05997563598662
At time: 691.6415567398071 and batch: 1250, loss is 3.807883276939392 and perplexity is 45.05496896848719
At time: 692.7915737628937 and batch: 1300, loss is 3.802353677749634 and perplexity is 44.806520591612
At time: 693.9422762393951 and batch: 1350, loss is 3.6933536672592164 and perplexity is 40.179369495261156
At time: 695.1005339622498 and batch: 1400, loss is 3.7147997617721558 and perplexity is 41.0503664087514
At time: 696.2512078285217 and batch: 1450, loss is 3.6508442640304564 and perplexity is 38.50716254154077
At time: 697.4033551216125 and batch: 1500, loss is 3.6324356603622436 and perplexity is 37.80478418517876
At time: 698.5550475120544 and batch: 1550, loss is 3.668486590385437 and perplexity is 39.1925465773701
At time: 699.70885181427 and batch: 1600, loss is 3.741667914390564 and perplexity is 42.16826459818452
At time: 700.8612389564514 and batch: 1650, loss is 3.6962206840515135 and perplexity is 40.29472971312919
At time: 702.0134592056274 and batch: 1700, loss is 3.684459004402161 and perplexity is 39.82357224382956
At time: 703.1678321361542 and batch: 1750, loss is 3.6808763790130614 and perplexity is 39.68115456974167
At time: 704.3210327625275 and batch: 1800, loss is 3.6409768629074097 and perplexity is 38.12906540847047
At time: 705.4854581356049 and batch: 1850, loss is 3.6610210943222046 and perplexity is 38.90104423386006
At time: 706.6373674869537 and batch: 1900, loss is 3.772498083114624 and perplexity is 43.48856731100483
At time: 707.8045265674591 and batch: 1950, loss is 3.7095067930221557 and perplexity is 40.83366211263087
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324675803960756 and perplexity of 75.54101879040869
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 711.4590864181519 and batch: 50, loss is 3.9153301525115967 and perplexity is 50.16563108639271
At time: 712.6140410900116 and batch: 100, loss is 3.9076036548614503 and perplexity is 49.77952001967139
At time: 713.7385816574097 and batch: 150, loss is 3.8625920534133913 and perplexity is 47.588543686445874
At time: 714.8829643726349 and batch: 200, loss is 3.8632633781433103 and perplexity is 47.62050177861199
At time: 716.0039751529694 and batch: 250, loss is 3.870425901412964 and perplexity is 47.96280915959227
At time: 717.1394882202148 and batch: 300, loss is 3.8720952701568603 and perplexity is 48.04294364246342
At time: 718.2757377624512 and batch: 350, loss is 3.8855400037765504 and perplexity is 48.693229889228576
At time: 719.4191184043884 and batch: 400, loss is 3.8412679862976074 and perplexity is 46.58450552126063
At time: 720.5619397163391 and batch: 450, loss is 3.8945339918136597 and perplexity is 49.13315157603318
At time: 721.7054393291473 and batch: 500, loss is 3.884902458190918 and perplexity is 48.66219562939139
At time: 722.849189043045 and batch: 550, loss is 3.875723543167114 and perplexity is 48.217573168438605
At time: 724.0051248073578 and batch: 600, loss is 3.84102557182312 and perplexity is 46.5732141314889
At time: 725.1495232582092 and batch: 650, loss is 3.8621729230880737 and perplexity is 47.56860206401046
At time: 726.2923269271851 and batch: 700, loss is 3.90073676109314 and perplexity is 49.43886031947279
At time: 727.4351212978363 and batch: 750, loss is 3.846071982383728 and perplexity is 46.80883571270824
At time: 728.5825750827789 and batch: 800, loss is 3.835701251029968 and perplexity is 46.32590236691059
At time: 729.73512840271 and batch: 850, loss is 3.8360032510757445 and perplexity is 46.33989490431315
At time: 730.8864188194275 and batch: 900, loss is 3.78382595539093 and perplexity is 43.984001054210296
At time: 732.0374009609222 and batch: 950, loss is 3.88870717048645 and perplexity is 48.847693943518195
At time: 733.1880009174347 and batch: 1000, loss is 3.848510003089905 and perplexity is 46.92309585110318
At time: 734.3387629985809 and batch: 1050, loss is 3.8051537132263182 and perplexity is 44.93215624892007
At time: 735.4901852607727 and batch: 1100, loss is 3.810931434631348 and perplexity is 45.19251314037547
At time: 736.6420819759369 and batch: 1150, loss is 3.7890319776535035 and perplexity is 44.213579820463444
At time: 737.7937784194946 and batch: 1200, loss is 3.8261566400527953 and perplexity is 45.8858430887241
At time: 738.944473028183 and batch: 1250, loss is 3.8197144269943237 and perplexity is 45.591186849385934
At time: 740.0959966182709 and batch: 1300, loss is 3.8077863216400147 and perplexity is 45.05060086224135
At time: 741.2465505599976 and batch: 1350, loss is 3.6950404930114744 and perplexity is 40.247202285399695
At time: 742.398839712143 and batch: 1400, loss is 3.7147960376739504 and perplexity is 41.05021353344019
At time: 743.5495445728302 and batch: 1450, loss is 3.648558807373047 and perplexity is 38.419256581446476
At time: 744.6998064517975 and batch: 1500, loss is 3.6311803007125856 and perplexity is 37.75735536089348
At time: 745.8515250682831 and batch: 1550, loss is 3.66954758644104 and perplexity is 39.234151782273905
At time: 747.0039865970612 and batch: 1600, loss is 3.7425578880310058 and perplexity is 42.20580994684724
At time: 748.1533641815186 and batch: 1650, loss is 3.698587164878845 and perplexity is 40.390199337401214
At time: 749.3038892745972 and batch: 1700, loss is 3.6847510862350465 and perplexity is 39.83520568467826
At time: 750.454756975174 and batch: 1750, loss is 3.6829199171066285 and perplexity is 39.762327432371656
At time: 751.6059670448303 and batch: 1800, loss is 3.641441226005554 and perplexity is 38.14677525099333
At time: 752.7573268413544 and batch: 1850, loss is 3.657131404876709 and perplexity is 38.7500251517556
At time: 753.9117543697357 and batch: 1900, loss is 3.766897358894348 and perplexity is 43.24568064428719
At time: 755.0687732696533 and batch: 1950, loss is 3.7102298069000246 and perplexity is 40.86319609247458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319036723292151 and perplexity of 75.11623571033593
finished 16 epochs...
Completing Train Step...
At time: 758.735696554184 and batch: 50, loss is 3.918925757408142 and perplexity is 50.346331544210486
At time: 759.8577268123627 and batch: 100, loss is 3.9035319805145265 and perplexity is 49.57724610121783
At time: 760.9803247451782 and batch: 150, loss is 3.8573100900650026 and perplexity is 47.33784541528593
At time: 762.1034636497498 and batch: 200, loss is 3.8548674297332766 and perplexity is 47.22235624593004
At time: 763.2316980361938 and batch: 250, loss is 3.8585835886001587 and perplexity is 47.39816849460367
At time: 764.369660615921 and batch: 300, loss is 3.860346736907959 and perplexity is 47.4818122116483
At time: 765.5100939273834 and batch: 350, loss is 3.8728368520736693 and perplexity is 48.07858463442314
At time: 766.6478743553162 and batch: 400, loss is 3.827789959907532 and perplexity is 45.9608505862347
At time: 767.7858872413635 and batch: 450, loss is 3.880870609283447 and perplexity is 48.466391999678564
At time: 768.9266228675842 and batch: 500, loss is 3.872214126586914 and perplexity is 48.04865419459523
At time: 770.0825598239899 and batch: 550, loss is 3.8625928115844728 and perplexity is 47.58857976671719
At time: 771.2394549846649 and batch: 600, loss is 3.8300388193130495 and perplexity is 46.06432638501321
At time: 772.4320201873779 and batch: 650, loss is 3.851896057128906 and perplexity is 47.08224928833911
At time: 773.5812456607819 and batch: 700, loss is 3.8922655963897705 and perplexity is 49.02182447451789
At time: 774.7347130775452 and batch: 750, loss is 3.83725172996521 and perplexity is 46.39778541486189
At time: 775.8804378509521 and batch: 800, loss is 3.8282520389556884 and perplexity is 45.98209303979445
At time: 777.0307881832123 and batch: 850, loss is 3.8279603719711304 and perplexity is 45.968683537023544
At time: 778.182341337204 and batch: 900, loss is 3.7770049953460694 and perplexity is 43.68500880672265
At time: 779.3447253704071 and batch: 950, loss is 3.881907858848572 and perplexity is 48.5166898248925
At time: 780.5079138278961 and batch: 1000, loss is 3.8426543569564817 and perplexity is 46.64913370182871
At time: 781.6743314266205 and batch: 1050, loss is 3.79950731754303 and perplexity is 44.67916642829775
At time: 782.831748008728 and batch: 1100, loss is 3.8060318088531493 and perplexity is 44.97162830641062
At time: 783.9866816997528 and batch: 1150, loss is 3.783781967163086 and perplexity is 43.98206631850353
At time: 785.1415684223175 and batch: 1200, loss is 3.8203245258331298 and perplexity is 45.619010466257656
At time: 786.2943878173828 and batch: 1250, loss is 3.8153454303741454 and perplexity is 45.392433600419785
At time: 787.4470534324646 and batch: 1300, loss is 3.804539637565613 and perplexity is 44.90457297535985
At time: 788.6086995601654 and batch: 1350, loss is 3.6927681732177735 and perplexity is 40.15585159929856
At time: 789.7631590366364 and batch: 1400, loss is 3.7135284328460694 and perplexity is 40.99821105084189
At time: 790.9177408218384 and batch: 1450, loss is 3.648745050430298 and perplexity is 38.426412567605205
At time: 792.0736634731293 and batch: 1500, loss is 3.632186994552612 and perplexity is 37.795384596637994
At time: 793.22753739357 and batch: 1550, loss is 3.6711033821105956 and perplexity is 39.295239613485165
At time: 794.3816576004028 and batch: 1600, loss is 3.7448774194717407 and perplexity is 42.30382127623708
At time: 795.5356302261353 and batch: 1650, loss is 3.7014278745651246 and perplexity is 40.50509928932624
At time: 796.6889960765839 and batch: 1700, loss is 3.688258857727051 and perplexity is 39.9751838457289
At time: 797.842930316925 and batch: 1750, loss is 3.6874117851257324 and perplexity is 39.94133630044852
At time: 798.9969952106476 and batch: 1800, loss is 3.6468298864364623 and perplexity is 38.35289011209568
At time: 800.1517889499664 and batch: 1850, loss is 3.6620936679840086 and perplexity is 38.94279085348215
At time: 801.3042187690735 and batch: 1900, loss is 3.771659607887268 and perplexity is 43.45211850748617
At time: 802.4576504230499 and batch: 1950, loss is 3.7144326400756835 and perplexity is 41.03529869460624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318078329396802 and perplexity of 75.04427925541088
finished 17 epochs...
Completing Train Step...
At time: 806.1311912536621 and batch: 50, loss is 3.918254771232605 and perplexity is 50.31256118274516
At time: 807.251781463623 and batch: 100, loss is 3.9009834814071653 and perplexity is 49.451059395433916
At time: 808.3732743263245 and batch: 150, loss is 3.8545962285995485 and perplexity is 47.2095512258253
At time: 809.4982945919037 and batch: 200, loss is 3.8511945724487306 and perplexity is 47.049233393181346
At time: 810.6417806148529 and batch: 250, loss is 3.854008870124817 and perplexity is 47.18183043764142
At time: 811.7791137695312 and batch: 300, loss is 3.8556328916549685 and perplexity is 47.258516999563206
At time: 812.9220447540283 and batch: 350, loss is 3.8680236530303955 and perplexity is 47.84772885993914
At time: 814.0675001144409 and batch: 400, loss is 3.822298502922058 and perplexity is 45.70915028543678
At time: 815.2133033275604 and batch: 450, loss is 3.875197401046753 and perplexity is 48.19221054501042
At time: 816.3605935573578 and batch: 500, loss is 3.8667731142044066 and perplexity is 47.78793081494581
At time: 817.5074951648712 and batch: 550, loss is 3.856723403930664 and perplexity is 47.31008110301622
At time: 818.6553690433502 and batch: 600, loss is 3.8251102066040037 and perplexity is 45.837851721955076
At time: 819.8134512901306 and batch: 650, loss is 3.8475598382949827 and perplexity is 46.87853235204338
At time: 820.9642953872681 and batch: 700, loss is 3.8884409713745116 and perplexity is 48.83469246133847
At time: 822.1187217235565 and batch: 750, loss is 3.8336061429977417 and perplexity is 46.22894619905014
At time: 823.2755107879639 and batch: 800, loss is 3.8250195932388307 and perplexity is 45.83369838813487
At time: 824.4362654685974 and batch: 850, loss is 3.8245563745498656 and perplexity is 45.81247227900186
At time: 825.5951161384583 and batch: 900, loss is 3.7740328741073608 and perplexity is 43.55536441908851
At time: 826.751190662384 and batch: 950, loss is 3.879064512252808 and perplexity is 48.37893599379178
At time: 827.9040400981903 and batch: 1000, loss is 3.8403513336181643 and perplexity is 46.54182327484047
At time: 829.0983698368073 and batch: 1050, loss is 3.797394452095032 and perplexity is 44.58486501948193
At time: 830.2499141693115 and batch: 1100, loss is 3.8044788217544556 and perplexity is 44.90184215036919
At time: 831.403382062912 and batch: 1150, loss is 3.7821535634994508 and perplexity is 43.910504042525886
At time: 832.5568356513977 and batch: 1200, loss is 3.8185390567779542 and perplexity is 45.537631805901256
At time: 833.7106878757477 and batch: 1250, loss is 3.814104299545288 and perplexity is 45.336130598604555
At time: 834.8692893981934 and batch: 1300, loss is 3.803582019805908 and perplexity is 44.86159214167608
At time: 836.0229279994965 and batch: 1350, loss is 3.6920540046691896 and perplexity is 40.12718379108669
At time: 837.1764402389526 and batch: 1400, loss is 3.7131325721740724 and perplexity is 40.98198468336689
At time: 838.3319845199585 and batch: 1450, loss is 3.6488365650177004 and perplexity is 38.429929305810646
At time: 839.490727186203 and batch: 1500, loss is 3.6326610612869263 and perplexity is 37.813306378910625
At time: 840.6438732147217 and batch: 1550, loss is 3.6717703533172608 and perplexity is 39.32145714906513
At time: 841.7969615459442 and batch: 1600, loss is 3.7458078622817994 and perplexity is 42.34320087997516
At time: 842.9497020244598 and batch: 1650, loss is 3.7023255681991576 and perplexity is 40.54147678458419
At time: 844.109582901001 and batch: 1700, loss is 3.6893887519836426 and perplexity is 40.02037710335546
At time: 845.2631506919861 and batch: 1750, loss is 3.6889668607711794 and perplexity is 40.00349641909265
At time: 846.4237124919891 and batch: 1800, loss is 3.6486107683181763 and perplexity is 38.42125293419535
At time: 847.5846402645111 and batch: 1850, loss is 3.6637799406051634 and perplexity is 39.0085144138361
At time: 848.7386496067047 and batch: 1900, loss is 3.77305287361145 and perplexity is 43.512701048834735
At time: 849.900887966156 and batch: 1950, loss is 3.7153592538833617 and perplexity is 41.07334019114493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317641715116279 and perplexity of 75.01152100329716
finished 18 epochs...
Completing Train Step...
At time: 853.5620958805084 and batch: 50, loss is 3.916638116836548 and perplexity is 50.23128887185244
At time: 854.6917345523834 and batch: 100, loss is 3.8986554956436157 and perplexity is 49.3360719296919
At time: 855.8119840621948 and batch: 150, loss is 3.8522068452835083 and perplexity is 47.096884167765744
At time: 856.9323017597198 and batch: 200, loss is 3.848440184593201 and perplexity is 46.919819865453675
At time: 858.0791409015656 and batch: 250, loss is 3.850839114189148 and perplexity is 47.03251232656139
At time: 859.20760846138 and batch: 300, loss is 3.852472825050354 and perplexity is 47.10941265212366
At time: 860.3521251678467 and batch: 350, loss is 3.86484206199646 and perplexity is 47.6957388680121
At time: 861.4987766742706 and batch: 400, loss is 3.8188658475875856 and perplexity is 45.55251551726539
At time: 862.6521832942963 and batch: 450, loss is 3.871762685775757 and perplexity is 48.02696796656311
At time: 863.801460981369 and batch: 500, loss is 3.8634413290023804 and perplexity is 47.628976641845064
At time: 864.9482820034027 and batch: 550, loss is 3.853234920501709 and perplexity is 47.145328205023326
At time: 866.0944526195526 and batch: 600, loss is 3.8221473789215086 and perplexity is 45.702243057721006
At time: 867.240443944931 and batch: 650, loss is 3.844842758178711 and perplexity is 46.75133250824747
At time: 868.3946301937103 and batch: 700, loss is 3.88592809677124 and perplexity is 48.71213105810579
At time: 869.5428712368011 and batch: 750, loss is 3.8312318468093873 and perplexity is 46.11931518804562
At time: 870.6944015026093 and batch: 800, loss is 3.8228133153915405 and perplexity is 45.73268798420372
At time: 871.8421409130096 and batch: 850, loss is 3.822327013015747 and perplexity is 45.71045347617081
At time: 872.9878597259521 and batch: 900, loss is 3.771988229751587 and perplexity is 43.46640017018348
At time: 874.1389904022217 and batch: 950, loss is 3.8770734071731567 and perplexity is 48.28270428410197
At time: 875.2864077091217 and batch: 1000, loss is 3.8386696481704714 and perplexity is 46.46362034272678
At time: 876.4382691383362 and batch: 1050, loss is 3.795861744880676 and perplexity is 44.516581817661056
At time: 877.5851590633392 and batch: 1100, loss is 3.8032431602478027 and perplexity is 44.84639293773025
At time: 878.7382407188416 and batch: 1150, loss is 3.780957374572754 and perplexity is 43.85801018636859
At time: 879.8929393291473 and batch: 1200, loss is 3.817356963157654 and perplexity is 45.48383386522566
At time: 881.0513460636139 and batch: 1250, loss is 3.8132077932357786 and perplexity is 45.295504684889146
At time: 882.2162573337555 and batch: 1300, loss is 3.8027858209609984 and perplexity is 44.825887609671824
At time: 883.3767523765564 and batch: 1350, loss is 3.6913595151901246 and perplexity is 40.099325558863576
At time: 884.5312747955322 and batch: 1400, loss is 3.712599792480469 and perplexity is 40.96015612954547
At time: 885.6885900497437 and batch: 1450, loss is 3.6485886573791504 and perplexity is 38.42040341360631
At time: 886.8488314151764 and batch: 1500, loss is 3.6326415157318115 and perplexity is 37.81256730406955
At time: 888.0048553943634 and batch: 1550, loss is 3.671888680458069 and perplexity is 39.32611021994886
At time: 889.159411907196 and batch: 1600, loss is 3.746086630821228 and perplexity is 42.35500647767737
At time: 890.3175547122955 and batch: 1650, loss is 3.702562999725342 and perplexity is 40.55110375211849
At time: 891.4736328125 and batch: 1700, loss is 3.6897609424591065 and perplexity is 40.035275078808105
At time: 892.635468006134 and batch: 1750, loss is 3.689591293334961 and perplexity is 40.02848370554761
At time: 893.7891998291016 and batch: 1800, loss is 3.649287519454956 and perplexity is 38.447263361095345
At time: 894.9499642848969 and batch: 1850, loss is 3.6644316482543946 and perplexity is 39.033944846768506
At time: 896.1048099994659 and batch: 1900, loss is 3.773449602127075 and perplexity is 43.52996720289404
At time: 897.2586433887482 and batch: 1950, loss is 3.7154368114471437 and perplexity is 41.07652586288141
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3174177302870635 and perplexity of 74.99472144206969
finished 19 epochs...
Completing Train Step...
At time: 900.9159142971039 and batch: 50, loss is 3.9149517965316774 and perplexity is 50.14665421011844
At time: 902.0578269958496 and batch: 100, loss is 3.896618895530701 and perplexity is 49.23569632720511
At time: 903.1817650794983 and batch: 150, loss is 3.8501145792007447 and perplexity is 46.99844796768839
At time: 904.3101584911346 and batch: 200, loss is 3.8461607694625854 and perplexity is 46.812991917001774
At time: 905.4532241821289 and batch: 250, loss is 3.848323736190796 and perplexity is 46.91435644549866
At time: 906.589878320694 and batch: 300, loss is 3.8499864101409913 and perplexity is 46.992424606815
At time: 907.723032951355 and batch: 350, loss is 3.862335081100464 and perplexity is 47.576316319420606
At time: 908.8628349304199 and batch: 400, loss is 3.8162448835372924 and perplexity is 45.43328033551336
At time: 910.0104207992554 and batch: 450, loss is 3.869207067489624 and perplexity is 47.904386071982984
At time: 911.1546847820282 and batch: 500, loss is 3.8609460735321046 and perplexity is 47.510278330229156
At time: 912.3057270050049 and batch: 550, loss is 3.850686936378479 and perplexity is 47.025355566369115
At time: 913.4567821025848 and batch: 600, loss is 3.8199467134475706 and perplexity is 45.60177829455549
At time: 914.6081881523132 and batch: 650, loss is 3.8427518939971925 and perplexity is 46.653683942186596
At time: 915.7790718078613 and batch: 700, loss is 3.8839386510849 and perplexity is 48.6153172539339
At time: 916.9297869205475 and batch: 750, loss is 3.8293555068969725 and perplexity is 46.0328608104893
At time: 918.0811131000519 and batch: 800, loss is 3.8210198497772216 and perplexity is 45.650741486931416
At time: 919.2327797412872 and batch: 850, loss is 3.820562553405762 and perplexity is 45.62987034100836
At time: 920.3835406303406 and batch: 900, loss is 3.770317625999451 and perplexity is 43.39384566075963
At time: 921.5409781932831 and batch: 950, loss is 3.8754161834716796 and perplexity is 48.20275530715828
At time: 922.6934418678284 and batch: 1000, loss is 3.837217631340027 and perplexity is 46.39620334114113
At time: 923.8522176742554 and batch: 1050, loss is 3.794536590576172 and perplexity is 44.45762954669822
At time: 925.0035781860352 and batch: 1100, loss is 3.802093925476074 and perplexity is 44.79488350746299
At time: 926.1561603546143 and batch: 1150, loss is 3.7798773050308228 and perplexity is 43.810666057474826
At time: 927.3083872795105 and batch: 1200, loss is 3.8163389205932616 and perplexity is 45.43755294832795
At time: 928.4594733715057 and batch: 1250, loss is 3.8123725414276124 and perplexity is 45.257687328405574
At time: 929.6115810871124 and batch: 1300, loss is 3.8020036125183108 and perplexity is 44.790838131718445
At time: 930.7640523910522 and batch: 1350, loss is 3.6906137037277222 and perplexity is 40.06943017177409
At time: 931.9143388271332 and batch: 1400, loss is 3.711961145401001 and perplexity is 40.934005396892154
At time: 933.0716786384583 and batch: 1450, loss is 3.648148341178894 and perplexity is 38.40349001145866
At time: 934.2253134250641 and batch: 1500, loss is 3.632356171607971 and perplexity is 37.80177924940922
At time: 935.3857855796814 and batch: 1550, loss is 3.67172333240509 and perplexity is 39.31960826175063
At time: 936.5305833816528 and batch: 1600, loss is 3.7460384225845336 and perplexity is 42.35296466671634
At time: 937.6751229763031 and batch: 1650, loss is 3.70249321937561 and perplexity is 40.54827418064205
At time: 938.8188569545746 and batch: 1700, loss is 3.6897931575775145 and perplexity is 40.03656484071007
At time: 939.9618849754333 and batch: 1750, loss is 3.6898057985305788 and perplexity is 40.03707094424588
At time: 941.1043677330017 and batch: 1800, loss is 3.6495095252990724 and perplexity is 38.45579982578925
At time: 942.2491471767426 and batch: 1850, loss is 3.6646505880355833 and perplexity is 39.04249186571928
At time: 943.4011263847351 and batch: 1900, loss is 3.773469295501709 and perplexity is 43.53082446328711
At time: 944.5455098152161 and batch: 1950, loss is 3.715226993560791 and perplexity is 41.067908177150066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317305595930232 and perplexity of 74.98631242869352
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
2914.831120967865


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}, 'best_accuracy': -74.98631242869352}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.17814085302781324, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.8667473068914826}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6490967273712158 and batch: 50, loss is 7.714379911422729 and perplexity is 2240.333261913464
At time: 2.8561995029449463 and batch: 100, loss is 6.962964181900024 and perplexity is 1056.7613521483147
At time: 4.038319110870361 and batch: 150, loss is 6.696934423446655 and perplexity is 809.9191464175784
At time: 5.223118782043457 and batch: 200, loss is 6.605364818572998 and perplexity is 739.0494389983814
At time: 6.404433250427246 and batch: 250, loss is 6.547961549758911 and perplexity is 697.8202511520055
At time: 7.588024377822876 and batch: 300, loss is 6.477970094680786 and perplexity is 650.648849299178
At time: 8.769619941711426 and batch: 350, loss is 6.43797381401062 and perplexity is 625.1388680965805
At time: 9.956072092056274 and batch: 400, loss is 6.398118772506714 and perplexity is 600.7138947425109
At time: 11.142189502716064 and batch: 450, loss is 6.317573051452637 and perplexity is 554.2262802460542
At time: 12.323705434799194 and batch: 500, loss is 6.3035218620300295 and perplexity is 546.4931985292671
At time: 13.509644746780396 and batch: 550, loss is 6.2456089305877684 and perplexity is 515.7431811268045
At time: 14.695123195648193 and batch: 600, loss is 6.2925676822662355 and perplexity is 540.5394823655395
At time: 15.88603138923645 and batch: 650, loss is 6.3634278678894045 and perplexity is 580.2319096739063
At time: 17.074362754821777 and batch: 700, loss is 6.255581436157226 and perplexity is 520.9121638894486
At time: 18.265687465667725 and batch: 750, loss is 6.18574595451355 and perplexity is 485.7751946872236
At time: 19.453797817230225 and batch: 800, loss is 6.192650928497314 and perplexity is 489.14106702561367
At time: 20.64365530014038 and batch: 850, loss is 6.231362209320069 and perplexity is 508.4476240608631
At time: 21.83321976661682 and batch: 900, loss is 6.20639892578125 and perplexity is 495.9122153011524
At time: 23.02406620979309 and batch: 950, loss is 6.21832015991211 and perplexity is 501.8594798615423
At time: 24.21488118171692 and batch: 1000, loss is 6.202120542526245 and perplexity is 493.79504504562897
At time: 25.40570878982544 and batch: 1050, loss is 6.091205348968506 and perplexity is 441.95379878055775
At time: 26.59639072418213 and batch: 1100, loss is 6.170429782867432 and perplexity is 478.3916664550995
At time: 27.786725282669067 and batch: 1150, loss is 6.077291107177734 and perplexity is 435.8469315048285
At time: 28.978043794631958 and batch: 1200, loss is 6.1607390308380126 and perplexity is 473.7780820988692
At time: 30.1663498878479 and batch: 1250, loss is 6.091791515350342 and perplexity is 442.2129331802445
At time: 31.359936237335205 and batch: 1300, loss is 6.1002592086792 and perplexity is 445.97335526590507
At time: 32.54942846298218 and batch: 1350, loss is 6.090441083908081 and perplexity is 441.616157973798
At time: 33.73553776741028 and batch: 1400, loss is 6.112062215805054 and perplexity is 451.26836902764455
At time: 34.92229413986206 and batch: 1450, loss is 6.096785144805908 and perplexity is 444.42670348302715
At time: 36.10774850845337 and batch: 1500, loss is 6.075239048004151 and perplexity is 434.95346484750945
At time: 37.29327893257141 and batch: 1550, loss is 6.039556188583374 and perplexity is 419.7067229107794
At time: 38.47877240180969 and batch: 1600, loss is 6.041824369430542 and perplexity is 420.6597740987464
At time: 39.669626235961914 and batch: 1650, loss is 6.036004037857055 and perplexity is 418.21850612015965
At time: 40.85717701911926 and batch: 1700, loss is 6.057230758666992 and perplexity is 427.1908029191764
At time: 42.04354190826416 and batch: 1750, loss is 6.059541254043579 and perplexity is 428.1789664282513
At time: 43.22884726524353 and batch: 1800, loss is 6.073764591217041 and perplexity is 434.31261732627826
At time: 44.41400480270386 and batch: 1850, loss is 6.017785558700561 and perplexity is 410.66818748116725
At time: 45.60621404647827 and batch: 1900, loss is 5.990392217636108 and perplexity is 399.57129810716765
At time: 46.79166841506958 and batch: 1950, loss is 5.938754482269287 and perplexity is 379.46200842383894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.42159792877907 and perplexity of 226.2403497833422
finished 1 epochs...
Completing Train Step...
At time: 50.42264199256897 and batch: 50, loss is 5.657862110137939 and perplexity is 286.5354061337645
At time: 51.56893849372864 and batch: 100, loss is 5.544544134140015 and perplexity is 255.837923880734
At time: 52.690375328063965 and batch: 150, loss is 5.415795726776123 and perplexity is 224.93145847062326
At time: 53.80720067024231 and batch: 200, loss is 5.354983987808228 and perplexity is 211.66058717584764
At time: 54.92563843727112 and batch: 250, loss is 5.353385610580444 and perplexity is 211.3225439455568
At time: 56.0466194152832 and batch: 300, loss is 5.333208227157593 and perplexity is 207.10133761269856
At time: 57.16717767715454 and batch: 350, loss is 5.298524408340454 and perplexity is 200.04141264540976
At time: 58.28585600852966 and batch: 400, loss is 5.2381396484375 and perplexity is 188.31943596842103
At time: 59.40639400482178 and batch: 450, loss is 5.177344884872436 and perplexity is 177.21166841965723
At time: 60.551767110824585 and batch: 500, loss is 5.15623215675354 and perplexity is 173.50946596132627
At time: 61.67052745819092 and batch: 550, loss is 5.110402555465698 and perplexity is 165.73705980590495
At time: 62.78989028930664 and batch: 600, loss is 5.085602540969848 and perplexity is 161.6773271080407
At time: 63.909473180770874 and batch: 650, loss is 5.1532447719573975 and perplexity is 172.99189989014934
At time: 65.02772450447083 and batch: 700, loss is 5.133759202957154 and perplexity is 169.65368343445778
At time: 66.14817237854004 and batch: 750, loss is 5.061583576202392 and perplexity is 157.840270615023
At time: 67.2685329914093 and batch: 800, loss is 5.058685703277588 and perplexity is 157.38353167369826
At time: 68.38846778869629 and batch: 850, loss is 5.053365602493286 and perplexity is 156.5484587291395
At time: 69.50821352005005 and batch: 900, loss is 5.061821336746216 and perplexity is 157.87780326531657
At time: 70.62704682350159 and batch: 950, loss is 5.099287977218628 and perplexity is 163.90516153301525
At time: 71.74581217765808 and batch: 1000, loss is 5.044505882263183 and perplexity is 155.1676091850948
At time: 72.86516880989075 and batch: 1050, loss is 4.961348037719727 and perplexity is 142.78614733182357
At time: 73.98455715179443 and batch: 1100, loss is 5.027756309509277 and perplexity is 152.59026300521015
At time: 75.10401058197021 and batch: 1150, loss is 4.9387853240966795 and perplexity is 139.6005770752624
At time: 76.22289514541626 and batch: 1200, loss is 5.014761505126953 and perplexity is 150.62021033401024
At time: 77.34435963630676 and batch: 1250, loss is 4.974198703765869 and perplexity is 144.6328849171336
At time: 78.46527171134949 and batch: 1300, loss is 4.986536121368408 and perplexity is 146.42833404626282
At time: 79.58421015739441 and batch: 1350, loss is 4.893449659347534 and perplexity is 133.41301058494983
At time: 80.70456194877625 and batch: 1400, loss is 4.896105709075928 and perplexity is 133.7678331801127
At time: 81.83288264274597 and batch: 1450, loss is 4.840662307739258 and perplexity is 126.55314110465734
At time: 82.95416808128357 and batch: 1500, loss is 4.813249282836914 and perplexity is 123.13105584823357
At time: 84.07394027709961 and batch: 1550, loss is 4.81147611618042 and perplexity is 122.91291742067217
At time: 85.19446325302124 and batch: 1600, loss is 4.864130249023438 and perplexity is 129.558206217981
At time: 86.32266116142273 and batch: 1650, loss is 4.849956493377686 and perplexity is 127.734832414027
At time: 87.44320321083069 and batch: 1700, loss is 4.852072019577026 and perplexity is 128.0053448357361
At time: 88.56587672233582 and batch: 1750, loss is 4.849169111251831 and perplexity is 127.63429587566587
At time: 89.6899242401123 and batch: 1800, loss is 4.804560489654541 and perplexity is 122.06583003463928
At time: 90.8101806640625 and batch: 1850, loss is 4.814381942749024 and perplexity is 123.27060047251088
At time: 91.93649530410767 and batch: 1900, loss is 4.910788660049438 and perplexity is 135.7464299896483
At time: 93.07357215881348 and batch: 1950, loss is 4.823030805587768 and perplexity is 124.34137480346976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6288889330486915 and perplexity of 102.40022737364473
finished 2 epochs...
Completing Train Step...
At time: 96.75252985954285 and batch: 50, loss is 4.788882827758789 and perplexity is 120.16704635811087
At time: 97.89271664619446 and batch: 100, loss is 4.723360633850097 and perplexity is 112.54584321104028
At time: 99.01735091209412 and batch: 150, loss is 4.656544580459594 and perplexity is 105.27169509185823
At time: 100.1391453742981 and batch: 200, loss is 4.645293703079224 and perplexity is 104.09393400515128
At time: 101.25982928276062 and batch: 250, loss is 4.648865118026733 and perplexity is 104.4663612873243
At time: 102.40124869346619 and batch: 300, loss is 4.6648188495635985 and perplexity is 106.14635502171355
At time: 103.53534936904907 and batch: 350, loss is 4.673658838272095 and perplexity is 107.08884727437771
At time: 104.66982007026672 and batch: 400, loss is 4.622033414840698 and perplexity is 101.70062157055432
At time: 105.80276679992676 and batch: 450, loss is 4.617724494934082 and perplexity is 101.26334451023781
At time: 106.94420647621155 and batch: 500, loss is 4.615550022125245 and perplexity is 101.04338935099324
At time: 108.07804870605469 and batch: 550, loss is 4.592268123626709 and perplexity is 98.718081244369
At time: 109.21242213249207 and batch: 600, loss is 4.552359018325806 and perplexity is 94.85591142066633
At time: 110.34525728225708 and batch: 650, loss is 4.615611600875854 and perplexity is 101.04961166824614
At time: 111.47855162620544 and batch: 700, loss is 4.647678489685059 and perplexity is 104.34247206203938
At time: 112.61555051803589 and batch: 750, loss is 4.5929726886749265 and perplexity is 98.78765906221193
At time: 113.75478792190552 and batch: 800, loss is 4.590677261352539 and perplexity is 98.56115922689314
At time: 114.88778781890869 and batch: 850, loss is 4.587249612808227 and perplexity is 98.22390453840845
At time: 116.04353952407837 and batch: 900, loss is 4.568619728088379 and perplexity is 96.41094457312677
At time: 117.17679023742676 and batch: 950, loss is 4.625547428131103 and perplexity is 102.05862755689603
At time: 118.3105001449585 and batch: 1000, loss is 4.598488035202027 and perplexity is 99.33401251388528
At time: 119.45126724243164 and batch: 1050, loss is 4.5320484066009525 and perplexity is 92.94876306992407
At time: 120.59346747398376 and batch: 1100, loss is 4.583928871154785 and perplexity is 97.89826930173157
At time: 121.73501014709473 and batch: 1150, loss is 4.530700883865356 and perplexity is 92.82359684954557
At time: 122.87641620635986 and batch: 1200, loss is 4.600581254959106 and perplexity is 99.5421582027631
At time: 124.01860570907593 and batch: 1250, loss is 4.579900407791138 and perplexity is 97.50468301672656
At time: 125.16127848625183 and batch: 1300, loss is 4.577728366851806 and perplexity is 97.29312868893999
At time: 126.30450415611267 and batch: 1350, loss is 4.465974798202515 and perplexity is 87.00580131408236
At time: 127.44808149337769 and batch: 1400, loss is 4.471883745193481 and perplexity is 87.5214359103929
At time: 128.58897256851196 and batch: 1450, loss is 4.425792512893676 and perplexity is 83.579018431705
At time: 129.7302348613739 and batch: 1500, loss is 4.409530200958252 and perplexity is 82.23082246655422
At time: 130.87793493270874 and batch: 1550, loss is 4.425248613357544 and perplexity is 83.53357220256143
At time: 132.0223786830902 and batch: 1600, loss is 4.495203590393066 and perplexity is 89.58640606025895
At time: 133.16539645195007 and batch: 1650, loss is 4.467148599624633 and perplexity is 87.10798880957825
At time: 134.30882263183594 and batch: 1700, loss is 4.468309602737427 and perplexity is 87.20918018612035
At time: 135.45106863975525 and batch: 1750, loss is 4.466650085449219 and perplexity is 87.06457506444758
At time: 136.59859251976013 and batch: 1800, loss is 4.428699398040772 and perplexity is 83.82232650197172
At time: 137.74436235427856 and batch: 1850, loss is 4.4668623733520505 and perplexity is 87.08305978247054
At time: 138.88609170913696 and batch: 1900, loss is 4.568943872451782 and perplexity is 96.44220070285597
At time: 140.02777886390686 and batch: 1950, loss is 4.488445472717285 and perplexity is 88.98301178722909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488341717387355 and perplexity of 88.97377980442491
finished 3 epochs...
Completing Train Step...
At time: 143.703768491745 and batch: 50, loss is 4.462115669250489 and perplexity is 86.67068175793544
At time: 144.8720099925995 and batch: 100, loss is 4.409016828536988 and perplexity is 82.18861826428568
At time: 145.9930603504181 and batch: 150, loss is 4.356329011917114 and perplexity is 77.9703800731457
At time: 147.11482071876526 and batch: 200, loss is 4.355141687393188 and perplexity is 77.87785886596342
At time: 148.23587918281555 and batch: 250, loss is 4.345817184448242 and perplexity is 77.1550616410887
At time: 149.3574731349945 and batch: 300, loss is 4.3704956436157225 and perplexity is 79.08281888161592
At time: 150.4894504547119 and batch: 350, loss is 4.387267370223999 and perplexity is 80.42035937806968
At time: 151.62620496749878 and batch: 400, loss is 4.335234231948853 and perplexity is 76.34283872756745
At time: 152.76373863220215 and batch: 450, loss is 4.351002025604248 and perplexity is 77.55613723821583
At time: 153.9083571434021 and batch: 500, loss is 4.35400351524353 and perplexity is 77.7892708796799
At time: 155.04591822624207 and batch: 550, loss is 4.325889673233032 and perplexity is 75.63277138847825
At time: 156.18301367759705 and batch: 600, loss is 4.295363640785217 and perplexity is 73.35888587818307
At time: 157.32640027999878 and batch: 650, loss is 4.357072162628174 and perplexity is 78.02834535234015
At time: 158.46280670166016 and batch: 700, loss is 4.392969799041748 and perplexity is 80.880260784193
At time: 159.60726404190063 and batch: 750, loss is 4.338786172866821 and perplexity is 76.61448613240566
At time: 160.7571723461151 and batch: 800, loss is 4.340560436248779 and perplexity is 76.75054107263526
At time: 161.9054458141327 and batch: 850, loss is 4.339823551177979 and perplexity is 76.69400557738241
At time: 163.05216789245605 and batch: 900, loss is 4.312391843795776 and perplexity is 74.61875206576154
At time: 164.19834852218628 and batch: 950, loss is 4.3835202503204345 and perplexity is 80.11957853167665
At time: 165.3444366455078 and batch: 1000, loss is 4.3560028171539305 and perplexity is 77.9449506911735
At time: 166.489892244339 and batch: 1050, loss is 4.303922681808472 and perplexity is 73.98946230707995
At time: 167.63456416130066 and batch: 1100, loss is 4.342950277328491 and perplexity is 76.93418201751474
At time: 168.7804079055786 and batch: 1150, loss is 4.30225971698761 and perplexity is 73.86652268461438
At time: 169.92648315429688 and batch: 1200, loss is 4.3675164175033565 and perplexity is 78.84756389546929
At time: 171.07278156280518 and batch: 1250, loss is 4.358411664962769 and perplexity is 78.13293453619377
At time: 172.21864533424377 and batch: 1300, loss is 4.343681383132934 and perplexity is 76.99044961082356
At time: 173.365394115448 and batch: 1350, loss is 4.230732812881469 and perplexity is 68.76760750235285
At time: 174.51216340065002 and batch: 1400, loss is 4.250755743980408 and perplexity is 70.15841411542405
At time: 175.6624653339386 and batch: 1450, loss is 4.199534077644348 and perplexity is 66.65526762560852
At time: 176.8121099472046 and batch: 1500, loss is 4.1883909797668455 and perplexity is 65.9166443728095
At time: 177.9580159187317 and batch: 1550, loss is 4.208495326042176 and perplexity is 67.25526638962164
At time: 179.10346508026123 and batch: 1600, loss is 4.285982236862183 and perplexity is 72.67389465197913
At time: 180.25530362129211 and batch: 1650, loss is 4.2501477527618405 and perplexity is 70.11577138025112
At time: 181.4092104434967 and batch: 1700, loss is 4.253433928489685 and perplexity is 70.34656312973031
At time: 182.5554645061493 and batch: 1750, loss is 4.254111814498901 and perplexity is 70.39426624748369
At time: 183.69892477989197 and batch: 1800, loss is 4.212237162590027 and perplexity is 67.50739602319331
At time: 184.84380555152893 and batch: 1850, loss is 4.260996999740601 and perplexity is 70.88061619397322
At time: 185.98906469345093 and batch: 1900, loss is 4.360087156295776 and perplexity is 78.26395532227647
At time: 187.14187622070312 and batch: 1950, loss is 4.2815569877624515 and perplexity is 72.35300509686421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.445634424963663 and perplexity of 85.25394791661404
finished 4 epochs...
Completing Train Step...
At time: 190.83549904823303 and batch: 50, loss is 4.260435557365417 and perplexity is 70.84083198177913
At time: 191.95657634735107 and batch: 100, loss is 4.212950053215027 and perplexity is 67.55553857108308
At time: 193.0815727710724 and batch: 150, loss is 4.1720625686645505 and perplexity is 64.84906992162068
At time: 194.2125210762024 and batch: 200, loss is 4.16852231502533 and perplexity is 64.619893676212
At time: 195.34832453727722 and batch: 250, loss is 4.1568519449234005 and perplexity is 63.87013906748968
At time: 196.49070930480957 and batch: 300, loss is 4.18227285861969 and perplexity is 65.51458952119013
At time: 197.63172960281372 and batch: 350, loss is 4.199803576469422 and perplexity is 66.67323356270934
At time: 198.77755641937256 and batch: 400, loss is 4.148449325561524 and perplexity is 63.33571104234444
At time: 199.92267394065857 and batch: 450, loss is 4.176275744438171 and perplexity is 65.12286682418414
At time: 201.0677845478058 and batch: 500, loss is 4.180544962882996 and perplexity is 65.40148488591439
At time: 202.23617243766785 and batch: 550, loss is 4.149448800086975 and perplexity is 63.399045117207514
At time: 203.38074707984924 and batch: 600, loss is 4.127934861183166 and perplexity is 62.04964938948529
At time: 204.52595567703247 and batch: 650, loss is 4.183177103996277 and perplexity is 65.57385757825853
At time: 205.67188215255737 and batch: 700, loss is 4.22684317111969 and perplexity is 68.50064567387145
At time: 206.8282561302185 and batch: 750, loss is 4.170539212226868 and perplexity is 64.75035688014104
At time: 207.97456097602844 and batch: 800, loss is 4.17077871799469 and perplexity is 64.76586682136842
At time: 209.119295835495 and batch: 850, loss is 4.173611207008362 and perplexity is 64.94957548115673
At time: 210.26485991477966 and batch: 900, loss is 4.142530846595764 and perplexity is 62.96196705768508
At time: 211.41086554527283 and batch: 950, loss is 4.220192933082581 and perplexity is 68.0466114655549
At time: 212.56029629707336 and batch: 1000, loss is 4.193835201263428 and perplexity is 66.27648783002981
At time: 213.72072052955627 and batch: 1050, loss is 4.146957364082336 and perplexity is 63.24128705720184
At time: 214.87687802314758 and batch: 1100, loss is 4.179833250045776 and perplexity is 65.35495436969485
At time: 216.02970337867737 and batch: 1150, loss is 4.143512983322143 and perplexity is 63.0238346941634
At time: 217.18150758743286 and batch: 1200, loss is 4.20735924243927 and perplexity is 67.17890217054942
At time: 218.3422691822052 and batch: 1250, loss is 4.204038920402527 and perplexity is 66.95621647995512
At time: 219.49530410766602 and batch: 1300, loss is 4.186890616416931 and perplexity is 65.81781961050751
At time: 220.6531698703766 and batch: 1350, loss is 4.074293212890625 and perplexity is 58.80890052314501
At time: 221.81100487709045 and batch: 1400, loss is 4.100253138542175 and perplexity is 60.35556398323826
At time: 222.9639129638672 and batch: 1450, loss is 4.0447159767150875 and perplexity is 57.09496743082177
At time: 224.1178843975067 and batch: 1500, loss is 4.0390946435928345 and perplexity is 56.77491799431806
At time: 225.2712264060974 and batch: 1550, loss is 4.057266268730164 and perplexity is 57.81604132397092
At time: 226.42375540733337 and batch: 1600, loss is 4.13891104221344 and perplexity is 62.734469050959305
At time: 227.57735204696655 and batch: 1650, loss is 4.099000043869019 and perplexity is 60.279980114277734
At time: 228.73116540908813 and batch: 1700, loss is 4.104272589683533 and perplexity is 60.59864842953317
At time: 229.88515090942383 and batch: 1750, loss is 4.104459757804871 and perplexity is 60.60999162622463
At time: 231.0397334098816 and batch: 1800, loss is 4.062651362419128 and perplexity is 58.12822594050383
At time: 232.19267320632935 and batch: 1850, loss is 4.113598742485046 and perplexity is 61.16644424418456
At time: 233.34925413131714 and batch: 1900, loss is 4.209404430389404 and perplexity is 67.31643624534843
At time: 234.50168871879578 and batch: 1950, loss is 4.134308915138245 and perplexity is 62.4464203790833
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.432463606013808 and perplexity of 84.13844576777466
finished 5 epochs...
Completing Train Step...
At time: 238.1827507019043 and batch: 50, loss is 4.11505576133728 and perplexity is 61.255629863358976
At time: 239.31592845916748 and batch: 100, loss is 4.071773300170898 and perplexity is 58.66089378703179
At time: 240.438702583313 and batch: 150, loss is 4.037935838699341 and perplexity is 56.70916504629543
At time: 241.56052112579346 and batch: 200, loss is 4.0320322751998905 and perplexity is 56.37536516331373
At time: 242.68147373199463 and batch: 250, loss is 4.022846827507019 and perplexity is 55.85990319414462
At time: 243.80560612678528 and batch: 300, loss is 4.044927935600281 and perplexity is 57.10707049909969
At time: 244.94035148620605 and batch: 350, loss is 4.060248279571534 and perplexity is 57.988706703069674
At time: 246.07809591293335 and batch: 400, loss is 4.007443518638611 and perplexity is 55.00606867212016
At time: 247.22117400169373 and batch: 450, loss is 4.047650637626648 and perplexity is 57.2627678982962
At time: 248.36738204956055 and batch: 500, loss is 4.055037426948547 and perplexity is 57.68732201619298
At time: 249.51452136039734 and batch: 550, loss is 4.021828451156616 and perplexity is 55.80304574585013
At time: 250.66013097763062 and batch: 600, loss is 4.003035383224487 and perplexity is 54.76412811795274
At time: 251.80444049835205 and batch: 650, loss is 4.058646149635315 and perplexity is 57.89587564366446
At time: 252.9501495361328 and batch: 700, loss is 4.102596254348755 and perplexity is 60.497149870509816
At time: 254.09547686576843 and batch: 750, loss is 4.043907432556153 and perplexity is 57.04882228610853
At time: 255.24143195152283 and batch: 800, loss is 4.045380601882934 and perplexity is 57.13292679611115
At time: 256.3941259384155 and batch: 850, loss is 4.047187728881836 and perplexity is 57.23626659659929
At time: 257.53887963294983 and batch: 900, loss is 4.015092310905456 and perplexity is 55.42841181322245
At time: 258.7092254161835 and batch: 950, loss is 4.096715712547303 and perplexity is 60.14243782352158
At time: 259.8545923233032 and batch: 1000, loss is 4.071598439216614 and perplexity is 58.65063718393086
At time: 261.00055718421936 and batch: 1050, loss is 4.0254736328125 and perplexity is 56.00682917270493
At time: 262.1462941169739 and batch: 1100, loss is 4.054912109375 and perplexity is 57.68009323392964
At time: 263.2966649532318 and batch: 1150, loss is 4.023025908470154 and perplexity is 55.86990753517603
At time: 264.4460988044739 and batch: 1200, loss is 4.08615620136261 and perplexity is 59.51070434702331
At time: 265.5924334526062 and batch: 1250, loss is 4.084241433143616 and perplexity is 59.39686416521212
At time: 266.74625182151794 and batch: 1300, loss is 4.06665533542633 and perplexity is 58.36143636067467
At time: 267.89273953437805 and batch: 1350, loss is 3.9560314559936525 and perplexity is 52.24955928087996
At time: 269.0361053943634 and batch: 1400, loss is 3.98751829624176 and perplexity is 53.92090746170135
At time: 270.186781167984 and batch: 1450, loss is 3.928980369567871 and perplexity is 50.85509781919387
At time: 271.3406181335449 and batch: 1500, loss is 3.9247669887542727 and perplexity is 50.641276696998624
At time: 272.49486231803894 and batch: 1550, loss is 3.9441542720794676 and perplexity is 51.632652465824016
At time: 273.6511867046356 and batch: 1600, loss is 4.026950798034668 and perplexity is 56.08962164699004
At time: 274.80490159988403 and batch: 1650, loss is 3.985041446685791 and perplexity is 53.78751874608047
At time: 275.9617621898651 and batch: 1700, loss is 3.989465413093567 and perplexity is 54.026000049856634
At time: 277.1159086227417 and batch: 1750, loss is 3.9912205600738524 and perplexity is 54.12090688405907
At time: 278.27141880989075 and batch: 1800, loss is 3.9518636512756347 and perplexity is 52.032246494394116
At time: 279.4261984825134 and batch: 1850, loss is 3.999022641181946 and perplexity is 54.544814118168986
At time: 280.58549904823303 and batch: 1900, loss is 4.089922027587891 and perplexity is 59.73523382228539
At time: 281.7459852695465 and batch: 1950, loss is 4.018348155021667 and perplexity is 55.60917218581375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.434643270803052 and perplexity of 84.32203938902545
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 285.42928433418274 and batch: 50, loss is 4.045602021217346 and perplexity is 57.14557853135303
At time: 286.549124956131 and batch: 100, loss is 4.032149057388306 and perplexity is 56.38194918627106
At time: 287.69275403022766 and batch: 150, loss is 4.006899843215942 and perplexity is 54.9761713524409
At time: 288.8127133846283 and batch: 200, loss is 4.005407357215882 and perplexity is 54.89418138601846
At time: 289.94198775291443 and batch: 250, loss is 3.99064462184906 and perplexity is 54.089745559384475
At time: 291.08281445503235 and batch: 300, loss is 4.007060899734497 and perplexity is 54.98502633625968
At time: 292.22616744041443 and batch: 350, loss is 4.013509631156921 and perplexity is 55.34075577236985
At time: 293.37591528892517 and batch: 400, loss is 3.9653396940231325 and perplexity is 52.73818119215079
At time: 294.5199394226074 and batch: 450, loss is 3.9954706239700317 and perplexity is 54.35141368377806
At time: 295.66415524482727 and batch: 500, loss is 3.9988688707351683 and perplexity is 54.5364273825652
At time: 296.80738067626953 and batch: 550, loss is 3.966080026626587 and perplexity is 52.77723944339869
At time: 297.95117950439453 and batch: 600, loss is 3.93060546875 and perplexity is 50.93780958627633
At time: 299.093861579895 and batch: 650, loss is 3.9743250608444214 and perplexity is 53.214188442923884
At time: 300.23605370521545 and batch: 700, loss is 4.013607711791992 and perplexity is 55.3461838950338
At time: 301.3792881965637 and batch: 750, loss is 3.9477278661727904 and perplexity is 51.81749669009862
At time: 302.5213668346405 and batch: 800, loss is 3.94347532749176 and perplexity is 51.59760865363285
At time: 303.6630139350891 and batch: 850, loss is 3.947377882003784 and perplexity is 51.79936455974393
At time: 304.80553364753723 and batch: 900, loss is 3.9022360849380493 and perplexity is 49.51304077798376
At time: 305.95021080970764 and batch: 950, loss is 3.982651586532593 and perplexity is 53.6591275778664
At time: 307.10406470298767 and batch: 1000, loss is 3.94945818901062 and perplexity is 51.9072353040173
At time: 308.25814175605774 and batch: 1050, loss is 3.8998166370391845 and perplexity is 49.39339135664385
At time: 309.40889978408813 and batch: 1100, loss is 3.919921793937683 and perplexity is 50.39650331186566
At time: 310.5602014064789 and batch: 1150, loss is 3.8833748292922974 and perplexity is 48.58791460444326
At time: 311.7168891429901 and batch: 1200, loss is 3.931033186912537 and perplexity is 50.95960127261402
At time: 312.8673646450043 and batch: 1250, loss is 3.9257846546173094 and perplexity is 50.69283882761383
At time: 314.01959705352783 and batch: 1300, loss is 3.914998197555542 and perplexity is 50.14898112020226
At time: 315.16980385780334 and batch: 1350, loss is 3.798506064414978 and perplexity is 44.63445366128699
At time: 316.32063269615173 and batch: 1400, loss is 3.810475492477417 and perplexity is 45.17191266526206
At time: 317.47083806991577 and batch: 1450, loss is 3.7451185178756714 and perplexity is 42.31402188965335
At time: 318.62842202186584 and batch: 1500, loss is 3.740668363571167 and perplexity is 42.12613633293142
At time: 319.7795481681824 and batch: 1550, loss is 3.757895255088806 and perplexity is 42.85812556074862
At time: 320.9313704967499 and batch: 1600, loss is 3.8286365699768066 and perplexity is 45.99977798097052
At time: 322.09023571014404 and batch: 1650, loss is 3.7824779462814333 and perplexity is 43.92475016445887
At time: 323.24165964126587 and batch: 1700, loss is 3.7706557178497313 and perplexity is 43.4085192467
At time: 324.39141511917114 and batch: 1750, loss is 3.758553590774536 and perplexity is 42.886349883748885
At time: 325.5436689853668 and batch: 1800, loss is 3.7167656993865967 and perplexity is 41.13114824817141
At time: 326.6940712928772 and batch: 1850, loss is 3.752236833572388 and perplexity is 42.61630103868417
At time: 327.84959745407104 and batch: 1900, loss is 3.830420274734497 and perplexity is 46.08190122384377
At time: 329.00354623794556 and batch: 1950, loss is 3.7590008687973024 and perplexity is 42.90553629603897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361736634720203 and perplexity of 78.39315655602061
finished 7 epochs...
Completing Train Step...
At time: 332.6591739654541 and batch: 50, loss is 3.9617572164535524 and perplexity is 52.54958586194451
At time: 333.8180527687073 and batch: 100, loss is 3.9323845386505125 and perplexity is 51.02851216930351
At time: 334.94091272354126 and batch: 150, loss is 3.89764732837677 and perplexity is 49.286357981096245
At time: 336.06409549713135 and batch: 200, loss is 3.8950413417816163 and perplexity is 49.15808560351507
At time: 337.19782972335815 and batch: 250, loss is 3.8754313659667967 and perplexity is 48.20348715081096
At time: 338.3361032009125 and batch: 300, loss is 3.8925399732589723 and perplexity is 49.03527677465537
At time: 339.47336888313293 and batch: 350, loss is 3.9029311418533323 and perplexity is 49.54746712212151
At time: 340.6156380176544 and batch: 400, loss is 3.857426242828369 and perplexity is 47.343344156183534
At time: 341.7650055885315 and batch: 450, loss is 3.8954863119125367 and perplexity is 49.179964350635345
At time: 342.9184341430664 and batch: 500, loss is 3.9016144561767576 and perplexity is 49.48227161226717
At time: 344.0647873878479 and batch: 550, loss is 3.870477347373962 and perplexity is 47.96527671587402
At time: 345.238303899765 and batch: 600, loss is 3.8407029724121093 and perplexity is 46.55819206322667
At time: 346.3853795528412 and batch: 650, loss is 3.8851956796646117 and perplexity is 48.67646652227088
At time: 347.53909516334534 and batch: 700, loss is 3.9258417177200315 and perplexity is 50.69573160081765
At time: 348.6862573623657 and batch: 750, loss is 3.861100363731384 and perplexity is 47.51760926607178
At time: 349.83129811286926 and batch: 800, loss is 3.8599999380111694 and perplexity is 47.46534842653199
At time: 350.98330760002136 and batch: 850, loss is 3.866498951911926 and perplexity is 47.77483096210558
At time: 352.130065202713 and batch: 900, loss is 3.823088164329529 and perplexity is 45.74525929245376
At time: 353.2735438346863 and batch: 950, loss is 3.906137809753418 and perplexity is 49.706604408322605
At time: 354.41955161094666 and batch: 1000, loss is 3.875385618209839 and perplexity is 48.201281999837
At time: 355.56553077697754 and batch: 1050, loss is 3.8310232067108156 and perplexity is 46.10969385331174
At time: 356.71911787986755 and batch: 1100, loss is 3.8506382417678835 and perplexity is 47.02306574074324
At time: 357.8730881214142 and batch: 1150, loss is 3.816525926589966 and perplexity is 45.446050837758236
At time: 359.0367269515991 and batch: 1200, loss is 3.869575023651123 and perplexity is 47.92201602932781
At time: 360.1946964263916 and batch: 1250, loss is 3.8670101594924926 and perplexity is 47.79926006149208
At time: 361.34847807884216 and batch: 1300, loss is 3.858638324737549 and perplexity is 47.400762958271244
At time: 362.50140857696533 and batch: 1350, loss is 3.743579125404358 and perplexity is 42.24893411359501
At time: 363.6548161506653 and batch: 1400, loss is 3.7598305416107176 and perplexity is 42.94114862429625
At time: 364.80774879455566 and batch: 1450, loss is 3.6973441553115847 and perplexity is 40.34002512317566
At time: 365.95996284484863 and batch: 1500, loss is 3.6955027294158938 and perplexity is 40.2658103077934
At time: 367.1133213043213 and batch: 1550, loss is 3.714604501724243 and perplexity is 41.04235169474178
At time: 368.2658488750458 and batch: 1600, loss is 3.790449647903442 and perplexity is 44.27630454820314
At time: 369.420508146286 and batch: 1650, loss is 3.746189889907837 and perplexity is 42.359380242771174
At time: 370.58154010772705 and batch: 1700, loss is 3.738257842063904 and perplexity is 42.024712666358944
At time: 371.7349307537079 and batch: 1750, loss is 3.7302831649780273 and perplexity is 41.69091189890005
At time: 372.8891577720642 and batch: 1800, loss is 3.6926141595840454 and perplexity is 40.149667526906256
At time: 374.04239225387573 and batch: 1850, loss is 3.7318339204788207 and perplexity is 41.75561446582452
At time: 375.195778131485 and batch: 1900, loss is 3.8142823696136476 and perplexity is 45.3442043253026
At time: 376.3497393131256 and batch: 1950, loss is 3.745291385650635 and perplexity is 42.32133725274422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364973485192587 and perplexity of 78.64731459573075
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 380.0098431110382 and batch: 50, loss is 3.935657567977905 and perplexity is 51.19580361171996
At time: 381.1532530784607 and batch: 100, loss is 3.9390954971313477 and perplexity is 51.37211405524123
At time: 382.27286100387573 and batch: 150, loss is 3.9115641021728518 and perplexity is 49.977060101234976
At time: 383.3933153152466 and batch: 200, loss is 3.923738660812378 and perplexity is 50.589227623502836
At time: 384.52798986434937 and batch: 250, loss is 3.9123570251464845 and perplexity is 50.01670377545681
At time: 385.66447377204895 and batch: 300, loss is 3.921206679344177 and perplexity is 50.46129866189485
At time: 386.80200958251953 and batch: 350, loss is 3.93741979598999 and perplexity is 51.28610183060308
At time: 387.93804121017456 and batch: 400, loss is 3.888493757247925 and perplexity is 48.837270311269336
At time: 389.08449697494507 and batch: 450, loss is 3.9289775037765504 and perplexity is 50.85495207930476
At time: 390.2298183441162 and batch: 500, loss is 3.9328235149383546 and perplexity is 51.05091739347097
At time: 391.38278365135193 and batch: 550, loss is 3.9041969108581545 and perplexity is 49.61022247878608
At time: 392.53739070892334 and batch: 600, loss is 3.8606530380249025 and perplexity is 47.496358171371355
At time: 393.6903018951416 and batch: 650, loss is 3.893780817985535 and perplexity is 49.096159704576245
At time: 394.85192942619324 and batch: 700, loss is 3.93724826335907 and perplexity is 51.277305345090156
At time: 396.00435090065 and batch: 750, loss is 3.8651409006118773 and perplexity is 47.70999432651138
At time: 397.15861439704895 and batch: 800, loss is 3.860299906730652 and perplexity is 47.47958868202811
At time: 398.3101804256439 and batch: 850, loss is 3.8618652629852295 and perplexity is 47.55396935407324
At time: 399.4635736942291 and batch: 900, loss is 3.8178313684463503 and perplexity is 45.50541675567542
At time: 400.61505031585693 and batch: 950, loss is 3.9008920335769655 and perplexity is 49.446537410117145
At time: 401.7666108608246 and batch: 1000, loss is 3.8678778219223022 and perplexity is 47.84075168137696
At time: 402.9439105987549 and batch: 1050, loss is 3.8231149244308473 and perplexity is 45.74648345660657
At time: 404.1049659252167 and batch: 1100, loss is 3.8419497632980346 and perplexity is 46.61627659486429
At time: 405.2604236602783 and batch: 1150, loss is 3.8114554357528685 and perplexity is 45.216200273445516
At time: 406.423211812973 and batch: 1200, loss is 3.852892527580261 and perplexity is 47.129188741543274
At time: 407.58315086364746 and batch: 1250, loss is 3.842103137969971 and perplexity is 46.62342689931769
At time: 408.7372508049011 and batch: 1300, loss is 3.831721262931824 and perplexity is 46.14189224879249
At time: 409.8952407836914 and batch: 1350, loss is 3.7099415063858032 and perplexity is 40.85141691008215
At time: 411.0534625053406 and batch: 1400, loss is 3.724458165168762 and perplexity is 41.448768273001484
At time: 412.2118401527405 and batch: 1450, loss is 3.6606950616836547 and perplexity is 38.888363291079095
At time: 413.3660809993744 and batch: 1500, loss is 3.65804069519043 and perplexity is 38.78527619857141
At time: 414.52024602890015 and batch: 1550, loss is 3.678513765335083 and perplexity is 39.587513993008955
At time: 415.6717791557312 and batch: 1600, loss is 3.747799711227417 and perplexity is 42.42762619332485
At time: 416.8264582157135 and batch: 1650, loss is 3.706141276359558 and perplexity is 40.696466738552246
At time: 417.97864603996277 and batch: 1700, loss is 3.688733606338501 and perplexity is 39.99416651439337
At time: 419.13187623023987 and batch: 1750, loss is 3.674928512573242 and perplexity is 39.44583687503058
At time: 420.28444719314575 and batch: 1800, loss is 3.6331961584091186 and perplexity is 37.83354558482205
At time: 421.43871879577637 and batch: 1850, loss is 3.666646008491516 and perplexity is 39.12047583216391
At time: 422.5924744606018 and batch: 1900, loss is 3.757471385002136 and perplexity is 42.83996313287954
At time: 423.746906042099 and batch: 1950, loss is 3.6923944664001467 and perplexity is 40.1408478874576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338456690588663 and perplexity of 76.58924717509771
finished 9 epochs...
Completing Train Step...
At time: 427.38764119148254 and batch: 50, loss is 3.926474566459656 and perplexity is 50.727824484564984
At time: 428.534277677536 and batch: 100, loss is 3.910379309654236 and perplexity is 49.91788271770769
At time: 429.6539101600647 and batch: 150, loss is 3.872189702987671 and perplexity is 48.0474806878517
At time: 430.7960114479065 and batch: 200, loss is 3.8777354669570925 and perplexity is 48.31468090491746
At time: 431.912415266037 and batch: 250, loss is 3.8634132528305054 and perplexity is 47.627639421282744
At time: 433.04037046432495 and batch: 300, loss is 3.868688979148865 and perplexity is 47.87957379611828
At time: 434.1801290512085 and batch: 350, loss is 3.884522032737732 and perplexity is 48.643686812401825
At time: 435.32269954681396 and batch: 400, loss is 3.837630844116211 and perplexity is 46.41537880662896
At time: 436.4652132987976 and batch: 450, loss is 3.879942536354065 and perplexity is 48.421432519344194
At time: 437.60783195495605 and batch: 500, loss is 3.8838680362701417 and perplexity is 48.61188441351773
At time: 438.7511203289032 and batch: 550, loss is 3.8562634992599487 and perplexity is 47.28832797831027
At time: 439.89408111572266 and batch: 600, loss is 3.818546838760376 and perplexity is 45.53798618033035
At time: 441.03582406044006 and batch: 650, loss is 3.8548757219314576 and perplexity is 47.222747824690124
At time: 442.1791944503784 and batch: 700, loss is 3.900932788848877 and perplexity is 49.44855265826009
At time: 443.32335782051086 and batch: 750, loss is 3.8289853143692016 and perplexity is 46.01582294322549
At time: 444.4737160205841 and batch: 800, loss is 3.8253454399108886 and perplexity is 45.84863557970767
At time: 445.62561535835266 and batch: 850, loss is 3.8288376760482787 and perplexity is 46.009029745870734
At time: 446.7769193649292 and batch: 900, loss is 3.7852872514724734 and perplexity is 44.048321686899875
At time: 447.92960476875305 and batch: 950, loss is 3.8698299312591553 and perplexity is 47.93423327287394
At time: 449.0796775817871 and batch: 1000, loss is 3.837857322692871 and perplexity is 46.42589208602756
At time: 450.23062324523926 and batch: 1050, loss is 3.7959527730941773 and perplexity is 44.52063426701591
At time: 451.380539894104 and batch: 1100, loss is 3.8151066875457764 and perplexity is 45.381597775974626
At time: 452.5336821079254 and batch: 1150, loss is 3.786898384094238 and perplexity is 44.11934657479699
At time: 453.68527340888977 and batch: 1200, loss is 3.830774874687195 and perplexity is 46.09824476137555
At time: 454.83787727355957 and batch: 1250, loss is 3.8222899770736696 and perplexity is 45.70876057781277
At time: 455.98765993118286 and batch: 1300, loss is 3.8131425094604494 and perplexity is 45.29254771985985
At time: 457.1426877975464 and batch: 1350, loss is 3.6923415231704713 and perplexity is 40.138722757584645
At time: 458.293612241745 and batch: 1400, loss is 3.7094993591308594 and perplexity is 40.83335856075378
At time: 459.4454519748688 and batch: 1450, loss is 3.648377013206482 and perplexity is 38.412272819539034
At time: 460.5991744995117 and batch: 1500, loss is 3.647236080169678 and perplexity is 38.36847198012425
At time: 461.75672721862793 and batch: 1550, loss is 3.6695086145401 and perplexity is 39.2326227825914
At time: 462.90879344940186 and batch: 1600, loss is 3.74144766330719 and perplexity is 42.15897801495033
At time: 464.06330609321594 and batch: 1650, loss is 3.7011058950424194 and perplexity is 40.4920595761629
At time: 465.2187259197235 and batch: 1700, loss is 3.6864704847335816 and perplexity is 39.90375719431428
At time: 466.3694853782654 and batch: 1750, loss is 3.6742489385604857 and perplexity is 39.41903961577068
At time: 467.52025055885315 and batch: 1800, loss is 3.634526934623718 and perplexity is 37.88392708321483
At time: 468.67154455184937 and batch: 1850, loss is 3.6695741271972655 and perplexity is 39.2351931001507
At time: 469.82170701026917 and batch: 1900, loss is 3.761339702606201 and perplexity is 43.006002656179845
At time: 470.97794127464294 and batch: 1950, loss is 3.6958843660354614 and perplexity is 40.28118014818384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33828494049782 and perplexity of 76.57609409449154
finished 10 epochs...
Completing Train Step...
At time: 474.7297532558441 and batch: 50, loss is 3.9087983083724978 and perplexity is 49.8390248347822
At time: 475.85329699516296 and batch: 100, loss is 3.89009521484375 and perplexity is 48.91554378786673
At time: 476.97676396369934 and batch: 150, loss is 3.8508352565765382 and perplexity is 47.03233089369871
At time: 478.1002037525177 and batch: 200, loss is 3.855529441833496 and perplexity is 47.25362836728498
At time: 479.2267644405365 and batch: 250, loss is 3.840229420661926 and perplexity is 46.53614956943244
At time: 480.36417293548584 and batch: 300, loss is 3.8445462512969972 and perplexity is 46.737472471329205
At time: 481.5021810531616 and batch: 350, loss is 3.8606292724609377 and perplexity is 47.495229407046054
At time: 482.645357131958 and batch: 400, loss is 3.8136759328842165 and perplexity is 45.31671427066481
At time: 483.789434671402 and batch: 450, loss is 3.857179365158081 and perplexity is 47.33165758431078
At time: 484.9349763393402 and batch: 500, loss is 3.860620608329773 and perplexity is 47.49481790393144
At time: 486.0800247192383 and batch: 550, loss is 3.833636260032654 and perplexity is 46.23033849880264
At time: 487.22685194015503 and batch: 600, loss is 3.797684864997864 and perplexity is 44.59781491987268
At time: 488.41683626174927 and batch: 650, loss is 3.8349332094192503 and perplexity is 46.290335806286365
At time: 489.56298089027405 and batch: 700, loss is 3.8817885160446166 and perplexity is 48.51090005258088
At time: 490.71046566963196 and batch: 750, loss is 3.8095434951782225 and perplexity is 45.12983217715522
At time: 491.8571619987488 and batch: 800, loss is 3.806550636291504 and perplexity is 44.994966874944815
At time: 493.00273156166077 and batch: 850, loss is 3.8104950523376466 and perplexity is 45.17279623020128
At time: 494.1496419906616 and batch: 900, loss is 3.7673038148880007 and perplexity is 43.2632616831019
At time: 495.2964115142822 and batch: 950, loss is 3.8523957443237307 and perplexity is 47.105781564310874
At time: 496.4425358772278 and batch: 1000, loss is 3.8207675218582153 and perplexity is 45.63922398348587
At time: 497.58762550354004 and batch: 1050, loss is 3.7802154302597044 and perplexity is 43.82548205365286
At time: 498.7363226413727 and batch: 1100, loss is 3.7994825267791748 and perplexity is 44.67805881136297
At time: 499.8899796009064 and batch: 1150, loss is 3.7720928382873535 and perplexity is 43.47094736449385
At time: 501.04525113105774 and batch: 1200, loss is 3.816978063583374 and perplexity is 45.46660332446593
At time: 502.19950342178345 and batch: 1250, loss is 3.8094277429580687 and perplexity is 45.124608601211634
At time: 503.3552567958832 and batch: 1300, loss is 3.8007297706604004 and perplexity is 44.73381801227323
At time: 504.5077123641968 and batch: 1350, loss is 3.680252332687378 and perplexity is 39.65639941601828
At time: 505.6634006500244 and batch: 1400, loss is 3.698520135879517 and perplexity is 40.38749211348922
At time: 506.8164849281311 and batch: 1450, loss is 3.6385567569732666 and perplexity is 38.03690060029512
At time: 507.9720048904419 and batch: 1500, loss is 3.637657208442688 and perplexity is 38.002699947132236
At time: 509.12664318084717 and batch: 1550, loss is 3.6605849361419676 and perplexity is 38.88408092480962
At time: 510.2804317474365 and batch: 1600, loss is 3.7336376428604128 and perplexity is 41.83099796721017
At time: 511.433819770813 and batch: 1650, loss is 3.6939012813568115 and perplexity is 40.201378310047865
At time: 512.5881612300873 and batch: 1700, loss is 3.6803020429611206 and perplexity is 39.65837079548741
At time: 513.7535653114319 and batch: 1750, loss is 3.6685879325866697 and perplexity is 39.19651863757743
At time: 514.9089875221252 and batch: 1800, loss is 3.6297753477096557 and perplexity is 37.70434529813961
At time: 516.0629663467407 and batch: 1850, loss is 3.6657335329055787 and perplexity is 39.08479563418723
At time: 517.2178592681885 and batch: 1900, loss is 3.758076033592224 and perplexity is 42.86587408890935
At time: 518.3709726333618 and batch: 1950, loss is 3.6923661184310914 and perplexity is 40.139709992072426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339910178960756 and perplexity of 76.7006496968164
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 522.0542867183685 and batch: 50, loss is 3.906059308052063 and perplexity is 49.70270250846286
At time: 523.1760671138763 and batch: 100, loss is 3.9059488344192506 and perplexity is 49.69721197364141
At time: 524.2974565029144 and batch: 150, loss is 3.873737139701843 and perplexity is 48.12188867947273
At time: 525.42990899086 and batch: 200, loss is 3.889585828781128 and perplexity is 48.890633236698044
At time: 526.5784425735474 and batch: 250, loss is 3.884271845817566 and perplexity is 48.631518320474925
At time: 527.7213613986969 and batch: 300, loss is 3.886533737182617 and perplexity is 48.741642028815036
At time: 528.8663146495819 and batch: 350, loss is 3.9039916133880617 and perplexity is 49.6000386710112
At time: 530.010776758194 and batch: 400, loss is 3.8626265859603883 and perplexity is 47.59018706844217
At time: 531.154922246933 and batch: 450, loss is 3.903677248954773 and perplexity is 49.584448633568314
At time: 532.300042629242 and batch: 500, loss is 3.90427143573761 and perplexity is 49.61391981240603
At time: 533.4502651691437 and batch: 550, loss is 3.8795669078826904 and perplexity is 48.40324746629085
At time: 534.5995044708252 and batch: 600, loss is 3.831524620056152 and perplexity is 46.132819666470326
At time: 535.7438535690308 and batch: 650, loss is 3.8596493864059447 and perplexity is 47.448712288531325
At time: 536.8890960216522 and batch: 700, loss is 3.9057694911956786 and perplexity is 49.6882999146261
At time: 538.0348553657532 and batch: 750, loss is 3.8332424783706665 and perplexity is 46.21213742313444
At time: 539.1811079978943 and batch: 800, loss is 3.826324853897095 and perplexity is 45.893562372015936
At time: 540.3323867321014 and batch: 850, loss is 3.826204915046692 and perplexity is 45.88805828098791
At time: 541.4906010627747 and batch: 900, loss is 3.78380735874176 and perplexity is 43.983183106779165
At time: 542.6453261375427 and batch: 950, loss is 3.8747557020187378 and perplexity is 48.170928792865396
At time: 543.8031136989594 and batch: 1000, loss is 3.836528387069702 and perplexity is 46.364236041727935
At time: 544.998960018158 and batch: 1050, loss is 3.7954989099502563 and perplexity is 44.50043257672623
At time: 546.1537318229675 and batch: 1100, loss is 3.8110479068756105 and perplexity is 45.197777120352626
At time: 547.3163893222809 and batch: 1150, loss is 3.786918840408325 and perplexity is 44.12024910323901
At time: 548.4733436107635 and batch: 1200, loss is 3.826326537132263 and perplexity is 45.893639621739126
At time: 549.6275010108948 and batch: 1250, loss is 3.8157873821258543 and perplexity is 45.41249929967268
At time: 550.782173871994 and batch: 1300, loss is 3.8049910640716553 and perplexity is 44.924848665991206
At time: 551.9445223808289 and batch: 1350, loss is 3.676862554550171 and perplexity is 39.52220060088431
At time: 553.1082398891449 and batch: 1400, loss is 3.6936713314056395 and perplexity is 40.19213506785069
At time: 554.2683608531952 and batch: 1450, loss is 3.6295156192779543 and perplexity is 37.694553679302935
At time: 555.422590970993 and batch: 1500, loss is 3.6264747285842898 and perplexity is 37.580102766369826
At time: 556.5809979438782 and batch: 1550, loss is 3.6535872650146484 and perplexity is 38.61293272382934
At time: 557.7386355400085 and batch: 1600, loss is 3.725390748977661 and perplexity is 41.48744075305324
At time: 558.8972084522247 and batch: 1650, loss is 3.688778290748596 and perplexity is 39.99595367006002
At time: 560.0520215034485 and batch: 1700, loss is 3.6697077465057375 and perplexity is 39.24043602979103
At time: 561.2106235027313 and batch: 1750, loss is 3.6556001996994016 and perplexity is 38.69073631589264
At time: 562.3642210960388 and batch: 1800, loss is 3.6140395069122313 and perplexity is 37.11567944612916
At time: 563.519832611084 and batch: 1850, loss is 3.6462706565856933 and perplexity is 38.33144802716752
At time: 564.6766407489777 and batch: 1900, loss is 3.7425747442245485 and perplexity is 42.20652138214436
At time: 565.8358688354492 and batch: 1950, loss is 3.6852526473999023 and perplexity is 39.85519048822545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326069960483285 and perplexity of 75.64640824209938
finished 12 epochs...
Completing Train Step...
At time: 569.5378613471985 and batch: 50, loss is 3.9144698858261107 and perplexity is 50.1224938226485
At time: 570.6660046577454 and batch: 100, loss is 3.900200171470642 and perplexity is 49.41233905623091
At time: 571.7976913452148 and batch: 150, loss is 3.8598452949523927 and perplexity is 47.45800880739062
At time: 572.9212574958801 and batch: 200, loss is 3.867832260131836 and perplexity is 47.8385720207281
At time: 574.0792813301086 and batch: 250, loss is 3.8593483924865724 and perplexity is 47.43443266379835
At time: 575.2202231884003 and batch: 300, loss is 3.8585526371002197 and perplexity is 47.396701472897774
At time: 576.3653743267059 and batch: 350, loss is 3.8751376914978026 and perplexity is 48.1893330957623
At time: 577.515398979187 and batch: 400, loss is 3.834699296951294 and perplexity is 46.279509185885495
At time: 578.6641082763672 and batch: 450, loss is 3.876732783317566 and perplexity is 48.26626084388336
At time: 579.8091468811035 and batch: 500, loss is 3.8789881658554077 and perplexity is 48.37524257730992
At time: 580.9630825519562 and batch: 550, loss is 3.8547221279144286 and perplexity is 47.21549525014687
At time: 582.1107547283173 and batch: 600, loss is 3.80968252658844 and perplexity is 45.13610707755971
At time: 583.2560586929321 and batch: 650, loss is 3.840007348060608 and perplexity is 46.52581631305125
At time: 584.4007518291473 and batch: 700, loss is 3.888146457672119 and perplexity is 48.820312092968194
At time: 585.5463020801544 and batch: 750, loss is 3.8168014669418335 and perplexity is 45.458574783944094
At time: 586.7017662525177 and batch: 800, loss is 3.8100995206832886 and perplexity is 45.154932492446136
At time: 587.8547785282135 and batch: 850, loss is 3.811226897239685 and perplexity is 45.205867810990995
At time: 589.0094830989838 and batch: 900, loss is 3.769376583099365 and perplexity is 43.35302939833225
At time: 590.1631579399109 and batch: 950, loss is 3.8608631467819214 and perplexity is 47.50633862060285
At time: 591.3187565803528 and batch: 1000, loss is 3.8235661458969115 and perplexity is 45.76712990965024
At time: 592.4706542491913 and batch: 1050, loss is 3.7834996128082277 and perplexity is 43.96964954359056
At time: 593.6239640712738 and batch: 1100, loss is 3.8001739168167115 and perplexity is 44.70895945709001
At time: 594.7781467437744 and batch: 1150, loss is 3.777615008354187 and perplexity is 43.71166535994998
At time: 595.9300045967102 and batch: 1200, loss is 3.8175981140136717 and perplexity is 45.49480365333097
At time: 597.0827839374542 and batch: 1250, loss is 3.8085662078857423 and perplexity is 45.08574891017366
At time: 598.2369804382324 and batch: 1300, loss is 3.7991385650634766 and perplexity is 44.66269391222018
At time: 599.3891015052795 and batch: 1350, loss is 3.6716472721099853 and perplexity is 39.316617714475235
At time: 600.543651342392 and batch: 1400, loss is 3.690421781539917 and perplexity is 40.061740696985424
At time: 601.6971924304962 and batch: 1450, loss is 3.62796875 and perplexity is 37.63629020687574
At time: 602.8524792194366 and batch: 1500, loss is 3.6267288970947265 and perplexity is 37.58965565908284
At time: 604.0054988861084 and batch: 1550, loss is 3.6547554683685304 and perplexity is 38.658066839120096
At time: 605.1657485961914 and batch: 1600, loss is 3.7274926567077635 and perplexity is 41.574735235809264
At time: 606.3191432952881 and batch: 1650, loss is 3.691473536491394 and perplexity is 40.103897996816535
At time: 607.4734318256378 and batch: 1700, loss is 3.672934536933899 and perplexity is 39.367261202251285
At time: 608.6268699169159 and batch: 1750, loss is 3.6599420738220214 and perplexity is 38.85909184746605
At time: 609.780787229538 and batch: 1800, loss is 3.619024062156677 and perplexity is 37.30114645202595
At time: 610.93381690979 and batch: 1850, loss is 3.651438512802124 and perplexity is 38.53005217597648
At time: 612.0857157707214 and batch: 1900, loss is 3.7483406972885134 and perplexity is 42.450585157380665
At time: 613.2375836372375 and batch: 1950, loss is 3.6902181911468506 and perplexity is 40.05358534165417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324939532612645 and perplexity of 75.56094374873234
finished 13 epochs...
Completing Train Step...
At time: 616.8945858478546 and batch: 50, loss is 3.909969606399536 and perplexity is 49.89743538764539
At time: 618.0377237796783 and batch: 100, loss is 3.8937767553329468 and perplexity is 49.09596024434112
At time: 619.1637217998505 and batch: 150, loss is 3.852412371635437 and perplexity is 47.10656481333575
At time: 620.286248922348 and batch: 200, loss is 3.8594558238983154 and perplexity is 47.4395288856069
At time: 621.4135127067566 and batch: 250, loss is 3.8502323150634767 and perplexity is 47.00398169625969
At time: 622.5493502616882 and batch: 300, loss is 3.8487641525268557 and perplexity is 46.93502284504892
At time: 623.6924223899841 and batch: 350, loss is 3.865441389083862 and perplexity is 47.724332783967654
At time: 624.8281309604645 and batch: 400, loss is 3.8248716402053833 and perplexity is 45.826917655051616
At time: 625.9701235294342 and batch: 450, loss is 3.8669825553894044 and perplexity is 47.79794062400082
At time: 627.1142694950104 and batch: 500, loss is 3.8690634775161743 and perplexity is 47.89750797628339
At time: 628.2605640888214 and batch: 550, loss is 3.844746723175049 and perplexity is 46.74684295943921
At time: 629.4082159996033 and batch: 600, loss is 3.800622305870056 and perplexity is 44.729010960198295
At time: 630.5605905056 and batch: 650, loss is 3.8314644289016724 and perplexity is 46.130042962362545
At time: 631.7375309467316 and batch: 700, loss is 3.8800930070877073 and perplexity is 48.428719076012406
At time: 632.8882713317871 and batch: 750, loss is 3.8090672445297242 and perplexity is 45.10834418255606
At time: 634.0448760986328 and batch: 800, loss is 3.802508144378662 and perplexity is 44.81344223837422
At time: 635.1974830627441 and batch: 850, loss is 3.80391242980957 and perplexity is 44.876417309556906
At time: 636.3514368534088 and batch: 900, loss is 3.7623093557357787 and perplexity is 43.047723785488884
At time: 637.5028257369995 and batch: 950, loss is 3.8544166898727417 and perplexity is 47.20107604393954
At time: 638.6556620597839 and batch: 1000, loss is 3.8173612213134764 and perplexity is 45.484027542890026
At time: 639.8079628944397 and batch: 1050, loss is 3.777813892364502 and perplexity is 43.7203597758158
At time: 640.9570496082306 and batch: 1100, loss is 3.794771966934204 and perplexity is 44.46809505324576
At time: 642.1067433357239 and batch: 1150, loss is 3.7728732299804686 and perplexity is 43.5048849712998
At time: 643.2562034130096 and batch: 1200, loss is 3.8130782890319823 and perplexity is 45.28963910643611
At time: 644.4080274105072 and batch: 1250, loss is 3.8046574115753176 and perplexity is 44.90986187841478
At time: 645.5580792427063 and batch: 1300, loss is 3.7956648778915407 and perplexity is 44.50781883483133
At time: 646.7072870731354 and batch: 1350, loss is 3.66839900970459 and perplexity is 39.18911421776311
At time: 647.8569164276123 and batch: 1400, loss is 3.6879491424560547 and perplexity is 39.96280483791382
At time: 649.0069239139557 and batch: 1450, loss is 3.6262314224243166 and perplexity is 37.57096040811548
At time: 650.1591820716858 and batch: 1500, loss is 3.6256703996658324 and perplexity is 37.549888155827674
At time: 651.3120727539062 and batch: 1550, loss is 3.6540736722946168 and perplexity is 38.63171890390413
At time: 652.463502407074 and batch: 1600, loss is 3.7273457622528077 and perplexity is 41.568628586264325
At time: 653.6215538978577 and batch: 1650, loss is 3.691364550590515 and perplexity is 40.09952747553152
At time: 654.7729790210724 and batch: 1700, loss is 3.673147120475769 and perplexity is 39.37563092367238
At time: 655.9235591888428 and batch: 1750, loss is 3.66059428691864 and perplexity is 38.884444522866424
At time: 657.0747945308685 and batch: 1800, loss is 3.619943208694458 and perplexity is 37.33544743304167
At time: 658.2274250984192 and batch: 1850, loss is 3.6524261093139647 and perplexity is 38.56812311737661
At time: 659.3781027793884 and batch: 1900, loss is 3.7494017934799193 and perplexity is 42.49565321815933
At time: 660.5296936035156 and batch: 1950, loss is 3.6907883644104005 and perplexity is 40.076429337024116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324871116460756 and perplexity of 75.55577433656558
finished 14 epochs...
Completing Train Step...
At time: 664.1911020278931 and batch: 50, loss is 3.905008144378662 and perplexity is 49.65048428287522
At time: 665.3380062580109 and batch: 100, loss is 3.888024001121521 and perplexity is 48.814334091980314
At time: 666.4611756801605 and batch: 150, loss is 3.846264863014221 and perplexity is 46.81786510122223
At time: 667.5921964645386 and batch: 200, loss is 3.8529989242553713 and perplexity is 47.13420339729264
At time: 668.7383720874786 and batch: 250, loss is 3.8434050464630127 and perplexity is 46.68416586448073
At time: 669.8775806427002 and batch: 300, loss is 3.841571817398071 and perplexity is 46.59866149324109
At time: 671.0215542316437 and batch: 350, loss is 3.8583769369125367 and perplexity is 47.38837459509185
At time: 672.1710653305054 and batch: 400, loss is 3.817785120010376 and perplexity is 45.50331224998754
At time: 673.3281123638153 and batch: 450, loss is 3.860030345916748 and perplexity is 47.466791770309634
At time: 674.4844498634338 and batch: 500, loss is 3.8620049715042115 and perplexity is 47.560613512815394
At time: 675.6410429477692 and batch: 550, loss is 3.8376920080184935 and perplexity is 46.41821783914496
At time: 676.7955112457275 and batch: 600, loss is 3.7941623735427856 and perplexity is 44.440995856957
At time: 677.951877117157 and batch: 650, loss is 3.8252892208099367 and perplexity is 45.84605808308846
At time: 679.1055774688721 and batch: 700, loss is 3.874165663719177 and perplexity is 48.14251448354193
At time: 680.2607219219208 and batch: 750, loss is 3.8033523845672605 and perplexity is 44.85129152199641
At time: 681.4163227081299 and batch: 800, loss is 3.7969401979446413 and perplexity is 44.56461675877865
At time: 682.572432756424 and batch: 850, loss is 3.798436460494995 and perplexity is 44.631347036463765
At time: 683.7324395179749 and batch: 900, loss is 3.75701699256897 and perplexity is 42.820501399761824
At time: 684.8910882472992 and batch: 950, loss is 3.8495755290985105 and perplexity is 46.9731202765671
At time: 686.0518293380737 and batch: 1000, loss is 3.812593460083008 and perplexity is 45.2676867003197
At time: 687.210250377655 and batch: 1050, loss is 3.773442072868347 and perplexity is 43.5296394557424
At time: 688.3674757480621 and batch: 1100, loss is 3.790507674217224 and perplexity is 44.27887381348574
At time: 689.5365545749664 and batch: 1150, loss is 3.768976454734802 and perplexity is 43.33568609158612
At time: 690.6795573234558 and batch: 1200, loss is 3.8093132543563843 and perplexity is 45.1194426435986
At time: 691.821661233902 and batch: 1250, loss is 3.8013124370574953 and perplexity is 44.759890499886325
At time: 692.965497970581 and batch: 1300, loss is 3.7925561380386354 and perplexity is 44.3696704496075
At time: 694.1133468151093 and batch: 1350, loss is 3.6654048013687133 and perplexity is 39.0719493408569
At time: 695.2557978630066 and batch: 1400, loss is 3.6854175662994386 and perplexity is 39.86176390440696
At time: 696.3985869884491 and batch: 1450, loss is 3.6241486501693725 and perplexity is 37.492790087931056
At time: 697.5417125225067 and batch: 1500, loss is 3.623925542831421 and perplexity is 37.484426104409906
At time: 698.6833152770996 and batch: 1550, loss is 3.6525105571746828 and perplexity is 38.57138025039281
At time: 699.8266487121582 and batch: 1600, loss is 3.726195840835571 and perplexity is 41.520855402935446
At time: 700.969654083252 and batch: 1650, loss is 3.6901795053482056 and perplexity is 40.052035866688165
At time: 702.1126964092255 and batch: 1700, loss is 3.6722462606430053 and perplexity is 39.34017497220262
At time: 703.2623202800751 and batch: 1750, loss is 3.6599076986312866 and perplexity is 38.85775608173074
At time: 704.4138572216034 and batch: 1800, loss is 3.6194548988342286 and perplexity is 37.31722061645335
At time: 705.567399263382 and batch: 1850, loss is 3.652030873298645 and perplexity is 38.552882618072836
At time: 706.7199504375458 and batch: 1900, loss is 3.749022855758667 and perplexity is 42.479553062836466
At time: 707.8718645572662 and batch: 1950, loss is 3.690113377571106 and perplexity is 40.04938740215749
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325175724473111 and perplexity of 75.5787927364247
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 711.5283589363098 and batch: 50, loss is 3.905957970619202 and perplexity is 49.697666019381145
At time: 712.6808891296387 and batch: 100, loss is 3.897515335083008 and perplexity is 49.27985294168902
At time: 713.80091547966 and batch: 150, loss is 3.8599216413497923 and perplexity is 47.461632193705306
At time: 714.9324176311493 and batch: 200, loss is 3.8696860790252687 and perplexity is 47.92733832227691
At time: 716.0712187290192 and batch: 250, loss is 3.863125967979431 and perplexity is 47.613958687212495
At time: 717.2335152626038 and batch: 300, loss is 3.860645446777344 and perplexity is 47.49599761612688
At time: 718.3730380535126 and batch: 350, loss is 3.8774588346481322 and perplexity is 48.30131735166257
At time: 719.5254762172699 and batch: 400, loss is 3.8426724767684934 and perplexity is 46.64997898302004
At time: 720.677561044693 and batch: 450, loss is 3.8832470846176146 and perplexity is 48.581708153527565
At time: 721.8318798542023 and batch: 500, loss is 3.886404762268066 and perplexity is 48.73535598507898
At time: 722.9854860305786 and batch: 550, loss is 3.865050587654114 and perplexity is 47.705685690374644
At time: 724.145316362381 and batch: 600, loss is 3.8207490921020506 and perplexity is 45.63838287146708
At time: 725.2979764938354 and batch: 650, loss is 3.8470513296127318 and perplexity is 46.85470027125473
At time: 726.4556310176849 and batch: 700, loss is 3.8956212186813355 and perplexity is 49.18659950826931
At time: 727.6096169948578 and batch: 750, loss is 3.822756080627441 and perplexity is 45.73007055949988
At time: 728.7614290714264 and batch: 800, loss is 3.8135213613510133 and perplexity is 45.309710137993974
At time: 729.9140138626099 and batch: 850, loss is 3.81259379863739 and perplexity is 45.26770202589601
At time: 731.0668179988861 and batch: 900, loss is 3.7644369268417357 and perplexity is 43.139408376951295
At time: 732.2189321517944 and batch: 950, loss is 3.8623838806152344 and perplexity is 47.57863807722143
At time: 733.3710510730743 and batch: 1000, loss is 3.8246427011489867 and perplexity is 45.81642728463967
At time: 734.5226759910583 and batch: 1050, loss is 3.782312126159668 and perplexity is 43.91746716088905
At time: 735.6755728721619 and batch: 1100, loss is 3.796235818862915 and perplexity is 44.53323742771822
At time: 736.8281164169312 and batch: 1150, loss is 3.777447533607483 and perplexity is 43.70434537283942
At time: 737.9820139408112 and batch: 1200, loss is 3.8167841815948487 and perplexity is 45.45778902349661
At time: 739.1353940963745 and batch: 1250, loss is 3.806141963005066 and perplexity is 44.97658239083851
At time: 740.2886900901794 and batch: 1300, loss is 3.794614496231079 and perplexity is 44.46109318236033
At time: 741.440938949585 and batch: 1350, loss is 3.664694585800171 and perplexity is 39.044209685875146
At time: 742.5930490493774 and batch: 1400, loss is 3.685440468788147 and perplexity is 39.862676848458975
At time: 743.7452988624573 and batch: 1450, loss is 3.619564661979675 and perplexity is 37.32131689677373
At time: 744.8976049423218 and batch: 1500, loss is 3.6152858304977418 and perplexity is 37.161966431104105
At time: 746.0503880977631 and batch: 1550, loss is 3.6444933223724365 and perplexity is 38.263380740222345
At time: 747.2035436630249 and batch: 1600, loss is 3.7195292997360228 and perplexity is 41.24497551793742
At time: 748.3612039089203 and batch: 1650, loss is 3.682476511001587 and perplexity is 39.74470048187503
At time: 749.516373872757 and batch: 1700, loss is 3.6641399097442626 and perplexity is 39.02255880280884
At time: 750.6769344806671 and batch: 1750, loss is 3.6532965755462645 and perplexity is 38.60170998218854
At time: 751.8304922580719 and batch: 1800, loss is 3.613795504570007 and perplexity is 37.10662423820196
At time: 752.9841766357422 and batch: 1850, loss is 3.6451717376708985 and perplexity is 38.28934801038811
At time: 754.1397376060486 and batch: 1900, loss is 3.7412214994430544 and perplexity is 42.14944425571101
At time: 755.2959642410278 and batch: 1950, loss is 3.6897706890106203 and perplexity is 40.03566528658062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319266669694767 and perplexity of 75.13351040456634
finished 16 epochs...
Completing Train Step...
At time: 758.9771666526794 and batch: 50, loss is 3.9106289291381837 and perplexity is 49.930344749149675
At time: 760.0963988304138 and batch: 100, loss is 3.897233371734619 and perplexity is 49.26595978811757
At time: 761.2140066623688 and batch: 150, loss is 3.855162010192871 and perplexity is 47.236269078459785
At time: 762.3340210914612 and batch: 200, loss is 3.8601728820800782 and perplexity is 47.47355798689798
At time: 763.468421459198 and batch: 250, loss is 3.8510643529891966 and perplexity is 47.04310706632953
At time: 764.6019270420074 and batch: 300, loss is 3.8482665538787844 and perplexity is 46.911673850829786
At time: 765.735111951828 and batch: 350, loss is 3.8637909269332886 and perplexity is 47.64563054444566
At time: 766.8801782131195 and batch: 400, loss is 3.828384208679199 and perplexity is 45.98817088196247
At time: 768.0323452949524 and batch: 450, loss is 3.870177597999573 and perplexity is 47.9509013088033
At time: 769.1866116523743 and batch: 500, loss is 3.87413284778595 and perplexity is 48.14093466792295
At time: 770.3421583175659 and batch: 550, loss is 3.852824716567993 and perplexity is 47.12599297190275
At time: 771.495406627655 and batch: 600, loss is 3.8088597154617307 and perplexity is 45.0989838612321
At time: 772.6521799564362 and batch: 650, loss is 3.835505690574646 and perplexity is 46.31684373813415
At time: 773.8117418289185 and batch: 700, loss is 3.8848152112960816 and perplexity is 48.65795018913024
At time: 775.0066084861755 and batch: 750, loss is 3.8129444551467895 and perplexity is 45.28357822366031
At time: 776.1585235595703 and batch: 800, loss is 3.804676752090454 and perplexity is 44.91073046667766
At time: 777.313490152359 and batch: 850, loss is 3.8043062686920166 and perplexity is 44.89409486842482
At time: 778.4686558246613 and batch: 900, loss is 3.7578127002716064 and perplexity is 42.85458756206886
At time: 779.6194567680359 and batch: 950, loss is 3.855711350440979 and perplexity is 47.26222499089599
At time: 780.7716710567474 and batch: 1000, loss is 3.8175567865371702 and perplexity is 45.49292350675317
At time: 781.9227139949799 and batch: 1050, loss is 3.77668484210968 and perplexity is 43.67102514834767
At time: 783.0738942623138 and batch: 1100, loss is 3.7909901905059815 and perplexity is 44.300244246725015
At time: 784.2256224155426 and batch: 1150, loss is 3.7722307109832762 and perplexity is 43.47694123438732
At time: 785.373970746994 and batch: 1200, loss is 3.811775631904602 and perplexity is 45.23068064492497
At time: 786.528561592102 and batch: 1250, loss is 3.8019819116592406 and perplexity is 44.789866142599045
At time: 787.6802701950073 and batch: 1300, loss is 3.792171640396118 and perplexity is 44.35261369527141
At time: 788.8307337760925 and batch: 1350, loss is 3.662888512611389 and perplexity is 38.97375662642608
At time: 789.9825210571289 and batch: 1400, loss is 3.684241223335266 and perplexity is 39.814900368098186
At time: 791.1337842941284 and batch: 1450, loss is 3.6194987154006957 and perplexity is 37.31885576475389
At time: 792.2863955497742 and batch: 1500, loss is 3.6169454622268677 and perplexity is 37.22369281707607
At time: 793.4375095367432 and batch: 1550, loss is 3.6471430969238283 and perplexity is 38.36490452092078
At time: 794.5898153781891 and batch: 1600, loss is 3.722303018569946 and perplexity is 41.35953628957327
At time: 795.7411360740662 and batch: 1650, loss is 3.686402235031128 and perplexity is 39.901033867693165
At time: 796.8916804790497 and batch: 1700, loss is 3.6684404706954954 and perplexity is 39.19073907095507
At time: 798.043913602829 and batch: 1750, loss is 3.6581543684005737 and perplexity is 38.7896852960166
At time: 799.1959178447723 and batch: 1800, loss is 3.618447952270508 and perplexity is 37.27966308177468
At time: 800.3552856445312 and batch: 1850, loss is 3.64977511882782 and perplexity is 38.46601479382045
At time: 801.5065014362335 and batch: 1900, loss is 3.7460697364807127 and perplexity is 42.354290923819825
At time: 802.6577324867249 and batch: 1950, loss is 3.6946368932724 and perplexity is 40.2309618026066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318360794422238 and perplexity of 75.06547963370136
finished 17 epochs...
Completing Train Step...
At time: 806.3344495296478 and batch: 50, loss is 3.9107818841934203 and perplexity is 49.93798243188496
At time: 807.456707239151 and batch: 100, loss is 3.895615510940552 and perplexity is 49.18631876471049
At time: 808.5787041187286 and batch: 150, loss is 3.8525011587142943 and perplexity is 47.110747453299986
At time: 809.7057428359985 and batch: 200, loss is 3.8561614513397218 and perplexity is 47.283502549005775
At time: 810.8369798660278 and batch: 250, loss is 3.8463488245010375 and perplexity is 46.82179616381232
At time: 811.9762196540833 and batch: 300, loss is 3.8435213565826416 and perplexity is 46.68959602118217
At time: 813.1219654083252 and batch: 350, loss is 3.8587269735336305 and perplexity is 47.404965165098375
At time: 814.2754430770874 and batch: 400, loss is 3.8231614780426026 and perplexity is 45.74861317020912
At time: 815.4205992221832 and batch: 450, loss is 3.865226836204529 and perplexity is 47.714094489321674
At time: 816.5645265579224 and batch: 500, loss is 3.869423899650574 and perplexity is 47.91477440975611
At time: 817.7099256515503 and batch: 550, loss is 3.8480701065063476 and perplexity is 46.90245908090348
At time: 818.8563253879547 and batch: 600, loss is 3.804410719871521 and perplexity is 44.89878435449352
At time: 820.00235247612 and batch: 650, loss is 3.8312124967575074 and perplexity is 46.11842278553811
At time: 821.1509323120117 and batch: 700, loss is 3.880798568725586 and perplexity is 48.46290057952484
At time: 822.3001503944397 and batch: 750, loss is 3.8091834735870362 and perplexity is 45.113587387577795
At time: 823.4465041160583 and batch: 800, loss is 3.801117944717407 and perplexity is 44.75118589055826
At time: 824.5928981304169 and batch: 850, loss is 3.800865035057068 and perplexity is 44.73986931443094
At time: 825.7381703853607 and batch: 900, loss is 3.7547875213623048 and perplexity is 42.72514066634034
At time: 826.8846576213837 and batch: 950, loss is 3.8527228164672853 and perplexity is 47.121191073134106
At time: 828.0372333526611 and batch: 1000, loss is 3.814779963493347 and perplexity is 45.366772938390916
At time: 829.1842906475067 and batch: 1050, loss is 3.774318799972534 and perplexity is 43.5678198049166
At time: 830.331170797348 and batch: 1100, loss is 3.788909339904785 and perplexity is 44.208157899044394
At time: 831.5223286151886 and batch: 1150, loss is 3.7702735233306885 and perplexity is 43.39193191855901
At time: 832.6739120483398 and batch: 1200, loss is 3.8099595355987548 and perplexity is 45.14861191780747
At time: 833.8279752731323 and batch: 1250, loss is 3.800627393722534 and perplexity is 44.72923853538648
At time: 834.9829771518707 and batch: 1300, loss is 3.7914492464065552 and perplexity is 44.32058520370429
At time: 836.1385684013367 and batch: 1350, loss is 3.6622917556762697 and perplexity is 38.95050570513588
At time: 837.291318655014 and batch: 1400, loss is 3.683938364982605 and perplexity is 39.80284391875169
At time: 838.4464919567108 and batch: 1450, loss is 3.619576306343079 and perplexity is 37.32175148228061
At time: 839.599858045578 and batch: 1500, loss is 3.6177711343765258 and perplexity is 37.254440075373196
At time: 840.7573521137238 and batch: 1550, loss is 3.6483061838150026 and perplexity is 38.409552197981
At time: 841.9105911254883 and batch: 1600, loss is 3.7236253786087037 and perplexity is 41.41426466491741
At time: 843.0643961429596 and batch: 1650, loss is 3.687952494621277 and perplexity is 39.96293880006292
At time: 844.2179007530212 and batch: 1700, loss is 3.6700284576416013 and perplexity is 39.25302289286763
At time: 845.3757977485657 and batch: 1750, loss is 3.659931960105896 and perplexity is 38.8586988396296
At time: 846.5308828353882 and batch: 1800, loss is 3.6201836395263673 and perplexity is 37.34442510493902
At time: 847.6835558414459 and batch: 1850, loss is 3.65144419670105 and perplexity is 38.53027117752104
At time: 848.8363196849823 and batch: 1900, loss is 3.7477980756759646 and perplexity is 42.42755680081595
At time: 849.9912810325623 and batch: 1950, loss is 3.6962383222579955 and perplexity is 40.29544044616002
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317991176871367 and perplexity of 75.03773924194778
finished 18 epochs...
Completing Train Step...
At time: 853.6553001403809 and batch: 50, loss is 3.909785041809082 and perplexity is 49.88822693772138
At time: 854.776031255722 and batch: 100, loss is 3.893784589767456 and perplexity is 49.09634488493304
At time: 855.8958129882812 and batch: 150, loss is 3.850262222290039 and perplexity is 47.005387476011
At time: 857.0255308151245 and batch: 200, loss is 3.8533999633789064 and perplexity is 47.15310984777138
At time: 858.1708812713623 and batch: 250, loss is 3.8433088636398316 and perplexity is 46.67967586554388
At time: 859.3181021213531 and batch: 300, loss is 3.8404769992828367 and perplexity is 46.54767235150372
At time: 860.485102891922 and batch: 350, loss is 3.855616207122803 and perplexity is 47.25772851989395
At time: 861.629289150238 and batch: 400, loss is 3.8199719905853273 and perplexity is 45.602930991555766
At time: 862.7734241485596 and batch: 450, loss is 3.8621496868133547 and perplexity is 47.56749675974653
At time: 863.9177565574646 and batch: 500, loss is 3.866441125869751 and perplexity is 47.77206841258988
At time: 865.0616412162781 and batch: 550, loss is 3.8450791788101197 and perplexity is 46.76238679447746
At time: 866.2076771259308 and batch: 600, loss is 3.801643691062927 and perplexity is 44.77471984890213
At time: 867.3533835411072 and batch: 650, loss is 3.8285675621032715 and perplexity is 45.99660374363391
At time: 868.4993588924408 and batch: 700, loss is 3.878283829689026 and perplexity is 48.34118214081195
At time: 869.6445405483246 and batch: 750, loss is 3.806784586906433 and perplexity is 45.005494706562246
At time: 870.7871887683868 and batch: 800, loss is 3.798801231384277 and perplexity is 44.647630222247635
At time: 871.9362740516663 and batch: 850, loss is 3.798618540763855 and perplexity is 44.63947426401317
At time: 873.0861930847168 and batch: 900, loss is 3.7527041149139406 and perplexity is 42.636219494404465
At time: 874.2405536174774 and batch: 950, loss is 3.850722842216492 and perplexity is 47.02704408148218
At time: 875.3924360275269 and batch: 1000, loss is 3.813006253242493 and perplexity is 45.286376749032044
At time: 876.5448513031006 and batch: 1050, loss is 3.7727061796188353 and perplexity is 43.497618071518545
At time: 877.7052862644196 and batch: 1100, loss is 3.7874812698364257 and perplexity is 44.145070609228206
At time: 878.860517501831 and batch: 1150, loss is 3.7689885759353636 and perplexity is 43.33621137531223
At time: 880.013787984848 and batch: 1200, loss is 3.8087603759765627 and perplexity is 45.09450397391226
At time: 881.1667716503143 and batch: 1250, loss is 3.7997103834152224 and perplexity is 44.68824016344914
At time: 882.320511341095 and batch: 1300, loss is 3.790841507911682 and perplexity is 44.29365806112003
At time: 883.4737977981567 and batch: 1350, loss is 3.661720595359802 and perplexity is 38.928265074058324
At time: 884.6258723735809 and batch: 1400, loss is 3.683575463294983 and perplexity is 39.78840202017461
At time: 885.7795422077179 and batch: 1450, loss is 3.619403567314148 and perplexity is 37.315305115957116
At time: 886.9324457645416 and batch: 1500, loss is 3.6180182123184204 and perplexity is 37.263645962992506
At time: 888.0861585140228 and batch: 1550, loss is 3.6486898946762083 and perplexity is 38.42429318829159
At time: 889.2396397590637 and batch: 1600, loss is 3.7241627264022825 and perplexity is 41.43652450876117
At time: 890.4007954597473 and batch: 1650, loss is 3.688505702018738 and perplexity is 39.98505270965661
At time: 891.5533878803253 and batch: 1700, loss is 3.670616793632507 and perplexity is 39.27612365382555
At time: 892.7063801288605 and batch: 1750, loss is 3.660640697479248 and perplexity is 38.88624921361369
At time: 893.8640239238739 and batch: 1800, loss is 3.6208937120437623 and perplexity is 37.37095177169791
At time: 895.0166096687317 and batch: 1850, loss is 3.652122163772583 and perplexity is 38.55640228965252
At time: 896.1776602268219 and batch: 1900, loss is 3.74849271774292 and perplexity is 42.45703900517213
At time: 897.3299171924591 and batch: 1950, loss is 3.696801433563232 and perplexity is 40.318137654152196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317814032976018 and perplexity of 75.02444794179138
finished 19 epochs...
Completing Train Step...
At time: 900.988893032074 and batch: 50, loss is 3.9085097551345824 and perplexity is 49.82464569746467
At time: 902.132780790329 and batch: 100, loss is 3.8920449781417847 and perplexity is 49.01101055840673
At time: 903.2538096904755 and batch: 150, loss is 3.848313798904419 and perplexity is 46.91389024641986
At time: 904.3762154579163 and batch: 200, loss is 3.8512038564682007 and perplexity is 47.04967020120788
At time: 905.5110969543457 and batch: 250, loss is 3.840950593948364 and perplexity is 46.56972230177939
At time: 906.6533124446869 and batch: 300, loss is 3.838103384971619 and perplexity is 46.43731715240843
At time: 907.7977449893951 and batch: 350, loss is 3.8532497119903564 and perplexity is 47.14602555976768
At time: 908.9488182067871 and batch: 400, loss is 3.8175607204437254 and perplexity is 45.49310247201519
At time: 910.0946049690247 and batch: 450, loss is 3.8598044729232788 and perplexity is 47.45607151471577
At time: 911.2413494586945 and batch: 500, loss is 3.8641399717330933 and perplexity is 47.66226390674605
At time: 912.3870723247528 and batch: 550, loss is 3.8427824354171753 and perplexity is 46.65510883370061
At time: 913.5305728912354 and batch: 600, loss is 3.7995220232009888 and perplexity is 44.679823469668236
At time: 914.6742172241211 and batch: 650, loss is 3.8265367460250856 and perplexity is 45.90328788695166
At time: 915.8224568367004 and batch: 700, loss is 3.8763340520858764 and perplexity is 48.247019414582354
At time: 916.9661786556244 and batch: 750, loss is 3.804909658432007 and perplexity is 44.92119167880116
At time: 918.1331074237823 and batch: 800, loss is 3.79697096824646 and perplexity is 44.5659880465841
At time: 919.2759399414062 and batch: 850, loss is 3.79683265209198 and perplexity is 44.55982427678121
At time: 920.4206471443176 and batch: 900, loss is 3.751006956100464 and perplexity is 42.56392042756932
At time: 921.5674107074738 and batch: 950, loss is 3.849114565849304 and perplexity is 46.951472384243765
At time: 922.7180082798004 and batch: 1000, loss is 3.811577205657959 and perplexity is 45.221706581105835
At time: 923.8683767318726 and batch: 1050, loss is 3.7713632869720457 and perplexity is 43.43924464345346
At time: 925.019143819809 and batch: 1100, loss is 3.786270246505737 and perplexity is 44.09164225680592
At time: 926.168781042099 and batch: 1150, loss is 3.767895884513855 and perplexity is 43.28888413064782
At time: 927.3184716701508 and batch: 1200, loss is 3.8077311611175535 and perplexity is 45.04811591609669
At time: 928.4711802005768 and batch: 1250, loss is 3.798879690170288 and perplexity is 44.651133358537244
At time: 929.6210210323334 and batch: 1300, loss is 3.7901914644241335 and perplexity is 44.26487461341761
At time: 930.7726011276245 and batch: 1350, loss is 3.6610830879211425 and perplexity is 38.90345592434847
At time: 931.9237568378448 and batch: 1400, loss is 3.6831012535095216 and perplexity is 39.76953844358856
At time: 933.074832201004 and batch: 1450, loss is 3.619055905342102 and perplexity is 37.30233425826064
At time: 934.2335410118103 and batch: 1500, loss is 3.6179495334625242 and perplexity is 37.26108682630154
At time: 935.3877196311951 and batch: 1550, loss is 3.6486794328689576 and perplexity is 38.42389120284526
At time: 936.5380549430847 and batch: 1600, loss is 3.724289689064026 and perplexity is 41.44178573418873
At time: 937.6907756328583 and batch: 1650, loss is 3.688598008155823 and perplexity is 39.9887437457634
At time: 938.8415193557739 and batch: 1700, loss is 3.6707592725753786 and perplexity is 39.281720073080315
At time: 939.9954974651337 and batch: 1750, loss is 3.660891170501709 and perplexity is 38.8959903898864
At time: 941.1480228900909 and batch: 1800, loss is 3.621160960197449 and perplexity is 37.38094042422542
At time: 942.3087077140808 and batch: 1850, loss is 3.652381272315979 and perplexity is 38.56639387728535
At time: 943.4628994464874 and batch: 1900, loss is 3.748756237030029 and perplexity is 42.468228728112685
At time: 944.617110490799 and batch: 1950, loss is 3.696951994895935 and perplexity is 40.324208463692614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317734261446221 and perplexity of 75.01846336550948
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
3886.3594348430634


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}, 'best_accuracy': -74.98631242869352}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.17814085302781324, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.8667473068914826}, 'best_accuracy': -75.01846336550948}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.46505974392752214, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.5624524957122032}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6629831790924072 and batch: 50, loss is 7.637656660079956 and perplexity is 2074.875975593118
At time: 2.844348907470703 and batch: 100, loss is 6.825937576293946 and perplexity is 921.4399194067914
At time: 4.0711753368377686 and batch: 150, loss is 6.51635669708252 and perplexity is 676.1106168721167
At time: 5.2518603801727295 and batch: 200, loss is 6.383761262893676 and perplexity is 592.1507589746393
At time: 6.434383869171143 and batch: 250, loss is 6.2678876304626465 and perplexity is 527.3622165945039
At time: 7.617871999740601 and batch: 300, loss is 6.167929735183716 and perplexity is 477.1971582633517
At time: 8.802742004394531 and batch: 350, loss is 6.0976858329772945 and perplexity is 444.82717368021423
At time: 9.982785701751709 and batch: 400, loss is 6.0290373420715335 and perplexity is 415.3150305748705
At time: 11.165814876556396 and batch: 450, loss is 5.924672327041626 and perplexity is 374.1558145289642
At time: 12.349528551101685 and batch: 500, loss is 5.900601348876953 and perplexity is 365.25704875241826
At time: 13.533896684646606 and batch: 550, loss is 5.848833847045898 and perplexity is 346.82968809264656
At time: 14.72087836265564 and batch: 600, loss is 5.873856382369995 and perplexity is 355.61773731882914
At time: 15.912136793136597 and batch: 650, loss is 5.932770538330078 and perplexity is 377.19810931643497
At time: 17.10441303253174 and batch: 700, loss is 5.84652792930603 and perplexity is 346.03084874504185
At time: 18.296571969985962 and batch: 750, loss is 5.767824487686157 and perplexity is 319.8411568422842
At time: 19.491143703460693 and batch: 800, loss is 5.779490652084351 and perplexity is 323.59432633858324
At time: 20.68486475944519 and batch: 850, loss is 5.795506477355957 and perplexity is 328.81868103105757
At time: 21.87638282775879 and batch: 900, loss is 5.764536170959473 and perplexity is 318.7911451480166
At time: 23.06577467918396 and batch: 950, loss is 5.789734554290772 and perplexity is 326.9262316916711
At time: 24.261324644088745 and batch: 1000, loss is 5.757032985687256 and perplexity is 316.4081473396405
At time: 25.451359510421753 and batch: 1050, loss is 5.653765563964844 and perplexity is 285.3640016068553
At time: 26.64009428024292 and batch: 1100, loss is 5.724655447006225 and perplexity is 306.32770093172655
At time: 27.82976746559143 and batch: 1150, loss is 5.639673919677734 and perplexity is 281.3709539834445
At time: 29.019243478775024 and batch: 1200, loss is 5.701888427734375 and perplexity is 299.4323236959379
At time: 30.209986925125122 and batch: 1250, loss is 5.6496033859252925 and perplexity is 284.1787341842111
At time: 31.399803400039673 and batch: 1300, loss is 5.6568998336792 and perplexity is 286.2598124777563
At time: 32.58956789970398 and batch: 1350, loss is 5.613031978607178 and perplexity is 273.9736622539503
At time: 33.77809238433838 and batch: 1400, loss is 5.615386943817139 and perplexity is 274.61962100366225
At time: 34.97190809249878 and batch: 1450, loss is 5.591349821090699 and perplexity is 268.0972589190719
At time: 36.167022943496704 and batch: 1500, loss is 5.556689949035644 and perplexity is 258.9642312901644
At time: 37.35870409011841 and batch: 1550, loss is 5.5380308628082275 and perplexity is 254.17699697109668
At time: 38.5542573928833 and batch: 1600, loss is 5.554684410095215 and perplexity is 258.4453888933556
At time: 39.74514365196228 and batch: 1650, loss is 5.549191064834595 and perplexity is 257.0295515433042
At time: 40.94424533843994 and batch: 1700, loss is 5.5651898765563965 and perplexity is 261.1747899717225
At time: 42.139591217041016 and batch: 1750, loss is 5.553757486343383 and perplexity is 258.20594071608474
At time: 43.33014106750488 and batch: 1800, loss is 5.551203060150146 and perplexity is 257.5472143899485
At time: 44.520493268966675 and batch: 1850, loss is 5.522595081329346 and perplexity is 250.28370171842604
At time: 45.71213102340698 and batch: 1900, loss is 5.537676782608032 and perplexity is 254.08701386068304
At time: 46.90369915962219 and batch: 1950, loss is 5.4735628032684325 and perplexity is 238.30772561194655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.986192428234012 and perplexity of 146.3780162806007
finished 1 epochs...
Completing Train Step...
At time: 50.53569173812866 and batch: 50, loss is 5.258568830490113 and perplexity is 192.20621468641568
At time: 51.68294596672058 and batch: 100, loss is 5.185048522949219 and perplexity is 178.58211491048863
At time: 52.79945969581604 and batch: 150, loss is 5.097924041748047 and perplexity is 163.68175785812073
At time: 53.91866421699524 and batch: 200, loss is 5.052822275161743 and perplexity is 156.4634247755285
At time: 55.04036593437195 and batch: 250, loss is 5.063639459609985 and perplexity is 158.16510560545007
At time: 56.16120481491089 and batch: 300, loss is 5.071303234100342 and perplexity is 159.38190398568995
At time: 57.281641244888306 and batch: 350, loss is 5.059117984771729 and perplexity is 157.45158036895947
At time: 58.406532764434814 and batch: 400, loss is 5.006142034530639 and perplexity is 149.32752300341383
At time: 59.52609038352966 and batch: 450, loss is 4.968117589950562 and perplexity is 143.7560247280065
At time: 60.646650314331055 and batch: 500, loss is 4.953881006240845 and perplexity is 141.72392941771304
At time: 61.76642417907715 and batch: 550, loss is 4.922045021057129 and perplexity is 137.28307309077917
At time: 62.91045784950256 and batch: 600, loss is 4.890351934432983 and perplexity is 133.0003732266172
At time: 64.0302324295044 and batch: 650, loss is 4.959134721755982 and perplexity is 142.47046595272107
At time: 65.14975643157959 and batch: 700, loss is 4.96845085144043 and perplexity is 143.80394105887532
At time: 66.26963138580322 and batch: 750, loss is 4.913425140380859 and perplexity is 136.1047949859249
At time: 67.39037919044495 and batch: 800, loss is 4.906075944900513 and perplexity is 135.1082008100238
At time: 68.5100667476654 and batch: 850, loss is 4.90372784614563 and perplexity is 134.7913255846811
At time: 69.63092136383057 and batch: 900, loss is 4.88221432685852 and perplexity is 131.92246014719782
At time: 70.75133085250854 and batch: 950, loss is 4.928055734634399 and perplexity is 138.11072722627407
At time: 71.87215614318848 and batch: 1000, loss is 4.8967207908630375 and perplexity is 133.85013664708984
At time: 72.99402356147766 and batch: 1050, loss is 4.820502815246582 and perplexity is 124.02743799076244
At time: 74.11466979980469 and batch: 1100, loss is 4.880412034988403 and perplexity is 131.684911500088
At time: 75.23485040664673 and batch: 1150, loss is 4.81347321510315 and perplexity is 123.15863195208817
At time: 76.3549907207489 and batch: 1200, loss is 4.882923641204834 and perplexity is 132.01606783549468
At time: 77.4738540649414 and batch: 1250, loss is 4.858455877304078 and perplexity is 128.8251266466044
At time: 78.59364056587219 and batch: 1300, loss is 4.856628627777099 and perplexity is 128.5899459272415
At time: 79.71443438529968 and batch: 1350, loss is 4.744305648803711 and perplexity is 114.92797741334779
At time: 80.83875632286072 and batch: 1400, loss is 4.750310850143433 and perplexity is 115.62021950351843
At time: 81.96649765968323 and batch: 1450, loss is 4.701451148986816 and perplexity is 110.10683800126155
At time: 83.09781908988953 and batch: 1500, loss is 4.6884690284729 and perplexity is 108.68665619247892
At time: 84.21882843971252 and batch: 1550, loss is 4.6927806091308595 and perplexity is 109.15627915823117
At time: 85.33840131759644 and batch: 1600, loss is 4.746722745895386 and perplexity is 115.20610548917692
At time: 86.46674585342407 and batch: 1650, loss is 4.7172959041595455 and perplexity is 111.86534868760845
At time: 87.58746790885925 and batch: 1700, loss is 4.734581050872802 and perplexity is 113.81576571272949
At time: 88.71400237083435 and batch: 1750, loss is 4.724123363494873 and perplexity is 112.63171800751694
At time: 89.85747718811035 and batch: 1800, loss is 4.67798378944397 and perplexity is 107.553004314647
At time: 91.00978446006775 and batch: 1850, loss is 4.704696617126465 and perplexity is 110.46476674494525
At time: 92.16254353523254 and batch: 1900, loss is 4.801861629486084 and perplexity is 121.7368355827355
At time: 93.30719232559204 and batch: 1950, loss is 4.716108922958374 and perplexity is 111.73264539539109
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.57241097383721 and perplexity of 96.77715591683425
finished 2 epochs...
Completing Train Step...
At time: 96.95235872268677 and batch: 50, loss is 4.675322561264038 and perplexity is 107.26716174357908
At time: 98.09677767753601 and batch: 100, loss is 4.620885543823242 and perplexity is 101.58394934973732
At time: 99.21858501434326 and batch: 150, loss is 4.560284566879273 and perplexity is 95.61068359309294
At time: 100.34079813957214 and batch: 200, loss is 4.545650787353516 and perplexity is 94.22172556857137
At time: 101.4788146018982 and batch: 250, loss is 4.560164575576782 and perplexity is 95.5992118309062
At time: 102.62665820121765 and batch: 300, loss is 4.5739852333068844 and perplexity is 96.92962825500638
At time: 103.76510095596313 and batch: 350, loss is 4.574807357788086 and perplexity is 97.00934924114557
At time: 104.90083527565002 and batch: 400, loss is 4.517802925109863 and perplexity is 91.63404978113475
At time: 106.04248285293579 and batch: 450, loss is 4.528136157989502 and perplexity is 92.58583479639033
At time: 107.17835974693298 and batch: 500, loss is 4.52842511177063 and perplexity is 92.61259168900004
At time: 108.31438565254211 and batch: 550, loss is 4.501795978546142 and perplexity is 90.17894540095445
At time: 109.45382785797119 and batch: 600, loss is 4.471714906692505 and perplexity is 87.50666016974252
At time: 110.60144329071045 and batch: 650, loss is 4.532278146743774 and perplexity is 92.97011958515735
At time: 111.74309039115906 and batch: 700, loss is 4.569431638717651 and perplexity is 96.48925342939847
At time: 112.88886713981628 and batch: 750, loss is 4.5205211353302 and perplexity is 91.88346922544895
At time: 114.03576993942261 and batch: 800, loss is 4.516153860092163 and perplexity is 91.48306380227457
At time: 115.18621802330017 and batch: 850, loss is 4.51177939414978 and perplexity is 91.08374828819834
At time: 116.33587956428528 and batch: 900, loss is 4.48021279335022 and perplexity is 88.25345042507494
At time: 117.4880838394165 and batch: 950, loss is 4.547447662353516 and perplexity is 94.39118243250898
At time: 118.63664078712463 and batch: 1000, loss is 4.5210795402526855 and perplexity is 91.93479173499688
At time: 119.81350517272949 and batch: 1050, loss is 4.468043222427368 and perplexity is 87.18595247150266
At time: 120.96593809127808 and batch: 1100, loss is 4.509904918670654 and perplexity is 90.91317395413347
At time: 122.11330509185791 and batch: 1150, loss is 4.470367965698242 and perplexity is 87.38887320574199
At time: 123.2701621055603 and batch: 1200, loss is 4.531595659255982 and perplexity is 92.90669028911441
At time: 124.42669796943665 and batch: 1250, loss is 4.522315235137939 and perplexity is 92.04846530538103
At time: 125.57922601699829 and batch: 1300, loss is 4.510188570022583 and perplexity is 90.93896525652973
At time: 126.72625160217285 and batch: 1350, loss is 4.390057220458984 and perplexity is 80.64503339428191
At time: 127.87722396850586 and batch: 1400, loss is 4.405597429275513 and perplexity is 81.90806250313399
At time: 129.0285017490387 and batch: 1450, loss is 4.356609249114991 and perplexity is 77.99223333588031
At time: 130.1749289035797 and batch: 1500, loss is 4.355633568763733 and perplexity is 77.91617495663056
At time: 131.32554936408997 and batch: 1550, loss is 4.364798603057861 and perplexity is 78.63356178805897
At time: 132.47552800178528 and batch: 1600, loss is 4.427088975906372 and perplexity is 83.68744580859375
At time: 133.63318634033203 and batch: 1650, loss is 4.400454177856445 and perplexity is 81.48787024791773
At time: 134.78114914894104 and batch: 1700, loss is 4.409856605529785 and perplexity is 82.25766736383848
At time: 135.93384265899658 and batch: 1750, loss is 4.403009223937988 and perplexity is 81.69634172519052
At time: 137.08748531341553 and batch: 1800, loss is 4.351677808761597 and perplexity is 77.60856608278023
At time: 138.23789048194885 and batch: 1850, loss is 4.39944465637207 and perplexity is 81.40564800173148
At time: 139.3885109424591 and batch: 1900, loss is 4.504767036437988 and perplexity is 90.44727067594948
At time: 140.53740239143372 and batch: 1950, loss is 4.423645763397217 and perplexity is 83.39978766658213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457215491006541 and perplexity of 86.24701882847219
finished 3 epochs...
Completing Train Step...
At time: 144.23375725746155 and batch: 50, loss is 4.395840911865235 and perplexity is 81.11281081704006
At time: 145.39071202278137 and batch: 100, loss is 4.348112335205078 and perplexity is 77.33234751028212
At time: 146.51743578910828 and batch: 150, loss is 4.296965055465698 and perplexity is 73.4764579906992
At time: 147.66238570213318 and batch: 200, loss is 4.289788227081299 and perplexity is 72.95101781370752
At time: 148.78288578987122 and batch: 250, loss is 4.2965806865692135 and perplexity is 73.44822135261408
At time: 149.915673494339 and batch: 300, loss is 4.309648084640503 and perplexity is 74.41429679789779
At time: 151.0501434803009 and batch: 350, loss is 4.318206090927124 and perplexity is 75.05386763987072
At time: 152.1959924697876 and batch: 400, loss is 4.256897320747376 and perplexity is 70.59062326586175
At time: 153.34623098373413 and batch: 450, loss is 4.2885000514984135 and perplexity is 72.85710459515737
At time: 154.49008131027222 and batch: 500, loss is 4.295724973678589 and perplexity is 73.38539764617046
At time: 155.63371109962463 and batch: 550, loss is 4.266418991088867 and perplexity is 71.26597404113161
At time: 156.7773838043213 and batch: 600, loss is 4.244224429130554 and perplexity is 69.70168058233658
At time: 157.92070412635803 and batch: 650, loss is 4.297449321746826 and perplexity is 73.51204877877456
At time: 159.06515550613403 and batch: 700, loss is 4.339925661087036 and perplexity is 76.70183719515322
At time: 160.21674227714539 and batch: 750, loss is 4.295319156646729 and perplexity is 73.35562264392593
At time: 161.36676216125488 and batch: 800, loss is 4.293179292678833 and perplexity is 73.19881941880709
At time: 162.51600313186646 and batch: 850, loss is 4.287140350341797 and perplexity is 72.75810802389981
At time: 163.6592357158661 and batch: 900, loss is 4.259125599861145 and perplexity is 70.74809425681649
At time: 164.80295610427856 and batch: 950, loss is 4.332403545379639 and perplexity is 76.12704165036433
At time: 165.94698882102966 and batch: 1000, loss is 4.305964670181274 and perplexity is 74.14070229141335
At time: 167.09107971191406 and batch: 1050, loss is 4.2610587215423585 and perplexity is 70.8849912083299
At time: 168.242351770401 and batch: 1100, loss is 4.295263953208924 and perplexity is 73.35157327314428
At time: 169.39337825775146 and batch: 1150, loss is 4.262364172935486 and perplexity is 70.97758854636623
At time: 170.54649996757507 and batch: 1200, loss is 4.319204616546631 and perplexity is 75.1288482783665
At time: 171.6988787651062 and batch: 1250, loss is 4.317359027862548 and perplexity is 74.99031919930763
At time: 172.85042929649353 and batch: 1300, loss is 4.304177007675171 and perplexity is 74.00828213429078
At time: 174.00253701210022 and batch: 1350, loss is 4.185319714546203 and perplexity is 65.71450744243877
At time: 175.15332651138306 and batch: 1400, loss is 4.20495614528656 and perplexity is 67.01765856164673
At time: 176.30494856834412 and batch: 1450, loss is 4.1517491006851195 and perplexity is 63.54504984160929
At time: 177.45453310012817 and batch: 1500, loss is 4.152263345718384 and perplexity is 63.577735971498555
At time: 178.60493755340576 and batch: 1550, loss is 4.165538768768311 and perplexity is 64.42738455703878
At time: 179.75547337532043 and batch: 1600, loss is 4.2326371431350704 and perplexity is 68.89868850893711
At time: 180.9058427810669 and batch: 1650, loss is 4.202315826416015 and perplexity is 66.84094396718653
At time: 182.0557940006256 and batch: 1700, loss is 4.213586735725403 and perplexity is 67.59856369618919
At time: 183.20801281929016 and batch: 1750, loss is 4.206246247291565 and perplexity is 67.10417397218075
At time: 184.35943818092346 and batch: 1800, loss is 4.158619103431701 and perplexity is 63.98310751434655
At time: 185.5096127986908 and batch: 1850, loss is 4.209503803253174 and perplexity is 67.32312600478167
At time: 186.66164803504944 and batch: 1900, loss is 4.313205671310425 and perplexity is 74.67950357657388
At time: 187.81258249282837 and batch: 1950, loss is 4.232595982551575 and perplexity is 68.89585265707908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421188567405523 and perplexity of 83.19510961265051
finished 4 epochs...
Completing Train Step...
At time: 191.5302610397339 and batch: 50, loss is 4.213494920730591 and perplexity is 67.59235741933317
At time: 192.6529619693756 and batch: 100, loss is 4.170857610702515 and perplexity is 64.7709765775352
At time: 193.78070306777954 and batch: 150, loss is 4.127163324356079 and perplexity is 62.00179426324348
At time: 194.90435028076172 and batch: 200, loss is 4.120888285636902 and perplexity is 61.61394874904563
At time: 196.02761006355286 and batch: 250, loss is 4.120471611022949 and perplexity is 61.5882811286308
At time: 197.15540266036987 and batch: 300, loss is 4.136345610618592 and perplexity is 62.5737343270949
At time: 198.29164290428162 and batch: 350, loss is 4.149881792068482 and perplexity is 63.426502339327975
At time: 199.4363923072815 and batch: 400, loss is 4.084054131507873 and perplexity is 59.38574007720846
At time: 200.5856056213379 and batch: 450, loss is 4.124968619346618 and perplexity is 61.86586782855203
At time: 201.73287987709045 and batch: 500, loss is 4.1381922578811645 and perplexity is 62.68939269954015
At time: 202.87804508209229 and batch: 550, loss is 4.1066819190979 and perplexity is 60.74482656058872
At time: 204.02353024482727 and batch: 600, loss is 4.088750929832458 and perplexity is 59.66531897058933
At time: 205.19311714172363 and batch: 650, loss is 4.139171180725097 and perplexity is 62.75079082523681
At time: 206.3389654159546 and batch: 700, loss is 4.184143695831299 and perplexity is 65.63727137627697
At time: 207.4852728843689 and batch: 750, loss is 4.141470432281494 and perplexity is 62.895236673742765
At time: 208.63090443611145 and batch: 800, loss is 4.137038826942444 and perplexity is 62.617126499518285
At time: 209.77612137794495 and batch: 850, loss is 4.13068274974823 and perplexity is 62.220389391321596
At time: 210.92936372756958 and batch: 900, loss is 4.100815548896789 and perplexity is 60.38951812456634
At time: 212.08252120018005 and batch: 950, loss is 4.182914566993714 and perplexity is 65.55664427390694
At time: 213.23643350601196 and batch: 1000, loss is 4.1531750679016115 and perplexity is 63.63572763586949
At time: 214.39201641082764 and batch: 1050, loss is 4.117998266220093 and perplexity is 61.436140299508274
At time: 215.54588794708252 and batch: 1100, loss is 4.148814473152161 and perplexity is 63.358842147509485
At time: 216.70014476776123 and batch: 1150, loss is 4.115572047233582 and perplexity is 61.28726344641022
At time: 217.85513973236084 and batch: 1200, loss is 4.170548882484436 and perplexity is 64.75098303579723
At time: 219.00931978225708 and batch: 1250, loss is 4.171985831260681 and perplexity is 64.84409376328273
At time: 220.1625473499298 and batch: 1300, loss is 4.159033088684082 and perplexity is 64.00960106084939
At time: 221.32029676437378 and batch: 1350, loss is 4.0410540628433225 and perplexity is 56.88627292144763
At time: 222.47454190254211 and batch: 1400, loss is 4.064353461265564 and perplexity is 58.22725017743498
At time: 223.62887334823608 and batch: 1450, loss is 4.0092020606994625 and perplexity is 55.10288425967368
At time: 224.7796928882599 and batch: 1500, loss is 4.012235226631165 and perplexity is 55.27027418332194
At time: 225.93195390701294 and batch: 1550, loss is 4.0234816360473635 and perplexity is 55.8953747954016
At time: 227.08514547348022 and batch: 1600, loss is 4.096786971092224 and perplexity is 60.146723638827595
At time: 228.2396821975708 and batch: 1650, loss is 4.060571908950806 and perplexity is 58.00747658930427
At time: 229.40159702301025 and batch: 1700, loss is 4.073377637863159 and perplexity is 58.755081204005236
At time: 230.5568552017212 and batch: 1750, loss is 4.065590357780456 and perplexity is 58.299315819934385
At time: 231.71250796318054 and batch: 1800, loss is 4.0204656267166134 and perplexity is 55.727047788980116
At time: 232.8672435283661 and batch: 1850, loss is 4.070872898101807 and perplexity is 58.60809916864983
At time: 234.02380537986755 and batch: 1900, loss is 4.170683279037475 and perplexity is 64.75968592952951
At time: 235.178560256958 and batch: 1950, loss is 4.0956672668457035 and perplexity is 60.07941478699081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.420336346293604 and perplexity of 83.12423918675609
finished 5 epochs...
Completing Train Step...
At time: 238.89077138900757 and batch: 50, loss is 4.080637545585632 and perplexity is 59.183189805913266
At time: 240.02349090576172 and batch: 100, loss is 4.0409601783752445 and perplexity is 56.880932434671756
At time: 241.14744806289673 and batch: 150, loss is 3.9995743799209595 and perplexity is 54.574916908804504
At time: 242.27464985847473 and batch: 200, loss is 3.9929168891906737 and perplexity is 54.212791665617
At time: 243.39814710617065 and batch: 250, loss is 3.987547197341919 and perplexity is 53.922465857768124
At time: 244.53087401390076 and batch: 300, loss is 4.006090316772461 and perplexity is 54.93168469696121
At time: 245.67107510566711 and batch: 350, loss is 4.0190823364257815 and perplexity is 55.65001439689213
At time: 246.8222906589508 and batch: 400, loss is 3.960619764328003 and perplexity is 52.489847205180965
At time: 247.97234535217285 and batch: 450, loss is 4.001138219833374 and perplexity is 54.6603301109633
At time: 249.12875699996948 and batch: 500, loss is 4.017511558532715 and perplexity is 55.56266920243813
At time: 250.27714896202087 and batch: 550, loss is 3.982723832130432 and perplexity is 53.663004353656106
At time: 251.42751240730286 and batch: 600, loss is 3.9711488246917725 and perplexity is 53.04543575482344
At time: 252.57876634597778 and batch: 650, loss is 4.019107007980347 and perplexity is 55.651387386195715
At time: 253.7341058254242 and batch: 700, loss is 4.065213503837586 and perplexity is 58.277349632183196
At time: 254.89161705970764 and batch: 750, loss is 4.024559960365296 and perplexity is 55.95568064609252
At time: 256.0487906932831 and batch: 800, loss is 4.019107503890991 and perplexity is 55.651414984317924
At time: 257.20513010025024 and batch: 850, loss is 4.014433035850525 and perplexity is 55.39188128713497
At time: 258.36123275756836 and batch: 900, loss is 3.9831321954727175 and perplexity is 53.68492283251808
At time: 259.515921831131 and batch: 950, loss is 4.068579950332642 and perplexity is 58.473867809964624
At time: 260.67898535728455 and batch: 1000, loss is 4.039583759307861 and perplexity is 56.802694291286365
At time: 261.8677885532379 and batch: 1050, loss is 4.008495073318482 and perplexity is 55.063940983670896
At time: 263.0264313220978 and batch: 1100, loss is 4.034822878837585 and perplexity is 56.53290617744126
At time: 264.18249702453613 and batch: 1150, loss is 4.002222986221313 and perplexity is 54.71965597135351
At time: 265.34394216537476 and batch: 1200, loss is 4.05852475643158 and perplexity is 57.88884790440554
At time: 266.5001006126404 and batch: 1250, loss is 4.058119068145752 and perplexity is 57.8653678400462
At time: 267.6588888168335 and batch: 1300, loss is 4.045921092033386 and perplexity is 57.16381492692422
At time: 268.81569933891296 and batch: 1350, loss is 3.932593092918396 and perplexity is 51.03915549311688
At time: 269.97460103034973 and batch: 1400, loss is 3.9587997341156007 and perplexity is 52.39440098127595
At time: 271.1304597854614 and batch: 1450, loss is 3.8994569253921507 and perplexity is 49.37562717366967
At time: 272.28501534461975 and batch: 1500, loss is 3.9041114711761473 and perplexity is 49.60598397822383
At time: 273.44077825546265 and batch: 1550, loss is 3.913261470794678 and perplexity is 50.061961629072705
At time: 274.6036922931671 and batch: 1600, loss is 3.9877719640731812 and perplexity is 53.93458719634637
At time: 275.7616837024689 and batch: 1650, loss is 3.949069595336914 and perplexity is 51.88706839937816
At time: 276.91462421417236 and batch: 1700, loss is 3.967097806930542 and perplexity is 52.83098242283501
At time: 278.0688805580139 and batch: 1750, loss is 3.956088819503784 and perplexity is 52.252556584970264
At time: 279.22345757484436 and batch: 1800, loss is 3.9102611923217774 and perplexity is 49.91198689876516
At time: 280.378103017807 and batch: 1850, loss is 3.958375210762024 and perplexity is 52.37216305505623
At time: 281.53364062309265 and batch: 1900, loss is 4.064345192909241 and perplexity is 58.22676873577317
At time: 282.69865918159485 and batch: 1950, loss is 3.9869920206069946 and perplexity is 53.89253766772027
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416659474927326 and perplexity of 82.81916325802321
finished 6 epochs...
Completing Train Step...
At time: 286.3846879005432 and batch: 50, loss is 3.976527714729309 and perplexity is 53.33153006587762
At time: 287.5088973045349 and batch: 100, loss is 3.9391423320770262 and perplexity is 51.37452012175596
At time: 288.63441467285156 and batch: 150, loss is 3.90348445892334 and perplexity is 49.57489016757575
At time: 289.7549810409546 and batch: 200, loss is 3.8927443981170655 and perplexity is 49.04530182880182
At time: 290.9163691997528 and batch: 250, loss is 3.8881300258636475 and perplexity is 48.81950989354117
At time: 292.0512385368347 and batch: 300, loss is 3.903953652381897 and perplexity is 49.598155839374755
At time: 293.18814516067505 and batch: 350, loss is 3.9175593709945677 and perplexity is 50.27758597801471
At time: 294.3373649120331 and batch: 400, loss is 3.8586613512039185 and perplexity is 47.40185444291186
At time: 295.4760982990265 and batch: 450, loss is 3.902056031227112 and perplexity is 49.50412657379375
At time: 296.62167596817017 and batch: 500, loss is 3.921733021736145 and perplexity is 50.48786557356694
At time: 297.77096915245056 and batch: 550, loss is 3.8844363260269166 and perplexity is 48.6395179006576
At time: 298.91978931427 and batch: 600, loss is 3.8788502740859987 and perplexity is 48.368572489401025
At time: 300.0655357837677 and batch: 650, loss is 3.923561010360718 and perplexity is 50.58024122260911
At time: 301.21523356437683 and batch: 700, loss is 3.9700736474990843 and perplexity is 52.988433161559016
At time: 302.3616461753845 and batch: 750, loss is 3.932691206932068 and perplexity is 51.04416339518542
At time: 303.50650930404663 and batch: 800, loss is 3.9288389396667482 and perplexity is 50.84790589632617
At time: 304.65314197540283 and batch: 850, loss is 3.922433919906616 and perplexity is 50.52326483036642
At time: 305.80742383003235 and batch: 900, loss is 3.8896118783950806 and perplexity is 48.891906835408065
At time: 306.9532837867737 and batch: 950, loss is 3.9793364572525025 and perplexity is 53.48153516643667
At time: 308.1048254966736 and batch: 1000, loss is 3.9467680311203 and perplexity is 51.767784302106044
At time: 309.25995087623596 and batch: 1050, loss is 3.9146170616149902 and perplexity is 50.12987118308856
At time: 310.41223669052124 and batch: 1100, loss is 3.9425354385375977 and perplexity is 51.54913541449751
At time: 311.56702613830566 and batch: 1150, loss is 3.9108576917648317 and perplexity is 49.94176825254943
At time: 312.72059297561646 and batch: 1200, loss is 3.964429340362549 and perplexity is 52.690192642440124
At time: 313.8818061351776 and batch: 1250, loss is 3.9667757320404053 and perplexity is 52.813969629819155
At time: 315.03628516197205 and batch: 1300, loss is 3.953568959236145 and perplexity is 52.12105319841251
At time: 316.19074964523315 and batch: 1350, loss is 3.8437074565887452 and perplexity is 46.698285763842186
At time: 317.3438866138458 and batch: 1400, loss is 3.8706654024124147 and perplexity is 47.97429767602313
At time: 318.5023293495178 and batch: 1450, loss is 3.811710386276245 and perplexity is 45.22772963701651
At time: 319.66798734664917 and batch: 1500, loss is 3.816012258529663 and perplexity is 45.422712647530595
At time: 320.8219106197357 and batch: 1550, loss is 3.823898882865906 and perplexity is 45.78236085954548
At time: 321.97739911079407 and batch: 1600, loss is 3.901654419898987 and perplexity is 49.48424914753973
At time: 323.1339440345764 and batch: 1650, loss is 3.86353009223938 and perplexity is 47.63320453162459
At time: 324.29051423072815 and batch: 1700, loss is 3.884246006011963 and perplexity is 48.630261707730746
At time: 325.44588017463684 and batch: 1750, loss is 3.8658834648132325 and perplexity is 47.74543521728497
At time: 326.6011497974396 and batch: 1800, loss is 3.8238899230957033 and perplexity is 45.78195066195048
At time: 327.75638699531555 and batch: 1850, loss is 3.87121196269989 and perplexity is 48.00052568889458
At time: 328.91166162490845 and batch: 1900, loss is 3.977480025291443 and perplexity is 53.38234243599238
At time: 330.06828474998474 and batch: 1950, loss is 3.8986612510681153 and perplexity is 49.33635588054613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425799418604651 and perplexity of 83.57959560624272
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 333.7794280052185 and batch: 50, loss is 3.9353233671188352 and perplexity is 51.178696788888814
At time: 334.9234745502472 and batch: 100, loss is 3.938614220619202 and perplexity is 51.34739581199923
At time: 336.04180550575256 and batch: 150, loss is 3.910244688987732 and perplexity is 49.91116319136947
At time: 337.16278982162476 and batch: 200, loss is 3.902439079284668 and perplexity is 49.52309266554925
At time: 338.2979505062103 and batch: 250, loss is 3.882804608345032 and perplexity is 48.56021665547771
At time: 339.4423243999481 and batch: 300, loss is 3.8998757648468017 and perplexity is 49.39631196592931
At time: 340.5860755443573 and batch: 350, loss is 3.912638101577759 and perplexity is 50.03076426800209
At time: 341.74100852012634 and batch: 400, loss is 3.8434367847442625 and perplexity is 46.68564756318001
At time: 342.89096784591675 and batch: 450, loss is 3.88229097366333 and perplexity is 48.535280848548354
At time: 344.04249143600464 and batch: 500, loss is 3.8942239904403686 and perplexity is 49.117922592195406
At time: 345.19364953041077 and batch: 550, loss is 3.854504871368408 and perplexity is 47.20523848894477
At time: 346.34552216529846 and batch: 600, loss is 3.8342954683303834 and perplexity is 46.26082396858124
At time: 347.497407913208 and batch: 650, loss is 3.8757612800598142 and perplexity is 48.219392784156625
At time: 348.6881814002991 and batch: 700, loss is 3.921044931411743 and perplexity is 50.45313731122694
At time: 349.83024311065674 and batch: 750, loss is 3.8696938037872313 and perplexity is 47.92770855098691
At time: 350.9764316082001 and batch: 800, loss is 3.855462894439697 and perplexity is 47.25048386609993
At time: 352.1212480068207 and batch: 850, loss is 3.8514031982421875 and perplexity is 47.059050100803134
At time: 353.2618851661682 and batch: 900, loss is 3.811089038848877 and perplexity is 45.19963623234705
At time: 354.4053840637207 and batch: 950, loss is 3.9008749771118163 and perplexity is 49.44569403416759
At time: 355.54960083961487 and batch: 1000, loss is 3.8571326112747193 and perplexity is 47.3294446972437
At time: 356.70071840286255 and batch: 1050, loss is 3.8186597871780394 and perplexity is 45.54312991429585
At time: 357.8451340198517 and batch: 1100, loss is 3.8374489307403565 and perplexity is 46.406935996332024
At time: 358.98913979530334 and batch: 1150, loss is 3.807769274711609 and perplexity is 45.04983289441958
At time: 360.13256072998047 and batch: 1200, loss is 3.8360055351257323 and perplexity is 46.34000074707041
At time: 361.2855727672577 and batch: 1250, loss is 3.8288438177108763 and perplexity is 46.009312318675605
At time: 362.4298691749573 and batch: 1300, loss is 3.8174206447601318 and perplexity is 45.48673044088135
At time: 363.57337975502014 and batch: 1350, loss is 3.7044109439849855 and perplexity is 40.62610921313033
At time: 364.7188742160797 and batch: 1400, loss is 3.717846164703369 and perplexity is 41.17561304430189
At time: 365.8698012828827 and batch: 1450, loss is 3.6586172914505006 and perplexity is 38.8076460923521
At time: 367.02194237709045 and batch: 1500, loss is 3.6477700519561767 and perplexity is 38.38896513254838
At time: 368.174777507782 and batch: 1550, loss is 3.6528548765182496 and perplexity is 38.58466340941415
At time: 369.3255307674408 and batch: 1600, loss is 3.727770142555237 and perplexity is 41.58627323719167
At time: 370.47652316093445 and batch: 1650, loss is 3.683103156089783 and perplexity is 39.76961410839938
At time: 371.6351566314697 and batch: 1700, loss is 3.6832592916488647 and perplexity is 39.77582404411594
At time: 372.78594946861267 and batch: 1750, loss is 3.6502664422988893 and perplexity is 38.48491869331163
At time: 373.938294172287 and batch: 1800, loss is 3.601488513946533 and perplexity is 36.652751991064605
At time: 375.0955021381378 and batch: 1850, loss is 3.6446164321899412 and perplexity is 38.26809162801471
At time: 376.24748373031616 and batch: 1900, loss is 3.7323440742492675 and perplexity is 41.77692168449845
At time: 377.40785479545593 and batch: 1950, loss is 3.6517509841918945 and perplexity is 38.5420935961295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367310138081395 and perplexity of 78.83130094297975
finished 8 epochs...
Completing Train Step...
At time: 381.0593433380127 and batch: 50, loss is 3.8587256813049318 and perplexity is 47.40490390708151
At time: 382.21610283851624 and batch: 100, loss is 3.8441306257247927 and perplexity is 46.71805121885408
At time: 383.33851766586304 and batch: 150, loss is 3.803776216506958 and perplexity is 44.87030496084684
At time: 384.46737575531006 and batch: 200, loss is 3.793307728767395 and perplexity is 44.40303081765679
At time: 385.6154923439026 and batch: 250, loss is 3.7715496110916136 and perplexity is 43.44733917654631
At time: 386.76365184783936 and batch: 300, loss is 3.7868052339553833 and perplexity is 44.11523704294207
At time: 387.91851592063904 and batch: 350, loss is 3.801575927734375 and perplexity is 44.77168586764766
At time: 389.06549286842346 and batch: 400, loss is 3.739071092605591 and perplexity is 42.05890318754464
At time: 390.2111496925354 and batch: 450, loss is 3.779453492164612 and perplexity is 43.792102467544396
At time: 391.35711002349854 and batch: 500, loss is 3.7960576009750366 and perplexity is 44.52530151538524
At time: 392.50578808784485 and batch: 550, loss is 3.759634757041931 and perplexity is 42.93274223297734
At time: 393.6592733860016 and batch: 600, loss is 3.744328556060791 and perplexity is 42.28060862746473
At time: 394.81429171562195 and batch: 650, loss is 3.787101078033447 and perplexity is 44.128290205328796
At time: 395.96626257896423 and batch: 700, loss is 3.833734087944031 and perplexity is 46.23486133748656
At time: 397.1198356151581 and batch: 750, loss is 3.783480443954468 and perplexity is 43.968806703886756
At time: 398.27313208580017 and batch: 800, loss is 3.7720132303237914 and perplexity is 43.46748686864339
At time: 399.4266085624695 and batch: 850, loss is 3.768201484680176 and perplexity is 43.302115242450014
At time: 400.5805265903473 and batch: 900, loss is 3.731786012649536 and perplexity is 41.75361409289217
At time: 401.73784136772156 and batch: 950, loss is 3.8249877166748045 and perplexity is 45.83223739059956
At time: 402.8925814628601 and batch: 1000, loss is 3.7850427770614625 and perplexity is 44.03755431562646
At time: 404.0469114780426 and batch: 1050, loss is 3.750144386291504 and perplexity is 42.52722190465186
At time: 405.1998841762543 and batch: 1100, loss is 3.769025750160217 and perplexity is 43.33782239532222
At time: 406.3913085460663 and batch: 1150, loss is 3.7444538068771362 and perplexity is 42.2859046398689
At time: 407.5427498817444 and batch: 1200, loss is 3.773803849220276 and perplexity is 43.54539029887496
At time: 408.692302942276 and batch: 1250, loss is 3.7720317316055296 and perplexity is 43.46829108030385
At time: 409.8405222892761 and batch: 1300, loss is 3.761452012062073 and perplexity is 43.01083290817378
At time: 410.98635601997375 and batch: 1350, loss is 3.6513117742538452 and perplexity is 38.52516924253307
At time: 412.1333546638489 and batch: 1400, loss is 3.6693429946899414 and perplexity is 39.22612561952925
At time: 413.27957248687744 and batch: 1450, loss is 3.611088171005249 and perplexity is 37.00630009566468
At time: 414.4261691570282 and batch: 1500, loss is 3.601615719795227 and perplexity is 36.65741473204628
At time: 415.57540249824524 and batch: 1550, loss is 3.6124829864501953 and perplexity is 37.05795306940691
At time: 416.7289123535156 and batch: 1600, loss is 3.6919912672042847 and perplexity is 40.124666392270306
At time: 417.88024377822876 and batch: 1650, loss is 3.648727087974548 and perplexity is 38.42572234106893
At time: 419.03958916664124 and batch: 1700, loss is 3.653748950958252 and perplexity is 38.61917639703559
At time: 420.19317984580994 and batch: 1750, loss is 3.6242350816726683 and perplexity is 37.4960307861883
At time: 421.3469274044037 and batch: 1800, loss is 3.577874975204468 and perplexity is 35.79738962353485
At time: 422.50115394592285 and batch: 1850, loss is 3.6257618713378905 and perplexity is 37.55332306397889
At time: 423.65457248687744 and batch: 1900, loss is 3.716613335609436 and perplexity is 41.12488182846517
At time: 424.8104546070099 and batch: 1950, loss is 3.639198422431946 and perplexity is 38.06131539779396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373588526526163 and perplexity of 79.32779142105232
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 428.4834005832672 and batch: 50, loss is 3.8349919223785403 and perplexity is 46.29305372867593
At time: 429.6327540874481 and batch: 100, loss is 3.8587542152404786 and perplexity is 47.40625657485257
At time: 430.7617201805115 and batch: 150, loss is 3.834405207633972 and perplexity is 46.265900877750134
At time: 431.88713335990906 and batch: 200, loss is 3.837100796699524 and perplexity is 46.39078297405256
At time: 433.02572536468506 and batch: 250, loss is 3.8215662908554076 and perplexity is 45.675693744177806
At time: 434.19759917259216 and batch: 300, loss is 3.830792589187622 and perplexity is 46.09906137598499
At time: 435.3426697254181 and batch: 350, loss is 3.846420841217041 and perplexity is 46.8251682372308
At time: 436.48251938819885 and batch: 400, loss is 3.788050012588501 and perplexity is 44.17018493929668
At time: 437.62772941589355 and batch: 450, loss is 3.8249776363372803 and perplexity is 45.83177538850574
At time: 438.77211141586304 and batch: 500, loss is 3.8335804557800293 and perplexity is 46.22775872129608
At time: 439.9156243801117 and batch: 550, loss is 3.8043283128738405 and perplexity is 44.89508453292306
At time: 441.0672986507416 and batch: 600, loss is 3.7780242443084715 and perplexity is 43.72955740582145
At time: 442.21505212783813 and batch: 650, loss is 3.8152483606338503 and perplexity is 45.38802758252779
At time: 443.36461329460144 and batch: 700, loss is 3.8647325801849366 and perplexity is 47.69051733795539
At time: 444.5119845867157 and batch: 750, loss is 3.806319990158081 and perplexity is 44.984590156532605
At time: 445.66243743896484 and batch: 800, loss is 3.7906497812271116 and perplexity is 44.285166598958426
At time: 446.81499767303467 and batch: 850, loss is 3.782568712234497 and perplexity is 43.92873721721222
At time: 447.96835947036743 and batch: 900, loss is 3.741338348388672 and perplexity is 42.15436966158929
At time: 449.1248564720154 and batch: 950, loss is 3.838088150024414 and perplexity is 46.436609687722395
At time: 450.28361535072327 and batch: 1000, loss is 3.7923500776290893 and perplexity is 44.360528559066424
At time: 451.4435987472534 and batch: 1050, loss is 3.751045880317688 and perplexity is 42.56557722709856
At time: 452.59950137138367 and batch: 1100, loss is 3.7698172998428343 and perplexity is 43.37214001514329
At time: 453.75244545936584 and batch: 1150, loss is 3.755488243103027 and perplexity is 42.75508959298724
At time: 454.9060182571411 and batch: 1200, loss is 3.772172660827637 and perplexity is 43.47441746443527
At time: 456.0590469837189 and batch: 1250, loss is 3.760603165626526 and perplexity is 42.97433880710487
At time: 457.2111701965332 and batch: 1300, loss is 3.7502243185043334 and perplexity is 42.530621335464396
At time: 458.3645706176758 and batch: 1350, loss is 3.633589172363281 and perplexity is 37.84841761843927
At time: 459.5182523727417 and batch: 1400, loss is 3.647112698554993 and perplexity is 38.36373830812839
At time: 460.6700904369354 and batch: 1450, loss is 3.584811315536499 and perplexity is 36.04655565214298
At time: 461.82522320747375 and batch: 1500, loss is 3.5697158861160276 and perplexity is 35.50650382772907
At time: 462.9787483215332 and batch: 1550, loss is 3.5767123699188232 and perplexity is 35.75579557256306
At time: 464.13361382484436 and batch: 1600, loss is 3.6566036319732667 and perplexity is 38.72957933432159
At time: 465.28551173210144 and batch: 1650, loss is 3.618169322013855 and perplexity is 37.26927728664785
At time: 466.438006401062 and batch: 1700, loss is 3.617382583618164 and perplexity is 37.2399676462483
At time: 467.5918972492218 and batch: 1750, loss is 3.586464138031006 and perplexity is 36.106183473702345
At time: 468.74761056900024 and batch: 1800, loss is 3.530464978218079 and perplexity is 34.1398382058633
At time: 469.9019863605499 and batch: 1850, loss is 3.5716137647628785 and perplexity is 35.57395484984911
At time: 471.0579741001129 and batch: 1900, loss is 3.660471410751343 and perplexity is 38.879666844893364
At time: 472.21238589286804 and batch: 1950, loss is 3.591769199371338 and perplexity is 36.29823797181578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346504530795785 and perplexity of 77.20811212084025
finished 10 epochs...
Completing Train Step...
At time: 475.9330983161926 and batch: 50, loss is 3.8271831941604613 and perplexity is 45.93297157526255
At time: 477.05416560173035 and batch: 100, loss is 3.8285008382797243 and perplexity is 45.9935347767497
At time: 478.1756012439728 and batch: 150, loss is 3.7923697233200073 and perplexity is 44.361400060860056
At time: 479.30088353157043 and batch: 200, loss is 3.7872067213058473 and perplexity is 44.1329523085671
At time: 480.4419560432434 and batch: 250, loss is 3.768528251647949 and perplexity is 43.31626725542521
At time: 481.5868785381317 and batch: 300, loss is 3.7754103708267213 and perplexity is 43.6154031327583
At time: 482.7304632663727 and batch: 350, loss is 3.7924044942855835 and perplexity is 44.36294257639171
At time: 483.87999176979065 and batch: 400, loss is 3.7333440256118773 and perplexity is 41.81871746765502
At time: 485.0253584384918 and batch: 450, loss is 3.7725902366638184 and perplexity is 43.49257512149605
At time: 486.1770861148834 and batch: 500, loss is 3.781846995353699 and perplexity is 43.89704454395471
At time: 487.3274209499359 and batch: 550, loss is 3.7551725482940674 and perplexity is 42.74159416347673
At time: 488.47230195999146 and batch: 600, loss is 3.731789507865906 and perplexity is 41.75376003106268
At time: 489.617463350296 and batch: 650, loss is 3.770933036804199 and perplexity is 43.4205589212103
At time: 490.7647478580475 and batch: 700, loss is 3.823334226608276 and perplexity is 45.75651686017172
At time: 491.9388542175293 and batch: 750, loss is 3.7662140989303587 and perplexity is 43.216142694285935
At time: 493.095538854599 and batch: 800, loss is 3.751506013870239 and perplexity is 42.585167584109094
At time: 494.248423576355 and batch: 850, loss is 3.745214958190918 and perplexity is 42.318102864045805
At time: 495.404061794281 and batch: 900, loss is 3.7053683185577393 and perplexity is 40.665022241280546
At time: 496.55633759498596 and batch: 950, loss is 3.804760389328003 and perplexity is 44.91448683319407
At time: 497.7126820087433 and batch: 1000, loss is 3.758675289154053 and perplexity is 42.89156940063007
At time: 498.8645136356354 and batch: 1050, loss is 3.719701657295227 and perplexity is 41.25208501391721
At time: 500.01606917381287 and batch: 1100, loss is 3.739218525886536 and perplexity is 42.06510452676519
At time: 501.1684970855713 and batch: 1150, loss is 3.7274164962768555 and perplexity is 41.57156900663103
At time: 502.3234043121338 and batch: 1200, loss is 3.7455068588256837 and perplexity is 42.33045734818705
At time: 503.47436571121216 and batch: 1250, loss is 3.737378649711609 and perplexity is 41.98778109773059
At time: 504.6251916885376 and batch: 1300, loss is 3.729583764076233 and perplexity is 41.66176343194156
At time: 505.7776052951813 and batch: 1350, loss is 3.6149891805648804 and perplexity is 37.15094397124414
At time: 506.92939949035645 and batch: 1400, loss is 3.6317659616470337 and perplexity is 37.779474845543206
At time: 508.07972717285156 and batch: 1450, loss is 3.5716495084762574 and perplexity is 35.57522641782016
At time: 509.2350845336914 and batch: 1500, loss is 3.5589039373397826 and perplexity is 35.12467719169964
At time: 510.3916313648224 and batch: 1550, loss is 3.5686281967163085 and perplexity is 35.46790477558993
At time: 511.54372382164 and batch: 1600, loss is 3.6514111137390137 and perplexity is 38.52899650310755
At time: 512.6954963207245 and batch: 1650, loss is 3.6145438957214355 and perplexity is 37.134404901545885
At time: 513.8476684093475 and batch: 1700, loss is 3.6159082317352294 and perplexity is 37.18510328445447
At time: 514.9993908405304 and batch: 1750, loss is 3.587462649345398 and perplexity is 36.14225391179369
At time: 516.1523535251617 and batch: 1800, loss is 3.532751159667969 and perplexity is 34.217977356776785
At time: 517.3058774471283 and batch: 1850, loss is 3.575330810546875 and perplexity is 35.70643092603523
At time: 518.4648683071136 and batch: 1900, loss is 3.664606223106384 and perplexity is 39.04075978675395
At time: 519.617951631546 and batch: 1950, loss is 3.596328716278076 and perplexity is 36.46411828119424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34658089571221 and perplexity of 77.21400833699886
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 523.3412473201752 and batch: 50, loss is 3.8224449825286864 and perplexity is 45.71584623418789
At time: 524.4678745269775 and batch: 100, loss is 3.8424117851257322 and perplexity is 46.63781930839583
At time: 525.5889613628387 and batch: 150, loss is 3.8168189096450806 and perplexity is 45.45936771128947
At time: 526.7110679149628 and batch: 200, loss is 3.8217800664901733 and perplexity is 45.68545913836582
At time: 527.8373353481293 and batch: 250, loss is 3.815763974189758 and perplexity is 45.41143629923248
At time: 528.9804065227509 and batch: 300, loss is 3.8171116876602174 and perplexity is 45.472679163292504
At time: 530.1311876773834 and batch: 350, loss is 3.834567484855652 and perplexity is 46.27340938881677
At time: 531.2842004299164 and batch: 400, loss is 3.7825656604766844 and perplexity is 43.92860315754978
At time: 532.4303958415985 and batch: 450, loss is 3.82216046333313 and perplexity is 45.70284104859336
At time: 533.5770516395569 and batch: 500, loss is 3.8289640140533447 and perplexity is 46.01484280210108
At time: 534.7234528064728 and batch: 550, loss is 3.806319246292114 and perplexity is 44.98455669403939
At time: 535.8776912689209 and batch: 600, loss is 3.775242319107056 and perplexity is 43.60807410510304
At time: 537.0237300395966 and batch: 650, loss is 3.8002749633789064 and perplexity is 44.7134773719985
At time: 538.1757814884186 and batch: 700, loss is 3.8521569967269897 and perplexity is 47.09453651458751
At time: 539.3303916454315 and batch: 750, loss is 3.795142593383789 and perplexity is 44.484579159969435
At time: 540.487372636795 and batch: 800, loss is 3.7813862895965578 and perplexity is 43.87682558066585
At time: 541.644847869873 and batch: 850, loss is 3.7787452363967895 and perplexity is 43.76109743942776
At time: 542.7981331348419 and batch: 900, loss is 3.7261931037902833 and perplexity is 41.52074175862935
At time: 543.9516308307648 and batch: 950, loss is 3.832438826560974 and perplexity is 46.17501387446617
At time: 545.1058533191681 and batch: 1000, loss is 3.788482813835144 and perplexity is 44.18930598791122
At time: 546.2596924304962 and batch: 1050, loss is 3.744771647453308 and perplexity is 42.299346952306585
At time: 547.4123969078064 and batch: 1100, loss is 3.7596177291870116 and perplexity is 42.9320111866954
At time: 548.5895886421204 and batch: 1150, loss is 3.7519342708587646 and perplexity is 42.60340888543811
At time: 549.7425825595856 and batch: 1200, loss is 3.7654833936691285 and perplexity is 43.18457596584096
At time: 550.8978018760681 and batch: 1250, loss is 3.7532992219924926 and perplexity is 42.66160016178664
At time: 552.0584809780121 and batch: 1300, loss is 3.7420280265808104 and perplexity is 42.18345263884303
At time: 553.2200720310211 and batch: 1350, loss is 3.61881459236145 and perplexity is 37.29333380680207
At time: 554.375462770462 and batch: 1400, loss is 3.6352006483078 and perplexity is 37.90945860279891
At time: 555.5347938537598 and batch: 1450, loss is 3.5629129791259766 and perplexity is 35.2657761370884
At time: 556.6900081634521 and batch: 1500, loss is 3.5558661794662476 and perplexity is 35.01813882780979
At time: 557.852475643158 and batch: 1550, loss is 3.5588230991363528 and perplexity is 35.12183789066295
At time: 559.0114843845367 and batch: 1600, loss is 3.6376061153411867 and perplexity is 38.00075832092879
At time: 560.1653175354004 and batch: 1650, loss is 3.5974920177459717 and perplexity is 36.506561725990636
At time: 561.3177146911621 and batch: 1700, loss is 3.5981018590927123 and perplexity is 36.52883172665188
At time: 562.4767389297485 and batch: 1750, loss is 3.5777215909957887 and perplexity is 35.79189929033063
At time: 563.6302626132965 and batch: 1800, loss is 3.526146426200867 and perplexity is 33.99272143307261
At time: 564.7851023674011 and batch: 1850, loss is 3.561885266304016 and perplexity is 35.229551664141916
At time: 565.9384407997131 and batch: 1900, loss is 3.658046522140503 and perplexity is 38.785502199097834
At time: 567.0925512313843 and batch: 1950, loss is 3.5932073831558227 and perplexity is 36.35047906621514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327528842659884 and perplexity of 75.75684797850127
finished 12 epochs...
Completing Train Step...
At time: 570.7757682800293 and batch: 50, loss is 3.8293309879302977 and perplexity is 46.03173214614604
At time: 571.9052772521973 and batch: 100, loss is 3.827936096191406 and perplexity is 45.96756762493266
At time: 573.0256407260895 and batch: 150, loss is 3.7944147300720217 and perplexity is 44.452212247632445
At time: 574.1478841304779 and batch: 200, loss is 3.7914705657958985 and perplexity is 44.32153010158845
At time: 575.2839765548706 and batch: 250, loss is 3.7861225938797 and perplexity is 44.08513249064427
At time: 576.4296255111694 and batch: 300, loss is 3.7881285619735716 and perplexity is 44.17365461643084
At time: 577.5981450080872 and batch: 350, loss is 3.8034982967376707 and perplexity is 44.85783634876141
At time: 578.743732213974 and batch: 400, loss is 3.7520150756835937 and perplexity is 42.60685158552173
At time: 579.8889310359955 and batch: 450, loss is 3.7943821811676024 and perplexity is 44.450765400371544
At time: 581.0346693992615 and batch: 500, loss is 3.8009244871139525 and perplexity is 44.74252927075558
At time: 582.1825988292694 and batch: 550, loss is 3.7788414096832277 and perplexity is 43.76530629037292
At time: 583.3269910812378 and batch: 600, loss is 3.7496086072921755 and perplexity is 42.50444281507939
At time: 584.4707911014557 and batch: 650, loss is 3.775297918319702 and perplexity is 43.610498747091775
At time: 585.6156613826752 and batch: 700, loss is 3.830312008857727 and perplexity is 46.07691239646931
At time: 586.7668538093567 and batch: 750, loss is 3.7756786823272703 and perplexity is 43.627107217119914
At time: 587.9203667640686 and batch: 800, loss is 3.762587685585022 and perplexity is 43.05970691951495
At time: 589.0728845596313 and batch: 850, loss is 3.759862289428711 and perplexity is 42.942511933708126
At time: 590.2264091968536 and batch: 900, loss is 3.7091915464401244 and perplexity is 40.82079146903783
At time: 591.3799073696136 and batch: 950, loss is 3.815586748123169 and perplexity is 45.40338892212255
At time: 592.5315449237823 and batch: 1000, loss is 3.772338409423828 and perplexity is 43.4816238853108
At time: 593.6850402355194 and batch: 1050, loss is 3.7297418212890623 and perplexity is 41.66834889457739
At time: 594.8380997180939 and batch: 1100, loss is 3.7447566270828245 and perplexity is 42.29871160521574
At time: 595.9910764694214 and batch: 1150, loss is 3.7379129266738893 and perplexity is 42.01022019568114
At time: 597.1441960334778 and batch: 1200, loss is 3.752765245437622 and perplexity is 42.638825948496084
At time: 598.2968854904175 and batch: 1250, loss is 3.7418970394134523 and perplexity is 42.17792750974089
At time: 599.4489634037018 and batch: 1300, loss is 3.7320434761047365 and perplexity is 41.7643655066323
At time: 600.6031472682953 and batch: 1350, loss is 3.6110873317718504 and perplexity is 37.0062690387547
At time: 601.7561848163605 and batch: 1400, loss is 3.629097032546997 and perplexity is 37.67877854116551
At time: 602.9111230373383 and batch: 1450, loss is 3.5604407024383544 and perplexity is 35.17869706700462
At time: 604.0647299289703 and batch: 1500, loss is 3.5551345491409303 and perplexity is 34.99252786552796
At time: 605.2179491519928 and batch: 1550, loss is 3.55993314743042 and perplexity is 35.1608464735979
At time: 606.3708608150482 and batch: 1600, loss is 3.6407148313522337 and perplexity is 38.11907569903079
At time: 607.5306077003479 and batch: 1650, loss is 3.6028742265701292 and perplexity is 36.70357737874591
At time: 608.6816148757935 and batch: 1700, loss is 3.6042309856414794 and perplexity is 36.75340908747279
At time: 609.8319554328918 and batch: 1750, loss is 3.5848292827606203 and perplexity is 36.04720331450551
At time: 610.9845068454742 and batch: 1800, loss is 3.5336748647689817 and perplexity is 34.24959927942481
At time: 612.1436831951141 and batch: 1850, loss is 3.5694722890853883 and perplexity is 35.49785560221204
At time: 613.2973229885101 and batch: 1900, loss is 3.6659201908111574 and perplexity is 39.09209180120273
At time: 614.4510962963104 and batch: 1950, loss is 3.600153660774231 and perplexity is 36.60385858881227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3257179437681685 and perplexity of 75.61978412830109
finished 13 epochs...
Completing Train Step...
At time: 618.1183226108551 and batch: 50, loss is 3.82442307472229 and perplexity is 45.806365891345514
At time: 619.2747111320496 and batch: 100, loss is 3.819965057373047 and perplexity is 45.60261481785065
At time: 620.3980047702789 and batch: 150, loss is 3.7853441524505613 and perplexity is 44.05082815079644
At time: 621.5308365821838 and batch: 200, loss is 3.7811049890518187 and perplexity is 43.86448474155235
At time: 622.6775217056274 and batch: 250, loss is 3.775066375732422 and perplexity is 43.60040222831144
At time: 623.8198800086975 and batch: 300, loss is 3.776574559211731 and perplexity is 43.666209246698564
At time: 624.9601354598999 and batch: 350, loss is 3.791658544540405 and perplexity is 44.32986239029361
At time: 626.1090106964111 and batch: 400, loss is 3.7397526025772097 and perplexity is 42.08757651893314
At time: 627.2624032497406 and batch: 450, loss is 3.7826963901519775 and perplexity is 43.93434630496836
At time: 628.4127492904663 and batch: 500, loss is 3.788935170173645 and perplexity is 44.20929982239675
At time: 629.5667667388916 and batch: 550, loss is 3.7672048902511595 and perplexity is 43.258982092333305
At time: 630.7233836650848 and batch: 600, loss is 3.7387527132034304 and perplexity is 42.04551463052575
At time: 631.8810429573059 and batch: 650, loss is 3.7648264026641844 and perplexity is 43.15621340587266
At time: 633.0408878326416 and batch: 700, loss is 3.8205050945281984 and perplexity is 45.62724857519778
At time: 634.2014787197113 and batch: 750, loss is 3.7663631296157836 and perplexity is 43.222583705595326
At time: 635.3832204341888 and batch: 800, loss is 3.753483061790466 and perplexity is 42.66944378270436
At time: 636.5443825721741 and batch: 850, loss is 3.750509009361267 and perplexity is 42.54273113819158
At time: 637.7058265209198 and batch: 900, loss is 3.700642910003662 and perplexity is 40.47331669756166
At time: 638.8651738166809 and batch: 950, loss is 3.807457933425903 and perplexity is 45.03580920471547
At time: 640.0259110927582 and batch: 1000, loss is 3.764413585662842 and perplexity is 43.13840146405432
At time: 641.1840102672577 and batch: 1050, loss is 3.7223240995407103 and perplexity is 41.360408197938916
At time: 642.3417031764984 and batch: 1100, loss is 3.737616858482361 and perplexity is 41.99778414681219
At time: 643.4965350627899 and batch: 1150, loss is 3.731309232711792 and perplexity is 41.73371155230742
At time: 644.6504473686218 and batch: 1200, loss is 3.746747875213623 and perplexity is 42.38302274998123
At time: 645.8070583343506 and batch: 1250, loss is 3.736377086639404 and perplexity is 41.945748739241985
At time: 646.9614036083221 and batch: 1300, loss is 3.7273398780822755 and perplexity is 41.568383990084556
At time: 648.1163082122803 and batch: 1350, loss is 3.6070252752304075 and perplexity is 36.85625237589144
At time: 649.2724778652191 and batch: 1400, loss is 3.6256206464767455 and perplexity is 37.54801997561641
At time: 650.4299161434174 and batch: 1450, loss is 3.5583326482772826 and perplexity is 35.104616578546214
At time: 651.585901260376 and batch: 1500, loss is 3.553761210441589 and perplexity is 34.94450425671064
At time: 652.7441201210022 and batch: 1550, loss is 3.55943302154541 and perplexity is 35.14326602072382
At time: 653.8975462913513 and batch: 1600, loss is 3.641050705909729 and perplexity is 38.13188107709328
At time: 655.0515813827515 and batch: 1650, loss is 3.604073362350464 and perplexity is 36.7476163507235
At time: 656.2086961269379 and batch: 1700, loss is 3.605616235733032 and perplexity is 36.80435703045035
At time: 657.3626613616943 and batch: 1750, loss is 3.5866710233688353 and perplexity is 36.1136540864215
At time: 658.5167765617371 and batch: 1800, loss is 3.535556664466858 and perplexity is 34.314110844886216
At time: 659.6726686954498 and batch: 1850, loss is 3.5713922595977783 and perplexity is 35.56607590775222
At time: 660.8273253440857 and batch: 1900, loss is 3.667785029411316 and perplexity is 39.1650602590065
At time: 661.982533454895 and batch: 1950, loss is 3.6015744495391844 and perplexity is 36.655901902372065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325461596111919 and perplexity of 75.6004016583052
finished 14 epochs...
Completing Train Step...
At time: 665.6625189781189 and batch: 50, loss is 3.8189387941360473 and perplexity is 45.55583853724607
At time: 666.813184261322 and batch: 100, loss is 3.813143277168274 and perplexity is 45.292582491316466
At time: 667.9336550235748 and batch: 150, loss is 3.778156065940857 and perplexity is 43.73532228742188
At time: 669.0543735027313 and batch: 200, loss is 3.7732990980148315 and perplexity is 43.52341625680871
At time: 670.1842474937439 and batch: 250, loss is 3.766916289329529 and perplexity is 43.24649931159031
At time: 671.3136632442474 and batch: 300, loss is 3.768115382194519 and perplexity is 43.29838698320194
At time: 672.4635479450226 and batch: 350, loss is 3.782999887466431 and perplexity is 43.947682284698836
At time: 673.6092247962952 and batch: 400, loss is 3.7308064842224122 and perplexity is 41.71273526520843
At time: 674.7523038387299 and batch: 450, loss is 3.774199433326721 and perplexity is 43.56261957077453
At time: 675.8965184688568 and batch: 500, loss is 3.7804270935058595 and perplexity is 43.83475927923785
At time: 677.0393507480621 and batch: 550, loss is 3.7589961957931517 and perplexity is 42.90533579875823
At time: 678.1938619613647 and batch: 600, loss is 3.730967631340027 and perplexity is 41.719457693899706
At time: 679.3381569385529 and batch: 650, loss is 3.7573388767242433 and perplexity is 42.83428685922473
At time: 680.4843339920044 and batch: 700, loss is 3.813432564735413 and perplexity is 45.305686967704474
At time: 681.6389038562775 and batch: 750, loss is 3.7595468235015868 and perplexity is 42.92896717093583
At time: 682.7934699058533 and batch: 800, loss is 3.7468347358703613 and perplexity is 42.386704327061636
At time: 683.9457652568817 and batch: 850, loss is 3.743749599456787 and perplexity is 42.25613707454569
At time: 685.0987708568573 and batch: 900, loss is 3.694322233200073 and perplexity is 40.218304716700224
At time: 686.2511365413666 and batch: 950, loss is 3.801450295448303 and perplexity is 44.76606145171234
At time: 687.404009103775 and batch: 1000, loss is 3.758521146774292 and perplexity is 42.88495850157391
At time: 688.5559010505676 and batch: 1050, loss is 3.7167688274383544 and perplexity is 41.131276908733206
At time: 689.709568977356 and batch: 1100, loss is 3.732241554260254 and perplexity is 41.77263893448382
At time: 690.8622188568115 and batch: 1150, loss is 3.726323432922363 and perplexity is 41.52615347351045
At time: 692.014416217804 and batch: 1200, loss is 3.742087516784668 and perplexity is 42.185962215686814
At time: 693.2077775001526 and batch: 1250, loss is 3.7320548152923583 and perplexity is 41.764839083293666
At time: 694.3597221374512 and batch: 1300, loss is 3.7235114049911497 and perplexity is 41.409544800330345
At time: 695.5111997127533 and batch: 1350, loss is 3.60353720664978 and perplexity is 36.72791918757552
At time: 696.6628065109253 and batch: 1400, loss is 3.6225080823898317 and perplexity is 37.431331052189165
At time: 697.813634634018 and batch: 1450, loss is 3.5559864807128907 and perplexity is 35.02235180697414
At time: 698.965708732605 and batch: 1500, loss is 3.5518307209014894 and perplexity is 34.877109330289905
At time: 700.1205613613129 and batch: 1550, loss is 3.558048768043518 and perplexity is 35.09465248615704
At time: 701.274772644043 and batch: 1600, loss is 3.6401558256149293 and perplexity is 38.09777287177036
At time: 702.4348556995392 and batch: 1650, loss is 3.6036371278762815 and perplexity is 36.731589269664084
At time: 703.5865066051483 and batch: 1700, loss is 3.6052332401275633 and perplexity is 36.79026382243622
At time: 704.7397809028625 and batch: 1750, loss is 3.5866608381271363 and perplexity is 36.113286261999185
At time: 705.8974862098694 and batch: 1800, loss is 3.535555672645569 and perplexity is 34.31407681143744
At time: 707.0486283302307 and batch: 1850, loss is 3.571499104499817 and perplexity is 35.56987616466391
At time: 708.2075614929199 and batch: 1900, loss is 3.6678669118881224 and perplexity is 39.168267322444144
At time: 709.3575487136841 and batch: 1950, loss is 3.601404252052307 and perplexity is 36.64966369086808
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325720782612645 and perplexity of 75.61999880141231
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 713.0284662246704 and batch: 50, loss is 3.819003825187683 and perplexity is 45.55880117766505
At time: 714.1762623786926 and batch: 100, loss is 3.8193216800689695 and perplexity is 45.57328456669095
At time: 715.3003730773926 and batch: 150, loss is 3.787591648101807 and perplexity is 44.149943534474744
At time: 716.4288268089294 and batch: 200, loss is 3.784281325340271 and perplexity is 44.00403460753507
At time: 717.5544917583466 and batch: 250, loss is 3.7836908102035522 and perplexity is 43.97805722979487
At time: 718.6858353614807 and batch: 300, loss is 3.7851017999649046 and perplexity is 44.04015361665105
At time: 719.8354225158691 and batch: 350, loss is 3.8021280002593993 and perplexity is 44.79640990941835
At time: 721.0121734142303 and batch: 400, loss is 3.7533547115325927 and perplexity is 42.663967500040194
At time: 722.1654028892517 and batch: 450, loss is 3.800397539138794 and perplexity is 44.71895849638422
At time: 723.3185079097748 and batch: 500, loss is 3.8107561922073363 and perplexity is 45.18459418871398
At time: 724.4733197689056 and batch: 550, loss is 3.791675019264221 and perplexity is 44.33059271854925
At time: 725.6249339580536 and batch: 600, loss is 3.759982032775879 and perplexity is 42.9476543217001
At time: 726.7802991867065 and batch: 650, loss is 3.779915647506714 and perplexity is 43.81234589908635
At time: 727.9356989860535 and batch: 700, loss is 3.833862690925598 and perplexity is 46.240807660856156
At time: 729.0928671360016 and batch: 750, loss is 3.776842293739319 and perplexity is 43.677901763778216
At time: 730.2513678073883 and batch: 800, loss is 3.7623611211776735 and perplexity is 43.04995222761085
At time: 731.4093658924103 and batch: 850, loss is 3.7598630952835084 and perplexity is 42.94254653915133
At time: 732.564484834671 and batch: 900, loss is 3.703528447151184 and perplexity is 40.59027261554781
At time: 733.7194051742554 and batch: 950, loss is 3.8153945541381837 and perplexity is 45.39466350238723
At time: 734.8748183250427 and batch: 1000, loss is 3.771944727897644 and perplexity is 43.46450934231941
At time: 736.0310819149017 and batch: 1050, loss is 3.7311188650131224 and perplexity is 41.725767557846225
At time: 737.1884388923645 and batch: 1100, loss is 3.7403478908538816 and perplexity is 42.1126382185563
At time: 738.3445837497711 and batch: 1150, loss is 3.7357446432113646 and perplexity is 41.91922881317809
At time: 739.5028893947601 and batch: 1200, loss is 3.7532917356491087 and perplexity is 42.66128078359401
At time: 740.6534371376038 and batch: 1250, loss is 3.7437946462631224 and perplexity is 42.258040621443
At time: 741.8101501464844 and batch: 1300, loss is 3.734426302909851 and perplexity is 41.86400141667545
At time: 742.974053144455 and batch: 1350, loss is 3.6085214710235594 and perplexity is 36.911437819467
At time: 744.1301763057709 and batch: 1400, loss is 3.62677414894104 and perplexity is 37.59135669889101
At time: 745.2850048542023 and batch: 1450, loss is 3.550181269645691 and perplexity is 34.819628657322795
At time: 746.4406659603119 and batch: 1500, loss is 3.546168341636658 and perplexity is 34.68017998010633
At time: 747.5977516174316 and batch: 1550, loss is 3.5516977882385254 and perplexity is 34.8724733314148
At time: 748.7529981136322 and batch: 1600, loss is 3.631307864189148 and perplexity is 37.76217212762433
At time: 749.9064445495605 and batch: 1650, loss is 3.5892726945877076 and perplexity is 36.20773226804966
At time: 751.0610899925232 and batch: 1700, loss is 3.587046947479248 and perplexity is 36.127232631799075
At time: 752.2153356075287 and batch: 1750, loss is 3.5708262586593627 and perplexity is 35.5459511712598
At time: 753.3701140880585 and batch: 1800, loss is 3.5230561113357544 and perplexity is 33.887835369675
At time: 754.530168056488 and batch: 1850, loss is 3.561345548629761 and perplexity is 35.21054278262879
At time: 755.6840212345123 and batch: 1900, loss is 3.661983389854431 and perplexity is 38.93849655213442
At time: 756.836900472641 and batch: 1950, loss is 3.6024206018447877 and perplexity is 36.68693150431398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321721702398256 and perplexity of 75.31819223694731
finished 16 epochs...
Completing Train Step...
At time: 760.5224528312683 and batch: 50, loss is 3.826337819099426 and perplexity is 45.89415739519508
At time: 761.6545686721802 and batch: 100, loss is 3.8185857915878296 and perplexity is 45.53976004819699
At time: 762.7797536849976 and batch: 150, loss is 3.783395700454712 and perplexity is 43.965080791202254
At time: 763.9003591537476 and batch: 200, loss is 3.7745875120162964 and perplexity is 43.579528575892084
At time: 765.0214381217957 and batch: 250, loss is 3.7718694972991944 and perplexity is 43.46123960426399
At time: 766.1614644527435 and batch: 300, loss is 3.7734057807922365 and perplexity is 43.528059703420624
At time: 767.3162627220154 and batch: 350, loss is 3.7894426345825196 and perplexity is 44.23174016195314
At time: 768.4694533348083 and batch: 400, loss is 3.7402671003341674 and perplexity is 42.109236054061256
At time: 769.6225218772888 and batch: 450, loss is 3.787278580665588 and perplexity is 44.13612378821235
At time: 770.776374578476 and batch: 500, loss is 3.7980164003372194 and perplexity is 44.612603122847155
At time: 771.9303321838379 and batch: 550, loss is 3.778148922920227 and perplexity is 43.73500988622828
At time: 773.0846474170685 and batch: 600, loss is 3.74775249004364 and perplexity is 42.42562275789383
At time: 774.246960401535 and batch: 650, loss is 3.7681851387023926 and perplexity is 43.30140743282123
At time: 775.3997671604156 and batch: 700, loss is 3.823555226325989 and perplexity is 45.766630154957824
At time: 776.5522518157959 and batch: 750, loss is 3.7671950387954714 and perplexity is 43.25855593048727
At time: 777.7053911685944 and batch: 800, loss is 3.753764228820801 and perplexity is 42.68144271027114
At time: 778.8996574878693 and batch: 850, loss is 3.7520841360092163 and perplexity is 42.60979413017136
At time: 780.0431122779846 and batch: 900, loss is 3.6962404155731203 and perplexity is 40.29552479730326
At time: 781.1878430843353 and batch: 950, loss is 3.8076869106292723 and perplexity is 45.046122559075094
At time: 782.3399631977081 and batch: 1000, loss is 3.7652559423446657 and perplexity is 43.174754693814165
At time: 783.4848029613495 and batch: 1050, loss is 3.724692659378052 and perplexity is 41.45848890881555
At time: 784.6286277770996 and batch: 1100, loss is 3.7350769519805906 and perplexity is 41.891249053658235
At time: 785.7742772102356 and batch: 1150, loss is 3.7310243463516235 and perplexity is 41.72182388052513
At time: 786.9196903705597 and batch: 1200, loss is 3.7486073684692385 and perplexity is 42.46190701458648
At time: 788.0659878253937 and batch: 1250, loss is 3.73930543422699 and perplexity is 42.068760494055354
At time: 789.2108254432678 and batch: 1300, loss is 3.729826726913452 and perplexity is 41.67188692195467
At time: 790.3561675548553 and batch: 1350, loss is 3.6045481157302857 and perplexity is 36.76506654772864
At time: 791.5024025440216 and batch: 1400, loss is 3.6244359588623047 and perplexity is 37.50356364003908
At time: 792.6544790267944 and batch: 1450, loss is 3.5495188665390014 and perplexity is 34.79657166448133
At time: 793.8026757240295 and batch: 1500, loss is 3.5465663051605225 and perplexity is 34.69398417333998
At time: 794.9488105773926 and batch: 1550, loss is 3.553046045303345 and perplexity is 34.91952209974166
At time: 796.0938544273376 and batch: 1600, loss is 3.6332535696029664 and perplexity is 37.8357177161933
At time: 797.240784406662 and batch: 1650, loss is 3.59191686630249 and perplexity is 36.303598416993815
At time: 798.3930912017822 and batch: 1700, loss is 3.591055932044983 and perplexity is 36.27235685584068
At time: 799.5458617210388 and batch: 1750, loss is 3.5761937141418456 and perplexity is 35.73725543102029
At time: 800.6988575458527 and batch: 1800, loss is 3.528540005683899 and perplexity is 34.07418316734245
At time: 801.8524742126465 and batch: 1850, loss is 3.5670087575912475 and perplexity is 35.410513146579994
At time: 803.0071356296539 and batch: 1900, loss is 3.6683464670181274 and perplexity is 39.18705517051643
At time: 804.1607296466827 and batch: 1950, loss is 3.6084153842926026 and perplexity is 36.90752221339441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320702557231105 and perplexity of 75.24147116692488
finished 17 epochs...
Completing Train Step...
At time: 807.8680641651154 and batch: 50, loss is 3.82736111164093 and perplexity is 45.941144580874386
At time: 808.9909248352051 and batch: 100, loss is 3.81697425365448 and perplexity is 45.46643010027021
At time: 810.1150977611542 and batch: 150, loss is 3.780753345489502 and perplexity is 43.84906278955264
At time: 811.2435102462769 and batch: 200, loss is 3.7708550834655763 and perplexity is 43.417174275601454
At time: 812.3789277076721 and batch: 250, loss is 3.7672421073913576 and perplexity is 43.260592097894374
At time: 813.5254094600677 and batch: 300, loss is 3.768679656982422 and perplexity is 43.32282606586405
At time: 814.677915096283 and batch: 350, loss is 3.7842701292037964 and perplexity is 44.003541935116175
At time: 815.8303046226501 and batch: 400, loss is 3.734895691871643 and perplexity is 41.88365652942249
At time: 816.9826309680939 and batch: 450, loss is 3.7818437385559083 and perplexity is 43.89690158038984
At time: 818.1349954605103 and batch: 500, loss is 3.7925099468231203 and perplexity is 44.367621007930886
At time: 819.2879457473755 and batch: 550, loss is 3.772442116737366 and perplexity is 43.48613348154722
At time: 820.4466004371643 and batch: 600, loss is 3.742561812400818 and perplexity is 42.2059755783787
At time: 821.6009020805359 and batch: 650, loss is 3.763100037574768 and perplexity is 43.081774298683115
At time: 822.7554807662964 and batch: 700, loss is 3.8191094636917113 and perplexity is 45.563614195482316
At time: 823.9107558727264 and batch: 750, loss is 3.7631693124771117 and perplexity is 43.084758887767826
At time: 825.060510635376 and batch: 800, loss is 3.7501192903518676 and perplexity is 42.526154657449894
At time: 826.20947098732 and batch: 850, loss is 3.7484650468826293 and perplexity is 42.45586419863149
At time: 827.3592801094055 and batch: 900, loss is 3.6931221675872803 and perplexity is 40.17006906096968
At time: 828.5141770839691 and batch: 950, loss is 3.8045075798034667 and perplexity is 44.903133458314095
At time: 829.6793584823608 and batch: 1000, loss is 3.7624858522415163 and perplexity is 43.055322228846606
At time: 830.8313896656036 and batch: 1050, loss is 3.722026572227478 and perplexity is 41.348104177295454
At time: 831.9870998859406 and batch: 1100, loss is 3.7325976610183718 and perplexity is 41.78751710246367
At time: 833.1345059871674 and batch: 1150, loss is 3.7287672185897827 and perplexity is 41.627758592192244
At time: 834.2832753658295 and batch: 1200, loss is 3.746362771987915 and perplexity is 42.366704053597935
At time: 835.4314558506012 and batch: 1250, loss is 3.7373571729660036 and perplexity is 41.98687934652079
At time: 836.578732252121 and batch: 1300, loss is 3.728071064949036 and perplexity is 41.598789361179925
At time: 837.7274317741394 and batch: 1350, loss is 3.603194208145142 and perplexity is 36.71532372645135
At time: 838.8771076202393 and batch: 1400, loss is 3.623621983528137 and perplexity is 37.47304908502506
At time: 840.0242948532104 and batch: 1450, loss is 3.549466247558594 and perplexity is 34.79474075252944
At time: 841.1724076271057 and batch: 1500, loss is 3.546995453834534 and perplexity is 34.70887624587217
At time: 842.3209412097931 and batch: 1550, loss is 3.553921480178833 and perplexity is 34.95010525204901
At time: 843.4689042568207 and batch: 1600, loss is 3.63442955493927 and perplexity is 37.88023813796689
At time: 844.6172096729279 and batch: 1650, loss is 3.5934373235702513 and perplexity is 36.358838471482024
At time: 845.7675228118896 and batch: 1700, loss is 3.5929215145111084 and perplexity is 36.34008908918485
At time: 846.9141654968262 and batch: 1750, loss is 3.578510088920593 and perplexity is 35.82013225800131
At time: 848.0625653266907 and batch: 1800, loss is 3.530820565223694 and perplexity is 34.15198004731569
At time: 849.2104744911194 and batch: 1850, loss is 3.569309034347534 and perplexity is 35.49206088212195
At time: 850.359002828598 and batch: 1900, loss is 3.670708441734314 and perplexity is 39.279723400957224
At time: 851.5078060626984 and batch: 1950, loss is 3.610457320213318 and perplexity is 36.98296200414363
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320245219385901 and perplexity of 75.20706826210629
finished 18 epochs...
Completing Train Step...
At time: 855.1676511764526 and batch: 50, loss is 3.82648512840271 and perplexity is 45.90091852952254
At time: 856.287611246109 and batch: 100, loss is 3.814959750175476 and perplexity is 45.374930013221146
At time: 857.425151348114 and batch: 150, loss is 3.7783484411239625 and perplexity is 43.743736687390026
At time: 858.5481133460999 and batch: 200, loss is 3.7680747747421264 and perplexity is 43.29662878171212
At time: 859.6766719818115 and batch: 250, loss is 3.7640366888046266 and perplexity is 43.12214579962093
At time: 860.8150722980499 and batch: 300, loss is 3.765390558242798 and perplexity is 43.18056709340583
At time: 861.9458425045013 and batch: 350, loss is 3.7807660818099977 and perplexity is 43.84962126882623
At time: 863.0688405036926 and batch: 400, loss is 3.731360855102539 and perplexity is 41.735866001880936
At time: 864.2611594200134 and batch: 450, loss is 3.778339457511902 and perplexity is 43.74334371239472
At time: 865.3888032436371 and batch: 500, loss is 3.7889676475524903 and perplexity is 44.21073564789137
At time: 866.51584815979 and batch: 550, loss is 3.768890771865845 and perplexity is 43.33197312474466
At time: 867.6522419452667 and batch: 600, loss is 3.739312629699707 and perplexity is 42.069063199762795
At time: 868.7908573150635 and batch: 650, loss is 3.7599134397506715 and perplexity is 42.94470851319673
At time: 869.9286992549896 and batch: 700, loss is 3.8162225914001464 and perplexity is 45.432267541885835
At time: 871.0665001869202 and batch: 750, loss is 3.760532884597778 and perplexity is 42.97131863249548
At time: 872.2048344612122 and batch: 800, loss is 3.747677626609802 and perplexity is 42.422446748976405
At time: 873.3411076068878 and batch: 850, loss is 3.7459710693359374 and perplexity is 42.350112153022465
At time: 874.4786083698273 and batch: 900, loss is 3.690917105674744 and perplexity is 40.08158915934123
At time: 875.614739894867 and batch: 950, loss is 3.8023686599731445 and perplexity is 44.80719189794706
At time: 876.7590968608856 and batch: 1000, loss is 3.7605821180343626 and perplexity is 42.973434310266946
At time: 877.9047355651855 and batch: 1050, loss is 3.7201986932754516 and perplexity is 41.27259388082859
At time: 879.0506329536438 and batch: 1100, loss is 3.7308325147628785 and perplexity is 41.71382108438388
At time: 880.1974666118622 and batch: 1150, loss is 3.7271375370025637 and perplexity is 41.559973849273305
At time: 881.3460075855255 and batch: 1200, loss is 3.744796495437622 and perplexity is 42.30039801887454
At time: 882.4935977458954 and batch: 1250, loss is 3.7359865713119507 and perplexity is 41.92937147943142
At time: 883.640031337738 and batch: 1300, loss is 3.7268896532058715 and perplexity is 41.54967308191453
At time: 884.7863953113556 and batch: 1350, loss is 3.6022834634780883 and perplexity is 36.6819006634168
At time: 885.9329252243042 and batch: 1400, loss is 3.6229485368728636 and perplexity is 37.44782148113204
At time: 887.0810453891754 and batch: 1450, loss is 3.549223041534424 and perplexity is 34.7862794909256
At time: 888.2274005413055 and batch: 1500, loss is 3.5470539569854735 and perplexity is 34.71090688389691
At time: 889.3733561038971 and batch: 1550, loss is 3.554243903160095 and perplexity is 34.961375786021755
At time: 890.5204899311066 and batch: 1600, loss is 3.6349566078186033 and perplexity is 37.900208288747784
At time: 891.6673593521118 and batch: 1650, loss is 3.5941912078857423 and perplexity is 36.386259164251555
At time: 892.813768863678 and batch: 1700, loss is 3.5937939167022703 and perplexity is 36.37180609551457
At time: 893.9617812633514 and batch: 1750, loss is 3.579602656364441 and perplexity is 35.85928955543972
At time: 895.1066541671753 and batch: 1800, loss is 3.531864671707153 and perplexity is 34.18765697311971
At time: 896.2643442153931 and batch: 1850, loss is 3.570364317893982 and perplexity is 35.52953483934795
At time: 897.421130657196 and batch: 1900, loss is 3.671703634262085 and perplexity is 39.31883374611247
At time: 898.5661196708679 and batch: 1950, loss is 3.611233549118042 and perplexity is 37.01168039281328
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.32002804778343 and perplexity of 75.19073719596075
finished 19 epochs...
Completing Train Step...
At time: 902.2181658744812 and batch: 50, loss is 3.825142879486084 and perplexity is 45.83934940114582
At time: 903.3582062721252 and batch: 100, loss is 3.8129895448684694 and perplexity is 45.28562009363241
At time: 904.4787023067474 and batch: 150, loss is 3.776178894042969 and perplexity is 43.64893546618977
At time: 905.6008508205414 and batch: 200, loss is 3.7657007789611816 and perplexity is 43.19396467794647
At time: 906.7240970134735 and batch: 250, loss is 3.761433148384094 and perplexity is 43.01002157332461
At time: 907.8546180725098 and batch: 300, loss is 3.762707619667053 and perplexity is 43.064871555638625
At time: 908.9896688461304 and batch: 350, loss is 3.777948875427246 and perplexity is 43.726261682202356
At time: 910.125396490097 and batch: 400, loss is 3.7285399532318113 and perplexity is 41.61829911968016
At time: 911.2597584724426 and batch: 450, loss is 3.7755898904800413 and perplexity is 43.62323365765364
At time: 912.3950669765472 and batch: 500, loss is 3.786207790374756 and perplexity is 44.088888549415806
At time: 913.5293574333191 and batch: 550, loss is 3.7661933422088625 and perplexity is 43.21524567815748
At time: 914.6629092693329 and batch: 600, loss is 3.7368269634246825 and perplexity is 41.964623403159116
At time: 915.8011517524719 and batch: 650, loss is 3.757477240562439 and perplexity is 42.84021398560148
At time: 916.9392228126526 and batch: 700, loss is 3.8139621686935423 and perplexity is 45.32968739364767
At time: 918.07475233078 and batch: 750, loss is 3.758433904647827 and perplexity is 42.88121728979888
At time: 919.213294506073 and batch: 800, loss is 3.7456986618041994 and perplexity is 42.338577234672684
At time: 920.3471274375916 and batch: 850, loss is 3.7439361381530762 and perplexity is 42.26402021449826
At time: 921.5287787914276 and batch: 900, loss is 3.689068841934204 and perplexity is 40.00757623021092
At time: 922.6732909679413 and batch: 950, loss is 3.800609302520752 and perplexity is 44.72842933702629
At time: 923.8157670497894 and batch: 1000, loss is 3.7589897298812867 and perplexity is 42.90505837753531
At time: 924.9575433731079 and batch: 1050, loss is 3.7186739015579224 and perplexity is 41.20970972632088
At time: 926.1047835350037 and batch: 1100, loss is 3.729344344139099 and perplexity is 41.65178996913036
At time: 927.2510757446289 and batch: 1150, loss is 3.7257533740997313 and perplexity is 41.502487869387004
At time: 928.4036133289337 and batch: 1200, loss is 3.7434872674942015 and perplexity is 42.24505339304116
At time: 929.5475876331329 and batch: 1250, loss is 3.734805483818054 and perplexity is 41.87987845669865
At time: 930.6908836364746 and batch: 1300, loss is 3.7258709907531737 and perplexity is 41.507369540197
At time: 931.8324360847473 and batch: 1350, loss is 3.6014589071273804 and perplexity is 36.65166683572904
At time: 932.9779031276703 and batch: 1400, loss is 3.622260084152222 and perplexity is 37.42204929903362
At time: 934.1227509975433 and batch: 1450, loss is 3.548825478553772 and perplexity is 34.77245250269685
At time: 935.2674553394318 and batch: 1500, loss is 3.546861419677734 and perplexity is 34.704224382672336
At time: 936.414666891098 and batch: 1550, loss is 3.554239158630371 and perplexity is 34.961209911128634
At time: 937.5623548030853 and batch: 1600, loss is 3.6351183748245237 and perplexity is 37.906339787890175
At time: 938.710823059082 and batch: 1650, loss is 3.5945259523391724 and perplexity is 36.398441301525544
At time: 939.858137845993 and batch: 1700, loss is 3.594178099632263 and perplexity is 36.38578220706932
At time: 941.0055663585663 and batch: 1750, loss is 3.580134000778198 and perplexity is 35.87834825154376
At time: 942.1531646251678 and batch: 1800, loss is 3.5323516273498536 and perplexity is 34.204308899639216
At time: 943.2976748943329 and batch: 1850, loss is 3.5708685874938966 and perplexity is 35.54745582179011
At time: 944.4512884616852 and batch: 1900, loss is 3.6721346473693846 and perplexity is 39.33578433152061
At time: 945.5930805206299 and batch: 1950, loss is 3.611507439613342 and perplexity is 37.02181892864888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319936920875727 and perplexity of 75.18388560877887
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
4858.76700091362


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}, 'best_accuracy': -74.98631242869352}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.17814085302781324, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.8667473068914826}, 'best_accuracy': -75.01846336550948}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.46505974392752214, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.5624524957122032}, 'best_accuracy': -75.18388560877887}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7505577639643596, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7101460218637431}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6492834091186523 and batch: 50, loss is 7.643597440719605 and perplexity is 2087.2390454008055
At time: 2.855422019958496 and batch: 100, loss is 6.837692985534668 and perplexity is 932.3357396895344
At time: 4.042761325836182 and batch: 150, loss is 6.545607957839966 and perplexity is 696.1797982835847
At time: 5.223089218139648 and batch: 200, loss is 6.436051235198975 and perplexity is 623.9381439676805
At time: 6.402361154556274 and batch: 250, loss is 6.3828585338592525 and perplexity is 591.6164484968326
At time: 7.585851430892944 and batch: 300, loss is 6.311947212219239 and perplexity is 551.1170465196244
At time: 8.775449514389038 and batch: 350, loss is 6.264674015045166 and perplexity is 525.6701974502325
At time: 9.958307981491089 and batch: 400, loss is 6.216886835098267 and perplexity is 501.14066748486425
At time: 11.140297412872314 and batch: 450, loss is 6.128309946060181 and perplexity is 458.66034455669217
At time: 12.32114028930664 and batch: 500, loss is 6.115602130889893 and perplexity is 452.8686514954056
At time: 13.502192258834839 and batch: 550, loss is 6.069550094604492 and perplexity is 432.4860599852381
At time: 14.691334247589111 and batch: 600, loss is 6.109532432556152 and perplexity is 450.12820066440355
At time: 15.877983570098877 and batch: 650, loss is 6.1760614967346195 and perplexity is 481.0934320816862
At time: 17.06748867034912 and batch: 700, loss is 6.081474847793579 and perplexity is 437.6742218034176
At time: 18.26168966293335 and batch: 750, loss is 6.007886476516724 and perplexity is 406.62300417684764
At time: 19.45409369468689 and batch: 800, loss is 6.021028203964233 and perplexity is 412.0020001061141
At time: 20.64413595199585 and batch: 850, loss is 6.058526964187622 and perplexity is 427.7448890234372
At time: 21.834736824035645 and batch: 900, loss is 6.031012716293335 and perplexity is 416.13624401508685
At time: 23.02554965019226 and batch: 950, loss is 6.046832208633423 and perplexity is 422.77165417090623
At time: 24.215834140777588 and batch: 1000, loss is 6.024182415008545 and perplexity is 413.30359303538955
At time: 25.410887718200684 and batch: 1050, loss is 5.919713878631592 and perplexity is 372.30517416936704
At time: 26.602234840393066 and batch: 1100, loss is 5.999716920852661 and perplexity is 403.31460737647797
At time: 27.793496131896973 and batch: 1150, loss is 5.90743860244751 and perplexity is 367.76296082912046
At time: 28.983784675598145 and batch: 1200, loss is 5.980014419555664 and perplexity is 395.4460702708351
At time: 30.172482013702393 and batch: 1250, loss is 5.925214996337891 and perplexity is 374.3589125040615
At time: 31.363877534866333 and batch: 1300, loss is 5.937676048278808 and perplexity is 379.05300427748614
At time: 32.55468559265137 and batch: 1350, loss is 5.9100362586975095 and perplexity is 368.7195244566865
At time: 33.74670338630676 and batch: 1400, loss is 5.922788429260254 and perplexity is 373.45160675608963
At time: 34.93820023536682 and batch: 1450, loss is 5.90904748916626 and perplexity is 368.35512600805674
At time: 36.13091969490051 and batch: 1500, loss is 5.883356037139893 and perplexity is 359.0120800691673
At time: 37.32140278816223 and batch: 1550, loss is 5.850498247146606 and perplexity is 347.40743212567634
At time: 38.51133179664612 and batch: 1600, loss is 5.858886823654175 and perplexity is 350.33394342021313
At time: 39.70197415351868 and batch: 1650, loss is 5.856104021072388 and perplexity is 349.3603884518818
At time: 40.89321184158325 and batch: 1700, loss is 5.87190954208374 and perplexity is 354.9260798730591
At time: 42.0854651927948 and batch: 1750, loss is 5.874265842437744 and perplexity is 355.76337839671237
At time: 43.2760066986084 and batch: 1800, loss is 5.880661869049073 and perplexity is 358.04614296156694
At time: 44.46787667274475 and batch: 1850, loss is 5.835320358276367 and perplexity is 342.17433487370846
At time: 45.65860915184021 and batch: 1900, loss is 5.826581993103027 and perplexity is 339.19731666226045
At time: 46.85300159454346 and batch: 1950, loss is 5.762665843963623 and perplexity is 318.19545870107834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.216548759992732 and perplexity of 184.2970319308147
finished 1 epochs...
Completing Train Step...
At time: 50.493480920791626 and batch: 50, loss is 5.5005086898803714 and perplexity is 244.81643623824277
At time: 51.63768243789673 and batch: 100, loss is 5.402860679626465 and perplexity is 222.04069583104246
At time: 52.755653381347656 and batch: 150, loss is 5.291081428527832 and perplexity is 198.55803566984048
At time: 53.87410569190979 and batch: 200, loss is 5.234128618240357 and perplexity is 187.56559387641377
At time: 54.99188590049744 and batch: 250, loss is 5.245476350784302 and perplexity is 189.7061603881056
At time: 56.110400915145874 and batch: 300, loss is 5.236527938842773 and perplexity is 188.01616418526703
At time: 57.22781753540039 and batch: 350, loss is 5.214652080535888 and perplexity is 183.9478108213368
At time: 58.34522199630737 and batch: 400, loss is 5.152972984313965 and perplexity is 172.94488921809452
At time: 59.460877656936646 and batch: 450, loss is 5.102786302566528 and perplexity is 164.4795592434898
At time: 60.60083270072937 and batch: 500, loss is 5.085256214141846 and perplexity is 161.6213436070372
At time: 61.718961000442505 and batch: 550, loss is 5.040036544799805 and perplexity is 154.4756602048162
At time: 62.83675193786621 and batch: 600, loss is 5.021592149734497 and perplexity is 151.65256527242235
At time: 63.956411600112915 and batch: 650, loss is 5.095108690261841 and perplexity is 163.22158425703847
At time: 65.07465291023254 and batch: 700, loss is 5.085874586105347 and perplexity is 161.7213166216962
At time: 66.19214129447937 and batch: 750, loss is 5.017889957427979 and perplexity is 151.09215632294863
At time: 67.30972862243652 and batch: 800, loss is 5.017019844055175 and perplexity is 150.9607461963514
At time: 68.42733120918274 and batch: 850, loss is 5.010884933471679 and perplexity is 150.03745058068884
At time: 69.54646444320679 and batch: 900, loss is 5.013237438201904 and perplexity is 150.39082989316793
At time: 70.66474533081055 and batch: 950, loss is 5.048319826126098 and perplexity is 155.7605397190162
At time: 71.78320384025574 and batch: 1000, loss is 5.006725025177002 and perplexity is 149.41460493407843
At time: 72.90134716033936 and batch: 1050, loss is 4.925334053039551 and perplexity is 137.73534486927917
At time: 74.01940178871155 and batch: 1100, loss is 4.988720979690552 and perplexity is 146.7486089607521
At time: 75.13661789894104 and batch: 1150, loss is 4.9061008739471434 and perplexity is 135.1115689706443
At time: 76.25408220291138 and batch: 1200, loss is 4.977197456359863 and perplexity is 145.06725411332664
At time: 77.37166595458984 and batch: 1250, loss is 4.944688501358033 and perplexity is 140.4271011865043
At time: 78.4913239479065 and batch: 1300, loss is 4.950784330368042 and perplexity is 141.28573516783527
At time: 79.60914611816406 and batch: 1350, loss is 4.868519487380982 and perplexity is 130.12811789036897
At time: 80.72697615623474 and batch: 1400, loss is 4.865468330383301 and perplexity is 129.73168167499287
At time: 81.84454464912415 and batch: 1450, loss is 4.812982730865478 and perplexity is 123.09823939639156
At time: 82.96100521087646 and batch: 1500, loss is 4.787654714584351 and perplexity is 120.01955820995164
At time: 84.07862854003906 and batch: 1550, loss is 4.788273658752441 and perplexity is 120.09386660956554
At time: 85.1984875202179 and batch: 1600, loss is 4.842234706878662 and perplexity is 126.75228968431487
At time: 86.33228063583374 and batch: 1650, loss is 4.815623598098755 and perplexity is 123.42375513602916
At time: 87.46904015541077 and batch: 1700, loss is 4.827416009902954 and perplexity is 124.88783442966752
At time: 88.60952734947205 and batch: 1750, loss is 4.82086630821228 and perplexity is 124.07252928671366
At time: 89.74240803718567 and batch: 1800, loss is 4.779101362228394 and perplexity is 118.99736645404832
At time: 90.8769474029541 and batch: 1850, loss is 4.790750360488891 and perplexity is 120.3916719327856
At time: 92.0103600025177 and batch: 1900, loss is 4.886184644699097 and perplexity is 132.4472753965599
At time: 93.14364981651306 and batch: 1950, loss is 4.800461797714234 and perplexity is 121.56654371027665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.620557776162791 and perplexity of 101.55065887238854
finished 2 epochs...
Completing Train Step...
At time: 96.76441621780396 and batch: 50, loss is 4.756898365020752 and perplexity is 116.38438362745538
At time: 97.90911030769348 and batch: 100, loss is 4.699229936599732 and perplexity is 109.86253874949585
At time: 99.03136563301086 and batch: 150, loss is 4.636851720809936 and perplexity is 103.21887367872841
At time: 100.15791749954224 and batch: 200, loss is 4.629767608642578 and perplexity is 102.4902434959397
At time: 101.29313254356384 and batch: 250, loss is 4.639609088897705 and perplexity is 103.5038788585831
At time: 102.4281792640686 and batch: 300, loss is 4.656072025299072 and perplexity is 105.22196016126023
At time: 103.56473422050476 and batch: 350, loss is 4.658230295181275 and perplexity is 105.44930279395186
At time: 104.70916414260864 and batch: 400, loss is 4.6036834716796875 and perplexity is 99.85143903038315
At time: 105.84821653366089 and batch: 450, loss is 4.590650291442871 and perplexity is 98.55850107717718
At time: 106.9930408000946 and batch: 500, loss is 4.594707107543945 and perplexity is 98.95914691501018
At time: 108.13858938217163 and batch: 550, loss is 4.569421749114991 and perplexity is 96.48829919373958
At time: 109.28295564651489 and batch: 600, loss is 4.538293027877808 and perplexity is 93.531008953896
At time: 110.42812466621399 and batch: 650, loss is 4.605327043533325 and perplexity is 100.0156869848022
At time: 111.57259702682495 and batch: 700, loss is 4.636086168289185 and perplexity is 103.13988444885435
At time: 112.7183747291565 and batch: 750, loss is 4.585504570007324 and perplexity is 98.05264908842074
At time: 113.87009644508362 and batch: 800, loss is 4.582422227859497 and perplexity is 97.75088258815005
At time: 115.02436995506287 and batch: 850, loss is 4.575942621231079 and perplexity is 97.11954294657531
At time: 116.19953036308289 and batch: 900, loss is 4.554993886947631 and perplexity is 95.10617384477968
At time: 117.35344505310059 and batch: 950, loss is 4.616544504165649 and perplexity is 101.14392516925145
At time: 118.5078125 and batch: 1000, loss is 4.589614133834839 and perplexity is 98.4564318254977
At time: 119.66143488883972 and batch: 1050, loss is 4.527045888900757 and perplexity is 92.48494633043777
At time: 120.81339716911316 and batch: 1100, loss is 4.577758178710938 and perplexity is 97.29602922122184
At time: 121.96607232093811 and batch: 1150, loss is 4.523742198944092 and perplexity is 92.17990889410146
At time: 123.12007546424866 and batch: 1200, loss is 4.584519090652466 and perplexity is 97.95606782429229
At time: 124.27236938476562 and batch: 1250, loss is 4.575672254562378 and perplexity is 97.09328860859193
At time: 125.42720699310303 and batch: 1300, loss is 4.567827730178833 and perplexity is 96.33461753598421
At time: 126.57833528518677 and batch: 1350, loss is 4.459701738357544 and perplexity is 86.46171703639666
At time: 127.73192167282104 and batch: 1400, loss is 4.471657009124756 and perplexity is 87.5015938936208
At time: 128.88610005378723 and batch: 1450, loss is 4.419165983200073 and perplexity is 83.02701055253485
At time: 130.0435106754303 and batch: 1500, loss is 4.410266895294189 and perplexity is 82.29142376728149
At time: 131.19534492492676 and batch: 1550, loss is 4.415220670700073 and perplexity is 82.70008837909157
At time: 132.34437441825867 and batch: 1600, loss is 4.492815561294556 and perplexity is 89.37272635397993
At time: 133.49046802520752 and batch: 1650, loss is 4.45477593421936 and perplexity is 86.036870766604
At time: 134.6364893913269 and batch: 1700, loss is 4.468985347747803 and perplexity is 87.26813127019734
At time: 135.78042554855347 and batch: 1750, loss is 4.462579431533814 and perplexity is 86.710885673014
At time: 136.92544317245483 and batch: 1800, loss is 4.420361957550049 and perplexity is 83.126368130225
At time: 138.0737156867981 and batch: 1850, loss is 4.4582314205169675 and perplexity is 86.33468424348739
At time: 139.2205536365509 and batch: 1900, loss is 4.568204784393311 and perplexity is 96.37094775832755
At time: 140.36636447906494 and batch: 1950, loss is 4.483529663085937 and perplexity is 88.54666162672636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48222287200218 and perplexity of 88.43102521159028
finished 3 epochs...
Completing Train Step...
At time: 143.981383562088 and batch: 50, loss is 4.450486946105957 and perplexity is 85.66864986257649
At time: 145.1253206729889 and batch: 100, loss is 4.400576601028442 and perplexity is 81.49784686214468
At time: 146.2459146976471 and batch: 150, loss is 4.352956237792969 and perplexity is 77.70784657475339
At time: 147.3660340309143 and batch: 200, loss is 4.349702310562134 and perplexity is 77.45540183787729
At time: 148.49266743659973 and batch: 250, loss is 4.356753482818603 and perplexity is 78.00348325583667
At time: 149.61511707305908 and batch: 300, loss is 4.378746910095215 and perplexity is 79.73805182744238
At time: 150.74854612350464 and batch: 350, loss is 4.382592611312866 and perplexity is 80.04529094671864
At time: 151.88360786437988 and batch: 400, loss is 4.327157096862793 and perplexity is 75.72869092262225
At time: 153.02314829826355 and batch: 450, loss is 4.336264810562134 and perplexity is 76.42155657993767
At time: 154.1664378643036 and batch: 500, loss is 4.345242023468018 and perplexity is 77.11069781959846
At time: 155.31879210472107 and batch: 550, loss is 4.322122802734375 and perplexity is 75.34840844863066
At time: 156.4617886543274 and batch: 600, loss is 4.2932669544219975 and perplexity is 73.2052364361743
At time: 157.60705471038818 and batch: 650, loss is 4.357345724105835 and perplexity is 78.04969382172052
At time: 158.7519679069519 and batch: 700, loss is 4.3916902828216555 and perplexity is 80.77683935744061
At time: 159.8966679573059 and batch: 750, loss is 4.347475366592407 and perplexity is 77.28310491683204
At time: 161.05546712875366 and batch: 800, loss is 4.34497449874878 and perplexity is 77.09007156095409
At time: 162.20891976356506 and batch: 850, loss is 4.340549030303955 and perplexity is 76.74966566519099
At time: 163.36242413520813 and batch: 900, loss is 4.312771563529968 and perplexity is 74.64709165867251
At time: 164.5138177871704 and batch: 950, loss is 4.381772422790528 and perplexity is 79.97966563405993
At time: 165.66490197181702 and batch: 1000, loss is 4.354339179992675 and perplexity is 77.81538637855691
At time: 166.81867170333862 and batch: 1050, loss is 4.304860820770264 and perplexity is 74.05890727385354
At time: 167.97928476333618 and batch: 1100, loss is 4.343719520568848 and perplexity is 76.99338588515216
At time: 169.1392695903778 and batch: 1150, loss is 4.2987280321121215 and perplexity is 73.60610952292978
At time: 170.29244303703308 and batch: 1200, loss is 4.3581936740875244 and perplexity is 78.11590412571331
At time: 171.4507565498352 and batch: 1250, loss is 4.3601975250244145 and perplexity is 78.27259369221777
At time: 172.61063146591187 and batch: 1300, loss is 4.349499139785767 and perplexity is 77.43966676225995
At time: 173.76362252235413 and batch: 1350, loss is 4.232390451431274 and perplexity is 68.88169387038387
At time: 174.91455459594727 and batch: 1400, loss is 4.2543881273269655 and perplexity is 70.4137197737757
At time: 176.06673169136047 and batch: 1450, loss is 4.200569915771484 and perplexity is 66.72434746477856
At time: 177.21920228004456 and batch: 1500, loss is 4.18903757572174 and perplexity is 65.95927959081553
At time: 178.3728494644165 and batch: 1550, loss is 4.203268375396728 and perplexity is 66.90464357391363
At time: 179.5235526561737 and batch: 1600, loss is 4.284610667228699 and perplexity is 72.57428567086968
At time: 180.67514729499817 and batch: 1650, loss is 4.248338775634766 and perplexity is 69.98904820779464
At time: 181.82741022109985 and batch: 1700, loss is 4.261480536460876 and perplexity is 70.91489786221352
At time: 182.98013997077942 and batch: 1750, loss is 4.256293215751648 and perplexity is 70.54799199587339
At time: 184.1339509487152 and batch: 1800, loss is 4.210994181632995 and perplexity is 67.42353774339689
At time: 185.28706765174866 and batch: 1850, loss is 4.255676245689392 and perplexity is 70.50447942121785
At time: 186.4405734539032 and batch: 1900, loss is 4.368149213790893 and perplexity is 78.89747413102408
At time: 187.58940720558167 and batch: 1950, loss is 4.281406259536743 and perplexity is 72.34210027863385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4364720544149705 and perplexity of 84.47638724418026
finished 4 epochs...
Completing Train Step...
At time: 191.2554931640625 and batch: 50, loss is 4.2594562339782716 and perplexity is 70.77148985797832
At time: 192.37309312820435 and batch: 100, loss is 4.213314146995544 and perplexity is 67.58013960078546
At time: 193.49128127098083 and batch: 150, loss is 4.171035966873169 and perplexity is 64.78252991116062
At time: 194.60916352272034 and batch: 200, loss is 4.170841279029847 and perplexity is 64.76991876778524
At time: 195.72945952415466 and batch: 250, loss is 4.175225610733032 and perplexity is 65.0545150023142
At time: 196.87139868736267 and batch: 300, loss is 4.195035605430603 and perplexity is 66.35609417254015
At time: 198.0054488182068 and batch: 350, loss is 4.199902005195618 and perplexity is 66.67979644714318
At time: 199.14000535011292 and batch: 400, loss is 4.145425267219544 and perplexity is 63.144469465605205
At time: 200.27563047409058 and batch: 450, loss is 4.169248309135437 and perplexity is 64.66682437205976
At time: 201.41028261184692 and batch: 500, loss is 4.175312986373902 and perplexity is 65.06019943059063
At time: 202.5950894355774 and batch: 550, loss is 4.153212141990662 and perplexity is 63.63808691623647
At time: 203.73712062835693 and batch: 600, loss is 4.126568970680236 and perplexity is 61.96495421800692
At time: 204.87870335578918 and batch: 650, loss is 4.189315013885498 and perplexity is 65.97758175096942
At time: 206.02196145057678 and batch: 700, loss is 4.223869128227234 and perplexity is 68.29722445712555
At time: 207.16659235954285 and batch: 750, loss is 4.1846382474899295 and perplexity is 65.66974042585348
At time: 208.31924986839294 and batch: 800, loss is 4.179048209190369 and perplexity is 65.30366819391692
At time: 209.4747109413147 and batch: 850, loss is 4.178063230514526 and perplexity is 65.23937714114747
At time: 210.62668180465698 and batch: 900, loss is 4.149502692222595 and perplexity is 63.4024619192137
At time: 211.7764105796814 and batch: 950, loss is 4.221844902038574 and perplexity is 68.15911525605598
At time: 212.9286870956421 and batch: 1000, loss is 4.191771593093872 and perplexity is 66.13986014977834
At time: 214.07948637008667 and batch: 1050, loss is 4.149863910675049 and perplexity is 63.42536819522566
At time: 215.2312366962433 and batch: 1100, loss is 4.183267140388489 and perplexity is 65.57976187761521
At time: 216.38312911987305 and batch: 1150, loss is 4.142520461082459 and perplexity is 62.961313168733966
At time: 217.53484916687012 and batch: 1200, loss is 4.202740726470947 and perplexity is 66.86935072253846
At time: 218.69424867630005 and batch: 1250, loss is 4.2080776977539065 and perplexity is 67.22718455213528
At time: 219.84479236602783 and batch: 1300, loss is 4.193977780342102 and perplexity is 66.28593814429492
At time: 220.99457478523254 and batch: 1350, loss is 4.080654797554016 and perplexity is 59.18421084124005
At time: 222.1451187133789 and batch: 1400, loss is 4.104103026390075 and perplexity is 60.58837399423454
At time: 223.29463148117065 and batch: 1450, loss is 4.046044783592224 and perplexity is 57.17088604561149
At time: 224.44369435310364 and batch: 1500, loss is 4.0404815769195555 and perplexity is 56.85371565112321
At time: 225.5952935218811 and batch: 1550, loss is 4.054915518760681 and perplexity is 57.680289887948845
At time: 226.74528551101685 and batch: 1600, loss is 4.139765934944153 and perplexity is 62.788123223529425
At time: 227.89691948890686 and batch: 1650, loss is 4.104341249465943 and perplexity is 60.60280926238798
At time: 229.04872632026672 and batch: 1700, loss is 4.115411553382874 and perplexity is 61.27742800678525
At time: 230.19945526123047 and batch: 1750, loss is 4.110748534202576 and perplexity is 60.99235535084696
At time: 231.3497748374939 and batch: 1800, loss is 4.062781600952149 and perplexity is 58.13579696838648
At time: 232.50100874900818 and batch: 1850, loss is 4.1107384204864506 and perplexity is 60.9917384945985
At time: 233.66074466705322 and batch: 1900, loss is 4.218766522407532 and perplexity is 67.94961824508765
At time: 234.81248354911804 and batch: 1950, loss is 4.141278400421142 and perplexity is 62.883159944032585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.423056810955669 and perplexity of 83.35068361940489
finished 5 epochs...
Completing Train Step...
At time: 238.47561764717102 and batch: 50, loss is 4.121804966926574 and perplexity is 61.67045499820055
At time: 239.59779143333435 and batch: 100, loss is 4.077151188850403 and perplexity is 58.97721535236225
At time: 240.7186894416809 and batch: 150, loss is 4.037387204170227 and perplexity is 56.6780609733982
At time: 241.83994793891907 and batch: 200, loss is 4.035946040153504 and perplexity is 56.59643742197565
At time: 242.9743139743805 and batch: 250, loss is 4.038810710906983 and perplexity is 56.75880002767998
At time: 244.1156620979309 and batch: 300, loss is 4.059104981422425 and perplexity is 57.92244620699569
At time: 245.26142477989197 and batch: 350, loss is 4.065582451820373 and perplexity is 58.298854909692615
At time: 246.40605235099792 and batch: 400, loss is 4.010185823440552 and perplexity is 55.15711909686698
At time: 247.55136632919312 and batch: 450, loss is 4.04200927734375 and perplexity is 56.94063747498872
At time: 248.69631147384644 and batch: 500, loss is 4.052854733467102 and perplexity is 57.561545590093715
At time: 249.84722018241882 and batch: 550, loss is 4.027566895484925 and perplexity is 56.12418896719812
At time: 250.99238777160645 and batch: 600, loss is 4.001094083786011 and perplexity is 54.65791767328279
At time: 252.13733100891113 and batch: 650, loss is 4.061033439636231 and perplexity is 58.03425499878781
At time: 253.28401923179626 and batch: 700, loss is 4.098747472763062 and perplexity is 60.26475705556652
At time: 254.428879737854 and batch: 750, loss is 4.06223955154419 and perplexity is 58.10429303317463
At time: 255.5741753578186 and batch: 800, loss is 4.055284900665283 and perplexity is 57.701599878805865
At time: 256.7196671962738 and batch: 850, loss is 4.0552098846435545 and perplexity is 57.69727149668661
At time: 257.8715612888336 and batch: 900, loss is 4.026334581375122 and perplexity is 56.05506893477534
At time: 259.05907130241394 and batch: 950, loss is 4.100226860046387 and perplexity is 60.353977950643696
At time: 260.20349383354187 and batch: 1000, loss is 4.068303761482238 and perplexity is 58.45772020963179
At time: 261.34831619262695 and batch: 1050, loss is 4.0346833515167235 and perplexity is 56.52501884276394
At time: 262.49349188804626 and batch: 1100, loss is 4.063680772781372 and perplexity is 58.188094548021475
At time: 263.63971424102783 and batch: 1150, loss is 4.0264466810226445 and perplexity is 56.06135304046123
At time: 264.78565549850464 and batch: 1200, loss is 4.08069905757904 and perplexity is 59.18683039386325
At time: 265.9306974411011 and batch: 1250, loss is 4.0904351282119755 and perplexity is 59.765891872699235
At time: 267.0770380496979 and batch: 1300, loss is 4.0706929683685305 and perplexity is 58.59755477765176
At time: 268.22313594818115 and batch: 1350, loss is 3.9649099349975585 and perplexity is 52.715521352275225
At time: 269.3849518299103 and batch: 1400, loss is 3.9901063013076783 and perplexity is 54.0606357741724
At time: 270.53796100616455 and batch: 1450, loss is 3.9302216148376465 and perplexity is 50.91826066098569
At time: 271.6897418498993 and batch: 1500, loss is 3.9246690177917483 and perplexity is 50.636315565404544
At time: 272.84273958206177 and batch: 1550, loss is 3.9419775676727293 and perplexity is 51.52038567380759
At time: 273.99340176582336 and batch: 1600, loss is 4.02557373046875 and perplexity is 56.01243560562983
At time: 275.1473603248596 and batch: 1650, loss is 3.9937254285812376 and perplexity is 54.25664256835326
At time: 276.2990052700043 and batch: 1700, loss is 4.003864369392395 and perplexity is 54.809545645310045
At time: 277.4515447616577 and batch: 1750, loss is 3.9988022089004516 and perplexity is 54.53279200542879
At time: 278.6026816368103 and batch: 1800, loss is 3.9495503664016725 and perplexity is 51.91202019807051
At time: 279.7559530735016 and batch: 1850, loss is 3.996976933479309 and perplexity is 54.43334542684274
At time: 280.90879583358765 and batch: 1900, loss is 4.108046197891236 and perplexity is 60.82775599584237
At time: 282.0614550113678 and batch: 1950, loss is 4.023608312606812 and perplexity is 55.902455877663854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429242653070494 and perplexity of 83.8678757737622
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 285.7260391712189 and batch: 50, loss is 4.054626054763794 and perplexity is 57.66359593696175
At time: 286.84463834762573 and batch: 100, loss is 4.038789758682251 and perplexity is 56.757610817004625
At time: 287.9905505180359 and batch: 150, loss is 4.006486458778381 and perplexity is 54.95344975546798
At time: 289.12333393096924 and batch: 200, loss is 4.0001579809188845 and perplexity is 54.606776180421264
At time: 290.2590079307556 and batch: 250, loss is 3.9987750101089476 and perplexity is 54.531308799559696
At time: 291.3938341140747 and batch: 300, loss is 4.0176205778121945 and perplexity is 55.56872693479935
At time: 292.5357549190521 and batch: 350, loss is 4.023613352775573 and perplexity is 55.90273763618571
At time: 293.68011379241943 and batch: 400, loss is 3.9658784532546996 and perplexity is 52.76660202943089
At time: 294.82528018951416 and batch: 450, loss is 3.991918683052063 and perplexity is 54.158703124433295
At time: 295.9704611301422 and batch: 500, loss is 4.002209272384643 and perplexity is 54.71890556007441
At time: 297.1171953678131 and batch: 550, loss is 3.9650367593765257 and perplexity is 52.72220738949996
At time: 298.2650876045227 and batch: 600, loss is 3.9242972898483277 and perplexity is 50.617496130028734
At time: 299.40870356559753 and batch: 650, loss is 3.9733530712127685 and perplexity is 53.1624899327787
At time: 300.5527894496918 and batch: 700, loss is 4.015765833854675 and perplexity is 55.46575669552331
At time: 301.69700860977173 and batch: 750, loss is 3.960116076469421 and perplexity is 52.46341536370254
At time: 302.8421552181244 and batch: 800, loss is 3.9545128202438353 and perplexity is 52.170271452147595
At time: 303.99377179145813 and batch: 850, loss is 3.951999349594116 and perplexity is 52.03930766183366
At time: 305.1473662853241 and batch: 900, loss is 3.9199842023849487 and perplexity is 50.39964857752952
At time: 306.29949951171875 and batch: 950, loss is 3.9990080642700194 and perplexity is 54.544019029012524
At time: 307.4516954421997 and batch: 1000, loss is 3.949769959449768 and perplexity is 51.923420968537755
At time: 308.60385966300964 and batch: 1050, loss is 3.9082385015487673 and perplexity is 49.81113241650308
At time: 309.7568345069885 and batch: 1100, loss is 3.9247641706466676 and perplexity is 50.641133984632724
At time: 310.9075620174408 and batch: 1150, loss is 3.8876015090942384 and perplexity is 48.7937147810633
At time: 312.06139373779297 and batch: 1200, loss is 3.931263651847839 and perplexity is 50.971347027264656
At time: 313.21384501457214 and batch: 1250, loss is 3.9313181924819944 and perplexity is 50.97412711266839
At time: 314.367094039917 and batch: 1300, loss is 3.9092514324188232 and perplexity is 49.861613212662355
At time: 315.5196051597595 and batch: 1350, loss is 3.799099369049072 and perplexity is 44.66094334693407
At time: 316.6705710887909 and batch: 1400, loss is 3.8161678218841555 and perplexity is 45.42977930672254
At time: 317.8238596916199 and batch: 1450, loss is 3.752464060783386 and perplexity is 42.62598572218239
At time: 318.9754898548126 and batch: 1500, loss is 3.7390296936035154 and perplexity is 42.05716202696569
At time: 320.12747263908386 and batch: 1550, loss is 3.7585608196258544 and perplexity is 42.88665990391633
At time: 321.28048634529114 and batch: 1600, loss is 3.8296036911010742 and perplexity is 46.04428685723558
At time: 322.4324905872345 and batch: 1650, loss is 3.7901889419555665 and perplexity is 44.26476295680361
At time: 323.5836639404297 and batch: 1700, loss is 3.7798280334472656 and perplexity is 43.80850748975994
At time: 324.7357301712036 and batch: 1750, loss is 3.7659570455551146 and perplexity is 43.20503526660339
At time: 325.88691210746765 and batch: 1800, loss is 3.7136324405670167 and perplexity is 41.00247540309513
At time: 327.03892612457275 and batch: 1850, loss is 3.7451459884643556 and perplexity is 42.315184296710186
At time: 328.19243335723877 and batch: 1900, loss is 3.8515295457839964 and perplexity is 47.064996271737364
At time: 329.348135471344 and batch: 1950, loss is 3.7725522327423096 and perplexity is 43.49092226449264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360436727834302 and perplexity of 78.29131895604472
finished 7 epochs...
Completing Train Step...
At time: 333.00644302368164 and batch: 50, loss is 3.9702325773239138 and perplexity is 52.996855273204005
At time: 334.15179657936096 and batch: 100, loss is 3.9394580221176145 and perplexity is 51.390741106365326
At time: 335.27604389190674 and batch: 150, loss is 3.898271179199219 and perplexity is 49.317114908928104
At time: 336.39761662483215 and batch: 200, loss is 3.889010901451111 and perplexity is 48.86253275411017
At time: 337.53072810173035 and batch: 250, loss is 3.885233497619629 and perplexity is 48.67830740150115
At time: 338.6733121871948 and batch: 300, loss is 3.906359648704529 and perplexity is 49.71763249249192
At time: 339.81770849227905 and batch: 350, loss is 3.912472014427185 and perplexity is 50.02245549093343
At time: 340.9641146659851 and batch: 400, loss is 3.8593340873718263 and perplexity is 47.433754113649556
At time: 342.1100392341614 and batch: 450, loss is 3.890915484428406 and perplexity is 48.9556841813741
At time: 343.2565770149231 and batch: 500, loss is 3.9045925426483152 and perplexity is 49.62985374303568
At time: 344.40717458724976 and batch: 550, loss is 3.868871431350708 and perplexity is 47.88831032675609
At time: 345.5847523212433 and batch: 600, loss is 3.833173813819885 and perplexity is 46.20896439641612
At time: 346.739426612854 and batch: 650, loss is 3.8840726518630984 and perplexity is 48.62183218077118
At time: 347.89454078674316 and batch: 700, loss is 3.927714219093323 and perplexity is 50.79074835960306
At time: 349.0487608909607 and batch: 750, loss is 3.876024308204651 and perplexity is 48.23207750973258
At time: 350.20181250572205 and batch: 800, loss is 3.871329107284546 and perplexity is 48.00614901990462
At time: 351.3558759689331 and batch: 850, loss is 3.873128685951233 and perplexity is 48.09261764175866
At time: 352.50975346565247 and batch: 900, loss is 3.8404140853881836 and perplexity is 46.544743948268646
At time: 353.6650357246399 and batch: 950, loss is 3.9226936674118043 and perplexity is 50.53638982687883
At time: 354.8179843425751 and batch: 1000, loss is 3.874221196174622 and perplexity is 48.1451880298161
At time: 355.97136330604553 and batch: 1050, loss is 3.837719225883484 and perplexity is 46.41948126112494
At time: 357.126656293869 and batch: 1100, loss is 3.855180778503418 and perplexity is 47.23715563174646
At time: 358.2797546386719 and batch: 1150, loss is 3.821893615722656 and perplexity is 45.69064698171885
At time: 359.43216848373413 and batch: 1200, loss is 3.8680508852005007 and perplexity is 47.849031875172486
At time: 360.5849041938782 and batch: 1250, loss is 3.872286467552185 and perplexity is 48.052130206347144
At time: 361.7388801574707 and batch: 1300, loss is 3.853033857345581 and perplexity is 47.13584996943164
At time: 362.89354133605957 and batch: 1350, loss is 3.7423547983169554 and perplexity is 42.197239251313384
At time: 364.0483434200287 and batch: 1400, loss is 3.7658375549316405 and perplexity is 43.19987297843082
At time: 365.2007694244385 and batch: 1450, loss is 3.702344832420349 and perplexity is 40.54225779208313
At time: 366.3553125858307 and batch: 1500, loss is 3.6921830415725707 and perplexity is 40.13236201270816
At time: 367.5080637931824 and batch: 1550, loss is 3.7170621395111083 and perplexity is 41.14334297829376
At time: 368.66183948516846 and batch: 1600, loss is 3.7907500886917114 and perplexity is 44.289608954536334
At time: 369.81870198249817 and batch: 1650, loss is 3.7532171869277953 and perplexity is 42.65810055820434
At time: 370.97150564193726 and batch: 1700, loss is 3.748110466003418 and perplexity is 42.440812829597796
At time: 372.1228392124176 and batch: 1750, loss is 3.7389819765090944 and perplexity is 42.05515522927383
At time: 373.2758276462555 and batch: 1800, loss is 3.6890867567062378 and perplexity is 40.008292963238745
At time: 374.428325176239 and batch: 1850, loss is 3.7260660982131957 and perplexity is 41.51546872772044
At time: 375.5831296443939 and batch: 1900, loss is 3.834700164794922 and perplexity is 46.27954934928008
At time: 376.73629999160767 and batch: 1950, loss is 3.759230079650879 and perplexity is 42.91537183779994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363580464207849 and perplexity of 78.53783350853557
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 380.40074849128723 and batch: 50, loss is 3.942054567337036 and perplexity is 51.52435287894421
At time: 381.54146432876587 and batch: 100, loss is 3.943523874282837 and perplexity is 51.60011361276359
At time: 382.6600139141083 and batch: 150, loss is 3.91832453250885 and perplexity is 50.316071173653725
At time: 383.78017807006836 and batch: 200, loss is 3.917227153778076 and perplexity is 50.26088567256727
At time: 384.9120533466339 and batch: 250, loss is 3.9111108875274656 and perplexity is 49.95441489762033
At time: 386.0463442802429 and batch: 300, loss is 3.9276584815979003 and perplexity is 50.78791748939239
At time: 387.18192315101624 and batch: 350, loss is 3.9372885036468506 and perplexity is 51.27936880013059
At time: 388.32870507240295 and batch: 400, loss is 3.8821056413650514 and perplexity is 48.52628652689598
At time: 389.4704792499542 and batch: 450, loss is 3.9153437662124633 and perplexity is 50.166314030936796
At time: 390.6137933731079 and batch: 500, loss is 3.926871671676636 and perplexity is 50.74797276854343
At time: 391.7586667537689 and batch: 550, loss is 3.894271955490112 and perplexity is 49.12027859229822
At time: 392.9105215072632 and batch: 600, loss is 3.8497780704498292 and perplexity is 46.98263523937776
At time: 394.0617563724518 and batch: 650, loss is 3.8915815353393555 and perplexity is 48.98830202078425
At time: 395.21132373809814 and batch: 700, loss is 3.935994019508362 and perplexity is 51.213031416196166
At time: 396.36364102363586 and batch: 750, loss is 3.8749937295913695 and perplexity is 48.18239616683883
At time: 397.5152814388275 and batch: 800, loss is 3.865160117149353 and perplexity is 47.71091115621443
At time: 398.6749303340912 and batch: 850, loss is 3.870244698524475 and perplexity is 47.95411894740207
At time: 399.8333640098572 and batch: 900, loss is 3.8321644401550294 and perplexity is 46.162345816415645
At time: 400.98529624938965 and batch: 950, loss is 3.9257104349136354 and perplexity is 50.689076559756586
At time: 402.1358561515808 and batch: 1000, loss is 3.870992741584778 and perplexity is 47.99000411344497
At time: 403.31751537323 and batch: 1050, loss is 3.8267259311676027 and perplexity is 45.911972928527064
At time: 404.46859645843506 and batch: 1100, loss is 3.8419342184066774 and perplexity is 46.61555195554137
At time: 405.6204483509064 and batch: 1150, loss is 3.812945008277893 and perplexity is 45.28360327142283
At time: 406.76977586746216 and batch: 1200, loss is 3.853841094970703 and perplexity is 47.17391516278016
At time: 407.9282748699188 and batch: 1250, loss is 3.8484863471984863 and perplexity is 46.9219858565717
At time: 409.0796055793762 and batch: 1300, loss is 3.823419098854065 and perplexity is 45.760400483320694
At time: 410.23011541366577 and batch: 1350, loss is 3.7127513885498047 and perplexity is 40.96636599889809
At time: 411.3835072517395 and batch: 1400, loss is 3.7317512464523315 and perplexity is 41.752162503743875
At time: 412.53530502319336 and batch: 1450, loss is 3.6557534170150756 and perplexity is 38.696664860818686
At time: 413.6958155632019 and batch: 1500, loss is 3.648191714286804 and perplexity is 38.4051557262984
At time: 414.8473496437073 and batch: 1550, loss is 3.677516760826111 and perplexity is 39.548064731872316
At time: 415.9984896183014 and batch: 1600, loss is 3.75038094997406 and perplexity is 42.53728349093054
At time: 417.1504464149475 and batch: 1650, loss is 3.711010427474976 and perplexity is 40.89510719771483
At time: 418.3018639087677 and batch: 1700, loss is 3.6968079900741575 and perplexity is 40.318402001328806
At time: 419.45529103279114 and batch: 1750, loss is 3.682725534439087 and perplexity is 39.75459907625126
At time: 420.6075279712677 and batch: 1800, loss is 3.6311392688751223 and perplexity is 37.75580613900919
At time: 421.7685115337372 and batch: 1850, loss is 3.661634373664856 and perplexity is 38.92490875775803
At time: 422.91881489753723 and batch: 1900, loss is 3.7768272161483765 and perplexity is 43.67724321120691
At time: 424.07097721099854 and batch: 1950, loss is 3.7104115962982176 and perplexity is 40.87062526355229
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331735442405523 and perplexity of 76.07619793373748
finished 9 epochs...
Completing Train Step...
At time: 427.73558139801025 and batch: 50, loss is 3.930322275161743 and perplexity is 50.92338636757957
At time: 428.8931682109833 and batch: 100, loss is 3.910941252708435 and perplexity is 49.945941608192165
At time: 430.01609206199646 and batch: 150, loss is 3.8776099777221678 and perplexity is 48.308618312978034
At time: 431.1619758605957 and batch: 200, loss is 3.870523509979248 and perplexity is 47.96749096911794
At time: 432.2916865348816 and batch: 250, loss is 3.8644308996200563 and perplexity is 47.67613220571195
At time: 433.430025100708 and batch: 300, loss is 3.8780875158309938 and perplexity is 48.33169302829667
At time: 434.56652307510376 and batch: 350, loss is 3.888927812576294 and perplexity is 48.858472989905884
At time: 435.7032780647278 and batch: 400, loss is 3.8337868642807007 and perplexity is 46.23730150848546
At time: 436.8398160934448 and batch: 450, loss is 3.867161259651184 and perplexity is 47.8064830829588
At time: 437.98196506500244 and batch: 500, loss is 3.8804150772094728 and perplexity is 48.44431903146709
At time: 439.14254331588745 and batch: 550, loss is 3.8485195875167846 and perplexity is 46.92354558423954
At time: 440.2949423789978 and batch: 600, loss is 3.805856475830078 and perplexity is 44.96374398607827
At time: 441.448121547699 and batch: 650, loss is 3.8508636808395384 and perplexity is 47.03366777204135
At time: 442.60210061073303 and batch: 700, loss is 3.8959330463409425 and perplexity is 49.20193964209271
At time: 443.7553265094757 and batch: 750, loss is 3.8390208864212036 and perplexity is 46.47994300986336
At time: 444.90987753868103 and batch: 800, loss is 3.830409593582153 and perplexity is 46.08140901866517
At time: 446.064466714859 and batch: 850, loss is 3.837376012802124 and perplexity is 46.40355222160992
At time: 447.2180461883545 and batch: 900, loss is 3.799909553527832 and perplexity is 44.697141611696615
At time: 448.3738250732422 and batch: 950, loss is 3.8951656341552736 and perplexity is 49.164195958386564
At time: 449.5261380672455 and batch: 1000, loss is 3.8412438821792603 and perplexity is 46.5833826563593
At time: 450.6804828643799 and batch: 1050, loss is 3.79873441696167 and perplexity is 44.64464721626859
At time: 451.8333284854889 and batch: 1100, loss is 3.8147859621047973 and perplexity is 45.36704507685075
At time: 452.9860107898712 and batch: 1150, loss is 3.787272644042969 and perplexity is 44.1358617694793
At time: 454.13971853256226 and batch: 1200, loss is 3.8299208450317384 and perplexity is 46.05889229976131
At time: 455.29191160202026 and batch: 1250, loss is 3.8272092151641846 and perplexity is 45.9341668128375
At time: 456.44422125816345 and batch: 1300, loss is 3.8048077774047853 and perplexity is 44.91661529477621
At time: 457.59658002853394 and batch: 1350, loss is 3.6950449419021605 and perplexity is 40.24738134120138
At time: 458.7505738735199 and batch: 1400, loss is 3.7172113847732544 and perplexity is 41.14948388554138
At time: 459.9029748439789 and batch: 1450, loss is 3.642834105491638 and perplexity is 38.199946133419935
At time: 461.05551862716675 and batch: 1500, loss is 3.637992057800293 and perplexity is 38.015427257543735
At time: 462.2094326019287 and batch: 1550, loss is 3.6691115427017214 and perplexity is 39.21704770535561
At time: 463.3617699146271 and batch: 1600, loss is 3.7445238494873045 and perplexity is 42.288866558732266
At time: 464.51573276519775 and batch: 1650, loss is 3.7063848686218264 and perplexity is 40.706381290456456
At time: 465.6684498786926 and batch: 1700, loss is 3.6945106983184814 and perplexity is 40.225885178564724
At time: 466.82136034965515 and batch: 1750, loss is 3.682595844268799 and perplexity is 39.749443629839924
At time: 467.9733340740204 and batch: 1800, loss is 3.6329675483703614 and perplexity is 37.82489744506303
At time: 469.1277096271515 and batch: 1850, loss is 3.6643588066101076 and perplexity is 39.03110165359555
At time: 470.2792851924896 and batch: 1900, loss is 3.77977153301239 and perplexity is 43.80603235995913
At time: 471.4319899082184 and batch: 1950, loss is 3.7135852670669554 and perplexity is 41.00054121844068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331292866551599 and perplexity of 76.04253589502586
finished 10 epochs...
Completing Train Step...
At time: 475.1142065525055 and batch: 50, loss is 3.9122787427902224 and perplexity is 50.01278850328316
At time: 476.2352430820465 and batch: 100, loss is 3.8904988861083982 and perplexity is 48.93529357323077
At time: 477.3575620651245 and batch: 150, loss is 3.856412034034729 and perplexity is 47.295352461133334
At time: 478.4786744117737 and batch: 200, loss is 3.8479688358306885 and perplexity is 46.89770947768411
At time: 479.61701250076294 and batch: 250, loss is 3.8417122888565065 and perplexity is 46.605207734951485
At time: 480.76136088371277 and batch: 300, loss is 3.8553433084487914 and perplexity is 47.244833708012635
At time: 481.9061903953552 and batch: 350, loss is 3.865733470916748 and perplexity is 47.73827423048296
At time: 483.0574667453766 and batch: 400, loss is 3.810694794654846 and perplexity is 45.18182005038406
At time: 484.20515513420105 and batch: 450, loss is 3.8444428730010984 and perplexity is 46.732641080805266
At time: 485.35143756866455 and batch: 500, loss is 3.858319387435913 and perplexity is 47.38564749740813
At time: 486.4975664615631 and batch: 550, loss is 3.8263613414764404 and perplexity is 45.89523694756485
At time: 487.6419541835785 and batch: 600, loss is 3.7844570779800417 and perplexity is 44.01176911243781
At time: 488.81383442878723 and batch: 650, loss is 3.8304367733001707 and perplexity is 46.082661515389326
At time: 489.96873712539673 and batch: 700, loss is 3.875738296508789 and perplexity is 48.21828454401787
At time: 491.1228744983673 and batch: 750, loss is 3.8201325845718386 and perplexity is 45.61025513613134
At time: 492.27553391456604 and batch: 800, loss is 3.81189537525177 and perplexity is 45.23609704230238
At time: 493.42883467674255 and batch: 850, loss is 3.819634294509888 and perplexity is 45.5875336606868
At time: 494.5827763080597 and batch: 900, loss is 3.7823885917663573 and perplexity is 43.920825465055515
At time: 495.7353632450104 and batch: 950, loss is 3.878017449378967 and perplexity is 48.328306716680544
At time: 496.88911652565 and batch: 1000, loss is 3.8243219518661498 and perplexity is 45.80173405499338
At time: 498.04466485977173 and batch: 1050, loss is 3.7829395866394044 and perplexity is 43.945032283010626
At time: 499.19680428504944 and batch: 1100, loss is 3.7990791273117064 and perplexity is 44.660039340997685
At time: 500.3510112762451 and batch: 1150, loss is 3.772289237976074 and perplexity is 43.479485883478425
At time: 501.50269985198975 and batch: 1200, loss is 3.815757641792297 and perplexity is 45.411148736879035
At time: 502.65723609924316 and batch: 1250, loss is 3.8138872528076173 and perplexity is 45.32629160715863
At time: 503.8099367618561 and batch: 1300, loss is 3.7924152612686157 and perplexity is 44.36342023401315
At time: 504.96515798568726 and batch: 1350, loss is 3.682814211845398 and perplexity is 39.75812456729968
At time: 506.11710691452026 and batch: 1400, loss is 3.7062886095047 and perplexity is 40.702463118714924
At time: 507.2707931995392 and batch: 1450, loss is 3.632269973754883 and perplexity is 37.798520957625904
At time: 508.4265067577362 and batch: 1500, loss is 3.6284154081344604 and perplexity is 37.653104516892185
At time: 509.58720445632935 and batch: 1550, loss is 3.6602548694610597 and perplexity is 38.87124870313952
At time: 510.74112129211426 and batch: 1600, loss is 3.7370583486557005 and perplexity is 41.9743345207011
At time: 511.8941881656647 and batch: 1650, loss is 3.6993823528289793 and perplexity is 40.42232991044701
At time: 513.0478115081787 and batch: 1700, loss is 3.6885690259933472 and perplexity is 39.98758480228938
At time: 514.2008292675018 and batch: 1750, loss is 3.6775446271896364 and perplexity is 39.54916680797622
At time: 515.3565545082092 and batch: 1800, loss is 3.6285497188568114 and perplexity is 37.65816207219296
At time: 516.5090143680573 and batch: 1850, loss is 3.660331673622131 and perplexity is 38.874234291437304
At time: 517.6628239154816 and batch: 1900, loss is 3.775774736404419 and perplexity is 43.63129797990902
At time: 518.815833568573 and batch: 1950, loss is 3.709508514404297 and perplexity is 40.83373240302809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3328156227289245 and perplexity of 76.15841834426502
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 522.4810147285461 and batch: 50, loss is 3.9070876359939577 and perplexity is 49.75383947451926
At time: 523.5988874435425 and batch: 100, loss is 3.9038454341888427 and perplexity is 49.592788706986916
At time: 524.7147014141083 and batch: 150, loss is 3.8824684715270994 and perplexity is 48.54389652182559
At time: 525.8320169448853 and batch: 200, loss is 3.883681893348694 and perplexity is 48.6028364974648
At time: 526.959282875061 and batch: 250, loss is 3.8822804737091063 and perplexity is 48.534771232996675
At time: 528.0968227386475 and batch: 300, loss is 3.8893712854385374 and perplexity is 48.88014520193132
At time: 529.2424740791321 and batch: 350, loss is 3.8997565698623657 and perplexity is 49.39042452417707
At time: 530.3932330608368 and batch: 400, loss is 3.849625029563904 and perplexity is 46.975445525431745
At time: 531.5422537326813 and batch: 450, loss is 3.885373983383179 and perplexity is 48.685146491070874
At time: 532.6937983036041 and batch: 500, loss is 3.8987402582168578 and perplexity is 49.340253959339606
At time: 533.8442583084106 and batch: 550, loss is 3.872095422744751 and perplexity is 48.04295097323542
At time: 534.9971811771393 and batch: 600, loss is 3.8237379360198975 and perplexity is 45.77499292590106
At time: 536.1480967998505 and batch: 650, loss is 3.8560407638549803 and perplexity is 47.27779636635271
At time: 537.300892829895 and batch: 700, loss is 3.8973276901245115 and perplexity is 49.27060669326215
At time: 538.4523096084595 and batch: 750, loss is 3.8403741836547853 and perplexity is 46.542886769357104
At time: 539.6041026115417 and batch: 800, loss is 3.8273331689834595 and perplexity is 45.939860881142636
At time: 540.7539458274841 and batch: 850, loss is 3.8318708419799803 and perplexity is 46.14879462532779
At time: 541.9054892063141 and batch: 900, loss is 3.7895346879959106 and perplexity is 44.23581203202717
At time: 543.057092666626 and batch: 950, loss is 3.893228850364685 and perplexity is 49.06906769175601
At time: 544.2075939178467 and batch: 1000, loss is 3.842259225845337 and perplexity is 46.63070481894743
At time: 545.4019243717194 and batch: 1050, loss is 3.80037052154541 and perplexity is 44.71775031406817
At time: 546.5474891662598 and batch: 1100, loss is 3.813554048538208 and perplexity is 45.31119120917688
At time: 547.6914234161377 and batch: 1150, loss is 3.790154662132263 and perplexity is 44.26324559455848
At time: 548.8355748653412 and batch: 1200, loss is 3.8303053903579714 and perplexity is 46.07660743744505
At time: 549.9807567596436 and batch: 1250, loss is 3.8273527240753173 and perplexity is 45.94075924812589
At time: 551.1239192485809 and batch: 1300, loss is 3.8000160789489748 and perplexity is 44.70190324714379
At time: 552.2682983875275 and batch: 1350, loss is 3.685098795890808 and perplexity is 39.8490591786913
At time: 553.4114348888397 and batch: 1400, loss is 3.7054690599441527 and perplexity is 40.66911909835773
At time: 554.5559532642365 and batch: 1450, loss is 3.6246790933609008 and perplexity is 37.512683158770145
At time: 555.6987929344177 and batch: 1500, loss is 3.620114731788635 and perplexity is 37.34185187374692
At time: 556.8432626724243 and batch: 1550, loss is 3.6518147945404054 and perplexity is 38.54455305902297
At time: 557.999321937561 and batch: 1600, loss is 3.72614866733551 and perplexity is 41.518896765058834
At time: 559.1516871452332 and batch: 1650, loss is 3.6873619508743287 and perplexity is 39.93934590344931
At time: 560.3025670051575 and batch: 1700, loss is 3.681116194725037 and perplexity is 39.690671875230905
At time: 561.4554269313812 and batch: 1750, loss is 3.668778491020203 and perplexity is 39.20398857647628
At time: 562.604371547699 and batch: 1800, loss is 3.6164221239089964 and perplexity is 37.204217328871344
At time: 563.7568166255951 and batch: 1850, loss is 3.6437524795532226 and perplexity is 38.235044087161114
At time: 564.9068291187286 and batch: 1900, loss is 3.7608400201797485 and perplexity is 42.984518680450144
At time: 566.0588552951813 and batch: 1950, loss is 3.6997158575057982 and perplexity is 40.43581319476428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318774697946948 and perplexity of 75.0965559311566
finished 12 epochs...
Completing Train Step...
At time: 569.7533717155457 and batch: 50, loss is 3.915860123634338 and perplexity is 50.19222446846244
At time: 570.8737440109253 and batch: 100, loss is 3.8939623260498046 and perplexity is 49.10507186227708
At time: 571.9972608089447 and batch: 150, loss is 3.8639998626708985 and perplexity is 47.65558645944436
At time: 573.1336040496826 and batch: 200, loss is 3.857866587638855 and perplexity is 47.364196142788856
At time: 574.289457321167 and batch: 250, loss is 3.856510558128357 and perplexity is 47.300012422422846
At time: 575.425539970398 and batch: 300, loss is 3.863983702659607 and perplexity is 47.654816350851576
At time: 576.5674257278442 and batch: 350, loss is 3.875368299484253 and perplexity is 48.20044722228981
At time: 577.7177891731262 and batch: 400, loss is 3.824002537727356 and perplexity is 45.787106669776136
At time: 578.873309135437 and batch: 450, loss is 3.861510591506958 and perplexity is 47.537106308062256
At time: 580.0278272628784 and batch: 500, loss is 3.875738515853882 and perplexity is 48.218295120463125
At time: 581.1889269351959 and batch: 550, loss is 3.849677629470825 and perplexity is 46.977916494479764
At time: 582.3416879177094 and batch: 600, loss is 3.8028757858276365 and perplexity is 44.82992054608114
At time: 583.4967927932739 and batch: 650, loss is 3.8368528175354 and perplexity is 46.379280452719364
At time: 584.6571991443634 and batch: 700, loss is 3.8784940910339354 and perplexity is 48.35134749143608
At time: 585.8119518756866 and batch: 750, loss is 3.824575023651123 and perplexity is 45.813326648402835
At time: 586.9722309112549 and batch: 800, loss is 3.812048873901367 and perplexity is 45.243041255061435
At time: 588.125182390213 and batch: 850, loss is 3.818139510154724 and perplexity is 45.51944103315622
At time: 589.2787969112396 and batch: 900, loss is 3.776128554344177 and perplexity is 43.646738247229955
At time: 590.4326727390289 and batch: 950, loss is 3.880309510231018 and perplexity is 48.439205181015254
At time: 591.5880787372589 and batch: 1000, loss is 3.8301257848739625 and perplexity is 46.06833256919286
At time: 592.743326663971 and batch: 1050, loss is 3.7886268949508666 and perplexity is 44.195673291114026
At time: 593.8958835601807 and batch: 1100, loss is 3.8027651166915892 and perplexity is 44.824959532025865
At time: 595.0508368015289 and batch: 1150, loss is 3.780171732902527 and perplexity is 43.823567037750955
At time: 596.2058691978455 and batch: 1200, loss is 3.820743007659912 and perplexity is 45.63810518821197
At time: 597.3658900260925 and batch: 1250, loss is 3.8188645219802857 and perplexity is 45.552455132558315
At time: 598.5219166278839 and batch: 1300, loss is 3.7933236455917356 and perplexity is 44.4037375785232
At time: 599.6795401573181 and batch: 1350, loss is 3.6795560264587404 and perplexity is 39.62879602941985
At time: 600.8341875076294 and batch: 1400, loss is 3.7015175104141234 and perplexity is 40.50873016101552
At time: 601.9895198345184 and batch: 1450, loss is 3.6217614364624025 and perplexity is 37.40339353231639
At time: 603.1467826366425 and batch: 1500, loss is 3.6195202827453614 and perplexity is 37.3196606420582
At time: 604.3006703853607 and batch: 1550, loss is 3.6526870727539062 and perplexity is 38.57818930085322
At time: 605.4527056217194 and batch: 1600, loss is 3.7284842681884767 and perplexity is 41.61598166741448
At time: 606.6070940494537 and batch: 1650, loss is 3.6901139068603515 and perplexity is 40.04940859987314
At time: 607.7608070373535 and batch: 1700, loss is 3.6845858526229858 and perplexity is 39.828624113519155
At time: 608.9145667552948 and batch: 1750, loss is 3.6732666873931885 and perplexity is 39.380339227956476
At time: 610.0672843456268 and batch: 1800, loss is 3.621535954475403 and perplexity is 37.39496069158477
At time: 611.2186238765717 and batch: 1850, loss is 3.649372959136963 and perplexity is 38.45054842338629
At time: 612.374324798584 and batch: 1900, loss is 3.766448736190796 and perplexity is 43.22628400133211
At time: 613.5275473594666 and batch: 1950, loss is 3.7044996070861815 and perplexity is 40.629711409651286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3173390942950585 and perplexity of 74.98882438961728
finished 13 epochs...
Completing Train Step...
At time: 617.1844420433044 and batch: 50, loss is 3.911364631652832 and perplexity is 49.96709214525726
At time: 618.3284134864807 and batch: 100, loss is 3.8872959852218627 and perplexity is 48.77880941346456
At time: 619.4484841823578 and batch: 150, loss is 3.8564580726623534 and perplexity is 47.29752992437699
At time: 620.580486536026 and batch: 200, loss is 3.8489225625991823 and perplexity is 46.94245841433144
At time: 621.7197985649109 and batch: 250, loss is 3.8472860050201416 and perplexity is 46.86569720743472
At time: 622.8709015846252 and batch: 300, loss is 3.8547081661224367 and perplexity is 47.21483604182527
At time: 624.0236279964447 and batch: 350, loss is 3.8660706233978273 and perplexity is 47.754372021634836
At time: 625.1706819534302 and batch: 400, loss is 3.8141851234436035 and perplexity is 45.33979498949725
At time: 626.3235950469971 and batch: 450, loss is 3.8519698715209962 and perplexity is 47.08572476421706
At time: 627.471025466919 and batch: 500, loss is 3.866196827888489 and perplexity is 47.76039921815432
At time: 628.616352558136 and batch: 550, loss is 3.839946689605713 and perplexity is 46.52299421451391
At time: 629.7741897106171 and batch: 600, loss is 3.793728666305542 and perplexity is 44.42172565453872
At time: 630.9184911251068 and batch: 650, loss is 3.828334970474243 and perplexity is 45.985906562725
At time: 632.1030297279358 and batch: 700, loss is 3.8701647520065308 and perplexity is 47.950285335815124
At time: 633.2451114654541 and batch: 750, loss is 3.8171119117736816 and perplexity is 45.472689354333305
At time: 634.3987619876862 and batch: 800, loss is 3.804863076210022 and perplexity is 44.91909919861511
At time: 635.5603270530701 and batch: 850, loss is 3.8112899398803712 and perplexity is 45.20871779810672
At time: 636.7114970684052 and batch: 900, loss is 3.76941810131073 and perplexity is 43.354829375935786
At time: 637.8672165870667 and batch: 950, loss is 3.873845586776733 and perplexity is 48.12710764052362
At time: 639.025431394577 and batch: 1000, loss is 3.8239783954620363 and perplexity is 45.78600127864207
At time: 640.1797189712524 and batch: 1050, loss is 3.7827258777618407 and perplexity is 43.93564184293286
At time: 641.3326990604401 and batch: 1100, loss is 3.797242007255554 and perplexity is 44.57806880492799
At time: 642.4869711399078 and batch: 1150, loss is 3.775162434577942 and perplexity is 43.60459063377718
At time: 643.6393604278564 and batch: 1200, loss is 3.8159313583374024 and perplexity is 45.41903808998261
At time: 644.7941687107086 and batch: 1250, loss is 3.8145144414901733 and perplexity is 45.35472866104387
At time: 645.9471626281738 and batch: 1300, loss is 3.7897975206375123 and perplexity is 44.24744017541782
At time: 647.1080429553986 and batch: 1350, loss is 3.676299662590027 and perplexity is 39.49996013199668
At time: 648.2610249519348 and batch: 1400, loss is 3.6989522886276247 and perplexity is 40.404949451041766
At time: 649.417521238327 and batch: 1450, loss is 3.6197140073776244 and perplexity is 37.32689107992661
At time: 650.5769820213318 and batch: 1500, loss is 3.6183428049087523 and perplexity is 37.27574342962864
At time: 651.7304532527924 and batch: 1550, loss is 3.652005033493042 and perplexity is 38.55188643195124
At time: 652.8838238716125 and batch: 1600, loss is 3.7285130071640014 and perplexity is 41.61717768527914
At time: 654.0358383655548 and batch: 1650, loss is 3.690314702987671 and perplexity is 40.057451173453224
At time: 655.1898982524872 and batch: 1700, loss is 3.6850068759918213 and perplexity is 39.84539642553941
At time: 656.3433463573456 and batch: 1750, loss is 3.673969473838806 and perplexity is 39.408024924016146
At time: 657.4972956180573 and batch: 1800, loss is 3.622481174468994 and perplexity is 37.43032386644706
At time: 658.6511664390564 and batch: 1850, loss is 3.6504453468322753 and perplexity is 38.491804435659745
At time: 659.80446600914 and batch: 1900, loss is 3.767495951652527 and perplexity is 43.27157494484057
At time: 660.9575409889221 and batch: 1950, loss is 3.704931445121765 and perplexity is 40.647260653355495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317158827670785 and perplexity of 74.97530762573365
finished 14 epochs...
Completing Train Step...
At time: 664.6060886383057 and batch: 50, loss is 3.906277446746826 and perplexity is 49.71354577373913
At time: 665.7512159347534 and batch: 100, loss is 3.8814440107345582 and perplexity is 48.49419066831812
At time: 666.8727989196777 and batch: 150, loss is 3.850268678665161 and perplexity is 47.00569096140501
At time: 668.0003561973572 and batch: 200, loss is 3.842253174781799 and perplexity is 46.63042265444345
At time: 669.1366009712219 and batch: 250, loss is 3.8405159521102905 and perplexity is 46.54948555026758
At time: 670.272093296051 and batch: 300, loss is 3.84789888381958 and perplexity is 46.89442900332899
At time: 671.4092948436737 and batch: 350, loss is 3.8591608095169065 and perplexity is 47.425535606549154
At time: 672.5545873641968 and batch: 400, loss is 3.807104063034058 and perplexity is 45.019875184720355
At time: 673.7042555809021 and batch: 450, loss is 3.845107326507568 and perplexity is 46.76370306651784
At time: 674.8583490848541 and batch: 500, loss is 3.8594450998306273 and perplexity is 47.439020143615934
At time: 676.0140376091003 and batch: 550, loss is 3.8330302000045777 and perplexity is 46.20232862724321
At time: 677.165833234787 and batch: 600, loss is 3.7872043657302856 and perplexity is 44.13284835018562
At time: 678.3204476833344 and batch: 650, loss is 3.822164649963379 and perplexity is 45.7030323898907
At time: 679.4744584560394 and batch: 700, loss is 3.8641089248657225 and perplexity is 47.660784165730725
At time: 680.6299088001251 and batch: 750, loss is 3.811564354896545 and perplexity is 45.22112545147783
At time: 681.7834508419037 and batch: 800, loss is 3.7995292568206787 and perplexity is 44.68014666768797
At time: 682.9370224475861 and batch: 850, loss is 3.806133108139038 and perplexity is 44.97618413099031
At time: 684.0910143852234 and batch: 900, loss is 3.7643280124664305 and perplexity is 43.134710131094785
At time: 685.2436897754669 and batch: 950, loss is 3.8689030027389526 and perplexity is 47.889822251060444
At time: 686.398698091507 and batch: 1000, loss is 3.819219584465027 and perplexity is 45.56863197218823
At time: 687.551215171814 and batch: 1050, loss is 3.7781670188903806 and perplexity is 43.73580132082271
At time: 688.7131879329681 and batch: 1100, loss is 3.79287549495697 and perplexity is 44.383842473676324
At time: 689.9044148921967 and batch: 1150, loss is 3.771171770095825 and perplexity is 43.43092609161093
At time: 691.0514166355133 and batch: 1200, loss is 3.812047438621521 and perplexity is 45.24297631868275
At time: 692.1977939605713 and batch: 1250, loss is 3.8108780431747435 and perplexity is 45.190100310684116
At time: 693.3442049026489 and batch: 1300, loss is 3.7866744804382324 and perplexity is 44.10946919763001
At time: 694.490199804306 and batch: 1350, loss is 3.6732928276062013 and perplexity is 39.381368651867035
At time: 695.6354506015778 and batch: 1400, loss is 3.6963667058944703 and perplexity is 40.300614053434
At time: 696.780837059021 and batch: 1450, loss is 3.617475638389587 and perplexity is 37.243433164164415
At time: 697.927375793457 and batch: 1500, loss is 3.616587324142456 and perplexity is 37.210363981960036
At time: 699.0726165771484 and batch: 1550, loss is 3.6504560804367063 and perplexity is 38.49221759367973
At time: 700.2183957099915 and batch: 1600, loss is 3.7274777555465697 and perplexity is 41.57411572859362
At time: 701.3647317886353 and batch: 1650, loss is 3.689396276473999 and perplexity is 40.020678237429976
At time: 702.5168254375458 and batch: 1700, loss is 3.684240288734436 and perplexity is 39.814863157076644
At time: 703.6692979335785 and batch: 1750, loss is 3.673330898284912 and perplexity is 39.38286795583975
At time: 704.8234488964081 and batch: 1800, loss is 3.6220155143737793 and perplexity is 37.412898115824724
At time: 705.9776511192322 and batch: 1850, loss is 3.650080485343933 and perplexity is 38.47776282038247
At time: 707.1309225559235 and batch: 1900, loss is 3.7671712923049925 and perplexity is 43.2575287037973
At time: 708.285165309906 and batch: 1950, loss is 3.7041468238830566 and perplexity is 40.61538045792631
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317395871184593 and perplexity of 74.99308214268582
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 711.9316244125366 and batch: 50, loss is 3.906017389297485 and perplexity is 49.7006190767423
At time: 713.0773606300354 and batch: 100, loss is 3.8887464094161985 and perplexity is 48.84961071235495
At time: 714.1983652114868 and batch: 150, loss is 3.8621758127212527 and perplexity is 47.56873952001986
At time: 715.3318099975586 and batch: 200, loss is 3.857485694885254 and perplexity is 47.346158899043715
At time: 716.4692580699921 and batch: 250, loss is 3.8594215154647826 and perplexity is 47.437901337602774
At time: 717.6396934986115 and batch: 300, loss is 3.8653504753112795 and perplexity is 47.719994182052595
At time: 718.7901957035065 and batch: 350, loss is 3.8775679063796997 and perplexity is 48.30658594730531
At time: 719.9408221244812 and batch: 400, loss is 3.829060797691345 and perplexity is 46.01929650150862
At time: 721.0901947021484 and batch: 450, loss is 3.869559922218323 and perplexity is 47.92129234368745
At time: 722.2393367290497 and batch: 500, loss is 3.887751808166504 and perplexity is 48.801048982275304
At time: 723.389452457428 and batch: 550, loss is 3.8642572212219237 and perplexity is 47.66785261045554
At time: 724.5465166568756 and batch: 600, loss is 3.818703393936157 and perplexity is 45.54511594584783
At time: 725.6951718330383 and batch: 650, loss is 3.847504458427429 and perplexity is 46.875936297015876
At time: 726.8454191684723 and batch: 700, loss is 3.8844579076766967 and perplexity is 48.640567633025846
At time: 727.9942193031311 and batch: 750, loss is 3.833028073310852 and perplexity is 46.2022303691453
At time: 729.1512219905853 and batch: 800, loss is 3.8189408731460572 and perplexity is 45.55593324838885
At time: 730.3051927089691 and batch: 850, loss is 3.8212878704071045 and perplexity is 45.662978467227695
At time: 731.4554734230042 and batch: 900, loss is 3.773508768081665 and perplexity is 43.532542771149096
At time: 732.6049544811249 and batch: 950, loss is 3.8800792026519777 and perplexity is 48.428050549486784
At time: 733.7536199092865 and batch: 1000, loss is 3.832294030189514 and perplexity is 46.16832838403409
At time: 734.9020538330078 and batch: 1050, loss is 3.791042490005493 and perplexity is 44.302561187914264
At time: 736.0517115592957 and batch: 1100, loss is 3.801506824493408 and perplexity is 44.768592105946375
At time: 737.2013208866119 and batch: 1150, loss is 3.7804314374923704 and perplexity is 43.83494969725446
At time: 738.351343870163 and batch: 1200, loss is 3.818063807487488 and perplexity is 45.51599522048916
At time: 739.5002644062042 and batch: 1250, loss is 3.8192145299911497 and perplexity is 45.56840164731039
At time: 740.6488840579987 and batch: 1300, loss is 3.792345323562622 and perplexity is 44.36031766666644
At time: 741.7995705604553 and batch: 1350, loss is 3.671065330505371 and perplexity is 39.2937443949881
At time: 742.9496669769287 and batch: 1400, loss is 3.6947260332107543 and perplexity is 40.234548147902544
At time: 744.1000788211823 and batch: 1450, loss is 3.61428870677948 and perplexity is 37.124929821068214
At time: 745.2505986690521 and batch: 1500, loss is 3.6122107696533203 and perplexity is 37.047866645032975
At time: 746.3990657329559 and batch: 1550, loss is 3.643584966659546 and perplexity is 38.22863976070482
At time: 747.5493302345276 and batch: 1600, loss is 3.7189217901229856 and perplexity is 41.21992640837862
At time: 748.7002098560333 and batch: 1650, loss is 3.6831103229522704 and perplexity is 39.769899132776246
At time: 749.8479726314545 and batch: 1700, loss is 3.6801134824752806 and perplexity is 39.650893498806084
At time: 750.9961297512054 and batch: 1750, loss is 3.6684902811050417 and perplexity is 39.19269122633704
At time: 752.14466547966 and batch: 1800, loss is 3.6154877042770384 and perplexity is 37.169469214995836
At time: 753.2927629947662 and batch: 1850, loss is 3.6450732517242432 and perplexity is 38.285577233389816
At time: 754.4407262802124 and batch: 1900, loss is 3.763940625190735 and perplexity is 43.11800352942057
At time: 755.5883507728577 and batch: 1950, loss is 3.7034076499938964 and perplexity is 40.58536972213608
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312123285337936 and perplexity of 74.59871525942813
finished 16 epochs...
Completing Train Step...
At time: 759.251900434494 and batch: 50, loss is 3.9081303024291993 and perplexity is 49.80574318739111
At time: 760.368889093399 and batch: 100, loss is 3.88267035484314 and perplexity is 48.55369771394423
At time: 761.4848773479462 and batch: 150, loss is 3.8532139015197755 and perplexity is 47.1443372686358
At time: 762.6027312278748 and batch: 200, loss is 3.8465327167510988 and perplexity is 46.830407120980674
At time: 763.7240264415741 and batch: 250, loss is 3.8475867319107055 and perplexity is 46.8797931022311
At time: 764.862224817276 and batch: 300, loss is 3.853443398475647 and perplexity is 47.15515799213959
At time: 766.0065846443176 and batch: 350, loss is 3.864646830558777 and perplexity is 47.686428069251434
At time: 767.1484553813934 and batch: 400, loss is 3.815055766105652 and perplexity is 45.379286938496804
At time: 768.2915029525757 and batch: 450, loss is 3.8558821487426758 and perplexity is 47.270297988066325
At time: 769.4349417686462 and batch: 500, loss is 3.874109206199646 and perplexity is 48.139796553314724
At time: 770.5791368484497 and batch: 550, loss is 3.850358180999756 and perplexity is 47.0098982687644
At time: 771.733736038208 and batch: 600, loss is 3.8057181644439697 and perplexity is 44.95752541838222
At time: 772.8815710544586 and batch: 650, loss is 3.8347968292236327 and perplexity is 46.28402315170422
At time: 774.0330398082733 and batch: 700, loss is 3.8734929847717283 and perplexity is 48.11014091730058
At time: 775.205283164978 and batch: 750, loss is 3.8232140731811524 and perplexity is 45.751019388134395
At time: 776.3633093833923 and batch: 800, loss is 3.810120358467102 and perplexity is 45.155873430971035
At time: 777.5114130973816 and batch: 850, loss is 3.8135255479812624 and perplexity is 45.309899833394105
At time: 778.6633324623108 and batch: 900, loss is 3.766291470527649 and perplexity is 43.21948652563204
At time: 779.8185343742371 and batch: 950, loss is 3.8725391101837157 and perplexity is 48.06427175664516
At time: 780.9654474258423 and batch: 1000, loss is 3.824885425567627 and perplexity is 45.82754940006641
At time: 782.1172347068787 and batch: 1050, loss is 3.7846665477752683 and perplexity is 44.02098921433407
At time: 783.2609341144562 and batch: 1100, loss is 3.7959267330169677 and perplexity is 44.519474961356444
At time: 784.4120254516602 and batch: 1150, loss is 3.775648603439331 and perplexity is 43.62579498198619
At time: 785.5573577880859 and batch: 1200, loss is 3.81438729763031 and perplexity is 45.34896245235565
At time: 786.7090938091278 and batch: 1250, loss is 3.8156320095062255 and perplexity is 45.40544398880786
At time: 787.8534235954285 and batch: 1300, loss is 3.7901499843597413 and perplexity is 44.26303854164878
At time: 789.0036158561707 and batch: 1350, loss is 3.6699357891082762 and perplexity is 39.24938554134418
At time: 790.1551213264465 and batch: 1400, loss is 3.694058408737183 and perplexity is 40.20769554360122
At time: 791.3004970550537 and batch: 1450, loss is 3.6137965154647826 and perplexity is 37.1066617491135
At time: 792.4449980258942 and batch: 1500, loss is 3.6126438665390013 and perplexity is 37.06391543578785
At time: 793.5880362987518 and batch: 1550, loss is 3.645381212234497 and perplexity is 38.29736949497222
At time: 794.7334589958191 and batch: 1600, loss is 3.7215184688568117 and perplexity is 41.32710040268852
At time: 795.8815543651581 and batch: 1650, loss is 3.6864016008377076 and perplexity is 39.901008562728045
At time: 797.038033246994 and batch: 1700, loss is 3.6844958114624022 and perplexity is 39.82503805942819
At time: 798.192214012146 and batch: 1750, loss is 3.6734533309936523 and perplexity is 39.387690002223614
At time: 799.3452355861664 and batch: 1800, loss is 3.6206387758255003 and perplexity is 37.36142577689252
At time: 800.5068459510803 and batch: 1850, loss is 3.65067147731781 and perplexity is 38.500509590299224
At time: 801.6620454788208 and batch: 1900, loss is 3.7695594310760496 and perplexity is 43.36095713680426
At time: 802.8148987293243 and batch: 1950, loss is 3.7080143213272097 and perplexity is 40.77276448302499
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311210029069767 and perplexity of 74.53061861469685
finished 17 epochs...
Completing Train Step...
At time: 806.4917829036713 and batch: 50, loss is 3.9083943128585816 and perplexity is 49.818894158956155
At time: 807.6148579120636 and batch: 100, loss is 3.880758829116821 and perplexity is 48.46097472108288
At time: 808.7443428039551 and batch: 150, loss is 3.850336055755615 and perplexity is 47.00885817479438
At time: 809.864072561264 and batch: 200, loss is 3.842822203636169 and perplexity is 46.65696426117917
At time: 810.9839901924133 and batch: 250, loss is 3.8435617542266844 and perplexity is 46.691482208961254
At time: 812.1197888851166 and batch: 300, loss is 3.8491900825500487 and perplexity is 46.95501813841347
At time: 813.2621922492981 and batch: 350, loss is 3.8602176475524903 and perplexity is 47.47568321071631
At time: 814.4080436229706 and batch: 400, loss is 3.8099350690841676 and perplexity is 45.1475073021485
At time: 815.554206609726 and batch: 450, loss is 3.850762815475464 and perplexity is 47.0289239432658
At time: 816.6984066963196 and batch: 500, loss is 3.8688732099533083 and perplexity is 47.88839550110511
At time: 817.8446989059448 and batch: 550, loss is 3.845045623779297 and perplexity is 46.76081770747275
At time: 818.9909250736237 and batch: 600, loss is 3.8009031581878663 and perplexity is 44.74157497083299
At time: 820.1360292434692 and batch: 650, loss is 3.8302764749526976 and perplexity is 46.07527513292951
At time: 821.2805013656616 and batch: 700, loss is 3.869251165390015 and perplexity is 47.90649860140699
At time: 822.4338705539703 and batch: 750, loss is 3.8193358898162844 and perplexity is 45.57393215614998
At time: 823.5788850784302 and batch: 800, loss is 3.8065821886062623 and perplexity is 44.996386592699764
At time: 824.7236557006836 and batch: 850, loss is 3.8103652000427246 and perplexity is 45.16693081976949
At time: 825.8688704967499 and batch: 900, loss is 3.7632808446884156 and perplexity is 43.08956449418505
At time: 827.014134645462 and batch: 950, loss is 3.8696866607666016 and perplexity is 47.927366203598694
At time: 828.159695148468 and batch: 1000, loss is 3.8222547483444216 and perplexity is 45.70715034462551
At time: 829.3242833614349 and batch: 1050, loss is 3.7822375869750977 and perplexity is 43.914193710700154
At time: 830.4801723957062 and batch: 1100, loss is 3.7939232873916624 and perplexity is 44.43037190037653
At time: 831.6554136276245 and batch: 1150, loss is 3.773958706855774 and perplexity is 43.55213415720898
At time: 832.8101811408997 and batch: 1200, loss is 3.8128918027877807 and perplexity is 45.281193999210544
At time: 833.9629282951355 and batch: 1250, loss is 3.8142449140548704 and perplexity is 45.34250596459901
At time: 835.1167924404144 and batch: 1300, loss is 3.7893349027633665 and perplexity is 44.22697525279196
At time: 836.2786550521851 and batch: 1350, loss is 3.669370274543762 and perplexity is 39.22719571709809
At time: 837.4357664585114 and batch: 1400, loss is 3.693769054412842 and perplexity is 40.196062956074805
At time: 838.5928106307983 and batch: 1450, loss is 3.6136387729644777 and perplexity is 37.10080891314385
At time: 839.7466378211975 and batch: 1500, loss is 3.6130020427703857 and perplexity is 37.07719322709166
At time: 840.9059610366821 and batch: 1550, loss is 3.6462088680267333 and perplexity is 38.32907965540096
At time: 842.060533285141 and batch: 1600, loss is 3.722686381340027 and perplexity is 41.37539503560668
At time: 843.2141704559326 and batch: 1650, loss is 3.687690758705139 and perplexity is 39.95248043238945
At time: 844.3709979057312 and batch: 1700, loss is 3.686029453277588 and perplexity is 39.88616226242367
At time: 845.5228002071381 and batch: 1750, loss is 3.675239992141724 and perplexity is 39.45812536098562
At time: 846.6765098571777 and batch: 1800, loss is 3.6224555015563964 and perplexity is 37.42936293334897
At time: 847.8276948928833 and batch: 1850, loss is 3.6526799488067625 and perplexity is 38.577914472850665
At time: 848.9871549606323 and batch: 1900, loss is 3.771406683921814 and perplexity is 43.44112981507629
At time: 850.1373586654663 and batch: 1950, loss is 3.709358730316162 and perplexity is 40.82761661769006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310786757358285 and perplexity of 74.49907858766947
finished 18 epochs...
Completing Train Step...
At time: 853.9525694847107 and batch: 50, loss is 3.907367286682129 and perplexity is 49.76775511563609
At time: 855.1081008911133 and batch: 100, loss is 3.878845715522766 and perplexity is 48.36835199870742
At time: 856.2316565513611 and batch: 150, loss is 3.8480064821243287 and perplexity is 46.89947503585931
At time: 857.3497357368469 and batch: 200, loss is 3.8401525115966795 and perplexity is 46.53257065529611
At time: 858.4737040996552 and batch: 250, loss is 3.8407578897476196 and perplexity is 46.56074898528999
At time: 859.6064903736115 and batch: 300, loss is 3.8462975931167604 and perplexity is 46.819397479824985
At time: 860.7805433273315 and batch: 350, loss is 3.8573067235946654 and perplexity is 47.33768605410176
At time: 861.9020369052887 and batch: 400, loss is 3.8066753149032593 and perplexity is 45.00057713468318
At time: 863.0379455089569 and batch: 450, loss is 3.8475589179992675 and perplexity is 46.87848920995077
At time: 864.1828877925873 and batch: 500, loss is 3.8656256341934205 and perplexity is 47.7331265689711
At time: 865.3265097141266 and batch: 550, loss is 3.841798281669617 and perplexity is 46.609215620192394
At time: 866.4687728881836 and batch: 600, loss is 3.7979533767700193 and perplexity is 44.60979156605437
At time: 867.6103918552399 and batch: 650, loss is 3.8275347900390626 and perplexity is 45.949124258202296
At time: 868.7596311569214 and batch: 700, loss is 3.8665928411483765 and perplexity is 47.779316715084825
At time: 869.9160587787628 and batch: 750, loss is 3.816921911239624 and perplexity is 45.464050339805624
At time: 871.067919254303 and batch: 800, loss is 3.804320240020752 and perplexity is 44.894722102964145
At time: 872.2146594524384 and batch: 850, loss is 3.808265738487244 and perplexity is 45.072204057326566
At time: 873.3777389526367 and batch: 900, loss is 3.7612586402893067 and perplexity is 43.0025166312587
At time: 874.5526080131531 and batch: 950, loss is 3.8677902603149414 and perplexity is 47.836562851655394
At time: 875.7142953872681 and batch: 1000, loss is 3.8205256128311156 and perplexity is 45.62818477850994
At time: 876.8639469146729 and batch: 1050, loss is 3.780592703819275 and perplexity is 43.84201936861682
At time: 878.0144517421722 and batch: 1100, loss is 3.792529764175415 and perplexity is 44.36850026541913
At time: 879.1660854816437 and batch: 1150, loss is 3.772747721672058 and perplexity is 43.49942508941689
At time: 880.3168818950653 and batch: 1200, loss is 3.8117618417739867 and perplexity is 45.23005691223175
At time: 881.4687869548798 and batch: 1250, loss is 3.8132140159606935 and perplexity is 45.29578654723166
At time: 882.617879152298 and batch: 1300, loss is 3.7886315298080446 and perplexity is 44.195878132222326
At time: 883.7691614627838 and batch: 1350, loss is 3.6687432098388673 and perplexity is 39.20260543784576
At time: 884.9191336631775 and batch: 1400, loss is 3.693361396789551 and perplexity is 40.17968006411676
At time: 886.0696997642517 and batch: 1450, loss is 3.613332076072693 and perplexity is 37.0894319550955
At time: 887.2216236591339 and batch: 1500, loss is 3.613036208152771 and perplexity is 37.0784600052159
At time: 888.3732376098633 and batch: 1550, loss is 3.646485686302185 and perplexity is 38.33969131381355
At time: 889.5283796787262 and batch: 1600, loss is 3.7231463956832886 and perplexity is 41.39443268924232
At time: 890.6794669628143 and batch: 1650, loss is 3.688202419281006 and perplexity is 39.972927772137524
At time: 891.831062078476 and batch: 1700, loss is 3.6865955114364626 and perplexity is 39.90874654140316
At time: 892.9815180301666 and batch: 1750, loss is 3.675954456329346 and perplexity is 39.48632685174469
At time: 894.1334910392761 and batch: 1800, loss is 3.6231825828552244 and perplexity is 37.45658701902731
At time: 895.2844109535217 and batch: 1850, loss is 3.653523783683777 and perplexity is 38.61048160127226
At time: 896.4357545375824 and batch: 1900, loss is 3.772114896774292 and perplexity is 43.47190627839455
At time: 897.5861191749573 and batch: 1950, loss is 3.7097456789016725 and perplexity is 40.84341786312766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310565043604651 and perplexity of 74.4825629482534
finished 19 epochs...
Completing Train Step...
At time: 901.2855236530304 and batch: 50, loss is 3.906040987968445 and perplexity is 49.70179195913756
At time: 902.4291367530823 and batch: 100, loss is 3.877054982185364 and perplexity is 48.281814684060386
At time: 903.5514781475067 and batch: 150, loss is 3.8459741258621216 and perplexity is 46.804255386975974
At time: 904.6726369857788 and batch: 200, loss is 3.8379395961761475 and perplexity is 46.42971186301472
At time: 905.792542219162 and batch: 250, loss is 3.838480439186096 and perplexity is 46.454829839958606
At time: 906.9144582748413 and batch: 300, loss is 3.843972225189209 and perplexity is 46.710651640583635
At time: 908.0558762550354 and batch: 350, loss is 3.854986157417297 and perplexity is 47.22796317976366
At time: 909.205454826355 and batch: 400, loss is 3.80415771484375 and perplexity is 44.88742617321011
At time: 910.3581371307373 and batch: 450, loss is 3.8451004600524903 and perplexity is 46.76338196675387
At time: 911.5113208293915 and batch: 500, loss is 3.8631656694412233 and perplexity is 47.6158490684993
At time: 912.6654539108276 and batch: 550, loss is 3.8393535947799684 and perplexity is 46.49540984824819
At time: 913.8185951709747 and batch: 600, loss is 3.795711727142334 and perplexity is 44.509904041643004
At time: 914.9708931446075 and batch: 650, loss is 3.825441770553589 and perplexity is 45.85305242097516
At time: 916.1250035762787 and batch: 700, loss is 3.8645389747619627 and perplexity is 47.68128508890991
At time: 917.2815775871277 and batch: 750, loss is 3.8150463342666625 and perplexity is 45.3788589303874
At time: 918.4776737689972 and batch: 800, loss is 3.8025480270385743 and perplexity is 44.81522955329172
At time: 919.6315698623657 and batch: 850, loss is 3.806575975418091 and perplexity is 44.996107022551335
At time: 920.7860865592957 and batch: 900, loss is 3.759616985321045 and perplexity is 42.93197925104528
At time: 921.9391846656799 and batch: 950, loss is 3.8662337112426757 and perplexity is 47.76216081436138
At time: 923.0917611122131 and batch: 1000, loss is 3.819090905189514 and perplexity is 45.562768610894565
At time: 924.2462871074677 and batch: 1050, loss is 3.7792120742797852 and perplexity is 43.781531546850566
At time: 925.4003248214722 and batch: 1100, loss is 3.791313052177429 and perplexity is 44.31454940679774
At time: 926.5545334815979 and batch: 1150, loss is 3.7716639614105225 and perplexity is 43.45230767770632
At time: 927.7081665992737 and batch: 1200, loss is 3.81073184967041 and perplexity is 45.183494294448614
At time: 928.8666636943817 and batch: 1250, loss is 3.8122708797454834 and perplexity is 45.25308658964588
At time: 930.0276582241058 and batch: 1300, loss is 3.787925329208374 and perplexity is 44.16467799465698
At time: 931.1810436248779 and batch: 1350, loss is 3.668052763938904 and perplexity is 39.17554750174875
At time: 932.3332288265228 and batch: 1400, loss is 3.6928573131561278 and perplexity is 40.159431248977185
At time: 933.4864385128021 and batch: 1450, loss is 3.6129058170318604 and perplexity is 37.07362561844158
At time: 934.638201713562 and batch: 1500, loss is 3.6128580522537233 and perplexity is 37.07185484722976
At time: 935.7928159236908 and batch: 1550, loss is 3.6464592599868775 and perplexity is 38.338678150429246
At time: 936.9451620578766 and batch: 1600, loss is 3.7232486820220947 and perplexity is 41.398666990760965
At time: 938.0998282432556 and batch: 1650, loss is 3.6883371543884276 and perplexity is 39.97831389169641
At time: 939.253645658493 and batch: 1700, loss is 3.686733593940735 and perplexity is 39.91425762155109
At time: 940.4037520885468 and batch: 1750, loss is 3.6762006521224975 and perplexity is 39.49604941608071
At time: 941.5475587844849 and batch: 1800, loss is 3.623448038101196 and perplexity is 37.466531386381554
At time: 942.692164182663 and batch: 1850, loss is 3.6538766288757323 and perplexity is 38.62410752784432
At time: 943.8374643325806 and batch: 1900, loss is 3.772370624542236 and perplexity is 43.483024673536
At time: 944.982684135437 and batch: 1950, loss is 3.7097714233398436 and perplexity is 40.844469367508665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310454328670058 and perplexity of 74.47431707264751
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa196122b38>
ELAPSED
5830.986634731293


RESULTS SO FAR:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}, 'best_accuracy': -74.98631242869352}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.17814085302781324, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.8667473068914826}, 'best_accuracy': -75.01846336550948}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.46505974392752214, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.5624524957122032}, 'best_accuracy': -75.18388560877887}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7505577639643596, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7101460218637431}, 'best_accuracy': -74.47431707264751}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.20248657679234472, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.9912900087454175}, 'best_accuracy': -88.38281320453017}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7605020115795246, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7016045975715188}, 'best_accuracy': -74.48768007880594}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.8785975160962679, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.20780870029632548}, 'best_accuracy': -74.98631242869352}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.17814085302781324, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.8667473068914826}, 'best_accuracy': -75.01846336550948}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.46505974392752214, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.5624524957122032}, 'best_accuracy': -75.18388560877887}, {'params': {'num_layers': 2, 'batch_size': 32, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'rnn_dropout': 0.7505577639643596, 'tune_wordvecs': 'TRUE', 'data': 'wikitext', 'seq_len': 35, 'tie_weights': 'FALSE', 'dropout': 0.7101460218637431}, 'best_accuracy': -74.47431707264751}]
